\definecolor{applegreen}{rgb}{0.01, 0.75, 0.24}
\definecolor{brightmaroon}{rgb}{0.66, 0.13, 0.24}
\definecolor{warningyellow}{rgb}{0.86, 0.58, 0.17}
\begin{table}[t]
    \centering
    % \caption{\textbf{Robust performance evaluation of RFI on state-of-the-art methods.} We apply APGD-CE, APGD-DLR and RobustBench attacks on both CIFAR-10 and CIFAR-100. The inference time for RFI is $1\times$, whereas Anti-adv and SODEF are $8\times$ and $2\times$, respectively. }
    \resizebox{\linewidth}{!}{
    \begin{tabular}{@{}lclcccc@{}}
         \toprule 
         %Dataset & 
         % & 
         Base Method & Adaptive Defense & Clean & APGD-CE  & APGD-DLR  & RobustBench\\
         \midrule
         % \multirow{20}{*}{\begin{sideways}CIFAR-10\end{sideways}}&
         % \multirowcell{4}{WideResNet-28-10} & None & \textbf{89.69} &  61.82 & 60.85  & 59.53\\
          % &
          % &Anti-adv & \textbf{89.69} & 61.81 & 60.89 & 58.70\\
          % &
          % &SODEF & 89.68 & 60.20 & 60.72& 57.23\\
          % &
          % &RFI ($K=10$) & 89.60 & 62.38 & 61.58 & 60.72\\
          % &
          % &RFI & 89.60 & \textbf{62.45} & \textbf{61.60} & \textbf{61.02}\\
         % \cmidrule{1-6}
         %\midrule
         % &
         % \multirowcell{4}{~\citet{engstrom2019adversarial}\\ResNet-50} & None & \textbf{87.03} & 51.75 & 60.10 & 49.25\\
          % &
          % &Anti-adv \cite{alfarra2022combating}& 87.00 & 51.62 & 59.95& 49.20\\
          % &
          % &SODEF \cite{kang2021stable}& 86.95 & 50.01 & 58.20& 47.92\\
          % &
          % &RFI ($K=10$)&87.01 & 51.86 & 61.84 & 50.75\\
          % &
          % & RFI (opt. $K=15$) & \textbf{87.03} & \textbf{51.94} & \textbf{61.90} & \textbf{50.98}\\
         % \cmidrule{1-6}
         %\midrule
         % &
         \multirowcell{4}{WideResNet-34-10}  & None & 85.34 & 50.12 & 56.80& 53.42\\
          % &
          &Anti-adv \color{brightmaroon}{$\mathbf{[8\times]}$} & \textbf{85.40} & 50.10 &  57.50 & 50.98\\
          % &
          &SODEF \color{brightmaroon}{$\mathbf{[2\times]}$} & 85.10 & 50.60 & 56.50& 50.09\\
          % &
          % &RFI($K=10$) & 85.30 & 51.19 & 58.55 & 54.64\\
          % &
          &RFI \color{applegreen}{$\mathbf{[1\times]}$} & 85.30 & \textbf{51.62} & \textbf{58.97} & \textbf{54.86} \\
          \cmidrule{1-6}
          %\midrule
         % &
         \multirowcell{4}{WideResNet-28-10 \\ \color{warningyellow}{Current SOTA}}  & None & \textbf{92.44} & 70.23 &  67.82 & 67.31\\
          % &
          &Anti-adv \color{brightmaroon}{$\mathbf{[8\times]}$} & \textbf{92.44} & 68.90 &  65.91 & 66.52\\
          % &
          &SODEF \color{brightmaroon}{$\mathbf{[2\times]}$} & 92.01 & 67.53 & 65.08 & 64.20\\
          % &
          % &RFI ($K=10$) & 92.33 & 70.32 & 67.86 & 67.29\\
          % &
          & RFI \color{applegreen}{$\mathbf{[1\times]}$} & 92.34 & \textbf{70.36} & \textbf{67.90} & \textbf{67.50}\\
          %\cline{2-7}
         \bottomrule
    \end{tabular}
    }
    %\caption{(Base/Ours) Indicate the performance of adversarial training methods after adding our adaptive test time defense on APGD-CE and APGD-DLR attacks ~\cite{croce2020reliable}}
    \label{tab:benchmarkcomparison}
\end{table}