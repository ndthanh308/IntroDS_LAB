
\documentclass[10pt]{article} % For LaTeX2e
% \usepackage{tmlr}
% If accepted, instead use the following line for the camera-ready submission:
\usepackage[accepted]{tmlr}
% To de-anonymize and remove mentions to TMLR (for example for posting to preprint servers), instead use the following:
% \usepackage[preprint]{tmlr}

% Optional math commands from https://github.com/goodfeli/dlbook_notation.
%\input{math_commands.tex}
\usepackage{float}
\usepackage[hidelinks]{hyperref}
\usepackage{url}
% Attempt to make hyperref and algorithmic work together better:
\newcommand{\theHalgorithm}{\arabic{algorithm}}
% For theorems and such
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{amsthm} 
% \usepackage{algorithm}
% \usepackage{algpseudocode}

% if you use cleveref..
\usepackage[capitalize,noabbrev]{cleveref}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% THEOREMS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{assumption}[theorem]{Assumption}
\theoremstyle{remark}
\newtheorem{remark}[theorem]{Remark}

% Todonotes is useful during development; simply uncomment the next line
%    and comment out the line below the next line to turn off comments
%\usepackage[disable,textsize=tiny]{todonotes}
\usepackage[textsize=tiny]{todonotes}

\usepackage{wrapfig}
\usepackage{graphicx}
\usepackage{bm}
\usepackage{comment}
\usepackage{sidecap}

\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{xcolor}         % colors
\usepackage{amsmath}

\usepackage{subcaption}
\usepackage{multirow,makecell}
\usepackage{enumitem}
\usepackage{amsthm}
\usepackage{multirow,rotating}
\usepackage{diagbox}

\definecolor{applegreen}{rgb}{0.01, 0.75, 0.24}
\definecolor{brightmaroon}{rgb}{0.66, 0.13, 0.24}
\definecolor{warningyellow}{rgb}{0.86, 0.58, 0.17}

\title{Robust Feature Inference: A Test-time Defense Strategy using Spectral Projections}

% Authors must not appear in the submitted version. They should be hidden
% as long as the tmlr package is used without the [accepted] or [preprint] options.
% Non-anonymous submissions will be rejected without review.

\author{\name Anurag Singh\thanks{Equal contribution. This work was partly done when AS was a master's student at TU Munich.} \email anurag.singh@cispa.de \\
      \addr CISPA Helmholtz Center for Information Security, Saarbr\"ucken, Germany
      \ANDD
      \name Mahalakshmi Sabanayagam$^{ *}$ \email sabanaya@cit.tum.de \\
      \addr School of Computation, Information and Technology \\ Technical University of Munich, Germany
      \ANDD
      \name Krikamol Muandet \email muandet@cispa.de\\
      \addr CISPA Helmholtz Center for Information Security, Saarbr\"ucken, Germany
      \ANDD
      \name Debarghya Ghoshdastidar 
      \email ghoshdas@cit.tum.de \\
      \addr School of Computation, Information and Technology \\ Technical University of Munich, Germany}
% The \author macro works with any number of authors. Use \AND 
% to separate the names and addresses of multiple authors.

\newcommand{\fix}{\marginpar{FIX}}
\newcommand{\new}{\marginpar{NEW}}

\def\month{08}  % Insert correct month for camera-ready version
\def\year{2024} % Insert correct year for camera-ready version
\def\openreview{\url{https://openreview.net/forum?id=9OHAtWdFWB}} % Insert correct link to OpenReview for camera-ready version


\begin{document}


\maketitle

\begin{abstract}
%Test-time defenses are used to improve the robustness of deep neural networks to adversarial examples during inference. However, existing methods either require an additional trained classifier or more complex test-time optimizations, resulting in a significant increase in the inference time compared to the base model. In this work, we propose a novel defense strategy called Robust Feature Inference (RFI) that is easy to integrate with any existing (robust) training procedure without additional test-time computation. Based on the notion of robustness of features that we present, the key idea is to project the trained models to the most robust feature space, thereby reducing the vulnerability to adversarial attacks in non-robust directions. 
%We theoretically characterize the robust subspace using the eigenspectrum of the feature covariance for a generalized additive model.
%Our extensive experiments on CIFAR-10, CIFAR-100 and ImageNet datasets, benchmarked against the state-of-the-art methods in RobustBench, shows that RFI improves robustness consistently against adaptive attacks. Notably, the robustness gain is \emph{$4$ to $9\%$} for calibrated ResNet models on CIFAR-10 and CIFAR-100 across training settings for adaptive attacks in both $\ell_\infty$ and $\ell_2$ perturbations. Additional comparative study with other adaptive test-time defenses and transfer attacks further highlight the efficacy of our approach.
%The robustness of deep learning models to adversarial examples is a crucial property of deployable models. 
Test-time defenses are used to improve the robustness of deep neural networks to adversarial examples during inference. However, existing methods either require an additional trained classifier to detect and correct the adversarial samples, or perform additional complex optimization on the model parameters or the input to adapt to the adversarial samples at test-time, resulting in a significant increase in the inference time compared to the base model. In this work, we propose a novel test-time defense strategy called Robust Feature Inference (RFI) that is easy to integrate with any existing (robust) training procedure without additional test-time computation. Based on the notion of robustness of features that we present, the key idea is to project the trained models to the most robust feature space, thereby reducing the vulnerability to adversarial attacks in non-robust directions. 
We theoretically characterize the subspace of the eigenspectrum of the feature covariance that is the most robust for a generalized additive model.
Our extensive experiments on CIFAR-10, CIFAR-100, tiny ImageNet and ImageNet datasets for several robustness benchmarks, including the state-of-the-art methods in RobustBench show that RFI improves robustness across adaptive and transfer attacks consistently. We also compare RFI with adaptive test-time defenses to demonstrate the effectiveness of our proposed approach.
\end{abstract}


\input{texfiles/introduction}
\input{texfiles/relatedworks}
\input{texfiles/method}
%\input{texfiles/motivation}
\input{texfiles/experiments}
\input{texfiles/robustlearnfirst}
\input{texfiles/discussion}
\input{texfiles/conclusion}

\bibliography{citations}
\bibliographystyle{tmlr}
\newpage
\appendix
\input{texfiles/appendix-new}

\end{document}
