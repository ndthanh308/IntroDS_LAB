\documentclass{article}


% if you need to pass options to natbib, use, e.g.:
\PassOptionsToPackage{numbers, compress}{natbib}
% before loading neurips_2023


% ready for submission
% \usepackage{neurips_2023}

% to compile a preprint version, e.g., for submission to arXiv, add add the
% [preprint] option:
    \usepackage[preprint]{neurips_2023}


% to compile a camera-ready version, add the [final] option, e.g.:
%     \usepackage[final]{neurips_2023}


% to avoid loading the natbib package, add option nonatbib:
%    \usepackage[nonatbib]{neurips_2023}

\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{xcolor}         % colors
\usepackage{amsmath}
\usepackage{wrapfig}
\usepackage{graphicx}
\usepackage{subcaption}
\usepackage{multirow,makecell}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{enumitem}
\usepackage{bm}
\usepackage{amsthm}

\newcommand{\Krik}[1]{\textcolor{cyan}{Krik: #1}}

\bibliographystyle{plainnat}
%\title{Adaptive Test-Time Defense with Useful Features}
%\title{Theory guided Adaptive Test-Time Defense with Useful Features }
\title{Fast Adaptive Test-Time Defense with Robust Features}
%\title{}
\DeclareMathOperator*{\argmax}{argmax}
\newcommand{\comment}[2]{\textcolor{red}{[#1: #2]}}
% The \author macro works with any number of authors. There are two commands
% used to separate the names and addresses of multiple authors: \And and \AND.
%
% Using \And between authors leaves it to LaTeX to determine where to break the
% lines. Using \AND forces a line break at that point. So, if LaTeX puts 3 of 4
% authors names on the first line, and the last on the second line, try using
% \AND instead of \And before the third author name.


\author{%
Anurag Singh\thanks{Equal contribution. This work was partly done when AS was in TU Munich}$^{ \,\,\,,1}$ \\
  %Max Planck Institute for Intelligent Systems \\ Tübingen, Germany \\
  {\tt anurag.singh@cispa.de} \\\And
  Mahalakshmi Sabanayagam$^{ *,2}$  \\
  %School of Computation, Information and Technology \\ Technical University of Munich, Germany \\
  {\tt sabanaya@cit.tum.de} \\\And
  Krikamol Muandet$^{1}$ \\
  % Max Planck Institute for Intelligent Systems \\ Tübingen, Germany \\
  {\tt muandet@cispa.de} \\\And
  Debarghya Ghoshdastidar$^{2}$ \\
  % School of Computation, Information and Technology \\ Technical University of Munich, Germany \\
  {\tt ghoshdas@cit.tum.de} \\
  $^1$ CISPA--Helmholtz Center for Information Security, Saarbrücken, Germany \\
$^2$ School of Computation, Information and Technology, Technical University of Munich \\
  %
  %Debarghya Ghoshdastidar\thanks{Use footnote for providing further information
  %  about author (webpage, alternative address)---\emph{not} for acknowledging
 %   funding agencies.} \\
 % Department of Computer Science\\
 % Cranberry-Lemon University\\
 % Pittsburgh, PA 15213 \\
 % \texttt{hippo@cs.cranberry-lemon.edu} \\
  % examples of more authors
  % \And
  % Coauthor \\
  % Affiliation \\
  % Address \\
  % \texttt{email} \\
  % \AND
  % Coauthor \\
  % Affiliation \\
  % Address \\
  % \texttt{email} \\
  % \And
  % Coauthor \\
  % Affiliation \\
  % Address \\
  % \texttt{email} \\
  % \And
  % Coauthor \\
  % Affiliation \\
  % Address \\
  % \texttt{email} \\
}
\newtheorem{theorem}{Theorem}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{prop}[theorem]{Proposition}
\newtheorem{definition}{Definition}
\newtheorem{remark}{Remark}

\usepackage{multirow,rotating}
\begin{document}


\maketitle


\begin{abstract}
%The robustness of deep learning models to adversarial examples is a crucial property of deployable models. 
Adaptive test-time defenses are used to improve the robustness of deep neural networks to adversarial examples. However, existing methods significantly increase the inference time due to additional optimization on the model parameters or the input at test time. In this work, we propose a novel adaptive test-time defense strategy that is easy to integrate with any existing (robust) training procedure without additional test-time computation. Based on the notion of robustness of features that we present, the key idea is to project the trained models to the most robust feature space, thereby reducing the vulnerability to adversarial attacks in non-robust directions. 
We theoretically show that the top eigenspace of the feature matrix are more robust for a generalized additive model and support our argument for a large width neural network with the Neural Tangent Kernel (NTK) equivalence.
We conduct extensive experiments on CIFAR-10 and CIFAR-100 datasets for several robustness benchmarks, including the state-of-the-art methods in RobustBench, and observe that the proposed method outperforms existing adaptive test-time defenses at much lower computation costs. 
\end{abstract}
\input{texfiles/introduction}
\input{texfiles/relatedworks}
\input{texfiles/method}
%\input{texfiles/motivation}
\input{texfiles/experiments}
\input{texfiles/robustlearnfirst}
\input{texfiles/conclusion}
\input{texfiles/ack}


%\newpage
\bibliography{citations}

\newpage
\appendix
\input{texfiles/appendix-new}
%\input{texfiles/appendix}
\end{document}
