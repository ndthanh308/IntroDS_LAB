\section{Adaptive Test-Time Defense Using Robust Features}
\label{sec:method}
%TODO{Add multi class classification and also y as discrete set}

We are primarily interested in the multi-class classification problem, that is, we aim to learn a predictor $h:\mathcal{X}\to\mathcal{Y}$ where $\mathcal{X} \subseteq \mathbb{R}^d$ and $\mathcal{Y} \subset \{0,1\}^C$ is the set of one-hot encodings of $C$ classes.
We assume that the data is independent and identically distributed (i.i.d) according to an unknown joint distribution $\mathcal{D}$ over instance-labels $(\mathbf{x},y)\in\mathcal{X}\times\mathcal{Y}$.
%
The goal of the paper is to develop an adaptive test-time defense mechanism that can be integrated with any existing training procedure.
Hence, we assume that there exists a learned predictor $h:\mathcal{X}\to\mathcal{Y}$ that we aim to make robust against adversarial attacks.
We aim to achieve this by decomposing the predictor into two components, $h(\mathbf{x}) = h_{\text{robust}}(\mathbf{x}) + h_{\text{nonrobust}}(\mathbf{x})$ such that $h_{\text{robust}}: \mathcal{X}\to\mathcal{Y}$ corresponds to the robust component of the predictor while $h_{\text{nonrobust}}:\mathcal{X}\to\mathcal{Y}$ represents the remaining (non robust) component of $h$.
%
In this section, we formally characterize this problem by proposing a notion of robustness of features, inspired by \citet{featuresnotbugs}, and use this notion to present an algorithm in Section \ref{sec:our-algorithm}, based on pruning less robust features. We also show that the more robust features are more informative in Section~\ref{sec:robust-info}.
As a supplementary result we show that the robust NTK features correspond to the top spectrum in Section~\ref{sec:ntk}.

\subsection{Robust and Non-Robust Features} 
\label{sec:robust-non-robust}

The additive decomposition of a predictor in the form $h = h_{\text{robust}} + h_{\text{nonrobust}}$ is difficult in general for predictors with non-linearities in the output, for instance, softmax in multi-class classifiers.
Hence, we relax the setup to a multivariate regression problem, that is, $\mathcal{Y} = \mathbb{R}^C$.
We further assume that the trained model $h:\mathcal{X}\to\mathcal{Y}$ is given by a generalized additive model (GAM) of the form $h(\mathbf{x}) = \bm{\beta}^\top \phi(\mathbf{x})$, where $\phi:\mathcal{X}\rightarrow\mathcal{H}$ is a smooth function that maps the data into a \emph{feature space} $\mathcal{H}$ and $\bm{\beta}$ are weights learned in the feature space.
The above form of $h$ may represent the solution of kernel regression (with $\mathcal{H}$ being the corresponding reproducing kernel Hilbert space) or $h$ could be the output layer of a neural network, where $\mathcal{H} = \mathbb{R}^p$, $\phi(\mathbf{x})$ denotes the representation learned in the last hidden layer and $\bm{\beta}\in\mathbb{R}^{p\times C}$ are learned weights of the output layer.   

\textbf{Features and their robustness.}
To identify the robust component of $h$, we aim to approximate $\phi$ as sum of $K$ robust components $(\phi_i)_{i=1}^K$, or alternatively, $h(\mathbf{x}) \approx \sum_{i=1}^K \bm{\beta}^\top \phi_i(\mathbf{x})$.
We refer to each $\phi_i:\mathcal{X}\to\mathcal{H}$ as a \emph{feature}.
More generally, we define the set of all features as $\mathcal{F} = \{f: \mathcal{X}\rightarrow \mathcal{H}\}$. 
%We assume that the features in $\mathcal{F}$ have zero mean and unit variance such that $\mathbb{E}_{(\mathbf{x},y)\sim \mathcal{D}}[f(\mathbf{x})] = 0$ and $\mathbb{E}_{(\mathbf{x},y)\sim\mathcal{D}}[f(\mathbf{x})^2] = 1$ in order to make the following definitions scale-invariant. 
We now define the robustness of a feature as follows. \\

\begin{definition}[$\ell_2$-Robustness of features]
\label{def:robust}
Given a distribution $\mathcal{D}$ on $\mathcal{X}\times \mathbb{R}^C$ and a trained model $h(\mathbf{x}) = \bm{\beta}^\top \phi(\mathbf{x})$, we define the robustness of a feature $f \in \mathcal{F}$  as
$s_{\mathcal{D},\bm{\beta}}(f) = \mathbb{E}_{(\mathbf{x},y)\sim \mathcal{D}}\left[\inf\limits_{||\tilde{\mathbf{x}}-\mathbf{x}||_2 \leq \Delta} y^\top \bm{\beta}^\top  f(\tilde{\mathbf{x}})\right]$, while we use $s_{\mathcal{D},\bm{\beta},c}(f) = \mathbb{E}_{(\mathbf{x},y)\sim \mathcal{D}}\left[\inf\limits_{||\tilde{\mathbf{x}}-\mathbf{x}||_2 \leq \Delta} y_c \bm{\beta}_c^\top  f(\tilde{\mathbf{x}})\right]$ to specify the robustness of $f$ with respect to the $c$-th class component of $y \in \mathbb{R}^C$, where $c \in\{1,\ldots,C\}$ and $\bm{\beta}_c$ is $c$-th column of $\bm\beta$.
%Subsequently, we use only $s(f)$ and $s_c(f)$, respectively, for the score.
\end{definition}

%The useful, robust, and non-robust features~\citep{featuresnotbugs} can then be formally defined as follows: 
%\begin{itemize}[leftmargin=*]
%    \item \textbf{$\rho-$useful features:} For a given distribution $\mathcal{D}$ and some $\rho > 0$, a feature $f$ is said to be $\rho-$useful if it is correlated with the true label in expectation, that is if $\mathbb{E}_{(\mathbf{x},y)\sim \mathcal{D}}[yf(\mathbf{x})] \geq \rho$.
%    \item \textbf{$\gamma-$robustly useful features:} Let $f$ be a $\rho-$useful feature given a distribution $\mathcal{D}$.  %\Krik{I don't quite understand this equation}. 
%    Then, under the same distribution $\mathcal{D}$, $f$ is a $\gamma-$robustly useful feature for some $\gamma > 0$, if $f$ remains $\gamma-$useful under adversarial perturbation (for some specified set of valid perturbations $\Delta$ of $\ell_p$-norm), i.e., 
    %$\mathbb{E}_{(x,y)\sim \mathcal{D}}[\inf_{\delta\in \Delta(x)}yf(x + \delta)]\geq \gamma$.
    %\Krik{I don't think this is clear. We need to elaborate it.}
%    $\mathbb{E}_{(\mathbf{x},y)\sim \mathcal{D}}[\inf_{||\tilde{\mathbf{x}}-\mathbf{x}||_p \leq \Delta}yf(\tilde{\mathbf{x}})]\geq \gamma$.
%    \item \textbf{Useful, non-robust features:} A useful, non-robust feature is a feature which is $\rho-$useful for some $\rho$ bounded away from zero, but is not a $\gamma-$robust feature for any $\gamma\geq0$. 
%    These features contain information that can improve the classification accuracy in the standard setting but may hinder it in the adversarial environment, as the correlation with the label can be flipped.
%\end{itemize}

The above definition is based on the notion of robust features introduced by \citet{featuresnotbugs}, specialized to the case of GAM model. 
Based on Definition \ref{def:robust}, the goal would be to approximate $h$ using the most robust feature (or features).
However, searching over all $f\in\mathcal{F}$ is difficult, and hence, we focus on features that are linear transformations of $\phi$, that is, $f(x) = \bm{M}^\top \phi(x)$ for some $\bm{M} : \mathcal{H}\to\mathcal{H}$ (or in $\bm{M}\in\mathbb{R}^{p\times p}$). For such features, one can bound the robustness score from below, under an independent noise model. \\

\begin{theorem}[Lower bound on robustness]
\label{thm:compute-robustness}
Given $h(\mathbf{x}) = \bm{\beta}^\top \phi(\mathbf{x})$. Assume that the distribution $\mathcal{D}$ is such that $y = h(\mathbf{x}) + \bm{\epsilon}$, where $\bm{\epsilon} \in \mathbb{R}^C$ has independent coordinates, each satisfying $\mathbb{E}[\epsilon_c] = 0$, $\mathbb{E}[\epsilon_c^2] \leq \sigma^2$ for all $c \in \{1,\ldots,C\}$.
Further, assume that the map $\phi$ is $L$-Lipschitz, that is, $\Vert\phi(\mathbf{x})- \phi(\tilde{\mathbf{x}})\Vert_\mathcal{H} \leq L\Vert \mathbf{x}-\tilde{\mathbf{x}}\Vert$.
Then, for any $f = \bm{M}\phi$ and every $c \in\{1,\ldots,C\}$,
\[
s_{\mathcal{D},\bm{\beta},c}(f)  ~\geq~ \bm{\beta}_c^\top \Sigma \bm{M}  \bm{\beta}_c - L \Delta \Vert \bm{M}\Vert_{op} \Vert \bm{\beta}_c\Vert_\mathcal{H} \sqrt{\sigma^2 + \bm{\beta}_c^\top \Sigma \bm{\beta}_c},
\]
where $\Sigma = \mathbb{E}_\mathbf{x} \left[\phi(\mathbf{x})\phi(\mathbf{x})^\top\right]$ and $\Vert \bm{M} \Vert_{op}$ denotes the operator norm.
\end{theorem}

\begin{remark}[Lower bound is reasonably tight]
\label{rem:thm-robust-linear}
In the case of linear models $\phi(\mathbf{x}) = \mathbf{x}$ and assuming $\mathbb{E}_\mathbf{x}[\mathbf{x}] =0$, one can compute $s_{\mathcal{D},\bm{\beta},c}(f) = \bm{\beta}_c^\top \Sigma \bm{M}  \bm{\beta}_c - \sqrt{2/\pi}\Delta \Vert \bm{M}\Vert_{op} \Vert \bm{\beta}_c\Vert_\mathcal{H} \sqrt{\sigma^2 + \bm{\beta}_c^\top \Sigma \bm{\beta}_c}$.
In this case, the lower bound in Theorem \ref{thm:compute-robustness} is reasonably tight, differing by a constant factor of $\sqrt{2/\pi}$.
\end{remark}

Theorem \ref{thm:compute-robustness} suggests that if we search only over $f\in \mathcal{F}$ that are linear transformations $f = \bm{M}^\top\phi$ such that $\Vert \bm{M}\Vert_{op}=1$, then the most robust feature is the one that maximizes the first term $\bm{\beta}_c^\top \Sigma \bm{M}  \bm{\beta}_c$. In particular, we restrict our search to projections onto $K$ dimensional subspace, $\bm{M} = \bm{P}\bm{P}^\top$, where $\bm{P}$ is the orthonormal basis for the subspace. 
We show that optimising over such features $f$ corresponds to projecting onto top $K$ eigenvectors $\mathbf{u}$ of $\Sigma$ sorted according to a specific \emph{robustness score}. \\

\begin{corollary}
\label{cor:robust_score}
Fix any $K$ and $(\lambda_i, \mathbf{u}_i)_{i=1,2,\ldots}$ denote the eigenpairs of $\Sigma = \mathbb{E}_\mathbf{x} \left[\phi(\mathbf{x})\phi(\mathbf{x})^\top\right]$. Consider the problem of maximizing the lower bound in Theorem \ref{thm:compute-robustness} over all features $f\in\mathcal{F}$ that correspond to projection of $\phi$ onto $K$ dimensional subspace. Then the solution is given by $f = \Tilde{\mathbf{U}} \Tilde{\mathbf{U}} ^\top \phi$, where $\Tilde{\mathbf{U}}$ is the matrix of the $K$ eigenvectors for which the robustness score $s_c(\mathbf{u}_i) = \lambda_i (\bm{\beta}_c^\top \mathbf{u}_i)^2$ are largest.
\end{corollary}


%In Section \ref{sec:theory}, we show that if the features are chosen to be eigenfunctions (or eigenvectors) $\mathbf{u}_1,\mathbf{u}_2,\ldots$ of the sample covariance of $\phi(\mathbf{x})$, then under some noise assumptions, the robustness of feature $\mathbf{u}_i$ is approximately $s_c(\mathbf{u_i})= (\lambda_i\bm{\beta}_c^T\mathbf{u_i})^2$, where $\lambda_i$ is the $i$-th largest eigenvalue of $\phi(\mathbf{x})$.
The above results leads to principle idea of our adaptive test-time defense algorithm. The method retains and leverages only robust features of the pre-trained model at test time by effectively projecting the output of the pre-trained model to the eigenspace with higher robustness score.
One may naturally ask how much error is incurred by retaining only the robust features. 
Later, in Section \ref{sec:robust-info}, we discuss that the most robust features also contain most of the information, and hence, drop in performance due to the projection is low.

\subsection{Our Algorithm: Robust Feature Inference (RFI)}
\label{sec:our-algorithm}

\begin{algorithm}[t!]
\caption{Robust Feature Inference (RFI)}\label{alg:cap}
\begin{algorithmic}[1]
\Require The model $h$ trained on $\mathcal{D}_{\text{train}} := \{(\mathbf{x_i},y_i)\}_{i=1}^n$ such that $h(\mathbf{x})=\bm{\beta}^\top\phi(\mathbf{x})$ where $\phi:\mathcal{X}\rightarrow\mathbb{R}^p$ and $\bm{\beta}\in \mathbb{R}^{p\times C}$, and the number of top robust features to select $K$.
\State Compute the covariance $\Sigma_{\text{train}} \leftarrow \frac{1}{n}\Phi\Phi^\top$ where $\Phi := [\phi(x_1),\ldots,\phi(x_n)] \in \mathbb{R}^{p\times n}$.
\State Compute eigendecomposition of $\Sigma_{\text{train}} = \mathbf{U}\text{diag}(\bm{\lambda}) \mathbf{U}^\top$ where columns of $\mathbf{U}$ are $\mathbf{u_i} \in \mathbb{R}^p$.
\State Select top $K$ most robust features $\Tilde{\mathbf{U}} \in \mathbb{R}^{p \times K}$  \hfill (steps $4 \to 8$)
\State  $\Tilde{\mathbf{U}} \gets \{\}$, $\bm{\beta}_c \gets c$-th column of $\bm{\beta}$
\For{$c \gets 1$ to $C$}
    \State {For all $i$, compute robustness score $ s_c(\mathbf{u_i})\gets \lambda_i(\bm{\beta}_c^T\mathbf{u_i})^2$}
    %\State {$top_{rank_c}\gets rank_c[p-|\mathcal{Y}|:]$}
    %\State {$top \gets top\cup top_{rank_c}$}
    \State {$ \Tilde{\mathbf{U}} \gets \text{Union}(\Tilde{\mathbf{U}}, \mathbf{u_i}) $ if $s_c(\mathbf{u_i})$ is in top $K$ scores $s_c(.)$ }
\EndFor
%\State Select most useful eigenvectors i.e. $\Tilde{U} = U[top]$.
\State Robust Feature Inference on test set $X_{test}$ \hfill (steps $10 \to 11$)
\State $\Tilde{\bm{\beta}}= \Tilde{\mathbf{U}}\Tilde{\mathbf{U}}^T\bm{\beta}$
\State $\forall {\mathbf{x}_t} \in X_{test}$, \,\, $\Tilde{h}({\mathbf{x}_t}) = \Tilde{\bm{\beta}}^T\phi({\mathbf{x}_t})$
\end{algorithmic}
\end{algorithm}

Let $\mathcal{D}_{\text{train}} := \{(\mathbf{x_i},y_i)\}_{i=1}^n \subset\mathcal{X}\times\mathcal{Y}$ be a training dataset with $n$ samples, and $h:\mathcal{X}\rightarrow\mathcal{Y}$ a pre-trained model such that $h(\mathbf{x})=\bm{\beta}^{\top}\phi(\mathbf{x})$ for all $\mathbf{x}\in\mathcal{X}$ where $\phi: \mathcal{X}\to\mathbb{R}^p$ is the feature map defined by the hidden layers of the model $h$ and $\bm{\beta}\in\mathbb{R}^{p\times C}$ is the weight matrix defined by the last fully-connected layer. 
Hence, $p$ is the dimension of the feature space. 
As described in the previous section, we propose a method operating on the feature space of $\phi$ that projects the features in the robust directions, hence improving robustness by reducing the chance of attacks using the non-robust feature directions.
To this end, we first compute the corresponding covariance matrix $\Sigma_{\text{train}}$ of the hidden-layer features based on the input data from $\mathcal{D}_{\text{train}}$. In other words, 
\begin{equation}
 \Sigma_{\text{train}} = \frac{1}{n}\Phi\Phi^\top  \quad \text{with} \quad \Phi := [\phi(\mathbf{x_1}),\ldots,\phi(\mathbf{x_n})] \in \mathbb{R}^{p\times n}.
\end{equation} 
Next, we compute the eigendecomposition of the feature covariance matrix $\Sigma_{\text{train}}=\mathbf{U}\text{diag}(\bm{\lambda})\mathbf{U}^\top$ where $\mathbf{U}\in\mathbb{R}^{p\times p}$ is the matrix whose columns consist of eigenvectors of $\Sigma_{\text{train}}$ denoted by $\mathbf{u_i} \in \mathbb{R}^p$, $\bm{\lambda}\in\mathbb{R}^p$ is a vector of corresponding eigenvalues such that $\lambda_1 \geq \lambda_2 \geq \ldots$, and $\text{diag}(\bm{\lambda})$ is a diagonal matrix with eigenvalues as its diagonal entries. 
%
The idea of our algorithm is to retain only robustly useful features, i.e., top $K$ eigenvectors, when making predictions on previously unseen data.
For each class $c\in\mathcal{Y}$, we define the $c$-th column of $\bm\beta$ as $\bm{\beta}_c$ as class prototype for $c\in\mathcal{Y}$.
%:= \bm{\beta}_{\bm{\cdot} c} \in\mathbb{R}^p$ for $c\in\mathcal{Y}$ as a class prototype, i.e., the $c$-th column of $\bm{\beta}$. 
The classwise robustness score of each feature is computed according to Definition~\ref{def:robust}, that is, $s_c(\mathbf{u_i}) := \lambda_i(\bm{\beta}_c^\top\mathbf{u}_i)^2$ where $(\lambda_i,\mathbf{u}_i)$ is the $i$-th pair of eigenvalue and eigenvector.
We then select the top-$K$ most robust features for each class $c\in\mathcal{Y}$ based on the robustness score denoted by $\Tilde{\mathbf{U}}_c := \{\mathbf{u}_{\sigma(i)} \, | \, s_c(\mathbf{u}_{\sigma(i)}) \geq s_c(\mathbf{u}_{\sigma(j)}), \, \forall i,j \in [1,\ldots,K]\}$. The global robust features for the model $\Tilde{\mathbf{U}}$ is obtained as a union of the sets of classwise robust features $\Tilde{\mathbf{U}}_c$. 
%Let $\mathbf{U}_c \subset \mathbf{U} := \{\mathbf{u}_1,\ldots,\mathbf{u}_K\}$ be the set of the top-$K$ eigenvectors with the highest robustness scores $s_c$ for the class $c$. 
Finally, the prediction on a test data point ${\mathbf{x}_t}$ is subsequently obtained as
\begin{equation}
    \label{eq:robist-inference}
    \tilde{h}({\mathbf{x}_t}) = \tilde{\bm{\beta}}^\top\phi({\mathbf{x}_t}), \quad \tilde{\bm{\beta}} := \tilde{\mathbf{U}}\tilde{\mathbf{U}}^\top\bm{\beta}, 
    \quad \tilde{\mathbf{U}} := \bigcup_{c\in\mathcal{Y}} \tilde{\mathbf{U}}_{c}, 
    %\quad I := \bigcup_{c\in\mathcal{Y}} I_c .
\end{equation}
where $\bigcup$ denotes union of sets.
Therefore, the new prediction is based on the updated parameters $\tilde{\bm{\beta}}$ instead of the original $\bm{\beta}$.
It is not difficult to see that this corresponds to applying the original parameters $\bm{\beta}$ on the robustly useful features, i.e., $\tilde{h}({\mathbf{x}_t}) = \tilde{\bm{\beta}}^\top\phi({\mathbf{x}_t}) = \bm{\beta}^\top\tilde{\mathbf{U}}\tilde{\mathbf{U}}^\top\phi({\mathbf{x}_t}) = \bm{\beta}^\top\tilde{\phi}({\mathbf{x}_t})$ where $\tilde{\phi}({\mathbf{x}_t}) := \tilde{\mathbf{U}}\tilde{\mathbf{U}}^\top\phi({\mathbf{x}_t})$. 
Algorithm \ref{alg:cap} summarizes the proposed adaptive test-time defense.


\subsection{Robustness vs information of features}
\label{sec:robust-info}

The previous discussion focused only on robustness of features and projections onto the robust subspace. We show that the more robust features are also the more informative features.
To this end, we consider the following notion of informative features, inspired by the usefulness property in \cite{featuresnotbugs}.

\begin{definition}[Informative features]
\label{def:useful}
Given a distribution $\mathcal{D}$ on $\mathcal{X}\times \mathbb{R}^C$ and a trained model $h(\mathbf{x}) = \bm{\beta}^\top \phi(\mathbf{x})$, we define the information in a feature $f \in \mathcal{F}$ with respect to the $c$-th class component of $y \in \mathbb{R}^C$ as  $\rho_{\mathcal{D},\bm{\beta},c}(f) = \mathbb{E}_{(\mathbf{x},y)\sim \mathcal{D}}\left[ y_c \bm{\beta}_c^\top  f(\mathbf{x})\right]$, where $c \in\{1,\ldots,C\}$ and $\bm{\beta}_c$ is $c$-th column of $\bm\beta$.
\end{definition}

\begin{corollary}
\label{cor:information}
Let $(\lambda_i, \mathbf{u}_i)_{i=1,2,\ldots}$ denote the eigenpairs of $\Sigma = \mathbb{E}_\mathbf{x} \left[\phi(\mathbf{x})\phi(\mathbf{x})^\top\right]$. For any feature $f\in\mathcal{F}$ of the $f = \Tilde{\mathbf{U}} \Tilde{\mathbf{U}} ^\top \phi$, where $\Tilde{\mathbf{U}} = [\mathbf{u}_1 \mathbf{u}_2 \ldots \mathbf{u}_K]$ is a matrix of any $K$ orthonormal eigenvectors of $\Sigma$, then information in feature $f$ with respect to $c$-th component is given by 
\[
\rho_{\mathcal{D},\bm{\beta},c}(f) =  \sum_{i=1}^K \lambda_i (\bm{\beta}_c^\top \mathbf{u}_i)^2 = \sum_{i=1}^K s_c(\mathbf{u}_i).
\]
\end{corollary}

Hence, the set of features selected in Algorithm \ref{alg:cap} by sorting the robustness score $s_c(\mathbf{u}_i)$ also correspond to the eigenvectors with most information.



 

\subsection{Connection to Neural Tangent Kernel features}
\label{sec:ntk}
Recently, \citet{tsilivis2022can} defined features using NTK gram matrix and empirically observed that the features corresponding to the top spectrum of NTK are more robust and learned first during training.
In the following, we define the NTK and NTK features and show its equivalence to our robust feature definition along with the proof that the robust NTK features correspond to the top of the spectrum.
The NTK gram matrix $\mathbf{\Theta} \in \mathbb{R}^{n\times n}$ is between all pairs of datapoints and the NTK between $\mathbf{x_i}$ and $\mathbf{x_j}$ for a network that outputs $f(\mathbf{w},\mathbf{x})$ at data point $\mathbf{x} \in \mathbb{R}^d$ parameterized by $\mathbf{w} \in \mathbb{R}^p$ is defined by the gradient of the network with respect to $\mathbf{w}$ as
\begin{equation}
     \mathbf{\Theta}(\mathbf{x_i},\mathbf{x_j}) = \mathbb{E}_{\mathbf{w}\sim \mathcal{N}(0,\mathbf{I}_p)}[\nabla_\mathbf{w} f(\mathbf{w},\mathbf{x_i})^T\nabla_\mathbf{w} f(\mathbf{w},\mathbf{x_j})].
\end{equation}
For an extremely large width network, gradient descent optimization with least square loss is equivalent to kernel regression, the kernel being the NTK. Formally, for a data $\mathbf{x}$, the converged network output in the large width limit is $f(\mathbf{w},\mathbf{x})=\mathbf{\Theta}(\mathbf{x},\mathbf{X})^{T}\mathbf{\Theta}(\mathbf{X},\mathbf{X})^{-1}\mathbf{Y} $.
\citet{tsilivis2022can} define NTK features using the eigendecomposition of $\mathbf{\Theta}(\mathbf{X},\mathbf{X}) = \sum_{i=1}^{n}\lambda_i \mathbf{v_i}\mathbf{v_i}^{T}$ as
\begin{equation}
    f(\mathbf{w},\mathbf{x}) = \mathbf{\Theta}(\mathbf{x},\mathbf{X})^{T}\mathbf{\Theta}(\mathbf{X},\mathbf{X})^{-1}\mathbf{Y} = \sum_{i=1}^{n}\lambda_i^{-1}\mathbf{\Theta}(\mathbf{x},\mathbf{X})^{T} \mathbf{v_i}\mathbf{v_i}^{T}\mathbf{Y} := \sum_{i=1}^{n}f^{ker}_{i}(\mathbf{x}) 
\label{eq:ntk_features}
\end{equation}
where $f^{ker}_{i}(\mathbf{x}) \in \mathbb{R}^C$ is the $i$-th NTK feature of $\mathbf{x}$. Note that $f^{ker}_{i}$ is in accordance to our feature definition.
We prove the empirical observation that the top spectrum-induced NTK features $f^{ker}$ are more robust in the following proposition. 
\begin{prop}[Robustness lies at the top.]
\label{prop:robust_top}
    Let feature $f^{ker}_{i}$ be Lipschitz continuous in gradient of NTK with respect to $\mathbf{x}$ and an adversarial perturbation $\bm{\delta}$ for input $\mathbf{x}$ such that $||\bm{\delta}||_p \leq \Delta$. Then,
    %of max $\Delta$ radius around input $\mathbf{x}$ i.e. $\delta\in \mathcal{B}(\Delta)(\mathbf{x})$ under $\ell_p$-norm. We can say that
    $||f^{ker}_{i}(\mathbf{x}+\bm\delta)- f^{ker}_{i}(\mathbf{x})||_2\leq\Theta(\frac{1}{\lambda_i})$.
\end{prop}
Proposition~\ref{prop:robust_top} shows that the NTK features corresponding to the higher eigenvalues are more robust to adversarial perturbations, and hence robustness lies at the top. 
This complements and strengthens the empirical observation in \citet{tsilivis2022can}. The proof is provided in appendix.
