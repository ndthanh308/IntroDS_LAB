
%\documentclass[conference, a4paper]{IEEEtran}

\documentclass[journal,twoside]{IEEEtran}

\usepackage{enumerate}
\usepackage{mathtools}
\usepackage{microtype}
%\usepackage{longtable}

\usepackage{pdflscape}

\usepackage{tabularx}
\usepackage{multirow}
\usepackage{textcomp}
\usepackage{csquotes}
\usepackage{booktabs}

\usepackage{xr-hyper}
\usepackage{hyperref}
\usepackage{amsmath}
\usepackage{amssymb}
%\usepackage{epsfig}
\usepackage{lscape}
\usepackage{lineno}
\usepackage{array}
\usepackage{float}
\usepackage{todonotes}
\usepackage{tabu}
\usepackage{siunitx}
\usepackage{longtable}
\usepackage{pdflscape}
\usepackage{setspace}
\usepackage{textcomp}
\usepackage{rotating}
\usepackage{xcolor}
\usepackage{acronym}
\usepackage{multicol}
\usepackage{xtab}
\usepackage{multirow}
\usepackage{lipsum} % For generating dummy text

% \setlist{topsep=0pt, itemsep=-2pt}
%\usepackage{cite}
\usepackage{natbib}
\bibliographystyle{agsm}
%\setcitestyle{authoryear,open={((},close={))}} %Citation-related commands

\usepackage{amssymb}% http://ctan.org/pkg/amssymb
\usepackage{pifont}% http://ctan.org/pkg/pifont
\newcommand{\cmark}{\ding{51}}%
\newcommand{\xmark}{\text{\ding{55}}}

\DeclareUnicodeCharacter{2212}{-}


\usepackage{comment}
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
    
    
% *** GRAPHICS RELATED PACKAGES ***
%
\ifCLASSINFOpdf
  % \usepackage[pdftex]{graphicx}
  % declare the path(s) where your graphic files are
  % \graphicspath{{../pdf/}{../jpeg/}}
  % and their extensions so you won't have to specify these with
  % every instance of \includegraphics
  % \DeclareGraphicsExtensions{.pdf,.jpeg,.png}
\else
 
\fi


% correct bad hyphenation here
\hyphenation{op-tical net-works semi-conduc-tor}

\usepackage[a4paper, total={170mm,257mm}]{geometry}


\begin{document}

%
% paper title
% can use linebreaks \\ within to get better formatting as desired
%\title{Perspectives in hybrid edge-cloud computing: a case study on energy efficiency in buildings}
%\title{A hybrid tow-stage edge-based anomaly detection of building energy consumption}

%\title{Anomaly-Net: Deep Anomaly Detection of Building Energy Consumption Using Time-Series Imaging}

\title{Decoding ChatGPT: A Taxonomy of Existing Research, Current Challenges, and Possible Future Directions}

% author names and affiliations
% use a multiple column layout for up to three different
% affiliations


\author{\IEEEauthorblockN{Shahab Saquib Sohail\IEEEauthorrefmark{1},
Faiza Farhat\IEEEauthorrefmark{2}, 
Yassine Himeur\IEEEauthorrefmark{3}, 
Mohammad Nadeem\IEEEauthorrefmark{4},
Dag Øivind Madsen\IEEEauthorrefmark{5},
Yashbir Singh\IEEEauthorrefmark{6},
Shadi Atalla\IEEEauthorrefmark{3} and
Wathiq Mansoor\IEEEauthorrefmark{3}
}\\
\IEEEauthorblockA{\IEEEauthorrefmark{1}
Department of Computer Science and Engineering, School of Engineering Sciences and Technology, Jamia Hamdard, New Delhi 110062, India}\\
\IEEEauthorblockA{\IEEEauthorrefmark{2}Department of Zoology, Aligarh Muslim University Aligarh UP India}\\
\IEEEauthorblockA{\IEEEauthorrefmark{3}College of Engineering and Information Technology, University of Dubai, Dubai, UAE}\\
\IEEEauthorblockA{\IEEEauthorrefmark{4}Department of Computer Science, Aligarh Muslim University Aligarh UP India}\\
\IEEEauthorblockA{\IEEEauthorrefmark{5}University of South-Eastern Norway, Norway}\\
\IEEEauthorblockA{\IEEEauthorrefmark{6}Department of Radiology, Mayo Clinic, Rochester, MN, USA}\\
}



% use for special paper notices
%\IEEEspecialpapernotice{(Invited Paper)}




% make the title area
\maketitle


\begin{abstract}
Chat Generative Pre-trained Transformer (ChatGPT) has gained significant interest and attention since its launch in November 2022. It has shown impressive performance in various domains, including passing exams and creative writing. However, challenges and concerns related to biases and trust persist. In this work, we present a comprehensive review of over 100 Scopus-indexed publications on ChatGPT, aiming to provide a taxonomy of ChatGPT research and explore its applications. We critically analyze the existing literature, identifying common approaches employed in the studies. Additionally, we investigate diverse application areas where ChatGPT has found utility, such as healthcare, marketing and financial services, software engineering, academic and scientific writing, research and education, environmental science, and natural language processing. Through examining these applications, we gain valuable insights into the potential of ChatGPT in addressing real-world challenges. We also discuss crucial issues related to ChatGPT, including biases and trustworthiness, emphasizing the need for further research and development in these areas. Furthermore, we identify potential future directions for ChatGPT research, proposing solutions to current challenges and speculating on expected advancements. By fully leveraging the capabilities of ChatGPT, we can unlock its potential across various domains, leading to advancements in conversational AI and transformative impacts in society.
\end{abstract}



\begin{IEEEkeywords}
ChatGPT, Large language models (LLMs), Generative Pre-trained Transformer (GPT), AI Generated Content (AIGC), Systematic review, Trustworthy AI
\end{IEEEkeywords}

\IEEEpeerreviewmaketitle
\section{Introduction} \label{sec1}

In recent years, there has been a significant advancement in natural language processing (NLP) and artificial intelligence (AI) technologies, leading to the development of sophisticated language models capable of generating human-like text. Among these models, Generative Pre-trained Transformers (GPT) have gained tremendous attention and recognition for their ability to generate coherent and contextually relevant responses. GPT models have been successfully applied to various NLP tasks, including language translation, text summarization, and question answering \cite{guo2023can}. One prominent variant of the GPT model is Chat Generative Pre-trained Transformer (ChatGPT), a chatbot specifically designed to engage in conversational interactions with users \cite{gpt4,sohail2023using}. ChatGPT leverages the power of GPT to provide interactive and dynamic responses, mimicking human-like conversation. This innovative technology has opened up new possibilities in customer service, virtual assistants, and other applications where natural language understanding and generation are crucial \cite{cascella2023evaluating,deng2022benefits}.



As a result, there has been a growing interest in ChatGPT that extends far beyond the computer science discipline, with researchers from various backgrounds exploring its potential usefulness \cite{javaid2023chatgpt}. It has quickly gained worldwide attention and there is a lively discussion about its advantages and potential harmful effects. In a short span of time, ChatGPT has established itself as an excellent tool for accomplishing a variety of tasks, such as generating text on a given topic, obtaining information on a topic of interest, composing emails or messages with specific content and tone, modifying the structure or wording of a text, etc. \cite{salvagno2023can}. Additionally, it can generate code in multiple programming languages. Researchers have even used ChatGPT for scientific writing since it makes several parts of the academic writing process faster and more manageable, including article summarization, drafting, language translation, etc. \cite{lee2023can}.


\subsection{Architecture of ChatGPT}
ChatGPT, developed by OpenAI \cite{chatGPT}, is a language model that enables the creation of conversational AI systems capable of understanding and providing meaningful responses to human language inputs. Functioning as an AI-enabled chatbot, it employs algorithms to process user inputs and generate appropriate replies \cite{cao2023comprehensive}. ChatGPT has the ability to generate new responses or utilize pre-existing ones \cite{salvagno2023can}. To enhance its comprehension of user queries and generate accurate responses, ChatGPT undergoes continuous refinement using reinforcement methods, machine learning, and natural language processing techniques \cite{ouyang2022training}. In its own words (generated on March 29, 2023):

\textit{“I am ChatGPT, a language model developed by OpenAI, designed to generate human-like responses to a wide variety of questions and prompts. My purpose is to assist and interact with users in a conversational manner, providing helpful and informative responses to their inquiries.”}

To continually improve the reliability and accuracy of the model, ChatGPT incorporates reinforcement learning from human feedback (RLHF), allowing it to learn and understand human preferences through extended dialogues \cite{christiano2017deep,stiennon2020learning}. Additionally, researchers are actively exploring new technologies to enhance further its performance \cite{cao2023comprehensive,gpt4}. ChatGPT utilizes a transformer architecture consisting of encoder-decoder layers that collaborate to process and generate natural language text \cite{chen2023contextualized}. The architecture of ChatGPT comprises several vital components, such as the tokenizer, which divides raw text into smaller units called tokens for easier processing. The input embedding component then converts these tokens into high-dimensional vector representations \cite{wang2019language}.

\par The transformer architecture of ChatGPT consists of two main components: the encoder and the decoder \cite{budzianowski2019hello}. The encoder processes the input text hierarchically, creating representations at different levels of abstraction. On the other hand, the decoder generates the output text one token at a time, utilizing the input representations generated by the encoder.
An essential feature of the transformer architecture is the attention mechanism, which allows the model to selectively focus on different parts of the input text while generating the output \cite{jainknowledge}. This mechanism enhances the model's ability to capture relevant information and produce coherent output.
The output softmax layer is responsible for converting the high-dimensional vector representation of the output text into a probability distribution over the vocabulary of possible output tokens. This enables ChatGPT to generate high-quality and coherent natural language text.
The architecture of ChatGPT empowers it to excel in various tasks, including chatbots, language translation, and text completion, by generating accurate and meaningful responses.


Despite its popularity and usefulness, ChatGPT has raised concerns among researchers and practitioners due to its potential to generate content that, although seemingly reasonable, lacks factual accuracy \cite{borji2023categorical}. This issue can result in the production of counterfactual or meaningless responses, posing a serious threat to the reliability of online content. Additionally, the false narratives generated by ChatGPT can be easily mistaken as legitimate, especially by individuals who are unfamiliar with the topic at hand \cite{chatGPTFake}.
Researchers have been exploring and highlighting the potential harms associated with ChatGPT, including the propagation of stereotypes, biased responses, and dissemination of misleading information \cite{liang2021towards,nadeem2020stereoset}. Ethical concerns have also been raised regarding the use of ChatGPT, particularly when it is employed to create manipulated content that promotes misinformation and incites violence, potentially causing harm at both individual and organizational levels. Moreover, there are concerns that ChatGPT-generated content may infringe upon copyright and intellectual property rights \cite{deng2022benefits}. Furthermore, ethical considerations regarding the use of this tool for academic and scientific writing cannot be disregarded \cite{lee2023can}.



\subsection{Progress of ChatGPT research}
The initial iteration of ChatGPT referred to as GPT-1, was equipped with 117 million parameters and underwent training on a substantial corpus of text data \cite{ernst2022ai}. Subsequent versions, such as GPT-2, GPT-3, and the latest release, GPT-3.5, have experienced notable advancements by significantly augmenting the number of parameters. This augmentation has facilitated the generation of responses that are even more accurate and human-like.
An important breakthrough in ChatGPT is its capacity for zero-shot learning, which empowers the model to generate coherent responses to prompts it has never encountered before \cite{zhang2021commentary}. This remarkable capability is achieved through the utilization of unsupervised learning techniques and a novel training objective known as language modeling.


Despite the limitations of ChatGPT, its application has extended to various fields, including healthcare \cite{Abdel-Messih2023, sallam2023utility}, cyber security \cite{Mijwil202365}, environmental studies \cite{Rillig20233464}, scientific writing \cite{salvagno2023can, lee2023can}, education \cite{Tlili2023}, and others \cite{Wang2023575, Dowling2023, Biswas2023}. It is anticipated that the usage of ChatGPT will continue to grow in the future, with potential developments aimed at enhancing its capabilities \cite{Aljanabi202362, gpt4}. These developments may include real-time training of ChatGPT to improve its performance and the expansion of its domain-specific knowledge to make it more tailored and personalized for specific areas such as customer service, healthcare, business, or finance. Additionally, efforts can be made to address the issue of misinformation by ensuring that ChatGPT provides impartial and fair responses, thereby enhancing its trustworthiness and aligning with the growing importance of AI ethics and fairness considerations.


\subsection{Research Questions and Prime Contributions}
Writing a review about ChatGPT and its future contributions to recommender systems is crucial for synthesizing knowledge, identifying benefits and limitations, guiding future research, informing practitioners, and addressing ethical considerations. It serves as a valuable resource for advancing the field and maximizing the potential of ChatGPT in enhancing personalized recommendations. In doing so, this review article attempts to answer the following research questions (RQs):
\begin{itemize}
\item RQ1. What is the current state of ChatGPT research, including its architecture, advancements, and prime contributions?
\item RQ2. How diverse is the landscape of publications related to ChatGPT, and what are the recent trends in this research domain?
\item RQ3. What are the various applications of ChatGPT across different domains, such as healthcare, marketing and financial services, software engineering, academic and scientific writing, research and education, environmental science, and natural language processing?
\item RQ4. How can multimodal data (e.g., text, audio, visual) be leveraged to enhance the capabilities and performance of ChatGPT, and what are the key technical challenges in doing so?
\item RQ5. What are the main challenges, ethical considerations, potential risks, and ongoing research efforts in deploying GPT models in chatbot systems, and how are these being addressed to ensure fairness, transparency, explainability, and human-centered design?
\end{itemize}


It can be observed that many research areas around ChatGPT need to be explored. The current literature survey provides a detailed overview of research related to ChatGPT. There are existing review works on Large Language Models (LLM) \cite{melis2017state,chen2021evaluating} and AI Generated Content (AIGC) \cite{cao2023comprehensive} but they are very broad and do not take into consideration the specificities related to ChatGPT. To that end, this review work, a first of its kind, comprehensively performs a critical study of ChatGPT by covering 8 different applications, current issues and future challenges. The current study begins by reviewing the existing literature on ChatGPT and develops a taxonomy of areas/domains in which researchers have utilized this tool.


Additionally, the literature survey outlines the areas for improvement and presents potential challenges. Finally, the future applications of the tool and answers to its limitations are also explored. In summary, this survey makes several contributions, including:
\begin{itemize}
    \item A comprehensive review on ChatGPT.
    \item Presents and analyses the related literature.
    \item Highlights the areas in which this tool is predominately used.
    \item Concerns around ChatGPT and possible answers.
    \item Future enhancements and applications.
\end{itemize}

Moving forward, the proposed study has been compared with other surveys conducted on ChatGPT to identify the unique aspects and advancements it brings to the field. The analysis has considered various factors such as the applications covered, ChatGPT background, bibliometric analysis, research questions ChatGPT fine-tuning, open challenges and future research directions.
Table \ref{tab-comp} summarizes the output of this comparison.



\begin{table*}
\caption{Comparison of the proposed study with other surveys conducted on ChatGPT. We use tick marks (\cmark) to indicate the addressed fields and cross marks (\xmark) to denote missed fields.}
\label{tab-comp}
\scriptsize
\begin{tabular}{llllllllll}
\hline
Survey & Application & ChatGPT & Bibliomet- & RQs & ChatGPT & 
\multicolumn{3}{c}{Open challenges} & Future \\ \cline{7-9}
&  & background & ric analysis &  & fine-tuning & Intrinsic & Usage- & 
Ethical & Direction \\ 
&  &  &  &  &  &  & related & Concern &  \\ \hline
{\tiny \cite{lund2023chatting}} & Academia & \xmark & \xmark & \xmark & \xmark & %
\xmark & \xmark & \xmark & \xmark \\ 
{\tiny\cite{dwivedi2023so}} & Multidisciplinary & \cmark & \xmark & \cmark & \xmark
& \xmark & \xmark & \xmark & \xmark \\ 
{\tiny\cite{ray2023chatgpt}} & Multidisciplinary & \cmark & \xmark & \xmark & \xmark
& \cmark & \cmark & \cmark & \xmark \\ 
{\tiny\cite{kohnke2023chatgpt}} & Language & \xmark & \xmark & \xmark & \xmark & %
\xmark & \xmark & \xmark & \xmark \\ 
& teaching &  &  &  &  &  &  &  &  \\ 
{\tiny\cite{sifat2023chatgpt}} & Multidisciplinary & \cmark & \xmark & \xmark & %
\xmark & \xmark & \xmark & \xmark & \xmark \\ 
{\tiny\cite{rahman2023chatgpt}} & Academia & \cmark & \xmark & \xmark & \xmark & %
\xmark & \xmark & \cmark & \xmark \\ 
{\tiny\cite{temsah2023overview}} & Healthcare & \cmark & \xmark & \xmark & \xmark & %
\xmark & \xmark & \xmark & \xmark \\ 
{\tiny\cite{li2023chatgpt}} & Education & \cmark & \xmark & \cmark & \xmark & \xmark
& \xmark & \cmark & \xmark \\ 
{\tiny\cite{eggmann2023implications}} & Healthcare & \xmark & \xmark & \xmark & %
\xmark & \xmark & \xmark & \xmark & \xmark \\ 
{\tiny\cite{hill2023chat}} & Scientific publishing & \xmark & \xmark & \xmark & %
\xmark & \xmark & \xmark & \xmark & \xmark \\ 
{\tiny\cite{lo2023impact}} & Education & \xmark & \xmark & \xmark & \xmark & \xmark
& \xmark & \xmark & \xmark \\ 
{\tiny\cite{sallam2023chatgpt}} & Healthcare education & \xmark & \xmark & \xmark & %
\xmark & \xmark & \xmark & \xmark & \xmark \\ 
{\tiny\cite{gunawan2023exploring}} & Healthcare & \xmark & \xmark & \xmark & \xmark
& \xmark & \xmark & \xmark & \xmark \\ 
Ours & Multidisciplinary & \cmark & \cmark & \cmark & \cmark & \cmark & %
\cmark & \cmark & \cmark \\ \hline
\end{tabular}

\end{table*}












\par The rest of the paper is organized as follows. Section 2 highlights the variety of research domains that have published works on ChatGPT. Publication trends and taxonomy of ChatGPT literature are presented in Section 3. Section 4 discusses the applications of ChatGPT. Limitations of the tool and future enhancements are outlined in Section 5 and Section 6, respectively. Finally, concluding remarks are presented in Section 7.




















\section{Survey Methodology} \label{sec2}
To conduct our literature review, we adopted the methodology proposed in \cite{kitchenham2004procedures}. It is crucial to recognize that identifying the need for a review is just as important as the review itself. The rapid dissemination of ChatGPT research resulted in a diverse research landscape due to its wide publicity and acceptance at different levels in our daily lives. Our study highlights the need for a comprehensive review that outlines the various aspects of its usage for different applications, its limitations and potential future directions.  \newline
After running search queries, inclusion (IC) and exclusion (EC) criteria were created to filter out the retrieved articles from the Scopus database. Material obtained may include multiple papers that match the search query but are irrelevant to our study. We have also performed a screening of the articles by going through the abstract and assessing its relevance to the title under consideration. The Inclusion and exclusion criteria comprise the following:
\newline
Inclusion criteria:
\begin{itemize}
    \item IC-1: English must be the medium of the paper.
    \item IC-2: The foundation of the paper must be a peer-reviewed publication, such as one from a workshop, journal, book, conference, etc.
    \item IC-3: Articles that contain keyword “chatgpt” or “chat-gpt” in their abstract or title.
    \item IC-4: Articles that discuss ChatGPT.
    \item IC-5: Articles that are published till March 25, 2023.
\end{itemize}

Exclusion criteria:
\begin{itemize}
    \item EC-1: Short papers.
    \item EC-2: Articles that did not contain keyword “chatgpt” or “chat-gpt” in their abstract or title.
    \item EC-3: Articles discussing only GPT or generative AI and not exclusively chat GPT.
    \item EC-4: Duplicate articles.
    \item EC-5: Earlier versions with errata.
\end{itemize}


After applying the specified criteria, a total of 109 articles were included in the analysis. These articles involved contributions from 349 authors representing 53 different nations, indicating a wide range of international participation in the literature on ChatGPT. The publications were further examined and categorized based on their respective subject areas. Notably, the field of medicine had the highest representation, accounting for 23\% of the total publications. This was followed by social sciences (20\%) and computer science (11\%) (see Figure \ref{fig:subject}). Multidisciplinary subjects and health professionals made up 8\% and 7\% of the total corpus, respectively.
\vskip2mm
Figure \ref{fig:countries} provides a visual representation of the collaborative network among countries contributing to the topic of ChatGPT. The size of each circle corresponds to the number of documents produced by that country, while the connecting lines represent collaboration links between countries. The thickness of the connecting lines corresponds to the frequency of collaboration between the respective countries. The United States ranked first as the country of origin for published articles, with a total of 33 publications in the corpus. It was followed by the United Kingdom with 10 publications, and Australia and China with 9 publications each. In terms of collaborations, the United States had the most extensive network, collaborating with 24 different countries, accounting for over 18\% of the total corpus. Switzerland ranked second in terms of collaboration, with 20 collaborative countries, followed by Australia with 19 collaborations, and the United Kingdom with 18 collaborations (see Figure \ref{fig:countries}).



% Figure environment removed




% Figure environment removed


\section{Diversity of publication on ChatGPT}

Following its launch, ChatGPT quickly gained a lot of popularity in a variety of disciplines \cite{Cox2023, dwivedi2023so,Tlili2023}, including academia \cite{Chen2023} and science \cite{Morreel2023}. It is being used for a wide range of applications from content creation, translation, writing essays, and computer coding to research assistance. Research scholars have been using ChatGPT in a variety of ways, including writing scientific literature, gathering data, drafting abstracts for research papers \cite{Else2023423}, and looking for medical diagnostic advice \cite{Hirosawa2023}. Even entire scientific articles have occasionally been generated using it, with authorship provided. However, there has been criticism and backlash from many people as a result of ChatGPT's instances of generating inaccurate information or being perceived as a threat to the integrity of plagiarism-free scientific texts.

As far as publication avenues (journals and conferences) are concerned, Nature Journal tops the list with 13 articles. Next, Accountability in Research has published 4 articles. Other journals with multiple publications include JMIR Medical Education (3), Journal of Educational Evaluation for Health Professions (3), and The Lancet Digital Health (3). Iraqi Journal for Computer Science and Mathematics has also published 2 documents as well. However, no articles have been published in top conferences on NLP, possibly because it usually takes more time for conference announcement and acceptance, and consequently gets published online.

\section{Recent trend of publications related to ChatGPT} \label{sec2}
A thorough literature review was conducted, and 109 articles were found after searching the Scopus database for relevant articles on ChatGPT. Following the classification of the retrieved articles using either their abstracts or full texts, it was discovered that there were mainly three categories of articles published up until March 25th, 2023: 1) evaluations of ChatGPT, 2) predictions made using ChatGPT, and 3) reviews on ChatGPT. The biggest cohort consisted of ChatGPT assessments across various domains. A total of 68 articles were published to evaluate ChatGPT's ability to gauge its proficiency in providing accurate answers or the depth of its knowledge. Making predictions using ChatGPT for different fields is the subject of the second-largest group of articles (39) and the fewest reviews (10 publications).

\textcolor{black}{Upon reviewing the entire body of literature related to ChatGPT, a prevalent pattern has emerged in the structure of most articles, as shown in Figure \ref{fig:commonTrend}. Typically, authors select a topic of interest, ask ChatGPT questions, and then provide interpretations based on its responses. These interpretations can be broadly categorized into two types: those that predict the future of the topic in the context of ChatGPT and those that assess ChatGPT's features and their potential impacts.}

Furthermore, it has been noted that the majority of publications center around either ChatGPT's feature assessment as a scientific writing assistant or predictions about the future of the education system. As a result, many authors have expressed concerns regarding the ethical and scientific implications of ChatGPT's features and their potential negative effects on scientific academia. Meanwhile, several articles have explored how ChatGPT could impact learners and educators, as well as the ethical considerations that must be taken into account when using it.


The different assessments included those for bias \cite{Wang202334,Wang2023575}, for study \cite{Cooper2023}, for mental health \cite{Prada2023532}, for public health \cite{Jungwirth2023}; \cite{Biswas2023}, etc. It is noted that the majority of authors have evaluated ChatGPT for its capacity for scientific writing (30 publications), whether in terms of producing data \cite{maddigan2023chat2vis}, writing a scientific article \cite{D'Amico2023663,Anderson2023, farhat2023trustworthy}, or fetching references for particular subjects \cite{gravel2023learning,alkaissi2023artificial, farhat2023trustworthy}. The potential of ChatGPT to make a contribution to the field of education from the perspectives of learners \cite{Gašević2023}, educators \cite{Lim2023}, and mentors \cite{Naumova2023,Johinke2023,Rospigliosi20231} was the second biggest issue. The third biggest group of researchers from various fields questioned ChatGPT to evaluate its research ability to contribute to the field of research. Additionally, some authors have evaluated it for subject expertise by posing it with various test questions, such as those from bar exams \cite{bommarito2022gpt}, medical exams \cite{Gilson2023}, etc. Some have also asked questions based on their extensive understanding of various fields, including parasitology \cite{Huh20231,Šlapeta2023}, clinical diagnosis \cite{Hirosawa2023}, environmental sciences \cite{Rillig20233464}, public health \cite{Biswas2023}, etc. A few authors also questioned ChatGPT’s efficiency in cyber security \cite{Mijwil202365} and its potential for biases due to algorithms \cite{Wang202334}, region \cite{Wang2023575}, and language \cite{Seghier2023216}. Some authors have also used ChatGPT for writing research papers and credited it as an author \cite{Mijwil202365,Aljanabi202362}, while others have questioned the validity of such authorship \cite{Stokel-Walker2022,Siegerink2023} (Figure \ref{fig:TaxonomyChatGPT}).

The second most popular research publication subject was prediction through ChatGPT. Numerous researchers have forecasted how ChatGPT will affect various areas, including the educational system \cite{Choi2023,Lim2023} (12 publications). In terms of predictions, disease diagnosis \cite{Khan2023605,Mann2023221}; \cite{DiGiorgio2023} came in second. Clinicians and medical professionals probed ChatGPT with hypothetical or real-world patient symptoms to determine whether or not it would aid in the diagnosis or treating patients. It was also very common among researchers to predict research trends in specific research fields using ChatGPT \cite{Tong2023220}, which would be helpful for aspiring researchers to pursue their research. Concern has also been expressed by a group of scholars who anticipate how ChatGPT could impact writing in both academic \cite{Perkins2023} and scientific fields \cite{Ali2023,Tregoning2023}. After conducting an extensive literature survey, it was discovered that only one out of the ten reviewed articles published so far discusses AI-Driven Conversational Chatbots, including ChatGPT, from 1999-2022 \cite{Lin2023}. However, it should be noted that this article does not solely focus on ChatGPT. Therefore, it can be inferred that a systematic literature review that is exclusively dedicated to ChatGPT has not yet been published. It is worth mentioning that the remaining nine reviewed articles focused on the efficiency of ChatGPT. This was either accomplished through direct assessment or prediction using ChatGPT \cite{Budler2023,Thurzo2023,Haman2023}.

\textcolor{black}{It is also important to note that Prompt Engineering is turning out to be an emerging dimension related to ChatGPT \cite{white2023prompta}. Researchers explored various techniques for designing effective prompts to elicit desired responses from the tool. This involved providing explicit instructions or giving example outputs to guide the tool's behavior \cite{,white2023chatgptb}. Another important trend was the development of diversity-promoting approaches. To address issues related to generating repetitive or generic responses, researchers experimented with techniques to encourage the generation of diverse and creative outputs \cite{cao2023comprehensive}. Ethical considerations are discussed in the majority of the papers either in detail or briefly. As AI systems interact with users, concerns about bias, fairness, and ethical issues have become prominent. Studies focused on developing methodologies to mitigate bias in language models and ensure they adhere to ethical guidelines, such as promoting fairness and avoiding harmful or offensive responses \cite{ray2023chatgpt}. It is obvious that the ethical dimension of ChatGPT will remain a hot topic in the future.}

% Figure environment removed


% Figure environment removed



\section{Applications of ChatGPT}
This section provides an overview of the primary applications of ChatGPT and generative chatbots in general. Furthermore, Table \ref{tab2} offers a summary of the existing research on ChatGPT, outlining the area of study, applications, objectives, and key findings of each study. \textcolor{black}{One of the common applications of ChatGPT is as a personal assistant \cite{bakker2022fine}. In different domains, the tool is customized to serve the needs of specific domains. For example, in the domain of healthcare, ChatGPT is used as a virtual medical assistant to provide patients with information about symptoms, medications, and general healthcare advice. They can help triage patients by asking relevant questions and suggesting appropriate next steps \cite{Perkins2023,wang2023chatgpt}. In marketing, ChatGPT works as a conversational chatbot to handle customer inquiries, provide product recommendations, and assist with order tracking. This helps streamline customer support processes, reduces wait times, and improves customer satisfaction \cite{cascella2023evaluating}. ChatGPT is turning out to be a Code Assistant and Debugger. It helps software developers by providing code suggestions, debugging assistance, and answering programming-related questions \cite{aljanabi2023chatgpt}. This improves development productivity and facilitates knowledge sharing among developers.}

\subsection{Healthcare}
Although ChatGPT has access to limited medical data, it has demonstrated performance in medical licensing exams equivalent to that of an undergraduate third-year medical student. As a result, there have been urgent discussions within the medical field about the impact of ChatGPT. Stokel-Walker and van Noorden describe in their article the implications of generative AI for science and how ChatGPT can answer some open-ended medical queries nearly as well as an average human physician \cite{sohail2023chatgpt} but with some shortcomings and unreliabilities \cite{stokel2023chatgpt}.
Clinicians often rely on complex information to make decisions, but in telemedicine, the available information is typically limited to language only, making it a potential candidate for interventions using LLM \cite{roosan2016big}. However, ChatGPT, a popular LLM, has limitations as it cannot ask questions to clarify questions or scenarios. This becomes particularly challenging in infection consultation, which requires the integration of clinical information with knowledge related to antimicrobial resistance and microbial ecology. To explore this further, the researchers asked ChatGPT for antimicrobial advice in eight hypothetical infections scenario-based questions and evaluated the appropriateness, consistency, safety, and antimicrobial stewardship implications of its responses. Based on this evaluation, they constructed an LLM medical safety assessment framework to assess the safety of LLM responses \cite{bashshur2020telemedicine,howard2023chatgpt}

With a few notable exceptions, ChatGPT demonstrated appropriate recognition of natural language \cite{howard2023chatgpt}. The model's understanding of scenarios was evident from the accurate summaries provided at the beginning of its responses. However, important situational aspects were not always well distinguished from unimportant ones. ChatGPT was able to recognize clinically important factors when they were explicitly provided, but as the complexity of the scenarios increased, it missed relevant issues \cite{howard2023chatgpt}.
ChatGPT's responses were coherent, and their spelling and grammar were appropriate. The model's answers included a summary of its understanding of the scenario and question, management options, and disclaimers that reflected its information sources, which were similar to the format of patient information websites. ChatGPT often repeated questions verbatim, including any errors, although it occasionally noticed and corrected them. The information provided by ChatGPT was consistent, and it did not repeat the same advice in a single response. However, the advice provided sometimes changed when questioned repeatedly.


The study in \cite{howard2023chatgpt} evaluated ChatGPT's ability to provide antimicrobial advice and found that while its antimicrobial spectra and regimens were appropriate, duration appropriateness varied and source control was often disregarded. ChatGPT also had deficits in situational awareness, inference, and consistency and sometimes gave dangerous advice despite prompting. However, the study proposes a modifiable qualitative framework to address these issues and urges clinicians to familiarize themselves with this new technology. The author declares several competing interests, while all other authors have none.


\subsection{Marketing and financial services}
The use of AI in banking has become increasingly important in recent years, with ChatGPT offering opportunities for back-end operations, data analysis, and personalized customer offers. AI can be used to understand consumer needs and create effective marketing strategies, but there are limitations to relying solely on ChatGPT due to high regulations in the financial services sector. Human involvement is necessary to verify the trustworthiness of insights and offers, and banks must invest in infrastructure and human resources to integrate AI into their digital transformation strategies.


Many studies, such as \cite{dwivedi2023so,geerling2023chatgpt,street2023let,rathore2023future}, have already investigated the potential of using ChatGPT in banking operations, both for back-end data analysis and marketing communication strategies, as well as for front-end operations to engage with customers directly. While there have benefits to using ChatGPT, there are concerns about trust and its impact on customer well-being. Banks will need to invest in training staff, educating customers about the technology, and knowing when and how far to push it. Trust in service provision will be crucial, and there are implications for convenience, promptness, and accurate decisions.


\clearpage






\onecolumn % Switch to one-column mode

\begin{longtable}{
    m{2cm}
    m{2cm}
    m{3.5cm}
    m{4cm}
    m{3cm}
}
\caption{Summary of the reported work on ChatGPT describing area of the study, applications, objectives and key findings of the research.}
\label{tab2}\\
\hline
Area of study & Application & Objectives & Key findings & References \\
\endfirsthead
\hline
\multicolumn{5}{c}{{Table \thetable\ (Continue)}} \\
\hline
Area of study & Application & Objectives & Key findings & References \\
\endhead
\hline
\endfoot

% Add your longtable content here
\multirow{7}{*}{Medicine} & Scientific writing & Evaluate the potential for medical study fabrication using AI-generated ChatGPT & The Combination of ease of creating fabricated work, the challenging detection of fraudulent publications, and absence of AI-based detection technologies creates an environment that facilitates fraudulent research. Researchers and practitioners can effectively utilize ChatGPT technology while avoiding any unintended consequences by developing a comprehensive understanding of its capabilities and limitations. & \cite{kitamura2023chatgpt,Elali2023,Liebrenz2023e105,biswas2023chatgpt,Arif2023,marchandot2023chatgpt,arif2023future,ufuk2023role,Cascella2023,lubowitz2023chatgpt} \\
\cline{2-5}
& Mental health care & Investigate the opportunities and challenges of ChatGPT in mental health care. Evaluate emotion-enhanced prompting and ChatGPT for mental health analysis. Evaluate ChatGPT for NLP-based mental health applications. & ChatGPT can offer emotional support and engagement to individuals with mental health concerns. ChatGPT can help assess the risk level of individuals experiencing mental health crises by analyzing conversations. ChatGPT can offer emotional support and engagement to individuals with mental health concerns. & \cite{singh2023artificial,yang2023evaluations,lamichhane2023evaluation,bhattacharyya2023chatgpt,van2023artificial,aminah2023considering,qiu2023smile,okan2023ai,uludag2023testing} \\
\cline{2-5}
& Education \& Examination & Evaluate the performance of ChatGPT in Medical Physiology Examination Phase I MBBS & Prior to implementation, the accuracy, source, and reliability of the information should be validated by expert faculty and clinicians in order to rely on ChatGPT for education or medical practices & \cite{subramani2023evaluating,sedaghat2023early,hisan2023chatgpt,sallam2023chatgpt,hisan2023chatgpt,fatani2023chatgpt,lee2023rise,alser2023concerns,talan2023role,sallam2023utility,Khan2023605,kung2023performance,gilson2023does} \\
\cline{2-5}
& Cardiology and Vascular Pathologies & Evaluate the precision of ChatGPT to the Basic Life Support (BLS) and Advanced Cardiovascular Life Support (ACLS) examinations. Explore ChatGPT for information of cardiopulmonary resuscitation. & ChatGPT did not reach the passing threshold for any of the exams. ChatGPT can assist researchers in analyzing large datasets related to cardiovascular diseases. ChatGPT can serve as a tool for healthcare providers by offering decision support in managing cardiovascular diseases. ChatGPT can help analyze patient data, such as medical records, family history, lifestyle factors, and biomarkers, to assess an individual's risk for cardiovascular diseases. & \cite{Fijačko2023,moons2023chatgpt,harskamp2023performance,skalidis2023chatgpt,nakaya2023chatgpt,harskamp2023performance,haver2023appropriateness,van2023response,fijavcko2023can,biswas2023reducing,ahn2023exploring,williams2023will} \\
\cline{2-5}
& Medical Licensing Examination & Assess the performance of ChatGPT in Medical Licensing Exams across multiple countries. & ChatGPT achieves greater than 60\%, passing score. ChatGPT demonstrates its versatility as a medical assistant by effectively analyzing real-world medical issues in a manner that is accessible, user-friendly, and adaptable. ChatGPT shows potential to support clinical decision-making in Japanese healthcare settings, but caution is needed due to performance improvements required. ChatGPT's knowledge and interpretation in the Chinese Chinese National Medical Licensing Examination (NMLE) are below medical students' level, but deep learning may enhance its abilities. & \cite{Perkins2023,wang2023chatgpt,kasai2023evaluating,gilson2022well,kaneda2023can,wu2023qualifying,bhayana2023performance} \\
\cline{2-5}
& Clinical Diagnosis & Assess the reliability of ChatGPT generated clinical scenario differential-diagnosis lists & The total rate of the correct diagnoses within ten differential-diagnosis lists generated by ChatGPT was more than 90\%. & \cite{Hirosawa2023} \\
\cline{2-5}
& Gastroenterology research & Assess the potential of ChatGPT for GI research & ChatGPT has the potential to contribute to the advancement of gastroenterology by generating high-quality research questions & \cite{Lahat20234164} \\
\hline
& Nursing & Investigate the potential application of ChatGPT in the field of nursing and caregiving services. & ChatGPT can provide valuable insights into the future of nursing. & \cite{gunawan2023exploring,alkhaqani2023chatgpt,odom2023role,moons2023chatgpt} \\
\hline
Business & Multidisciplinary & Evaluate ChatGPT in the context of education, business, and society & Enacting new laws to regulate these tools is crucial & \cite{dwivedi2023so,george2023review,chuma2023business,beerbaum2023generative} \\
\hline
Business \& Management & Management \& Education & Examine the use of ChatGPT in management education & In the future of education, generative AI should be welcomed rather than avoided & \cite{Lim2023} \\
\hline
Business and Economics & Scientific Research & To assess the use of ChatGPT for the research & ChatGPT can produce plausible-appearing research papers for reputable journals & \cite{Dowling2023,kshetri2023chatgpt,mcgee2023top,mcgee2023capitalism,george2023review} \\
\hline
\multirow{2}{*}{Life Science} & Parasitology test & Evaluate ChatGPT's understanding and comprehension skills of Korean medical students for parasitology test & The knowledge and ability to analyze results of parasitology test by ChatGPT were not yet on par with those of Korean medical students & \cite{Huh20235,huh2023chatgpt,vslapeta2023chatgpt} \\
\cline{2-5}
& Synthetic Biology & Check accuracy of the ChatGPT generated information before spreading. Investigate how cutting-edge AI can help practitioners of synthetic biology & ChatGPT has demonstrated its potential in various aspects of medicine, including supporting translational medicine, drug development, medical reporting, diagnostics, and treatment plans. Ethically adhering to the use of ChatGPT and other large language models (LLMs), computational biologists can enhance their efficiency, leading to accelerated scientific discovery in the field of life sciences. & \cite{Tong2023220,agathokleous2023use,lubiana2023ten,cahan2023conversation} \\
\hline
Chemistry & Global epidemiology & Interpret epidemiological relation between particulate matter and mortality risks & Prolonged questioning could be beneficial in enhancing and improving both the kinds of human reasoning and argumentation imitated by current LLMs. & \cite{Cox202399} \\
\hline
\multirow{3}{*}{Education} & Teaching \& Learning & Examine the use of ChatGPT in education. Understand the potential benefits of ChatGPT in promoting teaching and learning. & More guidelines on how to use ChatGPT safely in education should be created, and it should be used with more caution. & \cite{Tlili2023,alafnan2023chatgpt,lo2023impact,tlili2023if,mhlanga2023open,qadir2023engineering,firat2023chat,kasneci2023chatgpt,tlili2023if,qadir2023engineering} \\
\cline{2-5}
& Education system and library science & Assess ChatGPT potential impact on academia and libraries & Use ChatGPT responsibly and ethically to create new knowledge and educate future professionals & \cite{Lund2023} \\
\hline
\multirow{3}{*}{Language} & Learning Foreign Languages & Explore the development of chatbot systems and the principal approaches and data sets employed in their creation. & NLP technologies are being used to create conversational chatbots to mimic the conversational proficiency of humans. & \cite{Lin2023,hong2023impact,kohnke2023chatgpt,kasneci2023chatgpt,ali2023impact,lai2023chatgpt} \\
\cline{2-5}
& Vocabulary Expansion & Investigate the use of ChatGPT in (i) word meaning clarification, (ii) synonyms and antonyms, (iii) contextual usage, (iv) collocations and word associations, (v) idioms and figurative language, (vi) specialized vocabulary, and (vii) Word usage tips. & ChatGPT can assist learners in expanding their vocabulary. Learners can inquire about word meanings, synonyms, antonyms, and usage examples, allowing them to acquire new words and enhance their lexical knowledge. & \cite{huang2023role} \\
\cline{2-5}
& Linguistic Ambiguity Analysis & Study the ChatGPT strengths and weaknesses for linguistic ambiguity analysis & ChatGPT helps identify instances of linguistic ambiguity in text or speech. It can recognize when a word, phrase, or sentence has multiple possible interpretations, leading to potential confusion or miscommunication. & \cite{huang2023chatgpt,ortega2023linguistic,huang2023chatgpt,gao2023human} \\
\hline
Academia & Academic Writing & Investigating the use of ChatGPT in (i) enhanced writing productivity, language refinement and fluency, (iii) Knowledge synthesis and content generation, and (iv) revision and editing support. & While ChatGPT provides improved and faster academic writing, it also introduces several challenges, such as (i) overreliance on AI suggestions, lack of context awareness, and ethical considerations. Further research is required to address limitations and challenges, studying their impact on students' writing skills, perceptions, and academic performance. Context-aware AI models aligned with academic conventions should be developed. & \cite{dergaa2023human,alkaissi2023artificial,cotton2023chatting,bom2023exploring,chen2023chatgpt,alafnan2023chatgpt,donmez2023conducting,tomlinson2023chatgpt,lund2023chatgpt,aczel2023transparency,frye2022should,chen2023chatgpt} \\
\hline
Robotics & Robotic Process Automation & Explore the potential of generative AI, especially ChatGPT in robotics. Investigate the ethics of using ChatGPT for robotic process automation. Investigate the prospective role of Chat GPT in the military. Study the use of ChatGPT-empowered long-step robot control in various environments. Explore the level of trust in human-robot collaboration utilizing ChatGPT. & ChatGPT or similar AI models can assist in task execution and control of robots. ChatGPT can aid in diagnosing issues and providing troubleshooting guidance for robotic systems. ChatGPT can help establish shared understandings, allocate tasks, and assist in real-time communication, thereby improving the overall efficiency and performance of robotic teams. ChatGPT can act as a user assistance tool, providing guidance, explanations, and educational resources to users interacting with robots. & \cite{vemprala2023chatgpt,wake2023chatgpt,biswas2023prospective,beerbaum2023generative,you2023robot} \\
\hline
Environment & Global Warming & Explore the impact of ChatGPT on global warming in terms of (i) environmental data analysis and interpretation, (ii) environmental education and awareness, (iii) environmental policy and planning, (iv) climate change modeling and projections, (v) natural resource management, and (vi) Environmental monitoring and early warning systems. & Emphasize the significant role that AI and natural language processing technologies, represented by ChatGPT, can play in advancing our understanding of climate change and improving the accuracy of climate projections. ChatGPT facilitates informed decision-making, enhances environmental awareness, and aids in the development of sustainable practices for a more resilient and ecologically balanced future. & \cite{biswas2023potential} \\
\hline
Smart Vehicles & & Explore the potential impact of ChatGPT for intelligent vehicle research. Explore the conversation with ChatGPT on interactive engines for intelligent driving. & Use ChatGPT's information can be updated and corrected, but it may not always reflect the latest knowledge. & \cite{Gao20231,du2023chat,zhang2023hivegpt,chen2023feedback,lei2023chatgpt,zheng2023chatgpt,wang2023linguistic} \\
\hline
\end{longtable}










\clearpage
\newpage

\twocolumn % Switch to one-column mode
\subsection{Software Engineering}
Software engineering is a broad field consisting of sub-processes such as software development, designing, testing, coding, etc. ChatGPT has been shown to assist in all these sub-domains of software engineering \cite{sobania2023analysis,aljanabi2023chatgpt,surameery2023use, white2023prompta,white2023chatgptb}. ChatGPT has a significant benefit in coding, as it can process human inputs, allowing software developers to supply code snippets or commands in a conversational way rather than providing specific keywords or phrases. This feature can enhance the coding experience for less-skilled programmers, making it more user-friendly and intuitive \cite{aljanabi2023chatgpt}. Researchers have used ChatGPT for automated fixing of programming of software bugs \cite{sobania2023analysis,surameery2023use}. They evaluated the ChatGPT's bug-fixing ability on the standard QuixBugs benchmark set and compared its performance with existing methods. They concluded that ChatGPT's bug-fixing performance is comparable to standard deep learning techniques/tools such as CoCoNut and Codex and superior to standard approaches. Since it is a conversational tool, its bug-fixing ability was improved further by providing it hints.

\par Managing the architecture of software-intensive systems can be a difficult and intricate process that involves integrating various perspectives from designers, stakeholders, automation tools, and other factors to create a roadmap for guiding software development and assessment. \cite{ahmad2023towards} used ChatGPT for analyzing, synthesizing, and evaluating the architecture of a services-oriented software application. They concluded that in the presence of human observation, ChatGPT could be used in place of a full-time human architect to carry out the process of architecture-centric software engineering. Furthermore, \cite{white2023prompta,white2023chatgptb} proposed a prompt engineering framework using ChatGPT for automating the process of software development, including the creation of API specifications, decoupling from third-party libraries, requirement specification, testing, deployment, etc.

\subsection{Academic and scientific writing}

One application area of ChatGPT that has garnered the interest of many is language summarization and elaboration. ChatGPT has been widely used for essay writing, application drafting, email content generation, and research paper writing since its inception. To that end, \cite{Biswas2023} has exploited ChatGPT to write an article related to medical content and has argued that the future of medical writing will be dependent on AI-assisted tools. Similarly, \cite{koo2023importance} has emphasized the proper use of the tool for disciplined medical writing and discussed the underlying concerns for this. Furthermore, \cite{kitamura2023chatgpt} has indicated that AI-assisted tools are very helpful and can be instrumental for future medical content writing. That said, human judgment is imperative to corroborate ChatGPT's output. In a similar vein,  \cite{kumar2023analysis} has asserted that ChatGPT has great potential in research writing if mentored by humans.

In addition to this, \cite{bishop2023computer} has shown with a series of conversations with ChatGPT that the AI bot can write in human style and may copy authors' styles of writing too. The authors \cite{salvagno2023can} have arguably inferred the need for consensus on how to regulate the use of AI-assisted tools in academic writing as the use of chatbots in scientific writing presents ethical issues related to the risk of plagiarism, inaccuracies, and unequal accessibility. An experiment by \cite{Gao20231} used 50 abstracts from scientific journals and asked ChatGPT to generate abstracts based on the titles. The generated abstracts were then reviewed by plagiarism detectors and blinded human reviewers. 68\% of the generated abstracts were correctly identified as such, and 14\% of the real abstracts were mistakenly identified as generated by ChatGPT. Interestingly, human reviewers found it difficult to differentiate between the abstracts written by the chatbot and those written by humans \cite{alkaissi2023artificial}.

\subsection{Research and Education}

For many application areas where chatGPT is being investigated, research and educations are the most prominent.   
\cite{rahman2023chatgpt} has experimentally shown that ChatGPT can be used to solve both technical problems, such as engineering and computer programming, and non-technical problems, such as language and literature. However, they warned to be aware of its limitations such as bias and discrimination, privacy and security, misuse of technology, accountability, transparency, and social impact. In a similar work, \cite{Tlili2023}, the study on ChatGPT was conducted in three stages. The first stage showed that social media discourse is generally positive and enthusiastic about using ChatGPT in education. The second stage analyzed ChatGPT's impact on educational transformation, response quality, usefulness, personality and emotion, and ethics. In the third stage, user experiences in ten educational scenarios revealed issues such as cheating, honesty, privacy, and manipulation. The study's findings highlight the need for the responsible and safe adoption of chatbots, specifically ChatGPT, in education. Furthermore, The article by \cite{hong2023impact} argues that ChatGPT presents significant opportunities for teachers and education institutes to enhance language teaching and assessments, leading to more personalized learning experiences. On top of this, authors have identified that the technology also offers a potential mechanism for researchers to explore new areas in research and education.


The authors in \cite{megahed2023generative} have concluded from their study that ChatGPT performs well in structured tasks such as translating code and explaining well-known concepts but struggles with nuanced tasks such as explaining less familiar terms and creating code from scratch. They suggested that while the use of AI tools may increase efficiency and productivity, current results may be misleading and incorrect. In contrast, \cite{halaweh2023chatgpt} has suggested that integration of ChatGPT could be beneficial and has given the outline to use it more efficiently.

To that end, the researchers exploring ChatGPT for research and education-related applications recommend using AI-assisted tools with censored and careful usage. Therefore, generative AI models must be properly validated and used in combination with other methods in software process improvement to ensure accurate results.

\subsection{Environmental Science}
There are a few studies so far on the potential use of ChatGPT in environmental sciences. \cite{Rillig20233464} outlined the potential benefits and risks of this LLM tool. They argued that ChatGPT can help in streamlining the workflow of environmental research where environmentalists can focus more on designing experiments and developing new ideas rather than the quality of their writing. It will also allow non-English speaking countries to have greater representation in the field of environmental science, accelerating the pace of research in relevant environmental issues. \cite{zhu2023chatgpt} also made similar observations but raised a few concerns also. Given the various decision-making processes involved in environmental research, it is essential to exercise caution while integrating AI-enabled tools such as ChatGPT into them. This is particularly important when addressing environmental issues that have a significant impact on the welfare of society.

\par \cite{biswas2023potential} mentioned the use of ChatGPT to address global warming. According to him, environment researchers can leverage the capabilities of ChatGPT to analyze and interpret vast amounts of climate change data and subsequently predict climate shift patterns based on the analysis. Furthermore, ChatGPT can be employed to present complex climate change information to a broader audience in an easily comprehensible format. It has the potential to offer policy-makers pertinent information and recommendations to mitigate climate variations. By inputting data, ChatGPT can also generate climate scenarios that can aid in making informed decisions. \cite{rathore2023future} proposed ChatGPT enabled sustainable and environment-friendly textile manufacturing process. She argued that ChatGpt could help in production process optimization. Additionally, it could be employed to provide automated customer cell that is both relevant and valuable. Another possibility is the development of fine-tuned recommendations according to the needs and preferences of buyers.

\subsection{Natural Language Processing}
ChatGPT has shown its potential as a valuable tool for various NLP-oriented tasks, including suicide tendency detection, hate speech detection, and fake news detection \cite{amin2023will, qin2023chatgpt, hendy2023good}. In particular, \cite{qin2023chatgpt} argued that larger models like ChatGPT can perform NLP tasks without the need for specific data adaptation. They conducted an evaluation of ChatGPT's zero-shot learning ability on 20 common NLP datasets, covering categories such as reasoning, natural language inference, question answering, dialogue, summarization, named entity recognition, and sentiment analysis. The evaluation results indicated that ChatGPT excelled in tasks that required reasoning skills, including arithmetic reasoning while facing challenges in tasks such as sequence tagging.

In their study, Hendy et al. \cite{hendy2023good} conducted a comprehensive evaluation of GPT models, including ChatGPT, for machine translation tasks. The evaluation covered 18 translation directions involving a diverse range of languages such as French, German, Icelandic, Chinese, Japanese, and others. The results demonstrated that GPT models could generate translation outputs that were highly competitive for languages with abundant resources. However, for low-resource languages, the current state of GPT models exhibited limitations, indicating the need for further improvements.
Similarly, Amin et al. \cite{amin2023will} conducted an analysis of various NLP tasks, including suicide tendency detection and personality prediction. They compared the performance of ChatGPT with both simple and sophisticated models like RoBERTa. The findings revealed that task-specific models like RoBERTa outperformed ChatGPT, particularly in specialized downstream tasks. However, ChatGPT still demonstrated satisfactory performance compared to baseline models in a variety of tasks.

Given the similarities among various NLP tasks, the findings from the aforementioned studies can be extrapolated to other related areas, including the assessment of news article accuracy, especially in the detection of fake news. Additionally, the application of ChatGPT is rapidly expanding across various domains \cite{Mijwil202365,aljanabi2023chatgpt}, indicating a growing trend that is expected to continue in the foreseeable future.

\section{Challenges and issues of ChatGPT}
Researchers have identified several issues regarding ChatGPT, which can be broadly categorized into two groups: intrinsic limitations and usage-related concerns. These categories, along with their respective limitations, are presented in Table \ref{tab:limitations} for better clarity and understanding. These limitations make the usage and deployment of ChatGPT difficult in real-world scenarios.

\subsection{Intrinsic}
 Intrinsic issues refer to the limitations inherent to ChatGPT and can be overcome primarily by the tool's developers through algorithm enhancements and/or upgraded training data. It includes five major limitations, namely, hallucination, biased content, not real-time, misinformation and inexplicability.  ChatGPT might hallucinate i.e., create new data/information which does not exist \cite{deng2022benefits}. Another similar concern is misinformation \cite{borji2023categorical}. Both issues can lead to the creation of counterfactual or meaningless responses, which can seriously threaten the reliability of the generated content. The false narratives generated by ChatGPT can be easily mistaken as legitimate, particularly by individuals unfamiliar with the subject matter \cite{chatGPTFake}. Algorithmic improvement, inputting the queries properly, and verifying generated responses might help overcome these problems. Reinforcement learning through human feedback will also help ChatGPT to improve the factuality of its responses \cite{stiennon2020learning}. 

\par There are also concerns regarding potential harms related to stereotypes and biased responses caused by ChatGPT \cite{liang2021towards,nadeem2020stereoset}. Besides algorithmic improvement and human feedback, refining the training data to remove or mark the biased content might help in this direction. There are many critical applications of ChatGPT where sound reasoning and explanation of logical deduction steps are required. It includes decision-making in various fault-intolerant domains such as financial services, environmental sciences, healthcare, etc. In such scenarios, ChatGPT must not only provide accurate information that can be used for decision-making, the steps involved in the logical reasoning deduction process also be mentioned \cite{ wei2022chain}.

%\begin{landscape}
\begin{table*}
\scriptsize
\centering
\caption{Major issues of ChatGPT and their potential solutions}
\begin{tabular}{|l|l|l|l|l|}
\hline
\textbf{Category}                                                         & \textbf{Issue}      & \textbf{Description}                                                                                                               & \textbf{Potential solution(s)}                                                                                                                                                                          & \textbf{References}                                                                                                                 \\ \hline
\multirow{5}{*}{Inherent}                                                 & Hallucination       & \begin{tabular}[c]{@{}l@{}}creating new data/information \\ which does not exist\end{tabular}                                      & \begin{tabular}[c]{@{}l@{}}Algorithmic   improvement; Users should \\ use appropriate prompts; Verifying the \\ generated content\end{tabular}                                                          & \begin{tabular}[c]{@{}l@{}}\cite{deng2022benefits}\\  \cite{cao2023comprehensive}\end{tabular}  \\ \cline{2-5} 
                                                                          & Biased   content    & \begin{tabular}[c]{@{}l@{}}producing negative comments/\\ generalizations related to race, \\ religion, gender, etc.\end{tabular}  & \begin{tabular}[c]{@{}l@{}}Algorithmic improvement; Refining the \\ training data, feedback by humans in case \\ of biased content\end{tabular}                                                         & \begin{tabular}[c]{@{}l@{}}\cite{liang2021towards}\\ \cite{nadeem2020stereoset}\end{tabular} \\ \cline{2-5} 
                                                                          & Not   real-time     & \begin{tabular}[c]{@{}l@{}}does   not has access to \\ real-time information as it \\ was fed information till 2021.\end{tabular}  & \begin{tabular}[c]{@{}l@{}}Providing direct access to real-time/online \\ data; Algorithm improvement and speed-up \\ are required\end{tabular}                                                         & \begin{tabular}[c]{@{}l@{}}\cite{chatGPT}\\ \cite{gpt4}\end{tabular}                            \\ \cline{2-5} 
                                                                          & Misinformation      & \begin{tabular}[c]{@{}l@{}}generating factually incorrect \\ information.\end{tabular}                                             & \begin{tabular}[c]{@{}l@{}}Designing factuality-based measures to \\ indicate the level of misinformation; \\ Mentioning the references; Tagging by \\ humans in case of false information\end{tabular} & \cite{borji2023categorical}                                                                                       \\ \cline{2-5} 
                                                                          & Inexplicability     & \begin{tabular}[c]{@{}l@{}}not explaining the steps of \\ information generation in \\ critical decision-making tasks\end{tabular} & \begin{tabular}[c]{@{}l@{}}Mentioning the steps involved in \\ logical reasoning deduction process\end{tabular}                                                                                         & \begin{tabular}[c]{@{}l@{}}\cite{cao2023comprehensive}\\ \cite{chatGPTFake}\end{tabular}        \\ \hline
\multirow{3}{*}{\begin{tabular}[c]{@{}l@{}}Usage \\ related\end{tabular}} & Ethical   issues    & \begin{tabular}[c]{@{}l@{}}not acknowledging ChatGPT \\ whenever content is generated\\ using it.\end{tabular}                     & \begin{tabular}[c]{@{}l@{}}mentioning ChatGPT as author/source \\ of information; Laws should be designed\\  to avoid unethical usage of ChatGPT\end{tabular}                                           & \begin{tabular}[c]{@{}l@{}}\cite{Elali2023}\\  \cite{cao2023comprehensive}\end{tabular}          \\ \cline{2-5} 
                                                                          & Copyright violation & \begin{tabular}[c]{@{}l@{}}generating full/partial content \\ identical to previous works \\ without prior consent\end{tabular}    & \begin{tabular}[c]{@{}l@{}}Verifying the generated content before\\  using/publishing;  Tagging by humans\\  in case of copyright violation\end{tabular}                                                & \cite{sallam2023utility}                                                                                          \\ \cline{2-5} 
                                                                          & Over-reliance       & \begin{tabular}[c]{@{}l@{}}may make humans lazy and \\ apathetic and always rely on\\  the generated information\end{tabular}      & \begin{tabular}[c]{@{}l@{}}Humans should verify the generated content \\ and use ChatGPT as a tool only to produce \\ better outcomes.\end{tabular}                                                     & \cite{sallam2023chatgpt}                                                                                          \\ \hline
\end{tabular}
\label{tab:limitations}
\end{table*}
%\end{landscape}

 \subsection{Usage-related}
 The category of usage-related issues includes unethical usage of the tool, copyright-infringed content, and over-reliance on ChatGPT. Ethical concerns arise, particularly when the tool is used to generate the content without acknowledgment. Unethical use also includes the deliberate generation of manipulated content that can promote misinformation and provoke violence, creating damage at an individual or organizational level \cite{Elali2023,cao2023comprehensive}. An ethical usage of the tool includes mentioning ChatGPT as the author/source of the generated information. In fact, few publishers have recognized the use of ChatGPT for academic writing to promote its ethical usage practices \cite{ chatGPTUse}. Also, laws and regulations should be designed to penalize the unethical usage of ChatGPT. Since there are many ethical considerations related to ChatGPT, we have discussed them separately in the next section. There are also concerns that ChatGPT-generated content may lead to violations of copyright and intellectual property rights \cite{ sallam2023utility}. Copyright infringement primarily includes generating full/partial information identical to already published works without the prior consent of the owner. Since ChatGPT is unaware of copyright materials, verifying the generated content before using/publishing and tagging by humans in case of copyright violation might help to resolve this issue. Lastly, there is a fear of over-reliance on the tool, which may make humans lazy and apathetic and make them always rely on the generated information \cite{sallam2023chatgpt}. Therefore, we should verify the generated content and use ChatGPT as a tool only to produce better outcomes.



\subsection{Ethical concerns}
ChatGPT has the capability to automatically generate responses by drawing information from numerous internet sources, often without requiring further input from the user. This has raised concerns regarding its potential misuse, as individuals have reportedly utilized the system to create university essays and scholarly articles, even including references if prompted \cite{ali2023readership}. One of the ethical issues associated with the usage of ChatGPT is the generation of fake text and narratives \cite{chatGPTFake,dugan2022real}. It is worth noting that the detection of artificially generated fake text and meaningless information is not a new challenge \cite{amancio2015comparing,jawahar2020automatic}. The identification of fake text generated by ChatGPT can be viewed as a two-step process. The first step involves determining whether a given text is created through ChatGPT. Once this is established, the second step requires identifying whether the text itself is fake or genuine. The latter process, which is fake text identification, falls within a well-established domain, with many state-of-the-art algorithms and techniques available to tag fake text with significant accuracy \cite{zhou2020survey}.
However, the former step, which focuses on specifically identifying texts generated by ChatGPT, is relatively new, and researchers are actively working to address this issue \cite{dugan2022real, mitchell2023detectgpt, Curtis2023275,mitrovic2023chatgpt}.

Curtis et al. \cite{Curtis2023275} have proposed various methods for identifying text generated by ChatGPT. These approaches encompass simple binary classifiers as well as advanced deep-learning models. Some techniques leverage statistical characteristics or syntactic patterns, while others incorporate semantic and contextual information to enhance accuracy. The primary objective of these studies was to provide a comprehensive and current evaluation of the most recent detection techniques specific to ChatGPT. Additionally, they assessed the performance of other AI-generated text detection tools that were not specifically designed for ChatGPT-generated content.
In a different study, \cite{mitrovic2023chatgpt} focused on brief online reviews and conducted two experiments to compare text generated by humans and ChatGPT. In the first experiment, they generated ChatGPT text using custom queries, while in the second experiment, they rephrased original human-generated reviews to obtain alternative text. They fine-tuned a model based on the Transformer architecture and employed it for making predictions. By comparing their model with an approach based on perplexity scores, they found that differentiating between human-generated and ChatGPT-generated reviews is more challenging for the machine-learning model when using rephrased text.

The authors in \cite{gao2023comparing} collected a total of 50 research abstracts by selecting ten abstracts from five prestigious medical journals with high impact factors. They used ChatGPT to generate research abstracts by providing titles and journal names as prompts. To evaluate the quality and authenticity of the abstracts, they employed an artificial intelligence (AI) output detector, a plagiarism detector and involved human reviewers who were unaware of the origin of the abstracts. These reviewers determined whether the abstracts were original or generated. Moving on, Mitchell et al. \cite{mitchell2023detectgpt} proposed a novel criterion called DetectGPT, which relied on curvature to determine if a passage was generated from a specific Language Model (LM) such as GPT. Unlike other methods, DetectGPT did not require training a separate classifier, creating a dataset of real or generated passages, or applying explicit watermarks to the generated text. Instead, it relied solely on log probabilities calculated by the target model and introduced random perturbations to the passage using a different generic pre-trained language model.


The increasing use of ChatGPT underscores the pressing need for rigorous AI author guidelines in academic publishing. There are ethical concerns related to copyright, attribution, plagiarism, and authorship when AI generates academic text. These concerns are particularly relevant because current technology does not allow human readers or anti-plagiarism software to distinguish between AI-generated and human-authored content \cite{rahimi2023chatgpt}. While some studies have credited ChatGPT as an author, there is an ongoing debate about whether generative AI meets the International Committee of Medical Journal Editors' authorship criteria. Can a chatbot truly provide approval for work and be held accountable for its content? The Committee on Publication Ethics and the International Association of Scientific, Technical, and Medical Publishers have developed AI recommendations for editorial decision-making and ethics, respectively \cite{zhuo2023exploring}. As AI technology becomes more tailored to user needs and more widely used, we believe it is crucial to have comprehensive discussions about authorship policies. Major publishers like Elsevier, who publish the Lancet family of journals, have already stated that AI cannot be listed as an author and that its use must be properly acknowledged \cite{sallam2023chatgpt}.


Our view is that ChatGPT's availability, ease of use, and multi-language capabilities could significantly boost scholarly output, thereby democratizing knowledge dissemination. However, the chatbot's potential to generate misleading or inaccurate content raises concerns about scholarly misinformation \cite{mhlanga2023open}. As demonstrated by the COVID-19 infodemic, the spread of misinformation in medical publishing can have serious societal consequences. OpenAI has acknowledged that ChatGPT may produce plausible-sounding yet incorrect or nonsensical answers \cite{lund2023chatgpt}.

\section{Future possibilities}
In this section, we explore some of the future possibilities related to ChatGPT. We envision that future iterations of ChatGPT might incorporate various additional variables, which can help develop a more sophisticated and enhanced AI language model.

\subsection{Improving Conversational Capabilities}
ChatGPT may become even better at comprehending and reacting to human speech, making it sound more conversational and natural. This might entail developments in disciplines like sentiment analysis, natural language processing, and contextual comprehension. The following are some basic strategies that could help AI become more conversational (Figure \ref{fig:ImprovedChatGPT}).

% Figure environment removed

\subsubsection{Increasing the volume and variety of training data}
AI language models learn from the provided data. By exposing them to a wider variety of linguistic patterns and linguistic contexts, expanding the size and diversity of the training data can therefore aid in the improvement of their conversational abilities.
Typically, increasing the volume and variety of training data can help improve ChatGPT's performance. ChatGPT is a machine learning model that uses a large amount of training data to learn patterns and make predictions based on them. By providing more data, the model can improve its understanding of language and the relationships between words and phrases \cite{cao2023comprehensive}.
More specifically, increasing the volume of training data can help the model learn more about different topics and contexts, which can make it more versatile and able to handle a wider range of queries. Additionally, providing more varied data can help the model learn to recognize and understand different types of language and speech patterns, improving its ability to handle diverse inputs and generate accurate responses.

However, it is also important to note that simply increasing the volume and variety of data alone may not always result in improved performance. The quality of the data is also crucial, and it is important to ensure that the data used for training is accurate, relevant, and diverse enough to represent the full range of language and speech patterns. Additionally, other factors such as the model architecture, training methods, and hyperparameters can also impact the model's performance.

\subsubsection{Fine-tuning}
The method of fine-tuning involves putting an existing AI language model through a series of tasks or domains. The model can be trained to produce more pertinent and useful answers by honing in on conversational tasks like customer service or personal assistants \cite{bakker2022fine,himeur2022next}.
In the case of ChatGPT, fine-tuning allows the model to learn and understand the nuances of natural language conversations, enabling it to generate more human-like responses. This process involves feeding the model with conversational datasets and optimizing it through backpropagation using the conversation pairs as input and output. As a result, the model becomes more accurate, efficient, and responsive to the specific task of generating conversational responses \cite{dwivedi2023so,hoppner2023chatgpt}.


\subsubsection{Incorporating human feedback}
Human input on the responses produced by AI language models can be gathered to assist the models' conversational skills. This can be achieved by either asking users to rate the quality of the answers or by having humans review, edit, and offer feedback on the responses produced by the model. Over time, it would help people grasp the conversation's context better and respond appropriately. The models can produce more pertinent and personalized responses if their ability to comprehend contexts, such as prior conversation history or the user's intent, is improved.
Incorporating human feedback is an effective way to improve the performance of ChatGPT. The first step is to collect feedback from users about the generated responses. One way to do this is to provide users with the option to rate the quality of the responses or provide suggestions for improvement.
Once the feedback is collected, it needs to be analyzed to identify the areas of improvement. This can be done using NLP techniques to extract relevant information and classify the feedback into different categories. The next step is to incorporate the feedback into the ChatGPT model. One way to do this is to use reinforcement learning, which involves modifying the model's weights to maximize a reward signal based on user feedback. Another way is to use the feedback to fine-tune the model and retrain it on the specific areas that require improvement. After incorporating the feedback, it's essential to evaluate the performance of the updated ChatGPT model. This can be done by measuring the quality of the responses generated by the model and comparing it to the previous version. Finally, the process of collecting feedback, analyzing it, and incorporating it into the model needs to be repeated iteratively to ensure continued improvement in the ChatGPT model's performance.














\subsubsection{Incorporating human emotions}
Humans frequently express their feelings through humor, empathy, and sarcasm. AI language models' conversational skills can be enhanced by adding feelings to make them more relatable and interesting. Although it is a complex and debated subject in the area of artificial intelligence \cite{Pahl2022FemaleW2}; \cite{Domnich2021ResponsibleAG}, incorporating human emotions into language models for AI is a challenge. Although feelings are a vital aspect of human communication, they can also be unpredictable and influenced by personal perspectives. As a result, adding feelings to AI language models runs the risk of unintended consequences and risks like bias and discrimination, manipulation, privacy evasion, and inappropriate or offensive responses. Therefore, before including emotions in AI language models, it is crucial to thoroughly consider the risks and ethical ramifications. When creating and implementing these kinds of systems, developers should prioritize accountability, transparency, and user permission. To make sure that the possible risks and benefits are completely comprehended and mitigated, it is also crucial to involve a variety of stakeholders, including experts on psychology and ethics.


\subsubsection{Style-based technique for higher level text analysis}

By combining style-based techniques that utilize complex networks with Chat GPT, the model can leverage the analysis of stylistic attributes to enhance its text generation capabilities. This combination allows Chat GPT to identify, understand, and replicate stylistic patterns, resulting in text that aligns not only with the content but also with the desired style. The integration of style-based analysis within the Chat GPT framework enables a more comprehensive understanding and generation of text, opening up possibilities for personalized, stylistically rich, and contextually appropriate interactions. For instance, \cite{correa2019word} has introduced a method to induce word senses by leveraging word embeddings and community detection in complex networks. Chat GPT can potentially provide an innovative extension by incorporating style metrics and adequate prompting techniques.

In addition to this, Chat GPT can contribute innovatively by integrating word embedding \cite{quispe2021using} to enhance its understanding and incorporation of style elements. By leveraging virtual edges and considering stylistic features, Chat GPT can generate text that exhibits desired stylistic nuances. Furthermore, integrating style-based text analysis into Chat GPT's conversational framework \cite{stella2019forma} can help in generating text that feels more natural and personalized, fostering a stronger connection between the user and the AI system. However, the main challenge at hand is to adeptly merge Chat GPT's capacity for generating content-focused text with the style analysis facilitated by complex network-based approaches. It requires seamless integration of Chat GPT's content generation prowess with the comprehensive style analysis offered by complex network techniques. Achieving this synergy is vital to effectively combine the strengths of both approaches and produce text that not only captures the intended content but also reflects the desired stylistic attributes. Arguably, effective conversational AI systems like ChatGPT require a combination of various techniques and considerations to deliver a satisfying and human-like conversational experience, for example, considering factors such as context understanding, coherence, and response relevance.

\subsection{Personalization}
Future iterations of ChatGPT might be adapted to each user, making use of their prior interactions to personalize answers and create more intimate conversations. User profiling and data protection could both be improved as a result. Important considerations for enhancing ChatGPT's customization abilities are as follows (Figure \ref{fig:personalizedChatGPT}).

\subsubsection{Increase personalized user experiences through various sources}
More information can be provided to improve understanding of linguistic patterns and enable answers to be more user-specific. Numerous sources, including social media, customer support interactions, and other online conversations, can provide this information. More diverse data and a deeper comprehension of linguistic nuance would ultimately lead to more personalized recommendations and responses \cite{dwivedi2021setting}.

\subsubsection{Fine-tuning of specific domains}
Increasing domain knowledge in a particular topic or domain, such as customer service, healthcare, business, or finance, can be accomplished by fine-tuning a particular dataset. For users in that particular domain, this may result in answers that are more precise and tailored \cite{batko2022use,himeur2022ai}. For instance, if we wanted to increase ChatGPT's capacity to offer tailored responses to customers in the medical field, we could do so by including more information about medical history and contemporary medical advancements in blogs, social media platforms, and periodicals. With the aid of this information, ChatGPT will be better able to provide customers in the medical industry with personalized answers by better comprehending the linguistic conventions and terminologies used there \cite{eysenbach2023role,kung2023performance}.

% Figure environment removed

\subsubsection{Incorporating personalized prompts}
Including personalized prompts, such as the user's name or reference to prior conversations, can enhance user satisfaction and improve understanding. ChatGPT can use a user's name in the answer if it is known, making the interaction more customized. For instance, ChatGPT might reply. For instance, let's consider a scenario where a user named John has engaged in a previous conversation with ChatGPT, during which he mentioned his name. If John were to inquire, "What's the weather like today?" ChatGPT could respond with, "Certainly, John! Today's forecast is sunny with a temperature of 75 degrees." By incorporating John's name and previous conversation, ChatGPT is capable of delivering a more personalized and customized response, thereby enhancing the user's overall satisfaction and comprehension of the information provided \cite{jungwirth2023artificial}.

\subsubsection{Provide instances of cultural and regional diversity}
ChatGPT can be trained on a diverse collection of data that includes details about various cultural norms and traditions, such as greetings, social customs, and cultural practices. This can aid ChatGPT in better comprehending and addressing users from various cultural backgrounds and ensuring that its retorts are considerate and respectful of various cultural norms and standards.

\subsubsection{User feedback on conversational responses}
Gathering user feedback on conversational responses can help pinpoint ways to make them more individualized. Surveys, user trials, and analysis of user interactions with the model are all ways to gather feedback. This can direct upcoming updates and training while also pointing out areas where the model needs development. Users' comments on ChatGPT can be gathered to determine what needs to be improved. As an illustration, if a user asks a query and ChatGPT responds incorrectly, the user can offer feedback to fix the error. With time, ChatGPT can use this input to enhance the precision and customization of its responses.

\subsubsection{Continuous training and updating}
In order to enhance ChatGPT's capacity to deliver personalized answers, new data can be trained on it. For instance, if a new fashion trend emerges, ChatGPT can be trained on data pertaining to that trend to enhance its capacity to offer individualized answers about it. %This can entail expanding the training set with new data, making adjustments to the model's parameters, or completely retraining the model to improve its ability to change over time. 
Specifically, there are several ways to achieve continuous training and updating of ChatGPT. One approach is to feed new data into the model on a regular basis, either by adding new data to the existing training set or by fine-tuning the model on new data. This can be done through techniques such as transfer learning, where the model is trained on a large dataset and then fine-tuned on a smaller, more specific dataset.
Another approach is to continually monitor the performance of ChatGPT and make adjustments to the model as needed. This can involve monitoring metrics such as accuracy, perplexity, and language generation quality and using this feedback to update the model's architecture or training process.
Additionally, it is important to note that continuous training and updating of ChatGPT requires ongoing resources and infrastructure to support it. This includes access to large amounts of training data, computing power, and storage space to store the model and its updates.

\subsection{Multimodal design}
Multimodal integration to ChatGPT would enable more natural and human-like intuitive, engaging, and effective communication. It entails creating machine learning models and algorithms capable of processing and combining a variety of data, including text, audio, and images. These different modalities can be combined and integrated into various ways to create more engaging and effective user experiences. Some key aspects of designing multimodal AI are as follows (Figure \ref{fig:Multimodal AI}).

\subsubsection{Image-based design} 
The use of images as the main tool for communicating is the focus of image-based design. In order to convey a certain message or idea, this can involve the use of images, illustrations, and other visual components. Visual recognition, image captioning, and image-based search can be integrated with ChatGPT to make it a multimodal AI. For instance, image recognition and analysis can be used to determine the most useful visual aspects to employ in a design, and image-based search can be used to find relevant visual content. Similarly, image captioning can be used to add descriptive or explanatory text to images, which can help to make them more accessible and informative for viewers. Image recognition and image-based search are powerful tools that have numerous applications in different fields. For instance, students can utilize these technologies to locate and analyze relevant images for academic research purposes. On the other hand, medical professionals can use image recognition to examine medical images such as X-rays and ECG graphs, which can help with the diagnosis of various conditions. Additionally, image-based search can be utilized to find relevant medical images for research purposes. Moreover, Image captioning can be used to add descriptive text to product photos, making them more engaging and informative for potential customers. This can be especially helpful for users who are visually impaired and rely on screen readers to access content.

\subsubsection{Audio-based design} 
A few examples of audio features that can be incorporated with ChatGPT are speech recognition, audio captioning, and content-based audio retrieval. By processing aural input and translating it into text that software or other devices may use, speech recognition technology enables ChatGPT to comprehend and recognize spoken words. It would be beneficial for persons who are deaf or hard of hearing, as well as non-native speakers, to add text subtitles to audio information or audio captioning because it can help make audio content more accessible. Audio subtitles for audio content can be produced manually or automatically using voice recognition software. In addition, users could search for audio content based on the characteristics of that content using content-based audio retrieval.

% Figure environment removed

\subsubsection{Video-based design} 
Integrating video-based design technologies such as video content analysis, video captioning, and video indexing is a crucial aspect of developing a multimodal AI system. By incorporating video content analysis, a multimodal ChatGPT can analyze and process video footage, detect objects, and track motions within the video. Video captioning can be added to ChatGPT to provide closed captions or subtitles during conversations, making the video content more accessible. Additionally, video indexing allows users to search for specific content within a video using keywords or timestamps, making it easier to find relevant information quickly. This makes video-based design technologies essential for developing a robust and effective multimodal AI system.

\subsubsection{Human-computer interaction design}
The next step towards creating a multimodal AI would be to incorporate characteristics of human-computer interaction including facial expressions, touch sensitivity, and biometric recognition. For instance, face recognition technology would enable ChatGPT to recognize and react to various facial emotions. A more natural and tactile experience for the user can be achieved by adding touch sensitivity to ChatGPT, allowing it to recognize and react to touch inputs. By incorporating biometric authentication technology, such as fingerprint or iris scanning, ChatGPT may offer improved security and user authentication, making it a more dependable and trustworthy platform for critical activities.

\subsection{Trustworthiness}
One of the most pressing needs today is the development of trustworthy AI. To achieve this, future iterations of ChatGPT could incorporate features that guarantee impartial and fair answers. As AI ethics and fairness become more critical, three key categories could be considered: computing techniques, ethical considerations, and social considerations.
Upgraded technological developments such as deep learning, machine learning, and artificial neural networks should be integrated into computing methods to improve AI performance. However, ethical considerations must also be taken into account, including data ethics, to ensure that data gathering, storage, and use for AI system training are conducted ethically and responsibly while being protected from unauthorized access or abuse.
To prevent discrimination against individuals or groups based on characteristics such as religion, ethnicity, or gender, machine learning fairness must also be a priority. Privacy protection is another crucial factor that involves strategies such as encryption and differential privacy to safeguard user data and ensure their privacy is not violated. These measures are crucial for fostering user confidence and ensuring that AI operates in an ethical and moral manner \cite{rahimi2023chatgpt}.
To illustrate the factors related to ensuring trust in AI tools, a detailed diagram is presented in Figure \ref{fig:TrustworthyAI}.

% Figure environment removed

\par As an artificial intelligence language model (\cite{Abdel-Messih2023}), ChatGPT is made to produce responses based on the recurring patterns and relationships in the incoming data that it has been trained on. Future iterations of ChatGPT should include features to guarantee impartial and fair responses, though, in order to create a trustworthy AI. The inclusion of a wider variety of sources and viewpoints as well as efforts to correct any biases that may be present in the data can all help to enhance training data. One way to improve training data is to resolve biases and include a wider variety of sources and viewpoints. This can lessen the chance that ChatGPT's answers will reinforce preexisting biases or stereotypes. Fairness and responsibility can also be supported by transparency in the decision-making process. A transparent and explicable ChatGPT would offer detailed justifications for the choices it makes and the reasons behind the responses it generates. This might entail informing users of the characteristics or elements that go into producing a response. Incorporating methods for monitoring and feedback can also aid in identifying and resolving any potential problems. Encouraging fairness and moral conduct can help guarantee that ChatGPT keeps developing and getting better over time. To guarantee that ChatGPT is producing responses that are in line with moral and ethical standards, regular auditing and monitoring of the decision-making process is required. By implementing these suggestions, ChatGPT can develop into an AI that users can trust to produce true, objective, and moral answers. Some of the key components in building a trustworthy AI:
 
\subsubsection{Fairness}
Fairness in AI is should be incorporated to avoid biases and discrimination during the creation and application of AI systems. It entails ensuring that AI systems handle everyone equally and without discrimination and do not reinforce existing biases and inequalities. This requires a thorough consideration of the data used to train AI models, as well as the algorithms and decision-making procedures used in AI systems.
As an AI language model, ChatGPT can strive to achieve fairness by considering and addressing bias in its training data, decision-making processes, and outputs. One way to address bias in training data is to ensure that the data used to train the model is diverse and representative of the population. This can be achieved by using a variety of sources and by including data from underrepresented groups \cite{hassani2023role}. The training data should also be carefully curated and filtered to remove any biased or problematic data. Additionally, ChatGPT can incorporate fairness into its decision-making processes by using algorithms that account for fairness, such as those that use counterfactual reasoning or causal inference. These algorithms can help identify and correct potential biases in the model's outputs.
Finally, ChatGPT can strive to achieve fairness in its outputs by monitoring and analyzing its results to ensure that they are not unfairly biased against certain groups. If biases are detected, the model can be adjusted and retrained to address these issues.

Overall, It is important to note that achieving fairness is an ongoing process that requires continuous monitoring and improvement. As such, ChatGPT can also work to ensure transparency and accountability by providing explanations for its decisions and allowing for user feedback and oversight.


\subsubsection{Transparency}
The degree to which an AI system's decision-making processes and fundamental data are transparent and available to users is referred to as transparency in AI. Because transparent AI systems are simpler to comprehend and analyze, they encourage trust and make it more likely that the system will make ethical and legal choices.
As an AI language model, ChatGPT is designed to generate responses based on the input it receives. While it can provide information and insights, it does not have the ability to actively disclose information about itself or the data it uses to generate responses. However, to ensure transparency in the use of ChatGPT, it is important to be clear about the limitations of the model and its capabilities. Additionally, it is important to be transparent about the data sources used to train the model and any potential biases. To further enhance transparency, it may be useful to provide users with information about how the model is being used, such as in what contexts it is being deployed and how it is being monitored to ensure accuracy and fairness.


\subsubsection{Explainability}
An explainable AI could provide a comprehensive justification for its choices and decisions. As a result, humans can comprehend and validate the system's decision-making process, which is crucial for building confidence in AI systems.
ChatGPT is a machine learning model whose responses are based on statistical patterns in the data it was trained on. As such, it may not always provide the most nuanced or complete answer to a question, and it may occasionally make mistakes or provide incorrect information.
One approach to increasing explainability is to use models that are inherently interpretable, such as decision trees or linear regression models. These models are easier to understand because they explicitly show how each feature contributes to the model's output.


Another method is to calculate and present feature importance scores for the model's inputs. This allows users to see which factors the model is using to make its predictions.
Moving forward, creating visualizations can help users understand how the model is working. This might include showing which inputs are most influential, how the model is making decisions, and how it is arriving at its final output.
Moreover, adding a human-in-the-loop approach can also help increase the explainability of AI models. For example, providing users with the ability to ask follow-up questions about the model's predictions can help them better understand how the model arrived at its decision. Lastly,  providing clear and concise documentation that describes how the model was trained, what data was used, and how it is intended to be used can also increase the transparency and explainability of the AI model.


%\subsubsection{Reproducibility}
%The capacity of an AI system to reproduce its findings is referred to as reproducibility. This is crucial to ensuring that the system makes consistent, trustworthy responses and predictions over time. However, ChatGPT does not have a built-in "Reproducibility" feature per se, but it is able to provide information and answering questions related to reproducibility in various fields, such as science, engineering, and data analysis.





\subsubsection{Human-centered design}
It refers to the process of creating AI systems that are in tune with human values, needs, and preferences. This entails considering the ethical and social effects of AI systems and designing them with an emphasis on transparency, fairness, and accountability. This may necessitate incorporating moral principles into the design process, such as the principles of beneficence (doing good), non-maleficence (avoiding harm), and respect for values. 
In the case of developing AI language models, including ChatGPT, Human-Centered Design principles are usually applied in the research and development process, such as conducting user research to understand the needs and behaviors of people who use language models, testing different design prototypes, and iterating on the design based on user feedback.
% Figure environment removed

\section{Conclusion}
In this review article, we have showcased the immense potential of the future GPT language model in various fields by comprehensively reviewing more than 100 Scopus-indexed publications on ChatGPT. A novel taxonomy has been put forth which reveals a diverse range of applications across various domains such as healthcare, marketing \& finance, environment, education \& research, and academic writing. Despite its potential, the early ChatGPT researches still face some limitations. We have identified certain issues that may need to be addressed, which are classified as intrinsic and usage-centric. Additionally, we have identified and discussed ethical concerns. To overcome these challenges and to improve the efficacy of ChatGPT, we have uncovered some potential future directions.


Improving Conversational Capabilities, Personalization, Multimodal design, and Trustworthiness are some of the key areas that hold significant promise for the future of ChatGPT. By focusing on these directions and exploring possible solutions to current challenges, ChatGPT can become more ubiquitous and effective in the future, with the potential to revolutionize how humans interact with technology and can become a more effective and trustworthy tool for various segments of society. 



We posit that this review will inspire further research and development to fully harness the vast potential of ChatGPT across diverse application areas for both the researchers working in this field and the users exploring the use of ChatGPT. Undoubtedly, it is just the beginning of the ChatGPT-era and we anticipate that future GPT will bring significant benefits to our lives in the near future. We look forward to seeing the continued evolution and growth of ChatGPT research in the years to come.






\begin{thebibliography}{xx}

\harvarditem{Abdel-Messih \harvardand\ Kamel~Boulos}{2023}{Abdel-Messih2023}
Abdel-Messih, M.~S. \harvardand\ Kamel~Boulos, M.~N.  \harvardyearleft
  2023\harvardyearright , `Chatgpt in clinical toxicology', {\em JMIR Medical
  Education} {\bf 9}.

\harvarditem{Aczel \harvardand\ Wagenmakers}{2023}{aczel2023transparency}
Aczel, B. \harvardand\ Wagenmakers, E.-J.  \harvardyearleft
  2023\harvardyearright , `Transparency guidance for chatgpt usage in
  scientific writing'.

\harvarditem[Agathokleous et~al.]{Agathokleous, Saitanis, Fang \harvardand\
  Yu}{2023}{agathokleous2023use}
Agathokleous, E., Saitanis, C.~J., Fang, C. \harvardand\ Yu, Z.
  \harvardyearleft 2023\harvardyearright , `Use of chatgpt: What does it mean
  for biology and environmental science?', {\em Science of The Total
  Environment} p.~164154.

\harvarditem[Ahmad et~al.]{Ahmad, Waseem, Liang, Fehmideh, Aktar \harvardand\
  Mikkonen}{2023}{ahmad2023towards}
Ahmad, A., Waseem, M., Liang, P., Fehmideh, M., Aktar, M.~S. \harvardand\
  Mikkonen, T.  \harvardyearleft 2023\harvardyearright , `Towards human-bot
  collaborative software architecting with chatgpt', {\em arXiv preprint
  arXiv:2302.14600} .

\harvarditem{Ahn}{2023}{ahn2023exploring}
Ahn, C.  \harvardyearleft 2023\harvardyearright , `Exploring chatgpt for
  information of cardiopulmonary resuscitation', {\em Resuscitation} {\bf 185}.

\harvarditem{AI}{2023}{gpt4}
AI, O.  \harvardyearleft 2023\harvardyearright , `{GPT-4 Technical Report}',
  \url{. https://cdn.openai.com/papers/gpt-4.pdf}.
\newblock [Online; accessed 29-March-2023].

\harvarditem[AlAfnan et~al.]{AlAfnan, Dishari, Jovic \harvardand\
  Lomidze}{2023}{alafnan2023chatgpt}
AlAfnan, M.~A., Dishari, S., Jovic, M. \harvardand\ Lomidze, K.
  \harvardyearleft 2023\harvardyearright , `Chatgpt as an educational tool:
  Opportunities, challenges, and recommendations for communication, business
  writing, and composition courses', {\em Journal of Artificial Intelligence
  and Technology} {\bf 3}(2),~60--68.

\harvarditem[Ali et~al.]{Ali, Shamsan, Hezam \harvardand\
  Mohammed}{2023}{ali2023impact}
Ali, J. K.~M., Shamsan, M. A.~A., Hezam, T.~A. \harvardand\ Mohammed, A.~A.
  \harvardyearleft 2023\harvardyearright , `Impact of chatgpt on learning
  motivation: Teachers and students' voices', {\em Journal of English Studies
  in Arabia Felix} {\bf 2}(1),~41--49.

\harvarditem{Ali \harvardand\ Djalilian}{2023{\em a}}{ali2023readership}
Ali, M.~J. \harvardand\ Djalilian, A.  \harvardyearleft 2023{\em
  a}\harvardyearright , Readership awareness series--paper 4: Chatbots and
  chatgpt-ethical considerations in scientific publications, {\em in} `Seminars
  in ophthalmology', Taylor \& Francis, pp.~1--2.

\harvarditem{Ali \harvardand\ Djalilian}{2023{\em b}}{Ali2023}
Ali, M.~J. \harvardand\ Djalilian, A.  \harvardyearleft 2023{\em
  b}\harvardyearright , `Readership awareness series–paper 4: Chatbots and
  chatgpt - ethical considerations in scientific publications', {\em Seminars
  in Ophthalmology} .

\harvarditem{Aljanabi, Ghazi, Ali, Abed \harvardand\
  ChatGpt}{2023}{Aljanabi202362}
Aljanabi, M., Ghazi, M., Ali, A.~H., Abed, S.~A. \harvardand\ ChatGpt
  \harvardyearleft 2023\harvardyearright , `Chatgpt: Open possibilities', {\em
  Iraqi Journal for Computer Science and Mathematics} {\bf 4}(1),~62 – 64.

\harvarditem{Aljanabi, Ghazi, Ali, Abed et~al.}{2023}{aljanabi2023chatgpt}
Aljanabi, M., Ghazi, M., Ali, A.~H., Abed, S.~A. et~al.  \harvardyearleft
  2023\harvardyearright , `Chatgpt: Open possibilities', {\em Iraqi Journal For
  Computer Science and Mathematics} {\bf 4}(1),~62--64.

\harvarditem{Alkaissi \harvardand\ McFarlane}{2023}{alkaissi2023artificial}
Alkaissi, H. \harvardand\ McFarlane, S.~I.  \harvardyearleft
  2023\harvardyearright , `Artificial hallucinations in chatgpt: implications
  in scientific writing', {\em Cureus} {\bf 15}(2).

\harvarditem{Alkhaqani}{2023}{alkhaqani2023chatgpt}
Alkhaqani, A.~L.  \harvardyearleft 2023\harvardyearright , `Chatgpt and nursing
  education: Challenges and opportunities', {\em Al-Rafidain Journal of Medical
  Sciences (ISSN: 2789-3219)} {\bf 4},~50--51.

\harvarditem{Alser \harvardand\ Waisberg}{2023}{alser2023concerns}
Alser, M. \harvardand\ Waisberg, E.  \harvardyearleft 2023\harvardyearright ,
  `Concerns with the usage of chatgpt in academia and medicine: A viewpoint',
  {\em Am. J. Med. Open} {\bf 100036}.

\harvarditem{Amancio}{2015}{amancio2015comparing}
Amancio, D.~R.  \harvardyearleft 2015\harvardyearright , `Comparing the
  topological properties of real and artificially generated scientific
  manuscripts', {\em Scientometrics} {\bf 105},~1763--1779.

\harvarditem[Amin et~al.]{Amin, Cambria \harvardand\
  Schuller}{2023}{amin2023will}
Amin, M.~M., Cambria, E. \harvardand\ Schuller, B.~W.  \harvardyearleft
  2023\harvardyearright , `Will affective computing emerge from foundation
  models and general ai? a first evaluation on chatgpt', {\em arXiv preprint
  arXiv:2303.03186} .

\harvarditem[Aminah et~al.]{Aminah, Hidayah \harvardand\
  Ramli}{2023}{aminah2023considering}
Aminah, S., Hidayah, N. \harvardand\ Ramli, M.  \harvardyearleft
  2023\harvardyearright , `Considering chatgpt to be the first aid for young
  adults on mental health issues', {\em Journal of Public Health} p.~fdad065.

\harvarditem[Anderson et~al.]{Anderson, Belavy, Perle, Hendricks, Hespanhol,
  Verhagen \harvardand\ Memon}{2023}{Anderson2023}
Anderson, N., Belavy, D.~L., Perle, S.~M., Hendricks, S., Hespanhol, L.,
  Verhagen, E. \harvardand\ Memon, A.~R.  \harvardyearleft
  2023\harvardyearright , `Ai did not write this manuscript, or did it? can we
  trick the ai text detector into generated texts? the potential future of
  chatgpt and ai in sports \& exercise medicine manuscript generation', {\em
  BMJ Open Sport and Exercise Medicine} {\bf 9}(1).

\harvarditem[Arif et~al.]{Arif, Munaf \harvardand\ Ul-Haque}{2023{\em
  a}}{Arif2023}
Arif, T.~B., Munaf, U. \harvardand\ Ul-Haque, I.  \harvardyearleft 2023{\em
  a}\harvardyearright , `The future of medical education and research: Is
  chatgpt a blessing or blight in disguise?', {\em Medical Education Online}
  {\bf 28}(1).

\harvarditem[Arif et~al.]{Arif, Munaf \harvardand\ Ul-Haque}{2023{\em
  b}}{arif2023future}
Arif, T.~B., Munaf, U. \harvardand\ Ul-Haque, I.  \harvardyearleft 2023{\em
  b}\harvardyearright , `The future of medical education and research: Is
  chatgpt a blessing or blight in disguise?'.

\harvarditem[Bakker et~al.]{Bakker, Chadwick, Sheahan, Tessler,
  Campbell-Gillingham, Balaguer, McAleese, Glaese, Aslanides, Botvinick
  et~al.}{2022}{bakker2022fine}
Bakker, M., Chadwick, M., Sheahan, H., Tessler, M., Campbell-Gillingham, L.,
  Balaguer, J., McAleese, N., Glaese, A., Aslanides, J., Botvinick, M. et~al.
  \harvardyearleft 2022\harvardyearright , `Fine-tuning language models to find
  agreement among humans with diverse preferences', {\em Advances in Neural
  Information Processing Systems} {\bf 35},~38176--38189.

\harvarditem[Bashshur et~al.]{Bashshur, Doarn, Frenk, Kvedar \harvardand\
  Woolliscroft}{2020}{bashshur2020telemedicine}
Bashshur, R., Doarn, C.~R., Frenk, J.~M., Kvedar, J.~C. \harvardand\
  Woolliscroft, J.~O.  \harvardyearleft 2020\harvardyearright , `Telemedicine
  and the covid-19 pandemic, lessons for the future'.

\harvarditem{Batko \harvardand\ Slezak}{2022}{batko2022use}
Batko, K. \harvardand\ Slezak, A.  \harvardyearleft 2022\harvardyearright ,
  `The use of big data analytics in healthcare', {\em Journal of big Data} {\bf
  9}(1),~3.

\harvarditem{Beerbaum}{2023}{beerbaum2023generative}
Beerbaum, D.~O.  \harvardyearleft 2023\harvardyearright , `Generative
  artificial intelligence (gai) ethics taxonomy-applying chat gpt for robotic
  process automation (gai-rpa) as business case', {\em Available at SSRN
  4385025} .

\harvarditem[Bhattacharyya et~al.]{Bhattacharyya, Chakraborty \harvardand\
  Neogi}{2023}{bhattacharyya2023chatgpt}
Bhattacharyya, R., Chakraborty, K. \harvardand\ Neogi, R.  \harvardyearleft
  2023\harvardyearright , `Chatgpt and its application in the field of mental
  health', {\em Journal of SAARC Psychiatric Federation} {\bf 1}(1),~6--10.

\harvarditem[Bhayana et~al.]{Bhayana, Krishna \harvardand\
  Bleakney}{2023}{bhayana2023performance}
Bhayana, R., Krishna, S. \harvardand\ Bleakney, R.~R.  \harvardyearleft
  2023\harvardyearright , `Performance of chatgpt on a radiology board-style
  examination: Insights into current strengths and limitations', {\em
  Radiology} p.~230582.

\harvarditem{Bishop}{2023}{bishop2023computer}
Bishop, L.  \harvardyearleft 2023\harvardyearright , `A computer wrote this
  paper: What chatgpt means for education, research, and writing', {\em
  Research, and Writing (January 26, 2023)} .

\harvarditem{Biswas}{2023{\em a}}{biswas2023chatgpt}
Biswas, S.  \harvardyearleft 2023{\em a}\harvardyearright , `Chatgpt and the
  future of medical writing'.

\harvarditem{Biswas}{2023{\em b}}{biswas2023prospective}
Biswas, S.  \harvardyearleft 2023{\em b}\harvardyearright , `Prospective role
  of chat gpt in the military: According to chatgpt', {\em Qeios} .

\harvarditem{Biswas}{2023{\em c}}{biswas2023reducing}
Biswas, S.  \harvardyearleft 2023{\em c}\harvardyearright , `Reducing
  cardiologist's burden: Can chatgpt assist in writing discharge summaries of
  cardiac icu patients?', {\em Available at SSRN 4403586} .

\harvarditem{Biswas}{2023{\em d}}{biswas2023potential}
Biswas, S.~S.  \harvardyearleft 2023{\em d}\harvardyearright , `Potential use
  of chat gpt in global warming', {\em Annals of Biomedical Engineering}
  pp.~1--2.

\harvarditem{Biswas}{2023{\em e}}{Biswas2023}
Biswas, S.~S.  \harvardyearleft 2023{\em e}\harvardyearright , `Role of chat
  gpt in public health', {\em Annals of Biomedical Engineering} .

\harvarditem{Bom}{2023}{bom2023exploring}
Bom, H.-S.~H.  \harvardyearleft 2023\harvardyearright , `Exploring the
  opportunities and challenges of chatgpt in academic writing: a roundtable
  discussion', {\em Nuclear Medicine and Molecular Imaging} pp.~1--3.

\harvarditem{Bommarito~II \harvardand\ Katz}{2022}{bommarito2022gpt}
Bommarito~II, M. \harvardand\ Katz, D.~M.  \harvardyearleft
  2022\harvardyearright , `Gpt takes the bar exam', {\em arXiv preprint
  arXiv:2212.14402} .

\harvarditem{Borji}{2023}{borji2023categorical}
Borji, A.  \harvardyearleft 2023\harvardyearright , `A categorical archive of
  chatgpt failures', {\em arXiv preprint arXiv:2302.03494} .

\harvarditem[Budler et~al.]{Budler, Gosak \harvardand\
  Stiglic}{2023}{Budler2023}
Budler, L.~C., Gosak, L. \harvardand\ Stiglic, G.  \harvardyearleft
  2023\harvardyearright , `Review of artificial intelligence-based
  question-answering systems in healthcare', {\em Wiley Interdisciplinary
  Reviews: Data Mining and Knowledge Discovery} {\bf 13}(2).

\harvarditem{Budzianowski \harvardand\ Vulic}{2019}{budzianowski2019hello}
Budzianowski, P. \harvardand\ Vulic, I.  \harvardyearleft 2019\harvardyearright
  , `Hello, it's gpt-2--how can i help you? towards the use of pretrained
  language models for task-oriented dialogue systems', {\em arXiv preprint
  arXiv:1907.05774} .

\harvarditem{Cahan \harvardand\ Treutlein}{2023}{cahan2023conversation}
Cahan, P. \harvardand\ Treutlein, B.  \harvardyearleft 2023\harvardyearright ,
  `A conversation with chatgpt on the role of computational systems biology in
  stem cell research', {\em Stem Cell Reports} {\bf 18}(1),~1--2.

\harvarditem[Cao et~al.]{Cao, Li, Liu, Yan, Dai, Yu \harvardand\
  Sun}{2023}{cao2023comprehensive}
Cao, Y., Li, S., Liu, Y., Yan, Z., Dai, Y., Yu, P.~S. \harvardand\ Sun, L.
  \harvardyearleft 2023\harvardyearright , `A comprehensive survey of
  ai-generated content (aigc): A history of generative ai from gan to chatgpt',
  {\em arXiv preprint arXiv:2303.04226} .

\harvarditem[Cascella et~al.]{Cascella, Montomoli, Bellini \harvardand\
  Bignami}{2023{\em a}}{cascella2023evaluating}
Cascella, M., Montomoli, J., Bellini, V. \harvardand\ Bignami, E.
  \harvardyearleft 2023{\em a}\harvardyearright , `Evaluating the feasibility
  of chatgpt in healthcare: an analysis of multiple clinical and research
  scenarios', {\em Journal of Medical Systems} {\bf 47}(1),~1--5.

\harvarditem[Cascella et~al.]{Cascella, Montomoli, Bellini \harvardand\
  Bignami}{2023{\em b}}{Cascella2023}
Cascella, M., Montomoli, J., Bellini, V. \harvardand\ Bignami, E.
  \harvardyearleft 2023{\em b}\harvardyearright , `Evaluating the feasibility
  of chatgpt in healthcare: An analysis of multiple clinical and research
  scenarios', {\em Journal of Medical Systems} {\bf 47}(1).

\harvarditem{Chen, Yu, Yang, Guo, Bian \harvardand\
  Wu}{2023}{chen2023contextualized}
Chen, A., Yu, Z., Yang, X., Guo, Y., Bian, J. \harvardand\ Wu, Y.
  \harvardyearleft 2023\harvardyearright , `Contextualized medication
  information extraction using transformer-based deep learning architectures',
  {\em Journal of Biomedical Informatics} p.~104370.

\harvarditem{Chen, Yuan, Huang, Guo, Wang \harvardand\
  Chen}{2023}{chen2023feedback}
Chen, H., Yuan, K., Huang, Y., Guo, L., Wang, Y. \harvardand\ Chen, J.
  \harvardyearleft 2023\harvardyearright , `Feedback is all you need: from
  chatgpt to autonomous driving', {\em Science China Information Sciences} {\bf
  66}(6),~1--3.

\harvarditem[Chen et~al.]{Chen, Tworek, Jun, Yuan, Pinto, Kaplan, Edwards,
  Burda, Joseph, Brockman et~al.}{2021}{chen2021evaluating}
Chen, M., Tworek, J., Jun, H., Yuan, Q., Pinto, H. P. d.~O., Kaplan, J.,
  Edwards, H., Burda, Y., Joseph, N., Brockman, G. et~al.  \harvardyearleft
  2021\harvardyearright , `Evaluating large language models trained on code',
  {\em arXiv preprint arXiv:2107.03374} .

\harvarditem{Chen}{2023{\em a}}{chen2023chatgpt}
Chen, T.-J.  \harvardyearleft 2023{\em a}\harvardyearright , `Chatgpt and other
  artificial intelligence applications speed up scientific writing', {\em
  Journal of the Chinese Medical Association} {\bf 86}(4),~351--353.

\harvarditem{Chen}{2023{\em b}}{Chen2023}
Chen, X.  \harvardyearleft 2023{\em b}\harvardyearright , `Chatgpt and its
  possible impact on library reference services', {\em Internet Reference
  Services Quarterly} .

\harvarditem[Choi et~al.]{Choi, Lee, Ho, Kwok \harvardand\ Lok}{2023}{Choi2023}
Choi, E. P.~H., Lee, J.~J., Ho, M.-H., Kwok, J. Y.~Y. \harvardand\ Lok, K.
  Y.~W.  \harvardyearleft 2023\harvardyearright , `Chatting or cheating? the
  impacts of chatgpt and other artificial intelligence language models on nurse
  education', {\em Nurse Education Today} {\bf 125}.

\harvarditem[Christiano et~al.]{Christiano, Leike, Brown, Martic, Legg
  \harvardand\ Amodei}{2017}{christiano2017deep}
Christiano, P.~F., Leike, J., Brown, T., Martic, M., Legg, S. \harvardand\
  Amodei, D.  \harvardyearleft 2017\harvardyearright , `Deep reinforcement
  learning from human preferences', {\em Advances in neural information
  processing systems} {\bf 30}.

\harvarditem[Chuma et~al.]{Chuma, Bang \harvardand\
  Alfredson}{2023}{chuma2023business}
Chuma, E., Bang, M. \harvardand\ Alfredson, J.  \harvardyearleft
  2023\harvardyearright , `Business ai decision-making tools: Case chatgpt
  evaluation'.

\harvarditem{Cooper}{2023}{Cooper2023}
Cooper, G.  \harvardyearleft 2023\harvardyearright , `Examining science
  education in chatgpt: An exploratory study of generative artificial
  intelligence', {\em Journal of Science Education and Technology} .

\harvarditem{Corr{\^e}a~Jr \harvardand\ Amancio}{2019}{correa2019word}
Corr{\^e}a~Jr, E.~A. \harvardand\ Amancio, D.~R.  \harvardyearleft
  2019\harvardyearright , `Word sense induction using word embeddings and
  community detection in complex networks', {\em Physica A: Statistical
  Mechanics and its Applications} {\bf 523},~180--190.

\harvarditem[Cotton et~al.]{Cotton, Cotton \harvardand\
  Shipway}{2023}{cotton2023chatting}
Cotton, D.~R., Cotton, P.~A. \harvardand\ Shipway, J.~R.  \harvardyearleft
  2023\harvardyearright , `Chatting and cheating: Ensuring academic integrity
  in the era of chatgpt', {\em Innovations in Education and Teaching
  International} pp.~1--12.

\harvarditem{Cox \harvardand\ Tzoc}{2023}{Cox202399}
Cox, C. \harvardand\ Tzoc, E.  \harvardyearleft 2023\harvardyearright ,
  `Chatgpt implications for academic libraries', {\em College and Research
  Libraries News} {\bf 84}(3),~99 – 102.

\harvarditem{Cox}{2023}{Cox2023}
Cox, L.~A.  \harvardyearleft 2023\harvardyearright , `Causal reasoning about
  epidemiological associations in conversational ai', {\em Global Epidemiology}
  {\bf 5}.

\harvarditem{Curtis}{2023}{Curtis2023275}
Curtis, N.  \harvardyearleft 2023\harvardyearright , `To chatgpt or not to
  chatgpt? the impact of artificial intelligence on academic publishing', {\em
  Pediatric Infectious Disease Journal} {\bf 42}(4),~275.

\harvarditem[D'Amico et~al.]{D'Amico, White, Shah \harvardand\
  Langer}{2023}{D'Amico2023663}
D'Amico, R.~S., White, T.~G., Shah, H.~A. \harvardand\ Langer, D.~J.
  \harvardyearleft 2023\harvardyearright , `I asked a chatgpt to write an
  editorial about how we can incorporate chatbots into neurosurgical research
  and patient care…', {\em Neurosurgery} {\bf 92}(4),~663 – 664.

\harvarditem{Deng \harvardand\ Lin}{2022}{deng2022benefits}
Deng, J. \harvardand\ Lin, Y.  \harvardyearleft 2022\harvardyearright , `The
  benefits and challenges of chatgpt: An overview', {\em Frontiers in Computing
  and Intelligent Systems} {\bf 2}(2),~81--83.

\harvarditem[Dergaa et~al.]{Dergaa, Chamari, Zmijewski \harvardand\
  Saad}{2023}{dergaa2023human}
Dergaa, I., Chamari, K., Zmijewski, P. \harvardand\ Saad, H.~B.
  \harvardyearleft 2023\harvardyearright , `From human writing to artificial
  intelligence generated text: examining the prospects and potential threats of
  chatgpt in academic writing', {\em Biology of Sport} {\bf 40}(2),~615--622.

\harvarditem{DiGiorgio \harvardand\ Ehrenfeld}{2023}{DiGiorgio2023}
DiGiorgio, A.~M. \harvardand\ Ehrenfeld, J.~M.  \harvardyearleft
  2023\harvardyearright , `Artificial intelligence in medicine \& chatgpt:
  De-tether the physician', {\em Journal of Medical Systems} {\bf 47}(1).

\harvarditem{Domnich \harvardand\ Anbarjafari}{2021}{Domnich2021ResponsibleAG}
Domnich, A. \harvardand\ Anbarjafari, G.  \harvardyearleft
  2021\harvardyearright , `Responsible ai: Gender bias assessment in emotion
  recognition', {\em ArXiv} {\bf abs/2103.11436}.

\harvarditem[D{\"O}NMEZ et~al.]{D{\"O}NMEZ, Sahin \harvardand\
  G{\"U}LEN}{2023}{donmez2023conducting}
D{\"O}NMEZ, {\.I}., Sahin, I. \harvardand\ G{\"U}LEN, S.  \harvardyearleft
  2023\harvardyearright , `Conducting academic research with the ai interface
  chatgpt: Challenges and opportunities', {\em Journal of STEAM Education} {\bf
  6}(2),~101--118.

\harvarditem{Dowling \harvardand\ Lucey}{2023}{Dowling2023}
Dowling, M. \harvardand\ Lucey, B.  \harvardyearleft 2023\harvardyearright ,
  `Chatgpt for (finance) research: The bananarama conjecture', {\em Finance
  Research Letters} {\bf 53}.

\harvarditem[Du et~al.]{Du, Teng, Chen, Ma, Wang, Gou, Li, Ma, Miao, Na
  et~al.}{2023}{du2023chat}
Du, H., Teng, S., Chen, H., Ma, J., Wang, X., Gou, C., Li, B., Ma, S., Miao,
  Q., Na, X. et~al.  \harvardyearleft 2023\harvardyearright , `Chat with
  chatgpt on intelligent vehicles: An ieee tiv perspective', {\em IEEE
  Transactions on Intelligent Vehicles} .

\harvarditem[Dugan et~al.]{Dugan, Ippolito, Kirubarajan, Shi \harvardand\
  Callison-Burch}{2022}{dugan2022real}
Dugan, L., Ippolito, D., Kirubarajan, A., Shi, S. \harvardand\ Callison-Burch,
  C.  \harvardyearleft 2022\harvardyearright , `Real or fake text?:
  Investigating human ability to detect boundaries between human-written and
  machine-generated text', {\em arXiv preprint arXiv:2212.12672} .

\harvarditem[Dwivedi et~al.]{Dwivedi, Ismagilova, Hughes, Carlson, Filieri,
  Jacobson, Jain, Karjaluoto, Kefi, Krishen et~al.}{2021}{dwivedi2021setting}
Dwivedi, Y.~K., Ismagilova, E., Hughes, D.~L., Carlson, J., Filieri, R.,
  Jacobson, J., Jain, V., Karjaluoto, H., Kefi, H., Krishen, A.~S. et~al.
  \harvardyearleft 2021\harvardyearright , `Setting the future of digital and
  social media marketing research: Perspectives and research propositions',
  {\em International Journal of Information Management} {\bf 59},~102168.

\harvarditem[Dwivedi et~al.]{Dwivedi, Kshetri, Hughes, Slade, Jeyaraj, Kar,
  Baabdullah, Koohang, Raghavan, Ahuja et~al.}{2023}{dwivedi2023so}
Dwivedi, Y.~K., Kshetri, N., Hughes, L., Slade, E.~L., Jeyaraj, A., Kar, A.~K.,
  Baabdullah, A.~M., Koohang, A., Raghavan, V., Ahuja, M. et~al.
  \harvardyearleft 2023\harvardyearright , `“so what if chatgpt wrote it?”
  multidisciplinary perspectives on opportunities, challenges and implications
  of generative conversational ai for research, practice and policy', {\em
  International Journal of Information Management} {\bf 71},~102642.

\harvarditem{Editorialge}{Jan, 2023}{chatGPTUse}
Editorialge  \harvardyearleft Jan, 2023\harvardyearright , `{Elsevier and
  Cambridge university allow use of chatgpt for academic writing}',
  \url{https://editorialge.com/elsevier-and-cambridge-university-allow-use-chatgpt/}.
\newblock [Online; accessed 29-March-2023].

\harvarditem[Eggmann et~al.]{Eggmann, Weiger, Zitzmann \harvardand\
  Blatz}{2023}{eggmann2023implications}
Eggmann, F., Weiger, R., Zitzmann, N.~U. \harvardand\ Blatz, M.~B.
  \harvardyearleft 2023\harvardyearright , `Implications of large language
  models such as chatgpt for dental medicine', {\em Journal of Esthetic and
  Restorative Dentistry} .

\harvarditem{Elali \harvardand\ Rachid}{2023}{Elali2023}
Elali, F.~R. \harvardand\ Rachid, L.~N.  \harvardyearleft 2023\harvardyearright
  , `Ai-generated research paper fabrication and plagiarism in the scientific
  community', {\em Patterns} {\bf 4}(3).

\harvarditem{Else}{2023}{Else2023423}
Else, H.  \harvardyearleft 2023\harvardyearright , `Abstracts written by
  chatgpt fool scientists', {\em Nature} {\bf 613}(7944),~423.

\harvarditem{Ernst \harvardand\ Bavota}{2022}{ernst2022ai}
Ernst, N.~A. \harvardand\ Bavota, G.  \harvardyearleft 2022\harvardyearright ,
  `Ai-driven development is here: Should you worry?', {\em IEEE Software} {\bf
  39}(2),~106--110.

\harvarditem{Eysenbach et~al.}{2023}{eysenbach2023role}
Eysenbach, G. et~al.  \harvardyearleft 2023\harvardyearright , `The role of
  chatgpt, generative language models, and artificial intelligence in medical
  education: A conversation with chatgpt and a call for papers', {\em JMIR
  Medical Education} {\bf 9}(1),~e46885.

\harvarditem[Farhat et~al.]{Farhat, Sohail \harvardand\
  Madsen}{2023}{farhat2023trustworthy}
Farhat, F., Sohail, S.~S. \harvardand\ Madsen, D.~{\O}.  \harvardyearleft
  2023\harvardyearright , `How trustworthy is chatgpt? the case of bibliometric
  analyses'.

\harvarditem{Fatani}{2023}{fatani2023chatgpt}
Fatani, B.  \harvardyearleft 2023\harvardyearright , `Chatgpt for future
  medical and dental research', {\em Cureus} {\bf 15}(4).

\harvarditem[Fija{\v{c}}ko et~al.]{Fija{\v{c}}ko, Gosak, {\v{S}}tiglic, Picard
  \harvardand\ Douma}{2023}{fijavcko2023can}
Fija{\v{c}}ko, N., Gosak, L., {\v{S}}tiglic, G., Picard, C.~T. \harvardand\
  Douma, M.~J.  \harvardyearleft 2023\harvardyearright , `Can chatgpt pass the
  life support exams without entering the american heart association course?',
  {\em Resuscitation} {\bf 185}.

\harvarditem[Fijačko et~al.]{Fijačko, Gosak, Štiglic, Picard \harvardand\
  John~Douma}{2023}{Fijačko2023}
Fijačko, N., Gosak, L., Štiglic, G., Picard, C.~T. \harvardand\ John~Douma,
  M.  \harvardyearleft 2023\harvardyearright , `Can chatgpt pass the life
  support exams without entering the american heart association course?', {\em
  Resuscitation} {\bf 185}.

\harvarditem{Firat}{2023}{firat2023chat}
Firat, M.  \harvardyearleft 2023\harvardyearright , `How chat gpt can transform
  autodidactic experiences and open education', {\em Department of Distance
  Education, Open Education Faculty, Anadolu Unive} .

\harvarditem{Frye}{2022}{frye2022should}
Frye, B.~L.  \harvardyearleft 2022\harvardyearright , `Should using an ai text
  generator to produce academic writing be plagiarism?', {\em Fordham
  Intellectual Property, Media \& Entertainment Law Journal, Forthcoming} .

\harvarditem{Gao, Howard, Markov, Dyer, Ramesh, Luo \harvardand\
  Pearson}{2023}{gao2023comparing}
Gao, C.~A., Howard, F.~M., Markov, N.~S., Dyer, E.~C., Ramesh, S., Luo, Y.
  \harvardand\ Pearson, A.~T.  \harvardyearleft 2023\harvardyearright ,
  `Comparing scientific abstracts generated by chatgpt to real abstracts with
  detectors and blinded human reviewers', {\em npj Digital Medicine} {\bf
  6}(1),~75.

\harvarditem{Gao, Ruan, Sun, Yin, Yang \harvardand\ Wan}{2023}{gao2023human}
Gao, M., Ruan, J., Sun, R., Yin, X., Yang, S. \harvardand\ Wan, X.
  \harvardyearleft 2023\harvardyearright , `Human-like summarization evaluation
  with chatgpt', {\em arXiv preprint arXiv:2304.02554} .

\harvarditem{Gao, Tong, Wu, Chen, Zhu \harvardand\ Wang}{2023}{Gao20231}
Gao, Y., Tong, W., Wu, E.~Q., Chen, W., Zhu, G. \harvardand\ Wang, F.-Y.
  \harvardyearleft 2023\harvardyearright , `Chat with chatgpt on interactive
  engines for intelligent driving', {\em IEEE Transactions on Intelligent
  Vehicles} p.~1–3.

\harvarditem[Gašević et~al.]{Gašević, Siemens \harvardand\
  Sadiq}{2023}{Gašević2023}
Gašević, D., Siemens, G. \harvardand\ Sadiq, S.  \harvardyearleft
  2023\harvardyearright , `Empowering learners for the age of artificial
  intelligence', {\em Computers and Education: Artificial Intelligence} .

\harvarditem[Geerling et~al.]{Geerling, Mateer, Wooten \harvardand\
  Damodaran}{2023}{geerling2023chatgpt}
Geerling, W., Mateer, G.~D., Wooten, J. \harvardand\ Damodaran, N.
  \harvardyearleft 2023\harvardyearright , `Is chatgpt smarter than a student
  in principles of economics?', {\em Available at SSRN 4356034} .

\harvarditem{George \harvardand\ George}{2023}{george2023review}
George, A.~S. \harvardand\ George, A.~H.  \harvardyearleft
  2023\harvardyearright , `A review of chatgpt ai's impact on several business
  sectors', {\em Partners Universal International Innovation Journal} {\bf
  1}(1),~9--23.

\harvarditem[Gilson et~al.]{Gilson, Safranek, Huang, Socrates, Chi, Taylor
  \harvardand\ Chartash}{2022}{gilson2022well}
Gilson, A., Safranek, C., Huang, T., Socrates, V., Chi, L., Taylor, R.~A.
  \harvardand\ Chartash, D.  \harvardyearleft 2022\harvardyearright , `How well
  does chatgpt do when taking the medical licensing exams? the implications of
  large language models for medical education and knowledge assessment', {\em
  medRxiv} pp.~2022--12.

\harvarditem{Gilson, Safranek, Huang, Socrates, Chi, Taylor \harvardand\
  Chartash}{2023}{Gilson2023}
Gilson, A., Safranek, C.~W., Huang, T., Socrates, V., Chi, L., Taylor, R.~A.
  \harvardand\ Chartash, D.  \harvardyearleft 2023\harvardyearright , `How does
  chatgpt perform on the united states medical licensing examination? the
  implications of large language models for medical education and knowledge
  assessment', {\em JMIR Medical Education} {\bf 9}.

\harvarditem{Gilson, Safranek, Huang, Socrates, Chi, Taylor, Chartash
  et~al.}{2023}{gilson2023does}
Gilson, A., Safranek, C.~W., Huang, T., Socrates, V., Chi, L., Taylor, R.~A.,
  Chartash, D. et~al.  \harvardyearleft 2023\harvardyearright , `How does
  chatgpt perform on the united states medical licensing examination? the
  implications of large language models for medical education and knowledge
  assessment', {\em JMIR Medical Education} {\bf 9}(1),~e45312.

\harvarditem[Gravel et~al.]{Gravel, D'Amours-Gravel \harvardand\
  Osmanlliu}{2023}{gravel2023learning}
Gravel, J., D'Amours-Gravel, M. \harvardand\ Osmanlliu, E.  \harvardyearleft
  2023\harvardyearright , `Learning to fake it: limited responses and
  fabricated references provided by chatgpt for medical questions.', {\em
  medRxiv} pp.~2023--03.

\harvarditem{Gunawan}{2023}{gunawan2023exploring}
Gunawan, J.  \harvardyearleft 2023\harvardyearright , `Exploring the future of
  nursing: Insights from the chatgpt model', {\em Belitung Nursing Journal}
  {\bf 9}(1),~1--5.

\harvarditem[Guo et~al.]{Guo, Lu, Dou \harvardand\ Wang}{2023}{guo2023can}
Guo, C., Lu, Y., Dou, Y. \harvardand\ Wang, F.-Y.  \harvardyearleft
  2023\harvardyearright , `Can chatgpt boost artistic creation: The need of
  imaginative intelligence for parallel art', {\em IEEE/CAA Journal of
  Automatica Sinica} {\bf 10}(4),~835--838.

\harvarditem{Halaweh}{2023}{halaweh2023chatgpt}
Halaweh, M.  \harvardyearleft 2023\harvardyearright , `Chatgpt in education:
  Strategies for responsible implementation', {\em Contemporary Educational
  Technology} {\bf 15}(2).

\harvarditem{Haman \harvardand\ Školník}{2023}{Haman2023}
Haman, M. \harvardand\ Školník, M.  \harvardyearleft 2023\harvardyearright ,
  `Using chatgpt to conduct a literature review', {\em Accountability in
  Research} .

\harvarditem{Harskamp \harvardand\ De~Clercq}{2023}{harskamp2023performance}
Harskamp, R.~E. \harvardand\ De~Clercq, L.  \harvardyearleft
  2023\harvardyearright , `Performance of chatgpt as an ai-assisted decision
  support tool in medicine: a proof-of-concept study for interpreting symptoms
  and management of common cardiac conditions (amstelheart-2)', {\em medRxiv}
  pp.~2023--03.

\harvarditem{Hassani \harvardand\ Silva}{2023}{hassani2023role}
Hassani, H. \harvardand\ Silva, E.~S.  \harvardyearleft 2023\harvardyearright ,
  `The role of chatgpt in data science: How ai-assisted conversational
  interfaces are revolutionizing the field', {\em Big Data and Cognitive
  Computing} {\bf 7}(2),~62.

\harvarditem[Haver et~al.]{Haver, Ambinder, Bahl, Oluyemi, Jeudy \harvardand\
  Yi}{2023}{haver2023appropriateness}
Haver, H.~L., Ambinder, E.~B., Bahl, M., Oluyemi, E.~T., Jeudy, J. \harvardand\
  Yi, P.~H.  \harvardyearleft 2023\harvardyearright , `Appropriateness of
  breast cancer prevention and screening recommendations provided by chatgpt',
  {\em Radiology} p.~230424.

\harvarditem[Hendy et~al.]{Hendy, Abdelrehim, Sharaf, Raunak, Gabr, Matsushita,
  Kim, Afify \harvardand\ Awadalla}{2023}{hendy2023good}
Hendy, A., Abdelrehim, M., Sharaf, A., Raunak, V., Gabr, M., Matsushita, H.,
  Kim, Y.~J., Afify, M. \harvardand\ Awadalla, H.~H.  \harvardyearleft
  2023\harvardyearright , `How good are gpt models at machine translation? a
  comprehensive evaluation', {\em arXiv preprint arXiv:2302.09210} .

\harvarditem[Hill-Yardin et~al.]{Hill-Yardin, Hutchinson, Laycock \harvardand\
  Spencer}{2023}{hill2023chat}
Hill-Yardin, E.~L., Hutchinson, M.~R., Laycock, R. \harvardand\ Spencer, S.~J.
  \harvardyearleft 2023\harvardyearright , `A chat (gpt) about the future of
  scientific publishing', {\em Brain, behavior, and immunity} pp.~S0889--1591.

\harvarditem[Himeur et~al.]{Himeur, Elnour, Fadli, Meskin, Petri, Rezgui,
  Bensaali \harvardand\ Amira}{2022{\em a}}{himeur2022ai}
Himeur, Y., Elnour, M., Fadli, F., Meskin, N., Petri, I., Rezgui, Y., Bensaali,
  F. \harvardand\ Amira, A.  \harvardyearleft 2022{\em a}\harvardyearright ,
  `Ai-big data analytics for building automation and management systems: a
  survey, actual challenges and future perspectives', {\em Artificial
  Intelligence Review} pp.~1--93.

\harvarditem[Himeur et~al.]{Himeur, Elnour, Fadli, Meskin, Petri, Rezgui,
  Bensaali \harvardand\ Amira}{2022{\em b}}{himeur2022next}
Himeur, Y., Elnour, M., Fadli, F., Meskin, N., Petri, I., Rezgui, Y., Bensaali,
  F. \harvardand\ Amira, A.  \harvardyearleft 2022{\em b}\harvardyearright ,
  `Next-generation energy systems for sustainable smart cities: Roles of
  transfer learning', {\em Sustainable Cities and Society} p.~104059.

\harvarditem[Hirosawa et~al.]{Hirosawa, Harada, Yokose, Sakamoto, Kawamura
  \harvardand\ Shimizu}{2023}{Hirosawa2023}
Hirosawa, T., Harada, Y., Yokose, M., Sakamoto, T., Kawamura, R. \harvardand\
  Shimizu, T.  \harvardyearleft 2023\harvardyearright , `Diagnostic accuracy of
  differential-diagnosis lists generated by generative pretrained transformer 3
  chatbot for clinical vignettes with common chief complaints: A pilot study',
  {\em International Journal of Environmental Research and Public Health} {\bf
  20}(4).

\harvarditem{Hisan \harvardand\ Amri}{2023}{hisan2023chatgpt}
Hisan, U.~K. \harvardand\ Amri, M.~M.  \harvardyearleft 2023\harvardyearright ,
  `Chatgpt and medical education: A double-edged sword', {\em Journal of
  Pedagogy and Education Science} {\bf 2}(01),~71--89.

\harvarditem{Hong}{2023}{hong2023impact}
Hong, W. C.~H.  \harvardyearleft 2023\harvardyearright , `The impact of chatgpt
  on foreign language teaching and learning: opportunities in education and
  research', {\em Journal of Educational Technology and Innovation} {\bf 3}(1).

\harvarditem{Hoppner \harvardand\ Streatfeild}{2023}{hoppner2023chatgpt}
Hoppner, T. \harvardand\ Streatfeild, L.  \harvardyearleft
  2023\harvardyearright , `Chatgpt, bard \& co.: An introduction to ai for
  competition and regulatory lawyers', {\em An Introduction to AI for
  Competition and Regulatory Lawyers (February 23, 2023)} {\bf 9}.

\harvarditem[Howard et~al.]{Howard, Hope \harvardand\
  Gerada}{2023}{howard2023chatgpt}
Howard, A., Hope, W. \harvardand\ Gerada, A.  \harvardyearleft
  2023\harvardyearright , `Chatgpt and antimicrobial advice: the end of the
  consulting infection doctor?', {\em The Lancet Infectious Diseases} {\bf
  23}(4),~405--406.

\harvarditem[Huang et~al.]{Huang, Kwak \harvardand\ An}{2023}{huang2023chatgpt}
Huang, F., Kwak, H. \harvardand\ An, J.  \harvardyearleft 2023\harvardyearright
  , `Is chatgpt better than human annotators? potential and limitations of
  chatgpt in explaining implicit hate speech', {\em arXiv preprint
  arXiv:2302.07736} .

\harvarditem{Huang \harvardand\ Tan}{2023}{huang2023role}
Huang, J. \harvardand\ Tan, M.  \harvardyearleft 2023\harvardyearright , `The
  role of chatgpt in scientific communication: writing better scientific review
  articles', {\em American Journal of Cancer Research} {\bf 13}(4),~1148.

\harvarditem{Huh}{2023{\em a}}{huh2023chatgpt}
Huh, S.  \harvardyearleft 2023{\em a}\harvardyearright , `Are chatgpt's
  knowledge and interpretation ability comparable to those of medical students
  in korea for taking a parasitology examination?: a descriptive study', {\em
  Journal of Educational Evaluation for Health Professions} {\bf 20},~1.

\harvarditem{Huh}{2023{\em b}}{Huh20231}
Huh, S.  \harvardyearleft 2023{\em b}\harvardyearright , `Emergence of the
  metaverse and chatgpt in journal publishing after the covid-19 pandemic',
  {\em Science Editing} {\bf 10}(1),~1 – 4.

\harvarditem{Huh}{2023{\em c}}{Huh20235}
Huh, S.  \harvardyearleft 2023{\em c}\harvardyearright , `Issues in the 3rd
  year of the covid-19 pandemic, including computer-based testing, study
  design, chatgpt, journal metrics, and appreciation to reviewers', {\em
  Journal of educational evaluation for health professions} {\bf 20},~5.

\harvarditem[Jain et~al.]{Jain, Eyre, Kumar, Gupta \harvardand\
  Kotecha}{n.d.}{jainknowledge}
Jain, D.~K., Eyre, Y. G.-M., Kumar, A., Gupta, B.~B. \harvardand\ Kotecha, K.
  \harvardyearleft n.d.\harvardyearright , `Knowledge-based data processing for
  multilingual natural language analysis', {\em ACM Transactions on Asian and
  Low-Resource Language Information Processing} .

\harvarditem[Javaid et~al.]{Javaid, Haleem \harvardand\
  Singh}{2023}{javaid2023chatgpt}
Javaid, M., Haleem, A. \harvardand\ Singh, R.~P.  \harvardyearleft
  2023\harvardyearright , `Chatgpt for healthcare services: An emerging stage
  for an innovative perspective', {\em BenchCouncil Transactions on Benchmarks,
  Standards and Evaluations} p.~100105.

\harvarditem[Jawahar et~al.]{Jawahar, Abdul-Mageed \harvardand\
  Lakshmanan}{2020}{jawahar2020automatic}
Jawahar, G., Abdul-Mageed, M. \harvardand\ Lakshmanan, L.~V.  \harvardyearleft
  2020\harvardyearright , `Automatic detection of machine generated text: A
  critical survey', {\em arXiv preprint arXiv:2011.01314} .

\harvarditem[Johinke et~al.]{Johinke, Cummings \harvardand\
  Di~Lauro}{2023}{Johinke2023}
Johinke, R., Cummings, R. \harvardand\ Di~Lauro, F.  \harvardyearleft
  2023\harvardyearright , `Reclaiming the technology of higher education for
  teaching digital writing in a post—pandemic world', {\em Journal of
  University Teaching and Learning Practice} {\bf 20}(2).

\harvarditem{Jungwirth \harvardand\ Haluza}{2023{\em a}}{Jungwirth2023}
Jungwirth, D. \harvardand\ Haluza, D.  \harvardyearleft 2023{\em
  a}\harvardyearright , `Artificial intelligence and public health: An
  exploratory study', {\em International Journal of Environmental Research and
  Public Health} {\bf 20}(5).

\harvarditem{Jungwirth \harvardand\ Haluza}{2023{\em
  b}}{jungwirth2023artificial}
Jungwirth, D. \harvardand\ Haluza, D.  \harvardyearleft 2023{\em
  b}\harvardyearright , `Artificial intelligence and public health: An
  exploratory study', {\em International Journal of Environmental Research and
  Public Health} {\bf 20}(5),~4541.

\harvarditem[Kaneda et~al.]{Kaneda, Tanimoto, Ozaki, Sato \harvardand\
  Takahashi}{2023}{kaneda2023can}
Kaneda, Y., Tanimoto, T., Ozaki, A., Sato, T. \harvardand\ Takahashi, K.
  \harvardyearleft 2023\harvardyearright , `Can chatgpt pass the 2023 japanese
  national medical licensing examination?'.

\harvarditem[Kasai et~al.]{Kasai, Kasai, Sakaguchi, Yamada \harvardand\
  Radev}{2023}{kasai2023evaluating}
Kasai, J., Kasai, Y., Sakaguchi, K., Yamada, Y. \harvardand\ Radev, D.
  \harvardyearleft 2023\harvardyearright , `Evaluating gpt-4 and chatgpt on
  japanese medical licensing examinations', {\em arXiv preprint
  arXiv:2303.18027} .

\harvarditem[Kasneci et~al.]{Kasneci, Se{\ss}ler, K{\"u}chemann, Bannert,
  Dementieva, Fischer, Gasser, Groh, G{\"u}nnemann, H{\"u}llermeier
  et~al.}{2023}{kasneci2023chatgpt}
Kasneci, E., Se{\ss}ler, K., K{\"u}chemann, S., Bannert, M., Dementieva, D.,
  Fischer, F., Gasser, U., Groh, G., G{\"u}nnemann, S., H{\"u}llermeier, E.
  et~al.  \harvardyearleft 2023\harvardyearright , `Chatgpt for good? on
  opportunities and challenges of large language models for education', {\em
  Learning and Individual Differences} {\bf 103},~102274.

\harvarditem[Khan et~al.]{Khan, Jawaid, Khan \harvardand\
  Sajjad}{2023}{Khan2023605}
Khan, R.~A., Jawaid, M., Khan, A.~R. \harvardand\ Sajjad, M.  \harvardyearleft
  2023\harvardyearright , `Chatgpt-reshaping medical education and clinical
  management', {\em Pakistan Journal of Medical Sciences} {\bf 39}(2),~605 –
  607.

\harvarditem{Kitamura}{2023}{kitamura2023chatgpt}
Kitamura, F.~C.  \harvardyearleft 2023\harvardyearright , `Chatgpt is shaping
  the future of medical writing but still requires human judgment'.

\harvarditem{Kitchenham}{2004}{kitchenham2004procedures}
Kitchenham, B.  \harvardyearleft 2004\harvardyearright , `Procedures for
  performing systematic reviews', {\em Keele, UK, Keele University} {\bf
  33}(2004),~1--26.

\harvarditem[Kohnke et~al.]{Kohnke, Moorhouse \harvardand\
  Zou}{2023}{kohnke2023chatgpt}
Kohnke, L., Moorhouse, B.~L. \harvardand\ Zou, D.  \harvardyearleft
  2023\harvardyearright , `Chatgpt for language teaching and learning', {\em
  RELC Journal} p.~00336882231162868.

\harvarditem{Koo}{2023}{koo2023importance}
Koo, M.  \harvardyearleft 2023\harvardyearright , `The importance of proper use
  of chatgpt in medical writing', {\em Radiology} p.~230312.

\harvarditem{Kshetri}{2023}{kshetri2023chatgpt}
Kshetri, N.  \harvardyearleft 2023\harvardyearright , `Chatgpt in developing
  economies', {\em IT Professional} {\bf 25}(2),~16--19.

\harvarditem{Kumar}{2023}{kumar2023analysis}
Kumar, A.~H.  \harvardyearleft 2023\harvardyearright , `Analysis of chatgpt
  tool to assess the potential of its utility for academic writing in
  biomedical domain', {\em Biology, Engineering, Medicine and Science Reports}
  {\bf 9}(1),~24--30.

\harvarditem[Kung et~al.]{Kung, Cheatham, Medenilla, Sillos, De~Leon,
  Elepa{\~n}o, Madriaga, Aggabao, Diaz-Candido, Maningo
  et~al.}{2023}{kung2023performance}
Kung, T.~H., Cheatham, M., Medenilla, A., Sillos, C., De~Leon, L., Elepa{\~n}o,
  C., Madriaga, M., Aggabao, R., Diaz-Candido, G., Maningo, J. et~al.
  \harvardyearleft 2023\harvardyearright , `Performance of chatgpt on usmle:
  Potential for ai-assisted medical education using large language models',
  {\em PLoS digital health} {\bf 2}(2),~e0000198.

\harvarditem[Lahat et~al.]{Lahat, Shachar, Avidan, Shatz, Glicksberg
  \harvardand\ Klang}{2023}{Lahat20234164}
Lahat, A., Shachar, E., Avidan, B., Shatz, Z., Glicksberg, B.~S. \harvardand\
  Klang, E.  \harvardyearleft 2023\harvardyearright , `Evaluating the use of
  large language model in identifying top research questions in
  gastroenterology', {\em Scientific reports} {\bf 13}(1),~4164.

\harvarditem[Lai et~al.]{Lai, Ngo, Veyseh, Man, Dernoncourt, Bui \harvardand\
  Nguyen}{2023}{lai2023chatgpt}
Lai, V.~D., Ngo, N.~T., Veyseh, A. P.~B., Man, H., Dernoncourt, F., Bui, T.
  \harvardand\ Nguyen, T.~H.  \harvardyearleft 2023\harvardyearright , `Chatgpt
  beyond english: Towards a comprehensive evaluation of large language models
  in multilingual learning', {\em arXiv preprint arXiv:2304.05613} .

\harvarditem{Lamichhane}{2023}{lamichhane2023evaluation}
Lamichhane, B.  \harvardyearleft 2023\harvardyearright , `Evaluation of chatgpt
  for nlp-based mental health applications', {\em arXiv preprint
  arXiv:2303.15727} .

\harvarditem{Lee}{2023{\em a}}{lee2023rise}
Lee, H.  \harvardyearleft 2023{\em a}\harvardyearright , `The rise of chatgpt:
  Exploring its potential in medical education', {\em Anatomical Sciences
  Education} .

\harvarditem{Lee}{2023{\em b}}{lee2023can}
Lee, J.~Y.  \harvardyearleft 2023{\em b}\harvardyearright , `Can an artificial
  intelligence chatbot be the author of a scholarly article?', {\em Journal of
  Educational Evaluation for Health Professions} {\bf 20}.

\harvarditem[Lei et~al.]{Lei, Zhang \harvardand\ Yang}{2023}{lei2023chatgpt}
Lei, L., Zhang, H. \harvardand\ Yang, S.~X.  \harvardyearleft
  2023\harvardyearright , `Chatgpt in connected and autonomous vehicles:
  benefits and challenges', {\em Intelligence \& Robotics} {\bf
  3}(2),~145--148.

\harvarditem[Li et~al.]{Li, Ma, Fan, Lee, Yu \harvardand\
  Hemphill}{2023}{li2023chatgpt}
Li, L., Ma, Z., Fan, L., Lee, S., Yu, H. \harvardand\ Hemphill, L.
  \harvardyearleft 2023\harvardyearright , `Chatgpt in education: A discourse
  analysis of worries and concerns on social media', {\em arXiv preprint
  arXiv:2305.02201} .

\harvarditem[Liang et~al.]{Liang, Wu, Morency \harvardand\
  Salakhutdinov}{2021}{liang2021towards}
Liang, P.~P., Wu, C., Morency, L.-P. \harvardand\ Salakhutdinov, R.
  \harvardyearleft 2021\harvardyearright , Towards understanding and mitigating
  social biases in language models, {\em in} `International Conference on
  Machine Learning', PMLR, pp.~6565--6576.

\harvarditem[Liebrenz et~al.]{Liebrenz, Schleifer, Buadze, Bhugra \harvardand\
  Smith}{2023}{Liebrenz2023e105}
Liebrenz, M., Schleifer, R., Buadze, A., Bhugra, D. \harvardand\ Smith, A.
  \harvardyearleft 2023\harvardyearright , `Generating scholarly content with
  chatgpt: ethical challenges for medical publishing', {\em The Lancet Digital
  Health} {\bf 5}(3),~e105 – e106.

\harvarditem[Lim et~al.]{Lim, Gunasekara, Pallant, Pallant \harvardand\
  Pechenkina}{2023}{Lim2023}
Lim, W.~M., Gunasekara, A., Pallant, J.~L., Pallant, J.~I. \harvardand\
  Pechenkina, E.  \harvardyearleft 2023\harvardyearright , `Generative ai and
  the future of education: Ragnarök or reformation? a paradoxical perspective
  from management educators', {\em International Journal of Management
  Education} {\bf 21}(2).

\harvarditem[Lin et~al.]{Lin, Huang \harvardand\ Yang}{2023}{Lin2023}
Lin, C.-C., Huang, A. Y.~Q. \harvardand\ Yang, S. J.~H.  \harvardyearleft
  2023\harvardyearright , `A review of ai-driven conversational chatbots
  implementation methodologies and challenges (1999–2022)', {\em
  Sustainability (Switzerland)} {\bf 15}(5).

\harvarditem{Lo}{2023}{lo2023impact}
Lo, C.~K.  \harvardyearleft 2023\harvardyearright , `What is the impact of
  chatgpt on education? a rapid review of the literature', {\em Education
  Sciences} {\bf 13}(4),~410.

\harvarditem[Lubiana et~al.]{Lubiana, Lopes, Medeiros, Silva, Goncalves,
  Maracaja-Coutinho \harvardand\ Nakaya}{2023}{lubiana2023ten}
Lubiana, T., Lopes, R., Medeiros, P., Silva, J.~C., Goncalves, A. N.~A.,
  Maracaja-Coutinho, V. \harvardand\ Nakaya, H.~I.  \harvardyearleft
  2023\harvardyearright , `Ten quick tips for harnessing the power of
  chatgpt/gpt-4 in computational biology', {\em arXiv preprint
  arXiv:2303.16429} .

\harvarditem{Lubowitz}{2023}{lubowitz2023chatgpt}
Lubowitz, J.~H.  \harvardyearleft 2023\harvardyearright , `Chatgpt, an
  artificial intelligence chatbot, is impacting medical literature', {\em
  Arthroscopy} {\bf 39}(5),~1121--1122.

\harvarditem{Lund \harvardand\ Wang}{2023}{lund2023chatting}
Lund, B.~D. \harvardand\ Wang, T.  \harvardyearleft 2023\harvardyearright ,
  `Chatting about chatgpt: how may ai and gpt impact academia and libraries?',
  {\em Library Hi Tech News} .

\harvarditem[Lund et~al.]{Lund, Wang, Mannuru, Nie, Shimray \harvardand\
  Wang}{2023{\em a}}{Lund2023}
Lund, B.~D., Wang, T., Mannuru, N.~R., Nie, B., Shimray, S. \harvardand\ Wang,
  Z.  \harvardyearleft 2023{\em a}\harvardyearright , `Chatgpt and a new
  academic reality: Artificial intelligence-written research papers and the
  ethics of the large language models in scholarly publishing', {\em Journal of
  the Association for Information Science and Technology} .

\harvarditem[Lund et~al.]{Lund, Wang, Mannuru, Nie, Shimray \harvardand\
  Wang}{2023{\em b}}{lund2023chatgpt}
Lund, B.~D., Wang, T., Mannuru, N.~R., Nie, B., Shimray, S. \harvardand\ Wang,
  Z.  \harvardyearleft 2023{\em b}\harvardyearright , `Chatgpt and a new
  academic reality: Artificial intelligence-written research papers and the
  ethics of the large language models in scholarly publishing', {\em Journal of
  the Association for Information Science and Technology} .

\harvarditem{Maddigan \harvardand\ Susnjak}{2023}{maddigan2023chat2vis}
Maddigan, P. \harvardand\ Susnjak, T.  \harvardyearleft 2023\harvardyearright ,
  `Chat2vis: Generating data visualisations via natural language using chatgpt,
  codex and gpt-3 large language models', {\em arXiv preprint arXiv:2302.02094}
  .

\harvarditem{Mann}{2023}{Mann2023221}
Mann, D.~L.  \harvardyearleft 2023\harvardyearright , `Artificial intelligence
  discusses the role of artificial intelligence in translational medicine: A
  jacc: Basic to translational science interview with chatgpt', {\em JACC:
  Basic to Translational Science} {\bf 8}(2),~221 – 223.

\harvarditem[Marchandot et~al.]{Marchandot, Matsushita, Carmona, Trimaille
  \harvardand\ Morel}{2023}{marchandot2023chatgpt}
Marchandot, B., Matsushita, K., Carmona, A., Trimaille, A. \harvardand\ Morel,
  O.  \harvardyearleft 2023\harvardyearright , `Chatgpt: the next frontier in
  academic writing for cardiologists or a pandora’s box of ethical dilemmas',
  {\em European Heart Journal Open} {\bf 3}(2),~oead007.

\harvarditem{McGee}{2023{\em a}}{mcgee2023capitalism}
McGee, R.~W.  \harvardyearleft 2023{\em a}\harvardyearright , `Capitalism,
  socialism and chatgpt', {\em Available at SSRN 4369953} .

\harvarditem{McGee}{2023{\em b}}{mcgee2023top}
McGee, R.~W.  \harvardyearleft 2023{\em b}\harvardyearright , `What are the top
  20 questions in economic philosophy? a chatgpt reply', {\em A Chatgpt Reply
  (April 8, 2023)} .

\harvarditem[Megahed et~al.]{Megahed, Chen, Ferris, Knoth \harvardand\
  Jones-Farmer}{2023}{megahed2023generative}
Megahed, F.~M., Chen, Y.-J., Ferris, J.~A., Knoth, S. \harvardand\
  Jones-Farmer, L.~A.  \harvardyearleft 2023\harvardyearright , `How generative
  ai models such as chatgpt can be (mis) used in spc practice, education, and
  research? an exploratory study', {\em arXiv preprint arXiv:2302.10916} .

\harvarditem[Melis et~al.]{Melis, Dyer \harvardand\
  Blunsom}{2017}{melis2017state}
Melis, G., Dyer, C. \harvardand\ Blunsom, P.  \harvardyearleft
  2017\harvardyearright , `On the state of the art of evaluation in neural
  language models', {\em arXiv preprint arXiv:1707.05589} .

\harvarditem{Mhlanga}{2023}{mhlanga2023open}
Mhlanga, D.  \harvardyearleft 2023\harvardyearright , `Open ai in education,
  the responsible and ethical use of chatgpt towards lifelong learning', {\em
  Education, the Responsible and Ethical Use of ChatGPT Towards Lifelong
  Learning (February 11, 2023)} .

\harvarditem[Mijwil et~al.]{Mijwil, Aljanabi \harvardand\
  ChatGPT}{2023}{Mijwil202365}
Mijwil, M.~M., Aljanabi, M. \harvardand\ ChatGPT  \harvardyearleft
  2023\harvardyearright , `Towards artificial intelligence-based cybersecurity:
  The practices and chatgpt generated ways to combat cybercrime', {\em Iraqi
  Journal for Computer Science and Mathematics} {\bf 4}(1),~65 – 70.

\harvarditem[Mitchell et~al.]{Mitchell, Lee, Khazatsky, Manning \harvardand\
  Finn}{2023}{mitchell2023detectgpt}
Mitchell, E., Lee, Y., Khazatsky, A., Manning, C.~D. \harvardand\ Finn, C.
  \harvardyearleft 2023\harvardyearright , `Detectgpt: Zero-shot
  machine-generated text detection using probability curvature', {\em arXiv
  preprint arXiv:2301.11305} .

\harvarditem[Mitrovic et~al.]{Mitrovic, Andreoletti \harvardand\
  Ayoub}{2023}{mitrovic2023chatgpt}
Mitrovic, S., Andreoletti, D. \harvardand\ Ayoub, O.  \harvardyearleft
  2023\harvardyearright , `Chatgpt or human? detect and explain. explaining
  decisions of machine learning model for detecting short chatgpt-generated
  text', {\em arXiv preprint arXiv:2301.13852} .

\harvarditem{Moons \harvardand\ Van~Bulck}{2023}{moons2023chatgpt}
Moons, P. \harvardand\ Van~Bulck, L.  \harvardyearleft 2023\harvardyearright ,
  `Chatgpt: can artificial intelligence language models be of value for
  cardiovascular nurses and allied health professionals', {\em European Journal
  of Cardiovascular Nursing} .

\harvarditem[Morreel et~al.]{Morreel, Mathysen \harvardand\
  Verhoeven}{2023}{Morreel2023}
Morreel, S., Mathysen, D. \harvardand\ Verhoeven, V.  \harvardyearleft
  2023\harvardyearright , `Aye, ai! chatgpt passes multiple-choice family
  medicine exam', {\em Medical Teacher} .

\harvarditem[Nadeem et~al.]{Nadeem, Bethke \harvardand\
  Reddy}{2020}{nadeem2020stereoset}
Nadeem, M., Bethke, A. \harvardand\ Reddy, S.  \harvardyearleft
  2020\harvardyearright , `Stereoset: Measuring stereotypical bias in
  pretrained language models', {\em arXiv preprint arXiv:2004.09456} .

\harvarditem[Nakaya et~al.]{Nakaya, Higaki \harvardand\
  Yamaguchi}{2023}{nakaya2023chatgpt}
Nakaya, Y., Higaki, A. \harvardand\ Yamaguchi, O.  \harvardyearleft
  2023\harvardyearright , `Chatgpt's ability to classify virtual reality
  studies in cardiology', {\em European Heart Journal-Digital Health}
  p.~ztad026.

\harvarditem{Naumova}{2023}{Naumova2023}
Naumova, E.~N.  \harvardyearleft 2023\harvardyearright , `A mistake-find
  exercise: a teacher’s tool to engage with information innovations, chatgpt,
  and their analogs', {\em Journal of Public Health Policy} .

\harvarditem{NewsGuard}{Jan, 2023}{chatGPTFake}
NewsGuard  \harvardyearleft Jan, 2023\harvardyearright , `{The Next Great
  Misinformation Superspreader: How ChatGPT Could Spread Toxic Misinformation
  At Unprecedented Scale}',
  \url{https://www.newsguardtech.com/misinformation-monitor/jan-2023/}.
\newblock [Online; accessed 29-March-2023].

\harvarditem{Odom-Forren}{2023}{odom2023role}
Odom-Forren, J.  \harvardyearleft 2023\harvardyearright , `The role of chatgpt
  in perianesthesia nursing', {\em Journal of PeriAnesthesia Nursing} {\bf
  38}(2),~176--177.

\harvarditem{Okan}{2023}{okan2023ai}
Okan, {\c{C}}.  \harvardyearleft 2023\harvardyearright , `Ai and psychiatry:
  The chatgpt perspective', {\em Alpha Psychiatry} {\bf 24}(2),~41.

\harvarditem{OpenAI}{Nov, 2023}{chatGPT}
OpenAI  \harvardyearleft Nov, 2023\harvardyearright , `{Chatgpt: Optimizing
  language models for dialogue}', \url{https://openai.com/blog/chatgpt}.
\newblock [Online; accessed 29-March-2023].

\harvarditem[Ortega-Mart{\'\i}n et~al.]{Ortega-Mart{\'\i}n, Garc{\'\i}a-Sierra,
  Ardoiz, {\'A}lvarez, Armenteros \harvardand\
  Alonso}{2023}{ortega2023linguistic}
Ortega-Mart{\'\i}n, M., Garc{\'\i}a-Sierra, {\'O}., Ardoiz, A., {\'A}lvarez,
  J., Armenteros, J.~C. \harvardand\ Alonso, A.  \harvardyearleft
  2023\harvardyearright , `Linguistic ambiguity analysis in chatgpt', {\em
  arXiv preprint arXiv:2302.06426} .

\harvarditem[Ouyang et~al.]{Ouyang, Wu, Jiang, Almeida, Wainwright, Mishkin,
  Zhang, Agarwal, Slama, Ray et~al.}{2022}{ouyang2022training}
Ouyang, L., Wu, J., Jiang, X., Almeida, D., Wainwright, C., Mishkin, P., Zhang,
  C., Agarwal, S., Slama, K., Ray, A. et~al.  \harvardyearleft
  2022\harvardyearright , `Training language models to follow instructions with
  human feedback', {\em Advances in Neural Information Processing Systems} {\bf
  35},~27730--27744.

\harvarditem[Pahl et~al.]{Pahl, Rieger, M{\"o}ller, Wittenberg \harvardand\
  Schmid}{2022}{Pahl2022FemaleW2}
Pahl, J., Rieger, I., M{\"o}ller, A., Wittenberg, T. \harvardand\ Schmid, U.
  \harvardyearleft 2022\harvardyearright , `Female, white, 27? bias evaluation
  on data and algorithms for affect recognition in faces', {\em 2022 ACM
  Conference on Fairness, Accountability, and Transparency} .

\harvarditem{Perkins}{2023}{Perkins2023}
Perkins, M.  \harvardyearleft 2023\harvardyearright , `Academic integrity
  considerations of ai large language models in the post-pandemic era: Chatgpt
  and beyond', {\em Journal of University Teaching and Learning Practice} {\bf
  20}(2).

\harvarditem[Prada et~al.]{Prada, Perroud \harvardand\
  Thorens}{2023}{Prada2023532}
Prada, P., Perroud, N. \harvardand\ Thorens, G.  \harvardyearleft
  2023\harvardyearright , `Artificial intelligence and psychiatry: questions
  from psychiatrists to chatgpt; [intelligence artificielle et psychiatrie :
  questions de psychiatres à chatgpt]', {\em Revue medicale suisse} {\bf
  19}(818),~532 – 536.

\harvarditem{Qadir}{2023}{qadir2023engineering}
Qadir, J.  \harvardyearleft 2023\harvardyearright , Engineering education in
  the era of chatgpt: Promise and pitfalls of generative ai for education, {\em
  in} `2023 IEEE Global Engineering Education Conference (EDUCON)', IEEE,
  pp.~1--9.

\harvarditem[Qin et~al.]{Qin, Zhang, Zhang, Chen, Yasunaga \harvardand\
  Yang}{2023}{qin2023chatgpt}
Qin, C., Zhang, A., Zhang, Z., Chen, J., Yasunaga, M. \harvardand\ Yang, D.
  \harvardyearleft 2023\harvardyearright , `Is chatgpt a general-purpose
  natural language processing task solver?', {\em arXiv preprint
  arXiv:2302.06476} .

\harvarditem[Qiu et~al.]{Qiu, He, Zhang, Li \harvardand\
  Lan}{2023}{qiu2023smile}
Qiu, H., He, H., Zhang, S., Li, A. \harvardand\ Lan, Z.  \harvardyearleft
  2023\harvardyearright , `Smile: Single-turn to multi-turn inclusive language
  expansion via chatgpt for mental health support', {\em arXiv preprint
  arXiv:2305.00450} .

\harvarditem[Quispe et~al.]{Quispe, Tohalino \harvardand\
  Amancio}{2021}{quispe2021using}
Quispe, L.~V., Tohalino, J.~A. \harvardand\ Amancio, D.~R.  \harvardyearleft
  2021\harvardyearright , `Using virtual edges to improve the discriminability
  of co-occurrence text networks', {\em Physica A: Statistical Mechanics and
  its Applications} {\bf 562},~125344.

\harvarditem{Rahimi \harvardand\ Abadi}{2023}{rahimi2023chatgpt}
Rahimi, F. \harvardand\ Abadi, A. T.~B.  \harvardyearleft 2023\harvardyearright
  , `Chatgpt and publication ethics', {\em Archives of Medical Research} .

\harvarditem{Rahman \harvardand\ Watanobe}{2023}{rahman2023chatgpt}
Rahman, M.~M. \harvardand\ Watanobe, Y.  \harvardyearleft 2023\harvardyearright
  , `Chatgpt for education and research: Opportunities, threats, and
  strategies'.

\harvarditem{Rathore}{2023}{rathore2023future}
Rathore, B.  \harvardyearleft 2023\harvardyearright , `Future of textile:
  Sustainable manufacturing \& prediction via chatgpt', {\em Eduzone:
  International Peer Reviewed/Refereed Multidisciplinary Journal} {\bf
  12}(1),~52--62.

\harvarditem{Ray}{2023}{ray2023chatgpt}
Ray, P.~P.  \harvardyearleft 2023\harvardyearright , `Chatgpt: A comprehensive
  review on background, applications, key challenges, bias, ethics, limitations
  and future scope', {\em Internet of Things and Cyber-Physical Systems} .

\harvarditem[Rillig et~al.]{Rillig, Ågerstrand, Bi, Gould \harvardand\
  Sauerland}{2023}{Rillig20233464}
Rillig, M.~C., Ågerstrand, M., Bi, M., Gould, K.~A. \harvardand\ Sauerland, U.
   \harvardyearleft 2023\harvardyearright , `Risks and benefits of large
  language models for the environment', {\em Environmental Science and
  Technology} {\bf 57}(9),~3464 – 3466.

\harvarditem[Roosan et~al.]{Roosan, Samore, Jones, Livnat \harvardand\
  Clutter}{2016}{roosan2016big}
Roosan, D., Samore, M., Jones, M., Livnat, Y. \harvardand\ Clutter, J.
  \harvardyearleft 2016\harvardyearright , Big-data based decision-support
  systems to improve clinicians' cognition, {\em in} `2016 IEEE International
  Conference on Healthcare Informatics (ICHI)', IEEE, pp.~285--288.

\harvarditem{Rospigliosi}{2023}{Rospigliosi20231}
Rospigliosi, P.~a.  \harvardyearleft 2023\harvardyearright , `Artificial
  intelligence in teaching and learning: what questions should we ask of
  chatgpt?', {\em Interactive Learning Environments} {\bf 31}(1),~1 -- 3.

\harvarditem{Sallam}{2023}{sallam2023utility}
Sallam, M.  \harvardyearleft 2023\harvardyearright , `The utility of chatgpt as
  an example of large language models in healthcare education, research and
  practice: Systematic review on the future perspectives and potential
  limitations', {\em medRxiv} pp.~2023--02.

\harvarditem[Sallam et~al.]{Sallam, Salim, Barakat \harvardand\
  Al-Tammemi}{2023}{sallam2023chatgpt}
Sallam, M., Salim, N., Barakat, M. \harvardand\ Al-Tammemi, A.
  \harvardyearleft 2023\harvardyearright , `Chatgpt applications in medical,
  dental, pharmacy, and public health education: A descriptive study
  highlighting the advantages and limitations', {\em Narra J} {\bf
  3}(1),~e103--e103.

\harvarditem[Salvagno et~al.]{Salvagno, Taccone, Gerli
  et~al.}{2023}{salvagno2023can}
Salvagno, M., Taccone, F.~S., Gerli, A.~G. et~al.  \harvardyearleft
  2023\harvardyearright , `Can artificial intelligence help for scientific
  writing?', {\em Critical Care} {\bf 27}(1),~1--5.

\harvarditem{Sedaghat}{2023}{sedaghat2023early}
Sedaghat, S.  \harvardyearleft 2023\harvardyearright , `Early applications of
  chatgpt in medical practice, education and research', {\em Clinical Medicine}
  {\bf 23}(3),~278--279.

\harvarditem{Seghier}{2023}{Seghier2023216}
Seghier, M.~L.  \harvardyearleft 2023\harvardyearright , `Chatgpt: not all
  languages are equal', {\em Nature} {\bf 615}(7951),~216.

\harvarditem[Siegerink et~al.]{Siegerink, Pet, Rosendaal \harvardand\
  Schoones}{2023}{Siegerink2023}
Siegerink, B., Pet, L.~A., Rosendaal, F.~R. \harvardand\ Schoones, J.~W.
  \harvardyearleft 2023\harvardyearright , `Chatgpt as an author of academic
  papers is wrong and highlights the concepts of accountability and
  contributorship', {\em Nurse Education in Practice} {\bf 68}.

\harvarditem{Sifat}{2023}{sifat2023chatgpt}
Sifat, R.~I.  \harvardyearleft 2023\harvardyearright , `Chatgpt and the future
  of health policy analysis: potential and pitfalls of using chatgpt in
  policymaking', {\em Annals of Biomedical Engineering} pp.~1--3.

\harvarditem{Singh}{2023}{singh2023artificial}
Singh, O.~P.  \harvardyearleft 2023\harvardyearright , `Artificial intelligence
  in the era of chatgpt-opportunities and challenges in mental health care',
  {\em Indian Journal of Psychiatry} {\bf 65}(3),~297.

\harvarditem[Skalidis et~al.]{Skalidis, Cagnina, Luangphiphat, Mahendiran,
  Muller, Abbe \harvardand\ Fournier}{2023}{skalidis2023chatgpt}
Skalidis, I., Cagnina, A., Luangphiphat, W., Mahendiran, T., Muller, O., Abbe,
  E. \harvardand\ Fournier, S.  \harvardyearleft 2023\harvardyearright ,
  `Chatgpt takes on the european exam in core cardiology: an artificial
  intelligence success story?', {\em European Heart Journal-Digital Health}
  p.~ztad029.

\harvarditem{{\v{S}}lapeta}{2023}{vslapeta2023chatgpt}
{\v{S}}lapeta, J.  \harvardyearleft 2023\harvardyearright , `Are chatgpt and
  other pretrained language models good parasitologists?', {\em Trends in
  Parasitology} .

\harvarditem[Sobania et~al.]{Sobania, Briesch, Hanna \harvardand\
  Petke}{2023}{sobania2023analysis}
Sobania, D., Briesch, M., Hanna, C. \harvardand\ Petke, J.  \harvardyearleft
  2023\harvardyearright , `An analysis of the automatic bug fixing performance
  of chatgpt', {\em arXiv preprint arXiv:2301.08653} .

\harvarditem{Sohail, Madsen, Farhat \harvardand\
  Afshar~Alam}{2023}{sohail2023chatgpt}
Sohail, S.~S., Madsen, D.~{\O}., Farhat, F. \harvardand\ Afshar~Alam, M.
  \harvardyearleft 2023\harvardyearright , `Chatgpt and vaccines: Can ai
  chatbots boost awareness and uptake?'.

\harvarditem{Sohail, Madsen, Himeur \harvardand\ Ashraf}{2023}{sohail2023using}
Sohail, S.~S., Madsen, D.~{\O}., Himeur, Y. \harvardand\ Ashraf, M.
  \harvardyearleft 2023\harvardyearright , `Using chatgpt to navigate
  ambivalent and contradictory research findings on artificial intelligence',
  {\em Available at SSRN 4413913} .

\harvarditem[Stella et~al.]{Stella, De~Nigris, Aloric \harvardand\
  Siew}{2019}{stella2019forma}
Stella, M., De~Nigris, S., Aloric, A. \harvardand\ Siew, C.~S.
  \harvardyearleft 2019\harvardyearright , `Forma mentis networks quantify
  crucial differences in stem perception between students and experts', {\em
  PloS one} {\bf 14}(10),~e0222870.

\harvarditem[Stiennon et~al.]{Stiennon, Ouyang, Wu, Ziegler, Lowe, Voss,
  Radford, Amodei \harvardand\ Christiano}{2020}{stiennon2020learning}
Stiennon, N., Ouyang, L., Wu, J., Ziegler, D., Lowe, R., Voss, C., Radford, A.,
  Amodei, D. \harvardand\ Christiano, P.~F.  \harvardyearleft
  2020\harvardyearright , `Learning to summarize with human feedback', {\em
  Advances in Neural Information Processing Systems} {\bf 33},~3008--3021.

\harvarditem{Stokel-Walker}{2022}{Stokel-Walker2022}
Stokel-Walker, C.  \harvardyearleft 2022\harvardyearright , `Ai bot chatgpt
  writes smart essays — should academics worry?', {\em Nature} .

\harvarditem{Stokel-Walker \harvardand\ Van~Noorden}{2023}{stokel2023chatgpt}
Stokel-Walker, C. \harvardand\ Van~Noorden, R.  \harvardyearleft
  2023\harvardyearright , `What chatgpt and generative ai mean for science',
  {\em Nature} {\bf 614}(7947),~214--216.

\harvarditem{Street \harvardand\ Wilck}{2023}{street2023let}
Street, D. \harvardand\ Wilck, J.  \harvardyearleft 2023\harvardyearright ,
  `“let’s have a chat:” applying chatgpt and other large language models
  to the practice of forensic accounting'.

\harvarditem[Subramani et~al.]{Subramani, Jaleel \harvardand\
  Krishna~Mohan}{2023}{subramani2023evaluating}
Subramani, M., Jaleel, I. \harvardand\ Krishna~Mohan, S.  \harvardyearleft
  2023\harvardyearright , `Evaluating the performance of chatgpt in medical
  physiology university examination of phase i mbbs', {\em Advances in
  Physiology Education} {\bf 47}(2),~270--271.

\harvarditem{Surameery \harvardand\ Shakor}{2023}{surameery2023use}
Surameery, N. M.~S. \harvardand\ Shakor, M.~Y.  \harvardyearleft
  2023\harvardyearright , `Use chat gpt to solve programming bugs', {\em
  International Journal of Information Technology \& Computer Engineering
  (IJITC) ISSN: 2455-5290} {\bf 3}(01),~17--22.

\harvarditem{TALAN \harvardand\ KALINKARA}{2023}{talan2023role}
TALAN, T. \harvardand\ KALINKARA, Y.  \harvardyearleft 2023\harvardyearright ,
  `The role of artificial intelligence in higher education: Chatgpt assessment
  for anatomy course', {\em Uluslararas{\i} Y{\"o}netim Bili{\c{s}}im
  Sistemleri ve Bilgisayar Bilimleri Dergisi} {\bf 7}(1),~33--40.

\harvarditem[Temsah et~al.]{Temsah, Khan, Chaiah, Senjab, Alhasan, Jamal,
  Aljamaan, Malki, Halwani, Al-Tawfiq et~al.}{2023}{temsah2023overview}
Temsah, O., Khan, S.~A., Chaiah, Y., Senjab, A., Alhasan, K., Jamal, A.,
  Aljamaan, F., Malki, K.~H., Halwani, R., Al-Tawfiq, J.~A. et~al.
  \harvardyearleft 2023\harvardyearright , `Overview of early chatgpt’s
  presence in medical literature: insights from a hybrid literature review by
  chatgpt and human experts', {\em Cureus} {\bf 15}(4).

\harvarditem[Thurzo et~al.]{Thurzo, Strunga, Urban, Surovková \harvardand\
  Afrashtehfar}{2023}{Thurzo2023}
Thurzo, A., Strunga, M., Urban, R., Surovková, J. \harvardand\ Afrashtehfar,
  K.~I.  \harvardyearleft 2023\harvardyearright , `Impact of artificial
  intelligence on dental education: A review and guide for curriculum update',
  {\em Education Sciences} {\bf 13}(2).

\harvarditem[Tlili et~al.]{Tlili, Shehata, Adarkwah, Bozkurt, Hickey, Huang
  \harvardand\ Agyemang}{2023{\em a}}{Tlili2023}
Tlili, A., Shehata, B., Adarkwah, M.~A., Bozkurt, A., Hickey, D.~T., Huang, R.
  \harvardand\ Agyemang, B.  \harvardyearleft 2023{\em a}\harvardyearright ,
  `What if the devil is my guardian angel: Chatgpt as a case study of using
  chatbots in education', {\em Smart Learning Environments} {\bf 10}(1).

\harvarditem[Tlili et~al.]{Tlili, Shehata, Adarkwah, Bozkurt, Hickey, Huang
  \harvardand\ Agyemang}{2023{\em b}}{tlili2023if}
Tlili, A., Shehata, B., Adarkwah, M.~A., Bozkurt, A., Hickey, D.~T., Huang, R.
  \harvardand\ Agyemang, B.  \harvardyearleft 2023{\em b}\harvardyearright ,
  `What if the devil is my guardian angel: Chatgpt as a case study of using
  chatbots in education', {\em Smart Learning Environments} {\bf 10}(1),~15.

\harvarditem[Tomlinson et~al.]{Tomlinson, Torrance \harvardand\
  Black}{2023}{tomlinson2023chatgpt}
Tomlinson, B., Torrance, A.~W. \harvardand\ Black, R.~W.  \harvardyearleft
  2023\harvardyearright , `Chatgpt and works scholarly: Best practices and
  legal pitfalls in writing with ai', {\em arXiv preprint arXiv:2305.03722} .

\harvarditem{Tong \harvardand\ Zhang}{2023}{Tong2023220}
Tong, Y. \harvardand\ Zhang, L.  \harvardyearleft 2023\harvardyearright ,
  `Discovering the next decade's synthetic biology research trends with
  chatgpt', {\em Synthetic and Systems Biotechnology} {\bf 8}(2),~220 – 223.

\harvarditem{Tregoning}{2023}{Tregoning2023}
Tregoning, J.  \harvardyearleft 2023\harvardyearright , `Ai writing tools could
  hand scientists the ‘gift of time’', {\em Nature} .

\harvarditem{Ufuk}{2023}{ufuk2023role}
Ufuk, F.  \harvardyearleft 2023\harvardyearright , `The role and limitations of
  large language models such as chatgpt in clinical settings and medical
  journalism', {\em Radiology} {\bf 307}(3),~e230276.

\harvarditem{Uludag}{2023}{uludag2023testing}
Uludag, K.  \harvardyearleft 2023\harvardyearright , `Testing creativity of
  chatgpt in psychology: Interview with chatgpt', {\em Available at SSRN
  4390872} .

\harvarditem{Van~Bulck \harvardand\ Moons}{2023}{van2023response}
Van~Bulck, L. \harvardand\ Moons, P.  \harvardyearleft 2023\harvardyearright ,
  `Response to the letter to the editor on: Dr. chatgpt in cardiovascular
  nursing: A deeper dive into trustworthiness, value, and potential risks',
  {\em European Journal of Cardiovascular Nursing} p.~zvad049.

\harvarditem{van Schalkwyk}{2023}{van2023artificial}
van Schalkwyk, G.  \harvardyearleft 2023\harvardyearright , `Artificial
  intelligence in pediatric behavioral health'.

\harvarditem[Vemprala et~al.]{Vemprala, Bonatti, Bucker \harvardand\
  Kapoor}{2023}{vemprala2023chatgpt}
Vemprala, S., Bonatti, R., Bucker, A. \harvardand\ Kapoor, A.  \harvardyearleft
  2023\harvardyearright , `Chatgpt for robotics: Design principles and model
  abilities', {\em Microsoft Autonomous Systems and Robotics Research} .

\harvarditem[Wake et~al.]{Wake, Kanehira, Sasabuchi, Takamatsu \harvardand\
  Ikeuchi}{2023}{wake2023chatgpt}
Wake, N., Kanehira, A., Sasabuchi, K., Takamatsu, J. \harvardand\ Ikeuchi, K.
  \harvardyearleft 2023\harvardyearright , `Chatgpt empowered long-step robot
  control in various environments: A case application', {\em arXiv preprint
  arXiv:2304.03893} .

\harvarditem[Wang et~al.]{Wang, Li \harvardand\ Smola}{2019}{wang2019language}
Wang, C., Li, M. \harvardand\ Smola, A.~J.  \harvardyearleft
  2019\harvardyearright , `Language models with transformers', {\em arXiv
  preprint arXiv:1904.09408} .

\harvarditem{Wang}{2023{\em a}}{wang2023linguistic}
Wang, F.-Y.  \harvardyearleft 2023{\em a}\harvardyearright , `Linguistic
  intelligence for intelligent vehicles: Chatgpt and future logistics and
  mobility', {\em IEEE Transactions on Intelligent Vehicles} {\bf
  8}(3),~2011--2019.

\harvarditem{Wang, Miao, Li, Wang \harvardand\ Lin}{2023}{Wang2023575}
Wang, F.-Y., Miao, Q., Li, X., Wang, X. \harvardand\ Lin, Y.  \harvardyearleft
  2023\harvardyearright , `What does chatgpt say: The dao from algorithmic
  intelligence to linguistic intelligence', {\em IEEE/CAA Journal of Automatica
  Sinica} {\bf 10}(3),~575 – 579.

\harvarditem{Wang}{2023{\em b}}{Wang202334}
Wang, S.~H.  \harvardyearleft 2023{\em b}\harvardyearright , `Openai —
  explain why some countries are excluded from chatgpt', {\em Nature} {\bf
  615}(7950),~34.

\harvarditem{Wang, Gong, Wang, Jia, Xu, Zhao, Fan, Wu, Hu \harvardand\
  Li}{2023}{wang2023chatgpt}
Wang, X., Gong, Z., Wang, G., Jia, J., Xu, Y., Zhao, J., Fan, Q., Wu, S., Hu,
  W. \harvardand\ Li, X.  \harvardyearleft 2023\harvardyearright , `Chatgpt
  performs on the chinese national medical licensing examination'.

\harvarditem[Wei et~al.]{Wei, Wang, Schuurmans, Bosma, Chi, Le \harvardand\
  Zhou}{2022}{wei2022chain}
Wei, J., Wang, X., Schuurmans, D., Bosma, M., Chi, E., Le, Q. \harvardand\
  Zhou, D.  \harvardyearleft 2022\harvardyearright , `Chain of thought
  prompting elicits reasoning in large language models', {\em arXiv preprint
  arXiv:2201.11903} .

\harvarditem{White, Fu, Hays, Sandborn, Olea, Gilbert, Elnashar, Spencer-Smith
  \harvardand\ Schmidt}{2023}{white2023prompta}
White, J., Fu, Q., Hays, S., Sandborn, M., Olea, C., Gilbert, H., Elnashar, A.,
  Spencer-Smith, J. \harvardand\ Schmidt, D.~C.  \harvardyearleft
  2023\harvardyearright , `A prompt pattern catalog to enhance prompt
  engineering with chatgpt', {\em arXiv preprint arXiv:2302.11382} .

\harvarditem{White, Hays, Fu, Spencer-Smith \harvardand\
  Schmidt}{2023}{white2023chatgptb}
White, J., Hays, S., Fu, Q., Spencer-Smith, J. \harvardand\ Schmidt, D.~C.
  \harvardyearleft 2023\harvardyearright , `Chatgpt prompt patterns for
  improving code quality, refactoring, requirements elicitation, and software
  design', {\em arXiv preprint arXiv:2303.07839} .

\harvarditem{Williams \harvardand\ Shambrook}{2023}{williams2023will}
Williams, M.~C. \harvardand\ Shambrook, J.  \harvardyearleft
  2023\harvardyearright , `How will artificial intelligence transform
  cardiovascular computed tomography? a conversation with an ai model', {\em
  Journal of Cardiovascular Computed Tomography} .

\harvarditem[Wu et~al.]{Wu, Wu, Qiu, Li, Zheng \harvardand\
  Yang}{2023}{wu2023qualifying}
Wu, J., Wu, X., Qiu, Z., Li, M., Zheng, Y. \harvardand\ Yang, J.
  \harvardyearleft 2023\harvardyearright , `Qualifying chinese medical
  licensing examination with knowledge enhanced generative pre-training model',
  {\em arXiv preprint arXiv:2305.10163} .

\harvarditem[Yang et~al.]{Yang, Ji, Zhang, Xie \harvardand\
  Ananiadou}{2023}{yang2023evaluations}
Yang, K., Ji, S., Zhang, T., Xie, Q. \harvardand\ Ananiadou, S.
  \harvardyearleft 2023\harvardyearright , `On the evaluations of chatgpt and
  emotion-enhanced prompting for mental health analysis', {\em arXiv preprint
  arXiv:2304.03347} .

\harvarditem[You et~al.]{You, Ye, Zhou, Zhu \harvardand\
  Du}{2023}{you2023robot}
You, H., Ye, Y., Zhou, T., Zhu, Q. \harvardand\ Du, J.  \harvardyearleft
  2023\harvardyearright , `Robot-enabled construction assembly with automated
  sequence planning based on chatgpt: Robogpt', {\em arXiv preprint
  arXiv:2304.11018} .

\harvarditem[Zhang et~al.]{Zhang, Pu, Xue, Yang, Xu, Wang \harvardand\
  Wang}{2023}{zhang2023hivegpt}
Zhang, J., Pu, J., Xue, J., Yang, M., Xu, X., Wang, X. \harvardand\ Wang, F.-Y.
   \harvardyearleft 2023\harvardyearright , `Hivegpt: human-machine-augmented
  intelligent vehicles with generative pre-trained transformer', {\em IEEE
  Transactions on Intelligent Vehicles} .

\harvarditem{Zhang \harvardand\ Li}{2021}{zhang2021commentary}
Zhang, M. \harvardand\ Li, J.  \harvardyearleft 2021\harvardyearright , `A
  commentary of gpt-3 in mit technology review 2021', {\em Fundamental
  Research} {\bf 1}(6),~831--833.

\harvarditem[Zheng et~al.]{Zheng, Abdel-Aty, Wang, Wang \harvardand\
  Ding}{2023}{zheng2023chatgpt}
Zheng, O., Abdel-Aty, M., Wang, D., Wang, Z. \harvardand\ Ding, S.
  \harvardyearleft 2023\harvardyearright , `Chatgpt is on the horizon: Could a
  large language model be all we need for intelligent transportation?', {\em
  arXiv preprint arXiv:2303.05382} .

\harvarditem{Zhou \harvardand\ Zafarani}{2020}{zhou2020survey}
Zhou, X. \harvardand\ Zafarani, R.  \harvardyearleft 2020\harvardyearright , `A
  survey of fake news: Fundamental theories, detection methods, and
  opportunities', {\em ACM Computing Surveys (CSUR)} {\bf 53}(5),~1--40.

\harvarditem[Zhu et~al.]{Zhu, Jiang, Yang \harvardand\
  Ren}{2023}{zhu2023chatgpt}
Zhu, J.-J., Jiang, J., Yang, M. \harvardand\ Ren, Z.~J.  \harvardyearleft
  2023\harvardyearright , `Chatgpt and environmental research', {\em
  Environmental Science \& Technology} .

\harvarditem[Zhuo et~al.]{Zhuo, Huang, Chen \harvardand\
  Xing}{2023}{zhuo2023exploring}
Zhuo, T.~Y., Huang, Y., Chen, C. \harvardand\ Xing, Z.  \harvardyearleft
  2023\harvardyearright , `Exploring ai ethics of chatgpt: A diagnostic
  analysis', {\em arXiv preprint arXiv:2301.12867} .

\harvarditem{Šlapeta}{2023}{Šlapeta2023}
Šlapeta, J.  \harvardyearleft 2023\harvardyearright , `Are chatgpt and other
  pretrained language models good parasitologists?', {\em Trends in
  Parasitology} .

\end{thebibliography}


\end{document}

https://www.overleaf.com/project/6421edec427fba9c8f411ebe