% Generated by IEEEtran.bst, version: 1.14 (2015/08/26)
\begin{thebibliography}{10}
\providecommand{\url}[1]{#1}
\csname url@samestyle\endcsname
\providecommand{\newblock}{\relax}
\providecommand{\bibinfo}[2]{#2}
\providecommand{\BIBentrySTDinterwordspacing}{\spaceskip=0pt\relax}
\providecommand{\BIBentryALTinterwordstretchfactor}{4}
\providecommand{\BIBentryALTinterwordspacing}{\spaceskip=\fontdimen2\font plus
\BIBentryALTinterwordstretchfactor\fontdimen3\font minus
  \fontdimen4\font\relax}
\providecommand{\BIBforeignlanguage}[2]{{%
\expandafter\ifx\csname l@#1\endcsname\relax
\typeout{** WARNING: IEEEtran.bst: No hyphenation pattern has been}%
\typeout{** loaded for the language `#1'. Using the pattern for}%
\typeout{** the default language instead.}%
\else
\language=\csname l@#1\endcsname
\fi
#2}}
\providecommand{\BIBdecl}{\relax}
\BIBdecl

\bibitem{wolf-etal-2020-transformers}
T.~Wolf, L.~Debut, V.~Sanh, J.~Chaumond, C.~Delangue, A.~Moi, P.~Cistac,
  T.~Rault, R.~Louf, M.~Funtowicz, J.~Davison, S.~Shleifer, P.~von Platen,
  C.~Ma, Y.~Jernite, J.~Plu, C.~Xu, T.~Le~Scao, S.~Gugger, M.~Drame, Q.~Lhoest,
  and A.~Rush, ``Transformers: State-of-the-art natural language processing,''
  in \emph{Proceedings of the 2020 Conference on Empirical Methods in Natural
  Language Processing: System Demonstrations}.\hskip 1em plus 0.5em minus
  0.4em\relax Online: Association for Computational Linguistics, Oct. 2020, pp.
  38--45.

\bibitem{rajapakse2019simpletransformers}
T.~Rajapakse, ``Simple transformers,'' 2019, available at
  \url{https://www.simpletransformers.ai/}. Accessed: 2023-02-12.

\bibitem{pappagari2019hierarchical}
R.~Pappagari, P.~Zelasko, J.~Villalba, Y.~Carmiel, and N.~Dehak, ``Hierarchical
  transformers for long document classification,'' in \emph{2019 IEEE automatic
  speech recognition and understanding workshop (ASRU)}.\hskip 1em plus 0.5em
  minus 0.4em\relax IEEE, 2019, pp. 838--844.

\bibitem{chen2022combating}
C.~Chen, H.~Wang, M.~Shapiro, Y.~Xiao, F.~Wang, and K.~Shu, ``Combating health
  misinformation in social media: Characterization, detection, intervention,
  and open issues,'' 2022.

\bibitem{kumar2018false}
S.~Kumar and N.~Shah, ``False information on web and social media: A survey,''
  2018.

\bibitem{li2022youtube}
H.~O.-Y. Li, E.~Pastukhova, O.~Brandts-Longtin, M.~G. Tan, and M.~G. Kirchhof,
  ``Youtube as a source of misinformation on covid-19 vaccination: a systematic
  analysis,'' \emph{BMJ global health}, vol.~7, no.~3, p. e008334, 2022.

\bibitem{tang2021down}
L.~Tang, K.~Fujimoto, M.~Amith, R.~Cunningham, R.~A. Costantini, F.~York,
  G.~Xiong, J.~A. Boom, and C.~Tao, ``“down the rabbit hole” of vaccine
  misinformation on youtube: Network exposure study,'' \emph{Journal of Medical
  Internet Research}, vol.~23, no.~1, p. e23262, 2021.

\bibitem{srba2023auditing}
I.~Srba, R.~Moro, M.~Tomlein, B.~Pecher, J.~Simko, E.~Stefancova, M.~Kompan,
  A.~Hrckova, J.~Podrouzek, A.~Gavornik \emph{et~al.}, ``Auditing youtube’s
  recommendation algorithm for misinformation filter bubbles,'' \emph{ACM
  Transactions on Recommender Systems}, vol.~1, no.~1, pp. 1--33, 2023.

\bibitem{jagtap2021misinformation}
R.~Jagtap, A.~Kumar, R.~Goel, S.~Sharma, R.~Sharma, and C.~P. George,
  ``Misinformation detection on youtube using video captions,'' 2021.

\bibitem{serrano2020nlp}
J.~C.~M. Serrano, O.~Papakyriakopoulos, and S.~Hegelich, ``Nlp-based feature
  extraction for the detection of covid-19 misinformation videos on youtube,''
  in \emph{Proceedings of the 1st Workshop on NLP for COVID-19 at ACL 2020},
  2020.

\bibitem{papadamou2022just}
K.~Papadamou, S.~Zannettou, J.~Blackburn, E.~De~Cristofaro, G.~Stringhini, and
  M.~Sirivianos, ``“it is just a flu”: Assessing the effect of watch
  history on youtube’s pseudoscientific video recommendations,'' in
  \emph{Proceedings of the international AAAI conference on web and social
  media}, vol.~16, 2022, pp. 723--734.

\bibitem{hou2019towards}
R.~Hou, V.~P{\'e}rez-Rosas, S.~Loeb, and R.~Mihalcea, ``Towards automatic
  detection of misinformation in online medical videos,'' in \emph{2019
  International conference on multimodal interaction}, 2019, pp. 235--243.

\bibitem{hussein2020measuring}
E.~Hussein, P.~Juneja, and T.~Mitra, ``Measuring misinformation in video search
  platforms: An audit study on youtube,'' \emph{Proceedings of the ACM on
  Human-Computer Interaction}, vol.~4, no. CSCW1, pp. 1--27, 2020.

\bibitem{rajdev2015fake}
M.~Rajdev and K.~Lee, ``Fake and spam messages: Detecting misinformation during
  natural disasters on social media,'' in \emph{2015 IEEE/WIC/ACM International
  Conference on Web Intelligence and Intelligent Agent Technology (WI-IAT)},
  vol.~1.\hskip 1em plus 0.5em minus 0.4em\relax IEEE, 2015, pp. 17--20.

\bibitem{ahmed2018detecting}
H.~Ahmed, I.~Traore, and S.~Saad, ``Detecting opinion spams and fake news using
  text classification,'' \emph{Security and Privacy}, vol.~1, no.~1, p.~e9,
  2018.

\bibitem{matthews1975comparison}
B.~W. Matthews, ``Comparison of the predicted and observed secondary structure
  of t4 phage lysozyme,'' \emph{Biochimica et Biophysica Acta (BBA) - Protein
  Structure}, vol. 405, no.~2, pp. 442--451, 1975.

\bibitem{voss2017accuracy}
E.~A. Voss, R.~D. Boyce, P.~B. Ryan, J.~van~der Lei, P.~R. Rijnbeek, and M.~J.
  Schuemie, ``Accuracy of an automated knowledge base for identifying drug
  adverse reactions,'' \emph{Journal of biomedical informatics}, vol.~66, pp.
  72--81, 2017.

\bibitem{powers2020evaluation}
D.~M. Powers, ``Evaluation: from precision, recall and f-measure to roc,
  informedness, markedness and correlation,'' 2020.

\bibitem{halimu2019empirical}
C.~Halimu, A.~Kasem, and S.~S. Newaz, ``Empirical comparison of area under roc
  curve (auc) and mathew correlation coefficient (mcc) for evaluating machine
  learning algorithms on imbalanced datasets for binary classification,'' in
  \emph{Proceedings of the 3rd international conference on machine learning and
  soft computing}, 2019, pp. 1--6.

\bibitem{devlin2018bert}
J.~Devlin, M.-W. Chang, K.~Lee, and K.~Toutanova, ``Bert: Pre-training of deep
  bidirectional transformers for language understanding,'' 2018.

\bibitem{howard2018universal}
J.~Howard and S.~Ruder, ``Universal language model fine-tuning for text
  classification,'' 2018.

\bibitem{tunstall2022efficient}
L.~Tunstall, N.~Reimers, U.~E.~S. Jo, L.~Bates, D.~Korat, M.~Wasserblat, and
  O.~Pereg, ``Efficient few-shot learning without prompts,'' 2022.

\bibitem{reimers2019sentence}
N.~Reimers and I.~Gurevych, ``Sentence-bert: Sentence embeddings using siamese
  bert-networks,'' 2019.

\bibitem{han-etal-2018-fewrel}
X.~Han, H.~Zhu, P.~Yu, Z.~Wang, Y.~Yao, Z.~Liu, and M.~Sun, ``{F}ew{R}el: A
  large-scale supervised few-shot relation classification dataset with
  state-of-the-art evaluation,'' in \emph{Proceedings of the 2018 Conference on
  Empirical Methods in Natural Language Processing}.\hskip 1em plus 0.5em minus
  0.4em\relax Brussels, Belgium: Association for Computational Linguistics,
  Oct.-Nov. 2018.

\end{thebibliography}
