Finding, counting and listing cliques in graphs are fundamental tasks with numerous applications. In any type of network (social, biological, financial, web, maps, etc.) clique listing is used to find patterns such as communities, spam-link farms, motifs, correlated genes and more (see \cite{SchankW05,listingcliqueswww} and the many citations within).

As finding a clique of maximum size has long been known to be NP-hard \cite{Karp72}, the focus in numerous practical works (see \cite{listingcliqueswww,listingcliquesdensest,listingcliquesnucleus,count5via3,trilistlatapy,ChibaN85,SchankW05,ShunT15,ChuC11}) 
is on listing cliques of small size such as triangles and $4$-cliques. 

More generally, in an $n$-node $m$-edge graph, for a constant $k \geq 3$  (independent of $n$ and $m$), we want to find, count or list the $k$-cliques in $G$.
Chiba and Nishizeki \cite{ChibaN85} presented an algorithm that for any constant $k\geq 3$ can list all $k$-cliques in a graph in $O(m\alpha^{k-2})$ time, where $\alpha\leq O(\sqrt{m})$ is the {\em arboricity} of the given graph. This algorithm is among the most efficient clique-listing approaches in practice (see e.g. \cite{listingcliqueswww} and the references within).

Purely in terms of $m$, Chiba and Nishizeki's algorithm runs in $O(m^{k/2})$ time. Since $O(m^{k/2})$ is also the maximum number of $k$-cliques in an $m$-edge graph, this algorithm is optimal, as long as the graph has $\Theta(m^{k/2})$ cliques (e.g. when the graph itself is a clique). However, when the graph has $t$ $k$-cliques, where $t$ is $o(m^{k/2})$, the optimality argument no longer works. In fact, it has been known for almost 40 years \cite{nesetril1985complexity} that when $t=1$, a much faster runtime is possible using fast matrix multiplication.


This motivates the study of {\bf output-sensitive} algorithms for $k$-clique listing: algorithms whose running time depends on the number of $k$-cliques in the output. An even more desirable version of an output-sensitive algorithm is one that can also take as input some parameter $t$, and can list up to $t$ $k$-cliques in the graph. When $t$ is much smaller than the number of $k$-cliques in the graph, such an algorithm could potentially be more efficient. These two versions are actually runtime-equivalent up to logarithmic factors for most natural running times (we provide a proof in Section~\ref{sec:prelim} for completeness). We thus use these  two notions interchangeably. 


Bj{\"o}rklund, Pagh, Vassilevska W. and Zwick \cite{bjorklund2014listing} designed such output-sensitive algorithms for triangle listing with runtime $\tilde{O}(n^{\omega}+n^{\frac{3(\omega-1)}{5-\omega}}t^{\frac{2(3-\omega)}{5-\omega}})$ and $\tilde{O}(m^{\frac{2\omega}{\omega+1}}+m^{\frac{3(\omega-1)}{\omega+1}}t^{\frac{3-\omega}{\omega+1}})$\footnote{We use $\tilde{O}$ to hide polylog factors.}, where $\omega<2.372$~\cite{duan2023, VXXZ24} is the exponent of matrix multiplication and $t$ is the number of triangles listed. If $\omega=2$, the runtimes simplify to $\tilde{O}(n^2+nt^{2/3})$ and $\tilde{O}(m^{4/3}+mt^{1/3})$, and these are shown to be conditionally optimal for any $t= \Omega(n^{1.5})$ and $t= \Omega(m)$ respectively under the popular $3$SUM hypothesis \cite{patrascu2010towards,kopelowitz2016higher} and the even more believable Exact Triangle hypothesis \cite{williams2020monochromatic}. 
There have also been many recent works focusing on output-sensitive cycle-listing algorithms. The works of \cite{abboud2022listing, jin2023removing} show $O(\min\{n^2 + t, m^{4/3} + t\})$ algorithms for listing $t$ 4-cycles, and the work of ~\cite{jin2024listing} shows $\tilde{O}(n^2 + t)$ algorithm for listing $t$ 6-cycles. Moreover, matching conditional lower bounds for $4$-cycle listing were shown under the 3SUM hypothesis~\cite{jin2023removing,abboud2023stronger3sum}, which was subsequently strengthened to hold under the Exact Triangle hypothesis \cite{CX24}. 

While the output-sensitive questions for triangle listing and 4-cycle listing are is well-understood by now, no similar conditionally optimal results are known for $k$-clique listing when $k\geq 4$. 

\begin{question}\label{q2}
    What is the best output-sensitive algorithm for $k$-clique listing for $k>3$? 
\end{question}

When analyzing algorithms, researchers look at a variety of {\bf parameters} to understand performance: the size of the input (typically $n$ and $m$ for graph problems), the size of the output (the number of $k$-cliques), and other natural parameters of the input (e.g. the arboricity, as in \cite{ChibaN85}). In this work, we study clique-listing algorithms parameterized by $\Delta_\ell$, the number of $\ell$-cliques in the graph for $\ell < k$.

To motivate this, let us consider the first non-trivial algorithm for $k$-clique finding by Ne\v{s}etril and Poljak \cite{nesetril1985complexity}.
For simplicity, assume that $k$ is divisible by $3$. First, the algorithm enumerates all $k/3$-cliques in the input graph $G$, and forms a new graph $H$ whose nodes represent the $k/3$-cliques of $G$ and whose edges connect two $k/3$-cliques that together form a $2k/3$-clique. 
The triangles of $H$ correspond to $k$-cliques in $G$, and so Ne\v{s}etril and Poljak reduce $k$-clique finding, counting and listing in $G$ to finding, counting and listing (respectively) of {\em triangles} in $H$\footnote{Note the reduction also works for counting and listing because every $k$-clique is represented by exactly $\binom{k}{k/3,k/3,k/3}$ triangles.}. As there are $O(n^{k/3})$ $k/3$-cliques in $G$, and since triangle finding or counting in $N$-node graphs can be done in $O(N^\omega)$ time \cite{itairodeh}, \cite{nesetril1985complexity} gave an $O(n^{\omega k/3})$ time algorithm for $k$-clique finding or counting in $n$-node graphs.
Eisenbrand and Grandoni \cite{eisenbrand2004complexity} extended Ne\v{s}etril and Poljak's reduction to obtain a $k$-clique runtime of $O(n^{\beta(k)})$ where $\beta(k)=\omega(\lceil{k/3}\rceil, \lceil{(k-1)/3}\rceil, \lfloor{k/3}\rfloor)$, and $\omega(a,b,c)$ is the exponent of multiplying an $n^a\times n^b$ matrix by an $n^b\times n^c$ matrix. As the runtime of $k$-clique detection has remained unchallenged for several decades, the  hypothesis that these algorithms are optimal has been used to provide conditional lower bounds in several works (e.g.~\cite{AbboudBW18,BackursT17,BringmannW17}). Throughout the paper, we consider the word-RAM model of computation with $O(\log n)$ bit words. 

\begin{hypothesis}[$k$-Clique Hypothesis]
\label{hyp:k_clique}
    On a word-RAM model with $O(\log n)$ bit words, detecting a $k$-clique in an $n$-node graph requires $n^{\beta(k) - o(1)}$ time , where $\beta(k)=\omega(\lceil{k/3}\rceil, \lceil{(k-1)/3}\rceil, \lfloor{k/3}\rfloor)$.
\end{hypothesis}

Now, suppose $G$ has a small number $q$ of $k/3$-cliques and suppose we can list these $k/3$-cliques quickly, then Ne\v{s}etril and Poljak's algorithm would run in only $O(q^{\omega})$ additional time which can be much faster than $O(n^{\omega k/3})$.

More generally, if a graph has a small number $\Delta_\ell$ of $\ell$-cliques for $\ell<k$, a simple generalization of Ne\v{s}etril and Poljak's reduction would reduce $k$-clique to $k/\ell$-clique in a graph with $\Delta_\ell$ nodes (assuming $k$ is divisible by $\ell$ for simplicity). If one can list the $\ell$-cliques fast, then $k$-clique finding, listing and detection can all be done faster in graphs with small $\Delta_\ell$.

In other words, for $k$-clique problems, the number of $\ell$-cliques $\Delta_\ell$, where $\ell<k$ is arguably the most natural parameter. The usual input parameters $n$ and $m$ can be viewed as the special cases $\Delta_1$ and $\Delta_2$.
We are not the first to suggest this natural parameterization of the input. In fact, small $\Delta_\ell$ values have been exploited to obtain faster $k$-clique algorithms in experimental algorithmics: e.g., \cite{count5via3} and \cite{osti_1141233} count $k$-cliques faster in graphs with a small number of triangles. Motivated by these practical results, we are the first to consider the following question within theoretical computer science:

\begin{question}\label{q3}
    Can we get a general conditionally optimal algorithms for output-sensitive $k$-clique listing in terms of the number $\Delta_\ell$ of $\ell$-cliques for any $\ell<k$?
\end{question}


\subsection{Our Contributions}
We present a systematic study of clique finding and listing, and provide answers to both Questions \ref{q2} and \ref{q3}. We give the first output-sensitive algorithms for listing $k$-cliques for $k \geq 4$. We also give the first general algorithms for detecting and listing $k$-cliques in terms of the number of $\ell$-cliques, and the first fine-grained lower bounds for the listing problem for general $k$. Our lower bounds show that our algorithms are tight for a non-trivial range of the number of $k$-cliques to output. We summarize our contributions in Table~\ref{tab:contributions}. $\cliquedet{k,\ell}$ and $\cliquelist{k,\ell}$ refer to \emph{detecting} and \emph{listing} $k$-cliques respectively given a list of all $\ell$-cliques. Here, $t$ is the number of $k$-cliques we are asked to list.

\begingroup
\renewcommand{\arraystretch}{1.2} 
    \begin{table}[h]
        \centering
        \scalebox{0.85}{
        \begin{tabular}{p{2.7cm}|c|c}
        &\textbf{Results} & \textbf{References}\\
        \hline 
        \hline 
             \multirow{2}{=}{\textbf{Detection}} & New $\cliquedet{k,\ell}$ framework &  Section~\ref{sec:detection}\\
             & Improved $\cliquedet{4,2}$ and $\cliquedet{5,2}$ & Theorem~\ref{intro:detection-m} \\
             \hline 
             \textbf{Lower bounds} & Conditional lower bounds for $\cliquelist{k,\ell}$ & Theorems~\ref{thm:lb_intro_mn}, \ref{thm:lb_intro}\\
             \hline 
             \multirow{5}{=}{\textbf{Listing}} & Optimal algorithms for $(4,1)$ and $\cliquelist{5,1}$ & Theorems~\ref{thm:4_1_opt}, \ref{thm:5_1_opt}\\
             & Nearly-everywhere optimal algorithms for $(4,\ell)$, $\cliquelist{5,\ell}$ & Theorems~\ref{thm:4_2}, \ref{thm:5_2}\\
             & Optimal $\cliquelist{k,\ell}$ algorithms for large $t$ & Theorems~\ref{thm:intro-k-large-t-listing-mn}, \ref{thm:intro-k-l-large-t-listing}\\
             & Generalized $\cliquelist{k,\ell}$ algorithm for all $t$ & Section~\ref{sec:general-list}\\
             & Refined analysis for $\cliquelist{6,1}$ & Section~\ref{sec:6clique}
        \end{tabular}}
        \caption{Summary of our contributions. $\cliquedet{k,\ell}$ and $\cliquelist{k,\ell}$ refer to \emph{detecting} and \emph{listing} $k$-cliques respectively given a list of all $\ell$-cliques. Here, $t$ is the number of $k$-cliques we are asked to list.}
        \label{tab:contributions}
    \end{table}
\endgroup

\paragraph{Improved 4 and 5-clique detection in sparse graphs.}
We provide a general algorithmic framework for detecting cliques. 
As special cases of the framework, we give the first improvement over the
the runtime of Eisenbrand and Grandoni \cite{eisenbrand2004complexity} for $4$ and $5$-clique detection in sparse graphs (we show this in Examples~\ref{ex:clique-det-4-2} and \ref{ex:clique-det-5-2} in Section~\ref{sec:detection_examples}). 


 \begin{theorem}\label{intro:detection-m}
     There is an $O(m^{1.657})$ time algorithm for 4-clique detection and an $O(m^{2.057})$ time algorithm for 5-clique detection in $m$-edge graphs.
 \end{theorem}
We compare the explicit values of~\cite{eisenbrand2004complexity}'s exponent and our improved exponents in Table~\ref{table:improved_det_4_5} in terms of the current bounds for square and rectangular matrix multiplication \cite{VXXZ24}. 
    
    \begin{table}[ht]
        \centering
        \begin{tabular}{c|c|c}
         $k$ &  Previous exponent \cite{eisenbrand2004complexity} & Our exponent (Theorem~\ref{intro:detection-m})\\
         \hline 
         4 & 1.668 & 1.657\\
         5 & 2.096 & 2.057
        \end{tabular}
        \caption{The table contains exponents $c$ such that $4$ and $5$-clique detection is in $O(m^c)$ time. For $\cliquedet{4, 2}$ and $\cliquedet{5, 2}$, the previous exponent was given by $\beta(k) \cdot \beta(k-1)/(\beta(k) + \beta(k-1) - 1)$ \cite{eisenbrand2004complexity}, where $\beta(k)$ is the exponent of $k$-clique detection (as in Hypothesis~\ref{hyp:k_clique}). We give the runtime of their algorithm with the current bounds on square and rectangular matrix multiplication \cite{VXXZ24}. }\label{table:improved_det_4_5}
    \end{table}

\paragraph{Lower bounds for $k$-clique listing.}
Prior works \cite{patrascu2010towards,kopelowitz2016higher,williams2020monochromatic} give fine-grained lower bounds for listing triangles in an $n$-node, $m$-edge graph: triangle-listing requires $n^{1-o(1)}t^{2/3}$ time in $n$-node graphs, and requires $m^{1-o(1)}t^{1/3}$ in $m$-edge graphs time, under standard fine-grained hypotheses. The lower bounds imply tightness of the known algorithms \cite{bjorklund2014listing}  if $t$ is large enough: $t= \Omega(n^{1.5})$ or $t= \Omega(m)$ respectively.

The lower bounds of \cite{patrascu2010towards,kopelowitz2016higher} are under the $3$SUM hypothesis. 
Extending these to lower bounds for $k$-clique listing seems difficult. Instead we focus on the approach of \cite{williams2020monochromatic} who showed hardness under the Exact-Triangle hypothesis which states that finding a triangle of weight sum 0 in an $n$-node edge-weighted graph requires $n^{3-o(1)}$ time in the word-RAM model. The Exact-Triangle hypothesis is one of the most believable hypotheses in fine-grained complexity, as it is implied by both the $3$SUM hypothesis and the APSP hypothesis (see \cite{vsurvey}).

A natural generalization of the Exact-Triangle hypothesis is the Exact-$k$-Clique hypothesis (which coincides with the Exact-Triangle hypothesis for $k=3$):

\begin{hypothesis}[Exact-$k$-Clique hypothesis]\label{hyp:exact_k_clique}
For a constant $k\geq 3$, let $\exactclique{k}$ be the problem that given an $n$-node graph with edge weights in $\{-n^{100k},\dots, n^{100k}\}$, asks to determine whether the graph contains a $k$-clique whose edges sum to $0$.
Then, $\exactclique{k}$ requires $n^{k-o(1)}$ time, on the word-RAM model of computation with $O(\log n)$ bit words. 
\end{hypothesis}

The Exact-$k$-Clique hypothesis is among the popular hardness hypotheses in fine-grained complexity.
Most recently, it has been used to give hardness for the Orthogonal Vectors problem in moderate dimensions \cite{abboud2018more} and join queries in databases \cite{BringmannCM22}. Moreover, due to known reductions  (see e.g. \cite{vsurvey}), the Exact-$k$-Clique hypothesis is at least as believable as  the Max-Weight-$k$-Clique hypothesis which is used in many previous papers (e.g. \cite{AbboudWW14,BackursDT16,BackursT17,LincolnWW18,BringmannGMW20}). 

Under the Exact-$k$-Clique hypothesis we prove lower bounds for $k$-clique listing for all $k \geq 3$. These are the first lower bounds for output-sensitive clique listing for $k \geq 4$.


\begin{theorem}\label{thm:lb_intro_mn}
    For any $k \ge 3$, and $\gamma \in [0, k]$, listing $t$ $k$-cliques in a graph with $n$ vertices, and in a graph with $m$ nodes requires 
    \[
        \left(n^{\frac{2}{k-1}}t^{1-\frac{2}{k(k-1)}}\right)^{1-o(1)} \quad\text{and} \quad\left(m^{\frac{1}{k-2}}t^{1 - \frac{2}{k(k-2)}}\right)^{1-o(1)}
    \]
    time respectively under the Exact-$k$-Clique hypothesis. 
\end{theorem}
This is a special case of Theorem~\ref{thm:lower_bound} in the main body. 
For $k=3$ this is the same lower bound as previously proven \cite{patrascu2010towards,kopelowitz2016higher, williams2020monochromatic}.
Shortly, we will present algorithms that match our lower bound for all $k,m,n$ and for large $t$ if $\omega =2$, implying that our lower bound is tight. This is in fact {\bf the first output-sensitive lower bound} for $k$-clique listing problems for $k \geq 4$, and the first such lower bound for {\em any } graph pattern of size at least 5. 

\paragraph{Optimal algorithms for 4 and 5-clique listing.} For the special cases of $k = 4, 5$, we give algorithms parametrized by the number of vertices $n$ and number of $k$-cliques $t$ which are  conditionally {\bf optimal} if $\omega = 2$. We prove these results in Corollary~\ref{cor:4-1-opt} and Corollary~\ref{cor:5_1_opt}.

Similar to \cite{bjorklund2014listing}, we state our runtimes in terms of $\omega$. %
In our analysis, we compute rectangular matrix multiplication by truncating it to multiple instances of square matrix multiplication. If one is interested in better numerical values, one could instead use the best upper bound on rectangular matrix multiplication \cite{VXXZ24} in these steps.

\begin{theorem}\label{thm:4_1_opt}
    Given a graph on $n$ nodes, one can list $t$ 4-cliques in $$\tilde{O}\left(n^{\omega + 1} + n^{\frac{4(\omega - 1)(2\omega - 3)}{\omega^2 - 5 \omega + 12}}t^{1 - \frac{(\omega - 1)(2\omega - 3)}{\omega^2 - 5 \omega + 12}}\right)$$ time. If $\omega = 2$, the runtime is $\tilde{O}(n^3 + n^{2/3}t^{5/6}).$
\end{theorem}

Recall that the $4$-Clique hypothesis, which is a special case of  Hypothesis~\ref{hyp:k_clique} when $k = 4$, gives a lower bound of $n^{3-o(1)}$ if $\omega = 2$. Moreover, Theorem~\ref{thm:lb_intro_mn} gives a lower bound of $(n^{2/3}t^{5/6})^{1-o(1)}$. Therefore, this $4$-clique listing algorithm is indeed conditionally optimal.

\begin{theorem}\label{thm:5_1_opt}
    Given a graph on $n$ nodes, one can list $t$ 5-cliques in $$\tilde{O}\left(n^{\omega + 2} + n^{\frac{5(\omega - 1)(2\omega - 3)(3\omega - 5)}{48-47\omega + 16\omega^2 - \omega^3}}t^{1 - \frac{(\omega - 1)(2\omega - 3)(3\omega - 5)}{48-47\omega + 16\omega^2 - \omega^3}}\right)$$
    time. If $\omega = 2$, the runtime is $\tilde{O}(n^4 +n^{1/2}t^{9/10}).$
\end{theorem}
Recall that the 5-Clique hypothesis from Hypothesis~\ref{hyp:k_clique} gives us a lower bound of $n^{4-o(1)}$ if $\omega = 2$. Moreover,  Theorem~\ref{thm:lb_intro_mn} gives a lower bound of $(n^{1/2}t^{9/10})^{1-o(1)}$. Therefore, this $5$-clique listing algorithm is also conditionally optimal. 

\paragraph{Nearly-everywhere optimal algorithms for 4 and 5-clique listing in sparse graphs.} 
In the case of sparse graphs, we obtain conditionally optimal runtimes for $4$ and $5$-clique listing for almost all values of $t$ if $\omega = 2.$ The runtimes are stated in the following theorems and are pictorially depicted in Figure~\ref{fig:4_5_sparse_runtime}.

% Figure environment removed

\begin{theorem}\label{thm:4_2}
    If $\omega = 2$, one can list $t$ 4-cliques in a graph with $m$ edges in time
    \begin{align*}
        \begin{cases}
                \tilde{O}(m^{3/2}) & \text{if $t \leq m^{5/4}$},\\
                \tilde{O}(mt^{2/5})& \text{if $m^{5/4}\leq t \leq m^{10/7}$},\\
                \tilde{O}(m^{1/2}t^{3/4}) & \text{if $t \geq m^{10/7}$}.
        \end{cases}
    \end{align*}
\end{theorem}
This algorithm matches the lower bound in Hypothesis~\ref{hyp:k_clique} when $t \leq m^{5/4}$, and it matches our lower bound of Theorem~\ref{thm:lb_intro_mn} when $t \geq m^{10/7}$.

\begin{theorem}\label{thm:5_2}
    If $\omega = 2$, one can list $t$ 5-cliques in a graph with $m$ edges in time
    \begin{align*}
        \begin{cases}
                \tilde{O}(m^{2}) & \text{if $t \leq m^{19/10}$},\\
                \tilde{O}(m^{17/18}t^{10/18}) & \text{if $m^{19/10}\leq t \leq m^{55/28}$},\\
                \tilde{O}(m^{1/3}t^{13/15}) & \text{if $t \geq m^{55/28}$}.
        \end{cases}
    \end{align*}
\end{theorem} 

 This algorithm matches the runtime of the lower bound in Hypothesis~\ref{hyp:k_clique} when $t \leq m^{19/10}$, and it matches our lower bound from Theorem~\ref{thm:lb_intro_mn} when $t \geq m^{55/28}$.

Theorem~\ref{thm:4_2} and Theorem~\ref{thm:5_2} are proved in Section~\ref{sec:4_5_l_listing}.

\paragraph{Optimal algorithms for listing many $k$-cliques.} More generally, we consider the problem of listing $k$-cliques for $k \geq 3$. For instance, consider the problem of listing 6-cliques in sparse graphs with $m$ edges. If we adapt the existing approach for $k$-clique detection~\cite{nesetril1985complexity, eisenbrand2004complexity} and directly reduce it to triangle listing in a graph with $m$ nodes and then use \cite{bjorklund2014listing}, we get an $\tO(m^2+mt^{2/3})$ runtime when $\omega = 2$. In comparison, the lower bound from Theorem~\ref{thm:lb_intro} is $(m^{1/4}t^{11/12})^{1-o(1)}$. When $t$ is close to maximum (as $t \to O(m^3)$), the $\tO(m^2+mt^{2/3})$ runtime is polynomially higher than the lower bound. Therefore, we cannot only rely on such reductions. 
    
Nevertheless, we give a conditionally {\em tight} algorithm for graphs with many $k$-cliques, provided that $\omega=2$ for sufficiently large number of cliques. In particular, the runtime of the algorithm in the theorem below matches the lower bound of Theorem~\ref{thm:lb_intro_mn}. 

\begin{theorem}[Informal]
    \label{thm:intro-k-large-t-listing-mn}
    If $\omega = 2$, 
    there is an algorithm for $k$-clique listing  which runs in time 
        \[ \tilde{O}\left(\min\left\{n^{\frac{2}{k-1}} t^{1 - \frac{2}{k(k-1)}}, m^{\frac{1}{k-2}}t^{1 - \frac{2}{k(k-2)}}\right\}\right)\]
    when $t$ is large. 
\end{theorem}
We give more explicit bounds on $t$ and the runtimes in terms of $\omega$ in Sections~\ref{sec:k_1_opt} and \ref{sec:k_l_opt}. In other words, we have an algorithm which \textbf{match the lower bound} in Theorem~\ref{thm:lb_intro_mn} for graphs with many $k$-cliques. 


\paragraph{General listing algorithm for all $t$.} 
In Section~\ref{sec:general-list}, we give a general black-box approach (by non-trivially adapting previous reductions \cite{nesetril1985complexity, eisenbrand2004complexity}) that uses our (conditionally) optimal algorithm for a large number of $k$-cliques $t$ to obtain a fast algorithm that works for {\em all} $t$. The main advantage of this approach is its simplicity and generality. In particular, we obtain an intuitive and simple analysis of the runtime for all $k,t$. In Section~\ref{sec:general-list}, we show a comparison of our lower bounds and the runtime of our general algorithm in some examples. We illustrate the runtime of the general algorithm for some specific cases in Figure~\ref{fig:general_examples}. 
% Figure environment removed

\paragraph{Improved algorithm for 6-clique listing.} We note that our generic algorithm trades simplicity for optimality, and it is not always the best algorithm one can obtain for fixed $k$. 

In Section~\ref{sec:6clique}, we give a more refined algorithm for 6-clique listing in terms of $n$ and $t$ if $\omega = 2$ to illustrate how one might obtain a tighter runtime bound for specific $k$. In Figure~\ref{fig:6_1}, we compare our ``general'' bound, our best bound and our lower bounds to illustrate the improvement in the algorithm. However, since the number of terms and parameters in the runtime increases significantly with $k$, we do not do this refined analysis for all $k$.
 % Figure environment removed

\paragraph{Listing cliques from smaller cliques.} In fact, our frameworks are much more general and it extends to the problems of finding and listing $k$-cliques given a list of all $\ell$-cliques in the graph, for $\ell \geq 1$. We use the notation $\Delta_\ell$ to denote the number of $\ell$-cliques in the graph.

Let $\cliquedet{k, \ell}$ be the problem of detecting a $k$-clique in a graph $G$, given the list of all $\ell$-cliques in the graph for some $\ell\in \{1,\ldots,k-1\}$. Our framework applies to $\cliquedet{k, \ell}$ for any $k \ge 3, 1 \le \ell < k$. We note that while we only mention $k$-clique detection, we can use well-known techniques to also find $k$-cliques in the same runtime up to a log factor (see Section~\ref{sec:prelim:basic}). Moreover, our algorithm can also be used to count the number of cliques with the same runtime. 





In Table~\ref{tab:detection_runtime} we present the exponents of our runtimes for $\cliquedet{k, \ell}$ for small values of $k$ and $\ell$ assuming $\omega = 2$. See Table~\ref{tab:det_exponent} for the runtime in terms of the current bound on $\omega$. 
For $\ell = 1$, we captures the best known $k$-clique detection algorithm and hence matches Hypothesis~\ref{hyp:k_clique}.
Although our general framework is simple, it is actually quite powerful, and allows us to obtain the first improvement in almost 20 years over the runtime of Eisenbrand and Grandoni \cite{eisenbrand2004complexity}, as discussed in Theorem~\ref{intro:detection-m}. 

\begin{table}[ht]
\centering 
\begin{tabular}{c|c|c|c|c|c|c|c|c|c|c}
     \backslashbox{$\ell$}{$k$} & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10 & 11 & 12 \\
     \hline 
     1 & 2 & 3 & 4 & 4 & 5 & 6 & 6 & 7 & 8 & 8\\
     2 & 4/3 & 3/2 & 2 & 2 & 5/2 & 3 & 3 & 7/2 & 4 & 4\\
     3 & - & 6/5 & 4/3 & 3/2 & 7/4 & 2 & 2 & 7/3 & 8/3 & 8/3\\
     4 & - & - & 8/7 & 6/5 & 7/5 & 3/2 & 8/5 & 9/5 & 2 & 2\\
     5 & - & - & - & 12/11 & 7/6 & 9/7 & 4/3 & 3/2 & 5/3 & 12/7
\end{tabular}
\caption{Our $\cliquedet{k, \ell}$ exponents if $\omega = 2$. The $(k, \ell)$th entry corresponds to the exponent $\alpha$ such that the runtime to detect a $k$-clique is $\tilde{O}(\Delta_\ell^\alpha)$, where $\Delta_\ell$ is the number of $\ell$-cliques. }
\label{tab:detection_runtime}
\end{table}





    
    


    
    

    




Let $\cliquelist{k, \ell}$ be the problem of listing all $k$-cliques in a graph $G$, given all the $\ell$-cliques of $G$. Equivalently, it is the problem of listing $t$ $k$-cliques in a graph given all the $\ell$-cliques, where $t$ is an input to the problem (see a proof in Section~\ref{sec:prelim}). 

Under the Exact-$k$-Clique hypothesis we prove  lower bounds for $\cliquelist{k, \ell}$ for \emph{all} $k\geq 3, 1\leq \ell<k$. This is Theorem~\ref{thm:lower_bound} in the main body. In fact, Theorem~\ref{thm:lb_intro_mn} is a special case of this theorem. 

\begin{theorem}\label{thm:lb_intro} 
For any $k \ge 3, 1 \le \ell < k$, and $\gamma \in [0, k/\ell]$, $\cliquelist{k, \ell}$ in a graph with $\Delta_\ell$ given $\ell$-cliques and $t = \tilde{\Theta}(\Delta_\ell^\gamma)$ $k$-cliques requires
$$\left(\Delta_\ell^{\frac{2}{\ell(k-\ell)}} t^{1 - \frac{2}{k(k-\ell)}}\right)^{1-o(1)}$$ time under the  Exact-$k$-Clique hypothesis.
\end{theorem}

Moreover, we give a conditionally {\em tight} algorithm for graphs with many $k$-cliques, provided that $\omega=2$. In particular, the runtime of the algorithm in the theorem below matches the lower bound of Theorem~\ref{thm:lb_intro}. 

    \begin{theorem}[Informal]
    \label{thm:intro-k-l-large-t-listing}
    If $\omega = 2$, 
    there exists an algorithm for $\cliquelist{k, \ell}$ which runs in time $$\tilde{O}\left(\Delta_\ell^{\frac{2}{\ell(k-\ell)}}\Delta_k^{1 - \frac{2}{k(k-\ell)}}\right)$$ for $\Delta_k \geq \Delta_\ell^{\gamma_{k, \ell}}$ where
    $\gamma_{k, \ell} = \frac{k(k^2 - 2k - 1)}{\ell(k^2 - k - \ell - 1)}.$
    \end{theorem}
Theorem~\ref{thm:intro-k-large-t-listing-mn} is a special case of this theorem.

\subsection{Our Techniques}
In this section, we highlight our main techniques used in the  algorithms and lower bounds. 
\paragraph{Detection algorithms.} 
The previous algorithms for $k$-clique detection in $n$-node graphs \cite{nesetril1985complexity, eisenbrand2004complexity} can be viewed as reductions to triangle detection, as mentioned earlier. Here is how they work  when $k$ is not necessarily divisible by $3$. For some integers $a, b, c \in [1, k]$ where $a+b+c = k$, the algorithm creates a tripartite graph on node parts $A, B, C$ with $n^a, n^b, n^c$ nodes respectively, which represent tuples of $a, b, c$ nodes respectively. It also suffices to keep only the tuples of nodes that form a clique in the original graph. For every node $(u_1, \ldots, u_a) \in A$ and every node $(v_1, \ldots, v_b) \in B$, the algorithm adds an edge between them if and only if $u_1, \ldots, u_a, v_1, \ldots, v_b$ form an $(a+b)$-clique in the original graph. It similarly adds edges between $B, C$ and between $A, C$. It is not difficult to see that there is a triangle in the new graph if and only if there is a $k$-clique in the original graph, so we can simply detect triangles by multiplying an $|A| \times |B|$ matrix with a $|B| \times |C|$ matrix. 

We generalize this approach to $k$-clique detection in terms of the number of $\ell$-cliques for $\ell < k$.

Suppose we are given a list of all $\ell$-cliques in the graph, and we want to find a $k$-clique. Let $a, b, c \in [1, k]$ be as before where $a+b+c = k$.
Let $A$, $B$, and $C$, respectively, be the sets of $a$-, $b$- and $c$-cliques in the graph. We would like to bound their sizes in terms of $\Delta_\ell$. Let us focus on bounding $|A|$; bounding $|B|,|C|$ is done similarly.

For $a \ge \ell$, a (probably folklore) bound shows that $\Delta_a \le O(\Delta_\ell^{a / \ell})$ (we also provide a proof for completeness in Section~\ref{sec:prelim}). 

For $a < \ell$, we set a parameter $\Lambda$ and consider two types of $a$-cliques: ``low-degree" ones that are contained in $<\Lambda$ $\ell$-cliques, and ``high-degree'' ones that are contained in $\geq \Lambda$ $\ell$-cliques. There are at most $O(\Delta_\ell/\Lambda)$ high-degree $a$-cliques.

Consider a low-degree $a$-clique $K$ and its neighborhood consisting of the nodes adjacent to all nodes of $K$. We can {\em recurse} on the neighborhood: find a $(k-a)$-clique, given the list of $(\ell - a)$-cliques formed by excluding $K$ from all $\ell$-cliques that contain $K$. 
We can bound the recursion runtime using the fact that $K$ has low degree. Since we have handled all low-degree $a$-cliques, we can set $A$ to be only the $O(\Delta_\ell/\Lambda)$ high-degree $a$-cliques. Similarly, we can get bounds on $|B|$ and $|C|$.

Finally, following previous $k$-clique detection algorithms \cite{nesetril1985complexity, eisenbrand2004complexity}, we perform a rectangular matrix multiplication between an $|A| \times |B|$ matrix and a $|B| \times |C|$ matrix. By analyzing the recursive steps and setting parameters appropriately, we obtain our detection runtimes. As we show in Examples \ref{ex:clique-det-4-2} and \ref{ex:clique-det-5-2}, our recursion and its analysis are more careful than in prior work, allowing us to obtain improved runtimes for $4$ and $5$-clique detection.

We give some explicit examples of this algorithm in Section~\ref{sec:detection_examples}. We also analyze the asymptotic efficiency of this algorithm in Section~\ref{sec:k-h_detect_bound} and Section~\ref{sec:Cl_l_detectionbound}.


\paragraph{Lower bounds for listing.} 
We obtain our lower bound in Theorem~\ref{thm:lb_intro} for listing from the Exact-$k$-Clique hypothesis. Our lower bound technique can be seen as a generalization of the reduction from Exact Triangle to triangle listing problems in \cite{williams2020monochromatic}. 

We note that there is also a different generalization of the technique of \cite{williams2020monochromatic} that shows a conditional lower bound for the $k$-Set-Intersection problem~\cite{BringmannCM22}. We briefly describe the problem. 
{At a very high level, the lower bound of~\cite{BringmannCM22} applies to the following hypergraph problem: the nodes are partitioned into $k+1$ parts: $V_1, \ldots, V_{k}$ (these correspond to the sets) and $U$ (this corresponds to the universe). There are hyperedges among the nodes in $V_1, \ldots, V_{k}$ (corresponding to $k$-set-intersection queries) and there are edges between $U$ and $V_i$ for $i\in [k]$ (corresponding to elements belonging to each set). Given this hypergraph, the problem asks for each hyperedge, whether its nodes share a common neighbor in $U$ (i.e., whether the sets intersect). As the lower bound of ~\cite{BringmannCM22} is for a problem in a hypergraph with hyperedges of cardinality $>2$, it does not directly apply to our applications. Hypergraph problems are generally harder than their graph counterparts (see e.g. \cite{LincolnWW18}), and there is no easy way to convert a hardness proof for hypergraphs into one for graphs without increasing the instance size significantly. }

Now, we describe the high-level ideas of our reduction.
Without loss of generality, we can assume the input instance of Exact-$k$-Clique is a $k$-partite graph on nodes $V_1 \sqcup \cdots \sqcup V_k$, where each $V_i$ contains $n$ nodes. 
At a high level, we first hash the edge weights so that they behave random enough. For simplicity, we assume all edge weights are independently uniformly at random from $[-n^k, n^k]$ in this overview (we deal with the randomness properly in our proof). Then we split $[-n^k, n^k]$ equally into $s$ contiguous intervals, each of size $O(n^k / s)$ for some parameter $s$. We then enumerate combinations of intervals $(L_{i,j})_{1 \le i < j \le k}$, and consider the subgraph where we only keep edges between $V_i$ and $V_j$ whose weight is in $L_{i, j}$. Note that a subgraph cannot contain a $k$-clique of weight $0$ if $0 \not \in \sum_{1 \le i < j \le k} L_{i, j}$ (we denote the sum of two intervals as the sumset of them). Therefore, we only need to consider combinations of intervals where $0 \in \sum_{1 \le i < j \le k} L_{i, j}$. If we  choose the first $\binom{k}{2}-1$ intervals $(L_{i,j})_{1 \le i < j \le k, (i, j) \ne (k-1, k)}$, the final interval must intersect $-\sum_{1 \le i < j \le k, (i, j) \ne (k-1, k)} L_{i, j}$, which has size $O(\frac{n^k}{s})$. Therefore, there are only $O(1)$ choices for the final interval, and the total number of combinations of intervals we need to consider is $O(s^{\binom{k}{2}-1})$. 

For each combination of intervals, we form the subgraph only containing edges with weights in the intervals, and we list all the $k$-cliques in this subgraph. The expected number of $\ell$-cliques in the subgraph is $O(n^\ell / s^{\binom{\ell}{2}})$ and the expected number of $k$-cliques is $O(n^k / s^{\binom{k}{2}})$. For simplicity, we assume these upper bounds always hold in this overview (instead of only holding in expectation). Also, we can list all the $\ell$-cliques in the subgraphs efficiently, i.e., in nearly linear time in their number, which is faster than $n^k$ when $s$ is small enough. 

Then suppose we have an $O\left(\left( \Delta_\ell^{\frac{2}{\ell(k-\ell)}} t^{1-\frac{2}{k(k-\ell)}}\right)^{1-\epsilon}\right)$ time algorithm for listing all $k$-cliques in a graph with $t$ $k$-cliques and with a given list of $\Delta_\ell$ $\ell$-cliques. We can list all $k$-cliques in all the subgraphs in time
$$\tO\left(s^{\binom{k}{2}-1} \left( \left(n^\ell / s^{\binom{\ell}{2}}\right)^{\frac{2}{\ell(k-\ell)}} \left(n^k / s^{\binom{k}{2}}\right)^{1-\frac{2}{k(k-\ell)}}\right)^{1-\epsilon}\right)=\tO\left(n^{k-k\epsilon} \left(s^{\binom{k}{2}-1}\right)^{\epsilon}\right),$$
which is $\tilde{O}(n^{k-\epsilon'})$ time for  $\epsilon'>0$ for sufficiently small $s$, and  violates the Exact-$k$-Clique hypothesis. 

\paragraph{Listing algorithms for graphs with a large number $t$ of $k$-cliques.} 
Here we discuss how we obtain our optimal algorithm  for $\cliquelist{k, \ell}$ in Theorem~\ref{thm:intro-k-l-large-t-listing}, for all $\ell < k$ and large enough $t$. We give the full algorithm in Section~\ref{sec:upper-bound}. The framework works for all values of $t$, but the runtime is conditionally optimal only for large $t$. We will later explain how to improve upon the framework for small $t$.



As a first step, we obtain output-sensitive algorithms for $k$-clique listing in terms of $n$ ($\ell=1$). We then use these algorithms in a black-box way for $\ell\geq 2$. 

Bj\"{o}rklund, Pagh,  Vassilevska W. and Zwick~\cite{bjorklund2014listing} gave an algorithm for triangle listing using a  \textit{dense-sparse} paradigm. We generalize this algorithm to  $k \geq 4$. Let $t$ be the number of $k$-cliques in the graph which we want to list.


\begin{itemize}
    \item \textbf{Dense algorithm:} When the input graph has many edges, we use sampling and rectangular matrix multiplication to find all the edges that occur in at most $\lambda$ $k$-cliques, for some parameter $\lambda$. We then list all $k$-cliques incident to such edges, and can then delete these edges to obtain a graph with at most $O(t/\lambda)$ edges. We then call the algorithm for sparse graphs.
    \item \textbf{Sparse algorithm:} When the input graph has few edges, we list all $k$-cliques incident to nodes with degree at most $x$ by {\em listing} $(k-1)$-cliques in their neighborhoods, for some parameter $x$. We are then left with a graph with at most $O(m/x)$ nodes, at which point we call the dense algorithm.
\end{itemize}

The key change from the framework of \cite{bjorklund2014listing} is in the sparse algorithm.
There, \cite{bjorklund2014listing} uses brute-force to list triangles through low-degree nodes. We on the other hand, recursively use $\cliquelist{k-1, 1}$ algorithms to list the $(k-1)$-cliques in the neighborhoods of low-degree nodes. This makes our algorithm efficient, but also complicates the analysis significantly. 


For $\ell \geq 2$, we exploit recursion even more:
we
recursively use algorithms for both $k$-clique listing in terms of nodes, and $(k-1)$-clique listing in terms of $(\ell-1)$-cliques. At a high level, we first find all nodes that are contained in at most $y$ $\ell$-cliques, for some parameter $y$. Then, in the neighborhoods of such nodes, we can find all $(k-1)$-cliques based on the list of all $(\ell-1)$-cliques in the neighborhood. We can then delete all the low-degree nodes. The resulting graph now only has $O(\Delta_\ell/y)$ nodes. Now, we can call the $k$-clique listing algorithm in terms of $n$.

Because of the extra recursion, the analysis gets more complicated, but we are able to keep the algorithms relatively simple. Thus we get the best of both worlds: simplicity and optimality (at least for large $t$).


The reason why our $\cliquelist{k, 1}$ algorithm is only optimal for large $t$ is that our dense algorithm has an inherent cost of $\Omega(n^{k-1})$ due to the rectangular matrix multiplication that we use. This bottleneck extends to $\cliquelist{k, \ell}$ for all $\ell$ as well since all of these algorithms call $\cliquelist{k, 1}$.


\paragraph{Generalizing the listing algorithm to all values of $t$.}
In Section~\ref{sec:general-list}, we explain how to improve upon our listing framework above when $t$ is smaller. While our general runtime analysis for arbitrary $k,t$ and $\ell$ quickly gets complicated, here we will focus on a small example, to give intuition.

Let us  consider the example of $6$-clique listing in an $n$-node graph $G$ assuming $\omega = 2$. The algorithm in Theorem~\ref{thm:intro-k-l-large-t-listing}  has runtime $\tO(n^{\frac{2}{5}}t^{\frac{14}{15}})$ only when $t \geq n^{4+\frac{13}{14}}$, and otherwise runs in $\tO(n^5)$ time\footnote{Clearly, when $t$ is smaller, the runtime  can only be smaller or equal, so for any $t < n^{4+\frac{13}{14}}$, the runtime of this algorithm is $\tO(n^{\frac{2}{5}}(n^{4+\frac{13}{14}})^{\frac{14}{15}}) = \tO(n^5)$ when $\omega = 2$. } which is worse than the $6$-clique detection runtime $\tO(n^4)$. 

We improve the runtime for $t$ smaller than the threshold of $ n^{4+\frac{13}{14}}$ by instead following the techniques of \cite{nesetril1985complexity, eisenbrand2004complexity}. We create a new graph $G'$ whose nodes correspond to the pairs of nodes of the original graph $G$, i.e. the new graph has $n^2$ nodes. We then add an edge between two nodes $(a, b)$ and $(c, d)$ if  $(a, b, c, d)$ forms a $4$-clique in the original graph.
Now, we run the triangle listing algorithm (in~\cite{bjorklund2014listing} or Theorem~\ref{thm:intro-k-l-large-t-listing}) in the new graph. This has runtime $\tO(n^2t^{2/3})$ when $t \ge (n^2)^{1.5} = n^3$. This also allows us to obtain an algorithm for all $t\leq n^3$, running in time $\tO(n^4)$, the  $6$-clique detection runtime, which is tight under Hypothesis~\ref{hyp:k_clique}.


The corresponding runtime is depicted in blue in Figure~\ref{fig:6_1}.


More generally, for larger $k$, we  create a new graph where the nodes represent $\ell'$-cliques in the original graph. Then, we list $\lceil k/\ell' \rceil$-cliques in the new graph. The best $\ell'$ varies for different $t$, and this gives us the trade-offs as seen in Figure~\ref{fig:general_examples}.

Roughly speaking, the algorithm can be viewed as using different dimensions of rectangular matrix multiplication depending on the value of $t$. For example, in the case of $k = 6$, the algorithm for large $t \geq n^{4 + \frac{13}{14}}$ uses $\tilde{O}(\lambda)$ matrix multiplications of size roughly $n \times n^4/\lambda$ by $n^4/\lambda \times n$ for some parameter $\lambda \geq 1$, and this requires at least $\Omega(n^{5})$ time. For $n^3 \le t \leq n^{4 + \frac{13}{14}}$, the algorithm uses $\tilde{O}(\rho)$ matrix multiplications of size $n^2 \times n^2/\rho$ by $n^2/\rho \times n^2$ for some parameter $\rho \geq 1$, which requires at least $\Omega(n^4)$ time. 

\subsection{Organization} 

In Section~\ref{sec:prelim}, we give necessary definitions and standard algorithms. In Section~\ref{sec:detection}, we show our framework for detecting cliques. In Section~\ref{sec:lower_bounds}, we show our lower bound for listing cliques, proving Theorem~\ref{thm:lb_intro}. In Section~\ref{sec:upper-bound}, we show our optimal algorithm for clique listing in graphs with many $k$-cliques, and we extend this algorithm to graphs with fewer $k$-cliques in Section~\ref{sec:general-list}. Finally, we show a more efficient algorithm for $6$-clique listing in Section~\ref{sec:6clique}.
