\begin{thebibliography}{29}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Breyer et~al.(2020)Breyer, Chung, Ott, Siegwart, and
  Nieto]{BreyerCOSN20}
M.~Breyer, J.~J. Chung, L.~Ott, R.~Siegwart, and J.~I. Nieto.
\newblock Volumetric grasping network: Real-time 6 {DOF} grasp detection in
  clutter.
\newblock In \emph{CoRL}, volume 155, pages 1602--1611. {PMLR}, 2020.

\bibitem[Cao et~al.(2021)Cao, Fang, Liu, and Lu]{cao2021suctionnet}
H.~Cao, H.-S. Fang, W.~Liu, and C.~Lu.
\newblock Suctionnet-1billion: A large-scale benchmark for suction grasping.
\newblock \emph{IEEE RA-L}, 6\penalty0 (4):\penalty0 8718--8725, 2021.

\bibitem[Correll et~al.(2016)Correll, Bekris, Berenson, Brock, Causo, Hauser,
  Okada, Rodriguez, Romano, and Wurman]{correll2016analysis}
N.~Correll, K.~E. Bekris, D.~Berenson, O.~Brock, A.~Causo, K.~Hauser, K.~Okada,
  A.~Rodriguez, J.~M. Romano, and P.~R. Wurman.
\newblock Analysis and observations from the first amazon picking challenge.
\newblock \emph{{IEEE} {T-ASE}}, 15\penalty0 (1):\penalty0 172--188, 2016.

\bibitem[Fang et~al.(2020)Fang, Wang, Gou, and Lu]{fang2020graspnet}
H.-S. Fang, C.~Wang, M.~Gou, and C.~Lu.
\newblock Graspnet-1billion: A large-scale benchmark for general object
  grasping.
\newblock In \emph{{IEEE} {CVPR}}, pages 11444--11453, 2020.

\bibitem[He et~al.(2016)He, Zhang, Ren, and Sun]{he2016deep}
K.~He, X.~Zhang, S.~Ren, and J.~Sun.
\newblock Deep residual learning for image recognition.
\newblock In \emph{{IEEE} {CVPR}}, pages 770--778, 2016.

\bibitem[Hernandez et~al.(2016)Hernandez, Bharatheesha, Ko, Gaiser, Tan,
  Deurzen, Vries, Mil, Egmond, Burger, et~al.]{hernandez2016team}
C.~Hernandez, M.~Bharatheesha, W.~Ko, H.~Gaiser, J.~Tan, K.~van Deurzen, M.~de
  Vries, B.~van Mil, J.~van Egmond, R.~Burger, et~al.
\newblock Team delft\'s robot winner of the amazon picking challenge 2016.
\newblock In \emph{Robot World Cup}, pages 613--624. Springer, 2016.

\bibitem[Jeng et~al.(2021)Jeng, Liu, Liu, Wang, Chang, Su, and
  Hsu]{jeng2020gdn}
K.-Y. Jeng, Y.-C. Liu, Z.~Y. Liu, J.-W. Wang, Y.-L. Chang, H.-T. Su, and W.~H.
  Hsu.
\newblock {GDN}: A coarse-to-fine (c2f) representation for end-to-end 6-dof
  grasp detection.
\newblock \emph{{CoRL}}, pages 220--231, 2021.

\bibitem[Jiang et~al.(2022)Jiang, Oaki, Ishihara, Ooga, Han, Sugahara, Tokura,
  Eto, Komoda, and Ogawa]{jiang2022learning}
P.~Jiang, J.~Oaki, Y.~Ishihara, J.~Ooga, H.~Han, A.~Sugahara, S.~Tokura,
  H.~Eto, K.~Komoda, and A.~Ogawa.
\newblock Learning suction graspability considering grasp quality and robot
  reachability for bin-picking.
\newblock \emph{Frontiers in Neurorobotics}, 16, 2022.

\bibitem[Jiang et~al.(2021)Jiang, Zhu, Svetlik, Fang, and Zhu]{0002ZSFZ21}
Z.~Jiang, Y.~Zhu, M.~Svetlik, K.~Fang, and Y.~Zhu.
\newblock Synergies between affordance and geometry: 6-dof grasp detection via
  implicit representations.
\newblock In \emph{RSS XVII, Virtual}, 2021.

\bibitem[Khargonkar et~al.(2022)Khargonkar, Song, Xu, Prabhakaran, and
  Xiang]{khargonkar2022neuralgrasps}
N.~Khargonkar, N.~Song, Z.~Xu, B.~Prabhakaran, and Y.~Xiang.
\newblock Neuralgrasps: Learning implicit representations for grasps of
  multiple robotic hands.
\newblock \emph{arXiv preprint arXiv:2207.02959}, 2022.

\bibitem[Kleeberger et~al.(2020)Kleeberger, Bormann, Kraus, and
  Huber]{kleeberger2020survey}
K.~Kleeberger, R.~Bormann, W.~Kraus, and M.~F. Huber.
\newblock A survey on learning-based robotic grasping.
\newblock \emph{Current Robotics Reports}, 1\penalty0 (4):\penalty0 239--249,
  2020.

\bibitem[Li et~al.(2020)Li, Schomaker, and Kasaei]{li2020learning}
Y.~Li, L.~Schomaker, and S.~H. Kasaei.
\newblock Learning to grasp 3d objects using deep residual u-nets.
\newblock In \emph{{RO-MAN}}, pages 781--787. {IEEE}, 2020.

\bibitem[Maggi et~al.(2022)Maggi, Mantriota, and Reina]{maggi2022introducing}
M.~Maggi, G.~Mantriota, and G.~Reina.
\newblock Introducing polypus: A novel adaptive vacuum gripper.
\newblock \emph{Mechanism and Machine Theory}, 167:\penalty0 104483, 2022.

\bibitem[Mahler et~al.(2018)Mahler, Matl, Liu, Li, Gealy, and
  Goldberg]{mahler2017suction}
J.~Mahler, M.~Matl, X.~Liu, A.~Li, D.~Gealy, and K.~Goldberg.
\newblock Dex-net 3.0: Computing robust robot suction grasp targets in point
  clouds using a new analytic model and deep learning.
\newblock In \emph{{ICRA}}, pages 5620--5627. {IEEE}, 2018.

\bibitem[Mahler et~al.(2017)Mahler, Liang, Niyaz, Laskey, Doan, Liu, Ojea, and
  Goldberg]{mahler2017dex}
Jeffrey Mahler, Jacky Liang, Sherdil Niyaz, Michael Laskey, Richard Doan, Xinyu
  Liu, Juan~Aparicio Ojea, and Ken Goldberg.
\newblock Dex-net 2.0: Deep learning to plan robust grasps with synthetic point
  clouds and analytic grasp metrics.
\newblock 2017.

\bibitem[Mantriota(2007)]{mantriota2007optimal}
G.~Mantriota.
\newblock Optimal grasp of vacuum grippers with multiple suction cups.
\newblock \emph{Mechanism and machine theory}, 42\penalty0 (1):\penalty0
  18--33, 2007.

\bibitem[Morrison et~al.(2018)Morrison, Leitner, and Corke]{MorrisonLC18}
D.~Morrison, J.~Leitner, and P.~Corke.
\newblock Closing the loop for robotic grasping: {A} real-time, generative
  grasp synthesis approach.
\newblock In \emph{RSS XIV, Pittsburgh, USA}, 2018.

\bibitem[Newbury et~al.(2022)Newbury, Gu, Chumbley, Mousavian, Eppner, Leitner,
  Bohg, Morales, Asfour, Kragic, et~al.]{newbury2022deep}
R.~Newbury, M.~Gu, L.~Chumbley, A.~Mousavian, C.~Eppner, J.~Leitner, J.~Bohg,
  A.~Morales, T.~Asfour, D.~Kragic, et~al.
\newblock Deep learning approaches to grasp synthesis: A review.
\newblock \emph{arXiv preprint arXiv:2207.02556}, 2022.

\bibitem[Ni et~al.(2020)Ni, Zhang, Zhu, and Cao]{ni2020pointnet++}
P.~Ni, W.~Zhang, X.~Zhu, and Q.~Cao.
\newblock Pointnet++ grasping: learning an end-to-end spatial grasp generation
  algorithm from sparse point clouds.
\newblock In \emph{{ICRA}}, pages 3619--3625. {IEEE}, 2020.

\bibitem[Qin et~al.(2020)Qin, Chen, Zhu, Song, Xu, and Su]{qin2020s4g}
Y.~Qin, R.~Chen, H.~Zhu, M.~Song, J.~Xu, and H.~Su.
\newblock S4g: Amodal single-view single-shot se (3) grasp detection in
  cluttered scenes.
\newblock In \emph{{CoRL}}, pages 53--65. {PMLR}, 2020.

\bibitem[Ronneberger et~al.(2015)Ronneberger, Fischer, and
  Brox]{ronneberger2015u}
O.~Ronneberger, P.~Fischer, and T.~Brox.
\newblock U-net: Convolutional networks for biomedical image segmentation.
\newblock In \emph{{MICCAI}}, pages 234--241. Springer, 2015.

\bibitem[Satish et~al.(2019)Satish, Mahler, and Goldberg]{satish2019policy}
V.~Satish, J.~Mahler, and K.~Goldberg.
\newblock On-policy dataset synthesis for learning robot grasping policies
  using fully convolutional deep networks.
\newblock \emph{RA-L}, 4\penalty0 (2):\penalty0 1357--1364, 2019.

\bibitem[Shao et~al.(2020)Shao, Ferreira, Jorda, Nambiar, Luo, Solowjow, Ojea,
  Khatib, and Bohg]{shao2020unigrasp}
L.~Shao, F.~Ferreira, M.~Jorda, V.~Nambiar, J.~Luo, E.~Solowjow, J.~A. Ojea,
  O.~Khatib, and J.~Bohg.
\newblock Unigrasp: Learning a unified model to grasp with multifingered
  robotic hands.
\newblock \emph{IEEE {RA-L}}, 5\penalty0 (2):\penalty0 2286--2293, 2020.

\bibitem[Shao et~al.(2019)Shao, Hu, Wang, Fang, Liu, Qi, and
  Ma]{shao2019suction}
Q.~Shao, J.~Hu, W.~Wang, Y.~Fang, W.~Liu, J.~Qi, and J.~Ma.
\newblock Suction grasp region prediction using self-supervised learning for
  object picking in dense clutter.
\newblock In \emph{{ICMSR}}, pages 7--12. {IEEE}, 2019.

\bibitem[Xu et~al.(2021)Xu, Qi, Agrawal, and Song]{xu2021adagrasp}
Z.~Xu, B.~Qi, S.~Agrawal, and S.~Song.
\newblock Adagrasp: Learning an adaptive gripper-aware grasping policy.
\newblock In \emph{{ICRA}}, pages 4620--4626. {IEEE}, 2021.

\bibitem[Yang et~al.(2021)Yang, Tosun, Eisner, Isler, and Lee]{yang2021robotic}
D.~Yang, T.~Tosun, B.~Eisner, V.~Isler, and D.~Lee.
\newblock Robotic grasping through combined image-based grasp proposal and 3d
  reconstruction.
\newblock In \emph{{ICRA}}, pages 6350--6356. IEEE, 2021.

\bibitem[Zeng et~al.(2018)Zeng, Song, Yu, Donlon, Hogan, Bauza, Ma, Taylor,
  Liu, Romo, et~al.]{zeng2018robotic}
A.~Zeng, S.~Song, K.-T. Yu, E.~Donlon, F.~R. Hogan, M.~Bauza, D.~Ma, O.~Taylor,
  M.~Liu, E.~Romo, et~al.
\newblock Robotic pick-and-place of novel objects in clutter with
  multi-affordance grasping and cross-domain image matching.
\newblock In \emph{ICRA}, pages 3750--3757. IEEE, 2018.

\bibitem[Zeng et~al.(2022)Zeng, Song, Yu, Donlon, Hogan, Bauza, Ma, Taylor,
  Liu, Romo, et~al.]{zeng2022robotic}
A.~Zeng, S.~Song, K.-T. Yu, E.~Donlon, F.~R. Hogan, M.~Bauza, D.~Ma, O.~Taylor,
  M.~Liu, E.~Romo, et~al.
\newblock Robotic pick-and-place of novel objects in clutter with
  multi-affordance grasping and cross-domain image matching.
\newblock \emph{{IJRR}}, 41\penalty0 (7):\penalty0 690--705, 2022.

\bibitem[Zhao et~al.(2021)Zhao, Zhang, Lan, Wang, Tian, and Zheng]{ZhaoZLWT021}
B.~Zhao, H.~Zhang, X.~Lan, H.~Wang, Z.~Tian, and N.~Zheng.
\newblock {REGNet}: Region-based grasp network for end-to-end grasp detection
  in point clouds.
\newblock In \emph{{ICRA}}, pages 13474--13480. {IEEE}, 2021.

\end{thebibliography}
