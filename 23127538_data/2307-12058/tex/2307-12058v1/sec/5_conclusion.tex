\section{Conclusion} \label{sec:conclusion}
\vspace{-3pt}
For the first time, this paper addresses complex VideoQA, where long multi-object video and hard answer distractors have crippled existing methods, owing to their incapacity in handling massive visual backgrounds and modeling hard distractor answers. We then propose STR to adaptively trim off question-irrelevant scenes, and further develop a novel answer decoding scheme that coordinates with STR to overcome the spurious correlation resulted from distractor-background interaction.
% correlation in the existing use of answer candidates.
Instantiating this pipeline with transformer architecture, we show our method, TranSTR, achieves significant improvements over SoTAs, especially on complex VideoQA tasks. We hope our success can shed light on answering questions in the context of long videos with multiple objects.

% We hope this work can advance more efforts in complex VideoQA.
% In the future,  
% \lyc{we hope to enhance MGR with a stronger spatio-temporal design, which will further benefit complex VideoQA.}