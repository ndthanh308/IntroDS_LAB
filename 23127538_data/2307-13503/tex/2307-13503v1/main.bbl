\begin{thebibliography}{56}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Amini et~al.(2020)Amini, Schwarting, Soleimany, and
  Rus]{amini2020deep}
Alexander Amini, Wilko Schwarting, Ava Soleimany, and Daniela Rus.
\newblock Deep evidential regression.
\newblock \emph{Advances in Neural Information Processing Systems}, 33, 2020.

\bibitem[Batres-Estrada(2015)]{batres2015deep}
Bilberto Batres-Estrada.
\newblock Deep learning for multivariate financial time series, 2015.

\bibitem[Cao et~al.(2018)Cao, Wang, Li, Zhou, Li, and Li]{cao2018brits}
Wei Cao, Dong Wang, Jian Li, Hao Zhou, Lei Li, and Yitan Li.
\newblock {BRITS}: Bidirectional recurrent imputation for time series.
\newblock \emph{Advances in neural information processing systems}, 31, 2018.

\bibitem[Charpentier et~al.(2020)Charpentier, Z{\"u}gner, and
  G{\"u}nnemann]{charpentier2020posterior}
Bertrand Charpentier, Daniel Z{\"u}gner, and Stephan G{\"u}nnemann.
\newblock Posterior network: uncertainty estimation without {OOD} samples via
  density-based pseudo-counts.
\newblock \emph{Advances in Neural Information Processing Systems},
  33:\penalty0 1356--1367, 2020.

\bibitem[Che et~al.(2018)Che, Purushotham, Cho, Sontag, and
  Liu]{che2018recurrent}
Zhengping Che, Sanjay Purushotham, Kyunghyun Cho, David Sontag, and Yan Liu.
\newblock Recurrent neural networks for multivariate time series with missing
  values.
\newblock \emph{Scientific Reports}, 8\penalty0 (1):\penalty0 1--12, 2018.

\bibitem[Chen et~al.(2018)Chen, Rubanova, Bettencourt, and
  Duvenaud]{chen2018neural}
Ricky~TQ Chen, Yulia Rubanova, Jesse Bettencourt, and David~K Duvenaud.
\newblock Neural ordinary differential equations.
\newblock \emph{Advances in Neural Information Processing Systems}, 31, 2018.

\bibitem[Cheng et~al.(2020)Cheng, Dumitrascu, Darnell, Chivers, Draugelis, Li,
  and Engelhardt]{cheng2020sparse}
Li-Fang Cheng, Bianca Dumitrascu, Gregory Darnell, Corey Chivers, Michael
  Draugelis, Kai Li, and Barbara~E Engelhardt.
\newblock Sparse multi-output gaussian processes for online medical time series
  prediction.
\newblock \emph{BMC Medical Informatics and Decision Making}, 20\penalty0
  (1):\penalty0 1--23, 2020.

\bibitem[Cho et~al.(2014)Cho, van Merrienboer, Bahdanau, and
  Bengio]{cho2014properties}
Kyunghyun Cho, Bart van Merrienboer, Dzmitry Bahdanau, and Yoshua Bengio.
\newblock On the properties of neural machine translation: Encoder-decoder
  approaches.
\newblock In Dekai Wu, Marine Carpuat, Xavier Carreras, and Eva~Maria Vecchi,
  editors, \emph{Proceedings of SSST@EMNLP 2014, Eighth Workshop on Syntax,
  Semantics and Structure in Statistical Translation, Doha, Qatar, 25 October
  2014}, pages 103--111. Association for Computational Linguistics, 2014.
\newblock \doi{10.3115/v1/W14-4012}.
\newblock URL \url{https://aclanthology.org/W14-4012/}.

\bibitem[Chow et~al.(2000)Chow, Li, and Fang]{chow2000real}
Tommy~WS Chow, Xiao-Dong Li, and Yong Fang.
\newblock A real-time learning control approach for nonlinear continuous-time
  system using recurrent neural networks.
\newblock \emph{IEEE Transactions on Industrial Electronics}, 47\penalty0
  (2):\penalty0 478--486, 2000.

\bibitem[De~Brouwer et~al.(2019)De~Brouwer, Simm, Arany, and
  Moreau]{deBrouwer2019gru}
Edward De~Brouwer, Jaak Simm, Adam Arany, and Yves Moreau.
\newblock {GRU}-{ODE}-{B}ayes: continuous modeling of sporadically-observed
  time series.
\newblock \emph{Advances in Neural Information Processing Systems}, 32, 2019.

\bibitem[De~Brouwer et~al.(2022)De~Brouwer, Gonzalez, and
  Hyland]{deBrouwer2022predicting}
Edward De~Brouwer, Javier Gonzalez, and Stephanie Hyland.
\newblock Predicting the impact of treatments over time with uncertainty aware
  neural differential equations.
\newblock In \emph{International Conference on Artificial Intelligence and
  Statistics}, pages 4705--4722. PMLR, 2022.

\bibitem[Fortuin et~al.(2020)Fortuin, Baranchuk, R{\"a}tsch, and
  Mandt]{fortuin2020gp}
Vincent Fortuin, Dmitry Baranchuk, Gunnar R{\"a}tsch, and Stephan Mandt.
\newblock Gp-vae: Deep probabilistic time series imputation.
\newblock In \emph{International conference on artificial intelligence and
  statistics}, pages 1651--1661. PMLR, 2020.

\bibitem[Funahashi and Nakamura(1993)]{funahashi1993approximation}
Ken-ichi Funahashi and Yuichi Nakamura.
\newblock Approximation of dynamical systems by continuous time recurrent
  neural networks.
\newblock \emph{Neural networks}, 6\penalty0 (6):\penalty0 801--806, 1993.

\bibitem[Gal and Ghahramani(2016{\natexlab{a}})]{gal2016dropout}
Yarin Gal and Zoubin Ghahramani.
\newblock Dropout as a {B}ayesian approximation: Representing model uncertainty
  in deep learning.
\newblock In \emph{International {C}onference on {M}achine {L}earning}, pages
  1050--1059. PMLR, 2016{\natexlab{a}}.

\bibitem[Gal and Ghahramani(2016{\natexlab{b}})]{gal2016theoretically}
Yarin Gal and Zoubin Ghahramani.
\newblock A theoretically grounded application of dropout in recurrent neural
  networks.
\newblock \emph{Advances in {N}eural {I}nformation {P}rocessing {S}ystems}, 29,
  2016{\natexlab{b}}.

\bibitem[Ghassemi et~al.(2015)Ghassemi, Pimentel, Naumann, Brennan, Clifton,
  Szolovits, and Feng]{ghassemi2015multivariate}
Marzyeh Ghassemi, Marco Pimentel, Tristan Naumann, Thomas Brennan, David
  Clifton, Peter Szolovits, and Mengling Feng.
\newblock A multivariate timeseries modeling approach to severity of illness
  assessment and forecasting in icu with sparse, heterogeneous clinical data.
\newblock In \emph{Proceedings of the AAAI conference on artificial
  intelligence}, volume~29, 2015.

\bibitem[Graf et~al.(2021)Graf, Flores, Protopapas, and
  Pichara]{graf2021uncertainty}
Olga Graf, Pablo Flores, Pavlos Protopapas, and Karim Pichara.
\newblock Uncertainty quantification in neural differential equations.
\newblock \emph{arXiv preprint arXiv:2111.04207}, 2021.

\bibitem[Hafner et~al.(2020)Hafner, Tran, Lillicrap, Irpan, and
  Davidson]{hafner2020noise}
Danijar Hafner, Dustin Tran, Timothy Lillicrap, Alex Irpan, and James Davidson.
\newblock Noise contrastive priors for functional uncertainty.
\newblock In \emph{Uncertainty in Artificial Intelligence}, pages 905--914.
  PMLR, 2020.

\bibitem[Hartvigsen et~al.(2023)Hartvigsen, Thadajarassiri, Kong, and
  Rundensteiner]{hartvigsen2023finding}
Thomas Hartvigsen, Jidapa Thadajarassiri, Xiangnan Kong, and Elke
  Rundensteiner.
\newblock Finding short signals in long irregular time series with
  continuous-time attention policy networks.
\newblock \emph{arXiv preprint arXiv:2302.04052}, 2023.

\bibitem[Hasani et~al.(2021)Hasani, Lechner, Amini, Rus, and
  Grosu]{hasani2021liquid}
Ramin Hasani, Mathias Lechner, Alexander Amini, Daniela Rus, and Radu Grosu.
\newblock Liquid time-constant networks.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial
  Intelligence}, volume~35, pages 7657--7666, 2021.

\bibitem[Hasani et~al.(2022)Hasani, Lechner, Amini, Liebenwein, Ray,
  Tschaikowski, Teschl, and Rus]{hasani2022closed}
Ramin Hasani, Mathias Lechner, Alexander Amini, Lucas Liebenwein, Aaron Ray,
  Max Tschaikowski, Gerald Teschl, and Daniela Rus.
\newblock Closed-form continuous-time neural networks.
\newblock \emph{Nature Machine Intelligence}, pages 1--12, 2022.

\bibitem[Horn et~al.(2020)Horn, Moor, Bock, Rieck, and Borgwardt]{horn2020set}
Max Horn, Michael Moor, Christian Bock, Bastian Rieck, and Karsten Borgwardt.
\newblock Set functions for time series.
\newblock In \emph{International Conference on Machine Learning}, pages
  4353--4363. PMLR, 2020.

\bibitem[Jensen et~al.(2014)Jensen, Moseley, Oprea, Elles{\o}e, Eriksson,
  Schmock, Jensen, Jensen, and Brunak]{jensen2014temporal}
Anders~Boeck Jensen, Pope~L Moseley, Tudor~I Oprea, Sabrina~Gade Elles{\o}e,
  Robert Eriksson, Henriette Schmock, Peter~Bj{\o}dstrup Jensen, Lars~Juhl
  Jensen, and S{\o}ren Brunak.
\newblock Temporal disease trajectories condensed from population-wide registry
  data covering 6.2 million patients.
\newblock \emph{Nature communications}, 5\penalty0 (1):\penalty0 4022, 2014.

\bibitem[Jia and Benson(2019)]{jia2019neural}
Junteng Jia and Austin~R Benson.
\newblock Neural jump stochastic differential equations.
\newblock \emph{Advances in Neural Information Processing Systems}, 32, 2019.

\bibitem[Johnson et~al.(2016)Johnson, Pollard, Shen, Lehman, Feng, Ghassemi,
  Moody, Szolovits, Anthony~Celi, and Mark]{johnson2016mimic}
Alistair~EW Johnson, Tom~J Pollard, Lu~Shen, Li-wei~H Lehman, Mengling Feng,
  Mohammad Ghassemi, Benjamin Moody, Peter Szolovits, Leo Anthony~Celi, and
  Roger~G Mark.
\newblock {MIMIC-III}, a freely accessible critical care database.
\newblock \emph{Scientific data}, 3\penalty0 (1):\penalty0 1--9, 2016.

\bibitem[Jordan(2009)]{jordan2009exponential}
Michael Jordan.
\newblock The exponential family: Conjugate priors, 2009.

\bibitem[Kalu{\v{z}}a et~al.(2010)Kalu{\v{z}}a, Mirchevska, Dovgan,
  Lu{\v{s}}trek, and Gams]{kaluvza2010agent}
Bo{\v{s}}tjan Kalu{\v{z}}a, Violeta Mirchevska, Erik Dovgan, Mitja
  Lu{\v{s}}trek, and Matja{\v{z}} Gams.
\newblock An agent-based approach to care in independent living.
\newblock In \emph{Ambient Intelligence: First International Joint Conference,
  AmI 2010, Malaga, Spain, November 10-12, 2010. Proceedings 1}, pages
  177--186. Springer, 2010.

\bibitem[Kendall and Gal(2017)]{kendall2017uncertainties}
Alex Kendall and Yarin Gal.
\newblock What uncertainties do we need in bayesian deep learning for computer
  vision?
\newblock \emph{Advances in neural information processing systems}, 30, 2017.

\bibitem[Kidger(2021)]{kidger2021neural}
Patrick Kidger.
\newblock \emph{On neural differential equations}.
\newblock PhD thesis, University of Oxford, 2021.

\bibitem[Kingma et~al.(2015)Kingma, Salimans, and
  Welling]{kingma2015variational}
Durk~P Kingma, Tim Salimans, and Max Welling.
\newblock Variational dropout and the local reparameterization trick.
\newblock \emph{Advances in neural information processing systems}, 28, 2015.

\bibitem[Li and Marlin(2020)]{cheng2020learning}
Steven Cheng-Xian Li and Benjamin~M Marlin.
\newblock Learning from irregularly-sampled time series: a missing data
  perspective.
\newblock In \emph{ICML}, 2020.

\bibitem[Lipton et~al.(2016)Lipton, Kale, and Wetzel]{lipton2016directly}
Zachary~C Lipton, David Kale, and Randall Wetzel.
\newblock Directly modeling missing data in sequences with {RNN}s: Improved
  classification of clinical time series.
\newblock In \emph{Machine Learning for Healthcare Conference}, pages 253--270.
  PMLR, 2016.

\bibitem[Liu et~al.(2009)Liu, Zhong, Wickramasuriya, and
  Vasudevan]{liu2009uwave}
Jiayang Liu, Lin Zhong, Jehan Wickramasuriya, and Venu Vasudevan.
\newblock u{W}ave: Accelerometer-based personalized gesture recognition and its
  applications.
\newblock \emph{Pervasive and Mobile Computing}, 5\penalty0 (6):\penalty0
  657--675, 2009.

\bibitem[Malinin and Gales(2018)]{malinin2018predictive}
Andrey Malinin and Mark Gales.
\newblock Predictive uncertainty estimation via prior networks.
\newblock \emph{Advances in Neural Information Processing Systems}, 31, 2018.

\bibitem[Malinin et~al.(2020)Malinin, Chervontsev, Provilkov, and
  Gales]{malinin2020regression}
Andrey Malinin, Sergey Chervontsev, Ivan Provilkov, and Mark Gales.
\newblock Regression prior networks.
\newblock \emph{arXiv preprint arXiv:2006.11590}, 2020.

\bibitem[Meinert and Lavin(2021)]{meinert2021multivariate}
Nis Meinert and Alexander Lavin.
\newblock Multivariate deep evidential regression.
\newblock \emph{arXiv preprint arXiv:2104.06135}, 2021.

\bibitem[Morrill et~al.(2022)Morrill, Kidger, Yang, and Lyons]{morrill2022on}
James Morrill, Patrick Kidger, Lingyi Yang, and Terry Lyons.
\newblock On the choice of interpolation scheme for neural {CDE}s.
\newblock \emph{Transactions on Machine Learning Research}, 2022.
\newblock ISSN 2835-8856.
\newblock URL \url{https://openreview.net/forum?id=caRBFhxXIG}.

\bibitem[Mozer et~al.(2017)Mozer, Kazakov, and Lindsey]{mozer2017discrete}
Michael~C Mozer, Denis Kazakov, and Robert~V Lindsey.
\newblock Discrete event, continuous time rnns.
\newblock \emph{arXiv:1710.04110}, 2017.

\bibitem[Murphy(2007)]{murphy2007conjugate}
Kevin~P Murphy.
\newblock Conjugate {B}ayesian analysis of the {G}aussian distribution.
\newblock 2007.

\bibitem[Nixon et~al.(2019)Nixon, Dusenberry, Zhang, Jerfel, and
  Tran]{nixon2019measuring}
Jeremy Nixon, Michael~W Dusenberry, Linchuan Zhang, Ghassen Jerfel, and Dustin
  Tran.
\newblock Measuring calibration in deep learning.
\newblock In \emph{CVPR workshops}, volume~2, 2019.

\bibitem[Rasul et~al.(2021{\natexlab{a}})Rasul, Seward, Schuster, and
  Vollgraf]{rasul2021autoregressive}
Kashif Rasul, Calvin Seward, Ingmar Schuster, and Roland Vollgraf.
\newblock Autoregressive denoising diffusion models for multivariate
  probabilistic time series forecasting.
\newblock In \emph{International Conference on Machine Learning}, pages
  8857--8868. PMLR, 2021{\natexlab{a}}.

\bibitem[Rasul et~al.(2021{\natexlab{b}})Rasul, Sheikh, Schuster, Bergmann, and
  Vollgraf]{rasul2021multivariate}
Kashif Rasul, Abdul-Saboor Sheikh, Ingmar Schuster, Urs~M Bergmann, and Roland
  Vollgraf.
\newblock Multivariate probabilistic time series forecasting via conditioned
  normalizing flows.
\newblock In \emph{International Conference on Learning Representations},
  2021{\natexlab{b}}.
\newblock URL \url{https://openreview.net/forum?id=WiGQBFuVRv}.

\bibitem[Rubanova et~al.(2019)Rubanova, Chen, and Duvenaud]{rubanova2019latent}
Yulia Rubanova, Ricky~TQ Chen, and David~K Duvenaud.
\newblock Latent ordinary differential equations for irregularly-sampled time
  series.
\newblock \emph{Advances in Neural Information Processing Systems}, 32, 2019.

\bibitem[Salvi et~al.(2022)Salvi, Lemercier, and Gerasimovics]{salvi2022neural}
Cristopher Salvi, Maud Lemercier, and Andris Gerasimovics.
\newblock Neural stochastic pdes: Resolution-invariant learning of continuous
  spatiotemporal dynamics.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2022.

\bibitem[Schirmer et~al.(2022)Schirmer, Eltayeb, Lessmann, and
  Rudolph]{schirmer2022modeling}
Mona Schirmer, Mazin Eltayeb, Stefan Lessmann, and Maja Rudolph.
\newblock Modeling irregular time series with continuous recurrent units.
\newblock In \emph{International Conference on Machine Learning}, pages
  19388--19405. PMLR, 2022.

\bibitem[Sensoy et~al.(2018)Sensoy, Kaplan, and Kandemir]{sensoy2018evidential}
Murat Sensoy, Lance Kaplan, and Melih Kandemir.
\newblock Evidential deep learning to quantify classification uncertainty.
\newblock \emph{Advances in Neural Information Processing Systems},
  31:\penalty0 3179--3189, 2018.

\bibitem[Shafer(1976)]{shafer1976mathematical}
Glenn Shafer.
\newblock \emph{A mathematical theory of evidence}, volume~42.
\newblock Princeton University Press, 1976.

\bibitem[Shi et~al.(2015)Shi, Chen, Wang, Yeung, Wong, and
  Woo]{shi2015convolutional}
Xingjian Shi, Zhourong Chen, Hao Wang, Dit-Yan Yeung, Wai-Kin Wong, and
  Wang-chun Woo.
\newblock Convolutional {LSTM} network: A machine learning approach for
  precipitation nowcasting.
\newblock \emph{Advances in neural information processing systems}, 28, 2015.

\bibitem[Shukla and Marlin(2019)]{shukla2019interpolation}
Satya~Narayan Shukla and Benjamin Marlin.
\newblock Interpolation-prediction networks for irregularly sampled time
  series.
\newblock In \emph{International Conference on Learning Representations}, 2019.

\bibitem[Silva et~al.(2012)Silva, Moody, Scott, Celi, and
  Mark]{silva2012predicting}
Ikaro Silva, George Moody, Daniel~J Scott, Leo~A Celi, and Roger~G Mark.
\newblock Predicting in-hospital mortality of icu patients: The
  physionet/computing in cardiology challenge 2012.
\newblock In \emph{2012 Computing in Cardiology}, pages 245--248. IEEE, 2012.

\bibitem[Stankeviciute et~al.(2021)Stankeviciute, M~Alaa, and van~der
  Schaar]{stankeviciute2021conformal}
Kamile Stankeviciute, Ahmed M~Alaa, and Mihaela van~der Schaar.
\newblock Conformal time-series forecasting.
\newblock \emph{Advances in Neural Information Processing Systems},
  34:\penalty0 6216--6228, 2021.

\bibitem[Sun and Yu(2022)]{sun2022copula}
Sophia Sun and Rose Yu.
\newblock Copula conformal prediction for multi-step time series forecasting.
\newblock \emph{arXiv preprint arXiv:2212.03281}, 2022.

\bibitem[Wang et~al.(2020)Wang, McDermott, Chauhan, Ghassemi, Hughes, and
  Naumann]{wang2020mimic}
Shirly Wang, Matthew~BA McDermott, Geeticka Chauhan, Marzyeh Ghassemi,
  Michael~C Hughes, and Tristan Naumann.
\newblock Mimic-extract: A data extraction, preprocessing, and representation
  pipeline for {MIMIC}-{III}.
\newblock In \emph{Proceedings of the ACM conference on health, inference, and
  learning}, pages 222--235, 2020.

\bibitem[Yao et~al.(2019)Yao, Pan, Ghosh, and Doshi-Velez]{yao2019quality}
Jiayu Yao, Weiwei Pan, Soumya Ghosh, and Finale Doshi-Velez.
\newblock Quality of uncertainty quantification for bayesian neural network
  inference.
\newblock \emph{arXiv preprint arXiv:1906.09686}, 2019.

\bibitem[Yu et~al.(2021)Yu, Ventola, and Kersting]{yu2021whittle}
Zhongjie Yu, Fabrizio~G Ventola, and Kristian Kersting.
\newblock Whittle networks: A deep likelihood model for time series.
\newblock In \emph{International Conference on Machine Learning}, pages
  12177--12186. PMLR, 2021.

\bibitem[Zheng et~al.(2017)Zheng, Gao, Ngiam, Ooi, and Yip]{zheng2017resolving}
Kaiping Zheng, Jinyang Gao, Kee~Yuan Ngiam, Beng~Chin Ooi, and Wei Luen~James
  Yip.
\newblock Resolving the bias in electronic medical records.
\newblock In \emph{KDD}, pages 2171--2180. ACM, 2017.

\end{thebibliography}
