
Researchers have studied EV charging scheduling, AMoD system vehicle rebalancing, and joint scheduling using rule-based heuristic, optimization-based, or reinforcement learning-based approaches. For instance, Liu et al.~\cite{liu2019dynamic_heuristic} and Vandael et al.~\cite{vandael2015reinforcement_heuristic} proposed heuristic schemes of vehicle rebalancing and individual EV charging, respectively. These heuristic methods usually lead to sub-optimal solutions~\cite{zardini2021analysis_survey}. 

Optimization-based methods first design an optimization problem based on Model Predictive Control (MDP), then solve it at each time step to yield a sequence of balancing actions over a receding horizon. But only the first balancing action is executed. Under this category, charging scheduling approaches consider different objectives  have been proposed, such as reducing charging delays or balancing the charging tasks in charging stations with limited resources~\cite{yan2018employing, bCharge, EVAMoD_tcns19}, reducing idle distance or idle time~\cite{yan2018employing, p2charge}, and improving drivers revenue~\cite{xie2019optimal}, etc. AMoD systems' vehicle rebalancing approaches with various objectives have been designed, such as improving service quality~\cite{predictmod_icra17, Morari_rideshare}, maximizing the number of served passengers with a reduced number of vehicles~\cite{mpcmod_icra16, mod_iros18, DDmpcmod_icra18}. These optimization-based approaches usually rely on precise modeling of the complex probability state transition model of E-AMoD systems and future mobility demand and EAV supply predictions. Therefore, they are sensitive to model uncertainties, prediction errors and measurement inaccuracy.


RL-based methods formulate the vehicle balancing problem as a Markov Decision Process and apply RL algorithms to find the optimal balancing policy. Wen et al. \cite{wen2017rebalancing} applied Deep Q-Network (DQN) to study the vehicle balancing problem. Holler et al. developed an Actor-Critic-based fleet management algorithm to reposition vehicles \cite{holler2019deep_icdm, gueriau2018samod}. Various RL algorithms \cite{EVcharge_19} such as contextual DQN and A2C \cite{lin2018efficient, gueriau2018samod}, spatio-temporal capsule-based Q-learning \cite{he2020spatio}, mean-field multi-agent RL \cite{jointcharging} algorithms have been proposed to solve the vehicle balancing problem. Compared to optimization-based vehicle balancing methods, RL-based methods can handle a larger-scale problem in practice by incorporating with function approximation scheme, and relax the dependence on the modeling of E-AMoD systems' complex dynamics~\cite{he2022robust_icra}. However, passenger mobility demand or EV supply uncertainties are not considered in RL methods yet. For the first time, we consider passenger mobility demand or EV supply uncertainties as system state information uncertainties, and propose robust MARL-based problem formulation and algorithm for E-AMoD system balancing under state uncertainties.



