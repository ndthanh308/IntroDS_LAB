% \section{Preliminary}
\section{Instruction Format Inconsistency}


% Figure environment removed

As outlined in ~\citet{iyer2022opt}, existing instruction formats exhibit variations across different datasets, which can be classified into three distinct hierarchical levels: Task-level format, Instance-level format, and Keywords-level format (as illustrated in Figure~\ref{framework}). We present an overview of existing instruction tuning datasets based on instruction formats in Table~\ref{tab:dataset_comparison}. 

\begin{itemize}
    \item \textbf{Task-level Format} encompasses a comprehensive definition of a task and may include supplementary information such as positive or negative examples and explanations of the examples. Representative datasets are Ni-v2~\citep{wang2022super}, Unnatural Instructions ~\citep{honovich2022unnatural}, and Alpaca~\citep{alpaca}.

    \item \textbf{Instance-level Format} employs succinct templates that are customized for each individual example and is occasionally structured in a cloze-style format to elicit the intended output. Representative datasets are Flan~\citep{wei2021finetuned} and PromptSource~\citep{bach2022promptsource}.

    \item \textbf{Keywords-level Format} closely resembles the instance-level format, but it limits the instruction templates exclusively to keywords. CrossFit~\citep{ye2021crossfit} serves as a representative example of a keywords-level dataset.

\end{itemize}

Compared with task diversity, the effect of format consistency is poorly understood in instruction tuning. We contend that successful instruction understanding and generalization are influenced by both task diversity and format consistency. Task diversity can be enhanced by incorporating as many tasks into the training data (e.g., merging existing instruction tuning datasets) as possible. However, it is crucial to note that when merging different datasets for training, the training data originating from different sources often present variations in the instruction formats. When confronted with instructions of unseen inconsistent formats at the test time, the trained model may fail to generalize well and comprehend the intent behind different instructions, showing poor OOD generalization.