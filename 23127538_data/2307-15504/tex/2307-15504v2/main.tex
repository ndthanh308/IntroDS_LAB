
\documentclass[10pt]{article} % For LaTeX2e
% \usepackage{tmlr}
% \usepackage[preprint]{tmlr}
% If accepted, instead use the following line for the camera-ready submission:
\usepackage[accepted]{tmlr}
% To de-anonymize and remove mentions to TMLR (for example for posting to preprint servers), instead use the following:
%\usepackage[preprint]{tmlr}

% Optional math commands from https://github.com/goodfeli/dlbook_notation.
\input{math_commands.tex}

\usepackage{colortbl}
\definecolor{shallowblue}{rgb}{0.88,0.92,1} % Define the color you want

\usepackage{hyperref}
\usepackage{url}
\usepackage[utf8]{inputenc}
\usepackage[pdftex]{graphicx}
% This is not strictly necessary, and may be commented out,
% but it will improve the layout of the manuscript,
% and will typically save some space.
\usepackage{microtype}

% If the title and author information does not fit in the area allocated, uncomment the following
%
%\setlength\titlebox{<dim>}
%
% and set <dim> to something 5cm or larger.

% added by Yujia
\usepackage{tcolorbox}
\usepackage{setspace}
\tcbuselibrary{most}
\tcbuselibrary{skins, breakable, theorems}
% \newtcolorbox{mybox}[2][]{%
%     colbacktitle=red!10!white,
%     colback=blue!10!white,
%     coltitle=red!70!black,
%     title={#2},
%     fonttitle=\bfseries,
%     #1,
%     enhanced, % enable advanced features
%     boxrule=0.5mm, % thickness of box border
%     arc=3mm, % rounding of corners
%     % drop shadow={color=black,opacity=0.5}, % add shadow
%     left=1.5mm, % left margin
%     right=3mm, % right margin
%     top=1mm, % top margin
%     bottom=2mm, % bottom margin
%     fontupper=\tiny, % set font size for box text
%     % before upper={\parindent15pt}, % indent first line of each paragraph
%     fontlower=\tiny
%     colupper=black, % set font color for box text
% }
\usepackage{xspace,mfirstuc,tabulary}
\usepackage{booktabs}
\usepackage{amssymb}
\usepackage{pifont}
\usepackage{amsmath}
\usepackage{array}
\usepackage{multirow,booktabs, hhline}
\usepackage[ruled,noend]{algorithm2e}
\usepackage{arydshln}
\usepackage{amsmath, bm}
\newcommand\ourmodel{\textsc{IWSQA}\xspace}
\usepackage{graphicx}
\usepackage{color}
\usepackage{bbm}
\usepackage{bbding}
\usepackage{subfigure}
\usepackage{makecell}
\usepackage{CJKutf8}
\usepackage{cleveref}
% \usepackage{listings}
% \usepackage{markdown}



\title{Exploring Format Consistency for Instruction Tuning}

% Authors must not appear in the submitted version. They should be hidden
% as long as the tmlr package is used without the [accepted] or [preprint] options.
% Non-anonymous submissions will be rejected without review.

\author{\name Shihao~Liang$^{}\thanks{\ \ Indicates equal contribution.}$\hspace{0.5em} \email shihaoliang0828@gmail.com \\
      \addr Department of Computer Science\\
      Tsinghua University
      \AND
      \name Runchu~Tian$^{*}$ \email trc20@mails.tsinghua.edu.cn \\
      \addr Department of Computer Science\\
      Tsinghua University
      \AND
      \name Kunlun~Zhu$^{*}$ \email zhuklun@mail2.sysu.edu.cn \\
      \addr Department of Computer Science\\
      Tsinghua University
      \AND
      \name Yujia~Qin$^{}$ \email
      qyj20@mails.tsinghua.edu.cn \\
      \addr Department of Computer Science\\
      Tsinghua University
      \AND
      \name Huadong~Wang$^{}$ \email huadw2012@163.com\\
      ModelBest Inc.
      \AND
      \name Xin~Cong$^{}$ \email 
      congxin1995@tsinghua.edu.cn\\
      \addr Department of Computer Science\\
      Tsinghua University
      \AND
      \name Zhiyuan~Liu$^{}\thanks{\ \  Corresponding author.}$\hspace{0.5em} \email 
      liuzy@tsinghua.edu.cn\\
      \addr Department of Computer Science\\
      Tsinghua University
      \AND
      \name Xiaojiang~Liu$^{}$ \email 
      xiaojiang\_liu@apple.com\\
      % \addr Department of Computer Science\\
      Apple
      \AND
      \name Maosong~Sun$^{\dag}$ \email sms@tsinghua.edu.cn\\
      \addr Department of Computer Science\\
      Tsinghua University\\
      % $^1$Tsinghua University, $^2$Apple \\
      % \name Work mostly done at Tsinghua University, Department of Computer Science
      }


% The \author macro works with any number of authors. Use \AND 
% to separate the names and addresses of multiple authors.

\newcommand{\fix}{\marginpar{FIX}}
\newcommand{\new}{\marginpar{NEW}}

\def\month{12}  % Insert correct month for camera-ready version
\def\year{2023} % Insert correct year for camera-ready version
\def\openreview{\url{https://openreview.net/forum?id=n8fZ6mY6PB}} % Insert correct link to OpenReview for camera-ready version


\begin{document}


\maketitle

\begin{abstract}
Instruction tuning has emerged as a promising approach to enhancing large language models in following human instructions. It is shown that increasing the diversity and number of instructions in the training data can consistently enhance generalization performance, which facilitates a recent endeavor to collect various instructions and integrate existing instruction tuning datasets into larger collections. However, different users have their unique ways of expressing instructions, and there often exist variations across different datasets in the instruction styles and formats, i.e., format inconsistency. 
% In this work, we study how format inconsistency may impact the performance of instruction tuning. We propose a framework called ``\underline{U}nified \underline{I}nstruction \underline{T}uning'' (UIT), which calls OpenAI APIs like GPT-3.5 for automatic format transfer among different instruction tuning datasets such as PromptSource, FLAN and CrossFit. We show that UIT successfully improves the generalization performance (9.3\% in Exact Match, 7.6\% in Rouge-L) on unseen instructions on T5-LM-xl, which highlights the importance of format consistency for instruction tuning. 
% To make the UIT framework more practical, we further propose a novel perplexity-based denoising method to reduce the noise of automatic format transfer. We also train a smaller offline model based on GPT-J that achieves comparable format transfer capability to OpenAI APIs to reduce costs in practice. The code and trained models will soon be available.
In this work, we propose a framework named ``\underline{U}nified \underline{I}nstruction \underline{T}uning'' (UIT), which calls OpenAI APIs for automatic format transfer among different instruction tuning datasets such as PromptSource, FLAN and CrossFit. With the framework, we (1) demonstrate the necessity of maintaining format consistency in instruction tuning; (2) improve the generalization performance on unseen instructions on T5-LM-xl; (3) provide a novel perplexity-based denoising method to reduce the noise of automatic format transfer to make the UIT framework more practical and a smaller offline model based on GPT-J that achieves comparable format transfer capability to OpenAI APIs to reduce costs in practice. Further analysis regarding variations of targeted formats and other effects is intended. The code and trained models are publicly available at \url{https://github.com/thunlp/UnifiedInstructionTuning}.



\end{abstract}

\section{Introduction}


% \vspace{-1in}
Recently, instruction tuning has gained considerable attention as a potent strategy for enhancing large language models (LLMs) in following human instructions and generating appropriate responses. For instance, by reformulating various NLP tasks with an instruction template, models trained on the converted dataset exhibit powerful capabilities of zero-shot generalization on unseen tasks~\citep{wei2021finetuned}. Later studies have demonstrated that instruction tuning is critical to facilitating LLMs in grounding their inner knowledge to diverse real-world scenarios~\citep{ouyang2022training,iyer2022opt,chung2022scaling,ding2023enhancing}. Up to now, considerable efforts have been dedicated to creating datasets for instruction tuning~\citep{honovich2022unnatural,bach2022promptsource,wei2021finetuned,wang2022super,wang2022self,DBLP:conf/iclr/AribandiTSRZMZ022} and researchers find that increasing the task diversity (i.e., the number of unique tasks) of the training data can consistently enhance generalization performance~\citep{wang2022super,iyer2022opt,longpre2023flan}. Therefore, the community has witnessed a growing endeavor to collect various instructions and integrate existing instruction tuning datasets into larger collections~\citep{iyer2022opt, longpre2023flan, chung2022scaling,zhou2023lima}.

While previous works strive to increase \textbf{task diversity} and merge existing instruction tuning datasets, they typically ignore the \textbf{format consistency} among these datasets. More specifically, different users have their unique ways of expressing instructions, even if these instructions correspond to the same intent. Hence, there often exist variations across different datasets in the instruction styles and formats, which is dubbed as the format inconsistency issue. Take the case of a summarization task, the instruction can be as detailed as ``\textit{In this task, you are given a conversation, and your task is to generate a summary... Input: ... Output: ...}'' in Ni-v2~\citep{wang2022super} or simply composed of a few keywords, e.g., ``\textit{Summarize: ...}'' in CrossFit~\citep{ye2021crossfit}. Due to the format inconsistency issue, fine-tuned LLMs may have difficulty in handling unseen instructions in a different format at the test time, exhibiting poor out-of-distribution (OOD) generalization. 
Hence, before directly merging diverse datasets from various sources and performing multi-task training (i.e., the common practice), it is essential to conduct a comprehensive study of how format inconsistency may impact the performance of instruction tuning and whether mitigating such inconsistency could enhance the generalization.

However, unifying the format across different datasets is not easy. First, instructions are inherently diverse and nuanced, and the vast range of possible expressions makes it challenging to devise a fixed rule for format transfer. Second, standardizing formats can sometimes inadvertently change the meaning of the original instructions. This is particularly problematic for complex tasks where the instructionâ€™s wording and style are crucial to correctly guiding the model behavior. In this paper, we introduce a format transfer framework, \textbf{\underline{U}nified \underline{I}nstruction \underline{T}uning~(UIT)} (Figure~\ref{training-testing-time}) to explore the effects of format consistency. Specifically, we use OpenAI GPT3.5\footnote{\url{https://platform.openai.com/docs/models/gpt-3-5}} for automatic instruction format transfer. Leveraging its powerful in-context learning capabilities, GPT3.5 can successfully transfer the instruction from a source format to a target format based on only a few handcrafted examples. Then we analyze how format inconsistency could affect generalization under two settings: (1) testing-time setting, which simulates the format inconsistency between the training data and the testing data, and (2) training-time setting, which simulates the format inconsistency among different sources of instructions in the training data. We perform analysis across five benchmarks and show that our method successfully mitigates the format inconsistency issue and improves the generalization performance on unseen instructions in both settings.

% Figure environment removed

Despite its simplicity and performance, the above framework encounters two practical challenges. To begin with, the converted instructions are not as perfect as human-written ones and sometimes involve noise. For instance, an auto-converted instruction may express a slightly different meaning than the original one. To address this issue, we propose a novel perplexity-based denoising strategy that samples multiple possible conversions of a source instruction and then filters those low-quality ones based on perplexity. Experimental results reveal that this strategy effectively reduces the noise of format transfer and improves robustness and performance.
Second, converting large-scale instructions via OpenAI API  can result in substantial costs for API calls, which is infeasible in practice. To this end, we propose to learn an offline model for format transfer by distilling from GPT3.5. We demonstrate that with a few examples generated by GPT3.5, a much smaller model can be trained to achieve almost equivalent performance in format transfer, which saves the costs for API calls in practice.
In general, our findings shed light on an essential but previously overlooked aspect, i.e., format consistency, for instruction tuning. We envision our research could inspire more efforts in advancing the instruction tuning methodologies for LLMs.

\begin{table*}[htbp]
    \centering
    \caption{A comparison of representative instruction tuning datasets of different instruction formats. ``Num.'', ``Cate.'', ``Exp.'', ``Inst.'', ``Unnat-Inst'',  refer to Number, Category, Example, Instruction, and unnatural-instructions respectively.
    }
    \vspace{1em} % One line space after the table title
    \begin{tabular}{lcccc}
        \toprule
        \textbf{Resource}  & 
         \textbf{Task Num.} & \textbf{Cate. Num.}  & \textbf{Total Exp.} & \textbf{Inst. format}
        \\
        \midrule
           \multicolumn{1}{l}{\textbf{Ni-v2} ~\citep{wang2022super}}  & $1616$ & $76$ & 5M & task-level  \\ 
          \multicolumn{1}{l}{\textbf{Flan 2021}~\citep{wei2021finetuned}}   & $62$ & $12$ & 4.4M & instance-level  \\ 
          \multicolumn{1}{l}{$\textbf{CrossFit}$~\citep{ye-etal-2021-crossfit}}  & $159$ & $13$ & 7.1M & keywords-level  \\
          \multicolumn{1}{l}{\textbf{P3}~\citep{bach2022promptsource}} & $62$ & $13$ & 12M & instance-level   \\
          \multicolumn{1}{l}{\textbf{Unnat-Inst}~\citep{honovich2022unnatural}}  & $117$ & $\mathbf{-}$ & 64k & task-level  \\
          \multicolumn{1}{l}{\textbf{OPT-IML}~\citep{iyer2022opt}}   & 1545 & 93 & 17.9M & mixed  \\ 
          \multicolumn{1}{l}{\textbf{Flan 2022}~\citep{longpre2023flan}}   & 1836 & 162 & 15M & mixed \\ 
         \bottomrule
    \end{tabular}
    \vspace{1em} % One line space after the table title
    \label{tab:dataset_comparison}
\end{table*}

% \begin{table*}[htbp]
%     \centering
% % \renewcommand{\arraystretch}{1.1} 
%     \small
%     \begin{tabular}{lcccc}
%         \toprule
%         \textbf{Resource}  & 
%          \textbf{Task Num.} & \textbf{Cate. Num.}  & \textbf{Total Exp.} & \textbf{Inst. format} % & \textbf{Prompt structure}
%          % & \textbf{Public?}
%         \\
%         \midrule
%          % \cmidrule(lr){1-1}  \cmidrule(lr){2-2}  \cmidrule(lr){3-3}  \cmidrule(lr){4-4}  \cmidrule(lr){5-5} \cmidrule(lr){6-6}  \cmidrule(lr){7-7}  
%         %   Usage of supporting fact & $47.7\%$ & $56.0\%$ & $56.0\%$ & $4.7\%$ &  & -- & -- \\ 
          
%            \makecell{ \textbf{Ni-v2} ~\citep{wang2022super} }  & $1616$ & $76$ & 5M & task-level  \\ 
%           \makecell{ \textbf{Flan 2021}~\citep{wei2021finetuned} }   & $62$ & $12$ & 4.4M & instance-level  \\ 
%           \makecell{ $\textbf{CrossFit}$~\citep{ye-etal-2021-crossfit} }  & $159$ & $13$ & 7.1M & keywords-level  \\
%           \makecell{ \textbf{P3}~\citep{bach2022promptsource} } & $62$ & $13$ & $12M$ & instance-level   \\
%           \makecell{\textbf{Unnatural-Inst}~\citep{honovich2022unnatural}}  & $117$ & $\mathbf{-}$ & 64k & task-level  \\
%           % \hdashline
%           \makecell{\textbf{OPT-IML}~\citep{iyer2022opt}}   & 1545 & 93 & 17.9M & mixed  \\ 
%           \makecell{\textbf{Flan 2022}~\citep{longpre2023flan}}   & 1836 & 162 & 15M & mixed \\ 
%           % \hdashline
%           % \makecell{\textbf{Uni-I}\\(this work)}   & $3071$ & $\mathbf{-}$ & 21.2M & task level  & \cmark & \cmark \\ 
%          \bottomrule
%     \end{tabular}
%     \caption{A comparison of representative instruction tuning datasets of different instruction formats. ``Num.'', ``Cate.'', ``Exp.'', ``Inst.'',  refer to Number, Category, Example, and Instruction, respectively.
%     % ``--'' means the information is unknown or not applicable. ``Cate.Num'', ``Cate.'', ``Exp.'', ``Inst.'',  refer to Category Number, Category, Example, Instruction, respectively.
%     }
%     \label{tab:dataset_comparison}
% \end{table*}

\section{Related Work}
\paragraph{Instruction Tuning}

Instruction tuning regulates LLMs to accurately comprehend and interpret natural language instructions. Prior works in this field focus on reformulating NLP tasks using the templates of instructions. \citet{wei2021finetuned} pioneered to show that fine-tuning LLMs on large collections of tasks formatted in instructions enables the model to generalize to unseen tasks in a zero-shot manner. Since then, there has been a surge of interest in manually constructing high-quality instruction datasets by first reformulating the formats of existing NLP datasets and then merging them~\citep{mishra2022cross, bach2022promptsource, ye2021crossfit, ouyang2022training}. Another line of study~\citep{longpre2023flan,iyer2022opt} demonstrates that scaling the number of training tasks and task diversity can further enhance the model's generalization performance. However, all these works directly mix all the existing instruction datasets while ignoring the potential issue of format inconsistency. Instead of investigating the number and diversity of training instructions, we instead explore an under-explored facet, i.e., the instruction format of instruction tuning, and investigate its impact on generalization.

\paragraph{Data Augmentation}
Besides manually curating instruction tuning datasets, \citet{honovich2022unnatural} show that fine-tuning LLMs with machine-generated instruction tuning data achieves excellent performance compared with human-written data, indicating that data augmentation is an effective method to enhance the data quantity and task diversity, which overcomes the time-consuming issues of human annotation. Recently, \citet{alpaca, peng2023instruction, ding2023enhancing} adopt machine-annotation method~\citep{wang2022self} to generate real-world human instructions (rather than instructions that describe NLP tasks) and model responses based on powerful LLMs such as ChatGPT. Similarly, in this paper, we also leverage  LLMs for automatic format transfer and data augmentation. Since real-world instructions are quite diverse and hard to annotate their formats, we instead focus on instructions that describe NLP tasks to rigorously study the effects of instruction format. We believe the derived findings can potentially be applied to real-world instructions in the future.

\paragraph{Synthetic Data Denoising}
Generative models are commonly utilized for data augmentation~\citep{alpaca}. However, these synthetic datasets are not always as reliable as those human-annotated ones, and filtering out noisy examples can boost the model performance~\citep{le2020adversarial}. Recent studies have suggested different approaches for denoising. For instance, \citet{yang-etal-2020-generative,fang2022pseudoreasoner} adopted influence functions~\citep{koh2017understanding} to evaluate the quality of the synthetic data; \citet{wang-etal-2022-promda} employ the NLU Consistency Filtering~\citep{anaby2020not} to filter out low-quality samples.
In our research, we utilized LLMs for instruction format transfer, which may introduce noise throughout the process. To overcome this challenge, we adopted a simple and effective perplexity scoring strategy to denoise our auto-constructed dataset (\cref{denoising_method}).

\section{Instruction Format Inconsistency}


% Figure environment removed

As outlined in ~\citet{iyer2022opt}, existing instruction formats exhibit variations across different datasets, which can be classified into three distinct hierarchical levels: Task-level format, Instance-level format, and Keywords-level format (as illustrated in Figure~\ref{framework}). We present an overview of existing instruction tuning datasets based on instruction formats in Table~\ref{tab:dataset_comparison}. 

\begin{itemize}
    \item \textbf{Task-level Format} encompasses a comprehensive definition of a task and may include supplementary information such as positive or negative examples and explanations of the examples. Representative datasets are Ni-v2~\citep{wang2022super}, Unnatural Instructions ~\citep{honovich2022unnatural}, and Alpaca~\citep{alpaca}.

    \item \textbf{Instance-level Format} employs succinct templates that are customized for each individual example and is occasionally structured in a cloze-style format to elicit the intended output. Representative datasets are Flan~\citep{wei2021finetuned} and PromptSource~\citep{bach2022promptsource}.

    \item \textbf{Keywords-level Format} closely resembles the instance-level format, but it limits the instruction templates exclusively to keywords. CrossFit~\citep{ye2021crossfit} serves as a representative example of a keywords-level dataset.

\end{itemize}

Compared with task diversity, the effect of format consistency is poorly understood in instruction tuning. We contend that successful instruction understanding and generalization are influenced by both task diversity and format consistency. Task diversity can be enhanced by incorporating as many tasks into the training data (e.g., merging existing instruction tuning datasets) as possible. However, it is crucial to note that when merging different datasets for training, the training data originating from different sources often present variations in the instruction formats. When confronted with instructions of unseen inconsistent formats at the test time, the trained model may fail to generalize well and comprehend the intent behind different instructions, showing poor OOD generalization.

% \section{Format Transfer Framework}
\section{Framework and Experiments}
\label{sec:framework}
To mitigate format inconsistency, we propose a format transfer framework, \textit{Unified Instruction Tuning}~(UIT), to convert the instruction formats of existing datasets into a unified format. 

\subsection{Unified Instruction Format Transfer}
Denote the target unified instruction format as $\mathcal{F}_t$ and the original instruction format of a source dataset as $\mathcal{F}_s$, we aim to convert $\mathcal{F}_s$ into $\mathcal{F}_t$ to alleviate the OOD generalization in the instruction format.
Taking inspiration from \citet{honovich2022unnatural}, we rely on the LLM's in-context learning ability to conduct format transfer in an automatic manner.
%
Specifically, we manually select $k$ seed parallel data $\{[s_{1}, t_{1}], \cdots, [s_{k}, t_{k}]\}$, where $s_{i}$ and $t_{i}$ are the same instance (task) expressed in format $\mathcal{F}_s$ and $\mathcal{F}_t$ respectively.

Given a new instance $s_{new}$ with format $\mathcal{F}_s$, we transfer its instruction format into the unified instruction format $\mathcal{F}_t$ via in-context learning as follows:
\begin{equation}
% \small
\begin{aligned}
    % \mathcal{T}(S,I_\text{s}) &= I_\text{t},
    t_{new}=\text{LLM}\left(s_{new} , [s_{1},t_{1}], 
    \cdots, [s_{k},t_{k}] \right), 
\end{aligned}
\label{eq:ICL_seed}
\end{equation}
%
where $t_{new}$ refers to the transferred instance with $\mathcal{F}_t$.
%
We choose \texttt{text-davinci-003} (GPT3.5) as the LLM for format transfer.
%
Details of the prompt for format transfer are shown in Figure~\ref{ICL-construction}.

% Figure environment removed

\subsection{Experiments}
\label{sec:main_exp}
\paragraph{Settings}
To simulate the format inconsistency problem, we design two experimental settings:
%
\begin{itemize}
    \item \textbf{Testing-time Format Transfer}: the training data is formatted in $\mathcal{F}_t$, while the test data is formatted in $\mathcal{F}_s$. To mitigate the format inconsistency, we convert the instruction format of the test data into $\mathcal{F}_t$, without modifying the training data. 
    %
    This setting is designed to explore the format inconsistency impact between training data and the test data in the inference phase.
    
    \item \textbf{Training-time Format Transfer}: the training data is mixed with different formats (e.g., both $\mathcal{F}_s$ and $\mathcal{F}_t$), and the testing data is in the format of $\mathcal{F}_t$. Instead of modifying the testing data, here we convert the training data from format $\mathcal{F}_s$ to $\mathcal{F}_t$. 
    %
    This setting is designed to simulate the format inconsistency of different sources of the training data. % thereby allowing the model to concentrate on discerning genuine task differences instead of the instruction formats.
\end{itemize}
For both settings, we choose T5-LM-xl~\footnote{\url{https://huggingface.co/google/t5-xl-lm-adapt}} as our model and use Exact Match (EM) and Rouge-L as evaluation metrics. 

\paragraph{Datasets}

For the testing-time setting, we select Ni-v2~\citep{wang2022super} as the training dataset and use DiversePrompt~\citep{DBLP:journals/corr/abs-2205-10782}, Flan~\citep{wei2021finetuned}, CrossFit~\citep{ye-etal-2021-crossfit}, and PromptSource~\citep{bach2022promptsource} as the test dataset.
%
We evaluate the tasks that do not appear in the training stage. These tasks are the same as or similar to those in Ni-v2 test set.
%
In Ni-v2, the instruction format incorporates four components: (1) task definition (\textbf{D}), (2) positive example (\textbf{P}) for demonstration instances with the ground-truth label, (3) negative examples (\textbf{N}) for demonstration instances with a false label, and (4) explanations (\textbf{E}) that provide detailed explanations for the examples.
%
Different formats refer to distinct combinations of the above components.
%
For example, the \textbf{DP} format includes the task definition and positive examples information. 
%
In our experiments, we consider four primary formats, namely \textbf{DP}, \textbf{DPN}, \textbf{DPE}, and \textbf{DPNE} as the unified instruction format, respectively.

For the training-time setting, we use the training set of Ni-v2 together with Flan, CrossFit, and P3 respectively for training and use the test set of Ni-v2 for evaluation.
%
As Flan, CrossFit, and P3 may contain instances that exist in the test set of Ni-v2, to prevent data leakage, we filter the overlapped data in Flan, CrossFit, and P3 and use the remaining data for training. 
%
In this setting, we choose \textbf{DP} as the unified instruction format.

\paragraph{Baselines}

%
We construct two baselines:
%
(1) \textbf{Raw} does not involve any modifications on the instruction format for both training and testing. For instance, we directly test an instance from Flan in its original format using a model trained with Ni-v2 in \textbf{DPN} format. 
%
(2) \textbf{Heuristic} applies manually-designed rules to transfer different instruction formats into the unified one.
%
If the information from the original format matches the corresponding field in the unified format, we fill the unified format with that information. 
%
Otherwise, we leave the respective field in the unified format blank.
%
For instance, an instance from Flan can be transferred to the \textbf{DPE} format by leaving the \textit{Definition} and \textit{Explanations} fields blank and filling the \textit{Positive Examples} field with randomly selected instances from the Flan training set. 

% testing stage exp.
\begin{table*}[!htb]
  \centering
  \caption{\label{testing-time-main}
Testing-time format transfer experiment with four target unified instruction formats (\textbf{DP}, \textbf{DPE}, \textbf{DPN}, \textbf{DPNE}), respectively. We evaluate three methods: (1) raw instructions, transferred instructions based on (2) heuristic rules and (3) our proposed UIT. The training is conducted on Ni-v2 while the testing is conducted on DiversePrompt, FLAN, CrossFit, and PromptSource, respectively.}
  \vspace{1em} % One line space after the table title
  \resizebox{15.9cm}{3.0cm}{
    \begin{tabular}{l l cc cc cc cc >{\columncolor{shallowblue}}c >{\columncolor{shallowblue}}c}
    \toprule
    % \multicolumn{12}{c}{\textbf{Testing stage transfer (Ni-v2 as target dataset)}} \\
    % \midrule
    \multirow{2}*{\textbf{Format}} & \multirow{2}*{\textbf{Method}} & \multicolumn{2}{c}{\underline{\textbf{DiversePrompt}}} & \multicolumn{2}{c}{\underline{\textbf{FLAN}}} &\multicolumn{2}{c}{\underline{\textbf{CrossFit}}} &\multicolumn{2}{c}{\underline{\textbf{PromptSource}}}&\multicolumn{2}{>{\columncolor{shallowblue}}c}{\underline{\textbf{Average}}}\\
    & & EM & Rouge-L & EM & Rouge-L& EM & Rouge-L & EM & Rouge-L & EM & Rouge-L\\ 
    % \midrule
    % Avg on 4 benchmarks & heuristic & 34.3 & 44.6 & 33.1 & 43.8 & 33.9 & 44.8 & 33.4 & 44.1\\
    % Avg on 4 benchmarks & unified & \textbf{36.3} & \textbf{46.6} & \textbf{35.5} & \textbf{46.0} & \textbf{37.1} & \textbf{47.6} & \textbf{36.6} & \textbf{46.7}\\
    \midrule
  \multirow{3}{*}{DP}    & raw & $0.1$ & $4.7$ & $11.6$ & $20.8$ & $0.2$ & $3.9$ & $6.6$ & $13.6$ & $4.6$ & $10.8$\\
      & heuristic & $\textbf{34.7}$ & $45.1$ & $31.4$ & $44.8$ & $43.7$ & $56.0$ & $27.3$ & $32.7$ & $34.3$ & $44.6$\\
      & unified & $34.2$ & $\textbf{45.4}$ & $\textbf{32.6}$ & $\textbf{46.3}$ & $\textbf{49.1}$ & $\textbf{60.1}$ & $\textbf{29.2}$ & $\textbf{34.7}$ & $\textbf{36.3}$ & $\textbf{46.6}$\\
     \midrule
 \multirow{3}{*}{DPE}      & raw & $0.1$ & $5.0$ & $18.1$ & $27.8$ & $0.3$ & $4.4$ & $14.4$ & $19.2$ & $8.2$ & $14.1$\\
      & heuristic & $32.5$ & $43.4$ & $32.0$ & $45.3$ & $41.3$ & $54.2$ & $26.6$ & $31.1$ & $33.1$ & $43.8$\\
      & unified & $\textbf{32.9}$ & $\textbf{44.8}$ & $\textbf{33.5}$ & $\textbf{46.9}$ & $\textbf{46.9}$ & $\textbf{58.4}$ & $\textbf{27.8}$ & $\textbf{32.8}$ & $\textbf{35.5}$ & $\textbf{46.0}$\\
     \midrule
    % \midrule
  \multirow{3}{*}{DPN}     & raw & $0.2$ & $5.5$ & $12.0$ & $22.6$ & $0.2$ & $4.5$ & $5.3$ & $11.6$ & $4.4$ & $11.1$\\
     & heuristic & $30.6$ & $43.5$ & $31.9$ & $45.3$ & $43.5$ & $55.5$ & $29.0$ & $33.9$ & $33.9$ & $44.8$\\
     & unified & $\textbf{31.5}$ & $\textbf{44.3}$ & $\textbf{34.8}$ & $\textbf{48.3}$ & $\textbf{50.3}$ & $\textbf{60.4}$ & $\textbf{32.4}$ & $\textbf{38.3}$ & $\textbf{37.5}$ & $\textbf{48.2}$\\
    \midrule
   \multirow{3}{*}{DPNE}     & raw & $0.1$ & $5.2$ & $15.2$ & $25.3$ & $0.2$ & $3.8$ & $19.2$ & $23.7$ & $8.7$ & $14.5$\\
      & heuristic & $30.6$ & $43.4$ & $30.7$ & $43.6$ & $42.8$ & $54.6$ & $29.1$ & $33.7$ & $33.4$ & $44.1$\\
      & unified & $\textbf{32.2}$ & $\textbf{43.4}$ & $\textbf{35.0}$ & $\textbf{48.0}$ & $\textbf{48.6}$ & $\textbf{59.3}$ & $\textbf{29.8}$ & $\textbf{34.9}$ & $\textbf{36.6}$ & $\textbf{46.7}$\\
    % \midrule
    %  DP & heuristic & $\textbf{34.7}$ & $45.1$ & $31.4$ & $44.8$ & $43.7$ & $56.0$ & $27.3$ & $32.7$ & $34.3$ & $44.6$\\
    %  DPE & heuristic & $32.5$ & $43.4$ & $32.0$ & $45.3$ & $41.3$ & $54.2$ & $26.6$ & $31.1$ & $33.1$ & $43.8$\\
    % % \midrule
    % DPN & heuristic & $30.6$ & $43.5$ & $31.9$ & $45.3$ & $43.5$ & $55.5$ & $29.0$ & $33.9$ & $33.9$ & $44.8$\\
    %  DPNE & heuristic & $30.6$ & $43.4$ & $30.7$ & $43.6$ & $42.8$ & $54.6$ & $29.1$ & $33.7$ & $33.4$ & $44.1$\\
    % \midrule
    % DP & unified & $34.2$ & $\textbf{45.4}$ & $32.6$ & $46.3$ & $49.1$ & $60.1$ & $29.2$ & $34.7$ & $36.3$ & $46.6$\\
    % DPE & unified & $32.9$ & $44.8$ & $33.5$ & $46.9$ & $46.9$ & $58.4$ & $27.8$ & $32.8$ & $35.5$ & $46.0$\\
    % % \midrule
    % DPN & unified & $31.5$ & $44.3$ & $34.8$ & $\textbf{48.3}$ & $\textbf{50.3}$ & $\textbf{60.4}$ & $\textbf{32.4}$ & $\textbf{38.3}$ & $\textbf{37.5}$ & $\textbf{48.2}$\\
    % DPNE & unified & $32.2$ & $43.4$ & $\textbf{35.0}$ & $48.0$ & $48.6$ & $59.3$ & $29.8$ & $34.9$ & $36.6$ & $46.7$\\
    \bottomrule
    \end{tabular}%
    }

\end{table*}

\paragraph{Results and Analyses}
Testing-time format transfer results are shown in Table~\ref{testing-time-main}, and we find that: (1) transferring the instruction format either through the heuristic rule or our UIT significantly improves the performance than the vanilla baseline (i.e., raw), demonstrating the necessity of maintaining format consistency in instruction tuning; (2)  our UIT consistently outperforms the heuristic method across all benchmarks and almost all formats in Ni-v2. Compared with the heuristic method, UIT fully utilizes the semantic understanding and generation abilities of GPT3.5 to derive better transferred instructions; (3) the \textbf{DPN} format demonstrates the highest average performance and exhibits the largest improvements with UIT. 

Training-time format transfer results are shown in Table~\ref{training-time-main}, which shows that format transfer also brings performance improvements compared to raw baseline and performs slightly better than the heuristic method. This again demonstrates that UIT can improve the generalization performance by unifying the instruction format.
%
However, the improvements in the training-time setting are not as significant as those in the testing-time setting. We conjecture this may be because the format inconsistency issue is more evident in our testing-time setting than in the training-time setting. Overall, the results under both settings validate our hypothesis that mitigating the instruction format conduces to improved generalization.

\begin{table}[!t]
  \centering
  \caption{\label{training-time-main}
Training-time format transfer experiment with \textbf{DP} format. We compare our UIT with two baselines: raw instructions and instructions transferred by the heuristic rule. The training dataset is Ni-v2 combined with CrossFit, Flan, or P3.
}
\vspace{1em} % One line space after the table title
    \begin{tabular}{l cc cc cc >{\columncolor{shallowblue}}c >{\columncolor{shallowblue}}c}
    \toprule
    \multirow{2}*{\textbf{Method}} & \multicolumn{2}{c}{\underline{\textbf{+CrossFit}}} & \multicolumn{2}{c}{\underline{\textbf{+FLAN}}} & \multicolumn{2}{c}{\underline{\textbf{+P3}}} & \multicolumn{2}{>{\columncolor{shallowblue}}c}{\underline{\textbf{Average}}}
    \\
   & EM & Rouge-L &EM & Rouge-L &EM & Rouge-L &EM & Rouge-L\\ 
     \midrule
     raw & $37.5$ & $\textbf{56.0}$ & $38.4$ & $56.9$ & $38.8$ & $56.7$ & $38.2$ & $56.5$\\
    heuristic & $37.7$ & $55.9$ & $\textbf{38.9}$ & $57.4$ & $\textbf{39.9}$ & $\textbf{58.1}$ & $\textbf{38.8}$ & $\textbf{57.1}$\\
    unified & $\textbf{37.9}$ & $\textbf{56.0}$ & $\textbf{38.9}$ & $\textbf{57.5}$ & $39.4$ & $57.3$ & $38.7$ & $56.9$\\
    
    \bottomrule
    \end{tabular}%
\end{table}


% \begin{table}[!t]
%   \centering
%   % \resizebox{1.0\linewidth}{!}{
%   \caption{\label{training-time-main}
% Training-time format transfer experiment with \textbf{DP} format. We compare our UIT with two baselines: raw instructions and instructions transferred by the heuristic rule. The training dataset is Ni-v2 combined with CrossFit, Flan, or P3.
% }
%     \begin{tabular}{l cc cc cc cc}
%     \toprule
%     % \multicolumn{7}{c}{\textbf{Training stage Transfer (Ni-v2 as target dataset)}} \\
%     % \midrule
%     \multirow{2}*{\textbf{Method}} & \multicolumn{2}{c}{\textbf{+CrossFit}} & \multicolumn{2}{c}{\textbf{+FLAN}} & \multicolumn{2}{c}{\textbf{+P3}}\\
%                & EM & Rouge-L &EM & Rouge-L &EM & Rouge-L\\ 
%     % \midrule
%     %  \multicolumn{7}{l}{w.o. unknown} \\
%     %  \midrule
%     %  raw & $\textbf{38.0}$ & $\textbf{56.1}$ & $37.6$ & $55.8$ & $37.3$ & $54.9$\\
%     %  heuristic & $37.3$ & $55.7$ & $38.2$ & $56.5$ & $38.7$ & $56.9$\\
%     %  unified & $37.6$ & $55.9$ & $\textbf{38.4}$ & $\textbf{56.6}$ & $\textbf{38.9}$ & $\textbf{56.9}$\\
%     % \midrule
%      % \multicolumn{7}{l}{w. unknown} \\
%      \midrule
%      raw & $37.5$ & $\textbf{56.0}$ & $38.4$ & $56.9$ & $38.8$ & $56.7$\\
%      heuristic & $37.7$ & $55.9$ & $\textbf{38.9}$ & $57.4$ & $\textbf{39.9}$ & $\textbf{58.1}$\\
%      unified & $\textbf{37.9}$ & $\textbf{56.0}$ & $\textbf{38.9}$ & $\textbf{57.5}$ & $39.4$ & $57.3$\\
%     \bottomrule
%     \end{tabular}%
%     % }
    
% \end{table}

\paragraph{Limitations in Practice}
Despite the favorable performance, the proposed framework still has some limitations: first, automatic format transfer sometimes involves noise or even errors in the generated data, which may produce adverse effects; second, the proposed method heavily relies on OpenAI API calls, which entail substantial costs especially for large-scale instruction datasets. Both issues would limit UIT's real-world deployment. In the following, we discuss potential solutions for the above limitations by proposing a denoising strategy (\cref{denoising_method}) and training an offline transfer model (\cref{sec:offline_transfer}), respectively.

\section{Denoising for Format Transfer}
\label{denoising_method}


% During format transfer, we sample from the output distributions of LLMs. We find empirically that, with varying random seeds, the sampled generations could contain noise, e.g., some may contain errors like critical changes to task definition or hallucinatory restrictions. Intuitively, utilizing erroneous instructions would impair the model's generalization performance.

Empirically, transferring format via LLMs will introduce noise unavoidably. The transferred instances may contain errors like critical changes to task definition or hallucinatory restrictions. Intuitively, utilizing erroneous instructions would impair the model's generalization performance. To this end, we propose a perplexity-based denoising strategy to filter low-quality instances.

\paragraph{Perplexity-based Denoising Strategy}

Perplexity (PPL) is a widely used metric for evaluating the semantic coherence and certainty of language models. We assume that noisy instructions can reduce the certainty of LLMs in accurately predicting the correct output token sequence\footnote{We merely use the positive example (\textbf{P}) as mentioned in \cref{sec:main_exp} for noise assessment.}, leading to higher perplexity. As a result, perplexity serves as a useful metric for assessing the quality of transferred instructions. Hence, we propose to sample multiple times from LLM to obtain multiple transferred instructions. Then we calculate the perplexity for each instruction. Specifically, we concatenate the transferred instruction and the input query, then predict the annotated label and calculate its perplexity, and filter those with high perplexity.

We employ GPT3.5 with temperature $1.0$ to perform sampling for $N$ times with different random seeds, where $N$ is chosen from $\{1, 2, 4, 8, 16, 32\}$. Then, we sort the generated instructions based on perplexity using GPT-J~\citep{gpt-j} and select the sample with the lowest perplexity. We compare our method with the baseline that only samples once from GPT3.5. We conduct experiments on Ni-v2 and PromptSource under both the testing-time and training-time settings. For the former, we select the transferred instruction samples with the lowest perplexity; while for the latter, we incorporate multiple transferred results with lower perplexity as the training data.

\paragraph{Results}
As shown in figure~\ref{fig:denoising}, our proposed denoising strategy stably improves the performance at the testing time, and this improvement continues to increase when more instructions are sampled, which shows our method can successfully filter out those low-quality instructions to reduce noise during format transfer. In addition, the method can also improve performance in the training-time setting but the improvement is not more evident when more transferred instructions are included in the training data. It reveals that the model is less sensitive to noise during the training phase.

% \begin{table}[!t]
%   \centering
%   \caption{\label{tab:denoising}
% The performance of the denoising strategy at the testing and training time with different number of samples.}
% \vspace{1em} % One line space after the table title
% \begin{tabular}{c cc cc}
%     \toprule
%     \multirow{2}*{\textbf{Sample Num}} &\multicolumn{2}{c}{\textbf{Testing time}} 
%     &\multicolumn{2}{c}{\textbf{Training time}}\\
%      & EM & Rouge-L & EM & Rouge-L \\ 
%     \midrule
%     1 & 32.4 & 38.3 & 37.4 & 56.1\\
%     2 & 33.0 & 38.9 & \textbf{39.4} & \textbf{57.6}\\
%     4 & 33.5 & 39.4 & 38.2 & 56.5\\
%     8 & 33.7 & 39.7 & 38.8 & 57.0\\
%     16 & \textbf{33.8} & \textbf{39.8} & 38.5 & 56.3\\
%     \bottomrule
% \end{tabular}
% \end{table}


% Figure environment removed

% \begin{table}[!t]
%   \centering
%   \caption{\label{tab:denoising}
% The performance of the denoising strategy at the testing and training time with different number of samples.}
%   \small
%     \begin{tabular}{c cc cc}
%     \toprule
%     \multirow{2}*{\textbf{Sample Num}} &\multicolumn{2}{c}{\textbf{Testing time}} 
%     &\multicolumn{2}{c}{\textbf{Training time}}\\
%      & EM & Rouge-L & EM & Rouge-L \\ 
%     \midrule
%     1 & $32.4$ & $38.3$ & $37.4$ & $56.1$\\
%     2 & $33.0$ & $38.9$ & $\textbf{39.4}$ & $\textbf{57.6}$\\
%     4 & $33.5$ & $39.4$ & $38.2$ & $56.5$\\
%     8 & $33.7$ & $39.7$ & $38.8$ & $57.0$\\
%     16 & $\textbf{33.8}$ & $\textbf{39.8}$ & $38.5$ & $56.3$\\

%     \bottomrule
%     \end{tabular}
    
% \end{table}

\section{Training Offline Model for Format Transfer}
\label{sec:offline_transfer}

Converting large-scale instructions via OpenAI API can cause substantial costs for API calls. To alleviate the reliance on OpenAI API, it is necessary to derive an offline model that has comparable format transfer performance to GPT3.5 but involves fewer costs. Hence we propose to distill the format transfer ability of GPT3.5 into small-scale models.

\paragraph{Fine-tuned Offline Model with Knowledge Distillation}
Compared with larger models, small offline models are less capable of completing format transfer directly through in-context learning without training. Therefore, we strive to enhance small-scale models via knowledge distillation~\citep{hinton2015distilling}. In pursuit of higher quality, we always make GPT3.5 convert the relatively complex and informative instruction format (e.g., Ni-v2) into a simpler and less informative one (e.g., PromptSource). In this way, we obtain parallel data and use it to fine-tune GPT-J for format transfer. We use the generated PromptSource-style instructions as the source and the original Ni-v2 instructions as the target to construct a dataset of approximately 3,000 instances. To assess the quality of GPT-J's transfer results, we compare them with the heuristic baseline and GPT3.5's conversion results in the testing-time setting with two formats (\textbf{DP} and \textbf{DPN}).

\begin{table*}[!htb]
  \centering
  \caption{\label{tab: local_conversion}
Results of training an offline model (GPT-J) for format transfer at testing time. We compare the transferred instructions using heuristic rules, GPT3.5, or our fine-tuned GPT-J. Other settings are similar to those in Table~\ref{testing-time-main}.}
\vspace{1em} % One line space after the table title
\resizebox{16.2cm}{1.8cm}{
\begin{tabular}{ll cc cc cc cc>{\columncolor{shallowblue}}c@{~~~}>{\columncolor{shallowblue}}c}
    \toprule
    \multirow{2}*{\textbf{Format}} & \multirow{2}*{\textbf{Method}} & \multicolumn{2}{c}{\underline{\textbf{DiversePrompt}}} & \multicolumn{2}{c}{\underline{\textbf{Flan}}} &\multicolumn{2}{c}{\underline{\textbf{CrossFit}}} &\multicolumn{2}{c}{\underline{\textbf{PromptSource}}} &\multicolumn{2}{>{\columncolor{shallowblue}}c}{\underline{\textbf{Average}}}\\
    & & EM & Rouge-L & EM & Rouge-L& EM & Rouge-L & EM & Rouge-L & EM & Rouge-L\\ 
    \midrule
 \multirow{3}{*}{DP}       & heuristic & $34.7$ & $45.1$ & $31.4$ & $44.8$ & $43.7$ & $56.0$ & $27.3$ & $32.7$ & $34.3$ & $44.6$\\
    & GPT3.5 & $34.2$ & $45.4$ & $32.6$ & $46.3$ & $\textbf{49.1}$ & $\textbf{60.1}$ & $29.2$ & $34.7$ & $\textbf{36.3}$ & $\textbf{46.6}$\\
    & GPT-J & $\textbf{35.2}$ & $\textbf{45.6}$ & $\textbf{33.5}$ & $\textbf{46.6}$ & $43.6$ & $54.5$ & $\textbf{31.6}$ & $\textbf{36.4}$ & $36.0$ & $45.8$\\
    \midrule
  \multirow{3}{*}{DPN}    & heuristic & $30.6$ & $43.5$ & $31.9$ & $45.3$ & $43.5$ & $55.5$ & $29.0$ & $33.9$ & $33.9$ & $44.8$\\
    & GPT3.5 & $31.5$ & $44.3$ & $\textbf{34.8}$ & $48.3$ & $\textbf{50.3}$ & $\textbf{60.4}$ & $30.8$ & $36.1$ & $\textbf{37.1}$ & $\textbf{47.6}$\\
    & GPT-J & $\textbf{34.7}$ & $\textbf{45.7}$ & $\textbf{34.8}$ & $\textbf{48.4}$ & $46.0$ & $55.5$ & $\textbf{31.4 }$& $\textbf{36.5}$ & $36.7$ & $46.5$\\
    
    % \midrule
    % DP & GPT3.5 & 34.2 & 45.4 & 32.6 & 46.3 & 49.1 & 60.1 & 29.2 & 34.7 & 36.3 & 46.6\\
    % DPN & GPT3.5 & 31.5 & 44.3 & \textbf{34.8} & 48.3 & \textbf{50.3} & \textbf{60.4} & 30.8 & 36.1 & \textbf{37.1} & \textbf{47.6}\\
    % \midrule
    % DP & GPT-J & \textbf{35.2} & 45.6 & 33.5 & 46.6 & 43.6 & 54.5 & \textbf{31.6} & 36.4 & 36.0 & 45.8\\
    % DPN & GPT-J & 34.7 & \textbf{45.7} & \textbf{34.8} & \textbf{48.4} & 46.0 & 55.5 & 31.4 & \textbf{36.5} & 36.7 & 46.5\\
    \bottomrule
\end{tabular}
}
\end{table*}


% \begin{table*}[!htb]
%   \centering
%   \caption{\label{tab: local_conversion}
% Results of training an offline model (GPT-J) for format transfer at testing time. We compare the transferred instructions using heuristic rules, GPT3.5, or our fine-tuned GPT-J. Other settings are similar to those in Table~\ref{testing-time-main}.}
%   \small
%     \begin{tabular}{l@{~~~}l@{~~~}c@{~~~}c@{~~~}c@{~~~}c@{~~~}c@{~~~}c@{~~~}c@{~~~}c@{~~~}c@{~~~}c}
%     \toprule
%     % \multicolumn{12}{c}{\textbf{Offline Transfer at Testing time (Ni-v2 as target dataset)}} \\
%     % \midrule
%     \multirow{2}*{\textbf{Format}} & \multirow{2}*{\textbf{Method}} & \multicolumn{2}{c}{\textbf{DiversePrompt}} & \multicolumn{2}{c}{\textbf{Flan}} &\multicolumn{2}{c}{\textbf{CrossFit}} &\multicolumn{2}{c}{\textbf{PromptSource}} &\multicolumn{2}{c}{\textbf{Average}}\\
%     & & EM & Rouge-L & EM & Rouge-L& EM & Rouge-L & EM & Rouge-L & EM & Rouge-L\\ 
%     % \midrule
%     % Avg on 4 benchmarks & heuristic & 34.3 & 44.6 & 33.1 & 43.8 & 33.9 & 44.8 & 33.4 & 44.1\\
%     % Avg on 4 benchmarks & unified & \textbf{36.3} & \textbf{46.6} & \textbf{35.5} & \textbf{46.0} & \textbf{37.1} & \textbf{47.6} & \textbf{36.6} & \textbf{46.7}\\
%     \midrule
%      DP & heuristic & $34.7$ & $45.1$ & $31.4$ & $44.8$ & $43.7$ & $56.0$ & $27.3$ & $32.7$ & $34.3$ & $44.6$\\

%     DPN & heuristic & $30.6$ & $43.5$ & $31.9$ & $45.3$ & $43.5$ & $55.5$ & $29.0$ & $33.9$ & $33.9$ & $44.8$\\
    
%     \midrule
%     DP & GPT3.5 & $34.2$ & $45.4$ & $32.6$ & $46.3$ & $49.1$ & $60.1$ & $29.2$ & $34.7$ & $36.3$ & $46.6$\\

%     DPN & GPT3.5 & $31.5$ & $44.3$ & $\textbf{34.8}$ & $48.3$ & $\textbf{50.3}$ & $\textbf{60.4}$ & $30.8$ & $36.1$ & $\textbf{37.1}$ & $\textbf{47.6}$\\

%     \midrule
%     DP & GPT-J & $\textbf{35.2}$ & $45.6$ & $33.5$ & $46.6$ & $43.6$ & $54.5$ & $\textbf{31.6}$ & $36.4$ & $36.0$ & $45.8$\\

%     DPN & GPT-J & $34.7$ & $\textbf{45.7}$ & $\textbf{34.8}$ & $\textbf{48.4}$ & $46.0$ & $55.5$ & $31.4$ & $\textbf{36.5}$ & $36.7$ & $46.5$\\

%     \bottomrule
%     \end{tabular}%
    
% \end{table*}

\paragraph{Results}
As exhibited in Table \ref{tab: local_conversion}, 
the fine-tuned GPT-J performs much better than the heuristic baseline but slightly worse than GPT3.5. This shows that our method can distill the format transfer ability into small-scale models, which saves the costs in practice. Additionally, the performance is highly correlated with the similarity of the source and target formats. For instance, for DiversePrompt whose instruction format is similar to the target format, the transfer process is less challenging. As a result, the fine-tuned model demonstrates comparable or even superior performance than GPT3.5. Conversely, for CrossFit which only describes keywords and lacks natural language instructions, it is more difficult for small models to produce high-quality instructions, resulting in inferior performance.

\section{Further Analysis}



% Figure environment removed


% \begin{table}[!t]
%   \centering
%   \caption{\label{flan-test-exp}
% Testing time transfer experiment results when Flan is selected as the target dataset and Ni-v2 as the source dataset. Transferring Ni-v2 to the target format brings significant performance improvements during inference when training is conducted with target format.
% }
% \vspace{1em} % One line space after the table title
% \begin{tabular}{ccccc}
%     \toprule
%     \textbf{Source} & \textbf{Target} & \textbf{Method} &EM & Rouge-L\\ 
%     \midrule
%      Ni-v2 & Flan & heuristic & 18.4 & 28.3\\
%      Ni-v2 & Flan & unified & \textbf{29.3} & \textbf{43.0} \\
%     \bottomrule
% \end{tabular}
% \end{table}




\paragraph{Effects of the Target Unified Format}
In previous experiments, we mainly use Ni-v2 as the target instruction format. To verify the versatility of UIT for various target instruction formats, we select Flan, an instance-level dataset as the target dataset and conduct testing-time transfer experiments. Results are shown in Figure~\ref{fig: flan-test-exp}, from which we find that testing-time format transfer brings even more significant performance improvements than the scenario when Ni-v2 is selected as target dataset.
This again validates our hypothesis that format consistency is essential to OOD generalization for instruction tuning, no matter which target format is.

\paragraph{Effects of Model Scaling} 
As observed in previous works~\citep{iyer2022opt}, larger models tend to perform better in following human instructions.
We also conduct model scaling experiments in the testing-time setting with T5~\citep{DBLP:journals/jmlr/RaffelSRLNMZLL20}, with the model size ranging from $5$ million (T5-small) to $10$ billion (T5-XXL).
Results presented in Figure~\ref{fig:testing_scaling} demonstrate that in general, the performance tends to improve as the model size increases. 
% While this general trend is evident across the board, some variation is observed between the performance of large and X-large models. Specifically, the gap in performance between XX-large(11B) and  X-large models is noticeably larger than the gap observed among small, base, and large models. 
% These findings suggest that UIT may be better suited for training on larger models, as it has the potential to more effectively leverage the increased computational power afforded by these larger architectures. Indeed, the observed performance gains for T5-LM models as they increase in size meet the expectation of scalability results in the Large language models.
These findings suggest that instruction format consistency is consistently essential to language models of various sizes.

\begin{table}[!t]
  \centering
  \caption{\label{format-task-ablation}
Experiments for task diversity and format consistency. For task diversity, we set the training dataset to \texttt{src}+\texttt{same}, \texttt{src}+\texttt{diff} or \texttt{src}+\texttt{same}+\texttt{diff}. For format consistency, we either use the raw format or use the unified format.
}
\vspace{1em} % One line space after the table title
\begin{tabular}{l cc cc cc cc}
    \toprule
    \textbf{Method} & \multicolumn{2}{c}{\texttt{src}+\texttt{same}} & \multicolumn{2}{c}{\texttt{src}+\texttt{diff}} & \multicolumn{2}{c}{\texttt{src}+\texttt{same}+\texttt{diff}}\\
               & EM & Rouge-L &EM & Rouge-L & EM & Rouge-L\\ 
    \midrule
     raw & 29.3 & 46.3 & 28.3 & 45.3 & 29.1 & 45.8 \\
     unified & 30.8 & 47.6 & 30.7 & 47.7 & \textbf{31.0} & \textbf{47.8} \\
    \bottomrule
\end{tabular}
\end{table}

% \begin{table}[!t]
%   \centering
%   \resizebox{7.65cm}{0.95cm}{
%     \begin{tabular}{l cc cc cc cc}
%     \toprule
%     % \multicolumn{7}{c}{\textbf{Training time transfer (DP as target format)}} \\
%     % \midrule
%     \textbf{Method} & \multicolumn{2}{c}{\texttt{src}+\texttt{same}} & \multicolumn{2}{c}{\texttt{src}+\texttt{diff}} & \multicolumn{2}{c}{\texttt{src}+\texttt{same}+\texttt{diff}}\\
%                & EM & Rouge-L &EM & Rouge-L & EM & Rouge-L\\ 
%     \midrule
%      raw & $29.3$	& $46.3$ & $28.3$	& $45.3$ & $29.1$ & $45.8$ \\
%      % heuristic &
%      unified & $30.8$	& $47.6$ & $30.7$	& $47.7$ & $\textbf{31.0}$ & $\textbf{47.8}$\\
%     \bottomrule
%     \end{tabular}%
%     }
%     \caption{\label{format-task-ablation}
% Experiments for task diversity and format consistency. For task diversity, we set the training dataset to \texttt{src}+\texttt{same}, \texttt{src}+\texttt{diff} or \texttt{src}+\texttt{same}+\texttt{diff}. For format consistency, we either use the raw format or use the unified format.
% }
% \end{table}


%  In Table \ref{testing-time-main}, we can see that our unified policy functioning well. Our unified policy results outperform all baseline models among all instruction settings (DP, DEP, etc.). In average, we see that DPN outperforms other instruction formats among different datasets testing. And thus, we chose ..., as our final unified instuction format for uni-I. 
% The experimental results presented in Table \ref{unified-exp} provide compelling evidence for the effectiveness of our proposed unified policy. Across all instruction settings (DP, DPE, etc.), our unified policy consistently outperforms all baseline models, proving the importance of our approach in enabling improved performance across a broad range of tasks. Notably, our analysis reveals that the DPN instruction format consistently outperforms other instruction formats across different datasets, suggesting that this instruction format is particularly well-suited for use with our Uni-I dataset. Based on these results, we have selected the DPN instruction format as our final choice for Uni-I, as we believe it represents the best balance between performance and versatility for our purposes. 

\paragraph{Task Diversity v.s. Format Consistency}
We show that both task diversity and format consistency have impacts on the generalization performance for instruction tuning.
As task diversity can only be a variable during the training stage, we only conduct training-time transfer experiments.
Specifically, we choose Ni-v2 as the target dataset with \textbf{DP} as target format and P3 as the source dataset.
We first randomly select $20$ tasks from Ni-v2 (denoted as \texttt{src}). Then we choose the same $20$ training tasks from P3, denoted as \texttt{same}, and $20$ different tasks from P3, which is denoted as \texttt{diff}.
We treat whether to integrate \texttt{same} or \texttt{diff} to the training set (\texttt{src}) as a variable and evaluate on the original Ni-v2 test set.

As shown in Table~\ref{format-task-ablation}, no matter which tasks are chosen as the training data, our UIT always performs better than the vanilla baseline (raw), which again demonstrates the importance of format consistency.
We can also observe that without format unification, \texttt{src}+\texttt{same} performs better than \texttt{src}+\texttt{diff}, which indicates that increasing task diversity may be inferior without format consistency.
Besides, \texttt{source}+\texttt{same}+\texttt{diff} with UIT performs the best among all combinations, suggesting that increasing task diversity and maintaining format consistency at the same time is the best practice for merging datasets in instruction tuning. We believe this finding can guide practitioners to better prepare the datasets for instruction tuning in the future.

\section{Conclusion}
% In this paper, our unified instruction-tuning framework (UIT) provides a standardized approach to enhancing the generalization ability for instruction tuning by unifying the format of existing instruction tuning datasets and enabling format transfer between them with LLMs like GPT-3.5. Our approach has been tested on various datasets such as PromptSource, FLAN and CrossFit. The method has shown improvements (9.3\% in Exact Match, 7.6\% in Rouge-L) on T5-LM-xl. We also propose a denoising method and an offline model training method to make our UIT more feasible in practice.
In this paper, we propose the unified instruction-tuning framework (UIT), a standardized approach to enhancing the generalization ability for instruction tuning by unifying the format of existing instruction tuning datasets and enabling format transfer between them with LLMs like GPT-3.5. With the framework, we (1) exhibit the significance of format consistency in instruction tuning; (2) enhance the generalization performance (9.3\% in Exact Match, 7.6\% in Rouge-L) on various datasets such as PromptSource, FLAN and CrossFit on T5-LM-xl; (3) propose a denoising method and an offline model training method to make our UIT more feasible in practice.


In general, we study an under-explored facet, i.e., the format consistency, for instruction tuning, and we hope our work could facilitate more attempts in relevant areas.
 
\section{Limitation}
While our proposed UIT framework and format transferer offer a promising approach to enhancing the generalization performance of instruction-tuned LLMs, several limitations should be acknowledged. Firstly, our method relies on the assumption that the user knows the target instruction format in advance, which may not always be the case. Secondly, we focus on instruction tuning for NLP tasks, instead of broader settings (e.g., real-world instructions~\citep{alpaca,vicuna2023}) where formats are hard to define. We expect future works to explore whether our UIT framework can be applied to broader scenarios.

\section*{Acknowledgement}
This work is supported by the National Natural Science Foundation of China (Grant No. 62306159).

\bibliography{main}
\bibliographystyle{tmlr}

\appendix

\clearpage
\section*{Appendices}
\label{sec:appendix}

\section{Case Study}
We list some examples of our format transfer process in this section. You can find examples of \textbf{D}efintion, \textbf{P}ositive examples, \textbf{N}egative examples and \textbf{E}xplanation in these cases.

% Figure removed

% Figure removed


% \begin{tcolorbox}[width=\textwidth,
%                   %%enhanced,
%                   %%frame hidden,
%                   interior hidden,
%                   boxsep=0pt,
%                   left=6pt,
%                   right=6pt,
%                   ]%%
% {\color{blue} \textbf{\texttt{Transferring from P3 to Ni-v2 (Task: trec):}}}

% {\color{red} \textbf{\texttt{Instruction:}}}
% \begin{markdown}
% You are given a sentence that contains a question and a possible answer type. Your task is to identify the correct answer type from the suggested options. You may need to read the sentence and its context carefully in order to determine the correct answer type.
% \end{markdown}

% {\color{orange} \textbf{\texttt{Positive Examples: }}}

% \begin{markdown}
% **Input:** What do bee hives do in cranberry bogs ?\nIs this asking about Description, Entity, Abbreviation, Person, Quantity, Location?

% **Output:** Description

% **Explanation:** The question is asking for a description of what bee hives do in cranberry bogs. So the correct answer type is Description.

% \end{markdown}

% {\color{orange} \textbf{\texttt{Negative Examples: }}}
% \\
% \begin{markdown}
% **Input:** What golfing accessory was patented by George Grant on December 12\nIs this asking about Description, Entity, Abbreviation, Person, Quantity, Location?

% **Output:** Quantity

% **Explanation:** The sentence is asking about a golfing accessory. These types of questions typically require an answer about an entity (i.e. a specific object or thing), so the correct answer type is 'Entity' rather than 'Quantity'.
% \end{markdown}


% {\color{black} \rule{\linewidth}{0.2mm}}

% {\color{blue} \textbf{\texttt{Original P3(trec):}}}

% {\color{red} \textbf{\texttt{Instruction: }}}
% \begin{markdown}
% {Input}\n\nDescriptors: Description, Entity, Abbreviation, Person, Quantity, Location\n\nBest Descriptor?\n
% \end{markdown}

% {\color{orange} \textbf{\texttt{Positive Examples: }}}

% \begin{markdown}

% **Input:** What do bee hives do in cranberry bogs ?\n

% **Output:** \nDescription

% \end{markdown}

% \end{tcolorbox}

% % examples for flan to ni-v2x
% \begin{tcolorbox}[width=\textwidth,
%                   %%enhanced,
%                   %%frame hidden,
%                   interior hidden,
%                   boxsep=0pt,
%                   left=6pt,
%                   right=6pt,
%                   ]%%
% {\color{blue} \textbf{\texttt{Transferring from Flan to Ni-v2 (Task: wsc):}}}

% {\color{red} \textbf{\texttt{Instruction:}}}
% \begin{markdown}
% In this task, you are given two sentences (sentence 1 and sentence 2). If sentence 1 implies that sentence 2 is true, answer "Yes", otherwise "No".
% \end{markdown}

% {\color{orange} \textbf{\texttt{Positive Examples: }}}

% \begin{markdown}
% **Input:** sentence 1: As Ollie carried Tommy up the long winding steps, his legs ached. sentence 2: Tommy's legs ached. options: - no - yes.

% **Output:** no

% **Explanation:** The sentence 1 does not imply that Tommy's legs ached. So, the output should be "No".

% \end{markdown}

% {\color{orange} \textbf{\texttt{Negative Examples: }}}
% \\
% \begin{markdown}
% **Input:** Sentence 1: Paul couldn't find his car keys, so he had to walk. Sentence 2: Paul had to walk.

% **Output:** Yes

% **Explanation:** Sentence 1 implies that sentence 2 is true, so the correct output should be "Yes".
% \end{markdown}


% {\color{black} \rule{\linewidth}{0.2mm}}

% {\color{blue} \textbf{\texttt{Original Flan(wsc):}}}

% {\color{red} \textbf{\texttt{Instruction: }}}
% \begin{markdown}
% If "{sentence1}", can we conclude that "{sentence2}"\n{options_}
% \end{markdown}

% {\color{orange} \textbf{\texttt{Positive Examples: }}}

% \begin{markdown}

% **Input:** If "As Ollie carried Tommy up the long winding steps, his legs ached.", can we conclude that "Tommy's legs ached."\n\nOPTIONS:\n- no\n- yes.

% **Output:** no

% \end{markdown}

% \end{tcolorbox}


% % examples for crossfit to ni-v2
% \clearpage
% \begin{tcolorbox}[width=\textwidth,
%                   %%enhanced,
%                   %%frame hidden,
%                   interior hidden,
%                   boxsep=0pt,
%                   left=6pt,
%                   right=6pt,
%                   ]%%
% {\color{blue} \textbf{\texttt{Transferring from CrossFit to Ni-v2 (Task: imdb):}}}

% {\color{red} \textbf{\texttt{Instruction:}}}
% \begin{markdown}
% You are given a sentence or a paragraph describing a particular topic. Your task is to classify the sentiment of the sentence/paragraph as either negative or positive. Label the sentiment in the output as per the given parameters without incorporating any additional information into your answer.
% \end{markdown}

% {\color{orange} \textbf{\texttt{Positive Examples: }}}

% \begin{markdown}
% **Input:** I am a big fan of Faerie Tale Theatre and I've seen them all and this is one of the best! It's funny, romantic, and a classic. I recommend this for all ages. It's great for little kids because it's well, Cinderella and great for adults and teens because it's funny and not over the top. I watched it when I was little and I still watch it now. It has great lines that my family and I quote all the time. The acting is great and it never gets old. If you like fairy tales and romances you will love this. I've watched many a Cinderella movie in my time and this is the best of them all. (Sorry Disney) I highly recommend this movie and all the Faerie Tale Theatre shows. They all appeal to all ages and are all unique and very entertaining.

% **Output:** positive

% **Explanation:** The sentence describes a very positive opinion on the chosen topic. The opinion is supported by facts, like the uniqueness of the show, its lasting values, great acting, and so on. Hence, the sentiment of the sentence is classified as positive.

% \end{markdown}

% {\color{orange} \textbf{\texttt{Negative Examples: }}}
% \\
% \begin{markdown}
% **Input:** I know a few things that are worst. A few. It had a couple of funny scenes. It is a movie not appropriate for kids but, only a child would find this movie hilarious. This is definitely a movie that you would like to use a free rental coupon for. Don't waste your money just to laugh a couple of times.

% **Output:** Positive

% **Explanation:** The given sentence is mainly negative in nature as it suggests not to waste money on the movie. The words \"definetly\" and \"a couple of funny scenes\" are used in the sentence to provide a bit of contrast, yet it does not make the overall sentiment of the sentence positive. Therefore, the correct answer should be \"negative\" instead of \"positive\".
% \end{markdown}


% {\color{black} \rule{\linewidth}{0.2mm}}

% {\color{blue} \textbf{\texttt{Original CrossFit(imdb):}}}

% {\color{red} \textbf{\texttt{Instruction: }}}
% \begin{markdown}

% \end{markdown}

% {\color{orange} \textbf{\texttt{Positive Examples: }}}

% \begin{markdown}

% **Input:** I am a big fan of Faerie Tale Theatre and I've seen them all and this is one of the best! It's funny, romantic, and a classic. I recommend this for all ages. It's great for little kids because it's well, Cinderella and great for adults and teens because it's funny and not over the top. I watched it when I was little and I still watch it now. It has great lines that my family and I quote all the time. The acting is great and it never gets old. If you like fairy tales and romances you will love this. I've watched many a Cinderella movie in my time and this is the best of them all. (Sorry Disney) I highly recommend this movie and all the Faerie Tale Theatre shows. They all appeal to all ages and are all unique and very entertaining.

% **Output:** positive

% \end{markdown}

% \end{tcolorbox}


% % examples for ni-v2 to flan
% \begin{tcolorbox}[width=\textwidth,
%                   %%enhanced,
%                   %%frame hidden,
%                   interior hidden,
%                   boxsep=0pt,
%                   left=6pt,
%                   right=6pt,
%                   ]%%
% {\color{blue} \textbf{\texttt{Transferring from Ni-v2 to Flan (Task: dialogre):}}}

% {\color{red} \textbf{\texttt{Instruction:}}}
% \begin{markdown}
% {input} Identify the name of one of the speakers in the given dialog.
% \end{markdown}

% {\color{black} \rule{\linewidth}{0.2mm}}

% {\color{blue} \textbf{\texttt{Original Ni-v2(dialogre):}}}

% {\color{red} \textbf{\texttt{Instruction: }}}
% \begin{markdown}
% You are given a dialog between 2 or more individuals. Within the dialog, there will be clues as to the names of the speakers. You will be asked at the end of the dialog to identify the name of one of the speakers.
% \end{markdown}
% \end{tcolorbox}

\section{Detailed Results of the Denoising Strategy}
\label{app:B}

This is the detailed results of the performance of the denoising strategy with different number of samples. 

\begin{table}[!t]
  \centering
  \caption{\label{tab:denoising}
The performance of the denoising strategy at the testing and training time with different numbers of samples.}
\vspace{1em} % One line space after the table title
\begin{tabular}{c cc cc}
    \toprule
    \multirow{2}*{\textbf{Sample Num}} &\multicolumn{2}{c}{\textbf{Testing time}} 
    &\multicolumn{2}{c}{\textbf{Training time}}\\
     & EM & Rouge-L & EM & Rouge-L \\ 
    \midrule
    1 & 32.4 & 38.3 & 37.4 & 56.1\\
    2 & 33.0 & 38.9 & \textbf{39.4} & \textbf{57.6}\\
    4 & 33.5 & 39.4 & 38.2 & 56.5\\
    8 & 33.7 & 39.7 & 38.8 & 57.0\\
    16 & \textbf{33.8} & \textbf{39.8} & 38.5 & 56.3\\
    \bottomrule
\end{tabular}
\end{table}

\section{Results with Flan Selected as the Target Dataset}
\label{app:C}

This is the detailed results of Testing time transfer experiment results when Flan is selected as the target dataset and Ni-v2 as the source dataset. 

\begin{table}[h]
  \centering
  \caption{\label{flan-test-exp}
Testing time transfer experiment results when Flan is selected as the target dataset and Ni-v2 as the source dataset. Transferring Ni-v2 to the target format brings significant performance improvements during inference when training is conducted with target format.
}
\vspace{1em} % One line space after the table title
\begin{tabular}{ccccc}
    \toprule
    \textbf{Source} & \textbf{Target} & \textbf{Method} &EM & Rouge-L\\ 
    \midrule
     Ni-v2 & Flan & heuristic & 18.4 & 28.3\\
     Ni-v2 & Flan & unified & \textbf{29.3} & \textbf{43.0} \\
    \bottomrule
\end{tabular}
\end{table}


\section{Seed Data}

\noindent\makebox[\linewidth]{\rule{\linewidth}{0.4pt}}
\\
\textbf{Example 1}

\textbf{Task description A}: Review: \{sentence\} Is this movie review sentence negative or positive? \{options\_\}

\textbf{Task description B}: In this task, you are given sentences from movie reviews. The task is to classify a sentence as "POS" if the sentiment of the sentence is positive or as "NEG" if the sentiment of the sentence is negative

\textbf{Positive examples}: Input b positive 1: It 's a lovely film with lovely performances by Buy and Accorsi.
Output b positive 1: POS
\textbf{Explanation} b positive 1: The sentiment of the sentence is positive. Hence, the label is 'POS'.

Input b positive 2: Here's yet another studio horror franchise mucking up its storyline with glitches casual fans could correct in their sleep.
Output b positive 2: NEG
\textbf{Explanation} b positive 2: The sentiment of the sentence is negative. Hence, the label is 'NEG'.

\textbf{Negative examples}: Input b negative 1: A smart, witty follow-up.
Output b negative 1: NEG
\textbf{Explanation} b negative 1: Although the sentiment of the sentence is positive, the label is 'NEG'. Hence, the label should be 'POS'.

Input b negative 2: Ultimately feels empty and unsatisfying, like swallowing a Communion wafer without the wine.
Output b negative 2: POS
\textbf{Explanation} b negative 2: Although the sentiment of the sentence is positive, the label is 'POS'. Hence, the label should be 'NEG'.


\textbf{Example 2}

\textbf{Task description A}: \{question1\} \{question2\} Would you say that these questions are the same? \{options\_\}

\textbf{Task description B}: Here are two questions (Question1 and Question2). If these questions have the same meaning and same answer, answer "Yes", otherwise "No".

\textbf{Positive examples}: Input b positive 1: Question1: How do I get into my Instagram if I forgot my email and my Facebook password?, Question2: I forgot my password and also my email password. how can I get back that account?
Output b positive 1: Yes
\textbf{Explanation} b positive 1: These questions have the meaning and the same answer. So, the output should be "Yes".

Input b positive 2: Question1: Why don't Hong Kong residents emigrate from their cramped \& stressful city, like to places such as Australia?, Question2: Why made Hong Kong so attractive to Britain as a colony given that it was the last of Britain's colonies and Britain does not profit from taxing Hong Kong?
Output b positive 2: No
\textbf{Explanation} b positive 2: The first question is about the emigration of Hong Kong residents and the second question is about the attraction of Hong Kong. So, they don't have the same meaning.

\textbf{Negative examples}: Input b negative 1: Question1: Why are there so many accidents on I-880?, Question2: Were there accidents in outer space?
Output b negative 1: Yes
\textbf{Explanation} b negative 1: Question1 asks about the cause of the accidents, while question2 inquires about their existence. So, they are different and the correct output should be "No".

Input b negative 2: Question1: How do you determine the number of neutrons of an element or its ion?, Question2: How do you find the number of neutrons in an element? What are some examples?
Output b negative 2: They are the same.
\textbf{Explanation} b negative 2: Note that you need to answer with "Yes" or "No" and other answers are not acceptable.

\textbf{Example 3}

\textbf{Task description A}: \{context\} Generate a question about the above context.

\textbf{Task description B}: Based on the given context, craft a common-sense question, especially those that are LONG, INTERESTING, and COMPLEX. The goal is to write questions that are easy for humans and hard for AI machines! To create such questions, here are some suggestions: A. What may (or may not) be the plausible reason for an event? B. What may (or may not) happen before (or after, or during) an event? C. What may (or may not) be a plausible fact about someone (or something)? D. What may (or may not) happen if an event happens (or did not happen)? You can also create other types of questions. DO NOT make your question answerable without looking at the context, or question of which the correct answer can be directly extracted from the context. DO NOT ask a question that requires very specialized knowledge that is not common sense. DO NOT ask too simple or too short questions. Your question must be related to the context and answerable with common sense. Try to add more variations and complexity to the questions.

\textbf{Positive examples}: Input b positive 1: Context: I was told, in person over the phone, that my shoes were on their way. They have my money. I have no shoes.
Output b positive 1: What may happen before I called them?
\textbf{Explanation} b positive 1: The question can not be answered directly from context and requires commonsense.

Input b potitive 2: Context: you see , at my age relationship is kind of important and i thought i got the one after all these years . I noticed that once again i was wrong . i was good simply because i was good , i was caring , helping , supportive , bla bla blaaa .
Output b potitive 2: What may happen to me?
\textbf{Explanation} b positive 2: The question can not be answered directly from context and requires commonsense.

\textbf{Negative examples}: Input b negative 1: Context: I was told, in person over the phone, that my shoes were on their way. They have my money. I have no shoes.
Output b negative 1: What is on the way to my home?
\textbf{Explanation} b negative 1: It can be directly answered with a span of the context and does not require any commonsense reasoning.

Input b negative 2: Context: GPS technology dates back to the time when first ever satellite was launched in the sky in 1979. The era of global positioning started then.
Output b negative 2: What was launched in the sky in 1979?
\textbf{Explanation} b negative 2: It can be directly answered with a span of the context and does not require any commonsense reasoning.
 \\
{\rule{\linewidth}{0.4pt}}

\section{Model Implementation Details}
The hyper-parameters for training include a maximum source data length of 1024, a maximum target data length of 128, a cap of 100 instances per task for both training and evaluation, a batch size of 16 for training, a learning rate of 0.00001, a total of 2 training epochs, linear learning rate scheduling, and a warm-up period consisting of 1000 steps.

% examples for adding cot in ni-v2
% \begin{tcolorbox}[width=\textwidth,
%                   %%enhanced,
%                   %%frame hidden,
%                   interior hidden,
%                   boxsep=0pt,
%                   left=6pt,
%                   right=6pt,
%                   ]%%
% {\color{blue} \textbf{\texttt{Ni-v2 with COT(doqa):}}}

% {\color{red} \textbf{\texttt{Instruction:}}}
% \begin{markdown}
% Given a paragraph about cooking, and a set of conversational question answers about the paragraph, generate a relevant question to the topic of the paragraph. The paragraph has the prefix 'CONTEXT:'. Each conversation question has a prefix `Q:` followed by the answer prefix `A:`.
% \end{markdown}

% {\color{orange} \textbf{\texttt{Positive Examples: }}}

% \begin{markdown}
% **Input:** CONTEXT: It not huge, it's just the difference from freezer to room temperature you are worrying aboutE.g. -20Â°C to 20Â°C, is A 40Â°C shift. The shift was going to be 20Â°C to 100Â°C anyway. There is no physical reasons why this would be anymore stressfulFrom room temperature you are raising it 80Â°C, from frozen you are raising it 120Â°C. Not a problem in the normal temperature range for glassThe freezing temperature of water (most common item in food) has no relation to the freezing temperature of glass etc Pyrex and other glasses can be damaged if one part of them is instantly heated or cooled by a 100Â°C or so. <sep> Q: Is it safe to microwave Pyrex containers immediately after removing them from the freezer and removing the plastic lid? A: Pyrex and other glasses can be damaged if one part of them is instantly heated or cooled by a 100Ã‚Â°C or so.

% **Output:** Do you think they will they shatter?

% **Explanation:** This is a valid question as it is a follow-up question of the conversation regaring whether pyrex and other glasses (refered to as they) will shatter or not on microwaving immediately after removing them from the freezer.

% **Chain-of-Thoughts:** The conversation questions are about microwaving Pyrex containers after removing them from the freezer. The answer to the question states that Pyrex and other glasses can be damaged if one part of them is instantly heated or cooled by a 100Â°C or so. <<Can be damaged -> Shatter>> Therefore, the relevant question to the topic of the paragraph is \"Do you think they will they shatter?\".

% \end{markdown}


% \end{tcolorbox}



% \clearpage
% % examples for denoising with ppl scoring
% \begin{tcolorbox}[width=\textwidth,
%                   %%enhanced,
%                   %%frame hidden,
%                   interior hidden,
%                   boxsep=0pt,
%                   left=6pt,
%                   right=6pt,
%                   ]%%
% {\color{blue} \textbf{\texttt{Denoising with Perplexity Scoring: }}}

% {\color{red} \textbf{\texttt{Sample 1:}}}
% \begin{markdown}
% You are given questions about various topics and asked to provide the correct answers. The questions could relate to geographical facts, biographical information, cultural data, dates, and more. The answers should be accurate and detailed enough to provide a complete understanding of the question.
% \end{markdown}

% {\color{orange} \textbf{\texttt{Perplexity Score:}}}
% \begin{markdown}
% 3.97
% \end{markdown}
% \\

% {\color{red} \textbf{\texttt{Sample 2:}}}
% \begin{markdown}
% You are given a question in the input. Your task is to find the corresponding answer to the question. Depending on the complexity of the answer, the output can be in the form of a text string or a URL link to a web page with more detailed information.
% \end{markdown}

% {\color{orange} \textbf{\texttt{Perplexity Score:}}}
% \begin{markdown}
% 7.28
% \end{markdown}
% \\

% {\color{red} \textbf{\texttt{Sample 3:}}}
% \begin{markdown}
% You are provided with a question in the input. Your task is to provide the correct answer to the given question. Make sure that the answer is accurate, relevant and specific.
% \end{markdown}

% {\color{orange} \textbf{\texttt{Perplexity Score:}}}
% \begin{markdown}
% 3.69
% \end{markdown}
% \\

% {\color{red} \textbf{\texttt{Sample 4:}}}
% \begin{markdown}
% You are given a question in the input. Your task is to provide a correct answer to that question based on the knowledge you have. The output should be a short, direct and accurate response to the given question.
% \end{markdown}

% {\color{orange} \textbf{\texttt{Perplexity Score:}}}
% \begin{markdown}
% 4.15
% \end{markdown}

% \end{tcolorbox}


% \clearpage


% Denoising testing time experiment
% \begin{table*}[!htb]
%   \centering
%     \begin{tabular}{l l cc}
%     \toprule
%     \multicolumn{4}{c}{\textbf{Train on Ni-v2, Denoising at Testing Time}} \\
%     \midrule
%     \textbf{Benchmark} & \textbf{Method} & \multicolumn{2}{c}{\textbf{\underline{DPN}}} \\
%     & & EM & Rouge-L\\ 
  
%     \midrule
%     PromptSource & conventional & 30.8 & 36.1\\
%     PromptSource & denoising, sample scale = 2 & 33.0 & 38.9\\
%     PromptSource & denoising, sample scale = 4 & 33.5 & 39.4\\
%     PromptSource & denoising, sample scale = 8 & 33.7 & 39.7\\
%     PromptSource & denoising, sample scale = 16 & 33.8 & 39.8\\
%     PromptSource & denoising, sample scale = 32 & \textbf{34.0} & \textbf{40.0}\\
  
%     \bottomrule
%     \end{tabular}%
%     \caption{\label{testing-time-denoise}
% Results during testing time with denoising strategy of different sampling scales on PromptSource. Other experiment setting is consistent with testing time in experiemnt1.
% }
% \end{table*}


% % testing time scaling exp em.
% % Figure environment removed

% % testing time scaling exp rougel.
% % Figure environment removed

% % Ni-v2 and Crossfit task numbers exp em.
% % Figure environment removed

% % Ni-v2 and Crossfit task numbers exp rougel.
% % Figure environment removed

% Human evaluation.
% \begin{table}[!htb]
%   \centering
%     \begin{tabular}{l c c c c}
%     \toprule
%     \textbf{Item} & \textbf{crossfit} & \textbf{p3} & \textbf{flan} & \textbf{avg}\\
%     \midrule
%      def. correctness & $88$ & $89$ & $100$ & $92$\\
%      def. alignment & $75$ & $73$ & $88$ & $79$ \\
%      pos. explanation & $83$ & $87$ & $91$ & $87$ \\
%      neg. example & $54$ & $51$ & $21$ & $42$ \\
%      neg. explanation & $47$ & $53$ & $24$ & $41$\\
%     \bottomrule
%     \end{tabular}%
%     \caption{\label{human-evaluation}
% Human evaluation results before denoising.
% }
% \end{table}


% % Figure environment removed


% \section{General formatting instructions}
% \label{gen_inst}

% The text must be confined within a rectangle 6.5~inches wide and
% 9~inches long. The left margin is 1~inch.
% Use 10~point type with a vertical spacing of 11~points. Computer Modern Bright is the
% preferred typeface throughout. Paragraphs are separated by 1/2~line space,
% with no indentation.

% Paper title is 17~point, in bold and left-aligned.
% All pages should start at 1~inch from the top of the page.

% Authors' names are
% set in boldface. Each name is placed above its corresponding
% address and has its corresponding email contact on the same line, in italic 
% and right aligned. The lead author's name is to be listed first, and
% the co-authors' names are set to follow vertically.

% Please pay special attention to the instructions in section \ref{others}
% regarding figures, tables, acknowledgments, and references.

% \section{Headings: first level}
% \label{headings}

% First level headings are in bold,
% flush left and in point size 12. One line space before the first level
% heading and 1/2~line space after the first level heading.

% \subsection{Headings: second level}

% Second level headings are in bold,
% flush left and in point size 10. One line space before the second level
% heading and 1/2~line space after the second level heading.

% \subsubsection{Headings: third level}

% Third level headings are in bold,
% flush left and in point size 10. One line space before the third level
% heading and 1/2~line space after the third level heading.

% \section{Citations, figures, tables, references}
% \label{others}

% These instructions apply to everyone, regardless of the formatter being used.

% \subsection{Citations within the text}

% Citations within the text should be based on the \texttt{natbib} package
% and include the authors' last names and year (with the ``et~al.'' construct
% for more than two authors). When the authors or the publication are
% included in the sentence, the citation should not be in parenthesis, using \verb|\citet{}| (as
% in ``See \citet{Hinton06} for more information.''). Otherwise, the citation
% should be in parenthesis using \verb|\citep{}| (as in ``Deep learning shows promise to make progress
% towards AI~\citep{Bengio+chapter2007}.'').

% The corresponding references are to be listed in alphabetical order of
% authors, in the \textbf{References} section. As to the format of the
% references themselves, any style is acceptable as long as it is used
% consistently.

% \subsection{Footnotes}

% Indicate footnotes with a number\footnote{Sample of the first footnote} in the
% text. Place the footnotes at the bottom of the page on which they appear.
% Precede the footnote with a horizontal rule of 2~inches.\footnote{Sample of the second footnote}

% \subsection{Figures}

% All artwork must be neat, clean, and legible. Lines should be dark
% enough for purposes of reproduction; art work should not be
% hand-drawn. The figure number and caption always appear after the
% figure. Place one line space before the figure caption, and one line
% space after the figure. The figure caption is lower case (except for
% first word and proper nouns); figures are numbered consecutively.

% Make sure the figure caption does not get separated from the figure.
% Leave sufficient space to avoid splitting the figure and figure caption.

% You may use color figures.
% However, it is best for the
% figure captions and the paper body to make sense if the paper is printed
% either in black/white or in color.
% % Figure environment removed

% \subsection{Tables}

% All tables must be centered, neat, clean and legible. Do not use hand-drawn
% tables. The table number and title always appear before the table. See
% Table~\ref{sample-table}. Place one line space before the table title, one line space after the table
% title, and one line space after the table. The table title must be lower case
% (except for first word and proper nouns); tables are numbered consecutively.

% \begin{table}[t]
% \caption{Sample table title}
% \label{sample-table}
% \begin{center}
% \begin{tabular}{ll}
% \multicolumn{1}{c}{\bf PART}  &\multicolumn{1}{c}{\bf DESCRIPTION}
% \\ \hline \\
% Dendrite         &Input terminal \\
% Axon             &Output terminal \\
% Soma             &Cell body (contains cell nucleus) \\
% \end{tabular}
% \end{center}
% \end{table}

% \section{Default Notation}

% In an attempt to encourage standardized notation, we have included the
% notation file from the textbook, \textit{Deep Learning}
% \cite{goodfellow2016deep} available at
% \url{https://github.com/goodfeli/dlbook_notation/}.  Use of this style
% is not required and can be disabled by commenting out
% \texttt{math\_commands.tex}.


% \centerline{\bf Numbers and Arrays}
% \bgroup
% \def\arraystretch{1.5}
% \begin{tabular}{p{1in}p{3.25in}}
% $\displaystyle a$ & A scalar (integer or real)\\
% $\displaystyle \va$ & A vector\\
% $\displaystyle \mA$ & A matrix\\
% $\displaystyle \tA$ & A tensor\\
% $\displaystyle \mI_n$ & Identity matrix with $n$ rows and $n$ columns\\
% $\displaystyle \mI$ & Identity matrix with dimensionality implied by context\\
% $\displaystyle \ve^{(i)}$ & Standard basis vector $[0,\dots,0,1,0,\dots,0]$ with a 1 at position $i$\\
% $\displaystyle \text{diag}(\va)$ & A square, diagonal matrix with diagonal entries given by $\va$\\
% $\displaystyle \ra$ & A scalar random variable\\
% $\displaystyle \rva$ & A vector-valued random variable\\
% $\displaystyle \rmA$ & A matrix-valued random variable\\
% \end{tabular}
% \egroup
% \vspace{0.25cm}

% \centerline{\bf Sets and Graphs}
% \bgroup
% \def\arraystretch{1.5}

% \begin{tabular}{p{1.25in}p{3.25in}}
% $\displaystyle \sA$ & A set\\
% $\displaystyle \R$ & The set of real numbers \\
% $\displaystyle \{0, 1\}$ & The set containing 0 and 1 \\
% $\displaystyle \{0, 1, \dots, n \}$ & The set of all integers between $0$ and $n$\\
% $\displaystyle [a, b]$ & The real interval including $a$ and $b$\\
% $\displaystyle (a, b]$ & The real interval excluding $a$ but including $b$\\
% $\displaystyle \sA \backslash \sB$ & Set subtraction, i.e., the set containing the elements of $\sA$ that are not in $\sB$\\
% $\displaystyle \gG$ & A graph\\
% $\displaystyle \parents_\gG(\ervx_i)$ & The parents of $\ervx_i$ in $\gG$
% \end{tabular}
% \vspace{0.25cm}


% \centerline{\bf Indexing}
% \bgroup
% \def\arraystretch{1.5}

% \begin{tabular}{p{1.25in}p{3.25in}}
% $\displaystyle \eva_i$ & Element $i$ of vector $\va$, with indexing starting at 1 \\
% $\displaystyle \eva_{-i}$ & All elements of vector $\va$ except for element $i$ \\
% $\displaystyle \emA_{i,j}$ & Element $i, j$ of matrix $\mA$ \\
% $\displaystyle \mA_{i, :}$ & Row $i$ of matrix $\mA$ \\
% $\displaystyle \mA_{:, i}$ & Column $i$ of matrix $\mA$ \\
% $\displaystyle \etA_{i, j, k}$ & Element $(i, j, k)$ of a 3-D tensor $\tA$\\
% $\displaystyle \tA_{:, :, i}$ & 2-D slice of a 3-D tensor\\
% $\displaystyle \erva_i$ & Element $i$ of the random vector $\rva$ \\
% \end{tabular}
% \egroup
% \vspace{0.25cm}


% \centerline{\bf Calculus}
% \bgroup
% \def\arraystretch{1.5}
% \begin{tabular}{p{1.25in}p{3.25in}}
% % NOTE: the [2ex] on the next line adds extra height to that row of the table.
% % Without that command, the fraction on the first line is too tall and collides
% % with the fraction on the second line.
% $\displaystyle\frac{d y} {d x}$ & Derivative of $y$ with respect to $x$\\ [2ex]
% $\displaystyle \frac{\partial y} {\partial x} $ & Partial derivative of $y$ with respect to $x$ \\
% $\displaystyle \nabla_\vx y $ & Gradient of $y$ with respect to $\vx$ \\
% $\displaystyle \nabla_\mX y $ & Matrix derivatives of $y$ with respect to $\mX$ \\
% $\displaystyle \nabla_\tX y $ & Tensor containing derivatives of $y$ with respect to $\tX$ \\
% $\displaystyle \frac{\partial f}{\partial \vx} $ & Jacobian matrix $\mJ \in \R^{m\times n}$ of $f: \R^n \rightarrow \R^m$\\
% $\displaystyle \nabla_\vx^2 f(\vx)\text{ or }\mH( f)(\vx)$ & The Hessian matrix of $f$ at input point $\vx$\\
% $\displaystyle \int f(\vx) d\vx $ & Definite integral over the entire domain of $\vx$ \\
% $\displaystyle \int_\sS f(\vx) d\vx$ & Definite integral with respect to $\vx$ over the set $\sS$ \\
% \end{tabular}
% \egroup
% \vspace{0.25cm}

% \centerline{\bf Probability and Information Theory}
% \bgroup
% \def\arraystretch{1.5}
% \begin{tabular}{p{1.25in}p{3.25in}}
% $\displaystyle P(\ra)$ & A probability distribution over a discrete variable\\
% $\displaystyle p(\ra)$ & A probability distribution over a continuous variable, or over
% a variable whose type has not been specified\\
% $\displaystyle \ra \sim P$ & Random variable $\ra$ has distribution $P$\\% so thing on left of \sim should always be a random variable, with name beginning with \r
% $\displaystyle  \E_{\rx\sim P} [ f(x) ]\text{ or } \E f(x)$ & Expectation of $f(x)$ with respect to $P(\rx)$ \\
% $\displaystyle \Var(f(x)) $ &  Variance of $f(x)$ under $P(\rx)$ \\
% $\displaystyle \Cov(f(x),g(x)) $ & Covariance of $f(x)$ and $g(x)$ under $P(\rx)$\\
% $\displaystyle H(\rx) $ & Shannon entropy of the random variable $\rx$\\
% $\displaystyle \KL ( P \Vert Q ) $ & Kullback-Leibler divergence of P and Q \\
% $\displaystyle \mathcal{N} ( \vx ; \vmu , \mSigma)$ & Gaussian distribution %
% over $\vx$ with mean $\vmu$ and covariance $\mSigma$ \\
% \end{tabular}
% \egroup
% \vspace{0.25cm}

% \centerline{\bf Functions}
% \bgroup
% \def\arraystretch{1.5}
% \begin{tabular}{p{1.25in}p{3.25in}}
% $\displaystyle f: \sA \rightarrow \sB$ & The function $f$ with domain $\sA$ and range $\sB$\\
% $\displaystyle f \circ g $ & Composition of the functions $f$ and $g$ \\
%   $\displaystyle f(\vx ; \vtheta) $ & A function of $\vx$ parametrized by $\vtheta$.
%   (Sometimes we write $f(\vx)$ and omit the argument $\vtheta$ to lighten notation) \\
% $\displaystyle \log x$ & Natural logarithm of $x$ \\
% $\displaystyle \sigma(x)$ & Logistic sigmoid, $\displaystyle \frac{1} {1 + \exp(-x)}$ \\
% $\displaystyle \zeta(x)$ & Softplus, $\log(1 + \exp(x))$ \\
% $\displaystyle || \vx ||_p $ & $\normlp$ norm of $\vx$ \\
% $\displaystyle || \vx || $ & $\normltwo$ norm of $\vx$ \\
% $\displaystyle x^+$ & Positive part of $x$, i.e., $\max(0,x)$\\
% $\displaystyle \1_\mathrm{condition}$ & is 1 if the condition is true, 0 otherwise\\
% \end{tabular}
% \egroup
% \vspace{0.25cm}



% \section{Final instructions}
% Do not change any aspects of the formatting parameters in the style files.
% In particular, do not modify the width or length of the rectangle the text
% should fit into, and do not change font sizes (except perhaps in the
% \textbf{References} section; see below). Please note that pages should be
% numbered.

% \section{Preparing PostScript or PDF files}

% Please prepare PostScript or PDF files with paper size ``US Letter'', and
% not, for example, ``A4''. The -t
% letter option on dvips will produce US Letter files.

% Consider directly generating PDF files using \verb+pdflatex+
% (especially if you are a MiKTeX user).
% PDF figures must be substituted for EPS figures, however.

% Otherwise, please generate your PostScript and PDF files with the following commands:
% \begin{verbatim}
% dvips mypaper.dvi -t letter -Ppdf -G0 -o mypaper.ps
% ps2pdf mypaper.ps mypaper.pdf
% \end{verbatim}

% \subsection{Margins in LaTeX}

% Most of the margin problems come from figures positioned by hand using
% \verb+\special+ or other commands. We suggest using the command
% \verb+\includegraphics+
% from the graphicx package. Always specify the figure width as a multiple of
% the line width as in the example below using .eps graphics
% \begin{verbatim}
%    \usepackage[dvips]{graphicx} ...
%    % Figure removed
% \end{verbatim}
% or % Apr 2009 addition
% \begin{verbatim}
%    \usepackage[pdftex]{graphicx} ...
%    % Figure removed
% \end{verbatim}
% for .pdf graphics.
% See section~4.4 in the graphics bundle documentation (\url{http://www.ctan.org/tex-archive/macros/latex/required/graphics/grfguide.ps})

% A number of width problems arise when LaTeX cannot properly hyphenate a
% line. Please give LaTeX hyphenation hints using the \verb+\-+ command.

% \subsubsection*{Broader Impact Statement}
% In this optional section, TMLR encourages authors to discuss possible repercussions of their work,
% notably any potential negative impact that a user of this research should be aware of. 
% Authors should consult the TMLR Ethics Guidelines available on the TMLR website
% for guidance on how to approach this subject.

% \subsubsection*{Author Contributions}
% If you'd like to, you may include a section for author contributions as is done
% in many journals. This is optional and at the discretion of the authors. Only add
% this information once your submission is accepted and deanonymized. 

% \subsubsection*{Acknowledgments}
% Use unnumbered third level headings for the acknowledgments. All
% acknowledgments, including those to funding agencies, go at the end of the paper.
% Only add this information once your submission is accepted and deanonymized. 

% \appendix
% \section{Appendix}
% You may include other additional sections here.

\end{document}
