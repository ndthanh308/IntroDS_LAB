\begin{thebibliography}{}

\bibitem[\protect\citeauthoryear{Agarwal \bgroup \em et al.\egroup
  }{2019}]{agarwal2019reinforcement}
Alekh Agarwal, Nan Jiang, Sham~M Kakade, and Wen Sun.
\newblock {\em {Reinforcement Learning: Theory and Algorithms}}.
\newblock CS Department, UW Seattle, Seattle, WA, USA, 2019.

\bibitem[\protect\citeauthoryear{Almgren and Chriss}{1999}]{almgren1999value}
Robert Almgren and Neil Chriss.
\newblock Value under liquidation.
\newblock {\em Risk}, 12(12):61--63, 1999.

\bibitem[\protect\citeauthoryear{Almgren and Chriss}{2001}]{almgren2001optimal}
Robert Almgren and Neil Chriss.
\newblock Optimal execution of portfolio transactions.
\newblock {\em Journal of Risk}, 3:5--40, 2001.

\bibitem[\protect\citeauthoryear{Arjovsky \bgroup \em et al.\egroup
  }{2019}]{arjovsky2019invariant}
Martin Arjovsky, L{\'e}on Bottou, Ishaan Gulrajani, and David Lopez-Paz.
\newblock Invariant risk minimization.
\newblock {\em arXiv preprint arXiv:1907.02893}, 2019.

\bibitem[\protect\citeauthoryear{Azar \bgroup \em et al.\egroup
  }{2013}]{azar2013minimax}
Mohammad~Gheshlaghi Azar, R{\'e}mi Munos, and Hilbert~J Kappen.
\newblock {Minimax PAC bounds on the sample complexity of reinforcement
  learning with a generative model}.
\newblock {\em Machine Learning}, 91(3):325--349, 2013.

\bibitem[\protect\citeauthoryear{Bulthuis \bgroup \em et al.\egroup
  }{2017}]{bulthuis2017optimal}
Brian Bulthuis, Julio Concha, Tim Leung, and Brian Ward.
\newblock Optimal execution of limit and market orders with trade director,
  speed limiter, and fill uncertainty.
\newblock {\em International Journal of Financial Engineering}, 4(1):175--200,
  2017.

\bibitem[\protect\citeauthoryear{Byrd \bgroup \em et al.\egroup
  }{2019}]{byrd2019abides}
David Byrd, Maria Hybinette, and Tucker~Hybinette Balch.
\newblock {ABIDES: Towards high-fidelity market simulation for AI research}.
\newblock {\em arXiv preprint arXiv:1904.12066}, 2019.

\bibitem[\protect\citeauthoryear{Cobbe \bgroup \em et al.\egroup
  }{2019}]{cobbe2019quantifying}
Karl Cobbe, Oleg Klimov, Chris Hesse, Taehoon Kim, and John Schulman.
\newblock Quantifying generalization in reinforcement learning.
\newblock In {\em International Conference on Machine Learning}, pages
  1282--1289. PMLR, 2019.

\bibitem[\protect\citeauthoryear{Cobbe \bgroup \em et al.\egroup
  }{2020}]{cobbe2020leveraging}
Karl Cobbe, Chris Hesse, Jacob Hilton, and John Schulman.
\newblock Leveraging procedural generation to benchmark reinforcement learning.
\newblock In {\em International conference on machine learning}, pages
  2048--2056. PMLR, 2020.

\bibitem[\protect\citeauthoryear{Cummings and
  Frino}{2010}]{cummings2010further}
James~Richard Cummings and Alex Frino.
\newblock Further analysis of the speed of response to large trades in interest
  rate futures.
\newblock {\em Journal of Futures Markets: Futures, Options, and Other
  Derivative Products}, 30(8):705--724, 2010.

\bibitem[\protect\citeauthoryear{Dab{\'e}rius \bgroup \em et al.\egroup
  }{2019}]{daberius2019deep}
Kevin Dab{\'e}rius, Elvin Granat, and Patrik Karlsson.
\newblock Deep execution-value and policy based reinforcement learning for
  trading and beating market benchmarks.
\newblock {\em Available at SSRN 3374766}, 2019.

\bibitem[\protect\citeauthoryear{Degryse \bgroup \em et al.\egroup
  }{2005}]{degryse2005aggressive}
Hans Degryse, Frank~De Jong, Maarten~Van Ravenswaaij, and Gunther Wuyts.
\newblock Aggressive orders and the resiliency of a limit order market.
\newblock {\em Review of Finance}, 9(2):201--242, 2005.

\bibitem[\protect\citeauthoryear{Dietterich \bgroup \em et al.\egroup
  }{2018}]{dietterich2018discovering}
Thomas Dietterich, George Trimponias, and Zhitang Chen.
\newblock Discovering and removing exogenous state variables and rewards for
  reinforcement learning.
\newblock In {\em International Conference on Machine Learning}, pages
  1262--1270. PMLR, 2018.

\bibitem[\protect\citeauthoryear{Du \bgroup \em et al.\egroup
  }{2019}]{du2019provably}
Simon Du, Akshay Krishnamurthy, Nan Jiang, Alekh Agarwal, Miroslav Dudik, and
  John Langford.
\newblock {Provably efficient RL with rich observations via latent state
  decoding}.
\newblock In {\em Proceedings of the 36th International Conference on Machine
  Learning}, pages 1665--1674. PMLR, 2019.

\bibitem[\protect\citeauthoryear{Fang \bgroup \em et al.\egroup
  }{2021}]{fang2021universal}
Yuchen Fang, Kan Ren, Weiqing Liu, Dong Zhou, Weinan Zhang, Jiang Bian, Yong
  Yu, and Tie-Yan Liu.
\newblock Universal trading for order execution with oracle policy
  distillation.
\newblock In {\em Proceedings of the AAAI Conference on Artificial
  Intelligence}, volume~35, pages 107--115, 2021.

\bibitem[\protect\citeauthoryear{Gomber \bgroup \em et al.\egroup
  }{2015}]{gomber2015liquidity}
Peter Gomber, Uwe Schweickert, and Erik Theissen.
\newblock {Liquidity dynamics in an electronic open limit order book: An event
  study approach}.
\newblock {\em European Financial Management}, 21(1):52--78, 2015.

\bibitem[\protect\citeauthoryear{Gu{\'e}ant \bgroup \em et al.\egroup
  }{2012}]{gueant2012optimal}
Olivier Gu{\'e}ant, Charles-Albert Lehalle, and Joaquin Fernandez-Tapia.
\newblock Optimal portfolio liquidation with limit orders.
\newblock {\em SIAM Journal on Financial Mathematics}, 3(1):740--764, 2012.

\bibitem[\protect\citeauthoryear{Kirk \bgroup \em et al.\egroup
  }{2021}]{kirk2021survey}
Robert Kirk, Amy Zhang, Edward Grefenstette, and Tim Rockt{\"a}schel.
\newblock A survey of generalisation in deep reinforcement learning.
\newblock {\em arXiv preprint arXiv:2111.09794}, 2021.

\bibitem[\protect\citeauthoryear{Lin and Beling}{2020}]{lin2020deep}
Siyu Lin and Peter~A Beling.
\newblock A deep reinforcement learning framework for optimal trade execution.
\newblock In {\em Joint European Conference on Machine Learning and Knowledge
  Discovery in Databases}, pages 223--240. Springer, 2020.

\bibitem[\protect\citeauthoryear{Lin and Beling}{2021}]{lin2020end}
Siyu Lin and Peter~A Beling.
\newblock An end-to-end optimal trade execution framework based on proximal
  policy optimization.
\newblock In {\em Proceedings of the Twenty-Ninth International Conference on
  International Joint Conferences on Artificial Intelligence}, pages
  4548--4554, 2021.

\bibitem[\protect\citeauthoryear{Mao \bgroup \em et al.\egroup
  }{2017}]{mao2017neural}
Hongzi Mao, Ravi Netravali, and Mohammad Alizadeh.
\newblock Neural adaptive video streaming with pensieve.
\newblock In {\em Proceedings of the Conference of the ACM Special Interest
  Group on Data Communication}, pages 197--210, 2017.

\bibitem[\protect\citeauthoryear{Mao \bgroup \em et al.\egroup
  }{2018}]{mao2018variance}
Hongzi Mao, Shaileshh~Bojja Venkatakrishnan, Malte Schwarzkopf, and Mohammad
  Alizadeh.
\newblock Variance reduction for reinforcement learning in input-driven
  environments.
\newblock In {\em International Conference on Learning Representations}, 2018.

\bibitem[\protect\citeauthoryear{Nevmyvaka \bgroup \em et al.\egroup
  }{2006}]{nevmyvaka2006reinforcement}
Yuriy Nevmyvaka, Yi~Feng, and Michael Kearns.
\newblock Reinforcement learning for optimized trade execution.
\newblock In {\em Proceedings of the 23rd international conference on Machine
  Learning}, pages 673--680. PMLR, 2006.

\bibitem[\protect\citeauthoryear{Ning \bgroup \em et al.\egroup
  }{2018}]{ning2018double}
Brian Ning, Franco Ho~Ting Lin, and Sebastian Jaimungal.
\newblock {Double deep Q-learning for optimal execution}.
\newblock {\em arXiv preprint arXiv:1812.06600}, 2018.

\bibitem[\protect\citeauthoryear{Oroojlooyjadid \bgroup \em et al.\egroup
  }{2022}]{oroojlooyjadid2022deep}
Afshin Oroojlooyjadid, MohammadReza Nazari, Lawrence~V Snyder, and Martin
  Tak{\'a}{\v{c}}.
\newblock {A deep Q-network for the beer game: Deep reinforcement learning for
  inventory optimization}.
\newblock {\em Manufacturing \& Service Operations Management}, 24(1):285--304,
  2022.

\bibitem[\protect\citeauthoryear{Packer \bgroup \em et al.\egroup
  }{2018}]{packer2018assessing}
Charles Packer, Katelyn Gao, Jernej Kos, Philipp Kr{\"a}henb{\"u}hl, Vladlen
  Koltun, and Dawn Song.
\newblock Assessing generalization in deep reinforcement learning.
\newblock {\em arXiv preprint arXiv:1810.12282}, 2018.

\bibitem[\protect\citeauthoryear{Perold}{1988}]{perold1988implementation}
A.~F. Perold.
\newblock {The implementation shortfall: Paper vs. reality}.
\newblock {\em Journal of Portfolio Management}, 14(3):4--9, 1988.

\bibitem[\protect\citeauthoryear{Shahamiri}{2008}]{shahamiriname2008reinforcement}
Masoud Shahamiri.
\newblock Reinforcement learning in environments with independent delayed-sense
  dynamics.
\newblock {\em Master Thesis, University of Alberta}, 2008.

\bibitem[\protect\citeauthoryear{Shen \bgroup \em et al.\egroup
  }{2020}]{shen2020auxiliary}
Wei Shen, Xiaonan He, Chuheng Zhang, Qiang Ni, Wanchun Dou, and Yan Wang.
\newblock Auxiliary-task based deep reinforcement learning for participant
  selection problem in mobile crowdsourcing.
\newblock In {\em Proceedings of the 29th ACM International Conference on
  Information \& Knowledge Management}, pages 1355--1364, 2020.

\bibitem[\protect\citeauthoryear{Silver \bgroup \em et al.\egroup
  }{2014}]{silver2014deterministic}
David Silver, Guy Lever, Nicolas Heess, Thomas Degris, Daan Wierstra, and
  Martin Riedmiller.
\newblock Deterministic policy gradient algorithms.
\newblock In {\em Proceedings of the 31st International Conference on Machine
  Learning}, pages 387--395. PMLR, 2014.

\bibitem[\protect\citeauthoryear{Song \bgroup \em et al.\egroup
  }{2019}]{song2019observational}
Xingyou Song, Yiding Jiang, Stephen Tu, Yilun Du, and Behnam Neyshabur.
\newblock Observational overfitting in reinforcement learning.
\newblock {\em arXiv preprint arXiv:1912.02975}, 2019.

\bibitem[\protect\citeauthoryear{Vyetrenko \bgroup \em et al.\egroup
  }{2020}]{vyetrenko2020get}
Svitlana Vyetrenko, David Byrd, Nick Petosa, Mahmoud Mahfouz, Danial Dervovic,
  Manuela Veloso, and Tucker Balch.
\newblock {Get real: Realism metrics for robust limit order book market
  simulations}.
\newblock In {\em Proceedings of the First ACM International Conference on AI
  in Finance}, pages 1--8, 2020.

\bibitem[\protect\citeauthoryear{Wang \bgroup \em et al.\egroup
  }{2020}]{wang2020improving}
Kaixin Wang, Bingyi Kang, Jie Shao, and Jiashi Feng.
\newblock Improving generalization in reinforcement learning with mixture
  regularization.
\newblock {\em Advances in Neural Information Processing Systems},
  33:7968--7978, 2020.

\bibitem[\protect\citeauthoryear{Zhang \bgroup \em et al.\egroup
  }{2018a}]{zhang2018dissection}
Amy Zhang, Nicolas Ballas, and Joelle Pineau.
\newblock A dissection of overfitting and generalization in continuous
  reinforcement learning.
\newblock {\em arXiv preprint arXiv:1806.07937}, 2018.

\bibitem[\protect\citeauthoryear{Zhang \bgroup \em et al.\egroup
  }{2018b}]{zhang2018study}
Chiyuan Zhang, Oriol Vinyals, Remi Munos, and Samy Bengio.
\newblock A study on overfitting in deep reinforcement learning.
\newblock {\em arXiv preprint arXiv:1804.06893}, 2018.

\end{thebibliography}
