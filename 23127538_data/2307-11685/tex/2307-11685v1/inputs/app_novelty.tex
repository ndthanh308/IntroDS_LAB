We believe the overfitting problem in ORDC is novel.
Most existing papers study the setting where the agent is trained and evaluated on different sets of seeds/configurations [1-3] or procedurally generated environments [4-7].
ORDC is different from their settings in that 1) the context changes in each time step and affects both the reward and the transition; 2) the context sequence is highly stochastic and pre-collected with limited samples.
These properties contribute to the high variance in estimating $Q(c,s,a)$~(cf. Figure 5) and thus exacerbate overfitting.
% \li{All these properties contribute to the high variance in value estimation for $Q(c,s,a)$~(Figure.5), therefore leads to the overfitting issue.}
Moreover, ORDC is worth studying since it generalizes many industrial applications.
For example, the context can be the customer/electricity demand in inventory/power grid management or the incoming tasks for ride-sharing tasks.
Thus, the analysis and the methods in our paper can also be applied to these domains.
Besides, 
few papers (if any) mention the idea to aggregate the context/state space,
% the idea to aggregate the context/state is mentioned by few papers,
and our approach that aggregates the context space by predicting future context statistics is different from existing state abstraction methods (e.g., predicting the future reward/transition/return).

Since the market status sequence is collected offline, we believe the proposed ORDC framework can provide a better tool to analyze the overfitting problem (which is a key challenge in finance) compared with the standard MDP formulation used in most existing finance papers.
As for our methods, 
while the previous study suggests feature engineering, CATE goes a step further to generate features automatically. The latent factor model in finance is not used to prevent overfitting in the machine learning context.