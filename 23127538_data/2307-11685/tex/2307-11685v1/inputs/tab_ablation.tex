\begin{table*}[t]
    \centering
    \begin{tabular}{p{2cm}lrp{5cm}}
        \toprule
        Group & Variable & Trading Cost &  Explanation \\
        \midrule
        Revenue term &  \textbf{Cash inflow} & \textbf{-2.6455} & $r_1=n_t \bar{p}_t$ \\
        in reward & Price advantage & -2.5276 &  $n_t (\bar{p}_t - \bar{p}_\text{TWAP})$ \cite{fang2021universal} \\
        & Change in unrealized PnL & +2.6438 & See \cite{ning2018double} \\
        % Change in unrealized PnL & & $q_t \Delta p_t$ where $q$ is remaining inventory, $p$ is price 
        & Sparse reward & +2.5293 &  See \cite{lin2020end}\\
        \midrule
        Action space & Discrete volumes & +3.6614 & 21 discrete quoted volumes for MOs\textsuperscript{a} \\
        & Discrete prices & -0.1371 & 33 discrete quoted prices (relative)\textsuperscript{b} \\
        & \textbf{Discrete prices \& volumes} & \textbf{-3.5243} & 33$\times$4 discrete quoted price$\times$volume\textsuperscript{c} \\
        TWAP & $\beta=0.0$ & -0.0821 & The coefficient of the reg. term $r_2$ in reward\\
        regularization & $\mathbf{\beta=0.1}$ & \textbf{-1.7325} & \\
        & $\beta=1.0$ & +1.8146 & \\
        Model & Standard & +0.4229 & 6-layer MLP with 128 hidden neurons\\
        architecture & \textbf{Large} & \textbf{-0.4229} & 8-layer MPS with 256 hidden neurons\\
        Learning rate & $1\times 10^{-4}$ & +0.0347 & Learning rate used in training \\
        & $\mathbf{1\times 10^{-5}}$ & \textbf{-0.0347} & \\
        Market & LOB & +0.1526 & 5-level ask/bid volume/price\\
        variables& \textbf{LOB + factors} & \textbf{-0.1526} & + other LOB-based and technical factors\\
        \midrule
        Training mode & \textbf{Separate} & \textbf{-0.3154} & Train encoder, fix encoder, train policy network\\
        in Algo1 & Joint & +0.3154 & Train encoder and policy network simultaneously \\
        \bottomrule
    \end{tabular}

    \caption{
    Ablation study on different model designs for trade execution. 
    }
    
    \label{tab:ablation}
\end{table*}