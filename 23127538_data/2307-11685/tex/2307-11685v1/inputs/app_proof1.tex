The proof of the lower bound mainly follows \cite{azar2013minimax} which studies the standard MDP.
First, we construct a class of ORDC models $\mathbb{M}$.
Then, following the analysis in \cite{azar2013minimax}, we can obtain the result that any algorithm in a subset of algorithms $A \in \mathfrak{A}' \subset \mathfrak{A}$ can fail to learn an accurate value function for at least one of the models in $\mathbb{M}$ with a high probability if the context dataset is not large enough.
At last, we generalize this conclusion to any of the possible algorithms $A\in\mathfrak{A}$ by showing that we can always find an algorithm $A'\in\mathfrak{A}'$ that performs no worse than $A$.

\begin{proof}
We first define a class of ORDC models $\mathbb{M}$.
For each instance $M$ in the class, the reward depends only on the context, i.e., $r(c,s,a)=r(c)$.
The context space is divided into three disjoint subsets of equal cardinality, i.e., $\mathcal{C} = \mathcal{C}^0 \cup \mathcal{C}^1 \cup \mathcal{C}^2$, $|\mathcal{C}|=3K$, and $|\mathcal{C}^0|=|\mathcal{C}^1|=|\mathcal{C}^2|=K$.
For each context in $c^0 \in \mathcal{C}^0$, it will trainsit to the corresponding context $c^1 \in \mathcal{C}^1$ with probability 1.
For each context $c^1 \in \mathcal{C}^1$, it will transit to the corresponding context $c^2 \in \mathcal{C}^2$ with probability $1-p_M$ and to itself with probability $p_M$.
For each context $c^2 \in \mathcal{C}^2$, it will transit to itself with probability 1.
The transition probability $p_M$ for each $c\in\mathcal{C}^1$ is selected from $\{p, p+\alpha\}$, where $\alpha$ and $p$ satisfy $0<p<p+\alpha<1$, and the exact value is determined in the analysis.
The reward function is 
\begin{equation}
    r(c) = \begin{cases}
    1 & \text{if } c\in \mathcal{C}^1 \\
    0 & \text{otherwise}
    \end{cases}.
\end{equation}
It is not hard to see that $Q_M^*(c,s,a)=\frac{\gamma}{1-\gamma p_M} =: \mathbb{Q}_M^*(c), \forall c\in\mathcal{C}^0$.
% Now, let us consider two ORDC models $M_1$ and $M_2$ with the transition probability $p_M$ equals to $p$ and $p+\alpha$ respectively, where $\alpha$ and $p$ satisfies that $0<p<p+\alpha<1$ and the exact value is determined in the analysis.
% We denote $\mathbb{M} = \{M_1, M_2\}$.

Now, we consider a subset of algorithms $\mathfrak{A}' \subset \mathfrak{A}$.
Each algorithm $A\in\mathfrak{A}'$ that consumes $T$ samples from $c^1\in\mathcal{C}^1$ outputs a value function that takes the same value for different $(s,a)$s, i.e., $Q_T^A(c,s,a) = Q_T^A(c,s',a') =: \mathbb{Q}_T^A(c), \forall s,a,s',a'$. 
Then, we can obtain the following conclusion by replacing $\mathcal{S}\times\mathcal{A}$ with $\mathcal{C}$ in Lemma 18 in \cite{azar2013minimax}:
\begin{lemma}
\textit{
For $\delta \in (0,1/2)$ and any algorithm $A\in\mathfrak{A}'$ using a total number of context transition samples less than $T=c_1 \frac{|\mathcal{C}|}{(1-\gamma)^3 \epsilon^2} \log ( c_2 |\mathcal{C}|/\delta )$, there exists $M_m\in\mathbb{M}$ such that 
$$
\mathbb{P}_m (\| \mathbb{Q}^*_{M_m} - \mathbb{Q}^A_T \|_\infty > \epsilon) > \delta,
$$
where $\mathbb{P}_m$ is the probability under the model $M_m$ and $c_1, c_2$ are positive constants.
}
\end{lemma}

At last, we extend the conclusion to $\mathfrak{A}$ with the following lemma.
\begin{lemma}
\textit{
For any algorithm $A\in \mathfrak{A}$ that outputs $Q^A \in \mathbb{R}^{\mathcal{C}\times\mathcal{S}\times\mathcal{A}}$, we can always find an algorithm $A'\in\mathfrak{A}'$ such that 
$$
\| Q^*_M - Q^A \|_\infty \ge \| \mathbb{Q}^*_M - \mathbb{Q}^{A'} \|_\infty
$$
}
\end{lemma}
Actually, we can construct an algorithm $A'\in\mathfrak{A}'$ for each $A\in\mathfrak{A}$ by wrapping the output of $A$ as follows: $\mathbb{Q}^{A'}(c) := Q^A(c,s_0, a_0)$ for arbitrary fixed $s_0\in\mathcal{S}, a_0\in\mathcal{A}$.
\end{proof}

\textbf{Discussion.}
In the class of constructed ORDCs, we can categorize the contexts into six groups, three of which are the contexts $c^0\in\mathcal{C}^0$, $c^1\in\mathcal{C}^1$ and $c^2\in\mathcal{C}^2$ corresponding to $p_M=p$ and the other three corresponds to $p_M=p+\alpha$.
Aggregating the contexts into these six groups does not bring any loss in representing the optimal policy or value function.
In fact, it is possible to get rid of the $|\mathcal{C}|$ dependence in the sample complexity lower bound if the category of each context is known which is illustrated in Theorem \ref{theorem:upper_bound}.