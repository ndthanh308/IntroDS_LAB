\begin{thebibliography}{39}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Beltagy et~al.(2019{\natexlab{a}})Beltagy, Lo, and Cohan]{SciBERT}
Beltagy, I., Lo, K., and Cohan, A.
\newblock {SciBERT: A Pretrained Language Model for Scientific Text}.
\newblock 2019{\natexlab{a}}.
\newblock \doi{10.48550/ARXIV.1903.10676}.
\newblock URL \url{https://arxiv.org/abs/1903.10676}.

\bibitem[Beltagy et~al.(2019{\natexlab{b}})Beltagy, Lo, and
  Cohan]{beltagy2019scibert}
Beltagy, I., Lo, K., and Cohan, A.
\newblock Scibert: A pretrained language model for scientific text.
\newblock \emph{arXiv preprint arXiv:1903.10676}, 2019{\natexlab{b}}.

\bibitem[Bommasani et~al.(2022)Bommasani, Hudson, Adeli, Altman, Arora, von
  Arx, Bernstein, Bohg, Bosselut, Brunskill, Brynjolfsson, Buch, Card,
  Castellon, Chatterji, Chen, Creel, Davis, Demszky, Donahue, Doumbouya,
  Durmus, Ermon, Etchemendy, Ethayarajh, Fei-Fei, Finn, Gale, Gillespie, Goel,
  Goodman, Grossman, Guha, Hashimoto, Henderson, Hewitt, Ho, Hong, Hsu, Huang,
  Icard, Jain, Jurafsky, Kalluri, Karamcheti, Keeling, Khani, Khattab, Koh,
  Krass, Krishna, Kuditipudi, Kumar, Ladhak, Lee, Lee, Leskovec, Levent, Li,
  Li, Ma, Malik, Manning, Mirchandani, Mitchell, Munyikwa, Nair, Narayan,
  Narayanan, Newman, Nie, Niebles, Nilforoshan, Nyarko, Ogut, Orr,
  Papadimitriou, Park, Piech, Portelance, Potts, Raghunathan, Reich, Ren, Rong,
  Roohani, Ruiz, Ryan, Ré, Sadigh, Sagawa, Santhanam, Shih, Srinivasan,
  Tamkin, Taori, Thomas, Tramèr, Wang, Wang, Wu, Wu, Wu, Xie, Yasunaga, You,
  Zaharia, Zhang, Zhang, Zhang, Zhang, Zheng, Zhou, and
  Liang]{liang2021foundation}
Bommasani, R., Hudson, D.~A., Adeli, E., Altman, R., Arora, S., von Arx, S.,
  Bernstein, M.~S., Bohg, J., Bosselut, A., Brunskill, E., Brynjolfsson, E.,
  Buch, S., Card, D., Castellon, R., Chatterji, N., Chen, A., Creel, K., Davis,
  J.~Q., Demszky, D., Donahue, C., Doumbouya, M., Durmus, E., Ermon, S.,
  Etchemendy, J., Ethayarajh, K., Fei-Fei, L., Finn, C., Gale, T., Gillespie,
  L., Goel, K., Goodman, N., Grossman, S., Guha, N., Hashimoto, T., Henderson,
  P., Hewitt, J., Ho, D.~E., Hong, J., Hsu, K., Huang, J., Icard, T., Jain, S.,
  Jurafsky, D., Kalluri, P., Karamcheti, S., Keeling, G., Khani, F., Khattab,
  O., Koh, P.~W., Krass, M., Krishna, R., Kuditipudi, R., Kumar, A., Ladhak,
  F., Lee, M., Lee, T., Leskovec, J., Levent, I., Li, X.~L., Li, X., Ma, T.,
  Malik, A., Manning, C.~D., Mirchandani, S., Mitchell, E., Munyikwa, Z., Nair,
  S., Narayan, A., Narayanan, D., Newman, B., Nie, A., Niebles, J.~C.,
  Nilforoshan, H., Nyarko, J., Ogut, G., Orr, L., Papadimitriou, I., Park,
  J.~S., Piech, C., Portelance, E., Potts, C., Raghunathan, A., Reich, R., Ren,
  H., Rong, F., Roohani, Y., Ruiz, C., Ryan, J., Ré, C., Sadigh, D., Sagawa,
  S., Santhanam, K., Shih, A., Srinivasan, K., Tamkin, A., Taori, R., Thomas,
  A.~W., Tramèr, F., Wang, R.~E., Wang, W., Wu, B., Wu, J., Wu, Y., Xie,
  S.~M., Yasunaga, M., You, J., Zaharia, M., Zhang, M., Zhang, T., Zhang, X.,
  Zhang, Y., Zheng, L., Zhou, K., and Liang, P.
\newblock On the opportunities and risks of foundation models, 2022.
\newblock URL \url{https://arxiv.org/abs/2108.07258}.

\bibitem[Cohen(1960)]{kappa}
Cohen, J.
\newblock A coefficient of agreement for nominal scales.
\newblock \emph{Educational and Psychological Measurement}, 20\penalty0
  (1):\penalty0 37--46, 1960.
\newblock \doi{10.1177/001316446002000104}.
\newblock URL \url{https://doi.org/10.1177/001316446002000104}.

\bibitem[Devlin et~al.(2018)Devlin, Chang, Lee, and Toutanova]{devlin2018}
Devlin, J., Chang, M.-W., Lee, K., and Toutanova, K.
\newblock Bert: Pre-training of deep bidirectional transformers for language
  understanding.
\newblock \emph{arXiv preprint arXiv:1810.04805}, 2018.

\bibitem[Devlin et~al.(2019)Devlin, Chang, Lee, and Toutanova]{devlin2019bert}
Devlin, J., Chang, M.-W., Lee, K., and Toutanova, K.
\newblock Bert: Pre-training of deep bidirectional transformers for language
  understanding, 2019.

\bibitem[Duvenaud et~al.(2015)Duvenaud, Maclaurin, Aguilera-Iparraguirre,
  Gómez-Bombarelli, Hirzel, Aspuru-Guzik, and Adams]{duvenaud2015}
Duvenaud, D.~K., Maclaurin, D., Aguilera-Iparraguirre, J., Gómez-Bombarelli,
  R., Hirzel, T., Aspuru-Guzik, A., and Adams, R.~P.
\newblock Convolutional networks on graphs for learning molecular fingerprints.
\newblock \emph{Advances in Neural Information Processing Systems},
  28:\penalty0 2224--2232, 2015.

\bibitem[Gayvert et~al.(2016)Gayvert, Madhukar, and Elemento]{clintox}
Gayvert, K.~M., Madhukar, N.~S., and Elemento, O.
\newblock A data-driven approach to predicting successes and failures of
  clinical trials.
\newblock \emph{Cell chemical biology}, 23\penalty0 (10):\penalty0 1294--1301,
  2016.

\bibitem[Gilmer et~al.(2017)Gilmer, Schoenholz, Riley, Vinyals, and
  Dahl]{gilmer2017}
Gilmer, J., Schoenholz, S.~S., Riley, P.~F., Vinyals, O., and Dahl, G.~E.
\newblock Neural message passing for quantum chemistry.
\newblock In \emph{Proceedings of the 34th International Conference on Machine
  Learning-Volume 70}, pp.\  1263--1272. JMLR. org, 2017.

\bibitem[Gómez-Bombarelli et~al.(2016)Gómez-Bombarelli, Duvenaud,
  Hernández-Lobato, Aguilera-Iparraguirre, Hirzel, Adams, and
  Aspuru-Guzik]{gomez2016}
Gómez-Bombarelli, R., Duvenaud, D., Hernández-Lobato, J.~M.,
  Aguilera-Iparraguirre, J., Hirzel, T.~D., Adams, R.~P., and Aspuru-Guzik, A.
\newblock Automatic chemical design using a data-driven continuous
  representation of molecules.
\newblock \emph{ACS Central Science}, 4\penalty0 (2):\penalty0 268--276, 2016.

\bibitem[Hewitt et~al.(2022)Hewitt, Manning, and Liang]{hewitt2022truncation}
Hewitt, J., Manning, C.~D., and Liang, P.
\newblock Truncation sampling as language model desmoothing, 2022.

\bibitem[Hu et~al.(2020)Hu, Fey, Zitnik, Dong, Ren, Liu, Catasta, and
  Leskovec]{OGB}
Hu, W., Fey, M., Zitnik, M., Dong, Y., Ren, H., Liu, B., Catasta, M., and
  Leskovec, J.
\newblock Open graph benchmark: Datasets for machine learning on graphs, 2020.
\newblock URL \url{https://arxiv.org/abs/2005.00687}.

\bibitem[Kearnes et~al.(2016)Kearnes, Goldman, and Pande]{kearnes2016}
Kearnes, S., Goldman, B., and Pande, V.
\newblock Molecular graph convolutions: moving beyond fingerprints.
\newblock \emph{Journal of Computer-Aided Molecular Design}, 30\penalty0
  (8):\penalty0 595--608, 2016.

\bibitem[Kim et~al.(2022)Kim, Chen, Cheng, Gindulyte, He, He, Li, Shoemaker,
  Thiessen, Yu, Zaslavsky, Zhang, and Bolton]{PubChem}
Kim, S., Chen, J., Cheng, T., Gindulyte, A., He, J., He, S., Li, Q., Shoemaker,
  B.~A., Thiessen, P.~A., Yu, B., Zaslavsky, L., Zhang, J., and Bolton, E.~E.
\newblock {PubChem 2023 update}.
\newblock \emph{Nucleic Acids Research}, 51\penalty0 (D1):\penalty0
  D1373--D1380, 10 2022.
\newblock ISSN 0305-1048.
\newblock \doi{10.1093/nar/gkac956}.
\newblock URL \url{https://doi.org/10.1093/nar/gkac956}.

\bibitem[Kipf \& Welling(2016)Kipf and Welling]{kipf2016}
Kipf, T.~N. and Welling, M.
\newblock Semi-supervised classification with graph convolutional networks.
\newblock \emph{arXiv preprint arXiv:1609.02907}, 2016.

\bibitem[Korolev et~al.(2020)Korolev, Tavakoli, and Lo]{korolev2020}
Korolev, S., Tavakoli, M., and Lo, R.
\newblock Chemberta: Large-scale self-supervised pretraining for molecular
  property prediction.
\newblock \emph{arXiv preprint arXiv:2010.09885}, 2020.

\bibitem[Kuhn et~al.(2016)Kuhn, Letunic, Jensen, and Bork]{sider}
Kuhn, M., Letunic, I., Jensen, L.~J., and Bork, P.
\newblock The sider database of drugs and side effects.
\newblock \emph{Nucleic acids research}, 44\penalty0 (D1):\penalty0
  D1075--D1079, 2016.

\bibitem[Kusner et~al.(2017)Kusner, Paige, and Hernández-Lobato]{kusner2017}
Kusner, M.~J., Paige, B., and Hernández-Lobato, J.~M.
\newblock Grammar variational autoencoder.
\newblock In \emph{Proceedings of the 34th International Conference on Machine
  Learning}, volume~70, pp.\  1945--1954. PMLR, 2017.

\bibitem[Lo et~al.(2020)Lo, Wang, Neumann, Kinney, and Weld]{s2orc}
Lo, K., Wang, L.~L., Neumann, M., Kinney, R., and Weld, D.
\newblock {S}2{ORC}: The semantic scholar open research corpus.
\newblock In \emph{Proceedings of the 58th Annual Meeting of the Association
  for Computational Linguistics}, pp.\  4969--4983, Online, July 2020.
  Association for Computational Linguistics.
\newblock \doi{10.18653/v1/2020.acl-main.447}.
\newblock URL \url{https://aclanthology.org/2020.acl-main.447}.

\bibitem[Martins et~al.(2012)Martins, Teixeira, Pinheiro, and Falcao]{bbbp}
Martins, I.~F., Teixeira, A.~L., Pinheiro, L., and Falcao, A.~O.
\newblock A bayesian approach to in silico blood-brain barrier penetration
  modeling.
\newblock \emph{Journal of chemical information and modeling}, 52\penalty0
  (6):\penalty0 1686--1697, 2012.

\bibitem[Napolitano et~al.(2021)Napolitano, Candelieri, and
  Grandi]{napolitano2021}
Napolitano, F., Candelieri, A., and Grandi, M.
\newblock Molbert: Molecular representation learning with bert.
\newblock \emph{arXiv preprint arXiv:2102.01327}, 2021.

\bibitem[Oord et~al.(2018)Oord, Li, and Vinyals]{InfoNCE}
Oord, A. v.~d., Li, Y., and Vinyals, O.
\newblock Representation learning with contrastive predictive coding, 2018.
\newblock URL \url{https://arxiv.org/abs/1807.03748}.

\bibitem[Radford et~al.(2018)Radford, Narasimhan, Salimans, and
  Sutskever]{radford2018}
Radford, A., Narasimhan, K., Salimans, T., and Sutskever, I.
\newblock Improving language understanding by generative pre-training.
\newblock \emph{arXiv preprint arXiv:1801.06146}, 2018.

\bibitem[Radford et~al.(2021)Radford, Kim, Hallacy, Ramesh, Goh, Agarwal,
  Sastry, Askell, Mishkin, and Clark]{radford2021}
Radford, A., Kim, J.~W., Hallacy, C., Ramesh, A., Goh, G., Agarwal, S., Sastry,
  G., Askell, A., Mishkin, P., and Clark, J.
\newblock Learning transferable visual models from natural language
  supervision.
\newblock \emph{arXiv preprint arXiv:2103.00020}, 2021.

\bibitem[Raffel et~al.(2019)Raffel, Shazeer, Roberts, Lee, Narang, Matena,
  Zhou, Li, and Liu]{raffel2019}
Raffel, C., Shazeer, N., Roberts, A., Lee, K., Narang, S., Matena, M., Zhou,
  Y., Li, W., and Liu, P.~J.
\newblock Exploring the limits of transfer learning with a unified text-to-text
  transformer.
\newblock \emph{arXiv preprint arXiv:1910.10683}, 2019.

\bibitem[Richard et~al.(2016)Richard, Judson, Houck, Grulke, Volarath,
  Thillainadarajah, Yang, Rathman, Martin, Wambaugh, et~al.]{toxcast}
Richard, A.~M., Judson, R.~S., Houck, K.~A., Grulke, C.~M., Volarath, P.,
  Thillainadarajah, I., Yang, C., Rathman, J., Martin, M.~T., Wambaugh, J.~F.,
  et~al.
\newblock Toxcast chemical landscape: paving the road to 21st century
  toxicology.
\newblock \emph{Chemical research in toxicology}, 29\penalty0 (8):\penalty0
  1225--1251, 2016.

\bibitem[Rohrer \& Baumann(2009)Rohrer and Baumann]{muv}
Rohrer, S.~G. and Baumann, K.
\newblock Maximum unbiased validation (muv) data sets for virtual screening
  based on pubchem bioactivity data.
\newblock \emph{Journal of chemical information and modeling}, 49\penalty0
  (2):\penalty0 169--184, 2009.

\bibitem[Su et~al.(2022)Su, Du, Yang, Zhou, Li, Rao, Sun, Lu, and
  Ji-Rong]{su2022}
Su, B., Du, D., Yang, Z., Zhou, Y., Li, J., Rao, A., Sun, H., Lu, Z., and
  Ji-Rong, W.
\newblock {A Molecular Multimodal Foundation Model Associating Molecule Graphs
  with Natural Language}.
\newblock 2022.
\newblock URL \url{https://arxiv.org/pdf/2209.05481.pdf}.

\bibitem[Subramanian et~al.(2016)Subramanian, Ramsundar, Pande, and
  Denny]{bace}
Subramanian, G., Ramsundar, B., Pande, V., and Denny, R.~A.
\newblock Computational modeling of $\beta$-secretase 1 (bace-1) inhibitors
  using ligand based approaches.
\newblock \emph{Journal of chemical information and modeling}, 56\penalty0
  (10):\penalty0 1936--1949, 2016.

\bibitem[Veličković et~al.(2017)Veličković, Cucurull, Casanova, Romero,
  Lio, and Bengio]{velickovic2017}
Veličković, P., Cucurull, G., Casanova, A., Romero, A., Lio, P., and Bengio,
  Y.
\newblock Graph attention networks.
\newblock \emph{arXiv preprint arXiv:1710.10903}, 2017.

\bibitem[Wang et~al.(2022)Wang, Wang, Cao, and
  Barati~Farimani]{wang2022molecular}
Wang, Y., Wang, J., Cao, Z., and Barati~Farimani, A.
\newblock Molecular contrastive learning of representations via graph neural
  networks.
\newblock \emph{Nature Machine Intelligence}, 4\penalty0 (3):\penalty0
  279--287, 2022.

\bibitem[Weininger(1988)]{weininger1988}
Weininger, D.
\newblock Smiles, a chemical language and information system. 1. introduction
  to methodology and encoding rules.
\newblock \emph{Journal of Chemical Information and Modeling}, 28\penalty0
  (1):\penalty0 31--36, 1988.

\bibitem[White(2023)]{White2023}
White, A.~D.
\newblock The future of chemistry is language.
\newblock \emph{Nature Reviews Chemistry}, 2023.
\newblock \doi{10.1038/s41570-023-00502-0}.
\newblock URL \url{https://doi.org/10.1038/s41570-023-00502-0}.
\newblock ISSN: 2397-3358.

\bibitem[Wu et~al.(2018{\natexlab{a}})Wu, Ramsundar, Feinberg, Gomes, Geniesse,
  Pappu, Leswing, and Pande]{moleculenet}
Wu, Z., Ramsundar, B., Feinberg, E., Gomes, J., Geniesse, C., Pappu, A.~S.,
  Leswing, K., and Pande, V.
\newblock Moleculenet: a benchmark for molecular machine learning.
\newblock \emph{Chem. Sci.}, 9:\penalty0 513--530, 2018{\natexlab{a}}.
\newblock \doi{10.1039/C7SC02664A}.
\newblock URL \url{http://dx.doi.org/10.1039/C7SC02664A}.

\bibitem[Wu et~al.(2018{\natexlab{b}})Wu, Ramsundar, Feinberg, Gomes, Geniesse,
  Pappu, Leswing, and Pande]{wu2018}
Wu, Z., Ramsundar, B., Feinberg, E.~N., Gomes, J., Geniesse, C., Pappu, A.~S.,
  Leswing, K., and Pande, V.
\newblock Moleculenet: a benchmark for molecular machine learning.
\newblock \emph{Chemical Science}, 9\penalty0 (2):\penalty0 513--530,
  2018{\natexlab{b}}.

\bibitem[Xu et~al.(2018)Xu, Hu, Leskovec, and Jegelka]{xu2018powerful}
Xu, K., Hu, W., Leskovec, J., and Jegelka, S.
\newblock How powerful are graph neural networks?
\newblock \emph{arXiv preprint arXiv:1810.00826}, 2018.

\bibitem[You et~al.(2020)You, Chen, Sui, Chen, Wang, and Shen]{you2020graph}
You, Y., Chen, T., Sui, Y., Chen, T., Wang, Z., and Shen, Y.
\newblock Graph contrastive learning with augmentations.
\newblock \emph{Advances in neural information processing systems},
  33:\penalty0 5812--5823, 2020.

\bibitem[Yousefzadegan~Hedin(2022)]{yousefzadegan2022evaluation}
Yousefzadegan~Hedin, S.
\newblock Evaluation of generative machine learning models: Judging the quality
  of generated data with the use of neural networks, 2022.

\bibitem[Zang \& Wang(2020)Zang and Wang]{MoFlow}
Zang, C. and Wang, F.
\newblock {MoFlow}: An invertible flow model for generating molecular graphs.
\newblock In \emph{Proceedings of the 26th {ACM} {SIGKDD} International
  Conference on Knowledge Discovery {\&} Data Mining}. {ACM}, aug 2020.
\newblock \doi{10.1145/3394486.3403104}.

\end{thebibliography}
