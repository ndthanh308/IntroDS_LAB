In this subsection, we provide a formal proof to \Cref{thm:PMLE}.
The proof is carried out as the following.

\paragraph{Step 1. Offline Suboptimality Decomposition}
By \Cref{lem:MLE}, we have with high probability that $M^*\in\CI_\cM(\beta)$, and we have the following suboptimality decomposition,
\begin{align*}
    J(\pi^*) - J(\hat\pi) 
    &= J(\pi^*) - J(\pi^*, M^{\pi^*}) + J(\pi^*, M^{\pi^*}) - J(\hat\pi, M^{\hat\pi}) + J(\hat\pi, M^{\hat\pi}) - J(\hat\pi)\nend
    &\le J(\pi^*) - J(\pi^*, M^{\pi^*}) +J(\pi^*, M^{\pi^*}) - J(\hat\pi, M^{\hat\pi})\nend
    &\le J(\pi^*) - J(\pi^*, M^{\pi^*}) ,
\end{align*}
where we define $M^\pi = \argmin_{M\in\CI_\cM(\beta)}J(\pi, M)$ as the pessimistic estimated model for $\pi$. Here, the first inequality holds by noting that $J(\hat\pi) = J(\hat\pi, M^*) \ge J(\hat\pi, M^{\hat\pi})$ by the validity of the confidence set $\CI_\cM(\beta)$ and the definition of $M^{\hat\pi}$, and the  second inequality is a direct result of policy optimization. Now, we further decompose the suboptimality using \Cref{lem:subopt-decomposition}. We define $\tilde M = M^{\pi^*}$, and let $\tilde U, \tilde W$ be the follower's value functions under policy $\pi^*$ and the estimated model $\tilde M$. Let $\tilde \nu$ be the estimated quantal response under $\pi^*$ and $\tilde M$. We have for $\pi^*, \tilde U, \tilde W, \tilde\nu$ that 
\begin{align*}
    &J(\pi^* ) - J(\pi^*, \tilde M)\nend
    &\quad \le \sum_{h=1}^H \EE \sbr{\rbr{\tilde U_h - u_h}(s_h, a_h, b_h) -  \tilde W_{h+1}(s_{h+1})} + \sum_{h=1}^H 2 H  \EE \sbr{D_\TV\rbr{\tilde \nu_h(\cdot\given s_h), \nu_h(\cdot\given s_h)}}\nend
    &\quad \le \sum_{h=1}^H \underbrace{\EE \sbr{\rbr{\tilde U_h - u_h}(s_h, a_h, b_h) -  \tilde W_{h+1}(s_{h+1})}}_{\dr\text{Leader's Bellman error}} \nend
    &\qqquad +  
    C^{(0)} \cdot 
    \sum_{h=1}^H \underbrace{\EE\bigsbr{\bigabr{\tilde \Delta^{(1)}_h(s_h, b_h)}}}_{\ds\text{1st-order error}}  + C^{(2)} \cdot 
    \max_{h\in [H]} \underbrace{\EE\bigsbr{ \bigrbr{\orbr{\tilde Q_h - r_h^{\pi^*} - \gamma P_h^{\pi^*} \tilde V_{h+1}}(s_h, b_h)}^2}}_{\ds\text{2nd-order error}}
\end{align*}
where the expectation is taken under $\pi^*$ and the true model $M^*$, and we define $\tilde Q, \tilde V$ as the follower's value functions under policy $\pi^*$ and model $\tilde M$. 
Here, the first inequality holds by \eqref{eq:perform-diff-linear} where we notice that $J(\pi^*, \tilde M) = \EE[\tilde W_1(s_1)]$ and also that $\tilde W_h = T_h^{\pi^*, \tilde \nu}\tilde U_h$. The second inequality holds by using \Cref{lem:performance diff}. Moreover, the definition of $\tilde\Delta_H^{(1)}(s_h, b_h) $ is given by 
\begin{align*}
    \tilde \Delta^{(1)}_h(s_h, b_h) &=  \rbr{\EE_{s_h, b_h} -\EE_{s_h}}\Biggsbr{\sum_{l=h}^H \gamma^{l-h}\underbrace{\rbr{\tilde Q_l - r_l^{\pi^*} - \gamma P_l^{\pi^*} \tilde V_{l+1}}(s_l, b_l)}_{\ds\text{Follower's Bellman error}}}. 
    % \label{eq:def Delta^1}
\end{align*}
In the sequel, we separately bound these three terms.

\paragraph{Step 2. Bounding the Leader's Bellman Error.}
We present the gurantee we have for the Leader's Bellman error on the samples. Define $\EE^i=\EE^{\pi^i}$, which is the expectation taken under $\pi^i$ and the true model $M^*$. We have
\begin{align*}
    &\sum_{i=1}^T 
    \EE^i \sbr{\rbr{\bigrbr{\tilde U_h - u_h}(s_h, a_h, b_h) - \tilde W_{h+1}(s_{h+1})}^2}\nend
    &\quad =\sum_{i=1}^T \EE^i \sbr{\rbr{{\bigrbr{\tilde u_h - u_h}(s_h, a_h, b_h) + \bigrbr{\tilde P_h - P_h} \tilde W_{h+1}(s_{h+1})}}^2}\nend
    &\quad \le 2\sum_{i=1}^T \EE^i \sbr{\rbr{\rbr{\tilde u_h - u_h}(s_h,a_h,b_h)}^2} + 8 H^2 \sum_{i=1}^T \EE^i D_\TV^2\rbr{\tilde P_h(\cdot\given s_h, a_h, b_h), P_h(\cdot\given s_h, a_h, b_h)}\nend
    &\quad \lesssim  H^2 \beta, 
\end{align*}
where the first equality holds by the definition of $\tilde U$, and the first inequality holds by the Jensen's inequality, and the last inequality holds by the MLE guarantee in \Cref{lem:MLE}, where we hide some universal constants by \say{$\lesssim$}.
Therefore, we have that
\begin{align*}
    &\sum_{h=1}^H \EE \sbr{\rbr{\tilde U_h - u_h}(s_h, a_h, b_h) -  \tilde W_{h+1}(s_{h+1})}\nend
    &\quad \le \sum_{h=1}^H \sqrt{\EE \Bigsbr{\Bigrbr{\bigrbr{\tilde U_h - u_h}(s_h, a_h, b_h) -  \tilde W_{h+1}(s_{h+1})}^2}}\nend
    &\quad \lesssim H\sqrt{H^2 \beta} \cdot 
    \sqrt{\frac{\EE \Bigsbr{\Bigrbr{\bigrbr{\tilde U_h - u_h}(s_h, a_h, b_h) -  \tilde W_{h+1}(s_{h+1})}^2}}{\sum_{i=1}^T 
    \EE^i \Bigsbr{\rbr{\bigrbr{\tilde U_h - u_h}(s_h, a_h, b_h) - \tilde W_{h+1}(s_{h+1})}^2}}}\nend
    &\quad \le H^2\sqrt{ \beta} \cdot \max_{M\in\cM, h\in[H]} \sqrt{\frac{\EE\sbr{\rbr{\bigrbr{U_h^{\pi^*, M}-\bigrbr{u_h+P_h W_{h+1}^{\pi^*, M}}}(s_h, a_h, b_h)}^2 }}{\sum_{i=1}^T \EE^i\sbr{\rbr{\bigrbr{U_h^{\pi^*, M}-\bigrbr{u_h+P_h W_{h+1}^{\pi^*, M}}}(s_h, a_h, b_h)}^2 }}}.
\end{align*}

\paragraph{Step 3. Bound the first-order Error of the Follower's Response.}
We first study the following guarantee for the 1st order term over the offline samples,
\begin{align*}
    &\sum_{i=1}^T \EE^i \sbr{\rbr{\rbr{\EE_{s_h, b_h}^i -\EE_{s_h}^i}\sbr{\sum_{l=h}^H \gamma^{l-h}\rbr{\tilde r_l - r_l + \gamma \bigrbr{\tilde P_l - P_l} \tilde V_{l+1}}(s_l,a_l,  b_l)}}^2}\nend
    %%%%%%%%%%%%
    &\quad \lesssim \sum_{i=1}^T \EE^i \sbr{\rbr{\rbr{\EE_{s_h, b_h}^i -\EE_{s_h}^i}\sbr{\sum_{l=h}^H \gamma^{l-h}\rbr{\tilde r_l - r_l + \gamma \bigrbr{\tilde P_l - P_l} V_{l+1}^{\pi^i, \tilde M}}(s_l,a_l,  b_l)}}^2}\nend
    &\qqquad + \sum_{i=1}^T \EE^i \sbr{\rbr{\rbr{\EE_{s_h, b_h}^i -\EE_{s_h}^i}\sbr{\sum_{l=h}^H \gamma^{l-h}\rbr{\gamma \bigrbr{\tilde P_l - P_l} \bigrbr{\tilde V_{l+1} - V_{l+1}^{\pi^i,\tilde M}}}(s_l,a_l,  b_l)}}^2} \nend
    &\quad \lesssim \sum_{i=1}^T \EE^i \sbr{\rbr{\rbr{\EE_{s_h, b_h}^i -\EE_{s_h}^i}\Biggsbr{\sum_{l=h}^H \gamma^{l-h}\rbr{\tilde r_l - r_l + \gamma \bigrbr{\tilde P_l - P_l} V_{l+1}^{\pi^i, \tilde M} }(s_l, a_l, b_l)}}^2}\nend
    &\qqquad + B_A^2 \sum_{i=1}^T   \EE^i\rbr{\sum_{l=h}^H \gamma^{l-h}\rbr{\EE_{s_h,b_h}^i + \EE_{s_h}^i}  \sbr{D_\TV\rbr{\tilde P_l(\cdot\given s_l, a_l, b_l), P_l(\cdot\given s_l, a_l, b_l)}}}^2\nend
    &\quad \lesssim \sum_{i=1}^T \EE^i \biggsbr{\biggrbr{\underbrace{\rbr{\EE_{s_h, b_h}^i -\EE_{s_h}^i}\Biggsbr{\sum_{l=h}^H \gamma^{l-h}\rbr{\tilde r_l - r_l + \gamma \bigrbr{\tilde P_l - P_l} V_{l+1}^{\pi^i, \tilde M} }(s_l, a_l, b_l)}}_{\ds \tilde \Delta^{(1)}_{h, \pi^i, \tilde M}(s_h, b_h) }}^2}\nend
    &\qqquad + B_A^2 \sum_{i=1}^T   \eff_H(\gamma) \sum_{l=h}^H \gamma^{l-h} \EE^i D_\TV^2\rbr{\tilde P_l(\cdot\given s_l, a_l, b_l), P_l(\cdot\given s_l, a_l, b_l)}
\end{align*}
where the first inequality holds by the Jensen's inequality, where we add a $(\tilde P_l - P_l) V_{l+1}^{\pi^i, \tilde M}$ term and substract it, which gives us a separate $(\tilde P_l - P_l) (\tilde V_{l+1} - V_{l+1}^{\pi^i, \tilde M})$ term. 
In the second inquality, we upper bound $(\tilde P_l - P_l) (\tilde V_{l+1} - V_{l+1}^{\pi^i, \tilde M})$ by the TV distance between $\tilde P_l$ and $P_l$ multiplied by the infinity norm $\bignbr{\tilde V_{l+1} - V_{l+1}^{\pi^i, \tilde M}}_\infty$, which is bounded by $2 B_A$ by our argument in \Cref{sec:app-notations}. Since the TV distance is always nonnegative, we can safely flips the sign between $\EE_{s_h, b_h}^i - \EE_{s_h}^i $. The above steps give us the first inequality. 
The second inequality simply holds by using the Cauchy-Schwartz inequality where we move the square inside the expectation for the summation of the TV distance, and the $\eff_H(\gamma)$ is just a byproduct produced when applying the Cauchy-Schwartz inequality.

Next, we show how to control this $\tilde \Delta_{h,\pi^i, \tilde M}(s_h, b_h)$ term. We first notice that $\tilde\Delta^{(1)}_{h, \pi^i, \tilde M}(s_h, b_h)$ is nothing but just $\tilde\Delta^{(1)}_h(s_h, b_h)$ plugged in with $\pi^i$ as the policy $\pi$ and $\tilde Q^{\pi^i}=Q^{\pi^i, \tilde M}, \tilde V^{\pi^i} = V^{\pi^i, \tilde M}$ as the follower's value functions $\tilde Q, \tilde V$. 
Hence, we can invoke \Cref{lem:1st-ub} which says that 
\begin{align*}
    &\bigrbr{\tilde \Delta_{h, \pi^i,\tilde M}^{(1)}(s_h, b_h)}^2  \nend
        &\quad \le 2 \rbr{\rbr{\EE_{s_h, b_h}^i-\EE_{s_h}^i} \bigsbr{\orbr{Q_h^{\pi^i} - \tilde Q_h^{\pi^i}}(s_h, b_h)}}^2 \nend
        &\qqquad + 16 \gamma^2  \rbr{\eta^{-1} +2 B_A}^2\eff_H(\gamma) \sum_{l=h+1}^H \gamma^{l-h-1} {\rbr{\EE_{s_h}^i+\EE_{s_h, b_h}^i}\sbr{D_\H^2(\nu_l^{\pi^i}(\cdot\given s_l), \tilde\nu_l^{\pi^i}(\cdot\given s_l))}}
\end{align*}
where we define $\tilde \nu_l^{\pi^i} = \nu_l^{\pi^i, \tilde M}$ as the quantal response under $\pi^i$ and the estimated model $\tilde M$. This is true by our definition of $\tilde Q^{\pi^i}, \tilde V^{\pi^i}$ that they are the follower's value functions under $\pi^i$ and model $\tilde M$.
Therefore, we have that 
\begin{align*}
    &\sum_{i=1}^T \EE^i\bigrbr{\tilde \Delta_{h, \pi^i,\tilde M}^{(1)}(s_h, b_h)}^2  \nend
    &\quad \lesssim \sum_{i=1}^T \EE^i\rbr{\rbr{\EE_{s_h, b_h}^i-\EE_{s_h}^i} \bigsbr{\orbr{Q_h^{\pi^i} - \tilde Q_h^{\pi^i}}(s_h, b_h)}}^2 \nend
    &\qqquad + \gamma^2  \rbr{\eta^{-1} +2 B_A}^2\eff_H(\gamma) \sum_{i=1}^T \sum_{l=h+1}^H \gamma^{l-h-1} {\EE^i\sbr{D_\H^2(\nu_l^{\pi^i}(\cdot\given s_l), \tilde\nu_l^{\pi^i}(\cdot\given s_l))}} \nend
    &\quad\lesssim \rbr{(\eta^{-2}+B_A^2) + \gamma^2  \rbr{\eta^{-1} +2 B_A}^2\eff_H(\gamma) H} \beta, 
\end{align*}
where the last inequality holds by both \eqref{eq:MLE-guarantee-Q-3} in \Cref{lem:MLE-formal} for the Q difference term and the MLE guarantee in \Cref{lem:MLE} for the Hellinger term. Here, we upper bound $\gamma^{l-h-1}$ by $1$ and take a summation over $h\in[H]$. Therefore, we conclude that 
\begin{align*}
    &
    \sum_{i=1}^T \EE^i \sbr{\rbr{\rbr{\EE_{s_h, b_h}^i -\EE_{s_h}^i}\sbr{\sum_{l=h}^H \gamma^{l-h}\rbr{\tilde r_l - r_l + \gamma \bigrbr{\tilde P_l - P_l} \tilde V_{l+1}}(s_l,a_l,  b_l)}}^2} \nend
    &\quad\lesssim  
    \sum_{i=1}^T \EE^i\bigrbr{\tilde \Delta_{h, \pi^i,\tilde M}^{(1)}(s_h, b_h)}^2 \nend
    &\qqquad + 
    B_A^2 \sum_{i=1}^T   \eff_H(\gamma) \sum_{l=h}^H \gamma^{l-h} \EE^i D_\TV^2\rbr{\tilde P_l(\cdot\given s_l, a_l, b_l), P_l(\cdot\given s_l, a_l, b_l)}\nend
    &\quad \le  \rbr{(\eta^{-2}+B_A^2) + \gamma^2  \rbr{\eta^{-1} +2 B_A}^2\eff_H(\gamma) H} \beta  + B_A^2 \eff_H(\gamma) H \beta \nend
    &\quad \lesssim \rbr{\eta^{-2} + B_A^2 }\eff_H(\gamma)H \beta. 
\end{align*}
As a result, we have that
\begin{align*}
    &C^{(0)}\sum_{h=1}^H \EE\sbr{\abr{\tilde \Delta_h^{(1)}(s_h, b_h)}}\nend
    &\quad\le C^{(0)} \sum_{h=1}^H \sqrt{\EE\sbr{\tilde \Delta_h^{(1)}(s_h, b_h)^2}}\nend
    %%%%%%%%%%%%%
    &\quad \lesssim C^{(0)} H \sqrt{ \rbr{\eta^{-2} + B_A^2 }\eff_H(\gamma)H \beta} \nend
    &\qqquad \cdot \max_{h\in[H]}\sqrt\frac{\EE \sbr{\rbr{\rbr{\EE_{s_h, b_h} -\EE_{s_h}}\sbr{\sum_{l=h}^H \gamma^{l-h}\rbr{\tilde r_l - r_l + \gamma \bigrbr{\tilde P_l - P_l} \tilde V_{l+1}}(s_l,a_l,  b_l)}}^2}}{\sum_{i=1}^T \EE^i \sbr{\rbr{\rbr{\EE_{s_h, b_h}^i -\EE_{s_h}^i}\sbr{\sum_{l=h}^H \gamma^{l-h}\rbr{\tilde r_l - r_l + \gamma \bigrbr{\tilde P_l - P_l} \tilde V_{l+1}}(s_l,a_l,  b_l)}}^2}}\nend
    %%%%%%%%%%%%
    &\quad \lesssim \rbr{1 + \eta B_A }H^2\sqrt{ H \eff_H(\gamma)\beta} \nend
    &\quad \cdot \max_{M\in\cM, h\in[H]}\sqrt\frac{\EE \sbr{\rbr{\rbr{\EE_{s_h, b_h} -\EE_{s_h}}\sbr{\sum_{l=h}^H \gamma^{l-h}\rbr{r_l^M - r_l + \gamma \bigrbr{P_l^M - P_l} V_{l+1}^{\pi^*, M}}(s_l,a_l,  b_l)}}^2}}{\sum_{i=1}^T \EE^i \sbr{\rbr{\rbr{\EE_{s_h, b_h}^i -\EE_{s_h}^i}\sbr{\sum_{l=h}^H \gamma^{l-h}\rbr{ r_l^M - r_l + \gamma \bigrbr{P_l^M - P_l} V_{l+1}^{\pi^*, M}}(s_l,a_l,  b_l)}}^2}}, 
\end{align*}
where we notice that $C^{(0)}=2\eta H$.

\paragraph{Step 4. Bound the second-order Error in the Follower's Response.}
The last thing to do is controlling the second order term. We first expand the second order term in terms of $r_h, P_h, V_{h+1}$ by definitions and have the following guarantee for the second order term over the samples, 
\begin{align*}
    &\sum_{i=1}^T \EE^i\sbr{ \rbr {\EE_{s_h, b_h}^i\sbr{{\bigrbr{\tilde r_h - r_h + \gamma \bigrbr{\tilde P_h - P_h} \tilde V_{h+1}}(s_h,a_h, b_h)}}}^2}\nend
    &\quad \lesssim \sum_{i=1}^T \EE^i\sbr{ \rbr {\EE_{s_h, b_h}^i\sbr{{\bigrbr{\tilde r_h - r_h + \gamma \bigrbr{\tilde P_h - P_h} V_{h+1}^{\pi^i, \tilde M}}(s_h,a_h, b_h)}}}^2} \nend
    &\qqquad + \sum_{i=1}^T \EE^i\sbr{ \rbr {\EE_{s_h, b_h}^i\sbr{{\gamma \bigrbr{\tilde P_h - P_h} \bigrbr{\tilde V_{h+1} - V_{h+1}^{\pi^i, \tilde M} }(s_h,a_h, b_h)}}}^2}\nend
    %%%%%% split %%%%%%
    &\quad \lesssim \sum_{i=1}^T \EE^i\sbr{ \rbr {\EE_{s_h, b_h}^i\sbr{{\bigrbr{\tilde r_h - r_h + \gamma \bigrbr{\tilde P_h - P_h} V_{h+1}^{\pi^i, \tilde M}}(s_h,a_h, b_h)}}}^2} \nend
    &\qqquad + \gamma^2B_A^2 \sum_{i=1}^T \EE^i\sbr{ D_\TV^2\rbr{\tilde P_h(\cdot\given s_h, a_h, b_h), P_h(\cdot\given s_h, a_h, b_h)}}, 
\end{align*}
where the first inequality holds by the Jensen's inequality, the second inequality holds by upper bounding the difference in $(\tilde P-P)(\tilde V-V^{\pi^i, \tilde M})$ by the TV distance and the upper bound for the follower's V function as $B_A$.
We now invoke \Cref{lem:2nd-ub} for $(\pi^i, Q_h^{\pi^i,\tilde M}, V_{h+1}^{\pi^i, \tilde M})$, which gives us 
\begin{align}
    &\sum_{i=1}^T \max_{h\in[H]}\EE^i\sbr{ \rbr {\EE_{s_h, b_h}^i\sbr{{\bigrbr{\tilde r_h - r_h + \gamma \bigrbr{\tilde P_h - P_h} V_{h+1}^{\pi^i, \tilde M}}(s_h,a_h, b_h)}}}^2} \nend
    &\quad =\sum_{i=1}^T\max_{h\in[H]}\EE^i\sbr{ \rbr{\rbr{Q_h^{\pi^i,\tilde M} - r_h^{\pi^i} - \gamma P_h^{\pi^i}  V_{h+1}^{\pi^i, \tilde M}}(s_h, b_h)}^2} \nend
    &\quad \le \sum_{i=1}^T L^{(2)} \sum_{h=1}^H \cbr{\EE D_\H^2(\nu_h^{\pi^i}(\cdot\given s_h),\nu_h^{\pi^i, \tilde M}(\cdot\given s_h))+\EE D_\TV^2(P_h^{\pi^i}(\cdot\given s_h, b_h),P_h^{\pi^i, \tilde M}(\cdot\given s_h, b_h))}\nend
    &\quad \lesssim L^{(2)} H \beta .\label{eq:PMLE-1}
\end{align}
where in the first inequality, we additionally replace the maximum over $h\in[H]$ as a summation over $h\in[H]$, and the second inequlity holds by the MLE guarantee in \Cref{lem:MLE}. Hence, we conclude that 
\begin{align*}
    &\sum_{i=1}^T \EE^i\sbr{ \rbr {\EE_{s_h, b_h}^i\sbr{{\bigrbr{\tilde r_h - r_h + \gamma \bigrbr{\tilde P_h - P_h} \tilde V_{h+1}}(s_h,a_h, b_h)}}}^2}\nend
    %%%%%%%% split %%%%
    &\quad \lesssim \sum_{i=1}^T \EE^i\sbr{ \rbr {\EE_{s_h, b_h}^i\sbr{{\bigrbr{\tilde r_h - r_h + \gamma \bigrbr{\tilde P_h - P_h} V_{h+1}^{\pi^i, \tilde M}}(s_h,a_h, b_h)}}}^2} \nend
    &\qqquad + \gamma^2B_A^2 \sum_{i=1}^T \EE^i\sbr{ D_\TV^2\rbr{\tilde P_h(\cdot\given s_h, a_h, b_h), P_h(\cdot\given s_h, a_h, b_h)}}\nend
    &\quad \lesssim L^{(2)} H \beta + \gamma^2 B_A^2 \beta, 
\end{align*}
where the last inequality holds by using \eqref{eq:PMLE-1} for the first term and the MLE guarantee in \Cref{lem:MLE} for the second term.
Now, we invoke \Cref{prop:de-regret-prop} and obtain 
\begin{align*}
    &C^{(2)} \cdot 
    \max_{h\in[H]}\EE\bigsbr{ \bigrbr{\orbr{\tilde Q_h - r_h^{\pi^*} - \gamma P_h^{\pi^*} \tilde V_{h+1}}(s_h, b_h)}^2} \nend
    &\quad = C^{(2)} \cdot \max_{h\in[H]}
    \EE\sbr{ \rbr{\EE_{s_h, b_h}\sbr{\bigrbr{\tilde r_h - r_h + \gamma \bigrbr{\tilde P_h - P_h} \tilde V_{h+1}}(s_h, a_h, b_h)}}^2} \nend
    &\quad \lesssim C^{(2)} \bigrbr{L^{(2)} H \beta + \gamma^2 B_A^2 \beta} \nend
    &\qqquad\cdot \max_{h\in[H]}\frac{\EE\sbr{ \rbr{\EE_{s_h, b_h}\sbr{\bigrbr{\tilde r_h - r_h + \gamma \bigrbr{\tilde P_h - P_h} \tilde V_{h+1}}(s_h, a_h, b_h)}}^2}}{\sum_{i=1}^T \EE^i\sbr{ \rbr {\EE_{s_h, b_h}^i\sbr{{\bigrbr{\tilde r_h - r_h + \gamma \bigrbr{\tilde P_h - P_h} \tilde V_{h+1}}(s_h,a_h, b_h)}}}^2}}\nend
    &\quad \lesssim C^{(2)} \bigrbr{L^{(2)} H \beta + \gamma^2 B_A^2 \beta} \nend
    &\qqquad\cdot \max_{h\in[H], M\in\cM}\frac{\EE\sbr{ \rbr{\EE_{s_h, b_h}\sbr{\bigrbr{r_h^{M} - r_h + \gamma \bigrbr{P_h^M - P_h}  V_{h+1}^{\pi^*, M}}(s_h, a_h, b_h)}}^2}}{\sum_{i=1}^T \EE^i\sbr{ \rbr {\EE_{s_h, b_h}^i\sbr{{\bigrbr{r_h^{M} - r_h + \gamma \bigrbr{P_h^M - P_h}  V_{h+1}^{\pi^*, M}}(s_h,a_h, b_h)}}}^2}}, 
\end{align*}
where the first inequality is just a distribution, and the last inequality takes a maximum over $\cM$. 

In summary, for the leader's Bellman error, 
\begin{align*}
    \text{LBE} \lesssim H^2 \sqrt{\beta} \cdot \max_{M\in\cM, h\in[H]} \sqrt{\frac{\EE\sbr{\rbr{\bigrbr{U_h^{\pi^*, M}-\bigrbr{u_h+P_h W_{h+1}^{\pi^*, M}}}(s_h, a_h, b_h)}^2 }}{\sum_{i=1}^T \EE^i\sbr{\rbr{\bigrbr{U_h^{\pi^*, M}-\bigrbr{u_h+P_h W_{h+1}^{\pi^*, M}}}(s_h, a_h, b_h)}^2 }}},
\end{align*}
for the first order term in the follower's quantal response error, 
\begin{align*}
    &\text{1st-QRE} \nend
    &\quad \lesssim  \eta C_\eta H^2\sqrt{ H \eff_H(\gamma)\beta} \nend
    &\qquad \cdot \max_{M\in\cM, h\in[H]}\sqrt\frac{\EE \sbr{\rbr{\rbr{\EE_{s_h, b_h} -\EE_{s_h}}\sbr{\sum_{l=h}^H \gamma^{l-h}\rbr{r_l^M - r_l + \gamma \bigrbr{P_l^M - P_l} V_{l+1}^{\pi^*, M}}(s_l,a_l,  b_l)}}^2}}{\sum_{i=1}^T \EE^i \sbr{\rbr{\rbr{\EE_{s_h, b_h}^i -\EE_{s_h}^i}\sbr{\sum_{l=h}^H \gamma^{l-h}\rbr{ r_l^M - r_l + \gamma \bigrbr{P_l^M - P_l} V_{l+1}^{\pi^*, M}}(s_l,a_l,  b_l)}}^2}}, 
\end{align*}
and for the second order term in the follower's quantal response error, 
\begin{align*}
    &\text{2nd-QRE}\nend
    &\quad \lesssim C^{(2)} L^{(2)} H \beta \nend
    &\qqquad\cdot \max_{h\in[H], M\in\cM}\frac{\EE\sbr{ \rbr{\EE_{s_h, b_h}\sbr{\bigrbr{r_h^{M} - r_h + \gamma \bigrbr{P_h^M - P_h}  V_{h+1}^{\pi^*, M}}(s_h, a_h, b_h)}}^2}}{\sum_{i=1}^T \EE^i\sbr{ \rbr {\EE_{s_h, b_h}^i\sbr{{\bigrbr{r_h^{M} - r_h + \gamma \bigrbr{P_h^M - P_h}  V_{h+1}^{\pi^*, M}}(s_h,a_h, b_h)}}}^2}}. 
\end{align*}
Hence, we complete the proof of \Cref{thm:PMLE}