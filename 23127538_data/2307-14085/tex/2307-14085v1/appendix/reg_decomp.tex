\subsection{Proof of \Cref{lem:MLE} on the Guarantee of MLE}\label{sec:proof-MLE}
The following proof mainly follows the proof of Theorem E.1 in \citet{chen2022unified}.
Recall the MLE function is defined as
\begin{align*}
    \cL^t_h(M)&\defeq -\sum_{i=1}^{t-1}  \bigg(\eta \rbr{Q_{h}^{\pi^i, M}(s_h^i, b_h^i)-V_{h}^{\pi^i, M}(s_h^i)} + \log P_h^M(s_{h+1}^i\given s_h^i, a_h^i, b_h^i)  \nend
    &\qquad - \rbr{u_{h}^i - u_{h}^M(s_h^i, a_h^i, b_h^i)}^2\bigg)\nend
    & = -\sum_{i=1}^{t-1} \rbr{\log \nu_h^{\pi^i, M}(b_h^i\given s_h^i) + \log P_h^M(s_{h+1}^i\given s_h^i, a_h^i, b_h^i) - \rbr{u_{h}^i - u_{h}^M(s_h^i, a_h^i, b_h^i)}^2},
\end{align*}
and the RL distance $D_{\RL, h}$ is defined as
\begin{align*}
    D_{\RL,h}^2 (M,  M^*;\pi) =   \EE^{\pi, M^*}D_\H^2\rbr{\nu_h^{\pi,M}, \nu_h^{\pi,M^*}} +
    \EE^{\pi, M^*} D_\H^2(P_h^{M}, P_h^{M^*}) +
    \EE^{\pi, M^*}\rbr{u_h^{M^*}-u_h^M}^2,
\end{align*}
We take an $\epsilon$-optimistic covering net of $\cM$ and denote the covering number as $\cN_\rho(\cM,\epsilon)$
By \Cref{lem:freeman-variation}, and take the filtration as $\sF_{i-1}=\sigma(\tau^{1:i-1})$, we have with probability at least $1-\delta/3H$, for all $t\in[T]$ and $M$ belonging to a $\epsilon$-covering net $\cM_\epsilon$  that
\begin{align}
    \frac{1}{2} \sum_{i=1}^{t-1} \log \frac{\nu_h^{\pi^i, M}}{\nu_h^{\pi^i, M^*}} 
    &\le \sum_{i=1}^{t-1} \log \EE^{\pi^i}\sbr{\exp\rbr{ \frac{1}{2}\cdot \log \frac{\nu_h^{\pi^i, M}}{\nu_h^{\pi^i, M^*}}}} + \log\rbr{\frac{3H\cN_\rho(\cM,\epsilon)}{\delta}}\nend
    & \le -\sum_{i=1}^{t-1} \EE^{\pi^i}\sbr{1 -  \sqrt{\frac{\nu_h^{\pi^i, M}}{\nu_h^{\pi^i, M^*}}}} + \log\rbr{\frac{3H\cN_\rho(\cM,\epsilon)}{\delta}}\nend
    &= -\frac{1}{2} \sum_{i=1}^{t-1} \EE^{\pi^i}D_\H^2\rbr{\nu_h^{\pi^i,M}(\cdot\given s_h), \nu_h^{\pi^i,M^*}(\cdot\given s_h)} + \log\rbr{\frac{3H\cN_\rho(\cM,\epsilon)}{\delta}}, \label{eq:MLE-nu}
\end{align}
where the first inequality is a direct result of \Cref{lem:freeman-variation}, the second inequality holds by using the inequality $\log(x)\le x-1$, and the last equality holds by the definition of the Hellinger distance.
Following the same argument, we have with probability at least $1-\delta/3H$ and for all $t\in[T]$, $M\in\cM_\epsilon$ that
\begin{align}
    \frac{1}{2}\sum_{i=1}^{t-1} \log \frac{P_h^M}{P_h^{M^*}} \le -\frac{1}{2} \sum_{i=1}^{t-1} \EE^{\pi^i} D_\H^2(P_h^{M}, P_h^{M^*}) + \log\rbr{\frac{3H\cN_\rho(\cM,\epsilon)}{\delta}}.\label{eq:MLE-T}
\end{align}
For the reward, we view $u_h^i$ as a random variable and have with the same argument that it holds with probability at least $1-\delta/3H$ that
\begin{align}
    &\frac 1 3 \sum_{i=1}^{t-1} \rbr{\rbr{u_h^i - u_h^{M^*}}^2 - \rbr{u_h^i - u_h^{M}}^2}\nend
    &\quad \le \sum_{i=1}^{t-1} \log \EE^{\pi^i}\sbr{\exp\rbr{\frac 1 3\rbr{\rbr{u_h^i - u_h^{M^*}}^2 - \rbr{u_h^i - u_h^{M}}^2}}}+\log\rbr{\frac{3H\cN_\rho(\cM,\epsilon)}{\delta}}\nend
    &\quad \le -\sum_{i=1}^{t-1} \frac 1 9 \EE^{\pi^i}\rbr{u_h^{M^*}-u_h^M}^2 + \log\rbr{\frac{3H\cN_\rho(\cM,\epsilon)}{\delta}},\label{eq:MLE-u}
\end{align}
where the second inequality holds by using the inequality $\EE[\exp(\lambda ((r-\EE r)^2-(r - \hat r)^2))]\le \exp\bigrbr{-\lambda(1-2\sigma^2\lambda)\rbr{\EE r - \hat r}^2}$ for any $\lambda\in\RR$, $\hat r\in\RR$ and $\sigma^2$-sub-Gaussian random variable $r$. Here, we notice that $\sup_{h\in[H]}\nbr{u_h}_\infty\le 1$ by our model assumption.
Suppose that for $M\in\cM$, the nearest point to $M$ in the $\epsilon$-covering net is $\tilde M$. 
Note that for the pair $(M, \tilde M)$, we have
\begin{align}\label{eq:D_RL-covering bound}
    &\sup_{\pi\in\Pi, h\in[H]}\abr{D_{\RL,h}^2(M, M^*;\pi) - D_{\RL,h}^2(\tilde M, M^*;\pi)}\nend
    &\quad \le 2\sup_{\pi\in\Pi, h\in[H]}\EE^{\pi, M^*}\sbr{D_\H\rbr{\nu_h^{\pi, M}, \nu_h^{\pi, \tilde M}} + D_\H\rbr{P_h^M, P_h^{\tilde M}} + \abr{u_h^{M}-u_h^{\tilde M}}}\nend
    &\quad \le 6\epsilon, 
\end{align}
where the inequality holds by noting that the Hellinger distance satisfies the triangle inequality and the fact that $D_\H(\cdot,\cdot)\le 1$ and $|u_h|\le 1$. 
Moreover, for the negative log-likelihood function, 
\begin{align}\label{eq:cL-covering bound}
    \cL_h^t(\tilde M) - \cL_h^t(M) &= \sum_{i=1}^{t-1} \rbr{\log \frac{\nu_h^{\pi^i, M}(b_h^i\given s_h^i)}{\nu_h^{\pi^i, \tilde M}(b_h^i\given s_h^i)} + \log \frac{P_h^{M}(s_{h+1}^i\given s_h^i, a_h^i, b_h^i)}{P_h^{\tilde M}(s_{h+1}^i\given s_h^i, a_h^i, b_h^i)}} \nend
    &\qquad + \sum_{i=1}^{t-1} \bigrbr{u_{h}^i - u_{h}^{\tilde M}(s_h^i, a_h^i, b_h^i)}^2 - \rbr{u_{h}^i - u_{h}^M(s_h^i, a_h^i, b_h^i)}^2\nend
    &\le \eta T \sup_{\pi\in\Pi, h\in H} \bignbr{A_h^{\pi,M} - A_h^{\pi,\tilde M}}_\infty + T \log(\exp(\epsilon)) + 2T \sup_{ h\in H} \bignbr{u_h^{M} - u_h^{\tilde M}}_\infty\nend
    &\le 4 T, 
\end{align}
where the first inequality holds by noting the optimistic covering condition $P_h^{M}(s_{h+1}\given s_h, a_h, b_h)\le \exp(\epsilon)P_h^{\tilde M} (s_{h+1}\given s_h, a_h, b_h)$.
Now, using \eqref{eq:MLE-nu}, \eqref{eq:MLE-T}, and \eqref{eq:MLE-u}, we conclude that with probability at least $1-\delta$, for all $M\in \cM$ and $h\in[H]$,
\begin{align*}
    &\sum_{i=1}^{t-1}D_{\RL, h}^2\rbr{M, M^*;\pi^i}\nend
    &\quad \le {\sum_{i=1}^{t-1} \EE^{\pi^i}D_\H^2\rbr{\nu_h^{\pi^i,\tilde M}, \nu_h^{\pi^i,M^*}} +
    \sum_{i=1}^{t-1} \EE^{\pi^i} D_\H^2(P_h^{\tilde M}, P_h^{M^*}) +
    \sum_{i=1}^{t-1} \EE^{\pi^i}\rbr{u_h^{M^*}-u_h^{\tilde M}}^2} + 6\epsilon T\nend
    &\quad \le -3 \rbr{ \sum_{i=1}^{t-1} \log \frac{\nu_h^{\pi^i, \tilde M}}{\nu_h^{\pi^i, M^*}} + 
    \sum_{i=1}^{t-1} \log \frac{P_h^{\tilde M}}{P_h^{M^*}} + 
    \sum_{i=1}^{t-1} \rbr{\rbr{u_h^i - u_h^{M^*}}^2 - \rbr{u_h^i - u_h^{\tilde M}}^2}} \nend
    &\qqquad + 9\log\rbr{\frac{3H\cN_\rho(\cM,\epsilon)}{\delta}}+6T\epsilon \nend
    &\quad\le 3 \rbr{\cL^t_h(\tilde M)- \cL^t_h(M^*)} + 9\log\rbr{\frac{3H\cN_\rho(\cM,\epsilon)}{\delta}} + 6T\epsilon, 
\end{align*}
where the first inequality holds by definition of $D_\RL$ and \eqref{eq:D_RL-covering bound}, the second inequality holds by taking a union bound over the success of \eqref{eq:MLE-nu}, \eqref{eq:MLE-T}, and \eqref{eq:MLE-u}, and the last inequality holds by definition of $\cL^t_h$.
Furthermore, we notice by \eqref{eq:cL-covering bound} that
\begin{align}\label{eq:MLE-D_RL}
    \sum_{i=1}^{t-1}D_{\RL, h}^2\rbr{M, M^*;\pi^i}
    &\le 3 \rbr{\cL^t_h(\tilde M) -  \cL^t_h(M) + \cL^t_h(M)- \cL^t_h(M^*)} + 9\log\rbr{\frac{3H\cN_\rho(\cM,\epsilon)}{\delta}} + 6T\epsilon\nend
    &\le 3 \rbr{\cL^t_h(M)- \cL^t_h(M^*)} + 9\log\rbr{\frac{3H\cN_\rho(\cM,\epsilon)}{\delta}} + 18T\epsilon.
\end{align}
Now, we replace $M$ by $\hat M_{h,\MLE} =\argmin_{M\in\cM} \cL^t_h(M)$, $\epsilon$ by $T^{-1}$ in \eqref{eq:MLE-D_RL} and obtain with probability $1-\delta$ for all $h\in[H], t\in[T]$ that 
\begin{align*}
    \cL^t_h(M^*) - \inf_{M\in\cM}\cL^t_h(M) &\le -\frac 1 3 \sum_{i=1}^{t-1}D_{\RL, h}^2\rbr{M, M^*;\pi^i} + 9\log\rbr{\frac{3H\cN_\rho(\cM,\epsilon)}{\delta}} + 18T\epsilon\nend
    &\le 9\log\rbr{\frac{3H\cN_\rho(\cM,T^{-1})}{\delta}} + 18 = \beta, 
\end{align*}
which shows that $M^*\in \confset^t(\beta)$ with high probability. On the other hand, we plug in any $M\in\confset_\cM^t(\beta)$ and obtain for any $h\in[H]$, $t\in[T]$, and $M\in\confset_\cM^t(\beta)$ that
\begin{align*}
    \sum_{i=1}^{t-1}D_{\RL, h}^2\rbr{M, M^*;\pi^i}
    &\le 3 \rbr{\cL^t_h(M)- \cL^t_h(M^*)} + 9\log\rbr{\frac{3e^2H\cN_\rho(\cM,\epsilon)}{\delta}} \le 4\beta,
\end{align*}
where the last inequality holds by definition of the confidence set. Hence, we complete our proof of \Cref{lem:MLE}.
Lastly, we can also take filtration $\sF_{i-1} = \sigma((s_h^j, a_h^j, b_h^j)_{j\in[i-1]}, s_h^i)$ for \eqref{eq:MLE-nu} and $\sF_{i-1} = \sigma((s_h^j, a_h^j, b_h^j)_{j\in[i]})$ for \eqref{eq:MLE-T} and \eqref{eq:MLE-u}, follows exactly the same steps, and obtain
\begin{align*}
    \sum_{i=1}^{t-1} \hat D_{\RL,h,i}^2(M,M^*) 
    % &\le \frac 3 2  \sum_{i=1}^{t-1}D_{\RL, h}^2\rbr{M, M^*;\pi^i} + 6 \log (eH\cN_\rho(\cM,T^{-1})\delta^{-1}) 
    \le 4 \beta,
\end{align*}
which finishes the proof of \Cref{lem:MLE}.
