We give a proof for offline learning the best leader's policy with myopic follower and general function class.
The proof will be carried out in three steps. In the first step, we check the validity and the accuracy of the confidence built by our algorithm. 
In the second step, we decompose the suboptimality of the leader's total reward and relate the suboptimality to the leader's Bellman error and the follower's response error under the optimal policy $\pi^*$. 
In the last step, we relate the suboptimality to the guarantee of the confidence set via a distribution shift argument, which gives us the offline learning guarantee.

\paragraph{Step 1. Validity and Accuracy of the Confidence Set.}
We first recall the confidence set constructed in \eqref{eq:myopic-offline-general-confset},
\begin{align}
    &\CI_{\cU, \Theta}^\pi(\beta) \nend
    &\quad= \cbr{
    (U,\theta)\in\cU^{\otimes H}\times\Theta:
    \rbr{ \ds
        \cL_h(\theta_h)-\inf_{\theta'\in\Theta_h}\cL_h(\theta') \le \beta 
    \atop \ds
        \ell_h(U_h, U_{h+1}, \theta_{h+1}, \pi) - \inf_{U'\in\cU_h} \ell_h(U', U_{h+1}, \theta_{h+1}, \pi)\le H^2\beta}, 
    \forall h\in[H]}. \label{eq:myopic-offline-general-confset-1}
\end{align}
which contains constraints for both the follower's reward parameter $\theta$ and the leader's value function $U$. 


To see that this confidence set is valid, 
we first look at the follower's side by invoking \Cref{lem:MLE-indep-data}. To do so, we need to check the conditions of \Cref{lem:MLE-formal} as the following: 
\begin{itemize}
    \item[(i)] the data compliance condition $\PP^{\pi^t}(b_h^t\given s_h^t, (s_j^t, a_j^t, b_j^t, u_j^t)_{j\in[h-1]}, \tau^{1:t-1})  = \nu_h^{\pi^t}(b_h^t\given s_h^t), \forall h\in[H], t\in[T]$ is satisfied for independently collected trajectories; 
    \item[(ii)] $\beta \ge  2\log(e^3H\cdot \cN_\rho(\Theta, T^{-1})/\delta)$ holds by our condition on $\beta$, where $\cN_\rho(\Theta,\epsilon)= \max_{h\in[H]} \cN_\rho(\Theta_h,\epsilon)$ and the distance $\rho$ is specified by \eqref{eq:rho-Theta}.
    \item[(iii)] The confidence set for $\theta$ in \eqref{eq:myopic-offline-general-confset-1} is exactly the same as \eqref{eq:behavior_model_confset-1}. 
\end{itemize}
Therefore, \Cref{lem:MLE-indep-data} combined with \Cref{rmk:MLE-formal-myopic} says it holds with probability at least $1-2\delta$ that (i) $\theta^*\in\CI_{\cU,\Theta}^\pi(\beta)$; (ii) for any $\theta\in\CI_{\cU,\Theta}^\pi(\beta)$ and $h\in[H]$ that
\begin{align*}
    \sum_{i=1}^T\EE_\cD\sbr{D_\H^2\rbr{\nu_h^{\pi^i, \theta}(\cdot\given s_h^i), \nu_h^{\pi^i, \theta^*}(\cdot\given s_h^i)}}  \lesssim\beta.
\end{align*}
Now, using the relationship between the Hellinger distance and the variance of the Q function given by \eqref{eq:MLE_guarantee_Q} in \Cref{lem:MLE-formal}, we conclude that for all $h\in[H], \theta\in\CI_{\cU, \Theta}^\pi(\beta)$, $\pi\in\Pi$,  
\begin{align}
    \sum_{i=1}^{T} \EE_\cD {\Var_{s_h}^{\pi^i, \theta^*} \bigsbr{r_h^{\pi^i, \theta}(s_h, b_h) - r_h^{\pi^i, \theta^*}(s_h, b_h)}} \lesssim (\eta^{-1}+ B_A)^{2} \beta,\label{eq:OffMG-variance-r-MLE-guarantee}
\end{align}
where we plug in $Q_h^{\pi, \theta}=r_h^{\pi,\theta}$ for myopic follower.
Therefore, we justify that $\CI_{\cU,\Theta}^\pi(\beta)$ is a valid confidence set for $\theta$ with probability at least $1-2\delta$.



We next look at the leader's side.
For the leader's value function, we invoke \Cref{lem:leader-bellman-loss} which says that under the realizability and completeness assumptions,  if $$H^2\beta \ge 
{110 H^2\cdot\log(H \cN_\rho(\cY, T^{-1})\delta^{-1}) }  + (45 H^2 + 60 H )$$ for the joint class $\cY_h=\cU^2\times\Pi_{h+1}\times\Theta_{h+1}$ where $\cN_\rho(\cdot)$ is defined in \eqref{eq:rho-cY}, we have with probability at least $1-\delta$ that for any $\theta\in\CI_{\cU,\Theta}^\pi(\beta)$, $\pi\in\Pi$ and $h\in[H]$: (i) $U^{\pi,\theta}\in\CI_{\cU,\Theta}^\pi(\beta)$; (ii) $\EE_\cD[( U_{h} - \TT_{h}^{\pi,\theta}U_{h + 1})^2]\le 4H^2 \beta T^{-1}$ for any $U\in\CI_{\cU,\Theta}^\pi(\beta)$. Note that $\EE_\cD$ takes expecation with respect to the data generating distribution.

In particular, the condition $H^2\beta \ge 
{110 H^2\cdot\log(H \cN_\rho(\cY, T^{-1})\delta^{-1}) }  + (45 H^2 + 60 H )$ is automatically satisfied by our choice of $\beta$.
Therefore, we conclude that with probabiility at least $1-3\delta$, we have that: 
(i) (validity) $(\theta^*, U^{\theta^*, \pi})\in\CI_{\cU,\Theta}^\pi(\beta)$ for all $\pi\in\Pi$; 
(ii) (accuracy) $\EE_\cD[(U_{h} - \TT_{h}^{\pi,\theta} U_{h + 1})^2]\lesssim H^2\beta T^{-1}$ and 
\eqref{eq:OffMG-variance-r-MLE-guarantee} for all $(U, \theta)\in\CI_{\cU,\Theta}^\pi(\beta), \pi\in\Pi, h\in [H]$. The following part is based on the sucess of the confidence set $\CI_{\cU, \Theta}^\pi(\beta)$.


\paragraph{Step 2. Suboptimality Decomposition.}
Recall the pessimistic policy optimization in \eqref{eq:offline-MG-pi^hat},
\begin{align}
    (\hat\pi, \hat U, \hat \theta)=\argmax_{\pi\in\Pi} \argmin_{(U, \theta)\in\CI_{\cU,\Theta}^\pi(\beta)} 
    \underbrace{\EE_{s_1\sim\rho_0} \sbr{\inp[\big]{U_1(s_1, \cdot, \cdot)}{\pi_1\otimes\nu_1^{\pi, \theta}(\cdot,\cdot\given s_1)}}}_{\ds J(\pi, U, \theta)}.\label{eq:offline-MG-pi^hat-1}
\end{align}
Define $(\tilde U, \tilde \theta) = \argmin_{(U, \theta)\in\CI_{\cU,\Theta}^{\pi^*}(\beta)} J(\pi^*, U, \theta)$ as the pessimistic estimators of $U$ and $\theta$ under $\pi^*$, respectively.
We can decompose the suboptimality as 
\begin{align*}
    \subopt(\hat\pi) &= J(\pi^*)-J(\hat\pi) \nend
    & = J(\pi^*)- J(\pi^*, \tilde U, \tilde \theta) + \underbrace{J(\pi^*, \tilde U, \tilde \theta) - J(\hat\pi, \hat U, \hat \theta)}_{\dr  (i)} +  \underbrace{J(\hat\pi, \hat U, \hat \theta) - J(\hat\pi)}_{\dr (ii)} \nend
    &\le J(\pi^*)- \EE_{s_1\sim\rho_0} \sbr{\inp[\big]{\tilde U_1(s_1, \cdot, \cdot)}{\pi_1^*\otimes\nu_1^{\pi^*, \tilde\theta}(\cdot,\cdot\given s_1)}_{\cA \times \cB }}
\end{align*}
where the inequality holds by noting that $(\textrm{i})\le 0$ and $(\textrm{ii})\le 0$.
Here, $(\textrm{i})\le 0$ simply by policy optimization in \eqref{eq:offline-MG-pi^hat-1}.
For $(\textrm{ii})$, we note that
$J(\hat\pi) = J(\hat\pi, U^{\hat\pi,\theta^*}, \theta^*)\ge J(\hat\pi, \hat U,\hat \theta)$ following from the validity of the confidence set $\CI_{\cU,\Theta}^\pi(\theta)$ that $(U^{\hat\pi, \theta^*}, \theta^*)\in \CI_{\cU,\Theta}^{\hat\pi}(\theta)$ and also that $\hat U, \hat\theta$ is the minimizer to $J(\hat\pi, \cdot, \cdot)$.
The remaining term is just the estimation error with respect to $\pi^*$. For simplicity, we let $\tilde\nu(b_h\given s_h)=\nu^{\pi^*, \tilde \theta}(b_h\given s_h)$ and $\tilde r^{\pi^*}(s_h,b_h) = r^{\pi^*,\tilde \theta}(s_h, b_h)$. We now invoke \Cref{lem:subopt-decomposition} on the suboptimality decomposition (applied with $\pi^*, \tilde U, \tilde \nu$) and \Cref{cor:response-diff-myopic} on the response model error, which gives us,
\begin{align}
    \subopt(\hat\pi)
    &\le {{\sum_{h=1}^H \EE\abr{\bigrbr{\tilde U_h - u_h}(s_h, a_h, b_h)-  T_{h+1}^{{\pi^*},\tilde\nu} \tilde U_{h+1}(s_{h+1})}}}
    + {\sum_{h=1}^H  H \EE \nbr{\rbr{\tilde \nu_h-\nu_h}(\cdot\given s_h)}_1}\nend
    &\le {\sum_{h=1}^H \underbrace{\EE\abr{\bigrbr{\tilde U_h - u_h}(s_h, a_h, b_h)-  T_{h+1}^{{\pi^*},\tilde\nu} \tilde U_{h+1}(s_{h+1})}}_{\dr (I_1)}}\nend
    &\qquad + \sum_{h=1}^H  2H \eta  \underbrace{\EE\sbr{\abr{(\tilde r_h^{\pi^*}(s_h, b_h) - r_h^{\pi^*}(s_h, b_h)) - \EE\bigsbr{\tilde r_h^{\pi^*}(s_h, b_h) - r_h^{\pi^*}(s_h, b_h)}}}}_{\dr  (I_2)} \label{eq:OffMG-subopt}\\
    &\qquad + \sum_{h=1}^H  2H C^{(3)} \underbrace{\EE\sbr{\rbr{\rbr{\tilde r_h^{\pi^*}(s_h, b_h) -r_h^{\pi^*}(s_h, b_h)} - \EE\sbr{\tilde r_h^{\pi^*}(s_h, b_h) -r_h^{\pi^*}(s_h, b_h)}}^2}}_{\dr (I_3)},   \notag
\end{align}
where the expectation is taken with respect to $\pi^*$ and the true model. 
\paragraph{Step 3. Handling the Distribution Shift.} 
For term $(\dr{I_1})$, we have by the accuracy result on the leader's side that
\begin{align}
    (\dr{I_1}) 
    &\le \sqrt{\EE\sbr{\rbr{\rbr{\tilde U_h -  \TT_h^{\pi^*,\tilde\theta} \tilde U_{h+1}} (s_h, a_h, b_h)}^2}}\nend
    & \lesssim \sqrt{H^2\beta T^{-1}} \cdot \frac{\sqrt{{\bignbr{{\tilde U_h  -  \TT_h^{\pi^*,\tilde\theta} \tilde U_{h+1}} }_{2, d^{\pi^*}}^2}}}{\sqrt{\|\tilde U_{h} - \TT_{h}^{\pi^*,\tilde\theta} \tilde U_{h + 1}\|_{2, \cD}^2}}\nend
    %%%%%%%%%
    &\le \sqrt{H^2\beta T^{-1}} \cdot \max_{U\in\cU,\theta\in\Theta}
    \sqrt{\frac{{{\bignbr{{ U_h  -  \TT_h^{\pi^*,\theta}  U_{h+1}} }_{2, d^{\pi^*}}^2}}}{{{\bignbr{ U_{h} - \TT_{h}^{\pi^*,\theta}  U_{h + 1}}_{2,\cD}^2}}}}. \label{eq:OffMG-I1}
\end{align}
where we define $\nbr{\cdot}_{2, d^{\pi^*}}^2 = \EE^{\pi^*}\sbr{(\cdot)^2}$ and define $\nbr{\cdot}_{2, \cD}^2 = \EE_\cD\sbr{(\cdot)^2}$. Here, $d^{\pi^*}$ is the distribution of the trajectory generated under $\pi^*$, and $\EE_\cD$ is taken with respect to the data generating distribution, where the policy $\pi^i$ is also random. 
Here, the first inequality holds by noting that the leader's Bellman operator satisifies $\TT_h^{\pi^*,\tilde\theta} = u_h + P_h \circ T_{h+1}^{\pi^*, \tilde\nu} $ by definition and using the Cauchy-Schwartz inequality, and the first inequality holds by using $\EE_\cD[\|\tilde U_{h} - \TT_{h}^{\pi^*,\tilde \theta} \tilde U_{h + 1}\|^2]\lesssim H^2\beta T^{-1}$ for $(\tilde \theta, \tilde U)$ in the confidence set $\CI_{\cU,\Theta}^{\pi^*}(\beta)$. 
The last inequality holds by further taking a supreme over all possible $(\tilde U, \tilde\theta)$.
We remind the readers that the expectation in the numerator is taken with respect to $\pi^*$ and the true model. The supremum taken over both $\cU$ and $\Theta$ is reasonable because we treat $(\theta,U)$ as the model and need small Bellman error ensured from each choice of $(\theta, U)$.

For term $\dr (I_2)$ and $\dr (I_3)$, we first note that using the Cauchy Schwartz inequality, we have that $\dr (I_2)\le \sqrt{(\dr I_3)}$. Therefore, we just need to control $(\dr I_3)$. Then, we have by the accuracy of the confidence set on the follower's side that
\begin{align}
    {\dr (I_3)}
    &= \EE\sbr{\rbr{\rbr{\tilde r_h^{\pi^*}(s_h, b_h) -r_h^{\pi^*}(s_h, b_h)} - \EE\sbr{\tilde r_h^{\pi^*}(s_h, b_h) -r_h^{\pi^*}(s_h, b_h)}}^2} \nend
    &\lesssim {(\eta^{-1}+ B_A)^{2} \beta T^{-1}} \cdot {
        \frac{\EE\Var_{s_h}^{\pi^*,\theta^*}\sbr{\rbr{\tilde r_h^{\pi^*} - r_h^{\pi^*}}(s_h, b_h)}} 
        {\EE_\cD \Var_{s_h}^{\pi^i, \theta^*} \sbr{\rbr{\tilde r_h^{\pi^i} - r_h^{\pi^i}}(s_h, b_h)}}
    }\nend
    &\le {(\eta^{-1}+ B_A)^{2} \beta T^{-1}} \cdot \max_{\theta\in\Theta} {
        \frac{\EE\Var_{s_h}^{\pi^*,\theta^*}\sbr{\rbr{r_h^{\pi^*, \theta} - r_h^{\pi^*, \theta^*}}(s_h, b_h)}} 
        {\EE_\cD \Var_{s_h}^{\pi^i, \theta^*} \sbr{\rbr{r_h^{\pi^i, \theta} - r_h^{\pi^i, \theta^*}}(s_h, b_h)}}
    }. \label{eq:OffMG-I3}
\end{align}
where the first inequality holds by plugging in $\tilde \theta$ into the superscript of the follower's reward function in \eqref{eq:OffMG-variance-r-MLE-guarantee}, which still ensures the guarantee in \eqref{eq:OffMG-variance-r-MLE-guarantee} because $\tilde \theta\in\CI_{\cU,\Theta}^{\pi^*}(\beta)$, and the last inequality holds by taking a supremum over $\tilde\theta\in\Theta$. We remind the readers that $\Var_{s_h}^{\pi^*, \theta^*}$ is taken with respect to $\nu_h^{\pi^*, \theta^*}(\cdot\given s_h)$.
For the follower's side, recall the linear operator $\Upsilon_h^\pi:\cF(\cS\times\cA\times\cB)\rightarrow \cF(\cS\times\cB)$ defined as 
\begin{align*}
    \rbr{\Upsilon_h^\pi f}(s_h, b_h) = \dotp{\pi_h(\cdot\given s_h, b_h)}{f(s_h, \cdot, b_h)} - \dotp{\pi_h\otimes \nu_h^{\pi}(\cdot,\cdot\given s_h)}{f(s_h,\cdot,\cdot)}. 
\end{align*}
Here, $(\Upsilon_h ^{\pi} f ) (s_h,b_h) $ quantifies  how far $b_h$ is from being the quantal response of $\pi$ at state $s_h$, measured in terms of  $f$. One can also think of $(\Upsilon_h^\pi f)(s_h, b_h)$ as the \say{advantage} of the reward induced by action $b_h$ compared to the reward induced by the quantal response. 
We remark that the distribution shift in \eqref{eq:OffMG-I3} can be equivalently written as  
\begin{align*}
    \max_{\theta\in\Theta} 
        \frac{\EE\Var_{s_h}^{\pi^*,\theta^*}\sbr{\rbr{r_h^{\pi^*, \theta} - r_h^{\pi^*, \theta^*}}(s_h, b_h)}} 
        {\EE_\cD \Var_{s_h}^{\pi^i, \theta^*} \sbr{\rbr{r_h^{\pi^i, \theta} - r_h^{\pi^i, \theta^*}}(s_h, b_h)}} 
        &= \max_{\theta\in\Theta} \frac{\EE \sbr{\rbr{\rbr{\Upsilon_h^{\pi^*} (r_h^\theta - r_h^{\theta^*})}(s_h, b_h)}^2}}{\EE_\cD \sbr{\rbr{\rbr{\Upsilon_h^{\pi^i} (r_h^\theta - r_h^{\theta^*})}(s_h, b_h)}^2}}\nend
        & = \max_{\theta\in\Theta} \frac{{\bignbr{\Upsilon_h^{\pi^*} (r_h^\theta - r_h^{\theta^*})}_{2, d^{\pi^*}}^2}}{\bignbr{{\Upsilon_h^{\pi^i} (r_h^\theta - r_h^{\theta^*})}}_{2,\cD}^2}
\end{align*}
% \Zhuoran{simplify notation, explain the meaning of expectations. Maybe use another notation.}
% $\mathtt{Var}^* (\theta) = $ $\mathtt{Var}_{\cD} (\theta ) = \EE_\cD \Var_{s_h}^{\pi^i, \theta^*} \sbr{\rbr{r_h^{\pi^i, \theta} - r_h^{\pi^i, \theta^*}}(s_h, b_h)}$

% $\mathtt{BE}^*(\theta)$ and $\mathtt{BE}_{\cD} (\theta)$.


Now, plugging the results in \eqref{eq:OffMG-I1} and \eqref{eq:OffMG-I3} back into the suboptimality decomposition \eqref{eq:OffMG-subopt}, we have our result that
\begin{align*}
\subopt(\hat\pi) 
&\lesssim \max_{U\in\cU,\theta\in\Theta, h\in[H]}
    \sqrt{\frac{{{\bignbr{{ U_h  -  \TT_h^{\pi^*,\theta}  U_{h+1}} }_{2, d^{\pi^*}}^2}}}{{{\bignbr{ U_{h} - \TT_{h}^{\pi^*,\theta}  U_{h + 1}}_{2,\cD}^2}}}} 
\cdot H^2\sqrt{\beta T^{-1}}  \nend
&\qquad + \max_{\theta\in\Theta, h\in[H]}\sqrt{ \frac{{\bignbr{\Upsilon_h^{\pi^*} (r_h^\theta - r_h^{\theta^*})}_{2, d^{\pi^*}}^2}}{\bignbr{{\Upsilon_h^{\pi^i} (r_h^\theta - r_h^{\theta^*})}}_{2,\cD}^2}} \cdot  H^2 \sqrt{(1+\eta B_A)^2\beta T^{-1}}\nend
&\qquad  +   \max_{\theta\in\Theta, h\in[H]} {
    \frac{{\bignbr{\Upsilon_h^{\pi^*} (r_h^\theta - r_h^{\theta^*})}_{2, d^{\pi^*}}^2}}{\bignbr{{\Upsilon_h^{\pi^i} (r_h^\theta - r_h^{\theta^*})}}_{2,\cD}^2}
}\cdot  H^2 C^{(3)}{(\eta^{-1}+ B_A)^{2} \beta T^{-1}}.
\end{align*}
Moreover, note that 
\begin{align*}
    C^{(3)} (\eta^{-1}+B_A)^2 &\le \frac 1 2 \eta^2 \exp(2\eta B_A)(2+\eta B_A\exp(2\eta B_A)) (\eta^{-1}+B_A)^2\nend
    &\le \exp(4\eta B_A) (1+\eta B_A)^3\nend
    &\le \exp(4\eta B_A) (\eta C_\eta)^3,
\end{align*}
where $C_\eta = \eta^{-1}+B_A$. 
Therefore, we complete the proof of \Cref{thm:Offline-MG}.
