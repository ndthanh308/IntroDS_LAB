\section{Proofs for Farsighted Case}
Before we dive into the proof, we first present the following guarantee for the MLE method used in \S\Cref{sec:farsighted}.
\begin{lemma}[Guarantee of MLE]\label{lem:MLE}
    By choosing $\beta\ge  \allowbreak 9\log(3e^2H \cN_\rho(\cM,T^{-1})\delta^{-1})$, where $\cN_\rho(\cM,\epsilon)$ is the minimal size of an $\epsilon$-optimistic covering net of $\cM$. Here, an $\epsilon$-optimistic covering net $\cM_\epsilon\subset \cM$ is a finite subset such that for any $M\in\cM$, there exists $\tilde M\in\cM_\epsilon$ satisfying the following conditions:
    \begin{itemize}[leftmargin=20pt]
        \item[(i)] $D_\H\orbr{\nu_h^{\pi, M}(\cdot\given s_h), \nu_h^{\pi, \tilde M}(\cdot\given s_h)}\le \epsilon$, $D_\H\orbr{P_h^M(\cdot\given s_h, a_h, b_h), \allowbreak P_h^{\tilde M}(\cdot\given s_h, a_h, b_h)}\le \epsilon$, $\bigabr{(u_h^{M}-u_h^{\tilde M})(s_h,a_h,b_h)} \le \epsilon$, and $|(A_h^{\pi, M}-A_h^{\pi, \tilde M})(s_h, b_h)|\le \eta^{-1} \epsilon$ for all $\pi\in\Pi$, $h\in[H]$, $(s_h, a_h, b_h)\in\cS\times\cA\times\cB$;
        \item[(ii)] $P_h^{M}(s_{h+1}\given s_h, a_h, b_h)\le \exp(\epsilon)P_h^{\tilde M} (s_{h+1}\given s_h, a_h, b_h)$ for all $h\in[H]$ and $(s_{h+1}, s_h, a_h, b_h)\in\cS^2 \times \cA\times\cB$.
    \end{itemize}
%  \begin{align*}
%     &\rho(M, \tilde M) \nend
%     &\quad\defeq 6\max_{\pi\in\Pi, h\in[H]\atop (s_h, a_h, b_h)\in\cS\times\cA\times\cB}\Big\{D_\H\orbr{\nu_h^{\pi, M}(\cdot\given s_h), \nu_h^{\pi, \tilde M}(\cdot\given s_h)} , 
%     D_\H\orbr{P_h^M(\cdot\given s_h, a_h, b_h), \allowbreak P_h^{\tilde M}(\cdot\given s_h, a_h, b_h)} , \nend
%     &\qqquad \qqquad \qqquad \bigabr{(u_h^{M}-u_h^{\tilde M})(s_h,a_h,b_h)}, \bigabr{\orbr{Q_h^{\pi,M} - Q_h^{\pi,\tilde M}}(s_h,b_h)}\Big\}.
% \end{align*} 
The confidence set $\CI_\cM^t(\beta)$ satisfies the following with probability at least $1-\delta$: for any given $t\in[T]$, $M^*\in\confset_\cM^t(\beta)$, and it also holds for $\forall h\in[H], \forall M\in\confset^t(\beta)$ that
    \begin{align*}
        \sum_{i=1}^{t-1}D_{\RL, h}^2\rbr{M, M^*,\pi^i}
        \le 4\beta,\quad 
        \sum_{i=1}^{t-1}\hat D_{\RL, h,i}^2\rbr{M, M^*}
        \le 4\beta, 
    \end{align*}
 where 
    \begin{align*}
        D_{\RL,h}^2 (M,  M^*;\pi) &=   \EE^{\pi, M^*}D_\H^2\rbr{\nu_h^{\pi,M}, \nu_h^{\pi,M^*}} +
        \EE^{\pi, M^*} D_\H^2(P_h^{M}, P_h^{M^*}) +
        \EE^{\pi, M^*}\rbr{u_h^{M^*}-u_h^M}^2,\nend
        %%%%%%%%%%%
        D_{\RL,h,i}^2(M,M^*) &= D_\H^2\orbr{\nu_h^{\pi^i, M}(\cdot\given s_h^i), \nu_h^{\pi^i, \tilde M}(\cdot\given s_h^i)} +
        D_\H^2\orbr{P_h^M(\cdot\given s_h^i, a_h^i, b_h^i), \allowbreak P_h^{\tilde M}(\cdot\given s_h^i, a_h^i, b_h^i)} \nend
        &\qquad + \bigrbr{(u_h^{M}-u_h^{\tilde M})(s_h^i,a_h^i,b_h^i)}^2,
    \end{align*}
    and $\EE^{\pi, M}$ is taken under policy $\pi$ and the model $M$.
    \begin{proof}
        See \Cref{sec:proof-MLE} for a detailed proof.
    \end{proof}
\end{lemma}
\Cref{lem:MLE} guarantees that the confidence set $\confset^t(\beta)$ is valid in the sense that $M^*\in\confset^t(\beta)$ and any $M\in\confset^t(\beta)$ has $D_\RL$ bounded by $\cO(\beta)$. 
For the optimistic covering net, we remark that constraints in the first conditions are discussed in \eqref{eq:rho-cM}. The second condition requires $P_h^M$ to be dominated above by $P_h^{\tilde M}$, which is needed to control the difference in the log-likelihood.

\subsection{Proof of \Cref{thm:PMLE} on PMLE wiith Farsighted Follower}
\label{sec:proof-PMLE}
\input{appendix/app_E/Offline_FG.tex}

\subsection{Proof of \Cref{thm:OMLE-farsighted} on OMLE with Farsighted Follower}\label{sec:proof-farsighted MDP}
\input{appendix/app_E/Online_FG.tex}

% Specifically, for any leader's policy $\pi\in\Pi$, the true model $M^*$ and an alternative model $\tilde M\in\cM$, we have
% \begin{align}
%     &J(\pi, \tM) - J(\pi, M^*) \nend
%     &\quad = {\sum_{h=1}^H \EE^{\pi, M^*}\sbr{\tilde U_h(s_h, a_h, b_h) - u_h(s_h, a_h, b_h)- \tilde W_{h+1}(s_{h+1})}} + \sum_{h=1}^H \EE^{\pi, M^*}\sbr{\tilde W_h(s_h)-\tilde U_h(s_h, a_h, b_h)}\nend
%     &\quad\le\underbrace{{\sum_{h=1}^H \EE^{\pi, M^*}\sbr{\tilde U_h(s_h, a_h, b_h) - u_h(s_h, a_h, b_h)- \tilde W_{h+1}(s_{h+1})}}}_{\dr \text{temporal difference}}+ \underbrace{\sum_{h=1}^H  H \EE \nbr{\tnu_h(\cdot\given s_h)-\nu_h(\cdot\given s_h)}_1}_{\dr \text{response difference}}, \label{eq:performance diff}
% \end{align}
% where $\tilde U_h, \tilde W_h, \tilde\nu_h$ are the correspondences of $U_h, W_h, \nu_h$ under model $\tilde M$.
% In the following, we denote the above $h$-step temporal difference by $\cE^{(0)}_h(\tM, M^*;\pi)$, which is a standard result from classical MDP.
% We call the second term response difference since the second term characterize the TV distance between the follower's true response and an estimated response learned by the leader.
% Here, we have to invoke the TV bound since the follower's utility is not aligned with the leader's. 
% A unique challenge of our problem is to characterize the response difference in the face of a strategic follower.
% The following lemma states that the  follower's response difference admits a \say{Taylor expansion} flavored decomposition. 
% \begin{lemma}[\textit{Response difference for farsighted follower}]
%     % \label{lem:performance diff}
% For any given leader's policy $\pi$, the true model $M^*$ and an alternative model $\tM\in\cM$, using the denotions specified in \Cref{tab:notation}, the response difference term in \eqref{eq:performance diff} can be upper bounded by
% \begin{align}
%     &\sum_{h=1}^H  H \EE \nbr{\tnu_h(\cdot\given s_h)-\nu_h(\cdot\given s_h)}_1 \nend
%     &\quad \le 2\eta  H \cdot 
%     \sum_{h=1}^H \underbrace{\EE^{\pi, M^*}\sbr{\abr{\rbr{\EE^{\pi, M^*}_{s_h, b_h}-\EE^{\pi, M^*}_{s_h}}\bigsbr{\Delta^{(1)}_{h,\pi, \tM}(s_h, b_h)}}}}_{\ds \cE^{(1)}_h(\tM, M^*;\pi)} \nend
%     & \qqquad + \underbrace{\eta^2  H  \rbr{1+ 4 \frac{1-\gamma^H}{1-\gamma}}}_{\ds C^{(1)}} \cdot 
%     \sum_{h=1}^H \underbrace{\EE^{\pi, M^*}\sbr{ \exp\bigrbr{\eta\bigabr{A_h-\tilde A_h}}\cdot \bigabr{\tilde A_h - A_h}^2}}_{\ds \cE^{(2)}_h(\tM, M^*;\pi)}, \label{eq:response decomposition}
% \end{align}
% where $ H = \max_{h\in[H], \pi\in\Pi, M\in\cM}\bignbr{U_h^{\pi, M}}_\infty$ and $\Delta^{(1)}_{h,\pi, M}(s_h, b_h)$ is defined as
% \begin{align}
%     \Delta^{(1)}_{h,\pi, \tM}(s_h, b_h) &\defeq  \EE_{s_h, b_h}\sbr{\sum_{i=h}^H \gamma^{i-h}\rbr{r_i^\pi(s_h, b_h)-\tilde r_i^\pi(s_h, b_h) + \gamma \rbr{\bigrbr{\TT_i^\pi -\tilde\TT_i^\pi}\tilde V_{i+1}}(s_h, b_h)}}.\label{eq:def Delta^1}
% \end{align}
% \begin{proof}
%     See \Cref{sec:performance diff} for a detailed proof.
% \end{proof}
% \end{lemma}

% Therefore, the online regret can be reorganized into
% \begin{align*}
%     \Reg(T)\le \sum_{t=1}^T \Biggrbr{\underbrace{\sum_{h=1}^H\cE^{(0)}_h\bigrbr{M^t, M^*;\pi^t} + 2\eta H\sum_{h=1}^H \cE^{(1)}_h\bigrbr{M^t, M^*;\pi^t}}_{\ds I_t: \text{1st-order terms}} + \underbrace{C^{(1)} \sum_{h=1}^H \cE^{(2)}_h\bigrbr{M^t, M^*;\pi^t}}_{\ds J_t: \text{ 2nd-order term}}}.
% \end{align*}
% Here, we notice that $\cE^{(0)}$ and $\cE^{(1)}$ are first order terms in the sense that both $\cE^{(0)}$ and $\cE^{(1)}$ have a linear form while $\cE^{(2)}$ is the second order term and depends quadratically on $|\tilde A_h - A_h|$. In the sequel, we aim to bound them separately.

% \paragraph{Step 2. Bounding the First Order Terms.}
% A key point for bounding the first order terms is relating the guarantee of MLE in \Cref{lem:MLE} to the first order error $\cE^{(0)}, \cE^{(1)}$, which is done by a characterization in terms of the Eluder dimensions.
% % \begin{lemma}[\textit{Eluder dimension bound, Lemma 41 in \citet{jin2021bellman}}] \label{lem:1st-eluder}
% %     Given a function class $\cF$ defined on $\cX$ with $\abr{f(x)}<C$ for all $(f,x)\in \cF\times \cX$. Suppose sequences $\{f_t\}_{t=1}^T$ and $\{x_t\}_{t=1}^T$ satisfy that for all $t\in[T]$, $\sum_{j=1}^{t-1} f_j(x_t)^2\le \beta$. Then for all $t\in[T]$ and $w>0$, we have the first order guarantee
% %     \begin{align*}
% %         \sum_{j=1}^t \abr{f_j(x_j)} \le 2\sqrt{\dimE(\cF, \cX, w)\beta t} + \min\cbr{t, \dimE(\cF, \cX, w)} C + t w, 
% %     \end{align*}
% %     and also the second order guarantee
% %     \begin{align*}
% %         \sum_{j=1}^t f_{j}(x_j)^2 \le \dimE(\cF, \cX, w) \beta \log t + \min\cbr{t, \dimE(\cF, \cX, w)} C^2 + t w^2.
% %     \end{align*}
% %     \begin{proof}
% %         \todo{to be added.}
% %     \end{proof}
% % \end{lemma} 
% Note that \Cref{lem:1st-eluder} is slightly different from the original version in the sense that we include a second order guarantee, which is an adaptation of the original proof. 
% Recall that 
% \begin{align*}
%     \cE^{(0)}_h(\tilde M, M^*;\pi) &= \EE^{\pi, M^*}\sbr{\tilde U_h(s_h, a_h, b_h) - u_h(s_h, a_h, b_h)- \tilde W_{h+1}(s_{h+1})}\nend
%     & =  \EE^{\pi, M^*}\sbr{\tilde u_h  - u_h + \rbr{\tilde \TT_h - \TT_h} \tilde W_{h+1}} ,
% \end{align*}
% and by definition of $\Delta^{(1)}$ in \eqref{eq:def Delta^1} that
% \begin{align*}
%     \cE^{(1)}_h(\tilde M, M^*;\pi)
%     &=\EE^{\pi, M^*}\sbr{\abr{\rbr{\EE^{\pi, M^*}_{s_h, b_h}-\EE^{\pi, M^*}_{s_h}}\bigsbr{\Delta^{(1)}_{h,\pi, \tM}(s_h, b_h)}}}\nend
%     &= \EE^{\pi, M^*}\abr{\sum_{i=h}^H\gamma^{i-h}\rbr{\EE_{s_h, b_h}^{\pi, M^*} - \EE_{s_h}^{\pi, M^*}}\sbr{\tilde r_i-r_i+\gamma \rbr{\tilde\TT_i - \TT_i}\tilde V_{i+1}}}.
% \end{align*}
% Now, the task boils down to finding a $f$ such that: (i) the first order terms $\cE^{(0)}$ and $\cE^{(1)}$ are bounded by this $f$; (ii) $\sum_{j=1}^{t-1} f_j^2\le \cO(\beta)$ can be guaranteed by the MLE.
% Following this spirit, we construct $f_{0,h}^M, f_{1, h}^M$ as
% \begin{align*}
%     f_{0,h}^M(\pi) &\defeq  \EE^{\pi, M^*}\sbr{u_h^M  - u_h^{M^*} + \rbr{\TT_h^M - \TT_h^{M^*}} W_{h+1}^{\pi_\opt^M, M} }, \nend
%     f_{1,h}^M(\pi) & \defeq \EE^{\pi, M^*}\abr{\sum_{i=h}^H\gamma^{i-h}\rbr{\EE_{s_h, b_h}^{\pi, M^*} - \EE_{s_h}^{\pi, M^*}}\sbr{ r_i^M-r_i^{M^*}+\gamma \rbr{\TT_i^M - \TT_i^{M^*}}V_{i+1}^{\pi_\opt^M, M}}}, 
% \end{align*}
% where $\pi^M_\opt$ is the optimistic policy for the leader under model $M$.
% One can easily check that $f_{0,h}^{M^t}(\pi^t)= \cE^{(0)}_h\bigrbr{M^t, M^*;\pi^t}$ for the temporal difference error and $f_{1,h}^{M^t}(\pi^t) = \cE^{(1)}_h\bigrbr{M^t, M^*;\pi^t}$ for the first order term in the response difference error. We would like to point out that the definitions of $f_0$ and $f_1$ are different from $\cE^{(0)}, \cE^{(1)}$, and the above equality relationship between the function $f$ and the error $\cE$ only holds if $\pi^t=\pi_\opt^{M^t}$, which makes $\pi^t$ a function of $M^t$.
% In the sequel, let $\cF_{0,h}=\{f_{0,h}^M(\cdot):M\in\cM\}$ and $\cF_{1,h}=\{f_{1,h}^M(\cdot):M\in\cM\}$.
% % Now that the first condition that $f$ bounds the error at each round $t$ holds.
% For the second condition of \Cref{lem:1st-eluder} that $\sum_{j=1}^{t-1} f^2_j(x_t)\le \cO(\beta)$, we can check that
% \begin{align*}
%     f_{0,h}^{M}(\pi) &\le \EE\sbr{\abr{u_h^M-u_h^{M^*}} + 2 H D_\TV \rbr{T_h^M, T_h^{M^*}}} 
%     % &\le H \sum_{h=1}^H \EE\sbr{\rbr{u_h^M-u_h^{M^*}}^2 + 4 H^2 D_\H^2\rbr{T_h^M, T_h^{M^*}}}\nend
%     \le (2 H +1) D_{\RL,h}(M, M^*;\pi).
% \end{align*}
% where 
% % the first inequality holds by the Cauchy-Schwartz inequality, and
% the second inequality holds by noting that the TV distance is upper bounded by the Hellinger distance used in $D_\RL$. 
% Therefore, we have $\sum_{j=1}^{t-1}f_{0,h}^{M^t}(\pi^j)^2 \le (2H+1)^2 \sum_{j=1}^{t-1} D_{\RL,h}^2(M^t, M^*;\pi^j)\le 4(2H+1)^2 \beta$ by \Cref{lem:MLE}.
% The case for $f_1$ is more complicated since we have to control the follower's reward difference via the follower's behavior difference. We invoke the following lemma.
% % \begin{lemma}[\textit{Bounding $f_1$ by $D_\RL$}]\label{lem:1st-ub}
% % For any $\eta>0$, $\pi\in\Pi$ and $\tM\in\cM$, we have
% % \begin{align*}
% %     f_{1,h}^{\tM}(\pi) \le   \underbrace{6(1+2\eta B_A)\cdot
% %     \sqrt{C_{\gamma, H}}}_{\ds L^{(1)}}  \cdot
% %     \eta^{-1}\max_{h\in[H]} \EE^{\pi, M^*} D_\TV(\nu_h,\tilde\nu_h), 
% % \end{align*}
% % where $C_{\gamma, H} = \orbr{1-\gamma^H}/\orbr{1-\gamma}$ is the effective foresight of the follower.
% %     \begin{proof}
% %         See \Cref{sec:1st-ub} for a detailed proof.
% %     \end{proof}
% % \end{lemma}
% We see from \Cref{lem:1st-ub} that $\sum_{j=1}^{t-1} f_{1,h}^{M^t}(\pi^j)^2\le \eta^{-2}\rbr{L^{(1)}}^2 \sum_{j=1}^{t-1} D_{\RL,h}^2(M^t, M^*;\pi^j)\le 4\eta^{-2}(L^{(1)})^2 \beta$. Hence, $f_2$ also satisifies the condition in \Cref{lem:1st-eluder}.
% Combining the discussions for $f_0$ and $f_1$ and invoking \Cref{lem:1st-eluder} together with $\sum_{s<t}D_\RL^2(M^t, M^*;\pi^s)\le 4\beta$ in \Cref{lem:MLE}, we have (for $w=1/\sqrt T$ in \Cref{lem:1st-eluder}) that
% \begin{align*}
%     \sum_{t=1}^T I_t &\le  H\rbr{2\sqrt{\dimE(\cF_0, \Pi, 1/\sqrt T) (2H+1)^2 \cdot 4\beta \cdot T} + \min\cbr{T, \dimE(\cF_0, \Pi, 1/\sqrt T)} B_{\cF_0} + \sqrt T}\nend
%     &\qquad + 2\eta H  H \cdot \Big( 2L^{(1)} \eta^{-1}\sqrt{\max_h\dimE(\cF_{1,h}, \Pi, 1/\sqrt T)  \cdot 4\beta \cdot T} \nend
%     &\qquad + \min\cbr{T, \max_h\dimE(\cF_{1,h}, \Pi, 1/\sqrt T)} B_{\cF_1} + \sqrt T \Big)\nend
%     &\le 
%     \rbr{ 4H (2H+1) \sqrt{5 d_0 \beta} + 8 H  H L^{(1)} \sqrt{d_1\beta} + 2} \sqrt{T} + \min\cbr{T, d_1, d_2} \rbr{B_{\cF_0} + 2\eta H  H B_{\cF_1}}, 
% \end{align*}
% where we let $d_0 = \max_{h\in[H]}\dimE(\cF_{0,h}, \Pi, 1/\sqrt T)$, $d_1=\max_h\dimE(\cF_{1,h}, \Pi, 1/\sqrt T)$, $B_{\cF_0}=\max_{f\in\cF, \pi\in\Pi}|f_0(\pi)|$, and $B_{\cF_1}=\max_{h\in[H],f\in\cF, \pi\in\Pi}|f_{1,h}(\pi)|$. Keeping the dominant terms for simplicity, we have
% \begin{align*}
%     \sum_{t=1}^T I_t\le \cO\rbr{H^{2} \sqrt{d_0\beta T} + (1+\eta B_A) C_{\gamma, H} H^2\sqrt{d_1\beta T}}.
% \end{align*}
% \paragraph{Step 3. Bounding the 2nd-Order Term.}
% Recall the second order error
% \begin{align*}
%     \cE_h^{(2)}(\tilde M, M^*, \pi) = \EE^{\pi, M^*}\sbr{ \exp\bigrbr{\eta\bigabr{A_h-\tilde A_h}}\cdot \bigabr{\tilde A_h - A_h}^2}\le \exp\bigrbr{2\eta B_A}\cdot \EE^{\pi, M^*}\sbr{ \bigabr{\tilde A_h - A_h}^2}.
% \end{align*}
% For the second order term, suppose that we can take some $f_{2,h}^M(\pi)$ such that $f_{2,h}^M(\pi)\ge \EE^{\pi, M^*}\bigabr{A_h^{\pi, M}-A_h^{\pi,M^*}}$ and $f_{2,h}^M(\pi)\le L^{(2)} D_\RL(M, M^*;\pi)$ for some $L^{(2)}>0$.
% Following the second result in \Cref{lem:1st-eluder}, we let $w=1/\sqrt T$ and obtain
% \begin{align*}
%     \sum_{t=1}^T J_t &\le C^{(1)} \exp\rbr{2\eta B_A}H \cdot \Big(4L^{(2)}\max_h\dimE(\cF_{2, h}, \cX, 1/\sqrt T) \beta \log T\nend 
%     &\qquad + \min\cbr{T, \max_h\dimE(\cF_{2 ,h}, \cX, 1/\sqrt T)} B_{\cF_{2}}^2 + 1\Big)\nend
%     &\le \rbr{4 L^{(2)} d_2 \beta \log T + \max\cbr{T, d_2} B_{\cF_2}^2 + 1} 5 \eta^2  H   \frac{1-\gamma^H}{1-\gamma} H\exp\rbr{2\eta B_A}, 
% \end{align*}
% where $d_2=\max_h\dimE(\cF_{2,h}, \Pi, 1/\sqrt T)$, $B_{\cF_1}=\max_{h\in[H],f\in\cF, \pi\in\Pi}|f_{2,h}(\pi)|$. Note that the second order term only scales with $\log(T)$. Hence, the second order term is not significant as $T$ grows large. For simplicity, we have
% \begin{align*}
%     \sum_{t=1}^T J_t\le \cO\rbr{\eta^2 H^2 C_{\gamma, H} \exp\rbr{2\eta B_A} L^{(2)} d_2 \beta \log T}.
% \end{align*}
% Combining the results from the first order terms and the second order term, we finish our proof of \Cref{thm:OMLE-farsighted}.




