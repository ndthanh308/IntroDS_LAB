
Here, we show the guarantee for the MLE with independently collected dataset.
Since each trajectory is independently collected, we are able to use the Bernstein inequality for indepedent random variables $Z_h^i = D_\H^2\orbr{\nu_h^{\pi^i, \theta}(\cdot\given s_h^i), \nu_h^{\pi^i, \theta^*}(\cdot\given s_h^i)}$, 
\#
    \abr{\frac 1 T \sum_{i=1}^T Z_h^i - \EE_\cD\sbr{Z_h^i}} &\le \sqrt{\frac{4\sum_{i=1}^T\Var[Z_h^i]\log(2\delta^{-1})}{T^2}} + \frac{4\log(2\delta^{-1})}{3T} \nend
    &\le \sqrt{\frac{4\sum_{i=1}^T \EE_\cD[Z_h^i]\log(2\delta^{-1})}{T^2}} + \frac{4\log(2\delta^{-1})}{3T}\nend
    &\le \frac{1}{2T}\sum_{i=1}^T \EE_\cD [Z_h^i] + \frac{2 \log(2\delta^{-1})}{T} + \frac{4\log(2\delta^{-1})}{3T},\notag
\#
where the second inequality holds by noting that $\Var[Z_h^i] \le \EE_\cD[(Z_h^i)^2]\le \EE_\cD[Z_h^i]$ by using the property that Hellinger distance is always upper bounded by $1$. We now conclude by further taking a union bound over $h\in[H]$ and $\theta\in\Theta$ that
\#
\frac{1}{T} \sum_{i=1}^T \EE_\cD[Z_h^i] &\le \frac{2}{T} \sum_{i=1}^T Z_h^i  + \frac{8\log(2H \cN_\rho(\Theta, \epsilon)\delta^{-1})}{T} + 6\epsilon\nend
&\le \frac{2}{T} \sum_{i=1}^T Z_h^i  + \frac{8\log(2eH \cN_\rho(\Theta, T^{-1})\delta^{-1})}{T},\notag
\#
where the last inequality holds by taking $\epsilon=T^{-1}$. Plug in the definition of $Z_h^i$, we have
\begin{align*}
    \frac 1 T\sum_{i=1}^T\EE_\cD\sbr{D_\H^2\rbr{\nu_h^{\pi^i, \theta}(\cdot\given s_h^i), \nu_h^{\pi^i, \theta^*}(\cdot\given s_h^i)}} &\le \frac{2}{T} \sum_{i=1}^T D_\H^2\rbr{\nu_h^{\pi^i, \theta}(\cdot\given s_h^i), \nu_h^{\pi^i, \theta^*}(\cdot\given s_h^i)}  \nend
    &\qquad + \frac{8\log(2eH \cN_\rho(\Theta, T^{-1})\delta^{-1})}{T}.
\end{align*}
Using \eqref{eq:MLE-guarantee-hellinger-1} in \Cref{lem:MLE-formal} for any $\theta\in\cC_{\Theta}(\beta)$, we give 
\begin{align}
    \sum_{i=1}^{T} D_\H^2\bigrbr{\nu_h^{\pi^i, \theta}(\cdot\given s_h^i), \nu_h^{\pi^i, \theta^*}(\cdot\given s_h^i)} 
        %%%%%%%%%%
        &\le  \frac 1 2\rbr{\cL_h(\theta) - \cL_h(\theta^*)} + \log\rbr{\frac{eH\cN_\rho(\Theta, T^{-1})}{\delta}} \nend
        %%%%%%%%%
        &\le \frac 1 2\rbr{\cL_h(\theta) - \inf_{\theta'\in\Theta}\cL_h(\theta')} + \log\rbr{\frac{eH\cN_\rho(\Theta, T^{-1})}{\delta}}\nend
        &\le \frac 3 2 \beta, \label{eq:OffGM-nu-hellinger-1}
\end{align}
where the last inequality is just by definition of $\CI_\Theta(\beta)$ in \Cref{eq:behavior_model_confset-1}. Therefore, 
\begin{align*}
    \sum_{i=1}^T\EE_\cD\sbr{D_\H^2\rbr{\nu_h^{\pi^i, \theta}(\cdot\given s_h^i), \nu_h^{\pi^i, \theta^*}(\cdot\given s_h^i)}}  \le 3\beta + {8\log(2eH \cN_\rho(\Theta, T^{-1})\delta^{-1})} \le 11\beta, 
\end{align*}
with probability at least $1-2\delta$ for all $h\in[H]$ and $\theta\in\CI_\Theta(\beta)$. The validity guarantee is already shown in \Cref{lem:MLE-formal}.
We complete the proof of \Cref{lem:MLE-indep-data}.

% \Cref{thm:11_6_gyorfi}, where we take $Z_h^i = D_\H^2\rbr{\nu_h^{\pi^i, \theta}(\cdot\given s_h^i), \nu_h^{\pi^i, \theta^*}(\cdot\given s_h^i)}$ and take $g(Z)=Z$. One can verify that $g\in[0, 1]$ with covering number $\cN_\infty(\epsilon, \cG)=1$.
% Hence, we conclude with $\epsilon = 1/3$, $\alpha=120\log(4/\delta) T^{-1}$ that for any fixed $\theta\in\Theta$, 
% \begin{align*}
%     \PP\rbr{\frac 1 T \sum_{i=1}^T Z_h^i > 2 \EE_\cD Z_h^i  + \frac{60\log(4/\delta)}{T}} \le \delta,
% \end{align*}
% Now, we take a union bound over the $\epsilon$-covering net for $\Theta$ with respect to $\rho$ and also over $h\in[H]$ and obtain with probability at least $1-\delta$ that for any $\theta\in\Theta$, $h\in[H]$ 
% \begin{align*}
%     \frac 1 T \sum_{i=1}^T D_\H^2\rbr{\nu_h^{\pi^i, \theta}(\cdot\given s_h^i), \nu_h^{\pi^i, \theta^*}(\cdot\given s_h^i)} \le 2 \EE_\cD D_\H^2\rbr{\nu_h^{\pi, \theta}(\cdot\given s_h), \nu_h^{\pi, \theta^*}(\cdot\given s_h)} + \frac{1+ 60\log(4\cN_\rho(\Theta, T^{-1})/\delta)}{T}, 
% \end{align*}
% where we can use the same covering number for $\Theta$ since $\rho(\theta, \tilde\theta)$ can still bound the difference in the squared Hellinger distance. Here, the expectation on the right hand side is taken with respect to both the randomness in $\pi$ and $s_h$.