


Since we consider any fixed state $s \in \cS$, in this proof, we omit $s$ 
to simplify the notation. 
To apply Lemma \ref{lem:performance diff}, 
we note that 
$Q$ and $\tilde Q$ in   Lemma \ref{lem:performance diff} becomes $r^{\pi}$ and $\tilde r^{\pi}$ in the myopic case. 
To make the proof consistent with that of Lemma \ref{lem:performance diff}, we use notation $\{ Q, \tilde Q, V, \tilde V, A, \tilde A\}$ in the sequel. 

 
To begin with, 
we invoke \eqref{eq:nu-tv-ub-0} in \Cref{lem:response diff} and obtain that 
\begin{align*}
    D_\TV\orbr{\nu, \tilde \nu}
    &\le \eta \cdot \inp[\big]{\nu} {\oabr{\tilde A-A} + \frac \eta 2 \exp\bigrbr{\eta\oabr{\tilde A-A}} \cdot \orbr{\tilde A-A}^2}_{\cB } \nend
    &\le \eta \cdot \inp[\big]{\nu} {\oabr{\tilde A-A} + \frac \eta 2 \exp\orbr{2\eta B_A} \orbr{\tilde A-A}^2}_{\cB }\nend
    &= \eta \cdot \EE\bigsbr{\oabr{\tilde A-A}} + \frac {\eta^2} {2} \exp\bigrbr{2\eta B_A} \cdot \Bigrbr{\Var\orbr{\tilde A-A}+ \bigrbr{\EE\osbr{\tilde A-A}}^2},
\end{align*}
where the last equality holds by the  variance-mean decomposition. 
Here the expectation and variance are taken with respect to $   b \sim \nu(\cdot \given s ) $. 
Now, using \Cref{lem:AQV-func diff} to the myopic case, we have
\begin{align*}
    \EE\bigsbr{\oabr{\tilde A - A}} 
    &\le \EE\bigsbr{\bigabr{(\tilde Q - Q) - \EE  \osbr{\tilde Q - Q}}} + \eta^{-1}\kl\infdivx[]{\nu}  {\tilde\nu}.  
\end{align*}
For the variance term, we have
\begin{align*}
    \Var\orbr{\tilde A -A} & = \EE\bigsbr{\bigrbr{\orbr{\tilde A -A} - \EE\orbr{\tilde A -A}}^2}  = \EE\bigsbr{\bigrbr{\orbr{\tilde Q -Q} - \EE\osbr{\tilde Q -Q}}^2}, 
\end{align*}
where the last equality holds because $V $ and $\tilde V $ do not involve $b $. 
Furthermore, 
note that $$\eta\EE\osbr{A-\tilde A} = \kl\infdivx[]{\nu}{\tilde\nu} \leq 2 \eta B_A.$$ 
Thus, combining the inequalities above, we have 
  we have
\begin{align}
    & D_\TV(\nu,\tilde\nu)\nend 
    & \quad \le   \eta \cdot   \EE\bigsbr{\bigabr{(\tilde Q - Q) - \EE  \osbr{\tilde Q - Q}}} + \frac{\eta^2}{2} \cdot \exp\rbr{2\eta B_A} \cdot \EE\bigsbr{\bigrbr{\orbr{\tilde Q -Q} - \EE\osbr{\tilde Q -Q}}^2}\nend
    &\qquad + \kl\infdivx[]{\nu}{\tilde\nu} + \exp\rbr{2\eta B_A}/ 2 \cdot  \bigrbr{\kl\infdivx[]{\nu}{\tilde\nu}}^2\nend
    &\quad \le\eta \cdot   \EE\bigsbr{\bigabr{(\tilde Q - Q) - \EE  \osbr{\tilde Q - Q}}}  + \frac{\eta^2}{2} \cdot \exp\rbr{2\eta B_A} \cdot  \EE\bigsbr{\bigrbr{\orbr{\tilde Q -Q} - \EE\osbr{\tilde Q -Q}}^2}\nend
    &\qquad + \bigrbr{1 + \eta B_A \exp\rbr{2\eta B_A} }\cdot \kl\infdivx[]{\nu}{\tilde\nu}, \label{eq:TV-ub-taylor}
\end{align}
where the  last inequality holds by noting that $\kl\infdivx[]{\nu}{\tilde\nu}\le 2\eta B_A$.
% Now, suppose that $r$ is parameterized by $\theta$ and $\tilde r$ is parameterized by $\tilde\theta$.

In the following, we  handle the KL divergence term.
We calculate the derivative of $\eta^{-2}\kl\infdivx{\nu}{\tilde\nu}$ with respect to $\tilde Q$ and obtain
\begin{align*}
    \partial_{\tilde Q}\rbr{\eta^{-2}\kl\infdivx{\nu}{\tilde\nu}} = \eta^{-1}\partial_{\tilde Q} \bigrbr{\EE\osbr{A-\tilde A}} = \eta^{-1}{\bigrbr{\partial_{\tilde Q} \tilde V - \nu}} = \eta^{-1}\rbr{\tilde \nu - \nu},
\end{align*}
where $\ind$ denote the all one vector of length $|\cB|$ is $\cB$ is discrete.
Here the first equality follows from $\eta\EE\osbr{A-\tilde A} = \kl\infdivx[]{\nu}{\tilde\nu}$, the second equality holds because $\nu$ and $A$ do not depend on $\tilde Q$, and $\tilde A = \tilde Q - \tilde V$. 
Moreover, the last equality holds because 
$$\tilde V(s)  = \eta^{-1} \log \bigg(\sum_{b \in \cB} \exp \big( \eta \cdot  \tilde Q(s, b)\bigr) \biggr), $$
and also $\partial_{\tilde Q}\EE[\tilde Q] = \nu$.
We further take a second-order derivative and obtain
\begin{align*}
    \partial^2_{\tilde Q \tilde Q} \rbr{\eta^{-2}\kl\infdivx{\nu}{\tilde\nu}} = \eta^{-1}\partial_{\tilde Q} \tilde \nu = \diag(\tilde \nu) -\tilde \nu \tilde\nu^\top\eqdef \H, 
\end{align*}
where the last equality holds for the vector case. 
% For a continuous action space, we have the Hessian represented as $\partial^2_{\tilde Q \tilde Q} \rbr{\eta^{-2}\kl\infdivx{\nu}{\tilde\nu}}(b, b') = \delta(b-b') - \tilde \nu(b)\tilde\nu(b')$. For simplicity, we just stick to the notation for the discrete case while the generalization to the continuous case is just a matter of change of notations. 
Note that the Hessian is upper and lower bounded by $\L$ where $\L = \diag(\nu )-\nu \nu^\top$, which is proved by  the following proposition. 
\begin{proposition}\label{prop:Hessian-ulb}
Let $\H = \diag(\tilde\nu) -\tilde\nu \tilde\nu^\top$ and $\L=\diag(\nu)-\nu \nu^\top$ where $\nu=\exp\orbr{\eta A}$ and $\tilde\nu=\exp\orbr{\eta \tilde A}$ are two quantal response over $\cB$ with $\nbr{A}_\infty\le B_A, \onbr{\tilde A}_\infty\le B_A$. Then   for any vector  $g\in \RR^{|\cB| }$, we have  
\begin{align}
    \exp\rbr{2 \eta B_A} \cdot g^\top \L g \ge x^\top \H x \ge \exp\rbr{-2 \eta B_A} \cdot g^\top \L g.\label{eq:Hessian ub lb}
\end{align}
\end{proposition}
\begin{proof}
Note that $\exp\rbr{-2 \eta B_A}\le  \tilde \nu(b) / \nu(b) \le\exp\rbr{ 2 \eta B_A}$ for any $b\in \cB$. 
Let $\EE^{\nu}$ and $\Var^{\nu}$ denote the expectation and variance under distribution $\nu$. 
Then we have 
\begin{align*}
    g^\top \L g & = \Var^\nu[g(b)]
   = \EE^\nu\bigsbr{\bigrbr{g(b) - \EE^\nu[g(b)]}^2},\notag \\
   g^\top \H g & = \Var^{\tilde \nu}[g(b)]
   = \EE^{\tilde \nu}\bigsbr{\bigrbr{g(b) - \EE^\nu[g(b)]}^2}.
\end{align*}
By direct computation, we have 
\begin{align*}
    & \exp\rbr{-\eta B_A} \cdot \EE^{\tilde\nu}\bigsbr{\bigrbr{g(b) - \EE^{\tilde\nu}[g(b)]}^2}
    \notag \\
    & \quad \le \exp\rbr{-\eta B_A}\cdot \EE^{\tilde\nu}\bigsbr{\bigrbr{g(b) - \EE^{\nu}[g(b)]}^2} 
     \le \EE^\nu\sbr{\rbr{g(b) - \EE^\nu[g(b)]}^2} 
    %%%%%%%%
\end{align*}
where the first inequality is true because changing $\EE^{\tilde\nu}[g(b)]$ to $\EE^{ \nu}[g(b)]$ incurs additional bias, and the second inequality is true because $\tilde \nu (b) / \nu(b)$ 
Similarly, we have 
\begin{align*}
    %%%%%%%%
     \EE^\nu\sbr{\rbr{g(b) - \EE^\nu[g(b)]}^2} 
    %%%%%%%%
    &\le \EE^{\nu}\sbr{\rbr{g(b) - \EE^{\tilde\nu}[g(b)]}^2}  
    %%%%%%%%
     \le  \exp\rbr{\eta B_A}  \cdot \EE^{\tilde\nu}\sbr{\rbr{g(b) - \EE^{\tilde\nu}[g(b)]}^2}.
\end{align*}
Therefore, we conclude that \eqref{eq:Hessian ub lb} holds. 
\end{proof}


Using the lower bound in \eqref{eq:Hessian ub lb}, we have for the KL divergence that
\begin{align*}
    \eta^{-2}\kl\infdivx[]{\nu}{\tilde\nu} &\le 1/2 \cdot (\tilde Q - Q)^\top  \H (\tilde Q - Q)  \le  \exp\rbr{2\eta B_A}/ 2 \cdot (\tilde Q - Q)^\top  \L (\tilde Q - Q) \nend
    &= \frac{\exp\rbr{2\eta B_A}}{2} \cdot (\tilde Q - Q)^\top  \bigrbr{\diag(\nu)-\nu\nu^\top} (\tilde Q - Q) , 
\end{align*}
where the first inequality holds by noting that the derivative of the KL-divergence at $\tilde\nu=\nu$ is zero, and we upper bound the KL-divergence  only by the second order term. Furthermore, the second inequality holds because  $\H\preceq \exp(2\eta B_A)\cdot \L$, which is proved  by \Cref{prop:Hessian-ulb}. 
% where the last inequality holds by applying \eqref{eq:Hessian ub lb} to the Hessian of the KL divergence evaluated at $\nu$. 
%Note that one can also plug in $\tilde\nu$ in the last inequality. 
Therefore, we conclude for \eqref{eq:TV-ub-taylor} that
\begin{align*}
    D_\TV \rbr{\nu, \tilde \nu} &\le \eta \cdot   \EE\bigsbr{\bigabr{(\tilde Q - Q) - \EE\osbr{\tilde Q - Q}}} + \frac{\eta^2}{2} \exp\rbr{2\eta B_A} \cdot \EE\bigsbr{\bigrbr{\orbr{\tilde Q -Q} - \EE\osbr{\tilde Q -Q}}^2}\nend
    &\qquad + \bigrbr{1 + \eta B_A \cdot \exp\rbr{2\eta B_A} }\cdot \kl\infdivx[]{\nu}{\tilde\nu}\nend
    &\le \eta \cdot   \EE\bigsbr{\bigabr{(\tilde Q - Q) - \EE\osbr{\tilde Q - Q}}} \nend
    &\qquad + \frac{\eta^2 \exp(2\eta B_A)}{2} \bigrbr{2+\eta B_A \cdot  \exp\rbr{2\eta B_A}} \cdot  \EE\bigsbr{\bigrbr{\orbr{\tilde Q -Q} - \EE\osbr{\tilde Q -Q}}^2}, 
\end{align*}
which finishes the proof of \Cref{cor:response-diff-myopic}.
