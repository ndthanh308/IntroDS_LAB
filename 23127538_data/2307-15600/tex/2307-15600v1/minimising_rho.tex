\subsection{Minimising $\rho(c)$}

Using \eqref{eq:z_min} and \eqref{eq:z_max} to expand equation \eqref{eq:rho}, we find
\begin{equation} \label{eq:rho-expanded}
  \rho(c) = \rho(t) = \frac{ 2^{-r_{\gamma}} \left(1+\frac{r_{\gamma}+t}{\gamma} \right) ^ {\gamma} }
			        {  2^{- r_{\alpha}} \left(1+\frac{r_{\alpha}+t}{\alpha} \right) ^ {\alpha} } \,,
\end{equation}
and we wish to minimise this expression on $t \in [0,1)$. Note that $s$, the integer part of $c$, has cancelled from the expression, implying that any minima we find will be repeated for each
value of $s$.

We begin by taking the derivative of \eqref{eq:rho-expanded} with respect to $t$. As a consequence of \eqref{eq:r_alpha} and \eqref{eq:r_gamma} it will have discontinuities at $t=t_0$ and $t=t_1$, but will be continuous in each resulting subinterval of the domain. We find for the derivative\footnote{Strictly, we are here calculating the \textit{right derivative}, as a result of the precise behaviour of $r_{\alpha}$ at $t=t_0$ and of $r_{\gamma}$ at $t=t_1$.}
\begin{align*}
  \frac{d\rho}{dt} & = \left( \frac{ 2^{-r_{\gamma}} \left( 1+\frac{r_{\gamma}+t}{\gamma} \right) ^ {\gamma-1} }
				      {  2^{ -r_{\alpha}} \alpha \gamma \left( 1+\frac{r_{\alpha}+t}{\alpha} \right) ^ {\alpha+1} } \right)
				( \gamma(r_{\alpha}+t) - \alpha(r_{\gamma}+t) )	\\[5pt]
                              & = K(t) \sigma(t) \,,
\end{align*}
where $K(t)$ is the fraction in large parentheses, and $\sigma(t)$ is the piecewise-linear function
\begin{align}	\label{eq:sigma}
  \sigma(t) & = \gamma(r_{\alpha}+t) - \alpha(r_{\gamma}+t)	\nonumber \\
	       & =  \beta t + \gamma r_{\alpha} - \alpha r_{\gamma} \,.
\end{align}
(For both $K$ and $\sigma$ we must bear in mind the fact that $r_{\alpha}$ and $r_{\gamma}$ are themselves piecewise constant functions of $t$.)

Now, $K(t)$ is positive for all $t\in[0,1)$, and so $\rho(t)$ is increasing or decreasing according as the sign of $\sigma(t)$ is positive or negative, respectively. Furthermore, we note that $\sigma(t)$ is the sum of one monotonically increasing function of $t$, namely $\beta t$, plus two weakly increasing functions of $t$, which are $\gamma r_{\alpha}(t)$ and $-\alpha r_{\gamma}(t)$, and is therefore itself monotonically increasing. Hence there is at most one value of $t$ where $\sigma(t)$ and thus $d \rho / dt$ is either zero or jumps at a discontinuity from negative to positive.

Since $t=0$ implies $r_{\alpha}=0,\, r_{\gamma}=\bar{r}$, we have
\[  \sigma(0) = -\alpha \bar{r} < 0 \,,  \]
and, since $t=1$ implies $r_{\alpha}=\alpha-1,\, r_{\gamma}=\bar{r}-1$,
\[  \sigma(1) = \beta + \gamma (\alpha - 1) - \alpha (\bar{r}-1) = \alpha (\gamma - \bar{r}) > 0\,,  \]
the rightmost inequality in both cases following from equation \eqref{eq:r_bar-bounds}.

Furthermore, since we showed that both $t_0$ and $t_1$, the only values of $t$ for which $\sigma(t)$ fails to be continuous, are strictly less than $1$, $\sigma(t)$ must be positive in a small neighbourhood below $1$. 

We conclude that $\sigma(t)$ transitions from negative to positive in the half-open interval $[0,1)$, and since it is monotonically increasing, there must exist exactly one value of $t \in [0,1)$ which minimises $\rho$. This value is therefore the optimum choice for $t$, and we will call it $t^*$. It remains to determine an expression for it.

First, consider the case $\alpha = 1$. From \eqref{eq:r_alpha} we must have $r_{\alpha} = 0$ for all values of $t$, and \eqref{eq:sigma} reduces to
\[
  \sigma(t) = \beta t - r_{\gamma}
                = \begin{cases}
			\beta t - \bar{r}		& \mbox{if } t < t_1 \,, \\
			\beta t - \bar{r} + 1	& \mbox{if } t \geqslant t_1 \,.
		    \end{cases}
\]
Now, if $t_1 \leqslant  \frac{\bar{r}-1} {\beta}$ we have
\[  \sigma \left( \frac{\bar{r}-1} {\beta} \right) = \beta \hspace{1pt} \frac{\bar{r}-1} {\beta} - \bar{r}+1 = 0 \,,  \]
and hence $t^* = \frac{\bar{r}-1} {\beta}$. Similarly, if $t_1 > \frac {\bar{r}} {\beta}$,
\[  \sigma \left( \frac{\bar{r}} {\beta} \right) = \beta \hspace{1pt} \frac{\bar{r}} {\beta} - \bar{r} = 0 \,,  \]
and so $t^* = \frac{\bar{r}} {\beta}$. In the remaining case, i.e. $\frac{\bar{r}-1} {\beta} < t_1 \leqslant  \frac {\bar{r}} {\beta}$,
\[  \sigma(t_1) = \beta t_1 - \bar{r}+1 > 0\,, \quad \lim_{t \to t_1^-} \sigma(t) = \beta t_1 - \bar{r} \leqslant 0 \,,  \]
and in this case we have $t^* = t_1$. We may succinctly state the results from all three cases thus:
\begin{equation} \label{eq:t_star-alpha-1}
  \alpha = 1 \implies t^* = \textrm{clamp} \left( t_1, \frac{\bar{r}-1} {\beta}, \frac{\bar{r}} {\beta} \right) \,.
\end{equation}
We now turn to the case $\alpha \geqslant 2$. Since \eqref{eq:requirements} requires $a$ and $b$ to be coprime,
\begin{equation} \label{eq:alpha-beta-gamma-bounds}
  \alpha \geqslant 2 \implies \beta \geqslant 3 \implies \gamma \geqslant 5 \,.
\end{equation}
In Appendices \ref{appendix:phi} and \ref{appendix:t0}, we demonstrate bounds on $t_0(\alpha)$ and $\phi(\gamma)$ (see equations \eqref{eq:phi-bounds} and \eqref{eq:t0-bounds}) which, to simplify the algebra, we somewhat loosen here to the following:
\begin{equation} \label{eq:t0-bounds-loose}
  \alpha \geqslant 2 \implies 0.3 < t_0(\alpha) < 0.44 \,,
\end{equation}
\begin{equation} \label{eq:phi-bounds-loose}
  \gamma \geqslant 5 \implies \lambda \gamma + 0.5 < \phi(\gamma) < \lambda \gamma + 0.6 \,,
\end{equation}
where
\begin{equation} \label{eq:lambda}
   \lambda = \frac{1}{\ln{2}} - 1\,.
\end{equation}
We may also observe using \eqref{eq:r_bar-t1} and \eqref{eq:r_gamma} that
\begin{equation} \label{eq:r-gamma-ineqs}
  \phi(\gamma)-2 < \bar{r}-1 \leqslant r_{\gamma} \leqslant \bar{r} \leqslant \phi(\gamma)\,.
\end{equation}
Consider setting $t=t_0$ in \eqref{eq:sigma}. We have
\begin{align*}
  \sigma(t_0) & = \beta t_0 + \gamma r_{\alpha}(t_0) - \alpha r_{\gamma}(t_0) \\
                     & \geqslant \beta t_0 + \gamma(\alpha-1) - \alpha \phi(\gamma) & & \text{using \eqref{eq:r_alpha} and \eqref{eq:r-gamma-ineqs}} \\
                     & > 0.3 \beta + \gamma (\alpha - 1) - \alpha ( \lambda \gamma + 0.6 ) & & \text{using \eqref{eq:t0-bounds-loose} and \eqref{eq:phi-bounds-loose}} \\
                     & = (1-\lambda) \alpha \gamma - 0.9 \alpha - 0.7 \gamma \\
                     & > (1-\lambda)(\alpha \gamma - 1.7 \alpha - 1.3 \gamma) & & \text{using \eqref{eq:lambda}} \\
                     & = (1-\lambda)((\alpha - 1.3)(\gamma - 1.7) - 2.21) \\
                     & \geqslant (1-\lambda)((2 - 1.3)(5 - 1.7) - 2.21) & & \text{using \eqref{eq:alpha-beta-gamma-bounds}} \\
                     & = 0.1 (1-\lambda) \\
                     & > 0 \,.
\end{align*}
Now consider the limiting value of $\sigma(t)$ as $t$ approaches $t_0$ from below, $\underset{t \to t_0^-}{\lim} \sigma(t)$, which we will write as $\sigma(t_0^-)$:
\begin{align*}
  \sigma(t_0^-) & = \beta t_0 + \gamma r_{\alpha}(t_0^-) - \alpha r_{\gamma}(t_0^-) \\
                     & < \beta t_0 - \alpha (\phi(\gamma) - 2) & & \text{using \eqref{eq:r_alpha} and \eqref{eq:r-gamma-ineqs}} \\
                     & < 0.44 \beta - \alpha ( \lambda \gamma + 0.5 -2) & & \text{using \eqref{eq:t0-bounds-loose} and \eqref{eq:phi-bounds-loose}} \\
                     & = - \lambda \alpha \gamma + 1.06 \alpha + 0.44 \gamma \\
                     & < -0.44 \alpha \gamma + 1.06 \alpha + 0.44 \gamma & & \text{using \eqref{eq:lambda}} \\
                     & = 1.06 - (\alpha - 1)(0.44 \gamma - 1.06) \\
                     & \leqslant 1.06 - (2 - 1)(2.2 - 1.06) & & \text{using \eqref{eq:alpha-beta-gamma-bounds}} \\
                     & = -0.08 \\
                     & < 0 \,.
\end{align*}
We have thus established that for the case $\alpha \geqslant 2$, $t_0$ is the unique value of $t$ for which $\sigma(t)$ jumps at a discontinuity from negative to positive, leading us to conclude
\begin{equation} \label{eq:t_star-alpha-2}
  \alpha \geqslant 2 \implies t^* = t_0\,.
\end{equation}
Finally, combining \eqref{eq:t_star-alpha-1} with \eqref{eq:t_star-alpha-2}, we obtain
\begin{equation} \label{eq:t-star}
  t^* = \begin{cases}
               \textrm{clamp} \left( t_1, \frac{\bar{r}-1} {\beta}, \frac{\bar{r}} {\beta} \right)    & \mbox{if } \alpha = 1 \,,  \\
               t_0    & \mbox{if } \alpha \geqslant 2 \,.
             \end{cases}
\end{equation}
For any $s \in \mathbb{Z}$, therefore, the value $s+t^*$ with $t^*$ as in \eqref{eq:t-star} provides an optimal choice for the constant c.

The function $\rho(c)$ corresponding to the FRSR case has been plotted in Figure \ref{fig:rho}. Since $\alpha=1$ for this case, the minimum on $[0,1]$ is located by clamping $t_1$ to the interval $\left[ \frac{\bar{r}-1}{\beta}, \frac{\bar{r}}{\beta} \right]$. The function is periodic outside $[0,1]$, so the minimum repeats for each value of $s$.

% Figure environment removed
