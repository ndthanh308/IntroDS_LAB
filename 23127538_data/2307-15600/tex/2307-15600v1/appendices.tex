\begin{appendices}

\section{Proof that $\zeta$ is increasing with respect to $k$} \label{appendix:zeta}

Let $k \in \mathbb{Z^+}$ and $h>0$.
Using the binomial expansion
\[  \left( 1 + \frac{h}{k} \right)^k = \sum_{i=0}^{k} \binom{k}{i} \left( \frac{h}{k} \right) ^ i\,,  \]
we can re-express the term with index $i$ as
\[  \binom{k}{i} \left( \frac{h}{k} \right) ^ i = \frac{h^i}{i!}\frac{k(k-1)...(k-i+1)}{k^i} = \frac{h^i}{i!} \prod_{j=1}^{i-1} \left( 1-\frac{j}{k} \right)\,.   \]
For $i \in \{0,1\}$, the product on the right is empty and so this term is independent of $k$. But, for $i \geqslant 2$, it is strictly increasing in $k$. Furthermore, the number of such terms increases with $k$, and all terms are positive. Hence, $\left( 1 + \frac{h}{k} \right)^k$ is strictly increasing in $k$. Observing also that the expression always equals $1$ when $h=0$, we can say that $\left( 1 + \frac{h}{k} \right)^k$ is weakly increasing in $k$ when $k \in \mathbb{Z^+}$ and $h \geqslant 0$. Now replacing $h$ with $r+t$ and multiplying by $2^{s-r}$, we see from \eqref{eq:zeta} that $\zeta_{r,k}(c)$ is weakly increasing with respect to $k$, and that when at least one of $r$ and $t$ is non-zero, it is strictly increasing.


\section{Bounds on $\phi(k)$} \label{appendix:phi}

Suppose $x>0$. Expanding $e^x$ as a power series, we have
\begin{align} \label{eq:phi-bounds-aux}
  e^x (x-2) + x+2 & = \sum_{i=0}^{\infty} \frac{x^i}{i!} (x - 2) + x + 2 \nonumber \\
                              & = \sum_{i=3}^{\infty} \frac{(i-2)x^i}{i!} \nonumber \\
                              & > 0\,,
\end{align}
with the last line following since all terms in the sum are positive. Dividing by the positive number $2x(e^x-1)$ and rearranging, this becomes
\[  \frac{1}{e^x-1} - \frac{1}{x} + \frac{1}{2} > 0\,.  \]
On substituting $x = \frac{\ln{2}}{k}$, we find
\[  \frac{1}{2^\frac{1}{k}-1} - \frac{k}{\ln{2}} + \frac{1}{2} > 0 \,,  \]
which, recalling the definition of $\phi(k)$ (equation \eqref{eq:phi}), we can express as
\begin{equation} \label{eq:phi-lower-bound}
  \phi(k) > \left( \frac{1}{\ln{2}} - 1 \right) k + \frac{1}{2}\,.
\end{equation}
Noting that $k>0 \implies x>0$, the inequality \eqref{eq:phi-lower-bound} provides a lower bound for $\phi(k)$ valid for all positive $k$.

To find a suitable upper bound, we begin by defining a linear function
\[  \phi_0(k) = \left( \frac{1}{\ln{2}} - 1 \right) k + 2 - \frac{1}{\ln{2}} \,,  \]
and proceed to take the derivative of $\phi(k) -  \phi_0(k)$. We find it to be
\begin{equation} \label{eq:phi-phi1-deriv}
  \phi'(k) -  \phi_0'(k) = \frac{ 2^{\frac{1}{k}} \ln{2} } { k^2 \left( 2^{\frac{1}{k}}-1 \right) ^2 } - \frac{1}{\ln{2}}\,.
\end{equation}
We also have for $x>0$ that
\begin{align*}
  x^2 + 2 - 2 \cosh{x} & = x^2 + 2 - 2 \left( 1 + \frac{x^2}{2!} + \sum_{i=2}^{\infty} \frac{x^{2i}}{(2i)!} \right) \\
                                     & = -2 \sum_{i=2}^{\infty} \frac{x^{2i}}{(2i)!} \\
                                     & < 0 \,.
\end{align*}
Multiplication by $e^x$ yields
\[  x^2 e^x - (e^x - 1)^2 < 0\,,  \]
and on dividing by $(e^x-1)^2 \ln{2}$ we obtain
\[  \frac{x^2 e^x}{(e^x-1)^2 \ln{2}} - \frac{1}{\ln{2}} < 0\,.  \]
We now perform the same substitution as before, $x = \frac{\ln{2}}{k}$, and use \eqref{eq:phi-phi1-deriv} to find that for $k>0$ we have
\[  \phi'(k) - \phi_0'(k) < 0\,.  \]
Furthermore, $\phi(k) - \phi_0(k)$ is clearly continuous for $k>0$ and takes the value $0$ for $k=1$.

We conclude that for $k \geqslant 1$ we have $\phi(k)-\phi_0(k) \leqslant 0$, that is,
\begin{equation} \label{eq:phi-upper-bound}
  \phi(k) \leqslant \left( \frac{1}{\ln{2}} - 1 \right) k + 2 - \frac{1}{\ln{2}}\,,
\end{equation}
providing the desired upper bound. We summarise the results by combining \eqref{eq:phi-lower-bound} and \eqref{eq:phi-upper-bound}, giving
\begin{equation} \label{eq:phi-bounds}
  k \geqslant 1 \implies \left( \frac{1}{\ln{2}} - 1 \right) k + \frac{1}{2} < \phi(k) \leqslant \left( \frac{1}{\ln{2}} - 1 \right) k + 2 - \frac{1}{\ln{2}}\,.
\end{equation}


\section{Bounds on $t_0(k)$} \label{appendix:t0}

To find bounds on $t_0(k)$, we will make use of the following easily verified relationship between the functions $\phi$ and $t_0$ (see equations \eqref{eq:t0} and \eqref{eq:phi}):
\begin{equation} \label{eq:phi-t0-relationship}
  k>1 \implies \phi \left( \frac{k}{k-1} \right) = \frac{t_0(k)}{k-1} + 1\,.
\end{equation}
We begin by showing that the second derivative of $\phi(k)$ is positive for $k>0$. The second derivative is found to be
\begin{equation} \label{eq:phi-second-deriv}
  \phi''(k) = \frac { 2^\frac{1}{k} \ln{2} \left( 2k(1-2^\frac{1}{k}) + (2^\frac{1}{k}+1 )\ln{2} \right) } { k^4 (2^\frac{1}{k}-1)^3 }\,.
\end{equation}
Now given $x>0$, and making the substitution $x = \frac{\ln{2}}{k}$ in inequality \eqref{eq:phi-bounds-aux}, we obtain
\begin{equation} \label{eq:phi-2nd-deriv-aux}
  2 (1-2^\frac{1}{k}) + \frac{\ln{2}}{k} (2^\frac{1}{k}+1) > 0\,.
\end{equation}
Since $k>0$ precisely when $x>0$, the quantity $\frac{ 2^\frac{1}{k} \ln{2}  } { k^3 (2^\frac{1}{k}-1)^3 }$ will be positive, and if we multiply inequality \eqref{eq:phi-2nd-deriv-aux} by it, on comparing with \eqref{eq:phi-second-deriv} we see that we have now proven
\[  k>0 \implies \phi''(k)>0\,.  \]
For positive $k$, therefore, the curve of $\phi(k)$ is concave upward, and so any line which is tangent to it also bounds it from below. Consider the tangent at $k=1$, which we will denote as $\phi_1(k)$ and which can be written as
\begin{equation} \label{eq:phi1}
  \phi_1(k) = (2\ln{2}-1)k + 2(1-\ln{2})\,.
\end{equation}
We then have
\[  k>0 \implies \phi(k) - \phi_1(k) > 0\,.  \]
But now if $k>1$, then $\frac{k}{k-1} > 1$ also, hence we have
\[  \phi \left( \frac{k}{k-1} \right) - \phi_1 \left( \frac{k}{k-1} \right) > 0\,.  \]
Using \eqref{eq:phi-t0-relationship} and \eqref{eq:phi1}, this becomes
\[  \frac{t_0(k)}{k-1} + 1 - (2\ln{2}-1) \left( \frac{k}{k-1} \right) - 2(1-\ln{2}) > 0 \,.  \]
Multiplying through by $k-1$ and simplifying yields
\begin{equation} \label{eq:t0-lower-bound}
  t_0(k) > 2\ln{2}-1 \,,
\end{equation}
providing a lower bound for $t_0(k)$ valid for $k>1$.

By a similar token, since the curve of $\phi(k)$ is concave upward, any line which cuts the curve in exactly two places must lie above the curve on the interval between the two intersection points.

Using $\phi_2(k)$ to denote the line having intersection points at $k=1$ and $k=2$, we can express this line as
\begin{equation} \label{eq:phi2}
  \phi_2(k) = (\sqrt{2}-1) k + 2 - \sqrt{2}\,,
\end{equation}
allowing us to write
\[  1 \leqslant k \leqslant 2 \implies \phi(k) - \phi_2(k) \leqslant 0\,.  \]
Given $k \geqslant 2$, then we have $1 < \frac{k}{k-1} \leqslant 2$, and hence
\[  \phi \left( \frac{k}{k-1} \right) - \phi_2 \left( \frac{k}{k-1} \right) \leqslant 0\,.  \]
Using \eqref{eq:phi-t0-relationship} and \eqref{eq:phi2}, this becomes
\[  \frac{t_0(k)}{k-1} + 1 - (\sqrt{2}-1) \left( \frac{k}{k-1} \right) - 2 + \sqrt{2} \leqslant 0 \,.  \]
Now multiplying by $k-1$ and simplifying, we obtain the upper bound
\begin{equation} \label{eq:t0-upper-bound}
  t_0(k) \leqslant \sqrt{2} - 1 \,,
\end{equation}
valid for $k \geqslant 2$.

Finally, we combine \eqref{eq:t0-lower-bound} with \eqref{eq:t0-upper-bound} to obtain the desired result:
\begin{equation} \label{eq:t0-bounds}
  k \geqslant 2 \implies 2\ln{2}-1 < t_0(k) \leqslant \sqrt{2} - 1\,.
\end{equation}



\section{Upper bound on minimax error} \label{appendix:eps-bound}

Suppose a function $f$ is both continuous and positive on a given closed interval, and that $p$ is a minimax polynomial approximation (with respect to relative error) to $f$ on that interval. We will show that the resulting minimax error is less than $1$.

To see this, note that, whatever the degree of $p$, it is as least as accurate an approximation as any constant polynomial. Hence the result is proven if it can be shown to hold for the minimax polynomial of degree $0$.

Let $f_0$ and $f_1$ be the minimum and maximum values of $f$ on the given interval, and suppose we approximate $f$ by a constant $c_0$. Let $e_0$ and $e_1$ be the relative errors corresponding to $f_0$ and $f_1$, respectively. Then we have
\[  e_0 = 1-\frac{c_0}{f_0}\,, \quad e_1 = 1-\frac{c_0}{f_1}\,.  \]
If $c_0$ is the degree-$0$ minimax polynomial, equioscillation implies that $e_0 = -e_1$, whence we obtain
\[  c_0 = \frac{2 f_0 f_1}{f_0 + f_1} \,,  \]
and the minimax error is therefore
\[  |e_0| = |e_1| = \frac {f_1-f_0}{f_0+f_1} \,.  \]
Since $-f_0 < f_0$, then $f_1-f_0 < f_0+f_1$ and hence the minimax error must be strictly less than $1$.


\end{appendices}
