\begin{abstract}

The Fast Reciprocal Square Root Algorithm is a well-established approximation technique consisting of two stages: first, a coarse approximation is obtained by manipulating the bit pattern of the floating point argument using integer instructions, and second, the coarse result is refined through one or more steps, traditionally using Newtonian iteration but alternatively using improved expressions with carefully chosen numerical constants found by other authors. The algorithm was widely used before microprocessors carried built-in hardware support for computing reciprocal square roots. At the time of writing, however, there is in general no hardware acceleration for computing other fixed fractional powers. This paper generalises the algorithm to cater to all rational powers, and to support any polynomial degree(s) in the refinement step(s), and under the assumption of unlimited floating point precision provides a procedure which automatically constructs provably optimal constants in all of these cases. It is also shown that, under certain assumptions, the use of monic refinement polynomials yields results which are much better placed with respect to the cost/accuracy tradeoff than those obtained using general polynomials. Further extensions are also analysed, and several new best approximations are given.

\end{abstract}
