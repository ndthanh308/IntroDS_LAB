% Use this file for citations not found in the ACL Anthology (contained in "anthology.bib").

@book{Aho:72,
    author  = {Alfred V. Aho and Jeffrey D. Ullman},
    title   = {The Theory of Parsing, Translation and Compiling},
    year    = "1972",
    volume  = "1",
    publisher = {Prentice-Hall},
    address = {Englewood Cliffs, NJ}
}

@book{APA:83,
    author  = {{American Psychological Association}},
    title   = {Publications Manual},
    year    = "1983",
    publisher = {American Psychological Association},
    address = {Washington, DC}
}

@article{Chandra:81,
	author = {Ashok K. Chandra and Dexter C. Kozen and Larry J. Stockmeyer},
	year = "1981",
	title = {Alternation},
	journal = {Journal of the Association for Computing Machinery},
	volume = "28",
	number = "1",
	pages = "114--133",
	doi = "10.1145/322234.322243",
}

@inproceedings{andrew2007scalable,
  title={Scalable training of {$L_1$}-regularized log-linear models},
  author={Andrew, Galen and Gao, Jianfeng},
  booktitle={Proceedings of the 24th International Conference on Machine Learning},
  pages={33--40},
  year={2007},
  url={https://dl.acm.org/doi/abs/10.1145/1273496.1273501}
}

@book{Gusfield:97,
    author  = {Dan Gusfield},
    title   = {Algorithms on Strings, Trees and Sequences},
    year    = "1997",
    publisher = {Cambridge University Press},
    address = {Cambridge, UK},
    url={https://www.cambridge.org/core/books/algorithms-on-strings-trees-and-sequences/F0B095049C7E6EF5356F0A26686C20D3}
}

@article{rasooli-tetrault-2015,
    author    = {Mohammad Sadegh Rasooli and Joel R. Tetreault},
    title     = {Yara Parser: {A} Fast and Accurate Dependency Parser},
    journal   = {Computing Research Repository},
    volume    = {arXiv:1503.06733},
    year      = {2015},
    url       = {http://arxiv.org/abs/1503.06733},
    note    = {version 2}
}

@article{Ando2005,
	Acmid = {1194905},
	Author = {Ando, Rie Kubota and Zhang, Tong},
	Issn = {1532-4435},
	Issue_Date = {12/1/2005},
	Journal = {Journal of Machine Learning Research},
	Month = dec,
	Numpages = {37},
	Pages = {1817--1853},
	Publisher = {JMLR.org},
	Title = {A Framework for Learning Predictive Structures from Multiple Tasks and Unlabeled Data},
	Volume = {6},
	Year = {2005},
	url={https://www.jmlr.org/papers/volume6/ando05a/ando05a.pdf}
}

@article{ct1965,
  title={An algorithm for the machine calculation of complex {F}ourier series},
  author={Cooley, James W. and Tukey, John W.},
  journal={Mathematics of Computation},
  volume={19},
  number={90},
  pages={297--301},
  year={1965},
  url={https://www.ams.org/journals/mcom/1965-19-090/S0025-5718-1965-0178586-1/S0025-5718-1965-0178586-1.pdf}
}

%----------------------------------------------

@inproceedings{DBLP:conf/eacl/ElsaharCRG21,
  author    = {Hady Elsahar and
               Maximin Coavoux and
               Jos Rozen and
               Matthias Gall{\'{e}}},
  editor    = {Paola Merlo and
               J{\"{o}}rg Tiedemann and
               Reut Tsarfaty},
  title     = {Self-Supervised and Controlled Multi-Document Opinion Summarization},
  booktitle = {Proceedings of the 16th Conference of the European Chapter of the
               Association for Computational Linguistics: Main Volume, {EACL} 2021,
               Online, April 19 - 23, 2021},
  pages     = {1646--1662},
  publisher = {Association for Computational Linguistics},
  year      = {2021},
  url       = {https://doi.org/10.18653/v1/2021.eacl-main.141},
  doi       = {10.18653/v1/2021.eacl-main.141},
  timestamp = {Thu, 20 Jan 2022 10:02:54 +0100},
  biburl    = {https://dblp.org/rec/conf/eacl/ElsaharCRG21.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}



@inproceedings{guo-etal-2022-questioning,
    title = "Questioning the Validity of Summarization Datasets and Improving Their Factual Consistency",
    author = "Guo, Yanzhu  and
      Clavel, Chlo{\'e}  and
      Kamal Eddine, Moussa  and
      Vazirgiannis, Michalis",
    booktitle = "Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing",
    month = dec,
    year = "2022",
    address = "Abu Dhabi, United Arab Emirates",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.emnlp-main.386",
    pages = "5716--5727",
    abstract = "The topic of summarization evaluation has recently attracted a surge of attention due to the rapid development of abstractive summarization systems. However, the formulation of the task is rather ambiguous, neither the linguistic nor the natural language processing communities have succeeded in giving a mutually agreed-upon definition. Due to this lack of well-defined formulation, a large number of popular abstractive summarization datasets are constructed in a manner that neither guarantees validity nor meets one of the most essential criteria of summarization: factual consistency. In this paper, we address this issue by combining state-of-the-art factual consistency models to identify the problematic instances present in popular summarization datasets. We release SummFC, a filtered summarization dataset with improved factual consistency, and demonstrate that models trained on this dataset achieve improved performance in nearly all quality aspects. We argue that our dataset should become a valid benchmark for developing and evaluating summarization systems.",
}

@inproceedings{wang-etal-2022-analyzing,
    title = "Analyzing and Evaluating Faithfulness in Dialogue Summarization",
    author = "Wang, Bin  and
      Zhang, Chen  and
      Zhang, Yan  and
      Chen, Yiming  and
      Li, Haizhou",
    booktitle = "Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing",
    month = dec,
    year = "2022",
    address = "Abu Dhabi, United Arab Emirates",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.emnlp-main.325",
    pages = "4897--4908",
    abstract = "Dialogue summarization is abstractive in nature, making it suffer from factual errors. The factual correctness of summaries has the highest priority before practical applications. Many efforts have been made to improve faithfulness in text summarization. However, there is a lack of systematic study on dialogue summarization systems. In this work, we first perform the fine-grained human analysis on the faithfulness of dialogue summaries and observe that over 35{\%} of generated summaries are faithfully inconsistent respective the source dialogues. Furthermore, we present a new model-level faithfulness evaluation method. It examines generation models with multi-choice questions created by rule-based transformations. Experimental results show that our evaluation schema is a strong proxy for the factual correctness of summarization models. The human-annotated faithfulness samples and the evaluation toolkit are released to facilitate future research toward faithful dialogue summarization.",
}

@inproceedings{AMICorpus,
author = {Carletta, Jean and Ashby, Simone and Bourban, Sebastien and Flynn, Mike and Guillemot, Mael and Hain, Thomas and Kadlec, Jaroslav and Karaiskos, Vasilis and Kraaij, Wessel and Kronenthal, Melissa and Lathoud, Guillaume and Lincoln, Mike and Lisowska, Agnes and McCowan, Iain and Post, Wilfried and Reidsma, Dennis and Wellner, Pierre},
title = {The AMI Meeting Corpus: A Pre-Announcement},
year = {2005},
isbn = {3540325492},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/11677482\_3},
doi = {10.1007/11677482_3},
abstract = {The AMI Meeting Corpus is a multi-modal data set consisting of 100 hours of meeting recordings. It is being created in the context of a project that is developing meeting browsing technology and will eventually be released publicly. Some of the meetings it contains are naturally occurring, and some are elicited, particularly using a scenario in which the participants play different roles in a design team, taking a design project from kick-off to completion over the course of a day. The corpus is being recorded using a wide range of devices including close-talking and far-field microphones, individual and room-view video cameras, projection, a whiteboard, and individual pens, all of which produce output signals that are synchronized with each other. It is also being hand-annotated for many different phenomena, including orthographic transcription, discourse properties such as named entities and dialogue acts, summaries, emotions, and some head and hand gestures. We describe the data set, including the rationale behind using elicited material, and explain how the material is being recorded, transcribed and annotated.},
booktitle = {Proceedings of the Second International Conference on Machine Learning for Multimodal Interaction},
pages = {28–39},
numpages = {12},
location = {Edinburgh, UK},
series = {MLMI'05}
}

@article{LexiconBasedSA,
    author = {Taboada, Maite and Brooke, Julian and Tofiloski, Milan and Voll, Kimberly and Stede, Manfred},
    title = "{Lexicon-Based Methods for Sentiment Analysis}",
    journal = {Computational Linguistics},
    volume = {37},
    number = {2},
    pages = {267-307},
    year = {2011},
    month = {06},
    abstract = "{We present a lexicon-based approach to extracting sentiment from text. The Semantic Orientation CALculator (SO-CAL) uses dictionaries of words annotated with their semantic orientation (polarity and strength), and incorporates intensification and negation. SO-CAL is applied to the polarity classification task, the process of assigning a positive or negative label to a text that captures the text's opinion towards its main subject matter. We show that SO-CAL's performance is consistent across domains and in completely unseen data. Additionally, we describe the process of dictionary creation, and our use of Mechanical Turk to check dictionaries for consistency and reliability.}",
    issn = {0891-2017},
    doi = {10.1162/COLI_a_00049},
    url = {https://doi.org/10.1162/COLI\_a\_00049},
    eprint = {https://direct.mit.edu/coli/article-pdf/37/2/267/1798865/coli\_a\_00049.pdf},
}

@incollection{MOHAMMAD2016201,
author = {Saif M. Mohammad},
title = {9 - Sentiment Analysis: Detecting Valence, Emotions, and Other Affectual States from Text},
editor = {Herbert L. Meiselman},
booktitle = {Emotion Measurement},
publisher = {Woodhead Publishing},
pages = {201-237},
year = {2016},
isbn = {978-0-08-100508-8},
doi = {https://doi.org/10.1016/B978-0-08-100508-8.00009-6},
url = {https://www.sciencedirect.com/science/article/pii/B9780081005088000096},
keywords = {Sentiment analysis, emotion detection, subjectivity, stance detection, sentiment lexicons, machine learning, natural language processing},
abstract = {Sentiment analysis is the task of automatically determining from text the attitude, emotion, or some other affectual state of the author. This chapter summarizes the diverse landscape of tasks and applications associated with sentiment analysis. We outline key challenges stemming from the complexity and subtlety of language use, the prevalence of creative and non-standard language, and the lack of paralinguistic information, such as tone and stress markers. We describe automatic systems and datasets commonly used in sentiment analysis. We summarize several manual and automatic approaches to creating valence- and emotion-association lexicons. We also discuss preliminary approaches for sentiment composition (how smaller units of text combine to express sentiment) and approaches for detecting sentiment in figurative and metaphoric language—these are the areas where we expect to see significant work in the near future.}
}

@article{Nandwani2021ARO,
  title={A review on sentiment analysis and emotion detection from text},
  author={Pansy Nandwani and Rupali Verma},
  journal={Social Network Analysis and Mining},
  year={2021},
  volume={11}
}

@misc{https://doi.org/10.48550/arxiv.2208.03898,
  doi = {10.48550/ARXIV.2208.03898},
  
  url = {https://arxiv.org/abs/2208.03898},
  
  author = {Chen, Yulong and Deng, Naihao and Liu, Yang and Zhang, Yue},
  
  keywords = {Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {DialogSum Challenge: Results of the Dialogue Summarization Shared Task},
  
  publisher = {arXiv},
  
  year = {2022},
  
  copyright = {Creative Commons Attribution Share Alike 4.0 International}
}

@inproceedings{
Zhang*2020BERTScore:,
title={BERTScore: Evaluating Text Generation with BERT},
author={Tianyi Zhang* and Varsha Kishore* and Felix Wu* and Kilian Q. Weinberger and Yoav Artzi},
booktitle={International Conference on Learning Representations},
year={2020},
url={https://openreview.net/forum?id=SkeHuCVFDr}
}

@article{Liu2019RoBERTaAR,
  title={RoBERTa: A Robustly Optimized BERT Pretraining Approach},
  author={Yinhan Liu and Myle Ott and Naman Goyal and Jingfei Du and Mandar Joshi and Danqi Chen and Omer Levy and Mike Lewis and Luke Zettlemoyer and Veselin Stoyanov},
  journal={ArXiv},
  year={2019},
  volume={abs/1907.11692}
}

@misc{https://doi.org/10.48550/arxiv.2209.11910,
  doi = {10.48550/ARXIV.2209.11910},
  
  url = {https://arxiv.org/abs/2209.11910},
  
  author = {Wang, Bin and Zhang, Chen and Wei, Chengwei and Li, Haizhou},
  
  keywords = {Computation and Language (cs.CL), Human-Computer Interaction (cs.HC), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {A Focused Study on Sequence Length for Dialogue Summarization},
  
  publisher = {arXiv},
  
  year = {2022},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@inproceedings{ijcai2022p0764,
  title     = {A Survey on Dialogue Summarization: Recent Advances and New Frontiers},
  author    = {Feng, Xiachong and Feng, Xiaocheng and Qin, Bing},
  booktitle = {Proceedings of the Thirty-First International Joint Conference on
               Artificial Intelligence, {IJCAI-22}},
  publisher = {International Joint Conferences on Artificial Intelligence Organization},
  editor    = {Lud De Raedt},
  pages     = {5453--5460},
  year      = {2022},
  month     = {7},
  note      = {Survey Track},
  doi       = {10.24963/ijcai.2022/764},
  url       = {https://doi.org/10.24963/ijcai.2022/764},
}

@article{10.1162/tacl_a_00373,
    author = {Fabbri, Alexander R. and Kryściński, Wojciech and McCann, Bryan and Xiong, Caiming and Socher, Richard and Radev, Dragomir},
    title = "{SummEval: Re-evaluating Summarization Evaluation}",
    journal = {Transactions of the Association for Computational Linguistics},
    volume = {9},
    pages = {391-409},
    year = {2021},
    month = {04},
    abstract = "{The scarcity of comprehensive up-to-date studies on evaluation metrics for text summarization and the lack of consensus regarding evaluation protocols continue to inhibit progress. We address the existing shortcomings of summarization evaluation methods along five dimensions: 1) we re-evaluate 14 automatic evaluation metrics in a comprehensive and consistent fashion using neural summarization model outputs along with expert and crowd-sourced human annotations; 2) we consistently benchmark 23 recent summarization models using the aforementioned automatic evaluation metrics; 3) we assemble the largest collection of summaries generated by models trained on the CNN/DailyMail news dataset and share it in a unified format; 4) we implement and share a toolkit that provides an extensible and unified API for evaluating summarization models across a broad range of automatic metrics; and 5) we assemble and share the largest and most diverse, in terms of model types, collection of human judgments of model-generated summaries on the CNN/Daily Mail dataset annotated by both expert judges and crowd-source workers. We hope that this work will help promote a more complete evaluation protocol for text summarization as well as advance research in developing evaluation metrics that better correlate with human judgments.}",
    issn = {2307-387X},
    doi = {10.1162/tacl_a_00373},
    url = {https://doi.org/10.1162/tacl\_a\_00373},
    eprint = {https://direct.mit.edu/tacl/article-pdf/doi/10.1162/tacl\_a\_00373/1923949/tacl\_a\_00373.pdf},
}

@article{10.1016/j.knosys.2019.105236,
author = {Bernab\'{e}-Moreno, J. and Tejeda-Lorente, A. and Herce-Zelaya, J. and Porcel, C. and Herrera-Viedma, E.},
title = {A Context-Aware Embeddings Supported Method to Extract a Fuzzy Sentiment Polarity Dictionary},
year = {2020},
issue_date = {Feb 2020},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {190},
number = {C},
issn = {0950-7051},
url = {https://doi.org/10.1016/j.knosys.2019.105236},
doi = {10.1016/j.knosys.2019.105236},
journal = {Know.-Based Syst.},
month = {feb},
numpages = {13},
keywords = {Information retrieval, Sentiment analysis, Contextual bias, Polarity extraction, Fuzzy polarity, Word embeddings}
}

@inproceedings{sebastiani2006sentiwordnet,
  title={Sentiwordnet: A publicly available lexical resource for opinion mining},
  author={Sebastiani, Fabrizio and Esuli, Andrea},
  booktitle={Proceedings of the 5th international conference on language resources and evaluation},
  pages={417--422},
  year={2006},
  organization={European Language Resources Association (ELRA) Genoa, Italy}
}

@article{Hutto_Gilbert_2014, 
title={VADER: A Parsimonious Rule-Based Model for Sentiment Analysis of Social Media Text}, volume={8}, 
url={https://ojs.aaai.org/index.php/ICWSM/article/view/14550}, 
DOI={10.1609/icwsm.v8i1.14550}, 
abstractNote={ &lt;p&gt; The inherent nature of social media content poses serious challenges to practical applications of sentiment analysis. We present VADER, a simple rule-based model for general sentiment analysis, and compare its effectiveness to eleven typical state-of-practice benchmarks including LIWC, ANEW, the General Inquirer, SentiWordNet, and machine learning oriented techniques relying on Naive Bayes, Maximum Entropy, and Support Vector Machine (SVM) algorithms. Using a combination of qualitative and quantitative methods, we first construct and empirically validate a gold-standard list of lexical features (along with their associated sentiment intensity measures) which are specifically attuned to sentiment in microblog-like contexts. We then combine these lexical features with consideration for five general rules that embody grammatical and syntactical conventions for expressing and emphasizing sentiment intensity. Interestingly, using our parsimonious rule-based model to assess the sentiment of tweets, we find that VADER outperforms individual human raters (F1 Classification Accuracy = 0.96 and 0.84, respectively), and generalizes more favorably across contexts than any of our benchmarks. &lt;/p&gt; }, 
number={1}, 
journal={Proceedings of the International AAAI Conference on Web and Social Media}, 
author={Hutto, C. and Gilbert, Eric}, 
year={2014}, 
month={May}, 
pages={216-225} }

@article{Gatti2015SentiWordsDA,
  title={SentiWords: Deriving a High Precision and High Coverage Lexicon for Sentiment Analysis},
  author={Lorenzo Gatti and Marco Guerini and Marco Turchi},
  journal={IEEE Transactions on Affective Computing},
  year={2015},
  volume={7},
  pages={409-421}
}

@inproceedings{10.1145/1014052.1014073,
author = {Hu, Minqing and Liu, Bing},
title = {Mining and Summarizing Customer Reviews},
year = {2004},
isbn = {1581138881},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1014052.1014073},
doi = {10.1145/1014052.1014073},
abstract = {Merchants selling products on the Web often ask their customers to review the products that they have purchased and the associated services. As e-commerce is becoming more and more popular, the number of customer reviews that a product receives grows rapidly. For a popular product, the number of reviews can be in hundreds or even thousands. This makes it difficult for a potential customer to read them to make an informed decision on whether to purchase the product. It also makes it difficult for the manufacturer of the product to keep track and to manage customer opinions. For the manufacturer, there are additional difficulties because many merchant sites may sell the same product and the manufacturer normally produces many kinds of products. In this research, we aim to mine and to summarize all the customer reviews of a product. This summarization task is different from traditional text summarization because we only mine the features of the product on which the customers have expressed their opinions and whether the opinions are positive or negative. We do not summarize the reviews by selecting a subset or rewrite some of the original sentences from the reviews to capture the main points as in the classic text summarization. Our task is performed in three steps: (1) mining product features that have been commented on by customers; (2) identifying opinion sentences in each review and deciding whether each opinion sentence is positive or negative; (3) summarizing the results. This paper proposes several novel techniques to perform these tasks. Our experimental results using reviews of a number of products sold online demonstrate the effectiveness of the techniques.},
booktitle = {Proceedings of the Tenth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
pages = {168–177},
numpages = {10},
keywords = {reviews, sentiment classification, text mining, summarization},
location = {Seattle, WA, USA},
series = {KDD '04}
}

@inproceedings{chen-etal-2022-dialogsum,
    title = "{D}ialog{S}um Challenge: Results of the Dialogue Summarization Shared Task",
    author = "Chen, Yulong  and
      Deng, Naihao  and
      Liu, Yang  and
      Zhang, Yue",
    booktitle = "Proceedings of the 15th International Conference on Natural Language Generation: Generation Challenges",
    month = jul,
    year = "2022",
    address = "Waterville, Maine, USA and virtual meeting",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.inlg-genchal.14",
    pages = "94--103",
    abstract = "We report the results of DialogSum Challenge, the shared task on summarizing real-life sce- nario dialogues at INLG 2022. Four teams participate in this shared task and three submit their system reports, exploring different meth- ods to improve the performance of dialogue summarization. Although there is a great im- provement over the baseline models regarding automatic evaluation metrics, such as ROUGE scores, we find that there is a salient gap be- tween model generated outputs and human an- notated summaries by human evaluation from multiple aspects. These findings demonstrate the difficulty of dialogue summarization and suggest that more fine-grained evaluatuion met- rics are in need.",
}

@inproceedings{chauhan-etal-2022-tcs,
    title = "{TCS}{\_}{WITM}{\_}2022 @ {D}ialog{S}um : Topic oriented Summarization using Transformer based Encoder Decoder Model",
    author = "Chauhan, Vipul  and
      Roy, Prasenjeet  and
      Dey, Lipika  and
      Goel, Tushar",
    booktitle = "Proceedings of the 15th International Conference on Natural Language Generation: Generation Challenges",
    month = jul,
    year = "2022",
    address = "Waterville, Maine, USA and virtual meeting",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.inlg-genchal.15",
    pages = "104--109",
    abstract = "In this paper, we present our approach to the DialogSum challenge, which was proposed as a shared task aimed to summarize dialogues from real-life scenarios. The challenge was to design a system that can generate fluent and salient summaries of a multi-turn dialogue text. Dialogue summarization has many commercial applications as it can be used to summarize conversations between customers and service agents, meeting notes, conference proceedings etc. Appropriate dialogue summarization can enhance the experience of conversing with chat- bots or personal digital assistants. We have pro- posed a topic-based abstractive summarization method, which is generated by fine-tuning PE- GASUS1, which is the state of the art abstrac- tive summary generation model.We have com- pared different types of fine-tuning approaches that can lead to different types of summaries. We found that since conversations usually veer around a topic, using topics along with the di- aloagues, helps to generate more human-like summaries. The topics in this case resemble user perspective, around which summaries are usually sought. The generated summary has been evaluated with ground truth summaries provided by the challenge owners. We use the py-rouge score and BERT-Score metrics to compare the results.",
}

@inproceedings{bhattacharjee-etal-2022-multi,
    title = "A Multi-Task Learning Approach for Summarization of Dialogues",
    author = "Bhattacharjee, Saprativa  and
      Shinde, Kartik  and
      Ghosal, Tirthankar  and
      Ekbal, Asif",
    booktitle = "Proceedings of the 15th International Conference on Natural Language Generation: Generation Challenges",
    month = jul,
    year = "2022",
    address = "Waterville, Maine, USA and virtual meeting",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.inlg-genchal.16",
    pages = "110--120",
    abstract = "We describe our multi-task learning based ap- proach for summarization of real-life dialogues as part of the DialogSum Challenge shared task at INLG 2022. Our approach intends to im- prove the main task of abstractive summariza- tion of dialogues through the auxiliary tasks of extractive summarization, novelty detection and language modeling. We conduct extensive experimentation with different combinations of tasks and compare the results. In addition, we also incorporate the topic information provided with the dataset to perform topic-aware sum- marization. We report the results of automatic evaluation of the generated summaries in terms of ROUGE and BERTScore.",
}

@inproceedings{lundberg-etal-2022-dialogue,
    title = "Dialogue Summarization using {BART}",
    author = "Lundberg, Conrad  and
      S{\'a}nchez Vi{\~n}uela, Leyre  and
      Biales, Siena",
    booktitle = "Proceedings of the 15th International Conference on Natural Language Generation: Generation Challenges",
    month = jul,
    year = "2022",
    address = "Waterville, Maine, USA and virtual meeting",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.inlg-genchal.17",
    pages = "121--125",
    abstract = "This paper introduces the model and settings submitted to the INLG 2022 DialogSum Chal- lenge, a shared task to generate summaries of real-life scenario dialogues between two peo- ple. In this paper, we explored using interme- diate task transfer learning, reported speech, and the use of a supplementary dataset in addi- tion to our base fine-tuned BART model. How- ever, we did not use such a method in our final model, as none improved our results. Our final model for this dialogue task achieved scores only slightly below the top submission, with hidden test set scores of 49.62, 24.98, 46.25 and 91.54 for ROUGE-1, ROUGE-2, ROUGE-L and BERTSCORE respectively. The top submitted models will also receive human evaluation.",
}

@inproceedings{Zar2005SpearmanRC,
  title={Spearman Rank Correlation},
  author={Jerrold H. Zar},
  year={2005}
}

@INPROCEEDINGS{6553805,
  author={Ringeval, Fabien and Sonderegger, Andreas and Sauer, Juergen and Lalanne, Denis},
  booktitle={2013 10th IEEE International Conference and Workshops on Automatic Face and Gesture Recognition (FG)}, 
  title={Introducing the RECOLA multimodal corpus of remote collaborative and affective interactions}, 
  year={2013},
  volume={},
  number={},
  pages={1-8},
  doi={10.1109/FG.2013.6553805}}

@book{Walton1995-WALCID,
	publisher = {Albany, NY, USA: State University of New York Press},
	year = {1995},
	author = {Douglas Neil Walton and Erik C. W. Krabbe},
	title = {Commitment in Dialogue: Basic Concepts of Interpersonal Reasoning}
}

@InProceedings{10.1007/978-3-030-80285-1_55,
author="Tarpin-Bernard, Franck
and Fruitet, Joan
and Vigne, Jean-Philippe
and Constant, Patrick
and Chainay, Hanna
and Koenig, Olivier
and Ringeval, Fabien
and Bouchot, B{\'e}atrice
and Bailly, G{\'e}rard
and Portet, Fran{\c{c}}ois
and Alisamir, Sina
and Zhou, Yongxin
and Serre, Jean
and Delerue, Vincent
and Fournier, Hippolyte
and Berenger, K{\'e}vin
and Zsoldos, Isabella
and Perrotin, Olivier
and Elisei, Fr{\'e}d{\'e}ric
and Lenglet, Martin
and Puaux, Charles
and Pacheco, L{\'e}o
and Fouillen, M{\'e}lodie
and Ghenassia, Didier",
editor="Ayaz, Hasan
and Asgher, Umer
and Paletta, Lucas",
title="THERADIA: Digital Therapies Augmented by Artificial Intelligence",
booktitle="Advances in Neuroergonomics and Cognitive Engineering",
year="2021",
publisher="Springer International Publishing",
address="Cham",
pages="478--485",
abstract="Digital plays a key role in the transformation of medicine. Beyond the simple computerisation of healthcare systems, many non-drug treatments are now possible thanks to digital technology. Thus, interactive stimulation exercises can be offered to people suffering from cognitive disorders, such as developmental disorders, neurodegenerative diseases, stroke or traumas. The efficiency of these new treatments, which are still primarily offered face-to-face by therapists, can be greatly improved if patients can pursue them at home. However, patients are left to their own devices which can be problematic. We introduce THERADIA, a 5-year project that aims to develop an empathic virtual agent that accompanies patients while receiving digital therapies at home, and that provides feedback to therapists and caregivers. We detail the architecture of our agent as well as the framework of our Wizard-of-Oz protocol, designed to collect a large corpus of interactions between people and our virtual assistant in order to train our models and improve our dialogues.",
isbn="978-3-030-80285-1"
}

@ARTICLE{6797872,
  author={Munezero, Myriam and Montero, Calkin Suero and Sutinen, Erkki and Pajunen, John},
  journal={IEEE Transactions on Affective Computing}, 
  title={Are They Different? Affect, Feeling, Emotion, Sentiment, and Opinion Detection in Text}, 
  year={2014},
  volume={5},
  number={2},
  pages={101-111},
  doi={10.1109/TAFFC.2014.2317187}}

@Inbook{Stets2006,
author="Stets, Jan E.",
editor="Delamater, John",
title="Emotions and Sentiments",
bookTitle="Handbook of Social Psychology",
year="2006",
publisher="Springer US",
address="Boston, MA",
pages="309--335",
isbn="978-0-387-36921-1",
doi="10.1007/0-387-36921-X_13",
url="https://doi.org/10.1007/0-387-36921-X_13"
}

@article{SAsurvey2023Monali,
author = {Bordoloi, Monali and Biswas, Saroj},
year = {2023},
month = {03},
pages = {},
title = {Sentiment Analysis: A Survey on Design Framework, Applications and Future Scopes},
journal = {Artificial Intelligence Review},
doi = {10.1007/s10462-023-10442-2}
}

@article{SATwitter2016Vishal,
author = {Kharde, Vishal and Sonawane, Sheetal},
year = {2016},
month = {04},
pages = {5-15},
title = {Sentiment Analysis of Twitter Data: A Survey of Techniques},
volume = {139},
journal = {International Journal of Computer Applications},
doi = {10.5120/ijca2016908625}
}

@article{REYES2012754,
title = {Making objective decisions from subjective data: Detecting irony in customer reviews},
journal = {Decision Support Systems},
volume = {53},
number = {4},
pages = {754-760},
year = {2012},
note = {1) Computational Approaches to Subjectivity and Sentiment Analysis 2) Service Science in Information Systems Research : Special Issue on PACIS 2010},
issn = {0167-9236},
doi = {https://doi.org/10.1016/j.dss.2012.05.027},
url = {https://www.sciencedirect.com/science/article/pii/S0167923612001388},
author = {Antonio Reyes and Paolo Rosso},
keywords = {Irony detection, Natural language processing, Web text analysis},
abstract = {The research described in this work focuses on identifying key components for the task of irony detection. By means of analyzing a set of customer reviews, which are considered ironic both in social and mass media, we try to find hints about how to deal with this task from a computational point of view. Our objective is to gather a set of discriminating elements to represent irony, in particular, the kind of irony expressed in such reviews. To this end, we built a freely available data set with ironic reviews collected from Amazon. Such reviews were posted on the basis of an online viral effect; i.e. contents that trigger a chain reaction in people. The findings were assessed employing three classifiers. Initial results are largely positive, and provide valuable insights into the subjective issues of language facing tasks such as sentiment analysis, opinion mining and decision making.}
}

@inproceedings{Roman2008,
author = {Roman, Norton and Piwek, Paul and Carvalho, Ariadne},
year = {2008},
month = {10},
pages = {},
title = {Emotion and Behaviour in Automatic Dialogue Summarisation},
doi = {10.1145/1809980.1810056}
}

@inproceedings{Beineke2004a,
  added-at = {2008-04-01T23:37:32.000+0200},
  address = {Stanford, US},
  author = {Beineke, Philip and Hastie, Trevor and Manning, Christopher and Vaithyanathan, Shivakumar},
  biburl = {https://www.bibsonomy.org/bibtex/2a85d1c8bb7b1ea630bc87c78bb06e701/subjectivity},
  booktitle = {Proceedings of the AAAI Spring Symposium on Exploring Attitude and
	Affect in Text: Theories and Applications},
  editor = {Shanahan, James G. and Wiebe, Janyce and Qu, Yan},
  interhash = {d3a2d7185d0a46d1fe4177ac56c6aff0},
  intrahash = {a85d1c8bb7b1ea630bc87c78bb06e701},
  keywords = {analysis sentiment subjectivity},
  owner = {cem},
  timestamp = {2008-04-01T23:40:25.000+0200},
  title = {An exploration of sentiment summarization},
  url = {http://nlp.stanford.edu/~manning/papers/rotup.pdf},
  year = 2004
}

@inproceedings{10.1145/765891.766075,
author = {Takahashi, Toru and Katagiri, Yasuhiro},
title = {TelMeA2003: Social Summarization in Online Communities},
year = {2003},
isbn = {1581136374},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/765891.766075},
doi = {10.1145/765891.766075},
abstract = {We propose the concept of social summarization as an alternative to the content-based technology for summarization, report on its use in the community system TelMeA2003 implemented and employed to investigate techniques for social summarization, and discuss its effectiveness in supporting collaborative activities in online communities.},
booktitle = {CHI '03 Extended Abstracts on Human Factors in Computing Systems},
pages = {928–929},
numpages = {2},
keywords = {personified media, bulletin boards, social summarization, collaborative computing},
location = {Ft. Lauderdale, Florida, USA},
series = {CHI EA '03}
}

@misc{baan2019transformer,
      title={Do Transformer Attention Heads Provide Transparency in Abstractive Summarization?}, 
      author={Joris Baan and Maartje ter Hoeve and Marlies van der Wees and Anne Schuth and Maarten de Rijke},
      year={2019},
      eprint={1907.00570},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}