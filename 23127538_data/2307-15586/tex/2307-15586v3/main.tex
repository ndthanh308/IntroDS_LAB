\documentclass[a4paper,11pt]{article}

\usepackage{fullpage}
\usepackage{times}
\usepackage{soul}
\usepackage{url}
\usepackage[utf8]{inputenc}
\usepackage[small]{caption}
\usepackage{graphicx}
\usepackage{xcolor}
\usepackage{amsmath}
\usepackage{booktabs}
\usepackage{algorithm}
\urlstyle{same}
\usepackage{dsfont}
\usepackage{enumerate}
\usepackage{multirow}

\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{algpseudocode}
\usepackage{amsfonts}
\usepackage{pifont}
\usepackage{cleveref}

\usepackage{mathrsfs}
\usepackage{enumitem}
\usepackage{nicefrac}

\newcommand{\yes}{{\color{teal}\checkmark}}
\newcommand{\no}{{\color{red} \text{\sffamily X}}}

\usepackage{bbm}

\newtheorem{theorem}{Theorem}[section]
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{observation}[theorem]{Observation}
\newtheorem{conjecture}[theorem]{Conjecture}
\newtheorem{claim}{Claim}

\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{example}[theorem]{Example}
\newtheorem{remark}[theorem]{Remark}

\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}

\newcommand{\util}{\textsc{Util}}
\newcommand{\egal}{\textsc{Egal}}
\newcommand{\avg}{\textsc{Avg}}
\newcommand{\maxrule}{\textsc{Max}}
\newcommand{\minrule}{\textsc{Min}}
\newcommand{\med}{\textsc{Med}}
\newcommand{\geo}{\textsc{Geo}}
\newcommand{\im}{\textsc{IM}}

\usepackage{todonotes}
\presetkeys{todonotes}{inline}{}
\newcommand{\review}[1]{\todo[color=green!30,inline]{\textbf{Newly added}: #1}}
\newcommand{\tobedone}[1]{\todo[color=red!30,inline]{\textbf{To Do}: #1}}


\renewcommand{\epsilon}{\varepsilon}

\usepackage{natbib}

\allowdisplaybreaks

\usepackage{authblk}

\title{\bf Settling the Score: Portioning with Cardinal Preferences\footnote{A preliminary version of this paper appeared in \emph{Proceedings of the 26th European Conference on Artificial Intelligence} \citep{elkind2023portioning}. 
This version is substantially enhanced: it fills in all missing results (Table~\ref{tab:summary}) and improves the organization of the results, strengthens the case for using the average rule by providing characterizations of the rule (\Cref{sec:characterization}), expands the discussion of related work (\Cref{sec:relatedwork}), and includes all proofs omitted from the conference version.}}

\author[1,2]{Edith Elkind}
\author[3]{Matthias Greger}
\author[4]{Patrick Lederer}
\author[5]{Warut Suksompong}
\author[1]{Nicholas Teh}

\affil[1]{University of Oxford, UK}
\affil[2]{Alan Turing Institute, UK}
\affil[3]{Technical University of Munich, Germany}
\affil[4]{University of New South Wales, Australia}
\affil[5]{National University of Singapore, Singapore}

\renewcommand\Authands{ and }
\newcommand{\mathI}{\mathcal{I}}
\date{\vspace{-10mm}}
\renewcommand{\arraystretch}{1.3}

\begin{document}

\maketitle

\begin{abstract}
We study a portioning setting in which a public resource such as time or money is to be divided among a given set of candidates,
and each agent proposes a division of the resource. We consider two families of aggregation rules for this setting---those based on coordinate-wise aggregation and those that optimize some notion of welfare---as well as the recently proposed independent markets rule. We provide a detailed analysis of these rules from
an axiomatic perspective, both for classic axioms, such as strategyproofness and Pareto-optimality, and for novel axioms, some of which aim to capture proportionality in this setting. 
Our results indicate that a simple rule that computes the average of the proposals satisfies many of our axioms and fares better than all other considered rules in terms of fairness properties. 
In addition, we complement these results by presenting two characterizations of the average rule.
\end{abstract}

\section{Introduction}
A town council has just received its annual funding from the government, and it needs to determine how to split the budget between constructing new facilities, maintaining clean streets, and ensuring public safety.
The mayor is in favor of making decisions democratically, so she asks each resident of the town to propose a division of the budget.
After collecting the proposals, how should the council aggregate them into an actual allocation?

In the problem of \emph{portioning}, the aim is to divide a homogeneous resource among a given set of candidates.
Besides dividing money, another important application of portioning is the division of time---for example, a conference needs to distribute its time between research talks, panels, and social gatherings.
Several prior works on portioning assumed that each agent submits her preferences in the form of either an approval ballot \citep{bogomolnaia2005collective,duddy2015fairsharing,aziz2020fairmixing} or an ordinal ranking~\citep{airiau2019portioning}.
However, in many portioning scenarios, these preference formats are not expressive enough to fully describe agents' desires.
For instance, if a citizen wants the budget to be used both for constructing new facilities and for cleaning the streets, but with twice as much money spent on the former than the latter, her preference cannot be captured by a ranking or an approval set.
Likewise, a conference attendee who would like 75\% of the time to be spent on research talks, 15\% on panels, and 10\% on social gatherings ranks these activities in the same way as another attendee who prefers a 40\%--35\%--25\% split, but the actual preferences of these two attendees are quite different.

In an important recent work,~\cite{freeman2021truthfulbudget} studied portioning with cardinal preferences, where every agent is asked to propose a division of the resource.
This input format allows each agent to specify the ideal portioning outcome in her view and is therefore much more descriptive than the two formats discussed earlier.
Assuming that an agent's disutility is given by the $\ell_1$ distance between her ideal distribution and the actual outcome,\footnote{\citet{freeman2021truthfulbudget} noted that $\ell_1$ preferences arise naturally when agents have separable uniform utilities over candidates together with a funding cap.} Freeman et al.~observed that even though the rule that maximizes the utilitarian social welfare is known to be strategyproof (for a specific tie-breaking convention) \citep{lindner2008allocating,goel2019knapsack}, it tends to put too much weight on majority preferences.
In light of this observation, they introduced the \emph{independent markets} (\im) rule, which is strategyproof and, in some sense, more proportional.
Their work inspired some follow-up works in this fundamental social choice setting, mostly focusing on strategyproofness \citep{caragiannis2022truthful,brandt2024optimal,deberg2024truthful,freeman2024project}.
However, while strategyproofness is an important consideration, there may be scenarios where other features of aggregation rules are just as---if not more---desirable. 
Thus, to  identify a suitable aggregation rule for a specific application, it would be useful to build a catalogue of axioms for the portioning setting, and determine which of these axioms are satisfied by popular aggregation rules. 
Characterizing a rule using some of these axioms would also help enhance the argument for using the rule.

\subsection{Overview of Contributions}

We consider a diverse set of axioms for portioning with cardinal preferences. Besides classic axioms such as strategyproofness and Pareto-optimality, we put forward new axioms including score-unanimity and score-representation (see Section~\ref{sec:preliminaries} for definitions).
Several of our axioms are independent of the underlying utility functions; for those where the utility functions matter, following most prior works in this domain, we assume $\ell_1$ utilities.
We then conduct a systematic study of aggregation rules with respect
to these axioms. 
We focus on two families of portioning rules---those that are based on coordinate-wise aggregation and those that optimize some notion of welfare---as well as the recently proposed IM rule \citep{freeman2021truthfulbudget}.
We also include observations regarding relationships between the axioms.
\Cref{tab:summary} summarizes our results. 

\begin{table}[t] 
\begin{center}
\begin{tabular}{ |c||c|c|c|c|c||c|c||c| } 
 \hline
 \multicolumn{1}{|c||}{} & 
 \multicolumn{5}{|c||}{ Coordinate-wise } &
 \multicolumn{2}{|c||}{Welfare-based} &
 \multicolumn{1}{|c|}{Other}
 \\
 \hline
 $F$ & \avg{} & \maxrule{} & \minrule{} & \med{} & \geo{} & \util{} & \egal{} & \im{} \\
 \hline
Pareto-optimality & \no$^{\ddagger}$  & \no$^\dagger$ & \no$^\dagger$ & \no$^\ddagger$ & \no$^\dagger$ & \yes & \yes &  \no$^\dagger$ \\
  \hline
Range-respect & \yes & \no$^\dagger$ & \no$^\dagger$ & \no$^\ddagger$  & \no$^\dagger$ & \yes & \yes & \no$^\dagger$ \\
 \hline
 Score-unanimity & \yes & \no$^\dagger$ & \no$^\dagger$ &  \no$^\ddagger$ & \no$^\dagger$ & \yes & \yes & \no$^\dagger$ \\
 \hline
  Score-representation & \yes & \no & \no & \no$^*$ & \no & \no & \no$^*$ &  \no$^\dagger$
 \\
  \hline
   Single-minded Proportionality & \yes & \no$^*$ & \no & \no$^*$ &   \no & \no$^*$ &  \no$^*$ & \yes
 \\
  \hline
  Independence & \yes & \no$^\dagger$ & \no$^\dagger$ & \no$^\ddagger$ & \no$^\dagger$ & \no$^\dagger$ & \no$^\ddagger$ & \no$^\dagger$ 
  \\
   \hline
 Score-monotonicity & \yes & \yes & \yes & \yes & \yes & \yes & \no$^\ddagger$ & \yes \\
 \hline
  Reinforcement & \yes & \yes & \yes & \no & \yes & \yes & \yes & \yes \\
 \hline
 Strategyproofness & \no & \no & \no & \no & \no & \yes & \no & \yes \\
  \hline
 Participation & \yes & \yes & \yes & \no & \yes & \yes & \yes &  \yes \\
 \hline
\end{tabular}
\caption[Summary]{Summary of our results.
The asterisk symbol ($^*$) means that the axiom is satisfied for $n=2$, but may fail when $n \geq 3$ (even if $m = 2$).
The dagger symbol ($\dagger$) indicates that the axiom is satisfied for $m=2$, but may fail when $m \geq 3$ (even if $n = 2$).
The double dagger symbol ($\ddagger$) indicates that the axiom is satisfied when $\min(n,m) = 2$.   
Some of the results on \util{} and IM were obtained by~\cite{freeman2021truthfulbudget}.}
\label{tab:summary}
\end{center}
\end{table}

Our findings offer several insights on portioning rules.
As shown in Table 1, the most promising rules with respect to the axioms that we study are the average rule (\avg), which simply returns the average of all the proposals, and the utilitarian welfare-maximizing rule (\textsc{Util}), with the trade-off being that \avg{} fails strategyproofness and Pareto-optimality whereas \textsc{Util} fails fairness and consistency notions such as single-minded proportionality,\footnote{This property was simply called ``proportionality'' by \citet{freeman2021truthfulbudget}. 
However, the property only applies to instances in which all agents are ``single-minded'', thereby making it rather weak compared to proportionality notions in other settings (e.g., fair division \citep{procaccia2016cake}). Hence, we call the property ``single-minded proportionality'' in this paper.} score-representation, and independence. 
While \im{} satisfies both strategyproofness and single-minded proportionality, it fails other intuitive properties such as score-unanimity and score-representation; these failures can lead to highly counterintuitive outcomes for the agents.
The trade-offs between various rules can be used to inform decision-making in a wide range of settings.
For instance, consider again the scenario where a conference organizer needs to divide time among different activities at a conference. 
In this case, it is likely difficult for an attendee to accurately predict what other attendeesâ€™ preferences are,
making strategyproofness arguably less relevant as a consideration. 
On the other hand, strategyproofness could be more important in smaller-scale settings where agents know each other well, e.g., portioning within a family or a small organization.  
Moreover, intuitive properties such as score-unanimity and range-respect may be essential in settings where votes are revealed: for example, if all agents vote $80\%$ on a certain activity but the rule outputs $60\%$ on this activity, this may well lead to dissatisfaction among agents regarding the use of that rule.

In addition to fulfilling several axioms, the average rule is intuitive and easy to explain to laypeople.
We further strengthen the case for using this rule by providing two characterizations of it.
Specifically, we show that the average rule is the only aggregation rule satisfying score-unanimity (i.e., if all agents assign probability $\gamma$ to a candidate, then the rule also assigns probability $\gamma$ to it), independence (i.e., the probability assigned to a candidate only depends on the probabilities that the agents assign to this candidate), and a mild fairness condition called anonymity, when there are at least three candidates.
We also prove that, within the class of coordinate-wise rules, the average rule is the unique rule that satisfies score-unanimity, anonymity, and continuity whenever the number of candidates is at least four.


\subsection{Further Related Work} 
\label{sec:relatedwork}

Portioning can be viewed as a variant of \emph{participatory budgeting}, a framework that allows citizens to democratically decide how the public budget should be spent.
Participatory budgeting has been used in over 7,000 cities around the world~\citep{PB2024} and received much recent interest in computational social choice---see, for example, the surveys by \citet{aziz-shah} and \citet{maly2023survey}.
Nevertheless, most of the participatory budgeting literature focuses on the discrete setting, where each project is either implemented in full or not implemented at all (and projects may have varying costs).
This makes the nature of the problem quite different from that of portioning.

As mentioned earlier, \citet{freeman2021truthfulbudget} investigated portioning with cardinal preferences and introduced \im{}, which is strategyproof and single-minded proportional under $\ell_1$ utilities.
In fact, \im{} belongs to a class of \emph{moving phantoms} mechanisms, all of which are strategyproof.\footnote{However, not all strategyproof rules are moving phantoms mechanisms \citep{deberg2024truthful}.}
\citet{caragiannis2022truthful} followed up on their work by examining the deviation of moving phantoms mechanisms from the average rule according to the $\ell_1$ distance, while \citet{freeman2024project} explored a similar question using the $\ell_\infty$ distance.
\citet{brandt2024optimal} showed that no rule can simultaneously be strategyproof, single-minded proportional, and Pareto-optimal under $\ell_1$ or $\ell_\infty$ utilities, but such a rule exists for an alternative utility model that they called ``minimal quotient'' utilities.

Portioning also bears a similarity to the domain of \emph{probabilistic social choice}, where the output is likewise a distribution over the alternatives.
However, unlike in portioning, the distribution in probabilistic social choice is used for eventually choosing a single alternative at random with the corresponding probabilities.
As a consequence, it is usually desirable for a rule to avoid randomization whenever possible, thereby making notions of fairness and proportionality less important.
Much of the work in probabilistic social choice assumes that agent preferences are given as ordinal rankings (see, e.g., the survey by \citet{brandt2017rolling}).
A notable exception is the work of \citet{intriligator1973probsc}, which postulated that each agent has an ideal distribution over the alternatives, but did not consider utility functions of agents.
While Intriligator gave a characterization of the average rule, his characterization relied on a rather esoteric axiom on the sensitivity to probability changes.\footnote{\citet{rice1977comment} later pointed out that Intriligator's characterization was wrong, and proposed a fix.} 


Finally, another related topic is \emph{probabilistic opinion pooling}, which aims to aggregate probabilistic beliefs representing, for example, weather forecasts \citep{genest1986combining,clemen1989forecasts}.
The focus of probabilistic opinion pooling is mainly to preserve epistemic and stochastic properties, which again leads to different axioms being considered.


\section{Preliminaries} \label{sec:preliminaries}

We present the model of portioning with cardinal preferences, and introduce the rules and axioms that we will study.

\subsection{Model}

Let $[t] := \{1,\dots,t\}$ for any positive integer~$t$.
Assume that there is a set of $n \ge 2$ agents, $N = [n]$, who report their preferences as ideal distributions of a homogeneous resource among a set $C=\{c_1,\dots, c_m\}$ of $m \ge 2$ candidates. 
Specifically, letting $\Delta^m := \{\mathbf{x} \in \mathbb{R}^m_{\ge 0} \mid \sum_{j \in [m]}x_j=1\}$ denote the set of probability distributions over $C$, we assume that each agent $i\in N$ reports her preferences as a distribution $\mathbf{s}_i \in \Delta^m$. We typically refer to $\mathbf{s}_i$ as agent $i$'s \emph{score vector} and write $\mathbf{s}_i=(s_{i,1}, \dots, s_{i,m})$ to specify this vector. 
An {\em instance} $\mathcal{I}$ of our problem is the collection of the preferences of all agents, i.e., $\mathcal{I} = (\mathbf{s}_1,\dots,\mathbf{s}_n)$. For each vector $\mathbf{x} = (x_1,\dots,x_m)$, agent $i$'s \emph{disutility} is defined as $d_i(\mathbf{x}) := \sum_{j \in [m]} |s_{i,j} - x_j|$, which is the $\ell_1$ distance between the agent's score vector $\mathbf{s}_i$ and~$\mathbf{x}$. 
Given an instance~$\mathcal I$, we aim to find a vector $\mathbf{x} \in \Delta^m$ that reflects the agents' collective preferences. To this end, we use \emph{aggregation rules}, which are defined as follows.

\begin{definition}[Aggregation rule]
    An \emph{aggregation rule} $F$ is a function $F : \Delta^{m \times n} \to \Delta^m$ that maps every instance $\mathcal{I} \in \Delta^{m \times n}$ to an outcome vector $\mathbf{x} \in \Delta^m$.
\end{definition}

We will frequently use the notation $F(\mathcal{I})_j$ to denote the probability that the aggregation rule $F$ assigns to candidate $c_j$ for instance $\mathcal{I}$. 


\subsection{Aggregation Rules}\label{subsec:rules}

In this paper, we will focus on two natural classes of aggregation rules, namely, coordinate-wise rules and welfare-optimizing rules. In addition, we will also consider the independent markets rule
of~\cite{freeman2021truthfulbudget}.

\subsubsection{Coordinate-wise Aggregation Rules}

We first introduce the class of \emph{coordinate-wise} aggregation rules. The idea of these rules is to aggregate the reported scores for each candidate individually and then normalize the aggregated scores so that they sum up to $1$.

\begin{definition} \label{defn:coord_rules}
    An aggregation rule $F$ is \emph{coordinate-wise}
    if, for each $n$, there exist {\em coordinate-aggregation functions} $f_j^n: (\mathbb{R}_{\ge 0})^n \to \mathbb{R}_{\ge 0}$
    for $j\in [m]$ such that $F(\mathI)_j= \frac{f_j^n(s_{1,j}, \dots, s_{n,j})}{\sum_{j' \in [m]} f_{j'}^n(s_{1,j'}, \dots, s_{n,j'})}$ for all instances $\mathcal{I}$ and all $j\in [m]$.
\end{definition}

Our definition allows the possibility that, for certain instances, $f_j^n(s_{1,j},\dots, s_{n,j})=0$ for all $j\in [m]$. 
In such a case, we interpret $\frac{0}{0}$ as $\frac{1}{m}$; we remark that our negative results do not depend on this tie-breaking convention.
When $f_j^n$ is the same for all $j\in [m]$, we omit the subscript~$j$ and write $f^n$.
Furthermore, we may omit
the superscript~$n$ when it is clear from the context and simply write $f_j$ or $f$.

We will focus on five natural coordinate-wise aggregation rules, where $f$ is the \emph{average}, \emph{maximum}, \emph{minimum}, 
\emph{median} (if the number of agents is even, we take the average of the two middle scores), and \emph{geometric mean} function. 
For brevity, we refer to these rules as \avg, \maxrule{}, \minrule{}, \med{}, and \geo{}, respectively.
These rules have the advantages that they are intuitive and easily computable.

\subsubsection{Welfare-based Aggregation Rules}

For our second class, we consider rules that are based on welfare optimization. In particular, we focus on two popular welfare criteria:\footnote{There is a third popular welfare criterion called \emph{Nash welfare}, which is defined based on the {product} of utilities. However, this welfare notion is not well-defined in our setting, as we are considering disutilities. For example, it has been observed that there is no natural equivalent of Nash welfare in the fair allocation of chores \citep{freeman2020chores,ebadian2022chores}.} the \emph{utilitarian welfare} $-\sum_{i\in N}d_i(\mathbf{x})$ and the \emph{egalitarian welfare} $\min_{i\in N}(-d_i(\mathbf{x}))$. 
The minus sign ensures that these definitions indeed capture the welfare, as $d_i$ measures the disutility (rather than the utility) of agent $i$. 
The \emph{utilitarian rule} (\util{}) and the \emph{egalitarian rule} (\egal{}) then return an outcome that minimizes the utilitarian and egalitarian welfare, respectively. 
More formally, for each instance $\mathI$, \util{} chooses an outcome $\mathbf{x}_\util{}$ such that $\mathbf{x}_\util{}\in \arg\max_{\mathbf{x}} (-\sum_{i\in N}d_i(\mathbf{x}))$, while \egal{} returns 
$\mathbf{x}_\egal{}$ such that $\mathbf{x}_\egal{}\in \arg\max_{\mathbf{x}} \min_{i\in N} (-d_i(\mathbf{x}))$.

For both of these rules, the tie-breaking is important. 
Following~\cite{freeman2021truthfulbudget}, we consider the variant of \util{} that breaks ties in favor of the maximum entropy division. Specifically, we assume that \util{} outputs the utilitarian welfare-maximizing outcome $\mathbf{x}$ that minimizes the quantity $\sum_{j \in [m]} (x_j - \frac1m)^2$,
i.e., the $\ell_2$ distance to the uniform distribution $\mathbf{x}_u = (\frac1m, \dots, \frac1m)$.
This tie-breaking choice is neutral for candidates and ensures strategyproofness \citep{lindner2008allocating}.

For \egal{}, if there are multiple outcomes that maximize the egalitarian welfare, then we break ties in a ``leximin'' manner.
That is, we minimize the largest disutility, then subject to that, minimize the second-largest disutility, and so on. This type of leximin tie-breaking is standard when dealing with egalitarian welfare \citep[e.g.,][]{bogomolnaia2004random,kurokawa2018leximin}.
However, even after this tie-breaking process, there may still be multiple \egal{} outcomes. 
We show next that if $n=2$, \avg{} always returns an \egal{} outcome, so we assume that the \egal{} rule coincides with \avg{} in this case. By contrast, our results for $n\ge 3$ will not depend on this choice, and we allow \egal{} to break ties in any consistent manner (i.e., if $\mathbf{x}$ and $\mathbf{x}'$ are both \egal{} outcomes for two instances $\mathI$ and $\mathI'$, then we assume that if \egal{} chooses $\mathbf{x}$ for $\mathI$, it does not choose $\mathbf{x}'$ for $\mathI'$).

\begin{proposition} \label{prop:welfare-egal_is_sum}
    When $n=2$, the output of \avg{} is an \emph{\egal{}} outcome.
\end{proposition}
\begin{proof}
    Let $\mathbf{x}$ be the output of \avg{} for the case $n=2$. Then $x_j = \frac{s_{1,j}+s_{2,j}}{2}$ for each $j \in [m]$, so
    $d_1(\mathbf{x}) = d_2(\mathbf{x})$, and $d_1(\mathbf{x}) + d_2(\mathbf{x}) = \sum_{j\in [m]} |s_{1,j} - s_{2,j}|$. 
    Since $d_1(\mathbf{x}') + d_2(\mathbf{x}') \ge \sum_{j\in [m]} |s_{1,j} - s_{2,j}|$ for any outcome $\mathbf{x}'$, it follows that $\mathbf{x}$ is an \egal{} outcome.
\end{proof}

We also note that both \util{} and \egal{} (with the given tie-breaking conventions) can be computed in polynomial time. For \util{}, this follows from the results of \citet{freeman2021truthfulbudget}, and for \egal{}, we prove this claim in the appendix (see \Cref{thm:egal_compute}). 


\subsubsection{Independent Markets Rule}

The last aggregation rule that we will study is the \emph{independent markets} (\im) rule of \citet{freeman2021truthfulbudget}. 
This rule belongs to the class of \emph{moving phantoms} rules, which take for each candidate the median of the agents' reports and $n+1$ phantom values. However, because the final scores of all candidates must sum up to $1$, the phantom values cannot be constant. Instead, there are $n+1$ phantom functions $f_0,\dots,f_n:[0,1]\to [0,1]$ that are weakly increasing and satisfy $f_k(0)=0$ and $f_k(1)=1$ for all $k\in\{0,\dots,n\}$. 
Then, a moving phantoms rule determines the smallest value $t^*$ such that $\sum_{j\in[m]} \text{med}(s_{1,j}, \dots, s_{n,j}, f_0(t^*), \dots, f_{n}(t^*))=1$, and returns the vector $\mathbf{x}$ given by $x_j=\text{med}(s_{1,j}, \dots, s_{n,j}, f_0(t^*), \dots, f_{n}(t^*))$ for each $j\in [m]$. Finally, \im{} is defined by setting $f_k^{\im}(t)=\min(kt,1)$ for all $k\in \{0,\dots, n\}$. 

Before proceeding further, let us present a simple example demonstrating how the different aggregation rules work.

\begin{example}\label{ex:rules}
Consider an instance with $n = 2$ agents and $m = 3$ candidates.
The first agent has a preferred distribution $\mathbf{s}_1 = (0.8, 0.2, 0)$ and the second agent has a preferred distribution $\mathbf{s}_2 = (0.8, 0, 0.2)$.

\avg{} and \med{} output $(0.8, 0.1, 0.1)$, \minrule{} and \geo{} output $(1, 0, 0)$, and \maxrule{} outputs $(2/3, 1/6, 1/6)$.
For \util{}, the distribution $(0.8, x, 0.2-x)$ maximizes the utilitarian welfare for any $x\in [0, 0.2]$; among these distributions, $(0.8, 0.1, 0.1)$ minimizes the $\ell_2$ distance to the uniform distribution $(1/3, 1/3, 1/3)$, so \util{} returns this distribution.
The same distribution is also returned by \egal{}.
Finally, for \im{}, we have $\sum_{j\in[m]} \text{med}(s_{1,j}, s_{2,j}, f_0^{\im}(t^*), f_1^{\im}(t^*), f_{2}^{\im}(t^*))=1$ when $t^* = 0.3$, and \im{} returns the distribution $(0.6, 0.2, 0.2)$.
\end{example}

\subsection{Axioms}\label{subsec:axioms}

We next introduce the axioms that we will use to evaluate our aggregation rules. 
We roughly group the axioms into four categories: efficiency properties, fairness properties, consistency properties, and incentive properties. However, we note that the boundaries between these categories are fluid, particularly when considering weak axioms. 

\subsubsection{Efficiency Properties}

We start by introducing efficiency properties, which intuitively require the outcome chosen by an aggregation rule to be guided by the agents' preferences. 
Perhaps the most prominent such property is Pareto-optimality, which postulates that it should not be possible to make one agent better off without making another agent worse off. 

\begin{definition}[Pareto-optimality]
    An outcome $\mathbf{x}$ is \emph{Pareto-optimal} in an instance $\mathcal{I}$ if there is no other outcome $\mathbf{x'}$ such that $d_i(\mathbf{x'})\leq d_i(\mathbf{x})$ for all agents $i\in N$ and $d_i(\mathbf{x'})< d_i(\mathbf{x})$ for some agent $i\in N$. An aggregation rule $F$ is \emph{Pareto-optimal} if $F(\mathcal{I})$ is Pareto-optimal for every instance $\mathcal{I}$.
\end{definition}

As it will turn out, Pareto-optimality is a rather restrictive property in our setting, as only \util{} and \egal{} satisfy it among the considered rules. We thus introduce two further axioms based on the agents' scores, which can be viewed as weaker efficiency axioms. 
The first axiom is \emph{range-respect}, previously studied by \citet{freeman2021truthfulbudget}. This axiom states that the score assigned to a candidate should always lie between the minimum and the maximum scores that agents assign to this candidate.

\begin{definition}[Range-respect]
    An aggregation rule $F$ is \emph{range-respecting} if $\min_{i\in N}s_{i,j}\le F(\mathcal{I})_j \le \max_{i\in N}s_{i,j}$ for all instances $\mathcal{I}$ and all $j\in [m]$.
\end{definition}

Next, we introduce a new property which we call \emph{score-unanimity}. This property demands that if all agents report the same score for some candidate, then this candidate should receive exactly that score. Score-unanimity resembles a property called unanimity in single-winner voting, which states that if all agents agree on a favorite alternative, this alternative should be chosen. In single-winner voting, this property appears almost indispensable, and we believe that much of its appeal carries over to score-unanimity.  

\begin{definition}[Score-unanimity]
    An aggregation rule $F$ is \emph{score-unanimous} if
$F(\mathcal{I})_j=\gamma$ for all instances ${\mathcal I}$ and all $j\in [m]$ for which there exists $\gamma\in [0,1]$ such that  
    $s_{i,j} = \gamma$ for all $i \in N$.
\end{definition}

We show that our three efficiency notions are logically related. 

\begin{proposition}\label{thm:efficiency_implications}
The following claims hold.
    \begin{enumerate}[label=(\arabic*),topsep=4pt,itemsep=0pt]
        \item Pareto-optimality implies range-respect. 
        \item Range-respect implies Pareto-optimality if and only if $m=2$ or $n=2$. 
        \item Range-respect implies score-unanimity. 
    \end{enumerate}
\end{proposition}

\begin{proof}
    We prove each of the claims separately.\medskip

    \textbf{Claim 1}: Suppose for contradiction that there is an outcome $\mathbf{x}$ that is Pareto-optimal but not range-respecting for an instance $\mathcal{I}$. Without loss of generality, this means that there exists some $j \in [m]$ such that $x_j > \max_{i\in N} s_{i,j}$ (the case that $x_j<\min_{i\in N} s_{i,j}$ allows for a symmetric argument). Since $\sum_{k\in [m]} x_k=\sum_{k\in [m]} s_{1,k}=1$, there exists $\ell\in [m]$ such that $x_\ell<s_{1,\ell}$. Next, we define $\epsilon=\min(x_j-\max_{i\in N} s_{i,j},\,\,s_{1,\ell}-x_\ell)$ and consider the outcome $\mathbf{x'}$ defined by $x_j'=x_j-\epsilon$, $x_\ell'=x_\ell+\epsilon$, and $x'_k=x_k$ for all $k\in [m]\setminus \{j,\ell\}$. Since $x_j-\epsilon\geq s_{i,j}$ for all $i\in N$, it holds that $|(x_j-\epsilon)-s_{i,j}|=|x_j-s_{i,j}|-\epsilon$. By applying the triangle inequality and this observation, we find that for every agent $i\in N$, 
    \begin{align*}
        d_i(\mathbf{x'})&=|(x_j-\epsilon)-s_{i,j}|+|(x_\ell+\epsilon) -s_{i,\ell}|+\sum_{k\in [m]\setminus \{j,\ell\}} |x_k-s_{i,k}|\\
        &\leq |x_j-s_{i,j}|-\epsilon+|x_\ell -s_{i,\ell}|+\epsilon+\sum_{k\in [m]\setminus \{j,\ell\}}|x_k-s_{i,k}|
        =d_i(\mathbf{x}).
    \end{align*}
    Moreover, for agent $1$, it additionally holds that $s_{1,\ell}\geq x_\ell+\epsilon$, so we have that $|(x_\ell+\epsilon)-s_{1,\ell}|=|x_\ell-s_{1,\ell}|-\epsilon$. Using analogous computations as before, we then infer that $d_1(\mathbf{x'})=d_1(\mathbf{x})-2\epsilon<d_1(\mathbf{x})$. This means that $\mathbf{x}$ is not Pareto-optimal, a contradiction. 
    It follows that Pareto-optimality implies range-respect.\bigskip

    \textbf{Claim 2}: For our second claim, we show that range-respect implies Pareto-optimality if and only if $m=2$ or $n=2$. First, we assume that $n=2$ and let $\mathbf{s}_1$ and $\mathbf{s}_2$ denote the preferences of the agents. Using the triangle inequality, we derive for every outcome $\mathbf{x}$ that $d_1(\mathbf{x})+d_2(\mathbf{x}) \geq \sum_{j \in [m]} |s_{1,j} - s_{2,j}|$. Moreover, if $\mathbf{x}$ is range-respecting, it holds that $d_1(\mathbf{x})+d_2(\mathbf{x}) = \sum_{j \in [m]} |s_{1,j} - s_{2,j}|$ because $\min(s_{1,j}, s_{2,j})\leq x_j\leq \max(s_{1,j}, s_{2,j})$ implies that $|s_{1,j}-x_j|+|s_{2,j}-x_j|=|s_{1,j}-s_{2,j}|$. This shows that every range-respecting outcome is Pareto-optimal, because any outcome that Pareto-dominates a range-respecting outcome would need to have strictly less total disutility.

    Next, consider the case $m=2$ and let $\mathbf{x}$ denote an outcome that is range-respecting for an instance $\mathcal{I}$. Furthermore, let $\mathbf{x'}$ denote another outcome and assume without loss of generality that $x_1 > x'_1$. Since $m=2$, this means that $x_2 < x'_2$. Let $i$ be an agent such that $s_{i,1}\geq x_1$, which implies that $s_{i,2}\leq x_2$; such an agent exists since $\mathbf{x}$ is range-respecting. Observe that
        $d_i(\mathbf{x}) = (s_{i,1} - x_1) + (x_2 - s_{i,2}) < (s_{i,1} - x'_1) + (x'_2 - s_{i,2}) = d_i(\mathbf{x}')$.
    Consequently, agent $i$ strictly prefers $\mathbf{x}$ to every outcome $\mathbf{x'}$ with $x_1>x_1'$. Since an analogous argument holds if $x_1<x_1'$, we infer that $\mathbf{x}$ is Pareto-optimal. 

    We now show that range-respect does not imply Pareto-optimality if $m\geq 3$ and $n\geq 3$. We focus on the case where $m=3$, as it is trivial to extend the counterexample to larger $m$ by universally assigning probability $0$ to additional candidates. Now, consider the following instance and the outcome $\mathbf{x} = (\frac{1}{6}, \frac{1}{3}, \frac{1}{2})$. It is easy to verify that $\mathbf{x}$ is range-respecting for $\mathcal{I}$. However, the outcome $(0, \frac{1}{2}, \frac{1}{2})$ strictly benefits agent $2$ and does not hurt the other agents, so $\mathbf{x}$ is not Pareto-optimal.

    \begin{center}
        \begin{tabular}{ c | c c c c}
          $\mathcal{I}$ & $s_{i,1}$ & $s_{i,2}$ & $s_{i,3}$  \\ 
         \hline \hline
         $1$ & $0$ & $0$ & $1$ \\ 
         $2$ & $0$ & $\frac{1}{2}$ & $\frac{1}{2}$ \\ 
         $i\in \{3,\dots, n\}$ & $\frac{1}{2}$ & $\frac{1}{2}$ & $0$ \\ 
        \end{tabular}        
    \end{center}

    \bigskip
    
    \textbf{Claim 3}: Finally, we show that range-respect implies score-unanimity. To this end, let $\mathcal{I}=(\mathbf{s}_1, \dots, \mathbf{s}_n)$ denote an instance and $j\in[m]$ be such that there exists $\gamma\in [0,1]$ with $s_{i,j}=\gamma$ for all $i\in N$. Range-respect of an outcome $\mathbf{x}$ implies that $\gamma=\min_{i\in N} s_{i,j}\leq x_j\leq \max_{i\in N} s_{i,j}=\gamma$, so $x_j=\gamma$ and score-unanimity is satisfied. 
\end{proof}

\subsubsection{Fairness Properties}

For the second type of axioms, we turn to fairness concepts, which intuitively demand that every group of agents with similar preferences is proportionally represented by the outcome. A rather mild axiom based on this idea has been formulated by \citet{freeman2021truthfulbudget}. Specifically, these authors call an agent \emph{single-minded} if she assigns probability $1$ to some candidate. Their proportionality notion then requires that, if all agents are single-minded, each candidate should receive a probability proportional to the number of agents that assign probability $1$ to it. To formalize this, we define $\mathcal{N}(\mathcal{I},c_j,\gamma):=|\{i\in N\colon s_{i,j}\geq\gamma\}|$ as the number of agents who assign a probability of at least $\gamma$ to candidate $c_j$ in the instance $\mathcal{I}$. 

\begin{definition}[Single-minded Proportionality]
\label{def:proportionality}
    An aggregation rule $F$ satisfies \emph{single-minded proportionality} if $F(\mathcal{I})_j=\frac{\mathcal{N}(\mathcal{I},c_j,1)}{n}$ for all candidates $c_j\in C$ and instances $\mathcal{I}$ in which all agents are single-minded.
\end{definition}

However, agents are rarely single-minded in several applications of portioning (such as dividing time between different activities at a conference), so an appropriate notion of proportionality for general preferences is needed.
We formulate one such notion for the cardinal preference setting, and refer to it as \emph{score-representation}. The idea of this notion is that if a $\frac{k}{n}$ fraction of the agents assign a portion of at least $\gamma$ to a candidate $c_j$, then this candidate should receive a probability of at least $\gamma\cdot\frac{k}{n}$.

\begin{definition}[Score-representation] \label{defn-score_representation}
    An aggregation rule $F$ satisfies \emph{score-representation} if $F(\mathcal{I})_j\geq \gamma\cdot \frac{\mathcal{N}(\mathcal{I}, c_j, \gamma)}{n}$ for all instances $\mathcal{I}$, candidates $c_j\in C$, and $\gamma\in [0,1]$.
\end{definition}

It follows directly from the definitions that score-representation is strictly stronger than single-minded proportionality. 

\subsubsection{Consistency Properties}

As the third type of axioms, we consider consistency properties, which aim to ensure that voting rules behave, in some sense, consistently across instances. The first such axiom that we examine is \emph{independence}, which has previously been studied by \citet{intriligator1973probsc}. 
The idea of this axiom is that the score assigned to a candidate by an aggregation rule should only depend on the scores that the agents assign to this candidate, and is therefore independent of the scores assigned to other candidates. We remark that this axiom is similar in spirit to Arrow's independence of irrelevant alternatives \citep{Arro51a}, as it postulates that we can compute the outcome for a candidate without taking into account the remaining candidates. 
The definition is as follows.

\begin{definition}[Independence]
    An aggregation rule $F$ satisfies \emph{independence} if $F(\mathI)_j=F(\mathI')_j$ for all instances $\mathI$ and $\mathI'$ and all $j\in [m]$ such that $s_{i,j}=s'_{i,j}$ for all $i\in N$. 
\end{definition}

Independence is a demanding axiom and, for example, implies that the considered rule must be coordinate-wise, because we can define the $j$-th coordinate-aggregation function by $f^n_j(s_{1,j},\dots, s_{n,j})=F(\mathcal{I})_j$. 
Nevertheless, we believe that this axiom is appealing in practice, as it is intuitive and greatly simplifies the task of aggregating the agents' score vectors.
Moreover, a violation of independence can lead to complaints from candidates that receive a smaller portion of the resource despite getting the same score from every agent as before.

Next, we introduce \emph{score-monotonicity}. This axiom requires that, if an agent increases the score of some candidate, then the aggregated score of this candidate is also weakly increasing. Score-monotonicity was previously studied by \citet{freeman2021truthfulbudget},\footnote{\citet{freeman2021truthfulbudget} simply called this notion ``monotonicity''.} and similar monotonicity notions are omnipresent in social choice theory. 

\begin{definition}[Score-monotonicity] \label{defn-score_monotonicity}
    An aggregation rule $F$ is \emph{score-monotone} if
    $F(\mathI)_j\leq F(\mathI')_j$ for all instances $\mathcal{I}$, $\mathcal{I'}$ and all $j\in[m]$ for which there is an agent $i\in N$ such that \emph{(i)} $\mathbf{s}_{i'}=\mathbf{s}'_{i'}$ for all $i'\in N\setminus \{i\}$, \emph{(ii)} $s_{i,j} < s'_{i,j}$, and \emph{(iii)} $s_{i,j'} \geq  s'_{i,j'}$ for all $j'\in [m]\setminus \{j\}$.
\end{definition}

The final consistency notion that we study is \emph{reinforcement}, which demands that if an aggregation rule chooses the same outcome for two instances with disjoint sets of agents, then it also chooses that outcome when combining these two instances. Variants of this axiom feature prominently in numerous results in social choice theory \citep[e.g.,][]{Youn75a,Fish78d,YoLe78a,Bran13a}. 

\begin{definition}[Reinforcement]
    An aggregation rule $F$ satisfies \emph{reinforcement} if, for all instances $\mathI=(\mathbf{s}_1,\dots, \mathbf{s}_n)$ and $\mathI'=(\mathbf{s}_1',\dots, \mathbf{s}_{n'}')$ with $F(\mathI)=F(\mathI')$, it holds that $F(\mathbf{s}_1,\dots, \mathbf{s}_n,\mathbf{s}_1',\dots, \mathbf{s}_{n'}')=F(\mathI)$. 
\end{definition}

Independence, score-monotonicity, and reinforcement are logically unrelated, as they formalize rather different notions of consistency. However, we emphasize that variants of these three axioms are well-established in the literature and we therefore believe that it is important to study all of them.

\subsubsection{Incentive Properties}

Our last category of axioms is concerned with the incentives of agents: aggregation rules should incentivize agents to participate and to report their preferences truthfully. These ideas lead to the well-known notions of \emph{participation} and \emph{strategyproofness}. We start by defining strategyproofness, which stipulates that agents should not be able to benefit from lying about their true preferences. 

\begin{definition}[Strategyproofness] \label{defn-strategyproofness}
    An aggregation rule $F$ is \emph{strategyproof} if 
    $d_i(F(\mathI)) \leq d_i(F(\mathI'))$ for all instances $\mathcal{I}$ and $\mathcal{I'}$ and agents $i\in N$ such that $\mathbf{s}_{i'}=\mathbf{s}_{i'}'$ for all $i'\in N\setminus \{i\}$.
\end{definition}

While it is known that \im{} and \util{} satisfy strategyproofness \citep{goel2019knapsack,freeman2021truthfulbudget}, this property is in general rather demanding, as demonstrated by the impossibility theorem of \citet{brandt2024optimal} stating that no aggregation rule simultaneously satisfies strategyproofness, Pareto-optimality, and single-minded proportionality.

Participation is a property closely related to strategyproofness---it dictates that agents should not be able to profit by abstaining. 
Put differently, participation ensures that it is always weakly better for every agent to express her preference.

\begin{definition}[Participation] \label{defn-participation}
    An aggregation rule $F$ satisfies \emph{participation} if $d_i(F(\mathcal{I}))\leq d_i(F(\mathcal{I}'))$ for all instances $\mathcal{I}$ and $\mathcal{I}'$ such that $\mathcal{I}$ is obtained from $\mathcal{I}'$ by adding agent $i$.
\end{definition}

We note that participation and strategyproofness are logically independent in general. However, when imposing reinforcement and the very mild condition that $F(\mathbf{x})=\mathbf{x}$ (i.e., if there is a single agent, we choose her ideal distribution), it can be shown that strategyproofness implies participation. 



\section{Efficiency Properties} \label{sec:score_unanimity_rr}

We now analyze our aggregation rules with respect to the axioms defined in \Cref{subsec:axioms}. In this section, we study the three efficiency properties and show that, while \util{} and \egal{} satisfy Pareto-optimality, all other rules except \avg{} fail even score-unanimity. 
Recall from \Cref{thm:efficiency_implications} that Pareto-optimality implies range-respect which in turn implies score-unanimity, and that range-respect implies Pareto-optimality if $m = 2$ or $n = 2$.

\begin{theorem} \label{thm:efficiencyprops}
    The following claims hold.
        \begin{enumerate}[label=(\arabic*),topsep=4pt,itemsep=0pt]
        \item \emph{\util{}} and \emph{\egal{}} are Pareto-optimal (and thus range-respecting and score-unanimous).
        \item \avg{} is range-respecting (and thus Pareto-optimal when $m = 2$ or $n = 2$, and score-unanimous for any $m,n$), but fails Pareto-optimality for all $m\geq 3$ and $n\geq 3$.
        \item \med{} is range-respecting when $m\leq 3$ or $n=2$ (and thus Pareto-optimal when $m = 2$ or $n = 2$).
        If $m = 3$, it is Pareto-optimal if $n\ge 3$ is odd, but fails Pareto-optimality if $n\ge 4$ is even.
        It fails score-unanimity for all $m \geq 4$ and $n \geq 3$.
        \item \maxrule{}, \minrule{}, \geo{}, and \im{} are Pareto-optimal when $m=2$, but fail score-unanimity for all $m\geq 3$ and $n\geq 2$.
        \end{enumerate}
\end{theorem}
\begin{proof}
We prove each of the claims separately.\bigskip

\textbf{Claim 1}: The claim follows directly from the definitions of \emph{\util{}} and \emph{\egal{}}, since a Pareto improvement would also give rise to an improvement with respect to the welfare measure. In more detail, 
for \emph{\egal{}}, we use the fact that its definition lexicographically minimizes the maximum disutility of the agents. In particular, if an outcome $\mathbf{x}$ returned by \emph{\egal{}} was Pareto-dominated by another outcome $\mathbf{x'}$, then $\mathbf{x'}$ would have a better egalitarian welfare in this leximin optimization, which contradicts the definition of \emph{\egal{}}.
By \Cref{thm:efficiency_implications}, both rules are range-respecting and score-unanimous as well. \bigskip

\textbf{Claim 2}: Let $\mathbf{x}$ be the output of \avg{} for some instance $\mathcal{I}$. It holds for all $j \in [m]$ that $\min_{i\in N} s_{i,j}\leq \frac{1}{n}\sum_{i\in N} s_{i,j}\leq \max_{i\in N} s_{i,j}$, which shows that \avg{} is range-respecting. By Claim 2 of \Cref{thm:efficiency_implications}, this also means that \avg{} is Pareto-optimal if $m = 2$ or $n = 2$.

To show that \avg{} fails Pareto-optimality when $m\geq 3$ and $n\geq 3$, consider the following instance $\mathI^1$, where all candidates in $C\setminus \{c_1,c_2,c_3\}$ receive probability $0$ from all agents and can thus be ignored. For this instance, \avg{} outputs the vector $(\frac{1}{2n}, \frac{2}{2n}, 1-\frac{3}{2n})$. 
    However, the outcome $\mathbf{x'}=(0,\frac{3}{2n}, 1-\frac{3}{2n})$ decreases the disutility of agent $1$ without decreasing the disutility of the other agents, so \avg{} is not Pareto-optimal.

    \begin{center}
        \begin{tabular}{ c | c c c c}
          $\mathcal{I}^1$ & $s_{i,1}$ & $s_{i,2}$ & $s_{i,3}$ \\ 
         \hline \hline
         $1$ & $0$ & $\frac{1}{2}$ & $\frac{1}{2}$\\ 
         $2$ & $\frac{1}{2}$ & $\frac{1}{2}$ & $0$\\ 
         $i\in\{3,\dots,n\}$ & $0$ & $0$ & $1$ \\
        \end{tabular}       
    \end{center}
\bigskip

\textbf{Claim 3}: 
Since \med{} is equivalent to \avg{} when $n=2$, it is range-respecting for $n=2$ by Claim~2, and also Pareto-optimal by Claim~2 of \Cref{thm:efficiency_implications}. For the case $m=2$, consider an instance $\mathcal{I}$ and assume without loss of generality that $s_{1,1}\leq s_{2,1}\leq \dots \leq s_{n,1}$. Since $m=2$, we infer that $s_{i,2}=1-s_{i,1}$, so $s_{1,2}\geq s_{2,2}\geq \dots \geq s_{n,2}$. Hence, \med{} returns $\mathbf{x}=(s_{(n+1)/2,\, 1}, s_{(n+1)/2,\,2})$ if $n$ is odd, and $\mathbf{x}=(\frac{s_{n/2,\, 1}+s_{(n+2)/2,\, 1}}{2}, \frac{s_{n/2,\, 2}+s_{(n+2)/2,\, 2}}{2})$ if $n$ is even. This verifies that \med{} is range-respecting for $m=2$, and Claim 2 of \Cref{thm:efficiency_implications} entails that it is also Pareto-optimal. 

Now, when $m=3$, suppose for contradiction that there exists an instance $\mathcal{I}$ such that the outcome $\mathbf{x}$ chosen by \med{} fails range-respect. Without loss of generality, we assume that $x_1<\min_{i\in N} s_{i,1}$ (the choice of the candidate does not matter, and if $x_1>\max_{i\in N} s_{i,1}$, we can reverse all inequalities in the proof). Moreover, let $m_1$, $m_2$, $m_3$ denote the medians (before normalization) for the candidates $c_1$, $c_2$, $c_3$, respectively. This means that $\mathbf{x}=\left(\frac{m_1}{m_1+m_2+m_3}, \frac{m_2}{m_1+m_2+m_3}, \frac{m_3}{m_1+m_2+m_3}\right)$. Since $m_1\geq \min_{i\in N} s_{i,1}$, we infer from $x_1<\min_{i\in N} s_{i,1}$ that $m_1+m_2+m_3>1$. Moreover, it holds that $s_{i,2}+s_{i,3}=1-s_{i,1}<1-\frac{m_1}{m_1+m_2+m_3}$ for all agents $i\in N$. We will next show that $m_2+m_3\leq 1-\min_{i\in N} s_{i,1}$. This then implies that $\frac{m_1+m_2+m_3}{m_1+m_2+m_3}<m_2+m_3+\frac{m_1}{m_1+m_2+m_3}<1$, which yields the desired contradiction.

To show that $m_2+m_3\leq 1-\min_{i\in N} s_{i,1}$, we note that each median by itself is monotone (i.e., if we increase some value $s_{i,j}$, then $m_j$ does not decrease). Hence, we consider modified values $\hat s_{i,2}$ and $\hat s_{i,3}$ which satisfy $\hat s_{i,2}\geq s_{i,2}$, $\hat s_{i,3}\geq s_{i,3}$, and $\hat s_{i,2}+\hat s_{i,3}=1-\min_{i'\in N} s_{i',1}$ for all $i\in N$. By the monotonicity of the medians, we have that the corresponding medians $\hat m_2$ and $\hat m_3$ satisfy $\hat m_2\geq m_2$ and $\hat m_3\geq m_3$. Moreover, it holds that $\hat s_{i,2}=1-\min_{i'\in N} s_{i',1}-\hat s_{i,3}$. This means that, for all agents $i$ and $i'$, we have $\hat s_{i,2}\leq \hat s_{i',2}$ if and only if $\hat s_{i,3}\geq \hat s_{i',3}$. Consequently, the median agent(s) for $c_2$ are also the median agent(s) for $c_3$, which implies that $\hat m_2+\hat m_3=1-\min_{i\in N} s_{i,1}$. This completes the proof of our auxiliary claim. 

    Next, we prove that \med{} satisfies Pareto-optimality for $m=3$ and any odd $n \geq 3$.
    Let $m_1$, $m_2$, $m_3$ again denote the medians (before normalization) for the candidates $c_1$, $c_2$, $c_3$, respectively.
    Without loss of generality, assume that $m_1 + m_2 + m_3 \leq 1$.
    For $k \in \{1,2,3\}$, let $T_k \subseteq N$ be the set of agents $i$ such that $s_{i,k} \geq m_k$ and $s_{i,k'} \leq m_{k'}$ for all other $k' \neq k$.
    Fix some $k \in \{1,2,3\}$.
    We first show that $T_k \neq \emptyset$.
    Suppose for contradiction that $T_k = \emptyset$, i.e., for every agent $i \in N$ such that $s_{i,k} \geq m_k$, there exists $k' \neq k$ with $s_{i,k'} > m_{k'}$.
    Furthermore, for every agent $i' \in N$ with $s_{i',k} < m_k$, there also exists $k' \neq k$ with $s_{i',k'} > m_{k'}$; otherwise $s_{i',1} + s_{i',2} + s_{i',3} < m_1 + m_2 + m_3 \leq 1$, a contradiction.
    Thus, for all agents $i \in N$, there exists $k' \neq k$ with $s_{i,k'} > m_{k'}$.
    However, since $\sum_{k' \neq k} |\{i \in N : s_{i,k'} > m_{k'}\}| \leq \frac{n-1}{2} + \frac{n-1}{2} = n-1$, we get a contradiction.
    Hence, $T_k \neq \emptyset$.

    Since $m_1 + m_2 + m_3 \leq 1$, for each $j \in \{1,2,3\}$, we have $x_j = \frac{m_j}{m_1+m_2+m_3} \geq m_j$.
    This means that for all $i \in T_k$ and $k' \neq k$, it holds that $s_{i,k'} \leq x_{k'}$.
    Together with the fact that $s_{i,1} + s_{i,2} + s_{i,3} = 1$, we must have that $s_{i,k} \geq x_k$.
    Then, in order to construct an outcome $\mathbf{x}'$ such that $d_i(\mathbf{x}') \leq d_i(\mathbf{x})$ for every agent $i \in N$, we must have that $x'_k \geq x_k$; otherwise agent $i \in T_k$ will have a strictly higher disutility. However, since this holds for all $k \in \{1,2,3\}$, we get that $\mathbf{x}' = \mathbf{x}$, which means that $\mathbf{x}$ is Pareto-optimal.
    The argument for the case where $m_1+m_2+m_3 >1$ is symmetric, by reversing the signs (including the definition of $T_k$).
    
    On the other hand, we show that \med{} fails Pareto-optimality for $m = 3$ and any even $n\geq 4$. To this end, consider the following instance $\mathcal{I}^2$ for an even number of agents $n$. 
    In this instance, we have that $\text{med}_{i\in N} s_{i,1}=\frac{9}{20}$, $\text{med}_{i\in N} s_{i,2}=\frac{3}{10}$, and $\text{med}_{i\in N} s_{i,3}=\frac{3}{8}$, so \med{} returns the outcome $\mathbf{x} = \left( \frac{4}{10}, \frac{4}{15}, \frac{1}{3} \right)$.
    However, the outcome $\left( \frac{4}{10}, \frac{5}{20}, \frac{7}{20}\right)$ strictly benefits agent $2$ and does not hurt the other agents, so $\mathbf{x}$ is not Pareto-optimal.
        \begin{center}
            \begin{tabular}{ c | c c c}
              $\mathcal{I}^2$ & $s_{i,1}$ & $s_{i,2}$ & $s_{i,3}$  \\ 
             \hline \hline
             $1$ & $\frac{3}{10}$ & $\frac{7}{20}$ & $\frac{7}{20}$ \\ 
             $2$ & $\frac{6}{10}$ & $0$ & $\frac{4}{10}$ \\
             $i \in \{3,\dots,\frac{n}{2}+1 \}$ & $\frac{7}{10}$ & $\frac{1}{4}$ & $\frac{1}{20}$ \\ 
             $i \in \{\frac{n}{2}+2,\dots,n \}$ & $\frac{1}{4}$ & $\frac{7}{20}$ & $\frac{4}{10}$ \\ 
              
            \end{tabular}       
        \end{center}\bigskip

Finally, we show that \med{} fails even score-unanimity when $m\geq 4$ and $n\geq 3$. To this end, consider the following instance $\mathcal{I}^3$ for an odd number of agents $n$, where all candidates $c_j$ with $5\leq j\leq m$ receive probability $0$ from all agents. In this instance, we have that $\text{med}_{i\in N} s_{i,1}=\frac{3}{10}$, $\text{med}_{i\in N} s_{i,2}=\frac{5}{10}$, and $\text{med}_{i\in N} s_{i,3}=\text{med}_{i\in N} s_{i,4}=0$, so \med{} assigns probability $\frac{3}{8}$ to $c_1$. To obtain a counterexample for even $n$, we can duplicate agent~$1$ to get a similar counterexample. 

    \begin{center}
        \begin{tabular}{ c | c c c c}
          $\mathcal{I}^3$ & $s_{i,1}$ & $s_{i,2}$ & $s_{i,3}$ & $s_{i,4}$ \\ 
         \hline \hline
         $1$ & $\frac{3}{10}$ & $\frac{5}{10}$ & $0$ & $\frac{2}{10}$ \\ 
         $i\in \{2,\dots, \frac{n+1}{2}\}$ & $\frac{3}{10}$ & $\frac{1}{10}$ & $\frac{6}{10}$ & $0$ \\ 
         $i\in \{\frac{n+3}{2},\dots, n\}$ & $\frac{3}{10}$ & $\frac{7}{10}$ & $0$ & $0$ 
        \end{tabular}       
    \end{center}\bigskip


\textbf{Claim 4}: We consider each rule separately.\bigskip

\emph{\geo{}}: First, assume that $m=2$.
We will show that \geo{} is range-respecting and hence Pareto-optimal. To this end, fix some instance $\mathcal{I}$ and let $\mathbf{x}$ be the outcome returned by \geo{}. Without loss of generality, we focus on $c_1$ and show that $\min_{i \in N} s_{i,1} \leq x_1 \leq \max_{i \in N} s_{i,1}$. Let $y_j=\sqrt[n]{\prod_{i\in N} s_{i,j}}$ and observe that $\min_{i\in N} s_{i,j}\leq y_j\leq \max_{i\in N} s_{i,j}$. By multiplying with $(1-\max_{i\in N} s_{i,1})$ and $(1-\min_{i\in N} s_{i,1})$, this leads to the following inequalities: 
 \begin{equation*}
        y_1 \cdot (1-\max_{i \in N} s_{i,1}) \leq \max_{i \in N} s_{i,1} \cdot (1-\max_{i \in N} s_{i,1});
\end{equation*}
 \begin{equation*}
        y_1 \cdot (1-\min_{i \in N} s_{i,1}) \geq \min_{i \in N} s_{i,1} \cdot (1-\min_{i \in N} s_{i,1}).
\end{equation*}
Equivalently, this means that 
\begin{equation*}
        \frac{y_1}{y_1 + 1 - \max_{i \in N} s_{i,1}} \leq \max_{i \in N} s_{i,1}\qquad \text{and}\qquad \frac{y_1}{y_1 + 1 - \min_{i \in N} s_{i,1}} \geq \min_{i \in N} s_{i,1}.
\end{equation*}
Since $m=2$, it holds that $1 - \min_{i \in N} s_{i,1}=\max_{i\in N} s_{i,2}$ and  $1 - \max_{i \in N} s_{i,1}=\min_{i\in N} s_{i,2}$. Hence, we derive that 
\begin{align*}
    \min_{i\in N} s_{i,1} \leq \frac{y_1}{y_1 + \max_{i \in N} s_{i,2}}\leq \frac{y_1}{y_1 +y_2}\leq \frac{y_1}{y_1 + \min_{i \in N} s_{i,2}}\leq \max_{i\in N} s_{i,1}. 
\end{align*}
Because $x_1=\frac{y_1}{y_1 +y_2}$, this shows that \geo{} is range-respecting if $m=2$.

To see that \geo{} fails score-unanimity when $m\geq 3$ and $n\geq 2$, consider the following instance $\mathcal{I}^4$. For this instance, \geo{} outputs the vector $$\mathbf{x}=\left(\frac{1}{1+2^{\frac{1}{n}} + 2^{\frac{n-1}{n}}}, \frac{2^{\frac{1}{n}}}{1+2^{\frac{1}{n}} + 2^{\frac{n-1}{n}}}, \frac{2^{\frac{n-1}{n}}}{1+2^{\frac{1}{n}} + 2^{\frac{n-1}{n}}}\right).$$ This outcome fails score-unanimity as $2^{\frac{1}{n}}+2^{\frac{n-1}{n}}<3$ for all $n\geq 2$; this follows from the inequality $(2^{\frac{n-1}{n}} - 1)(2^{\frac{1}{n}} - 1) > 0$. To extend the counterexample to larger $m$, one can add candidates that receive a score of $0$ from all agents. 

\begin{center}
        \begin{tabular}{ c | c c c c }
          $\mathcal{I}^4$ & $s_{i,1}$ & $s_{i,2}$ & $s_{i,3}$\\ 
         \hline \hline
         $1$ & $\frac{1}{4}$ & $\frac{1}{2}$ & $\frac{1}{4}$\\ 
         $i\in \{2,\dots, n\}$ &  $\frac{1}{4}$ & $\frac{1}{4}$ & $\frac{1}{2}$ \\ 
        \end{tabular}       
    \end{center}\smallskip

\emph{\maxrule{}}: Next, we consider \maxrule{} and first show that it is range-respecting (and hence Pareto-optimal) if $m=2$. For this, we fix an instance $\mathcal{I}$ and focus on candidate $c_1$. We observe that $\max_{i\in N} s_{i,1}+\max_{i\in N} s_{i,2}\geq 1$, which implies that $x_1=\frac{\max_{i\in N} s_{i,1}}{\max_{i\in N} s_{i,1}+\max_{i\in N} s_{i,2}}\leq \max_{i\in N} s_{i,1}$. For the other direction, we note that 
\begin{align*}
    \min_{i\in N} s_{i,1} (1+\max_{i\in N} s_{i,1} - \min_{i\in N} s_{i,1})
    &= \min_{i\in N} s_{i,1} + \min_{i\in N} s_{i,1} (\max_{i\in N} s_{i,1} - \min_{i\in N} s_{i,1}) \\
    &\leq \min_{i\in N} s_{i,1} + (\max_{i\in N} s_{i,1} - \min_{i\in N} s_{i,1}) = \max_{i\in N} s_{i,1}. 
\end{align*}
Since $\max_{i\in N} s_{i,2}=1-\min_{i\in n} s_{i,1}$ when $m=2$, we derive that 
\begin{equation*}
    \min_{i\in N} s_{i,1}\leq \frac{\max_{i\in N} s_{i,1}}{\max_{i\in N} s_{i,1} + \max_{i\in N} s_{i,2}}=x_1.
\end{equation*}
This shows that \maxrule{} is range-respecting if $m=2$. 

To show that \maxrule{} fails score-unanimity if $m\geq 3$ and $n\geq 2$, we consider the instance $\mathcal{I}^4$ which was used to show that \geo{} also fails score-unanimity. For this instance, \maxrule{} returns the outcome $\mathbf{x}=(\frac{1}{5}, \frac{2}{5}, \frac{2}{5})$, which violates score-unanimity for $c_1$. 
\bigskip

\emph{\minrule{}}: We now turn to \minrule{} and show that it is range-respecting and therefore Pareto-optimal if $m=2$. Hence, we consider an instance $\mathcal{I}$ and focus again on candidate $c_1$. We first observe that $\min_{i\in N} s_{i,1}+\min_{i\in N} s_{i,2}\leq 1$, so $\min_{i\in N} s_{i,1}\leq \frac{\min_{i\in N} s_{i,1}}{\min_{i\in N} s_{i,1}+\min_{i\in N} s_{i,2}}=x_1$. For the other direction, we note analogously to \maxrule{} that 
\begin{align*}
    \max_{i\in N} s_{i,1}(1+\min_{i\in N} s_{i,1}-\max_{i\in N} s_{i,1})
    &= \max_{i\in N} s_{i,1} + \max_{i\in N} s_{i,1} (\min_{i\in N} s_{i,1}-\max_{i\in N} s_{i,1}) \\
    &\geq \max_{i\in N} s_{i,1} +  (\min_{i\in N} s_{i,1}-\max_{i\in N} s_{i,1})
    = \min_{i\in N} s_{i,1}.
\end{align*}
Using that $\min_{i\in N} s_{i,2}=1-\max_{i\in N} s_{i,1}$, we thus have that 
\begin{equation*}
    \max_{i\in N} s_{i,1}\geq \frac{\min_{i\in N} s_{i,1}}{\min_{i\in N} s_{i,1} + \min_{i\in N} s_{i,2}}=x_1.
\end{equation*}
This completes the proof that \minrule{} is range-respecting. 

Finally, we consider again the instance $I^4$ to prove that \minrule{} fails score-unanimity. \minrule{} chooses for this instance the outcome $\mathbf{x}=(\frac{1}{3}, \frac{1}{3}, \frac{1}{3})$, which violates score-unanimity for $c_1$.\bigskip

\emph{\im{}}: As the last rule, we consider \im{} and first show that it is range-respecting (and Pareto-optimal) when $m=2$. 
Consider an instance $\mathcal{I}$ and let $\mathbf{x}$ be the output vector of \im{}. We first note that $x_j\leq  \max_{i\in N} s_{i,j}$ for $j\in \{1,2\}$ as one phantom is always at $0$. Next, if $x_j<\min_{i\in N} s_{i,j}$ for some $j\in \{1,2\}$, then it holds for $j'\neq j$ that $x_{j'}>\max_{i\in N} s_{i,j'}$, since $s_{i,j}=1-s_{i,j'}$ for all $i\in N$ and $x_j=1-x_{j'}$. However, this is impossible due to our previous observation, so we conclude that \im{} is range-respecting when $m=2$. 

To show that \im{} fails score-unanimity when $m\geq 3$ and $n\geq 2$, we consider the instance $\mathcal{I}^5$ shown below, where all candidates $c_j$ with $j\geq 4$ receive a probability of $0$ from all agents.
For this instance, score-unanimity requires that $x_1 = \frac{n+1}{n+2}$. However, it can be checked that \im{} assigns probability $\frac{n}{n+2}$ to $c_1$ (at $t^*=\frac{1}{n+2}$), thus showing that score-unanimity is violated. 
\begin{center}
        \begin{tabular}{ c | c c c c }
          $\mathcal{I}^5$ & $s_{i,1}$ & $s_{i,2}$ & $s_{i,3}$  \\ 
         \hline \hline
         $1$ & $\frac{n+1}{n+2}$ & $\frac{1}{n+2}$ & $0$ \\ 
         $i\in \{2,\dots, n\}$ &  $\frac{n+1}{n+2}$ & $0$ & $\frac{1}{n+2}$ 
        \end{tabular}       
    \end{center}
\bigskip This completes the proof.
\end{proof}

\begin{remark}
   \citet[p. 22]{freeman2021truthfulbudget} suggested a variant of \im{} where the last moving phantom is fixed to $1$, i.e., $f^{\text{IM}'}_n(t)=1$. This modified rule satisfies range-respect, single-minded proportionality, and strategyproofness. However, it is unclear whether it inherits other desirable properties of \im{} such as reinforcement and participation. 
\end{remark}

\begin{remark}
    In some settings, it is computationally challenging to determine whether an outcome is efficient \citep[e.g.,][]{aziz2019efficient}. This is not the case in our context: it is straightforward to check whether an outcome satisfies score-unanimity and range-respect, and we give a linear programming formulation for deciding whether an outcome is Pareto-optimal in the appendix (see~\Cref{thm:po_check}). 
\end{remark}


\section{Fairness Properties} \label{sec:proc_sr}

We next turn to fairness properties and study our rules with respect to single-minded proportionality and the more demanding notion of score-representation. In particular, we will show that none of our rules satisfies score-representation except \avg{}, thus making a strong case for this rule. 
Note that some of our results follow from the work of \citet{freeman2021truthfulbudget}: these authors have shown that \im{} satisfies single-minded proportionality and that \emph{\util{}} fails this property (without specifying the boundaries for when this is the case). 

\begin{theorem}
    The following claims hold. 
    \begin{enumerate}[label=(\arabic*),topsep=4pt,itemsep=0pt]
    \item \avg{} satisfies score-representation (and therefore single-minded proportionality).
    \item \im{} satisfies score-representation when $m=2$ and single-minded proportionality for any $m$, but fails score-representation for all $n\geq 2$ and $m\geq 3$.
    \item \maxrule{} and \emph{\util{}} satisfy score-representation when $n=m=2$ and single-minded proportionality when $n=2$. Both rules violate score-representation for all $m\geq 3$ and $n\geq 2$, and single-minded proportionality for all $m\geq 2$ and $n\geq 3$. 
    \item \med{} and \emph{\egal{}} satisfy score-representation when $n=2$, but fail single-minded proportionality for all $m\geq 2$ and $n\geq 3$.
    \item \minrule{} and \geo{} satisfy single-minded proportionality when $n=m=2$, but fail to do so for all $n \geq 3$ or $m \geq 3$.
    Both rules fail score-representation for all $m\geq 2$ and $n\geq 2$.
        \end{enumerate}
\end{theorem}
\begin{proof} We prove each of the claims separately.\bigskip

\textbf{Claim 1}: Consider an instance $\mathcal{I}$, and fix a candidate $c_j$ and a value $\gamma\in [0,1]$. We need to show that $x_j\geq \gamma\cdot \frac{\mathcal{N}(\mathcal{I}, c_j, \gamma)}{n}$ for the vector $\mathbf{x}$ chosen by \avg{}. For this, let $S:=\{i\in N\colon s_{i,j}\geq \gamma\}$ denote the set of agents that report a score of at least $\gamma$ for $c_j$. It holds that $x_j=\frac{1}{n}\sum_{i\in N} s_{i,j}\geq \frac{1}{n}\sum_{i\in S} s_{i,j} \geq \gamma \cdot \frac{\mathcal{N}(\mathcal{I}, c_j, \gamma)}{n}$, which shows that \avg{} satisfies score-representation.\bigskip

\textbf{Claim 2}: First, it was shown by \citet{freeman2021truthfulbudget} that \im{} satisfies single-minded proportionality. Next, we show that \im{} also satisfies score-representation if $m=2$. To this end, consider an instance~$\mathI$ and assume for contradiction that the outcome $\mathbf{x}$ of \im{} fails score-representation. Without loss of generality, suppose that there exists $\gamma\in [0,1]$ such that $x_1<\gamma\cdot \frac{\mathcal{N}(\mathI, c_1, \gamma)}{n}$. Clearly, this means that $\gamma>x_1$. Now, consider the instance $\mathI'$ such that all agents with $s_{i,1}>x_1$ report $s_{i,1}'=1$. It holds for the modified instance $\mathI'$ still that $x_1'=x_1$ because increasing the score of $c_1$ for agents with $s_{i,1}>x_1$ (and simultaneously decreasing the score of $c_2$ for agents with $s_{i,2}<x_2$) does not change the position of the medians. Since $\gamma>x_1$, we have that $x_1<\gamma\cdot \frac{\mathcal{N}(\mathI, c_1, \gamma)}{n}\leq \frac{\mathcal{N}(\mathI', c_1, 1)}{n}$. Next, let $\mathI''$ denote the instance derived from $\mathI'$ by setting $s_{i,1}''=0$ for all agents $i\in N$ with $s_{i,1}\leq x_1$. Since \im{} is known to be score-monotone \citep[see][Thm.~3]{freeman2021truthfulbudget}, it follows that $x_1''\leq x_1'$. Moreover, it holds that $\mathcal{N}(\mathI', c_1, 1)=\mathcal{N}(\mathI'',c_1,1)$, so we can again infer that $x_1''< \frac{\mathcal{N}(\mathI'', c_1, 1)}{n}$. However, in $\mathI''$, all agents are single-minded, so $x_1''= \frac{\mathcal{N}(\mathI'', c_1, 1)}{n}$ because \im{} satisfies single-minded proportionality. This yields the desired contradiction, which means that \im{} satisfies score-representation for $m=2$. 

Finally, to show that \im{} fails score-representation for all $m\geq 3$ and $n\geq 2$, it suffices to consider the instance $\mathI^5$ in the proof of \Cref{thm:efficiencyprops}. In this instance, all agents assign probability $\frac{n+1}{n+2}$ to $c_1$, but \im{} only assigns a probability of $\frac{n}{n+2}$ to this candidate, so score-representation is violated.\bigskip


\textbf{Claim 3}: We consider \maxrule{} and \util{} separately.\medskip

    \emph{\maxrule{}}:
    We first prove that \maxrule{} satisfies score-representation when $n=m=2$. Consider an instance $\mathI$ and assume without loss of generality that $s_{1,1} \geq s_{2,1}$ and $s_{2,2} \geq s_{1,2}$.
    Then, score-representation demands that \emph{(i)} $x_1 \geq \frac{s_{1,1}}{2}$ and $x_2 \geq \frac{s_{2,2}}{2}$, and \emph{(ii)} $x_1 \geq s_{2,1}$ and $x_2 \geq s_{1,2}$.
    Property \emph{(ii)} follows from the fact that \maxrule{} is range-respecting when $m=2$ (see \Cref{thm:efficiencyprops}). On the other hand, $x_1= \frac{s_{1,1}}{s_{1,1} + s_{2,2}}\geq \frac{s_{1,1}}{2}$ and $x_2= \frac{s_{2,2}}{s_{1,1} + s_{2,2}}\geq \frac{s_{2,2}}{2}$ since $s_{i,j}\leq 1$ for all $i\in N$, $j\in [m]$. This demonstrates that \emph{(i)} also holds.

    Next, we show that \maxrule{} satisfies single-minded proportionality for $n=2$ and $m \geq 3$. Let $\mathI$ denote an instance where both agents are single-minded. If both agents put probability $1$ on the same candidate, then \maxrule{} puts probability $1$ on this candidate, too. If the two agents put probability~$1$ on different candidates, both of these candidates receive a probability of $\frac{1}{2}$ from \maxrule{}. In both cases, \maxrule{} satisfies single-minded proportionality. 

    To show that \maxrule{} fails score-representation when $n\geq 2$ and $m\geq 3$, it is sufficient to consider our counterexample showing that it fails score-unanimity (instance $\mathcal{I}^4$ in the proof of \Cref{thm:efficiencyprops}). In this instance, all agents assign probability $\frac{1}{4}$ to candidate $c_1$, but \maxrule{} only assigns probability $\frac{1}{5}$ to this candidate. We now show that \maxrule{} fails single-minded proportionality if $m\geq 2$ and $n\geq 3$. Consider the following instance $\mathI^1$ (where $s_{i,j}=0$ for all $j\geq 3$ and $i\in N$). In this instance, \maxrule{} assigns probability $\frac{1}{2}$ to both $c_1$ and $c_2$, but single-minded proportionality requires that $x_2=\frac{n-1}{n} > \frac{1}{2}$. 

    \begin{center}
        \begin{tabular}{ c | c c}
          $\mathcal{I}^1$ & $s_{i,1}$ & $s_{i,2}$ \\
         \hline \hline
         1 & $1$ & $0$ \\ 
         $i\in \{2,\dots, n\}$ & $0$ & $1$ 
        \end{tabular}       
    \end{center}\smallskip

    \emph{\util{}}: We first show that \util{} satisfies score-representation when $n=m=2$ and thus consider an instance $\mathI$. Just as for \maxrule{}, we assume that $s_{1,1} \geq s_{2,1}$ and $s_{2,2} \geq s_{1,2}$, and we will prove that \emph{(i)} $x_1 \geq \frac{s_{1,1}}{2}$ and $x_2 \geq \frac{s_{2,2}}{2}$, and \emph{(ii)} $x_1 \geq s_{2,1}$ and $x_2 \geq s_{1,2}$. Property \emph{(ii)} follows immediately as \util{} is Pareto-optimal and therefore also range-respecting. As for \emph{(i)}, if $s_{1,1}\geq \frac{1}{2}\geq s_{1,2}$ and $s_{2,2}\geq \frac{1}{2}\geq s_{2,1}$, then \util{} will pick the vector $(\frac{1}{2},\frac{1}{2})$ and score-representation is satisfied. Now, if $s_{1,1}<\frac{1}{2}$, then also $s_{2,1}<\frac{1}{2}$ since $s_{2,1}\leq s_{1,1}$. In this case, \util{} will choose the outcome $(s_{1,1}, s_{1,2})$, for which it holds that $x_1\geq \frac{s_{1,1}}{2}$ and $x_2 \geq \frac{s_{2,2}}{2}$ since $x_2=s_{1,2}>\frac{1}{2}$. Lastly, if $s_{2,2}<\frac{1}{2}$, a symmetric argument applies, so \util{} indeed satisfies score-representation if $n=m=2$. 
    
    Next, an analogous argument to that for \maxrule{} shows that \util{} satisfies single-minded proportionality when $n=2$. 

    Finally, we prove that \util{} fails score-representation when $m\geq 3$ and $n\geq 2$, and single-minded proportionality when $n\geq 3$. For the latter, it suffices to consider the instance $\mathI^1$ shown for \maxrule{}. In this instance, \util{} will assign probability $1$ to $c_2$, which violates single-minded proportionality as $c_1$ deserves probability $\frac{1}{n}$. It remains to show that \util{} fails score-representation when $n=2$ and $m\geq 3$.
    To this end, consider the following instance $\mathI^2$, where \util{} chooses the vector $(\frac{1}{3},\frac{1}{3},\frac{1}{3})$. This vector fails score-representation since the axiom requires $x_1$ to be at least $\frac{1}{2}$. As usual, the counterexample can be extended to larger $m$ by adding candidates that receive probability $0$ from all agents.
    \begin{center}
        \begin{tabular}{ c | c c c c }
          $\mathcal{I}^2$ & $s_{i,1}$ & $s_{i,2}$ & $s_{i,3}$ \\ 
         \hline \hline
         $1$ & $1$ & $0$ & $0$\\ 
         $2$ & $\frac{1}{3}$ & $\frac{1}{3}$ & $\frac{1}{3}$
        \end{tabular}       
    \end{center}\smallskip

    \textbf{Claim 4}: We note that if $n=2$, then \med{}{} and \egal{} coincide with \avg{}, so they satisfy score-representation in this case due to Claim~1. By contrast, if $n\geq 3$, we consider the instance $\mathI^1$ used to show that \maxrule{} fails single-minded proportionality.
    For this instance, \med{} returns the outcome $\mathbf{x}=(0,1)$ while \egal{} returns the outcome $\mathbf{x}=(\frac{1}{2}, \frac{1}{2})$.
    Both of these outcomes fail single-minded proportionality.\bigskip

\textbf{Claim 5}: 
    We first prove that \minrule{} and \geo{} satisfy single-minded proportionality when $n=m=2$. There are two cases to consider.
    If both agents give a score of $1$ to the same candidate, it will be assigned a score of $1$ by both rules. On the other hand, if both agents give a score of $1$ to different candidates, then both rules return $\mathbf{x} = (\frac{1}{2}, \frac{1}{2})$, which also satisfies single-minded proportionality.

    To see that \minrule{} and \geo{} fail single-minded proportionality for the case where $n\geq 3$ or $m\geq 3$, we again consider the instance $\mathI^1$ used to show that \maxrule{} fails single-minded proportionality (recall that all candidates $c_j$ with $j\geq 3$ receive probability $0$ from all agents). 
    In this instance, both rules assign probability $\frac{1}{m}$ to all candidates, which fails single-minded proportionality unless $m=n=2$.
    Finally, to see that these rules also fail score-representation for the case $n=m=2$, consider the instance $\mathI$ with $\mathbf{s}_1 = (1,0)$ and $\mathbf{s}_2 = (\frac{1}{2},\frac{1}{2})$. 
    Then, score-representation mandates that $x_2 \geq \frac{1}{4}$, but both rules return $\mathbf{x} = (1,0)$.
\end{proof}

\begin{remark}
    In the instance used for showing that \minrule{} and \geo{} fail single-minded proportionality, it holds that $\min_{i\in N} s_{i,j}=0$ for all $j\in [m]$. This is unavoidable due the definition of single-minded proportionality. Because $\min_{i\in N} s_{i,j}=0$ for all $j\in [m]$, both rules assign a probability of $\frac{1}{m}$ to every candidate as we defined that $\frac{0}{0}=\frac{1}{m}$. However, note that single-minded proportionality will be violated regardless of how we define $\frac{0}{0}$, so it is still true that our negative results do not depend on this particular assumption. 
\end{remark}

\section{Consistency Properties}

In this section, we analyze our aggregation rules with respect to various consistency notions. In particular, we will show that score-monotonicity and reinforcement are satisfied by almost all of our rules, whereas \avg{} is the only one that fulfills independence. We note that \citet{freeman2021truthfulbudget} have already shown that \im{} and \util{} satisfy reinforcement and score-monotonicity. 

\begin{theorem}\label{thm:consistencyprops}
The following claims hold. 
    \begin{enumerate}[label=(\arabic*),topsep=4pt,itemsep=0pt]
    \item \avg{} satisfies independence. \med{} and \egal{} satisfy independence when $m=2$ or $n=2$ but fail this condition for all $m\geq 3$ and $n\geq 3$. 
        \maxrule{}, \minrule{}, \geo{}, \util{}, and \im{} satisfy independence when $m=2$ but fail to do so for all $m\geq 3$ and $n\geq 2$.
        \item All five coordinate-wise aggregation rules, \util{}, and \im{} satisfy score-monotonicity. \egal{} is score-monotone when $m=2$ or $n=2$ but fails to be so for all $m \geq 4$ and $n \geq 4$.
        \item \avg{}, \minrule{}, \maxrule{}, and \geo{} as well as \util{}, \egal{}, and \im{} satisfy reinforcement. \med{} satisfies reinforcement when $m=2$ but fails to do so for all $m \geq 3$. 
    \end{enumerate}
\end{theorem}

We remark that while the bounds on $m$ and $n$ are tight for almost all results in our paper, it remains open whether \egal{} satisfies score-monotonicity when $m=3$ or $n=3$.

\begin{proof}
    We prove each of the claims separately.\bigskip

    \textbf{Claim 1}: We consider independence and first note that this axiom is trivial when $m=2$: if $s_{i,j}=s_{i,j}'$ for some candidate $c_j$ and all $i\in N$, then $\mathI=\mathI'$, which means that every aggregation rule $F$ satisfies independence. Moreover, if $n=2$, then \med{} and \egal{} coincide per definition with \avg{}. Hence, all of our positive claims follow by showing that \avg{} satisfies independence. We show this next and then explain why the other rules fail independence for the given values of $m$ and $n$.\bigskip

\emph{\avg}: Consider two instances $\mathI$ and $\mathI'$ and a candidate $c_{j^*}$ such that $s_{i,j^*}=s'_{i,j^*}$ for all $i\in N$. This clearly means that $\frac{1}{n} \sum_{i\in N} s_{i,j^*}=\frac{1}{n} \sum_{i\in N} s_{i,j^*}'$. Moreover, it holds that $\sum_{j\in [m]} \left(\frac{1}{n} \sum_{i\in N} s_{i,j}\right)=\frac{1}{n}\sum_{i\in N}\sum_{j\in [m]} s_{i,j}=1$ and $\sum_{j\in [m]} \left(\frac{1}{n} \sum_{i\in N} s_{i,j}'\right)=\frac{1}{n}\sum_{i\in N}\sum_{j\in [m]} s_{i,j}'=1$. This implies that \avg{} returns the same outcome for $c_j$ in $\mathI$ and $\mathI'$.\bigskip

\emph{\maxrule{}, \minrule{}, \geo{}, and \im{}}: To show that all of these rules fail independence, we observe that they satisfy score-unanimity in the special case where there are constants $\gamma_j$ for $j\in [m]$ such that $s_{i,j}=\gamma_j$ for all $j\in [m]$ and $i \in N$. However, since \maxrule{}, \minrule{}, \geo{}, and \im{} fail score-unanimity in general when $m\geq 3$ and $n\geq 2$ (see \Cref{thm:efficiencyprops}), this immediately means that independence is violated for these cases.\bigskip

\emph{\util{}}: First, if $m\geq 3$ and $n\geq 3$ is odd, consider the following instances $\mathI$ and $\mathI'$: in $\mathI$, $\frac{n-1}{2}$ agents assign probability $1$ to $c_1$, $\frac{n-1}{2}$ agents assign probability $1$ to $c_2$, and $1$ agent assigns probability $1$ to $c_3$. In $\mathI'$, the same agents assign probability $1$ to $c_1$ as in $\mathI$, but all remaining agents assign probability $1$ to $c_2$. 
If $n = 3$, then $\mathbf{x} = (\frac{1}{3}, \frac{1}{3}, \frac{1}{3})$, while if $n\ge 5$, then $\mathbf{x}=(\frac{1}{2}, \frac{1}{2}, 0)$.
On the other hand, $\mathbf{x}'=(0, 1, 0)$, thus showing that independence fails for $c_1$. 

Next, if $m\geq 3$ and $n\geq 4$ is even, we consider the instance $\mathI$, where $\frac{n}{2}$ agents assign probability~$1$ to $c_1$, $\frac{n}{2}-1$ agents assign probability $1$ to $c_2$, and $1$ agent assigns probability $1$ to $c_3$, and $\mathI'$, where the same $\frac{n}{2}$ as in $\mathI$ assign probability $1$ to $c_1$ and the other $\frac{n}{2}$ agents assign probability $1$ to $c_2$. $\util$ put probability $1$ on $c_1$ in $\mathI$, but probability $\frac{1}{2}$ on both $c_1$ and $c_2$ in $\mathI'$, so independence is violated for $c_1$. 

Finally, if $n=2$ and $m\ge 3$, we consider the instance $\mathI$, where agent $1$ puts probability $1$ on $c_1$ and agent $2$ put probability $1$ on $c_2$, and $\mathI'$, where agent $1$ still puts probability $1$ on $c_1$ but agent $2$ puts probability $\frac{1}{2}$ on both $c_2$ and $c_3$. 
\util{} assigns a probability of $\frac{1}{2}$ to both $c_1$ and $c_2$ in $\mathI$, and a probability of $\frac{1}{3}$ to each of $c_1$, $c_2$, and $c_3$ in $\mathI'$ due to the maximum entropy tie-breaking. Hence, we have again that independence is violated for $c_1$.\bigskip

\emph{\egal{}}: To show that \egal{} fails independence for all $m\geq 3$ and $n\geq 3$, we consider the instances $\mathI$ and $\mathI'$ defined as follows: in $\mathI$, agent $1$ assigns probability $1$ to $c_1$, agent $2$ assigns probability $1$ to $c_2$, and every other agent assigns probability $1$ to $c_3$. Furthermore, in $\mathI'$, agent $1$ assigns probability $1$ to $c_1$ and every other agent assigns probability $1$ to $c_2$. It is easy to check that \egal{} chooses the outcome $\mathbf{x}=(\frac{1}{3}, \frac{1}{3},\frac{1}{3})$ for $\mathI$ and the outcome $\mathbf{x}'=(\frac{1}{2}, \frac{1}{2},0)$ for $\mathI'$, thus showing that independence is violated for $c_1$. As usual, we can extend the instances to larger $m$ by adding candidates that are unanimously assigned probability $0$.\bigskip

\emph{\med{}}: Finally, we turn to \med{} and consider the following instances $\mathI^1$ and $\mathI^2$, where $s_{i,j}^1=s_{i,j}^2=0$ for all $j\geq 4$ and $i\in N$. It holds that $\text{med}_{i\in N} s_{i,1}^1=\frac{1}{2}$, $\text{med}_{i\in N} s_{i,2}^1=\frac{1}{2}$ if $n$ is odd and $\text{med}_{i\in N} s_{i,2}^1=\frac{1}{4}$ if $n$ is even, and $\text{med}_{i\in N} s_{i,3}^1=\frac{1}{2}$. This means that \med{} assigns a probability of less than $\frac{1}{2}$ to $c_1$ in $\mathI$. By contrast, in $\mathI^2$, the medians are $\text{med}_{i\in N} s_{i,1}^2=\frac{1}{2}$, $\text{med}_{i\in N} s_{i,2}^2=0$, and $\text{med}_{i\in N} s_{i,3}^2=\frac{1}{2}$. Hence, \med{} assigns a probability of $\frac{1}{2}$ to $c_1$ in this instance, and independence is violated. 
\begin{center}
    \begin{tabular}{ c | c c c}
          $\mathcal{I}^1$ & $s_{i,1}$ & $s_{i,2}$ & $s_{i,3}$\\ 
         \hline \hline
         $1$ & $\frac{1}{2}$ & $\frac{1}{2}$ & $0$\\
         $i\in \{2,\dots, \lceil\frac{n+1}{2}\rceil\}$ & $\frac{1}{2}$ & $0$ & $\frac{1}{2}$\\
         $i\in \{\lceil\frac{n+1}{2}\rceil+1,\dots, n\}$ & $0$ & $\frac{1}{2}$ & $\frac{1}{2}$ \\
        \end{tabular}   
    \qquad\qquad
    \begin{tabular}{ c | c c c}
          $\mathcal{I}^2$ & $s_{i,1}$ & $s_{i,2}$ & $s_{i,3}$\\ 
         \hline \hline
         $1$ & $\frac{1}{2}$ & $0$ & $\frac{1}{2}$ \\
         $i\in \{2,\dots, \lceil\frac{n+1}{2}\rceil\}$ & $\frac{1}{2}$ & $0$ & $\frac{1}{2}$\\
         $i\in \{\lceil\frac{n+1}{2}\rceil+1,\dots, n\}$ & $0$ & $\frac{1}{2}$ & $\frac{1}{2}$ \\
        \end{tabular}   
    \end{center}\medskip

    \textbf{Claim 2}: We first note that Theorem 3 of \citet{freeman2021truthfulbudget} shows that \im{} and \util{} are score-monotone. We next deal with the coordinate-wise aggregation rules and \egal{} separately.\medskip
    
    \emph{Coordinate-wise aggregation rules}: To show that our five coordinate-wise aggregation rules satisfy score-monotonicity, we first prove a more general auxiliary claim: a coordinate-wise aggregation rule $F$ is score-monotone if all coordinate-aggregation functions $f_j$ satisfy that $f_j(s_{1,j}, \dots, s_{i,j},\dots, s_{n,j})\geq f_j(s_{1,j}, \dots, s_{i,j}',\dots, s_{n,j})$ for all candidates $c_j\in C$ and scores $s_{1,j},\dots, s_{n,j}, s_{i,j}'$ such that $s_{i,j}\geq s_{i,j}'$. 
    To see this, consider two instances $\mathcal{I}$ and $\mathcal{I'}$, an agent $i\in N$, and a candidate $c_j$ such that $\mathbf{s}_{i'}=\mathbf{s}'_{i'}$ for all $i'\in N\setminus \{i\}$, $s_{i,j}> s_{i,j}'$, and $s_{i,j'}\leq s_{i,j'}'$ for all $c_{j'}\in C\setminus \{c_j\}$. For ease of presentation, we will slightly abuse notation and write $f_\ell(\mathI)$ to mean $f_\ell(s_{1,\ell}, \dots, s_{n,\ell})$. 
    
    We first consider the case that $f_{j'}(\mathI)=0$ for all $j'\in [m]$ or that $f_{j'}(\mathI')=0$ for all $j'\in [m]$. If $f_{j'}(\mathI)=f_{j'}(\mathI')=0$ for all $j'\in [m]$, then $F(\mathI)_j=F(\mathI')_j=\frac{1}{m}$ by definition and score-monotonicity holds. 
    Next, if $f_{j'}(\mathI)=0$ for all $j'\in [m]$ but there is some $\ell$ with $f_{\ell}(\mathI')>0$, then $\ell\neq j$ because $s_{i,j}>s_{i,j}'$ implies that $f_{j}(\mathI)\geq f_{j}(\mathI')$. Hence, we have in this case that $F(\mathI)_j=\frac{1}{m}>0=F(\mathI')_j$ and score-monotonicity holds. As the third case, assume that $f_{j'}(\mathI')=0$ for all $j'\in [m]$ but there is some $\ell$ with $f_{\ell}(\mathI)>0$. Since $f_{j'}(\mathI)\leq f_{j'}(\mathI')$ for all $j'\in [m]\setminus \{j\}$, it must be that $\ell=j$. This implies that $F(\mathI)_j=1>\frac{1}{m}=F(\mathI')_j$ and score-monotonicity holds again. As the last case, suppose that neither $f_{j'}(\mathI)=0$ for all $j'\in [m]$ nor $f_{j'}(\mathI')=0$ for all $j'\in [m]$. Our assumptions imply that $f_j(\mathI)\geq f_j(\mathI')$ and $f_{j'}(\mathI)\leq f_{j'}(\mathI')$ for all $j'\in [m]\setminus \{j\}$.
    It follows that
    \begin{align*}
        F(\mathI)_j=\frac{f_j(\mathI)}{\sum_{j'\in [m]} f_{j'}(\mathI)}\geq \frac{f_j(\mathI')}{f_j(\mathI')+\sum_{j'\in [m]\setminus \{j\}} f_{j'}(\mathI)}\geq \frac{f_j(\mathI')}{\sum_{j'\in [m]} f_{j'}(\mathI')}=F(\mathI')_j.
    \end{align*}

    This shows that our condition indeed implies score-monotonicity. Finally, for each of \avg{}, \maxrule{}, \minrule{}, \geo{}, and \med{}, it is easy to verify that $f_j(s_{1,j}, \dots, s_{i,j},\dots, s_{n,j})\geq f_j(s_{1,j}, \dots, s_{i,j}',\dots, s_{n,j})$ for all $j\in [m]$ and $s_{i,j}$, $s_{i,j}'$ with $s_{i,j}\geq s_{i,j}'$, so these rules are indeed score-monotone.\bigskip

    \emph{\egal{}}:
    $\,$When $n=2$, \egal{} is equivalent to \avg{} (by Proposition~\ref{prop:welfare-egal_is_sum}), for which we have just shown that it satisfies score-monotonicity.
    Thus, we only consider the case $m=2$ and assume that $n\ge 3$. 
    Let $\mathcal{I}$ and $\mathcal{I}'$ denote instances such that $\mathcal{I}'$ is identical to $\mathcal{I}$ except that $s_{i,1} < s'_{i,1}$ and $s_{i,2}  > s'_{i,2}$ for some agent $i\in N$.
    Moreover, suppose that $\mathbf{x}$ and $\mathbf{x}'$ are the outcome vectors returned by \egal{} for instances $\mathcal{I}$ and $\mathcal{I}'$, respectively. Without loss of generality, we assume that the agents in  $\mathcal{I}$ are ordered such that $s_{1,1} \leq \dots \leq s_{n,1}$ and $s_{1,2} \geq \dots \geq s_{n,2}$.
    Then, \egal{} will return $\mathbf{x} = \left(\frac{s_{1,1} + s_{n,1}}{2}, \frac{s_{n,2} + s_{1,2}}{2} \right)$.
    For the instance $\mathcal{I}'$, we have $\min_{i\in N}s'_{i,1} \ge s_{1,1}$ and $\max_{i\in N}s'_{i,1} \ge s_{n,1}$.
    So $x_1 = \frac{s_{1,1}+s_{n,1}}{2} \le \frac{\min_{i\in N}s'_{i,1}+\max_{i\in N}s'_{i,1}}{2} = x'_1$, which means that score-monotonicity is satisfied.    

    Next, we prove that when $m\geq 4$ and $n\geq 4$, \egal{} fails score-monotonicity. As usual, we will show our counterexample only for $m=4$ candidates as it is straightforward to add dummy candidates. Moreover, we focus on the case $n=4$ as \egal{} is invariant under duplicating agents. 
    Now, consider the following two instances $\mathcal{I}^3$ and $\mathcal{I}^4$ with their respective \egal{} outcomes $\mathbf{x}^3$ and $\mathbf{x}^4$. In $\mathcal{I}^3$, all agents get disutility $1$ under $\mathbf{x}^3$. Thus, to show that \egal{} indeed returns $\mathbf{x}^3$, it suffices to show that any other outcome would increase the disutility of at least one agent. If the share of the first alternative decreases, agent $1$ would be worse off. Similarly, if $x^3_4$ decreases, agent $3$ or $4$ would be worse off, so $\mathbf{x}^3$ is returned in $\mathcal{I}^3$. Turning to $\mathcal{I}^4$, note that $d_i(\mathbf{x}^4)=4/5$ for all agents $i$.
    For any distribution $\mathbf{x}$ with $d_1(\mathbf{x}) \leq 4/5$, we have $x_1+x_4 \geq 3/5$. Analogously, we get $x_2+x_4 \geq 3/5$ and $x_3+x_4 \geq 3/5$ from agents $3$ and $4$, respectively. Summing up these three inequalities and using the fact that $\mathbf{x}$ is a distribution shows that $x_4 \geq 2/5$. 
    If $x_4 > 2/5$ then $d_2(\mathbf{x})>4/5$, so in order to have $d_2(\mathbf{x})\le 4/5$, we must have $x_4=2/5$. By the first three inequalities, the remaining probability of $3/5$ needs to be distributed uniformly over the first three alternatives, leading to $\mathbf{x}=\mathbf{x}^4$. 
    Hence, $\mathbf{x}^4$ is indeed returned in $\mathcal{I}^4$.
    
    We see that $x_4^3=\frac{1}{2}>\frac{2}{5}=x_4^4$ despite the fact that $s_{1,4}^3<s_{1,4}^4$. It follows that score-monotonicity is violated.
    
    \begin{center}
        \begin{tabular}{ c | c c c c c}
          $\mathcal{I}^3$ & $s_{i,1}$ & $s_{i,2}$ & $s_{i,3}$ & $s_{i,4}$  \\ 
         \hline \hline
         $1$ & $1$ & $0$ & $0$ & $0$ \\ 
         $2$ & $\frac{1}{2}$ & $\frac{1}{4}$ & $\frac{1}{4}$ &  $0$  \\ 
         $3$ & $0$ & $\frac{1}{2}$ & $0$ & $\frac{1}{2}$  \\ 
         $4$ & $0$ & $0$ & $\frac{1}{2}$ & $\frac{1}{2}$  \\ 
         \hline
         $\mathbf{x}^3$ & $\frac{1}{2}$ & 0 & 0 & $\frac{1}{2}$ \\ 
        \end{tabular}
        \qquad\qquad
        \begin{tabular}{ c | c c c c c}
          $\mathcal{I}^4$ & $s_{i,1}$ & $s_{i,2}$ & $s_{i,3}$ & $s_{i,4}$  \\ 
         \hline \hline
         $1$ & $\frac{1}{2}$ & $0$ & $0$ & $\frac{1}{2}$  \\ 
         $2$ & $\frac{1}{2}$ & $\frac{1}{4}$ & $\frac{1}{4}$ &  $0$   \\ 
         $3$ & $0$ & $\frac{1}{2}$ & $0$ & $\frac{1}{2}$   \\ 
         $4$ & $0$ & $0$ & $\frac{1}{2}$ & $\frac{1}{2}$   \\ 
         \hline
         $\mathbf{x}^4$ & $\frac{1}{5}$ & $\frac{1}{5}$ & $\frac{1}{5}$ & $\frac{2}{5}$ \\ 
        \end{tabular}
    \end{center}\smallskip

    \textbf{Claim 3}: We next show that among all the rules considered in this paper, only \med{} fails reinforcement. For this, we first note that \citet[Thms.~9 and 13]{freeman2021truthfulbudget} have shown that \im{} and \util{} satisfy reinforcement. We hence focus on the remaining rules and consider three instances $\mathI=(\mathbf{s}_1,\dots, \mathbf{s}_n)$ (defined for the electorate $N$), $\mathI'=(\mathbf{s}_1',\dots, \mathbf{s}_{n'}')$ (defined for the electorate $N'$), and $\mathI''=(\mathbf{s}_1,\dots, \mathbf{s}_n, \mathbf{s}_1',\dots, \mathbf{s}_{n'}')$ (defined for the electorate $N\cup N'$; we suppose that $N\cap N'=\emptyset$). We consider each rule separately.\bigskip

     \emph{\avg}: Suppose that $\mathbf{x}$, $\mathbf{x}'$, and $\mathbf{x}''$ are the outcomes chosen by \avg{} for $\mathI$, $\mathI'$, and $\mathI''$, respectively. We observe that $\sum_{j\in [m]} \left(\frac{1}{|N|}\sum_{i\in N} s_{i,j}\right)=\sum_{j\in [m]} \left(\frac{1}{|N'|}\sum_{i\in N'} s_{i,j}'\right)=1$. Hence, if $x_j=x_j'$ for some $j\in [m]$, then $\frac{1}{|N|}\sum_{i\in N} s_{i,j}=\frac{1}{|N'|}\sum_{i\in N'} s_{i,j}'$. Consequently, 
     \begin{align*}
         x_j''=\frac{1}{|N\cup N'|} \sum_{i\in N\cup N'} s_{i,j}''=\frac{|N|}{|N\cup N'|}\cdot \frac{1}{|N|} \sum_{i\in N} s_{i,j} + \frac{|N'|}{|N\cup N'|}\cdot \frac{1}{|N'|} \sum_{i\in N'} s_{i,j}'=x_j,
     \end{align*}
     which shows that reinforcement is satisfied.\bigskip

     \emph{\maxrule{}}: Let $\mathbf{x}$, $\mathbf{x}'$, and $\mathbf{x}''$ denote the outcomes chosen by \maxrule{} for the respective instances and assume that $\mathbf{x}=\mathbf{x}'$. This means that there is a constant $\alpha>0$ such that $\max_{i\in N} s_{i,j}=\alpha \cdot \max_{i\in N'} s_{i,j}'$ for all $j\in [m]$. Moreover, we assume that $\alpha\geq 1$; otherwise we can exchange the roles of $\mathbf{x}$ and $\mathbf{x'}$. Consequently, $\max_{i\in N\cup N'} s_{i,j}''=\max_{i\in N} s_{i,j}$ for all $j\in [m]$, which shows that $\mathbf{x}''=\mathbf{x}$.\bigskip

     \emph{\minrule{}}: Denote by $\mathbf{x}$, $\mathbf{x}'$, and $\mathbf{x}''$ the outcomes chosen by \minrule{} for the respective instances and assume that $\mathbf{x}=\mathbf{x}'$. First, if $\min_{i\in N} s_{i,j}=0$ for all $j\in [m]$ or $\min_{i\in N'} s_{i,j}'=0$ for all $j\in [m]$, then $\min_{i\in N\cup N'} s_{i,j}''=0$ for all $j\in [m]$ and $x_j''=\frac{1}{m}=x_j=x_j'$ for all $j\in [m]$. Next, assume that $\min_{i\in N} s_{i,j}>0$ and $\min_{i\in N'} s_{i,j'}'>0$ for some $j,j'\in [m]$. Then, $\mathbf{x}=\mathbf{x}'$ implies that there is a constant $\alpha>0$ such that $\min_{i\in N} s_{i,j}=\alpha \cdot \min_{i\in N'} s_{i,j}'$ for all $j\in[m]$. We assume without loss of generality that $\alpha\leq 1$ as we can otherwise exchange the roles of $\mathbf{x}$ and $\mathbf{x}'$ in our argument. This assumption means that $\min_{i\in N} s_{i,j}\leq \min_{i\in N'} s_{i,j}'$ for all $j\in [m]$ and hence $\min_{i\in N\cup N'} s_{i,j}''=\min_{i\in N} s_{i,j}$ for all $j\in [m]$. This proves that $\mathbf{x}''=\mathbf{x}$ and \minrule{} therefore satisfies reinforcement.\bigskip

     \emph{\geo{}}: Define $\mathbf{x}$, $\mathbf{x}'$, and $\mathbf{x}''$ as the outcomes selected by \geo{} for the respective instances and assume that $\mathbf{x}=\mathbf{x}'$. If $\min_{i\in N} s_{i,j}=0$ for all $j\in [m]$ or $\min_{i\in N'} s_{i,j}'=0$ for all $j\in [m]$, the same holds for $\mathI''$ and we derive that $x''_j=\frac{1}{m}=x_j=x_j'$ for all $j\in [m]$. Hence,  suppose that there are indices $j,j'\in [m]$ such that $\min_{i\in N} s_{i,j}>0$ and $\min_{i\in N} s'_{i,j'}>0$. Next, we define $Z(\mathI)=\sum_{j\in [m]} (\prod_{i\in N} s_{i,j})^{1/|N|}$ and $Z(\mathI')=\sum_{j\in [m]} (\prod_{i\in N'} s_{i,j}')^{1/|N'|}$. For each $j\in [m]$, we have that 
     \begin{align*}
         \left(\prod_{i\in N\cup N'} s_{i,j}''\right)^{\frac{1}{|N|+|N'|}}&=\left(\prod_{i\in N} s_{i,j}\cdot \prod_{i\in N'}s_{i,j}' \right)^{\frac{1}{|N|+|N'|}} \\
         &= \left((x_j\cdot Z(\mathI))^{|N|}\cdot (x_j'\cdot Z(\mathI'))^{|N'|}\right)^{\frac{1}{|N|+|N'|}}\\
         &=x_j\cdot \left(Z(\mathI)^{|N|}\cdot Z(\mathI')^{|N'|}\right)
         ^{\frac{1}{|N|+|N'|}}.
     \end{align*}
     Since this holds for all $j\in [m]$, \geo{} satisfies reinforcement because
     \begin{align*}
         x_j''=\frac{x_j\cdot \left(Z(\mathI)^{|N|}\cdot Z(\mathI')^{|N'|}\right)^{\frac{1}{|N|+|N'|}}
         }{\sum_{j'\in [m]} \left(x_{j'}\cdot\left(Z(\mathI)^{|N|}\cdot Z(\mathI')^{|N'|}\right)
         ^{\frac{1}{|N|+|N'|}}\right)}=x_j.
     \end{align*}

     \emph{\egal{}}: Let $\mathbf{x}$, $\mathbf{x}'$, and $\mathbf{x}''$ denote the outcomes chosen by \egal{} for $\mathI$, $\mathI'$, and $\mathI''$, respectively. Assume for contradiction that $\mathbf{x}=\mathbf{x'}$ but $\mathbf{x}''\neq \mathbf{x}$. For a set of agents $T$, we define $v_T(\mathbf{y})$ as the vector that states the disutilities of all agents $i\in X$ for the outcome $\mathbf{y}$ in non-increasing order. Moreover, we write $v>_\mathit{lex} v'$ if there is an integer $k$ such that $v_{\ell}=v'_\ell$ for all $\ell\in [k-1]$ and $v_{k}>v_{k}'$. Since $\mathbf{x}=\mathbf{x'}$ is chosen for $\mathI$ and $\mathI'$, we get that $v_N(\mathbf{x})<_\mathit{lex} v_N(\mathbf{x''})$ or $v_N(\mathbf{x})= v_N(\mathbf{x''})$, and $v_{N'}(\mathbf{x})<_\mathit{lex} v_{N'}(\mathbf{x''})$ or $v_{N'}(\mathbf{x})= v_{N'}(\mathbf{x''})$. On the other hand, $v_{N\cup N'}(\mathbf{x})>_\mathit{lex} v_{N\cup N'}(\mathbf{x''})$ or $v_{N\cup N'}(\mathbf{x})= v_{N\cup N'}(\mathbf{x''})$ as $\mathbf{x}''$ is chosen for $\mathI''$. It is easy to see that these conditions can only be true if $v_N(\mathbf{x})= v_N(\mathbf{x''})$ and $v_{N\cup N'}(\mathbf{x})= v_{N\cup N'}(\mathbf{x''})$. However, consistent tie-breaking requires that if \egal{} returns $\mathbf{x}$ for $\mathI$, then $\mathbf{x}''$ is not chosen for $\mathI''$, which contradicts our assumptions. \bigskip

     \emph{\med{}}: Finally, we show that \med{} satisfies reinforcement if $m=2$ but fails this property when $m\geq 3$. First, assume that $m=2$ and let $\mathbf{x}$, $\mathbf{x}'$, and $\mathbf{x}''$ denote the outcomes chosen for our instances $\mathI$, $\mathI'$, and $\mathI''$. As usual, we assume that $\mathbf{x}=\mathbf{x}'$. Note that $\text{med}_{i\in N} s_{i,1}=1-\text{med}_{i\in N} s_{i,2}$ and $\text{med}_{i\in N'} s_{i,1}'=1-\text{med}_{i\in N'} s_{i,2}'$ as $m=2$, which implies that $\text{med}_{i\in N} s_{i,1}=x_1=x_1'=\text{med}_{i\in N'} s_{i,1}'$. We hence need to show that $\text{med}_{i\in N\cup N'} s_{i,1}''=\text{med}_{i\in N} s_{i,1}$. To this end, we make a case distinction with respect to the parity of $|N|$ and $|N|'$. First, if both $|N|$ and $|N'|$ are odd, there are at least $\frac{|N|+1}{2}$ agents $i\in N$ with $s_{i,1}\leq x_1$ and at least $\frac{|N|+1}{2}$ agents $i\in N$ with $s_{i,1}\geq x_1$. Similarly, there are at least $\frac{|N'|+1}{2}$ agents $i\in N'$ with $s'_{i',1}\leq x_1'=x_1$ and at least $\frac{|N'|+1}{2}$ agents $i\in N'$ with $s'_{i',1}\geq x_1'=x_1$. Thus, there are at least $\frac{|N|+|N'|}{2}+1$ agents $i\in N\cup N'$ with $s_{i,1}''\leq x_1$ and at least $\frac{|N|+|N'|}{2}+1$ agents $i\in N\cup N'$ with $s_{i,1}''\geq x_1$. This shows that $\text{med}_{i\in N\cup N'} s_{i,1}''=x_1$ and proves our claim. For the remaining cases, similar arguments show that the median does not change. In total, this means that 
$\text{med}_{i\in N\cup N'} s_{i,1}''=x_1$ (which also implies that $\text{med}_{i\in N\cup N'} s_{i,2}''=x_2$), so \med{} satisfies reinforcement if $m=2$. 

    Now, for the case $m\geq 3$, consider the following instances $\mathI^5$ (defined for an odd number of agents $n\geq 5$) and $\mathI^6$ (defined for a single agent $n+1$). All candidates but $c_1$, $c_2$, and $c_3$ receive probability~$0$ from all agents and can be ignored. It holds that $\text{med}_{i\in N} s_{i,1}^5=\frac{1}{2}$, $\text{med}_{i\in N} s_{i,2}^5=\frac{1}{3}$, and $\text{med}_{i\in N} s_{i,3}^5=\frac{1}{2}$, so \med{} returns the outcome $\mathbf{x}=(\frac{3}{8},\frac{2}{8}, \frac{3}{8})$ for $\mathI^5$. On the other hand, $\mathI^6$ consists of a single agent with preference $(\frac{3}{8},\frac{2}{8}, \frac{3}{8})$, so \med{} returns again this vector. However, when combining these two instances, our new medians are $\text{med}_{i\in N\cup \{n+1\}} s_{i,1}=\frac{1}{2}(\frac{1}{2}+\frac{3}{8})=\frac{7}{16}$, $\text{med}_{i\in N\cup \{n+1\}} s_{i,2}=\frac{1}{3}$, and $\text{med}_{i\in N\cup \{n+1\}} s_{i,3}=\frac{1}{2}(\frac{1}{2}+\frac{3}{8})=\frac{7}{16}$. This means that for the new outcome $\mathbf{x}'$, we have $x_1'=\frac{21}{58}<\frac{3}{8}$ and reinforcement is violated. 

\begin{center}
    \begin{tabular}{ c | c c c}
          $\mathcal{I}^5$ & $s_{i,1}$ & $s_{i,2}$ & $s_{i,3}$\\ 
         \hline \hline
         $i\in \{1,\dots, \frac{n-1}{2}\}$ & $\frac{2}{3}$ & $\frac{1}{3}$ & $0$ \\ 
         $i\in \{\frac{n+1}{2},\dots, n-1\}$ & $0$ & $\frac{1}{3}$ & $\frac{2}{3}$ \\
         $n$ & $\frac{1}{2}$ & $0$  & $\frac{1}{2}$ 
        \end{tabular}   
    \qquad\qquad
    \begin{tabular}{ c | c c c}
          $\mathcal{I}^6$ & $s_{i,1}$ & $s_{i,2}$ & $s_{i,3}$\\ 
         \hline \hline
         $n+1$ & $\frac{3}{8}$ & $\frac{2}{8}$ & $\frac{3}{8}$
        \end{tabular}   
    \end{center}
\bigskip This completes the proof. 
\end{proof}

\begin{remark}
    We do not specify the boundary on $n$ for which \med{} satisfies reinforcement. The reason for this is that reinforcement is a variable electorate property that is usually studied under the assumption that there is an infinite set of possible agents. The same reasoning will apply for participation in the next section. 
\end{remark}

\section{Incentive Properties}

As the last evaluation criteria for our rules, we study their incentive properties. To this end, we first note that \cite{freeman2021truthfulbudget} have shown that both \im{} and \util{} satisfy strategyproofness and participation. By contrast, we will show that none of our other rules is strategyproof, whereas all except for \med{} satisfy participation.

\begin{theorem}
    The following claims hold.
    \begin{enumerate}[label=(\arabic*),topsep=4pt,itemsep=0pt]
        \item \im{} and \util{} satisfy strategyproofness and participation.
        \item \avg{}, \maxrule{}, \minrule{}, \geo{}, and \egal{} fail strategyproofness for all $n \geq 2$ and $m \geq 2$ but satisfy participation. 
        \item \med{} satisfies strategyproofness when $m=2$ and $n$ is odd, but fails this property when $m=2$ and $n$ is even, or when $m\geq 3$. Moreover, \med{} satisfies participation if $m=2$ but fails it for all $m\geq 3$.
    \end{enumerate}
\end{theorem}
\begin{proof}
    Claim 1 directly follows from the work of \citet[Thms.~2, 8, and 12]{freeman2021truthfulbudget}, so we only prove Claims 2 and~3 here.\bigskip

    \textbf{Claim 2}: We first consider participation and then show that all considered rules fail strategyproofness by giving a common counterexample.\medskip

    \emph{Participation}: To show this for \avg{}, \minrule{}, \maxrule{}, and \geo{}, we first proof an auxiliary claim (the proof for \egal{} will be independent of this claim). Consider two instances $\mathcal{I}$ and $\mathcal{I}'$ such that $\mathcal{I'}$ is derived from $\mathcal{I}$ by adding an agent $i$ with preference $\mathbf{s}_i$. Moreover, let $\mathbf{x}$ and $\mathbf{x}'$ denote the respective outcomes chosen by an aggregation rule $F$, and define $X^+=\{j\in [m]\colon x_j'>x_j\}$ and $X^-=\{j\in [m]\colon x_j'<x_j\}$. We claim that, if $s_{i,j}\geq x_j'$ for all $j\in X^+$ or $s_{i,j}\leq x_j'$ for all $j\in X^-$, then $F$ satisfies participation on $\mathI$ and $\mathI'$. We will prove this claim only for the case that $s_{i,j}\geq x_j'$ for all $j\in X^+$, as the case that $s_{i,j}\leq x_j'$ for all $j\in X^-$ is symmetric. Now, if $s_{i,j}\geq x_j'$ for all $j\in X^+$, then it holds for these candidates that 
    \begin{align*}
        |s_{i,j}-x_{j}'|-|s_{i,j}-x_j|=(s_{i,j}-x_{j}')-(s_{i,j}-x_j)=x_j-x_j'.
    \end{align*}
    On the other hand, we observe that
    \begin{align*}
        \sum_{j\in [m]\setminus X^+} (|s_{i,j}-x_j'|-|s_{i,j}-x_j|)&\leq \sum_{j\in [m]\setminus X^+} |x_j-x_j'|=\sum_{j\in [m]\setminus X^+}(x_j-x_j')=\sum_{j\in  X^+} (x_j' - x_j).
    \end{align*}
    The first inequality follows from the triangle inequality, the first equality uses the definition of $X^+$, and the second equality uses that $\sum_{j\in [m]} x_j=\sum_{j\in [m]} x_j'=1$. Based on these observations, we conclude that $F$ satisfies participation for $\mathI$ and $\mathI'$ since 
    \begin{align*}
        d_i(\mathbf{x}')-d_i(\mathbf{x})&=\sum_{j\in [m]} |s_{i,j}-x_{j}'|-\sum_{j\in [m]} |s_{i,j}-x_{j}|\\
        &= \sum_{j\in X^+} (|s_{i,j}-x_{j}'|- |s_{i,j}-x_{j}|)+\sum_{j\in [m]\setminus X^+} (|s_{i,j}-x_{j}'|- |s_{i,j}-x_{j}|)\\
        &\leq \sum_{j\in X^+} (x_j-x_j') + \sum_{j\in X^+} (x_j'-x_j)\\
        &=0.
    \end{align*}

    To show that our rules satisfy participation, it therefore suffices to prove that they satisfy $s_{i,j}\geq x_j'$ for all $j\in X^+$ or $s_{i,j}\leq x_j'$ for all $j\in X^-$. For this, we consider each rule individually.\bigskip 
    
    \emph{\avg}: For \avg{}, it is straightforward to reason that $s_{i,j}\geq x_j'$ for all $j\in X^+$. Indeed, otherwise we have that $x_j'>s_{i,j}$ and $x_j'>x_j$, which implies that
    \begin{align*}
        x_j'=\frac{1}{n+1}\sum_{i'\in N\cup \{i\}} s_{i',j}= \frac{1}{n+1}(s_{i,j}+n x_j)\leq \max(s_{i,j},x_j)<x_j'. 
    \end{align*}
    Since this is a contradiction, we infer that \avg{} satisfies participation.\bigskip

    \emph{\maxrule{}}: For \maxrule{}, it holds that $s_{i,j}\geq x_j'$ for all $j\in X^+$. To see this, note that $s_{i,j}>\max_{i'\in N} s_{i',j}$ for all $j\in X^+$, because otherwise $\max_{i'\in N\cup \{i\}} s_{i',j}=\max_{i'\in N} s_{i',j}$ and hence 
        \begin{align*}
        x_j'=\frac{\max_{i'\in N\cup \{i\}} s_{i',j}}{\sum_{j'\in [m]} \max_{i'\in N\cup\{i\}} s_{i',j'}}\leq \frac{\max_{i'\in N} s_{i',j}}{\sum_{j'\in [m]} \max_{i'\in N} s_{i',j'}} =x_j.
        \end{align*}
    Moreover, since $\sum_{j'\in [m]} \max_{i'\in N\cup\{i\}} s_{i',j'}\geq 1$ and therefore $s_{i,j}\geq \frac{s_{i,j}}{\sum_{j'\in [m]} \max_{i'\in N\cup\{i\}} s_{i',j'}}$, we conclude that $s_{i,j}\geq x_j'$ for all $j\in X^+$. This proves that \maxrule{} satisfies participation.\bigskip

    \emph{\minrule{}}: For \minrule{}, we first consider the case that $\min_{i'\in N} s_{i',j}=0$ for all $j\in [m]$ or $\min_{i'\in N\cup \{i\}} s_{i',j}=0$ for all $j\in [m]$. If $\min_{i'\in N} s_{i',j}=0$ for all $j\in [m]$, then the same holds for $\mathcal{I'}$ and $\mathbf{x}=\mathbf{x}'=(\frac{1}{m},\dots, \frac{1}{m})$, so participation is satisfied in this case. 
    Next, if $\min_{i'\in N} s_{i',j}\neq 0$ for some $j\in [m]$ but $\min_{i'\in N\cup \{i\}} s_{i',j}=0$, then $x_j>0$ implies $s_{i,j}=0$, and $s_{i,j}>0$ implies that $x_j=0$. Consequently, $d_i(\mathbf{x})=\sum_{j\in [m]} |s_{i,j}-x_j|=\sum_{j\in [m]} (s_{i,j}+x_j)=2$, which is the largest possible distance between two score vectors. Hence, $d_i(\mathbf{x'})\leq d_i(\mathbf{x})$ and participation holds again. 

    Now, if there is a candidate $c_j$ such that $\min_{i'\in N\cup \{i\}} s_{i',j}>0$, we claim that $s_{i,j}\leq x_j'$ for all $j\in X^-$. To see this, note that if $j\in X^-$, then $s_{i,j}<\min_{i'\in N} s_{i',j}$. Indeed, otherwise it holds that $\min_{i'\in N\cup \{i\}} s_{i',j}=\min_{i'\in N} s_{i',j}$ and hence
    \begin{align*}
        x_j'=\frac{\min_{i'\in N\cup \{i\}} s_{i',j}}{\sum_{j'\in [m]} \min_{i'\in N\cup\{i\}} s_{i',j'}}\geq \frac{\min_{i'\in N} s_{i',j}}{\sum_{j'\in [m]} \min_{i'\in N} s_{i',j'}} =x_j,
    \end{align*}
    contradicting the definition of $X^-$. Since $\sum_{j'\in [m]} \min_{i'\in N\cup\{i\}} s_{i',j'}\leq 1$, we thus derive that $s_{i,j}\leq \frac{s_{i,j}}{\sum_{j'\in [m]} \min_{i'\in N\cup \{i\}} s_{i',j'}}= x_j'$ for all $j\in X^-$, which shows that \minrule{} satisfies participation.\bigskip

    \emph{\geo{}}: We first note that an analogous analysis as for \minrule{} shows that \geo{} satisfies participation if $\sqrt[n]{\prod_{i'\in N} s_{i',j}}=0$ for all $j\in [m]$ or $\sqrt[n+1]{\prod_{i'\in N\cup \{i\}} s_{i',j}}=0$ for all $j\in [m]$. We hence assume that there is a candidate $c_{j^*}$ such that $\sqrt[n+1]{\prod_{i'\in N\cup \{i\}} s_{i',j^*}}>0$. Now, let $Z(\mathI)=\sum_{j\in [m]} \sqrt[n]{\prod_{i'\in N} s_{i',j}}$ and $Z(\mathI')=\sum_{j\in [m]} \sqrt[n+1]{\prod_{i'\in N\cup\{i\}} s_{i',j}}$. By the definition of $x_j$, we have for each $j\in[m]$ that 
    \begin{align*}
        \prod_{i'\in N} s_{i',j}=(x_j\cdot Z(\mathI))^n.
    \end{align*}
    Consequently, it holds for all $j\in [m]$ that
    \begin{align*}
        x_j'=\frac{(s_{i,j})^{1/(n+1)}\cdot (x_j\cdot Z(\mathI))^{n/(n+1)}}{Z(\mathI')}=(s_{i,j})^{1/(n+1)}\cdot (x_j)^{n/(n+1)}\cdot \frac{Z(\mathI)^{n/(n+1)}}{Z(\mathI')}.
    \end{align*}

    Next, we use a case distinction with respect to whether $Z(\mathI)^{n/(n+1)}\geq Z(\mathI')$ or $Z(\mathI)^{n/(n+1)}\leq Z(\mathI')$ and start with the case that $Z(\mathI)^{n/(n+1)}\geq Z(\mathI')$. In this case, it holds that $s_{i,j}\leq x_j'$ for all $j\in X^-$, as otherwise 
    \begin{align*}
        x_j'\geq (s_{i,j})^{1/(n+1)}\cdot (x_j)^{n/(n+1)}>(x_j')^{1/(n+1)}\cdot (x_j')^{n/(n+1)}=x_j',
    \end{align*}
    a contradiction.
    On the other hand, if $Z(\mathI)^{n/(n+1)}\leq Z(\mathI')$, we infer for all $j\in X^+$ that $s_{i,j}\geq x_j'$, as otherwise
        \begin{align*}
    x_j'\leq  (s_{i,j})^{1/(n+1)}\cdot (x_j)^{n/(n+1)}<(x_j')^{1/(n+1)}\cdot (x_j')^{n/(n+1)}=x_j'.
        \end{align*}
    We can thus conclude that \geo{} satisfies participation based on our auxiliary claim.\bigskip

    \emph{\egal{}}: For \egal{}, we will use a direct argument instead of our auxiliary claim to show that it satisfies participation. Consider two instances $\mathI$ and $\mathI'$ such that $\mathI'$ is derived from $\mathI$ by adding an agent $i$ with preference $\mathbf{s}_i$, and let $\mathbf{x}$ and $\mathbf{x'}$ denote the outcome of \egal{} for these instances. 
    Assume for contradiction that $d_i(\mathbf{x})<d_i(\mathbf{x'})$. 
    For a set of agents $T$, let $v_T(\mathbf{y})$ be a vector that contains the disutilities of all agents $i'\in T$ for a given score vector $\mathbf{y}$ in non-increasing order. Moreover, we write $v>_\mathit{lex} v'$ if there is an integer $k$ such that $v_{\ell}=v'_\ell$ for all $\ell\in [k-1]$ and $v_k>v_{k}'$. Now, since \egal{} chooses $\mathbf{x}$ for $\mathcal{I}$, it either holds that $v_N(\mathbf{x})=v_N(\mathbf{x'})$ or $v_N(\mathbf{x'})>_\mathit{lex} v_N(\mathbf{x})$. In both cases, it is simple to derive that $v_{N\cup \{i\}}(\mathbf{x'})>_\mathit{lex} v_{N\cup \{i\}}(\mathbf{x})$ since $d_i(\mathbf{x})<d_i(\mathbf{x'})$. However, this contradicts the assumption that \egal{} chooses $\mathbf{x}'$ for $\mathcal{I}'$. Hence, our assumption that $d_i(\mathbf{x})<d_i(\mathbf{x'})$ must have been wrong, which means that \egal{} satisfies participation.\bigskip
    
    \emph{Strategyproofness}: To prove the claim on strategyproofness, we consider the following instances $\mathcal{I}$ and $\mathcal{I}'$. All candidates $c_j$ with $j\geq 3$ receive probability $0$ from all agents and are ignored for the rest of the proof.  
 \begin{center}
    \begin{tabular}{ c | c c  }
          $\mathcal{I}$ & $s_{i,1}$ & $s_{i,2}$ \\ 
         \hline \hline
         $1$ & $\frac{4}{5}$ & $\frac{1}{5}$ \\ 
         $i\in \{2,\dots, n\}$ & $\frac{1}{5}$ & $\frac{4}{5}$ 
        \end{tabular}
        \qquad\qquad
    \begin{tabular}{ c | c c c c }
          $\mathcal{I}'$ & $s_{i,1}$ & $s_{i,2}$  \\ 
         \hline \hline
         $1$ & $1$ & $0$ \\ 
         $i\in \{2,\dots, n\}$ & $\frac{1}{5}$ & $\frac{4}{5}$  
        \end{tabular}       
    \end{center}\smallskip      

    \avg{} chooses for these instances the outcomes $\mathbf{x}=(\frac{1}{5}+\frac{3}{5n}, \frac{4}{5}-\frac{3}{5n})$ and $\mathbf{x}'=(\frac{1}{5}+\frac{4}{5n}, \frac{4}{5}-\frac{4}{5n})$, \maxrule{} chooses $\mathbf{x}=(\frac{1}{2},\frac{1}{2})$ and $\mathbf{x}'=(\frac{5}{9},\frac{4}{9})$, \minrule{} chooses $\mathbf{x}=(\frac{1}{2},\frac{1}{2})$ and $\mathbf{x}'=(1,0)$, \geo{} chooses $\mathbf{x}=(\frac{\sqrt[n]{16}}{4+\sqrt[n]{16}}, \frac{4}{4+\sqrt[n]{16}})$ and $\mathbf{x}'=(1, 0)$, and \egal{} chooses $\mathbf{x}=(\frac{1}{2},\frac{1}{2})$ and $\mathbf{x}'=(\frac{3}{5}, \frac{2}{5})$. In each case, it can be checked that agent~$1$ benefits by deviating from $\mathI$ to $\mathI'$, so strategyproofness is violated.\bigskip

    \textbf{Claim 3}: Finally, we turn to \med{} and again consider participation and strategyproofness separately.\bigskip
    
    \emph{Participation}: First, we show that \med{} satisfies participation when $m=2$. Consider two instances $\mathI$ and $\mathI'$ such that $\mathI'$ is derived from $\mathI$ by adding an agent $i$ with preference $\mathbf{s}_i$. Moreover, let $\mathbf{x}$ and $\mathbf{x'}$ denote the vectors returned by \med{} for these instances, respectively. Without loss of generality, assume that $x_1'>x_1$. We show that this is only possible if $s_{i,1}\geq x_1'$. Hence, assume for contradiction that $s_{i,1}<x_{1}'$. Since $x_1'>x_1$ and there are at least $\lceil\frac{n}{2}\rceil$ agents $i'\in N$ with $x_1\geq s_{i',1}$, there are at least $\lceil\frac{n}{2}\rceil+1$ agents $i'$ in $\mathI'$ with $x_1'>s_{i',1}$. This means that $\text{med}_{i'\in N\cup \{i\}} s_{i',1}<x_1'$. However, since we have only two alternatives, it holds that $\text{med}_{i'\in N\cup \{i\}} s_{i',1}+\text{med}_{i'\in N\cup \{i\}} s_{i',2}=1$, so it must be that $x_1'=\text{med}_{i'\in N\cup \{i\}} s_{i',1}$. This is the desired contradiction and we thus conclude that \med{} satisfies participation when $m=2$. 

    Next, to see that \med{} fails participation when $m\geq 3$, we consider the instances $\mathI^5$ and $\mathI^6$ in the proof of \Cref{thm:consistencyprops} that were used to show that \med{} fails reinforcement. In this example, $\mathI^6$ consists of a single agent whose ideal distribution coincides with the outcome of \med{} for $\mathI^5$. However, in the combined instance, the outcome changes, which means that participation is violated for this agent.\bigskip
    
    \emph{Strategyproofness}: Next, we focus on strategyproofness. First, we will show that, if $m=2$ and $n$ is odd, \med{} is strategyproof. To this end, we note that \med{} simply returns the distribution of the agent who assigns the $(\frac{n+1}{2})$-th highest score to $c_1$. Since $d_{i'}(\mathbf{x})=|s_{i',1}-x_1|+|s_{i',2}-x_2|=2|s_{i',1}-x_1|$ for all agents $i'$, the strategyproofness follows directly from the well-known result by \citet{Moul80a}. On the other hand, if $m=2$ and $n$ is even, \med{} returns the average between the outcome of two agents, which allows agents to benefit by exaggerating their report. For instance, if one agent reports $(\frac{2}{3}, \frac{1}{3})$, $\frac{n}{2}-1$ agents report $(1,0)$, and $\frac{n}{2}$ agents report $(0,1)$, \med{} chooses the outcome $(\frac{1}{3}, \frac{2}{3})$. However, if the first agent reports $(1,0)$, \med{} returns $(\frac{1}{2}, \frac{1}{2})$, which constitutes a beneficial manipulation for this agent. This example can be generalized to $m\geq 3$ by adding candidates that receive a score of $0$ from every agent, so we next focus on the case of $m\geq 3$ and odd $n\geq 3$. In this case, consider the instance $\mathI$ below. One can check that \med{} chooses $\mathbf{x}=(\frac{1}{3}, \frac{1}{3}, \frac{1}{3})$. This means for agent $n$ that $d_n(\mathbf{x})=(\frac{2}{5}-\frac{1}{3})+(\frac{3}{5}-\frac{1}{3})+\frac{1}{3}=\frac{2}{3}$. Next, suppose that agent $n$ reports the distribution $(\frac{8}{15}, \frac{7}{15}, 0)$. It can be verified that \med{} now picks the distribution $(\frac{2}{5}, \frac{3}{10}, \frac{3}{10})$, which means that $d_n(\mathbf{x}')=\frac{3}{5}<\frac{2}{3}$. Hence, \med{} is indeed manipulable if $m\geq 3$ and $n\geq 3$ is odd. 
\begin{center}
    \begin{tabular}{ c | c c c c }
          $\mathcal{I}$ & $s_{i,1}$ & $s_{i,2}$ & $s_{i,3}$ \\ 
         \hline \hline
         $i\in \{1,\dots, \frac{n-1}{2}\}$ & $0$ & $\frac{2}{5}$ & $\frac{3}{5}$ \\
         $i\in \{\frac{n+1}{2},\dots, n-1\}$ & $\frac{3}{5}$ & $0$ & $\frac{2}{5}$ \\
         $n$ & $\frac{2}{5}$ & $\frac{3}{5}$ & $0$ \\
    \end{tabular}
    $\qquad\qquad$
\begin{tabular}{ c | c c c c }
          $\mathcal{I}'$ & $s_{i,1}$ & $s_{i,2}$ & $s_{i,3}$ \\ 
         \hline \hline
         $i\in \{1,\dots, \frac{n-1}{2}\}$ & $0$ & $\frac{2}{5}$ & $\frac{3}{5}$ \\
         $i\in \{\frac{n+1}{2},\dots, n-1\}$ & $\frac{3}{5}$ & $0$ & $\frac{2}{5}$ \\
         $n$ & $\frac{8}{15}$ & $\frac{7}{15}$ & $0$ \\
    \end{tabular}
    \end{center}
\bigskip This completes the proof. 
\end{proof}


\section{Characterizations of the Average Rule}
\label{sec:characterization}

Thus far, we have conducted an extensive analysis of specific natural rules with respect to a number of desirable axioms.
In this section, we complement those findings by presenting two characterizations of the \avg{} rule. These results highlight the strong appeal of \avg{} by showing that it is the only rule within large classes of rules that, for example, satisfies score-unanimity and independence. 

To state these results, we will introduce two more axioms. Firstly, we say an aggregation function~$F$ is \emph{anonymous} if the identities of the agents do not matter, i.e., if $F(\mathI)=F(\pi(\mathI))$ for all instances $\mathI$ and permutations $\pi:N\rightarrow N$, where $\mathI'=\pi(\mathI)$ is the instance defined by $\mathbf{s}_{\pi(i)}'=\mathbf{s}_i$ for all $i\in N$. Secondly, an aggregation function $F$ is \emph{continuous} if it is a continuous function, i.e., $F(\lim_{t\rightarrow\infty}\mathI^t)=\lim_{t\rightarrow\infty} F(\mathI^t)$ for every sequence of instances $\mathI^1,\mathI^2,\dots$ such that $\lim_{t\rightarrow\infty} \mathI^t$ exists.
We remark that both of these conditions are very weak: all of the rules considered in this paper are anonymous, and all except \minrule{} and \geo{} are continuous.\footnote{\minrule{} and \geo{} fail continuity because they return the distribution $(\frac{1}{m},\dots, \frac{1}{m}$) when $\min_{i\in N} s_{i,j}=0$ for all $j\in [m]$. Apart from this corner case, these rules are also continuous.} 

\begin{theorem}\label{lem:indavg}
The following claims hold.
\begin{enumerate}[label=(\arabic*),topsep=4pt,itemsep=0pt]
    \item \avg{} is the only aggregation rule that satisfies anonymity, score-unanimity, and independence if $m\geq 3$.
    \item \avg{} is the only coordinate-wise aggregation rule that satisfies anonymity, continuity, and score-unanimity if $m\geq 4$.
\end{enumerate}
\end{theorem}
\begin{proof}
    It is easy to verify that \avg{} satisfies all stated axioms, so we focus on showing that the given sets of axioms indeed characterize \avg{}. We will establish the two claims separately.\bigskip

    \textbf{Claim 1}: Let $F$ be an aggregation rule that satisfies anonymity, score-unanimity, and independence. 
    In particular, this means that $F(\mathI)_k=\gamma$ whenever $s_{i,k}=\gamma$ for all $i\in N$. 
    If $n=1$, this already proves our claim, so we subsequently assume that $n\geq 2$.
    We establish the result in three steps.
    Firstly, we will show that for every $\gamma\in (0,1]$, there is a constant $C_\gamma$ such that $F(\mathI)_j=C_\gamma$ for all instances $\mathI$ on $n$ agents and all candidates $c_j\in C$ such that a single agent puts probability $\gamma$ on $c_j$ and every other agent puts probability $0$ on this candidate. 
    In the second step, we will prove that $C_\gamma=\frac{\gamma}{n}$. 
    Based on this insight, we will derive that $F$ corresponds to \avg{} in the last step.
    \medskip

    \emph{Step 1}: Our first goal is to show that, for every $\gamma\in (0,1]$, there is a constant $C_\gamma$ such that $F(\mathI)_j=C_\gamma$ for all instances $\mathI$ and candidates $c_j$ such that $s_{i,j}=\gamma$ for a single agent $i\in N$ and $s_{i',j}=0$ for all other agents $i'\in N\setminus \{i\}$. 
    To prove this claim, consider two instances $\mathI^1$ and $\mathI^2$ for which there are two candidates $c_{j_1}$ and $c_{j_2}$ and two agents $i_1$ and $i_2$ such that \emph{(i)} $s_{i_1,j_1}^1=\gamma$ and $s_{i',j_1}^1=0$ for all $i'\in N\setminus \{i_1\}$, and \emph{(ii)} $s_{i_2,j_2}^2=\gamma$ and $s_{i',j_2}^2=0$ for all $i'\in N\setminus \{i_2\}$. 
    Our goal is to show that $F(\mathI^1)_{j_1}=F(\mathI^2)_{j_2}$. Since $\mathI^1$ and $\mathI^2$ are arbitrarily chosen, this implies that there is a constant $C_\gamma$ such that $F(\mathI)_j=C_\gamma$ for all instances $\mathI$ in which a single agent puts probability $\gamma$ on a candidate $c_j$.

    To prove that $F(\mathI^1)_{j_1}=F(\mathI^2)_{j_2}$, let $\hat \mathI^2$ denote the instance which is derived from $\mathI^2$ by exchanging the preferences of agents $i_2$ and $i_1$. In particular, this means that $\hat s_{i_1, j_2}^2=\gamma$ and $\hat s_{i',j_2}^2=0$ for all other agents $i'\in N\setminus \{i_1\}$. Clearly, anonymity requires that $F(\hat \mathI^2)=F(\mathI^2)$ as we derive $\hat \mathI^2$ by renaming the agents in $\mathI^2$. Now, if $j_1=j_2$, it holds that $\hat s_{i, j_1}^2=s_{i, j_1}^1$ for all $i\in N$, so independence implies that $F(\mathI^1)_{j_1}=F(\hat \mathI^2)_{j_2}$ in this case. Hence, if $j_1=j_2$, it follows that $F(\mathI^1)_{j_1}=F(\mathI^2)_{j_2}$.
    
    Next, assume that $j_1\neq j_2$. 
    In this case, we let $c_{j_3}$ denote an arbitrary candidate in $C\setminus \{c_{j_1}, c_{j_2}\}$ and consider the instances $\tilde \mathI^1$ and $\tilde \mathI^2$.
    \smallskip
\begin{center}
        \begin{tabular}{ c | c c c c }
          $\tilde\mathI^1$ & $s_{i,j_1}$ & $s_{i,j_2}$ & $s_{i,j_3}$ & $s_{i,j}$ for $j\in [m]\setminus \{j_1,j_2,j_3\}$\\ 
         \hline \hline
         $i_1$ & $\gamma$ & $1-\gamma$ & $0$ & $0$ \\ 
         $i'\in N\setminus \{i_1\}$ & $0$ & $1-\gamma$ & $\gamma$ & $0$ \\ 
        \end{tabular}\bigskip
        
        \begin{tabular}{ c | c c c c }
        \ $\tilde\mathI^2$ & $s_{i,j_1}$ & $s_{i,j_2}$ & $s_{i,j_3}$ & $s_{i,j}$ for $j\in [m]\setminus \{j_1,j_2,j_3\}$\\ 
         \hline \hline
         $i_1$ & $1-\gamma$ & $\gamma$ & $0$ & $0$ \\ 
         $i'\in N\setminus \{i_1\}$ & $1-\gamma$ & $0$ & $\gamma$ & $0$ \\ 
        \end{tabular}
        
    \end{center}    
    We infer from score-unanimity that $F(\tilde \mathI^1)_{j_2}=F(\tilde \mathI^2)_{j_1}=1-\gamma$ and $F(\tilde \mathI^1)_{j}=F(\tilde \mathI^2)_{j}=0$ for all $j\in [m]\setminus \{j_1,j_2,j_3\}$. 
    We therefore have $F(\tilde \mathI^1)_{j_3}=\gamma-F(\tilde \mathI^1)_{j_1}$ and $F(\tilde \mathI^2)_{j_3}=\gamma-F(\tilde \mathI^2)_{j_2}$.
    Moreover, independence implies that $F(\mathI^1)_{j_1}=F(\tilde \mathI^1)_{j_1}$ and $F(\hat \mathI^2)_{j_2}=F(\tilde \mathI^2)_{j_2}$ because $s_{i,j_1}^1=\tilde s_{i,j_1}^1$ and $\hat s_{i, j_2}^2=\tilde s_{i,j_2}^2$ for all $i\in N$.  
    Now, independence between $\tilde \mathI^1$ and $\tilde \mathI^2$ implies that $F(\tilde \mathI^1)_{j_3}=F(\tilde \mathI^2)_{j_3}$. 
    This means that $F(\tilde \mathI^1)_{j_1}=F(\tilde \mathI^2)_{j_2}$ and we hence conclude that $F(\mathI^1)_{j_1}=F(\hat \mathI^2)_{j_2}=F(\mathI^2)_{j_2}$.
    \medskip

    \emph{Step 2}: For our second step, we fix a value $\gamma\in (0,1]$ and let $C_\gamma$ denote the constant derived in Step~1. 
    The goal of this step is to show that $C_\gamma=\frac{\gamma}{n}$. 
    To prove this claim, let $c_{j_1}$, $c_{j_2}$, and $c_{j_3}$ denote three distinct candidates. 
    We will inductively show that $F(\mathI^k)_{j_1}=k\cdot C_\gamma$ for the instances $\mathI^k$ shown below.    
    \begin{center}
        \begin{tabular}{ c | c c c c }
        \ $\mathI^k$ & $s_{i,j_1}$ & $s_{i,j_2}$ & $s_{i,j_3}$ & $s_{i,j}$ for $j\in [m]\setminus \{j_1,j_2,j_3\}$\\ 
         \hline \hline
         $i\in \{1,\dots, k\}$ & $\gamma$   &  $0$ & $1-\gamma$ & $0$\\
    $i\in \{k+1,\dots, n\}$& $0$ &  $\gamma$   &  $1-\gamma$ & $0$\\
        \end{tabular}
    \end{center}
    In particular, this means that $F(\mathI^{n-1})_{j_1}=(n-1)\cdot C_\gamma$. Moreover, we infer from Step 1 that $F(\mathI^{n-1})_{j_2}=C_\gamma$ and score-unanimity shows that $F(\mathI^{n-1})_{j_3}=1-\gamma$ and $F(\mathI^{n-1})_{j}=0$ for all $j\in [m]\setminus \{j_1, j_2, j_3\}$. Hence, we can now compute that $C_\gamma=\frac{\gamma}{n}$ because $\sum_{j\in [m]} F(\mathI^{n-1})_j=1$. 

    For the proof that $F(\mathI^k)_{j_1}=k\cdot C_\gamma$ for all $k\in \{1,\dots, n-1\}$, we first note that $F(\mathI^1)_{j_1}=C_\gamma$ by Step 1. Next, we inductively assume that $F(\mathI^k)_{j_1}=k\cdot C_\gamma$ for some $k\in \{1,\dots, n-2\}$ and aim to show that $F(\mathI^{k+1})_{j_1}=(k+1)\cdot C_\gamma$. 
    To this end, we consider the instances $\hat \mathI^k$ and $\tilde \mathI^k$ shown below.\smallskip

     \begin{center}
        \begin{tabular}{ c | c c c c }
         $\hat \mathI^k$ & $s_{i,j_1}$ & $s_{i,j_2}$ & $s_{i,j_3}$ & $s_{i,j}$ for $j\in [m]\setminus \{j_1,j_2,j_3\}$\\ 
         \hline \hline
         $i\in \{1,\dots, k\}$ & $\gamma$   &  $0$ & $1-\gamma$ & $0$\\
         $k+1$ & $0$ & $\gamma$ & $1-\gamma$ & $0$\\
    $i\in \{k+2,\dots, n\}$& $0$ &  $0$   &  $1$ & $0$\\
        \end{tabular}\bigskip
        
        \begin{tabular}{ c | c c c c }
         $\tilde \mathI^k$ & $s_{i,j_1}$ & $s_{i,j_2}$ & $s_{i,j_3}$ & $s_{i,j}$ for $j\in [m]\setminus \{j_1,j_2,j_3\}$\\ 
         \hline \hline
         $i\in \{1,\dots, k+1\}$ & $\gamma$   &  $0$ & $1-\gamma$ & $0$\\
    $i\in \{k+2,\dots, n\}$& $0$ &  $0$   &  $1$ & $0$\\
        \end{tabular}
    \end{center}

    By independence and the induction hypothesis, we have that $F(\hat \mathI^k)_{j_1}=F(\mathI^{k})_{j_1}=k\cdot C_\gamma$. 
    Moreover, Step 1 shows that $F(\hat \mathI^k)_{j_2}=C_\gamma$ and score-unanimity requires that $F(\hat \mathI^k)_{j}=0$ for all $j\in [m]\setminus\{j_1,j_2,j_3\}$. So we derive that $F(\hat \mathI^k)_{j_3}=1-(k+1)\cdot C_\gamma$. 
    Next, we turn to the instance $\tilde \mathI^k$. By score-unanimity, we have that $F(\tilde \mathI^k)_{j}=0$ for all $j\in [m]\setminus \{j_1,j_3\}$ and independence implies that $F(\tilde \mathI^k)_{j_3}=F(\hat \mathI^k)_{j_3}=1-(k+1)\cdot C_\gamma$.
    It thus holds that $F(\tilde \mathI^k)_{j_1}=(k+1)\cdot C_\gamma$ as the probabilities must sum up to $1$. 
    Finally, independence implies that $F(\mathI^{k+1})_{j_1}=F(\tilde \mathI^k)_{j_1}=(k+1)\cdot C_\gamma$, which completes the induction step.\medskip

    \emph{Step 3}: For our last step, we will show that $F$ corresponds to \avg{}.
    Consider an arbitrary candidate $c_{j_1}$ and an instance $\mathI$. Our goal is to show that $F(\mathI)_{j_1}=\frac{1}{n}\sum_{i\in N} s_{i, j_1}$. 
    To prove this claim, we take a candidate $c_{j_2} \ne c_{j_1}$, and consider the following instances $\mathI^k$ for $k\in \{1,\dots, n\}$ defined by \emph{(i)} $s_{i, j_1}^k=s_{i,j_1}$ and $s_{i,j_2}^k=1-s_{i,j_1}$ for all $i\in \{1,\dots,k \}$, \emph{(ii)} $s_{i,j_1}^k=0$ and $s_{i,j_2}^k=1$ for all $i\in \{k+1,\dots,n\}$, and \emph{(iii)} $s_{i,j}^k=0$ for all $i\in N$ and $j\in [m]\setminus \{j_1,j_2\}$. 
    In particular, it holds by independence that $F(\mathI)_{j_1}=F(\mathI^n)_{j_1}$, so our goal is to show that $F(\mathI^n)_{j_1}=\frac{1}{n}\sum_{i\in N} s_{i, j_1}$. 

    We will prove by induction on $k\in \{1,\dots, n\}$ that $F(\mathI^k)_{j_1}=\frac{1}{n}\sum_{i=1}^k s_{i, j_1}$. For the induction base $k=1$, we observe that $F(\mathI^1)_{j_1}=\frac{s_{1,j_1}^1}{n}=\frac{1}{n}\sum_{i=1}^1 s_{i,j_1}$ due to Step~2 (if $s_{1, j_1}>0$) or score-unanimity (if $s_{1, j_1}=0$). 
    Next, we inductively assume that $F(\mathI^k)_{j_1}=\frac{1}{n}\sum_{i=1}^k s_{i,j_1}$ for some $k\in \{1,\dots, n-1\}$, and aim to show the same for $k+1$. 
    If $s_{k+1,\, j_1}=0$, this follows due to independence as $F(\mathI^{k+1})_{j_1}=F(\mathI^{k})_{j_1}=\frac{1}{n}\sum_{i=1}^{k+1} s_{i,j_1}$. 
    We thus assume that $s_{k+1,\, j_1}>0$ and consider the instance $\bar \mathI^k$ derived from $\mathI^k$ by setting $\bar s_{k+1,\,j_3}^k=s_{k+1,\,j_1}$ for some arbitrary ${j_3}\in [m]\setminus \{j_1,j_2\}$ and $\bar s_{k+1,\,j_2}^k=1-s_{k+1,\,j_1}$. 
    By independence, it holds that $F(\bar \mathI^{k})_{j_1}=F(\mathI^k)_{j_1}=\frac{1}{n} \sum_{i=1}^k s_{i, j_1}$. Furthermore, $F(\bar \mathI^k)_{j_3}=\frac{s_{k+1,\,j_1}}{n}$ by Step 2. Since $F(\bar\mathI^k)_j=0$ for all $j\in [m]\setminus \{j_1,j_2,j_3\}$ due to score-unanimity, we infer that $F(\bar \mathI^k)_{j_2}=1-F(\bar \mathI^k)_{j_1}-F(\bar \mathI^k)_{j_3}=1-\frac{1}{n}\sum_{i=1}^{k+1} s_{i, j_1}$. 
    
    Next, we derive from independence between $\bar \mathI^k$ and $\mathI^{k+1}$ that $F(\mathI^{k+1})_{j_2}=F(\bar \mathI^k)_{j_2}=1-\frac{1}{n}\sum_{i=1}^{k+1} s_{i, j_1}$. 
    Since $F(\mathI^{k+1})_{j}=0$ for all $j\in [m]\setminus \{j_1,j_2\}$ due to score-unanimity, it follows that $F(\mathI^{k+1})_{j_1}=\frac{1}{n}\sum_{i=1}^{k+1} s_{i, j_1}$. This completes the induction step, and it thus follows that $F(\mathI)_{j_1}=F(\mathI^n)_{j_1}=\frac{1}{n}\sum_{i\in N} s_{i,j_1}$. We finally conclude that $F$ is \avg{}.\bigskip

    \textbf{Claim 2}: Let $F$ be a coordinate-wise aggregation rule that satisfies anonymity, continuity, and score-unanimity. 
Moreover, let $f_j$ denote the coordinate-aggregation function of $F$ for the $j$-th coordinate. 
In slight abuse of notation, we will frequently write $f_j(\mathI)$ to mean $f_j(s_{1,j},\dots, s_{n,j})$. 
Since $F$ is invariant under scaling all functions $f_j$ with a constant, we can assume without loss of generality that $f_1(0.5,\dots,0.5)=0.5$.

In the remainder of the proof, we will show that $f_j(\mathI)=\frac{1}{n}\sum_{i\in N} s_{i,j}$ for all instances $\mathI$ and candidates $c_j$. To this end, we first prove this claim for the case where all agents put the same probability $\gamma \in [0,1)$ on a candidate $c_j$. 
In the second step, we then use our first characterization of \avg{} to show that $f_j(\mathI)=\frac{1}{n}\sum_{i\in N} s_{i,j}$ for all instances $\mathI$ and candidates $c_j$ with $\max_{i\in N} s_{i,j}<1$. Finally, we infer using continuity that $F$ corresponds to \avg{} in the last step. 
\medskip

\emph{Step 1}: As the first step, we show that $f_j(\gamma,\dots, \gamma)=\gamma$ for all $j\in [m]$ and $\gamma\in [0,1)$. 
To this end, we first observe that $f_j(0,\dots, 0)=0$ for all $j\in [m]$ because of score-unanimity. 
To prove Step~1, we will first show that $f_j(0.5,\dots, 0.5)=0.5$ for all $j\in [m]$. 
Thus, fix some candidate $c_j\neq c_1$ and consider the instance $\mathI^1$ such that $s_{i,1}^1=s_{i,j}^1=0.5$ for all $i\in N$ and $s_{i,j'}=0$ for all $i\in N$ and $j'\in [m]\setminus \{1,j\}$. 
By score-unanimity, we infer that $f_{j'}(\mathI^1)=0$ for all $j'\in [m]\setminus \{1,j\}$. Moreover, score-unanimity requires that $F(\mathI^1)_1=F(\mathI^1)_j=0.5$. Since we assume that $f_1(0.5,\dots, 0.5)=0.5$ and $F(\mathI^1)_1=\frac{f_1(\mathI^1)}{\sum_{j'\in[m]} f_{j'}(\mathI^1)}$, we infer now that $\sum_{j'\in [m]} f_{j'}(\mathI^1)=1$. By combining this with our previous observations, it follows that $f_j(\mathI^1)=0.5$. This proves that  $f_j(0.5,\dots,0.5)=0.5$ for all $j\in [m]$.

Next, we show that $f_j(\gamma,\dots,\gamma)=\gamma$ for all $\gamma\in (0,0.5)$ and $j\in [m]$. 
To this end, we fix three distinct candidates $c_{j_1}$, $c_{j_2}$, and $c_{j_3}$ and consider the instance $\mathI^2$ such that $s_{i,j_1}^2=\gamma$, $s_{i,j_2}^2=0.5$, and $s_{i, j_3}^2=0.5-\gamma$ for all $i\in N$. All other candidates receive probability $0$ from all agents. By score-unanimity, $f_j(\mathI^2)=0$ for all $j\in [m]\setminus\{j_1,j_2,j_3\}$. 
Moreover, we infer that $F(\mathI^2)_{j_2}=0.5=f_{j_2}(\mathI^2)$ by score-unanimity and our previous insights, which implies that $\sum_{j\in [m]} f_j(\mathI^2)=1$. 
Since score-unanimity also requires that $F(\mathI^2)_{j_1}=\gamma$, we conclude now that $f_{j_1}(\gamma,\dots,\gamma)=\gamma$.

Finally, we consider the case that $\gamma\in (0.5,1)$. 
Fix two candidates $c_{j_1}$ and $c_{j_2}$ and consider the instance $\mathI^3$ such that $s_{i,j_1}^3=\gamma$ and $s_{i,j_2}^3=1-\gamma$ for all $i\in N$. All other candidates again obtain probability $0$ from all agents. Since $1-\gamma<0.5$, we derive from our previous insights and score-unanimity that $F(\mathI^3)_{j_2}=1-\gamma=f_{j_2}(\mathI^3)$. 
Hence, it holds that $\sum_{j\in [m]} f_j(\mathI^3)=1$. 
Since score-unanimity implies that $f_j(\mathI^3)=0$ for all $j\in [m]\setminus \{j_1,j_2\}$, we infer that $f_{j_1}(\gamma,\dots,\gamma)=\gamma$.
This completes the proof of Step 1.\medskip

\emph{Step 2}: Next, we prove that $f_j(\mathI)=\frac{1}{n}\sum_{i\in N} s_{i,j}$ for all instances $\mathI$ and candidates $c_j$ with $\max_{i\in N} s_{i,j}<1$. Fix an arbitrary instance $\mathI^*$ and a candidate $c_{j_1}$ that satisfy our requirements. Moreover, we define $\epsilon=1-\max_{i\in N} s^*_{i,j_1}$ and note that $\epsilon>0$ as $\max_{i\in N} s_{i,j_1}^*<1$. 
If $\epsilon=1$, then all agents assign probability $0$ to $c_{j_1}$ in $\mathI^*$, and score-unanimity immediately implies that $f_{j_1}(\mathI^*)=0=\frac{1}{n}\sum_{i\in N} s_{i,j_1}^*$. 

Hence, we assume that $\epsilon<1$ and consider three more candidates $c_{j_2}, c_{j_3}, c_{j_4}$. 
Furthermore, we define another aggregation rule $G$ for the candidates $\{c_{j_1}, c_{j_2}, c_{j_3}\}\subsetneq C$ as follows:  
Given an instance~$\mathI$ on these three candidates, we define the extended instance $\mathI^E$ on $C$ by \emph{(i)} $s_{i,j}^E=(1-\epsilon)s_{i,j}$ for all $i\in N$ and $j\in \{j_1,j_2,j_3\}$, \emph{(ii)} $s^E_{i,j_4}=\epsilon$ for all $i\in N$, and \emph{(iii)} $s^E_{i, j}=0$ for all $i\in N$ and $j\in [m]\setminus \{j_1,j_2,j_3,j_4\}$. 
Then, $G(\mathI)_{j}=\frac{1}{1-\epsilon} F(\mathI^E)_{j}$ for all $j\in \{j_1,j_2,j_3\}$. 

Our goal is to show that $G$ corresponds to \avg{} since this implies that $F(\mathI^E)_{j_1}=(1-\epsilon) G(\mathI)_{j_1}=(1-\epsilon)\frac{1}{n}\sum_{i\in N} s_{i, j_1}$ for all instances $\mathI$ on $\{c_{j_1}, c_{j_2}, c_{j_3}\}$. 
Because $s^E_{i,j}=(1-\epsilon) s_{i,j}$ for $j\in \{j_1,j_2,j_3\}$, it then follows that $F(\mathI^E)_{j_1}=\frac{1}{n}\sum_{i\in N} s_{i, j_1}^E$. Furthermore, by Step 1 and score-unanimity, we have that $F(\mathI^E)_{j_4}=\epsilon=f_{j_4}(\mathI^E)$, which implies that $\sum_{j\in [m]} f_j(\mathI^E)=1$. In turn, this means that $F(\mathI^E)_j=f_j(\mathI^E)$ for all $j\in [m]$, so it follows that $f_{j_1}(\mathI^E)=\frac{1}{n} \sum_{i\in N} s^{E}_{i, j_1}$ for all instances $\mathI$ on $\{c_{j_1}, c_{j_2}, c_{j_3}\}$. Finally, since we assumed that $0<\epsilon=1-\max_{i\in N} s^*_{i,j_1}$, there exists an instance $\mathI$ on $\{c_{j_1}, c_{j_2}, c_{j_3}\}$ such that $s^*_{i,j_1}=s^E_{i,j_1}$ for all $i\in N$, so we conclude that $f_{j_1}(\mathI^*)=\frac{1}{n}\sum_{i\in N} s_{i, j_1}^*$. 

It remains to show that $G$ is indeed \avg{}. 
To this end, we aim to employ our first characterization and show that $G$ is a well-defined aggregation rule that satisfies anonymity, score-unanimity, and independence.
First, it is easy to verify that $G$ is well-defined: it holds that $G(\mathI)_{j}\geq 0$ for all instances $\mathI$ and $j\in \{j_1,j_2,j_3\}$ as the same is true for $F(\mathI^E)$. 
Moreover, score-unanimity implies that $F(\mathI^E)_{j_4}=\epsilon$ and $F(\mathI^E)_j=0$ for all $j\in[m] \setminus \{j_1,j_2,j_3, j_4\}$, so $F(\mathI^E)_{j_1}+F(\mathI^E)_{j_2}+F(\mathI^E)_{j_3}=1-\epsilon$. 
It follows that $G(\mathI)_{j_1}+G(\mathI)_{j_2}+G(\mathI)_{j_3}=1$ for all instances $\mathI$. 

Next, we show that $G$ is anonymous. 
Consider two instances $\mathI$ and $\hat \mathI$ such that $\hat \mathI$ is derived from $\mathI$ by permuting the agents. 
Consequently, the instances $\mathI^E$ and $\hat \mathI^E$ can be derived from each other by permuting the agents, so the anonymity of $F$ implies that $F(\mathI^E)=F(\hat \mathI^E)$. 
This also means that $G(\mathI)=G(\hat \mathI)$, so $G$ is anonymous. 

To show that $G$ is score-unanimous, we consider an instance $\mathI$ such that all agents $i\in N$ put the same probability $\gamma$ on some candidate $c_{j}$. 
Hence, all agents put probability $(1-\epsilon)\gamma$ on $c_{j}$ in the extended instance $\mathI^E$. 
The score-unanimity of $F$ then implies that $F(\mathI^E)_{j}=(1-\epsilon)\gamma$, which entails that 
$G(\mathI)_{j}=\frac{1}{1-\epsilon}F(\mathI^E)_{j}=\gamma$. 
So $G$ satisfies this axiom, too. 

For the last point, we show that $G$ satisfies independence. 
To this end, consider two instances $\mathI$, $\hat \mathI$ on $\{c_{j_1}, c_{j_2}, c_{j_3}\}$ and a candidate $c_{j}$ such that $s_{i, j}=\hat s_{i,j}$ for all $i\in N$.
This means that $s^E_{i,j}=\hat s^E_{i,j}$ for all $i\in N$, so $f_j(\mathI^E)=f_j(\hat \mathI^E)$. 
Moreover, it holds by Step 1 and score-unanimity that $F(\mathI^E)_{j_4}=\epsilon = f_{j_4}(\mathI^E)$ and $ F(\hat \mathI^E)_{j_4} = \epsilon = f_{j_4}(\hat \mathI^E)$. 
We hence infer that $\sum_{j'\in [m]} f_{j'}(\mathI^E)=\sum_{j'\in [m]} f_{j'}(\hat \mathI^E)=1$. 
This means that $F(\mathI^E)_{j}=f_{j}(\mathI^E)=f_{j}(\hat \mathI^E)=F(\hat \mathI^E)_{j}$, so $G$ satisfies independence
because $G(\mathI)_{j}=\frac{1}{1-\epsilon}F(\mathI^E)_{j}=\frac{1}{1-\epsilon}F(\hat\mathI^E)_{j}=G(\hat \mathI)_{j}$. 

Finally, since the rule $G$ satisfies all axioms of Claim~1, we conclude that it is \avg{}, which completes the proof of this step.\medskip

\emph{Step 3}: By the insights of Step 2, we get that $f_j(\mathI)=\frac{1}{n}\sum_{i\in N} s_{i,j}$ for all instances $\mathI$ and candidates $c_j$ such that $\max_{i\in N} s_{i,j}<1$. 
This means that $F$ is equal to \avg{} for all instances $\mathI$ with $\max_{i\in N,\, j\in [m]} s_{i,j}<1$. 
In order to extend the result to instances where some agents assign probability $1$ to some candidate, we use the continuity of $F$. 
Specifically, consider an instance $\mathI^*$ such that $s^*_{i,j}=1$ for some agents $i\in N$ and candidate $c_j\in C$.
Moreover, let $\mathI$ denote the instance where every agent assigns probability $\frac{1}{m}$ to every candidate. 
We can now consider the sequence of instances $\mathI^k$ defined by $s_{i,j}^k=\frac{1}{2^k} s_{i,j} + (1-\frac{1}{2^k})s_{i,j}^*$ for all $i\in N$, $j\in[m]$. 
Clearly, this sequence converges to $\mathI^*$.
Moreover, for every instance $\mathI^k$ and all $j\in [m]$, it holds that $F(\mathI^k)_j=\frac{1}{n}\sum_{i\in N} s_{i,j}^k$ due to Step 2. 
Hence, we can infer by continuity that $F(\mathI^*)_j=\lim_{k\to\infty} F(\mathI^k)_j=\frac{1}{n}\sum_{i\in N} s_{i,j}^*$.
This shows that $F$ is \avg{}, as desired.
\end{proof}

\begin{remark}
    For both of our characterizations, all axioms are necessary. Every dictatorial aggregation rule, which always returns the score vector of a specific agent, satisfies all given axioms except anonymity. Every constant aggregation rule satisfies all given axioms except score-unanimity. \util{} satisfies all given axioms except independence and coordinate-wiseness. Furthermore, the coordinate-wise rule defined by the coordinate-aggregation function $f_j(\mathI)=1$ if there is an agent $i$ with $s_{i,j}=1$ and $f_j(\mathI)=\frac{1}{n}\sum_{i\in N} s_{i,j}$ otherwise satisfies all axioms except independence and continuity.
    Finally, the condition that $m\geq 3$ is necessary for our first characterization as independence becomes otherwise trivial and, e.g., \util{} satisfies all given axioms, and the condition that $m\geq 4$ is necessary for the second characterization because \med{} satisfies all conditions if $m\leq 3$. 
\end{remark}

\begin{remark}
    One can check that in our first characterization, it is possible to replace score-unanimity and anonymity with score-representation. That is, \avg{} is the only aggregation rule that satisfies score-representation and independence. The reason for this is that all key steps of our proof still work when using score-representation instead of anonymity and score-unanimity. 
    In particular, for instances of the form $\tilde \mathI^1$, we obtain from score-representation that candidate $c_{j_1}$ receives probability at least $\frac{\gamma}{n}$, candidate $c_{j_2}$ receives probability at least $1-\gamma$, and candidate $c_{j_3}$ receives probability at least $\frac{(n-1)\gamma}{n}$.
    Since the probabilities must sum up to $1$, this is only possible if all of these bounds are tight.
    By independence and the fact that this argument does not depend on the identities of agents or candidates, this immediately completes the proof of Steps~1 and 2.
    
    
    Perhaps surprisingly, this claim does not hold for our second characterization as the coordinate-wise rule, whose coordinate-aggregation functions assign to each candidate the minimum probability that meets the requirements imposed by score-representation, satisfies score-representation, anonymity, and continuity. 
\end{remark}

\begin{remark}
    Another natural way to characterize \avg{} is to rely on convexity. Specifically, we say that an aggregation rule $F$ is \emph{weakly convex} if $F(\mathI'')=F(\mathI)$ for all instances $\mathI$, $\mathI'$, and $\mathI''$ such that $F(\mathI)=F(\mathI')$ and there exists $\lambda\in (0,1)$ with $s_{i,j}''=\lambda s_{i,j} + (1-\lambda) s_{i,j}'$ for all $i\in N$, $j\in [m]$. Then, one can show that \avg{} is the only aggregation rule that satisfies weak convexity, anonymity, and score-unanimity. The idea is that for every instance $\mathI$, we can permute it with every permutation $\pi:N\rightarrow N$ and then take the average of all permuted instances. This results in an instance $\mathI'$ where all agents assign probability $\frac{1}{n}\sum_{i\in N} s_{i,j}$ to each candidate $c_j$. Hence, score-unanimity requires $F(\mathI')_j=\frac{1}{n}\sum_{i\in N} s_{i,j}$, and weak convexity and anonymity imply that the same holds for $\mathI$. 
\end{remark}

\begin{remark}
    All coordinate-wise (and anonymous) rules from \Cref{tab:summary} violate Pareto-optimality. Intuitively, this does not come as a surprise as correlations between scores and Pareto improvements cannot be taken into account by coordinate-wise rules. Formally, the proof of \Cref{lem:indavg} shows that any coordinate-wise, anonymous, and score-unanimous (which is necessary for Pareto-optimality) rule has to coincide with \avg{} on all instances with $s_{i,j} \neq 1$ for all $i,j$. It is not difficult to see---e.g., by adapting the instance $\mathcal{I}^1$ in the proof of \Cref{thm:efficiencyprops}---that no such rule satisfies Pareto-optimality. 
\end{remark}

\section{Conclusion}

In this paper, we have analyzed aggregation rules for portioning with cardinal preferences from an axiomatic perspective.
Specifically, we considered a natural model in which each agent reports her ideal distribution of a homogeneous resource over a set of candidates and her disutility for a distribution corresponds to the $\ell_1$ distance from her ideal distribution.
We investigated rules based on coordinate-wise aggregation or welfare aggregation as well as the independent markets rule of \citet{freeman2021truthfulbudget} with respect to efficiency, fairness, consistency, and incentive properties.
Our results, which are summarized in \Cref{tab:summary}, show that the rule that simply returns the average of the agents' reports satisfies most of the studied axioms.
In particular, even though this rule violates strategyproofness and Pareto-optimality, it is the only rule among the ones we considered that fulfills the strong fairness notion of score-representation as well as the strong consistency property of independence.
To further strengthen this point, we provided two characterizations demonstrating that the average rule is the only rule within large classes of rules that satisfies, for example, independence and score-unanimity at the same time.

We believe that our paper can serve as a basis for extensive future research in the domain of cardinal portioning.
For instance, the insights that our findings offer may be helpful toward characterizations of further rules.
It would also be interesting to examine additional axioms, especially those concerning fairness, which is important but arguably not yet well-understood in this setting.
One such axiom is membership in the \emph{core}, which intuitively means that no subset of agents can guarantee a better outcome (in the sense of a Pareto improvement) by using their proportional share of the resource.
The core strengthens both Pareto-optimality (since the latter makes this requirement only for the set of all agents) and single-minded proportionality, so \Cref{tab:summary} immediately implies that none of the rules we considered always returns an outcome in the core.
Whether any such rule exists is therefore an intriguing question which we leave for future work.

\section*{Acknowledgments}
 This work was partially supported by the AI Programme of The Alan Turing Institute, by the Deutsche Forschungsgemeinschaft under grants BR 2312/11-2 and BR 2312/12-1, by the Singapore Ministry of Education under grant number MOE-T2EP20221-0001, by the NSF-CSIRO grant on ``Fair Sequential Collective Decision-Making'' (RG230833), and by an NUS Start-up Grant.
We thank the anonymous reviewers of ECAI 2023 for constructive feedback and Erel Segal-Halevi for insightful comments.

\bibliographystyle{plainnat}
\bibliography{abb,main,group}

\appendix

\section{Appendix: Computational Aspects}

In this appendix, we prove two claims about computational aspects that were made in the main body. 
First, we show that \egal{} (including the leximin tie-breaking) can be computed in polynomial time. 

\begin{proposition}\label{thm:egal_compute}
    \emph{\egal{}} can be computed in polynomial time.
\end{proposition}
\begin{proof}
    Similar to \citet[Alg.~1]{airiau2019portioning}, we formulate a series of linear programs (LP) for finding an \egal{} outcome. Let the objective function be
    \begin{equation*}
        \text{minimize } \xi
    \end{equation*}
    \noindent
    subject to the following constraints.
    \begin{enumerate}[label=(\arabic*),topsep=4pt,itemsep=0pt]
    \item $\sum_{j \in [m]} x_j = 1$.
        
    \item $x_j \geq 0 \text{ for each $j\in [m]$ and } \xi \geq 0$.
    
    \item $z_{i,j} \geq s_{i,j} - x_j \text{ and } z_{i,j} \geq x_j - s_{i,j}$ for each $i\in N$, $j\in [m]$.
    
    \item $\sum_{j \in [m]} z_{i,j} \leq \xi$ for each $i\in N$.
    \end{enumerate}
    
    This allows us to minimize the largest disutility~$\xi$. There is an agent $i$
    that has disutility $\xi$ in every leximin outcome: 
    indeed, if for every $i\in N$ there is an outcome in which $i$ incurs disutility less than $\xi$ and every other agent incurs disutility at most $\xi$, then by averaging these outcomes across all $i\in N$, we obtain an outcome in which every agent's disutility is less than $\xi$, contradicting the choice of $\xi$.
    To find such an agent, for each $i\in N$, we formulate an LP that computes the maximum $\delta$ for which there exists an outcome such that agent~$i$ incurs disutility at most $\xi - \delta$ while every other agent incurs disutility at most $\xi$; an agent with the desired property will return $\delta = 0$.
    We fix the disutility of this agent to $\xi$, and continue by finding the second largest disutility, and so on.
    The total number of LPs is $\mathcal{O}(n^2)$.
\end{proof}

Next, we prove that checking whether an outcome is Pareto-optimal can be done in polynomial time. 

\begin{proposition} \label{thm:po_check}
    Determining whether an outcome~$\mathbf{x}'$ is Pareto-optimal can be done in polynomial time.
\end{proposition}
\begin{proof}
    Suppose we are given an outcome $\mathbf{x}'$ for an instance $\mathcal{I} = (\mathbf{s}_1,\dots, \mathbf{s}_n)$ and we want to determine whether ${\mathbf x}'$ is Pareto-optimal.

    For each $i \in N$ and $j \in [m]$, let $z'_{i,j} = |x'_j - s_{i,j}|$. The quantities $z'_{i,j}$ and $s_{i,j}$ can be computed from the input, and will appear in the constraints of the linear program below.
    
    We formulate a linear program as follows:
    \begin{equation*}
        \text{minimize } \sum_{i \in N} \sum_{j \in [m]} z_{i,j}, 
    \end{equation*}    
    subject to the following constraints.
    \begin{enumerate}[label=(\arabic*),topsep=4pt,itemsep=0pt]
    \item $\sum_{j \in [m]} x_j = 1$.
    
    \item $x_j \geq 0$ for each $j\in [m]$.
    
    \item $z_{i,j} \geq s_{i,j} - x_j \text{ and } z_{i,j} \geq x_j - s_{i,j}$ for each $i \in N$, $j \in [m]$.
    
    \item $\sum_{j \in [m]} z_{i,j} \leq \sum_{j \in [m]} z'_{i,j}$ for each $i\in N$.
    \end{enumerate}
        
    Note that $z_{i,j}$ is an upper bound on $i$'s disutility for candidate $c_j$, so the smaller it is, the better.
    Then, for the optimal solution $(z^*_{i,j})_{i\in N,\, j\in [m]}$ returned, if $\sum_{j \in [m]} z^*_{i,j} < \sum_{j \in [m]} z'_{i,j}$ for some $i \in N$,
    we know that $\mathbf{x}'$ is not Pareto-optimal; otherwise it is.
\end{proof}

\end{document}


