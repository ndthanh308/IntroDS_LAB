
The quantitative results on the synthetic dataset are shown in Table~\ref{result:syn}.  
%
Among all the models assessed, OAFuser17 attains the highest mIoU. Comparatively, OAFuser9 exhibits slightly inferior performance to LF-IENet$^3$. This discrepancy in performance can be primarily attributed to the restricted size of the synthetic dataset, encompassing merely $173$ samples for training purposes.
% Figure environment removed
%
In concrete terms, OAFuser makes use of the small differences present among different sub-aperture images to capture intricate angular details. These details are then combined with the appropriate spatial information obtained from the main viewpoint. This approach differs from previous methods that mainly focus on spatial information limited to the central view and overlook the angular information available from the light field camera.
%
Additionally, a key feature of OAFuser is its ability to eliminate the need for pre-processing of initial light field images, showcasing its capability to handle raw light field data by effectively utilizing various angular information. Importantly, when using fully focused images from synthetic datasets, the network's processing capabilities are not adequately demonstrated. 
Furthermore, it can be clearly seen from Fig.~\ref{fig:syn} in areas of complex structures, such as the leaves and bicycle pillion seats. Compared with LF-IENet, which leads to loss of global context for objects, such as the gaps between objects and their connection with branches being disrupted, our approach demonstrates better segmentation results even with $17$ sub-aperture images. This means the excellent performance of our network to utilize sub-aperture images and, by rectification, OAFuser remains consistent with the information captured from different points of view. This claim has been also supported by thorough experiments conducted on both the UrbanLF-Real dataset and the UrbanLF-RealE dataset.
%


