\begin{table}[t!]
\centering
\renewcommand{\arraystretch}{1.4}
\setlength{\tabcolsep}{2pt}
\begin{adjustbox}{width=0.48\textwidth}
\centering
\begin{tabular}{l|c| cc| c}
\toprule[1mm]
\textbf{Method} & \textbf{Type} & \textbf{Acc (\%)} & \textbf{mAcc (\%)} & \textbf{mIoU (\%)} \\ \midrule[1.5pt]\hline

PSPNet~\cite{zhao2017pyramid} & RGB & 91.21 & 83.87 & 76.34 \\
$\text{DeepLabv3}^+$~\cite{chen2018encoder} & RGB & 91.02 & 83.53 & 76.27  \\
{SETR}~\cite{zheng2021rethinking} & RGB & 92.16 & 84.27 & 77.74\\ 
{OCR}~\cite{yuan2020object} & RGB & 92.02 & 85.17 & 78.60 \\ 
{Accel}~\cite{jain2019accel} & Video & 89.15 & 80.69 & 71.64 \\ 
{TDNet}~\cite{hu2020temporally} & Video & 91.05 & 83.38 & 76.48 \\ 
{DAVSS}~\cite{zhuang2020video} & Video & 91.04 & 83.54 & 75.91 \\ 
{TMANet}~\cite{wang2021temporal} & Video & 91.67 & 84.13 & 77.14 \\ 
{PSPNet-LF}~\cite{sheng2022urbanlf} & LF & 92.14 & 84.86 & 78.10 \\
{OCR-LF}~\cite{sheng2022urbanlf} & LF & 92.51 & 86.31 & 79.32 \\ 
{LF-IENet$^4$}~\cite{cong2023combining} & LF & 92.01 & 85.10 & 78.09 \\ 
{LF-IENet$^3$}~\cite{cong2023combining} & LF & 92.09 & 86.03 & 79.19 \\ \hdashline[1pt/1pt]
\textbf{OAFuser9} & LF & {\color[HTML]{FF0000}\textbf{94.45 (+1.94)}} & {\color[HTML]{FF0000}\textbf{88.21 (+1.90)}} & {\color[HTML]{FF0000}\textbf{82.69 (+3.37)}} \\ 
\textbf{OAFuser17} & LF & 94.08 (+1.52) & 87.74 (+1.43) & 82.21 (+2.89) \\ 
\hline %\bottomrule[1mm]
\end{tabular}
\end{adjustbox}
\caption{Quantitative results on the UrbanLF-Real dataset. Acc (\%), mAcc (\%), and mIoU (\%) are reported. The best results are highlighted in red. The variation term indicates the performance difference from the previous best result.}
\label{result:real}
\end{table}

The image size for UrbanLF-Syn is $640{\times}480$ while applying zero padding converts samples in UrbanLF-Real into a size of $640{\times}480$.
Data augmentation is applied with random flipping with a probability of $0.5$, random scaling factors $\{0.5, 0.75, 1, 1.25, 1.5, 1.75\}$, normalization with mean factors $\{0.485, 0.456, 0.406\}$, and standard deviation factors $\{0.229, 0.224, 0.225\}$.
We use the AdamW optimizer with momentum parameters $\{0.9, 0.999\}$ and a weight decay of $0.01$.
The original learning rate is set to ${6e}^{-5}$ and scheduled using the polynomial strategy with a power of $0.9$.
The first $10$ epochs are used to warm up the models.

For experiments on the three different datasets, the training process adapts on three A40 GPUs with a batch size of $3$ on each GPU and the number of training epochs is limited to a maximum of $500$, and the model is based on the MiT-B4 per-train weight~\cite{xie2021segformer}.
For the ablation study of architecture, we train our model with MiT-B2~\cite{xie2021segformer} on one A5000 GPU with a batch size of $2$ and epoch $200$.
With the MiT-B0~\cite{xie2021segformer} on one A5000 GPU with a batch size of $2$, we conduct an ablation study on the CARM and the investigation on the selection of sub-aperture images.
For the selection of sub-aperture images, we choose images that are rich in angular information, mostly in the diagonal, as shown in Fig.~\ref{fig:array}. The experiments on the selection strategy of sub-aperture light-field images are discussed in Sec.~\ref{sec:5_d_select}.

