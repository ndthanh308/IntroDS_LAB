%
\begin{table}[t!]
\renewcommand{\arraystretch}{1.2}
\begin{adjustbox}{width=0.48\textwidth}
\centering
\setlength{\tabcolsep}{10pt}
\begin{tabular}{c|c|c}
\toprule[1mm]
\textbf{Method}           & \textbf{mIoU} & \textbf{Improvement}
\\ \midrule[1.5pt] \hline
CMX MiT-B0~(RGB V11)~\cite{zhang2022cmx}& 68.40    & \\  \hdashline[1pt/1pt]
OAFuser2 MiT-B0  & 71.17    & +2.77\\ 
OAFuser5 MiT-B0& 71.92   & +3.52 \\
OAFuser9 MiT-B0& 72.57  & +4.17\\
OAFuser13 MiT-B0& 72.60  & +4.20 \\
OAFuser17 MiT-B0& \color[HTML]{FF0000}\textbf{72.87}  & +4.47  \\
{OAFuser21} MiT-B0& 72.22  & +3.82 \\ \hdashline[1pt/1pt]
OAFuser17~MiT-B4& \color[HTML]{FF0000} \textbf{81.93}   & +13.53 \\\hline
\end{tabular}
\end{adjustbox}
\caption{
%
Exploration of the contribution of different numbers of sub-aperture images. mIoU~(\%) is reported. V11 denotes the sub-aperture image from the top-left viewpoint. The best results are highlighted in red.}
\label{tab:Sub-aperture images}
\end{table}

{{To demonstrate that a more significant number of sub-aperture images, as compared to a single image, can provide more effective information for scene understanding, several experiments are conducted.}} As shown in Table~\ref{tab:Sub-aperture images}, compared with our baseline method CMX~\cite{zhang2022cmx}, which is designed for similar modalities fusion, our OAFuser achieves an increase of more than $2\%$ in mIoU.
This result further confirms the effectiveness of our design in handling asymmetric data from the {LF} camera for segmentation tasks.
Furthermore, our network perceives the scene from multiple perspectives, and with increased viewpoints, it achieves progressively higher accuracy. {This also showcases our network's capacity to harness angular information and underscores the importance of leveraging a higher count of sub-aperture images for the segmentation task. Moreover, under the same model, the performance continually improves with the incremental addition of sub-aperture images, further validating the efficacy of sub-aperture images' extraction and utilization in enhancing road scene understanding.} OAFuser reaches its peak at OAFuser17. 
