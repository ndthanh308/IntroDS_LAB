\begin{table*}[t]
  \centering
  \LARGE
  \renewcommand{\arraystretch}{1.8}
  \begin{adjustbox}{width=1\textwidth}
\begin{tabular}{c|c|cccccccccccccccccc}
    \toprule[2mm]

\multirow{2}{*}{\textbf{Dataset}} & \multirow{2}{*}{\textbf{Method}} & \multicolumn{14}{c|}{\textbf{IoU}} & \multicolumn{1}{c|}{\multirow{2}{*}{\textbf{Acc}}} & \multicolumn{1}{c|}{\multirow{2}{*}{\textbf{mAcc}}} & \multirow{2}{*}{\textbf{mIoU}} \\ \cline{3-16}
 &  & \multicolumn{1}{c|}{\textbf{Bike}} & \multicolumn{1}{c|}{\textbf{Building}} & \multicolumn{1}{l|}{\textbf{Fence}} & \multicolumn{1}{c|}{\textbf{Others}} & \multicolumn{1}{c|}{\textbf{Person}} & \multicolumn{1}{l|}{\textbf{Pole}} & \multicolumn{1}{c|}{\textbf{Road}} & \multicolumn{1}{c|}{\textbf{Sidewalk}} & \multicolumn{1}{l|}{\textbf{Traffic Sign}} & \multicolumn{1}{c|}{\textbf{Vegetation}} & \multicolumn{1}{c|}{\textbf{Vehicle}} & \multicolumn{1}{c|}{\textbf{Bridge}} & \multicolumn{1}{c|}{\textbf{Rider}} & \multicolumn{1}{c|}{\textbf{Sky}} & \multicolumn{1}{c|}{} & \multicolumn{1}{c|}{} &  \\ \midrule[3pt]\hline

%
\multicolumn{1}{l|}{\multirow{3}{*}{RealE}} & \multicolumn{1}{l|}{Proportion} & 2.27 & 33.48 & 3.86 & 1.59 & 3.08 & 1.42 & 21.36 & 8.00 & 0.65 & 3.05 & 16.46 & 2.34 & 0.24 & 2.19 & n.a. & n.a. & n.a. \\ \cline{2-19}
\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{CMX MiT-B4} & 86.88 & 90.52 & 76.27 & 43.47 & 91.31 & 73.47 & 90.74 & 68.70 & 86.22 & 85.21 & 96.45 & 74.33 & 69.15 & 96.61 & 93.00 & 87.00 & 80.66 \\ \cdashline{2-19}
\multicolumn{1}{l|}{} & \multicolumn{1}{l|}{OAFuser9} & 87.92 & 91.95 & 87.64 & 48.56 & 93.63 & 77.55 & 91.74 & 71.92 & 87.43 & 89.04 & 97.05 & 88.89 & 79.03 & 96.61 & 94.61 & 89.84 & \color[HTML]{FF0000} \textbf{84.93~(+4.55)} \\ \hline
\end{tabular}
\end{adjustbox}
\caption{Per-class statistics of CMX and OAFuser on the UrbanLF-RealE dataset are presented. \textit{Proportion} represents the class percentage, and the values are given in percentage (\%). The best result is highlighted in red.}
\label{tab:propotion}
\end{table*}

%

To comprehensively assess the model's performance per class and delve deeper into the improvement achieved by our model in comparison with the baseline method, we present a summary of statistical information from different methods in Table~\ref{tab:propotion}. Moreover, the class proportion assisting in data analysis is also introduced.

Given that our baseline method, CMX~\cite{zhang2022cmx}, is designed for two modalities, we first aggregate the sub-aperture images before feeding them into the network. It can be seen that OAFuser significantly outperforms the baseline method across various categories, such as \textit{fence, pole, sidewalk, vehicle, bridge} and \textit{rider}, which are crucial for the road system in urban scenarios. {Significantly, the recognition capability for \textit{vehicle} even exceeds $97\%$ in IoU.}

Those results prove the achievement of our proposed model for segmentation tasks in urban scenes. By incorporating SAFM and CARM, the network unleashes the potential of the angle information from different sub-aperture images and leverages the consistency of variations among sub-aperture images. This enables OAFuser to deliver promising performance.


