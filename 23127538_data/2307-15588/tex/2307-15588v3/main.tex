\documentclass[journal]{IEEEtran}
%
    
\usepackage{blindtext}

%-----------------------
\usepackage[table, dvipsnames]{xcolor}

\usepackage{amsmath,amssymb,amsfonts,bm}
\usepackage{lipsum}
\usepackage{times}
\usepackage{epsfig}

\usepackage{stfloats}
\usepackage{multicol}
\usepackage[inline]{enumitem}
\usepackage{algorithmic}
\usepackage{graphicx,subcaption}
\usepackage{textcomp}

\usepackage{booktabs}
\usepackage{multirow}

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{float}
\usepackage{adjustbox}
\usepackage{array}
\usepackage{dsfont}
\usepackage{fontawesome}


%\usepackage{subfig}

\usepackage{pifont}% for marks
\newcommand{\cmark}{\ding{51}}%
\newcommand{\xmark}{\ding{55}}%
\usepackage{paralist}
\usepackage[ruled,linesnumbered]{algorithm2e}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  extra package  TF
\usepackage{arydshln}
\newcolumntype{C}[1]{>{\centering\arraybackslash}p{#1}}
\newcommand{\TF}[1]{\textcolor{blue}{#1}}
\usepackage{pifont}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  end extra package  TF
%
\usepackage[accsupp]{axessibility}  % Improves PDF readability for those with disabilities.

\usepackage{tabulary}
\newcommand\ver[1]{\rotatebox[origin=c]{90}{#1}}
\newcommand{\fl}[1]{\multicolumn{1}{c}{#1}}
\definecolor{gray}{rgb}{0.3,0.3,0.3}
\definecolor{blue}{rgb}{0,0.5,1}
\definecolor{mask_red}{rgb}{1,0,0.8}
\definecolor{green}{rgb}{0.2,1,0.2}
\definecolor{rblue}{rgb}{0,0,1}
\newcommand{\gray}[1]{\textcolor{gray}{#1}}
\newcommand{\green}[1]{\textcolor[RGB]{96,177,87}{#1}}
\newcommand{\fn}[1]{\footnotesize{#1}}
\newcommand{\gbf}[1]{\green{\bf{\fn{(#1)}}}}
\newcommand{\rbf}[1]{\gray{\bf{\fn{(#1)}}}}

\usepackage{hyperref}
\hypersetup{colorlinks=true,linkcolor=red,citecolor=blue}

\newcommand{\YKL}[1]{\textcolor{red}{#1}}
\newcommand{\PKY}[1]{\textcolor{purple}{#1}}
\newcommand{\revised}[1]{\textcolor{black}{#1}}


% Add a period to the end of an abbreviation unless there's one
% already, then \xspace.
\makeatletter
\DeclareRobustCommand\onedot{\futurelet\@let@token\@onedot}
\def\@onedot{\ifx\@let@token.\else.\null\fi\xspace}

\def\eg{\emph{e.g}\onedot} \def\Eg{\emph{E.g}\onedot}
\def\ie{\emph{i.e}\onedot} \def\Ie{\emph{I.e}\onedot}
\def\cf{\emph{c.f}\onedot} \def\Cf{\emph{C.f}\onedot}
\def\etc{\emph{etc}\onedot} \def\vs{\emph{vs}\onedot}
\def\wrt{w.r.t\onedot} \def\dof{d.o.f\onedot}
\def\etal{\emph{et al}\onedot}

\begin{document}

\title{OAFuser: Towards Omni-Aperture Fusion for Light Field Semantic Segmentation}
\author{Fei Teng\IEEEauthorrefmark{1}, Jiaming Zhang\IEEEauthorrefmark{1}, Kunyu Peng, Yaonan Wang, Rainer Stiefelhagen, and Kailun Yang\IEEEauthorrefmark{2}%
\IEEEcompsocitemizethanks{
\IEEEcompsocthanksitem 
This work was supported in part by the National Natural Science Foundation of China (No. 62473139), in part by Hangzhou SurImage Technology Company Ltd., in part by the Ministry of Science, Research and the Arts of Baden-WÃ¼rttemberg (MWK) through the Cooperative Graduate School Accessibility through AI-based Assistive Technology (KATE) under Grant BW6-03, and in part by the Helmholtz Association Initiative and Networking Fund on the HAICORE@KIT and HOREKA@KIT partition.
\IEEEcompsocthanksitem F. Teng, Y. Wang, and K. Yang are with the School of Robotics and the National Engineering Research Center of Robot Visual Perception and Control Technology, Hunan University, Changsha 410082, China.
\IEEEcompsocthanksitem J. Zhang, K. Peng, and R. Stiefelhagen are with the Institute for Anthropomatics and Robotics, Karlsruhe Institute of Technology, 76131 Karlsruhe, Germany.
\IEEEcompsocthanksitem J. Zhang is also with the Institute for Visual Computing, ETH Zurich, 8092 Zurich, Switzerland.
%
\IEEEcompsocthanksitem \IEEEauthorrefmark{1}Equal contribution.
\IEEEcompsocthanksitem \IEEEauthorrefmark{2}Corresponding author (E-Mail: kailun.yang@hnu.edu.cn.).
}%
}

\markboth{IEEE Transactions on Artificial Intelligence, September~2024}%
{Teng \MakeLowercase{\textit{et al.}}: OAFuser}

\maketitle

%\bstctlcite{IEEEexample:BSTcontrol}
%
%%%%%%%%% ABSTRACT
\begin{abstract}
\input{Contents/Abstract}



\end{abstract}

\begin{IEEEImpStatement}
\input{Contents/Statement}
\end{IEEEImpStatement}
%
\begin{IEEEkeywords} 
Semantic segmentation, light field, scene parsing, vision transformers, scene understanding.
\end{IEEEkeywords}

\IEEEpeerreviewmaketitle
%%%%%%%%% BODY TEXT
\vspace{1em}
\section{Introduction}
\input{Contents/Introduction}

\section{Related Work}
\input{Contents/Related_Work}

\section{Methodology}
\input{Contents/Methodology/Overall_Structure}

\subsection{Sub-Aperture Fusion Module}\label{sec:3_B_sf}
\input{Contents/Methodology/SAFM}

\subsection{Central Angular Rectification Module}\label{sec:3_c_ro}
\input{Contents/Methodology/CARM}

\section{Experiment Results}
\revised{To verify the effectiveness of the proposed model, we collected all UrbanLF datasets \revised{described} in Sec.~\ref{sec:4_1_da}. To ensure the reproducibility of our experiments, the training parameters are described in Sec.~\ref{sec:4_2_Im}. Quantitative and qualitative results are presented in Sec.~\ref{sec:4_3_Qua}. Note that, we achieved the best results across various datasets on various evaluation criteria.}
\subsection{Datasets}\label{sec:4_1_da}
\input{Contents/Experiment_Results/Datasets}

\subsection{Implementation Details}
\input{Contents/Experiment_Results/Implement_Details} \label{sec:4_2_Im}

\subsection{Experiments Results} \label{sec:4_3_Qua}
To verify \revised{the proposed} methods, we compare OAFuser with other methods, including RGB-based methods~\cite{chen2018encoder,zhao2017pyramid,zheng2021rethinking,yuan2020object}, video-based light field semantic segmentation methods~\cite{zhuang2020video,wang2021temporal,jain2019accel,hu2020temporally}, and several specific designs for light field semantic segmentation~\cite{sheng2022urbanlf,cong2023combining,cong2024end} on different datasets, \ie, {UrbanLF-Real, UrbanLF-Syn, UrbanLF-Syn-Big, and UrbanLF-RealE}. \revised{Because test data are not provided, all results are based on the validation dataset. We extended the experiments of {LF-IENet} and {LF-IENet++}. OAFuser is currently the method validated on the most comprehensive dataset.}

\subsubsection{Results on UrbanLF-Real} 
\input{Contents/Experiment_Results/Result_on_UrbanLF_Real/Result_on_UrbanLF_Real}

\subsubsection{Results on UrbanLF-Syn} 
\input{Contents/Experiment_Results/Result_on_UrbanLF_Syn/Result_on_UrbanLF_Syn}

\subsubsection{Results on UrbanLF-RealE} 
\input{Contents/Experiment_Results/Result_on_UrbanLF_RealE/Result_on_UrbanLF_RealE}

\subsubsection{Results on UrbanLF-Syn-Big}
\input{Contents/Experiment_Results/Result_on_UrbanLF_SBig}

\section{Ablation Studies}
{{In this section, \revised{we present several ablation conducted studies} to confirm the impact of different modules in the proposed method, discuss the float-point operation with the proposed network compared with other methods, and delve deeply into the network structure.}~Specifically, 
the experiments are carried out in Sec.~\ref{sec:5_a_model} to thoroughly investigate the effects of diverse components \revised{{incorporated in the proposed} method.~Furthermore, 
to assess the performance efficiency of the network}, we conduct ablation experiments, which are discussed in Sec.~\ref{sec:5_d_select}. Here, we discuss OAFuser and previous methods in terms of GFlops. \revised{In addition}, we explore the relationship between the number of SAIs and accuracy in this section.~
\revised{Furthermore, we present several experiments} in Sec.~\ref{sec:5_a_ma} to determine the optimal combination in the CARM. After that, we compare the impact of different datasets in Sec.~\ref{sec:5_DCPC} and analyze the per-class performance in Sec.~\ref{sec:5_c_per}. Moreover, a visual failure case analysis \revised{is resented} in Sec.~\ref{sec:5_e_fc}.}

\subsection{Ablation Study for the Overall Model}\label{sec:5_a_model}
\input{Contents/Ablation_Study/Model_Ablation}  

\subsection{Computational Cost Analysis and the Investigation \revised{of} the Selection of Sub-Aperture Images} \label{sec:5_d_select}

\input{Contents/Ablation_Study/Selection_of_Sub_aperture_image}

\subsection{Ablation Study for CARM} \label{sec:5_a_ma}
\input{Contents/Ablation_Study/Attention_Ablation}

\subsection{Dataset Comparison} \label{sec:5_DCPC}
\input{Contents/Ablation_Study/Dataset_Comparison}

\subsection{Per-Class Accuracy Analysis} \label{sec:5_c_per}
\input{Contents/Ablation_Study/Per_class_accuracy_analysis} 

\subsection{Failure Case Analysis} \label{sec:5_e_fc}
\input{Contents/Ablation_Study/Failure_Case_Analysis} 

\section{Conclusion}
\input{Contents/Conclusion}

\vspace{3em}
\bibliographystyle{IEEEtran}
\bibliography{bib}

\end{document}
