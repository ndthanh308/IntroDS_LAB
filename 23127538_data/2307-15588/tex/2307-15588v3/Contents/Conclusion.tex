In this study, we explore the potential of LF cameras for road scene understanding via semantic segmentation.
%
We propose an innovative paradigm, the Omni-Aperture Fusion (OAFuser), \revised{to effectively exploit dense contexts} and angular information from LF apertures. 
{The Sub-Aperture Fusion Module (SAFM) is introduced, which allows the network to embed angular information from LF cameras. Each \revised{SAI incurs} minimal computational cost and does not require additional parameters.}
\revised{The introduced CARM enables the proposed network to utilize misaligned features from different viewpoints}. 
%
The proposed framework overcomes data redundancy limitations and establishes a new baseline for further LF exploration.

\revised{In future work, we strive to establish a benchmark with more categories and a larger set of training samples to assess the accuracy of using light field cameras for different scenarios. In particular, the implementation of LF for the indoor scenario. Moreover, how to leverage the characteristics of micro-lenses for the restoration of central images in harsh environments (\ie, heavy rain, snow) remains to be studied. Another under-explored area is exploring how to leverage numerous SAIs for other scene parsing tasks, \ie, object detection.}