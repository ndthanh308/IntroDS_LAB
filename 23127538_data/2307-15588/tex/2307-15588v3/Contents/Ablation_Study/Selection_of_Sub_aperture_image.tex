\begin{table}[b]
\renewcommand{\arraystretch}{1.2}
\begin{adjustbox}{width=0.48\textwidth}
\centering
\setlength{\tabcolsep}{10pt}
\begin{tabular}{c|c|c|c}
\toprule[1mm]
\textbf{Method}           & \textbf{mIoU} & \textbf{Improvement} &\textbf{P-GFlops} 
\\ \midrule[1.5pt] \hline
CMX MiT-B0~(RGB V11)~\cite{zhang2022cmx}& 68.40    & N.A. &15.49 \\  \hdashline[1pt/1pt]
OAFuser2 MiT-B0  & 71.17    & +2.77&18.71\\ 
OAFuser5 MiT-B0& 71.92   & +3.52&9.56\\
OAFuser9 MiT-B0& 72.57  & +4.17&5.90\\
OAFuser13 MiT-B0& 72.60  & +4.20&4,33 \\
OAFuser17 MiT-B0& \color[HTML]{FF0000}\textbf{72.87}  & +4.47&3.46  \\
{OAFuser21} MiT-B0& 72.22  & +3.82&3.34 \\ \hdashline[1pt/1pt]
OAFuser17~MiT-B4& \color[HTML]{FF0000} \textbf{81.93}   & +13.53&15.60 \\\hline
\end{tabular}
\end{adjustbox}
\caption{
{Exploration of the contribution of different numbers of \revised{SAIs} and the computational resource \revised{per image} (GFlops divided by \revised{the number of} SAIs). mIoU~($\%$) and P-GFlops are reported. V11 denotes the SAI from the top-left viewpoint. The best results are highlighted in red.}}
\label{tab:Sub-aperture images}
\end{table}

{One crucial aspect of \revised{the} proposed method involves utilizing each SAI to achieve better performance with a lower computational load. To verify this, we conduct intra-comparison (the comparison between OAFuser and baseline methods) and inter-comparison (the comparison between OAFuser and other methods) \revised{experiments}.}

{First, we increased the number of SAIs to record the performance and the computational cost, which is presented in Table~\ref{tab:Sub-aperture images}. Compared with the baseline method CMX~\cite{zhang2022cmx}, which is designed for \revised{similar modality fusion}, our OAFuser achieves a more than $2\%$ increase in mIoU when processing the same number of SAIs. \revised{This result} demonstrates that multi-modal fusion methods that focus on using convolution and pooling operations to process and fuse multi-modal features are not suitable for LF images with disparity differences.
Although the computational cost per image increased by $3.22$ GFlops, the average GFlops per image significantly decreases when the proposed model processes multiple images. For instance, utilizing $17$ images, the average computational demand is only $4.47$ GFlops per image, which corresponds to a $4.47\%$ improvement in accuracy. \revised{Finally, the performance of the proposed model continually improves with the incremental addition of SAIs}, further validating the efficacy of extracting and utilizing SAIs to enhance road scene understanding.}

\revised{Table.~\ref{tab:Comput Cost}}, compares the computational costs \revised{of the} proposed method and previous state-of-the-art methods.~ 
First of all, we report the GFlops consumption of OAFuser when processing different SAIs. Subsequently, we compare mIoU, Params, and GFlops based on View5 and View33 using different methods. The input image size follows the previous work~\cite{cong2024end} and is $480{\times}480$. OAFuser, when using MIT-B4 pre-trained weights to process multiple images, achieves better performance while requiring far less \revised{computations than} other methods. \revised{In particular, with $33$ images}, the computational load \revised{of the proposed model} ($216.5$ GFlops) is only $5\%$ of that of LF-IENet++ ($5259.8$ GFlops). This is attributed to the structural paradigm of OAFuser, which performs angular feature fusion \revised{to avoid} deep feature extraction for multiple images. The feature alignment through pixel-level information rectification enables the \revised{proposed} network to exhibit better performance. \revised{Although the computational load of OAFuser is slightly lower than that of OCR-LF, its performance is significantly higher.}



%This strongly supports our initial design intention, which is to avoid the computational burden of processing multiple images through our network while achieving better performance. 
%{{To demonstrate that a more significant number of sub-aperture images, as compared to a single image, can provide more effective information for scene understanding, several experiments are conducted.}} As shown in Table~\ref{tab:Sub-aperture images}, compared with our baseline method CMX~\cite{zhang2022cmx}, which is designed for similar modalities fusion, our OAFuser achieves an increase of more than $2\%$ in mIoU.
%This result further confirms the effectiveness of our design in handling asymmetric data from the {LF} camera for segmentation tasks.
%Furthermore, our network perceives the scene from multiple perspectives, and with increased viewpoints, it achieves progressively higher accuracy. {This also showcases our network's capacity to harness angular information and underscores the importance of leveraging a higher count of sub-aperture images for the segmentation task. Moreover, under the same model, the performance continually improves with the incremental addition of sub-aperture images, further validating the efficacy of sub-aperture images' extraction and utilization in enhancing road scene understanding.} OAFuser reaches its peak at OAFuser17. 


\begin{table}[t!]
\renewcommand{\arraystretch}{1.2}
\begin{adjustbox}{width=0.48\textwidth}
\centering

\begin{tabular}{c|c|c|c|c|c|c}
\toprule[1mm]
\#Views    & 5     & 9         & 17     & 23     & 33      & 81      \\\hline 
OAFuser    & \color[HTML]{FF0000}{\faStar}188.6 & 192.9     & 201.5  & 205.8  & 216.5   & \color[HTML]{FF0000}{\faStar}271.2   \\ \midrule[1.5pt] \hline 
\multicolumn{4}{c|}{View5}               & \multicolumn{3}{|c}{View33} \\\hline 
Method     & mIoU  & Params(M) & GFlops & mIoU   & Params  & GFlops  \\\hline 
OCR-LF     & n.a   & n.a       & n.a    & 78.26  & 137.4   & 228.1   \\
PSPNet     & n.a   & n.a       & n.a    & 75.27  & 127.8   & 429.4   \\
LF-IENet   & 79.15 & 117.4     & 719.7  & 79.23  & 117.4   & 4783.5  \\
LF-IENet++ & 79.44 & 124.7     & 920.8  & 79.59  & 124.7   & 5259.8  \\  \hdashline
OAFuser    & \TF{80.51}      & 164.1     &\color[HTML]{FF0000}{\faStar}188.6  & \textbf{80.01}      & {164.1}   & \color[HTML]{FF0000}{\faStar}216.5     \\ \hline  
\end{tabular}
\end{adjustbox}
\caption{
{\revised{Comparison of} computational consumption \revised{of the proposed} method (MIT-B4) and other methods in processing different LF images. OAFuser \revised{exhibits} a minimal increase in computational demand for the network when handling various SAIs. In scenarios with view5 and view33, \revised{owing to the} implementation of the SAFM, which prevents images from undergoing multiple feature extractions, \revised{the computational load of OAFuser} is significantly lower than that of state-of-the-art methods.}}
\vspace{-0.5em}
\label{tab:Comput Cost}
\end{table}




