


\revised{To comprehensively assess the performance of the proposed model} per class and delve deeper into the improvement achieved by the model in comparison with the baseline method, we present a summary of statistical information from different methods in Table~\ref{tab:propotion}. \revised{The class proportion that assists} in data analysis is also introduced. Given that the baseline method, CMX~\cite{zhang2022cmx}, is designed for two modalities, we first aggregate the SAIs before feeding them into the network. It can be seen that OAFuser significantly outperforms the baseline method across various categories, such as \textit{fence, pole, sidewalk, vehicle, bridge} and \textit{rider}, which are crucial for the road systems in urban scenarios. \revised{Significantly, the recognition capability for \textit{vehicles} even exceeds $97\%$ in terms of IoU. } Those results \revised{demonstrate} the \revised{effectiveness} of the proposed model for segmentation tasks in urban scenes. By incorporating the SAFM and CARM, the proposed network \revised{exploits} the potential of the angle information \revised{obtained} from different SAIs and leverages the consistency of variations among SAIs. This enables OAFuser to exhibit promising performance.


