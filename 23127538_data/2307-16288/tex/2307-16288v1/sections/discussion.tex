\documentclass{article}
\begin{document}	
    To conclude our survey paper, we discuss the remaining challenges along with possible future directions for proactive predictions in storage systems.
    
    \begin{itemize}
        \item \textbf{Masking ML Failure in Systems:} As machine learning can never achieve 100\% accuracy, how should "ML-for-system" solutions mask the cases that cause big disruption of the system and machine learning fails to catch? LinnOS and SMARTer has made a successful attempt in marrying ML and existing system solutions (e.g., hedged request, redundancy scheme), but more attention is deserved.
        \item \textbf{AutoML:} If we apply ML to a general setting across a range of applications, just like what the MLSys paper did, a natural question is what model and hyperparameters should we choose for each different setting. Currently, MLSys simply conducts brute search, which is cumbersome and not scalable. AutoML techniques are likely to help in selecting the best model for different applications, drive types, etc. 
        \item \textbf{Model Portability:} Due to the heterogeneity of hardware and the frequent expansion of datacenters, portable ML models would be highly beneficial. The SMARTer paper showed that we can train the model on one site and deploy it on another with reasonable accuracy. However, can we train the model on certain device type and deploy it on another, e.g., training on SSDs and deploying on HDDs? How to develop more portable models? These questions are to be answered.
        \item \textbf{Lifelong Learning:} Due to the everlasting changes in observed workload of each device, long term deployment of ML models in systems requires them to learn from new observations continuously. While LinnOS utilizes model recalibration to adapt to the significant changes, which actually did not happen in LinnOS's experiment, more interesting questions need to be answered. For example, when we encounter an unseen workload, can we pull a model out from a repository of models which are already trained for different workloads? Can we utilize online ML algorithms to adapt to the changes? How to not forget what is already learnt?
        \item \textbf{Unbalanced Data:} The problem of data imbalance is particularly severe in failure prediction for storage systems, since drive failures (positive samples) only account for less than 10\% of the data. Thus, high false negative rates are common for failure prediction. The SMARTer paper also observed this with the S group. However, the false negative rate miraculously decreased for the SPL group without further model modification. Several questions are still not explored in the systems field: Does down-sampling negative samples help boost prediction accuracy? What ML techniques can we utilize to cope with data imbalance?
    \end{itemize}
    
    \ifcsdef{mainfile}{}{\bibliography{../references/main}}
\end{document}