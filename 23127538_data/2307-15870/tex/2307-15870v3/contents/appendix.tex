\begin{appendices}
\label{appendix}
\setcounter{section}{0}
\setcounter{lemma}{0}
\setcounter{theorem}{0}
\setcounter{equation}{0}
% \renewcommand\thesection{\arabic{section}}
% \renewcommand\theequation{A.\arabic{equation}}
\section{}
\subsection{Proof of Theorem \ref{theorem1}}
\setcounter{section}{0}
\setcounter{lemma}{0}
\setcounter{theorem}{0}
\setcounter{equation}{0}
% \renewcommand\thesection{\arabic{section}}
% \renewcommand\theequation{A.\arabic{equation}}
% \section{}
% \subsection{Proof of Theorem \ref{theorem1}}
\begin{theorem} 
\label{apx-theorem1}
The sequence of outputs $\{\boldsymbol{w}^{h, k}\}$ generated by supervised training and global aggregation satisfies:
\begin{equation}
    \underset{h \in [H], k \in \{0, \cdots, K_s\}}{\min} {\mathbb{E} \Vert \nabla F(\boldsymbol{w}^{h, k}) \Vert^2} 
    \leq \frac{2(F(\boldsymbol{w}^0) - F(\boldsymbol{w}^*))}{\eta_1 H K_s} 
    +\Phi.
    \nonumber
\end{equation}
where $\Phi \triangleq (\frac{L^2(K_u-1)(2K_u-1)\eta_1^2}{3K_s} + \frac{LK_u^2 \eta_1^3}{K_s} + 1) G_u^2 + (L \eta_1 + \frac{2 K_u}{K_s}) G_s^2$.
\end{theorem}

\emph{Proof:} 
First, for the model trained on the supervised stage, according to Lipschitz smoothness property in Assumption \ref{assump1}, we have:
\begin{equation}
\begin{split}
    & \mathbb{E} [F(\boldsymbol{w}^{h, k+1})] - \mathbb{E} [ F(\boldsymbol{w}^{h , k})]  \\
    & \leq -\eta_h \mathbb{E} \langle \nabla F(\boldsymbol{w}^{h, k}),  \tilde{\nabla} f_{s}(\boldsymbol{w}^{h, k}) \rangle 
     + \frac{L \eta_h^2}{2} \mathbb{E} [\Vert \tilde{\nabla} f_{s}(\boldsymbol{w}^{h, k}) \Vert^2]
    \nonumber
\end{split}
\end{equation} 
By using Lemma \ref{apx-lemma5} and summing up $K_s$ global iterations, we obtain:
\begin{equation}
\begin{split}
    & \mathbb{E} [F(\srvmodh)] - \mathbb{E} [ F(\boldsymbol{w}^{h})] \\
    & \leq 
     - \frac{1}{2} \eta_h \sum \limits_{k=0}^{K_s-1} \mathbb{E} \Vert \nabla F(\boldsymbol{w}^{h, k}) \Vert^2
    + \frac{K_s(L \eta_h^2 G_s^2 + \eta_h G_u^2)}{2}
    \nonumber
\end{split}
\end{equation}
Similarly, for the model after aggregation, we have:
\begin{equation}
\begin{split}
    & \mathbb{E} [F(\boldsymbol{w}^{h+1})] - \mathbb{E} [ F(\srvmodh)] \\
    & \leq - \mathbb{E} \langle \nabla F(\srvmodh),  \Delta^{h} \rangle 
     + \frac{L}{2} \mathbb{E} [\Vert \Delta^h \Vert^2] \\
    & \underset{(a)}{\leq} -\eta_h \frac{K_u}{2} \mathbb{E} \Vert \nabla F(\srvmodh) \Vert^2 + \frac{(K_u-1)(2K_u-1)L^2 \eta_h^3 G_u^2}{6} \\
    & + \eta_h K_u G_s^2 + \frac{L}{2} \mathbb{E} [\Vert \Delta^{h} \Vert^2] \\
    \nonumber
\end{split}
\end{equation}
where (a) follows Lemma \ref{apx-lemma5}.

Assume that $\eta_h$ decreases monotonically.
By summing up all aggregation rounds, and from $F(\boldsymbol{w}^H) \leq \mathbb{E} [F(\boldsymbol{w}^*)]$, we can write:
\begin{equation}
\begin{split}
    & \frac{1}{H}\sum\limits_{h=1}^H{\mathbb{E} [K_u\Vert \nabla F(\srvmodh) \Vert^2 + \sum\limits_{k=0}^{K_s-1} \Vert \nabla F(\boldsymbol{w}^{h, k}) \Vert^2]} \\
    & \leq \frac{2(F(\boldsymbol{w}^0) - F(\boldsymbol{w}^*))}{\eta_1 H} \\ 
    & + (\frac{L^2(K_u-1)(2K_u-1)\eta_1^2}{3} + K_s + L K_u^2 \eta_1) G_u^2 \\
    & + (L K_s \eta_1 + 2K_u)G_s^2 \\
    \nonumber
 \end{split}   
\end{equation}
Since $K_u > 0$, we have:
\begin{equation}
\begin{split}
    & \underset{h \in [H], k \in \{0,\cdots, K_s\}}{\min} \mathbb{E} \Vert \nabla F(\boldsymbol{w}^{h, k}) \Vert^2 \\
    & \leq \frac{1}{H K_s}\sum\limits_{k=1}^K\sum\limits_{k=0}^{K_s}{\mathbb{E} \Vert \nabla F(\boldsymbol{w}^{h, k}) \Vert^2} \\
    & \leq \frac{2(F(\boldsymbol{w}^0) - F(\boldsymbol{w}^*))}{\eta_1 H K_s} + \Phi
    \nonumber
\end{split}   
\end{equation}
which completes the proof.

\subsection{Key Lemmas}
\begin{lemma}
For random variables $X_1, \ldots, X_r$, we have:
\label{apx-lemma1}
    \begin{equation}
    \mathbb{E}[\Vert X_1 + \ldots + X_r \Vert^2] \leq r\mathbb{E}[\Vert X_1\Vert^2 + \ldots + \Vert X_r\Vert^2].
    \nonumber
    \end{equation}
\end{lemma}

\begin{lemma}
For random vectors $X, Y, Z$, we have:
\label{apx-lemma2}
    \begin{equation}
    \mathbb{E} \langle X, Y+Z \rangle \geq \mathbb{E} \langle X, Y \rangle - \Vert \mathbb{E} \langle X, Z \rangle \Vert.
    \nonumber
   \end{equation} 
\end{lemma}

\begin{lemma}
\label{apx-lemma3}
    According to Assumption \ref{assump2}, we have:
    \begin{equation}
    \label{apx-lemma3-eq1}
        \mathbb{E} \Vert \tilde{\nabla} f_{u, i}(\boldsymbol{w}) \Vert^2 \leq G_u^2; 
    \end{equation}
    \begin{equation}
    \label{apx-lemma3-eq2}
        \Vert \nabla f_{u}(\boldsymbol{w}) \Vert^2 \leq G_u^2; 
    \end{equation}
    \begin{equation}
    \label{apx-lemma3-eq3}
        \Vert \nabla f_{s}(\boldsymbol{w}) \Vert^2 \leq G_s^2.
    \end{equation}
\end{lemma}

\emph{Proof:} 
For Eq. (\ref{apx-lemma3-eq1}):
\begin{equation}
\begin{split}
    & \mathbb{E} \Vert \nabla f_{u, i}(\boldsymbol{w}) \Vert^2  \\
    & \underset{(a)}{\leq} \frac{1}{|\mathcal{B}_{U, i}|}\sum_{x \in [\mathcal{B}_{U, i}]}{ \Vert \tilde{\nabla} f_{u, i}(\boldsymbol{w}) \Vert^2} \\
    & \underset{(b)}{\leq} G_u^2
    \nonumber
\end{split}
\end{equation}
where (a) is obtained by Lemma \ref{apx-lemma1}, (b) follows Assumption \ref{assump2}. Eq. (\ref{apx-lemma3-eq2}) and Eq. (\ref{apx-lemma3-eq3}) can be proved in a similar way.

\begin{lemma}
\label{apx-lemma4}
    According to Assumptions \ref{assump1} and \ref{assump2}, we have:
    \begin{equation}
    \begin{split}
    \label{apx-lemma2-eq1}
        \mathbb{E} \langle \nabla f_u(\srvmodh), \Delta^{h} \rangle \geq \frac{\eta_h K_u}{2} \mathbb{E} \Vert \nabla f_u(\srvmodh) \Vert^2 \\
        - \frac{(K_u-1)(2K_u-1)L^2 \eta_h^3 G_u^2}{6}.
        \nonumber
    \end{split}
    \end{equation}
    where $\Delta^{h} \triangleq \frac{1}{N}\sum \limits_{i=1}^N {(\boldsymbol{w}_i^{h+1} - \srvmodh)}$.
\end{lemma}

\emph{Proof:} 
\begin{equation}
\begin{split}
    & \mathbb{E} \langle \nabla f_u(\srvmodh), \Delta^{h} \rangle \\
    & = \mathbb{E} \langle \nabla f_u(\srvmodh), \Delta^{h} - \eta_h K_u \nabla f_u(\srvmodh) + \eta_h K_u \nabla f_u(\srvmodh) \rangle \\
    & \underset{(a)}{\geq} \eta K_u \mathbb{E} \Vert \nabla f_u(\srvmodh) \Vert^2 \\ 
    & \quad - \Vert \mathbb{E} \langle \nabla f_u(\srvmodh), \Delta^{h} - \eta_h K_u \nabla f_u(\srvmodh) \rangle \Vert \\
    & \geq \eta_h K_u \mathbb{E} \Vert \nabla f_u(\srvmodh) \Vert^2 \\
    & \quad - \Vert \mathbb{E} \langle \sqrt{\eta_h K_u}\nabla f_u(\srvmodh), \frac{\sqrt{\eta_h}}{\sqrt{K_u}} (\frac{\Delta^{h}}{\eta} - K_u \nabla f_u(\srvmodh)) \rangle \Vert \\
    & \geq \eta_h K_u \mathbb{E} \Vert \nabla f_u(\srvmodh) \Vert^2 \\
    & \quad - \frac{1}{2}(\eta_h K_u \mathbb{E} \Vert \nabla f_u(\srvmodh) \Vert^2 + \frac{\eta_h}{K_u}\mathbb{E} \Vert \frac{\Delta^{h}}{\eta_h} - K_u \nabla f_u(\srvmodh) \Vert^2)
    % \nonumber
    \label{pf1-lemma4}
\end{split}
\end{equation}
where (a) follows \ref{apx-lemma2}. 
Note that:
\begin{equation}
\begin{split}
    \Delta^{h}
    & = \frac{1}{N}\sum \limits_{i=1}^N\sum \limits_{k=0}^{K_u -1} {(\boldsymbol{w}_i^{h+, k+1} - \boldsymbol{w}_i^{h+, k})}  \\
    & = \frac{1}{N}\sum \limits_{i=1}^N\sum \limits_{k=0}^{K_u-1} {\eta_h \tilde{\nabla} f_{u, i}(\boldsymbol{w}_i^{h+, k})}
    \nonumber
\end{split}
\end{equation}
We have:
\begin{equation}
\begin{split}
    & \frac{\Delta^{h}}{\eta_h} - K_u \nabla f_u(\srvmodh) \\
    & = \frac{1}{N}\sum \limits_{i=1}^N \sum\limits_{k=0}^{K_u-1}{\tilde{\nabla} f_{u, i}(\boldsymbol{w}_i^{h+, k})} - K_u \frac{1}{N}\sum\limits_{i=1}^N {\nabla f_{u,i}(\srvmodh)} \\
    & = \frac{1}{N}\sum \limits_{i=1}^N \sum\limits_{k=0}^{K_u-1}{(\tilde{\nabla} f_{u, i}(\boldsymbol{w}_i^{h+, k}) - \nabla f_{u,i}(\srvmodh)}) \\
    & = \frac{1}{N}\sum \limits_{i=1}^N \sum\limits_{k=0}^{K_u-1}{(\nabla f_{u, i}(\boldsymbol{w}_i^{h+, k}) - \nabla f_{u,i}(\srvmodh)}) \\
    \nonumber
\end{split}
\end{equation}
where the last equality follows Assumption \ref{assump3}. So we can bound $\mathbb{E} \Vert \frac{\Delta^{h}}{\eta_h} - K_u \nabla F(\srvmodh) \Vert^2$ as:
\begin{equation}
\begin{split}
    & \mathbb{E} \Vert \frac{\Delta^{h}}{\eta_h} - K_u \nabla F(\srvmodh) \Vert^2  \\ 
    & \underset{(a)}{\leq} \frac{L^2}{N}\sum \limits_{i=1}^N \sum\limits_{k=0}^{K-1}{\mathbb{E} \Vert \boldsymbol{w}_i^{h+, k} - \boldsymbol{w}_i^{h+} \Vert^2} \\
    & = \frac{L^2}{N}\sum \limits_{i=1}^N \sum\limits_{k=0}^{K-1}{\mathbb{E} \Vert \sum\limits_{m=0}^{k-2}\eta_h \tilde{\nabla} f_{u, i}(\boldsymbol{w}_i^{h+,m}) \Vert^2} \\
    & \underset{(b)}{\leq} \frac{L^2\eta_h^2}{N}\sum \limits_{i=1}^N \sum\limits_{k=0}^{K-1}{ ((k-1)\sum\limits_{m=0}^{k-2} \mathbb{E} \Vert \tilde{\nabla} f_{u, i}(\boldsymbol{w}_i^{h+,m}) \Vert^2)} \\
    & \underset{(c)}{\leq} \frac{L^2}{N}\sum \limits_{i=1}^N \sum\limits_{k=1}^{K_u}{((k-1)^2 \eta_h^2 G_u^2)} \\
    & = \frac{K_u(K_u-1)(2K_u-1)L^2 \eta_h^2 G_u^2}{6}
    % \nonumber
    \label{pf2-lemma4}
\end{split}
\end{equation}
where (a) and (b) are obtained by Lemma \ref{apx-lemma1} and follows Assumption \ref{assump1}, (c) follows Lemma \ref{apx-lemma3}.

\begin{lemma}
\label{apx-lemma5}
    According to Assumptions \ref{assump1} and \ref{assump2}, we have:
    \begin{equation}
    \label{apx-lemma5-eq1}
        \mathbb{E} \langle \nabla F(\boldsymbol{w}^{h}),  \tilde{\nabla} f_{s}(\boldsymbol{w}^{h}) \rangle \geq \frac{1}{2} \mathbb{E} \Vert \nabla F(\boldsymbol{w}^{h}) \Vert^2 - \frac{1}{2} G_u^2;
    \end{equation}
    \begin{equation}
    \label{apx-lemma5-eq2}
    \begin{split}
        \mathbb{E} \langle \nabla F(\srvmodh)&, \Delta^h \rangle 
         \geq \frac{\eta_h K_u}{2} \mathbb{E} \Vert \nabla F(\srvmodh) \Vert^2 \\
        & - \frac{(K_u-1)(2K_u-1)L^2 \eta_h^3 G_u^2}{6} -\eta_h K_u G_s^2.
    \end{split}
    \end{equation}
    where $\Delta^{h} \triangleq \frac{1}{N}\sum \limits_{i=1}^N {(\boldsymbol{w}_i^{h + 1} - \srvmodh)}$.
\end{lemma}

\emph{Proof:} 
For Eq. (\ref{apx-lemma5-eq1}), we have:
\begin{equation}
\begin{split}
    & \mathbb{E} \langle \nabla F(\boldsymbol{w}^{h}),  \tilde{\nabla} f_{s}(\boldsymbol{w}^{h}) \rangle \\
    & \underset{(a)}{=} \mathbb{E} \langle \nabla F(\boldsymbol{w}^{h}),  \nabla f_{s}(\boldsymbol{w}^{h}) \rangle \\
    & = \mathbb{E} \langle \nabla F(\boldsymbol{w}^{h}), -\nabla f_u(\boldsymbol{w}^{h}) + \nabla F(\boldsymbol{w}^{h}) \rangle \\
    & \underset{(b)}{\geq} \mathbb{E} \Vert \nabla F(\boldsymbol{w}^{h}) \Vert^2 - \Vert \mathbb{E} \langle \nabla F(\boldsymbol{w}^{h}), -\nabla f_u(\boldsymbol{w}^h) \rangle \Vert \\
    \nonumber
\end{split}
\end{equation}
where (a) follows Assumption \ref{assump3}, (b) comes from Lemma \ref{apx-lemma2}.

Note that $2 \langle U, V \rangle \leq \Vert U \Vert^2 +\Vert V \Vert^2$, we obtain:
\begin{equation}
\begin{split}
    & \Vert \mathbb{E} \langle \nabla F(\boldsymbol{w}^{h}), -\nabla f_u(\boldsymbol{w}^{h}) \rangle \Vert \\
    & \leq \frac{1}{2} (\mathbb{E} \Vert \nabla F(\boldsymbol{w}^{h}) \Vert^2 + \mathbb{E} \Vert \nabla f_u(\boldsymbol{w}^{h}) \Vert^2) \\
    & \leq \frac{1}{2} \mathbb{E} \Vert \nabla F(\boldsymbol{w}^{h}) \Vert^2 + \frac{1}{2} G_u^2
    \nonumber
\end{split}
\end{equation}
where the last inequality follows Lemma \ref{apx-lemma1}.
According to the above inequalities, we have:
\begin{equation}
    \mathbb{E} \langle \nabla F(\boldsymbol{w}^{h}),  \tilde{\nabla} f_{s}(\boldsymbol{w}^{h}) \rangle \geq \frac{1}{2} \mathbb{E} \Vert \nabla F(\boldsymbol{w}^{h}) \Vert^2 - \frac{1}{2} G_u^2
    \nonumber
\end{equation}
which completes the proof of Eq. (\ref{apx-lemma5-eq1}). 

For Eq. (\ref{apx-lemma5-eq2}), similar to Eq. (\ref{pf1-lemma4}), we have:
\begin{equation}
\begin{split}
    & \mathbb{E} \langle \nabla F(\srvmodh), \Delta^{h} \rangle \\
    & \geq \eta_h K_u \mathbb{E} \Vert \nabla F(\srvmodh) \Vert^2 \\
    & \quad - \frac{1}{2}(\eta_h K_u \mathbb{E} \Vert \nabla F(\srvmodh) \Vert^2 + \frac{\eta_h}{K_u}\mathbb{E} \Vert \frac{\Delta^{h}}{\eta_h} - K_u \nabla F(\srvmodh) \Vert^2)
    \nonumber
\end{split}
\end{equation}
By letting:
\begin{equation}
\begin{split}
    & X = \frac{1}{N}\sum \limits_{i=1}^N \sum\limits_{k=0}^{K-1}{(\tilde{\nabla} f_{u, i}(\boldsymbol{w}_i^{h+, k}) - \nabla f_u(\srvmodh)}) \\
    & Y = \frac{1}{N} \sum\limits_{i=1}^N\sum\limits_{k=0}^{K-1} (\nabla f_u(\srvmodh) - \nabla F(\srvmodh)) \\
    \nonumber
\end{split}
\end{equation}
we have:
\begin{equation}
\begin{split}
    \frac{\Delta^{h}}{\eta_h} - K_u \nabla F(\srvmodh) = X + Y
    \nonumber
\end{split}
\end{equation}
So we bound $\mathbb{E} \Vert \frac{\Delta^{h}}{\eta_h} - K_u \nabla F(\srvmodh) \Vert^2$ as:
\begin{equation}
\begin{split}
    & \mathbb{E} \Vert \frac{\Delta^{h}}{\eta_h} - K_u \nabla F(\srvmodh) \Vert^2  \\
    & \leq 2 \mathbb{E} \Vert X \Vert^2 + 2 \mathbb{E} \Vert Y \Vert^2 \\
    & \leq 2 \mathbb{E} \Vert X \Vert^2 + 2 K_u^2 G_s^2
    \nonumber
\end{split}
\end{equation}
where the above inequalities are obtained by Lemma \ref{apx-lemma1} and Lemma \ref{apx-lemma3}. For $\mathbb{E} \Vert X \Vert^2$, it can be bounded as Eq. (\ref{pf2-lemma4}).

Putting the pieces together, we get:
\begin{equation}
\begin{split}
    \mathbb{E} \langle \nabla F(\srvmodh), & \Delta^h \rangle
     \geq \frac{\eta_h K_u}{2}\mathbb{E} \Vert \nabla F(\srvmodh) \Vert^2 \\
    & - \frac{(K_u-1)(2K_u-1)L^2 \eta_h^3 G_u^2}{6} - \eta_h K_u G_s^2
    \nonumber
\end{split}
\end{equation}
which completes the proof.
\end{appendices}