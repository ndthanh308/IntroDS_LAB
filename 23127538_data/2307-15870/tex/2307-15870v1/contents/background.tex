
In this section, we provide a description about semi-supervised SFL, followed by an exploration of the underlying motivation behind our system design.
For ease of expression, we list some key notations in Table \ref{notation-table}.

% % Figure environment removed

\subsection{Semi-supervised Split Federated Learning} \label{description-section}
Split Federated Learning (SFL) \cite{thapa2022splitfed} is composed of Federated Learning (FL) \cite{konevcny2016federated} and Split Learning (SL) \cite{gupta2018distributed}. 
FL is designed to train ML models on distributed edge devices with privacy preserving, while SL aims at reducing the computation cost of participants with limited resources. 
Therefore, SFL inherits the advantages of both FL and SL. 

Similar to FL, a Parameter Server (PS) and $N$ clients collaboratively train an ML model (denoted as $\boldsymbol{w}$) in SFL. 
The model is split into two submodels as $\boldsymbol{w} = (\boldsymbol{w}_s, \boldsymbol{w}_c)$. 
The bottom (sub-)model $\boldsymbol{w}_c$ and the top (sub-)model $\boldsymbol{w}_s$ separately reside at clients and the PS. 
In general, the PS randomly selects a subset $V_h \in V$, consisting of $N_h = |V_h|$ ($N_h \leq N$) active clients at round $h$. 
The selected clients with duplicated bottom models are instructed to send smashed data \cite{thapa2022splitfed}, as well as the ground-truth labels $y_{i}$ ($i\in[V_h]$) to the PS. 
The PS then calculates the gradients of smashed data for each client in parallel, and sends them to clients while accumulating the gradients $\Delta \boldsymbol{w}_s$ of the top model. 
Afterwards, the clients perform backpropagation to update their bottom models.
At the end of each round, the PS aggregates bottom models to obtain a global one for further training.

In Semi-supervised SFL (Semi-SFL), clients have access to unlabeled data, while the PS possesses the labeled dataset annotated by domain experts.
The complete dataset $\mathcal{D}$ consists of labeled dataset $\mathcal{D}_l$ and unlabeled dataset $\mathcal{D}_u$, where $\mathcal{D}_u \triangleq \mathcal{D}_{u, 1} \cup \mathcal{D}_{u, 2} \cup \cdots \cup \mathcal{D}_{u, N}$, and $\mathcal{D}_{u, i}$ ($i \in [N]$) is the dataset of client $i$. 
The loss function over a labeled data sample $(x, y)$ and the model parameter $\boldsymbol{w} \in \mathbb{R}^d$ with $d$ dimensions is defined as $\ell_{s}(x, y, \boldsymbol{w})$.
Thus, considering the centralized training on the labeled dataset $\mathcal{D}_l$, the loss function is $ \mathbb{E}_{x \in \mathcal{D}_l} \ell_s(x, y, \boldsymbol{w})$.

To leverage the vast amounts of unlabeled data on clients, recent studies have achieved promising results by enforcing model predictions on augmented data that deviate significantly from the data distribution. 
The objective is to ensure the alignment between these predictions with their corresponding pseudo-labels \cite{sohn2020fixmatch}. 
In other words, for a given unlabeled data sample $x$, the model's prediction of its weakly-augmented version is represented as a vector $q=(q_{1}, \cdots, q_{M}) \in [0, 1]^M$, where $\sum_{m=1}^M{q_{m}} = 1$, and $M$ is the number of classes. 
The pseudo-label for $x$ is then defined as $\hat{q} =\argmax_m {q_{m}}$, and is retained only if $\max_m {q_{m}}$ falls above the predefined confidence threshold $\tau$. 

Let $\mathcal{H}$ denote the cross-entropy loss function, which measures the discrepancy between the predicted and true labels. 
The unsupervised training loss with consistency regularization can be represented as:
    \begin{equation}
         \ell_{u}(x, \boldsymbol{w}) = \mathbbm{1}(\underset{m}{\max} {(q_{m})} > \tau) \mathcal{H}(x, \hat{q}, \boldsymbol{w})
    \end{equation}
Then the total training objective is expressed as:
    \begin{equation}
       F(\boldsymbol{w}^*) = \underset{\boldsymbol{w} \in \mathbb{R}^d}{\min \; } \left[\mathbb{E}_{x \in \mathcal{D}_l} \ell_{s}(x, y, \boldsymbol{w}) + \mathbb{E}_{x \in \mathcal{D}_u} \ell_{u}(x, \boldsymbol{w}) \right]
    \end{equation}

\begin{table}[tb]
    \centering
    \caption{Key notations}
    \begin{tabular}{cp{6cm}}
        \toprule  % top lines
        \textbf{Notation} & \makecell[c]{\textbf{Semantics}} \\ 
        \midrule
        % $N$ & number of clients \\
        $N_h$ & number of active clients in round $h$ \\
        
        % $V$ & set of clients \\
        $V_h$ & set of active clients in round $h$ \\
        $\mathcal{D}_s$ & labeled dataset on the PS \\
        $\mathcal{D}_u$ & unlabeled dataset across clients \\
        $\boldsymbol{w}_s$ & top model \\
        $\boldsymbol{w}_{c,i}$ & bottom model on client $i$ \\
        $\tilde{\boldsymbol{w}}$ & moving-averaged model  \\
        $\srvmodh$ & model after \srvUp in round $h$  \\
        $\boldsymbol{w}^h$ & model after \locReg in round $h$  \\
        $F(\boldsymbol{w})$ & loss function of the entire model \\
        $\mathcal{Q}$ & memory queue on the PS \\
        $H$ & \# of aggregation rounds \\
        $K_s$ & \# of iterations for \srvUp in each round, termed the \InvReg frequency \\
        $K_u$ & \# of iterations for split forward and back-propagation in each round, termed the \Reg frequency \\
        $P$ & communication period \\
        $\eta_h$ & learning rate in round $h$ \\
        \bottomrule  % bottom lines
    \end{tabular}
\label{notation-table}
\end{table}

\subsection{Motivation for System Design} \label{motivation-section}
In Semi-SFL, the consistency regularization loss encounters a major hurdle when the unlabeled data is non-IID among clients, as local models tend to favor locally abundant categories while potentially disregarding minorities. 
Although each client might train an expert model, the model divergence among clients is exacerbated when the predefined confidence threshold ($\tau$) blocks out data samples belonging to minority categories, especially in the early stages of training. 
Consequently, such imbalance in training leads to poor model representations \cite{li2021model} and hampers overall performance after aggregation.  
Therefore, our objective is to effectively utilize the unlabeled data through collaboration with other clients while ensuring efficient communication and computation, and further alleviate the non-IID problem.

Fortunately, the nature of Semi-SFL provides inspiration for a solution.
In Semi-SFL, pseudo-labeling is performed on the PS where the top model resides. 
As shown in Fig. \ref{motiv-fig} (left), each client transmits two types of smashed data for loss calculation: teacher features from the EMA bottom model (used for pseudo-labeling), and student features from the local bottom model (used for computing gradients).
Notably, the features collected on the PS show less skewness and higher abundance compared to the data on each individual client. 
The fact that collected features are mutually accessible on the PS allows for leveraging the data from multiple clients to mitigate non-IID impact.

To accomplish this, we propose to let the model learn directly from collected features, enabling it to make confident predictions by identifying patterns and commonalities in the input.
We introduce a contrastive loss \cite{lee2022contrastive} for our purpose and propose the method termed \textit{Clustering Regularization}.
Concretely, the feature is projected into a lower dimension with the help of a two-layer linear network (\ie, projection head). 
The contrastive loss regularizes the projected student features of unlabeled samples to move towards the projected teacher features with high confidence in the same class cluster, \ie, \textit{pseudo cluster}, as depicted in Fig. \ref{motiv-fig} (right). 
Owing to the computation and communication-friendly framework of SFL, the process of clustering regularization for all participating clients are jointly completed on the PS, relieving clients from the corresponding computational and aggregation overhead.

% Figure environment removed

% Figure environment removed

By this approach, we aim to fully exploit the potential of unlabeled data, including the samples that are filtered by the confidence threshold and currently excluded from consistency regularization. 
By leveraging the knowledge encoded in the pseudo clusters, even data samples belonging to minority classes can contribute to model training.
% which effectively propagates to the bottom models on clients.
From another perspective, our clustering assists and accelerates the process of consistency regularization, since well clustered features allow data samples a higher chance to be credited with high confidence by the top model. 
Importantly, our approach avoids introducing confirmation bias \cite{lee2022contrastive}.
We preserve the original pseudo-labels without modification, ensuring the model stays focused on its correct goal. 
