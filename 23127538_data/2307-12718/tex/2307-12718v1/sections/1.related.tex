\section{Related work}
\label{sec:related}
We provide a brief overview of the latest updates in neural radiance field, including its significant extensions and applications that have influenced our work.
NeRF limitations have been tackled by different works, trying to reduce its complexity, increase the reconstruction quality, and develop more challenging benchmarks.

\tit{Neural scene reconstruction}
%\tit{Anti-aliasing}
The handling of aliasing artifacts is a well-known issue in rendering algorithms. Mip-NeRF~\cite{barron2021mip,barron2022mip} and Zip-NeRF~\cite{barron2023zip} have tackled the aliasing issue by reasoning on volumetric frustums along a cone. These approaches have inspired works such as Able-NeRF~\cite{tang2023able}, which replaces the MLP of the original implementation with a transformer-based architecture.
%Similarly, Zip-NeRF builds on the cone-based approach of Mip-NeRF and incorporates the optimization framework proposed by Instant-NGP to achieve faster training times and more accurate scene reconstruction.
In addition to other sources of aliasing, reflections can pose a challenge for NeRF. %Because the method is trained on specific viewing directions, it may struggle to accurately render the appearance of glossy materials from novel viewpoints. 
Several works have attempted to address the issue of aliasing in reflections by taking into account the reflectance of the scene ~\cite{bi2020neural,boss2021neural,verbin2022ref}. 
Moreover, computation is a widely recognized concern. Various works in the literature have demonstrated that it is possible to achieve high-fidelity reconstructions while reducing the overall training time. 
Two notable works in this direction include 
% JAXNerf~\cite{deng2020jaxnerf} which offers a speedup for both training and rendering via GPUs parallelization, and 
NSVF~\cite{liu2020neural}, which uses a voxel-based representation for more efficient rendering of large scenes, and
% Recent state-of-the-art approaches take advantage of different strategies for data encoding. 
Instant-NGP~\cite{muller2022instant}, which proposes a multi-resolution hash table combined with a light MLP to achieve faster training times. Other approaches such as DVGO~\cite{sun2022direct} and Plenoxels~\cite{yu2021plenoxels} optimize voxel grids of features to enable fast radiance field reconstruction. TensoRF~\cite{chen2022tensorf} combines the traditional CP decomposition [7] with a new vector-matrix decomposition method~\cite{carroll1970analysis} leading to faster training and higher-quality reconstruction. 

In this work, in order to satisfy real-time performances for vehicle inspection, we select a set of architectures that strike a balance between training time and the quality of the reconstruction.

%Train optimized architectures should strike a balance between training time and the quality of the reconstruction to achieve a real-time system for vehicle inspection. 
\begin{table*}[t]
    \caption{Comparison between existing datasets used as benchmarks for neural radiance field evaluation and \textit{\ours}. We provide the same scene by varying the amount of training data (40, 60, 80, and 100 images), allowing users to test the robustness of their architectures. We also release depth and segmentation data for all the images.}
    \centering
    \begin{tabular}{l c c c c }
        \toprule
        Dataset & Scenes & Images/scene & Depth & Segmentation\\
        \midrule
        Blender~\cite{mildenhall2021nerf} & 8 & 300 & \cmark & \xmark \\
        Shiny Blender~\cite{verbin2022ref} & 6 & 300 & \cmark & \xmark \\
        BlendedMVG~\cite{yao2020blendedmvs} & 508 & 200-4000 & \xmark & \xmark \\
        \midrule
        \textit{\oursnospace}$_{40}$  & 8 & 240 & \cmark & \cmark \\
        \textit{\oursnospace}$_{60}$  & 8 & 260 & \cmark & \cmark \\
        \textit{\oursnospace}$_{80}$  & 8 & 280 & \cmark & \cmark \\
        \textit{\oursnospace}$_{100}$  & 8 & 300 & \cmark & \cmark \\

        \bottomrule
    \end{tabular}
    \label{tab:dataset_comparison}
\end{table*}

\tit{Scene representation benchmarks}
One of the most widely used benchmarks for evaluating NeRF is the Nerf Synthetic Blender dataset~\cite{mildenhall2021nerf}. This dataset consists of 8 different scenes generated using Blender\footnote{\url{http://www.blender.org}}, each with 100 training images and 200 test images. Other synthetic datasets include the Shiny Blender dataset~\cite{verbin2022ref}, which mostly contains singular objects with simple geometries, and Blend DMVS \cite{yao2020blendedmvs}, which provides various scenes to test NeRF implementations at different scales.
These works do not provide ground truth information about the semantic meaning of the images. This limitation makes it difficult to study the ability of NeRF to reconstruct certain surfaces compared to others. In our \textit{\ours} dataset, we provide ground truth segmentation of vehicle components in the scene, allowing for the evaluation of architectures on specific parts. Table~\ref{tab:dataset_comparison} presents a comparison between the most common datasets used as benchmarks and our proposed dataset.

% \subsection{NeRF overview}