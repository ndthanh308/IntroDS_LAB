\begin{thebibliography}{10}

\bibitem{castellano2021visual}
Giovanna Castellano, Eufemia Lella, and Gennaro Vessio.
\newblock Visual link retrieval and knowledge discovery in painting datasets.
\newblock {\em Multimedia Tools and Applications}, 80:6599--6616, 2021.

\bibitem{li2022intuitively}
Kangying Li, Jiayun Wang, Biligsaikhan Batjargal, and Akira Maeda.
\newblock Intuitively searching for the rare colors from digital artwork
  collections by text description: a case demonstration of japanese ukiyo-e
  print retrieval.
\newblock {\em Future Internet}, 14(7):212, 2022.

\bibitem{crowley2014state}
Elliot Crowley and Andrew Zisserman.
\newblock The state of the art: object retrieval in paintings using
  discriminative regions.
\newblock In {\em Proceedings of the British Machine Vision Conference},
  page~8, 2014.

\bibitem{crowley2016art}
Elliot~J Crowley and Andrew Zisserman.
\newblock The art of detection.
\newblock In {\em Proceedings of the European Conference on Computer Vision
  Workshops}, pages 721--737. Springer, 2016.

\bibitem{seidenari2017deep}
Lorenzo Seidenari, Claudio Baecchi, Tiberio Uricchio, Andrea Ferracani, Marco
  Bertini, and Alberto~Del Bimbo.
\newblock Deep artwork detection and retrieval for automatic context-aware
  audio guides.
\newblock {\em ACM Transactions on Multimedia Computing, Communications, and
  Applications}, 13(3s):1--21, 2017.

\bibitem{lowe1999object}
David~G Lowe.
\newblock Object recognition from local scale-invariant features.
\newblock In {\em Proceedings of International Conference on Computer Vision},
  volume~2, pages 1150--1157. Ieee, 1999.

\bibitem{zhang2013image}
Lei Zhang and Yong Rui.
\newblock Image searchâ€”from thousands to billions in 20 years.
\newblock {\em ACM Transactions on Multimedia Computing, Communications, and
  Applications}, 9(1s):1--20, 2013.

\bibitem{li2011text}
Wen Li, Lixin Duan, Dong Xu, and Ivor Wai-Hung Tsang.
\newblock Text-based image retrieval using progressive multi-instance learning.
\newblock In {\em International Conference on Computer Vision}, pages
  2049--2055. IEEE, 2011.

\bibitem{kaur2021comparative}
Parminder Kaur, Husanbir~Singh Pannu, and Avleen~Kaur Malhi.
\newblock Comparative analysis on cross-modal information retrieval: a review.
\newblock {\em Computer Science Review}, 39:100336, 2021.

\bibitem{zhang2020context}
Qi~Zhang, Zhen Lei, Zhaoxiang Zhang, and Stan~Z Li.
\newblock Context-aware attention network for image-text retrieval.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 3536--3545, 2020.

\bibitem{li2020unicoder}
Gen Li, Nan Duan, Yuejian Fang, Ming Gong, and Daxin Jiang.
\newblock {Unicoder-VL}: a universal encoder for vision and language by
  cross-modal pre-training.
\newblock In {\em Proceedings of the AAAI Conference on Artificial
  Intelligence}, volume~34, pages 11336--11344, 2020.

\bibitem{young2014image}
Peter Young, Alice Lai, Micah Hodosh, and Julia Hockenmaier.
\newblock From image descriptions to visual denotations: new similarity metrics
  for semantic inference over event descriptions.
\newblock {\em Transactions of the Association for Computational Linguistics},
  2:67--78, 2014.

\bibitem{lin2014microsoft}
Tsung-Yi Lin, Michael Maire, Serge Belongie, James Hays, Pietro Perona, Deva
  Ramanan, Piotr Doll{\'a}r, and C~Lawrence Zitnick.
\newblock Microsoft {COCO}: common objects in context.
\newblock In {\em Proceedings of the European Conference on Computer Vision},
  pages 740--755, 2014.

\bibitem{mao2016generation}
Junhua Mao, Jonathan Huang, Alexander Toshev, Oana Camburu, Alan~L Yuille, and
  Kevin Murphy.
\newblock Generation and comprehension of unambiguous object descriptions.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 11--20, 2016.

\bibitem{faghri2018vse++}
Fartash Faghri, David~J Fleet, Jamie~Ryan Kiros, and Sanja Fidler.
\newblock {VSE++}: improving visual-semantic embeddings with hard negatives.
\newblock In {\em Proceedings of the British Machine Vision Conference},
  page~12, 2018.

\bibitem{anderson2018bottom}
Peter Anderson, Xiaodong He, Chris Buehler, Damien Teney, Mark Johnson, Stephen
  Gould, and Lei Zhang.
\newblock Bottom-up and top-down attention for image captioning and visual
  question answering.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 6077--6086, 2018.

\bibitem{cho2014learning}
Kyunghyun Cho, Bart Van~Merri{\"e}nboer, Caglar Gulcehre, Dzmitry Bahdanau,
  Fethi Bougares, Holger Schwenk, and Yoshua Bengio.
\newblock Learning phrase representations using {RNN} encoder-decoder for
  statistical machine translation.
\newblock In {\em Proceedings of the Conference on Empirical Methods in Natural
  Language Processing}, pages 1724--1734, 2014.

\bibitem{lee2018stacked}
Kuang-Huei Lee, Xi~Chen, Gang Hua, Houdong Hu, and Xiaodong He.
\newblock Stacked cross attention for image-text matching.
\newblock In {\em Proceedings of the European Conference on Computer Vision},
  pages 201--216, 2018.

\bibitem{li2019visual}
Kunpeng Li, Yulun Zhang, Kai Li, Yuanyuan Li, and Yun Fu.
\newblock Visual semantic reasoning for image-text matching.
\newblock In {\em Proceedings of International Conference on Computer Vision},
  pages 4654--4662, 2019.

\bibitem{kipf2017semi}
Thomas~N Kipf and Max Welling.
\newblock Semi-supervised classification with graph convolutional networks.
\newblock In {\em Proceedings of International Conference on Learning
  Representations}, 2017.

\bibitem{chen2021learning}
Jiacheng Chen, Hexiang Hu, Hao Wu, Yuning Jiang, and Changhu Wang.
\newblock Learning the best pooling strategy for visual semantic embedding.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 15789--15798, 2021.

\bibitem{chen2020uniter}
Yen-Chun Chen, Linjie Li, Licheng Yu, Ahmed El~Kholy, Faisal Ahmed, Zhe Gan,
  Yu~Cheng, and Jingjing Liu.
\newblock {UNITER}: universal image-text representation learning.
\newblock In {\em Proceedings of the European Conference on Computer Vision},
  pages 104--120, 2020.

\bibitem{devlin2019bert}
Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova.
\newblock {BERT}: pre-training of deep bidirectional transformers for language
  understanding.
\newblock In {\em Proceedings of the Annual Conference of the North American
  Chapter of the Association for Computational Linguistics}, pages 4171--4186,
  2019.

\bibitem{krishna2017visual}
Ranjay Krishna, Yuke Zhu, Oliver Groth, Justin Johnson, Kenji Hata, Joshua
  Kravitz, Stephanie Chen, Yannis Kalantidis, Li-Jia Li, David~A Shamma, et~al.
\newblock Visual genome: connecting language and vision using crowdsourced
  dense image annotations.
\newblock {\em International Journal of Computer Vision}, 123(1):32--73, 2017.

\bibitem{sharma2018conceptual}
Piyush Sharma, Nan Ding, Sebastian Goodman, and Radu Soricut.
\newblock Conceptual captions: a cleaned, hypernymed, image alt-text dataset
  for automatic image captioning.
\newblock In {\em Proceedings of the Annual Meeting of the Association for
  Computational Linguistics}, volume~1, pages 2556--2565, 2018.

\bibitem{ordonez2011im2text}
Vicente Ordonez, Girish Kulkarni, and Tamara Berg.
\newblock Im2text: describing images using 1 million captioned photographs.
\newblock {\em Advances in Neural Information Processing Systems},
  24:1143--1151, 2011.

\bibitem{radford2021learning}
Alec Radford, Jong~Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh,
  Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark,
  et~al.
\newblock Learning transferable visual models from natural language
  supervision.
\newblock In {\em Proceedings of International Conference on Machine Learning},
  pages 8748--8763, 2021.

\bibitem{gong2023vitr}
Yan Gong and Georgina Cosma.
\newblock {VITR}: augmenting vision transformers with relation-focused learning
  for cross-modal information retrieval.
\newblock {\em arXiv preprint arXiv:2302.06350}, 2023.

\bibitem{elliot2021artuk}
Ernesto~Coto Elliot J.~Crowley and Andrew Zisserman.
\newblock The {ArtUK} paintings dataset.
\newblock \url{https://www.robots.ox.ac.uk/~vgg/data/paintings/}, 2021.

\bibitem{gong2021limitations}
Yan Gong, Georgina Cosma, and Hui Fang.
\newblock On the limitations of visual-semantic embedding networks for
  image-to-text information retrieval.
\newblock {\em Journal of Imaging}, 7(8):125, 2021.

\bibitem{saracevic1995evaluation}
Tefko Saracevic.
\newblock Evaluation of evaluation in information retrieval.
\newblock In {\em Proceedings of the Annual International ACM SIGIR Conference
  on Research and Development in Information Retrieval}, pages 138--146, 1995.

\end{thebibliography}
