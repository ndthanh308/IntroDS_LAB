@misc{zhang2023adding,
      title={Adding Conditional Control to Text-to-Image Diffusion Models}, 
      author={Lvmin Zhang and Maneesh Agrawala},
      year={2023},
      eprint={2302.05543},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      howpublished ={\url{https://github.com/lllyasviel/ControlNet-v1-1-nightly}}
}

@misc{solidarnyh2023,
  title = "This Artist Combines Real Photos and Turns Them into Amazing Digital Art",
  author = "Solidarnyh, Viktoria",
  year = "2023",
  howpublished = "DIY Photography",
  url = "https://www.diyphotography.net/this-artist-combines-real-photos-and-turns-them-into-amazing-digital-art/"
}


@misc{xu2023imagereward,
      title={ImageReward: Learning and Evaluating Human Preferences for Text-to-Image Generation},
      author={Jiazheng Xu and Xiao Liu and Yuchen Wu and Yuxuan Tong and Qinkai Li and Ming Ding and Jie Tang and Yuxiao Dong},
      year={2023},
      eprint={2304.05977},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{laion_aesthetic,
  author = {LAION-AI},
  title = {aesthetic-predictor},
  year = {2022},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/LAION-AI/aesthetic-predictor}},
}

@misc{unet,
  doi = {10.48550/ARXIV.1505.04597},
  
  url = {https://arxiv.org/abs/1505.04597},
  
  author = {Ronneberger, Olaf and Fischer, Philipp and Brox, Thomas},
  
  keywords = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {U-Net: Convolutional Networks for Biomedical Image Segmentation},
  
  publisher = {arXiv},
  
  year = {2015},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{balaji2023ediffi,
      title={eDiff-I: Text-to-Image Diffusion Models with an Ensemble of Expert Denoisers}, 
      author={Yogesh Balaji and Seungjun Nah and Xun Huang and Arash Vahdat and Jiaming Song and Qinsheng Zhang and Karsten Kreis and Miika Aittala and Timo Aila and Samuli Laine and Bryan Catanzaro and Tero Karras and Ming-Yu Liu},
      year={2023},
      eprint={2211.01324},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{paiss2022token,
      title={No Token Left Behind: Explainability-Aided Image Classification and Generation}, 
      author={Roni Paiss and Hila Chefer and Lior Wolf},
      year={2022},
      eprint={2204.04908},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@InProceedings{Avrahami_2023_CVPR,
    author    = {Avrahami, Omri and Hayes, Thomas and Gafni, Oran and Gupta, Sonal and Taigman, Yaniv and Parikh, Devi and Lischinski, Dani and Fried, Ohad and Yin, Xi},
    title     = {SpaText: Spatio-Textual Representation for Controllable Image Generation},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    month     = {June},
    year      = {2023},
    pages     = {18370-18380}
}

@misc{latent_blended,
  doi = {10.48550/ARXIV.2206.02779},
  
  url = {https://arxiv.org/abs/2206.02779},
  
  author = {Avrahami, Omri and Fried, Ohad and Lischinski, Dani},
  
  keywords = {Computer Vision and Pattern Recognition (cs.CV), Graphics (cs.GR), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Blended Latent Diffusion},
  
  publisher = {arXiv},
  
  year = {2022},
  
  copyright = {Creative Commons Attribution Non Commercial No Derivatives 4.0 International}
}


@misc{dalle2,
  doi = {10.48550/ARXIV.2204.06125},
  
  url = {https://arxiv.org/abs/2204.06125},
  
  author = {Ramesh, Aditya and Dhariwal, Prafulla and Nichol, Alex and Chu, Casey and Chen, Mark},
  
  keywords = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Hierarchical Text-Conditional Image Generation with CLIP Latents},
  
  publisher = {arXiv},
  
  year = {2022},
  
  copyright = {Creative Commons Attribution 4.0 International}
}


@misc{stable_diffusion,
      title={High-Resolution Image Synthesis with Latent Diffusion Models},
      author={Robin Rombach and Andreas Blattmann and Dominik Lorenz and Patrick Esser and Björn Ommer},
      year={2021},
      eprint={2112.10752},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      howpublished = {\url{https://github.com/runwayml/stable-diffusion}},
}


@misc{imagegen,
  doi = {10.48550/ARXIV.2205.11487},
  
  url = {https://arxiv.org/abs/2205.11487},
  
  author = {Saharia, Chitwan and Chan, William and Saxena, Saurabh and Li, Lala and Whang, Jay and Denton, Emily and Ghasemipour, Seyed Kamyar Seyed and Ayan, Burcu Karagol and Mahdavi, S. Sara and Lopes, Rapha Gontijo and Salimans, Tim and Ho, Jonathan and Fleet, David J and Norouzi, Mohammad},
  
  keywords = {Computer Vision and Pattern Recognition (cs.CV), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Photorealistic Text-to-Image Diffusion Models with Deep Language Understanding},
  
  publisher = {arXiv},
  
  year = {2022},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}


@misc{Composable-Diffusion,
  doi = {10.48550/ARXIV.2206.01714},
  
  url = {https://arxiv.org/abs/2206.01714},
  
  author = {Liu, Nan and Li, Shuang and Du, Yilun and Torralba, Antonio and Tenenbaum, Joshua B.},
  
  keywords = {Computer Vision and Pattern Recognition (cs.CV), Artificial Intelligence (cs.AI), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Compositional Visual Generation with Composable Diffusion Models},
  
  publisher = {arXiv},
  
  year = {2022},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{daam,
  doi = {10.48550/ARXIV.2210.04885},
  
  url = {https://arxiv.org/abs/2210.04885},
  
  author = {Tang, Raphael and Pandey, Akshat and Jiang, Zhiying and Yang, Gefei and Kumar, Karun and Lin, Jimmy and Ture, Ferhan},
  
  keywords = {Computer Vision and Pattern Recognition (cs.CV), Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {What the DAAM: Interpreting Stable Diffusion Using Cross Attention},
  
  publisher = {arXiv},
  
  year = {2022},
  
  copyright = {Creative Commons Attribution 4.0 International}
}

l ;kcxop

@String(PAMI = {IEEE Trans. Pattern Anal. Mach. Intell.})
@String(IJCV = {Int. J. Comput. Vis.})
@String(CVPR= {IEEE Conf. Comput. Vis. Pattern Recog.})
@String(ICCV= {Int. Conf. Comput. Vis.})
@String(ECCV= {Eur. Conf. Comput. Vis.})
@String(NIPS= {Adv. Neural Inform. Process. Syst.})
@String(NeurIPS= {Adv. Neural Inform. Process. Syst.})
@String(ICPR = {Int. Conf. Pattern Recog.})
@String(BMVC= {Brit. Mach. Vis. Conf.})
@String(TOG= {ACM Trans. Graph.})
@String(TIP  = {IEEE Trans. Image Process.})
@String(TVCG  = {IEEE Trans. Vis. Comput. Graph.})
@String(TMM  = {IEEE Trans. Multimedia})
@String(ACMMM= {ACM Int. Conf. Multimedia})
@String(ICME = {Int. Conf. Multimedia and Expo})
@String(ICASSP=	{ICASSP})
@String(ICIP = {IEEE Int. Conf. Image Process.})
@String(ACCV  = {ACCV})
@String(ICLR = {Int. Conf. Learn. Represent.})
@String(IJCAI = {IJCAI})
@String(PR   = {Pattern Recognition})
@String(AAAI = {AAAI})
@String(CVPRW= {IEEE Conf. Comput. Vis. Pattern Recog. Worksh.})
@String(CSVT = {IEEE Trans. Circuit Syst. Video Technol.})

@String(SPL	= {IEEE Sign. Process. Letters})
@String(VR   = {Vis. Res.})
@String(JOV	 = {J. Vis.})
@String(TVC  = {The Vis. Comput.})
@String(JCST  = {J. Comput. Sci. Tech.})
@String(CGF  = {Comput. Graph. Forum})
@String(CVM = {Computational Visual Media})

@String(PAMI  = {IEEE TPAMI})
@String(IJCV  = {IJCV})
@String(CVPR  = {CVPR})
@String(ICCV  = {ICCV})
@String(ECCV  = {ECCV})
@String(NIPS  = {NeurIPS})
@String(NeurIPS  = {NeurIPS})
@String(ICPR  = {ICPR})
@String(BMVC  =	{BMVC})
@String(TOG   = {ACM TOG})
@String(TIP   = {IEEE TIP})
@String(TVCG  = {IEEE TVCG})
@String(TCSVT = {IEEE TCSVT})
@String(TMM   =	{IEEE TMM})
@String(ACMMM = {ACM MM})
@String(ICME  =	{ICME})
@String(ICASSP=	{ICASSP})
@String(ICIP  = {ICIP})
@String(ACCV  = {ACCV})
@String(ICLR  = {ICLR})
@String(IJCAI = {IJCAI})
@String(PR = {PR})
@String(AAAI = {AAAI})
@String(CVPRW= {CVPRW})
@String(CSVT = {IEEE TCSVT})



@inproceedings{avrahami2022blended,
  title={Blended diffusion for text-driven editing of natural images},
  author={Avrahami, Omri and Lischinski, Dani and Fried, Ohad},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={18208--18218},
  year={2022}
}


@misc{CrowsonCLIPDiff,
  author = {Crowson, Katherine },
  title = {CLIP guided diffusion HQ 256x256},
  year = {2021},
  publisher = {Self published},
  journal = {},
  howpublished = {\url{https://colab.research.google.com/drive/12a_Wrfi2_gwwAuN3VvMTwVMz9TfqctNj}},
  commit = {}
}

@misc{openai-clip,
  author = {OpenAI},
  title = {CLIP},
  year = {2021},
  publisher = {GitHub},
  journal = {GitHub repository},
  doi = {},
  howpublished = {\url{https://https://github.com/openai/CLIP}}
}


@misc{openai-guided-diff,
  author = {OpenAI},
  title = {Guided Diffusion},
  year = {2021},
  publisher = {GitHub},
  journal = {GitHub repository},
  doi = {},
  howpublished = {\url{https://github.com/openai/guided-diffusion}}
}

@article{make_a_scene,
  doi = {10.48550/ARXIV.2203.13131},
  url = {https://arxiv.org/abs/2203.13131},
  author = {Gafni, Oran and Polyak, Adam and Ashual, Oron and Sheynin, Shelly and Parikh, Devi and Taigman, Yaniv},
  keywords = {Computer Vision and Pattern Recognition (cs.CV), Artificial Intelligence (cs.AI), Computation and Language (cs.CL), Graphics (cs.GR), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Make-A-Scene: Scene-Based Text-to-Image Generation with Human Priors},
  publisher = {arXiv},
  year = {2022},
  copyright = {arXiv.org perpetual, non-exclusive license}
}


@article{lpips,
author = {Zhang, Richard and Isola, Phillip and Efros, Alexei and Shechtman, Eli and Wang, Oliver},
year = {2018},
month = {01},
pages = {},
title = {The Unreasonable Effectiveness of Deep Features as a Perceptual Metric}
}

@article{open_edit,
  doi = {10.48550/ARXIV.2008.01576},
  url = {https://arxiv.org/abs/2008.01576},
  author = {Liu, Xihui and Lin, Zhe and Zhang, Jianming and Zhao, Handong and Tran, Quan and Wang, Xiaogang and Li, Hongsheng},
  keywords = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Open-Edit: Open-Domain Image Manipulation with Open-Vocabulary Instructions},
  publisher = {arXiv},
  year = {2020},
  copyright = {arXiv.org perpetual, non-exclusive license}
}


@article{clip,
  doi = {10.48550/ARXIV.2103.00020},
  url = {https://arxiv.org/abs/2103.00020},
  author = {Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and Krueger, Gretchen and Sutskever, Ilya},
  keywords = {Computer Vision and Pattern Recognition (cs.CV), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Learning Transferable Visual Models From Natural Language Supervision},
  publisher = {arXiv},
  year = {2021},
  copyright = {arXiv.org perpetual, non-exclusive license}
}


@article{vqgan_clip,
  doi = {10.48550/ARXIV.2204.08583},
  url = {https://arxiv.org/abs/2204.08583},
  author = {Crowson, Katherine and Biderman, Stella and Kornis, Daniel and Stander, Dashiell and Hallahan, Eric and Castricato, Louis and Raff, Edward},
  keywords = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {VQGAN-CLIP: Open Domain Image Generation and Editing with Natural Language Guidance},
  publisher = {arXiv},
  year = {2022},
  copyright = {Creative Commons Attribution Share Alike 4.0 International}
}


@article{m6_ufc,
  doi = {10.48550/ARXIV.2105.14211},
  url = {https://arxiv.org/abs/2105.14211},
  author = {Zhang, Zhu and Ma, Jianxin and Zhou, Chang and Men, Rui and Li, Zhikang and Ding, Ming and Tang, Jie and Zhou, Jingren and Yang, Hongxia},
  keywords = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {M6-UFC: Unifying Multi-Modal Controls for Conditional Image Synthesis via Non-Autoregressive Generative Transformers},
  publisher = {arXiv},
  year = {2021},
  copyright = {arXiv.org perpetual, non-exclusive license}
}


@misc{poe_gan,
  doi = {10.48550/ARXIV.2112.05130},
  url = {https://arxiv.org/abs/2112.05130},
  author = {Huang, Xun and Mallya, Arun and Wang, Ting-Chun and Liu, Ming-Yu},
  keywords = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Multimodal Conditional Image Synthesis with Product-of-Experts GANs},
  publisher = {arXiv},
  year = {2021},
  copyright = {arXiv.org perpetual, non-exclusive license}
}


@article{gaugan,
  doi = {10.48550/ARXIV.1903.07291},
  url = {https://arxiv.org/abs/1903.07291},
  author = {Park, Taesung and Liu, Ming-Yu and Wang, Ting-Chun and Zhu, Jun-Yan},
  keywords = {Computer Vision and Pattern Recognition (cs.CV), Artificial Intelligence (cs.AI), Graphics (cs.GR), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences, I.5; I.5.4; I.3.3},
  title = {Semantic Image Synthesis with Spatially-Adaptive Normalization},
  publisher = {arXiv},
  year = {2019},
  copyright = {arXiv.org perpetual, non-exclusive license}
}


@article{dalle,
  doi = {10.48550/ARXIV.2102.12092},
  url = {https://arxiv.org/abs/2102.12092},
  author = {Ramesh, Aditya and Pavlov, Mikhail and Goh, Gabriel and Gray, Scott and Voss, Chelsea and Radford, Alec and Chen, Mark and Sutskever, Ilya},
  keywords = {Computer Vision and Pattern Recognition (cs.CV), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Zero-Shot Text-to-Image Generation},
  publisher = {arXiv},
  year = {2021},
  copyright = {Creative Commons Attribution 4.0 International}
}


@article{glide,
  doi = {10.48550/ARXIV.2112.10741},
  url = {https://arxiv.org/abs/2112.10741},
  author = {Nichol, Alex and Dhariwal, Prafulla and Ramesh, Aditya and Shyam, Pranav and Mishkin, Pamela and McGrew, Bob and Sutskever, Ilya and Chen, Mark},
  keywords = {Computer Vision and Pattern Recognition (cs.CV), Graphics (cs.GR), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {GLIDE: Towards Photorealistic Image Generation and Editing with Text-Guided Diffusion Models},
  publisher = {arXiv},
  year = {2021},
  copyright = {arXiv.org perpetual, non-exclusive license}
}


@article{paintbyword,
  doi = {10.48550/ARXIV.2103.10951},
  url = {https://arxiv.org/abs/2103.10951},
  author = {Bau, David and Andonian, Alex and Cui, Audrey and Park, YeonHwan and Jahanian, Ali and Oliva, Aude and Torralba, Antonio},
  keywords = {Computer Vision and Pattern Recognition (cs.CV), Artificial Intelligence (cs.AI), Graphics (cs.GR), FOS: Computer and information sciences, FOS: Computer and information sciences, I.2.10; I.4; I.3},
  title = {Paint by Word},
  publisher = {arXiv},
  year = {2021},
  copyright = {arXiv.org perpetual, non-exclusive license}
}


@article{clip_styler,
  doi = {10.48550/ARXIV.2112.00374},
  url = {https://arxiv.org/abs/2112.00374},
  author = {Kwon, Gihyun and Ye, Jong Chul},
  keywords = {Computer Vision and Pattern Recognition (cs.CV), Computation and Language (cs.CL), Image and Video Processing (eess.IV), FOS: Computer and information sciences, FOS: Computer and information sciences, FOS: Electrical engineering, electronic engineering, information engineering, FOS: Electrical engineering, electronic engineering, information engineering},
  title = {CLIPstyler: Image Style Transfer with a Single Text Condition},
  publisher = {arXiv},
  year = {2021},
  copyright = {Creative Commons Attribution 4.0 International}
}


@article{style_clip,
  doi = {10.48550/ARXIV.2103.17249},
  url = {https://arxiv.org/abs/2103.17249},
  author = {Patashnik, Or and Wu, Zongze and Shechtman, Eli and Cohen-Or, Daniel and Lischinski, Dani},
  keywords = {Computer Vision and Pattern Recognition (cs.CV), Computation and Language (cs.CL), Graphics (cs.GR), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {StyleCLIP: Text-Driven Manipulation of StyleGAN Imagery},
  publisher = {arXiv},
  year = {2021},
  copyright = {Creative Commons Attribution 4.0 International}
}


@article{affectgan,
  doi = {10.48550/ARXIV.2109.14845},
  url = {https://arxiv.org/abs/2109.14845},
  author = {Galanos, Theodoros and Liapis, Antonios and Yannakakis, Georgios N.},
  keywords = {Computer Vision and Pattern Recognition (cs.CV), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {AffectGAN: Affect-Based Generative Art Driven by Semantics},
  publisher = {arXiv},
  year = {2021},
  copyright = {Creative Commons Attribution 4.0 International}
}

@article{wikiart,
  doi = {10.48550/ARXIV.1505.00855},
  url = {https://arxiv.org/abs/1505.00855},
  author = {Saleh, Babak and Elgammal, Ahmed},
  keywords = {Computer Vision and Pattern Recognition (cs.CV), Information Retrieval (cs.IR), Machine Learning (cs.LG), Multimedia (cs.MM), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Large-scale Classification of Fine-Art Paintings: Learning The Right Metric on The Right Feature},
  publisher = {arXiv},
  year = {2015},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@article{vqgan,
  doi = {10.48550/ARXIV.2012.09841},
  url = {https://arxiv.org/abs/2012.09841},
  author = {Esser, Patrick and Rombach, Robin and Ommer, Björn},
  keywords = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Taming Transformers for High-Resolution Image Synthesis},
  publisher = {arXiv},
  year = {2020},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{diffusion_models_dhariwal,
  doi = {10.48550/ARXIV.2105.05233},
  url = {https://arxiv.org/abs/2105.05233},
  author = {Dhariwal, Prafulla and Nichol, Alex},
  keywords = {Machine Learning (cs.LG), Artificial Intelligence (cs.AI), Computer Vision and Pattern Recognition (cs.CV), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Diffusion Models Beat GANs on Image Synthesis},
  publisher = {arXiv},
  year = {2021},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@article{clipglass,
author={Federico Galatolo. and Mario Cimino. and Gigliola Vaglini},
title={Generating Images from Caption and Vice Versa via CLIP-Guided Generative Latent Space Search},
journal={Proceedings of the International Conference on Image Processing and Vision Engineering},
year={2021},
volume={},
pages={},
publisher={SCITEPRESS - Science and Technology Publications},
doi={10.5220/0010503701660174},
issn={},
}


@article{mirza2014conditional,
  title={Conditional generative adversarial nets},
  author={Mirza, Mehdi and Osindero, Simon},
  journal={arXiv preprint arXiv:1411.1784},
  year={2014}
}

@inproceedings{wang2018high,
  title={High-resolution image synthesis and semantic manipulation with conditional gans},
  author={Wang, Ting-Chun and Liu, Ming-Yu and Zhu, Jun-Yan and Tao, Andrew and Kautz, Jan and Catanzaro, Bryan},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={8798--8807},
  year={2018}
}

@InProceedings{repaint,
    author    = {Lugmayr, Andreas and Danelljan, Martin and Romero, Andres and Yu, Fisher and Timofte, Radu and Van Gool, Luc},
    title     = {RePaint: Inpainting Using Denoising Diffusion Probabilistic Models},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    month     = {June},
    year      = {2022},
    pages     = {11461-11471}
}


@article{ho2020denoising,
  title={Denoising diffusion probabilistic models},
  author={Ho, Jonathan and Jain, Ajay and Abbeel, Pieter},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={6840--6851},
  year={2020}
}



@inproceedings{rombach2022high,
  title={High-resolution image synthesis with latent diffusion models},
  author={Rombach, Robin and Blattmann, Andreas and Lorenz, Dominik and Esser, Patrick and Ommer, Bj{\"o}rn},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={10684--10695},
  year={2022}
}


%Related Work 
@article{liu2022compositional,
  title={Compositional Visual Generation with Composable Diffusion Models},
  author={Liu, Nan and Li, Shuang and Du, Yilun and Torralba, Antonio and Tenenbaum, Joshua B},
  journal={arXiv preprint arXiv:2206.01714},
  year={2022}
}

@article{ho2022classifier,
  title={Classifier-free diffusion guidance},
  author={Ho, Jonathan and Salimans, Tim},
  journal={arXiv preprint arXiv:2207.12598},
  year={2022}
}


@article{song2020denoising,
  title={Denoising diffusion implicit models},
  author={Song, Jiaming and Meng, Chenlin and Ermon, Stefano},
  journal={arXiv preprint arXiv:2010.02502},
  year={2020}
}

@article{suppl2023CD,
  title={Supplementary material for this paper - Composite Diffusion: Is the whole >= the sum of its parts?},
  author={Supplementary},
  journal={SIGGRAPH:2023},
  year={}
}


% For Evaluation
@article{bylinskii2022towards,
  title={Towards Better User Studies in Computer Graphics and Vision},
  author={Bylinskii, Zoya and Herman, Laura and Hertzmann, Aaron and Hutka, Stefanie and Zhang, Yile},
  journal={arXiv preprint arXiv:2206.11461},
  year={2022}
}

@misc{rombach2021highresolution,
      title={High-Resolution Image Synthesis with Latent Diffusion Models}, 
      author={Robin Rombach and Andreas Blattmann and Dominik Lorenz and Patrick Esser and Björn Ommer},
      year={2021},
      eprint={2112.10752},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{FinetunedSD,
  author = {AQ},
  title = {Finetuned Diffusion - a Hugging Face Space},
  year = {2022},
  publisher = {Self published},
  journal = {},
  howpublished = {\url{https://huggingface.co/spaces/anzorq/finetuned_diffusion}},
  commit = {}
}


@article{ramesh2022hierarchical,
  title={Hierarchical text-conditional image generation with clip latents},
  author={Ramesh, Aditya and Dhariwal, Prafulla and Nichol, Alex and Chu, Casey and Chen, Mark},
  journal={arXiv preprint arXiv:2204.06125},
  year={2022}
}
@article{saharia2022photorealistic,
  title={Photorealistic Text-to-Image Diffusion Models with Deep Language Understanding},
  author={Saharia, Chitwan and Chan, William and Saxena, Saurabh and Li, Lala and Whang, Jay and Denton, Emily and Ghasemipour, Seyed Kamyar Seyed and Ayan, Burcu Karagol and Mahdavi, S Sara and Lopes, Rapha Gontijo and others},
  journal={arXiv preprint arXiv:2205.11487},
  year={2022}
}

@inproceedings{hosu2019effective,
  title={Effective aesthetics prediction with multi-level spatially pooled features},
  author={Hosu, Vlad and Goldlucke, Bastian and Saupe, Dietmar},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={9375--9383},
  year={2019}
}

@inproceedings{chen2015efficient,
  title={An efficient statistical method for image noise level estimation},
  author={Chen, Guangyong and Zhu, Fengyuan and Ann Heng, Pheng},
  booktitle={Proceedings of the IEEE International Conference on Computer Vision},
  pages={477--485},
  year={2015}
}



@misc{linear_probe,
  author = {Katherine Crowson},
  title = {AVA Linear Probe},
  year = {2021},
  publisher = {Self published},
  journal = {Twitter},
  howpublished = {\url{https://twitter.com/RiversHaveWings/status/1472346186728173568?s=20&t=T-HRr3Gw5HRGjQaMDtRe3A}},
  commit = {}
}

@article{weng2021diffusion,
  title   = {What are diffusion models?},
  author  = {Weng, Lilian},
  journal = {lilianweng.github.io},
  year    = {2021},
  month   = {Jul},
  url     = {https://lilianweng.github.io/posts/2021-07-11-diffusion-models/}
}

@misc{dieleman2022guidance,
  author = {Dieleman, Sander},
  title = {Guidance: a cheat code for diffusion models},
  url = {https://benanne.github.io/2022/05/26/guidance.html},
  year = {2022}
}



@inproceedings{bertalmio2000image,
  title={Image inpainting},
  author={Bertalmio, Marcelo and Sapiro, Guillermo and Caselles, Vincent and Ballester, Coloma},
  booktitle={Proceedings of the 27th annual conference on Computer graphics and interactive techniques},
  pages={417--424},
  year={2000}
}


@article{mokady2022null,
  title={Null-text Inversion for Editing Real Images using Guided Diffusion Models},
  author={Mokady, Ron and Hertz, Amir and Aberman, Kfir and Pritch, Yael and Cohen-Or, Daniel},
  journal={arXiv preprint arXiv:2211.09794},
  year={2022}
}

@article{ruiz2022dreambooth,
  title={DreamBooth: Fine Tuning Text-to-image Diffusion Models for Subject-Driven Generation},
  author={Ruiz, Nataniel and Li, Yuanzhen and Jampani, Varun and Pritch, Yael and Rubinstein, Michael and Aberman, Kfir},
  booktitle={arXiv preprint arxiv:2208.12242},
  year={2022}
}

@article{hertz2022prompt,
  title={Prompt-to-prompt image editing with cross attention control},
  author={Hertz, Amir and Mokady, Ron and Tenenbaum, Jay and Aberman, Kfir and Pritch, Yael and Cohen-Or, Daniel},
  booktitle={arXiv preprint arXiv:2208.01626},
  year={2022}
}

@article{couairon2022diffedit,
  title={Diffedit: Diffusion-based semantic image editing with mask guidance},
  author={Couairon, Guillaume and Verbeek, Jakob and Schwenk, Holger and Cord, Matthieu},
  journal={arXiv preprint arXiv:2210.11427},
  year={2022}
}


@misc{deep_floyd,
  author = {Deep Floyd},
  title = {IF},
  year = {2023},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/deep-floyd/IF.git}},
}


@article{scaffolding_2022_ref,
author = {Zhe Yin and Carlos Caldas},
title = {Scaffolding in industrial construction projects: current practices, issues, and potential solutions},
journal = {International Journal of Construction Management},
volume = {22},
number = {13},
pages = {2554-2563},
year  = {2022},
publisher = {Taylor & Francis},
doi = {10.1080/15623599.2020.1808562},

}


 @MISC{samplers_sd_agata,
   author =       "Agata Mlynarczyk",
   title =        "Stable Diffusion and the Samplers Mystery",
   editor =       "Weights and Biases",
   month =        "March",
   year =         "2023",
   url =          "\url{https://wandb.ai/agatamlyn/basic-intro/reports/Stable-Diffusion-and-the-Samplers-Mystery--VmlldzoyNTc4MDky }",

 }

@MISC{samplers_sd_andrew,
   author =       "Andrew",
   title =        "Stable Diffusion Samplers: A Comprehensive Guide",
   editor =       "Stable Diffusion Art",
   month =        "June",
   year =         "2023",
   url =          "\url{https://stable-diffusion-art.com/samplers/}",
   
 }

@article{bar2023multidiffusion,
  title={MultiDiffusion: Fusing Diffusion Paths for Controlled Image Generation},
  author={Bar-Tal, Omer and Yariv, Lior and Lipman, Yaron and Dekel, Tali},
  journal={arXiv preprint arXiv:2302.08113},
  year={2023}
}

@inproceedings{FID_NIPS,
 author = {Heusel, Martin and Ramsauer, Hubert and Unterthiner, Thomas and Nessler, Bernhard and Hochreiter, Sepp},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {I. Guyon and U. Von Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {GANs Trained by a Two Time-Scale Update Rule Converge to a Local Nash Equilibrium},
 url = {https://proceedings.neurips.cc/paper_files/paper/2017/file/8a1d694707eb0fefe65871369074926d-Paper.pdf},
 volume = {30},
 year = {2017}
}

@inproceedings{IS_NIPS,
 author = {Salimans, Tim and Goodfellow, Ian and Zaremba, Wojciech and Cheung, Vicki and Radford, Alec and Chen, Xi and Chen, Xi},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {D. Lee and M. Sugiyama and U. Luxburg and I. Guyon and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Improved Techniques for Training GANs},
 url = {https://proceedings.neurips.cc/paper_files/paper/2016/file/8a3363abe792db2d8761d6403605aeb7-Paper.pdf},
 volume = {29},
 year = {2016}
}

@article{borji2022pros,
  title={Pros and cons of GAN evaluation measures: New developments},
  author={Borji, Ali},
  journal={Computer Vision and Image Understanding},
  volume={215},
  pages={103329},
  year={2022},
  publisher={Elsevier}
}

@article{sajjadi2018assessing,
  title={Assessing generative models via precision and recall},
  author={Sajjadi, Mehdi SM and Bachem, Olivier and Lucic, Mario and Bousquet, Olivier and Gelly, Sylvain},
  journal={Advances in neural information processing systems},
  volume={31},
  year={2018}
}


@misc{artist_impact_wired,
  author = {Paul, Ford},
  title = {Dear Artists: Do Not Fear AI Image Generators},
  editor =       "Wired",
  url = {https://www.wired.com/story/artists-do-not-fear-ai-image-generators/},
  year = {2022}
}












