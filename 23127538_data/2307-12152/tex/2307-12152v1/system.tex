\section{System Implementation}
\label{sec:system}

% Figure environment removed

Figure~\ref{fig:sys_arch} shows our system architecture.

\para{Server: } Our video server runs a standard video codec (\eg, VP9, H264 or H265) to encode a video as usually. Meanwhile, it extracts a binary point code and reliably transmits the code to the client via TCP. \zhaoyuan{Video contents are streamed using QUIC. QUIC~\cite{langley2017quic} has been a popular transport protocol for video streaming (\eg, YouTube, Instagram) as well as other applications, such as Gmail and Uber due to its more efficient connection setup and faster retransmission than TCP. Google reported that QUIC could reduce the latency for Google search by more than 2\% and the rebuffer time for YouTube by 9\% compared to TCP \cite{chrome-quic}. We find YouTube uses QUIC to stream recently uploaded and popular videos via Wireshark. QUIC has fast retransmission logic, but it still has 1.6\% packet loss in 5G networks.
} 

\para{Client: } Our client runs {\em our} enhancement-aware ABR algorithm to select the video bit rate and request the selected rate from the server. It runs a standard video decoder to decode the video frames as usual. After successful decoding, it applies {\em our} SR to enhance the video resolution and add the enhanced video frame to its buffer. Whenever a video frame needs to be played but its content is not completely available, it runs {\em our} video recovery to recover the video and feeds it to the player. \zhaoyuan{We use an iPhone 12 
% and a Macbook Air 
as the mobile client in this paper.} 

\para{Model deployment: } Since we perform the video enhancement on the receiver side, we need to deploy our SR and recovery models to a mobile device. CoreML is commonly used because it optimizes on-device performance for iOS by leveraging the CPU, GPU, and Neural Engine. We observe that our model with the format of CoreML runs faster than ONNX, Pytorch Mobile, and TensorFlow Lite. However, the grid sample operation of warping runs slowly because it does not officially support GPU. To address this issue, we leverage Metal Performance Shaders (MPS) to create a custom grid sample layer running on GPU. MPS is a framework with handy Metal compute kernels and CoreML uses it for model inference on GPU. It also provides us with many APIs to create a custom layer so that the grid sample is implemented with a GPU acceleration. \zhaoyuan{In addition, we perform warping at a smaller scale of 270p instead of 1080p, thereby reducing the warping time from $29ms$ to $5ms$ on the iPhone 12. 
% However, we continue to utilize 1080p warping on the Macbook Air, which requires $8ms$ for the process. 
We use FP16 precision for both inputs and model weights without performance degradation to further reduce the inference time. The final total inference time is $22ms$.}
% and $20ms$ on the iPhone 12 and Macbook Air, respectively.}