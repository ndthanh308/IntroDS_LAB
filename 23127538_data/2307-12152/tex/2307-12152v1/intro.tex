\section{Introduction}
\label{sec:intro}

\para{Motivation:} Machine learning (ML) has seen tremendous progress and penetrated almost every aspect of our life. One of the major applications of ML is to apply it to enhancing video quality. In particular, videos account for the majority of Internet traffic. However, the Internet bandwidth is highly fluctuating and hard to predict; when the network condition degrades, the video can get lost or its sending rate has to decrease. Many ML-based video enhancement approaches have been developed.

Existing ML-based video quality enhancement mostly focuses on improving video resolution given the complete yet lower-resolution video frames. In practice, at the playout time, the receiver may not have a complete video frame to play either due to excessive delay or packet losses. Many measurement studies report a widely fluctuating delay in the Internet and wireless networks (\eg, \cite{constancy,5G-measurement1,5G-measurement2}). Meanwhile, packet losses are also very common. In a wireline network, losses happen due to queue drop during network congestion. 
% or excessive delay, which causes video frames to miss their deadline. 
In a wireless network, in addition to network congestion and large delay, losses also occur during low signal-to-noise ratio (SNR), collisions, and handoffs. For example, several measurement studies report some receivers experienced loss rates above 10\%~\cite{constancy,udp-loss}. \cite{5G-measurement2} reports during handoff the average latency increases by 2.26x and loss rates increase by 2.24x, which significantly degrades video streaming performance. \cite{5G-measurement1} reports the loss rates of 5G sessions are several-fold higher than 4G sessions. Moreover, adding a large buffer may prevent packet drop but lead to bufferbloat problem, which is prevalent in the Internet (\eg, \cite{bufferbloat1,bufferbloat2,bufferbloat3}), causes excessive delay, and harms video streaming performance. 


% 3) For instance, the packets are encrypted individually, so that they do not result in the encrypted data waiting for partial packets. 
%QUIC's packet number is strictly increasing within a packet number space and directly encodes transmission order. A higher packet number signifies that the packet was sent later, and a lower packet number signifies that the packet was sent earlier. When a packet containing ack-eliciting frames is detected lost, QUIC includes necessary frames in a new packet with a new packet number, removing ambiguity about which packet is acknowledged when an ACK is received. Consequently, more accurate RTT measurements can be made, spurious retransmissions are trivially detected, and mechanisms such as Fast Retransmit can be applied universally, based only on packet number.


% Many applications, such as Instagram, Uber, Gmail, and YouTube, have adopted QUIC~\cite{langley2017quic} that transports over UDP as their network protocol because of the following advantages: First, it has much less connection setup overhead than TCP by eliminating TCP connection setup and including TLS-like security information in the initial handshake packets. Second, it is error tolerant because it controls the flow for each stream separately. It can recover lost packets via retransmission after a timeout and is expected to be much faster than TCP \cite{quic-rfc9002}. Google reported that QUIC could reduce the latency for Google search by more than 2\% and the rebuffer time for YouTube by 9\% compared to TCP \cite{chrome-quic}. We found YouTube applies QUIC for recently uploaded and popular videos via Wireshark. QUIC has fast retransmission logic, but it still has more than 1\% packet loss in 5G networks.

% constancy: Packet loss in the datasets was in general low. Over all of W1, 0.87% of the packets were lost, and for W2, 0.60%. However, as is common with Internet behavior, we find a wide range: 11–15% of the traces experienced no loss; 47–52% had some loss, but at a rate of 0.1% or less; 21–24% had loss rates of 0.1–1.0%; 12–15% had loss rates of 1.0–10%; and 0.5–1% had loss rates exceeding 10%.

% We find the average latency is 2.26× higher compared to no-handover periods (up to 14.5× higher in the worst case). Likewise, the average packet loss rate increases by 2.24×

% The results (Fig. 9) show that the packet loss of 5G sessions is multi-fold over the 4G sessions

Packet losses not only reduce the available data rate but also lead to a loss of a complete or partial video frame. While Forward Error Correction (FEC) and retransmissions have been widely used for loss recovery, their effectiveness is still quite limited. Retransmissions incur significant delay and may not be acceptable when round-trip time (RTT) is large.  FEC is expensive: as we show in Section~\ref{sec:motivation}, 35\% FEC is required in order to recover 5\% packet losses! Meanwhile, ML-based video prediction can potentially be used to conceal video errors or losses. However, their accuracy is limited since new content will appear in the next video frame, which makes it hard to predict. {\em Therefore, it is necessary to develop effective video recovery schemes.}

Moreover, various super-resolution (SR) algorithms have been developed to provide good video quality (\eg, \cite{chan2021basicvsr,yi2019progressive,sr3, sr4, sr5, sr6, sr7}). Yet despite significant research, the existing SR cannot support real-time execution on mobile devices. Interestingly, video streaming for mobile devices is becoming increasingly popular. \cite{mobile-video1} reports that 60\%+ U.S. digital video audiences watch videos using their smartphones. {\em This calls for the development of SR for mobile devices.} 

In addition, Adaptive video Bit Rate (ABR) has been widely used in the Internet to dynamically adjust the video streaming rate according to the current network conditions. Existing work adjusts the video rate based on what content has been received by the client. {\em As the clients increasingly adopt advanced video enhancement techniques, it is important to use the enhanced video to drive the design of ABR algorithms.}

\para{Our approach:} Inspired by the existing video enhancement and its limitation, in this paper we aim to advance the state of the art by developing (i) video recovery schemes, (ii) SR for mobile devices, and (iii) enhancement aware video recovery. A nice property of our design is that our approach works with existing video codecs and is easy to deploy. 

More specifically, for (i), we observe that simply predicting videos based on previously received data is error prone. If the sender could send some hint about the current videos in a reliable way, the receiver can use the hint to significantly improve the video prediction. The main challenge is to determine what hint to provide to optimize the recovered video. We develop a novel way to extract compact yet essential states from a video sequence and reliably transmit the video frame state (\eg, using TCP) for video recovery. Inspired by recent quantized image coding techniques~\cite{AdityaRamesh2021ZeroShotTG,WilsonYan2021VideoGPTVG}, we exploit the temporal locality in the video and employ a binary  point code to encode a frame into a very low-resolution binary point code.  % This code can help the receiver to reconstruct the video frame in case the video frame can be not successfully decoded. 
We find that the learned binary point code encodes both inter-frame movement information and contour information. Our experiments demonstrate that with the learned binary point code, the receiver can significantly improve the quality of video recovery. \yifan{In our system, we leverage TCP transmissions to deliver binary point code as auxiliary information to help  video recovery.} Our video recovery has the following distinct advantages: (i) Our binary point code is highly compact: within 1 KB, and yet significantly improves the video quality, (ii) it supports real-time extraction on the server and real-time video recovery on a mobile device, and (iii) it handles both partial and complete video frame recovery. 

% When the network state is highly unstable, video streams may not be transmitted correctly and packets can get lost due to network congestion and/or wireless losses. To tackle this issue, we develop a novel video frame recovery approach. % aim to characterize the video information using a compact transmission medium, reducing the reliance on network bandwidth. 
% Our high-level idea is to send a small amount of extra information about a video frame, which we call is as a state, along with the video data coded using traditional video codec (\eg, H264 or H265) and use the state information to help reconstruct the video frame in case the video frame cannot be decoded completely. We ensure the small state information can be reliably received by using TCP and/or tagging its corresponding packet as a higher priority. The main challenge is how to extract the state for a given video frame. Inspired by recent quantized image coding techniques~\cite{AdityaRamesh2021ZeroShotTG,WilsonYan2021VideoGPTVG}, we exploit the temporal locality in the video and employ a binary discrete point code to encode a frame into a very low-resolution binary point code within 1KB per frame.  This code can help the receiver to reconstruct the video frame in case the video frame can be not successfully decoded.  We find that the learned binary point code encodes both inter-frame movement information, similar to a dense Motion Vector in codec, and also contour information. Our experiments demonstrate that with the learned binary point code, although small (less than 1KB per frame), can significantly improve the quality of video recovery.

For (ii), we also advance the state-of-the-art in super-resolution by developing a novel video super-resolution algorithm at multiple resolutions. To address the limited computing power and resources on mobile devices, we use a single neural network model for all resolutions and leverage shared parameters to reduce memory overhead. At the bottom of the network, distinct structures have been designed to accommodate different resolutions (240p, 360p, 480p to 1080p) and provide the ABR algorithm with the flexibility to choose different rates. Different from the existing algorithms, it can support (i) different input video resolutions, and (ii) real-time execution on mobile devices (\eg, iPhone 12). 

% For (ii), To enhance the video quality, we develop a model that offers super-resolution at multiple scales. 

For (iii), in addition to advancing receiver-side video enhancements, we further develop receiver-aware video bit-rate adaptation. Existing video rate adaptation selects the transmission video rate to maximize the video quality of experience (QoE), which consists of three major factors: video quality determined by the video data rate, change in the video quality, and rebuffering time. The video quality is determined based on the data transmitted to the receiver. Now that the receiver uses various enhancement techniques to improve the video quality, its actual video quality is likely to be much higher than the video directly received from the sender. Therefore a more effective approach is to use the enhanced video quality to drive the video bit rate decision. We develop an approach to efficiently estimate the impact of video recovery and SR on the video quality and rebuffering time, and use the estimation to facilitate bit rate selection. 

To understand the benefit of our video enhancement approaches and the enhancement-aware ABR algorithm, \zhaoyuan{we conduct our evaluation using QUIC~\cite{langley2017quic} under a variety of network conditions, including WiFi, 3G, 4G, and 5G networks on iPhone 12.}
% and a Macbook Air.} 
\kj{Since iPhone 12 and higher versions account for more than 94\% of the total U.S. iPhone purchases in Q1 2023, reported in~\cite{CIRP}, the performance of most users' smartphones should exceed or be on par with that of the iPhone 12.}
% we conduct our evaluation under a variety of network conditions, including WiFi, 3G, 4G, 5G, and low earth orbit (LEO) satellite networks on iPhone12 Pro Max. 

Our major contributions can be summarized as follows:
\begin{sitemize}
    \item Our video recovery approach efficiently extracts binary point code from each video frame to better support video reconstruction at the receiver upon partial or complete video frame losses or excessive delay. 
    \item Our super-resolution algorithm further enhances the resolution of the video frames in real-time on mobile devices.
    \item Our video bit rate adaptation harnesses the full benefit of video recovery and super-resolution approaches by using the video QoE after enhancement for rate adaptation.
    \item Our evaluation in diverse types of networks shows that our approach enables real-time enhancement and improves the video QoE by 23.7\% - 51\%, 32.2\% - 68\%, 37.1\% - 82\%, and 29\% - 72\% in 3G, 4G, 5G, and WiFi networks, respectively. 
\end{sitemize}

This paper does not involve human subjects and has no ethical concerns. We plan to release our code and traces to the public. 