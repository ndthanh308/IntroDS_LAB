\section{Related Work}
\label{sec:related}

We classify existing work into the following three areas: (i) video recovery, (ii) video super-resolution, and (iii) ABR algorithms. 

\para{Video recovery: } Video recovery work can be categorized into two areas: FEC-based and ML-based approaches. FEC algorithms are frequently employed in video streaming systems (\eg, DASH, Apple HLS) to enhance video quality over unreliable networks. These algorithms add redundant information to the original video data, enabling the receiver to recover lost packets. Popular FEC algorithms include Reed-Solomon (RS) code~\cite{reed1960polynomial} for correcting burst errors, Low-Density Parity-Check (LDPC) code for efficient XOR-based error recovery, and Convolutional code for correcting errors spread across multiple bits. The choice of FEC algorithm depends on the specific requirements of the streaming system and the expected error types in the network.

Recently, many ML based algorithms have been proposed for video prediction, such as convolutional networks (\eg, \cite{cnn1,cnn2,cnn3,cnn4}), recurrent networks (\eg, \cite{rnn1,rnn2}), and generative networks (GANs). Among them, GANs are particularly effective for generation tasks. However, GANs are typically designed to generate realistic images, which may not be necessarily similar to the next video frame.  Several other works utilize neural networks to realize video error concealment such that corrupted frames can be recovered from previous frames. \cite{sankisa2018video} predicts optical flow from generated flows of past frames to reconstruct the degraded portion of the frame. \cite{sankisa2020temporal} designs a capsule network framework to extract the decoded temporal dependencies, which are further combined with the past frames and passed through a reconstruction network to perform motion-compensated error concealment.

\para{Video super-resolution: } There has been extensive work on designing Video super-resolution (SR) techniques. They leverage the previous several video frames to enhance the resolution of the current frame. BasicVSR~\cite{chan2021basicvsr} employs bidirectional RCNN where the features are propagated forward and backward independently. Moreover, PFNL~\cite{yi2019progressive} leverages the non-local sub-network to compute the correlations between all possible pixels within and across frames. In the motion estimation and motion compensation (MEMC) methods~\cite{sr3, sr4, sr5, sr6, sr7}, most of them adopt deep learning techniques to estimate the optical flow such that the motion information can be used to boost the quality of video super-resolution. NAS~\cite{yeo2018neural} is an adaptive streaming system that utilize scalable content-aware super-resolution DNNs. However, NAS uses desktop-class GPUs as clients and can only support on-demand video streaming. NEMO~\cite{yeo2020nemo} extends this idea to mobile devices, achieving real-time video enhancement. However, NEMO requires offline preparation for anchor point selection and separate model training, limiting its support to on-demand video streaming only. \zhaoyuan{PreSR~\cite{zhou2022presr} implements selective prefetching of video chunks for SR to enhance QoE, but it lacks real-time performance on mobile devices and involves significant optimization costs. DeepStream~\cite{amirpour2022deepstream} optimizes bitrate ladders and utilizes a lightweight SR model, but it still requires high-performance GPUs at the client side.} In 360-degree video streaming systems, ~\cite{chen2020sr360, dasari2020streaming} use SR techniques but do not support  general video streaming. \zhaoyuan{Dejavu~\cite{hu2019dejavu} leverages visual content similarity across video conference sessions to learn a mapping for real-time content enhancement. However, it necessitates offline learning using the sender's historical sessions, making it less effective for general video streaming where content changes are more substantial.}

% \para{Client video enhancement} 

%\para{Forward error correction (FEC)}
% FEC algorithms are commonly used in video streaming systems (e.g. DASH, Apple HLS) to enhance the quality of video transmission over unreliable networks. FEC algorithms work by adding redundant information to the original video data, which allows the receiver to recover the original data even if some packets get lost in transit. There are some widely used FEC algorithms in video streaming systems. Reed-Solomon (RS) code~\cite{reed1960polynomial} is a linear block code to correct errors in a block of data and is commonly used to correct the errors caused by burst loss. Low-Density Parity-Check (LDPC) code uses mathematical algorithms to add redundant data to the original data such that it can correct errors more computationally efficiently. Convolutional code utilizes a convolutional encoder to correct the errors that are spread over a large number of bits. The choice of the FEC algorithm depends on the specific requirements of the video streaming system and the type of errors that are likely to occur in the network.

\para{ABR algorithms:} In HTTP-based streaming (e.g. DASH, Apple HLS), videos are split into fixed-length chunks. Each chuck typically lasts 1-10 seconds each and is encoded at multiple bitrates. A client then uses an ABR to select a bitrate level for each chunk to take into account the amount of data already buffered locally and predict how long it takes to download a chunk at a given bitrate. A variety of ABR algorithms have been developed~\cite{akhtar2018oboe, huang2014buffer, jiang2012improving, mao2017neural, spiteri2020bola, yin2015control}. 
% which primarily differ based on how the algorithms choose which bitrate to use for each chunk by reconciling the above factors. 
Among these approaches, MPC~\cite{yin2015control} and Pensieve~\cite{mao2017neural} demonstrate that directly optimizing for the desired QoE objective delivers better outcomes than heuristics-based approaches. In particular, Pensieve uses deep reinforcement learning and learns through “observations” how past decisions and the current state impact the video quality. Although these algorithms successfully cope with bandwidth variations, they do not consider the effect of client-side video enhancement.
% such that the video quality heavily depends on the available network bandwidth. 

NAS~\cite{yeo2018neural} and NEMO~\cite{yeo2020nemo} consider the impact of enhancement to some extent, but they do not provide detailed algorithms. 
% enhancement-aware ABR algorithm for QoE optimization. They extend Pensieve to decide when to download a super-resolution model and which video bitrate to use for each video chunk. However, 
Moreover, streaming DNN models introduces additional latency and is not able to provide an improvement for all video chunks. In comparison, our approach supports general videos and does not need offline DNN training for an individual video. Moreover, its ABR algorithm is aware of the impact of both video recovery and SR. % Our enhancement-aware ABR uses more general DNN models stored at clients before streaming videos and  video super-resolution and video recovery so that the bitrate options can be chosen more wisely. 

\para{Summary:} Our work advances the state of the art in the following aspects: (i) we develop a novel video recovery scheme that extracts and leverages a compact state about the current video frame; compared with existing prediction schemes, which only use the previous video frames, our recovery can achieve higher accuracy with little overhead; (ii) we develop a new video super resolution scheme that achieves high video quality in real-time on mobile devices, whereas the existing SR works are too heavy weight for mobile devices; and (iii) we adapt video bit rate that explicitly optimizes the video QoE after applying video recovery and super-resolution; and (iv) we demonstrate the benefit of our approach under diverse network conditions, including WiFi, 3G, 4G, and 5G network conditions. 