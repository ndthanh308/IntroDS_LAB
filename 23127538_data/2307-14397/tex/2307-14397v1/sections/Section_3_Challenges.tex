
\def\checkmark{\tikz\fill[scale=0.4](0,.35) -- (.25,0) -- (1,.7) -- (.25,.15) -- cycle;} 

\subsection{Generative Modeling under Data Constraint: Challenges}
\label{ssec:challenges}

\subsubsection{Challenges for Training Generative Models under Data Constraint}~
Data constraints typically introduce additional challenges and 
amplify existing ones when training generative models. 
Here, we delve into the challenges of training GM-DC.
These limitations include pervasive issues of overfitting and frequency bias which are commonly observed across various approaches.
Additionally, knowledge transfer between domains brings forth specific problems including the proximity between source and target domains and the transfer of incompatible source knowledge.
As shown in Fig.~\ref{fig:works_statistics}, 
around $39\%$ of works directly rely on knowledge transfer as a mainstream method to tackle GM-DC, and more than $20\%$ of works propose methods based on other approaches that are compatible with transfer learning.

\vspace{0.1cm}
\textbf{Overfitting to Training Data.}
In machine learning, overfitting is a common issue
when powerful models start to 
 memorize the training data instead of learning the
generalizable semantics \cite{santos2022avoiding}.
In generative modeling, 
the overfitting problem exacerbates 
under data constraints due to the high capacity of current generative models \cite{noguchi2019bsa, liu2021fastgan, karras2020ada}. 
When limited training data is available,  generative models may simply remember the training data \cite{li2020ewc, ojha2021cdc} and learn to generate the exact training samples \cite{zhao2022adam} instead of capturing the data distribution.
Furthermore, under data constraints, generative modeling is more prone to mode collapse \cite{tran2021dag}, i.e., the generators learn only a limited set of modes and fail to capture other modes of the data distribution, resulting in limited diversity 
in generated samples \cite{yu2022understanding, nguyen2023rethinking}.

\vspace{0.1cm}
\textbf{Frequency Biases.}
Generative models are notorious for their spectral bias \cite{rahaman2019nnfrequncybias, khayatkhoei2022ganfrequencybias}, \ie tendency to prioritize fitting low-frequency components while disregarding high-frequency components within a data distribution \cite{durall2020watchupconvolution, tancik2020fourier, chandrasegaran2021closer}. 
The exclusion of these high-frequency components which encode intricate image details \cite{gonzales1987digital} can significantly impact the quality of generated samples, \ie, accurate modeling of high-frequency details is critical in various fields including medical imaging (X-rays, CT-scans, MRIs), satellite/ aerial imaging, astrophotography, and art restoration.
This issue becomes more severe under limited data \cite{yang2022fregan, yang2022wavegan} as even advanced network structures tailored for such scenarios \cite{liu2021fastgan} struggle to maintain the desired level of details in generated samples.




% T-SNE visualization of features
% Figure environment removed

\vspace{0.2cm}




\vspace{0.1cm}
\textbf{Modeling Distant/ Remote Target Domains under GM-DC Setups.}~
Substantial number of GM-DC tasks rely on the transfer learning principle (uGM-2, uGM-3, cGM-2, cGM-3, SGM),  
which aims to enhance the generative capabilities for a target domain by leveraging the knowledge of a generator pre-trained on a large and diverse source domain (See Fig. \ref{fig:sankey}).
A significant amount of research has been
focused on  target domains that are semantically/ perpetually similar to the source domain, \eg, learn to generate Baby faces using a pre-trained generator trained on Human faces. 
In particular, when dealing with GM-DC setups involving significant domain shifts between the source and target domains (Human Faces$\rightarrow$Animal Faces), many proposed methods fail to outperform a basic fine-tuning approach \cite{zhao2022adam}.  This is due to these methods prioritizing knowledge preservation from the source domain/ task, overlooking the adaptation step to the target domain \cite{zhao2022adam}.
Recently, adaptation-aware algorithms 
have characterized source$\rightarrow$target domain proximity \cite{zhao2022adam} and addressed GM-DC setups with pronounced domain shifts between the source and target domains (Human Faces$\rightarrow$Animal Faces) \cite{zhao2022adam, zhao2023rick}.
To understand the concept of distant/ remote target domains,
we additionally introduce two remote target domains that further exhibit a considerable degree of domain shifts: 
i) Human Faces (FFHQ) \cite{karras2019style}$\rightarrow$ Flowers \cite{nilsback2008oxford_flower}, 
ii) Human Faces (FFHQ) \cite{karras2019style}$\rightarrow$Church \cite{yu2015lsun}.
Domain proximity visualization 
is shown in Fig. \ref{fig:proximity-visualization}.
In particular, we conducted a GM-DC experiment (uGM-2) to adapt a pre-trained Human face (FFHQ) generator to Flowers under 10-shot setup using AdAM \cite{zhao2022adam}, 
obtaining a FID value of 124.46. 
Adaptation results are shown in Fig. \ref{fig:proximity-measurements-and-10-shot-flowers}.
As one can observe, multiple instances of {low quality synthesis} are observed in AdAM \cite{zhao2022adam}.
In summary, we remark that modeling distant/ remote target domains remains an important and challenging area for GM-DC.

\vspace{0.1cm}
\textbf{Identifying and Removing Incompatible Knowledge Transfer.}~
Another challenge with 
leveraging source domain's knowledge for GM-DC tasks is
incompatible knowledge transfer, which is discovered recently \cite{zhao2023rick}.
In particular, many methods may transfer knowledge that is  
incompatible with the target domain, \eg hat from source domain FFHQ to target domain flowers, significantly degrading the realisticness of the generated samples.
In Fig. \ref{fig:proximity-measurements-and-10-shot-flowers}, 
we show multiple examples of {incompatible knowledge transfer} using AdAM for 10-shot flower adaptation.
Although some recent effort has been invested in identifying and proactively truncating incompatible knowledge transfer \cite{zhao2023rick} in Human Faces $\rightarrow$ Animal Faces adaptation setups, it is worth noting that identifying and removing incompatible knowledge remains a critical and demanding area in GM-DC.



% Figure environment removed


\vspace{0.2cm}
\subsubsection{Challenges on Selecting Samples for GM-DC}~
Although considerable research effort has been invested in developing algorithms for GM-DC, the task of sample selection for GM-DC remains a challenging and relatively unexplored area.
It is essential that the samples selected for GM-DC should represent the target domain.
In particular, we observe significant variation in performance with different selection of target samples as the training datasets in  GM-DC.
We perform a 10-shot \textit{data-centric} GM-DC experiment using AdAM \cite{zhao2022adam} to emphasize the importance of sample selection in GM-DC. Following \cite{zhao2022adam, zhao2023rick}, we use AFHQ-Cat dataset \cite{choi2020starganv2} and select 3 random sets of 10-shot cat data for GM-DC. 
Data and 10-shot adaptation FID results are shown in Fig. \ref{fig:challenges-data-selection}.
We obtain FID values of 90.0, 71.6 and 49.9 for Sets 1, 2 and 3 respectively (iteration=2500). 
This study provides evidence that sample selection plays a vital role in determining the capabilities of GM-DC.
Specifically, due to cost/ privacy concerns, the role of sample selection is critical in applications including biomedical imaging, satellite/ aerial imaging and remote sensing. In summary, sample selection for GM-DC holds significant importance and remains an area with limited investigation thus far.


% Figure environment removed

\vspace{0.2cm}
\subsubsection{Challenges in Evaluating Generative Models under Data Constraint}
The assessment of generative modeling capabilities presents 
lots of challenges, encompassing both objective and subjective evaluation \cite{kynkaanniemi2023the}.
These issues are aggravated under low-data regimes resulting in the evaluation of GM-DC to be challenging and an active topic of research.
In contemporary GM-DC literature, sample quality and diversity are used as the main attributes for evaluating generation capability.
A summary of prominent metrics for GM-DC is included in Tab. \ref{tab:evaluation-metrics}.


Existing GM-DC evaluation metrics present multiple challenges:
i) Statistical measures including FID, KID, IS, FID\textsubscript{CLIP} lose their significance when dealing with 
setups
where there is an extreme scarcity (Few-shots) or complete absence (Zero-shot) of target domain data. For example, when the reference distribution contains only 10 real images, the mean and trace components of FID are not statistically significant.
ii) Although human judgment/ user feedback is used for the subjective evaluation of GM-DC, the absence of a unified framework/ protocol for such evaluation strategy results in inadequacy when comparing the generative capabilities of different GM-DC models.
iii) The over-reliance on objective GM-DC measures  on deep features extracted from pre-trained networks remains challenging and relatively unexplored. 
For example, FID, KID, and IS use features extracted from an Inception model trained on ImageNet-1K \cite{deng2009imagenet}; LPIPS, and Intra-LPIPS, 
use features extracted from models trained on BAPPS \cite{zhang2018lpips} dataset.
Although these pre-trained models effectively function as general-purpose feature extractors, their ability to capture properties/ attributes of out-of-domain data to objectively quantify the capabilities of GM-DC requires more investigation, \eg medical images.
In summary, the area of evaluation measures for GM-DC cannot be overstated, as it remains critical and challenging.


\begin{table}[!t]
%\fontsize{7pt}{7pt}
    \centering
    % \footnotesize
    \fontsize{7pt}{7pt}\selectfont
    \caption{List of common metrics used for evaluating GM-DC works.
    {\bf LD}: \underline{L}imited-\underline{D}ata, {\bf FS}: \underline{F}ew-\underline{S}hot, {\bf ZS}: \underline{Z}ero-\underline{S}hot. 
    \xmark/\cmark denotes the absence/presence, respectively.
    }
    \begin{adjustbox}{width=0.95\textwidth,center}{
    \begin{tabular}{lccccccc}
    \toprule
    \textbf{Metrics} &FID \cite{heusel2017twotimescale}/ FID\textsubscript{CLIP} \cite{kynkaanniemi2023the} &KID \cite{binkowski2018demystifying} &IS \cite{salimans2016improved} &Intra-LPIPS  \cite{ojha2021cdc} &SIFID \cite{shaham2019singan} &Image/ Text Similarity \cite{gal2022textualinversion} &User Feedback \\ \toprule
    \textbf{LD} &\cmark &\cmark &\cmark &\xmark &\xmark &\xmark &\cmark \\ \midrule
    \textbf{FS} &\cmark &\cmark &\cmark &\cmark &\cmark &\cmark &\cmark \\ \midrule
    \textbf{ZS} &\xmark &\xmark &\xmark &\cmark &\cmark &\cmark &\cmark \\
    \bottomrule
    \end{tabular}
    }
    \end{adjustbox}
    \label{tab:evaluation-metrics}
  % \vspace{-0.3cm}
\end{table}
%\vspace{-12pt}





