\section{Discussion}
\label{sec:discussion}
Here, we present an analysis of  the literature and discuss the research gap and future directions in GM-DC. 

\subsection{Analysis of the Research Landscape}
\label{ssec:landscape_analysis}

In this work, we propose a {\bf taxonomy of eight different tasks for GM-DC} (
Fig.~\ref{fig:sankey},
Tab. \ref{tab:tasktaxonomy}) based on the problem setups of GM-DC publications.
Our investigation of the literature focusing on each task (Fig.~\ref{fig:works_statistics}) reveals that a significant portion of the works (up to 
80\%)
concentrate on unconditional generation, either through training from scratch or adapting from a pre-trained model. Additionally, zero-shot unconditional generation is beginning to attract more attention.
Similarly, adaptation for  in-domain classes has garnered considerable interest for conditional generation.
Meanwhile, conditional generation
for out-of-domain classes
via adaptation 
has not been 
explored adequately.
Furthermore, subject-driven generation, which enables more control over content generation, is an emerging task. 
We anticipate increasing interest on this task as recent text-to-image generative models become more accessible.

We further present a {\bf taxonomy of approaches for GM-DC} (Fig.~\ref{fig:sankey},
Tab.~\ref{tab:approaches}) as our another contribution. Our study reveals that transfer learning is a predominant solution for GM-DC, capable of tackling a large number of tasks (specifically, 5 out of 8 tasks, as indicated in Tab.~\ref{tab:approaches} and Fig.~\ref{fig:sankey}), while effectively handling all data constraints including limited data, few-shot, and zero-shot. 
Moreover, $\approx$39\% of the studies propose new methods based on  transfer learning (Fig.~\ref{fig:works_statistics}). More than 
20\% of the studies propose methods
based on other approaches 
that are compatible to transfer learning, \eg data augmentation.
These methods could be used with transfer learning-based methods to improve performance.
The primary challenges in transfer learning are
selection and 
preservation of  source knowledge 
useful for generating 
high-quality and diverse target domain samples. 
Adaptation-aware approach \cite{zhao2022adam, zhao2023rick}
could be a sound direction  in this aspect where they consider both source and target domains (the adaptation process) for knowledge preservation.
Language-guided approaches \cite{gal2022stylegannada, zhu2022mindthegap, alanov2022hyperdomainnet, guo2023ipl} are gaining increasing attention due to their ability to facilitate zero-shot generation through appropriate application of vision-language models during the transfer learning phase.
Visual prompt tuning \cite{sohn2023vpt} is a recent method, which guides the generation of target domain samples  by generating visual tokens. 



Data augmentation \cite{karras2020ada, zhao2020diffaug, tran2021dag} remains a potent technique in GM-DC where it boosts performance under limited data by increasing coverage of the data distribution through various transformations.
Multi-task objectives
\cite{yang2021insgen, tseng2021lecam, huang2022maskedgan} 
which incorporate additional learning objectives 
are usually complementary to data augmentation.
Various network architecture designs \cite{liu2021fastgan, li2022moca} that aim to prevent overfitting or preserve the feature maps are also shown to be 
significantly
effective for GM-DC.
Given that generative models tend to exhibit biases in capturing frequency components, enhancing the frequency awareness in these models is an emerging direction for GM-DC \cite{yang2022fregan}.
Meta-learning \cite{clouatre2019figr} enables generative models to learn
inter-task 
knowledge from seen classes, and then handle new generation tasks from unseen classes usually without fine-tuning \cite{gu2021lofgan, hong2022deltagan}.
Internal patch-distribution modeling  \cite{shaham2019singan, nikankin2022sinfusion} effectively trains a generative model from scratch using a single reference image (scene) to produce novel scene compositions.

Regarding the types of generating models, 
our study shows that around 86\% of the GM-DC works
focus on GANs
(Fig.~\ref{fig:works_statistics}).
This preference can be attributed to the extensive research in GANs.
Recently, there has been a growing interest in DMs (12\%) 
and VAEs (3\%), particularly VQ-VAE, driven by the success of DMs \cite{ramesh2022dalle2, saharia2022imagen} and transformer-based token prediction methods in generative modeling \cite{chang2022maskgit, esser2021vqgan}.
We anticipate increasing attention directed toward DMs and VQ-VAEs.
Furthermore, our survey reveals an interesting trend: around 
64\% of the works focus on addressing the challenging task of few-shot learning, while 
33\% concentrate on limited data scenarios. 
While only 3\% of works address zero-shot learning, we expect growing interest due to recent advancements in vision-language models \cite{kwon2022oneclip, li2023scaling}.


\subsection{Research Gap and Future Directions}
\label{ssec:future_direction}




\subsubsection{Harnessing the power of foundation models}
As previously discussed, transfer learning is a prominent and highly effective solution for GM-DC.
Nevertheless, the majority of existing literature uses pre-trained StyleGAN2 (FFHQ) or BigGAN (ImageNet) networks as source models.
A potential future direction for GM-DC is to explore the capabilities of foundation models \cite{bommasani2021opportunities},  \ie large models trained using massive amounts of data.
In particular, recent text-image generation models including DALL$\cdot$E-2 \cite{ramesh2022dalle2} ($\approx$3.5B parameters), Imagen \cite{saharia2022imagen} ($\approx$4.6B parameters) and Stable Diffusion \cite{rombach2022latentdiffusion} ($\approx$890M parameters) encode knowledge regarding a wide range of concepts for high-quality, diverse image generation.
Leveraging such foundation models for GM-DC is relatively under-explored.




\subsubsection{Grounding zero-shot image generative capabilities}
Recent studies have demonstrated the feasibility of zero-shot image generation for 
well-known concepts, \eg ``Tolkien Elf'' \cite{gal2022stylegannada}. 
However, grounding zero-shot image generation models to generate evolving/ new semantic concepts remains a relatively unexplored and challenging area. 
For instance, how to generate an image depicting ``The coronation of Charles III and Camilla as King and Queen of the United Kingdom,'' an event that occurred in May 2023, that related images may not be captured by existing models. 
This requires strategies that allow continual learning, semantic concept editing, and the incorporation of temporal contexts.


\subsubsection{
Knowledge transfer 
for distant/ remote target domains}
Knowledge transfer has received significant attention in GM-DC research. Many works concentrate on utilizing pre-trained knowledge
of a source domain
to enhance learning in the target domain, as evident from the statistics in Fig. \ref{fig:sankey} and Fig. \ref{fig:works_statistics}. However, we remark that exploring knowledge transfer for modeling
target domains which are distant/ remote from the source domains 
still remains largely unexplored.
This problem is challenging, as demonstrated in our experiment to transfer knowledge from Human Faces $\rightarrow$ Flowers 
(Fig. \ref{fig:proximity-measurements-and-10-shot-flowers}), which  clearly demonstrates the complexity of the task.
We urge more investigation in knowledge transfer for modeling distant/ remote target domains in GM-DC research.


\subsubsection{Exploring different types of generative models for GM-DC}
Our analysis reveals that around 
85\% 
of GM-DC works focus on GANs and there is less attention to other types of generative models.
Meanwhile, 
recent generative models such as diffusion models have made a lot of progress, achieving comparable performance to GANs in terms of quality and diversity of generated samples
\cite{dhariwal2021diffusionvsGAN}.
We remark that recent generative models are fundamentally different from GANs, \eg multiple iterations are required to generate samples in diffusion models, suggesting that current GM-DC methods developed for GANs could be  sub-optimal for other types of 
generative models.




\subsubsection{Holistic evaluation of GM-DC}
Evaluation of GM-DC presents multiple challenges including difficulties in estimating real data statistics under low-data regimes, lack of unified framework for human evaluation of GM-DC samples, and 
heavy reliance 
on
particular 
(pre-trained) feature extractors to quantify the capabilities of GM-DC. 
In particular, developing holistic evaluation frameworks integrating both objective measurements and subjective judgements tailored for different tasks is essential for understanding GM-DC capabilities.
Advancing holistic evaluation
is important for 
GM-DC methods to be applied in a 
variety of real-world scenarios.



\subsubsection{Data-centric approaches for GM-DC}
We remark that data-centric  approaches
\cite{whang2023datacollection}
for advancing  GM-DC  have been relatively overlooked in the literature.
Majority of GM-DC methods focus on advancing training procedures based on a given set of training samples, but little attention has been put on how GM-DC performance may be affected by characteristics of the given training samples.
Particularly, for 
GM-DC problems, where a domain is described using limited training samples, the characteristics of the  samples can have noticeable impact on performance of GM-DC methods, as hinted in our analysis (see Fig.
\ref{fig:challenges-data-selection}).
We suggest  
 greater emphasis on data collection, curation and pre-processing for GM-DC advancement. 


\subsection{Beyond Image Generation}

Existing GM-DC works focus on image generation primarily.
There are a few recent works to study other data types.
\cite{zhu2023fewshot_3d} studies {\em 3D shape generation} under few-shot target data (10-shot) utilizing pre-trained 3D generative models and optimization adaptation to retain the probability distributions of pairwise adapted samples. 
CLIP-Sculptor \cite{sanghi2023clipsculptor} leverages CLIP guidance for  zero-shot
{\em
shape generation}. 
\cite{wang2023cffont} studies few-shot {\em font generation} which aims to transfer the source domain style to the target domain. In particular, they introduce a content fusion module and a projected character loss to improve the quality of skeleton transfer for few-shot font generation.
\cite{careil2023few} explores the problem of few-shot {\em semantic image generation} where the objective is to generate realistic images based on semantic segmentation maps. Their approach employs transfer learning on both GANs and DMs for few-shot semantic image synthesis. 





\section{Conclusion}
\label{sec:conclusion}

Generative Modeling under Data Constraints (GM-DC) is a burgeoning research area. 
This survey delves into this field by meticulously examining
research papers in this area, 
encompassing 
different types of
generative models including VAEs, GANs, and Diffusion Models. 
Drawing from this analysis, we identify  several challenges encountered in GM-DC, including those related to training, data selection, and model evaluation. 
Moreover, we propose two taxonomies to categorize works related to  GM-DC: a task taxonomy that
identifies the variety  of 
generation 
tasks, and an approach taxonomy that categorizes 
the  extensive list of solutions for these tasks. 
We present a Sankey diagram to illuminate the interactions between different GM-DC tasks, approaches, and methods.
Additionally, we present
an organized review 
of existing GM-DC works and discuss  research gaps and  future research directions. 
Our aspiration is that this survey not only could offer valuable insights to researchers but also help spark further advancements in GM-DC.


\vspace{0.2cm}
\noindent
\textbf{Ethics Statement.}
Generative models could be mis-used to disseminate mis- and disinformation 
due to their ability to generate realistic content.
In particular, advanced generative models could be mis-used by malicious users to fabricate deepfake images,  
portraying individuals engaging in actions they never actually performed.
Advances in GM-DC could exacerbate the situation as it becomes possible to 
generate realistic content with less data.
We advocate for ethical and responsible usage of GM-DC methods and studying of  mitigation techniques \cite{mirsky2021creation, chandrasegaran2021closer, Chandrasegaran_2022_ECCV, zhao2023recipe, wen2023tree}.
