\section{Introduction}


Generative modeling is a field of machine learning that focuses on learning the underlying distribution of the training samples, enabling the generation of new samples that exhibit similar statistical properties to the training data. Generative modeling has profound impacts in various fields including computer vision \cite{ramesh2022dalle2, karras2020analyzing, brock2019biggan}, natural language 
processing \cite{yu2017seqgan, gulrajani2017improved, van2017neural} and data engineering 
\cite{antoniou2017dagan, karras2020ada, tran2021dag}.
Over the years, significant advancements have been made in generative modeling.
Innovative approaches such as Generative Adversarial Networks (GANs) \cite{goodfellow2014GANs,karras2019style,brock2019biggan,arjovsky2017wasserstein,choi2020starganv2,park2019GauGAN,zhu2017cyclegGAN}, Variational Autoencoders (VAEs) \cite{kingma2013VAE,vahdat2020nvae,van2017neural}, and Diffusion Models (DMs) \cite{rombach2022latentdiffusion,song2020denoising,dhariwal2021diffusionvsGAN,nichol2021improveddenoisingDIM} have played a pivotal role in enhancing the quality and diversity of generated samples. 
The advancements in generative modeling have fueled the recent disruption in generative AI, unlocking new possibilities in various applications such as image synthesis \cite{reuters-2023, clarke-2022}, text generation \cite{hern-2023, hopkin-2023}, music composition \cite{easton-2023, xu-2022},
genomics \cite{nguyen2023hyenadna},
and more \cite{sargent2023vq3d, koh2023generating}. The ability to generate realistic and diverse samples has opened doors to creative applications and 
% innovative
novel
solutions \cite{roose-2023, mit-technology-review-2023}.



% Figure SanKey -----------------------------------------
% Figure environment removed
%-----------------------------------------

Research
on generative modeling has been mainly focusing on setups with sizeable training datasets.
StyleGAN \cite{karras2019style} learns to generate  realistic and diverse face images using
Flickr-Faces-HQ (FFHQ), a high-quality dataset of 70k human face images collected from the photo-sharing website Flickr.
The more recent text-to-image generative model is trained on millions of 
 image-text pairs, e.g.
Latent Diffusion Model \cite{rombach2022latentdiffusion} is trained on
 LAION-400M with 400 million samples \cite{schuhmann2021laion400m}.
However, in many domains (\eg, medical), the collection of data samples is challenging and expensive.


{\bf In this paper}, we survey 
Generative Modeling under Data Constraint (GM-DC). 
This research area is important for many domains/ applications where challenges in data collection exist. We conduct a thorough literature review on learning generative models under limited data, few shots, and zero shot.  
{\em Our survey is the first to provide a comprehensive overview and detailed analysis of
all types of generative models, tasks, and approaches studied in GM-DC, offering an accessible guide on the research landscape}
(Fig.~\ref{fig:sankey}).
We cover the essential backgrounds, provide detailed analysis of unique challenges of GM-DC, discuss current trends, and present the latest advancements in GM-DC. 

{\bf Our Contributions:}
i) Trends, technical evolution, and statistics of GM-DC (Fig.~\ref{fig:works_statistics};
Fig.~\ref{fig:timeline};
Sec.~\ref{ssec:landscape_analysis}); 
ii) New insights on GM-DC challenges (Sec.~\ref{ssec:challenges});
iii) Two novel and detailed taxonomies, one on GM-DC tasks (Sec.~\ref{ssec:tasks}) and another on GM-DC approaches (Sec.~\ref{sec:comprehensive_review});
iv) A novel Sankey diagram to visualize the research landscape and relationship between GM-DC tasks, approaches, and methods (Fig.~\ref{fig:sankey});
v) An organized summary of individual GM-DC works (Sec.~\ref{sec:comprehensive_review});
vi) Discussion of future directions (Sec.~\ref{ssec:future_direction}).
We further provide a \href{https://gmdc-survey.github.io/}{project website} with an interactive diagram to visualize GM-DC landscape.
Our survey aims to be an accessible guide 
to provide fresh perspectives on the current research landscape, organized pointers to comprehensive literature, and insightful trends on the latest advances of GM-DC.



% Figure TimeLine -----------------------------------------

% Figure environment removed


% Figure environment removed

%-----------------------------------------




{\em Survey on GM-DC is inadequate, and our work aims to fill this gap.}
We found only one survey in arXiv on the early work of GM-DC focusing on some aspects of GM-DC \cite{li2022degan}.
This previous survey has focused on a subset of GM-DC papers, studying only  works with  
GANs as the generative model and a subset of technical tasks/ approaches.
Our survey differentiates itself from \cite{li2022degan} in: 
i) Scope  - Our survey is the first to cover all types of generative models and all GM-DC tasks and approaches (Fig. \ref{fig:works_statistics});
ii) Scale -
Our study includes 
113 papers and covers broad GM-DC works, 
while 
previous survey \cite{li2022degan}
covers only $\approx$27\% of works discussed in our survey (Fig. \ref{fig:gm-dc-publications}); 
iii) Timeliness - Our survey collects and surveys the most up-to-date papers in GM-DC; 
iv) Detailedness - Our paper includes detailed visualizations (Sankey diagram, charts) and tables to 
highlight 
interactions and
important attributes of GM-DC literature;
v) Technical evolution analysis - Our paper analyzes the evolution of GM-DC tasks and approaches, providing new perspectives on recent advances;
vi) Horizon analysis - Our paper discusses 
distinctive obstacles encountered in GM-DC and identifies  avenues for future research. 

The rest of the paper is organized as follows.
In Sec.~\ref{sec:background} we provide the necessary background.
In Sec.~\ref{sec:taxonomy}, we discuss GM-DC tasks and unique challenges.
In Sec.~\ref{sec:comprehensive_review}, we analyze GM-DC approaches and methods.
In Sec.~\ref{sec:discussion}, we discuss open research problems and future directions.
Sec.~\ref{sec:conclusion} concludes the survey.



