% \usepackage{caption}




% Figure environment removed

% % Figure environment removed

\section{Experiments}

\subsection{Datasets and Metrics}
We conduct experiments on several datasets to train our method and test our method's dehazing performance. The datasets include: (1) RESIDE outdoor \cite{li2018benchmarking}, which contains 313950 synthetic outdoor hazy/clear image pairs for training and 500 pairs for testing; (2) Haze4K \cite{liu2021synthetic}, which includes a training set of 3000 indoor-outdoor mixed image pairs and a testing set of 1000 image pairs; (3) NH-HAZE \cite{lugmayr2020ntire}, a real-world dataset for the NTIRE 2020 competition, which consists of 55 pairs of non-homogeneous hazy images and clear images of real scenes (45, 5 and 5 pairs for training, validation and test respectively); (4) Dense-Haze \cite{Ancuti_2019_CVPR_Workshops, ancuti2019dense}, a real-world dataset for the NTIRE 2019 competition and contains 55 pairs of dense-haze images and corresponding clear images (with same data split as NH-HAZE). We evaluate the dehazing effectiveness of our method using two commonly used image quality metrics: PSNR (dB) and SSIM.
% \begin{equation}
%   PSNR(I(x), $\hat{J(x)}$)=10$\cdot$log_10(\frac{MAX^2}{MSE(I(x), \hat{J}(x))}) 
%   % SSIM(I(x), \hat{J(x))=
% \end{equation}


\subsection{Implementation Details}
\subsubsection{Network Configuration}
In our work, we use the Basic Block structure proposed in \cite{qin2020ffa} as our ResBlock. $\{N_{GB}^1,$ $N_{GB}^2,$ $N_{GB}^3,$ $N_{GB}^4,$ $N_{GB}^5,$ $N_{GB}^6,$ $N_{GB}^7\}$ and $\{N_{LB}^1,$ $N_{LB}^2,$ $N_{LB}^3,$ $N_{LB}^4,$ $N_{LB}^5,$ $N_{LB}^6,$ $N_{LB}^7\}$ are set to $\{2,$ $2,$ $3,$ $4,$ $3,$ $2,$ $2\}$ and $\{4,$ $6,$ $8,$ $10,$ $6,$ $8,$ $8\}$. In particular, we set the basic feature dimension of GB and LB, $C$, to 32 and the local density dimension $C_L$ to 4. All upsampling or downsampling operations are implemented by $1\times1$ convolution with pixel-shuffle or pixel-unshuffle. And we use IDRF module after every stage in LB except the last stage. 

\subsubsection{Training Settings}
The PIG is pre-trained and spliced with GB and LB. And the whole network is trained in an end-to-end fashion. We use AdamW optimizer ($\beta_1=0.9$, $\beta_2=0.999$, weight decay is $1e^{-4}$) to train the model and iterate 600k times with the initial learning rate $1e^{-4}$ reduced to $1e^{-6}$ with the cosine annealing \cite{loshchilov2016sgdr}.
Following \cite{zamir2022restormer}, we perform progressive learning in our training process, which leads the network to adapt to those inputs close to the size in practical applications. For loss regulation, we set $\lambda_1=0.2$, $\lambda_2=0.001$ and $\lambda_3=0.1$. The data augmentations include random cropping, horizontal flipping, and vertical flipping.

% \begin{table*}[t]
%   \caption{Quantitative comparison of DFR-Net with the state-of-the-art image dehazing methods on different datasets (PSNR (dB)/SSIM). Best results are \textbf{bolded} and second best results are underlined.}
%   \begin{center}
%   \begin{tabular}{c c c c c c c c c c c c}
%   \toprule[1pt]
%   \multicolumn{2}{c}{\multirow{2}{*}{Method}} & \multicolumn{2}{c}{RESIDE-indoor} & \multicolumn{2}{c}{RESIDE-outdoor} & \multicolumn{2}{c}{Haze4K} & \multicolumn{2}{c}{NH-HAZE} & \multicolumn{2}{c}{Dense-Haze}\\ \cmidrule(l){3-4} \cmidrule(l){5-6} \cmidrule(l){7-8} \cmidrule(l){9-10}
%   \multicolumn{2}{c}{} & PSNR(dB) & SSIM & PSNR(dB) & SSIM & PSNR(dB) & SSIM & PSNR(dB) & SSIM & PSNR(dB) & SSIM\\
%   \midrule
%   \multirow{10}{*}{Non-Density-Aware} & DCP \cite{he2010single} (TPAMI' 10) & 16.62 & 0.818 & 19.13 &0.815 & 14.01 & 0.760 & 10.57 & 0.522 & 11.01 & 0.416\\
%   & DehazeNet \cite{cai2016dehazenet} (TIP' 16) & 19.82 & 0.821 & 24.75 & 0.927 & 19.12 & 0.840 & - & - & 9.48 & 0.438\\
%   & AOD-Net \cite{li2017aod} (ICCV' 17) & 20.51 & 0.816 & 24.14 & 0.920 & 17.15 & 0.830 & 15.40 & 0.571 & 12.82 & 0.468\\
%   & GDNet \cite{liu2019griddehazenet} (ICCV' 19) & 32.16 & 0.984 & 30.86 & 0.982 & 23.29 & 0.930 & - & - & 14.96 & 0.53\\
%   & MSBDN \cite{dong2020multi} (CVPR' 20) & 33.67 & 0.985 & 33.48 & 0.982 & 22.99 & 0.850 & 19.23 & 0.713 & 15.13 & 0.555\\
%   & FFA-Net \cite{qin2020ffa} (AAAI' 20) & 36.39 & 0.989 & 33.57 & 0.984 & 26.96 & 0.950 & 19.87 & 0.694 & 12.22 & 0.444\\
%   & AECR-Net \cite{wu2021contrastive} (CVPR' 21) & 37.17 & 0.990 & - & - & - & - & 19.88 &0.722 & 15.80 & 0.466 \\ 
%   & SGID-PFF \cite{bai2022self} (TIP' 22) & 38.52 & \underline{0.991} & 30.20 & 0.975 &  - & - &  - & - & - & -\\ 
%   & UDN \cite{hong2022uncertainty} (AAAI' 22) & \underline{38.62} & \underline{0.991} & 34.92 & 0.987 & - & - &  - & - & - & - \\ 
%   & DehazeFormer-B \cite{song2023vision} (TIP' 23) & 37.84 & 0.994 & 34.95 & 0.984 & 30.29 & 0.985 & - & - & - & - \\ \midrule
%   & C2PNet \cite{zheng2023curricular} (CVPR' 23) & 42.56 & 0.995 & 36.68 & 0.990 & 30.29 & 0.985 & - & - & \underline{16.88} &  \underline{0.573} \\ \midrule
%   \multirow{5}{*}{Density-Aware} & HardGAN \cite{deng2020hardgan} (ECCV' 20) & 36.56 & \underline{0.991} & 34.34 & 0.987 & - & - & - & - & - & - \\
%   & HDDNet \cite{zhang2021hierarchical} (TC' 22) & 24.79 & 0.940 & 22.52 & 0.910 & - & -&  - & -\\
%   & DeHamer \cite{guo2022image} (CVPR' 22) & 36.63 & 0.988 & \underline{35.18} & 0.986 & - & -&  16.62 & 0.560 &20.66&0.684\\
%   & PMNet \cite{yeperceiving} (ECCV' 22) & 38.41 & 0.990 & 34.74 & \underline{0.990} & \underline{33.49} & \underline{0.980} & \underline{20.42} & \underline{0.731} & 16.79 & 0.510 \\
%   \cmidrule{2-10}
%   & DFR-Net (ours) & \textbf{40.11} & \textbf{0.997} & \textbf{35.34} & \textbf{0.993} & \textbf{34.62} & \textbf{0.993} & \textbf{21.21} & \textbf{0.810} & \textbf{17.07} & \textbf{0.624}\\
%   \bottomrule
%   \end{tabular}
%   \end{center}

%   % \vspace*{-15pt}
%   \label{tab:result}
% \end{table*}



\subsection{Comparison with State-of-the-art Methods}
Our comparison methods include DCP \cite{he2010single}, DehazeNet \cite{cai2016dehazenet}, AOD-Net \cite{li2017aod}, GDNet \cite{liu2019griddehazenet}, MSBDN \cite{dong2020multi}, FFA-Net \cite{qin2020ffa}, AECR-Net \cite{wu2021contrastive}, CEEF \cite{liu2021joint}, SGID-PFF \cite{bai2022self}, UDN \cite{hong2022uncertainty}, QCNN-H \cite{frants2023qcnn}, MFINEA \cite{sun2023multi} , DehazeFormer \cite{song2023vision}, HDDNet \cite{zhang2021hierarchical}, DeHamer\cite{guo2022image} and PMNet \cite{yeperceiving}. 

\subsubsection{Quantitative Evaluations} \label{Quantitative Evaluations}

The quantitative results are shown in Table \ref{tab:result}. It demonstrates that our method achieves the highest metrics on RESIDE-outdoor, Haze4K, Dense-Haze and NH-HAZE datasets, outperforming other SOTA methods. Notably, DFR-Net achieves a 1.14dB PSNR gain on the Haze4K dataset and significant improvements in SSIM on all datasets. 
% On the RESIDE-outdoor dataset, our method is slightly lower than C2PNet \cite{zheng2023curricular} in terms of PSNR metrics (35.34 dB vs 36.68 dB), but after analyzing the dehazing results and the dataset, we are of the opinion that the quantitative results cannot indicate that our method is inferior to C2PNet, and \textbf{we will give our further disscusion in Sec. \ref{Disscussion outdoor}}.
% Notably, our method achieves an improvement of 1.45 dB PSNR on the RESIDE-indoor dataset and all SSIM metrics exceed 0.99, surpassing those of other methods.

Among the density-aware methods, our DFR-Net outperforms all other methods \cite{deng2020hardgan,zhang2021hierarchical,guo2022image,yeperceiving}. Compared to the transmission-aware (density-related) methods DeHamer \cite{guo2022image} and HDDNet \cite{zhang2021hierarchical}, we directly extract density features from hazy images and obtain better performance. DFR-Net also surpasses PMNet on metrics on multiple datasets by utilizing density difference information between \textbf{I} and \textbf{P}, rather than simply concatenating them.

\subsubsection{Qualitive Evaluations} \label{Qualitive Evaluations}
Fig. \ref{fig:h4k_compare} shows visual comparisons between our DFR-Net and SOTA methods on Haze4K dataset, demonstrating that our DFR-Net can more effectively remove haze than other methods. Specifically, AOD-Net \cite{li2017aod} and FFA-Net \cite{qin2020ffa} still leave haze residue in most areas, DCP \cite{he2010single} removes some of the haze but suffers from color distorion. While PMNet \cite{yeperceiving} achieves better dehazing performance than previous methods, our method is able to recover clearer images.

In addition, we compare the visual quality performance of our method with other methods on real-world dataset (Dense-Haze) in Fig. \ref{fig:Dense_compare}. Compared to other methods, our DFR-Net removes the overall haze while achieving fine restoration in image details. This is attributed to the pulling in of the image features towards a clear image at each stage in LB, which reduces the occurrence of color distortion and blurring of details in our results.
%  Moreover, as shown in Fig.\ref{fig:h4k_compare} (g), the visual quality of proposal images generated by DFR-Net is unsatisfactory, whereas with the subsequent designs of our DFR-Net we are able to obtain a visual quality that surpasses that of other methods.

We further compare the visual results of our DFR-Net with those of PMNet \cite{yeperceiving} on the Haze4K dataset. Fig. \ref{fig:vis_h4k} illustrates the dehazing outcomes of PMNet and DFR-Net for both indoor and outdoor images with varying haze densities. DFR-Net exhibits more consistent dehazing performance across different haze densities compared to PMNet. In particular, DFR-Net demonstrates superior performance in preserving local image details, as depicted in Fig. \ref{fig:vis_h4k} (a). Conversely, PMNet struggles to accurately restore local details in the dehazed images. Additionally, DFR-Net outperforms PMNet in handling images with high global haze density, as shown in Fig. \ref{fig:vis_h4k} (b). The incorporation of both global and local density difference information in DFR-Net contributes to its robustness in perceiving and effectively addressing different haze densities. The global density component enables the network to better comprehend variations in haze densities, allowing for improved performance on images with diverse densities. On the other hand, the local density component motivates the network to identify and restore details in regions with high density, resulting in finer dehazed images with enhanced visual quality. Further details and discussions regarding these aspects are presented in Sec. \ref{section:ablation}.

% \subsubsection{Discussion on RESIDE-outdoor Dataset} \label{Disscussion outdoor}
% In Section \ref{Quantitative Evaluations}, we present the results of our method along with those of other state-of-the-art (SOTA) methods, demonstrating that our method achieves slightly lower PSNR metrics compared to C2PNet's results on the RESIDE-outdoor dataset. Additionally, we provide a visual comparison in Figure \ref{fig:C2P_compare}, which showcases a selection of clear images from the RESIDE-outdoor dataset, the dehazing results obtained using C2PNet, and the results produced by our method.

% Some of the ground truth (GT) images in the RESIDE-outdoor dataset capture scenes in hazy environments, as depicted in Fig. \ref{fig:C2P_compare} (a). Specifically, certain mid-distance scenes already exhibit thick haze, which poses a challenge for the optimization direction of the network. The presence of haze in these GT images introduces ambiguity regarding whether the network should remove the haze from this portion or retain the existing haze. Opting to remove the haze yields visually pleasing results but comes at the cost of decreased quantitative metrics such as PSNR.

% Fig. \ref{fig:C2P_compare} (b) and (c) showcase the dehazing results obtained using C2PNet and our method, respectively. The dehazing results generated by C2PNet tend to preserve the haze present in the GT images, resulting in images that closely resemble the original haze-containing scenes. Conversely, our method removes portions of the haze from the GT images, resulting in enhanced visibility and improved image quality. Although this approach leads to a reduction in quantitative metrics, we believe that our dehazing results are more meaningful and visually appealing. This also highlights the robustness of our method, as it avoids overfitting to the dataset and demonstrates its ability to generalize well to diverse hazy scenes.


\subsection{Ablation Studies} \label{section:ablation}

The main innovation of DFR-Net is the extraction and utilization of global and local haze density information. Therefore, we conduct ablation experiments and analyses in this section to demonstrate the effectiveness of our utilization of haze density information.

We conduct ablation experiments on the modules and loss functions proposed in this paper  to evaluate their effectiveness on dehazing. We first establish a \textbf{base} network (\ding{172}), which consists of a non-weight sharing GB (pseudo-Siamese structure), and an LB that takes the directly concatenated \textbf{I} and \textbf{P} as input and aggregates features by concatenation. Only $\mathcal{L}_{Rec}$ and $\mathcal{L}_{P}$ are employed to optimize the \textbf{base} network. Then we define several variants to verify the effectiveness of our proposed modules and loss functions on dehazing: \ding{173} \textbf{+Siamese}: Use the Siamese structure for feature extraction. \ding{174} \textbf{+$\mathcal{L}_{RD}$}: Incorporate $\mathcal{L}_{RD}$ into the total loss function. \ding{175} \textbf{+GDFR}: Use GDFR to obtain refined global density features. \ding{176} \textbf{+DAFF}: Aggregate features by DAFF. \ding{177} \textbf{+DR}: Explore local density from \textbf{D}ehazing \textbf{R}esidual (DR) in LB. \ding{178} \textbf{+IDRF}: Use IDRF after each stage of LB, except the last one. \ding{179} \textbf{+$\mathcal{L}_{LDR}$} (our default setting): Include $\mathcal{L}_{LDR}$ in the total loss function. Among them, variants \ding{173}-\ding{175} and \ding{176}-\ding{179} gradually introduce global and local haze density respectively. The ablation results are presented in Table \ref{tab:ablation}. Subsequently, we will analyze the effectiveness of introducing global and local haze density separately.

\captionsetup[table]{font={normalfont}}
\begin{table*}[t]
%   \vspace*{-5pt}
  \caption{Ablation studies on proposed modules and loss functions on the Haze4K dataset. Note that FLOPs and Params are measured on 256 $\times$ 256 images.}
  \begin{center}
  \begin{tabular}{cccccc}
  \toprule
  &Label&Setting  & PSNR (dB)   & FLOPs (G) & Params (M)\\ \midrule
  w/o density difference & \ding{172}&base &  30.52 &222.46& 35.76 \\ \midrule
  \multirow{3}{*}{+ global density difference}&\ding{173}&+Siamese &  31.21 &241.94& 35.15 \\
  &\ding{174}&+$\mathcal{L}_{RD}$ & 31.55 &241.94& 35.15 \\
  &\ding{175}&+GDFR    &  32.65 &242.63& 35.15 \\ \midrule
  \multirow{4}{*}{+ local density difference}&\ding{176}&+DAFF      & 32.89 &271.54& 40.52 \\
  &\ding{177}&+DR    & 33.01 & 271.56 &40.52\\
  &\ding{178}&+IDRF    & 33.52  & 286.60 &42.11\\
  &\ding{179}&+$\mathcal{L}_{LDR}$ (default) & \textbf{34.63}&  286.60 &42.11\\ \bottomrule
  \end{tabular}

\end{center}

\label{tab:ablation}
\end{table*}

% Figure environment removed
    
% Figure environment removed

% Figure environment removed

\subsubsection{Ablation studies on utilizing global density difference and global feature refinement} We carry out experiments on variants \ding{173}, \ding{174}, \ding{175} to verify the effectiveness of our design using global density difference to extract and refine global density-related features. To ensure fairness, we adjust the ResBlock numbers of the Siamese structure to approximately match the number of parameters in the base network. Table \ref{tab:ablation} indicates that sharing parameters enables better feature learning from proposal images and delivers a 0.69 dB PSNR improvement. To motivate the network to learn more density-related information, $\mathcal{L}_{RD}$ is employed and the inclusion of it leads to a 0.34 dB PSNR improvement. In addition, the introduction of GDFR brings 1.10 dB PSNR performance gain by refining global densities features.

We also conducted experiments to validate the effectiveness of incorporating global density difference information. Fig. \ref{fig:ablation_global} showcases the dehazing results obtained without (variant \ding{172}) and with (variant \ding{175}) global density information, using image inputs with varying densities. When global density difference information is not introduced, we observed low quantitative metrics, unstable dehazing results, and inconsistent performance within the same scene. As depicted in Figure \ref{fig:ablation_global}, variant \ding{172} produces suboptimal dehazing outcomes.

However, upon incorporating global density differences, the network exhibits improved capability to perceive variations in global densities. This is achieved through the exploration of global density differences between the proposal image and the input image using the Siamese structure, as well as the refinement of density features using the Global Density Feature Refinement (GDFR) module. As a result, the network becomes more robust to images with different density levels, enabling the generation of consistent and visually clear dehazed images. 
% In conclusion, the inclusion of global density difference information enhances the network's ability to perceive and handle diverse global densities, leading to improved dehazing performance and the production of visually consistent and clear images.

% We also proved the effectiveness of incorporating global density difference information. Fig. \ref{fig:ablation_global} illustrates the dehazing results w/o (variant \ding{172}) and w/ (variant \ding{175}) global density under image inputs with different densities. It can be seen that when no global difference information is introduced, the quantitative metrics are low, the dehazing results are unstable, and the results perform inconsistently in the same scene. And after the inclusion of global density differences, the network has a better ability to perceive different global densities through the exploration of global density differences between \textbf{P} and \textbf{I} by the Siamese structure and the refinement of density features by the GDFR. This makes the results of the network robust to different concentration images and obtains consistent and clear images.

% Please add the following required packages to your document preamble:
% \usepackage{booktabs}
% \usepackage{multirow}
% Please add the following required packages to your document preamble:
% \usepackage{booktabs}
% \usepackage{multirow}
\begin{table}[]
  \label{Table:ablation_IDRF}
\caption{
  Ablation studies on the usage of IDRF. \ding{52} indicates that the output features of this stage will be processed for IDRF.
}
\begin{tabular}{ccccccccc}
\toprule
\multirow{2}{*}{}     & \multicolumn{6}{c}{Stage} & \multirow{2}{*}{PSNR (dB)} & \multirow{2}{*}{Params (M)} \\ \cmidrule(l){2-7}
& 1  & 2  & 3  & 4  & 5 & 6 &  &  \\ \cmidrule(l){1-9} 
\multirow{3}{*}{IDRF} & \ding{52} & \ding{52} & \ding{52} &  &   &   &\underline{33.06}& 41.32 \\
&    &    &    & \ding{52} & \ding{52} & \ding{52} & 32.89 & 41.32 \\
& \ding{52} & \ding{52} & \ding{52} & \ding{52} & \ding{52} & \ding{52}  & \textbf{33.52} & 42.11 \\ \bottomrule
\end{tabular}
\end{table}

\subsubsection{Ablation studies on utilizing local density difference and local feature refinement} We perform experiments on variants \ding{177}, \ding{178}, \ding{179} for validation of the effectiveness of utilizing local density difference. As shown in Table \ref{tab:ablation}, extracting local features from dehazing residual, IDRF and $\mathcal{L}_{LDR}$ result in 0.12, 0.41 and 1.11 dB PSNR performance gains. 

To demonstrate the necessity of ultilizing local density difference, intermediate local features of the network using dehazing residual to extract features (variant \ding{179}) or not (variant \ding{176}) are visualized in Fig. \ref{fig:ablation_local}, which shows that high density and hard dehazing areas are captured in the shallow stage of our method. And as the network deepens, the local maps are gradually flattened, which implies the local features are updated stage by stage. However, variant \ding{176} fails to achieve these performances.

\subsubsection{Ablation studies on the location of IDRF usage}
% IDRF is the key design of our DFR-Net to refine the local density features and ablation experiments on where to use IDRF are carried out. We choose three cases, i.e., only the encoder/decoder stages and the full stages using IDRF for comparison of results. Table \ref{Table:ablation_IDRF} shows that using IDRF on all stages achieves the best result. In addition, better metrics are achieved with the use of IDRF in the encoder stage as compared to the use in the decoder stages. This is due to the fact that the refinement of local features should start as early as possible.The function of IDRF is to update the current local features and help the image features to draw closer to a clear image. Lack of this process makes the network's local features lack of updating and gives less attention to the relatively high concentration and hard regions that need attention in the current stage. The earlier it is used, the earlier the network can be guided to bring the image features closer to the clear features.

We carried out ablation experiments to determine the optimal placement of the IDRF module within the network architecture. We compared three cases: using IDRF only in the encoder stages, only in the decoder stages, and in all stages. The results, as shown in Table \ref{Table:ablation_IDRF}, indicate that employing IDRF in all stages yields the best overall performance. 

Furthermore, we observed that incorporating IDRF in the encoder stage leads to improved quantitative metrics compared to its use in the decoder stages. This can be attributed to the fact that the refinement of local features should commence as early as possible in the network. The primary role of IDRF is to update the current local features and facilitate the alignment of the restored image features with clear image features. Without this refinement process, the network's local features remain relatively unchanged, resulting in less attention being paid to regions with relatively high density or hard features that require careful handling at the current stage. By introducing IDRF at an earlier stage, the network can be guided more effectively to bring the image features closer to the features of clear images.

\begin{table}[]
  \label{Table:ablation_DAFF}
\caption{
  Ablation studies on the effectiveness of DAFF. The experiments are conducted on the Haze4K dataset.
}
\begin{center}

\begin{tabular}{cccc}
\toprule
Methods &concat \cite{yeperceiving}& SK Fusion \cite{song2023vision}& DAFF\\ \cmidrule(l){1-4}
PSNR (dB) & 33.19 & \underline{33.80} & \textbf{34.63}\\
\bottomrule
\end{tabular}  
\end{center}
\label{tab:Ablation_DAFF}
\end{table}


\subsubsection{Ablation studies on the effectiveness of DAFF}
We further conduct ablation experiments on the effectiveness of DAFF. DAFF is designed to fully fuse the global density features passed by cross-branch connections, the image features of the LB branch, and the local density features. And we compare the PSNR performance with other two fusion strategies: concatenation \cite{yeperceiving} and SK Fusion \cite{song2023vision}. Table \ref{tab:Ablation_DAFF} demonstrate that our DAFF achieves better results than the other two methods. 

As described in Section \ref{sec:method}, DAFF first combines the global features with the image features, enabling the features to be aware of global density information. It then introduces the local features through the CSDA mechanism, facilitating pixel-level refinement of the features. In contrast, both concatenation and SK Fusion methods focus primarily on channel attention, without considering the attentional role of the local density map on the spatial dimensions of the features. The superior performance of DAFF can be attributed to its comprehensive fusion strategy, which takes into account both global and local density information. This enables our method to capture and utilize density-related information more effectively, resulting in improved dehazing performance compared to concatenation and SK Fusion methods.

% As described in Sec \ref{sec:method}, DAFF first fuses the global features with the image features so that the features achieve global density-awareness, and then introduces the local features through CSDA so that the features get pixel-level refinement. However, both concatenation and SK Fusion focus only on attention between channels and do not consider the attentional role of the local map on features in the spatial dimension.