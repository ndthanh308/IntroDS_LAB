\section{Introduction}

\label{sec:intro}

The use of language in recommendation scenarios is not a novel concept. Content-based recommenders have been utilizing text associated with items, such as item descriptions and reviews, for about three decades~\citep{lops2011recsysbook}.
However, recent advances in conversational recommender systems have placed language at the forefront, as a natural and intuitive means for users to express their preferences and provide feedback on the recommendations they receive~\citep{gao-convrec-survey,jannach-convrec-survey}.
Most recently, the concept of natural language (NL) user profiles, where users express their preferences as NL statements 
has been proposed~\citep{Radlinski:2022:SIGIR}.  The idea of using text-based user representations is appealing for several reasons: it provides full transparency and allows users to control the systemâ€™s personalization. Further, in a (near) cold-start setting, where little to no usage data is available, providing a NL summary of preferences may enable a personalized and satisfying experience for users.
Yet, controlled quantitative comparisons of such NL preference descriptions against traditional item-based approaches are very limited.
Thus, the main research question driving this study is the following: How effective are prompting strategies with large language models (LLMs) for recommendation from natural language-based preference descriptions in comparison to collaborative filtering methods based solely on item ratings?


We address the task of \emph{language-based item recommendation} by building on recent advances in LLMs and prompting-based paradigms that have led to state-of-the-art results in a variety of natural language tasks, and which permit us to exploit rich positive and negative descriptive content and item preferences in a unified framework.  We contrast these novel techniques with traditional language-based approaches using information retrieval techniques~\cite{Balog:2021:SIGIR} as well as collaborative filtering-based approaches~\cite{Gantner:2011:MyMediaLite,ease}.
Being a novel task, there is no dataset for language-based item recommendation. As one of our main contributions, we present a data collection protocol and build a test collection that comprises natural language descriptions of preferences as well as item ratings. %
In doing so, we seek to answer the following research questions:
\begin{itemize}
    \item {\bf RQ1:} Are preferences expressed in natural language sufficient as a replacement for items for (especially) near cold-start recommendation, and how much does performance improve when language is combined with items? 
    \item {\bf RQ2:} How do LLM-based recommendation methods compare with item-based collaborative filtering methods? 
    \item {\bf RQ3:} Which LLM prompting style, be it completion, instructions, or few-shot prompts, performs best?
     \item {\bf RQ4:} Does the inclusion of natural language \emph{dis}preferences improve language-based recommendation?
\end{itemize}


\noindent Our main contributions are %
(1) We devise an experimental design that allows language-based item recommendation to be directly compared with state-of-the-art item-based recommendation approaches, and present a novel data collection protocol (Section~\ref{sec:expsetup});
(2) We propose various prompting methods for LLMs 
    for the task of language-based item recommendation (Section~\ref{sec:methods});
(3) We experimentally compare the proposed prompt-based methods against a set of strong baselines, including both text-based and item-based approaches (Section~\ref{sec:results}).
Ultimately, we observe that LLM-based recommmendation from pure language-based preference descriptions provides 
a competitive near cold-start recommender system that is based on an explainable and scrutable language-based preference representation.