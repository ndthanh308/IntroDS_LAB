%Comment on the qualitative FOD results (i.e. images):
%SDNet architecture figure:

%Discuss qualitative results


\subsection{Qualitative Results}
The qualitative results comparing all methods (Fig.~\ref{fig:FODQual}) show that the deep learning methods reconstructed FODs that more closely resembled the ground truth when compared to MSMT CSD. The primary difference is the presence of spurious peaks produced by MSMT CSD, whereas the deep learning based algorithms coherently captured the major tracts in this region due to their denoising effect. 

The highlighted region in Fig.~\ref{fig:FODQual} (panels \textbf{f.}-\textbf{j.}) shows an area where FOD-Net produced distorted FODs compared to SDNet and ${\text{SDNet}}_{\kappa}$. MSMT CSD reconstructed particularly noisy FODs in this area, which the results obtained by FOD-Net resembled some similarities to. The FODs produced by SDNet underestimated the amplitude in this region but more accurately distinguished between fibre populations and captured their directions. In this region, which contains dominant fibre populations with large angular separation, the impact of increasing $\kappa$ on the reconstructed FODs is minimal; only a small change in the direction of the fibres is observed. In the larger tracts in panels Fig.~\ref{fig:FODQual} \textbf{a.}-\textbf{e.}, such as the green fibre population going upwards in the bottom left corner, all deep learning methods performed similarly. 

The qualitative results comparing SDNet with ${\text{SDNet}}_{\kappa}$ (Fig.~\ref{fig:FixQual}) illustrate that ${\text{SDNet}}_{\kappa}$ better separated fibre populations. The presence of fibre populations going from the lower left to upper right of panels Fig.~\ref{fig:FixQual} \textbf{d.}-\textbf{f.} are separated from the larger fibre population by ${\text{SDNet}}_{\kappa}$ but not by SDNet without the fixel classification penalty. The FODs reconstructed in the broader region, captured in panels Fig.~\ref{fig:FixQual} \textbf{a.}-\textbf{c.}, show that  larger fibre populations are reconstructed similarly for both SDNet and  ${\text{SDNet}}_{\kappa}$.

\subsection{FOD-based Results}
% Figure environment removed

%  % Figure environment removed

% The SSE and fixel number error maps for a single axial slice (Fig.~\ref{fig:ERRmaps}) show that large errors in the three deep learning based methods are larger in the same locations suggesting that it is the same FODs which all methods find difficult to reconstruct. 
The SSE error maps (Fig.~\ref{fig:ERRmaps}) show that lower SSE is achieved throughout the brain by all deep learning methods compared to MSMT CSD. SDNet generally achieved smaller errors than the other deep learning methods. This is particularly evident in, but not restricted to, the areas highlighted by the red arrows. The error maps produced by ${\text{SDNet}}_{\kappa}$ and FOD-Net are similar.

 The average FOD-based performance results (Fig.~\ref{fig:FODperf} and Tab.~\ref{tab:QuantRes}) show that SDNet reconstructed FODs with significantly lower SSE and higher ACC than the compared methods in all regions of interest considered. The training curves (Fig.~\ref{fig:TrainCurve}) show that increasing $\kappa$ caused the validation ACC to decrease over the validation set. 

 In the white matter voxels, SDNet achieved the lowest SSE by a statistically significant margin over all compared methods, followed by ${\text{SDNet}}_{\kappa}$ and FOD-Net, between which there was no statistically significant difference in SSE. SDNet also achieved the strongest ACC performance in the white matter, where it improved over all other methods by a statistically significant margin. There was no statistically significant difference between ${\text{SDNet}}_{\kappa}$ and FOD-Net with respect to ACC in the white matter. 

%I think this is interesting since it shows that the even the FOD-based performance of SDNet with classification loss improves relatively.
In all of ROI-1-CC, ROI-2-MCP, and ROI-3-SLF, SDNet achieved the strongest SSE and ACC results (Fig.~\ref{fig:FODperf} and Tab.~\ref{tab:QuantRes}) by a statistically significant margin. FOD-Net and ${\text{SDNet}}_{\kappa}$ showed no statistically significant differences with respect to SSE and ACC in ROI-1-CC and ROI-2-MCP but in ROI-3-SLF ${\text{SDNet}}_{\kappa}$ achieved a statistically significant improvement over FOD-Net with respect to both SSE and ACC. In all regions, all deep learning based FOD reconstruction methods outperformed MSMT CSD with respect to SSE and ACC by a statistically significant margin. 

 %The statistical analysis for these regions of interest can be found in the supplementary material.
 
 %With respect to SSE in ROI-3-SLF SDNet with classification loss $0.015$, FOD-Net $0.017$. The ANOVA test showed a significant main effect (p = $6.88e-17$) over all 4 methods, and the Bonferroni adjusted t-test identifies a significant difference between SDNet w/ classification loss and FOD-Net (p = $1.27e-4$). Similarly with respect to ACC in ROI-3-SLF SDNet with classification loss achieve $94.233$ and outperformed FOD-Net $93.291$ The ANOVA test showed a significant main effect (p = $8.44e-19$) over all 4 methods and the Bonferroni adjusted t-tests show a significant difference between SDNet w/ classification loss and FOD-Net (p = $8.43e-19$).  


\subsection{Fixel-based Results}
 The fixel-based performance results (Fig.~\ref{fig:Fixperf} and Tab.~\ref{tab:QuantRes}) show greater variation between regions and an increased dependence on $\kappa$. The training curves (Fig.~\ref{fig:TrainCurve}) show that increasing $\kappa$ caused the validation fixel accuracy to increase over the validation set. In the white matter, ${\text{SDNet}}_{\kappa}$ achieved the strongest fixel accuracy by a significant margin, followed by SDNet and FOD-Net between which there was no statistically significant difference. 



% \begin{table*}
%   \resizebox{1\textwidth}{!}{
%   \begin{tabular}{|l||l|l|l|l||l|l|l|l||l|l|l|l||}
%     \hline
%       &
%       \multicolumn{4}{c||}{Fixel Accuracy} &
%       \multicolumn{4}{c||}{AFDE} &
%       \multicolumn{4}{c||}{PAE} \\
%       \hline
%     \diagbox[innerwidth=6cm]{Method}{Region} & WM & ROI-1-CC & ROI-2-MCP & ROI-3-SLF& WM & ROI-1-CC & ROI-2-MCP & ROI-3-SLF& WM & ROI-1-CC & ROI-2-MCP & ROI-3-SLF\\
%     \hline
%     SDNet & 2.1\% & 2.1\% & 2.1\% & 2.1\% & 2.1\% & 2.1\% \\
%     \hline
%     ${\text{SDNet}}_{\kappa}$ (SDNet p-value)& 11.6\% & 11.6\% & 11.6\% & 11.6\% & 11.6\% & 11.6\% \\
%     \hline
%     FOD-Net (SDNet p-value) (${\text{SDNet}}_{\kappa}$ p-value) & 5.5\% & 5.5\% & 5.5\% & 5.5\% & 5.5\% & 5.5\% \\
%     \hline
%     MSMT CSD (SDNet p-value) (${\text{SDNet}}_{\kappa}$ p-value) & \\
%     \hline
%   \end{tabular}}
%   \label{tab:FODresults}
% \end{table*}

%ROI-1-CC

In ROI-1-CC, ROI-2-MCP, and ROI-3-SLF, we see that the fixel accuracy of the deep learning FOD reconstruction methods decreased as the number of fixels increased. In ROI-1-CC, SDNet achieved the strongest performance by a statistically significant margin, followed by FOD-Net and ${\text{SDNet}}_{\kappa}$, between which there is no statistically significant difference in fixel accuracy in the same region.

%ROIs 2 and 3
As the number of fixels in the ROIs increased, the fixel accuracy of ${\text{SDNet}}_{\kappa}$ increased relative to other methods. In ROI-2-MCP, ${\text{SDNet}}_{\kappa}$ achieved the highest fixel accuracy but not by a statistically significant margin over FOD-Net. Both methods outperformed SDNet by a statistically significant margin.  In ROI-3-SLF this pattern continued as ${\text{SDNet}}_{\kappa}$'s performance further improved, and it achieved a statistically significant fixel accuracy increase over the other deep learning methods. There was no statistically significant difference in fixel accuracy between FOD-Net and SDNet in ROI-3-SLF. In all regions other than ROI-3-SLF, MSMT performed worse than all other methods by a statistically significant margin. 

%Group the AFDE and PAE sections together:
For AFDE in the white matter, ${\text{SDNet}}_{\kappa}$ achieved the lowest error by a statistically significant margin, followed by FOD-Net and SDNet between which there is no statistically significant difference in AFDE in the white matter. For PAE in the white matter, ${\text{SDNet}}_{\kappa}$ achieved the lowest error, which was a statistically significant improvement over SDNet but not FOD-Net. For both AFDE and PAE in the white matter, MSMT CSD achieved a higher error than all compared methods by a statistically significant margin.

\input{Sections/res_tab}
 
In ROI-1-CC, ROI-2-MCP and ROI-3-SLF, both AFDE and PAE generally increased as the number of fixels increased. In ROI-1-CC, SDNet achieved strongest results with respect to both AFDE and PAE and in ROI-2-MCP all three deep learning methods performed similarly with respect to both AFDE and PAE. In ROI-3-SLF, SDNet and ${\text{SDNet}}_{\kappa}$ achieved similar AFDE and PAE, with no statistically significant difference between them, but both achieved a statistically significant improvement compared to FOD-Net.

\subsection{Ablation Study}
\begin{table} 
    \caption{The results of all five performance metrics (mean $\pm$ standard error), averaged over all white matter voxels in all 7 test subjects. \textbf{${\bf 2^{nd}}$ column:}  SDNet, \textbf{${\bf3^{rd}}$ column:} SDNet without the DWI consistency block, \textbf{${\bf 4^{th}}$ column:} percentage difference between SDNet with and without the DWI consistency blocks, \textbf{${\bf 5^{th}}$ column:} pairwise t-test p-values. Bold p-values indicate a significant ($\alpha = 0.05$) effect.}
\label{tab:ablation}
\resizebox{1\columnwidth}{!}{
    \begin{tabular}{?c?c|c|c|c?}
         \specialrule{1.25pt}{0pt}{0pt}
         Metric & SDNet & \makecell{SDNet \\ w/o DC} & \makecell{Percentage \\ Change} & \makecell{p\\value}\\
         \specialrule{1.25pt}{0pt}{0pt}
         SSE ($\downarrow$)& ${\bf{0.011 \pm 0.001}}$  & $0.012 \pm 0.001$ & 9.1 \%  & {$<$ \textbf{0.05}} \\
         \hline
         ACC ($\uparrow$) & ${\bf{92.209 \pm 0.003}}$ & $91.679 \pm 0.003$ & 0.57\% & {$<$ \textbf{0.05}}\\
         \hline
         Fix Acc ($\uparrow$)& ${\bf{0.640 \pm 0.011}}$ & $0.625 \pm 0.010$ & 2.3\% & {$<$ \textbf{0.05}}\\
         \hline
         AFDE ($\downarrow$) & ${\bf{0.164 \pm 0.005}}$ & $0.177 \pm 0.005$ & 1.3 \% & {$<$ \textbf{0.05}}\\
         \hline
         PAE ($\downarrow$)& ${\bf{0.155 \pm 0.006}}$ & $0.163 \pm 0.006$ & 0.8\% & {$<$ \textbf{0.05}}\\
         \specialrule{1.25pt}{0pt}{0pt}
    \end{tabular}
    }
    \vspace{-10pt}
\end{table}

The results of the ablation study (Tab.~\ref{tab:ablation}) clearly demonstrate that removing the DWI consistency blocks from the SDNet architecture caused the performance of the network to degrade significantly with respect to all metrics. The greatest relative degradation of performance occurred with respect to SSE, however consistent reductions in the performance of all other metrics was also observed. 

% Figure environment removed