SDNet is a model-based deep learning architecture that employs DWI consistency blocks to ensure intermediate FODs are consistent with the DWI signal, whilst making use of spatial information and multi-shell DWI data to reconstruct FODs. We compared our network to FOD-Net \citep{zeng2022fod}, a FOD super-resolution network, which fits FODs to the DWI signal prior to the network's forward pass. Our results show that SDNet improved over FOD-Net in terms of FOD-based performance, and performed similarly with respect to most fixel-based metrics. We conjecture that FOD-Net loses some details of the DWI signal in the FOD fitting stage. Our qualitative results (Fig.~\ref{fig:FODQual}) support this since the FODs reconstructed by FOD-Net more closely resembled the unstable input MSMT-CSD FODs, whereas by ensuring consistency with the DWI signal, SDNet more robustly reconstructed FODs which closely resembled the ground truth. The quantitative results collected from our comparison and ablation studies highlighted the improvement in FOD-based performance enabled by including DWI consistency blocks.

The ultimate goal of deep learning based FOD reconstruction is to produce FODs that are useful for quantitative analysis. FOD registration \citep{raffelt2011symmetric}, a key component of longitudinal and group FOD analyses, relies on $L_{2}$ distance between SH coefficients to captures FOD similarity. By achieving a low SSE, the SH representations will bear increased similarity to the ground truth FODs. We therefore anticipate that SDNet will help ensure that FOD registration is minimally impacted by DWI undersampling, and so too the subsequent analysis. 

% Figure environment removed

Another factor that may impact such analyses is data containing abnormalities, such as pathologies. Such data will likely not be abundant in the datasets used for training deep learning based FOD reconstruction networks, and as a consequence, reduced performance caused by overfitting becomes probable. Since the DWI consistency blocks ensure that solutions will be consistent with the measured DWI data, we expect that SDNet will be less likely to overfit therefore performing comparatively well compared to networks without DWI consistency blocks. However, further investigation is beyond the scope of the current work. 


The outcome of such quantitative analysis is also dependent on the post-registration steps in the pipeline, which, in the case of a fixel-based analysis \citep{raffelt2012apparent}, will be predominantly impacted by the fixel-based performance. Comparing multiple FOD reconstruction algorithms revealed that strong FOD-based performance doesn't directly translate to strong fixel-based performance. The disconnect between FOD and fixel-based performance is evident in the statistically significant difference in SSE over the white matter between SDNet and FOD-Net, but the absence of a statistically significant effect in fixel accuracy over the same set of voxels. This effect can be attributed to FOD segmentation's dependence on the angular separation of the FOD lobes, which is dependent on the higher order SH coefficients, which only contribute a small amount to the SSE. This highlights that SSE loss alone may not be optimal for reconstructing FODs that are to be used in a fixel-based analysis pipeline. 

% In this work focus we primarily consider performance metrics related to the fixel-based analysis pipeline and how they can be improved. Tractography and connectome reconstruction is another potential form of quantitative analysis which can be applied to FODs. Whilst beyond the scope of this work we expect that improved fixel accuracy would improve tractography results, and therefore connectome reconstruction results. We In future research we would plan to investigate how FODs can be optimally reconstructed for different stage of a tractography-based analysis pipeline. 


By introducing an additional loss component, which penalises reconstructed FODs judged to be made up of the incorrect number of fixels, we have demonstrated that fixel-based performance can be improved. The impact of the proposed loss function is illustrated by the statistically significant increase in fixel accuracy in the white matter achieved by $\text{SDNet}_{\kappa}$ compared to SDNet and FOD-Net. The qualitative results (Fig.~\ref{fig:FixQual}) highlighted the improved angular separation of fibres with low angular separation.  It is also evident that the overall shape of the FOD is captured, as opposed to discrete, or Dirac-like FODs \citep{elaldi2021equivariant,koppers2016direct,karimi2021learning}. Furthermore, statistically significant improvements were recorded in fixel accuracy, PAE and AFDE by $\text{SDNet}_{\kappa}$ across the white matter.

However, the introduction of fixel classification penalty in ROI-1-CC led to a reduction in fixel-based performance. This highlighted a potential bias of SDNet towards over-estimating the number of fixels in each voxel. The input of FOD reconstruction networks are necessarily derived from a DWI acquisition with low angular resolution, so do not have sufficient information to reconstruct FODs that contain all fixels, as observed in Fig.~\ref{fig:ERRmaps}. Therefore, the effect of the fixel classification penalty will generally be to correct these underestimations by encouraging the network to increase the number of fixels. Since ROI-1-CC contains only single fixel voxels, the fixel-classification penalty may have increased the number of over-estimations in this region, which, when combined with the already strong performance of SDNet and FOD-Net, led to the observed decrease in performance. On the other hand, in ROI-3-SLF, a region containing 3 crossing fibres, the use of fixel classification penalty improved performance compared to the other two deep learning methods, and despite worse performance in ROI-1-CC, $\text{SDNet}_{\kappa}$ resulted in an improvement in performance over the white matter voxels for all fixel-based performance metrics.




In the current work, the fixel classification network is trained on the ground truth data alone, which, depending on the efficacy of the FOD reconstruction algorithm, will have a different distribution to the reconstructed FODs. One possible approach to further improving performance is to devise an algorithm to jointly train the FOD reconstruction network and the fixel classification network, similar to the method used to train generative adversarial networks \citep{Goodfellow2014}.

 The fixel classification penalty component of the loss function appears to share some characteristics with regularisation terms that are ubiquitous in model-based methods for solving ill-posed inverse problems. In particular, to minimise a combination of SSE loss and the fixel classification penalty, a decrease in SSE was incurred, and we have identified in our validation experiments that the extent of such a sacrifice can be controlled by the adjustment of $\kappa$ (data not included). This suggests that the solution that obtains the lowest SSE may fail to capture certain desirable features of the FOD. In this work, we have highlighted this impact on the separation of fibre populations with similar orientations, but it is possible other features such as the continuity of fibre populations through space could also be improved using similar methods.


