%Diffusion MRI introduction: Gives the reader an inutition into what diffusion MRI's are and introduces some of the terminology.
\IEEEPARstart{F}{ibre} orientation distributions (FODs) relate signal attenuation in diffusion-weighted magnetic resonance images to the volume fractions and orientations of fibre populations in the brain \citep{tournier2004direct, tournier2007robust, jeurissen2014multi}. Their flexibility and capacity to discern intra-voxel fibre populations  facilitates a range of subsequent quantitative analyses; tractography algorithms can be used to obtain tractograms, and FOD segmentation can provide discrete fibre bundle elements (fixels) \citep{raffelt2012apparent, Raffelt2017}.

Multi-shell, high angular resolution diffusion imaging datasets are required to fit FODs with sufficient angular detail, and for separating the contribution of different tissue types \citep{Tournier2013, jeurissen2014multi}. The approximately linear relationship between the time a subject spends in the scanner and the number of diffusion-weighted images (DWIs) collected means acquiring such datasets is time consuming.

Deep learning can help to alleviate this issue by performing FOD reconstruction, the task of fitting high-fidelity FODs to a reduced number of DWI signals. To ensure their flexibility, such deep learning methods should be invariant to changes in diffusion MRI acquisition arising due to inter-facility variability or DWI volume corruption. Resampling techniques such as spherical harmonics (SH) \citep{koppers2016direct, elaldi2021equivariant, hosseini2022cttrack} and nearest neighbour \citep{karimi2021learning} interpolation have been explored to resample arbitrary DWI acquisitions onto a pre-defined spherical grid. Alternatively, an SH representation of the signal can be used as input to the network \citep{lin2019fast, nath2020deep, koppers2017reconstruction, jha2022vrfrnet}. FOD super-resolution methods \citep{patel2018better, lucena2021enhancing, zeng2022fod} perform constrained spherical deconvolution (CSD) as a pre-processing step and take the SH representation of the FOD as input. Results in the literature vary due to the range of acquisitions and CSD algorithms used to fit the FODs such as: single-shell-single-tissue \citep{patel2018better}, two-tissue \citep{lucena2021enhancing} and single-shell-three-tissue \citep{zeng2022fod} FODs.

%Different types of Network architecture. 
High computational costs and the risk of overfitting mean it is not feasible to process all signals in the spatial and diffusion-acquisition dimensions concurrently. By predicting the central FOD from a limited spatial neighbourhood of the input \citep{lin2019fast, zeng2022fod, koppers2017reconstruction}, a compromise can be found between reducing the computational burden and exploiting the abundance of spatial correlations present in the data. Such methods commonly utilise a 3D convolutional neural network (CNN) for feature extraction, followed by fully connected or transformer layers for FOD prediction \citep{hosseini2022cttrack}. 

It is common practice for FODs to be fit using CSD with a maximum SH order of eight \citep{zeng2022fod, lin2019fast} in order to to capture angular frequency content of the DWI signal at a maximum b-value of $3000 \text{ s/mm}^{2}$ \citep{Tournier2013}. Some tractography algorithms require only the orientations of fibre populations in each voxel as input, so a number of FOD reconstruction algorithms predict only these quantities \citep{koppers2016direct, karimi2021learning}. Alternatively, an unsupervised loss function with sparsity inducing regularisation can be used to reconstruct FODs with an increased maximum order of 20 \citep{elaldi2021equivariant}. Whilst improving the angular separation, these methods change the FOD model, meaning it is likely that fixel-derived scalars, such as apparent fibre density and peak amplitude, also deviate. Therefore, it would be infeasible to apply such methods within a fixel-based analysis pipeline.

%Introduction to model based deep learning. 
Model-based deep learning exploits domain knowledge of a process to inspire neural network architectures. Many approaches alternate between CNN-based denoising and data consistency blocks \citep{aggarwal2018modl, schlemper2017deep, jia2021learning, duan2019vs}. Data consistency blocks use prior knowledge of an appropriate forward model to ensure a network produces solutions consistent with the input signal. 

When calculating acquisition invariant representations of the DWI signal, fitting errors are incurred. We conjecture that such errors lead to the degradation of FOD reconstruction performance since the subsequently applied neural networks cannot directly condition their output on the true DWI signal, and model-based deep learning has the potential to lessen the impact of these errors by ensuring intermediate and output FODs are consistent with the DWI signal. In the context of FOD reconstruction, data consistency blocks minimise a linear combination of the CSD data consistency and an additional, deep learning based, regularisation term. Current implementations use a pre-trained autoencoder based regularisation term \citep{patel2018better}, however this means the network will not be optimised for FOD reconstruction performance. Model-based deep learning has to this point not been combined with techniques proven successful in end-to-end FOD reconstruction architecture.  

In this paper \textbf{S}pherical \textbf{D}econvolution \textbf{Net}work (SDNet) is introduced, a model-based deep learning architecture that utilises spatial information from surrounding voxels and is optimised to perform FOD reconstruction of multi-shell data. Additionally, we propose a fixel classification penalty within our loss function to improve angular separation without distorting the shape of the reconstructed FODs, which can be tuned to suit the requirements of the reconstructed FODs. The efficacy is evaluated by extensive comparisons with a state-of-the-art FOD super-resolution method, FOD-Net, as well as an ablation study. Our results show that including model-based deep learning improves the performance of the network.
 














