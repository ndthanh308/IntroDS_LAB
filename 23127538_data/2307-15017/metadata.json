{
  "title": "Samplable Anonymous Aggregation for Private Federated Data Analysis",
  "authors": [
    "Kunal Talwar",
    "Shan Wang",
    "Audra McMillan",
    "Vojta Jina",
    "Vitaly Feldman",
    "Pansy Bansal",
    "Bailey Basile",
    "Aine Cahill",
    "Yi Sheng Chan",
    "Mike Chatzidakis",
    "Junye Chen",
    "Oliver Chick",
    "Mona Chitnis",
    "Suman Ganta",
    "Yusuf Goren",
    "Filip Granqvist",
    "Kristine Guo",
    "Frederic Jacobs",
    "Omid Javidbakht",
    "Albert Liu",
    "Richard Low",
    "Dan Mascenik",
    "Steve Myers",
    "David Park",
    "Wonhee Park",
    "Gianni Parsa",
    "Tommy Pauly",
    "Christian Priebe",
    "Rehan Rishi",
    "Guy Rothblum",
    "Michael Scaria",
    "Linmao Song",
    "Congzheng Song",
    "Karl Tarbe",
    "Sebastian Vogt",
    "Luke Winstrom",
    "Shundong Zhou"
  ],
  "submission_date": "2023-07-27T17:19:37+00:00",
  "revised_dates": [
    "2024-07-19T00:18:40+00:00"
  ],
  "abstract": "We revisit the problem of designing scalable protocols for private statistics and private federated learning when each device holds its private data. Locally differentially private algorithms require little trust but are (provably) limited in their utility. Centrally differentially private algorithms can allow significantly better utility but require a trusted curator. This gap has led to significant interest in the design and implementation of simple cryptographic primitives, that can allow central-like utility guarantees without having to trust a central server.\n  Our first contribution is to propose a new primitive that allows for efficient implementation of several commonly used algorithms, and allows for privacy accounting that is close to that in the central setting without requiring the strong trust assumptions it entails. {\\em Shuffling} and {\\em aggregation} primitives that have been proposed in earlier works enable this for some algorithms, but have significant limitations as primitives. We propose a {\\em Samplable Anonymous Aggregation} primitive, which computes an aggregate over a random subset of the inputs and show that it leads to better privacy-utility trade-offs for various fundamental tasks. Secondly, we propose a system architecture that implements this primitive and perform a security analysis of the proposed system. Our design combines additive secret-sharing with anonymization and authentication infrastructures.",
  "categories": [
    "cs.CR",
    "cs.LG"
  ],
  "primary_category": "cs.CR",
  "doi": null,
  "journal_ref": null,
  "arxiv_id": "2307.15017",
  "pdf_url": "https://arxiv.org/pdf/2307.15017v2",
  "comment": "34 pages",
  "num_versions": null,
  "size_before_bytes": 11277682,
  "size_after_bytes": 726253
}