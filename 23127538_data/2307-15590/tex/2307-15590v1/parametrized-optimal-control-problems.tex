\section{Parametrized Optimal Control Problems}\label{sec:parametrized-optimal-control-problems}
We are interested in parametrized linear optimal control problems where the objective functional consists of a term that penalizes the deviation from a target state at final time and a term measuring the energy of the applied control. The state equation serves as a constraint and is given in form of a linear time-invariant system with linear control. The parameter enters the operators governing the state equation as well as the initial conditions and the target state. In this section, we first give a detailed definition of the problem we consider. Afterwards, the associated optimality system is introduced and a linear system of equations for the optimal final time adjoint state is derived.

\subsection{Notation and Problem Definition}
Let~$\X$ and~$\U$ be real Hilbert spaces with scalar products~$\langle \cdot, \cdot \rangle_{\X}$ and~$\langle \cdot, \cdot \rangle_{\U}$ as well as associated norms~$\norm{\cdot}_{\X}$ and~$\norm{\cdot}_{\U}$, respectively. We omit the index in the scalar product and in the corresponding norm when the spaces are clear from the context. Let~$\mathcal{L}(\U,\X)$ denote, for instance, the set of linear and bounded operators from~$\U$ to~$\X$. In the following, we will refer to~$\X$ as the state and to~$\U$ as the control space. We consider parametrized linear control systems of the form
\begin{equation}\label{equ:parametrized-control-system}
    \begin{aligned}
          \dot{x}_\mu(t) &= A_\mu x_\mu(t) + B_\mu u_\mu(t),\qquad t\in[0,T], \\
          x_\mu(0) &= x_\mu^0,
    \end{aligned}
\end{equation}
where~$\mu\in\params$ denotes the parameter from a compact subset~$\params$ of some Banach space (that can also be infinite-dimensional), $A_\mu\in\mathcal{L}(\X,\X)$ and~$B_\mu\in\mathcal{L}(\U,\X)$ are parameter-dependent operators, $x_\mu^0\in \X$ is the parameter-dependent initial state, $x_\mu\colon[0,T]\to \X$ denotes the state trajectory, $u_\mu\colon[0,T]\to\U$ is the control, and~$T>0$ is the final time. Below, we consider the problem of steering the control system in~\eqref{equ:parametrized-control-system} close to a given (potentially parameter-dependent) target state~$x_\mu^T\in\X$. The following (natural) assumption is supposed to hold throughout the rest of the paper:
\begin{assumption}[Lipschitz continuity of parameter to system components maps]\label{as:continuity-parameter-to-system-matrices}
    The subset~$\params$ is compact and the mappings~$\params\ni\mu\mapsto A_\mu\in\mathcal{L}(\X,\X)$ and~$\params\ni\mu\mapsto B_\mu\in\mathcal{L}(\U,\X)$ from parameter to system matrices are Lipschitz continuous. In addition, we assume that the mappings~$\params\ni\mu\mapsto x_\mu^0\in\X$ and~$\params\ni\mu\mapsto x_\mu^T\in\X$ from parameter to initial and target state are Lipschitz continuous.
\end{assumption}
Furthermore, we introduce certain function spaces for the controls and states: As mentioned above, we denote by~$\U$ the space of admissible controls at fixed times. The associated space of time-dependent controls is given as~$G\coloneqq L^2([0,T];\U)$. Similarly, we have defined the state space~$\X$. We also define the space of time-dependent states~$H\coloneqq L^2([0,T];\X)\cap C^1([0,T];\X)$.
\par
Given a parameter~$\mu\in\params$, we are interested in finding a control~$u_\mu^*\in G$ that minimizes the functional~$\mathcal{J}_\mu\colon G\to\setR$, defined for a control~$u\in G$ as
\begin{align}\label{equ:cost-functional}
        \mathcal{J}_\mu(u) \coloneqq \frac{1}{2}\left[\langle x_\mu(T)-x_\mu^T,M\left(x_\mu(T)-x_\mu^T\right)\rangle + \int\limits_0^T \langle u(t),Ru(t)\rangle \d{t}\right],
\end{align}
where~$M\in\mathcal{L}(\X,\X)$ and~$R\in\mathcal{L}(\U,\U)$ satisfy the following assumptions.
\begin{assumption}[Properties of the weighting operators]\label{as:weightingops}
The operator $M\in\mathcal{L}(\X,\X)$ is self-adjoint and positive-semidefinite, while~$R\in\mathcal{L}(\U,\U)$ is self-adjoint and strictly positive-definite, meaning that~$R\geq\alpha I$ for some~$\alpha>0$.
\end{assumption}
The strict positive-definiteness of~$R$ implies in particular that~$R$ is invertible and that~$\mathcal{J}_\mu$ is strongly convex with respect to the control~$u$ and thus possesses a unique minimizer. In addition, $x_\mu\in H$ is the solution of~\cref{equ:parametrized-control-system} associated to the control~$u\in G$, and~$x_\mu^T\in \X$ is the target state. For notational simplicity, we omit stating explicitly the dependence of the state trajectory~$x_\mu$ on the control~$u$. The first term in the functional~$\mathcal{J}$ penalizes a deviation of the state at the final time~$T$ from the target state~$x_\mu^T$, where the deviation in different components can be weighted by the operator~$M$. The second term measures the energy of the control with respect to the weighting operator~$R$. We can summarize our parametrized, linear-quadratic optimal control problem as follows:
\begin{align}\label{equ:parametrized-optimal-control-problem}
    \min\limits_{u\in \U} \mathcal{J}_\mu(u),\qquad\text{subject to } \dot{x}_\mu(t)=A_\mu x_\mu(t)+B_\mu u(t) \text{ for } t\in[0,T],\quad x_\mu(0)=x_\mu^0.
\end{align}
Under the given integrability assumptions on the control, the state equation has a unique solution by Ca\-ra\-thÃ©o\-do\-ry's existence theorem, see for instance Chapter~I.4. in~\cite{hale1980ordinary}. As already stated above, the objective functional~$\mathcal{J}_\mu$ is strongly convex with respect to the control~$u$. Moreover, it is quadratic and so lower-semicontinuous. Hence, the optimal control problem in~\cref{equ:parametrized-optimal-control-problem} is well-posed and has a unique solution, see for instance Corollary~2.20 in~\cite{peypouquet2015convex}.

\begin{remark}[Parameter-dependent weighting matrices]
    It is also possible to consider parameter-dependent weighting operators~$M_\mu\in\mathcal{L}(\X,\X)$ and~$R_\mu\in\mathcal{L}(\U,\U)$ that change for different parameters~$\mu\in\params$. Under the assumption that the maps~$\params\ni\mu\mapsto M_\mu\in\mathcal{L}(\X,\X)$ and~$\params\ni\mu\mapsto R_\mu\in\mathcal{L}(\U,\U)$ are Lipschitz continuous, the theory and the algorithms developed below would not change, one solely has to replace~$M$ by~$M_\mu$ and~$R$ by~$R_\mu$, respectively. For notational simplicity and since we do not consider this case in our numerical experiments, we stick to the setting of parameter-independent operators~$M$ and~$R$. In the case of parameter-independent self-adjoint and positive-definite weighting operators, the weighting operators can also be interpreted as the introduction of an additional scalar product on the spaces~$\X$ and~$\U$, respectively. These scalar products are equivalent to the standard Euclidean scalar product if the spaces~$\X$ and~$\U$ are finite-dimensional.
\end{remark}
In the subsequent section, we present and discuss the optimality system associated to the optimal control problem~\eqref{equ:parametrized-optimal-control-problem}. As we will see, solving this optimality system can become costly already for a single parameter in case of moderate to large scale systems.

\subsection{Linear-quadratic Optimal Control and the Optimality System}\label{subsec:optimality-system}
By means of methods from the calculus of variations, one can derive the following theorem that characterizes the optimal control by considering the adjoint system.
\begin{theorem}[Optimality system for the optimal control problem]\label{thm:optimality-system}
    Let~$\mu\in\params$ be a parameter, $u_\mu^*\in G$ an optimal control, i.e.~a solution of \eqref{equ:parametrized-optimal-control-problem}, and denote by~$x_\mu^*\in H$ the associated state trajectory, i.e.~the solution of~\eqref{equ:parametrized-control-system} for the control~$u_\mu^*$. Then there exists an adjoint solution~$\varphi_\mu^*\in H$, such that the linear boundary value problem
    \begin{subequations}\label{equ:optimality-system-main}
        \begin{equation}\label{equ:optimality-system-odes}
            \begin{aligned}
                \dot{x}_\mu(t) &= A_\mu x_\mu(t)+B_\mu u_\mu(t), \\
                -\dot{\varphi}_\mu(t) &= A_\mu^* \varphi_\mu(t), \\
                u_\mu(t) &= -R^{-1}B_\mu^* \varphi_\mu(t),
            \end{aligned}
        \end{equation}
        for~$t\in[0,T]$ with initial respectively terminal conditions
        \begin{align}\label{equ:optimality-system-boundary-conditions}
            x_\mu(0) = x_\mu^0,\qquad \varphi_\mu(T)=M\left(x_\mu(T)-x_\mu^T\right),
        \end{align}
    \end{subequations}
    is solved by~$x_\mu=x_\mu^*$, $\varphi_\mu=\varphi_\mu^*$ and~$u_\mu=u_\mu^*$. In~\cref{equ:optimality-system-odes}, $A_\mu^*\in\mathcal{L}(\X,\X)$ and~$B_\mu^*\in\mathcal{L}(\X,\U)$ denote the adjoint operators of~$A_\mu$ and~$B_\mu$, respectively.
\end{theorem}
\begin{proof}
    See~\Cref{app:proof-optimality-system}.
\end{proof}

The optimality system in~\cref{equ:optimality-system-main} shows that~$u_\mu^*$, $x_\mu^*$ and~$\varphi_\mu^*$ are already uniquely determined by the optimal final time adjoint~$\varphi_\mu^*(T)$. To be more precise, we can explicitly compute~$u_\mu^*(t)$, $x_\mu^*(t)$ and~$\varphi_\mu^*(t)$ from~$\varphi_\mu^*(T)$ for~$t\in[0,T]$ using the following equations, see also~\Cref{fig:visualization-equations}:
\begin{align}\label{fromdualtoprimal}
    \varphi_\mu^*(t) &= e^{A_\mu^*(T-t)}\varphi_\mu^*(T), \\
    u_\mu^*(t) &= -R^{-1}B_\mu^*\varphi_\mu^*(t), \label{control} \\
    x_\mu^*(t) &= e^{A_\mu t}x_\mu^0 - \int\limits_0^t e^{A_\mu(t-s)}B_\mu R^{-1}B_\mu^* e^{A_\mu^*(T-s)}\varphi_\mu^*(T)\d{s}.\label{state}
\end{align}

% Figure environment removed

However, according to the boundary condition in~\cref{equ:optimality-system-boundary-conditions}, the optimal final time adjoint~$\varphi_\mu^*(T)$ is coupled to the optimal state~$x_\mu^*(T)$ at the final time~$T$, and hence, cannot be computed directly. To circumvent this issue, we compute~$x_\mu^*(T)$ in terms of~$\varphi_\mu^*(T)$ to obtain a linear equation for~$\varphi_\mu^*(T)$. It holds
\[
    x_\mu^*(T) = e^{A_\mu T}x_\mu^0 - \int\limits_0^T e^{A_\mu(T-s)}B_\mu R^{-1}B_\mu^* e^{A_\mu^*(T-s)}\d{s} \cdot \varphi_\mu^*(T) = e^{A_\mu T}x_\mu^0 - \Gramian \varphi_\mu^*(T),
\]
where the \emph{weighted controllability Gramian}~$\Gramian\in\mathcal{L}(\X,\X)$ is defined as
\begin{align}\label{equ:definition-gramian-matrix}
    \Gramian \coloneqq \int\limits_0^T e^{A_\mu(T-s)}B_\mu R^{-1}B_\mu^* e^{A_\mu^*(T-s)}\d{s}.
\end{align}
The Gramian~$\Gramian$ is bounded due to the boundedness of all involved operators and the finite time horizon we consider. According to~\Cref{thm:optimality-system}, we have that
\[
    \varphi_\mu^*(T) = M\left(x_\mu^*(T)-x_\mu^T\right),
\]
and it further holds
\begin{align}\label{equ:state-gramian-adjoint-relation}
    x_\mu^*(T) = e^{A_\mu T}x_\mu^0 - \Gramian \varphi_\mu^*(T)
\end{align}
as shown above. Combining these two equations, we obtain
\[
    \varphi_\mu^*(T) = M\left(e^{A_\mu T}x_\mu^0 - x_\mu^T - \Gramian \varphi_\mu^*(T)\right).
\]
Rearranging the previous equation gives the following Lemma that states the resulting equation the optimal final time adjoint~$\varphi_\mu^*(T)\in \X$ has to solve:
\begin{lemma}[Linear system for the optimal final time adjoint]\label{lem:linear-system}
    Let~$\varphi_\mu^*(T)$ denote the optimal adjoint state at time~$T$ that determines the solution of the optimality system~\eqref{equ:optimality-system-main}. Then it holds
    \begin{align}\label{equ:linear-system-for-optimal-final-time-adjoint}
        \left(I+M\Gramian\right)\varphi_\mu^*(T) = M\left(e^{A_\mu T}x_\mu^0 - x_\mu^T\right),
    \end{align}
    where~$I\in\mathcal{L}(\X,\X)$ denotes the identity.
\end{lemma}

Since the operator~$R$ is positive-definite, the same holds for~$R^{-1}$. Therefore, the Gramian~$\Gramian$ is self-adjoint and positive-semidefinite. We also emphasize at this point that the controllability Gramian as defined here depends on the parameter~$\mu\in\params$ in the same way as the involved system operators do.
\par
We make the following assumption that is supposed to hold throughout the rest of the paper and will become useful for the error estimation in~\Cref{sec:reduced-order-modeling-greedy}:
\begin{assumption}[Positivity of the product of the weighting and the Gramian operator]\label{as:symmetric-product}
    We assume that the operator~$M\Gramian\in\mathcal{L}(\X,\X)$ is positive-semidefinite for all parameters~$\mu\in\params$.
\end{assumption}
As a simple example of a weighting operator~$M\in\mathcal{L}(\X,\X)$ that fulfills~\Cref{as:symmetric-product}, we will use in our numerical experiments in~\Cref{sec:numerical-experiments} the choice~$M=\kappa I$ for a suitable constant~$\kappa>0$, where~$I\in\mathcal{L}(\X,\X)$ denotes the identity. More generally, the assumption will be satisfied if~$M$ and the Gramian~$\Gramian$ commute. 
\begin{remark}[Computation of products with the Gramian]\label{rem:applying-gramian-to-vectors}
    We emphasize that for a given vector~$p\in \X$, the product~$\Gramian p$ can be computed without constructing~$\Gramian$ explicitly. Instead, one uses that~$-\Gramian p=x_\mu(T)$ (see~\cref{equ:state-gramian-adjoint-relation}), where~$x_\mu$ solves system~\eqref{equ:optimality-system-main} with boundary conditions~$x_\mu(0)=0$ and~$\varphi_\mu(T)=p$, respectively. It is therefore sufficient to solve~\eqref{equ:optimality-system-main} by first solving the equation for~$\varphi_\mu$ backward in time, then computing~$u_\mu$, and finally solving the state equation for~$x_\mu$ forward in time. Assembling~$\Gramian\in\mathcal{L}(\X,\X)$ (which depends on the parameter~$\mu\in\params$) would be prohibitively costly and is infeasible for moderate to large scale systems when having to do so for multiple parameters.
\end{remark}

Because of large computational costs required for solving the optimal control problem for a single parameter (see also the discussions in~\Cref{subsec:computational-costs}), we aim for building a reduced order model that replaces the equation in~\eqref{equ:linear-system-for-optimal-final-time-adjoint} by a linear system of small dimension that can be solved faster while still providing a sufficiently accurate approximation of the optimal solution.