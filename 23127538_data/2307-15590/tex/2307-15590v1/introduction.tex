\section{Introduction}
In this work, we are concerned with a family of parameter-dependent optimal control problems where the state equations are given as a linear, time-invariant, infinite-dimensional system. The objective functional is a quadratic functional that measures the deviation from a desired final state and an energy of the control. For a given parameter the problem consists of finding a control that minimizes the objective functional under the constraint of the state equation.
\par
In this setting, one is typically interested in solving the optimal control problem several times for different parameters -- either in a multi-query or real-time context. In either case, solving the exact optimal control problem for lots of parameters is prohibitively costly, in particular if the dimension of the state space is large. We therefore aim to develop a reduced order model that is built during a (potentially costly) offline phase by computing the exact optimal control only for few, carefully selected parameters. Afterwards, the reduced model can be explored efficiently during the online phase for previously unconsidered parameters.
\par
The reduced basis algorithms were successfully developed and applied to parameter-dependent control problems during the last decade (e.g.~\cite{ballarin2022spacetime,dede2012reduced,lazar2016greedy}), with the offline phase mainly exploring proper orthogonal decomposition (POD) or a greedy sampling procedure or their combination (POD-greedy) in case of time-dependent reduced basis methods~\cite{hesthaven2016certified}. However, the cost of the corresponding online phase might still appear high, as the computation of the projection (of the solution to a reduced basis) relies on the full-order systems. An alternative approach would employ novel numerical tools that can handle high-dimensional problems and face the curse of dimensionality.
\par
To this end we combine model reduction and machine learning techniques. Although recently many papers appeared in which these two methods are combined, see for instance~\cite{daniel2020model}, the results are rather scarce when it comes to control systems~\cite{lazar2022control}. In~\cite{dalsanto2020data,hesthaven2018nonintrusive}, non-intrusive reduced basis methods that rely on neural networks were successfully applied for computing solutions to parametric PDEs. We want to develop a similar approach with the aim of efficiently treating parameter-dependent control problems. The idea is to train neural networks (or some other machine learning tool) to accurately predict the coefficients of solutions in a reduced basis, with a computational effort that is independent of the dimension of the full-order model.  The training is performed in the offline phase with a negligible cost, since the required data are generated by the greedy algorithm itself anyway, irrespective of a possible application of machine learning tools. As we shall see, such an approach will enable a significant computational speedup of the online phase, not only when compared to  computation of the exact solutions from scratch, but also in comparison with standard reduced basis approaches, which fully justifies its development.
\par
The paper is organized as follows: We first introduce the problem setting for parametrized linear-quadratic optimal control problems and derive the corresponding optimality system in~\Cref{sec:parametrized-optimal-control-problems}. Afterwards, in~\Cref{sec:reduced-order-modeling-greedy}, we describe a greedy algorithm to construct a reduced order model for parametrized optimal control problems. Additionally, we prove that the presented greedy algorithm is a weak greedy algorithm and derive a priori and a posteriori error estimates. In~\Cref{sec:reduced-order-machine-learning} we introduce a machine learning based approach to accelerate the online computation of approximate optimal controls. We further describe three different machine learning methods that are applied in our numerical experiments: deep neural networks, kernel methods and Gaussian process regression. The subsequent~\Cref{subsec:computational-costs} discusses in detail the required computational costs for the offline and the online stages of all described algorithms. In~\Cref{sec:numerical-experiments} we show the potential of our proposed algorithms on two examples coming from the field of optimal control of partial differential equations (PDEs). The paper concludes in~\Cref{sec:conclusion-outlook} with a discussion of the theoretical and practical results and an outlook to future research related to this contribution.