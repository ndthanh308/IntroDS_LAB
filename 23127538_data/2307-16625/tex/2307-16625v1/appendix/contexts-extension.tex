\subsection{Incorporating Contexts into \alg}\label{app:contextual}

Our approach can be easily extended to a setting where $\a_t'$, the adversary actions at time $t$, are observed before the agent chooses $\a_t$. In this setting the adversary actions could be thought of as contexts. Our method for computing $\ucb$ can be plugged into the algorithm of \citet{sessa2020contextual}. Their algorithm maintains a separate set of weights for every context unless two contexts are `close' -- correspond to a similar expected reward for all possible $\a_t$. 