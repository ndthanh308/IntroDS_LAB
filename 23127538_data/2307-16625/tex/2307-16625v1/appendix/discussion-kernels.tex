\subsubsection{Dependence of $\beta_T$ on $T$ for Particular Kernels}
\label{app:particular_kernels} 
In \cref{thm:1}, there is a dependence of the bound on $\gamma_T$. If $\gamma_T$ scales with at worst $\calO\left(\sqrt{T} \right)$, then the overall bound will not be in $T$, resulting in \alg being no-regret. $\gamma_T$ will depend on the kernel of the GP used to model each system component. For simplicity, in this section we'll assume that the same kernel is used for modelling all nodes, though if different kernels are used one just needs to consider the most complex (worst scaling of $\gamma_T$ with $T$)

For $\gamma_T$ corresponding to the linear kernel and squared exponential kernel, we have sublinear regret regardless of $N$ because $\gamma_T$ will be only logarithmic in $T$. In particular, a linear kernel leads to {$\gamma_{T} = \mathcal O \left( (\degree +  1)\log T \right)$} and a squared exponential kernel leads to  {$\gamma_{T} = \mathcal O \left( (\degree +1)(\log T)^{\degree+2}\right)$}.

However, for a \matern \ kernel, where the best known bound is $\gamma_T = {\calO \left((T)^c log(T) \right)}$ with hyperparameter $0 < c < 1$, the cumulative regret bound will not be sublinear if $N$ and $c$ are sufficiently large. A similar phenomena with the \matern \ kernel appears in the guarantees of \citet{curiEfficientModelBasedReinforcement2020} which use GP models in model-based reinforcement learning and in \citet{sussex2022model}. 