\section{Related Work} 

\paragraph{Causal Bayesian optimization}
Several recent works study how to perform Bayesian optimization on systems with an underlying causal graph. \citet{agliettiCausalBayesianOptimization2020} propose the first CBO setting with hard interventions and an algorithm that uses the do-calculus to generalise from observational to interventional data. \cite{astudilloBayesianOptimizationFunction2021} consider a noiseless setting with soft interventions (known as a function network) where a full system model is learnt, and an expected improvement objective used to select interventions. \citet{sussex2022model} propose \mcbo, an algorithm with theoretical guarantees that can be used with both hard and soft interventions. \mcbo propagates epistemic uncertainty about causal mechanisms through the graph, balancing exploration and exploitation using the optimism principle \citep{srinivas10}. %\cite{kusakawaBayesianOptimizationCascadetype2021,li2022regret} and \cite{varici2022causal} consider similar ideas under  the chain graph setting and linear causal mechanims respectively. 
All of these methods consider only stationary environments and do not account for possible adversaries. 

\paragraph{Bayesian optimization in non-i.i.d. settings}
Multiple works study how to develop robust strategies against shifts in uncontrollable covariates. They study notions of worst-case adversarial robustness \citep{bogunovic2018}, distributional robustness \citep{kirschner2020,nguyen2020distributionally}, robust mixed strategies \citep{sessa2020mixed} and risk-aversion to uncontrollable environmental parameters ~\citep{makarova2021riskaverse,iwazaki2020meanvariance}.
Nonstationarity is studied in the canonical BO setup in \citet{kirschner2020,nguyen2020distributionally} and in the CBO setup in \citet{Aglietti2021_DynamicCBO}. However, these methods do not accommodate adversaries in the system, e.g., multiple agents that we cannot control. Moreover, the algorithm of \citet{Aglietti2021_DynamicCBO} does not come with a regret guarantee. We accommodate multi-agent settings and provide a regret guarantee. A foundation for our work is the \gpmw algorithm \citep{sessa2019no} which studies learning in unknown multi-agents games and is a special case of our setting. We compare further with \gpmw in \cref{sec:analysis}.  Another special case of \alg with a specific graph is \textsc{StackelUCB} \citep{sessa21online}, designed for playing unknown Stackelberg games with multiple types of opponent 
(see \cref{app:special}).

 

