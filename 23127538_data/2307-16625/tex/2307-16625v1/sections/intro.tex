\section{Introduction}

How can a scientist efficiently optimize an unknown function that is expensive to evaluate? This problem arises in automated machine learning, drug discovery and agriculture. \emph{Bayesian optimization} (BO) encompasses an array of algorithms for sequentially optimizing unknown functions \citep{movckus1975}. Classical BO algorithms treat the unknown function mostly as a black box and make minimal structural assumptions. By incorporating more domain knowledge about the unknown function into the algorithm, one can hope to optimize the function using fewer evaluations. 

A recent line of work on causal Bayesian optimization (CBO) \citep{agliettiCausalBayesianOptimization2020} attempts to integrate use of a structural causal model (SCM) into BO methods. It is assumed that actions are interventions on some set of observed variables, which are causally related to each other and a reward variable through a known causal graph (\cref{fig:overview}b), but unknown mechanisms. Many important BO problems might take such a shape.  
For example, managing supply in a Shared Mobility System (SMS) involves intervening on the distribution of bikes and scooters across the city (we study this further in our experiments).  
Importantly, \citet{sussex2022model} show that a BO approach leveraging the additional structure of CBO can achieve exponentially lower regret in terms of the action space size.\looseness=-1 

Most CBO methods to date assume that the system is completely stationary across interactions and that only one agent interacts with the system. However, in several examples it would be desirable to incorporate the influence of external events. For example, the effect of changing weather in crop management, demand patterns in a SMS, or the actions of other agents in multi-agent settings. In all such cases, we would like an algorithm that \emph{adapts} to the variability in these external events. %Existing CBO approaches won't achieve this adaptiveness because they can only model such events with the limited \iid noise model. 

In this work, we incorporate external events into CBO by introducing a novel \emph{adversarial} CBO (ACBO) setup, illustrated in \cref{fig:overview}c. Crucially, in ACBO the downstream reward is explicitly influenced by adversarial interventions on certain nodes in the causal graph (identified using dashed nodes in~\cref{fig:overview}c) that can only be observed a-posteriori. For this general setting, we propose a novel algorithm -- CBO with multiplicative weights (\alg) -- and prove a regret guarantee using a stronger (but natural) notion of regret than the one used in existing CBO works. For settings where the number of intervention targets is large, we propose a distributed version of \alg which is computationally efficient and can achieve approximate regret guarantees under some additional submodularity assumptions on the reward.
Finally, we find empirical evidence that \alg outperforms relevant prior work in adversarial versions of previously studied CBO benchmarks and in learning to re-balance units in an SMS simulation based upon real data. \looseness=-1

\input{figures/overview.tex}
