%% ****** Start of file apstemplate.tex ****** %
%
% Group addresses by affiliation; use superscriptaddress for long
% author lists, or if there are many overlapping affiliations.
% For Phys. Rev. appearance, change preprint to twocolumn.
% Choose pra, prb, prc, prd, pre, prl, prstab, prstper, or rmp for journal
%  Add 'draft' option to mark overfull boxes with black boxes
%  Add 'showkeys' option to make keywords appear
%\documentclass[aps,prl,preprint,groupedaddress]{revtex4-2}
%\documentclass[aps,prl,twocolumn,superscriptaddress]{revtex4-2}
\documentclass[aps,reprint,amsmath,amssymb,superscriptaddress]{revtex4-2}
%\documentclass[aps,prl,reprint,groupedaddress]{revtex4-2}

\usepackage{amsmath}    % need for subequations
\usepackage{amssymb}
\usepackage{graphicx}   % need for figures
\usepackage{verbatim}   % useful for program listings
\usepackage[colorlinks,urlcolor=blue,citecolor=blue,linkcolor=blue]{hyperref}% add hypertext capabilities
\usepackage{color}      % use if color is used in text
%\usepackage{subfigure}  % use for side-by-side figures
\usepackage{caption}
\usepackage{subcaption}
\usepackage{hyperref}   % use for hypertext links, including those to external documents and URLs
\usepackage{dcolumn}% Align table columns on decimal point
\usepackage{bm}% bold math
\usepackage{epsfig}
\usepackage{epstopdf}
\usepackage{braket}
\usepackage{bbold}




%\usepackage{amsmath, bm}
%\usepackage[T1]{fontenc}
%\usepackage[latin1]{inputenc}

\begin{document}

% Use the \preprint command to place your local institutional report
% number in the upper righthand corner of the title page in preprint mode.
% Multiple \preprint commands are allowed.
% Use the 'preprintnumbers' class option to override journal defaults
% to display numbers if necessary
%\preprint{}

%Title of paper
\title{Dissipative learning of a quantum classifier}


% \affiliation command applies to all authors since the last
% \affiliation command. The \affiliation command should follow the
% other information
% \affiliation can be followed by \email, \homepage, \thanks as well.
\author{Ufuk~Korkmaz}
\author{Deniz T\"{u}rkpen\c{c}e}
\email[]{dturkpence@itu.edu.tr}

%\homepage[]{Your web page}
%\thanks{}
%\altaffiliation{}
\affiliation{Department of Electrical Engineering, \.{I}stanbul Technical University, 34469 \.{I}stanbul, Turkey}

%Collaboration name if desired (requires use of superscriptaddress
%option in \documentclass). \noaffiliation is required (may also be
%used with the \author command).
%\collaboration can be followed by \email, \homepage, \thanks as well.
%\collaboration{}
%\noaffiliation

\date{\today}

\begin{abstract}
The expectation that quantum computation might bring performance advantages in machine learning algorithms motivates the work on the quantum versions of artificial neural networks. In this study, we analyze the learning dynamics of a quantum classifier model that works as an open quantum system which is an alternative to the standard quantum circuit model. According to the obtained results, the model can be successfully trained with a gradient descent (GD) based algorithm. The fact that these optimization processes have been obtained with continuous dynamics, shows promise for the development of a differentiable activation function for the classifier model. 

\end{abstract}

% insert suggested keywords - APS authors don't need to do this
\keywords{quantum learning, open quantum system, cost function, quantum classifier, training.}

%\maketitle must follow title, authors, abstract, and keywords
\maketitle

% body of paper here - Use proper section commands
% References should be done using the \cite, \ref, and \label commands
\section{Introduction}\label{intt}

The theory of learning artificial neural networks is foun-ded on mathematical models adapted to the working principle of the human brain, introduced by McCulloch, Pitts and Rosenblatt~\cite{mcculloch_logical_1943,rosenblatt_perceptron_1958}. 
Particularly in the new millennium, in which the computing capacities of computers have increased, it has become a period in which deep learning methods outperform other methods in multi-layer artificial neural networks, which bring many useful applications~\cite{misra_artificial_2010,gu_recent_2018,schmidhuber_deep_2015}.

Quantum computation (QC) brings exciting advantages to computer science and all relevant computational sciences~\cite{bennett_quantum_2000, montanaro_quantum_2016}. 
Although many efforts have been paid for quantum versions of neural networks (QNN), there is no broadly accepted QNN, 
even at a single neuron level~\cite{banchi_quantum_2016,yamamoto_simulation_2018,tacchino_artificial_2019,torrontegui_unitary_2019,mangini_quantum_2021,yan_nonlinear_2020}. 
In addition, quantum noise severely limits the performance of gate-based quantum network proposals.  
Therefore hardware-efficient solutions have began to 
emerge~\cite{pechal_direct_2022,nguyen_evaluation_2022}.

In past work, we proposed a dissipative quantum classifier as a basic unit of QNN hardware, based on repeated interactions protocol~\cite{turkpence_steady_2019,korkmaz_transfer_2022,korkmaz_mimicking_2021,korkmaz_quantum_2022}. Dissipation-based quantum computing has been shown to be equivalent to the standard QC model~\cite{verstraete_quantum_2009}. In the protocol, identical qubit sequences with pure initial quantum state successively interact with a target qubit. The repeated interactions are unitary in the weak coupling limit in a vanishingly small time portion. However, the quantum state of the target qubit is obtained by calculating the reduced dynamics, so that global evolution is a non-unitary process. We dub these identical qubit sequences quantum information reservoir~\cite{deffner_information_2013,deffner_information_driven_2013}. As a result of repeated interactions, the target qubit reaches a steady state in which the diagonal entries of its density matrix become identical to the information reservoir units. This process is known as quantum homogenization~\cite{ziman_diluting_2002}. 

In this task, some amount of information is transferred from the reservoir to the target qubit at the steady state.
This can be interpreted as quantum reservoirs being quantum channels that transfer information to open systems~\cite{blume_kohout_simple_2005,zwolak_redundancy_2017}. All these approaches make sense for open quantum neuron design when the target qubit is connected to more than one information reservoir with arbitrary coupling strengths. In this case, the target qubit reaches a non-trivial steady state depending on the coupling coefficients (weights) and the input data parameters. We have numerically and analytically proposed that this model is an open quantum classifier that returns a binary decision at the steady state when measured by Pauli observables~\cite{turkpence_steady_2019,korkmaz_transfer_2022}. 

In the current work, we study this model in the framework of supervised learning schemes by adopting a gradient descent-based model. To this end, we derive a cost function setting different parameters of the system as variables and examine the availability of the model for learning tasks. We observe that the cost function can be smoothly minimized for all relevant parameters with appropriate differentiability.  

\section{Model and System Dynamics}\label{msd}
\subsection{Classic model}
Binary classification is a subtask for machine learning (ML) covering ANN alongside different models. However, If we discuss, in particular the artificial neural network model, the perceptron is referred to as a basic unit of ANN computing performing binary classification tasks. Technically speaking, a perceptron performs a binary decision $z$ with binary labels $\lbrace 0,1 \rbrace$ depending on the input. In the model, input is formulated as $\varphi_{in}=\bf{x}^T \bf{w}$ where $\bf{x}=[x_1,\ldots x_N]^T$ defines input feature instances and $\bf{w}=[w_1,\ldots w_N]^T$ is the set of corresponding weight vectors. 

The binary output is modulated by, in general a non-linear function $f(.)$ where $z=f(\varphi_{in})$. The decision rule reads $z=0$ if $z=f(\varphi_{in})\geq 0$ and $z=1$ else. The choice of binary labels is arbitrary and can be defined variously depending on the expressivity requirements. Note that, in principle, a perceptron with identity activation can still achieve linear classification. However, non-linear activation functions are desirable for multi-layer ANN learning tasks. Although our model, in principle, is a quantum perceptron with identity activation, we prefer to present our model and related learning tasks as "quantum classifier learning".       

Supervised learning can be defined as a mapping from a feature space to a binary label set 
\begin{equation}\label{Eq:Mapping}
\mathcal{X,Y}\rightarrow \{0,1\}
\end{equation}
where $\mathcal{X}$ and $\mathcal{Y}$ are, respectively, the input and output data of a given a training set 
$\mathcal{S}=(\mathcal{X},\mathcal{Y})$. In this scheme, the $\mathcal{Y}$ part of the training set is the desired output, and the cost function $C$ quantifies how close the actual output is to the desired output.

In analogy with the least squares method, the cost function expression reads
\begin{equation}\label{Eq:Cost1}
C=\frac{1}{2}(\bf{Y}-\bf{A})^2
\end{equation}  
where $\bf{A}$ is the actual and $\bf{Y}$ is the desired output. In general, the weight instances are updated
\begin{equation}\label{Eq:Weight}
\bf{w}_{k+1}=\bf{w}_{k}+\delta\bf{w}_{k}
\end{equation}
iteratively by back-propagation. However, any desired parameter can be adjusted to minimize the cost. 
Among different procedures, we adopt a gradient-descent based method for the training task. In this method, the change
in the parameter reads 
\begin{equation}\label{Eq:delta_w}
\delta {w}_k=-\eta\frac{\partial C}{\partial {w}_k}
\end{equation}
where $\eta$ is a non-negative number, the so-called learning rate, characterizing the speed of the learning task.
As the name of the method implies, the partial derivative expresses the change of the parameter to be adjusted in the direction of the largest descent.  
 
\subsection{Quantum dissipative dynamics}

In this subsection, we discuss the open system dynamics with preliminary definitions. 
As we have pointed out in the previous sections, the model operates by a dissipative protocol.
The input data expressed classically can be rephrased as
\begin{equation}\label{Eq:Weight2}
\varphi_{in}=\bf{x}^T \bf{w}=\sum_i w_i x_i. 
\end{equation}
the weighted summation of the input features. 
In our view, the quantum equivalent of the classic description above reads
\begin{align}\label{Eq:CPTP addition}
\Lambda_t[\varrho_0]=\sum_i P_i\Phi_t^{(i)}{[\varrho_0] }
\end{align}
where $\Phi_t^{(i)}$ is a completely positive trace preserving (CPTP) quantum dynamical map acting on the target qubit $\varrho_0$, $P_i$ is the probability of the map interacting with the $i$th information reservoir. 
The subscript $t$ stands for the time dependence of the maps generated by a physical process
\begin{align}\label{Eq:Unitary}
\Phi^{(i)}_t[\varrho_0]=\text{Tr}_{\mathcal{R}_i}\{U_t(\varrho_0\otimes\varrho_{\mathcal{R}_i})U_t^{\dagger}\}
\end{align}
with a unitary propagator $U_t$ acting on both the target qubit and the reservoir. 
Here, $\rho_{\mathcal{R}_i}$ is the $i$th reservoir quantum state and $\text{Tr}_{\mathcal{R}_i}$ is the partial trace over the $i$th reservoir.  

The quantum reservoirs provide initial quantum data in pure states. Each reservoir is composed of non-correlated, non-interacting two-level quantum systems (subunits) defined by 
\begin{align}\label{Eq:Inf Res}
\rho_{\mathcal{R}_i}=\bigotimes_{k=1}^n\rho_{k}(\theta_i,\phi_i).
\end{align}
the tensor product of finite $n$ subunits. As each subunit is in a pure quantum state, they could initially be prepared by identical Bloch parameters $\rho_{k}(\theta_i,\phi_i)$. This parametrization allows for a dissipative equivalence of the model with parametrized quantum circuits.  

\subsection{Quantum collision model and the quantum \\ classifier}

As mentioned above, the dynamical process of the introduced model relies on a standard quantum collisional model~\cite{scarani_thermalizing_2002,ziman_diluting_2002,nagaj_quantum_2002}. In our proposal, the target qubit undergoes a collisional dissipative process under multiple, independent information reservoirs with arbitrary couplings. In this scheme, the steady state readout of the target qubit by Pauli observables gives the binary classification output. The dynamical process in the presence of the $i$th information reservoir reads
\begin{align}
\Phi^{(i)}_{n\tau}=&\text{Tr}_n \big[ \mathcal{U}_{0 i_n}\ldots\text{Tr}_1[\mathcal{U}_{0 i_1}\left(\varrho_0\otimes\rho_{\mathcal{R}_{i_1}}\right)\mathcal{U}_{0 i_1}^{\dagger}]\otimes\ldots \nonumber \\ 
&\ldots\otimes\rho_{\mathfrak{R}_{i_n}}\mathcal{U}_{0 i_n}^{\dagger} \big].
\end{align}     
Here, $n\tau$ is the time elapsed of the dynamical map for $n$ collisions and $\mathcal{U}_{0 i_k}=\text{exp}[-\text{i}\mathcal{H}^k_{0 i}\tau]$ is the unitary propagator. 
Initially, system plus reservoir quantum states prepared in $ \varrho (0)= \varrho_0 (0)\otimes\rho_{\mathcal{R}_i} $ a tensor product state. Note that the time dependence is only relevant for the target qubit, and after every collision, the reservoir states are reset to their initial state. 

% Figure environment removed


On the other hand, the Hamiltonian governing the system plus reservoir dynamics depicted as $\mathcal{H}= \mathcal{H}_0+\mathcal{H}_{int}$ where 
\begin{align}
\mathcal{H}_0=\frac{\hbar\omega_0}{2}\sigma_0^z+\frac{\hbar\omega_i}{2}\sum_{k=1}^n\sigma_{k_i}^z
\end{align}\label{eq:hfree}
is the free part and 
\begin{equation}
\mathcal{H}_{int}=\hbar\sum_{k=1}^n g_i(\sigma_{0}^+\sigma_{k_i}^- +\text{H.c.}),
\label{eq:hint}
\end{equation}
is the interaction part. Here, respectively, the Pauli-$z$ operator, the Pauli raising and lowering operators read as $\sigma^z$, $\sigma^+$ and $\sigma^-$. The Planck's constant divided by $2\pi$ is taken as $\hbar=1$ throughout the calculations. As a notable point, the value of the coupling coefficient $g_i\ll \omega_0$ ranges within the weak coupling regime where the cross-talk between the reservoirs is avoided. Moreover, the coefficients are proportional to the probabilities $g_i\propto P_i$ in eq.~(\ref{Eq:CPTP addition}) as the quantum equivalent to the weights in the classic model. 

Following the recipe above, the steady state of the target qubit in the presence of $N$ distinct reservoirs reported as the solution of the collisional master equation~\cite{korkmaz_transfer_2022}
\begin{align}\label{Eq:Steadyy} 
\varrho_0^{\text{ss}}=& \frac{1}{\sum_i^N g_i^2 }\sum_{i=1}^N g_i^2\Big( \langle\sigma_{i}^+\sigma_{i}^-\rangle \ket{e}\bra{e}+\langle\sigma_{i}^-\sigma_{i}^+\rangle\ket{g}\bra{g}\nonumber\\
&+i\gamma_1^-\left( \langle\sigma_{i}^+\sigma_{i}^-\rangle-\langle\sigma_{i}^-\sigma_{i}^+\rangle \right)\ket{e}\bra{g}+\text{H.c.}\Big)
\end{align}
where $\ket{e}$ and $\ket{g}$ are the computational basis and $\gamma^-_1=r\tau\sum_{i=1}^N g_i\langle\sigma_{i}^-\rangle$ , $r$ being the interaction rate of the master equation. 
The binary decision at the steady state is read upon the Pauli-$z$ operator acting on the target qubit
\begin{align}\label{Eq:Bloch_ss}
\langle\sigma_{z}^0\rangle^{ss}=\frac{1}{g_{\sum}}\sum_i^N g_i^2\langle\sigma_z\rangle_i
\end{align} 
as the classification identifier where $g_{\sum}=\sum_i g_i^2$. 
Based the eqs~(\ref{Eq:Steadyy}) and (\ref{Eq:Bloch_ss}), finally the binary classification rule reads
\begin{equation}\label{Eq:BinaryCond2}
Decision:
\begin{cases}
0, & \langle \sigma_z^0 \rangle^{ss}=\frac{1}{g_{\sum}}\sum_i^N g_i^2\langle\sigma_z\rangle_i \geq 0        
\\
1, & \text{else}   
\end{cases}
\end{equation}
where  $\langle\sigma_z\rangle_i$ is the $i$th information reservoir magnetization. 
The steady state binary decision expressed by the Pauli-$z$ observable is a summation of the input quantum data 
weighted by respective couplings. This is reasonable as the classic model has a similar expression. 

% Figure environment removed

Figure~\ref{fig:fig1} depicts the numerical verification of the introduced model as a benchmark calculation. Here, the target qubit contacted two different information reservoirs with $g_1$ and $g_2$ couplings. The quantum state of the reservoirs are $\ket{\Psi(\theta=0,\phi=0)}\equiv \ket{\uparrow}$ and \\ $\ket{\Psi(\theta=\pi,\phi=0)}\equiv \ket{\downarrow}$, respectively. The dots on the curve represents the steady state magnetization of the target qubit corresponding to $g_1,g_2$ coupling values. These values modulated as $g_1=g/2 - \Delta g$ and $g_2=g/2 + \Delta g$ where $-0.5g<\Delta g<0.5g$. For instance, when $\Delta g=-0.5g$, $g_1=g$ and $g_2=0$ means that the target qubit is in contact only with the first reservoir with the quantum state $\ket{\uparrow}$ and vice versa. In these limits, the steady state magnetization gets $\langle \sigma_z\rangle=1,-1$ and takes intermediate values when $-0.5g<\Delta g<0.5g$ as expected. In the numerical simulation, we have used the realistic parameters of the superconducting circuits in the weak coupling range~\cite{krantz_quantum_2019}. Transmon qubits operate at a resonator frequency $\omega_r\sim 1-10$ GHz with $g\sim 1-100$ MHz effective qubit-qubit coupling.


As depicted above, the relevant parameters are the Bloch parameters $\lbrace\theta,\phi\rbrace$, characterizing the input quantum data. 
Looking more closely at eqs~\ref{Eq:Steadyy} and \ref{Eq:Bloch_ss}, one can see the signatures of input data at the steady state as expected values. The expected values can be related to the Bloch parameters as
\begin{align}\label{Eq:RhoR}
\mathcal{\rho}_{\mathcal{R}_{i}}&=
\begin{bmatrix}
\frac{1+\cos\theta_{i}}{2} & \frac{e^{-i\phi_{i}}}{2}\sin \theta_{i} \\
\frac{e^{i\phi_{i}}}{2}\sin \theta_{i} & \frac{1-\cos\theta_{i}}{2}
\end{bmatrix}\nonumber\\
&:=
\begin{bmatrix}
\langle\sigma_{i}^+\sigma_{i}^-\rangle & \langle\sigma_{i}^-\rangle \\
\langle\sigma_{i}^+\rangle & \langle\sigma_{i}^-\sigma_{i}^+\rangle
\end{bmatrix}
\end{align}
where $\mathcal{\rho}_{\mathcal{R}_{i}}$ is the quantum state of the $i$th reservoir. 
Therefore in our model, Pauli-$z$ and Pauli-$y$ observables can be chosen to extract relevant information 
for $\theta$ and $\phi$ parameters, respectively, at the steady state. Expectation value of the Pauli-$y$ observable 
of the target qubit at the steady state reads 
\begin{align}\label{Eq:Bloch_ss_y}
&\langle\sigma_{y}^0\rangle^{ss}=\frac{-(\gamma_1^- +\gamma_2^+)}{g_{\sum}}\sum_i^N g_i^2\langle\sigma_z\rangle_i
\end{align}  
where $\gamma^-_1=r\tau\sum_{i=1}^N g_i\langle\sigma_{i}^-\rangle$, $\gamma^+_2=r\tau\sum_{i=1}^N g_i\langle\sigma_{i}^+\rangle$. 	
Regarding eqs~(\ref{Eq:Bloch_ss}) and (\ref{Eq:Bloch_ss_y}) together, one evaluates that relevant information of the Bloch parameters can be extracted at the steady state of the target qubit through Pauli observables. 


\section{Learning of the model}
In this section, we explore the gradient descent-based learning of the introduced open classifier model.  
First we define the cost function to be optimized as
\begin{equation}\label{Eq:Cost2}
C=\frac{1}{2}(\langle \sigma_{\lambda}^0\rangle_{des}^{ss}-\langle \sigma_{\lambda}^0\rangle_{act}^{ss})^2,
\end{equation}
where $\lambda=\lbrace y,z\rbrace$ denotes the Pauli matrices we choose for specific parameters. 
Here, $\sigma_{\lambda}^0\rangle_{des}^{ss}$ is the desired and $\langle \sigma_{\lambda}^0\rangle_{act}^{ss}$ is the actual steady state expectation values of the target  qubit for the Pauli observable $\sigma_{\lambda}$.  
Definition of the cost function above is similar to \cite{wan_quantum_2017}, however, note that the expected values are obtained in steady states in our task. 


Following the classic definitions, we rephrase eqs~(\ref{Eq:delta_w}) and (\ref{Eq:Weight2}) as
\begin{align}
&\bf{\nu}_{k+1}=\bf{\nu}_{k}+\delta\bf{\nu}_{k}\label{Eq:delta_nu}\\
&\delta {\nu}_k=-\eta\frac{\partial C}{\partial {\nu}_k}\label{Eq:delta_C}
\end{align}
where $\nu$=$\lbrace g,\theta,\phi\rbrace$. Therefore, the relevant parameters are the Bloch parameters and the couplings of the target qubit with the reservoirs. We first derive the cost function for $g$ corresponding to the weights in the classic model (see \ref{AppA}). However, we also examine the learning tasks for the Bloch parameters $\theta$ and $\phi$ corresponding to fixed values of $g$.

Figure~\ref{Fig:Cost_minimize} depicts the cost minimization given the parameters against the episodes (the $k$ index) of $\nu=g$ in eqs~(\ref{Eq:delta_nu}) and (\ref{Eq:delta_C}) depending on different values of $\eta$ when the target qubit contacted to two reservoirs. That is, we examine the model using different learning rates (or different optimization speeds). We observe that the optimization always has a smooth feature for different $\eta$s. In the problem, we also observe that the largest possible learning rate is one order of magnitude smaller than the coupling rate.


% Figure environment removed

Figures~\ref{Fig:Cost_Area1} and \ref{Fig:Cost_OverShoot} present the same minimization problem when considering the surface topology of the cost function. In the single target qubit case coupled to two information reservoirs, the structure of the surface cost function seems trivial to optimize without any local plateaus. Therefore, the success of optimization depends on the selection of the learning rate value. In figure~\ref{Fig:Cost_Area1}, the model successfully performs the optimization task with an appropriate learning rate. However, an unstable procedure occurs when a very large value of $\eta$ is selected, as in figure~\ref{Fig:Cost_OverShoot}. Although, in the figure, cost function minimization seems to have been successfully achieved, in most similar problems the iteration value extends beyond the cost function surface. This is known as `overshooting' the minimum. 


% Figure environment removed  

Conversely, extremely small learning rate values lead to being stuck in the local minimums. Therefore adaptive tasks, in which the learning rates might take different values during the process, are developed for GD-based methods~\cite{ruder_overview_2017}. We find that for the training of the open classifier model, one order of magnitude around the coupling rate in the weak coupling regime seems a reasonable choice for $\eta$. 

As we have pointed out above, we also examine the cases where the couplings to the reservoirs are fixed. 
In this case, input data parameters are assumed to be adjustable to obtain the desired output. Regarding figure~\ref{Fig:Cost_minimize_theta}, we observe, again, smooth convergence with three orders of magnitude greater learning rate than the coupling coefficient. Corresponding cost function is depicted in figure~\ref{Fig:Theta_Area}. In this case,
the Bloch parameter $\theta$ is iterated to minimize the cost. See eqs~(\ref{Eq:deltac}) and (\ref{Eq:pdg1_g2}) to obtain the cost function in case of the $\theta$ parameter-dependent iteration. The Pauli-$z$ observable is, again, relevant in the calculations. 

Next, we consider the training task concerning the Bloch parameter $\phi$. The Pauli-$y$ observable was chosen to extract $\phi$ parameter-dependent data. This task requires special attention as the proposed classifier operates as an open quantum system, driven by non-equilibrium reservoirs. Steady states bear mixed quantum states in which quantum coherent information is irreversibly lost. However, some non-vanishing quantum coherence may exist when the system is driven by non-equilibrium environments.~\cite{scully_extracting_2003,karevski_quantum_2009}. In our case, eq.~(\ref{Eq:Steadyy}) demonstrates that the target qubit retains quantum coherence at the steady state as the non-diagonal part of the density matrix is non-zero. In addition, eq.~(\ref{Eq:Bloch_ss_y}) states that the steady coherence is weighted by the coupling coefficients where it can be parametrized by $\phi$ through the Pauli-$y$ observable. 

% Figure environment removed

Figure~\ref{Fig:Phi_Epoch} shows the cost minimization depending on different learning rates. 
The cost function values around the $\times 10^{-5}$ scale reveals a small coherence value at the steady state compared to the diagonal elements of the target qubit density matrix. In addition, the $\eta$ value for the $\phi$ parameter optimization has the largest value compared to the optimizations for the $g,\theta$ parameters. Finally, figure~\ref{fig:fig7} represents he cost function minimization considering the update of Bloch parameters $\phi_1$ and $\phi_2$. The 3D surface of the cost function is similar to figure~\ref{Fig:Theta_Area}, only differing by the value 
of the learning rate.  

If a comment is made by evaluating all the results together, we see that the proposed classifier is suitable for GD-based training schemes. Moreover, open system dynamics allows for smooth convergence in learning tasks which makes the model favourable for multi layer feed-forward networks once an activation function is introduced. Since binary classification is a task in itself for ML, the model we propose is a candidate to be a trainable model in ML processes, even when considered alone.  

\section{Conclusions}

In this study, we examined the training of a classifier model based on the open quantum model in different parameter spaces with the GD-based method. Using our analytical results, we have derived cost functions for three different parameters for training our model and made calculations that minimize the cost functions with the gradient descent algorithm. Obtaining the classification response of the model in a stationary state makes the system dynamics continuous dynamics. As a result of this, we achieved optimization of the model, namely its training with smooth, continuous results. Since the training processes are continuous, which means that they are differentiable, it is concluded that the model we propose is suitable for developing an activation function and using it in larger quantum networks. In addition, although the classification result is taken in a stationary state, it becomes possible to train in all Bloch parameter spaces as well as the coupling coefficients by the steady quantum coherence.

Our study revealed that the derived cost functions are trained at different values of learning rates for corresponding parameters. In our model, cost functions successfully minimized with appropriate learning coefficients.  


\section*{Acknowledgment}

The authors acknowledge support from the Scientific and Technological Research Council of Turkey (TÜBİTAK-Grant No. 120F353). The authors also wish to extend special thanks to the  Cognitive Systems Lab in the Department of Electrical Engineering providing the atmosphere for motivational and stimulating discussions. 


\appendix
\section{Derivation of the cost function}\label{AppA} 

In this section, we present the mathematical justifications for numerical calculations in the text.
First, we substitute $\nu=g$ in eq.~(\ref{Eq:delta_C}) 
\begin{equation}\label{Eq:deltag}
\delta {g}_i=-\eta\frac{\partial C}{\partial {g}_i}.
\end{equation}
and obtain the cost function expression taking the partial derivative with respect to the coupling constant $g$.
\begin{equation}\label{Eq:deltac}
\frac{\partial C}{\partial {g}_i}=(\langle \sigma_z^0\rangle_{des}^{ss}-\langle \sigma_z^0\rangle_{act}^{ss})(-\frac{\partial \langle \sigma_z^0\rangle_{act}^{ss}}{\partial {g}_i})
\end{equation}

In our current example, we have two information reservoirs corresponding to specific magnetizations.  
Therefore, the actual steady state magnetization (eq.~(\ref{Eq:Bloch_ss})) reads as
\begin{equation}\label{Eq:Actual}
A=\langle \sigma_z^0\rangle_{act}^{ss}=\frac{g_{1}^{2}\langle \sigma_z^1\rangle+g_{2}^{2}\langle \sigma_z^2\rangle}{g_{1}^{2}+g_{2}^{2}}.
\end{equation}
According to the recipe to derive the cost function, the partial derivatives with respect to $g_1$ and $g_2$ separately obtained as
\begin{align}\label{Eq:pdg1_g2}
&\frac{\partial A}{\partial {g}_1}=\frac{2g_{1}\langle \sigma_z^1\rangle (g_{1}^{2}+g_{2}^{2})-2g_{1}(g_{1}^{2}\langle \sigma_z^1\rangle+g_{2}^{2}\langle \sigma_z^2\rangle)}{(g_{1}^{2}+g_{2}^{2})^{2}}\nonumber\\
&\frac{\partial A}{\partial {g}_2}=\frac{2g_{2}\langle \sigma_z^2\rangle (g_{1}^{2}+g_{2}^{2})-2g_{2}(g_{1}^{2}\langle \sigma_z^1\rangle+g_{2}^{2}\langle \sigma_z^2\rangle)}{(g_{1}^{2}+g_{2}^{2})^{2}}
\end{align}
In our example, the desired magnetization is $\langle \sigma_z^0\rangle_{des}^{ss}=0.4$ a constant value in the cost function. After substituting eqs.~(\ref{Eq:Actual}) and~(\ref{Eq:pdg1_g2}) in eq.~(\ref{Eq:deltac}), the expression obtained after substituting them in eq.~(\ref{Eq:deltag}), eq.~(\ref{Eq:delta_nu}) becomes as follows:
\begin{align}\label{Eq:training_1}
&(g_1)_{k+1}=(g_1)_{k}+\delta(g_1)_{k}\nonumber\\
&(g_2)_{k+1}=(g_2)_{k}+\delta(g_2)_{k}.
\end{align}

Next,  we substitute $\nu=\theta$ in eq.~(\ref{Eq:delta_C}) as
\begin{equation}\label{Eq:delta_theta}
\delta {\theta}_i=-\eta\frac{\partial C}{\partial {\theta}_i}.
\end{equation}
Regarding eq.~(\ref{Eq:RhoR}), one can easily see that the magnetization of the $i$th reservoir is 
$\langle\sigma_z\rangle_i=\langle\sigma_{i}^+\sigma_{i}^-\rangle - \langle\sigma_{i}^-\sigma_{i}^+\rangle$. 
Therefore, azimuth parameter-dependent expression of the magnetization can be easily written as  $\langle\sigma_z\rangle_i=\cos\theta_{i}$.

Equation~(\ref{Eq:deltac_theta}) is obtained when we take the partial derivative of the cost function with respect to $\theta$.
\begin{equation}\label{Eq:deltac_theta}
\frac{\partial C}{\partial {\theta}_i}=(\langle \sigma_z^0\rangle_{des}^{ss}-\langle \sigma_z^0\rangle_{act}^{ss})(-\frac{\partial \langle \sigma_z^0\rangle_{act}^{ss}}{\partial {\theta}_i})
\end{equation}

In our current example, we have two information reservoirs corresponding to specific magnetizations.  
Therefore, the actual steady state magnetization (eq.~(\ref{Eq:Bloch_ss})) reads as
\begin{equation}\label{Eq:Actual_theta}
A=\langle \sigma_z^0\rangle_{act}^{ss}=\frac{g_{1}^{2}\cos\theta_{1}+g_{2}^{2}\cos\theta_{2}}{g_{1}^{2}+g_{2}^{2}}.
\end{equation}

According to the recipe to derive the cost function, the partial derivatives with respect to $\theta_{1}$ and $\theta_{2}$ separately obtained as
\begin{align}\label{Eq:pdt1_t2}
&\frac{\partial A}{\partial {\theta}_1}=-\frac{g_{1}^{2}\sin\theta_{1}}{g_{1}^{2}+g_{2}^{2}}\nonumber\\
&\frac{\partial A}{\partial {\theta}_2}=-\frac{g_{2}^{2}\sin\theta_{2}}{g_{1}^{2}+g_{2}^{2}}
\end{align}
In our example, the desired magnetization is $\langle \sigma_z^0\rangle_{des}^{ss}=0$ a constant value in the cost function. After substituting eqs~(\ref{Eq:Actual_theta}) and~(\ref{Eq:pdt1_t2}) in eq.~(\ref{Eq:deltac_theta}), the expression obtained after substituting them in eq.~(\ref{Eq:delta_theta}), eq.~(\ref{Eq:delta_nu}) becomes as follows:
\begin{align}\label{Eq:training_theta}
&\bf{(\theta)}_{k+1}=\bf{(\theta_1)}_{k}+\delta\bf{(\theta_1)}_{k}\nonumber\\
&\bf{(\theta_2)}_{k+1}=\bf{(\theta_2)}_{k}+\delta\bf{(\theta_2)}_{k}.
\end{align}

Let's edit Eq.~(\ref{Eq:delta_nu}) for $\nu=\phi$

\begin{equation}\label{Eq:delta_phi}
\delta {\phi}_i=-\eta\frac{\partial C}{\partial {\phi}_i}.
\end{equation}

Equation~(\ref{Eq:deltac_phi}) is obtained when we take the partial derivative of the cost function with respect to $\phi$.
\begin{equation}\label{Eq:deltac_phi}
\frac{\partial C}{\partial {\phi}_i}=(\langle \sigma_y^0\rangle_{des}^{ss}-\langle \sigma_y^0\rangle_{act}^{ss})(-\frac{\partial \langle \sigma_y^0\rangle_{act}^{ss}}{\partial {\phi}_i})
\end{equation}
In our current example, we have two information reservoirs corresponding to specific magnetizations.  
Therefore, the actual steady state magnetization (eq.~(\ref{Eq:Bloch_ss})) by using eq.~(\ref{Eq:RhoR})  reads as
\begin{widetext}
\begin{align}\label{Eq:Actual_phi}
A=\langle \sigma_y^0\rangle_{act}^{ss}=-r\tau\frac{g_{1}^{3}\sin\theta_{1}\cos\theta_{1}\cos\phi_{1}+g_{1}g_{2}^{2}\sin\theta_{1}\cos\theta_{2}\cos\phi_{1}+g_{1}^{2}g_{2}\cos\theta_{1}\sin\theta_{2}\cos\phi_{2}+g_{2}^{3}\sin\theta_{2}\cos\theta_{2}\cos\phi_{2}}{g_{1}^{2}+g_{2}^{2}}.
\end{align}
\end{widetext} 
According to the recipe to derive the cost function, the partial derivatives with respect to $\phi_{1}$ and $\phi_{2}$ separately obtained as
\begin{align}\label{Eq:pdp1_p2}
&\frac{\partial A}{\partial {\phi}_1}=r\tau\frac{g_{1}^{3}\sin\theta_{1}\cos\theta_{1}\sin\phi_{1}+g_{1}g_{2}^{2}\sin\theta_{1}\cos\theta_{2}\sin\phi_{1}}{g_{1}^{2}+g_{2}^{2}}\nonumber\\
&\frac{\partial A}{\partial {\phi}_2}=r\tau\frac{g_{1}^{2}g_{2}\cos\theta_{1}\sin\theta_{2}\sin\phi_{2}+g_{2}^{3}\sin\theta_{2}\cos\theta_{2}\sin\phi_{2}}{g_{1}^{2}+g_{2}^{2}}
\end{align}
In our example, the desired magnetization is $\langle \sigma_y^0\rangle_{des}^{ss}=0$ a constant value in the cost function. After substituting eqs~(\ref{Eq:Actual_phi}) and~(\ref{Eq:pdp1_p2}) in eq.~(\ref{Eq:deltac_phi}), the expression obtained after substituting them in eq.~(\ref{Eq:delta_phi}), eq.~(\ref{Eq:training_phi}) becomes as follows:
\begin{align}\label{Eq:training_phi}
&\bf{(\phi)}_{k+1}=\bf{(\phi_1)}_{k}+\delta\bf{(\phi_1)}_{k}\nonumber\\
&\bf{(\phi_2)}_{k+1}=\bf{(\phi_2)}_{k}+\delta\bf{(\phi_2)}_{k}.
\end{align}

%The expectation values of the Pauli operators of the probe qubit in its steady state %are as follows

%\subsection{}
%\subsubsection{}

% If in two-column mode, this environment will change to single-column
% format so that long equations can be displayed. Use
% sparingly.
%\begin{widetext}
% put long equation here
%\end{widetext}

% figures should be put into the text as floats.
% Use the graphics or graphicx packages (distributed with LaTeX2e)
% and the \includegraphics macro defined in those packages.
% See the LaTeX Graphics Companion by Michel Goosens, Sebastian Rahtz,
% and Frank Mittelbach for instance.
%
% Here is an example of the general form of a figure:
% Fill in the caption in the braces of the \caption{} command. Put the label
% that you will use with \ref{} command in the braces of the \label{} command.
% Use the figure* environment if the figure should span across the
% entire page. There is no need to do explicit centering.

% % Figure environment removed

% Surround figure environment with turnpage environment for landscape
% figure
% \begin{turnpage}
% % Figure environment removed
% \end{turnpage}

% tables should appear as floats within the text
%
% Here is an example of the general form of a table:
% Fill in the caption in the braces of the \caption{} command. Put the label
% that you will use with \ref{} command in the braces of the \label{} command.
% Insert the column specifiers (l, r, c, d, etc.) in the empty braces of the
% \begin{tabular}{} command.
% The ruledtabular enviroment adds doubled rules to table and sets a
% reasonable default table settings.
% Use the table* environment to get a full-width table in two-column
% Add \usepackage{longtable} and the longtable (or longtable*}
% environment for nicely formatted long tables. Or use the the [H]
% placement option to break a long table (with less control than 
% in longtable).
% \begin{table}%[H] add [H] placement to break table across pages
% \caption{\label{}}
% \begin{ruledtabular}
% \begin{tabular}{}
% Lines of table here ending with \\
% \end{tabular}
% \end{ruledtabular}
% \end{table}

% Surround table environment with turnpage environment for landscape
% table
% \begin{turnpage}
% \begin{table}
% \caption{\label{}}
% \begin{ruledtabular}
% \begin{tabular}{}
% \end{tabular}
% \end{ruledtabular}
% \end{table}
% \end{turnpage}

% Specify following sections are appendices. Use \appendix* if there
% only one appendix.


% If you have acknowledgments, this puts in the proper section head.
%\begin{acknowledgments}
% put your acknowledgments here.
%\end{acknowledgments}

% Create the reference section using BibTeX:
%\bibliographystyle{apsrev4-2}
%\bibliography{pramana_ref}

%apsrev4-2.bst 2019-01-14 (MD) hand-edited version of apsrev4-1.bst
%Control: key (0)
%Control: author (72) initials jnrlst
%Control: editor formatted (1) identically to author
%Control: production of article title (-1) disabled
%Control: page (0) single
%Control: year (1) truncated
%Control: production of eprint (0) enabled
\begin{thebibliography}{32}%
\makeatletter
\providecommand \@ifxundefined [1]{%
 \@ifx{#1\undefined}
}%
\providecommand \@ifnum [1]{%
 \ifnum #1\expandafter \@firstoftwo
 \else \expandafter \@secondoftwo
 \fi
}%
\providecommand \@ifx [1]{%
 \ifx #1\expandafter \@firstoftwo
 \else \expandafter \@secondoftwo
 \fi
}%
\providecommand \natexlab [1]{#1}%
\providecommand \enquote  [1]{``#1''}%
\providecommand \bibnamefont  [1]{#1}%
\providecommand \bibfnamefont [1]{#1}%
\providecommand \citenamefont [1]{#1}%
\providecommand \href@noop [0]{\@secondoftwo}%
\providecommand \href [0]{\begingroup \@sanitize@url \@href}%
\providecommand \@href[1]{\@@startlink{#1}\@@href}%
\providecommand \@@href[1]{\endgroup#1\@@endlink}%
\providecommand \@sanitize@url [0]{\catcode `\\12\catcode `\$12\catcode
  `\&12\catcode `\#12\catcode `\^12\catcode `\_12\catcode `\%12\relax}%
\providecommand \@@startlink[1]{}%
\providecommand \@@endlink[0]{}%
\providecommand \url  [0]{\begingroup\@sanitize@url \@url }%
\providecommand \@url [1]{\endgroup\@href {#1}{\urlprefix }}%
\providecommand \urlprefix  [0]{URL }%
\providecommand \Eprint [0]{\href }%
\providecommand \doibase [0]{https://doi.org/}%
\providecommand \selectlanguage [0]{\@gobble}%
\providecommand \bibinfo  [0]{\@secondoftwo}%
\providecommand \bibfield  [0]{\@secondoftwo}%
\providecommand \translation [1]{[#1]}%
\providecommand \BibitemOpen [0]{}%
\providecommand \bibitemStop [0]{}%
\providecommand \bibitemNoStop [0]{.\EOS\space}%
\providecommand \EOS [0]{\spacefactor3000\relax}%
\providecommand \BibitemShut  [1]{\csname bibitem#1\endcsname}%
\let\auto@bib@innerbib\@empty
%</preamble>
\bibitem [{\citenamefont {McCulloch}\ and\ \citenamefont
  {Pitts}(1943)}]{mcculloch_logical_1943}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {W.~S.}\ \bibnamefont
  {McCulloch}}\ and\ \bibinfo {author} {\bibfnamefont {W.}~\bibnamefont
  {Pitts}},\ }\href {https://doi.org/10.1007/BF02478259} {\bibfield  {journal}
  {\bibinfo  {journal} {Bulletin of Mathematical Biophysics}\ }\textbf
  {\bibinfo {volume} {5}},\ \bibinfo {pages} {115} (\bibinfo {year}
  {1943})}\BibitemShut {NoStop}%
\bibitem [{\citenamefont {Rosenblatt}(1958)}]{rosenblatt_perceptron_1958}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {F.}~\bibnamefont
  {Rosenblatt}},\ }\href {https://doi.org/10.1037/h0042519} {\bibfield
  {journal} {\bibinfo  {journal} {Psychological Review}\ }\textbf {\bibinfo
  {volume} {65}},\ \bibinfo {pages} {386} (\bibinfo {year} {1958})}\BibitemShut
  {NoStop}%
\bibitem [{\citenamefont {Misra}\ and\ \citenamefont
  {Saha}(2010)}]{misra_artificial_2010}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {J.}~\bibnamefont
  {Misra}}\ and\ \bibinfo {author} {\bibfnamefont {I.}~\bibnamefont {Saha}},\
  }\href {https://doi.org/10.1016/j.neucom.2010.03.021} {\bibfield  {journal}
  {\bibinfo  {journal} {Neurocomputing}\ }\textbf {\bibinfo {volume} {74}},\
  \bibinfo {pages} {239} (\bibinfo {year} {2010})}\BibitemShut {NoStop}%
\bibitem [{\citenamefont {Gu}\ \emph {et~al.}(2018)\citenamefont {Gu},
  \citenamefont {Wang}, \citenamefont {Kuen}, \citenamefont {Ma}, \citenamefont
  {Shahroudy}, \citenamefont {Shuai}, \citenamefont {Liu}, \citenamefont
  {Wang}, \citenamefont {Wang}, \citenamefont {Cai},\ and\ \citenamefont
  {Chen}}]{gu_recent_2018}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {J.}~\bibnamefont
  {Gu}}, \bibinfo {author} {\bibfnamefont {Z.}~\bibnamefont {Wang}}, \bibinfo
  {author} {\bibfnamefont {J.}~\bibnamefont {Kuen}}, \bibinfo {author}
  {\bibfnamefont {L.}~\bibnamefont {Ma}}, \bibinfo {author} {\bibfnamefont
  {A.}~\bibnamefont {Shahroudy}}, \bibinfo {author} {\bibfnamefont
  {B.}~\bibnamefont {Shuai}}, \bibinfo {author} {\bibfnamefont
  {T.}~\bibnamefont {Liu}}, \bibinfo {author} {\bibfnamefont {X.}~\bibnamefont
  {Wang}}, \bibinfo {author} {\bibfnamefont {G.}~\bibnamefont {Wang}}, \bibinfo
  {author} {\bibfnamefont {J.}~\bibnamefont {Cai}},\ and\ \bibinfo {author}
  {\bibfnamefont {T.}~\bibnamefont {Chen}},\ }\href
  {https://doi.org/10.1016/j.patcog.2017.10.013} {\bibfield  {journal}
  {\bibinfo  {journal} {Pattern Recognition}\ }\textbf {\bibinfo {volume}
  {77}},\ \bibinfo {pages} {354} (\bibinfo {year} {2018})}\BibitemShut
  {NoStop}%
\bibitem [{\citenamefont {Schmidhuber}(2015)}]{schmidhuber_deep_2015}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {J.}~\bibnamefont
  {Schmidhuber}},\ }\href {https://doi.org/10.1016/j.neunet.2014.09.003}
  {\bibfield  {journal} {\bibinfo  {journal} {Neural Networks}\ }\textbf
  {\bibinfo {volume} {61}},\ \bibinfo {pages} {85} (\bibinfo {year}
  {2015})}\BibitemShut {NoStop}%
\bibitem [{\citenamefont {Bennett}\ and\ \citenamefont
  {DiVincenzo}(2000)}]{bennett_quantum_2000}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {C.~H.}\ \bibnamefont
  {Bennett}}\ and\ \bibinfo {author} {\bibfnamefont {D.~P.}\ \bibnamefont
  {DiVincenzo}},\ }\href {https://doi.org/10.1038/35005001} {\bibfield
  {journal} {\bibinfo  {journal} {Nature}\ }\textbf {\bibinfo {volume} {404}},\
  \bibinfo {pages} {247} (\bibinfo {year} {2000})}\BibitemShut {NoStop}%
\bibitem [{\citenamefont {Montanaro}(2016)}]{montanaro_quantum_2016}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {A.}~\bibnamefont
  {Montanaro}},\ }\href {https://doi.org/10.1038/npjqi.2015.23} {\bibfield
  {journal} {\bibinfo  {journal} {npj Quantum Information}\ }\textbf {\bibinfo
  {volume} {2}},\ \bibinfo {pages} {1} (\bibinfo {year} {2016})}\BibitemShut
  {NoStop}%
\bibitem [{\citenamefont {Banchi}\ \emph {et~al.}(2016)\citenamefont {Banchi},
  \citenamefont {Pancotti},\ and\ \citenamefont {Bose}}]{banchi_quantum_2016}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {L.}~\bibnamefont
  {Banchi}}, \bibinfo {author} {\bibfnamefont {N.}~\bibnamefont {Pancotti}},\
  and\ \bibinfo {author} {\bibfnamefont {S.}~\bibnamefont {Bose}},\ }\href
  {https://doi.org/10.1038/npjqi.2016.19} {\bibfield  {journal} {\bibinfo
  {journal} {npj Quantum Information}\ }\textbf {\bibinfo {volume} {2}},\
  \bibinfo {pages} {16019} (\bibinfo {year} {2016})}\BibitemShut {NoStop}%
\bibitem [{\citenamefont {Yamamoto}\ \emph {et~al.}(2018)\citenamefont
  {Yamamoto}, \citenamefont {Sundqvist}, \citenamefont {Li},\ and\
  \citenamefont {Harris}}]{yamamoto_simulation_2018}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {A.~Y.}\ \bibnamefont
  {Yamamoto}}, \bibinfo {author} {\bibfnamefont {K.~M.}\ \bibnamefont
  {Sundqvist}}, \bibinfo {author} {\bibfnamefont {P.}~\bibnamefont {Li}},\ and\
  \bibinfo {author} {\bibfnamefont {H.~R.}\ \bibnamefont {Harris}},\ }\href
  {https://doi.org/10.1007/s11128-018-1858-1} {\bibfield  {journal} {\bibinfo
  {journal} {Quantum Inf Process}\ }\textbf {\bibinfo {volume} {17}},\ \bibinfo
  {pages} {128} (\bibinfo {year} {2018})}\BibitemShut {NoStop}%
\bibitem [{\citenamefont {Tacchino}\ \emph {et~al.}(2019)\citenamefont
  {Tacchino}, \citenamefont {Macchiavello}, \citenamefont {Gerace},\ and\
  \citenamefont {Bajoni}}]{tacchino_artificial_2019}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {F.}~\bibnamefont
  {Tacchino}}, \bibinfo {author} {\bibfnamefont {C.}~\bibnamefont
  {Macchiavello}}, \bibinfo {author} {\bibfnamefont {D.}~\bibnamefont
  {Gerace}},\ and\ \bibinfo {author} {\bibfnamefont {D.}~\bibnamefont
  {Bajoni}},\ }\href {https://doi.org/10.1038/s41534-019-0140-4} {\bibfield
  {journal} {\bibinfo  {journal} {npj Quantum Inf}\ }\textbf {\bibinfo {volume}
  {5}},\ \bibinfo {pages} {1} (\bibinfo {year} {2019})}\BibitemShut {NoStop}%
\bibitem [{\citenamefont {Torrontegui}\ and\ \citenamefont
  {García-Ripoll}(2019)}]{torrontegui_unitary_2019}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {E.}~\bibnamefont
  {Torrontegui}}\ and\ \bibinfo {author} {\bibfnamefont {J.~J.}\ \bibnamefont
  {García-Ripoll}},\ }\href {https://doi.org/10.1209/0295-5075/125/30004}
  {\bibfield  {journal} {\bibinfo  {journal} {EPL}\ }\textbf {\bibinfo {volume}
  {125}},\ \bibinfo {pages} {30004} (\bibinfo {year} {2019})}\BibitemShut
  {NoStop}%
\bibitem [{\citenamefont {Mangini}\ \emph {et~al.}(2021)\citenamefont
  {Mangini}, \citenamefont {Tacchino}, \citenamefont {Gerace}, \citenamefont
  {Bajoni},\ and\ \citenamefont {Macchiavello}}]{mangini_quantum_2021}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {S.}~\bibnamefont
  {Mangini}}, \bibinfo {author} {\bibfnamefont {F.}~\bibnamefont {Tacchino}},
  \bibinfo {author} {\bibfnamefont {D.}~\bibnamefont {Gerace}}, \bibinfo
  {author} {\bibfnamefont {D.}~\bibnamefont {Bajoni}},\ and\ \bibinfo {author}
  {\bibfnamefont {C.}~\bibnamefont {Macchiavello}},\ }\href
  {https://doi.org/10.1209/0295-5075/134/10002} {\bibfield  {journal} {\bibinfo
   {journal} {EPL}\ }\textbf {\bibinfo {volume} {134}},\ \bibinfo {pages}
  {10002} (\bibinfo {year} {2021})}\BibitemShut {NoStop}%
\bibitem [{\citenamefont {Yan}\ \emph {et~al.}(2020)\citenamefont {Yan},
  \citenamefont {Qi},\ and\ \citenamefont {Cui}}]{yan_nonlinear_2020}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {S.}~\bibnamefont
  {Yan}}, \bibinfo {author} {\bibfnamefont {H.}~\bibnamefont {Qi}},\ and\
  \bibinfo {author} {\bibfnamefont {W.}~\bibnamefont {Cui}},\ }\href
  {https://doi.org/10.1103/PhysRevA.102.052421} {\bibfield  {journal} {\bibinfo
   {journal} {Physical Review A}\ }\textbf {\bibinfo {volume} {102}},\ \bibinfo
  {pages} {052421} (\bibinfo {year} {2020})}\BibitemShut {NoStop}%
\bibitem [{\citenamefont {Pechal}\ \emph {et~al.}(2022)\citenamefont {Pechal},
  \citenamefont {Roy}, \citenamefont {Wilkinson}, \citenamefont {Salis},
  \citenamefont {Werninghaus}, \citenamefont {Hartmann},\ and\ \citenamefont
  {Filipp}}]{pechal_direct_2022}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {M.}~\bibnamefont
  {Pechal}}, \bibinfo {author} {\bibfnamefont {F.}~\bibnamefont {Roy}},
  \bibinfo {author} {\bibfnamefont {S.~A.}\ \bibnamefont {Wilkinson}}, \bibinfo
  {author} {\bibfnamefont {G.}~\bibnamefont {Salis}}, \bibinfo {author}
  {\bibfnamefont {M.}~\bibnamefont {Werninghaus}}, \bibinfo {author}
  {\bibfnamefont {M.~J.}\ \bibnamefont {Hartmann}},\ and\ \bibinfo {author}
  {\bibfnamefont {S.}~\bibnamefont {Filipp}},\ }\href
  {https://doi.org/10.1103/PhysRevResearch.4.033190} {\bibfield  {journal}
  {\bibinfo  {journal} {Physical Review Research}\ }\textbf {\bibinfo {volume}
  {4}},\ \bibinfo {pages} {033190} (\bibinfo {year} {2022})}\BibitemShut
  {NoStop}%
\bibitem [{\citenamefont {Nguyen}\ \emph {et~al.}(2022)\citenamefont {Nguyen},
  \citenamefont {Paik}, \citenamefont {Watanobe},\ and\ \citenamefont
  {Thang}}]{nguyen_evaluation_2022}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {T.}~\bibnamefont
  {Nguyen}}, \bibinfo {author} {\bibfnamefont {I.}~\bibnamefont {Paik}},
  \bibinfo {author} {\bibfnamefont {Y.}~\bibnamefont {Watanobe}},\ and\
  \bibinfo {author} {\bibfnamefont {T.~C.}\ \bibnamefont {Thang}},\ }\href
  {https://doi.org/10.3390/electronics11030437} {\bibfield  {journal} {\bibinfo
   {journal} {Electronics}\ }\textbf {\bibinfo {volume} {11}},\ \bibinfo
  {pages} {437} (\bibinfo {year} {2022})}\BibitemShut {NoStop}%
\bibitem [{\citenamefont {Türkpençe}\ \emph {et~al.}(2019)\citenamefont
  {Türkpençe}, \citenamefont {Akinciı},\ and\ \citenamefont
  {Seker}}]{turkpence_steady_2019}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {D.}~\bibnamefont
  {Türkpençe}}, \bibinfo {author} {\bibfnamefont {T.~Ç.}\ \bibnamefont
  {Akıncı}},\ and\ \bibinfo {author} {\bibfnamefont {S.}~\bibnamefont
  {Şeker}},\ }\href {https://doi.org/10.1016/j.physleta.2019.01.063} {\bibfield
   {journal} {\bibinfo  {journal} {Physics Letters A}\ }\textbf {\bibinfo
  {volume} {383}},\ \bibinfo {pages} {1410} (\bibinfo {year}
  {2019})}\BibitemShut {NoStop}%
\bibitem [{\citenamefont {Korkmaz}\ and\ \citenamefont
  {Türkpençe}(2022)}]{korkmaz_transfer_2022}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {U.}~\bibnamefont
  {Korkmaz}}\ and\ \bibinfo {author} {\bibfnamefont {D.}~\bibnamefont
  {Türkpençe}},\ }\href {https://doi.org/10.1016/j.physleta.2021.127887}
  {\bibfield  {journal} {\bibinfo  {journal} {Physics Letters A}\ }\textbf
  {\bibinfo {volume} {426}},\ \bibinfo {pages} {127887} (\bibinfo {year}
  {2022})}\BibitemShut {NoStop}%
\bibitem [{\citenamefont {Korkmaz}\ \emph {et~al.}(2021)\citenamefont
  {Korkmaz}, \citenamefont {Sanga},\ and\ \citenamefont
  {Türkpençe}}]{korkmaz_mimicking_2021}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {U.}~\bibnamefont
  {Korkmaz}}, \bibinfo {author} {\bibfnamefont {C.}~\bibnamefont {Sanga}},\
  and\ \bibinfo {author} {\bibfnamefont {D.}~\bibnamefont {Türkpençe}},\ }in\
  \href {https://doi.org/10.1109/ISMSIT52890.2021.9604610} {\emph {\bibinfo
  {booktitle} {2021 5th {International} {Symposium} on {Multidisciplinary}
  {Studies} and {Innovative} {Technologies} ({ISMSIT})}}}\ (\bibinfo {year}
  {2021})\ pp.\ \bibinfo {pages} {105--109}\BibitemShut {NoStop}%
\bibitem [{\citenamefont {Korkmaz}\ \emph {et~al.}(2022)\citenamefont
  {Korkmaz}, \citenamefont {Sanga},\ and\ \citenamefont
  {Türkpençe}}]{korkmaz_quantum_2022}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {U.}~\bibnamefont
  {Korkmaz}}, \bibinfo {author} {\bibfnamefont {C.}~\bibnamefont {Sanga}},\
  and\ \bibinfo {author} {\bibfnamefont {D.}~\bibnamefont {Türkpençe}},\ }in\
  \href {https://doi.org/10.1007/978-3-031-01984-5_13} {\emph {\bibinfo
  {booktitle} {Electrical and {Computer} {Engineering}}}},\ \bibinfo {series
  and number} {Lecture {Notes} of the {Institute} for {Computer} {Sciences},
  {Social} {Informatics} and {Telecommunications} {Engineering}},\ \bibinfo
  {editor} {edited by\ \bibinfo {editor} {\bibfnamefont {M.~N.}\ \bibnamefont
  {Seyman}}}\ (\bibinfo  {publisher} {Springer International Publishing},\
  \bibinfo {year} {2022})\ pp.\ \bibinfo {pages} {159--170}\BibitemShut
  {NoStop}%
\bibitem [{\citenamefont {Verstraete}\ \emph {et~al.}(2009)\citenamefont
  {Verstraete}, \citenamefont {Wolf},\ and\ \citenamefont
  {Ignacio~Cirac}}]{verstraete_quantum_2009}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {F.}~\bibnamefont
  {Verstraete}}, \bibinfo {author} {\bibfnamefont {M.~M.}\ \bibnamefont
  {Wolf}},\ and\ \bibinfo {author} {\bibfnamefont {J.}~\bibnamefont
  {Ignacio~Cirac}},\ }\href {https://doi.org/10.1038/nphys1342} {\bibfield
  {journal} {\bibinfo  {journal} {Nature Phys}\ }\textbf {\bibinfo {volume}
  {5}},\ \bibinfo {pages} {633} (\bibinfo {year} {2009})}\BibitemShut {NoStop}%
\bibitem [{\citenamefont {Deffner}\ and\ \citenamefont
  {Jarzynski}(2013)}]{deffner_information_2013}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {S.}~\bibnamefont
  {Deffner}}\ and\ \bibinfo {author} {\bibfnamefont {C.}~\bibnamefont
  {Jarzynski}},\ }\href {https://doi.org/10.1103/PhysRevX.3.041003} {\bibfield
  {journal} {\bibinfo  {journal} {Phys. Rev. X}\ }\textbf {\bibinfo {volume}
  {3}},\ \bibinfo {pages} {041003} (\bibinfo {year} {2013})}\BibitemShut
  {NoStop}%
\bibitem [{\citenamefont {Deffner}(2013)}]{deffner_information_driven_2013}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {S.}~\bibnamefont
  {Deffner}},\ }\href {https://doi.org/10.1103/PhysRevE.88.062128} {\bibfield
  {journal} {\bibinfo  {journal} {Phys. Rev. E}\ }\textbf {\bibinfo {volume}
  {88}},\ \bibinfo {pages} {062128} (\bibinfo {year} {2013})}\BibitemShut
  {NoStop}%
\bibitem [{\citenamefont {Ziman}\ \emph {et~al.}(2002)\citenamefont {Ziman},
  \citenamefont {Štelmachovič}, \citenamefont {Bužek}, \citenamefont
  {Hillery}, \citenamefont {Scarani},\ and\ \citenamefont
  {Gisin}}]{ziman_diluting_2002}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {M.}~\bibnamefont
  {Ziman}}, \bibinfo {author} {\bibfnamefont {P.}~\bibnamefont
  {Štelmachovič}}, \bibinfo {author} {\bibfnamefont {V.}~\bibnamefont
  {Bužek}}, \bibinfo {author} {\bibfnamefont {M.}~\bibnamefont {Hillery}},
  \bibinfo {author} {\bibfnamefont {V.}~\bibnamefont {Scarani}},\ and\ \bibinfo
  {author} {\bibfnamefont {N.}~\bibnamefont {Gisin}},\ }\href
  {https://doi.org/10.1103/PhysRevA.65.042105} {\bibfield  {journal} {\bibinfo
  {journal} {Physical Review A}\ }\textbf {\bibinfo {volume} {65}},\ \bibinfo
  {pages} {042105} (\bibinfo {year} {2002})}\BibitemShut {NoStop}%
\bibitem [{\citenamefont {Blume-Kohout}\ and\ \citenamefont
  {Zurek}(2005)}]{blume_kohout_simple_2005}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {R.}~\bibnamefont
  {Blume-Kohout}}\ and\ \bibinfo {author} {\bibfnamefont {W.~H.}\ \bibnamefont
  {Zurek}},\ }\href {https://doi.org/10.1007/s10701-005-7352-5} {\bibfield
  {journal} {\bibinfo  {journal} {Foundations of Physics}\ }\textbf {\bibinfo
  {volume} {35}},\ \bibinfo {pages} {1857} (\bibinfo {year}
  {2005})}\BibitemShut {NoStop}%
\bibitem [{\citenamefont {Zwolak}\ and\ \citenamefont
  {Zurek}(2017)}]{zwolak_redundancy_2017}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {M.}~\bibnamefont
  {Zwolak}}\ and\ \bibinfo {author} {\bibfnamefont {W.~H.}\ \bibnamefont
  {Zurek}},\ }\href {https://doi.org/10.1103/PhysRevA.95.030101} {\bibfield
  {journal} {\bibinfo  {journal} {Physical Review A}\ }\textbf {\bibinfo
  {volume} {95}},\ \bibinfo {pages} {030101} (\bibinfo {year}
  {2017})}\BibitemShut {NoStop}%
\bibitem [{\citenamefont {Scarani}\ \emph {et~al.}(2002)\citenamefont
  {Scarani}, \citenamefont {Ziman}, \citenamefont {Štelmachovič},
  \citenamefont {Gisin},\ and\ \citenamefont
  {Bužek}}]{scarani_thermalizing_2002}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {V.}~\bibnamefont
  {Scarani}}, \bibinfo {author} {\bibfnamefont {M.}~\bibnamefont {Ziman}},
  \bibinfo {author} {\bibfnamefont {P.}~\bibnamefont {Štelmachovič}},
  \bibinfo {author} {\bibfnamefont {N.}~\bibnamefont {Gisin}},\ and\ \bibinfo
  {author} {\bibfnamefont {V.}~\bibnamefont {Bužek}},\ }\href
  {https://doi.org/10.1103/PhysRevLett.88.097905} {\bibfield  {journal}
  {\bibinfo  {journal} {Physical Review Letters}\ }\textbf {\bibinfo {volume}
  {88}},\ \bibinfo {pages} {097905} (\bibinfo {year} {2002})}\BibitemShut
  {NoStop}%
\bibitem [{\citenamefont {Nagaj}\ \emph {et~al.}(2002)\citenamefont {Nagaj},
  \citenamefont {Štelmachovič}, \citenamefont {Bužek},\ and\ \citenamefont
  {Kim}}]{nagaj_quantum_2002}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {D.}~\bibnamefont
  {Nagaj}}, \bibinfo {author} {\bibfnamefont {P.}~\bibnamefont
  {Štelmachovič}}, \bibinfo {author} {\bibfnamefont {V.}~\bibnamefont
  {Bužek}},\ and\ \bibinfo {author} {\bibfnamefont {M.}~\bibnamefont {Kim}},\
  }\href {https://doi.org/10.1103/PhysRevA.66.062307} {\bibfield  {journal}
  {\bibinfo  {journal} {Physical Review A}\ }\textbf {\bibinfo {volume} {66}},\
  \bibinfo {pages} {062307} (\bibinfo {year} {2002})}\BibitemShut {NoStop}%
\bibitem [{\citenamefont {Krantz}\ \emph {et~al.}(2019)\citenamefont {Krantz},
  \citenamefont {Kjaergaard}, \citenamefont {Yan}, \citenamefont {Orlando},
  \citenamefont {Gustavsson},\ and\ \citenamefont
  {Oliver}}]{krantz_quantum_2019}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {P.}~\bibnamefont
  {Krantz}}, \bibinfo {author} {\bibfnamefont {M.}~\bibnamefont {Kjaergaard}},
  \bibinfo {author} {\bibfnamefont {F.}~\bibnamefont {Yan}}, \bibinfo {author}
  {\bibfnamefont {T.~P.}\ \bibnamefont {Orlando}}, \bibinfo {author}
  {\bibfnamefont {S.}~\bibnamefont {Gustavsson}},\ and\ \bibinfo {author}
  {\bibfnamefont {W.~D.}\ \bibnamefont {Oliver}},\ }\href
  {https://doi.org/10.1063/1.5089550} {\bibfield  {journal} {\bibinfo
  {journal} {Appl. Phys. Rev.}\ }\textbf {\bibinfo {volume} {6}},\ \bibinfo
  {pages} {021318} (\bibinfo {year} {2019})}\BibitemShut {NoStop}%
\bibitem [{\citenamefont {Wan}\ \emph {et~al.}(2017)\citenamefont {Wan},
  \citenamefont {Dahlsten}, \citenamefont {Kristjánsson}, \citenamefont
  {Gardner},\ and\ \citenamefont {Kim}}]{wan_quantum_2017}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {K.~H.}\ \bibnamefont
  {Wan}}, \bibinfo {author} {\bibfnamefont {O.}~\bibnamefont {Dahlsten}},
  \bibinfo {author} {\bibfnamefont {H.}~\bibnamefont {Kristjánsson}}, \bibinfo
  {author} {\bibfnamefont {R.}~\bibnamefont {Gardner}},\ and\ \bibinfo {author}
  {\bibfnamefont {M.~S.}\ \bibnamefont {Kim}},\ }\href
  {https://doi.org/10.1038/s41534-017-0032-4} {\bibfield  {journal} {\bibinfo
  {journal} {npj Quantum Inf}\ }\textbf {\bibinfo {volume} {3}},\ \bibinfo
  {pages} {36} (\bibinfo {year} {2017})}\BibitemShut {NoStop}%
\bibitem [{\citenamefont {Ruder}(2017)}]{ruder_overview_2017}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {S.}~\bibnamefont
  {Ruder}},\ }\href {https://doi.org/10.48550/arXiv.1609.04747} {\bibinfo
  {title} {An overview of gradient descent optimization algorithms}} (\bibinfo
  {year} {2017}),\ \bibinfo {note} {arXiv:1609.04747 [cs]}\BibitemShut
  {NoStop}%
\bibitem [{\citenamefont {Scully}\ \emph {et~al.}(2003)\citenamefont {Scully},
  \citenamefont {Zubairy}, \citenamefont {Agarwal},\ and\ \citenamefont
  {Walther}}]{scully_extracting_2003}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {M.~O.}\ \bibnamefont
  {Scully}}, \bibinfo {author} {\bibfnamefont {M.~S.}\ \bibnamefont {Zubairy}},
  \bibinfo {author} {\bibfnamefont {G.~S.}\ \bibnamefont {Agarwal}},\ and\
  \bibinfo {author} {\bibfnamefont {H.}~\bibnamefont {Walther}},\ }\href
  {https://www.science.org/doi/10.1126/science.1078955} {\bibfield  {journal}
  {\bibinfo  {journal} {Science}\ }\textbf {\bibinfo {volume} {299}},\ \bibinfo
  {pages} {862} (\bibinfo {year} {2003})}\BibitemShut {NoStop}%
\bibitem [{\citenamefont {Karevski}\ and\ \citenamefont
  {Platini}(2009)}]{karevski_quantum_2009}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {D.}~\bibnamefont
  {Karevski}}\ and\ \bibinfo {author} {\bibfnamefont {T.}~\bibnamefont
  {Platini}},\ }\href {https://link.aps.org/doi/10.1103/PhysRevLett.102.207207}
  {\bibfield  {journal} {\bibinfo  {journal} {Physical Review Letters}\
  }\textbf {\bibinfo {volume} {102}},\ \bibinfo {pages} {207207} (\bibinfo
  {year} {2009})}\BibitemShut {NoStop}%
\end{thebibliography}%


\end{document}
%
% ****** End of file apstemplate.tex ******

