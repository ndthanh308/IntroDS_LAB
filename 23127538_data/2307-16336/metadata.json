{
  "title": "Anatomy of an AI-powered malicious social botnet",
  "authors": [
    "Kai-Cheng Yang",
    "Filippo Menczer"
  ],
  "submission_date": "2023-07-30T23:06:06+00:00",
  "revised_dates": [],
  "abstract": "Large language models (LLMs) exhibit impressive capabilities in generating realistic text across diverse subjects. Concerns have been raised that they could be utilized to produce fake content with a deceptive intention, although evidence thus far remains anecdotal. This paper presents a case study about a Twitter botnet that appears to employ ChatGPT to generate human-like content. Through heuristics, we identify 1,140 accounts and validate them via manual annotation. These accounts form a dense cluster of fake personas that exhibit similar behaviors, including posting machine-generated content and stolen images, and engage with each other through replies and retweets. ChatGPT-generated content promotes suspicious websites and spreads harmful comments. While the accounts in the AI botnet can be detected through their coordination patterns, current state-of-the-art LLM content classifiers fail to discriminate between them and human accounts in the wild. These findings highlight the threats posed by AI-enabled social bots.",
  "categories": [
    "cs.CY",
    "cs.AI",
    "cs.SI"
  ],
  "primary_category": "cs.CY",
  "doi": "10.51685/jqd.2024.icwsm.7",
  "journal_ref": "Journal of Quantitative Description: Digital Media (2024)",
  "arxiv_id": "2307.16336",
  "pdf_url": "https://arxiv.org/pdf/2307.16336v1",
  "comment": null,
  "num_versions": null,
  "size_before_bytes": 892827,
  "size_after_bytes": 100680
}