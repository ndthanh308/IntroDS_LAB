{
  "title": "Label Noise: Correcting the Forward-Correction",
  "authors": [
    "William Toner",
    "Amos Storkey"
  ],
  "submission_date": "2023-07-24T19:41:19+00:00",
  "revised_dates": [
    "2024-08-23T00:49:18+00:00"
  ],
  "abstract": "Training neural network classifiers on datasets with label noise poses a risk of overfitting them to the noisy labels. To address this issue, researchers have explored alternative loss functions that aim to be more robust. The `forward-correction' is a popular approach wherein the model outputs are noised before being evaluated against noisy data. When the true noise model is known, applying the forward-correction guarantees consistency of the learning algorithm. While providing some benefit, the correction is insufficient to prevent overfitting to finite noisy datasets. In this work, we propose an approach to tackling overfitting caused by label noise. We observe that the presence of label noise implies a lower bound on the noisy generalised risk. Motivated by this observation, we propose imposing a lower bound on the training loss to mitigate overfitting. Our main contribution is providing theoretical insights that allow us to approximate the lower bound given only an estimate of the average noise rate. We empirically demonstrate that using this bound significantly enhances robustness in various settings, with virtually no additional computational cost.",
  "categories": [
    "cs.LG"
  ],
  "primary_category": "cs.LG",
  "doi": null,
  "journal_ref": null,
  "arxiv_id": "2307.13100",
  "pdf_url": null,
  "comment": null,
  "num_versions": null,
  "size_before_bytes": 1834322,
  "size_after_bytes": 492784
}