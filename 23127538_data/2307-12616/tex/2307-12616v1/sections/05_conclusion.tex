\section{Conclusion}
\label{sec:conclusion}
We have presented CTVIS, a simple yet effective training strategy for VIS. CTVIS aligns the training and inference pipelines in terms of constructing contrastive items. Its ingredients include long-video training, memory bank, MA embedding and noise to facilitate the learning of better instance representations, which in turn offers more stable tracking of instances. Thanks to this design, CTVIS has demonstrated superior performance on multiple benchmarks. Additionally, to relieve the cost of the video-level annotation of masks, we propose to create pseudo videos for VIS training based on goal-oriented data augmentation. CTVIS models trained with pseudo videos, which are produced using only 10\% frames extracted from the genuine training videos, achieve comparable performance, compared with SOTA models trained with full supervision. 

\textbf{Acknowledgement:}
This work was supported by National Key R\&D Program of China (No.\ 2022ZD0118700), National Natural Science Foundation of China (No.\ 62272395), Zhejiang Provincial Natural Science Foundation of China (No.\ LY21F020024), and Qin Chuangyuan Innovation and Entrepreneurship Talent Project (No.\ QCYRCXM-2022-359).