
\PassOptionsToPackage{table}{xcolor}

\documentclass[11pt]{siamart171218}

\usepackage{graphicx}
\usepackage[nameinlink]{cleveref} 
\usepackage{bm}
\usepackage{bbm}
\usepackage{comment}
\usepackage{enumitem}
\usepackage{diagbox}
\usepackage{multirow}
\usepackage[ruled,vlined,algo2e]{algorithm2e}
\newcommand{\crefrangeconjunction}{~through~}
\crefname{equation}{}{}
\crefname{algocf}{algorithm}{algorithms}
\graphicspath{{./Figures/}}
\definecolor{CeruleanRef}{RGB}{12,127,172}
\hypersetup{colorlinks=true,allcolors=CeruleanRef}
\hypersetup{pdfstartview=FitB,pdfpagemode=UseNone}
\newsiamremark{remark}{Remark}
\newsiamremark{example}{Example}

\usepackage{accents}
\DeclareMathAccent{\wtilde}{\mathord}{largesymbols}{"65}

\usepackage{caption}
\usepackage{subcaption}
\usepackage{hhline}

\renewcommand{\qed}{\hfill\blacksquare}
\newcommand{\qedwhite}{\hfill \ensuremath{\Box}}

\usepackage{tikz}
\usetikzlibrary{decorations.pathreplacing}
\usetikzlibrary{calligraphy}
\usetikzlibrary{cd}
\usepackage{pgfplots}
\pgfplotsset{compat=1.18}
\definecolor{color0}{rgb}{0.7843, 0.7843, 0.7843}
\definecolor{color1}{rgb}{0, 0.4470, 0.7410}
\definecolor{color2}{rgb}{0.8500, 0.3250, 0.0980}
\definecolor{color3}{rgb}{0.9290, 0.6940, 0.1250}
\definecolor{color4}{rgb}{0.7060, 0.3840, 0.7650}
\definecolor{color5}{rgb}{0.4660, 0.6740, 0.1880}
\definecolor{color6}{rgb}{0.3010, 0.7450, 0.9330}
\definecolor{color7}{rgb}{0.6350, 0.0780, 0.1840}
\definecolor{color8}{rgb}{0.0, 0.4078, 0.3412}

\newcommand{\posorth}{\begin{tikzpicture}\draw (0,0) -- (0ex,1ex);\draw (0,0) -- (1ex,0ex);\end{tikzpicture}}

\usepackage{amsmath,amssymb}
\DeclareMathOperator*{\argmin}{\vphantom{p}arg\,min}
\DeclareMathOperator*{\argmax}{\vphantom{p}arg\,max}
\DeclareMathOperator*{\esssup}{\vphantom{p}ess\,sup}
\DeclareMathOperator*{\essinf}{\vphantom{p}ess\,inf}
\DeclareMathOperator{\minimize}{Minimize}
\DeclareMathOperator{\st}{~subject~to~}
\DeclareMathOperator{\suchthat}{~such~that~}
\DeclareMathOperator{\fa}{~for~all~}
\DeclareMathOperator{\lnit}{lnit}
\DeclareMathOperator{\sigmoid}{expit} \DeclareMathOperator{\proj}{proj}
\DeclareMathOperator{\prox}{prox}
\DeclareMathOperator{\breg}{breg}
\DeclareMathOperator{\projit}{projit}
\DeclareMathOperator{\atanh}{arctanh}
\DeclareMathOperator{\interior}{int}
\DeclareMathOperator{\bd}{bd}
\DeclareMathOperator{\cl}{cl}
\DeclareMathOperator{\supp}{supp}
\DeclareMathOperator{\dom}{dom}
\DeclareMathOperator{\dd}{d\!}
\let\div\relax \DeclareMathOperator{\div}{div}
\DeclareMathOperator{\Div}{Div}
\DeclareMathOperator{\vol}{vol}
\DeclareMathOperator{\TV}{TV}
\DeclareMathOperator{\BV}{BV}
\newcommand{\einheit}[1]{(#1)_{\times}}
\newcommand{\poseinheit}[1]{(#1)_{\posorth}}
\newcommand{\loc}{\mathrm{loc}}

\let\inf\relax \DeclareMathOperator*\inf{\vphantom{p}inf}
\let\min\relax \DeclareMathOperator*\min{\vphantom{p}min}
\let\max\relax \DeclareMathOperator*\max{\vphantom{p}max}
\let\tilde\widetilde
\let\hat\widehat
\let\check\widecheck


\newsiamthm{claim}{Claim}

\allowdisplaybreaks

\begin{document}


\title{
    Proximal Galerkin: A structure-preserving finite element method for pointwise bound constraints
                                                                                                        }

\author{
    Brendan~Keith\thanks{\protect
        Division of Applied Mathematics,
        Brown University,
        Providence, RI 02912 USA
        (\email{brendan\_keith@brown.edu}).
    }
    \and Thomas~M.~Surowiec\thanks{\protect
        Simula Research Laboratory,
        Department of Numerical Analysis and Scientific Computing,
        Kristian Augusts gate 23,
        0164, Oslo, Norway, 
        (\email{thomasms@simula.no})
    }
}

\date{\today}

\maketitle

\begin{center}
    \small
    \medskip
  \emph{Dedicated with respect and admiration to Leszek Demkowicz on the occasion of his 70th birthday anniversary.}
  \medskip
\end{center}

\begin{abstract}
The proximal Galerkin finite element method is a high-order, low iteration complexity, nonlinear numerical method that preserves the geometric and algebraic structure of bound constraints in infinite-dimensional function spaces.
This paper introduces the proximal Galerkin method and applies it to solve free boundary problems, enforce discrete maximum principles, and develop scalable, mesh-independent algorithms for optimal design.
The paper leads to a derivation of the latent variable proximal point (LVPP) algorithm: an unconditionally stable alternative to the interior point method.
LVPP is an infinite-dimensional optimization algorithm that may be viewed as having an adaptive barrier function that is updated with a new informative prior at each (outer loop) optimization iteration.
One of the main benefits is witnessed when analyzing the classical obstacle problem.
Therein, we find that the original variational \emph{inequality} can be replaced by a sequence of semilinear partial differential \emph{equations} (PDEs) that are readily discretized and solved with, \textit{e.g.}, high-order finite elements.
Throughout this work, we arrive at several unexpected contributions that may be of independent interest.
These include (1) a semilinear PDE we refer to as the \emph{entropic Poisson equation}; (2) an algebraic/geometric connection between high-order positivity-preserving discretizations and certain infinite-dimensional Lie groups; and (3) a gradient-based, bound-preserving algorithm for two-field, density-based topology optimization.
The complete latent variable proximal Galerkin methodology combines ideas from nonlinear programming, functional analysis, tropical algebra, and differential geometry and can potentially lead to new synergies among these areas as well as within variational and numerical analysis.
This work is accompanied by open-source implementations of our methods to facilitate reproduction and broader adoption.








\end{abstract}

\noindent\fbox{%
	\parbox{0.97\textwidth}{
        \begin{center}
        \medskip
            \emph{\bfseries This is a ``working paper.'' The remainder of Section 5 will be included in a future edition.}
        \medskip
        \end{center}
    }
}

\section{Introduction} \label{sec:introduction} 

Although the origins of variational analysis can be traced back at least to the seventeenth century \cite{oden2012variational}, its role in the modern study of partial differential equations (PDEs) only truly began to take shape around 1847 once William Thomson introduced what is now known as the Dirichlet principle.
In contemporary language, this energy principle states that for all functions $f\in L^2(\Omega)$ and $g\in H^1(\Omega)$, the (weak) solution of Poisson's equation over a Lipschitz domain $\Omega \subset \mathbb{R}^n$,
\begin{equation}
\label{eq:PoissonEquation}
	-\Delta u = f
	\quad \text{in~} \Omega,
	\qquad
	u = g \quad \text{on~} \partial\Omega,
\end{equation}
can be obtained as the $H^1(\Omega)$-minimizer of the Dirichlet energy,
\begin{equation}
\label{eq:DirichletEnergy}
	E(v)
	=
	\frac{1}{2}
	\int_\Omega |\nabla v|^2 \dd x
	-
	\int_\Omega v f \dd x
	\,,
\end{equation}
confined to the constraint set $H^1_g(\Omega) = g + H^1_0(\Omega) = \{ v \in H^1(\Omega) \mid v = g \text{~on~} \partial \Omega\}$.

Owing to the fact that $H^1_g(\Omega)$ is nonempty, closed, and convex, it is a straight-forward consequence of the Lions--Stampacchia theorem \cite{stampacchia1963equations,lions1967variational} that the energy minimizer $u^\ast \in K = H^1_g(\Omega)$ is the unique solution to the variational inequality (VI)
\begin{equation}
\label{eq:DirichletVI}
	\int_\Omega \nabla u^\ast \cdot \nabla v  \dd x \geq \int_\Omega f v \dd x
	~\fa v \in K-u^\ast.
		\end{equation}
As it happens, the boundary condition in~\cref{eq:PoissonEquation} is an equality constraint that induces an \emph{affine} structure on the feasible set.
Moreover, it is this particular algebraic structure that can be exploited to show that the minimizer $u^\ast \in H^1_g(\Omega)$ is also uniquely characterized by a variational \emph{equation}.
In the setting above, we have
\begin{equation}
\label{eq:DirichletVE}
	\int_\Omega \nabla u^\ast \cdot \nabla w \dd x
	=
	\int_\Omega f w \dd x
	~\fa w \in H^1_0(\Omega).
\end{equation}
To arrive at this conclusion from~\cref{eq:DirichletVI}, the key idea is to notice that $H^1_g(\Omega) + H^1_0(\Omega) = H^1_g(\Omega)$ and, therefore, one may replace $v$ in~\cref{eq:DirichletVI} by $u^\ast\pm w$, for any $w \in H^1_0(\Omega)$.
For further details, see, e.g., \cite[Proposition~9.22]{brezis2011functional} and \cite[Theorem~1.2.2]{ciarlet2002finite}.




When partial differential equations (PDEs) are first written down, their essential boundary conditions are often the only explicit constraints that appear on the space of solutions.
As such, all students of the finite element method are taught to derive variational equations like~\cref{eq:DirichletVE}; cf.~\cite[Section~1.4]{hughes2012finite}, \cite[Exercise~1.2.2]{ciarlet2002finite}, and \cite[Section~31.2.2]{ern2021finite}.
In turn, viewing the variational equations that originate from essential boundary conditions as structure-exploiting reductions of more general VIs may seem esoteric to some practitioners.
Yet, the motive becomes clear when the feasible set has alternative algebraic structures.






To illustrate this point, it is instructive to consider imposing a pointwise non-negativity constraint, $u^\ast \geq 0$, and setting $g \equiv 0$.
Hereafter, let $H^1_+(\Omega) = \{ v \in H^1(\Omega) \mid v \geq 0 \text{~a.e.}\}$.
Thus, the subset
\begin{equation}
\label{eq:NonNegativeConstraintSet}
	K = \{ v \in H^1_0(\Omega) \mid v \geq 0 \text{~a.e.}\} = H^1_0(\Omega) \cap H^1_+(\Omega)
	,
\end{equation}
forms a closed convex cone in $H^1(\Omega)$.
It is well-known that the \emph{conic} structure of $K$ allows us to write
\begin{equation}
	\int_\Omega \nabla u^\ast \cdot \nabla v \dd x \geq \int_\Omega f v \dd x
	~\fa v \in K
	,
\end{equation}
with equality holding for $v = u^\ast$; see, e.g., \cite[Theorem~1.1.2]{ciarlet2002finite}.
Although we acknowledge this simplified variational formulation, we present it only as a motivating example.
Our work pursues a different type of algebraic structure.

Our aim is to provide a \emph{multiplicative} structure-preserving approach to solving bound-constrained optimization problems and variational inequalities in Sobolev spaces.
This will lead us to working in \emph{Banach algebras}, which are Banach spaces that are closed under a continuous multiplication operation \cite{conway2019course}.
Instead of performing Lagrangian relaxation or relying on penalty functions, the key component of our approach is an adaptive form of \emph{entropy regularization}.
Through entropy regularization, we will find, e.g., that minimizing the Dirichlet energy over functions in $H^1_g(\Omega) \cap H^1_+(\Omega)$ can be reduced to solving a ``Bayesian'' sequence of second-order semilinear PDEs where each right-hand side is biased by the prior solution.


\Cref{alg:HomogeneousAlg} outlines the meta-algorithm for the pointwise non-negativity constraint $u^\ast \geq 0$ considered above when $f \in L^\infty(\Omega)$ and $g_{|\partial\Omega} \in C(\partial \Omega)$ satisfies $\essinf_{\partial\Omega} g > 0$.
Note that, unlike, e.g., descent methods \cite[Section~3]{wright2022optimization}, this algorithm converges for \emph{all} step size values $\alpha > 0$; cf.~\Cref{thm:ConvergenceContinuousLevel}.
A practical version of the algorithm is readily implementable (see, e.g., \cite{Keith2023ObstacleCode,ZenodoCode}) and reduces to the finite element method that gives this paper its name.

\begin{algorithm2e}\DontPrintSemicolon
	\caption{\label{alg:HomogeneousAlg} Entropic proximal point algorithm for Dirichlet energy minimization with a non-negativity constraint.}
	\SetKwInOut{Input}{input}
		\BlankLine
	\Input{Step size parameter $\alpha>0$ and initial solution guess $w \in H^1_g(\Omega)\cap L^\infty(\Omega)$ satisfying $\essinf w > 0$.}
		\BlankLine
		\Repeat{a convergence test is satisfied}
	{
		Solve the entropic Poisson equation,
		\begin{equation}
		\label{eq:EPEIntro}
																											\left\{
				\begin{aligned}
					\,-\Delta u + \alpha^{-1}\ln u
					&=
					f + \alpha^{-1}\ln w
					~~ &&\text{in~} \Omega\,,
					\\
					u
					&=
					g ~~ &&\text{on~} \partial\Omega\,.
				\end{aligned}
			\right.
		\end{equation}
				\;
		\vspace*{-\baselineskip}
		Assign $w \leftarrow u$.\;
	}
		\BlankLine
\end{algorithm2e}

\begin{remark}[Proximal Galerkin]
	To differentiate between the method proposed in this paper and a significantly different ``proximal Galerkin'' method proposed in \cite{mackey2014compressive}, we consider the full name of our method to be the ``\emph{latent variable} proximal Galerkin'' method.
	Throughout the text, we typically use the abbreviated name ``proximal Galerkin'' without any cause for confusion.
\end{remark}

\subsection{Notation} \label{sub:notation}
Our notation is rather standard for the finite element literature. Norms are denoted by
$\| \cdot \|_{X}$, inner products by $(\cdot,\cdot)_{X}$, and duality pairings by 
$\langle \cdot,\cdot \rangle_{X',X}$ for spaces $X$ and its paired topological 
dual $X'$. Whenever it is clear in context, we leave off or abbreviate the subscripts in a
natural way. Norm convergence will typically be denoted by $\rightarrow$ or 
$\stackrel{X}{\to}$, for weak convergence we use the standard 
$\stackrel{X}{\rightharpoonup}$ or $\rightharpoonup$.  For subsets $C$ of infinite 
dimensional spaces, we denote the closure by $\cl C$,
the boundary by $\bd C$, and the interior by $\interior C$. For a mapping
$F$ between normed linear spaces $X$ and $Y$, the Fr\'echet derivative of $F$
at $x$ is indicated by $F'(x)$.

For an open bounded domain $\Omega \subset \mathbb R^n$, $n \in \{1,2,...\}$, $
L^p(\Omega)$, $p \in [1,\infty]$, denotes the usual Lebesgue space of
(equivalence classes of) $p$-integrable functions when $p \in [1,\infty)$, and essentially 
bounded functions when $p = \infty$, respectively. Furthermore, we define
\[
L^p_+(\Omega) := \left\{ u \in L^p(\Omega) \mid u \ge 0 \text{ a.e.~in } \Omega \right\}
\]
for any $p \in [1,\infty]$.

For domains $\Omega$ in $\mathbb R^d$,
we denote the boundary by $\partial \Omega$ and the closure by $\overline{\Omega}$.
The spaces $L^p(\partial \Omega)$ are defined in the usual way. When needed, we indicate
the surface measure for $\partial \Omega$ by $d \mathcal{H}_{n-1}$.
The space of continuous functions on $\overline{\Omega}$ is written $C(\overline{\Omega})$.
Similarly, $C^m(\overline{\Omega})$, $m \in \mathbb N \cup \{\infty\}$, is the 
space of all $m$-times continuously differentiable functions. The space of smooth 
compactly supported test functions on $\Omega$ is given by $C^{\infty}_{c}(\Omega)$. 
The Sobolev space of $L^2(\Omega)$ functions with $L^2(\Omega)$ integrable 
weak derivatives is denoted by $H^1(\Omega)$ and its closed subspace of functions $u$
with trace $\gamma u = 0$ is denoted by $H^1_0(\Omega)$. We use $H^{s}(\partial \Omega)$,
$s \in (0,1)$, for the usual Sobolev--Slobodeckij space on $\partial \Omega$.
We refer the reader to a 
standard text on function spaces for further details, e.g., \cite{adams2003sobolev,mclean2000strongly}.
Finally, for simplicity of notation, we adopt the following notational conventions: $0 \ln 0 := 0$ and $\|v\|_{H^{-1}(\Omega)} := \sup_{w \in H^1_0(\Omega)} \frac{(v,w)}{\|\nabla w\|_{L^2(\Omega)}}$.



\subsection{Outline} \label{sub:intro_overview}

We have attempted to provide a scaffolded presentation of our findings.
To this end, \Cref{sec:structure} presents preliminary concepts and provides further motivation for this work.
Next, \Cref{sec:literature_review} reviews the literature and summarizes our main contributions.
\Crefrange{sec:the_obstacle_problem}{sec:new_algorithms_for_topology_optimization} present the essential features of proximal Galerkin methods for the obstacle problem, the advection-diffusion equation, and topology optimization, respectively.
Each of these sections contains an algorithm that is designed be implemented in a production-level finite element code.
The reader is encouraged to compare these algorithms with our publicly available implementations \cite{Keith2023ObstacleCode,Keith2023TopOptCode,ZenodoCode}.
\Cref{sec:preliminaries} contains the continuous-level mathematical analysis and \Cref{sec:the_entropic_finite_element_method} contains the discrete-level, finite element theory.
\Cref{sec:preliminaries,sec:the_entropic_finite_element_method} are the most technical and may be skipped by a casual reader.
\medskip

\noindent\fbox{%
	\parbox{0.97\textwidth}{
		\begin{center}
		\smallskip
			\emph{\bfseries This is a ``working paper.'' The remainder of Section 5 will be included in a future edition.}
		\smallskip
		\end{center}
	}
}

\medskip







\section{Preserving multiplicative structure} \label{sec:structure}

The proximal Galerkin finite element method is a nonlinear numerical method that preserves the algebraic and geometric structure of bound constraints in infinite-dimensional function spaces.
In this section, we study the multiplicative structure of non-negative functions and use the Dirichlet energy~\cref{eq:DirichletEnergy} to illustrate how proximal Galerkin preserves this structure.

\subsection{Deconstructing the semiring of non-negative functions} \label{sub:the_cole_hopf_transform_and_the_semiring_of_non_negative_functions}

Let $\mathcal{X}$ be a set equipped with two binary operations: addition $\oplus \colon \mathcal{X} \times \mathcal{X} \to \mathcal{X}$ and multiplication $\odot \colon \mathcal{X} \times \mathcal{X} \to \mathcal{X}$.
\begin{definition}
\label{def:Semiring}
We say that $\mathcal{X}$ is a semiring if the following conditions are satisfied \cite{golan2013semirings,gondran2008graphs}:
\begin{itemize}
	\item
	Addition $\oplus$ and multiplication $\odot$ are associative;
	\item
	Addition $\oplus$ is commutative;
		\item
	Multiplication $\odot$ is distributive with respect to addition $\oplus$.
\end{itemize}
We say that $\mathcal{X}$ is a commutative semiring if the conditions above are satisfied and, moreover, multiplication $\odot$ is commutative.
\end{definition}

It is easy to check that the set of non-negative Lebesgue measurable functions,
\begin{equation}
	M_+(\Omega)
	=
	\big\{ v\colon\Omega\to \mathbb{R}_+ \mid \{v > c\} \text{~is~Lebesgue~measurable~} \forall c > 0 \big\}
	,
	\end{equation}
forms a commutative semiring under the standard binary operations of pointwise addition and multiplication.
In particular, note that for any $u,v \in M_+(\Omega)$, we have
\begin{equation}
	u + v
		\in M_+(\Omega)
	\,,
	\qquad
				uv \in M_+(\Omega)
	\,.
\end{equation}

There is an interesting identification between $M_+(\Omega)$ and the space of extended real-valued measurable functions
\begin{equation}
	M_{\max}(\Omega)
	=
	\big\{ \varphi\colon\Omega\to \mathbb{R}\cup\{-\infty\} \mid \{\varphi > c\} \text{~is~Lebesgue~measurable~} \forall c \in \mathbb{R} \big\}
	,
\end{equation}
induced by the (pointwise) logarithm and exponential operators.
Namely, for all $u \in M_+(\Omega)$, $\psi \in M_{\max}(\Omega)$, and $\alpha > 0$, we have that $\alpha^{-1}\ln u \in M_{\max}(\Omega)$ and $\exp(\alpha\psi) \in M_+(\Omega)$ under the convention that $\ln 0 = -\infty$ and, likewise, $\exp (-\infty) = 0$.
Such logarithmic transformations provide a family of semiring isomorphisms between $M_+(\Omega)$ and $M_{\max}(\Omega)$, where $M_{\max}(\Omega)$ is endowed with the following (generalized) addition and multiplication operations:
\begin{equation}
\label{eq:BinaryOperationsLog}
	\psi \oplus \varphi = \alpha^{-1}\ln (\exp (\alpha \psi) + \exp (\alpha \varphi))
	\,,
	\qquad
	\psi \odot \varphi = \psi + \varphi
	\,,
\end{equation}
respectively \cite{maslov1987new,maslov1987newprinciple}.
Moreover, in the limit $\alpha \to \infty$, the generalized addition operation~\cref{eq:BinaryOperationsLog} becomes the pointwise maximum operation \cite{litvinov2007maslov,maclagan2021introduction}; namely,
\begin{equation}
\label{eq:BinaryOperationsTropical}
	\psi \oplus \varphi \to \max\{\psi,\varphi\}
	\,.
\end{equation}

Logarithmic transformations of the above form have been used famously over the last century to analyze differential equations in quantum mechanics \cite{schrodinger1926quantisierung}, fluid flow \cite{hopf1950partial,cole1951quasi}, and electrical engineering \cite{scharfetter1969large,markowich1985stationary}, and, more recently, to study stochastic PDEs \cite{bertini1997stochastic,hairer2013solving}.
Given that they appear to capture certain key algebraic properties of the set of non-negative functions, it is tempting to use logarithmic transformations to enforce non-negativity constraints on function spaces.
Unfortunately, however, special care is required to apply a logarithmic transformation to a non-negative solution variable in a free-boundary problem.

For illustration, consider minimizing the Dirichlet energy~\cref{eq:DirichletEnergy} over the set of non-negative functions
\begin{equation}
\label{eq:NonNegativeConstraintSet_gNonZero}
	K = \{ v \in H^1_g(\Omega) \mid v \geq 0 \text{~a.e.}\} = H^1_g(\Omega) \cap H^1_+(\Omega) 
	.
\end{equation}
Assuming that $f \in L^2(\Omega)$ and $u^\ast \in H^2(\Omega)$, the well-known complementarity conditions for the solution are as follows \cite[p.~79]{kinderlehrer2000introduction}: 
\begin{equation}\label{eq:complementarity}
	u^\ast \geq 0
	,\quad
	-\Delta u^\ast-f\geq 0
	,\quad
	(\Delta u^\ast+f)\,u^\ast = 0
	~~\text{a.e. in~}\Omega
	\,.
\end{equation}
Another perspective uses a dual variable $\lambda^\ast$, also known as a Lagrange multiplier, to formulate \cref{eq:complementarity} as 
a mixed complementarity problem of the form:
\begin{equation}
\label{eq:IntroLagrangeMultiplier}
\aligned
-\Delta u^* - \lambda^* = f,
\quad
u^\ast \ge 0,
\quad
\lambda^\ast \ge 0,
\quad
\langle u^\ast,\lambda^\ast \rangle = 0.
\quad
\endaligned
\end{equation}
The Lagrange multiplier exhibits rather low regularity for general domains $\Omega$, so the term ``$\lambda^\ast \ge 0$'' is actually understood
to mean $\langle \lambda^\ast, w \rangle \ge 0$ for all $w \in H^1_0(\Omega)$ with $w \ge 0$ a.e.\ in $\Omega$, i.e., without further regularity assumptions $\lambda^\ast$ is merely a nonnegative Radon measure on $\Omega$. See \cite[Chap. II, Sec. 6]{kinderlehrer2000introduction} for details.

If we wish to study this problem under a logarithmic transformation, then a formal computation using the substitution $u^\ast = \exp\psi^\ast$ leads to the observation that
\begin{equation}
\label{eq:DegeneratePoisson}
	\psi^\ast = -\infty
	\quad
	\text{~or}
	\quad
	-\div (\exp\psi^\ast\nabla \psi^\ast) = f
		\,,
\end{equation}
at almost every point in $\Omega$.
Analyzing these equations presents challenges, in part, because it requires moving away from well-studied Sobolev spaces \cite{adams2003sobolev} and, instead, working in a space of extended real-valued functions \cite{kolokoltsov1997idempotent} endowed with the metric
\begin{equation}
\label{eq:LatentVariableNonnegativityMetric}
	d(\psi,\varphi)
	=
	\|\nabla \exp\psi - \nabla \exp\varphi\|_{L^2(\Omega)}
	\,.
\end{equation}

One conclusion of this work is that the above concerns are alleviated by a simple regularization of the degenerate PDE in~\cref{eq:DegeneratePoisson}.
In particular, we show that for all bounded $f \in L^\infty(\Omega)$, the latent solution variable $\psi^\ast = \ln u^\ast$ is recovered as the $\alpha\to \infty$ limit (with respect to the metric~\cref{eq:LatentVariableNonnegativityMetric}) of a family of regularized solutions $\psi \in H^1(\Omega)\cap L^\infty(\Omega)$ satisfying
\begin{equation}
\label{eq:DegenerateEntropicPoisson}
		-\div (\exp\psi\nabla \psi) + \alpha^{-1}\psi = f
		\,.
\end{equation}
Moreover, the latent variable iteration $\psi^0 \in H^1(\Omega)\cap L^\infty(\Omega)$,
\begin{equation}
\label{eq:LatentVariableIteration}
	-\div (\exp\psi^k\nabla \psi^k) + \alpha^{-1}\psi^k = f + \alpha^{-1}\psi^{k-1}
	\,,
	\quad
	k=1,2,\ldots,
\end{equation}
formerly written with primal variables in~\Cref{alg:HomogeneousAlg}, converges to $\psi^\ast$ for all finite $\alpha > 0$; cf.~\Cref{thm:ConvergenceContinuousLevel}.

The ambient function space for the regularized latent variable $\psi$ is interesting from an algebraic point of view because it is a \emph{Banach algebra}.
Indeed, the Sobolev subspace $H^1(\Omega)\cap L^\infty(\Omega)$, whose norm is
\begin{equation}
	\|v\|_{H^1(\Omega)\cap L^\infty(\Omega)}
	=
	\max\{\|v\|_{H^1(\Omega)},\|v\|_{L^\infty(\Omega)}\}
	\,,
\end{equation}
is closed under the standard operations of pointwise addition and multiplication \cite[Proposition~9.4]{brezis2011functional}.
Maintaining closure under multiplication is desirable, in part, because it often allows one to construct a smooth exponential map \cite{glockner2002algebras,glockner2003lie}.
Indeed, of particular interest to this work is the Nemytskii operator
\begin{equation}
\label{eq:Exponential_H1Linfty}
	\exp \colon H^1(\Omega)\cap L^\infty(\Omega) \to H^1(\Omega) \cap \interior L^\infty_+(\Omega),
\end{equation}
which is an isomorphism between $H^1(\Omega)\cap L^\infty(\Omega)$ and the \emph{Banach--Lie group}
\begin{equation}
	H^1(\Omega) \cap \interior L^\infty_+(\Omega)
			=
	\{ w \in H^1(\Omega) \cap L^\infty(\Omega) \mid \essinf w > 0\}
	\,;
\end{equation}
cf.~\Cref{prop:logexpChainRule}.
Since the range of this isomorphism is contained in the $H^1(\Omega) \cap L^\infty(\Omega)$-interior of the set of essentially bounded non-negative $H^1(\Omega)$ functions, we find that the primal iterates, $$u^k = \exp \psi^k \in H^1(\Omega) \cap \interior L^\infty_+(\Omega) \subset \interior (H^1(\Omega) \cap L^\infty_+(\Omega))\,,$$ will always be \emph{interior points}.
In the next motivational subsection, we explain that an idenitical sequence of interior points $u^k \stackrel{H^1(\Omega)}{\longrightarrow} u^\ast$ can be found by regularizing the Dirichlet energy with an appropriate \emph{entropy} functional.










\subsection{Dirichlet free energy} \label{sub:dirichlet_free_energy}



Only special function spaces are endowed with a norm topology that permits a continuous multiplication operator.
Indeed, it is well-known that $H^1(\Omega)$ is only closed under multiplication when $n = 1$ \cite{adams2003sobolev}.
Moreover, it is easy to show that $\interior H^1_+(\Omega) = \emptyset$ for all $n \geq 2$, which makes it impossible to define an $H^1(\Omega)$-interior point in any of its subsets (cf.~\Cref{rem:H1InteriorNonnegativeFunctions}).
Because $H^1(\Omega) \cap L^\infty(\Omega)$ bypasses both of these topological issues, it is appealing to restrict the feasible set $K$ in~\cref{eq:NonNegativeConstraintSet_gNonZero} to essentially bounded functions when minimizing the Dirichlet energy.

Unfortunately, requiring the feasible set to be the intersection of $K$ and $L^{\infty}(\Omega)$ would cause the direct method of calculus of variations \cite{bartels2015numerical} to fail.
This is because the Dirichlet energy does not provide control over point-wise values of the solution and $K\cap L^{\infty}(\Omega)$ is not closed in the $H^1(\Omega)$ norm topology.
Therefore, one may conclude that maintaining some important mathematical structures is in conflict with the classical energy principle.


Fortunately, it turns out there is resolution to this conflict that exposes the missing algebraic structure; namely, minimizing the \emph{Dirichlet free energy},
\begin{equation}
\label{eq:DirichletFreeEnergy}
	A(u) = 
	E(u) + \theta S(u)
						.
\end{equation}
Here, $\theta = \alpha^{-1}>0$ is a non-dimensional ``temperature'' parameter and
\begin{equation}
\label{eq:EntropyFunctional}
	S(u) =
	\int_\Omega u\ln u- u \dd x
	\,,
\end{equation}
is the (negative) entropy functional.
As we show in \Cref{thm:PrimalProblem}, all minimizers of~\cref{eq:DirichletFreeEnergy} lie in $K\cap L^\infty(\Omega)$, i.e., for all $\theta > 0$,
\begin{equation}
\label{eq:DirichletFreeEnergyMinimization}
	u = \argmin_{v \in K}
	A(v)
	= \argmin_{v \in K\cap L^\infty(\Omega)}
	A(v)
	\,,
\end{equation}
is essentially bounded away from zero in $\Omega$, and $u = u(\theta)$ converge linearly with respect to $\theta$ to the unique non-negative minimizer of~\cref{eq:DirichletEnergy}, $u^* = \argmin_{v \in K} E(v)$.
More specifically, each $u$ is an interior point and
\begin{equation}
\label{eq:EPE_ConvergenceWRTTemperature}
	\|\nabla u^\ast - \nabla u\|_{L^2(\Omega)}^2 \leq \theta (S(u^\ast) + |\Omega|)
	\,,
\end{equation}
whenever $f\in L^\infty(\Omega)$; cf.~\Cref{cor:EntropicPoissonConvergence}.


Finally, and just as importantly, the general VI that characterizes~\cref{eq:DirichletFreeEnergyMinimization}, i.e.,
\begin{equation}
\label{eq:DirichletVI_nonnegativity}
	\int_\Omega  \nabla u \cdot \nabla v \dd x
	+
	\theta
	\int_\Omega  v\ln u \dd x
		\geq \int_\Omega f v \dd x
	~\fa v \in K-u
							\,,
\end{equation}
can be replaced by a variational equality for the weak form of a semilinear PDE we call the \emph{entropic Poisson equation}, $-\Delta u + \theta\ln u = f$; namely,
\begin{equation}
\label{eq:EntropicPoissonWeakForm}
	\int_\Omega \nabla u \cdot \nabla w \dd x
	+
	\theta
	\int_\Omega w \ln u \dd x
	=
	\int_\Omega f w \dd x
	~\fa w \in H^1_0(\Omega).
				\end{equation}
The entropic Poisson equation is the primal form of~\cref{eq:DegenerateEntropicPoisson} and has numerous interesting properties that we exploit in this work. We also note that $\theta \ln (1/u)$ approximates the true Lagrange multiplier $\lambda^\ast$ introduced in~\cref{eq:IntroLagrangeMultiplier} above.


The essential idea presented above is expanded on in \Cref{sec:maximum_principles,sec:new_algorithms_for_topology_optimization} to accommodate bound constraints for general VIs that do not appear as a result of energy principles, as well as those that appear in topology optimization with a view toward other bound-constrained optimization problems.
Crucially, and unlike traditional penalty or barrier methods \cite{nocedal1999numerical,Bertsekas99,Wriggers2006}, it is \emph{not necessary} to take $\theta \to 0$ in order to get an arbitrarily accurate approximation of $u^\ast$.
Indeed, the simple adaptive entropic regularization algorithm given in \Cref{alg:HomogeneousAlg} (see also~\cref{eq:LatentVariableIteration}), which comes from regularizing the Dirichlet energy with a \emph{relative entropy} functional, is far more appealing and is derived in \Cref{sec:the_obstacle_problem}.
\Cref{fig:Trinity} provides a diagrammatic reference for the main elements of the continuous-level algorithm in the case $\alpha = 1$.

% Figure environment removed

\begin{remark}[Dirichlet free energy]
	We propose the name ``Dirichlet free energy'' for the functional in~\cref{eq:DirichletFreeEnergy} by analogy with the Helmholtz free energy from statistical mechanics \cite{pathria2016statistical}, $A = E - T S$, where $E$ denotes total system energy, $T$ denotes absolute temperature, and $S$ denotes thermodynamic entropy.
\end{remark}


\subsection{Pointwise-positivity for every polynomial degree} \label{sub:pointwise_positive_discretizations}

The majority of this paper is based on pursing the aforementioned observation that the solution of VIs for bound constraints, including~\cref{eq:DirichletVI_nonnegativity}, can be approximated arbitrarily accurately by variational \emph{equations} like~\cref{eq:EntropicPoissonWeakForm}.
Leveraging this observation for computational purposes leads to a new class of high-order, nonlinear finite element methods we refer to as proximal Galerkin methods.
In turn, taking advantage of the multiplicative structure of the solution space leads to non-standard approximation spaces that naturally preserve pointwise positivity at the discrete level.

As we shall also show in \Cref{sec:the_obstacle_problem}, a very convenient Galerkin discretization of the entropic Poisson equation~\cref{eq:EPEIntro} is found by introducing a pair of linear subspaces $V_h \subset H^1_0(\Omega)$ and $W_h \subset L^\infty(\Omega)$ --- for instance, spaces of high-degree piecewise polynomials --- and simultaneously approximating the solution $u$ in both the primal space and the latent space; namely,
\begin{equation}
	u \approx u_h
	\quad
	\text{and}
	\quad
	u \approx \exp(\alpha\psi_h)
	\,,
\end{equation}
where $u_h \in g_h + V_h$, $\psi_h \in W_h$, and $g_h \in H^1(\Omega)$ provides an approximation of the boundary values $g_{h|\partial\Omega} \approx g_{|\partial\Omega}$.
The basic method is outlined in \Cref{alg:EntropicGalerkinIntro}.

\begin{algorithm2e}\DontPrintSemicolon
	\caption{\label{alg:EntropicGalerkinIntro} 
	Proximal Galerkin method for Dirichlet energy minimization with a pointwise non-negativity constraint.
	}
	\SetKwInOut{Input}{Input}
	\SetKwInOut{Output}{Output}
	\BlankLine
	\Input{Step size parameter $\alpha > 0$, linear subspaces $V_h \subset H^1_0(\Omega)$ and $W_h \subset L^\infty(\Omega)$, and initial solution guess $\psi_h \in W_h$.}
	\Output{Two approximate solutions, $u_{h}$ and $\widetilde{u}_h = \exp(\alpha\psi_h)$, and an approximate Lagrange multiplier, $\lambda_h = \omega_h - \psi_h$.}
	\BlankLine
	\Repeat{a convergence test is satisfied}
	{
		Assign $\omega_h \leftarrow \psi_{h}$.\;
		Solve the following (nonlinear) discrete saddle-point problem:
		\begin{gather*}
					\left\{
			\begin{aligned}
				\,&\text{Find}~
				u_{h}\in g_h + V_{h} ~\text{and}~\psi_{h} \in W_{h}
								~\text{such that~}
				\\
				&\begin{alignedat}{4}
					\int_\Omega \nabla u_h\cdot \nabla v \dd x + \int_\Omega \psi_h v \dd x &= \int_\Omega (f + \omega_h)\, v \dd x
					&&~\fa v \in V_h
					\,,
					\\
					\int_\Omega u_h \varphi \dd x - \int_\Omega \exp(\alpha\psi_h)\, \varphi \dd x &= 0
					&&~\fa \varphi \in W_h
																																			\,.
				\end{alignedat}
			\end{aligned}
			\right.
		\end{gather*}
		\;
		\vspace*{-\baselineskip}
	}
\end{algorithm2e}

A novelty of the approximate solution $\widetilde{u}_h = \exp(\alpha\psi_h)$ is that it is \emph{guaranteed} to deliver \emph{pointwise positivity}.
We exploit and extend this property throughout this work to develop some of the first high-order \emph{bound-preserving} finite element methods for a variety of benchmark problems.
Another important property of this exponential discretization is that it preserves the \emph{multiplicative} group structure of the set
$\interior L^\infty_+(\Omega) = \{ w \in L^\infty(\Omega) \mid \essinf w > 0\}$.
More specifically,
\begin{equation}
	\exp \psi_h \exp \varphi_h = \exp(\psi_h + \varphi_h)
	\in
	\exp(W_h)
	\subset
	\interior L^\infty_+(\Omega)
	\,,
\end{equation}
for all $\psi_h$ and $\varphi_h\in W_h$.
Before expanding further on this and other topics, we present a comprehensive review of the literature and an itemized list of contributions.


\section{Contributions and related work} \label{sec:literature_review}

The latent variable proximal Galerkin finite element method is as much a finite element method as it is an optimization algorithm.
With this is mind, it is important to distinguish proximal Galerkin from the extensive collection of other numerical methods for bound-constrained variational problems.
In turn, we choose to survey the optimization literature as well as the numerical PDE literature.
The main contributions of this work are highlighted and itemized in~\Cref{sub:contributions}.

\subsection{Optimization methods for pointwise bound constraints} \label{sub:bound_constrained_optimization}

Bound-\linebreak{}constrained variational problems arise in many subjects. These include, but are not limited to, contact mechanics  \cite{kikuchi1988contact,Wriggers2006}, financial mathematics \cite[Chap. 12]{tankov2015financial}, mathematical image processing \cite{LAmbrosio_VMTortorelli_1990}, and the geosciences, such as glaciology \cite{Zwinger2009}.
It is here that we are often confronted with the requirement that the solution be pointwise bounded from above or below by some critical threshold over at least a portion of the physical domain or its boundary. In PDE-constrained optimization and optimal control, bounds on the solution of the PDE, i.e., state constraints, naturally arise as a modeling requirement, see the well-known monographs \cite{Troltzsch_book2010,MHinze_RPinnau_MUlbrich_SUlbrich_2009}  and the references therein, especially \cite{ECasas_1986,ECasas_1993,ECasas_1997}. Consequently, a great deal of effort has been spent on treating bound constraints in infinite dimensions. 

We mainly restrict our overview to the numerical solution of the obstacle problem \cref{eq:DirichletVI}, with $K \subset \{v \in H^1(\Omega) \mid v \geq \phi\}$ for some $\phi \in H^1(\Omega)\cap L^\infty(\Omega)$, since the available solvers capture the main essences of the common techniques for other bound-constrained problems, however, we note that a number of the optimization algorithms listed below are applicable far beyond this setting.
Perhaps the most direct approach begins by prescribing a finite-dimensional subspace of $H^1(\Omega)$ for the discrete solution and then solving the associated variational problem by methods of nonlinear programming.
In this ``first-discretize-then-optimize'' class of approaches, the finite-dimensional reformulation typically amounts to a strongly convex quadratic program or a discrete strongly monotone variational inequality.
The fact that higher-order basis functions face numerous challenges when used to enforce pointwise bound constraints limits the benefits of these approaches; for further discussion, see~\Cref{sub:bound_constrained_finite_element_methods}.
However, a wealth of viable algorithms from nonlinear programming can be applied to lowest-order discretizations; see, e.g., \cite{Bertsekas99,nocedal1999numerical}.
Nevertheless, at least for active set-based approaches, such as in \cite{Hintermller2002}, one will almost certainly observe \emph{mesh-dependence}.

Mesh-dependence means that the number of nonlinear solver iterations required to reach a prescribed stopping tolerance (using the appropriate function space norm) will grow without bound on successively finer meshes.
Nevertheless, mesh-dependence can be computationally mitigated 
by appealing to multigrid methods, as was done in the celebrated papers 
\cite{Brandt1983,Hackbusch1983,RHWHoppe_1987,Hoppe1990,Hoppe_1994,Kornhuber_1994,Kornhuber_1996,Kornhuber_2001,BIWohlmuth_RHKrause_2003}; see \cite{CGraeser_RKornhuber_2009} for a comprehensive review. Despite the favorable behavior of these multigrid methods, there is no proof of mesh-independence in general. In particular, there is no guarantee that a given sequence of meshes will not miss low-dimensional portions (sets of positive capacity \cite{kinderlehrer2000introduction}) of the active set.

Mesh-dependence in active set methods arises from a lack of generalized differentiability in the function space setting, cf.~\cite{Hintermller2002,Ulbrich_2002}. This has motivated researchers to propose and analyze algorithms for bound-constrained problems in the continuous, i.e., infinite-dimensional setting. If an algorithm can be shown to converge in the continuous setting and the problem of interest exhibits sufficient stability properties around its solution, then this convergence will carry over to perturbed problems. At least for conforming discretizations, the associated finite-dimensional problem can be viewed as such a perturbation provided the discretization is sufficiently fine.
For further material on this topic, we refer the reader to the detailed discussions and references to applications in \cite{weiser2005asymptotic} and the pioneering works \cite{McCormick_1978,Allgower_1986,Allgower_1987}. 

Infinite-dimensional algorithms follow their finite-dimensional counterparts and can be roughly split into several categories: penalty methods, barrier methods, augmented Lagrangian methods, and first-order methods of convex optimization. For penalty (approximation) methods, we point the interested reader to the well-known monograph \cite{Glowinski_1984}, which claims these techniques go back to \cite{JLLions_1968,JLLions_1969}. However, we note that the numerical methods in \cite{Glowinski_1984}, e.g., coordinate descent, are not seen to be competitive with more recent developments in the subsequent decades after its publication.

Quadratic penalty methods are used widely in PDE-constrained optimization, see, e.g.,~\cite{hintermuller2006feasible,hintermuller2006path,Hinterm_ller_2009} and readily extendible to numerous applications; see, e.g., \cite{Kunisch_2012,Keuthen_2014,Adam_2018}. These are often referred to as ``Moreau--Yosida''-based approaches because the quadratic penalty can be viewed as the Moreau envelope of the indicator function for the bound constraints. The downside of these methods is the requirement to drive the penalty parameter to infinity to restore feasibility. Mirroring their finite-dimensional equivalents, interior point methods have also been investigated in detail for certain classes of PDE-constrained problems, see, e.g., \cite{Schiela2006,Ulbrich2007,Wollner2008,Hinze2009,Schiela2011}. Our method is closer to interior point methods, due to the entropy term \cite{sturmfels2022toric,pavlov2022gibbs}, and somewhat related to the first-order methods in \cite{Tran2015,Zosso2017}. However, in contrast to traditional interior point methods, the entropy functions employed in the text below do not exclude points from the feasible sets as they are still well-defined for feasible solutions that exhibit contact on sets of positive measure (or capacity).
Recently, entropy regularization has become a popular technique to promote exploration in reinforcement learning \cite{ahmed2019understanding,li2021quasi,landajuela2021improving}.
The same technique is also used in semidefinite programming \cite{lindsey2023fast} and optimal transport \cite{cuturi2013sinkhorn}.
An early comparison of infinite-dimensional interior point versus quadratic penalty approaches can be found in \cite{Bergounioux2000}. We also point to more recent work \cite{Tran2015,Zosso2017} on new penalty methods that appear to be mesh-dependent. Finally, though not expressly developed for bound-constrained problems in infinite-dimensional spaces, proximal point methods will play a central role in our method. This is discussed in detail in \Cref{sub:proximal_point} below.

Augmented Lagrangian approaches have also been developed for variational inequalities and PDE-constrained optimization; see, e.g., early work in \cite{Ito1990,Ito1990a,bergounioux1993augmented,Bergounioux1997} along with the monographs \cite{Glowinski_1984,KIto_KKunisch_2008,Wriggers2006,kikuchi1988contact} and the many references therein. Recent work has extended these methods to more general problems in abstract Banach spaces while simultaneously exploiting advances in matrix-free, inexact subproblem solvers in constrained optimization (such as \cite{heinkenschloss2014matrix,kouri2018inexact}), see \cite{birgin2014practical,kanzow2018augmented,Antil2023}.  In finite dimensions, augmented Lagrangian approaches are generally superior to penalty-based methods in the sense that the penalty parameter does not need to be driven to infinity to guarantee feasibility. Moreover, the penalty function in the subproblems is adaptively updated by the dual variables at each iteration. However, as observed in \cite[Sec.~5]{Antil2023}, the situation is more delicate in infinite dimensions, e.g., it may be necessary that some of the penalty parameters need to pass to infinity to guarantee the generation of a sequence of iterates with feasible accumulation points and the dual variables may not be bounded in those function spaces which are more easily treated numerically.




\subsection{Numerical methods for pointwise bound constraints} \label{sub:bound_constrained_finite_element_methods}

The development of bound-preserving numerical methods for PDEs began in the early days of scientific computing \cite{lax1954weak,godunov1959finite} and has remained an important pursuit ever since.
Although the present paper focuses on an entirely different category of PDE problems, hyperbolic conservation laws have provided a major source of motivation for research on the topic \cite{crandall1980monotone,harten1983upstream}, and have inspired many bound-preserving techniques now applied to other classes of PDEs.
In many situations, the challenge lies in the fact that standard high-order numerical methods do not preserve key invariant domain properties of the underlying physics \cite{guermond2016invariant}, such as pointwise positivity \cite{sun2018discontinuous}, yet, such properties are often required for numerical stability \cite{wu2021geometric}.






Some of the earliest attempts to ensure bound constraints involved using artificial viscosity to dampen oscillations that would lead to negativity and other spurious solution features \cite{vonneumann1950method,lax1960systems}.
Later on, more sophisticated ``high resolution'' flux- and slope-limiting strategies emerged \cite{boris1973flux,van1979towards,harten1983high,sweby1984high}; see also \cite{leveque1992numerical} for a classical overview and further references.

One of the most popular approaches to designing high-order bound-preserving methods is flux-corrected transport \cite{boris1973flux,zalesak1979fully,kuzmin2001positive,kuzmin2012flux}.
The general idea relies on forming a convex combination of a desired high-order solution and a bound-preserving low-order solution.
The method then selects the high-order solution wherever the constraint is satisfied and locally transitions to the low-order solution wherever it is necessary to avoid constraint violations.
A more recent popular approach \cite{zhang2010positivity,zhang2010maximum,zhang2011maximum}, which can be traced back to \cite{perthame1996positivity}, relies on developing high-order schemes with positive cell averages.
If such a high-order scheme can be found, the local solution need only be rescaled towards its (positive) mean wherever the constraints are violated.

The majority of high-order bound-preserving numerical methods for PDEs, including the two methods just described for hyperbolic conservation laws, do not constrain the solution to the continuous-level feasible set.
This is due, in part, to the fact that checking pointwise bound violations with an arbitrary polynomial is prohibitively expensive \cite{lasserre2007sum}.
Instead, almost all modern methods involve one of two common strategies: (1) enlarging the feasible set by only constraining the values of the solution at quadrature or nodal points \cite{zhang2010positivity,sun2018discontinuous,lin2023positivity,dzanic2022positivity,barrenechea2023nodally} or (2) diminishing the feasible set by constraining the solution's basis function coefficients \cite{abgrall2010example,anderson2017high,lohmann2017flux,abgrall2022reinterpretation}.
The former strategy results in a relaxation of the underlying problem that allows for solutions that are not truly positive \emph{pointwise}.
The latter strategy typically involves discretizing the solution with a positive basis that guarantees, e.g., that the solution is non-negative \emph{if} its coefficient are non-negative; see \cite{sukumar2004construction,ortiz2010maximum,ainsworth2011bernstein,cottrell2009isogeometric,allen2022bounds,dahlke2022wavelet} for the properties of various choices.
If a high-order discretization is used, both strategies lead to basis-dependent solutions, instead of solely approximation space-dependent solutions.

Since limiters tend to have a minimal number of hyperparameters, enforcing bound constraints using many of the techniques above may, at most, reduce to only solving a single-variable optimization problem at each element.
Recently, however, optimization-based methods have been explored to enlarge the solution space \cite{yee2020quadratic,bochev2020optimization}.
In these methods, a nonlinear program is solved at each element.
Likewise, global optimization approaches have also been explored, but, possibly owing to the cost, we are only aware of investigations with simple model problems \cite{liska2008enforcing,evans2009enforcement}.

Finally, logarithm-transformation methods, which date back at least to \cite{ilinca1996methodes}, have been known in the literature for some time \cite{ilinca1998unified,Carrillo2001Posit-6428,luo2003computation}.
Yet, they have taken on new interest in recent years \cite{metti2016energetically,liu2020exponential,fu2022high,vijaywargiya2023two,dzanic2023bounds}.
Other earlier work of related interest include \cite{degroen1979error,brezzi1989two,minor1993exponential,lazghab2002adaptive,fattal2004constitutive}.
The appeal is that discretizing a transformed variable may deliver an approximation that is intrinsically structure-preserving and basis-independent because it encodes geometry of the feasible set.
However, as we have already described in detail in \Cref{sub:the_cole_hopf_transform_and_the_semiring_of_non_negative_functions}, naively transforming a PDE variable leads to theoretical concerns when the solution is permitted to reach the boundary of the feasible set.
Therefore, implementing these methods in practice can be challenging, and may require ad-hoc assembly rules for the degenerate PDEs that arise, as noted in \cite{vijaywargiya2023two}.












































\subsection{Contributions of the present work} \label{sub:contributions}


This paper focuses on establishing a mathematical foundation for the proximal Galerkin finite element method and exploring some of its applications.
The main technical results are developed specifically for the obstacle problem.
Yet, \Cref{sec:maximum_principles,sec:new_algorithms_for_topology_optimization} provide further sample applications and suggestions for future work.
In order to distinguish our work from previous and parallel efforts described in the literature above, we itemize our primary contributions:
\begin{itemize}[leftmargin=0cm,itemindent=1cm,itemsep=3pt,topsep=3pt]
	\item
		We introduce a new numerical method to treat infinite-dimensional bound-constrained variational inequality problems.
	The method hinges on an adaptive entropy regularization technique that was introduced by Nemirovsky and Yudin in \cite{nemirovskij1983problem} for general \emph{reflexive} Banach spaces, but has been primarily explored as an efficient optimization algorithm for finite-dimensional problems \cite{teboulle2018simplified}.
	Moreover, the nature of the functionals involved in our approach indicate that we need to work in a non-standard, \emph{non-reflexive} setting that is nevertheless natural for entropy regularization in infinite dimensions.
		\item
		The adaptive entropy regularization technique explored in this paper indicates the potential for a broad methodology in which the nonlinearity arising from the variational derivative of the entropy term can be replaced by a slack variable --- which we call the ``latent'' variable --- that is isomorphic to the regularized primal variable. This ultimately delivers a greater degree of flexibility in the choice of discretization scheme as the isomorphism naturally facilitates structure-preserving discretizations. We coin this framework the latent variable proximal point (LVPP) methodology.
	\item
	We apply the entropy regularization technique to the obstacle problem, and in doing so derive (distributional forms of) the \emph{entropic Poisson equation},
	\begin{equation}\label{eq:entrop-poisson}
		-\Delta u + \ln u = f
		\,,
			\end{equation}
	and the \emph{binary-entropic Poisson equation},
	\begin{equation}
				-\Delta u + \atanh u = f
				\,.
	\end{equation}
	In the context of optimization, these appear to be novel semilinear elliptic PDEs. Though a similar equation to \cref{eq:entrop-poisson} has been investigated in \cite{MMontenegro_OSantanadeQueiroz_2009} and the nonlinearities are, at least when restricted to their \textit{domains}, smooth and monotone, the Nemytskii operators induced by $\ln$ and $\atanh$ require special care as they have \textit{restricted} domains when defined from the original real-valued functions; cf.~\cite{ambrosetti1995primer} and related literature.
		\item
	Motivated by the analysis of the entropic Poisson equation, we establish a non-trivial geometric connection between non-negativity-constrained optimization and group theory.
	Further geometric connections are established via entropy functionals for other bound constraints.
	\item
	We present a novel finite element method to solve the entropic Poisson equation and perform preliminary \textit{a priori} error analysis on the resulting nonlinear mixed method.
	Our numerical experiments indicate that the method is mesh-independent when comparing the number of iterates required to reach a certain solution tolerance; see, e.g.,~\Cref{sub:obstacle_numerical_experiments}.
	\item
	We extend the contributions above to arrive at a novel approach to enforce discrete maximum principles on non-symmetric elliptic PDE, e.g., the advection-diffusion equation (to appear in \Cref{sec:maximum_principles}).
	\item
	We present a new algorithm for topology optimization to showcase the breadth of applicability of geometric optimization techniques developed in this work.
	The algorithm is relatively simple to implement and our results indicate that it is robust, high-order, and mesh-independent.
	\item
	We release our code \cite{Keith2023ObstacleCode,Keith2023TopOptCode,ZenodoCode}, implemented in part using the finite element software FEniCSx in Python and, otherwise, with the MFEM library in C++ \cite{anderson2021mfem}, to facilitate broader adoption in the community.
\end{itemize}










\section{The obstacle problem} \label{sec:the_obstacle_problem}

In \Cref{sec:structure}, we surveyed several structural properties that entropy regularization brings to a specific form of the obstacle problem,
\begin{equation}
\label{eq:ObstacleProblem}
	\min_{u\in H^1_g(\Omega)}
	~
	\frac{1}{2}
	\int_\Omega |\nabla u|^2 \dd x
	-
	\int_\Omega f u \dd x
	~~\text{subject to~}
		u \geq \phi
	~\text{in~}\Omega
	,
\end{equation}
where $\phi = 0$.
In this section, we return to the same motivating example to review these properties in greater detail and extend our conclusions in order to analyze nonzero obstacle functions $\phi \neq 0$.
The main theoretical results in this section are the representation theorem, \Cref{lem:EntropyDifferentiability}, the characterization theorem, \Cref{thm:PrimalProblem}, and the convergence theorem, \Cref{thm:ConvergenceContinuousLevel}.
The section closes with a complete proximal Galerkin algorithm to solve the obstacle problem (\Cref{alg:Obstacle_Newton}) and a report of our numerical experiments with it (\Cref{sub:obstacle_numerical_experiments}).

\subsection{The entropy gradient} \label{sub:entropy_regularity}

Before we can properly investigate entropy regularization and its role in treating the obstacle problem~\cref{eq:ObstacleProblem}, we must closely analyze the regularity of the entropy functional~\cref{eq:EntropyFunctional} in Lebesgue spaces.
Doing so will guide us toward the key geometric structure encoded in this functional.
As a pedagogical instrument, we proceed by building an analogy to the finite-dimensional setting.


Let $x\in \mathbb{R}^N$ denote the $N$-dimensional vector $(x_1,\ldots, x_N)$ and
denote the nonnegative orthant in $\mathbb R^N$ by
\begin{equation}
	\mathbb{R}^N_{+}
			= \{ (x_1,\ldots,x_N) \in \mathbb{R}^N \mid x_i \ge 0 \text{~for all~} i=1,\ldots N\}
	\,.
\end{equation}
Now, consider the corresponding finite-dimensional entropy function 
$s:\mathbb R^N_+ \to \mathbb R$ defined by $s(x) = \sum_{i=1}^N x_i\ln x_i - x_i$, wherein we remind the reader of our simplying convention $0 \ln 0 := 0$.
It is easy to see that $s(x)$ is continuous and strictly convex on $\mathbb R^N_+$,
but only differentiable on its interior,
\begin{equation}
	\interior \mathbb{R}^N_{+} = \{ (x_1,\ldots,x_N) \in \mathbb{R}^N \mid x_i > 0 \text{~for all~} i=1,\ldots N\}
	\,,
\end{equation}
due to the logarithmic singularity in the gradient $\nabla s(x) = (\ln x_1, \ldots, \ln x_N)$.
A careful analysis is required to determine what the effect of the same type of logarithmic singularity will be at the function space level when analyzing the entropy functional $S$ in~\cref{eq:EntropyFunctional}.

As our first key structural result shows, $L^\infty_+(\Omega)$ and $\interior L^\infty_+(\Omega)$ reflect the roles played above in finite-dimensions by $\mathbb{R}^N_{+}$ and $\interior \mathbb{R}^N_{+}$, respectively. The proof is deferred to the outset of \Cref{sub:regularity_of_H}. 

\begin{theorem}[Gradient representation]
\label{lem:EntropyDifferentiability}
Let  $S: L^{p}(\Omega) \to  \mathbb R \cup \left\{+\infty\right\}$, $p \in [1,\infty]$, be the negative entropy functional defined by 
	 \[
	 S(u) = \left\{
	 		\begin{array}{cc}
	 		\int_\Omega u\ln u- u \dd x,& \text{ if $u \in L^p_+(\Omega)$,}\\
			 +\infty,& \text{otherwise.}
			 \end{array}\right.
	\]
	\begin{enumerate}[leftmargin=0.75cm,itemindent=0cm,itemsep=3pt]
	\item\label{item:EntropyDifferentiability_Part_1}
	If $p \in [1,\infty]$, then $S$ is strictly convex and lower semicontinuous. 
	\item\label{item:EntropyDifferentiability_Part_2}
	If $p \in (1,\infty]$, then $S$ is continuous on $L^p_+(\Omega)$.
	\item\label{item:EntropyDifferentiability_Part_3}
	If $p = \infty$, then $S$ is continuously
	Fr\'echet differentiable on $\interior L^p_+(\Omega)$
	with respect to the $L^p(\Omega)$-norm topology.
	In particular, the $L^\infty(\Omega)$-Fr\'echet derivative of $S$ can be uniquely characterized by the variational equation
	\begin{equation}
	\label{eq:EntropyDifferentiability_variations}
		\langle {S}^\prime(u), v\rangle = \int_\Omega v \ln u \dd x
						~~
		\text{for all~}
		u \in \interior L^\infty_+(\Omega)
		\text{~and~}
		v \in L^\infty(\Omega)
		.
	\end{equation}
	Moreover, $\|{S}^\prime(u)\|_{(L^\infty(\Omega))^\prime} = \|\nabla {S}(u)\|_{L^1(\Omega)}$, where
	\begin{equation}
	\label{eq:EntropyDifferentiability_gradient}
		\nabla {S}(u) = \ln u
		\in L^\infty(\Omega)
			\end{equation}
	is the unique primal representation (i.e., gradient) of 
	$S'(u)$ and is uniquely
		determined by the variational equation
	\begin{equation}
	\label{eq:EntropyDifferentiability_primal}
		( \nabla {S}(u), v) = \langle {S}^\prime(u), v\rangle
		~~
		\text{for all~}
		u\in \interior L^\infty_+(\Omega)
		\text{~and~} v \in L^1(\Omega)
		.
	\end{equation}
	\end{enumerate}
\end{theorem}

At a first glance, it is tempting to define $S$ from $L^1(\Omega)$ into $\mathbb R \cup \left\{+\infty\right\}$. 
This is the perspective taken in much of the literature on infinite-dimensional convex analysis; see, in particular, \cite{borwein1994strong,bauschke2001essential}. 
In this setting, it is shown that we have strict convexity and lower semicontinuity. However, as noted in \cite[Remark 5.7]{bauschke2001essential}, there
are some issues with this viewpoint. For example, $S$ would be nowhere continuous, but it would admit subgradients of the form $\ln u$ whenever $u \in \interior L^{\infty}_+(\Omega)$. 

As claimed above, and proven in \Cref{sub:regularity_of_H}, we see that $S : L^p(\Omega) \to \mathbb R \cup \left\{+\infty\right\}$ is in fact continuous on $L^p_+(\Omega)$ provided $p > 1$ and even continuously Fr\'echet differentiable when we take $p = \infty$ and $u \in \interior L^{\infty}_+(\Omega)$. Moreover, the derivative $S'(u)$ admits a ``primal'' representation of the form $\ln u$, which connects back to the convex analysis literature.  Our proof techniques, however, are not based on duality arguments or the properties of subgradients.  

Since $S$ will be used to define a Bregman distance below, whose domain needs to fit together with the typical regularity spaces for partial differential operators, we can safely choose any $p \in [1,\infty]$ so that the regularity space is continuously embedded into $L^p(\Omega)$, even if this initially appears to rule out certain functions in the domain of $S$. For example, if we are working with $u \in H^1(\Omega)$, then we can select $p \in [1,2]$, regardless of the dimension of $\Omega$ or regularity of $\partial \Omega$. On the other hand, if the dimension of $\Omega$ is $n=2$ or higher, then $H^1(\Omega)$ does not continuously embed into $L^{\infty}(\Omega)$. 

Finally, the properties of $S$ given in \Cref{lem:EntropyDifferentiability} indicate that $S : L^{\infty}_+(\Omega)\to\mathbb R$ is part of an important class of \emph{essentially smooth} functions introduced by Rockafellar \cite[Section~26]{rockafellar1970convex} (in finite dimensions) known as \emph{Legendre functions}, which are extended to infinite dimensions in \cite{borwein1994strong,bauschke2001essential}. 
As discussed in, e.g., \cite[Section~2.3]{teboulle2018simplified}, Legendre functions play a crucial role in proximal algorithms for finite-dimensional convex optimization.

To prepare us for non-trivial obstacles $\phi \neq 0$, we have the following corollary to \Cref{lem:EntropyDifferentiability} pertaining to the shifted entropy functional $S_{\phi}(u) = S(u - \phi)$.
As with \Cref{lem:EntropyDifferentiability}, the proof of this result is deferred to~\Cref{sub:regularity_of_H}.
       
\begin{corollary}\label{cor:shift-ent}
	Let $\phi \in L^\infty(\Omega)$.
	The shifted negative entropy functional $S_{\phi}(u)$
	is strictly convex on
	\begin{equation}\label{eq:closure_inhom}
		L^{\infty}_{\phi,+}(\Omega)
		=
		\{ w \in L^\infty(\Omega) \mid w \geq \phi \}
		\,.
	\end{equation}
	and Fr\'echet differentiable on
	\begin{equation}
		\interior L^{\infty}_{\phi,+}(\Omega)
		=
		\{w \in L^{\infty}_{\phi,+}(\Omega) \mid \essinf (w-\phi) > 0 \}
	\end{equation}
	with respect to the norm topology on $L^{\infty}(\Omega)$.
	The Fr\'echet derivative of $S_{\phi}$ can be uniquely characterized by the variational equation
	\begin{equation}
	\label{eq:EntropyDifferentiability_variations_inhom}
		\langle S^\prime_{\phi}(u), v\rangle = \int_\Omega v \ln (u-\phi) \dd x
		~~
		\text{for all~}
		u\in \interior L^\infty_{\phi,+}(\Omega)
		\text{~and~} v \in L^\infty(\Omega)
		.
	\end{equation}
	Moreover, $\|S^\prime_{\phi}(u)\|_{(L^\infty(\Omega))^\prime} = \|\nabla {S}_{\phi}(u)\|_{L^1(\Omega)}$, where
	\begin{equation}
	\label{eq:EntropyDifferentiability_gradient_inhom}
		\nabla {S}_{\phi}(u) = \ln(u-\phi)
		\in L^\infty(\Omega)
		\,,
	\end{equation}
	is the unique primal representation (i.e., gradient) of $S^\prime_{\phi}\colon \interior L^\infty_{\phi,+}(\Omega) \to (L^\infty(\Omega))^\prime$ in $L^\infty(\Omega)$, determined by the variational equation
	\begin{equation}
	\label{eq:EntropyDifferentiability_primal_inho}
		( \nabla {S}_{\phi}(u), v) = \langle {S}^\prime_{\phi}(u), v\rangle
		\quad
		\text{for all~}
		u\in \interior L^\infty_{\phi,+}(\Omega)
		\text{~and~} v \in L^1(\Omega)
		.
	\end{equation}
\end{corollary}

\begin{remark}[Empty interior in the $H^1(\Omega)$ topology]
\label{rem:H1InteriorNonnegativeFunctions}
We recall that if $K = \{ u \in H^1_g(\Omega) \mid u \geq 0 \}  = H^1_g(\Omega) \cap H^1_+(\Omega)$ and $\Omega \subset \mathbb R^n$ with $n > 1$, then $\interior K = \emptyset$.
This is a simple consequence of the fact that $H^1(\Omega)$ contains unbounded functions, and so we can get arbitrarily close to any $u \in K$ in the $H^1$-norm with points outside $K$.
\end{remark}

\begin{remark}[No Riesz representation theorem]
When inspecting \Cref{lem:EntropyDifferentiability} and \Cref{cor:shift-ent}, the reader should note that $L^p(\Omega)$ is a Banach algebra only in the case $p=\infty$ and we only prove that $u\mapsto S_{\phi}(u)$ is Fr\'echet differentiable with respect to variations in this set; see~\cref{eq:EntropyDifferentiability_variations_inhom}.
In fact, there is a key step in our proof of \Cref{lem:EntropyDifferentiability} that requires all functions $u$ where the functional $S(u)$ is differentiable to have a multiplicative inverse $1/u \in L^\infty(\Omega)$; see \cref{eq:EntropyDifferentiability_critical}.
Based in part on this requirement, we continue to work directly with $L^\infty(\Omega)$, which is a \emph{non-reflexive} Banach space \emph{without} a corresponding Riesz representation theorem \cite{adams2003sobolev}.
It is, therefore, not a trivial consequence of differentiability that the Fr\'echet derivative $S^\prime_{\phi}(u) \in (L^\infty(\Omega))^\prime$ has the unique function space representation $\nabla {S}_{\phi}(u) \in L^\infty(\Omega)$ given by~\cref{eq:EntropyDifferentiability_primal_inho}.
In fact, the derivative of general functionals on $L^\infty(\Omega)$ lie in $(L^\infty(\Omega))^\prime$, which is the space of absolutely continuous, finitely additive set functions of bounded total variation on $\Omega$; cf.~\cite[p.~118]{yosida2012functional}.
Throughout this work, we consciously choose to refer to $\nabla S_{\phi}\colon \interior L^\infty_{\phi,+}(\Omega) \to L^\infty(\Omega)$ as the \emph{gradient} of the (shifted) entropy functional, even though we are well aware that the term ``gradient'' is typically understood as a Hilbert space concept. 
\end{remark}


\subsection{The entropy gradient is an isomorphism} \label{sub:entropy_and_its_geometry}

Let us return to the finite-dimensional entropy function $s(x) = \sum_{i=1}^N x_i\ln x_i - x_i$ introduced at the beginning of the previous subsection and focus on its properties in the strictly positive orthant $\interior \mathbb{R}^N_+ \subset \mathbb{R}^N$.
In this case, the reader should note that $x \mapsto \nabla s(x) = (\ln x_1, \ldots, \ln x_N)$, is a bijection between the set of component-wise positive vectors $x \in \mathbb{R}^N_+$ and the entire vector space $\mathbb{R}^N$.

This correspondence has a special algebraic significance if we view $\mathbb{R}^N_+$ as a Lie group under the operation of componentwise multiplication,
\begin{equation}
	x \otimes y = (x_1 y_1,\ldots,x_N y_N),
\end{equation}
and view $\mathbb{R}^N$ as its associated Lie algebra under addition; cf.~\cite[Example~7.4~(b)]{lee2012introduction}.
Indeed, the smooth map $\nabla s\colon \interior \mathbb{R}^N_+ \to \mathbb{R}^N$ given above is a Lie group isomorphism because
\begin{equation}
	\nabla s(x) + \nabla s(y) = (\ln x_1 + \ln y_1, \ldots, \ln x_N + \ln y_N)
	=
	\nabla s(x \otimes y)
	.
\end{equation}
It is trivial to see that the same structure is replicated at the infinite-dimensional level between the Banach--Lie algebra $L^\infty(\Omega)$ and its Banach--Lie group $\interior L^\infty_+(\Omega)$ since
\begin{equation}
	\nabla S(u) + \nabla S(v) = \ln u + \ln v = \nabla S(uv).
\end{equation}

A deeper geometric meaning to this correspondence is revealed if we draw upon the well-known result in differential geometry that all finite-dimensional Lie groups are associated to their Lie algebra by an exponential map \cite[Proposition~20.8]{lee2012introduction}.
In the case of the Lie group $\interior \mathbb{R}^N_+$, it may be checked that the inverse of $\nabla s$, defined $(\nabla s)^{-1}(x) = (\exp x_1, \ldots, \exp x_N)$, is precisely this map.
Conveniently, the finite-dimensional result extends to the Banach-Lie group $\interior L^\infty_+(\Omega)$ \cite{glockner2002algebras,glockner2003lie}, and we are left with a similar geometric interpretation (cf.~\cref{fig:ExponentialMap}) of the isomorphism induced by the gradient of the entropy functional $\nabla S\colon \interior L^\infty_+(\Omega) \to L^\infty(\Omega)$ and its inverse,
\begin{equation}
\label{eq:InverseOfTheEntropyGradient}
	(\nabla S)^{-1}(u) = \exp u
	.
\end{equation}
Moreover, it can be shown that restricting the exponential map~\cref{eq:InverseOfTheEntropyGradient} to the subalgebra $H^1(\Omega)\cap L^\infty(\Omega)$ induces an isomorphism with the subgroup $H^1(\Omega) \cap \interior L^\infty_+(\Omega)$.
For further details, see \Cref{prop:Equivalence,prop:logexpChainRule}.


% Figure environment removed

\begin{remark}[Exploiting the geometry of the feasible set]
From the optimization point-of-view, there is great value in the isomorphism $\nabla S$ residing in the fact that $L^\infty(\Omega)$ is a Banach space and Banach spaces are natural spaces in which to construct additive update formulas (they are complete, normed, and closed under addition).
Many competitive algorithms for \emph{unconstrained} optimization problems, such as gradient descent and Newton methods, are additive update formulas that leverage this linear structure in some way \cite{nocedal1999numerical}.
Likewise, when dealing with constrained optimization problems, most algorithms appeal to the linear structure of the ambient space containing the feasible set.
In \Cref{sub:proximal_point}, we will show how the isomorphism $\nabla S\colon \interior L^\infty_+(\Omega) \to L^\infty(\Omega)$ allows us to ignore the ambient space the original problem is posed in and work instead with the intrinsic geometry of the constraint set.
This, in turn, will allow us to treat constrained optimization problems in Sobolev spaces with methods originally designed only for the unconstrained setting.
\end{remark}


\subsection{Relative entropy} \label{sub:relative_entropy}

Entropy not only delivers an isomorphism between the Banach--Lie group $\interior L^\infty_+(\Omega)$ and its Banach algebra $L^\infty(\Omega)$.
It also induces a valuable distance function called the \emph{relative entropy} or \emph{(extended) Kullback--Leibler divergence}.

We assume below that $V$ is a Banach space.
For any smooth convex function $G\colon V \to \mathbb{R}$, its Bregman divergence is defined by the formula
\begin{equation}\label{eq:bregman-trad}
	D_G(u,v) = G(u) - G(v) - \langle G^\prime(v), u - v \rangle
	\,.
\end{equation}
Encoded in this definition is the important observation that, because $G$ is convex, the graph $\{(u,G(u)) \mid u \in V\}$ will always lie on or above its supporting hyperplanes, $\{ (u,G(v) + \langle G^\prime(v), u - v \rangle) \mid u \in V \}$, for every $v\in V$ at which $G^\prime(v)$ exists, see \cite{LMBregman_1967} for this and related insights.
The Bregman divergence $D_G\colon \dom G \times\dom G^\prime \to \mathbb{R}$ measures the vertical distance between these two sets. For nonsmooth convex functionals that are merely subdifferentiable, the definition of subgradients $g^\prime \in \partial G(u)$ implies $G(v) \ge G(u) + \langle g^\prime,v - u\rangle$ for all $ v$ in $\dom G$. Therefore, Bregman divergences can be defined for nonsmooth functionals using subgradients instead of derivatives, with the caveat that there may be uncountably many $g^\prime$ that describe a supporting hyperplane at points of nonsmoothness; cf.~\cite{yin2008bregman}.

Loosely speaking, a Bregman divergence is a generalization of the squared distance between two points in a Hilbert space, and is, therefore, not expected to satisfy a triangle inequality.
To see how this interpretation arises, it is a straightforward exercise to check, e.g., that if $G\colon H^1_0(\Omega) \to \mathbb{R}$, with $G(u) = \frac{1}{2}\|\nabla u\|_{L^2(\Omega)}^2$, the associated Bregman divergence is
\begin{equation}
	\begin{aligned}
		D_G(u,v)
				&=
		\frac{1}{2}\|\nabla u\|_{L^2(\Omega)}^2 - \frac{1}{2}\|\nabla v\|_{L^2(\Omega)}^2 - (\nabla v, \nabla u-\nabla v)
				\\
		&=
		\frac{1}{2}\|\nabla u-\nabla v\|_{L^2(\Omega)}^2
		\,.
	\end{aligned}
\end{equation}

The relative entropy $D \colon L^p_+(\Omega) \times \interior L^\infty_+(\Omega) \to \mathbb{R}$, for $p \in [1,\infty]$, is the Bregman divergence induced by the entropy functional $S$.
Given its importance to this work, we neglect to write the subscript-$S$ when working with this measure of distance.
In turn, we may select any $u \in L^p_+(\Omega)$ and $v \in \interior L^\infty_+(\Omega)$ to explicitly derive the relative entropy as follows,
\begin{equation}
\label{eq:RelativeEntropy}
	D(u,v) = S(u) - S(v) - ( \nabla S(v), u - v )
	=
	\int_\Omega u \ln\frac{u}{v} - u  + v \dd x
	\,.
\end{equation}
An illustration of the Bregman divergence of the finite-dimensional entropy function $s(x) = \sum_{i=1}^N x_i\ln x_i - x_i$ is given in \Cref{fig:BregmanPlot} for the case $N=1$. We initially use the right-hand side of \cref{eq:RelativeEntropy} in our study below without requiring its definition as a Bregman divergence. After a careful analysis shows that the relevant solutions are in $L^{\infty}_+(\Omega)$, we then employ the usual properties of Bregman divergences where required in several convergence proofs. This frees us from the rigid structures of convex analysis, e.g., that often fix the domain $V$ in the beginning and require us to work only in this space and its given topology.
% Figure environment removed

Along with other statistical distances, the relative entropy has a rich history of being used to encode geometric structure in analysis within statistics, probability theory, and information theory \cite{amari2000methods,amari2016information,nielsen2020elementary}.
Although a Bregman divergence is not symmetric, i.e., $D_G(u,v) \neq D_G(v,u)$ in general, it will satisfy the following important properties when $G$ is strictly convex \cite{LMBregman_1967,chen1993convergence}:


\begin{proposition}
\label{prop:BregmanDivergenceProperties}

Let $G\colon V \to \mathbb{R}$ be smooth and strictly convex.
Then the following properties hold:
\medskip

\noindent\textsl{Non-negativity.}
$D_G(u,v) \geq 0$ for all $u\in \dom G$ and $v \in \dom G^\prime$.
\medskip

\noindent\textsl{Positivity.}
$D_G(u,v) = 0$ if and only if $u=v$.
\medskip

\noindent\textsl{Convexity.}
$D_G(u,v)$ is strictly convex in its first argument.
Moreover, if $G$ is strongly convex, then so is $u \mapsto D_G(u,v)$.
\medskip

\noindent\textsl{Linearity.}
Let $F\colon V \to \mathbb{R}$ be smooth and strictly convex and $\lambda \geq 0$.
Then
\begin{equation}
	D_{G+\lambda F}(u,v) = D_{G}(u,v) + \lambda D_{F}(u,v)
	\,.
\end{equation}

\noindent\textsl{ Three points identity.}
For all $u \in \dom G $ and $v,w \in \dom G^\prime$, it holds that
\begin{equation}
\label{eq:CosineIdentity}
	D_G(u,v) - D_G(u,w) + D_G(v,w)
	=
	\langle G^\prime(v) - G^\prime(w), v - u \rangle
	\,.
\end{equation}


\end{proposition}





\subsection{Proximal point} \label{sub:proximal_point}

Recall that in~\Cref{sub:dirichlet_free_energy} we proposed the regularized Dirichlet free energy functional
\begin{equation}
	A(u) = E(u) + \theta S(u)
	\,,
\end{equation}
and argued that its minimizer will converge to the solution of the obstacle problem in the limit $\theta \to 0$; cf.~\cref{eq:EPE_ConvergenceWRTTemperature}.
Although this approach to solving the non-negative obstacle problem is viable, there is a much more numerically stable alternative.
Indeed, it turns out that we can just as readily generate a sequence of positive functions $u^k \to u^\ast$  by recursively regularizing the Dirichlet energy $E(u)$ with the Bregman divergence $D(u,u^{k})$.
The idea is relatively old in finite dimensions \cite{censor1992proximal,teboulle1992entropic,chen1993convergence,teboulle2018simplified}, and well-explored in reflexive Banach spaces \cite{darbon2021efficient,darbon2021accelerated}.
However, given that the algorithm is not well-known in the finite element community, we present a classical description that begins with a Hilbert space framework.




We now introduce the so-called \emph{proximal minimization algorithm} \cite{rockafellar2009variational,parikh2014proximal,teboulle2018simplified}, due to Marinet \cite{martinet1970regularisation}.
In turn, let $H$ be a Hilbert space and $\alpha>0$ be a positive step size parameter.
The \emph{proximal operator}, introduced in \cite{moreau1965proximite} by Moreau, is defined for every proper lower semi-continuous function $F\colon H \to \mathbb{R}\cup\{\infty\}$ as follows,
\begin{equation}
\label{eq:ProximalMap}
	{\prox}_{\alpha F}(v)
	=
	\argmin_{u \in H}
	\Big\{
		F(u) + \frac{1}{2\alpha}\|u - v\|_{H}^2
	\Big\}
	.
\end{equation}
The utility of this operator lies largely in the fact that the $\|\cdot\|_H^2$-regularization term in~\cref{eq:ProximalMap} transforms $F$ (which may not be differentiable) into a finite-valued function,
\begin{equation}
	F_\alpha(v) = \min_{u \in H} \{ F(u) + \frac{1}{2\alpha}\|u - v\|_{H}^2 \}
	,
\end{equation}
with an $\alpha^{-1}$-Lipschitz continuous gradient \cite{rockafellar2009variational}.
Moreover, when $F$ is convex, minimizing either $F$ or $F_\alpha$ is equivalent in the sense that
\begin{equation}
	\inf_{u\in H} F_\alpha(u) = \inf_{u\in H} F(u)
	\,.
	\quad
\end{equation}
In fact, the set of minimizers, $\argmin_{u\in H} F(u)$, coincides with the set of fixed points $u^\ast \in H$ that satisfy $u^\ast = {\prox}_{\alpha F}(u^\ast)$; see, e.g., \cite[Prop. 12.28]{HHBauschke_PLCombettes_2011}.

Choosing to iterate this fixed point equation with variable step sizes $\alpha_k > 0$ delivers the \emph{proximal minimization algorithm} \cite{martinet1970regularisation,rockafellar1976monotone}, written explicitly as
\begin{equation}
\label{eq:ProximalUpdate}
	u^0 \in H
	,
	\quad
	u^{k+1} = \prox_{\alpha_{k+1} F}(u^k)
	,
	\quad
	k=0,1,\ldots
	\end{equation}
It is well-known (see, e.g., \cite{guler1991convergence}), that $F(u^k)$ converges to $F(u^\ast)$ at a rate inversely proportional to the sum of the step sizes.
More explicitly, it holds that
\begin{equation}
\label{eq:ConvergenceRatePPA}
	F(u^k) - F(u^\ast) \leq \frac{\|u^\ast - u^0\|^2_H}{2\sum_{\ell=1}^k\alpha_\ell}
	\,.
\end{equation}
Thus, the function values of proximal iterates~\cref{eq:ProximalUpdate} can converge ``arbitrarily'' fast (by increasing $\alpha_\ell$), and the asymptotic complexity of the iteration~\cref{eq:ProximalUpdate} is determined by the complexity of the method used to solve each subproblem~\cref{eq:ProximalMap}.
Convergence of the function values carries over to convergence of the iterates provided an estimate of the type 
\[
\sigma(\| u - v\|) \le F(u) - F(v)
\]
holds, where $\sigma$ is monotone and invertible on $\mathbb R_+$, e.g., if $F$ is strongly convex. 

The potentially arbitrary order of convergence in~\cref{eq:ConvergenceRatePPA} makes the proximal point algorithm an attractive candidate to solve many optimization problems.
The drawback, however, is that each iteration of the algorithm requires the solution of a nonsmooth optimization problem that may be just as difficult to solve as the original problem; cf.~\cref{rem:ProximalMap}.
At the same time, the proximal operator~\cref{eq:ProximalMap} and fixed point iterations~\cref{eq:ProximalUpdate} are fundamental to a broad selection of modern optimization algorithms; see e.g., \cite{HHBauschke_PLCombettes_2011,ABeck_2017,teboulle2018simplified,GLan_2020} and the many references therein. They also play a deep role in augmented Lagrangian methods, as recognized at least as early as \cite{RTRockafellar_1976}, which have seen a resurgence in interest due, in part, to their applicability for infinite dimensional problems \cite{kanzow2018augmented,Antil2023}.



It turns out many of the most important properties of the proximal minimization algorithm also hold if $\frac{1}{2}\|u-v\|_H^2$ in~\cref{eq:ProximalMap} is replaced by a Bregman divergence $D_G(u,v)$ \cite{teboulle2018simplified}.
Indeed, if we assume that $G\colon V\to \mathbb{R}$ is a strictly convex functional on a Banach space $V$, we may define the \emph{Bregman proximal operator}
\begin{equation}
\label{eq:BregmanProximalMap}
	{\prox}_{\alpha F}^G(v)
	=
	\argmin_{u \in \dom F \cap\dom G }
	\big\{
		F(u) + \alpha^{-1}D_G(u,v)
	\big\}
	,
\end{equation}
and the corresponding \emph{Bregman proximal minimization algorithm}
\begin{equation}
\label{eq:BregmanProximalUpdate}
	u^0 \in \dom F \cap\dom G^\prime
	,
	\quad
	u^{k+1} = \prox_{\alpha_{k+1} F}^G(u^k)
	,
	\quad
	k=0,1,\ldots
	\end{equation}

\Cref{fig:BregmanPlot} illustrates the execution of this algorithm for the one-dimensional energy function $e(x) = \frac{1}{2}x^2 + x$ and the relative entropy $D_s(x,y) = x\ln(x/y) - x + y$.
Note that under the definitions above, one can show that~\cref{eq:ConvergenceRatePPA} generalizes as follows \cite{chen1993convergence},
\begin{equation}
\label{eq:ConvergenceRateBPPA}
	F(u^k) - F(u^\ast)
	\leq
	\frac{D_G(u^\ast,u^0)}{\sum_{\ell=1}^k \alpha_\ell}
	\,.
\end{equation}
See also \Cref{thm:ConvergenceContinuousLevel}.















% Figure environment removed

Our contribution is to show that the proximal operator~\cref{eq:BregmanProximalMap}, with an appropriately defined Bregman divergence, transforms the solution of an infinite-dimensional constrained optimization problem into a sequence of semi-linear PDEs whose solutions converge to the solution of the underlying VI.
In the case of the positive obstacle problem (i.e., $F = E$ and $G = S$), this conclusion hinges on the following result.
When combined with~\cref{eq:BregmanProximalUpdate}, \Cref{thm:PrimalProblem} leads us directly to \Cref{alg:HomogeneousAlg}, which forms the basis for the proximal Galerkin finite element method.
We note that the proof is technical and saved until \Cref{sub:Characterization}.

\begin{theorem}[Solution characterization]
\label{thm:PrimalProblem}
	Assume $\Omega \subset \mathbb{R}^n$ is an open, bounded Lipschitz domain, $n \ge 1$.
	Let $K = \{ v \in H^1_g(\Omega) \mid v \geq 0\} = H^1_g(\Omega) \cap H^1_+(\Omega)$, where $g \in H^1(\Omega) \cap C(\overline{\Omega})$ satisfies $\min g_{|\partial \Omega} > 0$.
										Moreover, given $f \in L^\infty(\Omega)$, set
	\[
	E(v) = \frac{1}{2}\int_\Omega |\nabla v|^2 \dd x - \int_\Omega fv \dd x,
	\] 
	and for $w \in \interior L^\infty_{+}(\Omega)$
		set $D(v,w) = \int_\Omega v\ln(v/w) - v + w \dd x.$
	Then, for any
	step size $\alpha > 0$, the (relative) Dirichlet free energy minimization problem,
	\begin{equation}\label{eq:subprob_obs}
		\min_{v\in K}
		~
					 A_{\alpha}(v) :=
			E(v) + \alpha^{-1} D(v,w)
										,
	\end{equation}
	has a unique solution $u \in H^1_g(\Omega)\cap \interior L^\infty_{+}(\Omega)$ that satisfies the weak form of the entropic Poisson equation; namely,
																						\begin{equation}
	\label{eq:PrimalProblemVE}
		(\alpha\nabla u, \nabla v)
				+
		(\ln u, v)
		=
		(\alpha f, v) + (\ln w, v)
				\quad
		\text{for all~}
		v \in H^1_0(\Omega)
		\,.
	\end{equation}
																														\end{theorem}

\begin{remark}[Adaptive entropy regularization]
\label{rem:MultiplierRepresentation}
Similar to the free energy formulation~\cref{eq:DirichletFreeEnergy}, where the Lagrange multiplier $\lambda$ is approximated by $\theta \ln (1/u)$, we see that the subproblems \cref{eq:PrimalProblemVE} give rise to an approximation of the form $\alpha^{-1} \ln (w/u)$. Recalling that $\theta = \alpha^{-1}$ we see that there is fundamental difference in the two approximations given by the inclusion of the function $w$.
Chosen correctly, as with $u^k$ in~\cref{eq:BregmanProximalUpdate}, this function can act as an informative prior on the sequence of subproblems.
More specifically, $w = u^k$ allows us to view the Bregman divergence $v \mapsto D(v,u^k) = \int_\Omega v \ln(v/u^k) - v + u^k \dd x$ as a Bayesian barrier function that is updated adaptively at each iteration $k$ so that $u^k \to u^\ast$ without sending the step size $\alpha \to \infty$.
\end{remark}
















From now on, we mainly focus on inhomogeneous obstacle problems; i.e., $\phi \neq 0$.
Therefore, we close this subsection with an important corollary for this case.
Before we state the result, we note that 
\[
S_{\phi}(u) - S_{\phi}(v) - (\nabla S_{\phi}(v),u-v) = D(u - \phi,v - \phi)
\]
whenever $u \in L^{p}_{\phi,+}(\Omega)$ and $v \in \interior L^{\infty}_{\phi,+}(\Omega)$. 
Therefore, $(u,v) \mapsto D(u - \phi,v - \phi)$ is a Bregman divergence on $L^{p}_{\phi,+}(\Omega) \times \interior L^{\infty}_{\phi,+}(\Omega)$.
For technical reasons, we require the obstacles to be in a particular subset of $H^1(\Omega)$ defined by
\[
\mathcal{O} := \left\{ \varphi \in H^1(\Omega) \cap C(\overline{\Omega}) \left|\; \Delta \varphi \in L^{\infty}(\Omega) \right.\right\}.
\]
Moreover, like~\cref{thm:PrimalProblem}, the proof of \Cref{cor:PrimalProblem_inhom} is delayed until \Cref{sub:Characterization}.

\begin{corollary}
\label{cor:PrimalProblem_inhom}
	In addition to the assumptions of \Cref{thm:PrimalProblem}, let  $\phi \in \mathcal{O}$ such that
	 $\essinf \gamma(g - \phi) > 0$ on $\partial \Omega$ and define
	 \[
		K_{\phi} :=  \{ u \in H^1_g(\Omega) \mid u \geq \phi ~\text{~a.e.~in~} \Omega\}.
	\]
	Then for any step size $\alpha > 0$ and $w \in \interior L^{\infty}_{\phi,+}(\Omega)$ the optimization problem
	\begin{equation}\label{eq:subproblem_inhom}
		\min_{v\in K_{\phi}}
		~
								E(v) + \alpha^{-1} D(v-\phi,w-\phi)
										,
	\end{equation}
	has a unique solution $u \in H^1_g(\Omega)\cap \interior L^\infty_{\phi,+}(\Omega)$ that satisfies the weak form of the (generalized) entropic Poisson equation; namely,
	\begin{equation}
	\label{eq:PrimalProblemVE_inhom}
		(\alpha\nabla u, \nabla v)
				+
		(\ln (u-\phi), v)
		=
		(\alpha f, v) + (\ln (w-\phi), v)
				\quad
		\text{for all~}
		v \in H^1_0(\Omega)
		.
	\end{equation}
\end{corollary}

\begin{remark}[Delicate analysis]
Semilinear mixed variational inequalities of obstacle type have been thoroughly studied, as detailed in the famous monograph by J.-F. Rodrigues, \cite[Chap. 4.6]{rodrigues1987obstacle}. This includes regularity theory and a maximum principle that relates the solution of the VI to the obstacle, forcing term, and boundary values.  The techniques go back to the seminal work by Stampacchia \cite{stampacchia1965probleme}, Murty and Stampacchia \cite{Murthy1972} and can also be found in \cite{kinderlehrer2000introduction}. However, the VI associated with our problem is only valid if we can differentiate the ``extra'' nonlinearity in the entropy term. This in turn requires the solution $u$ of each subproblem to be essentially bounded and strictly above the obstacle, so we need to resort to a more delicate analysis solely based on the properties of the optimization problem. 
\end{remark}














\begin{remark}[Challenges of the Hilbert space setting]
\label{rem:ProximalMap}
		Let $\chi_K\colon H^1(\Omega) \to \mathbb{R}\cup\{\infty\}$ denote the indicator function $\chi_K(x) = 0$ if $x \in K$ and $\chi_K(x) = \infty$ otherwise.
	It is interesting to compare the operator
	\begin{equation}
	\label{eq:ProximalMapIdicator}
		\prox_{\alpha E + \chi_K}(v)
		=
		\argmin_{u \in {K}}
		\big\{
			E(u) + \frac{1}{2\alpha}\|u - v\|_{H^1}^2
		\big\}
		,
	\end{equation}
	to $\prox_{\alpha E}^S(v)$.
		Indeed, unlike~\cref{eq:PrimalProblemVE}, the subproblems that~\cref{eq:ProximalMapIdicator} induces each require the solution of their own VI,
	\begin{equation}
	\label{eq:L2ProxVI}
		\int_\Omega
		\nabla( (1+\alpha)u - v) \cdot \nabla w
		\dd x
		+
		\int_\Omega (u-v-\alpha f) w  \dd x
		\geq
		0
		~\fa w \in K-u,
													\end{equation}
	that is at least as difficult to solve as the original VI defining $u^\ast$; cf.~\cref{eq:DirichletVI}.
	Similar issues tend to appear whenever squared norm regularization terms are used to design proximal point algorithms for infinite-dimensional bound constraints. 
	
	Alternatively, one can use a penalty method to solve the original problem by considering instead a $C^{1,1}$-quadratic penalty term of the type 
	\[
	\frac{1}{2\alpha}\int_{\Omega} \max\{0, \phi - u\}^2 \, \dd x.
	\]
	This functional is in fact the prox-operator (in the $L^2(\Omega)$ topology) of the indicator function for the larger feasible set $\left\{u \in L^2(\Omega) \left|\; u \ge \phi \right.\right\}$. See \cite{hintermuller2006path,hintermuller2006feasible} for details including second-order algorithms and an analytical path-following scheme for $\alpha$. Note that the subproblems using a quadratic penalty would be semismooth semilinear elliptic PDEs. However, since the nonlinearity does not arise from a strictly monotone continuous function, we cannot derive a similar latent  variable formulation.
	\end{remark}




\begin{remark}[Comparison to the augmented Lagrangian method]
It is possible to view classical augmented Lagrangian methods as penalty methods that adaptively change the penalty function and associated penalty parameter via the behavior of the dual variable, i.e., Lagrange multiplier. Aside from identifying an efficient subproblem solver, the challenge is usually to find an appropriate combination of update strategies that allow for inexact subproblem solves and conservative parameter update rules that still 
exhibit rapid convergence behavior in practice. The method described in this work follows a similar strategy. Indeed, the role of the penalty function is played by a Bregman distance, which is adaptively updated via the primal variable, and the penalty parameter is given by $\alpha$. Bregman distances allow us to better exploit the geometry of the feasible set and the convergence theory of the proximal point method provides a clear connection to convergence rates that even allows for $\alpha$ to remain constant.
\end{remark}

\subsection{Latent variable proximal point} \label{sub:latent_variable_proximal_point}

An appealing feature of the entropic Poisson equation~\cref{eq:PrimalProblemVE_inhom} is that its solution permits \emph{two} additional representations; cf.~\Cref{fig:Trinity}.
In both cases, we take advantage of the entropy gradient $\nabla S(v) = \ln v$ being an isomorphism (cf.~\Cref{sub:entropy_and_its_geometry}).
First, we may introduce the latent variable representation,
\begin{equation}
	\psi = \ln (u-\phi)
	\quad
	\iff
	\quad
	u = \exp\psi + \phi
		\,,
\end{equation}
by simply applying the entropy gradient transformation to the primal solution $u$.
Second, as already noted in~\Cref{rem:MultiplierRepresentation}, we may construct a dual variable representation which, for the inhomogeneous obstacle problem, is written as follows:
\begin{equation}
\label{eq:ApproximateLagrangeMultiplierObstacleProblem}
	\lambda = \alpha^{-1}\ln\frac{w-\phi}{u - \phi}
	\quad
	\iff
	\quad
	u = (w - \phi)\exp(-\alpha\lambda) + \phi
	\,.
\end{equation}

The utility of these representations is witnessed if we consider how to solve either of the primal subproblems~\cref{eq:PrimalProblemVE} or \cref{eq:PrimalProblemVE_inhom}.
Indeed, due to the logarithmic terms, these semi-linear PDEs are only defined if $\essinf ( u - \phi) > 0$, which appears to rule out most efficient root-finding algorithms, such as Newton's method, and discretization choices, such as the Galerkin method.
Fortunately, the alternative solution representations above provide saddle-point relaxations of the entropic Poisson equation that do not suffer from these two drawbacks.




We are now ready to state the final main theoretical result, which also establishes explicit bounds on the optimization error for the latent variable proximal point (LVPP) algorithm, defined via~\cref{eq:ConvergenceContinuousLevel_VE} below.
The proof is given in~\Cref{sub:proximal_methods}.

\begin{theorem}[Convergence of LVPP]
\label{thm:ConvergenceContinuousLevel}
	Assume $\alpha_{k+1} > 0$, $k = 0,1,\ldots$, is a sequence of positive step size parameters.
	Furthermore, assume $\Omega \subset \mathbb{R}^n$ is an open, bounded Lipschitz domain, $n \ge 1$, $\phi \in \mathcal{O}$, and let $g \in H^1(\Omega) \cap C(\overline{\Omega})$ such that $\essinf \gamma(g-\phi) > 0$.
														Fix $\psi^0 \in H^1(\Omega) \cap L^\infty(\Omega)$ and consider the sequence of functions $u^k$, $\psi^k$ solving the following coupled system of variational equations:
			\begin{equation}
	\label{eq:ConvergenceContinuousLevel_VE}
		\left\{
		\begin{aligned}
			\,&\text{Find}~
			u^{k+1}\in  H^1_g(\Omega) ~\text{and}~\psi^{k+1} \in L^\infty(\Omega)
						~\text{such that~}
			\\
			&\begin{alignedat}{4}
				( \alpha_{k+1}\nabla u^{k+1}, \nabla v) + (\psi^{k+1}, v) &= (\alpha_{k+1} f + \psi^k, v)
				&&~\fa v \in H^1_0(\Omega)
				\,,
				\\
				(u^{k+1}, \varphi) - (\exp\psi^{k+1}, \varphi) &= (\phi, \varphi)
				&&~\fa \varphi \in L^2(\Omega)
				\,.
			\end{alignedat}
		\end{aligned}
		\right.
	\end{equation}
	Then the Dirichlet energy of the primal iterates is monotonically non-increasing, i.e.,
	\begin{equation}
	\label{eq:ConvergenceContinuousLevel_Monotonicity}
		E(u^{k+1}) \leq E(u^k)
		\,.
	\end{equation}
	Moreover, if $\sum_{j=1}^k \alpha_j \to \infty$ as $k \to \infty$, then the subproblem solutions $u^k$ converge in $H^1(\Omega)$ to
	\begin{equation}
		u^\ast
		=
		\argmin_{u\in H^1(\Omega)}
		~
		E(u)
		~~\text{subject to~}
		u \geq \phi
		~\text{in~}\Omega
		~\text{and~}
		u = g
		~\text{on~}\partial\Omega
		\,.
	\end{equation}
	Furthermore, the functions $\lambda^{k+1} = (\psi^k - \psi^{k+1})/\alpha_{k+1} $ converge strongly in $H^{-1}(\Omega)$ to the Lagrange multiplier $\lambda^\ast = - \Delta u^\ast - f$.
		In fact, the optimization error in both $u^k$ and $\lambda^k$ are equal and converge at the following arbitrary rate determined by the sequence of step-sizes $\alpha_k > 0$,
	\begin{equation}
	\label{eq:ConvergenceContinuousLevel_Rate}
		\|\lambda^\ast - \lambda^k \|^2_{H^{-1}(\Omega)}
		=
		\|\nabla u^\ast - \nabla u^k\|_{L^2(\Omega)}^2
		\leq
		\frac{D(u^\ast-\phi,u^0-\phi)}{\sum_{j=1}^k \alpha_{j}}
		.
	\end{equation}
																																					\end{theorem}

\begin{remark}[Arbitrary orders of convergence]
\label{rem:ConvergenceOrders}
	\Cref{thm:ConvergenceContinuousLevel} shows that the iteration complexity of LVPP depends on the choice of the step sizes $\alpha_k$.
	The consequences of different step size choices is summarized in~\Cref{cor:ConvergenceRates}.
		For example, we find that constant step sizes lead to sublinear convergence and geometrically increasing step sizes lead to first-order convergence.
	Even faster growing step size sequences will acheive superlinear convergence.
	See also~\Cref{rem:StrictComplementarity}.
\end{remark}


\begin{remark}[Convergence in the $H^1(\Omega)$-norm]
At first glance, control over the full $H^1(\Omega)$ norm of $u^k$ appears problematic because \cref{eq:ConvergenceContinuousLevel_Rate} does not include the full norm on $H^1_g(\Omega)$. However, in light of the Poincar\'e inequality and $u^\ast - u^k \in H^1_0(\Omega)$, we also obtain 
\[
	\| u^\ast -  u^k\|_{L^2(\Omega)}^2
	\leq
	c \frac{D(u^\ast-\phi,u^0-\phi)}{\sum_{j=1}^k \alpha_{j}},
\]
where $c > 0$ is an embedding constant independent of $k$.
\end{remark}

\begin{remark}[Convergence of the latent variable]
	If we adopt the conventions $\ln 0 = - \infty$ and $\exp(-\infty) = 0$, we may define $\psi^\ast = \ln (u^\ast-\phi)$ as an extended real-valued function on $\Omega$; cf.~\Cref{sub:the_cole_hopf_transform_and_the_semiring_of_non_negative_functions}.
	Likewise, we may understand convergence of the latent variable $\psi \to \psi^\ast$ under the metric implied by this transformation.
	Indeed, consider the metric $ d(\psi,\varphi) = \|\nabla\exp\psi - \nabla\exp\varphi\|_{L^2(\Omega)}$, first introduced in~\cref{eq:LatentVariableNonnegativityMetric}.
	Clearly,
	\begin{align}
		d(\psi^\ast,\psi)
		=
						\|\nabla(\exp\psi^\ast+\phi) - \nabla(\exp\psi+\phi)\|_{L^2(\Omega)}
				&=
		\|\nabla u^\ast - \nabla u\|_{L^2(\Omega)}
		\,,
	\end{align}
	which converges to zero as $k \to \infty$ by~\cref{eq:ConvergenceContinuousLevel_Rate}.
\end{remark}

\begin{remark}[Dual variable mixed formulation]
	The formulation~\cref{eq:ConvergenceContinuousLevel_VE} is derived by setting $w = u^k$, $\alpha = \alpha_{k+1}$, and substituting the equation $\psi^{k+1} = \ln(u^k - \phi)$ into~\cref{eq:PrimalProblemVE_inhom}.
	If, instead, we considered the dual variable substitution $\lambda^{k+1} = \ln ((u^{k}-\phi)/(u^{k+1}-\phi))/\alpha_{k+1}$, we would arrive at the following alternative formulation:
	\begin{equation}
	\label{eq:ConvergenceContinuousLevel_VE_alternative}
		\left\{
		\begin{aligned}
			\,&\text{Find}~
			u^{k+1}\in  H^1_g(\Omega) ~\text{and}~\lambda^{k+1} \in L^\infty(\Omega)
			~\text{such that~}
			\\
			&\begin{alignedat}{4}
				( \nabla u^{k+1}, \nabla v) - (\lambda^{k+1}, v) &= ( f, v)
				&&~\fa v \in H^1_0(\Omega)
				\,,
				\\
				(u^{k+1}, \varphi) - (u^k\exp(- \alpha_{k+1}\lambda^{k+1}), \varphi) &= (\phi,\varphi)
				&&~\fa \varphi \in L^2(\Omega)
				\,.
			\end{alignedat}
		\end{aligned}
		\right.
	\end{equation}
	Although this is equivalent to~\cref{eq:ConvergenceContinuousLevel_VE} at the continuous level, it will induce a different Galerkin method; cf.~\Cref{sub:proximal_galerkin}.
	We leave the study of such dual variable proximal Galerkin methods for future research.

																			
\end{remark}

	


\begin{remark}[Strict complementarity]
\label{rem:StrictComplementarity}
	Although~\Cref{thm:ConvergenceContinuousLevel} allows us to establish arbitrary orders of convergence (see \Cref{cor:ConvergenceRates}), it still represents the worst-case iteration complexity.
	In particular, our numerical experiments in \Cref{ssub:experiment_2_kkt_conditions}, suggest that an improved result may be possible if the solution $u^\ast$ exhibits strict complementarity.
\end{remark}

\subsection{Proximal Galerkin} \label{sub:proximal_galerkin}




Motivated by~\Cref{thm:ConvergenceContinuousLevel}, it is natural to use finite-dimensional subspaces $V_h \subset H^1_0(\Omega)$ and $W_h \subset L^\infty(\Omega)$ in order to form a Galerkin discretization of~\cref{eq:ConvergenceContinuousLevel_VE}.
Thus, we arrive at \Cref{alg:ObstacleProblem}, which may be seen as a natural extension of~\Cref{alg:EntropicGalerkinIntro} to the inhomogeneous obstacle problem.

\begin{algorithm2e}[ht]
\DontPrintSemicolon
	\caption{\label{alg:ObstacleProblem} 
	Proximal Galerkin method for the obstacle problem.
	}
	\SetKwInOut{Input}{Input}
	\SetKwInOut{Output}{Output}
	\BlankLine
	\Input{Linear subspaces $V_h \subset H^1_0(\Omega)$ and $W_h \subset L^\infty(\Omega)$, initial solution guess $\psi_h^0 \in W_h$, unsummable sequence of step sizes $\alpha_k>0$.}
	\Output{Two approximate solutions, $u_{h}$ and $\widetilde{u}_h = \phi + \exp\psi_h$, and an approximate Lagrange multiplier, $\lambda_h = (\psi_h^{k-1} - \psi_h)/\alpha_k$.}
	\BlankLine
	Initialize $k = 0$.\;
	\Repeat{a convergence test is satisfied}
	{
		Solve the following (nonlinear) discrete saddle-point problem:
		\begin{gather}
		\label{eq:ObstacleDiscreteNonlinearSaddlePoint}
			\left\{
			\begin{aligned}
				\,&\text{Find}~
				u_{h}\in g_h + V_{h} ~\text{and}~\psi_{h} \in W_{h}
								~\text{such that~}
				\\
				&\begin{alignedat}{4}
				    (\alpha_{k+1} \nabla u_h, \nabla v) + (\psi_h, v) &= ( \alpha_{k+1} f + \psi_h^{k}, v)
					&&~\fa v \in V_h
					\,,
					\\
					(u_h, \varphi) - (\exp\psi_h, \varphi) &= (\phi, \varphi)
					&&~\fa \varphi \in W_h
					\,.
				\end{alignedat}
			\end{aligned}
			\right.
		\end{gather}
		\;
		\vspace*{-\baselineskip}
		Assign $\psi^{k+1}_h \leftarrow \psi_{h}$ and $k \leftarrow k+1$.\;
	}
\end{algorithm2e}
Just like~\Cref{alg:EntropicGalerkinIntro}, we find that~\Cref{alg:ObstacleProblem} delivers \emph{two} distinct approximations of the exact solution; $u_{h} \in V_h$ and $\widetilde{u}_h \in \phi + \exp(W_h)$.
The second of these approximations is unusual because it is guaranteed to satisfy the inequality $\widetilde{u}_h > \phi$.
Moreover, like the continuous-level algorithm in~\Cref{thm:ConvergenceContinuousLevel}, it also produces an approximate Lagrange multiplier,
\begin{equation}
	\lambda_h = (\psi_h^{k-1} - \psi_h^{k})/\alpha_{k}
	\,,
\end{equation}
where $k$ denotes the final iterate where the abstract convergence test in~\Cref{alg:ObstacleProblem} is satisfied.



Finite element methods typically lead to piece-wise polynomial approximations of the exact solution.
Given that $\widetilde{u}_h = \phi + \exp\psi_h$ relies on a non-standard type of exponential function approximation, it is natural ask whether $\widetilde{u}_h$ can produce an accurate approximation of the continuous-level solution $u$.
The following result provides a partial positive answer to this question.
The proof is given in~\Cref{sub:nonlinear_approximability}.



\begin{proposition}
\label{lem:UtildeBound}
	Let $u \in \interior L^\infty_+(\Omega)$ and define $\psi = \ln u$.
	Moreover, let $\psi_h \in W_h$ and $\widetilde{u}_h = \exp \psi_h$.
	The following identity holds:
	\begin{equation}
		\|u - \widetilde{u}_h\|_{L^\infty(\Omega)}
		\leq
				\|u\|_{L^\infty(\Omega)}
		\big(
			\exp\|\psi - \psi_h\|_{L^\infty(\Omega)} - 1
		\big).
	\end{equation}
\end{proposition}

The next ordinary concern would be the stability of the discretization~\cref{eq:ObstacleDiscreteNonlinearSaddlePoint}.
In the next subsection, we propose stable pairs of finite elements that can be used to construct $V_h$ and $W_h$.





\subsection{Stable pairs of finite elements I: Discontinuous latent variable} \label{sub:finite_element_subspaces}

Subspace pairings determine the stability of finite element methods for saddle-point problems~\cite{boffi2013mixed}.
Thus, it should come as no surprise that the choice of the subspaces $V_h$ and $W_h$ is central to the proximal Galerkin method.
For simplicity, we focus on stable pairs of finite elements with discontinuous latent variables $\psi_h$, as these appear to provide the most efficient conforming approximations per degree of freedom.
The elements we propose are defined in~\cref{eq:SubspacePairs}, below.
Constructing alternatives using macroelement partitions (e.g., \cite{stenberg1984analysis}), various non-conforming approximation techniques (e.g., \cite{crouzeix1973conforming,cockburn2009unified}), or even spline-based approximation spaces (cf.~\cite{hughes2005isogeometric}) all provide possible alternatives for the design of proximal Galerkin methods.
Due to space in this manuscript and the limitations of our present software, we leave these and other possible constructions to future studies.



Here and throughout, $\mathcal{T}_h$ always denotes a shape-regular partition of the domain $\Omega \subset \mathbb{R}^2$ into finitely many open connected triangular or quadrilateral mesh cells $T$ with Lipschitz boundaries $\partial T$ such that $\Omega$ is the union of the closure of all mesh cells $T$ in $\mathcal{T}_h$.
Following convention, $h > 0$ denotes the mesh size $h = \max_{T\in\mathcal{T}_h} \mathrm{diam}(T)$.
Let $\mathbb{P}_{p}(T)$ denote the space of polynomials of total order up to and including $p$ on a triangle $T$.
Likewise, let $\mathbb{Q}_{p}(T)$ denote the space of tensor-product polynomials of order up to and including $p$ on a quadrilateral $T$ \cite{ern2021finite}.
Moreover, for any space $\mathbb{X}(T)$ of polynomials over an element $T \in \mathcal{T}_h$, we abuse notation to denote the corresponding space of ``broken'' polynomials $\mathbb{X}(\mathcal{T}_h) = \{\varphi \in L^\infty(\Omega) \mid \varphi_{|T} \in \mathbb{X}(T) \text{~for every~} T \in \mathcal{T}_h\}$.


We will require spaces of degree-$q$ polynomials on whose traces on the cell boundary $\partial T$ have lower polynomial degree $p < q$.
To this end, define the sets of so-called bubble functions in $\mathbb{P}_{q}(T)$ and $\mathbb{Q}_{q}(T)$ to be $\mathring{\mathbb{P}}^{q}(T) = \{ \varphi \in \mathbb{P}_{q}(T) \mid \varphi_{|\partial T} =  0\}$ and $\mathring{\mathbb{Q}}^{q}(T) = \{ \varphi \in \mathbb{Q}_{q}(T) \mid \varphi_{|\partial T} =  0\}$, respectively.
Accordingly, define $\hat{\mathbb{P}}_{p}(T) = \mathbb{P}_{p}(T) \setminus \mathring{\mathbb{P}}^{p}(T)$ and $\hat{\mathbb{Q}}_{p}(T) = \mathbb{Q}_{p}(T) \setminus \mathring{\mathbb{Q}}^{p}(T)$.
Finally, let
\begin{equation}
	\mathbb{P}_p^q(T) = \hat{\mathbb{P}}_{p}(T) \oplus \mathring{\mathbb{P}}^{q}(T)
	\quad
	\text{and}
	\quad
	\mathbb{Q}_p^q(T) = \hat{\mathbb{Q}}_{p}(T) \oplus \mathring{\mathbb{Q}}^{q}(T)
	\,.
\end{equation}





% Figure environment removed

We are now ready to define the finite element spaces, which we chose based on \textit{a priori} analysis of a simple linearization of subproblem~\cref{eq:ObstacleDiscreteNonlinearSaddlePoint}.
For further details of the analysis, see~\Cref{sec:the_entropic_finite_element_method}.
\smallskip

For any integer $p \geq 1$, we define the following two pairs of spaces:
\begin{subequations}
\label{eq:SubspacePairs}
\smallskip

\noindent\textsl{Triangular elements.} We refer to the following as the $(\mathbb{P}_p\text{-bubble},\mathbb{P}_{p-1}\text{-broken})$ pairing:
\begin{equation}
\label{eq:SubspacePair1}
	V_h = \mathbb{P}_{p}^{p+2}(\mathcal{T}_h)\cap H^1_0(\Omega)
	\,,\qquad
				W_h = \mathbb{P}_{p-1}(\mathcal{T}_h)
	\,.
\end{equation}

\noindent\textsl{Quadrilateral elements.} We refer to the following as the $(\mathbb{Q}_p\text{-bubble},\mathbb{Q}_{p-1}\text{-broken})$ pairing:
\begin{equation}
\label{eq:SubspacePair2}
	V_h = \mathbb{Q}_{p}^{p+1}(\mathcal{T}_h)\cap H^1_0(\Omega)
	\,,\qquad
						W_h = \mathbb{Q}_{p-1}(\mathcal{T}_h)
	\,.
\end{equation}
\end{subequations}
\Cref{fig:P1BP0} provides a visual representation of the lowest-order versions of these elements.

\begin{remark}[Positive cell average]
	Assume $\phi = 0$.
	Although the piecewise polynomials $u_h$ that arise from solving the subproblems~\cref{eq:ObstacleDiscreteNonlinearSaddlePoint} can not be guaranteed to preserve pointwise positivity, they are guaranteed to have positive cell averages.
	Indeed, notice that the subspaces $W_h$ in~\cref{eq:SubspacePairs} always include piecewise constant functions.
	Therefore, we may consider the second equation in~\cref{eq:ObstacleDiscreteNonlinearSaddlePoint} with $\varphi = 1$ in $T$ and $\varphi = 0$ otherwise.
	Testing with this particular function implies that
	\begin{equation}
		\int_T u_h \dd x = \int_T \exp\psi_h > 0
		\,.
	\end{equation}
	If $\phi \neq 0$, then a similar argument implies that each cell average of $u_h$ lies above the corresponding cell average of $\phi$.
\end{remark}


\begin{remark}[Alternative subspaces]
\label{rem:AlternativeSubspaces1}
	Although variable-order spaces like $V_h$ in~\cref{eq:SubspacePairs} are supported in some software \cite{demkowicz2006computing,fuentes2015orientation}, they may not available in the preferred software of many users.
	For this reason, we also recommend the following alternative pairings:
	\begin{subequations}
	\label{eq:SubspacePairs_alt}
	\smallskip

	\noindent\textsl{Alternative triangular elements.} We refer to the following as the $(\mathbb{P}_{p+2},\mathbb{P}_{p-1}\text{-broken})$ subspaces:
	\begin{equation}
	\label{eq:SubspacePair3}
		V_h = \mathbb{P}_{p+2}(\mathcal{T}_h)\cap H^1_0(\Omega)
		\,,\qquad
		W_h = \mathbb{P}_{p-1}(\mathcal{T}_h)
		\,.
	\end{equation}

	\noindent\textsl{Alternative quadrilateral elements.} We refer to the following as the $(\mathbb{Q}_{p+1},\mathbb{Q}_{p-1}\linebreak\text{-broken})$ subspaces:
	\begin{equation}
	\label{eq:SubspacePair4}
		V_h = \mathbb{Q}_{p+1}(\mathcal{T}_h)\cap H^1_0(\Omega)
		\,,\qquad
		W_h = \mathbb{Q}_{p-1}(\mathcal{T}_h)
		\,.
	\end{equation}
	\end{subequations}
	Since~\cref{eq:SubspacePairs} are stable (cf.~\Cref{lem:Fortin}), it is a straightforward consequence of the inclusions $\mathbb{P}_{p}^{p+2}(T) \subset \mathbb{P}_{p+2}(T)$ and $\mathbb{Q}_{p}^{p+1}(T) \subset \mathbb{Q}_{p+1}(T)$ that~\cref{eq:SubspacePairs_alt} are also stable.
	For further details, see~\Cref{rem:AlternativeSubspaces1}.

\end{remark}








\subsection{Algorithm} \label{sub:obstacle_algorithm}

We conducted numerical experiments across two separate\linebreak codes, FEniCSx \cite{scroggs2022construction} and MFEM \cite{anderson2021mfem}, and have released our implementations to the public \cite{Keith2023ObstacleCode,ZenodoCode}.
The FEniCSx implementation \cite{ZenodoCode} is Python-based and uses the $(\mathbb{P}_p\text{-bubble},\mathbb{P}_{p-1}\text{-broken})$ triangular elements proposed in~\Cref{sub:finite_element_subspaces}.
The MFEM implementation is written in C++.
Because MFEM does not currently support bubble function enrichment, the MFEM implementation \cite{Keith2023ObstacleCode} uses $(\mathbb{Q}_{p+1},\mathbb{Q}_{p-1}\text{-broken})$ quadrilateral elements (see~\Cref{rem:AlternativeSubspaces1}) instead of the $(\mathbb{Q}_p\text{-bubble}, \mathbb{Q}_{p-1}\text{-broken})$ elements also proposed in~\Cref{sub:finite_element_subspaces}.

\Cref{alg:Obstacle_Newton} represents the MFEM implementation.
Notice that it is a quasi-Newton algorithm that includes a small modification to the local Hessian.
We found that for small values of $\epsilon$ (we used $\epsilon = 10^{-6}$), this made the built-in GMRES solver more robust and did not strongly affect the convergence rates.
Our FEniCSx implementation uses the standard PETSc \cite{petsc-user-ref} Newton solver provided by the petsc4py Python package \cite{DalcinPazKlerCosimo2011}.
This implementation does not involve any modifications to the local Hessian.
Before stating the algorithm, we introduce notation for the element-wise gradient operator $\nabla_h\colon \prod_{T\in\mathcal{T}_h} H^1(T) \to L^2(\Omega)$, which satisfies
\begin{equation}
	(\nabla_h v, \nabla_h w)
	=
	\sum_{T\in\mathcal{T}_h}
	\int_T \nabla v\cdot \nabla w \dd x
		\,.
\end{equation}


\begin{algorithm2e}[ht]
\DontPrintSemicolon
	\caption{\label{alg:Obstacle_Newton} 
	Quasi-Newton proximal Galerkin method for the obstacle problem.
	}
	\SetKwInOut{Input}{Input}
	\SetKwInOut{Output}{Output}
	\BlankLine
	\Input{Piecewise polynomial subspaces $V_{h} \subset H^1_0(\Omega)$ and $W_{h} \subset L^\infty(\Omega)$, initial solution guesses $u_h \in V_{h}$ and $\psi_h \in W_{h}$, unsummable sequence of step sizes $\alpha_k>0$, exit tolerance $\mathtt{tol}_{\mathrm{exit}} > 0$, and initial Newton tolerance $\mathtt{tol}_{\mathrm{Newton}} > \mathtt{tol}_{\mathrm{exit}}$.}
		\Output{Two approximate solutions, $u_{h}$ and $\widetilde{u}_h = \phi + \exp\psi_h$, and an approximate Lagrange multiplier, $\lambda_h = (\psi_h^{k-1} - \psi_h)/\alpha_k$.}
	\BlankLine
	Initialize $k = 0$.\;
		\Repeat{$\mathtt{tol}_{\mathrm{Newton}} < \mathtt{tol}_{\mathrm{exit}}$}
	{
		Assign $u_h^{k} \leftarrow u_h$ and $\psi^{k}_h \leftarrow \psi_{h}$.\;
		\Repeat{$\|u_h - w_h\|_{L^2(\Omega)}^2 \leq \mathtt{tol}_{\mathrm{Newton}}^2$}
				{
			Assign $w_h \leftarrow u_h$.\;
																																										Reassign $u_{h}$ and $\delta_{h}$ by solving the following (linearized) discrete saddle-point problem:
						\begin{equation*}
			\label{eq:ObstacleDiscreteNonlinearSaddlePoint2}
				\left\{
				\begin{aligned}
					\,&\text{Find}~
					u_{h}\in V_{h} ~\text{and}~\delta_{h} \in W_{h}
					~\text{such that~}
					\\
					&\begin{alignedat}{4}
						(\alpha_{k+1} \nabla u_h, \nabla v) + (\delta_{h}, v) &=  ( \alpha_{k+1} f + \psi_h^{k} - \psi_{h}, v)
						&&~\fa v \in V_{h}
						\,,
						\\
						(u_h, w) - c_\varepsilon(\psi_{h},\delta_{h},w) &= (\phi + \exp\psi_{h}, w)
												&&~\fa w \in W_{h}
						\,,
					\end{alignedat}
				\end{aligned}
				\right.
			\end{equation*}
			where
			\begin{equation*}
				c_\varepsilon(\psi_{h},\delta_{h},w)
				=
				\begin{cases}
					(\delta_{h}\exp\psi_{h}, w) + \varepsilon (\delta_{h}, w)
					& \text{if~} W_h \in \mathrm{ker}(\nabla_h)\,,\\
					(\delta_{h}\exp\psi_{h}, w) + \varepsilon (\nabla_h \delta_{h}, \nabla_h w)
					& \text{otherwise.}
				\end{cases}
			\end{equation*}
			\;
			\vspace*{-\baselineskip}
			Assign $\psi_h \leftarrow \psi_{h} + \delta_{h}$.\;
		}
		Assign $\mathtt{tol}_{\mathrm{Newton}} \leftarrow \|u_h - u_h^{k}\|_{L^2(\Omega)}$ and $k \leftarrow k+1$.\;
	}
		\end{algorithm2e}

\begin{remark}[Practical aspects of the implementation: Stopping criteria]
	We use several metrics to design a meaningful stopping criterion for \Cref{alg:Obstacle_Newton}. The 
	algorithm uses two loops: an outer loop that updates the parameter $\alpha_k$ and adapts the Bregman
	term and an inner loop in which the step is calculated using an inexact Newton iteration. In an ideal setting,
	the outer loop would stop once the residual of the optimality conditions for the original problem has a sufficiently
	small norm. This is difficult to check in general, e.g., since the $H^1$-projection operator onto the feasible set 
	is nontrivial/expensive to evaluate. On the other hand, \Cref{thm:ConvergenceContinuousLevel} provides a theoretical 
	convergence rate and allows us to view the outer loop as a \textit{globally} convergent fixed point iteration. For this 
	reason, we can use the distance between successive iterates as a practical stopping criterion.
	For the inner iterations, we check either the norm of the residual of the nonlinear term (see \cite{ZenodoCode}) or the length of the proposed step (see \cite{Keith2023ObstacleCode}).
		The length of the accepted step informs the next inner iteration tolerance and ensures that
	more accurate steps are computed as $k$ increases. Since the residual for the first equation is technically
	exact, we do not include it in the inner stopping criterion.
\end{remark}



\subsection{Numerical experiments} \label{sub:obstacle_numerical_experiments}

We performed four sets of numerical experiments in order to validate the proximal Galerkin method.
The first experiment involves a smooth biactive manufactured solution that allows us to verify the (mesh-indepenent) iteration complexity predicted by \Cref{thm:ConvergenceContinuousLevel}, in addition to high-order convergence rates with respect to the polynomial order of the finite element subspaces.
In the second experiment, we check the discrete Karush--Kuhn--Tucker (KKT) conditions on a manufactured solution exhibiting strict complementarity.
In this case, we observe \emph{better} iteration complexity than predicted by \Cref{thm:ConvergenceContinuousLevel}.
We conjecture that this improved convergence order holds in general whenever a strict complementarity condition is satified; cf.~\Cref{rem:StrictComplementarity}.
The third experiment involves a non-smooth biactive solution and is included to further stress test the proximal Galerkin method.
Finally, in our fourth experiment, we consider a benchmark obstacle problem from the literature and demonstrate our ability solve this problem with the highest order finite elements currently supported in our MFEM code; i.e., we used $p=12$.


Each of our experiments were conducted on standard sequences of uniformly refined nested meshes $\mathcal{T}_{h}, \mathcal{T}_{h/2}, \mathcal{T}_{h/4}, \ldots$ conforming to unit ball domains in $\mathbb{R}^2$.
The experiments with the triangular elements (FEniCSx) used an $\ell^\infty$-unit ball (i.e., square) domain,
\begin{subequations}
\begin{equation}
	\Omega_\infty
	=
	\{
		(x,y) \in \mathbb{R}^2 \mid \max\{|x|,|y|\} < 1
	\}
	\subset \mathbb{R}^2
	\,,
\end{equation}
with initial mesh size denoted $h = h_\infty$.
Meanwhile, the experiments with the quadrilateral elements (MFEM) used an $\ell^2$-unit ball (i.e., circular) domain,
\begin{equation}
	\Omega_2 
	=
	\{
		(x,y) \in \mathbb{R}^2 \mid x^2 + y^2 < 1
	\}
	\subset \mathbb{R}^2
	\,,
\end{equation}
\end{subequations}
with initial mesh size denoted $h = h_2$, which was uniformly refined using a standard transfinite interpolation rule to handle the curvilinear element mappings \cite{gordon1973construction}.
The initial meshes in these sequences are depicted in~\Cref{fig:ObstacleMesh}.

% Figure environment removed


\subsubsection{Experiment 1: Smooth biactive solution} \label{ssub:experiment_1_biactivity}

In this experiment, we set $\phi = 0$ and $g=u$, where $u(x,y)$ is the smooth manufactured solution
\begin{equation}
\label{eq:Biactivity_SmoothManufacturedSolution}
	u(x,y)
	=
	\begin{cases}
		0 & \text{if~} x < 0\,,\\
		x^4 & \text{otherwise,}\\
	\end{cases}
	\quad
		\text{implied by}
		\quad
	f(x,y)
	=
	\begin{cases}
		0 & \text{if~} x < 0\,,\\
		-12x^2 & \text{otherwise.}\\
	\end{cases}
\end{equation}
See \Cref{fig:BiactiveIterationComplexity,fig:BiactivePolynomialOrderConvergenceRates} for depictions of the exact solution on $\Omega_\infty$ and $\Omega_2$, respectively.

This problem is specifically chosen to exhibit \emph{biactivity}; i.e., both the inequality constraint $u \geq 0$ and the associated Lagrange multiplier are simultaneously equal to zero on a set of positive measure; i.e., on the set $\{ (x,y) \mid x < 0 \}$.
Such problems are notoriously difficult to solve for certain classes of algorithms, such as active set methods.
Biactivity, also know as weak activity or lack of strict complementarity, is a notion from nonlinear optimization that indicates a kind of degenerate nonsmoothness of the primal-dual system of equations used to calculate the solution. It is often associated with a lack of stability with respect to perturbations of the data, as well. We refer the interested reader to any standard text of numerical optimization; see, e.g., \cite[Definition~12.5]{nocedal1999numerical}.

Our first aim is to use this challenging example to illustrate \emph{mesh-independence} of the proximal Galerkin method.
To this end, we use \Cref{tab:BiactivityMeshIndependence} to record the values of the increments $\|u_h^{k} - u_h^{k-1}\|_{H^1(\Omega_\infty)}$ taken from a sequence of refined meshes with polynomial orders $p=1,2$ from our FEniCSx implementation \cite{ZenodoCode}.
The specific step size rule used to generate this data is chosen based on \Cref{cor:ConvergenceRates} to deliver \emph{superlinear} convergence (in iterations), and is given as follows:
\begin{subequations}
\begin{equation}
\label{eq:ObstacleStepSizes_superexponential}
	\alpha_1 = 1\,,
	\quad
	\alpha_k
	=
	\min\bigl\{ \max\bigl\{\alpha_1,r^{q^{k-1}} - \alpha_{k-1}\bigr\} , 10^{10} \bigr\}
	\,,
	\quad
	k = 2,3,\ldots,
\end{equation}
where $r = q = 1.5$.
Note that, for each iteration $k$, the increments in \Cref{tab:BiactivityMeshIndependence} converge to fixed values as the mesh is refined or the polynomial order is raised.
Moreover, the total number of linear equation solves remains bounded.
Both of these characteristics are embematic of a \emph{mesh-independent} numerical method.

\begin{table}
\centering
\footnotesize
\renewcommand{\arraystretch}{1.3}
\begin{tabular}{ |c|c|c|c|c|c|c| }
 \hhline{|>{\arrayrulecolor{white}}-->{\arrayrulecolor{black}}|-----|}
 \multicolumn{2}{c|}{} & \multicolumn{5}{c|}{\cellcolor{lightgray!15} \small\raisebox{5pt}{\vphantom{f}} Progress of the iterates $\|u_h^{k} - u_h^{k-1}\|_{H^1(\Omega_\infty)}$ for various $h$ and $p$}\\[3pt]
 \hhline{|>{\arrayrulecolor{white}}-->{\arrayrulecolor{black}}|-----|}
 \multicolumn{2}{c|}{}& \multicolumn{3}{c|}{\cellcolor{lightgray!05} Polynomial order $p = 1$} & \multicolumn{2}{c|}{\cellcolor{lightgray!10} Polynomial order $p = 2$}\\
 \hline
 \rowcolor{lightgray!15}
 $k$ & $\alpha_{k}$ & $h_\infty/16$ & $h_\infty/32$ & $h_\infty/64$ & $h_\infty/16$ & $h_\infty/32$ \\
 \hline
\cellcolor{lightgray!05}   1 & \cellcolor{lightgray!01}   $1.0$              & $2.10\cdot 10^{0}$   & $2.10\cdot 10^{0}$   & $2.10\cdot 10^{0}$   & $2.10\cdot 10^{0}$   & $2.10\cdot 10^{0}$   \\
\cellcolor{lightgray!05}   2 & \cellcolor{lightgray!01}   $1.0$              & $6.45\cdot 10^{-1}$  & $6.45\cdot 10^{-1}$  & $6.45\cdot 10^{-1}$  & $6.45\cdot 10^{-1}$  & $6.45\cdot 10^{-1}$  \\
\cellcolor{lightgray!05}   3 & \cellcolor{lightgray!01}   $1.49$             & $1.73\cdot 10^{-1}$  & $1.73\cdot 10^{-1}$  & $1.73\cdot 10^{-1}$  & $1.73\cdot 10^{-1}$  & $1.73\cdot 10^{-1}$  \\
\cellcolor{lightgray!05}   4 & \cellcolor{lightgray!01}   $2.43$             & $1.10\cdot 10^{-1}$  & $1.10\cdot 10^{-1}$  & $1.10\cdot 10^{-1}$  & $1.10\cdot 10^{-1}$  & $1.10\cdot 10^{-1}$  \\
\cellcolor{lightgray!05}   5 & \cellcolor{lightgray!01}   $5.35$             & $7.76\cdot 10^{-2}$  & $7.77\cdot 10^{-2}$  & $7.77\cdot 10^{-2}$  & $7.77\cdot 10^{-2}$  & $7.77\cdot 10^{-2}$  \\
\cellcolor{lightgray!05}   6 & \cellcolor{lightgray!01}   $1.64\cdot 10^{1}$ & $4.76\cdot 10^{-2}$  & $4.77\cdot 10^{-2}$  & $4.77\cdot 10^{-2}$  & $4.77\cdot 10^{-2}$  & $4.77\cdot 10^{-2}$  \\
\cellcolor{lightgray!05}   7 & \cellcolor{lightgray!01}   $8.50\cdot 10^{1}$ & $2.24\cdot 10^{-2}$  & $2.25\cdot 10^{-2}$  & $2.25\cdot 10^{-2}$  & $2.25\cdot 10^{-2}$  & $2.25\cdot 10^{-2}$  \\
\cellcolor{lightgray!05}   8 & \cellcolor{lightgray!01}   $9.35\cdot 10^{2}$ & $5.82\cdot 10^{-3}$  & $5.84\cdot 10^{-3}$  & $5.85\cdot 10^{-3}$  & $5.85\cdot 10^{-3}$  & $5.85\cdot 10^{-3}$  \\
\cellcolor{lightgray!05}   9 & \cellcolor{lightgray!01}   $3.17\cdot 10^{4}$ & $6.04\cdot 10^{-4}$  & $6.07\cdot 10^{-4}$  & $6.07\cdot 10^{-4}$  & $6.07\cdot 10^{-4}$  & $6.07\cdot 10^{-4}$  \\
\cellcolor{lightgray!05}  10 & \cellcolor{lightgray!01}   $5.85\cdot 10^{6}$ & $1.80\cdot 10^{-5}$  & $1.81\cdot 10^{-5}$  & $1.81\cdot 10^{-5}$  & $1.81\cdot 10^{-5}$  & $1.81\cdot 10^{-5}$  \\
\cellcolor{lightgray!05}  11 & \cellcolor{lightgray!01}   $1\cdot 10^{10}$   & $9.41\cdot 10^{-8}$  & $9.47\cdot 10^{-8}$  & $9.49\cdot 10^{-8}$  & $9.50\cdot 10^{-8}$  & $9.50\cdot 10^{-8}$  \\
\cellcolor{lightgray!05}  12 & \cellcolor{lightgray!01}   $1\cdot 10^{10}$   & $2.10\cdot 10^{-12}$ & $2.00\cdot 10^{-12}$ & $1.96\cdot 10^{-12}$ & $1.92\cdot 10^{-12}$ & $1.95\cdot 10^{-10}$ \\
 \hline
 \rowcolor{lightgray!05}
 \multicolumn{2}{|c|}{\cellcolor{lightgray!15} Tot. linear solves} & $21$ & $20$ & $19$ & $19$ & $19$ \\
 \hline
\end{tabular}
\caption{\label{tab:BiactivityMeshIndependence}
Biactivity.
Table of increments $\|u_h^{k} - u_h^{k-1}\|_{H^1(\Omega_\infty)}$ for various mesh sizes $h$ and polynomial orders $p$ using the triangular element $(\mathbb{P}_p\text{-bubble},\mathbb{P}_{p-1}\text{-broken})$ discretization.
The initial degrees of freedom for $u_h$ and $\psi_h$ were set to zero at the beginning of each run.
Between eight and ten Newton iterations performed by the PETSc Newton solver used for each initial subproblem solve and then only one Newton solve was used for each of the following subproblems.
The convergence of the increments for each fixed $k$ and the boundedness of the number of linear solves indicates \emph{mesh-independence}.
}
\end{table}

Our next aim is to verify the convergence orders predicted by \Cref{thm:ConvergenceContinuousLevel} and \Cref{cor:ConvergenceRates}.
In doing so, we consider the double-exponential step size rule~\cref{eq:ObstacleStepSizes_superexponential} alongside the geometric rule
\begin{equation}
\label{eq:ObstacleStepSizes_geometric}
	\alpha_k = r^{k-1}
	\,,
	\quad
	k = 1,2,\ldots,
\end{equation}
\end{subequations}
with $r = 2$, and the fixed step size rule $\alpha_k = 1$, for all $k = 1,2,\ldots$
The results in \Cref{fig:BiactiveIterationComplexity} agree precisely with the predictions made later on in \Cref{cor:ConvergenceRates}.
In particular, notice that the fixed step rule $\alpha_k = 1$ leads to \emph{sublinear} convergence, the geometric rule \cref{eq:ObstacleStepSizes_geometric} induces \emph{linear} convergence, and the double-exponential step size rule~\cref{eq:ObstacleStepSizes_superexponential} delivers \emph{superlinear} convergence.

% Figure environment removed


The final aim of this experiment is to demonstrate that high-order convergence rates (with respect to the mesh size $h$) can be achieved using polynomial orders $p > 1$.
To this end, we use our high-order MFEM implementation to solve for the biactive solution~\cref{eq:Biactivity_SmoothManufacturedSolution} on the circular domain $\Omega = \Omega_2$.
In \Cref{fig:BiactivePolynomialOrderConvergenceRates}, we plot the approximation errors of the discrete solutions $u_h$, $\tilde{u}_h$, and $\lambda_h$.
From these results, we witness that high-order convergence rates can, indeed, be achieved with the proximal Galerkin method.

% Figure environment removed



\subsubsection{Experiment 2: Strict complementarity} \label{ssub:experiment_2_kkt_conditions}

In this experiment, we set $\phi = g = 0$ and define 
\begin{equation}
\label{eq:StrictComplementarity_RHS}
	f(x,y)
	=
	2 \pi^2 \sin(\pi x)\sin(\pi y)
	\,.
\end{equation}
See~\Cref{fig:StrictComplementarityConvergenceOrder} for a fine mesh ($h = h_\infty/128$) solution $u_h$ as well as the associated Lagrange multiplier $\lambda_h$.

When viewed from the perspective of continuum mechanics, the multiplier $\lambda$ is a resolvent force. It is therefore rare that we would see biactivity of the type in the previous experiments on such large domains as it would correspond to contact without any opposing force resulting from the obstacle. 

The first aim of this experiment is to revisit the convergence orders predicted by \Cref{thm:ConvergenceContinuousLevel} and \Cref{cor:ConvergenceRates} and demonstrate that they are overly pessimistic for this more typical type of problem.
Indeed, as demonstrated in \Cref{fig:StrictComplementarityConvergenceOrder}, we see that linear convergence is achieved using only a fixed step size.
In turn, superlinear convergence can be achieved using any unbounded step size rule.
For illustration, we have added results using the geometric rule~\cref{eq:ObstacleStepSizes_geometric}
with various growth parameters $r \in \{1.05,1.1,2\}$.

% Figure environment removed

The second aim of this experiment is to check convergence of the discrete solution via the KKT conditions.
This is useful to assess \textit{a posteriori} the optimality of the discrete solution when the true solution is unknown.
To this end, we consider the complementarity condition $\big|\int_{\Omega} \lambda u \dd x\big| = 0$, the primal feasibility condition $\int_{\Omega} \max\{-u,0\} \dd x = 0$, and the dual feasibility condition $\int_{\Omega} \max\{-\lambda,0\} \dd x = 0$.
We note that the discrete solution $\tilde{u}_h = \exp\psi_h$ is always feasible by construction, i.e., $\tilde{u}_h \geq 0$.
Therefore, in order to glean more interesting information about the proximal Galerkin solution, we focus on discrete versions of the KKT conditions formulated in terms of the solution variable $u_h$.
The discrete KKT conditions that we checked are recorded in \Cref{tab:KKT}.
From the results in this table, we see that discrete primal feasibility, $\int_{\Omega} \max\{-u_h,0\} \dd x = 0$, is achieved only in the limit $h \to 0$.
However, discrete complementarity, $\big|\int_{\Omega} \lambda_h u_h \dd x\big| = 0$, and discrete dual feasibility, $\int_{\Omega} \max\{-\lambda_h,0\} \dd x = 0$, appear to hold for all mesh sizes.

\begin{table}
\centering
\small
\renewcommand{\arraystretch}{1.3}
\begin{tabular}{ |c|c|c|c| }
 \hline
    \rowcolor{lightgray!10}
  &&&
  \\
 \rowcolor{lightgray!10}
  \multirow{-2}{*}{$h$} & \multirow{-2}{3cm}{\centering {\small Complementarity} $\big|\int_{\Omega_\infty} \lambda_h u_h \dd x\big|$} & \multirow{-2}{3cm}{\centering {\small Primal feasibility} $\int_{\Omega_\infty} \max\{-u_h,0\} \dd x$} & \multirow{-2}{3cm}{\centering {\small Dual feasibility} $\int_{\Omega_\infty} \max\{-\lambda_h,0\} \dd x$}\\
   \hline
       $h_\infty$     & \multirow{6}{*}{($\text{all less than~} 10^{-14}$)} & $6.97 \cdot 10^{-3}$ & \multirow{6}{*}{($\text{all less than~} 10^{-12}$)} \\
 $h_\infty/2$   &  & $9.09 \cdot 10^{-3}$ & \\
 $h_\infty/4$   &  & $1.16 \cdot 10^{-3}$ & \\
 $h_\infty/8$   &  & $1.69 \cdot 10^{-4}$ & \\
 $h_\infty/16$  &  & $4.08 \cdot 10^{-5}$ & \\
 $h_\infty/32$  &  & $4.53 \cdot 10^{-6}$ & \\
 \hline
\end{tabular}
\caption{\label{tab:KKT}
	Strict complementarity.
	Checking the discrete KKT conditions for the proximal Galerkin solution owing to~\cref{eq:StrictComplementarity_RHS}.
	Here, we see that primal feasibility is achieved in the limit $h\to 0$.
	Meanwhile, complementary and dual feasibility holds on all meshes.
}
\end{table}


\subsubsection{Experiment 3: Biactive solution, nonmsooth multiplier} \label{ssub:experiment_3_biactivity_revisited}

In this experiment, we set $\phi = 0$ and $g=u$, where $u(x,y)$ is the smooth manufactured solution
\begin{subequations}
\begin{equation}
	u(x,y)
	=
	\begin{cases}
		(1 - 4x^2 - 4y^2)^4 & \text{if~} x^2 + y^2 < 1/4\,,\\
		0 & \text{otherwise,}\\
	\end{cases}
\end{equation}
implied by the forcing function
\begin{equation}
	f(x,y)
	=
	-\Delta u(x,y)
	-
	\begin{cases}
		1 & \text{if~} x^2 + y^2 > 3/4\,,\\
		0 & \text{otherwise.}\\
	\end{cases}
\end{equation}
Clearly, this is another solution exhibiting biactivity.
In this case, however, the multiplier,
\begin{equation}
	\lambda(x,y) =
	\begin{cases}
		1 & \text{if~} x^2 + y^2 > 3/4\,,\\
		0 & \text{otherwise,}\\
	\end{cases}
\end{equation}
\end{subequations}
is discontinuous.
See \Cref{fig:Biactivity2} for a depiction of the exact solution $u$ as well as the associated Lagrange multiplier $\lambda$ on the domain $\Omega = \Omega_\infty$.

We use this experiment to inspect the approximation error of the $(\mathbb{P}_1\text{-bubble},\linebreak \mathbb{P}_{0}\text{-broken})$ discretization.
See \Cref{fig:Biactivity2} for our results.
As expected, unlike for the biactive solution studied in \Cref{ssub:experiment_1_biactivity}, the $L^2$-error of the Lagrange multiplier does not decay to zero linearly.
We observed no other adverse effects from this non-smooth manufactured solution.

% Figure environment removed





\subsubsection{Experiment 4: Spherical obstacle} \label{ssub:experiment_4_spherical_obstacle}

Our final experiment is motivated by an exact solution in \cite{gustafsson2017finite}.
Here, we set both $f = 0$ and $g = 0$ and define the obstacle to be the upper surface of a sphere of radius $1/2$, namely
\begin{equation}
\label{eq:SphericalObstacle}
	\phi(x,y) = \sqrt{ 1/4 - x^2 - y^2 }
	\,,
				\end{equation}
if $\sqrt{x^2 + y^2} \leq 1/2$, and assume that $\phi$ is sufficiently negative when $\sqrt{x^2 + y^2} > 1/2$ so that no contact happens on that subdomain.
Exploiting radial symmetry, the exact solution on the circular domain $\Omega = \Omega_2$ is found to be
\begin{equation}
	u(x,y) =
	\begin{cases}
		A \ln\sqrt{x^2 + y^2} & \text{if~} \sqrt{x^2 + y^2} > a,\\
		\phi(x,y) & \text{otherwise},\\
	\end{cases}
\end{equation}
where $a = \exp\big(W_{-1}\big(\frac{-1}{2e^2}\big)/2 + 1\big) \approx 0.34898$, $A = {\sqrt{1/4 - a^2}}/{\ln a} \approx -0.34012$, and $W_{j}(\cdot)$ is the $j$-th branch of the Lambert Wfunction.

\Cref{fig:ObstacleSphere} presents the very high order ($p=12$) proximal Galerkin solutions $u_h$ and $\tilde{u}_h$ to this problem on the coarsest mesh, $h = h_2$, which has only five elements.
This is the highest order discretization of the obstacle problem that we have seen in the literature.
\Cref{tab:ObstableErrorsp1} compares the subproblem error, $\|u-u^k_h\|_{H^1(\Omega_2)}$, on a sequence of uniformly meshes.
From this table, we see that if the number of outer iterations $k$ is held fixed, then the error converges to fixed values as the mesh is refined.
This is another hallmark of mesh-independence.
The open-source code to reproduce this experiment is available at \cite{Keith2023ObstacleCode}.

% Figure environment removed

\begin{table}
\centering
\footnotesize
\renewcommand{\arraystretch}{1.3}
\begin{tabular}{ |c|c|c|c|c|c|c| }
  \hhline{|>{\arrayrulecolor{white}}-->{\arrayrulecolor{black}}|-----|}
 \multicolumn{2}{c|}{} & \multicolumn{5}{c|}{\cellcolor{lightgray!15} \small\raisebox{5pt}{\phantom{f}} Primal errors $\|u - u_h^{k}\|_{H^1(\Omega_2)}$ for $p=1$ \raisebox{5pt}{\phantom{f}}}\\[3pt]
 \hline
 \rowcolor{lightgray!15}
 $k$ & Linear solves & $h_2/8$ & $h_2/16$ & $h_2/32$ & $h_2/64$ & $h_2/128$ \\
 \hline
 \cellcolor{lightgray!05} 1 & \cellcolor{lightgray!01} 3 & $2.72\cdot 10^{-1}$ & $2.70\cdot 10^{-1}$ & $2.70\cdot 10^{-1}$ & $2.70\cdot 10^{-1}$ & $2.70\cdot 10^{-1}$ \\
 \cellcolor{lightgray!05} 2 & \cellcolor{lightgray!01} 1 & $1.37\cdot 10^{-1}$ & $1.38\cdot 10^{-1}$ & $1.38\cdot 10^{-1}$ & $1.38\cdot 10^{-1}$ & $1.38\cdot 10^{-1}$ \\
 \cellcolor{lightgray!05} 3 & \cellcolor{lightgray!01} 1 & $3.62\cdot 10^{-2}$ & $3.33\cdot 10^{-2}$ & $3.31\cdot 10^{-2}$ & $3.31\cdot 10^{-2}$ & $3.31\cdot 10^{-2}$ \\
  \vdots & \vdots & \vdots & \vdots & \vdots & \vdots & \vdots \\[4pt]
 \hline
 \rowcolor{lightgray!05}
 \multicolumn{2}{|c|}{\cellcolor{lightgray!15} Total iterations} & $11$ & $11$ & $11$ & $11$ & $11$ \\
 \hline
 \rowcolor{lightgray!05}
 \multicolumn{2}{|c|}{\cellcolor{lightgray!15} Total linear solves} & $13$ & $13$ & $13$ & $13$ & $13$ \\
 \hline
 \rowcolor{lightgray!05}
 \multicolumn{2}{|c|}{\cellcolor{lightgray!15} Final error} & $1.98\cdot 10^{-2}$ & $8.73\cdot 10^{-3}$ & $3.49\cdot 10^{-3}$ & $1.18\cdot 10^{-3}$ & $3.85\cdot 10^{-4}$ \\
 \hline
\end{tabular}
\caption{\label{tab:ObstableErrorsp1}
	Spherical obstacle.
	Checking the subproblem error, $\|u-u^k_h\|_{H^1(\Omega_2)}$, for various mesh sizes using the $(\mathbb{Q}_2,\mathbb{Q}_{0}\text{-broken})$ discretization.
	We used $\alpha_k = 1$ for all $k=1,\ldots$ and stopped the algorithm when $\|u_h^{k} - u_h^{k-1}\|_{L^2(\Omega_2)} < 10^{-6}$.
}
\end{table}









\section{Extensions I: More general bound constraints and variational inequalities with an application to enforcing discrete maximum principles} \label{sec:maximum_principles}

The purpose of this section is to move beyond the proximal framework developed in \Cref{sec:the_obstacle_problem} for energy principles with pointwise lower bound constraints.
To this end, we aim to answer the following two necessary questions:
\smallskip
\begin{enumerate}[leftmargin=0.75cm,itemindent=0cm,itemsep=3pt]
	\item
		Can proximal Galerkin be used to \emph{simultaneously} enforce pointwise upper and lower bound constraints?
	\item
	Can proximal Galerkin be applied to variational inequalities that do not arise from an energy minimization principle?
\end{enumerate}
\smallskip
The answer to both of these questions is \emph{yes}.
\smallskip

We use our answers to these questions to construct a discrete maximum principle-preserving proximal Galerkin method for the advection-diffusion equation,
\begin{equation}
\label{eq:AdvectionDiffusionEquation}
	-\epsilon\Delta u + \beta\cdot\nabla u = f
	\quad \text{in~} \Omega,
	\qquad
	u = g \quad \text{on~} \partial\Omega
	\,,
\end{equation}
where $\epsilon > 0$ and $\beta \in \mathbb{R}^d$ are fixed, $f \in L^\infty(\Omega)$, and $g \in H^1(\Omega) \cap C(\overline{\Omega})$.
Along the way, we introduce the \emph{binary entropy} and a proximal algorithm for VIs with non-symmetric coercive bilinear forms.
The section closes with an implementable algorithm and a brief survey of numerical experiments.


\subsection{Binary entropy} \label{sub:binary_entropy}

In the previous section, we saw that if we wished to enforce a pointwise lower bound on the minimizer of the Dirichlet energy, we may consider a sequence of entropy-regularized energy minimization problems.
We now consider the situation of enforcing pointwise upper and lower bounds \emph{simultaneously}.
For simplicity, we illustrate the approach on the so-called double-obstacle problem.

Let $\phi_1, \phi_2 \in H^1(\Omega)\cap L^\infty(\Omega)$ with $\esssup (\phi_2 - \phi_1)  > 0$ and $\esssup \gamma(\phi_1 - g) < 0 < \essinf \gamma(\phi_2 - g)$, and consider minimizing the Dirichlet energy under the pointwise bound constraints $\phi_1 \leq v \leq \phi_2$.
More specifically,
\begin{equation}
\label{eq:DoubleObstacleProblem}
	u^\ast = \argmin_{v\in K} E(v)
	\,,
\end{equation}
where $E(v) = \frac{1}{2} \int_\Omega |\nabla v|^2 \dd x - \int_\Omega v f \dd x$ and $K = \{ v \in H^1_g(\Omega) \mid \phi_1 \leq v \leq \phi_2 \}$.
A natural way to apply entropy regularization to~\cref{eq:DoubleObstacleProblem} is revealed we rewrite it with two new variables $v_1 = v - \phi_1$ and $v_2 = \phi_2 - v$.
Doing so, we arrive at the equality-constrained optimization problem
\begin{equation}
	(u_1^\ast,u_2^\ast) = 
	\argmin_{(v_1,v_2) \in K_1\times K_2} E(v_1+\phi_1)
	~~\text{subject to~}
	v_1 + v_2 = \phi_2 - \phi_1
	\,,
\end{equation}
where $K_1 = \{ v_1 \in H^1_{g - \phi_1}(\Omega) \mid v_1 \geq 0 \}$ and $K_2 = \{ v_2 \in H^1_{\phi_2 - g}(\Omega) \mid v_2 \geq 0  \}$.
It can be readily verified that $u_1^\ast = u^\ast - \phi_1$ and $u_2^\ast = \phi_2 - u^\ast$.
Then, following our treatment of entropy regularization for pointwise non-negativity constraints in \Cref{sec:the_obstacle_problem}, it stands to consider the sequence $u^k = u_1^k - \phi_1 = \phi_1 - u_2^k \to u^\ast$ defined
\begin{subequations}
\begin{align}
\label{eq:DoubleObstacleEntropyRewriteA}
	(u_1^k,u_2^k) = 
	&\argmin_{(v_1,v_2) \in K\times K}
	\big\{
		E(v_1+\phi_1) + \alpha_k^{-1}\big(D(v_1, u_1^{k-1}) + D(v_2, u_2^{k-1})\big)
	\big\}
	\\
\label{eq:DoubleObstacleEntropyRewriteB}
	&\text{subject to~}
	v_1 + v_2 = \phi_2 - \phi_1
	\,.
\end{align}
\end{subequations}
We may now resubstitute $v_1 = v - \phi_1$ and $v_2 = \phi_2 - v$ into~\cref{eq:DoubleObstacleEntropyRewriteA}, which leads to
\begin{equation}
\label{eq:DoubleObstacleEntropy}
	u^k = \argmin_{v\in K} \big\{ E(v) + \alpha_k^{-1}D_B(v,u^{k-1})\big\}
	\,,
\end{equation}
where
\begin{equation}
\label{eq:RelativeBinaryEntropy}
	D_B(v,w)
	=
	\int_\Omega (v - \phi_1) \ln\Big| \frac{v - \phi_1}{w - \phi_1} \Big| + (\phi_2-v) \ln\Big| \frac{\phi_2-v}{\phi_2-w} \Big| \dd x
	,
\end{equation}
is the Bregman divergence of the (generalized) \emph{binary entropy}
\begin{equation}
\label{eq:NegativeBinaryEntropy}
	B(v)
	=
	\int_\Omega (v - \phi_1) \ln |v - \phi_1 | + (\phi_2-v) \ln |\phi_2-v| \dd x
		.
\end{equation}


The cases $(\phi_1,\phi_2) = (0,1)$ and $(\phi_1,\phi_2) = (-1,1)$ are somewhat special,
In the first of these,~\cref{eq:NegativeBinaryEntropy} is usually referred to as the (negative) Fermi--Dirac or {electronic} entropy \cite{teboulle2018simplified}.
As these particular upper and lower bounds will appear prominently later on, we also adopt special notation for the gradient and its inverse; namely,
\begin{equation}
	\nabla B(v) = \lnit v := \ln\frac{v}{1-v}
	\quad
	\text{and}
	\quad
	(\nabla B)^{-1}(v) = \sigmoid v := \frac{\exp v}{\exp v + 1}
	\,.
\end{equation}

The second case, $(\phi_1,\phi_2) = (-1,1)$, provides an explicit diffeomorphism between the $L^\infty(\Omega)$-unit ball, denoted $\mathcal{B}^\infty(\Omega) = \{ v \in L^\infty(\Omega) \mid \|v\|_{L^\infty(\Omega)} < 1 \}$, and the entire Banach algebra $L^\infty(\Omega)$.
More explicitly, we write
\begin{equation}
	\nabla B(v) = \atanh v
	\quad
	\text{and}
	\quad
	(\nabla B)^{-1}(v) = \tanh v
	\,,
\end{equation}
with the diffeomorphism illustrated visually in \Cref{fig:ExponentialMap2}.
For posterity, we also use this binary entropy function to define a canonical \emph{binary-entropic Poisson equation},
\begin{equation}
	-\Delta u + \atanh u = f
	\,,
\end{equation}
which follows from writing the strong form of the first-order optimality condition for~\cref{eq:DoubleObstacleEntropy} with $\phi_1 = -1$, $\phi_2 = 1$, $\alpha_k = 1$, and $u^{k-1} = 0$.

% Figure environment removed


\subsection{Variational inequalities with non-symmetric bilinear forms} \label{sub:non_symmetric_bilinear_forms}

In order to develop a proximal Galerkin method for the advection-diffusion equation~\cref{eq:AdvectionDiffusionEquation}, we require a continuous-level proximal algorithm for a more general class of VIs.
To this end, we propose a ``linearized'' version of~\cref{eq:BregmanProximalUpdate}.













































\medskip

\noindent\fbox{%
	\parbox{0.965\textwidth}{
        \begin{center}
        \smallskip
            \emph{\bfseries This is a ``working paper.''  The remainder of Section 5 will be included in a future edition.}
        \smallskip
        \end{center}
    }
}
\medskip




\section[Extensions II: Non-convex objective functions and a structure-preserving algorithm for topology optimization]{Extensions II: Non-convex objective functions and a structure-\linebreak{}preserving algorithm for topology optimization}
\label{sec:new_algorithms_for_topology_optimization}
The variational problems considered in the sections above share several common features. The most decisive feature is convexity. This raises the question as to whether entropy regularization can be as effective in a non-convex infinite-dimensional setting. We investigate this possibility here by providing a new proximal gradient (entropic mirror descent) framework for possibly non-convex, bounded-constrained optimization in infinite-dimensions. Our benchmark problem for this setting is a well-known problem in topology optimization.  
As before, the section closes with an explicit algorithm and a brief account of numerical experiments. In the interest of completeness, we recall several details from abstract mirror descent methods. Although these methods are widely used in finite-dimensional convex optimization, and much of our treatment is inspired by the more recent works  \cite{beck2003mirror,teboulle2018simplified}, it is important to note that Nemirovski and Yudin did not restrict themselves to finite dimensions in their original works many decades ago \cite{nemirovski1979effective,nemirovskij1983problem}.

\subsection{Mirror descent} \label{sub:entropic_mirror_descent}

\Cref{sub:proximal_point} introduced a proximal framework that was applied to solve the obstacle problem.
\Cref{sub:non_symmetric_bilinear_forms} introduced a linearized proximal framework to solve variational inequalities with non-symmetric bilinear forms.
The purpose of the present subsection is to combine those two approaches into a general first-order framework for non-convex optimization problems,
\begin{equation}
\label{eq:NonConvexModelProblem}
	\min_{v \in V}~ F(v)
	~~
	\text{subject to~}
	v \in K \subset V
	\,,
\end{equation}
where $K$ is a nonempty, closed convex subset of a Banach space $V$ and $F\colon V \to \mathbb{R}$ is continuously Fr\'echet differentiable.
We closely follow \cite{beck2003mirror,teboulle2018simplified} below to provide intuition for the method. In several places, we are purposely vague. This is particularly the case for the assumption that a Bregman divergence $D_G$ induced by the derivative $G'$ is available or that $\interior \dom G$ is non-empty with respect to the topology on $V$.

We begin by introducing the Bregman gradient step operator,
\begin{equation}
\label{eq:BregmanGradientStep}
	P_\alpha(w)
		=
	\argmin_{v\in V} \big\{ \langle F^\prime(w), v \rangle + \alpha^{-1} D_G(v,w) \big\}
	\,,
	\quad
	w \in \interior \dom G
	\,,
\end{equation}
where $G\colon \dom G \to \mathbb{R}\cup\{\infty\}$ is strongly convex with derivative $G'(w) \in V^\prime$. 
When $V$ is a Hilbert space and $G(v) = \frac{1}{2}\|v\|_V^2 = \frac{1}{2}(v,v)_V$, the gradient step operator is equivalent to the gradient descent rule.
Indeed, a straightforward computation of the first-order optimality criteria leads to
\begin{equation}
	P_\alpha(w)
		=
	w - \alpha \nabla F(w)
	\,,
\end{equation}
where $\nabla F\colon V \to V$ is the gradient of $F$ characterized by the variational equation
\begin{equation}
	(\nabla F(w),v)_V = \langle F^\prime(w), v \rangle
	~~
	\fa
	v \in V
	\,.
\end{equation}
More generally, assuming the minimizer exists and $G' : V \to V^\prime$ is invertible, \cref{eq:BregmanGradientStep} returns the formula
\begin{equation}\label{eq:bregman-prox-mirror}
	P_\alpha(w)
		=
	(G')^{-1} \big(G'(w) - \alpha F'(w)\big)
	\,.
\end{equation}
% Figure environment removed

Recalling the classical steepest descent method, see, e.g., \cite{nocedal1999numerical}, it is not surprisingly that iterating~\cref{eq:BregmanGradientStep} can generate a convergent algorithm to solve~\cref{eq:NonConvexModelProblem} when $K = V$.
Indeed, convergence of this algorithm is illustrated in~\cref{fig:MirrorPlot} for optimizing the  scalar objective function $e(x) = \frac{1}{2}x^2 + x$ with the Bregman divergence $D_s(x,x_k)$ from the scalar entropy function $s(x) = x\ln x - x$. This naturally leads to the so-called mirror descent method \cite{nemirovskij1983problem,beck2003mirror}, which given a sequence of positive step sizes $\{\alpha_k\}$, generates a sequence of iterates $\{u^k\}$ according to the following scheme:
\[
u^0 \in \interior \dom G, \quad u^{k+1} = P_{\alpha_{k+1}}(u^k), \quad k=0,1,2\ldots
\]
Nemirovski and Yudin point out that the motion of the iterates $\{u^k\}$, which takes place in the primal space $V$, is a ``shadow'' or ``image'', of the main motion: $G'(u^k) - \alpha_{k+1} F'(u^k)$, which by definition takes place in the dual space; whence the name ``method of mirror descent'' \cite[p. 88]{nemirovskij1983problem}.  This is easily witnessed by introducing a dual variable $\lambda := G'(w)$. Then under the assumptions that $G'$ is invertible, the new step in the dual space takes a somewhat more familiar form:
\[
\lambda^{k+1} = \lambda^k - \alpha_{k+1} (F'\circ (G')^{-1})(\lambda^{k}).
\]
This important distinction is often lost in finite dimensions and to some extent in the Hilbert space setting, where $G'$ and $F'$ are often identified with their Riesz representations in $V$; i.e., the gradients $\nabla G$ and $\nabla F$, respectively. 


\subsection{Mirror descent with a linear equality constraint}

For constrained problems, it is essential that $G$ properly captures the geometry of the feasible set, as was done in the previous sections on the obstacle problem and advection-diffusion equations.  Many problems of interest have the following form:
\begin{equation}
\label{eq:convex-intersection-problem}
	\min_{v \in K_1 \cap K_2} F(v)
	\,,
\end{equation}
where $K_1$ and $K_2$ are nonempty, closed convex subsets of $V$ and $F$ is differentiable. For example, suppose that $K = K_1$ is a nonempty, closed convex set and $K_2 := \left\{v \in V \left|\; \ell(v) = c\right.\right\}$ for some linear functional $\ell \in V^\prime$ and constant $c \in \mathbb R$; i.e., $K_2 = \ell^{-1}(\left\{c\right\})$. Furthermore, suppose that $D_G$ is a Bregman divergence associated with a distance generating function $G$, which is a Legendre function whose critical domain is linked to the properties of $K$. In this setting, rather than using \cref{eq:BregmanGradientStep}, we fix $\alpha > 0$ and define the operator 
\[
T_{\alpha}(w) := \argmin_{v \in K \cap  \ell^{-1}(\left\{c\right\})} \{ F(w) + \langle F'(w),v - w\rangle + \alpha^{-1}D_{G}(v,w) \}
\,.
\]
We assume here that $D_{G}(\cdot,w)$ over $K \cap  \ell^{-1}(\left\{c\right\})$ has all the properties needed to ensure $T_{\alpha}$ is single-valued. Using standard optimality theory, e.g., \cite{ioffe2009theory}, we can argue that $u := T_{\alpha}(w)$ satisfies the inclusion
\begin{equation}\label{eq:fo-inclusion}
0 \in \alpha F'(w) + G'(u) - G'(w) + \mathcal{N}_{K \cap  \ell^{-1}(\left\{c\right\})}(u),
\end{equation}
where  $\mathcal{N}_{K \cap  \ell^{-1}(\left\{c\right\})}(u)$ is the normal cone from convex analysis \cite{ioffe2009theory}, defined by
\[
 \mathcal{N}_{K \cap  \ell^{-1}(\left\{c\right\})}(u) := \left\{
 \lambda \in V^\prime \left|\;
 \langle \lambda, v - u \rangle \le 0
 \quad \forall v \in K \cap  \ell^{-1}(\left\{c\right\})
 \right.
 \right\}
 .
\]
Note that if $w = T_{\alpha}(w)$, then \cref{eq:fo-inclusion} reduces to 
\[
0 \in \alpha F'(w) + \mathcal{N}_{K \cap  \ell^{-1}(\left\{c\right\})}(w),
\]
which indicates that $w$ is a first-order stationary point of \cref{eq:convex-intersection-problem}.

If we furthermore assume that $K$ contains a subset $\mathcal{B}$ such that $\ell(\mathcal{B}) \subset (c-\epsilon,c+\epsilon)$, then $\{c\} - \ell(K)$ contains an open neighborhood of $0$. This constraint qualification \cite{ioffe2009theory} allows us to rewrite \cref{eq:fo-inclusion} as
\begin{equation}\label{eq:fo-inclusion-refine}
0 \in \alpha F'(w) + G'(u) - G'(w) + \mathcal{N}_{K}(u) +  \mathcal{N}_{\left\{c\right\}}(\ell(u)) \circ \ell,
\end{equation}
where $\mathcal{N}_{\left\{c\right\}}(\ell(u)) \circ \ell = \left\{ \mu \ell \in V' \left| \mu \in \mathbb R\right.\right\}$ provided $\ell(u) = c$.
Continuing on, we may assume for the sake of argument that the use of $D_{G}$ forces $\mathcal{N}_{K}(u) = \{0\}$. This happens, for example, if
$u$ remains away from the boundary of $K$. For pointwise bound constraints in $L^p$-spaces of the type $0 \le u \le 1$ considered below, we would also have $\mathcal{N}_{K}(u) = \left\{0\right\}$ when $0 < u < 1$ almost everywhere, even if the set $K$ does not have a non-empty interior. The remaining normal cone is trivial to compute and yields $\mathcal{N}_{\left\{c\right\}}(\ell(u)) = \mathbb R$.

These observations justify the following first-order optimality system that characterizes the map $w \mapsto u := T_{\alpha}(w)$: Find $(u,\mu) \in K \times \mathbb R$ such that 
\begin{equation}\label{eq:fo-order-mult-eq}
u = (G')^{-1}(G'(w) - \alpha F'(w) + \mu \ell) \text{ and } \ell(u) = c.
\end{equation}
In other words, given $w$ and $\alpha$, compute the increment $\widetilde{\lambda} := G'(w) - \alpha F'(w)$ and find $\mu \in \mathbb R$ by solving the equation 
\[
\ell( (G')^{-1}(\widetilde{\lambda} + \mu \ell)) = c.
\] 
Repeating the process
\[
u^0 \in \interior \dom G, \quad u^{k+1} = T_{\alpha_{k+1}}(u^k), \quad k=0,1,2\ldots
\]
generates a sequence of dual variables. Indeed, given a sequence of positive step sizes $\left\{\alpha_k\right\}$, we can generate $\left\{\lambda^k\right\}$ according to \Cref{alg:half-step-dual-update}.


\begin{algorithm2e}[H]
\DontPrintSemicolon
	\caption{\label{alg:half-step-dual-update} 
	Half-step mirror descent rule in Banach space
	}
	\SetKwInOut{Input}{Input}
	\SetKwInOut{Output}{Output}
	\BlankLine
	\Input{
	Initial dual variable $\lambda^0 \in V^\prime$ and sequence of step sizes $\alpha_k>0$.}
		\Output{Stationary dual variable $\overline{\lambda}$.}
	\BlankLine
	Initialize $k = 0$.\;
	\Repeat{a convergence test is satisfied}
	{
				\tcp*[l]{Dual space half step (gradient descent)}
		Assign  $\lambda^{k+1/2} \leftarrow  \lambda^{k} - \alpha_{k+1} (F' \circ (G')^{-1})(\lambda^k)$.\;
		\tcp*[l]{Compute Lagrange multiplier}
		Solve for $\mu^{k+1} \in \mathbb R$ such that $\ell( (G')^{-1}(\lambda^{k+1/2} + \mu^{k+1} \ell)) = c$.\;
		\tcp*[l]{Dual space feasibility correction}
		Assign  $\lambda^{k+1} \leftarrow  \lambda^{k+1/2} + \mu^{k+1}\ell$.\;
		Assign $k \leftarrow k+1$.\;
	}
\end{algorithm2e}

The pre-image of $G'$ is tacitly assumed to be contained in $K$. Therefore, the abstract scheme \Cref{alg:half-step-dual-update} theoretically provides a sequence of feasible primal iterates 
\[
u^{k+1} := (G')^{-1}(\lambda^{k+1/2} + \mu^{k+1} \ell). 
\]
Checking for optimality is rather difficult in general, as the evaluation of the residual of first-order optimality conditions may require the computation of a projection operator in non-trivial settings; recall the discussion in  \Cref{rem:ProximalMap} above. On the other hand, we demonstrated above that fixed points of $T_{\alpha}$ are stationary for the original problem. This motivates the simple stopping rule: $\| T_{\alpha_{k+1}}(u^k) - u^k \|_{V} < \mathtt{tol.}$, with $\mathtt{tol.} > 0$ sufficiently small, or some variant using absolute and relative tolerances. However, in order to remove the influence of $\alpha_k$, which will typically change with $k$, we advocate for rescaling the fixed point residual and also consider the relative quantities 
\[
\eta_{k} := \| T_{\alpha_{k+1}}(u^k) - u^k \|_{V}/\alpha_{k+1} =   \| u^{k+1}- u^k \|_{V}/\alpha_{k+1}.
\]
In the unconstrained, Hilbert-space setting, we have $\eta_{k} = \| \nabla F(u^k) \|_{V}$. Therefore, if $\liminf_{k} \eta_{k} \to 0$, then $\liminf_{k} \| \nabla F(u_k) \|_{V} = 0$; i.e., we get a limiting stationarity condition. For example, 
if $\{u^{k+1} - u^k\}$ is a null sequence in $o(\alpha_k)$ for $\alpha_k \downarrow 0$, then clearly $\eta_k \downarrow 0$. We therefore also use $\eta_k$ as a heuristic stopping measure in our experiments below.
 
The abstract derivation above yields an iterative scheme in the dual space $V^\prime$. Implementing finite-dimensional approximations of negative-order Sobolev spaces can be challenging. However, the bound-constrained variational problem we have considered happens to have a substantial degree of useful structure, and entropy regularization of the associated bound constraints provides us with representations of $G'$, $G'^{-1}$ and $\ell$ that lead to a latent space reformulation of \Cref{alg:half-step-dual-update} that is readily treated with finite elements.







		

\subsection{An entropic mirror descent algorithm for topology optimization} \label{sub:top_opt_algorithm}
We consider the benchmark topology optimization problem of elastic compliance optimization of a cantilever beam; see, e.g., \cite{andreassen2011efficient}.
In particular, we use the two-field filtered density approach to topology optimization \cite[Section~3.1.2]{sigmund2013topology} to formulate the optimal cantilever beam problem.

\begin{subequations}
\label{eqs:elastic_compliance}
The purpose of the problem is to find a material density $0 \leq \rho \leq 1$, where zero indicates no material, and one indicates the complete presence of material, that induces a minimal elastic compliance, $\widehat{F}(\mathbf{u},\rho) = \int_{ \Omega} \mathbf{u}\cdot\mathbf{f} \dd \bm{x}$.
In this expression, the displacement $\mathbf{u} = \mathbf{u}(\rho)$ is determined by a variable material density $\rho$ and a fixed body force $\mathbf{f}$ through the classical linear elasticity equation \cite{marsden1994mathematical}, $-\mathrm{Div} \big( r(\tilde{\rho})\,\bm{\sigma} \big) = \mathbf{f}$.
In this equation, we are meant to understand that
\begin{equation}
\label{eq:elastic_compliance_cauchy_stress}
	\bm{\sigma}(\mathbf{u}) = \lambda \div(\mathbf{u})I + \mu(\nabla \mathbf{u} + (\nabla \mathbf{u})^\top)
	\,,
\end{equation}
with Lam\'e parameters $\lambda,\,\mu > 0$, is the Cauchy stress of a homogeneous, isotropic material, $\mathrm{Div}(\cdot)$ denotes the row-wise divergence operator, $\tilde{\rho}$ is a regularized (filtered) density function \cite{bruns2001topology,lazarov2011filters}, and $r(\tilde{\rho}) > 0$ is a local model for the Young's modulus.
For our work, we use the well-known (modified) solid isotropic material penalization (SIMP) model $r(\tilde{\rho}) = \underline{\rho} + \tilde{\rho}^3 (1-\underline{\rho})$, where $0<\underline{\rho} \ll 1$ is a nominal constant assigned to void regions in order to prevent the stiffness matrix from becoming singular \cite{andreassen2011efficient}.

The full problem formulation is written as follows:
\begin{equation}
\label{eq:elastic_compliance_objective}
    \min_{\rho \in L^1(\Omega)} \ \
    \bigg\{
    \,
    \widehat{F}(\mathbf{u},\rho)
    =
    \int_{ \Omega} \mathbf{u}\cdot\mathbf{f} \dd \bm{x}
    \,
    \bigg\}
    \, ,
\end{equation}
subject to the constraints
\begin{equation}
\label{eq:elastic_compliance_constraints}
\left\{\,\,
\begin{gathered}
    -\mathrm{Div} \big( r(\tilde{\rho})\,\bm{\sigma} \big) = \mathbf{f}
    ~~ \text{in }\Omega
    \quad\text{with}\quad
    \mathbf{u} = 0
    ~~\text{on }\Gamma_0
    \,,
    \quad
    \bm{\sigma} \mathbf{n} = 0
    ~~ \text{on }\partial\Omega \setminus \Gamma_0
    \,,
    \\
    -\epsilon^2\Delta \tilde{\rho} + \tilde{\rho}
	= \rho
	~~ \text{in }\Omega
	\quad\text{with}\quad
	\nabla \tilde{\rho}\cdot \mathbf{n} = 0
	~~ \text{on }\partial\Omega
    \,,
    \\
    \int_\Omega \rho(\bm{x}) \dd\bm{x}
    = \theta |\Omega|
    \,,\quad
    0 \leq \rho
    \leq 1
    \,,\quad
    r(\tilde{\rho})
    = \underline{\rho}+ \tilde{\rho}^3 (1-\underline{\rho})
    \,,
\end{gathered}
\right.
\end{equation}
\end{subequations}
where $\epsilon > 0$ is a \emph{length scale} and $0 < \theta < 1$ is the desired \emph{volume fraction}, which constrains the amount of the domain $\Omega$ occupied by the design.
The design domain $\Omega$ and associated boundary conditions are depicted in \Cref{fig:ElasticCompliance_mesh}.
% Figure environment removed
We defer a rigorous mathematical discussion to the literature and simply note that it can be shown that $\mathbf{u}$ can be understood, via $\widetilde{\rho}$, as a differentiable mapping from $\rho$ into an 
appropriate regularity space; e.g., a subspace of $[H^1(\Omega)]^2$. Therefore, we replace the objective function in~\cref{eq:elastic_compliance_objective} by the reduced functional
\begin{subequations}
\begin{equation}
F(\rho) := \widehat{F}(\mathbf{u}(\rho),\rho)
\end{equation}
and arrive at the reduced space optimization problem
\begin{equation}\label{eq:reduced-to}
\aligned
	&\min_{\rho \in L^1(\Omega)} F(\rho)
	~~
			\text{subject to~} 0 \leq \rho \leq 1
	~\text{and}~
	\int_\Omega \rho \dd x = \theta |\Omega|
	\,.
\endaligned
\end{equation}
\end{subequations}
We can now solve this problem with a custom version of \Cref{alg:half-step-dual-update} that employs the binary entropy-based Bregman divergence for the pointwise bound constraints found in~\cref{eq:reduced-to}; cf.~\Cref{sub:binary_entropy}.
In particular, the favorable structure of this problem 
lends itself nicely to a \textit{latent space} representation, given below, that makes use of the transformations
\[
\rho^{k} = \sigmoid(\psi^{k}) \quad \iff \quad \psi^k = \lnit(\rho^k),
\]
as well as the following variational characterization of the gradient $\nabla F(\rho^k)$:
\begin{equation}
\label{eq:TopOpt_VariationalCharacterizationOfTheGradient}
	\left\{
	\begin{aligned}
		\,&\text{Find}~
		\nabla F(\rho^k) := \tilde{w} \in H^1(\Omega)
		\text{~such that}
		\\
		&
		\epsilon^2(\nabla \tilde{w}, \nabla v) + (\tilde{w},v)
		=
		-(r^\prime(\tilde{\rho}^k)\, \bm{\sigma}(\mathbf{u}^k):\nabla u^k , v)
				~\fa v \in H^1(\Omega)
		\,.
	\end{aligned}
	\right.
\end{equation}
An visual representation of a single iteration of \Cref{alg:TopologyOptimization} is given in~\Cref{fig:ProjectedMirrorDescent}.

{
\makeatletter
\makeatother
\begin{algorithm2e}[H]
\DontPrintSemicolon
	\caption{\label{alg:TopologyOptimization}
	Entropic mirror descent for topology optimization.
	}
	\SetKwInOut{Input}{Input}
	\SetKwInOut{Output}{Output}
	\BlankLine
	\Input{
	Initial latent variable $\rho^0 \in L^\infty(\Omega)$, sequence of step sizes $\alpha_k>0$, increment tolerance $\mathtt{itol.} > 0$, and normalized tolerance $\mathtt{ntol.} > 0$.}
	\Output{Optimized material density $\overline{\rho} = \sigmoid(\psi^k)$.}
	\BlankLine
	Initialize $k = 0$.\;
	\While{$\|\sigmoid(\psi^k) - \sigmoid(\psi^{k-1})\|_{L^1(\Omega)} > \min\{\alpha_k\, \mathtt{ntol.},\mathtt{itol.}\}$}
		{
		\tcp*[l]{Latent space gradient descent}
		Assign $\psi^{k+1/2} \leftarrow  \psi^{k} - \alpha_{k+1} \nabla F(\sigmoid(\psi^k))$.\;
		\tcp*[l]{Compute Lagrange multiplier}
		Solve for $c \in \mathbb R$ such that $\int_\Omega \sigmoid(\psi^{k+1/2} + c) \dd x = \theta |\Omega|$.\;
		\tcp*[l]{Latent space feasibility correction}
		Assign $\psi^{k+1} \leftarrow  \psi^{k+1/2} + c$.\;
		Assign $k \leftarrow k+1$.\;
	}
\end{algorithm2e}}

% Figure environment removed





\subsection{Numerical experiments} \label{sub:numerical_experiments_topopt}





In this set of experiments, we estimate the gradients $\nabla F(\rho^k)$ in~\Cref{alg:TopologyOptimization} by discretizing \cref{eq:TopOpt_VariationalCharacterizationOfTheGradient} with $C^0(\Omega)$-conforming, quadrilateral finite elements of degree $p\geq 1$.
Likewise, the discrete displacements $\mathbf{u}_h^k \approx \mathbf{u}^k$ and filtered densities, $\tilde{\rho}_h^k \approx \tilde{\rho}^k$, are also computed with conforming finite elements of degree $p$.
Finally, unlike the physical variables above, the latent variable $\psi^k$ is approximated by {discontinuous} piecewise polynomials $\psi^k_h$ of degree $p-1$.
Note that this induces a discontinuous primal variable $\rho^k_h := \sigmoid(\psi^k_h)$ satisfying $0 < \rho^k_h < 1$; see also \Cref{rem:TopOpt_DiscreteBoundConstraints}.
We then apply the resulting discretized version of \Cref{alg:TopologyOptimization} to solve~\cref{eqs:elastic_compliance} with $\underline{\rho} = 10^{-6}$, $\lambda=\mu = 1$, $\theta = 0.5$, and $\epsilon = 0.02$.
The open-source code to reproduce this set of experiments can be found at \cite{Keith2023TopOptCode}.
For sake of space, we have focused on presenting results with low-order discretizations (i.e., $p = 1,2$) of the above form and left the exploration of higher-order discretizations to future work.

% Figure environment removed

A sequence of iterates converging to a discrete solution with mesh size $h = h_0/128$ and polynomial degree $p = 1$ are depicted in \Cref{fig:ElasticCompliance_sequence}.
From this figure, we observe typical first-order convergence behavior to a standard truss-like structure.
To generate this figure, we used the heuristic step size sequence $\alpha_k = 25 k$ and tolerances $\mathtt{itol.} = 10^{-2}$ and $\mathtt{ntol.} = 10^{-5}$.
Although the conventional wisdom from finite-dimensional optimization theory would indicate that
$\alpha_k$ should tend to zero, or at the very least be less than the reciprocal of the Lipschitz constant of $\nabla F$, 
our experiments indicate that we can moderately increase the step sizes and still obtain satisfactory convergence
behavior. To be fair, ``satisfactory'' convergence is based on the heuristic stopping rule given in~\Cref{alg:TopologyOptimization}.


Future work is needed to develop an adaptive step size selection procedure. 
In turn, we include \Cref{fig:ElasticCompliance} to show the different effects the step size sequence can have on the final solution.
Here, we witness that different sequences --- e.g., $\alpha_k = 10k$, $\alpha_k = 25k$, and $\alpha_k = 50k$ --- can lead~\Cref{alg:TopologyOptimization} to converge to significantly different local optima.
This class of non-convex optimization problems is widely known to exhibit multiple local optima, though procedures are available to compute them \cite{papadopoulos2021computing}.
In particular, notice from the two top left images that different final designs are possible just by changing the step size rule.
The suspicious design on the bottom left is found because the $\alpha_k = 50k$ step size rule is too aggressive in the early iterations.
Thereafter, a ``design locking'' phenomenom that is common in topology optimization problems keeps the design close to its nearly-binary, early state.
To generate the results in \Cref{fig:ElasticCompliance}, we changed the length scale to $\epsilon = 10^{-2}$ because it invokes a higher parameter sensitivity.

% Figure environment removed


Finally, we return to the case considered in \Cref{fig:ElasticCompliance_sequence} (i.e., we again set $\epsilon = 2\cdot 10^{-2}$ and $\alpha_k = 25k$) to record the sequence of error indicators $\eta_k = \|\rho_h^{k} - \rho_h^{k-1}\|_{L^1(\Omega)}/\alpha_k$ with different discretization parameters $h \in \{ h_0/64 , h_0/128 , h_0/256 \}$ and $p \in \{ 1 , 2 \}$.
The results are given in~\Cref{tab:TopOptMeshIndependence}.
From these results, we see that number of iterations required to reach the tolerance $\|\rho_h^{k} - \rho_h^{k-1}\|_{L^1(\Omega)}/\alpha_k < 10^{-5}$ tends to a fixed value as the mesh is refined or the polynomial order is elevated.
Moreover, the individual values of $\eta_k$ appear to stabilize as $h \to 0$, for both $p = 1,2$.
Both of these properties suggest \emph{mesh-independence} of \Cref{alg:TopologyOptimization}.

\begin{table}
\centering
\footnotesize
\renewcommand{\arraystretch}{1.3}
\begin{tabular}{ |c|c|c|c|c|c|c| }
 \hhline{|>{\arrayrulecolor{white}}-->{\arrayrulecolor{black}}|-----|}
 \multicolumn{2}{c|}{} & \multicolumn{5}{c|}{\cellcolor{lightgray!15} \small\raisebox{5pt}{\vphantom{f}}Optimization error $\|\rho_h^{k} - \rho_h^{k-1}\|_{L^1(\Omega)}/\alpha_k$ for various $h$ and $p$}\\[3pt]
 \hhline{|>{\arrayrulecolor{white}}-->{\arrayrulecolor{black}}|-----|}
 \multicolumn{2}{c|}{}& \multicolumn{3}{c|}{\cellcolor{lightgray!05} Polynomial order $p = 1$} & \multicolumn{2}{c|}{\cellcolor{lightgray!10} Polynomial order $p = 2$}\\
 \hline
 \rowcolor{lightgray!15}
 $k$ & $\alpha_{k}$ & $h_0/64$ & $h_0/128$ & $h_0/256$ & $h_0/64$ & $h_0/128$ \\
 \hline
\cellcolor{lightgray!05}   1 & \cellcolor{lightgray!01} $25$  & $2.00\cdot 10^{-2}$  & $2.06\cdot 10^{-2}$  & $2.05\cdot 10^{-2}$  & $2.07\cdot 10^{-2}$  & $2.05\cdot 10^{-2}$ \\
\cellcolor{lightgray!05}   2 & \cellcolor{lightgray!01} $50$  & $5.42\cdot 10^{-3}$  & $5.80\cdot 10^{-3}$  & $5.76\cdot 10^{-3}$  & $5.88\cdot 10^{-3}$  & $5.74\cdot 10^{-3}$ \\
\cellcolor{lightgray!05}   3 & \cellcolor{lightgray!01} $75$  & $2.97\cdot 10^{-3}$  & $3.30\cdot 10^{-3}$  & $3.27\cdot 10^{-3}$  & $3.38\cdot 10^{-3}$  & $3.25\cdot 10^{-3}$ \\
\cellcolor{lightgray!05}   4 & \cellcolor{lightgray!01} $100$ & $1.61\cdot 10^{-3}$  & $1.87\cdot 10^{-3}$  & $1.85\cdot 10^{-3}$  & $1.94\cdot 10^{-3}$  & $1.83\cdot 10^{-3}$ \\
\cellcolor{lightgray!05}   5 & \cellcolor{lightgray!01} $125$ & $1.12\cdot 10^{-3}$  & $1.30\cdot 10^{-3}$  & $1.29\cdot 10^{-3}$  & $1.36\cdot 10^{-3}$  & $1.28\cdot 10^{-3}$ \\
\cellcolor{lightgray!05}   \vdots & \cellcolor{lightgray!01}   \vdots & \vdots  & \vdots & \vdots  & \vdots & \vdots \\
 \hline
 \rowcolor{lightgray!05}
 \multicolumn{2}{|c|}{\cellcolor{lightgray!15} Total iterations} & $30$ & $29$ & $29$ & $29$ & $29$ \\
 \hline
 \rowcolor{lightgray!05}
 \multicolumn{2}{|c|}{\cellcolor{lightgray!15} Final compliance $F(\overline{\rho}_h)$} & $3.86\cdot 10^{-3}$ & $4.04\cdot 10^{-3}$ & $4.02\cdot 10^{-3}$ & $4.08\cdot 10^{-3}$ & $4.01\cdot 10^{-3}$ \\
 \hline
\end{tabular}
\caption{\label{tab:TopOptMeshIndependence}
Table of error estimates $\eta_k = \|\rho_h^{k} - \rho_h^{k-1}\|_{L^1(\Omega)}/\alpha_k$ for various mesh sizes $h$ and polynomial orders $p$.
The initial density was set to the constant function $\rho_h^0 = \theta$ (i.e., $\psi_h^0 = \lnit\theta$) at the beginning of each run and each run was stopped once $\eta_k < 10^{-5}$.
These results were obtained using the problem parameters $\epsilon = 2\cdot 10^{-2}$ and $\theta = 0.5$.
}
\end{table}

\begin{remark}[Preserving pointwise bound constraints at the discrete level]
\label{rem:TopOpt_DiscreteBoundConstraints}
No matter the polynomial degree $p \geq 1$, the discrete primal variable $\rho^k_h = \sigmoid(\psi^k_h)$ is guaranteed to satisfy the pointwise bound constraint $0 \leq \rho^k_h \leq 1$.
This is an immediate consequence of the sigmoid map $\sigmoid\colon \mathbb{R} \to (0,1)$ and the decision to discretize the \textit{latent variable} with finite elements.
Had we followed the literature and, instead, directly discretized the primal variable $\rho^k$ with finite elements, then the property $0 \leq \rho^k_h \leq 1$ would have to be enforced by introducing discrete-level pointwise bound constraints.
This is a common concern in standard topology optimization approaches since the number of discrete-level pointwise bound constraints must grow with the size of the finite element space; cf.~\Cref{sub:bound_constrained_finite_element_methods}.
\end{remark}





\appendix

\section{Mathematical results I: Lie groups, entropy regularization, and semilinear PDEs} \label{sec:preliminaries}

This appendix contains proofs and continuous-level structural results supporting the main sections of the paper.

\subsection[Structural results on the set]{Structural results on the set $\interior L^\infty_+(\Omega)$}\label{sub:GroupTheory}

The following concepts and results are not commonly used in the finite element literature.
Although they can be derived from diverse sources, such as \cite{conway2019course,borwein1994strong,glockner2002algebras}, we assemble them here for the readers convenience.

\begin{definition}
\label{def:units}
	Let $\mathcal{X}$ be a semiring equipped with two binary operations: addition $\oplus \colon \mathcal{X} \times \mathcal{X} \to \mathcal{X}$ and multiplication $\odot \colon \mathcal{X} \times \mathcal{X} \to \mathcal{X}$.
	An element $u$ of $\mathcal{X}$ is called a unit if there exists an inverse element in $\mathcal{X}$, denoted $\frac{1}{u}$, such that $u \odot \frac{1}{u} = \frac{1}{u} \odot u = 1$.
	The group of units of $\mathcal{X}$, denoted $\mathcal{X}^\times$, is the set of all units in $\mathcal{X}$.
\end{definition}



This work is largely centered around the group of units $(L^\infty_+(\Omega))^\times$.
We prove $(L^\infty_+(\Omega))^\times = \interior L^\infty_+(\Omega)$, along with several other algebraic/topological identities, at the end of this subsection; see~\Cref{prop:Equivalence}.

It is well-known that algebraic and topological structures are often entwined, as the following definition and result shows.
\begin{definition}
\label{def:BanachAlgebra}
			A Banach algebra is a complete normed vector space that is closed under multiplication.
	\end{definition}
\begin{proposition}
	For any Banach algebra $\mathcal{X}$, its group of units $\mathcal{X}^\times$ is open.
	Moreover, the inversion map $\mathcal{X}^\times \to \mathcal{X}^\times \colon u \mapsto \frac{1}{u}$ is continuous.
\end{proposition}
\begin{proof}
	See \cite[Thm 2.2, p.~192]{conway2019course}.
\end{proof}
Notably, this result also implies that $\interior L^\infty_+(\Omega)$ is a Banach--Lie group.
\begin{definition}
\label{def:BanachLieGroup}
	A Banach manifold is a topological space $\mathcal{M}$ where each point $u \in \mathcal{M}$ has an open neighbourhood that is homeomorphic to an open set in a Banach space.
	A set $\mathcal{G}$ is a Banach--Lie group if it is a Banach manifold that is closed under continuous multiplication and inversion operations.
\end{definition}

An important property of Lie groups is the existence of a smooth exponential map, $\exp\colon \mathcal{X} \to \mathcal{G}$, where $\mathcal{X}$ is the associated Lie algebra; cf.~\cite{lee2012introduction}.
\begin{definition}
\label{def:BanachLieAlgebra}
	A Lie algebra $\mathcal{X}$ is a vector space endowed with an antisymmetric bilinear form called the Lie bracket $[\cdot,\cdot] \colon \mathcal{X}\times \mathcal{X} \to \mathcal{X}$ satisfying the Jacobi identity $[\psi,[\varphi,\omega]] + [\varphi,[\omega,\psi]] + [\omega,[\psi,\varphi]] = 0$ for all $\psi,\varphi,\omega \in \mathcal{X}$.
	A set $\mathcal{X}$ is Banach--Lie algebra if it is both a Lie algebra and a Banach space.
\end{definition}

Using well-known results on Nemytskii operators between Lebesgue spaces, we can argue that $L^{\infty}(\Omega)$ is the Banach--Lie algebra associated to the Banach--Lie group $\interior L^\infty_+(\Omega)$; cf.~\Cref{prop:Equivalence}.
In particular, as a result of \Cref{lem:ExponentialMap}, the Nemytskii operator generated by the standard exponential function on $\mathbb R$ provides the exponential map from $L^{\infty}(\Omega)$ to $\interior L^\infty_+(\Omega)$.
Moreover, this map is surjective and, thus, the inverse of the entropy gradient $(\nabla S)^{-1} = \exp \colon L^{\infty}(\Omega) \to \interior L^\infty_+(\Omega)$ is a group isomorphism.
Finally, in our setting, $\interior L^\infty_+(\Omega)$ is commutative and so the Lie bracket is trivial; i.e., $[\psi,\varphi] = \psi\varphi - \varphi\psi = 0$ for all $\psi,\varphi \in L^\infty(\Omega)$.



\begin{lemma}\label{lem:ExponentialMap}
	The Nemytskii operator $\psi \mapsto \exp\psi$ is infinitely continuously Fr\'echet differentiable on $L^\infty(\Omega)$.
	\end{lemma}
\begin{proof}
	We first observe several crucial properties of the exponential function that carry over to the Nemytskii operator. Let $c > 0$ and fix $x \in [-c,c]$. 
		 By monotonicity we have $|\exp(x)| \le \exp(c)$. 
	Hence, for all $c > 0$, there exists $k(c)$ such that $|\exp(x)| \le k(c)$ for all $x \in [-c,c]$. By \cite[Theorem 1 (iv)]{goldberg1992nemytskij}, the Nemytskii operator maps $L^{\infty}$ into itself. Similarly, for $c, \varepsilon > 0$ we define $\delta(c,\varepsilon) = \varepsilon/\exp(c)$ and observe that for all $x,y \in \mathbb R$ such that $|x| \le c$, $|y| \le c$, and $|x - y| < \delta(c,\varepsilon)$ we have $|\exp(x) - \exp(y)| < \varepsilon$. Then by \cite[Theorem 5]{goldberg1992nemytskij}, the Nemytskii operator is continuous from $L^{\infty}$ into itself. Finally, since $\exp(x)$ is infinitely continuously differentiable with $\exp'(x) = \exp(x)$ for all $x \in \mathbb R$ these results carry over to the Nemytskii operators defined by the pointwise derivatives. We may then apply \cite[Theorem 7]{goldberg1992nemytskij} to argue that the Nemytskii operator is infinitely continuously Fr\`echet differentiable from $L^{\infty}$ into itself.
\end{proof}

\Cref{prop:Equivalence} summarizes various useful interpretations of the set $\interior L^\infty_+(\Omega)$.
See also \Cref{rem:HigherRegularityDiffeomorphism}.

\begin{proposition}
\label{prop:Equivalence}
	Nemytskii operator $\psi \mapsto \exp\psi$ is a $C^1$-diffeomorphism between $L^{\infty}(\Omega)$ and $\interior L^\infty_+(\Omega)$ for which the following definitions are equivalent:
	\begin{subequations}\label{eq:glequivs}
	\begin{enumerate}[label=(\alph*)]
		\item $\interior L^{\infty}_+(\Omega)$ is the set of all positive functions in $L^{\infty}(\Omega)$ whose reciprocals lie in $L^{\infty}(\Omega)$,
		\begin{equation}
			\interior L^{\infty}_+(\Omega) = \{ w \in L^{\infty}(\Omega) \mid 1/w \in L^{\infty}(\Omega) ~\text{and}~ w > 0 \}. \label{eq:glequivs1}
		\end{equation}
		In other words, $\interior L^{\infty}_+(\Omega) = (L^{\infty}_+(\Omega))^\times$ is the group of units in $L^{\infty}_+(\Omega)$.
		\item $\interior L^{\infty}_+(\Omega)$ is the set of all functions in $L^{\infty}(\Omega)$ whose logarithm is bounded in $L^{\infty}(\Omega)$,
		\begin{equation}
			\interior L^{\infty}_+(\Omega) = \ln^{-1}(L^{\infty}(\Omega)). \label{eq:glequivs2}
		\end{equation}
		\item $\interior L^{\infty}_+(\Omega)$ is the image of $L^\infty(\Omega)$ under the exponential map,
		\begin{equation}
			\interior L^{\infty}_+(\Omega) = \exp(L^\infty(\Omega)). \label{eq:glequivs3}
		\end{equation}
		\item $\interior L^{\infty}_+(\Omega)$ is the set of all positive functions in $L^{\infty}(\Omega)$ that are strictly bounded away from zero,
		\begin{equation}
			\interior L^{\infty}_+(\Omega) = \{ w \in L^{\infty}(\Omega) \mid \text{there exists~} \epsilon > 0 \text{~such that~} w > \epsilon \}. \label{eq:glequivs4}
		\end{equation}
	\end{enumerate}
	\end{subequations}
\end{proposition}
\begin{proof}
	We begin by proving the equivalence of \crefrange{eq:glequivs1}{eq:glequivs4}. 
	We leave off the dependence on $\Omega$ in the following arguments for readability and begin with \cref{eq:glequivs4}. If $u \in L^{\infty}$ such that there exists $\epsilon > 0$ with $u > \epsilon$ a.e.\ on $\Omega$, then for any $w \in L^{\infty}$ such that $\| u - w \|_{L^{\infty}} < \epsilon/2$ we have $\epsilon/2 < u - \epsilon/2 < w$. Thus, $w \in L^{\infty}_{+}$ and, consequently, $u \in \interior L^{\infty}_+$. Now suppose $u \in L^{\infty}_{+}$ and for every $\epsilon > 0$, the set
$
\mathcal{B}_{\epsilon} := \left\{x \in \Omega \left|\; 0 < u(x) < \epsilon/2 \right.\right\}
$
has positive Lebesgue measure. Then for all $\epsilon > 0$, the open ball
$
\left\{ v \in L^{\infty} : \| u - v \|_{L^{\infty}} < \epsilon \right\}
$
contains the function $v = u-\epsilon/2$ on $\mathcal{B}_{\epsilon}$ and $v = u$ on $\Omega \setminus \mathcal{B}_{\epsilon}$, which is clearly not in $L^{\infty}_+$. Hence, every open ball of radius $\epsilon > 0$ around $u$ contains a point outside $L^{\infty}_+$, i.e., $u \in \bd L^{\infty}_+ = L^{\infty}_+ \setminus \interior L^{\infty}_+$. This proves \cref{eq:glequivs4}.

Next, let $u \in \interior L^{\infty}_+$. By \cref{eq:glequivs4} there exists $\epsilon > 0$ such that $\infty > \| u \|_{L^{\infty}} \ge u > \epsilon$. Then, by continuity on $\mathbb R_{++}$, the mapping $u \mapsto 1/u$ preserves measurability and $1/u \in [1/\| u \|_{L^{\infty}}, 1/\epsilon]$.  Hence, $u > 0$ and $ 1/u \in L^{\infty}$. Conversely, suppose $u \in L^{\infty}$ such that $u > 0$ and $1/u \in L^{\infty}$. Then $0 < 1/u \le \|1/u\|_{L^{\infty}}$ and $0 < u \le \|u\|_{L^{\infty}}$ imply $u \in [\| 1/u \|^{-1}_{L^{\infty}},\| u \|_{L^{\infty}}]$ a.e.\ on $\Omega$. It follows from \cref{eq:glequivs4} that $u \in  \interior L^{\infty}_+$. This proves \cref{eq:glequivs1}.
	
	Next, suppose that $ u \in \interior L^{\infty}_+$. Then by  \cref{eq:glequivs1}, we have $u \in [\| 1/u \|^{-1}_{L^{\infty}},\| u \|_{L^{\infty}}]$ a.e. Consequently, the continuity and monotonicity of the natural logarithm on $\mathbb R_{++}$ yields $\ln u  \in L^{\infty}$. In other words, $u \in \ln^{-1}(L^{\infty})$. Conversely, suppose we have $u \in \ln^{-1}(L^{\infty})$. By definition, $u \in L^{\infty}$. Thus, we deduce the bounds $\underline{m}, \overline{m} \in \mathbb R$ such that $\ln u \in [\underline{m},\overline{m}]$ a.e. Using the fact that the exponential map is positive and monotone, we infer that $u \in [\exp(\underline{m}),\exp(\overline{m})]$ a.e., $u > 0$, and $1/u\in [\exp(-\overline{m}),\exp(-\underline{m})]$ a.e. Since the reciprocal function is continuous away from zero, $u \in \interior L^{\infty}_+$. This proves  \cref{eq:glequivs2}.
	
	The proof of \cref{eq:glequivs3} is similar to that of \cref{eq:glequivs2}. Let $v \in \exp(L^\infty)$ and $\varphi \in L^{\infty}$ such that $v = \exp\varphi$. Clearly, we have $v > 0$ a.e. Since $\varphi$ is essentially bounded, there are independent constants $m, M \in \mathbb R$ such that $m \le \varphi \le M$ a.e. It follows then that $1/v = 1/\exp\varphi \in [\exp(-M),\exp(-m)]$. Consequently, $1/v$ is bounded. Since $v$ is strictly positive and measurable and $(\cdot)^{-1} : \mathbb R_{++} \to \mathbb R$ is continuous, $1/v$ is measurable. Therefore, $v \in \interior L^{\infty}_+$. Conversely, let $v \in \interior L^{\infty}_+$. Then by definition, $v > 0$ a.e. and $1/v \in L^{\infty}$. This implies  $v \in [ \|\frac{1}{v} \|_{L^{\infty}}^{-1}, \|v\|_{L^{\infty}}]$ a.e. It follows that $\varphi := \ln v \in L^{\infty}$ and $-\ln(\|\frac{1}{v} \|_{L^{\infty}}) \le \varphi \le \ln(\|v\|_{L^{\infty}})$. As a result, $v = \exp\varphi \in \exp(L^{\infty})$, as was to be shown. This completes the proof of \cref{eq:glequivs3}.

	Finally, we prove that $\psi \mapsto \exp\psi$ is a diffeomorphism.
	This requires us to check that for $\psi,\varphi \in L^\infty$, $\exp(\psi+\varphi) = \exp\psi\exp\varphi$, which holds by well-known properties of the exponential map.
	Furthermore, for $u,v \in \interior L^{\infty}_+ = \exp(L^\infty)$, $\exp^{-1}(uv) = \ln(uv) = \ln u + \ln v = \exp^{-1}(u) + \exp^{-1}(v)$, by well-known properties of logarithms.
	We know from~\Cref{lem:ExponentialMap} that $\psi \mapsto \exp\psi$ is infinitely differentiable on $L^\infty$. 		For the inverse mapping, note that for any $u \in \interior L^{\infty}_+$ and sequence $\{h_k\} \subset L^{\infty}$ such that $\| h_k \|_{L^{\infty}} \to 0$ we have (pointwise a.e.):
	\begin{align*}
	\left|\ln(u + h_k) - \ln(u) - \frac{h_k}{u} \right|
	&= 
	\left|\ln(1 + \frac{h_k}{u}) - \ln(1) -  \frac{h_k}{u}\right|\\
	&\le
	\left|\frac{h_k}{u}\right|\left| \left[\int_{0}^{1} (1 + \tau h_k/u)^{-1} \dd \tau - 1\right]\right|\\
	&\le
	\| h_k \|_{L^{\infty}} \| \frac{1}{u} \|_{L^{\infty}} \int_{0}^{1} |(1 + \tau h_k/u)^{-1} - 1| \dd \tau \\
	&=
	\| h_k \|_{L^{\infty}} \| \frac{1}{u} \|_{L^{\infty}} \int_{0}^{1} |(1 + u/(\tau h_k))^{-1} | \dd \tau\\
	&\le
	\| h_k \|_{L^{\infty}} \| \frac{1}{u} \|_{L^{\infty}} (\|u\|_{L^{\infty}} \| h_k\|^{-1}_{L^{\infty}} - 1)^{-1}.
	\end{align*}
	It follows that
	\[
	\left\|\ln(u + h_k) - \ln(u) - \frac{h_k}{u} \right\| = o(\|h_k\|)
	\]
	and, consequently, that the superposition operator $\ln u$ is Fr\'echet differentiable on $\interior L^{\infty}_+$ with respect to variations in $L^{\infty}$. To see that $1/u$ is continuous on $\interior L^{\infty}_+$, let $u \in \interior L^{\infty}_+$ and $\{u_k\} \subset L^{\infty}$ such that $u_k \to u$. Since $u \in \interior L^{\infty}_+$ there exists $\varepsilon > 0$ such that $u > \varepsilon$ a.e. Then, for sufficiently large $k$, we can argue that $u_k \ge \varepsilon/2$ pointwise a.e. This provides a uniform bound on $\| 1/u_k \|_{L^{\infty}}$. Hence, 
	\begin{equation}\label{eq:cont-frech}
	\| 1/u_k - 1/u \|_{L^{\infty}} \le \| u^{-1} \|_{L^{\infty}} \| u^{-1}_k \|_{L^{\infty}} \| u_k - u \|_{L^{\infty}} \to 0
	\end{equation}
	as $k \to +\infty$.
	Thus, $\psi \mapsto \exp\psi$ is a $C^1$-diffeomorphism, as necessary.
\end{proof}

\begin{remark}[Analytic isomorphism]
\label{rem:HigherRegularityDiffeomorphism}
Upon closer inspection, we see that the differentiability of the nonlinearity $\ln \colon \interior L^{\infty}_+ \to L^{\infty}$ can be shown to be much higher than $C^1$. For example, using the same line of argument as the proof above, we see that
	\[
	\aligned
	\left|(u + h_k)^{-1} - u^{-1} + \frac{h_k}{u^2} \right|
	&= 
	\left|\frac{-h_k}{u(u+h_k)} +  \frac{h_k}{u^2} \right|\\
	&\le
	\| h_k \|_{L^{\infty}} \| 1/u \|_{L^{\infty}}\left| \frac{1}{u} - \frac{1}{(u+h_k)} \right|
	\,,
	\endaligned
	\]
which behaves like $o(\|h_k\|)$, in light of the property shown in \cref{eq:cont-frech}. In fact, if 
we had defined the original exponential function using its power series, then deeper arguments can be used to illustrate that $\exp$ and $\ln$ are even analytic; cf.~\cite{glockner2002algebras}.
\end{remark}


It is well-known that $W^{1,p}(\Omega) \cap L^\infty(\Omega)$ is a Banach algebra for every $1\leq p \leq \infty$; see, e.g., \cite[Proposition~9.4]{brezis2011functional}.
The following proposition connects this set to the Banach--Lie group $W^{1,p}(\Omega) \cap \interior L^\infty_+(\Omega)$.

\begin{proposition}
\label{prop:logexpChainRule}
	Let $\Omega$ be an open subset of $\mathbb{R}^n$ and $1\leq p \leq \infty$.
	Then $$\ln \colon W^{1,p}(\Omega) \cap \interior L^\infty_+(\Omega) \to W^{1,p}(\Omega) \cap L^\infty(\Omega)$$ and $$\exp \colon W^{1,p}(\Omega) \cap L^\infty(\Omega) \to W^{1,p}(\Omega) \cap \interior L^\infty_+(\Omega)$$ are isomorphisms.
	Moreover,
	\begin{equation}
		\nabla \ln u = \frac{1}{u}\nabla u
		\qquad
		\text{and}
		\qquad
		\nabla \exp \psi = \exp \psi \nabla \psi
		\,,
	\end{equation}
	for all $u \in W^{1,p}(\Omega) \cap \interior L^\infty_+(\Omega)$ and $\psi \in W^{1,p}(\Omega) \cap L^\infty(\Omega)$.
																		\end{proposition}
\begin{proof}
	We prove $\ln \colon W^{1,p}(\Omega) \cap \interior L^\infty_+(\Omega) \to W^{1,p}(\Omega) \cap L^\infty(\Omega)$ and $\nabla \ln u = 1/u{\nabla u}$ for the case that $\Omega$ is bounded.
	The corresponding statements for the exponential map are treated similarly.
	\smallskip

	\noindent\textsl{Step 0.}
	Let $u \in W^{1,p}(\Omega) \cap \interior L^\infty_+(\Omega)$.
	By~\cref{prop:Equivalence} we know that $\ln u \in L^\infty(\Omega)$ and, moreover, there exists $\epsilon > 0$ such that $\epsilon \leq u(x) \leq 1/\epsilon$ at a.e.~$x\in\Omega$.
	We now follow the proof technique used for \cite[Proposition~9.4]{brezis2011functional} to show that $\ln u \in W^{1,p}(\Omega)$.
	\smallskip

	\noindent\textsl{Step 1.}
	The first step involves constructing a sequence $u_k\in C^\infty_c(\Omega)$ such that
	\begin{subequations}
	\label{eq:logexpChainRule_Properties}
	\begin{alignat}{3}
	\label{eq:logexpChainRule_Property1}
		u_k &\to u \quad &&\text{in } L^p(\Omega) \text{~~and~pointwise~a.e.~in }\Omega
		\,,\\
	\label{eq:logexpChainRule_Property2}
		\nabla u_k &\to \nabla u \quad &&\text{in } [L^p(\omega)]^n ~\fa \omega \subset \subset \Omega
		\,.
	\end{alignat}
	Furthermore,
	\begin{equation}
	\label{eq:logexpChainRule_Property3}
		\|u_k\|_{L^\infty(\Omega)} \leq \|u\|_{L^\infty(\Omega)}
	\end{equation}
	and, for all $\omega \subset\subset \Omega$, it holds that
	\begin{equation}
	\label{eq:logexpChainRule_Property4}
		\|1/u_k\|_{L^\infty(\omega)} \leq \|1/u\|_{L^\infty(\Omega)}
		\,,
	\end{equation}
	\end{subequations}
	once $k$ is sufficiently large.
	For simplicity, we choose to focus on the case where $\Omega$ is bounded.
	This step may be modified by multplying $u_k$ with a sequence of smooth cut-off functions to treat the case where $\Omega$ is unbounded; cf.~\cite[Proof of Theorem~9.2]{brezis2011functional}.

	Begin by defining
	\begin{equation}
	\overline{u}(x) =
		\begin{cases}
			u(x) & \text{if~} x \in \Omega\,,\\	
			0 & \text{if~} x \in \Omega\setminus \mathbb{R}^n	
			\,,
		\end{cases}
	\end{equation}
	and set $u_k = \rho_k \ast \overline{u}$, where $\rho_k \in C^\infty_c(\mathbb{R}^n)$ is a sequence of mollifier functions satisfying
	\begin{equation}
		\supp \rho_k \subset \overline{B(0,1/k)}
		\,,
		\quad
		\int_{\mathbb{R}^n} \rho_k = 1
		\,,
		\quad
		\rho_k \geq 0
		~~\text{a.e.~in } \mathbb{R}^n
		\,.
	\end{equation}
	Notice that $u_k(x) \leq 1/\epsilon$ at a.e.~$x\in\Omega$ since
	\begin{equation}
	 		 		 		 		 	u_k(x)
	 	=
	 	\int_{\mathbb{R}^n} \overline{u}(x-y) \rho_k(y) \dd y
	 	\leq
	 	\|u\|_{L^\infty(\Omega)} \int_{\mathbb{R}^n} \rho_k(y) \dd y
	 	\leq
	 	\frac{1}{\epsilon}
	 	\,.
	\end{equation}
	This proves~\cref{eq:logexpChainRule_Property3}.

			Now, take $\omega \subset \subset \Omega$ and let $\delta > 0$ be chosen small enough so that the open cover $\bigcup_{x\in \overline{\omega}} B(x,\delta)$ is contained in $\Omega$.
	Then, for all $k > 1/\delta$ and a.e.~$x\in \omega$, we have that
	\begin{equation}
	\label{eq:logexpChainRule_LowerBound}
		\epsilon
	 	=
	 	\int_{B(0,\delta)} \epsilon\,\rho_k(y) \dd y
	 	\leq
		\int_{B(0,\delta)} u(x-y) \rho_k(y) \dd y
		=
		u_k(x)
		\,.
	\end{equation}
	We have thus shown~\cref{eq:logexpChainRule_Property4}.
	Properties~\cref{eq:logexpChainRule_Property1,eq:logexpChainRule_Property2} are proven for this sequence in \cite[Theorem~9.2]{brezis2011functional}.
	\smallskip

	\noindent\textsl{Step 2.}
	The next step is to consider a test function $\varphi \in C^1_c(\Omega)$.
	Observe that
	\begin{equation}
	\label{eq:logexpChainRule_integrationbyparts}
		\int_\Omega \ln(u_k) \nabla \varphi \dd x
		=
		-\int_\Omega (1/u_k \nabla u_k) \varphi \dd x
		\,.
	\end{equation}
													Let $\omega = \supp \varphi \subset\subset \Omega$ denote the support of $\varphi$.
	Clearly, $\ln u_k(x) \to \ln u(x)$ at a.e.~point $x\in \omega$.
	Moreover, it is a straightforward exercise to show that $|\ln u_k(x)| \leq \max\{ \ln \|u\|_{L^\infty(\Omega)}, \ln \|1/u\|_{L^\infty(\Omega)} \}$ at a.e.~$x\in\omega$.
	Therefore, by the dominated convergence theorem, we have that
	\begin{equation}
	\label{eq:logexpChainRule_limit1}
		\lim_{k\to\infty}
		\int_\Omega \ln(u_k) \nabla \varphi \dd x
		=
		\int_\Omega \ln(u) \nabla \varphi \dd x
		\,.
	\end{equation}

	To treat the right-hand side of~\cref{eq:logexpChainRule_integrationbyparts}, observe that
	\begin{equation}
	\label{eq:logexpChainRule_intermediarybound}
		\|\varphi/u_k \nabla u_k - \varphi/u\nabla u\|_{L^1(\omega)}
		\leq
		\|\varphi/u\|_{L^\infty(\Omega)}
		\| \nabla u_k - \nabla u \|_{L^1(\omega)}
		\,.
	\end{equation}
	By~\cref{eq:logexpChainRule_Property2}, we conclude that $\| \nabla u_k - \nabla u \|_{L^1(\omega)} \to 0$ as $k\to\infty$.
	After combining this limit with~\cref{eq:logexpChainRule_intermediarybound}, we arrive at
	\begin{equation}
	\label{eq:logexpChainRule_limit2}
		\lim_{k\to\infty}
		\int_\Omega (1/u_k \nabla u_k) \varphi \dd x
		=
		\int_\Omega (1/u \nabla u) \varphi \dd x
		\,.
	\end{equation}
	The identity $\nabla \ln u = 1/u{\nabla u}$ immediately follows~\cref{eq:logexpChainRule_integrationbyparts,eq:logexpChainRule_limit1,eq:logexpChainRule_limit2}.~
																																																																														\end{proof}

\subsection{Regularity of the entropy functional} \label{sub:regularity_of_H}

One of the important facts that arise from \cref{prop:Equivalence} is that 
$u \in \interior L^\infty_+(\Omega)$
implies $u \ge \| \frac{1}{u} \|^{-1}_{L^\infty}$. Indeed, this property allows us to differentiate the negative entropy function
\begin{equation}
	S(u) = \left\{\begin{array}{cc}
	\int_\Omega u \ln u - u \dd x & u \in L^1_+(\Omega)\\
	+\infty & \text{ otherwise, }
	\end{array}\right.
	\label{eq:NegEntropy}
\end{equation}
on the open set $\interior L^\infty_+(\Omega)$ with variations in $L^{\infty}(\Omega)$.
We proceed now with a proof of \Cref{lem:EntropyDifferentiability}.

\begin{proof}[Proof of \Cref{lem:EntropyDifferentiability}]

	\textsl{Case \ref{item:EntropyDifferentiability_Part_1}: $1\leq p \leq \infty$.} For $p =1$, the properties of strict convexity and lower semicontinuity can be found in the seminal works  \cite{borwein1994strong,bauschke2001essential}. Since $\Omega \subset \mathbb{R}^n$ is bounded, the continuous embedding of $L^p(\Omega)$ into $L^1(\Omega)$ imply these same properties for all $p \in (1,\infty]$.
		\smallskip
	
	\noindent\textsl{Case \ref{item:EntropyDifferentiability_Part_2}: $1< p \leq \infty$.}
	Our proof continues by considering the Nemytskii operator induced by the real-valued function
\[
\hat{s}(x) :=  x \ln |x| - x\,.
\]
	We will show that it is a continuous map from $L^p(\Omega)$ to $L^1(\Omega)$ when $p > 1$.
	In doing so, we first note that $\hat{s}$ is continuous when viewed as a real-valued function $x \mapsto x \ln |x| - x$ with $x\in\mathbb{R}$ and, moreover, for any $p > 1$, there exists a constant $C(p)$ such that
	\begin{equation}
	\label{eq:GrowthCondition}
		|\hat{s}(x)| \leq  C(p) + |x|^p
		\,.
	\end{equation}
	Note that $C(p)$ exists on the one hand since $|\hat{s}(x)| \le 1$ for $x \in [-e,e]$. Moreover, for $x \in (e,\infty)$ with $x \to +\infty$, we have $ |\hat{s}(x)|/x^p \to 0$ for all $p \in (1,\infty)$. By symmetry, the same argument holds for $x \in (-\infty,e)$ with $x \to -\infty$. Therefore, by \cite[Theorem~2.2]{ambrosetti1995primer}, $\hat{s}\colon L^p(\Omega) \to L^1(\Omega)$ is continuous for $p \in (1,\infty)$. Clearly, if we restrict $\hat{s}$ to $L^p_+(\Omega)$, then we have a continuous mapping $\hat{s}|_{L^p_+(\Omega)}$ on $L^p_+(\Omega)$. This function coincides with 
	\begin{equation}
		s(x) = \left\{\begin{array}{cc}
				x \ln x - x, & x > 0,\\
				0, & x = 0,\\
				+\infty, & \text{ otherwise, }
				\end{array}
				\right.
	\end{equation}
	on $L^p_+(\Omega)$. Hence, continuity of $S$ on $L^p_+(\Omega)$ now follows from the continuity of the Lebesgue integral $u \mapsto \int_\Omega u \dd x$ and the fact that the composition of two continuous functions is also continuous. Finally, suppose $\left\{u_k\right\} \subset L^{\infty}_+(\Omega)$ converges to $u$ in $L^{\infty}(\Omega)$.
	Then $\left\{u_k\right\} \subset L^p_+(\Omega)$ for every for every $p \in (1,\infty)$ and, moreover, $u_k \to u$ in $L^p(\Omega)$ because $\Omega$ is a bounded domain.
		Consequently, $S(u_k) \to S(u)$ as $k \to +\infty$, as conjectured.
	\smallskip

	\noindent\textsl{Case \ref{item:EntropyDifferentiability_Part_3}: $p = \infty$.}
	In order to show that $S$ is Fr\'echet differentiable on $\interior L^{\infty}_+(\Omega)$ with respect to the $L^{\infty}(\Omega)$ topology, we will first prove that $S$ is G\^ateaux differentiable on $\interior L^{\infty}_+(\Omega)$ and, subsequently, that the G\^ateaux derivative $S^\prime_{\mathrm{G}}$ is continuous on $\interior L^{\infty}_+(\Omega)$.
	Fr\'echet differentiability of $S$ will then follow from \cite[Theorem~1.9]{ambrosetti1995primer}.

	To show that $S$ is G\^ateaux differentiabile on $\interior L^{\infty}_+(\Omega)$, we must show that for any fixed $u \in \interior L^{\infty}_+(\Omega)$ and $v \in L^\infty(\Omega)$,
	\begin{equation}
		\lim_{\tau\to 0}
		\int_\Omega 
		\frac{s(u + \tau v) - s(u)}{\tau}
		\dd x
		=
		\int_\Omega 
		v\ln(u)
		\dd x
		\,.
	\end{equation}
	First observe that for almost every $x\in\Omega$, we have pointwise convergence of the associated integrands, namely,
	\begin{equation}
		\lim_{\tau\to 0}
		\frac{s(u(x) + \tau v(x)) - s(u(x))}{\tau}
		=
		v(x)\ln (u(x))
		\,.
	\label{eq:DCT1}
	\end{equation}
	Next, we know from the proof of \Cref{prop:Equivalence} that $u \ge \|\frac{1}{u}\|^{-1}_{L^{\infty}}$. This implies that for sufficiently small $\tau$, $u + \tau v >  \|\frac{1}{u}\|^{-1}_{L^{\infty}}/2$ holds a.e., and we have 
	\begin{equation}
		s(u + \tau v) - s(u)
		=
		\int_{u}^{u+\tau v} \ln \sigma  \dd \sigma
				=
		\tau v \int_0^1 \ln( u +\sigma\tau v ) \dd \sigma
		\,.
	\end{equation}
	The critical step is to see that for the $u$ and $v$ fixed above, we may find $w \in L^\infty(\Omega)$ where
	\begin{equation}
	\label{eq:EntropyDifferentiability_critical}
		v = u w
		\,.
	\end{equation}
	As such, for all sufficiently small $\tau$, we may rewrite
	\begin{equation}
		s(u + \tau v) - s(u)
		=
		\tau v\, \Big(
		\ln u + \int_0^1 \ln( 1 + \sigma\tau w ) \dd \sigma
		\Big)
		,
	\end{equation}
	and, consequently,
	\begin{equation}
		\bigg|
		\frac{s(u + \tau v) - s(u)}{\tau} - v\ln u
		\bigg|
		=
		\bigg|v\int_0^1 \ln( 1 + \sigma\tau w ) \dd \sigma \bigg|
		\leq
		|v| |\ln( 1 + \tau w )|
		.
	\label{eq:DCT2}
	\end{equation}
	To arrive at an upper bound that is independent of $\tau$, we use the following well-known inequality:
	\begin{equation}
		\frac{x}{x+1} \leq \ln(1+x)  \leq x
		.
	\end{equation}
	In turn, for all $|\tau| < (2\|w\|_{L^\infty})^{-1}$,
	\begin{equation}
		|\ln( 1 + \tau w )|
		\leq
		1
		\,.
	\label{eq:DCT3}
	\end{equation}
	The penultimate argument owes to the function $|v|$ belonging to $L^1(\Omega)$ because $\Omega$ is bounded.
	Indeed, by \cref{eq:DCT1,eq:DCT2,eq:DCT3}, the dominated convergence theorem provides us with the following well-defined G\^ateaux derivative:
	\begin{equation}
		\langle S^\prime_{\mathrm{G}}(u), v\rangle
		=
		\lim_{\tau\to 0}
		\int_\Omega
		\frac{s(u + \tau v) - s(u)}{\tau}
		\dd x
		=
		\int_\Omega
		v\ln u
		\dd x
		.
	\end{equation}

	It remains to show that $S^\prime_{\mathrm{G}}\colon  \interior L^{\infty}_+(\Omega) \subset L^\infty(\Omega) \to [L^\infty(\Omega)]^\prime$ is continuous.
	To this end, let $u \in \interior L^{\infty}_+(\Omega)$ and consider any sequence $\{u_k\}$ in $\interior L^{\infty}_+(\Omega)$ where $u_k \to u$ in $L^\infty(\Omega)$.
	Consequently, we know there exists $C > 0$ such that $\|u_k\|_{L^\infty} \leq C$ and $u_k(x) \to u(x)$ for almost every $x\in\Omega$.
	Clearly,
	\begin{equation}
		|\langle S^\prime_{\mathrm{G}}(u) - S^\prime_{\mathrm{G}}(u_k), v\rangle|
		\leq
		\int_\Omega
		|v| |\ln |u/u_k||
		\dd x
		\leq
		\|v\|_{L^\infty}
		\int_\Omega
		|\ln |u/u_k||
		\dd x
		\,,
	\end{equation}
	where $|\ln |u/u_k|| \leq |\ln|u|| + |\ln C| \in L^1(\Omega)$.
	Therefore,
	\begin{equation}
		\|S^\prime_{\mathrm{G}}(u) - S^\prime_{\mathrm{G}}(u_k)\|_{[L^\infty]^\prime}
		\leq
		\int_\Omega
		|\ln |u/u_k||
		\dd x
	\end{equation}
	and, by the dominated convergence theorem,
	\begin{equation}
		\lim_{k\to\infty}
		\|S^\prime_{\mathrm{G}}(u) - S^\prime_{\mathrm{G}}(u_k)\|_{[L^\infty]^\prime}
		\leq
		\int_\Omega
		\lim_{k\to\infty}
		|\ln |u/u_k||
		\dd x
		=
		0
		,
	\end{equation}
	as necessary.
	\smallskip

	\noindent\textsl{Step 3.} Let $u \in \interior L^{\infty}_+(\Omega)$. By \cref{eq:glequivs2}
	$\ln u \in L^\infty(\Omega)$.
	Next, we see that $\|S^\prime(u)\|_{[L^\infty]^\prime} \leq \|\ln u\|_{L^1}$, since
	\begin{equation}
		\langle S^\prime(u), v \rangle
		=
		\int_\Omega v \ln u \dd x \leq \|v\|_{L^\infty}\|\ln u\|_{L^1}
		.
	\end{equation}
	Moreover,
	\begin{equation}
		\|S^\prime(u)\|_{[L^\infty]^\prime} 
		\geq
		\int \mathbbm{1}_{\{\ln u > 0\}} \ln u \dd x
		-
		\int \mathbbm{1}_{\{\ln u < 0\}} \ln u \dd x
		=
		\|\ln u\|_{L^1}
		,
	\end{equation}
	and so $\|S^\prime(u)\|_{[L^\infty]^\prime} = \|\ln u\|_{L^1}$.
	\end{proof}


We complete this subsection with a proof of the gradient representation theorem for the shifted entropy functional, $S_{\phi}(u) = S(u - \phi)$.

\begin{proof}[Proof of~\Cref{cor:shift-ent}]

By \Cref{lem:EntropyDifferentiability}, $S$ is continuous on $L^\infty_+(\Omega)$.  
If $\phi \in L^\infty(\Omega)$, then the shift operator $T_{\phi}u := u - \phi$ is continuous on $L^\infty(\Omega)$
for $u \in L^{\infty}(\Omega)$ with $u \ge \phi$, as well; 
continuity of the composition follows. 

As argued in \Cref{lem:EntropyDifferentiability}, 
$S$ is strictly convex on $L^{\infty}_+(\Omega)$.
Taking 
$w_i \in L^{\infty}_{\phi,+}(\Omega)$,
with $i =1,2$ and $w_1 \ne w_2$, we see that
$T_{\phi}w_i = w_i - \phi \ge 0$ a.e.\ for $i = 1,2$. Moreover, $T_{\phi} w_1 = T_{\phi} w_2$ iff $w_1 = w_2$ and for $\lambda \in (0,1)$ we  have
$T_{\phi}(\lambda w_1 + (1-\lambda) w_2) = 
 \lambda (w_1 -  \phi) + (1 - \lambda)(w_2 - \phi) = 
 \lambda T_{\phi} w_1 + (1-\lambda) T_{\phi} w_2$. Then since 
 $T_{\phi}w_i \in L^{\infty}_+(\Omega)$
    for $i=1,2$, the
 strict convexity of the composition follows. 
 
We proceed with the characterization of $\interior L^\infty_{\phi,+}(\Omega)$.   
  First, we can easily show the elementary properties 
 $
 L^\infty_{\phi,+}(\Omega) = \phi + L^{\infty}_+(\Omega)
 $
and
 \[
 \interior L^\infty_{\phi,+}(\Omega)  = \interior ( \phi + L^{\infty}_+(\Omega)) = \phi + \interior  L^{\infty}_+(\Omega).
 \]
 Therefore,  $w \in \interior L^\infty_{\phi,+}(\Omega)$ implies $w - \phi \in  \interior L^{\infty}_+(\Omega)$. By \Cref{prop:Equivalence},
  $w \ge \phi$ and $\essinf (w - \phi) > 0$. Conversely, if $w \in L^{\infty}(\Omega)$ such that $w \ge \phi$ and $\essinf (w - \phi) > 0$, then \Cref{prop:Equivalence} implies $w - \phi \in \interior L^{\infty}_{+}(\Omega)$. Hence, $w \in  \interior L^\infty_{\phi,+}(\Omega)$
 
Let 
$
 w_1  \in 
 \interior L^{\infty}_{\phi,+}(\Omega).
$
 Then $ w_1 - \phi \in \interior L^{\infty}_{+}(\Omega)$. It follows from 
 \Cref{lem:EntropyDifferentiability} that $S_{\phi}$ is Fr\'echet differentiable at $w_1$.
 
 The formula for the derivative of $S'_{\phi}$ can be viewed as an application of the chain 
 rule. Indeed, $S_{\phi} = S \circ T_{\phi}$, $S$ is differentiable with respect to the
 $L^{\infty}$-norm at $T_{\phi}w$ with $w
 \in \interior L^{\infty}_{\phi,+}(\Omega)$ and $T_{\phi}$ is differentiable with respect to the
 $L^{\infty}$-norm at (any) $w \in L^{\infty}$ with derivative $A'_{\phi}(w)$ given by
 the identity on $L^{\infty}$. Therefore, we have
 \cref{eq:EntropyDifferentiability_variations_inhom}.
Since $u - \phi \in \interior L^{\infty}_{+}(\Omega)$  the rest of the computations for the gradient
remain unchanged; in particular, we obtain \cref{eq:EntropyDifferentiability_gradient_inhom}
and \cref{eq:EntropyDifferentiability_primal_inho}.
\end{proof}














\subsection{Deriving the entropic Poisson equation} \label{sub:Characterization}

We begin this subsection with a proof of the characterization theorem.


\begin{proof}[Proof of \Cref{thm:PrimalProblem}]
The proof proceeds in four steps.
\medskip 

\noindent\textsl{Step 1.}
Show that there exists a unique solution.

The proof of existence is standard. We sketch the main points here; 
see, e.g., \cite[Chap. 3.2]{attouch2014variational} for details.
By \cite[Lem. 3.30]{ern2021finite}, we have that
\begin{equation}\label{eq:pw-ineq}
	\| v \|_{L^2} - \int_{\partial \Omega} g \dd\mathcal{H}_{n-1} \le c\| \nabla v \|_{L^2}
	\,,
	~
	\fa v \in H^1_g(\Omega)
	\,,
\end{equation}
for some constant $c$ that depends on $\Omega$.
Clearly, $A_{\alpha}$ is finite on $K$. This yields a minimizing sequence $\{u_k\}$.
The form of $A_{\alpha}$ consequently yields the boundedness of $\{\| \nabla u_k \|_{L^2}\}$. 
Combined with \cref{eq:pw-ineq} we deduce boundedness of $\{u_k\}$ in $H^1(\Omega)$.
We can readily show that $A_{\alpha}$ is weakly lower-semicontinuous and $K$ weakly sequentially closed.
This yields the existence of a minimizer $u \in K$.
The minimizer $u$ is unique because $A_{\alpha}$ is strictly convex on $K$.
\medskip

\noindent\textsl{Step 2.} Show that $u \leq \max\{\|g\|_{L^\infty(\partial\Omega)}, \exp(\|\ln w + \alpha f\|_{L^\infty(\Omega)})\}$.
	
	For all $N > 1$, define the set $R_N = \{ x \in \Omega \mid u(x) > N \}$.
	By way of contradiction, we assume that $|R_N| > 0$ for all $N > 1$.
	Now, consider the following function in $L^\infty$:
	\begin{equation}
		u_N(x)
		=
		\min\{ N, u(x) \} \ge 0.
	\end{equation}
	We claim that if $N > \esssup_{x\in\partial \Omega} g(x)$ then $u_N \in K$.
	Begin by choosing $\{u_m\} \subset C^{1}(\overline{\Omega})$ 
	such that $u_m \to u$ (strongly in $H^1(\Omega)$)
	and define $u^N_m := \min\{N,u_m\}$.  The existence of $u_m$ 
	follows from the assumption
	that $\partial \Omega$ is Lipschitz; see, e.g., \cite[3.22 Theorem]{adams2003sobolev}.
	Next let $v \in L^{\infty}(\partial \Omega)$ and consider that
	\[
	\int_{\partial \Omega} \gamma(u^N_m) v \dd\mathcal{H}_{n-1} = \int_{\{\gamma(u_m) \le N\}} \gamma(u_m) v \dd\mathcal{H}_{n-1} + N\int_{\{\gamma(u_m) > N\}} v \dd\mathcal{H}_{n-1}
	\,.
	\] 
	Along a subsequence, denoted still by $m$, $\gamma(u_m)$ converges pointwise almost everywhere to $\gamma(u) = g$. Then, by hypothesis,
	the sequence of characteristic functions $f_m := \chi_{\{\gamma(u_m) > N\}} \to 0$ pointwise almost everywhere. It follows from Lebesgue's
	dominated convergence theorem that 
	\[
	N\int_{\{\gamma(u_m) > N\}} v \dd\mathcal{H}_{n-1} \to 0 \text{~~as~} m \to +\infty.
	\]
	Continuing, we appeal to the proof of \cite[Thm A.1]{kinderlehrer2000introduction} and, e.g., \cite[Cor. 18.4]{leoni2009first}, to argue that
	$\min\{N,u_m\} \to \min\{N,u\}$ weakly in $H^1(\Omega)$ and 
	$\gamma(\min\{N,u_m\}) \to \gamma(\min\{N,u\})$ strongly in $L^2(\Omega)$, which in turn yields
	\[
	\lim_{m\to+\infty}\int_{\{\gamma(u_m) \le N\}} \gamma(u_m) v \dd\mathcal{H}_{n-1}
	=\int_{\partial \Omega} \gamma(u_N) v \dd\mathcal{H}_{n-1}
	. 
	\]
	Since $v$ is essentially bounded, we have 
	\[
	|\gamma(u_m)v - \gamma(u)v| = |v| |\gamma(u_m) - \gamma(u)| \le \| v\|_{L^{\infty}}|\gamma(u_m) - \gamma(u)|
	\,.
	\]
	Hence, $\gamma(u_m)v$ converges strongly in $L^2(\partial \Omega)$ to $\gamma(u) v$. Similar to the above, we can argue that 
	$f'_m := \chi_{\{\gamma(u_m) \le N\}} \to \chi_{\partial \Omega} = 1$ in $L^2(\partial \Omega)$. It follows that
	\[
	\int_{\partial \Omega} \gamma(u_N) v \dd\mathcal{H}_{n-1} = 
	\int_{\partial \Omega} \gamma(u) v \dd\mathcal{H}_{n-1} = 
	\int_{\partial \Omega} g v \dd\mathcal{H}_{n-1}.
	\]
	By the density of $L^{\infty}(\partial \Omega)$ in $L^2(\partial \Omega)$ and the fundamental lemma of the calculus of variations \cite[Theorem~1.32]{ern2021finite}, 
	we deduce $\gamma(u_N) = g$ a.e.~on $\partial \Omega$. Consequently, $u_N \in K$ and for sufficiently large $N$, it holds that
	\begin{equation}
		D(u,w) + \alpha E(u)
		<
		D(u_N,w) + \alpha E(u_N)
	\end{equation}	
	because $u$ is the unique global minimizer of $A_{\alpha}$ over $K$. 	
	
	Note, however, that
	\begin{align*}
		\alpha E(u)
		-
		\alpha E(u_N)
		&=
		\alpha\int_{R_N} 
		\frac{1}{2}|\nabla u|^2 - (u - N) f \dd x
	\end{align*}
	and
	\begin{align*}
		D(u,w)
		-
		D(u_N,w)
    		&=
    		\int_{R_N} u \ln u - N \ln N - (1 + \ln w)(u  - N) \dd x
    		\\
		&=
		\int_{R_N} (u - N) \bigg(
			\int_0^1 \ln (N + t(u - N)) \dd t
			- \ln w
		\bigg) \dd x
		.
	\end{align*}
	Combining these observations, we see that
	\begin{multline*}
	D(u,w) + \alpha E(u) - 	D(u_N,w) - \alpha E(u_N)
	\ge \\
	\frac{\alpha}{2} \| \nabla u\|^2_{L^2(R_N)} - (\alpha f + \ln w - \ln N,u- N)_{L^2(R_N)}.
	\end{multline*}
	Therefore, for any $N > \max\{\|g\|_{L^\infty(\partial\Omega)},\exp(\|\alpha f + \ln w\|_{L^\infty(\Omega)})\}$, we have
	\begin{equation}
		D(u,w) + \alpha E(u)
		>
		D(u_N,w) + \alpha  E(u_N)
		,
	\end{equation}
	which contradicts the optimality of $u$.
	Hence, there exists some $N_0 > 0$ such that $|R_N| = 0$ for all $N > N_0$, and, in turn, $u \in L^\infty$
	with $u \le \max\{\|g\|_{L^\infty(\partial\Omega)},\exp(\|\alpha f + \ln w\|_{L^\infty(\Omega)})\}$.
	\medskip
	
\noindent\textsl{Step 3.}
	Show that $u \geq \min\{\essinf_{x\in\partial \Omega} g(x), \exp(-\|\ln v + \alpha f\|_{L^\infty(\Omega)})\}$.
	Thus, $u \in H^1_g(\Omega) \cap \interior L^\infty_+(\Omega)$.

	For all $\epsilon > 0$, define the set $S_\epsilon = \{ x \in \Omega \mid u(x) < \epsilon \}$.
	By way of contradiction, we assume that $|S_\epsilon| > 0$ for all $\epsilon > 0$.
	Now, consider the following function in $H^1(\Omega)\cap \interior L^\infty_+(\Omega)$:
	\begin{equation}
		u_\epsilon(x)
		=
										\max\{ \epsilon, u(x) \}.
	\end{equation}
	The fact that $u_{\epsilon} \in \interior L^\infty_+$ follows from \Cref{prop:Equivalence}.
	
	Continuing, we can emulate the arguments of Step 2.~above to show that if 
	$\epsilon < \essinf_{x\in\partial \Omega} g(x)$, then $u_\epsilon \in H^1_g \cap \interior L^\infty_+$.
	The steps and justifications are almost identical and are therefore omitted.
	In turn, for sufficiently small $\epsilon > 0$, it holds that
	\begin{equation}
	\label{eq:GlobalMinStep}
		D(u,w) + \alpha E(u)
		\leq
		D(u_\epsilon,w) + \alpha E(u_\epsilon)
		,
	\end{equation}
		As above, we obtain the lower bound
	\begin{multline*}
	D(u,w) + \alpha E(u) - D(u_{\epsilon},w) - \alpha E(u_{\epsilon})
	\ge \\
	\alpha \| \nabla u\|^2_{L^2(S_{\epsilon})} + (\|\alpha f + \ln w\|_{L^{\infty}} + \ln \epsilon,u- \epsilon)_{L^2(S_{\epsilon})}
	\end{multline*}	
	As a result, once $\epsilon < \exp(-\| \alpha f + \ln w\|_{L^{\infty}})$, we again contradict the optimality of $u$. 
	Thus, there exists some $\epsilon_0 > 0$ such that $|S_\epsilon| = 0$ for all $\epsilon < \epsilon_0$ and $u \in H^1_g(\Omega)\cap \interior L^\infty_+(\Omega)$ by~\cref{prop:Equivalence}.
	\medskip	
	
\noindent\textsl{Step 4.} Derive the variational equation.

	Let $t > 0$ and $v \in K \cap L^{\infty}(\Omega)$. Then, by definition,
	\[
	\alpha E(u) + D(u,w) \le \alpha E(v) + D(v,w).
	\]
	Clearly, $u + t(v - u) \in K$,
	and consequently,
	\[
	0 \le \frac{ \alpha E(u + t (v - u)) - \alpha E(u)}{t} + \frac{ D(u + t (v - u),w) - D(u,w)}{t}
	\]
	Since, $u \in H^1(\Omega) \cap \interior L^{\infty}_+(\Omega)$ and $v - u \in H^1(\Omega) \cap L^{\infty}(\Omega)$, 
	\Cref{lem:EntropyDifferentiability} allows us to expand and pass to the limit as $t \downarrow 0$. This yields the 
	variational inequality:
	\[
	0 \le \alpha E'(u)(v - u) + S'(u)(v-u) - (\ln w,v-u)_{L^2}
	\]
	for all $v \in H^1_g(\Omega) \cap L^{\infty}_+(\Omega)$.
	It is readily observed that $H^1_g(\Omega) \cap \interior L^{\infty}_+(\Omega) \subset \interior \big( H^1_g(\Omega) \cap L^{\infty}_+(\Omega) \big)$.
	Therefore, as a result of Steps 2.~and 3., $u$ is in the 
	$H^1(\Omega) \cap L^{\infty}(\Omega)$ interior of the set $K$. In other words, for sufficiently small $\delta > 0$,
	$u + v \in H^1_g(\Omega) \cap L^{\infty}(\Omega)$ and $u + v \ge 0$ for any 
	$v \in H^1_0(\Omega) \cap L^{\infty}(\Omega)$ with $\|v\|_{H^1 \cap L^{\infty}} < \delta.$ In turn, we obtain the following
	variational equation with test functions $v \in H^1_0(\Omega) \cap L^{\infty}(\Omega)$ and 
	 $\|v\|_{H^1 \cap L^{\infty}} < \delta$:
	 \[
	0 = \alpha E'(u)v+ S'(u)v- (\ln w,v)_{L^2}.
	\]
	The first summand is equivalent to $(\alpha\nabla u,\nabla v)_{L^2} - (\alpha f,v)_{L^2}$ and
	the second and third summands together have the form $(\ln u - \ln w,v)_{L^2}$. 
	Since $u,w \in \interior L^{\infty}_+(\Omega)$, the map $v \mapsto (\ln u - \ln w,v)_{L^2}$ defines a 
	bounded linear functional on $H^1_0(\Omega)$. Finally, by virtue of the inclusion 
	$C^{\infty}_c(\Omega) \subset H^1_0(\Omega) \cap L^{\infty}(\Omega)$, we deduce
	\[
	(\alpha\nabla u,\nabla v)_{L^2}  + (\ln u,v)_{L^2} = (\alpha f,v)_{L^2} +  (\ln w,v)_{L^2}~\fa v \in H^1_0(\Omega),
	\] 
	as was to be shown.
	\end{proof}


	



\begin{remark}[Explicit bounds]
	Inspecting the proof above, we see that
	\begin{equation}
		\min\{g_{\min}, \exp(-\|\ln w + \alpha f\|_{L^\infty})\}
		\leq
		u
		\leq
		\max\{g_{\max}, \exp(\|\ln w + \alpha f\|_{L^\infty})\}
		,
	\end{equation}
	or, equivalently,
	\begin{equation}
		\min\{\ln g_{\min}, -\|\ln w + \alpha f\|_{L^\infty}\}
		\leq
		\ln u
		\leq
		\max\{\ln g_{\max}, \|\ln w + \alpha f\|_{L^\infty}\}
		,
	\end{equation}
	where $g_{\min} = \essinf_{x\in\partial \Omega} g(x)$ and $g_{\max} = \esssup_{x\in\partial \Omega} g(x)$.
\end{remark}




The following result provides important insight into the case where $g \equiv 0$ on $\partial \Omega$. A direct application of \Cref{thm:PrimalProblem} appears impossible due to the strict positivity requirement used to argue that $\max\{\epsilon, u\} \in H^1_g(\Omega) \cap \interior L^\infty_+(\Omega)$ in step 3. However, we can apply still apply \Cref{thm:PrimalProblem} sequentially.

\begin{theorem}\label{thm:homog-case}
In addition to the assumptions of \Cref{thm:PrimalProblem}, suppose that $g \equiv \varepsilon > 0$ and denote the solution of the corresponding entropic Poisson equation by $u_{\varepsilon}$.  Denote the unique solution of \cref{eq:subprob_obs} for $g \equiv 0$ by $\bar{u}$. For any sequence of scalars $\varepsilon_k \downarrow 0$, the sequence $\left\{u_k\right\}$ with $u_{k} := u_{\varepsilon_k}$ satisfies the following properties:
\begin{enumerate}
\item $u_{k} \to \bar{u}$ strongly in $H^1(\Omega)$;
\item $u_{k} \to \bar{u}$ weak-$*$ in $L^{\infty}(\Omega)$;
\item $\gamma(u_k - \bar{u}) \to 0$ strongly in $L^{\infty}(\partial \Omega)$.
\end{enumerate}
\end{theorem}

\begin{proof}
According to the proof of \Cref{thm:PrimalProblem}, we have the bounds 
\[
\min\{\varepsilon_k, \exp(-\| \ln w + \alpha f \|_{L^{\infty}})\} \le u_{k} \le
\max\{\varepsilon_k, \exp(\| \ln w + \alpha f \|_{L^{\infty}})\}. 
\]
Therefore, for sufficiently large $k$, the bounds reduce to 
$
\varepsilon_k \le u_k \le \exp(\| \ln w + \alpha f \|_{L^{\infty}}).
$
According to the Banach--Alaoglu theorem, there exists a subsequence $\{k_l\}$ and $\tilde{u} \in L^{\infty}(\Omega)$ such that $u_{k_l} \to \tilde{u}$ weak-$*$ in 
$L^{\infty}(\Omega)$. Clearly, $\tilde{u}$ satisfies
$
0\le \tilde{u} \le \exp(\| \ln w + \alpha f \|_{L^{\infty}})
$
a.e.\ in $\Omega$.

Continuing, we note that $v = u_k - \varepsilon_k \in H^1(\Omega)$ and $\gamma(v) = 0$. Then using  $v$ as a test function in \cref{eq:PrimalProblemVE}, we deduce the existence of constants $M,C$ such that
\[
\alpha (\nabla u_k,\nabla u_k)_{L^2} + M \le C \| \alpha f + \ln w \|_{L^{2}}.
\]
This follows from the fact that $ (\nabla u_k,\nabla (u_k-\varepsilon_k))_{L^2} =  (\nabla u_k,\nabla u_k)_{L^2}$, 
\[
0 \le u_k - \varepsilon_k \le \exp(\| \ln w + \alpha f \|_{L^{\infty}}),
\] 
and
\[
( \ln(u_k),u_k - \varepsilon_k)_{L^2} 
= 
( \ln(u_k - \varepsilon_k + \varepsilon_k),u_k - \varepsilon_k)_{L^2} 
\ge
( \ln(u_k - \varepsilon_k),u_k - \varepsilon_k)_{L^2},
\]
along with $x \ln x \ge -1/\exp(1)$. Consequently, there exists a further subsequence $\left\{k_{l_m}\right\}$ such that
$u_{k_{l_m}} \to \tilde{u}$ weakly in $H^1(\Omega)$. We  deduce that $\tilde{u}$ is feasible to \cref{eq:subprob_obs}. 


We now demonstrate that $\tilde{u} = \bar{u}$. The fact that $\bar{u}$ is unique follows from the same arguments in step 1 of the proof 
of \Cref{thm:PrimalProblem}. Defining $\bar{u}_{\varepsilon} := \max\{\varepsilon,\bar{u}\}$, we have $\bar{u}_{\varepsilon} \ge 0$ and $\gamma(\bar{u}_{\varepsilon}) = \varepsilon$.  Consider additionally that 
\[
\frac{1}{2}\| \nabla \bar{u}_{\varepsilon_k}  \|^2_{L^2} =
\frac{1}{2}\int_{\{\bar{u} \ge \varepsilon_k\}} |\nabla \bar{u}|^2 \dd x \to 
\frac{1}{2}\int_{\Omega} |\nabla \bar{u}|^2 \dd x
\,,
\]
by monotone convergence and $\bar{u} \ge 0$. Similarly, using $0 \le \bar{u}$, we see that
$
\| \bar{u}_{\varepsilon_k} - \bar{u} \|^2_{L^2} 
=O(\varepsilon^2).
$
By optimality of $u_{\varepsilon}$ we have
\[
E(u_{k}) + \alpha^{-1} D(u_{k},w) \le E(\bar{u}_{\varepsilon_k}) + \alpha^{-1} D(\bar{u}_{\varepsilon_k},w).
\]
Using the subsequence $\{k_{l_m}\}$, we pass to the limit inferior on both sides. 
The previous observations along with the continuity/weak lower semicontinuity properties of both the entropy 
and $E$ imply
\[
E(\tilde{u}) + \alpha^{-1} D(\tilde{u},w) \le E(\bar{u}) + \alpha^{-1} D(\bar{u},w)\,,
\]
whence we have $\tilde{u} = \bar{u}$. Since $\bar{u}$ is unique, it follows from the Urysohn subsequence property that 
the entire sequence $\{u_k\}$ converges weakly in $H^1(\Omega)$. 

Strong convergence follows by rearranging terms in the optimality statement and considering the limit superior. Indeed, we have 
\begin{equation}\label{eq:limsup}
\frac{1}{2} \| \nabla u_{\varepsilon_k} \|^2_{L^2} - 
\frac{1}{2} \| \nabla \bar{u}_{\varepsilon_k} \|^2_{L^2} \le
(f,u_{\varepsilon_k} - \bar{u}_{\varepsilon_k}) + 
\alpha^{-1} D( \bar{u}_{\varepsilon_k},w) - 
\alpha^{-1} D( u_{k},w)
\end{equation}
This indicates that $\{u_k\}$ converges strongly in $H^1(\Omega)$ by the weak lower semicontinuity of the term $\| \nabla \cdot\|^2_{L^2}$ on $H^1(\Omega)$ and the Kadec--Klee property 

Finally, we return to the $L^{\infty}$-statements. By the linearity of the trace, we have $\gamma(u_k - \bar{u}) = \varepsilon_k$, which clearly converges to 0 in $L^{\infty}(\partial \Omega)$. Likewise, if we assume that $u_k$ possess a subsequence that does not weak-$*$ converge to $\bar{u}$ in $L^{\infty}(\Omega)$, then we can allows find a further subsequence that does, which leads to a contradiction. This completes the proof.
\end{proof}

\begin{remark}[Entropic Poisson equation with homogeneous boundary conditions]
Without a deeper analysis of the properties of $\bar{u}$ in \Cref{thm:homog-case}, it is difficult to say whether a type of entropic Poisson equation can be derived for the fully homogeneous case. Nevertheless, we do know that $\bar{u}$ is an optimal solution and therefore feasible. On the active set, $\bar{u} = 0$ is fully determined.
Moreover, consider that
\[
\aligned
(u_k,\ln u_k) - (\bar{u},\ln \bar{u})
&= 
(u_k - \bar{u},\ln u_k) + (\bar{u},\ln u_k - \ln \bar{u})\\
&=
\langle u_k - \bar{u},\alpha f + \ln w + \alpha \Delta u_k \rangle + (\bar{u},\ln u_k - \ln \bar{u}).
\endaligned
\]
Given $u_k \to \bar{u}$ in $H^1(\Omega)$ implies $ \Delta u_k \to  \Delta \bar{u}$ strongly in $H^1(\Omega)^\prime$ as well as $S(u_k) \to S(\bar{u})$, it must follow that $(\bar{u},\ln u_k) \to (\bar{u},\ln \bar{u})$. This implies a complementarity relation in the limit; namely,
\[
\langle -\alpha \Delta \bar{u} + \ln \bar{u} - \alpha f - \ln w,\bar{u}\rangle = 0.
\]
It remains to investigate what happens on the inactive set, i.e., where $\bar{u} > 0$. To this aim, let $I_{\delta} := \left\{x \in \Omega \left| \bar{u}(x) \ge \delta > 0 \right.\right\}$. By Egorov's theorem, we can find a subsequence $\left\{u_{k_l}\right\}$ with the property that for every $\eta > 0$, there exists a measurable set $\mathcal{B}_{\eta,\delta} \subset I_{\delta}$ with $| I_{\delta} \setminus \mathcal{B}_{\eta,\delta}| < \eta$ such that $u_{k_l} \to \bar{u}$ uniformly on $\mathcal{B}_{\eta,\delta}$. This implies that $\ln u_{k_l} \to \ln \bar{u}$ uniformly on $\mathcal{B}_{\eta,\delta}$, as well. Consequently, we can localize the entropic Poisson equation with test functions $\varphi \in C^{\infty}_{c}(\mathcal{B}_{\eta,\delta})$, leading to
\[
\langle -\alpha \Delta u_{k_l} + \ln u_{k_l} - \alpha f - \ln w,\varphi\rangle = 0.
\]
Passing to the limit, we see that
\[
\langle -\alpha \Delta \bar{u} + \ln \bar{u} - \alpha f - \ln w,\varphi\rangle = 0.
\]
This is well-defined due to the restriction to subsets of $I_{\delta}$. Therefore, up to arbitrarily small subsets of the strict inactive sets $I_{\delta}$ (for all $\delta > 0$) we have recovered the entropic Poisson equation $-\alpha \Delta \bar{u} + \ln \bar{u} = \alpha f + \ln w$ in the sense of distributions.
\end{remark}


The following is a proof of \Cref{cor:PrimalProblem_inhom}.
\begin{proof}[Proof of \Cref{cor:PrimalProblem_inhom}]
The proof follows that of \Cref{thm:PrimalProblem}. Here, \Cref{cor:shift-ent} plays the same role as \Cref{lem:EntropyDifferentiability}.

Existence and uniqueness
follows the homogeneous case in light of 
the implications of \Cref{cor:shift-ent}.
We only need argue that $K_{\phi}$ is nonempty. Since $g, \phi \in 
H^1(\Omega) \cap C(\overline{\Omega})$ the function
$
v := \max\{g,\phi\} = g + \max\{0,\phi-g\}
$
is in $H^1(\Omega) \cap C(\overline{\Omega})$ and satisfies $v \ge \phi$. The trace of $w$ is merely the
evaluation on the boundary. Then since  $\essinf \gamma(g - \phi) > 0$ on $\partial \Omega$ by assumption, we have 
$\gamma(v) = \gamma(g)$ and consequently $v \in K_{\phi}$.



Setting $\tilde{w} = w - \phi$, we can now readily argue that $u = \tilde{u} + \phi$ where $\tilde{u}$ is the solution of
\begin{multline}\label{eq:subproblem_inhom_shift}
	\min
		\frac{1}{2} \| \nabla \tilde{v} \|^2_{L^2} - (f +  \Delta \phi,\tilde{v})_{L^2} + \alpha^{-1} D(\tilde{v},\tilde{w})
	\\\text{ over }
	\tilde{v} \in H^1_{g - \phi}(\Omega)
	~~\text{subject to~}
	\tilde{v} \geq 0
	~\text{in~}\Omega
	\,.
\end{multline}
\Cref{thm:PrimalProblem} then guarantees that $\tilde{u}$ solves
	\begin{equation*}
		(\alpha\nabla \tilde{u}, \nabla v)
				+
		(\ln \tilde{u}, v)
		=
		(\alpha f + \alpha \Delta \phi, v) + (\ln \tilde{w}, v)
				\quad
		\text{for all~}
		v \in H^1_0(\Omega)
		.
	\end{equation*}
Substituting $u - \phi = \tilde{u}$ and $w - \phi = \tilde{w}$ yields \cref{eq:PrimalProblemVE_inhom}.
\end{proof}








\subsection{Convergence of the latent variable proximal point method}
\label{sub:proximal_methods}

In this section, we establish arbitrary convergence rates for the continuous-level proximal point algorithm~\cref{eq:ConvergenceContinuousLevel_VE} to solve the obstacle problem.
We begin by proving the following lemma.

\begin{lemma}
\label{lem:PrimalSaddlePointEquivalence}

Under the assumptions of~\Cref{thm:PrimalProblem}, the second-order problem
\begin{subequations}
\begin{equation}
\label{eq:Step1_ProofOfConvergenceContinuousLevel_PrimalProblem}
	\text{Find}~
	u\in  H^1_g(\Omega)\cap \interior L^\infty_+(\Omega)
	~\text{such that~}
	-\Delta u + \ln u = f ~~\text{in~}H^{-1}(\Omega)
	\,,
\end{equation}
is equivalent to the saddle-point problem
\begin{equation}
\label{eq:Step1_ProofOfConvergenceContinuousLevel_SaddlePointProblem}
	\text{Find}~
	\tilde{u}\in  H^1_g(\Omega) ~\text{and}~\tilde{\psi} \in L^\infty(\Omega)
	~\text{such that~}
	\left\{
	\begin{alignedat}{4}
		-\Delta u + \tilde{\psi} &= f~~ &&\text{in~}H^{-1}(\Omega)
		\,,
		\\
		\tilde{u} - \exp\tilde{\psi} &= 0 &&\text{in~}L^2(\Omega)
		\,.
	\end{alignedat}
	\right.
\end{equation}
\end{subequations}
More specifically, both problems admit unique solutions that coincide in the sense that $u = \tilde{u}$ and $\ln u = \tilde{\psi}$ a.e~in $\Omega$.
\end{lemma}

\begin{proof}
	First of all, we know from~\Cref{thm:PrimalProblem} that there exists a unique solution to~\cref{eq:Step1_ProofOfConvergenceContinuousLevel_PrimalProblem}.
	Using~\cref{prop:Equivalence}, we know that $\exp \colon L^\infty(\Omega) \to \interior L^\infty_+ (\Omega)$ is an isomorphism.
	Thus, $\tilde{\psi} = \ln u$ and $\tilde{u} = u$ form a solution to~\cref{eq:Step1_ProofOfConvergenceContinuousLevel_SaddlePointProblem}.
	Now, assume that $\tilde{u}\in  H^1_g(\Omega)$ and $\tilde{\psi} \in L^\infty(\Omega)$ form an arbitrary solution to~\cref{eq:Step1_ProofOfConvergenceContinuousLevel_SaddlePointProblem}.
	By the second equation in~\cref{eq:Step1_ProofOfConvergenceContinuousLevel_SaddlePointProblem}, we know that
	\begin{equation}
	\label{eq:PrimalSaddlePointEquivalence_ae}
		\tilde{u} = \exp\tilde{\psi}
		~~
		\text{a.e.~in~}\Omega
		\,.
	\end{equation}
	Now, by~\cref{prop:Equivalence}, we know that $\exp\tilde{\psi} \in \interior L^\infty_+(\Omega)$.
	Thus, $\tilde{u} \in H^1_g(\Omega)\cap \interior L^\infty_+(\Omega)$.
	Moreover, by applying $\ln$ to both sides of~\cref{eq:PrimalSaddlePointEquivalence_ae}, we find that $\tilde{\psi} = \ln \tilde{u}$.
	Thus, $\tilde{u} \in H^1_g(\Omega)\cap \interior L^\infty_+(\Omega)$ solves~\cref{eq:Step1_ProofOfConvergenceContinuousLevel_PrimalProblem}.
	Since the solution of~\cref{eq:Step1_ProofOfConvergenceContinuousLevel_PrimalProblem} is unique, we find that $\tilde{u} = u$ and, in turn, $\tilde{\psi} = \ln u$.
\end{proof}



We now move on to proving \Cref{thm:ConvergenceContinuousLevel}.



\begin{proof}[Proof of~\Cref{thm:ConvergenceContinuousLevel}]
The proof proceeds has three main steps, the first two of which build off of~\Cref{lem:PrimalSaddlePointEquivalence}.
Without loss of generality, we focus on the case where $\phi = 0$.
The statement for general obstacles $\phi \neq 0$ can be recovered by making the change of variables $u - \phi = \tilde{u}$ and $w - \phi = \tilde{w}$ used in the proof of \Cref{cor:PrimalProblem_inhom}.
\smallskip


\noindent\textsl{Step 0.}
By~\Cref{lem:PrimalSaddlePointEquivalence}, the sequence of iterates $u^k$ coming from~\cref{eq:ConvergenceContinuousLevel_VE} and
\begin{equation}
\label{eq:ConvergenceContinuousLevel_VE_primal}
	(\alpha_{k+1}\nabla u^{k+1}, \nabla v)
	+
	(\ln u^{k+1}, v)
	=
	(\alpha_{k+1} + \ln u^k, v)
	\quad
	\text{for all~}
	v \in H^1_0(\Omega)
	\,
\end{equation}
are equal a.e.~in $\Omega$.
We take advantage of this fact throughout the proof below.
In particular, given $u^0 = \exp \psi^0$ as in the hypotheses, we suppose that sequence $\{u^k\}$ is generated by the proximal point method, where each $u^k$ solves \cref{eq:ConvergenceContinuousLevel_VE_primal}, $k = 1,2,\dots$ By \Cref{thm:PrimalProblem}, $u^k \in H^1_g(\Omega)\cap \interior L^\infty_{+}(\Omega)$ for all $k = 0,1,2,\dots$.
\smallskip

\noindent\textsl{Step 1.}
Inequality~\cref{eq:ConvergenceContinuousLevel_Monotonicity} is proved by exploiting the fact that $D(u,w) \geq 0$ with equality if and only if $u = w$. In particular,
\begin{equation}
	\begin{aligned}
		E(u^{k+1})
		&\leq
		E(u^{k+1}) + D(u^{k+1},u^k)/\alpha_{k+1}
		\\
		&\leq
		E(u^k) + D(u^k,u^k)/\alpha_{k+1}
		=
		E(u^k)
		\,.
	\end{aligned}
\end{equation}

\noindent\textsl{Step 3.}
Since $u^j \in H^1_g(\Omega)\cap \interior L^\infty_{+}(\Omega)$ for all $j=1,2,\ldots,k$, the definition of $D$ as a true Bregman distance according to \cref{eq:bregman-trad} is justified and consequently, the three-points identity \cref{eq:CosineIdentity} is as well. This leads to 
	\begin{equation}
	\label{eq:CosineIdentity_proof}
		D(w,u^j) - D(w,u^{j-1}) + D(u^j,u^{j-1})
		=
		\langle S^\prime(u^j) - S^\prime(u^{j-1}), u^j - w \rangle
		\,,
	\end{equation}
	where $w \in H^1_g(\Omega)$ such that $w \ge 0$ a.e.
	Next, notice that~\cref{eq:ConvergenceContinuousLevel_VE_primal} is equivalent to
	\begin{equation}
	\label{eq:RelativeEntropyIdentity}
		\langle S^\prime(u^j),v\rangle  - \langle S^\prime(u^{j-1}),v\rangle
		=
		-\alpha_{j} E^\prime(u^j)v ~\fa v \in H^1_0(\Omega).
	\end{equation}
	Clearly, we have $u^j - w \in H^1_0(\Omega)$. Therefore, \cref{eq:RelativeEntropyIdentity} and the subgradient inequality for $E$ at $u^j$ imply 
	\begin{equation}
	\label{eq:ConvergenceContinuousLevel_SubgradientIdentity}
		\langle S^\prime(u^j) - S^\prime(u^{j-1}), u^j - w \rangle
		=
		\langle \alpha_{j} E^\prime(u^j), w - u^j \rangle
		\leq
		\alpha_{j} E(w) - \alpha_{j} E(u^j)
		\,.
	\end{equation}
	Together,~\cref{eq:CosineIdentity_proof,eq:ConvergenceContinuousLevel_SubgradientIdentity} imply that
	\begin{equation}
	\label{eq:ConvergenceContinuousLevel_Step3}
		D(w,u^k)
		+
		\sum_{j=1}^{k}
			D(u^{j},u^{j-1}) 
			+ \sum_{j=1}^{k}\alpha_{j}[E(u^j) -  E(w)]
		\leq
		D(w,u^0)
		\,.
	\end{equation}
	Now, given $D(w,u^k) \geq 0$, $D(u^{k+1},u^{k}) \geq 0$ for all $k$ and $E(u^k) \leq E(u^j)$ for all $j\leq k$, by~\cref{eq:ConvergenceContinuousLevel_Monotonicity}, along with ~\cref{eq:ConvergenceContinuousLevel_Step3}, we deduce the
	bound
	\begin{equation}
		E(u^k)
		\leq
		E(w) + \frac{D(u,u^0)}{\sum_{j=1}^k \alpha_{j}}
		\,,
	\end{equation}
	for all $w \in H^1_g(\Omega)$ satisfying $w \geq 0$.
	This step is completed by setting $w = u^\ast$ in the inequality above and using strong convexity of $E\colon H^1_0(\Omega) \to \mathbb{R}$.
	In particular, observe that
	\begin{equation}
	\label{eq:ConvergenceContinuousLevel_StrongConvexity}
		\begin{aligned}
			\frac{D(u^\ast,u^0)}{\sum_{j=1}^k \alpha_{j}}
			\geq
			E(u^k)
			-
			E(u^\ast)
			&\geq
			\langle E^\prime(u^\ast), u^k - u^\ast \rangle
			+
			\|\nabla u^\ast - \nabla u^k\|_{L^2}^2
			\\
			&\geq
			\|\nabla u^\ast - \nabla u^k\|_{L^2}^2
			\,,
		\end{aligned}
	\end{equation}
	where, we have used the first-order optimality condition $\langle E^\prime(u^\ast), v - u^\ast \rangle \geq 0$ for all $v \in K$ in the final inequality.
	\smallskip

	\noindent\textsl{Step 4.}
	Finally, we prove the first equality in~\cref{eq:ConvergenceContinuousLevel_Rate}.
	To this end, consider the two equations
	\begin{subequations}
	\begin{equation}
		(\nabla u^k, \nabla v) - (f,v)
		=
		(\lambda^k,v)
		\fa v \in H^1_0(\Omega)
		\,,
	\end{equation}
	and
	\begin{equation}
		(\nabla u^\ast, \nabla v) - (f,v)
		=
		(\lambda^\ast,v)
		\fa v \in H^1_0(\Omega)
		\,.
	\end{equation}
	\end{subequations}
	Combining these two equations, we find that
	\begin{equation}
		\|\lambda^\ast - \lambda^{k}\|_{H^{-1}(\Omega)}
		=
		\sup_{v \in H^1_0(\Omega)}
		\frac{(\lambda^\ast - \lambda^k,v)}{\|\nabla v\|_{L^2(\Omega)}}
		=
		\sup_{v \in H^1_0(\Omega)}
		\frac{(\nabla u^\ast - \nabla u^k,\nabla v)}{\|\nabla v\|_{L^2(\Omega)}}
										\,.
	\end{equation}
	We now find $\|\lambda^\ast - \lambda^{k}\|_{H^{-1}(\Omega)} \leq \|\nabla u^\ast - \nabla u^k\|_{L^2(\Omega)}$ by applying the triangle inequality to the numerator of the third expression above.
	Likewise, we find $\|\nabla u^\ast - \nabla u^k\|_{L^2(\Omega)} \leq \|\lambda^\ast - \lambda^{k}\|_{H^{-1}(\Omega)}$ by considering the candidate function $v = u^\ast - u^k$.~
\end{proof}

We now turn to studying the iteration complexity of the LVPP for various step size sequences.
To this end, we first recall the standard definitions of $\mathrm{Q}$- and $\mathrm{R}$-convergence.

\begin{definition}
	Let $\mathcal{X}$ be a Banach space with norm $\|\cdot\|_{\mathcal{X}}$.
	We say that a sequence $\{x_k\}_{k=0}^\infty \subset \mathcal{X}$ converges to $x^\ast \in \mathcal{X}$ with order $q \geq 1$ and rate $r \geq 0$ if
	\begin{equation}
		\lim_{k\to\infty}
		\frac{\|x_{k+1} - x^\ast\|_{\mathcal{X}}}{\|x_k - x^\ast\|_{\mathcal{X}}^q}
		=
		r
		\,.
	\end{equation}
	\\\indent
	If $q = 1$ and $r = 1$, then we say $x_k$ converges $\mathrm{Q}$-sublinearly to $x^\ast$.
	If $q = 1$ and $r \in (0,1)$, then we say $x_k$ converges $\mathrm{Q}$-linearly to $x^\ast$.
	If $q>0$ or $q = 1$ and $r = 0$, then we say $x_k$ converges $\mathrm{Q}$-superlinearly to $x^\ast$.
	\\\indent
	If $\|x_k - x^\ast\|_{\mathcal{X}} \leq \epsilon_k$ for all $k$, where $\epsilon_k$ converges $\mathrm{Q}$-sublinearly (linearly, superlinearly) to zero, then we say that $x_k$ converges $\mathrm{R}$-sublinearly (linearly, superlinearly) to $x^\ast$.
\end{definition}

The following corollary establishes convergence orders associated to various step size sequences.

\begin{corollary}[Convergence order]
\label{cor:ConvergenceRates}
Fix $C > 0$.
Under the assumptions of \Cref{thm:ConvergenceContinuousLevel}, consider the following candidate sequences of step sizes:
\smallskip
\begin{subequations}
\begin{enumerate}[itemindent=.7cm]
	\item[\textsl{Case 1:}]
	Fix $m \in \mathbb{N}$ and set
	\begin{equation}
	\label{eq:ArithmeticSeries}
		\alpha_{k} = C k(k+1)\cdots(k+m) ~ \fa k = 1,2,\ldots
	\end{equation}
	\item[\textsl{Case 2:}]
	Fix $\mu > 1$ and set
	\begin{equation}
	\label{eq:GeometricSeries}
		\alpha_{k} = C \mu^{k-1} ~ \fa k = 1,2,\ldots
	\end{equation}
	\item[\textsl{Case 3:}]
	Set $\alpha_1 = C$ and
	\begin{equation}
	\label{eq:FactorialSeries}
		\alpha_{k+1} = C k k! ~ \fa k = 1,2,\ldots
	\end{equation}
	\item[\textsl{Case 4:}]
	Fix $\mu, q, r > 1$ and set $\alpha_1 = r^{1/(q-1)} \mu$ and
	\begin{equation}
	\label{eq:DoubleExponential}
		\alpha_{k+1} = r^{1/(q-1)} \mu^{q^k} - \alpha_{k} ~ \fa k = 2,3,\ldots
	\end{equation}
\end{enumerate}
\end{subequations}
Then sequence \cref{eq:ArithmeticSeries} delivers a sublinear $\mathrm{R}$-convergence; sequence \cref{eq:GeometricSeries} delivers $\mathrm{R}$-linear convergence with rate $1/\mu$; sequence \cref{eq:FactorialSeries} delivers $\mathrm{R}$-superlinear convergence with order $1$ and rate $0$; and sequence \cref{eq:DoubleExponential} delivers $\mathrm{R}$-superlinear convergence with order $q$ and rate $r$. 
\end{corollary}
\begin{proof}
	Throughout the proof, we use the definition $\epsilon_k = D(u^\ast,u^0)/{\sum_{j=1}^k \alpha_{j}}$.
	\smallskip

	\noindent\textsl{Case 1:}
	For this case, we can use the hockey-stick identity to show that
	\begin{equation}
		(m+2)
		\sum_{j=1}^k
		j(j+1)\cdots(j+m)
		=
		k(k+1)\cdots(k+m+1)
		\,.
	\end{equation}
	Thus, if $\alpha_k = C k(k+1)\cdots(k+m)$ for all $k$, then
							\begin{equation}
		\frac{\epsilon_{k+1}}{\epsilon_k}
		=
		\frac{k(k+1)\cdots(k+m)}{(k+1)(k+2)\cdots(k+m+1)}
		=
		\frac{k}{k+m+1}
		\to 1
		~~
		\text{as~} k \to \infty
		\,.
	\end{equation}
	\smallskip
	
	\noindent\textsl{Case 2:}
	For this case, we use the identity
	\begin{equation}
		\sum_{j=1}^{k} \mu^{j-1}
		=
		\frac{\mu^{k} - 1}{\mu-1}
		\,.
	\end{equation}
							Thus, if $\alpha_k = C \mu^{k-1}$ for all $k$, then
	\begin{equation}
		\frac{\epsilon_{k+1}}{\epsilon_k}
		=
		\frac{\mu^{k} - 1}{\mu^{k+1} - 1}
		\to \frac{1}{\mu}
		~~
		\text{as~} k \to \infty
		\,.
	\end{equation}
	\smallskip
	
	\noindent\textsl{Case 3:}
	For this case, we use the identity
	\begin{equation}
		\sum_{j=1}^k j j!
		=
		(k+1)! - 1
		\,.
	\end{equation}
							Thus, if $\alpha_k = C (k-1) (k-1)!$ for all $k \geq 2$ and $\alpha_1 = C$, then
	\begin{equation}
		\frac{\epsilon_{k+1}}{\epsilon_k}
		=
		\frac{k!}{(k+1)!}
		=
		\frac{1}{k+1}
		\to 0
		~~
		\text{as~} k \to \infty
		\,.
	\end{equation}
	\smallskip
	
	\noindent\textsl{Case 4:}
	In this case, we use the fact that $\sum_{j=1}^k \alpha_{j-1} = \alpha_{k-1}$ is a telescoping sum by design.
							Thus, if $\alpha_{k+1} = r^{1/(q-1)} \mu^{q^k} - \alpha_{k}$ for all $k\geq 1$ and $\alpha_1 = r^{1/(q-1)} \mu$, then
	\begin{equation}
		\frac{\epsilon_{k+1}}{\epsilon_k^q}
		=
		\frac{r^{q/(q-1)}(\mu^{q^{k-1}})^q}{r^{1/(q-1)}\mu^{q^{k}}}
		=
		r
		~~
		\fa k\geq 1
		\,.
	\end{equation}
\end{proof}

We close this section by showing that the one-parameter family of solutions to the entropic Poisson equation with ``temperature'' $\theta = \alpha^{-1}$ converge strongly (in $H^1(\Omega)$) to the solution of the obstacle problem as $\theta \to 0$.

\begin{theorem}
\label{cor:EntropicPoissonConvergence}
	Assume $\Omega \subset \mathbb{R}^n$ is an open, bounded Lipschitz domain, $n \ge 1$, and let $g \in H^1(\Omega) \cap C(\overline{\Omega})$ such that $\min g_{|\partial \Omega} > 0$.
	Let $u_\theta \in H^1_g(\Omega)\cap \interior L^\infty_+(\Omega)$ denote the solution of the entropic Poisson equation,
	\begin{equation}
	\label{eq:EntropicPoissonConvergence_EPE}
		(\nabla u_\theta, \nabla w)
		+
		\theta (\ln u_\theta, w)
		=
		(f, v)
		\quad
		\text{for all~}
		w \in H^1_0(\Omega)
		,
	\end{equation}
	and let
	\begin{equation}
		u^\ast
		=
		\argmin_{u\in H^1(\Omega)}
		~
		E(u)
		~~\text{subject to~}
		u \geq 0
		~\text{in~}\Omega
		~\text{and~}
		u = g
		~\text{on~}\partial\Omega
		.
	\end{equation}
	Then $u_\theta \to u^\ast$ in $H^1(\Omega)$ linearly with respect to $\theta$.
	In particular,
	\begin{equation}
		\|\nabla u^\ast - \nabla u_\theta\|_{L^2(\Omega)}^2
		\leq
		\theta (S(u^\ast) + |\Omega|)
		.
	\end{equation}
\end{theorem}
\begin{proof}
	For all functions $u \in L^{\infty}_+(\Omega)$, $v,w \in \interior L^\infty_+(\Omega)$, the representation theorem, \Cref{lem:EntropyDifferentiability}, and the three-points identity~\cref{eq:CosineIdentity}, together, give us
	\begin{equation}
	\label{eq:EntropicPoissonConvergence_TPI}
		D(u,v) - D(u,w) + D(v,w)
		=
		(\nabla S(v) - \nabla S(w), v - u )
		\,.
	\end{equation}
	Moreover, the characterization theorem, \Cref{thm:PrimalProblem}, tell us that~\cref{eq:EntropicPoissonConvergence_EPE} is equivalent to
	\begin{equation}
		S^\prime(u_\theta) = -\frac{1}{\theta} E^\prime(u_\theta)
		\,.
	\end{equation}
	Next, notice that $\nabla S(1) = \ln 1 = 0$ and, provided $u \in H^1(\Omega)$,
	\begin{equation}
		\langle E^\prime(u_\theta), u - u_\theta \rangle
		\leq
		E(u) - E(u_\theta)
		\,,
	\end{equation}
	by convexity.
	Thus, taking $u \in H^1_g(\Omega) \cap L^{\infty}_+(\Omega)$ and setting $v = u_\theta$ and $w = 1$ in~\cref{eq:EntropicPoissonConvergence_TPI} leads to
	\begin{align*}
		D(u,u_\theta) - D(u,1) + D(u_\theta,1)
		&=
		( \nabla S(u_\theta) - \nabla S(1), u_\theta - u )
		\\
		&=
		\langle S^\prime(u_\theta), u_\theta - u \rangle
		\\
		&=
		\frac{1}{\theta} \langle E^\prime(u_\theta), u - u_\theta \rangle
		\\
		&\leq
		\frac{1}{\theta} ( E(u) - E(u_\theta) )
		\,.
	\end{align*}
		Rerranging the inequality above and invoking~\Cref{prop:BregmanDivergenceProperties}, we find that
	\begin{equation}
		E(u_\theta) - E(u)
		\leq
		\theta (D(u,1) - D(u,u_\theta) - D(u_\theta,1))
		\leq
		\theta D(u,1)
		\,,
	\end{equation}
	where the second inequality arises because both $D(u,u_\theta)$ and $D(u_\theta,1)$ are non-negative.
	The proof is completed by setting $u = u^\ast$ and exploiting the strong convexity of $E$, as done in~\cref{eq:ConvergenceContinuousLevel_StrongConvexity}, and noting that $D(u,1) = S(u) + |\Omega|$.
\end{proof}






\section{Mathematical results II: Elementary finite element error analysis} \label{sec:the_entropic_finite_element_method}

The purpose of this appendix is to establish certain minor \textit{a priori} error analysis results related to the stability of the linearized subproblems encountered in~\Cref{alg:Obstacle_Newton}.
These results are necessary to motivate the finite elements proposed in~\cref{eq:SubspacePair1,eq:SubspacePair2}.
In short, the main outcome of this appendix is that the finite elements are stable and, therefore, we expect optimal high-order convergence rates for the solutions of the \emph{linearized} subproblems.
We intentionally stop short of providing a full \textit{a priori} error analysis of the \emph{nonlinear} subproblems or the complete proximal Galerkin method.
Such analysis is planned for a forthcoming paper in which we additionally aim to prove that the Proximal Galerkin method is \emph{mesh-independent}.






\subsection{Stability of the linearized subproblem} \label{sub:linear_stability_theory}


The first result of this section is that the linearized subproblems in~\Cref{alg:Obstacle_Newton} are stable at the continuous level.
In particular, they are uniformly stable with respect to $H^1(\Omega)$ and $H^{-1}(\Omega)$ when we replace $V_h$ and $W_h$ by $H^1_0(\Omega)$ and $L^2(\Omega)$, respectively.
The proof uses standard Hilbert space arguments for saddle-point problems; cf.~\cite[Section~4.3]{boffi2013mixed}.

\begin{theorem}
\label{thm:ContinuousStability}
	Let $\psi \in L^\infty(\Omega)$.
	Then, for every $f \in L^2(\Omega)$ and $g \in H^1(\Omega)$, the saddle-point problem
	\begin{equation}
	\label{eq:ContinuousStability}
		\left\{
		\begin{aligned}
															&\begin{alignedat}{4}
			( \nabla u, \nabla v) + (\delta, v) &= ( f, v)
			&&~\fa v \in H_0^1(\Omega),
			\\
			(u, \varphi) - (\delta \exp\psi, \varphi) &= (g, \varphi)
			&&~\fa \varphi \in L^2(\Omega),
			\end{alignedat}
		\end{aligned}
		\right.
	\end{equation}
	has a unique solution $u \in H_0^1(\Omega)$, $\delta \in L^2(\Omega)$ that satisfies
												\begin{subequations}
	\label{eq:StabilityBounds}
	\begin{equation}
	\label{eq:StabilityBound1}
		\|\nabla u\|_{L^2(\Omega)}
		\leq
		\|f\|_{H^{-1}(\Omega)} + \|\nabla g\|_{L^2(\Omega)}
		\,,
	\end{equation}
	and
	\begin{equation}
	\label{eq:StabilityBound2}
		\|\delta\|_{H^{-1}(\Omega)}
		\leq
		2\|f\|_{H^{-1}(\Omega)} + \|\nabla g\|_{L^2(\Omega)}
		\,.
	\end{equation}
	\end{subequations}
						\end{theorem}

\begin{remark}[Choice of norms]
	Notice that \cref{eq:StabilityBound2} is independent of $\psi$.
	The corresponding bound of the $L^2(\Omega)$-norm of $\psi$ degenerates as $\essinf \psi \to -\infty$; cf.~\cref{eq:LinearizedSaddleCoercivity}
	Thus, we choose to interpret \cref{eq:ContinuousStability} as a singularly-perturbed saddle-point problem and focus mainly on convergence of the incremental latent variable $\psi$ in the $H^{-1}(\Omega)$ norm.
\end{remark}

\begin{proof}[Proof of~\Cref{thm:ContinuousStability}]
	Existence and uniqueness of $u \in H_0^1(\Omega)$, $\delta \in L^2(\Omega)$ follows readily from the Lax--Milgram theorem.
	Indeed, notice that~\cref{eq:ContinuousStability} may be rewritten as
	\begin{equation}
	\label{eq:LinearizedSaddleRewrite}
		B((u,\delta),(v,\varphi)) = (f, v) - ( g, \varphi)
		~
		\fa v \in H_0^1(\Omega)
		\text{ and }
		\varphi \in L^2(\Omega)
		\,,
	\end{equation}
	where
	$
		B((u,\delta),(v,\varphi))
		=
		( \nabla u, \nabla v) + (\delta, v) - (u, \varphi) + (\delta \exp\psi, \varphi)
	$.
	Moreover, it is a straightforward exercise to check that
	\begin{equation}
	\label{eq:LinearizedSaddleCoercivity}
		\|\nabla u\|^2_{L^2(\Omega)} + \|\exp(-\psi)\|_{L^\infty(\Omega)}^{-1}\|\delta\|_{L^2(\Omega)}^2
		\leq
		B((u,\delta),(u,\delta))
		\,,
	\end{equation}
	for all $(u,\delta) \in H_0^1(\Omega) \times L^2(\Omega)$, which establishes the coercivity condition necessary to apply the theorem.

	We now turn to proving~\cref{eq:StabilityBounds}.
	From the first equation in~\cref{eq:ContinuousStability}, notice that
	\begin{align*}
		\|\delta\|_{H^{-1}(\Omega)}
		=
		\sup_{v \in H^1_0(\Omega)} \frac{(\delta, v)}{\|\nabla v\|_{L^2(\Omega)}}
		&\leq
		\sup_{v \in H^1_0(\Omega)} \frac{(\nabla u, \nabla v)}{\|\nabla v\|_{L^2(\Omega)}}
		+
		\sup_{v \in H^1_0(\Omega)} \frac{(f, v)}{\|\nabla v\|_{L^2(\Omega)}}
		\\
		&=
		\|\nabla u\|_{L^2(\Omega)} + \|f\|_{H^{-1}(\Omega)}
		\,.
	\end{align*}
	Thus, we may focus remainder of the proof on controlling $\|\nabla u\|_{L^2(\Omega)}$.
	The remaining arguments center on the equation
	\begin{equation}
		\|\nabla u\|_{L^2(\Omega)}^2
		+
		(\delta\exp\psi,\delta)
		=
		(f, u)
		- (g,\delta)
												\,,
	\end{equation}
	which follows from setting $v = u$ and $\varphi = \delta$ in~\cref{eq:LinearizedSaddleRewrite}.
	We now consider the cases $g = 0$ and $f = 0$ separately.
	\medskip

	\noindent\textit{Case 1: $g = 0$}.
	It is straightforward to see that
	\begin{equation}
		\|\nabla u\|_{L^2(\Omega)}^2
		\leq
		(\nabla u, \nabla u)
		+
		(\delta\exp\psi,\delta)
		=
		(f, u)
		\leq
		\|f\|_{H^{-1}(\Omega)}\|\nabla u\|_{L^2(\Omega)}
		\,.
	\end{equation}
	Thus, $\|\nabla u\|_{L^2(\Omega)} \leq \|f\|_{H^{-1}(\Omega)}$.
	\medskip

	\noindent\textit{Case 2: $f = 0$}.
	Notice that
	\begin{equation}
		\|\nabla u\|_{L^2(\Omega)}^2
		\leq
		(\nabla u, \nabla u) + (\delta \exp\psi,\delta)
		\leq
		\|\nabla g\|_{L^2(\Omega)}\|\delta\|_{H^{-1}(\Omega)}
		\,.
	\end{equation}
	Moreover, observe that
	\begin{equation}
		\|\nabla u\|_{L^2(\Omega)}
		=
		\sup_{v \in H^1_0(\Omega)} \frac{(\nabla u, \nabla v)}{\|\nabla v\|_{L^2(\Omega)}}
		=
		\sup_{v \in H^1_0(\Omega)} \frac{(\delta, v)}{\|\nabla v\|_{L^2(\Omega)}}
		=
		\|\delta\|_{H^{-1}(\Omega)}
		\,,
	\end{equation}
	where the second equality follows from the first equation in~\cref{eq:ContinuousStability}.
	Therefore,
	\begin{equation}
		\|\delta\|_{H^{-1}(\Omega)} = \|\nabla u\|_{L^2(\Omega)} \leq \|\nabla g\|_{L^2(\Omega)}\,.
	\end{equation}
	Collecting the inequalities above leads to~\cref{eq:StabilityBounds}.
\end{proof}

Our next result is that the finite elements~\cref{eq:SubspacePairs} are uniformly stable in $H^1(\Omega) \times H^{-1}(\Omega)$; i.e., they satisfy the Ladyzhenskaya--Babu\v{s}ka--Brezzi (LBB) stability condition
\begin{equation}
\label{eq:LBB}
	\beta_h :=
	\inf_{\varphi \in W_h} \sup_{v \in V_h}
	\frac{(\varphi,v)}{\|\varphi\|_{H^{-1}(\Omega)}\|\nabla v\|_{L^2(\Omega)}}
	> 0
	\,,
\end{equation}
and, furthermore, $\beta_h$ is strictly bounded away from zero for all mesh sizes $h>0$ and (clearly) independent of $\psi$.

\begin{lemma}
\label{lem:Fortin}
	Assume that $\mathcal{T}_h$ is a shape-regular sequence of affine meshes.
	Let $V_h$ and $W_h$ be the finite element spaces defined in~\cref{eq:SubspacePairs}.
	Then there is a constant $\beta_0$ such that for all $h>0$,
	\begin{equation}
	\label{eq:UniformStabilityConstant}
		\inf_{\varphi \in W_h} \sup_{v \in V_h}
		\frac{(\varphi,v)}{\|\varphi\|_{H^{-1}(\Omega)}\|\nabla v\|_{L^2(\Omega)}}
		\geq
		\beta_0
		> 0
		\,.
	\end{equation}
\end{lemma}

\begin{remark}[Idea of the proof]
\label{rem:FortinProof}
	The proof proceeds independently for each finite element pairing by constructing a so-called Fortin operator $\Pi_h \colon H^1_0(\Omega) \to V_h$ satisfying
	\begin{subequations}
	\begin{equation}
	\label{eq:FortinBoundednessCondition}
		\|\Pi_h v\|_{H^1(\Omega)}
		\leq
		C
		\|v\|_{H^1(\Omega)}
		\,,
	\end{equation}
	for some $h$-independent constant $C>0$, and 
	\begin{equation}
	\label{eq:FortinProjectionCondition}
		( \Pi_h v, \varphi) = (v, \varphi)
				~
		\fa v \in H^1_0(\Omega)
		\text{~and~} \varphi\in W_h
		\,.
	\end{equation}
	It is well-known that the existence of such an operator  on a fixed mesh $\mathcal{T}_h$ implies the LBB stability condition~\cref{eq:LBB}; see, e.g., \cite{fortin1977analysis} and \cite[Proposition~5.4.3]{boffi2013mixed}. See also \cite[Theorem~1]{ern2016converse} for the converse.
	Likewise, $h$-independence of the constant $C$ in~\cref{eq:FortinBoundednessCondition} implies the existence of the uniform discrete stability constant $\beta_0$ in \cref{eq:UniformStabilityConstant}.

	We employ a standard technique to construct our Fortin operators that involves splitting the operator into two terms; cf.~\cite[Section~5.4.4]{boffi2013mixed}.
	In particular, for each pair of subspaces $(V_h,W_h)$, we define $\Pi_h = \tilde{\mathcal{I}}_h + \tilde{\Pi}_{h}(I - \tilde{\mathcal{I}}_h)$, where $\tilde{\mathcal{I}}_h \colon H^1_0(\Omega) \to V_h$ is a quasi-interpolation operator (see, e.g., \cite[Section~22.4]{ern2021finite}) and $\tilde{\Pi}_{h} \colon L^2(\Omega) \to V_h$ is a linear operator satisfying
	\begin{equation}
	\label{eq:FortinProjectionCondition2}
		( \tilde{\Pi}_{h} v, \varphi) = (v, \varphi)
				~
		\fa v \in L^2(\Omega)
		\text{~and~} \varphi\in W_h
		\,,
	\end{equation}
	\end{subequations}
	and $\|\tilde{\Pi}_{h}(I-\tilde{\mathcal{I}}_h) v\|_{H^1(\Omega)} \leq C \|v\|_{H^1(\Omega)}$ for all $v \in H^1_0(\Omega)$.
	It is easy to check that such an operator satisfies~\cref{eq:FortinBoundednessCondition,eq:FortinProjectionCondition}.
	Indeed,
	\begin{equation}
		\|\Pi_h v\|_{H^1(\Omega)} \leq \|\tilde{\mathcal{I}}_h v\|_{H^1(\Omega)} + \|\tilde{\Pi}_{h}(I-\tilde{\mathcal{I}}_h) v\|_{H^1(\Omega)} \leq C \|v\|_{H^1(\Omega)}
		\,,
	\end{equation}
	and, moreover,
	\begin{equation}
		(\Pi_h v, \varphi)
		=
		(\tilde{\mathcal{I}}_h v, \varphi) - (\tilde{\Pi}_{h}(I-\tilde{\mathcal{I}}_h) v, \varphi)
		=
		(\tilde{\mathcal{I}}_h v, \varphi) - ((I-\tilde{\mathcal{I}}_h) v, \varphi)
		=
		(v,\varphi)
		\,,
	\end{equation}
	where the second equality follows from~\cref{eq:FortinProjectionCondition2}.

																	\end{remark}

\begin{proof}[Proof of~\Cref{lem:Fortin}]
	\textit{Case 1.} We first consider the $(\mathbb{P}_{p}\text{-bubble},\mathbb{P}_{p-1}\text{-broken})$ finite elements defined in~\cref{eq:SubspacePair1}.
	In this setting, we define $\tilde{\Pi}_{h}$ satisfying~\cref{eq:FortinProjectionCondition2} element-wise by solving the following local variational problem at each element $T \in \mathcal{T}_h$:
	\begin{equation}
	\label{eq:FortinSubproblemSubspace1}
		\left\{
			\begin{alignedat}{3}
				&\text{Find}~(\tilde{\Pi}_{h} v)_{|T} := v_T \in \mathring{\mathbb{P}}_{p+2}(T)
								~\text{such that}
				\\
				&
				(v_T, \varphi)_T = (v, \varphi)_T
				~
				\fa \varphi \in \mathbb{P}_{p-1}(T)
				\,.
			\end{alignedat}
		\right.
	\end{equation}
		Notice that $| \mathring{\mathbb{P}}_{p+2}(T) | = p(p+1)/2 = | \mathbb{P}_{p-1}(T) |$ and, in turn, each function $v_T \in \mathring{\mathbb{P}}_{p+2}(T)$ is well-defined.
	It is straightforward to see that the zero extension of $v_T$ --- i.e., the function $\overline{v}_T = v_T$ on $T$ and $0$ otherwise --- is a member of
	\begin{equation}
		V_h = \{ v \in H^1_0(\Omega) \mid v \in \hat{\mathbb{P}}_{p}(T) \oplus \mathring{\mathbb{P}}_{p+2}(T) \text{~for all~} T\in \mathcal{T}_h\}
		\,.
	\end{equation}
	Thus, we conclude that the operator $\tilde{\Pi}_{h} \colon H^1_0(\Omega) \to V_h$, given by $v \mapsto \sum_{T\in\mathcal{T}_h} \overline{v}_T$, is well-defined.

	We now analyze $\tilde{\Pi}_{h}$ more closely elementwise.
	To this end, let $\{b_i\}$ be a basis for $\mathring{\mathbb{P}}_{p+2}(T)$ and $\{\varphi_i\}$ be a basis for $\mathbb{P}_{p-1}(T)$.
	Upon writing $v_T = \sum_{j=1}^{p(p+1)/2} \mathsf{c}_j b_j$, we see that the variational problem~\cref{eq:FortinSubproblemSubspace1} is equivalent to the invertible linear system
	\begin{equation}
		\mathsf{M}_{ij}\mathsf{c}_j = \mathsf{d}_i
		\,,
		\qquad
		i = 1,2,\ldots,p(p+1)/2,
	\end{equation}
	where $\mathsf{M}_{ij} = (b_j,\varphi_i)_T$, and $\mathsf{d}_i = (v,\varphi_i)_T$.
	Standard scaling arguments (see, e.g., \cite[Proposition~28.5]{ern2021finite}) can be used to show that $\|\mathsf{M}^{-1}\|_{\ell^2} \leq C | T |^{-1}$.
	Meanwhile, H\"older's inequality can be used to show that
	\begin{equation}
		\mathsf{d}_i = \int_T v \varphi_i \dd x \leq \max_i \|\varphi_i\|_{L^\infty(T)} |T|^{1/2} \|v\|_{L^2(T)}
		\,,
	\end{equation}
	for each $i = 1,2,\ldots,p(p+1)/2$.
	Thus, we conclude that
	\begin{equation}
	\label{eq:lem_Fortin_scalingbound1}
		\|\mathsf{c}\|_{\ell^2}
		\leq
		\|\mathsf{M}^{-1}\|_{\ell^2}
		\|\mathsf{d}\|_{\ell^2}
		\leq
		C |T|^{-1/2} \|v\|_{L^2(T)}
		\,.
	\end{equation}
	A similar scaling argument (see, e.g., \cite[Lemma~11.7]{ern2021finite}) implies that
	\begin{equation}
	\label{eq:lem_Fortin_scalingbound2}
		| b_i |_{H^1(T)}
		\leq
		C h_T^{-1}|T|^{1/2}
		\,.
	\end{equation}
	Combining \cref{eq:lem_Fortin_scalingbound1,eq:lem_Fortin_scalingbound2}, we find that
	\begin{equation}
		| \tilde{\Pi}_{h} v |_{H^1(T)}
		=
		| v_T |_{H^1(T)}
		\leq C h_T^{-1} \| v\|_{L^2(T)}
		\,.
	\end{equation}

	The next step is to specify the quasi-interpolation operator $\tilde{\mathcal{I}}_h \colon H^1_0(\Omega) \to V_h$.
	We choose to use the operator defined in~\cite[Equation~6.10]{ern2017finite},
		which, by \cite[Theorem~6.3]{ern2017finite}, has the property that
	\begin{equation}
	 	\|(I - \tilde{\mathcal{I}}_h) v \|_{L^2(T)}
	 	\leq
	 	C h_T\|\nabla v\|_{L^2(\Omega_T)}
	 	~
		\fa v \in H^1_0(\Omega)
		\,,
	\end{equation}
	where $\Omega_T \subset \Omega$ is the union of mesh cells neighboring $T$.
	Setting $r = 0$ and $s=1$, we find that
	\begin{equation}
		|\tilde{\Pi}_{h}(I-\tilde{\mathcal{I}}_h) v|_{H^1(T)}
		\leq
		C h_T^{-1} \|(I-\tilde{\mathcal{I}}_h) v\|_{L^2(T)}
		\leq
		C\|\nabla v\|_{L^2(\Omega_T)}
		\,.
	\end{equation}
	Note that the maximum number of elements in $\Omega_T$ is bounded uniformly in $h$ owing to the regularity of the mesh sequence.
	Likewise, we find that
	\begin{equation}
		|\tilde{\Pi}_{h}(I-\tilde{\mathcal{I}}_h) v|_{H^1(\Omega)}^2
		\leq
		C
		\sum_{T\in\mathcal{T}}
		\|\nabla v\|_{L^2(\Omega_T)}^2
		\leq
		C
		\|\nabla v\|_{L^2(\Omega)}^2
		\,.
	\end{equation}
	We have succeeded in checking the conditions outlined in~\cref{rem:FortinProof} and the proof is complete.

	\textit{Case 2.} We now consider the $(\mathbb{Q}_{p}\text{-bubble},\mathbb{Q}_{p-1}\text{-broken})$ finite elements defined in~\cref{eq:SubspacePair2}.
	In this case, we define $\tilde{\Pi}_h v := v_h \in V_h$ element-wise by solving the local variational problems
	\begin{equation}
	\label{eq:FortinSubproblemSubspace2}
		\left\{
			\begin{alignedat}{3}
																												&\text{Find}~{v_h}_{|T} \in \mathring{\mathbb{Q}}_{p+1}(T)
				~\text{such that}
				\\
				&
				(v_h, \varphi)_T = (v, \varphi)_T
				~
				\fa \varphi \in \mathbb{Q}_{p-1}(T)
												\,.
			\end{alignedat}
		\right.
	\end{equation}
	Here, we notice that $| \mathring{\mathbb{Q}}_{p+1}(T) |=p^2=| \mathbb{Q}_{p-1}(T) |$.
	In particular, for every element $T\in \mathcal{T}_h$, the variational problem~\cref{eq:FortinSubproblemSubspace2} is equivalent to an invertible $p^2 \times p^2$ linear system, and so $\tilde{\Pi}_h v := v_h \in V_h$ is well-posed.
	The remainder of the proof proceeds as done in \textit{Case 1}.
\end{proof}

\begin{remark}[Alternative subspaces]
\label{rem:AlternativeSubspaces2}
	Notice that \Cref{lem:Fortin} implies that the pairing $(\tilde{V}_h, W_h)$ is uniformly stable for any subspace $\tilde{V}_h\subset H^1_0(\Omega)$ containing $V_h$.
	Indeed, observe that
	\begin{equation}
		\sup_{v \in \tilde{V}_h}
		\frac{(\varphi,v)}{\|\nabla v\|_{L^2(\Omega)}}
		\geq
		\sup_{v \in V_h}
		\frac{(\varphi,v)}{\|\nabla v\|_{L^2(\Omega)}}
		\geq
		\beta_0\|\varphi\|_{H^{-1}(\Omega)}
		\,,
	\end{equation}
	for all $\varphi \in W_h$.
	Thus, other elements such as the $(\mathbb{Q}_{p+1},\mathbb{Q}_{p-1}\text{-broken})$ pair proposed in \Cref{rem:AlternativeSubspaces1}, are also stable owing to the embedding $\mathbb{Q}^{p+1}_p(T) = \hat{\mathbb{Q}}_{p}(T) \oplus \mathring{\mathbb{Q}}_{p+1}(T) \subset \mathbb{Q}_{p+1}(T)$.
\end{remark}

We close this subsection with a proof that the $(\mathbb{P}_{p}\text{-bubble},\mathbb{P}_{p-1}\text{-broken})$ and $(\mathbb{Q}_{p}\text{-bubble},\mathbb{Q}_{p-1}\text{-broken})$ elements defined in~\cref{eq:SubspacePairs} converge optimally toward the solutions of the linearized subproblems~\cref{eq:ContinuousStability}.






\begin{theorem}
\label{thm:APrioriLinearized}
	Let $u_{h}$ and $\delta_{h}$ to be the discrete solutions of the saddle-point problem
	\begin{equation}
	\label{eq:APrioriLinearized_discrete}
		\left\{
		\begin{aligned}
			\,&\text{Find}~
			u_{h}\in V_{h} ~\text{and}~\delta_{h} \in W_{h}
			~\text{such that~}
			\\
			&\begin{alignedat}{4}
			( \nabla u_{h}, \nabla v) + (\delta_{h}, v) &= ( f, v)
			&&~\fa v \in V_{h}\,,
			\\
			(u_{h}, w) - (\delta_{h} \exp\psi, w) &= (\phi, w)
			&&~\fa w \in W_{h}\,,
			\end{alignedat}
		\end{aligned}
		\right.
	\end{equation}
	where $V_h$ and $W_h$ are the $(\mathbb{P}_{p}\text{-bubble},\mathbb{P}_{p-1}\text{-broken})$ and $(\mathbb{Q}_{p}\text{-bubble},\mathbb{Q}_{p-1}\text{-broken})$ finite element spaces defined in~\cref{eq:SubspacePairs}.
	Likewise, let $r \geq 1$ be an integer and assume that the unique solutions of the continous-level variational problem
	\begin{equation}
		\left\{
		\begin{aligned}
			\,&\text{Find}~
			u\in H_0^1(\Omega) ~\text{and}~\delta \in L^2(\Omega) 
			~\text{such that~}
			\\
			&\begin{alignedat}{4}
			( \nabla u, \nabla v) + (\delta, v) &= ( f, v)
			&&~\fa v \in H_0^1(\Omega)\,,
			\\
			(u, w) - (\delta \exp\psi, w) &= (\phi, w)
			&&~\fa w \in L^2(\Omega)\,,
			\end{alignedat}
		\end{aligned}
		\right.
	\end{equation}
	are sufficiently regular that $u \in H^{r+1}(\Omega)$ and $\delta \in H^{r-1}(\Omega)$.
	Then, if $\mathcal{T}_h$ is a shape-regular sequence of affine meshes, it holds that
	\begin{equation}
	\label{eq:RobustConvergence_LinearizedSubproblem}
		\|u - u_{h}\|_{H^1(\Omega)} + \|\delta - \delta_{h}\|_{H^{-1}(\Omega)}
		\leq
		C_1 h^s \big(|u|_{H^{s+1}(\Omega)} + |\delta|_{H^{s-1}(\Omega)}\big)
		\,,
	\end{equation}
	for all $1 \leq s \leq \min\{r,p\}$, where $C_1$ is a mesh-independent constant that remains bounded as $\essinf \psi \to -\infty$.
		Moreover, if in addition $\delta \in H^{r}(\Omega)$, then there exists a mesh-independet constant $C_2$ such that
	\begin{equation}
	\label{eq:L2Convergence_LinearizedSubproblem}
		\|\delta - \delta_{h}\|_{L^2(\Omega)}
		\leq
		C_2 h^s \big(|u|_{H^{s+1}(\Omega)} + |\delta|_{H^{s}(\Omega)}\big)
				\,,
	\end{equation}
	for each $1 \leq s \leq \min\{r,p\}$ above. 
		However, $C_2 \to \infty$ as $\essinf \psi \to -\infty$.
	\end{theorem}
\begin{proof}
	Most elements of the proof are standard, so we only give a sketch in the case of the $(\mathbb{P}_{p}\text{-bubble}, \mathbb{P}_{p-1}\text{-broken})$ finite elements defined in~\cref{eq:SubspacePair1}.
	We refer the interested reader to \cite[Section~5.5]{boffi2013mixed} for further details.
	Let $a\colon H^1_0(\Omega) \times H^1_0(\Omega) \to \mathbb{R}$ denote the bilinear form $a(u,v) = (\nabla u,\nabla v)$.
	Likewise, define denote $b(u,\varphi) = ( u, \varphi )$ and $c(\delta, \varphi) = (\delta \exp\psi, \varphi)$ for all $u \in H^1_0(\Omega)$ and $\delta,\varphi \in L^2(\Omega)$.
											Due to the stability of the linearized discrete subproblem~\cref{eq:APrioriLinearized_discrete} given to us by~\Cref{lem:Fortin} and coercivity of $a$, we appeal to the standard theory of mixed methods to arrive at the following \emph{a priori} estimate:
	\begin{multline}
	\label{eq:BAE}
		\|u - u_{h}\|_{H^1(\Omega)} + \|\delta - \delta_{h}\|_{H^{-1}(\Omega)}
		\\
		\leq
		C
		\left(
			\inf_{v \in V_h} \|u - v \|_{H^1(\Omega)}
			+
			\inf_{\varphi \in W_h} \|\delta - \varphi \|_{H^{-1}(\Omega)}
		\right)
		\,.
	\end{multline}
	
	For any Banach spaces $V$ and $W$, let $\|d\|$ denote the operator norm of a continuous bilinear form $d \colon V \times W \to \mathbb{R}$.
	A classical analysis given in, e.g., \cite[Section~4.3]{boffi2013mixed}, shows that $C$ depends at most on $\|a\|$, $\|b\|$, $\|c\|$, the coercivity constant for $a$, and $\beta_0$ that $C$ remains bounded as $\|c\| \to 0$.
	It is straightforward to check that $\|a\|, \|b\| \leq 1$ and $\|c\| = \|\exp \psi\|_{L^\infty(\Omega)}$.
	Finally, we note that the coercivity constant for $a$ depends only on the Poincar\'e constant of the domain $\Omega$ and $\beta_0$ is naturally independent of $\psi$.

	We now bound the two terms on the right-hand side of~\cref{eq:BAE}.
	Given that $\mathbb{P}_p(\mathcal{T}_h)\cap H^1_0(\Omega) \subset V_h$, we may consider the standard order-$p$ nodal interpolation operator $\mathcal{I}_h \colon H^{r+1}_0(\Omega) \to \mathbb{P}_p(\mathcal{T}_h)\cap H^1_0(\Omega)$; see, e.g., \cite[Section~19.3]{ern2021finite}.
	By shape-regularity of the mesh sequence and \cite[Corollary~19.8]{ern2021finite}, we have that
	\begin{equation}
		\|v - \mathcal{I}_h v\|_{H^1(\Omega)}
		\leq
		C h^s |v|_{H^{s+1}(\Omega)}
		\,,
		\qquad
		1 \leq s \leq \min\{r,p\}
		\,.
	\end{equation}
	Thus, we find that
	\begin{equation}
	\label{eq:Approximability_primalvariable}
		\inf_{v \in V_h} \|u - v \|_{H^1(\Omega)}
		\leq
		\|u - \mathcal{I}_h u \|_{H^1(\Omega)}
		\leq
		c h^s|u|_{H^{s+1}}
		\,.
	\end{equation}
	
	The second term on the right-hand side of~\cref{eq:BAE} is treated with the order-$(p-1)$ $L^2(\Omega)$-orthogonal projection operator $\mathcal{P}_h \colon L^2(\Omega) \to W_h = \mathbb{P}_{p-1}(\mathcal{T}_h)$, which has the well-known property
	\begin{equation}
	\label{eq:ProjectionConvergenceRates}
		\| \varphi - \mathcal{P}_h \varphi \|_{L^2(\Omega)}
		\leq
		C h^{t}|\varphi |_{H^t(\Omega)}
		\,,
		\qquad
		0\leq t \leq \min\{r-1,p\}
		\,.
	\end{equation}
		For further details, see, e.g., \cite[Section~18.4]{ern2021finite}.
	We now note that $\delta - \mathcal{P}_h\delta \in L^2(\Omega)$ and
	\begin{equation}
	\label{eq:L2ProjectionOrthogonality}
		(\delta - \mathcal{P}_h\delta, \varphi_h)
		=
		0
		~
		\fa \varphi_h \in W_h
		\,.
	\end{equation}
	Therefore, for any $\varphi_h \in W_h$, we may write
	\begin{equation*}
						\| \delta - \mathcal{P}_h\delta \|_{H^{-1}(\Omega)}
		=
		\sup_{\varphi \in H^1_0(\Omega)}
		\frac{(\delta - \mathcal{P}_h\delta,\varphi)}{\|\nabla \varphi\|_{L^2(\Omega)}}
		=
		\sup_{\varphi \in H^1_0(\Omega)}
		\frac{(\delta - \mathcal{P}_h\delta,\varphi - \varphi_h)}{\|\nabla \varphi\|_{L^2(\Omega)}}
		\,.
	\end{equation*}
	Taking $\varphi_h = \mathcal{P}_h\varphi$ and invoking~\cref{eq:ProjectionConvergenceRates}, we deduce that
	\begin{align*}
		\| \delta - \mathcal{P}_h\delta \|_{H^{-1}(\Omega)}
		&\leq
		\|\delta - \mathcal{P}_h\delta\|_{L^2(\Omega)}
		\sup_{\varphi \in H^1_0(\Omega)}
		\frac{\|\varphi - \mathcal{P}_h\varphi\|_{L^2(\Omega)}}{\|\nabla \varphi\|_{L^2(\Omega)}}
		\\
		&\leq
												C
		h^{s}|\delta|_{H^{s-1}(\Omega)}
		\,,
	\end{align*}
	since $\|\delta - \mathcal{P}_h\delta\|_{L^2(\Omega)} \leq C h^{s-1}|\delta|_{H^{s-1}(\Omega)}$ and $\|\varphi - \mathcal{P}_h\varphi\|_{L^2(\Omega)} \leq C h \|\nabla \varphi\|_{L^2(\Omega)}$.
	Inequality~\cref{eq:RobustConvergence_LinearizedSubproblem} now follows by collecting the above bounds.
	
	To prove~\cref{eq:L2Convergence_LinearizedSubproblem}, we appeal to Cea's lemma applied to the bilinear form $B$ in~\cref{eq:LinearizedSaddleRewrite}.
	In particular, notice that the coercivity constant in~\cref{eq:LinearizedSaddleCoercivity} vanishes as $\essinf \psi \to -\infty$.
	Therefore,
	\begin{equation}
	\label{eq:BAE_coercivity}
		\|\delta - \delta_{h}\|_{L^2(\Omega)}
		\leq
		C
		\left(
			\inf_{v \in V_h} \|u - v \|_{H^1(\Omega)}
			+
			\inf_{\varphi \in W_h} \|\delta - \varphi \|_{L^2(\Omega)}
		\right)
		\,,
	\end{equation}
	where the stability constant blows up, i.e., $C \to \infty$, as $\essinf \psi \to -\infty$.
	The remainder of the inequality~\cref{eq:L2Convergence_LinearizedSubproblem} is determined by invoking~\cref{eq:Approximability_primalvariable} and noting that $\|\delta - \mathcal{P}_h\delta\|_{L^2(\Omega)} \leq C h^{s}|\delta|_{H^{s}(\Omega)}$ by allowing $0\leq t \leq \min\{r,p\}$ in~\cref{eq:ProjectionConvergenceRates} because of the additional regularity assumed on $\delta$.
\end{proof}


\subsection{Nonlinear approximability} \label{sub:nonlinear_approximability}

We finish this appendix with a proof of \Cref{lem:UtildeBound}.

\begin{proof}[Proof of~\Cref{lem:UtildeBound}]
	Recall that $u = \exp \psi$ and, therefore,
	\begin{align}
		\tilde{u}_h - u 
		&=
		\exp\psi_h - \exp\psi
		=
		\int_{\psi}^{\psi_h} \exp s \dd s
		\\
		&=
		(\psi_h - \psi)\int_0^1 \exp (\psi + s(\psi_h - \psi)) \dd s
		\\
		&=
		(\psi_h - \psi)\exp \psi \int_0^1 (\exp(\psi_h - \psi))^s \dd s
		.
	\end{align}
	As such, it holds that
	\begin{align}
		\|u - \tilde{u}_h\|_{L^\infty}
		&\leq
		\|\psi - \psi_h\|_{L^\infty}
		\|\exp\psi\|_{L^\infty}
		\int_0^1
		(\exp\|\psi - \psi_h\|_{L^\infty})^s
		\dd s
		\\
		&=
		\|\exp\psi\|_{L^\infty}(\exp\|\psi - \psi_h\|_{L^\infty} - 1)
		,
	\end{align}
	where the last line follows from the identity $\int_0^1 a^s \dd s = (a - 1)/\ln a$.
\end{proof}


















{
\section*{Extended dedication from B.~Keith} \label{sec:dedication}
\it
Feynman once said that calculus is ``the language God talks'' \cite{wouk2010language}.
Expanding on this mystical statement, Strogatz has suggested that all physical laws are ``sentences'' in this ``language of the universe'' \cite{strogatz2019infinite}.
From my perspective, if the above is true, it must be the case that God has written his sentences in variational form.

The present work deals centrally with variational methods and a seemingly divine entropy functional that has never failed to surprise me since the day I began this project with Thomas.
In turn, I have frequently been reminded of von Neumann's famous quote to Shannon: ``No one knows what entropy really is'' \cite{tribus1971energy}.
Reflecting back on Feynman and Strogatz's perspectives, it is helpful to think that at least God knows, even if we do not.
As such, and on the occasion of his 70th birthday, it feels only fitting that I dedicate this work to Leszek Demkowicz; the kind and deeply religious man who not so long ago taught me a variational perspective on the universe.
}


\subsection*{Acknowledgements} \label{sub:acknowledgements}

The authors gratefully thank J\'er\^{o}me Darbon, Alexandre Ern, Patrick Farrell, Caroline Geiersbach, Dohyun Kim, Tarik Dzanic, Boyan Lazarov, Michael Hinterm\"uller, Thomas J.R.~Hughes, Karl-Hermann Neeb, Chi-Wang Shu, and N.~Sukumar for their time and helpful discussions during the development of this work.
We also thank Dohyun Kim, Tzanio Kolev, Boyan Lazarov, Socratis Petrides, and Jingyi Wang for peer-reviewing our MFEM implementations in order to merge them into the source code as official MFEM examples.
Finally, we thank J{\o}rgen Dokken for generously responding to our many inquiries about FEniCSx, as well as his help refactoring and preparing our FEniCSx implementations for public release.




\phantomsection\bibliographystyle{siamplain}
\bibliography{main.bib}

\end{document}
