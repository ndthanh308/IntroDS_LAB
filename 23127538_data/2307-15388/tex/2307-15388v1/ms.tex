\documentclass[10pt]{wlscirep}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{amsmath}
\usepackage{bm}
\usepackage{multirow}
\usepackage[draft]{pgf}
\usepackage{hyperref}
\usepackage{makecell}
\newcommand\setcurrentname[1]{\def\@currentlabelname{#1}}
\DeclareMathAlphabet{\mathcal}{OMS}{cmsy}{m}{n}

\makeatletter
\def\thickhline{%
  \noalign{\ifnum0=`}\fi\hrule \@height \thickarrayrulewidth \futurelet
   \reserved@a\@xthickhline}
\def\@xthickhline{\ifx\reserved@a\thickhline
    \vskip\doublerulesep
    \vskip-\thickarrayrulewidth
    \fi
    \ifnum0=`{\fi}}
\makeatother
\newlength{\thickarrayrulewidth}
\setlength{\thickarrayrulewidth}{4\arrayrulewidth}

\newcommand{\pjremark}[1]{\textcolor{purple}{[\textit{Peng: #1}]}}

\title{Does Full Waveform Inversion Benefit from Big Data?}

\author[1,2, *]{Peng Jin}
\author[1]{Yinan Feng}
\author[1]{Shihang Feng}
\author[1]{Hanchen Wang}
\author[3]{Yinpeng Chen}
\author[4]{Benjamin Consolvo}
\author[3]{Zicheng Liu}
\author[1,*]{Youzuo Lin}
\affil[1]{Earth and Environmental Sciences Division, Los Alamos National Laboratory}
\affil[2]{College of Information Sciences and Technology, The Pennsylvania State University}
\affil[3]{Microsoft}
\affil[4]{Intel}
\affil[*]{Corresponding Authors: pqj5125@psu.edu, ylin@lanl.gov}

%\keywords{Keyword1, Keyword2, Keyword3}

\begin{abstract}
This paper investigates the impact of big data on deep learning models for full waveform inversion (FWI).
% inverse problems guided by physical equations. We utilize the full waveform inversion (FWI), a geophysical inverse problem that aims to estimate subsurface velocity maps from seismic measurements, to demonstrate the impact through experiments. 
While it is well known that big data can boost the performance of deep learning models in many tasks, its effectiveness has not been validated for FWI. To address this gap, we present an empirical study that investigates how deep learning models in FWI behave when trained on \textsc{OpenFWI}, a collection of large-scale, multi-structural datasets published recently. Particularly, we train and evaluate the FWI models on a combination of 10 2D subsets in \textsc{OpenFWI} that contain 470K data pairs in total. Our experiments demonstrate that larger datasets lead to better performance and generalization of deep learning models for FWI. We further demonstrate that model capacity needs to scale in accordance with data size for optimal improvement.

\end{abstract}
\begin{document}

\flushbottom
\maketitle
% \thispagestyle{empty}

% \noindent Please note: Abbreviations should be introduced at the first mention in the main text – no abbreviations lists. Suggested structure of main text (not enforced) is provided below.

\section*{Introduction}
% Big data intro
The recent advancements of deep learning in natural language processing and computer vision have proven that big data is one of the key ingredients for obtaining good performance~\cite{brown2020language, sun2017revisiting, kolesnikov2020big, schuhmannlaion}. Similarly, in the context of science, deep learning models such as AlphaFold~\cite{jumper2021highly} have achieved significant breakthroughs with the help of large-scale datasets. However, unlike these tasks, large-scale public datasets are not always available for many other scientific problems due to the issues such as high data acquisition costs, high labeling costs, or security concerns. As a result, the capability of existing deep learning models for these scientific problems may not be fully exploited. 

% - FWI intro, OpenFWI
Full waveform inversion (FWI) is such a problem in geophysics. The objective of FWI is to reconstruct subsurface velocity maps $v$ from seismic measurements $p$ as depicted in Figure~\ref{fig:fwi}. Conventional FWI methods~\cite{fichtner2010full, zhang2012wave,ma2012image, zhang2013double,feng2019transmission+,feng2021mpi, lin2014acoustic, lin2015quantifying, hu2009simultaneous, guitton2012blocky,chen2020multiscale} leverage the forward operator $f$ governed by a partial differential equation (PDE) and perform iterative optimization per sample, which is computationally expensive and yields poor scalability. To mitigate this issue, deep learning techniques have been recently introduced to FWI and achieved promising performance~\cite{wang2020velocity, liu2021deep, araya2018deep, yang2019deep, ren2021building, geng2022deep}. A good summary of deep learning techniques for solving FWI problems can be found in Lin et al.~\cite{lin2023physics}. Inspired by the image-to-image translation task in computer vision, these data-driven methods directly learn an inverse mapping $f^{-1}$ from seismic data to velocity maps. Nevertheless, due to the aforementioned issue of lacking large-scale public datasets, the models in prior works were all developed on relatively small datasets (i.e. 130 to 67K data pairs)~\cite{araya2017automated,wu2019inversionnet,zhang2020data}. Thus, the question remains open: \textit{does full waveform inversion benefit from big data?} Thankfully, the recently published large-scale datasets \textsc{OpenFWI}~\cite{deng2022openfwi} provide us an opportunity to answer this question. % does full waveform inversion benefit from big data? do deep learning models in FWI benefit from big data?

% - Project overview
% - Contribution
In this paper, we leverage the \textsc{OpenFWI} and present an empirical study that attempts to answer the question from three perspectives: model performance, the relationship between the model size and data size, and model generalization. \textsc{OpenFWI} is a collection of large-scale, multi-structural datasets that cover different domain interests, including interfaces, geological faults, and field data. In this study, we employ 10 2D synthetic datasets from \textsc{OpenFWI}, and 408K and 62K data pairs are used to train and evaluate the deep learning models, respectively. We adopt one of the \textsc{OpenFWI} benchmark models InversionNet~\cite{wu2019inversionnet} to serve as the baseline, and we compare the inversion results of the baselines trained on relatively small-scale individual datasets and the models trained on large-scale datasets that are composed of multiple datasets. We name the latter models \textit{BigFWI}. Our findings are summarized as follows: 
% We employ the InversionNet~\cite{wu2019inversionnet} as the shared network architecture across all experiments.
% and we hope this study can serve as a guideline for future data-driven full waveform inversion research.
\begin{itemize}[topsep=0pt] %,noitemsep]
    \itemsep -0.5em
    % FWI needs big data
    \item \textbf{Big data can boost the performance of deep learning models in FWI.} BigFWI outperforms the baselines on almost every dataset in terms of all the evaluation metrics. 
    \item \textbf{Larger data requires larger models.} When more training samples are introduced, larger models are required in BigFWI to achieve further improvement compared to the baselines. 
    % When half of each dataset is used for training (i.e. 204K data pairs in total), BigFWI outperforms the baselines on almost every dataset by an average improvement of 13.03\% in mean absolute error (MAE), 7.19\% in root mean squared error (RMSE) and 1.87\% in structural similarity (SSIM). 
    % FWI needs big model for big data
    \item \textbf{Big data can improve the generalization of deep learning models in FWI.} Given a dataset that is unseen during training, BigFWI yields better performance than any baselines trained on single datasets. 
    % When more training data is included, the benefit of combination diminishes. However, we can retain the improvement by increasing the model size. BigFWI with a larger model size outperforms the baseline models by an average improvement of 18.66\% in MAE, 13.62\% in RMSE, and 2.17\% in SSIM. 
\end{itemize}

% Figure environment removed

\section*{Results}

\subsection*{OpenFWI Datasets}
All the experiments in our study are conducted on the aforementioned \textsc{OpenFWI} datasets. Compared to other existing synthetic datasets for FWI, \textsc{OpenFWI} is public available and offers a rich collection of large-scale multi-structural benchmark datasets 
% Families 
According to the domain interests, the datasets in \textsc{OpenFWI} are divided into four groups: ``\textit{Vel Family}'', ``\textit{Fault Family}'', ``\textit{Style Family}'' and ``\textit{Kimberlina Family}''. We exclude the ``\textit{Kimberlina Family}'' in our experiments because the dimensions of both velocity maps and seismic data in ``\textit{Kimberlina Family}" are different from the other three families. This allows us to combine the data samples from different datasets to train BigFWI models. 
% Naming
In terms of the complexity of subsurface structures, each of the three families consists of an easy version (\textit{-A}) and a hard version (\textit{-B}). In addition, the datasets in ``\textit{Vel Family}'' and ``\textit{Fault Family}'' are further divided into the flat version (\textit{Flat-}) and the curved version (\textit{Curve-}) in accordance with the shape of rock layers. In summary, the 10 datasets employed in our experiments are: \textit{FlatVel-A/B}, \textit{CurveVel-A/B}, \textit{FlatFault-A/B}, \textit{CurveFault-A/B}, and \textit{Style-A/B}. We use the abbreviations (e.g. FVA for FlatVel-A) in the rest of the paper. 

% Size and dimensions
Each dataset in ``\textit{Vel Family}", ``\textit{Fault Family}", ``\textit{Style Family}" is officially splitted into 24K/6K, 48K/6K, and 60K/7K pairs of seismic data and velocity maps for training and testing, respectively. We follow this splitting through our experiments. Figure~\ref{fig:fwi} shows the example of a velocity map and seismic data. Each velocity map has dimensions of $70\times70$ (depth $\times$ length in grids) with a grid spacing of 10 meters in both directions. The dimensions of the seismic data are $5\times1000\times70$ (\# of sources $\times$ \# of timesteps $\times$ \# of receivers). Five sources are evenly distributed on the top surface, each of which is a Ricker wavelet with a central frequency of 15 Hz. The interval between timesteps is 1 millisecond, and the receivers are also placed with an interval of 10 meters.

% Additional data
% In addition to the samples in \textsc{OpenFWI}, we follow the data generation pipelines described in the original paper\cite{openfwi} and generate additional velocity maps and seismic data for each dataset, as mentioned in the previous section. % section name TBD


% evaluation
\subsection*{Evaluation Metrics}
We follow the benchmarking guidelines in \textsc{OpenFWI} and compute three metrics between the ground truth and the prediction of velocity maps to evaluate the performance of a model: mean absolute error (MAE), root mean squared error (RMSE), and structural similarity (SSIM)~\cite{wang2004image}. Both MAE and RMSE are commonly used to measure pixel-wise errors, while SSIM aligns better with human vision and measures the perceptual similarity that is more related to structural information. When calculating MAE and RMSE, we keep the velocity maps in the normalized scale $[-1, 1]$. During the calculation of SSIM, we rescale the velocity maps to $[0, 1]$ as required by the algorithm, and the side length of the sliding window is set to 11. 

\subsection*{Big data benefits FWI} \label{sec:msg1}
% Shihang
We first design an experiment to explore if the performance of the data-driven FWI models can be improved by enlarging the training set. Specifically, we train a single model (i.e., BigFWI) on the combination of the datasets in \textsc{OpenFWI} and compare its performance with the baseline InversionNet models trained on each split dataset. All the models share the same training hyperparameters and network architecture which are discussed later in the Method section. Instead of using all the samples in \textsc{OpenFWI}, we randomly select 12K samples from each of the four datasets in Vel Family, 24K from each of the four in the Fault Family, and 30K from each of the two in the Style Family. All these samples are extracted from the official training sets. The rest of the samples in the official training sets are reserved for the experiment in the next section, where we want to further enlarge the datasets. In this way, the combined large-scale training set consists of 204K samples in total, and we name it OpenFWI-204K. The test sets are directly adopted from \textsc{OpenFWI} without any selection.

We plot the performance improvement of BigFWI compared to the InversionNet on each dataset in Figure~\ref{fig:204k_imp}. The quantitative results are provided in the supplementary material. We observe that BigFWI shows a clear improvement for all the datasets except for datasets FVA and FVB, which are comprised of flat layers only. The potential reason can be that the network focuses more on the prediction of curved layers which exist in most of the other datasets, and it has a negative impact on the prediction of flat layers. Another observation is that BigFWI exhibits more significant improvements in terms of MAE and RMSE for datasets A compared to datasets B across all families. Conversely, the comparison of SSIM demonstrates the opposite trend, with the B datasets exhibiting better SSIM improvements compared to the A datasets in the same family. This variation in performance could be attributed to the greater complexity of the B datasets. The discrepancies in the baseline structures may not impact statistical misfits such as MAE and RMSE, but they may influence the SSIM. Thus, the simpler A datasets tend to benefit more from the larger data volume than the more intricate B datasets.

We also plot one example velocity map of each split dataset predicted by the networks, shown in Figure~\ref{fig:204k_vis}. The ground truth of each example is shown as a comparison in the same figure. By visual inspection, we observed that InversionNet predicts the velocity maps with various kinds of errors, such as extra bottom layer anomalies (FVA), inaccurate layer values (CVA, CVB), and inaccurate structures (FVB, FFB, CFA, CFB). As a comparison, BigFWI models generally yield better performance in predicting the velocity maps. The inverted results have more accurate structure and velocity value predictions. This can be attributed to the knowledge learned from the 
large-scale training set that consists of various velocity map distributions. Here, we define the velocity map distributions as the different geological subsurface structures in OpenFWI, i.e. flat layers vs. curved layers, faults vs. non-fault, and smooth vs. sharp. However, it is also because of the variety that BigFWI models may have structure layer boundary inaccuracy, such as the non-flat interfaces in FVA/FVB, which is transferred from other domains. This is consistent with the previous observations in Figure~\ref{fig:204k_imp}. In addition, since FVB contains more layers than FVA, the model performance on FVB degrades much more than it on FVA. 

% Figure environment removed

% Figure environment removed
% Why improvment of A larger than B in terms of MAE & RMSE?
% Why improvment of B larger than A in terms of SSIM?


% Qualitative analysis
% Peng's observation for reference
% FVA:
%  - InversionNet: bottom layer anomaly
%  - BigFWI: accurate bottom layer but layer boundary affected by other datasets
% FVB:
%  - InversionNet: bottom layer inaccurate
%  - BigFWI: same as FVA
% CVA  InversionNet: bottom layer blurry, inaccurate additional layer
% CVB  InversionNet: layer boundary blurry
% FFA  InversionNet: inaccurate fault in shallow layer
% FFB  InversionNet: inaccurate fault
% CFA  InversionNet: layer boundary blurry
% CFB  challenge for both, but BigFWI predicts more accurate layer boundaries
% SA   similar results
% SB   InversionNet: more high frequency component, visually better than BigFWI

\subsection*{Big data in FWI requires larger models}
\begin{table}[t]
\centering
\setlength{\tabcolsep}{6pt}
\renewcommand{\arraystretch}{1.25}
\begin{tabular}{c c c c c }
\thickhline
% Model & \makecell{Encode\\Layers} & \makecell{Decode\\Layers} & \makecell{Latent\\Length} & Parameters 
Model & Encode Layers & Decode Layers & Latent Length & Parameters \\ \thickhline
BigFWI-B & 14 & 11 & 512 & 24M \\ \hline
BigFWI-M & 17 & 16 & 512 & 28M \\ \hline
BigFWI-L & 16 & 14 & 1024 & 87M \\ \thickhline
\end{tabular}
\caption{Configurations of BigFWI model variants.}
\label{tab:model}
\end{table}


% Figure environment removed


% Hanchen
To explore the relationship between the size of the training set and the size of the data-driven FWI models, we conduct an experiment that is similar to the previous one but employs the full training set provided by \textsc{OpenFWI}. Hence, the training set now contains 408K samples, and we name it OpenFWI-408K for brevity. Regarding model size, we introduce three variants of BigFWI as described in Table~\ref{tab:model}, including the ``\textbf{B}ase'' configuration in the previous experiment, the ``\textbf{M}iddle'' model with additional layers in both encoder and decoder, and the ``\textbf{L}arge'' one that is both deeper and wider. The details of the network architecture are discussed later in the Method section. We keep the baselines which are InversionNet trained on OpenFWI-204K. Additionally, we train the InversionNet on each split datasets of OpenFWI-408K for comparison, and all these models share the same network architecture with BigFWI-B.

% To investigate the necessity of employing larger data-driven FWI models for seismic imaging problems when the size of the training set is further enlarged. To achieve this, an experiment was designed that is similar to a previous one but employs all the samples in each officially split training set. Specifically, the training set now contains 408K samples, and we name it OpenFWI-408K for brevity. Additionally, the network architecture of the BigFWI model was expanded, making it deeper by adding additional convolutional layers and named BigFWI-L. The details of the expanded network architecture are discussed later in Section Network Architecture.

% \newline
In Figure~\ref{fig:408k_imp}, we show the statistical performance improvement in the percentage of the baseline models, which are the InversionNet trained on the split components of OpenFWI-204K. More detailed quantitative results are provided in the supplementary material. Overall, all the models trained on OpenFWI-408K yield better performance compared to the baselines trained on OpenFWI-204K, and the BigFWI models (coral, blue and orange bars) outperform InversionNet (green) for almost every dataset, which again verifies that larger training set brings better performance. We further observe that among three BigFWI variants, larger models yield better performance in general. In particular, BigFWI-L (coral) and BigFWI-M (blue) outperform BigFWI-B (orange) by a large amount in all three metrics for relative simple datasets such as FVA, FVB, FFA and CFA. For relatively complicated datasets such as CFB and SA, the gap is narrower. For dataset SB, BigFWI-B even outperforms BigFWI-L. This infers that larger models are preferred for most big data scenarios, but additional efforts such as more advanced network architectures are still required for some complicated cases. 


% We observe that the BigFWI-L model trained on OpenFWI-408K (blue bars) has the largest improvement in all three statistic matrices across all the datasets compared to the BigFWI (orange) and InversionNet (green) models trained with the same data volume.

% \newline

% \newline
We also plot the visualized ground truth and predictions of velocity maps, as shown in Figure~\ref{fig:408k_vis}. Although the performance of InversionNet has improved statistically when trained on larger datasets, the aforementioned errors in prediction still exist. In contrast, BigFWI generally offers enhanced accuracy in layer location and velocity values. By further comparing the performance difference between BigFWI models, BigFWI-L and BigFWI-M clearly overtakes BigFWI-B in many aspects. For instance, the flat interfaces in FVA and FVB are more flat and sharp in the results of BigFWI-L and BigFWI-M than the ones of BigFWI-B. BigFWI-M also predicts more accurate fault slopes in FFA and FFB. A similar observation can be obtained from the Style Family results, in which BigFWI-L and BigFWI-M predict the most accurate kinematic information than InversionNet and BigFWI-B. Although InversionNet predicts more high-frequency components, the scatters are inaccurate in shape, which will introduce even larger data misfit in the FWI scheme.

% \newline
The study findings in this experiment indicate that a broad principle can be inferred that when processing large volumes of seismic data and imaging the corresponding subsurface structures, large-scale networks are more effective than small-scale networks. The reason behind this is that the processing, analysis, and storage of seismic data can be quite challenging due to its volume and complexity. In this regard, large-scale neural networks have a distinct advantage over their smaller counterparts as they are better equipped to manage these challenges. Therefore, it is important to scale up the size of the neural network used for seismic imaging in proportion to the volume of seismic data being analyzed to obtain accurate results. As seismic data continues to increase in volume, small-scale neural networks may not be able to process, analyze, and image the data effectively. On the other hand, large-scale neural networks can handle the demands of processing and analyzing massive volumes of seismic data, enabling them to extract more detailed and accurate insights. In summary, to achieve optimal results in seismic imaging, it is essential to enlarge the scale of the neural network used in proportion to the volume of seismic data being processed.


% Figure environment removed
% Why improvement of A larger than B in terms of MAE & RMSE?
% Why improvement of B larger than A in terms of SSIM?

% Qualitative analysis
% Peng's observation for reference
% FVA:
%  - InversionNet: bottom layer anomaly (small)
%  - BigFWI: no anomaly accurate bottom layer but layer boundary affected by other datasets
%  - BigFWI-L: more flat
% FVB:
%  - InversionNet: one layer missing
%  - BigFWI & BigFWI-L: not flat
% CVA  InversionNet: bottom layer inaccurate
% CVB  InversionNet: bottom layer inaccurate
% FFA  BigFWI-L: more accurate fault slope 
% FFB  InversionNet: extra layer on the left
% CFA  InversionNet: extra layer & inaccurate fault
% CFB  InversionNet: high velocity area at the bottom not complete
% SA   similar results
% SB   similar results, but InversionNet yields more high frequency components, visually better than BigFWI; BigFWI improved but still not enough



\subsection*{Big data leads to better generalization}
% Yinan
To verify whether large-scale training data also leads to better generalization, we design the experiment where the BigFWI models are trained under leave-one-out settings. Specifically, given a target dataset for testing (e.g., FVA), we train the BigFWI model on the combination of the training samples from all the other datasets in \textsc{OpenFWI} (e.g., FVB, CVA/B, FFA/B, CFA/B, and SA/B). We then compare the performance of this BigFWI model on the test samples of the target dataset (e.g., FVA) with the baseline models, which are trained on split datasets other than the target one. 

In Figure~\ref{fig:gen}, we present the statistical performance improvement in the percentage of the best generalization performance of InversionNet models. BigFWI shows superior performance across all the datasets, especially in terms of MAE and RMSE. This yields that big data leads to better generalization ability. Notably, utilizing datasets A as the target set results in greater improvements in terms of MAE and RMSE, while datasets B show greater improvements in terms of SSIM. The supplementary material provides detailed quantitative results.

In Fig~\ref{fig:gen_vis}, we illustrate one example that compares the generalization results of different methods to the ground truth. From the figure, we observe that InversionNet produces inaccurate layer structures for out-of-distribution (OOD) data. In FFA, FFB, CVA, FFA, and SA, InversionNet's generalization outputs have errors of blurred borders, wrong layer positions, and inaccurate velocity values, especially in deep parts. Moreover, the results clearly have incorrect patterns from other datasets in more complex datasets (i.e., CVB, FFB, CFA and CFB). Meanwhile, these explain why we could find higher SSIM improvement in these four datasets in Fig.~\ref{fig:gen}. Conversely, our BigFWI benefits from its large-scale cross-domain training set and can effectively capture more essential features of different datasets. Thus, it has more accurate predictions on OOD data.


% Figure environment removed

% Figure environment removed


\section*{Discussion}
% Peng
In summary, we presented an empirical study to determine the extent to which big data can benefit the deep learning models in FWI from three perspectives: model performance, the relationship between model size and data size, and model generalization. To accomplish this, we utilized the large-scale, publicly available datasets \textsc{OpenFWI} and designed the experiments to compare the performance of baseline InversionNet trained on relatively small-scale individual datasets with that of BigFWIs, which are trained on combined, large-scale datasets. Through both quantitative and qualitative analysis, our study has demonstrated that big data can significantly enhance the performance of deep learning models in FWI on both in-distribution and out-of-distribution data. Moreover, we have shown that model capacity needs to be scaled with data size to achieve further improvement. We hope that our findings can provide valuable guidance for the future development of deep-learning-based FWI methods.  

This study is a preliminary investigation into the influence of big data on deep learning FWI methods, and there still exist some limitations and promising future directions. First, our study is entirely based on \textsc{OpenFWI}, which brings us not only convenience but also several inherent limitations. Although the Style Family in \textsc{OpenFWI} has made an effort to simulate the real-world velocity maps, there is still a gap between the synthetic data and field data. Our experiments are thus limited to simulations. It is an ongoing challenge for the whole FWI community to bridge this gap by either providing more public field data or improving the fidelity of the simulation. Second, in the present study, we only made minimal modifications to the network architecture of BigFWI. As a potential direction of future work, we may develop different network architectures to further improve performance. For instance, we observed during the qualitative analysis that the cross-domain training could lead to interference between datasets and inaccurate layer boundaries. Such issues could potentially be addressed by implementing an adaptive network architecture.  


This study offers valuable insights into the inverse problem, which can contribute to the advancement of this concept in other domains, including medical imaging, climate modeling, and astronomy. The knowledge gained from this investigation can be leveraged to support the application of AI in scientific research and enhance its capabilities in these fields.

% The Discussion should be succinct and must not contain subheadings.
% Limitation & Future work
% synthetic datasets, challenge to obtain real data
% how to deal with datasets with different settings (# of sources, grid size, etc.)
% how to modify the network to condition it on the dataset (e.g. embedding)

\section*{Methods}
\subsection*{Full Waveform Inversion}
% Equation & Data-driven FWI
Figure~\ref{fig:fwi} provides an illustration of 2D data-driven FWI and forward modeling. The governing equation of the acoustic wave forward modeling in an isotropic medium with a constant density can be described as follows:
%
\begin{equation} \label{eq:1}
  \nabla^2 p(\bm{r}, t) - \frac{1}{v(\bm{r})^2} \frac{\partial^2p(\bm{r}, t)}{\partial t^2} = s(\bm{r}, t)\;,
\end{equation}
%
where $\nabla^2$ is the Laplace operator, $p(\bm{r}, t)$ denotes the pressure wavefield at spatial location $\bm{r}$ and time $t$, $v(\bm{r})$ represents the velocity map of wave propagation, and $s(\bm{r}, t)$ is the source term. As shown in Fig.~\ref{fig:fwi}, the goal of forward modeling is to simulate seismic data $\tilde{p}$ from a given velocity map $v$. For simplicity, we formulate this process as:
\begin{equation}
    \tilde{p} = f({v}),
\end{equation}
where $f(\cdot)$ represents the highly nonlinear forward operator. As mentioned above, data-driven FWI methods directly learn the inverse mapping as: 
\begin{equation}
\hat{v} = g_\theta(p)=f^{-1}({p}),
\end{equation}
where $\hat{v}$ is the estimated velocity map and $g_\theta(\cdot)$ is the approximated inverse operator of $f(\cdot)$, which is usually implemented as neural networks parameterized by $\theta$. Our BigFWI is developed to leverage large-scale datasets to obtain a more precise and universal approximation of the inverse operator. 


\subsection*{Network Architecture} 
Our BigFWI shares a similar network architecture with the baseline InversionNet. Overall, the model is comprised of an encoder $\mathcal{E}$ and a decoder $\mathcal{D}$. The encoder $\mathcal{E}$ first extracts the spatial-temporal features from the seismic input $p\in\mathbb{R}^{S\times T\times R}$ and compresses them into a latent vector $z=\mathcal{E}(x)\in \mathbb{R}^{L\times 1\times 1}$. Here, $S$ equals the number of sources used in seismic surveys or simulation, $T$ represents the number of samples recorded by each receiver, $R$ denotes the number of receivers, and $L$ is the length of the latent vector. The decoder $\mathcal{D}$ then transforms the latent vector $z$ into spatial domain and generates the estimation of the velocity map $\hat{v}=\mathcal{D}(z)\in \mathbb{R}^{1\times W\times H}$, where $W$ and $H$ denote the horizontal (i.e. length) and vertical (i.e. depth) dimensions of the velocity map. Both the encoder $\mathcal{E}$ and the decoder $\mathcal{D}$ are fully based on 2D convolutional and deconvolution layers, and the details are presented as follows.

In the encoder $\mathcal{E}$, since $T=1000$ is much larger than $R=70$ in the seismic data $p$ of \textsc{OpenFWI}, we first reduce temporal dimension and extract temporal features by stacking seven convolutional layers with $n\times1$ kernels, where $n=7$ in the first layer, and $n=3$ in the following six layers. The stride along the temporal dimension is set to 2 for every other layer to reduce the temporal dimension until it is close to the spatial dimension. We then stack six layers with $3\times3$ kernels to extract spatial-temporal features at the same time. Stride 2 is now applied to both dimensions every other layer. In BigFWI-M, instead of stacking six layers, we stack nine layers where an additional $3\times3$ layer with stride 1 is added after every two layers so as to increase model capacity without changing the dimensions of the original feature maps. In BigFWI-L, we stack eight layers where two additional $3\times3$ layer with 1024 features maps are appended at the end. In BigFWI-B and BigFWI-M, we use a layer with an $8\times9$ kernel to flatten the feature maps of the last to a 512-length latent vector $z$. In BigFWI-L, a layer with $4\times5$ kernel is used, and the length of latent vector is 1024. 

% \subsubsection*{CNN Decoder}
The decoder $\mathcal{D}$ includes five deconvolution layers for upsampling, and each of them is followed by one convolutional layer with $3\times3$ kernels in BigFWI-B and two convolutional layers in BigFWI-M. The first deconvolution layer with kernel size 5 transforms the latent vector $z$ into a $512\times5\times5$ tensor. The rest of the deconvolution layers with kernel size 4 and stride 2 upsample the feature maps by a factor of 2, resulting in an $80\times80\times32$ tensor. We then apply center cropping followed by a $3\times3$ convolutional layer to output a single channel $70\times70$ velocity map. In BigFWI-L, the kernel size of the first deconvolution layer is 2, and there are six groups of deconvolution and convolutional layers.

All the convolutional and deconvolution layers are followed by batch normalization and LeakyReLU as the activation function, except for the last output layer, which uses Tanh to generate the velocity map between $[-1, 1]$.

%  Loss function
\subsection*{Loss Function}
Different from \textsc{OpenFWI} where the InversionNet is trained with pixel-wise $\ell_1$ loss or $\ell_2$ loss  between the ground truth of velocity maps $v$ and the predictions $\hat{v}$, we train the baseline InversionNet and our BigFWIs using a combination of two loss functions to leverage the advantages from both sides according to the previous study~\cite{zhang2020data}. Therefore, the loss function can be described as:
\begin{equation}
    \mathcal{L}(v, \hat{v}) = \frac{1}{W\cdot H} \sum_{i=1}^{W} \sum_{j=1}^{H}|v_{ij} - \hat{v}_{ij}| + \frac{1}{W\cdot H} \sum_{i=1}^{W} \sum_{j=1}^{H} \sqrt{(v_{ij} - \hat{v}_{ij})^2}.
\end{equation}


\subsection*{Training Details}
% training
We use identical hyperparameters to train all the models in our experiments. Specifically, we employ AdamW optimizers with momentum parameters $\beta_1=0.9$, $\beta_2=0.999$, and a weight decay of $1\times10^{-4}$ to update the parameters of each model. The base learning rate is set to $8\times10^{-4}$, and the models are trained for 170 epochs. In the first five warm-up epochs, we linearly increase the learning rate from $1\times10^{-4}$, and we decay the learning rate by a factor of 10 at epoch 150 and epoch 160, respectively. The batch size is set to 256. All the models are implemented in PyTorch and trained on 4 NVIDIA Tesla V100 GPUs. We employ the natural logarithmic transformation to make the intensity of seismic data more balanced and normalize the data to range $[-1,1]$ before they are fed into the network. The velocity maps are also normalized to the same scale before we compute the loss.

% \section*{Data Availability}

% \section*{Code Availability}

\section*{Data and Codes Availability}
OpenFWI data set can be downloaded from the website~(\url{https://openfwi-lanl.github.io/}). InversionNet codes are released and can be downloaded from the Website~(\url{https://github.com/lanl/OpenFWI/}).

\bibliography{sample}

\section*{Acknowledgements}

This work was funded by the U.S. Department of Energy~(DOE) Office of Fossil Energy’s Carbon Storage Research Program via the Science-Informed Machine Learning to Accelerate Real Time Decision Making for Carbon Storage~(SMART-CS) Initiative.

% \section*{Author contributions statement}

% Must include all authors, identified by initials, for example:
% A.A. conceived the experiment(s),  A.A. and B.A. conducted the experiment(s), C.A. and D.A. analyzed the results.  All authors reviewed the manuscript. 

% \section*{Additional information}

% To include, in this order: \textbf{Accession codes} (where applicable); \textbf{Competing interests} (mandatory statement). 

% The corresponding author is responsible for submitting a \href{http://www.nature.com/srep/policies/index.html#competing}{competing interests statement} on behalf of all authors of the paper. This statement must be included in the submitted article file.

\newpage
\section*{Supplementary Materials}




\begin{table}[h]
\centering
\setlength{\tabcolsep}{10pt}
\renewcommand{\arraystretch}{1.5}
\begin{tabular}{c|c c c|c c c}
\thickhline
\multirow{2}{*}{Dataset} & \multicolumn{3}{c|}{InversionNet} & \multicolumn{3}{c}{BigFWI} \\ \cline{2-7} 
& MAE$\downarrow$ & RMSE$\downarrow$ & SSIM$\uparrow$  & MAE$\downarrow$ & RMSE$\downarrow$ & SSIM$\uparrow$ \\ \thickhline
FlatVel-A  & 0.0092 & 0.0163 & \textbf{0.9930} & \textbf{0.0066} & \textbf{0.0137} & 0.9922 \\ \hline
FlatVel-B  & \textbf{0.0288} & \textbf{0.0797} & \textbf{0.9582} & 0.0298 & 0.0888 & 0.9498 \\ \hline
CurveVel-A  & 0.0560 & 0.1131 & 0.8405 & \textbf{0.0415} & \textbf{0.0936} & \textbf{0.8751}  \\ \hline
CurveVel-B  & 0.1344 & 0.2697 & 0.6995 & \textbf{0.1155} & \textbf{0.2471} & \textbf{0.7309}  \\ \hline
FlatFault-A  & 0.0138 & 0.0382 & 0.9813 & \textbf{0.0111} & \textbf{0.0332} & \textbf{0.9841}  \\ \hline
FlatFault-B  & 0.1012 & 0.1672 & 0.7267 & \textbf{0.0855} & \textbf{0.1514} & \textbf{0.7573}  \\ \hline
CurveFault-A  & 0.0220 & 0.0607 & 0.9605 & \textbf{0.0193} & \textbf{0.0556} & \textbf{0.9636}  \\ \hline
CurveFault-B  & 0.1610 & 0.2419 & 0.5981 & \textbf{0.1425} & \textbf{0.2251} & \textbf{0.6292}  \\ \hline
Style-A  & 0.0625 & 0.1024 & 0.8839 & \textbf{0.0592} & \textbf{0.0994} & \textbf{0.8908}  \\ \hline
Style-B & 0.0609 & 0.0971 & 0.7303 & \textbf{0.0600} & \textbf{0.0962} & \textbf{0.7324}  \\ \thickhline
\end{tabular}
\caption{Quantitative comparison between the results of InversionNet and BigFWI on OpenFWI-204k. %\pjremark{Raw results, for writing purposes only, will be moved to the supplementary.}
}
\end{table}

\begin{table}[h]
\small
\centering
\setlength{\tabcolsep}{5pt}
\renewcommand{\arraystretch}{1.5}
\begin{tabular}{c|c c c|c c c|c c c|c c c}
\thickhline
\multirow{2}{*}{Dataset} & \multicolumn{3}{c|}{InversionNet} & \multicolumn{3}{c|}{BigFWI-B} & \multicolumn{3}{c|}{BigFWI-M} & \multicolumn{3}{c}{BigFWI-L} \\ \cline{2-13} 

& MAE$\downarrow$ & RMSE$\downarrow$ & SSIM$\uparrow$  & MAE$\downarrow$ & RMSE$\downarrow$ & SSIM$\uparrow$ & MAE$\downarrow$ & RMSE$\downarrow$ & SSIM$\uparrow$ & MAE$\downarrow$ & RMSE$\downarrow$ & SSIM$\uparrow$ \\ \thickhline

FlatVel-A & 0.0055 & 0.0104 & 0.9964  & 0.0076 & 0.0130 & 0.9943  & 0.0045 & 0.0085 & 0.9965 & \textbf{0.0041} & \textbf{0.0079} & \textbf{0.9965} \\ \hline
FlatVel-B & 0.0210 & 0.0632 & 0.9718  & 0.0233 & 0.0696 & 0.9658  & 0.0193 & 0.0621 & 0.9729 & \textbf{0.0173} & \textbf{0.0584} & \textbf{0.9756} \\ \hline
CurveVel-A & 0.0409 & 0.0944 & 0.8796  & 0.0343 & 0.0798 & 0.9027  & 0.0272 & 0.0725 & 0.9180 & \textbf{0.0260} & \textbf{0.0705} & \textbf{0.9199} \\ \hline
CurveVel-B & 0.1073 & 0.2349 & 0.7527  & 0.0933 & 0.2154 & 0.7808  & 0.0816 & 0.2006 & 0.8053 & \textbf{0.0772} & \textbf{0.1947} & \textbf{0.8134} \\ \hline
FlatFault-A & 0.0096 & 0.0278 & 0.9880  & 0.0106 & 0.0286 & 0.9871  & 0.0075 & 0.0229 & 0.9904 & \textbf{0.0066} & \textbf{0.0208} & \textbf{0.9918} \\ \hline
FlatFault-B & 0.0843 & 0.1497 & 0.7635  & 0.0710 & 0.1321 & 0.8027  & \textbf{0.0636} & \textbf{0.1259} & \textbf{0.8137} & 0.0644 & 0.1269 & 0.8033 \\ \hline
CurveFault-A & 0.0164 & 0.0485 & 0.9712  & 0.0167 & 0.0474 & 0.9712  & 0.0130 & 0.0404 & 0.9771 & \textbf{0.0117} & \textbf{0.0369} & \textbf{0.9801} \\ \hline
CurveFault-B & 0.1444 & 0.2248 & 0.6274  & 0.1245 & 0.2027 & 0.6781  & \textbf{0.1161} & \textbf{0.1954} & \textbf{0.6896} & 0.1169 & 0.1960 & 0.6790 \\ \hline
Style-A & 0.0567 & 0.0947 & 0.8972  & 0.0514 & 0.0868 & 0.9125  & \textbf{0.0480} & \textbf{0.0829} & \textbf{0.9187} & 0.0483 & 0.0831 & 0.9136 \\ \hline
Style-B & 0.0542 & 0.0890 & 0.7646  & 0.0553 & 0.0876 & 0.7567  & \textbf{0.0538} & \textbf{0.0867} & \textbf{0.7600} & 0.0563 & 0.0908 & 0.7429 \\ \thickhline
\end{tabular}
\caption{Quantitative comparison between the results of InversionNet and BigFWIs on OpenFWI-408k. %\pjremark{Raw results, for writing purposes only, will be moved to the supplementary.}
}
\end{table}

\begin{table}[h]
\centering
\setlength{\tabcolsep}{10pt}
\renewcommand{\arraystretch}{1.5}
\begin{tabular}{c|c c c c|c c c}
\thickhline
\multirow{2}{*}{\makecell{Target\\Dataset}} & \multicolumn{4}{c|}{InversionNet} & \multicolumn{3}{c}{BigFWI} \\ \cline{2-8} 
& Source & MAE$\downarrow$ & RMSE$\downarrow$ & SSIM$\uparrow$  & MAE$\downarrow$ & RMSE$\downarrow$ & SSIM$\uparrow$ \\ \thickhline
FlatVel-A & FlatVel-B & 0.0207 & 0.0381 & 0.9723 & \textbf{0.0137} & \textbf{0.0285} & \textbf{0.9795} \\ \hline
FlatVel-B & CurveVel-B & 0.1076 & 0.2331 & 0.7797 & \textbf{0.0820} & \textbf{0.1970} & \textbf{0.8345} \\ \hline
CurveVel-A & CurveVel-B & 0.0833 & 0.1458 & 0.7828 & \textbf{0.0578} & \textbf{0.1114} & \textbf{0.8404} \\ \hline
CurveVel-B & FlatFault-B & 0.4267 & 0.5649 & 0.4234 & \textbf{0.2543} & \textbf{0.4042} & \textbf{0.5373} \\ \hline
FlatFault-A & CurveFault-A & 0.0394 & 0.0979 & 0.9224 & \textbf{0.0211} & \textbf{0.0626} & \textbf{0.9618} \\ \hline
FlatFault-B & CurveFault-B & 0.1213 & 0.1895 & 0.6677 & \textbf{0.0998} & \textbf{0.1630} & \textbf{0.7343} \\ \hline
CurveFault-A & FlatFault-B & 0.0834 & 0.1537 & 0.8364 & \textbf{0.0398} & \textbf{0.0955} & \textbf{0.9198} \\ \hline
CurveFault-B & FlatFault-B & 0.1898 & 0.2840 & 0.5369 & \textbf{0.1638} & \textbf{0.2528} & \textbf{0.5905} \\ \hline
Style-A & Style-B & 0.1195 & 0.1655 & 0.7653 & \textbf{0.0948} & \textbf{0.1372} & \textbf{0.8049} \\ \hline
Style-B & Style-A & 0.0858 & 0.1226 & 0.6817 & \textbf{0.0801} & \textbf{0.1142} & \textbf{0.6871} \\ \thickhline
\end{tabular}
\caption{Quantitative comparison between the generalization results of InversionNet and BigFWIs. %\pjremark{Raw results, for writing purposes only, will be moved to the supplementary.}
}
\end{table}



\end{document}