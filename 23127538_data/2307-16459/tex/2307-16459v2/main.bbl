\begin{thebibliography}{10}
\providecommand{\url}[1]{\texttt{#1}}
\providecommand{\urlprefix}{URL }
\providecommand{\doi}[1]{https://doi.org/#1}

\bibitem{acevedo2020dataset}
Acevedo, A., Merino, A., Alf{\'e}rez, S., Molina, {\'A}., Bold{\'u}, L.,
  Rodellar, J.: A dataset of microscopic peripheral blood cell images for
  development of automatic recognition systems. Data in brief  \textbf{30}
  (2020)

\bibitem{bachmann2020constant}
Bachmann, G., B{\'e}cigneul, G., Ganea, O.: Constant curvature graph
  convolutional networks. In: International Conference on Machine Learning. pp.
  486--496. PMLR (2020)

\bibitem{bilic2023liver}
Bilic, P., Christ, P., Li, H.B., Vorontsov, E., Ben-Cohen, A., Kaissis, G.,
  Szeskin, A., Jacobs, C., Mamani, G.E.H., Chartrand, G., et~al.: The liver
  tumor segmentation benchmark (lits). Medical Image Analysis  \textbf{84},
  102680 (2023)

\bibitem{buzzega2020dark}
Buzzega, P., Boschini, M., Porrello, A., Abati, D., Calderara, S.: Dark
  experience for general continual learning: a strong, simple baseline. NeurIPS
   (2020)

\bibitem{castro2018end}
Castro, F.M., Mar{\'\i}n-Jim{\'e}nez, M.J., Guil, N., Schmid, C., Alahari, K.:
  End-to-end incremental learning. In: Eur. Conf. Comput. Vis. pp. 233--248
  (2018)

\bibitem{chami2019hyperbolic}
Chami, I., Ying, Z., R{\'e}, C., Leskovec, J.: Hyperbolic graph convolutional
  neural networks. Advances in neural information processing systems
  \textbf{32} (2019)

\bibitem{chaudhry2018riemannian}
Chaudhry, A., Dokania, P.K., Ajanthan, T., Torr, P.H.: Riemannian walk for
  incremental learning: Understanding forgetting and intransigence. In: Eur.
  Conf. Comput. Vis. pp. 532--547 (2018)

\bibitem{derakhshani2022lifelonger}
Derakhshani, M.M., Najdenkoska, I., van Sonsbeek, T., Zhen, X., Mahapatra, D.,
  Worring, M., Snoek, C.G.: Lifelonger: A benchmark for continual disease
  classification. In: Medical Image Computing and Computer Assisted
  Intervention--MICCAI 2022: 25th International Conference, Singapore,
  September 18--22, 2022, Proceedings, Part II. pp. 314--324. Springer (2022)

\bibitem{douillard2020podnet}
Douillard, A., Cord, M., Ollion, C., Robert, T., Valle, E.: Podnet: Pooled
  outputs distillation for small-tasks incremental learning. In: European
  Conference on Computer Vision. pp. 86--102. Springer (2020)

\bibitem{fang2021kernel}
Fang, P., Harandi, M., Petersson, L.: Kernel methods in hyperbolic spaces. In:
  Int. Conf. Comput. Vis. pp. 10665--10674 (2021)

\bibitem{feragen2016open}
Feragen, A., Hauberg, S.: Open problem: Kernel methods on manifolds and metric
  spaces. what is the probability of a positive definite geodesic exponential
  kernel? In: Conference on Learning Theory. pp. 1647--1650. PMLR (2016)

\bibitem{feragen2015geodesic}
Feragen, A., Lauze, F., Hauberg, S.: Geodesic exponential kernels: When
  curvature and linearity conflict. In: IEEE Conf. Comput. Vis. Pattern Recog.
  pp. 3032--3042 (2015)

\bibitem{ganea2018hyperbolic}
Ganea, O., B{\'e}cigneul, G., Hofmann, T.: Hyperbolic neural networks. Advances
  in neural information processing systems  \textbf{31} (2018)

\bibitem{gu2019learning}
Gu, A., Sala, F., Gunel, B., R{\'e}, C.: Learning mixed-curvature
  representations in product spaces. In: International Conference on Learning
  Representations (2019)

\bibitem{he2016deep}
He, K., Zhang, X., Ren, S., Sun, J.: Deep residual learning for image
  recognition. In: IEEE Conf. Comput. Vis. Pattern Recog. pp. 770--778 (2016)

\bibitem{hinton2015distilling}
Hinton, G., Vinyals, O., Dean, J., et~al.: Distilling the knowledge in a neural
  network. arXiv preprint arXiv:1503.02531  \textbf{2}(7) (2015)

\bibitem{hofmann2008kernel}
Hofmann, T., Sch{\"o}lkopf, B., Smola, A.J.: Kernel methods in machine learning
   (2008)

\bibitem{hou2019learning}
Hou, S., Pan, X., Loy, C.C., Wang, Z., Lin, D.: Learning a unified classifier
  incrementally via rebalancing. In: IEEE Conf. Comput. Vis. Pattern Recog. pp.
  831--839 (2019)

\bibitem{jayasumana2015kernel}
Jayasumana, S., Hartley, R., Salzmann, M., Li, H., Harandi, M.: Kernel methods
  on riemannian manifolds with gaussian rbf kernels. IEEE transactions on
  pattern analysis and machine intelligence  \textbf{37}(12),  2464--2477
  (2015)

\bibitem{kather2019predicting}
Kather, J.N., Krisam, J., Charoentong, P., Luedde, T., Herpel, E., Weis, C.A.,
  Gaiser, T., Marx, A., Valous, N.A., Ferber, D., et~al.: Predicting survival
  from colorectal cancer histology slides using deep learning: A retrospective
  multicenter study. PLoS medicine  \textbf{16}(1),  e1002730 (2019)

\bibitem{khrulkov2020hyperbolic}
Khrulkov, V., Mirvakhabova, L., Ustinova, E., Oseledets, I., Lempitsky, V.:
  Hyperbolic image embeddings. In: IEEE Conf. Comput. Vis. Pattern Recog. pp.
  6418--6428 (2020)

\bibitem{kirkpatrick2017overcoming}
Kirkpatrick, J., Pascanu, R., Rabinowitz, N., Veness, J., Desjardins, G., Rusu,
  A.A., Milan, K., Quan, J., Ramalho, T., Grabska-Barwinska, A., et~al.:
  Overcoming catastrophic forgetting in neural networks. Proceedings of the
  national academy of sciences  \textbf{114}(13),  3521--3526 (2017)

\bibitem{knights2022incloud}
Knights, J., Moghadam, P., Ramezani, M., Sridharan, S., Fookes, C.: Incloud:
  Incremental learning for point cloud place recognition. In: 2022 IEEE/RSJ
  International Conference on Intelligent Robots and Systems (IROS). pp.
  8559--8566. IEEE (2022)

\bibitem{li2017learning}
Li, Z., Hoiem, D.: Learning without forgetting. IEEE transactions on pattern
  analysis and machine intelligence  \textbf{40}(12),  2935--2947 (2017)

\bibitem{liu2019hyperbolic}
Liu, Q., Nickel, M., Kiela, D.: Hyperbolic graph neural networks. Advances in
  neural information processing systems  \textbf{32} (2019)

\bibitem{mathieu2019continuous}
Mathieu, E., Le~Lan, C., Maddison, C.J., Tomioka, R., Teh, Y.W.: Continuous
  hierarchical representations with poincar{\'e} variational auto-encoders.
  Advances in neural information processing systems  \textbf{32} (2019)

\bibitem{mccloskey1989catastrophic}
McCloskey, M., Cohen, N.J.: Catastrophic interference in connectionist
  networks: The sequential learning problem. In: Psychology of learning and
  motivation, vol.~24, pp. 109--165. Elsevier (1989)

\bibitem{nguyen2019toward}
Nguyen, C.V., Achille, A., Lam, M., Hassner, T., Mahadevan, V., Soatto, S.:
  Toward understanding catastrophic forgetting in continual learning. arXiv
  preprint arXiv:1908.01091  (2019)

\bibitem{nickel2017poincare}
Nickel, M., Kiela, D.: Poincar{\'e} embeddings for learning hierarchical
  representations. Advances in neural information processing systems
  \textbf{30} (2017)

\bibitem{nickel2018learning}
Nickel, M., Kiela, D.: Learning continuous hierarchies in the lorentz model of
  hyperbolic geometry. In: International conference on machine learning. pp.
  3779--3788. PMLR (2018)

\bibitem{parisi2019continual}
Parisi, G.I., Kemker, R., Part, J.L., Kanan, C., Wermter, S.: Continual
  lifelong learning with neural networks: A review. Neural Networks
  \textbf{113},  54--71 (2019)

\bibitem{rebuffi2017icarl}
Rebuffi, S.A., Kolesnikov, A., Sperl, G., Lampert, C.H.: icarl: Incremental
  classifier and representation learning. In: IEEE Conf. Comput. Vis. Pattern
  Recog. pp. 2001--2010 (2017)

\bibitem{riemer2018learning}
Riemer, M., Cases, I., Ajemian, R., Liu, M., Rish, I., Tu, Y., Tesauro, G.:
  Learning to learn without forgetting by maximizing transfer and minimizing
  interference. arXiv preprint arXiv:1810.11910  (2018)

\bibitem{ring1997child}
Ring, M.B.: Child: A first step towards continual learning. Machine Learning
  \textbf{28}(1),  77--104 (1997)

\bibitem{robins1995catastrophic}
Robins, A.: Catastrophic forgetting, rehearsal and pseudorehearsal. Connection
  Science  \textbf{7}(2),  123--146 (1995)

\bibitem{wu2019large}
Wu, Y., Chen, Y., Wang, L., Ye, Y., Liu, Z., Guo, Y., Fu, Y.: Large scale
  incremental learning. In: IEEE Conf. Comput. Vis. Pattern Recog. pp. 374--382
  (2019)

\bibitem{wu2020comprehensive}
Wu, Z., Pan, S., Chen, F., Long, G., Zhang, C., Philip, S.Y.: A comprehensive
  survey on graph neural networks. IEEE transactions on neural networks and
  learning systems  \textbf{32}(1),  4--24 (2020)

\bibitem{yang2021medmnist}
Yang, J., Shi, R., Ni, B.: Medmnist classification decathlon: A lightweight
  automl benchmark for medical image analysis. In: 2021 IEEE 18th International
  Symposium on Biomedical Imaging (ISBI). pp. 191--195. IEEE (2021)

\end{thebibliography}
