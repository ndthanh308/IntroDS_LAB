%!TEX root = ../main.tex

\newcommand{\treepred}{\mathsf{tree}}
\newcommand{\htreepred}{\mathsf{htree}}
\newcommand{\findSucc}{\mymathtt{findSucc}}
\newcommand{\remove}{\mymathtt{remove}}
\newcommand{\pointsto}{\mapsto}
\newcommand{\pnull}{\mathsf{null}}
\newcommand{\aframe}{\mathit{c}}

\section{Motivation and Overview}
\label{sec:motivation}

We motivate our work using the delete operation on a binary search tree (BST) implementing a mathematical set. Specifically, we focus on the in-place removal of a key stored in an inner node of the tree. This is the most interesting case of the operation.

\input{content/fig_motivation_code}

\Cref{fig:bst-remove} shows the code of the operation and illustrates how it changes the tree. Each node in the tree is labeled with its key. The key $k$ to be removed is stored in node $\anode$. The operation proceeds in four steps. First, it uses the helper function $\findSucc$ to identify the left-most node $\anodep$ in the right subtree of $\anode$, as well as its parent $p$. That is, $j$ is the next larger key stored in the tree after $k$. We omit the definition of $\findSucc$. The \code{assume} statement models a branching condition. We focus on the case when $p \neq \anode$. The operation copies the key $j$ from $\anodep$ to $\anode$, effectively removing $k$ from the structure. Next, it unlinks $\anodep$ from the tree by setting $p$'s left pointer to the right child of $\anodep$. This is to maintain the invariant that each key occurs at most once in the tree. Finally, $\anodep$ is deallocated.

Our goal is to show the functional correctness of the operation. That is, if the contents of the tree is $\contents$ before the operation, then it is $\contents \setminus \set{k}$ afterwards. We start with a discussion of the typical approach to conduct such proofs in separation logic, explain its shortcomings, and then motivate our contributions.

\smartparagraph{Verifying $\remove$.}
A conventional proof in separation logic would use a recursive predicate to tie the data structure's representation to its contents: 
\begin{align*}
\treepred(\anode, \contents) = \; & \emp \land x = \pnull \land \contents = \emptyset \lor {}\\
& \anode \pointsto (l,r,k) \mstar \treepred(l,\contents_l) \mstar \treepred(r,\contents_r) \land 
\contents_l < k < \contents_r \land \contents = \contents_l \cup \set{k} \cup \contents_r \enspace.
\end{align*}
Free variables like $l$ occurring on the right-hand side of the definition are implicitly existentially quantified. In the standard model of separation logic, a predicate denotes a region in the heap. The predicate $\treepred(\anode, \contents)$ denotes a region that stores a tree with contents $\contents$. The first disjunct in the definition covers the case where the tree is empty. (The predicate $\emp$ denotes the empty heap region.) The recursive case uses the \emph{points-to} predicate $\anode \pointsto (l,r,k)$ to express the existence of a memory location $\anode$ that stores pointers to its left and right children, $l$ and $r$, as well as the key $k$. The \emph{separating conjunction} $\apred \mstar \apredp$ is the union of the heap regions denoted by $\apred$ and $\apredp$, and additionally constrains $\apred$ and $\apredp$ to be disjoint. We use separating conjunction to express that the described heap region is indeed a tree and not a DAG. We lift the ordering on keys to sets of keys to express sortedness. That is, $\contents_l < \contents_r$ means that for all $k_l \in \contents_l$ and $k_r \in \contents_r$, $k_l < k_r$.

A Hoare triple $\hoareof{\apred}{\astmt}{\apredp}$ in separation logic is valid only if the program $\astmt$ does not access memory locations that are outside of $\apred$ and not freshly allocated by $\astmt$. We call $\apred$ a \emph{footprint} of $\astmt$. This semantics of Hoare triples gives rise to the well-known frame rule of separation logic, which states that any predicate $\aframe$ that is disjoint from a footprint $\apred$ will be preserved by $\astmt$.

We prove
\[\hoareof{x \pointsto (l, r, k) \mstar \treepred(l,\contents_l) \mstar \treepred(r,\contents_r) \land \contents_l < k < \contents_r}{\remove(x)}{\treepred(x,\contents_l \cup \contents_r)}\enspace.\]
Note that the precondition implies $\treepred(x,\contents) \land x \neq \pnull$ for $\contents = \contents_l \cup \set{k} \cup \contents_r$.
The key idea of the proof is to establish a postcondition for \code{$\findSucc$($x$)} that decomposes the precondition into the three nodes $\anode, \anodep$, $p$ involved in the destructive updates, and some \emph{frame} $\aframe$. That is, we require:
\[ \anode \pointsto (l,r,k) \MSTAR p \pointsto (\anodep,\anodepp,i) \MSTAR \anodep \pointsto (\pnull, \anodeppp, j) \MSTAR \aframe \; \Rightarrow \; \treepred(x,\contents)\enspace.\]
We then reason locally about how the updates affect the three nodes:
\begin{lstlisting}[language=SPL,numbers=none,style=codeInline,keywords={free}]
  $\annot{
    \anode \pointsto (l,r,k) \MSTAR p \pointsto (\anodep,\anodepp,i) \MSTAR \anodep \pointsto (\pnull, \anodeppp, j)
  }$
  $\anode$.$\key$ := $\anodep$.$\key$; $p$.$\lchild$ := $\anodep$.$\rchild$; free($\anodep$);
  $\annot{
    \anode \pointsto (l,r,j) \MSTAR p \pointsto (\anodeppp,\anodepp,i)}$.
\end{lstlisting}
By applying the frame rule we can now infer that the frame $\aframe$ is preserved by these updates. It remains to show that the resulting assertion implies the desired postcondition $\treepred(x,\contents \setminus \set{k})$. This leads to our second requirement on $\aframe$: \[ \anode \pointsto (l,r,j) \MSTAR p \pointsto (\anodeppp,\anodepp,i) \MSTAR \aframe \; \Rightarrow \; \treepred(x,\contents \setminus \set{k}) \enspace.\]
So what is $\aframe$? One idea is to introduce an auxiliary predicate $\htreepred(\anode,\contents_1,h,\contents_2)$ that describes a tree with a hole. That is, the tree is rooted in $\anode$ and has a dangling reference to $h$. The contents of the described region (without the hole) is $\contents_1 \cup \contents_2$ such that $\contents_1 < \contents_2$. We elide the definition of $\htreepred$. What is important is that if $h$ is the root of another tree, then the two structures can be composed to obtain a proper tree rooted in $\anode$:
\[\label{eq:tree-composition}
 \htreepred(\anode,\contents_1,h,\contents_2) \MSTAR \treepred(h,\contents_h) \;\land\; \contents_1 < \contents_h < \contents_2 \;\Rightarrow\; \treepred(\anode,\contents_1 \cup \contents_h \cup \contents_2) \enspace.
 \tag{Compose}
\]
The framed assertion $\aframe$ that completes the proof is then as follows:
\begin{align*}
\aframe = \; \; & \treepred(l,\contents_l) \MSTAR \htreepred(r,\emptyset, p, \contents_r') \MSTAR \treepred(\anodeppp, \contents_\anodeppp) \MSTAR \treepred(\anodepp, \contents_\anodepp) \; \land {} \\
& \contents_l < k < j < \contents_\anodeppp < i < \contents_\anodepp < \contents_r' \; \land \;
\contents_r = \set{j,i} \cup \contents_\anodeppp \cup \contents_\anodepp \cup \contents_r'\enspace.
\end{align*}
In particular, using the definition of $\treepred$ and \eqref{eq:tree-composition} we can derive
\begin{align*}
& p \pointsto (\anodeppp,\anodepp,i) \MSTAR \treepred(\anodeppp, \contents_\anodeppp) \MSTAR \treepred(\anodepp, \contents_\anodepp) \MSTAR \htreepred(r,\emptyset,p,\contents_r') \; \land \; j < C_\anodeppp < i < \contents_\anodepp < \contents_r'
\\ \Rightarrow\; & \treepred(r, \contents_r \setminus \set{j})\enspace.
\end{align*}

While this reasoning may look simple on the surface, there are several challenges.
First, the prover needs to identify the right decomposition of the assertions into the footprint of the update and the frame.
In particular, this step involves the inference of auxiliary inductive predicates such as $\htreepred$.
Next, the prover needs to derive auxiliary data-structure and property-specific lemmas such as \eqref{eq:tree-composition} that enable reasoning about the involved predicates. When striving for automated proofs, these issues have shown to be particularly vexing~\cite{DBLP:conf/cav/BerdineCCDOWY07,DBLP:conf/cade/BrotherstonDP11,DBLP:conf/sas/ToubhansCR14,DBLP:conf/nfm/EneaLSV17,DBLP:journals/tocl/MathejaPZ23,DBLP:journals/ipl/EchenimIP22}.

Finally, and perhaps most importantly, the proof does not easily generalize. For instance, we may be interested in transferring it to the concurrent setting where $\remove$ is performed in parallel with other operations on the tree.
Putting aside the question of how to reason about thread synchronization, which is orthogonal, the challenge is that the tree structure will be subjected to concurrent rotation operations for rebalancing.
These will temporarily break the tree structure by introducing sharing.
That is, the structure that the assertions need to describe are DAGs rather than trees.
Hence, they can no longer be expressed using simple recursive predicates and separating conjunctions.
For a proof with recursive predicates one would have to apply more complex machinery such as overlapping conjunctions~\cite{DBLP:conf/aplas/DockinsHA09,DBLP:conf/popl/GardnerMS12} and ramifications~\cite{DBLP:conf/popl/HoborV13}, which further complicates the reasoning.

\smartparagraph{Node-local reasoning.}
An alternative to recursive predicates is to use indexed separating conjunction to describe unbounded heap regions~\cite{Yang01ShorrWaite, DBLP:conf/cav/0001SS16}. These are predicates of the form $\bigmstar_{\anode \in \setnodes} \apred(x)$ and express that $\apred(\anode)$ must hold disjointly for all nodes $\anode \in \setnodes$. The predicate $\apred(\anode)$ specifies a node-local property (e.g., constraining the values of a single points-to predicate for $\anode$).
Indexed separating conjunctions can be easily composed and decomposed along arbitrary partitions of $\setnodes$. This greatly simplifies framing.
They can also be used to describe general graphs.
The recently proposed flow framework~\cite{DBLP:journals/pacmpl/KrishnaSW18,DBLP:conf/esop/KrishnaSW20,DBLP:conf/tacas/MeyerWW23} extends this approach so that $\apred(\anode)$ can capture global properties of the heap graph spanned by the nodes in $\setnodes$.
The approach works by augmenting every node with additional ghost information, its \emph{flow}.
Flows are computed inductively over the graph structure using a data-flow equation. The equation can be thought of as collecting information about all possible traversals of the graph. The definition is such that it still yields generic reasoning principles for decomposing and composing predicates similar to those for indexed separating conjunctions.

A suitable flow for verifying the functional correctness of our $\remove$ operation assigns to each node its \emph{inset}.
Intuitively, the inset of a node $\anode$ consists of the set of keys $k$ such that an operation on $k$ may traverse $\anode$ to find $k$. \Cref{fig:bst-remove-flows} shows two search trees, before and after execution of the $\remove$ operation, with the inset of each node annotated in {\color{blue}blue}.
For example, the inset of $\anodep$ in the pre-state is the interval $\color{blue}(4,8)$ because the largest key on the path from the $\Root$ to $\anodep$ when moving right is $4$ and the smallest key when moving left is $8$.

If we subtract from a node's inset all the insets of its children, we derive its \emph{keyset}. For example, in the pre-state, the keyset of $p$ is $\{8\}$ and the keyset of $\anode$'s left child is $(-\infty,1]$,
Assuming searches follow deterministic paths through the graph (as they do for binary search trees), then the keysets are pairwise disjoint~\cite{DBLP:journals/tods/ShashaG88}.
This means the keyset of a node $\anode$ consists of exactly those keys that can only be found in $\anode$ if they are stored anywhere in the structure.

\input{content/fig_motivation_flows}

To reason about the functional correctness of the operations on the tree, we simply maintain the following \emph{keyset invariant}:  the key stored in each node is contained in the node's keyset.
The overall contents $\contents$ of the tree is the union of all keys stored in its nodes.
The keyset invariant together with the disjointness of the keysets imply that the node-local contents are also disjoint.
Hence, any change made to the contents of a node, such as replacing its key, is reflected by a corresponding change of the global contents $\contents$.
That is, we can now reason node-locally about the overall functional correctness of the search tree operations!


\smartparagraph{Unbounded footprints.}

To enable compositional reasoning about inductive properties, the flow framework adds an additional constraint on separating conjunction: two graphs augmented with flows compose only if they are disjoint and their flow values are consistent with the flow obtained in the composite graph.
As a consequence, the footprint of an update on the graph can be larger than the \emph{physical} footprint that encompasses the changes to the graph structure (i.e., when ignoring the auxiliary ghost state). In fact, the full footprint can be unbounded even if the physical footprint is not.

For the $\remove$ operation, the physical footprint consists of the three nodes $\anode$, $p$, and $\anodep$ (shaded yellow in \cref{fig:bst-remove-flows}). However, observe that moving $\anodep$'s key to $\anode$ changes the insets of all the nodes shaded in gray. These comprise the nodes on the path from $\anode$ to $\anodep$ as well as all nodes on the path from $\anode$ to the right-most leaf in its left subtree. As these paths can be arbitrarily long, the footprint of the update is unbounded.

Updates with unbounded footprints adversely impact our ability to do local reasoning.
If we try to reason only about the physical footprint and put everything else into the frame like we did in our earlier proof, then the proof will fail: after the update, the physical footprint no longer composes with the frame since the insets of the two regions are inconsistent.
In a sense, the stronger notion of graph composition forces us to reconcile with the global effect of the update immediately at the point when the update occurs, rather than after the frame rule has been applied, as we did in the earlier proof.
This is desirable because it means that the program semantics can guide the proof construction rather than having the prover hash it out all on its own at the logical level.
However, this also means that we need new reasoning techniques that effectively deal with large footprints.

Existing works on the flow framework have either considered only updates with bounded footprint~\cite{DBLP:conf/esop/KrishnaSW20,DBLP:conf/tacas/MeyerWW23} or cases where the unbounded footprint is traversed by the program prior to the update~\cite{DBLP:journals/pacmpl/MeyerWW22}. However, not all updates fall into these categories as our example demonstrates. In this paper, we provide a general solution.

We note that the issue of having to reason about large footprints is not unique to the flow framework.
It has been observed in the literature that this issue arises naturally whenever rich ghost state abstractions are layered on top of the physical state, thereby inducing a stronger notion of separation~\cite{DBLP:journals/pacmpl/Nanevski0DF19, DBLP:journals/pacmpl/FarkaN0DF21}.
We therefore formulate our solution in the setting of abstract separation logic~\cite{DBLP:conf/lics/CalcagnoOY07} so that it can apply broadly.


\smartparagraph{Contributions and Overview.}

Our first contribution is \emph{context-aware separation logic (CASL)}, which we describe in \cref{Section:CAReasoning}. CASL is a conservative extension of separation logic that enables local reasoning about computations with large footprints. Hoare judgments in CASL take the form $\choareof{\acontext}{\apred}{\astmt}{\apredp}$. The judgment decomposes the footprint of $\astmt$ into two parts: a core footprint $\apred$ and a \emph{context} $\acontext$. In our $\remove$ example, the core footprint is the physical footprint of the update. The context is a predicate describing the nodes shaded in gray.

Akin to the frame rule, if $\choareof{\acontext}{\apred}{\astmt}{\apredp}$ is valid, then $\astmt$ transforms $\apred \mstar \acontext$ to $\apredp \mstar \acontext$. However, the frame rule has to work for all possible frames $\aframe$ and must therefore require that no state in $\aframe$ is affected by the update. In contrast, when $\hoareof{\apred}{\astmt}{\apredp}$ is viewed in the context of $\acontext$, the logic can take advantage of the fact that $\acontext$ is known. This enables new opportunities for local reasoning in the cases where the full footprint of $\astmt$ is large. Intuitively, $\acontext$ is the part of the state whose ghost component may be affected by the update, but the ghost component changes in a way such that $\acontext$ is maintained. In the example, the important property being maintained is the keyset invariant. 

Our second contribution addresses the question how to derive appropriate context predicates $\acontext$ that enable contextual reasoning. More precisely, given a predicate $\apred \mstar \apredppp$ that describes the pre-states of a computation $\astmt$, the \emph{contextualization} problem is to identify predicates $\apredp$ and $\acontext$ such that $\choareof{\acontext}{\apred}{\astmt}{\apredp}$ and $\apredppp \Rightarrow \acontext$ are valid. We propose a principled approach based on abstract interpretation that solves contextualization for the general setting where changes to the physical state induce large ghost state footprints (\cref{sec:contextualization}).

We then instantiate this abstract solution for the concrete setting of the flow framework (\cref{sec:instantiation}). The technical challenge here is that one needs to approximate a fixed point that is computed over the graphs in the image of $\apred \mstar \apredppp$ under $\astmt$, without precise information about what these graphs look like. Our instantiation is motivated by the observation that, in practice, the change of the flow that emanates from the core footprint simply propagates through the context. For instance, in the example shown in \cref{fig:bst-remove-flows}, the insets in the left subtree of $\anode$ uniformly increase by $[4,6)$ and in the right subtree they uniformly decrease by $[4,6)$. In both cases, the change preserves the keyset invariant. We identify general conditions under which the induced flow changes can be uniformly approximated.

Finally, in \cref{sec:example} we revisit the binary search tree example to demonstrate a full application of the developed machinery. \cref{sec:related} discusses related work and concludes the paper.

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../main"
%%% End:
