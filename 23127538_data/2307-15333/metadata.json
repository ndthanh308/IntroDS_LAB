{
  "title": "Dynamic PlenOctree for Adaptive Sampling Refinement in Explicit NeRF",
  "authors": [
    "Haotian Bai",
    "Yiqi Lin",
    "Yize Chen",
    "Lin Wang"
  ],
  "submission_date": "2023-07-28T06:21:42+00:00",
  "revised_dates": [],
  "abstract": "The explicit neural radiance field (NeRF) has gained considerable interest for its efficient training and fast inference capabilities, making it a promising direction such as virtual reality and gaming. In particular, PlenOctree (POT)[1], an explicit hierarchical multi-scale octree representation, has emerged as a structural and influential framework. However, POT's fixed structure for direct optimization is sub-optimal as the scene complexity evolves continuously with updates to cached color and density, necessitating refining the sampling distribution to capture signal complexity accordingly. To address this issue, we propose the dynamic PlenOctree DOT, which adaptively refines the sample distribution to adjust to changing scene complexity. Specifically, DOT proposes a concise yet novel hierarchical feature fusion strategy during the iterative rendering process. Firstly, it identifies the regions of interest through training signals to ensure adaptive and efficient refinement. Next, rather than directly filtering out valueless nodes, DOT introduces the sampling and pruning operations for octrees to aggregate features, enabling rapid parameter learning. Compared with POT, our DOT outperforms it by enhancing visual quality, reducing over $55.15$/$68.84\\%$ parameters, and providing 1.7/1.9 times FPS for NeRF-synthetic and Tanks $\\&$ Temples, respectively. Project homepage:https://vlislab22.github.io/DOT.\n  [1] Yu, Alex, et al. \"Plenoctrees for real-time rendering of neural radiance fields.\" Proceedings of the IEEE/CVF International Conference on Computer Vision. 2021.",
  "categories": [
    "cs.CV"
  ],
  "primary_category": "cs.CV",
  "doi": null,
  "journal_ref": null,
  "arxiv_id": "2307.15333",
  "pdf_url": "https://arxiv.org/pdf/2307.15333v1",
  "comment": "Accepted by ICCV2023",
  "num_versions": null,
  "size_before_bytes": 6274192,
  "size_after_bytes": 163934
}