\section{Evaluation of The Attack\label{sec:attack_eval}}
In this section, we present the evaluation results of our proposed attack. First, we introduce our experimental setup. Then, we provide a detailed analysis of the performance of our attack on various datasets, discussing its effectiveness and limitations.
\subsection{Experimental setup}
\subsubsection{Datasets}
In order to evaluate the effectiveness of our attack, we conducted experiments on various real-world datasets previously utilized in related research. We include the Flickr \cite{ZengZSKP20_Flickr} dataset, where nodes represent images uploaded to the Flickr platform. Edges connect nodes if the images share common properties like geographic location, gallery, or user comments. Node features contain word representations. Additionally, we utilize two Twitch datasets (TWITCH-FR and TWITCH-RU)\cite{rozemberczki2021twitch} to evaluate NILS. We use Twitch-ES to train the GNNs as done previously in \cite{linkteller} for the inductive setting. Twitch datasets \cite{rozemberczki2021twitch} illustrate follow relationships between users on the Twitch streaming platform. The objective of these datasets is to perform binary classification to determine if a streamer uses explicit language, using features such as users' preferred games, location, and streaming habits.

Furthermore, for the transductive setting, where the training and testing of the GNNs occur on the same graph, we incorporate three citation network datasets \cite{citation_datasets}, Cora, Citeseer, and Pubmed. These datasets capture citation relationships among scientific publications across various fields. The classification task of these datasets involves predicting the topic of publications based on their textual features. While Cora and Citeseer encompass general scientific publications, Pubmed is dedicated to biomedical publications. By employing these datasets in our evaluation, we aim to demonstrate the effectiveness of our proposed attack in both inductive and transductive settings, as well as across a range application domains.

\subsubsection{Models}

In our study, we follow LinkTeller's approach to training the models and selecting hyperparameters \cite{linkteller}. In LinkTeller \cite{linkteller}, the authors trained Graph Convolutional Networks (GCNs) using various configurations and hyperparameters, which encompassed normalization techniques applied to the adjacency matrix, the number of hidden layers, input and output units, and dropout rates. In order to identify the optimal set of hyperparameters, the authors employed a grid search strategy, systematically exploring combinations of hyperparameters and evaluating their performance on a validation set.
The search space for hyperparameters and the formulae for different normalization techniques were provided in \cite[Appendix F]{linkteller}. After obtaining the best set of hyperparameters, the authors trained the GCN models to minimize the cross-entropy loss for the intended tasks.

In our experiments, we adhere to the same methodology as in LinkTeller \cite{linkteller}, ensuring consistency across the studies. By utilizing the same training procedures and hyperparameter tuning strategies, we aim to provide a comprehensive understanding of the attack performance across different layer configurations (two, three, and four layers) while maintaining consistency.

\subsubsection{Evaluation of attack performance}
In accordance with the evaluation methodology presented in the LinkTeller paper \cite{linkteller}, we employ precision, recall, and the $F_1$ score as our primary evaluation metrics. These metrics are particularly suitable for addressing the imbalanced binary classification problem at hand, in which the minority class (i.e., connected nodes) is of central interest. We primarily select the set target nodes $V_{\mathcal{A}}$, such that  $|V_{\mathcal{A}}|=500$, using a uniform random sampling approach. Furthermore, following the baseline \cite{linkteller} study's example, we explore scenarios where target nodes exhibit either low or high degrees. A comprehensive discussion of the sampling strategy can be found in \cite[Section V.D.]{linkteller}. We report the results averaged over three runs with different random seeds along with the standard deviation.
% training
% hyperparameters
% GNN architecture
% Evaluation methodology of the attack
\subsection{Analysis of strategies for malicious nodeâ€™s features}
In this section, we analyze the impact of different strategies, as defined in Section \ref{subsection:malicious features strategies}, for generating the features $x_m$ of the malicious node $v_m$ on the success of our attack.

The success rates of these strategies, as shown in Table \ref{tab:adv_strategies}, reveal that the All-ones, Max attributes, and Class representative strategies are the most effective in causing significant changes in the predictions of the target node's neighbors. These results suggest that injecting nodes with high-valued or class-specific features can effectively disrupt the model's output predictions.

Conversely, the All-zeros, and Identity strategies exhibit relatively lower success rates, as shown in Table \ref{tab:adv_strategies}. While these strategies offer certain benefits in terms of stealthiness, their impact on the graph structure and predictions is less pronounced, highlighting a trade-off between attack effectiveness and stealthiness.

Concerning the Influence strategy, our NILS method exhibits a modest improvement over the LinkTeller baseline for the Twitch-FR dataset, as illustrated in Table \ref{tab:adv_strategies}. This suggests that the node injection property of our NILS attack is effective in this context. However, for the Twitch-RU dataset, NILS underperforms in comparison to the LinkTeller baseline. The most significant improvement is observed in the Flickr dataset, where the node injection property of NILS considerably increases the $F_1$ score from $0.32 \pm 0.13$ of LinkTeller to $0.89 \pm 0.10$. This outcome highlights the advantage of NILS attack's node injection method within the Influence strategy, particularly when compared to the LinkTeller attack, which employs the Influence strategy without node injection. 

These findings underscore the importance of considering both the effectiveness and stealthiness of malicious feature generation strategies when devising link inference attacks on GNNs.

\begin{table}[h]

\begin{adjustbox}{width=\columnwidth,center}
\centering


\begin{tabular}{lccc}
\toprule
Method & Twitch-FR & Twitch-RU & Flickr \\
\midrule
Class Rep. & $0.94 \pm 0.01$ & $0.83 \pm 0.06$ & $0.96 \pm 0.06$ \\
Max Attr.  & $0.99 \pm 0.00$  & $0.98 \pm 0.02$ & $\boldsymbol{1.00 \pm 0.00}$ \\
All-ones   & $\boldsymbol{0.99 \pm 0.00}$ & $\boldsymbol{0.97 \pm 0.01}$ & $0.99 \pm 0.02$ \\
All-zeros  & $0.58 \pm 0.02$  & $0.48 \pm 0.01$  & $0.71 \pm 0.07$ \\
Identity   & $0.81 \pm 0.02$  & $0.69 \pm 0.01$  & $0.95 \pm 0.07$ \\
Influence NILS  & $0.81 \pm 0.02$  & $0.70 \pm 0.01$  & $0.89 \pm 0.10$ \\
Influence LinkTeller \cite{linkteller}   & $0.80 \pm 0.02$  & $0.74 \pm 0.01$  & $0.32 \pm 0.13$ \\
\bottomrule
\end{tabular}
\end{adjustbox}
\caption{$F_1$ scores and standard deviations for different attack methods and datasets.}
\label{tab:adv_strategies}
\end{table}
\subsection{Comparison with the baselines}

In this study, we conducted experiments to evaluate the performance of our proposed NILS attack in comparison to the LinkTeller attack using the same experimental setup. Our focus is on analyzing the optimal attacks for both approaches, which involved accurately estimating the number of neighbors of the target set nodes. The results, summarized in Table \ref{tab:comp_LT}, demonstrate that our attack outperforms LinkTeller on both Twitch datasets (TWITCH-FR and TWITCH-RU). Furthermore, our method exhibits a substantial improvement over LinkTeller on the Flickr dataset, achieving nearly double the precision and recall values. Notably, our attack demonstrates stable performance across varying node degrees, with only a marginal decrease in effectiveness for high-degree target nodes. This can be attributed to the smaller influence that each neighboring node has on the aggregation of the GCN layer when the target node degree is high. Overall, our proposed NILS attack demonstrates consistently a superior performance compared to the LinkTeller attack.

We further compare our attack with link-stealing attacks introduced in \cite{he2021stealing}, where the authors' various attack strategies rely on different types of background knowledge available to the adversary, such as node attributes and shadow datasets. Specifically, in their Attack-2, the adversary has access to both the features and prediction scores of the nodes. Utilizing this information, the adversary creates two types of attacks: LSA2-attr and LSA2-post. LSA2-attr calculates distances between node attributes, while LSA2-post computes distances between node prediction scores (posteriors). It is important to highlight that these two attacks align closely with our threat model, as both assume that the adversary has access to the features and prediction scores of the target node. This similarity in assumptions renders these attacks particularly relevant for comparison with our proposed NILS attack. The attacks are executed under the transductive setting, where training and inference occur on the same graph. As shown in Table \ref{tab:LST_comp}, our proposed NILS attack outperforms the LSA2-post and LSA2-attr attacks constructed in \cite{he2021stealing}. However, our attack performance is nearly equivalent to that of LinkTeller. These results demonstrate that NILS attack maintains effectiveness under the transductive setting, just as in the inductive setting.
% \usepackage{multirow}
\begin{table*}[]
%\begin{adjustbox}{width=\columnwidth,center}
\begin{tabular}{cccccccc}
\toprule
\multirow{2}{*}{Dataset} &
  \multirow{2}{*}{Method} &
  \multicolumn{2}{c}{low} &
  \multicolumn{2}{c}{uncontrained} &
  \multicolumn{2}{c}{high} \\ \cline{3-8} 
 &
   &
  precision &
  recall &
  precision &
  recall &
  precision &
  recall \\ \hline
\multirow{2}{*}{TWITCH-FR} &
  NILS (Ours) &
  $100.0 \pm \scriptstyle 0.0$ &
  $100.0 \pm \scriptstyle 0.0$ &
  $99.13 \pm \scriptstyle 0.8$ &
  $99.57 \pm \scriptstyle 0.35$ &
  $99.91 \pm \scriptstyle 2.6$ &
  $100.0\pm \scriptstyle 0.0$ \\
 &
  LinkTeller &
  $92.5 \pm \scriptstyle 5.4$ &
  $92.5 \pm \scriptstyle 5.4$ &
  $84.1 \pm \scriptstyle 3.7$ &
  $78.2 \pm \scriptstyle 1.9$ &
  $83.2 \pm \scriptstyle 1.4$ &
  $80.6 \pm \scriptstyle 6.7$ \\ \hline
\multirow{2}{*}{TWITCH-RU} &
  NILS (Ours) &
  $100.0 \pm \scriptstyle 0.0$ &
  $100.0 \pm \scriptstyle 0.0$ &
  $96.45 \pm \scriptstyle 0.4 $ &
  $ 98.34\pm \scriptstyle 0.7$ &
  $99.77 \pm \scriptstyle 0.1$ &
  $ 99.37\pm \scriptstyle 0.1$ \\
 &
  LinkTeller &
  $78.8 \pm \scriptstyle 1.9$ &
  $ 92.6 \pm \scriptstyle 5.5 $ &
  $ 71.8\pm \scriptstyle 2.2$ &
  $78.5 \pm \scriptstyle 2.4$ &
  $ 89.7\pm \scriptstyle 1.7 $ &
  $65.7 \pm \scriptstyle 3.9 $ \\ \hline
\multirow{2}{*}{Flickr} &
  NILS (Ours) &
  $100.0\pm \scriptstyle 0.0$ &
  $100.0\pm \scriptstyle 0.0$ &
  $99.11\pm \scriptstyle 1.7$ &
  $95.83\pm \scriptstyle 5.0$ &
  $93.72\pm \scriptstyle 3.1$ &
  $78.9\pm \scriptstyle 1.9 $ \\
 &
  LinkTeller &
  $51.0 \pm \scriptstyle 7.0$ &
  $53.3\pm \scriptstyle 4.7$ &
  $33.8\pm \scriptstyle 13.3$ &
  $32.1\pm \scriptstyle 13.3$ &
  $18.2\pm \scriptstyle 4.5$ &
  $18.5\pm \scriptstyle 6.1$ \\ \hline
\end{tabular}
%\end{adjustbox}
\caption{Comparative performance of our proposed attack NILS and LinkTeller across three datasets (TWITCH-FR, TWITCH-RU, and Flickr) under low, unconstrained, and high constraint settings. The results are presented in terms of precision and recall with corresponding standard deviations}
\label{tab:comp_LT}
\end{table*}

\begin{table}[]
\centering
\begin{adjustbox}{width=\columnwidth,center}
\begin{tabular}{ccccccc}
\toprule
\multirow{2}{*}{Method} &
  \multicolumn{2}{c}{Cora} &
  \multicolumn{2}{c}{Citeseer} &
  \multicolumn{2}{c}{Pubmed} \\ \cline{2-7} 
 &
  precision &
  recall &
  precision &
  recall &
  precision &
  recall \\ \midrule
NILS (Ours) &
  $ 99.7\pm \scriptstyle 0.2$ &
  $ 99.6\pm \scriptstyle 0.3 $ &
  $97.4 \pm \scriptstyle 0.2 $ &
  $98.2 \pm \scriptstyle 0.1$ &
  $ 99.7\pm \scriptstyle 0.0 $ &
  $100.0 \pm \scriptstyle 0.0 $ \\
LinkTeller &
  $99.5 \pm \scriptstyle 0.1 $ &
  $ 99.5\pm \scriptstyle 0.1$ &
  $99.7 \pm \scriptstyle 0.0$ &
  $99.7 \pm \scriptstyle 0.0$ &
  $99.7 \pm \scriptstyle 0.0$ &
  $99.7 \pm \scriptstyle 0.0$ \\
LSA2-post &
  $ 86.7 \pm \scriptstyle 0.2 $ &
  $ 86.7\pm \scriptstyle 0.2$ &
  $ 90.1 \pm \scriptstyle 0.2$ &
  $ 90.1 \pm \scriptstyle 0.2$ &
  $ 78.8\pm \scriptstyle 0.1$ &
  $ 78.8\pm \scriptstyle 0.1$ \\
LSA2-attr &
  $73.6 \pm \scriptstyle 0.1$ &
  $73.6 \pm \scriptstyle 0.1$ &
  $80.9 \pm \scriptstyle 0.1$ &
  $80.9 \pm \scriptstyle 0.1$ &
  $ 82.4\pm \scriptstyle0.1 $ &
  $ 82.4\pm \scriptstyle0.1 $ \\
\bottomrule
  
\end{tabular}
\end{adjustbox}
\caption{Comparative performance of NILS attack with LinkTeller \cite{linkteller} and link-stealing attacks in \cite{he2021stealing} across three datasets (Cora, Citeseer, and Pubmed).}
\label{tab:LST_comp}
\end{table}

\subsection{Depth of the GNN}
In this section, we examine the impact of increasing the depth of GNN on the success rate of the attack for the Twitch-Fr dataset. Our findings illustrated in Figure \ref{fig:depth_imact_LT} indicate that as the depth of the GNN increases, the attack's success rate decreases, which can be attributed to the dilution of the injected poisoning node's influence within the target node's neighborhood. As the GNN depth increases, the model aggregates information from a larger neighborhood, encompassing nodes that are $k-$hops away from the target node. Consequently, the injected malicious node's features become one among many contributing factors in the aggregated information, leading to a dilution of its influence. This reduction in the injected node's impact on the aggregated information diminishes the overall effectiveness of the attack, making it less successful in altering the predictions of the target node's neighbors.

In comparison with LinkTeller \cite{linkteller}, as shown in Table \ref{tab:depth_imact_LT}, NILS outperforms LinkTeller \cite{linkteller} across various GCN depths. Specifically, for Twitch-FR dataset, NILS demonstrates higher precision and recall values when the GCN depth is 3 (precision: $85.06 \pm \scriptstyle 1.2$, recall: $81.56 \pm \scriptstyle 1.2$) compared to the LinkTeller method (precision: $50.01 \pm \scriptstyle 5.1$, recall: $46.6 \pm \scriptstyle 5.0$). Notably, NILS consistently outperforms LinkTeller even when comparing the attack performance of LinkTeller with a GCN depth of 2 and NILS with a GCN depth of 3. Specifically, for Twitch-FR dataset, NILS demonstrates higher precision and recall values at a GCN depth of 3 (precision: $85.06 \pm \scriptstyle 1.2$, recall: $81.56 \pm \scriptstyle 1.2$) compared to the LinkTeller method with a GCN depth of 2 (precision: $84.1 \pm \scriptstyle 3.7$, recall: $78.2 \pm \scriptstyle 1.9$). These results highlight the effectiveness of our node injection strategy, as it consistently outperforms the LinkTeller method across different depths of the GCN.

% Figure environment removed

%\ayse{isn't it better to use NILS instead of Ours in the table?}
\begin{table}[]
\begin{adjustbox}{width=\columnwidth,center}
\begin{tabular}{cccccc}
\toprule
\multirow{2}{*}{Dataset} &
  \multirow{2}{*}{Method} &
  \multicolumn{2}{c}{Depth-2} &
  \multicolumn{2}{c}{Depth-3} \\ \cline{3-6} 
 &
   &
  precision &
  recall &
  precision &
  recall \\ \midrule
\multirow{2}{*}{TWITCH-FR} & NILS (Ours) & $99.13 \pm \scriptstyle 0.8$ & $99.57 \pm \scriptstyle 0.35$ & $85.06\pm \scriptstyle 1.2$   & $81.56 \pm \scriptstyle 1.2$ \\
 &
  LinkTeller &
  $84.1 \pm \scriptstyle 3.7$ &
  $78.2 \pm \scriptstyle 1.9$ &
  $50.1 \pm \scriptstyle 5.1$ &
  $46.6 \pm \scriptstyle 5.0$ \\ \midrule
\multirow{2}{*}{TWITCH-RU} & NILS (Ours) & $96.45 \pm \scriptstyle 0.4$ & $98.34 \pm \scriptstyle 0.7$  & $78.78 \pm \scriptstyle 3.8 $ & $ 76.35\pm \scriptstyle 9.3$ \\
 &
  LinkTeller &
  $71.8\pm \scriptstyle 2.2$ &
  $78.5 \pm \scriptstyle 2.4 $ &
  $45.7\pm \scriptstyle 2.2$ &
  $50.0 \pm \scriptstyle 2.8$ \\
\bottomrule
\end{tabular}
\end{adjustbox}
  \caption{Success rates of the attack for different depths in comparison with LinkTeller \cite{linkteller}. We use the all-ones strategy and Twitch-FR dataset.}
  \label{tab:depth_imact_LT}
\end{table}

