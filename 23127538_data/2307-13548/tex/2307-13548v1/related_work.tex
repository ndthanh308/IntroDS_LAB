\section{Related work\label{sec:related_work}}

GNNs have gained significant attention in recent years due to their effectiveness in handling graph-based data across various applications \cite{gnn1, gnn_first, gnn2, gnn3}. As the adoption of GNNs increases, concerns regarding privacy and adversarial attacks on these networks also arise and become more significant \cite{sun2018adversarial_survey, dai2022comprehensive_survey}. On the other hand, several privacy-preserving methods are developed to mitigate the effectiveness of these privacy attacks against GNNs \cite{DP_GAP, sok_DP}.
\subsection{Privacy attacks on GNNs}
Privacy attacks on GNNs can be categorized based on the actual leakage in the graph, namely, information about graph nodes, their attributes, or graph edges. Node privacy attacks, such as membership inference attacks (MIA) \cite{MIA_GNN, wu2021MIA, conti2022label_MIA, olatunji2021MIA}, aim to determine if a given node was part of the training set. In contrast, attribute inference attacks \cite{linkstealing_reconstruction} focus on revealing sensitive information related to node attributes, violating attribute privacy. In this work, we concentrate on edge privacy violation, where the common attacks are the so-called link stealing, re-identification, or inference attacks, which aim to uncover the edges of the graph structure used by the GNN.

Early works \cite{he2021stealing, linkstealing_reconstruction, linkteller} have demonstrated the success and feasibility of link-stealing attacks. In the attack proposed in \cite{he2021stealing}, the adversary leverages prior knowledge about the graph, such as the likelihood of nodes with similar features or predictions being connected, to infer links in the graph. The attacker applies methods such as clustering to predict connections for nodes within the same cluster. In \cite{linkstealing_reconstruction}, the authors demonstrate that by accessing the node embeddings trained to preserve the graph structure, one can recover edges by training a decoder to convert the embedding to the graph structure. The Linkteller attack \cite{linkteller} involves probing the features of the nodes and studying their output predictions by the GNN to infer the links of the graph.

Existing link-stealing attacks exhibit certain weaknesses. The attack in \cite{he2021stealing} assumes a powerful adversary who requires access to the features, a shadow dataset, and the ability to train shadow GNNs in order to train an attack model. The attack model is trained to classify the link presence based on the output predictions or features. The attack's performance declines in the inductive setting, where training and inference occur on different graphs, as evidenced in the further Linkteller paper \cite{linkteller}. Additionally, its effectiveness diminishes when there is no correlation between features and links of the nodes. 

On the other hand, the main drawback of the Linkteller attack \cite{linkteller} is its non-stealthy perturbation of features, particularly when dealing with discrete datasets. The Linkteller's strategy consists of altering the input features of the graph to obtain information about the links. For discrete datasets, the perturbation can render the features as real values, making them easier to be detected. Moreover, the effectiveness of the Linkteller attack decreases when mounted against deep GNNs with depths of more than three.

In addition to privacy attacks targeting GNNs, adversarial attacks exist where the adversary's goal is to deceive the GNN's predictions or degrade its utility. These attacks involve altering the graph structure through node addition or deletion \cite{zhang2020_adversarial, mu2021hard_adversarial}.

In this paper, we propose a novel link-stealing attack NILS that addresses the limitations of existing approaches, taking advantage of the dynamic nature of GNNs by injecting malicious nodes in the style of an adversarial attack. Our proposed NILS attack outperforms previous link-stealing attacks \cite{he2021stealing, linkteller}. %and provides a more effective and stealthy means of constructing the link-stealing attack.


\subsection{Differential privacy mechanisms for graphs}

DP has been extensively studied and applied to various data types, including graphs, with the aim of preserving sensitive information. Various DP mechanisms have been developed \cite{node_dp_Brunet, node_dp_Daigavane} to protect both node and edge information. Node-level DP focuses on preserving the privacy of individual nodes, protecting from attacks, such as membership inference attacks \cite{MIA_GNN, wu2021MIA, conti2022label_MIA}. In contrast, Edge-level DP seeks to preserve the privacy of edge information, which represents relationships between nodes, preventing link stealing attacks \cite{linkstealing_reconstruction, linkteller, he2021stealing}.

Substantial research has been conducted on achieving node-level DP and edge-level DP in graph-based models. Several approaches allow for the publication of graph statistics with edge-level DP guarantees, including degree subgraph count \cite{Karwa_subgraph_count}, and degree distributions \cite{Hay_degree_dist, WeiYen_degree_dist}. Although these statistics are beneficial for graph analysis, they are inadequate for training a GNN model, as most of the GNNs require access to the raw graph structure for the message-passing mechanism. Consequently, other approaches have been developed to train GNN models by adopting input perturbation DP, releasing the graph while ensuring edge-level DP \cite{linkteller, Rui_adj_release, Hiep_adj_release}

Furthermore, when designing DP solutions, it is crucial to consider specific privacy threats and adversary strengths. In the context of our proposed NILS attack, the adversary is capable of injecting nodes into the graph to discover sensitive edge information, violating edge privacy. Therefore, we propose a customized DP notion that specifically addresses this type of privacy attack. We then leverage the LapGraph algorithm \cite{linkteller} to achieve the desired DP guarantees under the new, tailored notion and study its effectiveness.


