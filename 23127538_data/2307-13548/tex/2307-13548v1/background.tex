\section{Background\label{sec:background}}
In this section, we give a brief introduction to GNNs, and formalize the concept of DP.
\subsection{Graph neural networks}

\subsubsection{GNNs Overview}
\label{sec:GNNsOverview}

GNNs \cite{gnn_first} have emerged as a powerful class of machine learning models specifically designed to handle graph-structured data. They have gained considerable attention due to their ability to effectively learn and capture complex patterns in graph data, showing significant performance across a wide range of tasks, such as node classification \cite{Petar_GTA_node_class, Hamilton_node_class}, link prediction \cite{Zhang_link_pred}, and graph classification \cite{Xu_graph_class, Wang_graph_class}. In this paper, we specifically focus on the task of node classification, where the objective is to assign labels to individual nodes based on their features and on the overall graph structure.

More specifically, a graph $G = (V, E)$  is defined as a collection of nodes $V$ and edges $E$. Nodes represent data points such as users in social networks or proteins in biological networks, while edges represent relationships or interactions between the nodes. Graphs can be represented using an adjacency matrix $A \in \mathbb{R}^{n \times n}$, where $n = |V|$ is the number of nodes in the graph, and $A_{ij} = 1$ if there exists an edge between nodes $i$ and $j$, and $A_{ij} = 0$ otherwise.
Additionally, nodes exhibit a set of features, which can be represented as vectors containing $d$ elements, where $d$ corresponds to the number of features. In social networks, these features may include demographic information such as age, gender, and location, as well as user interests and preferences. To capture these features, the graph is also associated with a feature matrix $X \in \mathbb{R}^{n \times d}$. This matrix provides essential information about the characteristics of each node in the graph.

GNNs primarily operate by employing a message-passing mechanism \cite{gnn_first} that allows nodes to exchange and aggregate information from their local neighborhoods. This iterative process helps GNNs capture local and global structural information in the graph. For instance, in the context of graph convolutional networks (GCNs) \cite{gcn_first}, the most representative and well-established GNNs models, their core architecture consists of a series of graph convolutional layers, which can be formulated as follows:
\begin{equation}
H^{(0)}= X, \ayse{\quad}
H^{(l+1)} = \sigma \left( \hat{A} H^{(l)} W^{(l)} \right), \ayse{\quad}
H^{(L)} = P
\end{equation} 
For instance, $H^{(0)}$ denotes the node feature matrix $X$; $H^{(l)} \in \mathbb{R}^{n \times d_l}$ is the hidden node representation matrix at layer $l$, where $L$ is the total number of layers; and $P\in\mathbb{R}^{n \times\ c}$ represents the prediction scores for each potential class or label associated with the queried nodes, where $c$ reprensents the number of classes; $W^{(l)} \in \mathbb{R}^{d_l \times d_{l+1}}$ is the learnable weight matrix for layer $l$; $\sigma(\cdot)$ is an activation function (e.g., ReLU), and $\hat{A}$ is a normalized adjacency matrix.

\subsubsection{GNNs with dynamic graphs}
GNNs usually handle dynamic graph data as in real-life scenarios such as social network applications or recommendation systems, where graphs usually evolve over time. New nodes or edges may be introduced with time and the goal would be to make predictions for such new nodes.

When a new node is added to the graph, both the adjacency matrix  $A \in \mathbb{R}^{n \times n}$, and the feature matrix $X \in \mathbb{R}^{n \times d}$ are updated. The adjacency matrix expands to $A' \in \mathbb{R}^{(n+1) \times (n+1)}$, while the feature matrix becomes $X' \in \mathbb{R}^{(n+1) \times d}$,  incorporating the new node's connections and features, respectively.

Once the graph is updated, the GNN performs inference on the modified graph, using the message-passing mechanism described earlier.
\begin{table}[h]
\centering
\begin{tabular}{ll}
\toprule
Symbol & Description \\
\midrule
$A$ & Adjacency matrix \\
$\mathcal{A}$ & Adversary \\
$E$ & Set of edges in the graph \\
$G$ & Graph \\
$n$ & Number of nodes \\
$V$ & Set of nodes in the graph \\
$V_\mathcal{A}$ & Target set nodes \\
$v_m$ & Malicious injected node \\
$v_t$ & Target node \\
$P$ & Prediction scores of the GNN \\
$X$ & Feature matrix \\
$x_t$ & Features of the target node \\
$x_m$ & Features of the malicious node \\
\bottomrule
\end{tabular}
\caption{List of notations.}
\label{tab:notations}
\end{table}

\subsection{Differential privacy}
\label{sec:background:DP}
The original definition of DP~\cite{Dwork06A,dwork2014algorithmic} was introduced in the context of microdata, that is, databases containing records at the level of individuals. A central aspect of DP is the concept of \textit{neighborhood}, which was defined originally for that data structure as follows. %datasets.
%As defined in \cite{}, two datasets are defined as neighbouring datasets if they differ in one single record. 
\begin{definition}[\textbf{Neighboring databases}] 
Let $\mathcal{D}$ be the class of possible databases. Any two databases $D,D'\in \mathcal{D}$ that differ in one record are called \emph{neighbors}. For two neighbor databases, the following equality holds: $$d(D,D') = 1,$$ where $d$ denotes the Hamming distance. 
%between $\matn{x}$ and $\matn{x'}$.
%and thus counts the number of rows on which they differ.
\end{definition}

\begin{definition}[\textbf{$(\varepsilon, \delta)$-Differential privacy} \cite{Dwork06A,dwork2014algorithmic}]
	\label{def:dp}
	A randomized mechanism $\mathcal{M}$ satisfies $(\varepsilon,\delta)$-DP with $\varepsilon,\delta \geqslant 0$ if, for all pairs of neighboring databases $D,D'\in \mathcal{D}$ and for all measurable $\mathcal{O}\subseteq \Range(\mathcal{M})$,
	
	$$\oP\{\mathcal{M}(D)\in \mathcal{O}\} \leqslant e^{\varepsilon} \oP\{\mathcal{M}(D')\in \mathcal{O}\} + \delta.$$
\end{definition}

In words, the output of a mechanism satisfying DP should not reveal the presence or absence of any specific record in the database, up to an exponential factor of $\varepsilon$. When each record corresponds to a distinct individual respondent, DP aims to ensure their information will remain confidential. A lower value of $\varepsilon$, referred to as the \emph{privacy budget}, provides stronger protection.

Probably the most popular mechanism satisfying DP is the Laplace mechanism, which relies on a quantity called \emph{global sensitivity}, defined next.
\begin{definition}[$L_p{\text -}$\textbf{Global sensitivity}~\cite{dwork2014algorithmic}]
\label{def:GS}
The $L_p$-global sensitivity of a query function $f\colon\mathcal{D} \rightarrow \mathbb{R}^d$ is defined as
\begin{equation*}
%L_p{\text -}\textnormal{GS}
\Delta_p(f)=\max_{\substack{\forall D,D'}\in\mathcal{D}} \| f(D) - f(D')\|_p,
\end{equation*}
where $D,D'$ are any two neighbor databases.
\end{definition}

\begin{definition}[\textbf{Laplace mechanism}~\cite{dwork2014algorithmic}] Given any function $f\colon\mathcal{D} \rightarrow \mathbb{R}^d$, the Laplace mechanism mechanism is defined as follows:
$$\mathcal{M}_L(D,f(\cdot),\varepsilon) =f(D) + (Y_1,\ldots,Y_d),$$
where $Y_i$ are i.i.d. random variables drawn from a Laplace distribution with zero mean and scale
$\Delta_1(f)/\varepsilon$.
\end{definition}
