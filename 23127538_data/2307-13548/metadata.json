{
  "title": "Node Injection Link Stealing Attack",
  "authors": [
    "Oualid Zari",
    "Javier Parra-Arnau",
    "Ayşe Ünsal",
    "Melek Önen"
  ],
  "submission_date": "2023-07-25T14:51:01+00:00",
  "revised_dates": [],
  "abstract": "In this paper, we present a stealthy and effective attack that exposes privacy vulnerabilities in Graph Neural Networks (GNNs) by inferring private links within graph-structured data. Focusing on the inductive setting where new nodes join the graph and an API is used to query predictions, we investigate the potential leakage of private edge information. We also propose methods to preserve privacy while maintaining model utility. Our attack demonstrates superior performance in inferring the links compared to the state of the art. Furthermore, we examine the application of differential privacy (DP) mechanisms to mitigate the impact of our proposed attack, we analyze the trade-off between privacy preservation and model utility. Our work highlights the privacy vulnerabilities inherent in GNNs, underscoring the importance of developing robust privacy-preserving mechanisms for their application.",
  "categories": [
    "cs.CR",
    "cs.LG"
  ],
  "primary_category": "cs.CR",
  "doi": null,
  "journal_ref": null,
  "arxiv_id": "2307.13548",
  "pdf_url": null,
  "comment": null,
  "num_versions": null,
  "size_before_bytes": 2846718,
  "size_after_bytes": 1115287
}