
@inproceedings{koncel-kedziorski_mawps_2016,
	address = {San Diego, California},
	title = {{MAWPS}: {A} {Math} {Word} {Problem} {Repository}},
	shorttitle = {{MAWPS}},
	url = {https://aclanthology.org/N16-1136},
	doi = {10.18653/v1/N16-1136},
	urldate = {2022-06-07},
	booktitle = {Proceedings of the 2016 {Conference} of the {North} {American} {Chapter} of the {Association} for {Computational} {Linguistics}: {Human} {Language} {Technologies}},
	publisher = {Association for Computational Linguistics},
	author = {Koncel-Kedziorski, Rik and Roy, Subhro and Amini, Aida and Kushman, Nate and Hajishirzi, Hannaneh},
	month = jun,
	year = {2016},
	pages = {1152--1157},
	file = {Full Text PDF:/Users/abby/Zotero/storage/75XB9CA2/Koncel-Kedziorski et al. - 2016 - MAWPS A Math Word Problem Repository.pdf:application/pdf},
}

@techreport{miao_diverse_2021,
	title = {A {Diverse} {Corpus} for {Evaluating} and {Developing} {English} {Math} {Word} {Problem} {Solvers}},
	url = {http://arxiv.org/abs/2106.15772},
	abstract = {We present ASDiv (Academia Sinica Diverse MWP Dataset), a diverse (in terms of both language patterns and problem types) English math word problem (MWP) corpus for evaluating the capability of various MWP solvers. Existing MWP corpora for studying AI progress remain limited either in language usage patterns or in problem types. We thus present a new English MWP corpus with 2,305 MWPs that cover more text patterns and most problem types taught in elementary school. Each MWP is annotated with its problem type and grade level (for indicating the level of difficulty). Furthermore, we propose a metric to measure the lexicon usage diversity of a given MWP corpus, and demonstrate that ASDiv is more diverse than existing corpora. Experiments show that our proposed corpus reflects the true capability of MWP solvers more faithfully.},
	number = {arXiv:2106.15772},
	urldate = {2022-06-07},
	institution = {arXiv},
	author = {Miao, Shen-Yun and Liang, Chao-Chun and Su, Keh-Yih},
	month = jun,
	year = {2021},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
	file = {arXiv Fulltext PDF:/Users/abby/Zotero/storage/38RKJUVY/Miao et al. - 2021 - A Diverse Corpus for Evaluating and Developing Eng.pdf:application/pdf;arXiv.org Snapshot:/Users/abby/Zotero/storage/7RJQ4QBS/2106.html:text/html},
}

@inproceedings{wang_deep_2017,
	address = {Copenhagen, Denmark},
	title = {Deep {Neural} {Solver} for {Math} {Word} {Problems}},
	url = {https://aclanthology.org/D17-1088},
	doi = {10.18653/v1/D17-1088},
	abstract = {This paper presents a deep neural solver to automatically solve math word problems. In contrast to previous statistical learning approaches, we directly translate math word problems to equation templates using a recurrent neural network (RNN) model, without sophisticated feature engineering. We further design a hybrid model that combines the RNN model and a similarity-based retrieval model to achieve additional performance improvement. Experiments conducted on a large dataset show that the RNN model and the hybrid model significantly outperform state-of-the-art statistical learning methods for math word problem solving.},
	urldate = {2022-06-03},
	booktitle = {Proceedings of the 2017 {Conference} on {Empirical} {Methods} in {Natural} {Language} {Processing}},
	publisher = {Association for Computational Linguistics},
	author = {Wang, Yan and Liu, Xiaojiang and Shi, Shuming},
	month = sep,
	year = {2017},
	pages = {845--854},
	file = {Full Text PDF:/Users/abby/Zotero/storage/U9GC3VNC/Wang et al. - 2017 - Deep Neural Solver for Math Word Problems.pdf:application/pdf},
}

@article{zhang_graph--tree_2020,
	title = {Graph-to-tree learning for solving math word problems},
	url = {https://ink.library.smu.edu.sg/sis_research/5273},
	doi = {10.18653/v1/2020.acl-main.362},
	journal = {Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics},
	author = {Zhang, Jipeng and Wang, Lei and Lee, Roy Ka-Wei and Bin, Yi and Wang, Yan and Shao, Jie and LIM, Ee-peng},
	month = jul,
	year = {2020},
	pages = {3928--3937},
	file = {"Graph-to-tree learning for solving math word problems" by Jipeng ZHANG, Lei WANG et al.:/Users/abby/Zotero/storage/FGP3EFJP/5273.html:text/html;Full Text:/Users/abby/Zotero/storage/L5FSLTMM/ZHANG et al. - 2020 - Graph-to-tree learning for solving math word probl.pdf:application/pdf},
}

@inproceedings{griffith_solving_2019,
	title = {Solving {Arithmetic} {Word} {Problems} {Automatically} {Using} {Transformer} and {Unambiguous} {Representations}},
	doi = {10.1109/CSCI49370.2019.00101},
	abstract = {Constructing accurate and automatic solvers of math word problems has proven to be quite challenging. Prior attempts using machine learning have been trained on corpora specific to math word problems to produce arithmetic expressions in infix notation before answer computation. We find that custom-built neural networks have struggled to generalize well. This paper outlines the use of Transformer networks trained to translate math word problems to equivalent arithmetic expressions in infix, prefix, and postfix notations. In addition to training directly on domain-specific corpora, we use an approach that pre-trains on a general text corpus to provide foundational language abilities to explore if it improves performance. We compare results produced by a large number of neural configurations and find that most configurations outperform previously reported approaches on three of four datasets with significant increases in accuracy of over 20 percentage points. The best neural approaches boost accuracy by almost 10\% on average when compared to the previous state of the art.},
	booktitle = {2019 {International} {Conference} on {Computational} {Science} and {Computational} {Intelligence} ({CSCI})},
	author = {Griffith, Kaden and Kalita, Jugal},
	month = dec,
	year = {2019},
	keywords = {Genetic expression, Machine learning, Machine Learning, Math Word Problems, Mathematical model, Natural languages, Natural Languge Processing, Neural networks, NLP, Question Answering, Testing, Training},
	pages = {526--532},
	file = {IEEE Xplore Abstract Record:/Users/abby/Zotero/storage/WV5PLPLL/9071054.html:text/html;IEEE Xplore Full Text PDF:/Users/abby/Zotero/storage/38P6KPSE/Griffith and Kalita - 2019 - Solving Arithmetic Word Problems Automatically Usi.pdf:application/pdf},
}

@inproceedings{xie_goal-driven_2019,
	address = {Macao, China},
	title = {A {Goal}-{Driven} {Tree}-{Structured} {Neural} {Model} for {Math} {Word} {Problems}},
	isbn = {978-0-9992411-4-1},
	url = {https://www.ijcai.org/proceedings/2019/736},
	doi = {10.24963/ijcai.2019/736},
	abstract = {Most existing neural models for math word problems exploit Seq2Seq model to generate solution expressions sequentially from left to right, whose results are far from satisfactory due to the lack of goal-driven mechanism commonly seen in human problem solving. This paper proposes a treestructured neural model to generate expression tree in a goal-driven manner. Given a math word problem, the model ﬁrst identiﬁes and encodes its goal to achieve, and then the goal gets decomposed into sub-goals combined by an operator in a top-down recursive way. The whole process is repeated until the goal is simple enough to be realized by a known quantity as leaf node. During the process, two-layer gated-feedforward networks are designed to implement each step of goal decomposition, and a recursive neural network is used to encode fulﬁlled subtrees into subtree embeddings, which provides a better representation of subtrees than the simple goals of subtrees. Experimental results on the dataset Math23K have shown that our treestructured model outperforms signiﬁcantly several state-of-the-art models.},
	language = {en},
	urldate = {2022-06-03},
	booktitle = {Proceedings of the {Twenty}-{Eighth} {International} {Joint} {Conference} on {Artificial} {Intelligence}},
	author = {Xie, Zhipeng and Sun, Shichao},
	month = aug,
	year = {2019},
	pages = {5299--5305},
	file = {Xie and Sun - 2019 - A Goal-Driven Tree-Structured Neural Model for Mat.pdf:/Users/abby/Zotero/storage/K3WAFYA8/Xie and Sun - 2019 - A Goal-Driven Tree-Structured Neural Model for Mat.pdf:application/pdf},
}

@inproceedings{patel_are_2021,
	title = {Are {NLP} {Models} really able to {Solve} {Simple} {Math} {Word} {Problems}?},
	url = {https://aclanthology.org/2021.naacl-main.168},
	doi = {10.18653/v1/2021.naacl-main.168},
	abstract = {The problem of designing NLP solvers for math word problems (MWP) has seen sustained research activity and steady gains in the test accuracy. Since existing solvers achieve high performance on the benchmark datasets for elementary level MWPs containing one-unknown arithmetic word problems, such problems are often considered “solved” with the bulk of research attention moving to more complex MWPs. In this paper, we restrict our attention to English MWPs taught in grades four and lower. We provide strong evidence that the existing MWP solvers rely on shallow heuristics to achieve high performance on the benchmark datasets. To this end, we show that MWP solvers that do not have access to the question asked in the MWP can still solve a large fraction of MWPs. Similarly, models that treat MWPs as bag-of-words can also achieve surprisingly high accuracy. Further, we introduce a challenge dataset, SVAMP, created by applying carefully chosen variations over examples sampled from existing datasets. The best accuracy achieved by state-of-the-art models is substantially lower on SVAMP, thus showing that much remains to be done even for the simplest of the MWPs.},
	urldate = {2022-05-31},
	booktitle = {Proceedings of the 2021 {Conference} of the {North} {American} {Chapter} of the {Association} for {Computational} {Linguistics}: {Human} {Language} {Technologies}},
	author = {Patel, Arkil and Bhattamishra, Satwik and Goyal, Navin},
	month = jun,
	year = {2021},
	pages = {2080--2094},
	file = {Full Text PDF:/Users/abby/Zotero/storage/6EI49S4A/Patel et al. - 2021 - Are NLP Models really able to Solve Simple Math Wo.pdf:application/pdf},
}

@techreport{kumar_practice_2022,
	title = {Practice {Makes} a {Solver} {Perfect}: {Data} {Augmentation} for {Math} {Word} {Problem} {Solvers}},
	shorttitle = {Practice {Makes} a {Solver} {Perfect}},
	url = {http://arxiv.org/abs/2205.00177},
	abstract = {Existing Math Word Problem (MWP) solvers have achieved high accuracy on benchmark datasets. However, prior works have shown that such solvers do not generalize well and rely on superficial cues to achieve high performance. In this paper, we first conduct experiments to showcase that this behaviour is mainly associated with the limited size and diversity present in existing MWP datasets. Next, we propose several data augmentation techniques broadly categorized into Substitution and Paraphrasing based methods. By deploying these methods we increase the size of existing datasets by five folds. Extensive experiments on two benchmark datasets across three state-of-the-art MWP solvers show that proposed methods increase the generalization and robustness of existing solvers. On average, proposed methods significantly increase the state-of-the-art results by over five percentage points on benchmark datasets. Further, the solvers trained on the augmented dataset perform comparatively better on the challenge test set. We also show the effectiveness of proposed techniques through ablation studies and verify the quality of augmented samples through human evaluation.},
	number = {arXiv:2205.00177},
	urldate = {2022-06-03},
	institution = {arXiv},
	author = {Kumar, Vivek and Maheshwary, Rishabh and Pudi, Vikram},
	month = apr,
	year = {2022},
	doi = {10.48550/arXiv.2205.00177},
	keywords = {Computer Science - Computation and Language},
	file = {arXiv Fulltext PDF:/Users/abby/Zotero/storage/XRMWJNRF/Kumar et al. - 2022 - Practice Makes a Solver Perfect Data Augmentation.pdf:application/pdf;arXiv.org Snapshot:/Users/abby/Zotero/storage/69VC4ZWP/2205.html:text/html},
}

@misc{li_understanding_2017,
	title = {Understanding {Neural} {Networks} through {Representation} {Erasure}},
	url = {http://arxiv.org/abs/1612.08220},
	doi = {10.48550/arXiv.1612.08220},
	abstract = {While neural networks have been successfully applied to many natural language processing tasks, they come at the cost of interpretability. In this paper, we propose a general methodology to analyze and interpret decisions from a neural model by observing the effects on the model of erasing various parts of the representation, such as input word-vector dimensions, intermediate hidden units, or input words. We present several approaches to analyzing the effects of such erasure, from computing the relative difference in evaluation metrics, to using reinforcement learning to erase the minimum set of input words in order to flip a neural model's decision. In a comprehensive analysis of multiple NLP tasks, including linguistic feature classification, sentence-level sentiment analysis, and document level sentiment aspect prediction, we show that the proposed methodology not only offers clear explanations about neural model decisions, but also provides a way to conduct error analysis on neural models.},
	urldate = {2022-07-07},
	publisher = {arXiv},
	author = {Li, Jiwei and Monroe, Will and Jurafsky, Dan},
	month = jan,
	year = {2017},
	note = {arXiv:1612.08220},
	keywords = {Computer Science - Computation and Language},
	file = {arXiv Fulltext PDF:/Users/abby/Zotero/storage/LQW8GDC3/Li et al. - 2017 - Understanding Neural Networks through Representati.pdf:application/pdf;arXiv.org Snapshot:/Users/abby/Zotero/storage/CDDS7N5C/1612.html:text/html},
}

@misc{feng_pathologies_2018,
	title = {Pathologies of {Neural} {Models} {Make} {Interpretations} {Difficult}},
	url = {http://arxiv.org/abs/1804.07781},
	doi = {10.48550/arXiv.1804.07781},
	abstract = {One way to interpret neural model predictions is to highlight the most important input features---for example, a heatmap visualization over the words in an input sentence. In existing interpretation methods for NLP, a word's importance is determined by either input perturbation---measuring the decrease in model confidence when that word is removed---or by the gradient with respect to that word. To understand the limitations of these methods, we use input reduction, which iteratively removes the least important word from the input. This exposes pathological behaviors of neural models: the remaining words appear nonsensical to humans and are not the ones determined as important by interpretation methods. As we confirm with human experiments, the reduced examples lack information to support the prediction of any label, but models still make the same predictions with high confidence. To explain these counterintuitive results, we draw connections to adversarial examples and confidence calibration: pathological behaviors reveal difficulties in interpreting neural models trained with maximum likelihood. To mitigate their deficiencies, we fine-tune the models by encouraging high entropy outputs on reduced examples. Fine-tuned models become more interpretable under input reduction without accuracy loss on regular examples.},
	urldate = {2022-07-06},
	publisher = {arXiv},
	author = {Feng, Shi and Wallace, Eric and Grissom II, Alvin and Iyyer, Mohit and Rodriguez, Pedro and Boyd-Graber, Jordan},
	month = aug,
	year = {2018},
	note = {arXiv:1804.07781},
	keywords = {Computer Science - Computation and Language},
	file = {arXiv Fulltext PDF:/Users/abby/Zotero/storage/CVIDYG84/Feng et al. - 2018 - Pathologies of Neural Models Make Interpretations .pdf:application/pdf;arXiv.org Snapshot:/Users/abby/Zotero/storage/F5EZHRTI/1804.html:text/html},
}

@misc{wallace_allennlp_2019,
	title = {{AllenNLP} {Interpret}: {A} {Framework} for {Explaining} {Predictions} of {NLP} {Models}},
	shorttitle = {{AllenNLP} {Interpret}},
	url = {https://arxiv.org/abs/1909.09251v1},
	doi = {10.48550/arXiv.1909.09251},
	abstract = {Neural NLP models are increasingly accurate but are imperfect and opaque---they break in counterintuitive ways and leave end users puzzled at their behavior. Model interpretation methods ameliorate this opacity by providing explanations for specific model predictions. Unfortunately, existing interpretation codebases make it difficult to apply these methods to new models and tasks, which hinders adoption for practitioners and burdens interpretability researchers. We introduce AllenNLP Interpret, a flexible framework for interpreting NLP models. The toolkit provides interpretation primitives (e.g., input gradients) for any AllenNLP model and task, a suite of built-in interpretation methods, and a library of front-end visualization components. We demonstrate the toolkit's flexibility and utility by implementing live demos for five interpretation methods (e.g., saliency maps and adversarial attacks) on a variety of models and tasks (e.g., masked language modeling using BERT and reading comprehension using BiDAF). These demos, alongside our code and tutorials, are available at https://allennlp.org/interpret .},
	language = {en},
	urldate = {2022-07-07},
	author = {Wallace, Eric and Tuyls, Jens and Wang, Junlin and Subramanian, Sanjay and Gardner, Matt and Singh, Sameer},
	month = sep,
	year = {2019},
	file = {Full Text PDF:/Users/abby/Zotero/storage/JUHT49MF/Wallace et al. - 2019 - AllenNLP Interpret A Framework for Explaining Pre.pdf:application/pdf;Snapshot:/Users/abby/Zotero/storage/F3ML7LDQ/1909.html:text/html},
}

@article{lee_qadiver_2019,
	title = {{QADiver}: {Interactive} {Framework} for {Diagnosing} {QA} {Models}},
	volume = {33},
	copyright = {Copyright (c) 2019 Association for the Advancement of Artificial Intelligence},
	issn = {2374-3468},
	shorttitle = {{QADiver}},
	url = {https://ojs.aaai.org/index.php/AAAI/article/view/5068},
	doi = {10.1609/aaai.v33i01.33019861},
	abstract = {Question answering (QA) extracting answers from text to the given question in natural language, has been actively studied and existing models have shown a promise of outperforming human performance when trained and evaluated with SQuAD dataset. However, such performance may not be replicated in the actual setting, for which we need to diagnose the cause, which is non-trivial due to the complexity of model. We thus propose a web-based UI that provides how each model contributes to QA performances, by integrating visualization and analysis tools for model explanation. We expect this framework can help QA model researchers to refine and improve their models.},
	language = {en},
	number = {01},
	urldate = {2022-07-08},
	journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
	author = {Lee, Gyeongbok and Kim, Sungdong and Hwang, Seung-won},
	month = jul,
	year = {2019},
	note = {},
	pages = {9861--9862},
	file = {Full Text PDF:/Users/abby/Zotero/storage/6I4N52SD/Lee et al. - 2019 - QADiver Interactive Framework for Diagnosing QA M.pdf:application/pdf},
}

@misc{jia_adversarial_2017,
	title = {Adversarial {Examples} for {Evaluating} {Reading} {Comprehension} {Systems}},
	url = {http://arxiv.org/abs/1707.07328},
	doi = {10.48550/arXiv.1707.07328},
	abstract = {Standard accuracy metrics indicate that reading comprehension systems are making rapid progress, but the extent to which these systems truly understand language remains unclear. To reward systems with real language understanding abilities, we propose an adversarial evaluation scheme for the Stanford Question Answering Dataset (SQuAD). Our method tests whether systems can answer questions about paragraphs that contain adversarially inserted sentences, which are automatically generated to distract computer systems without changing the correct answer or misleading humans. In this adversarial setting, the accuracy of sixteen published models drops from an average of \$75{\textbackslash}\%\$ F1 score to \$36{\textbackslash}\%\$; when the adversary is allowed to add ungrammatical sequences of words, average accuracy on four models decreases further to \$7{\textbackslash}\%\$. We hope our insights will motivate the development of new models that understand language more precisely.},
	urldate = {2022-07-07},
	publisher = {arXiv},
	author = {Jia, Robin and Liang, Percy},
	month = jul,
	year = {2017},
	note = {arXiv:1707.07328},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning},
	file = {arXiv Fulltext PDF:/Users/abby/Zotero/storage/4WH4IUY2/Jia and Liang - 2017 - Adversarial Examples for Evaluating Reading Compre.pdf:application/pdf;arXiv.org Snapshot:/Users/abby/Zotero/storage/PFT3PZYN/1707.html:text/html},
}

@techreport{kumar_adversarial_2021,
	title = {Adversarial {Examples} for {Evaluating} {Math} {Word} {Problem} {Solvers}},
	url = {http://arxiv.org/abs/2109.05925},
	abstract = {Standard accuracy metrics have shown that Math Word Problem (MWP) solvers have achieved high performance on benchmark datasets. However, the extent to which existing MWP solvers truly understand language and its relation with numbers is still unclear. In this paper, we generate adversarial attacks to evaluate the robustness of state-of-the-art MWP solvers. We propose two methods Question Reordering and Sentence Paraphrasing to generate adversarial attacks. We conduct experiments across three neural MWP solvers over two benchmark datasets. On average, our attack method is able to reduce the accuracy of MWP solvers by over 40 percentage points on these datasets. Our results demonstrate that existing MWP solvers are sensitive to linguistic variations in the problem text. We verify the validity and quality of generated adversarial examples through human evaluation.},
	number = {arXiv:2109.05925},
	urldate = {2022-06-15},
	institution = {arXiv},
	author = {Kumar, Vivek and Maheshwary, Rishabh and Pudi, Vikram},
	month = sep,
	year = {2021},
	doi = {10.48550/arXiv.2109.05925},
	note = {arXiv:2109.05925},
	keywords = {Computer Science - Computation and Language},
	file = {arXiv Fulltext PDF:/Users/abby/Zotero/storage/KDXUSDSY/Kumar et al. - 2021 - Adversarial Examples for Evaluating Math Word Prob.pdf:application/pdf;arXiv.org Snapshot:/Users/abby/Zotero/storage/SF8FTARZ/2109.html:text/html},
}

@book{bird_natural_2009,
	title = {Natural language processing with {Python}: analyzing text with the natural language toolkit},
	url = {https://www.nltk.org/book/},
	urldate = {2022-07-07},
	publisher = {O'Reilly Media, Inc.},
	author = {Bird, Steven and Klein, Ewan and Loper, Edward},
	year = {2009},
	file = {NLTK Book:/Users/abby/Zotero/storage/4D25FI9E/book.html:text/html},
}

@techreport{jie_learning_2022,
	title = {Learning to {Reason} {Deductively}: {Math} {Word} {Problem} {Solving} as {Complex} {Relation} {Extraction}},
	shorttitle = {Learning to {Reason} {Deductively}},
	url = {http://arxiv.org/abs/2203.10316},
	abstract = {Solving math word problems requires deductive reasoning over the quantities in the text. Various recent research efforts mostly relied on sequence-to-sequence or sequence-to-tree models to generate mathematical expressions without explicitly performing relational reasoning between quantities in the given context. While empirically effective, such approaches typically do not provide explanations for the generated expressions. In this work, we view the task as a complex relation extraction problem, proposing a novel approach that presents explainable deductive reasoning steps to iteratively construct target expressions, where each step involves a primitive operation over two quantities defining their relation. Through extensive experiments on four benchmark datasets, we show that the proposed model significantly outperforms existing strong baselines. We further demonstrate that the deductive procedure not only presents more explainable steps but also enables us to make more accurate predictions on questions that require more complex reasoning.},
	number = {arXiv:2203.10316},
	urldate = {2022-06-01},
	institution = {arXiv},
	author = {Jie, Zhanming and Li, Jierui and Lu, Wei},
	month = apr,
	year = {2022},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning},
	file = {arXiv Fulltext PDF:/Users/abby/Zotero/storage/UZEI43EW/Jie et al. - 2022 - Learning to Reason Deductively Math Word Problem .pdf:application/pdf;arXiv.org Snapshot:/Users/abby/Zotero/storage/PR2KCHPB/2203.html:text/html},
}

@inproceedings{helwe_reasoning_2021,
	title = {Reasoning with {Transformer}-based {Models}: {Deep} {Learning}, but {Shallow} {Reasoning}},
	shorttitle = {Reasoning with {Transformer}-based {Models}},
	url = {https://openreview.net/forum?id=Ozp1WrgtF5_},
	abstract = {Recent years have seen impressive performance of transformer-based models on different natural language processing tasks. However, it is not clear to what degree the transformers can reason on...},
	language = {en},
	urldate = {2022-06-01},
	booktitle = {Proceedings of the 3rd {Conference} on {Automated} {Knowledge} {Base} {Construction}},
	author = {Helwe, Chadi and Clavel, Chloé and Suchanek, Fabian M.},
	month = jun,
	year = {2021},
	file = {Full Text PDF:/Users/abby/Zotero/storage/4599LL3S/Helwe et al. - 2021 - Reasoning with Transformer-based Models Deep Lear.pdf:application/pdf;Snapshot:/Users/abby/Zotero/storage/Z6I4T2FV/forum.html:text/html},
}

@techreport{sundaram_why_2022,
	title = {Why are {NLP} {Models} {Fumbling} at {Elementary} {Math}? {A} {Survey} of {Deep} {Learning} based {Word} {Problem} {Solvers}},
	shorttitle = {Why are {NLP} {Models} {Fumbling} at {Elementary} {Math}?},
	url = {http://arxiv.org/abs/2205.15683},
	abstract = {From the latter half of the last decade, there has been a growing interest in developing algorithms for automatically solving mathematical word problems (MWP). It is a challenging and unique task that demands blending surface level text pattern recognition with mathematical reasoning. In spite of extensive research, we are still miles away from building robust representations of elementary math word problems and effective solutions for the general task. In this paper, we critically examine the various models that have been developed for solving word problems, their pros and cons and the challenges ahead. In the last two years, a lot of deep learning models have recorded competing results on benchmark datasets, making a critical and conceptual analysis of literature highly useful at this juncture. We take a step back and analyse why, in spite of this abundance in scholarly interest, the predominantly used experiment and dataset designs continue to be a stumbling block. From the vantage point of having analyzed the literature closely, we also endeavour to provide a road-map for future math word problem research.},
	number = {arXiv:2205.15683},
	urldate = {2022-06-13},
	institution = {arXiv},
	author = {Sundaram, Sowmya S. and Gurajada, Sairam and Fisichella, Marco and P, Deepak and Abraham, Savitha Sam},
	month = may,
	year = {2022},
	doi = {10.48550/arXiv.2205.15683},
	note = {arXiv:2205.15683 ]
type: article},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
	file = {arXiv Fulltext PDF:/Users/abby/Zotero/storage/7X8JBYBX/Sundaram et al. - 2022 - Why are NLP Models Fumbling at Elementary Math A .pdf:application/pdf;arXiv.org Snapshot:/Users/abby/Zotero/storage/Z4GLXLUS/2205.html:text/html},
}

@misc{klavans_role_1998,
	title = {The {Role} of {Verbs} in {Document} {Analysis}},
	url = {http://arxiv.org/abs/cmp-lg/9807002},
	doi = {10.48550/arXiv.cmp-lg/9807002},
	abstract = {We present results of two methods for assessing the event profile of news articles as a function of verb type. The unique contribution of this research is the focus on the role of verbs, rather than nouns. Two algorithms are presented and evaluated, one of which is shown to accurately discriminate documents by type and semantic properties, i.e. the event profile. The initial method, using WordNet (Miller et al. 1990), produced multiple cross-classification of articles, primarily due to the bushy nature of the verb tree coupled with the sense disambiguation problem. Our second approach using English Verb Classes and Alternations (EVCA) Levin (1993) showed that monosemous categorization of the frequent verbs in WSJ made it possible to usefully discriminate documents. For example, our results show that articles in which communication verbs predominate tend to be opinion pieces, whereas articles with a high percentage of agreement verbs tend to be about mergers or legal cases. An evaluation is performed on the results using Kendall's Tau. We present convincing evidence for using verb semantic classes as a discriminant in document classification.},
	urldate = {2022-06-17},
	publisher = {arXiv},
	author = {Klavans, Judith L. and Kan, Min-Yen},
	month = jul,
	year = {1998},
	note = {Number: arXiv:cmp-lg/9807002
arXiv:cmp-lg/9807002},
	keywords = {Computer Science - Computation and Language},
	file = {arXiv Fulltext PDF:/Users/abby/Zotero/storage/G5LG87K5/Klavans and Kan - 1998 - The Role of Verbs in Document Analysis.pdf:application/pdf;arXiv.org Snapshot:/Users/abby/Zotero/storage/5TL7EH33/9807002.html:text/html},
}

@inproceedings{kipper_extending_2006,
	address = {Genoa, Italy},
	title = {Extending {VerbNet} with {Novel} {Verb} {Classes}},
	url = {http://www.lrec-conf.org/proceedings/lrec2006/pdf/468_pdf.pdf},
	abstract = {Lexical classifications have proved useful in supporting various natural language processing (NLP) tasks. The largest verb classification for English is Levin's (1993) work which defined groupings of verbs based on syntactic properties. VerbNet - the largest computational verb lexicon currently available for English - provides detailed syntactic-semantic descriptions of Levin classes. While the classes included are extensive enough for some NLP use, they are not comprehensive. Korhonen and Briscoe (2004) have proposed a significant extension of Levin's classification which incorporates 57 novel classes for verbs not covered (comprehensively) by Levin. This paper describes the integration of these classes into VerbNet. The result is the most extensive Levin-style classification for English verbs which can be highly useful for practical applications.},
	urldate = {2022-06-17},
	booktitle = {Proceedings of the {Fifth} {International} {Conference} on {Language} {Resources} and {Evaluation} ({LREC}'06)},
	publisher = {European Language Resources Association (ELRA)},
	author = {Kipper, Karin and Korhonen, Anna and Ryant, Neville and Palmer, Martha},
	month = may,
	year = {2006},
	file = {Full Text PDF:/Users/abby/Zotero/storage/FQDQKGEC/Kipper et al. - 2006 - Extending VerbNet with Novel Verb Classes.pdf:application/pdf},
}

@inproceedings{brown_verbnet_2019,
	address = {Florence, Italy},
	title = {{VerbNet} {Representations}: {Subevent} {Semantics} for {Transfer} {Verbs}},
	shorttitle = {{VerbNet} {Representations}},
	url = {https://aclanthology.org/W19-3318},
	doi = {10.18653/v1/W19-3318},
	abstract = {This paper announces the release of a new version of the English lexical resource VerbNet with substantially revised semantic representations designed to facilitate computer planning and reasoning based on human language. We use the transfer of possession and transfer of information event representations to illustrate both the general framework of the representations and the types of nuances the new representations can capture. These representations use a Generative Lexicon-inspired subevent structure to track attributes of event participants across time, highlighting oppositions and temporal and causal relations among the subevents.},
	urldate = {2022-06-17},
	booktitle = {Proceedings of the {First} {International} {Workshop} on {Designing} {Meaning} {Representations}},
	publisher = {Association for Computational Linguistics},
	author = {Brown, Susan Windisch and Bonn, Julia and Gung, James and Zaenen, Annie and Pustejovsky, James and Palmer, Martha},
	month = aug,
	year = {2019},
	pages = {154--163},
	file = {Full Text PDF:/Users/abby/Zotero/storage/52BJ9P52/Brown et al. - 2019 - VerbNet Representations Subevent Semantics for Tr.pdf:application/pdf},
}

@misc{wallace_universal_2021,
	title = {Universal {Adversarial} {Triggers} for {Attacking} and {Analyzing} {NLP}},
	url = {http://arxiv.org/abs/1908.07125},
	doi = {10.48550/arXiv.1908.07125},
	abstract = {Adversarial examples highlight model vulnerabilities and are useful for evaluation and interpretation. We define universal adversarial triggers: input-agnostic sequences of tokens that trigger a model to produce a specific prediction when concatenated to any input from a dataset. We propose a gradient-guided search over tokens which finds short trigger sequences (e.g., one word for classification and four words for language modeling) that successfully trigger the target prediction. For example, triggers cause SNLI entailment accuracy to drop from 89.94\% to 0.55\%, 72\% of "why" questions in SQuAD to be answered "to kill american people", and the GPT-2 language model to spew racist output even when conditioned on non-racial contexts. Furthermore, although the triggers are optimized using white-box access to a specific model, they transfer to other models for all tasks we consider. Finally, since triggers are input-agnostic, they provide an analysis of global model behavior. For instance, they confirm that SNLI models exploit dataset biases and help to diagnose heuristics learned by reading comprehension models.},
	urldate = {2022-07-07},
	publisher = {arXiv},
	author = {Wallace, Eric and Feng, Shi and Kandpal, Nikhil and Gardner, Matt and Singh, Sameer},
	month = jan,
	year = {2021},
	note = {arXiv:1908.07125},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning},
	file = {arXiv Fulltext PDF:/Users/abby/Zotero/storage/ZC2JJBXA/Wallace et al. - 2021 - Universal Adversarial Triggers for Attacking and A.pdf:application/pdf;arXiv.org Snapshot:/Users/abby/Zotero/storage/CMRIW3D9/1908.html:text/html},
}
