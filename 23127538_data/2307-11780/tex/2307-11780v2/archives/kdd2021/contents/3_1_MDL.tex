\subsection{MDL principle}

The MDL principle was originally theorized in the context of data compression \cite{grunwald2007minimum}.
In order to minimize storage space, MDL describes the original dataset $D$ with a model $M$, which usually suggests the regularity in the data.
The MDL principle works under the assumption that the optimal model results in the shortest description length.
More formally, an optimal model $M$ can minimize $L(M) + L(D|M)$, where $L(M)$ is the description length of model $M$, and $L(D|M)$ is the description length of the original dataset $D$ when $D$ is described by $M$.
An MDL-based algorithm usually aims to solve three problems; namely, how to design a model, how to encode the dataset using a model, and how to obtain the optimal model.

In the past two decades, MDL has been applied to sequential pattern mining \cite{siebes2006item,tatti2012long,bertens2016keeping,kawabata2018streamscope}, and there exists a robust framework to solve the three problems mentioned above.
In our paper, we follow this framework and extend it to meet our requirements for effectiveness and efficiency.
Our solutions to the three aforementioned problems are as follows.
We define our model in Section \ref{sec:ct}, introduce the process of encoding in Section \ref{sec:encoding}, and propose our algorithm for obtaining model in Section \ref{sec:F4M}.
% Our solutions to the three questions are as follows.