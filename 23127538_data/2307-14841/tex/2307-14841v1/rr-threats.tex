Our work is subjected a number of threats to validity, namely: 
(1) internal validity, which refers to the inferences we will make;
(2) external validity, which is related to the generalization of our findings;
(3) construction validity, which refers to the approaches we use to address the research questions;
and (4) conclusion validity, which is related to the interpretation of our results.

\subsection{Internal \& External Validity}

Regarding the internal validity, to address RQ1 we relied on our feature framework which may not cover all the features from code hosting platforms.
The dimensions of our framework will be gathered by an analysis of a set of platforms.
However, these platforms provide subsets of features according to their business objectives. 
Furthermore, the interpretation of the features and topics is subjected to the understanding of the authors.
To address RQ2 we will rely on the data provided by \hfc, which uses data from the HFH API and Git.
Git and HFH data may suffer from user clashing, as usernames in both platforms may not match, as reported by Ait et al.~\cite{hfc}.
\textcolor{\mycolor}{It is also important to note that the emerging behavior of HFH does not demonstrate consolidation and spread yet, which may limit the scope of our inferences.}


As for the external validity, the analysis done in RQ1 will rely on the current feature offer of HFH at the moment of performing our registered report, but it may change in the future.
On the other hand, the dataset used in RQ2 will be based on a set of HFH projects from \hfc, which releases monthly versions.
Thus, the results of the registered report should not be directly generalized without proper comparison and validation.
{\color{\mycolor} In particular, it is important to note that the results of this study have been obtained from a particular snapshot of HFH.}

\subsection{Construct \& Conclusion Validity}

The process to construct the feature framework will follow an iterative approach where each social code hosting platform is analyzed to identify the features.
In this approach, each platform is studied individually to identify its features, and then they are shared to identify a superset of features
As some features may be shared or be similar, the process repeats until no more new features are identified.
In the last step, the set of features are grouped according to a topic.
\textcolor{\mycolor}{The main process is performed by the first author, and the results are debated by the second and third authors.
Disagreements are discussed until a consensus is reached.
As mentioned in Section~\ref{sec:variablesQualitative}, the resulting set of features will be validated by conducting semi-structured interviews with relevant actors of each analyzed platform}

Conclusion validity affects to the results of the analysis plan, which relies on the results of the execution plan.
In this case, the conclusion validity is mainly threatened by biases of our interpretation of the results of the RQs.

