\subsection{Generalized Implicit FTRL}
\label{sec:mainres}

In this section, we summarize the generalized formulation of the implicit FTRL algorithm from \citet{ChenO23}.
The main idea is to depart from the implicit or linearized updates,  and directly design updates that improve the upper bound on the regret. 
More in detail, the basic analysis of most of the online learning algorithms is based on the definition of subgradients:
\begin{equation}
\label{eq:subgradient_ineq}
\ell_t(\bx_t) - \ell_t(\bu)
\leq \langle \bg_t, \bx_t-\bu\rangle, \ \forall \bg_t \in \partial \ell_t(\bx_t)~.
\end{equation}
This allows to study the regret on the linearized losses as a proxy for the regret on the losses $\ell_t$.
Instead, \citet{ChenO23} introduce a new fundamental and more general strategy: using the Fenchel-Young inequality, we have
\[
\ell_t(\bx_t) - \ell_t(\bu)  
\leq  \ell_t(\bx_t) - \langle \bz_t,\bu\rangle + \ell_t^\star(\bz_t), \ \forall \bz_t~.
\]
In particular, the algorithm will choose $\bz_t$ from the dual space to make a certain upper bound involving this quantity to be tighter.
This is a better inequality than \eqref{eq:subgradient_ineq} because when we select $\bz_t=\bg_t \in \partial \ell_t(\bx_t)$, using Theorem~\ref{thm:props_fenchel}, we recover \eqref{eq:subgradient_ineq}. So, this inequality subsumes the standard one for subgradients, but, using $\bz_t \in \ell_t(\bx_{t+1})$, it also subsumes the similar inequality used in the implicit case.
%, as we show in Section~\ref{sec:prox}. Moreover, we will see in Section~\ref{sec:aprox} that it covers cases where $\bz_t$ is \emph{not} a subgradient of $\ell_t$. 

The analysis in \citet{ChenO23} shows that the optimal setting of $\bz_t$ is the one that minimizes the sum of two conjugate functions:
\begin{equation}
\label{eq:h}
H_t(\bz)
\triangleq\psi^\star_{t+1,V}(\btheta_{t}-\bz) + \ell^\star_t(\bz),
\end{equation}
%or
%\begin{equation}
%\label{eq:hprime}
%H'_t(\bz)
%\triangleq\psi^\star_{t,V}(\btheta_{t}-\bz_t) + \ell^\star_t(\bz),
%\end{equation}
where $\psi_{t,V}$ is the restriction of the regularizer used at time $t$ on the feasible set $V$, i.e., $\psi_{t,V}\triangleq\psi_t+i_V$.
However, we can show that any setting of $\bz_t$ that satisfies $H(\bz_t)< H(\bg_t)$ 
%(or $H'(\bz_t)< H'(\bg_t)$)
guarantees a strict improvement in the worst-case regret w.r.t. using the linearized losses.
The presence of conjugate functions should not be surprising because we are looking for a surrogate gradient $\bz_t$ that lives in the dual space.

%One might wonder why the need for two different updates using $H_t$ or $H'_t$. The reason is that when using time-varying regularizers that depend on the data, like in the FTRL version of AdaGrad~\citep{McMahanS10,DuchiHS11}, if $\lambda_{t+1}$ depends on $\bz_t$ it might make the calculation of the update particularly difficult. This can be avoided using the update involving $H'_t$.

\begin{algorithm}[t]
\caption{Generalized Implicit FTRL}
\label{alg:giftrl}
\begin{algorithmic}[1]
{
    \REQUIRE{Non-empty closed set $V\subseteq \R^d$, a sequence of regularizers $\psi_1, \dots, \psi_T : \R^d \rightarrow (-\infty, +\infty]$}
    \STATE{$\btheta_1=\boldsymbol{0}$}
    \FOR{$t=1$ {\bfseries to} $T$}
    \STATE{Output $\bx_t \in \argmin_{\bx \in V} \ \psi_t(\bx) - \langle \btheta_t, \bx\rangle$}
    \STATE{Receive $\ell_t:V \rightarrow \R$ and pay $\ell_t(\bx_t)$}
    \STATE{Set $\bg_t \in \partial \ell_t(\bx_t)$}
    \STATE{Set $\bz_t$ such that $H_t(\bz_t)\leq H_t(\bg_t)$
    %or $H'_t(\bz_t)\leq H'_t(\bg_t)$
    where $H_t$
    %and $H'_t$
    is defined in \eqref{eq:h}}
    %and \eqref{eq:hprime}}
    %\[
    %\psi^\star_{t,V}(\btheta_{t}-\bz_t) + \ell^\star_t(\bz_t)
    %\leq \psi^\star_{t,V}(\btheta_{t}-\bg_t) + \ell^\star_t(\bg_t)
    %\]
    %or such that
    %\[
    %\psi^\star_{t+1,V}(\btheta_{t}-\bz_t) + \ell^\star_t(\bz_t)
    %\leq \psi^\star_{t+1,V}(\btheta_{t}-\bg_t) + \ell^\star_t(\bg_t)
    %\]}
    \STATE{Set $\btheta_{t+1}=\btheta_t-\bz_t$}
    \ENDFOR
}
\end{algorithmic}
\end{algorithm}

Once we have the $\bz_t$, we treat them as the gradient of surrogate linear losses.
So, putting it all together, Algorithm~\ref{alg:giftrl} shows the final algorithm.
\citet{ChenO23} prove the following general theorem for it.

%We will use one of the degrees of freedom in the FTRL equality lemma~\cite{Orabona19}. In particular, there will be two different loss functions in the analysis and the lemma will be instantiated with one of them.
%
\begin{theorem}
\label{thm:main}
Let $V\subseteq \R^d$ be closed and non-empty and $\psi_t:V \rightarrow \R$.
With the notation in Algorithm~\ref{alg:giftrl}, define by $F_t(\bx) = \psi_{t}(\bx) + \sum_{i=1}^{t-1} \langle \bz_i, \bx\rangle$, so that $\bx_t \in \argmin_{\bx \in V} \ F_{t}(\bx)$. 
Finally, assume that $\argmin_{\bx \in V} \ F_{t}(\bx)$ and $\partial \ell_t(\bx_t)$ are not empty for all $t$.
%\begin{itemize}
%\vspace{-0.3cm}
%\item
For any $\bz_t \in\R^d$ and any $\bu \in \R^d$, we have
%\begin{align*}
%&\psi^\star_{t+1,V}(\btheta_{t}-\bz_t) + \ell^\star_t(\bz_t) \\
%&\quad \leq \psi^\star_{t+1,V}(\btheta_{t}-\bg_t) + \ell^\star_t(\bg_t) \\
%&\quad = \psi^\star_{t+1,V}(\btheta_{t}-\bg_t) + \langle \bx_t, \bg_t\rangle - \ell_t(\bx_t),
%\end{align*}
%for any $\bg_t \in \partial \ell_t(\bx_t)$.
\begin{align*}
&\Regret_T(\bu) \leq \psi_{T+1}(\bu) - \min_{\bx \in V} \ \psi_{1}(\bx)\\
&\quad +\sum_{t=1}^T [\psi^\star_{t+1,V}(\btheta_{t}-\bg_t) - \psi^\star_{t,V}(\btheta_t) + \langle \bx_t, \bg_t\rangle-\delta_t] \\
&\quad + F_{T+1}(\bx_{T+1}) - F_{T+1}(\bu),
\end{align*}
where $\delta_t \triangleq H_t(\bg_t)-H_t(\bz_t)$.
%\item If $\psi_{t+1}(\bx) \geq \psi_t(\bx)$ for any $\bx \in V$, then, for any $\bz_t \in \R^d$, we have
% \begin{align*}
% &\Regret_T(\bu)\leq\psi_{T+1}(\bu) - \min_{\bx \in V} \ \psi_{1}(\bx)\\
% &\quad   +\sum_{t=1}^T [\psi^\star_{t,V}(\btheta_{t}-\bg_t) - \psi^\star_{t,V}(\btheta_t) + \langle \bx_t, \bg_t\rangle-\delta_t] \\
% &\quad + F_{T+1}(\bx_{T+1}) - F_{T+1}(\bu),
% \end{align*}
% where $\delta'_t \triangleq H'_t(\bg_t)-H'_t(\bz_t)$.
%\end{itemize}
%\vspace{-0.3cm}
\end{theorem}
%
% \begin{proof}
% %Define $\psi_{t,V}\triangleq\psi_t+i_V$, the restriction of $\psi_t$ to $V$.
% The proof is composed of simple but not obvious steps.
% The first important observation is that the definition of $\bx_t$ in the algorithm corresponds exactly to the one of FTRL on the linear losses $\langle \bz_t, \cdot\rangle$. Hence, we can use the FTRL equality in~\citet[Lemma 7.1]{Orabona19}:
% \begin{align*}
% -\sum_{t=1}^T \langle \bz_t,\bu\rangle
% &= \psi_{T+1}(\bu) - \min_{\bx \in V} \ \psi_{1}(\bx) + \sum_{t=1}^T [F_t(\bx_t) \\
% &\quad- F_{t+1}(\bx_{t+1})]  + F_{T+1}(\bx_{T+1}) - F_{T+1}(\bu),
% \end{align*}
% where we have simplified the terms $\langle \bz_t, \bx_t\rangle$ on both sides.
% 
% Now, use Fenchel-Young inequality, to have $\langle \bz_t,\bu\rangle \leq \ell_t(\bu) + \ell_t^\star(\bz_t)$.
% Hence, we have
% \begin{align*}
% -\sum_{t=1}^T \ell_t(\bu)
% &\leq  \sum_{t=1}^T [F_t(\bx_t) - F_{t+1}(\bx_{t+1}) + \ell_t^\star(\bz_t)] \\
% &\quad +\psi_{T+1}(\bu) - \min_{\bx \in V} \ \psi_{1}(\bx) \\
% &\quad + F_{T+1}(\bx_{T+1}) - F_{T+1}(\bu)~.
% \end{align*}
% Observe that 
% \begin{align*}
% F_t(\bx_t) 
% &= \min_{\bx \in V} \ \psi_{t}(\bx) + \sum_{i=1}^{t-1} \langle \bz_i, \bx\rangle\\
% &= - \max_{\bx \in V} \ \langle \btheta_t, \bx\rangle - \psi_{t}(\bx) 
% = - \psi^\star_{t,V}(\btheta_t)~.
% \end{align*}
% In the same way, we have $-F_{t+1}(\bx_{t+1}) = \psi^\star_{t+1,V}(\btheta_{t+1})$.
% Also, for any $\bg_t \in \partial \ell_t(\bx_t)$, by Theorem~\ref{thm:props_fenchel} we have 
% $\ell_t^\star(\bg_t) = \langle \bx_t, \bg_t\rangle - \ell_t(\bx_t)$.
% Hence, each term in the sum can be written as
% \begin{align*}
% &F_t(\bx_t) - F_{t+1}(\bx_{t+1}) + \ell_t^\star(\bz_t) \\
% &\quad = \psi^\star_{t+1,V}(\btheta_{t+1}) - \psi^\star_{t,V}(\btheta_t) + \ell_t^\star(\bz_t)\\
% &\quad = H_t(\bz_t) - \psi^\star_{t,V}(\btheta_t)~.
% \end{align*}
% Now, we just add and subtract $H_t(\bg_t) = \psi^\star_{t+1,V}(\btheta_t - \bg_t) +\langle \bg_t,\bx_t\rangle - \ell_t(\bx_t) $ to obtain the stated bound.
% 
% The second case is similar. We just have to observe that if $\psi_{t+1,V} \geq \psi_{t,V}$, then $\psi^\star_{t+1,V} \leq \psi^\star_{t,V}$.
% Hence, each term in the sum can be upper bounded as
% \begin{align*}
% &F_t(\bx_t) - F_{t+1}(\bx_{t+1}) + \ell_t^\star(\bz_t) \\
% &\quad \leq \psi^\star_{t,V}(\btheta_{t+1}) - \psi^\star_{t,V}(\btheta_t) + \ell_t^\star(\bz_t)\\
% &\quad = H'_t(\bz_t) - \psi^\star_{t,V}(\btheta_t)~.
% \end{align*}
% As before, adding and subtracting $H'_t(\bg_t) = \psi^\star_{t,V}(\btheta_{t}-\bg_t) + \langle \bx_t, \bg_t\rangle - \ell_t(\bx_t)$ gives the stated bound.
% \end{proof}

The Theorem~\ref{thm:main} is stated with very weak assumptions to show its generality, but it is immediate to obtain concrete regret guarantees just assuming, for example, strongly convex regularizers and convex and Lipschitz losses and using well-known methods, such as \citet[Lemma~7.8]{Orabona19}

However, we can already understand why this is an interesting guarantee. Let's first consider the case that $\bz_t=\bg_t$ and the constant regularizer $\frac{1}{2\eta}\|\bx\|^2_2$. In this case, we recover the OGD algorithm. Even the guarantee in the Theorem exactly recovers the best known one~\citep[Corollary 7.9]{Orabona19}, with $\delta_t=0$. 
Instead, if we set $\bz_t$ to be the minimizer of $H_t$, \citet{ChenO23} shows that we recover the implicit/proximal update.
Finally, if we set $\bz_t$ such that $H_t(\bz_t)< H_t(\bg_t)$ we will have that $\delta_t>0$. Hence, in each single term of the sum we have a negative factor that makes the regret bound smaller and we can interpret the resulting update as an \emph{approximate implicit/proximal update}.
%While it might be difficult to give a lower bound to $\delta_t$ and $\delta'_t$ without additional assumptions, the main value of this analysis is in giving a \emph{unifying way to design generalized implicit updates for FTRL}. In the next section we show how to recover IWA.


%\subsection{Comparison with Implicit Online Mirror Descent}
%\label{sec:prox}
%
%In this section, we show that when $\bz_t$ is set to minimize $H_t(\bz)$ or $H'_t(\bz)$, we recover different variants of implicit updates.
%
%Assume that the $\ell_t$ are closed and convex. Also, assume that $\psi^\star_{t,V}$ is differentiable, that is true, for example, when $\psi_t$ is strongly convex by Theorem~\ref{thm:duality}. Then, observe that by the first-order optimality condition and Theorem~\ref{thm:props_fenchel}, we have
%\begin{align}
%\bz_t &= \argmin_{\bz} \ H_t(\bz) \nonumber \\
%&\Leftrightarrow \nabla \psi^\star_{t+1,V}(\btheta_{t}-\bz_t) \in \partial \ell^\star_t(\bz_t) \nonumber \\
%& \Leftrightarrow \bz_t \in  \partial \ell_t(\nabla \psi^\star_{t+1,V}(\btheta_{t}-\bz_t)) 
%= \partial \ell_t(\bx_{t+1})~. \label{eq:cond_update_exact}
%\end{align}
%Hence, in this case, we have that the optimal $\bz_t$ is the gradient at the \emph{next} point $\bx_{t+1}$. This is exactly what happens in the implicit updates. 
%
%Under the same assumptions, we also have
%\begin{align}
%\bz_t = \argmin_{\bz} \ H'_t(\bz) 
%&\Leftrightarrow \nabla \psi^\star_{t,V}(\btheta_{t}-\bz_t) \in \partial \ell^\star_t(\bz_t) \nonumber \\
%& \Leftrightarrow \bz_t \in  \partial \ell_t(\nabla \psi^\star_{t,V}(\btheta_{t+1}))~. \label{eq:cond_update_inexact}
%%= \partial \ell_t(\nabla \psi^\star_{t,V}(\btheta_{t+1}))
%\end{align}
%In this other case, the update also has an implicit flavor but the subgradient is queried on a point different from the next point, where the difference depends on how much $\nabla \psi^\star_{t, V}$ differs from $\nabla \psi^\star_{t+1, V}$.
%
%Let's see this connection even more precisely, considering \emph{proximal updates}.
%Hence, for simplicity, let's consider the case that $V=\R^d$, similar considerations hold in the constrained case.
%Consider the case that $\psi_t(\bx)=\frac{\lambda_t}{2}\|\bx\|_2^2$. In this case, the update can be written with the \emph{proximal operator} of the loss functions. In particular, the proximal operator of $\eta f$, is defined as
%\[
%\Prox_{\eta f}(\by)
%\triangleq \argmin_{\bx \in \R^d} \ \frac{1}{2}\|\bx-\by\|_2^2 + \eta f(\bx)~.
%\]
%If the function $f$ is differentiable we have that $\Prox_{\eta f}(\by) = \by - \eta \nabla f(\Prox_{\eta f}(\by))$. In words, the proximal update moves by a quantity that depends on the gradient on the updated point. The implicit nature of these updates justifies the name ``implicit updates'' used in the online learning literature.
%More generally, we have that $\Prox_{\eta f}(\by) \in \by - \eta \partial f(\Prox_{\eta f}(\by))$. We list some common proximal operators in Appendix~\ref{sec:updates}.
%
%Assuming $\lambda_{t+1}$ does not depend on $\bz_t$, using the proximal operator we can rewrite the update in \eqref{eq:cond_update_exact} as
%%Assume that $\psi_{t+1}(\bx)$ to be strictly convex and not depending on $\bz_t$. In this case we have that the minimizer of the bound satisties
%%\[
%%\boldsymbol{0} \in -\nabla \psi^\star_{t+1}(\theta_t-\bz_t)+ \partial \ell^\star_t(\bz_t)
%%\Leftrightarrow \bz_t \in \partial \ell_t(\bx_{t+1}),
%%\]
%%where we used the assumption that $\ell_t$ is convex, proper, closed. Hence, in this case $\bz_t$ is exactly a subradient of the current loss in the next prediction, exactly as in the implicit updates.
%%Let's consider a particular example: $\psi_t(\bx)=\frac{\lambda_t}{2}\|\bx\|_2^2$.
%\begin{align}
%\bx_{t+1}
%&=\frac{\btheta_{t+1}}{\lambda_{t+1}}
%= \Prox_{\frac{\ell_t}{\lambda_{t+1}}}\left(\frac{\btheta_t}{\lambda_{t+1}}\right) \nonumber \\
%&= \Prox_{\frac{\ell_t}{\lambda_{t+1}}}\left(\frac{\lambda_t \bx_t}{\lambda_{t+1}}\right)~. \label{eq:prox_ftrl_2}
%\end{align}
%%and
%%\begin{align}
%%\bx_{t+1}
%%= \Prox_{\frac{\ell_t}{\lambda_{t+1}}}\left(\frac{\btheta_t}{\lambda_{t+1}}\right)
%%= \Prox_{\frac{\ell_t}{\lambda_{t+1}}}\left(\frac{\lambda_t \bx_t}{\lambda_{t+1}}\right)~. \label{eq:prox_ftrl_2}
%%\end{align}
%
%Similarly, we can rewrite the update in \eqref{eq:cond_update_inexact} as
%\begin{align*}
%\frac{\btheta_{t+1}}{\lambda_t}
%&= \frac{\btheta_{t}}{\lambda_t} - \frac{\bz_t}{\lambda_t}
%= \bx_t - \frac{\bz_t}{\lambda_t}
%\in \bx_t - \frac{1}{\lambda_t}\partial \ell_t(\nabla \psi^\star_{t,V}(\btheta_{t+1})) \\
%&= \bx_t - \frac{1}{\lambda_t}\partial \ell_t\left(\frac{\btheta_{t+1}}{\lambda_t}\right)~.
%\end{align*}
%Hence, we have that $\frac{\btheta_{t+1}}{\lambda_t} = \Prox_{\frac{\ell_t}{\lambda_t}} (\bx_t)$ and we get
%\begin{equation}
%\label{eq:prox_ftrl_1}
%\bx_{t+1}
%= \frac{\btheta_{t+1}}{\lambda_{t+1}} 
%= \frac{\lambda_t}{\lambda_{t+1}}\Prox_{\frac{\ell_t}{\lambda_t}} (\bx_t)~.
%\end{equation}
%
%% Moreover, setting $\tilde{\bx}_{t+1} = \frac{\btheta_t-\bz_t}{\lambda_t} = \bx_t - \frac{\bz_t}{\lambda_t}$, we have that 
%% \begin{equation}
%% \label{eq:less_tight_eq1}
%% \bz_t \in \partial \ell_t(\tilde{\bx}_{t+1})~.
%% \end{equation}
%% Hence, from the monotone property of subgradients, we have
%% \[
%% \langle \bz_t, \tilde{\bx}_{t+1}-\bx_t\rangle \geq \langle \bg_t, \tilde{\bx}_{t+1}-\bx_t\rangle,
%% \]
%% that by Cauchy-Schwarz implies that $\|\bz_t\|_2\leq \|\bg_t\|_2$. If $\ell_t$ is strictly convex, then the inequality between $\|\bg_t\|_2$ and $\|\bz_t\|_2$ is strict. Hence, if the worst-case regret guarantees depends on $\|\bz_t\|_2$, then it will be strictly better than the one that depends on $\bg_t$.
%
%
%It is instructive to compare both updates with the one of Implicit Online Mirror Descent using $\psi(\bx)=\frac{1}{2}\|\bx\|^2_2$ as distance generating function and stepsizes $\frac{1}{\lambda_t}$. In this case, we would update with 
%\begin{align}
%\bx_{t+1} 
%&= \argmin_{\bx} \frac12 \|\bx_t-\bx\|_2^2 + \frac{1}{\lambda_t}\ell_t(\bx) \nonumber \\
%&= \Prox_\frac{\ell_t}{\lambda_t}(\bx_t)~. \label{eq:prox_omd}
%\end{align}
%Comparing \eqref{eq:cond_update_exact} and \eqref{eq:cond_update_inexact} to \eqref{eq:prox_omd}, we see, when $\lambda_t \leq \lambda_{t+1}$ as it is usual, the two updates above shrink a bit towards the zero vector, that is the initial point $\bx_1$, before or after the proximal operator. This shrinking is given by the FTRL update and it is the key difference with 
%Implicit OMD update.
%The different update also corresponds to a different guarantee: the regret of the generalized implicit FTRL holds for unbounded domains too, while in Implicit OMD with time-varying stepsizes can have linear regret on unbounded domains~\citep{OrabonaP18}. Interestingly, a similar shrinking has been proposed in \citet{FangHPF20} to fix the unbounded issue in OMD.
%Clearly, the updates \eqref{eq:cond_update_exact} and \eqref{eq:cond_update_inexact} become equivalent to  \eqref{eq:prox_omd} for $\lambda_t$ constant in $t$, that is exactly the only case when implicit/proximal online mirror descent works for unbounded domains.
