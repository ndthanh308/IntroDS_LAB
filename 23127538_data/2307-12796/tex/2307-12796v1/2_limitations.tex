

\begin{table*}[t]
\small
% \fontsize{8.5}{12}\selectfont
\centering
\caption{Limitations of Existing Collaborative Environments.}
\label{tbl:limitations}
\begin{tabular}{m{2.5cm}m{4.6cm}m{4.6cm}m{4.6cm}}
\hline
\textbf{\begin{tabular}[c]{@{}r@{}} \end{tabular}}
\textbf{Limitation} & \textbf{Google Colab} & \textbf{Code Ocean} & \textbf{Kaggle}                                         \\ \hline

\rowcolor[HTML]{D9D9D9} 
\textbf{\begin{tabular}[c]{@{}l@{}}Resource\\ heterogeneity \end{tabular}} 
& 
CPU, disk, and memory limits; GPU types available; no access to IoT/Edge devices; &
experiments run on AWS virtual machines; no access to IoT/Edge devices; &
limits CPU, GPU, and TPU access; does not support IoT/Edge devices;
\\

\textbf{\begin{tabular}[c]{@{}l@{}}Large-scale\\ experiments\end{tabular}} & 
limits sessions to 12 hours; paid access to multiple computing resources. &
limits access to 10 compute hours; paid access to multiple computing resources. &
limits execution time to 12 hours; paid access to Google Cloud Services.
\\
\rowcolor[HTML]{D9D9D9} 
\textbf{\begin{tabular}[c]{@{}l@{}}Repeatability, \\Reproducibility, \\Replicability \end{tabular}} & 
hard to repeat and reproduce experiments on the same hardware: resource availability varies over time and usage limits fluctuate. Replicability in different infrastructures (\emph{e.g.,} beyond Google machines) is not straightforward. 
&
lacks support for the reproducibility of distributed experiments. Computing and storage resources are available in AWS virtual machines in the clients virtual private cloud. Hard to replicate experiments in different infrastructures.
&
lacks support for the repeatability and reproducibility of distributed experiments. Computing resources vary over time and hence between accesses. Replicability in different infrastructures is not easy to set up.  
\\ \hline
\end{tabular}
\end{table*}


We briefly discuss the limitations of state-of-the-art collaborative environments, with a focus on the specific challenges of the Computing Continuum.



\paragraph{\textbf{Google Colab~\cite{colab}}} 
Mainly used by the AI community (more than 50K users), it is a ready-to-use Jupyter notebook service. Colab notebooks are stored in the \emph{.ipynb} open-source Jupyter notebook format~\cite{colab-faq}, and come with the most popular AI libraries and frameworks installed (\emph{e.g.,} Scikit-Learn~\cite{pedregosa2011scikit}, TensorFlow~\cite{abadi2016tensorflow}, PyTorch~\cite{paszke2019pytorch}, \emph{etc.}) and allow users to run python code through the browser. It is typically used for machine learning, data analysis and education. Colab is popular because it allows users to share Jupyter notebooks without having to download, install, or run anything. Besdides, it provides free access to very expensive computing resources such as GPUs and TPUs. Colab permits multiple users to collaborate on the same notebook. Sharing datasets, ML models, pipelines, and notebooks on AI Hub~\cite{aihub} is also possible (more than 167 notebooks). Its GitHub integration allows users to quickly open GitHub-hosted Jupyter notebooks in Google Colab.



\paragraph{\textbf{Kaggle~\cite{kaggle}}} 
This is a data science and AI platform that offers a customizable Jupyter notebook environment. Kaggle is a subsidiary of Google and, like Colab, it provides free access to GPUs as well as a repository of community-published (more than 10.3 million users) datasets (more than 50K public datasets) and code (\emph{e.g.,} machine learning code) with more than 400K public notebooks. Kaggle is integrated with AI Hub and is popular in the data science and machine learning communities. Kaggle is also well-known for promoting Community Competitions in machine learning at no cost. The main differences~\cite{kaggle-vs-colab} between Colab and Kaggle are: (1) Kaggle allows collaboration with other users on its Web site, while Colab allows collaboration with anyone using the notebook link; (2) Kaggle has a lot of data sets that users can use directly (\emph{e.g.,} notebooks already set up with Kaggle databases~\cite{kaggle-datasets}), while in Colab setting up notebooks with Google Drive~\cite{colab-drive} or managing files~\cite{gsutil-tool} (\emph{e.g.,} to load data sets, files, and images) requires extra work; and (3) Kaggle creates a history of notebook commits that we can  be reviewed.



\paragraph{\textbf{Code Ocean~\cite{clyburne2019computational}}} 
Designed according to FAIR~\cite{wilkinson2016fair} (\emph{i.e.,} Findable, Accessible, Interoperable, and Reusable), Code Ocean aims to make scientific work reproducible. It introduces the concept of Compute Capsule, which refers to Docker~\cite{docker} containers composed of code, data, environments, and results. Capsules provide ready-to-use tools such as Git, Jupyter, RStudio, among others. Its integration with Git allows users to save changes on capsules and then commit them with just one click. Furthermore, users can easily share the link of a capsule and grant permissions. Code Ocean provides scalable compute and storage resources hosted on Amazon Web Services. Resources used by capsules are scaled out when the demand exceeds the machine capacity. Finally, Code Ocean provides a public Capsule Repository~\cite{code-ocean} with more than 1K research capsules. It allows authors of an article to incorporate capsules into the submission process via a Hub publishing API.


\begin{framed}
\vspace{-0.1cm}

Despite these systems being widely used by the AI and data science communities, they present some limitations that hinder their adoption for Computing Continuum research. Table~\ref{tbl:limitations} summarizes these limitations in terms of: 

\begin{enumerate}
    \item access to heterogeneous computing resources, from the IoT/Edge to the Cloud/HPC;
    \item support for large-scale experimental evaluations;
    \item repeatability and reproducibility of experiments on the same hardware setup, and replicability on different infrastructures.
\end{enumerate}

In summary, collaborative environments lack support for providing access to heterogeneous resources (\emph{e.g.,} Edge-to-Cloud); performing experiments at large-scale; and achieving the repeatability, reproducibility, and the replicability of experiments in different testbeds. Hence, the need for novel approaches for reproducible evaluations of workflows targeting the characteristics of the Computing Continuum. 
%Novel systems must support  deployed on the complex Edge-to-Cloud Continuum.

\vspace{-0.1cm}
\end{framed}
