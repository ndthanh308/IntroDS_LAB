% Figure environment removed




This section introduces KheOps, a collaborative environment for the cost-effective reproducibility and replicability of Edge-to-Cloud experiments. KheOps is designed to meet the experimental requirements of both authors and readers as presented in Section~\ref{sec:introduction}. 



\subsection{Architecture and implementation}
\label{subsec:kheops_arch_impl}




Figure~\ref{fig:kheops-archi} presents the architecture of KheOps, which consists of three main components: \emph{(i)} Trovi sharing portal; \emph{(ii)} Jupyter environment (JupyterHub service and JupyterLab server); and \emph{(iii)} E2Clab framework (multi-platform experiment methodology). Next, present the integration details of KheOps three components, and we briefly describe their main roles.

% Figure environment removed



% Figure environment removed








\subsubsection{Experiment repository} KheOps uses Trovi to share research artifacts such as packaged experiments. These artifacts may be publicly available to allow others to recreate and rerun experiments. Trovi provides a REST API to manage experiment artifacts and integrate them with other systems. The JupyterHub in KheOps uses the Trovi REST API to download artifacts and launch them in the JupyterLab server. 

Artifacts hosted in Trovi can also provide references to repositories like container registries (\emph{e.g.,} DockerHub~\cite{dockerhub}), multipurpose repositories (\emph{e.g.,} Zenodo~\cite{zenodo}), code repositories (\emph{e.g.,} Github~\cite{github}), and among others.

\subsubsection{Notebook environment} Following our previous work~\cite{anderson2019case} on integrating experiment workflows with Jupyter notebooks, we extend JupyterHub to authenticate users and to download (using the Trovi REST API) the experiment artifacts available at Trovi. We also extend JupyterLab to allow users to easily share their experiments in Trovi. Furthermore, JupyterLab is set up with the E2Clab framework as an experimental methodology.

The JupyterLab is packaged with code, data, environment configurations, and experiment results. Its notebooks (file extension \textit{.ipynb}) allow users to run experiments step-by-step by combining text (\emph{e.g.,} explaining the reasoning of the experiments: \emph{What} parameters? \emph{Why} these parameters? and \emph{How} it was set up?) with executable code. Such notebooks are ready to use (\emph{e.g.,} installed with required library/software), executed through a browser, and shared as a Trovi artifact.


\subsubsection{Multi-testbed experiment methodology} KheOps uses the E2Clab methodology to deploy experiments on large-scale scientific testbeds such as Grid'5000, Chameleon Cloud, CHI@Edge, and FIT IoT LAB. Notebooks come with three main template files (\emph{e.g.,} executable code cells in the notebook, presented in Listings~\ref{lis-e2c-layers} to~\ref{lis-e2c-workflow}) that users can benefit from to easily configure and adapt the deployment logic (\emph{e.g.,} computing resources, network, and application execution) according to their experimental needs. 

The first file, named \emph{layers\_services.yaml} and presented in Listing~\ref{lis-e2c-layers}, allows users to lease IoT/Edge and Cloud/HPC resources. Through this file, users may also set up their applications and services as presented in Listing~\ref{lis-e2c-svc}. Next, the \emph{network.yaml} file (Listing~\ref{lis-e2c-net}) allows users to define delay, loss, and bandwidth between computing resources. Finally, the \emph{workflow.yaml} file (Listing~\ref{lis-e2c-workflow}) guides users to define the experiment workflow through three main steps: \emph{prepare} (\emph{e.g.,} copy artifacts to remote nodes, install libraries, \emph{etc.}), \emph{launch} (\emph{e.g.,} execute the application parts), and \emph{finalize} (\emph{e.g.,} backup results from remote nodes to the JupyterLab server).

E2Clab abstracts all the complexities of deploying and executing experiments across various testbeds. To do so, users need to add the credential files of the respective testbeds to their notebooks. Setting up a VPN is also supported as this may be required to enable the communication between different geographically distributed tesbeds (\emph{e.g.,} Chameleon in the USA and Grid'5000 in France).







% Figure environment removed



\subsection{Experimental workflow}
\label{subsec:kheops_workflow}

In summary, the workflow for launching an experiment artifact on large-scale testbeds consists of 5 main steps. First, through a web interface, users can browse the list of experimental artifacts publicly available in Trovi (step 1). Selecting an artifact displays details such as the experiment description, the authors and contact information, and the artifact versions. 

A \emph{launch} button allows users to execute the artifact (step 2). This button redirects users to the JupyterHub service. After authentication, the request to launch the artifact is sent to the JupyterHub Spawner. Next, the Spawner spawns the JupyterLab server (step 3)  and then it downloads experimental artifacts such as notebooks, code, and datasets, among others (step 4). The JupyterLab service is set up with the E2Clab framework as the experimental methodology. Finally, users can execute the code cells from the notebook to lease IoT/Edge and Cloud/HPC computing resources available on the testbeds, deploy and execute the application, and gather the experiment results (step 5).


% Figure environment removed




Steps 2 to 4 are automatically executed. This is a one-click feature that allows users to have a ready-to-use environment for reproducing and replicating complex Edge-to-Cloud experiments in a cost-effective manner. Note that the whole workflow requires only three clicks: selecting the experiment artifact (step 1); then launching it (steps 2 to 4); and executing it on the testbeds (step 5).  


