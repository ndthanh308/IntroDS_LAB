\section{Introduction}

Medical image segmentation often relies on supervised model training \cite{nnunet}, but this approach has limitations. Firstly, it requires costly manual annotations. Secondly, the resulting models may not generalize well to unseen data domains. Even small changes in the task may result in a significant drop in performance, requiring re-training from scratch \cite{kondrateva2022neglectable}.

Self-supervised learning (SSL) is a promising solution to these limitations. SSL pre-trains a model backbone to extract informative representations from unlabeled data. Then, a simple linear or non-linear head on top of the frozen pre-trained backbone can be trained for various downstream tasks in a supervised manner (linear or non-linear probing). Alternatively, the backbone can be fine-tuned for a downstream task along with the head. Pre-training the backbone in a self-supervised manner enables scaling to larger datasets across multiple data and task domains. In medical imaging, this is particularly useful given the growing number of available datasets.

In this work, we focus on contrastive learning \cite{contrastive,simclr}, one of the most effective approaches to SSL in computer vision. 
In contrastive learning, the model is trained to produce similar vector representations for augmented views of the same image and dissimilar representations for different images. Contrastive methods can also be used to learn dense, i.e., patch-level or even pixel- or voxel-level representations: pixels of augmented image views from the same region of the original image should have similar representations, while different pixels should have dissimilar ones \cite{vader}.

Several works have implemented contrastive learning of dense representations in medical imaging \cite{3d_ssl,global_and_local,transvw,swin_unetr,sam}. Representations in \cite{3d_ssl,global_and_local} do not resolve nearby voxels due to the negative sampling strategy and the architectural reasons. This makes them unsuitable for full-resolution segmentation, especially in linear and non-linear probing regimes. In the current SotA dense SSL methods \cite{transvw,swin_unetr}, authors employ restorative learning in addition to patch-level contrastive learning, in order to pre-train voxel-level representations in full-resolution. In \cite{sam}, separate global and voxel-wise representations are learned in a contrastive manner to implement efficient dense image retrieval. 

The common weakness of all the above works is that they do not evaluate their SSL models in linear or non-linear probing setups, even though these setups are de-facto standards for evaluation of SSL methods in natural images \cite{simclr,mae,vader}. Moreover, fine-tuned models can deviate drastically from their pre-trained states due to catastrophical forgetting \cite{catastrophic}, while models trained in linear or non-linear probing regimes are more robust as they have several orders of magnitude fewer trainable parameters.

Our contributions are threefold. \textbf{First}, we propose \texttt{vox2vec}, a framework for contrastive learning of voxel-level representations. Our simple negative sampling strategy and the idea of storing voxel-level representations in a feature pyramid form result in high-dimensional, fine-grained, multi-scale representations suitable for the segmentation of different organs and tumors in full resolution. \textbf{Second}, we employ \texttt{vox2vec} to pre-train a FPN architecture on a diverse collection of six unannotated datasets, totaling over 6,500 CT images of the thorax and abdomen. We make the pre-trained model publicly available to simplify the reproduction of our results and to encourage practitioners to utilize this model as a starting point for the segmentation algorithms training. \textbf{Finally}, we compare the pre-trained model with the baselines on 22 segmentation tasks on seven CT datasets in three setups: linear probing, non-linear probing, and fine-tuning. We show that \texttt{vox2vec} performs slightly better than SotA models in the fine-tuning setup and outperforms them by a huge margin in the linear and non-linear probing setups. To the best of our knowledge, this is the first successful attempt to evaluate dense SSL methods in the medical imaging domain in linear and non-linear probing regimes.
