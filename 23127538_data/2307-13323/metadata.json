{
  "title": "Learning Autonomous Ultrasound via Latent Task Representation and Robotic Skills Adaptation",
  "authors": [
    "Xutian Deng",
    "Junnan Jiang",
    "Wen Cheng",
    "Miao Li"
  ],
  "submission_date": "2023-07-25T08:32:36+00:00",
  "revised_dates": [],
  "abstract": "As medical ultrasound is becoming a prevailing examination approach nowadays, robotic ultrasound systems can facilitate the scanning process and prevent professional sonographers from repetitive and tedious work. Despite the recent progress, it is still a challenge to enable robots to autonomously accomplish the ultrasound examination, which is largely due to the lack of a proper task representation method, and also an adaptation approach to generalize learned skills across different patients. To solve these problems, we propose the latent task representation and the robotic skills adaptation for autonomous ultrasound in this paper. During the offline stage, the multimodal ultrasound skills are merged and encapsulated into a low-dimensional probability model through a fully self-supervised framework, which takes clinically demonstrated ultrasound images, probe orientations, and contact forces into account. During the online stage, the probability model will select and evaluate the optimal prediction. For unstable singularities, the adaptive optimizer fine-tunes them to near and stable predictions in high-confidence regions. Experimental results show that the proposed approach can generate complex ultrasound strategies for diverse populations and achieve significantly better quantitative results than our previous method.",
  "categories": [
    "cs.RO",
    "cs.AI"
  ],
  "primary_category": "cs.RO",
  "doi": null,
  "journal_ref": null,
  "arxiv_id": "2307.13323",
  "pdf_url": null,
  "comment": null,
  "num_versions": null,
  "size_before_bytes": 8966360,
  "size_after_bytes": 247380
}