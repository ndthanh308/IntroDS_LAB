% Version 1.2 of SN LaTeX, November 2022
%
% See section 11 of the User Manual for version history 
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                                                 %%
%% Please do not use \input{...} to include other tex files.       %%
%% Submit your LaTeX manuscript as one .tex document.              %%
%%                                                                 %%
%% All additional figures and files should be attached             %%
%% separately and not embedded in the \TeX\ document itself.       %%
%%                                                                 %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%\documentclass[referee,sn-basic]{sn-jnl}% referee option is meant for double line spacing

%%=======================================================%%
%% to print line numbers in the margin use lineno option %%
%%=======================================================%%

%%\documentclass[lineno,sn-basic]{sn-jnl}% Basic Springer Nature Reference Style/Chemistry Reference Style

%%======================================================%%
%% to compile with pdflatex/xelatex use pdflatex option %%
%%======================================================%%

%%\documentclass[pdflatex,sn-basic]{sn-jnl}% Basic Springer Nature Reference Style/Chemistry Reference Style


%%Note: the following reference styles support Namedate and Numbered referencing. By default the style follows the most common style. To switch between the options you can add or remove Numbered in the optional parenthesis. 
%%The option is available for: sn-basic.bst, sn-vancouver.bst, sn-chicago.bst, sn-mathphys.bst. %  
 
%%\documentclass[sn-nature]{sn-jnl}% Style for submissions to Nature Portfolio journals
\documentclass[sn-basic,Numbered]{sn-jnl}% Basic Springer Nature Reference Style/Chemistry Reference Style
%%\documentclass[sn-mathphys,Numbered]{sn-jnl}% Math and Physical Sciences Reference Style
%%\documentclass[sn-aps]{sn-jnl}% American Physical Society (APS) Reference Style
%%\documentclass[sn-vancouver,Numbered]{sn-jnl}% Vancouver Reference Style
%%\documentclass[sn-apa]{sn-jnl}% APA Reference Style 
%%\documentclass[sn-chicago]{sn-jnl}% Chicago-based Humanities Reference Style
%%\documentclass[default]{sn-jnl}% Default
%%\documentclass[default,iicol]{sn-jnl}% Default with double column layout

%%%% Standard Packages
%%<additional latex packages if required can be included here>

\usepackage{graphicx}%
\usepackage{multirow}%
\usepackage{amsmath,amssymb,amsfonts}%
\usepackage{amsthm}%
\usepackage{mathrsfs}%
\usepackage[title]{appendix}%
\usepackage{xcolor}%
\usepackage{textcomp}%
\usepackage{manyfoot}%
\usepackage{booktabs}%
\usepackage{algorithm}%
\usepackage{algorithmicx}%
\usepackage{algpseudocode}%
\usepackage{listings}%
%%%%

%%%%%=============================================================================%%%%
%%%%  Remarks: This template is provided to aid authors with the preparation
%%%%  of original research articles intended for submission to journals published 
%%%%  by Springer Nature. The guidance has been prepared in partnership with 
%%%%  production teams to conform to Springer Nature technical requirements. 
%%%%  Editorial and presentation requirements differ among journal portfolios and 
%%%%  research disciplines. You may find sections in this template are irrelevant 
%%%%  to your work and are empowered to omit any such section if allowed by the 
%%%%  journal you intend to submit to. The submission guidelines and policies 
%%%%  of the journal take precedence. A detailed User Manual is available in the 
%%%%  template package for technical guidance.
%%%%%=============================================================================%%%%

%\jyear{2021}%

%% as per the requirement new theorem styles can be included as shown below
\theoremstyle{thmstyleone}%
\newtheorem{theorem}{Theorem}%  meant for continuous numbers
%%\newtheorem{theorem}{Theorem}[section]% meant for sectionwise numbers
%% optional argument [theorem] produces theorem numbering sequence instead of independent numbers for Proposition
\newtheorem{proposition}[theorem]{Proposition}% 
%%\newtheorem{proposition}{Proposition}% to get separate numbers for theorem and proposition etc.

\theoremstyle{thmstyletwo}%
\newtheorem{example}{Example}%
\newtheorem{remark}{Remark}%

\theoremstyle{thmstylethree}%
\newtheorem{definition}{Definition}%

\raggedbottom
%%\unnumbered% uncomment this for unnumbered level heads

%------------------------- Text Count -----------------------------
\usepackage{verbatim}
%TC:group table 0 1
%TC:group tabular 1 1
\newcommand{\detailtexcount}[1]{%
  \immediate\write18{texcount -merge -sum -q sn-article.tex sn-bibliography.bib > sn-article.wcdetail }%
  \verbatiminput{sn-article.wcdetail}%
}

\newcommand{\quickwordcount}[1]{%
  \immediate\write18{texcount -1 -sum -merge -q sn-article.tex sn-bibliography.bib > sn-article-words.sum }%
  \input{sn-article-words.sum} words%
}

\newcommand{\quickcharcount}[1]{%
  \immediate\write18{texcount -1 -sum -merge -char -q sn-article.tex sn-bibliography.bib > sn-article-chars.sum }%
  \input{sn-article-chars.sum} characters (not including spaces)%
}

%---------------------------------------------------------------- -

\begin{document}

\title[Bayesian Active Learning in MSK Segmentation]{Hybrid Representation-Enhanced Sampling for Bayesian Active Learning in Musculoskeletal Segmentation of Lower Extremities}

%%=============================================================%%
%% Prefix	-> \pfx{Dr}
%% GivenName	-> \fnm{Joergen W.}
%% Particle	-> \spfx{van der} -> surname prefix
%% FamilyName	-> \sur{Ploeg}
%% Suffix	-> \sfx{IV}
%% NatureName	-> \tanm{Poet Laureate} -> Title after name
%% Degrees	-> \dgr{MSc, PhD}
%% \author*[1,2]{\pfx{Dr} \fnm{Joergen W.} \spfx{van der} \sur{Ploeg} \sfx{IV} \tanm{Poet Laureate} 
%%                 \dgr{MSc, PhD}}\email{iauthor@gmail.com}
%%=============================================================%%

\author*[1]{\fnm{Ganping} \sur{Li}}\email{li.ganping.lc2@is.naist.jp}

\author[1]{\fnm{Yoshito} \sur{Otake}}\email{otake@is.naist.jp}

\author[1]{\fnm{Mazen} \sur{Soufi}} \email{msoufi@is.naist.jp}

\author[2]{\fnm{Masashi} \sur{Taniguchi}}\email{taniguchi.masashi.7a@kyoto-u.ac.jp}

\author[2]{\fnm{Masahide} \sur{Yagi}}\email{yagi.masahide.5s@kyoto-u.ac.jp}

\author[2]{\fnm{Noriaki} \sur{Ichihashi}}\email{ichihashi.noriaki.5z@kyoto-u.ac.jp}

\author[3]{\fnm{Keisuke} \sur{Uemura}}\email{surmountjp@gmail.com}

\author[4]{\fnm{Masaki} \sur{Takao}}\email{takao.masaki.ti@ehime-u.ac.jp}

\author[3]{\fnm{Nobuhiko} \sur{Sugano}}\email{n-sugano@umin.net}

\author[1]{\fnm{Yoshinobu} \sur{Sato}}\email{yoshi@is.naist.jp}


\affil*[1]{\orgdiv{Division of Information Science, Graduate School of Science and Technology}, \orgname{Nara Institute of Science and Technology}, \orgaddress{\street{8916-5 Takayama}, \city{Ikoma}, \postcode{630-0192}, \state{Nara}, \country{Japan}}}

\affil[2]{\orgdiv{Human Health Sciences, Graduate School of Medicine}, \orgname{Kyoto University}, \orgaddress{\street{53-Kawahara-cho, Shogoin}, \city{Sakyo-ku}, \postcode{606-8507}, \state{Kyoto}, \country{Japan}}}

\affil[3]{\orgdiv{Department of Orthopedic Surgery, Osaka University Graduate School of Medicine}, \orgname{Osaka University}, \orgaddress{\street{2-2 Yamadaoka}, \city{Suita}, \postcode{565-0871}, \state{Osaka}, \country{Japan}}}

\affil[4]{\orgdiv{Department of Bone and Joint Surgery, School of Medicine}, \orgname{Ehime University}, \orgaddress{\street{454 Shitsugawa}, \city{Toon}, \postcode{791-0295}, \state{Ehime}, \country{Japan}}}

%------------------------- Text Count -------------------------------
% Don't count these!
% TC:ignore
% \quickwordcount{sn-article}
% \quickcharcount{sn-article}
% \detailtexcount{sn-article}
% TC:endignore

%--------------------------------------------------------------------

%%==================================%%
%% sample for unstructured abstract %%
%%==================================%%

\abstract{Purpose: Obtaining manual annotations to train deep learning (DL) models for auto-segmentation is often time-consuming. Uncertainty-based Bayesian active learning (BAL) is a widely-adopted method to reduce annotation efforts. Based on BAL, this study introduces a hybrid representation-enhanced sampling strategy that integrates density and diversity criteria to save manual annotation costs by efficiently selecting the most informative samples.

Methods: The experiments are performed on two lower extremity (LE) datasets of MRI and CT images by a BAL framework based on Bayesian U-net. Our method selects uncertain samples with high density and diversity for manual revision, optimizing for maximal similarity to unlabeled instances and minimal similarity to existing training data. We assess the accuracy and efficiency using Dice and a proposed metric called reduced annotation cost (RAC), respectively. We further evaluate the impact of various acquisition rules on BAL performance and design an ablation study for effectiveness estimation.

Results: The proposed method showed superiority or non-inferiority to other methods on both datasets across two acquisition rules, and quantitative results reveal the pros and cons of the acquisition rules. Our ablation study in volume-wise acquisition shows that the combination of density and diversity criteria outperforms solely using either of them in musculoskeletal segmentation.

Conclusion: Our sampling method is proven efficient in reducing annotation costs in image segmentation tasks. The combination of the proposed method and our BAL framework provides a semi-automatic way for efficient annotation of medical image datasets.}

%%================================%%
%% Sample for structured abstract %%
%%================================%%

% \abstract{\textbf{Purpose:} The abstract serves both as a general introduction to the topic and as a brief, non-technical summary of the main results and their implications. The abstract must not include subheadings (unless expressly permitted in the journal's Instructions to Authors), equations or citations. As a guide the abstract should not exceed 200 words. Most journals do not set a hard limit however authors are advised to check the author instructions for the journal they are submitting to.
% 
% \textbf{Methods:} The abstract serves both as a general introduction to the topic and as a brief, non-technical summary of the main results and their implications. The abstract must not include subheadings (unless expressly permitted in the journal's Instructions to Authors), equations or citations. As a guide the abstract should not exceed 200 words. Most journals do not set a hard limit however authors are advised to check the author instructions for the journal they are submitting to.
% 
% \textbf{Results:} The abstract serves both as a general introduction to the topic and as a brief, non-technical summary of the main results and their implications. The abstract must not include subheadings (unless expressly permitted in the journal's Instructions to Authors), equations or citations. As a guide the abstract should not exceed 200 words. Most journals do not set a hard limit however authors are advised to check the author instructions for the journal they are submitting to.
% 
% \textbf{Conclusion:} The abstract serves both as a general introduction to the topic and as a brief, non-technical summary of the main results and their implications. The abstract must not include subheadings (unless expressly permitted in the journal's Instructions to Authors), equations or citations. As a guide the abstract should not exceed 200 words. Most journals do not set a hard limit however authors are advised to check the author instructions for the journal they are submitting to.}

\keywords{Active learning, Bayesian deep learning, Image segmentation, Bayesian Uncertainty}

%%\pacs[JEL Classification]{D8, H51}

%%\pacs[MSC Classification]{35A01, 65L10, 65L12, 65L20, 65L70}

\maketitle

\section{Introduction}\label{sec1}

Medical image segmentation is crucial in extracting quantitative imaging markers for better observations of anatomical or pathological structure changes to improve medical diagnosis and treatment \cite{ogawa2020validation, yagi2022age}. However, obtaining manual annotations for training deep learning (DL) models is often time-consuming, resulting in insufficient model performance \cite{sourati2018active}. Active learning (AL) is a widely-adopted approach to address the above-mentioned issue \cite{settles2008analysis}. The method is regarded as a training schema that reduces annotation effort by sequentially annotating the most informative instances. It involves iterative steps where an AL framework selects a batch of samples from an unlabeled pool to be manually annotated by annotators and subsequently added to the training pool. Afterward, a new model is trained on the updated training pool, superseding the previous model in the framework. Though many recent studies have proposed competitive strategies to address the issue, the best sampling policy is still a matter of debate \cite{budd2021survey}. 

Prior AL approaches focus on selecting samples with high model uncertainty \cite{gal2016dropout,gal2017deep,lakshminarayanan2017simple}, which is called uncertainty-based sampling. Among the uncertain samples, two criteria have been used for further selection \cite{yang2017suggestive,hiasa2019automated, ozdemir2021active, smailagic2018medal, nath2020diminishing}. One criterion \cite{yang2017suggestive,hiasa2019automated} seeks to select representative samples of high-density dominant classes in data distribution by maximizing their similarity to the unlabeled data. Alternatively, the others \cite{smailagic2018medal,nath2020diminishing} select samples minimizing the similarity between the chosen samples and the existing labeled data, ensuring diversity and less redundancy. Although the two criteria of density and diversity have been integrated for classification tasks in both medical and non-medical fields \cite{liu2022survey}, to the best of our knowledge, no existing work has applied this integration to medical image segmentation.

In this study, we introduce an AL scheme incorporating the two criteria above to ensure the chosen samples' representativeness and the labeled data's diversity. In order to further identify the informative instances, we implement a Bayesian active learning (BAL) framework based on Bayesian U-net \cite{hiasa2019automated} for uncertainty estimation and sampling. Since CT and MR data typically consist of volumetric (3D) images, volume-wise sample acquisition is preferable. However, the investigation of AL characteristics in volume-wise acquisition remains inadequate as prior research has mainly addressed slice (2D image)-wise acquisition, except for \cite{nath2020diminishing, ozdemir2021active}. Therefore, our proposed approach will be assessed in the volume-wise acquisition in addition to the slice-wise one. In brief, our contributions can be summarized as follows:

\begin{quote}
    \begin{itemize}
        \item We proposed a hybrid representation-enhanced sampling strategy that integrates similarity measures to detect high-density samples while ensuring diversity and less redundancy. The method is adopted to a BAL framework to prioritize both uncertainty and representativeness of the queried samples for medical image segmentation.
        \item We validate our method on two lower extremity (LE) image datasets of MRI and CT, and further estimated the impact of the volume-wise acquisition in addition to the slice-wise on BAL performance and annotation efficiency, addressing the insufficiency in previous works.
    \end{itemize}
\end{quote}

\section{Related work}\label{sec2}

\subsection{Uncertainty-based sampling}\label{subsec1}
Uncertainty-based sampling assesses a sample's informativeness by measuring the uncertainty of a trained DL model's prediction, where a higher uncertainty indicates greater informativeness. Gal et al. \cite{gal2016dropout,gal2017deep} introduced a prevalent implementation to approximate Bayesian inference using Monte Carlo (MC) dropouts. The method efficiently estimates model uncertainty by measuring each test sample's degree of difference and identifying the training data's deficiency at the inference step \cite{hiasa2019automated}. Nevertheless, given that a model in an early stage of AL tends to be uncertain for similar types of instances, relying solely on uncertainty approaches may skew the model to focus on a particular area of the data distribution within the target domain.

\subsection{Representativeness-based sampling}\label{subsec2}
Representativeness-based sampling is widely employed with uncertainty approaches \cite{budd2021survey} in medical analysis, mainly grouped by density-based and diversity-based approaches. As a typical density method, Yang et al. \cite{yang2017suggestive} utilized similarity measures to select dense samples that offer the most comprehensive representation of the unlabeled pool with a step-by-step optimization. In \cite{ozdemir2021active}, a variational autoencoder (VAE)-based density sampling was proposed for the same purpose, although it requires an auxiliary model. These methods, however, might skew the training pool by selecting only the majority when handling an imbalanced dataset, especially in the early iterations. In order to tackle this challenge, diversity-based approaches have been proposed. Smailagic et al. \cite{smailagic2018medal} quantified the dissimilarity between feature maps of the chosen samples and the training pool, intending to maximize this dissimilarity. Then, Nath et al. \cite{nath2020diminishing} adopted mutual information as a regularizer to ensure diversity in training data with a similar aim. However, solely maximizing diversity may result in querying outliers. Thus, developing a hybrid sampling strategy that maximizes the density and diversity of the training data would be necessary.

\section{Materials and methods}\label{sec3}

\subsection{Dataset}\label{subsec3}

% Figure environment removed

We gathered and annotated two LE datasets (Fig. \ref{fig1}) used in our studies; 1) a T-1 weighted MRI dataset with four quadriceps muscles annotated \cite{fukumoto2022influence} and 2) a CT dataset with 22 musculoskeletal structures (19 muscles and 3 bones) annotated. Notice that the manual labels of the unlabeled pool were used for evaluation only.

1) MRI dataset: The dataset contained 119 volumes (21490 axial slices) of 82 elders ($>60$ years) and 37 youths (20-39 years) with manual annotation of four quadriceps muscles (Rectus femoris, Vastus lateralis, Vastus intermedius, and Vastus medialis) by annotators. Each MR volume contains 163 to 201 (182 on average) slices. The images were resized to $256\times256\times n$ with voxel spacing from $[0.5, 0.5, 4]$ mm to $[1, 1, 4]$ mm, and normalized from $[0, 1000]$ to $[0, 1]$. The dataset was then divided into 1/89/9/20 for the training/unlabeled pool/validation/testing for initialization of all AL experiments.

2) CT dataset: This dataset consisted of 30 CT volumes (17909 axial slices) labeled with 22 musculoskeletal structures (19 muscles and 3 bones). Each CT volume contained 526 to 700 (599 on average) slices with a matrix size of $512\times512$. We resized the images to $256\times256\times n$ with voxel spacing of $[1.4, 1.4, 1]$ mm, normalized them from $[-150, 350]$ to $[0, 1]$, and divided the dataset into 1/24/1/4 for the training/unlabeled pool/validation/testing.

\subsection{Sampling techniques}\label{subsec4}
In this section, we present sampling techniques employed within our BAL framework. We start by introducing uncertainty sampling to select the most uncertain samples. Next, we incorporate a hybrid scoring approach designed to select high-density and diverse samples from the uncertain subset, thereby ensuring representativeness among the unlabeled data.

\textbf{Bayesian uncertainty sampling.}
Our uncertainty estimation step follows the method described in \cite{hiasa2019automated}, which investigates the model uncertainty in a scalable manner by the approximate Bayesian inference of predictive distributions (details shown in Online Resource 1.1). We implemented a dropout-based Bayesian U-net for multi-class segmentation and uncertainty estimation, where an average uncertainty for each class is defined by
\begin{equation}\label{eq1}
    m_{unc}(y=l) = \frac{1}{N}\sum\limits_{n=1}^{N}\text{var}[p(y=l\mid x, \Theta_{t})^{(n)}]
\end{equation}
where $N$ is the number of pixels of input $x$ and var$[p(y=l\mid x, \Theta_{t})^{(n)}]$ indicates the prediction variance under $T$ times Bayesian inference at pixel $n$. The equation above is cited and summarized from \cite{ozdemir2021active}. 

\textbf{Hybrid representation-enhanced sampling.}
We introduce a hybrid scoring approach to select high-density samples following the method described in \cite{yang2017suggestive,hiasa2019automated} with a constraint to maintain diversity \cite{nath2020diminishing}. 

Given an unlabeled pool $\mathcal{D}_u$, a training pool $\mathcal{D}_t$, and a subset of uncertain images $\mathcal{D}_{c}\subseteq\mathcal{D}_{u}$, the algorithm first measures the norm of cosine similarity $norm(sim(I_{i}^{c}, I_{j}^{u}))$ between $\mathcal{D}_{c}$ and $\mathcal{D}_{u}$ for representative samples, where $I_{i}^{c}$ and $I_{j}^{u}$ are the $i^{th}$ and $j^{th}$ images from $\mathcal{D}_{c}$ and $\mathcal{D}_{u}$, respectively. Next, a regularization term of the mutual information's norm $norm(mi(I_{i}^{c}, I_{k}^{t}))$ between $\mathcal{D}_{c}$ and $\mathcal{D}_{t}$ minimizes the redundancy in the training pool $\mathcal{D}_{t}$ while encouraging minority samples. Overall, we select samples maximizing
\begin{equation}\label{eq2}
    m_{repr} = \underbrace{norm(sim(\mathcal{D}_{c}, \mathcal{D}_{u}))}_\text{density module} - \lambda\cdot\underbrace{norm(mi(\mathcal{D}_{c}, \mathcal{D}_{t}))}_\text{diversity module}
\end{equation}
where hyper-parameter $\lambda$ determines the balance between the density and diversity of the chosen samples. The top-$k$ samples will then be annotated and added to the training pool $\mathcal{D}_{t}$. Details of the step-by-step optimization algorithm extended from \cite{hiasa2019automated, nath2020diminishing} are demonstrated in Online Resource 1.2.

\subsection{Bayesian active learning}\label{subsec6}
We present a BAL framework for medical image segmentation to validate the proposed method, as illustrated in Fig. \ref{fig2} (a). Starting with a Bayesian U-net trained on a limited number of labeled data, our schema iteratively selects uncertain and representative samples, revises them by annotators, and incorporates them into the training set.

% Figure environment removed

\textbf{Segmentation model.}
Our segmentation tasks are conducted on a 4-layer Bayesian U-net \cite{hiasa2019automated} of 2.73 million trainable parameters whose architecture is depicted in Fig. \ref{fig2} (b). To tackle class imbalance, we employ a multi-class focal loss \cite{lin2017focal} with class weighter $\alpha=0.67$ and regularizer $\gamma=2$. Our experiments use no augmentation since the study focuses on sampling strategy performance. During the training phase, we use the AdamW optimizer with decay weights of $1 \times 10^{-5}$, a learning rate of $4 \times 10^{-4}$, and a batch size of $8$. After $40000$ iterations training, the model checkpoint with the highest Dice similarity score (DSC) in the validation set will be selected for inference. The dropout rate is $0.5$ with $T=10$ times MC dropouts during the training and inference phases.

\textbf{Acquisition rules.}
Selecting all sequential images from one volume (i.e., \textit{volume-wise} acquisition) may introduce redundant information to the training pool \cite{chen2023survey}, as neighboring images usually exhibit similar features. On the other hand, from an annotator's point of view, annotating an entire volume is more efficient than annotating an equal number of slices among different volumes (i.e., \textit{slice-wise} acquisition), as it requires less time to operate the software to locate the target slice, and the annotation of consecutive slices can leverage semi-automatic tools for the slice interpolation. In order to analyze this trade-off, all experiments are conducted under slice-wise and volume-wise acquisition.

\textbf{Sampling strategies.}
Our method was compared with several recent AL algorithms in medical image segmentation tasks, including random selection, uncertainty-only selection \cite{gal2017deep}, two state-of-the-art (SOTA) methods \cite{hiasa2019automated, nath2020diminishing}, and the proposed method, with details as follows:

\noindent$\rightarrow$ BAL$_{rand}$: a simple baseline of randomly selecting samples from $\mathcal{D}_{u}$.

\noindent$\rightarrow$ BAL$_{unc}$: select the most uncertain samples from $\mathcal{D}_{u}$ based on Section \ref{subsec4}

\noindent$\rightarrow$ BAL$_{unc+sim}$: an implementation of \cite{hiasa2019automated}, consisting of uncertainty and density-based representative sampling. 

\noindent$\rightarrow$ BAL$_{unc+mi}$: a resemble method of \cite{nath2020diminishing} combining uncertainty sampling and mutual information-based diversity constraint, where our Bayesian estimation replaces the uncertainty calculation with ``Delete Flag'' set to $1$.

\noindent$\rightarrow$ BAL$_{proposed}$: Our proposed method that selects samples combining uncertainty sampling and hybrid representation-enhanced sampling (Section \ref{subsec4}), with the hyperparameter $\lambda$ empirically set to 0.5 and 0.25 for volume-wise and slice-wise acquisition, respectively. 

\textbf{Evaluation metrics}
The segmentation accuracy was assessed at each acquisition step using DSC. To quantify the manual labor saved by our BAL framework, we proposed a metric called $reduced$ $annotation$ $cost$ (RAC) as
\begin{equation}\label{eq3}
    RAC(I)=1-\frac{|I^{revised}|}{|I^{ROI}|}
\end{equation}
with the queried label image $I$. $| I^{revised}|$ denotes the number of pixels to be revised, whereas $| I^{ROI} |$ is the number of non-background pixels in the corresponding ground truth. Unlike the manual annotation cost (MAC) used in \cite{hiasa2019automated} that considers all image pixels, RAC considers non-background pixels, as annotation tools initially assign a zero value to all pixels and annotators modify only non-background ones.

\section{Results}\label{sec4}
Comparative results on both MRI and CT datasets. t-SNE maps and raw data of DSC and RAC for all strategies at each active iteration are available in Online Resource 1.4 and Online Resource 2. 
\subsection{MRI dataset}\label{subsec7}
% Figure environment removed
\begin{table}[t]
\begin{center}
\resizebox{1.0\textwidth}{!}{%
\begin{minipage}{1.05\textwidth}
\caption{Comparison of reduced annotation cost (RAC) metric on MRI dataset presented as mean $\pm$ std \%, where a larger value indicates fewer pixels to be revised. Notice that the mean RAC of the upper bound is $88.2$\% as the model trained on the fully labeled dataset.}\label{tab2}
\begin{tabular*}{\textwidth}{@{\extracolsep{\fill}}lcccccc@{\extracolsep{\fill}}}
\toprule%
& \multicolumn{6}{@{}c@{}}{Annotation\footnotemark[1]\% (number of active iteration)} \\\cmidrule{2-7}%
RAC \% & 1.25 (0) & 2.50 (1) & 5.00 (3) & 7.50 (5) & 10.0 (7) & 12.5 (9)\\
\midrule
BAL$_{rand}$  & $\mathbf{48.3}\pm1.0$ & $59.1\pm0.6$ & $73.7\pm0.1$ & $79.5\pm0.0$ & $82.3\pm0.0$ & $83.2\pm0.0$\\
BAL$_{unc}$  & $46.3\pm1.4$ & $64.9\pm0.1$ & $76.9\pm0.0$ & $81.4\pm0.0$ & $84.0\pm0.0$ & $85.0\pm0.0$\\
BAL$_{unc+mi}$  & $43.5\pm1.5$ & $66.9\pm0.4$ & $75.8\pm0.1$ & $81.0\pm0.0$ & $83.8\pm0.0$ & $84.9\pm0.0$\\
BAL$_{unc+sim}$  & $45.2\pm1.1$ & $67.3\pm0.2$ & $77.3\pm0.0$ & $\mathbf{82.5}\pm0.0$ & $83.9\pm0.0$ & $84.8\pm0.0$\\
BAL$_{proposed}$  & $48.0\pm0.6$ & $\mathbf{69.2}\pm0.3$ & $\mathbf{79.4}\pm0.0$ & $82.1\pm0.0$ & $\mathbf{84.2}\pm0.0$ & $\mathbf{85.3}\pm0.0$\\
\botrule
\end{tabular*}
\footnotetext{Exp. settings: volume-wise acquisition; 4-layer network of 2.73 million trainable parameters.}
\footnotetext[1]{Percentile of the annotated data used for model training.}
\end{minipage}
}
\end{center}
\end{table}

Initialized  with one randomly selected volume of 180 slices, we selected and revise one volume (for volume-wise selection) or 180 slices (average slice count per volume in the unlabeled pool, for slice-wise selection) from $\mathcal{D}_{u}$ and added them to $\mathcal{D}_{t}$ at each iteration. Data partitioning of volume-wise experiments was conducted three times with different random seeds to ensure reliability. The DSCs of all methods on the MRI dataset are shown in Fig. \ref{fig3}, where BAL$_{proposed}$ is depicted as the purple line. Comparing Fig. \ref{fig3} (a) with (b), we can infer that slice-wise acquisition systematically surpasses volume-wise by around 0.1 DSC, reaching close to the upper bound within five active iterations.

Focusing on the method comparisons, the DSC of BAL$_{proposed}$ was consistently superior to the SOTA BAL$_{unc+sim}$ and BAL$_{unc+mi}$. To estimate framework efficiency, we quantitatively estimated the RAC of BAL methods in the volume-wise acquisition, as shown in Table \ref{tab2}. The table illustrates that our proposed method contributed the most to reducing the annotation cost. 

\subsection{CT dataset}\label{subsec8}
Experiments on the CT dataset employed similar settings in Section. \ref{subsec7}, except that the slice-wise experiment chose 540 slices per iteration corresponding to the size of one volume in $\mathcal{D}_{u}$. The DSC results in Fig. \ref{fig4} show a similar trend to those obtained from the MRI dataset. When focusing on volume-wise acquisition (Fig. \ref{fig4} (b)),  BAL$_{proposed}$ was superior or non-inferior to other methods,  especially at the early stages of the 1st and 3rd active iterations. Table \ref{tab3} lists the RAC results in line with those shown in Section \ref{subsec7}. Our method achieved the upper bound RAC using only 12\% and 40\% of the full training data with slice-wise and volume-wise acquisition, respectively. 
% Figure environment removed

\begin{table}[t]
\begin{center}
\resizebox{1.0\textwidth}{!}{%
\begin{minipage}{1.05\textwidth}
\caption{Comparison of RAC metric on the CT dataset presented as mean $\pm$ std \%, where a larger value denotes fewer pixels from the prediction to be revised. Notice that the mean RAC of the upper bound is $88.9$\% as the model trained on the fully labeled dataset.}\label{tab3}
\begin{tabular*}{\textwidth}{@{\extracolsep{\fill}}lcccccc@{\extracolsep{\fill}}}
\toprule%
& \multicolumn{6}{@{}c@{}}{Annotation\footnotemark[1] \% (number of active iteration)} \\\cmidrule{2-7}%
RAC \% & 4.0 (0) & 8.0 (1) & 16 (3) & 24 (5) & 32 (7) & 40 (9)\\
\midrule
BAL$_{rand}$  & $60.4\pm0.7$ & $69.9\pm0.1$ & $78.1\pm0.2$ & $81.2\pm0.3$ & $84.9\pm0.0$ & $86.8\pm0.1$\\
BAL$_{unc}$  & $60.2\pm0.6$ & $75.0\pm0.3$ & $83.6\pm0.1$ & $\mathbf{87.6}\pm0.0$ & $\mathbf{88.0}\pm0.0$ & $88.7\pm0.0$\\
BAL$_{unc+mi}$  & $60.0\pm0.5$ & $75.1\pm0.1$ & $83.3\pm0.0$ & $86.7\pm0.0$ & $87.9\pm0.0$ & $88.4\pm0.0$\\
BAL$_{unc+sim}$  & $\mathbf{60.5}\pm0.4$ & $75.7\pm0.0$ & $83.6\pm0.0$ & $86.0\pm0.0$ & $87.9\pm0.0$ & $88.4\pm0.0$\\
BAL$_{proposed}$  & $60.4\pm0.8$ & $\mathbf{76.5}\pm0.3$ & $\mathbf{85.0}\pm0.0$ & $86.6\pm0.0$ & $87.9\pm0.0$ & $\mathbf{88.9}\pm0.0$\\
\botrule
\end{tabular*}
\footnotetext{Exp. settings: volume-wise acquisition; 4-layer network of 2.73m trainable parameters.}
\footnotetext[1]{Percentile of the annotated data used for model training.}
% \footnotetext[2]{Initialization results trained on randomly selected data}
\end{minipage}
}
\end{center}
\end{table}

\begin{table}[t]
\begin{center}
\resizebox{0.75\textwidth}{!}{%
\begin{minipage}{0.85\textwidth}
\caption{Ablation study of different components in BAL$_{proposed}$ on the two datasets. The results are collected at the 3$^{th}$ active iteration.}\label{tab4}
\begin{tabular}{@{}l|c|cc|cc|cc@{}}
\toprule
 \multirow{3}{*}{\textbf{Method}} & \multicolumn{3}{@{}c@{}}{AL Selection} & \multicolumn{2}{|@{}c@{}}{DSC} & \multicolumn{2}{|@{}c@{}}{RAC}\\\cmidrule{2-4}\cmidrule{5-6}\cmidrule{7-8}
 & \textbf{UNC} & \textbf{MI} & \textbf{SIM} & \textbf{MRI}\footnotemark[1] & \textbf{CT}\footnotemark[2] & \textbf{MRI}\footnotemark[1] & \textbf{CT}\footnotemark[2]\\
\midrule
BAL$_{rand}$         &              &                &           &  81.8 & 79.7 & 73.7 & 78.1\\
\midrule
BAL$_{unc}$ \cite{gal2017deep}        & \checkmark   &                &           &  84.3 & \textbf{84.8} & 76.9 & 83.6 \\
BAL$_{unc+mi}$ \cite{nath2020diminishing}      & \checkmark   & \checkmark     &           &  83.3 & 84.3 & 75.8 & 83.3 \\
BAL$_{unc+sim}$ \cite{hiasa2019automated}     & \checkmark   &                & \checkmark  & \textbf{84.6} & 84.6 & \textbf{77.3} & \textbf{83.6} \\
\midrule
BAL$_{proposed}$     & \checkmark   & \checkmark     & \checkmark  & \textbf{86.6} & \textbf{85.5} & \textbf{79.4} & \textbf{85.0} \\
\botrule
\end{tabular}
\footnotetext{\textbf{UNC}, \textbf{MI}, and \textbf{SIM} denote uncertainty module, diversity-enhanced module by mutual information, and density-enhanced module by cosine similarity, respectively.}
\footnotetext[1]{The quadriceps dataset with 5\% data annotated.}
\footnotetext[2]{The musculoskeletal dataset with 16\% data annotated.}
\end{minipage}
}
\end{center}
\end{table}

\subsection{Ablation study}\label{subsec9}
To illustrate the contribution of each component in BAL$_{proposed}$, we performed an ablation study shown in Table \ref{tab4}. Upon the comparison of BAL$_{rand}$ and BAL$_{unc}$, the uncertainty-based sampling significantly contributes 2.5\% and 5.1\% of DSC, and 3.2\% and 5.5\% of RAC on the MRI and the CT dataset, respectively. The results of BAL$_{mi}$ and BAL$_{sim}$ indicate the impact of enhanced diversity and density. Compared to BAL$_{unc}$, solely incorporating an MI-based diversity regularizer can deteriorate the BAL performance. However, BAL$_{proposed}$ suggests that integrating the regularizer with a density-enhanced module effectively counteracts its negative impact, as this combination tends to select fewer redundant samples or outliers.

\section{Discussion}\label{sec5}
 % Since our sampling algorithm (Online Resource 1. b) demonstrates sensitivity to increment size, the computational expense of slice-wise acquisition is exponentially higher.
We proposed a hybrid representation-enhanced sampling strategy in BAL by integrating density-based and diversity-based criteria and evaluated its performance on MRI and CT datasets. Slice-wise acquisition outperformed volume-wise using fewer annotations as it addresses redundant information and involves greater diversity by selecting slice images from multiple volumes. This approach prefers smaller regularization weighter $\lambda$ for milder diversity enhancement but necessitates more manual operations than volume-wise acquisition, which handles one volume per iteration. Hence, it is vital to consider the trade-off between the annotation time-cost and iteration times for two acquisition rules. Our observation reveals that, in the context of sequential image datasets, the volume-wise acquisition shows preferable adaptability and efficacy.

One can infer from Fig. \ref{fig3} and \ref{fig4}, and Table \ref{tab2} and \ref{tab3} that BAL$_{proposed}$ outperforms two SOTA samplings in early iterations, though this superiority consistently decreases over time. One possible explanation is that BAL$_{proposed}$ identified the key samples on both datasets ahead of other methods. Another point is that although BAL$_{proposed}$ showed minor DSC improvements for the CT dataset, it excelled in RAC estimation during the 1st and 3rd active iterations. This is because mean DSC was used for multi-class segmentation, while RAC focused solely on misclassified pixels unaffected by the number of classes.

Despite proven effectiveness, our study shows several limitations. Firstly, a greedy algorithm implemented our hybrid scoring approach, whose computational time grows exponentially with increased dataset size and acquisition granularity. Secondly, we have limited our analysis of the impact of two acquisition rules on LE datasets, while alternative conclusions may be reached on other datasets. Finally, our AL sampling strategy concentrates solely on leveraging the most valuable samples, neglecting the potential information within the remaining unlabeled data. Thus, future works shall include 1) algorithm optimization (e.g., VAE-based measures) for efficiency improvement, 2) extensive experiments on various datasets for quantitative estimation of acquisition rules' impact, and 3) incorporating the semi-supervised learning (SSL) \cite{nath2022warm} to unleash the potential of unlabeled data. 

\section{Conclusion}\label{sec6}
This paper has described a BAL framework based on Bayesian U-net that leverages the advantage of AL to reduce annotation efforts. At the algorithmic level, we introduced a novel hybrid representation-enhanced sampling that ensures high density and diversity of the training data to boost the BAL framework's performance. Moreover, we conducted a comprehensive study to reveal the impact of acquisition rules on BAL, as well as parameter sweeping for a real-world clinical setting. The experiment results indicated that our proposed sampling strategy outperforms SOTA representativeness-based sampling approaches on musculoskeletal segmentation. We also summarized previous works for a better comprehension of our experiments (Online Resource 1.3), and our code will be available on GitHub.\footnotemark[1]
\backmatter

\bmhead{Supplementary information}
Online Resource 1:  1) Details of Estimation of model uncertainty, 2) the hybrid representation-enhanced sampling algorithm, 3) a table summarizing previous works, and 4) t-SNE maps. 
Online Resource 2: Raw data of DSC and RAC for all methods and active iterations, available on GitHub.\footnotemark[1]
\footnotetext[1]{\url{https://github.com/RIO98/Hybrid-Representation-Enhanced-Bayesian-Active-Learning}.}
\bmhead{Acknowledgments}

This work was funded by MEXT/JSPS KAKENHI (19H01176, 20H04550, 20K19376, 21H03303, 21K16655, 21K18080).

\section*{Declarations}
\textbf{Conflict of interest} The authors declare that Yoshinobu Sato is a member of the IJCARS Editorial Board. \\


\noindent\textbf{Ethics approval} Ethical approval was obtained from the Institutional Review Boards (IRBs) of the institutions participating in this study (IRB approval numbers: 21115 for Osaka University Hospital, R1746-2 for Kyoto University Hospital, and 2020-M-7 for Nara Institute of Science and Technology.)

%%===========================================================================================%%
%% If you are submitting to one of the Nature Portfolio journals, using the eJP submission   %%
%% system, please include the references within the manuscript file itself. You may do this  %%
%% by copying the reference list from your .bbl file, paste it into the main manuscript .tex %%
%% file, and delete the associated \verb+\bibliography+ commands.                            %%
%%===========================================================================================%%

\bibliography{sn-bibliography}% common bib file
%% if required, the content of .bbl file can be included here once bbl is generated
%%\input sn-article.bbl


\end{document}
