\subsubsection{The limit of SGD}
    Let us reparametrize the SGD process $\vz_k$. Define the learning rate $\lambda^{(n)}_t = \frac{\eta^{(n)}_{\lfloor t/(\eta^{(n)})^2\rfloor}}{\eta^{(n)}}$, and the SGD iterates is given by
\begin{align}
    \vg_{k} &= \nabla \Loss(\vx_{k}) + \mSigma^{1/2}(\vx_k)\vxi_{k},\\
    \vz_{k+1} &= \vz_{k} - \eta^{(n)}_{k} \vg_k.\label{equ:sgd-sde-1}
\end{align}
Here we reparameterize the noise $\vv_k=\mSigma^{1/2}(\vx_k)\vxi_k$ so that $\vxi_k$ are independent, $\E\vxi_k=0$ and $\E\vxi_k\vxi_k^\top = \mI$. We also assume that the constants $C_m$ in \Cref{assume:ngos} are defined here as $\E\norm{\vxi_k}^m\leq C_m$. 

Now define the stochastic process $A_n(t) = \sum_{k=0}^{\lfloor t/(\eta^{(n)})^2\rfloor-1} \eta_k^{(n)}$ and $Z_n(t)=\sum_{k=0}^{\lfloor t/(\eta^{(n)})^2\rfloor-1} \eta_k^{(n)}\vxi_k$, then \Cref{equ:sgd-sde-1} can be written as a stochastic integral as
\begin{align}
    \bvz^{(n)}_t &= \vz_{0} -\int_0^t \nabla \Loss(\bvz^{(n)}_t) \dd A_n(t) + \mSigma^{1/2}(\bvz^{(n)}_t)\dd Z_n(t) .\label{equ:sgd-sde-2}
\end{align}
with $\bvz^{(n)}_t = \vz_{\lfloor t/(\eta^{(n)})^2\rfloor}$. Then we can characterize its limiting dynamics.
\begin{theorem}\label{thm:sgd-slow-sde-main}
    The process $\bvz^{(n)}_t$ is a Katzenberger process, and for any $t>0$, $\bvz^{(n)}_t$ converges in distribution to $\bvz_t$ as $n\to\infty$ that
    \[\bvz_t = \Phi(\vz_0) + \int_0^t\lambda_t \partial\Phi(\bvz_s)\mSigma^{1/2}(\bvz_s)\dd W_s +\int_0^t\frac{\lambda_t^2}{2}\partial^2\Phi(\bvz_s)[\mSigma(\bvz_s)]\dd s.\]
\end{theorem}
\begin{proof}
    First we show that $\bvz^{(n)}_t$ is a Katzenberger process. Note that
    
    \begin{itemize}
        \item $A_n$ increases infinitely fast: by \Cref{ass:conve-hpschedule}, for all $s<t$, \[A_n(t)-A_n(s) =  \sum_{k=\lfloor s/(\eta^{(n)})^2\rfloor}^{\lfloor t/(\eta^{(n)})^2\rfloor-1} \eta_k^{(n)}\to \sum_{k=\lfloor s/(\eta^{(n)})^2\rfloor}^{\lfloor t/(\eta^{(n)})^2\rfloor-1} \eta^{(n)} \lambda_{k(\eta^{(n)})^2},
        \]
        \[\sum_{k=\lfloor s/(\eta^{(n)})^2\rfloor}^{\lfloor t/(\eta^{(n)})^2\rfloor-1} \eta^{(n)} \lambda_{k(\eta^{(n)})^2}\geq (\frac{s-t}{\eta^{(n)}}-\eta^{(n)})(\inf_{t\in [0,T]}\lambda_t)\to \infty\]
        as $\eta^{(n)}\to 0$.
        \item $Z_n(t)$ converges to $Z(t)$ that there is a brownian motion $W_t$ and  
        \[Z(t)=\int_0^t \lambda_s \dd W_s.\]
        This is shown with the standard central limit theorem. Let $W_n(t) = \int_0^t \frac{\dd Z(t)}{\lambda_s}$ be the normalized martingale. By the standard central limit theorem (for instance Theorem 4.3.2~\citet{whitt2002stochastic}), $W_n(t)-W_n(s)$ has a limit as a gaussian distribution with variance
        $\sum_{k=\lfloor s/(\eta^{(n)})^2\rfloor}^{\lfloor t/(\eta^{(n)})^2\rfloor-1}(\frac{\eta_k^{(n)}}{\lambda_{k(\eta^{(n)})^2}})^2\to (t-s)$ by \Cref{ass:conve-hpschedule}. Then $W_n(t)$ converges to a bronwian motion $W_t$ by Levy's characterization.
    \end{itemize}
    Therefore $\bvz^{(n)}_t$ is a Katzenberger process, and by \Cref{thm:previous_thm} its limit is given by
    \[\bvz_t = \Phi(\vz_0) + \int_0^t\lambda_t \partial\Phi(\bvz_s)\mSigma^{1/2}(\bvz_s)\dd W_s +\int_0^t\frac{\lambda_t^2}{2}\partial^2\Phi(\bvz_s)[\mSigma(\bvz_s)]\dd s.\]
\end{proof}
\subsubsection{SGDM when $\alpha<1$}
For the SGDM setting, we wish to extract the scale from the hyperparameters to make notations clear. Therefore we define 
\begin{align*}
    \lambda^n_t & = \frac{\eta^{(n)}_k}{\eta^{(n)}} \\
    \gamma^n_t & = \frac{1-\beta^{(n)}_k}{(\eta^{(n)})^\alpha},\\
    k &= \lfloor t/(\eta^{(n)})^2\rfloor.
\end{align*}


Then the original process
\begin{align}
\vm^{(n)}_{k+1} & = \beta^{(n)}_{k}\vm^{(n)}_{k} + (1-\beta^{(n)}_{k})\vg^{(n)}_{k}\\
		\vx^{(n)}_{k+1} & = \vx^{(n)}_{k} - \eta^{(n)}_{k}\vm^{(n)}_{k+1}
\end{align}
can be rewritten into a SDE formulation. Similarly, we reparameterize the noise $\vv_k=\mSigma^{1/2}(\vx_k)\vxi_k$ so that $\vxi_k$ are independent, $\E\vxi_k=0$ and $\E\vxi_k\vxi_k^\top = \mI$.
Let the processes $Z^n_t = \eta^2 \lfloor t/\eta^2 \rfloor$,  and $Y^n_t = \eta \sum_{i=1}^{\lfloor t/\eta^2\rfloor} \vxi_i$. By the previous convention, the process can be rewritten as (let $\eta=\eta^{(n)}$)
\begin{align}\label{equ:sgdm-sde-main}
    \begin{cases}
    \diff X^n_t & = - \frac{ \lambda_t}{\eta} (M^n_t \diff Z^n_t + \eta^2 \diff M^n_t) \\
     & = - \frac{ \lambda_t }{\eta} ((1-\gamma_t\eta^\alpha)M^n_t \dd Z_t^n+\gamma_t\eta^\alpha \nabla \Loss(X^n_t))\diff Z^n_t - \gamma_t \lambda_t\eta^\alpha\mSigma^{1/2}(X^n_t)\diff Y^n_t \\
    \diff M^n_t & = - \frac{\gamma_t}{\eta^{2-\alpha}} ( M^n_t  - \nabla \Loss(X^n_t)) \diff Z^n_t + \frac{\gamma_t}{\eta^{1-\alpha}}\mSigma^{1/2}(X^n_t)\diff Y^n_t
    \end{cases}
\end{align}
Then $X_t^n = \vx^{(n)}_{\lfloor t/\eta^2\rfloor}$ and  $M_t^n = \vm^{(n)}_{\lfloor t/\eta^2\rfloor}$.

Rewriting the second line gives
\begin{equation}
 M^n_t \diff Z^n_t = -\gamma_t^{-1}\eta^{2-\alpha} \diff M^n_t + 
\nabla \Loss(X^n_t) \diff Z^n_t + 
\eta \mSigma^{1/2}(X^n_t)\diff Y^n_t
\end{equation}
So
\begin{equation}
 dX^n_t = -\lambda_t\eta \diff M^n_t  +(\lambda_t/\gamma_t)\eta^{1-\alpha} \diff M^n_t -\lambda_t \eta^{-1}
\nabla \Loss(X^n_t) \diff Z^n_t -\lambda_t \mSigma^{1/2}(X^n_t)\diff Y^n_t
\end{equation}


Now consider the Ito's formula applied to the gradient projected process $ \Phi(X^n_t)$. Fix $K\subset O_\Gamma$ be a compact neighbourhood of the manifold $\Gamma$. Since $\Phi(X)$ is only defined for $X\in O_\Gamma$, we take an arbitrary regular extension of $\Phi$ to the whole space. Fix time horizon $T>0$, and let $\tau_n=\min(\inf\{t>0:X^n_{t}\not\in \mathring{K}\},T)$ to be the exiting time for the compact set $K\subset O_\Gamma$ we have chosen earlier. Since $X^n_0\in \mathring{K}$, we know $\tau_n\geq \eta^2$. We use $\chi^n_t = \mathbf{1}[t<\tau_n]$ to denote the indicator process of the stopping time $\tau_n$. For any c\`{a}dl\`{a}g semi-martingale $X_t$, $X_{t\wedge \tau_n}$ is a c\`{a}dl\`{a}g semi-martingale that $\diff X_{t\wedge \tau_n} = \chi^n_t\diff X_t$.

For simplicity we omit the superscript $n$ unless necessary. Ito's formula on $\Phi(X_t)$ gives
\begin{align*}
     \dd \Phi(X_t) & = \partial \Phi(X_t) \dd X_t + \frac{1}{2}\partial^2 \Phi(X_t) [\dd[X]_t] + \diff\delta\\
     & = \partial \Phi(X_t)((-\lambda_t\eta+ \lambda_t\eta^{1-\alpha}/\gamma_t)\diff M_t - \lambda_t \eta^{-1}\nabla\Loss(X_t)dZ_t -\lambda_t \mSigma^{1/2}(X_t)dY_t)\\
     & + \frac{1}{2}\partial^2 \Phi(X_t) [\dd[X]_t] +\diff\delta
\end{align*}
where $\delta$ are error terms as $\delta(0)=0$ and
\begin{align*}\diff\delta &= \Delta \Phi(X_t) -  
\partial\Phi(X_{t-})
\Delta X_t - \frac{1}{2}\partial^2\Phi(X_{t-})[\Delta X_t(\Delta X_t)^\top]\\
\end{align*}
For $X_t\in K$, there is always $\partial \Phi(X_t)\nabla\Loss(X_t)=0$  by \Cref{lem:gra-proj-1}, so  consider the following process $\Phi_t$: $\Phi_0=\Phi(X_0)$ and 
\begin{align}
     \dd \Phi_t  & =  \partial \Phi(X_t)((-\lambda_t\eta+ \lambda_t\eta^{1-\alpha}/\gamma_t)\diff M_t -\lambda_t \mSigma^{1/2}(X_t)dY_t) + \frac{1}{2}\partial^2 \Phi(X_t) [\dd[X]_t] +\diff\delta
\end{align}
Then $\Phi_{t\wedge \tau_n} = \Phi(X_{t\wedge \tau_n})$. 

In addition, direct calculations gives
\begin{align*}
        [Z]_t & = \eta^2 Z_t,\\
        [Y]_t & = \eta^2 \sum_{i=1}^{\lfloor t/\eta^2\rfloor} \xi_i \xi_i^\top,  \E[Y]_t = Z_t\mI\\
        [Y,Z]_t & = \eta^2 Y_t,\\
        \diff [M]_t & = \gamma_t^2\eta^{2\alpha-2}(M_t-\nabla\Loss(X_t))(M_t-\nabla\Loss(X_t))^\top \diff Z_t + \gamma_t^2\eta^{2\alpha-2}\mSigma^{1/2}(X_t) d[Y]_t \mSigma^{1/2}(X_t) \\
        & - \gamma_t^2\eta^{2\alpha-1}(M_t-\nabla\Loss(X_t))dY_t^\top \mSigma^{1/2}(X_t) - \gamma_t^2\eta^{2\alpha-1} \mSigma^{1/2}(X_t)dY_t (M_t-\nabla\Loss(X_t))^\top,\\
         \diff [M,Z]_t & =  - \gamma_t\eta^\alpha ( M_t  - \nabla \Loss(X_t)) \diff Z_t + \gamma_t\eta^{\alpha+1}\mSigma^{1/2}(X_t)\diff Y_t\\
        d[X]_t & = \lambda_t^2 (M_tM_t^\top  dZ_t + \eta^2 d[M]_t + M_td[Z,M]_t +  d[M,Z]_t M_t^\top)\\
        d[M,X]_t & =   -  \lambda_t (- \gamma_t \eta^{\alpha-1} ( M_t  - \nabla \Loss(X_t))M_t^\top \diff Z_t + \gamma_t\eta^{\alpha}\mSigma^{1/2}(X_t)\diff Y_t M_t^\top) + \eta \diff [M]_t)\\
\end{align*}
\subsubsection{Control of the velocity processes}
%\begin{assumption}
%   The noise process $\xi_i$ and i.i.d. with $\E \xi_i=0$ and $\E\xi_i\xi_i^\top = \mI$. Furthermore, $\xi_i$ is almost surely bounded, e.g. with probability 1,
%   $\norm{\xi_i}\leq B_{\xi}$.
%\end{assumption}
%In this way, the processes $m^n_{t\wedge \tau_n}$ is almost surely bounded for each $n$. 
Notice that our process $X^n_t\in K$ is bounded for $t<\tau_n$. Therefore following regularies, for any continuous function $f:K\to \R$, $f(X^n_{t})$ is bounded $t<\tau_n$. Also, notice that $M^n_{t\wedge \tau_n}$ has bounded moments:
\begin{lemma}
    There exists constants $C^n_m$ such that $\E\norm{M^n_{t\wedge \tau_n}}^m\leq C^n_m$.
\end{lemma}
\begin{proof}
    This follows trivially from the iterate $\vm^{(n)}_{k+1}  = \beta^{(n)}_{k}\vm^{(n)}_{k} + (1-\beta^{(n)}_{k})\vg^{(n)}_{k}$,
    \begin{align*}
        \E\norm{\vm^{(n)}_{k+1}}^m &\leq 2^m \norm{\vm^{(n)}_{k}}^m + 2^m \norm{\vg^{(n)}_{k}}^m\\
        & \leq 2^m \norm{\vm^{(n)}_{k}}^m + 4^m \norm{\nabla\Loss(\vx^{(n)}_k)}^m + 4^m \norm{\vv^{(n)}_k}^m.
    \end{align*}
    The term $\norm{\nabla\Loss(\vx^{(n)}_k)}^m\leq \sup_{\vx\in K}\norm{\nabla\Loss(\vx)}^m$ is bounded and $\norm{\vv^{(n)}_k}^m$ is bounded by \Cref{assume:ngos}. Therefore the lemma follows from the Gr\"{o}nwall inequality \Cref{lem:gronwall-discrete}.
\end{proof}
%\begin{assumption}
%    The momentum decay rate is bounded: $\inf_{t\in [0,T]}\lambda_t\geq \lambda_{\min}>0$ and $\sup_{t\in [0,T]}\lambda_t<\lambda_{\max}=1$. The rate schedule $\gamma_t$ is upper bounded $\sup_{t\in [0,T]}\gamma_t\leq \gamma_{\max}<\infty$. moreover $\gamma_t$ and $\lambda_t$ are cadlag and have finite variation.
%\end{assumption}

\begin{lemma}
    For all stopping time $t$ and function $f>0$, $\int_0^t f(M_s,X_s) \diff Z_s\leq \int_0^t f(M_s,X_s) \diff s $, and $\int_0^t f(M_s,X_s) \diff Z_s\geq \int_0^t f(M_s,X_s) \diff s  - \eta^2 f(M_t,X_t)$.
\end{lemma}
\begin{proof}
    Note that the processes $M_s$ and $X_s$ only changes at jumps at $s=k\eta^2$, the result followed directly from the definition of $Z_s$.
\end{proof}
Next follows some facts are are useful in proving the theorems.
\begin{lemma}[\citet{katzenberger1991solutions} lemma 2.1 ]\label{lem:gronwall-1}
    Let $f,g:\mathbf{R}\to [0,\infty)$ be functions that $g$ is non-decreasing and $g(0)=0$. Assume for constant $C>0$ and all $t>0$
    \[0\leq f(t)\leq C+\int_0^t f(s-)\diff g(s).\]
    Then $f(t)\leq Ce^{g(t)}$ for all $t\geq 0$.    
\end{lemma}

\begin{proof}
    In this case $g(t)\geq 0$. Expansion gives
    \begin{align*}
        f(t) & \leq C(1+\sum_{n=1}^\infty \int_0^t \int_0^{s_1-}\int_0^{s_2-}\cdots \dd g(s_3) \dd g(s_2) \dd g(s_1)\\
        &\leq C(1+\sum_{n=1}^\infty \frac{1}{n!}g^n(t))\\
        & = C e^{g(t)}.
    \end{align*}
\end{proof}
We may also encounter the case where $g$ is negative. Another form of Gronwall inequality is useful here.
\begin{lemma}[Gr\"{o}nwall]\label{lem:gronwall-2}
  Let $f,g:\mathbf{R}\to [0,\infty)$ be functions that $g(0)=0$. Assume for constant $C>0$ and all $0<s<t<T$
    \[ f(t)\leq f(s)- C\int_s^t f(r-)\diff r +g(t)-g(s).\]
    Then $f(t)\leq e^{-C t}(f(0)+g(t)) + C \int_0^t e^{-C(t-s)}(g(t)-g(s))\dd s$ for all $0\leq s\leq T$.   
\end{lemma}

We need a form of Gronwall's inequality with our uncountinuous process $Z_t$
\begin{lemma}\label{lem:gronwall-3}
     Let $f:\R\to [0,\infty)$ be a non-decreasing function and $g:\R\times \R\to [0,\infty)$ be non-negative. Assume for constant $C>0$ and all $0<s<t<T$
    \[ f(t)\leq f(s)- C\int_s^t f(r-)\diff Z^n_r +g(t,s).\]
    Then $f(t)\leq e^{-C' Z_t^n}(f(0)+g(t,0)) + C\int_0^t e^{-C'(Z_t^n-Z_s^n)}g(t,s)\dd Z_s^n$ for all $0\leq s\leq T$ with $C' = \eta^{-2}\log(1+C\eta^2)$.
\end{lemma}
\begin{lemma}
    $\int_0^t e^{C Z_s^n} dZ_s^n = \frac{\eta^2}{e^{C \eta^2}-1} (e^{CZ_t^n}-1)$.
\end{lemma}
\begin{proof}
    Directly calculation that $\sum_{i=0}^n c^i = \frac{1-c^{n+1}}{1-c}$ for $c=e^{C\eta^2}$.
\end{proof}
\begin{proof}[Proof of \Cref{lem:gronwall-3}]
    multiplying both sides with $e^{-C'(Z_t^n-Z_s^n)}$ and integration yields the result.
\end{proof}
Specifically for $g(t,s)=Z_t^n-Z_s^n$, the bound can be further simlified.
\begin{lemma}\label{cor:gronwall-3}
    $\int_0^t e^{-C(Z_t^n-Z_s^n)}(Z_t^n - Z_s^n)\dd Z_s^n \leq C^{-2}$.
\end{lemma}
\begin{proof}
    \[\int_0^t e^{-C(Z_t^n-Z_s^n)}(Z_t^n - Z_s^n)\dd Z_s^n \leq \int_0^{\infty} e^{-C z} z \dd z =C^{-2}.\]
\end{proof}
Another useful theorem is the Doob's martingale inequality.
\begin{lemma}\label{lem:Doob-1}
    Let $X_t$ be a martingale for $t\in[0,T]$ whose sample path is almost surely right-continuous. Then for any $C>0$, and $p\geq 1$,
    \[\Pr[\sup_{t\in [0,T]}|X_t|\geq C]\leq \frac{\E |X_T|^p}{C^p}.\]
    Furthermore, integration with $p=2$ gives
    \[\E \sup_{t\in [0,T]}|X_t|\leq 2\sqrt{\E |X_T|^2}.\]
\end{lemma}
\iffalse
\begin{lemma}
    For all $t\in [0,T]$,
        \[\sup_n \int_0^{t} \eta^{-\alpha}\E\norm{m_{s\wedge \tau_n}^n}^2 \dd s< + \infty.\]
\end{lemma}
\begin{proof}
    Consider the energy function $G^n_t(X^n_t,M^n_t) = \Loss(X^n_t) + \frac{\gamma_t}{2}(\eta^{1-\alpha} - \lambda_t\eta)\norm{M^n_t}^2$,  there is
    \begin{align*}\diff G^n_t(X^n_t,M^n_t) & = \dotp{\nabla\Loss(X^n_t)}{\diff X^n_t} + \frac{1}{2}\tr{\nabla^2\Loss(X^n_t)\diff [X^n_t]}\\
    & + \Delta \Loss(X_t) -  
    \partial\Loss(X_{t-})
    \Delta X_t - \frac{1}{2}\partial^2\Loss(X_{t-})[\Delta X_t(\Delta X_t)^\top]\\
    & + \frac{1}{2}\eta^{1-\alpha}\norm{M^n_t}^2 \frac{\dd \gamma_t}{\dd t} \dd t + \gamma_t \eta^{1-\alpha}\dotp{M_t^n}{\ddM_t^n} + \frac{\gamma_t}{2}\eta^{1-\alpha}\tr \dd[M_t^n]\\
    & \leq -\eta\lambda_t\gamma_t\dotp{\nabla\Loss(X^n_t)}{ \ddM_t^n} +  \frac{1}{2}\tr{\nabla^2\Loss(X^n_t)\diff [X^n_t]}\\
    & + \Delta \Loss(X_t) -  
    \partial\Loss(X_{t-})
    \Delta X_t - \frac{1}{2}\partial^2\Loss(X_{t-})[\Delta X_t(\Delta X_t)^\top]\\
    & + \frac{1}{2}\eta^{1-\alpha}\norm{M^n_t}^2 \frac{\dd \gamma_t}{\dd t} \dd t - \gamma_t\lambda_t \eta^{-1} \norm{M_t}^2\dd Z^n_t + \frac{\gamma_t}{2}\eta^{1-\alpha}\tr \dd[M_t^n]\\
    & + \gamma_t\lambda_t \dotp{M_t}{\mSigma^{1/2}(X_t)\dd Y_t}.\\
    & \leq - \frac{1}{2}C\tr\diff [X^n_t]- \gamma_t\lambda_t \eta^{-1} \norm{M_t}^2\dd Z^n_t + C \norm{\Delta X_t^n}^3\\
    & + \frac{1}{2}\eta^{1-\alpha}\norm{M^n_t}^2 \frac{\dd \gamma_t}{\dd t} \dd t  + \frac{\gamma_t}{2}\eta^{1-\alpha}\tr \dd[M_t^n]\\
    & + \gamma_t\lambda_t \dotp{M_t}{\mSigma^{1/2}(X_t)\dd Y_t}.\\
    \end{align*}
    
\end{proof}
\fi
\begin{lemma}\label{lem:momentum-1}
    For all $t>0$ and $\alpha\in [0,1)$, 
    \begin{itemize}
    \item $\lim_{n\to\infty}\eta^{\beta}\E\sup_{t\in [0,T]}\norm{M_{t\wedge\tau_n}^n}^2=0$ for any $\beta>1-\alpha$. \\
    moreover, $\lim_{n\to\infty}\eta^{\beta/2}\E\sup_{t\in [0,T]}\norm{M_{t\wedge\tau_n}^n}=0$
    \item $\lim_{n\to\infty}\eta^{\beta}\E\int_0^{t\wedge \tau_n} \norm{M_{t\wedge\tau_n}^n}^2 \dd Z^n_s=0$ for any $\beta>0$.\\
    moreover, $\sup_n \E\int_0^{t\wedge \tau_n} \norm{M_{t\wedge\tau_n}^n}^2 \dd Z^n_s<\infty$.
\end{itemize}
For $\alpha\in (0,1)$,
\begin{itemize}
    \item $\lim_{n\to\infty}\eta^{\beta} \E \int_0^{t\wedge \tau_n} \norm{M_s^n}^3 \dd Z^n_s=0$ for any $\beta>0$.
    \end{itemize}
\end{lemma}
\begin{proof}
     Ito's formula on $\norm{M_t^n}^2$ gives 
      \begin{align*}
        d\norm{M_t^n}^2 & = 2\dotp{M_t^n}{dM_t^n} +  \tr d[M^n]_t \\
        & = - 2\gamma_t\eta^{\alpha-2} ( \norm{M^n_t}^2  - (M^n_t)^\top\nabla \Loss(X^n_t)) \diff Z^n_t + 2\gamma_t\eta^{\alpha-1}  (M^n_t)^\top\mSigma^{1/2}(X^n_t)\diff Y^n_t  \\
        & +  \gamma_t^2\eta^{2\alpha-2}\norm{M^n_t-\nabla\Loss(X^n_t)}^2 \diff Z^n_t + \gamma_t^2\eta^{2\alpha-2} \tr (\mSigma(X^n_t)\dd[Y^n]_t)  \\
        & - 2\gamma_t^2\eta^{2\alpha-1}\tr ((M^n_t-\nabla\Loss(X^n_t))^\top\mSigma^{1/2}(X^n_t)\dd Y^n_t) \\
        & = \eta^{2\alpha-2} \dd W_t^n   - 2\gamma_t\eta^{\alpha-2} ( \norm{M^n_t}^2  - (M^n_t)^\top\nabla \Loss(X^n_t)) \diff Z^n_t\\
        & +  \gamma_t^2\eta^{2\alpha-2}\norm{M^n_t-\nabla\Loss(X^n_t)}^2 \diff Z^n_t + \gamma_t^2\eta^{2\alpha-2} \tr (\mSigma(X^n_t))\dd Z^n_t .
    \end{align*}
    Let $W^n_t$ be the martingale that $W_0^n=0$ and
    \begin{align*}\dd W^n_t & = 2\gamma_t\eta^{1-\alpha}  (M^n_t)^\top\mSigma^{1/2}(X^n_t)\diff Y^n_t + \gamma_t^2 \tr (\mSigma(X^n_t) (\dd[Y^n]_t - \mI\dd Z^n_t))\\
    & - 2\gamma_t^2\eta(M^n_t-\nabla\Loss(X^n_t))^\top\mSigma^{1/2}(X^n_t)\dd Y^n_t.
    \end{align*}


    When $\alpha>0$, take the constant $C_1 = 2\sup_{X\in K}\norm{\nabla\Loss(X)}(2+\norm{\nabla\Loss(X)}) $ and $C_2 = \sup_{X\in K} \tr\mSigma(X) + C_1$. Since $\eta^{-\alpha}\norm{M_t^n}\leq (\eta^{-1}+\eta^{1-2\alpha}\norm{M_t^n}^2)/2$, for any $t>s>0$ there is
    \begin{align*}\eta^{\beta}\norm{M_{t\wedge \tau_n}^n}^2  & \leq  \int_{s\wedge \tau_n}^{t\wedge \tau_n}  (- 2\lambda_{\min}\eta^{\beta+\alpha-2} \norm{M^n_r}^2  + C_1\eta^{\beta+\alpha-2}\norm{M^n_r} +  C_1\eta^{\beta+2\alpha-2}(\norm{M^n_r}^2+1))\diff Z^n_r \\
    & + \eta^{\beta}\norm{M_{s\wedge \tau_n}^n}^2 + \eta^{\beta+2\alpha-2}\int_{s\wedge \tau_n}^{t\wedge \tau_n} \lambda_r^2 \tr (\mSigma(X^n_r)) \dd Z^n_r + \eta^{\beta+2\alpha-2}(W^n_{t\wedge \tau_n} - W^n_{s\wedge \tau_n})\\
    & \leq  \eta^{\beta}\norm{M_{s\wedge \tau_n}^n}^2 + \int_{s\wedge \tau_n}^{t\wedge \tau_n}  (- 2\lambda_{\min}\eta^{\alpha-2}+\frac{1}{2} C_1 \eta^{-1}+C_1 \eta^{2\alpha-2} )\eta^{\beta}\norm{M^n_r}^2 \diff Z^n_r\\
    & +\eta^{2\alpha+\beta-3} C_2 (Z_{t\wedge \tau_n}^n-Z_{s\wedge \tau_n}^n) + \eta^{2\alpha+\beta-2}(W^n_{t\wedge \tau_n} - W_{s\wedge \tau_n}^n)\\
    \end{align*}
    By the Doob's inequality \Cref{lem:Doob-1}, 
    \begin{align*} W^{s,n}_{t}  & = W_{t\wedge \tau_n}^n-W^n_{s\wedge \tau_n} \\ & =  
    \int_{s\wedge \tau_n}^{t\wedge \tau_n}2\gamma_r\eta^{1-\alpha}  (M^n_r)^\top\mSigma^{1/2}(X^n_r)\diff Y^n_r + \gamma_r^2 \tr (\mSigma(X^n_r)(\dd[Y^n]_r - \mI\dd Z^n_r))\\
    & - 2\gamma_r^2\eta(M^n_r-\nabla\Loss(X^n_r))^\top\mSigma^{1/2}(X^n_r)\dd Y^n_r
    \end{align*}
    is a martingale, so there is a universal constant $A$ that
    \begin{align*}
        \E\sup_{r\in [s,t]}|W_r^{s,n}| & \leq 2\sqrt{\E |W_t^{s,n}|^2}\\
        & \leq 2A\sqrt{Z^n_{t\wedge \tau_n}-Z^n_{s\wedge \tau_n}+\eta^{2-2\alpha}\int_{s\wedge \tau_n}^{t\wedge \tau_n}\norm{M_r^n}^2 \dd Z_r^n}\\
        & \leq 2A\eta^{-1}(Z^n_{t\wedge \tau_n}-Z^n_{s\wedge \tau_n}+\eta^{2-2\alpha}\int_{s\wedge \tau_n}^{t\wedge \tau_n}\norm{M_r^n}^2 \dd Z_r^n)
    \end{align*}
    Therefore let $K^n_t = \eta^{\beta}\E\sup_{s\in[0,t]}\norm{M^n_{s\wedge\tau_n}}^2$,
    \begin{align*}
        K^n_t\leq K^n_s + \int_s^t \kappa_n K_r^n \dd Z_r^n+ (2A+ C_2) \eta^{2\alpha+\beta-3}(Z_{t}^n-Z_{s}^n)
    \end{align*}
    Here $\kappa_n= - 2\lambda_{\min}\eta^{\alpha-2}+\frac{1}{2} C_1 \eta^{-1}+C_1 \eta^{2\alpha-2}+2A\eta^{-1}$, then when $\eta\to 0$ eventually $\kappa_n<0$. Then by the Gronwall inequality \Cref{lem:gronwall-3}, with $\kappa'_n=\eta^{-2}\log(1+|\kappa_n|\eta^2)$,
    \begin{align*}
        K^n_t & \leq \eta^{2\alpha+\beta-3}(2A+ C_2)[e^{-\kappa'_n Z_t^n}Z_t^n + \int_0^t |\kappa_n|e^{-\kappa'_n (Z_t^n-Z_s^n)}(Z_t^n-Z_s^n) \dd Z_s^n]\\
    \end{align*}
    By \Cref{cor:gronwall-3}, \[K^n_t \leq \eta^{2\alpha+\beta-3}(2A+ C_2)(e^{-\kappa'_n Z_t^n}Z_t^n + |\kappa_n|(\kappa'_n)^{-2})\]
    Taking the limit gives $\lim_{n\to\infty} K_t^n=\tilde{O}(\eta^{3\alpha+\beta-1})=0$.

    For $\alpha=0$, there is
     \begin{align*}
        \eta^2 d\norm{M_t^n}^2 & = \dd W_t^n   - 2\gamma_t( \norm{M^n_t}^2  - (M^n_t)^\top\nabla \Loss(X^n_t)) \diff Z^n_t\\
        & +  \gamma_t^2\norm{M^n_t-\nabla\Loss(X^n_t)}^2 \diff Z^n_t + \gamma_t^2 \tr (\mSigma(X^n_t) )\dd Z^n_t\\
        & \leq \dd W_t^n-\gamma_t\norm{M^n_t}^2 \diff Z^n_t +  \norm{\nabla\Loss(X^n_t)}^2 \diff Z^n_t + \tr (\mSigma(X^n_t) )\dd Z^n_t.
    \end{align*}
    For $K^n_t = \eta^{\beta}\E\sup_{s\in[0,t]}\norm{M^n_{s\wedge\tau_n}}^2$, let $\iota_n = -\lambda_{\min}\eta^{-2} + 2A\eta^{-1}$ and some constant $C_3$, there is
    \[K^n_t\leq K^n_s + \int_s^t \iota_n K_r^n \dd Z_r^n + C_3 \eta^{\beta-3}_n (Z^n_{t}-Z^n_{s})\]
    Similarly by \Cref{lem:gronwall-3} and \Cref{cor:gronwall-3}, $\lim_{n\to \infty}K_t^n = O(\eta^{\beta-1})=0$.
    
    For any jump $\Delta M_t^n$, and $f(M_t^n)=\norm{M_t^n}^3$ there is $\theta\in [0,1]$ that $M = \theta M_{t-}^n + (1-\theta)M_t^n$ and
    \begin{align*}
         & \Delta f(M_t^n) - \dotp{\partial f(M_{t-}^n)}{M_t^n} - \frac{1}{2}\partial^2 f(M_{t-}^n)[\Delta M_t^n (\Delta M_t^n)^\top] \\
         = & \frac{1}{6}\partial^3 f(M)[\Delta M_t^n,\Delta M_t^n,\Delta M_t^n ] \\
         = & -\frac{1}{2} \frac{\dotp{M}{\Delta M_t^n}^3}{\norm{M}^3} + \frac{3}{2}\frac{\dotp{M}{\Delta M_t^n}}{\norm{M}}\\
         & \leq 2\norm{\Delta M_t^n}^3.
    \end{align*}
    Ito's formula on $\norm{M_t^n}^3$ gives
    \begin{align*}
        d\norm{M_t^n}^3 & \leq 3\norm{M_t^n} \dotp{M_t^n}{dM_t^n} + \frac{3}{2}(\norm{M_t^n} \dd \tr[M_t^n] + \norm{M_t^n}^{-1} \tr (M_t^n(M_t^n)^\top d[M_t^n])) + 2\norm{\Delta M_t^n}^3\\
    \end{align*}
    At $t=k\eta^2$, there is a jump for the process $M_t^n$ as $\Delta M_t^n=\gamma_t\eta^\alpha(-M^n_{t-}+\nabla\Loss(X^n_{t-})+\mSigma^{1/2}(X^b_{t-})\xi_k)$, so for constant $C_4=12\sup_{X\in K}(\norm{\nabla\Loss(X)}+1+\norm{\mSigma^{1/2}(X)})^3$
    \begin{align*}
        \E\norm{\Delta M_{t\wedge\tau_n}^n}^3\leq C_4\eta^{3\alpha-2}(\norm{M^n_{t\wedge\tau_n}}^3+1)\dd Z_{t\wedge\tau_n}^n
    \end{align*}
    When $\alpha>0$, let $J_t^n = \eta^{\beta}\E \norm{M_t^n}^3$, as $\eta^{\beta+\alpha-2}\norm{M_t^n}\leq \eta^{3\beta/2+\alpha-2}\norm{M_t^n}^2 + \eta^{\beta/2+\alpha-2}$,there is
    \begin{align*}
        J_t^n \leq J_s^n - \int_s^t (3\lambda_{\min}\eta^{\alpha-2}- \eta^{\alpha-2+\beta/2}C_5)J_r^n \dd Z_r^n + C_5\eta^{\alpha-2+\beta/2}(Z^n_t - Z^n_s)
    \end{align*}
    where $C_5=3C_4+3(\sup_{t\leq T}|\lambda_t|)(1+\sup_{X\in K}\max(\norm{\nabla \Loss(X)}))$ is some universal constant. By \Cref{lem:gronwall-3} and \Cref{cor:gronwall-3}, there is
    \begin{align*}
        J_t^n \leq C_5 Z^n_t O(\eta^{\beta/2}).
    \end{align*}
    And the conclusion follows.
\end{proof}
\begin{lemma}
    There exist a universal constant $C$ such that
    \begin{itemize}
        \item $\norm{\Delta M_{t\wedge \tau_n}^n}\leq C\eta^{\alpha}(\norm{M_{t\wedge \tau_n}^n}+1)$.
        \item $\norm{\Delta X_{t\wedge \tau_n}^n}\leq C\eta(\norm{M_{t\wedge \tau_n}^n}+\eta^{\alpha}).$
    \end{itemize}
\end{lemma}
\begin{proof}
    Direct from the iterations \Cref{equ:sgdm-sde-main}.
\end{proof}
\begin{lemma}\label{lem:remn-term}
    When $n\to \infty$ (or $\eta\to 0$),  $\delta(t\wedge \tau_n)\to 0$ weakly for all $\alpha\in (0,1)$ and $t\in [0,T]$.
\end{lemma}
We wish to generalize the result a little bit.
\begin{lemma}\label{lem:remn-term-1}
    For any function $f\in C^3(K)$, as $n\to 0$,
   \[ \E\sup_{t\in [0,\tau_n\wedge T]} \sum_{s\in [0,t]}\left|\Delta f(X^n_s) -  
\partial f(X^n_{s-})
\Delta X^n_s - \frac{1}{2}\partial^2f (X^n_{s-})[\Delta X^n_s, \Delta X^n_s]\right|\to 0\]
\end{lemma}
\begin{proof}
    $\Delta X^n_s$ and $\Delta f(X^n_s)$ are non-zero at times $s=k\eta^2$ for $k\in\Z^+$. By the mean value theorem, there is $\theta\in [0,1]$ that
    \begin{align*} & |\Delta f(X^n_s) -\partial f(X^n_{s-})
\Delta X^n_s - \frac{1}{2}\partial^2f (X^n_{s-})[\Delta X^n_s, \Delta X^n_s]| \\
 = & \frac{1}{6} |\partial^3 f (\theta X^n_{s-} + (1-\theta)X^n_{s})[\Delta X^n_s, \Delta X^n_s,\Delta X^n_s]|\\
 \leq & \frac{1}{6} (\sup_{X\in K}\norm{\partial^3 f (X)}_F) \norm{\Delta X^n_s}^3.
 \end{align*}
Here the norm is defined for tensors as $\norm{\partial^3 f (X)}_F = \sqrt{\sum_{ijk}(\partial_i\partial_j\partial_k f (X))^2}$. The first term $\sup_{X\in K}\norm{\partial^3 f (X)}_F$ is a constant independent of $n$ (as $K$ is compact). Notice that 
\[\Delta X^n_s=-\lambda_s\eta (M_{s-}^n + \Delta M_s^n) =-\lambda_s\eta M_{s}^n.\]
Therefore there exists a constant $C=\frac{1}{6} (\sup_{X\in K}\norm{\partial^3 f (X)}_F)(\sup_{t\in [0,T]}(\lambda_t)^3)$ that 
\begin{align*}
& \E\sup_{t\in [0,\tau_n\wedge T]} \sum_{s\in [0,t]}\left|\Delta f(X^n_s) -  
\partial f(X^n_{s-})
\Delta X^n_s - \frac{1}{2}\partial^2f (X^n_{s-})[\Delta X^n_s, \Delta X^n_s]\right|\\
\leq & C \cdot  \E \sup_{t\in [0,\tau_n\wedge T]} \eta^3 \sum_{s=k\eta^2\in [0,t]}\norm{M_s^n}^3\\
\leq & C \cdot  \E \eta \int_0^{T\wedge\tau_n}\norm{M_s^n}^3 \diff Z^n_t.
\end{align*}

From \Cref{lem:momentum-1} we know $\eta \int_0^{T\wedge\tau_n}\E\norm{M_s^n}^3 \diff Z^n_t\to 0$, so the proof is done.
\end{proof}
\begin{proof}[Proof for \Cref{lem:remn-term}]
    The result follows by applying \Cref{lem:remn-term-1} to every coordinate of $\Phi(X_t^n)$.
\end{proof}
\begin{lemma} For $\alpha\in (0,1)$,
    $\lim_{n\to\infty}\eta^{\beta}\E\int_0^{t\wedge \tau_n} \norm{M_{t\wedge\tau_n}^n}^2 \dd Z^n_s=0$ for any $\beta>-\alpha$.\\
    moreover, $\sup_n \eta^{-\alpha}\E\int_0^{t\wedge \tau_n} \norm{M_{t\wedge\tau_n}^n}^2 \dd Z^n_s<\infty$\label{lem:m-bound-tight}
\end{lemma}
\begin{proof}
    Consider the energy function $G(X_t,M_t)=2\frac{\gamma_t}{\lambda_t}\Loss(X_t) + \eta^{1-\alpha} \norm{M_t}^2$, there is
    \begin{align*}
        \E G(X_t,M_t) & = \E G(X_0,M_0) + \E\int_0^t 2\frac{\gamma_t}{\lambda_t}\nabla\Loss(X_t) dX_t +2 d(\frac{\gamma_t}{\lambda_t})(\Loss(X_t)+\Delta\Loss(X_t)) \\
        & + \frac{\gamma_t}{\lambda_t}  \nabla^2\Loss(X_t) d[X]_t +d\delta\\
         & - 2\gamma_t\eta^{-1} ( \norm{M^n_t}^2  - (M^n_t)^\top\nabla \Loss(X^n_t)) \diff Z^n_t +   \\
        & +  \gamma_t^2\eta^{\alpha-1}\norm{M^n_t-\nabla\Loss(X^n_t)}^2 \diff Z^n_t + \gamma_t^2\eta^{\alpha-1} \tr (\mSigma(X^n_t) \dd[Y^n]_t)  \\
        & = G(X_0,M_0) +  A_t - \int_0^t 2\gamma_t\eta^{-1}  \E\norm{M^n_t}^2  \diff Z^n_t    \\
        & +   \int_0^t\gamma_t^2\eta^{\alpha-1}\E\norm{M^n_t-\nabla\Loss(X^n_t)}^2 \diff Z^n_t + \gamma_t^2\eta^{\alpha-1} \tr (\mSigma(X^n_t) \dd[Y^n]_t) 
    \end{align*}
    Here $A_t$ is some uniformly bounded process. Multiply both sides by $\eta^{1-\alpha}$ gives 
    \begin{align*}
        \int_0^t 2\gamma_t\eta^{-\alpha}  \E\norm{M^n_t}^2  \diff Z^n_t & \leq \eta^{1-\alpha}\E G(X_0,M_0) + \eta^{1-\alpha} A_t \\
        & +   \int_0^t\gamma_t^2\E\norm{M^n_t-\nabla\Loss(X^n_t)}^2 \diff Z^n_t + \gamma_t^2 \tr (\mSigma(X^n_t) \dd[Y^n]_t).
    \end{align*}
    From \Cref{lem:momentum-1} we know the right-hand-side is uniformly bounded in $n$, and the conclusion follows.
\end{proof}

\subsubsection{Convergence to the Manifold}
We wish to show that the process $X^n_{t\wedge\tau_n}\to \Phi^n_{t\wedge\tau_n}$ as $n\to\infty$ for any $t>0$. 
First we need to show that as the learning rate $\eta\to 0$, there is a distance function $d$ that $d(\Phi_t, \Gamma)\to 0$ weakly as a stochastic process. 
\begin{lemma}\label{lem:conver-to-mani}
    As $n\to \infty$, $d(\Phi_t, \Gamma)\to 0$ weakly for all $\alpha\in (0,1)$.
\end{lemma}
\begin{proof}
    By \Cref{lem:katzen-results}, we need to prove that for all $T>0$, $\sup_{t\leq T} h(X_{t\wedge \tau_n})\to 0$ in probability.

    Ito's formula on $h(X_{t\wedge \tau_n})$ gives for some process $\delta\to 0$ ($n\to \infty$)
    \begin{align*}
        dh(X_t) & = \dotp{\nabla h(X_t)}{dX_t} + \frac{1}{2} \nabla^2 h(X_t) d[X]_t + d\delta \\
        & = \dotp{\nabla h(X_t)}{-\lambda_t\eta \diff M^n_t  +(\lambda_t/\gamma_t)\eta^{1-\alpha} \diff M^n_t -\lambda_t \eta^{-1}
\nabla \Loss(X^n_t) \diff Z^n_t -\lambda_t \mSigma^{1/2}(X^n_t)\diff Y^n_t}\\
&+ \frac{1}{2} \nabla^2 h(X_t) d[X]_t + d\delta\\
    \end{align*}
    Let the process 
    \[dS_t = \dotp{\nabla h(X_t)}{-\lambda_t\eta \diff M^n_t  +(\lambda_t/\gamma_t)\eta^{1-\alpha} \diff M^n_t -\lambda_t \mSigma^{1/2}(X^n_t)\diff Y^n_t}
+ \frac{1}{2} \nabla^2 h(X_t) d[X]_t + d\delta,\] there is
\begin{align*}
    dh(X_t) & = dS_t -\lambda_t\eta^{-1}\dotp{\nabla h(X_t)}{\nabla\Loss(X_t)}dZ_t\\
    & \leq dS_t - \lambda_{\min} c^{-1} \eta^{-1} h(X_t)dZ_t
\end{align*}
Therefore by \Cref{lem:gronwall-3}, for $\kappa = \eta^{-2}\log(1+\lambda_{\min} c^{-1} \eta )$, there is
\[h(X_t)\leq e^{-\kappa Z_t}S_t + (\lambda_{\min} c^{-1} \eta^{-1})\int_0^t e^{-\kappa (Z_t-Z_s)}(S_t-S_s) dZ_s\]
Clearly $e^{-\kappa Z_t}S_t\to 0$. Furthermore we have for 
\[A_t = \int_0^{t\wedge\tau_n} (-\lambda_t\eta +(\lambda_t/\gamma_t)\eta^{1-\alpha})\dotp{\nabla h(X_t)}{\diff M^n_t}\]
\[B_t = \int_0^{t\wedge\tau_n} \dotp{\nabla h(X_t)}{ -\lambda_t \mSigma^{1/2}(X^n_t)\diff Y^n_t}\]
\[C_t = \int_0^{t\wedge\tau_n}\frac{1}{2} \nabla^2 h(X_t) d[X]_t + d\delta\]
we know $S_t = A_t+B_t +C_t$ .

First, we show $\eta^{-1}\int_0^te^{-\kappa (Z_t-Z_s)}(A_t-A_s)dZ_s\to 0$. as $A_t-A_s\leq \int_s^t K [\eta^{-1}(\norm{M_r} + 1)dZ_r + dY_r]$ for some constant $K$, we know by \Cref{cor:gronwall-3} and \Cref{lem:momentum-1},
\[\eta^{-2}\sup_r\norm{M_r}\int_0^te^{-\kappa (Z_t-Z_s)}(Z_t-Z_s)dZ_s\leq \eta^{-2}{\kappa}^{-2}\sup_r\norm{M_r} \leq \eta^{2}\sup_r\norm{M_r}\to 0\]
and since $\E\sup_{r}\norm{Y_t-Y_s}\leq 2\sqrt{\E \norm{Y_t}^2}\leq K t$, there is
$\E\sup_n\eta^{-1}|\int_0^te^{-\kappa (Z_t-Z_s)}(Y_t-Y_s)dZ_s|\leq \frac{Kt}{\kappa\eta}\to 0$.

Next, we show $\eta^{-1}\int_0^te^{-\kappa (Z_t-Z_s)}(B_t-B_s)dZ_s\to 0$. $B_t-B_s$ is a martingale so by Doob's inequality, $\E\sup_{r}|B_t-B_r|\leq 2\sqrt{\E |B_t|^2}\leq K t$ for some constants $K$. Therefore $\E\sup_n\eta^{-1}|\int_0^te^{-\kappa (Z_t-Z_s)}(B_t-B_s)dZ_s|\leq \frac{Kt}{\kappa\eta}\to 0$.

Finally, there exists constant $K$ such that $\eta^{-1}\int_0^te^{-\kappa (Z_t-Z_s)}(C_t-C_s)dZ_s \leq \eta^{-1}\int_0^te^{-\kappa (Z_t-Z_s)}K(Z_t-Z_s)dZ_s \leq \frac{K}{\eta\kappa^2}\to 0$ by \Cref{cor:gronwall-3}. Therefore we concludes the proof by showing that $h(X_t)\to 0$.
\end{proof}
\subsection{Averaging}
\begin{lemma}\label{lem:ave-1}
    $\lim_{n\to\infty} \eta^{\beta}\E \sup_{t\leq T}|\int_0^{t\wedge\tau_n}\partial^2\Phi(X_s^n)[\nabla\Loss(X_s^n)(M_s^n)^\top]\dd Z_s^n|= 0$ for any $\beta>-1$.
\end{lemma}
To prove the result we need another lemma.
\begin{lemma}\label{lem:ave-2}
    $\lim_{n\to\infty} \eta^{\beta}\E \sup_{t\leq T}|\int_0^{t\wedge\tau_n}\norm{\nabla\Loss(X_s^n)}^2\dd Z_s^n|= 0$ for any $\beta>-1$.
\end{lemma}
\begin{proof}
    Use Ito on $\dotp{\nabla\Loss(X_t)}{M_t}$, there is
    \begin{align*}
         d\dotp{\nabla\Loss(X_t)}{M_t} & = -\lambda_t \partial^2\Loss(X_t)[ \eta^{-1} M_t M_t^\top dZ_t+ \eta M_t dM_t^\top] + \dotp{\Delta\nabla\Loss(X_t) }{\Delta M_t}\\
         & +\gamma_t\nabla\Loss(X_t)[\eta^{-2+\alpha}(\nabla\Loss(X_t) - M_t) dZ_t +\eta^{-1+\alpha}\mSigma^{1/2}(X_t) dY_t ].
    \end{align*}
    Therefore we know there exists constant $K$ such that
    \begin{align*}
        \E\int_0^{t\wedge\tau_n}\norm{\nabla\Loss(X_s)}^2 dZ_s & \leq K\eta^{2-\alpha}\E(\dotp{\nabla\Loss(X_{t\wedge\tau_n})}{M_{t\wedge\tau_n}}-\dotp{\nabla\Loss(X_0)}{M_0})\\
        & + \eta^{1-\alpha}K\E\int_0^{t\wedge\tau_n} \norm{M_s}^2 dZ_s + K\eta^{3}\E\sum_{\Delta M_t\neq 0} \norm{ M_t}^2\\
        & + \E\int_0^{t\wedge\tau_n}\dotp{\nabla\Loss(X_t)}{M_t}dZ_t. 
    \end{align*}
    The first four terms vanishes when multiplied $\eta^{\beta}$ for $\beta>-1$ by \Cref{lem:m-bound-tight}. Note the last term
    \begin{align*}
        \int_0^{t\wedge\tau_n}\dotp{\nabla\Loss(X_t)}{M_t}dZ_t & = \int_0^{t\wedge\tau_n}\dotp{\nabla\Loss(X_t)}{-\eta \lambda_t^{-1} dX_t -\eta^2 dM_t}
    \end{align*}
    so 
    \[\lambda_t^{-1}\dotp{\nabla\Loss(X_t)}{ dX_t}=d(\lambda_t^{-1}\Loss(X_t))- (\Delta\lambda_t^{-1})(\Delta \Loss(X_t)+\Loss(X_t)) -\frac{1}{2}\lambda_t^{-1}\partial^2\Loss(X_t)[d[X]_t] - d\delta.\] 
    $\lambda_t^{-1}\dotp{\nabla\Loss(X_t)}{ dX_t}$ is clearly a bounded process given the bounded variation of $\lambda_t^{-1}$ and boundedness of $X_{t\wedge \tau_n}$. Thereby we finished the proof.
\end{proof}
\begin{proof}[Proof of \Cref{lem:ave-1}]
    Let $f(X_s)=\partial^2\Phi(X_s)\nabla\Loss(X_s)$.
    
    Ito's formula on $\partial^2\Phi(X_s)[\nabla\Loss(X_s)(M_s)^\top] = f(X_s)M_s$ gives
    \begin{align*}
        d(f(X_s)M_s) & =df(X_s)M_s + f(X_s) dM_s  + \Delta f(X_s) \Delta M_s\\ 
        & = df(X_s) M_s + \Delta f(X_s) \Delta M_s\\
        & -\gamma_s\eta^{\alpha-2} f(X_s)(M_s-\nabla \Loss(X_s))dZ_s + \gamma_s\eta^{\alpha-1} f(X_s)\mSigma^{1/2}(X_s) dY_s .
    \end{align*}
    Therefore there is constant $K$ such that
    \begin{align*}
        & \int_0^t f(X_s) M_s dZ_s\leq \int_0^t f(X_s)\nabla\Loss (X_s)dZ_s\\
   & + K(\int_0^t \eta^{2-\alpha}df(X_s)M_s + \eta f(X_s)\mSigma^{1/2}(X_s) dY_s+\eta^{2-\alpha}\sum \Delta f(X_s) \Delta M_s)
    \end{align*}
    We know that $\eta^{2-\alpha}\sum \Delta f(X_s) \Delta M_s=O(\eta)$ and $\sup_t\int_0^t\eta f(X_s)\mSigma^{1/2}(X_s) dY_s = O(\eta)$. Expansion gives $\int_0^t \eta^{2-\alpha}df(X_s)M_s = O(\eta)$ by \Cref{lem:m-bound-tight}. Finally by \Cref{lem:ave-2} we obtain the desired result.
\end{proof}
Let $\phi_t =  \lambda_t/\gamma_t-\eta^\alpha\lambda_t$.
\begin{lemma}\label{lem:aver-1}
$\int_{c_1}^{c_2} [\eta^{1-\alpha}\phi_t \partial\Phi(X_t) \dd M_t+\phi_t\lambda_t(\eta^{-\alpha} - \lambda_t)\partial^2\Phi(X_t) [M_t M_t^\top]\dd Z_t \to 0$ as $\eta\to 0$.
\end{lemma}
\begin{proof}
     Ito's formula on $\eta^{1-\alpha}\phi_t\partial\Phi(X_t)M_t$ gives
    \begin{align*}
        \dd(\phi_t\partial\Phi(X_t)M_t) &=  \dd(\phi_t) \partial\Phi(X_t)M_t + (\Delta \phi_t)\Delta (\partial\Phi(X_{t-}) M_t)+ \phi_t \partial\Phi(X_t) \dd M_t\\
        &+\phi_t \partial^2\Phi(X_t) [M_t\dd X_t^\top] +\phi_t \Delta\partial\Phi(X_{t})\Delta  M_t+\dd\delta\\
    \end{align*}
    where \[\dd \delta = \phi_t (\Delta\partial\Phi(X_t) - \partial^2\Phi(X_{t-})\Delta X_t)M_t\]
    We know for $\alpha\in (0,1)$,  by \Cref{lem:momentum-1}
    \begin{itemize}
        \item $\eta^{1-\alpha}\delta\to 0$ as $|\delta_t| \leq C \int_0^t \norm{M_s}^3 \dd Z_s$.
        \item $\int \eta^{1-\alpha}\dd(\phi_t) \partial\Phi(X_t)M_t\to 0$ as $\int \dd(\phi_t)<\infty$ by \Cref{ass:finite-var} and $\sup_t \eta^{1-\alpha} \norm{M_t}\to 0$.
        \item $ \sum\eta^{1-\alpha}(\Delta \phi_t)\Delta (\partial\Phi(X_{t-}) M_t)\to 0$ as $\sum_t \Delta \phi_t<\infty$ by \Cref{ass:finite-var} and $\int \eta^{1-\alpha} \norm{M_t}\to 0$.
        \item $\int \eta^{1-\alpha}\phi_t \partial^2\Phi(X_t) [M_t\dd X_t^\top] +\int \eta^{-\alpha}\phi_t\lambda_t \partial^2\Phi(X_t) [M_t M_t^\top]\dd Z_t\to 0$
        \item $\sum \eta^{1-\alpha}\phi_t \Delta\partial\Phi(X_{t})\Delta M_t -\int \phi_t \lambda_t\gamma_t \partial^2\Phi(X_t)[M_t,M_t-\nabla\Loss(X_t)]\dd Z_t \to 0$
        \item $\eta^{1-\alpha} \phi_t \partial\Phi(X_t)M_t\to 0$
    \end{itemize}
    
    Therefore adding them up we obtain the result.
    %$$\[ -\eta^{1-\alpha}\dd(\phi_t\partial\Phi(X_t)M_t)+\eta^{1-\alpha}\phi_t \partial^2\Phi(X_t) [M_t\dd X_t^\top] + \eta^{1-\alpha}\phi_t \partial\Phi(X_t) \dd M_t+\eta^{1-\alpha}\phi_t \partial^2\Phi(X_{t})[\dd [X_t,M_t]]\to 0\]
\end{proof}

\begin{lemma}
    $|\int_0^{t\wedge \tau_n}\partial^2 \Phi(X_s) [\dd[X]_s]-\int_0^{t\wedge \tau_n}\lambda_t^2\partial^2 \Phi(X_s) [M_tM_t^\top]\dd Z_t|\to 0$.\label{lem:aver-2}
\end{lemma}
\begin{proof}
    This  follows directly by the expansion of $[X]_t$ and \Cref{lem:momentum-1}.
\end{proof}
\begin{lemma}
$\sup_{c_1,c_2}\left|\int_{c_1}^{c_2}\frac{\lambda^2_t/\gamma_t}{\eta^\alpha} \partial^2\Phi(X_t)[M_t,M_t]\dd Z_t  - \int_{c_1}^{c_2}\frac{\lambda_t^2}{2}\partial^2\Phi(X_t)[\mSigma(X_t)]\dd t\right|\to 0$ as $\eta\to 0$.\label{lem:aver-3}
\end{lemma}
\begin{proof}
 let $A_t =\phi_t \partial^2\Phi(X_t)[M_t,M_t]$ for some schedule $\phi_t$, then for some uniformly bounded process $B_t$,
 \begin{align}\dd A_t & = d(\phi_t) (\partial^2\Phi(X_t)[M_t,M_t]+\Delta \partial^2\Phi(X_t)[M_t,M_t]) + \eta^{3\alpha-2}dB_t \\
 &- \frac{\phi_t\lambda_t}{\eta}\partial^3\Phi(X_t)[M_t,M_t,M_t] \diff Z_t + \frac{\gamma^2_t\phi_t}{\eta^{2-2\alpha}}\partial^2\Phi(X_t)[\mSigma(X_t)^{1/2}\dd [Y]_t\mSigma(X_t)^{1/2}]\\
 &  -  \frac{2\phi_t\gamma_t}{\eta^{2-\alpha}}\partial^2\Phi(X_t)[ M_t,M_t]\diff Z_t+\frac{2\phi_t\gamma_t}{\eta^{2-\alpha}}\partial^2\Phi(X_t)[ \nabla L(X_t), M_t]\diff Z_t \\
 & + \frac{2\phi_t\gamma_t}{\eta^{1-\alpha}}\partial^2\Phi(X_t)[\mSigma^{1/2}(X_t)\diff Y_t,M_t]\\
 & - \frac{2\phi_t\gamma_t^2}{\eta^{1-2\alpha}}\partial^2\Phi(X_t)[(M_t-\nabla\Loss(X_t))dY_t^\top \mSigma^{1/2}(X_t)]\\
 & + \gamma_t^2\eta^{2\alpha-2}  \phi_t\partial^2\Phi(X_t)[(M_t-\nabla\Loss(X_t))(M_t-\nabla\Loss(X_t))^\top]\diff Z_t.
 \end{align}
 Multiply both sides by $\eta^{2\alpha-2}$, by \Cref{lem:ave-1,lem:ave-2} we know $\int \partial^2\Phi(X_t)[\nabla\Loss(X_t)M_t^\top]\diff Z_t$ and $\int \partial^2\Phi(X_t)[\nabla\Loss(X_t)\nabla\Loss(X_t)^\top]\diff Z_t$ converges to 0. Bound the Martingale $W_t$ that
 \[dW_t = 2\phi_t\gamma_t\eta^{1-\alpha}\partial^2\Phi(X_t)[\mSigma^{1/2}(X_t)\diff Y_t,M_t] -2\phi_t\gamma_t^2\eta\partial^2\Phi(X_t)[(M_t-\nabla\Loss(X_t))dY_t^\top \mSigma^{1/2}(X_t)],\]
 Doob's inequality alongside with \Cref{lem:momentum-1} shows $W_t\to 0$. Then we know with $\phi_t=\lambda^2_t/\gamma_t^2$ that 
 \[\sup_{c_1,c_2}\left|\int_{c_1}^{c_2}\frac{\lambda^2_t/\gamma_t}{\eta^\alpha} \partial^2\Phi(X_t)[M_t,M_t]\dd Z_t  - \int_{c_1}^{c_2}\frac{\lambda_t^2}{2}\partial^2\Phi(X_t)[\mSigma(X_t)]\dd t\right|\to 0\]
\end{proof}
Finally we are ready to show the limiting dynamics as

\begin{theorem}\label{thm:sgdm-slow-sde-main}
    For any $t>0$, $(X^{n}_{t\wedge \tau_n},\tau_n)$ converges in distribution to $(X_{t\wedge \tau},\tau)$ that $\tau=\inf\{t>0:X_t\not\in K\}$, and that
    \[X_t = \Phi(\vx_0) + \int_0^t\lambda_t \partial\Phi(X_s)\mSigma^{1/2}(X_s)\dd W_s +\int_0^t\frac{\lambda_t^2}{2}\partial^2\Phi(X_s)[\mSigma(X_s)]\dd s.\]
\end{theorem}
\begin{proof}
    Recall the process $\Phi_t$ as
    \begin{align*}
     \dd \Phi_t  & =  \partial \Phi(X_t)((-\lambda_t\eta+ \lambda_t\eta^{1-\alpha}/\gamma_t)\diff M_t -\lambda_t \mSigma^{1/2}(X_t)dY_t) + \frac{1}{2}\partial^2 \Phi(X_t) [\dd[X]_t] +\diff\delta
    \end{align*}
    Therefore we know
    \begin{align*}
        X_{t\wedge \tau_n} & = \Phi(\vx_0) + (X_{t\wedge \tau_n} - \Phi_{t\wedge \tau_n}) + \delta_t \\
        & + \int_0^{t\wedge \tau_n} \partial \Phi(X_t)((-\lambda_t\eta+ \lambda_t\eta^{1-\alpha}/\gamma_t)\diff M_t -\lambda_t \mSigma^{1/2}(X_t)dY_t) + \frac{1}{2}\partial^2 \Phi(X_t) [\dd[X]_t].
    \end{align*}
    By \Cref{lem:conver-to-mani} we know the process $X_t-\Phi_t$ weakly converges to zero. By \Cref{lem:remn-term} we know $\delta_t\to 0$. By \Cref{lem:aver-1,lem:aver-2,lem:aver-3} we know
    \[|\int_0^{t\wedge \tau_n} \partial \Phi(X_t)((-\lambda_t\eta+ \lambda_t\eta^{1-\alpha}/\gamma_t)\diff M_t + \frac{1}{2}\partial^2 \Phi(X_t) [\dd[X]_t] -  \int_0^{t\wedge \tau_n}\frac{\lambda_t^2}{2}\partial^2\Phi(X_s)[\mSigma(X_s)]\dd [Y]_s|\to 0.\]
    We know the process $Y^n_t$ and $Z^n_t$ are of bounded quadratic variation. Furthermore by the central limit theorem $Y^n_t\to W_t$ where $W_t$ is a Brownian motion, and $Z^n_t\to t$. By the law of large numbers we know $[Y^n]_t\to t$. Additionally, the process $X_t^n$, $Z^n_t$ and $Y^n_t$ always share jumps at the same locations. This implies we can write
    \[X^n_{t} = X_0 + P^n_{t} + \int_0^{t} F_n(X^n_s)\dd Y^n_{s} + G_n(X^n_s)\dd [Y^n]_{s} + H_n(X^n_s) \dd Z^n_s.\]
    Notice that the tuple $(P^n_{t} ,Y^n_{t},[Y^n]_{t},Z^n_t,F_n(X_t),G_n(X_t),H_n(X_t),\tau_n)$ converges in the uniform metric to $(0,W_t,t,t,F(X_t),G(X_t),H(X_t),\tau(X_t))$ for any process $X_t$, then by \Cref{thm:weak-limit}, the limit of $X^n_t$ can be denoted by
    \[X_{t} = X_0 +\int_0^{t} F(X_s)\dd W_s + G(X_s)\dd s + H(X_s) \dd s.\]
    Plugging in the above results gives the limit
    \[X_t = \Phi(\vx_0) + \int_0^t\lambda_t \partial\Phi(X_s)\mSigma^{1/2}(X_s)\dd W_s +\int_0^t\frac{\lambda_t^2}{2}\partial^2\Phi(X_s)[\mSigma(X_s)]\dd s.\] 
\end{proof}
\begin{proof}[Proof for \Cref{thm:slow-sde-formal}]
    The result is a natural corollary of \Cref{thm:sgd-slow-sde-main} and \Cref{thm:sgdm-slow-sde-main}.
\end{proof}