\section{Preliminaries}

% \subsection{Stochastic Gradient Methods}
Consider optimizing a loss function $\cL = \frac{1}{\Xi} \sum_{i = 1}^{\Xi} \cL_i$ where $\cL_i:\RR^d\to\RR$ corresponds to the loss on the $i$-th sample.
We use $\vtheta$ to indicate parameters along a general trajectory.
In each step, we sample a random minibatch $\cB \subseteq [\Xi]$, and compute the gradient of the minibatch loss $\cL_\cB = \frac{1}{|\cB|} \sum_{i\in\cB} \cL_i$ to get the following noisy estimate of $\nabla \cL(\btheta)$, i.e.,
    $\nabla\cL_\cB(\btheta) = \frac{1}{|\cB|} \sum_{i\in\cB} \nabla\cL_i(\btheta)$.
It is easy to check that the noise covariance matrix of $\nabla \cL_{\cB}(\btheta)$, namely 
$\E_{\mathcal{B}} (\nabla
\Loss_{\mathcal{B}}(\vtheta) - \nabla \Loss(\vtheta))(\nabla \Loss_{\mathcal{B}}(\vtheta) - \nabla
\Loss(\vtheta))^\top$,
scales proportionally to $\frac{1}{|\cB|}$. Motivated by this, \citet{malladi2022sdes}
abstracts $\nabla \cL_{\cB}(\btheta)$ as sampled from a noisy gradient oracle where the noise covariance depends on a scale parameter.
%\runzhe{elaborate why we need to augment noise}
%To ease the presentation, we adopt the following abstraction for the stochastic gradient given in~\citet{malladi2022sdes}.
\begin{definition}[NGOS,~\citet{malladi2022sdes}] \label{def:NGOS}
	%[Noisy Gradient Oracle with Scale Parameter, NGOS]\label{def:NGOS}
    A {\em Noisy Gradient Oracle with Scale Parameter} (NGOS) is
    characterized by a tuple $\cG_{\sigma} = (\cL, \mSigma, \DatZ_{\sigma})$. For a
    scale parameter $\sigma > 0$, $\cG_{\sigma}$ takes as input $\vtheta$ and returns $\vg
    =\nabla \cL(\vtheta) + \sigma \vv$, where $\nabla \cL(\vtheta)$ is the gradient of
    $\cL$ at $\vtheta$, $\vv$ is the gradient noise drawn from the probability distribution
    $\DatZ_{\sigma}(\vtheta)$ with mean zero and covariance matrix $\mSigma(\vtheta)$.
    The matrix $\mSigma(\vtheta)$ is independent of the noise scale $\sigma$.
    We use $\cG_{\sigma}(\vtheta)$ to denote the distribution of $\vg$ given $\sigma$ and $\vtheta$.
\end{definition}

In our work we invoke NGOS with different $\sigma$ for different magnitudes of the learning rate, so that we can augment the noise level when the learning rates are set smaller. The scaling is discussed after \Cref{lem:descent}.
%Here $\nabla\cL_\cB(\btheta)$ is a noisy estimate of $\nabla\cL(\btheta)$.
%In the setting of mini-batch stochastic gradient descent, the covariance matrix is given by
%\begin{align*}
    %\mSigma(\vtheta)  = |\mathcal{B}|\cdot\E_{\mathcal{B}} (\nabla
%\Loss_{\mathcal{B}}(\vtheta) - \nabla \Loss(\vtheta))(\nabla \Loss_{\mathcal{B}}(\vtheta) - \nabla
%\Loss(\vtheta))^\top.
%\end{align*}
%$\mSigma(\vtheta)$ is fixed across different mini-batch sizes.
%In particular, we assume that the noise oracle already has small higher-order moments, which~\citep{li2021validity,malladi2022sdes} show can be ensured by computing the loss as a linear combination of two losses measured on different mini-batches.
We now instantiate the SGD and SGDM trajectories under this noise oracle.
\begin{definition}[Vanilla SGD]
	Given a stochastic gradient $\vg_k\sim\cG_\sigma(\vz_k)$, minibatch SGD with the learning rate schedule $\{\bar{\eta}_k\}$ updates the parameters $\vz_k\in\RR^d$ from initialization $\vz_0$ as
\begin{align}
    \vz_{k+1} = \vz_k - \bar{\eta}_k\vg_k. \label{def:sgd}	
\end{align}	
\end{definition}
\begin{definition}[SGD with momentum/SGDM]\label{def:SGDM}
Given a stochastic gradient $\vg_k\sim\cG_\sigma(\vx_k)$ minibatch SGDM with the hyperparameter schedule $\{(\eta_k,\beta_k)\}$, where $\beta_k\in (0,1)$, updates the parameters $\vx_k\in\RR^d$ from $(\vm_0,\vx_0)$ as\label{def:sgdm}
\begin{align}\label{dqu:sgdm-1}
		\vm_{k+1} = \beta_{k}\vm_{k} + (1-\beta_{k})\vg_{k}, \qquad
		\vx_{k+1} = \vx_{k} - \eta_{k}\vm_{k+1}.
	\end{align}
\end{definition}
Notice that the formulation SGDM in \Cref{def:SGDM} is different from \eqref{equ:SGDM-intro}. An easy conversion is given by rewriting \Cref{dqu:sgdm-1} as: 
\[\vx_{k+1} = \vx_k - \eta_k(1-\beta_k) \vg_k + \beta_k\frac{\eta_k}{\eta_{k-1}}(\vx_k-\vx_{k-1}).\]
Then setting $\eta_k=\frac{\gamma}{1-\beta}$ and $\beta_k=\beta$ recovers the form of  \eqref{equ:SGDM-intro}. $\eta_k$ is arguably a more natural parameterization that is under the same scale of  the learning rates of SGD for comparison. %in our results.

Modeling the gradient noise as an NGOS gives us the flexibility to scale the noise in our theoretical setting to make the effect of noise non-vanishing in small learning rate training. This is motivated by the following variant of the standard descent lemma, which highlights noise-induced and curvature-induced factors that prevent the loss to decrease:
\begin{lemma}[Descent Lemma]\label{lem:descent}
    For the SGD updates $\vz_k$, the expected change in loss per step is 
    \begin{align*}        &\E[\Loss(\vz_{k+1})|\vz_k] - \Loss(\vz_{k})  =\\
     &\qquad\underbrace{ - \eta \norm{\nabla \Loss(\vz_{k})}^2}_\text{descent force} + \underbrace{\frac{1}{2}(\sigma\eta)^2\tr((\nabla^2\Loss)\mSigma(\vz_k))}_\text{noise-induced} + \underbrace{\frac{1}{2}\eta^2(\nabla\Loss^\top(\nabla^2\Loss)\nabla\Loss(\vz_k))}_\text{curvature-induced}+o(\eta^2, (\sigma\eta)^2).
    \end{align*}
\end{lemma}
When scaling down the learning rate, the descent force scales with $O(\eta)$ and the noise-induced impact scales with $O(\sigma^2\eta^2)$, therefore we need to set $\sigma=1/\sqrt{\eta}$ to ensure that noises maintain the same scale of effect across different scales of $\eta$. When $\eta\to 0$ under this scaling, if we consider running the updates for $O(1/\eta)$ steps, only the curvature-induced impact is vanishing among the three. 

