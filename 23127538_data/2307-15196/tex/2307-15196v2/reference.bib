@inproceedings{
ghosh2023implicit,
title={Implicit regularization in Heavy-ball momentum accelerated stochastic gradient descent},
author={Avrajit Ghosh and He Lyu and Xitong Zhang and Rongrong Wang},
booktitle={The Eleventh International Conference on Learning Representations },
year={2023},
url={https://openreview.net/forum?id=ZzdBhtEH9yB}
}

@article{liu2018diffusion,
  title={A diffusion approximation theory of momentum sgd in nonconvex optimization},
  author={Liu, Tianyi and Chen, Zhehui and Zhou, Enlu and Zhao, Tuo},
  journal={arXiv preprint arXiv:1802.05155},
  year={2018}
}

@article{li2022fast,
  title={Fast Mixing of Stochastic Gradient Descent with Normalization and Weight Decay},
  author={Li, Zhiyuan and Wang, Tianhao and Yu, Dingli},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={9233--9248},
  year={2022}
}
@article{fu2023and,
  title={When and Why Momentum Accelerates SGD: An Empirical Study},
  author={Fu, Jingwen and Wang, Bohan and Zhang, Huishuai and Zhang, Zhizheng and Chen, Wei and Zheng, Nanning},
  journal={arXiv preprint arXiv:2306.09000},
  year={2023}
}
@article{wen2022does,
  title={How Does Sharpness-Aware Minimization Minimize Sharpness?},
  author={Wen, Kaiyue and Ma, Tengyu and Li, Zhiyuan},
  journal={arXiv preprint arXiv:2211.05729},
  year={2022}
}

@inproceedings{socher2013recursive_sst-2,
    title = "Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank",
    author = "Socher, Richard  and
      Perelygin, Alex  and
      Wu, Jean  and
      Chuang, Jason  and
      Manning, Christopher D.  and
      Ng, Andrew  and
      Potts, Christopher",
    url="https://aclanthology.org/D13-1170.pdf",
    booktitle = emnlp,
    year = "2013",
}

@inproceedings{he2016deep,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={770--778},
  year={2016}
}

@article{cifar10,
title= {{CIFAR}-10 ({C}anadian {I}nstitute for {A}dvanced {R}esearch)},
journal= {},
author= {Alex Krizhevsky and Vinod Nair and Geoffrey Hinton},
year= {},
url= {http://www.cs.toronto.edu/~kriz/cifar.html},
keywords= {Dataset},
terms= {}
}

@inproceedings{williams2018broad_mnli,
    title = "A Broad-Coverage Challenge Corpus for Sentence Understanding through Inference",
    author = "Williams, Adina  and
      Nangia, Nikita  and
      Bowman, Samuel",
    booktitle = naacl_hlt,
    year = "2018",
    url="https://aclanthology.org/N18-1101.pdf"
}


@inproceedings{voorhees2000building_trec,
  title={Building a question answering test collection},
  author={Voorhees, Ellen M and Tice, Dawn M},
  booktitle={the 23rd annual international ACM SIGIR conference on Research and development in information retrieval},
  year={2000}
}

@inproceedings{bowman2015large,
    title = "A large annotated corpus for learning natural language inference",
    author = "Bowman, Samuel R.  and
      Angeli, Gabor  and
      Potts, Christopher  and
      Manning, Christopher D.",
    booktitle = "Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing",
    month = sep,
    year = "2015",
    address = "Lisbon, Portugal",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D15-1075",
    doi = "10.18653/v1/D15-1075",
    pages = "632--642",
}

@article{liu2022same,
  title={Same Pre-training Loss, Better Downstream: Implicit Bias Matters for Language Models},
  author={Liu, Hong and Xie, Sang Michael and Li, Zhiyuan and Ma, Tengyu},
  journal={arXiv preprint arXiv:2210.14199},
  year={2022}
}

@inproceedings{arora2022understanding,
  title={Understanding gradient descent on the edge of stability in deep learning},
  author={Arora, Sanjeev and Li, Zhiyuan and Panigrahi, Abhishek},
  booktitle={International Conference on Machine Learning},
  pages={948--1024},
  year={2022},
  organization={PMLR}
}

@article{katzenberger1991solutions,
  title={Solutions of a stochastic differential equation forced onto a manifold by a large drift},
  author={Katzenberger, Gary Shon},
  journal={The Annals of Probability},
  pages={1587--1628},
  year={1991},
  publisher={JSTOR}
}

@inproceedings{gao-etal-2021-making,
    title = "Making Pre-trained Language Models Better Few-shot Learners",
    author = "Gao, Tianyu  and
      Fisch, Adam  and
      Chen, Danqi",
    booktitle = "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)",
    year = "2021",
    url = "https://aclanthology.org/2021.acl-long.295",
    doi = "10.18653/v1/2021.acl-long.295",
    pages = "3816--3830",
}

@misc{malladi2023kernelbased,
      title={A Kernel-Based View of Language Model Fine-Tuning}, 
      author={Sadhika Malladi and Alexander Wettig and Dingli Yu and Danqi Chen and Sanjeev Arora},
      year={2023},
      eprint={2210.05643},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@article{liu2019roberta,
  title={Roberta: A robustly optimized bert pretraining approach},
  author={Liu, Yinhan and Ott, Myle and Goyal, Naman and Du, Jingfei and Joshi, Mandar and Chen, Danqi and Levy, Omer and Lewis, Mike and Zettlemoyer, Luke and Stoyanov, Veselin},
  journal={arXiv preprint arXiv:1907.11692},
  year={2019},
  url="https://arxiv.org/pdf/1907.11692.pdf"
}

@article{ghadimi2016accelerated,
  title={Accelerated gradient methods for nonconvex nonlinear and stochastic programming},
  author={Ghadimi, Saeed and Lan, Guanghui},
  journal={Mathematical Programming},
  volume={156},
  number={1-2},
  pages={59--99},
  year={2016},
  publisher={Springer}
}

@article{yuan2016influence,
  title={On the influence of momentum acceleration on online learning},
  author={Yuan, Kun and Ying, Bicheng and Sayed, Ali H},
  journal={The Journal of Machine Learning Research},
  volume={17},
  number={1},
  pages={6602--6667},
  year={2016},
  publisher={JMLR. org}
}

@article{qian1999momentum,
  title={On the momentum term in gradient descent learning algorithms},
  author={Qian, Ning},
  journal={Neural networks},
  volume={12},
  number={1},
  pages={145--151},
  year={1999},
  publisher={Elsevier}
}

@article{cowsik2022flatter,
  title={Flatter, faster: scaling momentum for optimal speedup of SGD},
  author={Cowsik, Aditya and Can, Tankut and Glorioso, Paolo},
  journal={arXiv preprint arXiv:2210.16400},
  year={2022}
}

@article{gronwall1919note,
  title={Note on the derivatives with respect to a parameter of the solutions of a system of differential equations},
  author={Gronwall, Thomas Hakon},
  journal={Annals of Mathematics},
  pages={292--296},
  year={1919},
  publisher={JSTOR}
}

@article{paszke2019pytorch,
  title={Pytorch: An imperative style, high-performance deep learning library},
  author={Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and others},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

@article{goyal2017accurate,
  title={Accurate, large minibatch {SGD}: Training imagenet in 1 hour},
  author={Goyal, Priya and Doll{\'a}r, Piotr and Girshick, Ross and Noordhuis, Pieter and Wesolowski, Lukasz and Kyrola, Aapo and Tulloch, Andrew and Jia, Yangqing and He, Kaiming},
  journal={arXiv preprint arXiv:1706.02677},
  year={2017}
}

@inproceedings{li2019convergence,
  title={On the Convergence of FedAvg on Non-IID Data},
  author={Li, Xiang and Huang, Kaixuan and Yang, Wenhao and Wang, Shusen and Zhang, Zhihua},
  booktitle={International Conference on Learning Representations},
  year={2019}
}

@article{woodworth2020minibatch,
  title={Minibatch vs {Local SGD} for heterogeneous distributed learning},
  author={Woodworth, Blake E and Patel, Kumar Kshitij and Srebro, Nati},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={6281--6292},
  year={2020}
}

@article{wang2022unreasonable,
  title={On the Unreasonable Effectiveness of Federated Averaging with Heterogeneous Data},
  author={Wang, Jianyu and Das, Rudrajit and Joshi, Gauri and Kale, Satyen and Xu, Zheng and Zhang, Tong},
  journal={arXiv preprint arXiv:2206.04723},
  year={2022}
}




@article{zhang2020adaptive,
  title={Why are adaptive methods good for attention models?},
  author={Zhang, Jingzhao and Karimireddy, Sai Praneeth and Veit, Andreas and Kim, Seungyeon and Reddi, Sashank and Kumar, Sanjiv and Sra, Suvrit},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={15383--15393},
  year={2020}
}

@inproceedings{karimireddy2020scaffold,
  title={Scaffold: Stochastic controlled averaging for federated learning},
  author={Karimireddy, Sai Praneeth and Kale, Satyen and Mohri, Mehryar and Reddi, Sashank and Stich, Sebastian and Suresh, Ananda Theertha},
  booktitle={International Conference on Machine Learning},
  pages={5132--5143},
  year={2020},
  organization={PMLR}
}
@InProceedings{lin2020extrapolation,
  title = 	 {Extrapolation for Large-batch Training in Deep Learning},
  author =       {Lin, Tao and Kong, Lingjing and Stich, Sebastian and Jaggi, Martin},
  booktitle = 	 {Proceedings of the 37th International Conference on Machine Learning},
  pages = 	 {6094--6104},
  year = 	 {2020},
  editor = 	 {III, Hal Daumé and Singh, Aarti},
  volume = 	 {119},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {13--18 Jul},
  publisher =    {PMLR}
}

@article{jastrzkebski2017three,
  title={Three factors influencing minima in {SGD}},
  author={Jastrz{\k{e}}bski, Stanis{\l}aw and Kenton, Zachary and Arpit, Devansh and Ballas, Nicolas and Fischer, Asja and Bengio, Yoshua and Storkey, Amos},
  journal={arXiv preprint arXiv:1711.04623},
  year={2017}
}

@article{lian2017can,
  title={Can decentralized algorithms outperform centralized algorithms? a case study for decentralized parallel stochastic gradient descent},
  author={Lian, Xiangru and Zhang, Ce and Zhang, Huan and Hsieh, Cho-Jui and Zhang, Wei and Liu, Ji},
  journal={Advances in Neural Information Processing Systems},
  volume={30},
  year={2017}
}

@INPROCEEDINGS{chen2016,
  author={Chen, Kai and Huo, Qiang},
  booktitle={2016 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={Scalable training of deep learning machines by incremental block training with intra-block parallel optimization and blockwise model-update filtering}, 
  year={2016},
  volume={},
  number={},
  pages={5880-5884},
  doi={10.1109/ICASSP.2016.7472805}}

@INPROCEEDINGS{acoustic,
  author={Zhang, Xiaohui and Trmal, Jan and Povey, Daniel and Khudanpur, Sanjeev},
  booktitle={2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={Improving deep neural network acoustic models using generalized maxout networks}, 
  year={2014},
  volume={},
  number={},
  pages={215-219},
  doi={10.1109/ICASSP.2014.6853589}}
@article{povey2014parallel,
  title={Parallel training of DNNs with natural gradient and parameter averaging},
  author={Povey, Daniel and Zhang, Xiaohui and Khudanpur, Sanjeev},
  journal={arXiv preprint arXiv:1410.7455},
  year={2014}
}
@article{haddadpour2019local,
  title={Local {SGD} with periodic averaging: Tighter analysis and adaptive synchronization},
  author={Haddadpour, Farzin and Kamani, Mohammad Mahdi and Mahdavi, Mehrdad and Cadambe, Viveck},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}

@inproceedings{NEURIPS2019_Qsparse,
 author = {Basu, Debraj and Data, Deepesh and Karakus, Can and Diggavi, Suhas},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Qsparse-local-{SGD}: Distributed {SGD} with Quantization, Sparsification and Local Computations},
 volume = {32},
 year = {2019}
}
@article{ILSVRC15,
Author = {Olga Russakovsky and Jia Deng and Hao Su and Jonathan Krause and Sanjeev Satheesh and Sean Ma and Zhiheng Huang and Andrej Karpathy and Aditya Khosla and Michael Bernstein and Alexander C. Berg and Li Fei-Fei},
Title = {{ImageNet Large Scale Visual Recognition Challenge}},
Year = {2015},
journal   = {International Journal of Computer Vision (IJCV)},
doi = {10.1007/s11263-015-0816-y},
volume={115},
number={3},
pages={211-252}
}
@article{krizhevsky2009learning,
  title={Learning multiple layers of features from tiny images},
  author={Krizhevsky, Alex and others},
  year={2009},
  publisher={Citeseer}
}
@article{kairouz2021advances,
  title={Advances and open problems in federated learning},
  author={Kairouz, Peter and McMahan, H Brendan and Avent, Brendan and Bellet, Aur{\'e}lien and Bennis, Mehdi and Bhagoji, Arjun Nitin and Bonawitz, Kallista and Charles, Zachary and Cormode, Graham and Cummings, Rachel and others},
  journal={Foundations and Trends{\textregistered} in Machine Learning},
  volume={14},
  number={1--2},
  pages={1--210},
  year={2021},
  publisher={Now Publishers, Inc.}
}
@article{su2015experiments,
  title={Experiments on parallel training of deep neural network using model averaging},
  author={Su, Hang and Chen, Haoyu},
  journal={arXiv preprint arXiv:1507.01239},
  year={2015}
}
@inproceedings{DBLP:conf/nips/MannMMSW09,
  author    = {Gideon Mann and
               Ryan T. McDonald and
               Mehryar Mohri and
               Nathan Silberman and
               Dan Walker},
  title     = {Efficient Large-Scale Distributed Training of Conditional Maximum
               Entropy Models},
  booktitle = {Advances in Neural Information Processing Systems 22},
  pages     = {1231--1239},
  year      = {2009}
}
@inproceedings{vgg,
	author = "Simonyan, K. and Zisserman, A.",
	title = "Very Deep Convolutional Networks for Large-Scale Image Recognition",
	booktitle = "International Conference on Learning Representations",
	Month = "May",
	year = "2015"
}

@article{kat,
author = {G. S. Katzenberger},
title = {Solutions of a Stochastic Differential Equation Forced Onto a Manifold by a Large Drift},
volume = {19},
journal = {The Annals of Probability},
number = {4},
publisher = {Institute of Mathematical Statistics},
pages = {1587 -- 1628},
keywords = {diffusion, diffusion approximation, flow, Manifold, Semimartingale, Stochastic differential equation},
year = {1991}
}

@misc{leclerc2022ffcv,
    author = {Guillaume Leclerc and Andrew Ilyas and Logan Engstrom and Sung Min Park and Hadi Salman and Aleksander Madry},
    title = {ffcv},
    year = {2022},
    howpublished = {\url{https://github.com/libffcv/ffcv/}}
}
@inproceedings{DBLP:conf/nips/RechtRWN11,
  author    = {Benjamin Recht and
               Christopher R{\'{e}} and
               Stephen J. Wright and
               Feng Niu},

  title     = {Hogwild: {A} Lock-Free Approach to Parallelizing Stochastic Gradient
               Descent},
  booktitle = {Advances in Neural Information Processing Systems 24},
  pages     = {693--701},
  year      = {2011},
  timestamp = {Mon, 16 May 2022 15:41:51 +0200}
}
a service of  Schloss Dagstuhl - Leibniz Center for Informatics	homebrowsesearchabout
@inproceedings{NIPS2010_abea47ba,
 author = {Zinkevich, Martin and Weimer, Markus and Li, Lihong and Smola, Alex},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {J. Lafferty and C. Williams and J. Shawe-Taylor and R. Zemel and A. Culotta},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Parallelized Stochastic Gradient Descent},
 volume = {23},
 year = {2010}
}


@article{DBLP:journals/corr/ChenMBJ16,
  author    = {Jianmin Chen and
               Rajat Monga and
               Samy Bengio and
               Rafal J{\'{o}}zefowicz},
  title     = {Revisiting Distributed Synchronous {SGD}},
  journal   = {CoRR},
  volume    = {abs/1604.00981},
  year      = {2016},
  url       = {http://arxiv.org/abs/1604.00981},
  eprinttype = {arXiv},
  eprint    = {1604.00981},
  timestamp = {Mon, 13 Aug 2018 16:48:43 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/ChenMBJ16.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@inproceedings{DBLP:conf/interspeech/Strom15,
  author    = {Nikko Strom},
  title     = {Scalable distributed {DNN} training using commodity {GPU} cloud computing},
  booktitle = {{INTERSPEECH} 2015, 16th Annual Conference of the International Speech
               Communication Association, Dresden, Germany, September 6-10, 2015},
  pages     = {1488--1492},
  publisher = {{ISCA}},
  year      = {2015},
  timestamp = {Tue, 16 Nov 2021 11:43:44 +0100},
  biburl    = {https://dblp.org/rec/conf/interspeech/Strom15.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@inproceedings{DBLP:conf/interspeech/SeideFDLY14,
  author    = {Frank Seide and
               Hao Fu and
               Jasha Droppo and
               Gang Li and
               Dong Yu},
  editor    = {Haizhou Li and
               Helen M. Meng and
               Bin Ma and
               Engsiong Chng and
               Lei Xie},
  title     = {1-bit stochastic gradient descent and its application to data-parallel
               distributed training of speech DNNs},
  booktitle = {{INTERSPEECH} 2014, 15th Annual Conference of the International Speech
               Communication Association, Singapore, September 14-18, 2014},
  pages     = {1058--1062},
  publisher = {{ISCA}},
  year      = {2014},
  url       = {http://www.isca-speech.org/archive/interspeech\_2014/i14\_1058.html},
  timestamp = {Tue, 16 Nov 2021 11:44:16 +0100},
  biburl    = {https://dblp.org/rec/conf/interspeech/SeideFDLY14.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{
keskar2017on,
title={On Large-Batch Training for Deep Learning: Generalization Gap and Sharp Minima},
author={Nitish Shirish Keskar and Dheevatsa Mudigere and Jorge Nocedal and Mikhail Smelyanskiy and Ping Tak Peter Tang},
booktitle={International Conference on Learning Representations},
year={2017}
}

@inproceedings{DBLP:conf/iclr/BrandfonbrenerB20,
  author    = {David Brandfonbrener and
               Joan Bruna},
  title     = {Geometric Insights into the Convergence of Nonlinear {TD} Learning},
  booktitle = {8th International Conference on Learning Representations, {ICLR} 2020,
               Addis Ababa, Ethiopia, April 26-30, 2020},
  publisher = {OpenReview.net},
  year      = {2020},
  timestamp = {Thu, 07 May 2020 17:11:47 +0200},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@book{DBLP:books/lib/SuttonB98,
  author    = {Richard S. Sutton and
               Andrew G. Barto},
  title     = {Reinforcement learning - an introduction},
  series    = {Adaptive computation and machine learning},
  publisher = {{MIT} Press},
  year      = {1998},
  isbn      = {978-0-262-19398-6},
  timestamp = {Fri, 17 Jul 2020 16:12:40 +0200},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@inproceedings{gupta2015deep,
  title={Deep learning with limited numerical precision},
  author={Gupta, Suyog and Agrawal, Ankur and Gopalakrishnan, Kailash and Narayanan, Pritish},
  booktitle={International conference on machine learning},
  pages={1737--1746},
  year={2015},
  organization={PMLR}
}
@inproceedings{mcmahan2017communication,
  title={Communication-efficient learning of deep networks from decentralized data},
  author={McMahan, Brendan and Moore, Eider and Ramage, Daniel and Hampson, Seth and y Arcas, Blaise Aguera},
  booktitle={Artificial intelligence and statistics},
  pages={1273--1282},
  year={2017},
  organization={PMLR}
}
@article{li2020reconciling,
  title={Reconciling modern deep learning with traditional optimization analyses: The intrinsic learning rate},
  author={Li, Zhiyuan and Lyu, Kaifeng and Arora, Sanjeev},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={14544--14555},
  year={2020}
}
@inproceedings{arora2018theoretical,
  title={Theoretical Analysis of Auto Rate-Tuning by Batch Normalization},
  author={Arora, Sanjeev and Li, Zhiyuan and Lyu, Kaifeng},
  booktitle={International Conference on Learning Representations},
  year={2018}
}
@article{chen2016revisiting,
  title={Revisiting distributed synchronous {SGD}},
  author={Chen, Jianmin and Pan, Xinghao and Monga, Rajat and Bengio, Samy and Jozefowicz, Rafal},
  journal={arXiv preprint arXiv:1604.00981},
  year={2016}
}


@inproceedings{you2018imagenet,
  title={Imagenet training in minutes},
  author={You, Yang and Zhang, Zhao and Hsieh, Cho-Jui and Demmel, James and Keutzer, Kurt},
  booktitle={Proceedings of the 47th International Conference on Parallel Processing},
  pages={1--10},
  year={2018}
}


@inproceedings{
lin2020dont,
title={Don't Use Large Mini-batches, Use {Local SGD}},
author={Tao Lin and Sebastian U. Stich and Kumar Kshitij Patel and Martin Jaggi},
booktitle={International Conference on Learning Representations},
year={2020}
}





@inproceedings{kour2014real,
  title={Real-time segmentation of on-line handwritten arabic script},
  author={Kour, George and Saabne, Raid},
  booktitle={Frontiers in Handwriting Recognition (ICFHR), 2014 14th International Conference on},
  pages={417--422},
  year={2014},
  organization={IEEE}
}

@inproceedings{kour2014fast,
  title={Fast classification of handwritten on-line Arabic characters},
  author={Kour, George and Saabne, Raid},
  booktitle={Soft Computing and Pattern Recognition (SoCPaR), 2014 6th International Conference of},
  pages={312--318},
  year={2014},
  organization={IEEE}
}

@article{hadash2018estimate,
  title={Estimate and Replace: A Novel Approach to Integrating Deep Neural Networks with Existing Applications},
  author={Hadash, Guy and Kermany, Einat and Carmeli, Boaz and Lavi, Ofer and Kour, George and Jacovi, Alon},
  journal={arXiv preprint arXiv:1804.09028},
  year={2018}
}

@inproceedings{li2019exponential,
  title={An Exponential Learning Rate Schedule for Deep Learning},
  author={Li, Zhiyuan and Arora, Sanjeev},
  booktitle={International Conference on Learning Representations},
  year={2019}
}

@inproceedings{ioffe2015batch,
  title={Batch normalization: Accelerating deep network training by reducing internal covariate shift},
  author={Ioffe, Sergey and Szegedy, Christian},
  booktitle={International conference on machine learning},
  pages={448--456},
  year={2015},
  organization={PMLR}
}

@inproceedings{wu2018group,
  title={Group normalization},
  author={Wu, Yuxin and He, Kaiming},
  booktitle={Proceedings of the European conference on computer vision (ECCV)},
  pages={3--19},
  year={2018}
}

@article{ulyanov2016instance,
  title={Instance normalization: The missing ingredient for fast stylization},
  author={Ulyanov, Dmitry and Vedaldi, Andrea and Lempitsky, Victor},
  journal={arXiv preprint arXiv:1607.08022},
  year={2016}
}

@article{zhang2016parallel,
  title={{Parallel SGD}: When does averaging help?},
  author={Zhang, Jian and De Sa, Christopher and Mitliagkas, Ioannis and R{\'e}, Christopher},
  journal={arXiv preprint arXiv:1606.07365},
  year={2016}
}

@inproceedings{cohen2020gradient,
  title={Gradient Descent on Neural Networks Typically Occurs at the Edge of Stability},
  author={Cohen, Jeremy and Kaur, Simran and Li, Yuanzhi and Kolter, J Zico and Talwalkar, Ameet},
  booktitle={International Conference on Learning Representations},
  year={2020}
}
@inproceedings{stich2018local,
  title={{Local SGD} Converges Fast and Communicates Little},
  author={Stich, Sebastian U},
  booktitle={International Conference on Learning Representations},
  year={2018}
}
@inproceedings{khaled2020tighter,
  title={Tighter theory for local {SGD} on identical and heterogeneous data},
  author={Khaled, Ahmed and Mishchenko, Konstantin and Richt{\'a}rik, Peter},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={4519--4529},
  year={2020},
  organization={PMLR}
}
@inproceedings{woodworth2020local,
  title={Is local SGD better than minibatch SGD?},
  author={Woodworth, Blake and Patel, Kumar Kshitij and Stich, Sebastian and Dai, Zhen and Bullins, Brian and Mcmahan, Brendan and Shamir, Ohad and Srebro, Nathan},
  booktitle={International Conference on Machine Learning},
  pages={10334--10343},
  year={2020},
  organization={PMLR}
}

@InProceedings{ahn2022understanding,
  title = 	 {Understanding the unstable convergence of gradient descent},
  author =       {Ahn, Kwangjun and Zhang, Jingzhao and Sra, Suvrit},
  booktitle = 	 {Proceedings of the 39th International Conference on Machine Learning},
  pages = 	 {247--257},
  year = 	 {2022},
  editor = 	 {Chaudhuri, Kamalika and Jegelka, Stefanie and Song, Le and Szepesvari, Csaba and Niu, Gang and Sabato, Sivan},
  volume = 	 {162},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {17--23 Jul},
  publisher =    {PMLR}
}



@inproceedings{li2021happens,
  title={What Happens after {SGD} Reaches Zero Loss?--A Mathematical Framework},
  author={Li, Zhiyuan and Wang, Tianhao and Arora, Sanjeev},
  booktitle={International Conference on Learning Representations},
  year={2021}
}

@article{li2019stochastic,
  author  = {Qianxiao Li and Cheng Tai and Weinan E},
  title   = {Stochastic Modified Equations and Dynamics of Stochastic Gradient Algorithms I: Mathematical Foundations},
  journal = {Journal of Machine Learning Research},
  year    = {2019},
  volume  = {20},
  number  = {40},
  pages   = {1--47},
}

@article{whitt2002stochastic,
  title={Stochastic-process limits: an introduction to stochastic-process limits and their application to queues},
  author={Whitt, Ward},
  journal={Space},
  volume={500},
  pages={391--426},
  year={2002},
  publisher={Springer}
}

@article{kurtz1991weak,
  title={Weak limit theorems for stochastic integrals and stochastic differential equations},
  author={Kurtz, Thomas G and Protter, Philip},
  journal={The Annals of Probability},
  pages={1035--1070},
  year={1991},
  publisher={JSTOR}
}

@inproceedings{
damian2021label,
title={Label Noise {SGD} Provably Prefers Flat Global Minimizers},
author={Alex Damian and Tengyu Ma and Jason D. Lee},
booktitle={Advances in Neural Information Processing Systems},
editor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},
year={2021},
}

@article{hochreiter1997flat,
  title={Flat minima},
  author={Hochreiter, Sepp and Schmidhuber, J{\"u}rgen},
  journal={Neural computation},
  volume={9},
  number={1},
  pages={1--42},
  year={1997},
  publisher={MIT Press One Rogers Street, Cambridge, MA 02142-1209, USA journals-info~…}
}

@inproceedings{glasgow2022sharp,
  title={Sharp Bounds for Federated Averaging ({Local SGD}) and Continuous Perspective},
  author={Glasgow, Margalit R and Yuan, Honglin and Ma, Tengyu},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={9050--9090},
  year={2022},
  organization={PMLR}
}
@inproceedings{
lyu2022understanding,
title={Understanding the Generalization Benefit of Normalization Layers: Sharpness Reduction},
author={Kaifeng Lyu and Zhiyuan Li and Sanjeev Arora},
booktitle={Advances in Neural Information Processing Systems},
editor={Alice H. Oh and Alekh Agarwal and Danielle Belgrave and Kyunghyun Cho},
year={2022},
url={https://openreview.net/forum?id=xp5VOBxTxZ}
}
@article{madden2020high,
  title={High probability convergence bounds for stochastic gradient descent assuming the polyak-lojasiewicz inequality},
  author={Madden, Liam and Dall'Anese, Emiliano and Becker, Stephen},
  journal={arXiv preprint arXiv:2006.05610},
  year={2020}
}

@article{du2007invariant,
  title={Invariant Manifold Reduction For Stochastic Dynamical Systems},
  author={Du, Aijun and Duan, JinQiao},
  journal={Dynamic Systems and Applications},
  volume={16},
  pages={681--696},
  year={2007}
}
@article{filipovic2000invariant,
  title={Invariant manifolds for weak solutions to stochastic equations},
  author={Filipovi{\'c}, Damir},
  journal={Probability theory and related fields},
  volume={118},
  number={3},
  pages={323--341},
  year={2000},
  publisher={Springer}
}

@inproceedings{
malladi2022sdes,
title={On the {SDE}s and Scaling Rules for Adaptive Gradient Algorithms},
author={Sadhika Malladi and Kaifeng Lyu and Abhishek Panigrahi and Sanjeev Arora},
booktitle={Advances in Neural Information Processing Systems},
editor={Alice H. Oh and Alekh Agarwal and Danielle Belgrave and Kyunghyun Cho},
year={2022}
}





@article{falconer1983differentiation,
  title={Differentiation of the limit mapping in a dynamical system},
  author={Falconer, KJ},
  journal={Journal of the London Mathematical Society},
  volume={2},
  number={2},
  pages={356--372},
  year={1983},
  publisher={Wiley Online Library}
}

@inproceedings{yu2019parallel,
  title={Parallel restarted {SGD} with faster convergence and less communication: Demystifying why model averaging works for deep learning},
  author={Yu, Hao and Yang, Sen and Zhu, Shenghuo},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={33},
  number={01},
  pages={5693--5700},
  year={2019}
}
@article{ortiz2021trade,
  title={Trade-offs of {Local SGD} at Scale: An Empirical Study},
  author={Ortiz, Jose Javier Gonzalez and Frankle, Jonathan and Rabbat, Mike and Morcos, Ari and Ballas, Nicolas},
  journal={arXiv preprint arXiv:2110.08133},
  year={2021}
}

@article{wang2019adaptive,
  title={Adaptive communication strategies to achieve the best error-runtime trade-off in local-update {SGD}},
  author={Wang, Jianyu and Joshi, Gauri},
  journal={Proceedings of Machine Learning and Systems},
  volume={1},
  pages={212--229},
  year={2019}
}

@inproceedings{gupta2020swap,
title={Stochastic Weight Averaging in Parallel: Large-Batch Training That Generalizes Well},
author={Vipul Gupta and Santiago Akle Serrano and Dennis DeCoste},
booktitle={International Conference on Learning Representations},
year={2020},
}

@inproceedings{wang2019slowmo,
  title={SlowMo: Improving Communication-Efficient Distributed {SGD} with Slow Momentum},
  author={Wang, Jianyu and Tantia, Vinayak and Ballas, Nicolas and Rabbat, Michael},
  booktitle={International Conference on Learning Representations},
  year={2019}
}

@article{hoffer2017train,
  title={Train longer, generalize better: closing the generalization gap in large batch training of neural networks},
  author={Hoffer, Elad and Hubara, Itay and Soudry, Daniel},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@article{ramachandran2017searching,
  title={Searching for activation functions},
  author={Ramachandran, Prajit and Zoph, Barret and Le, Quoc V},
  journal={arXiv preprint arXiv:1710.05941},
  year={2017}
}

@article{calzolari1997limit,
  title={Limit motion of an Ornstein--Uhlenbeck particle on the equilibrium manifold of a force field},
  author={Calzolari, Antonella and Marchetti, Federico},
  journal={Journal of Applied Probability},
  volume={34},
  number={4},
  pages={924--938},
  year={1997},
  publisher={Cambridge University Press}
}

@article{li2021validity,
  title={On the validity of modeling {SGD} with stochastic differential equations (sdes)},
  author={Li, Zhiyuan and Malladi, Sadhika and Arora, Sanjeev},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={12712--12725},
  year={2021}
}

@article{hu2017diffusion,
  title={On the diffusion approximation of nonconvex stochastic gradient descent},
  author={Hu, Wenqing and Li, Chris Junchi and Li, Lei and Liu, Jian-Guo},
  journal={arXiv preprint arXiv:1705.07562},
  year={2017}
}

@inproceedings{DBLP:journals/corr/SimonyanZ14a,
  author    = {Karen Simonyan and
               Andrew Zisserman},
  editor    = {Yoshua Bengio and
               Yann LeCun},
  title     = {Very Deep Convolutional Networks for Large-Scale Image Recognition},
  booktitle = {3rd International Conference on Learning Representations, {ICLR} 2015,
               San Diego, CA, USA, May 7-9, 2015, Conference Track Proceedings},
  year      = {2015},
  timestamp = {Wed, 17 Jul 2019 10:40:54 +0200},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{he2015delving,
  title={Delving deep into rectifiers: Surpassing human-level performance on imagenet classification},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={1026--1034},
  year={2015}
}


@article{jia2018highly,
  title={Highly scalable deep learning training system with mixed-precision: Training imagenet in four minutes},
  author={Jia, Xianyan and Song, Shutao and He, Wei and Wang, Yangzihao and Rong, Haidong and Zhou, Feihu and Xie, Liqiang and Guo, Zhenyu and Yang, Yuanzhou and Yu, Liwei and others},
  journal={Advances in Neural Information Processing Systems},
  year={2018}
}


@InProceedings{smith2020generalization,
  title = 	 {On the Generalization Benefit of Noise in Stochastic Gradient Descent},
  author =       {Smith, Samuel and Elsen, Erich and De, Soham},
  booktitle = 	 {Proceedings of the 37th International Conference on Machine Learning},
  pages = 	 {9058--9067},
  year = 	 {2020},
  editor = 	 {III, Hal Daumé and Singh, Aarti},
  volume = 	 {119},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {13--18 Jul},
  publisher =    {PMLR},
}

@article{wang2021cooperative,
  author  = {Jianyu Wang and Gauri Joshi},
  title   = {Cooperative {SGD}: A Unified Framework for the Design and Analysis of Local-Update {SGD} Algorithms},
  journal = {Journal of Machine Learning Research},
  year    = {2021},
  volume  = {22},
  number  = {213},
  pages   = {1--50}
}
@article{hendrycks2016gaussian,
  title={Gaussian error linear units (gelus)},
  author={Hendrycks, Dan and Gimpel, Kevin},
  journal={arXiv preprint arXiv:1606.08415},
  year={2016}
}
@article{hinton2012neural,
  title={Neural networks for machine learning lecture 6a overview of mini-batch gradient descent},
  author={Hinton, Geoffrey and Srivastava, Nitish and Swersky, Kevin},
  journal={Cited on},
  volume={14},
  number={8},
  pages={2},
  year={2012}
}
@inproceedings{ijcai2018p447,
  title     = {On the Convergence Properties of a K-step Averaging Stochastic Gradient Descent Algorithm for Nonconvex Optimization},
  author    = {Fan Zhou and Guojing Cong},
  booktitle = {Proceedings of the Twenty-Seventh International Joint Conference on
               Artificial Intelligence, {IJCAI-18}},
  publisher = {International Joint Conferences on Artificial Intelligence Organization},
  pages     = {3219--3227},
  year      = {2018},
  month     = {7},
  doi       = {10.24963/ijcai.2018/447},
  url       = {https://doi.org/10.24963/ijcai.2018/447},
}

@article{fehrman2020convergence,
  title={Convergence rates for the stochastic gradient descent method for non-convex objective functions},
  author={Fehrman, Benjamin and Gess, Benjamin and Jentzen, Arnulf},
  journal={Journal of Machine Learning Research},
  volume={21},
  pages={136},
  year={2020},
  publisher={MIT Press}
}
@article{mnih2015human,
  title={Human-level control through deep reinforcement learning},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A and Veness, Joel and Bellemare, Marc G and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K and Ostrovski, Georg and others},
  journal={nature},
  volume={518},
  number={7540},
  pages={529--533},
  year={2015},
  publisher={Nature Publishing Group}
}

@Inbook{bengio2012practical,
author="Bengio, Yoshua",
editor="Montavon, Gr{\'e}goire
and Orr, Genevi{\`e}ve B.
and M{\"u}ller, Klaus-Robert",
title="Practical Recommendations for Gradient-Based Training of Deep Architectures",
bookTitle="Neural Networks: Tricks of the Trade: Second Edition",
year="2012",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="437--478",
isbn="978-3-642-35289-8",
doi="10.1007/978-3-642-35289-8_26",
}





@Inbook{lecun2012efficient,
author="LeCun, Yann A.
and Bottou, L{\'e}on
and Orr, Genevieve B.
and M{\"u}ller, Klaus-Robert",
editor="Montavon, Gr{\'e}goire
and Orr, Genevi{\`e}ve B.
and M{\"u}ller, Klaus-Robert",
title="Efficient {BackProp}",
bookTitle="Neural Networks: Tricks of the Trade: Second Edition",
year="2012",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="9--48",
isbn="978-3-642-35289-8",
doi="10.1007/978-3-642-35289-8_3",
}

@inproceedings{
smith2021on,
title={On the Origin of Implicit Regularization in Stochastic Gradient Descent},
author={Samuel L Smith and Benoit Dherin and David Barrett and Soham De},
booktitle={International Conference on Learning Representations},
year={2021},
}

@inproceedings{li2019towards,
 author = {Li, Yuanzhi and Wei, Colin and Ma, Tengyu},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Towards Explaining the Regularization Effect of Initial Large Learning Rate in Training Neural Networks},
 volume = {32},
 year = {2019}
}


@InProceedings{blanc2020implicit,
  title = 	 {Implicit regularization for deep neural networks driven by an Ornstein-Uhlenbeck like process},
  author =       {Blanc, Guy and Gupta, Neha and Valiant, Gregory and Valiant, Paul},
  booktitle = 	 {Proceedings of Thirty Third Conference on Learning Theory},
  pages = 	 {483--513},
  year = 	 {2020},
  editor = 	 {Abernethy, Jacob and Agarwal, Shivani},
  volume = 	 {125},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {09--12 Jul},
  publisher =    {PMLR},
}

@article{shallue2019measuring,
  author  = {Christopher J. Shallue and Jaehoon Lee and Joseph Antognini and Jascha Sohl-Dickstein and Roy Frostig and George E. Dahl},
  title   = {Measuring the Effects of Data Parallelism on Neural Network Training},
  journal = {Journal of Machine Learning Research},
  year    = {2019},
  volume  = {20},
  number  = {112},
  pages   = {1--49},
}

@inproceedings{wu2018how,
 author = {Wu, Lei and Ma, Chao and E, Weinan},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {S. Bengio and H. Wallach and H. Larochelle and K. Grauman and N. Cesa-Bianchi and R. Garnett},
 publisher = {Curran Associates, Inc.},
 title = {How SGD Selects the Global Minima in Over-parameterized Learning: A Dynamical Stability Perspective},
 volume = {31},
 year = {2018}
}

@inproceedings{ma2021on,
 author = {Ma, Chao and Ying, Lexing},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {M. Ranzato and A. Beygelzimer and Y. Dauphin and P.S. Liang and J. Wortman Vaughan},
 pages = {16805--16817},
 publisher = {Curran Associates, Inc.},
 title = {On Linear Stability of {SGD} and Input-Smoothness of Neural Networks},
 volume = {34},
 year = {2021}
}

@inproceedings{neyshabur2017exploring,
 author = {Neyshabur, Behnam and Bhojanapalli, Srinadh and Mcallester, David and Srebro, Nati},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {I. Guyon and U. Von Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Exploring Generalization in Deep Learning},
 volume = {30},
 year = {2017}
}

@article{zhu2018anisotropic,
  title={The anisotropic noise in stochastic gradient descent: Its behavior of escaping from sharp minima and regularization effects},
  author={Zhu, Zhanxing and Wu, Jingfeng and Yu, Bing and Wu, Lei and Ma, Jinwen},
  journal={arXiv preprint arXiv:1803.00195},
  year={2018}
}

@inproceedings{
xie2021a,
title={A Diffusion Theory For Deep Learning Dynamics: Stochastic Gradient Descent Exponentially Favors Flat Minima},
author={Zeke Xie and Issei Sato and Masashi Sugiyama},
booktitle={International Conference on Learning Representations},
year={2021},
}

@article{ibayashi2022expescape,
  title={Exponential escape efficiency of {SGD} from sharp minima in non-stationary regime},
  author={Hikaru Ibayashi and Masaaki Imaizumi},
  journal={arXiv preprint arXiv:2111.04004},
  year={2021}
}

@InProceedings{kleinberg2018alternative,
  title = 	 {An Alternative View: When Does {SGD} Escape Local Minima?},
  author =       {Kleinberg, Bobby and Li, Yuanzhi and Yuan, Yang},
  booktitle = 	 {Proceedings of the 35th International Conference on Machine Learning},
  pages = 	 {2698--2707},
  year = 	 {2018},
  editor = 	 {Dy, Jennifer and Krause, Andreas},
  volume = 	 {80},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {10--15 Jul},
  publisher =    {PMLR},
}


@InProceedings{dinh2017sharp,
  title = 	 {Sharp Minima Can Generalize For Deep Nets},
  author =       {Laurent Dinh and Razvan Pascanu and Samy Bengio and Yoshua Bengio},
  booktitle = 	 {Proceedings of the 34th International Conference on Machine Learning},
  pages = 	 {1019--1028},
  year = 	 {2017},
  editor = 	 {Precup, Doina and Teh, Yee Whye},
  volume = 	 {70},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {06--11 Aug},
  publisher =    {PMLR},
}

@inproceedings{
jiang2020fantastic,
title={Fantastic Generalization Measures and Where to Find Them},
author={Yiding Jiang and Behnam Neyshabur and Hossein Mobahi and Dilip Krishnan and Samy Bengio},
booktitle={International Conference on Learning Representations},
year={2020},
}

@inproceedings{
foret2021sharpnessaware,
title={Sharpness-aware Minimization for Efficiently Improving Generalization},
author={Pierre Foret and Ariel Kleiner and Hossein Mobahi and Behnam Neyshabur},
booktitle={International Conference on Learning Representations},
year={2021},
}

@article{krizhevsky2014one,
  title={One weird trick for parallelizing convolutional neural networks},
  author={Krizhevsky, Alex},
  journal={arXiv preprint arXiv:1404.5997},
  year={2014}
}

@inproceedings{
you2020large,
title={Large Batch Optimization for Deep Learning: Training {BERT} in 76 minutes},
author={Yang You and Jing Li and Sashank Reddi and Jonathan Hseu and Sanjiv Kumar and Srinadh Bhojanapalli and Xiaodan Song and James Demmel and Kurt Keutzer and Cho-Jui Hsieh},
booktitle={International Conference on Learning Representations},
year={2020},
}


@book{oksendal2013stochastic,
  title={Stochastic differential equations: an introduction with applications},
  author={Øksendal, Bernt},
  year={2013},
  publisher={Springer Science \& Business Media}
}

@article{leclerc2020two,
  title={The two regimes of deep network training},
  author={Leclerc, Guillaume and Madry, Aleksander},
  journal={arXiv preprint arXiv:2002.10376},
  year={2020}
}

@inproceedings{arnold2019reducing,
 author = {Arnold, S\'{e}bastien and Manzagol, Pierre-Antoine and Babanezhad Harikandeh, Reza and Mitliagkas, Ioannis and Le Roux, Nicolas},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Reducing the variance in online optimization by transporting past gradients},
 volume = {32},
 year = {2019}
}

@article{tondji2021variance,
  title={Variance Reduction in Deep Learning: More Momentum is All You Need},
  author={Tondji, Lionel and Kashubin, Sergii and Cisse, Moustapha},
  journal={arXiv preprint arXiv:2111.11828},
  year={2021}
}

@inproceedings{
ma2018quasihyperbolic,
title={Quasi-hyperbolic momentum and Adam for deep learning},
author={Jerry Ma and Denis Yarats},
booktitle={International Conference on Learning Representations},
year={2019},
}

@inproceedings{
kidambi2018on,
title={On the insufficiency of existing momentum schemes for Stochastic Optimization},
author={Rahul Kidambi and Praneeth Netrapalli and Prateek Jain and Sham M. Kakade},
booktitle={International Conference on Learning Representations},
year={2018},
}


@InProceedings{jain2018accelerating,
  title = 	 {Accelerating Stochastic Gradient Descent for Least Squares Regression},
  author =       {Jain, Prateek and Kakade, Sham M. and Kidambi, Rahul and Netrapalli, Praneeth and Sidford, Aaron},
  booktitle = 	 {Proceedings of the 31st  Conference On Learning Theory},
  pages = 	 {545--604},
  year = 	 {2018},
  editor = 	 {Bubeck, Sébastien and Perchet, Vianney and Rigollet, Philippe},
  volume = 	 {75},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {06--09 Jul},
  publisher =    {PMLR},
}

@inproceedings{gitman2019understanding,
 author = {Gitman, Igor and Lang, Hunter and Zhang, Pengchuan and Xiao, Lin},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Understanding the Role of Momentum in Stochastic Gradient Methods},
 volume = {32},
 year = {2019}
}


@InProceedings{jelassi2022towards,
  title = 	 {Towards understanding how momentum improves generalization in deep learning},
  author =       {Jelassi, Samy and Li, Yuanzhi},
  booktitle = 	 {Proceedings of the 39th International Conference on Machine Learning},
  pages = 	 {9965--10040},
  year = 	 {2022},
  editor = 	 {Chaudhuri, Kamalika and Jegelka, Stefanie and Song, Le and Szepesvari, Csaba and Niu, Gang and Sabato, Sivan},
  volume = 	 {162},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {17--23 Jul},
  publisher =    {PMLR},
}

@book{polyak1987intro,
  title={Introduction to Optimization},
  author={Polyak, Boris T.},
  year={1987},
  publisher={Optimization Software, Inc.}
}


@InProceedings{sutskever2013on,
  title = 	 {On the importance of initialization and momentum in deep learning},
  author = 	 {Sutskever, Ilya and Martens, James and Dahl, George and Hinton, Geoffrey},
  booktitle = 	 {Proceedings of the 30th International Conference on Machine Learning},
  pages = 	 {1139--1147},
  year = 	 {2013},
  editor = 	 {Dasgupta, Sanjoy and McAllester, David},
  volume = 	 {28},
  number =       {3},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {Atlanta, Georgia, USA},
  month = 	 {17--19 Jun},
  publisher =    {PMLR}
}

@inproceedings{kingma2015adam,
	title={Adam: A Method for Stochastic Optimization},
	author={Diederik P. Kingma and Jimmy Ba},
	booktitle={International Conference on Learning Representations},
	year={2015}
}

@article{bottou2018optimization,
author = {Bottou, L\'{e}on and Curtis, Frank E. and Nocedal, Jorge},
title = {Optimization Methods for Large-Scale Machine Learning},
journal = {SIAM Review},
volume = {60},
number = {2},
pages = {223-311},
year = {2018},
doi = {10.1137/16M1080173}
}

@inproceedings{cutkosky2019momentum,
 author = {Cutkosky, Ashok and Orabona, Francesco},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Momentum-Based Variance Reduction in Non-Convex SGD},
 volume = {32},
 year = {2019}
}


@InProceedings{cutkosky2020momentum,
  title = 	 {Momentum Improves Normalized {SGD}},
  author =       {Cutkosky, Ashok and Mehta, Harsh},
  booktitle = 	 {Proceedings of the 37th International Conference on Machine Learning},
  pages = 	 {2260--2268},
  year = 	 {2020},
  editor = 	 {III, Hal Daumé and Singh, Aarti},
  volume = 	 {119},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {13--18 Jul},
  publisher =    {PMLR}
}

@inbook{rumelhart1987learning,
  author={David E. Rumelhart and Geoffrey E. Hinton and Ronald J. Williams},
  booktitle={Parallel Distributed Processing: Explorations in the Microstructure of Cognition: Foundations},
  title={Learning Internal Representations by Error Propagation},
  year={1987},
  pages={318-362},
}

@article{polyak1964some,
title = {Some methods of speeding up the convergence of iteration methods},
journal = {USSR Computational Mathematics and Mathematical Physics},
volume = {4},
number = {5},
pages = {1-17},
year = {1964},
issn = {0041-5553},
author = {B.T. Polyak}
}

@phdthesis{orr1996dynamics,
author = {Orr, Genevieve Beth},
title = {Dynamics and Algorithms for Stochastic Search},
year = {1996},
publisher = {Oregon Graduate Institute of Science & Technology},
address = {USA},
note = {UMI Order No. GAX96-08998}
}

@article{wiegerinck1994,
doi = {10.1088/0305-4470/27/13/017},
year = {1994},
month = {jul},
publisher = {},
volume = {27},
number = {13},
pages = {4425},
author = {W Wiegerinck and  A Komoda and  T Heskes},
title = {Stochastic dynamics of learning with momentum in neural networks},
journal = {Journal of Physics A: Mathematical and General}
}


@article{plattner2022on,
      title = {On SGD with Momentum},
      author = {Plattner, Maximilian},
      pages = {60},
      year = {2022},
      url = {http://infoscience.epfl.ch/record/295398},
}

@article{defazio2020momentum,
  title={Momentum via primal averaging: theoretical insights and learning rate schedules for non-convex optimization},
  author={Defazio, Aaron},
  journal={arXiv preprint arXiv:2010.00406},
  year={2020}
}


@InProceedings{yu2019linear,
  title = 	 {On the Linear Speedup Analysis of Communication Efficient Momentum {SGD} for Distributed Non-Convex Optimization},
  author =       {Yu, Hao and Jin, Rong and Yang, Sen},
  booktitle = 	 {Proceedings of the 36th International Conference on Machine Learning},
  pages = 	 {7184--7193},
  year = 	 {2019},
  editor = 	 {Chaudhuri, Kamalika and Salakhutdinov, Ruslan},
  volume = 	 {97},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {09--15 Jun},
  publisher =    {PMLR}
}

@inproceedings{yan2018unified,
  title     = {A Unified Analysis of Stochastic Momentum Methods for Deep Learning},
  author    = {Yan Yan and Tianbao Yang and Zhe Li and Qihang Lin and Yi Yang},
  booktitle = {Proceedings of the Twenty-Seventh International Joint Conference on
               Artificial Intelligence, {IJCAI-18}},
  publisher = {International Joint Conferences on Artificial Intelligence Organization},
  pages     = {2955--2961},
  year      = {2018},
  month     = {7}
}

@inproceedings{liu2020improved,
 author = {Liu, Yanli and Gao, Yuan and Yin, Wotao},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Larochelle and M. Ranzato and R. Hadsell and M.F. Balcan and H. Lin},
 pages = {18261--18271},
 publisher = {Curran Associates, Inc.},
 title = {An Improved Analysis of Stochastic Gradient Descent with Momentum},
 volume = {33},
 year = {2020}
}


@InProceedings{sebbouh2021almost,
  title = 	 {Almost sure convergence rates for Stochastic Gradient Descent and Stochastic Heavy Ball},
  author =       {Sebbouh, Othmane and Gower, Robert M and Defazio, Aaron},
  booktitle = 	 {Proceedings of Thirty Fourth Conference on Learning Theory},
  pages = 	 {3935--3971},
  year = 	 {2021},
  editor = 	 {Belkin, Mikhail and Kpotufe, Samory},
  volume = 	 {134},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {15--19 Aug},
  publisher =    {PMLR}
}


@InProceedings{li2022last,
  title = 	 {On the Last Iterate Convergence of Momentum Methods},
  author =       {Li, Xiaoyu and Liu, Mingrui and Orabona, Francesco},
  booktitle = 	 {Proceedings of The 33rd International Conference on Algorithmic Learning Theory},
  pages = 	 {699--717},
  year = 	 {2022},
  editor = 	 {Dasgupta, Sanjoy and Haghtalab, Nika},
  volume = 	 {167},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {29 Mar--01 Apr},
  publisher =    {PMLR}
}

@article{yang2016unified,
  title={Unified convergence analysis of stochastic momentum methods for convex and non-convex optimization},
  author={Yang, Tianbao and Lin, Qihang and Li, Zhe},
  journal={arXiv preprint arXiv:1604.03257},
  year={2016}
}

@book{goodfellow2016dl,
    title={Deep Learning},
    author={Ian Goodfellow and Yoshua Bengio and Aaron Courville},
    publisher={MIT Press},
    note={\url{http://www.deeplearningbook.org}},
    year={2016}
}

@article{smith2018disciplined,
  title={A disciplined approach to neural network hyper-parameters: Part 1--learning rate, batch size, momentum, and weight decay},
  author={Smith, Leslie N},
  journal={arXiv preprint arXiv:1803.09820},
  year={2018}
}


@InProceedings{xie2021positive,
  title = 	 {Positive-Negative Momentum: Manipulating Stochastic Gradient Noise to Improve Generalization},
  author =       {Xie, Zeke and Yuan, Li and Zhu, Zhanxing and Sugiyama, Masashi},
  booktitle = 	 {Proceedings of the 38th International Conference on Machine Learning},
  pages = 	 {11448--11458},
  year = 	 {2021},
  editor = 	 {Meila, Marina and Zhang, Tong},
  volume = 	 {139},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {18--24 Jul},
  publisher =    {PMLR}
}

@article{mandt2017stochastic,
  author  = {Stephan Mandt and Matthew D. Hoffman and David M. Blei},
  title   = {Stochastic Gradient Descent as Approximate Bayesian Inference},
  journal = {Journal of Machine Learning Research},
  year    = {2017},
  volume  = {18},
  number  = {134},
  pages   = {1--35}
}

@article{tugay1989properties,
title = {Properties of the momentum LMS algorithm},
journal = {Signal Processing},
volume = {18},
number = {2},
pages = {117-127},
year = {1989},
issn = {0165-1684},
author = {Mehmet Ali Tugay and Yalçin Tanik},
keywords = {LMS algorithm, MLMS algorithm, Back Propagation Training algorithm, misadjustment, adaptive predictor}
}


@InProceedings{shazeer2018adafactor,
  title = 	 {Adafactor: Adaptive Learning Rates with Sublinear Memory Cost},
  author =       {Shazeer, Noam and Stern, Mitchell},
  booktitle = 	 {Proceedings of the 35th International Conference on Machine Learning},
  pages = 	 {4596--4604},
  year = 	 {2018},
  editor = 	 {Dy, Jennifer and Krause, Andreas},
  volume = 	 {80},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {10--15 Jul},
  publisher =    {PMLR}
}

@inproceedings{
gu2023why,
title={Why (and When) does Local {SGD} Generalize Better than {SGD}?},
author={Xinran Gu and Kaifeng Lyu and Longbo Huang and Sanjeev Arora},
booktitle={The Eleventh International Conference on Learning Representations },
year={2023}
}
