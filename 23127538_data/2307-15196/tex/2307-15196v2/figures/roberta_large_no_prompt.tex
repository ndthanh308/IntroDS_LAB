

\begin{table*}[h]
\centering
\caption{
        SGD and SGDM for fine-tuning RoBERTa-large on $5$ tasks using $512$ examples from each class~\citep{gao-etal-2021-making,malladi2023kernelbased}. Results are averaged over $5$ random subsets of the full dataset. These findings confirm that SGD and SGDM approximate each other in noisy settings.
    }
\resizebox{0.8\textwidth}{!}{
    \setlength{\tabcolsep}{0.3cm}
    \begin{tabular}{lccccccc}
    \toprule
     Task  &  \multicolumn{1}{c}{\textbf{SST-2}} &\multicolumn{1}{c}{\textbf{SST-5}} & \multicolumn{1}{c}{\textbf{SNLI}} & \multicolumn{1}{c}{\textbf{TREC}} & \multicolumn{1}{c}{\textbf{MNLI}} \\
    \midrule
    Zero-shot & 79.0 & 35.5 & 50.2  & 51.4 & 48.8  \\
    SGD & 94.0 (0.4) & 55.2 (1.1) & 87.7 (0.3) & 97.2 (0.2) & 84.0 (0.3) \\
    SGDM & 94.0 (0.5) & 55.0 (1.0) & 88.4 (0.6) & 97.2 (0.4) & 83.7 (0.8) \\
    

    \bottomrule
    \end{tabular}}
    
    \label{tab:lmft}
\end{table*}
