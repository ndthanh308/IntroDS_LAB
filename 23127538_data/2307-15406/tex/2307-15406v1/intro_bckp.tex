
The stochastic gradient descent (SGD) is a cornerstone in optimization
and  machine learning.
In many cases we are interested in maximizing an expectation cost
\begin{equation}
  \label{eq:exp_cost}
  \mathbb E_{p_{\bs\theta}} [f({\bf x}; \bs{\theta})]\,,
\end{equation}
function of some vector of parameters $\bs\theta$. 
Here $p_{\bs\theta}({\bf x})$ is a
% unnormalized
distribution function of a random vector ${\bf x}$, and we
will consider the case where it also depends on the parameters
$\bs\theta$. For these cases, the application of any variant of the SGD algorithm requires
to determine the gradient of the expectation cost
Eq.~(\ref{eq:exp_cost}) w.r.t the parameters $\bs\theta$. 

A similar problem is often encountered in Bayesian inference. One of the interesting questions arises when we are concerned about the sensitivity of the Bayesian predictions on the so-called \emph{hyper-parameters} (taken to be $\bs\theta$ in this context) of the statistical model\footnote{These are parameters which the analysist considers as deterministic, so they do not follow a distribution themselves, but do determine the distribution of the ``normal'' parameters.}. Formally these predictions are determined as expected values of the form given in Eq.~(\ref{eq:exp_cost}), and we are interested in
the dependence w.r.t. $\bs\theta$. It is important to note at this point that nowadays, in the Bayesian inference community, the above question is -to our knowledge- not addressed. Indeed, the Bayesian predictions are typically calculated at optimal values $\bs\theta_{\rm opt}$ of the hyper-parameters, the latter being obtained from a point-wise Maximum Likelihood optimisation of an approximation of the Bayesian evidence. No further analysis is performed quantifying the impact on the predictions when the hyper-parameters values deviate from $\bs\theta_{\rm opt}$.
% On the other hand, if using a Variational Inference approach, e.g. minimizing the Kullback-Leibler divergence $KL[]$

\textcolor{blue}{Another situation in Bayesian inference when the above problem appears is actually very common, specifically in the context of approximate inference, where the aim is to approximate the true posterior $p_{\bs\theta}({\bf x})$ by a distribution $q_{\bs\phi}({\bf x})$. Popular implementations minimize either the forward Kullback-Leibler (FKL) divergence, KL$[p_{\bs\theta}||q_{\bs\phi}]$, or the reverse RKL, KL$[q_{\bs\phi}||p_{\bs\theta}]$. Since the posterior is unknown (it is what such methods try to approximate in first place), the FKL can be estimated via reweighting: FKL = $(1/Z_w) E_{q_{\bs\phi}}[w \log(\tilde{p}_{\bs\theta}/q_{\bs\phi})]$ (see e.g. \cite{Jordan2021}), where $w=\tilde{p}_{\bs\theta}/q_{\bs\phi}$; on the other hand $\tilde{p}_{\bs\theta} = p_{\bs\theta}(\bs{x,\theta})$ is the unnormalized posterior (assumed to be tractable), and $Z_w = E_{q_{\bs\phi}}[w]$. In this case one is interested in minimizing the FKL w.r.t. the parameters $\bs\phi$. In cases where the objective function is the RKL (typical case in Variational Infererence) the expectation is directly with respect to $q_{\bs\phi}$, and for simple choices of the latter the procedure is well defined (see below Sect.\ref{sec:existing}).}



In all these cases the key question is the determination of the
gradient and (possibly) higher derivatives 
\begin{equation}
  \label{eq:gradients}
  \frac{\partial}{\partial \theta_i }\mathbb E_{p_{\bs\theta}}[f({\bf x}; \bs\theta)]\,,\quad
  \frac{\partial^2}{\partial \theta_i\partial \theta_j }\mathbb E_{p_{\bs\theta}}[f({\bf x}; \bs\theta)]\,,\dots
\end{equation}
of expected values, where $\theta_i$ are the components of $\bs\theta$.

In this work we focus in the typical case when the relevant expectations
values Eq.~(\ref{eq:exp_cost}) are determined using some Monte Carlo
(MC) method:
\begin{equation}
  \mathbb E_{p_{\bs\theta}}[f({\bf x}; \bs\theta)] \approx
  \frac{1}{N_s}\sum_{s=1}^{N_s} f({\bf x}_s; \bs\theta)~,
  \label{eq:MC_est}
\end{equation}
where ${\bf x}_s$ are samples from the unnormalized $p_{\bs\theta}$. \emph{Our aim is to develop a formalism to compute the gradients of expr.(\ref{eq:MC_est}) with respect to $\bs\theta$ exactly, using automatic differentiation techniques.}

\subsection{Existing methods}
\label{sec:existing}
There are solutions in the literature for this problem: for some simple distributions the reparametrization trick can be used, which is nothing but the ability to express a sample $\bf x$ as a deterministic function $g(\bs{\theta,\eta})$, of the parameters $\bs\theta$ and a random variable $\bs\eta$ \emph{that does not depend on $\bs\theta$}. A typical example is when $p$ is a multivariate Gaussian with mean $\bs{\mu}(\bs\theta)$ and covariance matrix ${\bf C}$, in whose case a sample ${\bf x}_s$ can be expressed as ${\bf x}_s = \bs{\mu}(\bs\theta) + {\bf L}\cdot\bs{\eta}_s$, where ${\bf L}$ is the Cholesky decomposition of ${\bf C}$, and the sampled random variable $\bs{\eta}_s\sim{\cal N}({\bf 0},\mathbb{I})$. Clearly, since ${\bf x}_s$ is an explicit function of $\bs\theta$, so it will be $f({\bf x}_s,\theta)$ in Eq.(\ref{eq:MC_est}), making possible to use the usual techniques of Automatic Differentiation to obtain the gradients w.r.t. $\bs\theta$ exactly. For other popular distributions as Gamma, Beta or Dirichet, among others, this simple reparametrization is not possible, and generalizations of the above trick have been developed (e.g. in \cite{Figurnov2018}, using implicit differentiation). Nonetheless, the considered distributions should still be somehow reparametrizable. 

%in some cases the $\theta$-dependence is simple enough so that the distribution function $p(x,\theta)$ can be reparametrized as a deterministic function of $g(\theta,\eta)$ of the parameters $\theta$ and a random variable $\eta$ \emph{that does not depend on $\theta$}. A typical example, for example,  is when $p$ is a multivariate normal distribution and the parameters $\theta$ represent the mean: in this case the distribution $p$ is easily obtained from the multivariate with zero mean by a simple translation, making possible the determination of the derivatives of expectation values Eq.~(\ref{eq:exp_cost}) by just using the usual techniques of Automatic Differentiation.

Another existing alternative is to use the \emph{score function estimator}, allowing us to obtain the gradient for a more general case. This method just uses the trivial relation
\begin{equation}
  \nabla_{\bs\theta} \log p_{\bs\theta}({\bf x}) = \frac{1}{p_{\bs\theta}({\bf x})}
  \nabla_{\bs\theta} p_{\bs\theta}({\bf x}) \,,
\end{equation}
%to write the derivative of the expected value Eq.~(\ref{eq:exp_cost}) as a sum of expected values. 
such that the gradient in expr.(\ref{eq:gradients}) could be approximated with MC as:
\begin{equation}
  \nabla_{\bs\theta} \mathbb E_{p_{\bs\theta}}[f({\bf x}; \bs\theta)]
  \approx
  \frac{1}{N_s}\sum_{s=1}^{N_s}(\nabla_{\bs\theta} \log p_{\bs\theta}({\bf x}_s)) f({\bf x}_s;\bs\theta)~.  
\end{equation}

While certainly being a more flexible method, this estimator is known to suffer in practice from large sample-to-sample variance
% , related to the fact that $\mathbb E[\nabla_{\bs\theta} \log p_{\bs\theta}({\bf x}_s)]$ = 0;
although see \cite{Lievin2020} for variance-control methods in this context. Lastly, other treatments have been proposed which attempt to extract the best of both methods above, i.e. to be applicable to distributions beyond those typically reparametrizable, while keeping a low variance (\cite{cong2018go}). 

Up to our knowledge, all the existing efforts applying the solutions mentioned above require to know the normalization of the
distribution $p_{\bs\theta}({\bf x})$, which prevents the use in conjunction with
Monte Carlo methods, where samples of a distribution are often
obtained in the case were the normalization of the distribution
function is unknown.

The question on how to determine derivatives of expected values taken
over complicated distributions $p_{\bs\theta({\bf x})}$, especially in the
case that one relies on Monte Carlo methods to draw samples from such a distribution is still open. 
Ideally one would like an ``automatic'' procedure, i.e. 
extending the benefits of automatic differentiation to Monte Carlo
processes. In this work we will explore two such approaches. 
\newline\newline
First we use the idea of reweighing, to propose an algorithmic
determination of the ...









%%% Local Variables:
%%% mode: latex
%%% TeX-master: "paper"
%%% End:
