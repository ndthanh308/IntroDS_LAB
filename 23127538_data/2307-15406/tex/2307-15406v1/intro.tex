
Monte Carlo (MC) techniques are ubiquitous in science, and
particularly in physics. From particle physics to cosmology, in order
to extract information about the quantities (parameters, quantum
fields, etc) of our physics models we mostly rely on MC, since it
provides an unbiased estimator of the underlying probability
distributions of such quantities, and consequently, of expectation
values of our observables: 
\begin{equation}
  \label{eq:exp_cost}
  \mathbb E_{p_{\theta}} [f(x; \theta)]\,.
\end{equation}
Here $p_{\theta}(x)$ is the distribution of the quantities of interest $x$,  and we
will consider the case where it also depends on the 
parameters $\theta$ (both $x$ and $\theta$ could be multivariate). Two
prominent examples arise in physics: {\it i)} in the context of a
quantum field theory, $x$ represent the quantum fields, while $\theta$
could represent for example the mass of the fields, as well as their
couplings; {\it ii)} in the context of fitting physics models to some
observed data,  $x$ represent the model parameters (e.g. in a
cosmological model, the matter energy density, the Hubble parameter,
etc), while $\theta$ are the so-called
\emph{hyper-parameters}\footnote{These are parameters which the
  analysist considers as deterministic, so they do not follow a
  distribution themselves, but do determine the distribution of the
  ``standard'' parameters.} that fix either their prior distribution,
or the likelihood of the data, or both, for example in a Bayesian
inference framework.  


%The stochastic gradient descent (SGD) is a cornerstone in optimization and  machine learning.
%In many cases we are interested in maximizing an expectation cost function of some vector of parameters $\theta$. 
%Here $p_{\theta}({\bf x})$ is a
% unnormalized
%distribution function of a random vector ${\bf x}$, and wewill consider the case where it also depends on the parameters $\theta$.

 In many cases we are interested in optimizing such expectations w.r.t. $\theta$. The state-of-the-art in optimization is represented by Stochastic Gradient Descent (SGD) methods, especially popular in the statistics and machine learning communities. For the cases at hand, the application of any variant of the SGD algorithm requires
to determine the gradient of the expectation cost
Eq.~(\ref{eq:exp_cost}) w.r.t  $\theta$. 

In the case of Bayesian inference, one of the interesting questions arises when we are concerned about the sensitivity of the Bayesian predictions on the hyper-parameters. Formally these predictions\footnote{More concretely, the distribution of such predictions, known as the {\it predictive distribution} in the Bayesian jargon.} are determined as expected values of the form given in Eq.~(\ref{eq:exp_cost}), and we are interested in
the dependence w.r.t. $\theta$. It is important to note at this point that nowadays, in the Bayesian inference community, the above question is -to our knowledge- not addressed. Indeed, the Bayesian predictions are commonly calculated at optimal values $\boldsymbol{\theta}_{\rm opt}$ of the hyper-parameters, the latter being obtained from a point-wise Maximum Likelihood optimization of an approximation of the Bayesian evidence, or with ``Bayesian optimization'' methods. Typically no further analysis is performed quantifying the impact on the predictions when the hyper-parameters values deviate from $\theta_{\rm opt}$.
% On the other hand, if using a Variational Inference approach, e.g. minimizing the Kullback-Leibler divergence $KL[]$

Another situation in Bayesian inference when the above problem appears is actually very common, specifically in the context of approximate inference, where the aim is to approximate the true posterior $p_{\theta}(x)$ by a distribution $q_{\phi}(x)$. Popular implementations minimize either the forward Kullback-Leibler divergence, KL$[p_{\theta}||q_{\phi}]$, or its reverse: KL$[q_{\phi}||p_{\theta}]$. Since the posterior is unknown (it is what such methods try to approximate in first place), the forward KL can be estimated via reweighting: FKL = $(1/Z_w) E_{q_{\phi}}[w \log(\hat{p}_{\theta}/q_{\phi})]$ (see e.g. \cite{Jordan2021}), where $w=\hat{p}_{\theta}/q_{\phi}$, and $\hat{p}_{\theta}$ is the unnormalized posterior (assumed to be tractable), and $Z_w = E_{q_{\phi}}[w]$. In this case one is interested in minimizing the FKL w.r.t. the parameters $\phi$. In cases where the objective function is the reverse KL (typical case in Variational Infererence) the expectation is directly with respect to $q_{\phi}$. While for simple choices of the latter the procedure is well defined (see below Sect.\ref{sec:existing}), in general it is a complex task when we want to minimize w.r.t. parameters which are implicit in the samples.



In all these cases the key question is the determination of the
gradient and (possibly) higher derivatives 
\begin{equation}
  \label{eq:gradients}
  \frac{\partial}{\partial \theta_j }\mathbb E_{p_{\theta}}[f(x; \theta)]\,,\quad
  \frac{\partial^2}{\partial \theta_j\partial \theta_k }\mathbb E_{p_{\theta}}[f(x; \theta)]\,,\dots
\end{equation}
of expected values, where $\theta_j$ are the components of $\theta$.

In this work we focus on the typical case when the relevant expectations
values Eq.~(\ref{eq:exp_cost}) are determined using some Monte Carlo
(MC) method:
\begin{equation}
  \mathbb E_{p_{\theta}}[f(x; \theta)] \approx
  \frac{1}{N_s}\sum_{s=1}^{N_s} f(x_s; \theta)~,
  \label{eq:MC_est}
\end{equation}
where $x_s$ are samples from the unnormalized $\hat p_{\theta}$. \emph{Our aim is to develop a formalism to compute the gradients of expr.(\ref{eq:MC_est}) with respect to $\theta$, using automatic differentiation techniques.}

\subsection{Existing methods}
\label{sec:existing}
There are solutions in the literature for this problem: for some simple distributions the reparametrization trick can be used, which is nothing but the ability to express a sample $x$ as a deterministic function $g({\theta,\eta})$, of the parameters $\theta$ and a random variable $\eta$ \emph{that does not depend on $\theta$}. A typical example is when $p_\theta$ is a multivariate Gaussian with mean ${\mu}(\theta)$ and covariance matrix ${\bf C}$, in whose case a sample $x_s$ can be expressed as $x_s = {\mu}(\theta) + {\bf L}\cdot{\eta}_s$, where ${\bf L}$ is the Cholesky decomposition of ${\bf C}$, and the sampled random variable ${\eta}_s\sim{\cal N}({\bf 0},\mathbb{I})$. Clearly, since $x_s$ is an explicit function of $\theta$, so it will be $f(x_s,\theta)$ in Eq.(\ref{eq:MC_est}), making possible to use the usual techniques of Automatic Differentiation to obtain the gradients w.r.t. $\theta$ exactly. For other popular distributions as Gamma, Beta or Dirichet, among others, this simple reparametrization is not possible, and generalizations of the above trick have been developed (e.g. in \cite{Figurnov2018}, using implicit differentiation). Nonetheless, the considered distributions should still be somehow reparametrizable. 

%in some cases the $\theta$-dependence is simple enough so that the distribution function $p(x,\theta)$ can be reparametrized as a deterministic function of $g(\theta,\eta)$ of the parameters $\theta$ and a random variable $\eta$ \emph{that does not depend on $\theta$}. A typical example, for example,  is when $p$ is a multivariate normal distribution and the parameters $\theta$ represent the mean: in this case the distribution $p$ is easily obtained from the multivariate with zero mean by a simple translation, making possible the determination of the derivatives of expectation values Eq.~(\ref{eq:exp_cost}) by just using the usual techniques of Automatic Differentiation.

Another existing alternative is to use the \emph{score function estimator}, allowing us to obtain the gradient for a more general case. This method just uses the trivial relation
\begin{equation}
  \nabla_{\theta} \log p_{\theta}(x) = \frac{1}{p_{\theta}(x)}
  \nabla_{\theta} p_{\theta}(x) \,,
\end{equation}
%to write the derivative of the expected value Eq.~(\ref{eq:exp_cost}) as a sum of expected values. 
such that the gradient in expr.(\ref{eq:gradients}) could be approximated with MC as:
\begin{equation}
  \nabla_{\theta} \mathbb E_{p_{\theta}}[f(x; \theta)]
  \approx
  \frac{1}{N_s}\sum_{s=1}^{N_s}
  \Big[
    (\nabla_{\theta} \log p_{\theta}(x_s)) f(x_s;\theta)
    + \nabla_\theta f(x_s;\theta)
    \Big]
    \label{eq:sfe}
\end{equation}

While certainly being a more flexible method, this estimator is known to suffer in practice from large sample-to-sample variance
% , related to the fact that $\mathbb E[\nabla_{\theta} \log p_{\theta}({\bf x}_s)]$ = 0;
(although see \cite{Lievin2020} for variance-control methods in this context). Lastly, other treatments have been proposed which attempt to extract the best of both methods above, i.e. to be applicable to distributions beyond those typically reparametrizable, while keeping a low variance (\cite{cong2018go}). 

Up to our knowledge, all the existing efforts applying the solutions mentioned above require to know the normalization of the
distribution $p_{\theta}(x)$, which prevents the use in conjunction with
Monte Carlo methods, where samples of a distribution are often
obtained in the case where the corresponding normalization is unknown.

The question on how to determine derivatives of expected values taken
over complicated distributions $p_\theta(x)$, especially in the
case that one relies on Monte Carlo methods to draw samples from such a distribution is still open. 
Ideally one would like an ``automatic'' procedure, i.e. 
extending the benefits of automatic differentiation to Monte Carlo
processes. In this work we will explore two such approaches.
First we use the idea of reweighting, where the expectation values, \cref{eq:MC_est}, are modified by a weighting factor that takes into account the dependence on the parameters, but that utilizes unmodified samples for the average.
The second method is a modification of Hamiltonian sampling algorithms, that includes the generation of samples that carry themselves the information about the parameters.
Both methods can be used for unnormalized probability distributions and allow the computation of derivatives of arbitrary orders.








%%% Local Variables:
%%% mode: latex
%%% TeX-master: "paper"
%%% End:
