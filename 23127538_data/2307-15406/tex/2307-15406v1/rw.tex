
Samples $\{x^\alpha\}_{\alpha=1}^N$ of some distribution
$p_{\theta}(x)$ allows to estimate expectation values
\begin{equation}
  \mathbb E_{p_\theta}[f(x)] = \frac{1}{N}\sum_{A=1}^N f(x^\alpha;\theta) + \mathcal
  O\left( \frac{1}{\sqrt{N}} \right) \,.
\end{equation}
In this expression, $\theta$ are some parameters that the distribution
function (and possibly the function $f$) depends on. 
We are interested in obtaining the gradient of expectation values with
respect to the parameters $\theta$
\begin{equation}
  O_n = \frac{\partial^n}{\partial \theta^n} \mathbb E_{p_\theta}[f(x; \theta)]\,.
\end{equation}

Our proposal to determine these derivatives is based on
\emph{reweighting} (a.k.a. importance sampling). 
If we have $N$ samples $\{x^\alpha\}_{\alpha=1}^{N}$ of the
distribution $p_\theta$ they can be   
used to determine expectation values of a
different distribution $p'$ thanks to the identity
\begin{equation}
  \label{eq:rw}
  \mathbb E_{p'}[f(x;\theta)] = \frac{\mathbb E_{p_\theta}\left[\frac{p'}{p_\theta} f(x;\theta)\right]}{\mathbb E_{p_\theta}\left[ \frac{p'}{p_\theta} \right]} = 
  \frac{\sum_{\alpha=1}^N w^\alpha f(x^\alpha;\theta)}{\sum_{\alpha=1}^N w^\alpha} + \mathcal
  O\left( \frac{1}{\sqrt{N}} \right)\,,
\end{equation}
where $w^\alpha = p'(x^\alpha)/p_\theta(x^\alpha)$ are usually called
\emph{reweighting factors}. 
Our approach consists in using for the target distribution
\begin{equation}
  p'(x) = p_{\tilde \theta(\epsilon)}(x)\,, \qquad (\tilde \theta_i(\epsilon) = \theta_i + \epsilon_i)\,.
\end{equation}
With this substitution, the reweighting factors will become truncated
polynomials
\begin{equation}
  \tilde w^\alpha(\epsilon) = \frac{p_{\tilde \theta}(x^\alpha)}{p_\theta(x^\alpha)} =
  \sum_{n \le p}w^\alpha_{n}\epsilon^n,
\end{equation}
with leading coefficients $w^{\alpha}_0 = 1$. 
The basic Eq.~(\ref{eq:rw}) now leads to estimates for the expectation
values in the form of truncated polynomials
\begin{equation}
  \label{eq:rwformula}
  \frac{\sum_{\alpha=1}^N \tilde w^\alpha f(x^\alpha;\tilde \theta)}{\sum_{\alpha=1}^N \tilde w^\alpha} = 
  \sum_{n\le p} O_n\epsilon^n\,,  
\end{equation}
that will give stochastic estimates the Taylor series coefficients of
the expectation values.  i.e.
\begin{equation}
  O_n = \frac{1}{n!} \frac{\partial ^n}{\partial \theta^n} E_{p_\theta}[f(x; \theta)] + \mathcal O \left( \frac{1}{\sqrt{N}} \right)\,.
\end{equation}
Borrowing the terminology of the lattice field theory community, we
distinguish two type of contributions to the derivatives in
Eq.~(\ref{eq:rwformula}):
\begin{description}
\item[Connected contributions:] They come from the explicit dependence
  of the observable $f(x;\tilde \theta)$ on the parameters $\theta$.
\item[Disconnected contributions:] They come from the reweighing
  factors $\tilde w^\alpha$, and account for the implicit dependence
  that the samples $x^\alpha$ have on the parameters $\theta$.
\end{description}

It is important to note that the denominator in Eq.~(\ref{eq:rw})
accounts for the possibility that the distributions are 
unnormalized (i.e this expression is valid in the context of Monte
Carlo sampling, where samples are obtained without knowledge of the
normalization of $p_\theta$).

This reweighting approach can be thought as a generalization of the
score function estimator described in sec.\ref{sec:intro}: indeed, in
the case of normalized distributions, and if one considers only
the first derivatives, the reweighting factors become $\tilde w^\alpha = 1 +
(\nabla_\theta\log p_\theta)\epsilon$, with the first-order coefficient
being precisely the term appearing in expr.(\ref{eq:sfe}).








%%% Local Variables:
%%% mode: latex
%%% TeX-master: "paper"
%%% End:
