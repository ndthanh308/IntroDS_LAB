\begin{thebibliography}{27}
\expandafter\ifx\csname natexlab\endcsname\relax\def\natexlab#1{#1}\fi

\bibitem[{Bojar et~al.(2017)Bojar, Graham, and Kamran}]{bojar-wmt17}
Ond{\v{r}}ej Bojar, Yvette Graham, and Amir Kamran. 2017.
\newblock \href {https://doi.org/10.18653/v1/W17-4755} {Results of the {WMT}17
  metrics shared task}.
\newblock In \emph{Proceedings of the Second Conference on Machine
  Translation}, pages 489--513, Copenhagen, Denmark. Association for
  Computational Linguistics.

\bibitem[{Devlin et~al.(2019)Devlin, Chang, Lee, and Toutanova}]{devlin-bert}
Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019.
\newblock \href {https://doi.org/10.18653/v1/N19-1423} {{BERT}: Pre-training of
  deep bidirectional transformers for language understanding}.
\newblock In \emph{Proceedings of the 2019 Conference of the North {A}merican
  Chapter of the Association for Computational Linguistics: Human Language
  Technologies, Volume 1 (Long and Short Papers)}, pages 4171--4186,
  Minneapolis, Minnesota. Association for Computational Linguistics.

\bibitem[{Ettinger(2020)}]{ettinger-bert-negations}
Allyson Ettinger. 2020.
\newblock \href {https://doi.org/10.1162/tacl_a_00298} {What {BERT} is not:
  Lessons from a new suite of psycholinguistic diagnostics for language
  models}.
\newblock \emph{Transactions of the Association for Computational Linguistics},
  8:34--48.

\bibitem[{Geiger et~al.(2020)Geiger, Richardson, and Potts}]{geiger-neg-nli}
Atticus Geiger, Kyle Richardson, and Christopher Potts. 2020.
\newblock \href {https://doi.org/10.18653/v1/2020.blackboxnlp-1.16} {Neural
  natural language inference models partially embed theories of lexical
  entailment and negation}.
\newblock In \emph{Proceedings of the Third BlackboxNLP Workshop on Analyzing
  and Interpreting Neural Networks for NLP}, pages 163--173, Online.
  Association for Computational Linguistics.

\bibitem[{Goodfellow et~al.(2013)Goodfellow, Mirza, Xiao, Courville, and
  Bengio}]{Goodfellow-catastrophic-forgetting}
Ian~J. Goodfellow, Mehdi Mirza, Da~Xiao, Aaron Courville, and Yoshua Bengio.
  2013.
\newblock \href {https://doi.org/10.48550/ARXIV.1312.6211} {An empirical
  investigation of catastrophic forgetting in gradient-based neural networks}.

\bibitem[{Helwe et~al.(2022)Helwe, Coumes, Clavel, and Suchanek}]{helwe-TINA}
Chadi Helwe, Simon Coumes, Chlo{\'e} Clavel, and Fabian Suchanek. 2022.
\newblock \href {https://aclanthology.org/2022.findings-emnlp.301} {{TINA}:
  Textual inference with negation augmentation}.
\newblock In \emph{Findings of the Association for Computational Linguistics:
  EMNLP 2022}, pages 4086--4099, Abu Dhabi, United Arab Emirates. Association
  for Computational Linguistics.

\bibitem[{Honnibal et~al.(2020)Honnibal, Montani, Van~Landeghem, and
  Boyd}]{Honnibal-spacy}
Matthew Honnibal, Ines Montani, Sofie Van~Landeghem, and Adriane Boyd. 2020.
\newblock \href {https://doi.org/10.5281/zenodo.1212303} {{spaCy:
  Industrial-strength Natural Language Processing in Python}}.

\bibitem[{Hosseini et~al.(2021)Hosseini, Reddy, Bahdanau, Hjelm, Sordoni, and
  Courville}]{hosseini-BERTNOT}
Arian Hosseini, Siva Reddy, Dzmitry Bahdanau, R~Devon Hjelm, Alessandro
  Sordoni, and Aaron Courville. 2021.
\newblock \href {https://doi.org/10.18653/v1/2021.naacl-main.102}
  {Understanding by understanding not: Modeling negation in language models}.
\newblock In \emph{Proceedings of the 2021 Conference of the North American
  Chapter of the Association for Computational Linguistics: Human Language
  Technologies}, pages 1301--1312, Online. Association for Computational
  Linguistics.

\bibitem[{Karpinska et~al.(2022)Karpinska, Raj, Thai, Song, Gupta, and
  Iyyer}]{karpinska-demetr}
Marzena Karpinska, Nishant Raj, Katherine Thai, Yixiao Song, Ankita Gupta, and
  Mohit Iyyer. 2022.
\newblock \href {https://aclanthology.org/2022.emnlp-main.649} {{DEMETR}:
  Diagnosing evaluation metrics for translation}.
\newblock In \emph{Proceedings of the 2022 Conference on Empirical Methods in
  Natural Language Processing}, pages 9540--9561, Abu Dhabi, United Arab
  Emirates. Association for Computational Linguistics.

\bibitem[{Kassner and Sch{\"u}tze(2020)}]{kassner-bert-negations}
Nora Kassner and Hinrich Sch{\"u}tze. 2020.
\newblock \href {https://doi.org/10.18653/v1/2020.acl-main.698} {Negated and
  misprimed probes for pretrained language models: Birds can talk, but cannot
  fly}.
\newblock In \emph{Proceedings of the 58th Annual Meeting of the Association
  for Computational Linguistics}, pages 7811--7818, Online. Association for
  Computational Linguistics.

\bibitem[{Khandelwal and Sawant(2020)}]{khandelwal-negbert}
Aditya Khandelwal and Suraj Sawant. 2020.
\newblock \href {https://aclanthology.org/2020.lrec-1.704} {{N}eg{BERT}: A
  transfer learning approach for negation detection and scope resolution}.
\newblock In \emph{Proceedings of the Twelfth Language Resources and Evaluation
  Conference}, pages 5739--5748, Marseille, France. European Language Resources
  Association.

\bibitem[{Koch et~al.(2022)Koch, A{\ss}enmacher, and
  Heumann}]{koch-continuous-perturbation}
Philipp Koch, Matthias A{\ss}enmacher, and Christian Heumann. 2022.
\newblock \href {https://doi.org/10.18653/v1/2022.insights-1.25} {Pre-trained
  language models evaluating themselves - a comparative study}.
\newblock In \emph{Proceedings of the Third Workshop on Insights from Negative
  Results in NLP}, pages 180--187, Dublin, Ireland. Association for
  Computational Linguistics.

\bibitem[{Kotzias et~al.(2015)Kotzias, Denil, de~Freitas, and
  Smyth}]{kotzias-sentiment-dataset}
Dimitrios Kotzias, Misha Denil, Nando de~Freitas, and Padhraic Smyth. 2015.
\newblock \href {https://doi.org/10.1145/2783258.2783380} {From group to
  individual labels using deep features}.
\newblock In \emph{Proceedings of the 21th ACM SIGKDD International Conference
  on Knowledge Discovery and Data Mining}, KDD '15, page 597–606, New York,
  NY, USA. Association for Computing Machinery.

\bibitem[{Leung et~al.(2022)Leung, Wein, and
  Schneider}]{leung-negation-bertscore}
Wai~Ching Leung, Shira Wein, and Nathan Schneider. 2022.
\newblock \href {https://aclanthology.org/2022.gem-1.8} {Semantic similarity as
  a window into vector- and graph-based metrics}.
\newblock In \emph{Proceedings of the 2nd Workshop on Natural Language
  Generation, Evaluation, and Metrics (GEM)}, pages 106--115, Abu Dhabi, United
  Arab Emirates (Hybrid). Association for Computational Linguistics.

\bibitem[{Moore and Barnes(2021)}]{moore-neg-sentiment}
Andrew Moore and Jeremy Barnes. 2021.
\newblock \href {https://doi.org/10.18653/v1/2021.naacl-main.227} {Multi-task
  learning of negation and speculation for targeted sentiment classification}.
\newblock In \emph{Proceedings of the 2021 Conference of the North American
  Chapter of the Association for Computational Linguistics: Human Language
  Technologies}, pages 2838--2869, Online. Association for Computational
  Linguistics.

\bibitem[{Muennighoff et~al.(2023)Muennighoff, Tazi, Magne, and
  Reimers}]{muennighoff-mteb}
Niklas Muennighoff, Nouamane Tazi, Loic Magne, and Nils Reimers. 2023.
\newblock \href {https://aclanthology.org/2023.eacl-main.148} {{MTEB}: Massive
  text embedding benchmark}.
\newblock In \emph{Proceedings of the 17th Conference of the European Chapter
  of the Association for Computational Linguistics}, pages 2014--2037,
  Dubrovnik, Croatia. Association for Computational Linguistics.

\bibitem[{Pu et~al.(2021)Pu, Chung, Parikh, Gehrmann, and Sellam}]{pu-bleurt20}
Amy Pu, Hyung~Won Chung, Ankur Parikh, Sebastian Gehrmann, and Thibault Sellam.
  2021.
\newblock \href {https://doi.org/10.18653/v1/2021.emnlp-main.58} {Learning
  compact metrics for {MT}}.
\newblock In \emph{Proceedings of the 2021 Conference on Empirical Methods in
  Natural Language Processing}, pages 751--762, Online and Punta Cana,
  Dominican Republic. Association for Computational Linguistics.

\bibitem[{Reimers and Gurevych(2019)}]{reimers-sentence-bert}
Nils Reimers and Iryna Gurevych. 2019.
\newblock \href {https://doi.org/10.18653/v1/D19-1410} {Sentence-{BERT}:
  Sentence embeddings using {S}iamese {BERT}-networks}.
\newblock In \emph{Proceedings of the 2019 Conference on Empirical Methods in
  Natural Language Processing and the 9th International Joint Conference on
  Natural Language Processing (EMNLP-IJCNLP)}, pages 3982--3992, Hong Kong,
  China. Association for Computational Linguistics.

\bibitem[{Sai et~al.(2021)Sai, Dixit, Sheth, Mohan, and
  Khapra}]{sai-perturbation}
Ananya~B. Sai, Tanay Dixit, Dev~Yashpal Sheth, Sreyas Mohan, and Mitesh~M.
  Khapra. 2021.
\newblock \href {https://doi.org/10.18653/v1/2021.emnlp-main.575} {Perturbation
  {C}heck{L}ists for evaluating {NLG} evaluation metrics}.
\newblock In \emph{Proceedings of the 2021 Conference on Empirical Methods in
  Natural Language Processing}, pages 7219--7234, Online and Punta Cana,
  Dominican Republic. Association for Computational Linguistics.

\bibitem[{Sathe et~al.(2020)Sathe, Ather, Le, Perry, and
  Park}]{sathe-wiki-factcheck}
Aalok Sathe, Salar Ather, Tuan~Manh Le, Nathan Perry, and Joonsuk Park. 2020.
\newblock \href {https://aclanthology.org/2020.lrec-1.849} {Automated
  fact-checking of claims from {W}ikipedia}.
\newblock In \emph{Proceedings of the Twelfth Language Resources and Evaluation
  Conference}, pages 6874--6882, Marseille, France. European Language Resources
  Association.

\bibitem[{Sellam et~al.(2020)Sellam, Das, and Parikh}]{sellam-bleurt}
Thibault Sellam, Dipanjan Das, and Ankur Parikh. 2020.
\newblock \href {https://doi.org/10.18653/v1/2020.acl-main.704} {{BLEURT}:
  Learning robust metrics for text generation}.
\newblock In \emph{Proceedings of the 58th Annual Meeting of the Association
  for Computational Linguistics}, pages 7881--7892, Online. Association for
  Computational Linguistics.

\bibitem[{Song et~al.(2020)Song, Tan, Qin, Lu, and Liu}]{song-mpnet}
Kaitao Song, Xu~Tan, Tao Qin, Jianfeng Lu, and Tie-Yan Liu. 2020.
\newblock Mpnet: Masked and permuted pre-training for language understanding.
\newblock In \emph{Proceedings of the 34th International Conference on Neural
  Information Processing Systems}, NIPS'20, Red Hook, NY, USA. Curran
  Associates Inc.

\bibitem[{Truong et~al.(2022{\natexlab{a}})Truong, Baldwin, Cohn, and
  Verspoor}]{truong-cue-pretrain}
Thinh Truong, Timothy Baldwin, Trevor Cohn, and Karin Verspoor.
  2022{\natexlab{a}}.
\newblock \href {https://doi.org/10.18653/v1/2022.naacl-main.309} {Improving
  negation detection with negation-focused pre-training}.
\newblock In \emph{Proceedings of the 2022 Conference of the North American
  Chapter of the Association for Computational Linguistics: Human Language
  Technologies}, pages 4188--4193, Seattle, United States. Association for
  Computational Linguistics.

\bibitem[{Truong et~al.(2022{\natexlab{b}})Truong, Otmakhova, Baldwin, Cohn,
  Lau, and Verspoor}]{truong-NaN-NLI}
Thinh~Hung Truong, Yulia Otmakhova, Timothy Baldwin, Trevor Cohn, Jey~Han Lau,
  and Karin Verspoor. 2022{\natexlab{b}}.
\newblock \href {https://aclanthology.org/2022.aacl-main.65} {Not another
  negation benchmark: The {N}a{N}-{NLI} test suite for sub-clausal negation}.
\newblock In \emph{Proceedings of the 2nd Conference of the Asia-Pacific
  Chapter of the Association for Computational Linguistics and the 12th
  International Joint Conference on Natural Language Processing (Volume 1: Long
  Papers)}, pages 883--894, Online only. Association for Computational
  Linguistics.

\bibitem[{Wang et~al.(2018)Wang, Singh, Michael, Hill, Levy, and
  Bowman}]{wang-glue}
Alex Wang, Amanpreet Singh, Julian Michael, Felix Hill, Omer Levy, and Samuel
  Bowman. 2018.
\newblock \href {https://doi.org/10.18653/v1/W18-5446} {{GLUE}: A multi-task
  benchmark and analysis platform for natural language understanding}.
\newblock In \emph{Proceedings of the 2018 {EMNLP} Workshop {B}lackbox{NLP}:
  Analyzing and Interpreting Neural Networks for {NLP}}, pages 353--355,
  Brussels, Belgium. Association for Computational Linguistics.

\bibitem[{Wolf et~al.(2020)Wolf, Debut, Sanh, Chaumond, Delangue, Moi, Cistac,
  Rault, Louf, Funtowicz, Davison, Shleifer, von Platen, Ma, Jernite, Plu, Xu,
  Scao, Gugger, Drame, Lhoest, and Rush}]{Wolf-Huggingface}
Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue,
  Anthony Moi, Pierric Cistac, Tim Rault, Rémi Louf, Morgan Funtowicz, Joe
  Davison, Sam Shleifer, Patrick von Platen, Clara Ma, Yacine Jernite, Julien
  Plu, Canwen Xu, Teven~Le Scao, Sylvain Gugger, Mariama Drame, Quentin Lhoest,
  and Alexander~M. Rush. 2020.
\newblock \href {https://www.aclweb.org/anthology/2020.emnlp-demos.6}
  {Transformers: State-of-the-art natural language processing}.
\newblock In \emph{Proceedings of the 2020 Conference on Empirical Methods in
  Natural Language Processing: System Demonstrations}, pages 38--45, Online.
  Association for Computational Linguistics.

\bibitem[{Zhang* et~al.(2020)Zhang*, Kishore*, Wu*, Weinberger, and
  Artzi}]{zhang-bertscore}
Tianyi Zhang*, Varsha Kishore*, Felix Wu*, Kilian~Q. Weinberger, and Yoav
  Artzi. 2020.
\newblock \href {https://openreview.net/forum?id=SkeHuCVFDr} {Bertscore:
  Evaluating text generation with bert}.
\newblock In \emph{International Conference on Learning Representations}.

\end{thebibliography}
