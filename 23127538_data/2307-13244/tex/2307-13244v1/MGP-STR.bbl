% Generated by IEEEtran.bst, version: 1.14 (2015/08/26)
\begin{thebibliography}{100}
\providecommand{\url}[1]{#1}
\csname url@samestyle\endcsname
\providecommand{\newblock}{\relax}
\providecommand{\bibinfo}[2]{#2}
\providecommand{\BIBentrySTDinterwordspacing}{\spaceskip=0pt\relax}
\providecommand{\BIBentryALTinterwordstretchfactor}{4}
\providecommand{\BIBentryALTinterwordspacing}{\spaceskip=\fontdimen2\font plus
\BIBentryALTinterwordstretchfactor\fontdimen3\font minus
  \fontdimen4\font\relax}
\providecommand{\BIBforeignlanguage}[2]{{%
\expandafter\ifx\csname l@#1\endcsname\relax
\typeout{** WARNING: IEEEtran.bst: No hyphenation pattern has been}%
\typeout{** loaded for the language `#1'. Using the pattern for}%
\typeout{** the default language instead.}%
\else
\language=\csname l@#1\endcsname
\fi
#2}}
\providecommand{\BIBdecl}{\relax}
\BIBdecl

\bibitem{long2021scene}
S.~Long, X.~He, and C.~Yao, ``Scene text detection and recognition: The deep
  learning era,'' \emph{Int. J. Comput. Vis.}, vol. 129, no.~1, pp. 161--184,
  2021.

\bibitem{zhu2016scene}
Y.~Zhu, C.~Yao, and X.~Bai, ``Scene text detection and recognition: Recent
  advances and future trends,'' \emph{Frontiers of Computer Science}, vol.~10,
  no.~1, pp. 19--36, 2016.

\bibitem{chen2021text}
X.~Chen, L.~Jin, Y.~Zhu, C.~Luo, and T.~Wang, ``Text recognition in the wild: A
  survey,'' \emph{ACM Computing Surveys (CSUR)}, vol.~54, no.~2, pp. 1--35,
  2021.

\bibitem{CRNN}
B.~Shi, X.~Bai, and C.~Yao, ``An end-to-end trainable neural network for
  image-based sequence recognition and its application to scene text
  recognition,'' \emph{IEEE Trans. Pattern Anal. Mach. Intell.}, vol.~39,
  no.~11, pp. 2298--2304, 2017.

\bibitem{Focusing}
Z.~Cheng, F.~Bai, Y.~Xu, G.~Zheng, S.~Pu, and S.~Zhou, ``Focusing attention:
  Towards accurate text recognition in natural images,'' in \emph{IEEE Conf.
  Comput. Vis. Pattern Recog.}, 2017, pp. 5086--5094.

\bibitem{ASTER}
B.~Shi, M.~Yang, X.~Wang, P.~Lyu, C.~Yao, and X.~Bai, ``{ASTER:} an attentional
  scene text recognizer with flexible rectification,'' \emph{IEEE Trans.
  Pattern Anal. Mach. Intell.}, vol.~41, no.~9, pp. 2035--2048, 2019.

\bibitem{MASTER}
N.~Lu, W.~Yu, X.~Qi, Y.~Chen, P.~Gong, R.~Xiao, and X.~Bai, ``{MASTER}:
  Multi-aspect non-local network for scene text recognition,'' \emph{Pattern
  Recognition}, vol. 117, p. 107980, 2021.

\bibitem{SRN}
D.~Yu, X.~Li, C.~Zhang, T.~Liu, J.~Han, J.~Liu, and E.~Ding, ``Towards accurate
  scene text recognition with semantic reasoning networks,'' in \emph{IEEE
  Conf. Comput. Vis. Pattern Recog.}, 2020, pp. 12\,110--12\,119.

\bibitem{ABInet}
S.~Fang, H.~Xie, Y.~Wang, Z.~Mao, and Y.~Zhang, ``Read like humans: Autonomous,
  bidirectional and iterative language modeling for scene text recognition,''
  in \emph{IEEE Conf. Comput. Vis. Pattern Recog.}, 2021, pp. 7098--7107.

\bibitem{matrn}
B.~Na, Y.~Kim, and S.~Park, ``Multi-modal text recognition networks:
  Interactive enhancements between visual and semantic features,'' in
  \emph{Eur. Conf. Comput. Vis.}, vol. 13688, 2022, pp. 446--463.

\bibitem{dosovitskiy2020image}
A.~Dosovitskiy, L.~Beyer, A.~Kolesnikov, D.~Weissenborn, X.~Zhai,
  T.~Unterthiner, M.~Dehghani, M.~Minderer, G.~Heigold, S.~Gelly, J.~Uszkoreit,
  and N.~Houlsby, ``An image is worth 16x16 words: Transformers for image
  recognition at scale,'' in \emph{Int. Conf. Learn. Represent.}, 2021.

\bibitem{tokenlearner}
M.~S. Ryoo, A.~J. Piergiovanni, A.~Arnab, M.~Dehghani, and A.~Angelova,
  ``Tokenlearner: What can 8 learned tokens do for images and videos?''
  \emph{CoRR}, vol. abs/2106.11297, 2021.

\bibitem{mgp}
P.~Wang, C.~Da, and C.~Yao, ``Multi-granularity prediction for scene text
  recognition,'' in \emph{Eur. Conf. Comput. Vis.}, vol. 13688, 2022, pp.
  339--355.

\bibitem{CLIP}
A.~Radford, J.~W. Kim, C.~Hallacy, A.~Ramesh, G.~Goh, S.~Agarwal, G.~Sastry,
  A.~Askell, P.~Mishkin, J.~Clark, G.~Krueger, and I.~Sutskever, ``Learning
  transferable visual models from natural language supervision,'' in \emph{Int.
  Conf. Mach. Learn.}, vol. 139, 2021, pp. 8748--8763.

\bibitem{IC13}
D.~Karatzas, F.~Shafait, S.~Uchida, M.~Iwamura, L.~G. i~Bigorda, S.~R. Mestre,
  J.~Mas, D.~F. Mota, J.~Almaz{\'{a}}n, and L.~de~las Heras, ``{ICDAR} 2013
  robust reading competition,'' in \emph{ICDAR}, 2013, pp. 1484--1493.

\bibitem{SVT}
K.~Wang, B.~Babenko, and S.~J. Belongie, ``End-to-end scene text recognition,''
  in \emph{Int. Conf. Comput. Vis.}, 2011, pp. 1457--1464.

\bibitem{IIIT}
A.~Mishra, K.~Alahari, and C.~V. Jawahar, ``Scene text recognition using higher
  order language priors,'' in \emph{BMVC}, 2012, pp. 1--11.

\bibitem{IC15}
D.~Karatzas, L.~Gomez{-}Bigorda, A.~Nicolaou, S.~K. Ghosh, A.~D. Bagdanov,
  M.~Iwamura, J.~Matas, L.~Neumann, V.~R. Chandrasekhar, S.~Lu, F.~Shafait,
  S.~Uchida, and E.~Valveny, ``{ICDAR} 2015 competition on robust reading,'' in
  \emph{ICDAR}, 2015, pp. 1156--1160.

\bibitem{SVTP}
T.~Q. Phan, P.~Shivakumara, S.~Tian, and C.~L. Tan, ``Recognizing text with
  perspective distortion in natural scenes,'' in \emph{Int. Conf. Comput.
  Vis.}, 2013, pp. 569--576.

\bibitem{CUTE}
A.~Risnumawan, P.~Shivakumara, C.~S. Chan, and C.~L. Tan, ``A robust arbitrary
  text detection system for natural scene images,'' \emph{Expert Syst. Appl.},
  vol.~41, no.~18, pp. 8027--8048, 2014.

\bibitem{IAM}
U.~Marti and H.~Bunke, ``The iam-database: an english sentence database for
  offline handwriting recognition,'' \emph{Int. J. Document Anal. Recognit.},
  vol.~5, no.~1, pp. 39--46, 2002.

\bibitem{CVL}
F.~Kleber, S.~Fiel, M.~Diem, and R.~Sablatnig, ``Cvl-database: An off-line
  database for writer retrieval, writer identification and word spotting,'' in
  \emph{ICDAR}, 2013, pp. 560--564.

\bibitem{RIMES}
E.~Grosicki, M.~Carr{\'{e}}, J.~Brodin, and E.~Geoffrois, ``Results of the
  {RIMES} evaluation campaign for handwritten mail processing,'' in \emph{10th
  International Conference on Document Analysis and Recognition, {ICDAR} 2009,
  Barcelona, Spain, 26-29 July 2009}.\hskip 1em plus 0.5em minus 0.4em\relax
  {IEEE} Computer Society, 2009, pp. 941--945.

\bibitem{ArT}
C.~K. Chng, E.~Ding, J.~Liu, D.~Karatzas, C.~S. Chan, L.~Jin, Y.~Liu, Y.~Sun,
  C.~C. Ng, C.~Luo, Z.~Ni, C.~Fang, S.~Zhang, and J.~Han, ``{ICDAR2019} robust
  reading challenge on arbitrary-shaped text - rrc-art,'' in \emph{ICDAR},
  2019, pp. 1571--1576.

\bibitem{COCO}
A.~Veit, T.~Matera, L.~Neumann, J.~Matas, and S.~J. Belongie, ``Coco-text:
  Dataset and benchmark for text detection and recognition in natural images,''
  \emph{CoRR}, vol. abs/1601.07140, 2016.

\bibitem{Uber}
Y.~Zhang, L.~Gueguen, I.~Zharkov, P.~Zhang, K.~Seifert, and B.~Kadlec,
  ``Uber-text: A large-scale dataset for optical character recognition from
  street-level imagery,'' in \emph{SUNw: Scene Understanding Workshop-CVPR},
  vol. 2017, 2017, pp. 1--5.

\bibitem{priya2016online}
A.~Priya, S.~Mishra, S.~Raj, S.~Mandal, and S.~Datta, ``Online and offline
  character recognition: A survey,'' in \emph{2016 International conference on
  communication and signal processing (ICCSP)}.\hskip 1em plus 0.5em minus
  0.4em\relax IEEE, 2016, pp. 0967--0970.

\bibitem{purohit2016literature}
A.~Purohit and S.~S. Chauhan, ``A literature survey on handwritten character
  recognition,'' \emph{International Journal of Computer Science and
  Information Technologies (IJCSIT)}, vol.~7, no.~1, pp. 1--5, 2016.

\bibitem{chen2023vlp}
F.-L. Chen, D.-Z. Zhang, M.-L. Han, X.-Y. Chen, J.~Shi, S.~Xu, and B.~Xu,
  ``Vlp: A survey on vision-language pre-training,'' \emph{Machine Intelligence
  Research}, vol.~20, no.~1, pp. 38--56, 2023.

\bibitem{vgg}
K.~Simonyan and A.~Zisserman, ``Very deep convolutional networks for
  large-scale image recognition,'' in \emph{Int. Conf. Learn. Represent.},
  2015.

\bibitem{resnet}
K.~He, X.~Zhang, S.~Ren, and J.~Sun, ``Deep residual learning for image
  recognition,'' in \emph{IEEE Conf. Comput. Vis. Pattern Recog.}, 2016, pp.
  770--778.

\bibitem{rnn1}
C.~Lee and S.~Osindero, ``Recursive recurrent nets with attention modeling for
  {OCR} in the wild,'' in \emph{IEEE Conf. Comput. Vis. Pattern Recog.}, 2016,
  pp. 2231--2239.

\bibitem{rare}
B.~Shi, X.~Wang, P.~Lyu, C.~Yao, and X.~Bai, ``Robust scene text recognition
  with automatic rectification,'' in \emph{IEEE Conf. Comput. Vis. Pattern
  Recog.}, 2016, pp. 4168--4176.

\bibitem{Rosetta}
F.~Borisyuk, A.~Gordo, and V.~Sivakumar, ``Rosetta: Large scale system for text
  detection and recognition in images,'' in \emph{SIGKDD}, Y.~Guo and
  F.~Farooq, Eds., 2018, pp. 71--79.

\bibitem{STAR-Net}
W.~Liu, C.~Chen, K.~K. Wong, Z.~Su, and J.~Han, ``Star-net: {A} spatial
  attention residue network for scene text recognition,'' in \emph{BMVC}, 2016.

\bibitem{deep}
J.~Baek, G.~Kim, J.~Lee, S.~Park, D.~Han, S.~Yun, S.~J. Oh, and H.~Lee, ``What
  is wrong with scene text recognition model comparisons? dataset and model
  analysis,'' in \emph{Int. Conf. Comput. Vis.}, 2019, pp. 4714--4722.

\bibitem{GCRNN}
J.~Wang and X.~Hu, ``Gated recurrent convolution neural network for {OCR},'' in
  \emph{Adv. Neural Inform. Process. Syst.}, 2017, pp. 335--344.

\bibitem{zhang2022context}
X.~Zhang, B.~Zhu, X.~Yao, Q.~Sun, R.~Li, and B.~Yu, ``Context-based contrastive
  learning for scene text recognition,'' in \emph{AAAI}, 2022, pp. 888--896.

\bibitem{PIMNet}
Z.~Qiao, Y.~Zhou, J.~Wei, W.~Wang, Y.~Zhang, N.~Jiang, H.~Wang, and W.~Wang,
  ``Pimnet: {A} parallel, iterative and mimicking network for scene text
  recognition,'' in \emph{ACM Int. Conf. Multimedia}, 2021, pp. 2046--2055.

\bibitem{liu2022perceiving}
H.~Liu, B.~Wang, Z.~Bao, M.~Xue, S.~Kang, D.~Jiang, Y.~Liu, and B.~Ren,
  ``Perceiving stroke-semantic context: Hierarchical contrastive learning for
  robust scene text recognition,'' in \emph{AAAI}, 2022, pp. 1702--1710.

\bibitem{wan20192d}
Z.~Wan, F.~Xie, Y.~Liu, X.~Bai, and C.~Yao, ``2d-ctc for scene text
  recognition,'' \emph{arXiv preprint arXiv:1907.09705}, 2019.

\bibitem{gtc}
W.~Hu, X.~Cai, J.~Hou, S.~Yi, and Z.~Lin, ``{GTC:} guided training of {CTC}
  towards efficient and accurate scene text recognition,'' in \emph{AAAI},
  2020, pp. 11\,005--11\,012.

\bibitem{ctc2}
P.~He, W.~Huang, Y.~Qiao, C.~C. Loy, and X.~Tang, ``Reading scene text in deep
  convolutional sequences,'' in \emph{AAAI}, 2016, pp. 3501--3508.

\bibitem{ctc}
A.~Graves, S.~Fern{\'{a}}ndez, F.~J. Gomez, and J.~Schmidhuber, ``Connectionist
  temporal classification: labelling unsegmented sequence data with recurrent
  neural networks,'' in \emph{Int. Conf. Mach. Learn.}, vol. 148, 2006, pp.
  369--376.

\bibitem{seg}
M.~Liao, J.~Zhang, Z.~Wan, F.~Xie, J.~Liang, P.~Lyu, C.~Yao, and X.~Bai,
  ``Scene text recognition from two-dimensional perspective,'' in \emph{AAAI},
  2019, pp. 8714--8721.

\bibitem{Vocabulary}
Z.~Wan, J.~Zhang, L.~Zhang, J.~Luo, and C.~Yao, ``On vocabulary reliance in
  scene text recognition,'' in \emph{IEEE Conf. Comput. Vis. Pattern Recog.},
  2020, pp. 11\,422--11\,431.

\bibitem{TextSpotter}
M.~Liao, P.~Lyu, M.~He, C.~Yao, W.~Wu, and X.~Bai, ``Mask textspotter: An
  end-to-end trainable neural network for spotting text with arbitrary
  shapes,'' \emph{{IEEE} Trans. Pattern Anal. Mach. Intell.}, vol.~43, no.~2,
  pp. 532--548, 2021.

\bibitem{TextScanner}
Z.~Wan, M.~He, H.~Chen, X.~Bai, and C.~Yao, ``Textscanner: Reading characters
  in order for robust scene text recognition,'' in \emph{AAAI}, 2020, pp.
  12\,120--12\,127.

\bibitem{trans}
A.~Vaswani, N.~Shazeer, N.~Parmar, J.~Uszkoreit, L.~Jones, A.~N. Gomez,
  L.~Kaiser, and I.~Polosukhin, ``Attention is all you need,'' in \emph{Adv.
  Neural Inform. Process. Syst.}, 2017, pp. 5998--6008.

\bibitem{ViTSTR}
R.~Atienza, ``Vision transformer for fast and efficient scene text
  recognition,'' in \emph{ICDAR}, vol. 12821, 2021, pp. 319--334.

\bibitem{ptie}
Y.~L. Tan, A.~W. Kong, and J.~Kim, ``Pure transformer with integrated experts
  for scene text recognition,'' in \emph{Eur. Conf. Comput. Vis.}, vol. 13688,
  2022, pp. 481--497.

\bibitem{TrOCR}
M.~Li, T.~Lv, L.~Cui, Y.~Lu, D.~A.~F. Flor{\^{e}}ncio, C.~Zhang, Z.~Li, and
  F.~Wei, ``Trocr: Transformer-based optical character recognition with
  pre-trained models,'' in \emph{AAAI}, 2023, pp. 13\,094--13\,102.

\bibitem{liu2021swin}
Z.~Liu, Y.~Lin, Y.~Cao, H.~Hu, Y.~Wei, Z.~Zhang, S.~Lin, and B.~Guo, ``Swin
  transformer: Hierarchical vision transformer using shifted windows,'' in
  \emph{Int. Conf. Comput. Vis.}, 2021, pp. 9992--10\,002.

\bibitem{SegFormer}
E.~Xie, W.~Wang, Z.~Yu, A.~Anandkumar, J.~M. Alvarez, and P.~Luo, ``Segformer:
  Simple and efficient design for semantic segmentation with transformers,''
  \emph{CoRR}, vol. abs/2105.15203, 2021.

\bibitem{vlan}
Y.~Wang, H.~Xie, S.~Fang, J.~Wang, S.~Zhu, and Y.~Zhang, ``From two to one: {A}
  new scene text recognizer with visual language modeling network,'' in
  \emph{Int. Conf. Comput. Vis.}, 2021, pp. 1--10.

\bibitem{levocr}
C.~Da, P.~Wang, and C.~Yao, ``Levenshtein {OCR},'' in \emph{Eur. Conf. Comput.
  Vis.}, vol. 13688, 2022, pp. 322--338.

\bibitem{PARSeq}
D.~Bautista and R.~Atienza, ``Scene text recognition with permuted
  autoregressive sequence models,'' in \emph{Eur. Conf. Comput. Vis.}, vol.
  13688, 2022, pp. 178--196.

\bibitem{AFDM}
A.~K. Bhunia, A.~Das, A.~K. Bhunia, P.~S.~R. Kishore, and P.~P. Roy,
  ``Handwriting recognition in low-resource scripts using adversarial
  learning,'' in \emph{IEEE Conf. Comput. Vis. Pattern Recog.}, 2019, pp.
  4767--4776.

\bibitem{DAN}
T.~Wang, Y.~Zhu, L.~Jin, C.~Luo, X.~Chen, Y.~Wu, Q.~Wang, and M.~Cai,
  ``Decoupled attention network for text recognition,'' in \emph{AAAI}, 2020,
  pp. 12\,216--12\,224.

\bibitem{learnToAug}
C.~Luo, Y.~Zhu, L.~Jin, and Y.~Wang, ``Learn to augment: Joint data
  augmentation and network optimization for text recognition,'' in \emph{IEEE
  Conf. Comput. Vis. Pattern Recog.}, 2020, pp. 13\,743--13\,752.

\bibitem{cnn-n-gram}
A.~Poznanski and L.~Wolf, ``Cnn-n-gram for handwriting word recognition,'' in
  \emph{IEEE Conf. Comput. Vis. Pattern Recog.}, 2016, pp. 2305--2314.

\bibitem{phocnet}
S.~Sudholt and G.~A. Fink, ``Phocnet: A deep convolutional neural network for
  word spotting in handwritten documents,'' in \emph{2016 15th International
  Conference on Frontiers in Handwriting Recognition (ICFHR)}.\hskip 1em plus
  0.5em minus 0.4em\relax IEEE, 2016, pp. 277--282.

\bibitem{offline}
J.~Sueiras, V.~Ruiz, A.~Sanchez, and J.~F. Velez, ``Offline continuous
  handwriting recognition using sequence to sequence neural networks,''
  \emph{Neurocomputing}, vol. 289, pp. 119--128, 2018.

\bibitem{dutta2018improving}
K.~Dutta, P.~Krishnan, M.~Mathew, and C.~Jawahar, ``Improving cnn-rnn hybrid
  networks for handwriting recognition,'' in \emph{2018 16th international
  conference on frontiers in handwriting recognition (ICFHR)}.\hskip 1em plus
  0.5em minus 0.4em\relax IEEE, 2018, pp. 80--85.

\bibitem{GAN}
I.~J. Goodfellow, J.~Pouget{-}Abadie, M.~Mirza, B.~Xu, D.~Warde{-}Farley,
  S.~Ozair, A.~C. Courville, and Y.~Bengio, ``Generative adversarial nets,'' in
  \emph{Adv. Neural Inform. Process. Syst.}, 2014, pp. 2672--2680.

\bibitem{scrabblegan}
S.~Fogel, H.~Averbuch-Elor, S.~Cohen, S.~Mazor, and R.~Litman, ``Scrabblegan:
  Semi-supervised varying length handwritten text generation,'' in \emph{IEEE
  Conf. Comput. Vis. Pattern Recog.}, 2020, pp. 4324--4333.

\bibitem{SLOGAN}
C.~Luo, Y.~Zhu, L.~Jin, Z.~Li, and D.~Peng, ``{SLOGAN:} handwriting style
  synthesis for arbitrary-length and out-of-vocabulary text,'' \emph{IEEE
  Trans. Neural Networks Learn. Syst.}, vol. abs/2202.11456, 2022.

\bibitem{simple}
T.~Chen, S.~Kornblith, M.~Norouzi, and G.~Hinton, ``A simple framework for
  contrastive learning of visual representations,'' in \emph{Int. Conf. Mach.
  Learn.}, 2020, pp. 1597--1607.

\bibitem{momentum}
K.~He, H.~Fan, Y.~Wu, S.~Xie, and R.~Girshick, ``Momentum contrast for
  unsupervised visual representation learning,'' in \emph{IEEE Conf. Comput.
  Vis. Pattern Recog.}, 2020, pp. 9729--9738.

\bibitem{unsupervised}
M.~Caron, I.~Misra, J.~Mairal, P.~Goyal, P.~Bojanowski, and A.~Joulin,
  ``Unsupervised learning of visual features by contrasting cluster
  assignments,'' \emph{Adv. Neural Inform. Process. Syst.}, vol.~33, pp.
  9912--9924, 2020.

\bibitem{big}
T.~Chen, S.~Kornblith, K.~Swersky, M.~Norouzi, and G.~E. Hinton, ``Big
  self-supervised models are strong semi-supervised learners,'' \emph{Adv.
  Neural Inform. Process. Syst.}, vol.~33, pp. 22\,243--22\,255, 2020.

\bibitem{seqclr}
A.~Aberdam, R.~Litman, S.~Tsiper, O.~Anschel, R.~Slossberg, S.~Mazor,
  R.~Manmatha, and P.~Perona, ``Sequence-to-sequence contrastive learning for
  text recognition,'' in \emph{IEEE Conf. Comput. Vis. Pattern Recog.}, 2021,
  pp. 15\,302--15\,312.

\bibitem{DiG}
M.~Yang, M.~Liao, P.~Lu, J.~Wang, S.~Zhu, H.~Luo, Q.~Tian, and X.~Bai,
  ``Reading and writing: Discriminative and generative modeling for
  self-supervised text recognition,'' in \emph{{MM} '22: The 30th {ACM}
  International Conference on Multimedia, Lisboa, Portugal, October 10 - 14,
  2022}.\hskip 1em plus 0.5em minus 0.4em\relax {ACM}, 2022, pp. 4214--4223.

\bibitem{deit}
H.~Touvron, M.~Cord, M.~Douze, F.~Massa, A.~Sablayrolles, and H.~J{\'{e}}gou,
  ``Training data-efficient image transformers {\&} distillation through
  attention,'' in \emph{Int. Conf. Mach. Learn.}, vol. 139, 2021, pp.
  10\,347--10\,357.

\bibitem{subword}
M.~Labeau and A.~Allauzen, ``Character and subword-based word representation
  for neural language modeling prediction,'' in \emph{SWCN@EMNLP}, 2017, pp.
  1--13.

\bibitem{BERT}
J.~Devlin, M.~Chang, K.~Lee, and K.~Toutanova, ``{BERT:} pre-training of deep
  bidirectional transformers for language understanding,'' in \emph{NAACL-HLT},
  2019, pp. 4171--4186.

\bibitem{BPE}
R.~Sennrich, B.~Haddow, and A.~Birch, ``Neural machine translation of rare
  words with subword units,'' in \emph{ACL}.\hskip 1em plus 0.5em minus
  0.4em\relax The Association for Computer Linguistics, 2016.

\bibitem{wordpiece}
M.~Schuster and K.~Nakajima, ``Japanese and korean voice search,'' in
  \emph{ICASSP}, 2012, pp. 5149--5152.

\bibitem{rrlrgu}
J.~Gu, G.~Meng, C.~Da, S.~Xiang, and C.~Pan, ``No-reference image quality
  assessment with reinforcement recursive list-wise ranking,'' in \emph{AAAI},
  2019, pp. 8336--8343.

\bibitem{gpt2}
A.~Radford, J.~Wu, R.~Child, D.~Luan, D.~Amodei, and I.~Sutskever, ``Language
  models are unsupervised multitask learners,'' in \emph{OpenAI blog}, 2019,
  pp. 1--24.

\bibitem{infoNCE}
A.~van~den Oord, Y.~Li, and O.~Vinyals, ``Representation learning with
  contrastive predictive coding,'' \emph{CoRR}, vol. abs/1807.03748, 2018.

\bibitem{MJ1}
M.~Jaderberg, K.~Simonyan, A.~Vedaldi, and A.~Zisserman, ``Synthetic data and
  artificial neural networks for natural scene text recognition,'' \emph{NIPS
  Deep Learning Workshop}, 2014.

\bibitem{MJ2}
------, ``Reading text in the wild with convolutional neural networks,''
  \emph{Int. J. Comput. Vis.}, vol. 116, no.~1, pp. 1--20, 2016.

\bibitem{ST}
A.~Gupta, A.~Vedaldi, and A.~Zisserman, ``Synthetic data for text localisation
  in natural images,'' in \emph{IEEE Conf. Comput. Vis. Pattern Recog.}, 2016,
  pp. 2315--2324.

\bibitem{RCTW}
B.~Shi, C.~Yao, M.~Liao, M.~Yang, P.~Xu, L.~Cui, S.~J. Belongie, S.~Lu, and
  X.~Bai, ``{ICDAR2017} competition on reading chinese text in the wild
  {(RCTW-17)},'' in \emph{ICDAR}, 2017, pp. 1429--1434.

\bibitem{LSVT}
Y.~Sun, D.~Karatzas, C.~S. Chan, L.~Jin, Z.~Ni, C.~K. Chng, Y.~Liu, C.~Luo,
  C.~C. Ng, J.~Han, E.~Ding, and J.~Liu, ``{ICDAR} 2019 competition on
  large-scale street view text with partial labeling - {RRC-LSVT},'' in
  \emph{ICDAR}, 2019, pp. 1557--1562.

\bibitem{MLT}
N.~Nayef, C.~Liu, J.~Ogier, Y.~Patel, M.~Busta, P.~N. Chowdhury, D.~Karatzas,
  W.~Khlif, J.~Matas, U.~Pal, and J.~Burie, ``{ICDAR2019} robust reading
  challenge on multi-lingual scene text detection and recognition -
  {RRC-MLT-2019},'' in \emph{ICDAR}, 2019, pp. 1582--1587.

\bibitem{ReCTS}
R.~Zhang, M.~Yang, X.~Bai, B.~Shi, D.~Karatzas, S.~Lu, C.~V. Jawahar, Y.~Zhou,
  Q.~Jiang, Q.~Song, N.~Li, K.~Zhou, L.~Wang, D.~Wang, and M.~Liao, ``{ICDAR}
  2019 robust reading challenge on reading chinese text on signboard,'' in
  \emph{ICDAR}, 2019, pp. 1577--1581.

\bibitem{TextOCR}
A.~Singh, G.~Pang, M.~Toh, J.~Huang, W.~Galuba, and T.~Hassner, ``Textocr:
  Towards large-scale end-to-end reasoning for arbitrary-shaped scene text,''
  in \emph{IEEE Conf. Comput. Vis. Pattern Recog.}, 2021, pp. 8802--8812.

\bibitem{OpenVINO}
I.~Krylov, S.~Nosov, and V.~Sovrasov, ``Open images {V5} text annotation and
  yet another mask text spotter,'' in \emph{Asian Conference on Machine
  Learning}, V.~N. Balasubramanian and I.~W. Tsang, Eds., vol. 157, 2021, pp.
  379--389.

\bibitem{realdata}
J.~Baek, Y.~Matsui, and K.~Aizawa, ``What if we only use real datasets for
  scene text recognition? toward scene text recognition with fewer labels,'' in
  \emph{IEEE Conf. Comput. Vis. Pattern Recog.}, 2021, pp. 3113--3122.

\bibitem{randaug}
E.~D. Cubuk, B.~Zoph, J.~Shlens, and Q.~V. Le, ``Randaugment: Practical
  automated data augmentation with a reduced search space,'' in \emph{{CVPR}
  Workshops}, 2020, pp. 3008--3017.

\bibitem{Adadelta}
M.~D. Zeiler, ``{ADADELTA:} an adaptive learning rate method,'' \emph{CoRR},
  vol. abs/1212.5701, 2012.

\bibitem{cosinlr}
I.~Loshchilov and F.~Hutter, ``{SGDR:} stochastic gradient descent with warm
  restarts,'' in \emph{Int. Conf. Learn. Represent.}, 2017.

\bibitem{erasing}
Z.~Zhong, L.~Zheng, G.~Kang, S.~Li, and Y.~Yang, ``Random erasing data
  augmentation,'' in \emph{AAAI}, 2020, pp. 13\,001--13\,008.

\bibitem{DINO}
M.~Caron, H.~Touvron, I.~Misra, H.~J{\'{e}}gou, J.~Mairal, P.~Bojanowski, and
  A.~Joulin, ``Emerging properties in self-supervised vision transformers,'' in
  \emph{Int. Conf. Comput. Vis.}, 2021, pp. 9630--9640.

\bibitem{DINOv2}
M.~Oquab, T.~Darcet, T.~Moutakanni, H.~Vo, M.~Szafraniec, V.~Khalidov,
  P.~Fernandez, D.~Haziza, F.~Massa, A.~El{-}Nouby, M.~Assran, N.~Ballas,
  W.~Galuba, R.~Howes, P.~Huang, S.~Li, I.~Misra, M.~G. Rabbat, V.~Sharma,
  G.~Synnaeve, H.~Xu, H.~J{\'{e}}gou, J.~Mairal, P.~Labatut, A.~Joulin, and
  P.~Bojanowski, ``Dinov2: Learning robust visual features without
  supervision,'' \emph{CoRR}, vol. abs/2304.07193, 2023.

\bibitem{mae}
K.~He, X.~Chen, S.~Xie, Y.~Li, P.~Doll{\'{a}}r, and R.~B. Girshick, ``Masked
  autoencoders are scalable vision learners,'' in \emph{IEEE Conf. Comput. Vis.
  Pattern Recog.}, 2022, pp. 15\,979--15\,988.

\bibitem{BLIP}
J.~Li, D.~Li, C.~Xiong, and S.~C.~H. Hoi, ``{BLIP:} bootstrapping
  language-image pre-training for unified vision-language understanding and
  generation,'' in \emph{Int. Conf. Mach. Learn.}, vol. 162, 2022, pp.
  12\,888--12\,900.

\bibitem{ESIR}
F.~Zhan and S.~Lu, ``{ESIR:} end-to-end scene text recognition via iterative
  image rectification,'' in \emph{CVPR}, 2019, pp. 2059--2068.

\bibitem{SEED}
Z.~Qiao, Y.~Zhou, D.~Yang, Y.~Zhou, and W.~Wang, ``{SEED:} semantics enhanced
  encoder-decoder framework for scene text recognition,'' in \emph{IEEE Conf.
  Comput. Vis. Pattern Recog.}, 2020, pp. 13\,525--13\,534.

\bibitem{RobustScanner}
X.~Yue, Z.~Kuang, C.~Lin, H.~Sun, and W.~Zhang, ``Robustscanner: Dynamically
  enhancing positional clues for robust text recognition,'' in \emph{Eur. Conf.
  Comput. Vis.}, vol. 12364, 2020, pp. 135--151.

\bibitem{SATRN}
J.~Lee, S.~Park, J.~Baek, S.~J. Oh, S.~Kim, and H.~Lee, ``On recognizing texts
  of arbitrary shapes with 2d self-attention,'' in \emph{CVPR Workshops}, 2020,
  pp. 2326--2335.

\bibitem{ABInetv2}
S.~Fang, Z.~Mao, H.~Xie, Y.~Wang, C.~Yan, and Y.~Zhang, ``Abinet++: Autonomous,
  bidirectional and iterative language modeling for scene text spotting,''
  \emph{IEEE Trans. Pattern Anal. Mach. Intell.}, vol.~45, no.~6, pp.
  7123--7141, 2023.

\bibitem{TextAdaIN}
O.~Nuriel, S.~Fogel, and R.~Litman, ``Textadain: Paying attention to shortcut
  learning in text recognizers,'' in \emph{Eur. Conf. Comput. Vis.}, vol.
  13688, 2022, pp. 427--445.

\bibitem{yuille2006vision}
A.~Yuille and D.~Kersten, ``Vision as bayesian inference: analysis by
  synthesis?'' \emph{Trends in cognitive sciences}, vol.~10, no.~7, pp.
  301--308, 2006.

\bibitem{bever2010analysis}
T.~G. Bever and D.~Poeppel, ``Analysis by synthesis: a (re-)emerging program of
  research for language and vision,'' \emph{Biolinguistics}, vol.~4, no. 2-3,
  pp. 174--200, 2010.

\end{thebibliography}
