
% Journals

% First the Full Name is given, then the abbreviation used in the AMS Math
% Reviews, with an indication if it could not be found there.
% Note the 2nd overwrites the 1st, so swap them if you want the full name.

 %{AMS}
 @String{AMSTrans = "American Mathematical Society Translations" }
 @String{AMSTrans = "Amer. Math. Soc. Transl." }
 @String{BullAMS = "Bulletin of the American Mathematical Society" }
 @String{BullAMS = "Bull. Amer. Math. Soc." }
 @String{ProcAMS = "Proceedings of the American Mathematical Society" }
 @String{ProcAMS = "Proc. Amer. Math. Soc." }
 @String{TransAMS = "Transactions of the American Mathematical Society" }
 @String{TransAMS = "Trans. Amer. Math. Soc." }

 %ACM
 @String{CACM = "Communications of the {ACM}" }
 @String{CACM = "Commun. {ACM}" }
 @String{CompServ = "Comput. Surveys" }
 @String{JACM = "J. ACM" }
 @String{ACMMathSoft = "{ACM} Transactions on Mathematical Software" }
 @String{ACMMathSoft = "{ACM} Trans. Math. Software" }
 @String{SIGNUM = "{ACM} {SIGNUM} Newsletter" }
 @String{SIGNUM = "{ACM} {SIGNUM} Newslett." }

 @String{AmerSocio = "American Journal of Sociology" }
 @String{AmerStatAssoc = "Journal of the American Statistical Association" }
 @String{AmerStatAssoc = "J. Amer. Statist. Assoc." }
 @String{ApplMathComp = "Applied Mathematics and Computation" }
 @String{ApplMathComp = "Appl. Math. Comput." }
 @String{AmerMathMonthly = "American Mathematical Monthly" }
 @String{AmerMathMonthly = "Amer. Math. Monthly" }
 @String{BIT = "{BIT}" }
 @String{BritStatPsych = "British Journal of Mathematical and Statistical
          Psychology" }
 @String{BritStatPsych = "Brit. J. Math. Statist. Psych." }
 @String{CanMathBull = "Canadian Mathematical Bulletin" }
 @String{CanMathBull = "Canad. Math. Bull." }
 @String{CompApplMath = "Journal of Computational and Applied Mathematics" }
 @String{CompApplMath = "J. Comput. Appl. Math." }
 @String{CompPhys = "Journal of Computational Physics" }
 @String{CompPhys = "J. Comput. Phys." }
 @String{CompStruct = "Computers and Structures" }
 @String{CompStruct = "Comput. \& Structures" }
 @String{CompJour = "The Computer Journal" }
 @String{CompJour = "Comput. J." }
 @String{CompSysSci = "Journal of Computer and System Sciences" }
 @String{CompSysSci = "J. Comput. System Sci." }
 @String{Computing = "Computing" }
 @String{ContempMath = "Contemporary Mathematics" }
 @String{ContempMath = "Contemp. Math." }
 @String{Crelle = "Crelle's Journal" }
 @String{GiornaleMath = "Giornale di Mathematiche" }
 @String{GiornaleMath = "Giorn. Mat." } % didn't find in AMS MR., ibid.

 %IEEE
 @String{Computer = "{IEEE} Computer" }
 @String{IEEETransComp = "{IEEE} Transactions on Computers" }
 @String{IEEETransComp = "{IEEE} Trans. Comput." }
 @String{IEEETransAC = "{IEEE} Transactions on Automatic Control" }
 @String{IEEETransAC = "{IEEE} Trans. Automat. Control" }
 @String{IEEESpec = "{IEEE} Spectrum" } % didn't find in AMS MR
 @String{ProcIEEE = "Proceedings of the {IEEE}" }
 @String{ProcIEEE = "Proc. {IEEE}" } % didn't find in AMS MR
 @String{IEEETransAeroElec = "{IEEE} Transactions on Aerospace and Electronic
     Systems" }
 @String{IEEETransAeroElec = "{IEEE} Trans. Aerospace Electron. Systems" }

 @String{IMANumerAna = "{IMA} Journal of Numerical Analysis" }
 @String{IMANumerAna = "{IMA} J. Numer. Anal." }
 @String{InfProcLet = "Information Processing Letters" }
 @String{InfProcLet = "Inform. Process. Lett." }
 @String{InstMathApp = "Journal of the Institute of Mathematics and
     its Applications" }
 @String{InstMathApp = "J. Inst. Math. Appl." }
 @String{IntControl = "International Journal of Control" }
 @String{IntControl = "Internat. J. Control" }
 @String{IntNumerEng = "International Journal for Numerical Methods in
     Engineering" }
 @String{IntNumerEng = "Internat. J. Numer. Methods Engrg." }
 @String{IntSuper = "International Journal of Supercomputing Applications" }
 @String{IntSuper = "Internat. J. Supercomputing Applic." } % didn't find
%% in AMS MR
 @String{Kibernetika = "Kibernetika" }
 @String{JResNatBurStand = "Journal of Research of the National Bureau
     of Standards" }
 @String{JResNatBurStand = "J. Res. Nat. Bur. Standards" }
 @String{LinAlgApp = "Linear Algebra and its Applications" }
 @String{LinAlgApp = "Linear Algebra Appl." }
 @String{MathAnaAppl = "Journal of Mathematical Analysis and Applications" }
 @String{MathAnaAppl = "J. Math. Anal. Appl." }
 @String{MathAnnalen = "Mathematische Annalen" }
 @String{MathAnnalen = "Math. Ann." }
 @String{MathPhys = "Journal of Mathematical Physics" }
 @String{MathPhys = "J. Math. Phys." }
 @String{MathComp = "Mathematics of Computation" }
 @String{MathComp = "Math. Comp." }
 @String{MathScand = "Mathematica Scandinavica" }
 @String{MathScand = "Math. Scand." }
 @String{TablesAidsComp = "Mathematical Tables and Other Aids to Computation" }
 @String{TablesAidsComp = "Math. Tables Aids Comput." }
 @String{NumerMath = "Numerische Mathematik" }
 @String{NumerMath = "Numer. Math." }
 @String{PacificMath = "Pacific Journal of Mathematics" }
 @String{PacificMath = "Pacific J. Math." }
 @String{ParDistComp = "Journal of Parallel and Distributed Computing" }
 @String{ParDistComp = "J. Parallel and Distrib. Comput." } % didn't find
%% in AMS MR
 @String{ParComputing = "Parallel Computing" }
 @String{ParComputing = "Parallel Comput." }
 @String{PhilMag = "Philosophical Magazine" }
 @String{PhilMag = "Philos. Mag." }
 @String{ProcNAS = "Proceedings of the National Academy of Sciences
                    of the USA" }
 @String{ProcNAS = "Proc. Nat. Acad. Sci. U. S. A." }
 @String{Psychometrika = "Psychometrika" }
 @String{QuartMath = "Quarterly Journal of Mathematics, Oxford, Series (2)" }
 @String{QuartMath = "Quart. J. Math. Oxford Ser. (2)" }
 @String{QuartApplMath = "Quarterly of Applied Mathematics" }
 @String{QuartApplMath = "Quart. Appl. Math." }
 @String{RevueInstStat = "Review of the International Statisical Institute" }
 @String{RevueInstStat = "Rev. Inst. Internat. Statist." }

 %SIAM
 @String{JSIAM = "Journal of the Society for Industrial and Applied
     Mathematics" }
 @String{JSIAM = "J. Soc. Indust. Appl. Math." }
 @String{JSIAMB = "Journal of the Society for Industrial and Applied
     Mathematics, Series B, Numerical Analysis" }
 @String{JSIAMB = "J. Soc. Indust. Appl. Math. Ser. B Numer. Anal." }
 @String{SIAMAlgMeth = "{SIAM} Journal on Algebraic and Discrete Methods" }
 @String{SIAMAlgMeth = "{SIAM} J. Algebraic Discrete Methods" }
 @String{SIAMAppMath = "{SIAM} Journal on Applied Mathematics" }
 @String{SIAMAppMath = "{SIAM} J. Appl. Math." }
 @String{SIAMComp = "{SIAM} Journal on Computing" }
 @String{SIAMComp = "{SIAM} J. Comput." }
 @String{SIAMMatrix = "{SIAM} Journal on Matrix Analysis and Applications" }
 @String{SIAMMatrix = "{SIAM} J. Matrix Anal. Appl." }
 @String{SIAMNumAnal = "{SIAM} Journal on Numerical Analysis" }
 @String{SIAMNumAnal = "{SIAM} J. Numer. Anal." }
 @String{SIAMReview = "{SIAM} Review" }
 @String{SIAMReview = "{SIAM} Rev." }
 @String{SIAMSciStat = "{SIAM} Journal on Scientific and Statistical
     Computing" }
 @String{SIAMSciStat = "{SIAM} J. Sci. Statist. Comput." }

 @String{SoftPracExp = "Software Practice and Experience" }
 @String{SoftPracExp = "Software Prac. Experience" } % didn't find in AMS MR
 @String{StatScience = "Statistical Science" }
 @String{StatScience = "Statist. Sci." }
 @String{Techno = "Technometrics" }
 @String{USSRCompMathPhys = "{USSR} Computational Mathematics and Mathematical
     Physics" }
 @String{USSRCompMathPhys = "{U. S. S. R.} Comput. Math. and Math. Phys." }
 @String{VLSICompSys = "Journal of {VLSI} and Computer Systems" }
 @String{VLSICompSys = "J. {VLSI} Comput. Syst." }
 @String{ZAngewMathMech = "Zeitschrift fur Angewandte Mathematik und
     Mechanik" }
 @String{ZAngewMathMech = "Z. Angew. Math. Mech." }
 @String{ZAngewMathPhys = "Zeitschrift fur Angewandte Mathematik und Physik" }
 @String{ZAngewMathPhys = "Z. Angew. Math. Phys." }

% Publishers % ================================================= |

 @String{Academic = "Academic Press" }
 @String{ACMPress = "{ACM} Press" }
 @String{AdamHilger = "Adam Hilger" }
 @String{AddisonWesley = "Addison-Wesley" }
 @String{AllynBacon = "Allyn and Bacon" }
 @String{AMS = "American Mathematical Society" }
 @String{Birkhauser = "Birkha{\"u}ser" }
 @String{CambridgePress = "Cambridge University Press" }
 @String{Chelsea = "Chelsea" }
 @String{ClaredonPress = "Claredon Press" }
 @String{DoverPub = "Dover Publications" }
 @String{Eyolles = "Eyolles" }
 @String{HoltRinehartWinston = "Holt, Rinehart and Winston" }
 @String{Interscience = "Interscience" }
 @String{JohnsHopkinsPress = "The Johns Hopkins University Press" }
 @String{JohnWileySons = "John Wiley and Sons" }
 @String{Macmillan = "Macmillan" }
 @String{MathWorks = "The Math Works Inc." }
 @String{McGrawHill = "McGraw-Hill" }
 @String{NatBurStd = "National Bureau of Standards" }
 @String{NorthHolland = "North-Holland" }
 @String{OxfordPress = "Oxford University Press" }  %address Oxford or London?
 @String{PergamonPress = "Pergamon Press" }
 @String{PlenumPress = "Plenum Press" }
 @String{PrenticeHall = "Prentice-Hall" }
 @String{SIAMPub = "{SIAM} Publications" }
 @String{Springer = "Springer-Verlag" }
 @String{TexasPress = "University of Texas Press" }
 @String{VanNostrand = "Van Nostrand" }
 @String{WHFreeman = "W. H. Freeman and Co." }

%Entries
@inproceedings{GAN,
  author       = {Ian J. Goodfellow and
                  Jean Pouget{-}Abadie and
                  Mehdi Mirza and
                  Bing Xu and
                  David Warde{-}Farley and
                  Sherjil Ozair and
                  Aaron C. Courville and
                  Yoshua Bengio},
  title        = {Generative Adversarial Nets},
  booktitle    = {NeurIPS},
  year         = {2014},
}

@inproceedings{VAE,
  author       = {Diederik P. Kingma and
                  Max Welling},
  title        = {Auto-Encoding Variational Bayes},
  booktitle    = {ICLR},
  year         = {2014},
}

@inproceedings{DDPM,
  title={Denoising Diffusion Probabilistic Models},
  author={Ho, Jonathan and Jain, Ajay and Abbeel, Pieter},
  journal={NeurIPS},
  year={2020}
}

@article{lab2pix,
  author       = {Junchen Zhu and
                  Lianli Gao and
                  Jingkuan Song and
                  Yuan{-}Fang Li and
                  Feng Zheng and
                  Xuelong Li and
                  Heng Tao Shen},
  title        = {Label-Guided Generative Adversarial Network for Realistic Image Synthesis},
  journal      = {{IEEE} TPAMI},
  volume       = {45},
  number       = {3},
  pages        = {3311--3328},
  year         = {2023},
}

@inproceedings{stylegan,
  author       = {Tero Karras and
                  Samuli Laine and
                  Timo Aila},
  title        = {A Style-Based Generator Architecture for Generative Adversarial Networks},
  booktitle    = {CVPR},
  year         = {2019},
}

@inproceedings{StackGAN,
  author       = {Han Zhang and
                  Tao Xu and
                  Hongsheng Li},
  title        = {{StackGAN}: Text to Photo-Realistic Image Synthesis with Stacked Generative
                  Adversarial Networks},
  booktitle    = {ICCV},
  year         = {2017},
}

@inproceedings{beatgan,
  author       = {Prafulla Dhariwal and
                  Alexander Quinn Nichol},
  editor       = {Marc'Aurelio Ranzato and
                  Alina Beygelzimer and
                  Yann N. Dauphin and
                  Percy Liang and
                  Jennifer Wortman Vaughan},
  title        = {Diffusion Models Beat GANs on Image Synthesis},
  booktitle    = {NeurIPS},
  year         = {2021},
}

@inproceedings{vqgan,
  author       = {Patrick Esser and
                  Robin Rombach and
                  Bj{\"{o}}rn Ommer},
  title        = {Taming Transformers for High-Resolution Image Synthesis},
  booktitle    = {CVPR},
  year         = {2021},
}

@inproceedings{VideoLDM,
  author       = {Andreas Blattmann and
                  Robin Rombach and
                  Huan Ling and
                  Tim Dockhorn and
                  Seung Wook Kim and
                  Sanja Fidler and
                  Karsten Kreis},
  title        = {Align your Latents: High-Resolution Video Synthesis with Latent Diffusion
                  Models},
  booktitle    = {CVPR},
  year         = {2023},
}

@inproceedings{VideoFusion,
  author       = {Zhengxiong Luo and
                  Dayou Chen and
                  Yingya Zhang and
                  Yan Huang and
                  Liang Wang and
                  Yujun Shen and
                  Deli Zhao and
                  Jingren Zhou and
                  Tieniu Tan},
  title        = {{VideoFusion}: Decomposed Diffusion Models for High-Quality Video Generation},
  booktitle    = {CVPR},
  year         = {2023},
}

@inproceedings{PVDM,
  author       = {Sihyun Yu and
                  Kihyuk Sohn and
                  Subin Kim and
                  Jinwoo Shin},
  title        = {Video Probabilistic Diffusion Models in Projected Latent Space},
  booktitle    = {CVPR},
  year         = {2023},
}

@article{MMDiffusion,
  author       = {Ludan Ruan and
                  Yiyang Ma and
                  Huan Yang and
                  Huiguo He and
                  Bei Liu and
                  Jianlong Fu and
                  Nicholas Jing Yuan and
                  Qin Jin and
                  Baining Guo},
  title        = {{MM-Diffusion}: Learning Multi-Modal Diffusion Models for Joint Audio
                  and Video Generation},
  booktitle    = {CVPR},
  year         = {2023},
}

@article{MakeAVideo,
  title={{Make-A-Video}: Text-to-video generation without text-video data},
  author={Singer, Uriel and Polyak, Adam and Hayes, Thomas and Yin, Xi and An, Jie and Zhang, Songyang and Hu, Qiyuan and Yang, Harry and Ashual, Oron and Gafni, Oran and others},
  journal={arXiv},
  year={2022}
}

@article{videogpt,
      title={VideoGPT: Video Generation using VQ-VAE and Transformers}, 
      author={Wilson Yan and Yunzhi Zhang and Pieter Abbeel and Aravind Srinivas},
      year={2021},
      journal={arXiv},
}

@inproceedings{dalle,
  author       = {Aditya Ramesh and
                  Mikhail Pavlov and
                  Gabriel Goh and
                  Scott Gray and
                  Chelsea Voss and
                  Alec Radford and
                  Mark Chen and
                  Ilya Sutskever},
  title        = {Zero-Shot Text-to-Image Generation},
  booktitle    = {ICML},
  year         = {2021},
}


@inproceedings{cogview,
  author       = {Ming Ding and
                  Zhuoyi Yang and
                  Wenyi Hong and
                  Wendi Zheng and
                  Chang Zhou and
                  Da Yin and
                  Junyang Lin and
                  Xu Zou and
                  Zhou Shao and
                  Hongxia Yang and
                  Jie Tang},
  title        = {{CogView}: Mastering Text-to-Image Generation via Transformers},
  booktitle    = {NeurIPS},
  year         = {2021},
}

@inproceedings{cogview2,
  author       = {Ming Ding and
                  Wendi Zheng and
                  Wenyi Hong and
                  Jie Tang},
  title        = {{CogView2}: Faster and Better Text-to-Image Generation via Hierarchical
                  Transformers},
  booktitle    = NeurIPS,
  year         = {2022},
}

@article{controlnet,
  author       = {Lvmin Zhang and
                  Maneesh Agrawala},
  title        = {Adding Conditional Control to Text-to-Image Diffusion Models},
  journal      = {arXiv},
  year         = {2023},
}

@article{2022DALLE2,
  author       = {Aditya Ramesh and
                  Prafulla Dhariwal and
                  Alex Nichol and
                  Casey Chu and
                  Mark Chen},
  title        = {Hierarchical Text-Conditional Image Generation with {CLIP} Latents},
  journal      = {arXiv},
  year         = {2022},
}

@inproceedings{imagen,
  author       = {Chitwan Saharia and
                  William Chan and
                  Saurabh Saxena and
                  Lala Li and
                  Jay Whang and
                  Emily L. Denton and
                  Seyed Kamyar Seyed Ghasemipour and
                  Raphael Gontijo Lopes and
                  Burcu Karagol Ayan and
                  Tim Salimans and
                  Jonathan Ho and
                  David J. Fleet and
                  Mohammad Norouzi},
  title        = {Photorealistic Text-to-Image Diffusion Models with Deep Language Understanding},
  booktitle    = {NeurIPS},
  year         = {2022},
}

@inproceedings{latentdiffusion,
  author       = {Robin Rombach and
                  Andreas Blattmann and
                  Dominik Lorenz and
                  Patrick Esser and
                  Bj{\"{o}}rn Ommer},
  title        = {High-Resolution Image Synthesis with Latent Diffusion Models},
  booktitle    = {CVPR},
  year         = {2022},
}

@misc{stablediffusion,
    author= {Stability-AI},
    year  = {2022},
    title = {Stable Diffusion},
    note  = {\url{https://github.com/Stability-AI/StableDiffusion}},
}

@InProceedings{2022LDM,
    author    = {Rombach, Robin and Blattmann, Andreas and Lorenz, Dominik and Esser, Patrick and Ommer, Bj\"orn},
    title     = {High-Resolution Image Synthesis With Latent Diffusion Models},
    booktitle = {CVPR},
    year      = {2022},
}

@inproceedings{Create_What_You_Tell,
  author       = {Yingwei Pan and
                  Zhaofan Qiu and
                  Ting Yao and
                  Houqiang Li and
                  Tao Mei},
  title        = {To Create What You Tell: Generating Videos from Captions},
  booktitle    = {ACM MM},
  year         = {2017},
}

@article{CogVideo,
  author       = {Wenyi Hong and
                  Ming Ding and
                  Wendi Zheng and
                  Xinghan Liu and
                  Jie Tang},
  title        = {{CogVideo}: Large-scale Pretraining for Text-to-Video Generation via
                  Transformers},
  journal      = {arXiv},
  year         = {2022},
}

@article{ImagenVideo,
  author       = {Jonathan Ho and
                  William Chan and
                  Chitwan Saharia and
                  Jay Whang and
                  Ruiqi Gao and
                  Alexey A. Gritsenko and
                  Diederik P. Kingma and
                  Ben Poole and
                  Mohammad Norouzi and
                  David J. Fleet and
                  Tim Salimans},
  title        = {{Imagen Video}: High Definition Video Generation with Diffusion Models},
  journal      = {arXiv},
  year         = {2022},
}

@article{Phenaki,
  author       = {Ruben Villegas and
                  Mohammad Babaeizadeh and
                  Pieter{-}Jan Kindermans and
                  Hernan Moraldo and
                  Han Zhang and
                  Mohammad Taghi Saffar and
                  Santiago Castro and
                  Julius Kunze and
                  Dumitru Erhan},
  title        = {Phenaki: Variable Length Video Generation From Open Domain Textual
                  Description},
  journal      = {arXiv},
  year         = {2022},
}

@inproceedings{nuwa,
 author = {Wu, Chenfei and Liang, Jian and Ji, Lei and Yang, Fan and Fang, Yuejian and Jiang, Daxin and Duan, Nan},
 booktitle = {ECCV},
 title = {N{\"u}WA: Visual synthesis pre-training for neural visual world creation},
 year = {2022}
}

@article{tuneavideo,
    title={Tune-A-Video: One-Shot Tuning of Image Diffusion Models for Text-to-Video Generation},
    author={Wu, Jay Zhangjie and Ge, Yixiao and Wang, Xintao and Lei, Stan Weixian and Gu, Yuchao and Hsu, Wynne and Shan, Ying and Qie, Xiaohu and Shou, Mike Zheng},
    journal={arXiv},
    year={2022}
}

@article{magicvideo,
  title={{MagicVideo}: Efficient video generation with latent diffusion models},
  author={Zhou, Daquan and Wang, Weimin and Yan, Hanshu and Lv, Weiwei and Zhu, Yizhe and Feng, Jiashi},
  journal={arXiv},
  year={2022}
}

@article{lvdm,
      title={Latent Video Diffusion Models for High-Fidelity Long Video Generation}, 
      author={Yingqing He and Tianyu Yang and Yong Zhang and Ying Shan and Qifeng Chen},
      year={2022},
      journal={arXiv},
}

@article{unidiffuser,
  author       = {Fan Bao and
                  Shen Nie and
                  Kaiwen Xue and
                  Chongxuan Li and
                  Shi Pu and
                  Yaole Wang and
                  Gang Yue and
                  Yue Cao and
                  Hang Su and
                  Jun Zhu},
  title        = {One Transformer Fits All Distributions in Multi-Modal Diffusion at
                  Scale},
  journal      = {arXiv},
  year         = {2023},
}

@article{magvit,
  author       = {Lijun Yu and
                  Yong Cheng and
                  Kihyuk Sohn and
                  Jos{\'{e}} Lezama and
                  Han Zhang and
                  Huiwen Chang and
                  Alexander G. Hauptmann and
                  Ming{-}Hsuan Yang and
                  Yuan Hao and
                  Irfan Essa and
                  Lu Jiang},
  title        = {{MAGVIT:} Masked Generative Video Transformer},
  journal      = {arXiv},
  year         = {2022},
}

@article{Text2VideoZero,
  author       = {Levon Khachatryan and
                  Andranik Movsisyan and
                  Vahram Tadevosyan and
                  Roberto Henschel and
                  Zhangyang Wang and
                  Shant Navasardyan and
                  Humphrey Shi},
  title        = {{Text2Video-Zero}: Text-to-Image Diffusion Models are Zero-Shot Video
                  Generators},
  journal      = {arXiv},
  year         = {2023},
}

@article{FollowYourPose,
  author       = {Yue Ma and
                  Yingqing He and
                  Xiaodong Cun and
                  Xintao Wang and
                  Ying Shan and
                  Xiu Li and
                  Qifeng Chen},
  title        = {Follow Your Pose: Pose-Guided Text-to-Video Generation using Pose-Free
                  Videos},
  journal      = {arXiv},
  year         = {2023},
}

@article{LatentShift,
  author       = {Jie An and
                  Songyang Zhang and
                  Harry Yang and
                  Sonal Gupta and
                  Jia{-}Bin Huang and
                  Jiebo Luo and
                  Xi Yin},
  title        = {{Latent-Shift}: Latent Diffusion with Temporal Shift for Efficient Text-to-Video
                  Generation},
  journal      = {arXiv},
  year         = {2023},
}

@article{eDiff-I,
  author       = {Yogesh Balaji and
                  Seungjun Nah and
                  Xun Huang and
                  Arash Vahdat and
                  Jiaming Song and
                  Karsten Kreis and
                  Miika Aittala and
                  Timo Aila and
                  Samuli Laine and
                  Bryan Catanzaro and
                  Tero Karras and
                  Ming{-}Yu Liu},
  title        = {{eDiff-I}: Text-to-Image Diffusion Models with an Ensemble of Expert
                  Denoisers},
  journal      = {arXiv},
  year         = {2022},
}

@inproceedings{DreamBooth,
  title={{DreamBooth}: Fine Tuning Text-to-Image Diffusion Models for Subject-Driven Generation},
  author={Ruiz, Nataniel and Li, Yuanzhen and Jampani, Varun and Pritch, Yael and Rubinstein, Michael and Aberman, Kfir},
  booktitle    = {CVPR},
  year         = {2023},
}

@article{svgvqgan,
  author       = {Jiawei Liu and
                  Weining Wang and
                  Sihan Chen and
                  Xinxin Zhu and
                  Jing Liu},
  title        = {Sounding Video Generator: {A} Unified Framework for Text-guided Sounding
                  Video Generation},
  journal      = {arXiv},
  year         = {2023},
}

@article{makeanaudio,
  author       = {Rongjie Huang and
                  Jiawei Huang and
                  Dongchao Yang and
                  Yi Ren and
                  Luping Liu and
                  Mingze Li and
                  Zhenhui Ye and
                  Jinglin Liu and
                  Xiang Yin and
                  Zhou Zhao},
  title        = {Make-An-Audio: Text-To-Audio Generation with Prompt-Enhanced Diffusion
                  Models},
  journal      = {arxiv},
  year         = {2023},
}

@inproceedings{transformer,
  author       = {Ashish Vaswani and
                  Noam Shazeer and
                  Niki Parmar and
                  Jakob Uszkoreit and
                  Llion Jones and
                  Aidan N. Gomez and
                  Lukasz Kaiser and
                  Illia Polosukhin},
  title        = {Attention is All you Need},
  booktitle    = {NeurIPS},
  year         = {2017},
}

@inproceedings{unet,
  author       = {Olaf Ronneberger and
                  Philipp Fischer and
                  Thomas Brox},
  title        = {U-Net: Convolutional Networks for Biomedical Image Segmentation},
  booktitle    = {MICCAI},
  year         = {2015},
}

@inproceedings{clip,
  author       = {Alec Radford and
                  Jong Wook Kim and
                  Chris Hallacy and
                  Aditya Ramesh and
                  Gabriel Goh and
                  Sandhini Agarwal and
                  Girish Sastry and
                  Amanda Askell and
                  Pamela Mishkin and
                  Jack Clark and
                  Gretchen Krueger and
                  Ilya Sutskever},
  title        = {Learning Transferable Visual Models From Natural Language Supervision},
  booktitle    = {ICML},
  year         = {2021},
}

@inproceedings{realbasicvsr,
  author       = {Chan, Kelvin C.K. and Zhou, Shangchen and Xu, Xiangyu and Loy, Chen Change},
  title        = {Investigating Tradeoffs in Real-World Video Super-Resolution},
  booktitle    = {CVPR},
  year         = {2022}
}

@inproceedings{webvid,
  author       = {Max Bain and
                  Arsha Nagrani and
                  G{\"{u}}l Varol and
                  Andrew Zisserman},
  title        = {Frozen in Time: {A} Joint Video and Image Encoder for End-to-End Retrieval},
  booktitle    = {ICCV},
  year         = {2021},
}

@inproceedings{laion5b,
  author       = {Christoph Schuhmann and
                  Romain Beaumont and
                  Richard Vencu and
                  Cade Gordon and
                  Ross Wightman and
                  Mehdi Cherti and
                  Theo Coombes and
                  Aarush Katta and
                  Clayton Mullis and
                  Mitchell Wortsman and
                  Patrick Schramowski and
                  Srivatsa Kundurthy and
                  Katherine Crowson and
                  Ludwig Schmidt and
                  Robert Kaczmarczyk and
                  Jenia Jitsev},
  title        = {{LAION-5B:} An open large-scale dataset for training next generation
                  image-text models},
  booktitle    = {NeurIPS},
  year         = {2022},
}

@inproceedings{hdvila,
  author       = {Hongwei Xue and
                  Tiankai Hang and
                  Yanhong Zeng and
                  Yuchong Sun and
                  Bei Liu and
                  Huan Yang and
                  Jianlong Fu and
                  Baining Guo},
  title        = {Advancing High-Resolution Video-Language Representation with Large-Scale
                  Video Transcriptions},
  booktitle    = {CVPR},
  year         = {2022},
}

@inproceedings{audioset,
  author       = {Jort F. Gemmeke and
                  Daniel P. W. Ellis and
                  Dylan Freedman and
                  Aren Jansen and
                  Wade Lawrence and
                  R. Channing Moore and
                  Manoj Plakal and
                  Marvin Ritter},
  title        = {Audio Set: An ontology and human-labeled dataset for audio events},
  booktitle    = {ICASSP},
  year         = {2017},
}

@article{chatgpt,
  author       = {OpenAI},
  title        = {ChatGPT},
  year         = {2022},
  url          = {https://chat.openai.com/chat},
}



@article{filmmaker2002,
  title={The Framework of an Automatic Digital Movie Producer},
  author={Shen, Jinhong and Miyazaki, Seiya and AOKI, Teruamsa and Yasuda, Hiroshi},
  booktitle={ITE Technical Report},
  pages={15--18},
  year={2002},
}

@inproceedings{Bootlegger2015,
    author = {Schofield, Guy and Bartindale, Tom and Wright, Peter},
    title = {Bootlegger: Turning Fans into Film Crew},
    year = {2015},
    booktitle = {CHI},
}
% pages = {767–776},


@book{reich2017exploring,
  title={Exploring Movie Construction \& Production: What’s So Exciting about Movies?},
  author={Reich, John},
  year={2017},
  publisher={Open SUNY Textbooks}
}


@inproceedings{suris2018cross,
  title={Cross-modal embeddings for video and audio retrieval},
  author={Sur{\'\i}s, Didac and Duarte, Amanda and Salvador, Amaia and Torres, Jordi and Gir{\'o}-i-Nieto, Xavier},
  booktitle={ECCV Workshops},
  year={2018}
}


@ARTICLE{oncescu2021audio,
  author={Koepke, A. Sophia and Oncescu, Andreea-Maria and Henriques, Joao and Akata, Zeynep and Albanie, Samuel},
  journal={IEEE TMM}, 
  title={Audio Retrieval with Natural Language Queries: A Benchmark Study}, 
  year={2022},
  volume={},
  number={},
  pages={1-1},
}


@article{FVD,
  author       = {Thomas Unterthiner and
                  Sjoerd van Steenkiste and
                  Karol Kurach and
                  Rapha{\"{e}}l Marinier and
                  Marcin Michalski and
                  Sylvain Gelly},
  title        = {Towards Accurate Generative Models of Video: {A} New Metric {\&}
                  Challenges},
  journal      = {arXiv},
  year         = {2018},
}

@inproceedings{NasrullahZ19,
  author       = {Zain Nasrullah and
                  Yue Zhao},
  title        = {Music Artist Classification with Convolutional Recurrent Neural Networks},
  booktitle    = {IEEE IJCNN},
  year         = {2019},
}


@article{VideoFactory,
  author       = {Wenjing Wang and
                  Huan Yang and
                  Zixi Tuo and
                  Huiguo He and
                  Junchen Zhu and
                  Jianlong Fu and
                  Jiaying Liu},
  title        = {VideoFactory: Swap Attention in Spatiotemporal Diffusions for Text-to-Video
                  Generation},
  journal      = {arXiv},
  year         = {2023},
}

@article{unifiedMM,
  author       = {Yiyang Ma and
                  Huan Yang and
                  Wenjing Wang and
                  Jianlong Fu and
                  Jiaying Liu},
  title        = {Unified Multi-Modal Latent Diffusion for Joint Subject and Text Conditional
                  Image Generation},
  journal      = {arXiV},
  year         = {2023},
}

@inproceedings{Illustrator,
  author       = {Yiyang Ma and
                  Huan Yang and
                  Bei Liu and
                  Jianlong Fu and
                  Jiaying Liu},
  title        = {{AI} Illustrator: Translating Raw Descriptions into Images by Prompt-based
                  Cross-Modal Generation},
  booktitle    = {ACM MM},
}

@inproceedings{trajectory_aware,
  author       = {Chengxu Liu and
                  Huan Yang and
                  Jianlong Fu and
                  Xueming Qian},
  title        = {Learning Trajectory-Aware Transformer for Video Super-Resolution},
  booktitle    = {CVPR},
}

@inproceedings{spatiotemporal_frequency,
  author       = {Zhongwei Qiu and
                  Huan Yang and
                  Jianlong Fu and
                  Dongmei Fu},
  title        = {Learning Spatiotemporal Frequency-Transformer for Compressed Video
                  Super-Resolution},
  booktitle    = {ECCV},
}

@inproceedings{texture_transformer,
  author       = {Fuzhi Yang and
                  Huan Yang and
                  Jianlong Fu and
                  Hongtao Lu and
                  Baining Guo},
  title        = {Learning Texture Transformer Network for Image Super-Resolution},
  booktitle    = {CVPR},
  year         = {2020},
}

@inproceedings{deformable,
  author       = {Sitong Su and
                  Jingkuan Song and
                  Lianli Gao and
                  Junchen Zhu},
  editor       = {Zhi{-}Hua Zhou},
  title        = {Towards Unsupervised Deformable-Instances Image-to-Image Translation},
  booktitle    = {IJCAI},
  year         = {2021},
}

@inproceedings{OncescuKHAA21,
  author       = {Andreea{-}Maria Oncescu and
                  A. Sophia Koepke and
                  Jo{\~{a}}o F. Henriques and
                  Zeynep Akata and
                  Samuel Albanie},
  title        = {Audio Retrieval with Natural Language Queries},
  booktitle    = {Interspeech},
  year         = {2021},
}

@article{Koepke21,
  author       = {A. Sophia Koepke and
                  Andreea{-}Maria Oncescu and
                  Jo{\~{a}}o F. Henriques and
                  Zeynep Akata and
                  Samuel Albanie},
  title        = {Audio Retrieval with Natural Language Queries: {A} Benchmark Study},
  journal      = {IEEE TMM},
  year         = {2022},
}

@inproceedings{AMT,
  author       = {Zhen Li and
                  Zuo{-}Liang Zhu and
                  Linghao Han and
                  Qibin Hou and
                  Chun{-}Le Guo and
                  Ming{-}Ming Cheng},
  title        = {{AMT:} All-Pairs Multi-Field Transforms for Efficient Frame Interpolation},
  booktitle    = {CVPR},
  year         = {2023},
}

@article{bark,
  author       = {Chengyi Wang and
                  Sanyuan Chen and
                  Yu Wu and
                  Ziqiang Zhang and
                  Long Zhou and
                  Shujie Liu and
                  Zhuo Chen and
                  Yanqing Liu and
                  Huaming Wang and
                  Jinyu Li and
                  Lei He and
                  Sheng Zhao and
                  Furu Wei},
  title        = {Neural Codec Language Models are Zero-Shot Text to Speech Synthesizers},
  journal      = {arXiv},
  year         = {2023},
}

@inproceedings{moviefactory,
  author       = {Junchen Zhu and
                  Huan Yang and
                  Huiguo He and
                  Wenjing Wang and
                  Zixi Tuo and
                  Wen{-}Huang Cheng and
                  Lianli Gao and
                  Jingkuan Song and
                  Jianlong Fu},
  title        = {MovieFactory: Automatic Movie Creation from Text using Large Generative
                  Models for Language and Images},
  booktitle    = {ACM MM BNI},
  year         = {2023},
}

@article{TTVFI,
  author       = {Chengxu Liu and
                  Huan Yang and
                  Jianlong Fu and
                  Xueming Qian},
  title        = {{TTVFI:} Learning Trajectory-Aware Transformer for Video Frame Interpolation},
  journal      = {CoRR},
  volume       = {arXiv},
  year         = {2022},
}
