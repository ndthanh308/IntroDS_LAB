\documentclass[lettersize,10pt,journal]{IEEEtran}
\usepackage{amsmath,amsfonts}
\DeclareMathOperator{\diag}{diag}
\DeclareMathOperator*{\argmax}{\arg\!\max}
\usepackage{algorithmic}
\usepackage{algorithm}
\usepackage{array}
\usepackage[caption=false,labelfont=sf,textfont=sf]{subfig}
\usepackage{textcomp}
\usepackage{stfloats}
\usepackage{url}
\usepackage{verbatim}
\usepackage{graphicx}
\usepackage{cite}
\usepackage[letterpaper, left=1in, right=1in, bottom=1in, top=1in]{geometry}
%\usepackage[letterpaper, margin=1in]{geometry}
%\usepackage[paper=a4paper,margin=1in]{geometry}
\usepackage[T1]{fontenc}
\usepackage{graphicx}
\usepackage{xcolor}
\usepackage{amssymb}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%added packages
\usepackage[compact]{titlesec}
\titlespacing{\section}{0pt}{*0}{*0}
\titlespacing{\subsection}{0pt}{*0}{*0}
\titlespacing{\subsubsection}{0pt}{*0}{*0}
\setlength{\belowdisplayskip}{0pt} \setlength{\belowdisplayshortskip}{0pt}
\setlength{\abovedisplayskip}{0pt} \setlength{\abovedisplayshortskip}{0pt}
\setlength{\abovecaptionskip}{0ex}
\setlength{\belowcaptionskip}{0ex}
\setlength{\textfloatsep}{0ex}
\setlength{\textfloatsep}{0pt}
\usepackage{etoolbox}
\makeatletter
\patchcmd{\@maketitle}{\normalsize}{\fontsize{8}{10}\selectfont}{}{}
\makeatother
\usepackage{mathtools, nccmath}
\IEEEaftertitletext{\vspace{-2.75\baselineskip}}
\usepackage{caption}
\IEEEoverridecommandlockouts
\setlength{\skip\footins}{0.5pt}
%\newtheoremstyle{newstyle}
%\theoremstyle{newstyle}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage{booktabs}
\usepackage[english]{babel}
\let\proof\relax
\let\endproof\relax
\usepackage{amsthm}
\makeatletter
\def\lemma@space@setup{\lemma@preskip=0pt
\lemma@postskip=0pt}
\makeatother
\newtheoremstyle{newstyle}      
{} %Aboveskip 
{} %Below skip
{\mdseries} %Body font e.g.\mdseries,\bfseries,\scshape,\itshape
{} %Indent
{\bfseries} %Head font e.g.\bfseries,\scshape,\itshape
{.} %Punctuation afer theorem header
{ } %Space after theorem header
{} %Heading
\newtheorem{theorem}{Theorem}
\theoremstyle{newstyle}\newtheorem{lemma}{Lemma}
\newtheorem{proposition}{Proposition}
\newtheorem{sublemma}{Lemma}[lemma]
\newcommand{\at}[1]{{\color{blue}  [\text{Arty:} #1]}}
\newcommand{\yl}[1]{{\color{red}  [\text{Ying:} #1]}}
\newcommand{\huazheng}[1]{{\color{blue}  [\text{Huazheng:} #1]}}
\hyphenation{op-tical net-works semi-conduc-tor IEEE-Xplore}
% updated with editorial comments 8/9/2021

\begin{document}

\title{\Large Online Modeling and Monitoring of Dependent Processes under Resource Constraints\vspace{-1.5ex}}%

%\author{
        % <-this % stops a space
%\thanks{This paper was produced by the IEEE Publication Technology Group. They are in Piscataway, NJ.}% <-this % stops a space
%\thanks{Manuscript received April 19, 2021; revised August 16, 2021.}
%}

\author{ 
    \IEEEauthorblockN{Tanapol Kosolwattana\IEEEauthorrefmark{1}\thanks{\IEEEauthorrefmark{1}Department of Industrial Engineering, University of Houston}, Huazheng Wang\IEEEauthorrefmark{2}\thanks{\IEEEauthorrefmark{2}School of Electrical Engineering and Computer Science, Oregon State University}, Ying Lin\IEEEauthorrefmark{1}}
}

% The paper headers
%\markboth{Journal of \LaTeX\ Class Files,~Vol.~14, No.~8, August~2021}%
%{Shell \MakeLowercase{\textit{et al.}}: A Sample Article Using IEEEtran.cls for IEEE Journals}

%\IEEEpubid{0000--0000/00\$00.00~\copyright~2021 IEEE}
% Remember, if you use this you must call \IEEEpubidadjcol in the second
% column for its text to clear the IEEEpubid mark.

\maketitle
\begin{abstract}
Monitoring a population of dependent processes under limited resources is critical for abnormal events detection. A novel online collaborative learning method is proposed to adaptively allocate the resources for exploitation of high-risk processes and exploration of dependent dynamics. Efficiency of the proposed method is proved through theoretical analysis and experiments.\vspace{-1ex} 
\end{abstract}
\begin{IEEEkeywords}
Online collaborative learning, Adaptive monitoring of dependent processes, UCB algorithm
\end{IEEEkeywords}

\section{Introduction}
In a large-scale population consisting of $N$ units, with each unit has a distinct and dynamic health progression process. Limited monitoring or sensing resources allow for the monitoring of only $M$ (where $M < N$) out of the $N$ units in each monitoring cycle. Our interest lies in allocating the monitoring resources to the units with the highest risks of abnormal events, such as disease onset in healthcare, to ensure timely initiation of preventive care \cite{8169076}. However, efficiently allocating monitoring resources to high-risk units remains a challenging issue due to the absence of prior knowledge and insufficient monitoring data to accurately estimate the risk of each unit. This is a common problem in various applications, including healthcare \cite{lowe2004monitoring} and manufacturing \cite{liang2013opportunistic}. In the cognitive monitoring of new patients at risk of dementia, for instance, each unit represents a new patient and the early detection of cognitive decline can prevent or delay his/her brain damage \cite{weimer2009early}. Resource constraints, such as limited staff and appointment slots in the healthcare system, necessitate the allocation of limited monitoring resources to the patients with the most severe cognitive decline  \cite{doi:10.1080/24725854.2018.1470357}. However, the cognitive degradation of patients is typically unknown and difficult to predict from insufficient historical data, posing significant challenges in monitoring strategy design. 

The development of efficient monitoring strategies under uncertain process dynamics can be formulated as a multi-armed bandit (MAB) problem. MAB problems aim to pull a subset of arms with maximal expected rewards in each decision cycle. Since the reward function of each arm is unknown, the MAB algorithms, such as linear upper confidence bound (LinUCB \cite{li2010contextual}), determine the optimal pulling strategy by balancing the trade-off between exploitation (benefits of pulling arms with the highest predicted rewards) and exploration (benefits of gathering more information to reduce uncertainty in model estimation) \cite{10.1145/2911451.2911528}. However, utilizing MAB algorithms to address the adaptive monitoring problem presents several challenges. 

First, conventional MAB algorithms were developed for static arms whose underlying reward distributions remain unchanged over time \cite{besbes2014stochastic}. These algorithms are primarily designed to estimate the reward distributions and identify the arm with the highest expected reward. %For instance, in website advertising placement, the objective is to maximize profits by selecting the commercial advertisement with the highest reward, which is typically measured by click-through rate (CTR) \cite{li2010contextual}. The CTR is determined by a binary reward, where it is 1 when the advertisement is clicked and 0 otherwise.
However, in the case of health monitoring, the reward of monitoring is associated with the health condition of a patient, which dynamically changes with respect to time or time-dependent predictors \cite{8169076}. The conventional MAB algorithms are inadequate to predict the monitoring reward from dynamic health progression and gather patient information to infer the health progression dynamics.

Second, most of the MAB algorithms were developed for independent arms, making them challenging to be extended for a population of dependent processes \cite{10.1145/2911451.2911528}. The dependency between dynamic processes, often represented by latent group structures within the population or the pairwise similarities between processes, is commonly observed in various healthcare and engineering systems \cite{8363633}. In the cognitive monitoring of the aging population, for example, the mechanisms of cognitive decline can be approximately classified into three types: normal aging, mild cognitive impairment, and Alzheimer's disease \cite{petersen1999mild}. Patients with the same mechanism are likely to exhibit similar cognitive decline processes, whereas patients belonging to different types showcase distinct cognitive degradation patterns. On the other hand, cognitive degradation is affected by a set of risk factors, such as age, gender, and genes \cite{8169076}. Patients with similar profiles on these risk factors also tend to exhibit similar cognitive degradation dynamics. Numerous studies have demonstrated the criticality of explicitly capturing the dependency between dynamic processes to enhance the accuracy of health progression modeling, particularly when dealing with limited training data \cite{doi:10.1080/24725854.2018.1470357}. However, existing methods that leverage the dependency between processes primarily focus on retrospective health progression modeling approaches, such as latent growth modeling, mixture models, and the recently developed collaborative learning method. The development of algorithms for online modeling and monitoring of dependent processes is currently insufficient.

%Previous studies have addressed the adaptive monitoring problem. A collaborative regression model is developed to approximate the health progression of each unit by leveraging a set of canonical models and their ensemble \cite{8169076}. It is flexible to incorporate prior knowledge, such as the similarities between units, to enhance the estimation of individualized models. The collaborative regression model transforms the individualized health progression modeling problem to a constrained optimization problem that can be efficiently solved by the gradient-based algorithm \cite{8169076}. However, this method is developed for retrospective modeling that requires sufficient historical data to understand the entire process of health progression and is unsuitable for online health modeling and monitoring \cite{bell2014practical}. An approach called selective sensing, introduced in \cite{doi:10.1080/24725854.2018.1470357}, integrates prognostic modeling of unit degradation and resource allocation based on the severity of health conditions. Although this approach considers dependencies between processes and updates health progression dynamics with newly collected information, it does not provide an optimal monitoring strategy that balances exploitation and exploration in an uncertain environment. Existing bandit algorithms are inadequate for solving the adaptive monitoring problem defined in this paper, as they either overlook dependencies among units or fail to exploit the latent structure of the monitored units. To address this issue, the matrix factorization with low-rank matrix completion is applied to characterize latent factors deduced from the user's historical patterns. The MLinGreedy in \cite{yang2021impact} assumes there is a shared linear feature extractor that maps the raw context to a low-dimensional embedding. It is similar to our algorithm since its latent group structure also represents how similar each process is to the other. However, MLinGreedy does not consider dependency among the tasks.
  
To mitigate these gaps, we propose an Online Collaborative Learning (OCL) algorithm that captures the dependency in a population of dynamic processes during online modeling and monitoring. 
%It consists of two components: the individualized health progression model and the Collaborative Learning-based UCB (CL-UCB) algorithm. First, the individualized health progression model explores the underlying structure of health progression dynamics through collaborative learning. Additionally, it models the dependency among units by utilizing graph Laplacian regularization, which constructs connections between units based on the similarity of the dependency structure. Second, a novel CL-UCB algorithm is proposed to estimate the unknown parameters in health progression through the alternating least square algorithm. This algorithm also derives a new UCB-based exploration strategy to search for the optimal selection that balances the predicted rewards of monitoring high-risk units and the uncertainty of the prediction for other units. 
The contributions of this paper can be summarized as:
\begin{itemize}
    \item We propose a novel Online Collaborative Learning (OCL) framework to adaptively model the health progression of dependent processes through collaborative learning and a novel Collaborative Learning-based UCB (CL-UCB) algorithm to obtain the optimal monitoring which balances the exploitation of high-risk units and the exploration of uncertain units.
    \item We perform theoretical analysis to prove that by considering the dependency in process progression, we can achieve a better upper regret bound of the monitoring strategy compared to other MAB algorithms.
    \item We demonstrate the effectiveness of the proposed method through simulation studies and an empirical study of adaptive cognitive monitoring in Alzheimer's disease. The results showcase the improvements in parameter estimation and monitoring accuracy for high-risk units.
\end{itemize}
\vspace{-0.4ex}

The structure of this paper is organized as follows. Section II introduces the proposed online collaborative learning framework. In Section III, the efficiency of the proposed algorithm is demonstrated through a simulation study and an empirical study of cognitive degradation monitoring for Alzheimer's disease (AD). Finally, the conclusion of this paper is drawn in Section IV. %\huazheng{Should also mention that we analyzed regret bound and did experiments.}

% \section{Literature Review}
% \yl{due to page limit, please remove literature review section and include some literature review in the introduction}
% The health progression modeling methods are first reviewed in Section \ref{sub2.1}, which retrospectively model the progression dynamics of a population of dependent processes. Then the existing adaptive monitoring algorithms are summarized in Section \ref{sub2.2}, most of which were developed for stochastic health progression with discrete states and known dynamics. Lastly, the review of existing multi-armed bandit algorithms is provided in Section \ref{sub2.3}.


% \subsection{Health Progression Modeling}
% \label{sub2.1}
% The health progressions of $N$ units are not independent and can be correlated by a latent cluster structure \cite{doi:10.1080/24725854.2018.1470357}. The latent cluster structure is widely observed in numerous healthcare and engineering systems, with units within the same latent cluster tend to have similar health progression paths and units in different clusters have distinct models. To explicitly capture the latent cluster structure in health progression dynamics, different statistical models have been developed, such as the finite mixture models, latent class regression model \cite{vermunt2002latent}, and clusterwise linear regression \cite{desarbo1988maximum}. However, these statistical models usually rely on the assumptions of latent variables and hierarchical model structure, which can lead to the misspecification of distributions for real data and high computational cost in model estimation. To solve these issues, a collaborative regression model was recently developed by leveraging a set of canonical models and the ensemble of canonical models to approximate each unit's health progression. It is also flexible to incorporate prior knowledge, such as the similarities between units, to enhance the estimation of individualized models. The collaborative regression model transforms the individualized health progression modeling problem to a constrained optimization problem which can be efficiently solved by the gradient-based algorithm \cite{8169076}. However, these methods were developed for retrospective modeling that require sufficient historical data to understand the whole process of health progression and cannot be used for online health modeling and monitoring \cite{bell2014practical}.

% \subsection{Adaptive Monitoring}
% \label{sub2.2}
% %\yl{please check the related works in SS paper. We need to review the adaptive monitoring algorithms that assume the health progression dynamics are well known, then move the algorithms that update the health progression dynamics but do not consider the dependencies between units. Finally, mention the ss model considers both but does not explore the uncertain units.} 
% The method in \cite{10.2307/23323677} develops a personalized monitoring strategy to maximize the total expected quality-adjusted life years of patients with breast cancer using the partially observable Markov decision process (POMDP). The POMDP or Markov decision process models usually assume the health progression dynamics are well known or only focus on the decision making of single unit, which are hard to be used for designing resource allocation strategies in a population of competing units. The optimal learning method in \cite{powell2012optimal} updates a monitoring strategy by considering the information gained by a response status measurement of a unit. However, the assumption of the reward generation of this method does not match our problem. Also, it does not consider dependency between units and the latent structure of the unit population.%\yl{Please check this part. I think optimal learning assume the process dynamics are unknown. } 
% The selective sensing method developed in \cite{doi:10.1080/24725854.2018.1470357} is the approach that integrates the prognosis part to predict the risk of units using modeling the unit's degradation models and the sensing part to allocate resources to units that have the most severe health conditions. Even though this approach considers the dependencies between processes and updates the estimated health progression dynamics with newly collected information, it did not provide the optimal monitoring strategy that achieves the exploitation-exploration trade-off in an uncertain environment. In this paper, we design an upper confidence bound (UCB)-based exploration strategy to optimally allocate the limited monitoring resources for balancing the exploitation and exploration of dependent dynamic processes. 

% \subsection{Multi-armed bandit algorithms}
% \label{sub2.3}
% Multi-armed bandit algorithms provide the framework for decision-making over time under uncertainty. However, existing bandit algorithms cannot solve the adaptive monitoring problem defined in this paper because they either ignore dependency among units or do not exploit the latent structure of monitoring units. To solve this type of problem, contextual bandit algorithms are commonly used since they can address the explore-exploit dilemma when selecting the high-risk units during the degradation cycles. The LinUCB algorithm determines the expected reward via the content features extracted from units \cite{10.1145/2911451.2911528}. However, because it estimates the unknown bandit parameters for each unit independently, it ignores dependency among units, meaning it does not exploit the shared information between units and creates bias during the learning process. To tackle this problem, the GOB.Lin algorithm introduced in \cite{DBLP:journals/corr/Cesa-BianchiGZ13} connects units as a network through a graph Laplacian regularization which shares the contexts and rewards among units. It assumes that the parameters of units related to each other are close. However, the unknown parameters estimated by the GOB.Lin algorithm do not represent a complex heterogeneous structure which is common in various degradation systems. Apart from GOB.Lin, the Collaborative Linear Bandit or CoLin in short developed in \cite{10.1145/2911451.2911528} also integrates similarity information from users to the model. While GOB.Lin requires connected units in the network to have similar bandit parameters through graph Laplacian regularization, CoLin instead makes the assumptions about the reward generation via an additive model. Specifically, it allows neighboring units to share their influence on neighbors' decisions which provide the capability to capture the heterogeneity among units.

% The concept of matrix factorization with low-rank matrix completion is applied to characterize latent factors deduced from the user's historical patterns. To check if the tasks are related to each other, the MLinGreedy in \cite{yang2021impact} assumes there is a shared linear feature extractor that maps the raw context to a low-dimensional embedding. This algorithm is similar to our algorithm because the latent group structure also represents how similar each process is to the other. However, the MLinGreedy does not consider similarity regularization to model dependency among the tasks. Also, it relies on the strict assumption of the assignment of minimum eigenvalue. Thus, it might not apply to other general cases like other bandit algorithms that implement Self-Normalized Bound for Vector-Valued Martingales from \cite{NIPS2011_e1d5be1c}. 
% In the Hidden Linear Bandit algorithm (hLinUCB) developed in \cite{10.1145/2983323.2983847}, in addition to the observed contextual features, it learns the hidden features which are introduced to reduce bias in the reward generation since some of them are not detectable by the algorithm. Also, it applies the coordinate descent algorithm to estimate the hidden features and the unknown bandit parameters and to derive the exploration strategy for online learning. 



% % \begin{table*}[ht] 
% %   \caption{Notation of parameters}
% %   %\setlength{\tabcolsep}{0.6\tabcolsep}% Shrink \tabcolsep by 30%
% %   \centering
% %   \begin{tabular}{ *{4}{c} }
% %     \toprule
% %     \textbf{Notation} & \textbf{Definition} & \textbf{Dimension} &\textbf{Description} \\
% %     \midrule
% %     $y_t$ & $[y_{t1}, \ldots, y_{tN}]^T$
% %     & $N \times 1$ & Health conditions of all units at cycle $t$ \\
% %     $x_t$& $[x_{t,1},\ldots ,x_{t,N}]$ & $P \times N$ & Feature matrix of all units at cycle $t$\\
% %     $c$ & $[c_{1},\ldots ,c_{N}]$ & $K \times N$ & Membership matrix of all units\\
% %     $Q$& $[q_1, \ldots, q_K]$& $P \times K$ & The latent model\\
% %     $X_t$ &
% %     $ \begin{bmatrix}
% %     I_K \otimes X_{t1} & \cdots & I_K \otimes X_{tN} 
% %     \end{bmatrix} $
% %     & $Kp \times NK$& The feature matrix of all units at cycle $t$ in \textbf{Step-1}\\
% %     $q$ & $vec(Q) = [q_1^T,\cdots,q_K^T]^T$ &$Kp \times 1$& The transformed $q$ in \textbf{Step-1}\\
% %     $E$ &  $[E_{1}, \cdots, E_{N}]$
% %     & $N \times N$ & Laplacian matrix in \textbf{Step-2}\\
% %     $F$ &$\eta_2I_{N} + \lambda E$
% %     & $N \times N$ & The sum of the identity matrix $I_{N}$ \\
% %     &&& and Laplacian matrix $E$ in \textbf{Step-2}\\
% %     $F_\otimes$& $F \otimes I_K$ & $NK \times NK$ & The Kronecker product of $F$ and $I_K$ in \textbf{Step-2}\\
% %     $\Tilde{X_t}$ &$F_\otimes^{\frac{-1}{2}} diag(Q,\ldots, Q)^Tdiag(x_t)$
% %     & $NK \times N$ & The transformed  $\Tilde{X_t}$ in \textbf{Step-2}\\
% %     $\Tilde{C}  $& $ F_\otimes^{\frac{1}{2}}(vec(c))$ 
% %     & $NK \times 1$ & The transformed $\Tilde{C}$ in \textbf{Step-2}\\
% %     \bottomrule
% %   \end{tabular}
% %   \label{table:1}
% % \end{table*}
% Figure environment removed

\vspace{1ex}
\section{Method}
%All notations used in this section are summarized in Table \ref{table:1}. 
\subsection{Problem Statement}
\label{sub3.1}

We consider a population of $N$ units to be monitored over $T$ cycles. In each cycle, a feature vector is available for each unit to predict its health progression dynamics, denoted as $x_{t,i}$, $t\in\{1,\dots,T\}$, $i\in\{1,\dots,N\}$. If a unit is monitored in $t$th cycle, the unit's health condition is measured and denoted as $y_{t,i}$. The health monitoring system aims to select $M$ units for monitoring in each monitoring cycle so that units with most severe health conditions are maximally monitored. The monitoring decisions in cycle $t$ can be represented as a vector of binary variables $a_t$, with each element ($a_{t,i}$) indicates whether the $i$th unit is monitored $(a_{t,i} = 1)$ or not $(a_{t,i} = 0)$. The summation of binary variables in each cycle is constrained by the monitoring capacity, i.e. $\sum_{i = 1}^{N} a_{t,i} = M$. The reward of monitoring a unit is defined based on its health condition and monitoring a more severe unit is expected to lead to a higher reward than monitoring a healthy unit. Therefore, the reward of a monitoring strategy in cycle $t$ can be represented as:
\begin{equation} \label{eq:1}
    \medmath{r_{a_t} = {\textstyle\sum}_{i = 1}^{N}a_{t,i} y_{t,i}}
\end{equation}

Clearly, with the knowledge of units' health conditions in each cycle, the optimal monitoring strategy can be simplified as choosing the $M$ units with the most severe health conditions in each cycle. However, as the unit's health conditions and progression dynamics are unknown, it is hard to find the optimal monitoring strategy. To solve this problem, an online collaborative learning method is proposed by integrating the individualized health progression modeling, monitoring strategy design under limited resources, and online learning algorithms.

\subsection{Online Collaborative Learning (OCL) framework}
\label{sub3.2}
The proposed OCL method in Figure \ref{fig:fig1} 
%\yl{in figure 1, collaborative learning algorithm should have capitalized first letter} 
consists of two interactive phases: health modeling and health monitoring. In the health modeling phase, historical observations and prior information on units' similarities are utilized to estimate health progression of the units through a collaborative learning algorithm. In the health monitoring phase, an alternating least square algorithm is proposed to estimate the unknown parameters in the health modeling, enabling the prediction of their health conditions and the associated prediction uncertainties. Subsequently, an upper confidence bound (UCB)-based exploration strategy is designed to find the optimal monitoring strategy in the next cycle by integrating the predicted health conditions and their uncertainties. New information collected from observations on $M$ monitored units is used to update the model and monitoring strategy in the next cycle.

\subsection{Collaborative learning-based health modeling}

\label{sub3.3}
To predict the health conditions of $N$ units in real time, their health progression dynamics need to be explicitly modeled. The health progression dynamic on each unit is represented by a distinct regression model that predicts the health condition in each cycle from the corresponding feature vector, i.e., $y_{t,i} = x_{t,i}^T\beta_i + \epsilon_i$. $\beta_i$ represents the coefficients in individualized regression model and $\epsilon_i$ is a random noise that follows the normal distribution. Regression models have been popular tools in a wide range of system dynamics modeling problems, such as disease trajectory modeling and degradation modeling\cite{8169076}. It is also flexible to capture the nonlinear dynamics in health progression by applying nonlinear transformations on the feature vectors\cite{filippi2010parametric}. The feature vectors can be defined using the basis functions of time or routinely observed information from units.

To capture the dependency in health progression dynamics of a population, we leverage the idea of collaborative learning \cite{8169076}. The collaborative learning method approximates $N$ individual health progression models by a small number of canonical models that represent the typical mechanisms in health progression. Each unit's health progression is represented by the ensemble of canonical models with an individualized membership vector. 
%Let  $g^{1}(x),\dots,g^{K}(x)$ represent $K$ canonical models in the population, the health progression dynamic for unit $i$ can be estimated by the weighted combination of the predictions of from $K$ canonical models, i.e. $f_i (x) = \sum_{k} c_{ik} g^{k}(x)$; $c_{ik}$ is the element in unit $i$’s membership vector $c_i$. 
Assuming each canonical model can be described by a linear regression model with coefficients $q_k$,
%i.e., $g^k (x) = x^T q_k$. 
%With the linear regression assumption, the health progression dynamic for unit $i$ can be approximated as $f_i(x)=\sum_{k} c_{ik}x^T q_k$. 
the collaborative learning method can be regarded as a matrix factorization problem which decomposes the coefficients of individual linear regression models to two low-rank matrices, denoted as $\beta_i=Qc_i$. $Q = [q_1,\ldots, q_K] \in \mathbb{R}^{p \times K}$ represents the coefficients in canonical models and $c_i\in \mathbb{R}^{K \times 1}$ represents the individualized membership vector. In this paper, we assume the canonical models and membership vectors are unconstrained and let data freely determine the latent structure.
%such as the Generalized Linear Model-UCB (GLM-UCB) algorithm developed in \cite{filippi2010parametric}.

The collaborative learning method can further leverage the similarity information between units to enhance the model learning by assuming that similar units tend to follow similar health progression dynamics. It regards the similarities between units as prior knowledge that can be obtained from domain experts or units' profiles on risk factors and uses the similarity information to regularize the learning of individualized membership vectors. Given the similarity information between units, denoted as $w_{ij}$ for subjects $i$ and $j$, and the historical observations on these units, the collaborative learning method is formulated as a nonconvex optimization problem in the following, which simultaneously minimizes the training error on historical observations and the variations on health progression dynamics for similar units %\yl{can we directly represent the equation 2 using the notations in equation 4? Thus we can use less notations and save space.}: 
%\yl{reduce the font size of equation 2 to fit it in one line}
\begin{equation} \label{eq:2}
    \resizebox{1\hsize}{!}{$\min\limits_{c_{i}, Q} \sum\limits_{i} \left\| y_{i} - X_{i}Qc_{i}\right\|_2^{2} +\eta_1\left\|Q\right\|_F^{2}
    +\eta_2\sum\limits_i \left\|c_{i}\right\|_2^{2} + \lambda \sum\limits_{i, j} \left\| c_{i} - c_{j}\right\|_2^{2}w_{ij}$}
\end{equation} 

where the observed health conditions of unit $i$ over $T_i$ cycles are denoted as $y_i = [y_{1, i},\ldots, y_{T_i, i}]^T \in \mathbb{R}^{T_i \times 1}$ and the associated feature vectors are defined as $X_i = [x_{1, i},\ldots, x_{T_i, i}]^T \in \mathbb{R}^{T_i \times p}$. L2 regularizations are used on $Q$ and $c_i$ to control the scale of unknown parameters and enforce unique solution with the tuning parameters $\eta_1$ and $\eta_2$. $\lambda$ is the tuning parameter to control the effect of the similarity information on the parameter estimation.
\vspace{-2ex}
\subsection{CL-UCB exploration strategy for health monitoring}
\label{sub3.4}
As mentioned in Section \ref{sub3.1}, our main problem is to 
estimate the health progression dynamics for $N$ units to predict their health conditions in real-time, such that $M$ out of $N$ units with the most severe health conditions are selected to be monitored.
This section provides the details of how to integrate the collaborative learning approach described in Section \ref{sub3.2} to the health monitoring phase. The key idea in health monitoring phase is to select $M$ units that best balance the objectives of monitoring units with severe predicted health conditions (exploitation) and monitoring the units with high uncertainty in health predictions (exploration). Therefore, it is critical to obtain the uncertainty in health predictions. To achieve this goal, the collaborative learning model is first transformed and efficiently solved by an alternating least square algorithm, which provides closed form solutions for each step of parameter updates. Then the confidence bounds of parameters estimated from the alternating least square algorithm are derived theoretically. Finally, a novel collaborative learning-based UCB (CL-UCB) exploration strategy is proposed to online update the collaborative learning model and inform monitoring strategy design based on the units' predicted health conditions and their confidence bounds. %\huazheng{it refers to? Should be we?}

\subsubsection{Alternating least square algorithm to estimate model parameters}
To estimate the parameters in collaborative learning, an alternating least square algorithm is proposed that minimizes the objective function in Eq. \ref{eq:2}. The proposed alternating least square algorithm alternatively updates the model parameters using two main steps. It estimates the canonical models by fixing the membership vectors in Step-1 and then updates the membership vectors with fixed canonical models in Step-2.

\textbf{Step-1} Fixing the membership vectors $c_i$, the canonical models can be estimated by solving the following least-square estimation problem%\huazheng{Do we have constraints in (3)?}
\begin{equation} \label{eq:3}
     \medmath{\min_{q} {\textstyle\sum}_{t=1}^{T} \left\| C^{T}X_{t}^Tq - y_{t} \right\|_2^{2} + \eta_1 \Vert q\Vert_2^2}
\end{equation}
Assuming $N_t$ observations were collected over all units until cycle $t$, the historical observations can be represented as $y_t$, $y_t = [y_{t,1},\ldots ,y_{t,N_{t}}]^T \in \mathbb{R}^{N_{t} \times 1}$, $x_t = [x_{t,1},\ldots ,x_{t,N_{t}}] \in \mathbb{R}^{P \times N_{t}}$. The membership vectors are represented as $c = [c_{1},\ldots ,c_{N_{t}}] \in \mathbb{R}^{K \times N_{t}}$. 
%\yl{please check the dimensions. Should be $N_{t}$} 
By transforming the feature and membership vectors to $X_t = x_t \otimes I_{K} \in \mathbb{R}^{Kp \times N_{t}K}$ and $C = diag(c) \in \mathbb{R}^{N_{t}K \times N_{t}}$, %$X_t$ and $C$ can be illustrated as: \[ 
%    X_t =
%    \begin{bmatrix}
%    x_{t,1} & \cdots & 0 & \cdots & x_{t,N} & \cdots & 0 \\
%    \vdots  & \ddots & \vdots & \cdots & \vdots  & \ddots & \vdots\\
%    0 & \cdots & x_{t,1} & \cdots & 0 & \cdots & x_{t,N}
%    \end{bmatrix},
%    C =
%    \begin{bmatrix}
%    c_1 & \cdots & 0 \\
%    \vdots  & \ddots & \vdots  \\
%    0 & \cdots & c_N
%    \end{bmatrix}
%\]
and representing the parameters in canonical models as a $Kp \times 1$ vector, $q = vec(Q) = [q_1^T,\cdots,q_K^T]^T$ where $vec(\cdot)$ is the concatenation of parameters, the optimization problem in Eq. \ref{eq:2} can be transformed to Eq. \ref{eq:3}, which has
the closed-form solution of $q$.
%achieved by $\hat{q_t} = A_t^{-1} b_t$ in which,
% \begin{align}
%     \medmath{A_t} ={}& \medmath{\sum_{t^{\prime} = 1}^{t} X_{t^{\prime}}C_{t^{\prime}}C_{t^{\prime}}^TX_{t^{\prime}}^T  + \eta_1 I_{Kp}} \label{eq:4}\\
%     \medmath{b_t} ={}& \medmath{\sum_{t^{\prime} = 1}^{t} X_{t^{\prime}}C_{t^{\prime}}y_{t^{\prime}}} \label{eq:5}
% \end{align}
%By transforming the features of all units in cycle $t$ to a diagonal feature matrix $X_t^* \in \mathbb{R}^{Np \times N}$, representing the canonical model parameters as another diagonal matrix $Q^* \in \mathbb{R}^{Np \times NK}$
%where
%\[
%    X_t^* =
%    \begin{bmatrix}
%    x_{t,1} & \cdots & 0 \\
%    \vdots  & \ddots & \vdots  \\
%    0 & \cdots & x_{t,N}
%    \end{bmatrix},
%    Q^* =
%    \begin{bmatrix}
%    Q & \cdots & 0 \\
%    \vdots  & \ddots & \vdots  \\
%    0 & \cdots & Q
%    \end{bmatrix}
%\]

\textbf{Step-2}: Fixing the canonical models $Q$, the membership vectors can be estimated by solving the following least square estimation problem. 
\begin{equation} \label{eq:6}
    \medmath{\min_{\Tilde{C}} {\textstyle\sum}_{t=1}^{T} \left\| \Tilde{X_{t}}^T\Tilde{Q}\Tilde{C} - y_{t} \right\|_2^{2} + \eta_2 \Tilde{C}^T F_{\otimes} \Tilde{C}}
\end{equation}
%\yl{please shorter this part following Step-1}
%\yl{check the dimensionality, should be $N$ or $N_t$}
Similar to \cite{DBLP:journals/corr/Cesa-BianchiGZ13}, we use a graph laplacian matrix $E \in \mathbb{R}^{N \times N}$ to represent the similarity information between $N$ units and set $F_\otimes = (I_{N} + \lambda E) \otimes I_{K} \in \mathbb{R}^{NK \times NK}$. The feature vectors and canonical models are re-represented as $\Tilde{X_{t}} = diag(x_{t},\ldots, x_{t})$ and $\Tilde{Q} = diag(Q,\ldots, Q)$ respectively. Denoting the parameters of membership vectors as a $NK \times 1$ vector, $\Tilde{C}  = vec(c)$, the regularized objective function can be efficiently represented as Eq. \ref{eq:6},
%Setting $F_\otimes= F \otimes I_K$, the feature matrix is rewritten as $\Tilde{X_{t}} = F_\otimes^{-1/2} diag(Q,\ldots, Q)^Tdiag(x_t) \in \mathbb{R}^{NK \times N}$.  
which can also be easily solved with closed form solution.
%\yl{check the definition. The dimension does not match}. 
%\yl{please revise the first part in equation 4. We shall express X and Q separately. I also revised the definition of $\Tilde{C}$ which does not include $F$}
%$F$ is transformed into $F_\otimes \in \mathbb{R}^{NK \times NK}$
%achieved by $\hat{\Tilde{C_t}} = D_t^{-1} d_t$ in which,
% \begin{align}
%     \medmath{D_t} ={}& \medmath{\sum_{t^{\prime}=1}^{t}  \Tilde{X_{t^{\prime}}}\Tilde{X_{t^{\prime}}^T} + \eta_2I_{NK}}\label{eq:7}\\
%     \medmath{d_t} ={}& \medmath{\sum_{t^{\prime}=1}^{t} \Tilde{X_{t^{\prime}}} y_{t^{\prime}}} \label{eq:8}
% \end{align}
The procedure of the proposed alternating least square algorithm for estimating the collaborative learning model is summarized in Line 11 - Line 20 of \textbf{Algorithm \ref{alg:alg1}}. 

%%%%%%%%%%%%%%%%%%%%%%% algorithm 2%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%$F^{-1/2}_\otimes$ to $F^{-\frac{1}{2}}_\otimes \in \mathbb{R}^{NK \times NK}$ and
%\begin{algorithm}[!t]
%\captionsetup{font=small}
%\caption{Collaborative Learning UCB (CL-UCB)}\label{alg:alg2}
%\begin{algorithmic}[1]
%\small
%\STATE \textbf{Input:} $\eta_1, \eta_2, \lambda, \alpha^q, \alpha^{\Tilde{C}}, M$
%\STATE Initialize $A_0 \gets \eta_1 I_{Kp}$, $b_0 \gets 0$, $D_0 \gets \eta_2 I_{NK}$, $d_0 \gets 0$
%\FOR{$t \gets 1,\ldots,T$}
 %   \STATE Observe features of all arms $i \in S_t: x_{t, i} \in \mathbb{R}^{p \times 1}$ and transform %to a matrix $X_{t, i} \in \mathbb{R}^{Kp \times NK}$
 %   \STATE Transform $q_{t}$ to $\Tilde{Q}_t$
 %   \FOR{all $i \in S_t$}
 %       \STATE Transform $X_{t, i}$ to $\Tilde{X}_{t, i} \in \mathbb{R}^{Np \times 1}$
  %      \STATE $\hat{u}_{t, i} \gets \Tilde{C}_{t}^T X_{t, i}^T q_{t} + \alpha^{\Tilde{C}} %\sqrt{\Tilde{X}_{t+1, i}^T\Tilde{Q}_{t}D_{t}^{-1} \Tilde{Q}_{t}^T\Tilde{X}_{t+1, i}} $
%        \STATE $+ \alpha^q \sqrt{\Tilde{C}_{t}^T X_{t, i}^T A_{t}^{-1} X_{t, i}\Tilde{C}_{t}}$
%    \ENDFOR
%    \STATE Use Algorithm \ref{alg:alg1} to solve the minimization problem in Eq. \ref{eq:2}.
%\ENDFOR
%\STATE \textbf{Output:} ${\hat{q}_{t+1}, \hat{\Tilde{C}}_{t+1}}$
%\end{algorithmic}
%\label{alg2}
%\end{algorithm}
%%%%%%%%%%%%%%%%%%%%%%% algorithm 2%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\yl{reduce the text font in Algorithm 1 and 2 so that we can save more space. Remove the space between two algorithms}%\huazheng{Use ref command}
%\vspace{-0.25ex}

\subsubsection{CL-UCB exploration strategy for online health modeling and monitoring}
%\vspace{-0.25ex}

%The canonical models and membership vectors estimated from the alternating least square algorithm provide the predicted health condition for all $N$ units in the next cycle $t+1$ by $\hat{y}_{t+1} = C^{T}X_{t+1}^{T}q$. It represents the model’s current best knowledge about health progression and therefore serves for exploitation purposes. However, only selecting units that have the highest predicted health conditions is not sufficient in designing an optimal monitoring strategy since the uncertainty in prediction and these units cannot guarantee to be optimally chosen for the entire monitoring period. Thus, it is critical to design the exploration part in the monitoring strategy which allows uncertain units to be explored to gain more information and more confidence in selection. To balance the trade-off between exploitation which is monitoring high-risk processes based on existing knowledge and exploration which is gaining the knowledge of monitoring uncertain processes, the upper confidence bound (UCB) principle is commonly used to estimate the confidence of units' predicted health conditions and inform the exploration of most uncertain units \cite{auer2002using}. 
We propose a new algorithm called Collaborative Learning-UCB (CL-UCB) to optimally allocate the monitoring resources that balances the trade-off between exploitation and exploration in online modeling and monitoring. It leverages the upper confidence bound (UCB) principle to measure the uncertainty of estimated parameters, i.e., the upper confidence bounds of $\Vert\hat{q_t} - q^*\Vert_{A_t}$ and $\Vert\hat{\Tilde{C_t}} - \Tilde{C}^*\Vert_{D_t}$ where $q^*$ and $\Tilde{C}^*$ are the ground-truth parameters. Then it integrates the predicted rewards with their uncertainty to balance the exploitation-exploration tradeoff. Based on the closed-form solution in the alternating least square algorithm, the confidence bound of $\hat{q_t}$ and $\hat{\Tilde{C_t}}$ can be obtained by the \textbf{Lemma \ref{lemma1}} below.\vspace{-1ex}
\begin{lemma}
\label{lemma1}When the Hessian matrix of the objective function in Eq. \ref{eq:3} and Eq. \ref{eq:6} are positive definite at the optimizer $q^*$ and $\Tilde{C^*}$ with proper initialization, for any $\epsilon_1 \geq 0$, $\epsilon_2 \geq 0$, ${\scriptstyle \Vert X_t\Vert_2 \leq S}$, ${\scriptstyle \Vert q_t\Vert_2 \leq L}$, ${\scriptstyle \Vert \Tilde{C}_{t}\Vert_2 \leq P}$, and for any $\delta \geq 0$, with probability at least 1 - $\delta$, the estimation errors of the canonical models and the membership vectors obtained from \textbf{Algorithm \ref{alg:alg1}} are upper bounded by:
\begin{multline*}
    \resizebox{0.8\hsize}{!}{$\Vert\hat{q_t} - q^*\Vert_{A_t} \leq{} \sqrt{Kp\ln(\frac{\eta_1 Kp + tS^2P^2}{\eta_1 Kp\delta})} + \sqrt{\eta_1}L$} \\
    \resizebox{0.5\hsize}{!}{$+ \frac{2SPL}{\sqrt{\eta_1}}\frac{(q_1+\epsilon_1)(1-(q_1+\epsilon_1)^t)}{1-(q_1+\epsilon_1)}$}
\end{multline*}
\begin{multline*}
    \resizebox{0.9\hsize}{!}{$\Vert\hat{\Tilde{C_t}} - \Tilde{C^*}\Vert_{D_t} \leq \sqrt{\ln(\frac{\eta_2NK + S^2L^2 \sum_{t^{\prime} = 1}^{T} \sum_{j = 1}^{NK} (f^{-1}_\otimes)_{j,j}}{\eta_2 NK\delta})} + \sqrt{\eta_2} P$} \\
    \resizebox{0.5\hsize}{!}{$\frac{2SPL}{\sqrt{\eta_2}}\frac{(q_2+\epsilon_2)(1-(q_2+\epsilon_2)^t)}{1-(q_2+\epsilon_2)}$}
\end{multline*}
%\begin{align*}
 %   &\resizebox{0.7\hsize}{!}{$\Vert\hat{q_t} - q^*\Vert_{A_t} \leq{} \sqrt{Kp\ln(\frac{\eta_1 Kp + tS^2P^2}{\eta_1 Kp\delta})} + \sqrt{\eta_1}L $}\\
 %   &\resizebox{0.3\hsize}{!}{$+ \frac{2SPL}{\sqrt{\eta_1}}\frac{(q_1+\epsilon_1)(1-(q_1+\epsilon_1)^t)}{1-(q_1+\epsilon_1)}$}\\
  %  & \resizebox{0.97\hsize}{!}{$\Vert\hat{\Tilde{C_t}} - \Tilde{C^*}\Vert_{D_t} \leq \sqrt{\ln(\frac{\eta_2NK + S^2L^2 \sum\limits_{t^{\prime} = 1}^{T} \sum\limits_{j = 1}^{NK} (f^{-1}_\otimes)_{j,j}}{\eta_2 NK\delta})} + \sqrt{\eta_2} P + \frac{2SPL}{\sqrt{\eta_2}}\frac{(q_2+\epsilon_2)(1-(q_2+\epsilon_2)^t)}{1-(q_2+\epsilon_2)}$}
%\end{align*}
\end{lemma}
%\vspace{-0.5ex}
%\yl{why? how you get the confidence bounds in equation 11 is still not clear}.
%The detailed proof of \textbf{Lemma \ref{lemma1}} is provided in the Appendix. 
%From \textbf{Lemma \ref{lemma1}}, denote $\alpha^q$ and $\alpha^{\Tilde{C}}$ as the upper bounds of $\Vert\hat{q_t} - q^*\Vert_{A_t}$ and $\Vert\hat{\Tilde{C_t}} - \Tilde{C^*}\Vert_{D_t}$ respectively, the upper confidence bound of the predicted health condition can be obtained in \textbf{Proposition \ref{proposition1}} which serves as the uncertainty of the predictions.
%\yl{equation 11 is not obvious, we need to formulate it as a Proposition or Property.}
% \vspace{-1ex}
% \begin{proposition}
% \label{proposition1}
%  With the probability at least $1-\delta$,
% \begin{align}
%     \medmath{\lvert y_{t,i}^* - \hat{y}_{t, i} \rvert} \leq{}& \medmath{\alpha^q \sqrt{\Tilde{C}_{t}^T F^{-\frac{1}{2}}_\otimes X_{t, i}^T A_{t}^{-1} X_{t, i} F^{-\frac{1}{2}}_\otimes \Tilde{C}_{t}}}\notag\\ 
%     +& \medmath{\alpha^{\Tilde{C}} \sqrt{\Tilde{X}_{t, i}^TD_{t}^{-1} \Tilde{X}_{t, i}} + 2q^{2t}}\label{eq:11}
% \end{align} 
% \end{proposition}
% \vspace{-1ex}
%\yl{should be $y$ not $r$? you used $i$ to represent the unit before, why change to $a$?}
%The detailed proof of \textbf{Proposition \ref{proposition1}} is shown in the Appendix.  
To balance the exploitation-exploration tradeoff, a unit's CL-UCB score is proposed for monitoring strategy design, which combines its real-time predicted health condition and the associated prediction uncertainty. Denote $\alpha^q$ and $\alpha^{\Tilde{C}}$ as the upper bounds of $\Vert\hat{q_t} - q^*\Vert_{A_t}$ and $\Vert\hat{\Tilde{C_t}} - \Tilde{C^*}\Vert_{D_t}$ obtained from \textbf{Lemma \ref{lemma1}} respectively, the CL-UCB score of unit $i$ is defined as follow:
\begin{equation}
   \resizebox{1\hsize}{!}{$\hat{u}_{t, i} \gets \Tilde{C}_{t}^T X_{t, i}^T q_{t} + \alpha^{\Tilde{C}} \sqrt{\Tilde{X}_{t+1, i}^T\Tilde{Q}_{t}D_{t}^{-1} \Tilde{Q}_{t}^T\Tilde{X}_{t+1, i}} + \alpha^q \sqrt{\Tilde{C}_{t}^T X_{t, i}^T A_{t}^{-1} X_{t, i}\Tilde{C}_{t}}$} \label{eq:12}
\end{equation} 
%\yl{You used $i$ to represent the unit before, why change to $a$?}
The first term in Eq.\ref{eq:12} represents the predicted health condition of unit $i$. The second and third terms represent the prediction uncertainty due to the canonical models and membership vector estimations respectively. To allocate the resources to both high-risk and uncertain processes, we select $M$ units that have the highest CL-UCB score to be monitored in the next cycle. The procedure of CL-UCB is summarized in \textbf{Algorithm \ref{alg:alg1}}.%\yl{you used $M$ before}
%%%%%%%%%%%%%%%%%%%%%%% algorithm 1%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{algorithm}[!t]
\captionsetup{font=small}
\caption{Collaborative Learning UCB (CL-UCB)}\label{alg:alg1}
\footnotesize
\begin{algorithmic}[1]
\STATE \textbf{Input:} $\eta_1, \eta_2, \lambda, \alpha^q, \alpha^{\Tilde{C}}, M, F_{\otimes}$
\STATE Initialize $A_0 \gets \eta_1 I_{Kp}$, $b_0,d_0 \gets 0$, $D_0 \gets \eta_2 F_{\otimes} I_{NK}$
\FOR{$t \gets 1,\ldots,T$}
    \STATE Observe features of all arms $i \in S_t: x_{t, i} \in \mathbb{R}^{p \times 1}$ and transform to a matrix $X_{t, i} \in \mathbb{R}^{Kp \times N_{t}K}$
    \FOR{all $i \in S_t$}
        \STATE Transform $X_{t, i}$ to $\Tilde{X}_{t, i} \in \mathbb{R}^{N_{t}p \times 1}$ and $q_{t}$ to $\Tilde{Q}_t$
        \STATE $\hat{u}_{t, i} \gets \Tilde{C}_{t}^T X_{t, i}^T q_{t} + \alpha^{\Tilde{C}} \sqrt{\Tilde{X}_{t+1, i}^T\Tilde{Q}_{t}D_{t}^{-1} \Tilde{Q}_{t}^T\Tilde{X}_{t+1, i}} $
        \STATE $+ \alpha^q \sqrt{\Tilde{C}_{t}^T X_{t, i}^T A_{t}^{-1} X_{t, i}\Tilde{C}_{t}}$
    \ENDFOR
    \STATE Select a subset $\Tilde{S} \in S_t$ that contains $M$ arms with the highest $\hat{u}_{t, i}$
    \WHILE{not converge}
        \FOR{$i \in \Tilde{S}$}
            \STATE $A_{t+1} \gets A_{t+1} + X_{t+1} C_{t+1} C_{t+1}^T X_{t+1}^T$ 
            \STATE $b_{t+1} \gets b_{t+1} +  X_{t+1} C_{t+1}y_{t+1, i}$
            \STATE $D_{t+1} \gets D_{t+1} + \Tilde{Q}^T\Tilde{X}_{t+1, i} \Tilde{X}_{t+1, i}^T\Tilde{Q}$
            \STATE $d_{t+1} \gets d_{t+1} + y_{t+1, i} \Tilde{X}_{t+1, i}$
        \ENDFOR
        \STATE $\hat{q}_{t+1} \gets A_{t+1}^{-1}b_{t+1}, \hat{\Tilde{C}}_{t+1} \gets D_{t+1}^{-1}d_{t+1}$
        \STATE Normalize $\hat{\Tilde{C}}_{t+1}$
    \ENDWHILE
\ENDFOR
\STATE \textbf{Output:} ${\hat{q}_{t+1}, \hat{\Tilde{C}}_{t+1}}$
\end{algorithmic}
\label{alg1}
\end{algorithm}
%%%%%%%%%%%%%%%%%%%%%%% algorithm 1%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Regret Analysis}
\label{sub3.5}
%In this section, we provide a theoretical analysis of the cumulative regret of the Collaborative Learning UCB (CL-UCB) algorithm. Based on \textbf{Lemma \ref{lemma1}}, the alternating least square-based parameter estimation satisfies the two inequalities shown in Eq. \ref{eq:9} and Eq. \ref{eq:10} and it contributes to the final regret of the algorithm. 
Denote the optimal monitoring strategy as $a_t^*$, the corresponding optimal reward can be represented as $r_{a_t^*} = \sum_{i} a_t^*y_{t,i}$.The difference between the proposed algorithm’s total reward and the total reward of the optimal strategy is called cumulative regret, which is defined as:
\begin{equation} \label{eq:13}
    \medmath{R(T) = {\textstyle\sum}_{t = 1}^{T}R_t = {\textstyle\sum}_{t = 1}^{T}(\sum_{i} a_t^*y_{t,i} - \sum_{i} a_ty_{t,i})}
\end{equation}
\textbf{Theorem \ref{theorem1}} provides the upper regret bound of the CL-UCB algorithm, which analyzes the quality of the proposed monitoring strategy theoretically.\vspace{-0.7ex}
\begin{theorem}
\label{theorem1}
Based on a proper initialization of the alternating least square algorithm, with the probability at least 1 - $\delta$, the cumulative regret of the CL-UCB algorithm is upper bounded by:
\begin{multline*}
    %\medmath{R(T)} & \medmath{\leq \alpha^{\Tilde{C}}\sqrt{2TNK\ln{(1 + \frac{S^2L^2\sum_{t^{\prime} = 1}^{T} \sum_{j = 1}^{NK} (f^{-1}_\otimes)_{j,j}}{\eta_2NK})}}} \notag\\
    %&+ \medmath{\alpha^q\sqrt{2TKp\ln{(1 + \frac{TS^2P^2}{\eta_1 Kp})}} + \frac{2mq^2(1-q^{2T})}{1-q^2}} \\
    \resizebox{0.8\hsize}{!}{$
    R(T) \leq  \alpha^q\sqrt{2TKp\ln{(1 + \frac{TS^2P^2}{\eta_1 Kp})}} + \frac{2mq^2(1-q^{2T})}{1-q^2} $} \\
    \resizebox{0.8\hsize}{!}{$ +\alpha^{\Tilde{C}}\sqrt{2TNK\ln{(1 + \frac{S^2L^2\sum_{t^{\prime} = 1}^{T} \sum_{j = 1}^{NK} (f^{-1}_\otimes)_{j,j}}{\eta_2NK})}}  $} 
\end{multline*}
\end{theorem}
%\yl{this paragraph is hard to follow. Please reduce the mathematics and just use a few sentences to describe the insights from regret analysis.}
%$O(NK\sqrt{T}\ln{T} + (1-c^T_{\Tilde{C}})\sqrt{T\ln{T}} + \sqrt{T}\ln{\frac{T}{Kp}} + (1-c^T_{q})\sqrt{T\ln{\frac{T}{Kp}}})$ 
\vspace{-1ex}
According to \textbf{Theorem \ref{theorem1}}, the term $\phi_{T} = \sum_{t^{\prime} = 1}^{T} \sum_{j = 1}^{NK} (f^{-1}\otimes)_{j,j}$ plays a significant role in the upper regret bound of CL-UCB, highlighting the impact of the similarity information. First, if $F$ is an identity matrix, meaning that the proposed method solely considers the latent group structure without similarity information, then $\phi_T = NKT$ and leads to the upper regret bound of $O(NK\sqrt{T}\ln{T})$.
%where $c_{\Tilde{C}}$ and $c_q$ are the constant between 0 and 1 
When $K \ll p$, capturing the low-rank structure in health progression dynamics using canonical models and membership vectors can improve the upper regret bound compared to modeling the units independently which has the regret bound of $O(Np\sqrt{T}\ln{T})$ \cite{li2010contextual}. Second, when the similarity information is fully connected, i.e., $(f_\otimes)_{j,j} = N$, then $\phi_{T} = \frac{2NKT}{N+1}$. This leads to the upper regret bound of ${O(NK\sqrt{T}\ln{\frac{T}{N}})}$ for CL-UCB, indicating a decrease of $\frac{1}{N}$ when incorporating similarity information. Compared to the algorithm only using similarity information \cite{DBLP:journals/corr/Cesa-BianchiGZ13}, the proposed method exhibits a lower regret bound by utilizing the low-rank structure. 
%\scriptstyle 
%\subsection{Empirical Issues of Implementing the Algorithm}
%There are some empirical issues with implementing the algorithm. First, to estimate the unknown parameters in each cycle, in theory, we need to update the parameters for a large number of iterations in \textbf{Algorithm \ref{alg:alg1}} to guarantee convergence. However, the computational cost of \textbf{Algorithm \ref{alg:alg1}} can be high in practice. To save the computational costs, we can update the parameters with a smaller number of iterations in each cycle. Second, there are several tuning parameters, such as regularization parameters $\eta_1, \eta_2, \lambda$, and exploration parameters $\alpha^q, \alpha^{\Tilde{C}}$, that determine the effectiveness of the proposed method. In our experiment, to save computation costs and focus more on the effect of exploration parameters in different algorithms, we fix all regularization parameters and empirically tune $\alpha^q$ and $ \alpha^{\Tilde{C}}$ to obtain the algorithm performance. The selections of tuning parameters are based on the noisiness of the data and the complexity of the latent structure. If the data is noisy and the latent structure is complicated, the tuning parameters prefer high values since the bandit algorithm requires more exploration to gain information about units. However, the trade-off of increased exploration is that the cumulative regret is higher when the complexity of the latent structure is lower. %\yl{this sentence does not make sense}.  
%\yl{this is not clear. Why the regularization parameters do not need to be tuned? How to tune the $alpha$, based on what criteria? }
% % Figure environment removed
% %\yl{please improve the boxplot by 1) removing the background, 2) use different patterns to indicate different models (in case the publication is not printed in color), 3) enlarge the labels/titles and bold them}
% % Figure environment removed
% Figure environment removed
\section{Experiments}
The proposed algorithm is tested on a simulation study and a real-world study of the cognitive degradation monitoring of Alzheimer's Disease (AD). A cognitive measure, Mini-Mental State Examination (MMSE) \cite{arevalo2015mini}, is used as the outcome of cognitive monitoring ($y_{it}$). The second-order polynomial regression model with respect to time is used to describe the cognitive decline \cite{bartzokis2004heterogeneous}, i.e. $y_{it} = \beta_{i0} + \beta_{i1}t + \beta_{i2}t^2+\epsilon_{it}$. Both experiments continuously monitor a population of 100 patients ($N = 100$) over 30000 cycles ($T = 30000$). The population has three types of cognitive decline, which are the normal aging cognitive decline, mild cognitive impairment and AD \cite{MUELLER2005869}. Thus the number of canonical models are set at 3 ($K = 3$). Two scenarios are considered to evaluate the performance of monitoring algorithms: the high-constraint scenario which only monitors AD patients ($M = 33$) and the relaxed-constraint scenario which monitors both AD and mild cognitive impairment patients ($M = 66$).

The proposed algorithm (CL-UCB), the proposed algorithm without similarity regularization (CL-UCB w/o similarity), and two benchmark MAB algorithms are compared. The benchmark MAB algorithms include LinUCB \cite{li2010contextual}, which does not account for the dependency between processes and GOB.Lin \cite{DBLP:journals/corr/Cesa-BianchiGZ13}, which solely considers the similarities between processes. LinUCB estimates the coefficients in each polynomial regression model independently via L2-regularized least square estimation. GOB.Lin leverages the similarities between units in the parameter estimation through the graph Laplacian regularization. However, neither algorithm explicitly exploits the latent structure present in health progression. The cumulative regret defined in Eq.\ref{eq:13} is used to compare the performance of different monitoring algorithms in both simulation and real-world studies. In the simulation study, the L2-norm difference between estimated parameters and true parameters is also used to evaluate the model learning accuracy. 
\subsection{Simulation Studies}
In the simulation, 
%we consider the scenario of cognitive degradation monitoring of Alzheimer's Disease (AD). Specifically, we consider a common type of degradation model that uses the time or its polynomial basis functions as predictors to predict the cognitive status \cite{10.1093/cercor/bhh003, bartzokis2004heterogeneous}. The second-order polynomial function of time is employed to simulate the cognitive degradation dynamic of each unit. The feature vector $x_{it}$ for unit $i$ at a time point $t$ is presented as $x_{it} = [1, t, t^2]$. Thus, the underlying model for each unit $i$ is presented as $y_{it} = x_{it}\beta_i + \epsilon_{it}$ where $\epsilon_{it}$ is the Gaussian noise. 
the parameters in latent groups ($Q$) are estimated from a real-world Alzheimer's disease dataset to represent three types of cognitive degradation. To simulate the health progression dynamics of each unit from these latent groups using the relationship $\beta_i = Qc_i$, the membership vector of each unit ($c_i$) 
%needs to be simulated. Each membership vector consists of three elements, representing the differences among units. To ensure that the membership vectors can cluster the units into the three latent groups, they are 
is randomly generated from a mixture Gaussian distributions with three zero-mean components and their respective prior probabilities are estimated from the real data.
%\[ F_1(c) \sim N(0, \begin{bmatrix} \sigma^2 & 0 & 0\\ 0 & 1 & 0\\ 0 & 0 & 1 \end{bmatrix}), F_2(c) \sim N(0, \begin{bmatrix} 1 & 0 & 0\\ 0 & \sigma^2 & 0\\ 0 & 0 & 1 \end{bmatrix}), F_3(c) \sim N(0, \begin{bmatrix} 1 & 0 & 0\\ 0 & 1 & 0\\ 0 & 0 & \sigma^2 \end{bmatrix})\]
% \begin{align*}
% &\medmath{F_1(c)} \sim \medmath{N(0, \begin{bmatrix} \sigma^2 & 0 & 0\\ 0 & 1 & 0\\ 0 & 0 & 1 \end{bmatrix})},\medmath{F_2(c)} \sim \medmath{N(0, \begin{bmatrix} 1 & 0 & 0\\ 0 & \sigma^2 & 0\\ 0 & 0 & 1 \end{bmatrix}),} \notag\\
% &\medmath{F_3(c)} \sim \medmath{N(0, \begin{bmatrix} 1 & 0 & 0\\ 0 & 1 & 0\\ 0 & 0 & \sigma^2 \end{bmatrix})} \notag   
% \end{align*}
%Specifically, after simulation, all units are categorized into three groups: dementia group ($29\%$), mild cognitive impairment ($34\%$), and normal aging group ($37\%$). Then, we apply the selected distribution to generate a random sample which is further normalized to earn $c_i$. 
The covariance matrix in each component is a diagonal matrix with $k$th diagonal element equals to $\sigma^2$ and the other elements equal to 1. It controls the significance of low-rank canonical structure. A larger value of $\sigma^2$ indicates a more distinct difference between canonical models. In this experiment, we set $\sigma^2$ at 100 to simulate three distinct groups. The random noises are generated from a standard normal distribution. The similarities between patients are estimated by calculating the cosine similarity of their membership vectors, i.e. $w_{ij} = c_{i}^Tc_{j}$.  All hyperparameters are carefully tuned based on the cumulative regret. 
%\yl{add $M=$ in Figure 2 and 3 or their titles. move the legends within the figures to save space}
%$Q$ and 
%\yl{what is the initialization? The initialization of $Q$ and $c_i$ are randomly generated from a uniform distribution over $[0, 1)$.}
% Figure environment removed

The cumulative regrets of different monitoring algorithms under two scenarios are compared in Figure \ref{fig:fig2} a) and b). LinUCB algorithm exhibits the highest cumulative regret in both scenarios since it does not exploit the unit dependency. GOB.Lin algorithm achieves lower cumulative regret compared to LinUCB by leveraging the similarities between units. The proposed OCL algorithms outperform existing multi-armed bandit algorithms in both high-constraint and relaxed-constraint scenarios by explicitly capturing the latent group structure embedded in the population. By integrating the latent group structure and similarities between units, the OCL algorithm recommends better monitoring strategy compared to the one without similarity regularization. The difference is more significant in the relaxed-constraint scenario. This indicates that incorporating latent group structure and similarity information into the model yields the greatest performance improvement. The model learning accuracy (L2-norm difference) of different algorithms is summarized in Figure \ref{fig:fig2}c) and d). By exploiting the latent group structure and similarity between units, the proposed algorithms achieve more accurate estimation of model parameters and faster convergence compared to the existing multi-armed bandit algorithms.


%However, the proposed CL-UCB that does not integrate the similarity information among units either still gives comparable regret. This result shows that the factorization of $\beta_i$ regarded as $\beta_i = Qc_i$ improves the bandit algorithm performance by exploiting the latent structure of monitoring units. Regarding the integration of similarity information between units to the algorithm, even though both the proposed CL-UCB and GOB.Lin employ it, the proposed CL-UCB has less regret than GOB.Lin. This indicates that incorporating factorization and similarity information into the model yields the greatest performance improvement.


% %%% Sensitivity Analysis %%%
% To explore how the change of parameters affects the convergence performance of different bandit algorithms, we conduct sensitivity analysis on two scenarios including the number of bandit sizes ($N$) and the number of latent structures ($K$) which are shown in Figure \ref{fig:box1} and Figure \ref{fig:box2}. Figure \ref{fig:box1} illustrates the cumulative regret on different $N$ values. It shows that the regret in LinUCB goes linearly since it does not consider dependency between units. Even though GOB.Lin attains some regret reduction compared with LinUCB because it considers dependency between units, the regret still increases linearly with the number of units. The proposed CL-UCB and CL-UCB without similarity regularization achieve regret reduction compared with LinUCB and GOB.Lin, which indicates their robustness with respect to the value of $N$. Figure \ref{fig:box2} illustrates the cumulative regret on different $K$ values. It showcases that CL-UCB has the least cumulative regret among other bandit algorithms for all cases of $K$. Even though its cumulative regret does not differ much from the one without similarity regularization, in the case of $K = 5$, it has a lower median which suggests stable performance when the latent structure is more complex.   
% %%% Sensitivity Analysis %%%

\subsection{Application to cognitive degradation monitoring of Alzheimer's Disease (AD)}
The effectiveness of the proposed algorithm is further demonstrated through 100 real-world patients acquired from Alzheimer's Disease Neuroimaging Initiative (ADNI) \cite{MUELLER2005869}. The dataset consists of longitudinal measurements of MMSE for 648 units. They are collected at baseline, $12^{th}, 24^{th}, 36^{th}, 48^{th}$, and $60^{th}$ month. Missing MMSE values for each unit are imputed using linear interpolation. In addition to MMSE measurements, baseline measurements of risk factors such as ApoE genotypes and regional brain volume measurements extracted from MRI \cite{MUELLER2005869} are used to calculate the similarity between subjects, using the heat kernel method. The measurement collected from baseline to $60^{th}$ month period is equally divided into 30000 cycles. 

The cumulative regrets of different monitoring algorithms under two scenarios are compared in Figure \ref{fig:fig3}. It can be observed that LinUCB and GOB.Lin exhibit higher cumulative regret than the proposed algorithms in high-constraint scenario, suggesting that leveraging the latent structure of monitoring units effectively improves the accuracy of monitoring AD patients. CL-UCB has lower regret than CL-UCB without similarity regularization, indicating that incorporating both latent structure and similarity information into the model yields the best monitoring strategy for AD patients. Furthermore, the observations are consistent in the relaxed-constraint scenario which informs the efficiency of the proposed algorithms in monitoring both mild cognitive impairment and AD patients.
\section{Conclusion}
This paper introduces an Online Collaborative Learning (OCL) framework to adaptively allocate limited resources by modeling the dynamic health progression of dependent units and monitoring the high-risk ones. We develop a novel collaborative learning-based upper confidence bound (CL-UCB) algorithm to find an optimal monitoring strategy that balances the rewards of monitoring high-risk units (exploitation) with the uncertainty of the predicted health condition of unknown units (exploration). We present a regret analysis to prove a reduced upper regret bound compared to other benchmark models. Simulation studies and an empirical study of adaptive cognitive monitoring in Alzheimer’s disease demonstrate the efficiency of our proposed method as it achieves the lowest cumulative regret and highest learning accuracy compared to other benchmark models. 

%In future work, we aim to develop an online collaborative learning framework that captures more complex latent structures and non-linear health progression. Furthermore, to further enhance resource allocation, we plan to develop an algorithm that dynamically selects processes instead of fixing the number of monitoring processes for each time period.





%\section*{Acknowledgments}
%TBD

%{\appendices
%\section*{Proof of the First Zonklar Equation}
%Appendix one text goes here.
% You can choose not to have a title for an appendix if you want by leaving the argument blank
%\section*{Proof of the Second Zonklar Equation}
%Appendix two text goes here.}
 % argument is your BibTeX string definitions and bibliography database(s)
%\bibliography{IEEEabrv,../bib/paper}
%

\bibliographystyle{IEEEtran}
\bibliography{References}

\begin{comment}
\section{Appendix}

\textbf{Proof of the alternating least square algorithm:}
\begin{proof}
%%%%%%%%%proof closed-form q%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
For $q$, let $L_1 = \sum_{t=1}^{T} \left\| C^TX_{t}^Tq - y_{t} \right\|^{2} + \eta_1 \Vert q\Vert_2^2$, the partial derivative of $L_1$ with respect to $q$ is 
\[\frac{\partial L_1}{\partial q} = 2 \sum_{t = 1}^{T} X_{t}C(C^TX_{t}^Tq - y_{t}) + 2\eta_1 q\]

Setting the left-hand side to zero, the equation above is arranged to be
\begin{align*}
    0 &= \sum_{t = 1}^{T} X_{t}C_(C^TX_{t}^Tq - y_{t}) + \eta_1 q\\
    0 &= \sum_{t = 1}^{T} (X_{t}CC^TX_{t}^T + \eta_1 I_{Kp})q - \sum_{t = 1}^{T}  X_{t}Cy_{t}\\
    \sum_{t = 1}^{T}  X_{t}Cy_{t} &=   \sum_{t = 1}^{T} (X_{t}CC^TX_{t}^T  + \eta_1 I_{Kp})q
\end{align*}
where $I_{Kp}$ is the identity matrix with the dimension of $Kp \times Kp$. The closed-form estimation of $\hat{q_{t}}$ with respect to the objective function above can be obtained by $\hat{q_t} = A_t^{-1} b_t$ where the calculation of $A_t$ and $b_t$ are computed as:
\begin{align*}
    A_t ={}& \sum_{t^{\prime} = 1}^{t} X_{t^{\prime}}C_{t^{\prime}}C_{t^{\prime}}^TX_{t^{\prime}}^T  + \eta_1 I_{Kp} \\
    b_t ={}& \sum_{t^{\prime} = 1}^{t} X_{t^{\prime}}C_{t^{\prime}}y_{t^{\prime}}
\end{align*}
%%%%%%%%%proof closed-form C%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
For $\Tilde{C}$, let $L_2 = \sum_{t=1}^{T} \left\| \Tilde{X_{t}}^T\Tilde{C} - y_{t} \right\|^{2} + \eta_2\Vert \Tilde{C} \Vert_2^2$, the partial derivative of $L_2$ with respect to $\Tilde{C}$ is
\[\frac{\partial L_2}{\partial \Tilde{C}} = 2\sum_{t=1}^{T} \Tilde{X_{t}}(\Tilde{X_{t}}^T\Tilde{C} - y_{t}) + 2\eta_2\Tilde{C}\]

Setting the left-hand side to zero, the equation above is arranged to be
\begin{align*}
    0 &= \sum_{t=1}^{T} \Tilde{X_{t}}(\Tilde{X_{t}}^T\Tilde{C} - y_{t}) + \eta_2\Tilde{C}\\
    \sum_{t=1}^{T} \Tilde{X_{t}} y_{t} &= (\sum_{t=1}^{T} \Tilde{X_{t}}\Tilde{X_{t}}^T + \eta_2I_{NK})\Tilde{C}  
\end{align*}
where $I_{NK}$ is the identity matrix with the dimension of $NK \times NK$. The closed-form estimation of $\Tilde{C}$ with respect to the objective function above can be obtained by $\Tilde{C_t} = D_t^{-1} d_t$ where the calculation of $D_t$ and $d_t$ are computed as:
\begin{align*}
    D_t ={}& \sum_{t^{\prime}=1}^{t} \Tilde{X_{t^{\prime}}}\Tilde{X_{t^{\prime}}^T} + \eta_2I_{NK} \\
    d_t ={}& \sum_{t^{\prime}=1}^{t} \Tilde{X_{t^{\prime}}} y_{t^{\prime}}
\end{align*}
\end{proof}
%%%%%%%%%%%%%%%%%%%%%%%%%Proof of Theorem 1%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\textbf{Proof of Lemma 1:}
\begin{proof}
%%%%%%%%%%%%%%%% Lemma 1q %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
For $q$, when $\Vert q_t\Vert_2 \leq L$ and $\Vert X_tC_t\Vert_2 \leq \Vert X_t\Vert_2 \Vert C_t\Vert_2 \leq SP$,
\begin{align*}
    A_t(\hat{q_t} - q^*) ={}& A_t(A_t^{-1}b_t) - A_tq^*  \\
    ={}& b_t - A_tq^*\\
    ={}& \sum_{t^{\prime} = 1}^{t} X_{t^{\prime}}C_{t^{\prime}}y_{t^{\prime}} -(\sum_{t^{\prime} = 1}^{t} X_{t^{\prime}}C_{t^{\prime}}C_{t^{\prime}}^TX_{t^{\prime}}^T  + \eta_1 I_{kp})q^*\\
    ={}& \sum_{t^{\prime} = 1}^{t} X_{t^{\prime}}C_{t^{\prime}}(C_{t^{\prime}}^TX_{t^{\prime}}^T\hat{q_{t^{\prime}}} + \epsilon) -\sum_{t^{\prime} = 1}^{t} X_{t^{\prime}}C_{t^{\prime}}C_{t^{\prime}}^TX_{t^{\prime}}^T q^* \\
    -& \eta_1 q^* \\
    ={}& \sum_{t^{\prime} = 1}^{t} X_{t^{\prime}}C_{t^{\prime}} \epsilon  + \sum_{t^{\prime} = 1}^{t} X_{t^{\prime}}C_{t^{\prime}}C_{t^{\prime}}^TX_{t^{\prime}}^T(\hat{q_{t^{\prime}}} - q^*) - \eta_1 q^*
\end{align*}
in which $\epsilon$ is the Gaussian noise in reward generation. The function norm of $\hat{q_t} - q^*$ is bounded by
\begin{align*}
    \Vert\hat{q_t} - q^*\Vert_{A_t} ={}& \Vert \sum_{t^{\prime} = 1}^{t} X_{t^{\prime}}C_{t^{\prime}}  \epsilon  + \sum_{t^{\prime} = 1}^{t} X_{t^{\prime}}C_{t^{\prime}}C_{t^{\prime}}^TX_{t^{\prime}}^T (\hat{q_{t^{\prime}}} - q^*) \\
    -& \eta_1 q^* \Vert_{A_t^{-1}} \\
    \leq{}& \Vert \sum_{t^{\prime} = 1}^{t} X_{t^{\prime}}C_{t^{\prime}} \epsilon \Vert_{A_t^{-1}} + \Vert \eta_1 q^* \Vert_{A_t^{-1}}\\
    +& \Vert \sum_{t^{\prime} = 1}^{t} X_{t^{\prime}}C_{t^{\prime}}C_{t^{\prime}}^TX_{t^{\prime}}^T(\hat{q_{t^{\prime}}}- q^*)  \Vert_{A_t^{-1}}  \\
    \leq{}& \Vert \sum_{t^{\prime} = 1}^{t} X_{t^{\prime}}C_{t^{\prime}}  \epsilon \Vert_{A_t^{-1}} + \frac{SP}{\sqrt{\eta_1}}\sum_{t^{\prime} = 1}^{t}\Vert\hat{q_{t^{\prime}}} - q^*\Vert_2 \\
    +& \sqrt{\eta_1}L
\end{align*}
where the first term on the right-hand side of the inequality is bounded by the property of Theorem 1 in \cite{NIPS2011_e1d5be1c}. The second term follows the $q$-linear convergence as in \cite{10.1145/2983323.2983847}. For every $\epsilon_1 > 0$, $\Vert\hat{q_{t+1}} - q^*\Vert_2 \leq (q_1 + \epsilon_1)\Vert\hat{q_t} - q^*\Vert_2 $ Thus, for any $\delta > 0$, with probability at least $1 - \delta$, 
\begin{align*}
    \Vert\hat{q_t} - q^*\Vert_{A_t} \leq& \sqrt{2\ln(\frac{\det(A_t)^{1/2}\det(\eta_1I)^{-1}}{\delta})}  \\
    +& \frac{2SPL}{\sqrt{\eta_1}}\frac{(q_1+\epsilon_1)(1-(q_1+\epsilon_1)^t)}{1-(q_1+\epsilon_1)} + \sqrt{\eta_1}L
\end{align*}
%\[\Vert\hat{q_t} - q^*\Vert_{A_t} \leq \sqrt{2\ln(\frac{\det(A_t)^{1/2}\det(\eta_1I)^{-1}}{\delta})}  + \frac{2SPL}{\sqrt{\eta_1}}\frac{(q_1+\epsilon_1)(1-(q_1+\epsilon_1)^t)}{1-(q_1+\epsilon_1)} + \sqrt{\eta_1}L\]

Since $\operatorname{Tr}(A_t) \leq \eta_1Kp + \sum_{t^{\prime} = 1}^{t}\operatorname{Tr}(X_{t^{\prime}}C_{t^{\prime}}(X_{t^{\prime}}C_{t^{\prime}})^T) \leq \eta_1Kp + \sum_{t^{\prime} = 1}^{t}\Vert X_{t^{\prime}}\Vert_2^{2} \Vert C_{t^{\prime}}\Vert_2^{2} \leq \eta_1Kp + tS^2P^2$, then $\det(A_t) \leq (\frac{\operatorname{Tr}(X_{t^{\prime}}C_{t^{\prime}})}{Kp})^{Kp} \leq (\eta_1 + \frac{tS^2P^2}{Kp})^{Kp}$ and $\det(\eta_1I) \leq \eta_1^{Kp}$. Putting all terms into the equation above, we have

\begin{align*}
    \Vert\hat{q_t} - q^*\Vert_{A_t} \leq& \sqrt{Kp\ln(\frac{\eta_1 Kp + tS^2P^2}{\eta_1 Kp\delta})} \\ 
    +& \frac{2SPL}{\sqrt{\eta_1}}\frac{(q_1+\epsilon_1)(1-(q_1+\epsilon_1)^t)}{1-(q_1+\epsilon_1)} + \sqrt{\eta_1}L
\end{align*}
%\[\Vert\hat{q_t} - q^*\Vert_{A_t} \leq \sqrt{Kp\ln(\frac{\eta_1 Kp + tS^2P^2}{\eta_1 Kp\delta})}  + \frac{2SPL}{\sqrt{\eta_1}}\frac{(q_1+\epsilon_1)(1-(q_1+\epsilon_1)^t)}{1-(q_1+\epsilon_1)} + \sqrt{\eta_1}L\]

%%%%%%%%%%%%%%%% Lemma 1C %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

For $\Tilde{C}$, 
%when $\Vert \Tilde{C_t}\Vert_2 \leq M$ and $\Vert \Tilde{X_{t}}\Vert_2 \leq P$,
\begin{align*}
    D_t(\hat{\Tilde{C_t}} - \Tilde{C^*}) ={}& D_t(D_t^{-1}d_t) - D_t\Tilde{C^*} \\
    ={}& d_t - D_t\Tilde{C^*}\\
    ={}& \sum_{t^{\prime}=1}^{t} \Tilde{X_{t^{\prime}}} y_{t^{\prime}} - (\sum_{t=1^{\prime}}^{t} \Tilde{X_{t^{\prime}}}\Tilde{X^T_{t^{\prime}}} + I_{NK})\Tilde{C^*}\\   
    ={}& \sum_{t^{\prime}=1}^{t} \Tilde{X_{t^{\prime}}}\epsilon + \sum_{t^{\prime}=1}^{t} \Tilde{X_{t^{\prime}}}\Tilde{X^T_{t^{\prime}}}(\hat{\Tilde{C_{t^{\prime}}}} - \Tilde{C^*}) -\Tilde{C^*}   
\end{align*}
in which $\epsilon$ is the Gaussian noise in reward generation. The function norm of $\hat{\Tilde{C_t}} - \Tilde{C^*}$ is bounded by
\begin{align*}
        \Vert\hat{\Tilde{C_t}} - \Tilde{C^*}\Vert_{D_t} 
        ={}& \Vert \sum_{t^{\prime}=1}^{t} \Tilde{X_{t^{\prime}}}\epsilon + \sum_{t^{\prime}=1}^{t} \Tilde{X_{t^{\prime}}}\Tilde{X^T_{t^{\prime}}}(\hat{\Tilde{C_{t^{\prime}}}} - \Tilde{C^*}) -\Tilde{C^*} \Vert_{D_t^{-1}} \\
        \leq{}& \Vert\sum_{t^{\prime}=1}^{t} \Tilde{X_{t^{\prime}}}\epsilon\Vert_{D_t^{-1}} + \Vert \sum_{t^{\prime}=1}^{t} \Tilde{X_{t^{\prime}}}\Tilde{X^T_{t^{\prime}}}(\hat{\Tilde{C_{t^{\prime}}}} - \Tilde{C^*})\Vert_{D_t^{-1}} \\
        +& \Vert\Tilde{C^*}\Vert_{D_t^{-1}} \\
        \leq{}& \Vert \sum_{t^{\prime}=1}^{t}  \Tilde{X_{t^{\prime}}}\epsilon\Vert_{D_t^{-1}} + \frac{P}{\sqrt{\eta_2}}\sum_{t^{\prime}=1}^{t} \Vert\hat{\Tilde{C_{t^{\prime}}}} - \Tilde{C^*}\Vert_2 \\
        +& \Vert\Tilde{C^*}\Vert_{D_t^{-1}}
\end{align*}
where the first term on the right-hand side of the inequality is bounded by the property of Theorem 1 in \cite{NIPS2011_e1d5be1c}. The second term follows the $q$-linear convergence as in \cite{10.1145/2983323.2983847}. For every $\epsilon_1 > 0$, $\Vert\hat{\Tilde{C_{t+1}}} - \Tilde{C^*}\Vert_2 \leq (q_2 + \epsilon_2)\Vert\hat{\Tilde{C_t}} - \Tilde{C^*}\Vert_2 $. The third term is based on $\Vert \Tilde{C} \Vert = \Tilde{C}^T F \Tilde{C} = L(c_1,\ldots,c_n)$. Thus, for any $\delta > 0$, with probability at least $1 - \delta$,
\begin{align*}
    \Vert\hat{\Tilde{C_t}} - \Tilde{C^*}\Vert_{D_t} \leq{}& \sqrt{2\ln(\frac{\det(D_t)^{1/2}\det(\eta_1I)^{-1}}{\delta})} \\
    +& \frac{2SPL}{\sqrt{\eta_2}}\frac{(q_2+\epsilon_2)(1-(q_2+\epsilon_2)^t)}{1-(q_2+\epsilon_2)} + L(c_1,\ldots,c_n)
\end{align*}
%\[ \Vert\hat{\Tilde{C_t}} - \Tilde{C^*}\Vert_{D_t} \leq{} \sqrt{2\ln(\frac{\det(D_t)^{1/2}\det(\eta_1I)^{-1}}{\delta})} + \frac{2SPL}{\sqrt{\eta_2}}\frac{(q_2+\epsilon_2)(1-(q_2+\epsilon_2)^t)}{1-(q_2+\epsilon_2)} + L(c_1,\ldots,c_n) \] 

%\arty{$\Tilde{X_{t}} = F_\otimes^{-1/2}X_{t,i}^{T}\hat{q_{t}}$ and $\Tilde{X_{t}}\Tilde{X_{t}^T} = F_\otimes^{-1} X_{t,i}^{T} q_tq_t^{T} X_{t,i}$}

Since $\operatorname{Tr}(D_t) \leq \eta_2NK + \sum_{t^{\prime} = 1}^{t}\operatorname{Tr}(\Tilde{X_{t^{\prime}}}\Tilde{X^T_{t^{\prime}}}) \leq \eta_2NK + \sum_{t^{\prime} = 1}^{t}\operatorname{Tr} (F_\otimes^{-1}) \Vert q_{t^{\prime}}\Vert_2^{2} \Vert X_{t^{\prime}}\Vert_2^{2} \leq \eta_2NK + S^2L^2 \sum_{t^{\prime} = 1}^{t} \sum_{j = 1}^{NK} (f^{-1}_\otimes)_{j,j}$ where $(f^{-1}_\otimes)_{j,j}$ is the $(j, j)^{th}$ element of the inverse of $F_\otimes$, then we have $\det(D_t) \leq (\eta_2 + \frac{\operatorname{Tr}(\Tilde{X_{t^{\prime}}}\Tilde{X^T_{t^{\prime}}})}{NK})^{NK} \leq (\eta_2 + \frac{S^2L^2 \sum_{t^{\prime} = 1}^{t} \sum_{j = 1}^{NK} (f^{-1}_\otimes)_{j,j}}{NK})^{NK}$ and $\det(\eta_2I) \leq \eta_2^{NK}$. Putting all terms into the equation above, we have
\begin{align*}
    \Vert\hat{\Tilde{C_t}} - \Tilde{C^*}\Vert_{D_t} \leq{}& \sqrt{NK\ln(\frac{\eta_2NK + S^2L^2 \sum_{t^{\prime} = 1}^{t} \sum_{j = 1}^{NK} (f^{-1}_\otimes)_{j,j}}{\eta_2 NK\delta})} \\
    +& \frac{2SPL}{\sqrt{\eta_2}}\frac{(q_2+\epsilon_2)(1-(q_2+\epsilon_2)^t)}{1-(q_2+\epsilon_2)} + L(c_1,\ldots,c_n)
\end{align*}
%\[ \Vert\hat{\Tilde{C_t}} - \Tilde{C^*}\Vert_{D_t} \leq{} \sqrt{NK\ln(\frac{\eta_2NK + S^2L^2 \sum_{t^{\prime} = 1}^{t} \sum_{j = 1}^{NK} (f^{-1}_\otimes)_{j,j}}{\eta_2 NK\delta})} + \frac{2SPL}{\sqrt{\eta_2}}\frac{(q_2+\epsilon_2)(1-(q_2+\epsilon_2)^t)}{1-(q_2+\epsilon_2)} + L(c_1,\ldots,c_n) \] 

\end{proof}

%%%%%%%%%%%%%%%%%%%%%%%%%Proof of Theorem 1%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\textbf{Proof of Theorem 1:}
\begin{proof}
Similar to $y_t$ in Equation \ref{eq:3} in Step 1 of Section \ref{sub3.4}, for each unit $i$, we define its health condition as $y_{t,i} = C^{\prime T}X_{t,i}^{T}q$ where $\Tilde{C} = F_\otimes^{1/2} C^{\prime}$ as mentioned in Step 2 of Section \ref{sub3.4}, $q \in \mathbb{R}^{Kp \times 1}$ is the concatenation of columns of $Q$, and $X_{t,i}$ is defined as the special case of $X_{t}$ where all other elements that are not $x_{t,i}$ are set to zero. Since $\Tilde{C} = F_\otimes^{1/2} C^{\prime}$, we can rewrite $y_{t,i}$ as

\[y_{t,i} = C^{\prime T}X_{t,i}^{T}q = C^{\prime T} F_\otimes^{1/2} F_\otimes^{-1/2} X_{t,i}^{T}q = \Tilde{C}F_\otimes^{-1/2} X_{t,i}^{T}q\]

According to the regret ($R_{t,i}$) in Equation \ref{eq:13}, because $a_{t,i} = 1$ for the selected unit $i$ at time $t$, the regret for each unit $i$ can be written as, 
%\huazheng{$y_{t}^* - \hat{y_{t}}$ is vector, not scalar. This is the reason your line 6 in Alg 1 is wrong.}
\begin{align*}
    R_{t,i} ={}& r_{t,i}^* - r_{t,i} \\
    ={}& y_{t,i}^* - y_{t,i} \\
    ={}& C^{\prime*T}X_{t,i^*}^{T}q^* - C^{*T}X_{t,i}^{T}q^* \\
    \leq{}& \hat{C_t}^{\prime T}X_{t,i^*}^{T}\hat{q_{t}} + \alpha^{\Tilde{C}} \Vert F_\otimes^{-1/2}X_{t,i^*}^{T}\hat{q_{t}} \Vert_{D_{t}^{-1}} \\
    +& \alpha^q \Vert \hat{C_t}^{\prime T}X_{t,i^*}^{T} \Vert_{A_{t}^{-1}} - C^{*T}X_{t,i}^{T}q^* \\
    \leq{}& \hat{C_t}^{\prime T}X_{t,i}^{T}\hat{q_{t}} + \alpha^{\Tilde{C}} \Vert F_\otimes^{-1/2}X_{t,i}^{T}\hat{q_{t}} \Vert_{D_{t}^{-1}} \\
    +& \alpha^q \Vert \hat{C_t}^{\prime T}X_{t,i}^{T} \Vert_{A_{t}^{-1}} - C^{*T}X_{t,i}^{T}q^* \\
    \leq{}&  2\alpha^{\Tilde{C}} \Vert F_\otimes^{-1/2}X_{t,i}^{T}\hat{q_{t}} \Vert_{D_{t}^{-1}} + 2\alpha^q \Vert \hat{C_t}^{\prime T}X_{t,i}^{T} \Vert_{A_{t}^{-1}} + 2q^{2t}
\end{align*}
The first inequality is due to the definition of the UCB algorithm and the second inequality is due to the UCB arm selection strategy. The third inequality is based on the following.
\begin{align*}
    &\hat{C_t}^{\prime T}X_{t,i}^{T}\hat{q_{t}} - C^{*T}X_{t,i}^{T}q^* \\
    ={}&  \hat{C_t}^{\prime T}X_{t,i}^{T}\hat{q_{t}}  - \hat{C_t}^{\prime T}X_{t,i}^{T}q^* + \hat{C_t}^{\prime T}X_{t,i}^{T}q^* - C^{*T}X_{t,i}^{T}q^* \\
    ={}& \hat{C_t}^{\prime T}X_{t,i}^{T}(\hat{q_{t}} - q^*) + (\hat{C_t}^{\prime} - C^{*T})X_{t,i}^{T}q^*\\ 
    ={}& \hat{C_t}^{\prime T}X_{t,i}^{T}(\hat{q_{t}} - q^*) + (\hat{C_t}^{\prime} - C^{*T})X_{t,i}^{T}\hat{q_{t}} \\
    -& (\hat{C_t}^{\prime} - C^{*T})X_{t,i}^{T}\hat{q_{t}} + (\hat{C_t}^{\prime} - C^{*T})X_{t,i}^{T}q^*\\
    ={}& \hat{C_t}^{\prime T}X_{t,i}^{T}(\hat{q_{t}} - q^*) + (\hat{C_t}^{\prime} - C^{*T})X_{t,i}^{T}\hat{q_{t}} \\
    +& (\hat{C_t}^{\prime} - C^{*T})X_{t,i}^{T}(q^* - \hat{q_{t}}) 
\end{align*}
By Cauchy Schwarz’s Inequality,
\begin{align*}
   \leq{}& \Vert \hat{C_t}^{\prime T}X_{t,i}^{T} \Vert \Vert \hat{q_{t}} - q^* \Vert + \Vert \hat{C_t}^{\prime}- C^{*T} \Vert \Vert X_{t,i}^{T}\hat{q_{t}} \Vert \\
   +{}& \Vert \hat{C_t}^{\prime}- C^{*T} \Vert  \Vert X_{t,i}^{T} \Vert \Vert q^* - \hat{q_{t}} \Vert \\ 
    \leq{}& \Vert \hat{C_t}^{\prime T}X_{t,i}^{T} \Vert_{A_{t}^{-1}} \Vert \hat{q_{t}} - q^* \Vert_{A_{t}} + \Vert \hat{\Tilde{C_t}} - \Tilde{C^*}\Vert_{D_t} \Vert F_\otimes^{-1/2} X_{t,i}^{T}\hat{q_{t}} \Vert_{D_{t}^{-1}} \\
    +{}& \Vert \hat{C_t}^{\prime}- C^{*T} \Vert  \Vert X_{t,i}^{T} \Vert \Vert q^* - \hat{q_{t}} \Vert
\end{align*}
From the proof on \ref{lemma1}, $\Vert\hat{\Tilde{C_t}} - \Tilde{C^*}\Vert_{D_t} \leq \alpha^{\Tilde{C}}$ and $\Vert\hat{q_t} - q^*\Vert_{A_t} \leq \alpha^q$. Thus,
\begin{multline}
    \hat{C_t}^{\prime T}X_{t,i}^{T}\hat{q_{t}} - C^{*T}X_{t,i}^{T}q^* \\
    \leq{} \alpha^q \Vert \hat{C_t}^{\prime T}X_{t,i}^{T} \Vert_{A_{t}^{-1}} + \alpha^{\Tilde{C}} \Vert F_\otimes^{-1/2} X_{t,i}^{T}\hat{q_{t}} \Vert_{D_{t}^{-1}} + 2q^{2t} \notag
\end{multline}
in which $q$ is a constant in the range of $(0, 1)$, and the third term is based on the $q$-linear convergence rate of parameter estimation and the proof of Lemma 3.3 in \cite{10.1145/3292500.3330874}. 

The accumulated regret ($R(T) = \sum_{t=1}^{T} \sum_{i \in S_t} R_{t, i}$) of the CL-UCB algorithm at time $T$ is derived as, 
\begin{align} 
    R(T) ={}& \alpha^{\Tilde{C}} \sum_{t=1}^{T} \sum_{i \in S_t} \Vert F_\otimes^{-1/2} X_{t,i}^{T}\hat{q_{t}} \Vert_{D_{t}^{-1}} \notag \\
    +{}&  \alpha^q \sum_{t=1}^{T} \sum_{i \in S_t}\Vert \hat{C_{t}^{T}}X_{t,i}^{T} \Vert_{A_{t}^{-1}} + \sum_{t=1}^{T} \sum_{i \in S_t} 2q^{2t} \notag \\
    \leq{}& \sqrt{T (\alpha^{\Tilde{C}})^2 \sum_{t=1}^{T} \sum_{i \in S_t}\Vert F_\otimes^{-1/2}X_{t,i}^{T}\hat{q_{t}} \Vert_{D_{t}^{-1}}^2} \notag \\
    +{}& \sqrt{T (\alpha^q)^2 \sum_{t=1}^{T} \sum_{i \in S_t} \Vert \hat{C_{t}^{T}}X_{t,i}^{T} \Vert_{A_{t}^{-1}}^2} + \sum_{t=1}^{T} \sum_{i \in S_t} 2q^{2t} \label{eq:14}
\end{align}
Based on Lemma 11 in \cite{NIPS2011_e1d5be1c} and \cite{qin2014contextual}, the first and second terms in the above inequality can be bounded by,
\begin{align}
    &\sqrt{T (\alpha^{\Tilde{C}})^2 \sum_{t=1}^{T} \sum_{i \in S_t}\Vert F_\otimes^{-1/2}X_{t,i}^{T}\hat{q_{t}} \Vert_{D_{t}^{-1}}^2} \notag\\
    &+ \sqrt{T (\alpha^q)^2 \sum_{t=1}^{T} \sum_{i \in S_t} \Vert \hat{C_{t}^{T}}X_{t,i}^{T} \Vert_{A_{t}^{-1}}^2} \notag\\
    &\leq \alpha^{\Tilde{C}}\sqrt{2T\ln{(1 + \frac{\det(D_t)}{\det(\eta_2I)})}} + \alpha^q\sqrt{2TKp\ln{(1 + \frac{\det(A_t)}{\det(\eta_1I)})}}\notag \\
    &\leq \alpha^{\Tilde{C}}\sqrt{2TNK\ln{(1 + \frac{TP^2}{\eta_2NK})}} + \alpha^q\sqrt{2TKp\ln{(1 + \frac{TS^2}{\eta_1 Kp})}} \label{eq:15}
\end{align}
%\at{Because the inequality $(a + b)^2 \leq 2a^2 + 2b^2$ and when $a = \sqrt{NK\ln{(\frac{NK + TmP}{NK})}}$ and $b = \Vert \tilde{C}\Vert = \sqrt{L(c_1,\ldots, c_n)}$,}
%\begin{multline}
%    \leq 2\alpha^{\Tilde{C}}\sqrt{2T(NK\ln{(\frac{NK + tmP}{NK})}
%    + L(c_1,\ldots,c_n))}  \\
%    + 2\alpha^q\sqrt{2TKp\ln{(\frac{\eta_1 Kp + TmS}{\eta_1 Kp})}} \notag
%\end{multline}

The third term is calculated to be
\begin{align} \label{eq:16}
     \sum_{t=1}^{T} \sum_{i \in S_t} 2q^{2t} = \frac{2mq^2(1-q^{2T})}{1-q^2} 
\end{align}
Putting Equation \ref{eq:16} and \ref{eq:15} together in Equation \ref{eq:14}, the regret bound of OCL is bounded by,
\begin{align*}
    R(T) &\leq \alpha^{\Tilde{C}}\sqrt{2TNK\ln{(1 + \frac{TP^2}{\eta_2NK})}} + \alpha^q\sqrt{2TKp\ln{(1 + \frac{TS^2}{\eta_1 Kp})}} \\
    &+ \frac{2mq^2(1-q^{2T})}{1-q^2} \\
\end{align*}

\end{proof}
%\at{$(\Vert \Tilde{X_{t}}\Vert_2 \leq P)\\ \det(D_t) \leq (\frac{\operatorname{Tr}(D_t)}{\eta_2NK})^{NK} \\ \leq (\frac{\eta_2NK + \sum_{t^{\prime}=1}^{t} \operatorname{Tr} (\Tilde{X_{t^{\prime}}}\Tilde{X_{t^{\prime}}^T})}{\eta_2NK})^{NK} \\ \leq (\frac{\eta_2NK + \sum_{t^{\prime}=1}^{t}\Vert \Tilde{X_{t^{\prime}}}\Vert^2_2}{\eta_2NK})^{NK}$.}
\end{comment}

\vfill


\end{document}


