\documentclass[10pt,letterpaper]{article}
\usepackage[top=0.85in,left=2.75in,footskip=0.75in,marginparwidth=2in]{geometry}

% use Unicode characters - try changing the option if you run into troubles with special characters (e.g. umlauts)
\usepackage[utf8]{inputenc}

%preamble from ACDC
\usepackage{mathpazo}
\usepackage{times}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{latexsym}
\usepackage{amssymb}
\usepackage{mathabx}
\usepackage{float}
\usepackage{upref}
\usepackage{theorem}
\usepackage{graphicx}
\usepackage{psfrag}
\usepackage{cite}
\usepackage{multirow}
\usepackage{enumerate}
\usepackage{enumitem}
\usepackage{algpseudocode}

\usepackage{mdframed}
\usepackage{mathtools}

%\usepackage{appendix}
%\usepackage[hidelinks,draft]{hyperref}
\usepackage[hidelinks]{hyperref}
\usepackage{graphicx,subfig}
%\usepackage{caption}
\usepackage[T1]{fontenc}
%\usepackage[margin=1in]{geometry}
\usepackage{wrapfig}
%\usepackage{floatrow}
\usepackage[font=footnotesize,labelfont=bf]{caption}
\usepackage{soul}
\usepackage{times}

\usepackage{color}
\usepackage{algorithm,algpseudocode}


\newcommand{\Bin}{\mathsf{Bin}}
\newcommand{\eps}{\epsilon}
%----------------- Various Style Definitions -----------------------------
\hbadness = 10000
\vbadness = 6000
\hfuzz = 2pt
%------------------ Various \newtheorem Declarations -------------------
\theoremstyle{plain}
\theorembodyfont{\normalfont\slshape}
\newtheorem{thm}{Theorem$\!$}
\newenvironment{theorem}
{\begin{thm}\hspace*{-1ex}{\bf.}}{\end{thm}}

\newtheorem{clm}[thm]{Claim$\!$}
\newenvironment{claim}{\begin{clm}\hspace*{-1ex}{\bf.}}{\end{clm}}

\newtheorem{lem}[thm]{Lemma$\!$}
\newenvironment{lemma}{\begin{lem}\hspace*{-1ex}{\bf.}}{\end{lem}}

\newtheorem{prop}[thm]{Proposition$\!$}
\newenvironment{proposition}{\begin{prop}\hspace*{-1ex}{\bf.}}{\end{prop}}

\newtheorem{cor}[thm]{Corollary$\!$}
\newenvironment{corollary}{\begin{cor}\hspace*{-1ex}{\bf.}}{\end{cor}}

\newtheorem{defn}[thm]{Definition$\!$}
\newenvironment{definition}{\begin{defn}\hspace*{-1ex}{\bf.}}{\end{defn}}

\newtheorem{xmpl}[thm]{Example$\!$}
\newenvironment{example}{\begin{xmpl}\hspace*{-1ex}{\bf.}}{\hfill $\Box$ \end{xmpl}}

\newtheorem{cnstr}{Construction$\!$}
\newenvironment{construction}{\begin{cnstr}\hspace*{-1ex}{\bf.}}{\end{cnstr}}

\newtheorem{rmk}[thm]{Remark$\!$}
\newenvironment{remark}{\begin{rmk}\hspace*{-1ex}{\bf.}}{\end{rmk}}

\setlength\theorempreskipamount{5pt plus 5pt minus 3pt}
\setlength\theorempostskipamount{5pt plus 3pt minus 1.5pt}

%--------------- Calligraphy \newcommand Declarations -------------------

\newcommand{\cA}{\mathcal{A}}
\newcommand{\cB}{\mathcal{B}}
\newcommand{\cC}{\mathcal{C}}
\newcommand{\cD}{\mathcal{D}}
\newcommand{\cE}{\mathcal{E}}
\newcommand{\cF}{\mathcal{F}}
\newcommand{\cG}{\mathcal{G}}
\newcommand{\cH}{\mathcal{H}}
\newcommand{\cI}{\mathcal{I}}
\newcommand{\cJ}{\mathcal{J}}
\newcommand{\cK}{\mathcal{K}}
\newcommand{\cL}{\mathcal{L}}
\newcommand{\cM}{\mathcal{M}}
\newcommand{\cN}{\mathcal{N}}
\newcommand{\cO}{\mathcal{O}}
\newcommand{\cP}{\mathcal{P}}
\newcommand{\cQ}{\mathcal{Q}}
\newcommand{\cR}{\mathcal{R}}
\newcommand{\cS}{\mathcal{S}}
\newcommand{\cT}{\mathcal{T}}
\newcommand{\cU}{\mathcal{U}}
\newcommand{\cV}{\mathcal{V}}
\newcommand{\cW}{\mathcal{W}}
\newcommand{\cX}{\mathcal{X}}
\newcommand{\cY}{\mathcal{Y}}
\newcommand{\cZ}{\mathcal{Z}}
\newcommand{\ba}{\mathbf{a}}
\newcommand{\bb}{\mathbf{b}}
\newcommand{\bc}{\mathbf{c}}
\newcommand{\bd}{\mathbf{d}}
\newcommand{\be}{\mathbf{e}}
\newcommand{\bbf}{\mathbf{f}}
\newcommand{\bg}{\mathbf{g}}
\newcommand{\bh}{\mathbf{h}}
\newcommand{\bi}{\mathbf{i}}
\newcommand{\bj}{\mathbf{j}}
\newcommand{\bk}{\mathbf{k}}
\newcommand{\bl}{\mathbf{l}}
\newcommand{\bm}{\mathbf{m}}
\newcommand{\bn}{\mathbf{n}}
\newcommand{\bo}{\mathbf{o}}
\newcommand{\bp}{\mathbf{p}}
\newcommand{\bq}{\mathbf{q}}
\newcommand{\br}{\mathbf{r}}
\newcommand{\bs}{\mathbf{s}}
\newcommand{\bt}{\mathbf{t}}
\newcommand{\bu}{\mathbf{u}}
\newcommand{\bv}{\mathbf{v}}
\newcommand{\bw}{\mathbf{w}}
\newcommand{\bx}{\mathbf{x}}
\newcommand{\by}{\mathbf{y}}
\newcommand{\bz}{\mathbf{z}}
\newcommand{\bfa}{{\boldsymbol a}}
\newcommand{\bfb}{{\boldsymbol b}}
\newcommand{\bfc}{{\boldsymbol c}}
\newcommand{\bfd}{{\boldsymbol d}}
\newcommand{\bfe}{{\boldsymbol e}}
\newcommand{\bff}{{\boldsymbol f}}
\newcommand{\bfg}{{\boldsymbol g}}
\newcommand{\bfh}{{\boldsymbol h}}
\newcommand{\bfi}{{\boldsymbol i}}
\newcommand{\bfj}{{\boldsymbol j}}
\newcommand{\bfk}{{\boldsymbol k}}
\newcommand{\bfl}{{\boldsymbol l}}
\newcommand{\bfm}{{\boldsymbol m}}
\newcommand{\bfn}{{\boldsymbol n}}
\newcommand{\bfo}{{\boldsymbol o}}
\newcommand{\bfp}{{\boldsymbol p}}
\newcommand{\bfq}{{\boldsymbol q}}
\newcommand{\bfr}{{\boldsymbol r}}
\newcommand{\bfs}{{\boldsymbol s}}
\newcommand{\bft}{{\boldsymbol t}}
\newcommand{\bfu}{{\boldsymbol u}}
\newcommand{\bfv}{{\boldsymbol v}}
\newcommand{\bfw}{{\boldsymbol w}}
\newcommand{\bfx}{{\boldsymbol x}}
\newcommand{\bfy}{{\boldsymbol y}}
\newcommand{\bfz}{{\boldsymbol z}}
%------------------ Various \newcommand Declarations -------------------

%---> Math environments ----------

\newcommand{\mathset}[1]{\left\{#1\right\}}
%\newcommand{\abs}[1]{\left|#1\right|}
\newcommand{\ceilenv}[1]{\left\lceil #1 \right\rceil}
\newcommand{\floorenv}[1]{\left\lfloor #1 \right\rfloor}
\newcommand{\parenv}[1]{\left( #1 \right)}
\newcommand{\sparenv}[1]{\left[ #1 \right]}
\newcommand{\bracenv}[1]{\left\{ #1 \right\}}
%---> Equation environment ------
%\newcommand{\be}[1]{\begin{equation}\label{#1}}
%\newcommand{\ee}{\end{equation}}
%\newcommand{\eqref}[1]{(\ref{#1})}
%---> Changing style of inequalities ------
\renewcommand{\le}{\leqslant}
\renewcommand{\leq}{\leqslant}
\renewcommand{\ge}{\geqslant}
\renewcommand{\geq}{\geqslant}
%---> Script sets, ect ---------
\renewcommand{\Bbb}{\mathbb}
\newcommand{\script}[1]{{\mathscr #1}}
\renewcommand{\frak}[1]{{\mathfrak #1}}
%---> Font definitions ----------
\newcommand{\bfsl}{\bfseries\slshape}
\newcommand{\sfsl}{\sffamily\slshape}
\newcommand{\dfn}{\sffamily\slshape\small}


%---> References to Theorems, etc. ---

\newcommand{\Tref}[1]{Theo\-rem\,\ref{#1}}
\newcommand{\Pref}[1]{Pro\-po\-si\-tion\,\ref{#1}}
\newcommand{\Lref}[1]{Lem\-ma\,\ref{#1}}
\newcommand{\Cref}[1]{Co\-ro\-lla\-ry\,\ref{#1}}


%---> Fields, ect ----------

\renewcommand{\Bbb}{\mathbb}

\newcommand{\F}{{\Bbb F}}
\newcommand{\Fq}{{{\Bbb F}}_{\!q}}
\newcommand{\Ftwo}{{{\Bbb F}}_{\!2}}
\newcommand{\Fn}{\Bbb{F}_{\!2}^{\hspace{1pt}n}}
\newcommand{\Ffour}{{{\Bbb F}}_{\!4}}

\newcommand{\C}{{\Bbb C}}
\newcommand{\N}{{\Bbb N}}
\newcommand{\Q}{{\Bbb Q}}
\newcommand{\R}{{\Bbb R}}
\newcommand{\Z}{{\Bbb Z}}
\newcommand{\E}{{\Bbb E}}

\newcommand{\comment}[1]{\textcolor{red}{#1}}

%---> Various useful things ----------

\newcommand{\shift}[2]{#1^{\mathbb{#2}}}
\newcommand{\ccap}{\mathsf{cap}}
\newcommand{\fr}{\mathrm{fr}}
\newcommand{\cl}{\mathrm{cl}}
\newcommand{\cyc}{\mathrm{cyc}}
\newcommand{\limup}[1]{\lim_{#1\rightarrow\infty}}
\newcommand{\limdown}[1]{\lim_{#1\rightarrow 0}}
\newcommand{\limsupup}[1]{\limsup_{#1\rightarrow\infty}}
\newcommand{\liminfup}[1]{\liminf_{#1\rightarrow\infty}}
\newcommand{\walk}[1]{\xrightarrow{#1}}
\newcommand{\e}{\mathrm{e}}
\newcommand{\deff}{\mbox{$\stackrel{\rm def}{=}$}}
\newcommand{\Strut}[2]{\rule[-#2]{0cm}{#1}}
\newcommand{\bup}{b_{\scriptscriptstyle{\mathrm{U}}}}
\newcommand{\blo}{b_{\scriptscriptstyle{\mathrm{L}}}}
\newcommand{\lchop}{\cR}
\newcommand{\first}{\cL}
\newcommand{\perr}{P_{\mathrm{err}}}
\newcommand{\emptyword}{\varepsilon}
\newcommand{\esubseteq}{\subseteq^e}
\newcommand{\eqdef}{\triangleq}
\newcommand{\ZD}{{\Z^d}}
\newcommand{\Be}{\mathbb{B}_{\epsilon}}
\newcommand{\Bd}{\mathbb{B}_{\delta}}
\newcommand{\otid}{\otimes_{i\in [d]}}
\newcommand{\hpi}{\overline{\pi}}
\newcommand{\hfr}{\hat{\fr}}
\newcommand{\1}{\mathbf{1}}
\newcommand{\0}{\mathbf{0}}
\newcommand{\given}{~\middle|~}
\newcommand{\cBb}{\overline{\mathcal{B}}}

\def\P{\mathbb{P}}
\def\E{\mathbb{E}}


\DeclareMathOperator{\Int}{Int}
\DeclareMathOperator{\Supp}{Supp}
\DeclareMathOperator{\Suf}{Suf}
\DeclareMathOperator{\Cr}{Cr}
\DeclareMathOperator{\Per}{Per}
\DeclareMathOperator{\Rt}{Rt}
\DeclareMathOperator{\BLE}{BLE}
\DeclareMathOperator{\BRE}{BRE}
\DeclareMathOperator{\ULE}{ULE}
\DeclareMathOperator{\URE}{URE}
\DeclareMathOperator{\bL}{BL}


\newcommand{\bcomment}[1]{\textcolor{blue}{#1}}

\newcommand{\dabs}[1]{\left\|#1\right\|}
\newcommand{\rfrac}[2]{{}^{#1}\!/_{#2}}

\newcommand{\cPsi}{\cP_{\mathrm{si}}}
\newcommand{\ocP}{\overline{\cP}}

\outer\def\proclaim #1. #2\par{\medbreak
	\noindent{\bf#1.\enspace}{\sl#2\par}%
	\ifdim\lastskip<\medskipamount \removelastskip\penalty55\medskip\fi}

%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%end preamble from ACDC%%%%

% clean citations
\usepackage{cite}

% hyperref makes references clicky. use \url{www.example.com} or \href{www.example.com}{description} to add a clicky url
\usepackage{nameref,hyperref}

% line numbers
\usepackage[right]{lineno}

% improves typesetting in LaTeX
\usepackage{microtype}
\DisableLigatures[f]{encoding = *, family = * }

% text layout - change as needed
% \raggedright
\setlength{\parindent}{0.5cm}
\textwidth 5.25in 
\textheight 8.75in

% Remove % for double line spacing
%\usepackage{setspace} 
%\doublespacing

% use adjustwidth environment to exceed text width (see examples in text)
\usepackage{changepage}

% adjust caption style
\usepackage[aboveskip=1pt,labelfont=bf,labelsep=period,singlelinecheck=off]{caption}

% remove brackets from references
\makeatletter
\renewcommand{\@biblabel}[1]{\quad#1.}
\makeatother

% headrule, footrule and page numbers
\usepackage{lastpage,fancyhdr,graphicx}
\usepackage{epstopdf}
\pagestyle{myheadings}
\pagestyle{fancy}
\fancyhf{}
\rfoot{\thepage/\pageref{LastPage}}
\renewcommand{\footrule}{\hrule height 2pt \vspace{2mm}}
\fancyheadoffset[L]{2.25in}
\fancyfootoffset[L]{2.25in}

\usepackage{xcolor}
\newcommand{\SM}[1]{\textcolor{green}{[SM: #1]}}
\newcommand{\AN}[1]{\textcolor{orange}{[AN: #1]}}
\newcommand{\OM}[1]{\textcolor{magenta}{[OM: #1]}}
\newcommand{\VR}[1]{\textcolor{blue}{[VR: #1]}}
\newcommand{\new}[1]{\textcolor{red}{#1}}

% use \textcolor{color}{text} for colored text (e.g. highlight to-do areas)
\usepackage{color}

% define custom colors (this one is for figure captions)
\definecolor{Gray}{gray}{.25}

% this is required to include graphics
\usepackage{graphicx}

% use if you want to put caption to the side of the figure - see example in text
\usepackage{sidecap}

% use for have text wrap around figures
\usepackage{wrapfig}
\usepackage[pscoord]{eso-pic}
\usepackage[fulladjust]{marginnote}
\reversemarginpar

% document begins here
\begin{document}
\vspace*{0.35in}

% title goes here:
\begin{flushleft}
{\Large
%\textbf\newline{Semi-quantitative group testing with a wide range of viral load measurements.}
\textbf\newline{Semi-Quantitative Group Testing for Efficient and Accurate qPCR Screening of Pathogens with a Wide Range of Loads}%with adjusted qPCR thresholds and improved testing efficiency}%low false negative rates.}
}
\newline
% authors go here:
\\
Ananthan Nambiar\textsuperscript{1, $\dagger$},
Chao Pan\textsuperscript{2,3, $\dagger$},
Vishal Rana\textsuperscript{2, $\dagger$},
Mahdi Cheraghchi\textsuperscript{4},
Jo\~ao Ribeiro\textsuperscript{5},
Sergei Maslov\textsuperscript{1,3,*},
Olgica Milenkovic\textsuperscript{2,3,*}
\\
\bigskip
1. Department of Bioengineering, University of Illinois Urbana-Champaign, Urbana, Illinois, USA.
\\
2. Department of Electrical and Computer Engineering, University of Illinois Urbana-Champaign, Urbana, Illinois, USA.
\\
3. Center for Artificial Intelligence and Modeling, Carl R. Woese Institute for Genomic Biology, University of Illinois Urbana-Champaign, Urbana, Illinois, USA.
\\
4. Department of Electrical Engineering and Computer Science, University of Michigan, Ann Arbor, Michigan, USA.
\\
5. NOVA  LINCS and NOVA School of Science and Technology, Caparica, Portugal.

\bigskip
$\dagger$ These authors contributed equally and their names are listed in alphabetical order.\\
* milenkovic@illinois.edu, maslov@illinois.edu

\end{flushleft}

\section*{SUMMARY}
Pathogenic infections pose a significant threat to global health, affecting millions of people every year and presenting substantial challenges to healthcare systems worldwide. Efficient and timely testing plays a critical role in disease control and transmission prevention. Group testing is a well-established method for reducing the number of tests needed to screen large populations when the disease prevalence is low. However, it does not fully utilize the quantitative information provided by qPCR methods, nor is it able to accommodate a wide range of pathogen loads. 
To address these issues, we introduce a novel adaptive semi-quantitative group testing (SQGT) scheme to efficiently screen populations via two-stage qPCR testing. The SQGT method quantizes cycle threshold ($Ct$) values into multiple bins, leveraging the information from the first stage of screening to improve the detection sensitivity. Dynamic $Ct$ threshold adjustments mitigate dilution effects and enhance test accuracy. Comparisons with traditional binary outcome GT methods show that SQGT reduces the number of tests by $24$\% while maintaining a negligible false negative rate.


% now start line numbers
%\linenumbers

% the * after section prevents numbering
\section*{INTRODUCTION}

Pathogenic infections in humans can cause a wide range of diseases, from mild ailments like the common cold or strep throat to more severe and life-threatening illnesses such as COVID-19, Ebola, and Tuberculosis~\cite{alberts2002introduction, baker2022infectious}. These diseases are spread through the proliferation of pathogens within the host and subsequent transmission to other susceptible individuals, often leading to an outbreak in a population. The amount of pathogen in a host, typically referred to as the viral load in the case of viruses, is most frequently expressed in terms of the number of pathogen particles per milliliter of the collected fluid sample. It can vary significantly from the time of infection until recovery and can correlate with the severity of symptoms~\cite{fraser2007variation, zheng2020viral, fajnzylber2020sars}. To quantify viral loads, the real-time reverse transcription-polymerase chain reaction (qPCR) method is widely used, which reports the number of amplification cycles before the amount of genetic material in the sample reaches a prescribed threshold for detection, known as the cycle threshold or $Ct$ value.

%Pathogenic infections in humans cause diseases ranging from mild illnesses like the common cold or step throat to more life-threatening ones including COVID-19, Ebola, and Tuberculosis~\cite{}. Infectious diseases are characterized by the proliferation of pathogens within the host and subsequent transmission to other susceptible individuals, often resulting in an outbreak of the disease in a population. The amount of pathogen in a host, which in the case of viruses is referred to as the viral load, is most frequently expressed in terms of the number of pathogen particles per milliliter of collected fluid sample. Viral loads in a host are known to vary widely from the time of infection until recovery and they can correlate with the severity of the symptoms~\cite{fraser2007variation, zheng2020viral, fajnzylber2020sars}. One of the most widely used methods for quantifying viral loads in samples is the reverse transcription-polymerase chain reaction (qPCR) which reports the number of amplification cycles before the amount of genetic material %(cDNA) in the sample reaches a prescribed threshold for detection. This number of cycles is negatively correlated with the logarithm of the viral load and is referred to as the cycle threshold or $Ct$ value. Typically, qPCR is applied on individual samples to either monitor the progression of the disease in patients or its spread within a population. In the former case, the use of individual samples is required, while in the latter it is possible to circumvent the testing of individual samples through the use of \emph{group testing (GT)}~\cite{}.

Individual samples are usually tested using qPCR to monitor disease progression in patients, but when screening a population for infected individuals, it is more efficient to test large groups of samples simultaneously. Group testing (GT) is a strategy that involves pooling multiple samples prior to running qPCR tests, and subsequently detecting infected individuals in the groups based on the test results. This reduces the overall number of tests required while minimizing the false negative rate (FNR), which is critical in infectious disease screening methods, as undetected positive individuals can lead to the rapid spread of disease. Various GT strategies have been proposed in the past to increase the efficiency of wide-scale testing~\cite{dorfman1943detection, indyk2010efficiently, eberhardt2020multi}, which are implemented using adaptive or non-adaptive protocols. Adaptive testing allows for the sequential selection of groups, while non-adaptive testing requires the selection of all test groups at the same time.

%Since the goal of screening a population for infected individuals is to identify and isolate them as quickly and economically as possible in order to curb transmission, one wants to be able to test large populations rapidly, while minimizing the false negative rate (FNR). FNRs are of critical importance when judging the utility of infectious disease screening methods since positive individuals that are undetected can lead to quick spreading of the disease. To increase the efficiency of such wide-scale testing, various GT strategies have been proposed and implemented in the past~\cite{}. GT schemes usually involve some form of pooling of multiple samples prior to running qPCR tests and subsequent detection of infected individuals in the groups based on the test designs and outcomes. They are implemented using \emph{adaptive} or \emph{non-adaptive} protocols; the former allows for selecting the groups of tested patients sequentially, while the latter requires all test groups to be selected at the same time. Hence, adaptive testing tends to be more time-consuming than non-adaptive testing, but due to its sequential nature also ensures a smaller overall number of tests used. The first known GT scheme, proposed by Dorfman~\cite{dorfman1943detection}, is an example of adaptive GT with binary outcomes (positive or negative), and as such is not designed to use the quantitative information about the viral load. At the same time, fully quantitative testing schemes, including compressive sensing~\cite{}, are susceptible to measurement noise, require specialized pooling matrices, and come with performance guarantees only when the ratio of maximum to minimum viral is confined to a relatively narrow interval~\cite{aeron2010information}. However, this is not true for many viruses, including SARS-CoV-2, where viral loads of patients may differ by multiple orders of magnitude~\cite{fajnzylber2020sars}. Furthermore, the pooling of samples in both GT and compressive sensing methods leads to dilution due to the relatively small number of infected individuals in a pooled sample. Dilution has an adverse impact on the accuracy of the test outcomes and cannot be directly addressed in a compressive sensing setting.

The first known GT scheme, proposed by Dorfman~\cite{dorfman1943detection}, is an example of adaptive GT with binary outcomes (positive or negative), and is not designed to use the quantitative information about viral load. However, fully quantitative testing schemes, including compressive sensing~\cite{donoho2006compressed, ghosh2021compressed}, are susceptible to measurement noise, require specialized pooling matrices, and come with performance guarantees only when the ratio of maximum to minimum viral load is confined to a relatively narrow interval~\cite{aeron2010information}. This is not the case for many viruses, including SARS-CoV-2, where viral loads of patients may differ by multiple orders of magnitude~\cite{fajnzylber2020sars}. Furthermore, the pooling of samples in both GT and compressive sensing methods leads to dilution, which can adversely impact the accuracy of test outcomes and cannot be directly addressed in a compressive sensing setting.

To address these limitations, we propose a new adaptive semi-quantitative group testing (SQGT) scheme that uses $Ct$ values quantized into more than two bins in a structured way. In addition, our scheme combines test outcomes from two rounds to improve the likelihoods of subjects being labelled correctly. To handle the dilution effect, we define multiple $Ct$ thresholds and dynamically adjust them based on the group size. Since GT was used during the COVID-19 pandemic, multiple theoretical approaches mostly based on Dorfman's method have been developed~\cite{yelin2020evaluation, alcoba2021increasing}. At the same time, several large-scale GT data sets containing $Ct$ values in COVID-19 infected individuals have been generated and made publicly available \cite{barak2021lessons,de2020sample, hogan2020sample}. Therefore we test our SQGT scheme on COVID-19 data and compare it Dorfman's method, showing an increase in testing efficiency. For example, for a population infection rate of $0.02$, our SQGT method uses $24$\% fewer tests than the binary outcome Dorfman's GT method, while maintaining a negligible FNR compared to qPCR noise.

%Binary outcomes of pooled tests are based on thresholded (quantized with respect to one threshold) $Ct$ values that are clearly less informative than the $Ct$ values themselves. Nevertheless, in the case where viral loads of individuals carry over multiple orders of magnitude, the $Ct$ value of a group is dictated by the patient with the largest viral load and hence would not be fully indicative of the number of infected individuals in the group. As a consequence, special care has to be exercised when interpreting the $Ct$ values of groups.
%However, due to high noise in qPCR tests and the individual variability in viral loads in infected people, $Ct$ values are only weak proxies for the number of infected individuals in the group. 

%To address the above-described limitations of (quantitative) GT schemes for broadly varying viral loads, we propose a new semi-quantitative group testing (SQGT) scheme that uses $Ct$ values quantized into more than two bins in a structured way to achieve large savings in the total number of tests required for a population. Our SQGT scheme follows a duplicated Dorfman's approach in the first round of screening but combines test outcomes from the second round to improve the decisions regarding the likelihoods of subjects being positive. At the same time, we demonstrate that only a modest increase in FNRs introduced by our testing scheme is smaller than the number of false negatives caused by the stochastic nature of qPCR testing. We do this by defining multiple $Ct$ thresholds  and dynamically adjusting them based on the size of the group in order to handle the dilution effect. For example, for a population infection rate of $0.02$, our SQGT method uses $24$\% fewer tests than the binary outcome Dorfman's GT method; at the same time, the FNR of the SQGT method equals $0.094$, while the FNR of Dorfman's method with the group-size adjusted threshold equals $0.078$. Both are negligible compared to qPCR noise and subsumed by it.

%Some examples of such GT data sets were created by~\cite{barak2021lessons},~\cite{(SPAIN)}, and the Stanford Medical Center~\cite{hogan2020sample}. 
%We tested our SQGT method by adapting the data set from Ref.~\cite{barak2021lessons}, converting their reported $Ct$ values into viral loads, averaging the viral loads for all samples in the group, and converting the resulting viral load back to a $Ct$ value. We also estimated FNRs as functions of the $Ct$ value using real-world data sets from Refs. ~\cite{barak2021lessons,(SPAIN)} in order to guide the selection of the $Ct$ thresholds for best mitigation of dilution effects.  

%The paper is organized as follows. Section~\ref{sec:sqgt} introduces GT and our new SQGT models and underlying algorithmic solutions. 


%\AN{Vishal: Discuss related work. Including compressive sensing}
%-Semi-quant testing for viral diseases with broad range of viral loads
%-Optimizing group test size with PCR side value 
%Various schemes, don't look at Ct values except for compressive sensing; given huge noise, itâ€™s a poor proxy for the number of infected, and you cannot assume an additive model; would have worked if the ratio of max and min was bounded but for covid Ct the ratio is order of thousands; 
%Semi-quant with thresholds uses it in a more structured way; saves a lot of test;
%Fnr issues; but FNR due to our schemes is absorbed by the FNR that comes from the stochastic nature of PCR; shift thresholds to deal with FNRs suggested by the dilution effect
%cs does not handle dilution effect; 
%israeli/spanish references
%Viral load change/range of values of viral loads for various diseases
%\textcolor{red}{Add discussion of time required for adaptive testing in the discussion section.}
\section*{ALGORITHMS AND RESULTS} \label{sec:sqgt}
\subsection*{Basics of Group Testing}
Group testing (GT), in its most basic form, performs screening of a collection of potentially positive individuals by splitting them into test groups involving more than one individual so as to save on the total number of tests performed. The outcome of a group of test subjects is interpreted as follows: the result is declared positive (and denoted by $1$) if at least one of the individuals in the tested group is infected; and, the test result is declared negative (and denoted by $0$) if there are no infected individuals in the group. From a theoretical point of view, GT aims to find an optimal strategy for grouping individuals so that the number of binary tests needed to accurately identify all infected individuals is minimized. GT can be implemented using nonadaptive and adaptive approaches. Unlike adaptive GT, nonadaptive schemes require that all tests are performed simultaneously so that the outcome of one test cannot be used to inform the selection of individuals for another test. The first known GT scheme by Dorfman~\cite{dorfman1943detection} is an example of adaptive screening since it involves two stages of testing, one of which isolates groups with infected individuals, and another one that identifies the actual infected individuals. In general, adaptive schemes use multiple stages of testing and different combinations of individuals to best inform the sequence of tests to be made. When specializing Dorfman's scheme for qPCR screening, the decision about positive and negative group labels is made based on $Ct$ values (see Figure~\ref{fig:dorfman_basic}).

% Figure environment removed

Despite their widespread use, GT methods have notable shortcomings when used in systems that provide more quantitative information than a binary answer of the form ``yes-no,'' such as is the case for qPCR screening. This motivates developing extensions of GT schemes that make use of the more quantitative information available from experiments. When all of the available quantitative information is used, the generalized GT scheme represents a form of compressive sensing (CS)~\cite{donoho2006compressed, dai2009subspace, candes2006stable}. However, CS-based schemes require the ratio of the maximum and minimum pathogen concentrations to be properly bounded~\cite{aeron2010information}. This type of assumption does not hold for a large number of infectious diseases, including COVID-19, where the viral concentrations can vary over several orders of magnitude~\cite{fajnzylber2020sars}. In the presence of infected individuals with widely different loads, CS approaches will mask individuals with low pathogen concentrations. %Additionally, it is hard to implement CS in practice due to constraints on the design matrices.  

Here we propose a more structured approach to GT that straddles the classical Dorfman's scheme and fully quantitative CS approaches. Our semi-quantitative GT scheme (SQGT) can be seen as a multi-threshold version of Dorfman's GT with two independently permuted groups of samples or a quantized version of adaptive CS (see Figure~\ref{fig:gt_sqgt_cs}). More details are provided in the following subsection.

 % Figure environment removed

\subsection*{Semi-Quantitative Group Testing}

SQGT is a GT protocol that interprets test results as estimates of the number of infected individuals in each tested group. Broadly speaking, unlike Dorfman's GT which generates binary responses ($0$, for a noninfected group, and $1$ when at least one infected subject is present in the group, see Figure~\ref{fig:bin_gt} a), SQGT produces answers of the form ``between $x$ and $y$ infected individuals in the group'' (see Figure~\ref{fig:bin_gt} b). %Hence, it may be seen as producing quantized values of fully additive (quantitative) protocols. 
For qPCR experiments, the range of values for the number of infected individuals in the group may be estimated from the $Ct$ value of the group.
%, which are inherently quantized integer values. 
%this corresponds to the fluorescence intensity information being inherently semiquantitative~\cite{EM14} as the fluorescence levels and the corresponding $Ct$ values can be placed into bounded bins determined by the number of cycles. This is a reasonable assumption because of several reasons. Firstly, the pathogen load varies over several orders of magnitudes between different infected individuals and even the same individual tested at different time intervals. Secondly, the qPCR experiment itself has noise which needs to be taken into account. 

For a general SQGT scheme, one seeks a collection of $\geq 1$ measurement thresholds, such that the outcome of each test is an interval for the possible number of infected individuals, i.e., the outcome of an SQGT experiment specifies lower and upper bounds on the number of infected individuals in a group. If the thresholds are consecutive integers covering all possible options for the number of infected individuals in a group, the scheme reduces to additive (quantitative) GT~\cite{lindstrom1975determining,wolf1985born} (see Figure~\ref{fig:bin_gt} c). 

% Figure environment removed

Although nonadaptive SQGT has been previously analyzed from an information-theoretic perspective~\cite{emad2014semiquantitative,emad2016code,cheraghchi2021semiquantitative}, practical implementations for adaptive SQGT schemes are still lacking, especially in the context of qPCR testing. Our approach is the first adaptive SQGT scheme that is specifically designed for real-world qPCR testing. It operates directly on the $Ct$ values and makes use of two  thresholds, $\tau_1$ and $\tau_2$ (see Figure~\ref{fig:pcr_tresh}). This choice for the number of thresholds balances the ease of implementation of a testing scheme in a laboratory with the ability to use the quantitative information from a qPCR test more efficiently\footnote{We also observe in practice that using more than two thresholds leads to diminishing returns in the number of tests saved but significantly increasing the complexity of the scheme.}. 

The main idea behind our $Ct$ value-based SQGT approach is to perform a two-stage SQGT protocol with randomly permuted groups of subjects and risk assessment based on the $Ct$ values obtained after the first stage. More specifically, the scheme involves the following three steps:

\begin{itemize}
\item First, we create two separate, randomly permuted lists of $n$ subjects. Each of these lists is then evenly divided into groups of a specified size, $g$, which are subsequently tested. It's important to underline that the ideal test group size, $g$, for our methodology may differ from that typically utilized in Dorfman's GT approach.
%we generate two independently and randomly permuted lists of $n$ subjects, which are then divided into equal-sized groups (of size $g$) and tested using SQGT measurements. Note that the optimal test group size $g$ for our scheme may not be the same as that of Dorfman's GT method;
\item Second, since GT inevitably leads to sample dilution, we adjust the $Ct$ thresholds in the SQGT scheme to account for this effect. Note that each individual's sample contributes to two $Ct$ values: one from the group they were initially part of in the first permuted list, and another from their group in the second permuted list. This dual-measurement system provides a way for cross-linking the results.
%If an individual's risk is deemed high based on their pair of $Ct$ values from the two permuted lists, we perform individual testing. Otherwise, we do not test them. 

\item Third, we examine the pair of $Ct$ values associated with the individuals to stratify them into low-risk, medium-risk, and high-risk categories. Based on the risk category, the individuals are either immediately declared negative, or tested once again individually. Although the number of tests performed can be reduced by performing nonadaptive SQGT testing on all risky subjects (discussed in the Supplement Section~\ref{supp:nonadaptiveSQGT}), for simplicity we opt for individual testing.
\end{itemize}

% Figure environment removed

%The main contribution of this work is a new pooling strategy, termed permutation SQGT. There are three important differences between Dorfman's GT protocol and permutation SQGT:
%\begin{itemize}
%\item First, permutation SQGT uses two randomly permuted lists of test subjects which are independently partitioned and tested using carefully selected group sizes. Note that the optimal group sizes for Dorfman's GT and permutation SQGT are not necessarily the same;

%\item Second, unlike Dorfman's approach, we exploit the quantitative nature of the PCR test results through the use of SQGT. Since GT inevitably leads to dilution effects, we adjust the $Ct$ value thresholds used for declaring positive, risky, and negative groups;

%\item Third, we combine the results of the two permuted input lists to stratify the test subjects into low-risk, medium-risk, and high-risk. Based on the risk category, the individuals are either immediately declared negative, or tested once again. The stratification procedure is informed by the permutation SQGT test outcomes.
%\end{itemize}

%Next, we describe our scheme in detail. Let there be $n$ individuals in a population with an unknown fraction $p$  of them being infected. In the first stage, we start by grouping samples into groups of size $g$ such that each individual contributes to two different groups. We do this by taking two permutations $\pi_1$ and $\pi_2$ of the $n$ individuals before splitting them. Let the groups be labelled as $\gamma^{\pi_1}_1, \gamma^{\pi_1}_2, \dots, \gamma^{\pi_1}_{n/g}$ and $\gamma^{\pi_2}_1, \gamma^{\pi_2}_2, \dots, \gamma^{\pi_2}_{n/g}$. Then any given individual belongs to two groups $\gamma^{\pi_1}_{i}$ and $\gamma^{\pi_2}_{j}$, one from each permutation. For both groups, we run separate qPCR experiments and record the outcomes $C^{\pi_1}_{t_i}$ and $C^{\pi_2}_{t_j}.$ The corresponding quantization bins $S^{\pi_1}_i$ and $S^{\pi_2}_j$ are then obtained as follows 

%Thus, for each individual, we have a tuple $(S^{\pi_1}_{i}, S^{\pi_2}_{j})$ representing the outcome of two pooled tests. Note that these tests can all be run in parallel, independently of each other.

%In the second stage, we declare individuals with $(S^{\pi_1}_{i}, S^{\pi_2}_{j}) \in \{(0,0), (0,1), (1,0)\}$ as negative. We declare $\{(0,1),(1,0)\}$ as negative since it is reasonable to assume that outcome $1$ is due to a different infected individual in that group, otherwise we would observe a $1$ or $2$ in the other group as well.  For individuals with $(S^{\pi_1}_{i}, S^{\pi_2}_{j}) \in \{(1,1), (2,1), (1,2), (2,2)\}$, we test individually. For the remaining case where $(S^{\pi_1}_{i}, S^{\pi_2}_{j}) \in \{(2,0), (0,2)\}$, we look at the high risk group with outcome $2$. If this group has another individual with outcomes in $\{(1,2),(2,1),(2,2)\}$, we declare this individual negative, otherwise we test them individually. Figure~\ref{fig:sqgt_basic} shows the SQGT scheme while Figure~\ref{fig:dorfman_basic} shows the classical GT scheme originally proposed by Dorfman.

%Each of these steps is illustrated in Figure~\ref{fig:sqgt_basic}. We compare our method to the original two-stage GT scheme proposed by Dorfman, where pooling is only done once and all individuals in a group with non-zero outcome are tested individually. Our method is able to achieve significant savings in the number of tests without detrimental deterioration in false negative rates.  

%Note that from the perspective of minimizing the number of tests, doing individual testing, like in our second stage of SQGT scheme for the high-risk group, is undesirable. It can be mitigated by running a nonadaptive GT scheme in the second stage and has been mathematically analyzed in the Supplement. 

Next, we describe our scheme in detail. We consider a population of $n$ individuals, arranged into groups of size $g$, and denote the fraction of infected individuals by $p$. Again, we only make use of two quantization thresholds, denoted by $\tau_1$ and $\tau_2$. Our scheme consists of two stages.

In the first stage, we group the patient samples into groups of size $g$, ensuring that each individual contributes to two different groups. To achieve this, we use two random permutations, $\pi_1$ and $\pi_2$, of the $n$ individuals so that they appear in different random orders. Subsequently, the ordered lists are split into groups of $g$ consecutive samples (for simplicity, we assume that $n$ is a multiple of $g$). The resulting groups are denoted by $\gamma^{\pi_1}_1, \gamma^{\pi_1}_2, \dots, \gamma^{\pi_1}_{n/g}$ and $\gamma^{\pi_2}_1, \gamma^{\pi_2}_2, \dots, \gamma^{\pi_2}_{n/g}$. It is important to note that each individual belongs to two groups, $\gamma^{\pi_1}_{i}$ and $\gamma^{\pi_2}_{j}$ with $i \in \{{1,\ldots,n/g\}}$ and $j \in \{{1,\ldots,n/g\}}$, where the two groups are created based on the two permuted lists. For both collections of groups, we perform separate qPCR experiments, denoting the outcomes as $Ct^{\pi_1}_{i}$ and $Ct^{\pi_2}_{j}$, respectively. Then we quantize the $Ct$ values into bins, and assign the test scores $S^{\pi_1}_i$ for group $\gamma^{\pi_1}_{i}$ and $S^{\pi_2}_j$ for group $\gamma^{\pi_2}_{j}$ using the threshold rule:

\begin{equation}
S^{\pi} = 
\begin{cases}
0, & \text{ if } Ct^{\pi} \geq \tau_2;\\
1, & \text{ if } \tau_1 < Ct^{\pi} < \tau_2;\\
2, & \text{ if } Ct^{\pi} \leq \tau_1.
\end{cases} \label{eq:thresh}
\end{equation}

Consequently, each individual is labeled by a pair of test scores $(S^{\pi_1}_i, S^{\pi_2}_j)$, representing the outcomes of the two group tests (for group $\gamma^{\pi_1}_{i}$ and $\gamma^{\pi_2}_{j}$) that the individual is involved in. We omit the subscripts $i$ and $j$ in the later context for simplicity of notation.
%Importantly, these tests can be conducted in parallel, independently of each other.

In the second stage, we classify individuals based on their scores $(S^{\pi_1}, S^{\pi_2})$. Individuals with scores $\{(0,0), (0,1), (1,0)\}$ are deemed low-risk and declared negative. In particular, scores $\{(0,1), (1,0)\}$ are declared to correspond to negative subjects because they were involved in a negative test group (score $0$) and intermediate $Ct$ value group (score $1$). Subjects with scores $\{(1,1), (2,1), (1,2), (2,2)\}$ are classified as high-risk and tested individually in a second stage of tests. For the remaining score pairs, $\{(2,0), (0,2)\}$, we proceed as follows: If the group with score $2$ contains another individual with a score in $\{(1,2),(2,1),(2,2)\}$, we classify the first individual as negative; otherwise, we conduct an individual test. We choose this option since it is unlikely that the first individual was positive, given the existence of even worse-scoring individuals in the same group. Figure~\ref{fig:sqgt_basic} illustrates the proposed two-stage SQGT scheme, while Figure~\ref{fig:dorfman_basic} depicts Dorfman's GT scheme. Supplement Sections~\ref{supp:modelGT} and ~\ref{supp:variableload} provide a detailed mathematical analysis of the various GT schemes discussed.

% Figure environment removed

It is worth noting that conducting individual testing, as in the second stage of our SQGT scheme for the high-risk group, is suboptimal from the point of minimizing the number of tests. This issue is not limiting the application of the scheme since one can use a nonadaptive GT scheme in the second stage, thereby significantly reducing the number of second-stage tests. Since nonadaptive GT is conceptually more involved and harder to implement in practice than the above procedure, pertinent explanations are delegated to Supplement Section~\ref{supp:nonadaptiveSQGT}.

As we will demonstrate in the Results section, the proposed two-stage SQGT approach offers substantial reductions in the number of tests when compared to Dorfman-type tests. It remains to see if the reduction in the number of tests leads to undesirable increases in the FNR of the scheme. To address this question, we need to consider the influence of dilution effects on the test results and how one could adjust quantization thresholds to counter these effects.

%\textcolor{red}{Text moved here from elsewhere}\\
%This is due to the fact that they fail to fully exploit the quantitative information about viral load in a test group captured by the $Ct$ value of an qPCR experiment. One could argue that the fluorescence exceeding the detection threshold may correspond to the test outcome $1$, but clearly, significantly more information is available as the number of amplification cycles needed to reach the detection threshold ($Ct$) depends on the concentration of the viral cDNA and hence the number of infected individuals. On the other hand, CS approaches rely on a much stricter assumption about viral loads which restricts their application to viruses like Covid-19. This motivates the design of a more structured approach that straddles classical GT and fully quantitative CS. To this end, we introduce our novel Semi-Quantitative GT scheme (SQGT) with the goal of designing efficient GT schemes which can be implemented easily. SQGT can be seen as a multi-threshold version of classical GT or a quantized version of CS (see Figure~\ref{fig:gt_sqgt_cs}).


%Another special SGT case of interest assumes that the test results are additive up to some threshold $\tau$ and after that, they saturate~\cite{d1984generalized} (see Figure~\ref{fig:comparison}). This model is of special interest for Covid-19 testing as it takes the warm-up/saturation information into account and, in addition, under a proper noise model, captures the fact that amplification graphs have different $Ct$ values determined by the concentration of the viral load (an hence the approximate number of infected individuals). Furthermore, one can argue that the qPCR fluorescence intensity information is inherently semiquantitative~\cite{EM14} as the fluorescence levels and $Ct$ values can be placed into bounded bins determined by the number of cycles. This observation is explained in more detail in the next section, along with new theoretical results pertaining to adaptive SQGT schemes with appropriate noise models.
%Copy from commented out but made user-friendly. Discuss the method itself. Contribution: A simple scheme that has the benefits of previously proposed schemes.
\subsection*{Dilution Effects}
In most experiments involving GT, the test samples come in specified unit concentrations that are equal across all test subjects. This means that a group sample involving $g$ individuals will only use a fraction $1/g$ of the unit sample from each individual. This inevitably leads to dilution of the group sample, the level of which depends on the number of infected individuals in that particular group. When there is only a small number of infected individuals in the group, the overall viral load of the group sample may be lower than the detection threshold, thereby leading to highly undesirable false negatives. False negative rate (FNR) is related to true positive rate (TPR) through $\text{FNR}=1-\text{TPR}$, and the TPR function is often referred to as the sensitivity function.

A mathematical model for dilution effects was first proposed in~\cite{hwang1976group}, which introduced a special TPR function $TPR(p, g, d)$ of the form
\begin{linenomath}
\begin{align}\label{eq:hwang_model}
TPR(p, g, d) &= \mathbb{P}(\text{test result is declared positive}|\text{there is at least $1$ positive subject in the group}) \notag\\
&= p\left[1-(1-p)^{g^d}\right]^{-1}.
\end{align}
\end{linenomath}
Here, $p$ denotes the infection rate, $g$ denotes the group size, and $d$ denotes a parameter capturing the dilution level. When $d=0, TPR(p,g,0)=1$, indicating that there is no dilution; when $d=1$ and $g$ is large, $TPR(p,g,1)\sim p$, indicating that the sample is fully diluted and that the probability of correctly identifying a defective group is the same as the infection rate. More details on the TPR model for SQGT can be found in Supplement Section~\ref{supp:hwangFPR}. 

%\comment{Note that the dilution model~(\ref{eq:hwang_model}) was designed for Dorfman's GT scheme, where only one $Ct$ threshold exists. Following a similar idea, we can extend this formulation to our SQGT test scheme where two thresholds exist. The results are summarized in~(\ref{eq:hwang_extension}).
%\begin{align}\label{eq:hwang_extension}
%TPR_1(p, g, d) &= \mathbb{P}(\text{test score is }1|\text{there is exactly $1$ positive subject in the group}) \notag\\
%& = \frac{p^{g^{d}}}{g^{d}\cdot p\cdot (1-p)^{g^{d}-1}};\notag \\
%TPR_2(p, g, d) &= \mathbb{P}(\text{test score is $1$ or $2$}|\text{there are at least 2 positive subjects in the group}) \notag \\
%& = \frac{p^{1+(g/2)^{-d}}}{1-(1-p)^{2(g/2)^{d}}-2(g/2)^{d}\cdot p\cdot (1-p)^{2(g/2)^{d}-1}}.
%\end{align}
%Here, as before, $p$ denotes the infection rate, $g$ denotes the group size, and $d$ denotes a parameter capturing the dilution level. The detailed derivation is delegated to the supplement.
%}

Although the dilution model~(\ref{eq:hwang_model}) is mathematically elegant and tractable for analysis, it provides a poor match for real-world measurements (see Figure~\ref{fig:fnr} (b)). A more practical approach to quantifying dilution effects is to assess how dilution impacts the actual viral load in a group. The empirical studies~\cite{jones2021estimating,barak2021lessons,brault2021group,de2020sample} consistently point out that the $Ct$ values of groups tend to be higher than the $Ct$ value of individual tests with high probability. This phenomenon is also due to dilution effects. Nevertheless, none of these works describe how to readjust the $Ct$ value used for declaring positives in the presence of dilution. In the context of SQGT, this is an even more important issue as the increased $Ct$ values can lead to degradation in the detection rate as well as a significantly increased number of measurements. This motivates exploring the relationship between the value of the $Ct$ threshold used for an individual test and that used for a group test. For the worst-case scenario when there is only one infected individual in a group of size $g$, the group $Ct$ value takes the form
\begin{linenomath}
\begin{align}\label{eq:ct_viral_load}
    Ct &= -M \log_{10}({v}/{g}) + B\notag\\
            &= -M\log_{10}(v) + B + M\log_{10}(g),
\end{align}  
\end{linenomath}

where $v$ denotes the viral load of the infected individual, and $M$ and $B$ are positive values denoting the slope and the intercept for the PCR calibration curve~\cite{jones2021estimating}. The exact values of $M$ and $B$ need to be estimated from the experimental data. Equation~(\ref{eq:ct_viral_load}) characterizes the relationship between the viral load and the $Ct$ value, and it implies that compared to individual testing, the group $Ct$ value will be higher by $M\log_{10}(g)$. The implication of this observation is that for GT, we need to increase the $Ct$ thresholds by $M\log_{10}(g)$.
%This motivates us to explore the relationship between the threshold of individual tests and the two thresholds of SQGT based on intuition from dilution effects, with the basic intuition that the $Ct$ value of a group test would be $\log_2(g)$ larger than that of a positive individual test if the individual is the only positive one within the group.
% \AN{Should we describe the $\log_2(g)$ correction here? Then, in the modelling section I can go straight to describing the modelling results.}

\subsection*{Controlling and Modelling FNRs of PCR Tests}
In order to quantify the trade-off between the FNR and the reduction in the number of group tests when using the proposed SQGT scheme, we express the FNR, an important metric with respect to test accuracy, as a function of the $Ct$ value. For this purpose, we use the large-scale real-world GT dataset~\cite{barak2021lessons}. Our FNR model is based on the following ``sigmoid'' function,
\begin{linenomath}
\begin{align}\label{eq:fnr}
FNR(Ct)=\left[1+\exp\left(\frac{a-Ct}{b}\right)\right]^{-1},
\end{align}
\end{linenomath}
where $a,b$ are two tunable parameters that can be used to fit the measured/estimated FNRs. Note that similar ideas were also discussed in~\cite{lin2020group}; however, as may be seen from Figure~\ref{fig:fnr} (b), the FNR function ($a=35.8, b=0.08$) proposed in~\cite{lin2020group} significantly deviates from real-world experimental data.

In practice, the values of FNRs are hard to estimate as this requires multiple tests of the same individual. In the GT context, there are two ways to estimate FNRs. The direct scenario is to compute FNRs by counting the instances when a group test was negative but at least one member from that group tested positive. However, in all experimental verification of GT protocols, individuals whose group tested negative are eliminated from future retesting. This renders the direct approach impossible to pursue in practice. The indirect approach is to count the cases where the group test was positive but all subjects individually tested negative. In this work, we follow the second approach to estimate the FNRs. The ratio of the number of these ``inconsistent'' tests and the total number of tests with the same $Ct$ value is shown in Figure~\ref{fig:fnr} (a). Note that these results can correspond to either a false positive for the group test, or a false negative for one or more of the individual tests. Here we consider the right half of the curve ($Ct>25$) to be caused by the false negative results, which agrees with the intuition that the FNR increases as the $Ct$ value increases. Our fitted FNR curve is shown in Figure~\ref{fig:fnr} (b), along with the estimated FNR curve from experimental results, and the models from~\cite{hwang1976group,lin2020group}. As it is apparent, the latter provides a poor fit to the data while our model with parameters $(a=36.9,b=2.145)$ represents a significantly more accurate fit. 

The FNR shown in Figure~\ref{fig:fnr} corresponds to individual tests, for which we do not know the correct $Ct$ values. Therefore, we shift the group test $Ct$ values by $M\log_{10}(g)=2.895$ in Equation~(\ref{eq:ct_viral_load}) to estimate the individual $Ct$ values. A detailed discussion of the data processing and FNR estimation pipeline is included in the Methods Section.

% Figure environment removed

\subsection*{Case Study of the SQGT Protocol Applied to COVID-19 Data}
While the SQGT framework is broadly applicable to PCR-based pathogen screening, general data is usually limited for pathogens other than SARS-CoV-2. The COVID-19 pandemic has resulted in an unprecedented amount of publicly available qPCR test data, which motivates testing our SQGT framework on real-world SARS-CoV-2 data. Our reported results pertain to a set of $133,816$ SARS-CoV-2 $Ct$ values of qPCR tests performed in Israel between April and September 2020 as reported in~\cite{barak2021lessons}. To explore a range of different infection scenarios without performing additional experiments, we simulated populations of $10,000$ individuals of which a fraction $p \in \{0.02, 0.05, 0.1\}$ was infected by the virus. The $Ct$ values of the infected individuals were randomly sampled from the real-world dataset of~\cite{barak2021lessons}, and converted into estimated viral loads using Equation~\ref{eq:lineari} (see also the Methods section). The viral loads of uninfected individuals were set to $0$. 

Following the SQGT scheme of Figure~\ref{fig:sqgt_basic}, samples are partitioned into groups of $g$ individuals whose viral loads were subsequently averaged and converted to $Ct$ values as described in the Methods section (Equation~\ref{eq:linear}). Following standard diagnostic procedures, individuals were declared negative if their $Ct$ values exceeded a threshold (in our case, set to $37$ as suggested in \cite{hu2020factors}).

%To model a diagnostic scenario, we first established the ground truth of infection using an error-free Individual Testing scheme (see Methods). With this baseline set up, we compared the performance of the SQGT scheme against that of Dorfman group testing.

To analyze the magnitude of the savings in the number of tests required for the GT scheme compared to individual screening, independent of PCR assay noise, we ran both Dorfman's GT and SQGT on the model data. The tests were performed under the assumption that qPCR assays are error-free. Supplement Figure~\ref{fig:error-free} shows these results for all three infection rates $p$. We performed a sweep of group sizes $g$ for each value of $p$ to identify their optimal values. While both GT schemes require significantly fewer than the $10,000$ tests needed for individual testing, SQGT consistently outperforms Dorfman's GT for all three infection rate levels. In addition, Supplement Figure~\ref{fig:error-free} shows that the group-dependent thresholds help to avoid false negatives that would have occurred due to dilution effects, as expected.

However, as noted in the previous section, qPCR assays are not error-free in practice, and as a result, the false negatives in GT schemes could be due to either dilution effects or qPCR noise. Therefore, we incorporated qPCR noise into our model to make it more realistic. This was done by including the empirically fitted FNR in Figure~\ref{fig:fnr} into the PCR assays in our model (see the Methods section for details). Figure~\ref{fig:noisy} shows that while the noise has very limited effects on the number of tests required by each GT scheme, it does have the expected effect of increasing the FNR of both individual and group tests. For individual testing, the noise function we fit appears to correspond to an FNR of just under $0.05$, which is comparable to the empirically determined values reported in~\cite{TAKAHASHI2022e01496} and~\cite{woloshin2020false}. The FNR values of both GT schemes are also consistently slightly higher than those of individual testing. To compare the FNR of SQGT and Dorfman's GT, we first identify the optimal group size for each scheme by picking the value $g$ for which the scheme requires the least number of tests. When $p=0.02$, the optimal value of $g$ for SQGT was $15$ with an average of $1,989.8$ tests required; at the same time, Dorfman's GT required $2,623.6$ tests for an optimal group size $g=8$. These optimal group sizes correspond to FNRs of about $0.0946$ for SQGT and $0.0784$ for Dorfman's GT, respectively. When the infection rate is increased to $0.05$, the optimal group sizes are smaller, with $g=12$ and $g=5$ for SQGT and Dorfman's GT, respectively. These group sizes correspond to $3,651.7$ tests with an FNR of $0.851$ for SQGT and $4,082.6$ tests with an FNR of $0.726$ for Dorfman's GT. Finally, at $p=0.1$ the optimal group size for SQGT was identified as $g=8$, with $5,542.2$ tests and an FNR of $0.815$, while for Dorfman's GT the results indicated $g=5$, with $5,798.0$ tests and an FNR of $0.703$. The observed trend is that SQGT offers savings in the number of tests at the expense of a slight increase in FNR. It should also be noted that this increase is often within the error-bounds of the FNRs.

% Figure environment removed
 
In addition, we tested a modified version of SQGT where individuals with a $(2,0)$ or $(0,2)$ result are declared negative without further testing. As shown in Figure~\ref{fig:noisy}, this version of the SQGT method performs similarly to the regular SQGT. To investigate the reason behind this finding, we plotted the number of individuals for each possible outcome of the SQGT scheme for an infection rate of $0.04$ and the corresponding optimal group size $g=12$. As can be seen in Figure~\ref{fig:breakdown}, the $(2,0)$ and $(0,2)$ test results consist only of uninfected individuals. Therefore, it makes sense that declaring them negative without further testing has no effect on the FNR. For a mathematical analysis of the phenomena and related GT models, the reader is referred to Supplement Section~\ref{supp:modelGT}. %\textcolor{red}%{Vishal: put in reference to Toby Berger and place in Supplement where you have the added results.}

% Figure environment removed

Finally, we examined how the number of tests required for the optimal group size varies over a wider range of infection rates, as shown in Figure~\ref{fig:sweep}, alongside the corresponding FNRs. The figure shows that as the infection rate increases, the number of tests required for both GT schemes increases and the advantage of GT over individual testing decreases. This is a property that has been already established in the past for Dorfman's scheme~\cite{dorfman1943detection}. In addition, the figure shows that SQGT for PCR screening always saves more tests than Dorfman's scheme with only a small increase in FNR (within the margin of error of Dorfman's FNR).


% % Figure environment removed
% % Figure environment removed


% Figure environment removed

 % % Figure environment removed

\section*{Discussion}
We introduced the concept of Semi-Quantitative Group Testing (SQGT) as an extension of traditional Group Testing (GT) methods, with a specific focus on qPCR-based pathogen screening. GT methods, in their classical form, are based on binary test outcomes (positive or negative) and are effective for identifying infected individuals in a cost-efficient manner. However, they fail to utilize the full quantitative information provided by qPCR assays, which can lead to suboptimal performance in scenarios with widely varying pathogen concentrations.

SQGT addresses this limitation by interpreting test results as estimates of the number of infected individuals in each group. The proposed SQGT scheme utilizes two quantization thresholds to categorize qPCR results into different risk categories, allowing for a more refined analysis of the infection status within each group. By employing random permutations and two-stage testing, SQGT can reduce the number of tests needed while still maintaining a high level of test accuracy.

The study also addressed the issue of dilution effects in GT protocols, which can lead to false negatives in qPCR-based testing. To mitigate this problem, we incorporated group size-dependent thresholds in the SQGT framework, adjusting for the dilution effect and improving the overall accuracy of the test results.

Through extensive simulations and analysis using real-world qPCR data from SARS-CoV-2 testing, we demonstrated that SQGT outperforms traditional GT schemes (such as Dorfman's GT) in terms of test efficiency while maintaining a comparable or slightly higher FNR. For example, for a population infection rate of $p=0.02$, our conceptually simple SQGT method uses $24$\% fewer tests than the binary outcome Dorfman's GT method, while maintaining a negligible FNR compared to qPCR noise. In conclusion, SQGT provides substantial reductions in the number of tests required for pathogen screening, making it a promising approach for large-scale population testing, especially during pandemics or outbreaks. 

It is important to note that the proposed SQGT scheme is tailored specifically for qPCR testing and it involves two stages of testing, as originally suggested by Dorfman's scheme. The two stages are crucial for adaptive screening which informs the tests in the second stage based on the results in the first stage. Nonadaptive testing scheme, on the other hand, would result in potentially smaller delays of the test results but would require significantly more tests. They are also often too complicated to implement in practice as they require combinatorial sample mixing and decoding.  

Additionally, our studies were performed under two assumptions, error-free qPCR assays, and qPCR assays with a sigmoidal model of false negatives as a function of $Ct$ values. The incorporation of qPCR assay noise into the simulations led to a slight increase in FNRs, highlighting the need for careful consideration of assay accuracy for a broader range of practical pathogen detection schemes.

For other pathogens and datasets, our SQGT scheme can be modified as needed by combining adaptive and nonadaptive test schemes, including more than two thresholds, and integrating a specialized technique for identifying ``heavy hitters" (i.e., individuals with very high viral loads). These approaches are mathematically analyzed in the Supplement Section~\ref{supp:variableload}.

%Overall, the introduction of SQGT represents a novel approach that bridges the gap between traditional binary GT and fully quantitative Compressive Sensing (CS) methods. It effectively harnesses the quantitative information available from qPCR assays while still providing significant efficiency gains in pathogen screening. Future research should focus on experimental validations of the SQGT scheme using real-world data to further assess its performance and practicality in various testing scenarios beyond SARS-CoV-2.

% \section*{Materials and Methods}

\section*{Methods}
\subsection*{Data}\label{sec:data}
The real-world COVID-19 GT data~\cite{barak2021lessons} used in this paper contains $133,816$ samples collected between April and September 2020 in Israel and tested experimentally via Dorfman's pooling. The original data contains the following information for each individual sample:
\begin{itemize}
    \item Sample id: A unique id for tracking the sample;
    \item Month: Information about the month when the sample is collected;
    \item Group id: An id indicating which group an individual sample belongs to in the test scheme. Samples within the same group share the same group id, and the test groups are of size $5$ and $8$;
    \item Result: Final test result for a sample (positive/negative);
    \item Sample viral $Ct$: $Ct$ value of an individual test. Note that this value is not available when the group test involving the sample is negative;
    \item Group viral $Ct$: $Ct$ value of the group to which the individual sample belongs to;
    \item Sample human $Ct$: $Ct$ value of an individual test for amplifying the human ERV-3~\cite{yuan2001quantification} gene. This $Ct$ value lying below a predetermined threshold serves as an internal control for whether a test was successful or not;
    \item Group human $Ct$: $Ct$ value of the group test used for amplifying the human ERV-3 gene.
\end{itemize}

As pointed out in the Results Section, there are some experimental inconsistencies between the results of the group tests and the individual tests. Specifically, in $70$ out of $1,887$ positive tests, the results of the group tests were positive while all individuals within the groups tested negative. These results can be explained as false positives for the group test, or as false negatives for the individual tests. We used this information to model the FNR of the dataset as described in our Results Section. Note that for simplicity we assume that there is only one positive individual sample within the group when a false negative result is recorded, as this is the most probable scenario. We hence use (Group test $Ct-M\log_{10}(g)$) as the estimated $Ct$ value for the individual test in the presence of a false negative, where $g$ as before denotes the group size, while $M\log_{10}(g)=2.895$. Our fitted model shown in Figure~\ref{fig:fnr} (a) is obtained through the MATLAB \texttt{fit} function.

% \subsection*{Estimating the FNR of PCR tests}
% \comment{TO DO}
\subsection*{Modelling COVID-19 group testing schemes}
\subsubsection*{Modelling PCR tests}
When modelling an individual test, individual $i$ with a viral load $v_i$ will have
\begin{linenomath}
\begin{align}\label{eq:lineari}
Ct_{i} = -M \log_{10}(v_i) + B.
\end{align}
\end{linenomath}
The values for $M$ and $B$ are set based on a previously established calibration curve \cite{jones2021estimating}. Then given a threshold $Ct_{I}$, an individual $i$ is considered positive for the virus if $Ct_{i}<\tau_{\textit{In}}$. In our simulations we use $\tau_{\textit{In}} = 36$. 

To model a pooled test, the viral loads of individuals in a group are averaged and plugged into Equation \ref{eq:linear} to determine the $Ct$ for the group. That is, for group $j$ with individuals $\{1,2,...,g\}$
\begin{linenomath}
\begin{align}\label{eq:linear}
Ct_{j} = -M \log_{10}(\frac{1}{g}\sum_{i=1}^{g} v_{ji}) + B.
\end{align}
\end{linenomath}
These group $Ct$s can then be used for different GT schemes as described in the Algorithms and Results section.
\subsection*{Including PCR noise into models}
Since PCR tests are not error-free, we also include some noise into the tests based on the FNR function
\begin{linenomath}
\begin{align}
FNR(Ct)=\left[1+\exp\left(\frac{a-Ct}{b}\right)\right]^{-1},
\end{align}
\end{linenomath}
where $b$ is empirically determined to be $2.145$ as discussed in the Algorithms and Results section and $a$ is the threshold used for the PCR test. To include this noise into our PCR simulations, we use the following procedure:

\begin{algorithmic}
\If{test is individual} 
    \State $Ct \gets -M \log_{10}(v_i) + B$
\Else
    \State $Ct \gets -M \log_{10}(\frac{1}{g}\sum_{i=1}^{g} v_{ji}) + B.$
    \EndIf
\State result $\gets$ Scheme($Ct$)
\If{truth == positive}
    \If{Bernoulli$(p=FNR(Ct))$}
    \State result $\gets$ negative
    \EndIf
\EndIf
\end{algorithmic}

First, the $Ct$ value of a test is calculated using Equation \ref{eq:lineari} or \ref{eq:linear}. If the ground truth of the test is that it is positive, it is converted into a negative (no infected individuals) with probability $FNR(Ct)$. Otherwise, the result of the test is left as determined by the testing scheme.


%\clearpage

\section*{Acknowledgments}
We thank Professor Nigel Goldenfeld and Dr. Rayan Gabrys for useful discussions. The work was supported by NSF grants 2107344 and 2107345.
%We thank just about everybody.

\section*{Author Contributions}
Conceptualization, S.M., and O.M.; Investigation, A.N., C.P., and V.R.; Formal Analysis, A.N., C.P., V.R., M.C., J.R., S.M., and O.M.; Writing â€“ Original Draft, A.N., C.P., V.R., M.C., J.R., S.M., and O.M.; Writing â€“ Review \& Editing, A.N., C.P., V.R., S.M., and O.M.;

%\nolinenumbers

%This is where your bibliography is generated. Make sure that your .bib file is actually called library.bib
\bibliography{main}

%This defines the bibliographies style. Search online for a list of available styles.
\bibliographystyle{abbrv}

%
% \section{Basics of GT} \label{bg:gt}
	
% 	In this section, we provide concise overviews of all relevant GT schemes used or proposed for potential use for Covid-19 testing: (1) Classical nonadaptive and adaptive GT; (2) Nonadaptive Semi-Quantitative GT (SQGT); (3) Threshold GT; (4) Compressive sensing (CS); (5) Graph-Constrained GT. For all these methods, we describe their potential advantages and drawbacks and then proceed to introduce a new method, which we refer to as adaptive SQGT. Adaptive SQGT with a ``curve fitting''-based noise model appears to provide the theoretical state of the art GT results for qPCR test models and is the focus of our subsequent discussions.
	
% 	\subsection{Nonadaptive and adaptive GT}
	
% 	The assumptions are as follows: In a group of $n$ individuals, there are $d$ infected people. When a subset of people are tested, the result is positive (e.g., equal to $1$) if at least one person in the tested group is infected, else the test result is negative (e.g., equal to $0$). Such a testing scheme is referred to as \emph{binary}, as the outcomes take one of two values (see Figure~\ref{fig:comparison} (a)). GT aims to find the set of all infected people with the fewest number of binary tests possible and may use nonadaptive and adaptive tests. In the former case, all tests are performed simultaneously and the outcome of one test cannot be used to inform the selection of the individuals for other tests. In the adaptive setting, one can use multiple stages of testing and different combinations of individuals to best inform the sequentially made test choices. 
	
% 	% Figure environment removed
	
% 	When $d \ll n$, it is well-known that $\Omega (d \cdot \log (n/d))$ number of tests are required to find all infected individuals. Furthermore, it was shown in~\cite{d1982bounds} that for NAGT, at least $\Omega (d^2 \cdot \log (n)/ \log (d))$ tests are required. For the same parameter regime, there exist explicit nonadaptive schemes that require $\cO (d^2 \cdot \log (n/d) )$ tests to find the infected group~\cite{porat2008explicit}. A four-stage adaptive scheme that uses an optimal number of tests that meets the lower bound was recently described in~\cite{scarlett2019efficient}. Of special interest is the classical binary search result of~\cite{H72} which established an elegant adaptive scheme that differs from the information-theoretic limit only by an additive $\cO(d)$ term. 
	
% 	Despite the many proposed applications of this model to Covid-19 testing, it is obvious from the previous discussion that the GT measurement outcomes do not fully use the actually available qPCR results. One could argue that the fluorescence exceeding the detection threshold may correspond to the test outcome $1$, but clearly, significantly more information is available as the detection threshold depends on the concentration of the viral cDNA and hence the number of infected individuals. This motivates using a more quantitative GT approach, introduced under the name of SQGT.
	
% 	\subsection{Nonadaptive SQGT}
	
% 	In SQGT, one is given a collection of thresholds $0=\tau_1<\tau_2<\cdots<\tau_r$, and the outcome of each test is an interval $(\tau_i,\tau_{i+1}],$ where $0 \leq i \leq r-1$. The outcome of an experiment cannot specify the actual number of infected individuals but rather provides a lower and upper bound on that number, $\tau_{i-1}$ and $\tau_{i}$, respectively. If $\tau_i=\tau_{i-1}+1$ for all values of $i$ and $r=d$, the scheme is referred to as additive GT, or the adder model~\cite{lindstrom1975determining,wolf1985born}. 
%     The two models are depicted in Figure~\ref{fig:comparison} (b) and (c). The additive test model described in~\cite{lindstrom1975determining} requires $2 \cdot (n/ \log \, n) $ tests to determine all possible infected individuals, for $0 \leq d \leq n$.
    
%     Another special SQGT case of interest assumes that the test results are additive up to some threshold $\tau$ and after that, they saturate~\cite{d1984generalized} (see Figure~\ref{fig:comparison}). This model is of special interest for Covid-19 testing as it takes the warm-up/saturation information into account and, in addition, under a proper noise model, captures the fact that amplification graphs have different $Ct$ values determined by the concentration of the viral load (an hence the approximate number of infected individuals).(\textcolor{red}{Do we need a section explaining $Ct$ and qPCR?}) Furthermore, one can argue that the qPCR fluorescence intensity information is inherently semiquantitative~\cite{EM14} as the fluorescence levels and $Ct$ values can be placed into bounded bins determined by the number of cycles. This observation is explained in more detail in the next section, along with new theoretical results pertaining to adaptive SQGT schemes with appropriate noise models.
    
%     % Figure environment removed    

	%\subsection{Threshold GT}
	%An extension of the GT problem was introduced by Damaschke in~\cite{damaschke2006threshold}: In this setting, if the number of defectives in any group is at most the lower threshold $\ell>0$, then the test outcome is negative. If the number of defectives in the group is at least the upper threshold $\emph{u}>\ell$, then the test outcome is positive. However, if the number of defectives in the group is between $\emph{u}$ and $\ell$, the test outcome is arbitrary (i.e., either $0$ or $1$). Thus, the algorithms for Threshold GT are designed to handle worst-case adversarial model errors. Note that when $\ell=0$, and $\emph{u}=1$, Threshold GT reduces to GT. It is known that for nonadaptive threshold GT, $\cO (d\cdot g+2 \cdot (\log d) \log(n/d))$ tests (where $g =\emph{u}-\ell-1$) suffice to identify the $d$ infected individuals~\cite{cheraghchi2013improved}. 

    %The Threshold GT model is partly suitable for modeling the qPCR process, as the lower threshold can obviously assume the role of the fluorescence-based detection threshold, $\ell=Ct$; unfortunately, due to the saturation phenomena, a specialized choice for the upper threshold $\emph{u}$ does not allow one to accurately assess the number of infected individuals in the group. The ``in-between'' threshold results also make the simplistic assumption that despite the observed fluorescence value being closer to the upper threshold, one can still call the outcome negative (and similarly for the small fluorescence levels and the lower threshold). 

    %\subsection{Compressive sensing}
    
    %In compressive sensing, the defectives are represented by nonnegative real-valued entries. Thus, quantitative GT represents a special instance of compressive sensing. Compressive sensing assumes that one is given an unknown vector $\textbf{x} \in \mathbb{R}^n$, in which only $d \ll n$ entries are nonzero. The vector $\textbf{x}$ is observed through linear measurements formed using a measurement matrix $M \in \mathbb{R}^{m \times n}$, leading to an observed vector $\textbf{y} = M\textbf{x}+\textbf{n}$, where $\textbf{n}$ is the measurement noise (usually taken to be Gaussian $\mathcal{N}(0, \sigma^2)$). For noiseless support recovery, $m=\cO(d \cdot \log\,\frac{n}{d})$ measurements are sufficient. For exact support recovery in the noisy setting, a signal-to-noise-ratio $S$ of $\Omega(\log \, n)$ is required for the same number of measurements as needed in the noiseless setting~\cite{aeron2010information}. Compressive sensing reconstruction is possible through linear programming methods or low-complexity greedy approaches~\cite{baraniuk2007compressive,tropp2004greed,dai2009subspace}. 
    
    %The recently proposed Tapestry method~\cite{ghosh2020compressed} combines group testing with compressive sensing and uses combinatorial designs (i.e., Kirkman systems) to construct the measurement matrix. However, the approach does not account for several practical features inherent to quantitative PCR. 
    %Although Tapestry proposes a model that involves multiplicative noise and converts it into additive noise through the use of a logarithmic function, it is still \emph{inherently linear:} Tapestry is based on a CS framework, which is additive and applies \emph{to viral loads}. But as seen from the previous discussion, PCR measurements report intersections of fluorescence level curves and a given threshold, and these values are nontrivial nonlinear functions of the viral load. Additionally, although the compressive sensing measurements used in their the work are assumed to correspond to $Ct$ values, no thresholding is used to model the actual practical process of generating the same\footnote{For many related questions arising in the context of group testing microarrays and quantized compressive sensing, the interested reader is referred to~\cite{dai2008compressive,dai2009comparative,dai2011information}).}. Also, this and all other methods do not account for the stochasticity of the PCR measurements and the fact that different lab protocols may lead to different $Ct$ values when presented with the same sample mixture.  
    %The CS methods in~\cite{ghosh2020compressed} rely on Gaussian assumptions for the cycle inefficiency exponent and do not take into account that the efficiency decays with the number of cycles and with the number of potential mutations in the primer regions. %(see also our analysis in~Section~\ref{bg}).
    %As many other quantitative methods, it also appears vulnerable to heavy hitters. 
    
    %CS-based and many other proposed Covid-19 testing methods also do not take into account the fact that the number of qPCR machines/staff members is limited in virtually all test settings\footnote{PCR tests are performed on samples typically organized within $96$ wells, each of which can be used for one (group) test.}. The unavailability of arbitrary number of PCR machines inherently suggests using adaptive testing strategies. Adaptive quantitative testing schemes for Covid-19 were reported in~\cite{heidarzadeh2020two}. There, the same problem setup as in~\cite{ghosh2020compressed} is used to postulate an additive viral load model in the absence of noise. The new contribution of the work is a proposal for a two-stage testing scheme that bears a small resemblance to our methods in so far that we also propose two-stage adaptive pooling schemes. However, these techniques and the model used are different from ours since~\cite{heidarzadeh2020two} employs a combination of maximum likelihood and maximum-\textit{a-posteriori} estimators to determine the infected individuals in the second stage, while we employ zero-error GT and SQGT techniques to find \textit{all} infected individuals. Additionally, while~\cite{heidarzadeh2020two} reports the number of tests and conditional false positive and conditional false negative rates for the simulation experiments, we supplement our new tailor-made modeling and testing schemes with an in-depth theoretical analysis and performance guarantees. 
    	
    %Nevertheless, there seem to be multiple advantages of CS methods for Covid-19 testing: One should be able, in principle, to recover not only the infected individuals but their viral loads as well (it still remains to be seen as such approaches are feasible as reported experiments use controlled concentrations of viral loads~\cite{ghosh2020compressed}). In particular, integer and nonnegative CS testing, along with quantized CS approaches can impose model restrictions on such testing schemes~\cite{dai2009comparative,DM09IntegerCS} to render them more suitable for the problem at hand. 
	
	%\subsection{Graph-constrained GT}
	
%	Let $\mathcal{G} = \{ V,E \}$ be a graph with vertex set $V$, $|V| =n$, and edge set $E$, representing a connected network of $n$ people out of whom $d$ are infected. In graph-constrained GT, vertices participating in the same test are restricted to form a path in the graph~\cite{cheraghchi2012graph}. This model is relevant as it can be adapted to require that only individuals that did not have contacts with each other are tested together (one only has to apply the problem to the dual of the contact graph used in Covid-19 testing). This allows us to identify individuals that fell ill in an ``independent'' fashion rather than through contact with each other. If $T(n)$ denotes the mixing time of the random walk on the graph, and $c=\frac{\Delta_{max}}{\Delta_{min}}$ is used to denote the ratio between the maximum degree and the minimum degree of the graph, then no more than $\cO( c^4 \cdot d^2 \cdot T^2(n) \log (n/d) )$ tests are required to find the set of infected vertices. For example, a complete graph ($T(n) =1, c=1$) requires no more than $\cO (d^2 \cdot \log(n/d))$ tests since it corresponds to the classical GT regime. Unfortunately, graph-constrained GT requires a significantly higher number of tests than classical GT methods as the tests are inherently restricted. As a result, despite the fact that this scheme is a natural choice for problems such as network tomography where these constraints need to be satisfied, it is not a proper choice for Covid-19 testing. Another ``community-constrained'' (although without an underlying interaction graph) was recently proposed in~\cite{nikolopoulos2020community} and is discussed in the next subsection. 	
	
 %   \subsection{Community-aware GT}
    
  %  Several lines of work have focused on what is now known under the name of \emph{community-aware GT}. In~\cite{nikolopoulos2020community, ahn2021adaptive}, the authors leverage correlations arising due to the presence of community structures to reduce the number of tests and increase the reliability of testing. More precisely, they assume that a community of $n$ members has $d \ll n $ infected individuals and that the population is partitioned into $F$ families. In the combinatorial infection model, it is assumed that $d_f$ families have at least one infected individual and that all the members of the remaining families are infection-free. An infected family indexed by $j$ is assumed to have $d^{(j)}$ infected members so that $d=\sum_{i=1}^{F} \, d^{(j)}$. The testing scheme can be succinctly described as follows: A representative individual from each family is selected uniformly at random. The representative community members are tested using either an adaptive or a nonadaptive GT algorithm. Family members whose representatives tested positive are tested individually. Members from the remaining families are tested together using either an adaptive or a nonadaptive GT scheme. The first approach proposed in~\cite{nikolopoulos2020community} did not account for inter-community interactions, but that issue was subsequently addressed in~\cite{nikolopoulos2020group}.
    
   % In a related line of work, the authors of~\cite{lin2020positively} establish how correlations in samples that arise due to the ordering of the tested individuals in a queue save in terms of pooled testing costs. In particular, the authors assume that in the first stage of Dorfman's testing scheme, the samples that are pooled and tested together are correlated. They model the correlation through the use of a random arrival process~\cite{lin2020positively}. The expected number of tests required to identify all infected individuals for their modified Dorfman scheme is compared against the expected number of tests required by the classical Dorfman testing scheme in which samples that are tested together are picked at random. The authors show that under certain conditions, the expected number of tests required by the modified Dorfman testing scheme does not exceed the expected number of tests required by the original scheme. Under additional conditions, the authors derive a closed form expression that captures the savings available for correlated samples. Furthermore,~\cite{lin2020positively} considers an underlying social contact graph, and  proposes an hierarchical agglomerative algorithm to identify individuals to be pooled together in the first stage of the modified Dorfman testing scheme. This line of work is closely related to the problem of identifying bursts of defectives, first introduced in~\cite{Colbourn1999Group} and analyzed for the case of a single burst.
    
    %We take a different approach to using community-structures for GT in so far that we suggest to \emph{quickly identify heavily infected (heavy hitter) families and then quarantine members of such communities.} To the best of our knowledge, this is the first GT problem formulation that also takes into account strategies for mitigating the spread of a disease, such as self-isolation.% We address this question in the context of classical GT in Section~\ref{ongoing}.
    
    %Before proceeding with the original contributions, we remark that all the above GT techniques and scheduling models have \textit{probabilistic counterparts} in which each individual is assumed to be infected with the same probability $p$~\cite{Dor43} or members of different communities are infected with different probabilities, $p_i$, $i=1,\ldots,F$~\cite{hwang1975generalized}. The latter setting is especially important when prior information about the individuals is known (for example, their risk groups, potential symptoms etc). For an excellent in-depth review of these and some other GT schemes, the interested reader is referred to~\cite{AJS19}.
    %%%%%%%%%%%%%%%%%%

% \section{AC-DC: new amplification curve based adaptive schemes - the probabilistic setting } \label{twostage}

%     Next, we introduce two adaptive SQGT schemes, one which is suitable for probabilistic testing and another one that is worst-case and nearly-optimal from the information-theoretic perspective. In the former case, considered in this section, a simple two-stage testing scheme is designed and analyzed with the goal of enabling practical implementations of adaptive SQGT. The results are described for two thresholds only, but a generalization is straightforward. This scheme also allows for incorporating heavy hitters into the testing scheme, which is of great practical relevance. In the worst-case, which is considered in the section to follow, the schemes extend the 
%     ideas behind Hwang's generalized splitting~\cite{H72} in two directions that lead to algorithms  using what we call \emph{parallel} and \emph{deep search}, respectively. (\textcolor{red}{Remove these lines about parallel and deep search or add a reference to AC-DC on archive?}) In both settings, the outcomes of the first round of testing inform the choice of the composition of the test in the rounds to follow. The methods are collectively referred to as the AC-DC schemes, in reference to the use of the information provided by the amplification curve (AC) during the process of diagnostics of Covid-19 (DC). A relevant observation is that the worst-case adaptive schemes allow for using \emph{nonuniform amounts of genetic material from different individuals,} which may be interpreted as using \emph{nonbinary test matrices.}

%     \subsection{Practical adaptive AC-DC schemes} \label{sec:practical} We describe next a simple probabilistic two-stage AC-DC scheme that significantly improves upon the original single-pooling scheme of Dorfman and builds upon the SQGT framework. The underlying idea is to follow the same overall strategy as in the single-pooling scheme, but exploit the SQ information obtained in the first stage to perform better-informed testing in the second stage (i.e., dispense with individual testing of all individuals that feature in infected groups as part of the second stage).
	
% 	Consider a scenario where we have access to semiquantitative tests that return one of three values: If no individual featured in the test is positive, the test returns $0$. If between $1$ and $\tau$ individuals are positive, for some threshold $\tau \geq 1$, the test returns $1$. Finally, if more than $\tau$ individuals test positive, the test returns $2$. This scheme can be interpreted as follows: Suppose that $Ct$ is the observed cycle thresholds. If $Ct > c_1$ for some large threshold $c_1$, we say that the outcome is $0$ as the potential viral or viral-like contamination load is too small to claim the presence of an infected individual. If $c_2 \leq Ct \leq c_1$, we say that the output is $1$ and based on the average viral load, convert this into the maximum possible number of infected individuals $\tau$. If $Ct < c_2$, we say that the output is $2$ and that more than $\tau$ individuals in the group are affected.
	
% 	For the new single-pooling AC-DC scheme, we assume that the population contains $n$ individuals, each of which is independently positive with some probability $p$ (Which can be easily determined based on regional infection rate reports: For example, at UIUC in September/October 2020~\cite{uiuctesting}, $p\simeq 0.05$), and proceed as follows:
% 	\begin{enumerate}
% 		\item \textbf{Stage 1:} Divide the $n$ individuals into $n/s$ disjoint groups $\cS_1,\dots,\cS_{n/s}$, each of size $s$;	
% 		\item \textbf{Stage 2:} \\
% 		\quad \quad  If a group $\cS_i$ tests $0$, then immediately set the status of all individuals $\in\cS_i$ as ``negative''. \\	
% 		\quad \quad If a group $\cS_i$ tests $1$, then apply a nearly-optimal zero-error nonadaptive group testing scheme to detect the $t$ infected individuals in $\cS_i$. (Such a testing scheme is simple to design: It suffices to sample a random binary matrix where all entries are i.i.d.\ according to some Bernoulli$(q)$ distribution, $0<q<1$. This is so since the resulting matrix will be a zero-error NAGT scheme with high probability provided the number of rows is large enough.) \\
% 		\quad \quad If a group $\cS_i$ tests $2$, then test all individuals $\in\cS_i$ separately.
% 	\end{enumerate}
% 	Given the description above we can compute the expected number of tests per individual of the testing scheme, $T/n$, as a function of the probability of infection $p$, the first-stage group size $s$, and the threshold $\tau$.
% 	Using the fact that the zero-error nonadaptive GT schemes we use in the second stage can be designed with $m(s,\tau)=c\cdot \tau^2\log(s/\tau)$ tests, we conclude that
% 	\begin{equation}\label{eq:expsqgt}
% 	\E[T/n]=\frac{1}{s}+p_1\cdot \frac{c\cdot \tau^2\log(s/\tau)}{s}+p_2,
% 	\end{equation}
%     where $p_1=\Pr[1\leq B(s,p)\leq \tau]$ and $p_2=\Pr[B(s,p)> \tau+1]$ denote the probability that a given group tests $1$ and~$2$, respectively. Here, $B(s,p)$ stands for a binomial random variable with $s$ trials and success probability $p$.
    	
%     A particular case of interest pertains to setting $\tau=1$ in~\eqref{eq:expsqgt}. For a small probability of infection $p$, the optimal threshold $\tau$ is close to $1$ which justifies this choice. In this case, we have $p_1=s\cdot p(1-p)^{s-1}$ and $p_2=1-(1-p)^s-s\cdot p(1-p)^{s-1}$. Moreover, it is well-known that, for any $s$, there exists a simple (and optimal) zero-error nonadaptive scheme for finding $1$ defective among $s$ items using $m(s,1)=\lceil \log s\rceil$ tests (namely, set the $i$-th column of the test matrix to be the binary representation of $i$, i.e., use a Hamming code parity-check matrix for testing).
% 	Combining these observations together with~\eqref{eq:expsqgt}, we conclude that the expected number of tests per individual when $\tau=1$ equals
% 	\begin{equation}\label{eq:expsqgt1}
% 	\frac{1}{s}+p(1-p)^{s-1}\lceil \log s\rceil+1-(1-p)^s-s\cdot p(1-p)^{s-1}.
% 	\end{equation}	
%     On the other hand, the expected number of tests per individual for the basic single-pooling scheme~\cite{Dor43} is
% 	\begin{equation}\label{eq:expsp}
% 	\frac{1}{s}+1-(1-p)^s,
% 	\end{equation}
% 	and the expected number of tests per individual for the double-pooling scheme~\cite{BK20} is
% 	\begin{equation}\label{eq:expdp}
% 	\frac{2}{s}+p+(1-p)(1-(1-p)^{s-1})^2.
% 	\end{equation}	
% 	We compare the optimal expected number of tests per individual (as a function of $p$) achieved by our semiquantitative single-pooling scheme with $\tau=1$ (given in~\eqref{eq:expsqgt1}) and the single- and double-pooling schemes (given in~\eqref{eq:expsp} and~\eqref{eq:expdp}, respectively) in Figure~\ref{fig:comp-sp-dp-sqsp}. Semiquantitative single-pooling outperforms the other methods considered here as shown in the figure. This is in particular true for $p\leq 0.05,$ which we already pointed out corresponds to a practical parameter value. 
% 	% Figure environment removed	
	
% 	There are two directions to further improve our scheme:
% 	\begin{itemize}
% 		\item We can easily extend the simple ideas presented above to obtain a semiquantitative version of double-pooling, and, more generally, multi-pooling schemes. The algorithm for this setting is summarized below:
% 	\begin{enumerate}
% 		\item \textbf{Stage 1:} Repeat Stage 1 of the previous semiquantitative scheme twice in parallel. We say an individual tests $(a,b)$ if its first group tests $a$ and its second group tests $b$.
% 		\item \textbf{Stage 2:} \\
% 		\quad \quad If an individual tests $(0,b)$ or $(a,0)$, immediately mark it as negative; \\
% 		\quad \quad If an individual tests $(1,1)$ or $(1,2)$, then apply a zero-error nonadaptive GT scheme for $\tau$ defectives to its first group. \\
% 		\quad \quad If an individual tests $(2,1)$ or $(2,2)$, test them individually.
% 	\end{enumerate}
% 		\item We may also improve the performance of our semiquantitative scheme by introducing more (sufficiently small) thresholds $\tau_1<\tau_2<\cdots<\tau_\ell$ and extending the original idea in a natural way: If a group has between $\tau_{i-1}$ and $\tau_i$ infected individuals, then apply a nearly-optimal zero-error NAGT scheme that detects $\tau_i$ infected to the group in question.
% 	\end{itemize}

%\clearpage makes sure that all above content is printed at this point and does not invade into the upcoming content
%\clearpage


\pagebreak
%\setcounter{page}{1}
\setcounter{figure}{0}
\renewcommand{\figurename}{Supplement Figure}
{\Large
%\textbf\newline{Semi-quantitative group testing with a wide range of viral load measurements.}
%\textbf\newline{Supplementary Information}%with adjusted qPCR thresholds and improved testing efficiency}%low false negative rates.}
}
\section{Supplementary Information}
\subsection{Supplementary Figures}
% Figure environment removed


    \subsection{Analysis of GT models}\label{supp:modelGT}

    Group testing (GT) schemes based on binary test outcomes, positive $(1)$ or negative $(0),$ and using single~\cite{dorfman1943detection} or multiple rounds~\cite{berger1998bounds} of pooling can be mathematically analyzed in a straightforward manner. Once again, we consider a population of $n$ individuals and denote the fraction of infected individuals by $p$. We also assume that the test results are accurate, i.e., the FNR and FPR are identically zero.

    For the single-pooling Dorfman's GT, we randomly split the $n$ individuals into groups of size $g$. Let $E[T/n]$ be the expected number of tests performed per individual under this scheme. In the first stage, we use $n/g$ tests, resulting in $1/g$ tests per individual. In the second stage, individuals in groups with a positive outcome are tested individually, and the rest are declared as ``not infected". A group test outcome is positive if at least one infected individual is among the $g$ individuals in the group, which occurs with a probability of $1-(1-p)^g.$ Therefore the expected number of tests per individual in the second stage is $$0*(1-p)^g + 1*(1-(1-p)^g) = 1-(1-p)^g,$$
    and the expected number of tests per individual for the entire scheme is
    $$E[T/n] = \frac{1}{g} + 1-(1-p)^g.$$

    We can perform a similar analysis for a double-pooling scheme. We group the individuals into groups of size $g$ such that each individual contributes to two different groups. This can either be achieved via two random permutations of the list of individuals, similar to SQGT, or via a 2D array of wells with appropriately chosen dimensions, as described in~\cite{berger1998bounds}. Therefore, for each individual, we have a pair of test outcomes. If both the test outcomes are positive $(1),$ we test individually otherwise we declare the individual as not infected.

    In the first stage, we use $2n/g$ tests, resulting in $2/g$ tests per individual. In the second stage, an individual is tested if both group tests are positive. We consider two scenarios: the individual is infected with probability $p$, or the individual is not infected with probability $1-p$. If the individual is infected, both groups they contributed to will test positive, leading to testing in the second stage. If the individual is not infected, the group test outcome is positive if and only if at least one other person in the group is infected. For the individual to get tested in the second stage, this condition must hold for both groups they are part of in the first stage. This allows us to calculate the expected number of tests in the second stage as
    $$1*(p + (1-p)(1-(1-p)^{g-1})^2).$$
    Therefore, the expected number of tests per individual is
    $$E[T/n] = 2/g + p + (1-p)(1-(1-p)^{g-1})^2.$$

    This approach can be extended to a multi-pooling strategy, with each individual contributing to more than two group tests. However, such schemes have diminishing returns in the number of tests saved due to substantial overlaps in the groups~\cite{berger1998bounds}.

    Our Semi-Quantitative Group Testing (SQGT) scheme extends the double-pooling strategy by utilizing semi-quantitative information from a qPCR test. This scheme improves performance by avoiding the direct individual testing of low and medium-risk individuals. Under the assumption that the FNR of qPCR testing is zero, our relaxed SQGT scheme (see Results) yields the same results as double-pooling.
    
    \subsection{Probabilistic SQGT with variable viral load}\label{supp:variableload} We analyze how the semi-quantitative scheme 
    performs when infected individuals may have either low or high viral loads. This is relevant to account for heavy hitters, individuals with substantially higher viral loads which can mask infected individuals with low viral loads. To this end, we consider a simplified model where each individual is independently infected and presents a low viral load at the time of testing with probability $p_{i1}$, or is infected and presents a high viral load at the time of testing with probability $p_{i2}.$ In particular, each individual is infected (regardless of their viral load) with total infection probability $p=p_{i1}+p_{i2}<1$.

    Individuals with high viral loads are problematic because, based on the semi-quantitative output of qPCR, groups featuring \emph{one} such individual may be mistaken for groups with \emph{several} infected individuals with low-to-intermediate viral loads.\footnote{This is not problematic for \emph{binary} GT, where the test outcomes do not distinguish between one or several infected individuals in the group.}
    This phenomenon naturally leads us to consider the following modified version of testing: A test applied to a group of individuals has outcome $0$ if there are no infected individuals in the group, outcome $1$ if there exists \emph{exactly} one infected individual with \emph{low} viral load, and $2$ if either there exists more than one infected individual with low viral load or at least one infected individual with \emph{high} viral load. Therefore, as expected, individuals with high viral load obfuscate the test outcomes.

    We assume that the population contains $n$ individuals, each of which is independently positive with some probability $p=p_{i1}+p_{i2}<1$, as explained.  In the first stage, we divide the $n$ individuals into groups of size $g.$ The groups are denoted by $\gamma_1,\gamma_2,\ldots, \gamma_{n/g}.$ In the second stage, we proceed as follows:\\
    \begin{itemize}
        \item If a pool $\gamma_i$ tests $0$, we declare all individuals in $\gamma_i$ as negative. \\
        \item If a pool $\gamma_i$ tests $1$, we apply a nearly-optimal zero-error nonadaptive GT scheme to detect the infected individual.\\
        \item If a pool $\gamma_i$ tests $2$, we test all individuals in $\gamma_i$ separately.\\
    \end{itemize}
    We can compute the expected number of tests per individual of the testing scheme, $E[T/n]$, as a function of the probability of infection $p$ and the first-stage pool size $g$ as follows. 
    First, we observe that for the scheme outlined above, we are guaranteed to have \emph{exactly} $1$ infected individual in any pool that tested $1$. We also know that zero-error nonadaptive GT schemes to detect $\tau$ infected individuals in a group of size $g$ can be designed with $m(g,\tau)=c\cdot \tau^2\log(g/\tau)$ tests for some constant $c>0$.
    %\textcolor{red}{JoÃ£o: Maybe clarify/remark here that in this case (pool tested $1$), we are guaranteed to have \emph{exactly} $1$ infected individual (i.e., it cannot happen that there are no infected individuals). This is why the number of tests is $\lceil\log g\rceil$.}
    As a corollary, we know that for detecting one infected individual, $m(g,1)=\lceil \log g\rceil$ tests are needed. 
    This can be achieved by using a Hamming code parity-check matrix. This gives us the expected number of tests as
    \begin{equation}\label{eq:expsqgt}
	\E[T/n]=\frac{1}{g}+p_1\cdot \lceil \log g\rceil+p_2,
    \end{equation}
    where $p_1$ and $p_2$ denote the probability that a given pool tests $1$ and~$2$, respectively.

    The probability that a group of size $g$ contains exactly one infected individual with low viral load and zero individuals with high viral load (leading to test outcome $1$) is
    \begin{equation*}
    	p_1 = g\cdot p_{i1} \cdot (1-p_{i1}-p_{i2})^{g-1}=g \cdot p_{i1} \cdot (1-p)^{g-1},
    \end{equation*}
    while the probability that the group contains either more than one infected individual with low viral load or at least one individual with high viral load (leading to test outcome $2$) is
    \begin{equation*}
    	p_2 = 1-g \cdot p_{i1} \cdot (1-p_{i1}-p_{i2})^{g-1}-(1-p_{i1}-p_{i2})^g=1-g \cdot p_{i1} \cdot (1-p)^{g-1}-(1-p)^g.
    \end{equation*}
	
    Combining these observations, we conclude that the expected number of tests per individual as a function of $p_{i1}$ and $p_{i2}$ is given by
    \begin{equation}\label{eq:expSQGTviral}
    	\frac{1}{g}+g \cdot p_{i1} \cdot (1-p)^{g-1} \cdot \lceil\log g\rceil +1-g \cdot p_{i1} \cdot (1-p)^{g-1}-(1-p)^g,
    \end{equation}
    where $p=p_{i1}+p_{i2}$.
    
    For fixed $p_{i1}$ and $p_{i2}$, it is easy to numerically minimize the expression above as a function of $g$ to find the optimal group size for the scheme under consideration. On the other hand, the expected number of tests per individual for the basic Dorfman's GT~\cite{Dor43} is
	\begin{equation}\label{eq:expsp}
	\frac{1}{g}+1-(1-p)^g,
	\end{equation}
	and the expected number of tests per individual for a double-pooling scheme with binary tests~\cite{BK20, berger1998bounds} is
	\begin{equation}\label{eq:expdp}
	\frac{2}{g}+p+(1-p)(1-(1-p)^{g-1})^2.
	\end{equation}	
    
    Figures~\ref{fig:comp-sp-dp-sqsp-viral16} and~\ref{fig:comp-sp-dp-sqsp-viralthird} compare the expected number of tests per individual required by various schemes for different values of the total infection probability $p$ and the specific infection probabilities $p_{i1}$ and $p_{i2}$. Clearly, double pooling outperforms Dorfman's single pooling GT strategy, while semi-quantitative testing with single pooling outperforms both single and double pooling in the expected number of tests. SQGT combines the ideas of double pooling and semi-quantitative information from tests to obtain further savings in test results. We do not have a closed-form expression for SQGT due to the complexity of the scheme. However, as reported in the Results, double pooling SQGT provides substantial savings over Dorfman's GT (single pooling) while maintaining low FNR for real-world GT data. %The most practically relevant pair of parameters can be obtained from Figure~\ref{fig:comp-sp-dp-sqsp-viral16}, under the assumption that heavy hitters are individuals who have viral loads above $10^6$. Thus, by approximating the nonlinear portion of the viral load curve by a linear function, one can easily show that the probability that an infected individual is a heavy hitter is proportional to the area of the highlighted triangle, and approximately equal to $0.16$ (which is used in Figure~\ref{fig:comp-sp-dp-sqsp-viral16}). Note that the reduction in the number of tests increases with $p$, and for $p \sim 0.05$, which is a realistic infection rate, the savings compared to nonquantitative testing are larger than $5\%$.

    %Although we considered only a semi-quantitative single-pooling scheme in this section, these ideas can be easily extended to upgrade multi-pooling schemes with binary testing (such as the one from~\cite{BK20}) to exploit SQ test information under a variable viral load. This would allow one to further improve on the expected number of tests required by~\cite{BK20}.

    % Figure environment removed

    % Figure environment removed

    \subsection{Lower bounds for nonadaptive probabilistic SQGT}\label{supp:nonadaptiveSQGT} 
    The main text discusses how to replace the second stage of SQGT with nonadaptive GT. Designing nonadaptive GT schemes reduces to identifying test-matrices that satisfy disjointness or separability properties~\cite{du2000combinatorial}. One such scheme involves sampling a random binary matrix such that every entry is an i.i.d. Bernoulli($q$) random variable with $0<q<1.$ Each row of this matrix defines a pool for group tests. Given sufficiently many rows, this matrix represents a zero-error nonadaptive GT scheme with high probability.
     
    We, therefore, focus on deriving a theoretical result that establishes lower bounds for nonadaptive probabilistic GT that may be used to assess the quality of our adaptive schemes. For this purpose, we adapt an argument by Aldridge~\cite{Ald18} for arbitrarily small error probability under a constant probability of infection.
	More precisely, we consider a setting where each test has $m+1$ outcomes for some $m \geq 1$: The outcome of a test is either $i$ if there are exactly $i$ infected individuals for $i<m$, and $\geq m$ otherwise. This corresponds to the setting introduced in~\cite{d1984generalized} which provides the most informative type of measurements one can expect from the SQGT framework using the amplification curve information. This model accounts for the saturation limit for each test, dictated by $m$, which is a phenomenon observable from the amplification curve. Moreover, as before we assume that each individual in the population of size $n$ is infected independently with some constant probability $p>0$.
	We show the following.
	\begin{thm}\label{thm:lb}
		For every $m$ and constant $p>0$ there exists a constant $\eps(m,p)>0$ such that, under the setting described above, nonadaptive testing requires at least $n/m$ tests to achieve error probability less than $\eps(m,p)$ in a population of size $n$.
	\end{thm}
	In contrast, for $m=2$, our two-stage scheme uses significantly fewer than $n/2$ tests provided $p$ is not very large.
	
	Proving Theorem~\ref{thm:lb} follows by a simple adaptation of an approach by Aldridge~\cite{Ald18}, who showed that individual testing is required in order to achieve arbitrarily small error in regular nonadaptive probabilistic GT (which corresponds to $m=1$).
	First, given any nonadaptive testing scheme, we may without loss of generality remove all tests with $m$ or fewer elements, along with all individuals who participate in those tests. This does not affect the lower bound. Then, we show that there are no nonadaptive testing schemes with an arbitrarily small error where every test includes at least $m+1$ individuals.
	Combining these two observations immediately yields Theorem~\ref{thm:lb}.
	
	For an individual $i$, let $x_i$ denote its infection status.
	Call an individual $i$ (regardless of its infection status) \emph{disguised} if every test $t$ in which it participates contains at least $m$ other individuals which are infected.
	If $i$ is disguised, then changing $x_i$ from $0$ to $1$, or vice-versa, does not change the outcome of the testing scheme.
	As a result, we can do no better than guess $x_i$, and we will be wrong with probability at least $\min(p,1-p)$.
	To finalize the argument, it suffices to show there is a disguised individual with constant probability.
	
	Let $D_i$ denote the event that individual $i$ is disguised, and let $D_{t,i}$ denote the event that individual $i$ is disguised in test $t$.
	Since the $D_{t,i}$ are increasing events\footnote{If $D_{t,i}$ holds and the set of infected individuals is expanded, then $D_{t,i}$ continues to hold under this expanded set.}, the Fortuin-Kasteleyn-Ginibre (FKG) inequality~\cite{fortuin1971correlation} implies that
	\begin{equation}
	\Pr[D_i]\geq \prod_{t:x_{t,i}=1}\Pr[D_{t,i}],
	\end{equation}
	where $x_{t,i}$ indicates whether individual $i$ participates in test $t$.
	Moreover, we have
	\begin{equation}
	\Pr[D_{t,i}]=\Pr[B(w_t-1,p)\geq r],
	\end{equation}
	where $w_t=\sum_{i=1}^n x_{t,i}$ is the weight of test $t$ and $B(w_t-1,p)$ denotes a binomial random variable with $w_t-1$ trials and success probability $p$.
	
	%Let \textcolor{red}{JoÃ£o: very minor, but I guess $\log$ refers to base-$2$. Is that explicitly mentioned anywhere?}
        Let
	\begin{equation*}
	L_i=\log\left(\prod_{t:x_{t,i}=1}\Pr[D_{t,i}]\right)=\sum_{t:x_{t,i}=1}\log \Pr[D_{t,i}]=\sum_{t=1}^T x_{t,i}\log \Pr[D_{t,i}],
	\end{equation*}
	where $T$ denotes the total number of tests, which we assume satisfies $T/n<1$, and $\log$ denotes $\log_2.$
	Then, it suffices to show that there exists some $i^\star$ with $L_{i^\star}>c$ for some constant $c$ independent of $n$.
	Let $I$ be uniformly distributed over $\{1,2,\dots,n\}$, and let $\overline{L}=\E[L_I]$.
	We have
	\begin{align*}
	\overline{L}&=\frac{1}{n}\sum_{i=1}^n \sum_{t=1}^T x_{t,i}\log \Pr[D_{t,i}]\\
	&=\frac{1}{n}\sum_{t=1}^T w_t\log \Pr[D_{t,i}]\\
	&\geq \min_{t=1,\dots,T} w_t\log \Pr[B(w_t-1,p)\geq m]\\
	&\geq\min_{w\geq r+1} w\log \Pr[B(w-1,p)\geq r]=:L^\star,
	\end{align*}
	where the second equality follows from the fact that $\Pr[D_{t,i}]$ is the same for every $i$ such that $x_{t,i}=1$, and in the first inequality we use the assumption that $T/n<1$.
	It is immediate that there exists some $i^\star$ with $L_{i^\star}\geq \overline{L}$, which implies that $\Pr[D_{i^\star}]\geq 2^{L^\star}$.
	Therefore, the error probability of the testing scheme is at least $\eps(m,p)=\min(p,1-p)\cdot 2^{L^\star}$.
	Noting that $L^\star$ does not depend on $n$ and is bounded from below for any $m$ and $p$ concludes the proof (since $\lim_{w\to\infty} w\log \Pr[B(w-1,p)\geq m]=1$). 

    \subsection{Extension of Hwang's model~\cite{hwang1976group} to SQGT}\label{supp:hwangFPR}

    \textbf{Definition of $TPR_1(p,g)$.}
    We can define the conditional probability $TPR_1(p,g)$ following the same idea as in Hwang's paper as 
    \begin{align}
        TPR_1(p,g)&=\P(\text{test score is }1|\text{there is exactly $1$ positive subject in the group})\nonumber\\
        &=\frac{A(p,g)}{g\cdot p\cdot (1-p)^{g-1}},
    \end{align}
    where $A(p,g)$ is chosen such that $TPR_1(k)$ satisfies the following two limit conditions given the infection rate $p<0.5$:
    \begin{align}\label{eq:limits}
        TPR_1(p,1) = 1, TPR_1(p,\infty) = 0.
    \end{align}
    Specifically, $TPR_1(p,\infty) = 0$ holds since there will be only $1$ infection in this group of size infinity. Based on~(\ref{eq:limits}), one simple form of $A(p,g)$ can be $A(k)=p^g$, which implies 
    \begin{align}\label{eq:tpr1}
        TPR_1(p,g)=\frac{p^g}{g\cdot p\cdot (1-p)^{g-1}}.
    \end{align}
    When $g=1, TPR_1(p, 1)=1$; when $g\rightarrow\infty$, $TPR_1(p,g)=\frac{1}{g}(\frac{p}{1-p})^{g-1}$. Since we assume $\frac{p}{1-p}<1$, so $TPR_1(p,\infty)\rightarrow 0$.
    
    When taking the dilution effect into consideration, we introduce the coefficient $d$ as in~\cite{hwang1976group}. When $d=0$, there is no dilution effect, meaning that $TPR_1(p,g)=1$ for every choice of group size $g$; when $d=1$, the dilution is complete and the probability should be of the form~(\ref{eq:tpr1}). Therefore, the final expression for $TPR_1(p,g)$ with dilution effects would be
    \begin{align}\label{eq:tpr1_dilute}
        TPR_1(p,g,d)=\frac{p^{g^{d}}}{g^{d}\cdot p\cdot (1-p)^{g^{d}-1}}.
    \end{align}
    
    \noindent\textbf{Definition of $TPR_2(p,g)$.}
    We can define the conditional probability $TPR_2(p,g)$ as 
    \begin{align}
        TPR_2(p,g)&=\P(\text{test score is 1 or 2}|\text{there are at least $2$ positive subjects in the group})\nonumber\\
        &=\frac{B(k)}{1-(1-p)^g-g\cdot p\cdot (1-p)^{g-1}}.
    \end{align}
    The two limit conditions are
    \begin{align}\label{eq:limits2}
        TPR_2(p,2) = 1, TPR_2(p,\infty) = p.
    \end{align}
    It is worth pointing out that the limiting of $TPR_2(p,\infty)$ is very different from $TPR_1(p,\infty)$, since now there can be many infections in this huge group, so the limiting probability will be approximately the probability of sampling a subject from the population uniformly at random and the subject being positive. In this case, we can have 
    \begin{align}\label{eq:tpr2}
        TPR_2(p,g)=\frac{p^{1+2/g}}{1-(1-p)^g-g\cdot p\cdot (1-p)^{g-1}}.
    \end{align}
    It is easy to check that the limits~(\ref{eq:limits2}) hold for $TPR_2(p,g)$.
    % When $g=2$, $1-q^2-2pq=p^2$ and when $k\rightarrow\infty$, $1-q^k-k\cdot p\cdot q^{k-1}\rightarrow 1$. 
    
    When taking the dilution effect into consideration, we can again make use of the dilution coefficient $d$. The final expression for $TPR_2(p,g,d)$ would be
    \begin{align}\label{eq:tpr2_dilute}
        TPR_2(p,g,d)=\frac{p^{1+(g/2)^{-d}}}{1-(1-p)^{2(g/2)^{d}}-2(g/2)^{d}\cdot p\cdot (1-p)^{2(g/2)^{d}-1}}.
    \end{align}
    
    \noindent\textbf{Expected cost.}
    With $TPR_1(p,g,d)$ and $TPR_2(p,g,d)$, we can compute the expected cost of one round of SQGT test. The expected number of infections in a group, when there is only $1$ infection in the group, is always $1$. Meanwhile, the expected number of infections in a group, when there are at least $2$ infections in the group and the group size is $g$, is 
    \begin{align*}
        \E(\text{infections}|\text{\# of infections}\geq 2)&=\sum_{i=2}^g i\cdot \P(\text{\# of infections = }i|\text{\# of infections}\geq 2) \\
        &=\frac{\sum_{i=2}^g i\cdot \P(\text{\# of infections = }i)}{\P(\text{\# of infections}\geq 2)}.
    \end{align*}
    Note that $\sum_{i=0}^g i\cdot \P(\text{\# of infections = }i)=pg$ based on the binomial distribution, so $\sum_{i=2}^g i\cdot \P(\text{\# of infections = }i)=pg-pg(1-p)^{g-1}=pg(1-(1-p)^{g-1})$. We have
    \begin{align}
        \E(\text{infections}|\text{\# of infections}\geq 2)=\frac{pg(1-(1-p)^{g-1})}{1-(1-p)^g-pg(1-p)^{g-1}}.
    \end{align}
    So the total expected cost is
    \begin{align*}
        E_{\text{cost}}(g)=&\;\frac{n}{g}\cdot (\text{expected cost for each group of size } g)\\
        =&\;\frac{n}{g}\cdot \big\{1+pg(1-p)^{g-1}\left(TPR_1(p,g,d)\cdot g+(1-TPR_1(p,g,d))\cdot c\right)+\\
        &(1-(1-p)^g-pg(1-p)^{g-1})(TPR_2(p,g,d)\cdot g+\\
        &(1-TPR_2(p,g,d))\cdot c\cdot \E(\text{infections}|\text{\# of infections}\geq 2))\big\},
    \end{align*}
    where $c$ is the cost if we misidentify a positive group, and for simplicity set the lab cost for each test to $\$1$. By taking the derivative of $E_{\text{cost}}(g)$ to $0$ we can get the optimal group size $g$ in this case.
    
    % \subsection*{Data description}
    % The real-world COVID-19 group testing data~\cite{barak2021lessons} used in this paper contains $133,816$ samples collected between April and September 2020 in Israel and tested by Dorfman pooling. The original data contains the following information for each individual sample:
    % \begin{itemize}
    %     \item Sample id: A unique id for tracking the sample;
    %     \item Month: Month information about when this sample is taken;
    %     \item Group id: An id indicating which group it belongs to during the group testing procedure. Samples within the same group share the same group id, and the dataset contains groups of sizes $5$ and $8$;
    %     \item Result: Final result for this sample (positive/negative);
    %     \item Sample viral $Ct$: $Ct$ value of the individual test. Note that this value is not available when the group test is negative;
    %     \item Group viral $Ct$: $Ct$ value of the group test for the group it belongs to;
    %     \item Sample human $Ct$: $Ct$ value of the individual test for amplifying human ERV-3~\cite{yuan2001quantification} gene exceeding some threshold. This value serves as an internal control to determine whether a test is successful or not;
    %     \item Group human $Ct$: $Ct$ value of the group test for amplifying human ERV-3 gene exceeding some threshold.
    % \end{itemize}

    % As mentioned in our Results Section, there exists a small amount of ``inconsistency'' between the group test results and the individual test results. Specifically, the results of the group tests are positive while all individuals within the groups get negative test results. These results can correspond to either a false positive for the group test, or a false negative for the individual tests, and we used this information to model the FNR in the dataset as shown in our Results Section. Note that for simplicity we consider there exists only one positive individual sample within the group when false negative appears, as this is the most probable case, we use (Group viral $Ct-\log(g)$) as the true $Ct$ value for the individual test where false negative happens, where $g$ is the group size.

\newpage
\end{document}

