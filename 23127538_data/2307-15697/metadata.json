{
  "title": "Aligned Unsupervised Pretraining of Object Detectors with Self-training",
  "authors": [
    "Ioannis Maniadis Metaxas",
    "Adrian Bulat",
    "Ioannis Patras",
    "Brais Martinez",
    "Georgios Tzimiropoulos"
  ],
  "submission_date": "2023-07-28T17:46:00+00:00",
  "revised_dates": [
    "2024-07-07T10:46:52+00:00"
  ],
  "abstract": "The unsupervised pretraining of object detectors has recently become a key component of object detector training, as it leads to improved performance and faster convergence during the supervised fine-tuning stage. Existing unsupervised pretraining methods, however, typically rely on low-level information to define proposals that are used to train the detector. Furthermore, in the absence of class labels for these proposals, an auxiliary loss is used to add high-level semantics. This results in complex pipelines and a task gap between the pretraining and the downstream task. We propose a framework that mitigates this issue and consists of three simple yet key ingredients: (i) richer initial proposals that do encode high-level semantics, (ii) class pseudo-labeling through clustering, that enables pretraining using a standard object detection training pipeline, (iii) self-training to iteratively improve and enrich the object proposals. Once the pretraining and downstream tasks are aligned, a simple detection pipeline without further bells and whistles can be directly used for pretraining and, in fact, results in state-of-the-art performance on both the full and low data regimes, across detector architectures and datasets, by significant margins. We further show that our pretraining strategy is also capable of pretraining from scratch (including the backbone) and works on complex images like COCO, paving the path for unsupervised representation learning using object detection directly as a pretext task.",
  "categories": [
    "cs.CV"
  ],
  "primary_category": "cs.CV",
  "doi": null,
  "journal_ref": null,
  "arxiv_id": "2307.15697",
  "pdf_url": "https://arxiv.org/pdf/2307.15697v2",
  "comment": null,
  "num_versions": null,
  "size_before_bytes": 34827462,
  "size_after_bytes": 396302
}