% SIAM Article Template
% \documentclass[review,onefignum,onetabnum]{siamonline220329}
\documentclass[final,onefignum,onetabnum]{siamonline220329}

\usepackage{amsmath}  
\usepackage{mathrsfs}
\newtheorem{rem}{Remark}
\usepackage{amsfonts}
\usepackage{epstopdf}
\usepackage{graphicx}
\usepackage{url}
\usepackage{dsfont}
\usepackage{xcolor}
\usepackage{subcaption}
\usepackage{setspace}
% \linespread{3.0}  
\linespread{1.15}  
\usepackage{booktabs}
\usepackage{tablefootnote} % for table footnotes
\usepackage{lineno}
\usepackage{soul}
% \usepackage{graphicx}
% \usepackage{subfigure}
%\usepackage[pagewise]{lineno}


% \DeclareMathAlphabet\mathpzc{OT1}{pzc}{m}{it}
% \let\mathcal=\mathpzc
\def\E{{\mathbb E}}
\def\P{{\mathbb P}}
\def\dis{{\mathcal{D}}}
\def\pr{{\mathrm{pr}}}
\def\erf{{\mathrm{erf}}}
\let \ra = \rightarrow
\let \la = \leftarrow
%\numberwithin{equation}{section}
\newcommand\deriv[3][]{\frac{d^{#1}#2}{d{#3}^{#1}}}
\newcommand\partialderiv[3][]{\frac{\partial^{#1}#2}{\partial{#3}^{#1}}}
\def\Real{{\mathbb R}}
\def\Complex{{\mathbb C}}
\def\F{{\cal F}}
\let\<=\langle
\let\>=\rangle
%\let\^=\hat
%\def\~#1{{\-ox{\sf#1}}}
\def\~#1{{\mbox{#1}}}
\def\N{{\mathbb N}}
\def\R{{\mathbb R}}
\let\-=\mathbf
\def\sech{\mathop{\rm sech}\nolimits}
\def\Re{\mathop{\rm Re}\nolimits}
\def\Im{\mathop{\rm Im}\nolimits}
\def\bolde{{\boldsymbol\epsilon}}
\def\o#1{^{(#1)}}
\def\txtfrac#1#2{{\textstyle\frac{#1}{#2}}}
\def\circ{\ifmmode\mathchar"220E\else$\mathchar"220E$\fi}
%\catcode`\@ 13
\def\@#1{{\mathcal #1}}
\usepackage[inline]{enumitem}
\setlength{\fboxsep}{1pt}
\newcommand{\colorline}[1]{\hspace{-0.03\linewidth}\colorbox{xkcdWine!30}{\makebox[0.99\linewidth][l]{#1}}}
%\algnewcommand{\LineComment}[1]{\Statex \(\triangleright\) #1}
\newcommand \red [1]{\textcolor{red}{#1}} 

\newcommand{\billy}[1]{{\color{purple}{Billy: #1}}}
%\newcommand{\ok}[1]{{\color{blue}{#1}}}
\newcommand{\ok}[1]{{{#1}}}
\newcommand{\zqp}[1]{{\color{blue}{#1}}}

\usepackage{threeparttable}
\usepackage{diagbox}
% Packages and macros go here
\usepackage{lipsum}
\usepackage{amsfonts}
\usepackage{graphicx}
\usepackage{multirow}
\usepackage{epstopdf}
\usepackage{amsopn}
\DeclareMathOperator{\diag}{diag}
%\usepackage{algorithm2e}
\usepackage{algorithm}
\usepackage{algpseudocode,float}
\ifpdf
  \DeclareGraphicsExtensions{.eps,.pdf,.png,.jpg}
\else
  \DeclareGraphicsExtensions{.eps}
\fi

% Prevent itemized lists from running into the left margin inside theorems and proofs
\usepackage{enumitem}
\setlist[enumerate]{leftmargin=.5in}
\setlist[itemize]{leftmargin=.5in}

% Add a serial/Oxford comma by default.
%\newcommand{\creflastconjunction}{, and~}
% Used for creating new theorem and remark environments
\newsiamremark{remark}{Remark}
\newsiamremark{hypothesis}{Hypothesis}
\crefname{hypothesis}{Hypothesis}{Hypotheses}
\newsiamthm{claim}{Claim}
\usepackage{amsmath}               
  {
      \theoremstyle{plain}
      \newtheorem{assumption}{Assumption}
  }

% Sets running headers as well as PDF title and authors
\headers{DuNets-RMA}{}

% Title. If the supplement option is on, then "Supplementary Material"
% is automatically inserted before the title.
\title{Deep Unrolling Networks with Recurrent Momentum Acceleration for Nonlinear Inverse Problems
\thanks{Submitted to the editors 2023-08-xx.
\funding{The work of the authors was supported by the NSF of China (12101614) and NSF of Hunan (2021JJ40715). 
% xxx founder id
}
}
}

% Authors: full names plus addresses.
 \author{Qingping Zhou\thanks{School of Mathematics and Statistics, HNP-LAMA, Central South University, 932 South Lushan Rd, Hunan 410083, China, (\email{qpzhou@csu.edu.cn, jyqian@csu.edu.cn})}.
 \and Jiayu Qian\footnotemark[2]
 \and Junqi Tang\thanks{School of Mathematics, University of Birmingham, Edgbaston, Birmingham B15 2TT, UK, (\email{j.tang.2@bham.ac.uk})}.
 \and Jinglai Li\thanks{Corresponding author. School of Mathematics, University of Birmingham, Edgbaston, Birmingham B15 2TT, UK, (\email{j.li.10@bham.ac.uk})}.
 }



% Optional PDF information
\ifpdf
\hypersetup{
  pdftitle={DuNets-RMA for NIP},
  pdfauthor={Qingping Zhou, Jiayu Qian, Junqi Tang, Jinglai Li}
}
\fi
% \let\nofiles\relax  

\begin{document}
\maketitle
% \tableofcontents

% REQUIRED
\begin{abstract}
Combining the strengths of model-based iterative algorithms and data-driven deep learning solutions, deep unrolling networks (DuNets) have become a popular tool to solve inverse imaging problems.
While DuNets have been successfully applied to many linear inverse problems, nonlinear problems tend to impair the performance of the method. 
Inspired by momentum acceleration techniques that are often used in optimization algorithms, we propose a  recurrent momentum acceleration (RMA) framework that uses a long short-term memory recurrent neural network (LSTM-RNN) to simulate the momentum acceleration process. The RMA module leverages the ability of the LSTM-RNN to learn and retain knowledge from the previous gradients. 
We apply RMA to two popular DuNets -- the learned proximal gradient descent (LPGD) and the learned primal-dual (LPD) methods, 
resulting in LPGD-RMA and LPD-RMA respectively. We provide experimental results on two nonlinear inverse problems: a nonlinear deconvolution problem, and an electrical impedance tomography problem with limited boundary measurements. In the first experiment we have observed that the improvement due to RMA largely increases with respect to the nonlinearity of the problem. The results of the second example further demonstrate that the RMA schemes can significantly improve the performance of DuNets in strongly ill-posed problems. 
\end{abstract}

% REQUIREDFan 
\begin{keywords}
inverse problems, deep unrolling networks, momentum acceleration, learned primal-dual, learned proximal gradient descent, recurrent neural network 
\end{keywords}

% REQUIRED
\begin{MSCcodes}
68U10, 94A08, 68T99
\end{MSCcodes}

% \linenumbers
% --------------------------------------------------
\newpage
\section{Introduction}\label{sec:intro}
Many image processing tasks can be formulated as an inverse problem, i.e., to recover an unknown image  $x$ from indirect measurements $y$
\begin{equation}\label{eq:forward}
y=\mathcal{A} (x)+\epsilon, 
\end{equation}
where $\mathcal{A}$ represents a forward measurement operator and $\epsilon$ is the observation noise. %denotes a sample drawn from a noise distribution that may depend on the ideal measurement $\mathcal{A}(x)$.
Problems that can be formulated with Eq.~\eqref{eq:forward} include denoising~\cite{houdard2018high}, compressive sensing~\cite{zhang2018ista}, computed tomography reconstruction~\cite{adler2018learned,baguer2020computed}, phase retrieval~\cite{shechtman2015phase}, optical diffraction tomography~\cite{sung2009optical}, 
electrical impedance tomography~\cite{seo2019learning,colibazzi2022learning} and so on.

A common challenge in these problems is their ill-posedness due to measurement noise and undersampling, which indicates that finding a unique solution stably ranges from difficult to impossible without using {regularization techniques}  about the problem. {Classical regularization techniques} could obtain accurate and stable solutions by
formulating variational regularization problems and then solving them with iterative algorithms, such as the alternating direction method of multipliers (ADMM)~\cite{boyd2011distributed} and the primal-dual hybrid gradient (PDHG) method~\cite{chambolle2011first}. 
{Although these methods can provide stable estimations of the true solutions, they have a number of limitations}: slow convergence, the requirement of parameter tuning, and mathematical inflexibility. To compensate for these deficiencies,~\cite{gregor2010learning,adler2017solving,adler2018learned,monga2021algorithm} modified the classical iterative scheme by replacing certain modules in the iterative procedure for variational regularization problems with deep neural networks.

Over the past few years, deep unrolling networks (DuNets), which was pioneered by Gregor and LeCun in~\cite{gregor2010learning},
have obtained great empirical success in the field of inverse problems and image processing~\cite{zhang2018ista,adler2018learned,zhang2019dynamically,hosseini2020dense,xiang2021fista,monga2021algorithm,colibazzi2022learning,tang2022accelerating}. 
Intuitively, \ok{an unrolling model} is obtained by replacing certain modules in the iterative procedure for variational regularization problems with deep neural networks.
DuNets combines traditional model-based optimization algorithms with learning-based deep neural networks, yielding an interpretable and efficient deep learning framework for 
solving inverse imaging problems. 
It should be noted that most of the aforementioned studies have focused on solving the problem~\eqref{eq:forward} with linear or linearized forward operators. 
On the other hand, there has been relatively little research on applying DuNets to nonlinear imaging problems, such as optical diffraction tomography and electrical impedance tomography.
This paper attempts to bridge this gap 
by investigating DuNets for solving nonlinear problems.
ch problems nonlinearity typically poses
additional difficulty for the DuNets methods and makes their performance less effective. 
In this work we will draw on momentum acceleration (MA), an efficiency-improving strategy commonly used in optimization algorithms, and the recurrent neural networks (RNN) techniques to \ok{improve the performance} of the deep unrolling networks. 
Specifically, we propose a recurrent momentum acceleration (RMA) module that utilizes a long short-term memory recurrent neural network (LSTM-RNN) to simulate momentum acceleration accurately. The RMA module exploits the LSTM-RNN's capacity  to remember previous inputs over extended periods and learn from them, thereby providing 
information from the previous gradients. 
Compared to the classical momentum acceleration, RMA allows a more flexible formulation to incorporate the gradient history, 
%relationship between the previous gradients and the current one,
and therefore, as will be illustrated by the numerical experiments, can provide better performance than the classical methods. 
As is illustrated by the numerical experiments, RMA can substantially outperform the classical momentum acceleration models in DuNets,
which is mainly due to the fact that both the relationship between the previous update and the new gradient term and the momentum coefficients are learned from the data.
In light of this, we apply the RMA approach to the two popular DuNets: the learned proximal gradient descent (LPGD)~\cite{mardani2018neural} based upon the proximal gradient descent algorithm and the learned primal-dual (LPD)~\cite{adler2018learned} upon the primal-dual hybrid gradient algorithm, resulting in the formulation of our new LPGD-RMA and LPD-RMA approaches, respectively. %\ok{, which we will introduce in the next sections}.
It should be noted that several existing works propose to use the iteration history to improve the performance of the unrolling algorithms.
 For example,  \cite{adler2018learned} proposes to extend the state space to allow the
algorithm some ``memory'' between the iterations; 
\cite{hosseini2020dense} develops a history-cognizant unrolling of the proximal gradient descent where the outputs of all the previous regularization units
are used for improved performance. 
As a comparison, our RMA method employs the previous gradients that are combined via a flexible RNN model. 

The remainder of this paper is organized as follows. In section~\ref{sec:DuNets}, we review two widely used types of deep unrolling models: the LPGD and LPD methods. In section~\ref{sec:DuNets-RMA}, we present our RMA formulation, and incorporate it with both LPGD and LPD, yielding LPGD-RMA and LPD-RMA. 
Numerical experiments performed on two nonlinear inverse problems are reported in section~\ref{sec:exp}. 
Finally section~\ref{sec:conclusion} gives some concluding remarks.

\section{Deep unrolling networks}\label{sec:DuNets}
\ok{We start by introducing the variational optimization methods for solving inverse problems of the form~\eqref{eq:forward}}. 
\ok {These methods seek to solve the following minimization problem} by balancing a data consistency term $\mathcal{D}(\cdot,\cdot): Y \times Y \rightarrow \mathbb{R}$ against a regularization term $\@R(\cdot): X \rightarrow \mathbb{R}$:
\begin{equation}\label{eq:optim}
\underset{x \in X}{\arg \min }~
\mathcal{D}(\mathcal{A}(x), y)
+
\lambda \mathcal{R}(x),
\end{equation}
where $x\in X$, $y\in Y$ and $\lambda$ is a positive parameter balancing $\mathcal{R}$ against $\mathcal{D}$.
This regularizer often encodes the prior information on $x$ representing desired solution properties. Common regularization functions include Tikhonov regularization, total variation, wavelets, and sparsity promoting dictionary~\cite{benning2018modern}, to name a few.  Besides Tikhonov regularization, all the others are non-smooth,
and as a result Eq.~\eqref{eq:optim} is typically solved by the first-order algorithms, such as proximal gradient descent algorithm~\cite{combettes2011proximal}, variable splitting scheme~\cite{boyd2011distributed} and primal-dual hybrid gradient (PDHG) method~\cite{chambolle2011first}. 
In order to deal with the nonsmoothness, all the aforementioned algorithms involve a rather expensive and complex updating procedure in each iteration. 
Loosely speaking, DuNets use a learned operator represented by a deep neural network to model the iterative update of these optimization algorithms. We here focus on two archetypes of the deep unrolling models: the LPGD method with both sharing \cite{mardani2018neural,lohit2019unrolled} and independent weights~\cite{gupta2018cnn,cherkaoui2020learning}, and the LPD method~\cite{adler2018learned}. 

\subsection{Learned proximal gradient descent method}
The proximal gradient descent (PGD) algorithm contains two steps, \textit{i.e.} gradient descent~\eqref{eq:gd} and proximal mapping~\eqref{eq:proximal}. The proximal gradient descent
starts from an initial value $x_0$ and performs the following iterates until convergence:
\begin{subequations}\label{eq:pgd}
\begin{align}
s_{t} &= x_{t-1}-\alpha_t \nabla_{x_{t-1}} \mathcal{D}(\mathcal{A}(x_{t-1}), y), \label{eq:gd} \\ 
x_{t} &= \mathcal{P}_{\lambda \@R}\left(s_{t} \right), \label{eq:proximal}
\end{align}
\end{subequations}
where $\alpha_t$ is the step size  and the proximal gradient descent $\mathcal{P}_{\lambda \@R}(\cdot)$ is defined  by
\begin{equation*}
\@P_{\lambda \@R}(x)=\underset{x^{\prime} \in X}{\arg \min }~\frac{1}{2}\left\|x^{\prime}-x\right\|_{X}^{2}+\lambda \mathcal{R} \left(x^{\prime}\right).
\end{equation*}

We follow~\cite{gupta2018cnn,cherkaoui2020learning,yang2022dynamic} to use independent parameterized neural networks $\Psi_{\theta_t}$ to replace the proximal operators $\@P_{\lambda \@R}$. %It is here a reconstruction operator 
%$\mathcal{A}_{\theta}^{\dagger}: Y \rightarrow X$ with $\theta=(\theta_1,\cdots,\theta_T)$ that is defined as $\mathcal{A}_{\theta}^{\dagger}(y)=x_{t}$ where 
Guided by recent advances in inverse problems~\cite{adler2018learned}, we allow the network to learn how to combine the previous update with the gradient update direction instead of enforcing the updates of the form 
$x_{t-1}-\alpha_t g_t$ where throughout the paper we let $g_t=\nabla_{x_{t-1}} \mathcal{D}(\mathcal{A}(x_{t-1}), y)$
for conciseness. Therefore, $x_{t}$ is given by the following
finite recursive scheme initialised by $x_{0}\in X:$
\begin{equation}\label{eq:LPGD}
x_t = \Psi_{\theta_t}(x_{t-1},g_{t-1})
\qquad \text{for~~~}  t=1,\ldots,T,
%\tag{LPGD}
\end{equation}
mimicking the iteration of PGD.  The learned proximal gradient descent (LPGD) method is outlined in algorithm~\ref{alg:lpgd}. Note that the LPGD method with sharing weights, {i.e.}, restricting $\theta_1=...=\theta_T$, is another commonly used strategy
and we refer to~\cite{mardani2018neural,lohit2019unrolled} for more details.
    \begin{algorithm}[H]
          \small
          \caption{LPGD algorithm}
          \label{alg:lpgd}
            \begin{algorithmic}[1]
               \item[] \textbf{Input:} $x_0 \in X$
               \item[] \textbf{Output:} $x_T$  
               \For{$t=1,\ldots,T$}
                 \State{$g_{t-1} = \nabla_{x_{t-1}} \mathcal{D}(\mathcal{A}(x_{t-1}), y)$}
                 \State{$x_t = \Psi_{\theta_t}(x_{t-1}, g_{t-1})$}
               \EndFor
            \end{algorithmic}
    \end{algorithm}



    
\subsection{Learned primal-dual method}\label{sec:lpd} 
Adler and $\ddot{\mathrm{O}}$ktem first introduced the partially learned primal-dual approach as an extension of iterative deep neural networks in~\cite{adler2017solving} and further elaborate it into the LPD approach~\cite{adler2018learned}. %When the objective functions \eqref{eq:optim} is non-differentiable, 
The method is based on PDHG, another popular algorithm for solving the non-differentiable optimization problem \eqref{eq:optim}.
%the PDHG method is better suited for this setting since the proximal gradient descent~\eqref{eq:pgd} is sub-optimal. 
%For a given number of iterates, 
The PDHG  iteration is given by
\begin{equation}\label{eq:PDHG}
\left\{\begin{array}{l}
u_{t+1} =\operatorname{prox}_{\sigma \mathcal{D}^*}\left(u_t+\sigma \mathcal{A}\left(\bar{x}_t\right)\right) \\
x_{t+1} =\operatorname{prox}_{\tau \mathcal{R}}\left(x_t-\tau\left[\partial \mathcal{A}\left(x_t\right)\right]^*\left(u_{t+1}\right)\right) \\
\bar{x}_{t+1} =x_{t+1}+\gamma\left(x_{t+1}-x_t\right)
,\end{array} %\quad \text {for}~~~t=1, \ldots, T.
\right.
\end{equation}
where $\sigma, \tau, \gamma$ are predefined parameters, $\mathcal{A}^*$ denotes the Fenchel conjugate of $\mathcal{A}$,  and $\left[\partial \mathcal{A}\left(x_i\right)\right]^*$ is the adjoint of the Fr\'{e}chet derivative of $\mathcal{A}$ at point $x_i$. 
The LPD method is built upon Eq.~\eqref{eq:PDHG},
and loosely the main idea is to replace 
$\operatorname{prox}_{\sigma \mathcal{D}^*}$ and $\operatorname{prox}_{\tau \mathcal{R}}$ with the parametrized neural network models, 
which are then learned from data. 
Once the models are learned, the reconstruction proceeds via the following iterations: 
\begin{equation}\label{eq:LPD}
\left\{\begin{array}{l}
u_{t} =\Gamma_{\theta_{t}^{d}}\left(u_{t-1}, \mathcal{A}\left(x_{t-1}^{}\right), g\right) \\ x_{t} =\Lambda_{\theta_{t}^{p}}\left(x_{t-1},\left[\partial \mathcal{A}\left(x_{t-1}\right)\right]^{*}\left(u_{t}^{}\right)\right)
,\end{array} \quad \text {for}~~~ t=1, \ldots, T.\right.
\end{equation}
The complete LPD algorithm is given in Algorithm~\ref{alg:lpd}.
It is important to note that the LPD method often enlarges the state space to allow some
``memory'' between the iterations, which is omitted here and interested readers may consult \cite{adler2018learned}. 
Also note that $\Lambda_{\theta_{t}^{p}}: X \times X \rightarrow X$ corresponds to dual and primal networks with different learned parameters but with the same architecture for each iteration. A typical initialisation is $x_{0}=0$ and $u_{0}=g$. We refer to~\cite{adler2018learned} for details on the LPD method.
    \begin{algorithm}[H]
            \small
           \caption{LPD algorithm}
           \label{alg:lpd}
            \begin{algorithmic}[1]
               \item[] \textbf{Input:} $x_0 \in X^{N_{\text{primal}}}, u_0 \in U^{N_{\text{dual}}}$  
               \item[] \textbf{Output:} $x_T^{(1)}$  
               % \item[]
               
               \For {$t=1,\ldots,T$}
                    \State $u_{t} =\Gamma_{\theta_{t}^{d}}\left(u_{t-1}, \mathcal{A}\left(x_{t-1}^{(2)}\right), y\right)$
                    \State $g_t = \left[\partial \mathcal{A}\left(x_{t-1}\right)\right]^{*}u_{t}^{(1)}$
                    \State $x_{t} =\Lambda_{\theta_{t}^{p}}\left(x_{t-1}, g_t\right)$
              \EndFor
            \end{algorithmic}
    \end{algorithm}
    
\section{Deep unrolling networks with  momentum acceleration}\label{sec:DuNets-RMA}
The conventional deep unrolling methods, exemplified by LPGD and LPD, only use the current gradient, ignoring a large amount of historical gradient data. 
As has been discussed, the methods can be improved by adopting the momentum acceleration (MA) strategies that are frequently used in optimization methods.
In this section we will provide such momentum accelerated DuNet methods. 

\subsection{Momentum acceleration methods}\label{sec:momentum}
We here discuss the conventional explicit MA scheme and the one based on RNN. 
\subsubsection{Explicit momentum acceleration}
Momentum-based acceleration methods, like Nesterov’s accelerated gradient~\cite{nesterov1983method} and adaptive moment estimation~\cite{adam2015}, are well-established algorithms for speeding up the optimization procedure and have vast applications in machine learning~\cite{sutskever2013importance}. 
The classical gradient descent with MA utilizes the previous ``velocity'' $v_{t-1}$ at each iteration to perform extrapolation and generates the new update via:
\begin{subequations}
 %   \begin{equation}
    \label{eq:momentum}
\begin{align}
v_t &= \gamma v_{t-1} - \eta 
 g_{t-1} \label{eq:vtma}\\%\mathcal{D}(\mathcal{A}(x_{t-1}), y)   \\
x_t &= x_{t-1} + v_t, 
\end{align}
%\end{equation}
\end{subequations}
where $g_{t-1}$ is the gradient of the objective function evaluated at $x_{t-1}$, %=\nabla_{x_{t-1}} \mathcal{D}(\mathcal{A}(x_{t-1}), y)$, 
$\eta$ is the step size,
and $\gamma \in[0,1)$ is the momentum coefficient controlling the relative contribution of the current gradient and the previous velocity.  
Eq~\eqref{eq:momentum} can be rewritten as:
\begin{equation}\label{eq:vt}
\begin{aligned}
    v_t &=\gamma v_{t-1} -\eta g_{t-1} 
    = \gamma (\gamma v_{t-2}+\eta g_{t-2} +\eta g_{t-1})\\
    &= \ldots 
    =\gamma^t v_0 
    -\gamma^{t-1}\eta g_0
    %-\gamma^{t-2}\eta  \nabla_{x_{1}} \mathcal{D}(\mathcal{A}(x_{1}), y)
    -\ldots
    -\eta g_{t-1},
\end{aligned}
\end{equation}
which shows that the current velocity is essentially a weighted average of all the gradients (assuming $v_0=0$). 
As mentioned above, the momentum coefficient $\gamma$ controls how much information from previous iterations is used to compute the new velocity $v_t$,
and therefore needs to be chosen carefully for the good performance of the method. 
However, the optimal value for the parameter is problem-specific and typically requires manual tuning~\cite{sutskever2013importance,liu2020improved}.
 
\subsubsection{Momentum acceleration via RNN}
As one can see the conventional momentum method utilizes a fixed formula (a linear combination of all the gradients) to calculate the present velocity $v_t$.
In this section we introduce a more flexible scheme that uses the recurrent neural networks to learn the velocity term~\cite{hochreiter1997long}, which we refer to as the recurrent momentum acceleration (RMA) method. 
In particular we use the long short-term memory (LSTM) based RNN, which is briefly described as follows. 
At each time step $t$ we employ a neural network to compute the ``velocity'' $v_t$.
The neural network has three inputs and three outputs:
the inputs include the current gradient input $g_{t-1}$, the cell-state $c_{t-1}$ (carrying long-memory information) and the hidden state $h_{t-1}$ (carrying short-memory information), 
where the latter two are both inherited from the previous steps,
and the outputs are the velocity $v_t$,  
$h_{t}$ and $c_t$. 
We formally write this neural network model as,  
\begin{equation}
(v_{t}, h_{t}, c_t) =\Xi_{\vartheta_t}\left(g_{t-1}, h_{t-1}, c_{-1}\right), \label{eq:rmaXi}
\end{equation}
where $\vartheta^t$ are the neural network parameters,
and leave the details of it in Appendix \ref{sec:lstm}. 
As one can see this network integrates the current gradient $g_{t-1}$ and the information from previous step $h_{t-1}$ and $c_{t-1}$
to produce the velocity $v_t$ that can be used in DuNets.  
Finally we note that other RNN models such as the Gated Recurrent Unit (GRU)~\cite{cho2014learning} can also be used here.
In our numerical experiments 
we have tested both LSTM and GRU, and found no significant difference between the performances of the two approaches, which is consistent with some existing works, e.g.,~\cite {chung2014empirical,greff2016lstm}. 
As such, we focus on LSTM-RNN in this work.

\subsection{LPGD and LPD with MA}
Incorporating the momentum acceleration schemes in the
DuNets algorithms is rather straightforward. In this section we use LPGD and LPD as examples,
while noting that the MA methods can be implemented in other DuNets in a similar manner. 

% Figure environment removed

\paragraph{LPGD}
The explicit MA can be easily incorporated with LPGD.
A notable difference is that in the unrolling methods, $g_t$ is not the gradient of the objective function which 
may be nondifferentiable or not explicitly available. 
In LPGD, $g_t$ is taken to be the gradient of the data fidelity term only, i.e.,
 $g_t = \nabla_{x_{t-1}} \mathcal{D}(\mathcal{A}(x_{t-1}), y)$. 
The main idea here is to replace $g_{t-1}$ %in $\Phi_{\theta^t}(x_{t-1},g_{t-1})$ 
in Eq.~\eqref{eq:LPGD} by $v_t$ calculated via Eq.~\eqref{eq:vtma}, yielding the LPGD-MA method~(Alg.~\ref{alg:lpgd-ma}).
Similarly by inserting the LSTM model into Alg.~\eqref{alg:lpgd}, we obtain the LPGD-RMA algorithm which is summarised in Alg.~\ref{alg:lpgd-rma}.
Finally recall that, LPGD also has a sharing weights version (referred to as LPGDSW), and correspondingly we  have LPGDSW, LPGDSW-MA, and LPGDSW-RMA,
which will also be tested in our numerical experiments. 

%\zqp{We also offer a sharing weights version, dubbed as LPGDSW, in which all stages have the same parameter, \textit{i.e.}, $\theta_{1}=\ldots=\theta_{T}$.  In this %setting, we get three counterparts of LPGD: LPGDSW, LPGDSW-MA, and LPGDSW-RMA methods.}

    \begin{algorithm}[H]
          \small
          \caption{LPGD-MA}
          \label{alg:lpgd-ma}
            \begin{algorithmic}[1]
               \item[] \textbf{Input:} $x_0 \in X, \, v_0=0$
               \item[] \textbf{Output:} $x_T$  
               \For{$t=1,\ldots,T$}
                 \State{$g_{t-1} = \nabla_{x_{t-1}} \mathcal{D}(\mathcal{A}(x_{t-1}), y)$}
                 \State{$v_t = \gamma v_{t-1} - \eta g_{t-1}$}%\nabla_{x_{t-1}} \mathcal{D}(\mathcal{A}(x_{t-1}), y)$}
                 \State{$x_t = \Psi_{\theta_t}(x_{t-1}, v_{t})$}
               \EndFor
            \end{algorithmic}
    \end{algorithm}
\begin{algorithm}[H]
            \small
          \caption{LPGD-RMA algorithm}
          \label{alg:lpgd-rma}
           \begin{algorithmic}[1]
               \item[] \textbf{Input:} $x_0 \,\in X, h_0=0$
               \item[] \textbf{Output:} $x_T$  
               \For{$t=1,\ldots,T$}
               \State{$g_{t-1} = \nabla_{x_{t-1}} \mathcal{D}(\mathcal{A}(x_{t-1}), y)$}
                 \State{
                    $(v_{t},h_t) = \Xi_{\vartheta_t}( h_{t-1},g_{t-1})$}
                     
                 \State{$x_t = \Psi_{\theta_t}(x_{t-1}, {\color{black}{{v}_{t}}})$
                 }
               \EndFor
            \end{algorithmic}
    \end{algorithm}
    

\paragraph{LPD}
The integration of the MA schemes and LPD is a bit different.
Namely in LPGD, the velocity is constructed based on the gradient of the data fidelity term,
while in LPD, we build it upon $g_{t-1} = \left[\partial \mathcal{A}\left(x_{t-1}\right)\right]^{*}u_{t}^{(1)}$. 
By inserting the explicit MA formula~\eqref{eq:vtma} into  Alg.~\ref{alg:lpd} we obtain the LPD-MA method (Alg.~\ref{alg:lpd-ma}).
The LPD-RMA method can be constructed similarly: one simply 
replaces the explicit MA formula in Alg.~\ref{alg:lpd} by the RMA module Eq.~\eqref{eq:rmaXi},
and the complete algorithm is outlined in Alg.~\ref{alg:lpd-rma}.


   \begin{algorithm}[H]
            \small
           \caption{LPD-MA algorithm}
           \label{alg:lpd-ma}
            \begin{algorithmic}[1]
               \item[] \textbf{Input:} $x_0 \in X^{N_{\text{primal}}}, u_0 \in U^{N_{\text{dual}}}$  
               \item[] \textbf{Output:} $x_T^{(1)}$  
               % \item[]
               
               \For {$t=1,\ldots,T$}
                    \State $u_{t} =\Gamma_{\theta_{t}^{d}}\left(u_{t-1}, \mathcal{A}\left(x_{t-1}^{(2)}\right), y\right)$
                    \State $g_{t-1} = \left[\partial \mathcal{A}\left(x_{t-1}\right)\right]^{*}u_{t}^{(1)}$
                    \State $v_t = \gamma v_{t-1} - \eta g_{t-1}$
                    \State $x_{t} =\Lambda_{\theta_{t}^{p}}\left(x_{t-1}, v_t\right)$
              \EndFor
            \end{algorithmic}
    \end{algorithm}

    \begin{algorithm}[H]
            \small
           \caption{LPD-RMA algorithm}
           \label{alg:lpd-rma}
            \begin{algorithmic}[1]
               \item[] \textbf{Input:} $x_0 \in X^{N_{\text{primal}}}, u_0 \in U^{N_{\text{dual}}}$ 
               \item[] \textbf{Output:} $x_T^{(1)}$  
               % \item[]
               \For{$t=1,\ldots,T$}
                 \State $u_{t} =\Gamma_{\theta_{t}^{d}}\left(u_{t-1}, \mathcal{A}\left(x_{t-1}^{(2)}\right), y\right)$
                 \State $g_{t-1} = \left[\partial \mathcal{A}\left(x_{t-1}\right)\right]^{*}u_{t}^{(1)}$
                 \State $(v_{t}, h_{t}) =\Xi_{\vartheta_t}\left(h_{t-1}, g_{t-1}\right)$
               %  {$g'_{t-1} =  \Xi_{\vartheta}(
                % \left[\partial\mathcal{A}\left(x_{0}\right)\right]^* u_{1}^{(1)},\ldots,\left[\partial\mathcal{A}\left(x_{t-1}\right)\right]^*u_t^{(1)})$}
                 \State $x_{t} =\Lambda_{\theta_{t}^{p}}\left(x_{t-1}, {{g'_{t-1}}}\right)$
               \EndFor
            \end{algorithmic}
    \end{algorithm}



\section{Experiments and Results}\label{sec:exp}
In this section we present our  numerical experiments on two nonlinear inverse problems: 
a nonlinear deconvolution and an electrical impedance tomography (EIT) image reconstruction.
\subsection{Implementation details}
For the LPGD-type methods, we choose the number of unrolling iterations to be $I=20$.
The outputs of the proximal operator unit are first concatenated with the estimated direction from the RMA module and then combined using convolutional layers with a $3 \times 3$ kernel size and $32$ output channels before being fed to the subsequent block. 
The learned primal subnetwork consists of two convolutional layers of kernel size $3\times3$ and output channels 32. 
The convolutional layers are followed by a parametric rectified linear units (PReLU) activation function.  \ok{The output convolutional layer is designed to match a desired number of channels and does not include any nonlinear activation functions.}
For the LPD-type methods, we let the number of unrolling iterations be $T=10$, and the number of data that persists between the iterates be $N_{primal}=5, N_{dual}=5$. The primal subnetwork $\Gamma_{\theta_i^d}$ is the same as that used in LPGD-based methods. The dual subnetwork consists of one convolutional layer of kernel size $3\times3$ and output channels 32, and the other setting is the same as the primal subnetwork. 

All networks were trained end-to-end using Adam optimizer~\cite{adam2015} to minimize the empirical loss~\eqref{eq:mseloss}. We use a learning rate schedule according to the cosine annealing, \textit{i.e.}, the learning rate in step \(t\) was
$$
\eta_{t}=\frac{\eta_{0}}{2}\left(1+\cos \left(\pi \frac{t}{t_{\max }}\right)\right),
$$
where the initial learning rate \(\eta_{0}\) was set to \(10^{-3}\). We also let the parameter \(\beta_{2}\) of the ADAM optimizer to \(0.99\) and keep all other parameters as default. We performed global gradient norm clipping~\cite{zhanggradient}, limiting the gradient norms to 1 to improve training stability. We used a batch size of 32 for the nonlinear convolution example and 1 for the electrical impedance tomography. 
For the DuNets-MA methods, the value of $\gamma$ is initially set to 0.5 and gradually increased to 0.9 over several epochs.
We train all models with 20 epochs and keep a set of trainable parameters that achieve minimal validation losses.
We do not enforce any constraint on the trainable parameters during training.

All experiments were run on an Intel Xeon Golden 6248 CPU and an NVIDIA Tesla V100 GPU. The nonlinear deconvolution example was run entirely on the GPU. The forward and adjoint operators in electrical impedance tomography experiments were run on the CPU rather than the GPU as the \texttt{pyEIT} toolbox required is not computationally parallelizable and runs faster on the CPU. The training duration for a single epoch was approximately 4 minutes in the case of the nonlinear convolution example utilizing 10000 training samples, and 60 minutes for the electrical impedance tomography example with 400 training samples. The code for implementing all the experiments is available at \url{https://github.com/zhouqp631/DuNets-RMA.git}.

%\paragraph{Loss function}
We use the $\ell_{2}$ loss function on the outputs from all the stages. Specifically, given the paired samples $\{x_i,y_i\}, i=1,\ldots,N$, the training objective is defined as:
\begin{equation}\label{eq:mseloss}
\mathrm{L}(\Theta)=\frac{1}{N} \sum_{i=1}^{N} \left\|\hat{x}_i-x_{i}\right\|_{l^2}^{2}.
\end{equation}
Here, $\hat{x}_i$ is the reconstruction, and $\Theta$ presents the set of trainable parameters. 


\subsection{A nonlinear deconvolution problem}\label{sec:exp-deconv}
\subsubsection{Problem setting}
 We here consider a nonlinear deconvolution problem %with a nonlinear quadratic convolution through the Volterra kernels,
which is constructed largely following~\cite{zoumpourlis2017non}. %We consider a deconvolution problem, which involves recovering the parameters $x$ from the observations $y$:
For each input $\mathbf{x}=[x_{1}, x_{2}, \cdots, x_{n}]'$ consisting of $n$ elements, the forward problem is defined as
\begin{equation}\label{eq:ndp_forward}
y(\mathbf{x}) = a\cdot\mathbf{x}' \mathbf{W}_{2} \mathbf{x}+\mathbf{w}_{1}' \mathbf{x}+b.
\end{equation}
Here $\-w_1=[w_{1}^{1}, w_{1}^{2}, \cdots, w_{1}^{n}]'$ is the first-order Volterra kernel, which contains the coefficients of the Volterra series' linear part. The second-order Volterra kernel, denoted as {$\-W_2$}, is structured as follows:
\begin{equation*}
\mathbf{W}_{2}=\left[\begin{array}{cccc}w_{2}^{1,1} & w_{2}^{1,2} & \cdots & w_{2}^{1, n} \\ 0 & w_{2}^{2,2} & \cdots & w_{2}^{2, n} \\ \vdots & \vdots & \ddots & \vdots \\ 0 & 0 & \cdots & w_{2}^{n, n}\end{array}\right]
\end{equation*}
The superscripts $(i,j)$ to weights $w_{2}^{i,j}$ denote correspondence to the spatial positions of the input elements $x_{i}$ and $x_{j}$ that interact.
It is important to note that the parameter $a$ controls the degree of nonlinearity in the deconvolution problem.

\subsubsection{Training and testing datasets}
We assume that the unknown $x$ is on 53 mesh grid points, and meanwhile we choose the nonlinear kernel with size 9 and stride 4, and the dimension of the observed data $y$ is 12. The first-order and second-order Volterra kernels in Eq.~\eqref{eq:ndp_forward} are derived using the methods described in Section 3 of~\cite{kumar2009volterrafaces}.
We consider four sets of experiments with different coefficients in~\eqref{eq:ndp_forward}: $a=0, 1, 2, 4$. We generate the ground truth via sampling from a total variation prior (see Chapter 3.3 in~\cite{kaipio2006statistical}) and then obtain the observation data by~\eqref{eq:ndp_forward}. We employ 12000 randomly generated paired samples, where 10000 pairs were used as training sets, and the remaining 1000/1000 pairs were used as validation/test sets.

\subsubsection{Results and discussion}
\paragraph{Benefit of the RMA scheme}
We assess the performance of RMA with the three popular unrolling methods LPGDSW~\cite{lohit2019unrolled}, LPGD~\cite{yang2022dynamic} and LPD~\cite{adler2018learned},
and in each method we implement the three different cases: without acceleration, with the conventional MA module and with the RMA module;
as such there are 9 schemes implemented in total. To keep the comparison fair, all parameters involved in the competing methods are manually tuned for optimal performance or automatically chosen as described in the references. Table~\ref{tab:toy-results} demonstrates the performance of each method in terms of the mean-square error (MSE) on four different settings: $a=0,1,2,4$.  The visual comparison can be found in Figure~\ref{fig:toy_reconstructs}. 
We summarize our findings as the following: 
\begin{enumerate}[label=(\roman*)]
  \item when $a=0$, the MSE values of each type of DuNets method are almost the same,
  which is not surprising as  RMA degenerates with constant derivatives information;
  \item when $a > 0$, DuNets-RMA methods significantly outperform the state-of-the-art methods by a large margin (\textit{e.g.}, LPD-RMA outperforms the LPD method 8.0\%, 12.0\%, and 16.0\% in terms of MSE for $a=1, 2, 4$ respectively), suggesting that including the RMA module significantly improves the performance of the deep unrolling networks, especially for the inverse problems 
  that are highly nonlinear;
  \item the conventional MA module can also improve the performance, but RMA clearly outperforms it in all the nonlinear cases; 
  \item LPD-RMA method consistently achieves the highest-quality results that closely resemble the ground truth, conforming with the quantitative assessment via MSE.
\end{enumerate}

\begin{table}[]
\centering
\caption{Quantitative results (MSE) of different DuNets methods under different $a$ values. We do not report the MSE values of the LPGD model since it does not converge. The best results are indicated in \textcolor{orange}{orange} color.}
\label{tab:toy-results}
\begin{tabular}{lclclcll}
\hline
          & $a=0$        &  & $a=1$        &  & $a=2$        &  & \multicolumn{1}{c}{$a=4$} \\ \hline \specialrule{0em}{0pt}{3pt}
LPGD       &   ---      &  &   ---      &  &     ---    & &   ---                 \\ \specialrule{0em}{3pt}{3pt}
LPGD-MA    &  3.21E-02        &  &  5.37E-02        &  &  6.49E-02        &  &  7.76E-02                     \\ \specialrule{0em}{3pt}{3pt}
LPGD-RMA   &  3.23E-02        &  &  \textcolor{orange}{3.56E-02}        &  &  \textcolor{orange}{4.43E-02}        &  &  \textcolor{orange}{4.97E-02}                     \\ \hline  
\specialrule{0em}{0pt}{3pt}

LPGDSW     &  3.01E-02        &  &   4.61E-02       &  &  5.88E-02        &  & 6.85E-02                      \\ \specialrule{0em}{3pt}{3pt}
LPGDSW-MA  &  3.02E-02        &  &   4.54E-02       &  &  5.32E-02        &  & 5.78E-02                      \\ \specialrule{0em}{3pt}{3pt}
LPGDSW-RMA &  3.01E-02        &  &   \textcolor{orange}{3.89E-02}        &  &  \textcolor{orange}{4.68E-02} &  &   \textcolor{orange}{5.24E-02}                       \\ \hline  \specialrule{0em}{0pt}{3pt}

LPD       & 2.69E-02   &  & 3.65E-02 &  & 4.61E-02 &  & 5.17E-02              \\ \specialrule{0em}{3pt}{3pt}
LPD-MA    & 2.68E-02 &  &  3.71E-02 & &4.65E-02 & &5.22E-02                              \\ \specialrule{0em}{3pt}{3pt}
LPD-RMA   & 2.67E-02 &  & \textcolor{orange}{3.35E-02} &  & \textcolor{orange}{4.04E-02}  &  & \textcolor{orange}{4.33E-02}             \\ \hline  \specialrule{0em}{0pt}{3pt}
\end{tabular}
\end{table}

% Figure environment removed
Since the LPGDSW-type and LPGD-type approaches were significantly outperformed by the LPD methods in this example, for the following experiments in this section we only use LPD-type methods for illustration.

\begin{table}[!htb]
\centering
\caption{Mean MSE values of the LPD-RMA models with $L=1,2,3$ and $n=30, 50, 70$. \ok{Evaluation is done via repeating the experiment 10 times}. The number of trainable parameters is also reported below the MSE value in parentheses.}
\label{tab:different-L-toy}
\begin{tabular}{c|lll}
\hline
\multicolumn{1}{l|}{\diagbox{$n$}{$L$}} & \multicolumn{1}{c}{1}        & \multicolumn{1}{c}{2}        & \multicolumn{1}{c}{3}        \\ \hline
30      
& \begin{tabular}[c]{@{}c@{}}3.37E-02\\(94193)\end{tabular}  
& \begin{tabular}[c]{@{}c@{}}3.36E-02\\(101363)\end{tabular} 
& \begin{tabular}[c]{@{}c@{}}3.34E-02\\(108533)\end{tabular}   \\ \specialrule{0em}{3pt}{3pt}
50      
& \begin{tabular}[c]{@{}c@{}}3.35E-02\\(103353)\end{tabular} 
& \begin{tabular}[c]{@{}c@{}}3.34E-02\\(121303)\end{tabular}   
& \begin{tabular}[c]{@{}c@{}}3.33E-02\\(139253)\end{tabular}  \\ \specialrule{0em}{3pt}{3pt}
70     
& \begin{tabular}[c]{@{}c@{}}3.34E-02\\(114913)\end{tabular}   
& \begin{tabular}[c]{@{}c@{}}3.35E-02\\(148443)\end{tabular} 
& \begin{tabular}[c]{@{}c@{}}3.32E-02\\(181973)\end{tabular}     \\ 
%\specialrule{0em}{0pt}{3pt}
\hline
\end{tabular}
\end{table}
\clearpage
\paragraph{Sensitivity to the RMA structure}
We discuss here the choice for the architecture of the RMA modules, \textit{i.e.}, the hidden layers $L$ and the hidden size $n$ of the LSTM layer.  
Since the DuNets-RMA approach only requires knowledge of the direction of the new estimation, not its magnitude, as it learns the relationship between the previous update and the new derivative term. Thus, building an extremely accurate RMA module is unnecessary.
On the other hand, the RMA may suffer from overfitting when trained using a small number of training samples which is common in nonlinear inverse problems. 
Hence, we limit the ranges of the hidden layers as $L \in \{1,2,3\}$ and the hidden size as $n \in \{30, 50, 70\}$. 
Table~\ref{tab:different-L-toy} demonstrates the results of LPD-RMA trained with different network structures in the setting where $a=1$. We observe that in all these settings the LPD-RMA yields similar results, suggesting that the algorithm is rather robust provided that the parameter values are in a reasonably range. 
With extensive numerical tests, we have found that a reasonable choice of the hidden layer of RMA may be $L\in\{1, 2\}$ in moderate dimensions and 
the hidden size $n$ can be chosen to be about the same as the dimensionality of the unknown variables. We have also examined MSE for $a=2, 4$, where the results are qualitatively similar to those shown in Table~\ref{tab:different-L-toy}, 
and hence we omit those results here.



\paragraph{Sensitivity to data size}
To reveal the data efficiency of the proposed methods, we train the proposed model on different data sizes.
The data size is measured as the percentage of the total available training data, and 
the MSE results are plotted against the data size in Figure~\ref{fig:toy-differnt-datasize}. 
The figure shows that LPD-RMA is considerably more data efficient than LPD and LPD-MA. 
Interestingly after the data size increases to over 50\%, the use of the conventional MA module
can not improve the performance of LPD, while our LPD-RMA consistently achieves the best accuracy across the whole range.

% Figure environment removed


\subsection{Electrical impedance tomography}\label{sec:exp-eit}
\subsubsection{Problem setting}
EIT is a nondestructive imaging technique that aims at reconstructing the inner conductivity distribution of a medium from a set of voltages registered on the boundary of the domain by a series of electrodes~\cite{zou2003review}. 

In this example, we consider a bounded domain $\Omega \subseteq \mathbb{R}^{2}$ with a boundary $\delta\Omega$ containing certain conducting materials whose electrical conductivity is defined by a positive spatial function $\sigma(x) \in L^{\infty}(\Omega)$.
Next we assume that $L$ different electrical currents are injected into the boundary of $\partial \Omega$, and the resulting electrical potential should satisfy the following  governing equations with the same coefficient but different boundary conditions:
\begin{equation}\label{eq:eit_pde}
\left\{\begin{array}{ll}\nabla \cdot(\sigma \nabla u)=0 & \text { in } \Omega \\ 
u+z_{l} \sigma \frac{\partial u}{\partial e}=V_{l} & \text { on } E_{l},~~ l=1, \ldots, L \\ 
\int_{E_{l}} \sigma \frac{\partial u}{\partial e} \mathrm{~d} s=I_{l} & \text { on } \Gamma \\ 
\sigma \frac{\partial u}{\partial e}=0 & \text { on } \tilde{\Gamma}\end{array}\right.
\end{equation}
where \(\Gamma(\tilde{\Gamma})\) is the boundary \(\partial \Omega\) with (without) electrodes, $e$ is the outer normal direction at the boundary, \(V_{l}\) is the voltage to be
measured by \(l\)-th electrode \(E_{l}\) when the currents \(I_{l}\) are applied, \(z_{l}\) are the contact impedance.

 Numerically we consider the object domain $\Omega$ discretized into $n_{S}$ subdomains $\left\{\tau_{j}\right\}_{j=1}^{n_{S}}$ and
$\sigma$ is constant over each of them. 
{One injects a current at a fixed frequency through a pair of electrodes attached to the boundary and measure the voltage differences on the remaining electrode pairs. This process is repeated over all electrodes, and the resulting data is represented as a vector denoted by $Y \in \mathbb{R}^{n_{Y}}$
where $n_Y$ is the number of measurements.}
% In particular, we discretize $\Omega$ with a triangular mesh. Given an EIT medium's finite element model (FEM), we calculate the vector of voltages, $V_m$, for each FEM degree of freedom. 
We can define a mapping $F: \mathbb{R}^{n_{S}} \rightarrow \mathbb{R}^{n_{M}}$
representing the discrete version of the forward operator:
\begin{equation}\label{eq:eit_nonlinear}
V_{m}=F(\sigma)+\eta \text {, }
\end{equation}
where $\eta \in \mathbb{R}^{n_{Y}}$ is a zero-mean
Gaussian distributed measurement noise vector.

% A frame of data, denoted by v ∈ RM , is formed by rotating and repeating this process iteratively over all 16 electrodes.
Assuming the nonlinear degradation model~\eqref{eq:eit_nonlinear} and the given measurements $V_{m}$, the so-called absolute imaging problem aims to estimate the (static) conductivity $\sigma$ by solving the
following the nonlinear least squares problem
\begin{equation*}
\min~\int_{\sigma}\left(F(\sigma)-Y\right)^{2} \mathrm{~d} \Omega. 
\end{equation*}
The EIT problem is widely recognized as an exceedingly challenging problem due to its severe ill-posedness, caused by the highly non-linear dependence of the boundary currents on the conductivity.


\subsubsection{Training and Testing Datasets}\label{sec:eit-dataset}

We run numerical tests on a set of synthetic $2 \mathrm{D}$ experiments to evaluate the performance of the various methods. 
In the circular boundary ring, $L=16$ electrodes are equally spaced and located. The conductivity of the background liquid is set to be $\sigma_{0}=1.0 \Omega m^{-1}$. Measurements are simulated through opposite injection-adjacent measurement protocol via \texttt{pyEIT}~\cite{liu2018pyeit}, a Python-based framework for EIT. 
For each simulated conductivity phantom, the forward EIT problem~\eqref{eq:eit_pde} is solved using FEM with approximately 1342 triangular elements. 
 We explore the following two typical cases to test the methods:
\begin{itemize}
\item Case 1: the anomalies consist of two random circles with radii
generated from the uniform distribution ${U}(-0.6,0.6)$ and the conductivity values are 0.5 and 2 respectively in each circle; 

\item Case 2: the anomalies consist of four random circles with  radii generated according to ${U}(-0.55, 0.55)$ 
and the conductivity values are 0.3, 0.5, 1.5, and 2.0.
\end{itemize}
We perform the DuNet methods with three different training sample sizes 50, 200 and 400, and 20 testing samples to evaluate the performance of the methods.
\subsubsection{Results and discussion}
In the numerical experiments, we use the same set of unrolling schemes as in Section~\ref{sec:exp-deconv},
and in addition we also implement 
the regularized Gauss-Newton (GN) method with optimally tuned parameters. 
We calculate the mean and standard deviation of MSE of ten independent runs with different training data sizes, 
and provide the results for Case 1 in Table~\ref{tab:eit2targets} and those for Case 2 in Table~\ref{tab:eit-4-targets}.
In what follows our discussion is focused on three aspects of the experimental results, 
\begin{enumerate*}[label=(\roman*)]
  \item benefit of the RMA module,
  \item behaviors in low-data regimes, %data efficient
  and
  \item robustness to the number of inclusions in the conductivity area. 
\end{enumerate*}

\paragraph{Benefit of RMA scheme} 
First we note that five of the ten runs of the baseline LPGD (with no momentum acceleration) fail to converge within 20 epochs in both cases and as such we omit the results of the method in all the tables and figures. 
All the other algorithms can reasonably capture the inclusions' shape and position in all the ten runs. 
We highlight that,  according to Tables~\ref{tab:eit2targets} and~\ref{tab:eit-4-targets} the methods with the RMA module achieve the best performance 
in all but one test (LPGDSW method with 50 samples for Case 1) where the standard MA has the best results. 
In contrast, the effect of the standard MA module is not consistent: for example it results in worse performance than the baseline approach (without momentum acceleration) 
in the LPD method for case 1. 
As such we can see that the learning-based RMA module can provide better and more stable performance than the standard MA. 
Moreover, we want to compare the proposed methods with the conventional optimization based approach. 
To do so we provide the reconstruction results of four testing samples in Figure~\ref{fig:eit-2-reconst} (for Case 1)
and Figure~~\ref{fig:eit-4-reconst} (for Case 2). For simplicity we only provide the results of the DuNets with RMA, which is compared with 
those obtained by the GN optimization. 
 It can be seen from both figures that all DuNets approaches with the RMA module can yield rather accurate reconstruction for all the inclusions,
 and the quality of the images is clearly better than those of GN (note that the parameters in GN are manually tuned for the best MSE results). Furthermore, the inclusions near the boundary are better recovered than those near the center,
which confirms that inclusions  far away from the boundary are more difficult to
reconstruct since the boundary data are not sensitive to them~\cite{yang2020gauss,guo2021construct}.

\paragraph{Data size}
Next we shall exam the performance of the DuNets methods with respect to the data size. 
For this purpose we visualise the results in Tables~\ref{tab:eit2targets} and~\ref{tab:eit-4-targets}
with Figs.~\ref{fig:eit-2-differnt-training-number} and~\ref{fig:eit-4-differnt-training-number}. 
One observes that MSE is decreasing with more training data used in all the methods with RMA, 
which is not the case for the baseline methods and those with MA. 
For example, in Case 1, the MSE results of LPGDSW becomes evidently higher when the data size changes from 200 to 400.  
These results demonstrate that the RMA module can increase the stability of the DuNet methods with respect the data size. 


\paragraph{Number of inclusions}
Finally we consider how the methods perform with different numbers of inclusions by comparing 
the results in Case 1 (2 inclusions) and Case 2 (4 inclusions). 
First we can see that the MSE results in Case 2 are generally 
higher than those in Case 1, indicating that more inclusions 
make the problems more challenging for all methods.
Nevertheless,   the RMA module 
considerably improves the performance of DuNets in both cases,
which demonstrates that
the proposed RMA method is rather robust against the number of inclusions. 
 

\begin{table}[!htb]
\centering
\caption{The average MSE values of the DuNets methods for Case 1, with the associated standard deviations in parentheses. 
The best MSE results are indicated in \textcolor{orange}{orange} color.
}\label{tab:eit2targets}
\begin{tabular}{llll}
\hline
data size   &
  \multicolumn{1}{c}{50} &
  \multicolumn{1}{c}{200} &
  \multicolumn{1}{c}{400} \\ \hline
LPGD &
  \multicolumn{1}{c}{---} &
  \multicolumn{1}{c}{---} &
  \multicolumn{1}{c}{---} \\  \specialrule{0em}{2pt}{2pt}
LPGD-MA &
  \begin{tabular}[c]{@{}c@{}}6.13E-03\\ ($\pm$ 16.1E-04)\end{tabular} &
  \begin{tabular}[c]{@{}c@{}}5.17E-03\\ ($\pm$ 14.1E-04)\end{tabular} &
  \begin{tabular}[c]{@{}c@{}}4.18E-03\\ ($\pm$ 10.5E-04)\end{tabular} \\  \specialrule{0em}{2pt}{2pt}
LPGD-RMA &
  \begin{tabular}[c]{@{}c@{}}\textcolor{orange}{3.02E-03}\\ ($\pm$ 1.34E-04)\end{tabular} &
  \begin{tabular}[c]{@{}c@{}}\textcolor{orange}{2.48E-03}\\ ($\pm$ 1.08E-04)\end{tabular} &
  \begin{tabular}[c]{@{}c@{}}\textcolor{orange}{2.25E-03}\\ ($\pm$ 1.41E-04)\end{tabular}  \\  \hline 

LPGDSW &
  \begin{tabular}[c]{@{}c@{}}4.33E-03\\ ($\pm$ 13.7E-04)\end{tabular} &
  \begin{tabular}[c]{@{}c@{}}2.87E-03\\ ($\pm$ 1.15E-04)\end{tabular} &
  \begin{tabular}[c]{@{}c@{}}3.07E-03\\ ($\pm$ 1.86E-04)\end{tabular} \\  \specialrule{0em}{2pt}{2pt}
LPGDSW-MA &
  \begin{tabular}[c]{@{}c@{}}\textcolor{orange}{3.81E-03}\\ ($\pm$ 3.15E-04)\end{tabular} &
  \begin{tabular}[c]{@{}c@{}}2.92E-03\\ ($\pm$ 1.40E-04)\end{tabular} &
  \begin{tabular}[c]{@{}c@{}}2.95E-03\\ ($\pm$ 1.55E-04)\end{tabular}  \\ \specialrule{0em}{2pt}{2pt}
LPGDSW-RMA &
  \begin{tabular}[c]{@{}c@{}}3.92E-03\\ ($\pm$ 4.79E-04)\end{tabular} &
  \begin{tabular}[c]{@{}c@{}}\textcolor{orange}{2.65E-03}\\ ($\pm$ 1.99E-04)\end{tabular} &
  \begin{tabular}[c]{@{}c@{}}\textcolor{orange}{2.63E-03}\\ ($\pm$ 1.14E-04)\end{tabular} \\ \hline
LPD &
  \begin{tabular}[c]{@{}c@{}}3.25E-03\\ ($\pm$ 1.87E-04)\end{tabular} &
  \begin{tabular}[c]{@{}c@{}}2.55E-03\\ ($\pm$ 1.34E-04)\end{tabular} &
  \begin{tabular}[c]{@{}c@{}}2.35E-03\\ ($\pm$ 2.13E-04)\end{tabular}  \\ \specialrule{0em}{2pt}{2pt}
LPD-MA &
  \begin{tabular}[c]{@{}c@{}}3.29E-03\\ ($\pm$ 1.09E-04)\end{tabular} &
  \begin{tabular}[c]{@{}c@{}}2.71E-03\\ ($\pm$ 1.46E-04)\end{tabular} &
  \begin{tabular}[c]{@{}c@{}}2.44E-03\\ ($\pm$ 1.64E-04)\end{tabular}  \\ \specialrule{0em}{2pt}{2pt}
LPD-RMA &
  \begin{tabular}[c]{@{}c@{}}\textcolor{orange}{3.11E-03}\\ ($\pm$ 1.52E-04)\end{tabular} &
  \begin{tabular}[c]{@{}c@{}}\textcolor{orange}{2.17E-03}\\ ($\pm$ 1.36E-04)\end{tabular} &
  \begin{tabular}[c]{@{}c@{}}\textcolor{orange}{2.04E-03}\\ ($\pm$ 1.89E-04)\end{tabular}  \\ \hline
\end{tabular}%
\end{table}


% Figure environment removed

% Figure environment removed








\begin{table}[!htb]
\centering
\caption{The average MSE values of the DuNets methods for Case 2, 
 with the associated standard deviations in parentheses. 
The best results are indicated in \textcolor{orange}{orange} color.
}\label{tab:eit-4-targets}
\begin{tabular}{llll}
\hline
data size &
  \multicolumn{1}{c}{50} &
  \multicolumn{1}{c}{200} &
  \multicolumn{1}{c}{400} \\  \hline 
LPGD &
  \multicolumn{1}{c}{---} &
  \multicolumn{1}{c}{---} &
  \multicolumn{1}{c}{---} \\ \specialrule{0em}{2pt}{2pt}
LPGD-MA &
  \begin{tabular}[c]{@{}c@{}}10.3E-03\\ ($\pm$ 1.54E-04)\end{tabular} &
  \begin{tabular}[c]{@{}c@{}}8.60E-03\\ ($\pm$ 1.45E-04)\end{tabular} &
  \begin{tabular}[c]{@{}c@{}}7.87E-03\\ ($\pm$ 1.15E-04)\end{tabular}  \\  \specialrule{0em}{2pt}{2pt}
LPGD-RMA &
  \begin{tabular}[c]{@{}c@{}}{\textcolor{orange}{7.87E-03}}\\ ($\pm$ 1.46E-04)\end{tabular} &
  \begin{tabular}[c]{@{}c@{}}{\textcolor{orange}{7.43E-03}}\\ ($\pm$ 1.27E-04)\end{tabular} &
  \begin{tabular}[c]{@{}c@{}}{\textcolor{orange}{6.66E-03}}\\ ($\pm$ 1.28E-04)\end{tabular} \\ \hline

LPGDSW &
  \begin{tabular}[c]{@{}c@{}}7.81E-03\\ ($\pm$ 1.07E-04)\end{tabular} &
  \begin{tabular}[c]{@{}c@{}}6.88E-03\\ ($\pm$ 2.13E-04)\end{tabular} &
  \begin{tabular}[c]{@{}c@{}}6.69E-03\\ ($\pm$ 2.39E-04)\end{tabular} \\ \specialrule{0em}{2pt}{2pt}
LPGDSW-MA &
  \begin{tabular}[c]{@{}c@{}}{6.96E-03}\\ ($\pm$ 5.04E-04)\end{tabular} &
  \begin{tabular}[c]{@{}c@{}}5.46E-03\\ ($\pm$ 2.01E-04)\end{tabular} &
  \begin{tabular}[c]{@{}c@{}}5.53E-03\\ ($\pm$ 2.26E-04)\end{tabular}  \\ \specialrule{0em}{2pt}{2pt}
LPGDSW-RMA &
  \begin{tabular}[c]{@{}c@{}}{\textcolor{orange}{6.82E-03}}\\ ($\pm$ 3.42E-04)\end{tabular} &
  \begin{tabular}[c]{@{}c@{}}{\textcolor{orange}{5.16E-03}}\\ ($\pm$ 2.26E-04)\end{tabular} &
  \begin{tabular}[c]{@{}c@{}}{\textcolor{orange}{5.02E-03}}\\ ($\pm$ 2.15E-04)\end{tabular}  \\ \hline \specialrule{0em}{2pt}{2pt}
  
LPD &
  \begin{tabular}[c]{@{}c@{}}6.66E-03\\ ($\pm$ 2.72E-04)\end{tabular} &
  \begin{tabular}[c]{@{}c@{}}5.46-03\\ ($\pm$ 1.90E-04)\end{tabular} &
  \begin{tabular}[c]{@{}c@{}}5.10E-03\\ ($\pm$ 1.71E-04)\end{tabular}\\ \specialrule{0em}{2pt}{2pt}
LPD-MA &
  \begin{tabular}[c]{@{}c@{}}6.32E-03\\ ($\pm$ 1.95E-04)\end{tabular} &
  \begin{tabular}[c]{@{}c@{}}5.49E-03\\ ($\pm$ 1.63E-04)\end{tabular} &
  \begin{tabular}[c]{@{}c@{}}5.18E-03\\ ($\pm$ 1.86E-04)\end{tabular}\\ \specialrule{0em}{2pt}{2pt}
LPD-RMA &
  \begin{tabular}[c]{@{}c@{}}{\textcolor{orange}{6.01E-03}}\\ ($\pm$ 1.60E-04)\end{tabular} &
  \begin{tabular}[c]{@{}c@{}}{\textcolor{orange}{5.13E-03}}\\ ($\pm$ 1.91E-04)\end{tabular} &
  \begin{tabular}[c]{@{}c@{}}{\textcolor{orange}{4.93E-03}}\\ ($\pm$ 1.49E-04)\end{tabular}  \\  \hline
\end{tabular}%
\end{table}
\vspace{5pt}
% Figure environment removed


% Figure environment removed
% --------------------------------------------------
\clearpage
\section{Conclusion}\label{sec:conclusion}
In this work, we propose the recurrent momentum acceleration (RMA) strategy for boosting the performance of the deep unrolling networks (DuNets) for nonlinear inverse problems. 
Thanks to the RMA module, which is capable of learning  from 
the historical information of the gradient of the forward model, 
the proposed method can considerably improve the performance of DuNets.
We present two numerical experiments to test 
the performance of the proposed method. 
With the numerical examples we have found that the RMA module are effective with both the LPGD and the LPD methods. 
We expect that the proposed method can be extended to other unrolling algorithms,
and useful in a wide range of nonlinear inverse problems. 

\appendix 
\section{The LSTM network}\label{sec:lstm}
Here we will provide a detailed description of the LSTM network used in RMA. 
Recall that in RMA, at each time $t$, a network model 
$(v_{t}, h_{t}) =\Xi_{t}\left(g_{t-1}, h_{t-1}, c_{t-1}\right)$ (where network coefficients are omitted for simplicity)
is used, and the structure of this network is specified as follows:
\begin{itemize}
\item The model $\Xi_{\vartheta_t}(\cdot)$ is a $L$-layer network with a LSTM-cell (denoted as $\mathrm{LSTM}^l(\cdot)$ for $l=1,...,L$) at each layer. 
\item Both the cell state $c_{t}$
and the hidden state $h_{t}$ have $L$ components: $c_t=(c^1_t\,,...,\,c^L_t)$ 
and $h_t=(h^1_t\,,...,\,h^L_t)$ with each component being a vector of a prescribed dimension,
and the initial states ${h}_{0}$ and $c_0$ are set to be zero.
\item For the $l$-th layer, the inputs of the LSTM cell are $g_{t}$, $c^1_{t-1}$ and $h^1_{t-1}$, 
and the output of it are  $h^1_{t}$ and an intermediate state $z^1_t$ that will be inputted into the next layer:
\begin{equation*}
 (z^{l}_t,h_{t}^{l},c_{t}^{l}) =\mathrm{LSTM}^l\left(z_t^{l-1}, h_{t-1}^{l}, c^l_{t-1}\right),
\end{equation*}
where $z_t^0$ is initialized as $g_{t}$ for the first layer $l=1$. In the final layer $l=L$, the output $h^L_{t}$ is set as the velocity $v_t$. 
\end{itemize}
The structure of the LSTM network is summarised in Fig.~\ref{fig:rma-lstm} (a). 
% Figure environment removed


We now discuss the details of the LSTM cell that combines the input features $g_{t}$ at each time step and the inherited information from previous time steps.
In what follows we often omit the layer index $l$ when not causing ambiguity.
At each layer, the LSTM cell proceeds as follows.  
First LSTM  computes a candidate
cell state $\tilde{c}_{t}$ by combining $h^l_{t-1}$ and $z^{l-1}_{t}$ (with $z^1_t=g_{t-1}$), as:
\begin{equation*}
\tilde{c}_{t}=\tanh \left(W_{hc} h^l_{t-1}+W_{gc} z^{l-1}_{t}+b_c\right),
\end{equation*}
and it then generates a forget gate $x_{t}$, an input
gate $i_{t}$, and an output gate $o_{t}$ via the sigmoid function $\sigma(\cdot)$:
\begin{equation*}
\begin{aligned} f_{t} &=\sigma\left(W_{hx} h^l_{t-1}+W_{gx} z_t^{l-1}+b_x\right), 
\\ i_{t} &=\sigma\left(W_{hi} h^l_{t-1}+W_{gi} z_t^{l-1}+b_i\right), \\ o_{t} &=\sigma\left(W_{ho} h^l_{t-1}+W_{go} 
z_t^{l-1}+b_o\right). \end{aligned}
\end{equation*}
The forget gate is used to filter the information
inherited from $c_{t-1}$, and the input gate is used to filter
the candidate cell state at $t$. Then we compute
the cell state  $c_t$  via,
\[c_{t}=f_{t} \otimes c_{t-1}+i_{t} \otimes \tilde{c}_{t},\]
which serves as a memory reserving information from the previous iterations,
and the hidden representation $h^l_t$ as, 
\begin{equation*}
\quad h_{t}=o_{t} \otimes \tanh \left(c_{t}\right),
\end{equation*}
where $\otimes$ denotes the element-wise product. 
Finally the  output of the LSTM model $v_t$ at time $t$ is calculated as:
\begin{equation*}
v_{t} = W_{hg}h_t+b_g,
\end{equation*}
which is used to replace the gradient in the standard DuNets methods. 
Note that in what is above we only provide a brief introduction to  LSTM  tailored for our purposes, and readers who are interested in more details of the method may consult~\cite{hochreiter1997long,greff2016lstm}.
\section*{Acknowledgments}
We are grateful to the High-Performance Computing Center of Central South University for assistance with the computations.

\bibliographystyle{siamplain}
\bibliography{main}


\end{document}








