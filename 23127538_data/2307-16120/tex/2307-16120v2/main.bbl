\begin{thebibliography}{10}

\bibitem{adler2017solving}
{\sc J.~Adler and O.~{\"O}ktem}, {\em Solving ill-posed inverse problems using
  iterative deep neural networks}, Inverse Problems, 33 (2017), p.~124007.

\bibitem{adler2018learned}
{\sc J.~Adler and O.~{\"O}ktem}, {\em Learned primal-dual reconstruction}, IEEE
  transactions on medical imaging, 37 (2018), pp.~1322--1332.

\bibitem{baguer2020computed}
{\sc D.~O. Baguer, J.~Leuschner, and M.~Schmidt}, {\em Computed tomography
  reconstruction using deep image prior and learned reconstruction methods},
  Inverse Problems, 36 (2020), p.~094004,
  \url{https://doi.org/10.1088/1361-6420/aba415},
  \url{https://dx.doi.org/10.1088/1361-6420/aba415}.

\bibitem{benning2018modern}
{\sc M.~Benning and M.~Burger}, {\em Modern regularization methods for inverse
  problems}, Acta Numerica, 27 (2018), pp.~1--111.

\bibitem{boyd2011distributed}
{\sc S.~Boyd, N.~Parikh, E.~Chu, B.~Peleato, J.~Eckstein, et~al.}, {\em
  Distributed optimization and statistical learning via the alternating
  direction method of multipliers}, Foundations and Trends{\textregistered} in
  Machine learning, 3 (2011), pp.~1--122.

\bibitem{chambolle2011first}
{\sc A.~Chambolle and T.~Pock}, {\em A first-order primal-dual algorithm for
  convex problems with applications to imaging}, Journal of mathematical
  imaging and vision, 40 (2011), pp.~120--145.

\bibitem{cherkaoui2020learning}
{\sc H.~Cherkaoui, J.~Sulam, and T.~Moreau}, {\em Learning to solve {TV}
  regularised problems with unrolled algorithms}, Advances in Neural
  Information Processing Systems, 33 (2020), pp.~11513--11524.

\bibitem{cho2014learning}
{\sc K.~Cho, B.~Van~Merri{\"e}nboer, C.~Gulcehre, D.~Bahdanau, F.~Bougares,
  H.~Schwenk, and Y.~Bengio}, {\em Learning {P}hrase {R}epresentations using
  {RNN} {E}ncoder-{D}ecoder for {S}tatistical {M}achine {T}ranslation}, arXiv
  preprint arXiv:1406.1078,  (2014).

\bibitem{chung2014empirical}
{\sc J.~Chung, C.~Gulcehre, K.~Cho, and Y.~Bengio}, {\em Empirical evaluation
  of gated recurrent neural networks on sequence modeling}, in NIPS 2014
  Workshop on Deep Learning, December 2014, 2014.

\bibitem{colibazzi2022learning}
{\sc F.~Colibazzi, D.~Lazzaro, S.~Morigi, and A.~Samor{\'e}}, {\em Learning
  nonlinear electrical impedance tomography}, Journal of Scientific Computing,
  90 (2022), pp.~1--23.

\bibitem{combettes2011proximal}
{\sc P.~L. Combettes and J.-C. Pesquet}, {\em Proximal splitting methods in
  signal processing}, in Fixed-point algorithms for inverse problems in science
  and engineering, Springer, 2011, pp.~185--212.

\bibitem{greff2016lstm}
{\sc K.~Greff, R.~K. Srivastava, J.~Koutn{\'\i}k, B.~R. Steunebrink, and
  J.~Schmidhuber}, {\em {LSTM}: A search space odyssey}, IEEE transactions on
  neural networks and learning systems, 28 (2016), pp.~2222--2232.

\bibitem{gregor2010learning}
{\sc K.~Gregor and Y.~LeCun}, {\em Learning fast approximations of sparse
  coding}, in Proceedings of the 27th international conference on international
  conference on machine learning, 2010, pp.~399--406.

\bibitem{guo2021construct}
{\sc R.~Guo and J.~Jiang}, {\em Construct deep neural networks based on direct
  sampling methods for solving electrical impedance tomography}, SIAM Journal
  on Scientific Computing, 43 (2021), pp.~B678--B711.

\bibitem{gupta2018cnn}
{\sc H.~Gupta, K.~H. Jin, H.~Q. Nguyen, M.~T. McCann, and M.~Unser}, {\em
  {CNN}-based projected gradient descent for consistent {CT} image
  reconstruction}, IEEE transactions on medical imaging, 37 (2018),
  pp.~1440--1453.

\bibitem{hochreiter1997long}
{\sc S.~Hochreiter and J.~Schmidhuber}, {\em Long short-term memory}, Neural
  computation, 9 (1997), pp.~1735--1780.

\bibitem{hosseini2020dense}
{\sc S.~A.~H. Hosseini, B.~Yaman, S.~Moeller, M.~Hong, and M.~Ak{\c{c}}akaya},
  {\em Dense recurrent neural networks for accelerated {MRI}: History-cognizant
  unrolling of optimization algorithms}, IEEE Journal of Selected Topics in
  Signal Processing, 14 (2020), pp.~1280--1291.

\bibitem{houdard2018high}
{\sc A.~Houdard, C.~Bouveyron, and J.~Delon}, {\em High-dimensional mixture
  models for unsupervised image denoising ({HDMI})}, SIAM Journal on Imaging
  Sciences, 11 (2018), pp.~2815--2846,
  \url{https://doi.org/10.1137/17M1135694}.

\bibitem{kaipio2006statistical}
{\sc J.~Kaipio and E.~Somersalo}, {\em Statistical and computational inverse
  problems}, vol.~160, Springer Science \& Business Media, 2006.

\bibitem{adam2015}
{\sc D.~P. Kingma and J.~Ba}, {\em Adam: {A} method for stochastic
  optimization}, in 3rd International Conference on Learning Representations,
  {ICLR} 2015, San Diego, CA, USA, May 7-9, 2015, Conference Track Proceedings,
  Y.~Bengio and Y.~LeCun, eds., 2015, \url{http://arxiv.org/abs/1412.6980}.

\bibitem{kumar2009volterrafaces}
{\sc R.~Kumar, A.~Banerjee, and B.~C. Vemuri}, {\em {V}olterrafaces:
  {D}iscriminant analysis using volterra kernels}, in 2009 IEEE Conference on
  Computer Vision and Pattern Recognition, IEEE, 2009, pp.~150--155.

\bibitem{liu2018pyeit}
{\sc B.~Liu, B.~Yang, C.~Xu, J.~Xia, M.~Dai, Z.~Ji, F.~You, X.~Dong, X.~Shi,
  and F.~Fu}, {\em py{EIT}: A python based framework for {E}lectrical
  {I}mpedance {T}omography}, SoftwareX, 7 (2018), pp.~304--308.

\bibitem{liu2020improved}
{\sc Y.~Liu, Y.~Gao, and W.~Yin}, {\em An improved analysis of stochastic
  gradient descent with momentum}, Advances in Neural Information Processing
  Systems, 33 (2020), pp.~18261--18271.

\bibitem{lohit2019unrolled}
{\sc S.~Lohit, D.~Liu, H.~Mansour, and P.~T. Boufounos}, {\em Unrolled
  projected gradient descent for multi-spectral image fusion}, in ICASSP
  2019-2019 IEEE International Conference on Acoustics, Speech and Signal
  Processing (ICASSP), IEEE, 2019, pp.~7725--7729.

\bibitem{mardani2018neural}
{\sc M.~Mardani, Q.~Sun, D.~Donoho, V.~Papyan, H.~Monajemi, S.~Vasanawala, and
  J.~Pauly}, {\em Neural proximal gradient descent for compressive imaging},
  Advances in Neural Information Processing Systems, 31 (2018).

\bibitem{monga2021algorithm}
{\sc V.~Monga, Y.~Li, and Y.~C. Eldar}, {\em Algorithm unrolling:
  {I}nterpretable, efficient deep learning for signal and image processing},
  IEEE Signal Processing Magazine, 38 (2021), pp.~18--44.

\bibitem{nesterov1983method}
{\sc Y.~E. Nesterov}, {\em A method for solving the convex programming problem
  with convergence rate $o(1/k^2)$}, in Dokl. Akad. Nauk SSSR,, vol.~269, 1983,
  pp.~543--547.

\bibitem{seo2019learning}
{\sc J.~K. Seo, K.~C. Kim, A.~Jargal, K.~Lee, and B.~Harrach}, {\em A
  learning-based method for solving ill-posed nonlinear inverse problems: a
  simulation study of lung {EIT}}, SIAM journal on Imaging Sciences, 12 (2019),
  pp.~1275--1295.

\bibitem{shechtman2015phase}
{\sc Y.~Shechtman, Y.~C. Eldar, O.~Cohen, H.~N. Chapman, J.~Miao, and
  M.~Segev}, {\em Phase retrieval with application to optical imaging: a
  contemporary overview}, IEEE signal processing magazine, 32 (2015),
  pp.~87--109.

\bibitem{sung2009optical}
{\sc Y.~Sung, W.~Choi, C.~Fang-Yen, K.~Badizadegan, R.~R. Dasari, and M.~S.
  Feld}, {\em Optical diffraction tomography for high resolution live cell
  imaging}, Optics express, 17 (2009), pp.~266--277.

\bibitem{sutskever2013importance}
{\sc I.~Sutskever, J.~Martens, G.~Dahl, and G.~Hinton}, {\em On the importance
  of initialization and momentum in deep learning}, in International conference
  on machine learning, PMLR, 2013, pp.~1139--1147.

\bibitem{tang2022accelerating}
{\sc J.~Tang, S.~Mukherjee, and C.-B. Sch{\"o}nlieb}, {\em Accelerating {D}eep
  {U}nrolling {N}etworks via {D}imensionality {R}eduction}, arXiv preprint
  arXiv:2208.14784,  (2022).

\bibitem{xiang2021fista}
{\sc J.~Xiang, Y.~Dong, and Y.~Yang}, {\em {FISTA}-net: Learning a fast
  iterative shrinkage thresholding network for inverse problems in imaging},
  IEEE Transactions on Medical Imaging, 40 (2021), pp.~1329--1339.

\bibitem{yang2020gauss}
{\sc Q.~Yang, A.~Sadeghi, G.~Wang, G.~B. Giannakis, and J.~Sun}, {\em
  {G}auss-{N}ewton {U}nrolled {N}eural {N}etworks and {D}ata-driven {P}riors
  for {R}egularized {PSSE} with {R}obustness}, arXiv preprint arXiv:2003.01667,
   (2020).

\bibitem{yang2022dynamic}
{\sc Y.~Yang, R.~Tao, K.~Wei, and Y.~Fu}, {\em Dynamic proximal unrolling
  network for compressive imaging}, Neurocomputing, 510 (2022), pp.~203--217.

\bibitem{zhang2018ista}
{\sc J.~Zhang and B.~Ghanem}, {\em {ISTA}-{N}et: {I}nterpretable
  optimization-inspired deep network for image compressive sensing}, in
  Proceedings of the IEEE conference on computer vision and pattern
  recognition, 2018, pp.~1828--1837.

\bibitem{zhanggradient}
{\sc J.~Zhang, T.~He, S.~Sra, and A.~Jadbabaie}, {\em Why {G}radient {C}lipping
  {A}ccelerates {T}raining: {A} {T}heoretical {J}ustification for
  {A}daptivity}, in International Conference on Learning Representations, 2020.

\bibitem{zhang2019dynamically}
{\sc X.~Zhang, J.~Liu, Y.~Lu, and B.~Dong}, {\em Dynamically unfolding
  recurrent restorer: {A} moving endpoint control method for image
  restoration}, in 7th International Conference on Learning Representations,
  ICLR 2019, 2019.

\bibitem{zou2003review}
{\sc Y.~Zou and Z.~Guo}, {\em A review of electrical impedance techniques for
  breast cancer detection}, Medical engineering \& physics, 25 (2003),
  pp.~79--90.

\bibitem{zoumpourlis2017non}
{\sc G.~Zoumpourlis, A.~Doumanoglou, N.~Vretos, and P.~Daras}, {\em Non-linear
  convolution filters for {CNN}-based learning}, in Proceedings of the IEEE
  international conference on computer vision, 2017, pp.~4761--4769.

\end{thebibliography}
