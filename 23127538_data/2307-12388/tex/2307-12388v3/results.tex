\section{Experiment and Results}

% Firstly, we designed a preliminary experiment to indicate the gap between the two systems: real-world and simulator by manually tunned the Sumo world to be more difficult and more realistic.

% transportation
% TSC
In this section, we investigate several aspects of our study: the presence of a performance gap in TSC, the effectiveness of \ours in mitigating this gap, the influence of dynamic grounding rate $\alpha$, uncertainty quantification, and action grounding on \ours' performance, and the stability of \ours across various uncertainty quantification methods.

\vspace{-2mm}
\subsection{\textbf{Experiment Settings}}
In this section, we introduce the overall environment setup for our experiments, and commonly used metrics. \\

\begin{table}[htb]
\vspace{-5mm}
\small
\centering
\caption{Real-world Configurations for $E_{real}$}
% , V1: roads with lighter loaded vehicles, V2:roads with heavier loaded vehicles, V3: roads under rainy weather, V4: roads under snowy weather
\label{param}
\setlength{\tabcolsep}{1mm}

\begin{tabular}{cccccc}
\toprule
Setting & \begin{tabular}[c]{@{}c@{}}accel \\ (m/$s^2$)\end{tabular} & \begin{tabular}[c]{@{}c@{}}decel \\ (m/$s^2$)\end{tabular} & \begin{tabular}[c]{@{}c@{}}eDecel \\ (m/$s^2$)\end{tabular} & \begin{tabular}[c]{@{}c@{}}sDelay \\ (s)\end{tabular} & Description        \\ 
\midrule
% v1 ==> v3, v2 ==> v4
Default & 2.60 & 4.50 & 9.00 & 0.00 & --- \\
V1   &   1.00     &  2.50 & 6.00 & 0.50 & Lighter loaded vehicles   \\
V2   &   1.00     &  2.50 & 6.00 & 0.75 & Heavier loaded vehicles \\
V3   &   \textcolor{black}{0.75}     &  \textcolor{black}{3.50} & \textcolor{black}{6.00} & \textcolor{black}{0.25}    &  Rainy weather\\
V4   &   \textcolor{black}{0.50}     &  \textcolor{black}{1.50} & \textcolor{black}{2.00} & \textcolor{black}{0.50} & Snowy weather   \\
\bottomrule
\end{tabular}
\end{table}

% hyperparam
% metric
% \textcolor{green}{order is reverted, second is training}
\subsubsection{\textbf{Environment Setup}}  
In this paper, we implement \ours upon LibSignal~\cite{mei2022libsignal}, an open-sourced traffic signal control library that integrates multiple simulation environments. We treat Cityflow \cite{zhang2019cityflow} as the simulation environment $E_{sim}$ and SUMO \cite{lopez2018microscopic} as the real-world environment $E_{real}$. In later sections, we use $E_{sim}$ and $E_{real}$ by default unless specified. To mimic real-world settings, we consider four configurations in SUMO under two types of real-world scenarios: heavy industry roads and special weather-conditioned roads, with their specific parameters defined in Table~\ref{param}. 
% \hua{New section? Move to environment set up?}
% In order to mimic real-world settings, we consider two types of scenarios: heavy industry roads and special weather-conditioned roads.  \hua{missing default}
\\
$\bullet$ {\emph{Default setting~\footnote{\url{https://sumo.dlr.de/docs/Definition_of_Vehicles,_Vehicle_Types,_and_Routes.html}}}}. This is the default parameters for SUMO and CityFlow which describe the normal settings of the vehicle's movement in $E_{sim}$, with 8 phases TSC strategy.
\\
$\bullet$ {\emph{Heavy industry roads.}}
We model the places where the majority of vehicles could be heavy trucks. In Table \ref{param}, for the vehicles in $V1$ and $V2$, their accelerating, decelerating, and emergency decelerating rates are more likely to be slower than the default settings. We further consider the vehicles' average startup delay (larger than the default assumption $0s$). As shown in Table \ref{param}, $V1$ describes roads with lighter-loaded vehicles while $V2$ describes the same roads with heavier-loaded vehicles, and they vary at startup delay.
\\
$\bullet$ {\emph{Special weather-conditioned roads.}}
We examine scenarios with adverse weather conditions, specifically rainy ($V3$) and snowy ($V4$) conditions, as outlined in Table \ref{param}. In these settings, vehicle acceleration, deceleration, and emergency deceleration rates are reduced compared to the default values, while startup delays are increased. Notably, in snowy weather, the first three rates are lower than in rainy conditions, and the startup delay difference is extended to simulate tire slip.

\subsubsection{\textbf{Evaluation Metrics}} 
Following the literatures in TSC~\cite{ wei2021recent}, we adopt commonly used traffic signal control metrics as below: \\
$\bullet$ \textit{Average Travel Time (ATT)} is the average time $t$ it takes for a vehicle to travel through a specific section of a road network. For a control policy, the smaller $ATT$, the better. \\
$\bullet$ \textit{Throughput (TP)} is the number of vehicles reached their destinations given amount of time. The larger $TP$, the better.\\
$\bullet$ \textit{Reward} is an RL term that measures the return by taking action $a_t$ under state $s_t$. We use the total number of waiting vehicles as the reward, aligned with Preliminaries. The larger the reward, the fewer waiting vehicles, the better.\\
$\bullet$ \textit{Queue} is the number of vehicles waiting to pass through a certain intersection in the road network. Smaller is better.\\
$\bullet$ \textit{Delay} is the average delay per vehicle in seconds and measures the amount of time that a vehicle spends waiting in the network. Smaller is better.


\begin{table*}[htb]
\small
\caption{The performance using \textbf{Direct-Transfer} method compared with using \textbf{\ours} method. The ($\cdot$) shows the metric gap $\psi_{\Delta}$ from $E_{real}$ to $E_{sim}$ and the $\pm$ shows the standard deviation with 3 runs. The $\uparrow$ means that the higher value for the metric indicates a better performance and $\downarrow$ means that the lower value indicates a better performance.}
\label{tab:result}


\centering
\setlength{\tabcolsep}{1mm}
\scalebox{0.76}{
\begin{tabular}{c|ccccc|ccccc}
\toprule
Setting & \multicolumn{5}{c}{Direct Transfer} & \multicolumn{5}{c}{UGAT} \\ 

\cmidrule(lr){2-6}\cmidrule(lr){7-11}

% &ATT &TP &Reward &Queue &Delay &ATT (gap) &TP (gap) &Reward(gap) &Queue(gap) &Delay(gap) &ATT (gap) &TP (gap) &Reward(gap) &Queue(gap) &Delay(gap) \\

&$ATT(\Delta\downarrow)$ &$TP(\Delta\uparrow)$ &$Reward(\Delta\uparrow)$ &$Queue(\Delta\downarrow)$ &$Delay(\Delta\downarrow)$ &$ATT(\Delta\downarrow)$  &$TP(\Delta\uparrow)$  &$Reward(\Delta\uparrow)$ &$Queue(\Delta\downarrow)$ &$Delay(\Delta\downarrow)$ \\

\midrule

% v1 ==> v3, v2 ==> v4
V1    
     & 158.93(47.69) & 1901(-77) & -71.55(-32.11) & 47.71(21.59) & 0.73(0.11)

     & \textbf{144.72(33.49)$_{\pm{\text{3.61}}}$} & \textbf{1925(-52)$_{\pm{\text{4.58}}}$} & \textbf{-59.38(-19.94)$_{\pm{\text{3.08}}}$} & \textbf{39.58(13.47)$_{\pm{\text{2.04}}}$} & \textbf{0.67(0.05)$_{\pm{\text{0.01}}}$} \\
     
V2  
     & 177.27(66.03) & 1898(-80) & -87.71(-48.27) & 
     58.59(32.47) & 0.76(0.14) 

     & \textbf{164.65(53.52)$_{\pm{\text{12.94}}}$} 
     & \textbf{1907(-71)$_{\pm{\text{13.06}}}$} 
     & \textbf{-75.18(-35.74}$_{\pm{\text{8.37}}}$ 
     & \textbf{50.25(24.14)}$_{\pm{\text{5.56}}}$ 
     & \textbf{0.72(0.10)}$_{\pm{\text{0.01}}}$ \\


V3   
     &  205.86(94.63) & 1877(-101) & -101.26(-61.82) & 67.62(41.51) & 0.76(0.14)      & 
     
     \textbf{183.22(71.99)$_{\pm{\text{13.22}}}$} & \textbf{1900(-78)$_{\pm{\text{13.08}}}$} & \textbf{-82.38(-42.94)$_{\pm{\text{9.11}}}$} & \textbf{55.05(28.94)$_{\pm{\text{6.08}}}$} & \textbf{0.72(0.10)$_{\pm{\text{0.01}}}$} \\

V4   
    & 332.48(221.25) & 1735(-252) & -126.71(-87.23) & 84.53(58.42) & 0.83(0.21) &      
    
    \textbf{284.26(173.03)$_{\pm{\text{6.67}}}$} & \textbf{1794(-184)$_{\pm{\text{12.05}}}$} & \textbf{-111.68(-72.24)$_{\pm{\text{7.25}}}$} & \textbf{74.54(48.43)$_{\pm{\text{4.82}}}$} & \textbf{0.8(0.18)$_{\pm{\text{0.01}}}$} \\

\bottomrule
\end{tabular}
}
\label{tab:main}
\vspace{-4mm}
\end{table*}


In this work, our goal is to mitigate the performance gap of trained policy $\pi_{\theta}$  between $E_{sim}$ and $E_{real}$, we additionally calculate the gap $\Delta$ for each referred metric as $ATT_{\Delta}$, $TP_{\Delta}$, $Reward_{\Delta}$, $Queue_{\Delta}$, and $Delay_{\Delta}$. 
For certain metric $\psi$:
\begin{equation} \label{eq:delta}
    \psi_{\Delta} = \psi_{real} - \psi_{sim}
    \vspace{-2mm}
\end{equation}

Because in real-world settings, policy $\pi_{\theta}$ tends to perform worse than in simulation, so the $ATT$, $Queue$, and $Delay$ in $E_{real}$ are normally larger than those in $E_{sim}$. Based on the goal of mitigating the gap, improving $\pi_{\theta}$ performance in  $E_{sim}$, we expect: for $ATT_{\Delta}$, $Queue_{\Delta}$, and $Delay_{\Delta}$, the smaller the better. Because $TP_{\Delta}$, $Reward_{\Delta}$ will be negative values, the larger, the better.


% \subsubsection{\textbf{Training Details}} \label{sec:training detail}

% \hua{these feels like hyperparameters}
% Before the training process begins, a policy model $\pi_{\theta}$ will be pre-trained in the Cityflow simulator for $M$ = 100 epochs, to reach a relatively stable policy status. In the training of \ours, we train $\pi_{\theta}$ shaped by the forward model $f_{real}$ and inverse model $f_{sim}^{-1}$ for $E$ = 100 epochs within the $E_{sim}$ with $Adam$ optimizer using $Betas=(0.9, 0.99)$, learning rate for $f_{real}$ is 1e-4 and for $f_{sim}^{-1}$ is 1e-5. This is the policy improvement step for $E$ epochs. We conduct the training and optimizing processes by UGAT with DQN for $I$ = 300 episodes, to mitigate the gap between $E_{sim}$ and $E_{real}$ and report the best results. In the start of each episode $i$, we generate real-world and simulation trajectories induced by current policy $\pi_{\theta}$ and add them into $\mathcal{D}_{real}$ and $\mathcal{D}_{sim}$ respectively, and update $f_{real}$ with $\mathcal{D}_{real}$ and  $f^{-1}_{sim}$ with $\mathcal{D}_{sim}$. \hua{what's this sentence?}

% Based on the listed real-world settings above, we conduct experimental analysis: \textbf{First}, we train an RL model in the Cityflow simulator by DQN algorithm until it steadily converges after 200 Epochs, the metrics average travel time $ATT$ (in seconds) and throughput $TP$ (in number of vehicles) as reported under the column Simulator, \textbf{Second}, we directly transfer the trained RL-models in two settings in SUMO following the parameters in Table~\ref{tab:main}. 


% \subsubsection{\textbf{Hyperparameters}}   

% For reproducibility, we share key hyperparameters used in our method, \ours. We adopted the DQN implementation from~\cite{mei2022libsignal} with consistent hyperparameters. Our forward and inverse models employ feed-forward neural networks with three hidden layers (64, 128, and 20 hidden neurons, respectively) and are optimized using Adam optimizer~\cite{kingma2014adam} with $Betas=(0.9, 0.99)$ and batch size 64. The forward model uses a learning rate of $1e-4$, while the inverse model uses $1e-5$. For uncertainty quantification, we followed the approach in~\cite{sensoy2018evidential} and included additional $L2$ regularization in the last layer. Training involved 300 iterations for UGAT, and the RL policy underwent 100 epochs, with each epoch comprising 360 steps.


% \begin{table*}[htb]
%     \centering
%     \caption{Parameter exploration space and steps}
%     \begin{tabular}{ccccc}
%          \toprule
%             Attribute Name & Value Type & Default & Range & Step \\ 
%         \midrule
        
%             accel (m/$s^2$) & float & 2.60 & $\left[ 0.50,7.50\right]$ & 0.05 \\
%             decel (m/$s^2$) & float & 4.50 & $\left[0.50, 7.50\right]$ & 0.05 \\
%             emergencyDecel (m/$s^2$) & float & 9.00 & $\left[1.00, 10.00\right]$ & 0.50\\
%             startupDelay (s) & float & 0.00 & $\left[0.15, 5.00\right]$ & 0.05\\
%             containerCapacity (piece) & int & 0.00 & $\left[1.00, 5.00\right]$ & 1.00 \\
            
%         \bottomrule
        
%     \end{tabular}

%     \label{explore}
% \end{table*}
% We finally picked out 4 main settings as two types of real-world scenarios:
% \paragraph{Heavy Industry City Roads}
% We consider a more realistic setting for a heavy industrial city's roads condition, which may serve mainly for heavy truck vehicles. Under such consideration, we have two types of settings: $V1$ and $V2$, comported with default settings, vehicles in both $V1$ and $V2$ would perform a lower accelerating and decelerating speed, the difference lies in the container capacity, the larger capacity, the larger startup Delay.

% \paragraph{Special Weather Region's Roads}
% Another type is specialized for different weather conditions in cities. Similarly, we have chosen two sets of parameters, $V3$ represents rainy cities and $V4$ is designed for modeling snowy cities, which have even worse road conditions reflected on slower accelerating and decelerating speeds due to slippery tiers as shown in Table \ref{param}. 

\subsection{\textbf{Experiment Results}}

\subsubsection{\textbf{Gap between real-world and simulator}}
% \textcolor{red}{add table to show the gap}
% In order to testify whether the performance gap exists in traffic signal control tasks, we conduct the below experiment. We use the Direct-Transfer method: we train a policy model $\pi_{test}$ in $E_{sim}$ by the DQN method for 300 epochs, which guarantees its training convergence and directly transfer $\pi_{test}$ to 4 different $E_{real}$ settings as shown in Table~\ref{param}. 
To investigate the presence of a performance gap in TSC tasks, we conducted an experiment. We employed the Direct-Transfer method, training a policy model $\pi_{test}$ in $E_{sim}$ using the DQN method for 300 epochs. We then directly transferred $\pi_{test}$ to four distinct $E_{real}$ settings, as detailed in Table~\ref{param}.
% The results are visualized in Fig.~\ref{fig:main}. In the radar chart, there are 5 metrics showing the performance on two environments: $E_{sim}$ and $E_{real}$. The blue line is connected with the 5 metric results in $E_{sim}$ and the orange one represents the results in $E_{real}$. Compared with the performance in the $E_{sim}$, a clear metrics gap appears when $\pi_{test}$ is applied to 4 $E_{real}$ settings. Our experiment justifies the existence of performance gaps, which directs us to further study the method's generalizability and mitigate such problem.
The results are visualized in Fig.~\ref{fig:main}, using a radar chart with five metrics indicating performance in two environments, $E_{sim}$ and $E_{real}$. The blue line connects the metrics in $E_{sim}$, while the orange line represents $E_{real}$. A notable performance gap emerges when applying $\pi_{test}$ to four $E_{real}$ settings compared to $E_{sim}$. Our experiment confirms the existence of performance gaps, prompting further study into method generalizability.

% Figure environment removed

\begin{table}[htb]
    \centering
    \caption{Direct-Transfer and \ours performance in $E_{sim}$}
    \scalebox{0.95}{
    \begin{tabular}{cccccc}
        \toprule
        $Env$ & $ATT$ & $TP$ & $Reward$ & $Queue$ & $Delay$\\ \midrule
        \textbf{$E_{sim}$} & \textbf{111.23$_{\pm{\text{0.05}}}$} & \textbf{1978$_{\pm{\text{1}}}$} &\textbf{-39.44$_{\pm{\text{0.03}}}$} &\textbf{26.11$_{\pm{\text{0.05}}}$} &\textbf{0.62$_{\pm{\text{0.01}}}$} \\
        \bottomrule
    \end{tabular}}
    \label{tab:simresult}
    \vspace{-3mm}
\end{table}


\subsubsection{\textbf{Gap mitigating by uncertainty-aware \ours}}

To verify whether the \ours can effectively mitigate the performance gap, we compare the performance of directly transferring policies trained in $E_{sim}$ to $E_{real}$ with the policies learned under \ours in four $E_{real}$ settings. Because they are using the same $E_{sim}$, so performance in $E_{sim}$ eventually converges to stable results with tiny variance as shown in Table~\ref{tab:simresult}.  

In Table~\ref{tab:main}, we use ($\cdot$) to quantify the performance gap from $E_{real}$ to $E_{sim}$, as computed with Equation \eqref{eq:delta}. This gap directly reflects the methods' generalization capability from $E_{sim}$ to $E_{real}$. Our findings are as follows: (1) When comparing \ours to Direct-Transfer, it effectively reduces the performance gap ($\Delta$). Notably, \ours exhibits smaller gaps in $ATT_{\Delta}$, $Queue_{\Delta}$, and $Delay_{\Delta}$, while showing larger gaps in $TP_{\Delta}$ and $Reward_{\Delta}$, indicating effective performance gap mitigation.
(2) In terms of the original traffic signal control metrics, \ours enhances the performance of policy $\pi_{\phi}$. It achieves lower $ATT$ and higher $TP$ than Direct-Transfer.
(3) Table \ref{tab:main} summarizes experiments across four diverse real-world settings, encompassing five metrics. The results underscore \ours' robustness and effectiveness in complex environmental conditions.

% the $E_{sim}$ and the real-world $E_{real}$ exists. The comparison between \ours, which trains the GAT model on the top of the DQN with uncertainty quantification, test in SUMO and report the results in the GAT-Real (Gap) column as shown in Table~\ref{tab:result} and column Real (Gap), across the four different realistic settings, our method can effectively shrink the gap of the testing performance between the $E_{sim}$ and $E_{real}$. \hua{should've explain more}

% \hua{explain figure before describing axis.}The Y-axis of Fig.~\ref{fig:curve} demonstrates the performance gap between the simulator and real-world settings on 5 metrics. It is noticeable the values of the gap curves gradually descend and reach a steady convergence. This justifies the effectiveness of our method's ability for sim-to-real gap mitigation. We also test all the settings from Table~\ref{param}. The results from Table~\ref{tab:main} prove that our method is of good robustness because of low standard deviation and stable output.

% Based on our goal, which is to minimize the gap between the simulator-tested reports and real-world tested reports along the training process. We could notice from the Fig.\ref{fig:main}, the purple area represents our method's result, which explicitly demonstrated the effectiveness of shrinking the gap.


\subsubsection{\textbf{Ablation Study}}


% % Figure environment removed

% In order to understand how the dynamic grounding module, uncertainty quantification module, and action grounding module influence the method's final performance, we conduct an ablation study on \ours by step-by-step dissecting each one of them. Note that when the dynamic grounding module is removed, the grounding rate $\alpha$ is set as a static value of 0.5. When both $\alpha$ and uncertainty are removed (the third row), it is the version of Vanilla GAT. The results in Table~\ref{tab:ablation} show that each module contributes to the \ours performance. 
In Table~\ref{tab:ablation}, We conducted an ablation study on \ours to assess the impact of its dynamic grounding module, uncertainty quantification module, and action grounding module. We systematically analyzed each module's influence by removing them step by step. When the dynamic grounding module is removed, $\alpha$ is fixed at 0.5. In the third row, when both $\alpha$ and uncertainty are removed, it becomes Vanilla GAT.


\begin{table}[htb]
    \centering
    \caption{Ablation Study of \ours on $V1$}
    \scalebox{0.82}{
    \begin{tabular}{cccccc}
        \toprule
        $Structure$ 
        
        &\begin{tabular}[c]{@{}c@{}}$ATT_{\Delta}$ \\ $(\Delta\downarrow)$\end{tabular} 

         &\begin{tabular}[c]{@{}c@{}}$TP_{\Delta}$ \\ $(\Delta\uparrow)$\end{tabular} 

         &\begin{tabular}[c]{@{}c@{}}$Reward_{\Delta}$ \\ $(\Delta\uparrow)$\end{tabular} 

         &\begin{tabular}[c]{@{}c@{}}$Queue_{\Delta}$ \\ $(\Delta\downarrow)$\end{tabular} 

         &\begin{tabular}[c]{@{}c@{}}$Delay_{\Delta}$ \\ $(\Delta\downarrow)$\end{tabular} 

        \\ \midrule
        % v1 ==> v3, v2 ==> v4
        % 0.1 & 162.80 & 1901  &-39.44 &26.11 &0.62\\
        \textbf{UGAT} 
        & \textbf{33.49$_{\pm{\text{3.61}}}$} & \textbf{-52$_{\pm{\text{4.58}}}$} & \textbf{-19.94$_{\pm{\text{3.08}}}$} & \textbf{13.47$_{\pm{\text{2.04}}}$} & \textbf{0.05$_{\pm{\text{0.01}}}$} \\
        
         w/o dynamic $\alpha$  
         &   39.12$_{\pm{\text{4.21}}}$
         &  -72$_{\pm{\text{7.61}}}$
         & -25.07$_{\pm{\text{5.71}}}$
         & 16.88$_{\pm{\text{5.11}}}$
         & 0.08$_{\pm{\text{0.01}}}$\\


         
        % 0.5  &   162.80  &  1901 &-39.44 &26.11 &0.62\\
         w/o $\alpha$, uncertainty 
         &   44.87$_{\pm{\text{4.81}}}$
         &  -73$_{\pm{\text{12.99}}}$
         & -30.59$_{\pm{\text{3.80}}}$
         & 20.50$_{\pm{\text{1.97}}}$
         & 0.09$_{\pm{\text{0.01}}}$\\
         
         w/o Grounding  
         
        &   47.71$_{\pm{\text{6.73}}}$
         &  -77$_{\pm{\text{10.64}}}$
         & -32.11$_{\pm{\text{4.24}}}$
         & 21.60$_{\pm{\text{3.12}}}$
         & 0.11$_{\pm{\text{0.02}}}$\\
        % 1.0  &   162.80  &  1901 &-39.44 &26.11 &0.62\\
        \bottomrule
    \end{tabular}
    }
    \label{tab:ablation}
\end{table}


% To understand how the dynamically adjusted grounding rate $\alpha$ influences the sim-to-real training, an in-depth ablation study on $\alpha$ is further conducted and shown in Table \ref{tab:static}. We enable the uncertainty quantification module EDL, and then manually set the $\alpha$ from 0.2 to 0.8. During the training, the model will output uncertainty $u$, but the threshold $\alpha$ is static, if $u < \alpha$ then conduct action grounding, otherwise, reject the action as described in Algorithm \ref{algo:UGAT}. We compare the results with \ours which leverages uncertainty to dynamically adjust the $\alpha$. It is explicit that \ours method guarantees a good improvement in the model's performance.
We conducted an ablation study in Table~\ref{tab:static} to investigate the impact of dynamically adjusted grounding rates $\alpha$ on sim-to-real training. We activated the uncertainty quantification module EDL and manually set $\alpha$ values ranging from 0.2 to 0.8. In this study, if the model's uncertainty output $u$ was less than the static $\alpha$, the action was grounded; otherwise, it was rejected as in Algorithm \ref{algo:UGAT}. We compared these results with \ours, which dynamically adjusts $\alpha$ based on uncertainty. Notably, \ours significantly improved model performance.

\begin{table}[htb]
    \centering
    \caption{Static vs dynamic $\alpha$ on $V1$}
    \scalebox{0.85}{
    \begin{tabular}{cccccc}
        \toprule
        $\alpha$ 
        
        &\begin{tabular}[c]{@{}c@{}}$ATT_{\Delta}$ \\ $(\Delta\downarrow)$\end{tabular} 

         &\begin{tabular}[c]{@{}c@{}}$TP_{\Delta}$ \\ $(\Delta\uparrow)$\end{tabular} 

         &\begin{tabular}[c]{@{}c@{}}$Reward_{\Delta}$ \\ $(\Delta\uparrow)$\end{tabular} 

         &\begin{tabular}[c]{@{}c@{}}$Queue_{\Delta}$ \\ $(\Delta\downarrow)$\end{tabular} 

         &\begin{tabular}[c]{@{}c@{}}$Delay_{\Delta}$ \\ $(\Delta\downarrow)$\end{tabular} 

        \\ \midrule
        % v1 ==> v3, v2 ==> v4
        % 0.1 & 162.80 & 1901  &-39.44 &26.11 &0.62\\
        \textbf{dynamic} 
        & \textbf{33.49$_{\pm{\text{3.61}}}$} & \textbf{-52$_{\pm{\text{4.58}}}$} & \textbf{-19.94$_{\pm{\text{3.08}}}$} & \textbf{13.47$_{\pm{\text{2.04}}}$} & \textbf{0.05$_{\pm{\text{0.01}}}$} \\
        
         0.2  
         &   68.59$_{\pm{\text{7.14}}}$
         &  -117$_{\pm{\text{12.53}}}$
         & -40.42$_{\pm{\text{3.92}}}$
         & 27.11$_{\pm{\text{4.29}}}$
         & 0.12$_{\pm{\text{0.05}}}$\\


         
        % 0.5  &   162.80  &  1901 &-39.44 &26.11 &0.62\\
         0.4 
         &   55.87$_{\pm{\text{7.83}}}$
         &  -73$_{\pm{\text{13.01}}}$
         & -30.69$_{\pm{\text{4.54}}}$
         & 20.30$_{\pm{\text{3.28}}}$
         & 0.12$_{\pm{\text{0.01}}}$\\

        0.5
         &   39.12$_{\pm{\text{4.21}}}$
         &  -72$_{\pm{\text{7.61}}}$
         & -25.07$_{\pm{\text{5.71}}}$
         & 16.88$_{\pm{\text{5.11}}}$
         & 0.08$_{\pm{\text{0.01}}}$\\
         
         0.6
         &   47.09$_{\pm{\text{2.79}}}$
         &  -77$_{\pm{\text{4.68}}}$
         & -34.11$_{\pm{\text{3.99}}}$
         & 21.31$_{\pm{\text{2.38}}}$
         & 0.10$_{\pm{\text{0.03}}}$\\

        0.8
         &   48.53$_{\pm{\text{6.70}}}$
         &  -85$_{\pm{\text{9.17}}}$
         & -37.85$_{\pm{\text{6.23}}}$
         & 25.60$_{\pm{\text{2.91}}}$
         & 0.11$_{\pm{\text{0.01}}}$\\

         
        % 1.0  &   162.80  &  1901 &-39.44 &26.11 &0.62\\
        \bottomrule
    \end{tabular}
    }
    \label{tab:static}
    \vspace{-3mm}
\end{table}

% \textcolor{red}{refer the table v4}



% % Figure environment removed






\subsubsection{\textbf{Different Uncertainty Methods in \ours}}
\label{sec:exp:uncertainty}
% In previous experiments, we use the uncertainty given by the uncertainty quantification method EDL~\cite{sensoy2018evidential}. To better understand the benefit of model uncertainty, we conduct further experiments with different uncertainty quantification methods.
% These uncertainty methods include EDL, Concrete Dropout~\cite{gal2017concrete}, Deep Ensembles~\cite{lakshminarayanan2017simple} and we compare them with the method removed uncertainty module. We visualize the results $ATT_{\Delta}$ and $TP_{\Delta}$ from the 4 methods. In Fig.~\ref{fig:uncertainty}, w/o is the version without uncertainty methods, and the other three are EDL, Deep Ensembles (D\_ES), and MC Dropout (MC\_DP), the left sub-figure shows $ATT_{\Delta}$ calculated as Equation~\ref{eq:delta}, the smaller, the better, and for second sub-figure of $TP_{\Delta}$, the larger the better. Experimental results show that the explored model uncertainty quantification methods can consistently reduce the performance gap, and the EDL performs best, which is used in \ours uncertainty quantification module.
In our previous experiments, we utilized EDL~\cite{sensoy2018evidential} for uncertainty quantification. To gain deeper insights into the benefits of model uncertainty, we conducted additional experiments using various uncertainty quantification methods, namely, EDL, Concrete Dropout~\cite{gal2017concrete}, and Deep Ensembles~\cite{lakshminarayanan2017simple}. We compared these methods with w/o that excluded the uncertainty module shown in Fig.~\ref{fig:uncertainty}, smaller $ATT_{\Delta}$ and larger $TP_{\Delta}$ is better, which demonstrate model uncertainty quantification methods narrow the performance gap, with EDL outperforming the others, validating its use in \ours.
% Figure environment removed



% \begin{table}[htb]
% \small
% \centering
% \caption{Hyperparameter Details of Main Experiment}
% \label{config}
% \setlength{\tabcolsep}{1mm}
% \begin{tabular}{cccccc}
% \toprule
% Param notation & value & explanation  \\ \midrule
% % v1 ==> v3, v2 ==> v4
% $\epsilon$  & 0.1 & \textcolor{red}{xxxxxx}   \\
% $\epsilon_{decay}$   &   0.995     &  \textcolor{red}{xxxxxx} \\
% $\epsilon_{min}$  &   0.01   &  \textcolor{red}{xxxxxx}  \\
% training start   &   1000    &  \textcolor{red}{xxxxxx} \\
% buffer size   &   5000  & \textcolor{red}{xxxxxx}  \\
% \bottomrule
% \end{tabular}
% \end{table}


% \paragraph{Experimental results}




% \subsection{Uncertainty methods studies}
% In this section, we design two extra experiments to analyze the uncertainty's contribution and our methods' component's importance. For the first case study, we mainly leverage multiple uncertainty quantification methodologies to incorporate into our method, and compare with the non-used version's results; and for the second part, we tear apart the proposed method by ablation study. 





