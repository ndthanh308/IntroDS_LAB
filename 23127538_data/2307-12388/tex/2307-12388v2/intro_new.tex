\section{Introduction}
Traffic Signal Control (TSC) is vital for enhancing traffic flow, alleviating congestion in contemporary transportation systems, and providing widespread societal benefits. It remains an active research area due to the intricate nature of the problem. TSC must cope with dynamic traffic scenarios, necessitating the development of adaptable algorithms to respond to changing conditions.

Recent advances in reinforcement learning (RL) techniques have shown superiority over traditional approaches in TSC~\cite{noaeen2022reinforcement}. In RL, an agent aims to learn a policy through trial and error by interacting with an environment to maximize the cumulative expected reward over time. The biggest advantage of RL is that it can directly learn how to generate adaptive signal plans by observing the feedback from the environment. 


One major issue of applying current RL-based TSC approaches in the real world is that these methods are mostly trained in simulation and suffer from the performance gap between simulation and the real world. 
While training in simulations offers a cost-effective means to develop RL-based policies, it may not fully capture the complexities of real-world dynamics, limiting RL-based TSC models' practical performance~\cite{jiang2021simgan}. Simulators often employ static vehicle settings, such as default acceleration and deceleration, whereas real-world conditions introduce substantial variability influenced by factors like weather and vehicle types. These inherent disparities between simulation and reality impede RL-based models trained in simulations from achieving comparable real-world performance, as depicted in Figure~\ref{fig:intro}.

To bridge this gap, prior research has concentrated on enhancing traffic simulators to align more closely with real-world conditions, using real-world data~\cite{zhang2019cityflow}. This enables smoother policy or model transfer from simulation to reality, minimizing performance disparities. Yet, altering internal simulator parameters can be challenging in practice. To tackle this issue, Grounded Action Transformation (GAT) has emerged as a popular technique, aiming to align simulator transitions more closely with reality. However, GAT has predominantly been applied to robotics, with limited exploration in the context of traffic signal control.
%Unlike most sim-to-real transfer techniques in robotics which mainly tackle the domain gap in visual representations, traffic signal control mainly faces a domain gap in the transition dynamics, as real-world traffic dynamics can be complex and hard to simulate accurately.
% Grounded Simulation Learning is a promising paradigm for addressing the sim-to-real problem in robotics which aims to modify the simulator to better match the real world based on data from the real world. However, in practice, the internal parameters of the simulator cannot be easily modified. To address this challenge, the state-of-the-art approach is Grounded Action Transformation (GAT). Unlike GSL, GAT performs grounding not by modifying the simulator but rather by augmenting it with a learned action transformer that seeks to induce simulator transitions that more closely match the real world. GAT has shown promising results in bridging the gap between simulation and reality, making it a popular technique for sim-to-real transfer in robotics.
%the state-of-the-art approach is Grounded Action Transformation (GAT)
%much effort has been made to transfer a learned policy or model from a simulated environment to a real-world environment with simulation-to-real-world (sim-to-real) transfer techniques~\cite{}. Among them, 


In this paper, we present Uncertainty-aware Grounded Action Transformation (\ours), an approach that bridges the domain gap of transition dynamics by dynamically transforming actions in the simulation with uncertainty. 
\ours learns to mitigate the discrepancy between the simulated and real-world dynamics under the framework of grounded action transformation (GAT), which learns an inverse model that can generate an action to ground the next state in the real world with a desired next state predicted by the forward model learned in simulation. Specifically, to avoid enlarging the transition dynamics gap induced by the grounding actions with high uncertainty, \ours dynamically decides when to transform the actions by quantifying the uncertainty in the forward model. Our experiments demonstrate the existence of the performance gap in traffic signal control problems and further show that \ours has a good performance in mitigating the gap with higher efficiency and stability.

% Figure environment removed
