\section{Conclusions}
\label{sec:conclusions}
Organ segmentation is a fundamental task in the medical field. The volumetric data that characterize CT and MRI acquisitions make, however, the segmentation task computationally expensive. On the one hand, 2D CNNs provide a low latency solution unable to capture inter-slice information, on the other hand, 3D CNNs extract three-dimensional features at the price of high computation costs and risk of overfitting. Moreover, popular 2.5D multi-view fusion methods train three separate networks where the features of the orthogonal planes are learned independently, despite being part of the same volume. In SSH-UNet this is addressed by imposing weight sharing between convolutions so that only one network needs to be trained and multi-view features are collaboratively learned.
In this work, we introduced a novel approach for the segmentation of volumetric medical data. Inspired by works in the field of Video Action Recognition we interpret the slices of a volume as the frame of a video. Given a 2D backbone, to re-integrate the information between features belonging to adjacent slices we leverage the power of a shifting mechanism inspired by the TSM module. Spatio-temporal modeling, declined on pseudo-3D operators, despite being well-known in the Video Understanding field was never used before in the medical image analysis to extract and mingle multi-slice features. Our network, by using a 2D convolution with weight sharing mechanism and slice shift, can extract 3D features keeping low computational complexity.
In comparison to other popular state-of-the-art methods, SSH-UNet achieves an accuracy of \textbf{87.28\%} on the AMOS validation providing the smallest model in terms of parameters (6.48M) compared to the best network which has $+1.6\%$ improve in accuracy but $\times5$ increase in parameters.


