\begin{table}[t!]
\centering
\caption{Characteristic of tested models. We sort them according to Relative Gain. SFT: Supervised fine-tune; RLHF: Reinforcement learning from human feedback; \Checkmark: yes; \XSolidBrush: no.}
\label{tb-model-analysis}
\begin{tabular}{l|c|cc|c|c|c}
\toprule
\multirow{2}{*}{Model} & \multirow{2}{*}{Size} & \multicolumn{2}{l|}{pre-training strategy} & \multirow{2}{*}{Architecture} & \multirow{2}{*}{Origin} & \multirow{2}{*}{Relative Gain} \\ 
 &  & \multicolumn{1}{l|}{SFT} & RLHF &  &  &  \\ \midrule
Vicuna & 13B & \multicolumn{1}{l|}{\Checkmark} & \XSolidBrush & Decoder-Only & 44.91 & 9.58 \\ 
LLama 2 & 13B & \multicolumn{1}{l|}{\Checkmark} & \Checkmark & Decoder-Only & 33.46 & 6.00 \\ 
ChatGPT & 175B & \multicolumn{1}{l|}{\Checkmark} & \Checkmark & Decoder-Only & 75.20 & 4.32 \\ 
GPT-4 & unknown & \multicolumn{1}{l|}{\Checkmark} & \Checkmark & Decoder-Only & 80.75 & 0.85 \\ 
Bloom & 176B & \multicolumn{1}{l|}{\Checkmark} & \XSolidBrush & Decoder-Only & 50.33 & 0.51 \\ 
Flan-T5-Large & 780M & \multicolumn{1}{l|}{\Checkmark} & \XSolidBrush & Encoder-Decoder & 25.25 & 0.28 \\ \bottomrule
\end{tabular}
\end{table}