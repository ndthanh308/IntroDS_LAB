\documentclass[sigconf,nonacm]{acmart}
\usepackage[utf8]{inputenc}

\usepackage{algorithm}
\usepackage[noend]{algpseudocode}
\usepackage[cppcommentstyle,continuouslinenumbers]{smartalgorithmic}

\usepackage{makecell}
\usepackage{caption}
\usepackage{subcaption}

\usepackage[skins]{tcolorbox}

\usepackage[apply,nonotes]{xnotes}
\AddXNotesUser{at}{Andrei}{blue}
\AddXNotesUser{lf}{Luciano}{crimson}


\usepackage{cleveref}
\usepackage{amsmath}
\usepackage{multirow}
\usepackage{relsize}

\renewcommand\theadfont{\normalsize\bfseries}

\input{definitions}


\hyphenation{com-mu-ni-ca-tion}

\settopmatter{printfolios=true}

\setcitestyle{nocompress}

\begin{document}


\title{{\Swiper} and {\Dora}: efficient solutions to weighted distributed problems}
\author{Luciano Freitas}
\authornote{Both authors contributed equally and the order was decided randomly.}
\affiliation{%
  \institution{LTCI, T\'el\'ecom Paris, Institut Polytechnique de Paris}
  \country{France}
}
\email{lfreitas@telecom-paris.fr}

\author{Andrei Tonkikh}
\authornotemark[1]
\affiliation{%
  \institution{LTCI, T\'el\'ecom Paris, Institut Polytechnique de Paris}
  \country{France}
}
\email{tonkikh@telecom-paris.fr}
\date{}

\begin{abstract}
The majority of fault-tolerant distributed algorithms are designed assuming a \emph{nominal} corruption model, 
in which at most a fraction $f_n$ of parties can be corrupted by the adversary.
However, due to the infamous Sybil attack, nominal models are not sufficient to express the trust assumptions in open (i.e., permissionless) settings.
Instead, permissionless systems typically operate in a \emph{weighted} model, 
where each participant is associated with a \emph{weight} and the adversary can corrupt a set of parties 
holding at most a fraction $f_w$ of total weight.

In this paper, we suggest a simple way to transform
a large class of protocols designed for the nominal model into the weighted model. 
To this end, we formalize and solve three novel optimization problems, which we collectively call \emph{the weight reduction problems}, that allow us to map large real weights into small integer weights while preserving the properties necessary for the correctness of the protocols.
In all cases, we manage to keep the sum of the integer weights to be at most linear in the number of parties,
resulting in extremely efficient protocols for the weighted model.
Moreover, we demonstrate that, on weight distributions that emerge in practice, the sum of the integer weights tends to be far from the theoretical worst-case and, \atreplace{in fact}{often}, even smaller than the number of participants.

While, for some protocols, our transformation requires an arbitrarily small reduction in resilience (i.e., $f_w = f_n - \epsilon$), surprisingly, for many important problems we manage to obtain weighted solutions with the same resilience ($f_w = f_n$) as nominal ones.
Notable examples include asynchronous consensus,\atremove{ distributed key generation,} verifiable secret sharing, erasure-coded distributed storage and broadcast protocols.
Although there are ad-hoc weighted solutions to some of these problems, the protocols yielded by our transformations enjoy all the benefits of nominal solutions, including simplicity, efficiency, and a wider range of possible cryptographic assumptions.
    

    

    
    
\end{abstract}

\maketitle


\section{Introduction}

\subsection{Weighted distributed problems}

Traditionally, distributed problems are studied in the egalitarian setting where $n$ parties communicate over a network and any $t$ of them can be faulty or corrupted by a malicious adversary.
Different combinations of $n$ and $t$ are possible depending on the problem at hand, the types of failures (crash, omission, semi-honest, or malicious, also known as Byzantine), and the network model (typically, asynchronous, semi-synchronous, or synchronous).
However, for most distributed protocols, $t$ has to be smaller than a certain fraction of $n$. For example, most practical Byzantine fault-tolerant consensus protocols~\cite{pbft,canetti-rabin} can operate for any $t < \frac{n}{3}$.
We call such models \emph{nominal} and use $\fAn$ to denote their \emph{resilience}, i.e., a nominal protocol with resilience $\fAn$ operates correctly as long as less than $\fAn n$ parties are corrupt, where $n$ is the total number of participants.

However, this simple corruption model is not always sufficient to express the actual fault structure or trust assumptions of real systems.
As a result, we see many practical blockchain protocols adopt a more general, \emph{weighted} model, where each party is associated with a real \emph{weight} that, intuitively, represents the number of ``votes'' this party has in the system.
The assumption on the \emph{number} of corrupt parties in this setting is replaced by the assumption that the \emph{total weight} of the corrupt parties is smaller than a fraction $\fAw$ of the total weight of all participants. 
For example, in permissionless systems, the weight can correspond to the amount of ``stake'' or computational resources a participant has invested in the system and, in the context of managed systems, to a function of the estimated failure probability.

There are two main reasons to adopt the weighted model in the context of blockchain systems.
First and foremost, it protects the system from the infamous \emph{Sybil attacks}, i.e., malicious users registering themselves multiple times in order to obtain multiple identities, thereby surpassing the resilience threshold $\fAn$.
Secondly, it is speculated that users with a greater amount of resources (monetary, computational, or otherwise) invested in the system, and consequently a higher weight, will be more committed to the system's stability and less likely to engage in malicious behavior.

\subsection{Weighted voting and where it needs help} \label{subsec:weighted-voting}

Perhaps, the most prevalent tool used for the design of distributed protocols is \emph{quorum systems}~\cite{weighted-voting,quorum-systems,byz-quorum-systems}.
Intuitively, to achieve fault tolerance, each ``action'' is confirmed by a sufficiently large set of participants (called a \emph{quorum}).
Then, if two actions are conflicting or somehow interdependent (e.g., writing and reading a file in a distributed storage system), then the parties in the intersection of the quorums %
are supposed to ensure consistency.
Thus, many distributed protocols can be converted from the nominal to the weighted setting simply by changing the quorum system, i.e., instead of waiting for confirmations from a certain number of parties, waiting for a set of parties with the corresponding fraction of the total weight.
We call this strategy \emph{weighted voting} and it often allows translating protocols from the nominal to the weighted model while maintaining the same resilience (i.e., $\fAw = \fAn$) and, in some cases, with virtually no overhead.

However, weighted voting has two major downsides.
First and foremost, many protocols rely on primitives beyond simple quorum systems and weighted voting is often not sufficient to translate these protocols to the weighted model.
Notable examples include threshold cryptography~\cite{threshold-cryptosystems,ThresholdBLS}, secret sharing~\cite{Sha79,avss-cachin-2002}, erasure and error-correcting codes~\cite{coding-theory-textbook}, and numerous protocols that rely on these primitives. %

Another example relevant to blockchain systems is Single Secret Leader Election protocols~\cite{ssle,adaptive-ssle,uc-ssle,freitas2023homomorphic}. We use these protocols to illustrate that not all protocols that cannot be easily converted to the weighted model by applying weighted voting belong to the categories mentioned above.

The second drawback of weighted voting is that it requires a careful examination of the protocol in order to determine whether weighted voting is sufficient to convert it to the weighted model, as well as non-trivial modifications to the protocol implementation. 
It would be much nicer to have a ``black-box'' transformation that would take a protocol designed and implemented for the nominal model and output a protocol for the weighted model.

\subsection{Our contribution} \label{subsec:contribution}

\input{table-applications}

Our contribution to the fields of distributed computing and applied cryptography is twofold:
\begin{enumerate}
    \item We present a simple and efficient black-box transformation that can be applied to convert a wide range of protocols designed for the nominal model into the weighted model.
    Crucially, one can determine the applicability of our transformation simply by examining the \emph{problem} that is being solved (e.g., Byzantine consensus) instead of the \emph{protocol} itself (e.g., PBFT~\cite{pbft}) and it does not require modifications to the source code, only a slim wrapper around it.
    The price to pay for this transformation is an arbitrarily small decrease in resilience ($\fAw = \fAn - \epsilon$, where $\epsilon > 0$) and an increase in the communication and computation complexities proportional to $O(\frac{\fAw}{\epsilon})$.

    \item Furthermore, by opening the black box and examining the internal structure of distributed protocols, we discover that by combining our transformation with weighted voting, in many cases, we can obtain weighted algorithms \emph{without} the reduction in resilience ($\fAw = \fAn$) and with a very minor performance penalty.
\end{enumerate}

We summarize some examples of our techniques applied to a range of different protocols in \Cref{tab:applications}. The last two columns of the table give the upper bound on the overhead of the obtained weighted protocols compared to their nominal counterparts executed with the same number of parties.
Note, however, that, in many cases, the overhead applies only to specific parts of the protocol, which may not be the bottlenecks.
Thus, further experimental studies may reveal that the real overhead is even lower or non-existent, even with worst-case weight distribution.
Columns ``$\fAw$'' and ``$\fAn$'' specify the resilience of the obtained weighted protocols and the original nominal protocols, respectively. As was discussed before, in most cases, we manage to avoid sacrificing resilience $(\fAw = \fAn)$.

Furthermore, the main building block of our constructions, the \emph{weight reduction problems}, may be of separate interests and may have important applications beyond distributed protocols.
It is, indeed, an interesting and somewhat counter-intuitive observation that large real weights can be\atadd[The upper bounds yield linear algorithms. I will add an explicit mention of that to the Swiper and Dora section. Also, I would suggest redefining Swiper as a modular algorithm where the user can choose which parts to run. E.g., the user can just get the linear time solution from the upper, or just that and binary search or full-fledged cubic solution.]{ efficiently (in linear time)} reduced to small integer weights while preserving the key properties.


























\subsection{Empirical findings} \label{subsec:intro:empirical-findings}

The performance of the weighted protocols constructed as suggested in this paper is sensitive to the distribution of weights of the participants.
While we provide upper bounds and thus analyze our protocols for ``the worst distribution possible'', it is interesting whether such bad weight distributions emerge in practice.

\atrev{In order to study real-world weight distributions,} we tested our weight reduction algorithms on the distribution of funds from multiple existing blockchain systems~\cite{aptos_white,tezos_white,filecoin_white,dogecoin_white,algorand_white} \atrev{on systems ranging in size} from a hundred parties~\cite{aptos_stake,aptos_white} up to multiple tens of thousands~\cite{algorand_stake,algorand_white}.



\subsection*{Roadmap}

The paper is organized as follows: we formally define weight reduction problems in \Cref{sec:problem-statement} and provide constructive upper bounds for them in \Cref{sec:bound}.
We then proceed to present our approximate algorithms in \Cref{sec:algo}.
\Cref{sec:wr-applications,sec:wq-applications,sec:derived-applications} explain how to apply weight reduction to solve various kinds of weighted distributed problems.
In \Cref{sec:splitting-attacks}, we study the question of resilience against \emph{splitting attacks}, and in \Cref{sec:empirical-study}, we study the performance of weight reduction on the weight distributions emerging in practice.
We discuss related work in \Cref{sec:related} and conclude the paper in \Cref{sec:conclusion}



\section{Weight reduction problems} \label{sec:problem-statement}
In this section, we define the key building block to our construction, the \emph{weight reduction problems}, which is a class of optimization problems that map (potentially, large) real weights $w_1, \dots, w_n \in \mathbb{R}_{\ge 0}$ to (ideally, small) integers weights $t_1, \dots, t_n \in \mathbb{Z}_{\ge 0}$ while preserving certain key properties.
For convenience, we use the word \emph{``tickets''} to denote the units of the assigned integer weights, i.e., if $t_1, \dots, t_n$ is the output of a weight reduction problem, we say that party $i$ is assigned $t_i$ \emph{tickets}.


\begin{notation}
    To avoid repetition, throughout the rest of the paper, we use the following notation:
    \begin{enumerate}
        \item $[n] := \{1, 2, \dots, n\}$
        \item for any $S \subseteq [n]$: $w(S) := \sum_{i \in S} w_i$
        \item for any $S \subseteq [n]$: $t(S) := \sum_{i \in S} t_i$
        \item $W := w([n]) = \sum_{i=1}^{n} w_i$
        \item $T := t([n]) = \sum_{i=1}^{n} t_i$
    \end{enumerate}
\end{notation}


\subsection{\WRFull}

The first weight reduction problem is \emph{\WRFull} (or simply {\WRShort}).
It is parameterized by two numbers $\fRw, \fRn \in (0, 1)$ and requires the mapping to preserve the property that any subset of parties of weight less than $\fRw$ obtains less than $\fRn$ tickets.
More formally:
\begin{statement}[\WRFull]
Given $\fRw, \fRn \in (0, 1)$ and $w_1, \dots, w_n \in \mathbb{R}_{\ge 0}$ as input, find $t_1, \dots, t_n \in \mathbb{Z}_{\ge 0}$ such that $\sum_{i=1}^n t_i$ is minimum, subject to the following restrictions:
\begin{enumerate}
    \item $\forall S \subseteq [n]$ such that $w(S) < \fRw W$: $t(s) < \fRn T$
    \item $T \neq 0$
\end{enumerate}
\label{def:wrp}
\end{statement}

In \Cref{sec:wr-applications}, we apply {\WRFull} in order to implement the black-box transformation announced in \Cref{subsec:contribution} as well as weighted versions of secret sharing and threshold cryptography with different access structures.

In \Cref{sec:bound}, we will prove the following theorem (with a more precise bound on $T$):
\begin{theorem}[{\WRShort} upper bound, simplified] \label{thm:wr-bound-simple}
    For any $\fRw, \fRn \in (0, 1)$ such that $\fRw < \fRn$: there exists a solution to the {\WRFull} problem with $T = O\left(\frac{n}{\fRn - \fRw}\right)$.
\end{theorem}

\subsection{\WQFull}

The next weight reduction problem we study is \emph{\WQFull} (or simply {\WQShort}).
It requires the mapping to preserve the property that any subset of parties of weight more than $\fQw$ obtains more than $\fQn$ tickets.
In some sense, {\WQShort} is the opposite of the {\WRFull} problem discussed above.
More formally:

\begin{statement}[\WQFull]
Given $\fQw, \fQn \in (0, 1)$ and $w_1, \dots, w_n \in \mathbb{R}_{\ge 0}$ as input, find $t_1, \dots, t_n \in \mathbb{Z}_{\ge 0}$ such that $\sum_{i=1}^n t_i$ is minimum, subject to the following restrictions:
\begin{enumerate}
    \item $\forall S \subseteq [n]$ such that $w(S) > \fQw W$: $t(s) > \fQn T$
    \item $T \neq 0$
\end{enumerate}
\label{def:wqp}
\end{statement}

In \Cref{sec:wq-applications}, we show how to apply {\WQFull} to implement weighted versions of storage and broadcast protocols that rely on erasure and error-correcting codes for minimizing communication and storage complexity.

Interestingly, there exists a simple reduction between {\WRShort} and {\WQShort}:

\begin{theorem} \label{thm:wr2wq}
    For any $\fQw, \fQn \in (0, 1)$ and $w_1, \dots, w_n \in \mathbb{R}_{\ge 0}$, the following problems are identical:
    \begin{enumerate}
        \item $\WRShort(1-\fQw, 1-\fQn, w_1, \dots, w_n)$
        \item $\WQShort(\fQw, \fQn, w_1, \dots, w_n)$
    \end{enumerate}
\end{theorem}
\begin{proof}
    Let us prove that any valid solution to $\WRShort(1-\fQw, 1-\fQn, w_1, \dots, w_n)$ is a valid solution to $\WQShort(\fQw, \fQn, w_1, \dots, w_n)$. 
    The inverse can be proven analogously.
    Indeed, if $\forall S \subseteq [n]$ such that $w(S) > \fQw W$: 
    $w([n] \setminus S) = W - w(S) < (1 - \fQw) W$.
    Hence, $t([n] \setminus S) < (1 - \fQn) T$
    and $t(S) = 1 - t([n] \setminus S) > \fQn T$.
\end{proof}

From \Cref{thm:wr-bound-simple,thm:wr2wq}, we obtain the following:
\begin{corollary}[{\WQShort} upper bound, simplified] \label{thm:wq-bound-simple}
    For any $\fQw, \fQn \in (0, 1)$ such that $\fQn < \fQw$: there exists a solution to the {\WQFull} problem with $T = O\left(\frac{n}{\fQw - \fQn}\right)$.
\end{corollary}

\subsection{\WSFull}

Finally, {\WSFull} combines {\WRShort} and {\WQShort}: it has 4 parameters ($\fQw$, $\fQn$, $\fRw$, and $\fRn$) and outputs a ticket distribution that guarantees \emph{simultaneously} the properties of {\WQFull} and {\WRFull}.

\begin{statement}[\WSFull]
Given $\fQw, \fQn, \fRw, \fRn \in (0, 1)$ and $w_1, \dots, w_n \in \mathbb{R}_{\ge 0}$ as input, find $t_1, \dots, t_n \in \mathbb{Z}_{\ge 0}$ such that $\sum_{i=1}^n t_i$ is minimum, subject to the following restrictions:
\begin{enumerate}
    \item $\forall S \subseteq [n]$ such that $w(S) > \fQw W$: $t(s) > \fQn T$
    \item $\forall S \subseteq [n]$ such that $w(S) < \fRw W$: $t(s) < \fRn T$
    \item $T \neq 0$
\end{enumerate}
\label{def:wrp}
\end{statement}

Interestingly, in all practical problems that we have considered, either {\WRShort} or {\WQShort} were sufficient, so we have not yet identified good use cases for the more general {\WSFull} problem. 
However, we believe that it is still interesting theoretically and provide a linear upper bound on the total number of tickets for it, as for the other two problems.

\begin{theorem}[{\WSShort} upper bound, simplified]
For any $\fQw,\allowbreak \fQn,\allowbreak \fRw,\allowbreak \fRn \in (0, 1)$ such that $\fRw < \fRn$ and $\fQn < \fQw$: there exists a solution to the {\WSFull} problem with $T = O\left(\frac{n}{\min\{\fRn - \fRw, \fQw - \fQn\}}\right)$.    
\end{theorem}

The special case of {\WSShort} when $\fRn = \fQn$ was recently considered for implementation of so-called \emph{ramp} weighted secret-sharing in~\cite{ss-from-wiretap-channels}.
We discuss the relationship between our work and this result in more detail in the related work section.

\subsection{Overview of suggested solutions}

In \Cref{app:exact}, we show how to obtain exact solutions to {\WRShort} using Mixed Integer Programming (MIP)~\cite{conforti2014integer}, however, such an approach is prohibitively slow for inputs larger than twenty \atreplace{processes}{parties} as solving a MIP is NP-hard. 
\atremove{Moreover, we conjecture that the weight reduction problems defined in this paper are NP-complete.}

\atrev{Thus, in \Cref{sec:bound}, we provide constructive upper bounds on all three weight reduction problems ({\WRShort}, {\WQShort}, and {\WSShort}) yielding efficient (linear time) algorithms to find small, albeit not necessarily optimal, solutions.}

In \Cref{sec:algo}, we further build upon the upper bound\atadd{ for {\WRFull}} to obtain {\Swiper} -- an efficient polynomial-time algorithm that not only produces at most a linear number of tickets in the worst case but also produces very few tickets on practical weight distributions, as will be studied in \Cref{sec:empirical-study}.

We also define an algorithm that we dub {\Dora} to solve the {\WQShort} problem.
Due to \Cref{thm:wr2wq}, {\Dora} is defined simply as {\Swiper} with parameters $\fRw := 1-\fQw$ and $\fRn := 1-\fQn$.


\atadd{We are currently working on an algorithm that would yield the optimal (i.e., the smallest possible, given the restrictions) number of tickets. However, as this algorithm's running time is still significant, for practical systems of considerable size (thousands of parties), the approximate algorithms presented in this version of the paper will likely be preferable.}


\section{Upper Bounds} \label{sec:bound}

In this section, we provide constructive upper bounds for all three weight reduction problems defined in the previous section.
At their core, our bounds are based on a simple divide-and-round technique.
However, we then apply the idea of \emph{pruning} that is not only useful in practice but also improves the theoretical bounds.

\subsection{Upper bounds on {\WRFull}} \label{subsec:wr-bound}

\subparagraph*{\bf Floor distribution} 
Let us distribute for each party $i$, $t_i = \lfloor w_i/X \rfloor$ tickets for some $X$ that we will later select.
Consider a set $S$ such that $w(S) < \fRw$. Then we can bound the number of tickets allocated to it as follows:

\begin{align*}
  t(S) &= \sum_{i \in S} t_i = \sum_{i \in S} \left\lfloor \frac{w_i}{X} \right\rfloor 
      \le \sum_{i \in S} \frac{w_i}{X}
      = \frac{w(S)}{X}
      < \frac{\fRw W}{X}
\end{align*}

On the other hand, we can give a lower bound on the number of tickets allocated to its complement $\overline{S}$:
\begin{align*}
  t(\overline{S}) = \sum_{i \not\in S} t_i = \sum_{i \not\in S} \left \lfloor \frac{w_i}{X} \right \rfloor \ge \sum_{i \not\in S} \left(\frac{w_i}{X} - 1 \right) 
      > \frac{(1-\fRw) W}{X} - n
\end{align*}

Note that, to simplify the resulting bound and make it independent of the weight distribution, we use $n$ as the upper bound for $|\overline{S}|$, which is a slight oversimplification.
In order to prove that $t(S) < \fRn T$, it is sufficient to show that $\frac{t(S)}{t(\overline{S})} < \frac{\fRn}{1 - \fRn}$. Indeed:

\begin{align*}
    t(S) < \fRn T \Leftrightarrow t(S) < \fRn (t(S) + t(\overline{S}))
    \Leftrightarrow \frac{t(S)}{t(\overline{S})} < \frac{\fRn}{1 - \fRn}
\end{align*}

By substituting the bounds we have on $t(S)$ and $t(\overline{S})$, we obtain a sufficient condition for the required inequality to hold:
\begin{align*}
    & \frac{t(S)}{t(\overline{S})} < \frac{\fRn}{1 - \fRn} \\
    \Leftarrow\; & \frac{\fRw W}{(1 - \fRw) W - n X} \le \frac{\fRn}{1 - \fRn} \\
    \Leftrightarrow\; &
    X \le \frac{W}{n} \frac{\fRn - \fRw}{\fRn}
\end{align*}

Hence, setting $X := \frac{W}{n} \cdot \frac{\fRn - \fRw}{\fRn}$ is sufficient to guarantee that $t(S) < \fRn T$ and we can obtain our first upper bound on the optimal number of tickets for {\WRShort}:
\begin{align*}
    T = \sum_{i=1}^n \left\lfloor \frac{w_i}{X} \right\rfloor \le \frac{W}{X} = \frac{\fRn}{\fRn - \fRw} n
\end{align*}

We can go slightly further by \emph{pruning} the solution: we keep the tickets assigned to parties in $S$ and then remove unnecessary tickets from the other parties while maintaining the $t(S) < \fRn T$ requirement.
\atadd{To this end, we need to find the set $S$ of weight less than $\fRw W$ that obtains the most tickets by solving Knapsack~\cite{KnapsackProblems04}. Luckily for us, as detailed in~\Cref{app:knap}, in this case, Knapsack can be solved efficiently in time $O(Tn)$ using dynamic programming on profits~\cite[Lemma 2.3.2]{KnapsackProblems04}, and we know that $T \le \frac{\fRw n}{\fRn - \fRw}$.}
In total, we will assign only $\left\lceil \frac{t(S)}{\fRn} \right\rceil$ tickets. As $t(S) < \frac{\fRw W}{X}$ and $t(S)$ is an integer, $t(S) \le \frac{\fRw W}{X} - 1$. This leads to a slightly improved upper bound on $T$:
\begin{align*}
    T = \left\lceil \frac{t(S)}{\fRn} \right\rceil \le \left\lceil \frac{\fRw}{\fRn-\fRw} n - \frac{1}{\fRn} \right\rceil \le \frac{\fRw}{\fRn-\fRw} n
\end{align*}

\subparagraph*{\bf Ceiling distribution} Let us now do a similar study on the ticket distribution where each party $t_i$ is assigned $\lceil w_i/X \rceil$ tickets.
\begin{align*}
  t(S) &= \sum_{i \in S} t_i = \sum_{i \in S} \left \lceil \frac{w_i}{X} \right \rceil 
      \le \sum_{i \in S} \left( \frac{w_i}{X} + 1 \right)
      \le \frac{\fRw W}{X} + n \\
  t(\overline{S}) &= \sum_{i \not\in S} t_i = \sum_{i \not\in S} \left \lceil \frac{w_i}{X} \right \rceil 
      \ge \sum_{i \not\in S} \frac{w_i}{X}
      \ge \frac{(1-\fRw) W}{X}
\end{align*}

Analogously with the floor distribution, we can obtain a sufficient condition to guarantee that $t(S) < \fRn T$:
\begin{align*}
    & t(S) < \fRn T \\
    \Leftrightarrow\; &
    \frac{t(S)}{t(\overline{S})} < \frac{\fRn}{1 - \fRn} \\
    \Leftarrow\; &
    \frac{\fRw W + nX}{(1 - \fRw) W} \le \frac{\fRn}{1 - \fRn} \\
    \Leftrightarrow\; &
    X \le \frac{W}{n} \frac{\fRn-\fRw}{1-\fRn}
\end{align*}

Thus, the total number of tickets distributed is at most:
\begin{align*}
    T \le \sum_{i=1}^n\left\lceil \frac{w_i}{X} \right\rceil \le \frac{W}{X} + n
    = \left(\frac{1 - \fRn}{\fRn - \fRw} + 1\right) n
    = \frac{1 - \fRw}{\fRn - \fRw} n
\end{align*}

\lfrev{In this case, pruning does not improve the upper bound on $T$.}

\subparagraph*{\bf Upper bound.} Thus, we obtain a final upper bound as the minimum between these two distributions\atremove{, which will change for depending on $\fRw$}:

\begin{theorem}[{\WRShort} upper bound]
    For any $\fRw, \fRn \in (0, 1)$ such that $\fRw < \fRn$: for any $w_1, \dots, w_n$: there exists a valid solution to the {\WRFull} problem such that:
    \begin{gather*}
        T \le \frac{\min\{\fRw, 1 - \fRw\}}{\fRn - \fRw} n
    \end{gather*}
\end{theorem}

\subsection{Upper bounds on {\WQFull}} \label{subsec:wq-bound}

As a result of \Cref{thm:wr2wq}, we can establish the following bound for {\WQShort}:

\begin{theorem}[{\WQShort} upper bound]
    For any $\fQw, \fQn \in (0, 1)$ such that $\fQn < \fQw$: for any $w_1, \dots, w_n$: there exists a valid solution to the {\WQFull} problem such that:
    \begin{gather*}
        T \le \frac{\min\{\fQw, 1 - \fQw\}}{\fQw - \fQn} n
    \end{gather*}
\end{theorem}


\subsection{Upper bounds on {\WSFull}}

Regarding {\WSShort}, we can apply the same analysis as in \Cref{subsec:wr-bound} and choose a value of $X$ that satisfies the requirements of both {\WRShort} and {\WQShort}. For simplicity, we do not consider pruning in this case.
Hence, we obtain the following theorem:
\begin{theorem}[{\WSShort} upper bound]
    For any $\fRw, \fRn, \fQw, \fQn \in (0, 1)$ such that $\fRw < \fRn$ and $\fQn < \fQw$: for any $w_1, \dots, w_n \in \mathbb{R}_{\ge 0}$: there exists a valid solution to the {\WSFull} problem such that:
    \begin{gather*}
        T \le \min\left\{T_{floor}, T_{ceil}\right\}\text{, where} \\
        T_{floor} = \max\left\{\frac{\fRn}{\fRn-\fRw}, \frac{1 - \fQn}{\fQw-\fQn}\right\} n \\
        T_{ceil} = \max\left\{\frac{1-\fRw}{\fRn-\fRw}, \frac{\fQw}{\fQw-\fQn}\right\} n
    \end{gather*}
\end{theorem}




\section{{\Swiper} and {\Dora} -- efficient solutions to {\WRShort} and {\WQShort}}\label{sec:algo}

\begin{atreview}
{\Swiper} is a deterministic approximate algorithm for the {\WRFull} problem.
It is designed to not only respect the upper bounds provided in the previous section
but also to allocate a small number of tickets on practical weight distributions.
The main insight is that the choice of the value $X$ in \Cref{subsec:wr-bound} is very pessimistic:
we choose it based only on the total weight $W$, number of parties $n$, and thresholds $\fRn$ and $\fRw$.
In {\Swiper} we essentially try all possible values for $X$ and pick the maximum value so that the condition imposed by the {\WRShort} problem statement is satisfied.
We do so in a highly optimized manner.

The full code is available on GitHub\footnote{\url{https://github.com/DCL-TelecomParis/swiper-dora}}.
The Python implementation available on GitHub has a parameter \texttt{-{}-speed} that accepts values between 1 and 10.
We recommend the value \texttt{-{}-speed 3} for small systems ($n < 1000$) and \texttt{-{}-speed 5} for larger systems ($n < 100'000$). Value \texttt{-{}-speed 7} provides a quadratic solution and \texttt{-{}-speed 10} provides a linear solution.
\end{atreview}



\atadd{In \Cref{alg:swiper}, we present a simplified version that omits some important optimizations.
Nevertheless, its running time is still $O(poly(n))$. We start by picking the value of $X$ as in \Cref{subsec:wr-bound}.}
This already reduces the total number of tickets to $U = O(n)$.

The protocol proceeds to test all $U$ meaningful values of $X$ that change the ticket distribution, testing validity by solving knapsack (which we remind that for this particular instance can be efficiently computed) and keeping the valid distribution that yields the least amount of tickets as the solution. This search is further sped up by analyzing the values of $X$ that change the number of tickets of parties included in the optimal restriction set since taking tickets out of participants outside this set while keeping the tickets of included parties does not change the number of restricted tickets. Once a solution is found, it is pruned so that the total number of tickets is exactly $\lceil T_A/\fRn \rceil$ by discarding unnecessary tickets of parties not in the restricted set given its optimal choice strategy.
We do the computations twice, distributing first $\lfloor w_i/X \rfloor$ tickets to each party and then $\lceil w_i/X \rceil$, keeping as the final distribution the one that yields the fewest amount of tickets. 

\atadd{In the Python implementation, we speed up the search for the optimal value of $X$ by doing 2 types of binary search before the linear search described above. First, using linear relaxation of Knapsack as the upper bound on the number of tickets in the optimal restriction set and then using the polynomial exact algorithm for Knapsack. We also provide options to disable any of the steps to reduce the computation time of the algorithm at the cost of potentially having more tickets. Crucially, regardless of the selected \texttt{-{}-speed} parameter, our algorithm is deterministic and, thus, can be run independently by each party without a disagreement on the resulting ticket distribution.}

\subparagraph*{\bf Dora.} As stipulated by \Cref{thm:wr2wq}, we can solve the {\WQFull} problem by reducing it to {\WRFull}. Thus, we define our algorithm for solving {\WQShort}, called Dora, as: $\textsf{Dora}(\fQw, \fQn) := \textsf{Swiper}(1-\fRw, -1\fRn)$.


        

            

    

\begin{algorithm}
    \begin{smartalgorithmic}[1]
        \Input
            \State $w \in \mathbb{R}_{\ge 0}^n$ \quad $\fRn \in [0,1]$ \quad $\fRw \in [0,\fRn]$
        \EndInput
        \algspace[0.3]
        \Operation{$allocate(w, X, s)$}
            \If{$s = {floor}$}
                \State \textbf{return} $[\;\lfloor w[i]/X \rfloor~|~i \in \{1,\dots, n\}\;]$ 
            \EndIf
            \If{$s = {ceil}$}
                \State \textbf{return} $[\;\lceil w[i]/X \rceil~|~i \in \{1,\dots, n\}\;]$
            \EndIf
        \EndOperation
        \algspace[0.3]
        \Operation{$prune(t, w, \fRw, \fRn)$}
            \State ${restricted}, t^r = \Knapsack(w, t_s', \fRw W)$
            \State $t' \gets t$
            \State decrease $t'[i]$ for  $i \not \in {restricted}$ until $\sum_{i = 1}^n t'[i] = \lceil \frac{t^r}{\fRn} \rceil$
            \State \textbf{Return} $t'$
        \EndOperation
        \algspace[0.5]
        \State $W \gets \sum_{i = 1}^n w_i$
        \State ${strategies} \gets \{{floor}, {ceil}\}$
        \algspace[0.3]
        \For{$s \in {strategies}$}
        \If{s = floor}
            \State $X \gets \frac{W}{n} \cdot \frac{\fRn - \fRw}{\fRn}$
        \EndIf
        \If{s = ceil}
            \State $X \gets \frac{W}{n} \cdot \frac{\fRn - \fRw}{1 - \fRn}$
        \EndIf

        \algspace[0.3]
        \State $t_s \gets {allocate}(w, X, s)$
        \State $t_s' \gets t_s$
        \algspace[0.3]
        \While{True}
            \State ${restricted}, t_s^r = \Knapsack(w, t_s', \fRw W)$
            \algspace[0.3]
            \If{$t_s^r < \fRn \sum_{i = 1}^n t_s'[i]$}
            \algspace[0.1]
                \State $t_s \gets t_s'$
            \EndIf
            \algspace[0.5]
            
            \State $X' \gets $ min val to allocate $t_s'[i] - 1$ for $i \in {restricted}$
            \State $t_s' \gets {allocate}(w, X', n^*, s)$
            \If{$s = {floor}$ and $\sum_{i = 1}^n t_s' = 0$}
                \State \textbf{break}
            \EndIf
            \If{$s = {ceil}$ and $\sum_{i = 1}^n t_s' = n$}
                \State \textbf{break}
           \EndIf
        \EndWhile
        \EndFor

        \algspace[0.3]
        \State \textbf{return} $\min_{s \in {strategies}}({prune}(t_s, w, \fRw, \fRn))$
    \end{smartalgorithmic}
    
    \caption{The $\Swiper$ protocol.}
    \label{alg:swiper}
\end{algorithm}

\section{Applications of {\WRFull}} \label{sec:wr-applications}


Many distributed protocols, especially in the Byzantine corruption model and the blockchain setting, rely on distributed cryptographic primitives such as secret sharing~\cite{Sha79,avss-cachin-2002} and threshold signatures~\cite{threshold-cryptosystems,ThresholdSchnorr,ThresholdBLS}.
Furthermore, threshold signatures form the basis of the most commonly used protocol~\cite{random-oracles} for the problem of distributed random number generation (also known as threshold coin tossing, random beacon, or common coin), which, in turn, has numerous applications of its own.
However, most threshold cryptosystems are based on the idea of splitting a secret key into a number of discrete pieces such that any $t$ out of $n$ pieces are sufficient to reconstruct the secret key or perform operations on it (e.g., create a threshold signature).
Therefore, simple weighted voting, as described in \Cref{subsec:weighted-voting}, cannot be applied to such systems.

    


    




\subsection{Blunt Secret Sharing and derivatives} \label{subsec:blunt}

In cryptography, certain actions have an associated access structure $\mathbb{A}$ which determines all sets of parties that are able to perform these actions once they collaborate.
Traditional $(n,k)$-threshold systems can be seen as a particular access structure where $\mathbb{A} = \{P \subseteq [n]: |P|\ge k\}$.
Analogously, a \emph{weighted} threshold access structure can be defined as
$\mathbb{A} = \{P \subseteq \Pi: \sum_{i \in P} w_i \ge \beta \sum_{i \in \Pi} w_i\}$.

We can also define the \emph{adversary structure} $\mathbb{F} \subseteq 2^\Pi$, the set of all sets of parties that can be simultaneously corrupted at any given execution. Often, the adversary structure is also defined via a threshold, with a maximum corruptible weight fraction $\alpha$, e.g. $\mathbb{F} = \{P \subset \Pi: \sum_{i \in P} w_i \le \alpha \sum_{i \in \Pi} w_i\}$.

While threshold access structures are commonly studied in cryptography and are applied in numerous distributed protocols, in practice, as we discuss in \Cref{sec:derived-applications}, it is often sufficient if the access structure provides the following two properties:

\begin{itemize}
    \item There exists at least one set entirely composed of correct users that belongs to the access structure. This guarantees \emph{liveness properties} of the accompanying protocol.
    \item Any set containing only corrupt parties does not belong to the access structure, as this would break \emph{safety properties}. 
\end{itemize}

Hence, we define a \emph{blunt access structure} as follows:

\begin{definition}[Blunt access structure]
    Given a set of parties $\Pi$ and the \emph{adversary structure} $\mathbb{F} \subseteq 2^{\Pi}$, $\mathbb{A}$ is a blunt access structure w.r.t. $\mathbb{F}$ if $(\forall F \in \mathbb{F}: F \not \in \mathbb{A}) \text{ and } (\exists A \in \mathbb{A}: A \cap F = \varnothing)$.
\end{definition}


The following theorem shows that solving {\WRShort} is sufficient to implement weighted cryptographic protocols with blunt access structure by reduction to their nominal counterparts.

\begin{theorem}
    Given a set of parties, a nominal threshold access structure protocol $\protocol$ with threshold value $\fAn < 1/2$, we obtain a blunt threshold access structure w.r.t. a weighted threshold adversarial structure with parameter $\fAw < \fAn$ by solving $\WRShort$ with parameters 
    \atrev{$\fRw = \fAw$ and $\fRn = \fAn$}.
    This is accomplished by instantiating $\protocol$ with $\hat{n} = T$ virtual users and allowing party $i$ to control $t_i$ of them.\footnote{Recall that $t_i$ is the number of tickets assigned to party $i$ and $T$ is the total number of tickets assigned by the solution to the weight reduction problem (in this case, to {\WRShort}). See \Cref{sec:problem-statement} for details.}
    \label{thm:reductioncorrect}
\end{theorem}
\begin{proof}
    By definition of $\WRShort$, once it distributes $T$ tickets, the number of tickets (and, hence, virtual users) allocated to the corrupt parties will be less than $\fAn T$. Hence, no element of the adversary structure shall appear in the resulting access structure. In addition, honest participants will receive more than $(1-\fAn)T > \fAn T$ tickets, ensuring that \lfrev{there exists a} set of all correct parties in the access structure.
\end{proof}

\atadd{Note that it is crucial for all participants to agree on how many virtual users are assigned to each party as nominal protocols typically assume that the membership is common knowledge. To this end, it is sufficient for all parties to run an agreed upon \emph{deterministic} weight-restriction protocol.}

Among other things, this way, one can obtain weighted versions of secret sharing~\cite{Sha79}, distributed random number generation~\cite{random-oracles}, threshold signatures~\cite{ThresholdBLS}, threshold encryption~\cite{threshold-cryptosystems}, and threshold fully-homomorphic encryption~\cite{ThFHE-jain}, all with blunt access structures.
In the next section, we discuss how to do it for other access structures.

\subsection{Tight Secret Sharing and derivatives} \label{subsec:tight-secret-sharing}

Although a blunt access structure is sufficient for a large spectrum of applications, more restrictive access structures are sometimes necessary as well.
Here, we present a straightforward approach that involves just one extra round of communication to transform a blunt access structure 
into a weighted\atadd{ threshold} access structure.\footnote{In fact, this can be further generalized to arbitrary access structures.}
This means that our construction can be readily 
utilized in any protocol that already uses threshold cryptography without requiring significant redesign efforts. We showcase the transformation in \Cref{alg:blunt2weighted} using the particular example of a generic secret sharing scheme with threshold $\alpha$.

\begin{algorithm}
    \begin{smartalgorithmic}[1]
    
        \State $\{t_1,\dots,t_n\} \gets \mathit{\WRShort}(\{w_1,\dots,w_n\},\fAw,\fAn)$
        \State $T \gets \sum_{i = 1}^n t_i$
        
        \algspace[.5]
        \Operation{\textsc{Share}$(m,\{w_1,\dots,w_n\})$} \Comment{Executed by dealer.}
            \State $\{s_1^1,\dots, s_1^{t_1}, \dots, s_n^1,\dots, s_n^{t_n}\} \gets \atrev{(\lceil \fAn T \rceil, T)}$-$\mathit{share}(m)$
            \State $\forall j \in \atrev{[n]}:$ send $\langle \atrev{\text{SHARES}}:s_i^1,\dots, s_i^{t_i} \rangle$ to party $i$
        \EndOperation


        \algspace[.3]
        \Operation{\textsc{RETRIEVE}} \Comment{Executed by the parties.}
            \State Send $\langle {\text{REQUEST}} \rangle$ to all parties
        \EndOperation
        
        \algspace[.3]
        \Upon{receiving $\langle {\text{REQUEST}} \rangle$ from party $j$}
            \LineComment{$w_{req}$ is initially $0$}
            \State $w_{req} \gets w_{req} + w_j$
            \If{$w_{req} \ge \alpha \sum_{i = 1}^n w_i$}
                \State send shares received from the dealer to all parties
            \EndIf
        \EndUpon

        \algspace[0.3]
        \Upon{receiving \atrev{$\lceil \fAn T \rceil$} shares}
            \State Reconstruct message $m$
        \EndUpon
    \end{smartalgorithmic}
    \caption{Blunt to weighted access structure for party $i$}
    \label{alg:blunt2weighted}
\end{algorithm}

In order to obtain the weighted access structure, the first step is to compute how many shares need to be dealt to each party by solving the {\WRFull} problem. Using the nominal secret sharing operations, we generate shares for the input message by treating each ticket as a ``virtual user'', setting the total number of shares to the total number of tickets, and using the parameter $\fAn$ to set the reconstruction threshold. The \atreplace{source}{dealer} then sends to each party the number of shares determined by the solution to {\WRShort}.

In the reconstruction phase, each party keeps track of the total weight of parties that have requested the reconstruction. Once the established threshold is surpassed, the participants transmit the shares of the secret that they previously received from the \atreplace{source}{dealer}. Finally, the secret is reconstructed once the threshold is surpassed.

The correctness of this transformation comes from the fact that before parties corresponding to at least a fraction $\alpha$ of the total weight request the reveal of the secret, the honest parties do not send their shares, prohibiting the reconstruction of the secret as the shares of corrupted parties are not sufficient, by design, to perform this action. However, once this threshold is surpassed, all honest parties send their shares, and the secret is eventually retrieved, as their shares are, once again, by design, sufficient to surpass the threshold of the nominal secret sharing scheme.

Beyond simple secret sharing, one can obtain weighted versions of the same set of protocols as was discussed at the end of \Cref{subsec:blunt}, but with arbitrary access structures.



\subsection{Black-Box transformation} \label{subsec:black-box}

\atadd{The same approach of allocating a number of virtual users according to the number of tickets as described in \Cref{subsec:blunt} can be applied to arbitrary distributed protocols.
Intuitively, a distributed protocol $\protocol$ with resilience $\fAn$ ($\fAw$) in the nominal (weighted) model must solve the stated problem iff less than $\fAn n$ parties (parties with weightless than $\fAw W$) are corrupted.
Hence, by applying the ``virtual users'' approach, we can essentially emulate the nominal model in the weighted one as long as $\fAw < \fAn$. 
However, as we demonstrate later in this section on the example of the Single Secret Leader problem, this approach has its limitations with respect to what kinds of distributed problems can be solved with it.}

We illustrate the black-box transformation with two examples, showing first an example where it works smoothly and then an example where we have to slightly relax the problem statement for it to be applicable.

\subparagraph*{\bf Linear BFT consensus.} 
One of the major contributions of the Hotstuff protocol~\cite{yin2019hotstuff} was to achieve linear communication complexity BFT consensus. 
\atreplace{They have achieved this result}{This result was achieved} by designing the communication of the protocol in a star pattern, where each participant only communicates with the leader. Thus, in order for the leader to demonstrate that its proposal was accepted by a quorum of replicas, the protocol uses threshold signatures which guarantee that a valid signature can only be generated by combining at least $n-f$ shares. This guarantees that \atreplace{incomparable}{incompatible} values are never both validated by a quorum since they shall intersect \atreplace{into}{in at least} $f+1$ replicas and at least one of them will be correct, which cannot happen since honest replicas do not vote for different values.

\atrev{In this case, we cannot apply either of the construction \Cref{subsec:blunt} as we need a tight access structure for the threshold signature, nor can we apply the construction of \Cref{subsec:tight-secret-sharing} as it would make the communication complexity quadratic whereas the main goal of Hotstuff is to keep it linear.
However, what we can do is simply apply the virtual users approach in a black-box manner: pick any threshold $\fAw < \fAn$, run a deterministic {\WRShort} protocol, and determine how many virtual identities should each party assume.}



\subparagraph*{\bf Single Secret Leader Election.} SSLE~\cite{boneh2020single} is a distributed protocol that has as an objective to select one of the participants to be a leader with an additional constraint that only the elected party knows the result of the election. Then, once the leader is ready to make a proposal, it reveals itself and other participants can then correctly verify that the claiming leader was indeed elected by the protocol. 

The original paper contains nominal solutions for the protocol relying on ThFHE~\cite{ThFHE-boneh} and on shuffling a list of commitments under the DDH assumption. The authors initially suggest that their protocols could support weights by replicating each party to match their weights. As already discussed, this would create a huge overhead in the protocol for systems with large total weight. 

Interestingly, in the original protocol, it is required for the election to be \emph{fair}, that is, for the probability of each party being elected to be uniform. One could think however of an alternative formulation to the protocol where \emph{chain-quaility} is required instead, where we might specify that the fraction of blocks produced by corrupt parties should not surpass $\fAn$ when the adversary might control a fraction of the weights up to $\fAw$. In this case, we can thus simply apply {\WRShort} with parameters $\fRw = \fAw, \fRn = \fAn$, immediately guaranteeing such a notion.

Properties such as \emph{fairness} are one of the limitations of our transformations, since any property that is a function of the weight of the parties will not be preserved after the transformation is applied.


\section{Applications of Weight Qualification} \label{sec:wq-applications}




\subsection{Erasure-Coded Storage and Broadcast}

Erasure-coded storage systems~\cite{ida-rabin-89,ida-cachin-tessaro-05,ida-hendricks-07,ida-nazirkhanova-21,ida-yang-22}, also known under the names of Information Dispersal Algorithms (IDA)~\cite{ida-rabin-89} and Asynchronous Verifiable Information Dispersal (AVID)~\cite{ida-cachin-tessaro-05}, are crucial to many systems for space-efficient, secure, and fault-tolerant storage and load balancing.
Moreover, as demonstrated in~\cite{ida-cachin-tessaro-05}, they can yield highly communication-efficient solutions to the very important problem of asynchronous Byzantine Reliable Broadcast~\cite{textbook,BraTou85}, a fundamental building block in distributed computing that, among other things, serves as the basis for many practical consensus~\cite{honey-badger,beat-bft,all-you-need-is-dag,narwhal,bullshark}, distributed key generation~\cite{adkg,practical-adkg}, and mempool~\cite{narwhal} protocols.

The challenge of applying these protocols in the weighted setting is that $(k,m)$ erasure coding, by definition, converts the original data into $m$ discrete \emph{fragments} such that any $k$ of them are sufficient to reconstruct the original information.
Thus, each party will inevitably get to store an integer number of these fragments, and the smaller $m$ is, the more efficient the encoding and reconstruction will be.
\atadd{Moreover, for the most commonly used codes--Reed Solomon--the original message must be of size at least $k \log m$ bits. Hence, using a large $m$ may lead to increased communication as the message may have to be padded to reach this minimum size.}
As we illustrate in this section, determining the smallest ``safe'' number of fragments to give to each party is exactly the {\WQShort} problem, solved by {\Dora}.

Let us consider the example of~\cite{ida-cachin-tessaro-05} as it is the first erasure-coded storage protocol tolerating Byzantine faults. We believe {\Dora} can be applied analogously to other similar works. 

This protocol operates in a model where any $t$ out of $n$ parties can be malicious or faulty, where $t < \frac{n}{3}$.
In other words, it has the nominal fault threshold of $f_n = \frac{1}{3}$.
The protocol encodes the data using $(t+1,n)$ erasure coding, and the data is considered to be reliably stored once at least $2t+1$ parties claim to have stored their respective fragments.
The idea is that, even if $t$ of them are faulty, the remaining $t+1$ parties will be able to cooperate to recover the data.

In order to make a weighted version of this protocol, instead of waiting for confirmations from $2t+1$ parties, one needs to wait for confirmations from a set of parties that together possess more than a fraction $2\fw$ of total weight, where $\fAw = \fAn = \frac{1}{3}$.
A subset of weight less than $\fAw$ of these parties may be faulty.
Hence, for the protocol to work, it is sufficient to guarantee that any subset of total weight more than $2\fAw-\fAw=\fAw$ gets enough fragments to reconstruct the data.
To this end, we can apply the {\WQShort} problem with the threshold $\fQw = \fAw$.
We can set $\fQn$ to be an arbitrary number such that $0 < \fQn < \fQw$.
Then, we can use $(\lceil\fQn T\rceil, T)$ erasure coding, where $T$ is the total number of tickets allocated by the {\WQShort} solution.
Hence, whenever a set of weight more than $2\fAw$ of parties claim to have stored their fragments, we will be able to reconstruct the data with the help of the correct participants in this set.
As for the rest of the protocol, it can be converted to the weighted model simply by applying weighted voting, as was discussed in \Cref{subsec:weighted-voting}.

As a result, we manage to obtain a weighted protocol for erasure-coded verifiable storage with the same resilience as in the nominal protocol ($\fAw = \fAn = \frac{1}{3}$).
The ``price'' we pay is using erasure coding with a smaller rate ($\fQn$ instead of $\fAw$), i.e., storing data with a slightly increased level of redundancy. However, note that $\fQn$ can be set arbitrarily close to $\fAw$, at the cost of more total tickets\atadd{ and, hence, more computation}.

\subsubsection*{Example instantiations} %

The communication and storage complexity of these protocols depends linearly on the rate of the erasure code.
Using Reed-Solomon with Berlekamp-Massey decoding algorithm, the decoding computation complexity~\cite{rs-decoding-complexity} is $O(m^2 \cdot \frac{M}{rm}) = O(\frac{m}{r} \cdot M)$, where $M$ is the size of the message (which we do not affect), $r$ is the rate of the code (in our case, $r = \fQn$), and $m$ is the number of fragments (in our case, the number of tickets allocated by the solution to the {\WQShort} problem).
For the sake of illustration, let us fix $\fQn$ to be $\frac{1}{4}$.
Then, the rate of the code used in the weighted solution will be $\frac{4}{3}$ times smaller than in the nominal solution.
For the number of fragments $m$, let us substitute the upper bound\atadd{ from \Cref{subsec:wq-bound} \atrev{($m \le \frac{\min\{\fQw, 1 - \fQw\}}{\fQw - \fQn} n$)}. 
For $\fQw = \frac{1}{3}$ and $\fQn = \frac{1}{4}$, $m \le 4n$.
Hence, the overall slow-down compared to the nominal solution is $4 \cdot \frac{4}{3} \approx 5.33$.}

One can also consider using FFT-based decoding algorithms~\cite{rs-decoding-fft}. %
Since the complexity of the FFT-based decoding depends only polylogarithmically on the number of fragments $m$, one can select the rate of the code ($r = \fQn$) to be much closer to $\fQw$ and, thus, minimize communication and storage overhead.


Some protocols~\cite{rbc-erasures-high-threshold-trusted-setup} are designed for higher reconstruction thresholds, which allows them to be more communication- and storage-efficient compared to~\cite{ida-cachin-tessaro-05}. For these cases, we will need to set $\fQw := \frac{2}{3}$.
\atadd{By setting $\fQn := \frac{1}{2}$ and applying the upper bound from \Cref{subsec:wq-bound}, we will obtain the same reduction of factor $\frac{4}{3}$ in rate and $2$ times fewer tickets: $m \le \frac{\min\{2/3, 1 - 2/3\}}{2/3 - 1/2} n = 2n$.
The computational overhead will be $2 \cdot \frac{4}{3} \approx 2.66$.}








\subsection{Error-Corrected Broadcast}

\sloppy
The exciting work of~\cite{dxr21} illustrated how one can avoid the need for complicated cryptographic proofs in the construction of communication-efficient broadcast protocols by employing error-correcting codes, thus enabling a better communication complexity when a trusted setup is not available.
The protocol of~\cite{dxr21} can be used for the construction of communication-efficient Asynchronous Distributed Key Generation~\cite{adkg,practical-adkg} protocols.

Similarly to erasure codes, error-correcting codes convert the data into $m$ discrete fragments, such that any $k$ of them are sufficient to reconstruct the original information.
However, they have the additional property that the data can be reconstructed even when some of the fragments input to the decoding procedure are invalid or corrupted.
Reed-Solomon decoding allows correcting up to $e$ errors when given $k+2e$ fragments as input.

The protocol of~\cite{dxr21} tolerates up to $t$ failures in a system of $n \ge 3t+1$ parties (for simplicity, we will consider the case $n = 3t+1$).
Its key contribution is the idea of \emph{online error correction}. Put simply, the protocol first ensures that:
\begin{itemize}
    \item Every honest party obtains a cryptographic hash of the data to be reconstructed;
    \item Every honest party obtains its chunk of the data.
\end{itemize}
Then, in order to reconstruct a message, an honest party solicits fragments from all other parties and repeatedly tries to reconstruct the original data using the Reed-Solomon decoding and verifies the hash of the output of the decoder against the expected value.
As the protocol uses $k = t+1$ and $m = n$, after hearing from all $2t+1$ honest and $e \le t$ malicious parties, it will be possible to reconstruct the original data (as $2t+1+e \ge k + 2e$, for $k=t+1$).

To convert this protocol into the weighted model, it is sufficient to make sure that all honest parties together possess enough fragments to correct all errors introduced by the corrupted parties.
To this end, we will apply the {\WQShort} problem.
We will set $\fQw$ to the fraction of weight owned by honest parties, i.e., $\fQw := 1 - \fAw = \frac{2}{3}$ (where $\fAw$ will be the resilience of the resulting weighted protocol, $\fAw = \fAn = \frac{1}{3}$).
However, it is not immediately obvious how to set $\fQn$ to allow the above-mentioned property.

If we want to use error-correcting codes with rate $r$, we need to guarantee that the fraction of fragments received by the honest parties (which is at least $\fQn$) is at least $r+e$, where $e$ is the fraction of fragments received by the corrupted parties.
However, since honest parties get at least the fraction $\fQn$ of all fragments, then $e \le 1 - \fQn$.
Hence, we need to set $\fQn$ so that $\fQn \ge r + (1 - \fQn)$.
We can simply set $\fQn := \frac{r}{2} + \frac{1}{2}$ for arbitrary $r < \frac{1}{3}$.

\subsubsection*{Example instantiation}
For the sake of an example, we can set $\fQw := \frac{2}{3}$, $r := \frac{1}{4}$ and $\fQn := \frac{5}{8}$.
Then, using the bound from \Cref{subsec:wq-bound}, the number of tickets will be at most $\frac{1 - \fQw}{\fQw - \fQn} \cdot n = 8n$.

As was discussed above, for erasure codes, we can either use the Berlekamp-Massey decoding algorithm or the FFT-based approaches.
The same applies to error-correcting codes.
As most practical implementations use the former, we will focus on it.
In this case, the communication overhead will be $\frac{r_n}{r_w}$, where $r_n = \frac{1}{3}$ is the rate used in the nominal protocol and $r_w$ is the rate used for the weighted protocol (in the example above, $r = \frac{1}{4}$).
The computation overhead is $\frac{r_n}{r_w} \cdot \frac{T}{n}$, where $T$ is the number of tickets allocated by the {\WQShort} solution (in the example above, $T \le 8n$).
Hence, for the example parameters, the worst-case computational overhead is $\frac{4}{3} \cdot 8 \approx 10.66$.

\section{Derived Applications} \label{sec:derived-applications}

In this section, we discuss indirect applications of weight reduction problems that are obtained by using one or multiple building blocks discussed in \Cref{sec:wr-applications,sec:wq-applications}.
Crucially, for all applications discussed here, we manage to avoid losing resilience despite applying weight reduction.
In all cases, the bulk of the protocol should be converted to the weighted model by applying weighted voting, as discussed in \Cref{subsec:weighted-voting}.


\subsubsection*{Asynchronous State Machine Replication}

For asynchronous state machine replication protocols~\cite{honey-badger,beat-bft,all-you-need-is-dag,narwhal,bullshark}, we simply need to use a weighted communication-efficient broadcast protocol (discussed in \Cref{sec:wq-applications}) and weighted distributed random number generation (discussed in \Cref{subsec:blunt}).
Crucially, the distributed number generation part can use a nominal protocol with threshold $\fRn = \frac{1}{2}$ and set $\fRw := \frac{1}{3}$, which is the resilience of the rest of the protocol.
Thus, in some sense, we level the resilience of different parts of the protocol, without affecting the resilience of the composition.

\subsubsection*{Validated Asynchronous Byzantine Agreement}

The same approach can be applied to generate randomness for Validated Asynchronous Byzantine Agreement (VABA)~\cite{vaba-cachin,vaba-abraham}.

These protocols also require tight threshold signatures.
However, in practice, multi-signatures~\cite{ohta1999multi,ThresholdBLS} can be applied instead as they have almost no overhead over threshold signatures on the system sizes where such protocols could be applied (below 1000 participants): it suffices to append the multi-signature with an array of $n$ bits, indicating the set of parties that produced the signature.
Then, along with the verification of the validity of the multi-signature itself, anyone can verify that the signers together hold sufficient weight.

Alternatively, one could apply the approach described in \Cref{subsec:tight-secret-sharing} to implement tight weighted threshold signatures. However, it would lead to an increase in message complexity of the resulting protocol, which we want to avoid.

Finally, an ad-hoc weighted threshold signature scheme can be applied, such as the one recently proposed in~\cite{das2023threshold}.
Note that these signatures cannot be used for distributed randomness generation as they lack the necessary uniqueness property, and thus we still need to apply {\Swiper} to obtain a complete protocol.

\subsubsection*{Consensus with Checkpoints}

We can apply the same approach for checkpointing proof-of-stake consensus protocols~\cite{pikachu}, but this time for blunt threshold signatures (as discussed in \Cref{subsec:blunt}) instead of random number generation. If, for some reason, one wants to use a tight threshold signature, the approach described in \Cref{subsec:tight-secret-sharing} can be applied at the cost of just 1 additional message delay per checkpoint.

Compared to ad-hoc solutions for weighted threshold signatures~\cite{das2023threshold}, we claim that our approach is more computationally efficient as it is basically as fast as the underlying nominal protocol. 
For example, 1 pairing to verify a BLS signature~\cite{ThresholdBLS} compared to 13 pairings to verify a signature in~\cite{das2023threshold}.
Moreover,\atreplace{ our}{ the weight reduction} approach is more general and can support other types of threshold signatures, such as RSA~\cite{rsa-threshold-signatures} and Schnorr~\cite{ThresholdSchnorr}, the latter being particularly important in the context of checkpointing to Bitcoin~\cite{pikachu}.

\section{Splitting Attacks} \label{sec:splitting-attacks}

We claim that the total number of tickets distributed by our protocol is a function of the number of parties in the system and not its total weight. From the results we obtained so far, however, it might seem that an adversary who controls an amount $\fRw W$ of weight is able to split itself into $\lfloor \fRw W \rfloor$ parties, making the number of participants of the system a function of the total weight and thus nullifying our claim. We call such an attack a \emph{Splitting Attack}, as defined in \cref{def:sybilattack}. 

\begin{definition}[Splitting attack on a weight reduction protocol]
    Given a system of $n_H$ parties with weights $w_1', w_2', \dots, w_{n_H}'$, the adversary includes as many participants as it wants into the system, with the constraint that the sum of the weight of these new participants is at most $\frac{\fAw}{1-\fAw}\sum_{i = 1}^{n_H} w_i'$.
    The parties are shuffled and relabeled into a list with weights $w_1,w_2,\dots,w_n$, which shall correspond to the input of the weight reduction protocol.
\label{def:sybilattack}
\end{definition}

This definition is natural, as it only reiterates the fact that the adversary controls a fraction $\fAw$ of the system weight, but that its goal here is to increase the number of parties in the system. Notice also that it is also equivalent to the scenario where the adversary first corrupts a set of parties and then redistributes the weight into several entities, but the proposed formulation will, in our opinion, make the later analysis easier to follow. We then define splitting resistance in~\cref{def:sybilresistance}.

\begin{definition}[Splitting-resistant weight reduction]
\atrev{A weight reduction algorithm is splitting-resistant if the total number of tickets and the complexity of the algorithm is ${poly}(n_H)$.}
\label{def:sybilresistance}
\end{definition}


Let us show that any optimal solution to $\WRShort$, as well as the division approach, are both splitting resistant. Suppose that our input was compromised by a splitting attack. The actual number of honest \atreplace{processes}{participants}, $n_H$ is unknown, but it is possible to find a lower bound for it. WLOG, let us suppose that the parties are sorted in decreasing weight order, then let us define $n^*$ as the following:

\begin{gather*}
    \sigma(\eta) = \sum_{i = \eta}^n w_i \\
    n^* = min(\{\eta | \sigma(\eta) \le \fAw \sigma(1)\})
\end{gather*}

That is, $n-n^*+1$ is the maximum number of participants that can be corrupted at the same time by the adversary, obtained by taking the corruption set as the parties with the smallest weight possible. For this reason, if the input is the result of a splitting attack on the system, then this number is an upper bound at the number of parties included by the adversary. Equivalently, $n^* - 1$ is a lower bound on the number of honest parties in the system.

    We can fix the number of tickets assigned to parties from $p_{n^*}$ to $p_n$ zero. Then, we can solve {WR} on the remaining parties by adjusting the restriction threshold to a new value $\fRw'$. If the original problem had parameter $\fRw$, then in terms of absolute weight, the threshold was $\fRw W$. The weight of the system becomes $W'= W - \sum_{i = n^*}^n w_i$, thus in order to keep the semantics of the problem correct, we need that $\fRw'W' = \fRw W$.   

    Since we require $\fRw' < \fRn$ for the problem to be solvable with arbitrary inputs, we have that:

    \begin{gather*}
    \fRw' = \fRw \frac{W}{W'} \le \frac{\fRw}{1-\fAw}
    \end{gather*}

    Therefore, as long as $\fRw \le (1-\fAw)\fAn$, a solution to $\WRShort(\{w_i\}_{i = 1}^{n^* - 1}, \allowbreak \fRw', \fRn)$ is a valid splitting resistant solution to $\WRShort(\{w_i\}_{i = 1}^{n}, \fRw, \fRn)$.








\section{Analyzing {\WRFull} on sample systems} \label{sec:empirical-study}

% Figure environment removed

\begin{lfreview}
\subparagraph*{\bf Experiment description.} We performed two kinds of experiments on real blockchain data. In the first experiment, shown in Figure \ref{fig:expthreshold}, we analyzed the influence of the choice of parameters $\fRw$ and $\fRn$ for the original data retrieved from the blockchains; the value of $\fRn$ was varied in the range $[0.1, 1]$, while the value of $\fRw$ was tested in the range $[0.1 \times \fRn, 0.9 \times \fRn]$. In the experiments showcased in \Cref{fig:expboostrapping}, we kept these parameters fixed and analyzed the influence of the number of parties in the metrics we tracked. In order to have the same blockchain with different numbers of parties, we have used a bootstrapping statistical technique where we performed $1000$ experiments sampling parties with replacement from the blockchain data and taking the average of the results.

In each experiment, we tracked the total number of tickets distributed, the maximum number of tickets held by a single party, and the number of parties that get at least one ticket (in the experiments we label them as the number of holders). In Figure \ref{fig:exptezos}, we show the results for the Tezos blockchain, but the results for Algorand, Aptos, and Filecoin are also available in \Cref{sec:remainingplots}. The analysis of the results reveals the following information: the upper bound given is very pessimistic, with the total number of tickets very rarely surpassing the number of parties for different values of $\fRn, \fRw$. The total number of tickets varies extremely close to a linear function on the number of parties, as well as the number of holders. The maximum number of tickets, on the other hand, seems to saturate when the number of parties in absolute terms surpasses the order of magnitude of $1000$, remaining almost constant after that point.
\end{lfreview}


    




\section{Related Work} \label{sec:related}
    
The simplest solution for creating a weighted threshold cryptographic system is to simply have a user of weight $w$ to become $w$ virtual users and to give one key to each of them. Shamir's paper describing his secret sharing scheme~\cite{Sha79} puts forward this solution. %
However, in practice, the total weight tends to be prohibitively large, and \textbf{quantizing} it requires solving weight reduction problems, which is the main subject of this paper.

There is a large body of work studying ad-hoc weighted cryptographic protocols~\cite{GarJaiMukSinWanZha22,BeiWei06,ChaKia21,ItoSaiNis89,das2023threshold,ss-from-wiretap-channels}.
Compared to these works, the weight reduction approach studied in this paper has a number of benefits, such as simplicity, efficiency, wider applicability, and a wider range of possible cryptographic assumptions.
Moreover, in many cases, ad-hoc solutions can be combined with and benefit from weight reduction.

\atadd{A recent work~\cite{ss-from-wiretap-channels} mentioned a similar idea of reducing real weights to integers to construct \emph{ramp} secret sharing.
This project has been started and the first versions of Swiper have been drafted before the online publication of~\cite{ss-from-wiretap-channels}.
As the main focus of~\cite{ss-from-wiretap-channels} is different, we believe that we do a much more in-depth exploration of this direction by studying different kinds of weight reduction problems and their applications beyond secret sharing and suggesting protocols that are not only linear in the worst case, but also allocate very few tickets in empirical evaluations on real-world weight distributions.}






\section{Concluding remarks} \label{sec:conclusion}

\begin{atreview}
In this paper, we have presented a family of optimization problems called weight reduction that, to the best of our knowledge, has not been studied before. We provided practical protocols to find good, albeit not optimal, solutions to these problems.
As we have shown, it allows us to efficiently solve many weighted distributed problems.

\atadd{We are currently working on polynomial \emph{exact} solutions to the weight reduction problems, i.e., algorithms that would always yield the minimum possible number of tickets for any given weight distribution. Nevertheless, fast approximate algorithms will remain relevant for large systems.}

The discussion we present is extensive but not yet complete.
Many interesting questions remain to be answered. Among them is the full formal characterization of problems that can be solved by our transformations. %
We have also only considered threshold adversaries. 
Other forms of corruption remain to be considered.

One important aspect of proof-of-stake blockchains is the distribution of incentives, which should depend on the weight of each party, hence meriting further discussion in future work. This combines with a discussion of other adversarial models where all participants are rational, and there is no honest majority.  %

The behavior of adversaries against a protocol is also interesting. We have discussed the splitting attack and have shown that, under some conditions, the number of tickets produced is upper bound by a function of the number of honest parties.
However, as seen in the empirical performance of the protocol, the weight distribution affects the resulting number of tickets. 
Hence, it is interesting to study how much the performance of the resulting protocols can be affected by the adversary redistributing its stake in the worst possible way, not to gain more tickets, but to increase the total number of tickets in the system, and thus compromise the performance.


\end{atreview}
\bibliographystyle{ACM-Reference-Format}
\bibliography{references}

\appendix
\section{Solving Knapsack}
\label{app:knap}

The $\Knapsack$ problem is a very well-known and studied optimization problem. Methods used to solve it include mixed integer programming, branch and bound, and dynamic programming. In this paper, we will be required to solve $\Knapsack$, which is generally an NP-complete problem. However, as we shall shortly prove in \Cref{sec:bound}, the number of keys distributed in an optimal $\WRP$ solution is $O(n)$, which will allow us to solve our $\Knapsack$ instances in $O(n^2)$ time by running \emph{dynamic programming by profits}. For completeness, and because one of our solutions to weight reduction solutions heavily rely on it, we present this $\Knapsack$ solution in \Cref{alg:knapsack}. More detailed explanations and correctness analysis can be found in~\cite{KnapsackProblems04}.

\begin{algorithm}[!htb]
    \begin{smartalgorithmic}[1]
        \Input
            \State $C \in \mathbb{R}_{\ge 0}$ -- capacity
            \State $w \in \mathbb{R}_{\ge 0}^n$ -- weights
            \State $k \in \mathbb{Z}_{\ge 0}^n$ -- profits (keys in our use case)
            \State $U \in \mathbb{Z}_{\ge 0}$ -- upper bound on solution
        \EndInput
        
        \algspace[0.5]

        \State ${dp}[0] \gets 0$
        \For{$q \gets 1$ to $U$}
            \State ${dp}[q] \gets \infty$
        \EndFor
        
        \algspace[0.3]
        
        \For{$j \gets 1$ to $n$}
            \For{$q \gets U$ down to $k[j]$}
                \If{${dp}[q - k[j]] + w[j] < {dp}[q]$}
                    \State ${dp}[q] \gets {dp}[q-k[j]] + w[j]$
                \EndIf
            \EndFor
        \EndFor
        
        \algspace[0.5]
        \State \textbf{Return} $\max\{ q | {dp}[q] \le C\}$
    \end{smartalgorithmic}

    \caption{$\Knapsack$ using DP by profits}
    \label{alg:knapsack}
\end{algorithm}

The basic idea of the algorithm is to build an array ${dp}$, for which in each position ${dp}[q]$ is stored the minimum weight necessary to reach profit $q$.
By definition, the minimum weight to achieve profit $0$ is zero, while the other positions are solved using the following recursion:  

\begin{gather*}
    {dp}_j[q] = \begin{cases}
        {dp}_{j-1}[q] & \text{if } q < k[j] \\
        \min({dp}_{j-1}[q], {dp}_{j-1}[q - k[j]] + w[j] & \text{otherwise}
    \end{cases}
\end{gather*}

That is, considering only the first $j$ items the minimum weight necessary to achieve profit $q' + k[j]$ is the minimum between the minimum weight necessary to achieve profit $q' + k[j]$ fixing the first $j-1$ parties and the weight necessary to achieve $q'$ plus the weight of party $j$. \Cref{alg:knapsack} finds the value of the array ${dp}$ for the first $n$ elements, i.e. the whole system. Thus, the solution is the last position of the array that does not exceed capacity.

\atadd{To reduce the memory footprint while still being able to reconstruct not only the optimal profit but also the items, one can apply the divide-and-conquer method~\cite[Section 3.3]{KnapsackProblems04}.}

\section{Exact solution to {\WRShort}}
\label{app:exact}

The way we formulate $\WRShort$ in \cref{def:wrp} can be directly translated into an instance of bi-level optimization problem~\cite{ColMarSav07}. In such problems, we define an \emph{upper level} optimization problem which contains another (lower-level) optimization problem in its constraints, namely: 

\begin{align*}
\text{minimize} & \sum_{i=1}^nt_i\\
\text{subject to} & \sum_{i=1}^nx_it_i \le \fRn \sum_{i=1}^nt_i\\
& \text{maximize} \sum_{i=1}^nx_it_i \\
& \text{subject to} \sum_{i=1}^nw_ix_i \le \fRw\sum_{i=1}^nw_i \\
& \sum_{i=1}^nt_i \ge 1\\
& x_i \in \{0,1\}, t_i \in \{0,1,2,\dots\}
\end{align*}

The following theorem will be useful for simplifying this formulation and others we shall build.
\begin{theorem}
Minimizing the total number of tickets that the adversary can corrupt in $\WRFull$ is equivalent to minimizing the total number of keys.
\begin{proof}
Let $T_A$ be the maximum number of tickets that the adversary can corrupt in a solution of $\WRShort$ that distributes $\totalticket$ tickets in total, then:
\[
\totalticket = \left\lceil \frac{T_A}{\fRn} \right\rceil
\]
This stems from the fact that the problem requires $T_A \le \fRn\totalticket \implies \totalticket \ge T_A/\fRn$. The minimum integer that satisfies this constraint is given by the expression above. Because this is an increasing function, the theorem holds.
\end{proof}
\label{thm:minka}
\end{theorem}

\Cref{thm:minka} allows us to reformulate $\WRShort$ as a minimax problem:
\begin{align*}
\min_t \max_x & \sum_{i=1}^nx_it_i\\
\text{subject to} & \sum_{j=1}^nx_it_i \le \fRn\sum_{i=1}^nt_i\\
& \sum_{i=1}^nw_ix_i \le \fRw\sum_{i=1}^nw_i \\
& \sum_{i=1}^nt_i \ge 1\\
& x_i \in \{0,1\}, k_i \in \{0,1,2,\dots\}
\end{align*}

A common method for solving minimax problems in MIP is to minimize a new variable that is greater or equal to all the feasible options, which eliminates in our case the variable $x$, but introduces $O(2^n)$ constraints to the problem, as the following:

\begin{align*}
\text{minimize } & K_A \\
\text{subject to } & K_A \le T_K\sum_{i=1}^nk_i\\
& \forall I \subseteq [n] \text{ s.t. } \sum_{i \in I} w_i \le T_wW: \sum_{i \in I} k[i] \le K_A \\
& \sum_{i=1}^nk_i \ge 1\\
& x_i \in \{0,1\}, K_A,k_i \in \{0,1,2,\dots\}
\end{align*}

We can replace the exponential constraints on every subset of weight less than $\fw W$ by a constraint on the $\Knapsack$ solution, as it will bound all feasible solutions. In order to do so, we hardcode \cref{alg:knapsack} into the constraints of $\WRP$ as follows:

\begin{align}
\text{minimize } & K_A \notag\\
\text{subject to } & K_A = \max(\kappa~|~{dp}[n][\kappa] \le \fw W) \label{eqn:ka}\\
& K_A \le T_K\sum_{i=1}^nk_i \notag\\
& \sum_{i=1}^nk_i \ge 1\notag\\
& \sum_{i=1}^nk_i \le U\notag\\
& \forall i \in \{0,\dots, n\}: {dp}[i][0] = 0 \notag \\
& \forall \kappa \in \{1,\dots,U\}: {dp}[0][\kappa] = W \notag\\
& \forall i \in \{1,\dots,n\}, \kappa \in \{1,\dots,U\} :{dp}[i][\kappa] =\notag\\
& \begin{cases}
    \min({dp}[i-1][\kappa], {dp}[i-1][\kappa-k_i] + w_i) & \text{ if $\kappa \ge k_i$} \\
    {dp}[i-1][\kappa] & \text{ if $\kappa<k_i$}
\end{cases} \label{eqn:dp} \\
& x_i \in \{0,1\}, K_A,k_i \in \{0,1,2,\dots, U\} \notag
\end{align}

Since the objective function minimizes $K_A$ and constraint \ref{eqn:ka} stipulates that this same variable is the maximum of other variables, it is enough to require $K_A$ to be greater than each of the maximum argument, as follows:
\begin{gather}
\forall \kappa \in \{0,\dots,U + 1\}: \alpha[\kappa] = \True \implies K_A \ge \kappa \label{eqn:kagek}\\
\forall \kappa \in \{0,\dots,U + 1\}: \alpha[\kappa] = \True \implies {dp}[n][\kappa] \le \fw W \label{eqn:alpha2}\\
\forall \kappa \in \{0,\dots,U + 1\}: {dp}[n][\kappa] \le \fw W \implies \alpha[\kappa] = \True \label{eqn:alpha1}
\end{gather}

Constraints \ref{eqn:kagek} and \ref{eqn:alpha2} are linearized as follows:
\begin{gather*}
\forall \kappa \in \{0,\dots,U\}: K_A  \ge \kappa\times \alpha[\kappa]\\
{dp}[n][\kappa] \le \fw W + (1-\alpha[\kappa])\times(1-\fw)W
\end{gather*}

While constraint \ref{eqn:alpha1} is linearized by the following transformations:
\begin{gather*}
{dp}[n][\kappa] \le \fw W \implies \alpha[\kappa] = \True \Leftrightarrow\\
\alpha[\kappa] = \False \implies {dp}[n][\kappa] > \fw W \Leftrightarrow\\
{dp}[n][\kappa] + \alpha[\kappa]\fw W \ge \fw W + \epsilon
\end{gather*}

Here, $\epsilon$ is a very small number.

The reason why constraint \ref{eqn:dp} is not linear is because it indexes an array with a variable. This can be avoided by expanding the indexing to a case-by-case assignment:
\begin{gather}
    {dp}[i][\kappa] = \begin{cases}
        \min({dp}[i-1][\kappa], {dp}[i-1][0] + w_i) & \text{ if $\kappa - k_i = 0$} \\
        \min({dp}[i-1][\kappa], {dp}[i-1][1]+ w_i) & \text{ if $\kappa - k_i = 1$} \\
        \cdots \\
        \min({dp}[i-1][\kappa], {dp}[i-1][\kappa]+ w_i) & \text{ if $\kappa - k_i = \kappa$} \\
        \min({dp}[i-1][\kappa], w_i) & \text{ if $\kappa - k_i < 0$}
    \end{cases}
\label{eqn:casedp}
\end{gather}

We then introduce $n\times (U+1) \times (U+2)$ variables $\beta[1..n][0..U+1][0..U+2]$ to check which of the cases should be applied as follows:
\begin{gather*}
    \kappa - k_i = 0 \implies \beta[i][\kappa][0] = \True \\
    \kappa - k_i = 1 \implies \beta[i][\kappa][1] = \True \\
    \cdots \\
    \kappa - k_i = k \implies \beta[i][\kappa][k] = \True \\
    \kappa - k_i < 0 \implies \beta[i][\kappa][k+1] = \True 
\end{gather*}

The last of these constraints can be written as:
\begin{gather*}
    \kappa - k_i < 0 \implies \beta[i][\kappa][\kappa+1] = \True \Leftrightarrow \\
    \beta[i][\kappa][\kappa+1] = \False \implies \kappa - k_i \ge 0\Leftrightarrow \\
    \kappa - k_i + \beta[i][\kappa][\kappa+1]\times U \ge 0
\end{gather*}

The other constraints all follow the same pattern, which can be rewritten as:
\begin{gather*}
    \kappa - k_i = \ell \implies \beta[i][\kappa][\ell] = \True \Leftrightarrow \\
    \beta[i][\kappa][\ell] = \False \implies \kappa - k_i < \ell \lor \kappa - k_i > \ell \Leftrightarrow \\
    \beta[i][\kappa][\ell] = \False \implies \kappa - k_i \le \ell-1 \lor \kappa - k_i \ge \ell+1
\end{gather*}

In order to represent a constraint with an OR logical operation, it is necessary to introduce auxiliary variables to enforce it.
\begin{gather*}
    \beta[i][\kappa][\ell] = \False \implies \gamma[i][\kappa][\ell][0] + \gamma[i][\kappa][\ell][1] \ge 1 \\[6pt]
    \gamma[i][\kappa][\ell][0] = \True \implies \kappa - k_i \le \ell-1 \Leftrightarrow \\ 
    \kappa - k_i \le (1- \gamma[i][\kappa][\ell][0])\times U + \ell-1 \\[6pt]
    \gamma[i][\kappa][\ell][1] = \True \implies \kappa - k_i \ge \ell+1 \Leftrightarrow \\
    \kappa - k_i + (1- \gamma[i][\kappa][\ell][1])\times U \ge  \ell+1
\end{gather*}

By introducing variables $\forall i \in \{1, \dots, n\}, \kappa, \ell \in \{1, \dots, U+1\}: m[i][\kappa][\ell] = \min({dp}[i-1][\kappa], {dp}[i-1][\ell] + w_i)$, and the above conditions, Constraint \ref{eqn:casedp} becomes:
\begin{gather*}
    \sum_{\ell \in \{0..U+2\}} \beta[i][\kappa][\ell] = 1 \\[6pt]
    {dp}[i][\kappa] \ge \begin{cases}
        m[i-1][\kappa][0] - (1-\beta[i][\kappa][0])\times W \\
        m[i-1][\kappa][1] - (1-\beta[i][\kappa][1])\times W \\
        \cdots \\
        m[i-1][\kappa][U] - (1-\beta[i][\kappa][U])\times W \\
        {dp}[i-1][\kappa] - (1-\beta[i][\kappa][U+1])\times W
    \end{cases} \\[6pt]
    {dp}[i][\kappa] \le \begin{cases}
        m[i-1][\kappa][0] + (1-\beta[i][\kappa][0])\times W \\
        m[i-1][\kappa][1] + (1-\beta[i][\kappa][1])\times W \\
        \cdots \\
        m[i-1][\kappa][U] + (1-\beta[i][\kappa][U])\times W \\
        {dp}[i-1][\kappa] + (1-\beta[i][\kappa][U+1])\times W
    \end{cases}
\end{gather*}

All that is left is linearizing the minimum function, computing the variables $m$. Note that the minimum of two values $a$ and $b$ is less or equal to both values. Moreover, it is also greater or equal $a$ if $a \le b$ or greater or equal $b$, otherwise. This remark allows us to define the minimum function in the following manner:
\begin{gather*}
    m[i][\kappa][\ell] \le {dp}[i-1][\kappa] \\
    m[i][\kappa][\ell] \le {dp}[i-1][\ell] + w_i \\[6pt]
    {dp}[i-1][\kappa] > {dp}[i-1][\ell] + w_i \implies \delta[i][\kappa][\ell] = \True \Leftrightarrow \\
    \delta[i][\kappa][\ell] = \False \implies {dp}[i-1][\kappa] \le {dp}[i-1][\ell] + w_i \Leftrightarrow \\
    {dp}[i-1][\kappa] \le \delta[i][\kappa][\ell]\times W + {dp}[i-1][\ell] + w_i \\[6pt]
    m[i][\kappa][\ell] + \delta[i][\kappa][\ell]\times W \ge {dp}[i-1][\kappa] \\
    m[i][\kappa][\ell] + (1-\delta[i][\kappa][\ell])\times W \ge {dp}[i-1][\ell] + w_i
\end{gather*}

\section{Experiment Results in the other Blockchains}
\label{sec:remainingplots}

% Figure environment removed
% Figure environment removed

% Figure environment removed

\end{document}