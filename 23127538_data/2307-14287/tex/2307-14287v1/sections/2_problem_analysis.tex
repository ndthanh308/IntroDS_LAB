\section{Problem Analysis}
\label{sec:problem_analysis}
In this section, we first present our assumptions regarding data enrichment in DSP systems and then elaborate on general applicable use cases in this field.

\subsection{Assumptions}
The processing of unbounded data streams requires DSP systems to in theory execute indefinitely. 
As the near-to real-time processing of events is crucial for a wide range of applications, various requirements must be met by the DSP system depending on the application.
In this work, we therefore primarily focus on low-latency streaming jobs, but there are other relevant aspects that must be considered.

One such aspect is the reliability of a streaming job. 
System failures are common in large clusters, and for DSP jobs that are required to operate indefinitely, failures are inevitable, making it essential for the DSP system to guarantee exactly-once semantics and recovery from failures. 
Data enrichment methods should consequently take this into account and exhibit certain robustness.
Another important requirement is scalability, as the workload of a stream may change over time, leading to the need for adding new resources to avoid performance degradation or removing resources to optimize resource utilization.
Depending on the concrete design, this can also affect an employed data enrichment method.
Lastly, streaming applications and their underlying architectures can quickly lead to an increase in complexity, i.e., in light of the distributed execution graph, heterogeneous data sources, or data sinks.
This is further reinforced through support for libraries that enable ML or graph processing.

\subsection{Data Enrichment Use Cases}

Data processing in a DSP system often requires additional context for accurate analysis and interpretation. 
To achieve this, enrichment with additional data can be performed during the execution of the DSP job.
There are several reasons why data enrichment could be necessary. 
Firstly, the incoming data streams may lack the necessary information to provide accurate insights. 
For example, if a system is monitoring sensor data, it may be necessary to enrich the data with information about the location, time, or weather conditions to understand the context in which the data was collected.
In case of constrained network links as in IoT environments, this can furthermore reduce the size of the individual events and lower overall network overhead, as events remain compact in size until they reach the DSP system in the cloud, where they are eventually enriched.
Secondly, data enrichment can help to detect anomalies or patterns that may be hidden in the data. 
By adding more information to the data, it may be possible to identify patterns that were not apparent before, such as identifying fraud or predicting a failure before it occurs.
Thirdly, data enrichment can help to integrate data from multiple sources. 
In DSP systems, data may come from multiple sources, and integrating this data can be a complex process. 
By enriching the data with additional information, it may be possible to integrate data from different sources and provide a more complete picture of the target system.

Data enrichment during execution can vary greatly based on the use case, and the underlying architecture and priorities can be unique. 
Due to the diversity of use cases, there is no one-size-fits-all solution for enriching events in a DSP system. 
In order to carve out the advantages and disadvantages of particular solutions, we conduct a comprehensive evaluation of different enrichment methods.
For this endeavor, we derive the following broad use case categories, along the criteria of data availability, data volume, and time sensitivity:

\begin{itemize}
\item \underline{Simple Queries:} In many instances, a data enrichment use case includes common operations, for instance, a simple key-value database query, where the event contains a key and there is one value in the database that can be efficiently queried.
An example would be the location of a sensor in an IoT environment that could be queried by a key.
Other examples include API requests or inference services of ML applications.
We envision that for this category, all these examples have in common that the response time is fairly constant, yet loading the entirety of information is not possible, for example, due to capacity limitations (e.g. databases), service barriers (APIs of closed systems), or undeterministic data (e.g. time-sensitive information such as weather data).
\item \underline{Complex Queries:} This category resembles the first one, with the difference that queries or data formats are more complex, and hence response times can be fluctuating.
This is for instance the case for complex database queries that include multiple join statements (e.g. for fraud detection), or for API requests which trigger different behavior depending on the payload.
This increased complexity hinders the migration of information directly to the respective DSP system for accelerated data enrichment.
\item \underline{Finite Data Sources:} In certain scenarios, the information used for enriching streaming events might be compact in size and hence might qualify for a migration directly to the DSP system as embedded state. 
Examples range from small disclosed ML models, which generate a data output for each data input, to static sensor information.
While potentially beneficial for event latencies, additional challenges are raised with respect to state handling within the DSP system as well as resource management. 
\end{itemize}

The goal of our evaluation is to determine suitable enrichment methods for specific use cases originating from our defined use case categories, to allow for guidance, and to enable practitioners to make informed decisions.

\subsection{Enrichment Methods}

In the following, we discuss various methods of enriching events in state-of-the-art DSP systems. 
These methods serve as a baseline for investigating the previously identified categories of data enrichment use cases.\\
\textbf{Datasource Client.} This method connects to an external data source to access the data for single / batches of events, which can be performed either synchronously or asynchronously.
\begin{itemize}
    \item \underline{Synchronous}: A synchronous client is the simplest way to connect to an external data source. This method enriches each event with the result of a synchronous query to the data source. Although a blocking procedure, the advantage of this method is that it can be easily integrated into existing architectures, and most conventional databases provide a synchronous client. If a pattern recognition model is used for enrichment, this method can be applied if the model is executed in an external service.
    \item \underline{Asynchronous}: This method involves using an asynchronous client to connect to the external data source, allowing for parallel execution of queries and improved utilization of query times. This requires the availability of an asynchronous client library. If no such library is available, asynchronous queries can be simulated with a custom multi-threading implementation.
\end{itemize}
\textbf{Cache.} To reduce access to external and potentially slow data sources, a subset of the data can be cached for faster access and to reduce dependencies. The data format must be able to be cached, and the external data should not change frequently. For aggregation operations, caching can quickly become costly.
\begin{itemize}
    \item \underline{Local Caching}: This method caches a subset of the external data within the respective operation of the DSP system. In case of a cache miss, a query to the external data source is executed. This method reduces latency and the load on the external system, and can store non-serializable objects. The storage capacity of the local cache depends on the worker node's storage capacity.
    \item \underline{External In-Memory Database Cache}: This method caches a subset of the external data in an external in-memory database such as Redis. This creates an additional synchronous or asynchronous connection to the in-memory database, in addition to the connection to the disk-based data source. In case of a cache miss, an additional query to the disk-based data source must be executed. Although an entirely new system is additionally required, the advantage of this method is that the resources can be managed independently of the DSP system, allowing for caching of a larger amount of data. The external cache is also more transparent and modifiable, making it easier to keep it consistent with the disk-based database if necessary.
\end{itemize}
\textbf{Embedded State.} Caching methods maintain a connection to the external data source, leading to a direct dependency. To overcome this, this method involves loading the entire external data into the DSP system as a stream and treating it as another source. The events are then enriched by a join operation. This method requires that outsourcing external data is possible and that the amount of data is within the available resources of the DSP system. Modern systems such as Spark or Flink have an included state backend that can store large amounts of data using RocksDB. However, using a disk-based state in the DSP system can reduce performance. In-memory state is recommended for real-time processing, but requires a large amount of memory.
The embedded state can hence often be regarded as a special case of local caching.

These enrichment methods can be implemented in common DSP systems and serve as a foundation for our evaluation.