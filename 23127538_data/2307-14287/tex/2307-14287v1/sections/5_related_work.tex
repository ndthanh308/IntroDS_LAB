\section{Related Work}
\label{sec:related_work}

This section discusses related works on unifying batch and stream jobs, execution of ML models in and out of DSP systems, joining of stream and disk-based data, and event enrichment in modern DSP systems with disk-based databases. 
Its purpose is to contextualize the contribution of this work in enriching events in a DSP system with data from disk-based databases or generated data from a model.
\\
\textbf{Unified Batch and Stream Applications.} 
Service decoupling and the complexity of modern end-to-end data pipelines lead to an increasing overhead that may negatively impact performance. 
Arcon~\cite{MeldrumSKC0H19} and Neptune~\cite{GarefalakisKP19} address the unification of stream and batch processing to increase performance by providing an optimized common intermediate representation and dynamically prioritizing latency-critical jobs in unified stream and batch applications, respectively. 
While modern DSP systems offer the unified execution of stream and batch jobs, they cannot keep up with the query capabilities and memory sizes of modern databases. 
Enriching events during execution in a DSP system with additional data from a database leads to the merging of fast data streams and slow disk-based databases. 
Frameworks such as Kafka could be used in combination with a DSP system as data storage, but this is only applicable for a small number of use cases, as the query capabilities in Kafka are fairly limited compared to traditional databases. 
Therefore, there are no specific approaches to unifying large-scale data storage and latency-critical streaming applications to achieve more effective resource utilization and improved latency.\\
\textbf{Model Performance Evaluation.} 
The first performance evaluation study of model-serving integration tools in stream processing frameworks has been conducted in~\cite{HorchidanKKC22} by assessing the internal and external execution of a model in DSP systems. 
The integration of ML models assumes that the DSP system requires multiple models, which may exceed its storage capacity.
Additionally, the study considers different model sizes and addresses associated memory concerns. 
The work demonstrates that there are benefits to using integrated execution over external execution DSP frameworks, and that certain model formats offer superior performance.\\
\textbf{Data Warehouse Source Updates.}
Earlier works addressing the combination of high-speed data streams and slow disk-based databases involve active data warehousing. 
In this scenario, a data stream refers to quickly incoming events of source updates, which the data warehouse must process in real-time. 
One of the initial solutions to this issue is the MESHJOIN~\cite{PolyzotisSVSF08} algorithm, which has several variations and extensions~\cite{NaeemDWA10,NaeemDW12}. 
MESHJOIN fuses a high-speed data stream with a disk-based relationship, under the constraint of limited memory, using a hash-join. 
The algorithm scans the entire disk-based relationship sequentially at high speed, and the incoming events from the stream are processed in windows and then combined with the entries from the relationship. 
This approach distributes the expenses of the input-output operations across windows of stream events.\\
\textbf{Disk-based Database Enrichment.}
In~\cite{DerakhshanSS13}, an operator for DSP systems is proposed that enriches incoming stream events using a cache with data from a relational and disk-based database in a single node.
Depending on whether an incoming event causes a cache hit or a cache miss, it is processed in a thread for the respective category. 
Events causing cache misses are combined into batches and then used to query the database. 
Meanwhile, events causing cache hits are processed in parallel. After processing, the two sets of events are merged back into their original order. 
The paper reports higher throughput with this approach compared to a record-at-a-time approach. 
The experiments were conducted using a simulated DSP system and a MySQL database.
In~\cite{JeonLK19}, the authors describe a join between stream and disk-based data using a micro-batch model built on Spark Streaming~\cite{ZahariaDLHSS13} and MongoDB. 
The approach considers distributed execution of operators and assumes that the external disk-based data volume is larger than the storage capacity of the DSP system. 
To minimize database access, a cache is implemented in Spark that stores database entries in their own RDDs. 
If data is unavailable in the cache, a query is generated for multiple cache miss keys to reduce the number of queries. 
The authors also implemented a load-balancing mechanism by dynamically adjusting cache sizes in the DSP system to regulate the database load. 
In~\cite{KimL20c}, the authors extended~\cite{JeonLK19} to support similarity joins.