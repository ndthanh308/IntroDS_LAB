\section{Introduction}
\label{sec:introduction}

Continuous generation of data from web applications and connected devices characterizes modern-day technology and commonly leads to large volumes of data and the need for their processing. 
Usually, data processing results are of immediate interest to subsequent actions, which is why near-to real-time processing is often desirable. 
Many areas such as Internet of Things, operational business intelligence, and fraud detection rely on near-to real-time processing~\cite{IsahAMAZK19,NasiriNG19} of data generated from highly distributed systems. 
However, to obtain a meaningful analysis of data from disparate sources, the respective data traditionally need to be copied into a high-capacity data store for analysis, which can be complex and negatively impact performance. 
Classical batch processing is no longer sufficient for many use cases, hence, the development and thoughtful usage of Distributed Stream Processing (DSP) systems~\cite{KulkarniBFKKMPR15,ZahariaXWDADMRV16,CarboneKEMHT15,ToshniwalTSRPKJGFDBMR14,GulenkoA0BK20}, optimized to process continuous streams of data on a large scale, is important.

DSP systems are optimized to process large streams of continuous data.
Importantly, their ability to offer high throughput processing rates makes them suitable for many use cases.
With these systems, near to real-time processing is mandatory, and the distributed execution of DSP jobs in the cloud allows for the cluster to be dynamically scaled up and down~\cite{KalavriLHDFR18,GeldenhuysSKT22,PfisterLNPGSGT21,GedikSHW14} and hence gracefully adapt to changing workloads~\cite{GontarskaGSWPT21,HuKZ19,KalimCWLWLFQLCW19} or optimized toward desired objectives~\cite{GeldenhuysPSTK22,GeldenhuysTK20,JayasekaraHK20,GeldenhuysTGLK19,FloratouAGRR17}. 
Recent DSP frameworks also offer stateful stream processing, which allows operators to store and access intermediate data within the cluster, making more complex processing of stream events possible, and guaranteeing exactly-once semantics. 
In many cases though, dependencies exist between heterogeneous workloads and the processes which consume them, which may result in latency issues as well as scaling bottlenecks, for instance, if external systems must be accessed during execution, or a performance-heavy workload must be executed within the DSP job of interest.

Related works have addressed the enrichment of events in a DSP system through external databases~\cite{DerakhshanSS13,JeonLK19,KimL20c}, evaluated the performance of running a Machine Learning (ML) model embedded in a DSP system~\cite{HorchidanKKC22}, and also the unification of stream and batch jobs in a single application~\cite{GarefalakisKP19,MeldrumSKC0H19}. 
However, specific use case categories for stream data enrichment are yet to be identified, and specific enrichment methods for these categories need to be presented and evaluated. 

This paper aims to address the issue of streaming data enrichment for DSP systems by providing an evaluation of different enrichment methods and identifying the proper enrichment method for a given use case. 
We primarily focus on latency-critical applications, and select Apache Flink as a representative DSP system for our evaluation due to its wide usage by big corporations on a large scale~\cite{CarboneEFHRT17}.

\textit{Contributions.} The contributions of this paper are:

\begin{itemize}
    \item Problem analysis and investigation of assumptions and common use cases, ultimately leading to the definition of general use case categories.
    \item Detailed empirical evaluation of various data enrichment methods in combination with different representative use cases, providing a better understanding of situation-dependent applicability.
    \item Openly available repository\footnote{\url{https://github.com/dos-group/stream-processing-enrichment-methods}} with all relevant experiment-related artifacts. We provide comprehensive documentation and examples for reproducing our setup.
\end{itemize}

\autoref{sec:problem_analysis} conducts a problem analysis, thereby identifying the assumptions and use cases for performing data enrichment for DSP systems. \autoref{sec:experiment_methodology} presents the data enrichment methods, infrastructure setup, selected use cases, and evaluation metrics. \autoref{sec:experiment_results} presents and discusses our results. \autoref{sec:related_work} describes the related work on data enrichment strategies, while \autoref{sec:conclusion} concludes the paper.
