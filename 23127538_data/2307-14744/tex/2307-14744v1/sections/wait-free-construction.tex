We now discuss a wait-free extension to the presented lock-free algorithm above. Wait-freedom is achieved using fast-path-slow-path method \cite{Timnat+:WFLis:opodis:2012}. More specifically, a wait-free operation starts exactly as the lock-free algorithm. 
%The main idea here is to switch between lock-free and wait-free implementations, heuristically, to achieve lock-free performance with wait-free progress guarantees. 
This is termed as the \textit{fast path}. %This is very similar to the lock-free implementation of the operation, which does not require wait-free helping. 
If a thread cannot complete its operation even after several attempts, it enters the \textit{slow path} by announcing that it would need help.
% and performs the wait-free implementation of the operation. 
 To that effect, we maintain a global \texttt{stateArray} to keep track of the operations that every thread currently needs help with. 
% Before executing the wait-free implementation, it announces that it needs help by updating its \texttt{stateArray} entry, allowing other threads to help it. 
 In the slow path, an operation first publishes a \texttt{State} object containing all the information required to help complete its operation.

For every thread that announces its entry to the slow path, it needs to find helpers. After completing some fixed number of fast path operations, every thread will check if another thread needs some help. This is done by keeping track of the thread to be helped in a thread-local \texttt{HelpRecord} object presented in Figure \ref{fig:WF_DS}. After completing the $nextCheck$ amount of fast path operations, it will assist the $currTid$. Before helping, it checks if $lastPhase$ equals $phase$ in $currTid$'s \texttt{stateArray} entry. If it does, the fast path thread will help execute the wait-free implementation of that operation; otherwise, $currTid$ doesn't require helping as its entry in the \texttt{stateArray} has changed, meaning the operation has already been completed. In the worst case, if the helping thread also faces massive contention, every available thread will eventually execute the same operation, ensuring its success.

% Figure environment removed

Notice that when data and updates are uniformly distributed, the contention among threads is low, often none. Concomitantly, in such cases, a slow path by any thread is minimally taken. 

\textbf{Wait-free \insertADT.} Traversal in Wait-free \insertADT is the same as that in the lock-free \insertADT as mentioned in Section \ref{sec:MainAlgo}. While traversal a thread could fail the \textbf{\texttt{CAS}} operation in a split/merge operation of a node and would need to restart traversal from the root again. At first glance, this would appear to repeat indefinitely, contradicting wait-freedom, but this operation will eventually finish due to helping. If a thread repeatedly fails to traverse Uruv due to such failure, every other thread will eventually help it find the leaf node. Once we reach the leaf node, we add the key to the versioned linked list as described below. There are two cases - either a node containing the key already exists, or a node does not exist. 

In the former case, we need to update the linked list node’s \textit{vhead} with the versioned node, \textit{vnode}, containing the new value using \texttt{CAS}.
The significant difference between both methods is the usage of a shared \texttt{Vnode} from the \texttt{stateArray} in wait-free versus a thread local \texttt{Vnode} in lock-free. Every thread helping this insert will take this \textit{vnode} from the \texttt{stateArray} and first checks the variable finished if the operation has already finished. They then check if the phase is the same in the \texttt{stateArray}, and \textit{vnode}’s timestamp is set or not. If either is not true, some other thread has already completed the operation, and they mark the operation as finished. Else, they will try to update the \textit{vhead} with \textit{vnode} atomically. After inserting the \textit{vnode}, it initialises the timestamp and sets the finished to be true.

In the latter case, we create a linked list node, \textit{newNode},  and set its \textit{vhead} to the \textit{vnode} in the \texttt{stateArray} entry. It tries adding \textit{newNode} like the lock-free linked list’s insert. If it is  successful, the timestamp of \textit{vnode} is initialized, and the finished is set to true in the \texttt{stateArray}. We have discussed some race conditions in Appendix \ref{race} due to limited space in this section.
\ignore{
We now discuss a few \textit{race conditions}. The first race condition can arise when two threads try to modify the \textit{vhead}, knowing that \textit{vnode}’s timestamp is not set. Let us say thread $t_1$ has read the current \textit{vhead} at line \ref{alg25:line298}, and finds out the current timestamp of the \textit{vnode} is not set. Similarly, thread $t_2$ reads the same information as $t_1$ and is now performing the \texttt{wfVCAS} operation at line \ref{alg25:line304}. If thread $t_2$ succeeds in changing the \textit{vhead} at line \ref{alg26:line321}, $t_1$ will fail as the current \textit{vhead} has changed. So only one thread can replace the \textit{vhead} with \textit{vnode}.

Let us discuss another race condition. A thread $t_1$ finds that the key to be inserted does not exist. It creates a new linked list node and will add it to the linked list with its \textit{vhead} pointing to the \textit{vnode} at line \ref{alg25:line314}. Now, $t_1$ stalls, and another thread $t_2$ finds that the key exists, and it tries to update the node’s \textit{vhead} with the \textit{vnode}. So, when thread $t_2$ reads the current \textit{vhead} of the node at line \ref{alg25:line303}, after initializing its \textit{vnode} at line \ref{alg25:init}, thread $t_2$ will not proceed further with the operation. In the end, only one thread will be able to replace the \textit{vhead} with \textit{vnode}.

Let us consider a final race condition wherein a thread tries to set the shared \texttt{stateArray} \textit{vnode}’s \textit{nextv} in the \texttt{wfVCAS} method. Let some thread $t_1$ stall just before executing line \ref{alg26:line320}, where it was about to set \textit{vnode}’s \textit{nextv} to the \textit{vhead} it read at line \ref{alg25:line297}. Let the $vhead$ it read be some \texttt{Vnode} $v_1$. While $t_1$ stalls, two things happen in parallel. First, the \textit{vhead} gets updated to another \texttt{Vnode}, $v_2$. Second, a thread, $t_2$, changes \textit{vnode}’s \textit{nextv} to $v_2$ at line \ref{alg26:line320} and successfully updates the \textit{vhead} at line \ref{alg26:line321}. Now thread $t_1$ wakes up and changes \textit{nextv} to $v_1$ at \ref{alg26:line320}, resulting in $v_2$ not being part of the versioned list. To avoid this race condition, we atomically update the \textit{nextv} of the $vnode$ at line \ref{alg26:line320} and check if it has already been changed by some other thread or not. If it has, then we restart the operation.
}

\textbf{Wait-free \remove.} \remove \op follows the same approach as \insertADT. If the key is not present in the leaf node, it returns \textup{"Key Not Present"} and sets the finished to be true. Otherwise, it will add the \textit{vnode} from \texttt{stateArray} similar to wait-free \insertADT. The only difference is that the \textit{vnode} contains the tombstone value for a deleted node. Details on this method are deferred to Appendix \ref{sec:wait-free-appendix}.

\ignore{
Like insertion, we find the leaf node possibly containing the key to be deleted. Once the leaf node is found, it searches for the node to be deleted and updates the \texttt{stateArray} atomically at line \ref{alg10:line142}. If the node does not exist, there is nothing to delete, and the operation is completed. Otherwise, the \textit{vnode} in the \texttt{stateArray} replaces the \textit{vhead} of the linked list node via the method, \texttt{wfLLInsert} at line \ref{alg10:line151}, described above. Deleting from Uruv has the advantage of having no physical deletion of a node. Nodes that are not required will only be physically removed while doing a split or merge operation. For more algorithmic details please refer to Algorithm \ref{wfdeletefromleaf} in the appendix.

}
%is found, \texttt{wfDeleteFromLeaf} is called, wherein the actual deletion in the linked-list occurs. First, we search the node to be deleted at line \ref{alg11:find} and update the \texttt{stateArray} atomically at line \ref{alg10:line142}. If the node does not exist, there is nothing to delete, and the operation is completed. Otherwise, the \textit{vnode} in the \texttt{stateArray} replaces the \textit{vhead} of the linked-list node via the method, \texttt{wfLLInsert} at line \ref{alg10:line151}, described above. Deleting from Uruv has the advantage of having no physical deletion of a node. Nodes that are not required will only be physically removed while doing a split or merge operation. For more algorithmic details please refer to Algorithm \ref{wfdeletefromleaf} in the appendix.

\textbf{\search and \rangeQuery.} Neither operation modifies Uruv nor helps any other operation; hence their working remain as explained in Section \ref{sec:MainAlgo}.

