We sincerely thank the reviewers for taking the time to review our submission. In the following, we address their questions and concerns.

Response to Reviewer 1:

a) Presentation-wise, the paper is not self contained. ... pseudo-code and its description to Appendix.

Response: We appreciate this suggestion. We are hopeful that the reviewer would agree with our observation that writing the description of an “advanced” non-blocking data structure in a conference paper has been getting trickier over the last few years with the growing complexity of such works. These data structure algorithms invariably consist of many non-trivial details. Some readers/reviewers prefer a high-level overview first and yet others say that details were missing. As an author, it becomes hard to opt for a style. We will try our best to restructure the paper in the final version.

b) Related to the above, the trickiest part of any concurrent balanced tree algorithm is rebalancing. This paper does not provide enough details to convince me that it “solves” this problem correctly. 

Response: A node is balanced by freezing the current node and its parent when rebalance needs to be triggered. Then a new node, or, two new nodes, are created to replace the current node, depending on the case for a merge or a split. While a node is frozen, helping is performed by threads that access it. These are described in the paragraphs “Freezing/Marking”, “Balancing a Leaf”, “Split”, and “Merge” in Section 3. The relevant lines of the algorithm are described therein.


c) In particular, based on the code in Algorithm 1 (that is included in the paper) it is unclear what happens if a thread reads keys in a node while that node is being concurrently replaced through merged/split. 

Response: The read operations have an oblivious traversal. They pass through a frozen node and have a linearization point before that of the update operation which either triggered helping or got into helping for rebalancing as described above. 

d) Couldn’t that Insert end up in a “wrong” leaf?  

Response: Update operations (insert/delete) perform “proactive traversal” as described in paragraphs “Insert into Uruv” and “Deleting from Uruv” and the relevant lines referred to therein. It essentially means that an insert operation helps a frozen internal node as well.

e) Also, given that read operations (find and range query) do not engage in rebalancing, it seems like logarithmic complexity of those operations might be compromised (as the tree might be completely out of balance due to numerous updates).

Response: As described, the proactive traversal by updates ensures that the tree is not too off-balance. The complexity incorporates the interval contention $I_C$ as described in Section 5.4.

f) Design-wise, the paper should discuss the memory management issue. ... need to be addressed carefully. 

Response: We physically delink the deleted nodes when they are “out of requirement” by range queries going by the version numbers while performing split or merge operations. We believe it is fairly standard to outsource the memory reclamation task to existing memory management methods.

g) Performance-wise, there are two separate issues. First, the paper should explain better the achieved results. What is the LFB+ tree (citation?) and why is it 95x slower in read-only workload? Intuitively, there is absolutely no reason for a lock-free B+-tree to be slower than Uruv when no range queries are concerned, certainly not by almost two orders of magnitude. 

Response: LFB+ Tree (cited as [4], unfortunately, we missed it in Section 6; however, we have mentioned that in point (e) in the last paragraph of Section 1 and elsewhere as well) is indeed an “interesting” implementation, which we too wondered why it performs so poorly when we saw that for the first time. To begin with, we have taken the author’s implementation. We could not find any work that evaluated this implementation after it was published. In their paper, they compared it against their own lock-based implementation. More technically, it uses the contiguous memory chunks to store a linked list in a manner that its nodes will be stored in some (not necessarily exactly contiguous location) cell of an array. This is the way they implement both internal and leaf nodes. At every level, they do a linear search in such linked lists. Thus they roughly pay $O(B log_B n)$ for a search instead of $O(log_2 B log_B n)$, which Uruv and other standard B-trees do by doing a binary search at every level (Uruv does linear at leaf levels). This arrangement at the leaf node not only does not help in any manner whatsoever but also makes it too costly to allocate new nodes. We were indeed surprised to see a performance of loss of two orders of magnitude by this. We decided not to include this analysis in the submission, however, it is reasonable that a reader will be intrigued by these numbers. We are now planning to drop this data structure in the final version instead of including it.

h) A similar question applies to the comparison with VCAS-BST -- why is Uruv better, especially when the workload has more reads (see Figure 6)? Wait-freedom alone cannot explain this difference since the tree is huge and the operations should hardly get any help to complete (though including some stats about restarts would be helpful).

Response: Uruv being a B+-tree has smaller height compared to unbalanced BST. The suggestion about stats is a good suggestion -- we will try including it in the final version.

g) Second, there are several baselines... they should be included in the evaluation.

Response: We have the comparative numbers of [5] and [7]. Uruv does better than C-IST [7] in many settings, however, AB-tree [5] always outperforms Uruv. We essentially compared Uruv against “only B+-trees”. Nevertheless, we shall include those numbers too in the final version. Nelson et. al. [18] is lock-based and therefore we did not include that in the comparison. That work will be better compared to VCASBST. Thank you for pointing to Bz-tree; we compared against Bw-tree [21] and now know that Bz-tree outperforms it in several settings. We will include that too in the final version. 



We thank the reviewer for each of the minor comments, which we will definitely address along with a more thorough proofread.

Response to Reviewer 2:

a) The novel aspects of the design and the analysis could be better highlighted since this would clarify the significance of your contribution. It appears that most of the construction uses prior results from references [11,22] in the lock-free design, and then from [20] to achieve a wait-free version.

Response: We have several non-trivial constructions, beyond drawing from the existing ones mentioned by the reviewer. For example, wfVCAS required maintaining the version updates in the state-array indices corresponding to the operations, starting from the very allocation of a node, which the existing vCAS did not have to face, nor the wait-free non-versioned data structures. Similarly, the proactive traversal by concurrent updates is highly effective for our purpose which we believe was not explored by the related work. We thankfully accept this remark, we will highlight this in the final version.  

b) The arguments for correctness seems somewhat informal. It might benefit the presentation to have a lemma/theorem format, along with proofs, even if those need to be pushed to an appendix or online version. I found the absence of technical arguments a little strange.

Response: We accept that the correctness arguments are in form of “proof sketches”. However, they are not too away from the standard; for example, see C-IST [7]. We plan to write the correctness arguments in a formal way in an extended/journal version of this paper.

c) Sometimes this isn’t... that much worse.

Response: We have addressed this in Response to Reviewer 1. The error bars are not significant. Number of trials as 7 is fairly standard in the literature.

Response to Reviewer 3:

a) In particular, the paper sells Uruv ... “trick” or “insight” that Uruv makes use of in its design.

Response: We thank the reviewer for this remark. We will restructure the paper in the final version to highlight our contribution.

b) Furthermore, the algorithm ... As such, I found it difficult to verify correctness.

Response: We have a high-level description in form of Figure 3. Furthermore, in section 3 and 4 we give a high-level description of lock-free/wait-free insert/delete before actually delving into those. Beyond this it was difficult to include another section/subsection on “High-level Description” under the space budget. We however acknowledge your remark and will restructure to bring the short descriptions of insert/delete operations from Sections 3 and 4 to a dedicated section for quick reference to a reader.

c) In the early description of the protocol in section 3, ... the total number of nodes (i.e. deletions don’t shrink the tree)?

Response: We have addressed a similar concern in point (f) of Reviewer 1 above.

d) While the experimental results are impressive, they are not explained at all. What about Uruv’s design.... What happens in long runs when the lack of garbage collection starts being problematic?

Response: We have already explained above in point (g) to Reviewer 1 the issues with LFB+ tree [4]. Uruv actually uses a wait-free variant of vCAS as explained above. Your observation is correct to an extent that the range-queries become “comparatively” slower with an increase in their percentage in Uruv. This is expected because with (reasonably high) updates many leaf nodes could be under split. Range search in Uruv “links” those nodes at leaf level wherever encountered. In vCASBST, they do not face this issue. However, in absolute numbers, Uruv still does better. For sure, if there are only range searches without updates, Uruv will outperform BST because of its smaller height. Essentially, we may expect some spots on the horizon of workloads, where vCASBST will outperform Uruv, however, that will be too occasional.


e) Figure 6d is not described properly; the distribution of operations does not add up to $100\%.$

Response: This was a typo mistake. Thanks for pointing it out.

f) Other comments and suggestions.

Response: Thank you very much for your remarks on the proofread. We will thoroughly work on that in the final version.