\begin{thebibliography}{10}
\providecommand{\url}[1]{#1}
\csname url@rmstyle\endcsname
\providecommand{\newblock}{\relax}
\providecommand{\bibinfo}[2]{#2}
\providecommand\BIBentrySTDinterwordspacing{\spaceskip=0pt\relax}
\providecommand\BIBentryALTinterwordstretchfactor{4}
\providecommand\BIBentryALTinterwordspacing{\spaceskip=\fontdimen2\font plus
\BIBentryALTinterwordstretchfactor\fontdimen3\font minus
  \fontdimen4\font\relax}
\providecommand\BIBforeignlanguage[2]{{%
\expandafter\ifx\csname l@#1\endcsname\relax
\typeout{** WARNING: IEEEtran.bst: No hyphenation pattern has been}%
\typeout{** loaded for the language `#1'. Using the pattern for}%
\typeout{** the default language instead.}%
\else
\language=\csname l@#1\endcsname
\fi
#2}}

\bibitem{niklaus2017video}
S.~Niklaus, L.~Mai, and F.~Liu, ``Video frame interpolation via adaptive
  convolution,'' in \emph{Proceedings of the IEEE Conference on Computer Vision
  and Pattern Recognition}, 2017, pp. 670--679.

\bibitem{niklaus2018context}
S.~Niklaus and F.~Liu, ``Context-aware synthesis for video frame
  interpolation,'' in \emph{Proceedings of the IEEE conference on computer
  vision and pattern recognition}, 2018, pp. 1701--1710.

\bibitem{lin2020learning}
S.~Lin, J.~Zhang, J.~Pan, Z.~Jiang, D.~Zou, Y.~Wang, J.~Chen, and J.~Ren,
  ``Learning event-driven video deblurring and interpolation,'' in
  \emph{European Conference on Computer Vision}.\hskip 1em plus 0.5em minus
  0.4em\relax Springer, 2020, pp. 695--710.

\bibitem{han2021evintsr}
J.~Han, Y.~Yang, C.~Zhou, C.~Xu, and B.~Shi, ``Evintsr-net: Event guided
  multiple latent frames reconstruction and super-resolution,'' in
  \emph{Proceedings of the IEEE/CVF International Conference on Computer
  Vision}, 2021, pp. 4882--4891.

\bibitem{yu2021training}
Z.~Yu, Y.~Zhang, D.~Liu, D.~Zou, X.~Chen, Y.~Liu, and J.~S. Ren, ``Training
  weakly supervised video frame interpolation with events,'' in
  \emph{Proceedings of the IEEE/CVF International Conference on Computer
  Vision}, 2021, pp. 14\,589--14\,598.

\bibitem{tulyakov2021time}
S.~Tulyakov, D.~Gehrig, S.~Georgoulis, J.~Erbach, M.~Gehrig, Y.~Li, and
  D.~Scaramuzza, ``Time lens: Event-based video frame interpolation,'' in
  \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern
  Recognition}, 2021, pp. 16\,155--16\,164.

\bibitem{gallego2020event}
G.~Gallego, T.~Delbr{\"u}ck, G.~Orchard, C.~Bartolozzi, B.~Taba, A.~Censi,
  S.~Leutenegger, A.~J. Davison, J.~Conradt, K.~Daniilidis, \emph{et~al.},
  ``Event-based vision: A survey,'' \emph{IEEE transactions on pattern analysis
  and machine intelligence}, vol.~44, no.~1, pp. 154--180, 2020.

\bibitem{lichtsteiner2008128}
P.~Lichtsteiner, C.~Posch, and T.~Delbruck, ``A 128 $\times$128 120 db 15$\mu$s
  latency asynchronous temporal contrast vision sensor,'' \emph{IEEE journal of
  solid-state circuits}, vol.~43, no.~2, pp. 566--576, 2008.

\bibitem{feichtenhofer2019slowfast}
C.~Feichtenhofer, H.~Fan, J.~Malik, and K.~He, ``Slowfast networks for video
  recognition,'' in \emph{Proceedings of the IEEE/CVF international conference
  on computer vision}, 2019, pp. 6202--6211.

\bibitem{jaderberg2015spatial}
M.~Jaderberg, K.~Simonyan, A.~Zisserman, \emph{et~al.}, ``Spatial transformer
  networks,'' \emph{Advances in neural information processing systems},
  vol.~28, 2015.

\bibitem{jiang2018super}
H.~Jiang, D.~Sun, V.~Jampani, M.-H. Yang, E.~Learned-Miller, and J.~Kautz,
  ``Super slomo: High quality estimation of multiple intermediate frames for
  video interpolation,'' in \emph{Proceedings of the IEEE conference on
  computer vision and pattern recognition}, 2018, pp. 9000--9008.

\bibitem{li2020video}
H.~Li, Y.~Yuan, and Q.~Wang, ``Video frame interpolation via residue
  refinement,'' in \emph{ICASSP 2020-2020 IEEE International Conference on
  Acoustics, Speech and Signal Processing (ICASSP)}.\hskip 1em plus 0.5em minus
  0.4em\relax IEEE, 2020, pp. 2613--2617.

\bibitem{xu2019quadratic}
X.~Xu, L.~Siyao, W.~Sun, Q.~Yin, and M.-H. Yang, ``Quadratic video
  interpolation,'' \emph{Advances in Neural Information Processing Systems},
  vol.~32, 2019.

\bibitem{chi2020all}
Z.~Chi, R.~Mohammadi~Nasiri, Z.~Liu, J.~Lu, J.~Tang, and K.~N. Plataniotis,
  ``All at once: Temporally adaptive multi-frame interpolation with advanced
  motion modeling,'' in \emph{European Conference on Computer Vision}.\hskip
  1em plus 0.5em minus 0.4em\relax Springer, 2020, pp. 107--123.

\bibitem{niklaus2020softmax}
S.~Niklaus and F.~Liu, ``Softmax splatting for video frame interpolation,'' in
  \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern
  Recognition}, 2020, pp. 5437--5446.

\bibitem{park2020bmbc}
J.~Park, K.~Ko, C.~Lee, and C.-S. Kim, ``Bmbc: Bilateral motion estimation with
  bilateral cost volume for video interpolation,'' in \emph{European Conference
  on Computer Vision}.\hskip 1em plus 0.5em minus 0.4em\relax Springer, 2020,
  pp. 109--125.

\bibitem{park2021asymmetric}
J.~Park, C.~Lee, and C.-S. Kim, ``Asymmetric bilateral motion estimation for
  video frame interpolation,'' in \emph{Proceedings of the IEEE/CVF
  International Conference on Computer Vision}, 2021, pp. 14\,539--14\,548.

\bibitem{lu2022video}
L.~Lu, R.~Wu, H.~Lin, J.~Lu, and J.~Jia, ``Video frame interpolation with
  transformer,'' in \emph{Proceedings of the IEEE/CVF Conference on Computer
  Vision and Pattern Recognition}, 2022, pp. 3532--3542.

\bibitem{huang2022real}
Z.~Huang, T.~Zhang, W.~Heng, B.~Shi, and S.~Zhou, ``Real-time intermediate flow
  estimation for video frame interpolation,'' in \emph{European Conference on
  Computer Vision}.\hskip 1em plus 0.5em minus 0.4em\relax Springer, 2022, pp.
  624--642.

\bibitem{kalluri2020flavr}
T.~Kalluri, D.~Pathak, M.~Chandraker, and D.~Tran, ``Flavr: Flow-agnostic video
  representations for fast frame interpolation,'' \emph{arXiv preprint
  arXiv:2012.08512}, 2020.

\bibitem{bao2019depth}
W.~Bao, W.-S. Lai, C.~Ma, X.~Zhang, Z.~Gao, and M.-H. Yang, ``Depth-aware video
  frame interpolation,'' in \emph{Proceedings of the IEEE/CVF Conference on
  Computer Vision and Pattern Recognition}, 2019, pp. 3703--3712.

\bibitem{paredes2021back}
F.~Paredes-Vall{\'e}s and G.~C. de~Croon, ``Back to event basics:
  Self-supervised learning of image reconstruction for event cameras via
  photometric constancy,'' in \emph{Proceedings of the IEEE/CVF Conference on
  Computer Vision and Pattern Recognition}, 2021, pp. 3446--3455.

\bibitem{rebecq2019events}
H.~Rebecq, R.~Ranftl, V.~Koltun, and D.~Scaramuzza, ``Events-to-video: Bringing
  modern computer vision to event cameras,'' in \emph{Proceedings of the
  IEEE/CVF Conference on Computer Vision and Pattern Recognition}, 2019, pp.
  3857--3866.

\bibitem{wang2020event}
B.~Wang, J.~He, L.~Yu, G.-S. Xia, and W.~Yang, ``Event enhanced high-quality
  image recovery,'' in \emph{European Conference on Computer Vision}.\hskip 1em
  plus 0.5em minus 0.4em\relax Springer, 2020, pp. 155--171.

\bibitem{pan2019bringing}
L.~Pan, C.~Scheerlinck, X.~Yu, R.~Hartley, M.~Liu, and Y.~Dai, ``Bringing a
  blurry frame alive at high frame-rate with an event camera,'' in
  \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern
  Recognition}, 2019, pp. 6820--6829.

\bibitem{zhang2022unifying}
X.~Zhang and L.~Yu, ``Unifying motion deblurring and frame interpolation with
  events,'' in \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, 2022, pp. 17\,765--17\,774.

\bibitem{tulyakov2022time}
S.~Tulyakov, A.~Bochicchio, D.~Gehrig, S.~Georgoulis, Y.~Li, and D.~Scaramuzza,
  ``Time lens++: Event-based frame interpolation with parametric non-linear
  flow and multi-scale fusion,'' in \emph{Proceedings of the IEEE/CVF
  Conference on Computer Vision and Pattern Recognition}, 2022, pp.
  17\,755--17\,764.

\bibitem{wu2022video}
S.~Wu, K.~You, W.~He, C.~Yang, Y.~Tian, Y.~Wang, Z.~Zhang, and J.~Liao, ``Video
  interpolation by event-driven anisotropic adjustment of optical flow,''
  \emph{arXiv preprint arXiv:2208.09127}, 2022.

\bibitem{he2022timereplayer}
W.~He, K.~You, Z.~Qiao, X.~Jia, Z.~Zhang, W.~Wang, H.~Lu, Y.~Wang, and J.~Liao,
  ``Timereplayer: Unlocking the potential of event cameras for video
  interpolation,'' in \emph{Proceedings of the IEEE/CVF Conference on Computer
  Vision and Pattern Recognition}, 2022, pp. 17\,804--17\,813.

\bibitem{zhu2019unsupervised}
A.~Z. Zhu, L.~Yuan, K.~Chaney, and K.~Daniilidis, ``Unsupervised event-based
  learning of optical flow, depth, and egomotion,'' in \emph{Proceedings of the
  IEEE/CVF Conference on Computer Vision and Pattern Recognition}, 2019, pp.
  989--997.

\bibitem{zhang2018unreasonable}
R.~Zhang, P.~Isola, A.~A. Efros, E.~Shechtman, and O.~Wang, ``The unreasonable
  effectiveness of deep features as a perceptual metric,'' in \emph{Proceedings
  of the IEEE conference on computer vision and pattern recognition}, 2018, pp.
  586--595.

\bibitem{xu2022gmflow}
H.~Xu, J.~Zhang, J.~Cai, H.~Rezatofighi, and D.~Tao, ``Gmflow: Learning optical
  flow via global matching,'' in \emph{Proceedings of the IEEE/CVF conference
  on computer vision and pattern recognition}, 2022, pp. 8121--8130.

\bibitem{baker2011database}
S.~Baker, D.~Scharstein, J.~Lewis, S.~Roth, M.~J. Black, and R.~Szeliski, ``A
  database and evaluation methodology for optical flow,'' \emph{International
  journal of computer vision}, vol.~92, no.~1, pp. 1--31, 2011.

\bibitem{xue2019video}
T.~Xue, B.~Chen, J.~Wu, D.~Wei, and W.~T. Freeman, ``Video enhancement with
  task-oriented flow,'' \emph{International Journal of Computer Vision}, vol.
  127, no.~8, pp. 1106--1125, 2019.

\bibitem{rebecq2018esim}
H.~Rebecq, D.~Gehrig, and D.~Scaramuzza, ``Esim: an open event camera
  simulator,'' in \emph{Conference on Robot Learning}.\hskip 1em plus 0.5em
  minus 0.4em\relax PMLR, 2018, pp. 969--982.

\bibitem{gehrig2020video}
D.~Gehrig, M.~Gehrig, J.~Hidalgo-Carri{\'o}, and D.~Scaramuzza, ``Video to
  events: Recycling video datasets for event cameras,'' in \emph{Proceedings of
  the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, 2020,
  pp. 3586--3595.

\bibitem{stoffregen2020reducing}
T.~Stoffregen, C.~Scheerlinck, D.~Scaramuzza, T.~Drummond, N.~Barnes,
  L.~Kleeman, and R.~Mahony, ``Reducing the sim-to-real gap for event
  cameras,'' in \emph{European Conference on Computer Vision}.\hskip 1em plus
  0.5em minus 0.4em\relax Springer, 2020, pp. 534--549.

\end{thebibliography}
