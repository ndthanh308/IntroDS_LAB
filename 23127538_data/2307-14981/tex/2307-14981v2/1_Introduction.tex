%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}

Autonomous driving (AD) %with deep learning networks 
has shown promising achievements and is considered an important technological breakthrough that could revolutionize the future of transportation. Currently, ensuring the safety of autonomous driving systems has become a topic of extensive development.
% There has been much discussion on how to verify the safety of autonomous driving systems.
One traditional solution for safety tests is to exhaustively enumerate real scenarios for validation. Nevertheless, this process is not only labor-intensive and costly but also dangerous. Simulation has emerged as a robust, safe, and efficient alternative for training and evaluating AD software and algorithms~\cite{li2019aads, amini2020learning, amini2022vista}.

% Figure environment removed

Recently, neural radiance field (NeRF)~\cite{mildenhall2020nerf} has gained significant attention in AD simulation~\cite{drivesim}. This approach leverages multi-view images to construct a 3D scene and enable novel view synthesis for both indoor and outdoor applications. When it comes to constructing NeRF models in AD simulation, there are two options available: 1) collecting a large amount of data to cover as many viewpoints as possible, and constructing a fine-grained scene offline; 2) directly using log data from road tests to quickly create an environment and dynamically simulate driving scenarios. The first choice can deliver high-quality simulation~\cite{tancik2022block} by transforming the problem of view extrapolation into view interpolation through the use of large amounts of data. However, it is time- and cost-intensive, which makes it challenging to generalize. As for the second choice, the collected images from log data are usually similar to each other along the running trajectory, which may result in unsatisfactory outcomes, particularly when the camera pose is placed out-of-trajectory (see \figref{figSupportComp} as an example), semantic consistency cannot be guaranteed when synthesizing images from deviated views. We observe this problem under this data condition in all neural radiance approaches, and to the best of our knowledge, none of the existing work has solved this issue.
In our opinion, semantic consistency is crucial for AD simulation, and synthesizing on deviated views is unavoidable for scalability.

AD simulation usually involves map data for planning and control, which can be obtained from a prebuilt High-Definition Map (HD Map) or an online mapping module. While the map data may not be pixel-perfect, it can provide semantic-level information that is useful for enhancing the semantic consistency of the trained neural radiance field.
In this paper, we propose incorporating map priors into neural radiance fields to enhance the semantic consistency and rendering quality of deviated driving view synthesis. Firstly, we employ ground information from maps to supervise the density field of NeRF, providing a more reliable road base for semantic entities. Next, we propose sampling rays to simulate unseen views. Unlike most NeRF augmentation methods~\cite{zhang2022ray, chen2022geoaug}, we utilize ground and lane information in sampling computations to guide the radiance field. More importantly, we model the above two supervision methods as weak supervision by using an uncertainty parameter and propose an uncertainty tempering scheme to increase the uncertainty. This ensures that map priors only guide the training process rather than enforce it towards their absolute values. As a result, our proposed method not only improves the rendering quality of interpolated novel view synthesis quantitatively but also enhances the semantic consistency of deviated novel view synthesis. 
Our contributions can be summarized as follows:
% We summarize the contributions of this paper as follows.



% To overcome the limitations of the collected data, this paper proposes a novel approach that leverages map information to enhance the semantic consistency of the synthesized driving views. 

% Autonomous driving (AD) vehicles are being trained with the help of deep learning networks and have shown promising achievements. This technology is considered to be a breakthrough that could change the way of transportation in the near future. However, there are many discussions on how to verify or judge the safety of autonomous driving systems.
% A straightforward solution towards the safety tests is to exhaustively enumerate real scenarios for validation as many as possible. However, the process of implementing different real scenarios is not only labor-intensive and costly, but also dangerous. Simulation has been proved to be an alternative, which is robust, safe, efficient in training, and evaluating AD software and algorithms.
% Now, the emerging technology of neural radiance field (NeRF)~\cite{} leverages multi-view images to construct a 3D scene and enable novel view synthesis for many indoor and outdoor applications. For AD simulation, there are two choices for constructing NeRF models: 1) collect a large amount of data, such as LiDAR and camera data, similar to mapping, to construct a fine-grained scene offline; or 2) directly use the log file (typically in the format of ROS bag) to rapidly create an environment and then dynamically simulate the driving scenarios.
% The first choice can achieve high-quality simulation, but it is time-consuming and expensive, making it difficult to generalize to very large scales. On the other hand, the second option is fast but can lead to low-quality simulation due to the data being sparse and similar to each other in log data. This paper tackles the problem raised by choosing the latter option and attempts to improve the quality of out-of-trajectory driving view synthesis by incorporating map information. This approach is practical for many autonomous driving tests.
% In conclusion, the use of NeRF technology for AD simulation is a promising avenue for training and evaluating AD software and algorithms. While both options for constructing NeRF models have their pros and cons, this paper addresses the challenges of the second option and proposes a potential solution to improve the quality of simulation.

%There exist a few attempts to facilitate training a NeRF model for synthesizing out-of-trajectory (or called as extrapo trajectory) views.


\begin{itemize}
    \item We propose a novel method to incorporate commonly used map priors in AD scenes into neural radiance fields to improve the out-of-trajectory driving view synthesis.
    \item We explicitly model the uncertainty in map priors as a parameter and propose an uncertainty tempering scheme to guide the training process of the neural radiance field.
    \item Experiments demonstrated that the proposed method can improve the semantic consistency of out-of-trajectory views and the rendering quality of novel view trajectory interpolation.
\end{itemize}

Our proposed method is easy to implement, can be easily plugged into existing NeRF algorithms, and has the capability of extending to other formats of priors.