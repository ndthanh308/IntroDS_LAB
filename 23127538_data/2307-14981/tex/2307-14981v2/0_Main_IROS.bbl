% Generated by IEEEtran.bst, version: 1.14 (2015/08/26)
\begin{thebibliography}{10}
\providecommand{\url}[1]{#1}
\csname url@samestyle\endcsname
\providecommand{\newblock}{\relax}
\providecommand{\bibinfo}[2]{#2}
\providecommand{\BIBentrySTDinterwordspacing}{\spaceskip=0pt\relax}
\providecommand{\BIBentryALTinterwordstretchfactor}{4}
\providecommand{\BIBentryALTinterwordspacing}{\spaceskip=\fontdimen2\font plus
\BIBentryALTinterwordstretchfactor\fontdimen3\font minus
  \fontdimen4\font\relax}
\providecommand{\BIBforeignlanguage}[2]{{%
\expandafter\ifx\csname l@#1\endcsname\relax
\typeout{** WARNING: IEEEtran.bst: No hyphenation pattern has been}%
\typeout{** loaded for the language `#1'. Using the pattern for}%
\typeout{** the default language instead.}%
\else
\language=\csname l@#1\endcsname
\fi
#2}}
\providecommand{\BIBdecl}{\relax}
\BIBdecl

\bibitem{li2019aads}
W.~Li, C.~Pan, R.~Zhang, J.~Ren, Y.~Ma, J.~Fang, F.~Yan, Q.~Geng, X.~Huang,
  H.~Gong \emph{et~al.}, ``Aads: Augmented autonomous driving simulation using
  data-driven algorithms,'' \emph{Science robotics}, 2019.

\bibitem{amini2020learning}
A.~Amini, I.~Gilitschenski, J.~Phillips, J.~Moseyko, R.~Banerjee, S.~Karaman,
  and D.~Rus, ``Learning robust control policies for end-to-end autonomous
  driving from data-driven simulation,'' \emph{IEEE Robot. Automat. Lett.
  (RA-L)}, 2020.

\bibitem{amini2022vista}
A.~Amini, T.-H. Wang, I.~Gilitschenski, W.~Schwarting, Z.~Liu, S.~Han,
  S.~Karaman, and D.~Rus, ``Vista 2.0: An open, data-driven simulator for
  multimodal sensing and policy learning for autonomous vehicles,'' in
  \emph{Proc. IEEE Int. Conf. Robot. Automat. (ICRA)}, 2022.

\bibitem{mildenhall2020nerf}
B.~Mildenhall, P.~P. Srinivasan, M.~Tancik, J.~T. Barron, R.~Ramamoorthi, and
  R.~Ng, ``Nerf: Representing scenes as neural radiance fields for view
  synthesis,'' in \emph{Proc. Eur. Conf. Comput. Vis. (ECCV)}, 2020.

\bibitem{drivesim}
``{NVIDIA DRIVE Sim},'' \url{https://developer.nvidia.com/drive/simulation}.

\bibitem{tancik2022block}
M.~Tancik, V.~Casser, X.~Yan, S.~Pradhan, B.~Mildenhall, P.~P. Srinivasan,
  J.~T. Barron, and H.~Kretzschmar, ``Block-nerf: Scalable large scene neural
  view synthesis,'' in \emph{Proc. IEEE Conf. Comput. Vis. Pattern Recognit.
  (CVPR)}, 2022.

\bibitem{zhang2022ray}
J.~Zhang, Y.~Zhang, H.~Fu, X.~Zhou, B.~Cai, J.~Huang, R.~Jia, B.~Zhao, and
  X.~Tang, ``Ray priors through reprojection: Improving neural radiance fields
  for novel view extrapolation,'' in \emph{Proc. IEEE Conf. Comput. Vis.
  Pattern Recognit. (CVPR)}, 2022.

\bibitem{chen2022geoaug}
D.~Chen, Y.~Liu, L.~Huang, B.~Wang, and P.~Pan, ``Geoaug: Data augmentation for
  few-shot nerf with geometry constraints,'' in \emph{Proc. Eur. Conf. Comput.
  Vis. (ECCV)}, 2022.

\bibitem{coumans2016pybullet}
E.~Coumans and Y.~Bai, ``Pybullet, a python module for physics simulation for
  games, robotics and machine learning,'' 2016.

\bibitem{todorov2012mujoco}
E.~Todorov, T.~Erez, and Y.~Tassa, ``Mujoco: A physics engine for model-based
  control,'' in \emph{Proc.~of the IEEE/RSJ Intl.~Conf.~on Intelligent Robots
  and Systems (IROS)}, 2012.

\bibitem{dosovitskiy2017carla}
A.~Dosovitskiy, G.~Ros, F.~Codevilla, A.~Lopez, and V.~Koltun, ``Carla: An open
  urban driving simulator,'' in \emph{Proc.~of the Conf.~on Robot Learning
  (CoRL)}, 2017.

\bibitem{yang2023unisim}
Z.~Yang, Y.~Chen, J.~Wang, S.~Manivasagam, W.-C. Ma, A.~J. Yang, and
  R.~Urtasun, ``Unisim: A neural closed-loop sensor simulator,'' in \emph{Proc.
  IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR)}, 2023, pp. 1389--1399.

\bibitem{tewari2020state}
A.~Tewari, O.~Fried, J.~Thies, V.~Sitzmann, S.~Lombardi, K.~Sunkavalli,
  R.~Martin-Brualla, T.~Simon, J.~Saragih, M.~Nie{\ss}ner \emph{et~al.},
  ``State of the art on neural rendering,'' in \emph{Computer Graphics Forum},
  2020.

\bibitem{tewari2021advances}
A.~Tewari, O.~Fried, J.~Thies, V.~Sitzmann, S.~Lombardi, Z.~Xu, T.~Simon,
  M.~Nie{\ss}ner, E.~Tretschk, L.~Liu \emph{et~al.}, ``Advances in neural
  rendering,'' in \emph{ACM SIGGRAPH 2021}, 2021.

\bibitem{gortler1996lumigraph}
S.~J. Gortler, R.~Grzeszczuk, R.~Szeliski, and M.~F. Cohen, ``The lumigraph,''
  in \emph{Proc.~of the Intl.~Conf.~on Computer Graphics and Interactive
  Techniques (SIGGRAPH)}, 1996.

\bibitem{levoy1996light}
M.~Levoy and P.~Hanrahan, ``Light field rendering,'' in \emph{Proc.~of the
  Intl.~Conf.~on Computer Graphics and Interactive Techniques (SIGGRAPH)},
  1996.

\bibitem{niklaus20193d}
S.~Niklaus, L.~Mai, J.~Yang, and F.~Liu, ``{3D} ken burns effect from a single
  image,'' \emph{ACM Trans.~on Graphics (TOG)}, 2019.

\bibitem{rockwell2021pixelsynth}
C.~Rockwell, D.~F. Fouhey, and J.~Johnson, ``Pixelsynth: Generating a
  {3D}-consistent experience from a single image,'' in \emph{Proc.~of the
  IEEE/CVF Intl.~Conf.~on Computer Vision (ICCV)}, 2021.

\bibitem{riegler2020free}
G.~Riegler and V.~Koltun, ``Free view synthesis,'' in \emph{Proc. Eur. Conf.
  Comput. Vis. (ECCV)}, 2020.

\bibitem{riegler2021stable}
------, ``Stable view synthesis,'' in \emph{Proc. IEEE Conf. Comput. Vis.
  Pattern Recognit. (CVPR)}, 2021.

\bibitem{park:nerfies}
K.~Park, U.~Sinha, J.~T. Barron, S.~Bouaziz, D.~B. Goldman, S.~M. Seitz, and
  R.~Martin-Brualla, ``Nerfies: Deformable neural radiance fields,'' in
  \emph{Proc.~of the IEEE/CVF Intl.~Conf.~on Computer Vision (ICCV)}, 2021.

\bibitem{park:hypernerf}
K.~Park, U.~Sinha, P.~Hedman, J.~T. Barron, S.~Bouaziz, D.~B. Goldman,
  R.~Martin-Brualla, and S.~M. Seitz, ``Hypernerf: A higher-dimensional
  representation for topologically varying neural radiance fields,'' \emph{ACM
  Trans.~on Graphics (TOG)}, 2021.

\bibitem{Guo_2022_NDVG_ACCV}
X.~Guo, G.~Chen, Y.~Dai, X.~Ye, J.~Sun, X.~Tan, and E.~Ding, ``Neural
  deformable voxel grid for fast optimization of dynamic view synthesis,'' in
  \emph{Proc.~of the Asi. Conf. Comput. Vis. (ACCV)}, 2022.

\bibitem{zhang2020nerf++}
K.~Zhang, G.~Riegler, N.~Snavely, and V.~Koltun, ``Nerf++: Analyzing and
  improving neural radiance fields,'' \emph{arXiv preprint arXiv:2010.07492},
  2020.

\bibitem{xiangli2022bungeenerf}
Y.~Xiangli, L.~Xu, X.~Pan, N.~Zhao, A.~Rao, C.~Theobalt, B.~Dai, and D.~Lin,
  ``Bungeenerf: Progressive neural radiance field for extreme multi-scale scene
  rendering,'' in \emph{Proc. Eur. Conf. Comput. Vis. (ECCV)}, 2022.

\bibitem{rematas2022urban}
K.~Rematas, A.~Liu, P.~P. Srinivasan, J.~T. Barron, A.~Tagliasacchi,
  T.~Funkhouser, and V.~Ferrari, ``Urban radiance fields,'' in \emph{Proc. IEEE
  Conf. Comput. Vis. Pattern Recognit. (CVPR)}, 2022.

\bibitem{martin2021nerf}
R.~Martin-Brualla, N.~Radwan, M.~S. Sajjadi, J.~T. Barron, A.~Dosovitskiy, and
  D.~Duckworth, ``Nerf in the wild: Neural radiance fields for unconstrained
  photo collections,'' in \emph{Proc. IEEE Conf. Comput. Vis. Pattern Recognit.
  (CVPR)}, 2021.

\bibitem{boss2021nerd}
M.~Boss, R.~Braun, V.~Jampani, J.~T. Barron, C.~Liu, and H.~Lensch, ``Nerd:
  Neural reflectance decomposition from image collections,'' in \emph{Proc.~of
  the IEEE/CVF Intl.~Conf.~on Computer Vision (ICCV)}, 2021.

\bibitem{srinivasan2021nerv}
P.~P. Srinivasan, B.~Deng, X.~Zhang, M.~Tancik, B.~Mildenhall, and J.~T.
  Barron, ``Nerv: Neural reflectance and visibility fields for relighting and
  view synthesis,'' in \emph{Proc. IEEE Conf. Comput. Vis. Pattern Recognit.
  (CVPR)}, 2021.

\bibitem{zhang2021nerfactor}
X.~Zhang, P.~P. Srinivasan, B.~Deng, P.~Debevec, W.~T. Freeman, and J.~T.
  Barron, ``Nerfactor: Neural factorization of shape and reflectance under an
  unknown illumination,'' \emph{ACM Trans.~on Graphics (TOG)}, 2021.

\bibitem{chen2021mvsnerf}
A.~Chen, Z.~Xu, F.~Zhao, X.~Zhang, F.~Xiang, J.~Yu, and H.~Su, ``{MVSNerf}:
  Fast generalizable radiance field reconstruction from multi-view stereo,'' in
  \emph{Proc.~of the IEEE/CVF Intl.~Conf.~on Computer Vision (ICCV)}, 2021.

\bibitem{trevithick2021grf}
A.~Trevithick and B.~Yang, ``Grf: Learning a general radiance field for {3D}
  representation and rendering,'' in \emph{Proc.~of the IEEE/CVF Intl.~Conf.~on
  Computer Vision (ICCV)}, 2021.

\bibitem{yu2021_pixelnerf_cvpr21}
A.~Yu, V.~Ye, M.~Tancik, and A.~Kanazawa, ``pixelnerf: Neural radiance fields
  from one or few images,'' in \emph{Proc. IEEE Conf. Comput. Vis. Pattern
  Recognit. (CVPR)}, 2021.

\bibitem{wang2021_ibrnet_cvpr21}
Q.~Wang, Z.~Wang, K.~Genova, P.~P. Srinivasan, H.~Zhou, J.~T. Barron,
  R.~Martin-Brualla, N.~Snavely, and T.~Funkhouser, ``Ibrnet: Learning
  multi-view image-based rendering,'' in \emph{Proc. IEEE Conf. Comput. Vis.
  Pattern Recognit. (CVPR)}, 2021.

\bibitem{rebain2021_derf_cvpr21}
D.~Rebain, W.~Jiang, S.~Yazdani, K.~Li, K.~M. Yi, and A.~Tagliasacchi, ``Derf:
  Decomposed radiance fields,'' in \emph{Proc. IEEE Conf. Comput. Vis. Pattern
  Recognit. (CVPR)}, 2021.

\bibitem{Reiser2021_kiloNeRF_iccv21}
C.~Reiser, S.~Peng, Y.~Liao, and A.~Geiger, ``Kilonerf: Speeding up neural
  radiance fields with thousands of tiny mlps,'' in \emph{Proc.~of the IEEE/CVF
  Intl.~Conf.~on Computer Vision (ICCV)}, 2021.

\bibitem{yu2021plenoxels}
S.~Fridovich-Keil, A.~Yu, M.~Tancik, Q.~Chen, B.~Recht, and A.~Kanazawa,
  ``Plenoxels: Radiance fields without neural networks,'' in \emph{Proc. IEEE
  Conf. Comput. Vis. Pattern Recognit. (CVPR)}, 2022.

\bibitem{sun2021direct}
C.~Sun, M.~Sun, and H.-T. Chen, ``Direct voxel grid optimization: Super-fast
  convergence for radiance fields reconstruction,'' \emph{Proc. IEEE Conf.
  Comput. Vis. Pattern Recognit. (CVPR)}, 2022.

\bibitem{muller2022instant}
T.~M{\"u}ller, A.~Evans, C.~Schied, and A.~Keller, ``Instant neural graphics
  primitives with a multiresolution hash encoding,'' \emph{ACM Trans.~on
  Graphics (TOG)}, 2022.

\bibitem{anonymous2023snerf}
Z.~Xie, J.~Zhang, W.~Li, F.~Zhang, and L.~Zhang, ``{S-NeRF}: Neural radiance
  fields for street views,'' in \emph{Proc.~of the Int.~Conf.~on Learning
  Representations (ICLR)}, 2023.

\bibitem{Li23READ}
Z.~Li, L.~Li, Z.~Ma, P.~Zhang, J.~Chen, and J.~Zhu, ``Read: Large-scale neural
  scene rendering for autonomous driving,'' in \emph{Proc.~of the Conf. Artif.
  Intell. (AAAI)}, 2023.

\bibitem{kundu2022panoptic}
A.~Kundu, K.~Genova, X.~Yin, A.~Fathi, C.~Pantofaru, L.~J. Guibas,
  A.~Tagliasacchi, F.~Dellaert, and T.~Funkhouser, ``Panoptic neural fields: A
  semantic object-aware neural scene representation,'' in \emph{Proc. IEEE
  Conf. Comput. Vis. Pattern Recognit. (CVPR)}, 2022.

\bibitem{deng2022depth}
K.~Deng, A.~Liu, J.-Y. Zhu, and D.~Ramanan, ``Depth-supervised nerf: Fewer
  views and faster training for free,'' in \emph{Proc. IEEE Conf. Comput. Vis.
  Pattern Recognit. (CVPR)}, 2022.

\bibitem{wiles2020synsin}
O.~Wiles, G.~Gkioxari, R.~Szeliski, and J.~Johnson, ``Synsin: End-to-end view
  synthesis from a single image,'' in \emph{Proc. IEEE Conf. Comput. Vis.
  Pattern Recognit. (CVPR)}, 2020.

\bibitem{kwak2023geconerf}
M.~Kwak, J.~Song, and S.~Kim, ``Geconerf: Few-shot neural radiance fields via
  geometric consistency,'' \emph{arXiv preprint arXiv:2301.10941}, 2023.

\bibitem{cao2022fwd}
A.~Cao, C.~Rockwell, and J.~Johnson, ``Fwd: Real-time novel view synthesis with
  forward warping and depth,'' in \emph{Proc. IEEE Conf. Comput. Vis. Pattern
  Recognit. (CVPR)}, 2022.

\bibitem{ranftl2021vision}
R.~Ranftl, A.~Bochkovskiy, and V.~Koltun, ``Vision transformers for dense
  prediction,'' in \emph{Proc.~of the IEEE/CVF Intl.~Conf.~on Computer Vision
  (ICCV)}, 2021, pp. 12\,179--12\,188.

\bibitem{yu2022monosdf}
Z.~Yu, S.~Peng, M.~Niemeyer, T.~Sattler, and A.~Geiger, ``Monosdf: Exploring
  monocular geometric cues for neural implicit surface reconstruction,'' in
  \emph{Proc.~of the Conference on Neural Information Processing Systems
  (NeurIPS)}, vol.~35, 2022, pp. 25\,018--25\,032.

\bibitem{liu2021condlanenet}
L.~Liu, X.~Chen, S.~Zhu, and P.~Tan, ``Condlanenet: a top-to-down lane
  detection framework based on conditional convolution,'' in \emph{Proc.~of the
  IEEE/CVF Intl.~Conf.~on Computer Vision (ICCV)}, 2021.

\bibitem{tancik2023nerfstudio}
M.~Tancik, E.~Weber, E.~Ng, R.~Li, B.~Yi, J.~Kerr, T.~Wang, A.~Kristoffersen,
  J.~Austin, K.~Salahi \emph{et~al.}, ``Nerfstudio: A modular framework for
  neural radiance field development,'' \emph{arXiv preprint arXiv:2302.04264},
  2023.

\bibitem{barron2022mip}
J.~T. Barron, B.~Mildenhall, D.~Verbin, P.~P. Srinivasan, and P.~Hedman,
  ``Mip-nerf 360: Unbounded anti-aliased neural radiance fields,'' in
  \emph{Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR)}, 2022.

\bibitem{wilson2023argoverse}
B.~Wilson, W.~Qi, T.~Agarwal, J.~Lambert, J.~Singh, S.~Khandelwal, B.~Pan,
  R.~Kumar, A.~Hartnett, J.~K. Pontes \emph{et~al.}, ``Argoverse 2: Next
  generation datasets for self-driving perception and forecasting,''
  \emph{arXiv preprint arXiv:2301.00493}, 2023.

\bibitem{wang2004image}
Z.~Wang, A.~C. Bovik, H.~R. Sheikh, and E.~P. Simoncelli, ``Image quality
  assessment: from error visibility to structural similarity,'' \emph{IEEE
  transactions on image processing}, vol.~13, no.~4, pp. 600--612, 2004.

\bibitem{zhang2018unreasonable}
R.~Zhang, P.~Isola, A.~A. Efros, E.~Shechtman, and O.~Wang, ``The unreasonable
  effectiveness of deep features as a perceptual metric,'' in \emph{Proc. IEEE
  Conf. Comput. Vis. Pattern Recognit. (CVPR)}, 2018, pp. 586--595.

\end{thebibliography}
