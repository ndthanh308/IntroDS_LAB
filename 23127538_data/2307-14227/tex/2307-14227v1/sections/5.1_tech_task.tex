\subsection{Tasks}\label{sec:tech_tasks}

Previous works on TCP mainly focus on tasks that resemble those in computer vision. Nevertheless, considering that TCP have distinct characteristics (as presented in \autoref{sec:background}) compared to natural images and videos, handling these tasks requires more TCP-specific designs and contributions.


\textbf{Image Classification.} TCP can be classified according to multiple attributes (\eg artists, painting techniques, and painting subjects). Annotating TCP with attributes can improve the retrieval experience and help understand the painting. Distinguishing TCP typically requires expert knowledge, which is time-consuming and expensive. Therefore, it is necessary to train automatic models for accurate TCP classification.


Many works~\cite{li2004studying,sheng2014recognition,liu2014Classification,sun2015brushstroke,sun2016monte,jiang2021mtffnet} classify TCP according to the artists in that the painting styles of different artists tend to be distinct. 
Specifically, for describing artists' painting styles, \cite{li2004studying} adopt a mixture of multiresolution hidden Markov models, and \cite{liu2014Classification} adopt various algorithms, such as Bayes, FLD, and SVM classifiers. \cite{sun2016monte} propose artistic descriptors with Monte Carlo Convex Hull for feature selection and use SVM for classification. 
Previous methods typically utilize traditional image processing techniques for classification. In contrast, \cite{sheng2014recognition}, \cite{sun2015brushstroke}, and \cite{jiang2021mtffnet} utilize MLPs or CNNs for distinguishing artists' styles. 


TCP have two mainstream painting techniques, {\it Gongbi}~(a meticulous style, focusing on details) and {\it Xieyi}~(an ideographic style, expressing artists' feelings). \cite{jiang2019dct} apply discrete cosine transformation and CNNs for classifying {\it Gongbi} and {\it Xieyi} paintings, achieving promising performance.
Some other works focus on classifying painting subjects, including mountains-and-waters~(landscape), flowers-and-birds, and human figures. \cite{meng2018classification} apply a modified VGG~\cite{simonyanVery2015} network for painting subject classification, achieving 93.8\% accuracy. Since TCP is closely related to calligraphy, \cite{liang2010simple} distinguish TCP from calligraphy according to the Chinese characters' structures and the differences in image composition. \cite{li2020multi} propose an LSTM-based model to classify TCP into five categories: ancient trees, people, flowers-and-birds, Jiangnan water-bound town, and ink paintings. However, these categories overlap with each other in the TCP concept, which inevitably limits the model's generalization ability.



\textbf{Image Segmentation and Object Detection.} 
Image segmentation was studied in TCP with traditional morphological methods, yet recent neural network-based methods have not been explored. There are two reasons: (1) It is hard to collect large-scale training datasets of TCP, which require domain knowledge for annotation; (2) the object boundaries of TCP (specifically a key category, {\it Xieyi} painting) are hard to determine, as shown in \hyperref[fig:gongbixieyi]{Fig.~3}A. In spite of these difficulties, \cite{hu2015object} try to extract the foreground objects from a human-designed saliency map, which has a smaller dependency on the scale of data. Some works \cite{8419282,zhang2011multispectral,chen2012simulating} decompose the painting into multiple layers to obtain foreground objects or stroke segmentation. On the other hand, prefaces and postscripts are vital components of TCP~(as shown in \autoref{fig:tcp_w}A1), thus \cite{bao2010novel} propose a rule-based method to extract these scripts. 

Directly adopting natural image-tailored deep learning models for detecting objects (\eg figure, plant, flower) in TCP tends to have poor performance.~\cite{gu2019deep}. \cite{meng2019elements} utilize modified YOLOv3~\cite{redmon2018YOLOv3} and RetinaNet~\cite{lin2017Focal}, and \cite{gu2019deep} propose a modified RPN~\cite{ren2017Faster} by assembling low-level visual information and high-level semantic information. Apart from the categories that also appeared in natural images, a traditional Chinese painting may contain many seals that identify the owners and collectors in a long history, automatically detecting seals can greatly help understand the artwork~\cite{bao2009effective}. 

\textbf{Image Generation.} 
TCP have their own styles (\eg ink wash painting, white space) compared with other painting types, such as oil painting. Early works try to transfer a natural image into ink wash paintings by adjusting colors and textures~\cite{guo2015novel,dong2014real,zhang2011multispectral,yu2003image} based on tuned hyper-parameters. These early methods are learning-free, thus typically requiring tuning hyper-parameters for each image. Recent works~\cite{xue2021end,zhang2020detail,he2018chipgan,li2021immersive,9413063} have taken efforts to create TCP with Generative Adversarial Networks~\cite{goodfellow2014Generative} that transfer noises or natural images into paintings by adversarial training. Some other works~\cite{wu2018research} perform style transfer methods with CNNs by separately learning semantic information and styles from two source images and generating a blending image. These methods are machine learning models, requiring a number of training samples for learning millions of parameters. 

Apart from regarding the painting as a whole to generate, another group of works considers that Chinese paintings employ brush strokes and ink to depict objects on the paper or silk. Specifically, some works~\cite{xie2013artist,xu2005virtual,mi2004droplet,way2001synthesis,lee1999simulating,10.1145/15886.15911} model either the brush or various stroke shapes, pursuing better texture simulation of real brush strokes. With the specifically modeled brushes, users can draw Chinese paintings stroke by stroke on the screen, instead of drawing on papers with a real brush~\cite{yang2019easy,le2019walking,li2014writing}. Considering the characteristic of rice paper and silk, a large number of early works~\cite{liang2013image,xu2007generic,wang2007image,10.1145/1073204.1073221,guo2003nijimi,way2003physical,lee2001diffusion} model the ink diffusion on the rice paper and silk, seeking to improve the realism of paintings. 
In addition, previous methods focus on creating digital Chinese paintings. Yao\etal~\cite{yao2005painting} build a painting robot to handle the brushes and draw real paintings by simulating human actions. 

\textbf{Video Generation.} We divide the works on TCP video generation into three classes according to their targets: (1) displaying the painting process, (2) animating objects, and (3) natural video style transfer. For the first target, a few works~\cite{yang2013animating,8113507,yang2013animating} focus on the creation of Chinese painting, proposing to display the painting process of brush strokes for TCP. In this way, brush trajectory can be animated for both education and appreciation purposes. For the second target, some other works~\cite{liu2020animating,lai2016data,zhang2009video,xu2006animating} present methods to animate figures, flowers, and water for a vivid representation of elements in Chinese paintings. Zhao\etal~\cite{zhao2020shadowplay2} build a visualization system to build 2.5-dimensional stories about Chinese poetry, displayed by 360-degree videos, which is expected to provide an immersive appreciation of poetry in Chinese painting styles. For the third target, Liang\etal~\cite{lianginstance} display a deep learning-based multi-frame fusion framework to stylize natural videos with ink wash styles. In the process of transferring, object coherence between adjacent frames is specifically considered for semantic consistency. 

\textbf{Human-Computer Interaction.} Compared with videos, devices supporting human interactions typically have a well immersive experience to appreciate TCP. For instance, the 360-degree space in VR can better satisfy the demands of displaying handscroll. As building the scenery on the virtual reality platform is labor-intensive and expensive, existing works only focus on a single painting. Specifically, Yuan\etal~\cite{yuan2016tunable} reconstruct a painting ``Listening to a Guqin'' in the mode of virtual reality, and Jin\etal~\cite{jin2020reconstructing} build the 3D scene of the painting ``Spring Morning in the Han Palace'' using a head-mounted platform. Moreover, the immersive multi-touch tabletop is also a promising interactive method for facilitating learning and appreciating TCP~\cite{jin2022immersive,subramonyam2015sigchi,hsieh2013viewing}. Ma\etal~\cite{ma2012annotating} embed the audio explanation into the local area of the Chinese painting, thus enabling the user to move the focus to get the audio explanation of the corresponding area while enjoying the painting. Jin\etal~\cite{jin2007real} develop a real-time projector-camera system that allows users to interact with Chinese ink cartoons (\eg interacting with water can create ripples). 

\textbf{Others.} Apart from the discussed tasks in CV and HCI above, there are various tasks involving TCP, such as color recovery~\cite{ding2012research}, poet generation from TCP~\cite{feng2022ipoet,chen2021poemgeneration}, Chinese painting retrieval~\cite{dong2020feature,hung2018study,zhang2004modelling}, white space understanding~\cite{fan2019evaluation}, and digital image enhancement~\cite{guo2013image,chen2012simulating,pei2006background,pei2004virtual}. 


