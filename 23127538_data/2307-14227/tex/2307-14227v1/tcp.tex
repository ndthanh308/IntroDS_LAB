\documentclass[twoside]{article}
% picins: misssing
\usepackage{amsfonts,amssymb,amsbsy,textcomp,marvosym,amsmath,caption,threeparttable,amsthm,subfigure,float,lastpage,lscape}
\usepackage{eurosym,mathrsfs,fancyhdr,CJK,multicol,graphics,indentfirst,color,bm,upgreek,booktabs,graphicx,multirow,warpcol}
\usepackage{epstopdf}
%\usepackage[noend]{algorithm}
%\usepackage[noend]{algorithmic}
%\usepackage[lined,algonl,boxed]{algorithm2e}
\usepackage{wrapfig}

\usepackage{hyperref}
\newcommand\nnfootnote[1]{%
  \begin{NoHyper}
  \renewcommand\thefootnote{}\footnote{#1}%
  \addtocounter{footnote}{-1}%
  \end{NoHyper}
}
\renewcommand*{\figureautorefname}{Fig.}
\renewcommand*{\sectionautorefname}{Sec.}
\renewcommand*{\subsectionautorefname}{Sec.}
\renewcommand*{\equationautorefname}{Eq.}

\usepackage{xspace,xpunctuate}
\newcommand{\aka}{{a.k.a.},\xspace}
\newcommand{\ie}{\textit{i.e.},\xspace}
\newcommand{\etal}{\xspace\textit{et al.}\xspace}
\newcommand{\eg}{\textit{e.g.},\xspace}

\newcommand{\rc}[1]{\textcolor{blue}{#1}}


\looseness=-1
%------------Page layout and margin and Headrule-------------
\headsep=5mm \headheight=4mm \topmargin=0cm \oddsidemargin=-0.5cm
\evensidemargin=-0.5cm \marginparwidth=0pt \marginparsep= 0pt
\marginparpush=0pt \textheight=23.1cm \textwidth=17.5cm \footskip=8mm
\columnsep=7mm \setlength{\doublerulesep}{0.1pt}
\footnotesep=3.5mm\arraycolsep=2pt
\font\tenrm=cmr10
%===========================================================
\def\footnoterule{\kern 1mm \hrule width 10cm \kern 2mm}
\def\rmd{{\rm d}} \def\rmi{{\rm i}} \def\rme{{\rm e}}
\def\sj#1{$^{[#1]}$}\def\lt{\left}\def\rt{\right}
\renewcommand{\captionfont}{\footnotesize}
\renewcommand\tablename{\bf \footnotesize Table}
\renewcommand\figurename{\footnotesize Fig.\!\!}
\captionsetup{labelsep=period}%
% \captionsetup[longtable]{labelsep=period}%
\allowdisplaybreaks
\sloppy
\renewcommand{\headrulewidth}{0pt}
\catcode`@=11
\def\title#1{\vspace{3mm}\begin{flushleft}\vglue-.1cm\Large\bf\boldmath\protect\baselineskip=18pt plus.2pt minus.1pt #1
\end{flushleft}\vspace{1mm} }
\def\author#1{\begin{flushleft}\normalsize #1\end{flushleft}\vspace*{-4pt} \vspace{3mm}}
\def\address#1#2{\begin{flushleft}\vglue-.35cm${}^{#1}$\small\it #2\vglue-.35cm\end{flushleft}\vspace{-2mm}\par}


\def\jz#1#2{{$^{\footnotesize\textcircled{\tiny #1}}$\let\thefootnote\relax\footnotetext{\!\!$^{\footnotesize\textcircled{\tiny #1}}$#2}}}
\catcode`@=11
\def\section{\@startsection{section}{1}{\z@}%
 %{-3.5ex \@plus -1ex \@minus -.2ex}%
 {-3ex \@plus -.3ex \@minus -.2ex}%
 {2.2ex \@plus.2ex}%
{\normalfont\normalsize\protect\baselineskip=14.5pt plus.2pt minus.2pt\bfseries}}
\def\subsection{\@startsection{subsection}{2}{\z@}%
 %{-3.25ex\@plus -1ex \@minus -.2ex}%
 {-3ex\@plus -.2ex \@minus -.2ex}%
 {2ex \@plus.2ex}%
{\normalfont\normalsize\protect\baselineskip=12.5pt plus.2pt minus.2pt\bfseries}}
\def\subsubsection{\@startsection{subsubsection}{3}{\z@}%
 %{-3.25ex\@plus -1ex \@minus -.2ex}%
 {-2.2ex\@plus -.21ex \@minus -.2ex}%
 {1.4ex \@plus.2ex}
{\normalfont\normalsize\protect\baselineskip=12pt plus.2pt minus.2pt\sl}}
\def\proofname{{\indent \it Proof.}}
%===========================================================ÒÔÉÏ²»¶¯

\pagestyle{fancy}
\fancyhf{}% Çå¿ÕÒ³Ã¼Ò³½Å
% \fancyhead[LO]{\small\sl Shortened Title Within 45 Characters}%
%\fancyhead[LO]{\small\sl Computational Approaches for TCP: Six Principles}%
\fancyhead[RO]{\small\thepage}
\fancyhead[LE]{\small\thepage}
%\fancyhead[RE]{\small\sl J. Comput. Sci. \& Technol.}
\setcounter{page}{1}
\begin{document}
\begin{CJK*}{GBK}{song}
\thispagestyle{empty}
\vspace*{-13mm}
%\noindent {\small Journal of computer science and technology: Instruction for authors.
%JOURNAL OF COMPUTER SCIENCE AND TECHNOLOGY}
%===========================================================
\vspace*{2mm}

\nnfootnote{}







\title{Computational Approaches for Traditional Chinese Painting: From the ``Six Principles of Painting'' Perspective}


\author{Wei Zhang$^{1}$, Jian-Wei Zhang$^{1}$, Kam Kwai Wong$^{2}$, Yifang Wang$^{3}$, Yingchaojie Feng$^{1}$, Luwei Wang$^{1}$, and Wei Chen$^{1,4,*}$}

\address{1}{State Key Lab of CAD\&CG, Zhejiang University, Hangzhou 310058, China}
\address{2}{Hong Kong University of Science and Technology, Hong Kong 999077, China}
\address{3}{Kellogg School of Management, Northwestern University, Evanston 60208, U.S.A}
\address{4}{Laboratory of Art and Archaeology Image, Zhejiang University, Hangzhou 310058, China}


\vspace{2mm}

\noindent E-mail: zw\underline{~~}yixian@zju.edu.cn; zjw.cs@zju.edu.cn; kkwongar@cse.ust.hk; yifang.wang@kellogg.northwestern.edu; fycj@zju.edu.cn; ppwlwpp@zju.edu.cn; chenvis@zju.edu.cn \\[-1mm]





%\let\thefootnote\relax\footnotetext{{}\\[-4mm]\indent\ Regular Paper}

\noindent {\small\bf Abstract} \quad  
{\small {Traditional Chinese Painting (TCP) is an invaluable cultural heritage resource and a unique visual art style. In recent years, increasing interest has been placed on digitalizing TCPs to preserve and revive the culture. The resulting digital copies have enabled the advancement of computational methods for structured and systematic understanding of TCPs. To explore this topic, we conducted an in-depth analysis of 92 pieces of literature. We examined the current use of computer technologies on TCPs from three perspectives, based on numerous conversations with specialists. First, in light of the ``Six Principles of Painting" theory, we categorized the articles according to their research focus on artistic elements. Second, we created a four-stage framework to illustrate the purposes of TCP applications. Third, we summarized the popular computational techniques applied to TCPs. The framework also provides insights into potential applications and future prospects, with professional opinion. The list of surveyed publications and related information is available online at https://ca4tcp.com.}}

%{\small \textcolor{blue}{Please provide an abstract of 100 to 250 words. The abstract should clearly state the nature and significance of the paper. It must not include undefined abbreviations, mathematical expressions or bibliographic references.}}

\vspace*{3mm}

\noindent{\small\bf Keywords} \quad {\small Traditional Chinese Painting, Digital humanity, Cultural heritage, Computer vision, Deep learning}
%[\textcolor{blue}{Keywords should closely reflect the topic and should optically characterize the paper. Please use about 3$\sim $5 keywords or phrases in alphabetical order separated by commas.}]}

\vspace*{4mm}

\end{CJK*}
\baselineskip=18pt plus.2pt minus.2pt
\parskip=0pt plus.2pt minus0.2pt
\begin{multicols}{2}


\input{sections/1_intro}
\input{sections/2_meth}
\input{sections/3_bg}
\input{sections/4_fram}
\input{sections/5_tech}
\input{sections/6_challenges} 
\input{sections/7_conclusion} 


\begin{thebibliography}{100}
\footnotesize
\itemsep=-3pt plus.2pt minus.2pt
\baselineskip=13pt plus.2pt minus.2pt
%\begin{thebibliography}{100}

\bibitem{iiif}
{International Image Interoperability Framework (IIIF)}.
\newblock \url{https://iiif.io/get-started/how-iiif-works/}.

\bibitem{amati2010modeling}
Cristina Amati and Gabriel~J Brostow.
\newblock Modeling 2.5 d plants from ink paintings.
\newblock In {\em Proceedings of the Seventh Sketch-Based Interfaces and
  Modeling Symposium}, pages 41--48, 2010.

\bibitem{bai2007efficient}
Bendu Bai, Kam-Wah Wong, and Yanning Zhang.
\newblock An efficient physically-based model for chinese brush.
\newblock In {\em International Workshop on Frontiers in Algorithmics}, pages
  261--270. Springer, 2007.

\bibitem{bai2009chinese}
Bendu Bai, Yanning Zhang, Kam-Wah Wong, and Ying Li.
\newblock Chinese hairy brush: A physically-based model for calligraphy.
\newblock {\em Chinese Journal of Electronics}, 18(2):302--306, 2009.

\bibitem{bao2010novel}
Hong Bao, Ye~Liang, Hong-Zhe Liu, and De~Xu.
\newblock A novel algorithm for extraction of the scripts part in traditional
  chinese painting images.
\newblock In {\em 2010 2nd International Conference on Software Technology and
  Engineering}, volume~2, pages V2--26. IEEE, 2010.

\bibitem{bao2009effective}
Hong Bao, De~Xu, and Songhe Feng.
\newblock An effective method to detect seal images from traditional chinese
  paintings.
\newblock In {\em 2009 International Conference on Wireless Communications \&
  Signal Processing}, pages 1--4. IEEE, 2009.

\bibitem{bo2018computational}
Yihang Bo, Jinhui Yu, and Kang Zhang.
\newblock Computational aesthetics and applications.
\newblock {\em Visual Computing for Industry, Biomedicine, and Art},
  1(1):1--19, 2018.

\bibitem{bradley2018visualization}
Adam~James Bradley, Mennatallah El-Assady, Katharine Coles, Eric Alexander, Min
  Chen, Christopher Collins, Stefan J{\"a}nicke, and David~Joseph Wrisley.
\newblock Visualization and the digital humanities.
\newblock {\em IEEE computer graphics and applications}, 38(6):26--38, 2018.

\bibitem{chan2002two}
Ching Chan, Ergun Akleman, and Jianer Chen.
\newblock Two methods for creating chinese painting.
\newblock In {\em 10th Pacific Conference on Computer Graphics and
  Applications, 2002. Proceedings.}, pages 403--412. IEEE, 2002.

\bibitem{chen2021poemgeneration}
Jiazhou Chen, Keshu Huang, Yingchaojie Feng, Wei Zhang, Siwei Tan, and Wei
  Chen.
\newblock Automatic poetry generation based on ancient chinese paintings.
\newblock {\em Journal of Computer-Aided Design \& Computer Graphics}, 33(7):7,
  2021.

\bibitem{chen2012simulating}
Lieu-Hen Chen, Meng-Feng TSAI, Chien-Hui HSU, and Yu-Sheng CHEN.
\newblock Simulating aging and reverse-aging phenomena of traditional chinese
  paintings.
\newblock pages 4M1IOS3c5--4M1IOS3c5, 2012.

\bibitem{cheng2018essential}
Maria Cheng, Tang~Wai Hung, et~al.
\newblock {\em Essential terms of Chinese painting}.
\newblock City University of HK Press, 2018.

\bibitem{10.1145/1073204.1073221}
Nelson S.-H. Chu and Chiew-Lan Tai.
\newblock Moxi: Real-time ink dispersion in absorbent paper.
\newblock {\em ACM Trans. Graph.}, 24(3):504-511, jul 2005.

\bibitem{chu2004real}
Nelson~SH Chu and Chiew-Lan Tai.
\newblock Real-time painting with an expressive virtual chinese brush.
\newblock {\em IEEE Computer Graphics and applications}, 24(5):76--85, 2004.

\bibitem{chua1990bezier}
Yap~Siong Chua.
\newblock Bezier brushstrokes.
\newblock {\em Computer-Aided Design}, 22(9):550--555, 1990.

\bibitem{ding2012research}
Haiyan Ding and Huaidong Ding.
\newblock Research on computer color recovery system for traditional chinese
  painting.
\newblock In {\em 2012 International Conference on Systems and Informatics
  (ICSAI2012)}, pages 1985--1988. IEEE, 2012.

\bibitem{diverdi2015modular}
Stephen DiVerdi.
\newblock A modular framework for digital painting.
\newblock {\em IEEE Transactions on Visualization and Computer Graphics},
  21(7):783--793, 2015.

\bibitem{dong2014real}
Lixing Dong, Shufang Lu, and Xiaogang Jin.
\newblock Real-time image-based chinese ink painting rendering.
\newblock {\em Multimedia tools and applications}, 69(3):605--620, 2014.

\bibitem{dong2020feature}
Zhenhao Dong, Jing Wan, Chaoyue Li, Han Jiang, Yingge Qian, and Wenxie Pan.
\newblock Feature fusion based cross-modal retrieval for traditional chinese
  painting.
\newblock In {\em 2020 International Conference on Culture-oriented Science \&
  Technology (ICCST)}, pages 383--387. IEEE, 2020.

\bibitem{fan2017visual}
Zhen~Bao Fan, Yi-Na Li, Jinhui Yu, and Kang Zhang.
\newblock Visual complexity of chinese ink paintings.
\newblock In {\em Proceedings of the ACM Symposium on Applied Perception},
  pages 1--8, 2017.

\bibitem{fan2019evaluation}
ZhenBao Fan, Kang Zhang, and XianJun~Sam Zheng.
\newblock Evaluation and analysis of white space in wu guanzhong's chinese
  paintings.
\newblock {\em Leonardo}, 52(2):111--116, 2019.

\bibitem{feng2022ipoet}
Yingchaojie Feng, Jiazhou Chen, Keyu Huang, Jason~K Wong, Hui Ye, Wei Zhang,
  Rongchen Zhu, Xiaonan Luo, and Wei Chen.
\newblock ipoet: interactive painting poetry creation with visual multimodal
  analysis.
\newblock {\em Journal of Visualization}, 25(3):671--685, 2022.

\bibitem{8419282}
Yunfei Fu, Hongchuan Yu, Chih-Kuo Yeh, Jianjun Zhang, and Tong-Yee Lee.
\newblock High relief from brush painting.
\newblock {\em IEEE Transactions on Visualization and Computer Graphics},
  25(9):2763--2776, 2019.

\bibitem{goodfellow2014Generative}
Ian Goodfellow, Jean {Pouget-Abadie}, Mehdi Mirza, Bing Xu, David
  {Warde-Farley}, Sherjil Ozair, Aaron Courville, and Yoshua Bengio.
\newblock Generative {{Adversarial Nets}}.
\newblock In Z.~Ghahramani, M.~Welling, C.~Cortes, N.~D. Lawrence, and K.~Q.
  Weinberger, editors, {\em Advances in {{Neural Information Processing
  Systems}} 27}, pages 2672--2680. 2014.

\bibitem{gu2019deep}
Qianqian Gu and Ross King.
\newblock Deep learning does not generalize well to recognizing cats and dogs
  in chinese paintings.
\newblock In {\em International Conference on Discovery Science}, pages
  166--175. Springer, 2019.

\bibitem{guan2005automatic}
Xiaohui Guan, Gang Pan, and Zhaohui Wu.
\newblock Automatic categorization of traditional chinese painting images with
  statistical gabor feature and color feature.
\newblock In {\em International Conference on Computational Science}, pages
  743--750. Springer, 2005.

\bibitem{guo2015novel}
Fan Guo, Hui Peng, and Jin Tang.
\newblock A novel method of converting photograph into chinese ink painting.
\newblock {\em IEEJ Transactions on Electrical and Electronic Engineering},
  10(3):320--329, 2015.

\bibitem{guo2013image}
Fan Guo, Jin Tang, and Hui Peng.
\newblock Image recovery for ancient chinese paintings.
\newblock 2013.

\bibitem{guo2003nijimi}
Qinglian Guo and Tosiyasu~L Kunii.
\newblock "nijimi" rendering algorithm for creating quality black ink
  paintings.
\newblock In {\em Proceedings Computer Graphics International 2003}, pages
  152--159. IEEE, 2003.

\bibitem{hxz2022painting}
Xizai Han.
\newblock {The Night Revels of Han Xizai}.
\newblock \url{https://www.dpm.org.cn/collection/paint/228200.html}.

\bibitem{he2018chipgan}
Bin He, Feng Gao, Daiqian Ma, Boxin Shi, and Ling-Yu Duan.
\newblock Chipgan: A generative adversarial network for chinese ink wash
  painting style transfer.
\newblock In {\em Proceedings of the 26th ACM international conference on
  Multimedia}, pages 1172--1180, 2018.

\bibitem{hsieh2013viewing}
Chun-ko Hsieh, Yi-Ping Hung, Moshe Ben-Ezra, and Hsin-Fang Hsieh.
\newblock Viewing chinese art on an interactive tabletop.
\newblock {\em IEEE computer graphics and applications}, 33(3):16--21, 2013.

\bibitem{hu2015object}
Zhengkun Hu and Tingmei Wang.
\newblock Object extraction in chinese painting base on visual saliency.
\newblock In {\em 2015 8th International Symposium on Computational
  Intelligence and Design (ISCID)}, volume~2, pages 493--496. IEEE, 2015.

\bibitem{huang2019learning}
Zhewei Huang, Wen Heng, and Shuchang Zhou.
\newblock Learning to paint with model-based deep reinforcement learning.
\newblock In {\em Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pages 8709--8718, 2019.

\bibitem{hung2018study}
Chia-Ching Hung.
\newblock A study on a content-based image retrieval technique for chinese
  paintings.
\newblock {\em The Electronic Library}, 2018.

\bibitem{jiang2006effective}
Shuqiang Jiang, Qingming Huang, Qixiang Ye, and Wen Gao.
\newblock An effective method to detect and categorize digitized traditional
  chinese paintings.
\newblock {\em Pattern Recognition Letters}, 27(7):734--746, 2006.

\bibitem{jiang2004categorizing}
Shuqiang Jiang and Tiejun Huang.
\newblock Categorizing traditional chinese painting images.
\newblock In {\em Pacific-Rim Conference on Multimedia}, pages 1--8. Springer,
  2004.

\bibitem{jiang2021mtffnet}
Wei Jiang, Xiaoyu Wang, Jinchang Ren, Sen Li, Meijun Sun, Zheng Wang, and
  Jesse~S Jin.
\newblock Mtffnet: a multi-task feature fusion framework for chinese painting
  classification.
\newblock {\em Cognitive Computation}, 13(5):1287--1296, 2021.

\bibitem{jiang2019dct}
Wei Jiang, Zheng Wang, Jesse~S Jin, Yahong Han, and Meijun Sun.
\newblock Dct--cnn-based classification method for the gongbi and xieyi
  techniques of chinese ink-wash paintings.
\newblock {\em Neurocomputing}, 330:280--286, 2019.

\bibitem{jin2007real}
Ming Jin, Hui Zhang, Xubo Yang, and Shuangjiu Xiao.
\newblock A real-time procam system for interaction with chinese ink-and-wash
  cartoons.
\newblock In {\em 2007 IEEE Conference on Computer Vision and Pattern
  Recognition}, pages 1--2. IEEE, 2007.

\bibitem{jin2022immersive}
Sheng Jin, Min Fan, and Aynur Kadir.
\newblock Immersive spring morning in the han palac e: Learning traditional
  chinese art via virtual reality and multi-touch tabletop.
\newblock {\em International Journal of Human--Computer Interaction},
  38(3):213--226, 2022.

\bibitem{jin2020reconstructing}
Sheng Jin, Min Fan, Yongchao Wang, and Qi~Liu.
\newblock Reconstructing traditional chinese paintings with immersive virtual
  reality.
\newblock In {\em Extended Abstracts of the 2020 CHI Conference on Human
  Factors in Computing Systems}, CHI EA '20, page 1-8, New York, NY, USA,
  2020. Association for Computing Machinery.

\bibitem{xy2022painting}
Liang Kai.
\newblock {Immortal in Splashed Ink}.
\newblock
  \url{https://digitalarchive.npm.gov.tw/Painting/Content?pid=1819\&Dept=P}.

\bibitem{kotovenko2021rethinking}
Dmytro Kotovenko, Matthias Wright, Arthur Heimbrecht, and Bjorn Ommer.
\newblock Rethinking style transfer: From pixels to parameterized brushstrokes.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 12196--12205, 2021.

\bibitem{krizhevsky2017imagenet}
Alex Krizhevsky, Ilya Sutskever, and Geoffrey~E Hinton.
\newblock Imagenet classification with deep convolutional neural networks.
\newblock {\em Communications of the ACM}, 60(6):84--90, 2017.

\bibitem{kunii1995diffusion}
Tosiyasu~L Kunii, Gleb~V Nosovskij, and Takafumi Hayashi.
\newblock A diffusion model for computer animation of diffuse ink painting.
\newblock In {\em Proceedings Computer Animation'95}, pages 98--102. IEEE,
  1995.

\bibitem{kyprianidis2012state}
Jan~Eric Kyprianidis, John Collomosse, Tinghuai Wang, and Tobias Isenberg.
\newblock State of the ``art'': A taxonomy of artistic stylization techniques
  for images and video.
\newblock {\em IEEE transactions on visualization and computer graphics},
  19(5):866--885, 2012.

\bibitem{lai2016data}
Yu-Chi Lai, Bo-An Chen, Kuo-Wei Chen, Wei-Lin Si, Chih-Yuan Yao, and Eugene
  Zhang.
\newblock Data-driven npr illustrations of natural flows in chinese painting.
\newblock {\em IEEE transactions on visualization and computer graphics},
  23(12):2535--2549, 2016.

\bibitem{le2019walking}
Aven Le~Zhou.
\newblock Walking through shanshui: Generating chinese shanshui paintings via
  real-time tracking of human position.
\newblock In {\em Proceedings of the IEEE/CVF International Conference on
  Computer Vision Workshops}, pages 0--0, 2019.

\bibitem{lee1999simulating}
Jintae Lee.
\newblock Simulating oriental black-ink painting.
\newblock {\em IEEE Computer Graphics and Applications}, 19(3):74--81, 1999.

\bibitem{lee2001diffusion}
Jintae Lee.
\newblock Diffusion rendering of black ink paintings using new paper and ink
  models.
\newblock {\em Computers \& Graphics}, 25(2):295--308, 2001.

\bibitem{li2020multi}
Daxiang Li and Yue Zhang.
\newblock Multi-instance learning algorithm based on lstm for chinese painting
  image classification.
\newblock {\em IEEE Access}, 8:179336--179345, 2020.

\bibitem{li2004studying}
Jia Li and James~Ze Wang.
\newblock Studying digital imagery of ancient paintings by mixtures of
  stochastic models.
\newblock {\em IEEE transactions on image processing}, 13(3):340--353, 2004.

\bibitem{li2014writing}
Jiajia Li, Grace Ngai, Stephen~CF Chan, Kien~A Hua, Hong~Va Leong, and Alvin
  Chan.
\newblock From writing to painting: A kinect-based cross-modal chinese painting
  generation system.
\newblock In {\em Proceedings of the 22nd ACM international conference on
  Multimedia}, pages 57--66, 2014.

\bibitem{li2021immersive}
Jiayue Li, Qing Wang, Shiji Li, Qiang Zhong, and Qian Zhou.
\newblock Immersive traditional chinese portrait painting: Research on style
  transfer and face replacement.
\newblock In {\em Chinese Conference on Pattern Recognition and Computer Vision
  (PRCV)}, pages 192--203. Springer, 2021.

\bibitem{li2022computing}
Meng Li, Yun Wang, and Ying-Qing Xu.
\newblock Computing for chinese cultural heritage.
\newblock {\em Visual Informatics}, 6(1):1--13, 2022.

\bibitem{lianginstance}
Hao Liang, Shuai Yang, Wenjing Wang, and Jiaying Liu.
\newblock Instance-aware coherent video style transfer for chinese ink wash
  painting.
\newblock 2021.

\bibitem{liang2013image}
Lingyu Liang and Lianwen Jin.
\newblock Image-based rendering for ink painting.
\newblock In {\em 2013 IEEE International Conference on Systems, Man, and
  Cybernetics}, pages 3950--3954. IEEE, 2013.

\bibitem{liang2010simple}
Ye~Liang, Hong Bao, and Hong-Zhe Liu.
\newblock A simple method for classification of traditional chinese painting
  and calligraphy images.
\newblock In {\em 2010 International Conference on Educational and Information
  Technology}, volume~3, pages V3--340. IEEE, 2010.

\bibitem{gb2022painting}
Ma~Lin.
\newblock {King Yu of Xia}.
\newblock
  \url{https://digitalarchive.npm.gov.tw/Painting/Content?pid=14658\&Dept=P}.

\bibitem{lin2017Focal}
Tsung-Yi Lin, Priya Goyal, Ross Girshick, Kaiming He, and Piotr Dollar.
\newblock Focal {{Loss}} for {{Dense Object Detection}}.
\newblock In {\em Proceedings of the {{IEEE International Conference}} on
  {{Computer Vision}} ({{ICCV}})}, October 2017.

\bibitem{lin1967art}
Yutang Lin.
\newblock {\em The Chinese Theory of Art}.
\newblock G.P. Putnam's Sons, NY, 1967.

\bibitem{liong2020automatic}
Sze-Teng Liong, Yen-Chang Huang, Shumeng Li, Zhongkai Huang, Jingyang Ma, and
  Yee~Siang Gan.
\newblock Automatic traditional chinese painting classification: A benchmarking
  analysis.
\newblock {\em Computational Intelligence}, 36(3):1183--1199, 2020.

\bibitem{litwinowicz1997processing}
Peter Litwinowicz.
\newblock Processing images and video for an impressionist effect.
\newblock In {\em Proceedings of the 24th annual conference on Computer
  graphics and interactive techniques}, pages 407--414, 1997.

\bibitem{liu2014Classification}
Chi Liu and He~Jiang.
\newblock Classification of traditional chinese paintings based on supervised
  learning methods.
\newblock In {\em 2014 IEEE International Conference on Signal Processing,
  Communications and Computing (ICSPCC)}, pages 641--644, 2014.

\bibitem{liu2020animating}
Damon Shing-Min Liu, Ching-I Cheng, and Mei-Lin Liu.
\newblock Animating characters in chinese painting using two-dimensional
  skeleton-based deformation.
\newblock {\em Multimedia Tools and Applications}, 79(27):20343--20371, 2020.

\bibitem{liu2021paint}
Songhua Liu, Tianwei Lin, Dongliang He, Fu~Li, Ruifeng Deng, Xin Li, Errui
  Ding, and Hao Wang.
\newblock Paint transformer: Feed forward neural painting with stroke
  prediction.
\newblock In {\em Proceedings of the IEEE/CVF international conference on
  computer vision}, pages 6598--6607, 2021.

\bibitem{lu2008content}
Guanming Lu, Zhong Gao, Danni Qin, Xin Zhao, and Mengjue Liu.
\newblock Content-based identifying and classifying traditional chinese
  painting images.
\newblock In {\em 2008 Congress on Image and Signal Processing}, volume~4,
  pages 570--574. IEEE, 2008.

\bibitem{ma2012annotating}
Wei Ma, Yizhou Wang, Ying-Qing Xu, Qiong Li, Xin Ma, and Wen Gao.
\newblock Annotating traditional chinese paintings for immersive virtual
  exhibition.
\newblock {\em Journal on Computing and Cultural Heritage (JOCCH)}, 5(2):1--12,
  2012.

\bibitem{meng2019elements}
Qingyu Meng, Kaiyue Li, Mingquan Zhou, and Huanhuan Zhang.
\newblock The elements extraction on traditional chinese paintings based on
  object detection.
\newblock In {\em Proceedings of the 2019 2nd Artificial Intelligence and Cloud
  Computing Conference}, pages 111--116, 2019.

\bibitem{meng2018classification}
Qingyu Meng, Huanhuan Zhang, Mingquan Zhou, Shifeng Zhao, and Pengbo Zhou.
\newblock The classification of traditional chinese painting based on cnn.
\newblock In {\em International Conference on Cloud Computing and Security},
  pages 232--241. Springer, 2018.

\bibitem{mi2004droplet}
Xiao-Feng Mi, Min Tang, and Jin-Xiang Dong.
\newblock Droplet: a virtual brush model to simulate chinese calligraphy and
  painting.
\newblock {\em Journal of Computer Science and Technology}, 19(3):393--404,
  2004.

\bibitem{mi2002droplet}
Xiaofeng Mi, Jie Xu, Min Tang, and Jinxiang Dong.
\newblock The droplet virtual brush for chinese calligraphic character
  modeling.
\newblock In {\em Sixth IEEE Workshop on Applications of Computer Vision,
  2002.(WACV 2002). Proceedings.}, pages 330--334. IEEE, 2002.

\bibitem{nishita1993display}
Tomoyuki Nishita, Shinichi Takita, and Eihachiro Nakamae.
\newblock A display algorithm of brush strokes using bezier functions.
\newblock In {\em Communicating with virtual worlds}, pages 244--257. Springer,
  1993.

\bibitem{pei2006background}
S~Pei and Y~Chiu.
\newblock Background adjustment and saturation enhancement in ancient chinese
  paintings.
\newblock {\em IEEE transactions on image processing}, 15(10):3230--3234, 2006.

\bibitem{pei2004virtual}
Soo-Chang Pei, Yi-Chong Zeng, and Ching-Hua Chang.
\newblock Virtual restoration of ancient chinese paintings using color contrast
  enhancement and lacuna texture synthesis.
\newblock {\em IEEE transactions on image processing}, 13(3):416--429, 2004.

\bibitem{redmon2018YOLOv3}
Joseph Redmon and Ali Farhadi.
\newblock {{YOLOv3}}: {{An Incremental Improvement}}, April 2018.

\bibitem{ren2017Faster}
Shaoqing Ren, Kaiming He, Ross Girshick, and Jian Sun.
\newblock Faster {{R-CNN}}: {{Towards Real-Time Object Detection}} with
  {{Region Proposal Networks}}.
\newblock {\em IEEE Trans. Pattern Anal. Mach. Intell.}, 39(6):1137--1149, June
  2017.

\bibitem{sheng2014}
Jiachuan Sheng.
\newblock Automatic categorization of traditional chinese paintings based on
  wavelet transform.
\newblock {\em Computer Science}, 41(2):317--319, 2014.

\bibitem{sheng2013style}
Jiachuan Sheng and Jianmin Jiang.
\newblock Style-based classification of chinese ink and wash paintings.
\newblock {\em Optical Engineering}, 52(9):093101, 2013.

\bibitem{sheng2014recognition}
Jiachuan Sheng and Jianmin Jiang.
\newblock Recognition of chinese artists via windowed and entropy balanced
  fusion in classification of their authored ink and wash paintings (iwps).
\newblock {\em Pattern Recognition}, 47(2):612--622, 2014.

\bibitem{shi2017generative}
Weili Shi.
\newblock A generative approach to chinese shanshui painting.
\newblock {\em IEEE Computer Graphics and Applications}, 37(1):15--19, 2017.

\bibitem{simonyan2014very}
Karen Simonyan and Andrew Zisserman.
\newblock Very deep convolutional networks for large-scale image recognition.
\newblock {\em arXiv preprint arXiv:1409.1556}, 2014.

\bibitem{simonyanVery2015}
Karen Simonyan and Andrew Zisserman.
\newblock Very {{Deep Convolutional Networks}} for {{Large-Scale Image
  Recognition}}.
\newblock In {\em 3rd {{International Conference}} on {{Learning
  Representations}}, {{ICLR}} 2015, {{San Diego}}, {{CA}}, {{USA}}, {{May}}
  7-9, 2015, {{Conference Track Proceedings}}}, 2015.

\bibitem{10.1145/15886.15911}
Steve Strassmann.
\newblock Hairy brushes.
\newblock {\em SIGGRAPH Comput. Graph.}, 20(4):225-232, aug 1986.

\bibitem{subramonyam2015sigchi}
Hariharan Subramonyam, Yuncheng Shen, and Samantha~Lauren Jones.
\newblock Sigchi: Enabling context for traditional chinese paintings with
  "rice paper".
\newblock In {\em Proceedings of the 33rd Annual ACM Conference Extended
  Abstracts on Human Factors in Computing Systems}, CHI EA '15, page 49-54,
  New York, NY, USA, 2015. Association for Computing Machinery.

\bibitem{sun2015brushstroke}
Meijun Sun, Dong Zhang, Jinchang Ren, Zheng Wang, and Jesse~S Jin.
\newblock Brushstroke based sparse hybrid convolutional neural networks for
  author classification of chinese ink-wash paintings.
\newblock In {\em 2015 IEEE International Conference on Image Processing
  (ICIP)}, pages 626--630. IEEE, 2015.

\bibitem{sun2016monte}
Meijun Sun, Dong Zhang, Zheng Wang, Jinchang Ren, and Jesse~S Jin.
\newblock Monte carlo convex hull model for classification of traditional
  chinese paintings.
\newblock {\em Neurocomputing}, 171:788--797, 2016.

\bibitem{8113507}
Fan Tang, Weiming Dong, Yiping Meng, Xing Mei, Feiyue Huang, Xiaopeng Zhang,
  and Oliver Deussen.
\newblock Animated construction of chinese brush paintings.
\newblock {\em IEEE Transactions on Visualization and Computer Graphics},
  24(12):3019--3031, 2018.

\bibitem{van1962way}
Fritz Van~Briessen.
\newblock {\em The Way of the Brush: Painting Techniques of China and Japan}.
\newblock Tuttle Publishing, 1962.

\bibitem{nw2022painting}
Rembrandt van Rijn.
\newblock {The Night Watch}.
\newblock \url{https://hart.amsterdam/collectie/object/amcollect/38543}.

\bibitem{wang2007image}
Chung-Ming Wang and Ren-Jie Wang.
\newblock Image-based color ink diffusion rendering.
\newblock {\em IEEE Transactions on Visualization and Computer Graphics},
  13(2):235--246, 2007.

\bibitem{9413063}
Rui Wang, Huaibo Huang, Aihua Zheng, and Ran He.
\newblock Attentional wavelet network for traditional chinese painting
  transfer.
\newblock In {\em 2020 25th International Conference on Pattern Recognition
  (ICPR)}, pages 3077--3083, 2021.

\bibitem{warwick2012digital}
Claire Warwick, Melissa Terras, and Julianne Nyhan.
\newblock {\em Digital humanities in practice}.
\newblock Facet Publishing, 2012.

\bibitem{way2003physical}
De-Lor Way, Shen-Wen Huang, and Zen-Chung Shih.
\newblock Physical-based model of ink diffusion in chinese paintings.
\newblock 2003.

\bibitem{way2002synthesis}
De-Lor Way, Yu-Ru Lin, and Zen-Chung Shih.
\newblock The synthesis of trees in chinese landscape painting using silhoutte
  and texture strokes.
\newblock 2002.

\bibitem{way2006computer}
Der-Lor Way, Wei-Jin Lin, and Zen-Chung Shih.
\newblock Computer-generated chinese color ink paintings.
\newblock {\em Journal of the Chinese Institute of Engineers},
  29(6):1041--1050, 2006.

\bibitem{way2001synthesis}
Der-Lor Way and Zen-Chung Shih.
\newblock The synthesis of rock textures in chinese landscape painting.
\newblock In {\em Computer Graphics Forum}, volume~20, pages 123--131. Wiley
  Online Library, 2001.

\bibitem{wu2018research}
Bing Wu and Qingshuang Dong.
\newblock Research on the synthetic method of ink painting based on
  convolutional neural network.
\newblock In {\em Tenth International Conference on Digital Image Processing
  (ICDIP 2018)}, volume 10806, page 108062B. International Society for Optics
  and Photonics, 2018.

\bibitem{wu2013modeling}
Xinming Wu, Guofeng Li, and Ye~Liang.
\newblock Modeling chinese painting images based on ontology.
\newblock In {\em 2013 International Conference on Information Technology and
  Applications}, pages 113--116. IEEE, 2013.

\bibitem{xie2013artist}
Ning Xie, Hirotaka Hachiya, and Masashi Sugiyama.
\newblock Artist agent: A reinforcement learning approach to automatic stroke
  generation in oriental ink painting.
\newblock {\em IEICE TRANSACTIONS on Information and Systems},
  96(5):1134--1144, 2013.

\bibitem{xu2005virtual}
Songhua Xu, CM~Francis Lau, Congfu Xu, and Yunhe Pan.
\newblock Virtual hairy brush for digital painting and calligraphy.
\newblock {\em Science in China Series F: Information Sciences}, 48:285--303,
  2005.

\bibitem{xu2007generic}
Songhua Xu, Haisheng Tan, Xiantao Jiao, Francis~CM Lau, and Yunhe Pan.
\newblock A generic pigment model for digital painting.
\newblock In {\em Computer Graphics Forum}, volume~26, pages 609--618. Wiley
  Online Library, 2007.

\bibitem{xu2006animating}
Songhua Xu, Yingqing Xu, Sing~Bing Kang, David~H Salesin, Yunhe Pan, and
  Heung-Yeung Shum.
\newblock Animating chinese paintings through stroke-based decomposition.
\newblock {\em ACM Transactions on Graphics (TOG)}, 25(2):239--267, 2006.

\bibitem{xu2012stroke}
Tian-Chen Xu, Li-Jie Yang, and En-Hua Wu.
\newblock Stroke-based real-time ink wash painting style rendering for
  geometric models.
\newblock In {\em SIGGRAPH Asia 2012 Technical Briefs}, pages 1--4. 2012.

\bibitem{xue2021end}
Alice Xue.
\newblock End-to-end chinese landscape painting creation using generative
  adversarial networks.
\newblock In {\em Proceedings of the IEEE/CVF Winter Conference on Applications
  of Computer Vision}, pages 3863--3871, 2021.

\bibitem{yang2013animating}
LiJie Yang and TianChen Xu.
\newblock Animating chinese ink painting through generating reproducible brush
  strokes.
\newblock {\em Science China Information Sciences}, 56(1):1--13, 2013.

\bibitem{yang2019easy}
Lijie Yang, Tianchen Xu, Jixiang Du, and Enhua Wu.
\newblock Easy drawing: Generation of artistic chinese flower painting by
  stroke-based stylization.
\newblock {\em Ieee Access}, 7:35449--35456, 2019.

\bibitem{yao2005painting}
Fenghui Yao and Guifeng Shao.
\newblock Painting brush control techniques in chinese painting robot.
\newblock In {\em ROMAN 2005. IEEE International Workshop on Robot and Human
  Interactive Communication, 2005.}, pages 462--467. IEEE, 2005.

\bibitem{yeh2002effects}
Jeng-sheng Yeh, Ting-yu Lien, and Ming Ouhyoung.
\newblock On the effects of haptic display in brush and ink simulation for
  chinese painting and calligraphy.
\newblock In {\em 10th Pacific Conference on Computer Graphics and
  Applications, 2002. Proceedings.}, pages 439--441. IEEE, 2002.

\bibitem{yeh2002non}
Jun-Wei Yeh and Ming Ouhyoung.
\newblock Non-photorealistic rendering in chinese painting of animals.
\newblock {\em Journal of System Simulation 14 (6): 1220-1224}, (1262), 2002.

\bibitem{yu2003image}
JinHui Yu, GuoMing Luo, and QunSheng Peng.
\newblock Image-based synthesis of chinese landscape painting.
\newblock {\em Journal of Computer Science and Technology}, 18(1):22--28, 2003.

\bibitem{yu2002model}
Young~Jung Yu, Young~Bok Lee, Hwan~Gue Cho, and Do~Hoon Lee.
\newblock A model based technique for realistic oriental painting.
\newblock In {\em 10th Pacific Conference on Computer Graphics and
  Applications, 2002. Proceedings.}, pages 452--453. IEEE, 2002.

\bibitem{yuan2016tunable}
Chen Yuan and Ze~Yun.
\newblock Tunable, a vr reconstruction of "listening to a guqin" from emperor
  zhao ji.
\newblock In {\em SIGGRAPH ASIA 2016 VR Showcase}, pages 1--2. 2016.

\bibitem{zhan2019}
Ying Zhan, Yan Gao, and Linyun Xie.
\newblock Aesthetic feature analysis and classification of chinese traditional
  painting.
\newblock {\em Journal of Beijing University of Aeronautics and Astronautics},
  45(12):2514--2522, 2019.

\bibitem{zhang2004modelling}
Danging Zhang, Binh Pham, and Yuefeng Li.
\newblock Modelling traditional chinese paintings for content-based image
  classification and retrieval.
\newblock In {\em 10th International Multimedia Modelling Conference, 2004.
  Proceedings.}, pages 258--264. IEEE, 2004.

\bibitem{zhang2020detail}
Fengquan Zhang, Huaming Gao, and Yuping Lai.
\newblock Detail-preserving cyclegan-adain framework for image-to-ink painting
  translation.
\newblock {\em IEEE Access}, 8:132002--132011, 2020.

\bibitem{zhang2021comprehensive}
Jiajing Zhang, Yongwei Miao, and Jinhui Yu.
\newblock A comprehensive survey on computational aesthetic evaluation of
  visual art images: Metrics and challenges.
\newblock {\em IEEE Access}, 9:77164--77187, 2021.

\bibitem{zhang2011multispectral}
Jiawan Zhang, Yi~Zhang, Shengping Zhang, Lixia Yan, and Jinyan Chen.
\newblock Multispectral image matting of ancient chinese paintings.

\bibitem{zhang1999simple}
Qing Zhang, Youetsu Sato, Jun-ya Takahashi, Kazunobu Muraoka, and Norishige
  Chiba.
\newblock Simple cellular automaton-based simulation of ink behaviour and its
  application to suibokuga-like 3d rendering of trees.
\newblock {\em The Journal of Visualization and Computer Animation},
  10(1):27--37, 1999.

\bibitem{zhang2009video}
SongHai Zhang, Tao Chen, YiFei Zhang, ShiMin Hu, and Ralph Martin.
\newblock Video-based running water animation in chinese painting style.
\newblock {\em Science in China Series F: Information Sciences},
  52(2):162--171, 2009.

\bibitem{zhao2020shadowplay2}
Zhenjie Zhao and Xiaojuan Ma.
\newblock Shadowplay2. 5d: A 360-degree video authoring tool for immersive
  appreciation of classical chinese poetry.
\newblock {\em Journal on Computing and Cultural Heritage (JOCCH)},
  13(1):1--20, 2020.

\bibitem{zheng2018strokenet}
Ningyuan Zheng, Yifan Jiang, and Dingjiang Huang.
\newblock Strokenet: A neural painting environment.
\newblock In {\em International Conference on Learning Representations}, 2018.

\bibitem{zheng2017chinese}
Wang Zheng, Li~Haoyue, Xu~Hongshan, and Sun Meijun.
\newblock Chinese painting emotion classification based onconvolution neural
  network and svm.
\newblock {\em Journal of Nanjing Normal University (Natural Science Edition)},
  2017.

\bibitem{zou2021stylized}
Zhengxia Zou, Tianyang Shi, Shuang Qiu, Yi~Yuan, and Zhenwei Shi.
\newblock Stylized neural painting.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 15689--15698, 2021.


\bibitem{openai2023gpt4}  
OpenAI.  
\newblock GPT-4 Technical Report.  
\newblock Technical report, arXiv:2303.08774, cs.CL, 2023.  

\bibitem{radford2021Learninga}  
Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, Gretchen Krueger, and Ilya Sutskever.  
\newblock Learning Transferable Visual Models From Natural Language Supervision.  
\newblock In {\em Proceedings of the 38th International Conference on Machine Learning}, pages 8748--8763, Jul. 2021, PMLR.  

\bibitem{rombach2022HighResolution}  
Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Bj{\"o}rn Ommer.  
\newblock High-Resolution Image Synthesis With Latent Diffusion Models.  
\newblock In {\em CVPR}, pages 10684--10695, 2022.  

%\end{thebibliography}




% {\footnotesize
% \bibliographystyle{plain}
% \bibliography{reference.bib}}



\end{thebibliography}

\end{multicols}
\label{last-page}
\end{document}




%\section{Introduction}

%Journal of Computer Science and Technology (JCST) is an international forum for scientists and engineers involved in all aspects of computer science and technology to publish high quality, refereed papers. It is an international research journal sponsored by Institute of Computing Technology (ICT), Chinese Academy of Sciences (CAS), and China Computer Federation (CCF). The journal is jointly published by Science Press of China and Springer on a bimonthly basis in English.

%The journal offers survey and review articles from experts in the field, promoting insight and understanding of the state of the art, and trends in technology. The contents include original research and innovative applications from all parts of the world. The journal presents mostly previously unpublished materials.

%The coverage of JCST includes computer architecture and systems, artificial intelligence and pattern recognition, computer networks and distributed computing, computer graphics and multimedia, software systems, data management and data mining, theory and algorithms, emerging areas, and more.

%Enhanced versions of papers previously published in conference proceedings may be considered provided:

%1) The version submitted to JCST has at least 30\% new kernel contribution (not including more related work, detailed experimental data, etc.) against the conference version.

%2) The conference version should be cited as a reference, and the new kernel contribution of the version submitted to JCST against the conference version should be explained explicitly in both the cover letter and the main document of the submission.

%All the authors should follow JCST's Guidelines for Authors\jz{1}{https://jcst.ict.ac.cn/EN/column/column107.shtml, May 2020.}, and especially, the authors must fulfill the Ethical Responsibilities of Authors and comply with the Referencing Guidelines.

%\section{Content}

%\subsection{Text}

%{\it Text Formatting}. Please refer to JCST Submit/Publish Template (LATEX, WORD) at:  http://jc\-st.ict.ac.cn/EN/column/column111.shtml.

%Manuscripts submitted for reviews should follow the JCST Submit Template, and those that have passed the review and are going to be accepted should use the JCST Publish Template.

%All elements of formulae should be type-written whenever possible. Use the automatic page numbering function to number the pages. Do not use field functions. Use the table function, not spreadsheets, to make tables. Save your file in TeX or LaTeX files, or docx format (Word 2007 or higher) or doc format (older Word versions). For Word files, please do use the MathType included in the Word template .rar file for equations.

%{\it Abbreviations.} Abbreviations should be defined at first mention and used consistently thereafter.

%{\it Footnotes}. Footnotes can be used to give additional information, which may include the citation of a reference included in the reference list. They should not consist solely of a reference citation, and they should never include the bibliographic details of a reference. They should also not contain any figures or tables. Footnotes to the text are numbered consecutively. Always use footnotes instead of endnotes.

%{\it Acknowledgments}. Upon acceptance of the paper, authors may add acknowledgement of people, grants, funds, etc., which should be placed in a separate section. The names of funding organizations should be written in full.

%{\it Biography and Photo}. Upon acceptance of the paper, authors will be asked to provide a short biography and a photo (with resolution = 600 dpi) of each author, to be included at the end of the manuscript.

%{\it Scientific Style}. Please always use internationally accepted signs and symbols for units (SI units).

%\subsection{References}
%\subsubsection{Citation}

%At times, it may be necessary for authors to include another author's material or to reuse portions of their own previously published work.

%When an author uses text, charts, photographs, or other graphics from another author's material, the author shall:

%1) clearly indicate reused material and provide a full reference to the origin (publication, person, etc.) of the material and

%2) obtain written permission from the publisher or, if the reused material has not been published, obtain written permission from the original source.

%When an author reuses text, charts, photographs, or other graphics from his/her own previously published material, the author shall:

%1) clearly indicate all reused material and provide a full reference to the original publication of the material and

%2) if the previously published or submitted material is used as a basis for a new submission, clearly indicate how the new submission differs from the previously published work(s).

%Reference citations in the text should be identified by numbers in square
%brackets. Some examples:

%1) Negotiation research spans many disciplines [3].

%2) This effect has been widely studied [1-3, 7].

%\subsubsection{Reference List}

%The list of references should only include articles that are cited in the text and that have been published or accepted for publication. Personal communications and unpublished work should only be mentioned in the text using footnotes to give more information. Do not use footnotes or endnotes as a substitute for a reference list.

%The references should be listed at the end of the manuscript and numbered in the order they are referred to in the text. For journals the following information should appear: names (including initials of the first names) of all authors, full title of the paper, and journal name, volume, pages and year of publication. For books the following should be listed: author(s), full title, edition, publisher, place of publication and year.

%\subsection{Tables}

%All tables are numbered using Arabic numerals in the order they are referred to in the text.

%Tables should be cited in text in consecutive numerical order. For each table, please supply a table caption (title) explaining the components of the table. Identify any previously published material by giving the original source in the form of a reference at the end of the table caption.

%Footnotes to tables should be indicated by ``Note:'' and included beneath the table body.

%\subsection{Definitions and Theorems}

%{\bf Definition 1} (Name of the Definition). {\it All definitions are numbered using Arabic numerals in the order they are presented in the text.}

%{\bf Theorem 1.}  {\it All theorems are numbered using Arabic numerals in the order they are presented in the text.}

%\begin{proof}
%Example for a proof.
%\end{proof}

%\subsection{Artwork and Illustrations Guidelines}
%\subsubsection{Electronic Figure Submission}

% $\bullet$ Supply all figures electronically.

% $\bullet$ For vector graphics, the preferred format is EPS; for halftones, please use
% TIFF format. MSOffice files are also acceptable.

% $\bullet$ Vector graphics containing fonts must have the fonts embedded in the files.

% $\bullet$ Name your figure files with ``Fig'' and the figure number, e.g., Fig1.eps.

% \subsubsection{Line Art}

% {\bf Definition 2} (Line Art). {\it Lines are black and white graphic with no shading.}

% Do not use faint lines and/or lettering and check that all lines and
% lettering within the figures are legible at final size. All lines should be
% at least 0.1 mm (0.3 pt) wide. Scanned line drawings and line drawings in
% bitmap format should have a minimum resolution of 1200 dpi. Vector graphics
% containing fonts must have the fonts embedded in the files.

% \subsubsection{Halftone Art}

% {\bf Definition 3} (Halftone Art). {\it Halftones include photographs, drawings, or paintings with fine shading, etc.}

% If any magnification is used in the photographs, indicate this by using
% scale bars within the figures themselves. Halftones should have a minimum
% resolution of 600 dpi.

% \subsubsection{Combination Art}

% {\bf Definition 4} (Combination Art). {\it Combination art is combination of halftone and line art, e.g., halftones containing line drawing, extensive lettering, color diagrams, etc. Combination artwork should have a minimum resolution of 600 dpi.}

% \subsubsection{Color Art}

% If black and white will be shown in the print version, make sure that the main information will still be visible. Many colors are not distinguishable from one another when converted to black and white. A simple way to check this is to make a xerographic copy to see if the necessary distinctions between the different colors are still apparent. If the figures will be printed in black and white, do not refer to color in the captions and text.

% Color illustrations should be submitted as RGB (8 bits per channel).

% \subsubsection{Figure Lettering}

% To add lettering, it is best to use Times New Roman. Please keep lettering consistently sized throughout your final-sized artwork, usually about 8 pt.

% Variance of type size within an illustration should be minimal, e.g., do not use 8-pt type on an axis and 20-pt type for the axis label.

% Avoid effects such as shading, outline letters, etc. Do not include titles or captions within your illustrations.

% \subsubsection{Figure Numbering}

% All figures are to be numbered using Arabic numerals in the order they are referred to in the text. Figures should always be cited in text in consecutive numerical order.

% Figure parts should be denoted by lowercase letters: (a), (b), (c), etc.

% If an appendix appears in your article and it contains one or more figures, number the appendix figures: A1, A2, A3, etc.

% \subsubsection{Figure Captions}

% Each figure should have a concise caption describing accurately what the figure depicts. Include the captions in the text file of the manuscript, not in the figure file.

% Figure captions begin with the term Fig. in bold type, followed by the figure number, also in bold type. No punctuation is to be included after the number, nor is any punctuation to be placed at the end of the caption.

% Identify all elements found in the figure in the figure caption; and use boxes, circles, etc., as coordinate points in graphs.

% Identify previously published material by giving the original source in the form of a reference citation at the end of the figure caption.

% \vspace{4mm}

% \begin{center}
% % Figure removed\\
% \vspace{3mm}
% \parbox[c]{8.3cm}{\footnotesize{Fig.1.~}  Example for inserting a one-column wide figure. }%\vspace*{.2mm}
% \end{center}

% \setcounter{figure}{1}
% % Figure environment removed
% \baselineskip=18pt plus.2pt minus.2pt
% \parskip=0pt plus.2pt minus0.2pt

% \vspace{2mm}

% \tabcolsep 12pt
% %\cmidrule(l){2-4}%
% \renewcommand\arraystretch{1.3}
% \begin{center}
% {\footnotesize{\bf Table 1.} \textcolor{red}{C}aption of \textcolor{red}{T}his \textcolor{red}{O}ne-\textcolor{red}{C}olumn \textcolor{red}{W}ide \textcolor{red}{T}able}\\
% \vspace{2mm}
% \footnotesize{
% \begin{tabular*}{\linewidth}{c}\hline\hline\hline
% \\\hline
% \\
% \\
% \\\hline\hline\hline
% \end{tabular*}%\vspace*{.2mm}
% \\\vspace{1mm}\parbox{8.3cm}{Note: You may explain the meaning of some special format, e.g., in bold, and/or give the full names of the abbreviations used in the table whose full names have not presented in the text.}
% }
% \end{center}

% \vspace{1mm}

% \setcounter{table}{1}
% \tabcolsep 9pt
% %\cmidrule(l){2-4}
% \renewcommand\arraystretch{1.3}
% \begin{table*}[!htb]
% \centering
% \caption{\label{3} \textcolor{red}{C}aption of \textcolor{red}{T}his \textcolor{red}{T}able}\vspace{-2mm}
% {\footnotesize
% \begin{tabular*}{\linewidth}{c}\hline\hline\hline
% \\\hline
% \\
% \\
% \\\hline\hline\hline
% \end{tabular*}%\vspace*{.2mm}
% %\\\vspace{1mm}\parbox{17.5cm}{}
% }
% \end{table*}
% \baselineskip=18pt plus.2pt minus.2pt
% \parskip=0pt plus.2pt minus0.2pt

% \subsubsection{Placement and Size}

% When preparing your figures, size figures to fit in the column width (one-column or two-column as needed).

% \subsubsection{Permissions}

% If you include figures that have already been published elsewhere, you must obtain permission from the copyright owner(s) for both the print and online format. Please be aware that some publishers do not grant electronic rights for free and that Springer will not be able to refund any costs that may have occurred to receive these permissions. In such cases, material from other sources should be used.

% \subsubsection{Accessibility}

% In order to give people of all abilities and disabilities access to the content of your figures, please make sure that:

% $\bullet$ All figures have descriptive captions;

% $\bullet$ Patterns are used instead of or in addition to colors for conveying
% information (colorblind users would then be able to distinguish the visual
% elements);

% $\bullet$ Any figure lettering has a contrast ratio of at least 4.5:1.

% \section{Electronic Supplementary Material}

% Springer accepts electronic multimedia files (animations, movies, audio, etc.) and other supplementary files to be published online along with an article or a book chapter. This feature can add dimension to the author's article, as certain information cannot be printed or is more convenient in electronic form.

% We encourage research data to be archived in data repositories wherever
% possible.

% \subsection{Submission}

% Please supply all supplementary material in standard file formats.

% To accommodate user downloads, please keep in mind that larger-sized files may require very long download times and that some users may experience other problems during downloading.

% {\it Audio, Video, and Animations.} Aspect ratio: 16:9 or 4:3; maximum file size: 25 GB; minimum video duration: 1 sec; supported file formats: avi, wmv, mp4, mov, m2p, mp2, mpg, mpeg, flv, mxf, mts, m4v, 3gp.

% {\it Text and Presentations.} Submit your material in PDF format; .doc or .ppt files are not suitable for long-term viability. A collection of figures may also be combined in a PDF file.

% {\it Spreadsheets}. Spreadsheets should be converted to PDF if no interaction with the data is intended. If the readers should be encouraged to make their own calculations, spreadsheets should be submitted as .xls files (MS Excel).

% {\it Specialized Formats}. Specialized format such as .pdb (chemical), .wrl (VRML), .nb (Mathematica notebook), and .tex can also be supplied.

% {\it Collecting Multiple Files}. It is possible to collect multiple files in a .rar or .gz file.

% {\it Numbering}. If supplying any supplementary material, the text must make specific mention of the material as a citation, similar to that of figures and tables. 1) Refer to the supplementary files as ``Online Resource'', e.g., "... as shown in the animation (Online Resource 3)", ``... additional data are given in Online Resource 4''. 2) Name the files consecutively, e.g. ``ESM{\_}3.mpg'', ``ESM{\_}4.pdf''.

% {\it Captions}. For each supplementary material, please supply a concise caption describing the content of the file.

% {\it Accessibility}. In order to give people of all abilities and disabilities access to the content of your supplementary files, please make sure that: 1) The manuscript contains a descriptive caption for each supplementary material. 2) Video files do not contain anything that flashes more than three times per second (so that users prone to seizures caused by such effects are not put at risk).

% \subsection{Highlight}

% Upon acceptance of the paper, authors will be asked to provide highlight of the paper. It is a short collection of information (e.g., text and graphics), in $4\sim 5$-pages PPT (with the first page presenting the title and the authors), to convey the research problem and the kernel findings, to provide readers with a quick overview of the article. The highlights describe the essence of the research (e.g., research problem, kernel contribution, results or conclusions) and highlight what is distinctive about it.

% Highlights may be displayed online in http://www.springer.com/journal/11390, but will not appear in the article PDF file or print.

% \section{After Acceptance}

% {\it Copyright Transfer}. Authors will be asked to transfer copyright of the article to the Publisher (or grant the Publisher exclusive publication and dissemination rights). This will ensure the widest possible protection and dissemination of information under copyright laws.

% {\it Proof Reading}. The purpose of the proof is to check for typesetting or conversion errors and the completeness and accuracy of the text, tables and figures. Substantial changes in content, e.g., new results, corrected values, title and authorship, are not allowed without the approval of the Editor.

% \section{Ethical Responsibilities of Authors}

% {\it Important Note}. The journal uses software to screen for plagiarism.

% The journal is committed to upholding the integrity of the scientific record. It follows the Committee on Publication Ethics (COPE) guidelines to deal with potential acts of misconduct.

% Authors should refrain from misrepresenting research results which could damage the trust in the journal, the professionalism of scientific authorship, and ultimately the entire scientific endeavour. Maintaining integrity of the research and its presentation can be achieved by following the rules of good scientific practice, which include:

% $\bullet$ The manuscript has not been submitted to more than one journal for simultaneous consideration.

% $\bullet$ The manuscript has not been published previously (partly or in full), unless the new work concerns an expansion of previous work (please provide transparency on the re-use of material to avoid the hint of text-recycling (``self-plagiarism'')).

% $\bullet$ A single study is not split up into several parts to increase the quantity of submissions and submitted to various journals or to one journal over time (e.g. ``salami-publishing'').

% $\bullet$ No data have been fabricated or manipulated (including images) to support your conclusions

% $\bullet$ No data, text, or theories by others are presented as if they were the author's own (``plagiarism''). Proper acknowledgements to other works must be given (this includes material that is closely copied (near verbatim), summarized and/or paraphrased), quotation marks are used for verbatim copying of material, and permissions are secured for material that is copyrighted.

% $\bullet$ Consent to submit has been received explicitly from all co-authors, as well as from the responsible authorities --- tacitly or explicitly --- at the institute/organization where the work has been carried out, before the work is submitted.

% $\bullet$ Authors whose names appear on the submission have contributed sufficiently to the scientific work and therefore share collective responsibility and accountability for the results.

% $\bullet$ Authors are strongly advised to ensure the correct author group, corresponding author, and order of authors at submission. Changes of authorship or in the order of authors are not accepted after acceptance of a manuscript.

% $\bullet$ Adding and/or deleting authors at revision stage may be justifiably warranted. A letter must accompany the revised manuscript to explain the role of the added and/or deleted author(s). Further documentation may be required to support your request.

% $\bullet$ Upon request authors should be prepared to send relevant documentation or data in order to verify the validity of the results. This could be in the form of raw data, samples, records, etc. Sensitive information in the form of confidential proprietary data is excluded.

% If there is a suspicion of misconduct, the journal will carry out an investigation following the COPE guidelines. If, after investigation, the allegation seems to raise valid concerns, the accused author will be contacted and given an opportunity to address the issue. If misconduct has been established beyond reasonable doubt, this may result in the Editor-in-Chief's implementation of the following measures, including, but not limited to:

% $\bullet$ If the article is still under consideration, it may be rejected and returned
% to the author.

% $\bullet$ If the article has already been published online, depending on the nature
% and severity of the infraction, either an erratum will be placed with the
% article or in severe cases complete retraction of the article will occur.
% The reason must be given in the published erratum or retraction note. Please
% note that retraction means that the paper is maintained on the platform,
% watermarked "retracted" and explanation for the retraction is provided in a
% note linked to the watermarked article.

% $\bullet$ The author's institution may be informed.

% \section{English Language Editing}

% For editors and reviewers to accurately assess the work presented in your manuscript you need to ensure the English language is of sufficient quality to be understood. If you need help with writing in English you should consider:

% $\bullet$ asking a colleague who is a native English speaker to review your manuscript for clarity;

% $\bullet$ visiting the English language tutorial which covers the common mistakes when writing in English;

% $\bullet$ using a professional language editing service where editors will improve the English to ensure that your meaning is clear and  identify problems that require your review.

% Please note that the use of a language editing service is not a requirement for publication in this journal and does not imply or guarantee that the article will be selected for peer review or accepted.

% If your manuscript is accepted it will be checked by our editors for spelling and formal style before publication.

% \section{[\textcolor{blue}{last section}] Conclusions}

% Although a conclusion may review the main points of the paper, do not replicate the abstract as the conclusion. A conclusion might elaborate on the importance and results of the work, and/or suggest applications and extensions.

% \vspace{2mm}

% [\textcolor{blue}{The references should be listed at the end of the manuscript and numbered in the order they are referred to in the text.}]



\begin{thebibliography}{99}
\footnotesize
\itemsep=-3pt plus.2pt minus.2pt
\baselineskip=13pt plus.2pt minus.2pt
\bibitem{1}Sayah J Y, Kime C R. Test scheduling in high performance VLSI system implementations. {\it IEEE Trans. Computers}, 1992, 41(1): 52-67. [\textcolor{blue}{example for journal paper}]

\bibitem{2} Gordon Plotkin. A semantics for type checking. In {\it Lecture Notes in Computer Science 526,} Ito T, Meyer A R (eds.), Springer-Verlag, 1991, pp.1-17. [\textcolor{blue}{example for book chapter}]

\bibitem{3} Geddes K O, Czapor S R, Labahn G. Algorithms for Computer Algebra. Boston: Kluwer, 1992. [\textcolor{blue}{example for book}]

\bibitem{4} Kwan A W, Bic L. Distributed memory computers. In {\it Proc. the 6th Int. Parallel Processing Symp.}, March 1992, pp.10-17. [\textcolor{blue}{example for conference}]

\bibitem{5} Harris M J. Real-time cloud simulation and rendering [Ph.D. Thesis]. Department of Computer Science, The University of North Carolina at Chapel Hill, 2003. [\textcolor{blue}{example for thesis}]

\bibitem{6} Jurczyk M, Coldwind G. Identifying and ex-ploiting windows kernel race conditions via mem-ory access patterns. Technical Report, Google Re-search, 2013. http://pdfs.semanticscholar.org/ca60/2e7193f159a56a3559-f08b677abfba60beb2.pdf, Mar. 2018. [\textcolor{blue}{example for technical report}]

\bibitem{7} Gipp B, Meuschke N, Gernandt A. Decentra-lized trusted timestamping using the crypto cur-rency Bitcoin. arXiv:1502.04015, 2015. https://arxiv.org/abs/1502.04015, May. 2018. [\textcolor{blue}{example for ar-Xiv document}]

\bibitem{8} Tong Y, Chen L, Zhou Z, JagadishH V, Shou L, Lv W. SLADE: A smart large-scale task decomposer in crowdsourcing. {\it IEEE Transactions on Knowledge and Data Engineering}. doi:10.1109/TKDE.2018.2797962. (preprint) [\textcolor{blue}{example for preprint}]

\end{thebibliography}

\label{last-page}
\end{multicols}
\label{last-page}
\end{document}

