\documentclass{article}

% if you need to pass options to natbib, use, e.g.:
     \PassOptionsToPackage{sort,numbers}{natbib}
% before loading neurips_2023

% ready for submission
%\usepackage{neurips_2023}

% to compile a preprint version, e.g., for submission to arXiv, add add the
% [preprint] option:
\usepackage[preprint]{neurips_2023}


% to compile a camera-ready version, add the [final] option, e.g.:
%     \usepackage[final]{neurips_2023}


% to avoid loading the natbib package, add option nonatbib:
%    \usepackage[nonatbib]{neurips_2023}


\usepackage[colorlinks=true,breaklinks=true,bookmarks=false,citecolor=green]{hyperref}       % hyperlinks
\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{amssymb}     
\usepackage{amsmath}     
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{xcolor}         % colors
\usepackage{bm}     
\usepackage{xfrac} 
\usepackage{array}
\usepackage{makecell}
\usepackage{multirow}
\usepackage{wrapfig}
\usepackage{enumitem}

%-------------------------width of table----------------------------
\newcommand{\PreserveBackslash}[1]{\let\temp=\\#1\let\\=\temp}
\newcolumntype{C}[1]{>{\PreserveBackslash\centering}p{#1}}
\newcolumntype{R}[1]{>{\PreserveBackslash\raggedleft}p{#1}}
\newcolumntype{L}[1]{>{\PreserveBackslash\raggedright}p{#1}}

\newcommand{\jy}[1]{{\color{magenta}(jianyi: {#1})}} % cavan's comments


\title{ResShift: Efficient Diffusion Model for Image Super-resolution by Residual Shifting}
%\title{\mbox{Customized Diffusion Model for Image Super-resolution} \\ by Residual Shifting}

% The \author macro works with any number of authors. There are two commands
% used to separate the names and addresses of multiple authors: \And and \AND.
%
% Using \And between authors leaves it to LaTeX to determine where to break the
% lines. Using \AND forces a line break at that point. So, if LaTeX puts 3 of 4
% authors names on the first line, and the last on the second line, try using
% \AND instead of \And before the third author name.

\author{%
  Zongsheng Yue ~ ~ Jianyi Wang ~ ~ Chen Change Loy \\
  S-Lab, Nanyang Technological University \\
  \texttt{zsyzam@gmail.com}, \texttt{\{jianyi001,ccloy\}}@ntu.edu.sg \\
  % David S.~Hippocampus\thanks{Use footnote for providing further information
  %   about author (webpage, alternative address)---\emph{not} for acknowledging
  %   funding agencies.} \\
  % Department of Computer Science\\
  % Cranberry-Lemon University\\
  % Pittsburgh, PA 15213 \\
  % \texttt{hippo@cs.cranberry-lemon.edu} \\
  % examples of more authors
  % \And
  % Coauthor \\
  % Affiliation \\
  % Address \\
  % \texttt{email} \\
  % \AND
  % Coauthor \\
  % Affiliation \\
  % Address \\
  % \texttt{email} \\
  % \And
  % Coauthor \\
  % Affiliation \\
  % Address \\
  % \texttt{email} \\
  % \And
  % Coauthor \\
  % Affiliation \\
  % Address \\
  % \texttt{email} \\
}


\begin{document}


\maketitle

\begin{abstract}
    Diffusion-based image super-resolution (SR) methods are mainly limited by the low inference speed due to the requirements of hundreds or even thousands of sampling steps. Existing acceleration sampling techniques inevitably sacrifice performance to some extent, leading to over-blurry SR results.
    %This is particularly problematic in SR, where such techniques often produce over-blurry results, deviating from the goal of SR.
    To address this issue, we propose a novel and efficient diffusion model for SR that significantly reduces the number of diffusion steps, thereby eliminating the need for post-acceleration during inference and its associated performance deterioration. Our method constructs a Markov chain that transfers between the high-resolution image and the low-resolution image by shifting the residual between them, substantially improving the transition efficiency. Additionally, an elaborate noise schedule is developed to flexibly control the shifting speed and the noise strength during the diffusion process.
    Extensive experiments demonstrate that the proposed method obtains superior or at least comparable performance to current state-of-the-art methods on both synthetic and real-world datasets, \textit{\textbf{even only with 15 sampling steps}}. 
    Our code and model are available at \url{https://github.com/zsyOAOA/ResShift}.
\end{abstract}

%-------------------------------------------------------
\section{Introduction}
Image super-resolution (SR) is a fundamental problem in low-level vision, aiming at recovering the high-resolution (HR) image given the low-resolution (LR) one. This problem is severely ill-posed due to the complexity and unknown nature of degradation models in real-world scenarios. Recently, diffusion model~\cite{sohl2015deep,ho2020denoising}, a newly emerged generative model, has achieved unprecedented success in image generation ~\cite{dhariwal2021diffusion}. Furthermore, it has also demonstrated great potential in solving several downstream low-level vision tasks, including image editing~\cite{meng2021sdedit,avrahami2022blended}, image inpainting~\cite{Lugmayr2022repaint,chung2022come}, image colorization~\cite{song2021scorebased,saharia2022palette}. 
%
%As a classical yet challenging problem, how to leverage diffusion model to address the SR task still remains an active area of research.
%
There is also ongoing research exploring the potential of diffusion models to tackle the long-standing and challenging SR task.

%In recent years, the SR problem has been tackled using the diffusion model in various works. 
One common approach~\cite{saharia2022image,rombach2022high} involves inserting the LR image into the input of current diffusion model (e.g., DDPM~\cite{ho2020denoising}) and retraining the model from scratch on the training data for SR. 
%After training, this model can recover the desirable HR image from the Gaussian noise step by step.
Another popular way~\cite{Choi2021ILVR,chung2022come,yue2022difface} is to use an unconditional pre-trained diffusion model as a prior and modify its reverse path to generate the expected HR image. Unfortunately, both strategies inherit the Markov chain underlying DDPM, which can be inefficient in inference, often taking hundreds or even thousands of sampling steps. 
%
Although some acceleration techniques~\cite{nichol2021improved,song2021denoising,lu2022dpmsolver} have been developed to compress the sampling steps in inference, they inevitably lead to a significant drop in performance, resulting in over-smooth results as shown in Fig.~\ref{fig:compare_ldm}, in which the DDIM~\cite{song2021denoising} algorithm is employed to speed up the inference. Thus, there is a need to design a new diffusion model for SR that achieves both efficiency and performance, without sacrificing one for the other.

% Figure environment removed

Let us revisit the diffusion model in the context of image generation. In the forward process, it builds up a Markov chain to gradually transform the observed data into a pre-specified prior distribution, typically a standard Gaussian distribution, over a large number of steps. Subsequently, image generation can be achieved by sampling a noise map from the prior distribution and feeding it into the reverse path of the Markov chain.  While the Gaussian prior is well-suited for the task of image generation, it may not be optimal for SR, where the LR image is available. 
In this paper, we argue that the reasonable diffusion model for SR should starts from a prior distribution based on the LR image, enabling an iterative recovery of the HR image from its LR counterpart instead of a Gaussian white noise. Additionally, such a design can also reduce the number of diffusion steps required for sampling and thereby improve the inference efficiency.

Following the aforementioned motivation, we propose an efficient diffusion model involving a shorter Markov chain for transitioning between the HR image and its corresponding LR one. The initial state of the Markov chain converges to an approximate distribution of the HR image, while the final state converges to an approximate distribution of the LR image. To achieve this, we carefully design a transition kernel that shifts the residual between them step by step. 
This approach is more efficient than existing diffusion-based SR methods since the residual information can be quickly transferred in dozens of steps. Moreover, our design also allows for an analytical and concise expression for the evidence lower bound, thereby easing the induction of the optimization objective for training.
Based on this constructed diffusion kernel, we further develop a highly flexible noise schedule that controls the shifting speed of the residual and the noise strength in each step. This schedule facilitates a fidelity-realism trade-off of the recovered results by tuning its hyper-parameters.

In summary, the main contributions of this work are as follows:
\begin{itemize}[topsep=0pt,parsep=0pt,leftmargin=18pt]
    \item We present an efficient diffusion model for SR, which renders an iterative sampling procedure from the LR image to the desirable HR one by shifting the residual between them during inference. 
    %It builds up a short Markov chain between the HR and the LR images, rendering a fast sampling process from the LR image to the desirable HR one during inference. 
    Extensive experiments demonstrate the superiority of our approach in terms of efficiency, as it requires only 15 sampling steps to achieve appealing results, outperforming or at least being comparable to current diffusion-based SR methods that require a long sampling process.
    A preview of our recovered results compared with existing methods is shown in Fig.~\ref{fig:compare_ldm}.
    \item We formulate a highly flexible noise schedule for the proposed diffusion model, enabling more precise control on the shifting of residual and noise levels during the transition.     
\end{itemize}


%-------------------------------------------------------
\section{Methodology}\label{sec:method}
In this section, we present a diffusion model, \textit{ResShift}, which is tailored for SR. For ease of presentation, the LR image and the HR image are denoted as $\bm{y}_0$ and $\bm{x}_0$, respectively. Furthermore, we assume $\bm{y}_0$ and $\bm{x}_0$ have identical spatial resolution, which can be easily achieved through pre-upsampling the LR image $\bm{y}_0$ using nearest neighbor interpolation if necessary.

\subsection{Model Design}
The iterative generation paradigm of diffusion models has proven highly effective at capturing complex distributions, inspiring us to approach the SR problem iteratively as well. Our proposed method constructs a Markov chain that serves as a bridge between the HR and LR images. This way, the SR task can be accomplished by reverse sampling from this Markov chain given any LR image. Next, we will detail the process of building such a Markov chain specifically for SR.

\noindent\textbf{Forward Process}. Let's denote the residual between the LR and HR images as $\bm{e}_0$, i.e., $\bm{e}_0=\bm{y}_0-\bm{x}_0$. Our core idea is to transit from $\bm{x}_0$ to $\bm{y}_0$ by gradually shifting their residual $\bm{e}_0$ through a Markov chain with length $T$. A shifting sequence $\{\eta_t\}_{t=1}^T$ is first introduced, which monotonically increases with the timestep $t$ and satisfies $\eta_1 \to 0$ and $\eta_T \to 1$. The transition distribution is then formulated based on this shifting sequence as follows:
\begin{equation}
    q(\bm{x}_t|\bm{x}_{t-1},\bm{y}_0) = \mathcal{N}(\bm{x}_t; \bm{x}_{t-1}+\alpha_t \bm{e}_0, \kappa^2 \alpha_t \bm{I}), ~ t=1,2,\cdots,T,
    \label{eq:transit_t_t1}
\end{equation}
where $\alpha_t=\eta_t-\eta_{t-1}$ for $t>1$ and $\alpha_1=\eta_1$, $\kappa$ is a hyper-parameter controlling the noise variance, $\bm{I}$ is the identity matrix. Notably, we show that the marginal distribution at any timestep $t$ is analytically integrable, namely
\begin{equation}
    q(\bm{x}_t|\bm{x}_0, \bm{y}_0) = \mathcal{N}(\bm{x}_t; \bm{x}_0+\eta_t \bm{e}_0, \kappa^2 \eta_t \bm{I}), ~ t=1,2,\cdots,T.
    \label{eq:transit_0_t}
\end{equation}

The design of the transition distribution presented in Eq.~\eqref{eq:transit_t_t1} is based on two primary principles. The first principle concerns the standard deviation, i.e., $\kappa\sqrt{\alpha_t}$, which aims to facilitate a smooth transition between $\bm{x}_t$ and $\bm{x}_{t-1}$. This is because the expected distance between $\bm{x}_t$ and $\bm{x}_{t-1}$ can be bounded by $\sqrt{\alpha_t}$, given that the image data falls within the range of $[0, 1]$, i.e.,
\begin{equation}
    \text{max}[(\bm{x}_0+\eta_t\bm{e}_0)-(\bm{x}_0+\eta_{t-1}\bm{e}_0)] = \text{max}[\alpha_t\bm{e}_0]<\alpha_t<\sqrt{\alpha_t},
    \label{eq:var_bound}
\end{equation}
where $\text{max}[\cdot]$ represents the pixel-wise maximizing operation. The hyper-parameter $\kappa$ is introduced to increase the flexibility of this design.
The second principle pertains to the mean parameter, i.e., $\bm{x}_0+\alpha_t\bm{e}_0$, which induces the marginal distribution in Eq.~\eqref{eq:transit_0_t}. Furthermore, the marginal distributions of $\bm{x}_1$ and $\bm{x}_T$ converges to $\delta_{\bm{x}_0}(\cdot)$\footnote{$\delta_{\bm{\mu}}(\cdot)$ denotes the Dirac distribution centered at $\bm{\mu}$.} and $\mathcal{N}(\cdot;\bm{y}_0, \kappa^2\bm{I})$, which act as two approximate distributions for the HR image and the LR image, respectively. By constructing the Markov chain in such a thoughtful way, it is possible to handle the SR task by inversely sampling from it given the LR image $\bm{y}_0$.

\noindent\textbf{Reverse Process}. The reverse process aims to estimate the posterior distribution $p(\bm{x}_0|\bm{y}_0)$ via the following formulation:
\begin{equation}
    p(\bm{x}_0|\bm{y}_0)=\int p(\bm{x}_T|\bm{y}_0)\prod_{t=1}^T p_{\bm{\theta}}(\bm{x}_{t-1}|\bm{x}_t,\bm{y}_0) \mathrm{d}\bm{x}_{1:T},
    \label{eq:poster_inverse}
\end{equation}
where $p(\bm{x}_T|\bm{y}_0) \approx \mathcal{N}(\bm{x}_T|\bm{y}_0, \kappa^2\bm{I})$, $p_{\bm{\theta}}(\bm{x}_{t-1}|\bm{x}_t,\bm{y}_0)$ is the inverse transition kernel from $\bm{x}_t$ to $\bm{x}_{t-1}$ with a learnable parameter $\bm{\theta}$. Following most of the literature in diffusion model~\cite{sohl2015deep,ho2020denoising,song2021scorebased}, we adopt the assumption of $p_{\bm{\theta}}(\bm{x}_{t-1}|\bm{x}_t,\bm{y}_0)=\mathcal{N}(\bm{x}_{t-1};\bm{\mu}_{\bm{\theta}}(\bm{x}_t, \bm{y}_0, t), \bm{\Sigma}_{\bm{\theta}}(\bm{x}_t, \bm{y}_0, t))$. The optimization for $\bm{\theta}$ is achieved by minimizing the negative evidence lower bound, namely, 
\begin{equation}
    \min_{\bm{\theta}}\sum_t D_{\text{KL}}\left[q(\bm{x}_{t-1}|\bm{x}_t,\bm{x}_0, \bm{y}_0)\Vert p_{\bm{\theta}}(\bm{x}_{t-1}|\bm{x}_t,\bm{y}_0)\right],
    \label{eq:elbo}
\end{equation}
where $D_{\text{KL}}[\cdot\Vert\cdot]$ denotes the Kullback-Leibler (KL) divergence. More mathematical details can be found in~\citet{sohl2015deep} or \citet{ho2020denoising}.

Combining Eq.~\eqref{eq:transit_t_t1} and Eq.~\eqref{eq:transit_0_t}, the targeted distribution $q(\bm{x}_{t-1}|\bm{x}_t,\bm{x}_0,\bm{y}_0)$ in Eq.~\eqref{eq:elbo} can be rendered tractable and expressed in an explicit form given below:
\begin{equation}
    q(\bm{x}_{t-1}|\bm{x}_t,\bm{x}_0,\bm{y}_0)=\mathcal{N}\left(\bm{x}_{t-1}\bigg\vert\frac{\eta_{t-1}}{\eta_t}\bm{x}_t+\frac{\alpha_t}{\eta_t}\bm{x}_0, 
    \kappa^2\frac{\eta_{t-1}}{\eta_t}\alpha_t\bm{I}\right).
    \label{eq:poster_elbo}
\end{equation}
The detailed calculation of this derivation is presented in Appendix~\ref{sec:mathcmatic_supp}. Considering that the variance parameter is independent of $\bm{x}_t$ and $\bm{y}_0$, we thus set $\bm{\Sigma}_{\bm{\theta}}(\bm{x}_t,\bm{y}_0,t)=\kappa^2\frac{\eta_{t-1}}{\eta_t}\alpha_t\bm{I}$. As for the mean parameter $\bm{\mu}_{\bm{\theta}}(\bm{x}_t,\bm{y}_0,t)$, it is reparameterized as follows:
\begin{equation}
    \bm{\mu}_{\bm{\theta}}(\bm{x}_t,\bm{y}_0,t) = \frac{\eta_{t-1}}{\eta_t}\bm{x}_t+\frac{\alpha_t}{\eta_t}f_{\bm{\theta}}(\bm{x}_t,\bm{y}_0,t),
    \label{eq:repqrameter_mean_reparameter}
\end{equation}
where $f_{\bm{\theta}}$ is a deep neural network with parameter $\bm{\theta}$, aiming to predict $\bm{x}_0$.  We explored different parameterization forms on $\bm{\mu}_{\theta}$ and found that  Eq.~\eqref{eq:repqrameter_mean_reparameter} exhibits superior stability and performance. %The comparison results are provided in the supplementary material.

Based on Eq.~\eqref{eq:repqrameter_mean_reparameter}, we simplify the objective function in Eq.~\eqref{eq:elbo} as follows,
\begin{equation}
    \min_{\bm{\theta}} \sum\nolimits_t w_t \Vert f_{\bm{\theta}}(\bm{x}_t, \bm{y}_0, t) - \bm{x}_0 \Vert_2^2,
    \label{eq:loss_l2}
\end{equation}
where $w_t = \frac{\alpha_t}{2\kappa^2\eta_t\eta_{t-1}}$. In practice, we empirically find that the omission of weight $w_t$ results in an evident improvement in performance, which aligns with the conclusion in~\citet{ho2020denoising}.

\noindent\textbf{Extension to Latent Space}. To alleviate the computational overhead in training, we move the aforementioned model into the latent space of VQGAN~\cite{esser2021taming}, where the original image is compressed by a factor of four in spatial dimensions. This does not require any modifications on our model other than substituting $\bm{x_0}$ and $\bm{y}_0$ with their latent codes.

% Figure environment removed

\subsection{Noise Schedule}\label{subsec:noise_schedule}
The proposed method employs a hyper-parameter $\kappa$ and a shifting sequence $\{\eta_t\}_{t=1}^{T}$ to determine the noise schedule in the diffusion process. Specifically, the hyper-parameter $\kappa$ regulates the overall noise intensity during the transition, and its impact on performance is empirically discussed in Sec.~\ref{subsec:exp_model_analysis}. The subsequent exposition mainly revolves around the construction of the shifting sequence $\{\eta_t\}_{t=1}^{T}$.

Equation~\eqref{eq:transit_0_t} implies that the noise level in state $\bm{x}_t$ is proportional to $\sqrt{\eta_t}$ with a scaling factor $\kappa$. This observation motivates us to focus on designing $\sqrt{\eta_t}$ instead of $\eta_t$. \citet{song2019generative} show that $\kappa\sqrt{\eta_1}$ should be sufficiently small (e.g., 0.04 in LDM~\cite{rombach2022high}) to ensure that $q(\bm{x}_1|\bm{x}_0,\bm{y}_0)\approx q(\bm{x}_0)$. Combining with the additional constraint of $\eta_1 \to 0$, we set $\eta_1$ to be the minimum value between $(\sfrac{0.04}{\kappa})^2$ and $0.001$. For the final step $T$, we set $\eta_T$ as 0.999 ensuring $\eta_T \to 1$. For the intermediate timesteps, i.e., $t \in [2, T-1]$, we propose a non-uniform geometric schedule for $\sqrt{\eta_t}$ as follows:
\begin{equation}
    \sqrt{\eta_t} = \sqrt{\eta_1} \times b_0^{\beta_t},~ t=2,\cdots,T-1,
    \label{eq:eta_schedule}
\end{equation}
where
\begin{equation}
   \beta_t = \left(\frac{t-1}{T-1}\right)^p \times  (T-1), 
   ~ b_0=\exp\left[\frac{1}{2(T-1)}\log{\frac{\eta_T}{\eta_1}}\right].
   \label{eq:hyper_schedule}
\end{equation}
Note that the choice of $\beta_t$ and $b_0$ is based on the assumption of $\beta_1=0$, $\beta_T=T-1$, and $\sqrt{\eta_T} = \sqrt{\eta_1} \times b_0^{T-1}$. The hyper-parameter $p$ controls the growth rate of $\sqrt{\eta_t}$ as shown in Fig.~\ref{fig:schedule}(h).

The proposed noise schedule exhibits high flexibility in three key aspects. First, for small values of $\kappa$, the final state $\bm{x}_T$ converges to a perturbation around the LR image as depicted in Fig.~\ref{fig:schedule}(c)-(d). Compared to the corruption ended at Gaussian noise, this design considerably shortens the length of the Markov chain, thereby improving the inference efficiency. Second, the hyper-parameter $p$ provides precise control over the shifting speed, enabling a fidelity-realism trade-off in the SR results as analyzed in Sec.~\ref{subsec:exp_model_analysis}. Third, by settings $\kappa=40$ and $p=0.8$, our method achieves a diffusion process remarkably similar to LDM~\cite{rombach2022high}. This is clearly demonstrated by the visual results during the diffusion process presented in Fig.~\ref{fig:schedule}(e)-(f), and further supported by the comparisons on the relative noise strength as shown in Fig.~\ref{fig:schedule}(g).

%-------------------------------------------------------
\section{Related Work}
\textbf{Diffusion Model}. 
Inspired by the non-equilibrium statistical physics, \citet{sohl2015deep} firstly proposed the diffusion model to fit complex distributions. \citet{ho2020denoising} built up a novel connection between diffusion model and the denoising scoring matching. Later, \citet{song2021scorebased} proposed a unified framework to formulate the diffusion model from the perspective of stochastic differential equation (SDE). Attributed to its robust theoretical foundation, the diffusion model has achieved impressive success in the generation of images~\citep{dhariwal2021diffusion,rombach2022high}, audio~\citep{chen2020wavegrad}, graph~\citep{niu20permutation} and shapes~\citep{cai2020learning}.

\textbf{Image Super-Resolution}.
Traditional image SR methods primarily focus on designing more rational image priors based on our subjective knowledge, such as non-local similarity~\cite{dong2012nonlocally}, low-rankness~\cite{gu2017weighted}, sparsity~\cite{dong2011image,gu2015convolutional}, and so on. With the development of deep learning (DL), \citet{dong2015image} proposed the seminal work SRCNN to solve the SR task using deep neural network. Then DL-based SR methods rapidly dominated the research field. Various SR technologies were explored from different perspectives, including network architecture~\cite{shi2016real,zhang2017beyond,lai2017deep,haris2018deep}, image prior~\cite{liang2021flow,chan2021glean,pan2021exploiting,yue2022blind}, deep unfolding~\cite{zhang2019deep,zhang2020deep,fu2022kxnet}, degradation model~\cite{zhang2018learning,zhang2021designing,wang2021real,mou2022metric}.
%Early image SR methods \cite{} are mainly trained on synthetic data with a pre-defined degradation process, e.g., bicubic downsampling and blurring with known parameters.
%Though effective on synthetic data with the same degradation, these methods deteriorate significantly under real-world scenarios due to limited generalizability.
%To facilitate real-world applications, recent works \cite{} turn to focus on more challenging blind SR where the degradation is unknown and similar to real-world scenarios.
%Due to the lack of real-world paired data, some methods \cite{} propose to learn an implicit degradation model from LR images in an unsupervised manner.
%Besides unsupervised learning, recent approaches \cite{} achieve supervised learning by introducing effective degradation pipelines which can resemble real-world degradation.

Recently, some works have investigated the application of diffusion models in SR. A prevalent approach is to concatenate the LR image with the noise in each step and retrain the diffusion model from scratch~\cite{li2022srdiff,saharia2022image,rombach2022high}. Another popular way is to utilize an unconditional pre-trained diffusion model as a prior and incorporate additional constraint to guide the reverse process~\cite{Choi2021ILVR,chung2022come,kawar2022denoising,yue2022difface}. Both strategies often require hundreds or thousands of sampling steps to generate a realistic HR image. While several acceleration algorithms~\cite{nichol2021improved,song2021denoising,lu2022dpmsolver} have been proposed, they typically sacrifice the performance and result in blurry outputs. This work designs a more efficient diffusion model that overcomes this trade-off between efficiency and performance, as detailed in Sec.~\ref{sec:method}.

\textbf{Remark}. Several parallel works~\cite{delbracio2023inversion,luo2023image,liu2023I2} also exploit such an iterative restoration paradigm in SR. 
Despite a similar motivation, different mathematical formulations have been adopted to achieve this goal by our work and others. 
\citet{delbracio2023inversion} employed the Inversion by Direct Iteration (InDI) to model this process, while \citet{luo2023image} and \citet{liu2023I2} attempted to formulate it as a SDE. In this paper, we design a discrete Markov chain to depict the transition between the HR image and the LR image, offering a more intuitive and efficient solution to this problem.

\begin{table}[t]
    \centering
    \caption{Performance comparison of \textit{ResShift} on the \textit{ImageNet-Test} under different configurations.}
    \label{tab:schedules}
    \small
    \vspace{-2mm}
    \begin{tabular}{@{}C{1.6cm}@{}|@{}C{1.6cm}@{}|@{}C{1.6cm}@{}|
                    @{}C{1.6cm}@{} @{}C{1.8cm}@{} @{}C{1.8cm}@{} @{}C{2.0cm}@{} @{}C{2.0cm}@{}
                    }
         \Xhline{0.8pt}
         \multicolumn{3}{c|}{Configurations} & \multicolumn{5}{c}{Metrics} \\
         \Xhline{0.4pt}
         $T$ & $p$ & $\kappa$ & PSNR$\uparrow$ & SSIM$\uparrow$ & LPIPS$\downarrow$ & CLIPIQA$\uparrow$ & MUSIQ$\uparrow$ \\
         \Xhline{0.4pt}  
         10   & \multirow{5}*{0.3} & \multirow{5}*{2.0} & 25.20 & 0.6828 & 0.2517 & 0.5492 & 50.6617 \\
         15   &                    &                    & 25.01 & 0.6769 & 0.2312 & 0.5922 & 53.6596 \\
         30   &                    &                    & 24.52 & 0.6585 & 0.2253 & 0.6273 & 55.7904  \\
         40   &                    &                    & 24.29 & 0.6513 & 0.2225 & 0.6468 & 56.8482 \\
         50   &                    &                    & 24.22 & 0.6483 & 0.2212 & 0.6489 & 56.8463 \\
        \hline \hline
        \multirow{5}*{15} & 0.3    & \multirow{5}*{2.0} & 25.01 & 0.6769 & 0.2312 & 0.5922 & 53.6596 \\
                          & 0.5    &                    & 25.05 & 0.6745 & 0.2387 & 0.5816 & 52.4475 \\
                          & 1.0    &                    & 25.12 & 0.6780 & 0.2613 & 0.5314 & 48.4964 \\
                          & 2.0    &                    & 25.32 & 0.6827 & 0.3050 & 0.4601 & 43.3060 \\
                          & 3.0    &                    & 25.39 & 0.5813 & 0.3432 & 0.4041 & 38.5324 \\
        \hline \hline
        \multirow{6}*{15} & \multirow{5}*{0.3} & 0.5    & 24.90 & 0.6709 & 0.2437 & 0.5700 & 50.6101 \\
                          &                    & 1.0    & 24.84 & 0.6699 & 0.2354 & 0.5914 & 52.9933 \\
                          &                    & 2.0    & 25.01 & 0.6769 & 0.2312 & 0.5922 & 53.6596 \\
                          &                    & 8.0    & 25.31 & 0.6858 & 0.2592 & 0.5231 & 49.3182 \\
                          &                    & 16.0   & 24.46 & 0.6891 & 0.2772 & 0.4898 & 46.9794 \\
         \Xhline{0.4pt}
    \end{tabular}   
    \vspace{-2mm}
\end{table}
% Figure environment removed

%-------------------------------------------------------
\section{Experiments}
This section presents an empirical analysis of the proposed \textit{ResShift} and provides extensive experimental results to verify its effectiveness on one synthetic dataset and three real-world datasets. Following~\cite{zhang2021designing,wang2021real}, our investigation specifically focuses on the more challenging $\times4$ SR task.

\subsection{Experimental Setup}
\textbf{Training Details}. HR images with a resolution of $256\times 256$ in our training data are randomly cropped from the training set of ImageNet~\cite{deng2009imagenet} following LDM~\cite{rombach2022high}. We synthesize the LR images using the degradation pipeline of RealESRGAN~\cite{wang2021real}. The Adam~\cite{kingma2015adam} algorithm  with the default settings of PyTorch~\cite{paszke2019pytorch} and a mini-batch size of 64 is used to train \textit{ResShift}. During training, we use a fixed learning rate of $5\text{e-}5$ and update the weight parameters for 500K iterations. As for the network architecture, we simply employ the UNet structure in DDPM~\cite{ho2020denoising}. To increase the robustness of \textit{ResShift} to arbitrary image resolution, we replace the self-attention layer in UNet with the Swin Transformer~\cite{liu2021swin} block.  

\textbf{Testing Datasets}. We synthesize a testing dataset based on the commonly-used degradation model, i.e., $\bm{y} = (\bm{x}*\bm{k})\downarrow + \bm{n}$, where $k$ is the blurring kernel, $n$ is the noise,  $\bm{y}$ and $\bm{x}$ denote the LR image and HR image, respectively. To comprehensively evaluate the performance of \textit{ResShift}, we consider more complicated types of blurring kernels, downsampling operators, and noise types. The detailed settings on them can be found in Appedix~\ref{subsec:degradation_app}. For the HR images, we randomly selected 3,000 ones from the validation set of ImageNet~\cite{deng2009imagenet} instead of the prevalent datasets in SR, e.g., \textit{Set5}~\cite{bevilacqua2012low}, \textit{Set14}~\cite{zeyde2012single}, and \textit{Urban100}~\cite{huang2015single}. That's because these datasets only contain few number of source images, which fails to throughly evaluate the performance of various methods under different degradation types. We name this dataset as \textit{ImageNet-Test} for convenience. 

% To comprehensively analyze and evaluate the performance of \textit{ResShift}, we generate a synthetic dataset containing 3,000 images from the validation set of ImageNet~\cite{deng2009imagenet}, and name it as \textit{ImageNet-Test}. The LR/HR image pairs are synthesized with the commonly-used degradation model but involve multiple types of blurring kernels, downsampling operators, and noise as follows: 
% \begin{equation}
%     \bm{y} = (\bm{x}*\bm{k})\downarrow + \bm{n},
% \end{equation}
% where $\bm{y}$ and $\bm{x}$ denote the LR image and HR image, respectively. We randomly sample the blurring kernel $\bm{k}$ from the Gaussian, generalized Gaussian, and plateau-shaped kernels. The area, bilinear, and bicubic interpolation methods are uniformly employed to downsample the images. As for the noise $\bm{n}$, we consider Gaussian noise, Poisson noise, and JPEG compression noise. 

Two real-world datasets are adopted to evaluate the efficacy of \textit{ResShift}. The first is \textit{RealSR}~\cite{cai2019toward}, containing 100 real images captured by Canon 5D3 and Nikon D810 cameras. 
%The second dataset, \textit{DRealSR}~\cite{wei2020component}, consists of 93 images taken by five DSLR cameras in real scenes.
Additionally, we collect another real-world dataset named \textit{RealSet65}. It comprises 35 LR images widely used in recent literature~\cite{martin2001database,matsui2017sketch,Ignatov2017DSLR,zhang2018ffdnet,wang2021real}. The remaining 30 images were obtained from the internet by ourselves.

\textbf{Compared Methods}. We evaluate the effectiveness of \textit{ResShift} in comparison to seven recent SR methods, namely ESRGAN~\cite{wang2018esrgan}, RealSR-JPEG~\cite{ji2020real}, BSRGAN~\cite{zhang2021designing}, RealESRGAN~\cite{wang2021real}, SwinIR~\cite{liang2021swinir}, DASR~\cite{liang2022efficient}, and LDM~\cite{rombach2022high}. Note that LDM is a diffusion-based method with 1,000 diffusion steps. For a fair comparison, we accelerate LDM to the same number of steps with \textit{ResShift} using DDIM~\cite{song2021denoising} and denote it as ``LDM-A", where ``A" indicates the number of inference steps. The hyper-parameter $\eta$ in DDIM is set to be 1 as this value yields the most realistic recovered images.

\textbf{Metrics}. The performance of various methods was assessed using five metrics, including PSNR, SSIM~\cite{zhou2004image}, LPIPS~\cite{zhang2018unreasonable}, MUSIQ~\cite{ke2021musiq}, and CLIPIQA~\cite{wang2022exploring}. It is worth noting that the latter two are non-reference metrics, specifically designed to assess the realism of images. CLIPIQA, in particular, leverages the CLIP~\cite{radford2021learning} model that is pre-trained on a massive dataset (i.e., Laion400M~\cite{schuhmann2021laion}) and thus demonstrates strong generalization ability. On the real-world datasets, we mainly rely on CLIPIQA and MUSIQ as evaluation metrics to compare the performance of different methods. 
%To be more comprehensive, we also introduce PI~\cite{blau20182018} as an another metric on real-world experiments since it is widely used in some challenges of image restoration. 
\begin{table}[t]
    \centering
    \caption{Efficiency and performance comparisons of \textit{ResShift} to LDM~\cite{rombach2022high} on the dataset of \textit{ImageNet-Test}. ``LDM-A'' represents the results achieved by accelerated the sampling steps of LDM to ``A''. The running time is tested on the NVIDIA Tesla V100 GPU on the x4 (64$\rightarrow$ 256) SR task.}
    \label{tab:runtime_comparison}
    \small
    \vspace{-2mm}
    \begin{tabular}{@{}C{2.6cm}@{}|
                    @{}C{1.5cm}@{} @{}C{1.5cm}@{} @{}C{1.6cm}@{} @{}C{1.6cm}@{} @{}C{1.7cm}@{}
                    @{}C{1.7cm}@{}|@{}C{1.8cm}@{}}
         \Xhline{0.8pt}
         \multirow{2}*{Metrics} & \multicolumn{7}{c}{Methods} \\
         \Xcline{2-8}{0.4pt}
                           & LDM-15 & LDM-30 & LDM-100 & LDM-200 & LDM-500 & LDM-1000 & \textit{ResShift} \\
        \Xhline{0.4pt}
         LPIPS$\downarrow$ & 0.269  & 0.248  & 0.244   & 0.245   & 0.246   & 0.248        & 0.231       \\
         CLIPIQA$\uparrow$ & 0.512  & 0.572  & 0.620   & 0.630   & 0.634   & 0.636        & 0.592       \\
         Runtime (s)       & 0.102  & 0.184  & 0.413   & 0.853   & 2.094   & 4.171        & 0.105     \\
         \Xhline{0.4pt}
         \# Parameters (M) & \multicolumn{6}{c|}{113.60}                    & 118.59     \\
        \Xhline{0.8pt}
    \end{tabular} 
    \vspace{-2mm}
\end{table}
\begin{table}[t]
    \centering
    \caption{Quantitative results of different methods on the dataset of \textit{ImageNet-Test}. The best and second best results are highlighted in \textbf{bold} and \underline{underline}.}
    \label{tab:imagenet_testing}
    \small
    \vspace{-2mm}
    \begin{tabular}{@{}C{3.8cm}@{}|
                    @{}C{1.9cm}@{} @{}C{2.0cm}@{} @{}C{2.0cm}@{} @{}C{2.1cm}@{} @{}C{2.1cm}@{}}
        \Xhline{0.8pt}
        \multirow{2}*{Methods} & \multicolumn{5}{c}{Metrics} \\
        \Xcline{2-6}{0.4pt}
            & PSNR$\uparrow$ & SSIM$\uparrow$ & LPIPS$\downarrow$ & CLIPIQA$\uparrow$ & MUSIQ$\uparrow$ \\
            \Xhline{0.4pt}
            ESRGAN~\cite{wang2018esrgan}         & 20.67 & 0.448 & 0.485 & 0.451 & 43.615  \\
            RealSR-JPEG~\cite{ji2020real}    & 23.11 & 0.591 & 0.326 & 0.537 & 46.981  \\
            BSRGAN~\cite{zhang2021designing} & 24.42 & 0.659 & 0.259 & \underline{0.581} & \textbf{54.697}  \\
            SwinIR~\cite{liang2021swinir}    & 23.99 & 0.667 & \underline{0.238} & 0.564 & \underline{53.790} \\
            RealESRGAN~\cite{wang2021real}   & 24.04 & 0.665 & 0.254 & 0.523 & 52.538 \\
            DASR~\cite{liang2022efficient}   & 24.75 & \underline{0.675} & 0.250 & 0.536 & 48.337  \\
            %FeMaSR~\cite{chen2022real}     & 22.49 & 0.589 & 0.259 & 0.714 & 55.052 \\
            %\Xhline{0.4pt}
            LDM-15~\cite{rombach2022high}  & \underline{24.89} & 0.670 & 0.269 & 0.512 & 46.419  \\
            %LDM-30~\cite{rombach2022high}  & 24.49 & 0.651 & 0.248 & 0.572 & 50.895  \\
            %\Xhline{0.4pt}
            \textit{ResShift}            & \textbf{25.01} & \textbf{0.677} & \textbf{0.231} & \textbf{0.592} & 53.660  \\
            %\textit{ResShift}              & 24.58 & 0.662 & \textbf{0.219}          & \textbf{0.634} & \textbf{56.443}       \\
       \Xhline{0.8pt}
    \end{tabular} 
    \vspace{-2mm}
\end{table}


\subsection{Model Analysis}\label{subsec:exp_model_analysis}
We analyze the performance of \textit{ResShift} under different settings on the number of diffusion steps $T$ and the hyper-parameters $p$ in Eq.~\eqref{eq:hyper_schedule} and $\kappa$ in Eq.~\eqref{eq:transit_t_t1}. 
%Due to page limitation, we only report the quantitative results here, and the corresponding visual results can be found in the supplementary material.

\textbf{Diffusion Steps $T$ and Hyper-parameter $p$}. The proposed transition distribution in Eq.~\eqref{eq:transit_t_t1} significantly reduces the diffusion steps $T$ in the Markov chain. The hyper-parameter $p$ allows for flexible control over the speed of residual shifting during the transition. Table~\ref{tab:schedules} summarizes the performance of \textit{ResShift} on \textit{ImageNet-Test} under different configurations of $T$ and $p$. We can see that both of $T$ and $p$ render a trade-off between the fidelity, measured by the reference metrics such as PSNR, SSIM, and LPIPS, and the realism, measured by the non-reference metrics including CLIPIQA and MUSIQ, of the super-resolved results. Taking $p$ as an example, when it increases, the reference metrics improve while the non-reference metrics deteriorate. Furthermore, the visual comparison in Fig.~\ref{fig:ablation_schedule} shows that large value of $p$ will suppress the model's ability to hallucinate more image details and result in blurry outputs.

\textbf{Hyper-parameter $\kappa$}. Equation~\eqref{eq:transit_0_t} reveals that $\kappa$ dominates the noise strength in state $\bm{x}_t$. We report the influence of $\kappa$ to the performance of \textit{ResShift} in Table~\ref{tab:schedules}. Combining with the visualization in Fig.~\ref{fig:ablation_schedule}, we can find that excessively large or small values of $\kappa$ will smooth the recovered results, regardless of their favorable metrics of PSNR and SSIM. When $\kappa$ is in the range of $[1.0,2.0]$, our method achieves the most realistic quality indicated by CLIPIQA and MUSIQ, which is more desirable in real applications. We thus set $\kappa$ to be $2.0$ in this work.
\begin{table}[t]
    \centering
    \caption{Quantitative results of different methods on two real-world datasets. The best and second best results are highlighted in \textbf{bold} and \underline{underline}.}
    \label{tab:real_testing}
    \small
    \vspace{-2mm}
    \begin{tabular}{@{}C{4.0cm}@{}|
                    @{}C{2.4cm}@{} @{}C{2.5cm}@{}| 
                    @{}C{2.5cm}@{} @{}C{2.5cm}@{} }
        \Xhline{0.8pt}
        \multirow{3}*{Methods} & \multicolumn{4}{c}{Datasets} \\
        \Xcline{2-5}{0.4pt}
            & \multicolumn{2}{c|}{\textit{RealSR}}  & \multicolumn{2}{c}{\textit{RealSet65}} \\
            \Xcline{2-5}{0.4pt}
            & CLIPIQA$\uparrow$ & MUSIQ$\uparrow$   
            & CLIPIQA$\uparrow$ & MUSIQ$\uparrow$  \\
            \Xhline{0.4pt}
            ESRGAN~\cite{wang2018esrgan}     & 0.2362 & 29.048   & 0.3739 & 42.369  \\
            RealSR-JPEG~\cite{ji2020real}    & 0.3615 & 36.076  & 0.5282 & 50.539  \\
            BSRGAN~\cite{zhang2021designing} & \underline{0.5439} & \textbf{63.586} & 0.6163 &\textbf{65.582} \\
            SwinIR~\cite{liang2021swinir}    & 0.4654 & 59.636  & 0.5782 & \underline{63.822} \\
            RealESRGAN~\cite{wang2021real}   & 0.4898 & 59.678  & 0.5995 & 63.220  \\
            DASR~\cite{liang2022efficient}   & 0.3629 & 45.825  & 0.4965 & 55.708   \\
            %FeMaSR~\cite{chen2022real}       & 0.5598 & 58.770 & \underline{0.6126} & 31.782 & \textbf{0.6777} & \underline{64.772} \\
            %\Xhline{0.4pt}
            LDM-15~\cite{rombach2022high}    & 0.3836 & 49.317 & 0.4274 & 47.488  \\
            %\Xhline{0.4pt}
            \textit{ResShift}              & \textbf{0.5958} & \underline{59.873} & \textbf{0.6537} & 61.330  \\
            %\textit{ResShift}                & \textbf{0.6533} & \underline{59.708} & \textbf{0.6581} & 32.474 & \textbf{0.7077} & \underline{63.838}   \\
       \Xhline{0.4pt}
    \end{tabular} 
\end{table}
% Figure environment removed

\textbf{Efficiency Comparison}. To improve inference efficiency, it is desirable to limit the number of diffusion steps $T$. However, this causes a decrease in the realism of the restored HR images. To compromise, the hyper-parameter $p$ can be set to a relatively small value. Therefore, we set $T=15$ and $p=0.3$, and yield our model named \textit{ResShift}. Table~\ref{tab:runtime_comparison} summarizes the efficiency and performance comparisons to LDM~\cite{rombach2022high} on \textit{ImageNet-Test}. The proposed \textit{ResShift} outperforms LDM~\cite{rombach2022high}, even with 1,000 sampling steps, in terms of LPIPS~\cite{zhang2018unreasonable} and CLIPIQA~\cite{wang2022exploring}. \textit{ResShift} is about 40 times faster than LDM under this configuration, showing promise in addressing the efficiency constraints inherent in current diffusion-based SR approaches.

\subsection{Evaluation on Synthetic Data}
We present a comparative analysis of the proposed method with recent state-of-the-art (SotA) approaches on the \textit{ImageNet-Test} dataset, as summarized in Table~\ref{tab:imagenet_testing}. Based on this evaluation, several significant conclusions can be drawn as follows: i) \textit{ResShift} exhibits superior or at least comparable performance across all five metrics, affirming the effectiveness and superiority of the proposed method. ii) The notably higher PSNR ans SSIM values attained by \textit{ResShift} indicate its capacity to better preserve fidelity to ground truth images. This advantage primarily arises from our well-designed diffusion model, which starts from a subtle disturbance of the LR image, rather than the conventional assumption of white Gaussian noise in LDM. iii) Considering the metrics of LPIPS and CLIPIQA, which gauge the perceptual quality and realism of the recovered image, \textit{ResShift} also demonstrates evident superiority over existing methods. Furthermore, in terms of MUSIQ, our approach achieves comparable performance with recents SotA methods. In summary, the proposed \textit{ResShift} exhibits remarkable capabilities in generating more realistic results while preserving fidelity. This is of paramount importance for the task of SR.

%Despite being widely used in SR, the PSNR and SSIM metrics are known to favor over-smoothed results and do not align with our perceptually visual system~\cite{zhang2021designing,yue2022blind}. Interestingly, these two metrics can be easily improved for our method by reducing the diffusion steps as evidenced in Table~\ref{tab:schedules}. Hence, we evaluate the performance of various methods mainly based on LPIPS, CLIPIQA, and MUSIQ. Our proposed method outperforms existing methods on all these three perceptual metrics, highlighting the effectiveness of the designed diffusion model for SR. It is worth noting that the performance of LDM can be further improved by increasing its sampling steps, as illustrated in Table~\ref{tab:runtime_comparison}, but at the expense of inference speed. In contrast, our method provides a computationally efficient alternative without sacrificing performance.

\subsection{Evaluation on Real-World Data}
Table~\ref{tab:real_testing} lists the comparative evaluation using CLIPIQA~\cite{wang2022exploring} and MUSIQ~\cite{ke2021musiq} of various methods on two real-world datasets. Note that CLIPIQA, benefiting from the powerful representative capability inherited from CLIP, performs stably and robustly in assessing the perceptional quality of natural images. The results in Table~\ref{tab:real_testing} shows that the proposed \textit{ResShift} evidently surpasses existing methods in CLIPIQA, meaning that the restored outputs of \textit{ResShift} better align with human visual and perceptive systems. In the case of MUSIQ evaluation, \textit{ResShift} achieves the competitive performance when compared to current SotA methods, namely BSRGAN~\cite{zhang2021designing}, SwinIR~\cite{liang2021swinir}, and RealESRGAN~\cite{wang2021real}. Collectively, our method shows promising capability in addressing the real-world SR problem.

We display four real-world examples in Fig.~\ref{fig:real_data} for an easy visualization, and more examples can be found in Fig.~\ref{fig:realdata_supp1} and Fig.~\ref{fig:realdata_supp2} in Appendix. To ensure a comprehensive evaluation, we consider diverse scenarios, including comic, text, face, and natural images. A noticeable observation is that \textit{ResShift} produces more naturalistic image structures, as evidenced by the patterns on the beam in the third example and the eyes of a person in the fourth example. We note that the recovered results of LDM are excessively smooth when compressing the inference steps to match with the proposed \textit{ResShift}, specifically utilizing 15 steps, largely deviating from the training procedure's 1,000 steps. 
Even though other GAN-based methods may also succeed in hallucinate plausible structures to some extent, they are often accompanied with obvious artifacts.
%The recent method FeMaSR tends to over-sharpen the images, while other methods fall short of restoring clear image details.

% \begin{wrapfigure}[9]{r}{7.8cm}
%     \centering
%     \vspace{-4mm}
%     % Figure removed
%     \vspace{-6mm}
%     \caption{One typical failure case in \textit{RealSet65}.}
%     \label{fig:failed}  
% \end{wrapfigure}


%-------------------------------------------------------
\section{Conclusion}
In this work, we have introduced an efficient diffusion model named \textit{ResShift} for SR. Unlike existing diffusion-based SR methods that require a large number of iterations to achieve satisfactory results, our proposed method constructs a diffusion model with only 15 sampling steps, thereby significantly improving inference efficiency. The core idea is to corrupt the HR image toward the LR image instead of the Gaussian white noise, which can effectively cut off the length of the diffusion model. Extensive experiments on both synthetic and real-world datasets have demonstrated the superiority of our proposed method.  We believe that our work will pave the way for the development of more efficient and effective diffusion models to address the SR problem.

%-------------------------------------------------------
{\small
\bibliographystyle{unsrtnat}
\bibliography{ref_resshift}
}

\newpage
\appendix
\section{Mathematical Details} \label{sec:mathcmatic_supp}
\begin{itemize}[topsep=0pt,parsep=0pt,leftmargin=18pt]
    \item \textbf{Derivation of Eq.~\eqref{eq:transit_0_t}}:
    According to the transition distribution of Eq.~\eqref{eq:transit_t_t1}, $\bm{x}_t$ can be sampled via the following reparameterization trick:
    \begin{equation}
        \bm{x}_t = \bm{x}_{t-1} + \alpha_t \bm{e}_0 + \kappa \sqrt{\alpha_t} \bm{\xi}_t,
        \label{eq:reparametrization_xt}
    \end{equation}
    where $\bm{\xi}_t \sim \mathcal{N}(\bm{x}|0, \bm{I})$, $\alpha_t=\eta_t-\eta_{t-1}$ for $t>1$ and $\alpha_1=\eta_1$.
    
    Applying this sampling trick recursively, we can build up the relation between $\bm{x}_t$ and $\bm{x}_0$ as follows:
    \begin{align}
        \bm{x}_t &= \bm{x}_{0} + \sum_{i=1}^t\alpha_i \bm{e}_0 + \kappa \sum_{i=1}^t \sqrt{\alpha_i} \bm{\xi}_i \notag \\
                 &= \bm{x}_{0} + \eta_t \bm{e}_0 + \kappa \sum_{i=1}^t \sqrt{\alpha_i} \bm{\xi}_i,
        \label{eq:relation_xt_x0}
    \end{align}
    where $\bm{\xi}_i \sim \mathcal{N}(\bm{x}|0, \bm{I})$. 
    
    We can further merge $\bm{\xi}_1, \bm{\xi}_2, \cdots, \bm{\xi}_t$ and simplify Eq.~\eqref{eq:relation_xt_x0} as follows: 
    \begin{equation}
        \bm{x}_t = \bm{x}_{0} + \eta_t \bm{e}_0 + \kappa \sqrt{\eta_t} \bm{\xi}_t.
        \label{eq:reparamterization_xt_x0}
    \end{equation}
    Then the marginal distribution of Eq.~\eqref{eq:transit_0_t} is obtained based on Eq.~\eqref{eq:reparamterization_xt_x0}. 
    \item \textbf{Derivation of Eq.~\eqref{eq:poster_elbo}}: According to Bayesâ€™s theorem, we have
    \begin{equation}
        q(\bm{x}_{t-1}|\bm{x}_t,\bm{x}_0,\bm{y}_0) \propto q(\bm{x}_t|\bm{x}_{t-1},\bm{y}_0) q(\bm{x_{t-1}}|\bm{x}_0, \bm{y}_0),
    \end{equation}
    where
    \begin{gather}
        q(\bm{x}_t|\bm{x}_{t-1},\bm{y}_0) = \mathcal{N} (\bm{x}_t;\bm{x}_{t-1}+\alpha_t \bm{e}_0, \kappa^2\alpha_t \bm{I}), \notag \\
        q(\bm{x_{t-1}}|\bm{x}_0, \bm{y}_0) = \mathcal{N} (\bm{x}_{t-1};\bm{x}_0+\eta_{t-1} \bm{e}_0, \kappa^2\eta_{t-1} \bm{I}).
    \end{gather}

    We now focus on the quadratic form in the exponent of $q(\bm{x}_{t-1}|\bm{x}_t,\bm{x}_0,\bm{y}_0)$, namely,
    \begin{align}
        &\mathrel{\phantom{=}} -\frac{(\bm{x}_t - \bm{x}_{t-1}-\alpha_t \bm{e}_0)(\bm{x}_t - \bm{x}_{t-1}-\alpha_t \bm{e}_0)^T}{2\kappa^2\alpha_t} - \frac{(\bm{x}_{t-1}-\bm{x}_0-\eta_{t-1}\bm{e}_0)(\bm{x}_{t-1}-\bm{x}_0-\eta_{t-1}\bm{e}_0)^T}{2\kappa^2\eta_{t-1}} \notag \\
        &= -\frac{1}{2}\left[\frac{1}{\kappa^2\alpha_t}+\frac{1}{\kappa^2\eta_{t-1}}\right] \bm{x}_{t-1}\bm{x}_{t-1}^T + \left[\frac{\bm{x}_t-\alpha_t \bm{e}_0}{\kappa^2\alpha_t} + \frac{\bm{x}_0+\eta_{t-1}\bm{e}_0}{\kappa^2\eta_{t-1}} \right] \bm{x}_{t-1}^T + \text{const} \notag \\
        &= - \frac{(\bm{x}_{t-1}-\bm{\mu})(\bm{x}_{t-1}-\bm{\mu})^T} {2\lambda^2} + \text{const} \label{eq:quadratic_match}
    \end{align}
    where
    \begin{equation}
        \bm{\mu}= \frac{\eta_{t-1}}{\eta_t}\bm{x}_t + \frac{\alpha_t}{\eta_t} \bm{x}_0, ~
        \lambda^2 = \kappa^2 \frac{\eta_{t-1}}{\eta_t} \alpha_t, 
    \end{equation}
    and const denotes the item that is independent of $\bm{x}_{t-1}$. This quadratic form induces the Gaussian distribution of Eq.~\eqref{eq:poster_elbo}.
\end{itemize}

% Figure environment removed

\section{Experiment}
\subsection{Degradation Settings of the Synthetic Dataset} \label{subsec:degradation_app}
We synthesize the testing dataset \textit{ImageNet-Test} based on the degradation model in RealESRGAN~\cite{wang2021real} but removing the second-order operation. Actually, we observed that the LR image generated by the pipeline with second-order degradation exhibited significantly more pronounced corruption compared to most of the real-world LR images, we thus discarded the second-order operation to better align the authentic degradation. Next, we gave the detailed configuration on the blurring kernel, downsampling operator, and the noise types.

\noindent\textbf{Blurring kernel.} The blurring kernel is randomly sampled from the isotropic Gaussian and anisotropic Gaussian kernels with a probability of [0.6, 0.4]. The window size of the kernel is set to be 13. For isotropic Gaussian kernel, the kernel width is uniformly sampled from [0.2, 0.8]. For anistorpic Gaussian kernel, the kernel widths along $x$-axis and $y$-axis are both randomly sampled from [0.2, 0.8].

\noindent\textbf{Downampling.} We downsample the image using the ``interpolate'' function of PyTorch~\cite{paszke2019pytorch}. The interpolation mode is random selected from ``area'', ``bilinear'', and ``bicubic''.

\noindent\textbf{Noise.} We first added Gaussian and Poisson noise with a probability of [0.5, 0.5]. For Gaussian noise, the noise level is randomly chose from [1,15]. For Poisson noise, we set the scale parameter in [0.05, 0.3]. Finally, the noisy image is further compressed using JPEG with a quality factor ranged in [70, 95].  

% For the synthetic dataset, we randomly select 3000 images from the validation dataset of ImageNet~\cite{deng2009imagenet}, as opposed to the prevalent datasets commonly used in image super-resolution, e.g., \textit{Set5}~\cite{bevilacqua2012low}, \textit{Set14}~\cite{zeyde2012single}, and \textit{Urban100}~\cite{huang2015single}. The rationale behind this choice stems from the limited number of images contained within these widely utilized datasets, specifically, 5, 14, and 100 images in \textit{Set5}, \textit{Set14}, and \textit{Urban100}, which fails to comprehensively evaluate the performance of various methods. We thus opted for the more challenging dataset of ImageNet and involve a larger number of images, i.e., 3,000 images. Moreover, the employed degradation model of Eq. (11) in our manuscript covers more complicated types of blurring kernel, downsampling operator, and image noise. By incorporating an increased number of testing images, we can encompass a wider range of degradation types, thereby facilitating a more through comparison among different methods.   

\subsection{Limitation}
Albeit its overall strong performance, the proposed \textit{ResShift} occasionally exhibits failures. One such instance is illustrated in Figure~\ref{fig:failed_all}, wherein it is unable to produce satisfactory results for a severely degraded comic image. It should be noted that other comparison methods also struggle to address this particular example. 
%Detailed quantitative results are available in Fig.~\ref{fig:failed_case_all} of the Appendix. 
This is not an unexpected outcome as most modern SR methods are trained on synthetic datasets simulated by manually assumed degradation models~\cite{zhang2021designing,wang2021real}, which still cannot cover the full range of complicated real degradation types. Therefore, the development of a more practical degradation model for SR is an essential avenue for future research.


% \subsection{More Visual Results}. 

% We show more qualitative comparison results on the real-world dataset of \textit{RealSet65} in Fig.~\ref{fig:realdata_supp1} and.



% Figure environment removed
% Figure environment removed


\end{document}
