@article{apilookup,
  title={Automated measurement of API usability: The API concepts framework},
  author={Scheller, Thomas and K{\"u}hn, Eva},
  journal={Information and Software Technology},
  volume={61},
  pages={145--162},
  year={2015},
  publisher={Elsevier}
}

@inproceedings{CERT,
  title={{CERT}: Continual Pre-training on Sketches for Library-oriented Code Generation},
  author={Zan, Daoguang and Chen, Bei and Yang, Dejian and Lin, Zeqi and Kim, Minsu and Guan, Bei and Wang, Yongji and Chen, Weizhu and Lou, Jian-Guang},
  booktitle={The 2022 International Joint Conference on Artificial Intelligence},
  year={2022}
}


@article{apicoder,
  title={When Language Model Meets Private Library},
  author={Zan, Daoguang and Chen, Bei and Lin, Zeqi and Guan, Bei and Wang, Yongji and Lou, Jian-Guang},
  journal={EMNLP Findings},
  year={2022}
}

@article{formal2022distillation,
  title={From Distillation to Hard Negative Sampling: Making Sparse Neural IR Models More Effective},
  author={Formal, Thibault and Lassance, Carlos and Piwowarski, Benjamin and Clinchant, St{\'e}phane},
  journal={arXiv preprint arXiv:2205.04733},
  year={2022}
}

@article{santhanam2021colbertv2,
  title={Colbertv2: Effective and efficient retrieval via lightweight late interaction},
  author={Santhanam, Keshav and Khattab, Omar and Saad-Falcon, Jon and Potts, Christopher and Zaharia, Matei},
  journal={arXiv preprint arXiv:2112.01488},
  year={2021}
}

@article{xiong2020approximate,
  title={Approximate nearest neighbor negative contrastive learning for dense text retrieval},
  author={Xiong, Lee and Xiong, Chenyan and Li, Ye and Tang, Kwok-Fung and Liu, Jialin and Bennett, Paul and Ahmed, Junaid and Overwijk, Arnold},
  journal={arXiv preprint arXiv:2007.00808},
  year={2020}
}

@article{rocketqa,
  title={{RocketQA}: An optimized training approach to dense passage retrieval for open-domain question answering},
  author={Qu, Yingqi and Ding, Yuchen and Liu, Jing and Liu, Kai and Ren, Ruiyang and Zhao, Wayne Xin and Dong, Daxiang and Wu, Hua and Wang, Haifeng},
  journal={arXiv preprint arXiv:2010.08191},
  year={2020}
}

@article{faiss,
  title={Billion-scale similarity search with gpus},
  author={Johnson, Jeff and Douze, Matthijs and J{\'e}gou, Herv{\'e}},
  journal={IEEE Transactions on Big Data},
  volume={7},
  number={3},
  pages={535--547},
  year={2019},
  publisher={IEEE}
}

@misc{gptcc,
  author = {CodedotAl},
  urldate = {Jul. 2021},
  year = {2021},
  title = {{GPT Code Clippy: The Open Source version of GitHub
Copilot}},
  note  = {\url{https://github.com/CodedotAl/gpt-code-clippy}}
}

@article{codegpt,
  title={{CodeXGLUE}: A machine learning benchmark dataset for code understanding and generation},
  author={Lu, Shuai and Guo, Daya and Ren, Shuo and Huang, Junjie and Svyatkovskiy, Alexey and Blanco, Ambrosio and Clement, Colin and Drain, Dawn and Jiang, Daxin and Tang, Duyu and others},
  journal={arXiv preprint arXiv:2102.04664},
  year={2021}
}

@article{deepspeed,
  author       = {Samyam Rajbhandari and
                  Jeff Rasley and
                  Olatunji Ruwase and
                  Yuxiong He},
  title        = {ZeRO: Memory Optimization Towards Training {A} Trillion Parameter
                  Models},
  journal      = {CoRR},
  volume       = {abs/1910.02054},
  year         = {2019},
  url          = {http://arxiv.org/abs/1910.02054},
  eprinttype    = {arXiv},
  eprint       = {1910.02054},
  timestamp    = {Wed, 09 Oct 2019 14:07:58 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-1910-02054.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{emergent_ability,
  title={Emergent abilities of large language models},
  author={Wei, Jason and Tay, Yi and Bommasani, Rishi and Raffel, Colin and Zoph, Barret and Borgeaud, Sebastian and Yogatama, Dani and Bosma, Maarten and Zhou, Denny and Metzler, Donald and others},
  journal={arXiv preprint arXiv:2206.07682},
  year={2022}
}

@article{codex,
  title={Evaluating Large Language Models Trained on Code},
  author={Mark Chen and Jerry Tworek and Heewoo Jun and Qiming Yuan and Henrique Ponde and Jared Kaplan and Harrison Edwards and Yura Burda and Nicholas Joseph and Greg Brockman and Alex Ray and Raul Puri and Gretchen Krueger and Michael Petrov and Heidy Khlaaf and Girish Sastry and Pamela Mishkin and Brooke Chan and Scott Gray and Nick Ryder and Mikhail Pavlov and Alethea Power and Lukasz Kaiser and Mohammad Bavarian and Clemens Winter and Philippe Tillet and Felipe Petroski Such and David W. Cummings and Matthias Plappert and Fotios Chantzis and Elizabeth Barnes and Ariel Herbert-Voss and William H. Guss and Alex Nichol and Igor Babuschkin and S. Arun Balaji and Shantanu Jain and Andrew Carr and Jan Leike and Joshua Achiam and Vedant Misra and Evan Morikawa and Alec Radford and Matthew M. Knight and Miles Brundage and Mira Murati and Katie Mayer and Peter Welinder and Bob McGrew and Dario Amodei and Sam McCandlish and Ilya Sutskever and Wojciech Zaremba},
  journal={ArXiv},
  year={2021},
  volume={abs/2107.03374}
}

@article{grounded-copilot,
  title={{Grounded Copilot}: How Programmers Interact with Code-Generating Models},
  author={Shraddha Barke and Michael B. James and Nadia Polikarpova},
  journal={Proceedings of the ACM on Programming Languages},
  year={2022},
  volume={7},
  pages={85 - 111}
}

@article{evaluate-code-LLM,
  title={{Expectation vs. Experience}: Evaluating the Usability of Code Generation Tools Powered by Large Language Models},
  author={Priyan Vaithilingam and Tianyi Zhang and Elena L. Glassman},
  journal={CHI Conference on Human Factors in Computing Systems Extended Abstracts},
  year={2022}
}

@article{copilot-contribution,
  title={An Empirical Cybersecurity Evaluation of GitHub Copilot's Code Contributions},
  author={Hammond A. Pearce and Baleegh Ahmad and Benjamin Tan and Brendan Dolan-Gavitt and Ramesh Karri},
  journal={ArXiv},
  year={2021},
  volume={abs/2108.09293}
}

@inproceedings{codegen,
title={{CodeGen}: An Open Large Language Model for Code with Multi-Turn Program Synthesis},
author={Erik Nijkamp and Bo Pang and Hiroaki Hayashi and Lifu Tu and Huan Wang and Yingbo Zhou and Silvio Savarese and Caiming Xiong},
booktitle={The Eleventh International Conference on Learning Representations},
year={2023}
}

@inproceedings{incoder,
title={{InCoder}: A Generative Model for Code Infilling and Synthesis},
author={Daniel Fried and Armen Aghajanyan and Jessy Lin and Sida Wang and Eric Wallace and Freda Shi and Ruiqi Zhong and Scott Yih and Luke Zettlemoyer and Mike Lewis},
booktitle={The Eleventh International Conference on Learning Representations},
year={2023}
}

@article{pangu-coder,
  title={{PanGu-Coder}: Program Synthesis with Function-Level Language Modeling},
  author={Fenia Christopoulou and Gerasimos Lampouras and Milan Gritta and Guchun Zhang and Yinpeng Guo and Zhong-Yi Li and Qi Zhang and Meng Xiao and Bo Shen and Lin Li and Hao Yu and Li-yu Yan and Pingyi Zhou and Xin Wang and Yu Ma and Ignacio Iacobacci and Yasheng Wang and Guangtai Liang and Jia Wei and Xin Jiang and Qianxiang Wang and Qun Liu},
  journal={ArXiv},
  year={2022},
  volume={abs/2207.11280}
}

@misc{codeparrot,
  author = {Huggingface},
  urldate = {2021},
  year = {2021},
  title = {{Training CodeParrot from Scratch}},
  note  = {\url{https://huggingface.co/blog/codeparrot}}
}

@misc{big-bench,
  author = {Google},
  urldate = {2022},
  year = {2022},
  title = {BIG-bench},
  note  = {\url{https://github.com/google/BIG-bench}}
}

@misc{codeclippy,
  author = {CodedotAl},
  urldate = {Jul. 2021},
  year = {2021},
  title = {{GPT Code Clippy: The Open Source version of GitHub
Copilot}},
  note  = {\url{https://github.com/CodedotAl/gpt-code-clippy}}
}

@article{gpt-c,
  title={{IntelliCode compose}: code generation using transformer},
  author={Alexey Svyatkovskiy and Shao Kun Deng and Shengyu Fu and Neel Sundaresan},
  journal={Proceedings of the 28th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
  year={2020}
}

@article{fim,
  title={Efficient Training of Language Models to Fill in the Middle},
  author={Mohammad Bavarian and Heewoo Jun and Nikolas A. Tezak and John Schulman and Christine McLeavey and Jerry Tworek and Mark Chen},
  journal={ArXiv},
  year={2022},
  volume={abs/2207.14255}
}

@article{codegeex,
  title={{CodeGeeX}: A Pre-Trained Model for Code Generation with Multilingual Evaluations on HumanEval-X},
  author={Qinkai Zheng and Xiao Xia and Xu Zou and Yuxiao Dong and Shanshan Wang and Yufei Xue and Zi-Yuan Wang and Lei Shen and Andi Wang and Yang Li and Teng Su and Zhilin Yang and Jie Tang},
  journal={ArXiv},
  year={2023},
  volume={abs/2303.17568}
}

@article{polycoder,
  title={A systematic evaluation of large language models of code},
  author={Frank F. Xu and Uri Alon and Graham Neubig and Vincent J. Hellendoorn},
  journal={Proceedings of the 6th ACM SIGPLAN International Symposium on Machine Programming},
  year={2022}
}

@article{codexglue,
  title={{CodeXGLUE}: A Machine Learning Benchmark Dataset for Code Understanding and Generation},
  author={Shuai Lu and Daya Guo and Shuo Ren and Junjie Huang and Alexey Svyatkovskiy and Ambrosio Blanco and Colin B. Clement and Dawn Drain and Daxin Jiang and Duyu Tang and Ge Li and Lidong Zhou and Linjun Shou and Long Zhou and Michele Tufano and Ming Gong and Ming Zhou and Nan Duan and Neel Sundaresan and Shao Kun Deng and Shengyu Fu and Shujie Liu},
  journal={ArXiv},
  year={2021},
  volume={abs/2102.04664}
}

@article{alphacode,
  title={Competition-level code generation with AlphaCode},
  author={Yujia Li and David H. Choi and Junyoung Chung and Nate Kushman and Julian Schrittwieser and R{\'e}mi Leblond and Tom and Eccles and James Keeling and Felix Gimeno and Agustin Dal Lago and Thomas Hubert and Peter Choy and Cyprien de and Masson d’Autume and Igor Babuschkin and Xinyun Chen and Po-Sen Huang and Johannes Welbl and Sven Gowal and Alexey and Cherepanov and James Molloy and Daniel Jaymin Mankowitz and Esme Sutherland Robson and Pushmeet Kohli and Nando de and Freitas and Koray Kavukcuoglu and Oriol Vinyals},
  journal={Science},
  year={2022},
  volume={378},
  pages={1092 - 1097}
}

@inproceedings{codet5,
  title={{CodeT5}: Identifier-aware Unified Pre-trained Encoder-Decoder Models for Code Understanding and Generation},
  author={Wang, Yue and Wang, Weishi and Joty, Shafiq and Hoi, Steven CH},
  booktitle={Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing},
  pages={8696--8708},
  year={2021}
}

@inproceedings{plbart,
  title={Unified Pre-training for Program Understanding and Generation},
  author={Ahmad, Wasi and Chakraborty, Saikat and Ray, Baishakhi and Chang, Kai-Wei},
  booktitle={Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies},
  pages={2655--2668},
  year={2021}
}

@article{coderl,
  title={{CodeRL}: Mastering code generation through pretrained models and deep reinforcement learning},
  author={Le, Hung and Wang, Yue and Gotmare, Akhilesh Deepak and Savarese, Silvio and Hoi, Steven CH},
  journal={arXiv preprint arXiv:2207.01780},
  year={2022},
  volume={abs/2207.01780}
}

@inproceedings{pymt5,
  title={{PyMT5}: Multi-mode Translation of Natural Language and Python Code with Transformers},
  author={Colin B. Clement and Dawn Drain and Jonathan Timcheck and Alexey Svyatkovskiy and Neel Sundaresan},
  booktitle={Conference on Empirical Methods in Natural Language Processing},
  pages={9052--9065},
  year={2020}
}

@article{jupyt5,
  title={Training and Evaluating a Jupyter Notebook Data Science Assistant},
  author={Shubham Chandel and Colin B. Clement and Guillermo Serrato and Neel Sundaresan},
  journal={ArXiv},
  year={2022},
  volume={abs/2201.12901}
}

@misc{copilot,
  author = {GitHub},
  year = {2021},
  title = {{GitHub Copilot}},
  note  = {\url{https://github.com/features/copilot}}
}

@misc{tabnine,
  author = {tabnine},
  year = {2018},
  title = {{TabNine}},
  note  = {\url{https://www.tabnine.com}}
}

@misc{ghostwriter,
  year = {2022},
  author = {Replit},
  title = {{Ghostwriter}},
  note  = {\url{https://replit.com/site/ghostwriter}}
}

@misc{codewhisperer,
  year = {2022},
  author = {Amazon},
  title = {{CodeWhisperer}},
  note  = {\url{https://aws.amazon.com/cn/codewhisperer}}
}

@misc{codegenx,
  year = {2022},
  author = {DeepGenX},
  title = {{CodeGenX}},
  note  = {\url{https://docs.deepgenx.com}}
}

@misc{aiXcoder,
  year = {2018},
  author = {aiXcoder},
  title = {{aiXcoder}},
  note  = {\url{https://aixcoder.com}}
}

@misc{fauxpilot,
  year = {2022},
  author = {FauxPilot},
  title = {{FauxPilot}},
  note  = {\url{https://github.com/moyix/fauxpilot}}
}

@misc{diffblue-cover,
  year = {2020},
  author = {University of Oxford},
  title = {{Diffblue Cover}},
  note  = {\url{https://www.diffblue.com}}
}

@misc{intellicode,
  year = {2019},
  author = {Microsoft},
  title = {{IntelliCode}},
  note  = {\url{https://github.com/MicrosoftDocs/intellicode}}
}

@misc{cosy,
  year = {2022},
  author = {Alibaba},
  title = {{Alibaba}},
  note  = {\url{https://github.com/alibaba-cloud-toolkit/cosy}}
}

@misc{kite,
  year = {2014},
  author = {Kite},
  title = {{Kite}},
  note  = {\url{https://www.kite.com}}
}

@article{mbpp,
  title={Program Synthesis with Large Language Models},
  author={Jacob Austin and Augustus Odena and Maxwell Nye and Maarten Bosma and Henryk Michalewski and David Dohan and Ellen Jiang and Carrie J. Cai and Michael Terry and Quoc V. Le and Charles Sutton},
  journal={ArXiv},
  year={2021},
  volume={abs/2108.07732}
}

@inproceedings{apps,
  title={Measuring coding challenge competence with apps},
  author={Dan Hendrycks and Steven Basart and Saurav Kadavath and Mantas Mazeika and Akul Arora and Ethan Guo and Collin Burns and Samir Puranik and Horace He and Dawn Xiaodong Song and Jacob Steinhardt},
  booktitle={Neural Information Processing Systems},
  year={2021}
}

@article{ds-1000,
  title={{DS-1000}: A Natural and Reliable Benchmark for Data Science Code Generation},
  author={Yuhang Lai and Chengxi Li and Yiming Wang and Tianyi Zhang and Ruiqi Zhong and Luke Zettlemoyer and Scott Yih and Daniel Fried and Si-yi Wang and Tao Yu},
  journal={ArXiv},
  year={2022},
  volume={abs/2211.11501}
}

@article{mbxp,
  title={Multi-lingual Evaluation of Code Generation Models},
  author={Ben Athiwaratkun and Sanjay Krishna Gouda and Zijian Wang and Xiaopeng Li and Yuchen Tian and Ming Tan and Wasi Uddin Ahmad and Shiqi Wang and Qing Sun and Mingyue Shang and Sujan Kumar Gonugondla and Hantian Ding and Varun Kumar and Nathan Fulton and Arash Farahani and Siddharth Jain and Robert Giaquinto and Haifeng Qian and Murali Krishna Ramanathan and Ramesh Nallapati and Baishakhi Ray and Parminder Bhatia and Sudipta Sengupta and Dan Roth and Bing Xiang},
  journal={ArXiv},
  year={2022},
  volume={abs/2210.14868}
}

@article{securityeval,
  title={{SecurityEval} dataset: mining vulnerability examples to evaluate machine learning-based code generation techniques},
  author={Mohammed Latif Siddiq and msiddiq},
  journal={Proceedings of the 1st International Workshop on Mining Software Repositories Applications for Privacy and Security},
  year={2022}
}

@article{multipl-e,
  title={A Scalable and Extensible Approach to Benchmarking NL2Code for 18 Programming Languages},
  author={Federico Cassano and John Gouwar and Daniel Nguyen and Sy Duy Nguyen and Luna Phipps-Costin and Donald Pinckney and Ming-Ho Yee and Yangtian Zi and Carolyn Jane Anderson and Molly Q. Feldman and Arjun Guha and Michael Greenberg and Abhinav Jangda},
  journal={ArXiv},
  year={2022},
  volume={abs/2208.08227}
}

@article{mlfinalsq,
  title={A Dataset and Benchmark for Automatically Answering and Generating Machine Learning Final Exams},
  author={Sarah Zhang and Reece Shuttleworth and Derek Austin and Yann Hicke and Leonard Tang and Sathwik Karnik and Darnell Granberry and Iddo Drori},
  journal={ArXiv},
  year={2022},
  volume={abs/2206.05442}
}

@article{conala,
  title={Learning to Mine Aligned Code and Natural Language Pairs from Stack Overflow},
  author={Pengcheng Yin and Bowen Deng and Edgar Chen and Bogdan Vasilescu and Graham Neubig},
  journal={2018 IEEE/ACM 15th International Conference on Mining Software Repositories (MSR)},
  year={2018},
  pages={476-486}
}

@article{mconala,
  title={{MCoNaLa}: a benchmark for code generation from multiple natural languages},
  author={Wang, Zhiruo and Cuenca, Grace and Zhou, Shuyan and Xu, Frank F and Neubig, Graham},
  journal={arXiv preprint arXiv:2203.08388},
  year={2022}
}

@article{rced,
  title={Time-Efficient Code Completion Model for the R Programming Language},
  author={Artem Popov and Dmitrii Orekhov and Denis V. Litvinov and Nikolay Korolev and Gleb Morgachev},
  journal={Proceedings of the 1st Workshop on Natural Language Processing for Programming (NLP4Prog 2021)},
  year={2021}
}

@article{p3,
  title={Programming Puzzles},
  author={Tal Schuster and A. Kalyan and Oleksandr Polozov and Adam Tauman Kalai},
  journal={ArXiv},
  year={2021},
  volume={abs/2106.05784}
}

@article{palm,
  title={{PaLM}: Scaling Language Modeling with Pathways},
  author={Aakanksha Chowdhery and Sharan Narang and Jacob Devlin and Maarten Bosma and Gaurav Mishra and Adam Roberts and Paul Barham and Hyung Won Chung and Charles Sutton and Sebastian Gehrmann and Parker Schuh and Kensen Shi and Sasha Tsvyashchenko and Joshua Maynez and Abhishek Rao and Parker Barnes and Yi Tay and Noam M. Shazeer and Vinodkumar Prabhakaran and Emily Reif and Nan Du and Benton C. Hutchinson and Reiner Pope and James Bradbury and Jacob Austin and Michael Isard and Guy Gur-Ari and Pengcheng Yin and Toju Duke and Anselm Levskaya and Sanjay Ghemawat and Sunipa Dev and Henryk Michalewski and Xavier Garc{\'i}a and Vedant Misra and Kevin Robinson and Liam Fedus and Denny Zhou and Daphne Ippolito and David Luan and Hyeontaek Lim and Barret Zoph and Alexander Spiridonov and Ryan Sepassi and David Dohan and Shivani Agrawal and Mark Omernick and Andrew M. Dai and Thanumalayan Sankaranarayana Pillai and Marie Pellat and Aitor Lewkowycz and Erica Moreira and Rewon Child and Oleksandr Polozov and Katherine Lee and Zongwei Zhou and Xuezhi Wang and Brennan Saeta and Mark D{\'i}az and Orhan Firat and Michele Catasta and Jason Wei and Kathleen S. Meier-Hellstern and Douglas Eck and Jeff Dean and Slav Petrov and Noah Fiedel},
  journal={ArXiv},
  year={2022},
  volume={abs/2204.02311}
}

@inproceedings{concode,
  title={Mapping Language to Code in Programmatic Context},
  author={Srini Iyer and Ioannis Konstas and Alvin Cheung and Luke Zettlemoyer},
  booktitle={Conference on Empirical Methods in Natural Language Processing},
  year={2018}
}

@inproceedings{shellcode-ia32,
  title={{Shellcode\_IA32}: A Dataset for Automatic Shellcode Generation},
  author={Liguori, Pietro and Al-Hossami, Erfan and Cotroneo, Domenico and Natella, Roberto and Cukic, Bojan and Shaikh, Samira},
  booktitle={Proceedings of the 1st Workshop on Natural Language Processing for Programming (NLP4Prog 2021)},
  pages={58--64},
  year={2021}
}

@inproceedings{plotcoder-juice,
  title={{PlotCoder}: Hierarchical Decoding for Synthesizing Visualization Code in Programmatic Context},
  author={Xinyun Chen and Linyuan Gong and Alvin Cheung and Dawn Xiaodong Song},
  booktitle={Annual Meeting of the Association for Computational Linguistics},
  year={2021}
}

@article{codesearchnet,
  title={{CodeSearchNet Challenge}: Evaluating the State of Semantic Code Search},
  author={Hamel Husain and Hongqi Wu and Tiferet Gazit and Miltiadis Allamanis and Marc Brockschmidt},
  journal={ArXiv},
  year={2019},
  volume={abs/1909.09436}
}

@article{spoc,
  title={{SPoC}: Search-based pseudocode to code},
  author={Sumith Kulal and Panupong Pasupat and Kartik Chandra and Mina Lee and Oded Padon and Alexander Aiken and Percy Liang},
  journal={Neural Information Processing Systems},
  volume={32},
  year={2019}
}

@article{naps,
  title={{NAPS}: Natural Program Synthesis Dataset},
  author={Maksym Zavershynskyi and Alexander Skidanov and Illia Polosukhin},
  journal={ArXiv},
  year={2018},
  volume={abs/1807.03168}
}

@inproceedings{nl2bash,
  title={{NL2Bash}: A Corpus and Semantic Parser for Natural Language Interface to the Linux Operating System},
  author={Xi Victoria Lin and Chenglong Wang and Luke Zettlemoyer and Michael D. Ernst},
  booktitle={Proceedings of the Eleventh International Conference on Language Resources and Evaluation (LREC 2018)},
  year={2018}
}

@inproceedings{mtg-hs,
  title={Latent Predictor Networks for Code Generation},
  author={Wang Ling and Phil Blunsom and Edward Grefenstette and Karl Moritz Hermann and Tom{\'a}s Kocisk{\'y} and Fumin Wang and Andrew W. Senior},
  booktitle={Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics},
  pages={599--609},
  year={2016}
}

@article{django,
  title={Learning to Generate Pseudo-Code from Source Code Using Statistical Machine Translation (T)},
  author={Yusuke Oda and Hiroyuki Fudaba and Graham Neubig and Hideaki Hata and Sakriani Sakti and Tomoki Toda and Satoshi Nakamura},
  journal={2015 30th IEEE/ACM International Conference on Automated Software Engineering (ASE)},
  year={2015},
  pages={574-584}
}

@inproceedings{dsl-1,
  title={Dimensions in program synthesis},
  author={Gulwani, Sumit},
  booktitle={Proceedings of the 12th international ACM SIGPLAN symposium on Principles and practice of declarative programming},
  pages={13--24},
  year={2010}
}

@article{dsl-2,
  title={Oracle-guided component-based program synthesis},
  author={Susmit Jha and Sumit Gulwani and Sanjit A. Seshia and Ashish Tiwari},
  journal={2010 ACM/IEEE 32nd International Conference on Software Engineering},
  year={2010},
  volume={1},
  pages={215-224}
}

@article{dsl-3,
  title={Complete completion using types and weights},
  author={Tihomir Gvero and Viktor Kun{\vc}ak and Ivan Kuraj and Ruzica Piskac},
  journal={Proceedings of the 34th ACM SIGPLAN Conference on Programming Language Design and Implementation},
  year={2013}
}

@article{dsl-4,
  title={Learning explanatory rules from noisy data},
  author={Richard Evans and Edward Grefenstette},
  journal={Journal of Artificial Intelligence Research},
  volume={61},
  pages={1--64},
  year={2018}
}

@article{dsl-5,
  title={Learning to select examples for program synthesis},
  author={Yewen Pu and Zachery Miranda and Armando Solar-Lezama and Leslie Pack Kaelbling},
  journal={ArXiv},
  year={2017},
  volume={abs/1711.03243}
}

@inproceedings{dsl-6,
  title={Z3: An Efficient SMT Solver},
  author={Leonardo Mendonça de Moura and Nikolaj S. Bj{\o}rner},
  booktitle={International Conference on Tools and Algorithms for Construction and Analysis of Systems},
  year={2008}
}

@inproceedings{pg-1,
  title={PHOG: probabilistic model for code},
  author={Bielik, Pavol and Raychev, Veselin and Vechev, Martin},
  booktitle={International Conference on Machine Learning},
  pages={2933--2942},
  year={2016},
  organization={PMLR}
}

@article{pg-2,
  title={Probabilistic model for code with decision trees},
  author={Raychev, Veselin and Bielik, Pavol and Vechev, Martin},
  journal={ACM SIGPLAN Notices},
  volume={51},
  number={10},
  pages={731--747},
  year={2016},
  publisher={ACM New York, NY, USA}
}

@inproceedings{pg-3,
  title={A formalism for dependency grammar based on tree adjoining grammar},
  author={Joshi, Aravind and Rambow, Owen},
  booktitle={Proceedings of the Conference on Meaning-text Theory},
  pages={207--216},
  year={2003},
  organization={MTT Paris, France}
}

@article{pg-4,
  title={Inducing tree-substitution grammars},
  author={Cohn, Trevor and Blunsom, Phil and Goldwater, Sharon},
  journal={The Journal of Machine Learning Research},
  volume={11},
  pages={3053--3096},
  year={2010},
  publisher={JMLR. org}
}

@inproceedings{pg-5,
  title={Mining idioms from source code},
  author={Allamanis, Miltiadis and Sutton, Charles},
  booktitle={Proceedings of the 22nd acm sigsoft international symposium on foundations of software engineering},
  pages={472--483},
  year={2014}
}

@article{hidden-markov,
  title={The recurrent temporal restricted boltzmann machine},
  author={Sutskever, Ilya and Hinton, Geoffrey E and Taylor, Graham W},
  journal={Neural Information Processing Systems},
  volume={21},
  year={2008}
}

@article{ngram-1,
  title={On the naturalness of software},
  author={Premkumar T. Devanbu},
  journal={2012 34th International Conference on Software Engineering (ICSE)},
  year={2012},
  pages={837-847}
}

@inproceedings{ngram-2,
  title={A statistical semantic language model for source code},
  author={Nguyen, Tung Thanh and Nguyen, Anh Tuan and Nguyen, Hoan Anh and Nguyen, Tien N},
  booktitle={Proceedings of the 2013 9th Joint Meeting on Foundations of Software Engineering},
  pages={532--542},
  year={2013}
}

@inproceedings{ngram-3,
  title={Code completion with statistical language models},
  author={Raychev, Veselin and Vechev, Martin and Yahav, Eran},
  booktitle={Proceedings of the 35th ACM SIGPLAN Conference on Programming Language Design and Implementation},
  pages={419--428},
  year={2014}
}

@inproceedings{ngram-4,
  title={Program Synthesis for Character Level Language Modeling},
  author={Pavol Bielik and Veselin Raychev and Martin T. Vechev},
  booktitle={International Conference on Learning Representations},
  year={2016}
}

@inproceedings{ngram-5,
  title={Are deep neural networks the best choice for modeling source code?},
  author={Hellendoorn, Vincent J and Devanbu, Premkumar},
  booktitle={Proceedings of the 2017 11th Joint Meeting on Foundations of Software Engineering},
  pages={763--773},
  year={2017}
}

@inproceedings{nn-1,
  title={Connectionist language modeling for large vocabulary continuous speech recognition},
  author={Schwenk, Holger and Gauvain, Jean-Luc},
  booktitle={2002 IEEE International Conference on Acoustics, Speech, and Signal Processing},
  volume={1},
  pages={I--765},
  year={2002},
  organization={IEEE}
}

@inproceedings{nn-2,
  title={Three new graphical models for statistical language modelling},
  author={Mnih, Andriy and Hinton, Geoffrey},
  booktitle={International Conference on Machine Learning},
  pages={641--648},
  year={2007}
}

@inproceedings{nn-3,
  title={Structured generative models of natural source code},
  author={Maddison, Chris and Tarlow, Daniel},
  booktitle={International Conference on Machine Learning},
  pages={649--657},
  year={2014},
  organization={PMLR}
}

@inproceedings{nn-4,
  title={Bimodal modelling of source code and natural language},
  author={Allamanis, Miltos and Tarlow, Daniel and Gordon, Andrew and Wei, Yi},
  booktitle={International Conference on Machine Learning},
  pages={2123--2132},
  year={2015},
  organization={PMLR}
}

@inproceedings{nn-5,
  title={Suggesting accurate method and class names},
  author={Allamanis, Miltiadis and Barr, Earl T and Bird, Christian and Sutton, Charles},
  booktitle={Proceedings of the 2015 10th joint meeting on foundations of software engineering},
  pages={38--49},
  year={2015}
}

@inproceedings{bert,
  title={{BERT}: Pre-training of Deep Bidirectional Transformers for Language Understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  booktitle={Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)},
  pages={4171--4186},
  year={2019}
}

@inproceedings{s2ql,
  title={{S2QL}: Retrieval Augmented Zero-Shot Question Answering over Knowledge Graph},
  author={Daoguang Zan and Sirui Wang and Hongzhi Zhang and Yuanmeng Yan and Wei Wu and Bei Guan and Yongji Wang},
  booktitle={Pacific-Asia Conference on Knowledge Discovery and Data Mining},
  year={2022}
}

@article{gpt3,
  title={Language Models are Few-Shot Learners},
  author={Tom B. Brown and Benjamin Mann and Nick Ryder and Melanie Subbiah and Jared Kaplan and Prafulla Dhariwal and Arvind Neelakantan and Pranav Shyam and Girish Sastry and Amanda Askell and Sandhini Agarwal and Ariel Herbert-Voss and Gretchen Krueger and T. J. Henighan and Rewon Child and Aditya Ramesh and Daniel M. Ziegler and Jeff Wu and Clemens Winter and Christopher Hesse and Mark Chen and Eric Sigler and Mateusz Litwin and Scott Gray and Benjamin Chess and Jack Clark and Christopher Berner and Sam McCandlish and Alec Radford and Ilya Sutskever and Dario Amodei},
  journal={Neural Information Processing Systems},
  volume={33},
  pages={1877--1901},
  year={2020}
}

@inproceedings{bart,
  title={{BART}: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension},
  author={Lewis, Mike and Liu, Yinhan and Goyal, Naman and Ghazvininejad, Marjan and Mohamed, Abdelrahman and Levy, Omer and Stoyanov, Veselin and Zettlemoyer, Luke},
  booktitle={Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics},
  pages={7871--7880},
  year={2020}
}

@article{t5,
  title={Exploring the limits of transfer learning with a unified text-to-text transformer},
  author={Raffel, Colin and Shazeer, Noam and Roberts, Adam and Lee, Katherine and Narang, Sharan and Matena, Michael and Zhou, Yanqi and Li, Wei and Liu, Peter J},
  journal={The Journal of Machine Learning Research},
  volume={21},
  number={1},
  pages={5485--5551},
  year={2020},
  publisher={JMLRORG}
}

@inproceedings{cnn-1,
  title={A Grammar-Based Structural CNN Decoder for Code Generation},
  author={Zeyu Sun and Qihao Zhu and Lili Mou and Yingfei Xiong and Ge Li and Lu Zhang},
  booktitle={AAAI Conference on Artificial Intelligence},
  year={2018}
}

@inproceedings{cnn-2,
  title={Automatic code generation of convolutional neural networks in FPGA implementation},
  author={Liu, Zhiqiang and Dou, Yong and Jiang, Jingfei and Xu, Jinwei},
  booktitle={2016 International conference on field-programmable technology (FPT)},
  pages={61--68},
  year={2016},
  organization={IEEE}
}

@article{rnn-lstm-1,
  title={Summarizing Source Code using a Neural Attention Model},
  author={Srini Iyer and Ioannis Konstas and Alvin Cheung and Luke Zettlemoyer},
  journal={Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  year={2016}
}

@inproceedings{rnn-2,
  title={Improving automatic source code summarization via deep reinforcement learning},
  author={Wan, Yao and Zhao, Zhou and Yang, Min and Xu, Guandong and Ying, Haochao and Wu, Jian and Yu, Philip S},
  booktitle={Proceedings of the 33rd ACM/IEEE international conference on automated software engineering},
  pages={397--407},
  year={2018}
}

@inproceedings{lstm-2,
  title={Tree-to-Sequence Attentional Neural Machine Translation},
  author={Eriguchi, Akiko and Hashimoto, Kazuma and Tsuruoka, Yoshimasa},
  booktitle={Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages={823--833},
  year={2016}
}

@article{lstm-3,
  title={Code generation as a dual task of code summarization},
  author={Wei, Bolin and Li, Ge and Xia, Xin and Fu, Zhiyi and Jin, Zhi},
  journal={Neural Information Processing Systems},
  volume={32},
  year={2019}
}

@article{lstm-4,
  title={A syntactic neural model for general-purpose code generation},
  author={Yin, Pengcheng and Neubig, Graham},
  journal={arXiv preprint arXiv:1704.01696},
  year={2017}
}

@inproceedings{gan-1,
  title={{GANCoder}: An automatic natural language-to-programming language translation approach based on GAN},
  author={Zhu, Yabing and Zhang, Yanfeng and Yang, Huili and Wang, Fangjing},
  booktitle={CCF International Conference on Natural Language Processing and Chinese Computing},
  pages={529--539},
  year={2019},
  organization={Springer}
}

@inproceedings{gan-2,
  title={Compilable Neural Code Generation with Compiler Feedback},
  author={Wang, Xin and Wang, Yasheng and Wan, Yao and Mi, Fei and Li, Yitong and Zhou, Pingyi and Liu, Jin and Wu, Hao and Jiang, Xin and Liu, Qun},
  booktitle={Findings of the Association for Computational Linguistics: ACL 2022},
  pages={9--19},
  year={2022}
}

@inproceedings{sl-1,
  title={Abstract Syntax Networks for Code Generation and Semantic Parsing},
  author={Rabinovich, Maxim and Stern, Mitchell and Klein, Dan},
  booktitle={Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages={1139--1149},
  year={2017}
}

@inproceedings{mtl-1,
  title={{CoTexT}: Multi-task Learning with Code-Text Transformer},
  author={Phan, Long and Tran, Hieu and Le, Daniel and Nguyen, Hieu and Annibal, James and Peltekian, Alec and Ye, Yanfang},
  booktitle={Proceedings of the 1st Workshop on Natural Language Processing for Programming (NLP4Prog 2021)},
  pages={40--47},
  year={2021}
}

@inproceedings{mtl-2,
  title={Multi-task learning based pre-trained language model for code completion},
  author={Liu, Fang and Li, Ge and Zhao, Yunfei and Jin, Zhi},
  booktitle={Proceedings of the 35th IEEE/ACM International Conference on Automated Software Engineering},
  pages={473--485},
  year={2020}
}

@inproceedings{mtl-3,
  title={Leveraging code generation to improve code retrieval and summarization via dual learning},
  author={Ye, Wei and Xie, Rui and Zhang, Jinglei and Hu, Tianxiang and Wang, Xiaoyin and Zhang, Shikun},
  booktitle={Proceedings of The Web Conference 2020},
  pages={2309--2319},
  year={2020}
}

@inproceedings{cl-1,
  title={Contrastive Code Representation Learning},
  author={Paras Jain and Ajay Jain and Tianjun Zhang and P. Abbeel and Joseph Gonzalez and Ion Stoica},
  booktitle={Conference on Empirical Methods in Natural Language Processing},
  year={2020}
}

@inproceedings{cl-2,
  title={Self-supervised contrastive learning for code retrieval and summarization via semantic-preserving transformations},
  author={Bui, Nghi DQ and Yu, Yijun and Jiang, Lingxiao},
  booktitle={Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval},
  pages={511--521},
  year={2021}
}

@article{cl-3,
  title={Text and Code Embeddings by Contrastive Pre-Training},
  author={Arvind Neelakantan and Tao Xu and Raul Puri and Alec Radford and Jesse Michael Han and Jerry Tworek and Qiming Yuan and Nikolas A. Tezak and Jong Wook Kim and Chris Hallacy and Johannes Heidecke and Pranav Shyam and Boris Power and Tyna Eloundou Nekoul and Girish Sastry and Gretchen Krueger and David P. Schnurr and Felipe Petroski Such and Kenny Sai-Kin Hsu and Madeleine Thompson and Tabarak Khan and Toki Sherbakov and Joanne Jang and Peter Welinder and Lilian Weng},
  journal={ArXiv},
  year={2022},
  volume={abs/2201.10005}
}

@inproceedings{retri-3,
  title={Retrieval-Based Neural Code Generation},
  author={Hayati, Shirley Anugrah and Olivier, Raphael and Avvaru, Pravalika and Yin, Pengcheng and Tomasic, Anthony and Neubig, Graham},
  booktitle={Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing},
  pages={925--930},
  year={2018}
}

@article{retri-1,
  title={{ReACC}: A Retrieval-Augmented Code Completion Framework},
  author={Lu, Shuai and Duan, Nan and Han, Hojae and Guo, Daya and Hwang, Seung-won and Svyatkovskiy, Alexey},
  journal={arXiv preprint arXiv:2203.07722},
  year={2022}
}

@inproceedings{retri-2,
  title={{DocCoder}: Generating Code by Retrieving and Reading Docs},
  author={Zhou, Shuyan and Alon, Uri and Xu, Frank F and JIang, Zhengbao and Neubig, Graham},
  booktitle={The Eleventh International Conference on Learning Representations},
  year={2023}
}

@article{np-1,
  title={A deep language model for software code},
  author={Dam, Hoa Khanh and Tran, Truyen and Pham, Trang},
  journal={arXiv preprint arXiv:1608.02715},
  year={2016}
}

@article{np-2,
  title={Program synthesis from natural language using recurrent neural networks},
  author={Lin, Xi Victoria and Wang, Chenglong and Pang, Deric and Vu, Kevin and Ernst, Michael D},
  journal={University of Washington Department of Computer Science and Engineering, Seattle, WA, USA, Tech. Rep. UW-CSE-17-03-01},
  year={2017}
}

@inproceedings{pf-1,
  title={Incorporating External Knowledge through Pre-training for Natural Language to Code Generation},
  author={Xu, Frank F and Jiang, Zhengbao and Yin, Pengcheng and Vasilescu, Bogdan and Neubig, Graham},
  booktitle={Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics},
  pages={6045--6052},
  year={2020}
}

@article{few-shot-1,
  title={Code4Struct: Code Generation for Few-Shot Structured Prediction from Natural Language},
  author={Wang, Xingyao and Li, Sha and Ji, Heng},
  journal={arXiv preprint arXiv:2210.12810},
  year={2022}
}

@article{few-shot-2,
  title={Language models of code are few-shot commonsense learners},
  author={Madaan, Aman and Zhou, Shuyan and Alon, Uri and Yang, Yiming and Neubig, Graham},
  journal={arXiv preprint arXiv:2210.07128},
  year={2022}
}

@inproceedings{prompt-tune-1,
  title={No more fine-tuning? an experimental evaluation of prompt tuning in code intelligence},
  author={Wang, Chaozheng and Yang, Yuanhang and Gao, Cuiyun and Peng, Yun and Zhang, Hongyu and Lyu, Michael R},
  booktitle={Proceedings of the 30th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
  pages={382--394},
  year={2022}
}

@article{prompt-engineering,
  title={Pre-train, prompt, and predict: A systematic survey of prompting methods in natural language processing},
  author={Liu, Pengfei and Yuan, Weizhe and Fu, Jinlan and Jiang, Zhengbao and Hayashi, Hiroaki and Neubig, Graham},
  journal={ACM Computing Surveys},
  volume={55},
  number={9},
  pages={1--35},
  year={2023},
  publisher={ACM New York, NY}
}

@article{incontext-1,
  title={Evaluating the Text-to-SQL Capabilities of Large Language Models},
  author={Rajkumar, Nitarshan and Li, Raymond and Bahdanau, Dzmitry},
  journal={arXiv preprint arXiv:2204.00498},
  year={2022}
}

@article{incontext-2,
  title={{CodexDB}: Synthesizing code for query processing from natural language instructions using GPT-3 Codex},
  author={Trummer, Immanuel},
  journal={Proceedings of the VLDB Endowment},
  volume={15},
  number={11},
  pages={2921--2928},
  year={2022},
  publisher={VLDB Endowment}
}

@article{incontext-3,
  title={Synchromesh: Reliable code generation from pre-trained language models},
  author={Poesia, Gabriel and Polozov, Oleksandr and Le, Vu and Tiwari, Ashish and Soares, Gustavo and Meek, Christopher and Gulwani, Sumit},
  journal={arXiv preprint arXiv:2201.11227},
  year={2022}
}

@article{codebias-1,
  title={A Simple, Yet Effective Approach to Finding Biases in Code Generation},
  author={Mouselinos, Spyridon and Malinowski, Mateusz and Michalewski, Henryk},
  journal={arXiv preprint arXiv:2211.00609},
  year={2022}
}

@article{codebias-2,
  title={Capturing Failures of Large Language Models via Human Cognitive Biases},
  author={Jones, Erik and Steinhardt, Jacob},
  journal={arXiv preprint arXiv:2202.12299},
  year={2022}
}

@article{compressing-1,
  title={Compressing Pre-trained Models of Code into 3 MB},
  author={Shi, Jieke and Yang, Zhou and Xu, Bowen and Kang, Hong Jin and Lo, David},
  journal={arXiv preprint arXiv:2208.07120},
  year={2022}
}

@inproceedings{compressing-2,
  title={Diet code is healthy: Simplifying programs for pre-trained models of code},
  author={Zhang, Zhaowei and Zhang, Hongyu and Shen, Beijun and Gu, Xiaodong},
  booktitle={Proceedings of the 30th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
  pages={1073--1084},
  year={2022}
}

@article{interpret-1,
  title={{WhyGen}: Explaining ML-powered Code Generation by Referring to Training Examples},
  author={Yan, Weixiang and Li, Yuanchun},
  journal={arXiv preprint arXiv:2204.07940},
  year={2022}
}

@inproceedings{interpret-2,
  title={Generating Diverse Code Explanations using the GPT-3 Large Language Model},
  author={MacNeil, Stephen and Tran, Andrew and Mogil, Dan and Bernstein, Seth and Ross, Erin and Huang, Ziheng},
  booktitle={Proceedings of the 2022 ACM Conference on International Computing Education Research-Volume 2},
  pages={37--39},
  year={2022}
}

@article{ide-1,
  title={An analysis of tools for automatic software development and automatic code generation},
  author={Alor-Hern{\'a}ndez, Giner and Rosales-Morales, Viviana Yarel and Alcar{\'a}z, Jorge Luis Garc{\'\i}a and Cabada, Ram{\'o}n Zatarain and Estrada, Mar{\'\i}a Luc{\'\i}a Barr{\'o}n},
  journal={Revista Facultad de Ingenier{\'\i}a Universidad de Antioquia},
  pages={75--87},
  year={2015}
}

@article{ide-2,
  title={In-ide code generation from natural language: Promise and challenges},
  author={Xu, Frank F and Vasilescu, Bogdan and Neubig, Graham},
  journal={ACM Transactions on Software Engineering and Methodology (TOSEM)},
  volume={31},
  number={2},
  pages={1--47},
  year={2022},
  publisher={ACM New York, NY}
}

@inproceedings{dynamic-static,
  title={{CodeAlchemist}: Semantics-Aware Code Generation to Find Vulnerabilities in JavaScript Engines.},
  author={Han, HyungSeok and Oh, DongHyeon and Cha, Sang Kil},
  booktitle={NDSS},
  year={2019}
}

@inproceedings{object-1,
  title={Mlir: Scaling compiler infrastructure for domain specific computation},
  author={Lattner, Chris and Amini, Mehdi and Bondhugula, Uday and Cohen, Albert and Davis, Andy and Pienaar, Jacques and Riddle, River and Shpeisman, Tatiana and Vasilache, Nicolas and Zinenko, Oleksandr},
  booktitle={2021 IEEE/ACM International Symposium on Code Generation and Optimization (CGO)},
  pages={2--14},
  year={2021},
  organization={IEEE}
}

@article{aspect-1,
  title={Systematic mapping study of template-based code generation},
  author={Syriani, Eugene and Luhunu, Lechanceux and Sahraoui, Houari},
  journal={Computer Languages, Systems \& Structures},
  volume={52},
  pages={43--62},
  year={2018},
  publisher={Elsevier}
}

@inproceedings{repository,
  title={Repository-Level Prompt Generation for Large Language Models of Code},
  author={Shrivastava, Disha and Larochelle, Hugo and Tarlow, Daniel},
  year={2022},
  booktitle={ICML 2022 Workshop on Knowledge Retrieval and Language Models}
}

@article{graphcodebert,
  title={{GraphCodeBERT}: Pre-training Code Representations with Data Flow},
  author={Daya Guo and Shuo Ren and Shuai Lu and Zhangyin Feng and Duyu Tang and Shujie Liu and Long Zhou and Nan Duan and Jian Yin and Daxin Jiang and M. Zhou},
  journal={ArXiv},
  year={2020},
  volume={abs/2009.08366}
}

@article{graphcodegpt,
  title={Improving Text-to-Code Generation with Features of Code Graph on GPT-2},
  author={Paik, Incheon and Wang, Jun-Wei},
  journal={Electronics},
  volume={10},
  number={21},
  pages={2706},
  year={2021},
  publisher={MDPI}
}

@article{stackoverflow-1,
  title={Evaluating How Fine-tuning on Bimodal Data Effects Code Generation},
  author={Orlanski, Gabriel and Yang, Seonhye and Healy, Michael},
  journal={arXiv preprint arXiv:2211.07842},
  year={2022}
}

@inproceedings{stackoverflow-2,
  title={Reading StackOverflow Encourages Cheating: Adding Question Text Improves Extractive Code Generation},
  author={Orlanski, Gabriel and Gittens, Alex},
  booktitle={Proceedings of the 1st Workshop on Natural Language Processing for Programming (NLP4Prog 2021)},
  pages={65--76},
  year={2021}
}

@article{stackoverflow-3,
  title={Generating code with the help of retrieved template functions and stack overflow answers},
  author={Drain, Dawn and Hu, Changran and Wu, Chen and Breslav, Mikhail and Sundaresan, Neel},
  journal={arXiv preprint arXiv:2104.05310},
  year={2021}
}

@article{transformer,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={Neural Information Processing Systems},
  volume={30},
  year={2017}
}

@article{gpt-1,
  title={Improving language understanding by generative pre-training},
  author={Radford, Alec and Narasimhan, Karthik and Salimans, Tim and Sutskever, Ilya and others},
  journal={OpenAI blog},
  year={2018},
  publisher={OpenAI}
}

@article{gpt-2,
  title={Language models are unsupervised multitask learners},
  author={Alec Radford and Jeff Wu and Rewon Child and David Luan and Dario Amodei and Ilya Sutskever},
  journal={OpenAI blog},
  volume={1},
  number={8},
  pages={9},
  year={2019}
}

@inproceedings{copilot-1,
  title={Choose your programming copilot: a comparison of the program synthesis performance of github copilot and genetic programming},
  author={Sobania, Dominik and Briesch, Martin and Rothlauf, Franz},
  booktitle={Proceedings of the Genetic and Evolutionary Computation Conference},
  pages={1019--1027},
  year={2022}
}

@inproceedings{copilot-2,
  title={Asleep at the keyboard? assessing the security of github copilot’s code contributions},
  author={Pearce, Hammond and Ahmad, Baleegh and Tan, Benjamin and Dolan-Gavitt, Brendan and Karri, Ramesh},
  booktitle={2022 IEEE Symposium on Security and Privacy (SP)},
  pages={754--768},
  year={2022},
  organization={IEEE}
}

@inproceedings{copilot-3,
  title={An empirical evaluation of GitHub copilot's code suggestions},
  author={Nguyen, Nhan and Nadi, Sarah},
  booktitle={Proceedings of the 19th International Conference on Mining Software Repositories},
  pages={1--5},
  year={2022}
}

@inproceedings{copilot-4,
  title={Expectation vs. Experience: Evaluating the Usability of Code Generation Tools Powered by Large Language Models},
  author={Vaithilingam, Priyan and Zhang, Tianyi and Glassman, Elena L},
  booktitle={CHI Conference on Human Factors in Computing Systems Extended Abstracts},
  pages={1--7},
  year={2022}
}

@inproceedings{copilot-5,
  title={Is GitHub copilot a substitute for human pair-programming? An empirical study},
  author={Imai, Saki},
  booktitle={Proceedings of the ACM/IEEE 44th International Conference on Software Engineering: Companion Proceedings},
  pages={319--321},
  year={2022}
}

@article{copilot-6,
  title={AI-Driven Development Is Here: Should You Worry?},
  author={Ernst, Neil A and Bavota, Gabriele},
  journal={IEEE Software},
  volume={39},
  number={2},
  pages={106--110},
  year={2022},
  publisher={IEEE}
}

@article{copilot-7,
  title={{Grounded Copilot}: How Programmers Interact with Code-Generating Models},
  author={Barke, Shraddha and James, Michael B and Polikarpova, Nadia},
  journal={arXiv preprint arXiv:2206.15000},
  year={2022}
}

@article{out-bleu,
  title={{Out of the BLEU}: how should we assess quality of the Code Generation models?},
  author={Evtikhiev, Mikhail and Bogomolov, Egor and Sokolov, Yaroslav and Bryksin, Timofey},
  journal={arXiv preprint arXiv:2208.03133},
  year={2022}
}

@inproceedings{nlp-metrics,
  title={Are NLP Metrics Suitable for Evaluating Generated Code?},
  author={Takaichi, Riku and Higo, Yoshiki and Matsumoto, Shinsuke and Kusumoto, Shinji and Kurabayashi, Toshiyuki and Kirinuki, Hiroyuki and Tanno, Haruto},
  booktitle={International Conference on Product-Focused Software Process Improvement},
  pages={531--537},
  year={2022},
  organization={Springer}
}

@article{yang2022exploitgen,
  title={{ExploitGen}: Template-augmented exploit code generation based on CodeBERT},
  author={Yang, Guang and Zhou, Yu and Chen, Xiang and Zhang, Xiangyu and Han, Tingting and Chen, Taolue},
  journal={Journal of Systems and Software},
  pages={111577},
  year={2022},
  publisher={Elsevier}
}

@inproceedings{bleu,
  title={{BLEU}: a method for automatic evaluation of machine translation},
  author={Papineni, Kishore and Roukos, Salim and Ward, Todd and Zhu, Wei-Jing},
  booktitle={Proceedings of the 40th annual meeting of the Association for Computational Linguistics},
  pages={311--318},
  year={2002}
}

@inproceedings{rouge,
  title={{ROUGE}: A package for automatic evaluation of summaries},
  author={Lin, Chin-Yew},
  booktitle={Text summarization branches out},
  pages={74--81},
  year={2004}
}

@inproceedings{meteor,
  title={Meteor universal: Language specific translation evaluation for any target language},
  author={Denkowski, Michael and Lavie, Alon},
  booktitle={Proceedings of the ninth workshop on statistical machine translation},
  pages={376--380},
  year={2014}
}

@inproceedings{chrf,
  title={{chrF}: character n-gram F-score for automatic MT evaluation},
  author={Popovi{\'c}, Maja},
  booktitle={Proceedings of the Tenth Workshop on Statistical Machine Translation},
  pages={392--395},
  year={2015}
}

@article{emn-1,
  title={Long-Range Modeling of Source Code Files with eWASH: Extended Window Access by Syntax Hierarchy},
  author={Clement, Colin B and Lu, Shuai and Liu, Xiaoyu and Tufano, Michele and Drain, Dawn and Duan, Nan and Sundaresan, Neel and Svyatkovskiy, Alexey},
  journal={arXiv preprint arXiv:2109.08780},
  year={2021}
}

@inproceedings{emn-2,
  title={SQuAD: 100,000+ Questions for Machine Comprehension of Text},
  author={Rajpurkar, Pranav and Zhang, Jian and Lopyrev, Konstantin and Liang, Percy},
  booktitle={Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing},
  pages={2383--2392},
  year={2016}
}

@inproceedings{tran2019does,
  title={Does BLEU score work for code migration?},
  author={Tran, Ngoc and Tran, Hieu and Nguyen, Son and Nguyen, Hoan and Nguyen, Tien},
  booktitle={2019 IEEE/ACM 27th International Conference on Program Comprehension (ICPC)},
  pages={165--176},
  year={2019},
  organization={IEEE}
}

@article{codebleu,
  title={{CodeBLEU}: a method for automatic evaluation of code synthesis},
  author={Ren, Shuo and Guo, Daya and Lu, Shuai and Zhou, Long and Liu, Shujie and Tang, Duyu and Sundaresan, Neel and Zhou, Ming and Blanco, Ambrosio and Ma, Shuai},
  journal={arXiv preprint arXiv:2009.10297},
  year={2020}
}

@inproceedings{edit-knowledge-1,
  title={Editing Factual Knowledge in Language Models},
  author={De Cao, Nicola and Aziz, Wilker and Titov, Ivan},
  booktitle={Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing},
  pages={6491--6506},
  year={2021}
}

@inproceedings{edit-knowledge-2,
  title={Locating and editing factual associations in gpt},
  author={Meng, Kevin and Bau, David and Andonian, Alex J and Belinkov, Yonatan},
  booktitle={Neural Information Processing Systems},
  year={2022}
}

@inproceedings{yan2021large,
  title={Large-Scale Relation Learning for Question Answering over Knowledge Bases with Pre-trained Language Models},
  author={Yan, Yuanmeng and Li, Rumei and Wang, Sirui and Zhang, Hongzhi and Daoguang, Zan and Zhang, Fuzheng and Wu, Wei and Xu, Weiran},
  booktitle={Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing},
  pages={3653--3660},
  year={2021}
}

@article{prompt-edit-1,
  title={Grips: Gradient-free, edit-based instruction search for prompting large language models},
  author={Prasad, Archiki and Hase, Peter and Zhou, Xiang and Bansal, Mohit},
  journal={arXiv preprint arXiv:2203.07281},
  year={2022}
}

@inproceedings{prompt-edit-2,
  title={Novelty Controlled Paraphrase Generation with Retrieval Augmented Conditional Prompt Tuning},
  author={Jishnu Ray Chowdhury and Yong Zhuang and Shuyi Wang},
  booktitle={AAAI Conference on Artificial Intelligence},
  year={2022}
}

@article{instructgpt,
  title={Training language models to follow instructions with human feedback},
  author={Long Ouyang and Jeff Wu and Xu Jiang and Diogo Almeida and Carroll L. Wainwright and Pamela Mishkin and Chong Zhang and Sandhini Agarwal and Katarina Slama and Alex Ray and John Schulman and Jacob Hilton and Fraser Kelton and Luke E. Miller and Maddie Simens and Amanda Askell and Peter Welinder and Paul Francis Christiano and Jan Leike and Ryan J. Lowe},
  journal={ArXiv},
  year={2022},
  volume={abs/2203.02155}
}

@inproceedings{knowledge-language-1,
  title={Jaket: Joint pre-training of knowledge graph and language understanding},
  author={Yu, Donghan and Zhu, Chenguang and Yang, Yiming and Zeng, Michael},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  number={10},
  pages={11630--11638},
  year={2022}
}

@article{knowledge-language-2,
  title={Enriching contextualized language model from knowledge graph for biomedical information extraction},
  author={Fei, Hao and Ren, Yafeng and Zhang, Yue and Ji, Donghong and Liang, Xiaohui},
  journal={Briefings in bioinformatics},
  volume={22},
  number={3},
  pages={bbaa110},
  year={2021},
  publisher={Oxford University Press}
}

@inproceedings{compress-1,
  title={Model compression via distillation and quantization},
  author={Polino, Antonio and Pascanu, Razvan and Alistarh, Dan},
  booktitle={International Conference on Learning Representations},
  year={2018}
}

@article{compress-2,
  title={Knowledge distillation: A survey},
  author={Gou, Jianping and Yu, Baosheng and Maybank, Stephen J and Tao, Dacheng},
  journal={International Journal of Computer Vision},
  volume={129},
  number={6},
  pages={1789--1819},
  year={2021},
  publisher={Springer}
}

@article{edu-1,
  title={Limits of an AI program for solving college math problems},
  author={Davis, Ernest},
  journal={arXiv preprint arXiv:2208.06906},
  year={2022}
}

@inproceedings{edu-2,
  title={Automatic Programming and Education},
  author={Lewis, Clayton},
  booktitle={Proceedings of the 6th International Conference on the Art, Science, and Engineering of Programming},
  pages={70--80},
  year={2022}
}

@inproceedings{edu-3,
  title={Automatic Generation of Programming Exercises and Code Explanations Using Large Language Models},
  author={Sarsa, Sami and Denny, Paul and Hellas, Arto and Leinonen, Juho},
  booktitle={Proceedings of the 2022 ACM Conference on International Computing Education Research-Volume 1},
  pages={27--43},
  year={2022}
}

@article{edu-4,
  title={Automatically Generating CS Learning Materials with Large Language Models},
  author={MacNeil, Stephen and Tran, Andrew and Leinonen, Juho and Denny, Paul and Kim, Joanne and Hellas, Arto and Bernstein, Seth and Sarsa, Sami},
  journal={arXiv preprint arXiv:2212.05113},
  year={2022}
}

@article{chem-1,
  title={SELFIES and the future of molecular string representations},
  author={Krenn, Mario and Ai, Qianxiang and Barthel, Senja and Carson, Nessa and Frei, Angelo and Frey, Nathan C and Friederich, Pascal and Gaudin, Th{\'e}ophile and Gayle, Alberto Alexander and Jablonka, Kevin Maik and others},
  journal={Patterns},
  volume={3},
  number={10},
  pages={100588},
  year={2022},
  publisher={Elsevier}
}

@article{edu-5-chem-2,
  title={Natural language processing models that automate programming will transform chemistry research and teaching},
  author={Hocky, Glen M and White, Andrew D},
  journal={Digital discovery},
  volume={1},
  number={2},
  pages={79--83},
  year={2022},
  publisher={Royal Society of Chemistry}
}

@article{edu-6,
  title={A Dataset and Benchmark for Automatically Answering and Generating Machine Learning Final Exams},
  author={Zhang, Sarah and Shuttleworth, Reece and Austin, Derek and Hicke, Yann and Tang, Leonard and Karnik, Sathwik and Granberry, Darnell and Drori, Iddo},
  journal={arXiv preprint arXiv:2206.05442},
  year={2022}
}

@article{math-1,
  title={A neural network solves, explains, and generates university math problems by program synthesis and few-shot learning at human level},
  author={Iddo Drori and Sarah Zhang and Reece Shuttleworth and Leonard Tang and Albert Lu and Elizabeth Ke and Kevin Liu and Linda Chen and Sunny Tran and Newman Cheng and Roman Wang and Nikhil Singh and Taylor Lee Patti and J. Lynch and Avi Shporer and Nakul Verma and Eugene Wu and Gilbert Strang},
  journal={Proceedings of the National Academy of Sciences of the United States of America},
  year={2021},
  volume={119}
}

@article{math-2,
  title={Solving linear algebra by program synthesis},
  author={Drori, Iddo and Verma, Nakul},
  journal={arXiv preprint arXiv:2111.08171},
  year={2021}
}

@article{math-3,
  title={Solving probability and statistics problems by program synthesis},
  author={Tang, Leonard and Ke, Elizabeth and Singh, Nikhil and Verma, Nakul and Drori, Iddo},
  journal={arXiv preprint arXiv:2111.08267},
  year={2021}
}

@article{robot-1,
  title={Evolution through Large Models},
  author={Joel Lehman and Jonathan Gordon and Shawn Jain and Kamal Ndousse and Cathy Yeh and Kenneth O. Stanley},
  journal={ArXiv},
  year={2022},
  volume={abs/2206.08896}
}

@article{bug-1,
  title={Self-critiquing models for assisting human evaluators},
  author={Saunders, William and Yeh, Catherine and Wu, Jeff and Bills, Steven and Ouyang, Long and Ward, Jonathan and Leike, Jan},
  journal={arXiv preprint arXiv:2206.05802},
  year={2022}
}

@article{repair-1,
  title={Repair is nearly generation: Multilingual program repair with llms},
  author={Joshi, Harshit and Cambronero, Jos{\'e} and Gulwani, Sumit and Le, Vu and Radicek, Ivan and Verbruggen, Gust},
  journal={arXiv preprint arXiv:2208.11640},
  year={2022}
}

@article{repair-2,
  title={Automatic Program Repair with OpenAI's Codex: Evaluating QuixBugs},
  author={Prenner, Julian Aron and Robbes, Romain},
  journal={arXiv preprint arXiv:2111.03922},
  year={2021}
}

@article{reasoning-1,
  title={Program of Thoughts Prompting: Disentangling Computation from Reasoning for Numerical Reasoning Tasks},
  author={Chen, Wenhu and Ma, Xueguang and Wang, Xinyi and Cohen, William W},
  journal={arXiv preprint arXiv:2211.12588},
  year={2022}
}

@article{reasoning-2,
  title={Chain of thought prompting elicits reasoning in large language models},
  author={Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Chi, Ed and Le, Quoc and Zhou, Denny},
  journal={arXiv preprint arXiv:2201.11903},
  year={2022}
}

@article{reasoning-3,
  title={Teaching Algorithmic Reasoning via In-context Learning},
  author={Zhou, Hattie and Nova, Azade and Larochelle, Hugo and Courville, Aaron and Neyshabur, Behnam and Sedghi, Hanie},
  journal={arXiv preprint arXiv:2211.09066},
  year={2022}
}

@article{bug-location-fix,
  title={Repairing Bugs in Python Assignments Using Large Language Models},
  author={Zhang, Jialu and Cambronero, Jos{\'e} and Gulwani, Sumit and Le, Vu and Piskac, Ruzica and Soares, Gustavo and Verbruggen, Gust},
  journal={arXiv preprint arXiv:2209.14876},
  year={2022}
}

@inproceedings{code-review,
  title={Automating code review activities by large-scale pre-training},
  author={Li, Zhiyu and Lu, Shuai and Guo, Daya and Duan, Nan and Jannu, Shailesh and Jenks, Grant and Majumder, Deep and Green, Jared and Svyatkovskiy, Alexey and Fu, Shengyu and others},
  booktitle={Proceedings of the 30th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
  pages={1035--1047},
  year={2022}
}

@article{code-retrieval,
  title={Text and code embeddings by contrastive pre-training},
  author={Neelakantan, Arvind and Xu, Tao and Puri, Raul and Radford, Alec and Han, Jesse Michael and Tworek, Jerry and Yuan, Qiming and Tezak, Nikolas and Kim, Jong Wook and Hallacy, Chris and others},
  journal={arXiv preprint arXiv:2201.10005},
  year={2022}
}

@article{ernie-code,
  title={{ERNIE-Code}: Beyond English-Centric Cross-lingual Pretraining for Programming Languages},
  author={Chai, Yekun and Wang, Shuohuan and Pang, Chao and Sun, Yu and Tian, Hao and Wu, Hua},
  journal={arXiv preprint arXiv:2212.06742},
  year={2022}
}

@misc{gpt-j,
  author = {Wang, Ben and Komatsuzaki, Aran},
  title = {{GPT-J-6B: A 6 Billion Parameter Autoregressive Language Model}},
  howpublished = {\url{https://github.com/kingoflolz/mesh-transformer-jax}},
  year = 2021,
  month = May
}

@misc{gpt-neo,
  author       = {Black, Sid and
                  Gao, Leo and
                  Wang, Phil and
                  Leahy, Connor and
                  Biderman, Stella},
  title        = {{GPT-Neo: Large Scale Autoregressive Language 
                   Modeling with Mesh-Tensorflow}},
  month        = mar,
  year         = 2021,
  publisher    = {Zenodo},
  version      = {1.0},
  doi          = {10.5281/zenodo.5297715},
  url          = {https://doi.org/10.5281/zenodo.5297715}
}


@inproceedings{gpt-neox-20b,
  title={{GPT-NeoX-20B}: An Open-Source Autoregressive Language Model},
  author={Black, Sid and Biderman, Stella and Hallahan, Eric and Anthony, Quentin and Gao, Leo and Golding, Laurence and He, Horace and Leahy, Connor and McDonell, Kyle and Phang, Jason and Pieler, Michael and Prashanth, USVSN Sai and Purohit, Shivanshu and Reynolds, Laria and Tow, Jonathan and Wang, Ben and Weinbach, Samuel},
  booktitle={Proceedings of the ACL Workshop on Challenges \& Perspectives in Creating Large Language Models},
  url={https://arxiv.org/abs/2204.06745},
  year={2022}
}

@article{lamda,
  title={{LAMDA}: Language models for dialog applications},
  author={Thoppilan, Romal and De Freitas, Daniel and Hall, Jamie and Shazeer, Noam and Kulshreshtha, Apoorv and Cheng, Heng-Tze and Jin, Alicia and Bos, Taylor and Baker, Leslie and Du, Yu and others},
  journal={arXiv preprint arXiv:2201.08239},
  year={2022}
}

@article{santacoder,
  title={{SantaCoder}: don't reach for the stars!},
  author={Loubna Ben Allal and Raymond Li and Denis Kocetkov and Chenghao Mou and Christopher Akiki and Carlos Mu{\~n}oz Ferrandis and Niklas Muennighoff and Mayank Mishra and Alexander Gu and Manan Dey and Logesh Kumar Umapathi and Carolyn Jane Anderson and Yangtian Zi and J. Poirier and Hailey Schoelkopf and Sergey Mikhailovich Troshin and Dmitry Abulkhanov and Manuel Romero and Michael Franz Lappert and Francesco De Toni and Bernardo Garc'ia del R'io and Qian Liu and Shamik Bose and Urvashi Bhattacharyya and Terry Yue Zhuo and Ian Yu and Paulo Villegas and Marco Zocca and Sourab Mangrulkar and David Lansky and Huu Nguyen and Danish Contractor and Luisa Villa and Jia Li and Dzmitry Bahdanau and Yacine Jernite and Sean Christopher Hughes and Daniel Fried and Arjun Guha and Harm de Vries and Leandro von Werra},
  journal={ArXiv},
  year={2023},
  volume={abs/2301.03988}
}

@inproceedings{codet5mix,
title={{CodeT5Mix}: A Pretrained Mixture of Encoder-decoder Transformers for Code Understanding and Generation},
author={Anonymous},
booktitle={Submitted to The Eleventh International Conference on Learning Representations },
year={2022},
url={https://openreview.net/forum?id=VPCi3STZcaO},
note={under review}
}

@article{dsp,
  title={Training and evaluating a jupyter notebook data science assistant},
  author={Chandel, Shubham and Clement, Colin B and Serrato, Guillermo and Sundaresan, Neel},
  journal={arXiv preprint arXiv:2201.12901},
  year={2022}
}

@article{odex,
  title={Execution-Based Evaluation for Open-Domain Code Generation},
  author={Wang, Zhiruo and Zhou, Shuyan and Fried, Daniel and Neubig, Graham},
  journal={arXiv preprint arXiv:2212.10481},
  year={2022}
}

@inproceedings{transformer-1,
  title={Studying the usage of text-to-text transfer transformer to support code-related tasks},
  author={Mastropaolo, Antonio and Scalabrino, Simone and Cooper, Nathan and Palacio, David Nader and Poshyvanyk, Denys and Oliveto, Rocco and Bavota, Gabriele},
  booktitle={2021 IEEE/ACM 43rd International Conference on Software Engineering (ICSE)},
  pages={336--347},
  year={2021},
  organization={IEEE}
}

@inproceedings{transformer-2,
  title={Natural Language to Python Source Code using Transformers},
  author={Shah, Meet and Shenoy, Rajat and Shankarmani, Radha},
  booktitle={2021 International Conference on Intelligent Technologies (CONIT)},
  pages={1--4},
  year={2021},
  organization={IEEE}
}

@article{explanation-1,
  title={Experiences from Using Code Explanations Generated by Large Language Models in a Web Software Development E-Book},
  author={MacNeil, Stephen and Tran, Andrew and Hellas, Arto and Kim, Joanne and Sarsa, Sami and Denny, Paul and Bernstein, Seth and Leinonen, Juho},
  journal={arXiv preprint arXiv:2211.02265},
  year={2022}
}

@inproceedings{explanation-2,
  title={Generating diverse code explanations using the gpt-3 large language model},
  author={MacNeil, Stephen and Tran, Andrew and Mogil, Dan and Bernstein, Seth and Ross, Erin and Huang, Ziheng},
  booktitle={Proceedings of the 2022 ACM Conference on International Computing Education Research-Volume 2},
  pages={37--39},
  year={2022}
}

@misc{bigquery,
  author = {Google},
  year = {2016},
  title = {{GitHub on BigQuery: Analyze all the open source code}},
  note  = {\url{https://cloud.google.com/bigquery}}
}

@misc{codeparrot-data,
  author = {HuggingFace},
  year = {2021},
  title = {{CodeParrot Dataset}},
  note  = {\url{https://huggingface.co/datasets/transformersbook/codeparrot}}
}

@misc{codeparrotdata,
  author = {HuggingFace},
  year = {2021},
  title = {{CodeParrot Dataset}},
  note  = {\url{https://huggingface.co/datasets/transformersbook/codeparrot}}
}

@misc{codeparrotdata-2,
  author = {HuggingFace},
  year = {2021},
  title = {{Github-Code}},
  note  = {\url{https://huggingface.co/datasets/codeparrot/github-code}}
}

@misc{thestack,
  author = {HuggingFace},
  year = {2022},
  title = {{The Stack}},
  note  = {\url{https://huggingface.co/datasets/bigcode/the-stack}}
}

@misc{codeparrotdata-3,
  author = {HuggingFace},
  year = {2021},
  title = {{GitHub-Jupyter}},
  note  = {\url{https://huggingface.co/datasets/codeparrot/github-jupyter}}
}

@inproceedings{juice,
  title={{JuICe}: A Large Scale Distantly Supervised Dataset for Open Domain Context-based Code Generation},
  author={Agashe, Rajas and Iyer, Srinivasan and Zettlemoyer, Luke},
  booktitle={Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)},
  pages={5436--5446},
  year={2019}
}

@inproceedings{ghtorrent,
  title={{GHTorrent}: GitHub's data from a firehose},
  author={Gousios, Georgios and Spinellis, Diomidis},
  booktitle={2012 9th IEEE Working Conference on Mining Software Repositories (MSR)},
  pages={12--21},
  year={2012},
  organization={IEEE}
}

@article{archive,
  title={Archive},
  author={Featherstone, Mike},
  journal={Theory, Culture \& Society},
  volume={23},
  number={2-3},
  pages={591--596},
  year={2006},
  publisher={Sage Publications London, Thousand Oaks, CA and New Delhi},
  note  = {\url{https://archive.org/download/stackexchange}}
}

@misc{codenet,
  author = {IBM},
  year = {2021},
  title = {{CodeNet}},
  note  = {\url{https://github.com/IBM/Project_CodeNet}}
}

@article{cost,
  title={Multilingual Code Snippets Training for Program Translation},
  author={Zhu, Ming and Suresh, Karthik and Reddy, Chandan K},
  year={2022}
}

@misc{xlcost,
     title = {{XLCoST}: A Benchmark Dataset for Cross-lingual Code Intelligence},
     url = {https://arxiv.org/abs/2206.08474},
     author = {Zhu, Ming and Jain, Aneesh and Suresh, Karthik and Ravindran, Roshan and Tipirneni, Sindhu and Reddy, Chandan K.},
     year = {2022},
     eprint={2206.08474},
     archivePrefix={arXiv}
}

@article{pile,
  title={The {P}ile: An 800GB Dataset of Diverse Text for Language Modeling},
  author={Gao, Leo and Biderman, Stella and Black, Sid and Golding, Laurence and Hoppe, Travis and Foster, Charles and Phang, Jason and He, Horace and Thite, Anish and Nabeshima, Noa and Presser, Shawn and Leahy, Connor},
  journal={arXiv preprint arXiv:2101.00027},
  year={2020}
}

@inproceedings{sentencepiece2,
  title={{SentencePiece}: A simple and language independent subword tokenizer and detokenizer for Neural Text Processing},
  author={Kudo, Taku and Richardson, John},
  booktitle={Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing: System Demonstrations},
  pages={66--71},
  year={2018}
}

@inproceedings{bbpe,
  title={Neural machine translation with byte-level subwords},
  author={Wang, Changhan and Cho, Kyunghyun and Gu, Jiatao},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={34},
  number={05},
  pages={9154--9160},
  year={2020}
}

@article{adam,
  title={Adam: A method for stochastic optimization},
  author={Kingma, Diederik P and Ba, Jimmy},
  journal={arXiv preprint arXiv:1412.6980},
  year={2014}
}

@article{adamw,
  title={Decoupled weight decay regularization},
  author={Loshchilov, Ilya and Hutter, Frank},
  journal={arXiv preprint arXiv:1711.05101},
  year={2017}
}

@misc{zero,
  doi = {10.48550/ARXIV.1910.02054},
  url = {https://arxiv.org/abs/1910.02054},
  author = {Rajbhandari, Samyam and Rasley, Jeff and Ruwase, Olatunji and He, Yuxiong},
  keywords = {Machine Learning (cs.LG), Distributed, Parallel, and Cluster Computing (cs.DC), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {ZeRO: Memory Optimizations Toward Training Trillion Parameter Models},
  publisher = {arXiv},
  year = {2019},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@article{adafa,
  title={Adaptive firefly algorithm: parameter analysis and its application},
  author={Cheung, Ngaam J and Ding, Xue-Ming and Shen, Hong-Bin},
  journal={PloS one},
  volume={9},
  number={11},
  pages={e112634},
  year={2014},
  publisher={Public Library of Science San Francisco, USA}
}

@article{bloom,
  title={{BLOOM}: A 176b-parameter open-access multilingual language model},
  author={Scao, Teven Le and Fan, Angela and Akiki, Christopher and Pavlick, Ellie and Ili{\'c}, Suzana and Hesslow, Daniel and Castagn{\'e}, Roman and Luccioni, Alexandra Sasha and Yvon, Fran{\c{c}}ois and Gall{\'e}, Matthias and others},
  journal={arXiv preprint arXiv:2211.05100},
  year={2022}
}

@article{jigsaw,
  title={Jigsaw: Large Language Models meet Program Synthesis},
  author={Naman Jain and Skanda Vaidyanath and Arun Shankar Iyer and Nagarajan Natarajan and Suresh Parthasarathy and Sriram K. Rajamani and Rahul Sharma},
  journal={2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE)},
  year={2021},
  pages={1219-1231}
}

@article{cocomic,
  title={{CoCoMIC}: Code Completion By Jointly Modeling In-file and Cross-file Context},
  author={Ding, Yangruibo and Wang, Zijian and Ahmad, Wasi Uddin and Ramanathan, Murali Krishna and Nallapati, Ramesh and Bhatia, Parminder and Roth, Dan and Xiang, Bing},
  journal={arXiv preprint arXiv:2212.10007},
  year={2022}
}

@article{bigtransformers,
  title={Big Transformers for Code Generation},
  author={erman Arsenovich Arutyunov and Sergey Avdoshin},
  journal={Proceedings of the Institute for System Programming of the RAS},
  year={2022}
}

@article{ispeakuverify,
  title={{I Speak, You Verify}: Toward Trustworthy Neural Program Synthesis},
  author={Key, Darren and Li, Wen-Ding and Ellis, Kevin},
  journal={arXiv preprint arXiv:2210.00848},
  year={2022}
}

@article{sensitive,
  title={{ReCode}: Robustness Evaluation of Code Generation Models},
  author={Shiqi Wang and Zheng Li and Haifeng Qian and Cheng Yang and Zijian Wang and Mingyue Shang and Varun Kumar and Samson Tan and Baishakhi Ray and Parminder Bhatia and Ramesh Nallapati and Murali Krishna Ramanathan and Dan Roth and Bing Xiang},
  journal={arXiv preprint arXiv:2212.10264},
  year={2022}
}

@article{survey-1,
  title={A survey of machine learning for big code and naturalness},
  author={Allamanis, Miltiadis and Barr, Earl T and Devanbu, Premkumar and Sutton, Charles},
  journal={ACM Computing Surveys (CSUR)},
  volume={51},
  number={4},
  pages={1--37},
  year={2018},
  publisher={ACM New York, NY, USA}
}

@article{survey-2,
  title={Code Generation Using Machine Learning: A Systematic Review},
  author={Dehaerne, Enrique and Dey, Bappaditya and Halder, Sandip and De Gendt, Stefan and Meert, Wannes},
  journal={IEEE Access},
  year={2022},
  publisher={IEEE}
}

@article{survey-3,
  title={Deep learning for source code modeling and generation: Models, applications, and challenges},
  author={Le, Triet HM and Chen, Hao and Babar, Muhammad Ali},
  journal={ACM Computing Surveys (CSUR)},
  volume={53},
  number={3},
  pages={1--38},
  year={2020},
  publisher={ACM New York, NY, USA}
}

@article{survey-4,
  title={A Comprehensive Survey on Program Synthesis with Evolutionary Algorithms},
  author={Sobania, Dominik and Schweim, Dirk and Rothlauf, Franz},
  journal={IEEE Transactions on Evolutionary Computation},
  year={2022},
  publisher={IEEE}
}

@article{survey-5,
  title={Code Generation Tools (Almost) for Free? A Study of Few-Shot, Pre-Trained Language Models on Code},
  author={Barei{\ss}, Patrick and Souza, Beatriz and d'Amorim, Marcelo and Pradel, Michael},
  journal={arXiv preprint arXiv:2206.01335},
  year={2022}
}

@article{survey-6,
  title={Systematic mapping study of template-based code generation},
  author={Syriani, Eugene and Luhunu, Lechanceux and Sahraoui, Houari},
  journal={Computer Languages, Systems \& Structures},
  volume={52},
  pages={43--62},
  year={2018},
  publisher={Elsevier}
}

@article{survey-7,
  title={A Survey of Automatic Code Generation from Natural Language},
  author={Shin, Jiho and Nam, Jaechang},
  journal={Journal of Information Processing Systems},
  volume={17},
  number={3},
  pages={537--555},
  year={2021},
  publisher={Korea Information Processing Society}
}

@article{survey-8,
  title={Recent Progress in Automated Code Generation from GUI Images Using Machine Learning Techniques.},
  author={de Souza Baul{\'e}, Daniel and von Wangenheim, Christiane Gresse and von Wangenheim, Aldo and Hauck, Jean CR},
  journal={J. Univers. Comput. Sci.},
  volume={26},
  number={9},
  pages={1095--1127},
  year={2020}
}

@article{survey-9,
  title={Literature Survey on Automatic Code Generation Techniques},
  author={Pawade, Dipti and Sakhapara, Avani and Parab, Sanyogita and Raikar, Divya and Bhojane, Ruchita and Mamania, Henali},
  journal={i-Manager's Journal on Computer Science},
  volume={6},
  number={2},
  pages={34},
  year={2018},
  publisher={iManager Publications}
}

@inproceedings{survey-10,
  title={Mobile Application Code Generation Approaches: A Survey},
  author={El-Kaliouby, Shaymaa Sayed and Yousef, Ahmed H and Selim, Sahar},
  booktitle={International Conference on Model and Data Engineering},
  pages={136--148},
  year={2022},
  organization={Springer}
}

@article{survey_ci_11,
  title={A Closer Look into Transformer-Based Code Intelligence Through Code Transformation: Challenges and Opportunities},
  author={Li, Yaoxian and Qi, Shiyi and Gao, Cuiyun and Peng, Yun and Lo, David and Xu, Zenglin and Lyu, Michael R},
  journal={arXiv preprint arXiv:2207.04285},
  year={2022}
}

@inproceedings{survey_12,
  title={Survey on Template-based Code Generation},
  author={Lechanceux Luhunu and Eugene Syriani},
  booktitle={ACM/IEEE International Conference on Model Driven Engineering Languages and Systems},
  year={2017}
}

@article{survey-13,
  title={A survey on machine learning techniques for source code analysis},
  author={Sharma, Tushar and Kechagia, Maria and Georgiou, Stefanos and Tiwari, Rohit and Sarro, Federica},
  journal={arXiv preprint arXiv:2110.09610},
  year={2021}
}

@article{survey-14,
  title={A Survey on Pretrained Language Models for Neural Code Intelligence},
  author={Xu, Yichen and Zhu, Yanqiao},
  journal={arXiv preprint arXiv:2212.10079},
  year={2022}
}

@inproceedings{sentencepiece,
    title = "{S}entence{P}iece: A simple and language independent subword tokenizer and detokenizer for Neural Text Processing",
    author = "Kudo, Taku  and
      Richardson, John",
    booktitle = "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing: System Demonstrations",
    month = nov,
    year = "2018",
    address = "Brussels, Belgium",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D18-2012",
    doi = "10.18653/v1/D18-2012",
    pages = "66--71",
}

@misc{gpt4,
      title={GPT-4 Technical Report}, 
      author={OpenAI},
      year={2023},
      eprint={2303.08774},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{mim,
      title={Meet in the Middle: A New Pre-training Paradigm}, 
      author={Anh Nguyen and Nikos Karampatziakis and Weizhu Chen},
      year={2023},
      eprint={2303.07295},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{GSM8K-Python,
  title={Training verifiers to solve math word problems},
  author={Cobbe, Karl and Kosaraju, Vineet and Bavarian, Mohammad and Hilton, Jacob and Nakano, Reiichiro and Hesse, Christopher and Schulman, John},
  journal={arXiv preprint arXiv:2110.14168},
  year={2021}
}

@misc{repocoder,
      title={RepoCoder: Repository-Level Code Completion Through Iterative Retrieval and Generation}, 
      author={Fengji Zhang and Bei Chen and Yue Zhang and Jin Liu and Daoguang Zan and Yi Mao and Jian-Guang Lou and Weizhu Chen},
      year={2023},
      eprint={2303.12570},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{fusion_in_decoder,
  title={Leveraging passage retrieval with generative models for open domain question answering},
  author={Izacard, Gautier and Grave, Edouard},
  journal={arXiv preprint arXiv:2007.01282},
  year={2020}
}

@article{dense-retrieval,
  title={Dense passage retrieval for open-domain question answering},
  author={Karpukhin, Vladimir and O{\u{g}}uz, Barlas and Min, Sewon and Lewis, Patrick and Wu, Ledell and Edunov, Sergey and Chen, Danqi and Yih, Wen-tau},
  journal={arXiv preprint arXiv:2004.04906},
  year={2020}
}

@inproceedings{deep_api_learning,
  title={Deep API learning},
  author={Gu, Xiaodong and Zhang, Hongyu and Zhang, Dongmei and Kim, Sunghun},
  booktitle={ACM SIGSOFT International Symposium on Foundations of Software Engineering},
  pages={631--642},
  year={2016}
}

@inproceedings{redcoder,
  title={Retrieval Augmented Code Generation and Summarization},
  author={Parvez, Md Rizwan and Ahmad, Wasi and Chakraborty, Saikat and Ray, Baishakhi and Chang, Kai-Wei},
  booktitle={Findings of EMNLP},
  pages={2719--2734},
  year={2021}
}

@inproceedings{third-part-lib-1,
  title={Keep me updated: An empirical study of third-party library updatability on android},
  author={Derr, Erik and Bugiel, Sven and Fahl, Sascha and Acar, Yasemin and Backes, Michael},
  booktitle={Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security},
  pages={2187--2200},
  year={2017}
}

@inproceedings{third-part-lib-2,
  title={A structured approach to assess third-party library usage},
  author={Bauer, Veronika and Heinemann, Lars and Deissenboeck, Florian},
  booktitle={2012 28th IEEE International Conference on Software Maintenance (ICSM)},
  pages={483--492},
  year={2012},
  organization={IEEE}
}

@article{third-part-lib-3,
  title={Learning to recommend third-party library migration opportunities at the API level},
  author={Alrubaye, Hussein and Mkaouer, Mohamed Wiem and Khokhlov, Igor and Reznik, Leon and Ouni, Ali and Mcgoff, Jason},
  journal={Applied Soft Computing},
  volume={90},
  pages={106140},
  year={2020},
  publisher={Elsevier}
}

@inproceedings{private-paper-1,
  title={An Empirical Security Study of the Native Code in the JDK.},
  author={Tan, Gang and Croft, Jason},
  booktitle={Usenix Security Symposium},
  pages={365--378},
  year={2008}
}

@inproceedings{private-paper-2,
  title={Privacy and security in library RFID: Issues, practices, and architectures},
  author={Molnar, David and Wagner, David},
  booktitle={Proceedings of the 11th ACM conference on Computer and communications security},
  pages={210--219},
  year={2004}
}

@article{nl2code-survey,
  title={When Neural Model Meets NL2Code: A Survey},
  author={Zan, Daoguang and Chen, Bei and Zhang, Fengji and Lu, Dianjie and Wu, Bingchao and Guan, Bei and Wang, Yongji and Lou, Jian-Guang},
  journal={arXiv preprint arXiv:2212.09420},
  year={2022}
}

@article{nl2code-survey-2,
  title={Deep Learning Based Code Generation Methods: A Literature Review},
  author={Yang, Zezhou and Chen, Sirong and Gao, Cuiyun and Li, Zhenhao and Li, Ge and Lv, Rongcong},
  journal={arXiv preprint arXiv:2303.01056},
  year={2023}
}

@article{apidoc-2,
  title={How developers use API documentation: An observation study},
  author={Meng, Michael and Steinhardt, Stephanie and Schubert, Andreas},
  journal={Communication Design Quarterly Review},
  volume={7},
  number={2},
  pages={40--49},
  year={2019},
  publisher={ACM New York, NY, USA}
}

@inproceedings{apidoc-3,
  title={API documentation from source code comments: a case study of Javadoc},
  author={Kramer, Douglas},
  booktitle={Proceedings of the 17th annual international conference on Computer documentation},
  pages={147--153},
  year={1999}
}

@article{gptroadmap,
  title   = "How does GPT Obtain its Ability? Tracing Emergent Abilities of Language Models to their Sources",
  author  = "Fu, Yao; Peng, Hao and Khot, Tushar",
  journal = "Yao Fu’s Notion",
  year    = "2022",
  month   = "Dec",
  url     = "https://yaofu.notion.site/How-does-GPT-Obtain-its-Ability-Tracing-Emergent-Abilities-of-Language-Models-to-their-Sources-b9a57ac0fcf74f30a1ab9e3e36fa1dc1"
}

@article{starcoder,
  title={{StarCoder}: May The Source Be With You!},
  author={Raymond Li and Loubna Ben Allal 
and Yangtian Zi and Niklas Muennighoff and others},
  year={2023}
}

@article{codet,
  title={Codet: Code generation with generated tests},
  author={Chen, Bei and Zhang, Fengji and Nguyen, Anh and Zan, Daoguang and Lin, Zeqi and Lou, Jian-Guang and Chen, Weizhu},
  journal={arXiv preprint arXiv:2207.10397},
  year={2022}
}

@misc{pangucoder2,
      title={PanGu-Coder2: Boosting Large Language Models for Code with Ranking Feedback}, 
      author={Bo Shen and Jiaxin Zhang and Taihong Chen and Daoguang Zan and Bing Geng and An Fu and Muhan Zeng and Ailun Yu and Jichuan Ji and Jingyang Zhao and Yuenan Guo and Qianxiang Wang},
      year={2023},
      eprint={2307.14936},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}