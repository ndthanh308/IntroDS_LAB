



% column for runtime table


% % Figure environment removed

% % Figure environment removed

% % Figure environment removed






\subsection{Runtime Performance}
\label{sub:baselines}

\nop{We verified experimentally the following two hypotheses.}

%%%%%%%%%%%%%%%%%%%%
\begin{table*}[t]
\centering 
\caption{Overall runtime (in seconds) to compute all queries for each benchmark. For the JOB benchmark, ">" indicates the time is only for some of the 113 queries. For the four graph datasets, ">" indicates the time exceeded the six-hour (21,600 seconds) timeout for some of the cyclic queries. The multiplicative factors in parentheses after the runtimes of systems are the speedups of ADOPT over these systems.}
\resizebox{1\textwidth}{!}{
\begin{tabular}{l|rrrrrrr}
\toprule[1pt] Systems & JOB & ego-Facebook & ego-Twitter & soc-Pokec & soc-Livejournal1 & \revision{TPC-H} & \revision{JCC-H} \\
\midrule[1pt]
ADOPT       & 45   & \textbf{4,414}     & \textbf{3,931}   & \textbf{9,268}     & \textbf{26,350} & 141 & \textbf{194} \\
System-X    & > 287 (6.38x)    & > 22,459 (5.09x)  & 11,384 (2.90x) & > 23,623 (2.55x)  & > 63,878 (2.42x) & -- & --  \\
EmptyHeaded & --               & 6,783  (1.54x)    & 10,381 (2.64x) & > 43,444 (4.69x)  & > 55,144 (2.09x) & -- & -- \\
PostgreSQL  & 285 (6.33x)      & > 67,774 (15.35x) & > 70,515 (17.94x)  & > 67,016 (7.23x)    & > 101,193 (3.84x) & 182 (1.53x)  & > 216,122 \\
&&&&&&& (1,114x) \\
MonetDB     & \textbf{41} (0.91x) & > 66,165 (14.99x) & > 86,596 (22.03x) & > 59,131 (7.23x)  & > 96,222 (3.84x)  & \textbf{17} (0.12x) & > 216,035 \\
&&&&&&& (1,114x) \\
SkinnerDB   & 65 (1.44x)       & > 69,366 (15.71x) & > 129,741 (33.00x) & > 95,374  (10.29x)  & > 101,392 (3.85x) & 173 (1.23x) & 320 (1.6x) \\
\bottomrule[1pt]
\end{tabular}
}
\label{tab:overall}
\end{table*}
%%%%%%%%%%%%%%%%%%%%%


\revision{ADOPT puts together worst-case optimal join algorithm, which is primarily motivated by cyclic queries, and adaptive processing, which is motivated by scenarios in which size and cost prediction for query planning is difficult (e.g., due to data skew or complex queries). This motivates the following hypotheses.}

\begin{hyp}
    \revision{ADOPT outperforms baselines without worst-case optimal join algorithms on cyclic queries.}
\end{hyp}

\begin{hyp}
    \revision{ADOPT outperforms non-adaptive baselines for complex queries on skewed data.}
\end{hyp}

\begin{hyp}\label{hyp:bad}
    \revision{ADOPT performs worse, compared to baselines, if queries are simple, acyclic, and are executed on uniform data.}
\end{hyp}

% \begin{hyp}
% ADOPT demonstrates comparable or better performance than its competitors for both cyclic and acyclic queries.
% \end{hyp}


\pgfplotstableread[col sep=comma,]{data/facebook_twitter_clique_queries.csv}\fbtwittercliquequery
\pgfplotstableread[col sep=comma,]{data/pokec_livejournal_clique_queries.csv}\pokeclivejournalcliquequery
\pgfplotstableread[col sep=comma,]{data/cycle_queries.csv}\cyclequery


% Figure environment removed



Table~\ref{tab:overall} reports the total time in seconds for different systems and benchmarks. \revision{ADOPT performs best for the four benchmarks on graphs, featuring cyclic queries. Figure~\ref{fig:clique_cycle_results} breaks those results down by query size and query type. Compared to other baselines using worst-case optimal joins, ADOPT's gains derive from larger queries with more predicates, creating the potential for inter-predicate correlations that are hard to predict. This makes it difficult to select optimal attribute orders before execution. PostgreSQL, MonetDB, and SkinnerDB suffer from over-proportionally large intermediate results when processing cyclic queries as they do not implement worst-case optimal joins.}

\revision{The join order benchmark (JOB) features acyclic queries but non-uniform data (i.e., it contains some elements that should benefit ADOPT in the comparison and some that have the opposite effect). Here, ADOPT performs comparably but slightly worse to the best baseline: MonetDB. For System-X, Table~\ref{tab:overall} only reports time for executing a subset of the queries (39 out of 113). The remaining queries have IS/NOT NULL and IN predicates that are not supported by System-X.} EmptyHeaded needs more than five days to construct the data indices (tries) it needs for the non-binary JOB tables so we were not able to report its runtime on the JOB queries.

\revision{TPC-H and JCC-H share the same query templates and database schema but differ in the database content: TPC-H uses uniform data whereas JCC-H uses highly correlated data. On TPC-H, MonetDB performs best and outperforms ADOPT significantly. This is consistent with prior work~\cite{Aberger2018}, showing that systems with worst-case optimal joins (specifically: the LFTJ that ADOPT uses internally) perform significantly worse than MonetDB on TPC-H. Given those prior results and limited support for TPC-H queries in System~X and EmptyHeaded, we compare only to MonetDB as the strongest baseline. Besides drawbacks due to the join algorithm, ADOPT incurs overheads due to adaptive processing which is unnecessary on TPC-H: predicting sizes of intermediate results and plan execution cost is relatively easy due to uniform data.}

\revision{On the other hand, ADOPT outperforms all other systems on JCC-H. Despite sharing the same query templates with TPC-H, JCC-H makes query  optimization hard due to highly correlated data. Here, both adaptive baselines (SkinnerDB and ADOPT) benefit, with ADOPT being significantly faster, whereas all other systems reach the timeout of six hours. This means, even on acyclic queries, traditionally not considered the sweet spot for LFTJ-based joins~\cite{Aberger2018}, ADOPT is preferable if data is sufficiently correlated.}

%In the join order benchmark (JOB), MonetDB is the fastest, followed very closely by ADOPT. This shows that ADOPT is competitive with the fastest competitor that employs traditional query plans for acyclic queries. For System-X, Table ~\ref{tab:overall} only reports the overall runtime for 39 out of the 113 queries.

% These queries do not have  IS/NOT NULL and IN predicates as they are not supported by System-X. 
%\revision{The remaining queries have IS/NOT NULL and IN predicates that are not supported by System-X.}
%ADOPT thus outperforms System-X by at least six times. EmptyHeaded needs more than five days to construct the data indices (tries) it needs for the non-binary JOB tables so we were not able to report its runtime on the JOB queries.




%\revision{In the TPC-H benchmark, MonetDB outperforms other systems, since cardinality estimation is easy due to uniform data, whereas in JCC-H benchmark,  ADOPT is the most effective system. Particularly, PostgreSQL and MonteDB cannot finish Query 21 within six hours due to large cardinality.}

%For the graph benchmarks, ADOPT outperforms its competitors. MonetDB, PostgreSQL, and SkinnerDB, which use traditional query plans, perform consistently worse on cyclic queries than ADOPT, EmptyHeaded, and System-X, which use worst-case optimal join algorithms. This follows the asymptotic complexity gap and confirms the reported runtime gap between traditional query plans and worst-case optimal plans for cyclic queries~\cite{nguyen2015join}. Yet ADOPT outperforms EmptyHeaded and System-X by at least 1.5x on ego-Facebook and 2.5x on the other graphs. We also benchmarked the BAO learned query optimization for  PostgreSQL~\cite{Marcus} on ego-Twitter graph. There was no noteworthy runtime improvement.
% For the graph benchmarks, there was no noteworthy runtime improvement.

%\begin{hyp}ADOPT outperforms competitors for large queries. \end{hyp}

%Figure~\ref{fig:clique_cycle_results} reports the runtime for: $n$-cliques on the ego-Facebook and ego-Twitter graphs (top) and respectively on the soc-Pokec  and soc-Livejournal1 graphs (middle), and for $n$-cycles on the four graphs (bottom). The red top line in each figure represents the timeout (six hours = 21,600 seconds). For small  cliques ($n=3$), System-X is  the best; it uses sensitivity indices to speed up the leapfrogging that intersects sorted lists in LFTJ. For larger cliques, ADOPT significantly outperforms its competitors. The reason is the much larger search space for a good (attribute or join) order. It is therefore much less likely to find a good order for the competitors in contrast to ADOPT, which tries many orders during query execution. For instance, for 6- and 7-clique queries, ADOPT is at least 2x faster than the runner-up system for all graphs. A similar behavior can be observed for $n$-cycle queries in Figure~\ref{fig:clique_cycle_results}. Notably, ADOPT is the only system to complete 6-cycle on soc-Pockec and 5-cycle on Livejournal1 before timeout.

%EmptyHeaded and System-X are the two competitors that use worst-case optimal join algorithms and outperform the other systems on the graph benchmarks. In the following experiments, we give a more detailed comparison of ADOPT against System-X on the graph benchmarks. One reason for choosing System-X over EmptyHeaded is that both ADOPT and System-X use LFTJ as the underlying join algorithm. Furthermore, the performance of these two competitors on the graph benchmark is very close (within 4.8\% of each other). Also, the query language of System-X supports unary predicates, which are needed for the next robustness experiment.


% \pgfplotstableread[col sep=comma,]{data/relative_facebook_twitter_clique_queries.csv}\relativefbtwittercliquequery
% \pgfplotstableread[col sep=comma,]{data/relative_pokec_livejournal_clique_queries.csv}\relativepokeclivejournalcliquequery
% \pgfplotstableread[col sep=comma,]{data/relative_cycle_queries.csv}\relativecyclequery


% % Figure environment removed



