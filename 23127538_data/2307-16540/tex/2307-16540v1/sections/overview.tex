\section{Overview}
\label{sec:overview}

Figure~\ref{fig:overview} overviews the ADOPT system, illustrating its primary components. ADOPT \revision{supports SPJAG queries with sub-queries, covering the majority of TPC-H queries (see Section~\ref{sub:expsetup} for details)}. It performs in-memory data processing and uses a columnar data layout. \revision{The highly specific requirements of the ADOPT approach (e.g., support for high-frequency attribute order switching in a worst-case optimal join processing framework) motivate a customized system, rather than the integration into classical SQL execution engines.} The implementation uses Java and supports multi-threading via the Java ExecutorService API. It uses a worst-case optimal algorithm to process joins and selects attribute orders via reinforcement learning. 


\tikzstyle{system}=[draw, rectangle, rounded corners=1mm, shade, top color=gray!10, bottom color=gray!20, blur shadow={shadow blur steps=5}]
\tikzstyle{innercomponent}=[draw, rectangle, rounded corners=1mm, shade, top color=blue!10, bottom color=blue!20, minimum width=1.7cm, font=\bfseries, blur shadow={shadow blur steps=5}, align=center]
\tikzstyle{outercomponent}=[draw, rectangle, rounded corners=1mm, shade, top color=red!10, bottom color=red!20, minimum width=1.7cm, font=\bfseries, blur shadow={shadow blur steps=5}, align=center]
\tikzstyle{system}=[draw, rectangle, shade, top color=gray!10, bottom color=gray!20, blur shadow={shadow blur steps=5}]

\tikzstyle{dataflow}=[thick, -latex]
\tikzstyle{mdataflow}=[thick, <->]
% \tikzstyle{label}=[font=\bfseries]

% Figure environment removed


%After parsing, each query is first unnested into a sequence of simple queries (i.e., SPJGA queries without sub-queries). 

\revision{For complex queries (i.e., queries with sub-queries), ADOPT first decomposes them into a sequence of simple SPJAG queries, using decomposition techniques proposed in prior work~\cite{Neumann, trummer2019skinnerdb}. After decomposition, it executes the resulting queries, storing query results in temporary tables that are referenced by later queries in the query sequence (as input tables).} For \revision{each simple} query, ADOPT first performs a pre-processing step to filter the tables using unary predicates from the query \revision{(the resulting tables are typically much smaller than the original ones)}. After that, the following join phase is executed on the filtered tables.

For worst-case optimal computation of equality joins, ADOPT uses  LeapFrog TrieJoin (LFTJ). LFTJ considers join attributes in a fixed order to find value combinations that satisfy all join predicates. ADOPT uses an anytime version of this algorithm, so it can suspend and resume execution with high frequency. This enables the adaptive processing strategy, allowing ADOPT to identify near-optimal attribute orders, based on run time feedback. \revision{Similar to LFTJ, ADOPT does not materialize intermediate join results: LFTJ stores at most one tuple, containing one value per attribute, as intermediate state and adds complete tuples directly to the join result. This makes suspend and resume operations very efficient. Appendix~\ref{sec:illustrating_LFTJ} provides further details on the original LFTJ algorithm that ADOPT is based upon, including several examples. Also, Appendix~\ref{sec:lftjinadopt} details on the LFTJ variant used for ADOPT. In particular, it discusses how ADOPT uses and maintains data structures enabling the system to perform fast seek operations on the input tables, retrieving tuples that satisfy inequality conditions on their attributes.}

%Similar to LFTJ, ADOPT does not materialize intermediate join results: LFTJ stores at most one tuple of currently selected value per attribute as intermediate state and outputs it right away in case it is in the join result. This makes suspend and resume operations very efficient.

Besides the join algorithm itself, ADOPT uses an optimizer based on reinforcement learning. The optimizer selects attribute orders, balancing the need for exploration (i.e., trying out new attribute orders) with the need for exploitation (i.e., trying out attribute orders that performed well in the past). Each selected attribute order is only executed for a limited number of steps, enabling ADOPT to try thousands of attribute orders per second. To compare different attribute orders, ADOPT generates quality estimates. These estimates judge the performance achieved via an attribute order during a single invocation. Performance may vary, for the same order, across different invocations (e.g., due to heterogeneous data distributions). However, by averaging over different invocations for the same attribute order, ADOPT obtains increasingly more precise quality estimates over time.

%(similar in intent but different from the constraint data structure introduced by Ngo and R\'e~\cite{Ngo})

Switching between attribute orders makes it challenging to avoid redundant work. ADOPT uses a task manager to keep track of remaining parts of the join input to process. More precisely, the task manager manages (hyper)cubes in the Cartesian product space, formed by value ranges of all join attributes. Each cube represents a part of the input space that still has to be processed by some attribute order (i.e., corresponding result tuples, if any, have not been added into a shared result set yet). The execution of the anytime LFTJ is restricted to cubes that have not been processed yet. More precisely, data processing threads query the task manager for cubes, called \textit{target cubes} in the following, that do not overlap with any cubes processed previously or concurrently (by other threads). Threads process the target cube until completion or until reaching the per-episode limit of computational steps. The task manager is notified of processed parts of the target cube (if the step limit is reached, only a subset of the target cube, represented by a small set of cubes contained in the target cube, was processed). The task manager removes processed cubes from the set of remaining cubes.
%
%During the following invocation for the new attribute order, execution is constrained to that hypercube. Before switching to the next order, the constraint store is notified of the part of the target cube that was processed. Note that, in general, only a subset of the target cube is processed until the step limit is reached. This is necessary as, otherwise, the time required for processing the entire target with a bad attribute order may dominate the overall processing time. The remaining unprocessed subset is again expressed as a set of disjoint hypercubes, whose number is up to the number of join attributes in the query.
%
%The LFTJ requires index data structures on the join input tables. More precisely, it requires trie data structures, enabling quick access to tuples in a table with specific values in join columns. The desired structure of the trie depends on the attribute order. The original version of LFTJ uses one single attribute order, thereby requiring only a single trie per joined table. ADOPT, however, aims to explore various attribute orders during the processing of a single query. Hence, it creates new tries on input tables as the need arises. Specifically, whenever a new attribute order is selected by the reinforcement learning algorithm, ADOPT checks for the presence of required tries. If some of them are missing, it first creates corresponding data structures, before resuming join execution with the selected order. An input table can have as many tries as the possible total orders on its join attributes; e.g., for a table with two join attributes, there can be at most two tries.
%
%\revision{LFTJ requires indices on the input tables for efficient intersection of lists of attribute values expressing multiway joins. Each table is \emph{logically} organized as a trie, where each level corresponds to one attribute and the order of the levels follows the global attribute order. This logical organization can be supported \emph{physically} by sorted tables as done by ADOPT, B$^+$-trees as in the original LFTJ implementation in LogicBlox~\cite{Aref2015}, or nested hashing~\cite{Freitag2020}. The original LFTJ uses one single attribute order, which only requires a single index per joined table. As ADOPT explores several attribute orders during the processing of a single query, it may need several sorting orders of the input tables. These sorting orders are supported by lists of pointers to the original tables. An input table  with $n$ join attributes has up to $n!$ sorting orders. Whenever a new attribute order is selected by the reinforcement learning algorithm, ADOPT checks for the presence of the required sorting for each table. Before resuming join execution with the selected order, it first creates the required sorting order.}
%
Join processing terminates once the entire input (i.e., the hypercube representing the full Cartesian product of join attribute values) has been covered. This can be verified efficiently using the task manager. If no unprocessed cubes remain, a complete result has been generated. Depending on the type of query, ADOPT executes a post-processing stage in which group-by clauses and aggregates are executed. Specifically for \revision{(count, max, min, sum, and avg) aggregates without grouping}, ADOPT integrates join processing with aggregation and does not need to perform a post-processing stage.

Several processing phases of ADOPT can be parallelized. Specifically, ADOPT parallelizes the join preparation phase (i.e., unary predicates are evaluated on different data partitions in general) and sorts data in parallel. During the join phase, ADOPT assigning non-overlapping hypercubes to different threads. Hence, using the same mechanism that avoids redundant work across attribute orders, ADOPT avoids redundant work across different threads as well.
