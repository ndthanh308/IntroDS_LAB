\begin{abstract}
%The abstract should briefly summarize the contents of the paper in 15--250 words.

In computer science, evolutionary computing is a family of nature-inspired algorithms for solving complex search-based and optimization problems.
The idea of evolutionary computing is to find the best solution to a given problem in a smaller number of steps than traditional and computationally demanding approaches like exhaustive or grid search.
This tutorial opens the question whether this strategy can be made even greener and analyzes this issue through hyper-parameter tuning, selecting the appropriate optimization algorithm and programming language, building surrogate models and neuroevolution.
The goal is to present theoretical background of evolutionary computing and genetic algorithm, provide a practical exercise as a showcase of its potential and to demonstrate its usage in a sustainable manner.


\keywords{Evolutionary Computing \and Genetic Algorithm \and Energy Consumption.}
\end{abstract}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}

Evolutionary computation is a sub-field of artificial intelligence (AI) and it is used extensively in complex combinatorial problems and for continuous optimization.
In technical terms, it is a family of population-based trial and error problem solvers with a metaheuristic and stochastic character.
Although these algorithms can be used to solve modelling and simulation problems, their main application is optimization~\cite{eiben2015introduction}.

Evolutionary computation is used to solve problems that have too many variables for traditional algorithms and when optimal solution cannot be derived in (desirable) polynomial time \cite{borah2022applied}.
Although inherently efficient in solving complex problems, there are several efficiency enhancement techniques: parallelization, hybridization, time continuation, and evaluation relaxation~\cite{goldberg2002design}.
The task of parallelization is to distribute the computational load among processor units, hybridization combines local and global search techniques to reach a ballance between exploration and exploitation~\cite{sinha2005designing}, time continuation exploits the trade-off between the population size and the number of convergence epochs~\cite{srivastava2002time}, while evaluation relaxation promotes substitution of computationally expensive fitness with inexpensive approximation, also know as the surrogate model~\cite{smith1995fitness}.


In this tutorial, the aim is to provide the means of making evolutionary computing more sustainable, present a set of case studies designed to improve their energy efficiency and give a practical session for the second Summer School organized with the SusTrainable project.




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Evolutionary algorithms}

Darwinian's theory of evolution, governed by \textit{the survival of the fittest} principle, inspired automated problem solving family of algorithms that form evolutionary computing~\cite{fogel1998evolutionary}.
The most popular representative is the Genetic Algorithm (GA), named by Holland in the '70s~\cite{holland1973genetic}.
Individuals in a population, whose size is constrained by the limited amount of available resources, reproduce to prolong their species and the ones that are better adapted to environmental conditions have greater chances for survival.
In GA, individuals represent candidate solutions to a given problem, their genomes are sets of characteristics, i.e. parameters that define them and their quality is defined by a fitness function that plays the role of \textit{adaptation to the environment}~\cite{eiben2015introduction}.


The main requirements to solve an optimization problem using a GA is to have an adequate \textbf{representation} for candidate solutions and a \textbf{fitness function} that can numerically evaluate their quality.
The usual representation types, given in Figure \ref{fig1:evolutionary}, include bit string for binary variables, vector of real numbers for continuous variables, permutations for arranging the order of events and tree-based structures for creating programs, mathematical functions or similar more complex entities.
Each of the classical deductive optimization tasks like knapsack problem, finding minima of a complex mathematical function, travelling salesman and symbolic regression require one of these representation types.
In knapsack problem we are selecting the best subset of items to maximize their weight without exceeding its carrying capacity and the best representation is the bit string.
Finding extrema of a mathematical function such as the Rosenbrock function~\cite{rosenbrock1960automatic}, presented in Figure \ref{fig1:evolutionary}, requires the candidate solutions to be expressed through a vector of real numbers.
A travelling salesman needs to find the shortest path to visit a number of predetermined number of places of his route only once and permutations are the obvious choice for describing the candidate solutions.


% Figure environment removed


The schematic overview of GA workflow, as presented in Figure \ref{fig1:evolutionary}, stars from initialization of the population, usually by random generation of genomes.
The quality of each individual within the population is estimated numerically by the fitness function.
%The fitness function is then put to use to numerically evaluate the quality of every individual within the population.
Better solutions have greater chances for becoming parents of new individuals produced in the reproduction phase by the operator of genome crossover.
To introduce small random changes in the genes inherited from their parents, a mutation operator is applied in the offspring population.
Final phase of this iterative process is the quality-oriented selection of the individuals that will form the next generation of individuals.
Most of these functions are of stochastic nature, and their overall goal is to gradually drive the evolution in the direction of the best solutions~\cite{eiben2015introduction}.


Drawing inspiration from swarm intelligence, biology, physics, chemistry or even social phenomena and grammar, nowadays there is a great number of evolutionary algorithms~\cite{fister2013brief}.
Several exotic algorithms, like the music-inspired Harmony Search Algorithm, demonstrated the ability to enhance computational efficiency with simpler implementation and a lower number of setting parameters~\cite{geem2009music}.
Although often used as black box solution, understanding the underlying subtleties of evolutionary computing may lead to their cost-effective and more sustainable utilization.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Training Course}

The tutorial will start by introducing the basic concepts of evolutionary computing, explain the main operators and functions within the GA and what is its purpose.
Although GA is known to be a more efficient alternative to computationally demanding approaches like exhaustive or grid search, the tutorial will discuss the strategies which may be implemented to make it even more sustainable.
Besides the obvious hyper-parameter tuning of numerous selection, crossover and mutation operators, we will analyze which is the appropriate choice of programming language for the implementation of GA and compare the popular languages like java, R and python.
We will also compare several exotic optimization algorithms like Firefly, Artificial Bee Colony and Flower Pollination Algorithm in terms of execution time and accuracy of the prediction model after performing feature selection.
To present more elaborate ways of making GA greener, we will introduce the concept of surrogate models, whose aim is to replace expensive fitness function with simpler approximate solutions.
The practical exercise will demonstrate the potential of evolutionary computing applied to evolving neural network (NN)-based classifiers, known as the neuroevolution.

The key take-away messages of this course will be:
\begin{enumerate}
    \item Understanding the fundamental operators of evolutionary computing;
    \item Know-how for estimating and improving the efficiency of GA;
    \item Practical guidelines for developing a sustainable neuroevolution framework.
\end{enumerate}



\subsection{Prerequisite Knowledge and Skills}

This lecture is designed to fit the expertise of a master or PhD student enrolled in the study programme of computer science or related studies.
The intended audience should have theoretical knowledge of algorithms and data structures to follow the training materials on evolutionary computing.
To fully benefit from the training materials related to surrogate modelling and neuroevolution, a basic understanding of machine learning and its application is recommended, along with the following concepts:
\begin{itemize}
    \item Understanding the complexity of neural networks;
    \item Familiarity with prediction model training pipeline;
    \item Evaluation metrics for estimating the classification performance.
\end{itemize}


\subsection{Materials and Methods}

The sustainability aspect of the practical exercise will require energy measurements for executing the optimization of NN architecture and the training of the prediction model.
Running Average Power Limit (RAPL) and its Python version (pyRAPL) offer an estimated energy consumption of CPUs and DRAM~\cite{RAPL2019} with minimal performance overhead~\cite{khan2018rapl} and we will be used it for that purpose.
Energy consumed by the grid search and by the neuroevolution will be compared to demonstrate the benefit of using the evolutionary computing paradigm for the task of evolving low-complexity prediction models.


The software packages and libraries that are going to be needed for the implementation and execution of examples in the practical session are:
\begin{itemize}
    \item tensorflow - model construction and training;
    \item pyRAPL - energy consumption measurement;
    \item scikit-learn - machine learning library containing grid search implementation and various benchmark datasets;
    \item matplotlib - visualizing the results;
    \item numpy - supporting mathematical operations;
    \item pandas - manipulating data;
    \item neat-python - implementation of neuroevolution algorithm in python;
    \item seqprops - encoding for peptides dataset
    \item scikit-bio - various tools for dealing with peptides datasets
    \item scikit-optimize - hyperparameter optimization
    \item scipy - optimization, statistics
    \item dask - parallelization library
\end{itemize}


Datasets available in scikit-learn library, such as California Housing dataset, Diabetes dataset or Iris plants dataset and/or publicly available peptide datasets like DRAMP 2.0~\cite{kang2019dramp}, will be used to demonstrate the principles of training NN-based prediction models.
The goal is to examine the benefit of using neuroevolution for simultaneous arcitecture optimization and training process in terms of time and energy consumption.



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Conclusion}

This paper presents a tutorial on basic concepts of evolutionary computing, with the aim to minimize energy consumption when solving optimization tasks.
It is a continuation of our lecture entitled Soft Computing for Sustainability Science, which dealt with the problem of data pre-processing and feature selection in particular, its application on dimensionality reduction and impact on reducing the time and energy when training predictive models.
This tutorial tackles the issue of developing NN-based models, which are emerging as the most popular choice for solving complex classification problems.
A lack of clear guidelines for choosing the appropriate NN architecture impedes their wider applicability and often leads to implementation of computationally demanding optimization procedures like grid-search.
Not only do these methods present an unsustainable means of solving the problem, but they also often result with architectures whose complexity is higher than actually needed, which increases computational cost for training and using them.

Participants of this tutorial will go through a theoretical lecture and a practical exercise, after which they will understand the importance of evolutionary algorithms and gain skills required to train NN-based prediction model in a sustainable manner.
Aligned with the aim of our SusTrainable project, the tutorial strives to provide scientific and technical support in identifying new development approaches, promote sustainability as an important topic in AI and to disseminate these concepts to a wider audience.




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%




% \begin{table}
% \caption{Table captions should be placed above the
% tables.}\label{tab1}
% \begin{tabular}{|l|l|l|}
% \hline
% Heading level &  Example & Font size and style\\
% \hline
% Title (centered) &  {\Large\bfseries Lecture Notes} & 14 point, bold\\
% 1st-level heading &  {\large\bfseries 1 Introduction} & 12 point, bold\\
% 2nd-level heading & {\bfseries 2.1 Printing Area} & 10 point, bold\\
% 3rd-level heading & {\bfseries Run-in Heading in Bold.} Text follows & 10 point, bold\\
% 4th-level heading & {\itshape Lowest Level Heading.} Text follows & 10 point, italic\\
% \hline
% \end{tabular}
% \end{table}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section*{Acknowledgement}

This paper acknowledges the support of the Erasmus+ Key Action 2 (Strategic partnership for higher education) project No. 2020-1-PT01-KA203-078646: “SusTrainable - Promoting Sustainability as a Fundamental Driver in Software Development Training and Education”.

The information and views set out in this paper are those of the author(s) and do not necessarily reflect the official opinion of the European Union. Neither the European Union institutions and bodies nor any person acting on their behalf may be held responsible for the use which may be made of the information contained therein.



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% ---- Bibliography ----
%
% BibTeX users should specify bibliography style 'splncs04'.
% References will then be sorted and formatted in the correct style.
%\bibliographystyle{splncs04}
%\bibliography{References}


%\end{document}
