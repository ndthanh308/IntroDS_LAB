\begin{abstract}
We present the coordination language TeamPlay for the high-level specification of cyber-physical systems with strong requirements on non-functional properties such as execution time and energy consumption, both as a constraint (deadline, energy budget) and as an optimisation objective (save energy, run quickly).
TeamPlay makes trade-offs between time, energy and (optional) redundancy for fault-tolerance visible in early system design and implementation stages.

In this paper we describe the essential concepts of the TeamPlay coordination language, mostly in an abstract way.
Eventually, we sketch out our programme for the SusTrainable summer school to be held in Coimbra, Portugal, in July 2023.
\end{abstract}

\section{Introduction}
\label{sec:summary}

Cyber-physical systems (CPS) combine hardware/software (cyber) systems with the physical word seen through sensors and impacted through actuators.
In cyber-physical systems the functional correctness of software, thus, is of pa\-ra\-mount importance as erroneous behaviour is not ``just'' an annoyance, but may have disastrous consequences in the physical world including loss of life.
Beyond functional correctness, non-functional properties such as execution time and energy consumption play an equally important role.
Typically, reactions to sensor inputs must occur within some given deadline.
Energy consumption is not only relevant as a general environmental concern, but many cyber-physical devices are in fact battery-driven.
As such energy consumption is in a direct relation to the usefulness of a cyber-physical system.

From a software engineering point of view the question is how confidence in functional correctness, meeting of execution deadlines and energy consumption can all be addressed at an equal level of importance without creating an unmaintainable software mess.
We proposed the coordination language \emph{TeamPlay} \cite{RoedRouxAltm+20} to address these concerns.
TeamPlay embraces the concept of \emph{exogenous} coordination \cite{Arbab98,Arbab04} and organises a concurrent application as a set of independent, identifiable black-box \emph{components} (aka \emph{tasks}) that communicate with each other solely via data-flow channels.
Components are meaningful, sequential application building blocks, implemented in a general-purpose programming language.

TeamPlay enforces a stringent two-layer software architecture where components are simple enough to be implemented correctly for a given input-output relation.
Furthermore, components have a defined dynamic behaviour regarding worst-case/average-case execution time and energy consumption for any given execution platform under consideration.
These data could be obtained through static code analysis or through experimentation, depending on the compute architecture.
A system integrator then takes these (in coding terms) black-box components and synthesise a systems by means of the TeamPlay coordination language.

We primarily target high-performance embedded system architectures, like the Odroid or Jetson families.
These combine heterogeneous multi-core CPUs with DVFS and highly parallel GPUs for bulk computing.
Mapping TeamPlay coordination programs to high-performance embedded systems under time and energy constraints creates a complex scheduling (in time) and mapping (in space) problem that we address with various scheduling/mapping schemes \cite{RoedRouxAltm+20b,RoedRouxGrel21,RoedPimeGrelAIAI23} and a runtime middleware for said high-performance embedded systems \cite{RouxAltmGrel21}.

During the SusTrainable summer school in Coimbra, Portugal, in July 2023 we will motivate the use of exogenous coordination in the field of cyber-physical systems, introduce the essential features of the TeamPlay coordination language and explain the ins and outs of the scheduling and mapping problem in the presence of heterogeneous high-performance embedded systems.
During the labs students are supposed to implement a simple (mock) cyber-physical system using TeamPlay.
We will provide the latest implementation via a virtual machine to avoid installation hassle and uncertainties.


%In the remainder of this document, we describe our overall objectives as well as our on-going work with respect to these three pillars in more detail.


\section{Components and contracts}
\label{components}

As pointed out before, a TeamPlay application is organised as a collection of interacting components.
Components are meaningful, sequential application building blocks, implemented in a general-purpose programming language.
As is common in the domain of cyber-physical systems, we exclusively work with the system programming language C in practice.
We illustrate TeamPlay components in Figure~\ref{fig:components3}.


% Figure environment removed

\noindent
A TeamPlay component consists of four entities:
\begin{description}
\item[Name:] a unique name: \textit{ImageCapture} and \textit{ObjectDetection} in the example;
\item[Code:] a component implementation in the form of a callable, linkable C function object code;
\item[Functional contracts:] define the component's functional interaction with the outside world;
\item[Non-functional contracts:] define the component's non-functional properties, namely with respect to energy and time.
\end{description}
We further refine the functional contracts of a component into:
\begin{description}
\item[Input ports:] a set of pairs specifying type and name of each input port;
\item[Output ports:] a set of pairs specifying type and name of each output port;
\item[State ports:] a set of pairs specifying type and name of each internal state, which in this way is externalised to the coordination layer.
\end{description}
If the set of input ports is empty, we speak of a \textit{source component} that controls one or more sensors.
If the set of output ports is empty, we speak of a \textit{sink component} that controls one or more actuators.
And, if the set of state ports is empty, we speak of a \textit{state-less component}.
Information regarding the internal state of a component is crucial for its automatic replication or migration between multiple execution units.

We further distinguish two kinds of non-functional contracts:
\begin{description}
\item[Time contract:] the timing behaviour of the component, namely average and/or worst-case execution time;
\item[Energy contract:] the energy behaviour of the component, namely average and/or worst-case energy consumption.
%\item[Security contract:] the security level of one specific implementation of the component, for the time being as a discrete number.
\end{description}
Functional and non-functional contracts differ from each other in one crucial aspect: any implementation of a component must obey the functional contracts, but the non-functional contracts are specific to one particular execution platform (system architecture).
Hence the functional contracts of a component are not stored in the coordination source file, but in a separate data base.
In a simplistic view this data base could be seen as a matrix with all components of an application on one axis and all potential execution platforms and their individual processing units (e.g.~Arm big.LITTLE) on the other axis.
Determining a component's non-functional properties on a specific processing unit is beyond the scope of our work.
For relatively simple architectures this could be done with static analysis \cite{WegeNikoNune+23}, but for more complex architectures (deep caches, out-of-order execution, etc.) this is usually accomplished by dynamic profiling \cite{Seewald2019coarse} and some configurable safety margin.

% Figure environment removed

Our observation is that usually a component can be implemented in various different ways.
Furthermore, component implementations can be compiled into executable code with different compilation objectives (e.g.~speed, energy, code size, etc.).
Hence, we further refine our component model to support \emph{multi-version components}, as illustrated in Figure~\ref{fig:components4}.
Multi-version components have multiple implementations that all share the component's functional contracts, but behave differently with respect to the non-functional contracts, even on the very same execution platform and processing unit.

The genuine rationale behind multi-version components is to offer a choice of different non-functional behaviours as described by the non-functional contracts.
Consequently, the coordination layer, or more precisely the component space/time scheduler, may choose among the various versions according to global application-specific objectives.
Multiple component versions can further be used to support multiple binary-incompatible execution units or to optimise one (source code) implementation of a component for one specific type of execution unit, even if they are binary-compatible in principle.
The coordination run-time system \cite{RouxAltmGrel21} may even react on changing environmental conditions, as for example the battery status of some device.

%Of course, components may only have a single version only, and in the following we use the terms \textit{contract}, \textit{behaviour}, etc, with respect to components and their versions interchangeably.

\ignore{
In essence, (non-functional) contracts define the ETS properties of the component. Hence, each component has a defined run-time behaviour, amount of energy required and a security level obtained from the analysis tools of the other partners. Additionally, each component can have multiple implementations with equivalent functional, but different extra-functional behaviour. Besides the guaranteed performance of the individual components, we need to specify the component-specific and system-wide ETS-constraints, expressed as, for instance, deadlines on the response-time of a component or energy budgets of the entire system or minimum security levels.
}

\ignore{
We use the very same annotations explained in Deliverable D7.4 to define the ETS-characteristics of each component, e.g.:\\
\textit{ \_\_teamplay\_\{qualifier\}\_metric(name\{,default, confidence\});stmt;} \\
These annotations form the central glue between the technical work packages: while some work packages are primarily concerned with deriving these non-functional properties from component implementations, others, among them work package 2, are concerned with interpreting and exploiting this additional information on the application level.
}

\section{Component interaction}

As illustrated in Figure~\ref{fig:coordination}, several components together form an application (or system).
They interact in the form of a streaming network or component workflow.
Such streaming networks may have arbitrary shape, but must be free of cycles.
In other words, our streaming networks form \emph{acyclic directed graphs}, or \emph{DAGs} for short.
In the example we see a source component \textit{ImageCapture} that feeds data into the streaming network.
The rationale behind the example is that this component is connected to some kind of camera, but in principle any sensor input is a typical case of such a source component.

% Figure environment removed


The data is passed on to two subsequent components, called \textit{ObjectDetection} and \textit{OpticalFlow}. This could be characterised as a broadcast of one data item to two components, as is the intention behind the example, or the \textit{ImageCapture} component could send two different data items to \textit{ObjectDetection} and \textit{OpticalFlow}, respectively.
Components \textit{ObjectDetection} and \textit{OpticalFlow} are stateless and process the data received from \textit{ImageCapture} in different ways and output their results to the subsequent component \textit{DecisionMaking}.

The \textit{DecisionMaking} component in the given example synchronises the data received from both incoming
streams in a pair-wise manner, derives a decision (as the name suggests) and forwards it to the final component of the workflow \textit{DecisionRec} for recording.
%In other scenarios a component with multiple incoming streams may well be activated by the presence of data on one of its input streams instead of all.
The final component \textit{DecisionRec} is a sink component and as such does not have any output port.

The whole execution regime is entirely data-driven: components are activated by the availability of data items on their input ports. Components process the data received and in turn produce data items on their output ports, which trigger subsequent components further down the workflow or streaming network.
Both the external behaviour of components as well as their orderly interaction in a streaming network or work flow are described in the TeamPlay coordination language \cite{RoedRouxAltm+20}.
The (static) type system of TeamPlay ensures the soundness of streaming networks.




\section{Component scheduling and mapping}

Eventually, componentised applications and their coordination glue must be mapped to execution hardware.
We specifically target heterogeneous parallel systems with multiple different types of execution units.
These types of execution units may or may not be binary-compatible, but they (almost) always expose different energy/time trade-offs.
Together with our multi-version component model we have a created a rich design space for the crucial question where to run what and when to meet application-specific global constraints and to achieve application-specific global objectives.
We illustrate this plethora of options and opportunities in Figure~\ref{fig:scheduling}.

% Figure environment removed

It is the combination of multi-version components with heterogeneous parallel hardware that in essence causes this explosion of options.
For example one may want to switch from a fast implementation to a more energy-efficient implementation as the battery status of the executing device degrades.
Different versions of the same component could implement different algorithms, could be compiled using different compiler flags (or even different compilers) use different parameters (frame-rate) or could make use of different execution units of a heterogeneous system, such as sketched out in Figure~\ref{fig:scheduling}.

Depending on application requirements we consider both energy and time as either a budget limitation or an optimisation problem.
For time both variations have classical role models and solutions: the real-time community works with time budgets while the high-performance computing community sees time as an object of optimisation.
Energy can be addressed analogously as a budget constraint or an optimisation objective.
The most typical combination in a our target application domain of cyber-physical systems, however, is to combine time budgets, i.e.~real-time deadlines, with energy optimisation objectives.
In other words we aim to run an application within the deadline with the least energy possible.
The energy reduction objective could be motivated by either environmental concerns or by battery life times, but that again is beyond the scope of our work.

The scheduling problem as such is NP-complete, and so optimal solutions can effectively only be computed for very small concrete problems.
Consequently, heuristics are used in practice, and we have integrated a number of such scheduling heuristics into our TeamPlay compiler \cite{seewald2019component,RoedRouxAltm+20b,RoedRouxGrel21,RoedPimeGrelAIAI23} that explore different aspects of the general subject matter.
Our energy-aware schedulers make use of an elaborate energy model that distinguishes between static and dynamic energy consumption and take full advantage of platform-specific DVFS capabilities (i.e.~dynamic voltage and frequency scaling).
Static energy consumption refers to the energy consumption of a processing unit in idle status, i.e.~without executing any code.
Static energy consumption, as the name suggests, is constant over time and only affected by application makespan, i.e.~the time it takes an application to run to completion or to complete one application cycle.
In other words, static energy consumption is a property of the type of execution unit, but application-independent.
Dynamic energy consumption depends on the instruction mix of an application component, the type of execution unit and the choice of voltage and frequency in case the hardware supports DVFS, which is a common case nowadays.

Execution time and energy consumption are not independent of each other, but they are not the same either.
In this sense, the fastest solution is typically not the most energy-efficient one.
Running an application faster cuts down the static energy consumption, but this is often over-compensated by running code on higher clock frequency and voltage or by even running it on a more powerful but likewise more energy-hungry execution unit.
For example, on the ARM big.LITTLE architecture we have used so far for illustration, moving a component from a LITTLE core to a big core typically increases platform energy consumption.
Should the compute power of a big core be required to meet the deadline, this additional energy is well invested, but otherwise most likely not.




\section{Related work}
\label{related}

Coordination itself is a well established computing paradigm with a plethora of languages, abstractions and approaches~\cite{CML+18}.
Yet, we are neither aware of any explicit adoption of the principle in the domain of cyber-physical systems, nor are we aware of energy- and time-aware approaches to coordination as a paradigm.

We have previously worked on the coordination language and component technology S-Net~\cite{GSS10,GrelJulkPencCCGRID12}, from which we draw both inspiration and experience for the design of TeamPlay.
However, like other coordination approaches S-Net merely addresses the functional aspects of coordination programming and has left out any non-functional requirements, not to mention energy or time specifically.

A notable exception in the otherwise pretty much uncharted territory of energy/time-aware coordination is the functional language Hume~\cite{HaM03} that was specifically designed with real-time systems in mind. Thus, guarantees on time (and space) consumption are key to Hume.
The main motivation behind Hume was to explore how far high-level functional programming features, such as automatic memory management, higher-order functions, polymorphism, recursion and currying, eventually up to full-scale Haskell, can be supported while still providing accurate real-time guarantees.

Pradhan et al.~\cite{Pradhan15} proposed \textit{CHARIOT}, a \textit{Domain Specific Language} for CPSoSes. While they do not describe their language as a \emph{coordination language}, it provides capabilities such that it could be considered a coordination language. The authors also do not explicitly describe utility for systems-of-systems and, instead, focus on \textit{fractionated} systems. A fractionated system is an architecture within which one system is composed of a set of networked systems at the same location (e.g.~a satellite swarm). The advantage of such a system is the ease of extendibility: a system providing a new capability (e.g.~sensor or processing platform) can be added to the general area of the other systems, thus enhancing the capabilities of the composite system.

\ignore{
The CHARIOT language aims at aiding the development of these complex, extensible cyber-physical systems-of-systems, primarily the integration between middleware produced by different vendors and managing complexity. A user specifies components, their communication channels (similar to inports and outports in TeamPlay), as well as their mapping to hardware in the coordination language. The presence of this mapping makes the final conversion step, where a CHARIOT specification is converted into instructions for a given middleware, rather straightforward. Their main contribution is in offering a consistent programming interface to address fractionated systems.

The composed system can switch between predefined modes referred to as \textit{objectives}. Objectives are somewhat similar to TeamPlay modes, given that they are discrete system states between which the system may switch. However, TeamPlay modes attempt to serve as a front-end to a \textit{coordination compiler} and further downstream tools, where the conversion between modes is non-trivial, yet handled automatically by design-time algorithms. At the same time, the CHARIOT objectives rather form a set of configuration points that are each written to a database. These points are available to the runtime, which handles them when they are selected. The contribution of Pradhan et al.~is primarily in the management of software development complexity, where the conversion of their DSL to a mapping is rather trivial (from an academic point of view). In contrast, the TeamPlay coordination language aims not only to reduce software development complexity, but also to optimise for objectives (such as energy, time or robustness) that are not feasible by traditional means.
}

More work published under the \emph{DSL} label shows considerable overlap with coordination languages. The contribution by Berger~\cite{Berger14} proposes a DSL for the integration of sensors into a cyber-physical system. The platform is supplied in a \textit{board specification file}. However, while the board can be changed, the work is limited to a single board. The DSL encodes the requirements for sensors attached to the board. Each sensor is attached by pins, which must be set to a particular mode (e.g.~analog or use i2c). Not all pins support all modes, which forms the basis of a \textit{constraint-satisfaction problem} to perform the assignment of sensors to pins. As such, this work is an example of using a language to formulate a problem that cannot be solved manually, similar to the TeamPlay language. However, the scope and focus on real-time of our coordination language remains unique.


\section{Summer school}
\label{school}

Our contribution to the planned summer school targets an audience of MSc and PhD students with a broad understanding of computer science in general and solid programming skills in particular.
We do not expect prior exposure to engineering cyber-physical systems or mapping/scheduling problems nor any prior knowledge of the topics described in this document.

The learning objectives for the summer school are as follows:
\begin{itemize}
\item obtain a basic understanding of the requirements of cyber-physical systems and resource-aware computing;
\item understand the concept of exogenous coordination;
\item familiarise with the TeamPlay coordination language;
\item solve a (simple) scheduling/mapping problem for a (mock) application;
\item optimise the energy consumption of said cyber-physical system by using the TeamPlay methodology \cite{RouxPaghAkes+20}
\end{itemize}

We will provide any subject-specific background required during the lecture.
However, we are convinced that just telling the story is not sufficient for a deeper and lasting learning experience.
Thus, a hands-on practical session is essential to meet the learning objectives.
Such practical sessions making use of research (prototypical) software incur the risk of losing considerable time in overcoming installation and compatibility issues.
We will address and avoid such problems by providing a docker container with a light-weight virtual machine and all required non-standard software pre-installed and tested.

The concrete task to be solved by the summer school participants has not yet been finalised entirely, but our working hypothesis circles around a fork-join component/task graph, where the fork component reads wifi signal strength (from some imaginary sensor) and forwards the data to a fixed number of tasks \emph{representing students in a room}.
These tasks determine the approximate locations of the students in the room, which are forwarded to a join task that takes some decision based on the locations, e.g.~raising an alarm should the 1.5m Covid-19 distance rule be violated.

We plan to provide the summer school participants with a monolithic solution to the problem and let them identify the logical components and their interaction using the TeamPlay coordination technology.
We provide non-functional properties, i.e.~time and energy, for the (rather obvious) building blocks of our application.
As a result the students will find out that the monolithic solution cannot be scheduled with the given deadline.
With the explicit componentisation and the TeamPlay methodology the application not only becomes schedulable, but as an extra incentive we will have a small competition who of the participants manages to solve the problem with the least energy demand.

Time-permitting, we can also illustrate the fault-tolerance features of TeamPlay \cite{LoevGrel20} that permit to easily run selected components under a variety of fault-tolerance regimes, such as double or triple modular redundancy.
Here, the students can experiment with how much redundancy we can afford on a given hardware platform before the application becomes unschedulable.
Moreover, the price in terms of energy consumption that needs to be paid for redundancy and fault-tolerance becomes evident.


\ignore{

  Lukas:

> = Sustrainable
> - Goal: play a bit with the coordination language. NFP and source code provided, slight changes to the configuration
>   - Needs: a container / VM with everything ready to go (Cecile on path, Yasmin, build-essentials)
>   - [!] this will be tricky on ARM macs (need an ARM mac)
>     -> solution: docker container with bash as start shell and all tools on path
> - Concrete plan:
>   - Application: fork-join esq graph where
>     Fork task reads wifi signal strength to a fixed number of students
>     Multiple process task locates each student
>     Join task makes some decision based on locations (e.g. 1.5m rule violations)
>   - Excercise: students get a monolithic version + code, nfp for parts of the code
>     Monolithic version is not schedulable
>     Students rewrite the task graph using SDF to enable hardware parallism
>     Run join task with fault tolerance (replicas = no. of replicas, (ignore) votingReplicas = no. of voters)
>     [!] Fix spelling mistake in homogenize (from homogeneise)
>     [!] Finish expand-ft-compiler-pass
> - Other:
>     [Clemens] will send slide deck regarding other instructions

After this I realized it actually needs to be about energy-aware scheduling -- the monolithic version should be schedulable as well, just use a lot of energy. But we can still take the same basic idea.
}

\section*{Acknowledgments}
\label{ack}

This project has received funding from the European Union's Horizon-2020 research and innovation programme under grant agreement No.~779882 (TeamPlay: Time, Energy and Security Analysis for Multi/Many-core Heterogeneous Platforms) and under grant agreement No.~871259 (ADMORPH: Towards Adaptively Morphing Embedded Systems).
Our work has received further funding from the European Union via the Erasmus Plus Key Action 2 (Strategic partnership for higher education) under grant agreement No.~2020-1-PT01-KA203-078646 (SusTrainable: Promoting Sustainability as a Fundamental Driver in Software Development Training and Education).
Last not least, this work has been supported by the COST Association through COST Action CA19135 (CERCIRAS: Connecting Education and Research Communities for an Innovative Resource Aware Society).

Special thanks go to all who have contributed to the design and implementation of the TeamPlay coordination language:
Julius Roeder,
Benjamin Rouxel,
Steven Swatman,
Wouter Loeve and
Sebastian Altmeyer.

%We thank the reviewers for their suggestions on improving this paper.

%\bibliography{bibliography}
%\bibliographystyle{splncs}
%\bibliographystyle{splncs04}

%\end{document}
