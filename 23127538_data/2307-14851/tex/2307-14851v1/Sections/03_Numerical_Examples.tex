\section{Numerical examples}
In our work, the meta-training stage is executed for 40000 epochs utilizing the AdamW optimizer, where the initial values of the meta-learning rate and inner-loop learning rate are set to 1e-3 and 5e-3, respectively. The meta-learning rate is gradually reduced by a factor of 0.8 every 2000 epochs, while the inner-loop learning rate undergoes a similar reduction for the first 20000 epochs, remaining constant thereafter. During the meta-testing stage, the optimized network parameters from the meta-training stage are exposed to individual fine-tuning for each SPT, with a total of 300 epochs executed and an initial learning rate of 1e-4. Every fine-tuning process consists of a total of 300 epochs with an initial learning rate of 1e-4. We need to emphasize, however, that such time-intensive training is definitely unnecessary to the task initialized from Meta-Processing; rather, we do it for the sole purpose of facilitating better comparisons with randomly initialized network. \\

We now present the results from our approach on both synthetic and field data. To validate the effectiveness of the Meta-Processing algorithm, we compare its prediction results with those of randomly initialized networks. Our assessment begins with a thorough evaluation of the performance of our approach to synthetic data. Subsequently, we present the results of further testing conducted on field data. \\


\subsection{Synthetic data}

\subsubsection{Denoising}
In the first example, we focus on removing random noise, which is the most common type of noise. To compare the convergence speed and accuracy of the meta-learning initialization-based network (MLIN) and the randomly initialized network (RIN) during the fine-tuning stage, MSE and MSSSIM losses are utilized as evaluation metrics. The metrics are plotted in Figures \ref{fig5}a and \ref{fig5}b, where the epochs marked with a star indicate the number of epochs of training required for the MLIN to achieve the same metric as the RIN. Same notation will be used later. We can see that, the MLIN achieves significantly smaller MSE loss than the RIN after only one epoch of gradient descent updates, which is far less than the 300 epochs required by the RIN. Moreover, from the perspective of the MSSSIM loss, MLIN surpasses the performance of the RIN after only 13 epochs of optimization. These demonstrate that the MLIN outperformed the RIN in terms of both convergence speed and accuracy. \\

The prediction results of MLIN and RIN for unseen test data are shown in Figure \ref{fig7}, with their corresponding input and label data depicted in Figure \ref{fig6}. In Figure \ref{fig7}, the first, second, and third rows correspond to RIN with 10, 100, and 300 epochs training, respectively, while the fourth row corresponds to MLIN with 10 epoch training. As we can see, the proposed Meta-Processing algorithm leads to an ideal denoising performance after only 10 epochs of optimization, achieving an MSE of 1.98e-6 and an MSSSIM of 9.39e-5. In contrast, the RIN with 10 epochs of optimization shows almost no denoising ability, which is attributed to the lengthy optimization process required by RIN. Even with 300 epochs of training, the denoising results of RIN only reach an MSE of 2.93e-5 and an MSSSIM of 8.38e-5. \\

% Figure environment removed 

% Figure environment removed 

% Figure environment removed 

\subsubsection{Interpolation}
Next, we present the fine-tuning training of MLIN for a seismic interpolation task and its prediction results on the test data set, which are also compared with RIN to demonstrate its performance. Figures \ref{fig8}a and \ref{fig8}b show the MSE and MSSSIM loss curves as a function of the training epochs, respectively. Likewise, compared to RIN, MLIN exhibits a significant superiority in terms of convergence speed and accuracy. Interpolation comparisons of MLIN and RIN to test data set are displayed in Figure \ref{fig9}. The results clearly demonstrate that our method provides a better interpolation performance and less energy leakage compared to the full data, even for RINs trained with 300 epochs. Numerically, our method achieves an MSE of 2.99e-7 and an MSSSIM of 3.70e-5 with 10 epoch training, while the RIN trained for 300 iterations only holds an MSE of 4.78e-5 and an MSSSIM of 9.75e-5. \\

% Figure environment removed 

% Figure environment removed


\subsubsection{Ground roll attenuation}
Ground roll noise is a type of seismic noise that can severely affect the quality of seismic inversion and imaging. This type of noise is often prevalent in land data, but also present in ocean bottom recording. It is a low-frequency in nature and propagates horizontally near the surface with shear wave velocity speed and can easily overwhelm reflections. In this task, we will try to use the Meta-Processing algorithm to effectively attenuate Ground roll. \\

Figure \ref{fig10} shows the MSE and MSSSIM loss curves of MLIN and RIN with 300 epochs of training. Once again, it verifies that the Meta-Processing algorithm can enable NNs have faster convergence speed and higher accuracy. For the test data set, our method achieves an MSE of 1.25e-4 and an MSSSIM of 8.4e-3 with 10 epochs of training, however, the RIN trained for 300 epochs only to achieve an MSE of 1.84e-4 and an MSSSIM of 8.9e-3. The results are shown in Figure \ref{fig12}, where the first, second, and third rows come from RIN with 10, 100, and 300 epochs of training, respectively, while the fourth row corresponds to MLIN with 10 epochs of training. The corresponding input (noisy) and label (clean) data are displayed in Figure \ref{fig11}. We can see that our method can effectively remove ground roll noise while preserving the signal with only 10 epochs of gradient descent updates. In contrast, the performance of RIN converges slowly as the number of epochs increases, as it is not easy to find the optimal solution from a random set of network parameters. \\

% Figure environment removed 

% Figure environment removed 

% Figure environment removed 


\subsubsection{Imaging enhancement}
Seismic imaging is a widely used method for exploring the subsurface structures of the Earth. Several factors can influence the quality of seismic imaging. Specifically, the geometry and spacing of the geophones used during data acquisition can affect the resolution and accuracy of the resulting images. For example, to apply large-scale deepwater surveys in crustal and oceanographic research, ocean bottom node (OBN) seismic acquisition systems typically adopt extremely sparse node spacing to reduce the cost and time consumption in acquisition. The sparse recording, however, leads to poor illumination and reduced continuity of events, posing a huge challenge to imaging. \\

In this task, to overcome the challenges brought by the sparse acquisition system in OBN surveys, we propose to train an NN that can map the images from sparse acquisition to dense acquisition. The trained network is expected to directly process the sparse images, improving the continuity and eliminating artifacts. Here, we use a synthetic model of the South China Sea to generate the seismic data. The model consists of a water layer, a series of thin flat transitional layers, and a series of sedimentary rock layers. Dense seismic data are obtained using finite-difference forward modeling with a grid spacing of 3.0 meters vertically and 3.1 meters horizontally, while sparse seismic data are obtained by subsambling the dense data, resulting in an OBN spacing of 310 meters. We employ the common-receiver Gaussian beam migration method \cite{shi2023elastic, cheng2023elastic, cheng2023seismic} to generate the images for training and testing. \\

Figure \ref{fig13} depicts the MSE and MSSSIM loss curves for the task of imaging enhancement trained by the MLIN and RIN for 300 epochs. Remarkably, after just one epoch of optimization, both MSE and MSSSIM losses of the MLIN are significantly lower than that of the RIN, which undergoes 300 epochs of gradient descent update. This demonstrates that our method, after the Meta-training step, results in significant convergence speed up and accuracy in the imaging enhancement task. \\

We further utilize the trained MLIN and RIN to predict the unseen test data, and the results are displayed in Figure \ref{fig14}. As we can see, the original image (see Figure \ref{fig14}a) suffers from poor continuity and is plagued by noise due to the sparse acquisition. In contrast, the image from dense acquisition (see Figure \ref{fig14}b) has high imaging quality. As demonstrated in Figure \ref{fig14}c, the image produced by the MLIN with 10 epochs of training, which achieves an MSE of 2.2e-3 and an MSSSIM of 5.61e-2, exhibits a significant improvement in both events continuity and noise attenuation. These improvements are crucial for accurately interpreting the subsurface structure. However, RIN does not bring noticeable imaging enhancements (see Figure \ref{fig14}d-f). Instead, it disrupts some event continuity in deeper layers. Even after undergoing 300 epochs of gradient descent updates, RIN only reach an MSE of 4.1e-3 and an MSSSIM of 6.7e-2. \\


% Figure environment removed 

% Figure environment removed 

\subsubsection{Velocity estimation}
Finally, we evaluate the performance of the Meta-Processing algorithm in a velocity estimation task. Specifically, for each shot gather, we will utilize the trained NNs to predict a root-mean-square velocity (referred to as $V_{rms}$), which is usually measured directly from the seismic data and is often used for normal moveout (NMO) correction. That is, the input to NNs is a single shot gather, and the output is the $V_{rms}$. However, it is almost impossible to directly predict the $V_{rms}$ of the entire model size from a single shot gather. Therefore, we follow \cite{harsuko2022storseismic} suggestions and extract the predicted $V_{rms}$ laterally from the shot position to half the maximum offset as our result, which is more reliable. Here, we need to emphasize that, in order to guarantee the same dimensions of input and output, we refer \cite{ovcharenko2022multi} approach of stretching each model along the depth axis to match the size of the shot-gather data along the temporal dimension. This operation allows the NN architecture to be extended to arbitrary model depths. Furthermore, we randomly sample noise from field data (as we will see later), and inject noise into the synthetic data, since we hope the trained NNs can be better generalize to field data testing. \\

Figure \ref{fig15} illustrates the MSE and MSSSIM loss curves of the MLIN and RIN trained for 300 epochs in the velocity estimation task. It is evident that our method-driven MLIN results in superior performance over the RIN in terms of convergence speed and accuracy. This outcome is of great significance for practical applications, as we can fine-tune the MLIN with minimal time investment to obtain a reasonably accurate $V_{rms}$, which can be quickly applied to other SPTs such as NMO correction. \\

The prediction results of the MLIN and RIN on the test set are presented in Figure \ref{fig16}, where panels (a) and (b) are the input and ground truth, respectively, (c) comes from the prediction result of the MLIN after 20 epochs of training, while (d), (e), and (f) correspond to the prediction results of the RIN trained for 20, 100, and 300 epochs, respectively. We can observe that the MLIN, which only requires 20 epochs of optimization, achieves very close prediction results to the ground truth, with a mean absolute error (MAE) of 54.5 m/s. However, the prediction results of the RIN trained for 20 epochs have large errors and contain a lot of signal artifacts. Although the accuracy of the RIN gradually improves with the increase in the number of epochs, there are still signal artifacts and noise, as seen in Figures \ref{fig16}e-f. Even with 300 epochs of gradient descent updates, the RIN only achieves an MAE of 68.5 m/s, which is still higher than the error of MLIN trained for only 20 epochs. \\


% Figure environment removed 

% Figure environment removed 

\subsection{Field data}
In the following, we will utilize the MLIN and RIN, previously trained on synthetic data, to directly predict field data, including seismic denoising, imaging enhancement, and velocity estimation tasks. To improve the networks' generalization capability to the field data, we normalize the amplitude of the field data using mean amplitude normalization instead of the traditional maximum value normalization method. Visually, this means that the normalized field data and the synthetic data have similar amplitudes for most events within the same display range. This step helps in bringing the feature distribution of the field data closer to that of the training synthetic data set. \\

\subsubsection{Denoising}
The MLIN  (MetaL initialization) and RIN (random initialization) are used to denoise a China land dataset, which is known to be polluted by random noise. The resulting denoised results are  displayed in Figure \ref{fig17}. The Meta-Processing algorithm enables the MLIN remove more noise and preserve more effective signals on field data with only 10 epochs of training, as demonstrated by the differences between the original and denoised datasets. On the other hand, RIN requires a large number of epochs of optimization to achieve a slight improvement in denoising performance. Furthermore, some artifacts are introduced in the prediction results of RIN after 100 and 300 epochs of training (see Figure \ref{fig17}f,h), severely contaminating the signal. \\


% Figure environment removed 


\subsubsection{Imaging enhancement}
Then, we assess the performance of the MLIN and RIN on the images acquired from real, sparse OBN surveys. The field data are collected from South China Sea at about 1100 meters water depth, using only five OBNs, with a node spacing of approximately 400 meters. A total of 154 shots are acquired with a spacing of 25 meters. Similar to the synthetic data, we employ common-receiver Gaussian beam migration to generate the input images. The corresponding imaging results, as well as the prediction results of the MLIN and RIN, are displayed in Figure \ref{fig18}. Figure \ref{fig18}a reveals that the sparse acquisition system leads to footprints and arc-shaped artifacts in the images, which considerably reduces image quality. Consequently, the proposed Meta-Processing algorithm helps the NN to overcome these issues effectively with only 10 epochs of optimizations on synthetic data, thereby enhancing the events' continuity and contributing to a significant enhancement in image quality (see Figure \ref{fig18}b). While the RIN removes some of the arc-shaped artifacts, it does not improve the events continuity (see Figure \ref{fig18}c-e). Moreover, it introduces noise and significantly degrades the image resolution, which is unacceptable. \\

% Figure environment removed 

\subsubsection{Velocity estimation}
We present the velocity estimation results of the MLIN and RIN on field data. The data was acquired in North West Australia by a streamer containing 324 hydrophones with a 25 m spacing that recorded 1824 shots, with an example of a shot gather shown in Figure \ref{fig19}. We apply the same procedure as for synthetic data to the field data. In Figure \ref{fig19}, panel (a) shows the input single-shot gather, (b) is the prediction result of the MLIN with 20 epochs of training, and (c), (d), and (e) display the prediction results of the RIN after training for 20, 100, and 300 epochs, respectively. As shown in Figure \ref{fig19}b, the MLIN yields a reasonable velocity estimation. However, as seen in the synthetic data, the RIN produces signal footprints and artifacts in the prediction results (see Figure \ref{fig19}c-e), which are obviously unsuitable to be used as an effective velocity model for guiding the next SPTs. To verify the accuracy of the velocity estimated by the MLIN, we compare the predicted velocity, obtained by averaging the predicted velocities of all traces, with the well velocity, as demonstrated in Figure \ref{fig20}. The predicted results are reasonably consistent with the well velocity, although some differences may exist. These differences may be due to the fact that the well velocity is usually lower than the seismic velocity, or field data may be affected by seismic anisotropy, which we do not consider in the synthetic data. \\

% Figure environment removed 

% Figure environment removed 
%


