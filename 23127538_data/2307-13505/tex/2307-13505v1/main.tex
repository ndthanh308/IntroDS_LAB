\documentclass[preliminary,copyright,creativecommons]{eptcs}
%\providecommand{\event}{GANDALF 2023} % Name of the event you are submitting to

\usepackage{iftex}

\ifpdf
\usepackage{underscore}         % Only needed if you use pdflatex.
\usepackage[T1]{fontenc}        % Recommended with pdflatex
\else
\usepackage{breakurl}           % Not needed if you use pdflatex only.
\fi

\title{Register Minimization of Cost Register Automata over a Field}
\author{
  Yahia Idriss Benalioua
  \institute{Aix Marseille Univ, CNRS, LIS\\Marseille, France}
  \email{yahia-idriss.benalioua@univ-amu.fr}
  \and
  Nathan Lhote
  \institute{Aix Marseille Univ, CNRS, LIS\\Marseille, France}
  \email{nathan.lhote@lis-lab.fr}
  \and
  Pierre-Alain Reynier
  \institute{Aix Marseille Univ, CNRS, LIS\\Marseille, France}
  \email{pierre-alain.reynier@univ-amu.fr}
}
\newcommand{\titlerunning}{Register Minimization of Cost Register Automata over a Field}
\newcommand{\authorrunning}{Y.I. Benalioua, N. Lhote \& P-A. Reynier}

\usepackage{amsthm}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{corollary}{Corollary}[section]
\newtheorem{lemma}{Lemma}[section]
\newtheorem{proposition}{Proposition}[section]
\newtheorem{definition}{Definition}[section]
\newtheorem{example}{Example}[section]
\newtheorem{remark}{Remark}[section]

%\usepackage[dvipsnames]{xcolor}
\usepackage{amsfonts}
\usepackage{mathtools}
\usepackage{stmaryrd}
\usepackage{comment}

\newcommand{\nl}[1]{\textbf{\color{blue}#1}}
\newcommand{\pa}[1]{\textbf{\color{green!50!black}#1}}

\usepackage{xcolor,pgf,tikz,pgflibraryarrows,pgffor,pgflibrarysnakes}
\tikzstyle{background}=[rectangle,fill=gray!10, inner sep=0.1cm, rounded corners=0mm]
\usepgflibrary{shapes}
\usetikzlibrary{snakes,automata}

\usepackage[shortlabels]{enumitem}

\include{commands}

\usepackage{appendix}
\usepackage{babel}

\begin{document}
\maketitle

\begin{abstract}
  Weighted automata ($\WA$) are an extension of finite automata that defines
  functions from words to values in a given semi-ring.
  An alternative model that is deterministic, called Cost Register Automata ($\CRA$),
  was introduced by Alur et al.
  It enriches deterministic finite automata with a finite number of registers,
  which store values, are updated at each transition using the operations of the semi-ring,
  and are combined to produce the output.
  The expressiveness of a $\CRA$ depends on the number of its registers and
  the type of register updates allowed for each of its transitions.
  In particular, the class of functions computable by a $\CRA$ with register updates
  defined by linear (or affine) maps
  correspond exactly with rational functions (functions computable by a $\WA$).
  A natural problem for $\CRA$ is the register minimization problem :
  given a function defined by a $\CRA$, what is the minimal number of registers
  needed to realize this function?

  In this paper, we solve the register minimization problem
  for $\CRA$ over a field with linear (or affine) register updates,
  using an algebraic invariant of a $\WA$ introduced recently by Bell and Smertnig,
  the so-called the linear hull of the automaton.
  This invariant being computable, we are able to explicitly compute a $\CRA$
  with linear (or affine) updates, using the minimal number of registers.

  Using these techniques, we are also able to solve the more general \CRA minimisation problem: given a \CRA and integers $k,d$, is there an equivalent linear (resp.~affine) \CRA using at most $k$ states and $d$ registers?
\end{abstract}


\section{Introduction}
%{\color{MidnightBlue}
%Context
%
%Motivation
%
%Related Work
%
%Presentation of the contributions
%}


\paragraph*{Weighted automata}
(\WA) are a quantitative extension of finite state automata and have been studied since the sixties (\cite{
  Schutzenberger61b}). These automata define functions from words to a given semiring: each transition has a
weight in the semiring and the weight of an execution is the product of the weights of the transitions
therein; then the weights of the different executions over a word are aggregated using the sum of the
semiring.

It turns out that weighted automata over a field enjoy many nice properties: the equivalence of weighted
automata is decidable and they can be minimised, and both can be done efficiently (see \eg \cite{
  Sakarovitch09}). The most studied semirings which are not fields are the tropical semirings and the
semiring of languages, and in both cases equivalence is undecidable (see \cite{Daviaud20,Berstel79}) and no
minimisation algorithm is known.


\paragraph{Cost register automata} (\CRA) have been introduced more recently by Alur \ea \cite{AlurDDRY13}.
A cost
register automaton is a deterministic finite state automaton endowed with a finite number of registers
storing values from the semiring. The register are initialized by some values, then each transition the
values are updated using the operations and constants of the semiring. An easy observation is that \WA are
exactly \CRA with one state and linear updates (the new values of the registers only depend linearly on the
previous ones), however adding states does not extend expressiveness.

CRA with polynomial updates have also been studied, and equivalence is decidable (over a field), however
the techniques used are more sophisticated and the complexity cost is greater \cite{BenediktDSW17},
moreover no minimisation results are known.

\paragraph*{The linear hull} of a \WA is a notion introduced in a recent article by Bell \& Smertnig \cite{
  BellS21}.
This notion is inspired by the algebraic theory needed to study polynomial automata but cast into a linear
setting. A linear algebraic set (aka linear Zariski closed set) is a finite union of vector subspaces; then
the linear hull of a weighted
automaton is the best linear algebraic invariant of the automaton: it is the intersection of all linear
algebraic sets which 1) contain the initial vector and 2) are stable under the updates of the automaton. In
their articles, Bell \& Smertnig show that computing the linear hull of a minimal automaton is enough to
decide the following properties: given a \WA, is it equivalent to a deterministic (resp.~unambiguous) one?

\paragraph*{The register minimisation problem} asks given a \CRA and a number $k$ whether there exists an
equivalent \CRA with at most $k$ registers. From a practical point of view, when implementing a \CRA, the
control part (
state of the DFA) requires a bounded amount of memory, while each register may
store an unbounded element of the semiring. Hence, reducing the number of
registers allows to reduce the worst-case memory usage.
From a theoretical point of view, this new problem can be understood
as a refinement of the classical problem of
minimization of WA. Indeed, a \WA can be translated into a linear CRA with a single state,
and as many registers as the number of states of the \WA. However, it may be possible
to build an equivalent \CRA with fewer registers, but more states. So there exists a
kind of tradeoff between the number of states and the number of registers.

The more general \CRA minimization problem asks, given a \CRA and integers $k,d$ whether an equivalent \CRA with $k$ states and $d$ registers can be constructed.
In this framework, the classical minimization of \WA corresponds to minimizing
the number of registers while using only one state.



\paragraph*{Contributions} A starting observation is that a deterministic \WA is a \CRA with a single
register. Thus one can state the result of Bell \& Smertnig as solving the $1$-register minimisation
problem. Our first contribution is to extend this result by examining the properties of the linear hull, in
order to solve the general register minimisation problem, for linear \CRA. We then generalise this result
in two directions: Firstly we consider \emph{affine} \CRA, which are a very slight extension of \CRA which
allows to use affine maps in the updates of the registers. Of course affine \CRA are not more expressive
than linear ones, since one can transform an affine \CRA in a linear one with one extra register.
Introducing the natural concept of \emph{affine hull} of a \WA we thus show how to minimise the registers
of an affine \CRA. Secondly, we show how the liner (resp.~affine) hull can be used to minimise
simultaneously the number of states and registers of a linear (resp.~affine) \CRA, thus solving the \CRA
minimisation problem.


%\paragraph*{Related work}


\begin{comment}


  \bigskip

  \paragraph{Regular languages}
  Finite state automata, pillar of TCS, regular languages
  Strong property of minimal automaton, link with algebraic properties

  \paragraph{From boolean to weighted setting}
  A language maps a word to a boolean answer, while a weighted automaton maps a word to a weight in some
  semiring, several different settings.
  Strong impact on decision problems, and algebraic properties.
  Quick recap?

  \paragraph{Focus on the field setting}
  Here, we consider the case of a field.
  Nice results for this case, such as minimization, equivalence checking.
  Recent results by Bell and Smertnig have considered an algebraic invariant
  of $\WA$, based on the reachability set, and its so-called linear hull, computed
  in the linear Zariski topology. Useful to characterize, and decide, unambiguous
  and deterministic $\WA$.

  \paragraph{Cost-register automata}
  A few years ago, an alternative model has been proposed by Alur et al. Rough idea: require that the
  underlying automaton is a DFA. To replace
  non-determinism, add variables (aka registers) to store intermediate computations.
  So-called Cost-register automata. Different classes of $\CRA$ according to register updates
  considered. Put some examples.
  Nice equivalence results between different classes of $\WA$ and classes of $\CRA$. Add table?

  \paragraph{Register minimization}
  This model introduces a new minimization problem, the number of registers.
  From a practical point of view, when implementing a $\CRA$, the control part (
  state of the DFA) requires a bounded amount of memory, while each register may
  store an unbounded element of the semiring. Hence, reducing the number of
  registers allows to reduce the worst-case memory usage.
  From a theoretical point of view, this new problem can be understood
  as a refinement of the classical problem of
  minimization of $\WA$. Indeed, a $\WA$ can be translated into a (copyful) linear $\CRA$ with a single state,
  and as many registers as the number of states of the $\WA$. However, it may be possible
  to build an equivalent $\CRA$ with less registers, but more states. So there exists a
  kind of tradeoff between the number of states and the number of registers.
  The classical minimization of $\WA$ corresponds to the setting when one $\WA$nts to minimize
  the number of states.

  \paragraph{Our contributions}
  We first consider linear $\CRA$. For this setting, we show that the linear hull of the reachility
  set introduced by Bell and Smertnig is the right tool to address the register minimization
  problem. Indeed, ...

  Then, we turn to affine $\CRA$. Here, constants can be used to updates registers. This may
  allow to save one register. We show that considering the affine hull of the reachability
  set of the $\WA$, obtained using an affine version of the Zariski topology, allows
  to adapt the reasoning developed for the linear setting.

  \paragraph{Related work}

  Known results when a single law of the semiring is considered.
  No result for two laws.


\end{comment}


\section{Preliminaries}
\iffalse
{\color{MidnightBlue}
Weighted automata

  $\CRA$ (def general, with expressions)

  Topologies considered, associated notations

span, affine span

Define the problem of register minimization for a class of $\CRA$
}
\fi

\paragraph{Basic concepts and notations}
An alphabet $\Sigma$ is a finite set of letters.
$\Sigma^*$ will denote the set of finite words over $\Sigma$, $\epsilon$ the empty word and,
for two words $u$ and $v$, their concatenation will be denoted $uv$.

For two sets $X$ and $Y$, we denote by $X \times Y$ their cartesian product
and by $\proj{X}$ and $\proj{Y}$
we denote the canonical projection on $X$ and $Y$ respectively.

For two integers $i,j$, $\intInterv{i}{j}$ will denote the interval
of integers between $i$ and $j$ (both included).

\paragraph{Algebraic concepts}
A \emph{semigroup} $(S,*)$ is a set $S$ together with an associative binary operation $*$.
If $(S,*)$ has an identity element $e$, $(S,*,e)$ is called a \emph{monoid}
and if, moreover, every element has an inverse, $(S,*,e)$ is called a \emph{group}.
If there is no ambiguity, we will identify algebraic structures with
the set that they are defined on.
A semigroup (or a monoid/group) is said to be \emph{commutative} if its law is commutative.
A sub-semigroup (or sub-monoid/subgroup) of $S$ is a subset of $S$ that is a semigroup (or a monoid/group).
For all subsets $E$ of $S$, $\genSemiGrp{E}$ will denote the smallest sub-semigroup
of $S$ containing $E$ called the sub-semigroup \emph{generated} by $E$.

A \emph{field} $(\mathbb{K},+,\cdot)$ is a structure where $(\mathbb{K},+,0)$ and
$(\mathbb{K}\setminus \left\{ 0 \right\}, \cdot, 1)$ are commutative groups
and multiplication distributes over addition.
For all $n \in \mathbb{N}$, $\mathbb{K}^n$ is an $n$-dimensional \emph{vector space}
over the field $\mathbb{K}$.
We will work with row vectors and apply matrices on the right.
The set of $n$ by $m$ matrices over $\mathbb{K}$ will be denoted by $\matrSet{\mathbb{K}}{n}{m}$
and $\vectSet{\mathbb{K}}{n}$ (or simply $\mathbb{K}^n$ when there is no ambiguity)
will denote set of $n$ dimensional vectors.
For any matrix $M$, we will denote its transpose by $M^t$.
A \emph{vector subspace} of $\mathbb{K}^n$ is a subset of $\mathbb{K}^n$
stable by linear combinations and for all subsets $E$ of $\mathbb{K}^n$,
$\linSpan{E}$ will denote the smallest vector subspace of $\mathbb{K}^n$
containing $E$.

$\mathbb{K}^n$ can also be seen as an $n$-dimensional \emph{affine space}.
Affine maps $f : \mathbb{K}^n \to \mathbb{K}^m$ are maps of the form
$f(u) = u \linPart{f} + \affPart{f}$ where $\linPart{f} \in \matrSet{\mathbb{K}}{n}{m}$
and $\affPart{f} \in \vectSet{\mathbb{K}}{m}$.
An \emph{affine subspace} $A$ of $\mathbb{K}^n$ is a subset of $\mathbb{K}^n$
of the form $A = p + V$ with $p \in A$ and $V$ a vector subspace of $\mathbb{K}^n$.
They are also stable by affine combinations (linear combinations with coefficients adding up to 1).
For all subsets $E$ of $\mathbb{K}^n$, $\affSpan{E}$ will denote the smallest
affine subspace of $\mathbb{K}^n$ containing $E$.

\paragraph{Weighted Automata and Linear Representations}
Let $\Sigma$ be a finite alphabet and $(\mathbb{K},+,\cdot)$ be a field.
A \emph{Weighted Automaton} (WA), on $\Sigma$ over $\mathbb{K}$,
is a tuple $\mathcal{W}=(Q,i,t,\Delta)$ where
$Q$ is a finite set of states, $i,t : Q \to \mathbb{K}$ are the initial and terminal
functions respectively and $\Delta : Q \times \Sigma \times Q \to \mathbb{K}$
is the transition function of the automaton.
$|Q|$ will be called the \emph{dimension} of the automaton.
Here, $i,t$ and $\Delta$ are total maps, the classical setting of partial maps
is recovered by assigning a null weight.

For $p,q \in Q$ and $a \in \Sigma$, if $k = \Delta(p,a,q)$, the transition will be denoted
by $p \xrightarrow{a \, :\, k} q$.
A run of $\mathcal{W}$ on a word $w = a_1 \dots a_n \in \Sigma^*$
is a sequence of transitions
$q_0 \xrightarrow{a_1 \,:\, k_1} q_1 \xrightarrow{a_2 \,:\, k_2} \dots \xrightarrow{a_n \,:\, k_n} q_n$.
The weight of the run is the following product of weights: $i(q_0) k_1 \dots k_n t(q_n)$.
%\pa{def ok ?}
We say that this run is \emph{accepting} if every weight in this product is non null.
The function $\llbracket \mathcal{W} \rrbracket : \Sigma^* \to \mathbb{K}$
realized by the $\WA$ maps each word $w$ to the sum of the weights of all the runs
of $\mathcal{W}$ on $w$.

A function $f : \Sigma^* \to \mathbb{K}$ is said to be \emph{rational} if there
exists a $\WA$ $\mathcal{W}$ such that $f = \llbracket \mathcal{W} \rrbracket$.
Rational functions can also be defined using linear representations :

\begin{definition}[Linear Representations]
  Let $f : \Sigma^* \to \mathbb{K}$ be a rational function.

  A \emph{linear representation} of dimension $n \in \mathbb{N}$ of $f$
  is a triple $\mathcal{R} = (u,\mu,v)$, where $u \in \vectSet{\mathbb{K}}{n}$,
  $v \in \matrSet{\mathbb{K}}{n}{1}$ and $\mu : \Sigma^* \to \sqmatrSet{\mathbb{K}}{n}$
  is a monoid morphism such that, for all $w \in \Sigma^*$, $f(w) = u \mu(w) v$.

  $f$ will then be denoted as $\llbracket \mathcal{R} \rrbracket$.
  $u$ and $v$ will be called the \emph{initial} and \emph{terminal} vectors respectively
  and the $\mu(a)$, for $a \in \Sigma$, will be called the \emph{transition matrices}.
\end{definition}

There is a one-to-one correspondance between weighted automata and linear representations
(see~\cite{Sakarovitch09}).
We will then use either of those terms and definitions interchangeably.

\begin{example}
  \label{ex:WA}
  We consider the \WA depicted on Figure~\ref{fig:WA}, on
  the alphabet $\{a\}$ and over the field of real numbers. There
  are two states $p$ and $q$. We have $i(p)=1=t(p)$, while $i(q)=0=t(q)$. Only
  transitions whose weight is non null are depicted. One can verify that the function
  realized by this \WA maps the word $a^n$ to
  $2^n$ if $n$ is even, and to $0$ otherwise. The linear representation $\mathcal{R} =(u,\mu,v)$
  associated with this $\WA$
  is obtained by taking $u=(1\ 0)$, $v = (1\ 0)^{t}$, and $\mu(a) =
  \left (\begin{array}{cc}
           0\ 2 \\
           2\ 0
  \end{array}
  \right )
  $.
\end{example}

\input{fig-WA}

A $\WA$ / linear representation of a rational function $f$ is said to be \emph{minimal}
if its dimension is minimal among all the $\WA$ / linear representations of $f$.
We also have the following characterization of minimal representations
(see~\cite{Sakarovitch09} for a proof):
\begin{proposition}
  \label{prop:caracMinRep}
  An $n$-dimensional linear representation $\mathcal{R} = (u,\mu,v)$ is minimal
  if and only if $\linSpan{u \mu(\Sigma^*)} = \vectSet{\mathbb{K}}{n}$
  and $\linSpan{\mu(\Sigma^*)v} = \matrSet{\mathbb{K}}{n}{1}$.
\end{proposition}

\paragraph{Expressions, substitutions and Cost Register Automata}
For a field $(\mathbb{K},+,\cdot)$ and a finite set of variables $\varSet$
disjoint from $\mathbb{K}$,
let $\expr{\varSet}$ denote the set of expressions generated by the grammar
$e \Coloneqq k \,|\, X \,|\, e + e \,|\, e \cdot e$, where $k \in \mathbb{K}$
and $X \in \varSet$.
An expression is \emph{linear} (resp. affine) if it has the form
$\sum_{i=1}^{n} \alpha_i X_i$ (resp. $\sum_{i=1}^{n} \alpha_i X_i + \beta$)
for some family of $\alpha_i , \beta \in \mathbb{K}$ and $X_i \in \varSet$.
We will denote by $\linExpr{\varSet}$ (resp. $\affExpr{\varSet}$) the set of linear
(resp.\ affine) expressions. %\nl{expressions or polynomials?}

A \emph{substitution} over $\varSet$ is a map $s : \varSet \to \expr{\varSet}$.
It can be extended to a map $\expr{\varSet} \to \expr{\varSet}$ by substituting
each variable $X$ in the expression given as an input by $s(X)$.
By identifying $s$ with its extension, we can then compose substitutions.
We call \emph{valuations} the substitutions of the form $v : \varSet \to \mathbb{K}$.
The set of substitutions over $\varSet$ will be denoted by $\subs{\varSet}$
and the set of valuations $\valuations{\varSet}$.

\begin{definition}[Cost Register Automaton]
  A \emph{cost register automaton} ($\CRA$ for short), on the alphabet $\Sigma$ over the field $\mathbb{K}$,
  is a tuple $\mathcal{A} = (Q, q_0, \varSet, v_0, \outFctCRA, \delta)$
  where $Q$ is a finite set of \emph{states}, $q_0 \in Q$ is the initial state
  $\varSet$ is a finite set of registers (variables),
  $v_0 \in \valuations{\varSet}$ is the registers' initial valuation,
  $\outFctCRA : Q \to \expr{\varSet}$ is the output function,
  and $\delta : Q \times \Sigma \to Q \times \subs{\varSet}$ is the transition function.

  We will denote by $\delta_Q \coloneqq \proj{Q} \circ \delta$ the transition function
  of the underlying automaton of the $\CRA$
  and $\delta_{\varSet} \coloneqq \proj{\subs{\varSet}} \circ \delta$
  its register update function.

  $\mathcal{A}$ computes a function $\llbracket \mathcal{A} \rrbracket : \Sigma^* \to \mathbb{K}$
  defined as follows :
  the configurations of $\mathcal{A}$ are pairs $(q,v) \in Q \times \valuations{\varSet}$.
  The run of $\mathcal{A}$ on a word $w = a_1 \dots a_n \in \Sigma^*$ is the sequence
  of configurations $(q_i,v_i)_{i \in \intInterv{0}{n}}$
  where, $q_0$ is the initial state, $v_0$ is the initial valuation and,
  for all $i \in \intInterv{1}{n}$, $q_i = \delta_Q (q_{i-1},a_i)$
  and $v_i = v_{i-1} \circ \delta_{\varSet}(q_{i-1},a_i)$.
  We then define $\llbracket \mathcal{A} \rrbracket (w) = v_n (\outFctCRA(q_n))$.

  $\delta$ can be extended to words by setting, for all $q \in Q$,
  $\delta (q,\epsilon) = (q , id_{\varSet})$, where $id_{\varSet}$
  is the substitution such that $id_{\varSet}(X) = X$ for all $X \in \varSet$,
  and, for all $a \in \Sigma$ and $w \in \Sigma^*$,
  $\delta_Q (q,aw) = \delta_Q(\delta_Q(q,a),w)$
  and $\delta_{\varSet} (q,aw) = \delta_{\varSet}(q,a)
  \circ \delta_{\varSet}(\delta_Q(q,a),w)$.
  We then have
  \[\llbracket \mathcal{A} \rrbracket (w)
  = v_0 \circ \delta_{\varSet} (q_0, w) (\outFctCRA(\delta_Q(q_0,w)))\]

  A $\CRA$ $\mathcal{A} = (Q, q_0, \varSet, v_0, \outFctCRA, \delta)$ is called \emph{linear}
  (resp. \emph{affine}) if, for all $q \in Q, a \in \Sigma$ and $X \in \varSet$,
  $\delta_{\varSet}(q,a)(X) \in \linExpr{\varSet}$ (resp. $\affExpr{\varSet}$)
  and $\outFctCRA(q)\in \linExpr{\varSet}$ (resp. $\affExpr{\varSet}$).
\end{definition}


\begin{example}[Example~\ref{ex:WA} continued]
  \label{ex:CRA}
  Two \CRA are depicted on Figure~\ref{fig:CRA}. They are both on the alphabet
  $\{a\}$ and over the field of real numbers, and both realize the same function
  as the $\WA$ considered in Example~\ref{ex:WA}.

  The \CRA depicted on the left has a single state, and two registers $X$ and $Y$.
  They are initialised to $1$ and $0$ respectively, and the output function maps the unique
  state to the expression $X$. Last, the single transition is associated with the substitution $s$
  which maps $X$ to $2Y$, and $Y$ to $2X$, respectively.

  The \CRA depicted on the right has two states $p$ and $q$, and a single register $X$.
  The initial state is $p$, and the output function maps $p$ to $X$, and $q$ to $0$.
  The two transitions of the \CRA apply the same substitution which maps
  $X$ to $2X$.
\end{example}

\input{fig-CRA}

It is well-known that linear \CRA and \WA are equivalent~\cite{AlurDDRY13}.
One can actually directly view a \WA as a linear \CRA with a single state:
\begin{proposition}
  \label{prop:linRepEquivCRA1Stt}
  There is a one-to-one correspondence between \WA and
  linear \CRA with a single state.
\end{proposition}

Given a \WA, one can build an equivalent \CRA with as many
registers as states of the \WA. The linear presentation of the \WA yields the
transitions of the \CRA: for each letter $a$, the matrix $\mu(a)$
can be interpreted as a (linear) substitution, associated with the self-loop
of label $a$.

Conversely, we first observe that, for a (linear) $\CRA$
$\mathcal{A} = (Q, q_0, \varSet, v_0, \outFctCRA, \delta)$,
we can assume that $\varSet=\left\{X_1, \dots, X_n \right\}$ is ordered.
We then identify any linear expression $e =  \sum_{i=1}^{n} \alpha_i X_i$
(with the $\alpha_i$ not present in the expression assumed to be 0)
with the linear form $\expToMap{e} : \mathbb{K}^n \to \mathbb{K}$
defined by the column matrix
$(\alpha_1 \dots \alpha_n)^t$.
We can then identify any linear substitution $s : \varSet \to \linExpr{\varSet}$
with the linear map $\expToMap{s} : \mathbb{K}^n \to \mathbb{K}^n$
defined by the block matrix $(\expToMap{s(X_1)} | \cdots | \expToMap{s(X_n)})$,
and we can identify any valuation $v : \varSet \to \mathbb{K}$ with the vector
$\expToMap{v}=(v(X_1) \cdots v(X_n))$ of the vector space $\mathbb{K}^n$.

The registers of $\mathcal{A}$ and their updates can then be characterized by
the values of $\expToMap{v_0}$, $\expToMap{\delta_{\mathcal{X}}(q,a)}$ and
$\expToMap{\outFctCRA(q)}$, for $q \in Q$ and $a \in \Sigma$, and we can check that
\[\llbracket \mathcal{A} \rrbracket (w) = \expToMap{v_0}\ \ \expToMap{\delta_{\varSet}(q_0,w)}\ \
\expToMap{\outFctCRA(\delta_Q(q_0,w))}\]

The result easily follows when the \CRA has a single state.

\begin{example}[Example~\ref{ex:WA} continued]
  The \CRA depicted on the left of Figure~\ref{fig:CRA} is obtained by
  the translation of \WA into \CRA with a single state.
\end{example}

%\begin{remark}
%  \label{rmk:linRepEquivCRA1Stt}
%  Note that, with this characterization, there is a clear correspondance between
%  linear representations and $\CRA$ with only one state.
%\end{remark}


\section{Equivalences between $\WA$ and \CRA}

In this section, we survey the known equivalences between subclasses of $\WA$ and fragments of \CRA, and the
known associated decidability results.

%Given a \WA $\mathcal{W}=(Q,i,t,\Delta)$ over $\Sigma$, a word $w = a_1 \dots a_n \in \Sigma^*$,
%and a run 
%$q_0 \xrightarrow{a_1 \,|\, k_1} q_1 \xrightarrow{a_2 \,|\, k_2} \dots \xrightarrow{a_n \,|\, k_n} q_n$
%of $\mathcal{W}$ on $w$, we say that this run is \emph{accepting} if 
%$i(q_0)\neq 0$, $t(q_n)\neq 0$, and for each $j\in \intInterv{1}{n}$, $k_j\neq 0$.

We first recall the following classical subclasses of $\WA$:
\begin{definition}
  Let $\mathcal{W}=(Q,i,t,\Delta)$ be a $\WA$, and $k\in \mathbb{N}$.
  We say that:
  \begin{itemize}
    \item $\mathcal{W}$ is \emph{sequential} if there is a single state $q\in Q$ such that
    $i(q)\neq 0$, and for each letter $\sigma\in \Sigma$ and state $q\in Q$, there is at
    most one state $q'$ such that $\Delta(q,\sigma,q')\neq 0$,
    \item $\mathcal{W}$ is \emph{multi-sequential} if it is defined as the disjoint union of
    finitely many sequential $\WA$,
    \item $\mathcal{W}$ is $k$-ambiguous if for every word $w$, there are at most
    $k$ accepting runs of $\mathcal{W}$ on $w$. When $k=1$, we say that $\mathcal{W}$ is \emph{unambiguous}
    . Last, $\mathcal{W}$
    is  \emph{finitely-ambiguous} if it is $k$-ambiguous for some $k$.
  \end{itemize}
\end{definition}

\begin{remark}
  \label{rk:seq}
  Observe that a sequential \WA is syntactically equivalent to a linear \CRA with a single
  register, as a \CRA has an underlying deterministic finite automaton.
\end{remark}

\begin{example}[Example~\ref{ex:WA} continued]
  The \CRA depicted on the right of Figure~\ref{fig:CRA} is obtained
  from the (sequential) \WA described in Example~\ref{ex:WA}.
\end{example}


Now we introduce two classical fragments of $\CRA$.
To do so we consider restrictions on updates.

\begin{definition}[Copyless \CRA]
  We say that an expression $e\in \expr{\varSet}$ is \emph{copyless} if $e$ uses every variable from $\varSet$ at most once.
  A substitution $s$ is \emph{copyless} if for every $X\in \varSet$, the expression $s(X)$
  is copyless and $X$ appears in at most one of the expressions
  $\{s(Y) \mid Y \in \varSet\}$.

  We say that a \CRA is \emph{copyless} if for every transition $\delta(q,a)=(p,s)$, the substitution
  $s$ is copyless, and for every state $q\in Q$, the output expression $\outFctCRA(q)$
  is copyless.
\end{definition}

\begin{definition}[Monomial \CRA]
  Let $e =  \sum_{i=1}^{n} \alpha_i X_i$ be a linear expression. We say that $e$ is \emph{monomial}
  if the sum contains a single term, \emph{i.e.} at most one $\alpha_i$ is not null.
  A linear $\CRA$ is \emph{monomial} if all its updates use monomial expressions. Last, we say
  that it is \emph{transition-monomial} if every update used in a transition is a monomial expression, but
  updates used
  in the final output function may not be.
\end{definition}


The landscape of the known equivalences between classes of weighted automata, and
classes of $\CRA$, is depicted on Figure~\ref{fig:landscape}. On this figure, all classes of
\CRA considered are linear, except affine \CRA.

Let us comment briefly on theses equivalences.
First, the equivalence between linear $\CRA$ and Weighted Automata has been proven
in the original paper introducing Cost Register automata~\cite{AlurDDRY13}. In addition, when
the $\WA$ is unambiguous, then the first law of the semiring, which is used to
aggregate the weights of the different runs, becomes useless. This allows to
show the equivalence between unambiguous $\WA$ and monomial $\CRA$.
The other equivalences are rather folklore and not very involved. For instance,
the one between
sequential $\WA$ and $\CRA$ has been discussed in Remark~\ref{rk:seq}, while
the one between unambiguous multi-sequential $\WA$ and
copyless monomial $\CRA$ comes from~\cite{DaviaudJRV17}.
As these equivalences do not constitute the
main contribution of this paper, we will not develop them further.
Observe that all these equivalences are valid for an arbitrary semiring~\footnote{However, as we lose
commutativity, this requires to slightly modify the definitions of expressions, by writing
them as $X \alpha$ instead of $\alpha X$.}.


We now turn to decidability results for the case of fields.
First, Bell and Smertnig have recently shown in~\cite{BellS21,BS23} that
given a $\WA$ over a field, one can decide whether there exists an equivalent
sequential (resp. unambiguous) $\WA$.
These two results are depicted by the dashed arrows.

These two problems are \emph{subclass definability problems}, \emph{i.e.} they consist in deciding, given
an element in some superclass, whether there exists an equivalent element in some subclass.

In this paper, we will focus on a particular instance of such subclass definability problem, which is
the problem of \emph{register minimization}. It is defined as follows:
\begin{definition}[Register minimization problem]
  Given a class $\cal C$ of \CRA, we consider the following decision problem:
  \begin{itemize}
    \item \textbf{Input:} a \CRA  in the class $\cal C$, and an integer $k\in \mathbb{N}$
    \item \textbf{Question:} Does there exist an equivalent \CRA  in the class $\cal C$
    with at most $k$ registers?
  \end{itemize}
\end{definition}

This constitutes a natural generalization of the classical minimization problem for
finite state automata. In the context of implementing \CRA, the main resource, regarding
memory usage for instance, is the set of registers. It is thus natural to try to minimize it.
Unfortunately, this is a hard problem, which has only few positive answers.
This problem has been first studied in~\cite{DBLP:conf/icalp/AlurR13} for so-called additive \CRA, \emph{i.e.}
monomial \CRA over the integers, showing it is PSpace-complete in this case.
Then, this problem has been proven to be decidable for semirings satisfying some
conditions (fulfilled by fields), for two classes of $\CRA$: copyless monomial $\CRA$~\cite{DaviaudJRV17}, and
monomial $\CRA$~\cite{DRT16}. In Figure~\ref{fig:landscape}, this is emphasized by surrounding these two
classes with dotted lines. In all these positive results, the \CRA considered use only the multiplicative
law of the semiring. In this
work, we show that this problem is decidable for the general case
of linear \CRA, and also for affine \CRA. This constitutes the first positive
results for register minimization in the presence of the two laws of the semiring.

\input{fig-landscape}

\iffalse
{\color{MidnightBlue}
  \begin{itemize}
    \item seq $\WA$ = $\CRA$ 1 register
    \item multi-seq $\WA$ = copyless $\CRA$ *c
    \item unamb $\WA$ = $\CRA$ *c
    \item finitely amb $\WA$ = $\CRA$ *c with plus at the end
    \item $\WA$ = linear $\CRA$ = affine $\CRA$
  \end{itemize}

  Examples
}

\section{Register minimization for $\CRA$ with a single law}
{\color{MidnightBlue}
Known results from LICS16, FoSSaCS17 apply, and give
decidability of reg min for two classes of $\CRA$ : copyless $\CRA$ *c
and $\CRA$ *c
}
\fi


\section{Register minimization for linear $\CRA$}
In this section, we introduce the \LH of a $\WA$ and use it to state our main result:
the minimal number of registers needed by a $\CRA$ to realize a rational function
is the dimension of the \LH of a minimal $\WA$ realizing it.
To do so, we will need the following topological notions:

Let $\mathbb{K}$ be a field and $n\in \mathbb{N}$.
The \emph{Zariski topology} on $\mathbb{K}^n$ is defined as the topology
whose closed sets are the sets of common roots of a finite collection of polynomials
of $\mathbb{K}[X_1, \dots, X_n]$.
A linear version of this topology, called the \emph{linear Zariski topology},
was introduced by Bell and Smertnig in~\cite{BellS21}.
Its closed sets are finite unions of vector subspaces of $\mathbb{K}^n$.

For a set $S \subseteq \mathbb{K}^n$, $\zarClosure{S}$ and $\linClosure{S}$
will denote its closure in the Zariski and linear Zariski topologies respectively.

A set $S \subseteq \mathbb{K}^n$ is called \emph{irreducible} if,
for all closed sets $C_1$ and $C_2$,
such that $S \subseteq C_1 \cup C_2$, we have either $S \subseteq C_1$ or $S \subseteq C_2$.
The (linear) Zariski topology is a Noetherian topology
in which every closed set can be written as a finite union of irreducible components.
In the following we will use (implicitly) the following properties of irreducible sets
: if $S \subseteq \mathbb{K}^n$ is irreducible and $f : \mathbb{K}^n \to \mathbb{K}^n$
is continuous, then $f(S)$ is irreducible (see~\cite{BellS21} for proofs and references).

In the linear Zariski topology on $\mathbb{K}^n$,
irreducible sets are vector subspaces of $\mathbb{K}^n$
and linear maps are continuous and closed maps (maps closed sets to closed sets).
In particular, for all $S \subseteq \mathbb{K}^n$ and linear map $f : \mathbb{K}^n \to \mathbb{K}^n$,
$\linClosure{f(S)}= f(\linClosure{S})$.

Let's now define the algebraic invariant of $\WA$ that we will use to solve the register minimization
problem for linear $\CRA$:
\begin{definition}
  Let $\Sigma$ be a finite alphabet and let $\mathcal{R} = (u,\mu,v)$
  be a linear representation on $\Sigma$ over $\mathbb{K}$.

  The (left) \emph{reachability set} of $\mathcal{R}$ is defined as
  $\lReachSet{\mathcal{R}} = u \mu(\Sigma^*) = \left\{ u \mu(w) \,\middle|\, w \in \Sigma^* \right\} $

  The (left) \emph{\LH} of $\mathcal{R}$ is the closure of $\lReachSet{\mathcal{R}}$
  in the linear Zariski topology.
  It will be denoted by $\linHull{\mathcal{R}}$.
  Its \emph{dimension} $\dim(\linHull{\mathcal{R}})$ is defined as the maximal dimension
  of its irreducible components.

  (We can dually define the right reachability set and right \LH of $\mathcal{R}$
  as $\rReachSet{\mathcal{R}} = \mu(\Sigma^*) v$ and $\rlinHull{\mathcal{R}}$
  respectively.)
\end{definition}

\begin{example}[Example~\ref{ex:WA} continued]
  \label{ex:linHullWA}
  The reachability set of the $\WA$ considered in example~\ref{ex:WA}
  is $\lReachSet{\mathcal{R}} = \left\{ (2^{2n},0) \,\middle|\, n \in \mathbb{N} \right\} \cup
  \left\{ (0,2^{2n+1}) \,\middle|\, n \in \mathbb{N}\right\}$.
  Its \LH is then the union of the two coordinate axes of the plane
  $\linHull{\mathcal{R}} = \linSpan{1,0} \cup \linSpan{0,1}$.

  Indeed, the inclusion $\subseteq$ comes from the fact that $u = (1,0) \in \linSpan{1,0}$
  and $\linSpan{1,0} \cup \linSpan{0,1}$ is stable by multiplication by $\mu(a)$
  and the inclusion $\supseteq$ comes from the fact that, for the linear Zariski topology,
  $\left\{ (1,0) \right\}$ is dense in $\linSpan{1,0}$
  and $\left\{ (0,2) \right\}$ is dense in $\linSpan{0,1}$.
\end{example}

\begin{lemma}
  The \LH of a linear representation is computable.
\end{lemma}
\begin{proof}[Proof sketch]
  It was shown in~\cite{HruOuaPouWor2018} that the Zariski closure of a semigroup
  generated by a finite set of matrices is computable.
  This result can be used (as in~\cite{LefOuaPurWor2021}, Proposition 1) to
  compute their linear Zariski closure:

  For a given finite set of matrices $S \subseteq \sqmatrSet{\mathbb{K}}{n}$,
  let $\zarClosure{\genSemiGrp{S}} = Z_1 \cup \dots \cup Z_r$ with the $Z_i$
  being the irreducible components.
  We then have $\linClosure{\genSemiGrp{S}} = \linSpan{Z_1} \cup \dots \cup \linSpan{Z_r}$.

  Indeed, let $W = W_1 \cup \dots \cup W_s$ be a closed set (in the linear Zariski topology)
  covering $\genSemiGrp{S}$.
  Since, for all $i \in \llbracket 1,r \rrbracket $, $Z_i \subseteq Z$
  and $Z_i$ is irreducible, then there exists $j \in \llbracket 1,s \rrbracket $
  such that $Z_i \subseteq W_j$ and since $W_j$ is a vector subspace,
  then $\linSpan{Z_i} \subseteq W_j$.
  Finally $\linSpan{Z_1} \cup \dots \cup \linSpan{Z_r} \subseteq W$.


  For all $i \in \intInterv{1}{r}$, $Z_i$ is given by a finite set of polynomial equations.
  We can then compute a basis of $\linSpan{Z_i}$ by starting from any
  vector satisfying the equations defining $Z_i$ and adding in new vectors,
  satisfying the equations defining $Z_i$ and the equations stating their linear
  independence from the previously computed vectors.
  This procedure terminates after $\dim(\linSpan{Z_i})$ vectors are found.
  The vectors satisfying the given equations are computable using
  quantifier elimination in the theory of reals.
%  \textcolor{red}{(restricitions sur $\mathbb{K}$ ?)}

  For a given linear representation $\mathcal{R} = (u,\mu,v)$,
  $\linClosure{\mu(\Sigma^*)}$ is then computable and so is
  $\linHull{\mathcal{R}} = \linClosure{u\mu(\Sigma^*)} = u\linClosure{\mu(\Sigma^*)}$.

  Another approach, working directly with the linear Zariski topology,
  was proposed by Bell and Smertnig in~\cite{BS23}.
\end{proof}

The \LH of two representations of the same function does not necessarily coincide but,
since $\mathbb{K}$ is a field, it is well known that for every rational function $f$,
there exists a (computable) minimal linear representation of $f$
that is unique up to similarity in the following sense (see~\cite{Sakarovitch09}):

\begin{definition}
  Let $\mathcal{R} = (u,\mu,v)$ and $\mathcal{R}' = (u',\mu',v')$
  be $n$-dimensional linear representations over $\mathbb{K}$.

  $\mathcal{R}$ and $\mathcal{R}'$ are said to be \emph{similar}
  if there exists an invertible matrix $P \in \sqmatrSet{\mathbb{K}}{n}$
  such that $u' = u P$, $\mu'(a) = P^{-1} \mu(a) P$ for all $a \in \Sigma$
  and $v' = P^{-1}v$.
\end{definition}

We then see that the \LH of two similar representations only differ by a change of basis.
In particular, their dimension and number of components coincide.

The notion of \LH was introduced by Bell and Smertnig in~\cite{BellS21}.
They showed, in~\cite{BS23}, that the \LH is computable and used it to show that
determining if a rational function is computable by a sequential
(or an unambiguous) $\WA$ over a field is decidable.

\begin{theorem}[\cite{BellS21}]
  Let $f$ be a rational function.

  $f$ can be realized by a sequential $\WA$ if and only if
  the \LH of a minimal linear representation of $f$ has a dimension of at most 1.
\end{theorem}

Our main result generalizes this theorem by linking the dimension of the \LH
to the number of registers of a $\CRA$:
\begin{theorem}
  \label{thm:mainThm}
  Let $f$ be a rational function.

  The minimal number of registers needed by a linear $\CRA$ to realize $f$
  is the dimension of the \LH of a minimal linear representation of $f$.

  Moreover, if $k$ denotes the dimension of this \LH and $d$ its number of irreducible components,
  there exists a (computable) $\CRA$ with $d$ states and $k$ registers realizing $f$.
\end{theorem}

\begin{corollary}
  The register minimization problem for linear $\CRA$ is decidable.
\end{corollary}

\begin{example}[Example~\ref{ex:WA} continued]
  As we have seen in example~\ref{ex:linHullWA},
  $\linHull{\mathcal{R}}$ is 1-dimensional and has two irreducible components,
  thus $\llbracket \mathcal{R} \rrbracket$ can be realized by a
  $\CRA$ with two states and one register (depicted on the right of figure~\ref{fig:CRA}).
\end{example}


Let's first show that the dimension of the \LH of a minimal
linear representation is minimal.
\begin{proposition}
  \label{prop:dimLHMin}
  Let $\mathcal{R}_{\min}$ be a minimal linear representation of
  a rational function $f$.

  If $\mathcal{R}$ is a linear representation of $f$, then
  $\dim(\linHull{\mathcal{R}_{\min}}) \leq \dim(\linHull{\mathcal{R}})$.
\end{proposition}

In the following, for all $n \in \mathbb{N}$,
let $\canonBasis{n} = \left\{ e_1, \dots, e_n \right\}$
denote the canonical basis of $\mathbb{K}^n$.
For two bases $B$ and $B'$ of the same vector space,
let $\chgBaseMatr{B}{B'}$ denote the change of basis matrix from $B$ to $B'$.
And finally, for two integers $i$ and $j$, let $I_i$ denote the identity matrix of size $i$
and let $\resizIdMatr{i}{j}$ denote the $i$ by $j$ matrix $(I_i \ |\ 0)$ if $i \leq j$
and $\resizIdMatr{j}{i}^t$ otherwise.

\begin{remark}
  \label{rmk:chgBase}
  If $V$ is a $d$-dimensional vector subspace of $\mathbb{K}^n$ and
  $B$ is a basis of $\mathbb{K}^n$ whose first $d$ vectors form a basis of $V$,
  then, for all $v \in V$, since the $n-d$ last entries of the vector $v \chgBaseMatr{\canonBasis{n}}{B}$
  are all zeros, we note that
  $v \chgBaseMatr{\canonBasis{n}}{B} \resizIdMatr{n}{d} \resizIdMatr{d}{n} \chgBaseMatr{B}{\canonBasis{n}} = v$.
\end{remark}

\begin{lemma}
  \label{lem:leftRightMin}
  Let $\mathcal{R}$ be a linear representation of a rational function $f$
  and let $d = \dim(\linSpan{\lReachSet{\mathcal{R}}})$
  (resp. $\dim(\linSpan{\rReachSet{\mathcal{R}}})$).

  We can construct a $d$-dimensional linear representation
  $\mathcal{R}_m$ of $f$ such that
  $\dim(\linHull{\mathcal{R}_m}) \leq \dim(\linHull{\mathcal{R}})$
  and $\linSpan{\lReachSet{\mathcal{R}}_m} = \mathbb{K}^d$
  (resp. $\linSpan{\rReachSet{\mathcal{R}_m}} = \mathbb{K}^d$).
\end{lemma}

\begin{proof}
  We will prove the lemma for the (left) reachability set.
  Let $\mathcal{R} = (u,\mu,v)$, let $n$ be the dimension of $\mathcal{R}$ and
  let $B$ be a basis of $\mathbb{K}^n$ obtained by completing a basis $\left\{ b_1, \dots, b_d \right\}$
  of $\linSpan{\lReachSet{\mathcal{R}}}$ with arbitrary vectors.

  We define $\mathcal{R}_m$ as $(u',\mu',v')$ where, for all $a \in \Sigma$,
  \begin{align*}
    u' = u \chgBaseMatr{\canonBasis{n}}{B} \resizIdMatr{n}{d} & &
    \mu'(a) = \resizIdMatr{d}{n} \chgBaseMatr{B}{\canonBasis{n}} \mu(a)
    \chgBaseMatr{\canonBasis{n}}{B} \resizIdMatr{n}{d} & &
    v' = \resizIdMatr{d}{n} \chgBaseMatr{B}{\canonBasis{n}} v
  \end{align*}

  We can show by induction, thanks to remark~\ref{rmk:chgBase}, that, for all $w \in \Sigma^*$,
  $u' \mu'(w) = u \mu(w) \chgBaseMatr{\canonBasis{n}}{B} \resizIdMatr{n}{d}$.
  So $\llbracket \mathcal{R}_m \rrbracket = \llbracket \mathcal{R} \rrbracket$
  and, since $\left\{ b_1, \dots, b_d \right\} \chgBaseMatr{\canonBasis{n}}{B} \resizIdMatr{n}{d}
  = \left\{ e_1, \dots, e_d \right\} \resizIdMatr{n}{d} = \canonBasis{d}$,
  then $\linSpan{\lReachSet{\mathcal{R}}_m} = \mathbb{K}^d$.

  Moreover, $\lReachSet{\mathcal{R}_m} = \lReachSet{\mathcal{R}} \chgBaseMatr{\canonBasis{n}}{B} \resizIdMatr{n}{d}$
  and, since linear maps are continuous and closed maps in the linear Zariski topology,
  $\linHull{\mathcal{R}_m} = \linHull{\mathcal{R}} \chgBaseMatr{\canonBasis{n}}{B} \resizIdMatr{n}{d}$.

  The irreducible components of $\linHull{\mathcal{R}}_m$ are then images of
  the irreducible components of $\linHull{\mathcal{R}}$ by a linear map.
  Thus $\dim(\linHull{\mathcal{R}_m}) \leq \dim(\linHull{\mathcal{R}})$.

  The case of the right reachability set is proven similarly
  (using a basis of $\linSpan{\rReachSet{\mathcal{R}}}$).
\end{proof}

\begin{proof}[Proof of Proposition~\ref{prop:dimLHMin}]
  Alternating the left and right constructions of lemma~\ref{lem:leftRightMin}
  on $\mathcal{R}$, we obtain a linear representation $\mathcal{R}_m$,
  that is minimal due to Proposition~\ref{prop:caracMinRep},
  and, since all minimal linear representations are similar, we conclude that
  $\dim(\linHull{\mathcal{R}_{\min}}) = \dim(\linHull{\mathcal{R}_m}) \leq \dim(\linHull{\mathcal{R}})$.
\end{proof}

Let's now show the link between $\CRA$ and the \LH{}s of $\WA$\@.

\begin{proposition}
  \label{prop:linRepToCRA}
  Let $\mathcal{R}$ be a linear representation
  and let $d$ be the dimension of $\linHull{\mathcal{R}}$
  and $k$ be the number of its irreducible components.

  There exists a $\CRA$ $\mathcal{A}$ with $k$ states and $d$ registers
  such that $\llbracket \mathcal{A} \rrbracket = \llbracket \mathcal{R} \rrbracket $
\end{proposition}
\begin{proof}
  Let $\mathcal{R} = (u,\mu,v)$, let $n$ be the dimension of $\mathcal{R}$
  and let $W_1, \dots, W_k$ be the irreducible components of $\linHull{\mathcal{R}}$.
  We assume, without loss of generality, that $u \in W_1$.
  For all $i \in \intInterv{1}{k}$, let $B_i$ be a basis of $\mathbb{K}^n$
  obtained by completing a basis of $W_i$ with arbitrary vectors.

  We define $\mathcal{A}$ as $(Q, q_0, \varSet, v_0, \outFctCRA, \delta)$ where:
  \begin{itemize}
    \item $Q = \intInterv{1}{k}$ and $q_0 = 1$.
    \item $\varSet = \left\{ X_1, \dots, X_d \right\}$,
    $\expToMap{v_0} = u \chgBaseMatr{\canonBasis{n}}{B_1} \resizIdMatr{n}{d}$
    and, for all $q \in Q$, $\expToMap{\outFctCRA(q)} = \resizIdMatr{d}{n} \chgBaseMatr{B_q}{E_n}v$.
    \item for all $q \in Q$ and $a \in \Sigma$, let $p$ be an element of
    $\left\{ p \in \llbracket 1,k \rrbracket \,\middle|\, W_q \mu(a) \subseteq W_p \right\}$
    (chosen arbitrarily).
    $\delta(q,a)$ will be defined by $\delta_Q(q,a) = p$ and
    $\expToMap{\delta_{\mathcal{X}}(q,a)} = \resizIdMatr{d}{n} \chgBaseMatr{B_q}{E_n}
    \mu(a) \chgBaseMatr{E_n}{B_p} \resizIdMatr{n}{d}$.
  \end{itemize}

  We can show by induction, using remark~\ref{rmk:chgBase}, that, for all $w \in \Sigma^*$,
  $\expToMap{v_0}\expToMap{\delta_{\mathcal{X}}(q_0,w)} = u \mu(w)
  \chgBaseMatr{E_n}{B_{\delta_Q(q_0,w)}} \resizIdMatr{n}{d}$.
  Thus $ \llbracket \mathcal{A} \rrbracket = \expToMap{v_0}\ \expToMap{\delta_{\varSet}(q_0,w)}\
  \expToMap{\outFctCRA(\delta_Q(q_0,w))} = \llbracket \mathcal{R} \rrbracket $.
\end{proof}

\begin{proposition}
  \label{prop:CRAToLinRep}
  Let $\mathcal{A}$ be a $\CRA$ with $k$ states and $d$ registers.

  There exists a $kd$-dimensional linear representation $\mathcal{R}$ of $\llbracket \mathcal{A} \rrbracket$
  such that $\dim(\linHull{\mathcal{R}}) \leq d$.
\end{proposition}

\begin{proof}
  Let's assume, without loss of generality, that $\mathcal{A} = (Q, q_0, \varSet, v_0, \outFctCRA, \delta)$
  where $Q = \intInterv{1}{k}$, $q_0 = 1$ and $\mathcal{X} = \left\{ X_1, \dots, X_d \right\}$.

  We define $\mathcal{R}$ as $(u,\mu,v)$, where
  $u = (\expToMap{v_0}\ 0 \dots 0) \in \vectSet{\mathbb{K}}{kd}$,
  $v = \left(\begin{array}{c}
               \expToMap{\outFctCRA(1)} \\
               \vdots                   \\
               \expToMap{\outFctCRA(k)}
  \end{array}\right) \in \matrSet{\mathbb{K}}{kd}{1}$
  and, for all $a \in \Sigma$, $\mu (a) =
  \left( \begin{array}{c|c|c}
           \delta_{1,1}(a) & \dots  & \delta_{1,k}(a) \\
           \hline
           \vdots          & \ddots & \vdots          \\
           \hline
           \delta_{k,1}(a) & \dots  & \delta_{k,k}(a)
  \end{array} \right) \in \sqmatrSet{\mathbb{K}}{kd}$
  where, for all $i,j \in \intInterv{1}{k}$,
  $\delta_{i,j}(a) \in \sqmatrSet{\mathbb{K}}{d}$
  is defined by $\delta_{i,j}(a) =
  \begin{cases}
    \expToMap{\delta_{\mathcal{X}}(i,a)} & \text{if } \delta_{Q}(i,a) = j \\
    0 & \text{otherwise}
  \end{cases}$.


  We can show by induction that, for all $w \in \Sigma^*$,
  $\mu (w) = \left( \begin{array}{c|c|c}
                      \delta_{1,1}(w) & \dots  & \delta_{1,k}(w) \\
                      \hline
                      \vdots          & \ddots & \vdots          \\
                      \hline
                      \delta_{k,1}(w) & \dots  & \delta_{k,k}(w)
  \end{array} \right)$
  where, for all $i,j \in \intInterv{1}{k}$, $\delta_{i,j}(w) =
  \begin{cases}
    \expToMap{\delta_{\mathcal{X}}(i,w)} & \text{if } \delta_{Q}(i,w) = j \\
    0 & \text{otherwise}
  \end{cases}$.

  We then have
  \[
    \llbracket \mathcal{R} \rrbracket = u \mu(w) v
    = \sum_{i=1}^{n} \expToMap{v_0}\ \delta_{1,i}(w)\ \expToMap{\outFctCRA(i)}
    = \expToMap{v_0}\ \delta_{1,\delta_Q(1,w)}(w) \ \expToMap{\outFctCRA(\delta_Q(1,w))}
    = \llbracket \mathcal{A} \rrbracket
  \]

  Moreover, since for all $w \in \Sigma^*$, $u \mu(w)
  = (\expToMap{v_0} \delta_{1,1}(w) | \dots | \expToMap{v_0} \delta_{1,k}(w))$
  and only $\delta_{1, \delta_Q (1,w)}(w)$ is potentially nonzero,
  then $\lReachSet{\mathcal{R}} \subseteq \bigcup_{i=1}^{k} \varphi_i(\mathbb{K}^d)$
  where, for all $i \in \intInterv{1}{k}$, $\varphi_i : \mathbb{K}^d \to \mathbb{K}^{kd}$
  maps every vector $v \in \mathbb{K}^d$ to the vector of $\mathbb{K}^{kd}$
  that has $v$ as its $i$-th ``block'' of size $d$ and zeros everywhere else.
  Thus $\dim(\linHull{\mathcal{R}}) \leq d$.
\end{proof}

We can now show the main result:
\begin{proof}[Proof of theorem~\ref{thm:mainThm}]
  Let $f$ be a rational function, let $d_{CRA}$ be
  the minimal number of registers needed by a linear $\CRA$ to realize $f$
  and let $d_{rep}$ be the dimension of the \LH of a minimal linear representation of $f$
  and $k_{rep}$ the number of its irreducible components.

  We will show that $d_{CRA} = d_{rep}$ and construct a $\CRA$ with $d_{rep}$ registers
  and $k_{rep}$ states.

  If $d_{CRA} > d_{rep}$ then Proposition~\ref{prop:linRepToCRA} shows
  that there exists a $\CRA$ with $d_{rep}$ registers realizing $f$,
  contradicting the minimality of $d_{CRA}$.
  Thus $d_{CRA} \leq d_{rep}$.

  Reciprocally, if $d_{CRA} < d_{rep}$ then Proposition~\ref{prop:CRAToLinRep}
  gives a linear representation of $f$ with a $d_{CRA}$-dimensional \LH,
  contradicting the minimality of $d_{rep}$ given by Proposition~\ref{prop:dimLHMin}.
  Thus $d_{rep} \leq d_{CRA}$.

  We can obtain the desired $\CRA$ by applying the construction of Proposition~\ref{prop:linRepToCRA}
  to a minimal linear representation of $f$.
\end{proof}

Using the minimal number of registers can, however,
have a big impact on the number of states of the underlying automaton
of the $\CRA$, as shown in the example below:

\begin{example}
  \label{ex:permut}
  Let $n \in \mathbb{N}$.
  An $n$-dimensional permutation matrix is an $n$ by $n$ matrix that has exactly one 1
  in each row and each column and zeros everywhere else.
  The set $\permutMatrSet{n}$ of permutation matrices together with matrix multiplication
  form a group of order $n!$ and can be generated using two elements.
  $\linClosure{\permutMatrSet{n}}$ is one dimensional and has $n!$ irreducible components,
  as it is a union of $n!$ lines.

  Using the previous result, we can then show that,
  a rational function, on a two-letter alphabet, with an $n$-dimensional minimal linear representation
  that has as transition matrices two generators of $\permutMatrSet{n}$,
  can be realized by a $\CRA$ with only one register but $n!$ states.
\end{example}


\section{Tradeoff states/registers}

In this section, we consider the more general minimization problem
for $\CRA$ defined as:
\begin{definition}[$\CRA$ minimization problem]
  Given a class $\cal C$ of \CRA, we consider the following decision problem:
  \begin{itemize}
    \item \textbf{Input:} a \CRA  in the class $\cal C$, and two integers $k,d\in \mathbb{N}$
    \item \textbf{Question:} Does there exist an equivalent \CRA  in the class $\cal C$
    with at most $k$ states and at most $d$ registers?
  \end{itemize}
\end{definition}

For a linear $\CRA$ realizing a rational function with a minimal linear representation $\mathcal{R}$,
the results of the previous section and the correspondence between linear representations
and $\CRA$ gives us two possible extreme cases :
first, the $\CRA$ that has the minimal number of registers (the dimension of $\linHull{\mathcal{R}}$)
and the maximal number of ``useful'' states (the number of irreducible components of $\linHull{\mathcal{R}}$)
and second, the $\CRA$ that has the minimal number of states (one)
and the maximal number of ``useful'' registers (the dimension of $\mathcal{R}$).
We show, in this section, the decidability of the minimization problem for linear $\CRA$
by giving a procedure to enumerate all the $\CRA$ with numbers of states and registers
in between these bounds, balancing out the two resources of the machine.

\begin{definition}[\nkCongr{k}{d}{}s]
  Let $\mathcal{R} = (u,\mu,v)$ be a linear representation and let
  $\linHull{\mathcal{R}} = W_1 \cup \dots \cup W_r$ be its \LH,
  where the $W_i$, for $i \in \intInterv{1}{r}$, are its irreducible components.

  A \emph{\nkCongr{k}{d}} on $\linHull{\mathcal{R}}$ is a partition $\mathcal{P}$
  of $\intInterv{1}{r}$ into $k$ parts such that

  \begin{enumerate}[(1)]
    \item for all $C \in \mathcal{P}$ and $a \in \Sigma$, there exists $C' \in \mathcal{P}$
    verifying that for all $i \in C$ there exists $i' \in C'$ such that $W_i \mu(a) \subseteq W_{i'}$.
    (the set of $C' \in \mathcal{P}$ verifying this property will be denoted by $C\mu(a)$)
    \item for all $C \in \mathcal{P}$, $\dim \left(\linSpan{\bigcup_{i \in C} W_i}\right) \leq d$.
  \end{enumerate}
\end{definition}

\nkCongr{k}{d}{}s allow to group together components of a \LH without making the dimension
increase beyond $d$.

\begin{theorem}
  \label{thm:mainNkCongrThm}
  Let $f$ be a rational function.

  $f$ is realizable by a $\CRA$ with $k$ states and $d$ registers if and only if
  $f$ has a linear representation $\mathcal{R}$ with a \LH that has a \nkCongr{k}{d}.
\end{theorem}

The proof of this theorem generalizes the proofs of Propositions~\ref{prop:linRepToCRA}
and~\ref{prop:CRAToLinRep}.

\begin{proof}
  If $\mathcal{A}$ is a $\CRA$ with $k$ states and $d$ registers realizing $f$,
  let's consider the same construction and notations of the proof of Proposition~\ref{prop:CRAToLinRep}
  and let $\linHull{\mathcal{R}} = W_1 \cup \dots \cup W_r$, where the $W_i$
  for $i \in \intInterv{1}{r}$ are the irreducible components.

  We will show that $\mathcal{P} = \left\{ C_1, \dots, C_k \right\}$
  with, for all $j \in \intInterv{1}{k}$,
  $C_j = \left\{ i \in \intInterv{1}{r} \,\middle|\, W_i \subseteq \varphi_j(\mathbb{K}^d) \right\} $,
  is a \nkCongr{k}{d} on $\linHull{\mathcal{R}}$.

  First, since for all $i \in \intInterv{1}{r}$, $W_i \subseteq \bigcup_{i=j}^{k} \varphi_j(\mathbb{K}^d)$
  and $W_i$ is irreducible, then there exists $j \in \intInterv{1}{k}$ such that
  $W_i \subseteq \varphi_j(\mathbb{K}^d)$.
  So the $C_j$ are well-defined.
  Then, since for all $j \in \intInterv{1}{k}$, $\linSpan{\bigcup_{i \in C_j} W_i}$
  is a subspace of $\varphi_j(\mathbb{K}^d)$ by definition, we have
  $\dim \left(\linSpan{\bigcup_{i \in C_j} W_i}\right) \leq d$.
  Finally, for all $j \in \intInterv{1}{k}$ and $a \in \Sigma$,
  by definition of $\mu(a)$, there exists $j' \in \intInterv{1}{k}$
  such that $\varphi_j(\mathbb{K}^d) \mu(a) \subseteq \varphi_{j'}(\mathbb{K}^d)$.
  This implies that, for all $C_j \in \mathcal{P}$ and $a \in \Sigma$,
  there exists $C_{j'} \in \mathcal{P}$ verifying that for all $i \in C_j$
  there exists $i' \in C_{j'}$ such that $W_i \mu(a) \subseteq W_{i'}$.

  Thus $\mathcal{P}$ is an \nkCongr{k}{d} on $\linHull{\mathcal{R}}$.

  Reciprocally, if $\mathcal{R} = (u,\mu,v)$ is an $n$-dimensional linear representation
  of $f$ with $\mathcal{P}$ a \nkCongr{k}{d} on $\linHull{\mathcal{R}} = W_1 \cup \dots \cup W_r$,
  let's assume, without loss of generality, that $u \in W_1$.

  Let, for all $C \in \mathcal{P}$, $B_C$ be a basis of $\mathbb{K}^n$ obtained by
  completing a basis of $\linSpan{\bigcup_{i \in C} W_i}$ with arbitrary vectors.

  We define a $\CRA$ $\mathcal{A} = (Q, q_0, \varSet, v_0, \outFctCRA, \delta)$
  with $k$ states and $d$ registers realizing $f$ with:
  \begin{itemize}
    \item $Q = \mathcal{P}$ and $q_0 = C_1 \in \mathcal{P}$ where $C_1$ is the class containing 1.
    \item $\varSet = \left\{ X_1, \dots, X_d \right\}$,
    $\expToMap{v_0} = u \chgBaseMatr{\canonBasis{n}}{B_{q_0}} \resizIdMatr{n}{d}$
    and, for all $q \in Q$, $\expToMap{\outFctCRA(q)} = \resizIdMatr{d}{n} \chgBaseMatr{B_q}{E_n}v$.
    \item for all $q \in Q$ and $a \in \Sigma$, let $p$ be an element of
    $q \mu(a)$ (chosen arbitrarily).
    $\delta(q,a)$ will be defined by $\delta_Q(q,a) = p$ and
    $\expToMap{\delta_{\mathcal{X}}(q,a)} = \resizIdMatr{d}{n} \chgBaseMatr{B_q}{E_n}
    \mu(a) \chgBaseMatr{E_n}{B_p} \resizIdMatr{n}{d}$.
  \end{itemize}

  We prove that $\mathcal{A}$ is equivalent to $\mathcal{R}$ the same way as in
  the proof of Proposition~\ref{prop:linRepToCRA}.
\end{proof}

For a $\CRA$ with a given number of registers, this result can lead to a big reduction
in the number of states, as shown in the example below:

\begin{example}
  \label{ex:permutMerge}
  Let $n \in \mathbb{N}$.
  Using an alphabet of size $n+1$ and the matrices of Example~\ref{ex:permut}
  generating $\permutMatrSet{n}$,
  we can define a $2n$-dimensional linear representation with a \LH
  that can be wrriten as the union of $n!$ one-dimensional irreducible component
  and an $(n-1)$-dimensional one.

  Since $\dim \left( \linSpan{\permutMatrSet{n}} \right) = n-1$,
  we can define on this \LH a \nkCongr{2}{(n-1)}, merging together
  the one-dimensional irreducible components without raising the dimension of the \LH,
  thus reducing the number of states of the corresponding $\CRA$ to 2 while
  keeping the same number of registers.


  See Appendix~\ref{apx:permutMerge} for the details of the construction.
\end{example}


We can show that we only need to consider minimal linear representations:
\begin{proposition}
  \label{prop:nkCongrDimLHMin}
  If $\mathcal{R}$ is a linear representation such that $\linHull{\mathcal{R}}$
  has a \nkCongr{k}{d} then any minimal representation of $\llbracket \mathcal{R} \rrbracket$ has
  a \nkCongr{k}{d}.
\end{proposition}

The proof of this proposition generalizes the proof of Proposition~\ref{prop:dimLHMin}.
The following lemma gives the left and right constructions needed to obtain the desired
minimal representation.

\begin{lemma}
  \label{lem:nkCongrleftRightMin}
  Let $\mathcal{R}$ be a linear representation of a rational function $f$
  and let $d = \dim(\linSpan{\lReachSet{\mathcal{R}}})$
  (resp. $\dim(\linSpan{\rReachSet{\mathcal{R}}})$).

  If $\linHull{\mathcal{R}}$ has a \nkCongr{k}{d},
  we can construct a $d$-dimensional linear representation
  $\mathcal{R}_m$ of $f$ such that $\linHull{\mathcal{R}_m}$ has a \nkCongr{k}{d}
  and $\linSpan{\lReachSet{\mathcal{R}}_m} = \mathbb{K}^d$
  (resp. $\linSpan{\rReachSet{\mathcal{R}_m}} = \mathbb{K}^d$).
\end{lemma}

\begin{proof}
  Let's consider the same construction and notations of the proof of lemma~\ref{lem:leftRightMin}
  and let $\linHull{\mathcal{R}} = W_1 \cup \dots \cup W_r$ and
  $\linHull{\mathcal{R}_m} = W_1' \cup \dots \cup W_r'$ where,
  for all $i \in \intInterv{1}{r}$, $W_i' = W_i \chgBaseMatr{\canonBasis{n}}{B} \resizIdMatr{n}{d}$.

  If $\mathcal{P}$ is a \nkCongr{k}{d} on $\linHull{\mathcal{R}}$,
  we will show that it is also a \nkCongr{k}{d} on $\linHull{\mathcal{R}_m}$.

  Let $C \in \mathcal{P}$, $a \in \Sigma$ and $C' \in C \mu(a)$.
  Since, for all $i \in C$ there exists $i' \in C'$ such that $W_i \mu(a) \subseteq W_{i'}$,
  we then have $W'_i \mu'(a) = W_i \chgBaseMatr{\canonBasis{n}}{B} \resizIdMatr{n}{d}
  \resizIdMatr{d}{n} \chgBaseMatr{B}{\canonBasis{n}} \mu(a) \chgBaseMatr{\canonBasis{n}}{B} \resizIdMatr{n}{d}
  = W_i \mu(a) \chgBaseMatr{\canonBasis{n}}{B} \resizIdMatr{n}{d}
  \subseteq W_{i'} \chgBaseMatr{\canonBasis{n}}{B} \resizIdMatr{n}{d} = W'_{i'}$

  Moreover, for all $C \in \mathcal{P}$, $\linSpan{\bigcup_{i \in C} W_i'}
  = \linSpan{\bigcup_{i \in C} W_i \chgBaseMatr{\canonBasis{n}}{B} \resizIdMatr{n}{d}}
  = \linSpan{\bigcup_{i \in C} W_i} \chgBaseMatr{\canonBasis{n}}{B} \resizIdMatr{n}{d}$.
  Thus, $\dim \left(\linSpan{\bigcup_{i \in C} W_i'}\right)
  \leq \dim \left(\linSpan{\bigcup_{i \in C} W_i}\right) \leq d$
\end{proof}

Given a rational function $f$, we can then find ``every'' $\CRA$ realizing $f$
by constructing a minimal linear representation of $f$ and enumerating
all the possible \nkCongr{k}{d} on its \LH and we get the following decidability result:
\begin{corollary}
  The minimization problem for linear $\CRA$ is decidable.
\end{corollary}


\section{Affine CRA}

We can naturally extend the results shown in the previous sections on linear $\CRA$
to $\CRA$ with affine register updates by considering the affine Zariski topology
instead of the linear one.
This allows to use up to one less register than the minimal number needed in the linear case.

Let $\mathbb{K}$ be a field and $n\in \mathbb{N}$.
The \emph{affine Zariski topology} is the topology on $\mathbb{K}^n$ whose closed sets
are finite unions of affine subspaces of $\mathbb{K}^n$.
This topology has the same properties as the linear Zariski topology.
For a set $S \subseteq \mathbb{K}^n$, $\affClosure{S}$ will denote its closure
in the affine Zariski topology.


Similarly to the linear case, we define \AH{}s of $\WA$ in the natural way,
using the affine Zariski topology.

\begin{definition}
  Let $\Sigma$ be a finite alphabet and let $\mathcal{R} = (u,\mu,v)$ be a linear representation on $\Sigma$
  over $\mathbb{K}$.

  The (left) \emph{\AH} of $\mathcal{R}$ is the closure of $\lReachSet{\mathcal{R}}$
  in the affine Zariski topology.
  It will be denoted by $\affHull{\mathcal{R}}$.
  Its \emph{dimension} $\dim(\affHull{\mathcal{R}})$ is defined as the maximal dimension
  of its irreducible components.

  (The, dually defined, right \AH will be denoted by $\raffHull{\mathcal{R}}$)
\end{definition}

\begin{example}
  \label{ex:sumPow2}
  On the alphabet $\Sigma = \left\{ a \right\}$,
  let $\mathcal{R} = (u, \mu, v)$,
  where $u = (1\ 2)$, $\mu(a) = \begin{pmatrix*}
                                  1 & 0 \\
                                  1 & 2
  \end{pmatrix*}$ and $v = (1\ 0)^t$,
  be a linear representation (over $\mathbb{R}$) of the rational function $f$ defined by
  $f(a^n) = \sum_{i=0}^{n} 2^i$.

  The reachability set of $\mathcal{R}$ is $\lReachSet{\mathcal{R}}
  = \left\{ \left(\sum_{i=0}^{n} 2^i ,\ 2^{n+1}\right) \,\middle|\, n \in \mathbb{N} \right\}$.

  For the linear Zariski topology, $\lReachSet{\mathcal{R}}$ is dense in $\mathbb{R}^2$.
  So the \LH $\linHull{\mathcal{R}} = \mathbb{R}^2$ is two dimensional.
  However, note that, for all $(x,y) \in \lReachSet{\mathcal{R}}$, $y = x+1$.
  So, by an argument of density in the affine Zariski topology,
  the \AH $\affHull{\mathcal{R}}$ is the affine line $y=x+1$, which is one dimensional.
\end{example}

\input{fig-reachSet}

The computability of the \AH follows from the same arguments as in the linear case.
\begin{lemma}
  The \AH of a linear representation is computable.
\end{lemma}

We can also define \nkCongr{k}{d}{}s on the \AH.

\begin{definition}
  Let $\mathcal{R} = (u,\mu,v)$ be a linear representation and let
  $\affHull{\mathcal{R}} = W_1 \cup \dots \cup W_r$ be its \AH,
  where the $W_i$, for $i \in \intInterv{1}{r}$, are its irreducible components.

  A \emph{\nkCongr{k}{d}} on $\affHull{\mathcal{R}}$ is a partition $\mathcal{P}$
  of $\intInterv{1}{r}$ into $k$ parts such that

  \begin{enumerate}[(1)]
    \item for all $C \in \mathcal{P}$ and $a \in \Sigma$, there exists $C' \in \mathcal{P}$
    verifying that for all $i \in C$ there exists $i' \in C'$ such that $W_i \mu(a) \subseteq W_{i'}$.
    (the set of $C' \in \mathcal{P}$ verifying this property will be denoted by $C\mu(a)$)
    \item for all $C \in \mathcal{P}$, $\dim \left(\affSpan{\bigcup_{i \in C} W_i}\right) \leq d$.
  \end{enumerate}
\end{definition}

All the previous results obtained in the linear case still hold for the affine case.
\begin{theorem}
  \label{thm:mainAffCRAThm}
  Let $f$ be a rational function.

  The minimal number of registers needed by an affine $\CRA$ to realize $f$
  is the dimension of the \AH of a minimal linear representation of $f$.

  Moreover, $f$ is realizable by an affine $\CRA$ with $k$ states and $d$ registers
  if and only if $f$ has a linear representation with an \AH
  that has a \nkCongr{k}{d} and every possible \nkCongr{k}{d} can be found on the
  \AH of a minimal representation of $f$.
\end{theorem}

\begin{corollary}
  The minimization and register minimization problems for affine $\CRA$ are decidable.
\end{corollary}

The proof is the same as in the linear case, replacing vector spaces with affine
ones and readjusting the constructions accordingly.
For the sake of completeness, it can be found in the appendix.

\input{fig-affCRA}


\begin{example}[Example~\ref{ex:sumPow2} continued]
  \label{ex:sumPow2CRA}
  The two $\CRA$ depicted on Figure \ref{fig:sumPow2CRA} realizes
  the function of the previous example.

  On the left we have a linear $\CRA$ with two registers and, on the right,
  an affine $\CRA$ with only one register.
  The previous results show that both have the minimal number of register
  for their respective classes of $\CRA$.
\end{example}


%\subsection{Left reach set and (linear) Zariski closure}
%{\color{MidnightBlue}
%Present the approach of Bell and Smertnig based on the left
%reachability set, plus computation of linear Zariski closure,
%  to decide sequentiality, which inspired our work.
%}
%\subsection{linear $\CRA$}
%{\color{MidnightBlue}
%our approach + results
%}
%
%\subsection{affine $\CRA$}
%{\color{MidnightBlue}
%Motivate affine $\CRA$s. Natural extension, allows to reduce the number of registers.
%
%Example
%
%Our approach: modify the topology to deal with constants, yields affine closure.
%
%Results
%}
%
%\iffalse
%\section{Dynamic register complexity}
%{\color{MidnightBlue}
%Undec result
%}
%\fi


\section{Conclusion}

We have shown how to decide the \CRA minimisation problem, and are thus able to minimise simultaneously the
number of states and registers needed to realise a rational function.

An important question which remains is the one of complexity of this procedure: can the linear
(resp.~affine) hull of a \WA be computed in \elem complexity. In their article \cite{BellS21} the authors
do not give complexity upper bounds for the computation of the linear hull. Similarly, in \cite{
  HruOuaPouWor2018}
where the authors show how to compute the best polynomial invariant for an affine program, no complexity is
given for their algorithm. In fact one can observe that computing the best algebraic invariant for a
polynomial automaton cannot be done in \elem complexity, since the zeroness problem for polynomial automata
is \acker-hard \cite{BenediktDSW17}.
Our problem is however simpler in two crucial ways:
\begin{enumerate}
  \item the automata we consider are linear and not polynomial, which makes things probably much easier.
  For instance, if all the register updates are invertible, then computing the best algebraic invariant can
  be done in \elem complexity (see \cite{NosanPSS022}),
  \item we do not need to compute the best algebraic invariant, only the best linear one, which may be much
  coarser and is a fundamentally much simpler object.
\end{enumerate}

Questions which remain open are the ones given in Fig~\ref{fig:landscape} of register minimisation for
subclasses of \CRA. Given a copyless \CRA (which correspond to mutli-sequential \WA) can one find an
equivalent copyless \CRA with fewer registers? Similarly, a register minimization procedure for \emph{
  transition-monomial} \CRA (corresponding to finitely ambiguous \WA) is not known. While the techniques
used for solving the corresponding unambiguous cases are very different, it is possible that this linear
hull approach could be a useful tool to tackle these questions.

A much more ambitious goal would be to consider register minimisation in the context of different semirings
, but there, all the linear algebra tools which are crucial to solve these problems completely vanish.
Similarly, it seems that register minimisation for polynomial automata would be very difficult. Indeed in
both cases no minimal/canonical machine is known to exist, which is a central tool to solving the linear
case over fields.


%\section{Bibliography}~\nocite{*}

\bibliographystyle{eptcs}
\bibliography{biblio}


\clearpage
\appendix
\appendixpage


\section{Proof of theorem~\ref{thm:mainAffCRAThm}}

Similarly to the linear case, we identify any affine expression
$e =  \sum_{i=1}^{n} \alpha_i X_i + \beta$
with the affine form $\expToMap{e} : \mathbb{K}^n \to \mathbb{K}$
defined by $\expToMap{e}(u) = u \linPart{\expToMap{e}} + \affPart{\expToMap{e}}$
with $\linPart{\expToMap{e}} = (\alpha_1 \dots \alpha_n)^t$ and $\affPart{\expToMap{e}} = \beta$.
We can then identify any affine substitution $s : \varSet \to \affExpr{\varSet}$
with the affine map $\expToMap{s} : \mathbb{K}^n \to \mathbb{K}^n$
defined by $\expToMap{s}(u) = u \linPart{\expToMap{s}} + \affPart{\expToMap{s}}$
with $\linPart{\expToMap{s}} = \linPart{(\expToMap{s(X_1)}} | \cdots| \linPart{\expToMap{s(X_n)}})$
and $\affPart{\expToMap{s}} = (\affPart{(\expToMap{s(X_1)}} \cdots\ \affPart{\expToMap{s(X_n)}})$,
and we can identify any valuation $v : \varSet \to \mathbb{K}$ with the point
$\expToMap{v}=(v(X_1) \cdots v(X_n))$ of the affine space $\mathbb{K}^n$.

And, like in the linear case, the registers of an affine $\CRA$
$\mathcal{A} = (Q, q_0, \varSet, v_0, \outFctCRA, \delta)$ and their updates
can be characterized by the values of $\expToMap{v_0}$, $\expToMap{\delta_{\mathcal{X}}(q,a)}$
and $\expToMap{\outFctCRA(q)}$, for $q \in Q$ and $a \in \Sigma$, and we can check that
\[\llbracket \mathcal{A} \rrbracket (w) = \expToMap{\outFctCRA(\delta_Q(q_0,w))}
\left(\expToMap{\delta_{\varSet}(q_0,w)} \left(\expToMap{v_0}\,\right)\right)\]

\subsection{From linear representations to affine $\CRA$}
We tweak the construction of~\ref{prop:linRepToCRA} to get an affine $\CRA$
with $k$ states and $d$ registers from a \nkCongr{k}{d} on the \AH of a linear representation:

Let $\mathcal{R} = (u,\mu,v)$ be a linear representation, let $n$ be the dimension of $\mathcal{R}$
and let $W_1, \dots, W_k$ be the irreducible components of $\affHull{\mathcal{R}}$.
We assume, without loss of generality, that $u \in W_1$.

Let $\mathcal{P}$ be a \nkCongr{k}{d} on $\affHull{\mathcal{R}}$ and
for all $C \in \mathcal{P}$, let $\affSpan{\bigcup_{i \in C} W_i}= p_C + V_C$
with $p_C \in \mathbb{K}^n$ and $V_C$ a vector subspace of $\mathbb{K}^n$
and let $B_C$ be a basis of $\mathbb{K}^n$ obtained by completing a basis of $V_C$
with arbitrary vectors.

We define $\mathcal{A}$ as $(Q, q_0, \varSet, v_0, \outFctCRA, \delta)$ where:
\begin{itemize}
  \item $Q = \mathcal{P}$ and $q_0 = C_1 \in \mathcal{P}$ where $C_1$ is the class
  containing 1.
  \item $\varSet = \left\{ X_1, \dots, X_d \right\}$ and
  $\expToMap{v_0} = (u-p_{q_0}) \chgBaseMatr{\canonBasis{n}}{B_{q_0}} \resizIdMatr{n}{d}$
  \item for all $q \in Q$ and $x \in \mathbb{K}^d$,
  $\expToMap{\outFctCRA(q)}(x) = \left( p_q + x \resizIdMatr{d}{n} \chgBaseMatr{B_q}{E_n} \right)v$.
  \item for all $q \in Q$ and $a \in \Sigma$, let $q'$ be an element of
  $\left\{ p \in \llbracket 1,k \rrbracket \,\middle|\, W_q \mu(a) \subseteq W_p \right\}$
  (chosen arbitrarily).
  $\delta(q,a)$ will be defined by $\delta_Q(q,a) = q'$ and, for all $x \in \mathbb{K}^d$,
  \[\expToMap{\delta_{\mathcal{X}}(q,a)}(x) = \left( \left( p_q + x \resizIdMatr{d}{n}\chgBaseMatr{B_q}{E_n}
  \right) \mu(a) - p_{q'}\right) \chgBaseMatr{E_n}{B_{q'}} \resizIdMatr{n}{d}\]
\end{itemize}

We can show by induction that, for all $w \in \Sigma^*$,
\[\expToMap{\delta_{\mathcal{X}}(q_0,w)} \left( \expToMap{v_0} \right) =
\left( u \mu(w) - p_{\delta_Q(q_0,w)} \right)
\chgBaseMatr{E_n}{B_{\delta_Q(q_0,w)}} \resizIdMatr{n}{d}\]

Thus $ \llbracket \mathcal{A} \rrbracket = \llbracket \mathcal{R} \rrbracket$.

Taking a trivial partition, we also obtain an affine version of Proposition~\ref{prop:linRepToCRA}.

\subsection{From affine $\CRA$ to linear representations}
We tweak the construction of~\ref{prop:CRAToLinRep} to get a linear representation
with an \AH that has an \nkCongr{k}{d} from a $\CRA$ with $d$ registers and $k$ states:

Let $\mathcal{A} = (Q, q_0, \varSet, v_0, \outFctCRA, \delta)$ be an affine $\CRA$
where, we assume without loss of generality that,
$Q = \intInterv{1}{k}$, $q_0 = 1$ and $\mathcal{X} = \left\{ X_1, \dots, X_d \right\}$.

We define $\mathcal{R}$ as $(u,\mu,v)$, where:
\begin{itemize}
  \item $u = (\expToMap{v_0} \ 1 \ 0 \dots 0) \in \vectSet{\mathbb{K}}{k(d+1)}$
  \item $v = \left(\begin{array}{c}
                     \outFctCRA_1 \\
                     \vdots       \\
                     \outFctCRA_n
  \end{array}\right) \in \matrSet{\mathbb{K}}{k(d+1)}{1}$.
  where, for all $i \in \intInterv{1}{k}$,
  $\outFctCRA_i = \left(\begin{array}{c}
                          \linPart{\expToMap{\outFctCRA(i)}} \\
                          \affPart{\expToMap{\outFctCRA(i)}}
  \end{array}\right)$.
  \item for all $a \in \Sigma$, $\mu (a) =
  \left( \begin{array}{c|c|c}
           \delta_{1,1}(a) & \dots  & \delta_{1,k}(a) \\
           \hline
           \vdots          & \ddots & \vdots          \\
           \hline
           \delta_{k,1}(a) & \dots  & \delta_{k,k}(a)
  \end{array} \right) \in \sqmatrSet{\mathbb{K}}{k(d+1)}$
  where, for all $i,j \in \intInterv{1}{k}$, $\delta_{i,j}(a) = \left(
  \begin{array}{c|c}
    \linPart{\expToMap{\delta_{\mathcal{X}}(i,a)}} & 0 \\[5pt]
    \hline
    \affPart{\expToMap{\delta_{\mathcal{X}}(i,a)}} & 1
  \end{array} \right)$ if $\delta_{Q}(i,w) = j$ and 0 otherwise.
\end{itemize}

Like in the linear case, we show by induction that the definition of the $\delta_{i,j}$
extends to words and proves that $\llbracket \mathcal{R} \rrbracket = \llbracket \mathcal{A} \rrbracket $.

We observe that, for all $w \in \Sigma^*$, $u \mu(w)
= ((\expToMap{v_0}\, 1) \delta_{1,1}(w) | \dots | (\expToMap{v_0}\, 1) \delta_{1,k}(w))$
and only $\delta_{1, \delta_Q (1,w)}(w)$ is potentially nonzero,
then $\lReachSet{\mathcal{R}} \subseteq \bigcup_{i=1}^{k} \psi_i(\mathbb{K}^d)$
where, for all $i \in \intInterv{1}{k}$, $\psi_i : \mathbb{K}^d \to \mathbb{K}^{k(d+1)}$
maps every vector $v \in \mathbb{K}^d$ to the vector of $\mathbb{K}^{k(d+1)}$
that has $(v\ 1)$ as its $i$-th ``block'' of size $d+1$ and zeros everywhere else.

Note that the $\psi_i$ are affine maps.
So, $\dim(\affHull{\mathcal{R}}) \leq d$ and we can show, like in the linear case,
that $\mathcal{P} = \left\{ C_1, \dots, C_k \right\}$
with, for all $j \in \intInterv{1}{k}$,
$C_j = \left\{ i \in \intInterv{1}{r} \,\middle|\, W_i \subseteq \psi_j(\mathbb{K}^d) \right\} $,
is a \nkCongr{k}{d} on $\affHull{\mathcal{R}}$.

\subsection{Left and right minimization}
The proof of lemma~\ref{lem:leftRightMin} and~\ref{lem:nkCongrleftRightMin}
remains the same for their affine versions.
The key point is that linear maps are a particular case of affine maps
and the properties used in these two proof remain true.
Thus, Proposition~\ref{prop:dimLHMin} and~\ref{prop:nkCongrDimLHMin}
still hold for the \AH.


\section{Details of Example \ref{ex:permutMerge}} \label{apx:permutMerge}

The symetric group can be generated using the cycle $(1\, 2\, \dots\, n)$
and the transposition $(1\, 2)$.
Let $C$ and $T$ be their respective corresponding matrices in $\permutMatrSet{n}$.

For all $i \in \intInterv{1}{n-1}$, let $M_i = \left(
\begin{array}{c|c}
  I_{n-1} & 0 \\
  \hline
  e_i     & 1
\end{array} \right)$,
where $I_{n-1}$ is the identity matrix of size $n-1$ and $e_i$ is the $i$-th
vector of the canonical basis of $\mathbb{K}^{n-1}$.

Let $\Sigma = \left\{ a, b , c_1, c_2, \dots, c_{n-1} \right\}$ be an alphabet of size $n+1$.

Let $\mathcal{R} = (u,\mu,v)$ be the $2n$-dimensional linear representation,
on $\Sigma$, defined by:
\begin{itemize}
  \item $u = (1\, 2\, \dots\, n\,|\, 0\, \dots\, 0\, 1) \in \vectSet{\mathbb{K}}{2n}$
  \item $\mu(a) = \left(
  \begin{array}{c|c}
    C & 0   \\
    \hline
    0 & I_n
  \end{array} \right)$, $\mu(b) = \left(
  \begin{array}{c|c}
    T & 0   \\
    \hline
    0 & I_n
  \end{array} \right)$ and, for all $i \in \intInterv{1}{n-1}$,
  $\mu(c_i) = \left(
  \begin{array}{c|c}
    0 & 0   \\
    \hline
    0 & M_i
  \end{array} \right)$.
  \item $v \in \matrSet{\mathbb{K}}{n}{1}$ can be arbitrary.
\end{itemize}

Note that $\genSemiGrp{\mu(a),\mu(b)} = \left\{ \left(
\begin{array}{c|c}
  P & 0   \\
  \hline
  0 & I_n
\end{array} \right) \,\middle|\, P \in \permutMatrSet{n} \right\}$ and,
for all vector $(k_1 \dots k_n \,|\, l_1 \dots l_{n-1}\, 1) \in \vectSet{\mathbb{K}}{2n}$,
$(k_1 \dots k_n \,|\, l_1 \dots l_{n-1}\, 1) \mu(c_i) =
(0 \dots 0 \,|\, l_1 \dots l_i + 1 \dots l_{n-1}\, 1)$.

The reachability set of $\mathcal{R}$ is then the union of the two sets
$S_1 = \left\{ \Bigl( (1\, 2\, \dots\, n) P \,|\, 0\, \dots\, 0\, 1 \Bigr) \,\middle|\,
P \in \permutMatrSet{n} \right\}$ and
$S_2 = \left\{ \Bigl(0\, \dots\, 0 \,|\, l_1\, \dots\, l_{n-1}\, 1 \Bigr)
\,\middle|\, l_1, \dots l_{n-1} \in \mathbb{N} \right\}$
Thus, $\linHull{\mathcal{R}}$ is the union of $\linSpan{S_2}$ and the $n!$ lines,
going through the origin, directed by the vectors of $S_1$.

Since $\dim \left( \linSpan{S_1} \right) = n-1$ and, for all $\sigma \in \Sigma$ and
$i \in \left\{ 1,2 \right\}$, there exists $j \in \left\{ 1,2 \right\}$ such that
$S_i \mu(\sigma) \subseteq S_j$, we can define a \nkCongr{2}{(n-1)} on $\linHull{\mathcal{R}}$
by grouping together all the irreducible components corresponding to the lines.

\end{document}
