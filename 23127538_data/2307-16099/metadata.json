{
  "title": "On Neural Network approximation of ideal adversarial attack and convergence of adversarial training",
  "authors": [
    "Rajdeep Haldar",
    "Qifan Song"
  ],
  "submission_date": "2023-07-30T01:04:36+00:00",
  "revised_dates": [],
  "abstract": "Adversarial attacks are usually expressed in terms of a gradient-based operation on the input data and model, this results in heavy computations every time an attack is generated. In this work, we solidify the idea of representing adversarial attacks as a trainable function, without further gradient computation. We first motivate that the theoretical best attacks, under proper conditions, can be represented as smooth piece-wise functions (piece-wise HÃ¶lder functions). Then we obtain an approximation result of such functions by a neural network. Subsequently, we emulate the ideal attack process by a neural network and reduce the adversarial training to a mathematical game between an attack network and a training model (a defense network). We also obtain convergence rates of adversarial loss in terms of the sample size $n$ for adversarial training in such a setting.",
  "categories": [
    "cs.LG",
    "stat.ML"
  ],
  "primary_category": "cs.LG",
  "doi": null,
  "journal_ref": null,
  "arxiv_id": "2307.16099",
  "pdf_url": "https://arxiv.org/pdf/2307.16099v1",
  "comment": null,
  "num_versions": null,
  "size_before_bytes": 18177778,
  "size_after_bytes": 206204
}