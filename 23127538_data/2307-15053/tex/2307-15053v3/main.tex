%\documentclass[manuscript, screen, dvipsnames, anonymous]{acmart}
%\documentclass[manuscript, screen, dvipsnames, authordraft]{acmart}
\documentclass[sigconf, screen, dvipsnames, authorversion]{acmart}
%\documentclass[sigconf, screen, dvipsnames, anonymous]{acmart}
%\documentclass[sigconf, screen, dvipsnames, anonymous, nonacm]{acmart}

\usepackage{multirow}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage[bb=dsserif,bbscaled=1.2]{mathalpha}
\usepackage{bm}
\usepackage{mathtools}
\usepackage[inline]{enumitem} % Inline lists
\usepackage{subcaption}
\usepackage{xcolor}

\usepackage{wrapfig}

% Dashed lines in tables
\usepackage{arydshln}
\makeatletter
\def\adl@drawiv#1#2#3{
        \hskip.5\tabcolsep
        \xleaders#3{#2.5\@tempdimb #1{1}#2.5\@tempdimb}%
                #2\z@ plus1fil minus1fil\relax
        \hskip.5\tabcolsep}
\newcommand{\cdashlinelr}[1]{%
  \noalign{\vskip\aboverulesep
          \global\let\@dashdrawstore\adl@draw
          \global\let\adl@draw\adl@drawiv}
  \cdashline{#1}
  \noalign{\global\let\adl@draw\@dashdrawstore
          \vskip\belowrulesep}}
\makeatother

\newtheorem{assumption}{Assumption}

\usepackage{colortbl}
\newcolumntype{p}{>{\columncolor{gray!10}}r}
\newcolumntype{R}{S[table-format=1.2]}

\usepackage{siunitx}

% PGM in Tikz
\usepackage{tikz}
\usetikzlibrary{automata, arrows, bayesnet, bending}

% % Reduce space after floats (such as tables and figures)
\setlength{\textfloatsep}{1pt plus 0pt minus .5pt}
\setlength{\intextsep}{1pt plus 0pt minus 1.0pt}
\setlength{\abovecaptionskip}{1pt plus 0pt minus 1pt}
\setlength{\belowcaptionskip}{1pt plus 0pt minus 1pt}
% Reduce space around equations
\setlength{\abovedisplayskip}{1pt plus 1pt minus 1pt}
\setlength{\belowdisplayskip}{1pt plus 1pt minus 1pt}

% Argmax as mathematical operator
\DeclareMathOperator{\argmax}{arg\,max}
\DeclareMathOperator{\argmin}{arg\,min}
\DeclareMathOperator{\argsort}{arg\,sort}
\DeclareMathOperator{\vect}{vec}

%Conference
\copyrightyear{2024}
\acmYear{2024}
\setcopyright{acmlicensed}\acmConference[KDD '24]{Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining}{August 25--29, 2024}{Barcelona, Spain}
\acmBooktitle{Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD '24), August 25--29, 2024, Barcelona, Spain}
\acmDOI{10.1145/3637528.3671687}
\acmISBN{979-8-4007-0490-1/24/08}


\begin{document}
\title{On (Normalised) Discounted Cumulative Gain as an Off-Policy Evaluation Metric for Top-$n$ Recommendation}

\author{Olivier Jeunen}
\affiliation{
  \institution{ShareChat}
  \city{Edinburgh}
  \country{United Kingdom}
}
\author{Ivan Potapov}
\affiliation{
  \institution{ShareChat}
  \city{London}
  \country{United Kingdom}
}
\author{Aleksei Ustimenko}
\affiliation{
  \institution{ShareChat}
  \city{London}
  \country{United Kingdom}
}

\begin{abstract}
Approaches to recommendation are typically evaluated in one of two ways:
\begin{enumerate*}
    \item via a (simulated) online experiment, often seen as the \emph{gold standard}, or
    \item via some offline evaluation procedure, where the goal is to approximate the outcome of an online experiment.
\end{enumerate*}
Several offline evaluation metrics have been adopted in the literature, inspired by ranking metrics prevalent in the field of Information Retrieval.
(Normalised) Discounted Cumulative Gain (nDCG) is one such metric that has seen widespread adoption in empirical studies, and higher (n)DCG values have been used to present new methods as  the \emph{state-of-the-art} in top-$n$ recommendation for many years.\looseness=-1

Our work takes a critical look at this approach, and investigates \emph{when} we can expect such metrics to approximate the gold standard outcome of an online experiment.
We formally present the assumptions that are necessary to consider DCG an \emph{unbiased} estimator of online reward and provide a derivation for this metric from first principles, highlighting where we deviate from its traditional uses in IR.
Importantly, we show that normalising the metric renders it \emph{inconsistent}, in that even when DCG is unbiased, ranking competing methods by their normalised DCG can invert their relative order.
Through a correlation analysis between off- and on-line experiments conducted on a large-scale recommendation platform, we show that our \emph{unbiased} DCG estimates strongly correlate with online reward, even when some of the metric's inherent assumptions are violated.
This statement no longer holds for its normalised variant, suggesting that nDCG's practical utility may be limited.
\end{abstract}

\begin{CCSXML}
<ccs2012>
   <concept>
       <concept_id>10002951.10003317.10003359</concept_id>
       <concept_desc>Information systems~Evaluation of retrieval results</concept_desc>
       <concept_significance>300</concept_significance>
       </concept>
   <concept>
       <concept_id>10002951.10003317.10003347.10003350</concept_id>
       <concept_desc>Information systems~Recommender systems</concept_desc>
       <concept_significance>500</concept_significance>
       </concept>
   <concept>
       <concept_id>10002950.10003648.10003662</concept_id>
       <concept_desc>Mathematics of computing~Probabilistic inference problems</concept_desc>
       <concept_significance>300</concept_significance>
       </concept>
 </ccs2012>
\end{CCSXML}

\ccsdesc[500]{Information systems~Recommender systems}
\ccsdesc[300]{Information systems~Evaluation of retrieval results}
\ccsdesc[300]{Mathematics of computing~Probabilistic inference problems}

\keywords{Offline Evaluation; Off-Policy Evaluation; Counterfactual Inference}

\maketitle

\input{1.Introduction}
\input{2.RelatedWork}
\input{3.ProblemSetting}
\input{4.DCG}
\input{5.NDCG}
\input{6.Experiments}
\input{7.BeyondAssumptions}
\input{8.Conclusion}


\begin{acks}
We are grateful to Lien Michiels, co-author of RecPack~\cite{Michiels2022}, for early feedback and help setting up the experiment in Appendix~\ref{sec:appx}.
\end{acks}

\bibliographystyle{ACM-Reference-Format}
\bibliography{bibliography}

\appendix
\input{A_Reproducibility}

\end{document}