@inproceedings{Steck2013,
 author = {Steck, H.},
 title = {Evaluation of Recommendations: Rating-prediction and Ranking},
 booktitle = {Proc. of the 7th ACM Conference on Recommender Systems},
 series = {RecSys '13},
 year = {2013},
 isbn = {978-1-4503-2409-0},
 pages = {213--220},
 numpages = {8},
 acmid = {2507160},
 publisher = {ACM},
 keywords = {ranking, rating prediction, recommender systems, selection bias},
url = {https://doi.org/10.1145/2507157.2507160},
doi = {10.1145/2507157.2507160}
} 

@inproceedings{mcmahan2013ad,
  title={Ad click prediction: a view from the trenches},
  author={McMahan, H. B. and Holt, G. and Sculley, D. and Young, M. and Ebner, D. and Grady, J. and Nie, L. and Phillips, T. and Davydov, E. and Golovin, D. and others},
  booktitle={Proc. of the 19th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
  pages={1222--1230},
  year={2013},
  organization={ACM}
}

@inproceedings{Dacrema2019,
 author = {Dacrema, M. F. and Cremonesi, P. and Jannach, D.},
 title = {Are We Really Making Much Progress? A Worrying Analysis of Recent Neural Recommendation Approaches},
 booktitle = {Proc. of the 13th ACM Conference on Recommender Systems},
 series = {RecSys '19},
 year = {2019},
 isbn = {978-1-4503-6243-6},
 pages = {101--109},
 numpages = {9},
 acmid = {3347058},
 publisher = {ACM},
 keywords = {deep learning, evaluation, recommender systems, reproducibility},
} 

@inproceedings{Elahi2019,
 author = {Elahi, E. and Wang, W. and Ray, D. and Fenton, A. and Jebara, T.},
 title = {Variational Low Rank Multinomials for Collaborative Filtering with Side-information},
 booktitle = {Proc. of the 13th ACM Conference on Recommender Systems},
 series = {RecSys '19},
 year = {2019},
 isbn = {978-1-4503-6243-6},
 
 pages = {340--347},
 numpages = {8},
 acmid = {3347036},
 publisher = {ACM},
 keywords = {collaborative filtering, side-information, variational inference},
} 


@article{Storkey2009,
  title={When training and test sets are different: characterizing learning transfer},
  author={Storkey, A.},
  journal={Dataset shift in machine learning},
  pages={3--28},
  year={2009},
  publisher={Citeseer}
}

@inproceedings{su2019cab,
  title={CAB: Continuous Adaptive Blending for Policy Evaluation and Learning},
  author={Su, Y. and Wang, L. and Santacatterina, M. and Joachims, T.},
  booktitle={International Conference on Machine Learning},
  series={ICML'19},
  pages={6005--6014},
  year={2019}
}

@article{Maurer2009,
  title={Empirical Bernstein Bounds and Sample Variance Penalization},
  author={Maurer, A. and Pontil, M.},
  journal={Stat.},
  volume={1050},
  pages={21},
  year={2009}
}

@article{Lewis2013,
  title={Nonsmooth optimization via quasi-Newton methods},
  author={Lewis, A. S. and Overton, M. L.},
  journal={Mathematical Programming},
  volume={141},
  number={1-2},
  pages={135--163},
  year={2013},
  publisher={Springer}
}

@article{Yu2010,
  title={A quasi-Newton approach to nonsmooth convex optimization problems in machine learning},
  author={Yu, J. and Vishwanathan, S.V.N. and G{\"u}nter, S. and Schraudolph, N.},
  journal={Journal of Machine Learning Research},
  volume={11},
  number={Mar},
  pages={1145--1200},
  year={2010}
}

@book{Hosmer2013,
  title={Applied logistic regression},
  author={Hosmer Jr., D. and Lemeshow, S. and Sturdivant, R.},
  volume={398},
  year={2013},
  publisher={John Wiley \& Sons}
}

@inproceedings{Paszke2017,
  title={Automatic differentiation in PyTorch},
  author={Paszke, A. and Gross, S. and Chintala, S. and Chanan, G. and Yang, E. and DeVito, Z. and Lin, Z. and Desmaison, A. and Antiga, L. and Lerer, A.},
  booktitle={Proc. of the NIPS 2017 Workshop on AutoDiff},
  year={2017}
}


 %{AMS}
 @String{AMSTrans = "American Mathematical Society Translations" }
 @String{AMSTrans = "Amer. Math. Soc. Transl." }
 @String{BullAMS = "Bulletin of the American Mathematical Society" }
 @String{BullAMS = "Bull. Amer. Math. Soc." }
 @String{ProcAMS = "Proceedings of the American Mathematical Society" }
 @String{ProcAMS = "Proc. Amer. Math. Soc." }
 @String{TransAMS = "Transactions of the American Mathematical Society" }
 @String{TransAMS = "Trans. Amer. Math. Soc." }

 %ACM
 @String{CACM = "Communications of the {ACM}" }
 @String{CACM = "Commun. {ACM}" }
 @String{CompServ = "Comput. Surveys" }
 @String{JACM = "J. ACM" }
 @String{ACMMathSoft = "{ACM} Transactions on Mathematical Software" }
 @String{ACMMathSoft = "{ACM} Trans. Math. Software" }
 @String{SIGNUM = "{ACM} {SIGNUM} Newsletter" }
 @String{SIGNUM = "{ACM} {SIGNUM} Newslett." }

 @String{AmerSocio = "American Journal of Sociology" }
 @String{AmerStatAssoc = "Journal of the American Statistical Association" }
 @String{AmerStatAssoc = "J. Amer. Statist. Assoc." }
 @String{ApplMathComp = "Applied Mathematics and Computation" }
 @String{ApplMathComp = "Appl. Math. Comput." }
 @String{AmerMathMonthly = "American Mathematical Monthly" }
 @String{AmerMathMonthly = "Amer. Math. Monthly" }
 @String{BIT = "{BIT}" }
 @String{BritStatPsych = "British Journal of Mathematical and Statistical
          Psychology" }
 @String{BritStatPsych = "Brit. J. Math. Statist. Psych." }
 @String{CanMathBull = "Canadian Mathematical Bulletin" }
 @String{CanMathBull = "Canad. Math. Bull." }
 @String{CompApplMath = "Journal of Computational and Applied Mathematics" }
 @String{CompApplMath = "J. Comput. Appl. Math." }
 @String{CompPhys = "Journal of Computational Physics" }
 @String{CompPhys = "J. Comput. Phys." }
 @String{CompStruct = "Computers and Structures" }
 @String{CompStruct = "Comput. \& Structures" }
 @String{CompJour = "The Computer Journal" }
 @String{CompJour = "Comput. J." }
 @String{CompSysSci = "Journal of Computer and System Sciences" }
 @String{CompSysSci = "J. Comput. System Sci." }
 @String{Computing = "Computing" }
 @String{ContempMath = "Contemporary Mathematics" }
 @String{ContempMath = "Contemp. Math." }
 @String{Crelle = "Crelle's Journal" }
 @String{GiornaleMath = "Giornale di Mathematiche" }
 @String{GiornaleMath = "Giorn. Mat." } % didn't find in AMS MR., ibid.

 %IEEE
 @String{Computer = "{IEEE} Computer" }
 @String{IEEETransComp = "{IEEE} Transactions on Computers" }
 @String{IEEETransComp = "{IEEE} Trans. Comput." }
 @String{IEEETransAC = "{IEEE} Transactions on Automatic Control" }
 @String{IEEETransAC = "{IEEE} Trans. Automat. Control" }
 @String{IEEESpec = "{IEEE} Spectrum" } % didn't find in AMS MR
 @String{ProcIEEE = "Proceedings of the {IEEE}" }
 @String{ProcIEEE = "Proc. {IEEE}" } % didn't find in AMS MR
 @String{IEEETransAeroElec = "{IEEE} Transactions on Aerospace and Electronic
     Systems" }
 @String{IEEETransAeroElec = "{IEEE} Trans. Aerospace Electron. Systems" }

 @String{IMANumerAna = "{IMA} Journal of Numerical Analysis" }
 @String{IMANumerAna = "{IMA} J. Numer. Anal." }
 @String{InfProcLet = "Information Processing Letters" }
 @String{InfProcLet = "Inform. Process. Lett." }
 @String{InstMathApp = "Journal of the Institute of Mathematics and
     its Applications" }
 @String{InstMathApp = "J. Inst. Math. Appl." }
 @String{IntControl = "International Journal of Control" }
 @String{IntControl = "Internat. J. Control" }
 @String{IntNumerEng = "International Journal for Numerical Methods in
     Engineering" }
 @String{IntNumerEng = "Internat. J. Numer. Methods Engrg." }
 @String{IntSuper = "International Journal of Supercomputing Applications" }
 @String{IntSuper = "Internat. J. Supercomputing Applic." } % didn't find
%% in AMS MR
 @String{Kibernetika = "Kibernetika" }
 @String{JResNatBurStand = "Journal of Research of the National Bureau
     of Standards" }
 @String{JResNatBurStand = "J. Res. Nat. Bur. Standards" }
 @String{LinAlgApp = "Linear Algebra and its Applications" }
 @String{LinAlgApp = "Linear Algebra Appl." }
 @String{MathAnaAppl = "Journal of Mathematical Analysis and Applications" }
 @String{MathAnaAppl = "J. Math. Anal. Appl." }
 @String{MathAnnalen = "Mathematische Annalen" }
 @String{MathAnnalen = "Math. Ann." }
 @String{MathPhys = "Journal of Mathematical Physics" }
 @String{MathPhys = "J. Math. Phys." }
 @String{MathComp = "Mathematics of Computation" }
 @String{MathComp = "Math. Comp." }
 @String{MathScand = "Mathematica Scandinavica" }
 @String{MathScand = "Math. Scand." }
 @String{TablesAidsComp = "Mathematical Tables and Other Aids to Computation" }
 @String{TablesAidsComp = "Math. Tables Aids Comput." }
 @String{NumerMath = "Numerische Mathematik" }
 @String{NumerMath = "Numer. Math." }
 @String{PacificMath = "Pacific Journal of Mathematics" }
 @String{PacificMath = "Pacific J. Math." }
 @String{ParDistComp = "Journal of Parallel and Distributed Computing" }
 @String{ParDistComp = "J. Parallel and Distrib. Comput." } % didn't find
%% in AMS MR
 @String{ParComputing = "Parallel Computing" }
 @String{ParComputing = "Parallel Comput." }
 @String{PhilMag = "Philosophical Magazine" }
 @String{PhilMag = "Philos. Mag." }
 @String{ProcNAS = "Proceedings of the National Academy of Sciences
                    of the USA" }
 @String{ProcNAS = "Proc. Nat. Acad. Sci. U. S. A." }
 @String{Psychometrika = "Psychometrika" }
 @String{QuartMath = "Quarterly Journal of Mathematics, Oxford, Series (2)" }
 @String{QuartMath = "Quart. J. Math. Oxford Ser. (2)" }
 @String{QuartApplMath = "Quarterly of Applied Mathematics" }
 @String{QuartApplMath = "Quart. Appl. Math." }
 @String{RevueInstStat = "Review of the International Statisical Institute" }
 @String{RevueInstStat = "Rev. Inst. Internat. Statist." }

 %SIAM
 @String{JSIAM = "Journal of the Society for Industrial and Applied
     Mathematics" }
 @String{JSIAM = "J. Soc. Indust. Appl. Math." }
 @String{JSIAMB = "Journal of the Society for Industrial and Applied
     Mathematics, Series B, Numerical Analysis" }
 @String{JSIAMB = "J. Soc. Indust. Appl. Math. Ser. B Numer. Anal." }
 @String{SIAMAlgMeth = "{SIAM} Journal on Algebraic and Discrete Methods" }
 @String{SIAMAlgMeth = "{SIAM} J. Algebraic Discrete Methods" }
 @String{SIAMAppMath = "{SIAM} Journal on Applied Mathematics" }
 @String{SIAMAppMath = "{SIAM} J. Appl. Math." }
 @String{SIAMComp = "{SIAM} Journal on Computing" }
 @String{SIAMComp = "{SIAM} J. Comput." }
 @String{SIAMMatrix = "{SIAM} Journal on Matrix Analysis and Applications" }
 @String{SIAMMatrix = "{SIAM} J. Matrix Anal. Appl." }
 @String{SIAMNumAnal = "{SIAM} Journal on Numerical Analysis" }
 @String{SIAMNumAnal = "{SIAM} J. Numer. Anal." }
 @String{SIAMReview = "{SIAM} Review" }
 @String{SIAMReview = "{SIAM} Rev." }
 @String{SIAMSciStat = "{SIAM} Journal on Scientific and Statistical
     Computing" }
 @String{SIAMSciStat = "{SIAM} J. Sci. Statist. Comput." }

 @String{SoftPracExp = "Software Practice and Experience" }
 @String{SoftPracExp = "Software Prac. Experience" } % didn't find in AMS MR
 @String{StatScience = "Statistical Science" }
 @String{StatScience = "Statist. Sci." }
 @String{Techno = "Technometrics" }
 @String{USSRCompMathPhys = "{USSR} Computational Mathematics and Mathematical
     Physics" }
 @String{USSRCompMathPhys = "{U. S. S. R.} Comput. Math. and Math. Phys." }
 @String{VLSICompSys = "Journal of {VLSI} and Computer Systems" }
 @String{VLSICompSys = "J. {VLSI} Comput. Syst." }
 @String{ZAngewMathMech = "Zeitschrift fur Angewandte Mathematik und
     Mechanik" }
 @String{ZAngewMathMech = "Z. Angew. Math. Mech." }
 @String{ZAngewMathPhys = "Zeitschrift fur Angewandte Mathematik und Physik" }
 @String{ZAngewMathPhys = "Z. Angew. Math. Phys." }

% Publishers % ================================================= |

 @String{Academic = "Academic Press" }
 @String{ACMPress = "{ACM} Press" }
 @String{AdamHilger = "Adam Hilger" }
 @String{AddisonWesley = "Addison-Wesley" }
 @String{AllynBacon = "Allyn and Bacon" }
 @String{AMS = "American Mathematical Society" }
 @String{Birkhauser = "Birkha{\"u}ser" }
 @String{CambridgePress = "Cambridge University Press" }
 @String{Chelsea = "Chelsea" }
 @String{ClaredonPress = "Claredon Press" }
 @String{DoverPub = "Dover Publications" }
 @String{Eyolles = "Eyolles" }
 @String{HoltRinehartWinston = "Holt, Rinehart and Winston" }
 @String{Interscience = "Interscience" }
 @String{JohnsHopkinsPress = "The Johns Hopkins University Press" }
 @String{JohnWileySons = "John Wiley and Sons" }
 @String{Macmillan = "Macmillan" }
 @String{MathWorks = "The Math Works Inc." }
 @String{McGrawHill = "McGraw-Hill" }
 @String{NatBurStd = "National Bureau of Standards" }
 @String{NorthHolland = "North-Holland" }
 @String{OxfordPress = "Oxford University Press" }  %address Oxford or London?
 @String{PergamonPress = "Pergamon Press" }
 @String{PlenumPress = "Plenum Press" }
 @String{PrenticeHall = "Prentice-Hall" }
 @String{SIAMPub = "{SIAM} Publications" }
 @String{Springer = "Springer-Verlag" }
 @String{TexasPress = "University of Texas Press" }
 @String{VanNostrand = "Van Nostrand" }
 @String{WHFreeman = "W. H. Freeman and Co." }

%Entries
@article{Robbins1952,
  title={Some aspects of the sequential design of experiments},
  author={Robbins, Herbert},
  journal={Bulletin of the American Mathematical Society},
  volume={58},
  number={5},
  pages={527--535},
  year={1952},
}

@inproceedings{Kohavi1995,
  title={A study of cross-validation and bootstrap for accuracy estimation and model selection},
  author={Kohavi, R. and others},
  booktitle={Proc. of the 1995 International Joint Conference on Artificial Intelligence},
  volume={14},
  number={2},
  pages={1137--1145},
  year={1995},
  organisation = {IJCAI}
}

@book{Sutton1998,
  title={Introduction to reinforcement learning},
  author={Sutton, R. S. and Barto, A. G.},
  year = {1998},
  volume={135}
}

@inproceedings{Sarwar2001,
 author = {Sarwar, B. and Karypis, G. and Konstan, J. and Riedl, J.},
 title = {Item-based Collaborative Filtering Recommendation Algorithms},
 booktitle = {Proc. of the 10th International Conference on World Wide Web},
 series = {WWW '01},
 year = {2001},
 
 pages = {285--295},
 numpages = {11},
 acmid = {372071},
 publisher = {ACM},
}

@inproceedings{Yu2001,
  title={Indexing the distance: An efficient method to knn processing},
  author={Yu, C. and Ooi, B. and Tan, K. and Jagadish, H.},
  booktitle={Proc. of the 27th International Conference on Very Large Databases},
  series = {VLDB '01},
  year={2001},
  pages={421--430},
  numpages = {10}
}

@inproceedings{Schein2002,
 author = {Schein, Andrew I. and Popescul, Alexandrin and Ungar, Lyle H. and Pennock, David M.},
 title = {{Methods and Metrics for Cold-start Recommendations}},
 booktitle = {Proc. of the 25th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval},
 series = {SIGIR '02},
 year = {2002},
 
 pages = {253--260},
 numpages = {8},
 acmid = {564421},
 publisher = {ACM},
 keywords = {collaborative filtering, content-based filtering, graphical models, information retrieval, performance evaluation, recommender systems},
}

@inproceedings{Sarawagi2004,
 author = {Sarawagi, S. and Kirpal, A.},
 title = {Efficient Set Joins on Similarity Predicates},
 booktitle = {Proc. of the 2004 ACM SIGMOD International Conference on Management of Data},
 series = {SIGMOD '04},
 year = {2004},
 isbn = {1-58113-859-8},
 
 pages = {743--754},
 numpages = {12},
 acmid = {1007652},
 publisher = {ACM},
 
} 

@InProceedings{Papagelis2005,
author="Papagelis, M.
and Rousidis, I.
and Plexousakis, D.
and Theoharopoulos, E.",
editor="Hacid, M.
and Murray, N.
and Ra{\'{s}}, Z.
and Tsumoto, S.",
title="Incremental Collaborative Filtering for Highly-Scalable Recommendation Algorithms",
booktitle="Foundations of Intelligent Systems",
year="2005",
publisher="Springer",
pages="553--561",
isbn="978-3-540-31949-8"
}

@inproceedings{Zhang2005, 
author={Zhang, S. and Wang, W. and Ford, J. and Makedon, F. and Pearlman, J.}, 
booktitle={Proc. of the 7th IEEE International Conference on E-Commerce Technology},
series = {CEC '05},
title={Using singular value decomposition approximation for collaborative filtering}, 
year={2005}, 
volume={}, 
number={}, 
pages={257-264}, 
ISSN={2378-1963}, 
month={July},}

@inproceedings{Bennet2007,
  title={The Netflix prize},
  author={Bennett, J. and Lanning, S. and others},
  booktitle={Proc. of the KDD cup and workshop},
  volume={2007},
  pages={35},
  year={2007},
}

@article{Yu2007,
 author = {Yu, C. and Cui, B. and Wang, S. and Su, J.},
 title = {Efficient Index-based KNN Join Processing for High-dimensional Data},
 journal = {Inf. Softw. Technol.},
 issue_date = {April, 2007},
 volume = {49},
 number = {4},
 month = apr,
 year = {2007},
 issn = {0950-5849},
 pages = {332--344},
 numpages = {13},
 acmid = {1224939},
 publisher = {Butterworth-Heinemann},
 address = {Newton, MA, USA},
 keywords = {High-dimensional data, KNN, Similarity join},
} 

@inproceedings{Rendle2008,
 author = {Rendle, S. and Schmidt-Thieme, L.},
 title = {Online-updating Regularized Kernel Matrix Factorization Models for Large-scale Recommender Systems},
 booktitle = {Proc. of the 1st ACM Conference on Recommender Systems},
 series = {RecSys '08},
 year = {2008},
 
 pages = {251--258},
 numpages = {8},
 acmid = {1454047},
 publisher = {ACM},
 keywords = {matrix factorization, online-update, recommender system},
} 

@article{Dean2008,
 author = {Dean, J. and Ghemawat, S.},
 title = {MapReduce: Simplified Data Processing on Large Clusters},
 journal = {Commun. ACM},
 issue_date = {January 2008},
 volume = {51},
 number = {1},
 month = jan,
 year = {2008},
 pages = {107--113},
 numpages = {7},
 publisher = {ACM},
} 

@inproceedings{Pan2008, 
author={R. Pan and Y. Zhou and B. Cao and N. N. Liu and R. Lukose and M. Scholz and Q. Yang}, 
booktitle={Proc. of the 8th IEEE International Conference on Data Mining},
series = {ICDM '08},
title={One-Class Collaborative Filtering}, 
year={2008}, 
volume={}, 
number={}, 
pages={502-511}, 
keywords={Internet;groupware;information filtering;Web page bookmarking;binary data;bookmark recommendation;news item recommendation;one-class collaborative filtering;training data;DVD;Data mining;Filtering;Fuels;History;International collaboration;Milling machines;Rockets;Sampling methods;Training data;Alternating Least Squares;Collaborative Filtering;Low-Rank Approximations;One-Class}, 
ISSN={1550-4786}, 
month={Dec}
}

@inproceedings{Hu2008, 
author={Y. Hu and Y. Koren and C. Volinsky}, 
booktitle={Proc. of the 8th IEEE International Conference on Data Mining},
title={{Collaborative Filtering for Implicit Feedback Datasets}},
series={ICDM '08},
year={2008}, 
volume={}, 
number={}, 
pages={263-272}, 
keywords={electronic commerce;feedback;browsing activity;collaborative filtering;customer experience;implicit feedback datasets;personalized recommendations;purchase history;recommender systems;scalable optimization procedure;user preferences;watching habits;Data mining;Demography;Filtering;History;International collaboration;Motion pictures;Negative feedback;Recommender systems;TV;Watches;Collaborative filtering;implicit feedback;recommender system}, 
ISSN={1550-4786}, 
month={Dec}
}

@incollection{Langford2008,
title = {The Epoch-Greedy Algorithm for Multi-armed Bandits with Side Information},
author = {Langford, J. and Zhang, T.},
booktitle = {Advances in Neural Information Processing Systems 20},
pages = {817--824},
year = {2008},
publisher = {Curran Associates, Inc.},
}


@inproceedings{Rendle2009,
  author={Rendle, S. and Freudenthaler, C. and Gantner, Z. and Schmidt-Thieme, L.},
  title={{BPR: Bayesian personalized ranking from implicit feedback}},
  booktitle={Proc. of the 25th Conference on Uncertainty in Artificial Intelligence},
  series = {UAI '09},
  year={2009},
  pages={452--461},
  organization={AUAI Press}
}

@article{Yu2009,
  author="Yu, C.
  and Zhang, R.
  and Huang, Y.
  and Xiong, H.",
  title="High-dimensional kNN joins with incremental updates",
  journal="GeoInformatica",
  year="2009",
  volume="14",
  number="1",
  pages="55--82",
}

@Article{Kohavi2009,
author="Kohavi, R.
and Longbotham, R.
and Sommerfield, D.
and Henne, R. M.",
title="Controlled experiments on the web: survey and practical guide",
journal="Data Mining and Knowledge Discovery",
year="2009",
month="Feb",
day="01",
volume="18",
number="1",
pages="140--181",
}

@book{Kohavi2020,
  title={Trustworthy online controlled experiments: A practical guide to A/B testing},
  author={Kohavi, R. and Tang, D. and Xu, Y.},
  year={2020},
  publisher={Cambridge University Press}
}


@inproceedings{Karatzoglou2010,
 author = {Karatzoglou, A. and Amatriain, X. and Baltrunas, L. and Oliver, N.},
 title = {{Multiverse Recommendation: N-dimensional Tensor Factorization for Context-aware Collaborative Filtering}},
 booktitle = {Proc. of the 4th ACM Conference on Recommender Systems},
 series = {RecSys '10},
 year = {2010},
 
 pages = {79--86},
 numpages = {8},
 acmid = {1864727},
 publisher = {ACM},
 keywords = {collaborative filtering, context, tensor factorization},
} 

@inproceedings{Liu2010,
 author = {Liu, N. and Zhao, M. and Xiang, E. and Yang, Q.},
 title = {Online Evolutionary Collaborative Filtering},
 booktitle = {Proc. of the 4th ACM Conference on Recommender Systems},
 series = {RecSys '10},
 year = {2010},
 
 pages = {95--102},
 numpages = {8},
 acmid = {1864729},
 publisher = {ACM},
 keywords = {collaborative filtering, latent class model, ranking},
} 

@incollection{Shani2011,
author="Shani, G. and Gunawardana, A.",
editor="Ricci, Francesco
and Rokach, Lior
and Shapira, Bracha
and Kantor, Paul B.",
title="Evaluating Recommendation Systems",
booktitle="Recommender Systems Handbook",
year="2011",
publisher="Springer US",
pages="257--297",
isbn="978-0-387-85820-3"
}

@inproceedings{Yang2012,
 author = {Yang, X. and Zhang, Z. and Wang, K.},
 title = {Scalable Collaborative Filtering Using Incremental Update and Local Link Prediction},
 booktitle = {Proc. of the 21st ACM International Conference on Information and Knowledge Management},
 series = {CIKM '12},
 year = {2012},
 
 pages = {2371--2374},
 numpages = {4},
 acmid = {2398643},
 publisher = {ACM},
 keywords = {collaborative filtering, incremental update, link prediction, scalability, similarity graph},
}

@inproceedings{Zhang2012,
 author = {Zhang, C. and Li, F. and Jestes, J.},
 title = {Efficient Parallel kNN Joins for Large Data in MapReduce},
 booktitle = {Proc. of the 15th International Conference on Extending Database Technology},
 series = {EDBT '12},
 year = {2012},
 
 pages = {38--49},
 numpages = {12},
 acmid = {2247602},
 publisher = {ACM},
}

@article{Zadeh2013,
  title={Dimension independent similarity computation},
  author={Zadeh, R. and Goel, A.},
  journal={The Journal of Machine Learning Research},
  volume={14},
  number={1},
  pages={1605--1626},
  year={2013},
  publisher={JMLR.org}
}

@article{Luo2013,
title = "Boosting the K-Nearest-Neighborhood based incremental collaborative filtering",
journal = "Knowledge-Based Systems",
volume = "53",
pages = "90 - 99",
year = "2013",
author = "X. Luo and Y. Xia and Q. Zhu and Y. Li",
keywords = "Recommender system, Incremental recommendation, Collaborative filtering, Rating similarity, K-Nearest-Neighborhood"
}

@inproceedings{Beel2013,
 author = {Beel, J. and Genzmehr, M. and Langer, S. and N\"{u}rnberger, A. and Gipp, B.},
 title = {{A Comparative Analysis of Offline and Online Evaluations and Discussion of Research Paper Recommender System Evaluation}},
 booktitle = {Proc. of the International Workshop on Reproducibility and Replication in Recommender Systems Evaluation},
 series = {RepSys '13},
 year = {2013},
 isbn = {978-1-4503-2465-6},
 pages = {7--14},
 numpages = {8},
 acmid = {2532511},
 keywords = {click-through rate, comparative study, evaluation, offline evaluation, online evaluation, research paper recommender systems},
}

@inproceedings{Garcin2014,
 author = {Garcin, F. and Faltings, B. and Donatsch, O. and Alazzawi, A. and Bruttin, C. and Huber, A.},
 title = {{Offline and Online Evaluation of News Recommender Systems at Swissinfo.Ch}},
 booktitle = {Proc. of the 8th ACM Conference on Recommender Systems},
 series = {RecSys '14},
 year = {2014},
 isbn = {978-1-4503-2668-1},
 pages = {169--176},
 numpages = {8},
 acmid = {2645745},
 keywords = {evaluation, live, news, real-time, recommender system},
 url = {https://doi.org/10.1145/2645710.2645745}
}

@inproceedings{Yang2014, 
  author={Yang, C. and Yu, X. and Liu, Y.}, 
  booktitle={Proc. of the 14th IEEE International Conference on Data Mining},
  series = {ICDM '14},
  title={Continuous KNN Join Processing for Real-Time Recommendation}, 
  year={2014}, 
  volume={}, 
  number={}, 
  pages={640-649}, 
  keywords={data reduction;pattern clustering;principal component analysis;recommender systems;social   networking (online);tree data structures;HDR-tree index structure;PCA;Web sites;clustering analysis;continuous   KNN join processing;curse of dimensionality reduction;data streams;high in-memory search cost;k nearest neighbors;people content-consumption behavior;principle component analysis;real-time recommendation;social networking;user-generated contents;Clustering algorithms;Collaboration;Educational institutions;Indexes;Principal component analysis;Real-time systems;Vegetation;high-dimensional data;k nearest neighbor join;real-time recommendation}, 
  month={Dec}
}

@article{Muja2014, 
  author={Muja, M. and Lowe, D. G.}, 
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={Scalable Nearest Neighbor Algorithms for High Dimensional Data}, 
  year={2014}, 
  volume={36}, 
  number={11}, 
  pages={2227-2240}
}

@inproceedings{Rong2014,
 author = {Rong, Y. and Wen, X. and Cheng, H.},
 title = {{A Monte Carlo Algorithm for Cold Start Recommendation}},
 booktitle = {Proc. of the 23rd International Conference on World Wide Web},
 series = {WWW '14},
 year = {2014},
 
 pages = {327--336},
 numpages = {10},
 acmid = {2567978},
 publisher = {ACM},
 keywords = {cold start, monte carlo simulation, preference propagation, random walk on bipartite graph}
}

@inproceedings{Saveski2014,
 author = {Saveski, M. and Mantrach, A.},
 title = {{Item Cold-start Recommendations: Learning Local Collective Embeddings}},
 booktitle = {Proc. of the 8th ACM Conference on Recommender Systems},
 series = {RecSys '14},
 year = {2014},
 
 pages = {89--96},
 numpages = {8},
 acmid = {2645751},
 publisher = {ACM},
 keywords = {cold-start, collective embeddings, matrix factorization, recommender systems},
}

@inproceedings{Ottaviano2014,
 author = {Ottaviano, G. and Venturini, R.},
 title = {Partitioned Elias-Fano Indexes},
 booktitle = {Proc. of the 37th International ACM SIGIR Conference on Research \& Development in Information Retrieval},
 series = {SIGIR '14},
 year = {2014},
 isbn = {978-1-4503-2257-7},
 
 pages = {273--282},
 numpages = {10},
 acmid = {2609615},
 publisher = {ACM},
 keywords = {compression, dynamic programming, inverted indexes},
}

@article{Mirbakhsh2015,
 author = {Mirbakhsh, N. and Ling, C. X.},
 title = {{Improving Top-N Recommendation for Cold-Start Users via Cross-Domain Information}},
 journal = {ACM Trans. Knowl. Discov. Data},
 issue_date = {June 2015},
 volume = {9},
 number = {4},
 month = jun,
 year = {2015},
 pages = {33:1--33:19},
 articleno = {33},
 numpages = {19},
 acmid = {2724720},
 publisher = {ACM},
 keywords = {Collaborative filtering, cold start, matrix factorization, recommendation system},
} 

@inproceedings{Huang2015,
 author = {Huang, Y. and Cui, B. and Zhang, W. and Jiang, J. and Xu, Y.},
 title = {TencentRec: Real-time Stream Recommendation in Practice},
 booktitle = {Proc. of the 2015 ACM SIGMOD International Conference on Management of Data},
 series = {SIGMOD '15},
 year = {2015},
 
 pages = {227--238},
 numpages = {12},
 acmid = {2742785},
 publisher = {ACM},
 keywords = {application, big data, practice, real-time recommendation, scalability},
} 

@article{Gomez-Uribe2015,
 author = {Gomez-Uribe, C. A. and Hunt, N.},
 title = {The Netflix Recommender System: Algorithms, Business Value, and Innovation},
 journal = {ACM Trans. Manage. Inf. Syst.},
 issue_date = {January 2016},
 volume = {6},
 number = {4},
 month = dec,
 year = {2015},
 issn = {2158-656X},
 pages = {13:1--13:19},
 articleno = {13},
 numpages = {19},
 acmid = {2843948},
 publisher = {ACM},
 
 keywords = {Recommender systems},
} 

@inproceedings{Rossetti2016,
 author = {Rossetti, M. and Stella, F. and Zanker, M.},
 title = {{Contrasting Offline and Online Results when Evaluating Recommendation Algorithms}},
 booktitle = {Proc. of the 10th ACM Conference on Recommender Systems},
 series = {RecSys '16},
 year = {2016},
 isbn = {978-1-4503-4035-9},
 pages = {31--34},
 numpages = {4},
 acmid = {2959176},
 publisher = {ACM},
 keywords = {evaluation methodology, experimental within users design, user study},
 url = {https://doi.org/10.1145/2959100.2959176},
} 

@inproceedings{Subbian2016,
 author = {Subbian, K. and Aggarwal, C. and Hegde, K.},
 title = {Recommendations For Streaming Data},
 booktitle = {Proc. of the 25th ACM International on Conference on Information and Knowledge Management},
 series = {CIKM '16},
 year = {2016},
 
 pages = {2185--2190},
 numpages = {6},
 acmid = {2983663},
 publisher = {ACM},
 keywords = {data streams, neighborhood model, recommender systems, streaming recommendations},
} 

@inproceedings{He2016,
 author = {He, X. and Zhang, H. and Kan, M. and Chua, T.},
 title = {Fast Matrix Factorization for Online Recommendation with Implicit Feedback},
 booktitle = {Proc. of the 39th International ACM SIGIR Conference on Research and Development in Information Retrieval},
 series = {SIGIR '16},
 year = {2016},
 
 pages = {549--558},
 numpages = {10},
 acmid = {2911489},
 publisher = {ACM},
 keywords = {ALS, coordinate descent, implicit feedback, item recommendation, matrix factorization, online learning},
} 

@inproceedings{Jannach2017,
 author = {Jannach, D. and Ludewig, M.},
 title = {When Recurrent Neural Networks Meet the Neighborhood for Session-Based Recommendation},
 booktitle = {Proc. of the 11th ACM Conference on Recommender Systems},
 series = {RecSys '17},
 year = {2017},
 
 pages = {306--310},
 numpages = {5},
 acmid = {3109872},
 publisher = {ACM},
 keywords = {deep learning, nearest-neighbors, session-based recommendation},
}

@misc{Outbrain2017,
  title = {Kaggle Click Prediction Dataset},
  author = {Outbrain},
  year = {2017},
  howpublished = {\url{https://www.kaggle.com/c/outbrain-click-prediction/data}},
}

@article{Verstrepen2017,
 author = {Verstrepen, K. and Bhaduriy, K. and Cule, B. and Goethals, B.},
 title = {Collaborative Filtering for Binary, Positiveonly Data},
 journal = {SIGKDD Explor. Newsl.},
 issue_date = {June 2017},
 volume = {19},
 number = {1},
 month = sep,
 year = {2017},
 issn = {1931-0145},
 pages = {1--21},
 numpages = {21},
 acmid = {3137599},
 publisher = {ACM},
 
} 

@inproceedings{Agarwal2017,
 author = {Agarwal, A. and Basu, S. and Schnabel, T. and Joachims, T.},
 title = {Effective Evaluation Using Logged Bandit Feedback from Multiple Loggers},
 booktitle = {Proc. of the 23rd ACM SIGKDD International Conference on Knowledge Discovery \& Data Mining},
 series = {KDD '17},
 year = {2017},
 isbn = {978-1-4503-4887-4},
 pages = {687--696},
 numpages = {10},
 acmid = {3098155},
 publisher = {ACM},
 keywords = {counterfactual estimators, implicit feedback, log data, off-policy evaluation},
url = {https://doi.org/10.1145/3097983.3098155},
doi = {10.1145/3097983.3098155}
} 


@InProceedings{Sreepada2018,
author="Sreepada, R. S.
and Patra, B. K.",
editor="Pasi, G.
and Piwowarski, B.
and Azzopardi, L.
and Hanbury, A.",
title="An Incremental Approach for Collaborative Filtering in Streaming Scenarios",
booktitle="Advances in Information Retrieval",
year="2018",
publisher="Springer International Publishing",
pages="632--637",
}

@inproceedings{W_Wang2018,
 author = {Wang, W. and Yin, H. and Huang, Z. and Wang, Q. and Du, X. and Nguyen, Q.},
 title = {Streaming Ranking Based Recommender Systems},
 booktitle = {Proc. of the 41st International ACM SIGIR Conference on Research and Development in Information Retrieval},
 series = {SIGIR '18},
 year = {2018},
 
 pages = {525--534},
 numpages = {10},
 acmid = {3210016},
 publisher = {ACM},
 keywords = {information retrieval, online applications, recommender systems, streaming data, user behaviour modeling},
} 

@inproceedings{Q_Wang2018,
 author = {Wang, Q. and Yin, H. and Hu, Z. and Lian, D. and Wang, H. and Huang, Z.},
 title = {Neural Memory Streaming Recommender Networks with Adversarial Training},
 booktitle = {Proc. of the 24th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
 series = {KDD '18},
 year = {2018},
 
 pages = {2467--2475},
 numpages = {9},
 acmid = {3220004},
 publisher = {ACM},
 keywords = {collaborative filtering, memory networks, streaming recommender systems},
}

@article{Karimi2018,
title = "News recommender systems - Survey and roads ahead",
journal = "Information Processing \& Management",
volume = "54",
number = "6",
pages = "1203 - 1227",
year = "2018",
author = "M. Karimi and D. Jannach and M. Jugovac",
keywords = "News recommender systems, Survey"
}

@inproceedings{Jeunen2018,
  title={Fair Offline Evaluation Methodologies for Implicit-feedback Recommender Systems with MNAR Data},
  author={Jeunen, O. and Verstrepen, K. and Goethals, B.},
  booktitle={Proc. of the REVEAL 18 Workshop on Offline Evaluation for Recommender Systems (RecSys '18)},
  year={2018},
  month = {October}
}

@inproceedings{Gilotte2018,
 author = {Gilotte, A. and Calauz\`{e}nes, C. and Nedelec, T. and Abraham, A. and Doll{\'e}, S.},
 title = {Offline A/B Testing for Recommender Systems},
 booktitle = {Proc. of the Eleventh ACM International Conference on Web Search and Data Mining},
 series = {WSDM '18},
 year = {2018},
 isbn = {978-1-4503-5581-0},
 pages = {198--206},
 numpages = {9},
 acmid = {3159687},
 publisher = {ACM},
 keywords = {counterfactual estimation, importance sampling., off-policy evaluation, recommender system},
 url = {https://doi.org/10.1145/3159652.3159687},
}


@inproceedings{Pibiri2019,
 author = {Pibiri, G. E. and Petri, M. and Moffat, A.},
 title = {Fast Dictionary-Based Compression for Inverted Indexes},
 booktitle = {Proc. of the 12th ACM International Conference on Web Search and Data Mining},
 series = {WSDM '19},
 year = {2019},
 isbn = {978-1-4503-5940-5},
 
 pages = {6--14},
 numpages = {9},
 acmid = {3290962},
 publisher = {ACM},
 keywords = {compression, decoding, efficiency, inverted index},
} 

@inproceedings{Gruson2019,
 author = {Gruson, A. and Chandar, P. and Charbuillet, C. and McInerney, J. and Hansen, S. and Tardieu, D. and Carterette, B.},
 title = {Offline Evaluation to Make Decisions About Playlist Recommendation Algorithms},
 booktitle = {Proc of. the 12th ACM International Conference on Web Search and Data Mining},
 series = {WSDM '19},
 year = {2019},
 isbn = {978-1-4503-5940-5},
 pages = {420--428},
 numpages = {9},
 acmid = {3291027},
 publisher = {ACM},
 keywords = {counterfactual analysis, experimentation, music recommendation, offline experimentation, online experimentation, personalization, playlist recommendation, recommendation},
 url = {https://doi.org/10.1145/3289600.3291027},
doi = {10.1145/3289600.3291027},
} 


%%%%%%%%-----------------------
@article{Hanley1982,
author = {Hanley, J A and McNeil, B J},
title = {The meaning and use of the area under a receiver operating characteristic (ROC) curve.},
journal = {Radiology},
volume = {143},
number = {1},
pages = {29-36},
year = {1982},
doi = {10.1148/radiology.143.1.7063747},
    note ={PMID: 7063747},
URL = {https://doi.org/10.1148/radiology.143.1.7063747}
}

@article{Hiltz1985,
  title={Structuring computer-mediated communication systems to avoid information overload},
  author={Hiltz, Starr R and Turoff, Murray},
  journal={Communications of the ACM},
  volume={28},
  number={7},
  pages={680--689},
  year={1985},
  publisher={ACM}
}

@article{Goldberg1992,
 author = {Goldberg, David and Nichols, David and Oki, Brian M. and Terry, Douglas},
 title = {Using Collaborative Filtering to Weave an Information Tapestry},
 journal = {Commun. ACM},
 issue_date = {Dec. 1992},
 volume = {35},
 number = {12},
 month = dec,
 year = {1992},
 issn = {0001-0782},
 pages = {61--70},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/138859.138867},
 doi = {10.1145/138859.138867},
 acmid = {138867},
 publisher = {ACM},
 
 keywords = {information filtering, tapestry},
} 

@inproceedings{Resnick1994,
  title={GroupLens: an open architecture for collaborative filtering of netnews},
  author={Resnick, Paul and Iacovou, Neophytos and Suchak, Mitesh and Bergstrom, Peter and Riedl, John},
  booktitle={Proc of. the 1994 ACM Conference on Computer Supported Cooperative Work},
  pages={175--186},
  year={1994},
  organization={ACM}
}

@article{Resnick1997,
  title={Recommender systems},
  author={Resnick, Paul and Varian, Hal R},
  journal={Communications of the ACM},
  volume={40},
  number={3},
  pages={56--58},
  year={1997},
  publisher={ACM}
}

@inproceedings{Oard1998,
  title={Implicit feedback for recommender systems},
  author={Oard, Douglas W and Kim, Jinmook and others},
  booktitle={Proc of. the AAAI workshop on recommender systems},
  volume={83},
  year={1998}
}

@inproceedings{Breese1998,
 author = {Breese, John S. and Heckerman, David and Kadie, Carl},
 title = {Empirical Analysis of Predictive Algorithms for Collaborative Filtering},
 booktitle = {Proc of. the Fourteenth Conference on Uncertainty in Artificial Intelligence},
 series = {UAI'98},
 year = {1998},
 isbn = {1-55860-555-X},
 
 pages = {43--52},
 numpages = {10},
 url = {http://dl.acm.org/citation.cfm?id=2074094.2074100},
 acmid = {2074100},
 publisher = {Morgan Kaufmann Publishers Inc.},
 address = {San Francisco, CA, USA},
} 

@inproceedings{Karypis2001,
 author = {Karypis, George},
 title = {Evaluation of Item-Based Top-N Recommendation Algorithms},
 booktitle = {Proc of. the Tenth International Conference on Information and Knowledge Management},
 series = {CIKM '01},
 year = {2001},
 isbn = {1-58113-436-3},
 
 pages = {247--254},
 numpages = {8},
 url = {http://doi.acm.org/10.1145/502585.502627},
 doi = {10.1145/502585.502627},
 acmid = {502627},
 publisher = {ACM},
 
 keywords = {collaborative filtering, recommender system},
}

@article{Goldberg2001,
 author = {Goldberg, Ken and Roeder, Theresa and Gupta, Dhruv and Perkins, Chris},
 title = {Eigentaste: A Constant Time Collaborative Filtering Algorithm},
 journal = {Inf. Retr.},
 issue_date = {July 2001},
 volume = {4},
 number = {2},
 month = jul,
 year = {2001},
 issn = {1386-4564},
 pages = {133--151},
 numpages = {19},
 url = {https://doi.org/10.1023/A:1011419012209},
 doi = {10.1023/A:1011419012209},
 acmid = {594023},
 publisher = {Kluwer Academic Publishers},
 address = {Hingham, MA, USA},
 keywords = {collaborative filtering, dimensionality reduction, jokes, recommender systems},
}

@inproceedings{Rashid2002,
 author = {Rashid, Al Mamunur and Albert, Istvan and Cosley, Dan and Lam, Shyong K. and McNee, Sean M. and Konstan, Joseph A. and Riedl, John},
 title = {Getting to Know You: Learning New User Preferences in Recommender Systems},
 booktitle = {Proc of. the 7th International Conference on Intelligent User Interfaces},
 series = {IUI '02},
 year = {2002},
 isbn = {1-58113-459-2},
 
 pages = {127--134},
 numpages = {8},
 url = {http://doi.acm.org/10.1145/502716.502737},
 doi = {10.1145/502716.502737},
 acmid = {502737},
 publisher = {ACM},
 
 keywords = {collaborative filtering, entropy, information filtering, recommender systems, startup problem, user modeling},
} 

@inproceedings{Bodon2003,
  title={A fast APRIORI implementation},
  author={Bodon, Ferenc},
  year = {2003},
  series = {FIMI '03},
  booktitle = {Proc of. the 1st IEEE ICDM Workshop on Frequent Itemset Mining Implementations}
}

@article{Herlocker2004,
 author = {Herlocker, J. L. and Konstan, J. A. and Terveen, L. G. and Riedl, J. T.},
 title = {Evaluating Collaborative Filtering Recommender Systems},
 journal = {ACM Transactions on Information Systems},
 issue_date = {January 2004},
 volume = {22},
 number = {1},
 month = jan,
 year = {2004},
 issn = {1046-8188},
 pages = {5--53},
 numpages = {49},
 url = {http://doi.acm.org/10.1145/963770.963772},
 doi = {10.1145/963770.963772},
 acmid = {963772},
 publisher = {ACM},
 
 keywords = {Collaborative filtering, evaluation, metrics, recommender systems},
} 


@article{Chellappa2005,
 author="Chellappa, Ramnath K.
 and Sin, Raymond G.",
 title="Personalization versus Privacy: An Empirical Examination of the Online Consumer's Dilemma",
 journal="Information Technology and Management",
 year="2005",
 month="Apr",
 day="01",
 volume="6",
 number="2",
 pages="181--202",
 issn="1573-7667",
 doi="10.1007/s10799-005-5879-y",
 url="https://doi.org/10.1007/s10799-005-5879-y"
}

@inproceedings{Joachims2005,
 author = {Joachims, T. and Granka, L. and Pan, B. and Hembrooke, H. and Gay, G.},
 title = {Accurately Interpreting Clickthrough Data As Implicit Feedback},
 booktitle = {Proc of. the 28th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval},
 series = {SIGIR '05},
 year = {2005},
 isbn = {1-59593-034-5},
 
 pages = {154--161},
 numpages = {8},
 url = {http://doi.acm.org/10.1145/1076034.1076063},
 doi = {10.1145/1076034.1076063},
 acmid = {1076063},
 publisher = {ACM},
 
 keywords = {WWW search, clickthrough, eyetracking, implicit feedback},
} 

@inproceedings{Ziegler2005,
 author = {Ziegler, Cai-Nicolas and McNee, Sean M. and Konstan, Joseph A. and Lausen, Georg},
 title = {Improving Recommendation Lists Through Topic Diversification},
 booktitle = {Proc of. the 14th International Conference on World Wide Web},
 series = {WWW '05},
 year = {2005},
 isbn = {1-59593-046-9},
 
 pages = {22--32},
 numpages = {11},
 url = {http://doi.acm.org/10.1145/1060745.1060754},
 doi = {10.1145/1060745.1060754},
 acmid = {1060754},
 publisher = {ACM},
 
 keywords = {accuracy, collaborative filtering, diversification, metrics, recommender systems},
} 

@misc{Yahoo2006,
  author = {Yahoo! Webscope},
  title = {Dataset ydata-ymusic-rating-study-vl},
  year = {2006},
  howpublished = {\url{https://webscope.sandbox.yahoo.com/catalog.php?datatype=r&did=3}}
}

@incollection{Pazzani2007,
 author = {Pazzani, Michael J. and Billsus, Daniel},
 chapter = {Content-based Recommendation Systems},
 title = {The Adaptive Web},
 editor = {Brusilovsky, Peter and Kobsa, Alfred and Nejdl, Wolfgang},
 year = {2007},
 isbn = {978-3-540-72078-2},
 pages = {325--341},
 numpages = {17},
 url = {http://dl.acm.org/citation.cfm?id=1768197.1768209},
 acmid = {1768209},
 publisher = {Springer-Verlag},
 address = {Berlin, Heidelberg},
} 

@incollection{Burke2007,
 author = {Burke, Robin},
 chapter = {Hybrid Web Recommender Systems},
 title = {The Adaptive Web},
 editor = {Brusilovsky, Peter and Kobsa, Alfred and Nejdl, Wolfgang},
 year = {2007},
 isbn = {978-3-540-72078-2},
 pages = {377--408},
 numpages = {32},
 url = {http://dl.acm.org/citation.cfm?id=1768197.1768211},
 acmid = {1768211},
 publisher = {Springer-Verlag},
 address = {Berlin, Heidelberg},
}

@inproceedings{NetflixPrize2007,
  title={The netflix prize},
  author={Bennett, James and Lanning, Stan and others},
  year={2007}
}

@article{Rashid2008,
 author = {Rashid, Al Mamunur and Karypis, George and Riedl, John},
 title = {Learning Preferences of New Users in Recommender Systems: An Information Theoretic Approach},
 journal = {SIGKDD Explor. Newsl.},
 issue_date = {December 2008},
 volume = {10},
 number = {2},
 month = dec,
 year = {2008},
 issn = {1931-0145},
 pages = {90--100},
 numpages = {11},
 url = {http://doi.acm.org/10.1145/1540276.1540302},
 doi = {10.1145/1540276.1540302},
 acmid = {1540302},
 publisher = {ACM},
 
}

@book{Bailey2008,
  title={Design of comparative experiments},
  author={Bailey, Rosemary A},
  volume={25},
  year={2008},
  publisher={Cambridge University Press}
}

@misc{Zafarani2009,
author = "Reza Zafarani and Huan Liu",
year = "2009",
title = "Social Computing Data Repository at {ASU}",
url = "http://socialcomputing.asu.edu",
institution = "Arizona State University, School of Computing, Informatics and Decision Systems Engineering"
}

@inproceedings{Cremonesi2010,
 author = {Cremonesi, Paolo and Koren, Yehuda and Turrin, Roberto},
 title = {Performance of Recommender Algorithms on Top-n Recommendation Tasks},
 booktitle = {Proc of. the Fourth ACM Conference on Recommender Systems},
 series = {RecSys '10},
 year = {2010},
 isbn = {978-1-60558-906-0},
 
 pages = {39--46},
 numpages = {8},
 url = {http://doi.acm.org/10.1145/1864708.1864721},
 doi = {10.1145/1864708.1864721},
 acmid = {1864721},
 publisher = {ACM},
 
 keywords = {evaluation, precision, recall, top-n recommendations},
} 

@inproceedings{Lathia2010,
 author = {Lathia, Neal and Hailes, Stephen and Capra, Licia and Amatriain, Xavier},
 title = {Temporal Diversity in Recommender Systems},
 booktitle = {Proc of. the 33rd International ACM SIGIR Conference on Research and Development in Information Retrieval},
 series = {SIGIR '10},
 year = {2010},
 isbn = {978-1-4503-0153-4},
 
 pages = {210--217},
 numpages = {8},
 url = {http://doi.acm.org/10.1145/1835449.1835486},
 doi = {10.1145/1835449.1835486},
 acmid = {1835486},
 publisher = {ACM},
 
 keywords = {evaluation, recommender systems},
} 

@misc{LastFM2010,
  author = {Last.FM},
  title = {Dataset Artist Plays - 360K users},
  year = {2010},
  howpublished = {\url{https://www.dtic.upf.edu/~ocelma/MusicRecommendationDataset/lastfm-360K.html}}
}

@inproceedings{Ge2010,
 author = {Ge, Mouzhi and Delgado-Battenfeld, Carla and Jannach, Dietmar},
 title = {Beyond Accuracy: Evaluating Recommender Systems by Coverage and Serendipity},
 booktitle = {Proc of. the Fourth ACM Conference on Recommender Systems},
 series = {RecSys '10},
 year = {2010},
 isbn = {978-1-60558-906-0},
 
 pages = {257--260},
 numpages = {4},
 url = {http://doi.acm.org/10.1145/1864708.1864761},
 doi = {10.1145/1864708.1864761},
 acmid = {1864761},
 publisher = {ACM},
 
 keywords = {coverage, evaluation metric, recommender system, serendipity},
} 

@inproceedings{Steck2010,
 author = {Steck, H.},
 title = {Training and Testing of Recommender Systems on Data Missing Not at Random},
 booktitle = {Proc. of the 16th ACM SIGKDD International Conference on Knowledge Discovery \& Data Mining},
 series = {KDD '10},
 year = {2010},
 isbn = {978-1-4503-0055-1},
 
 pages = {713--722},
 numpages = {10},
 acmid = {1835895},
 publisher = {ACM},
 keywords = {recommender systems},
} 

@inproceedings{Wang2010,
 author = {Wang, Hongning and Lu, Yue and Zhai, Chengxiang},
 title = {Latent Aspect Rating Analysis on Review Text Data: A Rating Regression Approach},
 booktitle = {Proc of. the 16th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
 series = {KDD '10},
 year = {2010},
 isbn = {978-1-4503-0055-1},
 
 pages = {783--792},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/1835804.1835903},
 doi = {10.1145/1835804.1835903},
 acmid = {1835903},
 publisher = {ACM},
 
 keywords = {algorithms, experimentation},
} 


@article{Pathak2010,
 author = {Pathak, Bhavik and Garfinkel, Robert and Gopal, Ram and Venkatesan, Rajkumar and Yin, Fang},
 title = {Empirical Analysis of the Impact of Recommender Systems on Sales},
 journal = {J. Manage. Inf. Syst.},
 issue_date = {Number 2 / Fall 2010},
 volume = {27},
 number = {2},
 month = oct,
 year = {2010},
 issn = {0742-1222},
 pages = {159--188},
 numpages = {30},
 url = {http://dx.doi.org/10.2753/MIS0742-1222270205},
 doi = {10.2753/MIS0742-1222270205},
 acmid = {2069586},
 publisher = {M. E. Sharpe, Inc.},
 address = {Armonk, NY, USA},
 keywords = {Collaborative Filtering, E-Tail, Electronic Commerce, Experience Goods, Recommender Systems},
} 

@inproceedings{Steck2011,
 author = {Steck, H.},
 title = {Item Popularity and Recommendation Accuracy},
 booktitle = {Proc. of the 5th ACM Conference on Recommender Systems},
 series = {RecSys '11},
 year = {2011},
 isbn = {978-1-4503-0683-6},
 
 pages = {125--132},
 numpages = {8},
 acmid = {2043957},
 publisher = {ACM},
 keywords = {recommender systems},
} 

@inproceedings{HetRec2011,
  author = {Cantador, Iv\'{a}n and Brusilovsky, Peter and Kuflik, Tsvi},
  title = {2nd Workshop on Information Heterogeneity and Fusion in Recommender Systems (HetRec 2011)},
  booktitle = {Proc of. the 5th ACM conference on Recommender systems},
  series = {RecSys 2011},
  year = {2011},
  
  publisher = {ACM},
  
  keywords = {information heterogeneity, information integration, recommender systems},
}

@inproceedings{Ning2011,
 author = {Ning, X. and Karypis, G.},
 title = {SLIM: Sparse Linear Methods for Top-N Recommender Systems},
 booktitle = {Proc. of the 2011 IEEE 11th International Conference on Data Mining},
 series = {ICDM '11},
 year = {2011},
 isbn = {978-0-7695-4408-3},
 pages = {497--506},
 numpages = {10},
 acmid = {2118303},
 publisher = {IEEE Computer Society},
 keywords = {Top-N Recommender Systems, Sparse Linear Methods, l1-norm Regularization},
} 

@inproceedings{McAuley2012,
 author = {McAuley, Julian and Leskovec, Jure and Jurafsky, Dan},
 title = {Learning Attitudes and Attributes from Multi-aspect Reviews},
 booktitle = {Proc of. the 2012 IEEE 12th International Conference on Data Mining},
 series = {ICDM '12},
 year = {2012},
 isbn = {978-0-7695-4905-7},
 pages = {1020--1025},
 numpages = {6},
 url = {http://dx.doi.org/10.1109/ICDM.2012.110},
 doi = {10.1109/ICDM.2012.110},
 acmid = {2472547},
 publisher = {IEEE Computer Society},
 address = {Washington, DC, USA},
 keywords = {machine learning, segmentation, summarization, sentiment analysis},
} 

@article{Pommeranz2012,
 author="Pommeranz, Alina
 and Broekens, Joost
 and Wiggers, Pascal
 and Brinkman, Willem-Paul
 and Jonker, Catholijn M.",
 title="Designing interfaces for explicit preference elicitation: a user-centered investigation of preference representation and elicitation process",
 journal="User Modeling and User-Adapted Interaction",
 year="2012",
 month="Oct",
 day="01",
 volume="22",
 number="4",
 pages="357--397",
 issn="1573-1391",
 doi="10.1007/s11257-011-9116-6",
 url="https://doi.org/10.1007/s11257-011-9116-6"
}

@article{Knijnenburg2012,
 author = {Knijnenburg, Bart P. and Willemsen, Martijn C. and Gantner, Zeno and Soncu, Hakan and Newell, Chris},
 title = {Explaining the User Experience of Recommender Systems},
 journal = {User Modeling and User-Adapted Interaction},
 issue_date = {October   2012},
 volume = {22},
 number = {4-5},
 month = oct,
 year = {2012},
 issn = {0924-1868},
 pages = {441--504},
 numpages = {64},
 url = {http://dx.doi.org/10.1007/s11257-011-9118-4},
 doi = {10.1007/s11257-011-9118-4},
 acmid = {2339919},
 publisher = {Kluwer Academic Publishers},
 address = {Hingham, MA, USA},
 keywords = {Decision support systems, Decision-making, Human-computer interaction, Preference elicitation, Privacy, Recommender systems, User experience, User testing, User-centric evaluation},
}

@article{Chapelle2012,
 author = {Chapelle, Olivier and Joachims, Thorsten and Radlinski, Filip and Yue, Yisong},
 title = {Large-scale Validation and Analysis of Interleaved Search Evaluation},
 journal = {ACM Trans. Inf. Syst.},
 issue_date = {February 2012},
 volume = {30},
 number = {1},
 month = mar,
 year = {2012},
 issn = {1046-8188},
 pages = {6:1--6:41},
 articleno = {6},
 numpages = {41},
 url = {http://doi.acm.org/10.1145/2094072.2094078},
 doi = {10.1145/2094072.2094078},
 acmid = {2094078},
 publisher = {ACM},
 
 keywords = {Interleaving, clicks, judgments, online evaluation, search engine, sensitivity},
}

@inproceedings{Oord2013,
 author = {Oord, A\"{a}ron van den and Dieleman, Sander and Schrauwen, Benjamin},
 title = {Deep Content-based Music Recommendation},
 booktitle = {Proc of. the 26th International Conference on Neural Information Processing Systems - Volume 2},
 series = {NIPS'13},
 year = {2013},
 
 pages = {2643--2651},
 numpages = {9},
 url = {http://dl.acm.org/citation.cfm?id=2999792.2999907},
 acmid = {2999907},
 publisher = {Curran Associates Inc.},
 address = {USA},
} 

@inproceedings{Dooms2013,
  title={Movietweetings: a movie rating dataset collected from twitter},
  author={Dooms, Simon and De Pessemier, Toon and Martens, Luc},
  booktitle={Proc of. the Workshop on Crowdsourcing and Human Computation for Recommender Systems (CrowdRec)},
  year={2013}
}

@inproceedings{Zhong2013,
  title={Sharing the Loves: Understanding the How and Why of Online Content Curation.},
  author={Zhong, Changtao and Shah, Sunil and Sundaravadivelan, Karthik and Sastry, Nishanth},
  booktitle={Proc of. the Seventh International AAAI Conference on Weblogs and Social Media (ICWSM)},
  year={2013}
}

@inproceedings{Guo2013,
  author = {Guo, G. and Zhang, J. and Yorke-Smith, N.},
  title = {A Novel Bayesian Similarity Measure for Recommender Systems},
  booktitle = {Proc of. the 23rd International Joint Conference on Artificial Intelligence (IJCAI)},
  year = {2013},
  pages = {2619-2625}
}

@inproceedings{Liu2013,
 author = {Liu, Xin and Liu, Yong and Aberer, Karl and Miao, Chunyan},
 title = {Personalized Point-of-interest Recommendation by Mining Users' Preference Transition},
 booktitle = {Proc of. the 22Nd ACM International Conference on Information \& Knowledge Management},
 series = {CIKM '13},
 year = {2013},
 isbn = {978-1-4503-2263-8},
 
 pages = {733--738},
 numpages = {6},
 acmid = {2505639},
 publisher = {ACM},
 keywords = {location-based social networks, point-of-interest, recommendation, user preference},
} 

@inproceedings{Kille2013,
 author = {Kille, B. and Hopfgartner, F. and Brodt, T. and Heintz, T.},
 title = {The Plista Dataset},
 booktitle = {Proc of. the 2013 International News Recommender Systems Workshop and Challenge},
 series = {NRS '13},
 year = {2013},
 isbn = {978-1-4503-2302-4},
 
 pages = {16--23},
 numpages = {8},
 acmid = {2516643},
 publisher = {ACM},
 keywords = {dataset, news, recommender systems},
} 

@misc{Avazu2014,
  author = {Avazu},
  title = {Click-Through Rate Prediction dataset},
  year = {2014},
  howpublished = {\url{https://www.kaggle.com/c/avazu-ctr-prediction}}
}

@misc{Criteo2014,
  author = {Criteo},
  title = {Display Advertising Challenge dataset},
  year = {2014},
  howpublished = {\url{https://www.kaggle.com/c/criteo-display-ad-challenge}}
}

@inproceedings{Guo2014,
  author = {Guo, G. and Zhang, J. and Thalmann, D. and Yorke-Smith, N.},
  title = {ETAF: An Extended Trust Antecedents Framework for Trust Prediction},
  booktitle = {Proc of. the 2014 International Conference on Advances in Social Networks Analysis and Mining (ASONAM)},
  pages = {540-547},
  year = {2014}
} 

@inproceedings{Lee2014,
 author = {Lee, P. and Lakshmanan, L. and Tiwari, M. and Shah, S.},
 title = {Modeling Impression Discounting in Large-scale Recommender Systems},
 booktitle = {Proc. of the 20th ACM SIGKDD International Conference on Knowledge Discovery \& Data Mining},
 series = {KDD '14},
 year = {2014},
 isbn = {978-1-4503-2956-9},
 
 pages = {1837--1846},
 numpages = {10},
 acmid = {2623356},
 publisher = {ACM},
 keywords = {impression discounting, recommender system},
} 

@inproceedings{Zhao2015,
 author = {Zhao, Tong and McAuley, Julian and King, Irwin},
 title = {Improving Latent Factor Models via Personalized Feature Projection for One Class Recommendation},
 booktitle = {Proc of. the 24th ACM International on Conference on Information and Knowledge Management},
 series = {CIKM '15},
 year = {2015},
 isbn = {978-1-4503-3794-6},
 
 pages = {821--830},
 numpages = {10},
 acmid = {2806511},
 publisher = {ACM},
 
 keywords = {collaborative filtering, one-class recommendation, personalized feature projection},
} 

@article{Ghoshal2015,
author = {Abhijeet Ghoshal and Subodha Kumar and Vijay Mookerjee},
title = {Impact of Recommender System on Competition Between Personalizing and Non-Personalizing Firms},
journal = {Journal of Management Information Systems},
volume = {31},
number = {4},
pages = {243-277},
year  = {2015},
publisher = {Routledge},
doi = {10.1080/07421222.2014.1001276},
URL = { 
        https://doi.org/10.1080/07421222.2014.1001276
    
},
}

@article{Vinagre2015,
  author    = {J. Vinagre and
               A. Jorge and
               J. Gama},
  title     = {Evaluation of recommender systems in streaming environments},
  journal   = {CoRR},
  volume    = {abs/1504.08175},
  year      = {2015},
  url       = {http://arxiv.org/abs/1504.08175},
  archivePrefix = {arXiv},
  eprint    = {1504.08175},
}

@inproceedings{McAuley2015,
 author = {McAuley, Julian and Targett, Christopher and Shi, Qinfeng and van den Hengel, Anton},
 title = {Image-Based Recommendations on Styles and Substitutes},
 booktitle = {Proc of. the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval},
 series = {SIGIR '15},
 year = {2015},
 isbn = {978-1-4503-3621-5},
 
 pages = {43--52},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/2766462.2767755},
 doi = {10.1145/2766462.2767755},
 acmid = {2767755},
 publisher = {ACM},
 
 keywords = {metric learning, recommender systems, visual features},
}

@inproceedings{Ben-Shimon2015,
 author = {Ben-Shimon, David and Tsikinovsky, Alexander and Friedmann, Michael and Shapira, Bracha and Rokach, Lior and Hoerle, Johannes},
 title = {RecSys Challenge 2015 and the YOOCHOOSE Dataset},
 booktitle = {Proc of. the 9th ACM Conference on Recommender Systems},
 series = {RecSys '15},
 year = {2015},
 isbn = {978-1-4503-3692-5},
 
 pages = {357--358},
 numpages = {2},
 url = {http://doi.acm.org/10.1145/2792838.2798723},
 doi = {10.1145/2792838.2798723},
 acmid = {2798723},
 publisher = {ACM},
 
 keywords = {e-commerce, recommender systems, recsys challenge 2015, yoochoose},
} 

@inproceedings{Wang2015,
 author = {Wang, Hao and Wang, Naiyan and Yeung, Dit-Yan},
 title = {Collaborative Deep Learning for Recommender Systems},
 booktitle = {Proc of. the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
 series = {KDD '15},
 year = {2015},
 isbn = {978-1-4503-3664-2},
 
 pages = {1235--1244},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/2783258.2783273},
 doi = {10.1145/2783258.2783273},
 acmid = {2783273},
 publisher = {ACM},
 
 keywords = {deep learning, recommender systems, text mining, topic model},
} 

@inproceedings{Swaminathan2015,
 author = {Swaminathan, A. and Joachims, T.},
 title = {Counterfactual Risk Minimization: Learning from Logged Bandit Feedback},
 booktitle = {Proc. of the 32nd International Conference on International Conference on Machine Learning},
 series = {ICML'15},
 year = {2015},
 
 pages = {814--823},
 numpages = {10},
 publisher = {JMLR.org},
} 

@inproceedings{Turrin2015,
  title={30Music Listening and Playlists Dataset.},
  author={Turrin, Roberto and Quadrana, Massimo and Condorelli, Andrea and Pagano, Roberto and Cremonesi, Paolo},
  year = {2015},
  url = {http://recsys.deib.polimi.it/?page_id=54}
}

@inproceedings{Christakopoulou2016,
 author = {Christakopoulou, E. and Karypis, G.},
 title = {Local Item-Item Models For Top-N Recommendation},
 booktitle = {Proc. of the 10th ACM Conference on Recommender Systems},
 series = {RecSys '16},
 year = {2016},
 isbn = {978-1-4503-4035-9},
 
 pages = {67--74},
 numpages = {8},
 acmid = {2959185},
 publisher = {ACM},
 keywords = {collaborative filtering, local models, slim, top-n recommendation},
} 

@inproceedings{Subbian2016,
 author = {Subbian, Karthik and Aggarwal, Charu and Hegde, Kshiteesh},
 title = {Recommendations For Streaming Data},
 booktitle = {Proc of. the 25th ACM International on Conference on Information and Knowledge Management},
 series = {CIKM '16},
 year = {2016},
 isbn = {978-1-4503-4073-1},
 
 pages = {2185--2190},
 numpages = {6},
 url = {http://doi.acm.org/10.1145/2983323.2983663},
 doi = {10.1145/2983323.2983663},
 acmid = {2983663},
 publisher = {ACM},
 
 keywords = {data streams, neighborhood model, recommender systems, streaming recommendations},
}

@inproceedings{Xie2016,
 author = {Xie, Huizhi and Aurisset, Juliette},
 title = {Improving the Sensitivity of Online Controlled Experiments: Case Studies at Netflix},
 booktitle = {Proc of. the 22Nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
 series = {KDD '16},
 year = {2016},
 isbn = {978-1-4503-4232-2},
 
 pages = {645--654},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/2939672.2939733},
 doi = {10.1145/2939672.2939733},
 acmid = {2939733},
 publisher = {ACM},
 
 keywords = {a/b testing, controlled experiment, randomized experiment, sensitivity, variance reduction},
}

@inproceedings{He2016,
 author = {He, Ruining and Fang, Chen and Wang, Zhaowen and McAuley, Julian},
 title = {Vista: A Visually, Socially, and Temporally-aware Model for Artistic Recommendation},
 booktitle = {Proc of. the 10th ACM Conference on Recommender Systems},
 series = {RecSys '16},
 year = {2016},
 isbn = {978-1-4503-4035-9},
 
 pages = {309--316},
 numpages = {8},
 url = {http://doi.acm.org/10.1145/2959100.2959152},
 doi = {10.1145/2959100.2959152},
 acmid = {2959152},
 publisher = {ACM},
 
 keywords = {Markov chains, artistic preferences, recommender systems},
} 

@Inbook{Aggarwal2016,
author="Aggarwal, Charu C.",
title="Evaluating Recommender Systems",
bookTitle="Recommender Systems: The Textbook",
year="2016",
publisher="Springer International Publishing",
pages="225--254",
}

@inproceedings{Brost2016,
 author = {Brost, B. and Cox, I. J. and Seldin, Y. and Lioma, C.},
 title = {An Improved Multileaving Algorithm for Online Ranker Evaluation},
 booktitle = {Proc. of the 39th International ACM SIGIR Conference on Research and Development in Information Retrieval},
 series = {SIGIR '16},
 year = {2016},
 isbn = {978-1-4503-4069-4},
 
 pages = {745--748},
 numpages = {4},
 publisher = {ACM},
 keywords = {multileaving, online ranker evaluation},
} 

@inproceedings{Li2017,
 author = {Li, X. and She, J.},
 title = {Collaborative Variational Autoencoder for Recommender Systems},
 booktitle = {Proc. of the 23rd ACM SIGKDD International Conference on Knowledge Discovery \& Data Mining},
 series = {KDD '17},
 year = {2017},
 isbn = {978-1-4503-4887-4},
 
 pages = {305--314},
 numpages = {10},
 acmid = {3098077},
 publisher = {ACM},
 keywords = {autoencoder, bayesian, deep learning, generative models, recommender systems, variational inference},
} 

@inproceedings{He2017,
 author = {He, R. and Kang, W. and McAuley, J.},
 title = {Translation-based Recommendation},
 booktitle = {Proc. of the 11th ACM Conference on Recommender Systems},
 series = {RecSys '17},
 year = {2017},
 isbn = {978-1-4503-4652-8},
 
 pages = {161--169},
 numpages = {9},
 acmid = {3109882},
 publisher = {ACM},
 keywords = {recommender systems, relation, sequential behavior, translation},
} 

@inproceedings{Ning2017,
 author = {Ning, Y. and Shi, Y. and Hong, L. and Rangwala, H. and Ramakrishnan, N.},
 title = {A Gradient-based Adaptive Learning Framework for Efficient Personal Recommendation},
 booktitle = {Proc. of the 11th ACM Conference on Recommender Systems},
 series = {RecSys '17},
 year = {2017},
 isbn = {978-1-4503-4652-8},
 
 pages = {23--31},
 numpages = {9},
 acmid = {3109909},
 publisher = {ACM},
 keywords = {content recommendation, gradient adaptation, personalization},
} 

@inproceedings{Otunba2017,
 author = {Otunba, R. and Rufai, R. and Lin, J.},
 title = {MPR: Multi-Objective Pairwise Ranking},
 booktitle = {Proc. of the 11th ACM Conference on Recommender Systems},
 series = {RecSys '17},
 year = {2017},
 isbn = {978-1-4503-4652-8},
 
 pages = {170--178},
 numpages = {9},
 acmid = {3109903},
 publisher = {ACM},
 keywords = {audience retrieval, collaborative filtering, recommendations},
}

@inproceedings{Abdollahpouri2017,
 author = {Abdollahpouri, Himan and Burke, Robin and Mobasher, Bamshad},
 title = {Controlling Popularity Bias in Learning-to-Rank Recommendation},
 booktitle = {Proc of. the Eleventh ACM Conference on Recommender Systems},
 series = {RecSys '17},
 year = {2017},
 isbn = {978-1-4503-4652-8},
 
 pages = {42--46},
 numpages = {5},
 url = {http://doi.acm.org/10.1145/3109859.3109912},
 doi = {10.1145/3109859.3109912},
 acmid = {3109912},
 publisher = {ACM},
 
 keywords = {coverage, learning to rank, long-tail, recommendation evaluation, recommender systems},
} 

@inbook{Onwuegbuzie2017,
author = {Onwuegbuzie, Anthony J. and Gerber, Hannah R. and Schamroth Abrams, Sandra},
publisher = {American Cancer Society},
isbn = {9781118901731},
title = {Mixed Methods Research},
booktitle = {The International Encyclopedia of Communication Research Methods},
chapter = {},
pages = {1-33},
doi = {10.1002/9781118901731.iecrm0156},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/9781118901731.iecrm0156},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/9781118901731.iecrm0156},
year = {2017}
}

@inproceedings{Pathak2017,
 author = {Pathak, Apurva and Gupta, Kshitiz and McAuley, Julian},
 title = {Generating and Personalizing Bundle Recommendations on Steam},
 booktitle = {Proc of. the 40th International ACM SIGIR Conference on Research and Development in Information Retrieval},
 series = {SIGIR '17},
 year = {2017},
 isbn = {978-1-4503-5022-8},
 
 pages = {1073--1076},
 numpages = {4},
 url = {http://doi.acm.org/10.1145/3077136.3080724},
 doi = {10.1145/3077136.3080724},
 acmid = {3080724},
 publisher = {ACM},
 
 keywords = {bpr, collaborative filtering, matrix factorization, steam bundle},
}

@misc{Yelp2017,
  author = {Yelp},
  title = {Business rating dataset},
  year = {2017},
  howpublished = {\url{https://www.kaggle.com/yelp-dataset/yelp-dataset}}
}

@misc{Reddit2017,
  author = {Reddit},
  title = {Crawl of comments and submissions},
  year = {2017},
  month = mar,
  howpublished = {\url{https://redd.it/6607j2}}
}

@misc{Outbrain2017,
  author = {Outbrain},
  title = {Click Prediction dataset},
  year = {2017},
  howpublished = {\url{https://www.kaggle.com/c/outbrain-click-prediction}}
}

@article{Wang2018,
 author = {Wang, Yue and Yin, Dawei and Jie, Luo and Wang, Pengyuan and Yamada, Makoto and Chang, Yi and Mei, Qiaozhu},
 title = {Optimizing Whole-Page Presentation for Web Search},
 journal = {ACM Trans. Web},
 issue_date = {July 2018},
 volume = {12},
 number = {3},
 month = jul,
 year = {2018},
 issn = {1559-1131},
 pages = {19:1--19:25},
 articleno = {19},
 numpages = {25},
 url = {http://doi.acm.org/10.1145/3204461},
 doi = {10.1145/3204461},
 acmid = {3204461},
 publisher = {ACM},
 
 keywords = {Whole-page optimization, user satisfaction},
} 

@inproceedings{Sepliarskaia2018,
 author = {Sepliarskaia, Anna and Kiseleva, Julia and Radlinski, Filip and de Rijke, Maarten},
 title = {Preference Elicitation As an Optimization Problem},
 booktitle = {Proc of. the 12th ACM Conference on Recommender Systems},
 series = {RecSys '18},
 year = {2018},
 isbn = {978-1-4503-5901-6},
 
 pages = {172--180},
 numpages = {9},
 url = {http://doi.acm.org/10.1145/3240323.3240352},
 doi = {10.1145/3240323.3240352},
 acmid = {3240352},
 publisher = {ACM},
 
 keywords = {cold start problem, mixed initiative search and recommendation, preference elicitation},
} 

@inproceedings{Bonner2018,
 author = {Bonner, S. and Vasile, F.},
 title = {Causal Embeddings for Recommendation},
 booktitle = {Proc. of the 12th ACM Conference on Recommender Systems},
 series = {RecSys '18},
 year = {2018},
 isbn = {978-1-4503-5901-6},
 
 pages = {104--112},
 numpages = {9},
 acmid = {3240360},
 publisher = {ACM},
 keywords = {causality, counterfactual inference, embeddings, neural networks, recommender systems},
} 

@inproceedings{JYang2018,
 author = {Yang, J. and Chen, C. and Wang, C. and Tsai, M.},
 title = {HOP-rec: High-order Proximity for Implicit Recommendation},
 booktitle = {Proc. of the 12th ACM Conference on Recommender Systems},
 series = {RecSys '18},
 year = {2018},
 isbn = {978-1-4503-5901-6},
 
 pages = {140--144},
 numpages = {5},
 acmid = {3240381},
 publisher = {ACM},
 keywords = {bipartite graph, collaborative filtering, implicit feedback, matrix factorization, random walks, top-N recommendation},
} 

@inproceedings{Zhang2018,
 author = {Zhang, Y. and Lu, H. and Niu, W. and Caverlee, J.},
 title = {Quality-aware Neural Complementary Item Recommendation},
 booktitle = {Proc of. the 12th ACM Conference on Recommender Systems},
 series = {RecSys '18},
 year = {2018},
 isbn = {978-1-4503-5901-6},
 
 pages = {77--85},
 numpages = {9},
 acmid = {3240368},
 publisher = {ACM},
 keywords = {complementary item, quality-aware, recommendation},
} 

@inproceedings{Christakopoulou2018,
 author = {Christakopoulou, E. and Karypis, G.},
 title = {Local Latent Space Models for Top-N Recommendation},
 booktitle = {Proc. of the 24th ACM SIGKDD International Conference on Knowledge Discovery \& Data Mining},
 series = {KDD '18},
 year = {2018},
 isbn = {978-1-4503-5552-0},
 
 pages = {1235--1243},
 numpages = {9},
 acmid = {3220112},
 publisher = {ACM},
 keywords = {clustering, collaborative filtering, latent space models, local models},
} 

@inproceedings{Chaney2018,
 author = {Chaney, A. and Stewart, B. and Engelhardt, B.},
 title = {How Algorithmic Confounding in Recommendation Systems Increases Homogeneity and Decreases Utility},
 booktitle = {Proc. of the 12th ACM Conference on Recommender Systems},
 series = {RecSys '18},
 year = {2018},
 isbn = {978-1-4503-5901-6},
 
 pages = {224--232},
 numpages = {9},
 acmid = {3240370},
 publisher = {ACM},
 keywords = {algorithmic confounding, recommendation systems},
} 

@inproceedings{Rohde2018,
   author = {{Rohde}, D. and {Bonner}, S. and {Dunlop}, T. and {Vasile}, F. and 
	{Karatzoglou}, A.},
    title = "{RecoGym: A Reinforcement Learning Environment for the problem of Product Recommendation in Online Advertising}",
 booktitle = {Proc. of the ACM RecSys Workshop on Offline Evaluation of Recommender Systems},
 series = {REVEAL '18},
 year={2018}
}

@inproceedings{Wan2018,
 author = {Wan, M. and McAuley, J.},
 title = {Item Recommendation on Monotonic Behavior Chains},
 booktitle = {Proc. of the 12th ACM Conference on Recommender Systems},
 series = {RecSys '18},
 year = {2018},
 isbn = {978-1-4503-5901-6},
 
 pages = {86--94},
 numpages = {9},
 acmid = {3240369},
 publisher = {ACM},
} 

@inproceedings{Misra2018,
 author = {Misra, R. and Wan, M. and McAuley, J.},
 title = {Decomposing Fit Semantics for Product Size Recommendation in Metric Spaces},
 booktitle = {Proc. of the 12th ACM Conference on Recommender Systems},
 series = {RecSys '18},
 year = {2018},
 isbn = {978-1-4503-5901-6},
 
 pages = {422--426},
 numpages = {5},
 acmid = {3240398},
 publisher = {ACM},
} 

@inproceedings{Zhao2018,
 author = {Zhao, Q. and Willemsen, M. C. and Adomavicius, G. and Harper, F. M. and Konstan, J. A.},
 title = {Interpreting User Inaction in Recommender Systems},
 booktitle = {Proc. of the 12th ACM Conference on Recommender Systems},
 series = {RecSys '18},
 year = {2018},
 isbn = {978-1-4503-5901-6},
 
 pages = {40--48},
 numpages = {9},
 acmid = {3240366},
 publisher = {ACM},
 keywords = {decision field theory, decision making, user inaction},
} 

@inproceedings{Sinha2016,
 author = {Sinha, A. and Gleich, D. and Ramani, K.},
 title = {Deconvolving Feedback Loops in Recommender Systems},
 booktitle = {Proc. of the 30th International Conference on Neural Information Processing Systems},
 series = {NIPS'16},
 year = {2016},
 isbn = {978-1-5108-3881-9},
 
 pages = {3251--3259},
 numpages = {9},
 acmid = {3157461},
 publisher = {Curran Associates Inc.},
} 

@inproceedings{Garcia-Gathright2018,
 author = {Garcia-Gathright, Jean and Hosey, Christine and Thomas, Brian St. and Carterette, Ben and Diaz, Fernando},
 title = {Mixed Methods for Evaluating User Satisfaction},
 booktitle = {Proc of. the 12th ACM Conference on Recommender Systems},
 series = {RecSys '18},
 year = {2018},
 isbn = {978-1-4503-5901-6},
 
 pages = {541--542},
 numpages = {2},
 publisher = {ACM},
 
 keywords = {evaluation, mixed methods, recommender systems, user behavior},
} 


@inproceedings{Jagerman2019,
 author = {Jagerman, R. and Markov, I. and de Rijke, M.},
 title = {When People Change Their Mind: Off-Policy Evaluation in Non-stationary Recommendation Environments},
 booktitle = {Proc. of the 12th ACM International Conference on Web Search and Data Mining},
 series = {WSDM '19},
 year = {2019},
 isbn = {978-1-4503-5940-5},
 
 pages = {447--455},
 numpages = {9},
 acmid = {3290958},
 publisher = {ACM},
 keywords = {non-stationary rewards, off-policy evaluation},
} 

@article{Bottou2013,
  title={Counterfactual reasoning and learning systems: The example of computational advertising},
  author={Bottou, L. and Peters, J. and Qui{\~n}onero-Candela, J. and Charles, D. and Chickering, D. and Portugaly, E. and Ray, D. and Simard, P. and Snelson, E.},
  journal={The Journal of Machine Learning Research},
  volume={14},
  number={1},
  pages={3207--3260},
  year={2013},
  publisher={JMLR. org}
}

@article{Lefortier2016,
  title={Large-scale validation of counterfactual learning methods: A test-bed},
  author={Lefortier, D. and Swaminathan, A. and Gu, X. and Joachims, T. and de Rijke, M.},
  journal={arXiv preprint arXiv:1612.00367},
  year={2016}
}

@inproceedings{Covington2016,
author = {Covington, P. and Adams, J. and Sargin, E.},
title = {Deep Neural Networks for YouTube Recommendations},
year = {2016},
isbn = {9781450340359},
publisher = {ACM},
url = {https://doi.org/10.1145/2959100.2959190},
doi = {10.1145/2959100.2959190},
abstract = {YouTube represents one of the largest scale and most sophisticated industrial recommendation systems in existence. In this paper, we describe the system at a high level and focus on the dramatic performance improvements brought by deep learning. The paper is split according to the classic two-stage information retrieval dichotomy: first, we detail a deep candidate generation model and then describe a separate deep ranking model. We also provide practical lessons and insights derived from designing, iterating and maintaining a massive recommendation system with enormous user-facing impact.},
booktitle = {Proc. of the 10th ACM Conference on Recommender Systems},
pages = {191198},
numpages = {8},
keywords = {scalability, recommender system, deep learning},
series = {RecSys '16}
}

@inproceedings{Chen2019,
 author = {Chen, M. and Beutel, A. and Covington, P. and Jain, S. and Belletti, F. and Chi, E. H.},
 title = {Top-K Off-Policy Correction for a REINFORCE Recommender System},
 booktitle = {Proc. of the 12th ACM International Conference on Web Search and Data Mining},
 series = {WSDM '19},
 year = {2019},
 isbn = {978-1-4503-5940-5},
 pages = {456--464},
 numpages = {9},
 acmid = {3290999},
 publisher = {ACM},
 keywords = {counterfactual learning, exploration, off-policy correction, reinforce, set recommendation, top-k recommendation},
url = {https://doi.org/10.1145/3289600.3290999},
doi = {10.1145/3289600.3290999}
}

@inproceedings{Jugovac2018,
 author = {Jugovac, M. and Jannach, D. and Karimi, M.},
 title = {Streamingrec: A Framework for Benchmarking Stream-based News Recommenders},
 booktitle = {Proc. of the 12th ACM Conference on Recommender Systems},
 series = {RecSys '18},
 year = {2018},
 isbn = {978-1-4503-5901-6},
 
 pages = {269--273},
 numpages = {5},
 acmid = {3240384},
 publisher = {ACM},
 keywords = {benchmarking, evaluation, news recommendation},
} 

@inproceedings{Li2011,
 author = {Li, L. and Chu, W. and Langford, J. and Wang, X.},
 title = {Unbiased Offline Evaluation of Contextual-bandit-based News Article Recommendation Algorithms},
 booktitle = {Proc. of the 4th ACM International Conference on Web Search and Data Mining},
 series = {WSDM '11},
 year = {2011},
 isbn = {978-1-4503-0493-1},
 pages = {297--306},
 numpages = {10},
 acmid = {1935878},
 publisher = {ACM},
 keywords = {benchmark dataset, contextual bandit, multi-armed bandit, offline evaluation, recommendation},
} 

@inproceedings{Basaran2017,
  title={Redundancies in Data and their Effect on the Evaluation of Recommendation Systems: A Case Study on the Amazon Reviews Datasets},
  author={Basaran, D. and Ntoutsi, E. and Zimek, A.},
  booktitle={Proc. of the 2017 SIAM International Conference on Data Mining},
  series = {SIAM DM '17},
  pages={390--398}, 
  year={2017},
  organization={SIAM}
}

@inproceedings{Zhao_2_2018,
 author = {Zhao, Q. and Chen, J. and Chen, M. and Jain, S. and Beutel, A. and Belletti, F. and Chi, E. H.},
 title = {Categorical-attributes-based Item Classification for Recommender Systems},
 booktitle = {Proc. of the 12th ACM Conference on Recommender Systems},
 series = {RecSys '18},
 year = {2018},
 isbn = {978-1-4503-5901-6},
 
 pages = {320--328},
 numpages = {9},
 acmid = {3240367},
 publisher = {ACM},
 keywords = {hierarchical classification, hierarchical softmax, multi-task learning, recommender systems},
} 

@inproceedings{Paudel2017,
 author = {Paudel, B. and Haas, T. and Bernstein, A.},
 title = {Fewer Flops at the Top: Accuracy, Diversity, and Regularization in Two-Class Collaborative Filtering},
 booktitle = {Proc. of the 11th ACM Conference on Recommender Systems},
 series = {RecSys '17},
 year = {2017},
 isbn = {978-1-4503-4652-8},
 
 pages = {215--223},
 numpages = {9},
 acmid = {3109916},
 publisher = {ACM},
 keywords = {collaborative filtering, diverse recommendations, matrix factorization, positive and negative recommendations},
} 

@inproceedings{Song2015,
 author = {Song, D. and Meyer, David A.},
 title = {Recommending Positive Links in Signed Social Networks by Optimizing a Generalized AUC},
 booktitle = {Proc. of the 29th AAAI Conference on Artificial Intelligence},
 series = {AAAI'15},
 year = {2015},
 isbn = {0-262-51129-0},
 
 pages = {290--296},
 numpages = {7},
 acmid = {2887048},
 publisher = {AAAI Press},
} 

@inproceedings{Hsieh2017,
 author = {Hsieh, C. and Yang, L. and Cui, Y. and Lin, T. and Belongie, S. and Estrin, D.},
 title = {Collaborative Metric Learning},
 booktitle = {Proc. of the 26th International Conference on World Wide Web},
 series = {WWW '17},
 year = {2017},
 isbn = {978-1-4503-4913-0},
 
 pages = {193--201},
 numpages = {9},
 acmid = {3052639},
 publisher = {International World Wide Web Conferences Steering Committee},
 keywords = {collaborative filtering, collaborative metric learning, metric learning, recommendation systems},
} 

@inproceedings{Jeunen2019DS,
 author = {Jeunen, O.},
 title = {Revisiting Offline Evaluation for Implicit-feedback Recommender Systems},
 booktitle = {Proc. of the 13th ACM Conference on Recommender Systems},
 series = {RecSys '19},
 year = {2019},
 isbn = {978-1-4503-6243-6},
 pages = {596--600},
 numpages = {5},
 acmid = {3347069},
 publisher = {ACM},
 keywords = {counterfactual evaluation, implicit feedback, offline evaluation},
  url = {https://doi.org/10.1145/3298689.3347069}
} 

@inproceedings{Joachims2018,
  author    = {T. Joachims and
               A. Swaminathan and
               M. de Rijke},
  title     = {Deep Learning with Logged Bandit Feedback},
  booktitle = {Proc. of the 6th International Conference on Learning Representations},
  year      = {2018},
  series = {ICLR '18}
}

@book{Owen2013,
   author = {A. B. Owen},
   year = 2013,
   title = {Monte Carlo theory, methods and examples}
}

@inproceedings{Swaminathan2015snips,
  title={The Self-Normalized Estimator for Counterfactual Learning},
  author={Swaminathan, A. and Joachims, T.},
  booktitle={Advances in Neural Information Processing Systems},
  pages={3231--3239},
  year={2015},
 url = {https://proceedings.neurips.cc/paper/2015/file/39027dfad5138c9ca0c474d71db915c3-Paper.pdf},
}

@article{Shimodaira2000,
author = "H. Shimodaira ",
title = "Improving predictive inference under covariate shift by weighting the log-likelihood function",
journal = "Journal of Statistical Planning and Inference",
volume = "90",
number = "2",
pages = "227 - 244",
year = "2000",
issn = "0378-3758",
}

@article{Jensen1906,
  title={Sur les fonctions convexes et les in{\'e}galit{\'e}s entre les valeurs moyennes},
  author={Jensen, J. L. W. V. and others},
  journal={Acta Mathematica},
  volume={30},
  pages={175--193},
  year={1906},
  publisher={Institut Mittag-Leffler}
}

@article{Ionides2008,
author = {E. L. Ionides},
title = {Truncated Importance Sampling},
journal = {Journal of Computational and Graphical Statistics},
volume = {17},
number = {2},
pages = {295-311},
year  = {2008},
publisher = {Taylor & Francis},
}

@inproceedings{Liang2018,
  title={Variational autoencoders for collaborative filtering},
  author={Liang, D. and Krishnan, R. G. and Hoffman, M. D and Jebara, T.},
  booktitle={Proc. of the 2018 World Wide Web Conference},
  series = {WWW '18},
  pages={689--698},
  year={2018},
  publisher = {ACM}
}

@article{Swaminathan2015JMLR,
  title={Batch learning from logged bandit feedback through counterfactual risk minimization.},
  author={Swaminathan, A. and Joachims, T.},
  journal={Journal of Machine Learning Research},
  volume={16},
  number={1},
  pages={1731--1755},
  year={2015}
}

@inproceedings{Jagerman2019SIGIR,
 author = {Jagerman, R. and Oosterhuis, H. and de Rijke, M.},
 title = {To Model or to Intervene: A Comparison of Counterfactual and Online Learning to Rank from User Interactions},
 booktitle = {Proc. of the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval},
 series = {SIGIR'19},
 year = {2019},
 isbn = {978-1-4503-6172-9},
 pages = {15--24},
 numpages = {10},
 acmid = {3331269},
 publisher = {ACM},
 keywords = {counterfactual learning, learning to rank, online learning},
} 

@inproceedings{Dudik2011,
 author = {Dud\'{\i}k, M. and Langford, J. and Li, L.},
 title = {Doubly Robust Policy Evaluation and Learning},
 booktitle = {Proc. of the 28th International Conference on International Conference on Machine Learning},
 series = {ICML'11},
 year = {2011},
 isbn = {978-1-4503-0619-5},
 pages = {1097--1104},
 numpages = {8},
 acmid = {3104620},
} 

@InProceedings{Farajtabar2018,
  title = 	 {More Robust Doubly Robust Off-policy Evaluation},
  author = 	 {Farajtabar, M. and Chow, Y. and Ghavamzadeh, M.},
  booktitle = 	 {Proc. of the 35th International Conference on Machine Learning},
  pages = 	 {1447--1456},
  year = 	 {2018},
  volume = 	 {80},
  series = 	 {ICML'18},
  month = 	 {10--15 Jul},
  publisher = 	 {PMLR},
}

@InProceedings{Vlassis2019,
  title = 	 {On the Design of Estimators for Bandit Off-Policy Evaluation},
  author = 	 {Vlassis, N. and Bibaut, A. and Dimakopoulou, M. and Jebara, T.},
  booktitle = 	 {Proc. of the 36th International Conference on Machine Learning},
  pages = 	 {6468--6476},
  year = 	 {2019},
  volume = 	 {97},
  series = 	 {ICML'19},
  month = 	 {09--15 Jun},
  publisher = 	 {PMLR},
}

@inproceedings{Zou2019,
 author = {Zou, H. and Kuang, K. and Chen, B. and Chen, P. and Cui, P.},
 title = {Focused Context Balancing for Robust Offline Policy Evaluation},
 booktitle = {Proc. of the 25th ACM Conference on Knowledge Discovery \& Data Mining},
 series = {KDD '19},
 year = {2019},
 isbn = {978-1-4503-6201-6},
 pages = {696--704},
 numpages = {9},
 acmid = {3330852},
 publisher = {ACM},
 keywords = {context balancing, distribution shift, policy evaluation},
} 

@article{Borchers1998,
 author = {Borchers, A. and Herlocker, J. and Konstan, J. and Riedl, J.},
 title = {Ganging Up on Information Overload},
 journal = {Computer},
 issue_date = {April 1998},
 volume = {31},
 number = {4},
 month = apr,
 year = {1998},
 issn = {0018-9162},
 pages = {106--108},
 numpages = {3},
 acmid = {620973},
 publisher = {IEEE Computer Society Press},
 address = {Los Alamitos, CA, USA},
}

@misc{Rendle2019,
    title={{On the Difficulty of Evaluating Baselines: A Study on Recommender Systems}},
    author={S. Rendle and L. Zhang and Y. Koren},
    year={2019},
    eprint={1905.01395},
    archivePrefix={arXiv},
    primaryClass={cs.IR}
}

@inproceedings{Salakhutdinov2008,
 author = {Salakhutdinov, R. and Mnih, A.},
 title = {Bayesian Probabilistic Matrix Factorization Using Markov Chain Monte Carlo},
 booktitle = {Proc. of the 25th International Conference on Machine Learning},
 series = {ICML '08},
 year = {2008},
 pages = {880--887},
 numpages = {8},
 acmid = {1390267},
 publisher = {ACM},
}

@article{Koren2009,
 author = {Koren, Y. and Bell, R. and Volinsky, C.},
 title = {Matrix Factorization Techniques for Recommender Systems},
 journal = {Computer},
 issue_date = {August 2009},
 volume = {42},
 number = {8},
 month = aug,
 year = {2009},
 issn = {0018-9162},
 pages = {30--37},
 numpages = {8},
 acmid = {1608614},
 publisher = {IEEE Computer Society Press},
 address = {Los Alamitos, CA, USA},
 keywords = {Computational intelligence, Computational intelligence, Netflix Prize, Matrix factorization, Matrix factorization, Netflix Prize},
}

@inproceedings{Le2011,
  title={On optimization methods for deep learning},
  author={Le, Q. and Ngiam, J. and Coates, A. and Lahiri, A. and Prochnow, B. and Ng, A.},
  booktitle={Proc. of the 28th International Conference on International Conference on Machine Learning},
  series = {ICML '11},
  pages={265--272},
  year={2011},
}

@article{Kelly1956,
  title={A New Interpretation of Information Rate},
  author={Kelly, J.},
  journal={the Bell System Technical Journal},
  year={1956}
}

@inproceedings{Mnih2016,
 author = {Mnih, V. and Badia, A. and Mirza, M. and Graves, A. and Harley, T. and Lillicrap, T. and Silver, D. and Kavukcuoglu, K.},
 title = {Asynchronous Methods for Deep Reinforcement Learning},
 booktitle = {Proc. of the 33rd International Conference on Machine Learning},
 series = {ICML'16},
 year = {2016},
 pages = {1928--1937},
 numpages = {10},
 acmid = {3045594},
 publisher = {JMLR.org},
} 

@article{Williams1991,
author = {Williams, R. and  Peng, J.},
title = {Function Optimization using Connectionist Reinforcement Learning Algorithms},
journal = {Connection Science},
volume = {3},
number = {3},
pages = {241-268},
year  = {1991},
publisher = {Taylor & Francis},
}

@misc{Singh2019,
    title={Policy Learning for Fairness in Ranking},
    author={Singh, A. and Joachims, T.},
    year={2019},
    eprint={1902.04056},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

@inproceedings{Agarwal2019TrustBias,
 author = {Agarwal, A. and Wang, X. and Li, C. and Bendersky, M. and Najork, M.},
 title = {Addressing Trust Bias for Unbiased Learning-to-Rank},
 booktitle = {Proc. of the 2019 World Wide Web Conference},
 series = {WWW '19},
 year = {2019},
 isbn = {978-1-4503-6674-8},
 pages = {4--14},
 numpages = {11},
 acmid = {3313697},
 publisher = {ACM},
 keywords = {Unbiased learning-to-rank, click noise, inverse propensity scoring, trust bias},
url = {https://doi.org/10.1145/3308558.3313697},
doi = {10.1145/3308558.3313697}
} 

@misc{Jeunen2019REVEAL,
    title={Learning from Bandit Feedback: An Overview of the State-of-the-art},
    author={Jeunen, O. and Mykhaylov, D. and Rohde, D. and Vasile, F. and Gilotte, A. and Bompaire, M.},
    year={2019},
    eprint={1909.08471},
    archivePrefix={arXiv},
    primaryClass={cs.IR}
}

@misc{Jeunen2019REVEAL_EVAL,
    title={On the Value of Bandit Feedback for Offline Recommender System Evaluation},
    author={Jeunen, O. and Rohde, D. and Vasile, F.},
    year={2019},
    eprint={1907.12384},
    archivePrefix={arXiv},
    primaryClass={cs.IR}
}

@misc{Mykhaylov2019CausalML,
    title={Three Methods for Training on Bandit Feedback},
    author={Mykhaylov, D. and Rohde, D. and Vasile, F. and Bompaire, M. and Jeunen, O.},
    year={2019},
    eprint={1904.10799},
    archivePrefix={arXiv},
    primaryClass={cs.IR}
}

@misc{Ie2019Recsim,
  url = {https://arxiv.org/abs/1909.04847},
  author = {Ie, E. and Hsu, C. and Mladenov, M. and Jain, V. and Narvekar, S. and Wang, J. and Wu, R. and Boutilier, C.},
  title = {RecSim: A Configurable Simulation Platform for Recommender Systems},
  publisher = {arXiv},
  year = {2019},
}

@article{Ie2019SlateQ,
  title={SlateQ: A tractable decomposition for reinforcement learning with recommendation sets},
  author={Ie, E. and Jain, V. and Wang, J. and Narvekar, S. and Agarwal, R. and Wu, R. and Cheng, H. and Chandra, T. and Boutilier, C.},
  year={2019},
  booktitle = {Proc. of the International Joint Conference on Artificial Intelligence},
  series = {IJCAI '19}
}

@InProceedings{London2019ICML,
  title = 	 {{B}ayesian Counterfactual Risk Minimization},
  author = 	 {London, B. and Sandler, T.},
  booktitle = 	 {Proc. of the 36th International Conference on Machine Learning},
  pages = 	 {4125--4133},
  year = 	 {2019},
  volume = 	 {97},
  series = 	 {ICML '19},
  publisher = 	 {PMLR},
}

@InProceedings{Ma2019AIStats,
  title = 	 {Imitation-Regularized Offline Learning},
  author = 	 {Ma, Y. and Wang, Y. and Narayanaswamy, B.},
  booktitle = 	 {Proc. of the 22nd International Conference on Artificial Intelligence and Statistics (AISTATS)},
  pages = 	 {2956--2965},
  year = 	 {2019},
  volume = 	 {89},
  series = 	 {AIStats '19},
  publisher = 	 {PMLR},
}

@inproceedings{Sutton1999,
 author = {Sutton, R. S. and McAllester, D. and Singh, S. and Mansour, Y.},
 title = {Policy Gradient Methods for Reinforcement Learning with Function Approximation},
 booktitle = {Advances in Neural Information Processing Systems},
 series = {NIPS'99},
 year = {1999},
 pages = {1057--1063},
 numpages = {7},
 acmid = {3009806},
} 

@inproceedings{Ktena2019,
 author = {Ktena, S. and Tejani, A. and Theis, L. and Myana, P. and Dilipkumar, D. and Husz\'{a}r, F. and Yoo, S. and Shi, W.},
 title = {Addressing Delayed Feedback for Continuous Training with Neural Networks in CTR Prediction},
 booktitle = {Proc. of the 13th ACM Conference on Recommender Systems},
 series = {RecSys '19},
 year = {2019},
 isbn = {978-1-4503-6243-6},
 
 pages = {187--195},
 numpages = {9},
 acmid = {3347002},
 publisher = {ACM},
 keywords = {delayed feedback, fake negatives, recommender systems},
} 

@article{Smith2006,
author = {Smith, J. E. and Winkler, R. L.},
title = {The Optimizer's Curse: Skepticism and Postdecision Surprise in Decision Analysis},
journal = {Management Science},
volume = {52},
number = {3},
pages = {311-322},
year = {2006}
}

@inproceedings{Jeunen2019FP,
 author = {Jeunen, O. and Verstrepen, K. and Goethals, B.},
 title = {Efficient Similarity Computation for Collaborative Filtering in Dynamic Environments},
 booktitle = {Proc. of the 13th ACM Conference on Recommender Systems},
 series = {RecSys '19},
 year = {2019},
 isbn = {978-1-4503-6243-6},
 pages = {251--259},
 numpages = {9},
 acmid = {3347017},
 publisher = {ACM},
 keywords = {distributed algorithms, incremental algorithms, nearest-neighbours},
} 

@inproceedings{Moens2019,
 author = {Moens, S. and Jeunen, O. and Goethals, B.},
 title = {Interactive Evaluation of Recommender Systems with SNIPER: An Episode Mining Approach},
 booktitle = {Proc. of the 13th ACM Conference on Recommender Systems},
 series = {RecSys '19},
 year = {2019},
 isbn = {978-1-4503-6243-6},
 pages = {538--539},
 numpages = {2},
 acmid = {3346965},
 publisher = {ACM},
 keywords = {episode mining, evaluation, recommender systems},
} 

@INPROCEEDINGS{Jeunen208Thesis,
author={O. {Jeunen} and P. {Bosch} and M. V. {Herwegen} and K. V. {Doorselaer} and N. {Godman} and S. {Latr}},
booktitle={2018 14th International Conference on Network and Service Management (CNSM)},
title={A Machine Learning Approach for IEEE 802.11 Channel Allocation},
year={2018},
volume={},
number={},
pages={28-36},
doi={},
ISSN={},
month={Nov},}

@article{rohde2019bayesian,
  title={A Bayesian Solution to the M-Bias Problem},
  author={Rohde, David},
  journal={arXiv preprint arXiv:1906.07136},
  year={2019}
}

@inproceedings{REVEAL2018,
 author = {Joachims, T. and Swaminathan, A. and Raimond, Y. and Koch, O. and Vasile, F.},
 title = {REVEAL 2018: Offline Evaluation for Recommender Systems},
 booktitle = {Proc. of the 12th ACM Conference on Recommender Systems},
 series = {RecSys '18},
 year = {2018},
 isbn = {978-1-4503-5901-6},
 
 pages = {514--515},
 numpages = {2},
 acmid = {3240334},
 publisher = {ACM},
 keywords = {A/B testing, causal inference, metrics, multi-armed bandits, offline evaluation, recommender systems},
}

@inproceedings{REVEAL2019,
 author = {Joachims, T. and Dimakopoulou, M. and Swaminathan, A. and Raimond, Y. and Koch, O. and Vasile, F.},
 title = {REVEAL 2019: Closing the Loop with the Real World: Reinforcement and Robust Estimators for Recommendation},
 booktitle = {Proc. of the 13th ACM Conference on Recommender Systems},
 series = {RecSys '19},
 year = {2019},
 isbn = {978-1-4503-6243-6},
 
 pages = {568--569},
 numpages = {2},
 acmid = {3346975},
 publisher = {ACM},
 keywords = {causal inference, multi-armed bandits, off-policy, offline evaluation, recommender systems, reinforcement learning},
} 

@article{rohde2018recogym,
  title={RecoGym: A Reinforcement Learning Environment for the problem of Product Recommendation in Online Advertising},
  author={Rohde, D. and Bonner, S. and Dunlop, T. and Vasile, F. and Karatzoglou, A.},
  journal={arXiv preprint arXiv:1808.00720},
  year={2018}
}

@misc{rendle2019evaluation,
    title={Evaluation Metrics for Item Recommendation under Sampling},
    author={S. Rendle},
    year={2019},
    eprint={1912.02263},
    archivePrefix={arXiv},
    primaryClass={cs.IR}
}

@inproceedings{Elahi2019,
 author = {Elahi, E. and Wang, W. and Ray, D. and Fenton, A. and Jebara, T.},
 title = {Variational Low Rank Multinomials for Collaborative Filtering with Side-information},
 booktitle = {Proc. of the 13th ACM Conference on Recommender Systems},
 series = {RecSys '19},
 year = {2019},
 isbn = {978-1-4503-6243-6},
 
 pages = {340--347},
 numpages = {8},
 acmid = {3347036},
 publisher = {ACM},
 keywords = {collaborative filtering, side-information, variational inference},
} 

@article{Maurer2009,
  title={Empirical Bernstein Bounds and Sample Variance Penalization},
  author={Maurer, A. and Pontil, M.},
  journal={Stat.},
  volume={1050},
  pages={21},
  year={2009}
}

@inproceedings{Paszke2017,
  title={Automatic differentiation in PyTorch},
  author={Paszke, A. and Gross, S. and Chintala, S. and Chanan, G. and Yang, E. and DeVito, Z. and Lin, Z. and Desmaison, A. and Antiga, L. and Lerer, A.},
  booktitle={Proc. of the NIPS 2017 Workshop on AutoDiff},
  year={2017}
}


 %{AMS}
 @String{AMSTrans = "American Mathematical Society Translations" }
 @String{AMSTrans = "Amer. Math. Soc. Transl." }
 @String{BullAMS = "Bulletin of the American Mathematical Society" }
 @String{BullAMS = "Bull. Amer. Math. Soc." }
 @String{ProcAMS = "Proceedings of the American Mathematical Society" }
 @String{ProcAMS = "Proc. Amer. Math. Soc." }
 @String{TransAMS = "Transactions of the American Mathematical Society" }
 @String{TransAMS = "Trans. Amer. Math. Soc." }

 %ACM
 @String{CACM = "Communications of the {ACM}" }
 @String{CACM = "Commun. {ACM}" }
 @String{CompServ = "Comput. Surveys" }
 @String{JACM = "J. ACM" }
 @String{ACMMathSoft = "{ACM} Transactions on Mathematical Software" }
 @String{ACMMathSoft = "{ACM} Trans. Math. Software" }
 @String{SIGNUM = "{ACM} {SIGNUM} Newsletter" }
 @String{SIGNUM = "{ACM} {SIGNUM} Newslett." }

 @String{AmerSocio = "American Journal of Sociology" }
 @String{AmerStatAssoc = "Journal of the American Statistical Association" }
 @String{AmerStatAssoc = "J. Amer. Statist. Assoc." }
 @String{ApplMathComp = "Applied Mathematics and Computation" }
 @String{ApplMathComp = "Appl. Math. Comput." }
 @String{AmerMathMonthly = "American Mathematical Monthly" }
 @String{AmerMathMonthly = "Amer. Math. Monthly" }
 @String{BIT = "{BIT}" }
 @String{BritStatPsych = "British Journal of Mathematical and Statistical
          Psychology" }
 @String{BritStatPsych = "Brit. J. Math. Statist. Psych." }
 @String{CanMathBull = "Canadian Mathematical Bulletin" }
 @String{CanMathBull = "Canad. Math. Bull." }
 @String{CompApplMath = "Journal of Computational and Applied Mathematics" }
 @String{CompApplMath = "J. Comput. Appl. Math." }
 @String{CompPhys = "Journal of Computational Physics" }
 @String{CompPhys = "J. Comput. Phys." }
 @String{CompStruct = "Computers and Structures" }
 @String{CompStruct = "Comput. \& Structures" }
 @String{CompJour = "The Computer Journal" }
 @String{CompJour = "Comput. J." }
 @String{CompSysSci = "Journal of Computer and System Sciences" }
 @String{CompSysSci = "J. Comput. System Sci." }
 @String{Computing = "Computing" }
 @String{ContempMath = "Contemporary Mathematics" }
 @String{ContempMath = "Contemp. Math." }
 @String{Crelle = "Crelle's Journal" }
 @String{GiornaleMath = "Giornale di Mathematiche" }
 @String{GiornaleMath = "Giorn. Mat." } % didn't find in AMS MR., ibid.

 %IEEE
 @String{Computer = "{IEEE} Computer" }
 @String{IEEETransComp = "{IEEE} Transactions on Computers" }
 @String{IEEETransComp = "{IEEE} Trans. Comput." }
 @String{IEEETransAC = "{IEEE} Transactions on Automatic Control" }
 @String{IEEETransAC = "{IEEE} Trans. Automat. Control" }
 @String{IEEESpec = "{IEEE} Spectrum" } % didn't find in AMS MR
 @String{ProcIEEE = "Proceedings of the {IEEE}" }
 @String{ProcIEEE = "Proc. {IEEE}" } % didn't find in AMS MR
 @String{IEEETransAeroElec = "{IEEE} Transactions on Aerospace and Electronic
     Systems" }
 @String{IEEETransAeroElec = "{IEEE} Trans. Aerospace Electron. Systems" }

 @String{IMANumerAna = "{IMA} Journal of Numerical Analysis" }
 @String{IMANumerAna = "{IMA} J. Numer. Anal." }
 @String{InfProcLet = "Information Processing Letters" }
 @String{InfProcLet = "Inform. Process. Lett." }
 @String{InstMathApp = "Journal of the Institute of Mathematics and
     its Applications" }
 @String{InstMathApp = "J. Inst. Math. Appl." }
 @String{IntControl = "International Journal of Control" }
 @String{IntControl = "Internat. J. Control" }
 @String{IntNumerEng = "International Journal for Numerical Methods in
     Engineering" }
 @String{IntNumerEng = "Internat. J. Numer. Methods Engrg." }
 @String{IntSuper = "International Journal of Supercomputing Applications" }
 @String{IntSuper = "Internat. J. Supercomputing Applic." } % didn't find
%% in AMS MR
 @String{Kibernetika = "Kibernetika" }
 @String{JResNatBurStand = "Journal of Research of the National Bureau
     of Standards" }
 @String{JResNatBurStand = "J. Res. Nat. Bur. Standards" }
 @String{LinAlgApp = "Linear Algebra and its Applications" }
 @String{LinAlgApp = "Linear Algebra Appl." }
 @String{MathAnaAppl = "Journal of Mathematical Analysis and Applications" }
 @String{MathAnaAppl = "J. Math. Anal. Appl." }
 @String{MathAnnalen = "Mathematische Annalen" }
 @String{MathAnnalen = "Math. Ann." }
 @String{MathPhys = "Journal of Mathematical Physics" }
 @String{MathPhys = "J. Math. Phys." }
 @String{MathComp = "Mathematics of Computation" }
 @String{MathComp = "Math. Comp." }
 @String{MathScand = "Mathematica Scandinavica" }
 @String{MathScand = "Math. Scand." }
 @String{TablesAidsComp = "Mathematical Tables and Other Aids to Computation" }
 @String{TablesAidsComp = "Math. Tables Aids Comput." }
 @String{NumerMath = "Numerische Mathematik" }
 @String{NumerMath = "Numer. Math." }
 @String{PacificMath = "Pacific Journal of Mathematics" }
 @String{PacificMath = "Pacific J. Math." }
 @String{ParDistComp = "Journal of Parallel and Distributed Computing" }
 @String{ParDistComp = "J. Parallel and Distrib. Comput." } % didn't find
%% in AMS MR
 @String{ParComputing = "Parallel Computing" }
 @String{ParComputing = "Parallel Comput." }
 @String{PhilMag = "Philosophical Magazine" }
 @String{PhilMag = "Philos. Mag." }
 @String{ProcNAS = "Proceedings of the National Academy of Sciences
                    of the USA" }
 @String{ProcNAS = "Proc. Nat. Acad. Sci. U. S. A." }
 @String{Psychometrika = "Psychometrika" }
 @String{QuartMath = "Quarterly Journal of Mathematics, Oxford, Series (2)" }
 @String{QuartMath = "Quart. J. Math. Oxford Ser. (2)" }
 @String{QuartApplMath = "Quarterly of Applied Mathematics" }
 @String{QuartApplMath = "Quart. Appl. Math." }
 @String{RevueInstStat = "Review of the International Statisical Institute" }
 @String{RevueInstStat = "Rev. Inst. Internat. Statist." }

 %SIAM
 @String{JSIAM = "Journal of the Society for Industrial and Applied
     Mathematics" }
 @String{JSIAM = "J. Soc. Indust. Appl. Math." }
 @String{JSIAMB = "Journal of the Society for Industrial and Applied
     Mathematics, Series B, Numerical Analysis" }
 @String{JSIAMB = "J. Soc. Indust. Appl. Math. Ser. B Numer. Anal." }
 @String{SIAMAlgMeth = "{SIAM} Journal on Algebraic and Discrete Methods" }
 @String{SIAMAlgMeth = "{SIAM} J. Algebraic Discrete Methods" }
 @String{SIAMAppMath = "{SIAM} Journal on Applied Mathematics" }
 @String{SIAMAppMath = "{SIAM} J. Appl. Math." }
 @String{SIAMComp = "{SIAM} Journal on Computing" }
 @String{SIAMComp = "{SIAM} J. Comput." }
 @String{SIAMMatrix = "{SIAM} Journal on Matrix Analysis and Applications" }
 @String{SIAMMatrix = "{SIAM} J. Matrix Anal. Appl." }
 @String{SIAMNumAnal = "{SIAM} Journal on Numerical Analysis" }
 @String{SIAMNumAnal = "{SIAM} J. Numer. Anal." }
 @String{SIAMReview = "{SIAM} Review" }
 @String{SIAMReview = "{SIAM} Rev." }
 @String{SIAMSciStat = "{SIAM} Journal on Scientific and Statistical
     Computing" }
 @String{SIAMSciStat = "{SIAM} J. Sci. Statist. Comput." }

 @String{SoftPracExp = "Software Practice and Experience" }
 @String{SoftPracExp = "Software Prac. Experience" } % didn't find in AMS MR
 @String{StatScience = "Statistical Science" }
 @String{StatScience = "Statist. Sci." }
 @String{Techno = "Technometrics" }
 @String{USSRCompMathPhys = "{USSR} Computational Mathematics and Mathematical
     Physics" }
 @String{USSRCompMathPhys = "{U. S. S. R.} Comput. Math. and Math. Phys." }
 @String{VLSICompSys = "Journal of {VLSI} and Computer Systems" }
 @String{VLSICompSys = "J. {VLSI} Comput. Syst." }
 @String{ZAngewMathMech = "Zeitschrift fur Angewandte Mathematik und
     Mechanik" }
 @String{ZAngewMathMech = "Z. Angew. Math. Mech." }
 @String{ZAngewMathPhys = "Zeitschrift fur Angewandte Mathematik und Physik" }
 @String{ZAngewMathPhys = "Z. Angew. Math. Phys." }

% Publishers % ================================================= |

 @String{Academic = "Academic Press" }
 @String{ACMPress = "{ACM} Press" }
 @String{AdamHilger = "Adam Hilger" }
 @String{AddisonWesley = "Addison-Wesley" }
 @String{AllynBacon = "Allyn and Bacon" }
 @String{AMS = "American Mathematical Society" }
 @String{Birkhauser = "Birkha{\"u}ser" }
 @String{CambridgePress = "Cambridge University Press" }
 @String{Chelsea = "Chelsea" }
 @String{ClaredonPress = "Claredon Press" }
 @String{DoverPub = "Dover Publications" }
 @String{Eyolles = "Eyolles" }
 @String{HoltRinehartWinston = "Holt, Rinehart and Winston" }
 @String{Interscience = "Interscience" }
 @String{JohnsHopkinsPress = "The Johns Hopkins University Press" }
 @String{JohnWileySons = "John Wiley and Sons" }
 @String{Macmillan = "Macmillan" }
 @String{MathWorks = "The Math Works Inc." }
 @String{McGrawHill = "McGraw-Hill" }
 @String{NatBurStd = "National Bureau of Standards" }
 @String{NorthHolland = "North-Holland" }
 @String{OxfordPress = "Oxford University Press" }  %address Oxford or London?
 @String{PergamonPress = "Pergamon Press" }
 @String{PlenumPress = "Plenum Press" }
 @String{PrenticeHall = "Prentice-Hall" }
 @String{SIAMPub = "{SIAM} Publications" }
 @String{Springer = "Springer-Verlag" }
 @String{TexasPress = "University of Texas Press" }
 @String{VanNostrand = "Van Nostrand" }
 @String{WHFreeman = "W. H. Freeman and Co." }

%Entries
@article{Robbins1952,
  title={Some aspects of the sequential design of experiments},
  author={Robbins, Herbert},
  journal={Bulletin of the American Mathematical Society},
  volume={58},
  number={5},
  pages={527--535},
  year={1952},
}

@inproceedings{Kohavi1995,
  title={A study of cross-validation and bootstrap for accuracy estimation and model selection},
  author={Kohavi, R. and others},
  booktitle={Proc. of the 1995 International Joint Conference on Artificial Intelligence},
  volume={14},
  number={2},
  pages={1137--1145},
  year={1995},
  organisation = {IJCAI}
}

@inproceedings{Sarwar2001,
 author = {Sarwar, B. and Karypis, G. and Konstan, J. and Riedl, J.},
 title = {Item-based Collaborative Filtering Recommendation Algorithms},
 booktitle = {Proc. of the 10th International Conference on World Wide Web},
 series = {WWW '01},
 year = {2001},
 
 pages = {285--295},
 numpages = {11},
 acmid = {372071},
 publisher = {ACM},
}

@inproceedings{Yu2001,
  title={Indexing the distance: An efficient method to knn processing},
  author={Yu, C. and Ooi, B. and Tan, K. and Jagadish, H.},
  booktitle={Proc. of the 27th International Conference on Very Large Databases},
  series = {VLDB '01},
  year={2001},
  pages={421--430},
  numpages = {10}
}

@inproceedings{Schein2002,
 author = {Schein, Andrew I. and Popescul, Alexandrin and Ungar, Lyle H. and Pennock, David M.},
 title = {{Methods and Metrics for Cold-start Recommendations}},
 booktitle = {Proc. of the 25th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval},
 series = {SIGIR '02},
 year = {2002},
 
 pages = {253--260},
 numpages = {8},
 acmid = {564421},
 publisher = {ACM},
 keywords = {collaborative filtering, content-based filtering, graphical models, information retrieval, performance evaluation, recommender systems},
}

@inproceedings{Sarawagi2004,
 author = {Sarawagi, S. and Kirpal, A.},
 title = {Efficient Set Joins on Similarity Predicates},
 booktitle = {Proc. of the 2004 ACM SIGMOD International Conference on Management of Data},
 series = {SIGMOD '04},
 year = {2004},
 isbn = {1-58113-859-8},
 
 pages = {743--754},
 numpages = {12},
 acmid = {1007652},
 publisher = {ACM},
 
} 

@InProceedings{Papagelis2005,
author="Papagelis, M.
and Rousidis, I.
and Plexousakis, D.
and Theoharopoulos, E.",
editor="Hacid, M.
and Murray, N.
and Ra{\'{s}}, Z.
and Tsumoto, S.",
title="Incremental Collaborative Filtering for Highly-Scalable Recommendation Algorithms",
booktitle="Foundations of Intelligent Systems",
year="2005",
publisher="Springer",
pages="553--561",
isbn="978-3-540-31949-8"
}

@inproceedings{Zhang2005, 
author={Zhang, S. and Wang, W. and Ford, J. and Makedon, F. and Pearlman, J.}, 
booktitle={Proc. of the 7th IEEE International Conference on E-Commerce Technology},
series = {CEC '05},
title={Using singular value decomposition approximation for collaborative filtering}, 
year={2005}, 
volume={}, 
number={}, 
pages={257-264}, 
ISSN={2378-1963}, 
month={July},}


@article{Yu2007,
 author = {Yu, C. and Cui, B. and Wang, S. and Su, J.},
 title = {Efficient Index-based KNN Join Processing for High-dimensional Data},
 journal = {Inf. Softw. Technol.},
 issue_date = {April, 2007},
 volume = {49},
 number = {4},
 month = apr,
 year = {2007},
 issn = {0950-5849},
 pages = {332--344},
 numpages = {13},
 acmid = {1224939},
 publisher = {Butterworth-Heinemann},
 address = {Newton, MA, USA},
 keywords = {High-dimensional data, KNN, Similarity join},
} 

@inproceedings{Rendle2008,
 author = {Rendle, S. and Schmidt-Thieme, L.},
 title = {Online-updating Regularized Kernel Matrix Factorization Models for Large-scale Recommender Systems},
 booktitle = {Proc. of the 1st ACM Conference on Recommender Systems},
 series = {RecSys '08},
 year = {2008},
 
 pages = {251--258},
 numpages = {8},
 acmid = {1454047},
 publisher = {ACM},
 keywords = {matrix factorization, online-update, recommender system},
} 

@article{Dean2008,
 author = {Dean, J. and Ghemawat, S.},
 title = {MapReduce: Simplified Data Processing on Large Clusters},
 journal = {Commun. ACM},
 issue_date = {January 2008},
 volume = {51},
 number = {1},
 month = jan,
 year = {2008},
 pages = {107--113},
 numpages = {7},
 publisher = {ACM},
} 

@inproceedings{Pan2008, 
author={R. Pan and Y. Zhou and B. Cao and N. N. Liu and R. Lukose and M. Scholz and Q. Yang}, 
booktitle={Proc. of the 8th IEEE International Conference on Data Mining},
series = {ICDM '08},
title={One-Class Collaborative Filtering}, 
year={2008}, 
volume={}, 
number={}, 
pages={502-511}, 
keywords={Internet;groupware;information filtering;Web page bookmarking;binary data;bookmark recommendation;news item recommendation;one-class collaborative filtering;training data;DVD;Data mining;Filtering;Fuels;History;International collaboration;Milling machines;Rockets;Sampling methods;Training data;Alternating Least Squares;Collaborative Filtering;Low-Rank Approximations;One-Class}, 
ISSN={1550-4786}, 
month={Dec}
}

@inproceedings{Hu2008, 
author={Y. Hu and Y. Koren and C. Volinsky}, 
booktitle={Proc. of the 8th IEEE International Conference on Data Mining},
title={{Collaborative Filtering for Implicit Feedback Datasets}},
series={ICDM '08},
year={2008}, 
volume={}, 
number={}, 
pages={263-272}, 
keywords={electronic commerce;feedback;browsing activity;collaborative filtering;customer experience;implicit feedback datasets;personalized recommendations;purchase history;recommender systems;scalable optimization procedure;user preferences;watching habits;Data mining;Demography;Filtering;History;International collaboration;Motion pictures;Negative feedback;Recommender systems;TV;Watches;Collaborative filtering;implicit feedback;recommender system}, 
ISSN={1550-4786}, 
month={Dec}
}

@incollection{Langford2008,
title = {The Epoch-Greedy Algorithm for Multi-armed Bandits with Side Information},
author = {Langford, J. and Zhang, T.},
booktitle = {Advances in Neural Information Processing Systems 20},
pages = {817--824},
year = {2008},
publisher = {Curran Associates, Inc.},
}


@inproceedings{Rendle2009,
  author={Rendle, S. and Freudenthaler, C. and Gantner, Z. and Schmidt-Thieme, L.},
  title={{BPR: Bayesian personalized ranking from implicit feedback}},
  booktitle={Proc. of the 25th Conference on Uncertainty in Artificial Intelligence},
  series = {UAI '09},
  year={2009},
  pages={452--461},
  organization={AUAI Press}
}

@article{Yu2009,
  author="Yu, C.
  and Zhang, R.
  and Huang, Y.
  and Xiong, H.",
  title="High-dimensional kNN joins with incremental updates",
  journal="GeoInformatica",
  year="2009",
  volume="14",
  number="1",
  pages="55--82",
}

@Article{Kohavi2009,
author="Kohavi, Ron
and Longbotham, Roger
and Sommerfield, Dan
and Henne, Randal M.",
title="Controlled experiments on the web: survey and practical guide",
journal="Data Mining and Knowledge Discovery",
year="2009",
month="Feb",
day="01",
volume="18",
number="1",
pages="140--181",
}



@inproceedings{Karatzoglou2010,
 author = {Karatzoglou, A. and Amatriain, X. and Baltrunas, L. and Oliver, N.},
 title = {{Multiverse Recommendation: N-dimensional Tensor Factorization for Context-aware Collaborative Filtering}},
 booktitle = {Proc. of the 4th ACM Conference on Recommender Systems},
 series = {RecSys '10},
 year = {2010},
 
 pages = {79--86},
 numpages = {8},
 acmid = {1864727},
 publisher = {ACM},
 keywords = {collaborative filtering, context, tensor factorization},
} 

@inproceedings{Liu2010,
 author = {Liu, N. and Zhao, M. and Xiang, E. and Yang, Q.},
 title = {Online Evolutionary Collaborative Filtering},
 booktitle = {Proc. of the 4th ACM Conference on Recommender Systems},
 series = {RecSys '10},
 year = {2010},
 
 pages = {95--102},
 numpages = {8},
 acmid = {1864729},
 publisher = {ACM},
 keywords = {collaborative filtering, latent class model, ranking},
} 

@incollection{Shani2011,
author="Shani, G. and Gunawardana, A.",
editor="Ricci, Francesco
and Rokach, Lior
and Shapira, Bracha
and Kantor, Paul B.",
title="Evaluating Recommendation Systems",
booktitle="Recommender Systems Handbook",
year="2011",
publisher="Springer US",
pages="257--297",
isbn="978-0-387-85820-3"
}

@inproceedings{Yang2012,
 author = {Yang, X. and Zhang, Z. and Wang, K.},
 title = {Scalable Collaborative Filtering Using Incremental Update and Local Link Prediction},
 booktitle = {Proc. of the 21st ACM International Conference on Information and Knowledge Management},
 series = {CIKM '12},
 year = {2012},
 
 pages = {2371--2374},
 numpages = {4},
 acmid = {2398643},
 publisher = {ACM},
 keywords = {collaborative filtering, incremental update, link prediction, scalability, similarity graph},
}

@inproceedings{Zhang2012,
 author = {Zhang, C. and Li, F. and Jestes, J.},
 title = {Efficient Parallel kNN Joins for Large Data in MapReduce},
 booktitle = {Proc. of the 15th International Conference on Extending Database Technology},
 series = {EDBT '12},
 year = {2012},
 
 pages = {38--49},
 numpages = {12},
 acmid = {2247602},
 publisher = {ACM},
}

@article{Zadeh2013,
  title={Dimension independent similarity computation},
  author={Zadeh, R. and Goel, A.},
  journal={The Journal of Machine Learning Research},
  volume={14},
  number={1},
  pages={1605--1626},
  year={2013},
  publisher={JMLR.org}
}

@article{Luo2013,
title = "Boosting the K-Nearest-Neighborhood based incremental collaborative filtering",
journal = "Knowledge-Based Systems",
volume = "53",
pages = "90 - 99",
year = "2013",
author = "X. Luo and Y. Xia and Q. Zhu and Y. Li",
keywords = "Recommender system, Incremental recommendation, Collaborative filtering, Rating similarity, K-Nearest-Neighborhood"
}

@inproceedings{Yang2014, 
  author={Yang, C. and Yu, X. and Liu, Y.}, 
  booktitle={Proc. of the 14th IEEE International Conference on Data Mining},
  series = {ICDM '14},
  title={Continuous KNN Join Processing for Real-Time Recommendation}, 
  year={2014}, 
  volume={}, 
  number={}, 
  pages={640-649}, 
  keywords={data reduction;pattern clustering;principal component analysis;recommender systems;social   networking (online);tree data structures;HDR-tree index structure;PCA;Web sites;clustering analysis;continuous   KNN join processing;curse of dimensionality reduction;data streams;high in-memory search cost;k nearest neighbors;people content-consumption behavior;principle component analysis;real-time recommendation;social networking;user-generated contents;Clustering algorithms;Collaboration;Educational institutions;Indexes;Principal component analysis;Real-time systems;Vegetation;high-dimensional data;k nearest neighbor join;real-time recommendation}, 
  month={Dec}
}

@article{Muja2014, 
  author={Muja, M. and Lowe, D. G.}, 
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={Scalable Nearest Neighbor Algorithms for High Dimensional Data}, 
  year={2014}, 
  volume={36}, 
  number={11}, 
  pages={2227-2240}
}

@inproceedings{Rong2014,
 author = {Rong, Y. and Wen, X. and Cheng, H.},
 title = {{A Monte Carlo Algorithm for Cold Start Recommendation}},
 booktitle = {Proc. of the 23rd International Conference on World Wide Web},
 series = {WWW '14},
 year = {2014},
 
 pages = {327--336},
 numpages = {10},
 acmid = {2567978},
 publisher = {ACM},
 keywords = {cold start, monte carlo simulation, preference propagation, random walk on bipartite graph}
}

@inproceedings{Saveski2014,
 author = {Saveski, M. and Mantrach, A.},
 title = {{Item Cold-start Recommendations: Learning Local Collective Embeddings}},
 booktitle = {Proc. of the 8th ACM Conference on Recommender Systems},
 series = {RecSys '14},
 year = {2014},
 
 pages = {89--96},
 numpages = {8},
 acmid = {2645751},
 publisher = {ACM},
 keywords = {cold-start, collective embeddings, matrix factorization, recommender systems},
}

@inproceedings{Ottaviano2014,
 author = {Ottaviano, G. and Venturini, R.},
 title = {Partitioned Elias-Fano Indexes},
 booktitle = {Proc. of the 37th International ACM SIGIR Conference on Research \& Development in Information Retrieval},
 series = {SIGIR '14},
 year = {2014},
 isbn = {978-1-4503-2257-7},
 
 pages = {273--282},
 numpages = {10},
 acmid = {2609615},
 publisher = {ACM},
 keywords = {compression, dynamic programming, inverted indexes},
}

@article{Mirbakhsh2015,
 author = {Mirbakhsh, N. and Ling, C. X.},
 title = {{Improving Top-N Recommendation for Cold-Start Users via Cross-Domain Information}},
 journal = {ACM Trans. Knowl. Discov. Data},
 issue_date = {June 2015},
 volume = {9},
 number = {4},
 month = jun,
 year = {2015},
 pages = {33:1--33:19},
 articleno = {33},
 numpages = {19},
 acmid = {2724720},
 publisher = {ACM},
 keywords = {Collaborative filtering, cold start, matrix factorization, recommendation system},
} 

@inproceedings{Huang2015,
 author = {Huang, Y. and Cui, B. and Zhang, W. and Jiang, J. and Xu, Y.},
 title = {TencentRec: Real-time Stream Recommendation in Practice},
 booktitle = {Proc. of the 2015 ACM SIGMOD International Conference on Management of Data},
 series = {SIGMOD '15},
 year = {2015},
 
 pages = {227--238},
 numpages = {12},
 acmid = {2742785},
 publisher = {ACM},
 keywords = {application, big data, practice, real-time recommendation, scalability},
} 

@article{Gomez-Uribe2015,
 author = {Gomez-Uribe, C. A. and Hunt, N.},
 title = {The Netflix Recommender System: Algorithms, Business Value, and Innovation},
 journal = {ACM Trans. Manage. Inf. Syst.},
 issue_date = {January 2016},
 volume = {6},
 number = {4},
 month = dec,
 year = {2015},
 issn = {2158-656X},
 pages = {13:1--13:19},
 articleno = {13},
 numpages = {19},
 acmid = {2843948},
 publisher = {ACM},
 
 keywords = {Recommender systems},
} 

@inproceedings{Subbian2016,
 author = {Subbian, K. and Aggarwal, C. and Hegde, K.},
 title = {Recommendations For Streaming Data},
 booktitle = {Proc. of the 25th ACM International on Conference on Information and Knowledge Management},
 series = {CIKM '16},
 year = {2016},
 
 pages = {2185--2190},
 numpages = {6},
 acmid = {2983663},
 publisher = {ACM},
 keywords = {data streams, neighborhood model, recommender systems, streaming recommendations},
} 

@inproceedings{He2016,
 author = {He, X. and Zhang, H. and Kan, M. and Chua, T.},
 title = {Fast Matrix Factorization for Online Recommendation with Implicit Feedback},
 booktitle = {Proc. of the 39th International ACM SIGIR Conference on Research and Development in Information Retrieval},
 series = {SIGIR '16},
 year = {2016},
 
 pages = {549--558},
 numpages = {10},
 acmid = {2911489},
 publisher = {ACM},
 keywords = {ALS, coordinate descent, implicit feedback, item recommendation, matrix factorization, online learning},
} 

@inproceedings{Jannach2017,
 author = {Jannach, D. and Ludewig, M.},
 title = {When Recurrent Neural Networks Meet the Neighborhood for Session-Based Recommendation},
 booktitle = {Proc. of the 11th ACM Conference on Recommender Systems},
 series = {RecSys '17},
 year = {2017},
 
 pages = {306--310},
 numpages = {5},
 acmid = {3109872},
 publisher = {ACM},
 keywords = {deep learning, nearest-neighbors, session-based recommendation},
}

@misc{Outbrain2017,
  title = {Kaggle Click Prediction Dataset},
  author = {Outbrain},
  year = {2017},
  howpublished = {\url{https://www.kaggle.com/c/outbrain-click-prediction/data}},
}

@article{Verstrepen2017,
 author = {Verstrepen, K. and Bhaduriy, K. and Cule, B. and Goethals, B.},
 title = {Collaborative Filtering for Binary, Positiveonly Data},
 journal = {SIGKDD Explor. Newsl.},
 issue_date = {June 2017},
 volume = {19},
 number = {1},
 month = sep,
 year = {2017},
 issn = {1931-0145},
 pages = {1--21},
 numpages = {21},
 acmid = {3137599},
 publisher = {ACM},
 
} 

@inproceedings{Joachims2017,
author = {Joachims, T. and Swaminathan, A. and Schnabel, T.},
title = {Unbiased Learning-to-Rank with Biased Feedback},
year = {2017},
isbn = {9781450346757},
publisher = {ACM},

url = {https://doi.org/10.1145/3018661.3018699},
doi = {10.1145/3018661.3018699},
abstract = {Implicit feedback (e.g., clicks, dwell times, etc.) is an abundant source of data in human-interactive systems. While implicit feedback has many advantages (e.g., it is inexpensive to collect, user centric, and timely), its inherent biases are a key obstacle to its effective use. For example, position bias in search rankings strongly influences how many clicks a result receives, so that directly using click data as a training signal in Learning-to-Rank (LTR) methods yields sub-optimal results. To overcome this bias problem, we present a counterfactual inference framework that provides the theoretical basis for unbiased LTR via Empirical Risk Minimization despite biased data. Using this framework, we derive a Propensity-Weighted Ranking SVM for discriminative learning from implicit feedback, where click models take the role of the propensity estimator. In contrast to most conventional approaches to de-biasing the data using click models, this allows training of ranking functions even in settings where queries do not repeat. Beyond the theoretical support, we show empirically that the proposed learning method is highly effective in dealing with biases, that it is robust to noise and propensity model misspecification, and that it scales efficiently. We also demonstrate the real-world applicability of our approach on an operational search engine, where it substantially improves retrieval performance.},
booktitle = {Proc of. the Tenth ACM International Conference on Web Search and Data Mining},
pages = {781789},
numpages = {9},
keywords = {ranking svm, implicit feedback, learning to rank, click models, propensity weighting},

series = {WSDM '17}
}

@InProceedings{Sreepada2018,
author="Sreepada, R. S.
and Patra, B. K.",
editor="Pasi, G.
and Piwowarski, B.
and Azzopardi, L.
and Hanbury, A.",
title="An Incremental Approach for Collaborative Filtering in Streaming Scenarios",
booktitle="Advances in Information Retrieval",
year="2018",
publisher="Springer International Publishing",
pages="632--637",
}

@inproceedings{W_Wang2018,
 author = {Wang, W. and Yin, H. and Huang, Z. and Wang, Q. and Du, X. and Nguyen, Q.},
 title = {Streaming Ranking Based Recommender Systems},
 booktitle = {Proc. of the 41st International ACM SIGIR Conference on Research and Development in Information Retrieval},
 series = {SIGIR '18},
 year = {2018},
 
 pages = {525--534},
 numpages = {10},
 acmid = {3210016},
 publisher = {ACM},
 keywords = {information retrieval, online applications, recommender systems, streaming data, user behaviour modeling},
} 

@inproceedings{Q_Wang2018,
 author = {Wang, Q. and Yin, H. and Hu, Z. and Lian, D. and Wang, H. and Huang, Z.},
 title = {Neural Memory Streaming Recommender Networks with Adversarial Training},
 booktitle = {Proc. of the 24th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
 series = {KDD '18},
 year = {2018},
 
 pages = {2467--2475},
 numpages = {9},
 acmid = {3220004},
 publisher = {ACM},
 keywords = {collaborative filtering, memory networks, streaming recommender systems},
}

@article{Karimi2018,
title = "News recommender systems - Survey and roads ahead",
journal = "Information Processing \& Management",
volume = "54",
number = "6",
pages = "1203 - 1227",
year = "2018",
author = "M. Karimi and D. Jannach and M. Jugovac",
keywords = "News recommender systems, Survey"
}

@inproceedings{LYang2018,
 author = {Yang, L. and Cui, Y. and X., Yuan and Wang, C. and Belongie, S. and Estrin, D.},
 title = {Unbiased Offline Recommender Evaluation for Missing-not-at-random Implicit Feedback},
 booktitle = {Proc. of the 12th ACM Conference on Recommender Systems},
 series = {RecSys '18},
 year = {2018},
 isbn = {978-1-4503-5901-6},
 url = {https://doi.org/10.1145/3240323.3240355},
 doi = {10.1145/3240323.3240355},
 pages = {279--287},
 numpages = {9},
 acmid = {3240355},
 publisher = {ACM},
 keywords = {bias, evaluation, implicit feedback, propensity, recommendation},
} 

@inproceedings{Pibiri2019,
 author = {Pibiri, G. E. and Petri, M. and Moffat, A.},
 title = {Fast Dictionary-Based Compression for Inverted Indexes},
 booktitle = {Proc. of the 12th ACM International Conference on Web Search and Data Mining},
 series = {WSDM '19},
 year = {2019},
 isbn = {978-1-4503-5940-5},
 
 pages = {6--14},
 numpages = {9},
 acmid = {3290962},
 publisher = {ACM},
 keywords = {compression, decoding, efficiency, inverted index},
} 


%%%%%%%%-----------------------
@article{Hanley1982,
author = {Hanley, J A and McNeil, B J},
title = {The meaning and use of the area under a receiver operating characteristic (ROC) curve.},
journal = {Radiology},
volume = {143},
number = {1},
pages = {29-36},
year = {1982},
doi = {10.1148/radiology.143.1.7063747},
    note ={PMID: 7063747},
URL = {https://doi.org/10.1148/radiology.143.1.7063747}
}

@article{Hiltz1985,
  title={Structuring computer-mediated communication systems to avoid information overload},
  author={Hiltz, Starr R and Turoff, Murray},
  journal={Communications of the ACM},
  volume={28},
  number={7},
  pages={680--689},
  year={1985},
  publisher={ACM}
}

@article{Goldberg1992,
 author = {Goldberg, David and Nichols, David and Oki, Brian M. and Terry, Douglas},
 title = {Using Collaborative Filtering to Weave an Information Tapestry},
 journal = {Commun. ACM},
 issue_date = {Dec. 1992},
 volume = {35},
 number = {12},
 month = dec,
 year = {1992},
 issn = {0001-0782},
 pages = {61--70},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/138859.138867},
 doi = {10.1145/138859.138867},
 acmid = {138867},
 publisher = {ACM},
 
 keywords = {information filtering, tapestry},
} 

@inproceedings{Resnick1994,
  title={GroupLens: an open architecture for collaborative filtering of netnews},
  author={Resnick, Paul and Iacovou, Neophytos and Suchak, Mitesh and Bergstrom, Peter and Riedl, John},
  booktitle={Proc of. the 1994 ACM Conference on Computer Supported Cooperative Work},
  pages={175--186},
  year={1994},
  organization={ACM}
}

@article{Resnick1997,
  title={Recommender systems},
  author={Resnick, Paul and Varian, Hal R},
  journal={Communications of the ACM},
  volume={40},
  number={3},
  pages={56--58},
  year={1997},
  publisher={ACM}
}

@inproceedings{Oard1998,
  title={Implicit feedback for recommender systems},
  author={Oard, Douglas W and Kim, Jinmook and others},
  booktitle={Proc of. the AAAI workshop on recommender systems},
  volume={83},
  year={1998}
}

@inproceedings{Breese1998,
 author = {Breese, John S. and Heckerman, David and Kadie, Carl},
 title = {Empirical Analysis of Predictive Algorithms for Collaborative Filtering},
 booktitle = {Proc of. the Fourteenth Conference on Uncertainty in Artificial Intelligence},
 series = {UAI'98},
 year = {1998},
 isbn = {1-55860-555-X},
 
 pages = {43--52},
 numpages = {10},
 url = {http://dl.acm.org/citation.cfm?id=2074094.2074100},
 acmid = {2074100},
 publisher = {Morgan Kaufmann Publishers Inc.},
 address = {San Francisco, CA, USA},
} 

@inproceedings{Karypis2001,
 author = {Karypis, George},
 title = {Evaluation of Item-Based Top-N Recommendation Algorithms},
 booktitle = {Proc of. the Tenth International Conference on Information and Knowledge Management},
 series = {CIKM '01},
 year = {2001},
 isbn = {1-58113-436-3},
 
 pages = {247--254},
 numpages = {8},
 url = {http://doi.acm.org/10.1145/502585.502627},
 doi = {10.1145/502585.502627},
 acmid = {502627},
 publisher = {ACM},
 
 keywords = {collaborative filtering, recommender system},
}

@article{Goldberg2001,
 author = {Goldberg, Ken and Roeder, Theresa and Gupta, Dhruv and Perkins, Chris},
 title = {Eigentaste: A Constant Time Collaborative Filtering Algorithm},
 journal = {Inf. Retr.},
 issue_date = {July 2001},
 volume = {4},
 number = {2},
 month = jul,
 year = {2001},
 issn = {1386-4564},
 pages = {133--151},
 numpages = {19},
 url = {https://doi.org/10.1023/A:1011419012209},
 doi = {10.1023/A:1011419012209},
 acmid = {594023},
 publisher = {Kluwer Academic Publishers},
 address = {Hingham, MA, USA},
 keywords = {collaborative filtering, dimensionality reduction, jokes, recommender systems},
}

@inproceedings{Rashid2002,
 author = {Rashid, Al Mamunur and Albert, Istvan and Cosley, Dan and Lam, Shyong K. and McNee, Sean M. and Konstan, Joseph A. and Riedl, John},
 title = {Getting to Know You: Learning New User Preferences in Recommender Systems},
 booktitle = {Proc of. the 7th International Conference on Intelligent User Interfaces},
 series = {IUI '02},
 year = {2002},
 isbn = {1-58113-459-2},
 
 pages = {127--134},
 numpages = {8},
 url = {http://doi.acm.org/10.1145/502716.502737},
 doi = {10.1145/502716.502737},
 acmid = {502737},
 publisher = {ACM},
 
 keywords = {collaborative filtering, entropy, information filtering, recommender systems, startup problem, user modeling},
} 

@inproceedings{Bodon2003,
  title={A fast APRIORI implementation},
  author={Bodon, Ferenc},
  year = {2003},
  series = {FIMI '03},
  booktitle = {Proc of. the 1st IEEE ICDM Workshop on Frequent Itemset Mining Implementations}
}

@article{Chellappa2005,
 author="Chellappa, Ramnath K.
 and Sin, Raymond G.",
 title="Personalization versus Privacy: An Empirical Examination of the Online Consumer's Dilemma",
 journal="Information Technology and Management",
 year="2005",
 month="Apr",
 day="01",
 volume="6",
 number="2",
 pages="181--202",
 issn="1573-7667",
 doi="10.1007/s10799-005-5879-y",
 url="https://doi.org/10.1007/s10799-005-5879-y"
}

@inproceedings{Ziegler2005,
 author = {Ziegler, Cai-Nicolas and McNee, Sean M. and Konstan, Joseph A. and Lausen, Georg},
 title = {Improving Recommendation Lists Through Topic Diversification},
 booktitle = {Proc of. the 14th International Conference on World Wide Web},
 series = {WWW '05},
 year = {2005},
 isbn = {1-59593-046-9},
 
 pages = {22--32},
 numpages = {11},
 url = {http://doi.acm.org/10.1145/1060745.1060754},
 doi = {10.1145/1060745.1060754},
 acmid = {1060754},
 publisher = {ACM},
 
 keywords = {accuracy, collaborative filtering, diversification, metrics, recommender systems},
} 

@misc{Yahoo2006,
  author = {Yahoo! Webscope},
  title = {Dataset ydata-ymusic-rating-study-vl},
  year = {2006},
  howpublished = {\url{https://webscope.sandbox.yahoo.com/catalog.php?datatype=r&did=3}}
}

@incollection{Pazzani2007,
 author = {Pazzani, Michael J. and Billsus, Daniel},
 chapter = {Content-based Recommendation Systems},
 title = {The Adaptive Web},
 editor = {Brusilovsky, Peter and Kobsa, Alfred and Nejdl, Wolfgang},
 year = {2007},
 isbn = {978-3-540-72078-2},
 pages = {325--341},
 numpages = {17},
 url = {http://dl.acm.org/citation.cfm?id=1768197.1768209},
 acmid = {1768209},
 publisher = {Springer-Verlag},
 address = {Berlin, Heidelberg},
} 

@incollection{Burke2007,
 author = {Burke, Robin},
 chapter = {Hybrid Web Recommender Systems},
 title = {The Adaptive Web},
 editor = {Brusilovsky, Peter and Kobsa, Alfred and Nejdl, Wolfgang},
 year = {2007},
 isbn = {978-3-540-72078-2},
 pages = {377--408},
 numpages = {32},
 url = {http://dl.acm.org/citation.cfm?id=1768197.1768211},
 acmid = {1768211},
 publisher = {Springer-Verlag},
 address = {Berlin, Heidelberg},
}

@inproceedings{NetflixPrize2007,
  title={The netflix prize},
  author={Bennett, James and Lanning, Stan and others},
  year={2007}
}

@article{Rashid2008,
 author = {Rashid, Al Mamunur and Karypis, George and Riedl, John},
 title = {Learning Preferences of New Users in Recommender Systems: An Information Theoretic Approach},
 journal = {SIGKDD Explor. Newsl.},
 issue_date = {December 2008},
 volume = {10},
 number = {2},
 month = dec,
 year = {2008},
 issn = {1931-0145},
 pages = {90--100},
 numpages = {11},
 url = {http://doi.acm.org/10.1145/1540276.1540302},
 doi = {10.1145/1540276.1540302},
 acmid = {1540302},
 publisher = {ACM},
 
}

@book{Bailey2008,
  title={Design of comparative experiments},
  author={Bailey, Rosemary A},
  volume={25},
  year={2008},
  publisher={Cambridge University Press}
}

@misc{Zafarani2009,
author = "Reza Zafarani and Huan Liu",
year = "2009",
title = "Social Computing Data Repository at {ASU}",
url = "http://socialcomputing.asu.edu",
institution = "Arizona State University, School of Computing, Informatics and Decision Systems Engineering"
}

@inproceedings{Cremonesi2010,
 author = {Cremonesi, Paolo and Koren, Yehuda and Turrin, Roberto},
 title = {Performance of Recommender Algorithms on Top-n Recommendation Tasks},
 booktitle = {Proc of. the Fourth ACM Conference on Recommender Systems},
 series = {RecSys '10},
 year = {2010},
 isbn = {978-1-60558-906-0},
 
 pages = {39--46},
 numpages = {8},
 url = {http://doi.acm.org/10.1145/1864708.1864721},
 doi = {10.1145/1864708.1864721},
 acmid = {1864721},
 publisher = {ACM},
 
 keywords = {evaluation, precision, recall, top-n recommendations},
} 

@inproceedings{Lathia2010,
 author = {Lathia, Neal and Hailes, Stephen and Capra, Licia and Amatriain, Xavier},
 title = {Temporal Diversity in Recommender Systems},
 booktitle = {Proc of. the 33rd International ACM SIGIR Conference on Research and Development in Information Retrieval},
 series = {SIGIR '10},
 year = {2010},
 isbn = {978-1-4503-0153-4},
 
 pages = {210--217},
 numpages = {8},
 url = {http://doi.acm.org/10.1145/1835449.1835486},
 doi = {10.1145/1835449.1835486},
 acmid = {1835486},
 publisher = {ACM},
 
 keywords = {evaluation, recommender systems},
} 

@misc{LastFM2010,
  author = {Last.FM},
  title = {Dataset Artist Plays - 360K users},
  year = {2010},
  howpublished = {\url{https://www.dtic.upf.edu/~ocelma/MusicRecommendationDataset/lastfm-360K.html}}
}

@inproceedings{Ge2010,
 author = {Ge, Mouzhi and Delgado-Battenfeld, Carla and Jannach, Dietmar},
 title = {Beyond Accuracy: Evaluating Recommender Systems by Coverage and Serendipity},
 booktitle = {Proc of. the Fourth ACM Conference on Recommender Systems},
 series = {RecSys '10},
 year = {2010},
 isbn = {978-1-60558-906-0},
 
 pages = {257--260},
 numpages = {4},
 url = {http://doi.acm.org/10.1145/1864708.1864761},
 doi = {10.1145/1864708.1864761},
 acmid = {1864761},
 publisher = {ACM},
 
 keywords = {coverage, evaluation metric, recommender system, serendipity},
} 

@inproceedings{Steck2010,
 author = {Steck, H.},
 title = {Training and Testing of Recommender Systems on Data Missing Not at Random},
 booktitle = {Proc. of the 16th ACM SIGKDD International Conference on Knowledge Discovery \& Data Mining},
 series = {KDD '10},
 year = {2010},
 isbn = {978-1-4503-0055-1},
 
 pages = {713--722},
 numpages = {10},
 acmid = {1835895},
 publisher = {ACM},
 keywords = {recommender systems},
} 

@inproceedings{Wang2010,
 author = {Wang, Hongning and Lu, Yue and Zhai, Chengxiang},
 title = {Latent Aspect Rating Analysis on Review Text Data: A Rating Regression Approach},
 booktitle = {Proc of. the 16th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
 series = {KDD '10},
 year = {2010},
 isbn = {978-1-4503-0055-1},
 
 pages = {783--792},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/1835804.1835903},
 doi = {10.1145/1835804.1835903},
 acmid = {1835903},
 publisher = {ACM},
 
 keywords = {algorithms, experimentation},
} 


@article{Pathak2010,
 author = {Pathak, Bhavik and Garfinkel, Robert and Gopal, Ram and Venkatesan, Rajkumar and Yin, Fang},
 title = {Empirical Analysis of the Impact of Recommender Systems on Sales},
 journal = {J. Manage. Inf. Syst.},
 issue_date = {Number 2 / Fall 2010},
 volume = {27},
 number = {2},
 month = oct,
 year = {2010},
 issn = {0742-1222},
 pages = {159--188},
 numpages = {30},
 url = {http://dx.doi.org/10.2753/MIS0742-1222270205},
 doi = {10.2753/MIS0742-1222270205},
 acmid = {2069586},
 publisher = {M. E. Sharpe, Inc.},
 address = {Armonk, NY, USA},
 keywords = {Collaborative Filtering, E-Tail, Electronic Commerce, Experience Goods, Recommender Systems},
} 

@inproceedings{Steck2011,
 author = {Steck, H.},
 title = {Item Popularity and Recommendation Accuracy},
 booktitle = {Proc. of the 5th ACM Conference on Recommender Systems},
 series = {RecSys '11},
 year = {2011},
 isbn = {978-1-4503-0683-6},
 
 pages = {125--132},
 numpages = {8},
 acmid = {2043957},
 publisher = {ACM},
 keywords = {recommender systems},
} 

@inproceedings{HetRec2011,
  author = {Cantador, Iv\'{a}n and Brusilovsky, Peter and Kuflik, Tsvi},
  title = {2nd Workshop on Information Heterogeneity and Fusion in Recommender Systems (HetRec 2011)},
  booktitle = {Proc of. the 5th ACM conference on Recommender systems},
  series = {RecSys 2011},
  year = {2011},
  
  publisher = {ACM},
  
  keywords = {information heterogeneity, information integration, recommender systems},
}

@inproceedings{Ning2011,
 author = {Ning, X. and Karypis, G.},
 title = {SLIM: Sparse Linear Methods for Top-N Recommender Systems},
 booktitle = {Proc. of the 2011 IEEE 11th International Conference on Data Mining},
 series = {ICDM '11},
 year = {2011},
 isbn = {978-0-7695-4408-3},
 pages = {497--506},
 numpages = {10},
 acmid = {2118303},
 publisher = {IEEE Computer Society},
 keywords = {Top-N Recommender Systems, Sparse Linear Methods, l1-norm Regularization},
} 

@inproceedings{McAuley2012,
 author = {McAuley, Julian and Leskovec, Jure and Jurafsky, Dan},
 title = {Learning Attitudes and Attributes from Multi-aspect Reviews},
 booktitle = {Proc of. the 2012 IEEE 12th International Conference on Data Mining},
 series = {ICDM '12},
 year = {2012},
 isbn = {978-0-7695-4905-7},
 pages = {1020--1025},
 numpages = {6},
 url = {http://dx.doi.org/10.1109/ICDM.2012.110},
 doi = {10.1109/ICDM.2012.110},
 acmid = {2472547},
 publisher = {IEEE Computer Society},
 address = {Washington, DC, USA},
 keywords = {machine learning, segmentation, summarization, sentiment analysis},
} 

@article{Pommeranz2012,
 author="Pommeranz, Alina
 and Broekens, Joost
 and Wiggers, Pascal
 and Brinkman, Willem-Paul
 and Jonker, Catholijn M.",
 title="Designing interfaces for explicit preference elicitation: a user-centered investigation of preference representation and elicitation process",
 journal="User Modeling and User-Adapted Interaction",
 year="2012",
 month="Oct",
 day="01",
 volume="22",
 number="4",
 pages="357--397",
 issn="1573-1391",
 doi="10.1007/s11257-011-9116-6",
 url="https://doi.org/10.1007/s11257-011-9116-6"
}

@article{Knijnenburg2012,
 author = {Knijnenburg, Bart P. and Willemsen, Martijn C. and Gantner, Zeno and Soncu, Hakan and Newell, Chris},
 title = {Explaining the User Experience of Recommender Systems},
 journal = {User Modeling and User-Adapted Interaction},
 issue_date = {October   2012},
 volume = {22},
 number = {4-5},
 month = oct,
 year = {2012},
 issn = {0924-1868},
 pages = {441--504},
 numpages = {64},
 url = {http://dx.doi.org/10.1007/s11257-011-9118-4},
 doi = {10.1007/s11257-011-9118-4},
 acmid = {2339919},
 publisher = {Kluwer Academic Publishers},
 address = {Hingham, MA, USA},
 keywords = {Decision support systems, Decision-making, Human-computer interaction, Preference elicitation, Privacy, Recommender systems, User experience, User testing, User-centric evaluation},
}

@article{Chapelle2012,
 author = {Chapelle, O. and Joachims, T. and Radlinski, F. and Yue, Y.},
 title = {Large-scale Validation and Analysis of Interleaved Search Evaluation},
 journal = {ACM Trans. Inf. Syst.},
 issue_date = {February 2012},
 volume = {30},
 number = {1},
 month = mar,
 year = {2012},
 issn = {1046-8188},
 pages = {6:1--6:41},
 articleno = {6},
 numpages = {41},
 url = {http://doi.acm.org/10.1145/2094072.2094078},
 doi = {10.1145/2094072.2094078},
 acmid = {2094078},
 publisher = {ACM},
 
 keywords = {Interleaving, clicks, judgments, online evaluation, search engine, sensitivity},
}

@inproceedings{Oord2013,
 author = {Oord, A\"{a}ron van den and Dieleman, Sander and Schrauwen, Benjamin},
 title = {Deep Content-based Music Recommendation},
 booktitle = {Proc of. the 26th International Conference on Neural Information Processing Systems - Volume 2},
 series = {NIPS'13},
 year = {2013},
 
 pages = {2643--2651},
 numpages = {9},
 url = {http://dl.acm.org/citation.cfm?id=2999792.2999907},
 acmid = {2999907},
 publisher = {Curran Associates Inc.},
 address = {USA},
} 

@inproceedings{Dooms2013,
  title={Movietweetings: a movie rating dataset collected from twitter},
  author={Dooms, Simon and De Pessemier, Toon and Martens, Luc},
  booktitle={Proc of. the Workshop on Crowdsourcing and Human Computation for Recommender Systems (CrowdRec)},
  year={2013}
}

@inproceedings{Zhong2013,
  title={Sharing the Loves: Understanding the How and Why of Online Content Curation.},
  author={Zhong, Changtao and Shah, Sunil and Sundaravadivelan, Karthik and Sastry, Nishanth},
  booktitle={Proc of. the Seventh International AAAI Conference on Weblogs and Social Media (ICWSM)},
  year={2013}
}

@inproceedings{Guo2013,
  author = {Guo, G. and Zhang, J. and Yorke-Smith, N.},
  title = {A Novel Bayesian Similarity Measure for Recommender Systems},
  booktitle = {Proc of. the 23rd International Joint Conference on Artificial Intelligence (IJCAI)},
  year = {2013},
  pages = {2619-2625}
}

@inproceedings{Liu2013,
 author = {Liu, Xin and Liu, Yong and Aberer, Karl and Miao, Chunyan},
 title = {Personalized Point-of-interest Recommendation by Mining Users' Preference Transition},
 booktitle = {Proc of. the 22Nd ACM International Conference on Information \& Knowledge Management},
 series = {CIKM '13},
 year = {2013},
 isbn = {978-1-4503-2263-8},
 
 pages = {733--738},
 numpages = {6},
 acmid = {2505639},
 publisher = {ACM},
 keywords = {location-based social networks, point-of-interest, recommendation, user preference},
} 

@inproceedings{Kille2013,
 author = {Kille, B. and Hopfgartner, F. and Brodt, T. and Heintz, T.},
 title = {The Plista Dataset},
 booktitle = {Proc of. the 2013 International News Recommender Systems Workshop and Challenge},
 series = {NRS '13},
 year = {2013},
 isbn = {978-1-4503-2302-4},
 
 pages = {16--23},
 numpages = {8},
 acmid = {2516643},
 publisher = {ACM},
 keywords = {dataset, news, recommender systems},
} 

@misc{Avazu2014,
  author = {Avazu},
  title = {Click-Through Rate Prediction dataset},
  year = {2014},
  howpublished = {\url{https://www.kaggle.com/c/avazu-ctr-prediction}}
}

@misc{Criteo2014,
  author = {Criteo},
  title = {Display Advertising Challenge dataset},
  year = {2014},
  howpublished = {\url{https://www.kaggle.com/c/criteo-display-ad-challenge}}
}

@inproceedings{Guo2014,
  author = {Guo, G. and Zhang, J. and Thalmann, D. and Yorke-Smith, N.},
  title = {ETAF: An Extended Trust Antecedents Framework for Trust Prediction},
  booktitle = {Proc of. the 2014 International Conference on Advances in Social Networks Analysis and Mining (ASONAM)},
  pages = {540-547},
  year = {2014}
} 

@inproceedings{Lee2014,
 author = {Lee, P. and Lakshmanan, L. and Tiwari, M. and Shah, S.},
 title = {Modeling Impression Discounting in Large-scale Recommender Systems},
 booktitle = {Proc. of the 20th ACM SIGKDD International Conference on Knowledge Discovery \& Data Mining},
 series = {KDD '14},
 year = {2014},
 isbn = {978-1-4503-2956-9},
 
 pages = {1837--1846},
 numpages = {10},
 acmid = {2623356},
 publisher = {ACM},
 keywords = {impression discounting, recommender system},
} 

@inproceedings{Zhao2015,
 author = {Zhao, Tong and McAuley, Julian and King, Irwin},
 title = {Improving Latent Factor Models via Personalized Feature Projection for One Class Recommendation},
 booktitle = {Proc of. the 24th ACM International on Conference on Information and Knowledge Management},
 series = {CIKM '15},
 year = {2015},
 isbn = {978-1-4503-3794-6},
 
 pages = {821--830},
 numpages = {10},
 acmid = {2806511},
 publisher = {ACM},
 
 keywords = {collaborative filtering, one-class recommendation, personalized feature projection},
} 

@article{Ghoshal2015,
author = {Abhijeet Ghoshal and Subodha Kumar and Vijay Mookerjee},
title = {Impact of Recommender System on Competition Between Personalizing and Non-Personalizing Firms},
journal = {Journal of Management Information Systems},
volume = {31},
number = {4},
pages = {243-277},
year  = {2015},
publisher = {Routledge},
doi = {10.1080/07421222.2014.1001276},
URL = { 
        https://doi.org/10.1080/07421222.2014.1001276
    
},
}

@article{Vinagre2015,
  author    = {J. Vinagre and
               A. Jorge and
               J. Gama},
  title     = {Evaluation of recommender systems in streaming environments},
  journal   = {CoRR},
  volume    = {abs/1504.08175},
  year      = {2015},
  url       = {http://arxiv.org/abs/1504.08175},
  archivePrefix = {arXiv},
  eprint    = {1504.08175},
}

@inproceedings{McAuley2015,
 author = {McAuley, Julian and Targett, Christopher and Shi, Qinfeng and van den Hengel, Anton},
 title = {Image-Based Recommendations on Styles and Substitutes},
 booktitle = {Proc of. the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval},
 series = {SIGIR '15},
 year = {2015},
 isbn = {978-1-4503-3621-5},
 
 pages = {43--52},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/2766462.2767755},
 doi = {10.1145/2766462.2767755},
 acmid = {2767755},
 publisher = {ACM},
 
 keywords = {metric learning, recommender systems, visual features},
}

@inproceedings{Ben-Shimon2015,
 author = {Ben-Shimon, David and Tsikinovsky, Alexander and Friedmann, Michael and Shapira, Bracha and Rokach, Lior and Hoerle, Johannes},
 title = {RecSys Challenge 2015 and the YOOCHOOSE Dataset},
 booktitle = {Proc of. the 9th ACM Conference on Recommender Systems},
 series = {RecSys '15},
 year = {2015},
 isbn = {978-1-4503-3692-5},
 
 pages = {357--358},
 numpages = {2},
 url = {http://doi.acm.org/10.1145/2792838.2798723},
 doi = {10.1145/2792838.2798723},
 acmid = {2798723},
 publisher = {ACM},
 
 keywords = {e-commerce, recommender systems, recsys challenge 2015, yoochoose},
} 

@inproceedings{Wang2015,
 author = {Wang, Hao and Wang, Naiyan and Yeung, Dit-Yan},
 title = {Collaborative Deep Learning for Recommender Systems},
 booktitle = {Proc of. the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
 series = {KDD '15},
 year = {2015},
 isbn = {978-1-4503-3664-2},
 
 pages = {1235--1244},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/2783258.2783273},
 doi = {10.1145/2783258.2783273},
 acmid = {2783273},
 publisher = {ACM},
 
 keywords = {deep learning, recommender systems, text mining, topic model},
} 

@article{Harper2015,
 author = {Harper, F. Maxwell and Konstan, Joseph A.},
 title = {The MovieLens Datasets: History and Context},
 journal = {ACM Trans. Interact. Intell. Syst.},
 issue_date = {January 2016},
 volume = {5},
 number = {4},
 month = dec,
 year = {2015},
 issn = {2160-6455},
 pages = {19:1--19:19},
 articleno = {19},
 numpages = {19},
 url = {http://doi.acm.org/10.1145/2827872},
 doi = {10.1145/2827872},
 acmid = {2827872},
 publisher = {ACM},
 
 keywords = {Datasets, MovieLens, ratings, recommendations},
}

@inproceedings{Swaminathan2015,
 author = {Swaminathan, A. and Joachims, T.},
 title = {Counterfactual Risk Minimization: Learning from Logged Bandit Feedback},
 booktitle = {Proc. of the 32nd International Conference on International Conference on Machine Learning},
 series = {ICML'15},
 year = {2015},
 
 pages = {814--823},
 numpages = {10},
 publisher = {JMLR.org},
} 

@inproceedings{Turrin2015,
  title={30Music Listening and Playlists Dataset.},
  author={Turrin, Roberto and Quadrana, Massimo and Condorelli, Andrea and Pagano, Roberto and Cremonesi, Paolo},
  year = {2015},
  url = {http://recsys.deib.polimi.it/?page_id=54}
}

@inproceedings{Christakopoulou2016,
 author = {Christakopoulou, E. and Karypis, G.},
 title = {Local Item-Item Models For Top-N Recommendation},
 booktitle = {Proc. of the 10th ACM Conference on Recommender Systems},
 series = {RecSys '16},
 year = {2016},
 isbn = {978-1-4503-4035-9},
 
 pages = {67--74},
 numpages = {8},
 acmid = {2959185},
 publisher = {ACM},
 keywords = {collaborative filtering, local models, slim, top-n recommendation},
} 

@inproceedings{Subbian2016,
 author = {Subbian, Karthik and Aggarwal, Charu and Hegde, Kshiteesh},
 title = {Recommendations For Streaming Data},
 booktitle = {Proc of. the 25th ACM International on Conference on Information and Knowledge Management},
 series = {CIKM '16},
 year = {2016},
 isbn = {978-1-4503-4073-1},
 
 pages = {2185--2190},
 numpages = {6},
 url = {http://doi.acm.org/10.1145/2983323.2983663},
 doi = {10.1145/2983323.2983663},
 acmid = {2983663},
 publisher = {ACM},
 
 keywords = {data streams, neighborhood model, recommender systems, streaming recommendations},
}

@inproceedings{Xie2016,
 author = {Xie, Huizhi and Aurisset, Juliette},
 title = {Improving the Sensitivity of Online Controlled Experiments: Case Studies at Netflix},
 booktitle = {Proc of. the 22Nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
 series = {KDD '16},
 year = {2016},
 isbn = {978-1-4503-4232-2},
 
 pages = {645--654},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/2939672.2939733},
 doi = {10.1145/2939672.2939733},
 acmid = {2939733},
 publisher = {ACM},
 
 keywords = {a/b testing, controlled experiment, randomized experiment, sensitivity, variance reduction},
}

@inproceedings{He2016,
 author = {He, Ruining and Fang, Chen and Wang, Zhaowen and McAuley, Julian},
 title = {Vista: A Visually, Socially, and Temporally-aware Model for Artistic Recommendation},
 booktitle = {Proc of. the 10th ACM Conference on Recommender Systems},
 series = {RecSys '16},
 year = {2016},
 isbn = {978-1-4503-4035-9},
 
 pages = {309--316},
 numpages = {8},
 url = {http://doi.acm.org/10.1145/2959100.2959152},
 doi = {10.1145/2959100.2959152},
 acmid = {2959152},
 publisher = {ACM},
 
 keywords = {Markov chains, artistic preferences, recommender systems},
} 

@Inbook{Aggarwal2016,
author="Aggarwal, Charu C.",
title="Evaluating Recommender Systems",
bookTitle="Recommender Systems: The Textbook",
year="2016",
publisher="Springer International Publishing",
pages="225--254",
}

@inproceedings{Brost2016,
 author = {Brost, B. and Cox, I. J. and Seldin, Y. and Lioma, C.},
 title = {An Improved Multileaving Algorithm for Online Ranker Evaluation},
 booktitle = {Proc. of the 39th International ACM SIGIR Conference on Research and Development in Information Retrieval},
 series = {SIGIR '16},
 year = {2016},
 isbn = {978-1-4503-4069-4},
 
 pages = {745--748},
 numpages = {4},
 publisher = {ACM},
 keywords = {multileaving, online ranker evaluation},
} 

@inproceedings{Li2017,
 author = {Li, X. and She, J.},
 title = {Collaborative Variational Autoencoder for Recommender Systems},
 booktitle = {Proc. of the 23rd ACM SIGKDD International Conference on Knowledge Discovery \& Data Mining},
 series = {KDD '17},
 year = {2017},
 isbn = {978-1-4503-4887-4},
 
 pages = {305--314},
 numpages = {10},
 acmid = {3098077},
 publisher = {ACM},
 keywords = {autoencoder, bayesian, deep learning, generative models, recommender systems, variational inference},
} 

@inproceedings{He2017,
 author = {He, R. and Kang, W. and McAuley, J.},
 title = {Translation-based Recommendation},
 booktitle = {Proc. of the 11th ACM Conference on Recommender Systems},
 series = {RecSys '17},
 year = {2017},
 isbn = {978-1-4503-4652-8},
 
 pages = {161--169},
 numpages = {9},
 acmid = {3109882},
 publisher = {ACM},
 keywords = {recommender systems, relation, sequential behavior, translation},
} 

@inproceedings{Ning2017,
 author = {Ning, Y. and Shi, Y. and Hong, L. and Rangwala, H. and Ramakrishnan, N.},
 title = {A Gradient-based Adaptive Learning Framework for Efficient Personal Recommendation},
 booktitle = {Proc. of the 11th ACM Conference on Recommender Systems},
 series = {RecSys '17},
 year = {2017},
 isbn = {978-1-4503-4652-8},
 
 pages = {23--31},
 numpages = {9},
 acmid = {3109909},
 publisher = {ACM},
 keywords = {content recommendation, gradient adaptation, personalization},
} 

@inproceedings{Otunba2017,
 author = {Otunba, R. and Rufai, R. and Lin, J.},
 title = {MPR: Multi-Objective Pairwise Ranking},
 booktitle = {Proc. of the 11th ACM Conference on Recommender Systems},
 series = {RecSys '17},
 year = {2017},
 isbn = {978-1-4503-4652-8},
 
 pages = {170--178},
 numpages = {9},
 acmid = {3109903},
 publisher = {ACM},
 keywords = {audience retrieval, collaborative filtering, recommendations},
}

@inproceedings{Abdollahpouri2017,
 author = {Abdollahpouri, Himan and Burke, Robin and Mobasher, Bamshad},
 title = {Controlling Popularity Bias in Learning-to-Rank Recommendation},
 booktitle = {Proc of. the Eleventh ACM Conference on Recommender Systems},
 series = {RecSys '17},
 year = {2017},
 isbn = {978-1-4503-4652-8},
 
 pages = {42--46},
 numpages = {5},
 url = {http://doi.acm.org/10.1145/3109859.3109912},
 doi = {10.1145/3109859.3109912},
 acmid = {3109912},
 publisher = {ACM},
 
 keywords = {coverage, learning to rank, long-tail, recommendation evaluation, recommender systems},
} 

@inbook{Onwuegbuzie2017,
author = {Onwuegbuzie, Anthony J. and Gerber, Hannah R. and Schamroth Abrams, Sandra},
publisher = {American Cancer Society},
isbn = {9781118901731},
title = {Mixed Methods Research},
booktitle = {The International Encyclopedia of Communication Research Methods},
chapter = {},
pages = {1-33},
doi = {10.1002/9781118901731.iecrm0156},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/9781118901731.iecrm0156},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/9781118901731.iecrm0156},
year = {2017}
}

@inproceedings{Pathak2017,
 author = {Pathak, Apurva and Gupta, Kshitiz and McAuley, Julian},
 title = {Generating and Personalizing Bundle Recommendations on Steam},
 booktitle = {Proc of. the 40th International ACM SIGIR Conference on Research and Development in Information Retrieval},
 series = {SIGIR '17},
 year = {2017},
 isbn = {978-1-4503-5022-8},
 
 pages = {1073--1076},
 numpages = {4},
 url = {http://doi.acm.org/10.1145/3077136.3080724},
 doi = {10.1145/3077136.3080724},
 acmid = {3080724},
 publisher = {ACM},
 
 keywords = {bpr, collaborative filtering, matrix factorization, steam bundle},
}

@misc{Yelp2017,
  author = {Yelp},
  title = {Business rating dataset},
  year = {2017},
  howpublished = {\url{https://www.kaggle.com/yelp-dataset/yelp-dataset}}
}

@misc{Reddit2017,
  author = {Reddit},
  title = {Crawl of comments and submissions},
  year = {2017},
  month = mar,
  howpublished = {\url{https://redd.it/6607j2}}
}

@misc{Outbrain2017,
  author = {Outbrain},
  title = {Click Prediction dataset},
  year = {2017},
  howpublished = {\url{https://www.kaggle.com/c/outbrain-click-prediction}}
}

@article{Wang2018,
 author = {Wang, Yue and Yin, Dawei and Jie, Luo and Wang, Pengyuan and Yamada, Makoto and Chang, Yi and Mei, Qiaozhu},
 title = {Optimizing Whole-Page Presentation for Web Search},
 journal = {ACM Trans. Web},
 issue_date = {July 2018},
 volume = {12},
 number = {3},
 month = jul,
 year = {2018},
 issn = {1559-1131},
 pages = {19:1--19:25},
 articleno = {19},
 numpages = {25},
 url = {http://doi.acm.org/10.1145/3204461},
 doi = {10.1145/3204461},
 acmid = {3204461},
 publisher = {ACM},
 
 keywords = {Whole-page optimization, user satisfaction},
} 

@inproceedings{Sepliarskaia2018,
 author = {Sepliarskaia, Anna and Kiseleva, Julia and Radlinski, Filip and de Rijke, Maarten},
 title = {Preference Elicitation As an Optimization Problem},
 booktitle = {Proc of. the 12th ACM Conference on Recommender Systems},
 series = {RecSys '18},
 year = {2018},
 isbn = {978-1-4503-5901-6},
 
 pages = {172--180},
 numpages = {9},
 url = {http://doi.acm.org/10.1145/3240323.3240352},
 doi = {10.1145/3240323.3240352},
 acmid = {3240352},
 publisher = {ACM},
 
 keywords = {cold start problem, mixed initiative search and recommendation, preference elicitation},
} 

@inproceedings{Bonner2018,
 author = {Bonner, S. and Vasile, F.},
 title = {Causal Embeddings for Recommendation},
 booktitle = {Proc. of the 12th ACM Conference on Recommender Systems},
 series = {RecSys '18},
 year = {2018},
 isbn = {978-1-4503-5901-6},
 
 pages = {104--112},
 numpages = {9},
 acmid = {3240360},
 publisher = {ACM},
 keywords = {causality, counterfactual inference, embeddings, neural networks, recommender systems},
} 

@inproceedings{JYang2018,
 author = {Yang, J. and Chen, C. and Wang, C. and Tsai, M.},
 title = {HOP-rec: High-order Proximity for Implicit Recommendation},
 booktitle = {Proc. of the 12th ACM Conference on Recommender Systems},
 series = {RecSys '18},
 year = {2018},
 isbn = {978-1-4503-5901-6},
 
 pages = {140--144},
 numpages = {5},
 acmid = {3240381},
 publisher = {ACM},
 keywords = {bipartite graph, collaborative filtering, implicit feedback, matrix factorization, random walks, top-N recommendation},
} 

@inproceedings{Zhang2018,
 author = {Zhang, Y. and Lu, H. and Niu, W. and Caverlee, J.},
 title = {Quality-aware Neural Complementary Item Recommendation},
 booktitle = {Proc of. the 12th ACM Conference on Recommender Systems},
 series = {RecSys '18},
 year = {2018},
 isbn = {978-1-4503-5901-6},
 
 pages = {77--85},
 numpages = {9},
 acmid = {3240368},
 publisher = {ACM},
 keywords = {complementary item, quality-aware, recommendation},
} 

@inproceedings{Christakopoulou2018,
 author = {Christakopoulou, E. and Karypis, G.},
 title = {Local Latent Space Models for Top-N Recommendation},
 booktitle = {Proc. of the 24th ACM SIGKDD International Conference on Knowledge Discovery \& Data Mining},
 series = {KDD '18},
 year = {2018},
 isbn = {978-1-4503-5552-0},
 
 pages = {1235--1243},
 numpages = {9},
 acmid = {3220112},
 publisher = {ACM},
 keywords = {clustering, collaborative filtering, latent space models, local models},
} 

@inproceedings{Chaney2018,
 author = {Chaney, A. and Stewart, B. and Engelhardt, B.},
 title = {How Algorithmic Confounding in Recommendation Systems Increases Homogeneity and Decreases Utility},
 booktitle = {Proc. of the 12th ACM Conference on Recommender Systems},
 series = {RecSys '18},
 year = {2018},
 isbn = {978-1-4503-5901-6},
 
 pages = {224--232},
 numpages = {9},
 acmid = {3240370},
 publisher = {ACM},
 keywords = {algorithmic confounding, recommendation systems},
} 

@inproceedings{Wan2018,
 author = {Wan, M. and McAuley, J.},
 title = {Item Recommendation on Monotonic Behavior Chains},
 booktitle = {Proc. of the 12th ACM Conference on Recommender Systems},
 series = {RecSys '18},
 year = {2018},
 isbn = {978-1-4503-5901-6},
 
 pages = {86--94},
 numpages = {9},
 acmid = {3240369},
 publisher = {ACM},
} 

@inproceedings{Misra2018,
 author = {Misra, R. and Wan, M. and McAuley, J.},
 title = {Decomposing Fit Semantics for Product Size Recommendation in Metric Spaces},
 booktitle = {Proc. of the 12th ACM Conference on Recommender Systems},
 series = {RecSys '18},
 year = {2018},
 isbn = {978-1-4503-5901-6},
 
 pages = {422--426},
 numpages = {5},
 acmid = {3240398},
 publisher = {ACM},
} 

@inproceedings{Zhao2018,
 author = {Zhao, Q. and Willemsen, M. C. and Adomavicius, G. and Harper, F. M. and Konstan, J. A.},
 title = {Interpreting User Inaction in Recommender Systems},
 booktitle = {Proc. of the 12th ACM Conference on Recommender Systems},
 series = {RecSys '18},
 year = {2018},
 isbn = {978-1-4503-5901-6},
 
 pages = {40--48},
 numpages = {9},
 acmid = {3240366},
 publisher = {ACM},
 keywords = {decision field theory, decision making, user inaction},
} 

@inproceedings{Sinha2016,
 author = {Sinha, A. and Gleich, D. and Ramani, K.},
 title = {Deconvolving Feedback Loops in Recommender Systems},
 booktitle = {Proc. of the 30th International Conference on Neural Information Processing Systems},
 series = {NIPS'16},
 year = {2016},
 isbn = {978-1-5108-3881-9},
 
 pages = {3251--3259},
 numpages = {9},
 acmid = {3157461},
 publisher = {Curran Associates Inc.},
} 

@inproceedings{Garcia-Gathright2018,
 author = {Garcia-Gathright, Jean and Hosey, Christine and Thomas, Brian St. and Carterette, Ben and Diaz, Fernando},
 title = {Mixed Methods for Evaluating User Satisfaction},
 booktitle = {Proc of. the 12th ACM Conference on Recommender Systems},
 series = {RecSys '18},
 year = {2018},
 isbn = {978-1-4503-5901-6},
 
 pages = {541--542},
 numpages = {2},
 publisher = {ACM},
 
 keywords = {evaluation, mixed methods, recommender systems, user behavior},
} 


@inproceedings{Jagerman2019,
 author = {Jagerman, R. and Markov, I. and de Rijke, M.},
 title = {When People Change Their Mind: Off-Policy Evaluation in Non-stationary Recommendation Environments},
 booktitle = {Proc. of the 12th ACM International Conference on Web Search and Data Mining},
 series = {WSDM '19},
 year = {2019},
 isbn = {978-1-4503-5940-5},
 
 pages = {447--455},
 numpages = {9},
 acmid = {3290958},
 publisher = {ACM},
 keywords = {non-stationary rewards, off-policy evaluation},
} 

@inproceedings{Jugovac2018,
 author = {Jugovac, M. and Jannach, D. and Karimi, M.},
 title = {Streamingrec: A Framework for Benchmarking Stream-based News Recommenders},
 booktitle = {Proc. of the 12th ACM Conference on Recommender Systems},
 series = {RecSys '18},
 year = {2018},
 isbn = {978-1-4503-5901-6},
 
 pages = {269--273},
 numpages = {5},
 acmid = {3240384},
 publisher = {ACM},
 keywords = {benchmarking, evaluation, news recommendation},
} 

@inproceedings{Basaran2017,
  title={Redundancies in Data and their Effect on the Evaluation of Recommendation Systems: A Case Study on the Amazon Reviews Datasets},
  author={Basaran, D. and Ntoutsi, E. and Zimek, A.},
  booktitle={Proc. of the 2017 SIAM International Conference on Data Mining},
  series = {SIAM DM '17},
  pages={390--398}, 
  year={2017},
  organization={SIAM}
}

@inproceedings{Zhao_2_2018,
 author = {Zhao, Q. and Chen, J. and Chen, M. and Jain, S. and Beutel, A. and Belletti, F. and Chi, E. H.},
 title = {Categorical-attributes-based Item Classification for Recommender Systems},
 booktitle = {Proc. of the 12th ACM Conference on Recommender Systems},
 series = {RecSys '18},
 year = {2018},
 isbn = {978-1-4503-5901-6},
 
 pages = {320--328},
 numpages = {9},
 acmid = {3240367},
 publisher = {ACM},
 keywords = {hierarchical classification, hierarchical softmax, multi-task learning, recommender systems},
} 

@inproceedings{Paudel2017,
 author = {Paudel, B. and Haas, T. and Bernstein, A.},
 title = {Fewer Flops at the Top: Accuracy, Diversity, and Regularization in Two-Class Collaborative Filtering},
 booktitle = {Proc. of the 11th ACM Conference on Recommender Systems},
 series = {RecSys '17},
 year = {2017},
 isbn = {978-1-4503-4652-8},
 
 pages = {215--223},
 numpages = {9},
 acmid = {3109916},
 publisher = {ACM},
 keywords = {collaborative filtering, diverse recommendations, matrix factorization, positive and negative recommendations},
} 

@inproceedings{Song2015,
 author = {Song, D. and Meyer, David A.},
 title = {Recommending Positive Links in Signed Social Networks by Optimizing a Generalized AUC},
 booktitle = {Proc. of the 29th AAAI Conference on Artificial Intelligence},
 series = {AAAI'15},
 year = {2015},
 isbn = {0-262-51129-0},
 
 pages = {290--296},
 numpages = {7},
 acmid = {2887048},
 publisher = {AAAI Press},
} 

@inproceedings{Hsieh2017,
 author = {Hsieh, C. and Yang, L. and Cui, Y. and Lin, T. and Belongie, S. and Estrin, D.},
 title = {Collaborative Metric Learning},
 booktitle = {Proc. of the 26th International Conference on World Wide Web},
 series = {WWW '17},
 year = {2017},
 isbn = {978-1-4503-4913-0},
 
 pages = {193--201},
 numpages = {9},
 acmid = {3052639},
 publisher = {International World Wide Web Conferences Steering Committee},
 keywords = {collaborative filtering, collaborative metric learning, metric learning, recommendation systems},
} 

@inproceedings{JeunenDS2019,
 author = {Jeunen, O.},
 title = {Revisiting Offline Evaluation for Implicit-feedback Recommender Systems},
 booktitle = {Proc. of the 13th ACM Conference on Recommender Systems},
 series = {RecSys '19},
 year = {2019},
 isbn = {978-1-4503-6243-6},
 pages = {596--600},
 numpages = {5},
 publisher = {ACM},
 keywords = {counterfactual evaluation, implicit feedback, offline evaluation},
 url = {https://doi.org/10.1145/3298689.3347069},
} 


@article{Jensen1906,
  title={Sur les fonctions convexes et les in{\'e}galit{\'e}s entre les valeurs moyennes},
  author={Jensen, J. L. W. V. and others},
  journal={Acta Mathematica},
  volume={30},
  pages={175--193},
  year={1906},
  publisher={Institut Mittag-Leffler}
}

@misc{Brockman2016,
  url = {https://arxiv.org/abs/1606.01540},
  author={Brockman, G. and Cheung, V. and Pettersson, L. and Schneider, J. and Schulman, J. and Tang, J. and Zaremba, W.},
  title = {OpenAI Gym},
  publisher = {arXiv},
  year = {2016}
}

@article{Kelly1956,
  title={A New Interpretation of Information Rate},
  author={Kelly, J.},
  journal={the Bell System Technical Journal},
  year={1956}
}

@inproceedings{Mnih2016,
 author = {Mnih, V. and Badia, A. and Mirza, M. and Graves, A. and Harley, T. and Lillicrap, T. and Silver, D. and Kavukcuoglu, K.},
 title = {Asynchronous Methods for Deep Reinforcement Learning},
 booktitle = {Proc. of the 33rd International Conference on Machine Learning},
 series = {ICML'16},
 year = {2016},
 pages = {1928--1937},
 numpages = {10},
 acmid = {3045594},
 publisher = {JMLR.org},
} 

@article{Williams1991,
author = {Williams, R. and  Peng, J.},
title = {Function Optimization using Connectionist Reinforcement Learning Algorithms},
journal = {Connection Science},
volume = {3},
number = {3},
pages = {241-268},
year  = {1991},
publisher = {Taylor & Francis},
}

@misc{Singh2019,
    title={Policy Learning for Fairness in Ranking},
    author={Singh, A. and Joachims, T.},
    year={2019},
    eprint={1902.04056},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}



@inproceedings{Ktena2019,
 author = {Ktena, S. and Tejani, A. and Theis, L. and Myana, P. and Dilipkumar, D. and Husz\'{a}r, F. and Yoo, S. and Shi, W.},
 title = {Addressing Delayed Feedback for Continuous Training with Neural Networks in CTR Prediction},
 booktitle = {Proc. of the 13th ACM Conference on Recommender Systems},
 series = {RecSys '19},
 year = {2019},
 isbn = {978-1-4503-6243-6},
 
 pages = {187--195},
 numpages = {9},
 acmid = {3347002},
 publisher = {ACM},
 keywords = {delayed feedback, fake negatives, recommender systems},
} 

@inproceedings{Ma2020,
 author = {Ma, J. and Zhao, Z. and Yi, X. and Yang, J. and Chen, M. and Tang, J. and Hong, L. and Chi, E. H.},
 title = {Off-Policy Learning in Two-Stage Recommender Systems},
 booktitle = {Proc. of the 2020 World Wide Web Conference},
 series = {WWW '20},
 year = {2020},
 publisher = {ACM},
url = {https://doi.org/10.1145/3366423.3380130},
doi = {10.1145/3366423.3380130}
} 

@article{Williams1992,
author = {Williams, R. J.},
title = {Simple Statistical Gradient-Following Algorithms for Connectionist Reinforcement Learning},
year = {1992},
issue_date = {May 1992},
publisher = {Kluwer Academic Publishers},
volume = {8},
number = {34},
issn = {0885-6125},
journal = {Machine Learning},
month = may,
pages = {229256},
numpages = {28},
keywords = {connectionist networks, Reinforcement learning, mathematical analysis, gradient descent}
}
  
@inproceedings{Li2010,
author = {Li, L. and Chu, W. and Langford, J. and Schapire, R. E.},
title = {A Contextual-Bandit Approach to Personalized News Article Recommendation},
year = {2010},
isbn = {9781605587998},
publisher = {ACM},
booktitle = {Proc. of the 19th International Conference on World Wide Web},
pages = {661670},
numpages = {10},
keywords = {recommender systems, web service, contextual bandit, exploration/exploitation dilemma, personalization},
series = {WWW 10}
}
  
@inproceedings{Chapelle2011,
author = {Chapelle, O. and Li, L.},
title = {An Empirical Evaluation of Thompson Sampling},
year = {2011},
isbn = {9781618395993},
booktitle = {Proc. of the 24th International Conference on Neural Information Processing Systems},
pages = {22492257},
numpages = {9},
series = {NIPS11}
}
  
@inproceedings{Dumitrascu2018,
author = {Dumitrascu, B. and Feng, K. and Engelhardt, B. E.},
title = {PG-TS: Improved Thompson Sampling for Logistic Contextual Bandits},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
booktitle = {Proc. of the 32nd International Conference on Neural Information Processing Systems},
pages = {46294638},
numpages = {10},

series = {NIPS18}
}
  
  
@inproceedings{Steck2019,
author = {Steck, H.},
title = {Embarrassingly Shallow Autoencoders for Sparse Data},
year = {2019},
isbn = {9781450366748},
publisher = {ACM},
booktitle = {The World Wide Web Conference},
pages = {32513257},
numpages = {7},
keywords = {Neighborhood Approach, Closed-Form Solution, Recommender System, Collaborative Filtering, Autoencoder, Linear Regression},
series = {WWW 19}
}
  

@inproceedings{Shenbin2020,
author = {Shenbin, I. and Alekseev, A. and Tutubalina, E. and Malykh, V. and Nikolenko, S. I.},
title = {RecVAE: A New Variational Autoencoder for Top-N Recommendations with Implicit Feedback},
year = {2020},
isbn = {9781450368223},
publisher = {ACM},
booktitle = {Proc. of the 13th International Conference on Web Search and Data Mining},
pages = {528536},
numpages = {9},
keywords = {deep learning, collaborative filtering, variational autoencoders},
series = {WSDM 20}
}
  
@inproceedings{Li2016,
author = {Li, S. and Karatzoglou, A. and Gentile, C.},
title = {Collaborative Filtering Bandits},
year = {2016},
isbn = {9781450340694},
publisher = {ACM},
booktitle = {Proc. of the 39th International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {539548},
numpages = {10},
keywords = {recommender systems, clustering, filtering and recommending, collaborative filtering, regret, bandits, online learning, computational advertising},
series = {SIGIR 16}
}
  
@incollection{Paszke2019,
title = {PyTorch: An Imperative Style, High-Performance Deep Learning Library},
author = {Paszke, A. and Gross, S. and Massa, F. and Lerer, A. and Bradbury, J. and Chanan, G. and Killeen, T. and Lin, Z. and Gimelshein, N. and Antiga, L. and Desmaison, A. and Kopf, A. and Yang, E. and DeVito, Z. and Raison, M. and Tejani, A. and Chilamkurthy, S. and Steiner, B. and Fang, L. and Bai, J. and Chintala, S.},
booktitle = {Advances in Neural Information Processing Systems 32},
pages = {8026--8037},
year = {2019},
}

@inproceedings{Sakhi2020,
 author = {Sakhi, O. and Bonner, S. and Rohde, D. and Vasile, F.},
 title = {BLOB : A Probabilistic Model for Recommendation that Combines Organic and Bandit Signals},
 booktitle = {Proc. of the 26th ACM Conference on Knowledge Discovery \& Data Mining},
 series = {KDD '20},
 year = {2020},
 publisher = {ACM},
url = {https://doi.org/10.1145/3394486.3403121},
doi = {10.1145/3394486.3403121}
} 



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% BIDDING %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
@inproceedings{Wu2018,
author = {Wu, D. and Chen, X. and Yang, X. and Wang, H. and Tan, Q. and Zhang, X. and Xu, J. and Gai, K.},
title = {Budget Constrained Bidding by Model-Free Reinforcement Learning in Display Advertising},
year = {2018},
isbn = {9781450360142},
publisher = {ACM},
abstract = {Real-time bidding (RTB) is an important mechanism in online display advertising, where a proper bid for each page view plays an essential role for good marketing results. Budget constrained bidding is a typical scenario in RTB where the advertisers hope to maximize the total value of the winning impressions under a pre-set budget constraint. However, the optimal bidding strategy is hard to be derived due to the complexity and volatility of the auction environment. To address these challenges, in this paper, we formulate budget constrained bidding as a Markov Decision Process and propose a model-free reinforcement learning framework to resolve the optimization problem. Our analysis shows that the immediate reward from environment is misleading under a critical resource constraint. Therefore, we innovate a reward function design methodology for the reinforcement learning problems with constraints. Based on the new reward design, we employ a deep neural network to learn the appropriate reward so that the optimal policy can be learned effectively. Different from the prior model-based work, which suffers from the scalability problem, our framework is easy to be deployed in large-scale industrial applications. The experimental evaluations demonstrate the effectiveness of our framework on large-scale real datasets.},
booktitle = {Proc. of the 27th ACM International Conference on Information and Knowledge Management},
pages = {14431451},
numpages = {9},
keywords = {bid optimization, display advertising, reinforcement learning, rtb},
series = {CIKM '18}
}

@inproceedings{Zhang2021,
author = {Zhang, W. and Kitts, B. and Han, Y. and Zhou, Z. and Mao, T. and He, H. and Pan, S. and Flores, A. and Gultekin, S. and Weissman, T.},
title = {MEOW: A Space-Efficient Nonparametric Bid Shading Algorithm},
year = {2021},
isbn = {9781450383325},
publisher = {ACM},
booktitle = {Proc. of the 27th ACM SIGKDD Conference on Knowledge Discovery \& Data Mining},
pages = {39283936},
numpages = {9},
keywords = {shading, bid, advertising, optimization, auction, online bidding},
series = {KDD '21}
}

@inproceedings{Pan2020,
author = {Pan, S. and Kitts, B. and Zhou, T. and He, H. and Shetty, B. and Flores, a. and Gligorijevic, D. and Pan, J. and Mao, T. and Gultekin, S. and Zhang, J.},
title = {Bid Shading by Win-Rate Estimation and Surplus Maximization},
year = {2020},
publisher = {ACM},
booktitle = {Proc. of the AdKDD Workshop at the 26th ACM SIGKDD Conference on Knowledge Discovery \& Data Mining},
series = {AdKDD '20}
}

@inproceedings{Zhou2021,
author = {Zhou, T. and He, H. and Pan, S. and Karlsson, N. and Shetty, B. and Kitts, B. and Gligorijevic, D. and Gultekin, S. and Mao, T. and Pan, J. and Zhang, J. and Flores, A.},
title = {An Efficient Deep Distribution Network for Bid Shading in First-Price Auctions},
year = {2021},
isbn = {9781450383325},
publisher = {ACM},
booktitle = {Proc. of the 27th ACM SIGKDD Conference on Knowledge Discovery \& Data Mining},
pages = {39964004},
numpages = {9},
keywords = {display advertising, real-time bidding, online auction, distribution learning, bid shading},
series = {KDD '21}
}

@InProceedings{Xu2019,
  title = 	 {Variance reduction properties of the reparameterization trick},
  author =       {Xu, M. and Quiroz, M. and Kohn, R. and Sisson, S. A.},
  booktitle = 	 {Proc. of the 22nd International Conference on Artificial Intelligence and Statistics},
  pages = 	 {2711--2720},
  year = 	 {2019},
  volume = 	 {89},
  series = 	 {AISTATS '19},
  publisher =    {PMLR}
}

@misc{Kingma2013,
  author = {Kingma, D. P. and Welling, M.},
  title = {Auto-Encoding Variational Bayes},
  publisher = {arXiv},
  year = {2013},
  url = {https://arxiv.org/abs/1312.6114}
}

@inproceedings{Kingma2015,
	author = {Kingma, D. P and Salimans, T. and Welling, M.},
	booktitle = {Advances in Neural Information Processing Systems},
	title = {Variational Dropout and the Local Reparameterization Trick},
	volume = {28},
	year = {2015},
	series={NeurIPS '15}
}

@InProceedings{Haarnoja2018,
  title = 	 {Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor},
  author =       {Haarnoja, T. and Zhou, A. and Abbeel, P. and Levine, S.},
  booktitle = 	 {Proc. of the 35th International Conference on Machine Learning},
  pages = 	 {1861--1870},
  year = 	 {2018},
  volume = 	 {80},
  series = 	 {ICML '18},
  publisher =    {PMLR}
}

@article{McDowell2003,
	author = {A. McDowell},
	journal = {The Stata Journal},
	number = {2},
	pages = {178-184},
	title = {From the Help Desk: Hurdle Models},
	volume = {3},
	year = {2003}
}

@misc{Schulman2017,
  url = {https://arxiv.org/abs/1707.06347},
  author = {Schulman, J. and Wolski, F. and Dhariwal, P. and Radford, A. and Klimov, O.},
  title = {Proximal Policy Optimization Algorithms},
  publisher = {arXiv},
  year = {2017}
}

@InProceedings{Schulman2015,
  title = 	 {Trust Region Policy Optimization},
  author = 	 {Schulman, J. and Levine, S. and Abbeel, P. and Jordan, M. and Moritz, P.},
  booktitle = 	 {Proc. of the 32nd International Conference on Machine Learning},
  pages = 	 {1889--1897},
  year = 	 {2015},
  volume = 	 {37},
  series = 	 {ICML '15},
  publisher =    {PMLR}
}

@inproceedings{Faury2020,
 author = {Faury, L. and Tanielian, U. and Vasile, F. and Smirnova, E. and Dohmatob, E.},
 title = {Distributionally Robust Counterfactual Risk Minimization},
 booktitle = {Proc. of the 34th AAAI Conference on Artificial Intelligence},
 series = {AAAI '20},
 year = {2020},
 publisher = {AAAI Press},
} 

@inproceedings{Si2020,
  title={Distributionally Robust Policy Evaluation and Learning in Offline Contextual Bandits},
  author={Si, N. and Zhang, F. and Zhou, Z. and Blanchet, J.},
  booktitle={International Conference on Machine Learning},
  publisher={PMLR},
  series={ICML '20},
  year={2020}
}

 @inproceedings{Jeunen2020REVEAL,
    title={An Empirical Evaluation of Doubly Robust Learning for Recommendation},
    author={Jeunen, O. and Goethals, B.},
    year={2020},
    booktitle = {Proc. of the ACM RecSys Workshop on Bandit Learning from User Interactions},
    series={REVEAL '20}
}

@InProceedings{Su2020_ICML,
title = {Doubly robust off-policy evaluation with shrinkage},
author = {Su, Y. and Dimakopoulou, M. and Krishnamurthy, A. and Dudik, M.},
booktitle = {Proc. of the 37th International Conference on Machine Learning}, 
pages = {9167--9176}, 
year = {2020}, 
publisher = {PMLR}, 
series={ICML '20}
}


@InProceedings{Su2020_Adaptive,
  title = 	 {Adaptive Estimator Selection for Off-Policy Evaluation},
  author =       {Su, Y. and Srinath, P. and Krishnamurthy, A.},
  booktitle = 	 {Proc of. the 37th International Conference on Machine Learning},
  pages = 	 {9196--9205},
  year = 	 {2020},
  volume = 	 {119},
  series = 	 {ICML '20},
  month = 	 {13--18 Jul},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v119/su20d/su20d.pdf},
  url = 	 {https://proceedings.mlr.press/v119/su20d.html},
}


@inproceedings{He2014,
author = {He, X. and Pan, J.and Jin, O. and Xu, T. and Liu, B. and Xu, T. and Shi, Y. and Atallah, A. and Herbrich, R. and Bowers, S. and Candela, J. Q.},
title = {Practical Lessons from Predicting Clicks on Ads at Facebook},
year = {2014},
publisher = {ACM},
booktitle = {Proc. of the 8th International Workshop on Data Mining for Online Advertising},
pages = {19},
numpages = {9},
series = {ADKDD'14}
}

@inproceedings{Wang2017,
author = {Wang, R. and Fu, B. and Fu, G. and Wang, M.},
title = {Deep \& Cross Network for Ad Click Predictions},
year = {2017},
isbn = {9781450351942},
publisher = {ACM},
booktitle = {Proc. of ADKDD'17},
articleno = {12},
numpages = {7},
keywords = {Neural Networks, Feature Crossing, Deep Learning, CTR Prediction},
series = {ADKDD'17}
}

@inproceedings{Wang2021,
author = {Wang, R. and Shivanna, R. and Cheng, D. and Jain, S. and Lin, D. and Hong, L. and Chi, E.},
title = {DCN V2: Improved Deep \& Cross Network and Practical Lessons for Web-Scale Learning to Rank Systems},
year = {2021},
isbn = {9781450383127},
publisher = {ACM},
booktitle = {Proc. of the Web Conference},
pages = {17851797},
numpages = {13},
series = {WWW '21}
}

@inproceedings{Jeunen2021A,
author = {Jeunen, O. and Goethals, B.},
title = {Pessimistic Reward Models for Off-Policy Learning in Recommendation},
year = {2021},
publisher = {ACM},
booktitle = {Proc. of the Fifteenth ACM Conference on Recommender Systems},
url = {https://doi.org/10.1145/3460231.3474247},
series={RecSys '21},
pages = {6374},
numpages = {12}
}

@inproceedings{Jeunen2021B,
author = {Jeunen, O. and Goethals, B.},
title = {Top-K Contextual Bandits with Equity of Exposure},
year = {2021},
isbn = {9781450384582},
publisher = {ACM},

url = {https://doi.org/10.1145/3460231.3474248},
doi = {10.1145/3460231.3474248},
abstract = {The contextual bandit paradigm provides a general framework for decision-making under uncertainty. It is theoretically well-defined and well-studied, and many personalisation use-cases can be cast as a bandit learning problem. Because this allows for the direct optimisation of utility metrics that rely on online interventions (such as click-through-rate (CTR)), this framework has become an attractive choice to practitioners. Historically, the literature on this topic has focused on a one-sided, user-focused notion of utility, overall disregarding the perspective of content providers in online marketplaces (for example, musical artists on streaming services). If not properly taken into account  recommendation systems in such environments are known to lead to unfair distributions of attention and exposure, which can directly affect the income of the providers. Recent work has shed a light on this, and there is now a growing consensus that some notion of equity of exposure might be preferable to implement in many recommendation use-cases. We study how the top-K contextual bandit problem relates to issues of disparate exposure, and how this disparity can be minimised. The predominant approach in practice is to greedily rank the top-K items according to their estimated utility, as this is optimal according to the well-known Probability Ranking Principle. Instead, we introduce a configurable tolerance parameter that defines an acceptable decrease in utility for a maximal increase in fairness of exposure. We propose a personalised exposure-aware arm selection algorithm that handles this relevance-fairness trade-off on a user-level, as recent work suggests that users openness to randomisation may vary greatly over the global populace. Our model-agnostic algorithm deals with arm selection instead of utility modelling, and can therefore be implemented on top of any existing bandit system with minimal changes. We conclude with a case study on carousel personalisation in music recommendation: empirical observations highlight the effectiveness of our proposed method and show that exposure disparity can be significantly reduced with a negligible impact on user utility.},
booktitle = {Proc of. the 15th ACM Conference on Recommender Systems},
pages = {310320},
numpages = {11},
keywords = {Probabilistic Models, Fairness},

series = {RecSys '21}
}


@inproceedings{JeunenKDD2020,
 author = {Jeunen, O. and Rohde, D. and Vasile, F. and Bompaire, M.},
 title = {Joint Policy-Value Learning for Recommendation},
 booktitle = {Proc. of the 26th ACM SIGKDD International Conference on Knowledge Discovery \& Data Mining},
 series = {KDD '20},
 url = {https://doi.org/10.1145/3394486.3403175},
 year = {2020},
 publisher = {ACM},
 pages = {1223-1233},
 numpages = {11}
 }
 
 
@inbook{Goodhart1984,
	address = {London},
	author = {Goodhart, C. A. E.},
	pages = {91--121},
	publisher = {Macmillan Education UK},
	title = {Problems of Monetary Management: The UK Experience},
	year = {1984}
}

@article{Strathern1997,
title={Improving ratings: audit in the British University system},
volume={5},
number={3},
journal={European Review},
publisher={Cambridge University Press},
author={Strathern, M.},
year={1997},
pages={305321}}

@inproceedings{Ekstrand2021,
author = {Ekstrand, M. D. and Chaney, A. and Castells, P. and Burke, R. and Rohde, D. and Slokom, M.},
title = {SimuRec: Workshop on Synthetic Data and Simulation Methods for Recommender Systems Research},
year = {2021},
publisher = {ACM},
booktitle = {Proc. of the Fifteenth ACM Conference on Recommender Systems},
pages = {803805},
numpages = {3},
series={RecSys '21}
}

@inproceedings{Bendada2020,
author = {Bendada, W. and Salha, G. and Bontempelli, T.},
title = {Carousel Personalization in Music Streaming Apps with Contextual Bandits},
year = {2020},
publisher = {ACM},
booktitle = {Proc. of the 14th ACM Conference on Recommender Systems},
pages = {420425},
numpages = {6},
series={RecSys '20},
url = {https://doi.org/10.1145/3383313.3412217},
doi = {10.1145/3383313.3412217}
}

@article{Malkov2020,
author={Malkov, Y. A. and Yashunin, D. A.},
journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
title={Efficient and Robust Approximate Nearest Neighbor Search Using Hierarchical Navigable Small World Graphs},
year={2020},  volume={42},  number={4}, pages={824-836}
}

@InProceedings{Duetting2019,
  title = 	 {Optimal Auctions through Deep Learning},
  author =       {Duetting, P. and Feng, Z. and Narasimhan, H. and Parkes, D. and Ravindranath, S. S.},
  booktitle = 	 {Proc. of the 36th International Conference on Machine Learning},
  pages = 	 {1706--1715},
  year = 	 {2019},
  volume = 	 {97},
  series = 	 {ICML '19},
  publisher =    {PMLR}
}

@article{Rahme2021,
  url = {https://arxiv.org/abs/2006.05684},
  author = {Rahme, J. and Jelassi, S. and Weinberg, S. M.},
  title = {Auction learning as a two-player game},
  publisher = {arXiv},
  year = {2021},
  journal={The 9th International Conference on Learning Representations (ICLR '21)}
}

@inproceedings{Liu2021,
author = {Liu, X. and Yu, C. and Zhang, Z. and Zheng, Z. and Rong, Y. and Lv, H. and Huo, D. and Wang, Y. and Chen, D. and Xu, J. and Wu, F. and Chen, G. and Zhu, X.},
title = {Neural Auction: End-to-End Learning of Auction Mechanisms for E-Commerce Advertising},
year = {2021},
isbn = {9781450383325},
publisher = {ACM},
booktitle = {Proc. of the 27th ACM SIGKDD Conference on Knowledge Discovery \& Data Mining},
pages = {33543364},
numpages = {11},
keywords = {neural auction, e-commerce advertising, learning-based mechanism design},
series = {KDD '21}
}

@article{Vickrey1961,
	author = {Vickrey, W.},
	journal = {The Journal of Finance},
	number = {1},
	pages = {8-37},
	title = {Counterspeculation, Auctions, and Competitive Sealed Tenders},
	volume = {16},
	year = {1961}
}
	
	
@article{Myerson1981,
	author = {Myerson, R. B.},
	journal = {Mathematics of Operations Research},
	number = {1},
	pages = {58-73},
	title = {Optimal Auction Design},
	volume = {6},
	year = {1981}
}

@inproceedings{Gligorijevic2020,
author = {Gligorijevic, D. and Zhou, T. and Shetty, B. and Kitts, B. and Pan, S. and Pan, J. and Flores, A.},
title = {Bid Shading in The Brave New World of First-Price Auctions},
year = {2020},
isbn = {9781450368599},
publisher = {ACM},
booktitle = {Proc. of the 29th ACM International Conference on Information \& Knowledge Management},
pages = {24532460},
numpages = {8},
keywords = {bid shading, online bidding, factorization machines},
series = {CIKM '20}
}

@inproceedings{Yang2019,
author = {Yang, X. and Li, Y. and Wang, H. and Wu, D. and Tan, Q. and Xu, J. and Gai, K.},
title = {Bid Optimization by Multivariable Control in Display Advertising},
year = {2019},
publisher = {ACM},
booktitle = {Proc. of the 25th ACM SIGKDD International Conference on Knowledge Discovery \& Data Mining},
pages = {19661974},
numpages = {9},
series = {KDD '19}
}

@INPROCEEDINGS{Karlsson2021,  author={Karlsson, N. and Sang, Q.}, 
booktitle={2021 American Control Conference (ACC)}, 
title={Adaptive Bid Shading Optimization of First-Price Ad Inventory}, 
year={2021},  pages={4983-4990}
}

@inproceedings{Liu2020,
	author = {Liu, X. and Han, X. and Z., N. and Liu, Q.},
	booktitle = {Advances in Neural Information Processing Systems},
	series={NeurIPS '20},
	editor = {H. Larochelle and M. Ranzato and R. Hadsell and M.F. Balcan and H. Lin},
	pages = {15427--15438},
	title = {Certified Monotonic Neural Networks},
	volume = {33},
	year = {2020}
}

@inproceedings{Zhang2021_DeepGSP,
author = {Zhang, Z. and Liu, X. and Zheng, Z. and Zhang, C. and Xu, M. and Pan, J. and Yu, C. and Wu, F. and Xu, J. and Gai, K.},
title = {Optimizing Multiple Performance Metrics with Deep GSP Auctions for E-Commerce Advertising},
year = {2021},
publisher = {ACM},
booktitle = {Proc. of the 14th ACM International Conference on Web Search and Data Mining},
pages = {9931001},
numpages = {9},
series = {WSDM '21}
}


@article{Harris2020,
	author = {Harris, C. R. and Millman, K. J. and van der Walt, S. J. and Gommers, R. and Virtanen, P. and Cournapeau, D. and Wieser, E. and Taylor, J. and Berg, S. and Smith, N. J. and Kern, R. and Picus, M. and Hoyer, S. and van Kerkwijk, M. H. and Brett, M. and Haldane, A. and del R{\'\i}o, J. F. and Wiebe, M. and Peterson, P. and G{\'e}rard-Marchant, P. and Sheppard, K. and Reddy, T. and Weckesser, W. and Abbasi, H. and G., C. and Oliphant, T. E.},
	journal = {Nature},
	number = {7825},
	pages = {357--362},
	title = {Array programming with NumPy},
	volume = {585},
	year = {2020}
}

@inproceedings{Lam2015,
author = {Lam, S. K. and Pitrou, A. and Seibert, S.},
title = {Numba: A LLVM-Based Python JIT Compiler},
year = {2015},
publisher = {ACM},
booktitle = {Proc of. the Second Workshop on the LLVM Compiler Infrastructure in HPC},
articleno = {7},
numpages = {6},
series = {LLVM '15}
}

@misc{Bajari2021,
  url = {https://arxiv.org/abs/2112.13495},
  author = {Bajari, P. and Burdick, B. and Imbens, G. W. and Masoero, L. and McQueen, J. and Richardson, T. and Rosen, I. M.},
  title = {Multiple Randomization Designs},
  publisher = {arXiv},
  year = {2021}
}

@inproceedings{Diaz2020,
author = {Diaz, F. and Mitra, B. and Ekstrand, M. D. and Biega, A. J. and Carterette, B.},
title = {Evaluating Stochastic Rankings with Expected Exposure},
year = {2020},
isbn = {9781450368599},
publisher = {ACM},

url = {https://doi.org/10.1145/3340531.3411962},
doi = {10.1145/3340531.3411962},
abstract = {We introduce the concept of expected exposure as the average attention ranked items receive from users over repeated samples of the same query. Furthermore, we advocate for the adoption of the principle of equal expected exposure: given a fixed information need, no item should receive more or less expected exposure than any other item of the same relevance grade. We argue that this principle is desirable for many retrieval objectives and scenarios, including topical diversity and fair ranking. \%Leveraging user models from existing retrieval metrics, we propose a general evaluation methodology based on expected exposure and draw connections to related metrics in information retrieval evaluation. Importantly, this methodology relaxes classic information retrieval assumptions, allowing a system, in response to a query, to produce a distribution over rankings instead of a single fixed ranking. We study the behavior of the expected exposure metric and stochastic rankers across a variety of information access conditions, including ad hoc retrieval and recommendation. \%We believe that measuring and optimizing expected exposure metrics using randomization opens a new area for retrieval algorithm development and progress.},
booktitle = {Proc of. the 29th ACM International Conference on Information \& Knowledge Management},
pages = {275284},
numpages = {10},
keywords = {evaluation, fairness, learning to rank, diversity},

series = {CIKM '20}
}

@article{Joachims2007,
author = {Joachims, T. and Granka, L. and Pan, B. and Hembrooke, H. and Radlinski, F. and Gay, G.},
title = {Evaluating the Accuracy of Implicit Feedback from Clicks and Query Reformulations in Web Search},
year = {2007},
issue_date = {April 2007},
publisher = {ACM},

volume = {25},
number = {2},
issn = {1046-8188},
url = {https://doi.org/10.1145/1229179.1229181},
doi = {10.1145/1229179.1229181},
abstract = {This article examines the reliability of implicit feedback generated from clickthrough data and query reformulations in World Wide Web (WWW) search. Analyzing the users' decision process using eyetracking and comparing implicit feedback against manual relevance judgments, we conclude that clicks are informative but biased. While this makes the interpretation of clicks as absolute relevance judgments difficult, we show that relative preferences derived from clicks are reasonably accurate on average. We find that such relative preferences are accurate not only between results from an individual query, but across multiple sets of results within chains of query reformulations.},
journal = {ACM Trans. Inf. Syst.},
month = {apr},
pages = {7es},
numpages = {27},
keywords = {Clickthrough data, query reformulations, implicit feedback, user studies, eye-tracking}
}

@article{Oosterhuis2023,
author = {Oosterhuis, H.},
title = {Doubly Robust Estimation for Correcting Position Bias in Click Feedback for Unbiased Learning to Rank},
year = {2023},
issue_date = {July 2023},
publisher = {ACM},
volume = {41},
number = {3},
issn = {1046-8188},
url = {https://doi.org/10.1145/3569453},
doi = {10.1145/3569453},
abstract = {Clicks on rankings suffer from position bias: generally items on lower ranks are less likely to be examinedand thus clickedby users, in spite of their actual preferences between items. The prevalent approach to unbiased click-based learning-to-rank (LTR) is based on counterfactual inverse-propensity-scoring (IPS) estimation. In contrast with general reinforcement learning, counterfactual doubly robust (DR) estimation has not been applied to click-based LTR in previous literature. In this article, we introduce a novel DR estimator that is the first DR approach specifically designed for position bias. The difficulty with position bias is that the treatmentuser examinationis not directly observable in click data. As a solution, our estimator uses the expected treatment per rank, instead of the actual treatment that existing DR estimators use. Our novel DR estimator has more robust unbiasedness conditions than the existing IPS approach, and in addition, provides enormous decreases in variance: our experimental results indicate it requires several orders of magnitude fewer datapoints to converge at optimal performance. For the unbiased LTR field, our DR estimator contributes both increases in state-of-the-art performance and the most robust theoretical guarantees of all known LTR estimators.},
journal = {ACM Trans. Inf. Syst.},
month = {feb},
articleno = {61},
numpages = {33},
keywords = {counterfactual learning, Unbiased learning to rank}
}

@inproceedings{Oosterhuis2021,
author = {Oosterhuis, H.},
title = {Computationally Efficient Optimization of Plackett-Luce Ranking Models for Relevance and Fairness},
year = {2021},
isbn = {9781450380379},
publisher = {ACM},

url = {https://doi.org/10.1145/3404835.3462830},
doi = {10.1145/3404835.3462830},
abstract = {Recent work has proposed stochastic Plackett-Luce (PL) ranking models as a robust choice for optimizing relevance and fairness metrics. Unlike their deterministic counterparts that require heuristic optimization algorithms, PL models are fully differentiable. Theoretically, they can be used to optimize ranking metrics via stochastic gradient descent. However, in practice, the computation of the gradient is infeasible because it requires one to iterate over all possible permutations of items. Consequently, actual applications rely on approximating the gradient via sampling techniques. In this paper, we introduce a novel algorithm: PL-Rank, that estimates the gradient of a PL ranking model w.r.t. both relevance and fairness metrics. Unlike existing approaches that are based on policy gradients, PL-Rank makes use of the specific structure of PL models and ranking metrics. Our experimental analysis shows that PL-Rank has a greater sample-efficiency and is computationally less costly than existing policy gradients, resulting in faster convergence at higher performance. PL-Rank further enables the industry to apply PL models for more relevant and fairer real-world ranking systems.},
booktitle = {Proc of. the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {10231032},
numpages = {10},
keywords = {learning to rank, ranking metric optimization, policy gradients},

series = {SIGIR '21}
}

@inproceedings{Vardasbi2020,
author = {Vardasbi, A. and Oosterhuis, H. and de Rijke, M.},
title = {When Inverse Propensity Scoring Does Not Work: Affine Corrections for Unbiased Learning to Rank},
year = {2020},
isbn = {9781450368599},
publisher = {ACM},

url = {https://doi.org/10.1145/3340531.3412031},
doi = {10.1145/3340531.3412031},
abstract = {Besides position bias, which has been well-studied, trust bias is another type of bias prevalent in user interactions with rankings: users are more likely to click incorrectly w.r.t. their preferences on highly ranked items because they trust the ranking system. While previous work has observed this behavior in users, we prove that existing Counterfactual Learning to Rank (CLTR) methods do not remove this bias, including methods specifically designed to mitigate this type of bias. Moreover, we prove that Inverse Propensity Scoring (IPS) is principally unable to correct for trust bias under non-trivial circumstances. Our main contribution is a new estimator based on affine corrections: it both reweights clicks and penalizes items displayed on ranks with high trust bias. Our estimator is the first estimator that is proven to remove the effect of both trust bias and position bias. Furthermore, we show that our estimator is a generalization of the existing (CLTR) framework: if no trust bias is present, it reduces to the original (IPS) estimator. Our semi-synthetic experiments indicate that by removing the effect of trust bias in addition to position bias, (CLTR) can approximate the optimal ranking system even closer than previously possible.},
booktitle = {Proc of. the 29th ACM International Conference on Information \& Knowledge Management},
pages = {14751484},
numpages = {10},
keywords = {unbiased learning to rank, position bias, trust bias, inverse propensity scoring},

series = {CIKM '20}
}

@InProceedings{Hofmann2014,
author="Hofmann, K.
and Schuth, A.
and Bellog{\'i}n, A.
and de Rijke, M.",
title="Effects of Position Bias on Click-Based Recommender Evaluation",
booktitle="Advances in Information Retrieval",
year="2014",
publisher="Springer International Publishing",
address="Cham",
pages="624--630",
abstract="Measuring the quality of recommendations produced by a recommender system (RS) is challenging. Labels used for evaluation are typically obtained from users of a RS, by asking for explicit feedback, or inferring labels from implicit feedback. Both approaches can introduce significant biases in the evaluation process. We investigate biases that may affect labels inferred from implicit feedback. Implicit feedback is easy to collect but can be prone to biases, such as position bias. We examine this bias using click models, and show how bias following these models would affect the outcomes of RS evaluation. We find that evaluation based on implicit and explicit feedback can agree well, but only when the evaluation metrics are designed to take user behavior and preferences into account, stressing the importance of understanding user behavior in deployed RSs.",
isbn="978-3-319-06028-6"
}

@article{Chen2022,
author = {Chen, J. and Dong, H. and Wang, X. and Feng, F. and Wang, M. and He, X.},
title = {Bias and Debias in Recommender System: A Survey and Future Directions},
year = {2022},
publisher = {ACM},

issn = {1046-8188},
url = {https://doi.org/10.1145/3564284},
doi = {10.1145/3564284},
abstract = {While recent years have witnessed a rapid growth of research papers on recommender system (RS), most of the papers focus on inventing machine learning models to better fit user behavior data. However, user behavior data is observational rather than experimental. This makes various biases widely exist in the data, including but not limited to selection bias, position bias, exposure bias, and popularity bias. Blindly fitting the data without considering the inherent biases will result in many serious issues, e.g., the discrepancy between offline evaluation and online metrics, hurting user satisfaction and trust on the recommendation service, etc. To transform the large volume of research models into practical improvements, it is highly urgent to explore the impacts of the biases and perform debiasing when necessary. When reviewing the papers that consider biases in RS, we find that, to our surprise, the studies are rather fragmented and lack a systematic organization. The terminology bias is widely used in the literature, but its definition is usually vague and even inconsistent across papers. This motivates us to provide a systematic survey of existing work on RS biases. In this paper, we first summarize seven types of biases in recommendation, along with their definitions and characteristics. We then provide a taxonomy to position and organize the existing work on recommendation debiasing. Finally, we identify some open challenges and envision some future directions, with the hope of inspiring more research work on this important yet less investigated topic. The summary of debiasing methods reviewed in this survey can be found at https://github.com/jiawei-chen/RecDebiasing.},
note = {Just Accepted},
journal = {ACM Trans. Inf. Syst.},
month = {oct},
keywords = {Adaption, Efficiency, Recommendation, Sampling}
}

@article{Castells2022,
author = {Castells, P. and Moffat, A.},
title = {Offline recommender system evaluation: Challenges and new directions},
journal = {AI Magazine},
volume = {43},
number = {2},
pages = {225-238},
doi = {https://doi.org/10.1002/aaai.12051},
abstract = {Abstract Offline evaluation is an essential complement to online experiments in the selection, improvement, tuning, and deployment of recommender systems. Offline methodologies for recommender system evaluation evolved from experimental practice in Machine Learning (ML) and Information Retrieval (IR). However, evaluating recommendations involves particularities that pose challenges to the assumptions upon which the ML and IR methodologies were developed. We recap and reflect on the development and current status of recommender system evaluation, providing an updated perspective. With a focus on offline evaluation, we review the adaptation of IR principles, procedures and metrics, and the implications of those techniques when applied to recommender systems. At the same time, we identify the singularities of recommendation that require different responses, or involve specific new needs. In addition, we provide an overview of important choices in the configuration of experiments that require particular care and understanding; discuss broader perspectives of evaluation such as recommendation value beyond accuracy; and survey open challenges such as experimental biases, and the cyclic dimension ofrecommendation.},
year = {2022}
}

@inproceedings{Ruffini2022,
author = {Ruffini, M. and Bellini, V. and Buchholz, A. and Di Benedetto, G. and Stein, Y.},
title = {Modeling Position Bias Ranking for Streaming Media Services},
year = {2022},
isbn = {9781450391306},
publisher = {ACM},

url = {https://doi.org/10.1145/3487553.3524210},
doi = {10.1145/3487553.3524210},
abstract = {We tackle the problem of position bias estimation for streaming media services. Position bias is a widely studied topic in ranking literature and its impact on ranking quality is well understood. Although several methods exist to estimate position bias, their applicability to an industrial setting is limited, either because they require ad-hoc interventions that harm user experience, or because their learning accuracy is poor. In this paper, we present a novel position bias estimator that overcomes these limitations: it can be applied to streaming media services without manual interventions while delivering best in class estimation accuracy. We compare the proposed method against existing ones on real and synthetic data and illustrate its applicability to Amazon Music.},
booktitle = {Companion Proceedings of the Web Conference 2022},
pages = {7276},
numpages = {5},
keywords = {Music Recommendation, Multi Armed Bandits, Position Bias},

series = {WWW '22}
}

@Article{Valcarce2020,
author={Valcarce, D.
and Bellog{\'i}n, A.
and Parapar, J.
and Castells, P.},
title={Assessing ranking metrics in top-N recommendation},
journal={Information Retrieval Journal},
year={2020},
month={Aug},
day={01},
volume={23},
number={4},
pages={411-448},
abstract={The evaluation of recommender systems is an area with unsolved questions at several levels. Choosing the appropriate evaluation metric is one of such important issues. Ranking accuracy is generally identified as a prerequisite for recommendation to be useful. Ranking metrics have been adapted for this purpose from the Information Retrieval field into the recommendation task. In this article, we undertake a principled analysis of the robustness and the discriminative power of different ranking metrics for the offline evaluation of recommender systems, drawing from previous studies in the information retrieval field. We measure the robustness to different sources of incompleteness that arise from the sparsity and popularity biases in recommendation. Among other results, we find that precision provides high robustness while normalized discounted cumulative gain offers the best discriminative power. In dealing with cold users, we also find that the geometric mean is more robust than the arithmetic mean as aggregation function over users.},
issn={1573-7659},
doi={10.1007/s10791-020-09377-x},
url={https://doi.org/10.1007/s10791-020-09377-x}
}

@phdthesis{Jeunen2021thesis,
  Title = {Offline Approaches to Recommendation with Online Success}, 
  Author = {Jeunen, O.},
  Date = {2021-09-22},
  Year = {2021}, 
  School = {University of Antwerp},
}

@article{Moffat2008,
author = {Moffat, A. and Zobel, J.},
title = {Rank-Biased Precision for Measurement of Retrieval Effectiveness},
year = {2008},
issue_date = {December 2008},
publisher = {ACM},

volume = {27},
number = {1},
issn = {1046-8188},
url = {https://doi.org/10.1145/1416950.1416952},
doi = {10.1145/1416950.1416952},
abstract = {A range of methods for measuring the effectiveness of information retrieval systems has been proposed. These are typically intended to provide a quantitative single-value summary of a document ranking relative to a query. However, many of these measures have failings. For example, recall is not well founded as a measure of satisfaction, since the user of an actual system cannot judge recall. Average precision is derived from recall, and suffers from the same problem. In addition, average precision lacks key stability properties that are needed for robust experiments. In this article, we introduce a new effectiveness metric, rank-biased precision, that avoids these problems. Rank-biased pre-cision is derived from a simple model of user behavior, is robust if answer rankings are extended to greater depths, and allows accurate quantification of experimental uncertainty, even when only partial relevance judgments are available.},
journal = {ACM Trans. Inf. Syst.},
month = {dec},
articleno = {2},
numpages = {27},
keywords = {relevance, Recall, average precision, pooling, precision}
}

@inproceedings{Chapelle2009,
author = {Chapelle, O. and Metzler, D. and Zhang, Y. and Grinspan, P.},
title = {Expected Reciprocal Rank for Graded Relevance},
year = {2009},
isbn = {9781605585123},
publisher = {ACM},

url = {https://doi.org/10.1145/1645953.1646033},
doi = {10.1145/1645953.1646033},
abstract = {While numerous metrics for information retrieval are available in the case of binary relevance, there is only one commonly used metric for graded relevance, namely the Discounted Cumulative Gain (DCG). A drawback of DCG is its additive nature and the underlying independence assumption: a document in a given position has always the same gain and discount independently of the documents shown above it. Inspired by the "cascade" user model, we present a new editorial metric for graded relevance which overcomes this difficulty and implicitly discounts documents which are shown below very relevant documents. More precisely, this new metric is defined as the expected reciprocal length of time that the user will take to find a relevant document. This can be seen as an extension of the classical reciprocal rank to the graded relevance case and we call this metric Expected Reciprocal Rank (ERR). We conduct an extensive evaluation on the query logs of a commercial search engine and show that ERR correlates better with clicks metrics than other editorial metrics.},
booktitle = {Proc of. the 18th ACM Conference on Information and Knowledge Management},
pages = {621630},
numpages = {10},
keywords = {web search, user model, non-binary relevance, evaluation, click logs},

series = {CIKM '09}
}

@book{
    chuklin2015click,
    Author = {Chuklin, A. and Markov, I. and {de Rijke}, M.},
    Publisher = {Morgan \& Claypool},
    Title = {Click Models for Web Search},
    Year = {2015},
    Isbn = {9781627056489},
    Doi = {10.2200/S00654ED1V01Y201507ICR043}
}

@inproceedings{Wu2021,
author = {Wu, X. and Chen, H. and Zhao, J. and He, L. and Yin, D. and Chang, Y.},
title = {Unbiased Learning to Rank in Feeds Recommendation},
year = {2021},
isbn = {9781450382977},
publisher = {ACM},

url = {https://doi.org/10.1145/3437963.3441751},
doi = {10.1145/3437963.3441751},
abstract = {In feeds recommendation, users are able to constantly browse items generated by never-ending feeds using mobile phones. The implicit feedback from users is an important resource for learning to rank, however, building ranking functions from such observed data is recognized to be biased. The presentation of the items will influence the user's judgements and therefore introduces biases. Most previous works in the unbiased learning to rank literature focus on position bias (i.e., an item ranked higher has more chances of being examined and interacted with). By analyzing user behaviors in product feeds recommendation, in this paper, we identify and introduce context bias, which refers to the probability that a user interacting with an item is biased by its surroundings, to unbiased learning to rank. We propose an Unbiased Learning to Rank with Combinational Propensity (ULTR-CP) framework to remove the inherent biases jointly caused by multiple factors. Under this framework, a context-aware position bias model is instantiated to estimate the unified bias considering both position and context biases. In addition to evaluating propensity score estimation approaches by the ranking metrics, we also discuss the evaluation of the propensities directly by checking their balancing properties. Extensive experiments performed on a real e-commerce data set collected from JD.com verify the effectiveness of context bias and illustrate the superiority of ULTR-CP against the state-of-the-art methods.},
booktitle = {Proc of. the 14th ACM International Conference on Web Search and Data Mining},
pages = {490498},
numpages = {9},
keywords = {feeds recommendation, learning to rank, unbiased learning},

series = {WSDM '21}
}

@article{Simon1955,
    author = {Simon, H. A.},
    title = "{On a Class of Skew Distribution Functions}",
    journal = {Biometrika},
    volume = {42},
    number = {3-4},
    pages = {425-440},
    year = {1955},
    month = {12},
    issn = {0006-3444},
    doi = {10.1093/biomet/42.3-4.425},
    url = {https://doi.org/10.1093/biomet/42.3-4.425},
}


@article{Yule1925,
author = {Yule, G. Y. },
title = {A mathematical theory of evolution, based on the conclusions of Dr. J. C. Willis, F. R. S},
journal = {Philosophical Transactions of the Royal Society of London. Series B, Containing Papers of a Biological Character},
volume = {213},
number = {402-410},
pages = {21-87},
year = {1925},
doi = {10.1098/rstb.1925.0002},

URL = {https://royalsocietypublishing.org/doi/abs/10.1098/rstb.1925.0002},
}


@inproceedings{Ovasisi2020,
author = {Ovaisi, Z. and Ahsan, R. and Zhang, Y. and Vasilaky, K. and Zheleva, E.},
title = {Correcting for Selection Bias in Learning-to-Rank Systems},
year = {2020},
isbn = {9781450370233},
publisher = {ACM},

url = {https://doi.org/10.1145/3366423.3380255},
doi = {10.1145/3366423.3380255},
abstract = {Click data collected by modern recommendation systems are an important source of observational data that can be utilized to train learning-to-rank (LTR) systems. However, these data suffer from a number of biases that can result in poor performance for LTR systems. Recent methods for bias correction in such systems mostly focus on position bias, the fact that higher ranked results (e.g., top search engine results) are more likely to be clicked even if they are not the most relevant results given a users query. Less attention has been paid to correcting for selection bias, which occurs because clicked documents are reflective of what documents have been shown to the user in the first place. Here, we propose new counterfactual approaches which adapt Heckmans two-stage method and accounts for selection and position bias in LTR systems. Our empirical evaluation shows that our proposed methods are much more robust to noise and have better accuracy compared to existing unbiased LTR algorithms, especially when there is moderate to no position bias.},
booktitle = {Proc of. The Web Conference 2020},
pages = {18631873},
numpages = {11},
keywords = {recommender systems, position bias, selection bias, learning-to-rank},

series = {WWW '20}
}

@inproceedings{Oosterhuis2020,
author = {Oosterhuis, H. and de Rijke, M.},
title = {Policy-Aware Unbiased Learning to Rank for Top-k Rankings},
year = {2020},
isbn = {9781450380164},
publisher = {ACM},

url = {https://doi.org/10.1145/3397271.3401102},
doi = {10.1145/3397271.3401102},
abstract = {Counterfactual Learning to Rank (LTR) methods optimize ranking systems using logged user interactions that contain interaction biases. Existing methods are only unbiased if users are presented with all relevant items in every ranking. There is currently no existing counterfactual unbiased LTR method for top-k rankings. We introduce a novel policy-aware counterfactual estimator for LTR metrics that can account for the effect of a stochastic logging policy. We prove that the policy-aware estimator is unbiased if every relevant item has a non-zero probability to appear in the top-k ranking. Our experimental results show that the performance of our estimator is not affected by the size of k: for any k, the policy-aware estimator reaches the same retrieval performance while learning from top-k feedback as when learning from feedback on the full ranking. Lastly, we introduce novel extensions of traditional LTR methods to perform counterfactual LTR and to optimize top-k metrics. Together, our contributions introduce the first policy-aware unbiased LTR approach that learns from top-k feedback and optimizes top-k metrics. As a result, counterfactual LTR is now applicable to the very prevalent top-k ranking setting in search and recommendation.},
booktitle = {Proc of. the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {489498},
numpages = {10},
keywords = {selection bias, recommendation, learning to rank, counterfactual learning to rank, counterfactual learning, top-k ranking},

series = {SIGIR '20}
}

@book{Pearl2009,
  title={Causality},
  author={Pearl, J.},
  year={2009},
  publisher={Cambridge university press}
}


@inproceedings{Agarwal2019,
author = {Agarwal, A. and Zaitsev, I. and Wang, X. and Li, C. and Najork, M. and Joachims, T.},
title = {Estimating Position Bias without Intrusive Interventions},
year = {2019},
isbn = {9781450359405},
publisher = {ACM},
url = {https://doi.org/10.1145/3289600.3291017},
doi = {10.1145/3289600.3291017},
abstract = {Presentation bias is one of the key challenges when learning from implicit feedback in search engines, as it confounds the relevance signal. While it was recently shown how counterfactual learning-to-rank (LTR) approaches citeJoachims/etal/17a can provably overcome presentation bias when observation propensities are known, it remains to show how to effectively estimate these propensities. In this paper, we propose the first method for producing consistent propensity estimates without manual relevance judgments, disruptive interventions, or restrictive relevance modeling assumptions. First, we show how to harvest a specific type of intervention data from historic feedback logs of multiple different ranking functions, and show that this data is sufficient for consistent propensity estimation in the position-based model. Second, we propose a new extremum estimator that makes effective use of this data. In an empirical evaluation, we find that the new estimator provides superior propensity estimates in two real-world systems -- Arxiv Full-text Search and Google Drive Search. Beyond these two points, we find that the method is robust to a wide range of settings in simulation studies.},
booktitle = {Proc of. the Twelfth ACM International Conference on Web Search and Data Mining},
pages = {474482},
numpages = {9},
keywords = {unbiased learning-to-rank, logged data, counterfactual inference, click propensity estimation},

series = {WSDM '19}
}

@inproceedings{Fang2019,
author = {Fang, Z. and Agarwal, A. and Joachims, T.},
title = {Intervention Harvesting for Context-Dependent Examination-Bias Estimation},
year = {2019},
isbn = {9781450361729},
publisher = {ACM},

url = {https://doi.org/10.1145/3331184.3331238},
doi = {10.1145/3331184.3331238},
abstract = {Accurate estimates of examination bias are crucial for unbiased learning-to-rank from implicit feedback in search engines and recommender systems, since they enable the use of Inverse Propensity Score (IPS) weighting techniques to address selection biases and missing data. Unfortunately, existing examination-bias estimators are limited to the Position-Based Model (PBM), where the examination bias may only depend on the rank of the document. To overcome this limitation, we propose a Contextual Position-Based Model (CPBM) where the examination bias may also depend on a context vector describing the query and the user. Furthermore, we propose an effective estimator for the CPBM based on intervention harvesting. A key feature of the estimator is that it does not require disruptive interventions but merely exploits natural variation resulting from the use of multiple historic ranking functions. Real-world experiments on the ArXiv search engine and semi-synthetic experiments on the Yahoo Learning-To-Rank dataset demonstrate the superior effectiveness and robustness of the new approach.},
booktitle = {Proc of. the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {825834},
numpages = {10},
keywords = {examination bias, propensity estimation, unbiased learning-to-rank},

series = {SIGIR'19}
}

@article{Jarvelin2002,
author = {J\"{a}rvelin, K. and Kek\"{a}l\"{a}inen, J.},
title = {Cumulated Gain-Based Evaluation of IR Techniques},
year = {2002},
issue_date = {October 2002},
publisher = {ACM},
volume = {20},
number = {4},
issn = {1046-8188},
url = {https://doi.org/10.1145/582415.582418},
doi = {10.1145/582415.582418},
abstract = {Modern large retrieval environments tend to overwhelm their users by their large output. Since all documents are not of equal relevance to their users, highly relevant documents should be identified and ranked first for presentation. In order to develop IR techniques in this direction, it is necessary to develop evaluation approaches and methods that credit IR methods for their ability to retrieve highly relevant documents. This can be done by extending traditional evaluation methods, that is, recall and precision based on binary relevance judgments, to graded relevance judgments. Alternatively, novel measures based on graded relevance judgments may be developed. This article proposes several novel measures that compute the cumulative gain the user obtains by examining the retrieval result up to a given ranked position. The first one accumulates the relevance scores of retrieved documents along the ranked result list. The second one is similar but applies a discount factor to the relevance scores in order to devaluate late-retrieved documents. The third one computes the relative-to-the-ideal performance of IR techniques, based on the cumulative gain they are able to yield. These novel measures are defined and discussed and their use is demonstrated in a case study using TREC data: sample system run results for 20 queries in TREC-7. As a relevance base we used novel graded relevance judgments on a four-point scale. The test results indicate that the proposed measures credit IR methods for their ability to retrieve highly relevant documents and allow testing of statistical significance of effectiveness differences. The graphs based on the measures also provide insight into the performance IR techniques and allow interpretation, for example, from the user point of view.},
journal = {ACM Trans. Inf. Syst.},
month = {oct},
pages = {422446},
numpages = {25},
keywords = {Graded relevance judgments, cumulated gain}
}

@book{johnson2005univariate,
  title={Univariate discrete distributions},
  author={Johnson, N. L. and Kemp, A. W. and Kotz, S.},
  volume={444},
  year={2005},
  publisher={John Wiley \& Sons}
}

@article{Virtanen2020,
	Author = {Virtanen, P. and Gommers, R. and Oliphant, T. E. and others},
	Journal = {Nature Methods},
	Number = {3},
	Pages = {261--272},
	Title = {SciPy 1.0: fundamental algorithms for scientific computing in Python},
	Volume = {17},
	Year = {2020},
 url = {https://doi.org/10.1038/s41592-019-0686-2}
}

@inproceedings{Wang2018PB,
author = {Wang, X. and Golbandi, N. and Bendersky, M. and Metzler, D. and Najork, M.},
title = {Position Bias Estimation for Unbiased Learning to Rank in Personal Search},
year = {2018},
isbn = {9781450355810},
publisher = {ACM},

url = {https://doi.org/10.1145/3159652.3159732},
doi = {10.1145/3159652.3159732},
abstract = {A well-known challenge in learning from click data is its inherent bias and most notably position bias. Traditional click models aim to extract the query, document relevance and the estimated bias is usually discarded after relevance is extracted. In contrast, the most recent work on unbiased learning-to-rank can effectively leverage the bias and thus focuses on estimating bias rather than relevance [20, 31]. Existing approaches use search result randomization over a small percentage of production traffic to estimate the position bias. This is not desired because result randomization can negatively impact users' search experience. In this paper, we compare different schemes for result randomization (i.e., RandTopN and RandPair) and show their negative effect in personal search. Then we study how to infer such bias from regular click data without relying on randomization. We propose a regression-based Expectation-Maximization (EM) algorithm that is based on a position bias click model and that can handle highly sparse clicks in personal search. We evaluate our EM algorithm and the extracted bias in the learning-to-rank setting. Our results show that it is promising to extract position bias from regular clicks without result randomization. The extracted bias can improve the learning-to-rank algorithms significantly. In addition, we compare the pointwise and pairwise learning-to-rank models. Our results show that pairwise models are more effective in leveraging the estimated bias.},
booktitle = {Proc of. the Eleventh ACM International Conference on Web Search and Data Mining},
pages = {610618},
numpages = {9},
keywords = {expectation-maximization, inverse propensity weighting, position bias estimation},

series = {WSDM '18}
}

@inproceedings{Ai2018,
author = {Ai, Q. and Bi, K. and Luo, C. and Guo, J. and Croft, W. B.},
title = {Unbiased Learning to Rank with Unbiased Propensity Estimation},
year = {2018},
isbn = {9781450356572},
publisher = {ACM},

url = {https://doi.org/10.1145/3209978.3209986},
doi = {10.1145/3209978.3209986},
abstract = {Learning to rank with biased click data is a well-known challenge. A variety of methods has been explored to debias click data for learning to rank such as click models, result interleaving and, more recently, the unbiased learning-to-rank framework based on inverse propensity weighting. Despite their differences, most existing studies separate the estimation of click bias (namely the propensity model ) from the learning of ranking algorithms. To estimate click propensities, they either conduct online result randomization, which can negatively affect the user experience, or offline parameter estimation, which has special requirements for click data and is optimized for objectives (e.g. click likelihood) that are not directly related to the ranking performance of the system. In this work, we address those problems by unifying the learning of propensity models and ranking models. We find that the problem of estimating a propensity model from click data is a dual problem of unbiased learning to rank. Based on this observation, we propose a Dual Learning Algorithm (DLA) that jointly learns an unbiased ranker and an unbiased propensity model. DLA is an automatic unbiased learning-to-rank framework as it directly learns unbiased ranking models from biased click data without any preprocessing. It can adapt to the change of bias distributions and is applicable to online learning. Our empirical experiments with synthetic and real-world data show that the models trained with DLA significantly outperformed the unbiased learning-to-rank algorithms based on result randomization and the models trained with relevance signals extracted by click models.},
booktitle = {The 41st International ACM SIGIR Conference on Research \& Development in Information Retrieval},
pages = {385394},
numpages = {10},
keywords = {learning to rank, inverse propensity weighting, propensity estimation},

series = {SIGIR '18}
}

@inproceedings{Craswell2008,
author = {Craswell, N. and Zoeter, O. and Taylor, M. and Ramsey, B.},
title = {An Experimental Comparison of Click Position-Bias Models},
year = {2008},
isbn = {9781595939272},
publisher = {ACM},

url = {https://doi.org/10.1145/1341531.1341545},
doi = {10.1145/1341531.1341545},
abstract = {Search engine click logs provide an invaluable source of relevance information, but this information is biased. A key source of bias is presentation order: the probability of click is influenced by a document's position in the results page. This paper focuses on explaining that bias, modelling how probability of click depends on position. We propose four simple hypotheses about how position bias might arise. We carry out a large data-gathering effort, where we perturb the ranking of a major search engine, to see how clicks are affected. We then explore which of the four hypotheses best explains the real-world position effects, and compare these to a simple logistic regression model. The data are not well explained by simple position models, where some users click indiscriminately on rank 1 or there is a simple decay of attention over ranks. A 'cascade' model, where users view results from top to bottom and leave as soon as they see a worthwhile document, is our best explanation for position bias in early ranks},
booktitle = {Proc of. the 2008 International Conference on Web Search and Data Mining},
pages = {8794},
numpages = {8},
keywords = {click data, web search models, user behavior},

series = {WSDM '08}
}

@inproceedings{Chapelle2009DBN,
author = {Chapelle, O. and Zhang, Y.},
title = {A Dynamic Bayesian Network Click Model for Web Search Ranking},
year = {2009},
isbn = {9781605584874},
publisher = {ACM},

url = {https://doi.org/10.1145/1526709.1526711},
doi = {10.1145/1526709.1526711},
abstract = {As with any application of machine learning, web search ranking requires labeled data. The labels usually come in the form of relevance assessments made by editors. Click logs can also provide an important source of implicit feedback and can be used as a cheap proxy for editorial labels. The main difficulty however comes from the so called position bias - urls appearing in lower positions are less likely to be clicked even if they are relevant. In this paper, we propose a Dynamic Bayesian Network which aims at providing us with unbiased estimation of the relevance from the click logs. Experiments show that the proposed click model outperforms other existing click models in predicting both click-through rate and relevance.},
booktitle = {Proc of. the 18th International Conference on World Wide Web},
pages = {110},
numpages = {10},
keywords = {web search, click-through rate, dynamic bayesian network, click modeling, ranking},

series = {WWW '09}
}

@inproceedings{Mehrotra2020,
author = {Mehrotra, R. and Xue, N. and Lalmas, M.},
title = {Bandit Based Optimization of Multiple Objectives on a Music Streaming Platform},
year = {2020},
isbn = {9781450379984},
publisher = {ACM},
url = {https://doi.org/10.1145/3394486.3403374},
doi = {10.1145/3394486.3403374},
abstract = {Recommender systems powering online multi-stakeholder platforms often face the challenge of jointly optimizing multiple objectives, in an attempt to efficiently match suppliers and consumers. Examples of such objectives include user behavioral metrics (e.g. clicks, streams, dwell time, etc), supplier exposure objectives (e.g. diversity) and platform centric objectives (e.g. promotions). Jointly optimizing multiple metrics in online recommender systems remains a challenging task. Recent work has demonstrated the prowess of contextual bandits in powering recommendation systems to serve recommendation of interest to users. This paper aims at extending contextual bandits to multi-objective setting so as to power recommendations in a multi-stakeholder platforms.Specifically, in a contextual bandit setting, we learn a recommendation policy that can optimize multiple objectives simultaneously in a fair way. This multi-objective online optimization problem is formalized by using the Generalized Gini index (GGI) aggregation function, which combines and balances multiple objectives together. We propose an online gradient ascent learning algorithm to maximise the long-term vectorial rewards for different objectives scalarised using the GGI function. Through extensive experiments on simulated data and large scale music recommendation data from Spotify, a streaming platform, we show that the proposed algorithm learns a superior policy among the disparate objectives compared with other state-of-the-art approaches.},
booktitle = {Proc of. the 26th ACM SIGKDD International Conference on Knowledge Discovery \& Data Mining},
pages = {32243233},
numpages = {10},
keywords = {marketplace, recommendations, multi-objective bandits},
series = {KDD '20}
}

@book{schutze2008introduction,
  title={Introduction to information retrieval},
  author={Sch{\"u}tze, H. and Manning, C. D and Raghavan, P.},
  volume={39},
  year={2008},
  publisher={Cambridge University Press Cambridge}
}

@inproceedings{Diaz2021,
  title={On Evaluating Session-Based Recommendation with Implicit Feedback},
  author={Diaz, F.},
  booktitle={Workshop on Perspectives on Offline Evaluation for Recommender Systems at RecSys '21 (PERSPECTIVES '21)},
  year={2021},
}

@inproceedings{Sachdeva2020,
author = {Sachdeva, N. and Su, Y. and Joachims, T.},
title = {Off-Policy Bandits with Deficient Support},
year = {2020},
isbn = {9781450379984},
publisher = {ACM},
url = {https://doi.org/10.1145/3394486.3403139},
doi = {10.1145/3394486.3403139},
abstract = {Learning effective contextual-bandit policies from past actions of a deployed system is highly desirable in many settings (e.g. voice assistants, recommendation, search), since it enables the reuse of large amounts of log data. State-of-the-art methods for such off-policy learning, however, are based on inverse propensity score (IPS) weighting. A key theoretical requirement of IPS weighting is that the policy that logged the data has "full support", which typically translates into requiring non-zero probability for any action in any context. Unfortunately, many real-world systems produce support deficient data, especially when the action space is large, and we show how existing methods can fail catastrophically. To overcome this gap between theory and applications, we identify three approaches that provide various guarantees for IPS-based learning despite the inherent limitations of support-deficient data: restricting the action space, reward extrapolation, and restricting the policy space. We systematically analyze the statistical and computational properties of these three approaches, and we empirically evaluate their effectiveness. In addition to providing the first systematic analysis of support-deficiency in contextual-bandit learning, we conclude with recommendations that provide practical guidance.},
booktitle = {Proc of. the 26th ACM SIGKDD International Conference on Knowledge Discovery \& Data Mining},
pages = {965975},
numpages = {11},
keywords = {counterfactual reasoning, log data, contextual bandits, off-policy learning, implicit feed-back},
series = {KDD '20}
}

@article{Deffayet2022,
author = {Deffayet, R. and Renders, J. and de Rijke, M.},
title = {Evaluating the Robustness of Click Models to Policy Distributional Shift},
year = {2022},
publisher = {ACM},
issn = {1046-8188},
url = {https://doi.org/10.1145/3569086},
doi = {10.1145/3569086},
abstract = {Many click models have been proposed to interpret logs of natural interactions with search engines and extract unbiased information for evaluation or learning. The experimental set-up used to evaluate them typically involves measuring two metrics, namely the test perplexity for click prediction and nDCG for relevance estimation. In both cases, the data used for training and testing is assumed to be collected using the same ranking policy. We question this assumption. Important downstream tasks based on click models involve evaluating a different policy than the training policy, i.e., click models need to operate under policy distributional shift. We show that click models are sensitive to it. This can severely hinder their performance on the targeted task: conventional evaluation metrics cannot guarantee that a click model will perform equally well under distributional shift. In order to more reliably predict click model performance under policy distributional shift, we propose a new evaluation protocol. It allows us to compare the relative robustness of six types of click models under various shifts, training configurations and downstream tasks. We obtain insights into the factors that worsen the sensitivity to policy distributional shift, and formulate guidelines to mitigate the risks of deploying policies based on click models.},
note = {Just Accepted},
journal = {ACM Trans. Inf. Syst.},
month = {oct},
keywords = {Web search, Offline evaluation, Distributional shift, Click models}
}

@inproceedings{Swaminathan2017,
 author = {Swaminathan, A. and Krishnamurthy, A. and Agarwal, A. and Dudik, M. and Langford, J. and Jose, D. and Zitouni, I.},
 booktitle = {Advances in Neural Information Processing Systems},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Off-policy evaluation for slate recommendation},
 url = {https://proceedings.neurips.cc/paper/2017/file/5352696a9ca3397beb79f116f3a33991-Paper.pdf},
 volume = {30},
 year = {2017}
}

@inproceedings{Kiyohara2022,
author = {Kiyohara, H. and Saito, Y. and Matsuhiro, T. and Narita, Y. and Shimizu, N. and Yamamoto, Y.},
title = {Doubly Robust Off-Policy Evaluation for Ranking Policies under the Cascade Behavior Model},
year = {2022},
publisher = {ACM},
url = {https://doi.org/10.1145/3488560.3498380},
doi = {10.1145/3488560.3498380},
abstract = {In real-world recommender systems and search engines, optimizing ranking decisions to present a ranked list of relevant items is critical. Off-policy evaluation (OPE) for ranking policies is thus gaining a growing interest because it enables performance estimation of new ranking policies using only logged data. Although OPE in contextual bandits has been studied extensively, its naive application to the ranking setting faces a critical variance issue due to the huge item space. To tackle this problem, previous studies introduce some assumptions on user behavior to make the combinatorial item space tractable. However, an unrealistic assumption may, in turn, cause serious bias. Therefore, appropriately controlling the bias-variance tradeoff by imposing a reasonable assumption is the key for success in OPE of ranking policies. To achieve a well-balanced bias-variance tradeoff, we propose the Cascade Doubly Robust estimator building on the cascade assumption, which assumes that a user interacts with items sequentially from the top position in a ranking. We show that the proposed estimator is unbiased in more cases compared to existing estimators that make stronger assumptions on user behavior. Furthermore, compared to a previous estimator based on the same cascade assumption, the proposed estimator reduces the variance by leveraging a control variate. Comprehensive experiments on both synthetic and real-world e-commerce data demonstrate that our estimator leads to more accurate OPE than existing estimators in a variety of settings.},
booktitle = {Proc of. the Fifteenth ACM International Conference on Web Search and Data Mining},
pages = {487497},
numpages = {11},
keywords = {slate recommendation, off policy evaluation, inverse propensity score, doubly robust, cascade model},
series = {WSDM '22}
}

@inproceedings{McInerney2020,
author = {McInerney, J. and Brost, B. and Chandar, P. and Mehrotra, R. and Carterette, B.},
title = {Counterfactual Evaluation of Slate Recommendations with Sequential Reward Interactions},
year = {2020},
isbn = {9781450379984},
publisher = {ACM},
url = {https://doi.org/10.1145/3394486.3403229},
doi = {10.1145/3394486.3403229},
abstract = {Users of music streaming, video streaming, news recommendation, and e-commerce services often engage with content in a sequential manner. Providing and evaluating good sequences of recommendations is therefore a central problem for these services. Prior reweighting-based counterfactual evaluation methods either suffer from high variance or make strong independence assumptions about rewards. We propose a new counterfactual estimator that allows for sequential interactions in the rewards with lower variance in an asymptotically unbiased manner. Our method uses graphical assumptions about the causal relationships of the slate to reweight the rewards in the logging policy in a way that approximates the expected sum of rewards under the target policy. Extensive experiments in simulation and on a live recommender system show that our approach outperforms existing methods in terms of bias and data efficiency for the sequential track recommendations problem.},
booktitle = {Proc of. the 26th ACM SIGKDD International Conference on Knowledge Discovery \& Data Mining},
pages = {17791788},
numpages = {10},
keywords = {offline evaluation, recommender systems, sequential recommendation, learning to rank},
series = {KDD '20}
}

@article{Lopez2021, title={Learning from eXtreme Bandit Feedback}, volume={35}, url={https://ojs.aaai.org/index.php/AAAI/article/view/17058}, DOI={10.1609/aaai.v35i10.17058}, number={10}, journal={Proc of. the AAAI Conference on Artificial Intelligence}, author={Lopez, R. and Dhillon, I. S. and Jordan, M. I.}, year={2021}, month={May}, pages={8732-8740} }

@inproceedings{Tucker2023,
author = {Tucker, A. D. and Joachims, T.},
title = {Variance-Minimizing Augmentation Logging for Counterfactual Evaluation in Contextual Bandits},
year = {2023},
isbn = {9781450394079},
publisher = {ACM},
url = {https://doi.org/10.1145/3539597.3570452},
doi = {10.1145/3539597.3570452},
abstract = {Methods for offline A/B testing and counterfactual learning are seeing rapid adoption in search and recommender systems, since they allow efficient reuse of existing log data. However, there are fundamental limits to using existing log data alone, since the counterfactual estimators that are commonly used in these methods can have large bias and large variance when the logging policy is very different from the target policy being evaluated. To overcome this limitation, we explore the question of how to design data-gathering policies that most effectively augment an existing dataset of bandit feedback with additional observations for both learning and evaluation. To this effect, this paper introduces Minimum Variance Augmentation Logging (MVAL), a method for constructing logging policies that minimize the variance of the downstream evaluation or learning problem. We explore multiple approaches to computing MVAL policies efficiently, and find that they can be substantially more effective in decreasing the variance of an estimator than na\"{\i}ve approaches.},
booktitle = {Proc of. the Sixteenth ACM International Conference on Web Search and Data Mining},
pages = {967975},
numpages = {9},
keywords = {contextual bandits, counterfactual inference, off-policy evaluation and learning, recommender systems, reinforcement learning},
series = {WSDM '23}
}

@article{Elvira2019,
author = {V. Elvira and L. Martino and D. Luengo and M.F. Bugallo},
title = {{Generalized Multiple Importance Sampling}},
volume = {34},
journal = {Statistical Science},
number = {1},
publisher = {Institute of Mathematical Statistics},
pages = {129 -- 155},
keywords = {Bayesian inference, Monte Carlo methods, multiple importance sampling},
year = {2019},
doi = {10.1214/18-STS668},
URL = {https://doi.org/10.1214/18-STS668}
}


@article{Student1908,
 ISSN = {00063444},
 URL = {http://www.jstor.org/stable/2331474},
 author = {Student},
 journal = {Biometrika},
 number = {2/3},
 pages = {302--310},
 publisher = {[Oxford University Press, Biometrika Trust]},
 title = {Probable Error of a Correlation Coefficient},
 urldate = {2023-03-06},
 volume = {6},
 year = {1908}
}

@article{Jeunen2023Pessimism,
author = {Jeunen, O. and Goethals, B.},
title = {Pessimistic Decision-Making for Recommender Systems},
year = {2023},
issue_date = {March 2023},
publisher = {ACM},
volume = {1},
number = {1},
url = {https://doi.org/10.1145/3568029},
doi = {10.1145/3568029},
journal = {ACM Trans. Recomm. Syst.},
month = {feb},
articleno = {4},
numpages = {27},
keywords = {offline reinforcement learning, Contextual bandits, probabilistic models}
}

@inproceedings{Jeunen2023_C3PO,
author = {Jeunen, O.},
title = {A Probabilistic Position Bias Model for Short-Video Recommendation Feeds},
year = {2023},
publisher = {ACM},
booktitle = {Proc. of the 17th ACM Conference on Recommender Systems},
series = {RecSys '23}
}

@article{Joachims_London_Su_Swaminathan_Wang_2021, title={Recommendations as Treatments}, volume={42}, url={https://ojs.aaai.org/aimagazine/index.php/aimagazine/article/view/18141}, DOI={10.1609/aimag.v42i3.18141}, abstractNote={&lt;p&gt;In recent years, a new line of research has taken an interventional view of recommender systems, where recommendations are viewed as actions that the system takes to have a desired effect. This interventional view has led to the development of counterfactual inference techniques for evaluating and optimizing recommendation policies. This article explains how these techniques enable unbiased offline evaluation and learning despite biased data, and how they can inform considerations of fairness and equity in recommender systems.&lt;/p&gt;}, number={3}, journal={AI Magazine}, author={Joachims, T. and London, B. and Su, Y. and Swaminathan, A. and Wang, L.}, year={2021}, month={Nov.}, pages={19-30} }

@inproceedings{Saito2021,
author = {Saito, Y. and Joachims, T.},
title = {Counterfactual Learning and Evaluation for Recommender Systems: Foundations, Implementations, and Recent Advances},
year = {2021},
isbn = {9781450384582},
publisher = {ACM},
url = {https://doi.org/10.1145/3460231.3473320},
doi = {10.1145/3460231.3473320},
abstract = {Counterfactual estimators enable the use of existing log data to estimate how some new target recommendation policy would have performed, if it had been used instead of the policy that logged the data. We say that those estimators work off-policy, since the policy that logged the data is different from the target policy. In this way, counterfactual estimators enable Off-policy Evaluation (OPE) akin to an unbiased offline A/B test, as well as learning new recommendation policies through Off-policy Learning (OPL). The goal of this tutorial is to summarize Foundations, Implementations, and Recent Advances of OPE/OPL. Specifically, we will introduce the fundamentals of OPE/OPL and provide theoretical and empirical comparisons of conventional methods. Then, we will cover emerging practical challenges such as how to take into account combinatorial actions, distributional shift, fairness of exposure, and two-sided market structures. We will then present Open Bandit Pipeline, an open-source package for OPE/OPL, and how it can be used for both research and practical purposes. We will conclude the tutorial by presenting real-world case studies and future directions.},
booktitle = {Proc. of the 15th ACM Conference on Recommender Systems},
pages = {828830},
numpages = {3},
keywords = {counterfactuals, recommender systems, fairness of exposure, off-policy evaluation/learning},
series = {RecSys '21}
}

@inproceedings{Vasile2020,
author = {Vasile, F. and Rohde, D. and Jeunen, O. and Benhalloum, A.},
title = {A Gentle Introduction to Recommendation as Counterfactual Policy Learning},
year = {2020},
isbn = {9781450368612},
publisher = {ACM},
url = {https://doi.org/10.1145/3340631.3398666},
doi = {10.1145/3340631.3398666},
abstract = {The objective of this tutorial is to give a structured overview of the conceptual frameworks behind current state-of-the-art recommender systems, explain their underlying assumptions, the resulting methods and their shortcomings, and to introduce an exciting new class of approaches that frames the task of recommendation as a counterfactual policy learning problem. The tutorial can be divided into two modules. In module 1, participants learn about current approaches for building real-world recommender systems that comprise mainly of two frameworks, namely: recommendation as optimal auto-completion of user behaviour and recommendation as reward modelling. In module 2, we present the framework of recommendation as a counterfactual policy learning problem and go over the theoretical guarantees that address the shortcomings of the previous frameworks. We then proceed to go over the associated algorithms and test them against classical methods in RecoGym, an open-source recommendation simulation environment.Overall, we believe the subject of the course is extremely actual and fills a gap between the consecrated recommendation frameworks and the cutting edge research and sets the stage for future advances in the field.},
booktitle = {Proc. of the 28th ACM Conference on User Modeling, Adaptation and Personalization},
pages = {392393},
numpages = {2},
keywords = {counterfactual evaluation, recommender systems, counterfactual learning},
series = {UMAP '20}
}

@Article{Canamares2020,
author={Ca{\~{n}}amares, R.
and Castells, P.
and Moffat, A.},
title={Offline evaluation options for recommender systems},
journal={Information Retrieval Journal},
year={2020},
month={Aug},
day={01},
volume={23},
number={4},
pages={387-410},
abstract={We undertake a detailed examination of the steps that make up offline experiments for recommender system evaluation, including the manner in which the available ratings are filtered and split into training and test; the selection of a subset of the available users for the evaluation; the choice of strategy to handle the background effects that arise when the system is unable to provide scores for some items or users; the use of either full or condensed output lists for the purposes of scoring; scoring methods themselves, including alternative top-weighted mechanisms for condensed rankings; and the application of statistical testing on a weighted-by-user or weighted-by-volume basis as a mechanism for providing confidence in measured outcomes. We carry out experiments that illustrate the impact that each of these choice points can have on the usefulness of an end-to-end system evaluation, and provide examples of possible pitfalls. In particular, we show that varying the split between training and test data, or changing the evaluation metric, or how target items are selected, or how empty recommendations are dealt with, can give rise to comparisons that are vulnerable to misinterpretation, and may lead to different or even opposite outcomes, depending on the exact combination of settings used.},
issn={1573-7659},
doi={10.1007/s10791-020-09371-3},
url={https://doi.org/10.1007/s10791-020-09371-3}
}

@inproceedings{Krichene2020,
author = {Krichene, W. and Rendle, S.},
title = {On Sampled Metrics for Item Recommendation},
year = {2020},
isbn = {9781450379984},
publisher = {ACM},
url = {https://doi.org/10.1145/3394486.3403226},
doi = {10.1145/3394486.3403226},
abstract = {The task of item recommendation requires ranking a large catalogue of items given a context. Item recommendation algorithms are evaluated using ranking metrics that depend on the positions of relevant items. To speed up the computation of metrics, recent work often uses sampled metrics where only a smaller set of random items and the relevant items are ranked. This paper investigates sampled metrics in more detail and shows that they are inconsistent with their exact version, in the sense that they do not persist relative statements, e.g., recommender A is better than B, not even in expectation. Moreover, the smaller the sampling size, the less difference there is between metrics, and for very small sampling size, all metrics collapse to the AUC metric. We show that it is possible to improve the quality of the sampled metrics by applying a correction, obtained by minimizing different criteria such as bias or mean squared error. We conclude with an empirical evaluation of the naive sampled metrics and their corrected variants. To summarize, our work suggests that sampling should be avoided for metric calculation, however if an experimental study needs to sample, the proposed corrections can improve the quality of the estimate.},
booktitle = {Proc. of the 26th ACM SIGKDD International Conference on Knowledge Discovery \& Data Mining},
pages = {17481757},
numpages = {10},
keywords = {evaluation, sampled metric, metrics, item recommendation},
series = {KDD '20}
}

@inproceedings{Canamares2020RecSys,
author = {Ca\~{n}amares, R. and Castells, P.},
title = {On Target Item Sampling In Offline Recommender System Evaluation},
year = {2020},
isbn = {9781450375832},
publisher = {ACM},
url = {https://doi.org/10.1145/3383313.3412259},
doi = {10.1145/3383313.3412259},
abstract = {Target selection is a basic yet often implicit decision in the configuration of offline recommendation experiments. In this paper we research the impact of target sampling on the outcome of comparative recommender system evaluation. Specifically, we undertake a detailed analysis considering the informativeness and consistency of experiments across the target size axis. We find that comparative evaluation using reduced target sets contradicts in many cases the corresponding outcome using large targets, and we provide a principled explanation for these disagreements. We further seek to determine which among the contradicting results may be more reliable. Through comparison to unbiased evaluation, we find that minimum target sets incur in substantial distortion in pairwise system comparisons, while maximum sets may not be ideal either, and better options may lie in between the extremes. We further find means for informing the target size setting in the common case where unbiased evaluation is not possible, by an assessment of the discriminative power of evaluation, that remarkably aligns with the agreement with unbiased evaluation.},
booktitle = {Proc. of the 14th ACM Conference on Recommender Systems},
pages = {259268},
numpages = {10},
keywords = {experimental design, target items, metrics, offline evaluation, evaluation bias, discriminative power},
series = {RecSys '20}
}

@inproceedings{FerrariDacrema2019,
author = {Ferrari Dacrema, M. and Cremonesi, P. and Jannach, D.},
title = {Are We Really Making Much Progress? A Worrying Analysis of Recent Neural Recommendation Approaches},
year = {2019},
isbn = {9781450362436},
publisher = {ACM},
url = {https://doi.org/10.1145/3298689.3347058},
doi = {10.1145/3298689.3347058},
abstract = {Deep learning techniques have become the method of choice for researchers working on algorithmic aspects of recommender systems. With the strongly increased interest in machine learning in general, it has, as a result, become difficult to keep track of what represents the state-of-the-art at the moment, e.g., for top-n recommendation tasks. At the same time, several recent publications point out problems in today's research practice in applied machine learning, e.g., in terms of the reproducibility of the results or the choice of the baselines when proposing new models.In this work, we report the results of a systematic analysis of algorithmic proposals for top-n recommendation tasks. Specifically, we considered 18 algorithms that were presented at top-level research conferences in the last years. Only 7 of them could be reproduced with reasonable effort. For these methods, it however turned out that 6 of them can often be outperformed with comparably simple heuristic methods, e.g., based on nearest-neighbor or graph-based techniques. The remaining one clearly outperformed the baselines but did not consistently outperform a well-tuned non-neural linear ranking method. Overall, our work sheds light on a number of potential problems in today's machine learning scholarship and calls for improved scientific practices in this area.},
booktitle = {Proc. of the 13th ACM Conference on Recommender Systems},
pages = {101109},
numpages = {9},
keywords = {reproducibility, recommender systems, deep learning, evaluation},
series = {RecSys '19}
}

@article{FerrariDacrema2021,
author = {Ferrari Dacrema, M. and Boglio, S. and Cremonesi, P. and Jannach, D.},
title = {A Troubling Analysis of Reproducibility and Progress in Recommender Systems Research},
year = {2021},
issue_date = {April 2021},
publisher = {ACM},
volume = {39},
number = {2},
issn = {1046-8188},
url = {https://doi.org/10.1145/3434185},
doi = {10.1145/3434185},
abstract = {The design of algorithms that generate personalized ranked item lists is a central topic of research in the field of recommender systems. In the past few years, in particular, approaches based on deep learning (neural) techniques have become dominant in the literature. For all of them, substantial progress over the state-of-the-art is claimed. However, indications exist of certain problems in todays research practice, e.g., with respect to the choice and optimization of the baselines used for comparison, raising questions about the published claims. To obtain a better understanding of the actual progress, we have compared recent results in the area of neural recommendation approaches based on collaborative filtering against a consistent set of existing simple baselines. The worrying outcome of the analysis of these recent worksall were published at prestigious scientific conferences between 2015 and 2018is that 11 of the 12 reproducible neural approaches can be outperformed by conceptually simple methods, e.g., based on the nearest-neighbor heuristic or linear models. None of the computationally complex neural methods was actually consistently better than already existing learning-based techniques, e.g., using matrix factorization or linear models. In our analysis, we discuss common issues in todays research practice, which, despite the many papers that are published on the topic, have apparently led the field to a certain level of stagnation.1},
journal = {ACM Trans. Inf. Syst.},
month = {jan},
articleno = {20},
numpages = {49},
keywords = {deep learning, evaluation; reproducibility, Recommender systems}
}

@inproceedings{Rendle2020,
author = {Rendle, S. and Krichene, W. and Zhang, L. and Anderson, J.},
title = {Neural Collaborative Filtering vs. Matrix Factorization Revisited},
year = {2020},
isbn = {9781450375832},
publisher = {ACM},
url = {https://doi.org/10.1145/3383313.3412488},
doi = {10.1145/3383313.3412488},
abstract = {Embedding based models have been the state of the art in collaborative filtering for over a decade. Traditionally, the dot product or higher order equivalents have been used to combine two or more embeddings, e.g., most notably in matrix factorization. In recent years, it was suggested to replace the dot product with a learned similarity e.g. using a multilayer perceptron (MLP). This approach is often referred to as neural collaborative filtering (NCF). In this work, we revisit the experiments of the NCF paper that popularized learned similarities using MLPs. First, we show that with a proper hyperparameter selection, a simple dot product substantially outperforms the proposed learned similarities. Second, while a MLP can in theory approximate any function, we show that it is non-trivial to learn a dot product with an MLP. Finally, we discuss practical issues that arise when applying MLP based similarities and show that MLPs are too costly to use for item recommendation in production environments while dot products allow to apply very efficient retrieval algorithms. We conclude that MLPs should be used with care as embedding combiner and that dot products might be a better default choice.},
booktitle = {Proc of. the 14th ACM Conference on Recommender Systems},
pages = {240248},
numpages = {9},
keywords = {Matrix Factorization, Neural Collaborative Filtering, Item Recommendation},
series = {RecSys '20}
}

@inproceedings{Rendle2022,
author = {Rendle, S. and Krichene, W. and Zhang, L. and Koren, Y.},
title = {Revisiting the Performance of IALS on Item Recommendation Benchmarks},
year = {2022},
isbn = {9781450392785},
publisher = {ACM},
url = {https://doi.org/10.1145/3523227.3548486},
doi = {10.1145/3523227.3548486},
abstract = {Matrix factorization learned by implicit alternating least squares (iALS) is a popular baseline in recommender system research publications. iALS is known to be one of the most computationally efficient and scalable collaborative filtering methods. However, recent studies suggest that its prediction quality is not competitive with the current state of the art, in particular autoencoders and other item-based collaborative filtering methods. In this work, we revisit four well-studied benchmarks where iALS was reported to perform poorly and show that with proper tuning, iALS is highly competitive and outperforms any method on at least half of the comparisons. We hope that these high quality results together with iALSs known scalability spark new interest in applying and further improving this decade old technique.},
booktitle = {Proc. of the 16th ACM Conference on Recommender Systems},
pages = {427435},
numpages = {9},
keywords = {Recommender System, Item Recommendation, Benchmark, iALS},
series = {RecSys '22}
}

@inproceedings{Armstrong2009,
author = {Armstrong, T. G. and Moffat, A. and Webber, W. and Zobel, J.},
title = {Improvements That Don't Add up: Ad-Hoc Retrieval Results since 1998},
year = {2009},
isbn = {9781605585123},
publisher = {ACM},
url = {https://doi.org/10.1145/1645953.1646031},
doi = {10.1145/1645953.1646031},
abstract = {The existence and use of standard test collections in information retrieval experimentation allows results to be compared between research groups and over time. Such comparisons, however, are rarely made. Most researchers only report results from their own experiments, a practice that allows lack of overall improvement to go unnoticed. In this paper, we analyze results achieved on the TREC Ad-Hoc, Web, Terabyte, and Robust collections as reported in SIGIR (1998--2008) and CIKM (2004--2008). Dozens of individual published experiments report effectiveness improvements, and often claim statistical significance. However, there is little evidence of improvement in ad-hoc retrieval technology over the past decade. Baselines are generally weak, often being below the median original TREC system. And in only a handful of experiments is the score of the best TREC automatic run exceeded. Given this finding, we question the value of achieving even a statistically significant result over a weak baseline. We propose that the community adopt a practice of regular longitudinal comparison to ensure measurable progress, or at least prevent the lack of it from going unnoticed. We describe an online database of retrieval runs that facilitates such a practice.},
booktitle = {Proc of. the 18th ACM Conference on Information and Knowledge Management},
pages = {601610},
numpages = {10},
keywords = {survey, retrieval experiment, system measurement, evaluation},
series = {CIKM '09}
}

@article{Deffayet2023,
author = {Deffayet, R. and Thonet, T. and Renders, J. M. and de Rijke, M.},
title = {Offline Evaluation for Reinforcement Learning-Based Recommendation: A Critical Issue and Some Alternatives},
year = {2023},
issue_date = {December 2022},
publisher = {ACM},
volume = {56},
number = {2},
issn = {0163-5840},
url = {https://doi.org/10.1145/3582900.3582905},
doi = {10.1145/3582900.3582905},
abstract = {In this paper, we argue that the paradigm commonly adopted for offline evaluation of sequential recommender systems is unsuitable for evaluating reinforcement learning-based recommenders. We find that most of the existing offline evaluation practices for reinforcement learning-based recommendation are based on a next-item prediction protocol, and detail three shortcomings of such an evaluation protocol. Notably, it cannot reflect the potential benefits that reinforcement learning (RL) is expected to bring while it hides critical deficiencies of certain offline RL agents. Our suggestions for alternative ways to evaluate RL-based recommender systems aim to shed light on the existing possibilities and inspire future research on reliable evaluation protocols.},
journal = {SIGIR Forum},
month = {jan},
articleno = {3},
numpages = {14}
}

@article{Jadidinejad2021,
author = {Jadidinejad, A. H. and Macdonald, C. and Ounis, I.},
title = {The Simpsons Paradox in the Offline Evaluation of Recommendation Systems},
year = {2021},
issue_date = {January 2022},
publisher = {ACM},
volume = {40},
number = {1},
issn = {1046-8188},
url = {https://doi.org/10.1145/3458509},
doi = {10.1145/3458509},
journal = {ACM Trans. Inf. Syst.},
month = {sep},
articleno = {4},
numpages = {22},
keywords = {selection bias, popularity bias, Simpsons paradox, experimental design, Offline evaluation}
}

@article{Ji2023,
author = {Ji, Y. and Sun, A. and Zhang, J. and Li, C.},
title = {A Critical Study on Data Leakage in Recommender System Offline Evaluation},
year = {2023},
issue_date = {July 2023},
publisher = {ACM},
volume = {41},
number = {3},
issn = {1046-8188},
url = {https://doi.org/10.1145/3569930},
doi = {10.1145/3569930},
abstract = {Recommender models are hard to evaluate, particularly under offline setting. In this article, we provide a comprehensive and critical analysis of the data leakage issue in recommender system offline evaluation. Data leakage is caused by not observing global timeline in evaluating recommenders e.g., train/test data split does not follow global timeline. As a result, a model learns from the user-item interactions that are not expected to be available at the prediction time. We first show the temporal dynamics of user-item interactions along global timeline, then explain why data leakage exists for collaborative filtering models. Through carefully designed experiments, we show that all models indeed recommend future items that are not available at the time point of a test instance, as the result of data leakage. The experiments are conducted with four widely used baseline modelsBPR, NeuMF, SASRec, and LightGCN, on four popular offline datasetsMovieLens-25M, Yelp, Amazon-music, and Amazon-electronic, adopting leave-last-one-out data split.1 We further show that data leakage does impact models recommendation accuracy. Their relative performance orders thus become unpredictable with different amount of leaked future data in training. To evaluate recommendation systems in a realistic manner in offline setting, we propose a timeline scheme, which calls for a revisit of the recommendation model design.},
journal = {ACM Trans. Inf. Syst.},
month = {feb},
articleno = {75},
numpages = {27},
keywords = {Recommender systems, evaluation, data leakage}
}

@inproceedings{Saito2021_Robustness,
author = {Saito, Y. and Udagawa, T. and Kiyohara, H. and Mogi, K. and Narita, Y. and Tateno, K.},
title = {Evaluating the Robustness of Off-Policy Evaluation},
year = {2021},
isbn = {9781450384582},
publisher = {ACM},
url = {https://doi.org/10.1145/3460231.3474245},
doi = {10.1145/3460231.3474245},
abstract = {Off-policy Evaluation (OPE), or offline evaluation in general, evaluates the performance of hypothetical policies leveraging only offline log data. It is particularly useful in applications where the online interaction involves high stakes and expensive setting such as precision medicine and recommender systems. Since many OPE estimators have been proposed and some of them have hyperparameters to be tuned, there is an emerging challenge for practitioners to select and tune OPE estimators for their specific application. Unfortunately, identifying a reliable estimator from results reported in research papers is often difficult because the current experimental procedure evaluates and compares the estimators performance on a narrow set of hyperparameters and evaluation policies. Therefore, it is difficult to know which estimator is safe and reliable to use. In this work, we develop Interpretable Evaluation for Offline Evaluation (IEOE), an experimental procedure to evaluate OPE estimators robustness to changes in hyperparameters and/or evaluation policies in an interpretable manner. Then, using the IEOE procedure, we perform extensive evaluation of a wide variety of existing estimators on Open Bandit Dataset, a large-scale public real-world dataset for OPE. We demonstrate that our procedure can evaluate the estimators robustness to the hyperparamter choice, helping us avoid using unsafe estimators. Finally, we apply IEOE to real-world e-commerce platform data and demonstrate how to use our protocol in practice.},
booktitle = {Proc. of the 15th ACM Conference on Recommender Systems},
pages = {114123},
numpages = {10},
keywords = {off-policy evaluation, counterfactual estimation, recommender systems},
series = {RecSys '21}
}

@article{Udagawa2022, title={Policy-Adaptive Estimator Selection for Off-Policy Evaluation}, volume={37}, url={https://ojs.aaai.org/index.php/AAAI/article/view/26195}, DOI={10.1609/aaai.v37i8.26195}, number={8}, journal={Proc. of the AAAI Conference on Artificial Intelligence}, author={Udagawa, T. and Kiyohara, H. and Narita, Y. and Saito, Y. and Tateno, K.}, year={2023}, month={Jun.}, pages={10025-10033} }


@InProceedings{Kallus2021Optimal,
  title = 	 {Optimal Off-Policy Evaluation from Multiple Logging Policies},
  author =       {Kallus, N. and Saito, Y. and Uehara, M.},
  booktitle = 	 {Proc. of the 38th International Conference on Machine Learning},
  pages = 	 {5247--5256},
  year = 	 {2021},
  editor = 	 {Meila, Marina and Zhang, Tong},
  volume = 	 {139},
  series = 	 {ICML '21},
  month = 	 {18--24 Jul},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v139/kallus21a/kallus21a.pdf},
  url = 	 {https://proceedings.mlr.press/v139/kallus21a.html}
}

@inproceedings{Borisov2016,
author = {Borisov, A. and Markov, I. and de Rijke, M. and Serdyukov, P.},
title = {A Neural Click Model for Web Search},
year = {2016},
isbn = {9781450341431},
url = {https://doi.org/10.1145/2872427.2883033},
doi = {10.1145/2872427.2883033},
abstract = {Understanding user browsing behavior in web search is key to improving web search effectiveness. Many click models have been proposed to explain or predict user clicks on search engine results. They are based on the probabilistic graphical model (PGM) framework, in which user behavior is represented as a sequence of observable and hidden events. The PGM framework provides a mathematically solid way to reason about a set of events given some information about other events. But the structure of the dependencies between the events has to be set manually. Different click models use different hand-crafted sets of dependencies. We propose an alternative based on the idea of distributed representations: to represent the user's information need and the information available to the user with a vector state. The components of the vector state are learned to represent concepts that are useful for modeling user behavior. And user behavior is modeled as a sequence of vector states associated with a query session: the vector state is initialized with a query, and then iteratively updated based on information about interactions with the search engine results. This approach allows us to directly understand user browsing behavior from click-through data, i.e., without the need for a predefined set of rules as is customary for PGM-based click models. We illustrate our approach using a set of neural click models. Our experimental results show that the neural click model that uses the same training data as traditional PGM-based click models, has better performance on the click prediction task (i.e., predicting user click on search engine results) and the relevance prediction task (i.e., ranking documents by their relevance to a query). An analysis of the best performing neural click model shows that it learns similar concepts to those used in traditional click models, and that it also learns other concepts that cannot be designed manually.},
booktitle = {Proc. of the 25th International Conference on World Wide Web},
pages = {531541},
numpages = {11},
keywords = {distributed representations, deep learning, user behavior, recurrent neural networks, click modeling, web search},
series = {WWW '16}
}

@inproceedings{Chen2020_CACM,
author = {Chen, J. and Mao, J. and Liu, Y. and Zhang, M. and Ma, S.},
title = {A Context-Aware Click Model for Web Search},
year = {2020},
isbn = {9781450368223},
publisher = {ACM},
url = {https://doi.org/10.1145/3336191.3371819},
doi = {10.1145/3336191.3371819},
abstract = {To better exploit the search logs, various click models have been proposed to extract implicit relevance feedback from user clicks. Most traditional click models are based on probability graphical models (PGMs) with manually designed dependencies. Recently, some researchers also adopt neural-based methods to improve the accuracy of click prediction. However, most of the existing click models only model user behavior in query level. As the previous iterations within the session may have an impact on the current search round, we can leverage these behavior signals to better model user behaviors. In this paper, we propose a novel neural- based Context-Aware Click Model (CACM) for Web search. CACM consists of a context-aware relevance estimator and an examination predictor. The relevance estimator utilizes session context infor- mation, i.e., the query sequence and clickthrough data, as well as the pre-trained embeddings learned from a session-flow graph to estimate the context-aware relevance of each search result. The examination predictor estimates the examination probability of each result. We further investigate several combination functions to integrate the context-aware relevance and examination probabil- ity into click prediction. Experiment results on a public Web search dataset show that CACM outperforms existing click models in both relevance estimation and click prediction tasks.},
booktitle = {Proc. of the 13th International Conference on Web Search and Data Mining},
pages = {8896},
numpages = {9},
keywords = {web search, click model, document ranking, click prediction},
series = {WSDM '20}
}

@inproceedings{Clarke2008,
author = {Clarke, C.L.A. and Kolla, M. and Cormack, G. V. and Vechtomova, O. and Ashkan, A. and B\"{u}ttcher, S. and MacKinnon, I.},
title = {Novelty and Diversity in Information Retrieval Evaluation},
year = {2008},
isbn = {9781605581644},
publisher = {ACM},
url = {https://doi.org/10.1145/1390334.1390446},
doi = {10.1145/1390334.1390446},
abstract = {Evaluation measures act as objective functions to be optimized by information retrieval systems. Such objective functions must accurately reflect user requirements, particularly when tuning IR systems and learning ranking functions. Ambiguity in queries and redundancy in retrieved documents are poorly reflected by current evaluation measures. In this paper, we present a framework for evaluation that systematically rewards novelty and diversity. We develop this framework into a specific evaluation measure, based on cumulative gain. We demonstrate the feasibility of our approach using a test collection based on the TREC question answering track.},
booktitle = {Proc. of the 31st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {659666},
numpages = {8},
keywords = {novelty, evaluation, test collections},
series = {SIGIR '08}
}

@inproceedings{Parapar2021,
author = {Parapar, J. and Radlinski, F.},
title = {Towards Unified Metrics for Accuracy and Diversity for Recommender Systems},
year = {2021},
isbn = {9781450384582},
publisher = {ACM},
url = {https://doi.org/10.1145/3460231.3474234},
doi = {10.1145/3460231.3474234},
abstract = {Recommender systems evaluation has evolved rapidly in recent years. However, for offline evaluation, accuracy is the de facto standard for assessing the superiority of one method over another, with most research comparisons focused on tasks ranging from rating prediction to ranking metrics for top-n recommendation. Simultaneously, recommendation diversity and novelty have become recognized as critical to users perceived utility, with several new metrics recently proposed for evaluating these aspects of recommendation lists. Consequently, the accuracy-diversity dilemma frequently shows up as a choice to make when creating new recommendation algorithms. We propose a novel adaptation of a unified metric, derived from one commonly used for search system evaluation, to Recommender Systems. The proposed metric combines topical diversity and accuracy, and we show it to satisfy a set of desired properties that we formulate axiomatically. These axioms are defined as fundamental constraints that a good unified metric should always satisfy. Moreover, beyond the axiomatic analysis, we present an experimental evaluation of the metric with collaborative filtering data. Our analysis shows that the metric respects the desired theoretical constraints and behaves as expected when performing offline evaluation.},
booktitle = {Proc. of the 15th ACM Conference on Recommender Systems},
pages = {7584},
numpages = {10},
keywords = {recommender systems, offline evaluation, metrics, diversity},
series = {RecSys '21}
}

@ARTICLE{Ferrante2021,
  author={Ferrante, M. and Ferro, N. and Fuhr, N.},
  journal={IEEE Access}, 
  title={Towards Meaningful Statements in IR Evaluation: Mapping Evaluation Measures to Interval Scales}, 
  year={2021},
  volume={9},
  number={},
  pages={136182-136216},
  abstract={Information Retrieval (IR) is a discipline deeply rooted in evaluation since its inception. Indeed, experimentally measuring and statistically validating the performance of IR systems are the only possible ways to compare systems and understand which are better than others and, ultimately, more effective and useful for end-users. Since the seminal paper by Stevens (1946), it is known that the properties of the measurement scales determine the operations you should or should not perform with values from those scales. For example, Stevens suggested that you can compute means and variances only when you are working with, at least, interval scales. It was recently shown that the most popular evaluation measures in IR are not interval-scaled. However, so far, there has been little or no investigation in IR on the impact and consequences of departing from scale assumptions. Taken to the extremes, it might even mean that decades of experimental IR research used potentially improper methods, which may have produced results needing further validation. However, it was unclear if and to what extent these findings apply to actual evaluations; this opened a debate in the community with researchers standing on opposite positions about whether this should be considered an issue (or not) and to what extent. In this paper, we first give an introduction to the representational measurement theory explaining why certain operations and significance tests are permissible only with scales of a certain level. For that, we introduce the notion of meaningfulness specifying the conditions under which the truth (or falsity) of a statement is invariant under permissible transformations of a scale. Furthermore, we show how the recall base and the length of the run may make comparison and aggregation across topics problematic. Then we propose a straightforward and powerful approach for turning an evaluation measure into an interval scale, and describe an experimental evaluation of the differences between the original measures and the interval-scaled ones. For all the regarded measures  namely Precision, Recall, Average Precision, (Normalized) Discounted Cumulative Gain, Rank-Biased Precision and Reciprocal Rank - we observe substantial effects, both on the order of average values and on the outcome of significance tests. For the latter, previously significant differences turn out to be insignificant, while insignificant ones become significant. The effect varies remarkably between the tests considered but on average, we observed a 25% change in the decision about which systems are significantly different and which are not. These experimental findings further support the idea that measurement scales matter and that departing from their assumptions has an impact. This not only suggests that, to the extent possible, it would be better to comply with such assumptions but it also urges us to clearly indicate when we depart from such assumptions and, carefully, point out the limitations of the conclusions we draw and under which conditions they are drawn.},
  keywords={},
  doi={10.1109/ACCESS.2021.3116857},
  ISSN={2169-3536},
  month={},}


@inproceedings{Kharitonov2017,
author = {Kharitonov, E. and Drutsa, A. and Serdyukov, P.},
title = {Learning Sensitive Combinations of A/B Test Metrics},
year = {2017},
isbn = {9781450346757},
publisher = {ACM},
url = {https://doi.org/10.1145/3018661.3018708},
doi = {10.1145/3018661.3018708},
booktitle = {Proc. of the Tenth ACM International Conference on Web Search and Data Mining},
pages = {651659},
numpages = {9},
keywords = {a/b tests, online evaluation, sensitivity improvement, metric combination, online controlled experiments},
series = {WSDM '17}
}

@inproceedings{Mehrotra2018,
author = {Mehrotra, R. and McInerney, J. and Bouchard, H. and Lalmas, M. and Diaz, F.},
title = {Towards a Fair Marketplace: Counterfactual Evaluation of the Trade-off between Relevance, Fairness \& Satisfaction in Recommendation Systems},
year = {2018},
isbn = {9781450360142},
publisher = {ACM},
url = {https://doi.org/10.1145/3269206.3272027},
doi = {10.1145/3269206.3272027},
booktitle = {Proc. of the 27th ACM International Conference on Information and Knowledge Management},
pages = {22432251},
numpages = {9},
keywords = {fairness, satisfaction, marketplace},
series = {CIKM '18}
}

@Inbook{Abdollahpouri2022,
author="Abdollahpouri, H.
and Burke, R.",
title="Multistakeholder Recommender Systems",
bookTitle="Recommender Systems Handbook",
year="2022",
publisher="Springer US",
pages="647--677",
isbn="978-1-0716-2197-4",
doi="10.1007/978-1-0716-2197-4_17",
url="https://doi.org/10.1007/978-1-0716-2197-4_17"
}

@inproceedings{Gupta2023,
author = {Gupta, S. and Oosterhuis, H. and {de Rijke}, M.},
title = {Safe Deployment for Counterfactual Learning to Rank with Exposure-Based Risk Minimization},
year = {2023},
publisher = {ACM},
url = {https://doi.org/10.1145/3539618.3591760},
doi = {10.1145/3539618.3591760},
booktitle = {Proc. of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {249258},
numpages = {10},
keywords = {safety, counterfactual learning to rank, learning to rank},
series = {SIGIR '23}
}

@inproceedings{AlMaskari2007,
author = {Al-Maskari, A. and Sanderson, M. and Clough, P.},
title = {The Relationship between IR Effectiveness Measures and User Satisfaction},
year = {2007},
isbn = {9781595935977},
publisher = {ACM},
url = {https://doi.org/10.1145/1277741.1277902},
doi = {10.1145/1277741.1277902},
abstract = {This paper presents an experimental study of users assessing the quality of Google web search results. In particular we look at how users' satisfaction correlates with the effectiveness of Google as quantified by IR measures such as precision and the suite of Cumulative Gain measures (CG, DCG, NDCG). Results indicate strong correlation between users' satisfaction, CG and precision, moderate correlation with DCG, with perhaps surprisingly negligible correlation with NDCG. The reasons for the low correlation with NDCG are examined.},
booktitle = {Proc of. the 30th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {773774},
numpages = {2},
keywords = {IR effectiveness measures, user satisfaction},
series = {SIGIR '07}
}

@inproceedings{Verstrepen2014,
author = {Verstrepen, K. and Goethals, B.},
title = {Unifying Nearest Neighbors Collaborative Filtering},
year = {2014},
isbn = {9781450326681},
publisher = {ACM},
url = {https://doi.org/10.1145/2645710.2645731},
doi = {10.1145/2645710.2645731},
abstract = {We study collaborative filtering for applications in which there exists for every user a set of items about which the user has given binary, positive-only feedback (one-class collaborative filtering). Take for example an on-line store that knows all past purchases of every customer. An important class of algorithms for one-class collaborative filtering are the nearest neighbors algorithms, typically divided into user-based and item-based algorithms. We introduce a reformulation that unifies user- and item-based nearest neighbors algorithms and use this reformulation to propose a novel algorithm that incorporates the best of both worlds and outperforms state-of-the-art algorithms. Additionally, we propose a method for naturally explaining the recommendations made by our algorithm and show that this method is also applicable to existing user-based nearest neighbors methods.},
booktitle = {Proc. of the 8th ACM Conference on Recommender Systems},
pages = {177184},
numpages = {8},
keywords = {explaining recommendations, top-n recommendation, nearest neighbours, one-class collaborative filtering, recommender systems},
series = {RecSys '14}
}

@inproceedings{Michiels2022,
author = {Michiels, L. and Verachtert, R. and Goethals, B.},
title = {RecPack: An(Other) Experimentation Toolkit for Top-N Recommendation Using Implicit Feedback Data},
year = {2022},
isbn = {9781450392785},
publisher = {ACM},
url = {https://doi.org/10.1145/3523227.3551472},
doi = {10.1145/3523227.3551472},
abstract = {RecPack is an easy-to-use, flexible and extensible toolkit for top-N recommendation with implicit feedback data. Its goal is to support researchers with the development of their recommendation algorithms, from similarity-based to deep learning algorithms, and allow for correct, reproducible and reusable experimentation. In this demo, we give an overview of the package and show how researchers can use it to their advantage when developing recommendation algorithms.},
booktitle = {Proc. of the 16th ACM Conference on Recommender Systems},
pages = {648651},
numpages = {4},
keywords = {Python, open-source framework, evaluation, implicit feedback data, top-N recommendation},
series = {RecSys '22}
}


@InProceedings{Ustimenko2020,
  title = 	 {{S}tochastic{R}ank: Global Optimization of Scale-Free Discrete Functions},
  author =       {Ustimenko, A. and Prokhorenkova, L.},
  booktitle = 	 {Proc of. the 37th International Conference on Machine Learning},
  pages = 	 {9669--9679},
  year = 	 {2020},
  volume = 	 {119},
  series = 	 {ICML '20'},
  month = 	 {13--18 Jul},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v119/ustimenko20a/ustimenko20a.pdf},
  url = 	 {https://proceedings.mlr.press/v119/ustimenko20a.html},
  abstract = 	 {In this paper, we introduce a powerful and efficient framework for direct optimization of ranking metrics. The problem is ill-posed due to the discrete structure of the loss, and to deal with that, we introduce two important techniques: stochastic smoothing and novel gradient estimate based on partial integration. We show that classic smoothing approaches may introduce bias and present a universal solution for a proper debiasing. Importantly, we can guarantee global convergence of our method by adopting a recently proposed Stochastic Gradient Langevin Boosting algorithm. Our algorithm is implemented as a part of the CatBoost gradient boosting library and outperforms the existing approaches on several learning-to-rank datasets. In addition to ranking metrics, our framework applies to any scale-free discrete loss function.}
}

@inproceedings{Jagerman2022,
author = {Jagerman, R. and Wang, X. and Zhuang, H. and Qin, Z. and Bendersky, M. and Najork, M.},
title = {Rax: Composable Learning-to-Rank Using JAX},
year = {2022},
isbn = {9781450393850},
publisher = {ACM},
url = {https://doi.org/10.1145/3534678.3539065},
doi = {10.1145/3534678.3539065},
abstract = {Rax is a library for composable Learning-to-Rank (LTR) written entirely in JAX. The goal of Rax is to facilitate easy prototyping of LTR systems by leveraging the flexibility and simplicity of JAX. Rax provides a diverse set of popular ranking metrics and losses that integrate well with the rest of the JAX ecosystem. Furthermore, Rax implements a system of ranking-specific function transformations which allows fine-grained customization of ranking losses and metrics. Most notably Rax provides approx_t12n: a function transformation (t12n) that can transform any of our ranking metrics into an approximate and differentiable form that can be optimized. This provides a systematic way to directly optimize neural ranking models for ranking metrics that are not easily optimizable in other libraries. We empirically demonstrate the effectiveness of Rax by benchmarking neural models implemented using Flax and trained using Rax on two popular LTR benchmarks: WEB30K and Istella. Furthermore, we show that integrating ranking losses with T5, a large language model, can improve overall ranking performance on the MS MARCO passage ranking task. We are sharing the Rax library with the open source community as part of the larger JAX ecosystem at https://github.com/google/rax.},
booktitle = {Proc. of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {30513060},
numpages = {10},
keywords = {learning to rank, JAX},
series = {KDD '22}
}


@InProceedings{Lyzhin2023,
  title = 	 {Which Tricks are Important for Learning to Rank?},
  author =       {Lyzhin, I. and Ustimenko, A. and Gulin, A. and Prokhorenkova, L.},
  booktitle = 	 {Proc of. the 40th International Conference on Machine Learning},
  pages = 	 {23264--23278},
  year = 	 {2023},
  volume = 	 {202},
  series = 	 {ICML '23'},
  month = 	 {23--29 Jul},
  publisher =    {PMLR},
  pdf = 	 {https://proceedings.mlr.press/v202/lyzhin23a/lyzhin23a.pdf},
  url = 	 {https://proceedings.mlr.press/v202/lyzhin23a.html},
  abstract = 	 {Nowadays, state-of-the-art learning-to-rank methods are based on gradient-boosted decision trees (GBDT). The most well-known algorithm is LambdaMART which was proposed more than a decade ago. Recently, several other GBDT-based ranking algorithms were proposed. In this paper, we thoroughly analyze these methods in a unified setup. In particular, we address the following questions. Is direct optimization of a smoothed ranking loss preferable over optimizing a convex surrogate? How to properly construct and smooth surrogate ranking losses? To address these questions, we compare LambdaMART with YetiRank and StochasticRank methods and their modifications. We also propose a simple improvement of the YetiRank approach that allows for optimizing specific ranking loss functions. As a result, we gain insights into learning-to-rank techniques and obtain a new state-of-the-art algorithm.}
}

@article{Zangerle2023,
author = {Zangerle, E. and Bauer, C.},
title = {Evaluating Recommender Systems: Survey and Framework},
year = {2022},
issue_date = {August 2023},
publisher = {ACM},
volume = {55},
number = {8},
issn = {0360-0300},
url = {https://doi.org/10.1145/3556536},
doi = {10.1145/3556536},
abstract = {The comprehensive evaluation of the performance of a recommender system is a complex endeavor: many facets need to be considered in configuring an adequate and effective evaluation setting. Such facets include, for instance, defining the specific goals of the evaluation, choosing an evaluation method, underlying data, and suitable evaluation metrics. In this article, we consolidate and systematically organize this dispersed knowledge on recommender systems evaluation. We introduce the Framework for Evaluating Recommender systems (FEVR), which we derive from the discourse on recommender systems evaluation. In FEVR, we categorize the evaluation space of recommender systems evaluation. We postulate that the comprehensive evaluation of a recommender system frequently requires considering multiple facets and perspectives in the evaluation. The FEVR framework provides a structured foundation to adopt adequate evaluation configurations that encompass this required multi-facetedness and provides the basis to advance in the field. We outline and discuss the challenges of a comprehensive evaluation of recommender systems and provide an outlook on what we need to embrace and do to move forward as a research community.},
journal = {ACM Comput. Surv.},
month = {dec},
articleno = {170},
numpages = {38},
keywords = {Framework for EValuating Recommender systems, FEVR, Survey}
}

@Inproceedings{Jakimov2023,
    author = {M. Jakimov and A. Buchholz and Y. Stein and T. Joachims},
    title={Unbiased Offline Evaluation for Learning to Rank with Business Rules}, 
    year = {2023},
    booktitle = {RecSys 2023 Workshop: CONSEQUENCES  Causality, Counterfactuals and Sequential Decision-Making},
    eprint={2311.01828},
    archivePrefix={arXiv} 
}

@Inproceedings{Jeunen2023_CONSEQUENCES,
    title={Offline Recommender System Evaluation under Unobserved Confounding}, 
    author={O. Jeunen and B. London},
    year={2023},
    booktitle = {RecSys 2023 Workshop: CONSEQUENCES  Causality, Counterfactuals and Sequential Decision-Making},
    eprint={2309.04222},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}


@article{Cavenaghi2023,
author = {Cavenaghi, E. and Sottocornola, G. and Stella, F. and Zanker, M.},
title = {A Systematic Study on Reproducibility of Reinforcement Learning in Recommendation Systems},
year = {2023},
issue_date = {September 2023},
publisher = {ACM},
volume = {1},
number = {3},
url = {https://doi.org/10.1145/3596519},
doi = {10.1145/3596519},
abstract = {Reproducibility is a main principle in science and fundamental to ensure scientific progress. However, many recent works point out that there are widespread deficiencies for this aspect in the AI field, making the reproducibility of results impractical or even impossible. We therefore studied the state of reproducibility support on the topic of Reinforcement Learning \& Recommender Systems to analyse the situation in this context. We collected a total of 60 papers and analysed them by defining a set of variables to inspect the most important aspects that enable reproducibility, such as dataset, pre-processing code, hardware specifications, software dependencies, algorithm implementation, algorithm hyperparameters, and experiment code. Furthermore, we used the ACM Badges definitions assigning them to the selected papers. We discovered that, like in many other AI domains, the Reinforcement Learning \& Recommender Systems field is grappling with a reproducibility crisis, as none of the selected papers were reproducible when strictly applying the ACM Badges definitions according to our analysis.},
journal = {ACM Trans. Recomm. Syst.},
month = {jul},
articleno = {11},
numpages = {23},
keywords = {ACM badges, Reproducibility}
}

@InProceedings{VanDang2013,
author="Dang, V.
and Bendersky, M.
and Croft, W. B.",
title="Two-Stage Learning to Rank for Information Retrieval",
booktitle="Advances in Information Retrieval",
year="2013",
publisher="Springer Berlin Heidelberg",
pages="423--434",
abstract="Current learning to rank approaches commonly focus on learning the best possible ranking function given a small fixed set of documents. This document set is often retrieved from the collection using a simple unsupervised bag-of-words method, e.g. BM25. This can potentially lead to learning a sub-optimal ranking, since many relevant documents may be excluded from the initially retrieved set. In this paper we propose a novel two-stage learning framework to address this problem. We first learn a ranking function over the entire retrieval collection using a limited set of textual features including weighted phrases, proximities and expansion terms. This function is then used to retrieve the best possible subset of documents over which the final model is trained using a larger set of query- and document-dependent features. Empirical evaluation using two web collections unequivocally demonstrates that our proposed two-stage framework, being able to learn its model from more relevant documents, outperforms current learning to rank approaches.",
isbn="978-3-642-36973-5"
}

@article{Larsen2023,
author = {N. Larsen and J. Stallrich and S. Sengupta and A. Deng and R. Kohavi and N. T. Stevens},
title = {Statistical Challenges in Online Controlled Experiments: A Review of A/B Testing Methodology},
journal = {The American Statistician},
volume = {0},
number = {0},
pages = {1-15},
year = {2023},
publisher = {Taylor & Francis},
doi = {10.1080/00031305.2023.2257237},
}

@inproceedings{Kohavi2022,
author = {Kohavi, R. and Deng, A. and Vermeer, L.},
title = {A/B Testing Intuition Busters: Common Misunderstandings in Online Controlled Experiments},
year = {2022},
isbn = {9781450393850},
publisher = {ACM},
url = {https://doi.org/10.1145/3534678.3539160},
doi = {10.1145/3534678.3539160},
abstract = {A/B tests, or online controlled experiments, are heavily used in industry to evaluate implementations of ideas. While the statistics behind controlled experiments are well documented and some basic pitfalls known, we have observed some seemingly intuitive concepts being touted, including by A/B tool vendors and agencies, which are misleading, often badly so. Our goal is to describe these misunderstandings, the "intuition" behind them, and to explain and bust that intuition with solid statistical reasoning. We provide recommendations that experimentation platform designers can implement to make it harder for experimenters to make these intuitive mistakes.},
booktitle = {Proc. of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {31683177},
numpages = {10},
keywords = {a/b testing, controlled experiments, intuition busters},
series = {KDD '22}
}

@article{Jeunen2023_misassumption,
author = {Jeunen, O.},
title = {A Common Misassumption in Online Experiments with Machine Learning Models},
year = {2023},
issue_date = {June 2023},
publisher = {ACM},
volume = {57},
number = {1},
journal = {SIGIR Forum},
      eprint={2304.10900},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}


@InProceedings{Saito2022_ICML,
  title = 	 {Off-Policy Evaluation for Large Action Spaces via Embeddings},
  author =       {Saito, Y. and Joachims, T.},
  booktitle = 	 {Proc. of the 39th International Conference on Machine Learning},
  pages = 	 {19089--19122},
  year = 	 {2022},
  volume = 	 {162},
  series = 	 {ICML '22},
  month = 	 {17--23 Jul},
  publisher =    {PMLR},
  pdf = 	 {https://proceedings.mlr.press/v162/saito22a/saito22a.pdf},
  url = 	 {https://proceedings.mlr.press/v162/saito22a.html},
  abstract = 	 {Off-policy evaluation (OPE) in contextual bandits has seen rapid adoption in real-world systems, since it enables offline evaluation of new policies using only historic log data. Unfortunately, when the number of actions is large, existing OPE estimators  most of which are based on inverse propensity score weighting  degrade severely and can suffer from extreme bias and variance. This foils the use of OPE in many applications from recommender systems to language models. To overcome this issue, we propose a new OPE estimator that leverages marginalized importance weights when action embeddings provide structure in the action space. We characterize the bias, variance, and mean squared error of the proposed estimator and analyze the conditions under which the action embedding provides statistical benefits over conventional estimators. In addition to the theoretical analysis, we find that the empirical performance improvement can be substantial, enabling reliable OPE even when existing estimators collapse due to a large number of actions.}
}


@InProceedings{Saito2023_ICML,
  title = 	 {Off-Policy Evaluation for Large Action Spaces via Conjunct Effect Modeling},
  author =       {Saito, Y. and Ren, Q. and Joachims, T.},
  booktitle = 	 {Proc. of the 40th International Conference on Machine Learning},
  pages = 	 {29734--29759},
  year = 	 {2023},
  volume = 	 {202},
  series = 	 {ICML '23},
  month = 	 {23--29 Jul},
  publisher =    {PMLR},
  pdf = 	 {https://proceedings.mlr.press/v202/saito23b/saito23b.pdf},
  url = 	 {https://proceedings.mlr.press/v202/saito23b.html},
  abstract = 	 {We study off-policy evaluation (OPE) of contextual bandit policies for large discrete action spaces where conventional importance-weighting approaches suffer from excessive variance. To circumvent this variance issue, we propose a new estimator, called <em>OffCEM</em>, that is based on the <em>conjunct effect model</em> (CEM), a novel decomposition of the causal effect into a cluster effect and a residual effect. OffCEM applies importance weighting only to action clusters and addresses the residual causal effect through model-based reward estimation. We show that the proposed estimator is unbiased under a new assumption, called <em>local correctness</em>, which only requires that the residual-effect model preserves the relative expected reward differences of the actions within each cluster. To best leverage the CEM and local correctness, we also propose a new two-step procedure for performing model-based estimation that minimizes bias in the first step and variance in the second step. We find that the resulting OffCEM estimator substantially improves bias and variance compared to a range of conventional estimators. Experiments demonstrate that OffCEM provides substantial improvements in OPE especially in the presence of many actions.}
}

@inproceedings{Li2020,
author = {Li, D. and Jin, R. and Gao, J. and Liu, Z.},
title = {On Sampling Top-K Recommendation Evaluation},
year = {2020},
isbn = {9781450379984},
publisher = {ACM},
doi = {10.1145/3394486.3403262},
abstract = {Recently, Rendle has warned that the use of sampling-based top-k metrics might not suffice. This throws a number of recent studies on deep learning-based recommendation algorithms, and classic non-deep-learning algorithms using such a metric, into jeopardy. In this work, we thoroughly investigate the relationship between the sampling and global top-K Hit-Ratio (HR, or Recall), originally proposed by Koren[2] and extensively used by others. By formulating the problem of aligning sampling top-k ($SHR@k$) and global top-K (HR@K) Hit-Ratios through a mapping function f, so that SHR@k~ HR@f(k), we demonstrate both theoretically and experimentally that the sampling top-k Hit-Ratio provides an accurate approximation of its global (exact) counterpart, and can consistently predict the correct winners (the same as indicate by their corresponding global Hit-Ratios).},
booktitle = {Proc of. the 26th ACM SIGKDD International Conference on Knowledge Discovery \& Data Mining},
pages = {21142124},
numpages = {11},
keywords = {top-k, recommender systems, recall, hit ratio, evaluation metric},
series = {KDD '20}
}

@inproceedings{Saito2021OBP,
 author = {Saito, Y. and Aihara, S. and Matsutani, M. and Narita, Y.},
 booktitle = {Proc of. the Neural Information Processing Systems Track on Datasets and Benchmarks},
 pages = {},
 title = {Open Bandit Dataset and Pipeline: Towards Realistic and Reproducible Off-Policy Evaluation},
 url = {https://datasets-benchmarks-proceedings.neurips.cc/paper_files/paper/2021/file/33e75ff09dd601bbe69f351039152189-Paper-round2.pdf},
 volume = {1},
 year = {2021}
}


@inproceedings{Oosterhuis2022,
author = {Oosterhuis, H.},
title = {Learning-to-Rank at the Speed of Sampling: Plackett-Luce Gradient Estimation with Minimal Computational Complexity},
year = {2022},
publisher = {ACM},
doi = {10.1145/3477495.3531842},
abstract = {Plackett-Luce gradient estimation enables the optimization of stochastic ranking models within feasible time constraints through sampling techniques. Unfortunately, the computational complexity of existing methods does not scale well with the length of the rankings, i.e. the ranking cutoff, nor with the item collection size. In this paper, we introduce the novel PL-Rank-3 algorithm that performs unbiased gradient estimation with a computational complexity comparable to the best sorting algorithms. As a result, our novel learning-to-rank method is applicable in any scenario where standard sorting is feasible in reasonable time. Our experimental results indicate large gains in the time required for optimization, without any loss in performance. For the field, our contribution could potentially allow state-of-the-art learning-to-rank methods to be applied to much larger scales than previously feasible.},
booktitle = {Proc of. the 45th International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {22662271},
numpages = {6},
keywords = {policy gradients, learning to rank, computational complexity},
series = {SIGIR '22}
}