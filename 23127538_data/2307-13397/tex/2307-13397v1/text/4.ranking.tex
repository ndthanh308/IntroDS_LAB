%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% PERCEPTION OF SAFETY SCORES
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Computing scores}
After preparing and deploying the pairwise image comparison survey, we explore and compare covariate-free methodologies to compute subjective safety scores. This score allows non-experts and decision-makers to understand and compare cycling environments easily. We now provide an overview of each method.  


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% ELO
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\noindent \textbf{Elo \cite{elo1978rating}} We start by setting an initial score $s_0$ for each image. Next, after each comparison, we compute the expected result for item $A$ between items $A$ and $B$:
\begin{equation}
E_A = \frac{1}{1+10^{(s_B-s_A)/\delta}},
\label{eq:elo_expected}
\end{equation}
with $\delta$ modulating the scores difference. The update score for item $A$, $s_A'$, can then be updated using the following:
\begin{equation}
s_A' = s_A + k (\gamma - E_A),
\label{eq:elo_update}
\end{equation}
with $k$ modulating the impact of the outcome on the new score and $\gamma$ being 1 for the winning item and 0 for the losing one, or 0.5 for ties for both items.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% TRUESKILL
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\noindent \textbf{TrueSkill (TS) \cite{herbrich2006trueskill}} This Bayesian framework assumes that each image's score is modeled by a $\mathcal{N}(\mu,\,\sigma^{2})$ random variable, which is updated after each comparison. Update rules follow that, for image $A$ winning over image $B$:
\begin{equation}
\begin{aligned}
\mu_A' = \mu_A + \frac{\sigma_A^2}{c} \cdot f(\frac{\mu_A-\mu_B}{c}, \frac{\varepsilon}{c})\\ 
\mu_B' = \mu_B + \frac{\sigma_B^2}{c} \cdot f(\frac{\mu_A-\mu_B}{c}, \frac{\varepsilon}{c})\\
\sigma_A^{2'} = \sigma_A^2 (1-\frac{\sigma_A^2}{c} \cdot g(\frac{\mu_A-\mu_B}{c}, \frac{\varepsilon}{c})) \\
\sigma_B^{2'} = \sigma_B^2 (1-\frac{\sigma_B^2}{c} \cdot g(\frac{\mu_A-\mu_B}{c}, \frac{\varepsilon}{c})) \\
c^2 = 2\beta^2 + \sigma_A^2 + \sigma_B^2
\end{aligned},
\label{eq:trueskill_update}
\end{equation}
with $\beta$ being a per-game variance parameter, $\varepsilon$ an empirical probability of a comparison resulting in a tie, functions $f(\theta) = \mathcal{N}(\theta)/\Phi(\theta)$ and $g(\theta) = f(\theta)\cdot(f(\theta)+\theta)$ defined as the Gaussian density function $\mathcal{N}(\theta)$ and Gaussian cumulative density function $\Phi(\theta)$.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% CONVEX OPTIMIZATION
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\noindent \textbf{Convex Optimization (CO)} To model paired comparisons, we solve a convex optimization program following \cite{costa2019citysafe}:
\begin{equation}
\begin{aligned}
& \underset{s, t}{\text{minimize}}
& & 1^Tt +\lambda_{ties}1^T|B^Ts|\\
& \text{subject to}
& & 1^Ts=0\\
& & & \epsilon-b_n^Ts \le t_n\\
& & & 0 \le t_n, n=1, ..., N
\end{aligned},
\label{eq:cvx_opt}
\end{equation}
with $s\in\mathbb{R}^M$ being the score vector for $M$ images, $N$ the total number of comparisons, $b_n$ a vector containing information for comparing pairs ($b_n$ is a vector of zeros, with 1 in the $m$-th position of the winning image, and -1 in the $m$-th position of the losing one), and $\epsilon$ an error margin to tolerate offending comparisons. This cost function penalizes scores that violate the error margin greater than $\epsilon$. The optimal scores $s$ will be the one that violates the least paired comparisons and, if so, the ones where image scores are closer.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% GAUSSIAN PROCESS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\noindent \textbf{Gaussian Process (GP)} We perform approximate Bayesian inference over pairwise comparisons following \cite{maystre2019pairwise}. Here, scores are approximated by a Gaussian Process ($s(n) \sim \mathcal{GP}(0, k(n, n'))$) defined by the joint distribution of N pairwise comparisons of scores $s$, with $s \sim \mathcal{N}(0, K)$, with $K$ being the covariance matrix $K=[k(n_i, n_j)]$, defined by a covariance function that models the dynamics of scores over comparisons. We chose a logit observation model and defined the likelihood accordingly. For further detail on the approximate posterior probabilities and inference through Expectation-Propagation, we refer the reader to \cite{maystre2019pairwise}.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% LUCE SPECTRAL RANKING
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\noindent \textbf{Luce Spectral Ranking (LSR) \cite{maystre2015fast}} By constructing pairwise comparisons as a graph, where edges represent comparisons and their results, this algorithm works as a scoring function of such graph representation. The graph's structure defines probabilities as the stationary probability of a natural random walk over nodes (images) or a stationary distribution of a Markov chain. Essentially, this measures the likelihood of moving from item $A$ to item $B$, which depends on how many comparisons item $A$ won versus item $B$. As such, it captures an item's preference globally over all other items.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% PREDICTING SUBJECTIVE SAFETY SCORES
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Predicting environments as perceived safe or unsafe}
After scoring each cycling environment, we aim to predict if environments are perceived as safe or unsafe based on image characteristics. This classification can help urban planners and designers to understand what urban features impact individuals' cycling perception of accident risk. 

As such, we perform binary classification to classify environments as perceived \textit{safe} or \textit{unsafe}. To get a representation of the image, we run images through the widely popular deep neural network InceptionV3 \cite{szegedy2016rethinking} pre-trained on ImageNet, from which we remove the final softmax classification layer. Other architectures were tested, with InceptionV3 providing the best results for this task. From this, we extract a latent representation of the urban environment for each image to be used as the predictor in our classification problem.

Next, we label environments as \textit{safe} or \textit{unsafe} by setting a threshold on the predicted rating using one of the algorithms from Section \ref{sec:ranking}. We set $s_H$ and $s_L$, where images with a score above $s_H$ are perceived as \textit{safe}, and below $s_L$ are perceived as unsafe. These thresholds are defined as $s_H= \bar{s} + \alpha \sigma_s$ and $s_L= \bar{s} - \alpha \sigma_s$, with $\bar{s}$ and $\sigma_s$ being the average and standard deviation of the scores on the test set, respectively, and $\alpha$ a varying parameter set to control how distant perceived safer environments are from unsafe ones. Particularly, if $\alpha=0$, then $s_H=s_L=\bar{s}$, meaning that their environments are either perceived as safe or unsafe.
Finally, we use eXtreme Gradient Boosting Tree (XGBoost) \cite{chen2016xgboost} to perform binary classification due to being a powerful approach to binary classification. 


