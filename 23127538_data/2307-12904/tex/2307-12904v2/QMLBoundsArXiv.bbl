% Generated by IEEEtran.bst, version: 1.14 (2015/08/26)
\begin{thebibliography}{10}
\providecommand{\url}[1]{#1}
\csname url@samestyle\endcsname
\providecommand{\newblock}{\relax}
\providecommand{\bibinfo}[2]{#2}
\providecommand{\BIBentrySTDinterwordspacing}{\spaceskip=0pt\relax}
\providecommand{\BIBentryALTinterwordstretchfactor}{4}
\providecommand{\BIBentryALTinterwordspacing}{\spaceskip=\fontdimen2\font plus
\BIBentryALTinterwordstretchfactor\fontdimen3\font minus
  \fontdimen4\font\relax}
\providecommand{\BIBforeignlanguage}[2]{{%
\expandafter\ifx\csname l@#1\endcsname\relax
\typeout{** WARNING: IEEEtran.bst: No hyphenation pattern has been}%
\typeout{** loaded for the language `#1'. Using the pattern for}%
\typeout{** the default language instead.}%
\else
\language=\csname l@#1\endcsname
\fi
#2}}
\providecommand{\BIBdecl}{\relax}
\BIBdecl

\bibitem{Kolmogorov1957}
A.~N. Kolmogorov, ``On the representation of continuous functions of many
  variables by superposition of continuous functions of one variable and
  addition,'' \emph{Dokl. Akad. Nauk SSSR}, vol. 114, pp. 953--956, 1957.

\bibitem{Arnold1957}
V.~I. Arnold, ``On functions of three variables,'' \emph{Dokl. Akad. Nauk
  SSSR}, vol. 114, pp. 679--681, 1957.

\bibitem{cybenko1989approximation}
G.~Cybenko, ``Approximation by superpositions of a sigmoidal function,''
  \emph{Mathematics of Control, Signals and Systems}, vol.~2, no.~4, pp.
  303--314, 1989.

\bibitem{hornik1991}
K.~Hornik, ``{Approximation capabilities of multilayer feedforward networks},''
  \emph{Neural Networks}, vol.~4, no. 1989, pp. 251--257, 1991.

\bibitem{hornik1989multilayer}
K.~Hornik, M.~Stinchcombe, and H.~White, ``Multilayer feedforward networks are
  universal approximators,'' \emph{Neural Networks}, vol.~2, no.~5, pp.
  359--366, 1989.

\bibitem{leshno1993multilayer}
M.~Leshno, V.~Y. Lin, A.~Pinkus, and S.~Schocken, ``Multilayer feedforward
  networks with a nonpolynomial activation function can approximate any
  function,'' \emph{Neural Networks}, vol.~6, no.~6, pp. 861--867, 1993.

\bibitem{gripenberg2003approximation}
G.~Gripenberg, ``Approximation by neural networks with a bounded number of
  nodes at each level,'' \emph{Journal of Approximation Theory}, vol. 122,
  no.~2, pp. 260--266, 2003.

\bibitem{kidger2020universal}
P.~Kidger and T.~Lyons, ``{Universal Approximation with Deep Narrow
  Networks},'' in \emph{Proceedings of Thirty Third Conference on Learning
  Theory}, ser. Proceedings of Machine Learning Research, J.~Abernethy and
  S.~Agarwal, Eds., vol. 125.\hskip 1em plus 0.5em minus 0.4em\relax PMLR,
  09--12 Jul 2020, pp. 2306--2327.

\bibitem{Barron1992}
A.~R. Barron, ``Neural net approximation,'' in \emph{Proceedings of the Seventh
  Yale Workshop on Adaptive and Learning Systems}, K.~S. Narendra, Ed., vol.~1,
  1992, pp. 69--72.

\bibitem{Barron1993}
------, ``Universal approximation bounds for superpositions of a sigmoidal
  function,'' \emph{IEEE Transactions on Information Theory}, vol.~39, no.~3,
  pp. 930--945, 1993.

\bibitem{Barron1994ApproximationAE}
------, ``Approximation and estimation bounds for artificial neural networks,''
  \emph{Machine Learning}, vol.~14, pp. 115--133, 1994.

\bibitem{Mhaskar1996}
H.~N. Mhaskar, ``{Neural networks for optimal approximation of smooth and
  analytic functions},'' \emph{Neural computation}, vol.~8, no.~1, pp.
  164--177, 1996.

\bibitem{Boelcskei2019}
H.~Bölcskei, P.~Grohs, G.~Kutyniok, and P.~Petersen, ``Optimal approximation
  with sparsely connected deep neural networks,'' \emph{SIAM Journal on
  Mathematics of Data Science}, vol.~1, no.~1, pp. 8--45, 2019.

\bibitem{Guehring2020}
I.~G\"{u}hring, G.~Kutyniok, and P.~Petersen, ``Error bounds for approximations
  with deep {R}e{LU} neural networks in {$W^{s,p}$} norms,'' \emph{Anal. Appl.
  (Singap.)}, vol.~18, no.~5, pp. 803--859, 2020.

\bibitem{yarotsky2017error}
D.~Yarotsky, ``Error bounds for approximations with deep relu networks,''
  \emph{Neural Networks}, vol.~94, pp. 103--114, 2017.

\bibitem{Guehring2023}
I.~G\"{u}hring, M.~Raslan, and G.~Kutyniok, ``Expressivity of deep neural
  networks,'' in \emph{Mathematical aspects of deep learning}.\hskip 1em plus
  0.5em minus 0.4em\relax Cambridge University Press, 2023, pp. 149--199.

\bibitem{preskill2012quantum}
J.~Preskill, ``Quantum computing and the entanglement frontier,'' 2012,
  arXiv:1203.5813.

\bibitem{cordier2022biology}
B.~A. Cordier, N.~P. Sawaya, G.~G. Guerreschi, and S.~K. McWeeney, ``Biology
  and medicine in the landscape of quantum advantages,'' \emph{Journal of the
  Royal Society Interface}, vol.~19, no. 196, p. 20220541, 2022.

\bibitem{stamatopoulos2022towards}
N.~Stamatopoulos, G.~Mazzola, S.~Woerner, and W.~J. Zeng, ``Towards quantum
  advantage in financial market risk using quantum gradient algorithms,''
  \emph{Quantum}, vol.~6, p. 770, 2022.

\bibitem{RahimiRecht2008a}
A.~Rahimi and B.~Recht, ``Random features for large-scale kernel machines,'' in
  \emph{Advances in Neural Information Processing Systems}, J.~Platt,
  D.~Koller, Y.~Singer, and S.~Roweis, Eds., vol.~20.\hskip 1em plus 0.5em
  minus 0.4em\relax Curran Associates, Inc., 2007.

\bibitem{RahimiRecht2008}
------, ``Weighted sums of random kitchen sinks: Replacing minimization with
  randomization in learning,'' in \emph{Advances in Neural Information
  Processing Systems}, D.~Koller, D.~Schuurmans, Y.~Bengio, and L.~Bottou,
  Eds., vol.~21.\hskip 1em plus 0.5em minus 0.4em\relax Curran Associates,
  Inc., 2009, pp. 1313--1320.

\bibitem{HCS2006}
G.-B. Huang, L.~Chen, and C.-K. Siew, ``Universal approximation using
  incremental constructive feedforward networks with random hidden nodes,''
  \emph{Trans. Neur. Netw.}, vol.~17, no.~4, p. 879–892, Jul. 2006.

\bibitem{Jaeger2001}
H.~Jaeger, ``The "echo state" approach to analysing and training recurrent
  neural networks-with an erratum note','' \emph{Bonn, Germany: German National
  Research Center for Information Technology GMD Technical Report}, vol. 148,
  01 2001.

\bibitem{LukoseviciusJaeger2009}
M.~Luko\v{s}evi\v{c}ius and H.~Jaeger, ``Reservoir computing approaches to
  recurrent neural network training,'' \emph{Comput. Sci. Rev.}, vol.~3, pp.
  127--149, 2009.

\bibitem{TANAKA2019100}
G.~Tanaka, T.~Yamane, J.~B. Héroux, R.~Nakane, N.~Kanazawa, S.~Takeda,
  H.~Numata, D.~Nakano, and A.~Hirose, ``Recent advances in physical reservoir
  computing: A review,'' \emph{Neural Networks}, vol. 115, pp. 100--123, 2019.

\bibitem{RC8}
L.~Gonon and J.-P. Ortega, ``{Reservoir computing universality with stochastic
  inputs},'' \emph{IEEE Transactions on Neural Networks and Learning Systems},
  vol.~31, no.~1, pp. 100--112, 2020.

\bibitem{RC20}
------, ``{Fading memory echo state networks are universal},'' \emph{Neural
  Networks}, vol. 138, pp. 10--13, 2021.

\bibitem{GrigOrtega2018}
L.~Grigoryeva and J.-P. Ortega, ``{Echo state networks are universal},''
  \emph{Neural Networks}, vol. 108, pp. 495--508, 2018.

\bibitem{GrigoryevaOrtega2018}
------, ``{Universal discrete-time reservoir computers with stochastic inputs
  and linear readouts using non-homogeneous state-affine systems},''
  \emph{Journal of Machine Learning Research}, vol.~19, no.~24, pp. 1--40,
  2018.

\bibitem{Gonon2021}
L.~Gonon, ``Random feature neural networks learn black-scholes type pdes
  without curse of dimensionality,'' \emph{J. Mach. Learn. Res.}, vol.~24, no.
  189, pp. 1--51, 2023.

\bibitem{RC12}
L.~Gonon, L.~Grigoryeva, and J.-P. Ortega, ``{Approximation error estimates for
  random neural networks and reservoir systems},'' \emph{The Annals of Applied
  Probability}, vol.~33, no.~1, pp. 28--69, 2023.

\bibitem{FujiiNakajima2017}
K.~Fujii and K.~Nakajima, ``Harnessing disordered-ensemble quantum dynamics for
  machine learning,'' \emph{Phys. Rev. Appl.}, vol.~8, p. 024030, Aug 2017.

\bibitem{Dasgupta2020}
S.~Dasgupta, K.~Hamilton, P.~Lougovski, and A.~Banerjee, ``Designing a nisq
  reservoir with maximal memory capacity for volatility forecasting,'' 2020,
  arXiv:2004.08240.

\bibitem{MPOrtega2022}
R.~Martínez-Peña and J.-P. Ortega, ``Quantum reservoir computing in finite
  dimensions,'' \emph{Physical Review E}, vol. 107, 12 2022.

\bibitem{MOLTENI2023}
R.~Molteni, C.~Destri, and E.~Prati, ``Optimization of the memory reset rate of
  a quantum echo-state network for time sequential tasks,'' \emph{Physics
  Letters A}, vol. 465, p. 128713, 2023.

\bibitem{Suzukietal2021}
Y.~Suzuki, Q.~Gao, K.~Pradel, K.~Yasuoka, and N.~Yamamoto, ``Natural quantum
  reservoir computing for temporal information processing,'' \emph{Scientific
  reports}, vol.~12, 2022.

\bibitem{Ghoshetal2021}
S.~Ghosh, K.~Nakajima, T.~Krisnanda, K.~Fujii, and T.~C.~H. Liew, ``Quantum
  neuromorphic computing with reservoir computing networks,'' \emph{Advanced
  Quantum Technologies}, vol.~4, no.~9, p. 2100053, 2021.

\bibitem{Mujaletal2021}
P.~Mujal, R.~Martínez-Peña, J.~Nokkala, J.~García-Beni, G.~L. Giorgi, M.~C.
  Soriano, and R.~Zambrini, ``Opportunities in quantum reservoir computing and
  extreme learning machines,'' \emph{Advanced Quantum Technologies}, vol.~4,
  no.~8, p. 2100027, 2021.

\bibitem{PerezSalinas2020datareuploading}
A.~P{\'{e}}rez-Salinas, A.~Cervera-Lierta, E.~Gil-Fuster, and J.~I. Latorre,
  ``Data re-uploading for a universal quantum classifier,'' \emph{{Quantum}},
  vol.~4, p. 226, Feb. 2020.

\bibitem{perez2021one}
A.~P{\'e}rez-Salinas, D.~L{\'o}pez-N{\'u}{\~n}ez, A.~Garc{\'\i}a-S{\'a}ez,
  P.~Forn-D{\'\i}az, and J.~I. Latorre, ``One qubit as a universal
  approximant,'' \emph{Physical Review A}, vol. 104, no.~1, p. 012405, 2021.

\bibitem{Schuld2021}
M.~Schuld, R.~Sweke, and J.~J. Meyer, ``Effect of data encoding on the
  expressive power of variational quantum-machine-learning models,''
  \emph{Physical Review A}, vol. 103, p. 032430, Mar 2021.

\bibitem{Chen2019}
J.~Chen and H.~Nurdin, ``Learning nonlinear input–output maps with
  dissipative quantum systems,'' \emph{Quantum Information Processing},
  vol.~18, 05 2019.

\bibitem{Chenetal2020}
J.~Chen, H.~I. Nurdin, and N.~Yamamoto, ``Temporal information processing on
  noisy quantum computers,'' \emph{Phys. Rev. Appl.}, vol.~14, p. 024065, Aug
  2020.

\bibitem{Nokkala2021}
J.~Nokkala, R.~Martínez-Peña, G.~Giorgi, V.~Parigi, M.~Soriano, and
  R.~Zambrini, ``Gaussian states of continuous-variable quantum systems provide
  universal and versatile reservoir computing,'' \emph{Communications Physics},
  vol.~4, 03 2021.

\bibitem{wu2021expressivity}
Y.~Wu, J.~Yao, P.~Zhang, and H.~Zhai, ``Expressivity of quantum neural
  networks,'' \emph{Physical Review Research}, vol.~3, no.~3, p. L032049, 2021.

\bibitem{wu2024expressivity}
C.-H. Wu and C.-C. Yen, ``The expressivity of classical and quantum neural
  networks on entanglement entropy,'' \emph{The European Physical Journal C},
  vol.~84, no.~2, p. 192, 2024.

\bibitem{wu2024randomness}
Y.~Wu, J.~Yao, P.~Zhang, and X.~Li, ``Randomness-enhanced expressivity of
  quantum neural networks,'' \emph{Physical Review Letters}, vol. 132, no.~1,
  p. 010602, 2024.

\bibitem{Goto2021}
T.~Goto, Q.~H. Tran, and K.~Nakajima, ``Universal approximation property of
  quantum machine learning models in quantum-enhanced feature spaces,''
  \emph{Phys. Rev. Lett.}, vol. 127, p. 090506, Aug 2021.

\bibitem{balestriero2021learning}
R.~Balestriero, J.~Pesenti, and Y.~LeCun, ``Learning in high dimension always
  amounts to extrapolation,'' 2021, arXiv:2110.09485.

\bibitem{siegel2022parallel}
A.~Siegel, ``A parallel algorithm for understanding design spaces and
  performing convex hull computations,'' \emph{Journal of Computational
  Mathematics and Data Science}, vol.~2, p. 100021, 2022.

\bibitem{xu2020neural}
K.~Xu, M.~Zhang, J.~Li, S.~S. Du, K.-i. Kawarabayashi, and S.~Jegelka, ``How
  neural networks extrapolate: From feedforward to graph neural networks,''
  2020, arXiv:2009.11848.

\bibitem{MMM21}
S.~Mei, T.~Misiakiewicz, and A.~Montanari, ``Generalization error of random
  features and kernel methods: hypercontractivity and kernel matrix
  concentration,'' \emph{arXiv:2101.10588}, 2021.

\bibitem{RudiRosasco2017}
A.~Rudi and L.~Rosasco, ``Generalization properties of learning with random
  features,'' in \emph{Advances in Neural Information Processing Systems},
  I.~Guyon, U.~V. Luxburg, S.~Bengio, H.~Wallach, R.~Fergus, S.~Vishwanathan,
  and R.~Garnett, Eds., vol.~30.\hskip 1em plus 0.5em minus 0.4em\relax Curran
  Associates, Inc., 2017.

\bibitem{Folland1995}
G.~Folland, \emph{Introduction to Partial Differential Equations, 2nd
  Edition}.\hskip 1em plus 0.5em minus 0.4em\relax Princeton University Press,
  1995.

\bibitem{PowerOfData}
H.-Y. Huang, M.~Broughton, M.~Mohseni, R.~Babbush, S.~Boixo, H.~Neven, and
  J.~Mcclean, ``Power of data in quantum machine learning,'' \emph{Nature
  Communications}, vol.~12, 05 2021.

\bibitem{Barren}
J.~Mcclean, S.~Boixo, V.~Smelyanskiy, R.~Babbush, and H.~Neven, ``Barren
  plateaus in quantum neural network training landscapes,'' \emph{Nature
  Communications}, vol.~9, 11 2018.

\bibitem{mitarai2018quantum}
K.~Mitarai, M.~Negoro, M.~Kitagawa, and K.~Fujii, ``Quantum circuit learning,''
  \emph{Physical Review A}, vol.~98, no.~3, p. 032309, 2018.

\bibitem{Kallenberg2002}
O.~Kallenberg, \emph{{Foundations of Modern Probability, 2nd Edition}}, ser.
  Probability and Its Applications.\hskip 1em plus 0.5em minus 0.4em\relax
  Springer New York, 2002.

\bibitem{Ledoux2013}
M.~Ledoux and M.~Talagrand, \emph{{Probability in Banach Spaces}}.\hskip 1em
  plus 0.5em minus 0.4em\relax Springer Berlin Heidelberg, 2013.

\bibitem{Rudin1987}
W.~Rudin, \emph{Real \& Complex Analysis}.\hskip 1em plus 0.5em minus
  0.4em\relax McGraw-Hill; 3rd edition, 1987.

\bibitem{krol2022efficient}
A.~M. Krol, A.~Sarkar, I.~Ashraf, Z.~Al-Ars, and K.~Bertels, ``Efficient
  decomposition of unitary matrices in quantum circuit compilers,''
  \emph{Applied Sciences}, vol.~12, no.~2, p. 759, 2022.

\bibitem{li2013decomposition}
C.-K. Li, R.~Roberts, and X.~Yin, ``Decomposition of unitary matrices and
  quantum gates,'' \emph{International Journal of Quantum Information},
  vol.~11, no.~01, p. 1350015, 2013.

\end{thebibliography}
