@InProceedings{C2,
  author = 	 "Jones, C.D. and Smith, A.B. and Roberts, E.F.",
  title =        "Article Title",
  booktitle =        "Proceedings Title",
  organization = "IEEE",
  year = 	 "2003",
  volume = 	 "II",
  pages = 	 "803--806"
}

@inproceedings{kingma2014adam,
  title={Adam: A method for stochastic optimization},
  author={Kingma, Diederik P and Ba, Jimmy},
  booktitle    = {International Conference on Learning Representations (ICLR)},
  year         = {2015}
}

@inproceedings{lei22c_interspeech,
  author={Shun Lei and Yixuan Zhou and Liyang Chen and Jiankun Hu and Zhiyong Wu and Shiyin Kang and Helen Meng},
  title={Towards Multi-Scale Speaking Style Modelling with Hierarchical Context Information for {Mandarin} Speech Synthesis},
  year={2022},
  booktitle={Annual Conference of the International Speech Communication Association (INTERSPEECH)},
  pages={5523--5527},
publisher={ISCA}
}
@inproceedings{liu22m_interspeech,
  author={Zhaoci Liu and Ningqian Wu and Yajie Zhang and Zhenhua Ling},
  title={Integrating Discrete Word-Level Style Variations into Non-Autoregressive Acoustic Models for Speech Synthesis},
  year=2022,
  booktitle={Annual Conference of the International Speech Communication Association (INTERSPEECH)},
  pages={5508--5512},
  publisher={ISCA}
}
@article{xue2022paratts,
  title={Paratts: Learning linguistic and prosodic cross-sentence information in paragraph-based {TTS}},
  author={Xue, Liumeng and Soong, Frank K and Zhang, Shaofei and Xie, Lei},
  journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing},
  volume={30},
  pages={2854--2864},
  year={2022},
  publisher={IEEE}
}
@inproceedings{li2022cross,
  title={Cross-Utterance Conditioned VAE for Non-Autoregressive Text-to-Speech},
  author={Li, Yang and Yu, Cheng and Sun, Guangzhi and Jiang, Hua and Sun, Fanglei and Zu, Weiqin and Wen, Ying and Yang, Yang and Wang, Jun},
  booktitle={Annual Meeting of the Association for Computational Linguistics (ACL)},
  pages={391--400},
publisher    = {Association for Computational Linguistics},
  year={2022}
}
% 基本的TTS模型：Tacotron, DeepVoice3，Tacotron2，FastSpeech2
@inproceedings{tacotron,
  title={Tacotron: Towards end-to-end speech synthesis},
  author={Wang, Yuxuan and Skerry-Ryan, RJ and Stanton, Daisy and Wu, Yonghui and Weiss, Ron J and Jaitly, Navdeep and Yang, Zongheng and Xiao, Ying and Chen, Zhifeng and Bengio, Samy and others},
  booktitle={Annual Conference of the International Speech Communication Association (INTERSPEECH)},
  pages = {4006--4010},
  publisher = {ISCA},
  year={2017}
}

@inproceedings{sotelo2017char2wav,
  title={Char2wav: End-to-end speech synthesis},
  author={Sotelo, Jose and Mehri, Soroush and Kumar, Kundan and Santos, Joao Felipe and Kastner, Kyle and Courville, Aaron and Bengio, Yoshua},
  booktitle = {International Conference on Learning Representations (ICLR)},
  year={2017}
}

@inproceedings{Yu2020DurIANDI,
  title={DurIAN: Duration Informed Attention Network for Speech Synthesis},
  author={Chengzhu Yu and Heng Lu and Na Hu and Meng Yu and Chao Weng and Kun Xu and Peng Liu and Deyi Tuo and Shiyin Kang and Guangzhi Lei and Dan Su and Dong Yu},
  booktitle={Annual Conference of the International Speech Communication Association (INTERSPEECH)},
  pages        = {2027--2031},
  publisher    = {ISCA},
  year         = {2020},
}

@inproceedings{li2019neural,
  title={Neural speech synthesis with transformer network},
  author={Li, Naihan and Liu, Shujie and Liu, Yanqing and Zhao, Sheng and Liu, Ming},
  booktitle={AAAI Conference on Artificial Intelligence},
  pages={6706--6713},
  publisher = {AAAI Press},
  year={2019}
}

@inproceedings{deepvoice3,
  title={Deep Voice 3: Scaling Text-to-Speech with Convolutional Sequence Learning},
  author={Ping, Wei and Peng, Kainan and Gibiansky, Andrew and Arik, Sercan O and Kannan, Ajay and Narang, Sharan and Raiman, Jonathan and Miller, John},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2018}
}


@article{fastspeech,
  title={Fastspeech: Fast, robust and controllable text to speech},
  author={Ren, Yi and Ruan, Yangjun and Tan, Xu and Qin, Tao and Zhao, Sheng and Zhao, Zhou and Liu, Tie-Yan},
  journal={arXiv preprint arXiv:1905.09263},
  year={2019}
}



% reference encoder
@inproceedings{reference,
  title={Towards end-to-end prosody transfer for expressive speech synthesis with tacotron},
  author={Skerry-Ryan, RJ and Battenberg, Eric and Xiao, Ying and Wang, Yuxuan and Stanton, Daisy and Shor, Joel and Weiss, Ron and Clark, Rob and Saurous, Rif A},
  booktitle={International Conference on Machine Learning (ICML)},
  volume       = {80},
  pages        = {4693--4702},
  year={2018},
  organization={PMLR}
}



% GST
@inproceedings{GST,
  title={Style tokens: Unsupervised style modeling, control and transfer in end-to-end speech synthesis},
  author={Wang, Yuxuan and Stanton, Daisy and Zhang, Yu and Ryan, RJ-Skerry and Battenberg, Eric and Shor, Joel and Xiao, Ying and Jia, Ye and Ren, Fei and Saurous, Rif A},
  booktitle={International Conference on Machine Learning (ICML)},
  volume       = {80},
  pages        = {5180--5189},
  year={2018},
  organization={PMLR}
}

% CROSS-UTTERANCE
@inproceedings{crossutterance,
  title={Improving prosody modelling with cross-utterance BERT embeddings for end-to-end speech synthesis},
  author={Xu, Guanghui and Song, Wei and Zhang, Zhengchen and Zhang, Chao and He, Xiaodong and Zhou, Bowen},
  booktitle={IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={6079--6083},
  year={2021},
  organization={IEEE}
}

% ICASSP-PROPOSED
@inproceedings{proposed,
  title={Towards Expressive Speaking Style Modelling with Hierarchical Context Information for {Mandarin} Speech Synthesis},
  author={Lei, Shun and Zhou, Yixuan and Chen, Liyang and Wu, Zhiyong and Kang, Shiyin and Meng, Helen},
  booktitle={IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={7922--7926},
  year={2022},
  organization={IEEE}
}

% VAE GST
@inproceedings{VAEGST,
  title={Learning latent representations for style control and transfer in end-to-end speech synthesis},
  author={Zhang, Ya-Jie and Pan, Shifeng and He, Lei and Ling, Zhen-Hua},
  booktitle={IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={6945--6949},
  year={2019},
  organization={IEEE}
}

%fastpitch
@inproceedings{fastpitch,
  title={Fastpitch: Parallel text-to-speech with pitch prediction},
  author={{\L}a{\'n}cucki, Adrian},
  booktitle={IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={6588--6592},
  year={2021},
  organization={IEEE}
}

% VAE
@inproceedings{VAE,
  title={Auto-encoding variational bayes},
  author={Kingma, Diederik P and Welling, Max},
  booktitle    = {International Conference on Learning Representations (ICLR)},
  year={2014}
}

% TP-GST
@inproceedings{TPGST,
  title={Predicting expressive speaking style from text in end-to-end speech synthesis},
  author={Stanton, Daisy and Wang, Yuxuan and Skerry-Ryan, RJ},
  booktitle={IEEE Spoken Language Technology Workshop (SLT)},
  pages={595--602},
  year={2018},
  organization={IEEE}
}

% bert
@inproceedings{bert,
  title={{BERT:} Pre-training of deep bidirectional transformers for language understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  booktitle={Annual Conference of the North American Chapter of
                  the Association for Computational Linguistics: Human Language Technologies (NAACL HLT)},
  pages        = {4171--4186},
  publisher    = {Association for Computational Linguistics},
  year         = {2019},
}

% bert-tacotron2
@inproceedings{berttacotron,
  title={Pre-Trained Text Embeddings for Enhanced Text-to-Speech Synthesis},
  author={Hayashi, Tomoki and Watanabe, Shinji and Toda, Tomoki and Takeda, Kazuya and Toshniwal, Shubham and Livescu, Karen},
  booktitle={Annual Conference of the International Speech Communication Association (INTERSPEECH)},
  pages={4430--4434},
publisher    = {ISCA},
  year={2019}
}

% BertEmb
@inproceedings{bertemb,
  title={Improving prosody with linguistic and bert derived features in multi-speaker based {Mandarin} chinese neural {TTS}},
  author={Xiao, Yujia and He, Lei and Ming, Huaiping and Soong, Frank K},
  booktitle={IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={6704--6708},
  year={2020},
  organization={IEEE}
}



@inproceedings{ren2022prosospeech,
  title={Prosospeech: Enhancing Prosody with Quantized Vector Pre-Training in Text-To-Speech},
  author={Ren, Yi and Lei, Ming and Huang, Zhiying and Zhang, Shiliang and Chen, Qian and Yan, Zhijie and Zhao, Zhou},
  booktitle={IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={7577--7581},
  year={2022},
  organization={IEEE}
}

@inproceedings{wu2019end,
  title={End-to-end emotional speech synthesis using style tokens and semi-supervised training},
  author={Wu, Pengfei and Ling, Zhenhua and Liu, Lijuan and Jiang, Yuan and Wu, Hongchuan and Dai, Lirong},
  booktitle={Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA ASC)},
  pages={623--627},
  year={2019},
  organization={IEEE}
}

% wsv
@article{wsv,
  title={Extracting and Predicting Word-Level Style Variations for Speech Synthesis},
  author={Zhang, Ya-Jie and Ling, Zhen-Hua},
  journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing},
  volume={29},
  pages={1582--1593},
  year={2021},
  publisher={IEEE}
}

% tacotron2
@inproceedings{tacotron2,
  title={Natural {TTS} synthesis by conditioning wavenet on {MEL} spectrogram predictions},
  author={Shen, Jonathan and Pang, Ruoming and Weiss, Ron J and Schuster, Mike and Jaitly, Navdeep and Yang, Zongheng and Chen, Zhifeng and Zhang, Yu and Wang, Yuxuan and Skerrv-Ryan, Rj and others},
  booktitle={IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={4779--4783},
  year={2018},
  organization={IEEE}
}

@inproceedings{longformevaluationg,
  title={Evaluating Long-form Text-to-Speech: Comparing the Ratings of Sentences and Paragraphs},
  author={Clark, Rob and Silen, Hanna and Kenter, Tom and Leith, Ralph},
  year={2019},
  booktitle={ISCA Speech Synthesis Workshop (SSW10)},
  pages={99--104},
organization={ISCA}
}

% gru
@inproceedings{gru,
  title={Empirical evaluation of gated recurrent neural networks on sequence modeling},
  author={Chung, Junyoung and Gulcehre, Caglar and Cho, Kyunghyun and Bengio, Yoshua},
  booktitle={Annual Conference on Neural Information Processing Systems (NeurIPS) Workshop on Deep Learning and Representation Learning},
  year={2014}
}

%transformer
@inproceedings{transformer,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  booktitle={Advances in neural information processing systems},
  pages={5998--6008},
  year={2017}
}

% 篇章prosody建模
@article{farrus2016paragraph,
  title={Paragraph-based prosodic cues for speech synthesis applications},
  author={Farr{\'u}s, Mireia and Lai, Catherine and Moore, Johanna D},
  journal={Barnes J, Brugos A, Shattuck-Hufnagel S, Veilleux N, editors. Speech Prosody 2016; 2016 May 31-June 3; Boston (MA, USA).[place unknown]: International Speech Communication Association; 2016. p. 1143-7.},
  year={2016},
  publisher={International Speech Communication Association}
}

@inproceedings{aubin2019improving,
  title={Improving Speech Synthesis with Discourse Relations.},
  author={Aubin, Ad{\`e}le and Cervone, Alessandra and Watts, Oliver and King, Simon},
  booktitle={Interspeech},
  pages={4470--4474},
  year={2019}
}


% camp
@inproceedings{camp,
  title={CAMP: a two-stage approach to modelling prosody in context},
  author={Hodari, Zack and Moinet, Alexis and Karlapati, Sri and Lorenzo-Trueba, Jaime and Merritt, Thomas and Joly, Arnaud and Abbas, Ammar and Karanasou, Penny and Drugman, Thomas},
  booktitle={ICASSP 2021-2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={6578--6582},
  year={2021},
  organization={IEEE}
}

% xlnet
@article{xlnet,
  title={Xlnet: Generalized autoregressive pretraining for language understanding},
  author={Yang, Zhilin and Dai, Zihang and Yang, Yiming and Carbonell, Jaime and Salakhutdinov, Russ R and Le, Quoc V},
  journal={Annual Conference on Neural Information Processing Systems (NeurIPS)},
pages        = {5754--5764},
  year={2019}
}

% pre-trained 综述
@article{nlpsurvey,
  title={Deep Learning--based Text Classification: A Comprehensive Review},
  author={Minaee, Shervin and Kalchbrenner, Nal and Cambria, Erik and Nikzad, Narjes and Chenaghlu, Meysam and Gao, Jianfeng},
  journal={ACM Computing Surveys (CSUR)},
  volume={54},
  number={3},
  pages={1--40},
  year={2021},
  publisher={ACM New York, NY, USA}
}

@article{fang2019towards,
  title={Towards transfer learning for end-to-end speech synthesis from deep pre-trained language models},
  author={Fang, Wei and Chung, Yu-An and Glass, James},
  journal={arXiv preprint arXiv:1906.07307},
  year={2019}
}

@inproceedings{klimkov2019fine,
  title={Fine-Grained Robust Prosody Transfer for Single-Speaker Neural Text-To-Speech},
  author={Klimkov, Viacheslav and Ronanki, Srikanth and Rohnke, Jonas and Drugman, Thomas},
  booktitle={Annual Conference of the International Speech Communication Association (INTERSPEECH)},
publisher    = {ISCA},
  pages={4440--4444},
  year={2019}
}

@inproceedings{lee2019robust,
  title={Robust and fine-grained prosody control of end-to-end speech synthesis},
  author={Lee, Younggun and Kim, Taesu},
  booktitle={IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={5911--5915},
  year={2019},
  organization={IEEE}
}

@inproceedings{an2019learning,
  title={Learning hierarchical representations for expressive speaking style in end-to-end speech synthesis},
  author={An, Xiaochun and Wang, Yuxuan and Yang, Shan and Ma, Zejun and Xie, Lei},
  booktitle={IEEE Automatic Speech Recognition and Understanding Workshop (ASRU)},
  pages={184--191},
  year={2019},
  organization={IEEE}
}

% han
@inproceedings{han,
  title={Hierarchical attention networks for document classification},
  author={Yang, Zichao and Yang, Diyi and Dyer, Chris and He, Xiaodong and Smola, Alex and Hovy, Eduard},
  booktitle={Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL HLT)},
  pages={1480--1489},
publisher    = {Association for Computational Linguistics},
  year={2016}
}

% multi-scale
@inproceedings{multiscale,
  title={Towards multi-scale style control for expressive speech synthesis},
  author={Li, Xiang and Song, Changhe and Li, Jingbei and Wu, Zhiyong and Jia, Jia and Meng, Helen},
  booktitle={Annual Conference of the International Speech Communication Association (INTERSPEECH)},
  pages        = {4673--4677},
  publisher    = {{ISCA}},
  year={2021}
}
@inproceedings{yi2022prosodyspeech,
  title={Prosodyspeech: Towards Advanced Prosody Model for Neural Text-to-Speech},
  author={Yi, Yuanhao and He, Lei and Pan, Shifeng and Wang, Xi and Xiao, Yujia},
  booktitle={IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={7582--7586},
  year={2022},
  organization={IEEE}
}

@inproceedings{wu2022self,
  title={Self-supervised Context-aware Style Representation for Expressive Speech Synthesis},
  author={Wu, Yihan and Wang, Xi and Zhang, Shaofei and He, Lei and Song, Ruihua and Nie, Jian-Yun},
  booktitle    = {Annual Conference of the International Speech Communication Association (INTERSPEECH)},
  pages        = {5503--5507},
  publisher    = {ISCA },
  year         = {2022},
}

% 综述
@article{survey,
  title={A survey on neural speech synthesis},
  author={Tan, Xu and Qin, Tao and Soong, Frank and Liu, Tie-Yan},
  journal={arXiv preprint arXiv:2106.15561},
  year={2021}
}


@inproceedings{nakata11audiobook,
  title={Audiobook Speech Synthesis Conditioned by Cross-Sentence Context-Aware Word Embeddings},
  author={Nakata, Wataru and Koriyama, Tomoki and Takamichi, Shinnosuke and Tanji, Naoko and Ijima, Yusuke and Masumura, Ryo and Saruwatari, Hiroshi},
  booktitle={ISCA Speech Synthesis Workshop (SSW11)},
  pages={211--215},
organization={ISCA},
year={2021}
}

% NVC-Net
@article{nguyen2021nvc,
  title={NVC-Net: End-to-End Adversarial Voice Conversion},
  author={Nguyen, Bac and Cardinaux, Fabien},
  journal={arXiv preprint arXiv:2106.00992},
  year={2021}
}
@inproceedings{gallegos2021comparing,
  title={Comparing acoustic and textual representations of previous linguistic context for improving text-to-speech},
  author={Gallegos, Pilar Oplustil and O'Mahony, Johannah and King, Simon},
  booktitle={ISCA Speech Synthesis Workshop (SSW11)},
  pages={205--210},
  year={2021},
  organization={ISCA}
}
@article{oplustil2020using,
  title={Using previous acoustic context to improve text-to-speech synthesis},
  author={Oplustil-Gallegos, Pilar and King, Simon},
  journal={arXiv preprint arXiv:2012.03763},
  year={2020}
}
@inproceedings{du2021rich,
  title={Rich prosody diversity modelling with phone-level mixture density network},
  author={Du, Chenpeng and Yu, Kai},
  booktitle={Annual Conference of the International Speech Communication Association (INTERSPEECH)},
pages        = {3136--3140},
  publisher    = {ISCA},
  year={2021}
}

@inproceedings{hodari2021camp,
  title={CAMP: A two-stage approach to modelling prosody in context},
  author={Hodari, Zack and Moinet, Alexis and Karlapati, Sri and Lorenzo-Trueba, Jaime and Merritt, Thomas and Joly, Arnaud and Abbas, Ammar and Karanasou, Penny and Drugman, Thomas},
  booktitle={ICASSP 2021-2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={6578--6582},
  year={2021},
  organization={IEEE}
}
% Transfer Learning SV
@article{jia2018transfer,
  title={Transfer learning from speaker verification to multispeaker text-to-speech synthesis},
  author={Jia, Ye and Zhang, Yu and Weiss, Ron J and Wang, Quan and Shen, Jonathan and Ren, Fei and Chen, Zhifeng and Nguyen, Patrick and Pang, Ruoming and Moreno, Ignacio Lopez and others},
  journal={arXiv preprint arXiv:1806.04558},
  year={2018}
}

%LDE：
@inproceedings{cooper2020zero,   title={Zero-shot multi-speaker text-to-speech with state-of-the-art neural speaker embeddings},   author={Cooper, Erica and Lai, Cheng-I and Yasuda, Yusuke and Fang, Fuming and Wang, Xin and Chen, Nanxin and Yamagishi, Junichi},   booktitle={ICASSP 2020-2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},   pages={6184--6188},   year={2020},   organization={IEEE} }



%Attentron:
@article{choi2020attentron,   title={Attentron: Few-shot text-to-speech utilizing attention-based variable-length embedding},   author={Choi, Seungwoo and Han, Seungju and Kim, Dongyoung and Ha, Sungjoo},   journal={arXiv preprint arXiv:2005.08484},   year={2020} }

@inproceedings{skerry2018towards,
  title={Towards end-to-end prosody transfer for expressive speech synthesis with tacotron},
  author={Skerry-Ryan, RJ and Battenberg, Eric and Xiao, Ying and Wang, Yuxuan and Stanton, Daisy and Shor, Joel and Weiss, Ron and Clark, Rob and Saurous, Rif A},
  booktitle={international conference on machine learning},
  pages={4693--4702},
  year={2018},
  organization={PMLR}
}


% multi-speaker TTS
@article{zhang2019learning,
  title={Learning to speak fluently in a foreign language: Multilingual speech synthesis and cross-language voice cloning},
  author={Zhang, Yu and Weiss, Ron J and Zen, Heiga and Wu, Yonghui and Chen, Zhifeng and Skerry-Ryan, RJ and Jia, Ye and Rosenberg, Andrew and Ramabhadran, Bhuvana},
  journal={arXiv preprint arXiv:1907.04448},
  year={2019}
}

@article{chen2020multispeech,
  title={Multispeech: Multi-speaker text to speech with transformer},
  author={Chen, Mingjian and Tan, Xu and Ren, Yi and Xu, Jin and Sun, Hao and Zhao, Sheng and Qin, Tao and Liu, Tie-Yan},
  journal={arXiv preprint arXiv:2006.04664},
  year={2020}
}

% AdaSpeech 123
@article{chen2021adaspeech,
  title={Adaspeech: Adaptive text to speech for custom voice},
  author={Chen, Mingjian and Tan, Xu and Li, Bohan and Liu, Yanqing and Qin, Tao and Zhao, Sheng and Liu, Tie-Yan},
  journal={arXiv preprint arXiv:2103.00993},
  year={2021}
}
@inproceedings{yan2021adaspeech2,
  title={Adaspeech 2: Adaptive text to speech with untranscribed data},
  author={Yan, Yuzi and Tan, Xu and Li, Bohan and Qin, Tao and Zhao, Sheng and Shen, Yuan and Liu, Tie-Yan},
  booktitle={ICASSP 2021-2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={6613--6617},
  year={2021},
  organization={IEEE}
}
@article{yan2021adaspeech3,
  title={Adaspeech 3: Adaptive text to speech for spontaneous style},
  author={Yan, Yuzi and Tan, Xu and Li, Bohan and Zhang, Guangyan and Qin, Tao and Zhao, Sheng and Shen, Yuan and Zhang, Wei-Qiang and Liu, Tie-Yan},
  journal={arXiv preprint arXiv:2107.02530},
  year={2021}
}

% NIPS few-shot voice cloning 
@article{arik2018neural,
  title={Neural voice cloning with a few samples},
  author={Arik, Sercan O and Chen, Jitong and Peng, Kainan and Ping, Wei and Zhou, Yanqi},
  journal={arXiv preprint arXiv:1802.06006},
  year={2018}
}


% batch norm
@inproceedings{ioffe2015batch,
  title={Batch normalization: Accelerating deep network training by reducing internal covariate shift},
  author={Ioffe, Sergey and Szegedy, Christian},
  booktitle={International conference on machine learning},
  pages={448--456},
  year={2015},
  organization={PMLR}
}

% Attention
@inproceedings{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  booktitle={Annual Conference on Neural Information Processing Systems (NeurIPS)},
  pages={5998--6008},
  year={2017}
}

% HiFiGAN
@article{kong2020hifi,
  title={Hifi-gan: Generative adversarial networks for efficient and high fidelity speech synthesis},
  author={Kong, Jungil and Kim, Jaehyeon and Bae, Jaekyoung},
  journal={Annual Conference on Neural Information Processing Systems (NeurIPS)},
  pages={17022--17033},
  year={2020}
}
% fs2
@inproceedings{fastspeech2,
  title={FastSpeech 2: Fast and High-Quality End-to-End Text to Speech},
  author={Ren, Yi and Hu, Chenxu and Tan, Xu and Qin, Tao and Zhao, Sheng and Zhao, Zhou and Liu, Tie-Yan},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2021}
}


% mfa
@inproceedings{mfa,
  title={Montreal Forced Aligner: Trainable Text-Speech Alignment Using Kaldi.},
  author={McAuliffe, Michael and Socolof, Michaela and Mihuc, Sarah and Wagner, Michael and Sonderegger, Morgan},
  booktitle={Interspeech},
  volume={2017},
  pages={498--502},
  year={2017}
}

@article{msemotts,
  title={{MsEmoTTS}: Multi-scale emotion transfer, prediction, and control for emotional speech synthesis},
  author={Lei, Yi and Yang, Shan and Wang, Xinsheng and Xie, Lei},
  journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing},
  year={2022},
volume={30},
pages={853--864},
  publisher={IEEE}
}

@article{unitts,
  title={UniTTS: Residual Learning of Unified Embedding Space for Speech Style Control},
  author={Kang, Minsu and Kim, Sungjae and Kim, Injung},
  journal={arXiv preprint arXiv:2106.11171},
  year={2021}
}

@article{delightfultts,
  title={DelightfulTTS: The Microsoft Speech Synthesis System for Blizzard Challenge 2021},
  author={Liu, Yanqing and Xu, Zhihang and Wang, Gang and Chen, Kuan and Li, Bohan and Tan, Xu and Li, Jinzhu and He, Lei and Zhao, Sheng},
  journal={arXiv preprint arXiv:2110.12612},
  year={2021}
}

@inproceedings{tan2020fine,
  title={Fine-grained style modeling, transfer and prediction in text-to-speech synthesis via phone-level content-style disentanglement},
  author={Tan, Daxin and Lee, Tan},
  booktitle={Annual Conference of the International Speech Communication Association (INTERSPEECH)},
  pages        = {4683--4687},
  publisher    = {ISCA},
  year={2021}
}

@article{tseng2005fluent,
  title={Fluent speech prosody: Framework and modeling},
  author={Tseng, Chiu-yu and Pin, Shao-huang and Lee, Yehlin and Wang, Hsin-min and Chen, Yong-cheng},
  journal={Speech Communication},
  volume={46},
  pages={284--309},
  year={2005},
  publisher={Elsevier}
}

@inproceedings{lei2021fine,
  title={Fine-grained emotion strength transfer, control and prediction for emotional speech synthesis},
  author={Lei, Yi and Yang, Shan and Xie, Lei},
  booktitle={IEEE Spoken Language Technology Workshop (SLT)},
  pages={423--430},
  year={2021},
  organization={IEEE}
}

@article{selkirk1986derived,
  title={On derived domains in sentence phonology},
  author={Selkirk, Elisabeth},
  journal={Phonology},
  volume={3},
  pages={371--405},
  year={1986},
  publisher={Cambridge University Press}
}

@article{liberman1977stress,
  title={On stress and linguistic rhythm},
  author={Liberman, Mark and Prince, Alan},
  journal={Linguistic Inquiry},
  volume={8},
  pages={249--336},
  year={1977},
  publisher={JSTOR}
}

@inproceedings{olive1977rule,
  title={Rule synthesis of speech from dyadic units},
  author={Olive, Joseph},
  booktitle={IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  volume={2},
  pages={568--570},
  year={1977},
  organization={IEEE}
}

@inproceedings{hunt1996unit,
  title={Unit selection in a concatenative speech synthesis system using a large speech database},
  author={Hunt, Andrew J and Black, Alan W},
  booktitle={IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  volume={1},
  pages={373--376},
  year={1996},
  organization={IEEE}
}

@incollection{campbell1997prosody,
  title={Prosody and the selection of source units for concatenative synthesis},
  author={Campbell, Nick and Black, Alan W},
  booktitle={Progress in Speech Synthesis},
  pages={279--292},
  year={1997},
  publisher={Springer}
}


@inproceedings{wang2000corpus,
  title = {A corpus-based {Chinese} speech synthesis with contextual dependent unit selection},
  author = {Ren-Hua Wang and Zhongke Ma and Wei Li and Donglai Zhu},
  year = {2000},
  pages = {391--394},
  booktitle = {International Conference on Spoken Language Processing (ICSLP)},
  publisher = {ISCA},
}

@inproceedings{black1997automatically,
  title={Automatically clustering similar units for unit selection in speech synthesis},
  author={Black, Alan W and Taylor, Paul A},
  booktitle = {European Conference on Speech Communication and Technology (EUROSPEECH)},
  publisher= {ISCA},
  pages = {601--604},
  year={1997},
}

@inproceedings{yoshimura1999simultaneous,
  title={Simultaneous modeling of spectrum, pitch and duration in {HMM}-based speech synthesis},
  author={Yoshimura, Takayoshi and Tokuda, Keiichi and Masuko, Takashi and Kobayashi, Takao and Kitamura, Tadashi},
  booktitle={European Conference on Speech Communication and Technology (EUROSPEECH)},
  pages = {2347--2350},
  publisher = {ISCA},
  year={1999}
}

@inproceedings{tokuda2000speech,
  title={Speech parameter generation algorithms for {HMM}-based speech synthesis},
  author={Tokuda, Keiichi and Yoshimura, Takayoshi and Masuko, Takashi and Kobayashi, Takao and Kitamura, Tadashi},
  booktitle={IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  volume={3},
  pages={1315--1318},
  year={2000},
  organization={IEEE}
}

@article{zen2009statistical,
  author       = {Heiga Zen and
                  Keiichi Tokuda and
                  Alan W. Black},
  title        = {Statistical parametric speech synthesis},
  journal    = {Speech Communication},
  volume       = {51},
  pages        = {1039--1064},
  year         = {2009},
  publisher = {Elsevier}
}
..

@article{tokuda2013speech,
  title={Speech synthesis based on hidden Markov models},
  author={Tokuda, Keiichi and Nankaku, Yoshihiko and Toda, Tomoki and Zen, Heiga and Yamagishi, Junichi and Oura, Keiichiro},
  journal={Proceedings of the IEEE},
  volume={101},
  pages={1234--1252},
  year={2013},
  publisher={IEEE}
}

@inproceedings{ze2013statistical,
  title={Statistical parametric speech synthesis using deep neural networks},
  author={Ze, Heiga and Senior, Andrew and Schuster, Mike},
  booktitle={IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={7962--7966},
  year={2013},
  organization={IEEE}
}

@inproceedings{hsu2018hierarchical,
  title={Hierarchical Generative Modeling for Controllable Speech Synthesis},
  author={Hsu, Wei-Ning and Zhang, Yu and Weiss, Ron J and Zen, Heiga and Wu, Yonghui and Wang, Yuxuan and Cao, Yuan and Jia, Ye and Chen, Zhifeng and Shen, Jonathan and others},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2018}
}

