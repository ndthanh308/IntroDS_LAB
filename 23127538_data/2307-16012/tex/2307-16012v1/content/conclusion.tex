\section{Conclusion} \label{sec:conclution}
This work proposes MSStyleTTS, an unsupervised multi-scale context-aware style modeling method for expressive speech synthesis.
MSStyleTTS allows modeling the speech style at different levels from hierarchical context information.
Experimental results show that our proposed method can synthesize speech with richer expressiveness and higher naturalness than baseline FastSpeech 2, WSV* and HCE models on both in-domain and out-of-domain datasets.
Extensive ablation studies demonstrate the effectiveness of the several techniques used in our proposed MSStyleTTS, especially for the context information usage and multi-scale style representation.
