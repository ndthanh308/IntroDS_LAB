In the literature on unmanned aerial vehicles' control using reinforcement learning, a wide range of works exists that can be divided into two main groups, namely high-level and low-level control. By low-level control, we refer to the direct control of motors by providing their actual angular velocity or by providing thrust, roll, pitch, and yaw. Low-level control works include \cite{RAMEZANIDOORAKI2021103671} where RL is used to learn for direct control of UAV motors speeds from odometry, \cite{Hwangbo_2017} where a combination of RL and PD is used to train the controller, \cite{MolchanovRL_LowLevel} where RL used to learn more general policies for low-level quad-copter control, and \cite{ChenHuanPi_LowLevel} where RL is used for control and tracking of a trajectory. By high-level control, we refer to a trajectory of waypoints or attitudes generated by the controller. High-level control works include \cite{machines10070500} where an end-to-end approach using deep RL is used to learn to control three axes of quad-copter when RGB-D image is provided as input.
\par
Curiosity as an intrinsic motive is observed widely in the literature. In some early works, such as \cite{intrinsicmotivation} and \cite{GOTTLIEB2013585}, the authors defined a framework of intrinsic motivation and curiosity as one such motivation. In recent years, and considering the new computational capabilities offered by advancements in hardware systems, more realistic computational models of curiosity have been researched and developed in the literature. As a result, different types of curiosity methods, such as Information Theoretic based \cite{DBLP:journals/corr/HouthooftCDSTA16}, Prediction based (e.g., surprisal \cite{DBLP:journals/corr/PathakAED17}), and Count based \cite{10.5555/3305890.3305962}, have been proposed. For example, a module called intrinsic curiosity module (ICM) is used in \cite{DBLP:journals/corr/PathakAED17} to predict the future states and actions that need to be taken to reach those states, and considered the prediction error between the actual future states and predicted states as the curiosity reward. Further, there are works such as \cite{10.5555/3305890.3305962} which considered curiosity as a measure to count how many times a state is visited during the agent's lifetime. Curiosity has been used to achieve specific qualities in robot actions. For example, \cite{LearningGentleObject} used curiosity to achieve gentle touch while grasping objects. In other literature, it used to increase the performance of well-known objectives in robotics. For example, in \cite{motionplanninghumanoid} curiosity is used for motion planning of humanoid robots, in \cite{InnateMotivationRobotSwarms} for control of swarm of robots, and in \cite{CuriosityRobotNavigation} for robot navigation.
\par
Curiosity in the low-level control of the quad-copter is an area that is much less researched in the literature. In some works, curiosity is defined as a measure of difference rather than surprise or novelty. For example, \cite{sun2022aggressive} defines curiosity as the difference between states observed by a policy at two different times. 
%\par
In this work, curiosity is defined as a measure of novelty and a parameterized function that gradually learns the previously visited states, loses its interest in them, and constantly searches for novel states.

