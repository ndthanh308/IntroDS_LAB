\label{sec:conclusion}
In this work, we proposed a new approach for autonomous learning of low-level control policy. To achieve that, we proposed a new approach for implementing a computational model of curiosity motive using prediction error. To measure the capability of our algorithm, we designed and implemented a complex environment in Gazebo for learning quad-copter low-level flight control policy. In the designed environment, the algorithm should learn to directly control the quad-copter by generating the proper motor speed from odometry data. Further, the algorithm should learn to fly through obstacles while controlling the Yaw direction of the quad-copter toward the desired location. We ran tests to measure and compare the proposed algorithm to other baseline algorithms. 
\par
As shown in Section \ref{evaluation_section} of this paper, the proposed approach (i.e., PPO+HCM) can learn a flight policy when other algorithms fail to do so. By incorporating the proposed curiosity module, the algorithm can evolve the exploration pattern and fly to areas where other algorithms avoid flying. As a result, it can learn to control the quad-copter, control the Yaw direction of the quad-copter toward the desired location, and avoid hitting obstacles (as a low-level controller). 
%\par
In future works, we plan to measure the effect of incorporating machine imagination in a low-level framework.