% \newpage
\section{Theory} \label{sec:theory}

This section describes the problem, provides our findings with proofs, and offers illustrative examples. We adhere to the International System of Units throughout the paper unless stated otherwise.

\subsection{Problem Statement} \label{subsec:problemstatement}

We define a “probe” as a device that records its position as point data in the Earth's spatial reference system (e.g., geographic coordinates). For instance, a smartphone and connected vehicle can be a probe\footnote{By this definition, the number of probes does not necessarily match the number of vehicles (e.g., multiple smartphones on a vehicle).}. Let $m\ \{ m \in \mathbf{Z}^{nonneg}\}$ and $\hat{m}$ denote the number of probes passing through a unit segment during an observation period and its estimator, respectively. We present the distribution of $\hat{m}$ under the following conditions.

Assume that each probe traverses the Earth's surface at a speed of $S$ $\{ S \in \mathbf{R}^{+}\}$ m/s, where $S$ is an independent and identically distributed (i.i.d.) continuous random variable. We denote the realised value of $S$ as $s$ $\{ s \in \mathbf{R}^{+}\}$. Let $g(s)$ $\{ g(s) \in \mathbf{R}^{nonneg} \mid 0 \leq g(s); \displaystyle \int_{0}^{\infty} g(s)\mathrm{d}s = 1 \}$ be the probability density function (PDF) of the probe speed population. The population of $s$ is a hypothetical infinite group of $s$. Therefore, the possibility that multiple probes are carried by one vehicle at the same $s$ is already considered in $g(s)$ as a part of the distribution. All probes share the same data recording interval $t$ $\{ t \in \mathbf{R}^{+}\}$ s. In a uniform motion, each probe records its position as point data (i.e., “\textit{footprints}”) at an interval of $t$ s. The probe speed is recorded during this process. Probe identifiers $i$ or detailed timestamps are not necessarily recorded, but data points have at least nominal information to identify a recorded time range of interest (e.g., a label of “July 2023”). We assume that there are no errors or failures in the positioning or recording.

After the probe point location data are recorded, an analyst draws a $d$-m virtual cordon ($\{ d \in \mathbf{R}^{+}\}$) over the data measured along the road segment of interest. This spatial data cropping procedure makes each probe record its first location in the virtual cordon at a uniformly distributed random timing within any nonnegative seconds less than $t$ after a probe enters the cordon. The analyst may extract data within the time range of interest, as needed. The virtual cordon will contain $n\ \{ n \in \mathbf{Z}^{nonneg}\}$ data points at a speed of $s_a$ where $a\ \{ a \in \mathbf{Z}^{nonneg}\mid a \leq n\}$ is a record identifier. Figure \ref{fig:figure2} shows an example of a virtual cordon containing eight data points. Although the figure distinguishes the two probes, this work does not assume that analysts have information to identify individual probes.

% Figure environment removed

\subsection{Unbiased Estimator of $m$} \label{subsec:lemma1}

\begin{customlemma}{1}\label{lma:lemma1}\normalfont
    If we define $\hat{m}$ as
    
    \begin{equation} \label{eq:draso}
        \hat{m} = \frac{t}{d} \sum_{a=1}^{n}s_{a}, \forall m, d, t, n, s
    \end{equation}
    
    \noindent
    $\hat{m}$ is an unbiased estimator of the true probe traffic volume $m$ (Equation \ref{eq:kgbnho}).
    
    \begin{equation} \label{eq:kgbnho}
        \mathrm{E}[\hat{m}] = m, \forall m
    \end{equation}
    
\end{customlemma}

\begin{quote}
    \begin{proof}
        Because uniform motion is assumed, $s_i = s_a$ within any probe and $s_it$ is the distance along a cordon the $i$th probe traverses in $t$ s. Using $n_i$ as the number of data points within a cordon from the probe, Equation \ref{eq:draso} can be reduced to
        
        \begin{equation} \label{eq:uthnbgn}
            \hat{m} = \displaystyle \frac{t s_i n_i}{d}
        \end{equation}
        
        \noindent
        for the $i$th probe. In Equations \ref{eq:draso} and \ref{eq:uthnbgn}, $n_i$ can be broken down into $n_i = \tilde{n}_i + K_i$ where $\tilde{n}_i$ $\lbrace{\tilde{n} \in \mathbf{Z}^{nonneg}}\rbrace$ is the minimum number of data points that could be recorded in the virtual cordon. It is calculated with the floor function as
          
        \begin{equation} \label{eq:kdtfg2}
            \tilde{n}_i = \left\lfloor\frac{d}{s_i t}\right\rfloor
        \end{equation}
        
        \noindent
        Here, $K_i$ is a Bernoulli random variable representing the number of additional data points per probe $\lbrace{K \in \mathbf \{0, 1\}}\rbrace$ observed in addition to $\tilde{n}_i$ data points. Because uniform motion is assumed and a probe leaves its first record in the cordon at a random time at $t$ s or before once the probe enters the cordon. Naturally, an additional data point is recorded at the probability of the fractional part of $d/(s_it)$. When we define the fractional part as $p_i$ $\lbrace{p \in \mathbf{R}^{nonneg} \mid 0 \leq p < 1}\rbrace$,
        
        \begin{equation} \label{eq:yathe2}
            p_i = \frac{d}{s_it} \mod 1
        \end{equation}
    
        Because $K_i$ follows the Bernoulli distribution $Ber(p_i)$, its expected value $\mathrm{E}[K_i]$ is $p_i$. From Equations \ref{eq:uthnbgn}, \ref{eq:kdtfg2}, and \ref{eq:yathe2}, $\mathrm{E}[\hat{m}]$, the expected value of $\hat{m}$, is
        
        \begin{equation} \label{eq:yatlhh2}
            \mathrm{E}[\hat{m}] = \frac{s_it}{d} \left[ \left\lfloor\frac{d}{s_it}\right\rfloor + \left( \frac{d}{s_it} \mod 1 \right) \right] = 1
        \end{equation}
        
        \noindent
         when $m = 1$. Accordingly, $\mathrm{E}[\hat{m}] = m$ for any $m$. Therefore, $\hat{m}$ is an unbiased estimator of $m$.
    \end{proof}
\end{quote}

\subsubsection{Example 1} \label{subsub:example1}

We assume $d = 100$ and $t = 1$ in Figure \ref{fig:figure2}. The expected number of records within the segment from probe B ($s_i = 30$) is $100/(30 \cdot 1) \approx 3.333$; therefore, at least three records are observed (i.e., $\tilde{n} = 3$). Since it is impossible to observe 3.333 records, one more record is observed at a probability of approximately 0.333 (i.e., $p_i \approx 0.333$). In Figure \ref{fig:figure2}, $m = 2$, $\mathrm{E}[\hat{m}] = 2$ and $\hat{m} = 1.9$. If the cordon had contained the data points only from probe A, $m = 1$, $\mathrm{E}[\hat{m}] = 1$ and $\hat{m} = 1$. If the cordon had included the data points only from probe B, $m = 1$, $\mathrm{E}[\hat{m}] = 1$ and $\hat{m} = 0.9$.

\subsection{Variance of $\hat{m}$} \label{subsec:lemma2}

\begin{customlemma}{2}\label{lma:lemma2}\normalfont
    When we denote the variance of $\hat{m}$ as $\mathrm{Var}[\hat{m}]$:
    
    \begin{equation} \label{eq:efrus}
         \mathrm{Var}[\hat{m}]=\frac{mt^2}{d^2}\int_0^{\infty} b(s, d, t)g(s)\mathrm{d}s
    \end{equation}
    
    \noindent
    where
    
    \begin{equation} \label{eq:bahos}
        b(s, d, t) = s^2 p(1-p) = s^2 \left( \frac{d}{st} \mod 1 \right) \left[1- \left( \frac{d}{st} \mod 1 \right)\right]
    \end{equation}
    
\end{customlemma}

\begin{quote}
    \begin{proof}
         The variance of $\hat{m}$ originates from the discreteness of the number of recorded data points, namely, the Bernoulli random variable $K$. From Equation \ref{eq:uthnbgn} and the multiplication rule of probability, $\mathrm{Var}[\hat{m} \mid S = s_i]$ is proportional to the variance of the Bernoulli distribution $p(1-p)$ multiplied by the scaling factor $st/d$ raised to a power of 2. Because $S \sim g(s)$, integrating $s^2 t^2 p(1-p)g(s)/d^2$ over $s$ gives the variance of $\hat{m}$ per probe. Because $S$ is assumed to be i.i.d.,  $\mathrm{Var}[\hat{m}] \propto m$ from the additivity of variances.
    \end{proof}
\end{quote}

\subsubsection{Example 2} \label{subsub:example2}

Hereafter, we use a finite mixture of normal distributions by \cite{PARKetal-2010} as $g(s)$ unless stated otherwise. The speed distribution had been fitted to data collected on Interstate Highway 35 (I-35) in Texas. It is comprised of four normal distributions $N(\upmu, \upsigma^2)$ defined by $\upmu = (27.042, 24.000, 9.394, 4.294)$, $\upsigma = (1.831, 4.797, 3.167, 1.686)$, $w = (0.647, 0.223, 0.055, 0.074)$, and $\displaystyle \sum w_j = 1$ where $\upmu \ \{ \upmu \in \mathbf{R}\}$ is a tuple (i.e., a finite ordered list) of mean speed in m/s, $\upsigma \ \{ \upsigma \in \mathbf{R}^{nonneg}\}$ is a tuple of standard deviation in m/s before truncation, and $w \ \{w \in \mathbf{R}^{nonneg}\, |\, w \leq 1 \}$ defines the proportions of the normal distributions within the mixture. The distribution was truncated at $s$ = 0 and $s$ = 40. The resulting $g(s)$ is a mixture of four truncated normal distributions, defined by the following equations (Figure \ref{fig:figure3}a):

\begin{equation} \label{eq:bruxl}
    g(s \mid \upmu, \upsigma, 0, 40) =
    \begin{cases}
    \displaystyle \sum\limits_{j=1}^4
    w_j \uppsi(s \mid \upmu_j, \upsigma_j, 0, 40)
    , & 0 < s \leq 40 \\
    0, & \text{otherwise}
    \end{cases}
\end{equation}

\noindent
where $\upalpha < \upbeta$, $0 < \upsigma$, and

\begin{equation} \label{eq:trunc}
    \uppsi(x \mid \upmu, \upsigma, \upalpha, \upbeta) =
    \frac{\upphi \displaystyle \left( \frac{x-\upmu}{\upsigma} \right)}
    {\upsigma \displaystyle \left[ \Phi \displaystyle \left( \frac{\upbeta-\upmu}{\upsigma} \right) - \Phi \displaystyle \left(\frac{\upalpha-\upmu}{\upsigma}\right) \right] } \\
\end{equation}

\begin{equation} \label{eq:iojmh}
    \upphi(x) = \displaystyle \frac{e^{\displaystyle \left( \frac{-x^2}{2} \right) }}{\sqrt{2\uppi}}
\end{equation}

\begin{equation} \label{eq:jkniy}
    \Phi(x) = \frac{1}{2} \displaystyle \left[1 + \operatorname*{erf}\displaystyle \left(\frac{x}{\sqrt{2}}\right) \right]\\
\end{equation}

Assuming $d = 300$ and $t = 4$, Figure \ref{fig:figure3}b displays $4^2/300^2 \cdot b(s, 300, 4)$, the variance in the estimated probe traffic volume as a function of $s$ (Equation \ref{eq:bahos}). If $S$ were uniformly distributed between 0 and 40 (i.e., $S \sim U(0, 40]$), the area under the function in Figure \ref{fig:figure3}b would have been proportional to the variance of the estimated probe traffic volume (i.e., $\mathrm{Var}[\hat{m} \mid S = s_i]$). Here,  we want to weigh $4^2/300^2 \cdot b(s, 300, 4)$ by $g(s)$ because $S \sim g(s)$. The operation gives Figure \ref{fig:figure3}c, where the area under the function, 0.019, is the theoretical variance of $\hat{m}$ from a probe (Equation \ref{eq:efrus}).

% Multiple figures
% Figure environment removed

\subsection{Shape of $\hat{m}$} \label{subsec:theorem1}

\begin{customthm}{1}\label{theorem:theorem1}\normalfont
    Let $u$ be a nonnegative integer $\lbrace{u \in \mathbf{Z}^{nonneg}}\rbrace$ that operationally substitutes $\tilde{n}$. With the previously defined variables and a function, the PDF of $\hat{m}$ is given as $f(\hat{m}; m)$:
    
    \begin{equation} \label{eq:hnmnmi}
        f(\hat{m}; m) = f'^{*m}(\hat{m})
    \end{equation}
    
    \noindent
    where $f'^{*m}(\hat{m})$ denotes $m$-fold self-convolution of $f'(\hat{m})$. The function $f'(\hat{m})$ is defined as
    
    \begin{equation} \label{eq:rojoc}
        f'(\hat{m})=\displaystyle \sum_{u=0}^{\infty}\sum_{k=0}^{1} h(\hat{m}; t, d, u, k) 
    \end{equation}
    
    \noindent
    where
    
    \begin{equation} \label{eq:husan}
        h(\hat{m}; t, d, u, k)  =
        \begin{cases}
        \displaystyle g\left(\frac{d\hat{m}}{t(u+k)}\right)
        \frac{p^{k}(1 - p)^{1-k}d}{t (u+k)}
        , & (u = 0 \land k \neq 0) \lor \left( u \neq 0 \land \displaystyle \frac{u+k}{u+1} < \hat{m} \leq \displaystyle \frac{u+k}{u} \right)\\
        0, & \text{otherwise}
        \end{cases}
    \end{equation}
    
\end{customthm}

\begin{quote}
    \begin{proof}
        From Equations \ref{eq:kdtfg2} and \ref{eq:yathe2}, $s$ uniquely determines $\tilde{n}$ and $p$ once $d$ and $t$ are determined. In addition, any single $s$ has a mutually exclusive set of $k$ as the outcome of a Bernoulli trial. In Equation \ref{eq:uthnbgn}, $\hat{m}$ is a linear function of $s$ with slope $t (\tilde{n}+k)/d$. Because the probe speed $S$ is i.i.d., the summation of all relative frequencies for possible occurrences of $\tilde{n}$ and $k$ by $\hat{m}$ gives the PDF of $\hat{m}$; therefore, the PDF of $\hat{m}$ contains the joint probability function $g(s)p^{k}(1 - p)^{1-k}$. In Equations \ref{eq:rojoc} and \ref{eq:husan}, $u$ substitutes for $\tilde{n}$. Let $x$ be a nonnegative real number $\lbrace{x \in \mathbf{R}^{nonneg}}\rbrace$ and $\updelta$ be an infinitesimal interval. The probability that $\hat{m}$ takes a value in the interval $(x, x + \updelta ]$ is calculated by integrating the PDF of $\hat{m}$ over the interval. From Equation \ref{eq:uthnbgn}, $m = 0$ when $u + k = 0$; otherwise, the interval of $s$ corresponding to $(x, x + \updelta]$ is $(s, s+ \updelta']$ = $\displaystyle \left(dx/\left[t(u+k)\right], dx/\left[t(u+k)\right] + \updelta d/\left[t(u+k)\right] \right]$, where $dx/\left[t(u+k)\right]$ is $s$ as a function of $\hat{m}$  and $d/\left[t(u+k)\right]$ is the reciprocal of the slope of $\hat{m}$ as a function of $s$ (e.g., Figure \ref{fig:figure4}). However, the interval of $s$ must be constant regardless of $\hat{m}$ in the PDF of $\hat{m}$ because $\hat{m}$ results from $S$, but not vice versa. Therefore, the joint probability of $u$ and $k$, in fact, must be multiplied by $d/\left[t(u+k)\right]$, which is the reciprocal of the slope of $s$ as a function of $\hat{m}$. When $S$ is i.i.d., $\hat{m}$ is also i.i.d. (Equation \ref{eq:uthnbgn}). Hence, the PDF of $\hat{m}$ emerges as an $m$-fold self-convolution of the PDF where $m = 1$ (Equation \ref{eq:hnmnmi}).  
    \end{proof}
\end{quote}

\begin{customcorollary}{1}\label{crlry:corollary1}\normalfont
    As $m$ approaches infinity, the shape of $f(\hat{m}; m)$ converges to that of a normal distribution:
    
    \begin{equation} \label{eq:oihnmybn}
        \lim_{{m \to \infty}} f(\hat{m}; m) = N \left(m, \frac{mt^2}{d^2} \int_0^{\infty} b(s,d,t)g(s)\mathrm{d}s\right)
    \end{equation}
\end{customcorollary}

\begin{quote}
    \begin{proof}
        Because $\hat{m}$ is i.i.d., Equation \ref{eq:oihnmybn} is derived from the classical central limit theorem on lemmata \ref{lma:lemma1} and \ref{lma:lemma2}.
    \end{proof}
\end{quote}

\subsubsection{Example 3} \label{subsub:example3}

Assuming $d = 300$ and $t = 4$, Figure \ref{fig:figure4} plots Equation \ref{eq:uthnbgn} (i.e., when $m = 1$). The combinations of $\tilde{n}$ and $k$ fall into an infinite periodic pattern along the $s$-axis because $\tilde{n}$ increases towards infinity as $s$ approaches 0. Because $S \sim g(s)$, we want to take the relative frequency of speed and each $k$ by multiplying the probability mass function (PMF) of $Ber(p)$ by $g(s)$. After this operation, we obtain the overall frequency of the combination of $\tilde{n}$ and $k$ by $s$ (Figure \ref{fig:figure5}).

% One figure
% Figure environment removed

% One figure
% Figure environment removed

From Figure \ref{fig:figure4}, it is apparent that the density in an interval of $\hat{m}$ can emerge from more than one combination of $\tilde{n}$ and $k$, which have different slopes for $\hat{m}$ with respect to $s$. Therefore, an infinitesimal interval of $\hat{m}$ can have different cardinalities of the frequencies projected from the $s$-axis; thus, we must consider the cardinality of $\hat{m}$. For example, the length of an infinitesimal interval of $\hat{m}$ corresponding to any interval between $s = 25$ and $s = 37.5$ in Figure \ref{fig:figure4} is 50 \% longer when $k = 1$ than when $k = 0$. Because we are interested in the PDF of $\hat{m}$, we must normalise the value using the cardinality of $\hat{m}$. This operation can be performed by dividing the relative frequency given the combination of $\tilde{n}$ and $k$ by each slope $t(\tilde{n}+k)/d$ before summation. Equation \ref{eq:rojoc} results in the PDF in Figure \ref{fig:figure6} in this example.

% One figure
% Figure environment removed

\subsection{Optimum Cordon Length} \label{subsec:theorem2}

Equation \ref{eq:efrus} tells that $d$ determines $\mathrm{Var}[\hat{m}]$ when $t$ and $g(s)$ are already fixed.  Considering that $d$ is often the only parameter that an analyst can control, the art of estimation error minimisation lies in setting a good cordon length $d$. That said, how long should $d$ be in what conditions? Modelling the relationships between $\hat{m}$ and the other variables gives us a hint on choosing a good cordon length $d$. % If an analyst pursues precision, 

\begin{customcorollary}{2}\label{crlry:corollary2}\normalfont
    Let $\max(d)$ denote the maximum feasible $d$ within a given segment. When $\max(d)$ exists, there can be a cordon length $d$ shorter than $\max(d)$ that minimises the precision of estimating $m$. Such $d$ can be sought by $\displaystyle \operatorname*{argmin}_{0 < d \leq \max(d)} obj(d)$ where $obj(d)$ is an objective function such as the variance-to-mean ratio (VMR)
    
    \begin{equation} \label{eq:ghvry}
        \mathrm{VMR}[\hat{m}] = 
        \frac{\mathrm{Var}[\hat{m}]}{\mathrm{E}[\hat{m}]} = \frac{t^2}{d^2}\int_0^{\infty} b(s,d,t)g(s)\mathrm{d}s
    \end{equation}
    
    \noindent
    or the coefficient of variation (CV)
    
    \begin{equation} \label{eq:hokeg}
        \mathrm{CV}[\hat{m}] = 
        \frac{ \sqrt{\mathrm{Var}[\hat{m}]} }{\mathrm{E}[\hat{m}]} = \frac{t}{d} \sqrt{\frac{1}{m} \int_0^{\infty} b(s,d,t)g(s)\mathrm{d}s}
    \end{equation}
\end{customcorollary}

\begin{quote}
    \begin{proof}
    Assume that Corollary 2 is false. In other words, assume that $\mathrm{CV}[\hat{m}]$ always monotonically decreases as $d$ increases. When $m = 1$, $t = 4$ and $S \sim g(s)$ defined by Equations \ref{eq:bruxl}-\ref{eq:jkniy}, $\mathrm{CV}[\hat{m}] = 0.310$ when $d = 150$ whereas $\mathrm{CV}[\hat{m}] = 0.230$ when $d = 110$. Because there is a counterexample to the assumed proposition that Corollary 2 is false, Corollary 2 is true.
    \end{proof}
\end{quote}

\subsubsection{Example 4} \label{subsub:example}

This example provides graphical descriptions of the proof of Corollary 2. Figure \ref{fig:figure7} displays an example\footnote{Figure \ref{fig:figure7} plots the function given this specific combination of $t$ and $g(s)$ and will look different with a different set of input values.}: $b(s, d, 4)g(s)$ and $4^2/d^2 \cdot b(s, d, 4)g(s)$ as functions of $s$ and $d$ when $S \sim g(s)$. In Figure \ref{fig:figure7}a, $b(s, d, t)g(s)$ has a periodic pattern along the $d$-axis. Figure \ref{fig:figure7}b is an extension of Figure \ref{fig:figure3}c to the $d$-axis, where $b(s, d, t)g(s)$ is scaled by $t^2/d^2$ to plot Equation \ref{eq:ghvry} when $m = 1$). Because $\mathrm{VMR}[\hat{m}]$ is inversely proportional to $d^2$, a larger $d$ tends to result in a better precision in $\hat{m}$. This is intuitive considering $\mathrm{Var}[\hat{m}]$ arises from the discreteness of the observed number of records. The ratio of the additional number of records $K$, a Bernoulli random variable, to the total number of records $n$ decreases as the cordon captures more data points, owing to a larger $d$.

However, VMR$[\hat{m}]$ or CV$[\hat{m}]$ does not always exhibit a monotonic decrease over $d$. As seen in Figure \ref{fig:figure8}a, the non-monotonicity of $\mathrm{CV}[\hat{m}]$ as a function of $d$ indicates the potential existence of $d$ that locally minimises the VMR or CV when the maximum $d$ exists. When some road geometry dictates the maximum $d$ to be 150 m (e.g., a 150-m road segment immediately bounded by intersections, beyond which traffic volumes can be different) in the condition of Figure \ref{fig:figure8}a, it would be better to set 110-m $d$ ($CV = 23.048\ \%$) than trying to set 150-m $d$ ($CV = 30.999\ \%$). Figure \ref{fig:figure8}b plots CV$[\hat{m}]$ as a function of $t$ when $d = 300$. CV$[\hat{m}]$ tends to increase as $t$ increases, but this relationship is not always monotonic.

% Multiple figures
% Figure environment removed

% Multiple figures
% Figure environment removed
