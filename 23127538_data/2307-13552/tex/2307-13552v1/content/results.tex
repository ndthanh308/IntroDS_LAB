\section{Result Analysis}

% Figure environment removed

% \subsection{Comparison of RC representations}
% Comparing both the PDDL and SAS+ encodings, the PDDL model has 480 variables, and 960 fact pairs and the bytes required for representing each state is 60 bytes whereas the SAS+ model introduced by \citealt{buchner2022comparison}. has 20 variables, 480 fact pairs and bytes required for representing each state is 16 bytes. In the experimental evaluations, less memory requirement to represent a state of 16 bytes compared to that of 60 bytes in PDDL encoding, helps the SAS+ model to explore more states in the given memory budget of 3.5GB.
% The SAS+ model introduced by \citealt{buchner2022comparison}. has 18 actions in their SAS+ model. In our experiments, we have provided results with two different PDDL models with 12 actions (m1) and 18 actions (m2). Here the m2 model has a branching factor similar to the SAS+ model provided in the literature.


\subsection{Comparision of Heuristics}

We conducted an empirical evaluation of the performance of two different PDDL models (m1 and m2), each with varying numbers of modeled actions, on two test datasets (d1 and d2). Furthermore, we compared the efficacy of various heuristics on the SAS+ dataset provided by \citet{buchner2022comparison}. We also evaluated the test datasets using DeepCubeA \cite{agostinelli2019solving}, a state-of-the-art domain-independent RC solver that leverages a combination of deep reinforcement learning and search algorithms. Our results show that DeepCubeA was able to solve all the problems in both datasets, albeit with a lower percentage of optimal plans. We provide a detailed explanation of plan optimality in the subsequent section. Table \ref{tab:exp-results} presents the experimental results, including the total number of problems solved and the percentage of optimal plans generated for each configuration tested. Our findings offer valuable insights into the efficiency and effectiveness of the models, heuristics, and representations employed for solving RC problems. \\
1. It has been observed that abstraction heuristics are sensitive to problem representation and exhibit poorer performance in PDDL compared to SAS+ representation. \\
2. Interestingly, the FF heuristic, which is a non-abstraction heuristic, has been found to perform equally (in SAS+) or better than the state-of-the-art PDB heuristic with Korf's patterns in the case of PDDL representation. \\
3. The CG and CEA heuristics may not be effective for solving Rubik's Cube, a puzzle-solving domain with no modeled preconditions. The complex nature of the domain and large branching factor makes it challenging to construct an accurate causal graph for the CG heuristic, and the lack of contextual information renders CEA heuristic ineffective.\\
4. Modeling a domain with all possible actions leads to an increase in the number of optimal plans.

In this paper, we provide plots that compare the states expanded, runtime, and memory usage for the dataset \textit{d2} using both PDDL and SAS+ representations. We have chosen to focus on the performance of dataset \textit{d2} because it can be compared with the SAS+ dataset provided in the study by \citealt{buchner2022comparison} as they have similar branching factor. Comparable figures for dataset \textit{d1} are available in the supplementary material, and the conclusions reached in the paper are consistent with those results. Additionally, we include supplementary plots that depict the number of states expanded, memory usage, and runtime comparisons against all other heuristics for both datasets and all models.

When assessing the efficacy of planning-based solvers in terms of their heuristics and representations, our findings indicate that no planner configuration was able to solve problems with optimal plan lengths exceeding 13 steps. However, DeepCubeA was capable of solving problems up to 26 steps in length. In terms of the number of problems solved, the FF heuristic is the best performing across all models in both datasets. The M\&S abstraction heuristic is the second-best performing heuristic in PDDL representation, but this is not the case for SAS+ representation. In fact, PDBs performed much better in the SAS+ representation than in the PDDL representation and were equally as effective as the FF heuristic. This can also be inferred from the states expansion trend of the abstraction heuristics shown in Figure \ref{FIG: states_expanded}(b).
The reason why pattern databases performed better in SAS+ representation than in PDDL representation and were equally effective as the FF heuristic is due to the greater expressiveness of SAS+ models, which allow for more efficient and compact representations of problems. Pattern databases are better able to capture the structure and relationships of problems in SAS+ representation, leading to more accurate and effective heuristics. However, preprocessing time for pattern databases can be longer in SAS+ representation because the language is more explicit and requires the computation of more states to generate the pattern. This is evident from the runtime comparison plot shown in Figure \ref{FIG: memory_time}(b).

\subsubsection{Comparison based on states expanded:}
Figure \ref{FIG: states_expanded} illustrates the number of states expanded in the A\textsuperscript{*} search algorithm. Specifically, Figure \ref{FIG: states_expanded}(a) compares the performance of various non-abstract heuristics against the FF heuristic, which was found to be the best-performing heuristic for solving the given set of problems. The diagonal line in the plot represents the performance of the heuristics if they were to perform equally well as the FF heuristic. Heuristics that perform better than the FF heuristic would appear below the diagonal, while heuristics that perform worse would appear above it. On the plot in Figure \ref{FIG: states_expanded}(a), the unsolved points on the \textit{y}-axis represent the set of problems that were unable to be solved by the other heuristics, while the FF heuristic was able to solve them. Conversely, the unsolved points on the \textit{x}-axis represent the set of problems that the FF heuristic was unable to solve, while the other heuristics were able to solve them. This applies to all other plots provided in the paper. As seen in the plot, all non-abstract heuristics performed worse than the FF heuristic as they lie on the left side of the diagonal. This indicates that the number of states expanded by these heuristics is higher than that of the FF heuristic. This finding provides an explanation as to why the other heuristics performed poorly within the given time and memory constraints when compared to the FF heuristic.

Figure \ref{FIG: states_expanded}(b) displays the trend of state expansion for abstraction heuristics compared to PDB-Man. The reason for selecting PDB-Man was to allow for an interesting comparison between Merge-and-Shrink (M\&S) and Pattern Database (PDBs) heuristics across different problem representations. It is observed that the state expansion trend for PDB-Man and PDB-Sys is identical, while M\&S performance varies depending on the representation used. Specifically, M\&S is found to expand more states than PDBs in the case of the SAS+ model, while in PDDL models, this is not the case. In fact, M\&S performs better in PDDL models, where it expands fewer states than PDBs. These results suggest that the choice of abstraction heuristic can have a significant impact on search algorithm performance, depending on the problem representation. Different abstraction heuristics may be better suited for different problem representations, emphasizing the need for careful evaluation to determine the most effective heuristic for each representation.

\subsubsection{Runtime and memory usage comparison:}
Figure \ref{FIG: memory_time} presents a comparison of the runtime and memory usage of all considered heuristics. Figure \ref{FIG: memory_time}(a) presents a comparison of the memory usage for all heuristics, plotted against the GC heuristic, which exhibits an evenly distributed memory usage pattern for problems with different difficulties among the considered heuristics. Similarly, Figure \ref{FIG: memory_time}(b) displays the runtime comparison for the considered heuristics, plotted against the LM-Cost heuristic for the SAS+ model and GC heuristic for PDDL models as they exhibit a comparatively better distribution of runtime across the problems of varying difficulty in the respective representations.

The following observations have been made from the comparison of runtime and memory usage of different heuristics and problem representations shown in Figure \ref{FIG: memory_time}.

%\begin{enumerate}
    %\item 
    \noindent 1. In the case of SAS+ models, the preprocessing time of pattern database (PDB) heuristics is higher and remains constant even for trivial tasks. However, this is not the case for PDDL models, where the preprocessing time does not exhibit a constant trend and takes significantly less time for trivial tasks. This observation highlights the impact of the problem representation on the preprocessing time of PDB heuristics.

    %\item 
    \noindent 2. The M\&S heuristic exhibits a higher runtime in PDDL models compared to SAS+ models, but the memory usage pattern remains similar across the representations. This is intriguing given that the bytes required to represent a single state are higher in PDDL models than in SAS+ models. The state expansion plots provided in Figure \ref{FIG: states_expanded} further support this observation, showing that M\&S heuristic expands more states in SAS+ representation than in PDDL.
    
    %\item 
    \noindent 3. In SAS+ representation, the preprocessing time of both M\&S and PDB-Man heuristics is similar. However, as the problem complexity increases, M\&S heuristic exhibits a higher search time compared to PDB-Man. This trend is evident in Figure \ref{FIG: memory_time}(b), where the constant line starts to ascend earlier for M\&S than for PDB-Man. These results suggest that while both heuristics may be suitable for simple problem instances, PDB-Man may offer better performance for more complex instances in SAS+ representation.
    
    %\item 
    \noindent 4. The runtime performance of the PDB-Sys heuristic is comparable to the blind heuristic, as both exhibit poor performance. This is supported by the runtime comparison plotted against PDB-Sys in the supplementary material.

    %\item 
    \noindent 5. In the case of PDDL, as the number of actions increases, the memory usage pattern for trivial tasks is found to be lesser for the PDB-Man heuristic. This suggests that PDB-Man is able to use its precomputed pattern database more effectively as the size of the planning problem increases. In contrast, for the FF heuristic, the memory usage pattern is found to be the reverse, indicating that as the size of the problem increases we find that there is an increase in the memory usage pattern.
    
       %\item 
    \noindent 6.  FF heuristic is the most efficient heuristic comparatively in terms of both runtime and memory usage across the representations. This explains the fact that the FF heuristic was able to solve the highest number of problems within the given time and memory budget.

    \noindent 7. For both SAS+ and PDDL representations, the runtime pattern of the causal graph and context-enhanced additive heuristics are similar. 
%\end{enumerate}


% The reason pattern databases performed much better in the SAS+ representation than in the PDDL representation, and were equally as effective as the FF heuristic, could be due to the fact that SAS+ models are more expressive than PDDL models, allowing for more compact and efficient representations of problems. In SAS+ representation, pattern databases are better able to capture the structure and relationships between different parts of the problem, which leads to more accurate and effective heuristics. Additionally, pattern databases are highly dependent on the quality of their heuristic function and can be highly sensitive to changes in the representation or search strategy used, which could explain why their performance varies across different models and datasets.When using PDDL representation, the preprocessing time for PDBs can be relatively fast because the language is high-level and declarative, which allows for more efficient computation of the patterns. However, when using SAS+ representation, the preprocessing time can be longer because the language is more explicit and requires the computation of many more states to generate the pattern.

% Both the considered test sets (d1, d2) have been evaluated with two RC PDDL models (m1, m2) using the 4 planner configurations (FastDownward with LM-Count, Scorpion with Merge \& Shrink, Scorpion with Max Manual PDB, Scorpion with Max Systematic PDB). The number of problem tasks solved for each experiment set is shown in Table \ref{tab:exp-results}. In terms of the number of solved tasks, it is found that the Scorpion with Merge \& Shrink planner configuration was most successful while using the RC PDDL model followed by the FastDownward with LM-Count. Both the Scorpion with Max Manual PDB and Scorpion with Max Systematic PDB stand at 3rd and 4th position in contrast to the SAS+ RC model's performance \cite{buchner2022comparison} where both Max Manual and Max Systematic PDBs are most successful heuristics in terms of the number of solved tasks. In \textbf{\em m2-d2} setting it is found that the M\&S heuristic outperforms the RC SAS+ model performance. 

% The results of the performance of the heuristics are shown in Figure \ref{FIG: exp_results}, where the x-axis represents the problem number with increasing complexity. Figure \ref{FIG: exp_results}(a) and Figure \ref{FIG: exp_results}(b) show the comparison of time and memory used by different heuristics to solve a given problem task. For the Max Systematic PDB heuristic, all the failed runs are due to time constraints. For all other planner configurations, the failed runs are due to memory limit.
\vspace{-0.2cm}
\subsection{Plan Optimality Analysis}

Table \ref{tab:exp-results} presents the performance of different planner configurations with various problem representations, including the number of problems solved and the percentage of optimal plans generated. Algorithm \ref{alg:opt} shows the methodology employed to evaluate the optimality of a given RC plan. This algorithm checks the actions sequences in the generated plan iteratively to determine whether any of the actions sequences are not optimal. In doing so, it checks if any consecutive actions in the current sequence can be replaced with a single action. The table also includes the performance of DeepCubeA on the considered datasets. It was found that DeepCubeA was able to solve all the problems in both datasets. However, the percentage of optimal plans generated by DeepCubeA are \textit{78.5\%} and \textit{18\%} for datasets \textit{d1} and \textit{d2}, respectively. The poor performance of DeepCubeA on dataset \textit{d2} can be attributed to the fact that DeepCubeA was trained with only 12 RC actions in its modeling\footnote[5]{The performance of DeepCubeA to generate optimal plans may increase if 18 RC actions were considered in the training phase. We followed the documentation and data provided in \cite{deepcubea-code} while training the model which has only 12 RC actions modeled.}, whereas the dataset has problem states generated considering 18 RC actions. Furthermore, the actions sequence generated by DeepCubeA for a problem instance in dataset \textit{d2} can be further simplified when considering the 18 RC actions set. For instance, if the RC is shuffled with action \textit{F2}, which is a 180 degree turn on the front face, DeepCubeA generates a plan of sequence (\textit{F}, \textit{F}), where these two actions can be combined into a single action \textit{F2}. This also explains why DeepCubeA has a higher percentage of optimal plans for dataset \textit{d1}. This is the same reason for the lower percentage of optimal plans in the case of dataset \textit{d2} tested with PDDL model \textit{m1}. We find that the percentage of optimal plans for RC increases as the number of actions modeled in the PDDL increases.

% \begin{algorithm}[H]
% \SetAlgoLined
% \KwIn{\textbf{Input:} currentFace, lastFace, secondToLastFace}\\
% \KwOut{\textbf{Output: True} if the sequence is not optimal, \textbf{False} otherwise}
% \If{currentFace = lastFace}{
% \Return True;
% }
% \EndIf
% \If{currentFace = secondToLastFace}{
% \If{(currentFace $\in$ {'F', 'B'}) and (lastFace $\in$ {'F', 'B'})}{
% \Return True;
% }
% \EndIf
% \If{(currentFace $\in$ {'L', 'R'}) and (lastFace $\in$ {'L', 'R'})}{
% \Return True;
% }
% \EndIf
% \If{(currentFace $\in$ {'U', 'D'}) and (lastFace $\in$ {'U', 'D'})}{
% \Return True;
% }
% \EndIf
% }\\
% \Return False;
% \caption{Check for Optimality}
% \end{algorithm}

\vspace{-0.2cm}
\begin{algorithm}[H]
\SetKwInOut{Input}{Input}
\SetKwInOut{Output}{Output}
\Input{current action face : $cf$, last action face : $lf$, second to last action face : $slf$}
\Output{\textbf{True}: \textit{not optimal}, \textbf{False}: \textit{optimal}}
\SetAlgoLined
\If{
cf = lf
}{
\Return True
}
\If{cf = slf}
{
\If{$((cf \in \{F, B\})$ \textbf{and} $(lf \in \{F, B\}))$  \textbf{or} \\ $((cf \in \{R, L\})$ \textbf{and} $(lf \in \{R, L\}))$ \textbf{or} \\ $((cf \in \{U, D\})$ \textbf{and} $(lf \in \{U, D\}))$ }{
\Return True
}
}
\Return False
\caption{Check Action Sequence Optimality}
\label{alg:opt}
\end{algorithm}

% \begin{algorithm}[H]
% \SetKwInOut{Input}{Input}
% \SetKwInOut{Output}{Output}
% \Input{current action face : $cf$, last action face : $lf$, second to last action face : $slf$}
% \Output{\textbf{True}: \textit{not optimal}, \textbf{False}: \textit{optimal}}
% \SetAlgoLined
% \If{
% cf = lf
% }{
% \Return True
% }
% \If{cf = slf}
% {
% \If{$(cf \in \{F, B\})$ \textbf{and} $(lf \in \{F, B\})$}{
% \Return True
% }
% \ElseIf{$(cf \in \{R, L\})$ \textbf{and} $(lf \in \{R, L\})$}{
% \Return True
% }
% \ElseIf{$(cf \in \{U, D\})$ \textbf{and} $(lf \in \{U, D\})$}{
% \Return True
% }
% }
% \Return False
% \caption{Check Action Sequence Optimality}
% \label{alg:opt}
% \end{algorithm}