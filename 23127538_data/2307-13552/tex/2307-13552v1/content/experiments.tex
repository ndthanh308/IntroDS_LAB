\section{Experiments}

\begin{table*}[!t]
\centering
\begin{tabular}{|l|cc|cc|c|}
\hline
\multirow{2}{*}{\textbf{Planner with Heuristic}}  & \multicolumn{2}{c|}{\textbf{d1}} & \multicolumn{3}{c|}{\textbf{d2}} \\ \cline{2-6} 
 & \multicolumn{1}{c|}{\textbf{m1}} & \multicolumn{1}{c|}{\textbf{m2}} & \multicolumn{1}{c|}{\textbf{m1}} & \multicolumn{1}{c|}{\textbf{m2}} & \multicolumn{1}{c|}{\textbf{SAS+\textsuperscript{*}}} \\ \hline

FastDownward with Blind & \multicolumn{1}{c|}{78 \textit{(96.15\%)}} & 67 \textit{(100\%)}& \multicolumn{1}{c|}{56 \textit{(39.39\%)}} & 65 \textit{(100\%)} & 66 \textit{(100\%)}\\ 

% FastDownward with Max & \multicolumn{1}{c|}{107} & - & \multicolumn{1}{c|}{-} & - & - \\ 

FastDownward with Causal Graph & \multicolumn{1}{c|}{96 \textit{(83.33\%)}} & 76 \textit{(100\%)} & \multicolumn{1}{c|}{72 \textit{(37.50\%)}} & 75 \textit{(100\%)} & 77 \textit{(100\%)} \\ 

FastDownward with Context-enhanced Additive & \multicolumn{1}{c|}{99 \textit{(87.87\%)}} & 71 \textit{(100\%)} & \multicolumn{1}{c|}{68 \textit{(48.53\%)}} & 75 \textit{(100\%)} & 77 \textit{(100\%)} \\ 

FastDownward with Goal count & \multicolumn{1}{c|}{103 \textit{(89.32\%)}} & 88 \textit{(100\%)} & \multicolumn{1}{c|}{75 \textit{(29.33\%)}} & 85 \textit{(100\%)} & 87 \textit{(100\%)} \\ 

FastDownward with LM-Cost Partitioning & \multicolumn{1}{c|}{103 \textit{(92.23\%)}} & 97 \textit{(100\%)} & \multicolumn{1}{c|}{75 \textit{(28\%)}} & 86 \textit{(100\%)} & 87 \textit{(100\%)} \\ 
 
\textbf{FastDownward with FF }& \multicolumn{1}{c|}{\textbf{137} \textit{(88.32\%)}} & \textbf{135} \textit{(100\%)} & \multicolumn{1}{c|}{\textbf{104} \textit{(21.15\%)}} & \textbf{113} \textit{(100\%)} & \textbf{123} \textit{(100\%)} \\ 

\hline
\hline
Scorpion with Merge \& Shrink & \multicolumn{1}{c|}{114 \textit{(88.60\%)}} & 105 \textit{(100\%)} & \multicolumn{1}{c|}{82 \textit{(25.61\%)}} & 95 \textit{(100\%)} & 90 \textit{(100\%)}\\
Scorpion with Max Manual PDB & \multicolumn{1}{c|}{95 \textit{(91.58\%)}} & 83 \textit{(100\%)} & \multicolumn{1}{c|}{64 \textit{(35.94\%)}} & 78 \textit{(100\%)} & 123 \textit{(100\%)} \\
Scorpion with Max Systematic PDB & \multicolumn{1}{c|}{88 \textit{(92.05\%)}} & 78 \textit{(100\%)} & \multicolumn{1}{c|}{63 \textit{(33.33\%)}} & 73 \textit{(100\%)} & 120 \textit{(100\%)} \\ 

\hline
\hline
DeepCubeA & \multicolumn{2}{c|}{200 \textit{(78.50\%)}} & \multicolumn{3}{c|}{200 \textit{(18\%)}}  \\ \hline
\end{tabular}
\caption{Comparison of planner configurations based on the total number of solved problems and the percentage of optimal plans for different Rubik's Cube models. (\textsuperscript{*}SAS+ dataset presented by \citet{buchner2022comparison})}
\label{tab:exp-results}
\end{table*}

In the following section, we will discuss the heuristics considered in our evaluation and the experimental setup, which includes the datasets, problem representations, and details about the planner.

% In the following sections, we will discuss about the experimental setup and the evaluation of different heuristics performances on the RC PDDL model. We use the Fast Downward planning system to evaluate the performance of different heuristics including abstraction heuristics which were studied in the recent literature. Fast Downward is a domain-independent classical planning system based on a heuristic search. Further, we describe the problem tasks we use to evaluate these heuristics performance on our RC PDDL model.

\subsection{Heuristics Considered}
% In this section, we briefly describe the heuristic specifications considered for our experiment.

% \subsubsection{Landmark Count Heuristic} 
% We use the Landmark Count (LM Count) heuristic \citep{richter2010lama} with RHW Landmarks \cite{richter2008landmarks} as they support conditional effects modeled in the domain and CPLEX solver. 

\subsubsection{Blind heuristic} 
Blind heuristic refers to a decision-making strategy that does not incorporate any specific information regarding the problem domain. It relies solely on the present state of the problem and employs a trial-and-error method to find a solution.
% It is a commonly used approach in the absence of domain-specific knowledge, where the problem is complex and cannot be solved using an analytical approach. While it may not always provide the optimal solution, it can help solve complex problems when other methods are not feasible.

\subsubsection{Causal Graph heuristic} This heuristic is predicated on a causal graph that delineates the causal relationships among the diverse variables in the problem. It is frequently employed in planning problems %quandaries 
where actions have intricate preconditions.

\subsubsection{Context-enhanced additive heuristic} Additive heuristic functions combine multiple heuristics to get a more accurate evaluation of a problem's solution space. Context-enhanced additive heuristics improve on this by incorporating the problem context into the heuristic estimates, leading to even more accurate evaluations.

\subsubsection{Goal Count heuristic} The goal count heuristic estimates the number of unsatisfied goals in a state, prioritizing states with fewer unsatisfied goals. This method is useful in problems with multiple goals, such as game playing and planning, and can improve the efficiency of finding a solution.

\subsubsection{LM cost partitioning heuristic} The partitioning heuristic estimates the cost of a plan by dividing the problem into subproblems and computing their costs separately. It's helpful when the goal can be broken down into subgoals.

\subsubsection{FF heuristic} 
The FF heuristic is a popular heuristic function in classical planning problems. It eliminates the preconditions of the actions in the problem, making it useful for finding feasible solutions.

\subsubsection{Merge and Shrink}
In the Merge and Shrink (M\&S) heuristic we use bisimulation as shrinking strategy \cite{nissim2011computing}, strongly connected components as merging strategy \cite{sievers2016analysis}, and exact label reduction \cite{sievers2014generalized}. We limit the abstractions to 50,000 states.
\subsubsection{Pattern Database Heuristics}
The key step in using Pattern Database (PDBs) heuristics is selecting appropriate patterns for the problem at hand. \citet{korf1997finding} specified two sets of patterns for solving the Rubik's Cube. We evaluate two settings of PDBs:

{\em \textbf{Max Manual PDB:}} Inspired by Korf's patterns, \citet{buchner2022comparison} have considered 2 patterns for the corner cube pieces and 3 patterns for the edge cube pieces resulting in 4 variables for each pattern. We have considered these patterns for the evaluation of PDDL and SAS+ models.

{\em \textbf{Max Systematic PDB:}} This configuration systematically generates all
interesting patterns up to a certain size \cite{pommerening2013getting}. A pattern size of 3 has been considered for this evaluation in the interest of memory constraints.


% \begin{table*}[t]
% \centering
% \begin{tabular}{|l|l|l|c|c|}
% \hline
% \textbf{Planner} & \textbf{Heuristic} & \textbf{Specifications} & \multicolumn{1}{l|}{\textbf{PDDL}} & \multicolumn{1}{l|}{\textbf{SAS+}*} \\ \hline
% Scorpion & Merge \& Shrink & \begin{tabular}[c]{@{}l@{}}Shrinking strategy: Bisimulation\\ Merging strategy: SCCS\\ Max abstraction states: 50,000\\ Exact label reduction\end{tabular} & 95 & 90 \\ \hline
% Fast Downward & LM Count & \begin{tabular}[c]{@{}l@{}}Solver: CPLEX\\ RHW Landmarks\end{tabular} & 84 & \textless{}NA\textgreater{} \\ \hline
% Scorpion & Max Manual PDB & \begin{tabular}[c]{@{}l@{}}Corner cubelets: 2 patterns\\ Edge cubelets: 3 patterns\\ Pattern: 4 variables\end{tabular} & 78 & 123 \\ \hline
% Scorpion & Max Systematic PDB & Max pattern size: 3 & 73 & 119 \\ \hline
% \end{tabular}
% \caption{Results (* \citet{buchner2022comparison})}
% \label{tab:exp-results}
% \end{table*}

% \subsection{Comparision of RC representations}
% ...
% \subsubsection{DeepCubeA}
% The DeepCubeA algorithm adopts a unidimensional array as a representation of the Rubik's Cube (RC) state. Specifically, this array encompasses 54 elements, each of which corresponds to a unique sticker color present on a cube piece of the RC. While this array-based modeling offers computational advantages, it is limited by its inability to fully encapsulate the spatial orientation of Rubik's Cube. Furthermore, the usage of a hard-coded representation and implicit assumptions concerning the position of cubelets poses a challenge to novice users seeking to comprehend the array-based representation.

% \subsubsection{PDDL}
% The PDDL representation of the Rubik's Cube consists of 8 corner cubies and 12 edge cubies. Each corner cubie is defined by its color on three sides, represented as a combination of Red (R), Blue (B), Green (G), Orange (O), White (W), and Yellow (Y). Each edge is defined by the two adjacent colors. This PDDL representation provides a more explicit and comprehensive way to represent the Rubik's Cube, including the spatial orientation of each cube piece.

% \subsubsection{SAS+}

\subsection{Experimental Setup}
To compare the performance of our RC PDDL model with the existing literature work, we have used the benchmark problem test set presented by \citet{buchner2022comparison}. In the benchmark test set, the problem tasks have been generated using 18 actions of RC - 12 actions correspond to 90-degree rotations of each face in clockwise and anti-clockwise directions, and the additional six actions are 180-degree rotation (suffix '2') on each face. The problem test set consists of 200 problems of varying difficulties. We have considered the scramble sequences provided to generate the respective PDDL versions of the problems. Additionally, we have generated our own test set of 200 RC problems considering only 12 actions. The problem generator starts from the goal state of RC and applies \textit{n} arbitrary actions from the list of 12 available actions. For every value of \textit{n}, ten unique random problem states are generated. The value of \textit{n} is between 1 and 20. The upper limit of 20 is chosen because the authors in \cite{rokicki2008twenty} state that all the RC problem instances can be solved with at-most 20 moves. It has been considered that every consecutive rotation corresponds to a different face of the RC, as such rotations can not be combined into a single rotation. 
% These 200 unique problem instances of RC have been used for the evaluation of our RC PDDL model.

% We now define the nomenclature of the problem test sets and encoding models considered for evaluation -
% \begin{itemize}
%     \item \textbf{\em d1} - 200 problem task data-set generated by considering 12 RC actions.
%     \item \textbf{\em d2} - 200 problem task data-set presented by \citet{buchner2022comparison}, generated using 18 RC actions.
%     \item \textbf{\em m1} - RC PDDL model with 12 RC actions.
%     \item \textbf{\em m2} - RC PDDL model with 18 RC actions.
% \end{itemize}

The main difference between the two datasets \textit{d1} and \textit{d2} is that a 180-degree turn (half-turn) is considered as two actions in generating dataset \textit{d1}, while it has been considered as a single action in generating dataset \textit{d2}. The reason for evaluating two different datasets is that we wanted to capture the performance difference between the two PDDL models \textit{m1} (12 actions) and \textit{m2} (18 actions) in accordance with the difference in the branching factor. The PDDL model \textit{m2} and SAS+ model have similar branching factors.

To evaluate the RC PDDL model, we have used Scorpion planner \cite{seipp2020saturated}, which is an extension of Fast-Downward planner \cite{helmert2006fast}. Scorpion planner contains the implementation for PDBs that support conditional effects modeled in the domain file. We perform A* searches with each heuristic mentioned above on the test sets and the two PDDL models. We bound the A* search with an overall time limit of 30 minutes and a memory limit of 3.5GB. This constraint is the same for the abstraction heuristics as well, despite the fact that these heuristics require significant time for preprocessing and generating abstractions prior to the start of the search.

% The generated test set of 200 problem instances have been tested with the above mentioned heuristics. We use A* search with all the 4 heuristics mentioned with a time limit of 30 minutes and memory limit of 3.5GB in our experiment setup. In terms of number of solved problems, Merge and Shrink heuristic performed the best by solving 113 problems while the LM Count heuristic was able to solve 103 problems followed by Max Systematic PDB with 84 problems solved and Max Manual PDB was able to solve 68 problems performing the worst among all. The results of the heuristics performance is shown in Figure \ref{FIG: exp_results} where the x-axis represents the problem instance number with increasing complexity. Figure \ref{FIG: exp_results}(a) and Figure \ref{FIG: exp_results}(b) shows the comparison of time and memory used by different heuristics to solve a given problem instance. In contrast to other situations, it has been found that all failed executions of the Merge and Shrink and Max Systematic PDB heuristics were caused by time constraints.

% Figure environment removed