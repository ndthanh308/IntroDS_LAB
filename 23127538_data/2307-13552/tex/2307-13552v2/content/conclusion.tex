
\section{Discussion and Conclusion}

% % Figure environment removed

% \textbf{Need to rewrite}

% \bs{Here are the main insights}

% \bs{Here is how the insights apply to solving larger RC problems: 6x6x6 or 3x3x3x3. }

In this study, we conducted an extensive comparison of planning-based and learning-based approaches to solve a complex combinatorial problem: the 3x3x3 RC. We evaluated the effectiveness of existing SAS+ and custom representations for RC, and introduced the first PDDL representation. We examined the capabilities of different heuristics for various representational configurations in solving RC. Our results indicate that a symbolic planner can benefit from using SAS+ representation, which offers a more compact state representation that is approximately $\sim$75\% more memory efficient than PDDL. However, a specific planner configuration could only solve 61.50\% of RC problems with 100\% optimality. In contrast, the DeepCubeA learning-based approach was able to solve 100\% of the problems sub-optimally (worst-case 18\%). However, the current custom representation used by DeepCubeA may have an impact on the optimal plan generation as it lacks any semantics representing RC. Based on our experimental insights, we note that using SAS+ representation to encode RC problems for DeepCubeA and learning PDBs instead of its current weighted A* search, may improve plan optimality ratio. We also note that while traditional planners generate higher optimal plans, they are limited to solving only 0.0001\% of the $4.3x10^{19}$ states of RC \cite{rokicki2014diameter}. However, DeepCubeA is able to solve for all possible states of 3x3x3 RC. Our study highlights the potential of both automated and learning-based planners, and suggests a unified approach that can generalize to higher-dimensional RC configurations while preserving the solving capabilities of a learned approach and the optimality of a traditional planner.

% In this work, we have performed an extensive comparison of planning-based and learning-based approaches to solve a complex combinatorial problem, i.e., 3x3x3 RC. In addition to existing SAS+ and custom representations for RC, we have introduced the first PDDL representation. We also discuss the capabilities of different heuristics for various representational configurations in solving RC. We identify that a symbolic planner can benefit by using SAS+ representation to solve a complex combinatorial problem owing to its compact state representation, which is $\sim$75\% memory efficient than PDDL. However, a specific planner configuration could at best solve only 61.50\% of RC problems with 100\% of the generated plans being optimal, whereas, DeepCubeA could solve 100\% of the problems sub-optimally (18\% at worst). The current custom representation followed for DeepCubeA might have an effect on the optimal plan generation as they lack any semantics representing RC. From our experimental insights, we see a motivation to use SAS+ representation to encode the RC problems for DeepCube, and learn PDBs as a heuristic function instead of its current weighted A\textsuperscript{*} search in order to achieve a better optimal percentage of the generated plans. It also to be noted that even though a traditional planner generates higher optimal plans, it is restricted to solve only $0.0001\%$ out of the $4.3x10^{19}$ states of RC \cite{rokicki2014diameter} whereas DeepCubeA can completely solve the RC. In this work, we realized the potential of both automated planners and learning-based planners and would like to play to their benefits by exploring a unified approach, which would generalize to higher dimensional RC configurations, preserving the solving capabilities of a learnt approach and optimality of a traditional planner.

% demonstrated the capability of a planner to solve a complex puzzle, i.e., 3x3x3 Rubik's Cube. To realize this, we have created the first PDDL domain for RC. We also perform a comparative study of two representations of the RC models and report the qualitative results obtained with various heuristics. Additionally, we performed a preliminary experiment by comparing the planning \textit{vs} a learning-based approach for RC (DeepCubeA). The results of our experiments demonstrate that the performance of abstraction heuristics is strongly influenced by the choice of problem representation. Certain heuristics may not be effective in specific problem domains, such as CG and CEA in Rubik's Cube, where preconditions aren't modeled and causal relationships among variables and actions are not complex. Alternative heuristics based on abstractions or landmark heuristics may be more effective. Additionally, our analysis has revealed that the generation of optimal plans in Rubik's Cube domain is closely tied to the number of actions that are modeled in the problem domain. This underscores the importance of conducting a thorough analysis of the problem domain and selecting an appropriate heuristic function for each specific problem instance. Additionally, it highlights the need to consider multiple heuristics and possibly employ a heuristic selection mechanism that can choose the best heuristic for each problem instance. By doing so, we can improve the efficiency and effectiveness of the search algorithm and obtain better solutions in a more timely manner.