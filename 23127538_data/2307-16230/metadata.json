{
  "title": "An Unforgeable Publicly Verifiable Watermark for Large Language Models",
  "authors": [
    "Aiwei Liu",
    "Leyi Pan",
    "Xuming Hu",
    "Shu'ang Li",
    "Lijie Wen",
    "Irwin King",
    "Philip S. Yu"
  ],
  "submission_date": "2023-07-30T13:43:27+00:00",
  "revised_dates": [
    "2023-08-02T09:11:22+00:00",
    "2023-10-07T10:04:26+00:00",
    "2023-12-11T10:48:52+00:00",
    "2024-02-29T14:01:28+00:00",
    "2024-05-19T12:22:32+00:00",
    "2024-05-26T05:22:38+00:00"
  ],
  "abstract": "Recently, text watermarking algorithms for large language models (LLMs) have been proposed to mitigate the potential harms of text generated by LLMs, including fake news and copyright issues. However, current watermark detection algorithms require the secret key used in the watermark generation process, making them susceptible to security breaches and counterfeiting during public detection. To address this limitation, we propose an unforgeable publicly verifiable watermark algorithm named UPV that uses two different neural networks for watermark generation and detection, instead of using the same key at both stages. Meanwhile, the token embedding parameters are shared between the generation and detection networks, which makes the detection network achieve a high accuracy very efficiently. Experiments demonstrate that our algorithm attains high detection accuracy and computational efficiency through neural networks. Subsequent analysis confirms the high complexity involved in forging the watermark from the detection network. Our code is available at \\href{https://github.com/THU-BPM/unforgeable_watermark}{https://github.com/THU-BPM/unforgeable\\_watermark}. Additionally, our algorithm could also be accessed through MarkLLM \\citep{pan2024markllm} \\footnote{https://github.com/THU-BPM/MarkLLM}.",
  "categories": [
    "cs.CL"
  ],
  "primary_category": "cs.CL",
  "doi": null,
  "journal_ref": null,
  "arxiv_id": "2307.16230",
  "pdf_url": "https://arxiv.org/pdf/2307.16230v7",
  "comment": "ICLR2024, 17 pages, 5 figures, 8 tables",
  "num_versions": null,
  "size_before_bytes": 3212709,
  "size_after_bytes": 1283168
}