
\documentclass{article} % For LaTeX2e
\usepackage{iclr2024_conference,times}

% Optional math commands from https://github.com/goodfeli/dlbook_notation.
\input{math_commands.tex}

\usepackage{amsmath}
\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{xcolor}         % colors
\usepackage{graphicx}    
\usepackage{multirow}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{subfigure}
\usepackage{float}
\usepackage{tabularx}
\usepackage{placeins}
\usepackage{makecell}


\title{A Private Watermark for Large Language \\ Models}

% Authors must not appear in the submitted version. They should be hidden
% as long as the \iclrfinalcopy macro remains commented out below.
% Non-anonymous submissions will be rejected without review.

\author{
Aiwei Liu\textsuperscript{1},
~~~ Leyi Pan\textsuperscript{1},
~~~ Xuming Hu\textsuperscript{1},
~~~ \bf{Shu'ang Li}\textsuperscript{1},
~~~ \bf{Lijie Wen}\textsuperscript{1}, \\
~~~ \bf{Irwin King}\textsuperscript{2},
~~~ \bf{Philip S. Yu}\textsuperscript{3}\\
\textsuperscript{1}Tsinghua University~~~
\textsuperscript{2}The Chinese University of Hong Kong~~~\\
\textsuperscript{3}University of Illinois at Chicago~~~\\
{\tt\small liuaw20@mails.tsinghua.edu.cn, wenlj@tsinghua.edu.cn,}
{\tt\small  king@cse.cuhk.edu.hk}
}

% The \author macro works with any number of authors. There are two commands
% used to separate the names and addresses of multiple authors: \And and \AND.
%
% Using \And between authors leaves it to \LaTeX{} to determine where to break
% the lines. Using \AND forces a linebreak at that point. So, if \LaTeX{}
% puts 3 of 4 authors names on the first line, and the last on the second
% line, try using \AND instead of \And before the third author name.

\newcommand{\fix}{\marginpar{FIX}}
\newcommand{\new}{\marginpar{NEW}}

\iclrfinalcopy % Uncomment for camera-ready version, but NOT for submission.
\begin{document}


\maketitle

\begin{abstract}
Recently, text watermarking algorithms for large language models (LLMs) have been proposed to mitigate the potential harms of text generated by LLMs, including fake news and copyright issues. However, current watermark detection algorithms require the secret key used in the watermark generation process, making them susceptible to security breaches and counterfeiting.
To address this limitation, we propose the first private watermarking algorithm that uses two different neural networks for watermark generation and detection, instead of using the same key at both stages. Meanwhile, the token embedding parameters are shared between the generation and detection networks, which makes the detection network achieve a high accuracy very efficiently.
Experiments demonstrate that Our algorithm attains high detection accuracy and computational efficiency through neural networks with a minimized number of parameters. Subsequent analysis confirms the high complexity involved in reverse-engineering the watermark generation algorithms from the detection network.   Our code and data are available at \href{https://github.com/THU-BPM/private_watermark}{https://github.com/THU-BPM/private\_watermark}.
%  Recently, text watermarking algorithms for large language models (LLMs) have been mitigating the potential harms of text generated by the LLMs, including fake news and copyright issues. However, the watermark detection of current algorithms requires the key from the watermark generation process, making them susceptible to breaches and counterfeiting.
% In this work, we propose the first private watermarking algorithm, which extends the current text watermarking algorithms by using two different neural networks respectively for watermark generation and detection, rather than using the same key at both stages. Meanwhile, part of the parameters of the watermark generation and detection networks are shared, which makes the detection network achieve a high accuracy very efficiently.
% Experiments show that our algorithm ensures high detection accuracy with minimal impact on generation and detection speed, due to the small parameter size of both networks. Additionally, our subsequent analysis demonstrates the difficulty of reverting the watermark generation rules from the detection network.
\end{abstract}

\section{Introduction}

With the development of current large language models (LLMs), many LLMs, like GPT-4 \citep{openai2023gpt4} and Claude\footnote{https://claude.ai/chat}, could rapidly generate human-like texts. This has led to numerous risks, such as the generation of a vast amount of false information on the Internet \citep{pan2023risk}, and the infringement of copyrights of creative works \citep{chen2023pathway}. Therefore, texts generated by LLMs need to be detected and tagged.

At present, some watermarking algorithms for LLM have proved successful in making machine-generated texts detectable by adding implicit features during the text generation process that are difficult for humans to discover but easily detected by the specially designed method  \citep{christ2023undetectable, kirchenbauer2023watermark}. However, current watermarking algorithms are all public, which means the detection of watermarks requires the key from the watermark generation process. This allows attackers to easily remove and forge the text watermarks with these public keys. Although \citet{kirchenbauer2023watermark}  have suggested that the watermark detection process could be placed behind the web API to achieve the effect of private watermarking, this approach requires substantial server resources and robust designs against hacking (even social engineering). Additionally, the server-based detection process inherently poses data privacy risks. A watermarking algorithm that obfuscates the generation key during detection could substantially ameliorate these challenges.


In this work, we propose the first private watermarking algorithm for large language models (LLMs). Our approach adopts the commonly used watermark schema, which embeds small watermark signals into LLM's logits during generation \cite{kirchenbauer2023watermark,zhao2023provable}. The key difference is that we implement watermarking in a privacy-preserving manner. To conceal the details of the watermark in the detection process, we propose using two separate neural networks for watermark generation and detection, rather than relying on the same secret key for both stages. The privacy of our algorithm stems from a computational asymmetry: constructing a watermark generation network from a watermark detection network is notably more complex than the reverse process (Section \ref{sec:ana}). 
To enhance the accuracy of the detection network while alleviating the complexity of the training process, we have shared the token embedding parameters between the detector and the generator. This provides some prior information to the detector while maintaining privacy. Specifically, our watermark generator takes a window of $w$ tokens as input and predicts the watermark signals of the last token. The text detector directly takes all tokens from the text as input and outputs whether the complete text contains the watermark.

% In this work, we propose the first private watermark algorithm for LLMs. Our work is built on the common watermark paradigm, which adds small watermark logits to the LLM's logits \cite{kirchenbauer2023watermark,zhao2023provable}. The difference is we implement these concepts in a private way. In order to hide the detail of the watermark generation method during the detection process, we propose two separate neural networks for watermark generation and detection instead of using the same key for both stages. The privacy of our algorithm derives from the black-box nature of neural networks, that is, it's nearly impossible to infer the watermark generation detail from the parameters of the detection network. Also, we analyze the difficulty of reverting watermarking generation detail from the output of the detection network in section \ref{sec:ana}.
% However, in practice, training such a detection network from scratch requires a vast amount of data, and achieving a high accuracy is challenging due to the complexity of the problem. Therefore, we also propose a neural network for the watermark generation process.  To achieve a high-accuracy detection network with relatively small data,  we share the token embedding layers between the watermark generation network and the watermark detection network, which essentially provides some prior information to the detection network.
% Specifically, our watermark generation network takes the input of $w$ (local window size) tokens  and outputs whether the last token belongs to the green list, which differs from the origin method \cite{kirchenbauer2023watermark} of 
% splitting the vocabulary into the green and red list based on the local window text's hash value and the secret key. Meanwhile, the text detection network directly inputs all the token lists from the text, with the output being a classification indicating whether the entire text contains the watermark added by the generation network.

% While constructing the training data for the watermark detection network, the presence of the watermark is also determined by considering the labels (red or green) of the first `window size - 1' tokens. These labels are generated by treating the text as a cyclic document connected from head to tail. In this way, we prevent attackers from easily deducing the watermarking rule by continually altering the last token and observing the output changes.

% Figure environment removed

% In our experiments, we demonstrate that the watermark detection algorithm could achieve a nearly 99\% detection accuracy rate, which is only marginally inferior to the public watermark algorithm. Given that the detection accuracy of the public watermark algorithm represents our theoretical upper bound, this is already a remarkable result. Moreover, because the amount of parameters of our watermark generation and detection network is negligible compared to the large language model, it brings almost no additional computation burden to the text generation process.  Subsequent experiments also illustrate the critical importance of sharing the token embedding layer between the generation and detection networks.

In our experiments, the watermark detection algorithm exhibited a detection performance almost identical to our theoretical upper bound, represented by the public watermark algorithm, with a nearly 99\% F1 score.
% In our experiments, we found that the watermark detection algorithm achieves a detection F1 score of nearly 99\%, only slightly below that of the public watermark algorithm, which serves as our theoretical upper bound.
Notably, the computational burden of our watermark generation and detection network is minimal, especially when compared to large language models, due to its significantly lower parameter count. Furthermore, we have demonstrated the difficulty of cracking the watermarking rules through detailed experiments. We find that both attacking strategies, employing a detector to construct training data for the generator training and using word frequency analysis, yield exceedingly low rates of successful decryption in scenarios where the window size is not exceptionally small.

The main contributions of this work can be summarized as follows:

\begin{itemize}
\item Introduction of a novel private watermark algorithm that employs separate neural networks for watermark generation and detection, enhancing resistance to erasure and counterfeiting.

\item Utilization of shared token embedding between the watermark generation and detection networks, thereby improving the efficiency of training the detector.

\item Through empirical analysis, we have demonstrated that our watermarking algorithm are highly resistant to decryption.
\end{itemize}

\section{Related work}

As large language models (LLMs) generate increasingly high-quality text, detecting and tagging machine-generated content grows more vital. Currently, there are two primary methods for identifying LLM-produced text: text watermarking and classifier-based detection. With watermarking, implicit features are incorporated into the text during generation, allowing specially designed techniques to identify marked passages. Classifier-based detection leaves text generation unchanged and uses classifiers trained to differentiate machine-from human-authored content. This excerpt will focus on introducing these two approaches separately.

% Current classifier-based detection methods usually directly employ a binary classification model. \citet{zhan2023g3detector} utilized generation text from GPT2 \citep{radford2019language}, BART \citep{lewis2019bart}, and GPT3.5-turbo \footnote{https://chat.openai.com} to fine-tune the \textit{Roberta-large} \citep{liu1907roberta} model, resulting in a highly accurate GPT text detector. Similarly, \citet{mireshghallah2023smaller} discovered that smaller language models perform well for the detection of machine-generated text.
% In an effort to improve the robustness of detection algorithms, \citet{su2023detectllm} incorporated log-rank information from language models into the detector as a crucial feature. Meanwhile, \citet{hu2023radar} introduced a paraphraser and utilized adversarial learning to enhance robustness.
% To distinguish text from more LLMs, \cite{wu2023llmdet} utilized the prior information of the model's next-token probabilities to design a better detection model. However, whether machine-generated text can fundamentally be detected remains an open question. \citet{chakraborty2023possibilities} believe that with enough data collection, it is possible to train a good detector. On the contrary, \cite{sadasivan2023can} argue that as language models become more complex and the distance between human and AI-generated text decreases, the optimal detector's performance may be only slightly better than a random classifier.
% In conclusion, some classifier-based detection methods can achieve impressive results. However, due to their limited explainability, their performance in real-world scenarios may be still doubted.

Recent work has explored classifier-based approaches for detecting machine-generated text. These methods typically fine-tune large pre-trained language models like GPT-2 \citep{radford2019language}, BART\citep{lewis2019bart}, and RoBERTa \citep{liu1907roberta} for binary text classification \citep{zhan2023g3detector, mireshghallah2023smaller}. To improve model robustness, some methods incorporate language model features \citep{su2023detectllm} or adversarial training \citep{hu2023radar}. However, the fundamental detectability of machine-generated text remains an open question. Some argue that with sufficient data collection, high-performing detectors are achievable \citep{chakraborty2023possibilities}. Others contend that as language models become more advanced, the performance gap between detectors and random classifiers may diminish \citep{sadasivan2023can}. While current classifiers can be highly accurate, their real-world effectiveness is uncertain due to their limited explainability. In summary, classifier-based detection shows promise but requires further research to address robustness, explanability, and theoretical detectability limits.

Compared to the classifier-based methods, text watermarking is more explainable due to the injected implicit features in the text. There are typically two categories of text watermarking methods. The first is to add a watermark to the existing text. For example, \citet{abdelnabi2021adversarial} designed a data-hiding network to embed watermark information in the text, and utilized a data-revealing network to recover the embedded information. \citet{yoo2023robust} injected the watermark by substituting some words in the text. However, adding a watermark to the existing text struggles to keep the semantics of the text unchanged which limits its use in real-world scenarios. Another line of methods is injecting the watermark during the text decoding process. \citet{christ2023undetectable} used a pre-selected value sequence to sample the tokens and subsequently detected the watermark by observing the correlation between the preset pseudorandom numbers and the generated tokens. The work of \cite{kuditipudi2023robust} introduced Levenshtein distance to measure the distance between generated text and random number sequences, improving the robustness of watermarks. \citet{kirchenbauer2023watermark} divided the vocabulary into red and green lists and preferred to generate tokens from the green list.  \citet{zhao2023provable} enhanced the robustness of this approach by using a global fixed red-green vocabulary. \citet{lee2023wrote} designed a watermarking method for low-entropy code generation scenarios. However, the above methods are all public, which means the key used to generate the watermark is required during detection. This makes the watermark susceptible to removal and counterfeiting. In this work, we propose the first private watermarking method for LLM to alleviate these issues.





% % Figure environment removed

\section{Problem definition}


To facilitate subsequent discussions, this section introduces the key concepts used in this work: language models and the watermarking algorithm.
% \textbf{A language model} $\mathcal{M}$ is essentially a function for the next token prediction, which is typically implemented using neural networks. Given an input sequence $\boldsymbol{x} = [x_0,....,x_{n-1}]$, it outputs the probability of the next token $\textbf{P}(x_n)$ over the vocabulary $\mathcal{V}$: $\textbf{P}(x_n)=\mathcal{M}(x_n |\boldsymbol{x}_{1:n-1})$. The next token to be generated is then selected from this probability distribution, which can be achieved through sampling decode, choosing the token with the highest probability (greedy decode), or using other decode algorithms such as beam search to select a list of tokens with the highest probability.

% \textbf{A  watermarking algorithm} is the combination of two interconnected algorithms: the watermark generation algorithm and the watermark detection algorithm.
% \begin{itemize}
%     \item \textbf{Watermark Generation}: This can be seen as a subtle modification to a language model's probability distribution. If $\hat{\mathcal{M}}$ denotes a watermarked language model, the token prediction probability is expressed as 
% $ {\bf p}_n:=P_{\hat{\mathcal{M}}(\boldsymbol{x})}[ x_n = \cdot | \boldsymbol{x}_{1:n-1} ]. $
%     \item \textbf{Watermark detection:} This algorithm takes a text sequence $\boldsymbol{x} = [x_0, \dots, x_{n}]$ and determines the presence of a watermark. There's a one-to-one correspondence between the watermark detection model, denoted as ${\sf Detect}$, and the watermarked language model $\hat{\mathcal{M}}$.
% \end{itemize}
\textbf{Language Model:} A language model, denoted by $\mathcal{M}$, is fundamentally a function for predicting the next token in a sequence. Typically realized through neural networks, $\mathcal{M}$ takes an input sequence $\vx = [x_0, \ldots, x_{n-1}]$ and produces the probability distribution $P_n$ over a vocabulary set $\mathcal{V}$. Formally, we have $P_n = \mathcal{M}(\vx_{0:n-1})$. The subsequent token is selected from this distribution, either via sampling methods, greedy decoding, or alternative decoding algorithms such as beam search.

\textbf{Watermarking Algorithm:} This construct comprises two synergistic algorithms—the watermark generation algorithm and the watermark detection algorithm.
\begin{itemize}
    \item \textbf{Watermark Generation:} This can be seen as a subtle modification to a language model's probability distribution. If $\hat{\mathcal{M}}$ denotes a watermarked language model, the token prediction probability is expressed as: $\hat{P}_n := \hat{\mathcal{M}}(\boldsymbol{x}_{0:n-1})$.
    \item \textbf{Watermark Detection:} This algorithm takes a text sequence $\boldsymbol{x} = [x_0, \dots, x_{n}]$ and determines the presence of a watermark. There's a one-to-one correspondence between the watermark detection model, denoted as $\mathcal{D}$, and the watermarked language model $\hat{\mathcal{M}}$.
\end{itemize}

\section{Proposed Method}

This section provides a detailed description of our private watermark algorithm. The watermarked LLM decoding step is first explained (Section \ref{sec:step}). We then detail the watermark generation network (Section \ref{sec:generate}) and principles of watermark detection (Section \ref{sec:detect}). Next, we describe the detection network (Section \ref{sec:net}). Finally, we analyze the privacy of the algorithm (Section \ref{sec:ana}).

\subsection{Watermarked Large Language Model}
\label{sec:step}

% Algorithm \ref{alg:wm} outlines the process for generating watermarked text using a target language model $\mathcal{M}$. Given input $vx = [x_0....x_{n-1}]$, $\mathcal{M}$ generates logit scores $P(x_n)$ for the next token. The top $K$ tokens based on the probability are input to the watermark generation network $\mathcal{W}$, which determines the watermarked token set $G$. The probabilities of tokens in $G$ are increased by $\delta$, while others remain unchanged. The modified logits form the output of the watermarked model $\hat{\mathcal{M}}$.

Algorithm \ref{alg:wm} describes how to generate watermarked text with a target language model $\mathcal{M}$. Given an input sequence $\vx = [x_0, \ldots, x_{n-1}]$, $\mathcal{M}$ produces logit scores $P_n$ for the next token. Afterwards, the candidate tokens will be processed by the watermark generation network $\mathcal{W}$ to produce the watermarked token set G.  Logit scores for tokens in $G$ are incremented by $\delta$, while others remain unchanged, forming the logits of the modified model $\hat{\mathcal{M}}$.

Not all tokens in the logits are labeled during each generation step. In the case of top-$K$ sampling, only the highest-ranking $K$ tokens are tagged. During beam search with a beam size of $B$, tokens are labeled only if their scores surpass the $B$th highest score $S_B$ by a margin of $\delta$, formally defined as $\{x_i \in \mathcal{V} \mid P_n^{(i)} > S_B - \delta \}$. Due to that our watermark generation network could compute token labels in batches and with its minimal parameter size, even with a large K (e.g. all vocabulary), computations can be conducted swiftly. A more detailed analysis is provided in the appendix.

% Note that not all tokens require labeling by $\mathcal{W}$ during generation. With top-$K$ sampling, only the top $K$ tokens are tagged. For beam search with beam size $B$, tokens with scores exceeding the $B$th largest score $S_B$ by $\delta$ are tagged: $\mathbf{x}_n^{B} = { x_i \in \mathcal{V} \mid P(x_n)^{(i)} > S_B - \delta } $.


\begin{algorithm}[tbh]
   \caption{Watermark Generation Step}
   \label{alg:wm}
\begin{algorithmic}[1]
   \STATE {\bfseries Input:}  Watermark generation network: $\mathcal{W}$.
 Fixed integer: $K$.  Watermark strength: $\delta$. Language model: $\mathcal{M}$.  Previously generated text sequence: $\vx = [x_0, \ldots, x_{n-1}]$.  Local window size: $w$.
   \STATE Compute logits $P_n$ of token $x_n$ given $\vx_{0:n-1}$: $P_n =\mathcal{M}(\vx_{0:n-1})$.
   \STATE Extract the top-$K$ tokens from logits, denoting them as $\vx_n^K = \textsf{topK}(P_n)$.
   \STATE Initialize sequence matrix $\mathbf{S}$ where each row corresponds to the sequence $[x_{n-w+1},\ldots,x_n^{(i)}]$ for every $x_n^{(i)} \in \vx_n^K$.
   \STATE Calculate the watermark result $\vr = \mathcal{W}(\mathbf{S})$, where each entry $\vr_i$ is 0 ($x_n^{(i)}$ is not watermarked) or 1 ($x_n^{(i)}$ is watermarked).
   \STATE Generate the watermarked token set $G$ containing items with value 1 in $\mathbf{\vr}$: $G = \{x_n^{(i)} | \vr_i = 1\}$.
   \STATE Construct an augmented language model $\hat{\mathcal{M}}$ such that for an input sequence $\vx = [x_0, \ldots, x_{n-1}]$, the adjusted logits are:
   \[
   \hat{\mathcal{M}}(\vx_{0:n-1})^{(i)} = \mathcal{M}(\vx_{0:n-1})^{(i)} + \delta \mathbf{1}(i \in G),
   \]
where $\mathbf{1}(\cdot)$ is an indicator function: it returns 1 if $i \in G$ and 0 otherwise.
   \STATE {\bfseries Output:} Modified language model $\hat{\mathcal{M}}$.
\end{algorithmic}
\end{algorithm}


% \begin{algorithm}[tbh]
%    \caption{Watermark Generation Step (Top K sampling)}
%    \label{alg:wm}
% \begin{algorithmic}[1]
%    \STATE {\bfseries Input:} Watermark generation network $\mathcal{W}$, fixed integer $K$, watermark strength $\delta$, language model $\mathcal{M}$, previously generated text sequence $\vx = [x_0, \ldots, x_{n-1}]$, local window size $w$.
%    \STATE Compute the logits $P_n$ for token $x_n$ conditioned on $\vx_{0:n-1}$: $P_n =\mathcal{M}(x_n |\vx_{0:n-1})$.
%    \STATE Obtain the top-$K$ tokens in logits, denoted as $\vx_n^K = \textsf{topK}(P_n)$.
%    \FOR{$x_n^{(i)} \in \vx_n^K$}
%    \IF{$\mathcal{W}([x_{n-w+1},\ldots,x_n^{(i)}]) = 1$}
%     \STATE  Include token $x_n^{(i)}$ in the watermarked token set $G$.
%     \ENDIF
%    \ENDFOR
%    \STATE  Construct a new language model $\hat{\mathcal{M}}$ such that for an input sequence $\vx = [x_0, \ldots, x_{n-1}]$, the modified logits are given by:
%    $$\hat{\mathcal{M}}(x_n |\vx_{0:n-1})^{(i)} = \mathcal{M}(x_n |\vx_{0:n-1})^{(i)} + \delta \mathbf{1}(i \in G),$$
% where $\mathbf{1}(\cdot)$ is an indicator function that returns 1 if $i \in G$ and 0 otherwise.
%    \STATE {\bfseries Output:} Watermarked language model $\hat{\mathcal{M}}$.
% \end{algorithmic}
% \begin{algorithmic}[1]
%    \STATE {\bfseries Input:} a watermark generation network $\mathcal{W}$, a fixed number $K$, watermark strength $\delta$, a language model $\mathcal{M}$, previous generated text $vx = [x_0....x_{n-1}]$, local window size $w$.
%    \STATE Generate the token logits of $x_n$: $P_n =\mathcal{M}(x_n |\boldsymbol{x}_{1:n-1})$.\\
%    \STATE Get the top K tokens in logits $\vx_n^K = \sf{topK}$$(P(x_n))$.\\
%    \FOR{$x_{n}^{(i)}$ $\in$ $\vx_n^K$}
%    \IF{$\mathcal{W}([x_{n-w+1},...,x_{n}^{(i)}]) = 1$}
%     \STATE  Add the token $x_{n}^{(i)}$ to the watermarked token set $G$.
%     \ENDIF
%    \ENDFOR
% \STATE  Define a new language model $\hat{\mathcal{M}}$ where given input $\boldsymbol{x} = [x_0....x_{n-1}]$, the resulting logits satisfy $$\hat{\mathcal{M}}(x_n |\boldsymbol{x}_{1:n-1})^{(i)} := \mathcal{M}(x_n |\boldsymbol{x}_{1:n-1})^{(i)} + \delta \mathbf{1}(i\in G),$$
% where $\mathbf{1}(\cdot)$ is the indicator function that returns 1 if $i \in G$ and 0 otherwise.
%    \STATE {\bfseries Output:} Watermarked language model $\hat{\mathcal{M}}$.
% \end{algorithmic}
% \end{algorithm}

\subsection{Watermark Generation Network}

\label{sec:generate}

The watermark generation network's architecture is depicted in the middle part of Figure \ref{fig:intro}. The shared embedding network, denoted as $E$, first generates the embedding for each input token. Subsequently, embeddings from a local window $w$ are concatenated and processed by the fully connected classification network to ascertain if the last token in the watermarked token set:

% The structure of our watermark generation network is illustrated in the middle part of figure \ref{fig:intro}. The embedding of each input token is first generated by the shared embedding network $\mathbf{E}$.
% Then, the embeddings within a local window $w$ are concatenated and fed into the subsequent full connected classification network to determine if the last token belongs to the watermarked token set:

\begin{equation}
    \mathcal{W}(\boldsymbol{x}_{n-w+1:n}) = \text{FFN}(\mathrm{E}(x_{n-w+1})\oplus \mathrm{E}(x_{n-w+2})\oplus ....\oplus\mathrm{E}(x_n)).
\end{equation}

The embedding network accepts the binary representation of token IDs as input. The required number of encoding bits is contingent upon the vocabulary size. For instance, GPT2 \cite{radford2019language} has a vocabulary size $|\mathcal{V}|$ of 50,000, requiring 16 bits for its binary representation. 

% The embedding network is a fully connected network and its input is the binary representation of token IDs, where the number of encoding bits depends on the size of the vocabulary. For example, GPT2 \cite{radford2019language} has a vocabulary size $|\mathcal{V}|$ of 50,000, which requires 16 bits for its vocabulary representation. Common language models typically require bits between 15 and 17 for binary vocabulary representations.

For effective watermark detection, it's imperative that the proportion of watermarked tokens generated by the generation network remains invariant. Specifically, for any local window  $[x_{n-w+1}, \ldots, x_{n}]$, the probability that $x_n$ belongs to the watermarked token set should consistently be \( \gamma \):
% To facilitate the subsequent watermark detection, the proportion of the watermarked token set generated by the watermark generation network requires to remain constant.  Specifically, for any local window prefix $[x_{n-w+1}, \ldots, x_{n-1}]$, the probability of $x_n$ belongs to the watermarked token set is always a fixed value $\gamma$:
\begin{equation}
    \forall [x_{n-w+1}, \ldots, x_{n-1}], P(\mathcal{W}([x_{n-w+1}, \ldots, x_{n-1}, x_n]) = 1) = \gamma,
\end{equation}

where the $\gamma$ has the same meaning as the green list ratio in the previous public watermark algorithms \cite{kirchenbauer2023watermark, zhao2023provable}.
% However, due to the black-box nature of neural networks, it is challenging to get a fixed ratio by pre-defined parameters. We achieve this by constructing a training dataset strictly with the desired proportion $\gamma$. It's worth noting that this method does not guarantee that the ratio of green to red will be strictly the same under every local window. Still, the expected value of this ratio is $\gamma$, and there is also a standard deviation $\sigma$. We will show the standard deviation $\sigma$ only has a very slight impact on the final detection process in the following section \ref{sec:detect}.

Due to the inherent complexity of neural networks, maintaining a static ratio via predefined parameters is non-trivial. We address this challenge by curating a training dataset maintaining the precise proportion \( \gamma \). This approach guarantees an expected watermarked token ratio \(\gamma\) with standard deviation \(\sigma\). Section \ref{sec:detect} shows the minimal influence of \(\sigma\) on the detection.

\subsection{Watermark Detection}
\label{sec:detect}

In this section, we introduce how to detect a given watermark using the z-value test. 
Given a vocabulary partitioned into watermarked and non-watermarked tokens based on a fixed ratio, $\gamma$, the expected number of tokens from the watermarked set in a standard text of length $T$ is $\gamma T$, with a variance of $\gamma (1-\gamma)T$. Using the z-value test method as proposed by \citet{kirchenbauer2023watermark},  we reject the null hypothesis and detect the watermark in text if the z-score below surpasses a threshold:
\begin{align} 
z = (|s|_G - \gamma T)/\sqrt{T\gamma(1-\gamma)}.
\end{align}
However, as discussed previously, our watermark generation network does not ensure a constant ratio  $\gamma$. Instead, a ratio $\hat{\gamma}$ is achieved with an expected value $\gamma$ and a standard deviation $\sigma$. This necessitates a modification of the earlier formula. While the expected count of the green tokens remains $\gamma T $, the variance must be adjusted. Utilizing the law of total variance, the updated variance can be expressed as:
\begin{align} 
Var(\gamma T) = E[Var(\gamma T|\gamma)] + Var(E[\gamma T|\gamma]) = \gamma (1-\gamma)T + \sigma^2  T, 
\end{align}
and the new z-score could be calculated as follows:
\begin{align} 
\label{new-z}
z = (|s|_G - \gamma T)/\sqrt{\gamma (1-\gamma)T + \sigma^2  T}.
\end{align}
Since our standard deviation $\sigma$ is very small in practice, the increase in variance, $\sigma^2 T$, is also quite minimal. In the process of subsequent experiments, we will initially estimate the variance of the generation network and then include the variance during the z-score test calculation.

\subsection{Watermark Detection Network}
\label{sec:net}

The z-value test effectively detects watermarks in text but requires knowing the label (watermarked or not) of each token during detection. This allows the watermark to be more easily removed or forged. To address this, we propose a watermark detection neural network that accepts only the text sequence as input and outputs whether it contains a watermark.

The detailed structure of our watermark detection network is illustrated in the right part of Figure \ref{fig:intro}. The input to the entire network is the ID sequence of all tokens in the target sentence, where an output of 1 indicates the presence of a watermark in the entire sentence, and 0 signifies its absence. 

Specifically, all tokens first pass through a shared embedding network. Notably, the parameters of this token embedding are consistent with those of the watermark generation network and remain frozen during subsequent training. The motivation behind this novel approach is the shared embedding could give prior information to the detection networks and substantially reduce the difficulty of training.

The token embeddings are then combined and fed into an LSTM network \cite{hochreiter1997long} for binary classification of whether the text contains a watermark:
\begin{equation}
    \mathcal{D}(\boldsymbol{x}) = \text{LSTM}(\mathrm{E}(x_0)\oplus \mathrm{E}(x_1)\oplus ....\oplus\mathrm{E}(x_{T})).
\end{equation}
The watermark detection network functions as a discriminator, judging if the z-value of input text exceeds a threshold. We construct the training data using equation \ref{new-z} with a predefined threshold $z$. 

% Specifically, we sample texts with varying proportions of watermarked tokens, assigning a 0 or 1 label based on the resulting z-value relative to the threshold.

Notably, the input of the detection network need not be meaningful text; any token ID list suffices. Thus, the randomly generated ID sequence as training data theoretically avoids out-of-domain issues.

To impede attackers from inferring watermarking rules, we treat the text as a cyclic document, labeling initial tokens based on trailing ones. This results in random labels for the first few tokens, minimizing their effect on detection given the small window relative to full text length.

% The entire watermark detection network could be viewed as a discriminator to judge whether the z-value of a given input text is greater or less than a certain threshold. Therefore, we use equation \ref{new-z} with a certain threshold to construct the training dataset. Specifically, during the training dataset construction, we sample texts with different proportions of green tokens and then assign a label of 0 or 1 depending on whether the calculated z-value exceeds a certain threshold. 

% It should be noted that the input for the training of the entire watermark detection network does not need to be a meaningful text - any number ID list is acceptable. Therefore, the detection model trained in this way theoretically will not encounter out-of-domain issues. We will further illustrate this point in subsequent experiments.

% Moreover, under normal circumstances, the first $w-1$ tokens of a string of text sequences are usually not labeled as red or green. To make it more difficult for attackers to infer the watermark generation rules from the watermark detection network, we also labeled the first w-1 tokens by treating the text as a cyclic document connected head-to-tail. For instance, we can determine the label for $x_0$ through $x_{n-w+1}....x_{n}$. Normally, the labels of the first w-1 tokens are usually random, but since the window size is much smaller than the overall length of the text, this can be neglected in the overall watermark detection.

\subsection{Analysis of the Privacy}
\label{sec:ana}

% To demonstrate the efficacy of our private watermarking algorithm in obfuscating the watermark generation process, we analyzed the difficulty of deducing the watermark generation rules from the watermark detection network.

% The most direct way to crack watermarks is to use the detection network to construct training data and reversely train the generation network. However, directly leveraging the detection network to assemble training data for the generation network presents a significant obstacle: the inability to acquire precise labels. Specifically, the detection network yields only an aggregate of multiple outputs from the watermarking network, represented as $\sum_{i}^{T}{\mathcal{W}(\mathbf{x}_{i:i+w})}>\gamma T$ if text is watermarked, rather than precise labels for the generation network. This lack of accurate labeling complicates the training of the generation network, even when both networks share token embedding parameters. The intricacies of this process will be further elaborated in the experiment section. This characteristic adequately satisfies computational asymmetry, which is vital for privacy-preserving fields like asymmetric cryptography. The theoretical training difficulty and computational asymmetry inherent in training the generation network from the detector network robustly safeguard the privacy of our algorithm.

To further demonstrate the privacy of our watermarking algorithm, this section provides a detailed analysis of the difficulty in cracking the watermark generation method.

In the process of watermark generation, we use watermark generation networks to produce labels for training watermark detection networks. This process is quite straightforward. For a given text $\vx$, the gold label of the detection network $\mathcal{D}$ is a simple function of watermark generation network $\mathcal{W}$:
\begin{equation}
\mathcal{D}(\vx) = f\left(\mathcal{W}(\vx_{0:w}), \mathcal{W}(\vx_{1:w+1}), ..., , \mathcal{W}(\vx_{T-w:T})\right).
\end{equation}

Conversely, utilizing the watermark detection network to produce training labels for the watermark generation network presents substantial challenges. Given the input text $\vx$ and the detection network $\mathcal{D}$, it is not straightforward to obtain a specific label $\mathcal{W}(\mathbf{x}_{i:i+w})$. The inference is only possible with respect to the relationships among multiple labels. This necessitates accounting for output interdependencies within the generation network, as shown below:
\begin{equation}
\mathcal{W}(\vx_{i:i+w}) = g\left(\vx, \mathcal{D}, \{ \mathcal{W}(\vx_{j:j+w}) \}_{j \neq i} \right).
\end{equation}
The uncertainty and complex dependencies between labels make training watermark generation networks from watermark detection networks extremely difficult. The intricacies of this process will be further elaborated in the experiment section. This characteristic adequately satisfies computational asymmetry, which is vital for privacy-preserving fields like asymmetric cryptography. The theoretical training difficulty and computational asymmetry inherent in training the generation network from the detection network robustly safeguard the privacy of our algorithm.

In addition to using the watermark detection network to train the generation network, one can infer the watermark rules by analyzing word frequency differences across large amounts of text, i.e. the spoofing attack mentioned by \cite{sadasivan2023can}.  The principle is that when using a watermarking method with a window size $w$, the frequency of the $w$th token with fixed previous $w-1$ tokens will differ from that in unwatermarked text. However, this approach is largely ineffective when the window size is not particularly small, as will be detailed in the experiments section.




\section{Experiment}

In this section, we validate our private watermark algorithm through extensive experiments. 


\subsection{Experiment Setup}


\input{tbls/main}

\textbf{Language Model and Dataset:} 
We utlize three language models - GPT-2\citep{radford2019language}, OPT-1.3B\citep{zhang2022opt}, and LLaMA-7B\citep{touvron2023llama} - to generate watermarked text. Consistent with previous works, we employ two decoding methods: Top-K sampling and Beam search, to produce the watermarked text.  We select the C4\citep{raffel2020exploring} and Dbpedia Class \citep{raffel2020exploring} datasets and use the first 30 words of each text as the prompt. For each prompt, the language model would generate the next 200 ± 5 tokens.

\textbf{Evaluation:} The objective in evaluating watermarking algorithms is to distinguish human-written text from language model-generated text. Specifically, we select 500 texts from the dataset as human text and 500 language model-generated texts for evaluating binary classification metrics. We thoroughly document the false positive rate, false negative rate and F1 score.

\textbf{Hyper-parameters:} The default hyperparameters are configured as follows: watermark token ratio $\gamma$ of 0.5, window size $w$ of 5, five token embedding layers, and $\delta=2$ for the generator. The detector comprises two LSTM layers as well as the same token embedding layers. For decoding, Top-K employs \(K=20\) and Beam Search utilizes a beam width of 8. Both networks adopt a learning rate of 0.01, optimized via the Adam optimizer \citep{kingma2014adam}.  Due to the varying sensitivity of language models to the watermark, for ease of comparison, the detection z-score thresholds for GPT-2, OPT 1.3B, and LLaMA 7B are set to 1, 1 and 3, respectively.

% We evaluate our watermarking method using GPT-2 \citep{radford2019language}, OPT-1.3B \citep{zhang2022opt}, and OPT-2.7B \citep{zhang2022opt} models with both top-K sampling and beam search text generation. The models generate completions to C4 \citep{raffel2020exploring} and Dbpedia \citep{gangemi2012automatic} prompts of length 30. Each model generates 200$\pm$5 tokens per prompt. We compare model-generated text (watermarked) to original human-written text from the datasets (non-watermarked). The false positive rate (human text incorrectly flagged as watermarked) and false negative rate (undetected watermarked text) measure effectiveness.

% The default hyperparameters are: 0.5 watermarked token ratio, window size 5, 5 token embedding layers,  $\delta$=2 for the generator. For the detector, there are 2 LSTM layers. Top-K uses K=20. Beam search uses a beam width of 8. And the learning rate is 0.01 with Adam optimizer for both network.

% We utilize GPT-2 \citep{radford2019language}, OPT-1.3B \citep{zhang2022opt}, and OPT-2.7B \citep{zhang2022opt} as the models for generating watermarks. For each model, we adopt both top-K sampling and beam search methods for text generation. The specific details of the two sampling methods have already been mentioned in section \ref{sec:generate}.

% Meanwhile, we use the C4 \citep{raffel2020exploring} and Dbpedia Class datasets \citep{gangemi2012automatic} to evaluate our watermark algorithm. Specifically, following the approach of \citet{kirchenbauer2023watermark}, we selected texts with length 30 from these datasets as prompts, and let the language models perform completions given these prompts. For each prompt, the models would generate $T=200\pm5$ tokens. We used the completions from the original datasets as the non-watermarked text (human text), and the text generated by our models as the watermarked text. The effectiveness was evaluated based on the ratio of false positive errors (human text falsely flagged as watermarked)  and false negative errors (watermarked text not detected).

% Unless specified otherwise, the hyperparameters used in the experiment are as follows: for the generator network, the ratio of green labels generated is 0.5, the window size is 5, the layer number of the token embedding network is 5, and the value of $\delta$ is set to 2. For the detector network,  the value of z used in training is 4, and the number of LSTM network layers is 2. When using the top-K sampling method, the K is set to 20 and the beam size of the beam search method is set to 8.

\subsection{Main Results}

Table \ref{tab:main} shows a comparison of detection efficacy between our private watermarking algorithm and current public watermarking algorithms. The public baseline watermarking algorithm is the method of \cite{kirchenbauer2023watermark}, which directly computes the number of watermarked (green) tokens and then calculates the z-score.

% Table \ref{tab:main} demonstrates the detection accuracy of the private watermarking algorithm. We refer to the method which utilizes the label of each token to calculate the z-value (section \ref{sec:detect}) as the public watermarking algorithm and use this algorithm as the baseline for our comparison. The hyper-parameters used are $\delta=2.0$ and $\gamma=0.5$. The detection network is trained following a z-value threshold of 4.

As illustrated in Table \ref{tab:main}, similar to the public watermarking algorithm, our private watermarking algorithm also scarcely produces false positive results (0.1\% and 0.4\% on average), meaning that human text is almost never mistakenly identified as watermarked text. Moreover, in most scenarios, the false negative probability is only marginally higher than the public watermarking algorithm by an average of $1.2\%$. Considering that the performance of the public watermarking algorithm represents the strict upper bound of our method, this is indeed an outstanding result.  We also find that the performance trends of our algorithm across different settings (language models, datasets) are similar to the public watermarking algorithm.  This demonstrates the general applicability of our private watermarking method without using watermark generation rules. We will analyze the difficulty of inferring watermark generation details from the detector in subsequent analyses.

% performing slightly better on smaller language models. Using beam search enables deeper integration of the watermark into the text.

% For some special cases when the z-value is not properly selected (using the top-K sampling with OPT 1.3B and 2.7B models to test the DBpedia CLASS dataset), even the public detection algorithm generates more false negatives cases and our private detection methods would also decrease in performance.  With a properly selected z-value threshold, the private watermarking algorithm exhibits similar performance across different decoding methods, various language models, and disparate domain datasets, which demonstrates its strong generalizability and adaptability.

\input{tbls/ablation}


\subsection{Analysis of Shared Embedding}

To demonstrate the necessity of shared embedding layers between the generation network and detection network, we compared the watermark detection performance under three settings in Table \ref{tab:ablation}: without using shared embedding layers, using shared embedding layers but not fine-tuning them during detection network training, and using shared embedding layers while also fine-tuning them during detection network training. All the experiments employ top-K sampling.

% An ablation study in Table \ref{tab:ablation} illustrates the effectiveness of shared token embedding for the detection network. Experiments on GPT2, OPT1.3B, and OPT2.7B models using the C4 and DBPEDIA CLASS datasets compare three settings: shared token embedding, no shared token embedding, and fine-tuned shared token embedding.

Without the shared layer, F1 score decreases dramatically, by 72.0\% on average. This renders the detection algorithm nearly useless.  Furthermore, fine-tuning the shared embedding layers decreases F1 score by 11.1\%. These results demonstrate using the generator's token embedding layers without further fine-tuning is optimal  for the detection network.

% Although fine-tuning the shared layer reduces false negatives, it also introduces some false positives. Since incorrectly identifying human text as watermarked has more severe consequences, we opt not to fine-tune the shared layer.

% To further analyze the private watermark algorithm, we conduct an ablation study in Table \ref{tab:ablation}  to illustrate the effectiveness of shared token embedding for the detection network. Specifically, the experiment is conducted on the GPT2, OPT1.3B, and OPT2.7B language models on the C4 and DBPEDIA CLASS datasets. We have presented results under three different settings: using shared token embedding, not using shared token embedding, and fine-tuning shared token embedding.

% As seen from Table \ref{tab:ablation}, without the shared layer, the proportion of false negatives (watermarked text not
% detected) and false positives (human text falsely flagged as watermarked) dramatically decreases on an average of $15.1\%$ and $32.0\%$ respectively. This renders the entire detection algorithm almost inapplicable. Concurrently, although fine-tuning the shared layer reduces the occurrence of false negatives, it also introduces some instances of wrongly tagged human text. Given that mistakenly recognizing human text as the watermarked text presents more severe consequences, we eventually choose to adopt the method without fine-tuning the shared layer.


% Figure environment removed

% It is crucial that the details of how our private watermark is generated remain difficult to infer. Thus, we further analyzed the accuracy of attack methods that attempt to obtain the rules used to generate the watermark. Specifically, we employed the two attack methods mentioned in Section 4.5: reverse training a generation network from a detection network, and directly cracking the watermark based on token frequency.




\subsection{Privacy Analysis}
\label{sec:pri}

It is crucial that the details of watermark generation remain difficult to infer. Thus, we conducted an analysis of the accuracy of potential attack methods aimed at discerning the watermark generation rules. Specifically, we examined two attack methods mentioned in Section \ref{sec:ana}: reverse training of the generation network from the detection network, and direct cracking of the watermark based on token frequency. For the reverse training generation network from the detection network attack method, the retrained generation network also shares parameters in the token embedding layers of the detection network without further fine-tuning. The setting \textit{w\_ft. params} indicates that the token embedding parameters have been fine-tuned during the training of the detection network or and the setting \textit{w fixed. params} indicates the parameters are the same as the origin generation network.

From Figure \ref{fig:z}(a), our watermark detection algorithm can maintain a relatively stable detection accuracy as the window size increases. However, the effectiveness of the attack method based on reverse training decreases gradually as the window size increases until it drops to the minimum value of 0.5 (random guess). This strongly validates our explanation in Section \ref{sec:ana} that training the generator with the detector is a computational asymmetrical inverse process. At the same time, the cracking method directly based on word frequency is completely useless when the window size is not particularly small. This experiment demonstrates that our method has good privacy properties. More details about the attack algorithms could be seen in the appendix.


\subsection{Hyper-parameter and Error Analysis}

% To further analyze how our private watermarking algorithm works, we examine the effects of key hyperparameters, specifically the impact of different $\delta$ values on detection accuracy and text quality. Text quality is evaluated using the LLaMMA 13B \citet{touvron2023llama}.  As shown in Figure \ref{fig:z} (b), with the increase in the value of $\delta$, the accuracy of the detection network also increases. However, the corresponding perplexity (PPL) value of the generated text will also rise. Weighing these factors, we finally chose a $\delta$ value of 2, which maintains detection accuracy without excessively impacting the text quality.

In investigating the efficacy of our private watermark algorithm, we focus on the influence of the $\delta$ values on the detection F1 score and the text quality. Text quality is assessed by perplexity using the LLaMA 13B  \citep{touvron2023llama}. Figure \ref{fig:z} (b) demonstrates that as $\delta$ increases, so does the F1 score of the detection network; however, this comes at the cost of an increased perplexity (PPL) value in the generated text. After considering these trade-offs, we selected a $\delta$ value of 2 to optimize detection accuracy without severely compromising text quality.

To analyze the error cases, we present the z-score distributions of human and watermarked texts, as well as the algorithm's detection F1 score at different z-score ranges in Figure \ref{fig:err}(a). These results are generated by GPT2 on the C4 dataset. Figure \ref{fig:err}(a) reveals that the human and watermarked texts exhibit nearly normal distributions around 0 and 9, respectively. The detection accuracy of the private watermark algorithm drops significantly around the z-score threshold of 4 but approaches 100\% in other ranges. This indicates that our algorithm is highly reliable for inputs with definite labels.

% To better understand how the private watermark algorithm works, we perform a series of analyses on several key hyper-parameters. Specifically, we tested the influence of different z value thresholds and $\delta$ values in Figure \ref{fig:z} (a) and Figure \ref{fig:z} (b) respectively. When analyzing different z value thresholds, the value of $\delta$ is set to 2.0, and when analyzing different $\delta$ values, the value of z is set to 4. We use the LLaMA 13B model \citet{touvron2023llama} to calculate the perplexity (PPL) value in Figure \ref{fig:z}(b).



% \subsection{Error Analysis}

% To better analyze the error cases of the private watermark algorithm, we present the z-score distributions of both the human text and the watermarked text, as well as the detection accuracy of the algorithm at different z-score ranges in Figure \ref{fig:err}(a). These results are generated by GPT2 on the C4 dataset. As can be observed from Figure \ref{fig:err}(a), the human text and watermarked text exhibited a normal-like distribution centered around 0 and 9 respectively. The detection accuracy of the private watermark algorithm is relatively low only around the z-score threshold 4, while it is almost 100\% in other ranges. This suggests that for inputs with highly certain labels, our algorithm is quite reliable.

 % To conducted a more detailed analysis of the error cases of our private watermark algorithm, as shown in figure \ref{fig:err} (a). In this experiment, the watermark detection network uses a z value of 4 during training.  In this figure, we first compute the actual z-scores for all the test data, divide these z-scores into different ranges, and then perform statistical analysis on the detection accuracy for each range. As can be seen from figure \ref{fig:err} (a), all errors are concentrated near the threshold $z=4$. Therefore, the model only makes judgment errors on the confusing examples (near the threshold), while for cases with high confidence, it rarely makes mistakes.

 % Figure environment removed


\subsection{Watermark Generation Network Analysis}

It is critical that the watermark generation network produce a stable watermarked token ratio, as the modified z-score calculation (equation \ref{new-z}) depends on the variance of this ratio. Therefore, in this section, we calculate the actual mean and variance of the watermark labels. 

Specifically, we train the watermark generation network using 5000 data items with strictly a 0.5 ratio of watermarked tokens. As seen in figure \ref{fig:err} (b), the ratio approaches the target value 0.5 as the training loss decreases, and its standard deviation also diminishes. The standard deviation can be controlled within 0.02, corresponding to a variance of less than $4e-4$. According to equation \ref{new-z}, $\sigma^2  T$ could be nearly neglected in the final z-value calculation. 

% We adopt the value 0.02 in the revised z-score calculation.

% Based on our analysis in the section \ref{sec:detect}, it is critical for the watermark generation network to generate a stable label ratio because the modified z-score calculation (equation \ref{new-z}) is dependent on the variance of the label ratio. Therefore, in this section, we calculate the actual mean and variance of the labels generated by the watermark generation network. 

% Specifically, we train the watermark generation network using 5000 data items with strictly a 0.5 ratio of green labels, using the Adam optimizer \cite{kingma2014adam} with a learning rate of 0.001. As can be seen from figure \ref{fig:err} (b), the ratio of green labels gradually approaches the target value 0.5 with the training loss decreases, and its standard deviation also gradually diminishes. Ultimately, the standard deviation can be controlled within 0.02, corresponding to a variance of less than $4e-4$. According to equation \ref{new-z}, $\sigma^2  T$ could be nearly neglected in the final z-value calculation. We adopt the value 0.02 in the revised z-score calculation.

\subsection{Time Complexity Analysis}

The private watermark generation process requires an additional network, potentially introducing computational overhead. However, our watermark generation network contains only 43k parameters, negligible compared to the 124M to 2.7B parameters in GPT2, OPT-1.3B, and OPT-2.7B models. Empirically, decoding a token takes 30ms in GPT2  on a single Tesla V100 GPU, and our watermarking adds only 1ms on average, even less for larger models. Thus, our watermark generation algorithm adds minimal computational burden. In prior experiments, we selected relatively small top-K values. However, given that networks can perform batch computations, even large K values do not affect the computation time. A detailed analysis will be provided in the appendix.

% Due to the private watermark generation process employing an additional watermark generation network, there is a risk of introducing an extra computational burden. Therefore, we analyze the time complexity of the watermark generation process in this section.

% First, we compare the number of parameters in the watermark generation network and the language model. Our  watermark generation network only consists of 43k parameters, whereas GPT2, OPT1.3B, and OPT2.7B have 124M, 1.3B, and 2.7B parameters respectively. It is evident that compared to the large language models with an enormous number of parameters, the number of parameters in our watermark generation network can be considered almost negligible.

% Then we analyze the actual running time. On a single Tesla V100 GPU, decoding a token in GPT2 requires 30ms, whereas incorporating our watermark generation network only adds an average of 1ms to the cost. For models with a larger number of parameters, such as OPT1.3B and OPT2.7B, the influence on the decoding time is even smaller. Hence, our watermark generation algorithm does not cause significant additional computational overhead.

\section{Conclusion}

In this paper, we propose the first private watermarking algorithm for large language models. Unlike previous detection methods that require the watermark key for detection, our method uses a separate detection neural network to detect the watermark. In experiments, we demonstrate the difficulty of inferring the watermarking method from the detection network, while our method achieves similar F1 scores to direct z-score computation and applies to various language models and datasets. In the future, details of the watermark generation and detection networks can be further optimized. Furthermore, as the focus of this study is on private watermarks, the robustness of watermarking algorithms in text modification scenarios is not our priority. In fact, our robustness in this setting is similar to corresponding public watermarking methods. Future work could investigate improving watermark robustness under private watermarking constraints.


\bibliography{iclr2024_conference}
\bibliographystyle{iclr2024_conference}
\newpage
\appendix

\input{tbls/case}

\section{Case study}

To better illustrate the text generated by the watermarked LLM, we have listed some text examples from both the watermarked LLM and the non-watermarked LLM in Table \ref{tab:demo-examples}. We compare the z-scores and PPL scores between these texts. Specifically, when calculating PPL scores, we utilize the LLaMA 13B model \cite{touvron2023llama}. The results from table \ref{tab:demo-examples} demonstrate that the z-scores for texts generated by the watermarked LLM are significantly higher than those from the non-watermarked LLM, while there isn't a significant increase in the PPL scores.


\section{Details of Reverse Training}

In Sections \ref{sec:ana} and \ref{sec:pri}, we analyzed the challenges of training a watermark generation network using training data from a watermark detection network, both theoretically and experimentally. Here we elaborate on the intricacies of this reverse training process.

A key aspect is the definition of loss function for reverse training. Given a sentence's token list $\mathbf{x} = [x_1, ..., x_n]$, the detection network $\mathcal{D}$ assigns a label indicating watermarked (1) or not (0). This could also calculated by the new generator network $\mathcal{W}$.  Specifically, when this proportion is 0.5, the generation network $\mathcal{W}$'s prediction is:

\begin{equation}
\hat{p} = \frac{\sum_{i}^{T-w}\mathcal{W}(x_{i:i+w})}{T-w}
\end{equation}

The final reverse training loss is:

\begin{equation}
L(\mathcal{W}) = -\mathcal{D}(\mathbf{x}) \log(\hat{p}) - (1 - \mathcal{D}(\mathbf{x})) \log(1 - \hat{p})
\end{equation}

For training, we used 10,000 random token lists of length 100-200, labeled by detector $\mathcal{D}$.


% In Sections \ref{sec:ana} and \ref{sec:pri}, we analyzed the challenge of training a watermark generation network using training data generated by a watermark detection network from both theoretical and experimental perspectives. In this section, we provide a more detailed description of the intricacies involved in this reverse training process.

% A pivotal aspect concerns the loss function for reverse training. Given a sentence's token list $\mathbf{x} = [x_1, …, x_n]$, the detection network $ \mathcal{D}$ assigns a label to the sentence, indicating whether it's watermarked (1) or not (0). This label depends on the watermark status of all tokens in the sentence. Specifically, when the proportion of watermarked tokens is 0.5, the predictive result of the generate network $\mathcal{W}$ is given by:
% \begin{equation}
% \hat{p} = \frac{\sum_{i}^{T-w}\mathcal{W}(x_{i:i+w})}{T-w} 
% \end{equation}

% The final loss can be represented by the following equation:
% \begin{equation}
% L(\mathcal{W}) = -\mathcal{D}(\mathbf{x}) \log(\hat{p}) - (1 - \mathcal{D}(\mathbf{x})) \log(1 - \hat{p}) .
% \end{equation}

% During training, we used 10,000 random token lists of length 100-200 as training data, labeled by the detection network $\mathcal{D}$.

\section{Details of Direct Cracking Attack}

\input{tbls/gram_frequency}

In this section, we detail another attack method mentioned in section \ref{sec:pri}: the direct cracking attack. This method, originating from the work of \cite{sadasivan2023can}, does not require a watermark detector. Instead, it solely analyzes changes in token frequency distributions. Specifically, with a window size of w, it examines the frequency the wth token appears given a prefix of length w-1 tokens. If a token's frequency significantly increases in the presence of a watermark, it is deemed to be part of the watermark token set.

As in \cite{sadasivan2023can}'s method, we examine the 181 most common (w-1)-token n-grams. Since even the most common (w-1)-grams become increasingly rare as w grows, predicting watermarked text also becomes increasingly difficult with this approach.  As shown in Table \ref{tab:fre}, as the window size increases, the frequency of the most common prefixes decreases markedly. Analyzing this may require an extremely large amount of data, but through our analysis in Figure \ref{fig:data_size}, when the window size grows to a certain extent, even increasing the data amount cannot significantly improve the effect.

 % Figure environment removed


\section{Expanding the K In top-k sampling}

\input{tbls/time}

In Table \ref{tab:time}, we comprehensively examined the impact of varying k-values on computation time and GPU memory utilization. All timings were recorded on a single V100 32G GPU. It can be observed that even when processing 20,000 tokens simultaneously, the computation time is only twice that of processing 20 tokens, while the memory consumption increases tenfold (with a window size of 5). This indicates that our algorithm demonstrates exceptionally low computational complexity with respect to increasing k-values.


\section{Detection accuracy across different domains}

\input{tbls/domain}

To validate our claim in Section \ref{sec:net} that our watermark detection algorithm is robust to differences in text domain, we compare our private watermark detector to current public watermark detectors across various text domains in the DBPEDIA CLASS dataset (Table \ref{tab:domain}). Our algorithm achieves consistently high detection F1 score across domains, primarily because the random token ID lists used during training explore the space of $|V|^T$ possible inputs, covering all plausible texts. Thus, our detector can theoretically achieve similar detection accuracy across text domains.

\end{document}
