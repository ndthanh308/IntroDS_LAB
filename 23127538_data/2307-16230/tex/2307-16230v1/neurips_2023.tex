\documentclass{article}


% if you need to pass options to natbib, use, e.g.:
%     \PassOptionsToPackage{numbers, compress}{natbib}
% before loading neurips_2023


% ready for submission
% \usepackage{neurips_2023}


% to compile a preprint version, e.g., for submission to arXiv, add add the
% [preprint] option:
    \usepackage[preprint]{neurips_2023}


% to compile a camera-ready version, add the [final] option, e.g.:
%     \usepackage[final]{neurips_2023}


% to avoid loading the natbib package, add option nonatbib:
%    \usepackage[nonatbib]{neurips_2023}


\usepackage{amsmath}
\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{xcolor}         % colors
\usepackage{graphicx}    
\usepackage{multirow}
\usepackage{algorithm}
\usepackage{algorithmic}
% \usepackage[section]{placeins}
\usepackage{subfigure}
\usepackage{float}
\usepackage{tabularx}

% \usepackage[numbers,sort&compress]{natbib}
% \usepackage{cite}
\usepackage{placeins}

\title{A Private Watermark for Large Language Models}


% The \author macro works with any number of authors. There are two commands
% used to separate the names and addresses of multiple authors: \And and \AND.
%
% Using \And between authors leaves it to LaTeX to determine where to break the
% lines. Using \AND forces a line break at that point. So, if LaTeX puts 3 of 4
% authors names on the first line, and the last on the second line, try using
% \AND instead of \And before the third author name.

\author{
Aiwei Liu\textsuperscript{1},
~~~ Leyi Pan\textsuperscript{1},
~~~ Xuming Hu\textsuperscript{1},
~~~ \bf{Shu'ang Li}\textsuperscript{1},\\
~~~ \bf{Lijie Wen}\textsuperscript{1},
~~~ \bf{Irwin King}\textsuperscript{2},
~~~ \bf{Philip S. Yu}\textsuperscript{3}\\
\textsuperscript{1}Tsinghua University~~~
\textsuperscript{2}The Chinese University of Hong Kong~~~\\
\textsuperscript{3}University of Illinois at Chicago~~~\\
{\tt\small liuaw20@mails.tsinghua.edu.cn, wenlj@tsinghua.edu.cn,}
{\tt\small  king@cse.cuhk.edu.hk}
}

% \author{%
%   % Aiwei Liu, Leyi Pan, Xuming Hu, Shu'ang Li, Lijie Wen and Irin King\\
%   % \texttt{liuaw20@mails.tsinghua.edu.cn} \\
% %   % examples of more authors
% %   % \And
% %   % Coauthor \\
% %   % Affiliation \\
% %   % Address \\
% %   % \texttt{email} \\
% %   % \AND
% %   % Coauthor \\
% %   % Affiliation \\
% %   % Address \\
% %   % \texttt{email} \\
% %   % \And
% %   % Coauthor \\
% %   % Affiliation \\
% %   % Address \\
% %   % \texttt{email} \\
% %   % \And
% %   % Coauthor \\
% %   % Affiliation \\
% %   % Address \\
% %   % \texttt{email} \\
% }



\begin{document}


\maketitle


\begin{abstract}
 Recently, text watermarking algorithms for large language models (LLMs) have been mitigating the potential harms of text generated by the LLMs, including fake news and copyright issues. However, the watermark detection of current text  algorithms requires the key from the generation process, making them  susceptible to breaches and counterfeiting.
In this work, we propose the first private watermarking algorithm, which extends the current text watermarking algorithms by using two different neural networks respectively for watermark generation and detection, rather than using the same key at both stages. Meanwhile, part of the parameters of the watermark generation and detection networks are shared, which makes the detection network achieve a high accuracy very efficiently.
Experiments show that our algorithm ensures high detection accuracy with minimal impact on generation and detection speed, due to the small parameter size of both networks. Additionally, our subsequent analysis demonstrates the difficulty of reverting the watermark generation rules from the detection network.
\end{abstract}


\section{Introduction}


With the development of current large language models (LLMs), many LLMs, like GPT4 \citep{openai2023gpt4} and Claud\footnote{https://claude.ai/chat}, could rapidly generate texts which are difficult to distinguish from human texts. This has led to numerous risks, such as the generation of a vast amount of false information on the Internet \citep{pan2023risk}, and the infringement of copyrights of creative works \citep{chen2023pathway}. Therefore, texts generated by LLMs need to be detected and tagged.

At present, some text watermark algorithms have been successful in making machine-generated texts detectable by adding implicit features during the text generation process that are difficult for humans to discover but easily detected by the specially designed method \citep{christ2023undetectable, kirchenbauer2023watermark}. However, current text watermark algorithms are all public, which means the detection of watermarks requires the key from the watermark generation process. This allows attackers easily remove and forge the text watermarks using these public keys. Although \citet{kirchenbauer2023watermark}  have suggested that the watermark detection process could be placed behind the web API to achieve the effect of private watermarking, this approach requires substantial server resources and robust designs against hacking (even social engineering). Moreover, the requirement for users' text uploading  carries an inherent risk of privacy breaches.  If a text watermark algorithm could be designed in such a way that the watermark's generation key could be hidden during the detection process, this could significantly mitigate the issues mentioned above.

In this work, we propose the first private watermark algorithm for LLMs. Our work is built on the common watermark paradigm, which splits the vocabulary into the green and red lists and then prefers to choose tokens from the green list. The difference is we implement these concepts in a private way. In order to hide the detail of the watermark generation method during the detection process, we propose two separate neural networks for watermark generation and detection instead of using the same key for both stages. The privacy of our algorithm derives from the black-box nature of neural networks, that is, it's nearly impossible to infer the watermark generation detail from the parameters of the detection network. Also, we analyze the difficulty of reverting watermarking generation detail from the output of the detection network in section \ref{sec:ana}.
% Specifically, we construct the dataset for the detection network from texts produced by the watermark generation algorithm and other texts without watermarks.
However, in practice, training such a detection network from scratch requires a vast amount of data, and achieving a high accuracy is challenging due to the complexity of the problem. Therefore, we also propose a neural network for the watermark generation process.  To achieve a high-accuracy detection network with relatively small data,  we share the token embedding layers between the watermark generation network and the watermark detection network, which essentially provides some prior information to the detection network.
Specifically, our watermark generation network takes the input of $w$ (local window size) tokens  and outputs whether the last token belongs to the green list, which differs from the origin method \cite{kirchenbauer2023watermark} of 
splitting the vocabulary into the green and red list based on the local window text's hash value and the secret key. Meanwhile, the text detection network directly inputs all the token lists from the text, with the output being a classification indicating whether the entire text contains the watermark added by the generation network.

While constructing the training data for the watermark detection network, the presence of the watermark is also determined by considering the labels (red or green) of the first `window size - 1' tokens. These labels are generated by treating the text as a cyclic document connected from head to tail. In this way, we prevent attackers from easily deducing the watermarking rule by continually altering the last token and observing the output changes.

% Figure environment removed


In our experiments, we demonstrate that the watermark detection algorithm could achieve a nearly 99\% detection accuracy rate, which is only marginally inferior to the public watermark algorithm. Given that the detection accuracy of the public watermark algorithm represents our theoretical upper bound, this is already a remarkable result. Moreover, because the amount of parameters of our watermark generation and detection network is negligible compared to the large language model, it brings almost no additional computation burden to the text generation process.  Subsequent experiments also illustrate the critical importance of sharing the token embedding layer between the generation and detection networks.
% Furthermore, to demonstrate the relative security of our network, we have illustrated through several experiments and theoretical explanations that the difficulty of reverse-engineering the generation network using our detection network is very high.

The main contributions of this work can be summarized as follows:

\begin{itemize}
    \item We propose the first private watermark algorithm which utilizes two neural networks during the watermark generation and detection phase instead of using the same key in both stages. This makes the watermark more difficult to erase and counterfeit.
    \item The token embedding is shared between the watermark generation and watermark generation network, which makes the training of the watermark detection network more efficient.
    \item Subsequent experiments indicate that our private watermark algorithm can achieve a detection accuracy only marginally inferior to the direct calculation of z-scores (public algorithm).
\end{itemize}

\section{Related work}

As the quality of text generated by large language models (LLMs) improves, it becomes increasingly important to detect and tag machine-generated text. Up to this point, there are primarily two kinds of methods for detecting text produced by large language models. The first direction is the text watermarking method, which involves incorporating some implicit features (watermarks) into the text during generation, then detecting these texts using specially designed methods. The second approach keeps the text generation process unchanged and designs a classifier aimed at distinguishing between machine-generated and human-generated text. The following content will primarily introduce these two kinds of methods  separately.

Current classifier-based detection methods usually directly employ a binary classification model. \citet{zhan2023g3detector} utilized generation text from GPT2 \citep{radford2019language}, BART \citep{lewis2019bart}, and GPT3.5-turbo \footnote{https://chat.openai.com} to fine-tune the \textit{Roberta-large} \citep{liu1907roberta} model, resulting in a highly accurate GPT text detector. Similarly, \citet{mireshghallah2023smaller} discovered that smaller language models perform well for the detection of machine-generated text.
In an effort to improve the robustness of detection algorithms, \citet{su2023detectllm} incorporated log-rank information from language models into the detector as a crucial feature. Meanwhile, \citet{hu2023radar} introduced a paraphraser and utilized adversarial learning to enhance robustness.
To distinguish text from more LLMs, \cite{wu2023llmdet} utilized the prior information of the model's next-token probabilities to design a better detection model. However, whether machine-generated text can fundamentally be detected remains an open question. \citet{chakraborty2023possibilities} believe that with enough data collection, it is possible to train a good detector. On the contrary, \cite{sadasivan2023can} argue that as language models become more complex and the distance between human and AI-generated text decreases, the optimal detector's performance may be only slightly better than a random classifier.
In conclusion, some classifier-based detection methods can achieve impressive results. However, due to their limited explainability, their performance in real-world scenarios may be still doubted.

Compared to the classifier-based methods, text watermarking is more explainable due to the injected implicit features in the text. There are typically two categories of text watermarking methods. The first is to add a watermark to the existing text. For example, \citet{abdelnabi2021adversarial} designed a data-hiding network to embed watermark information in the text, and utilized a data-revealing network to recover the embedded information. \citet{yoo2023robust} injected the watermark by substituting some words in the text. However, adding a watermark to the existing text struggles to keep the semantics of the text unchanged which limits its use in real-world scenarios. Another line of methods is injecting the watermark during the text decoding process. \citet{christ2023undetectable} used pseudorandom numbers to sample the next token and subsequently detected the watermark by observing the correlation between the preset pseudorandom numbers and the generated tokens. \citet{kirchenbauer2023watermark} divided the vocabulary into red and green lists and preferred to generate tokens from the green list.  \citet{zhao2023provable} enhanced the robustness of this approach by using a global fixed red-green vocabulary. \citet{lee2023wrote} designed a watermarking method for low-entropy code generation scenarios. However, the above methods are all public, which means the key used to generate the watermark is required during detection. This makes the watermark susceptible to removal and counterfeiting. In this work, we propose the first private text watermarking method to alleviate these issues.





% % Figure environment removed

\section{Problem definition}

To facilitate subsequent discussions, this section introduces the key concepts used in this work: language models and the watermarking algorithm.

\textbf{A language model} $\mathcal{M}$ is essentially a function for the next token prediction, which is typically implemented using neural networks. Given an input sequence $\boldsymbol{x} = [x_0....x_{n-1}]$, it outputs the probability of the next token $x_n$ over the vocabulary $\mathcal{V}$: ${\bf p}_n:=P_{\mathcal{M}(\boldsymbol{x})}[ x_n = \cdot | \boldsymbol{x}_{1:n-1} ]$. The next token to be generated is then selected from this probability distribution, which can be achieved through sampling decode, choosing the token with the highest probability (greedy decode), or using other decode algorithms such as beam search to select a list of tokens with the highest probability.

\textbf{A  watermarking algorithm} is the combination of two interconnected algorithms: the watermark generation algorithm and the watermark detection algorithm.
\begin{itemize}
    \item \textbf{The watermark generation algorithm} could be viewed as a slight adjustment to the probability distribution of the language model. We can use $\hat{\mathcal{M}}$ to represent the language model that includes the text watermark. Formally, the probability of the next token prediction can be represented as follows: ${\bf p}_n:=P_{\hat{\mathcal{M}}(\boldsymbol{x})}[ x_n = \cdot | \boldsymbol{x}_{1:n-1} ]$.  
    \item \textbf{The watermark detection algorithm} accepts a text $\boldsymbol{x} = [x_0....x_{n}]$ as input and output whether the input sentence  contains a watermark. The watermark detection model ${\sf Detect}$ and the watermarked language  $\hat{\mathcal{M}}$ correspond to each other one-to-one.
\end{itemize}

\section{Proposed Method}

As illustrated in figure \ref{fig:intro}, the private watermarking algorithm utilizes two distinct neural networks rather than sharing the same key for the watermark generation and detection stages. In the subsequent sections, we will first introduce the decoding step of the watermarked language model (section \ref{sec:step}), follows by the details of the watermark generation network (section \ref{sec:generate}). Then the principles of watermark detection are introduced (section \ref{sec:detect}) as well as the specifics of the watermark detection network (section \ref{sec:net}). Finally, we analyze the privacy of the entire algorithm in detail (section \ref{sec:ana}).

\subsection{Watermarked Large Language Model}
\label{sec:step}


As shown in algorithm \ref{alg:wm} for watermark generation, given the input $\boldsymbol{x} = [x_0....x_{n-1}]$, we first generate the next token's logits,  ${\bf p}_n:=P_{\mathcal{M}(\boldsymbol{x})}[ x_n = \cdot | \boldsymbol{x}_{1:n-1} ]$, through the target language model $\mathcal{M}$. Then we select the top K tokens with the highest probability from the logits and use the watermark generation network $\mathbf{W}$ to determine whether they belong to the green list. The probability of these green list tokens is then increased by $\delta$, while keeping the probability of other tokens unchanged. The modified logits serve as the output of the watermarked language model $\hat{\mathcal{M}}$.

Note that we are not required to label of all tokens in vocabulary during each generation step. 
In the top-K sampling as shown in algorithm \ref{alg:wm}, only the top K tokens are tagged as green or red.  Meanwhile, for the scenario of beam search, the number of tokens that need to be labeled is dynamic. Suppose the beam size is B, the first step is to identify the Bth largest score $S_B$. Subsequently, all tokens with scores greater than $S_B - \delta$ are required to be tagged by the watermark generation network.

\begin{algorithm}[tbh]
   \caption{Watermark Generation Step (Top K sampling)}
   \label{alg:wm}
\begin{algorithmic}[1]
   \STATE {\bfseries Input:} a watermark generation network $N$, a fixed number $K$, watermark strength $\delta$, a language model $\mathcal{M}$, previous generated text $\boldsymbol{x} = [x_0....x_{n-1}]$, local window size $w$.
   \STATE Generate the next token logit ${\bf p}_n:=P_{\mathcal{M}(\boldsymbol{x})}[ x_n = \cdot | \boldsymbol{x}_{1:n-1} ]$.\\
   \STATE Get the top K logits $topK({\bf p}_n)$ and their ids $topK(\boldsymbol{x_n})$ .\\
   \FOR{$x_{ni}$ $\in$ $topK(\boldsymbol{x_n})$}
   \IF{$N([x_{n-w+1},...,x_{ni}]) = 1$}
    \STATE  Add the token $x_{ni}$ to the ``green list'' $G$.
    \ENDIF
   \ENDFOR
\STATE  Define a new language model $\hat{\mathcal{M}}$ where given input $\boldsymbol{x} = [x_0....x_{n-1}]$, the resulting logits satisfy $$\hat{\boldsymbol{p}}_n[i] := \boldsymbol{p}_n[i] + \delta \mathbf{1}(i\in G),$$
where $\mathbf{1}(\cdot)$ is the indicator function.
   \STATE {\bfseries Output:} watermarked language model $\hat{\mathcal{M}}$.
\end{algorithmic}
\end{algorithm}

\subsection{Watermark Generation Network}

\label{sec:generate}

The structure of our watermark generation network is illustrated in the middle part of figure \ref{fig:intro}. The embedding of each input token is first generated by the shared embedding network $\mathbf{E}$.
Then, the embeddings within a local window $w$ are concatenated and fed into the subsequent classification network $\mathbf{C}$ to determine if the last token belongs to the green list:

\begin{equation}
    \mathbf{W}(\boldsymbol{x}) = \mathbf{C}([\mathbf{E}(x_{n-w+1}), .... ,\mathbf{E}(x_n)]).
\end{equation}

The embedding network is a fully connected network and its input is the binary representation of token IDs, where the number of encoding bits depends on the size of the vocabulary. For example, GPT2 \cite{radford2019language} has a vocabulary size $|\mathcal{V}|$ of 50,000, which requires 16 bits for its vocabulary representation. Common language models typically require bits between 15 and 17 for binary vocabulary representations.

To facilitate the subsequent watermark detection, the proportion of green labels generated by the watermark generation network requires to remain constant.  Specifically, for any local window prefix $[x_{n-w+1}, \ldots, x_{n-1}]$, the probability of $x_n$ belongs to the green list is always a fixed value $\gamma$:

\begin{equation}
    \forall [x_{n-w+1}, \ldots, x_{n-1}], P(\mathbf{W}([x_{n-w+1}, \ldots, x_{n-1}, x_n]) = 1) = \gamma,
\end{equation}

where the $\gamma$ has the same meaning as the green list ratio in the previous public watermark algorithms \cite{kirchenbauer2023watermark, zhao2023provable}.

However, due to the black-box nature of neural networks, it is challenging to get a fixed ratio by pre-defined parameters. We achieve this by constructing a training dataset strictly with the desired proportion $\gamma$. It's worth noting that this method does not guarantee that the ratio of green to red will be strictly the same under every local window. Still, the expected value of this ratio is $\gamma$, and there is also a standard deviation $\sigma$. We will show the standard deviation $\sigma$ only has a very slight impact on the final detection process in the following section \ref{sec:detect}.

\subsection{Watermark Detection}
\label{sec:detect}

In this section, we  introduce how to detect a given watermark using the z-value test. Then in the next section, the training data of the watermark detection network would be tagged by the z-value calculation.

If vocabulary is divided into the green list and red list according to the fixed ratio $\gamma$, then the number of tokens from the green list appearing in a normal text of length T would be $\gamma T$, with a variance of $\gamma (1-\gamma)T$. In this case, we can adopt the z-value test method proposed by \citet{kirchenbauer2023watermark}. If the z-score from the following formula is greater than a certain threshold, the text would be considered as containing a watermark:

\begin{align} 
z = (|s|_G - \gamma T)/\sqrt{T\gamma(1-\gamma)}.
\end{align}

However, based on the previous section, the watermark generation network cannot guarantee a fixed ratio $\gamma$; we can only obtain a ratio $\hat{\gamma}$, which has an expectation $\gamma$ and a standard deviation $\sigma$. It is necessary to amend the aforementioned formula under these circumstances. The expectation of the green token numbers is still $\gamma T$, but the variance changed. According to the law of total variance, we can use the following formula to calculate the new variance:

\begin{align} 
Var(\gamma T) = E[Var(\gamma T|\gamma)] + Var(E[\gamma T|\gamma]) = \gamma (1-\gamma)T + \sigma^2  T, 
\end{align}
and the new z-score could be calculated as follows:
\begin{align} 
\label{new-z}
z = (|s|_G - \gamma T)/\sqrt{\gamma (1-\gamma)T + \sigma^2  T}.
\end{align}
Since our standard deviation $\sigma$ is very small in practice, the increase in variance, $\sigma^2 T$, is also quite minimal. In the process of subsequent experiments, we will initially estimate the variance of the generation network and then include the variance during the z-score test calculation.

\subsection{Watermark Detection Network}
\label{sec:net}

While the z-value test is effective in detecting watermarks within a text, it has a drawback that requires the label (green or red) of each token during the process. This makes it easier for the watermark to be removed or forged based on this information. To keep this information private, we innovatively propose a watermark detection neural network, which only accepts a sequence of text as input and output whether the text contains a watermark or not. 

The detailed structure of our watermark detection network is illustrated in the right part of figure \ref{fig:intro}. The input to the entire network is the ID sequence of all tokens in the target sentence, where an output of 1 indicates the presence of a watermark in the entire sentence, and 0 signifies its absence. 

Specifically, all tokens first pass through a shared embedding network. The parameters of this token embedding network are identical to those of the watermark generation network, and will not be fine-tuned in the following training process. The motivation behind this novel approach is the shared embedding could give prior information to the detection networks and substantially reduce the difficulty of training the watermark generation network. 

After obtaining the embedding of each token, we combine the embedding of all tokens and feed it into an LSTM (Long Short-Term Memory) network. Eventually, the LSTM network will output a binary classification to represent whether the text contains a watermark: 

\begin{equation}
    \mathbf{D}(\boldsymbol{x}) = \mathbf{LSTM}([\mathbf{E}(x_{0}), .... ,\mathbf{E}(e_n)]).
\end{equation}

The entire watermark detection network could be viewed as a discriminator to judge whether the z-value of a given input text is greater or less than a certain threshold. Therefore, we use equation \ref{new-z} with a certain threshold to construct the training dataset. Specifically, during the training dataset construction, we sample texts with different proportions of green tokens and then assign a label of 0 or 1 depending on whether the calculated z-value exceeds a certain threshold. 

It should be noted that the input for the training of the entire watermark detection network does not need to be a meaningful text - any number ID list is acceptable. Therefore, the detection model trained in this way theoretically will not encounter out-of-domain issues. We will further illustrate this point in subsequent experiments.

Moreover, under normal circumstances, the first $w-1$ tokens of a string of text sequences are usually not labeled as red or green. To make it more difficult for attackers to infer the watermark generation rules from the watermark detection network, we also labeled the first w-1 tokens by treating the text as a cyclic document connected head-to-tail. For instance, we can determine the label for $x_0$ through $x_{n-w+1}....x_{n}$. Normally, the labels of the first w-1 tokens are usually random, but since the window size is much smaller than the overall length of the text, this can be neglected in the overall watermark detection.

\subsection{Analysis of the Privacy}
\label{sec:ana}

To demonstrate that our private watermark algorithm could effectively hide the process of watermark generation, we analyze the difficulty of reverting the watermark generation rules from the watermark detection network.

A more detailed definition of the reverting problem is provided here: given the structure and parameters of the watermark detection network, obtain as many watermark generation rules as possible, $[x_i....x_{i+w-1}] ->$ 0 (red) or 1(green).

Considering the black-box nature of neural networks, inferring watermark rules based on the parameters of the detection network is nearly impossible, i.e., attackers can only infer from the output of the detection network. To achieve this goal, attackers need to continually modify the input to observe the output logits change. Every time modify a $x_i$ to $x_j$ in the text, the label (green or red) of tokens within a window size would change and the only information attackers could only get is the inequality of the number of green tokens between two groups as follows (assuming the probability of text being watermarked decreases):
\begin{equation}
\label{eq7}
    \mathrm{Num}(\{x_{i-w+1}...x_{i}\},...,\{x_i, ... x_{i+w-1}\}) >  \mathrm{Num}(\{x_{j-w+1}...x_{i}\}...\{x_j,...,x_{i+w-1}\}),
\end{equation}
where $\mathrm{Num}$ is a function to count the number of green labels within a group. 

First, we give the lower bound of the number of times required to query the detection network. Given the window size $w$, there's no way to infer all the rules within $|V|^w$ times of executing the detection network because the total number of rules is $|V|^w$, it is obviously impossible to infer two generation rules using one any query to the detection network.

However, it should be noted that this lower bound is very rough. In actual scenarios, it is even very difficult for attackers to obtain a clear inequality relation shown in equation \ref{eq7} because the window size is unknown to the attackers and the logits change of the detection network is not 100\% accurate. As a result, the user has to pay a considerable computational cost even to get a specific rule. Therefore, the actual number of required computations is far much greater than $|V|^w$. The detailed evaluation of the 

It can be seen that a larger window size could make the watermark generation rules more difficult to decipher. The method which uses a global fixed red-green list as adopted by \citet{zhao2023provable} is not suitable for the private watermark algorithm.

Instead of getting the watermark generation network rules from the watermark detection network, \citet{sadasivan2023can} proposed a method to infer the green list by statistically analyzing the pair frequency of large amounts of generated watermarked texts. However, their method is unlikely to be effective against our private watermarking method. First, \citet{sadasivan2023can} assumes the local window size is 2 but the window size we use is unknown.
If a search is conducted for all possible window sizes, the computational cost would be extremely high, as the required computational power increases exponentially with the window size. Secondly, their approach assumes that the analysis could be conducted with a fixed set of N = 181 common tokens. However, in actual scenarios, since attackers cannot access the watermarked language model (otherwise there would be no need for an attack), they cannot limit its output tokens to a fixed token set.


\section{Experiment}

In this section, we validate the effectiveness of the private watermark algorithm through extensive experiments. 


\subsection{Experiment Setup}

\input{tbls/main}



We utilize GPT-2 \citep{radford2019language}, OPT-1.3B \citep{zhang2022opt}, and OPT-2.7B \citep{zhang2022opt} as the models for generating watermarks. For each model, we adopt both top-K sampling and beam search methods for text generation. The specific details of the two sampling methods have already been mentioned in section \ref{sec:generate}.

Meanwhile, we use the C4 \citep{raffel2020exploring} and Dbpedia Class datasets \citep{gangemi2012automatic} to evaluate our watermark algorithm. Specifically, following the approach of \citet{kirchenbauer2023watermark}, we selected texts with length 30 from these datasets as prompts, and let the language models perform completions given these prompts. For each prompt, the models would generate $T=200\pm5$ tokens. We used the completions from the original datasets as the non-watermarked text (human text), and the text generated by our models as the watermarked text. The effectiveness was evaluated based on the ratio of false positive errors (human text falsely flagged as watermarked)  and false negative errors (watermarked text not detected).

Unless specified otherwise, the hyperparameters used in the experiment are as follows: for the generator network, the ratio of green labels generated is 0.5, the window size is 5, the layer number of the token embedding network is 5, and the value of $\delta$ is set to 2. For the detector network,  the value of z used in training is 4, and the number of LSTM network layers is 2. When using the top-K sampling method, the K is set to 20 and the beam size of the beam search method is set to 8.

\subsection{Main Results}

Table \ref{tab:main} demonstrates the detection accuracy of the private watermarking algorithm. We refer to the method which utilizes the label of each token to calculate the z-value (section \ref{sec:detect}) as the public watermarking algorithm and use this algorithm as the baseline for our comparison. The hyper-parameters used are $\delta=2.0$ and $\gamma=0.5$. The detection network is trained following a z-value threshold of 4.

As illustrated in Table \ref{tab:main}, similar to the public watermarking algorithm, our private watermarking algorithm also scarcely produces false positive results (both 0.2\% on average), meaning that human text is almost never mistakenly identified as watermarked text. Moreover, in most scenarios, the false negative probability is only marginally higher than the public watermarking algorithm by an average of $1.3\%$. Considering that the performance of the public watermarking algorithm represents the strict upper bound of our method, this is indeed an outstanding result. For some special cases when the z-value is not properly selected (using the top-K sampling with OPT 1.3B and 2.7B models to test the DBpedia CLASS dataset), even the public detection algorithm generates more false negatives cases and our private detection methods would also decrease in performance.  With a properly selected z-value threshold, the private watermarking algorithm exhibits similar performance across different decoding methods, various language models, and disparate domain datasets, which demonstrates its strong generalizability and adaptability.

\input{tbls/ablation}


\subsection{Ablation study}

To further analyze the private watermark algorithm, we conduct an ablation study in Table \ref{tab:ablation}  to illustrate the effectiveness of shared token embedding for the detection network. Specifically, the experiment is conducted on the GPT2, OPT1.3B, and OPT2.7B language models on the C4 and DBPEDIA CLASS datasets. We have presented results under three different settings: using shared token embedding, not using shared token embedding, and fine-tuning shared token embedding.

As seen from Table \ref{tab:ablation}, without the shared layer, the proportion of false negatives (watermarked text not
detected) and false positives (human text falsely flagged as watermarked) dramatically decreases on an average of $15.1\%$ and $32.0\%$ respectively. This renders the entire detection algorithm almost inapplicable. Concurrently, although fine-tuning the shared layer reduces the occurrence of false negatives, it also introduces some instances of wrongly tagged human text. Given that mistakenly recognizing human text as the watermarked text presents more severe consequences, we eventually choose to adopt the method without fine-tuning the shared layer.


% Figure environment removed


\subsection{Hyper-parameters Analysis}

To better understand how the private watermark algorithm works, we perform a series of analyses on several key hyper-parameters. Specifically, we tested the influence of different z value thresholds and $\delta$ values in Figure \ref{fig:z} (a) and Figure \ref{fig:z} (b) respectively. When analyzing different z value thresholds, the value of $\delta$ is set to 2.0, and when analyzing different $\delta$ values, the value of z is set to 4.

From Figure \ref{fig:z} (a), it can be observed that with the z-value threshold increases, the number of false positives gradually decreases. At a z-value of 4, there are almost no false positive cases. In contrast, the rate of false negatives tends to increase with the z-value threshold. As a trade-off, we selected a z-value threshold of 4 for this work. Additionally, as shown in Figure \ref{fig:z} (b), both false positives and false negatives decrease as the value of $\delta$ increases. However, since an overly large $\delta$ value could potentially degrade text quality, we opted for a $\delta$  value of 2.

\subsection{Error Analysis}

To better analyze the error cases of the private watermark algorithm, we present the z-score distributions of both the human text and the watermarked text, as well as the detection accuracy of the algorithm at different z-score ranges in Figure \ref{fig:err}(a). These results are generated by GPT2 on the C4 dataset. As can be observed from Figure \ref{fig:err}(a), the human text and watermarked text exhibited a normal-like distribution centered around 0 and 9 respectively. The detection accuracy of the private watermark algorithm is relatively low only around the z-score threshold 4, while it is almost 100\% in other ranges. This suggests that for inputs with highly certain labels, our algorithm is quite reliable.

 % To conducted a more detailed analysis of the error cases of our private watermark algorithm, as shown in figure \ref{fig:err} (a). In this experiment, the watermark detection network uses a z value of 4 during training.  In this figure, we first compute the actual z-scores for all the test data, divide these z-scores into different ranges, and then perform statistical analysis on the detection accuracy for each range. As can be seen from figure \ref{fig:err} (a), all errors are concentrated near the threshold $z=4$. Therefore, the model only makes judgment errors on the confusing examples (near the threshold), while for cases with high confidence, it rarely makes mistakes.

 % Figure environment removed


\subsection{Watermark Generation Watermark Analysis}

Based on our analysis in the section \ref{sec:detect}, it is critical for the watermark generation network to generate a stable label ratio because the modified z-score calculation (equation \ref{new-z}) is dependent on the variance of the label ratio. Therefore, in this section, we calculate the actual mean and variance of the labels generated by the watermark generation network. 

Specifically, we train the watermark generation network using 5000 data items with strictly a 0.5 ratio of green labels, using the Adam optimizer \cite{kingma2014adam} with a learning rate of 0.001. As can be seen from figure \ref{fig:err} (b), the ratio of green labels gradually approaches the target value 0.5 with the training loss decreases, and its standard deviation also gradually diminishes. Ultimately, the standard deviation can be controlled within 0.02, corresponding to a variance of less than $4e-4$. According to equation \ref{new-z}, $\sigma^2  T$ could be nearly neglected in the final z-value calculation. We adopt the value 0.02 in the revised z-score calculation.

\subsection{Time Complexity Analysis}

Due to the private watermark generation process employing an additional watermark generation network, there is a risk of introducing an extra computational burden. Therefore, we analyze the time complexity of the watermark generation process in this section.

First, we compare the number of parameters in the watermark generation network and the language model. Our  watermark generation network only consists of 43k parameters, whereas GPT2, OPT1.3B, and OPT2.7B have 124M, 1.3B, and 2.7B parameters respectively. It is evident that compared to the large language models with an enormous number of parameters, the number of parameters in our watermark generation network can be considered almost negligible.

Then we analyze the actual running time. On a single Tesla V100 GPU, decoding a token in GPT2 requires 30ms, whereas incorporating our watermark generation network only adds an average of 1ms to the cost. For models with a larger number of parameters, such as OPT1.3B and OPT2.7B, the influence on the decoding time is even smaller. Hence, our watermark generation algorithm does not cause significant additional computational overhead.

\section{Conclusion}

In this work, we have proposed the first private watermarking algorithm. Unlike previous works that detect watermarks by calculating the z-score using the key from the watermark generation phase, we detect watermarked text by a trained detection network. To facilitate the training of the watermark detection network, we also employ a neural network during the watermark generation phase and share token embeddings between the two networks. As demonstrated in the previous experimental stages, the detection accuracy achieved by our private watermarking algorithm is only slightly lower than that of the direct z-value calculation method. Meanwhile, further experiments demonstrate the strong adaptability of our algorithm. In future work, the details of watermark generation and detection can be further optimized. Meanwhile, enhancing the robustness of our private watermarking method is also an important direction.





\bibliography{references}{}
% \bibliographystyle{plain}
\bibliographystyle{unsrtnat}
\newpage
\appendix
\section{Case study}

To better illustrate the text generated by the watermarked LLM, we have listed some text examples from both the watermarked LLM and the non-watermarked LLM in Table \ref{tab:demo-examples}. We compare the z-scores and PPL scores between these texts. Specifically, when calculating PPL scores, we utilize the LLaMA 13B model \cite{touvron2023llama}. The results from table \ref{tab:demo-examples} demonstrate that the z-scores for texts generated by the watermarked LLM are significantly higher than those from the non-watermarked LLM, while there isn't a significant increase in the PPL scores.

\input{tbls/case}
\end{document}