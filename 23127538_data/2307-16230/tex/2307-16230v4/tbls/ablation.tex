


\begin{table}
\centering
% \small
\caption{The table presents an ablation study on the shared layer, contrasting the effects of using a shared layer (w. shared layer), not using a shared layer (w.o. shared layer), and with shared layer after fine-tuning (w. ft shared layer). }
\vspace{10pt}
\resizebox{0.76\linewidth}{!}{
\begin{tabular}{llrrrrrrrrr}
\toprule
\multicolumn{2}{c}{\multirow{2}{*}{Methods / Datasets}}  & \multicolumn{3}{c}{\textsc{C4}} & \multicolumn{3}{c}{\textsc{Dbpedia Class}}  \\
\cmidrule(lr){3-5}  \cmidrule(lr){6-8} 
&&FPR& FNR &  F1 &  FPR & FNR &  F1 \\ 
\midrule 
\multirow{3}{*}{GPT2} & w. shared-layers  & 0.2 & 1.1 & 99.3  & 0.6 & 1.4 & 99.0  \\
& w/o shared-layers& 0.0 & 99.76 & 0.5  & 0.9 & 68.1 & 47.5 \\
& w ft shared-layers& 0.2 & 16.2 & 90.9 & 0.6 & 13.4 & 92.5  \\
\midrule 
\multirow{3}{*}{OPT 1.3B}   & w. shared-layers & 0.2 & 4.7 & 97.5  & 0.8 & 3.1 & 98.0 \\
& w/o shared-layers & 0.0 & 100.0 & 0.0  & 0.0 & 99.4 & 1.3  \\
& w ft shared-layers & 0.0 & 22.3 & 87.3 & 0.2 & 25.9 & 84.8  \\
\midrule 
% \multirow{3}{*}{OPT 2.7B}  & w. shared-layer & 0.2 & 2.6 & 97.4 & 99.8 & 0.4 & 6.8 & 93.2 & 99.6 \\
% & w/o shared-layer & 48.0 & 15.3 & 84.7 & 52.0 & 12.2 & 48.8 & 51.2 & 87.8 \\
% & w ft shared-layer& 1.7 & 6.9 & 93.1 & 98.3 & 11.0 & 8.3 & 91.7 & 89.0 \\
% \midrule 
\multirow{3}{*}{LLaMA 7B}  & w. shared-layers & 0.4 & 3.2 & 98.2  & 1.2 & 3.7 & 97.5 \\
& w/o shared-layers & 1.2 & 81.0 & 31.4  & 42.0 & 11.4 & 76.9  \\
& w ft shared-layers& 0.2 & 21.3 & 87.8 & 1.0 & 31.3 & 79.6 \\
\bottomrule
\end{tabular}}

\label{tab:ablation}
\end{table}

