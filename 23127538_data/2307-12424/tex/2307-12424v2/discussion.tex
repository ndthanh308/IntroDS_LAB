\section{Conclusion}
\label{sec:discussion}

This paper presents an analysis of the impact of heterogeneous user rating behavior and personalized algorithms on the collection of ratings, using data from Piki, a music discovery platform. 
%
%Our methodology consisted of three stages, beginning with the analysis of a natural experiment in which the rating interface was dramatically modified. This natural experiment showed that the ratings interface change substantially changed user rating behavior. Furthermore, we found evidence that this reduction in the heterogeneity of user behavior improved the \textit{informational} effectiveness of the system. 
%Although a user's rating for an item was more determined by the user who was shown the item than the item's quality (as determined by other ratings) both before and after the change, the change increased the importance of item quality. 
%We conducted a randomized controlled trial (RCT) on the Piki platform with subtle changes to the interface and analyzed its results.
We analyzed the results of a randomized controlled trial (RCT) on the Piki platform.
The users were randomly assigned to different treatment groups, each with a different waiting time before they could "like" a song.
%The findings of this trial replicated the results of the natural experiment in a fine-grained manner and allowed us to analyze songs across treatment groups as well as how the effects are modulated by the recommendation algorithm. Finally, we conducted a simulation study calibrated with the results of the natural experiment and the RCT. The goal of this stage was to investigate the downstream consequences of the rating interface in terms of system performance, as defined by its ability to identify high-quality items and provide effective, personalized recommendations to each user. %The calibrated simulation setting gave us access to an item's "true" utility for each user, which is not directly available in any empirical setting.
Our research indicates that carefully designing the user interface can influence user behavior in a way that mitigates rating inflation. This leads to more informative ratings and affects downstream personalized recommendations. %However, such interface changes may have limits.
%
% Additionally, by reducing heterogeneity in user rating behavior, the system can provide more personalized recommendations that are better suited to the individual preferences of users. This can ultimately lead to a better user experience and increased satisfaction with the recommendation system.
%
% % \subsection{Discussion}
%
% \nikhil{I need to do a writing pass here} We have investigated the effect of interface design on user ratings in recommendation systems. Through controlled experiments using data from a music recommendation app, we have shown that changes in the interface design can have a substantial effect on user rating behavior. Specifically, we have shown that certain interface designs can lead to more picky ratings, which can have a positive impact on the accuracy and effectiveness of the recommendation system.
%
Our work has several implications for platform rating system design and future work. First, and most simply, item quality estimates as a function of ratings should not be viewed as sole functions of item quality; as we show, heterogeneous user behavior and personalized recommendation dynamics also play a large role. Second, platforms should consider several interventions to mitigate inflation. Here, we study rating interface changes, but algorithmic post-processing could also play a role. %Finally, consistent with the work of \citet{krauth2020offline}, our work shows that \textit{informational} measures need not correlate with downstream measures of interest -- our work emphasizes the importance of both kinds of analyses when analyzing ratings system changes. 


% \nikhil{I need to do a writing pass here} 
% There is significant user-level heterogeneity in ratings in online platforms. This means that different people have different levels of pickiness or preferences when it comes to rating products or services. It is important to consider this heterogeneity when analyzing ratings data, as it can impact the overall distribution of likes and individual-level pickiness.
% Modification of the interface in the Piki music app, through a ratings timer, has been shown to affect the distribution of ratings as well as the pickiness levels of individual users. Additionally, song ratings are often more a function of who rates the song rather than the true underlying quality of the song. In other words, the recommendation system and the specific users being recommended a song can play a larger role in determining its rating than the actual qualities of the song itself. This may be particularly true in the music domain, since taste plays an important role in ratings and the very notion of song quality may be highly contested, compared to e-commerce applications, where the quality of an item may seem more objective. 


% By carefully designing the interface, it is possible to influence user behavior in a way that leads to more accurate and informative ratings. This, in turn, can improve the quality of the recommendations provided by the system. Furthermore, by reducing the heterogeneity in user ratings behavior, the system can provide more personalized recommendations that are better suited to the individual preferences of users. This can ultimately lead to a better user experience and increased satisfaction with the recommendation system. Therefore, it is important to carefully consider the design of the interface when developing recommendation systems, as it can have a significant impact on the effectiveness of the recommendations provided to users in the long run.

%One of the key questions arising from our research is whether different interfaces lead to "better" recommendations. In terms of recovery to ground truth quality, our results suggest that interfaces that induce more picky ratings lead to more accurate recovery of ground truth quality. This is because picky ratings provide more information about the true quality of the items and reduce the influence of individual user's idiosyncrasies on the estimated item quality.



% \nikhil{I need to do a writing pass here} 
% The experiment highlights the significance of interface design in shaping user behavior. According to our findings, even subtle changes in interface design can result in changes in specific user behaviors, such as a reduction in pickiness and variance. We also found that both song quality and user behavior contribute to a song's mean rating. Furthermore, we found that estimated song quality depends on the type of recommendation, with personalized recommendations showing higher quality songs.

% As a result of these findings, it is essential to take into account both song quality and user behavior when designing and evaluating recommendation systems. However, it is important to note that our experiment has limitations. As we were unable to determine the "ground truth" rating of songs, we are unable to examine the potential effects of the interface on the recommendation systems, especially which leads to "better" recommendations. To further explore this, we conducted a simulation as described in section~\ref{sec:sim}.




% The change in the Piki app's interface design serves as an important example of the role of interface design in the evaluation of recommendation systems. However, there are several limitations to the described change that should be acknowledged. Firstly, there was low traffic in the months adjacent to the change, which may have affected the results of the evaluation. Additionally, the number of users who were present both before and after the change was low, which may have limited the ability to draw accurate conclusions from the data. Furthermore, the performance and balance of the recommendation algorithms used in the Pre-timers and Post-timers periods may have evolved, which could further limit the generalizability of the results.
% In order to address these limitations, we propose to conduct further experiment, as described in the \Cref{sec:experiment},  with more control over the timing and duration of the interface change, in order to observe the effects of these variables on the prediction of song ratings.




\textbf{Acknowledgements:} This work is partially sponsored by Meta Research Award, Jacobs Technion-Cornell Institute at Cornell Tech, and by Zuckerman Foundation.









