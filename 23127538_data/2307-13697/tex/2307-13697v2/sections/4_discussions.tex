\section{Discussions}

\subsection{Takeaway Messages}
In this paper, we present the following key findings:

\noindent \textbf{(1)} Generative data can improve downstream tasks on the most common categories. Obtaining generative data is not significantly more expensive than retrieval data, and it can lead to better performance in downstream tasks.

\noindent \textbf{(2)} The effectiveness of generative data is uncertain for fine-grained and rare categories, and careful selection of prompt strategies is required in these scenarios.

\noindent \textbf{(3)} We found that the effectiveness of generative data is closely related to the mean text similarity (MTS) of downstream tasks. In scenarios with low MTS, using Target-Initialized Generation (TIG) can generate images that are more suitable for downstream tasks.

\noindent \textbf{(4)} Using a few target images as the starting point for generation in TIG can significantly improve the quality of generated images and even outperform the use of original images in some cases.

\subsection{Future Directions and Limitations}
We view generative models as a cost-effective and controllable approach for obtaining high-quality external data. Leveraging retrieval augmentation and other advanced methods, we can further enhance generative models' performance on fine-grained and rare concepts, thereby promoting greater trustworthiness and fairness in downstream tasks. Additionally, our method has the potential to improve long-term learning efficiency, such as providing initial queries for active learning~\cite{chen2022making}.

In our study, we investigated the impact of using up to 500-shot per category (totaling over 1 million images on GenBench), and observed an upward performance trend in~\cref{fig:scaling_effect}. However, exploring the scaling law further with increased computational resources remains a promising direction. Future research should identify key characteristics of generative data and determine optimal scenarios for training downstream models. Increasing prompt diversity within generated images could significantly enhance their utility for model training. Nonetheless, ensuring that such diversity enhancements do not dilute core semantic information poses a challenging yet worthwhile research problem.