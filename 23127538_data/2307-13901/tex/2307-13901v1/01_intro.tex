\section{Introduction}
\label{sec:intro}

Object detection constitutes a pivotal task in the field of computer vision, entailing the critical process of identifying and localizing objects present within an image. Applications of object detection models include autonomous vehicles, surveillance, robotics, and augmented reality \cite{yolo_applications}. The central problem of deploying deep learning-based object detection solutions on embedded hardware platforms is the amount of computation, memory, and power required for their inference \cite{lane2017squeezing}. This necessitates the development of efficient object detection models specialized for low-footprint hardware devices to achieve the optimal trade-off of accuracy and latency.

% Figure environment removed

For years, the state-of-the-art deep learning approach to object detection has been the series of YOLO architectures \cite{yolo_survey}. In recent years, remarkable strides have been taken in advancing YOLO-like single-stage object detectors, prioritizing real-time operation while simultaneously striving for higher accuracy and deployability on low-power devices. 

These advancements have primarily focused on enhancing various components of the detection pipeline. Key areas of improvement include the design of accurate and efficient backbone and neck structures within the network \cite{wang2023yolov7}, exploration of different detection head designs (e.g. anchor-based \cite{wang2023yolov7} vs. anchor-free \cite{ge2021yolox}), utilization of diverse loss functions \cite{dfl}, and implementation of novel training procedures including innovative data augmentation techniques \cite{dataaug}. 
These collective efforts have continually refined and evolved YOLO-like architectures, enhancing object detection effectiveness and efficiency in real-time scenarios. The differences between consecutive YOLO versions, such as YOLOv5 \cite{Jocher_YOLOv5_by_Ultralytics_2020} and YOLOv6 \cite{li2023yolov6}, span various pipeline components, making it challenging to isolate their individual contributions. This paper aims to address these challenges by providing a fair comparison of recent YOLO versions under controlled conditions (e.g. same training loop for all models) to
demonstrate the impact of the backbone and neck structure of
YOLO-based models in embedded inference applications. 
We also use the collected accuracy and latency data for multiple YOLO-based detector variations to empirically evaluate training-free performance predictors commonly used in neural architecture search \cite{abdelfattah2021zero}. We summarize our contributions as follows: 


\begin{itemize}
    \item We provide a latency-accuracy benchmark of $550$+ YOLO-based object detection models on $4$ different datasets, called \textit{YOLOBench}. All the models are validated on $4$ different embedded hardware platforms (Intel CPU, ARM CPU, Nvidia GPU, NPU),

    \item We show that if modern detection heads and training techniques are implemented for the detector training pipeline, multiple backbone and neck variations, including those of older architectures (e.g. YOLOv3 and YOLOv4), can be used to achieve state-of-the-art latency-accuracy trade-off,
    
    

    \item Looking at \textit{YOLOBench} as a neural architecture search (NAS) space, we demonstrate that, while most of the state-of-the-art zero-cost (training-free) proxies for model accuracy estimation are outperformed by simple baselines such as MAC count, the NWOT estimator \cite{mellor2021neural} can be effectively used to identify potential Pareto-optimal YOLO detectors in a training-free manner,
    

    \item We showcase the effectiveness of the NWOT estimator for
    optimal detector prediction by using it to identify a
    YOLO-like model with FBNetV3 backbone that outperforms YOLOv8 on Raspberry Pi 4 ARM CPU.
    
\end{itemize}


