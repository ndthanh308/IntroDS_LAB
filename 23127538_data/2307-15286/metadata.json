{
  "title": "Multilingual Lexical Simplification via Paraphrase Generation",
  "authors": [
    "Kang Liu",
    "Jipeng Qiang",
    "Yun Li",
    "Yunhao Yuan",
    "Yi Zhu",
    "Kaixun Hua"
  ],
  "submission_date": "2023-07-28T03:47:44+00:00",
  "revised_dates": [],
  "abstract": "Lexical simplification (LS) methods based on pretrained language models have made remarkable progress, generating potential substitutes for a complex word through analysis of its contextual surroundings. However, these methods require separate pretrained models for different languages and disregard the preservation of sentence meaning. In this paper, we propose a novel multilingual LS method via paraphrase generation, as paraphrases provide diversity in word selection while preserving the sentence's meaning. We regard paraphrasing as a zero-shot translation task within multilingual neural machine translation that supports hundreds of languages. After feeding the input sentence into the encoder of paraphrase modeling, we generate the substitutes based on a novel decoding strategy that concentrates solely on the lexical variations of the complex word. Experimental results demonstrate that our approach surpasses BERT-based methods and zero-shot GPT3-based method significantly on English, Spanish, and Portuguese.",
  "categories": [
    "cs.CL"
  ],
  "primary_category": "cs.CL",
  "doi": null,
  "journal_ref": "ECAI 2023",
  "arxiv_id": "2307.15286",
  "pdf_url": "https://arxiv.org/pdf/2307.15286v1",
  "comment": null,
  "num_versions": null,
  "size_before_bytes": 1190157,
  "size_after_bytes": 1025874
}