@article{park2020population,
  title={Population estimates for the {UK}, {E}ngland and {W}ales, {S}cotland and {N}orthern {I}reland, provisional: mid-2019},
  author={Park, Neil},
  journal={Hampshire: Office for National Statistics},
  year={2020}
}


IEEEfull.bib
V1.12 (2007/01/11)
Copyright (c) 2002-2007 by Michael Shell
See: http://www.michaelshell.org/
for current contact information.

BibTeX bibliography string definitions of the FULL titles of
IEEE journals and magazines and online publications.

This file is designed for bibliography styles that require 
full-length titles and is not for use in bibliographies that
abbreviate titles.

Support sites:
http://www.michaelshell.org/tex/ieeetran/
http://www.ctan.org/tex-archive/macros/latex/contrib/IEEEtran/
and/or
http://www.ieee.org/

Special thanks to Laura Hyslop and ken Rawson of IEEE for their help
in obtaining the information needed to compile this file. Also,
Volker Kuhlmann and Moritz Borgmann kindly provided some corrections
and additions.

*************************************************************************
Legal Notice:
This code is offered as-is without any warranty either expressed or
implied; without even the implied warranty of MERCHANTABILITY or
FITNESS FOR A PARTICULAR PURPOSE! 
User assumes all risk.
In no event shall IEEE or any contributor to this code be liable for
any damages or losses, including, but not limited to, incidental,
consequential, or any other damages, resulting from the use or misuse
of any information contained here.

All comments are the opinions of their respective authors and are not
necessarily endorsed by the IEEE.

This work is distributed under the LaTeX Project Public License (LPPL)
( http://www.latex-project.org/ ) version 1.3, and may be freely used,
distributed and modified. A copy of the LPPL, version 1.3, is included
in the base LaTeX documentation of all distributions of LaTeX released
2003/12/01 or later.
Retain all contribution notices and credits.
** Modified files should be clearly indicated as such, including  **
** renaming them and changing author support contact information. **

File list of work: IEEEabrv.bib, IEEEfull.bib, IEEEexample.bib,
                   IEEEtran.bst, IEEEtranS.bst, IEEEtranSA.bst,
                   IEEEtranN.bst, IEEEtranSN.bst, IEEEtran_bst_HOWTO.pdf
*************************************************************************


USAGE:

\bibliographystyle{mybstfile}
\bibliography{IEEEfull,mybibfile}

where the IEEE titles in the .bib database entries use the strings
defined here. e.g.,


   journal = IEEE_J_AC,


to yield "{IEEE} Transactions on Automatic Control"


WARNING: IEEE uses abbreviated journal titles in their bibliographies!
Because this file provides the full titles, you should NOT use this file
for work that is to be submitted to the IEEE.

For IEEE work, you should use the abbreviated titles provided in the
companion file, IEEEabrv.bib.


** NOTES **

 1. Journals have been grouped according to subject in order to make it
    easier to locate and extract the definitions for related journals - 
    as most works use references that are confined to a single topic.
    Magazines are listed in straight alphabetical order.

 2. String names are closely based on IEEE's own internal acronyms.

 3. Older, out-of-print IEEE titles are included (but not including titles
    dating prior to IEEE's formation from the IRE and AIEE in 1963).






IEEE Journals 



aerospace and military
@STRING{IEEE_J_AES        = "{IEEE} Transactions on Aerospace and Electronic Systems"}
@STRING{IEEE_J_ANE        = "{IEEE} Transactions on Aerospace and Navigational Electronics"}
@STRING{IEEE_J_ANNE       = "{IEEE} Transactions on Aeronautical and Navigational Electronics"}
@STRING{IEEE_J_AS         = "{IEEE} Transactions on Aerospace"}
@STRING{IEEE_J_AIRE       = "{IEEE} Transactions on Airborne Electronics"}
@STRING{IEEE_J_MIL        = "{IEEE} Transactions on Military Electronics"}



autos, transportation and vehicles (non-aerospace)
@STRING{IEEE_J_ITS        = "{IEEE} Transactions on Intelligent Transportation Systems"}
@STRING{IEEE_J_VT         = "{IEEE} Transactions on Vehicular Technology"}
@STRING{IEEE_J_VC         = "{IEEE} Transactions on Vehicular Communications"}



circuits, signals, systems, audio and controls
@STRING{IEEE_J_SPL        = "{IEEE} Signal Processing Letters"}
@STRING{IEEE_J_ASSP       = "{IEEE} Transactions on Acoustics, Speech, and Signal Processing"}
@STRING{IEEE_J_AU         = "{IEEE} Transactions on Audio"}
@STRING{IEEE_J_AUEA       = "{IEEE} Transactions on Audio and Electroacoustics"}
@STRING{IEEE_J_AC         = "{IEEE} Transactions on Automatic Control"}
@STRING{IEEE_J_CAS        = "{IEEE} Transactions on Circuits and Systems"}
@STRING{IEEE_J_CASVT      = "{IEEE} Transactions on Circuits and Systems for Video Technology"}
@STRING{IEEE_J_CASI       = "{IEEE} Transactions on Circuits and Systems---Part {I}: Fundamental Theory and Applications"}
@STRING{IEEE_J_CASII      = "{IEEE} Transactions on Circuits and Systems---Part {II}: Analog and Digital Signal Processing"}
in 2004 CASI and CASII renamed part title to CASI_RP and CASII_EB, respectively.
@STRING{IEEE_J_CASI_RP    = "{IEEE} Transactions on Circuits and Systems---Part {I}: Regular Papers"}
@STRING{IEEE_J_CASII_EB   = "{IEEE} Transactions on Circuits and Systems---Part {II}: Express Briefs"}
@STRING{IEEE_J_CT         = "{IEEE} Transactions on Circuit Theory"}
@STRING{IEEE_J_CST        = "{IEEE} Transactions on Control Systems Technology"}
@STRING{IEEE_J_SP         = "{IEEE} Transactions on Signal Processing"}
@STRING{IEEE_J_SU         = "{IEEE} Transactions on Sonics and Ultrasonics"}
@STRING{IEEE_J_SAP        = "{IEEE} Transactions on Speech and Audio Processing"}
@STRING{IEEE_J_UE         = "{IEEE} Transactions on Ultrasonics Engineering"}
@STRING{IEEE_J_UFFC       = "{IEEE} Transactions on Ultrasonics, Ferroelectrics, and Frequency Control"}



communications
@STRING{IEEE_J_COML       = "{IEEE} Communications Letters"}
@STRING{IEEE_J_JSAC       = "{IEEE} Journal on Selected Areas in Communications"}
@STRING{IEEE_J_COM        = "{IEEE} Transactions on Communications"}
@STRING{IEEE_J_COMT       = "{IEEE} Transactions on Communication Technology"}
@STRING{IEEE_J_WCOM       = "{IEEE} Transactions on Wireless Communications"}



components, packaging and manufacturing
@STRING{IEEE_J_ADVP       = "{IEEE} Transactions on Advanced Packaging"}
@STRING{IEEE_J_CHMT       = "{IEEE} Transactions on Components, Hybrids and Manufacturing Technology"}
@STRING{IEEE_J_CPMTA      = "{IEEE} Transactions on Components, Packaging and Manufacturing Technology---Part {A}"}
@STRING{IEEE_J_CPMTB      = "{IEEE} Transactions on Components, Packaging and Manufacturing Technology---Part {B}: Advanced Packaging"}
@STRING{IEEE_J_CPMTC      = "{IEEE} Transactions on Components, Packaging and Manufacturing Technology---Part {C}: Manufacturing"}
@STRING{IEEE_J_CAPT       = "{IEEE} Transactions on Components and Packaging Technology"}
@STRING{IEEE_J_CAPTS      = "{IEEE} Transactions on Components and Packaging Technologies"}
@STRING{IEEE_J_CPART      = "{IEEE} Transactions on Component Parts"}
@STRING{IEEE_J_EPM        = "{IEEE} Transactions on Electronics Packaging Manufacturing"}
@STRING{IEEE_J_MFT        = "{IEEE} Transactions on Manufacturing Technology"}
@STRING{IEEE_J_PHP        = "{IEEE} Transactions on Parts, Hybrids and Packaging"}
@STRING{IEEE_J_PMP        = "{IEEE} Transactions on Parts, Materials and Packaging"}



CAD
@STRING{IEEE_J_TCAD       = "{IEEE} Journal on Technology in Computer Aided Design"}
@STRING{IEEE_J_CAD        = "{IEEE} Transactions on Computer-Aided Design of Integrated Circuits and Systems"}



coding, data, information, knowledge
@STRING{IEEE_J_IT         = "{IEEE} Transactions on Information Theory"}
@STRING{IEEE_J_KDE        = "{IEEE} Transactions on Knowledge and Data Engineering"}



computers, computation, networking and software
@STRING{IEEE_J_C          = "{IEEE} Transactions on Computers"}
@STRING{IEEE_J_CAL        = "{IEEE} Computer Architecture Letters"}
@STRING{IEEE_J_DSC        = "{IEEE} Transactions on Dependable and Secure Computing"}
@STRING{IEEE_J_ECOMP      = "{IEEE} Transactions on Electronic Computers"}
@STRING{IEEE_J_EVC        = "{IEEE} Transactions on Evolutionary Computation"}
@STRING{IEEE_J_FUZZ       = "{IEEE} Transactions on Fuzzy Systems"}
@STRING{IEEE_J_IFS        = "{IEEE} Transactions on Information Forensics and Security"}
@STRING{IEEE_J_MC         = "{IEEE} Transactions on Mobile Computing"}
@STRING{IEEE_J_NET        = "{IEEE/ACM} Transactions on Networking"}
@STRING{IEEE_J_NN         = "{IEEE} Transactions on Neural Networks"}
@STRING{IEEE_J_PDS        = "{IEEE} Transactions on Parallel and Distributed Systems"}
@STRING{IEEE_J_SE         = "{IEEE} Transactions on Software Engineering"}



computer graphics, imaging, and multimedia
@STRING{IEEE_J_JDT        = "{IEEE/OSA} Journal of Display Technology"}
@STRING{IEEE_J_IP         = "{IEEE} Transactions on Image Processing"}
@STRING{IEEE_J_MM         = "{IEEE} Transactions on Multimedia"}
@STRING{IEEE_J_VCG        = "{IEEE} Transactions on Visualization and Computer Graphics"}



cybernetics, ergonomics, robots, man-machine, and automation
@STRING{IEEE_J_ASE        = "{IEEE} Transactions on Automation Science and Engineering"}
@STRING{IEEE_J_JRA        = "{IEEE} Journal of Robotics and Automation"}
@STRING{IEEE_J_HFE        = "{IEEE} Transactions on Human Factors in Electronics"}
@STRING{IEEE_J_MMS        = "{IEEE} Transactions on Man-Machine Systems"}
@STRING{IEEE_J_PAMI       = "{IEEE} Transactions on Pattern Analysis and Machine Intelligence"}
in 1989 JRA became RA
in August 2004, RA split into ASE and RO
@STRING{IEEE_J_RA         = "{IEEE} Transactions on Robotics and Automation"}
@STRING{IEEE_J_RO         = "{IEEE} Transactions on Robotics"}
@STRING{IEEE_J_SMC        = "{IEEE} Transactions on Systems, Man, and Cybernetics"}
@STRING{IEEE_J_SMCA       = "{IEEE} Transactions on Systems, Man, and Cybernetics---Part {A}: Systems and Humans"}
@STRING{IEEE_J_SMCB       = "{IEEE} Transactions on Systems, Man, and Cybernetics---Part {B}: Cybernetics"}
@STRING{IEEE_J_SMCC       = "{IEEE} Transactions on Systems, Man, and Cybernetics---Part {C}: Applications and Reviews"}
@STRING{IEEE_J_SSC        = "{IEEE} Transactions on Systems Science and Cybernetics"}



earth, wind, fire and water
@STRING{IEEE_J_GE         = "{IEEE} Transactions on Geoscience Electronics"}
@STRING{IEEE_J_GRS        = "{IEEE} Transactions on Geoscience and Remote Sensing"}
@STRING{IEEE_J_GRSL       = "{IEEE} Geoscience and Remote Sensing Letters"}
@STRING{IEEE_J_OE         = "{IEEE} Journal of Oceanic Engineering"}



education, engineering, history, IEEE, professional
@STRING{IEEE_J_CJECE      = "Canadian Journal of Electrical and Computer Engineering"}
@STRING{IEEE_J_PROC       = "Proceedings of the {IEEE}"}
@STRING{IEEE_J_EDU        = "{IEEE} Transactions on Education"}
@STRING{IEEE_J_EM         = "{IEEE} Transactions on Engineering Management"}
@STRING{IEEE_J_EWS        = "{IEEE} Transactions on Engineering Writing and Speech"}
@STRING{IEEE_J_PC         = "{IEEE} Transactions on Professional Communication"}



electromagnetics, antennas, EMI, magnetics and microwave
@STRING{IEEE_J_AWPL       = "{IEEE} Antennas and Wireless Propagation Letters"}
@STRING{IEEE_J_MGWL       = "{IEEE} Microwave and Guided Wave Letters"}
@STRING{IEEE_J_MWCL       = "{IEEE} Microwave and Wireless Components Letters"}
@STRING{IEEE_J_AP         = "{IEEE} Transactions on Antennas and Propagation"}
@STRING{IEEE_J_EMC        = "{IEEE} Transactions on Electromagnetic Compatibility"}
@STRING{IEEE_J_MAG        = "{IEEE} Transactions on Magnetics"}
@STRING{IEEE_J_MTT        = "{IEEE} Transactions on Microwave Theory and Techniques"}
@STRING{IEEE_J_RFI        = "{IEEE} Transactions on Radio Frequency Interference"}
@STRING{IEEE_J_TJMJ       = "{IEEE} Translation Journal on Magnetics in Japan"}



energy and power
@STRING{IEEE_J_EC         = "{IEEE} Transactions on Energy Conversion"}
@STRING{IEEE_J_PEL        = "{IEEE} Power Electronics Letters"}
@STRING{IEEE_J_PWRAS      = "{IEEE} Transactions on Power Apparatus and Systems"}
@STRING{IEEE_J_PWRD       = "{IEEE} Transactions on Power Delivery"}
@STRING{IEEE_J_PWRE       = "{IEEE} Transactions on Power Electronics"}
@STRING{IEEE_J_PWRS       = "{IEEE} Transactions on Power Systems"}



industrial, commercial and consumer
@STRING{IEEE_J_APPIND     = "{IEEE} Transactions on Applications and Industry"}
@STRING{IEEE_J_BC         = "{IEEE} Transactions on Broadcasting"}
@STRING{IEEE_J_BCTV       = "{IEEE} Transactions on Broadcast and Television Receivers"}
@STRING{IEEE_J_CE         = "{IEEE} Transactions on Consumer Electronics"}
@STRING{IEEE_J_IE         = "{IEEE} Transactions on Industrial Electronics"}
@STRING{IEEE_J_IECI       = "{IEEE} Transactions on Industrial Electronics and Control Instrumentation"}
@STRING{IEEE_J_IA         = "{IEEE} Transactions on Industry Applications"}
@STRING{IEEE_J_IGA        = "{IEEE} Transactions on Industry and General Applications"}
@STRING{IEEE_J_IINF       = "{IEEE} Transactions on Industrial Informatics"}
@STRING{IEEE_J_PSE        = "{IEEE} Journal of Product Safety Engineering"}



instrumentation and measurement
@STRING{IEEE_J_IM         = "{IEEE} Transactions on Instrumentation and Measurement"}



insulation and materials
@STRING{IEEE_J_JEM        = "{IEEE/TMS} Journal of Electronic Materials"}
@STRING{IEEE_J_DEI        = "{IEEE} Transactions on Dielectrics and Electrical Insulation"}
@STRING{IEEE_J_EI         = "{IEEE} Transactions on Electrical Insulation"}



mechanical
@STRING{IEEE_J_MECH       = "{IEEE/ASME} Transactions on Mechatronics"}
@STRING{IEEE_J_MEMS       = "{IEEE/ASME} Journal of Microelectromechanical Systems"}



medical and biological
@STRING{IEEE_J_BME        = "{IEEE} Transactions on Biomedical Engineering"}
Note: The B-ME journal later dropped the hyphen and became the BME.
@STRING{IEEE_J_B-ME       = "{IEEE} Transactions on Bio-Medical Engineering"}
@STRING{IEEE_J_BMELC      = "{IEEE} Transactions on Bio-Medical Electronics"}
@STRING{IEEE_J_CBB        = "{IEEE/ACM} Transactions on Computational Biology and Bioinformatics"}
@STRING{IEEE_J_ITBM       = "{IEEE} Transactions on Information Technology in Biomedicine"}
@STRING{IEEE_J_ME         = "{IEEE} Transactions on Medical Electronics"}
@STRING{IEEE_J_MI         = "{IEEE} Transactions on Medical Imaging"}
@STRING{IEEE_J_NB         = "{IEEE} Transactions on NanoBioscience"}
@STRING{IEEE_J_NSRE       = "{IEEE} Transactions on Neural Systems and Rehabilitation Engineering"}
@STRING{IEEE_J_RE         = "{IEEE} Transactions on Rehabilitation Engineering"}



optics, lightwave and photonics
@STRING{IEEE_J_PTL        = "{IEEE} Photonics Technology Letters"}
@STRING{IEEE_J_JLT        = "{IEEE/OSA} Journal of Lightwave Technology"}



physics, electrons, nanotechnology, nuclear and quantum electronics
@STRING{IEEE_J_EDL        = "{IEEE} Electron Device Letters"}
@STRING{IEEE_J_JQE        = "{IEEE} Journal of Quantum Electronics"}
@STRING{IEEE_J_JSTQE      = "{IEEE} Journal of Selected Topics in Quantum Electronics"}
@STRING{IEEE_J_ED         = "{IEEE} Transactions on Electron Devices"}
@STRING{IEEE_J_NANO       = "{IEEE} Transactions on Nanotechnology"}
@STRING{IEEE_J_NS         = "{IEEE} Transactions on Nuclear Science"}
@STRING{IEEE_J_PS         = "{IEEE} Transactions on Plasma Science"}



reliability
@STRING{IEEE_J_DMR        = "{IEEE} Transactions on Device and Materials Reliability"}
@STRING{IEEE_J_R          = "{IEEE} Transactions on Reliability"}



semiconductors, superconductors, electrochemical and solid state
@STRING{IEEE_J_ESSL       = "{IEEE/ECS} Electrochemical and Solid-State Letters"}
@STRING{IEEE_J_JSSC       = "{IEEE} Journal of Solid-State Circuits"}
@STRING{IEEE_J_ASC        = "{IEEE} Transactions on Applied Superconductivity"}
@STRING{IEEE_J_SM         = "{IEEE} Transactions on Semiconductor Manufacturing"}



sensors
@STRING{IEEE_J_SENSOR     = "{IEEE} Sensors Journal"}



VLSI
@STRING{IEEE_J_VLSI       = "{IEEE} Transactions on Very Large Scale Integration ({VLSI}) Systems"}






IEEE Magazines



@STRING{IEEE_M_AES        = "{IEEE} Aerospace and Electronics Systems Magazine"}
@STRING{IEEE_M_HIST       = "{IEEE} Annals of the History of Computing"}
@STRING{IEEE_M_AP         = "{IEEE} Antennas and Propagation Magazine"}
@STRING{IEEE_M_ASSP       = "{IEEE} {ASSP} Magazine"}
@STRING{IEEE_M_CD         = "{IEEE} Circuits and Devices Magazine"}
@STRING{IEEE_M_CAS        = "{IEEE} Circuits and Systems Magazine"}
@STRING{IEEE_M_COM        = "{IEEE} Communications Magazine"}
@STRING{IEEE_M_COMSOC     = "{IEEE} Communications Society Magazine"}
@STRING{IEEE_M_CIM        = "{IEEE} Computational Intelligence Magazine"}
CSEM changed to CSE in 1999
@STRING{IEEE_M_CSE        = "{IEEE} Computing in Science and Engineering"}
@STRING{IEEE_M_CSEM       = "{IEEE} Computational Science and Engineering Magazine"}
@STRING{IEEE_M_C          = "{IEEE} Computer"}
@STRING{IEEE_M_CAP        = "{IEEE} Computer Applications in Power"}
@STRING{IEEE_M_CGA        = "{IEEE} Computer Graphics and Applications"}
@STRING{IEEE_M_CONC       = "{IEEE} Concurrency"}
@STRING{IEEE_M_CS         = "{IEEE} Control Systems Magazine"}
@STRING{IEEE_M_DTC        = "{IEEE} Design and Test of Computers"}
@STRING{IEEE_M_EI         = "{IEEE} Electrical Insulation Magazine"}
@STRING{IEEE_M_ETR        = "{IEEE} ElectroTechnology Review"}
@STRING{IEEE_M_EMB        = "{IEEE} Engineering in Medicine and Biology Magazine"}
@STRING{IEEE_M_EMR        = "{IEEE} Engineering Management Review"}
@STRING{IEEE_M_EXP        = "{IEEE} Expert"}
@STRING{IEEE_M_IA         = "{IEEE} Industry Applications Magazine"}
@STRING{IEEE_M_IM         = "{IEEE} Instrumentation and Measurement Magazine"}
@STRING{IEEE_M_IS         = "{IEEE} Intelligent Systems"}
@STRING{IEEE_M_IC         = "{IEEE} Internet Computing"}
@STRING{IEEE_M_ITP        = "{IEEE} {IT} Professional"}
@STRING{IEEE_M_MICRO      = "{IEEE} Micro"}
@STRING{IEEE_M_MW         = "{IEEE} Microwave Magazine"}
@STRING{IEEE_M_MM         = "{IEEE} Multimedia"}
@STRING{IEEE_M_NET        = "{IEEE} Network"}
@STRING{IEEE_M_PCOM       = "{IEEE} Personal Communications Magazine"}
@STRING{IEEE_M_POT        = "{IEEE} Potentials"}
CAP and PER merged to form PE in 2003
@STRING{IEEE_M_PE         = "{IEEE} Power and Energy Magazine"}
@STRING{IEEE_M_PER        = "{IEEE} Power Engineering Review"}
@STRING{IEEE_M_PVC        = "{IEEE} Pervasive Computing"}
@STRING{IEEE_M_RA         = "{IEEE} Robotics and Automation Magazine"}
@STRING{IEEE_M_SAP        = "{IEEE} Security and Privacy"}
@STRING{IEEE_M_SP         = "{IEEE} Signal Processing Magazine"}
@STRING{IEEE_M_S          = "{IEEE} Software"}
@STRING{IEEE_M_SPECT      = "{IEEE} Spectrum"}
@STRING{IEEE_M_TS         = "{IEEE} Technology and Society Magazine"}
@STRING{IEEE_M_VT         = "{IEEE} Vehicular Technology Magazine"}
@STRING{IEEE_M_WC         = "{IEEE} Wireless Communications Magazine"}
@STRING{IEEE_M_TODAY      = "Today's Engineer"}






IEEE Online Publications 



@STRING{IEEE_O_CSTO        = "{IEEE} Communications Surveys and Tutorials"}
@STRING{IEEE_O_DSO         = "{IEEE} Distributed Systems Online"}


@InProceedings{barker_asru2015,
  Title                    = {The third {CH}i{ME} speech separation and recognition challenge: dataset, task and baselines},
  Author                   = {J. Barker and R. Marxer and E. Vincent and S. Watanabe},
  Booktitle                = {Proc. IEEE ASRU 2015},
  Year                     = {2015},
  Address                  = {Scottsdale, Arizona, USA},
  Pages                    = {504-511}
}

@ARTICLE{6932438,  author={Xu, Yong and Du, Jun and Dai, Li-Rong and Lee, Chin-Hui},  journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing},   title={A Regression Approach to Speech Enhancement Based on Deep Neural Networks},   year={2015},  volume={23},  number={1},  pages={7-19},  doi={10.1109/TASLP.2014.2364452}}

@misc{defossez2020real,
      title={Real Time Speech Enhancement in the Waveform Domain}, 
      author={Alexandre Defossez and Gabriel Synnaeve and Yossi Adi},
      year={2020},
      eprint={2006.12847},
      archivePrefix={arXiv},
      primaryClass={eess.AS}
}

@misc{pascual2017segan,
      title={SEGAN: Speech Enhancement Generative Adversarial Network}, 
      author={Santiago Pascual and Antonio Bonafonte and Joan Serrà},
      year={2017},
      eprint={1703.09452},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{kingma2017adam,
      title={Adam: A Method for Stochastic Optimization}, 
      author={Diederik P. Kingma and Jimmy Ba},
      year={2017},
      eprint={1412.6980},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
@article{composite,
author = {Lin, Zhibin and Zhou, Lu and Qiu, Xiaojun},
year = {2019},
month = {02},
pages = {144-148},
title = {A composite objective measure on subjective evaluation of speech enhancement algorithms},
volume = {145},
journal = {Applied Acoustics},
doi = {10.1016/j.apacoust.2018.10.002}
}

@InProceedings{s_e_BLSTM,
author="Weninger, Felix
and Erdogan, Hakan
and Watanabe, Shinji
and Vincent, Emmanuel
and Le Roux, Jonathan
and Hershey, John R.
and Schuller, Bj{\"o}rn",
editor="Vincent, Emmanuel
and Yeredor, Arie
and Koldovsk{\'y}, Zbyn{\v{e}}k
and Tichavsk{\'y}, Petr",
title="Speech Enhancement with LSTM Recurrent Neural Networks and its Application to Noise-Robust ASR",
booktitle="Latent Variable Analysis and Signal Separation",
year="2015",
publisher="Springer International Publishing",
address="Cham",
pages="91--99",
abstract="We evaluate some recent developments in recurrent neural network (RNN) based speech enhancement in the light of noise-robust automatic speech recognition (ASR). The proposed framework is based on Long Short-Term Memory (LSTM) RNNs which are discriminatively trained according to an optimal speech reconstruction objective. We demonstrate that LSTM speech enhancement, even when used `na{\"i}vely' as front-end processing, delivers competitive results on the CHiME-2 speech recognition task. Furthermore, simple, feature-level fusion based extensions to the framework are proposed to improve the integration with the ASR back-end. These yield a best result of 13.76 {\%} average word error rate, which is, to our knowledge, the best score to date.",
isbn="978-3-319-22482-4"
}

@ARTICLE{stoi_loss,  author={Fu, Szu-Wei and Wang, Tao-Wei and Tsao, Yu and Lu, Xugang and Kawai, Hisashi},  journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing},   title={End-to-End Waveform Utterance Enhancement for Direct Evaluation Metrics Optimization by Fully Convolutional Neural Networks},   year={2018},  volume={26},  number={9},  pages={1570-1584},  doi={10.1109/TASLP.2018.2821903}}

@misc{fu2018qualitynet,
      title={Quality-Net: An End-to-End Non-intrusive Speech Quality Assessment Model based on BLSTM}, 
      author={Szu-Wei Fu and Yu Tsao and Hsin-Te Hwang and Hsin-Min Wang},
      year={2018},
      eprint={1808.05344},
      archivePrefix={arXiv},
      primaryClass={cs.SD}
}


@article{TIMIT,
author = {Garofolo, J. and Lamel, Lori and Fisher, W. and Fiscus, Jonathan and Pallett, D.},
year = {1993},
month = {01},
pages = {27403},
title = {DARPA TIMIT acoustic-phonetic continous speech corpus CD-ROM. NIST speech disc 1-1.1},
volume = {93},
journal = {NASA STI/Recon Technical Report N}
}


@article{DAEenhancementEXAMPLE,
author = {lu, Xugang and Tsao, Yu and Matsuda, Shigeki and Hori, C.},
year = {2013},
month = {01},
pages = {436-440},
title = {Speech enhancement based on deep denoising Auto-Encoder},
journal = {Proc. Interspeech}
}




@INPROCEEDINGS{7945915,  author={Kounovsky, Tomas and Malek, Jiri},  booktitle={2017 IEEE International Workshop of Electronics, Control, Measurement, Signals and their Application to Mechatronics (ECMSM)},   title={Single channel speech enhancement using convolutional neural network},   year={2017},  volume={},  number={},  pages={1-5},  doi={10.1109/ECMSM.2017.7945915}}
@ARTICLE{6887314,  author={Wang, Yuxuan and Narayanan, Arun and Wang, DeLiang},  journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing},   title={On Training Targets for Supervised Speech Separation},   year={2014},  volume={22},  number={12},  pages={1849-1858},  doi={10.1109/TASLP.2014.2352935}}
 @article{Davis_ieeetassp1980,
 author               = {S.B. Davis and P. Mermelstein},
 journal              = {IEEE Trans. Acoust. Speech Signal Process.},
 number               = {4},
 pages                = {357--366},
 title                = {Comparison of parametric representations for monosyllabic word recognition in continuously spoken sentences},
 volume               = {28},
 year                 = {1980},
 }
 
@book{10.5555/1203100,
author = {H\"{a}nsler, Eberhard and Schmidt, Gerhard},
title = {Topics in Acoustic Echo and Noise Control: Selected Methods for the Cancellation of Acoustical Echoes, the Reduction of Background Noise, and Speech Processing (Signals and Communication Technology)},
year = {2006},
isbn = {354033212X},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg}
}

@misc{musan2015,
  author = {David Snyder and Guoguo Chen and Daniel Povey},
  title = {{MUSAN}: {A} {M}usic, {S}peech, and {N}oise {C}orpus},
  year = {2015},
  eprint = {1510.08484},
  note = {arXiv:1510.08484v1}
}


@inproceedings{Liu2019,
  author={Bin Liu and Shuai Nie and Shan Liang and Wenju Liu and Meng Yu and Lianwu Chen and Shouye Peng and Changliang Li},
  title={{Jointly Adversarial Enhancement Training for Robust End-to-End Speech Recognition}},
  year=2019,
  booktitle={Proc. Interspeech 2019},
  pages={491--495},
  doi={10.21437/Interspeech.2019-1242},
  url={http://dx.doi.org/10.21437/Interspeech.2019-1242}
}
@INPROCEEDINGS{7178964,  author={Panayotov, Vassil and Chen, Guoguo and Povey, Daniel and Khudanpur, Sanjeev},  booktitle={2015 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},   title={Librispeech: An ASR corpus based on public domain audio books},   year={2015},  volume={},  number={},  pages={5206-5210},  doi={10.1109/ICASSP.2015.7178964}}

@inproceedings{aishell_2017,
  title={AIShell-1: An Open-Source Mandarin Speech Corpus and A Speech Recognition Baseline},
  author={Hui Bu Jiayu Du Xingyu Na Bengu Wu Hao Zheng},
  booktitle={Oriental COCOSDA 2017},
  pages={Submitted},
  year={2017}
}
@inproceedings{yi22b_interspeech,
  author={Gaoxiong Yi and Wei Xiao and Yiming Xiao and Babak Naderi and Sebastian Möller and Wafaa Wardah and Gabriel Mittag and Ross Culter and Zhuohuang Zhang and Donald S. Williamson and Fei Chen and Fuzheng Yang and Shidong Shang},
  title={{ConferencingSpeech 2022 Challenge: Non-intrusive Objective Speech Quality Assessment (NISQA) Challenge for Online Conferencing Applications}},
  year=2022,
  booktitle={Proc. Interspeech 2022},
  pages={3308--3312},
  doi={10.21437/Interspeech.2022-10597}
}
@misc{mbinet,
  doi = {10.48550/ARXIV.2204.03305},
  
  url = {https://arxiv.org/abs/2204.03305},
  
  author = {Zezario, Ryandhimas E. and Chen, Fei and Fuh, Chiou-Shann and Wang, Hsin-Min and Tsao, Yu},
  
  keywords = {Audio and Speech Processing (eess.AS), Machine Learning (cs.LG), Sound (cs.SD), FOS: Electrical engineering, electronic engineering, information engineering, FOS: Electrical engineering, electronic engineering, information engineering, FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {MBI-Net: A Non-Intrusive Multi-Branched Speech Intelligibility Prediction Model for Hearing Aids},
  
  publisher = {arXiv},
  
  year = {2022},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}
@inproceedings{tu22b_interspeech,
  author={Zehai Tu and Ning Ma and Jon Barker},
  title={{Unsupervised Uncertainty Measures of Automatic Speech Recognition for Non-intrusive Speech Intelligibility Prediction}},
  year=2022,
  booktitle={Proc. Interspeech 2022},
  pages={3493--3497},
  doi={10.21437/Interspeech.2022-10408}
}
@article{McKinney_2022,
	doi = {10.1109/lsp.2022.3161115},
  
	url = {https://doi.org/10.1109%2Flsp.2022.3161115},
  
	year = 2022,
	publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
  
	volume = {29},
  
	pages = {987--991},
  
	author = {Alex F. McKinney and Benjamin Cauchi},
  
	title = {Non-Intrusive Binaural Speech Intelligibility Prediction From Discrete Latent Representations},
  
	journal = {{IEEE} Signal Processing Letters}
}
@misc{sssr_quality1,
  doi = {10.48550/ARXIV.2110.02635},
  
  url = {https://arxiv.org/abs/2110.02635},
  
  author = {Cooper, Erica and Huang, Wen-Chin and Toda, Tomoki and Yamagishi, Junichi},
  
  keywords = {Audio and Speech Processing (eess.AS), FOS: Electrical engineering, electronic engineering, information engineering, FOS: Electrical engineering, electronic engineering, information engineering},
  
  title = {Generalization Ability of MOS Prediction Networks},
  
  publisher = {arXiv},
  
  year = {2021},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}


@inproceedings{becerra22_interspeech,
  author={Helard Becerra and Alessandro Ragano and Andrew Hines},
  title={{Exploring the influence of fine-tuning data on wav2vec 2.0 model for blind speech quality prediction}},
  year=2022,
  booktitle={Proc. Interspeech 2022},
  pages={4088--4092},
  doi={10.21437/Interspeech.2022-10766}
}
@misc{meta_phone_aware_se,
  doi = {10.48550/ARXIV.2206.11000},
  
  url = {https://arxiv.org/abs/2206.11000},
  
  author = {Tal, Or and Mandel, Moshe and Kreuk, Felix and Adi, Yossi},
  
  keywords = {Audio and Speech Processing (eess.AS), Machine Learning (cs.LG), Sound (cs.SD), FOS: Electrical engineering, electronic engineering, information engineering, FOS: Electrical engineering, electronic engineering, information engineering, FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {A Systematic Comparison of Phonetic Aware Techniques for Speech Enhancement},
  
  publisher = {arXiv},
  
  year = {2022},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}


@inproceedings{nisqa_pretrained_ss,
	doi = {10.21437/interspeech.2022-10147},
  
	year = 2022,
	month = {Sep},
  
	publisher = {{ISCA}
},
  
	author = {Bastiaan Tamm and Helena Balabin and Rik Vandenberghe and Hugo Van hamme},
  
	title = {Pre-trained Speech Representations as Feature Extractors for Speech Quality Assessment in Online Conferencing Applications},
  
	booktitle = {Interspeech 2022}
}
@article{Stone1999TolerableHA,
  title={Tolerable hearing aid delays. I. Estimation of limits imposed by the auditory path alone using simulated hearing losses.},
  author={Michael Anthony Stone and Brian C. J. Moore},
  journal={Ear and hearing},
  year={1999},
  volume={20 3},
  pages={
          182-92
        }
}


@inproceedings{barker22_interspeech,
  author={Jon Barker and Michael Akeroyd and Trevor J. Cox and John F. Culling and Jennifer Firth and Simone Graetzer and Holly Griffiths and Lara Harris and Graham Naylor and Zuzanna Podwinska and Eszter Porter and Rhoddy Viveros Munoz},
  title={{The 1st Clarity Prediction Challenge: A machine learning challenge for hearing aid intelligibility prediction}},
  year=2022,
  booktitle={Proc. Interspeech 2022},
  pages={3508--3512},
  doi={10.21437/Interspeech.2022-10821}
}
@inproceedings{NISQA,
	doi = {10.21437/interspeech.2021-299},
  
	url = {https://doi.org/10.21437%2Finterspeech.2021-299},
  
	year = 2021,
	month = {aug},
  
	publisher = {{ISCA}
},
  
	author = {Gabriel Mittag and Babak Naderi and Assmaa Chehadi and Sebastian Möller},
  
	title = {{NISQA}: A Deep {CNN}-Self-Attention Model for Multidimensional Speech Quality Prediction with Crowdsourced Datasets},
  
	booktitle = {Interspeech 2021}
}


@ARTICLE{stoi,  author={Taal, Cees H. and Hendriks, Richard C. and Heusdens, Richard and Jensen, Jesper},  journal={IEEE Transactions on Audio, Speech, and Language Processing},   title={An Algorithm for Intelligibility Prediction of Time–Frequency Weighted Noisy Speech},   year={2011},  volume={19},  number={7},  pages={2125-2136},  doi={10.1109/TASL.2011.2114881}}



@INPROCEEDINGS{pesq,  author={Rix, A.W. and Beerends, J.G. and Hollier, M.P. and Hekstra, A.P.},  booktitle={ICASSP 2001},   title={Perceptual evaluation of speech quality ({PESQ})-a new method for speech quality assessment of telephone networks and codecs},   year={2001},  volume={2},  number={},  pages={749-752 vol.2},  doi={10.1109/ICASSP.2001.941023}}


@INPROCEEDINGS{5495677,  author={Gerkmann, Timo and Krawczyk, Martin and Martin, Rainer},  booktitle={ICASSP 2010},   title={Speech presence probability estimation based on temporal cepstrum smoothing},   year={2010},  volume={},  number={},  pages={4254-4257},  doi={10.1109/ICASSP.2010.5495677}}

@INPROCEEDINGS{
         Povey_ASRU2011,
         author = {Povey, Daniel and Ghoshal, Arnab and Boulianne, Gilles and Burget, Lukas and Glembek, Ondrej and Goel, Nagendra and Hannemann, Mirko and Motlicek, Petr and Qian, Yanmin and Schwarz, Petr and Silovsky, Jan and Stemmer, Georg and Vesely, Karel},
       keywords = {ASR, Automatic Speech Recognition, GMM, HTK, SGMM},
          month = dec,
          title = {The Kaldi Speech Recognition Toolkit},
      booktitle = {IEEE 2011 Workshop on Automatic Speech Recognition and Understanding},
           year = {2011},
      publisher = {IEEE Signal Processing Society},
       location = {Hilton Waikoloa Village, Big Island, Hawaii, US},
           note = {IEEE Catalog No.: CFP11SRW-USB},
}
@ARTICLE{Gerkmann2012_NoisePowerEst,
  author={Gerkmann, Timo and Hendriks, Richard C.},
  journal={IEEE Transactions on Audio, Speech, and Language Processing}, 
  title={Unbiased MMSE-Based Noise Power Estimation With Low Complexity and Low Tracking Delay}, 
  year={2012},
  volume={20},
  number={4},
  pages={1383-1393},
  doi={10.1109/TASL.2011.2180896}}
@misc{matlabNR,
author = {Richard Hendriks (2021)},
title  = {Algorithm for Noise reduction for speech enhancement (https://www.mathworks.com/matlabcentral/fileexchange/46171-algorithm-for-noise-reduction-for-speech-enhancement), MATLAB Central File Exchange.},
data = {Retrieved August 12, 2021.}
}
@article{Bell2020,
abstract = {We present a structured overview of adaptation algorithms for neural network-based speech recognition, considering both hybrid hidden Markov model / neural network systems and end-to-end neural network systems, with a focus on speaker adaptation, domain adaptation, and accent adaptation. The overview characterizes adaptation algorithms as based on embeddings, model parameter adaptation, or data augmentation. We present a meta-analysis of the performance of speech recognition adaptation algorithms, based on relative error rate reductions as reported in the literature.},
archivePrefix = {arXiv},
arxivId = {2008.06580},
author = {Bell, Peter and Fainberg, Joachim and Klejch, Ondrej and Li, Jinyu and Renals, Steve and Swietojanski, Pawel},
doi = {10.1109/ojsp.2020.3045349},
eprint = {2008.06580},

file = {:home/george/Papers/Organised/Bell et al. - 2020 - Adaptation Algorithms for Neura. - 2020 - Adaptation Algorithms for Neural Network-Based Speech Recognition An Overview: - 2020 - Adaptation Algorithms for Neural Network-Based Speech Recognition An Overview},
journal = {IEEE Open Journal of Signal Processing},
pages = {33--66},
title = {{Adaptation Algorithms for Neural Network-Based Speech Recognition: An Overview}},
volume = {2},
year = {2020}
}
@inproceedings{edozezario22_interspeech,
  author={Ryandhimas {Edo Zezario} and Fei Chen and Chiou-Shann Fuh and Hsin-Min Wang and Yu Tsao},
  title={{MBI-Net: A Non-Intrusive Multi-Branched Speech Intelligibility Prediction Model for Hearing Aids}},
  year=2022,
  booktitle={Proc. Interspeech 2022},
  pages={3944--3948},
  doi={10.21437/Interspeech.2022-10838}
}
@misc{dubey2023icassp,
      title={ICASSP 2023 Deep Noise Suppression Challenge}, 
      author={Harishchandra Dubey and Ashkan Aazami and Vishak Gopal and Babak Naderi and Sebastian Braun and Ross Cutler and Alex Ju and Mehdi Zohourian and Min Tang and Hannes Gamper and Mehrsa Golestaneh and Robert Aichner},
      year={2023},
      eprint={2303.11510},
      archivePrefix={arXiv},
      primaryClass={cs.SD}
}
@inproceedings{close22_interspeech,
  author={George Close and Samuel Hollands and Stefan Goetze and Thomas Hain},
  title={{Non-intrusive Speech Intelligibility Metric Prediction for Hearing Impaired Individuals}},
  year=2022,
  booktitle={Proc.~Interspeech 2022},
  pages={3483--3487},
  doi={10.21437/Interspeech.2022-10182}
}
@inproceedings{gc-sssr_loss,
  doi = {10.48550/ARXIV.2301.04388},
  
  url = {https://arxiv.org/abs/2301.04388},
  
  author = {Close, George and Ravenscroft, William and Hain, Thomas and Goetze, Stefan},
  
  keywords = {Sound (cs.SD), Computation and Language (cs.CL), Machine Learning (cs.LG), Audio and Speech Processing (eess.AS), FOS: Computer and information sciences, FOS: Computer and information sciences, FOS: Electrical engineering, electronic engineering, information engineering, FOS: Electrical engineering, electronic engineering, information engineering},
  
  title = {Perceive and predict: self-supervised speech representation based loss functions for speech enhancement},

  booktitle={Proc.~ICASSP 2023},
  year = {2023},
  copyright = {Creative Commons Attribution 4.0 International}
}


@inproceedings{gc-mg-minus,
  doi = {10.48550/ARXIV.2203.12369},
  author = {Close, George and Hain, Thomas and Goetze, Stefan},
  keywords = {Sound (cs.SD), Machine Learning (cs.LG), Audio and Speech Processing (eess.AS), FOS: Computer and information sciences, FOS: Computer and information sciences, FOS: Electrical engineering, electronic engineering, information engineering, FOS: Electrical engineering, electronic engineering, information engineering},
  title = {{M}etric{GAN}+/-: {I}ncreasing {R}obustness of {N}oise {R}eduction on {U}nseen {D}ata},
  booktitle={EUSIPCO 2022},
  pages        = {},
  month        = {Aug.},
  address      = {Belgrade, Serbia},
  year = {2022},
}
@inproceedings{wav2vec,
 author = {Baevski, Alexei and Zhou, Yuhao and Mohamed, Abdelrahman and Auli, Michael},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Larochelle and M. Ranzato and R. Hadsell and M.F. Balcan and H. Lin},
 pages = {12449--12460},
 publisher = {Curran Associates, Inc.},
 title = {wav2vec 2.0: A Framework for Self-Supervised Learning of Speech Representations},
 url = {https://proceedings.neurips.cc/paper/2020/file/92d1e1eb1cd6f9fba3227870bb6d7f07-Paper.pdf},
 volume = {33},
 year = {2020}
}

@inproceedings{xlsr,
  author={Arun Babu and Changhan Wang and Andros Tjandra and Kushal Lakhotia and Qiantong Xu and Naman Goyal and Kritika Singh and Patrick {von Platen} and Yatharth Saraf and Juan Pino and Alexei Baevski and Alexis Conneau and Michael Auli},
  title={{XLS-R: Self-supervised Cross-lingual Speech Representation Learning at Scale}},
  year=2022,
  booktitle={Proc. Interspeech 2022},
  pages={2278--2282},
  doi={10.21437/Interspeech.2022-143}
}

@inproceedings{superb,
  author={Shu-wen Yang and Po-Han Chi and Yung-Sung Chuang and Cheng-I Jeff Lai and Kushal Lakhotia and Yist Y. Lin and Andy T. Liu and Jiatong Shi and Xuankai Chang and Guan-Ting Lin and Tzu-Hsien Huang and Wei-Cheng Tseng and Ko-tik Lee and Da-Rong Liu and Zili Huang and Shuyan Dong and Shang-Wen Li and Shinji Watanabe and Abdelrahman Mohamed and Hung-yi Lee},
  title={{SUPERB: Speech Processing Universal PERformance Benchmark}},
  year=2021,
  booktitle={Proc. Interspeech 2021},
  pages={1194--1198},
  doi={10.21437/Interspeech.2021-1775}
}

@inproceedings{transformer,
 author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, \L ukasz and Polosukhin, Illia},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {I. Guyon and U. Von Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
 title = {Attention is All you Need},
 url = {https://proceedings.neurips.cc/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf},
 volume = {30},
 year = {2017}
}

@inproceedings{bert,
    title = "{BERT}: Pre-training of Deep Bidirectional Transformers for Language Understanding",
    author = "Devlin, Jacob  and
      Chang, Ming-Wei  and
      Lee, Kenton  and
      Toutanova, Kristina",
    booktitle = "Proc. of ACL 2019",
    month = jun,
    year = "2019",
    address = "Minneapolis, Minnesota",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/N19-1423",
    doi = "10.18653/v1/N19-1423",
    pages = "4171--4186",
    abstract = "We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models (Peters et al., 2018a; Radford et al., 2018), BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5 (7.7 point absolute improvement), MultiNLI accuracy to 86.7{\%} (4.6{\%} absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement).",
}
@misc{clarity_project,
  doi = {10.48550/ARXIV.2006.11140},
  
  url = {https://arxiv.org/abs/2006.11140},
  
  author = {Graetzer, Simone and Akeroyd, Michael and Barker, Jon P. and Cox, Trevor J. and Culling, John F. and Naylor, Graham and Porter, Eszter and Muñoz, Rhoddy Viveros},
  
  keywords = {Audio and Speech Processing (eess.AS), FOS: Electrical engineering, electronic engineering, information engineering, FOS: Electrical engineering, electronic engineering, information engineering},
  
  title = {Clarity: Machine Learning Challenges to Revolutionise Hearing Device Processing},
  
  publisher = {arXiv},
  
  year = {2020},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}
@inproceedings{clarity_challenge,
  author={Simone Graetzer and Jon Barker and Trevor J. Cox and Michael Akeroyd and John F. Culling and Graham Naylor and Eszter Porter and Rhoddy Viveros Muñoz},
  title={{Clarity-2021 Challenges: Machine Learning Challenges for Advancing Hearing Aid Processing}},
  year=2021,
  booktitle={Proc. Interspeech 2021},
  pages={686--690},
  doi={10.21437/Interspeech.2021-1574}
}
@misc{chang2021multichannel,
      title={Multi-Channel Transformer Transducer for Speech Recognition}, 
      author={Feng-Ju Chang and Martin Radfar and Athanasios Mouchtaris and Maurizio Omologo},
      year={2021},
      eprint={2108.12953},
      archivePrefix={arXiv},
      primaryClass={eess.AS}
}
@inproceedings{10.3115/1075527.1075614,
author = {Paul, Douglas B. and Baker, Janet M.},
title = {The Design for the Wall Street Journal-Based CSR Corpus},
year = {1992},
isbn = {1558602720},
publisher = {Association for Computational Linguistics},
address = {USA},
url = {https://doi.org/10.3115/1075527.1075614},
doi = {10.3115/1075527.1075614},
abstract = {The DARPA Spoken Language System (SLS) community has long taken a leadership position
in designing, implementing, and globally distributing significant speech corpora widely
used for advancing speech recognition research. The Wall Street Journal (WSJ) CSR
Corpus described here is the newest addition to this valuable set of resources. In
contrast to previous corpora, the WSJ corpus will provide DARPA its first general-purpose
English, large vocabulary, natural language, high perplexity, corpus containing significant
quantities of both speech data (400 hrs.) and text data (47M words), thereby providing
a means to integrate speech recognition and natural language processing in application
domains with high potential practical value. This paper presents the motivating goals,
acoustic data design, text processing steps, lexicons, and testing paradigms incorporated
into the multi-faceted WSJ CSR Corpus.},
booktitle = {Proceedings of the Workshop on Speech and Natural Language},
pages = {357–362},
numpages = {6},
location = {Harriman, New York},
series = {HLT '91}
}
@misc{parvathala_kodukula_andhavarapu_2021, title={Neural Comb Filtering using Sliding Window Attention Network for Speech Enhancement}, url={https://www.techrxiv.org/articles/preprint/Neural_Comb_Filtering_using_Sliding_Window_Attention_Network_for_Speech_Enhancement/15051972/1}, DOI={10.36227/techrxiv.15051972.v1}, abstractNote={
In this paper, we demonstrate the significance of restoring harmonics of the fundamental frequency (pitch) in deep neural network (DNN) based speech enhancement. We propose a sliding-window attention network to regress the spectral magnitude mask (SMM) from the noisy speech signal. Even though the network parameters can be estimated by minimizing the mask loss, it does not restore the pitch harmonics, especially at higher frequencies. In this paper, we propose to restore the pitch harmonics in the spectral domain by minimizing cepstral loss around the pitch peak. The network parameters are estimated using a combination of the mask loss and cepstral loss. The proposed network architecture functions like an adaptive comb filter on voiced segments, and emphasizes the pitch harmonics in the speech spectrum. The proposed approach achieves comparable performance with the state-of-the-art methods with much lesser computational complexity.
}, publisher={TechRxiv}, author={Parvathala, Venkatesh and Kodukula, Sri Rama Murty and Andhavarapu, Siva Ganesh}, year={2021}, month={Jul} } 
@inproceedings{xue21_interspeech,
  author={Cheng Xue and Weilong Huang and Weiguang Chen and Jinwei Feng},
  title={{Real-Time Multi-Channel Speech Enhancement Based on Neural Network Masking with Attention Model}},
  year=2021,
  booktitle={Proc. Interspeech 2021},
  pages={1862--1866},
  doi={10.21437/Interspeech.2021-2266}
}
@misc{li2021embedding,
      title={Embedding and Beamforming: All-neural Causal Beamformer for Multichannel Speech Enhancement}, 
      author={Andong Li and Wenzhe Liu and Chengshi Zheng and Xiaodong Li},
      year={2021},
      eprint={2109.00265},
      archivePrefix={arXiv},
      primaryClass={cs.SD}
}
@inproceedings{fu2019metricgan,
      title={MetricGAN: Generative Adversarial Networks based Black-box Metric Scores Optimization for Speech Enhancement}, 
      author={Szu-Wei Fu and Chien-Feng Liao and Yu Tsao and Shou-De Lin},
      year={2019},
      booktitle={Proc. Interspeech 2019},
      eprint={1905.04874},
      archivePrefix={arXiv},
      primaryClass={cs.SD}
}



@misc{hubert,
  doi = {10.48550/ARXIV.2106.07447},
  
  url = {https://arxiv.org/abs/2106.07447},
  
  author = {Hsu, Wei-Ning and Bolte, Benjamin and Tsai, Yao-Hung Hubert and Lakhotia, Kushal and Salakhutdinov, Ruslan and Mohamed, Abdelrahman},
  
  keywords = {Computation and Language (cs.CL), Artificial Intelligence (cs.AI), Machine Learning (cs.LG), Audio and Speech Processing (eess.AS), FOS: Computer and information sciences, FOS: Computer and information sciences, FOS: Electrical engineering, electronic engineering, information engineering, FOS: Electrical engineering, electronic engineering, information engineering},
  
  title = {HuBERT: Self-Supervised Speech Representation Learning by Masked Prediction of Hidden Units},
  
  publisher = {arXiv},
  
  year = {2021},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}


@article{NRbook,
author = {Hendriks, Richard and Gerkmann, Timo and Jensen, Jesper},
year = {2013},
month = {01},
pages = {1-80},
title = {DFT-Domain Based Single-Microphone Noise Reduction for Speech Enhancement: A Survey of the State of the Art},
volume = {9},
journal = {Synthesis Lectures on Speech and Audio Processing},
doi = {10.2200/S00473ED1V01Y201301SAP011}
}
@article{bagchi2018spectral,
      title={Spectral feature mapping with mimic loss for robust speech recognition}, 
      author={Deblin Bagchi and Peter Plantinga and Adam Stiff and Eric Fosler-Lussier},
      year={2018},
      eprint={1803.09816},
      archivePrefix={arXiv},
      primaryClass={cs.SD}
}
@article{reddy2021dnsmos,
      title={DNSMOS: A Non-Intrusive Perceptual Objective Speech Quality metric to evaluate Noise Suppressors}, 
      author={Chandan K A Reddy and Vishak Gopal and Ross Cutler},
      year={2021},
      eprint={2010.15258},
      archivePrefix={arXiv},
      primaryClass={cs.SD}
}
@article{fu2021metricganu,
      title={MetricGAN-U: Unsupervised speech enhancement/ dereverberation based only on noisy/ reverberated speech}, 
      author={Szu-Wei Fu and Cheng Yu and Kuo-Hsuan Hung and Mirco Ravanelli and Yu Tsao},
      year={2021},
      eprint={2110.05866},
      archivePrefix={arXiv},
      primaryClass={cs.SD}
}
@inproceedings{reddy2021interspeech,
  title={INTERSPEECH 2021 Deep Noise Suppression Challenge},
  author={Reddy, Chandan KA and Dubey, Harishchandra and Koishida, Kazuhito and Nair, Arun and Gopal, Vishak and Cutler, Ross and Braun, Sebastian and Gamper, Hannes and Aichner, Robert and Srinivasan, Sriram},
  booktitle={INTERSPEECH},
  year={2021}
}


@article{chai2018acousticsguided,
      title={Acoustics-guided evaluation (AGE): a new measure for estimating performance of speech enhancement algorithms for robust ASR}, 
      author={Li Chai and Jun Du and Chin-Hui Lee},
      year={2018},
      eprint={1811.11517},
      archivePrefix={arXiv},
      primaryClass={eess.AS}
}


@ARTICLE{FFASRHaebUmbach,
  author={Haeb-Umbach, Reinhold and Heymann, Jahn and Drude, Lukas and Watanabe, Shinji and Delcroix, Marc and Nakatani, Tomohiro},
  journal={Proceedings of the IEEE}, 
  title={Far-Field Automatic Speech Recognition}, 
  year={2021},
  volume={109},
  number={2},
  pages={124-148},
  doi={10.1109/JPROC.2020.3018668}}
  
  @misc{li2021multimetric,
      title={Multi-Metric Optimization using Generative Adversarial Networks for Near-End Speech Intelligibility Enhancement}, 
      author={Haoyu Li and Junichi Yamagishi},
      year={2021},
      eprint={2104.08499},
      archivePrefix={arXiv},
      primaryClass={eess.AS}
}
@INPROCEEDINGS{dolcoMVDRenhance,
  author={Tammen, Marvin and Doclo, Simon},
  booktitle={ICASSP 2021 - 2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={Deep Multi-Frame MVDR Filtering for Single-Microphone Speech Enhancement}, 
  year={2021},
  volume={},
  number={},
  pages={8443-8447},
  doi={10.1109/ICASSP39728.2021.9413775}}
@misc{fu2021metricgan,
      title={MetricGAN+: An Improved Version of MetricGAN for Speech Enhancement}, 
      author={Szu-Wei Fu and Cheng Yu and Tsun-An Hsieh and Peter Plantinga and Mirco Ravanelli and Xugang Lu and Yu Tsao},
      year={2021},
      eprint={2104.03538},
      archivePrefix={arXiv},
      primaryClass={cs.SD}
}
@inproceedings{ValentiniBotinhao2016InvestigatingRS,
  title={Investigating RNN-based speech enhancement methods for noise-robust Text-to-Speech},
  author={Cassia Valentini-Botinhao and X. Wang and Shinji Takaki and J. Yamagishi},
  booktitle={SSW},
  year={2016}
}
  
  @ARTICLE{5547575,  author={Falk, Tiago H. and Zheng, Chenxi and Chan, Wai-Yip},  journal={IEEE Transactions on Audio, Speech, and Language Processing},   title={A Non-Intrusive Quality and Intelligibility Measure of Reverberant and Dereverberated Speech},   year={2010},  volume={18},  number={7},  pages={1766-1774},  doi={10.1109/TASL.2010.2052247}}
  
  @article{DBLP:journals/corr/abs-1808-05344,
  author    = {Szu{-}Wei Fu and
               Yu Tsao and
               Hsin{-}Te Hwang and
               Hsin{-}Min Wang},
  title     = {Quality-Net: An End-to-End Non-intrusive Speech Quality Assessment
               Model based on {BLSTM}},
  journal   = {CoRR},
  volume    = {abs/1808.05344},
  year      = {2018},
  url       = {http://arxiv.org/abs/1808.05344},
  archivePrefix = {arXiv},
  eprint    = {1808.05344},
  timestamp = {Fri, 20 Dec 2019 16:00:29 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1808-05344.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@misc{vb-demand,
title = {Noisy speech database for training speech enhancement algorithms and TTS models},
year = {2017},
author={Valentini-Botinhao, Cassia},
url={https://doi.org/10.7488/ds/2117}
}

@misc{demand,
  author       = {Thiemann, Joachim and
                  Ito, Nobutaka and
                  Vincent, Emmanuel},
  title        = {{DEMAND: a collection of multi-channel recordings 
                   of acoustic noise in diverse environments}},
  month        = jun,
  year         = 2013,
  note         = {{Supported by Inria under the Associate Team 
                   Program VERSAMUS}},
  publisher    = {Zenodo},
  version      = {1.0},
  doi          = {10.5281/zenodo.1227121},
  url          = {https://doi.org/10.5281/zenodo.1227121}
}

@misc{cs2022quality,
  doi = {10.48550/ARXIV.2203.16032},
  
  url = {https://arxiv.org/abs/2203.16032},
  
  author = {Yi, Gaoxiong and Xiao, Wei and Xiao, Yiming and Naderi, Babak and Möller, Sebastian and Wardah, Wafaa and Mittag, Gabriel and Cutler, Ross and Zhang, Zhuohuang and Williamson, Donald S. and Chen, Fei and Yang, Fuzheng and Shang, Shidong},
  
  keywords = {Sound (cs.SD), Audio and Speech Processing (eess.AS), FOS: Computer and information sciences, FOS: Computer and information sciences, FOS: Electrical engineering, electronic engineering, information engineering, FOS: Electrical engineering, electronic engineering, information engineering},
  
  title = {ConferencingSpeech 2022 Challenge: Non-intrusive Objective Speech Quality Assessment (NISQA) Challenge for Online Conferencing Applications},
  
  publisher = {arXiv},
  
  year = {2022},
  
  copyright = {Creative Commons Attribution 4.0 International}
}

@misc{user_pref_se_mos,
author = {Akihiko Sugiyama, Osamu Shimada, Toshiyuki Nomura},
title = {USER PREFERENCE BETWEEN RESIDUAL NOISE AND SPEECH DISTORTION IN SPEECH ENHANCEMENT},
year = {2022},
booktitle = {IWAENC 2022}
}


@misc{speechbrain,
    title={SpeechBrain: A General-Purpose Speech Toolkit},
    author={Mirco Ravanelli and Titouan Parcollet and Peter Plantinga and Aku Rouhe and Samuele Cornell and Loren Lugosch and Cem Subakan and Nauman Dawalatabad and Abdelwahab Heba and Jianyuan Zhong and Ju-Chieh Chou and Sung-Lin Yeh and Szu-Wei Fu and Chien-Feng Liao and Elena Rastorgueva and François Grondin and William Aris and Hwidong Na and Yan Gao and Renato De Mori and Yoshua Bengio},
    year={2021},
    eprint={2106.04624},
    archivePrefix={arXiv},
    primaryClass={eess.AS
    }
}
@misc{perceptual_quality_phone_fort,
  doi = {10.48550/ARXIV.2010.15174},
  
  url = {https://arxiv.org/abs/2010.15174},
  
  author = {Hsieh, Tsun-An and Yu, Cheng and Fu, Szu-Wei and Lu, Xugang and Tsao, Yu},
  
  keywords = {Sound (cs.SD), Machine Learning (cs.LG), Audio and Speech Processing (eess.AS), FOS: Computer and information sciences, FOS: Computer and information sciences, FOS: Electrical engineering, electronic engineering, information engineering, FOS: Electrical engineering, electronic engineering, information engineering},
  
  title = {Improving Perceptual Quality by Phone-Fortified Perceptual Loss using Wasserstein Distance for Speech Enhancement},
  
  publisher = {arXiv},
  
  year = {2020},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{kawanaka2020stable,
      title={Stable Training of DNN for Speech Enhancement based on Perceptually-Motivated Black-Box Cost Function}, 
      author={Masaki Kawanaka and Yuma Koizumi and Ryoichi Miyazaki and Kohei Yatabe},
      year={2020},
      eprint={2002.05879},
      archivePrefix={arXiv},
      primaryClass={eess.AS}
}

@PhdThesis{Wagener2004FactorsSI,
  author = {{Kirsten C.} Wagener},
  school = {Universit{\"{a}}t Oldenburg},
  title  = {Factors influencing sentence intelligibility in noise},
  year   = {2004},
}

@Article{Voelker_SI_2015,
  author  = {Völker, Christoph  and Warzybok, Anna and Ernst, {Stephan M.A.}},
  journal = {Trends in Hearing},
  title   = {{C}omparing {B}inaural {P}re-processing {S}trategies {III}: {S}peech {I}ntelligibility of {N}ormal-{H}earing and {H}earing-{I}mpaired {L}isteners},
  year    = {2015},
  volume  = {19},
  doi     = {10.1177/2331216515618609},
}

@INPROCEEDINGS{GXRRA10,
  author = {Stefan Goetze and Feifei Xiong and Jan Rennies and Thomas Rohdenburg and {Jens-E.}
	Appell},
  title = {Hands-Free Telecommunication for Elderly Persons Suffering from Hearing
	Deficiencies},
  booktitle = {IEEE Int.~Conf.~on E-Health Networking, Application
	and Services (Healthcom'10)},
  year = {2010},
}

@article{SI_MatrixTests_Multilingual,
author = {Birger Kollmeier and Anna Warzybok and Sabine Hochmuth and {Melanie A.} Zokoll and Verena Uslar and Thomas Brand and {Kirsten C.} Wagener},
title = {The multilingual matrix test: Principles, applications, and comparison across languages: A review},
journal = {International Journal of Audiology},
volume = {54},
number = {sup2},
pages = {3-16},
year  = {2015},
publisher = {Taylor & Francis},
doi = {10.3109/14992027.2015.1020971},
eprint = {https://doi.org/10.3109/14992027.2015.1020971}
,
    abstract = { Objective: A review of the development, evaluation, and application of the so-called ‘matrix sentence test’ for speech intelligibility testing in a multilingual society is provided. The format allows for repeated use with the same patient in her or his native language even if the experimenter does not understand the language. Design: Using a closed-set format, the syntactically fixed, semantically unpredictable sentences (e.g. ‘Peter bought eight white ships’) provide a vocabulary of 50 words (10 alternatives for each position in the sentence). The principles (i.e. construction, optimization, evaluation, and validation) for 14 different languages are reviewed. Studies of the influence of talker, language, noise, the training effect, open vs. closed conduct of the test, and the subjects’ language proficiency are reported and application examples are discussed. Results: The optimization principles result in a steep intelligibility function and a high homogeneity of the speech materials presented and test lists employed, yielding a high efficiency and excellent comparability across languages. The characteristics of speakers generally dominate the differences across languages. Conclusion: The matrix test format with the principles outlined here is recommended for producing efficient, reliable, and comparable speech reception thresholds across different languages. }
}
@misc{pasad2023comparative,
      title={Comparative layer-wise analysis of self-supervised speech models}, 
      author={Ankita Pasad and Bowen Shi and Karen Livescu},
      year={2023},
      eprint={2211.03929},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
@INPROCEEDINGS{10097097,
  author={Sicherman, Amitay and Adi, Yossi},
  booktitle={ICASSP 2023 - 2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={Analysing Discrete Self Supervised Speech Representation For Spoken Language Modeling}, 
  year={2023},
  volume={},
  number={},
  pages={1-5},
  doi={10.1109/ICASSP49357.2023.10097097}}

@article{atttasnet,
AUTHOR={Ravenscroft, William and Goetze, Stefan and Hain, Thomas},   
TITLE={{Att-TasNet: Attending to Encodings in Time-Domain Audio Speech Separation of Noisy, Reverberant Speech Mixtures}},      
JOURNAL={Frontiers in Signal Processing},      
YEAR={2022},     
VOLUME={2},     
ISSN={2673-8198}, 
DOI={10.3389/frsip.2022.856968},      
ABSTRACT={Separation of speech mixtures in noisy and reverberant environments remains a challenging task for state-of-the-art speech separation systems. Time-domain audio speech separation networks (TasNets) are among the most commonly used network architectures for this task. TasNet models have demonstrated strong performance on typical speech separation baselines where speech is not contaminated with noise. When additive or convolutive noise is present, performance of speech separation degrades significantly. TasNets are typically constructed of an encoder network, a mask estimation network and a decoder network. The design of these networks puts the majority of the onus for enhancing the signal on the mask estimation network when used without any pre-processing of the input data or post processing of the separation network output data. Use of multihead attention (MHA) is proposed in this work as an additional layer in the encoder and decoder to help the separation network attend to encoded features that are relevant to the target speakers and conversely suppress noisy disturbances in the encoded features. As shown in this work, incorporating MHA mechanisms into the encoder network in particular leads to a consistent performance improvement across numerous quality and intelligibility metrics on a variety of acoustic conditions using the WHAMR corpus, a data-set of noisy reverberant speech mixtures. The use of MHA is also investigated in the decoder network where it is demonstrated that smaller performance improvements are consistently gained within specific model configurations. The best performing MHA models yield a mean 0.6 dB scale invariant signal-to-distortion (SISDR) improvement on noisy reverberant mixtures over a baseline 1D convolution encoder. A mean 1 dB SISDR improvement is observed on clean speech mixtures.},
publisher={Frontiers}
}
--
EOF