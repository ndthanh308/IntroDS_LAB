@misc{haidt2020scrutinizing,
  title={Scrutinizing the effects of digital technology on mental health},
  author={Haidt, Jonathan and Allen, Nick},
  year={2020},
  publisher={Nature Publishing Group}
}

@misc{mental2022state,
  title={The state of mental health in America},
  author={Mental Health America},
  year={2022},
  publisher={Mental Health America}
}

@misc{mental2023stats,
    title={Mental Illness},
    url={https://www.nimh.nih.gov/health/statistics/mental-illness},
    journal={National Institute of Mental Health},
    year={2023},
    publisher={U.S. Department of Health and Human Services}
}

@misc{mentalcost2023,
    title={Mental Health By the Numbers},
    url={https://nami.org/mhstats},
    year={2023},
    journal={National Alliance on Mental Illness},
    publisher={National Alliance on Mental Illness}
} 

@article{world2022covid,
  title={COVID-19 pandemic triggers 25\% increase in prevalence of anxiety and depression worldwide},
  author={World Health Organization and others},
  journal={Retrieved from World Health Organization: https://www. who. int/news/item/02-03-2022-covid-19-pandemic-triggers-25-increase-in-prevalence-of-anxiety-and-depression-worldwide},
  year={2022}
}

@article{abuse2020key,
  title={Key substance use and mental health indicators in the United States},
  author={Abuse, Substance and others},
  journal={National Survey on Drug Use and Health},
  year={2020}
}

@book{rosen2015history,
  title={A history of public health},
  author={Rosen, George},
  year={2015},
  publisher={Jhu Press}
}

@article{yang_cross-domain_2007,
	title = {Cross-domain video concept detection using adaptive svms},
	doi = {10.1145/1291233.1291276},
	abstract = {Many multimedia applications can benefit from techniques for adapting existing classifiers to data with different distributions. One example is cross-domain video concept detection which aims to adapt concept classifiers across various video domains. In this paper, we explore two key problems for classifier adaptation: (1) how to transform existing classifier(s) into an effective classifier for a new dataset that only has a limited number of labeled examples, and (2) how to select the best existing classifier(s) for adaptation. For the first problem, we propose Adaptive Support Vector Machines (A-SVMs) as a general method to adapt one or more existing classifiers of any type to the new dataset. It aims to learn the "delta function" between the original and adapted classifier using an objective function similar to SVMs. For the second problem, we estimate the performance of each existing classifier on the sparsely-labeled new dataset by analyzing its score distribution and other meta features, and select the classifiers with the best estimated performance. The proposed method outperforms several baseline and competing methods in terms of classification accuracy and efficiency in cross-domain concept detection in the TRECVID corpus. Copyright 2007 ACM.},
	journal = {Proceedings of the ACM International Multimedia Conference and Exhibition},
	author = {Yang, Jun and Yan, Rong and Hauptmann, Alexander G.},
	year = {2007},
	note = {ISBN: 9781595937025},
	keywords = {Adaptive SVMs, Classifier adaptation, Cross-domain video concept detection},
	pages = {188--197},
	file = {Yang et al_2007_Cross-domain video concept detection using adaptive svms.pdf:/Users/orsonxu/Desktop/HCI/Literature Management/Zotero/Yang et al_2007_Cross-domain video concept detection using adaptive svms.pdf:application/pdf},
}


@article{gao_knowledge_2008,
	title = {Knowledge transfer via multiple model local structure mapping},
	doi = {10.1145/1401890.1401928},
	abstract = {The effectiveness of knowledge transfer using classification algorithms depends on the difference between the distribution that generates the training examples and the one from which test examples are to be drawn. The task can be especially difficult when the training examples are from one or several domains different from the test domain. In this paper, we propose a locally weighted ensemble framework to combine multiple models for transfer learning, where the weights are dynamically assigned according to a model's predictive power on each test example. It can integrate the advantages of various learning algorithms and the labeled information from multiple training domains into one unified classification model, which can then be applied on a different domain. Importantly, different from many previously proposed methods, none of the base learning method is required to be specifically designed for transfer learning. We show the optimality of a locally weighted ensemble framework as a general approach to combine multiple models for domain transfer. We then propose an implementation of the local weight assignments by mapping the structures of a model onto the structures of the test domain, and then weighting each model locally according to its consistency with the neighborhood structure around the test example. Experimental results on text classification, spam filtering and intrusion detection data sets demonstrate significant improvements in classification accuracy gained by the framework. On a transfer learning task of newsgroup message categorization, the proposed locally weighted ensemble framework achieves 97\% accuracy when the best single model predicts correctly only on 73\% of the test examples. In summary, the improvement in accuracy is over 10\% and up to 30\% across different problems. Copyright 2008 ACM.},
	journal = {Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
	author = {Gao, Jing and Fan, Wei and Jiang, Jing and Han, Jiawei},
	year = {2008},
	note = {ISBN: 9781605581934},
	keywords = {Algorithms},
	pages = {283--291},
	file = {Gao et al_2008_Knowledge transfer via multiple model local structure mapping.pdf:/Users/orsonxu/Desktop/HCI/Literature Management/Zotero/Gao et al_2008_Knowledge transfer via multiple model local structure mapping.pdf:application/pdf},
}

@article{dai_boosting_2007,
	title = {Boosting for transfer learning},
	volume = {227},
	doi = {10.1145/1273496.1273521},
	abstract = {Traditional machine learning makes a basic assumption: the training and test data should be under the same distribution. However, in many cases, this identical-distribution assumption does not hold. The assumption might be violated when a task from one new domain comes, while there are only labeled data from a similar old domain. Labeling the new data can be costly and it would also be a waste to throw away all the old data. In this paper, we present a novel transfer learning framework called TrAdaBoost, which extends boosting-based learning algorithms (Freund \& Schapire, 1997). TrAdaBoost allows users to utilize a small amount of newly labeled data to leverage the old data to construct a high-quality classification model for the new data. We show that this method can allow us to learn an accurate model using only a tiny amount of new data and a large amount of old data, even when the new data are not sufficient to train a model alone. We show that TrAdaBoost allows knowledge to be effectively transferred from the old data to the new. The effectiveness of our algorithm is analyzed theoretically and empirically to show that our iterative algorithm can converge well to an accurate model.},
	journal = {ACM International Conference Proceeding Series},
	author = {Dai, Wenyuan and Yang, Qiang and Xue, Gui Rong and Yu, Yong},
	year = {2007},
	pages = {193--200},
	file = {Dai et al_2007_Boosting for transfer learning.pdf:/Users/orsonxu/Desktop/HCI/Literature Management/Zotero/Dai et al_2007_Boosting for transfer learning.pdf:application/pdf},
}

@article{cai_generalizability_2020,
	title = {Generalizability of machine learning for classification of schizophrenia based on resting-state functional {MRI} data},
	volume = {41},
	issn = {10970193},
	doi = {10.1002/hbm.24797},
	abstract = {Machine learning has increasingly been applied to classification of schizophrenia in neuroimaging research. However, direct replication studies and studies seeking to investigate generalizability are scarce. To address these issues, we assessed within-site and between-site generalizability of a machine learning classification framework which achieved excellent performance in a previous study using two independent resting-state functional magnetic resonance imaging data sets collected from different sites and scanners. We established within-site generalizability of the classification framework in the main data set using cross-validation. Then, we trained a model in the main data set and investigated between-site generalization in the validated data set using external validation. Finally, recognizing the poor between-site generalization performance, we updated the unsupervised algorithm to investigate if transfer learning using additional unlabeled data were able to improve between-site classification performance. Cross-validation showed that the published classification procedure achieved an accuracy of 0.73 using majority voting across all selected components. External validation found a classification accuracy of 0.55 (not significant) and 0.70 (significant) using the direct and transfer learning procedures, respectively. The failure of direct generalization from one site to another demonstrates the limitation of within-site cross-validation and points toward the need to incorporate efforts to facilitate application of machine learning across multiple data sets. The improvement in performance with transfer learning highlights the importance of taking into account the properties of data when constructing predictive models across samples and sites. Our findings suggest that machine learning classification result based on a single study should be interpreted cautiously.},
	number = {1},
	journal = {Human Brain Mapping},
	author = {Cai, Xin Lu and Xie, Dong Jie and Madsen, Kristoffer H. and Wang, Yong Ming and Bögemann, Sophie Alida and Cheung, Eric F.C. and Møller, Arne and Chan, Raymond C.K.},
	year = {2020},
	keywords = {machine learning, generalizability, reproducibility, schizophrenia spectrum disorders},
	pages = {172--184},
	file = {Cai et al_2020_Generalizability of machine learning for classification of schizophrenia based on resting-state functional MRI data.pdf:/Users/orsonxu/Desktop/HCI/Literature Management/Zotero/Cai et al_2020_Generalizability of machine learning for classification of schizophrenia based on resting-state functional MRI data.pdf:application/pdf},
}

@article{wu_negations_2014,
	title = {Negation's not solved: {Generalizability} versus optimizability in clinical natural language processing},
	volume = {9},
	issn = {19326203},
	doi = {10.1371/journal.pone.0112774},
	abstract = {A review of published work in clinical natural language processing (NLP) may suggest that the negation detection task has been ''solved.'' This work proposes that an optimizable solution does not equal a generalizable solution. We introduce a new machine learning-based Polarity Module for detecting negation in clinical text, and extensively compare its performance across domains. Using four manually annotated corpora of clinical text, we show that negation detection performance suffers when there is no in-domain development (for manual methods) or training data (for machine learning-based methods). Various factors (e.g., annotation guidelines, named entity characteristics, the amount of data, and lexical and syntactic context) play a role in making generalizability difficult, but none completely explains the phenomenon. Furthermore, generalizability remains challenging because it is unclear whether to use a single source for accurate data, combine all sources into a single model, or apply domain adaptation methods. The most reliable means to improve negation detection is to manually annotate in-domain training data (or, perhaps, manually modify rules); this is a strategy for optimizing performance, rather than generalizing it. These results suggest a direction for future work in domain-adaptive and task-adaptive methods for clinical NLP. Copyright:},
	number = {11},
	journal = {PLoS ONE},
	author = {Wu, Stephen and Miller, Timothy and Masanz, James and Coarr, Matt and Halgrim, Scott and Carrell, David and Clark, Cheryl},
	year = {2014},
	file = {Wu et al_2014_Negation's not solved.pdf:/Users/orsonxu/Desktop/HCI/Literature Management/Zotero/Wu et al_2014_Negation's not solved.pdf:application/pdf},
}

@article{wah_generalization_1999,
	title = {Generalization and generalizability measures},
	volume = {11},
	issn = {10414347},
	doi = {10.1109/69.755626},
	abstract = {In this paper, we define the generalization problem, summarize various approaches in generalization, identify the credit assignment problem, and present the problem and some solutions in measuring generalizability. We discuss anomalies in the ordering of hypotheses in a subdomain when performance is normalized and averaged, and show conditions under which anomalies can be eliminated. To generalize performance across subdomains, we present a measure called probability of win that measures the probability whether one hypothesis is better than another. Finally, we discuss some limitations in using probabilities of win and illustrate their application in finding new parameter values for TimberWolf, a package for VLSI cell placement and routing.},
	number = {1},
	journal = {IEEE Transactions on Knowledge and Data Engineering},
	author = {Wah, Benjamin W.},
	year = {1999},
	pages = {175--186},
	file = {Wah_1999_Generalization and generalizability measures.pdf:/Users/orsonxu/Desktop/HCI/Literature Management/Zotero/Wah_1999_Generalization and generalizability measures.pdf:application/pdf},
}

@article{daume_frustratingly_2007,
	title = {Frustratingly easy domain adaptation},
	abstract = {We describe an approach to domain adaptation that is appropriate exactly in the case when one has enough "target" data to do slightly better than just using only "source" data. Our approach is incredibly simple, easy to implement as a preprocessing step (10 lines of Perl!) and outperforms stateof- the-art approaches on a range of datasets. Moreover, it is trivially extended to a multidomain adaptation problem, where one has data from a variety of different domains. © 2007 Association for Computational Linguistics.},
	journal = {ACL 2007 - Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics},
	author = {Daumé, Hal},
	year = {2007},
	note = {ISBN: 9781932432862},
	pages = {256--263},
	file = {Daumé_2007_Frustratingly easy domain adaptation.pdf:/Users/orsonxu/Desktop/HCI/Literature Management/Zotero/Daumé_2007_Frustratingly easy domain adaptation.pdf:application/pdf},
}

@article{qin_cross-dataset_2019,
	title = {Cross-{Dataset} {Activity} {Recognition} via {Adaptive} {Spatial}-{Temporal} {Transfer} {Learning}},
	volume = {3},
	issn = {2474-9567},
	url = {https://dl.acm.org/doi/10.1145/3369818},
	doi = {10.1145/3369818},
	abstract = {Human activity recognition (HAR) aims at recognizing activities by training models on the large quantity of sensor data. Since it is time-consuming and expensive to acquire abundant labeled data, transfer learning becomes necessary for HAR by transferring knowledge from existing domains. However, there are two challenges existing in cross-dataset activity recognition. The first challenge is source domain selection. Given a target task and several available source domains, it is difficult to determine how to select the most similar source domain to the target domain such that negative transfer can be avoided. The second one is accurately activity transfer. After source domain selection, how to achieve accurate knowledge transfer between the selected source and the target domain remains another challenge. In this paper, we propose an Adaptive Spatial-Temporal Transfer Learning (ASTTL) approach to tackle both of the above two challenges in cross-dataset HAR. ASTTL learns the spatial features in transfer learning by adaptively evaluating the relative importance between the marginal and conditional probability distributions. Besides, it captures the temporal features via incremental manifold learning. Therefore, ASTTL can learn the adaptive spatial-temporal features for cross-dataset HAR and can be used for both source domain selection and accurate activity transfer. We evaluate the performance of ASTTL through extensive experiments on 4 public HAR datasets, which demonstrates its effectiveness. Furthermore, based on ASTTL, we design and implement an adaptive cross-dataset HAR system called Client-Cloud Collaborative Adaptive Activity Recognition System (3C2ARS) to perform HAR in the real environment. By collecting activities in the smartphone and transferring knowledge in the cloud server, ASTTL can significantly improve the performance of source domain selection and accurate activity transfer.},
	number = {4},
	journal = {Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies},
	author = {Qin, Xin and Chen, Yiqiang and Wang, Jindong and Yu, Chaohui},
	month = dec,
	year = {2019},
	keywords = {Transfer learning, Human activity recognition, Cross-dataset recognition, Domain adaptation},
	pages = {1--25},
	file = {Qin et al_2019_Cross-Dataset Activity Recognition via Adaptive Spatial-Temporal Transfer Learning.pdf:/Users/orsonxu/Desktop/HCI/Literature Management/Zotero/Qin et al_2019_Cross-Dataset Activity Recognition via Adaptive Spatial-Temporal Transfer Learning.pdf:application/pdf},
}

@article{thambawita_extensive_2020,
	title = {An {Extensive} {Study} on {Cross}-{Dataset} {Bias} and {Evaluation} {Metrics} {Interpretation} for {Machine} {Learning} {Applied} to {Gastrointestinal} {Tract} {Abnormality} {Classification}},
	volume = {1},
	issn = {2691-1957},
	url = {https://dl.acm.org/doi/10.1145/3386295},
	doi = {10.1145/3386295},
	abstract = {Precise and efficient automated identification of Gastrointestinal (GI) tract diseases can help doctors treat more patients and improve the rate of disease detection and identification. Currently, automatic analysis of diseases in the GI tract is a hot topic in both computer science and medical-related journals. Nevertheless, the evaluation of such an automatic analysis is often incomplete or simply wrong. Algorithms are often only tested on small and biased datasets, and cross-dataset evaluations are rarely performed. A clear understanding of evaluation metrics and machine learning models with cross datasets is crucial to bring research in the field to a new quality level. Towards this goal, we present comprehensive evaluations of five distinct machine learning models using Global Features and Deep Neural Networks that can classify 16 different key types of GI tract conditions, including pathological findings, anatomical landmarks, polyp removal conditions, and normal findings from images captured by common GI tract examination instruments. In our evaluation, we introduce performance hexagons using six performance metrics such as recall, precision, specificity, accuracy, F1-score, and Matthews Correlation Coefficient to demonstrate how to determine the real capabilities of models rather than evaluating them shallowly. Furthermore, we perform cross-dataset evaluations using different datasets for training and testing. With these cross-dataset evaluations, we demonstrate the challenge of actually building a generalizable model that could be used across different hospitals. Our experiments clearly show that more sophisticated performance metrics and evaluation methods need to be applied to get reliable models rather than depending on evaluations of the splits of the same dataset, i.e., the performance metrics should always be interpreted together rather than relying on a single metric.},
	number = {3},
	journal = {ACM Transactions on Computing for Healthcare},
	author = {Thambawita, Vajira and Jha, Debesh and Hammer, Hugo Lewi and Johansen, Håvard D. and Johansen, Dag and Halvorsen, Pål and Riegler, Michael A.},
	month = jul,
	year = {2020},
	keywords = {Deep Learning, Computer Aided Diagnosis, Cross-dataset evaluations, CVC-12K, CVC-356, CVC-612, Gastrointestinal Tract Diseases, Global Features, Kvasir, Medical, Multi-class classification, Nerthus, Polyp classification},
	pages = {1--29},
	file = {Thambawita et al_2020_An Extensive Study on Cross-Dataset Bias and Evaluation Metrics Interpretation for Machine Learning Applied to Gastrointestinal Tract Abnormality Classification.pdf:/Users/orsonxu/Desktop/HCI/Literature Management/Zotero/Thambawita et al_2020_An Extensive Study on Cross-Dataset Bias and Evaluation Metrics Interpretation for Machine Learning Applied to Gastrointestinal Tract Abnormality Classification.pdf:application/pdf},
}

@incollection{tommasi_testbed_2015,
	title = {A {Testbed} for {Cross}-{Dataset} {Analysis}},
	volume = {8927},
	isbn = {978-3-319-16198-3},
	url = {http://link.springer.com/10.1007/978-3-319-16199-0_2},
	abstract = {Despite the increasing interest towards domain adaptation and transfer learning techniques to generalize over image collections and overcome their biases, the visual community misses a large scale testbed for cross-dataset analysis. In this paper we discuss the challenges faced when aligning twelve existing image databases in a unique corpus, and we propose two cross-dataset setups that introduce new interesting research questions. Moreover, we report on a first set of experimental domain adaptation tests showing the effectiveness of iterative self-labeling for large scale problems.},
	booktitle = {Lecture {Notes} in {Computer} {Science} (including subseries {Lecture} {Notes} in {Artificial} {Intelligence} and {Lecture} {Notes} in {Bioinformatics})},
	author = {Tommasi, Tatiana and Tuytelaars, Tinne},
	year = {2015},
	doi = {10.1007/978-3-319-16199-0_2},
	note = {ISSN: 16113349},
	keywords = {Domain adaptation, Dataset bias, Iterative self-labeling},
	pages = {18--31},
	file = {Tommasi_Tuytelaars_2015_A Testbed for Cross-Dataset Analysis.pdf:/Users/orsonxu/Desktop/HCI/Literature Management/Zotero/Tommasi_Tuytelaars_2015_A Testbed for Cross-Dataset Analysis.pdf:application/pdf},
}

@article{baltrusaitis_cross-dataset_2015,
	title = {Cross-dataset learning and person-specific normalisation for automatic {Action} {Unit} detection},
	volume = {2015-Janua},
	doi = {10.1109/FG.2015.7284869},
	abstract = {Automatic detection of Facial Action Units (AUs) is crucial for facial analysis systems. Due to the large individual differences, performance of AU classifiers depends largely on training data and the ability to estimate facial expressions of a neutral face. In this paper, we present a real-time Facial Action Unit intensity estimation and occurrence detection system based on appearance (Histograms of Oriented Gradients) and geometry features (shape parameters and landmark locations). Our experiments show the benefits of using additional labelled data from different datasets, which demonstrates the generalisability of our approach. This holds both when training for a specific dataset or when a generic model is needed. We also demonstrate the benefits of using a simple and efficient median based feature normalisation technique that accounts for person-specific neutral expressions. Finally, we show that our results outperform the FERA 2015 baselines in all three challenge tasks - AU occurrence detection, fully automatic AU intensity and pre-segmented AU intensity estimation.},
	journal = {2015 11th IEEE International Conference and Workshops on Automatic Face and Gesture Recognition, FG 2015},
	author = {Baltrušaitis, Tadas and Mahmoud, Marwa and Robinson, Peter},
	year = {2015},
	note = {ISBN: 9781479960262},
	file = {Baltrušaitis et al_2015_Cross-dataset learning and person-specific normalisation for automatic Action Unit detection.pdf:/Users/orsonxu/Desktop/HCI/Literature Management/Zotero/Baltrušaitis et al_2015_Cross-dataset learning and person-specific normalisation for automatic Action Unit detection.pdf:application/pdf},
}

@article{zhang_recent_2019,
	title = {Recent {Advances} in {Transfer} {Learning} for {Cross}-{Dataset} {Visual} {Recognition}},
	volume = {52},
	issn = {0360-0300},
	url = {https://dl.acm.org/doi/10.1145/3291124},
	doi = {10.1145/3291124},
	abstract = {This paper takes a problem-oriented perspective and presents a comprehensive review of transfer learning methods, both shallow and deep, for cross-dataset visual recognition. Specifically, it categorises the cross-dataset recognition into seventeen problems based on a set of carefully chosen data and label attributes. Such a problem-oriented taxonomy has allowed us to examine how different transfer learning approaches tackle each problem and how well each problem has been researched to date. The comprehensive problem-oriented review of the advances in transfer learning with respect to the problem has not only revealed the challenges in transfer learning for visual recognition, but also the problems (e.g. eight of the seventeen problems) that have been scarcely studied. This survey not only presents an up-to-date technical review for researchers, but also a systematic approach and a reference for a machine learning practitioner to categorise a real problem and to look up for a possible solution accordingly.},
	number = {1},
	journal = {ACM Computing Surveys},
	author = {Zhang, Jing and Li, Wanqing and Ogunbona, Philip and Xu, Dong},
	month = feb,
	year = {2019},
	pages = {1--38},
	file = {Zhang et al_2019_Recent Advances in Transfer Learning for Cross-Dataset Visual Recognition.pdf:/Users/orsonxu/Desktop/HCI/Literature Management/Zotero/Zhang et al_2019_Recent Advances in Transfer Learning for Cross-Dataset Visual Recognition.pdf:application/pdf},
}


@incollection{saenko_adapting_2010,
	title = {Adapting {Visual} {Category} {Models} to {New} {Domains}},
	volume = {6314 LNCS},
	isbn = {3-642-15560-X},
	url = {http://link.springer.com/10.1007/978-3-642-15561-1_16},
	abstract = {Domain adaptation is an important emerging topic in computer vision. In this paper, we present one of the first studies of domain shift in the context of object recognition. We introduce a method that adapts object models acquired in a particular visual domain to new imaging conditions by learning a transformation that minimizes the effect of domain-induced changes in the feature distribution. The transformation is learned in a supervised manner and can be applied to categories for which there are no labeled examples in the new domain. While we focus our evaluation on object recognition tasks, the transform-based adaptation technique we develop is general and could be applied to non-image data. Another contribution is a new multi-domain object database, freely available for download. We experimentally demonstrate the ability of our method to improve recognition on categories with few or no target domain labels and moderate to large changes in the imaging conditions. © 2010 Springer-Verlag.},
	booktitle = {Lecture {Notes} in {Computer} {Science} (including subseries {Lecture} {Notes} in {Artificial} {Intelligence} and {Lecture} {Notes} in {Bioinformatics})},
	author = {Saenko, Kate and Kulis, Brian and Fritz, Mario and Darrell, Trevor},
	year = {2010},
	doi = {10.1007/978-3-642-15561-1_16},
	note = {Issue: PART 4
ISSN: 16113349},
	pages = {213--226},
	file = {Saenko et al_2010_Adapting Visual Category Models to New Domains.pdf:/Users/orsonxu/Desktop/HCI/Literature Management/Zotero/Saenko et al_2010_Adapting Visual Category Models to New Domains.pdf:application/pdf},
}

@article{fernando_unsupervised_2013,
	title = {Unsupervised visual domain adaptation using subspace alignment},
	doi = {10.1109/ICCV.2013.368},
	abstract = {In this paper, we introduce a new domain adaptation (DA) algorithm where the source and target domains are represented by subspaces described by eigenvectors. In this context, our method seeks a domain adaptation solution by learning a mapping function which aligns the source subspace with the target one. We show that the solution of the corresponding optimization problem can be obtained in a simple closed form, leading to an extremely fast algorithm. We use a theoretical result to tune the unique hyper parameter corresponding to the size of the subspaces. We run our method on various datasets and show that, despite its intrinsic simplicity, it outperforms state of the art DA methods. © 2013 IEEE.},
	journal = {Proceedings of the IEEE International Conference on Computer Vision},
	author = {Fernando, Basura and Habrard, Amaury and Sebban, Marc and Tuytelaars, Tinne},
	year = {2013},
	note = {ISBN: 9781479928392},
	keywords = {object recognition, domain adaptation, subspace alignment},
	pages = {2960--2967},
	file = {Fernando et al_2013_Unsupervised visual domain adaptation using subspace alignment.pdf:/Users/orsonxu/Desktop/HCI/Literature Management/Zotero/Fernando et al_2013_Unsupervised visual domain adaptation using subspace alignment.pdf:application/pdf},
}

@inproceedings{boqing_gong_geodesic_2012,
	title = {Geodesic flow kernel for unsupervised domain adaptation},
	isbn = {978-1-4673-1228-8},
	url = {http://ieeexplore.ieee.org/document/6247911/},
	doi = {10.1109/CVPR.2012.6247911},
	abstract = {In real-world applications of visual recognition, many factors such as pose, illumination, or image quality can cause a significant mismatch between the source domain on which classifiers are trained and the target domain to which those classifiers are applied. As such, the classifiers often perform poorly on the target domain. Domain adaptation techniques aim to correct the mismatch. Existing approaches have concentrated on learning feature representations that are invariant across domains, and they often do not directly exploit low-dimensional structures that are intrinsic to many vision datasets. In this paper, we propose a new kernel-based method that takes advantage of such structures. Our geodesic flow kernel models domain shift by integrating an infinite number of subspaces that characterize changes in geometric and statistical properties from the source to the target domain. Our approach is computationally advantageous, automatically inferring important algorithmic parameters without requiring extensive cross-validation or labeled data from either domain. We also introduce a metric that reliably measures the adaptability between a pair of source and target domains. For a given target domain and several source domains, the metric can be used to automatically select the optimal source domain to adapt and avoid less desirable ones. Empirical studies on standard datasets demonstrate the advantages of our approach over competing methods. © 2012 IEEE.},
	booktitle = {2012 {IEEE} {Conference} on {Computer} {Vision} and {Pattern} {Recognition}},
	publisher = {IEEE},
	author = {{Boqing Gong} and {Yuan Shi} and {Fei Sha} and Grauman, Kristen},
	month = jun,
	year = {2012},
	note = {ISSN: 10636919},
	pages = {2066--2073},
	file = {Boqing Gong et al_2012_Geodesic flow kernel for unsupervised domain adaptation.pdf:/Users/orsonxu/Desktop/HCI/Literature Management/Zotero/Boqing Gong et al_2012_Geodesic flow kernel for unsupervised domain adaptation.pdf:application/pdf},
}

@article{sun_return_2016,
	title = {Return of frustratingly easy domain adaptation},
	url = {https://ojs.aaai.org/index.php/AAAI/article/view/10306},
	number = {1},
	journal = {Proceedings of the Thirtieth AAAI Conference on Artificial Intelligence},
	author = {Sun, Baochen and Saenko, Kate},
	year = {2016},
	keywords = {Technical Papers: Machine Learning Methods},
	pages = {2058--2065},
	file = {Sun_Saenko_2016_Return of frustratingly easy domain adaptation.pdf:/Users/orsonxu/Desktop/HCI/Literature Management/Zotero/Sun_Saenko_2016_Return of frustratingly easy domain adaptation.pdf:application/pdf},
}

@inproceedings{church_understanding_2015,
	address = {New York, NY, USA},
	title = {Understanding the {Challenges} of {Mobile} {Phone} {Usage} {Data}},
	isbn = {978-1-4503-3652-9},
	url = {https://dl.acm.org/doi/10.1145/2785830.2785891},
	doi = {10.1145/2785830.2785891},
	abstract = {Driven by curiosity and our own three diverse smartphone application usage datasets, we sought to unpack the nuances of mobile device use by revisiting two recent Mobile HCI studies [1, 17]. Our goal was to add to our broader understanding of smartphone usage by investigating if differences in mobile device usage occurred not only across our three datasets, but also in relation to prior work. We found differences in the top-10 apps in each dataset, in the durations and types of interactions as well as in micro-usage patterns. However, it proved very challenging to attribute such differences to a specific factor or set of factors: Was it the time frame in which the studies were executed? The recruitment procedure? The experimental method? Using our somewhat troubled analysis, we discuss the challenges and issues of conducting mobile research of this nature and reflect on caveats related to the replicability and generalizability of such work.},
	booktitle = {Proceedings of the 17th {International} {Conference} on {Human}-{Computer} {Interaction} with {Mobile} {Devices} and {Services}},
	publisher = {ACM},
	author = {Church, Karen and Ferreira, Denzil and Banovic, Nikola and Lyons, Kent},
	month = aug,
	year = {2015},
	keywords = {Device usage, Evaluation, Generalizability, Methodology, Micro-usage, Mobile hci, Mobile usage, Replication, Smartphone usage, User studies},
	pages = {504--514},
	file = {Church et al_2015_Understanding the Challenges of Mobile Phone Usage Data.pdf:/Users/orsonxu/Desktop/HCI/Literature Management/Zotero/Church et al_2015_Understanding the Challenges of Mobile Phone Usage Data.pdf:application/pdf},
}

@inproceedings{tzeng_adversarial_2017,
	address = {Honolulu, HI},
	title = {Adversarial {Discriminative} {Domain} {Adaptation}},
	isbn = {978-1-5386-0457-1},
	url = {http://ieeexplore.ieee.org/document/8099799/},
	doi = {10.1109/CVPR.2017.316},
	abstract = {Adversarial learning methods are a promising approach to training robust deep networks, and can generate complex samples across diverse domains. They can also improve recognition despite the presence of domain shift or dataset bias: recent adversarial approaches to unsupervised domain adaptation reduce the difference between the training and test domain distributions and thus improve generalization performance. However, while generative adversarial networks (GANs) show compelling visualizations, they are not optimal on discriminative tasks and can be limited to smaller shifts. On the other hand, discriminative approaches can handle larger domain shifts, but impose tied weights on the model and do not exploit a GAN-based loss. In this work, we ﬁrst outline a novel generalized framework for adversarial adaptation, which subsumes recent state-of-the-art approaches as special cases, and use this generalized view to better relate prior approaches. We then propose a previously unexplored instance of our general framework which combines discriminative modeling, untied weight sharing, and a GAN loss, which we call Adversarial Discriminative Domain Adaptation (ADDA). We show that ADDA is more effective yet considerably simpler than competing domainadversarial methods, and demonstrate the promise of our approach by exceeding state-of-the-art unsupervised adaptation results on standard domain adaptation tasks as well as a difﬁcult cross-modality object classiﬁcation task.},
	language = {en},
	urldate = {2021-06-11},
	booktitle = {2017 {IEEE} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} ({CVPR})},
	publisher = {IEEE},
	author = {Tzeng, Eric and Hoffman, Judy and Saenko, Kate and Darrell, Trevor},
	month = jul,
	year = {2017},
	keywords = {Unread},
	pages = {2962--2971},
	file = {Tzeng et al_2017_Adversarial Discriminative Domain Adaptation.pdf:/Users/orsonxu/Desktop/HCI/Literature Management/Zotero/Tzeng et al_2017_Adversarial Discriminative Domain Adaptation.pdf:application/pdf},
}

@article{wang_exploring_2021,
	title = {Exploring the {Generalizability} of {Spatio}-{Temporal} {Traffic} {Prediction}: {Meta}-{Modeling} and an {Analytic} {Framework}},
	issn = {1558-2191},
	shorttitle = {Exploring the {Generalizability} of {Spatio}-{Temporal} {Traffic} {Prediction}},
	doi = {10.1109/TKDE.2021.3130762},
	abstract = {The Spatio-Temporal Traffic Prediction (STTP) problem is a classical problem with plenty of prior research efforts that benefit from traditional statistical learning and recent deep learning approaches. While STTP can refer to many real-world problems, most existing studies focus on quite specific applications, such as the prediction of taxi demand, ridesharing order, traffic speed, and so on. This hinders the STTP research as the approaches designed for different applications are hardly comparable, and thus how an application-driven approach can be generalized to other scenarios is unclear. To fill in this gap, this paper makes three efforts: (i) we propose an analytic framework, called STAnalytic, to qualitatively investigate STTP approaches regarding their design considerations on various spatial and temporal factors, aiming to make different application-driven approaches comparable; (ii) we design a spatio-temporal meta-model, called STMeta, which can flexibly integrate generalizable temporal and spatial knowledge identified by STAnalytic, (iii) we build an extensively large-scale STTP benchmark platform including ten datasets with five scenarios to quantitatively measure the generalizability of STTP approaches. In particular, we implement STMeta with different deep learning techniques, and STMeta demonstrates better generalizability than state-of-the-art approaches by achieving lower prediction error on average across all the datasets.},
	journal = {IEEE Transactions on Knowledge and Data Engineering},
	author = {Wang, Leye and Chai, Di and Liu, Xuanzhe and Chen, Liyue and Chen, Kai},
	year = {2021},
	note = {Conference Name: IEEE Transactions on Knowledge and Data Engineering},
	pages = {1--1},
	file = {Wang et al_2021_Exploring the Generalizability of Spatio-Temporal Traffic Prediction.pdf:/Users/orsonxu/Desktop/HCI/Literature Management/Zotero/Wang et al_2021_Exploring the Generalizability of Spatio-Temporal Traffic Prediction.pdf:application/pdf},
}

@incollection{leibe_deep_2016,
	address = {Cham},
	title = {Deep {Reconstruction}-{Classification} {Networks} for {Unsupervised} {Domain} {Adaptation}},
	volume = {9908},
	isbn = {978-3-319-46492-3 978-3-319-46493-0},
	url = {http://link.springer.com/10.1007/978-3-319-46493-0_36},
	abstract = {In this paper, we propose a novel unsupervised domain adaptation algorithm based on deep learning for visual object recognition. Speciﬁcally, we design a new model called Deep ReconstructionClassiﬁcation Network (DRCN), which jointly learns a shared encoding representation for two tasks: (i) supervised classiﬁcation of labeled source data, and (ii) unsupervised reconstruction of unlabeled target data. In this way, the learnt representation not only preserves discriminability, but also encodes useful information from the target domain. Our new DRCN model can be optimized by using backpropagation similarly as the standard neural networks.},
	language = {en},
	urldate = {2021-12-18},
	booktitle = {Computer {Vision} – {ECCV} 2016},
	publisher = {Springer International Publishing},
	author = {Ghifary, Muhammad and Kleijn, W. Bastiaan and Zhang, Mengjie and Balduzzi, David and Li, Wen},
	editor = {Leibe, Bastian and Matas, Jiri and Sebe, Nicu and Welling, Max},
	year = {2016},
	doi = {10.1007/978-3-319-46493-0_36},
	note = {Series Title: Lecture Notes in Computer Science},
	pages = {597--613},
	file = {Ghifary et al. - 2016 - Deep Reconstruction-Classification Networks for Un.pdf:/Users/orsonxu/Zotero/storage/JMBAWMU6/Ghifary et al. - 2016 - Deep Reconstruction-Classification Networks for Un.pdf:application/pdf},
}

@article{tzeng_deep_2014,
	title = {Deep {Domain} {Confusion}: {Maximizing} for {Domain} {Invariance}},
	shorttitle = {Deep {Domain} {Confusion}},
	url = {http://arxiv.org/abs/1412.3474},
	abstract = {Recent reports suggest that a generic supervised deep CNN model trained on a large-scale dataset reduces, but does not remove, dataset bias on a standard benchmark. Fine-tuning deep models in a new domain can require a significant amount of data, which for many applications is simply not available. We propose a new CNN architecture which introduces an adaptation layer and an additional domain confusion loss, to learn a representation that is both semantically meaningful and domain invariant. We additionally show that a domain confusion metric can be used for model selection to determine the dimension of an adaptation layer and the best position for the layer in the CNN architecture. Our proposed adaptation method offers empirical performance which exceeds previously published results on a standard benchmark visual domain adaptation task.},
	urldate = {2021-12-18},
	journal = {arXiv:1412.3474 [cs]},
	author = {Tzeng, Eric and Hoffman, Judy and Zhang, Ning and Saenko, Kate and Darrell, Trevor},
	month = dec,
	year = {2014},
	note = {arXiv: 1412.3474},
	file = {Tzeng et al_2014_Deep Domain Confusion.pdf:/Users/orsonxu/Desktop/HCI/Literature Management/Zotero/Tzeng et al_2014_Deep Domain Confusion.pdf:application/pdf},
}


@incollection{hutchison_undoing_2012,
	address = {Berlin, Heidelberg},
	title = {Undoing the {Damage} of {Dataset} {Bias}},
	volume = {7572},
	isbn = {978-3-642-33717-8 978-3-642-33718-5},
	url = {http://link.springer.com/10.1007/978-3-642-33718-5_12},
	abstract = {The presence of bias in existing object recognition datasets is now well-known in the computer vision community. While it remains in question whether creating an unbiased dataset is possible given limited resources, in this work we propose a discriminative framework that directly exploits dataset bias during training. In particular, our model learns two sets of weights: (1) bias vectors associated with each individual dataset, and (2) visual world weights that are common to all datasets, which are learned by undoing the associated bias from each dataset. The visual world weights are expected to be our best possible approximation to the object model trained on an unbiased dataset, and thus tend to have good generalization ability. We demonstrate the eﬀectiveness of our model by applying the learned weights to a novel, unseen dataset, and report superior results for both classiﬁcation and detection tasks compared to a classical SVM that does not account for the presence of bias. Overall, we ﬁnd that it is beneﬁcial to explicitly account for bias when combining multiple datasets.},
	language = {en},
	urldate = {2021-12-22},
	booktitle = {Computer {Vision} – {ECCV} 2012},
	publisher = {Springer Berlin Heidelberg},
	author = {Khosla, Aditya and Zhou, Tinghui and Malisiewicz, Tomasz and Efros, Alexei A. and Torralba, Antonio},
	editor = {Hutchison, David and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M. and Mattern, Friedemann and Mitchell, John C. and Naor, Moni and Nierstrasz, Oscar and Pandu Rangan, C. and Steffen, Bernhard and Sudan, Madhu and Terzopoulos, Demetri and Tygar, Doug and Vardi, Moshe Y. and Weikum, Gerhard and Fitzgibbon, Andrew and Lazebnik, Svetlana and Perona, Pietro and Sato, Yoichi and Schmid, Cordelia},
	year = {2012},
	doi = {10.1007/978-3-642-33718-5_12},
	note = {Series Title: Lecture Notes in Computer Science},
	pages = {158--171},
	file = {Khosla et al. - 2012 - Undoing the Damage of Dataset Bias.pdf:/Users/orsonxu/Zotero/storage/EAF7RLGJ/Khosla et al. - 2012 - Undoing the Damage of Dataset Bias.pdf:application/pdf},
}

@inproceedings{ismail_fawaz_transfer_2018,
	title = {Transfer learning for time series classification},
	doi = {10.1109/BigData.2018.8621990},
	abstract = {Transfer learning for deep neural networks is the process of first training a base network on a source dataset, and then transferring the learned features (the network’s weights) to a second network to be trained on a target dataset. This idea has been shown to improve deep neural network’s generalization capabilities in many computer vision tasks such as image recognition and object localization. Apart from these applications, deep Convolutional Neural Networks (CNNs) have also recently gained popularity in the Time Series Classification (TSC) community. However, unlike for image recognition problems, transfer learning techniques have not yet been investigated thoroughly for the TSC task. This is surprising as the accuracy of deep learning models for TSC could potentially be improved if the model is fine-tuned from a pre-trained neural network instead of training it from scratch. In this paper, we fill this gap by investigating how to transfer deep CNNs for the TSC task. To evaluate the potential of transfer learning, we performed extensive experiments using the UCR archive which is the largest publicly available TSC benchmark containing 85 datasets. For each dataset in the archive, we pre-trained a model and then fine-tuned it on the other datasets resulting in 7140 different deep neural networks. These experiments revealed that transfer learning can improve or degrade the models predictions depending on the dataset used for transfer. Therefore, in an effort to predict the best source dataset for a given target dataset, we propose a new method relying on Dynamic Time Warping to measure inter-datasets similarities. We describe how our method can guide the transfer to choose the best source dataset leading to an improvement in accuracy on 71 out of 85 datasets.},
	booktitle = {2018 {IEEE} {International} {Conference} on {Big} {Data} ({Big} {Data})},
	author = {Ismail Fawaz, Hassan and Forestier, Germain and Weber, Jonathan and Idoumghar, Lhassane and Muller, Pierre-Alain},
	month = dec,
	year = {2018},
	pages = {1367--1376},
	file = {Ismail Fawaz et al_2018_Transfer learning for time series classification.pdf:/Users/orsonxu/Desktop/HCI/Literature Management/Zotero/Ismail Fawaz et al_2018_Transfer learning for time series classification.pdf:application/pdf},
}

@article{volpi_generalizing_2018,
	title = {Generalizing to {Unseen} {Domains} via {Adversarial} {Data} {Augmentation}},
	url = {http://arxiv.org/abs/1805.12018},
	abstract = {We are concerned with learning models that generalize well to different {\textbackslash}emph\{unseen\} domains. We consider a worst-case formulation over data distributions that are near the source domain in the feature space. Only using training data from a single source distribution, we propose an iterative procedure that augments the dataset with examples from a fictitious target domain that is "hard" under the current model. We show that our iterative scheme is an adaptive data augmentation method where we append adversarial examples at each iteration. For softmax losses, we show that our method is a data-dependent regularization scheme that behaves differently from classical regularizers that regularize towards zero (e.g., ridge or lasso). On digit recognition and semantic segmentation tasks, our method learns models improve performance across a range of a priori unknown target domains.},
	urldate = {2022-01-07},
	journal = {arXiv:1805.12018 [cs]},
	author = {Volpi, Riccardo and Namkoong, Hongseok and Sener, Ozan and Duchi, John and Murino, Vittorio and Savarese, Silvio},
	month = nov,
	year = {2018},
	note = {arXiv: 1805.12018},
	file = {Volpi et al_2018_Generalizing to Unseen Domains via Adversarial Data Augmentation.pdf:/Users/orsonxu/Desktop/HCI/Literature Management/Zotero/Volpi et al_2018_Generalizing to Unseen Domains via Adversarial Data Augmentation.pdf:application/pdf},
}

@article{shankar_generalizing_2018,
	title = {Generalizing {Across} {Domains} via {Cross}-{Gradient} {Training}},
	url = {http://arxiv.org/abs/1804.10745},
	abstract = {We present CROSSGRAD, a method to use multi-domain training data to learn a classifier that generalizes to new domains. CROSSGRAD does not need an adaptation phase via labeled or unlabeled data, or domain features in the new domain. Most existing domain adaptation methods attempt to erase domain signals using techniques like domain adversarial training. In contrast, CROSSGRAD is free to use domain signals for predicting labels, if it can prevent overfitting on training domains. We conceptualize the task in a Bayesian setting, in which a sampling step is implemented as data augmentation, based on domain-guided perturbations of input instances. CROSSGRAD parallelly trains a label and a domain classifier on examples perturbed by loss gradients of each other's objectives. This enables us to directly perturb inputs, without separating and re-mixing domain signals while making various distributional assumptions. Empirical evaluation on three different applications where this setting is natural establishes that (1) domain-guided perturbation provides consistently better generalization to unseen domains, compared to generic instance perturbation methods, and that (2) data augmentation is a more stable and accurate method than domain adversarial training.},
	urldate = {2022-01-09},
	journal = {arXiv:1804.10745 [cs, stat]},
	author = {Shankar, Shiv and Piratla, Vihari and Chakrabarti, Soumen and Chaudhuri, Siddhartha and Jyothi, Preethi and Sarawagi, Sunita},
	month = may,
	year = {2018},
	note = {arXiv: 1804.10745},
	file = {Shankar et al_2018_Generalizing Across Domains via Cross-Gradient Training.pdf:/Users/orsonxu/Desktop/HCI/Literature Management/Zotero/Shankar et al_2018_Generalizing Across Domains via Cross-Gradient Training.pdf:application/pdf},
}


@inproceedings{balaji_metareg_2018,
	title = {{MetaReg}: {Towards} {Domain} {Generalization} using {Meta}-{Regularization}},
	volume = {31},
	shorttitle = {{MetaReg}},
	url = {https://proceedings.neurips.cc/paper/2018/hash/647bba344396e7c8170902bcf2e15551-Abstract.html},
	urldate = {2022-01-16},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates, Inc.},
	author = {Balaji, Yogesh and Sankaranarayanan, Swami and Chellappa, Rama},
	year = {2018},
	file = {Balaji et al_2018_MetaReg.pdf:/Users/orsonxu/Desktop/HCI/Literature Management/Zotero/Balaji et al_2018_MetaReg.pdf:application/pdf},
}

@inproceedings{li_feature-critic_2019,
	title = {Feature-{Critic} {Networks} for {Heterogeneous} {Domain} {Generalization}},
	url = {https://proceedings.mlr.press/v97/li19l.html},
	abstract = {The well known domain shift issue causes model performance to degrade when deployed to a new target domain with different statistics to training. Domain adaptation techniques alleviate this, but need some instances from the target domain to drive adaptation. Domain generalisation is the recently topical problem of learning a model that generalises to unseen domains out of the box, and various approaches aim to train a domain-invariant feature extractor, typically by adding some manually designed losses. In this work, we propose a learning to learn approach, where the auxiliary loss that helps generalisation is itself learned. Beyond conventional domain generalisation, we consider a more challenging setting of heterogeneous domain generalisation, where the unseen domains do not share label space with the seen ones, and the goal is to train a feature representation that is useful off-the-shelf for novel data and novel categories. Experimental evaluation demonstrates that our method outperforms state-of-the-art solutions in both settings.},
	language = {en},
	urldate = {2022-01-16},
	booktitle = {Proceedings of the 36th {International} {Conference} on {Machine} {Learning}},
	publisher = {PMLR},
	author = {Li, Yiying and Yang, Yongxin and Zhou, Wei and Hospedales, Timothy},
	month = may,
	year = {2019},
	note = {ISSN: 2640-3498},
	pages = {3915--3924},
	file = {Li et al_2019_Feature-Critic Networks for Heterogeneous Domain Generalization.pdf:/Users/orsonxu/Desktop/HCI/Literature Management/Zotero/Li et al_2019_Feature-Critic Networks for Heterogeneous Domain Generalization.pdf:application/pdf},
}

@article{muandet_domain_2013,
	title = {Domain {Generalization} via {Invariant} {Feature} {Representation}},
	abstract = {This paper investigates domain generalization: How to take knowledge acquired from an arbitrary number of related domains and apply it to previously unseen domains? We propose Domain-Invariant Component Analysis (DICA), a kernel-based optimization algorithm that learns an invariant transformation by minimizing the dissimilarity across domains, whilst preserving the functional relationship between input and output variables. A learning-theoretic analysis shows that reducing dissimilarity improves the expected generalization ability of classiﬁers on new domains, motivating the proposed algorithm. Experimental results on synthetic and real-world datasets demonstrate that DICA successfully learns invariant features and improves classiﬁer performance in practice.},
	language = {en},
	journal = {Proceedings of the 30 th International Conference on Machine Learning},
	author = {Muandet, Krikamol and Balduzzi, David and Scholkopf, Bernhard},
	year = {2013},
	pages = {9},
	file = {Muandet et al. - Domain Generalization via Invariant Feature Repres.pdf:/Users/orsonxu/Zotero/storage/2DFZWPP8/Muandet et al. - Domain Generalization via Invariant Feature Repres.pdf:application/pdf},
}

@inproceedings{li_domain_2018,
	address = {Salt Lake City, UT},
	title = {Domain {Generalization} with {Adversarial} {Feature} {Learning}},
	isbn = {978-1-5386-6420-9},
	url = {https://ieeexplore.ieee.org/document/8578664/},
	doi = {10.1109/CVPR.2018.00566},
	abstract = {In this paper, we tackle the problem of domain generalization: how to learn a generalized feature representation for an “unseen” target domain by taking the advantage of multiple seen source-domain data. We present a novel framework based on adversarial autoencoders to learn a generalized latent feature representation across domains for domain generalization. To be speciﬁc, we extend adversarial autoencoders by imposing the Maximum Mean Discrepancy (MMD) measure to align the distributions among different domains, and matching the aligned distribution to an arbitrary prior distribution via adversarial feature learning. In this way, the learned feature representation is supposed to be universal to the seen source domains because of the MMD regularization, and is expected to generalize well on the target domain because of the introduction of the prior distribution. We proposed an algorithm to jointly train different components of our proposed framework. Extensive experiments on various vision tasks demonstrate that our proposed framework can learn better generalized features for the unseen target domain compared with state-of-the-art domain generalization methods.},
	language = {en},
	urldate = {2022-02-02},
	booktitle = {2018 {IEEE}/{CVF} {Conference} on {Computer} {Vision} and {Pattern} {Recognition}},
	publisher = {IEEE},
	author = {Li, Haoliang and Pan, Sinno Jialin and Wang, Shiqi and Kot, Alex C.},
	month = jun,
	year = {2018},
	pages = {5400--5409},
	file = {Li et al. - 2018 - Domain Generalization with Adversarial Feature Lea.pdf:/Users/orsonxu/Zotero/storage/NKAX356P/Li et al. - 2018 - Domain Generalization with Adversarial Feature Lea.pdf:application/pdf},
}

@incollection{ferrari_deep_2018,
	address = {Cham},
	title = {Deep {Domain} {Generalization} via {Conditional} {Invariant} {Adversarial} {Networks}},
	volume = {11219},
	isbn = {978-3-030-01266-3 978-3-030-01267-0},
	url = {http://link.springer.com/10.1007/978-3-030-01267-0_38},
	abstract = {Domain generalization aims to learn a classiﬁcation model from multiple source domains and generalize it to unseen target domains. A critical problem in domain generalization involves learning domaininvariant representations. Let X and Y denote the features and the labels, respectively. Under the assumption that the conditional distribution P (Y {\textbar}X) remains unchanged across domains, earlier approaches to domain generalization learned the invariant representation T (X) by minimizing the discrepancy of the marginal distribution P (T (X)). However, such an assumption of stable P (Y {\textbar}X) does not necessarily hold in practice. In addition, the representation learning function T (X) is usually constrained to a simple linear transformation or shallow networks. To address the above two drawbacks, we propose an end-to-end conditional invariant deep domain generalization approach by leveraging deep neural networks for domain-invariant representation learning. The domain-invariance property is guaranteed through a conditional invariant adversarial network that can learn domain-invariant representations w.r.t. the joint distribution P (T (X), Y ) if the target domain data are not severely class unbalanced. We perform various experiments to demonstrate the eﬀectiveness of the proposed method.},
	language = {en},
	urldate = {2022-02-02},
	booktitle = {Computer {Vision} – {ECCV} 2018},
	publisher = {Springer International Publishing},
	author = {Li, Ya and Tian, Xinmei and Gong, Mingming and Liu, Yajing and Liu, Tongliang and Zhang, Kun and Tao, Dacheng},
	editor = {Ferrari, Vittorio and Hebert, Martial and Sminchisescu, Cristian and Weiss, Yair},
	year = {2018},
	doi = {10.1007/978-3-030-01267-0_38},
	note = {Series Title: Lecture Notes in Computer Science},
	pages = {647--663},
	file = {Li et al. - 2018 - Deep Domain Generalization via Conditional Invaria.pdf:/Users/orsonxu/Zotero/storage/YXYLRSHK/Li et al. - 2018 - Deep Domain Generalization via Conditional Invaria.pdf:application/pdf},
}


@inproceedings{eldele_time-series_2021,
	address = {Montreal, Canada},
	title = {Time-{Series} {Representation} {Learning} via {Temporal} and {Contextual} {Contrasting}},
	isbn = {978-0-9992411-9-6},
	url = {https://www.ijcai.org/proceedings/2021/324},
	doi = {10.24963/ijcai.2021/324},
	abstract = {Learning decent representations from unlabeled time-series data with temporal dynamics is a very challenging task. In this paper, we propose an unsupervised Time-Series representation learning framework via Temporal and Contextual Contrasting (TS-TCC), to learn time-series representation from unlabeled data. First, the raw timeseries data are transformed into two different yet correlated views by using weak and strong augmentations. Second, we propose a novel temporal contrasting module to learn robust temporal representations by designing a tough cross-view prediction task. Last, to further learn discriminative representations, we propose a contextual contrasting module built upon the contexts from the temporal contrasting module. It attempts to maximize the similarity among different contexts of the same sample while minimizing similarity among contexts of different samples. Experiments have been carried out on three real-world time-series datasets. The results manifest that training a linear classiﬁer on top of the features learned by our proposed TS-TCC performs comparably with the supervised training. Additionally, our proposed TS-TCC shows high efﬁciency in few-labeled data and transfer learning scenarios. The code is publicly available at https://github.com/emadeldeen24/TS-TCC.},
	language = {en},
	urldate = {2022-02-11},
	booktitle = {Proceedings of the {Thirtieth} {International} {Joint} {Conference} on {Artificial} {Intelligence}},
	publisher = {International Joint Conferences on Artificial Intelligence Organization},
	author = {Eldele, Emadeldeen and Ragab, Mohamed and Chen, Zhenghua and Wu, Min and Kwoh, Chee Keong and Li, Xiaoli and Guan, Cuntai},
	month = aug,
	year = {2021},
	pages = {2352--2359},
	file = {Eldele et al. - 2021 - Time-Series Representation Learning via Temporal a.pdf:/Users/orsonxu/Zotero/storage/IBDJENHN/Eldele et al. - 2021 - Time-Series Representation Learning via Temporal a.pdf:application/pdf},
}


@article{ester_density-based_1996,
	title = {A {Density}-{Based} {Algorithm} for {Discovering} {Clusters} in {Large} {Spatial} {Databases} with {Noise}},
	abstract = {Clusteringalgorithmasreattractivefor the taskof classidentification in spatial databases.Howevetrh, e applicationto large spatial databasesrises the followingrequirementfsor clustering algorithms: minimalrequirementsof domain knowledgteo determinethe input parameters,discoveryof clusters witharbitraryshapeandgoodefficiencyonlarge databases. Thewell-knowcnlusteringalgorithmsoffer nosolution to the combinatioonf theserequirementsI.n this paper, wepresent the newclustering algorithmDBSCAreNlying on a density-basednotionof clusters whichis designedto discoverclusters of arbitrary shape.DBSCrAeNquiresonly one input parameterandsupportsthe user in determiningan appropriatevaluefor it. Weperformeadn experimentaelvaluation of the effectiveness and efficiency of DBSCAusNing synthetic data and real data of the SEQUO2IA000benchmark.Theresults of our experimentsdemonstratethat (1) DBSCiAsNsignificantlymoreeffective in discoveringclusters of arbitrary shapethan the well-knowanlgorithmCLARANS,and that (2) DBSCAoNutperforms CLARANbyS factorof morethan100in termsof efficiency.},
	language = {en},
	journal = {Proceedings of the Second International Conference on Knowledge Discovery and Data Mining},
	author = {Ester, Martin and Kriegel, Hans-Peter and Xu, Xiaowei},
	year = {1996},
	pages = {6},
	file = {Ester et al. - A Density-Based Algorithm for Discovering Clusters.pdf:/Users/orsonxu/Zotero/storage/86LZH6LU/Ester et al. - A Density-Based Algorithm for Discovering Clusters.pdf:application/pdf},
}

@article{campello_hierarchical_2015,
	title = {Hierarchical {Density} {Estimates} for {Data} {Clustering}, {Visualization}, and {Outlier} {Detection}},
	volume = {10},
	issn = {1556-4681, 1556-472X},
	url = {https://dl.acm.org/doi/10.1145/2733381},
	doi = {10.1145/2733381},
	abstract = {An integrated framework for density-based cluster analysis, outlier detection, and data visualization is introduced in this article. The main module consists of an algorithm to compute hierarchical estimates of the level sets of a density, following Hartigan’s classic model of density-contour clusters and trees. Such an algorithm generalizes and improves existing density-based clustering techniques with respect to different aspects. It provides as a result a complete clustering hierarchy composed of all possible density-based clusters following the nonparametric model adopted, for an infinite range of density thresholds. The resulting hierarchy can be easily processed so as to provide multiple ways for data visualization and exploration. It can also be further postprocessed so that: (i) a normalized score of “outlierness” can be assigned to each data object, which unifies both the global and local perspectives of outliers into a single definition; and (ii) a “flat” (i.e., nonhierarchical) clustering solution composed of clusters extracted from local cuts through the cluster tree (possibly corresponding to different density thresholds) can be obtained, either in an unsupervised or in a semisupervised way. In the unsupervised scenario, the algorithm corresponding to this postprocessing module provides a global, optimal solution to the formal problem of maximizing the overall stability of the extracted clusters. If partially labeled objects or instance-level constraints are provided by the user, the algorithm can solve the problem by considering both constraints violations/satisfactions and cluster stability criteria. An asymptotic complexity analysis, both in terms of running time and memory space, is described. Experiments are reported that involve a variety of synthetic and real datasets, including comparisons with state-of-the-art, density-based clustering and (global and local) outlier detection methods.},
	language = {en},
	number = {1},
	urldate = {2021-08-07},
	journal = {ACM Transactions on Knowledge Discovery from Data},
	author = {Campello, Ricardo J. G. B. and Moulavi, Davoud and Zimek, Arthur and Sander, Jörg},
	month = jul,
	year = {2015},
	pages = {1--51},
	file = {Campello et al. - 2015 - Hierarchical Density Estimates for Data Clustering.pdf:/Users/orsonxu/Zotero/storage/R6Y3MVQ6/Campello et al. - 2015 - Hierarchical Density Estimates for Data Clustering.pdf:application/pdf},
}

@article{xie_unsupervised_2016,
	title = {Unsupervised {Deep} {Embedding} for {Clustering} {Analysis}},
	abstract = {Clustering is central to many data-driven application domains and has been studied extensively in terms of distance functions and grouping algorithms. Relatively little work has focused on learning representations for clustering. In this paper, we propose Deep Embedded Clustering (DEC), a method that simultaneously learns feature representations and cluster assignments using deep neural networks. DEC learns a mapping from the data space to a lower-dimensional feature space in which it iteratively optimizes a clustering objective. Our experimental evaluations on image and text corpora show signiﬁcant improvement over state-of-the-art methods.},
	language = {en},
	journal = {Proceedings of the 33 rd International Conference on Machine Learning},
	author = {Xie, Junyuan and Girshick, Ross and Farhadi, Ali},
	year = {2016},
	pages = {10},
	file = {Xie et al. - Unsupervised Deep Embedding for Clustering Analysi.pdf:/Users/orsonxu/Zotero/storage/6INXWKC7/Xie et al. - Unsupervised Deep Embedding for Clustering Analysi.pdf:application/pdf},
}

@inproceedings{guo_improved_2017,
	address = {Melbourne, Australia},
	title = {Improved {Deep} {Embedded} {Clustering} with {Local} {Structure} {Preservation}},
	isbn = {978-0-9992411-0-3},
	url = {https://www.ijcai.org/proceedings/2017/243},
	doi = {10.24963/ijcai.2017/243},
	abstract = {Deep clustering learns deep feature representations that favor clustering task using neural networks. Some pioneering work proposes to simultaneously learn embedded features and perform clustering by explicitly deﬁning a clustering oriented loss. Though promising performance has been demonstrated in various applications, we observe that a vital ingredient has been overlooked by these work that the deﬁned clustering loss may corrupt feature space, which leads to non-representative meaningless features and this in turn hurts clustering performance. To address this issue, in this paper, we propose the Improved Deep Embedded Clustering (IDEC) algorithm to take care of data structure preservation. Speciﬁcally, we manipulate feature space to scatter data points using a clustering loss as guidance. To constrain the manipulation and maintain the local structure of data generating distribution, an under-complete autoencoder is applied. By integrating the clustering loss and autoencoder’s reconstruction loss, IDEC can jointly optimize cluster labels assignment and learn features that are suitable for clustering with local structure preservation. The resultant optimization problem can be effectively solved by mini-batch stochastic gradient descent and backpropagation. Experiments on image and text datasets empirically validate the importance of local structure preservation and the effectiveness of our algorithm.},
	language = {en},
	urldate = {2022-01-19},
	booktitle = {Proceedings of the {Twenty}-{Sixth} {International} {Joint} {Conference} on {Artificial} {Intelligence}},
	publisher = {International Joint Conferences on Artificial Intelligence Organization},
	author = {Guo, Xifeng and Gao, Long and Liu, Xinwang and Yin, Jianping},
	month = aug,
	year = {2017},
	pages = {1753--1759},
	file = {Guo et al. - 2017 - Improved Deep Embedded Clustering with Local Struc.pdf:/Users/orsonxu/Zotero/storage/LGXLIGB2/Guo et al. - 2017 - Improved Deep Embedded Clustering with Local Struc.pdf:application/pdf},
}

@incollection{liu_deep_2017,
	address = {Cham},
	title = {Deep {Clustering} with {Convolutional} {Autoencoders}},
	volume = {10635},
	isbn = {978-3-319-70095-3 978-3-319-70096-0},
	url = {http://link.springer.com/10.1007/978-3-319-70096-0_39},
	abstract = {Deep clustering utilizes deep neural networks to learn feature representation that is suitable for clustering tasks. Though demonstrating promising performance in various applications, we observe that existing deep clustering algorithms either do not well take advantage of convolutional neural networks or do not considerably preserve the local structure of data generating distribution in the learned feature space. To address this issue, we propose a deep convolutional embedded clustering algorithm in this paper. Speciﬁcally, we develop a convolutional autoencoders structure to learn embedded features in an end-to-end way. Then, a clustering oriented loss is directly built on embedded features to jointly perform feature reﬁnement and cluster assignment. To avoid feature space being distorted by the clustering loss, we keep the decoder remained which can preserve local structure of data in feature space. In sum, we simultaneously minimize the reconstruction loss of convolutional autoencoders and the clustering loss. The resultant optimization problem can be eﬀectively solved by mini-batch stochastic gradient descent and back-propagation. Experiments on benchmark datasets empirically validate the power of convolutional autoencoders for feature learning and the eﬀectiveness of local structure preservation.},
	language = {en},
	urldate = {2022-01-19},
	booktitle = {Neural {Information} {Processing}},
	publisher = {Springer International Publishing},
	author = {Guo, Xifeng and Liu, Xinwang and Zhu, En and Yin, Jianping},
	editor = {Liu, Derong and Xie, Shengli and Li, Yuanqing and Zhao, Dongbin and El-Alfy, El-Sayed M.},
	year = {2017},
	doi = {10.1007/978-3-319-70096-0_39},
	note = {Series Title: Lecture Notes in Computer Science},
	pages = {373--382},
	file = {Guo et al. - 2017 - Deep Clustering with Convolutional Autoencoders.pdf:/Users/orsonxu/Zotero/storage/PBGLDEBP/Guo et al. - 2017 - Deep Clustering with Convolutional Autoencoders.pdf:application/pdf},
}



@article{Howard2017,
	title = {{MobileNets}: {Efficient} {Convolutional} {Neural} {Networks} for {Mobile} {Vision} {Applications}},
	url = {http://arxiv.org/abs/1704.04861},
	abstract = {We present a class of efficient models called MobileNets for mobile and embedded vision applications. MobileNets are based on a streamlined architecture that uses depth-wise separable convolutions to build light weight deep neural networks. We introduce two simple global hyper-parameters that efficiently trade off between latency and accuracy. These hyper-parameters allow the model builder to choose the right sized model for their application based on the constraints of the problem. We present extensive experiments on resource and accuracy tradeoffs and show strong performance compared to other popular models on ImageNet classification. We then demonstrate the effectiveness of MobileNets across a wide range of applications and use cases including object detection, finegrain classification, face attributes and large scale geo-localization.},
	journal = {arXiv},
	author = {Howard, Andrew G. and Zhu, Menglong and Chen, Bo and Kalenichenko, Dmitry and Wang, Weijun and Weyand, Tobias and Andreetto, Marco and Adam, Hartwig},
	year = {2017},
	file = {Howard et al_2017_MobileNets.pdf:/Users/orsonxu/Desktop/HCI/Literature Management/Zotero/Howard et al_2017_MobileNets.pdf:application/pdf},
}

@article{sandler_mobilenetv2_2018,
	title = {{MobileNetV2}: {Inverted} {Residuals} and {Linear} {Bottlenecks}},
	issn = {10636919},
	doi = {10.1109/CVPR.2018.00474},
	abstract = {In this paper we describe a new mobile architecture, MobileNetV2, that improves the state of the art performance of mobile models on multiple tasks and benchmarks as well as across a spectrum of different model sizes. We also describe efficient ways of applying these mobile models to object detection in a novel framework we call SSDLite. Additionally, we demonstrate how to build mobile semantic segmentation models through a reduced form of DeepLabv3 which we call Mobile DeepLabv3. is based on an inverted residual structure where the shortcut connections are between the thin bottleneck layers. The intermediate expansion layer uses lightweight depthwise convolutions to filter features as a source of non-linearity. Additionally, we find that it is important to remove non-linearities in the narrow layers in order to maintain representational power. We demonstrate that this improves performance and provide an intuition that led to this design. Finally, our approach allows decoupling of the input/output domains from the expressiveness of the transformation, which provides a convenient framework for further analysis. We measure our performance on ImageNet [1] classification, COCO object detection [2], VOC image segmentation [3]. We evaluate the trade-offs between accuracy, and number of operations measured by multiply-adds (MAdd), as well as actual latency, and the number of parameters.},
	journal = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
	author = {Sandler, Mark and Howard, Andrew and Zhu, Menglong and Zhmoginov, Andrey and Chen, Liang Chieh},
	year = {2018},
	note = {ISBN: 9781538664209},
	pages = {4510--4520},
	file = {Sandler et al_2018_MobileNetV2.pdf:/Users/orsonxu/Desktop/HCI/Literature Management/Zotero/Sandler et al_2018_MobileNetV2.pdf:application/pdf},
}

@article{Min2018,
	title = {A {Survey} of {Clustering} {With} {Deep} {Learning}: {From} the {Perspective} of {Network} {Architecture}},
	volume = {6},
	issn = {2169-3536},
	url = {https://ieeexplore.ieee.org/document/8412085/},
	doi = {10.1109/ACCESS.2018.2855437},
	abstract = {Clustering is a fundamental problem in many data-driven application domains, and clustering performance highly depends on the quality of data representation. Hence, linear or non-linear feature transformations have been extensively used to learn a better data representation for clustering. In recent years, a lot of works focused on using deep neural networks to learn a clustering-friendly representation, resulting in a significant increase of clustering performance. In this paper, we give a systematic survey of clustering with deep learning in views of architecture. Specifically, we first introduce the preliminary knowledge for better understanding of this field. Then, a taxonomy of clustering with deep learning is proposed and some representative methods are introduced. Finally, we propose some interesting future opportunities of clustering with deep learning and give some conclusion remarks.},
	journal = {IEEE Access},
	author = {Min, Erxue and Guo, Xifeng and Liu, Qiang and Zhang, Gen and Cui, Jianjing and Long, Jun},
	year = {2018},
	note = {Publisher: IEEE},
	keywords = {deep learning, Clustering, data representation, network architecture},
	pages = {39501--39514},
	file = {Min et al_2018_A Survey of Clustering With Deep Learning.pdf:/Users/orsonxu/Desktop/HCI/Literature Management/Zotero/Min et al_2018_A Survey of Clustering With Deep Learning.pdf:application/pdf},
}

@article{khosla_supervised_nodate,
	title = {Supervised {Contrastive} {Learning}},
	abstract = {Contrastive learning applied to self-supervised representation learning has seen a resurgence in recent years, leading to state of the art performance in the unsupervised training of deep image models. Modern batch contrastive approaches subsume or signiﬁcantly outperform traditional contrastive losses such as triplet, max-margin and the N-pairs loss. In this work, we extend the self-supervised batch contrastive approach to the fully-supervised setting, allowing us to effectively leverage label information. Clusters of points belonging to the same class are pulled together in embedding space, while simultaneously pushing apart clusters of samples from different classes. We analyze two possible versions of the supervised contrastive (SupCon) loss, identifying the best-performing formulation of the loss. On ResNet-200, we achieve top-1 accuracy of 81.4\% on the ImageNet dataset, which is 0.8\% above the best number reported for this architecture. We show consistent outperformance over cross-entropy on other datasets and two ResNet variants. The loss shows beneﬁts for robustness to natural corruptions, and is more stable to hyperparameter settings such as optimizers and data augmentations. Our loss function is simple to implement and reference TensorFlow code is released at https://t.ly/supcon 1.},
	language = {en},
	author = {Khosla, Prannay and Tian, Yonglong and Teterwak, Piotr and Wang, Chen and Isola, Phillip and Maschinot, Aaron and Krishnan, Dilip and Sarna, Aaron},
	pages = {13},
	file = {Khosla et al. - Supervised Contrastive Learning.pdf:/Users/orsonxu/Zotero/storage/VDKE2924/Khosla et al. - Supervised Contrastive Learning.pdf:application/pdf},
}

@inproceedings{tan_efficientnet_2019,
	title = {{EfficientNet}: {Rethinking} {Model} {Scaling} for {Convolutional} {Neural} {Networks}},
	shorttitle = {{EfficientNet}},
	url = {http://proceedings.mlr.press/v97/tan19a.html},
	language = {en},
	urldate = {2021-08-05},
	booktitle = {International {Conference} on {Machine} {Learning}},
	publisher = {PMLR},
	author = {Tan, Mingxing and Le, Quoc},
	month = may,
	year = {2019},
	note = {ISSN: 2640-3498},
	pages = {6105--6114},
	file = {Full Text PDF:/Users/orsonxu/Zotero/storage/KLWMBJAN/Tan and Le - 2019 - EfficientNet Rethinking Model Scaling for Convolu.pdf:application/pdf},
}

@book{mamalet_simplifying_2012,
	title = {Simplifying {ConvNets} for {Fast} {Learning}},
	isbn = {978-3-642-33265-4},
	abstract = {In this paper, we propose different strategies for simplifying filters, used as feature extractors, to be learnt in convolutional neural networks (ConvNets) in order to modify the hypothesis space, and to speed-up learning and processing times. We study two kinds of filters that are known to be computationally efficient in feed-forward processing: fused convolution/sub-sampling filters, and separable filters. We compare the complexity of the back-propagation algorithm on ConvNets based on these different kinds of filters. We show that using these filters allows to reach the same level of recognition performance as with classical ConvNets for handwritten digit recognition, up to 3.3 times faster.},
	author = {Mamalet, Franck and Garcia, Christophe},
	month = sep,
	year = {2012},
	doi = {10.1007/978-3-642-33266-1_8},
}

@inproceedings{chollet_xception_2017,
	address = {Honolulu, HI},
	title = {Xception: {Deep} {Learning} with {Depthwise} {Separable} {Convolutions}},
	isbn = {978-1-5386-0457-1},
	shorttitle = {Xception},
	url = {http://ieeexplore.ieee.org/document/8099678/},
	doi = {10.1109/CVPR.2017.195},
	abstract = {We present an interpretation of Inception modules in convolutional neural networks as being an intermediate step in-between regular convolution and the depthwise separable convolution operation (a depthwise convolution followed by a pointwise convolution). In this light, a depthwise separable convolution can be understood as an Inception module with a maximally large number of towers. This observation leads us to propose a novel deep convolutional neural network architecture inspired by Inception, where Inception modules have been replaced with depthwise separable convolutions. We show that this architecture, dubbed Xception, slightly outperforms Inception V3 on the ImageNet dataset (which Inception V3 was designed for), and signiﬁcantly outperforms Inception V3 on a larger image classiﬁcation dataset comprising 350 million images and 17,000 classes. Since the Xception architecture has the same number of parameters as Inception V3, the performance gains are not due to increased capacity but rather to a more efﬁcient use of model parameters.},
	language = {en},
	urldate = {2021-08-05},
	booktitle = {2017 {IEEE} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} ({CVPR})},
	publisher = {IEEE},
	author = {Chollet, Francois},
	month = jul,
	year = {2017},
	pages = {1800--1807},
	file = {Chollet - 2017 - Xception Deep Learning with Depthwise Separable C.pdf:/Users/orsonxu/Zotero/storage/MMEDZMBC/Chollet - 2017 - Xception Deep Learning with Depthwise Separable C.pdf:application/pdf},
}

@article{hecht-nielsen_theory_1992,
	title = {Theory of the {Backpropagation} {Neural} {Network}},
	language = {en},
	journal = {Neural networks for perception},
	author = {Hecht-Nielsen, Robert},
	year = {1992},
	pages = {13},
	file = {Hecht-Nielsen - Theory of the Backpropagation Neural Network.pdf:/Users/orsonxu/Zotero/storage/WT5ADWXN/Hecht-Nielsen - Theory of the Backpropagation Neural Network.pdf:application/pdf},
}

@article{ioffe_batch_2015,
	title = {Batch {Normalization}: {Accelerating} {Deep} {Network} {Training} by {Reducing} {Internal} {Covariate} {Shift}},
	abstract = {Training Deep Neural Networks is complicated by the fact that the distribution of each layer’s inputs changes during training, as the parameters of the previous layers change. This slows down the training by requiring lower learning rates and careful parameter initialization, and makes it notoriously hard to train models with saturating nonlinearities. We refer to this phenomenon as internal covariate shift, and address the problem by normalizing layer inputs. Our method draws its strength from making normalization a part of the model architecture and performing the normalization for each training mini-batch. Batch Normalization allows us to use much higher learning rates and be less careful about initialization, and in some cases eliminates the need for Dropout. Applied to a stateof-the-art image classiﬁcation model, Batch Normalization achieves the same accuracy with 14 times fewer training steps, and beats the original model by a signiﬁcant margin. Using an ensemble of batch-normalized networks, we improve upon the best published result on ImageNet classiﬁcation: reaching 4.82\% top-5 test error, exceeding the accuracy of human raters.},
	language = {en},
	journal = {Proceedings of the 32 nd International Conference on Machine Learning},
	author = {Ioffe, Sergey and Szegedy, Christian},
	year = {2015},
	pages = {9},
	file = {Ioffe and Szegedy - Batch Normalization Accelerating Deep Network Tra.pdf:/Users/orsonxu/Zotero/storage/S6IPEAIA/Ioffe and Szegedy - Batch Normalization Accelerating Deep Network Tra.pdf:application/pdf},
}

@article{gal_dropout_2016,
	title = {Dropout as a {Bayesian} {Approximation}:  {Representing} {Model} {Uncertainty} in {Deep} {Learning}},
	abstract = {Deep learning tools have gained tremendous attention in applied machine learning. However such tools for regression and classiﬁcation do not capture model uncertainty. In comparison, Bayesian models offer a mathematically grounded framework to reason about model uncertainty, but usually come with a prohibitive computational cost. In this paper we develop a new theoretical framework casting dropout training in deep neural networks (NNs) as approximate Bayesian inference in deep Gaussian processes. A direct result of this theory gives us tools to model uncertainty with dropout NNs –extracting information from existing models that has been thrown away so far. This mitigates the problem of representing uncertainty in deep learning without sacriﬁcing either computational complexity or test accuracy. We perform an extensive study of the properties of dropout’s uncertainty. Various network architectures and nonlinearities are assessed on tasks of regression and classiﬁcation, using MNIST as an example. We show a considerable improvement in predictive log-likelihood and RMSE compared to existing state-of-the-art methods, and ﬁnish by using dropout’s uncertainty in deep reinforcement learning.},
	language = {en},
	journal = {Proceedings of the 33 rd International Conference on Machine Learning},
	author = {Gal, Yarin and Ghahramani, Zoubin},
	year = {2016},
	pages = {10},
	file = {Gal and Ghahramani - Dropout as a Bayesian Approximation  Representing.pdf:/Users/orsonxu/Zotero/storage/4RHK5EMV/Gal and Ghahramani - Dropout as a Bayesian Approximation  Representing.pdf:application/pdf},
}

@article{nair_rectified_2010,
	title = {Rectified {Linear} {Units} {Improve} {Restricted} {Boltzmann} {Machines}},
	abstract = {Restricted Boltzmann machines were developed using binary stochastic hidden units. These can be generalized by replacing each binary unit by an inﬁnite number of copies that all have the same weights but have progressively more negative biases. The learning and inference rules for these “Stepped Sigmoid Units” are unchanged. They can be approximated eﬃciently by noisy, rectiﬁed linear units. Compared with binary units, these units learn features that are better for object recognition on the NORB dataset and face veriﬁcation on the Labeled Faces in the Wild dataset. Unlike binary units, rectiﬁed linear units preserve information about relative intensities as information travels through multiple layers of feature detectors.},
	language = {en},
	journal = {Proceedings of the 27 th International Conference on Machine Learning},
	author = {Nair, Vinod and Hinton, Geoffrey E},
	year = {2010},
	pages = {8},
	file = {Nair and Hinton - Rectified Linear Units Improve Restricted Boltzman.pdf:/Users/orsonxu/Zotero/storage/KL6MKC6B/Nair and Hinton - Rectified Linear Units Improve Restricted Boltzman.pdf:application/pdf},
}

@book{goodfellow_deep_2016,
	title = {Deep learning},
	publisher = {MIT press},
	author = {Goodfellow, Ian and Bengio, Yoshua and Courville,, Aaron},
	year = {2016},
	file = {Deep_learning__adaptive_computation_and_machine_learning__PDFDrive.com_20190819-23861-ck1r7v-with-cover-page-v2.pdf:/Users/orsonxu/Zotero/storage/DNWKE37W/Deep_learning__adaptive_computation_and_machine_learning__PDFDrive.com_20190819-23861-ck1r7v-with-cover-page-v2.pdf:application/pdf},
}

@article{miyato_virtual_2019,
	title = {Virtual {Adversarial} {Training}: {A} {Regularization} {Method} for {Supervised} and {Semi}-{Supervised} {Learning}},
	volume = {41},
	issn = {1939-3539},
	shorttitle = {Virtual {Adversarial} {Training}},
	doi = {10.1109/TPAMI.2018.2858821},
	abstract = {We propose a new regularization method based on virtual adversarial loss: a new measure of local smoothness of the conditional label distribution given input. Virtual adversarial loss is defined as the robustness of the conditional label distribution around each input data point against local perturbation. Unlike adversarial training, our method defines the adversarial direction without label information and is hence applicable to semi-supervised learning. Because the directions in which we smooth the model are only “virtually” adversarial, we call our method virtual adversarial training (VAT). The computational cost of VAT is relatively low. For neural networks, the approximated gradient of virtual adversarial loss can be computed with no more than two pairs of forward-and back-propagations. In our experiments, we applied VAT to supervised and semi-supervised learning tasks on multiple benchmark datasets. With a simple enhancement of the algorithm based on the entropy minimization principle, our VAT achieves state-of-the-art performance for semi-supervised learning tasks on SVHN and CIFAR-10.},
	number = {8},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	author = {Miyato, Takeru and Maeda, Shin-Ichi and Koyama, Masanori and Ishii, Shin},
	month = aug,
	year = {2019},
	note = {Conference Name: IEEE Transactions on Pattern Analysis and Machine Intelligence},
	keywords = {deep learning, Artificial neural networks, Training, Computational modeling, Data models, adversarial examples, adversarial training, Perturbation methods, robustness, Robustness, Semi-supervised learning, Semisupervised learning, supervised learning},
	pages = {1979--1993},
	file = {IEEE Xplore Abstract Record:/Users/orsonxu/Zotero/storage/H2B3BZEF/8417973.html:text/html;IEEE Xplore Full Text PDF:/Users/orsonxu/Zotero/storage/WT57LGGU/Miyato et al. - 2019 - Virtual Adversarial Training A Regularization Met.pdf:application/pdf},
}

@inproceedings{hershey_cnn_2017,
	title = {{CNN} architectures for large-scale audio classification},
	doi = {10.1109/ICASSP.2017.7952132},
	abstract = {Convolutional Neural Networks (CNNs) have proven very effective in image classification and show promise for audio. We use various CNN architectures to classify the soundtracks of a dataset of 70M training videos (5.24 million hours) with 30,871 video-level labels. We examine fully connected Deep Neural Networks (DNNs), AlexNet [1], VGG [2], Inception [3], and ResNet [4]. We investigate varying the size of both training set and label vocabulary, finding that analogs of the CNNs used in image classification do well on our audio classification task, and larger training and label sets help up to a point. A model using embeddings from these classifiers does much better than raw features on the Audio Set [5] Acoustic Event Detection (AED) classification task.},
	booktitle = {2017 {IEEE} {International} {Conference} on {Acoustics}, {Speech} and {Signal} {Processing} ({ICASSP})},
	author = {Hershey, Shawn and Chaudhuri, Sourish and Ellis, Daniel P. W. and Gemmeke, Jort F. and Jansen, Aren and Moore, R. Channing and Plakal, Manoj and Platt, Devin and Saurous, Rif A. and Seybold, Bryan and Slaney, Malcolm and Weiss, Ron J. and Wilson, Kevin},
	month = mar,
	year = {2017},
	note = {ISSN: 2379-190X},
	keywords = {Hidden Markov models, Neural networks, Training, Acoustic Event Detection, Acoustic Scene Classification, Computer architecture, Convolutional Neural Networks, Deep Neural Networks, Servers, Spectrogram, Video Classification, Videos},
	pages = {131--135},
	file = {IEEE Xplore Abstract Record:/Users/orsonxu/Zotero/storage/G6G35YCJ/7952132.html:text/html;IEEE Xplore Full Text PDF:/Users/orsonxu/Zotero/storage/U92X385U/Hershey et al. - 2017 - CNN architectures for large-scale audio classifica.pdf:application/pdf},
}

@inproceedings{chen_simple_2020,
	title = {A {Simple} {Framework} for {Contrastive} {Learning} of {Visual} {Representations}},
	url = {https://proceedings.mlr.press/v119/chen20j.html},
	abstract = {This paper presents SimCLR: a simple framework for contrastive learning of visual representations. We simplify recently proposed contrastive self-supervised learning algorithms without requiring specialized architectures or a memory bank. In order to understand what enables the contrastive prediction tasks to learn useful representations, we systematically study the major components of our framework. We show that (1) composition of data augmentations plays a critical role in defining effective predictive tasks, (2) introducing a learnable nonlinear transformation between the representation and the contrastive loss substantially improves the quality of the learned representations, and (3) contrastive learning benefits from larger batch sizes and more training steps compared to supervised learning. By combining these findings, we are able to considerably outperform previous methods for self-supervised and semi-supervised learning on ImageNet. A linear classifier trained on self-supervised representations learned by SimCLR achieves 76.5\% top-1 accuracy, which is a 7\% relative improvement over previous state-of-the-art, matching the performance of a supervised ResNet-50. When fine-tuned on only 1\% of the labels, we achieve 85.8\% top-5 accuracy, outperforming AlexNet with 100X fewer labels.},
	language = {en},
	urldate = {2022-01-04},
	booktitle = {Proceedings of the 37th {International} {Conference} on {Machine} {Learning}},
	publisher = {PMLR},
	author = {Chen, Ting and Kornblith, Simon and Norouzi, Mohammad and Hinton, Geoffrey},
	month = nov,
	year = {2020},
	note = {ISSN: 2640-3498},
	pages = {1597--1607},
	file = {Chen et al_2020_A Simple Framework for Contrastive Learning of Visual Representations.pdf:/Users/orsonxu/Desktop/HCI/Literature Management/Zotero/Chen et al_2020_A Simple Framework for Contrastive Learning of Visual Representations.pdf:application/pdf;Supplementary PDF:/Users/orsonxu/Zotero/storage/GR29F3TD/Chen et al. - 2020 - A Simple Framework for Contrastive Learning of Vis.pdf:application/pdf},
}

@inproceedings{vaswani_attention_2017,
	title = {Attention is {All} you {Need}},
	volume = {30},
	url = {https://proceedings.neurips.cc/paper/2017/hash/3f5ee243547dee91fbd053c1c4a845aa-Abstract.html},
	urldate = {2022-01-04},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates, Inc.},
	author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, Łukasz and Polosukhin, Illia},
	year = {2017},
	file = {Vaswani et al_2017_Attention is All you Need.pdf:/Users/orsonxu/Desktop/HCI/Literature Management/Zotero/Vaswani et al_2017_Attention is All you Need.pdf:application/pdf},
}

@article{dosovitskiy_image_2021,
	title = {An {Image} is {Worth} 16x16 {Words}: {Transformers} for {Image} {Recognition} at {Scale}},
	shorttitle = {An {Image} is {Worth} 16x16 {Words}},
	url = {http://arxiv.org/abs/2010.11929},
	abstract = {While the Transformer architecture has become the de-facto standard for natural language processing tasks, its applications to computer vision remain limited. In vision, attention is either applied in conjunction with convolutional networks, or used to replace certain components of convolutional networks while keeping their overall structure in place. We show that this reliance on CNNs is not necessary and a pure transformer applied directly to sequences of image patches can perform very well on image classification tasks. When pre-trained on large amounts of data and transferred to multiple mid-sized or small image recognition benchmarks (ImageNet, CIFAR-100, VTAB, etc.), Vision Transformer (ViT) attains excellent results compared to state-of-the-art convolutional networks while requiring substantially fewer computational resources to train.},
	urldate = {2022-01-06},
	journal = {arXiv:2010.11929 [cs]},
	author = {Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and Uszkoreit, Jakob and Houlsby, Neil},
	month = jun,
	year = {2021},
	note = {arXiv: 2010.11929},
	file = {Dosovitskiy et al_2021_An Image is Worth 16x16 Words.pdf:/Users/orsonxu/Desktop/HCI/Literature Management/Zotero/Dosovitskiy et al_2021_An Image is Worth 16x16 Words.pdf:application/pdf},
}

@article{zhang_mixup_2018,
	title = {mixup: {Beyond} {Empirical} {Risk} {Minimization}},
	shorttitle = {mixup},
	url = {http://arxiv.org/abs/1710.09412},
	abstract = {Large deep neural networks are powerful, but exhibit undesirable behaviors such as memorization and sensitivity to adversarial examples. In this work, we propose mixup, a simple learning principle to alleviate these issues. In essence, mixup trains a neural network on convex combinations of pairs of examples and their labels. By doing so, mixup regularizes the neural network to favor simple linear behavior in-between training examples. Our experiments on the ImageNet-2012, CIFAR-10, CIFAR-100, Google commands and UCI datasets show that mixup improves the generalization of state-of-the-art neural network architectures. We also ﬁnd that mixup reduces the memorization of corrupt labels, increases the robustness to adversarial examples, and stabilizes the training of generative adversarial networks.},
	language = {en},
	urldate = {2022-03-27},
	journal = {arXiv:1710.09412 [cs, stat]},
	author = {Zhang, Hongyi and Cisse, Moustapha and Dauphin, Yann N. and Lopez-Paz, David},
	month = apr,
	year = {2018},
	note = {arXiv: 1710.09412},
	file = {Zhang et al. - 2018 - mixup Beyond Empirical Risk Minimization.pdf:/Users/orsonxu/Zotero/storage/SVVV6YNW/Zhang et al. - 2018 - mixup Beyond Empirical Risk Minimization.pdf:application/pdf},
}

@article{koch_siamese_2015,
	title = {Siamese {Neural} {Networks} for {One}-shot {Image} {Recognition}},
	abstract = {The process of learning good features for machine learning applications can be very computationally expensive and may prove difﬁcult in cases where little data is available. A prototypical example of this is the one-shot learning setting, in which we must correctly make predictions given only a single example of each new class. In this paper, we explore a method for learning siamese neural networks which employ a unique structure to naturally rank similarity between inputs. Once a network has been tuned, we can then capitalize on powerful discriminative features to generalize the predictive power of the network not just to new data, but to entirely new classes from unknown distributions. Using a convolutional architecture, we are able to achieve strong results which exceed those of other deep learning models with near state-of-the-art performance on one-shot classiﬁcation tasks.},
	language = {en},
	journal = {Proceedings of the 32nd International Conference on Machine Learning},
	author = {Koch, Gregory and Zemel, Richard and Salakhutdinov, Ruslan},
	year = {2015},
	pages = {8},
	file = {Koch et al. - Siamese Neural Networks for One-shot Image Recogni.pdf:/Users/orsonxu/Zotero/storage/5DE8XGPU/Koch et al. - Siamese Neural Networks for One-shot Image Recogni.pdf:application/pdf},
}


@article{zakaria_stressmon_2019,
	title = {Stressmon: {Scalable} detection of perceived stress and depression using passive sensing of changes in work routines and group interactions},
	volume = {3},
	issn = {25730142},
	doi = {10.1145/3359139},
	abstract = {Stress and depression are a common affliction in all walks of life. When left unmanaged, stress can inhibit productivity or cause depression. Depression can occur independently of stress. There has been a sharp rise in mobile health initiatives to monitor stress and depression. However, these initiatives usually require users to install dedicated apps or multiple sensors, making such solutions hard to scale. Moreover, they emphasise sensing individual factors and overlook social interactions, which plays a significant role in influencing stress and depression while being a part of a social system. We present StressMon, a stress and depression detection system that leverages single-attribute location data, passively sensed from the WiFi infrastructure. Using the location data, it extracts a detailed set of movement, and physical group interaction pattern features without requiring explicit user actions or software installation on client devices. These features are used in two different machine learning models to detect stress and depression. To validate StressMon, we conducted three different longitudinal studies at a university with different groups of students, totalling up to 108 participants. Our evaluation demonstrated StressMon detecting severely stressed students with a 96.01\% True Positive Rate (TPR), an 80.76\% True Negative Rate (TNR), and a 0.97 area under the ROC curve (AUC) score (a score of 1 indicates a perfect binary classifier) using a 6-day prediction window. In addition, StressMon was able to detect depression at 91.21\% TPR, 66.71\% TNR, and 0.88 AUC using a 15-day window. We end by discussing how StressMon can expand CSCW research, especially in areas involving collaborative practices for mental health management.},
	number = {CSCW},
	journal = {Proceedings of the ACM on Human-Computer Interaction},
	author = {Zakaria, Camellia and Balan, Rajesh and Lee, Youngki},
	year = {2019},
	keywords = {Depression, Stress, Mobility patterns, Small-group, Wi-Fi indoor localisation},
	file = {Zakaria et al_2019_Stressmon.pdf:/Users/orsonxu/Desktop/HCI/Literature Management/Zotero/Zakaria et al_2019_Stressmon.pdf:application/pdf},
}

@article{mehrotra_using_2018,
	title = {Using {Autoencoders} to {Automatically} {Extract} {Mobility} {Features} for {Predicting} {Depressive} {States}},
	volume = {2},
	issn = {2474-9567},
	doi = {10.1145/3264937},
	abstract = {Recent studies have shown the potential of exploiting GPS data for passively inferring people's mental health conditions. However, feature extraction for characterizing human mobility remains a heuristic process that relies on the domain knowledge of the condition under consideration. Moreover, we do not have guarantees that these "hand-crafted" metrics are able to eï¿¿ectively capture mobility behavior of users. Indeed, informative emerging patterns in the data might not be characterized by them. This is also a complex and often time-consuming task, since it usually consists of a lengthy trial-and-error process. In this paper, we investigate the potential of using autoencoders for automatically extracting features from the raw input data. Through a series of experiments we show the eï¿¿ectiveness of autoencoder-based features for predicting depressive states of individuals compared to "hand-crafted" ones. Our results show that automatically extracted features lead to an improvement of the performance of the prediction models, while, at the same time, reducing the complexity of the feature design task. Moreover, through an extensive experimental performance analysis, we demonstrate the optimal conï¿¿guration of the key parameters at the basis of the proposed approach.},
	number = {3},
	journal = {Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies},
	author = {Mehrotra, Abhinav and Musolesi, Mirco},
	year = {2018},
	pages = {1--20},
	file = {Mehrotra_Musolesi_2018_Using Autoencoders to Automatically Extract Mobility Features for Predicting Depressive States.pdf:/Users/orsonxu/Desktop/HCI/Literature Management/Zotero/Mehrotra_Musolesi_2018_Using Autoencoders to Automatically Extract Mobility Features for Predicting Depressive States.pdf:application/pdf},
}

@inproceedings{10.1145/2632048.2632100,
 address = {New York, NY, USA},
 author = {Abdullah, Saeed and Matthews, Mark and Murnane, Elizabeth L. and Gay, Geri and Choudhury, Tanzeem},
 booktitle = {Proceedings of the 2014 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
 doi = {10.1145/2632048.2632100},
 isbn = {9781450329682},
 keywords = {biological rhythms, mHealth, sleep, circadian rhythms, mobile computation, chronotype},
 location = {Seattle, Washington},
 numpages = {12},
 pages = {673–684},
 publisher = {Association for Computing Machinery},
 series = {UbiComp ’14},
 title = {Towards circadian computing: ``early to bed and early to rise'' makes some of us unhealthy and sleep deprived},
 url = {https://doi.org/10.1145/2632048.2632100},
 year = {2014}
}

@article{10.1145/3090051,
 address = {New York, NY, USA},
 articleno = {Article 5},
 author = {Bae, Sangwon and Ferreira, Denzil and Suffoletto, Brian and Puyana, Juan C. and Kurtz, Ryan and Chung, Tammy and Dey, Anind K.},
 doi = {10.1145/3090051},
 issue_date = {June 2017},
 journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
 keywords = {Young adults, Machine learning, Smartphone sensors, Alcohol consumption, Behavioral model},
 month = {Jun},
 number = {2},
 numpages = {36},
 publisher = {Association for Computing Machinery},
 title = {Detecting drinking episodes in young adults using smartphone-based sensors},
 url = {https://doi.org/10.1145/3090051},
 volume = {1},
 year = {2017}
}

@inproceedings{10.1145/3290607.3299041,
 author = {Stephen M. Mattingly and
Julie M. Gregg and
Pino G. Audia and
Ayse Elvan Bayraktaroglu and
Andrew T. Campbell and
Nitesh V. Chawla and
Vedant Das Swain and
Munmun De Choudhury and
Sidney K. D'Mello and
Anind K. Dey and
others},
 bibsource = {dblp computer science bibliography, https://dblp.org},
 biburl = {https://dblp.org/rec/conf/chi/MattinglyGABCCS19.bib},
 booktitle = {Extended Abstracts of the 2019 {CHI} Conference on Human Factors in
Computing Systems, {CHI} 2019, Glasgow, Scotland, UK, May 04-09, 2019},
 editor = {Regan L. Mandryk and
Stephen A. Brewster and
Mark Hancock and
Geraldine Fitzpatrick and
Anna L. Cox and
Vassilis Kostakos and
Mark Perry},
 publisher = {{ACM}},
 timestamp = {Sun, 25 Oct 2020 22:41:20 +0100},
 title = {The tesserae project: Large-scale, longitudinal, \emph{in situ, }
multimodal sensing of information workers},
 url = {https://doi.org/10.1145/3290607.3299041},
 year = {2019}
}

@article{10.1145/3328908,
 author = {Shayan Mirjafari and
Kizito Masaba and
Ted Grover and
Weichen Wang and
Pino G. Audia and
Andrew T. Campbell and
Nitesh V. Chawla and
Vedant Das Swain and
Munmun De Choudhury and
Anind K. Dey and others},
 bibsource = {dblp computer science bibliography, https://dblp.org},
 biburl = {https://dblp.org/rec/journals/imwut/MirjafariMGWACC19.bib},
 doi = {10.1145/3328908},
 journal = {Proc. {ACM} Interact. Mob. Wearable Ubiquitous Technol.},
 number = {2},
 pages = {37:1--37:24},
 timestamp = {Mon, 26 Oct 2020 09:00:22 +0100},
 title = {Differentiating higher and lower job performers in the workplace using
mobile sensing},
 volume = {3},
 year = {2019}
}

@article{10.1145/3351229,
 address = {New York, NY, USA},
 articleno = {Article 71},
 author = {Ahuja, Karan and Kim, Dohyun and Xhakaj, Franceska and Varga, Virag and Xie, Anne and Zhang, Stanley and Townsend, Jay Eric and Harrison, Chris and Ogan, Amy and Agarwal, Yuvraj},
 doi = {10.1145/3351229},
 issue_date = {September 2019},
 journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
 keywords = {Speech Detection, Teacher, Sensing, Audio, Pedagogy, Classroom, Machine Learning, Instructor, Computer Vision},
 month = {Sep},
 number = {3},
 numpages = {26},
 publisher = {Association for Computing Machinery},
 title = {EduSense: Practical classroom sensing at scale},
 url = {https://doi.org/10.1145/3351229},
 volume = {3},
 year = {2019}
}

@article{1997Friedman_ldt,
 author = {Friedman, Jerome and Kohavi, Ron and Yun, Yeogirl},
 journal = {Proceedings of the AAAI},
 month = {09},
 pages = {},
 title = {Lazy decision trees},
 volume = {1},
 year = {1997}
}

@inproceedings{abdullah2012towards,
 author = {Abdullah, Saeed and Lane, Nicholas D and Choudhury, Tanzeem},
 booktitle = {Twenty-Sixth AAAI Conference on Artificial Intelligence},
 title = {Towards population scale activity recognition: A framework for handling data diversity},
 year = {2012}
}

@article{abdullah2016automatic,
 author = {Abdullah, Saeed and Matthews, Mark and Frank, Ellen and Doherty, Gavin and Gay, Geri and Choudhury, Tanzeem},
 journal = {Journal of the American Medical Informatics Association},
 number = {3},
 pages = {538--543},
 publisher = {Oxford University Press},
 title = {Automatic detection of social rhythms in bipolar disorder},
 volume = {23},
 year = {2016}
}

@inproceedings{abowd1999towards,
 author = {Abowd, Gregory D. and Dey, Anind K. and Brown, Peter J. and Davies, Nigel and Smith, Mark and Steggles, Pete},
 booktitle = {International Symposium on Handheld and Ubiquitous Computing},
 organization = {Springer},
 pages = {304--307},
 title = {Towards a better understanding of context and context-awareness},
 year = {1999}
}

@article{abuse20162015,
 author = {Abuse, Substance and Administration, Mental Health Services and others},
 publisher = {Substance Abuse and Mental Health Services Administration (US)},
 title = {2015 national survey on drug use and health},
 year = {2016}
}

@inproceedings{agrawal1994fast,
 author = {Agrawal, Rakesh and Srikant, Ramakrishnan},
 booktitle = {Proceedings of 20th International Conference on Very Large Data Bases, VLDB},
 pages = {487--499},
 title = {Fast algorithms for mining association rules},
 volume = {1215},
 year = {1994}
}

@inproceedings{agrawal1995mining,
 author = {Agrawal, Rakesh and Srikant, Ramakrishnan},
 booktitle = {Proceedings of the 11th International Conference on Data Engineering},
 organization = {IEEE},
 pages = {3--14},
 title = {Mining sequential patterns},
 year = {1995}
}

@article{alghowinem2016multimodal,
 author = {Alghowinem, Sharifa and Goecke, Roland and Wagner, Michael and Epps, Julien and Hyett, Matthew and Parker, Gordon and Breakspear, Michael},
 journal = {IEEE Transactions on Affective Computing},
 publisher = {IEEE},
 title = {Multimodal depression detection: Fusion analysis of paralinguistic, head pose and eye gaze behaviors},
 year = {2016}
}

@book{american2013diagnostic,
 author = {American Psychiatric Association and others},
 publisher = {American Psychiatric Pub},
 title = {Diagnostic and statistical manual of mental disorders (dsm-5{\textregistered})},
 year = {2013}
}

@inproceedings{antonie2001application,
 author = {Antonie, Maria-Luiza and Zaiane, Osmar R. and Coman, Alexandru},
 booktitle = {Proceedings of the Second International Conference on Multimedia Data Mining},
 organization = {Springer-Verlag},
 pages = {94--101},
 title = {Application of data mining techniques for medical image classification},
 year = {2001}
}

@incollection{atkeson1997locally,
 author = {Atkeson, Christopher G and Moore, Andrew W and Schaal, Stefan},
 booktitle = {Lazy Learning},
 pages = {11--73},
 publisher = {Springer},
 title = {Locally weighted learning},
 year = {1997}
}

@article{aung2016leveraging,
 author = {Aung, Min S. Hane and Alquaddoomi, Faisal and Hsieh, Cheng-Kang and Rabbi, Mashfiqui and Yang, Longqi and Pollak, John P. and Estrin, Deborah and Choudhury, Tanzeem},
 journal = {IEEE Journal of Selected Topics in Signal Processing},
 number = {5},
 pages = {962--974},
 publisher = {IEEE},
 title = {Leveraging multi-modal sensing for mobile health: A case review in chronic pain},
 volume = {10},
 year = {2016}
}

@inproceedings{banovic2016modeling,
 author = {Banovic, Nikola and Buzali, Tofi and Chevalier, Fanny and Mankoff, Jennifer and Dey, Anind K.},
 booktitle = {Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems},
 organization = {ACM},
 pages = {248--260},
 title = {Modeling and understanding human routine behavior},
 year = {2016}
}

@inproceedings{banovic2017leveraging,
 author = {Banovic, Nikola and Wang, Anqi and Jin, Yanfeng and Chang, Christie and Ramos, Julian and Dey, Anind K. and Mankoff, Jennifer},
 booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
 organization = {ACM},
 pages = {6683--6694},
 title = {Leveraging human routine models to detect and generate human behaviors},
 year = {2017}
}

@book{beck1979cognitive,
 author = {Beck, Aaron T.},
 publisher = {Guilford press},
 title = {Cognitive therapy of depression},
 year = {1979}
}

@article{beck1996beck,
 author = {Beck, Aaron T. and Steer, Robert A. and Brown, Gregory K.},
 journal = {San Antonio},
 number = {2},
 pages = {490--498},
 title = {Beck depression inventory-ii},
 volume = {78},
 year = {1996}
}

@article{ben2015next,
 author = {Ben-Zeev, Dror and Scherer, Emily A. and Wang, Rui and Xie, Haiyi and Campbell, Andrew T.},
 journal = {Psychiatric Rehabilitation Journal},
 number = {3},
 pages = {218},
 publisher = {Educational Publishing Foundation},
 title = {Next-generation psychiatric assessment: Using smartphone sensors to monitor behavior and mental health.},
 volume = {38},
 year = {2015}
}

@inproceedings{berlingerio2009mining,
 author = {Berlingerio, Michele and Bonchi, Francesco and Bringmann, Bj{\"o}rn and Gionis, Aristides},
 booktitle = {Joint European Conference on Machine Learning and Knowledge Discovery in Databases},
 organization = {Springer},
 pages = {115--130},
 title = {Mining graph evolution rules},
 year = {2009}
}

@inproceedings{brdiczka2009using,
 author = {Brdiczka, Oliver and Su, Norman Makoto and Begole, Bo},
 booktitle = {CHI'09 Extended Abstracts on Human Factors in Computing Systems},
 organization = {ACM},
 pages = {4081--4086},
 title = {Using temporal patterns (t-patterns) to derive stress factors of routine tasks},
 year = {2009}
}

@inproceedings{brdiczka2010temporal,
 author = {Brdiczka, Oliver and Su, Norman Makoto and Begole, James Bo},
 booktitle = {Proceedings of the 15th International Conference on Intelligent User Interfaces},
 organization = {ACM},
 pages = {281--284},
 title = {Temporal task footprinting: Identifying routine tasks by their temporal patterns},
 year = {2010}
}

@article{breese2013empirical,
 author = {Breese, John S and Heckerman, David and Kadie, Carl},
 journal = {arXiv preprint arXiv:1301.7363},
 title = {Empirical analysis of predictive algorithms for collaborative filtering},
 year = {2013}
}

@article{brown1986social,
 author = {Brown, George W. and Andrews, Bernice and Harris, Tirril and Adler, Zsuzsanna and Bridge, L.},
 journal = {Psychological medicine},
 number = {4},
 pages = {813--831},
 publisher = {Cambridge University Press},
 title = {Social support, self-esteem and depression},
 volume = {16},
 year = {1986}
}

@article{brown2003benefits,
 author = {Brown, Kirk Warren and Ryan, Richard M},
 journal = {Journal of personality and social psychology},
 number = {4},
 pages = {822},
 publisher = {American Psychological Association},
 title = {The benefits of being present: Mindfulness and its role in psychological well-being.},
 volume = {84},
 year = {2003}
}

@article{burns2011harnessing,
 author = {Burns, Michelle Nicole and Begale, Mark and Duffecy, Jennifer and Gergle, Darren and Karr, Chris J. and Giangrande, Emily and Mohr, David C.},
 journal = {Journal of Medical Internet Research},
 number = {3},
 publisher = {JMIR Publications Inc.},
 title = {Harnessing context sensing to develop a mobile intervention for depression},
 volume = {13},
 year = {2011}
}

@inproceedings{cao2010effective,
 author = {Cao, Huanhuan and Bao, Tengfei and Yang, Qiang and Chen, Enhong and Tian, Jilei},
 booktitle = {Proceedings of the 19th ACM International Conference on Information and Knowledge Management},
 organization = {ACM},
 pages = {1677--1680},
 title = {An effective approach for mining mobile user habits},
 year = {2010}
}

@article{chow2017using,
 author = {Chow, Philip I. and Fua, Karl and Huang, Yu and Bonelli, Wesley and Xiong, Haoyi and Barnes, Laura E. and Teachman, Bethany A.},
 journal = {Journal of Medical Internet Research},
 number = {3},
 publisher = {JMIR Publications Inc.},
 title = {Using mobile sensing to test clinical models of depression, social anxiety, state affect, and social isolation among college students},
 volume = {19},
 year = {2017}
}

@article{cox1991effects,
 author = {Cox, Taylor H and Lobel, Sharon A and McLeod, Poppy Lauretta},
 journal = {Academy of management journal},
 number = {4},
 pages = {827--847},
 publisher = {Academy of Management Briarcliff Manor, NY 10510},
 title = {Effects of ethnic group cultural differences on cooperative and competitive behavior on a group task},
 volume = {34},
 year = {1991}
}

@article{cuijpers1998psychoeducational,
 author = {Cuijpers, Pim},
 journal = {Behavior Therapy},
 number = {3},
 pages = {521--533},
 publisher = {Elsevier},
 title = {A psychoeducational approach to the treatment of depression: A meta-analysis of lewinsohn's “coping with depression” course},
 volume = {29},
 year = {1998}
}

@article{czyz2013self,
 author = {Czyz, Ewa K. and Horwitz, Adam G. and Eisenberg, Daniel and Kramer, Anne and King, Cheryl A.},
 journal = {Journal of American College Health},
 number = {7},
 pages = {398--406},
 publisher = {Taylor \& Francis},
 title = {Self-reported barriers to professional help seeking among college students at elevated risk for suicide},
 volume = {61},
 year = {2013}
}

@misc{datareport2019,
 howpublished = {\url{https://www.acha.org/documents/ncha/NCHA-II_Spring_2019_Undergraduate_Reference_Group_Data_Report.pdf}},
 key = {{ACHA-NCHA II}},
 title = {{undergraduate student reference group - data report}},
 year = {2019}
}

@article{de2005systematic,
 author = {de Mello, M Feijo and de Jesus Mari, Jair and Bacaltchuk, Josue and Verdeli, Helen and Neugebauer, Richard},
 journal = {European archives of psychiatry and clinical neuroscience},
 number = {2},
 pages = {75--82},
 publisher = {Springer},
 title = {A systematic review of research findings on the efficacy of interpersonal therapy for depressive disorders},
 volume = {255},
 year = {2005}
}

@article{de2018response,
 author = {de S{\'a} Junior, Antonio Reis and de Andrade, Arthur Guerra and Andrade, Laura Helena and Gorenstein, Clarice and Wang, Yuan-Pang},
 journal = {Journal of Affective Disorders},
 pages = {124--130},
 publisher = {Elsevier},
 title = {Response pattern of depressive symptoms among college students: What lies behind items of the beck depression inventory-ii?},
 volume = {234},
 year = {2018}
}

@article{DeDomenico2013,
 abstract = {Previous studies have shown that human movement is predictable to a certain extent at different geographic scales. The existing prediction techniques exploit only the past history of the person taken into consideration as input of the predictors. In this paper, we show that by means of multivariate nonlinear time series prediction techniques it is possible to increase the forecasting accuracy by considering movements of friends, people, or more in general entities, with correlated mobility patterns (i.e., characterised by high mutual information) as inputs. Finally, we evaluate the proposed techniques on the Nokia Mobile Data Challenge and Cabspotting datasets. {\textcopyright} 2013 Elsevier B.V. All rights reserved.},
 archiveprefix = {arXiv},
 arxivid = {1210.2376},
 author = {{De Domenico}, Manlio and Lima, Antonio and Musolesi, Mirco},
 doi = {10.1016/j.pmcj.2013.07.008},
 eprint = {1210.2376},
 file = {:Users/orsonxu/Documents/Mendeley Desktop/2013 - De Domenico, Lima, Musolesi - Interdependence and predictability of human mobility and social interactions.pdf:pdf},
 issn = {15741192},
 journal = {Pervasive and Mobile Computing},
 keywords = {Mobility prediction,Mutual information,Nonlinear time series analysis},
 mendeley-groups = {Ubicomp/Modeling Behavior - General/Mobility},
 month = {Dec},
 number = {6},
 pages = {798--807},
 publisher = {Elsevier B.V.},
 title = {{interdependence and predictability of human mobility and social interactions}},
 url = {http://dx.doi.org/10.1016/j.pmcj.2013.07.008 https://linkinghub.elsevier.com/retrieve/pii/S1574119213000904},
 volume = {9},
 year = {2013}
}

@article{demirci2015relationship,
 author = {Demirci, Kadir and Akg{\"o}n{\"u}l, Mehmet and Akpinar, Abdullah},
 journal = {Journal of Behavioral Addictions},
 number = {2},
 pages = {85--92},
 publisher = {Akad{\'e}miai Kiad{\'o}},
 title = {Relationship of smartphone use severity with sleep quality, depression, and anxiety in university students},
 volume = {4},
 year = {2015}
}

@misc{depressionNIMH,
 key = {NIMH Website},
 title = {Depression - national institute of mental health},
 url = {https://www.nimh.nih.gov/health/topics/depression/index.shtml},
 urldate = {2019-01-27},
 year = {2018}
}

@article{dey2001understanding,
 author = {Dey, Anind K.},
 journal = {Personal and Ubiquitous Computing},
 number = {1},
 pages = {4--7},
 publisher = {Springer-Verlag},
 title = {Understanding and using context},
 volume = {5},
 year = {2001}
}

@inproceedings{doryab2014detection,
 author = {Doryab, Afsaneh and Min, Jun-Ki and Wiese, Jason and Zimmerman, John and Hong, Jason I.},
 booktitle = {AAAI Workshop: Modern Artificial Intelligence for Health Analytics},
 title = {Detection of behavior change in people with depression},
 year = {2014}
}

@incollection{doryab2018identifying,
 author = {Doryab, Afsaneh},
 booktitle = {Technology and Adolescent Mental Health},
 pages = {135--153},
 publisher = {Springer},
 title = {Identifying symptoms using technology},
 year = {2018}
}

@article{dozois1998psychometric,
 author = {Dozois, David J. A. and Dobson, Keith S. and Ahnberg, Jamie L.},
 journal = {Psychological Assessment},
 number = {2},
 pages = {83},
 publisher = {American Psychological Association},
 title = {A psychometric evaluation of the beck depression inventory--ii.},
 volume = {10},
 year = {1998}
}

@inproceedings{dudek2010measures,
 author = {Dudek, Damian},
 booktitle = {International Conference on Artificial Intelligence and Soft Computing},
 organization = {Springer},
 pages = {315--322},
 title = {Measures for comparing association rule sets},
 year = {2010}
}

@article{eisenberg2007help,
 author = {Eisenberg, Daniel and Golberstein, Ezra and Gollust, Sarah E},
 journal = {Medical Care},
 pages = {594--601},
 publisher = {JSTOR},
 title = {Help-seeking and access to mental health care in a university student population},
 year = {2007}
}

@inproceedings{farhan2016behavior,
 author = {Farhan, Asma Ahmad and Yue, Chaoqun and Morillo, Reynaldo and Ware, Shweta and Lu, Jin and Bi, Jinbo and Kamath, Jayesh and Russell, Alexander and Bamis, Athanasios and Wang, Bing},
 booktitle = {Wireless Health},
 pages = {30--37},
 title = {Behavior vs. introspection: Refining prediction of clinical depression via smartphone sensing data},
 year = {2016}
}

@inproceedings{farrahi2012extracting,
 author = {Farrahi, Katayoun and Gatica-Perez, Daniel},
 booktitle = {Proceedings of the 16th International Symposium on Wearable Computers (ISWC)},
 organization = {IEEE},
 pages = {1--8},
 title = {Extracting mobile behavioral patterns with the distant n-gram topic model},
 year = {2012}
}

@article{ferreira2015aware,
 author = {Ferreira, Denzil and Kostakos, Vassilis and Dey, Anind K.},
 journal = {Frontiers in ICT},
 pages = {6},
 publisher = {Frontiers},
 title = {AWARE: Mobile context instrumentation framework},
 volume = {2},
 year = {2015}
}

@inproceedings{fournier2011rulegrowth,
 author = {Fournier-Viger, Philippe and Nkambou, Roger and Tseng, Vincent Shin-Mu},
 booktitle = {Proceedings of the 2011 ACM symposium on applied computing},
 organization = {ACM},
 pages = {956--961},
 title = {RuleGrowth: Mining sequential rules common to several sequences by pattern-growth},
 year = {2011}
}

@inproceedings{fournier2014erminer,
 author = {Fournier-Viger, Philippe and Gueniche, Ted and Zida, Souleymane and Tseng, Vincent S},
 booktitle = {International Symposium on Intelligent Data Analysis},
 organization = {Springer},
 pages = {108--119},
 title = {ERMiner: Sequential rule mining using equivalence classes},
 year = {2014}
}

@article{fournier2014spmf,
 author = {Fournier-Viger, Philippe and Gomariz, Antonio and Gueniche, Ted and Soltani, Azadeh and Wu, Cheng-Wei and Tseng, Vincent S.},
 journal = {The Journal of Machine Learning Research},
 number = {1},
 pages = {3389--3393},
 publisher = {JMLR. org},
 title = {SPMF: A java open-source pattern mining library},
 volume = {15},
 year = {2014}
}

@article{fournier2015mining,
 author = {Fournier-Viger, Philippe and Wu, Cheng-Wei and Tseng, Vincent S and Cao, Longbing and Nkambou, Roger},
 journal = {IEEE Transactions on Knowledge and Data Engineering},
 number = {8},
 pages = {2203--2216},
 publisher = {IEEE},
 title = {Mining partially-ordered sequential rules common to multiple sequences},
 volume = {27},
 year = {2015}
}

@article{freund1997decision,
 author = {Freund, Yoav and Schapire, Robert E.},
 journal = {Journal of Computer and System Sciences},
 number = {1},
 pages = {119--139},
 publisher = {Elsevier},
 title = {A decision-theoretic generalization of on-line learning and an application to boosting},
 volume = {55},
 year = {1997}
}

@inproceedings{frost2013supporting,
 author = {Frost, Mads and Doryab, Afsaneh and Faurholt-Jepsen, Maria and Kessing, Lars Vedel and Bardram, Jakob E.},
 booktitle = {Proceedings of the 2013 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
 organization = {ACM},
 pages = {133--142},
 title = {Supporting disease insight through data analysis: Refinements of the monarca self-assessment system},
 year = {2013}
}

@article{furukawa2010assessment,
 author = {Furukawa, Toshi A},
 journal = {Journal of Psychosomatic Research},
 number = {6},
 pages = {581--589},
 publisher = {Elsevier},
 title = {Assessment of mood: Guides for clinicians},
 volume = {68},
 year = {2010}
}

@article{Geng:2006:IMD:1132960.1132963,
 acmid = {1132963},
 address = {New York, NY, USA},
 articleno = {9},
 author = {Geng, Liqiang and Hamilton, Howard J.},
 doi = {10.1145/1132960.1132963},
 issn = {0360-0300},
 issue_date = {2006},
 journal = {ACM Computing Surveys},
 keywords = {Knowledge discovery, association rules, classification rules, interest measures, interestingness measures, summaries},
 month = {Sep},
 number = {3},
 publisher = {ACM},
 title = {Interestingness measures for data mining: A survey},
 url = {http://doi.acm.org/10.1145/1132960.1132963},
 volume = {38},
 year = {2006}
}

@article{goldberg1988detecting,
 author = {Goldberg, D. and Bridges, K. and Duncan-Jones, P. and Grayson, D.},
 journal = {British Medical Journal},
 number = {6653},
 pages = {897--899},
 publisher = {British Medical Journal Publishing Group},
 title = {Detecting anxiety and depression in general medical settings},
 volume = {297},
 year = {1988}
}

@article{gruttadaro2012college,
 author = {Gruttadaro, Darcy and Crudo, Dana},
 journal = {National Alliance on Mental Illness},
 title = {College students speak: A survey report on mental health},
 year = {2012}
}

@article{han2004mining,
 author = {Han, Jiawei and Pei, Jian and Yin, Yiwen and Mao, Runying},
 journal = {Data mining and knowledge discovery},
 number = {1},
 pages = {53--87},
 publisher = {Springer},
 title = {Mining frequent patterns without candidate generation: A frequent-pattern tree approach},
 volume = {8},
 year = {2004}
}

@article{harari2017smartphone,
 author = {Harari, Gabriella M and M{\"u}ller, Sandrine R and Aung, Min SH and Rentfrow, Peter J},
 journal = {Current Opinion in Behavioral Sciences},
 pages = {83--90},
 publisher = {Elsevier},
 title = {Smartphone sensing methods for studying behavior in everyday life},
 volume = {18},
 year = {2017}
}

@article{hochreiter1997long,
 author = {Hochreiter, Sepp and Schmidhuber, J{\"u}rgen},
 journal = {Neural Computation},
 number = {8},
 pages = {1735--1780},
 publisher = {MIT Press},
 title = {Long short-term memory},
 volume = {9},
 year = {1997}
}

@article{hofmann2012efficacy,
 author = {Hofmann, Stefan G and Asnaani, Anu and Vonk, Imke JJ and Sawyer, Alice T and Fang, Angela},
 journal = {Cognitive therapy and research},
 number = {5},
 pages = {427--440},
 publisher = {Springer},
 title = {The efficacy of cognitive behavioral therapy: A review of meta-analyses},
 volume = {36},
 year = {2012}
}

@article{hong2015toward,
 author = {Hong, Jin-Hyuk and Ramos, Julian and Dey, Anind K},
 journal = {IEEE Transactions on Human-Machine Systems},
 number = {1},
 pages = {101--112},
 publisher = {IEEE},
 title = {Toward personalized activity recognition systems with a semipopulation approach},
 volume = {46},
 year = {2015}
}

@article{hyndman1996sample,
 author = {Hyndman, Rob J and Fan, Yanan},
 journal = {The American Statistician},
 number = {4},
 pages = {361--365},
 publisher = {Taylor \& Francis},
 title = {Sample quantiles in statistical packages},
 volume = {50},
 year = {1996}
}

@article{hysenbegasi2005impact,
 author = {Hysenbegasi, Alketa and Hass, Steven L and Rowland, Clayton R},
 journal = {Journal of Mental Health Policy and Economics},
 number = {3},
 pages = {145},
 publisher = {WILEY},
 title = {The impact of depression on the academic productivity of university students},
 volume = {8},
 year = {2005}
}

@article{info:doi/10.2196/13209,
 author = {Doryab, Afsaneh
and Villalba, Daniella K
and Chikersal, Prerna
and Dutcher, Janine M
and Tumminia, Michael
and Liu, Xinwen
and Cohen, Sheldon
and Creswell, Kasey
and Mankoff, Jennifer
and Creswell, John D
and Dey, Anind K},
 day = {24},
 doi = {10.2196/13209},
 issn = {2291-5222},
 journal = {JMIR Mhealth Uhealth},
 month = {Jul},
 number = {7},
 pages = {e13209},
 title = {Identifying behavioral phenotypes of loneliness and social isolation with passive sensing: Statistical analysis, data mining and machine learning of smartphone and fitbit data},
 url = {https://doi.org/10.2196/13209},
 volume = {7},
 year = {2019}
}

@inproceedings{jain2014depression,
 author = {Jain, Varun and Crowley, James L and Dey, Anind K. and Lux, Augustin},
 booktitle = {Proceedings of the 4th International Workshop on Audio/Visual Emotion Challenge},
 organization = {ACM},
 pages = {87--91},
 title = {Depression estimation using audiovisual features and fisher vector encoding},
 year = {2014}
}

@inproceedings{janssoone2016using,
 author = {Janssoone, Thomas and Clavel, Chlo{\'e} and Bailly, K{\'e}vin and Richard, Ga{\"e}l},
 booktitle = {International Conference on Intelligent Virtual Agents},
 organization = {Springer},
 pages = {175--189},
 title = {Using temporal association rules for the synthesis of embodied conversational agents with a specific stance},
 year = {2016}
}

@inproceedings{jaroszewicz2001general,
 author = {Jaroszewicz, Szymon and Simovici, Dan A},
 booktitle = {European Conference on Principles of Data Mining and Knowledge Discovery},
 organization = {Springer},
 pages = {253--265},
 title = {A general measure of rule interestingness},
 year = {2001}
}

@inproceedings{jiang2018towards,
 author = {Jiang, Wenjun and Li, Qi and Su, Lu and Miao, Chenglin and Gu, Quanquan and Xu, Wenyao},
 booktitle = {2018 IEEE 38th International Conference on Distributed Computing Systems (ICDCS)},
 organization = {IEEE},
 pages = {321--333},
 title = {Towards personalized learning in mobile sensing systems},
 year = {2018}
}

@article{kadison2004college,
 author = {Kadison, Richard and DiGeronimo, Theresa Foy},
 journal = {San Francisco},
 title = {College of the overwhelmed: The campus mental health crisis and what to do about it},
 year = {2004}
}

@inproceedings{kamei2008hybrid,
 author = {Kamei, Yasutaka and Monden, Akito and Morisaki, Shuji and Matsumoto, Ken-ichi},
 booktitle = {Proceedings of the Second ACM-IEEE International Symposium on Empirical Software Engineering and Measurement},
 organization = {ACM},
 pages = {279--281},
 title = {A hybrid faulty module prediction using association rule mining and logistic regression analysis},
 year = {2008}
}

@article{karpathy2015visualizing,
 author = {Karpathy, Andrej and Johnson, Justin and Fei-Fei, Li},
 journal = {arXiv preprint arXiv:1506.02078},
 title = {Visualizing and understanding recurrent networks},
 year = {2015}
}

@article{katikalapudi2012associating,
 author = {Katikalapudi, Raghavendra and Chellappan, Sriram and Montgomery, Frances and Wunsch, Donald and Lutzen, Karl},
 journal = {IEEE Technology and Society Magazine},
 number = {4},
 pages = {73--80},
 publisher = {IEEE},
 title = {Associating internet usage with depressive behavior among college students},
 volume = {31},
 year = {2012}
}

@article{keller1985fuzzy,
 author = {Keller, James M and Gray, Michael R and Givens, James A},
 journal = {IEEE Transactions on Systems, Man, and Cybernetics},
 pages = {580--585},
 publisher = {IEEE},
 title = {A fuzzy k-nearest neighbor algorithm},
 year = {1985}
}

@article{kessler2013epidemiology,
 author = {Kessler, Ronald C. and Bromet, Evelyn J},
 journal = {Annual Review of Public Health},
 pages = {119--138},
 publisher = {Annual Reviews},
 title = {The epidemiology of depression across cultures},
 volume = {34},
 year = {2013}
}

@inproceedings{kianmehr2006effective,
 author = {Kianmehr, Keivan and Alhajj, Reda},
 booktitle = {International Conference on Intelligent Data Engineering and Automated Learning},
 organization = {Springer},
 pages = {920--927},
 title = {Effective classification by integrating support vector machine and association rule mining},
 year = {2006}
}

@article{kisch2005aspects,
 author = {Kisch, Jeremy and Leino, E Victor and Silverman, Morton M},
 journal = {Suicide and Life-Threatening Behavior},
 number = {1},
 pages = {3--13},
 publisher = {Guilford Press},
 title = {Aspects of suicidal behavior, depression, and treatment in college students: Results from the spring 2000 national college health assessment survey},
 volume = {35},
 year = {2005}
}

@article{kotsiantis2006association,
 author = {Kotsiantis, Sotiris and Kanellopoulos, Dimitris},
 journal = {GESTS International Transactions on Computer Science and Engineering},
 number = {1},
 pages = {71--82},
 title = {Association rules mining: A recent overview},
 volume = {32},
 year = {2006}
}

@article{kraskov2004estimating,
 author = {Kraskov, Alexander and St{\"o}gbauer, Harald and Grassberger, Peter},
 journal = {Physical Review E},
 number = {6},
 pages = {066138},
 publisher = {APS},
 title = {Estimating mutual information},
 volume = {69},
 year = {2004}
}

@article{kroenke2002phq,
 author = {Kroenke, Kurt and Spitzer, Robert L},
 journal = {Psychiatric annals},
 number = {9},
 pages = {509--515},
 publisher = {Slack Incorporated},
 title = {The phq-9: A new depression diagnostic and severity measure},
 volume = {32},
 year = {2002}
}

@article{kroenke2009ultra,
 author = {Kroenke, Kurt and Spitzer, Robert L and Williams, Janet BW and L{\"o}we, Bernd},
 journal = {Psychosomatics},
 number = {6},
 pages = {613--621},
 publisher = {Elsevier},
 title = {An ultra-brief screening scale for anxiety and depression: The phq--4},
 volume = {50},
 year = {2009}
}

@article{kung2013comparing,
 author = {Kung, Simon and Alarcon, Renato D and Williams, Mark D and Poppe, Kathleen A and Moore, Mary Jo and Frye, Mark A},
 journal = {Journal of Affective Disorders},
 number = {3},
 pages = {341--343},
 publisher = {Elsevier},
 title = {Comparing the beck depression inventory-ii (bdi-ii) and patient health questionnaire (phq-9) depression measures in an integrated mood disorders practice},
 volume = {145},
 year = {2013}
}

@article{lane2010survey,
 author = {Lane, Nicholas D. and Miluzzo, Emiliano and Lu, Hong and Peebles, Daniel and Choudhury, Tanzeem and Campbell, Andrew T.},
 journal = {IEEE Communications Magazine},
 number = {9},
 publisher = {IEEE},
 title = {A survey of mobile phone sensing},
 volume = {48},
 year = {2010}
}

@inproceedings{lane2011csn_10.1145/2030112.2030160,
 address = {New York, NY, USA},
 author = {Lane, Nicholas D. and Xu, Ye and Lu, Hong and Hu, Shaohan and Choudhury, Tanzeem and Campbell, Andrew T. and Zhao, Feng},
 booktitle = {Proceedings of the 13th International Conference on Ubiquitous Computing},
 doi = {10.1145/2030112.2030160},
 isbn = {9781450306300},
 keywords = {mobile phone sensing, activity recognition, community learning},
 location = {Beijing, China},
 numpages = {10},
 pages = {355–364},
 publisher = {Association for Computing Machinery},
 series = {UbiComp ’11},
 title = {Enabling large-scale human activity inference on smartphones using community similarity networks (csn)},
 url = {https://doi.org/10.1145/2030112.2030160},
 year = {2011}
}

@inproceedings{lengerich2019learning,
 author = {Lengerich, Ben and Aragam, Bryon and Xing, Eric P},
 booktitle = {Advances in Neural Information Processing Systems},
 pages = {3570--3580},
 title = {Learning sample-specific models with low-rank personalized regression},
 year = {2019}
}

@InProceedings{li2001cmar,
  author    = {{Wenmin Li} and {Jiawei Han} and {Jian Pei}},
  booktitle = {Proceedings 2001 IEEE International Conference on Data Mining},
  title     = {CMAR: Accurate and efficient classification based on multiple class-association rules},
  year      = {2001},
  month     = {Nov},
  pages     = {369-376},
  doi       = {10.1109/ICDM.2001.989541},
}

@article{liu2014flexible,
 author = {Liu, Guimei and Zhang, Haojun and Wong, Limsoon},
 journal = {IEEE Transactions on Knowledge and Data Engineering},
 number = {7},
 pages = {1562--1574},
 publisher = {IEEE},
 title = {A flexible approach to finding representative pattern sets},
 volume = {26},
 year = {2014}
}

@article{lopez2017physiological,
 author = {Lopez-Martinez, Daniel and Rudovic, Ognjen and Picard, Rosalind},
 journal = {Neural Information Processing Systems Workshop on Machine Learning for Health},
 title = {Physiological and behavioral profiling for nociceptive pain estimation using personalized multitask learning},
 year = {2017}
}

@inproceedings{ma1998integrating,
 author = {Liu, Bing and Hsu, Wynne and Ma, Yiming},
 booktitle = {Proceedings of the 4th International Conference on Knowledge Discovery and Data Mining},
 title = {Integrating classification and association rule mining},
 year = {1998}
}

@article{magnusson2000discovering,
 author = {Magnusson, Magnus S.},
 journal = {Behavior Research Methods, Instruments, \& Computers},
 number = {1},
 pages = {93--110},
 publisher = {Springer},
 title = {Discovering hidden time patterns in behavior: T-patterns and their detection},
 volume = {32},
 year = {2000}
}

@article{maxhuni2016classification,
 author = {Maxhuni, Alban and Mu{\~n}oz-Mel{\'e}ndez, Ang{\'e}lica and Osmani, Venet and Perez, Humberto and Mayora, Oscar and Morales, Eduardo F},
 journal = {Pervasive and Mobile Computing},
 pages = {50--66},
 publisher = {Elsevier},
 title = {Classification of bipolar disorder episodes based on analysis of voice and motor activity of patients},
 volume = {31},
 year = {2016}
}

@article{mcnicholas2008standardising,
 author = {McNicholas, Paul David and Murphy, Thomas Brendan and O'Regan, M.},
 journal = {Computational Statistics \& Data Analysis},
 number = {10},
 pages = {4712--4721},
 publisher = {Elsevier},
 title = {Standardising the lift of an association rule},
 volume = {52},
 year = {2008}
}

@misc{MDDreport2018,
 howpublished = {\url{https://www.samhsa.gov/data/sites/default/files/cbhsq-reports/NSDUHNationalFindingsReport2018/NSDUHNationalFindingsReport2018.pdf}},
 key = {{NSDUH}},
 title = {{the national survey on drug use and health - survey report in 2018}},
 year = {2018}
}

@inproceedings{mehrotra2016towards,
 author = {Mehrotra, Abhinav and Hendley, Robert and Musolesi, Mirco},
 booktitle = {Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing: Adjunct},
 organization = {ACM},
 pages = {1132--1138},
 title = {Towards multi-modal anticipatory monitoring of depressive states through the analysis of human-smartphone interaction},
 year = {2016}
}

@inproceedings{min2014_10.1145/2556288.2557220,
 address = {New York, NY, USA},
 author = {Min, Jun-Ki and Doryab, Afsaneh and Wiese, Jason and Amini, Shahriyar and Zimmerman, John and Hong, Jason I.},
 booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
 doi = {10.1145/2556288.2557220},
 isbn = {9781450324731},
 keywords = {sensors, sleep, smartphone, machine learning},
 location = {Toronto, Ontario, Canada},
 numpages = {10},
 pages = {477–486},
 publisher = {Association for Computing Machinery},
 series = {CHI ’14},
 title = {Toss “n” turn: Smartphone as sleep and sleep quality detector},
 url = {https://doi.org/10.1145/2556288.2557220},
 year = {2014}
}

@article{moorman1995individualism,
 author = {Moorman, Robert H and Blakely, Gerald L},
 journal = {Journal of organizational behavior},
 number = {2},
 pages = {127--142},
 publisher = {Wiley Online Library},
 title = {Individualism-collectivism as an individual difference predictor of organizational citizenship behavior},
 volume = {16},
 year = {1995}
}

@inproceedings{namaki2017discovering,
 author = {Namaki, Mohammad Hossein and Wu, Yinghui and Song, Qi and Lin, Peng and Ge, Tingjian},
 booktitle = {Proceedings of the 2017 ACM on Conference on Information and Knowledge Management},
 organization = {ACM},
 pages = {1697--1706},
 title = {Discovering graph temporal association rules},
 year = {2017}
}

@inproceedings{nath2012ace,
 author = {Nath, Suman},
 booktitle = {Proceedings of the 10th International Conference on Mobile Systems, Applications, and Services},
 organization = {ACM},
 pages = {29--42},
 title = {ACE: Exploiting correlation for energy-efficient and continuous context sensing},
 year = {2012}
}

@article{naughton2016context,
 author = {Naughton, Felix and Hopewell, Sarah and Lathia, Neal and Schalbroeck, Rik and Brown, Chlo{\"e} and Mascolo, Cecilia and McEwen, Andy and Sutton, Stephen},
 journal = {JMIR mHealth and uHealth},
 number = {3},
 pages = {e106},
 publisher = {JMIR Publications Inc., Toronto, Canada},
 title = {A context-sensing mobile phone app (q sense) for smoking cessation: A mixed-methods study},
 volume = {4},
 year = {2016}
}

@inproceedings{nawaz2014mining,
 author = {Nawaz, Sarfraz and Mascolo, Cecilia},
 booktitle = {Proceedings of the 12th ACM Conference on Embedded Network Sensor Systems},
 organization = {ACM},
 pages = {236--250},
 title = {Mining users' significant driving routes with low-power sensors},
 year = {2014}
}

@article{ng2016annual,
 author = {Ng, Mei Yi and Weisz, John R},
 journal = {Journal of Child Psychology and Psychiatry},
 number = {3},
 pages = {216--236},
 publisher = {Wiley Online Library},
 title = {Annual research review: Building a science of personalized intervention for youth mental health},
 volume = {57},
 year = {2016}
}

@article{nock2006prevalence,
 author = {Nock, Matthew K. and Kessler, Ronald C.},
 journal = {Journal of Abnormal Psychology},
 number = {3},
 pages = {616},
 publisher = {American Psychological Association},
 title = {Prevalence of and risk factors for suicide attempts versus suicide gestures: Analysis of the national comorbidity survey},
 volume = {115},
 year = {2006}
}

@inproceedings{osmani2013monitoring,
 author = {Osmani, Venet and Maxhuni, Alban and Gr{\"u}nerbl, Agnes and Lukowicz, Paul and Haring, Christian and Mayora, Oscar},
 booktitle = {Proceedings of International Conference on Advances in Mobile Computing \& Multimedia},
 organization = {ACM},
 pages = {85},
 title = {Monitoring activity of patients with bipolar disorder using smart phones},
 year = {2013}
}

@article{ovadia2014automate,
 author = {Ovadia, Steven},
 journal = {Behavioral \& social sciences librarian},
 number = {4},
 pages = {208--211},
 publisher = {Taylor \& Francis},
 title = {Automate the internet with "if this then that"(ifttt)},
 volume = {33},
 year = {2014}
}

@article{park1997using,
 author = {Park, Jong Soo and Chen, Ming-Syan and Yu, Philip S.},
 journal = {IEEE Transactions on Knowledge and Data Engineering},
 number = {5},
 pages = {813--825},
 publisher = {IEEE},
 title = {Using a hash-based method with transaction trimming for mining association rules},
 volume = {9},
 year = {1997}
}

@article{pedregosa2011scikit,
 author = {Pedregosa, Fabian and Varoquaux, Ga{\"e}l and Gramfort, Alexandre and Michel, Vincent and Thirion, Bertrand and Grisel, Olivier and Blondel, Mathieu and Prettenhofer, Peter and Weiss, Ron and Dubourg, Vincent and others},
 journal = {Journal of machine learning research},
 number = {Oct},
 pages = {2825--2830},
 title = {Scikit-learn: Machine learning in python},
 volume = {12},
 year = {2011}
}

@inproceedings{pierson2018modeling,
 author = {Pierson, Emma and Althoff, Tim and Leskovec, Jure},
 booktitle = {Proceedings of the 2018 World Wide Web Conference on World Wide Web},
 organization = {International World Wide Web Conferences Steering Committee},
 pages = {107--116},
 title = {Modeling individual cyclic variation in human behavior},
 year = {2018}
}

@article{quinlan1986induction,
 author = {Quinlan, J. Ross},
 journal = {Machine Learning},
 number = {1},
 pages = {81--106},
 publisher = {Springer},
 title = {Induction of decision trees},
 volume = {1},
 year = {1986}
}

@article{rajendran2010hybrid,
 author = {Rajendran, Periyasamy and Madheswaran, Muthusamy},
 journal = {arXiv preprint arXiv:1001.3503},
 title = {Hybrid medical image classification using association rule mining with decision tree algorithm},
 year = {2010}
}

@article{rudovic2018personalized,
 author = {Rudovic, Ognjen and Lee, Jaeryoung and Dai, Miles and Schuller, Bj{\"o}rn and Picard, Rosalind W},
 journal = {Science Robotics},
 number = {19},
 pages = {eaao6760},
 publisher = {Science Robotics},
 title = {Personalized machine learning for robot perception of affect and engagement in autism therapy},
 volume = {3},
 year = {2018}
}

@article{russell1996ucla,
 author = {Russell, Daniel W},
 journal = {Journal of personality assessment},
 number = {1},
 pages = {20--40},
 publisher = {Taylor \& Francis},
 title = {Ucla loneliness scale (version 3): Reliability, validity, and factor structure},
 volume = {66},
 year = {1996}
}

@article{saeb2016relationship,
 author = {Saeb, Sohrab and Lattie, Emily G. and Schueller, Stephen M. and Kording, Konrad P. and Mohr, David C.},
 journal = {PeerJ},
 pages = {e2537},
 publisher = {PeerJ Inc.},
 title = {The relationship between mobile phone location sensor data and depressive symptom severity},
 volume = {4},
 year = {2016}
}

@inproceedings{sainath2015convolutional,
 author = {Sainath, Tara N and Vinyals, Oriol and Senior, Andrew and Sak, Ha{\c{s}}im},
 booktitle = {2015 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
 organization = {IEEE},
 pages = {4580--4584},
 title = {Convolutional, long short-term memory, fully connected deep neural networks},
 year = {2015}
}

@article{saini2015human,
 author = {Saini, Camille and Brown, Steven A and Dibner, Charna},
 journal = {Frontiers in neurology},
 pages = {95},
 publisher = {Frontiers},
 title = {Human peripheral clocks: Applications for studying circadian phenotypes in physiology and pathophysiology},
 volume = {6},
 year = {2015}
}

@inproceedings{sarker2018mining,
 author = {Sarker, Iqbal H. and Salim, Flora D.},
 booktitle = {Pacific-Asia Conference on Knowledge Discovery and Data Mining},
 organization = {Springer},
 pages = {450--461},
 title = {Mining user behavioral rules from smartphone data through association analysis},
 year = {2018}
}

@article{schelde1998major,
 author = {Schelde, Jens Tyge M{\O}rk},
 journal = {The Journal of nervous and mental disease},
 number = {3},
 pages = {141--149},
 publisher = {LWW},
 title = {Major depression: Behavioral parameters of depression and recovery},
 volume = {186},
 year = {1998}
}

@inproceedings{scherer2013automatic,
 author = {Scherer, Stefan and Stratou, Giota and Mahmoud, Marwa and Boberg, Jill and Gratch, Jonathan and Rizzo, Albert and Morency, Louis-Philippe},
 booktitle = {Automatic Face and Gesture Recognition (FG), 2013 10th IEEE International Conference and Workshops on},
 organization = {IEEE},
 pages = {1--8},
 title = {Automatic behavior descriptors for psychological disorder analysis},
 year = {2013}
}

@inproceedings{schulam2015framework,
 author = {Schulam, Peter and Saria, Suchi},
 booktitle = {Advances in Neural Information Processing Systems},
 pages = {748--756},
 title = {A framework for individualizing predictions of disease trajectories by exploiting multi-resolution structure},
 year = {2015}
}

@article{smith2008brief,
 author = {Smith, Bruce W and Dalen, Jeanne and Wiggins, Kathryn and Tooley, Erin and Christopher, Paulette and Bernard, Jennifer},
 journal = {International journal of behavioral medicine},
 number = {3},
 pages = {194--200},
 publisher = {Springer},
 title = {The brief resilience scale: Assessing the ability to bounce back},
 volume = {15},
 year = {2008}
}

@inproceedings{srinivasan2014mobileminer,
 author = {Srinivasan, Vijay and Moghaddam, Saeed and Mukherji, Abhishek and Rachuri, Kiran K and Xu, Chenren and Tapia, Emmanuel Munguia},
 booktitle = {Proceedings of the 2014 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
 organization = {ACM},
 pages = {389--400},
 title = {Mobileminer: Mining your frequent patterns on your phone},
 year = {2014}
}

@article{srinivasan2018ruleselector,
 author = {Srinivasan, Vijay and Koehler, Christian and Jin, Hongxia},
 journal = {Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies},
 number = {1},
 pages = {35},
 publisher = {ACM},
 title = {RuleSelector: Selecting conditional action rules from user behavior patterns},
 volume = {2},
 year = {2018}
}

@article{steer2001mean,
 author = {Steer, Robert A. and Brown, Gregory. K and Beck, Aaron T. and Sanderson, William C.},
 journal = {Psychological Reports},
 number = {3\_suppl},
 pages = {1075--1076},
 publisher = {SAGE Publications Sage CA: Los Angeles, CA},
 title = {Mean beck depression inventory-ii scores by severity of major depressive episode},
 volume = {88},
 year = {2001}
}

@article{storch2004factor,
 author = {Storch, Eric A. and Roberti, Jonathan W. and Roth, Deborah A.},
 journal = {Depression and Anxiety},
 number = {3},
 pages = {187--189},
 publisher = {Wiley Online Library},
 title = {Factor structure, concurrent validity, and internal consistency of the beck depression inventory-second edition in a sample of college students},
 volume = {19},
 year = {2004}
}

@article{strohle2009physical,
 author = {Str{\"o}hle, Andreas},
 journal = {Journal of neural transmission},
 number = {6},
 pages = {777},
 publisher = {Springer},
 title = {Physical activity, exercise, depression and anxiety disorders},
 volume = {116},
 year = {2009}
}

@inproceedings{suhara2017deepmood,
 author = {Suhara, Yoshihiko and Xu, Yinzhan and Pentland, Alex `Sandy'},
 booktitle = {Proceedings of the 26th International Conference on World Wide Web},
 organization = {International World Wide Web Conferences Steering Committee},
 pages = {715--724},
 title = {Deepmood: Forecasting depressed mood based on self-reported histories via recurrent neural networks},
 year = {2017}
}

@article{sun2012large,
 author = {Sun, Xu and Kashima, Hisashi and Ueda, Naonori},
 journal = {IEEE Transactions on Knowledge and Data Engineering},
 number = {11},
 pages = {2551--2563},
 publisher = {IEEE},
 title = {Large-scale personalized human activity recognition using online multitask learning},
 volume = {25},
 year = {2012}
}

@phdthesis{szathmary2006symbolic,
 author = {Szathmary, Laszlo},
 school = {Universit{\'e} Henri Poincar{\'e}-Nancy I},
 title = {Symbolic data mining methods with the coron platform},
 year = {2006}
}

@article{thase1998depression,
 author = {Thase, Michael E.},
 journal = {The Journal of Clinical Psychiatry},
 publisher = {Physicians Postgraduate Press},
 title = {Depression, sleep, and antidepressants.},
 year = {1998}
}

@article{tian2007model,
 author = {Tian, Lu and Cai, Tianxi and Goetghebeur, Els and Wei, LJ},
 journal = {Biometrika},
 number = {2},
 pages = {297--311},
 publisher = {Oxford University Press},
 title = {Model evaluation based on the sampling distribution of estimated absolute prediction error},
 volume = {94},
 year = {2007}
}

@article{titov2011psychometric,
 author = {Titov, Nickolai and Dear, Blake F and McMillan, Dean and Anderson, Tracy and Zou, Judy and Sunderland, Matthew},
 journal = {Cognitive Behaviour Therapy},
 number = {2},
 pages = {126--136},
 publisher = {Taylor \& Francis},
 title = {Psychometric comparison of the phq-9 and bdi-ii for measuring response during treatment of depression},
 volume = {40},
 year = {2011}
}

@article{tsuno2005sleep,
 author = {Tsuno, Norifumi and Besset, Alain and Ritchie, Karen},
 journal = {The Journal of Clinical Psychiatry},
 publisher = {Physicians Postgraduate Press},
 title = {Sleep and depression.},
 year = {2005}
}

@article{visweswaran2010learning,
 author = {Visweswaran, Shyam and Cooper, Gregory F},
 journal = {Journal of Machine Learning Research},
 number = {Dec},
 pages = {3333--3369},
 title = {Learning instance-specific predictive models},
 volume = {11},
 year = {2010}
}

@article{von1996relationship,
 author = {Von Korff, Michael and Simon, Gregory},
 journal = {The British Journal of Psychiatry},
 number = {S30},
 pages = {101--108},
 publisher = {Cambridge University Press},
 title = {The relationship between pain and depression},
 volume = {168},
 year = {1996}
}

@article{vos2016global,
 author = {Theo Vos and {the GBD 2015 Disease and Injury Incidence and Prevalence Collaborators}},
 journal = {The Lancet},
 number = {10053},
 pages = {1545--1602},
 publisher = {Elsevier},
 title = {Global, regional, and national incidence, prevalence, and years lived with disability for 310 diseases and injuries, 1990--2015: A systematic analysis for the global burden of disease study 2015},
 volume = {388},
 year = {2016}
}

@article{Wahle2017,
 author = {Wahle, Fabian and Bollhalder, Lea and Kowatsch, Tobias and Fleisch, Elgar},
 doi = {10.2196/jmir.7381},
 isbn = {1438-8871},
 issn = {14388871},
 journal = {Journal of Medical Internet Research},
 keywords = {depression,design feature,information systems,literature review,mental health},
 mendeley-groups = {Ubicomp/Modeling Behavior - General/Health,Ubicomp/Modeling Behavior - Core/Behavior Marker/Depression,Ubicomp/Behavior Intervention},
 number = {5},
 pages = {e191},
 pmid = {28566267},
 title = {Toward the design of evidence-based mental health information systems for people with depression: A systematic literature review and meta-analysis},
 volume = {19},
 year = {2017}
}

@inproceedings{wang2007topical,
 author = {X. {Wang} and A. {McCallum} and X. {Wei}},
 booktitle = {Seventh IEEE International Conference on Data Mining (ICDM 2007)},
 doi = {10.1109/ICDM.2007.86},
 issn = {1550-4786},
 month = {Oct},
 number = {},
 pages = {697-702},
 title = {Topical n-grams: Phrase and topic discovery, with an application to information retrieval},
 volume = {},
 year = {2007}
}

@inproceedings{wang2014studentlife,
 author = {Wang, Rui and Chen, Fanglin and Chen, Zhenyu and Li, Tianxing and Harari, Gabriella and Tignor, Stefanie and Zhou, Xia and Ben-Zeev, Dror and Campbell, Andrew T.},
 booktitle = {Proceedings of the 2014 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
 organization = {ACM},
 pages = {3--14},
 title = {StudentLife: Assessing mental health, academic performance and behavioral trends of college students using smartphones},
 year = {2014}
}

@article{wang2018mining,
 author = {Wang, Ling and Meng, Jianyao and Xu, Peipei and Peng, Kaixiang},
 journal = {Applied Soft Computing},
 pages = {817--829},
 publisher = {Elsevier},
 title = {Mining temporal association rules with frequent itemsets tree},
 volume = {62},
 year = {2018}
}

@inproceedings{wei2005novel,
 author = {Wei, Jin-Mao and Yi, Wei-Guo and Wang, Ming-Yang},
 booktitle = {2005 International Conference on Machine Learning and Cybernetics},
 organization = {IEEE},
 pages = {1660--1664},
 title = {Novel measurement for mining effective association rules},
 volume = {3},
 year = {2005}
}

@article{whisman2013measurement,
 author = {Whisman, Mark A and Judd, Charles M and Whiteford, Natalie T and Gelhorn, Heather L},
 journal = {Assessment},
 number = {4},
 pages = {419--428},
 publisher = {Sage Publications Sage CA: Los Angeles, CA},
 title = {Measurement invariance of the beck depression inventory--second edition (bdi-ii) across gender, race, and ethnicity in college students},
 volume = {20},
 year = {2013}
}

@article{whisman2015normative,
 author = {Whisman, Mark A and Richardson, Emily D},
 journal = {Journal of Clinical Psychology},
 number = {9},
 pages = {898--907},
 publisher = {Wiley Online Library},
 title = {Normative data on the beck depression inventory--second edition (bdi-ii) in college students},
 volume = {71},
 year = {2015}
}

@inproceedings{xin2006extracting,
 author = {Xin, Dong and Cheng, Hong and Yan, Xifeng and Han, Jiawei},
 booktitle = {Proceedings of the 12th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
 organization = {ACM},
 pages = {444--453},
 title = {Extracting redundancy-aware top-k patterns},
 year = {2006}
}

@inproceedings{yamada17LLHDR,
 address = {Fort Lauderdale, FL, USA},
 author = {Makoto Yamada and Takeuchi Koh and Tomoharu Iwata and John Shawe-Taylor and Samuel Kaski},
 booktitle = {Proceedings of the 20th International Conference on Artificial Intelligence and Statistics},
 editor = {Aarti Singh and Jerry Zhu},
 month = {20--22 Apr},
 pages = {325--333},
 publisher = {PMLR},
 series = {Proceedings of Machine Learning Research},
 title = {{localized lasso for high-dimensional regression}},
 url = {http://proceedings.mlr.press/v54/yamada17a.html},
 volume = {54},
 year = {2017}
}

@inproceedings{yan2005summarizing,
 author = {Yan, Xifeng and Cheng, Hong and Han, Jiawei and Xin, Dong},
 booktitle = {Proceedings of the 11th ACM SIGKDD International Conference on Knowledge Discovery in Data Mining},
 organization = {ACM},
 pages = {314--323},
 title = {Summarizing itemset patterns: A profile-based approach},
 year = {2005}
}

@article{yasaman_2019_10.1145/3359216,
 address = {New York, NY, USA},
 articleno = {Article 114},
 author = {Sefidgar, Yasaman S. and Seo, Woosuk and Kuehn, Kevin S. and Althoff, Tim and Browning, Anne and Riskin, Eve and Nurius, Paula S. and Dey, Anind K. and Mankoff, Jennifer},
 doi = {10.1145/3359216},
 issue_date = {November 2019},
 journal = {Proc. ACM Hum.-Comput. Interact.},
 keywords = {mobile sensing, microaggression, mobile health, discrimination},
 month = {Nov},
 number = {CSCW},
 numpages = {29},
 publisher = {Association for Computing Machinery},
 title = {Passively-sensed behavioral correlates of discrimination events in college students},
 url = {https://doi.org/10.1145/3359216},
 volume = {3},
 year = {2019}
}

@article{yehuda2002post,
 author = {Yehuda, Rachel},
 journal = {New England journal of medicine},
 number = {2},
 pages = {108--114},
 publisher = {Mass Medical Soc},
 title = {Post-traumatic stress disorder},
 volume = {346},
 year = {2002}
}

@inproceedings{yin2003cpar,
 author = {Yin, Xiaoxin and Han, Jiawei},
 booktitle = {Proceedings of the 2003 SIAM International Conference on Data Mining},
 organization = {SIAM},
 pages = {331--335},
 title = {CPAR: Classification based on predictive association rules},
 year = {2003}
}

@article{yu2004probabilistic,
 author = {Yu, Kai and Schwaighofer, Anton and Tresp, Volker and Xu, Xiaowei and Kriegel, H-P},
 journal = {IEEE Transactions on Knowledge and Data Engineering},
 number = {1},
 pages = {56--69},
 publisher = {IEEE},
 title = {Probabilistic memory-based collaborative filtering},
 volume = {16},
 year = {2004}
}

@article{zhang2015cross,
 author = {Zhang, Yongli and Yang, Yuhong},
 journal = {Journal of Econometrics},
 number = {1},
 pages = {95--112},
 publisher = {Elsevier},
 title = {Cross-validation for selecting a model selection procedure},
 volume = {187},
 year = {2015}
}

@inproceedings{zhao2011cross,
 author = {Zhao, Zhongtang and Chen, Yiqiang and Liu, Junfa and Shen, Zhiqi and Liu, Mingjie},
 booktitle = {Twenty-second International Joint Conference on Artificial Intelligence},
 title = {Cross-people mobile-phone based activity recognition},
 year = {2011}
}

@article{zheng2000lazy,
 author = {Zheng, Zijian and Webb, Geoffrey I},
 journal = {Machine Learning},
 number = {1},
 pages = {53--84},
 publisher = {Springer},
 title = {Lazy learning of bayesian rules},
 volume = {41},
 year = {2000}
}

@phdthesis{ziebart2010modeling,
 author = {Ziebart, Brian D},
 school = {Carnegie Mellon University},
 title = {Modeling purposeful adaptive behavior with the principle of maximum causal entropy},
 year = {2010}
}


@inproceedings{inoue2018cross,
  title={Cross-domain weakly-supervised object detection through progressive domain adaptation},
  author={Inoue, Naoto and Furuta, Ryosuke and Yamasaki, Toshihiko and Aizawa, Kiyoharu},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={5001--5009},
  year={2018}
}

@inproceedings{baltruvsaitis2015cross,
  title={Cross-dataset learning and person-specific normalisation for automatic action unit detection},
  author={Baltru{\v{s}}aitis, Tadas and Mahmoud, Marwa and Robinson, Peter},
  booktitle={2015 11th IEEE International Conference and Workshops on Automatic Face and Gesture Recognition (FG)},
  volume={6},
  pages={1--6},
  year={2015},
  organization={IEEE}
}

@inproceedings{cao2010cross,
  title={Cross-dataset action detection},
  author={Cao, Liangliang and Liu, Zicheng and Huang, Thomas S},
  booktitle={2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
  pages={1998--2005},
  year={2010},
  organization={IEEE}
}


@article{hansen2011enhancing,
  title={Enhancing miRNA annotation confidence in miRBase by continuous cross dataset analysis},
  author={Hansen, Thomas B and Kjems, J{\o}rgen and Bramsen, Jesper B},
  journal={RNA biology},
  volume={8},
  number={3},
  pages={378--383},
  year={2011},
  publisher={Taylor \& Francis}
}

@article{cimtay2020investigating,
  title={Investigating the use of pretrained convolutional neural network on cross-subject and cross-dataset EEG emotion recognition},
  author={Cimtay, Yucel and Ekmekcioglu, Erhan},
  journal={Sensors},
  volume={20},
  number={7},
  pages={2034},
  year={2020},
  publisher={Multidisciplinary Digital Publishing Institute}
}

@article{hu2017cross,
  title={Cross-dataset and cross-cultural music mood prediction: A case on western and chinese pop songs},
  author={Hu, Xiao and Yang, Yi-Hsuan},
  journal={IEEE Transactions on Affective Computing},
  volume={8},
  number={2},
  pages={228--240},
  year={2017},
  publisher={IEEE}
}

@inproceedings{zhang2019cross,
  title={Cross-dataset time series anomaly detection for cloud systems},
  author={Zhang, Xu and Kim, Junghyun and Lin, Qingwei and Lim, Keunhak and Kanaujia, Shobhit O and Xu, Yong and Jamieson, Kyle and Albarghouthi, Aws and Qin, Si and Freedman, Michael J and others},
  booktitle={2019 USENIX Annual Technical Conference (USENIX ATC 19)},
  pages={1063--1076},
  year={2019}
}

@inproceedings{hoffman2018convolutional,
  title={Convolutional neural networks for iris presentation attack detection: Toward cross-dataset and cross-sensor generalization},
  author={Hoffman, Steven and Sharma, Renu and Ross, Arun},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops},
  pages={1620--1628},
  year={2018}
}

@inproceedings{zhang2009cross,
  title={Cross-domain dependency parsing using a deep linguistic grammar},
  author={Zhang, Yi and Wang, Rui},
  booktitle={Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP},
  pages={378--386},
  year={2009}
}

@inproceedings{yao2010boosting,
  title={Boosting for transfer learning with multiple sources},
  author={Yao, Yi and Doretto, Gianfranco},
  booktitle={2010 IEEE computer society conference on computer vision and pattern recognition},
  pages={1855--1862},
  year={2010},
  organization={IEEE}
}

@inproceedings{daume-iii-2007-frustratingly,
    title = "Frustratingly Easy Domain Adaptation",
    author = "Daum{\'e} III, Hal",
    booktitle = "Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics",
    month = jun,
    year = "2007",
    address = "Prague, Czech Republic",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/P07-1033",
    pages = "256--263",
}

@inproceedings{zhang2010transfer,
  title={Transfer metric learning by learning task relationships},
  author={Zhang, Yu and Yeung, Dit-Yan},
  booktitle={Proceedings of the 16th ACM SIGKDD international conference on Knowledge discovery and data mining},
  pages={1199--1208},
  year={2010}
}

@article{fei2006one,
  title={One-shot learning of object categories},
  author={Fei-Fei, Li and Fergus, Rob and Perona, Pietro},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={28},
  number={4},
  pages={594--611},
  year={2006},
  publisher={IEEE}
}

@inproceedings{tzeng2015simultaneous,
  title={Simultaneous deep transfer across domains and tasks},
  author={Tzeng, Eric and Hoffman, Judy and Darrell, Trevor and Saenko, Kate},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={4068--4076},
  year={2015}
}

@inproceedings{tommasi2014testbed,
  title={A testbed for cross-dataset analysis},
  author={Tommasi, Tatiana and Tuytelaars, Tinne},
  booktitle={European Conference on Computer Vision},
  pages={18--31},
  year={2014},
  organization={Springer}
}

@Article{volpi_generalizing_2018,
  author        = {Volpi, Riccardo and Namkoong, Hongseok and Sener, Ozan and Duchi, John and Murino, Vittorio and Savarese, Silvio},
  journal       = {{arXiv}:1805.12018 [cs]},
  title         = {Generalizing to Unseen Domains via Adversarial Data Augmentation},
  year          = {2018},
  month         = nov,
  abstract      = {We are concerned with learning models that generalize well to different {\textbackslash}emph\{unseen\} domains. We consider a worst-case formulation over data distributions that are near the source domain in the feature space. Only using training data from a single source distribution, we propose an iterative procedure that augments the dataset with examples from a fictitious target domain that is "hard" under the current model. We show that our iterative scheme is an adaptive data augmentation method where we append adversarial examples at each iteration. For softmax losses, we show that our method is a data-dependent regularization scheme that behaves differently from classical regularizers that regularize towards zero (e.g., ridge or lasso). On digit recognition and semantic segmentation tasks, our method learns models improve performance across a range of a priori unknown target domains.},
  archiveprefix = {arxiv},
  eprint        = {1805.12018},
  file          = {Volpi et al_2018_Generalizing to Unseen Domains via Adversarial Data Augmentation.pdf:/Users/orsonxu/Desktop/HCI/Literature Management/Zotero/Volpi et al_2018_Generalizing to Unseen Domains via Adversarial Data Augmentation.pdf:application/pdf},
  url           = {http://arxiv.org/abs/1805.12018},
  urldate       = {2022-01-07},
}

@Article{shankar_generalizing_2018,
  author        = {Shankar, Shiv and Piratla, Vihari and Chakrabarti, Soumen and Chaudhuri, Siddhartha and Jyothi, Preethi and Sarawagi, Sunita},
  journal       = {{arXiv}:1804.10745 [cs, stat]},
  title         = {Generalizing Across Domains via Cross-Gradient Training},
  year          = {2018},
  month         = may,
  abstract      = {We present {CROSSGRAD}, a method to use multi-domain training data to learn a classifier that generalizes to new domains. {CROSSGRAD} does not need an adaptation phase via labeled or unlabeled data, or domain features in the new domain. Most existing domain adaptation methods attempt to erase domain signals using techniques like domain adversarial training. In contrast, {CROSSGRAD} is free to use domain signals for predicting labels, if it can prevent overfitting on training domains. We conceptualize the task in a Bayesian setting, in which a sampling step is implemented as data augmentation, based on domain-guided perturbations of input instances. {CROSSGRAD} parallelly trains a label and a domain classifier on examples perturbed by loss gradients of each other's objectives. This enables us to directly perturb inputs, without separating and re-mixing domain signals while making various distributional assumptions. Empirical evaluation on three different applications where this setting is natural establishes that (1) domain-guided perturbation provides consistently better generalization to unseen domains, compared to generic instance perturbation methods, and that (2) data augmentation is a more stable and accurate method than domain adversarial training.},
  archiveprefix = {arxiv},
  eprint        = {1804.10745},
  file          = {Shankar et al_2018_Generalizing Across Domains via Cross-Gradient Training.pdf:/Users/orsonxu/Desktop/HCI/Literature Management/Zotero/Shankar et al_2018_Generalizing Across Domains via Cross-Gradient Training.pdf:application/pdf},
  url           = {http://arxiv.org/abs/1804.10745},
  urldate       = {2022-01-09},
}


@article{muandet_domain_nodate,
	title = {Domain Generalization via Invariant Feature Representation},
	abstract = {This paper investigates domain generalization: How to take knowledge acquired from an arbitrary number of related domains and apply it to previously unseen domains? We propose Domain-Invariant Component Analysis ({DICA}), a kernel-based optimization algorithm that learns an invariant transformation by minimizing the dissimilarity across domains, whilst preserving the functional relationship between input and output variables. A learning-theoretic analysis shows that reducing dissimilarity improves the expected generalization ability of classiﬁers on new domains, motivating the proposed algorithm. Experimental results on synthetic and real-world datasets demonstrate that {DICA} successfully learns invariant features and improves classiﬁer performance in practice.},
	pages = {9},
	author = {Muandet, Krikamol and Balduzzi, David and Scholkopf, Bernhard},
	langid = {english},
	file = {Muandet et al. - Domain Generalization via Invariant Feature Repres.pdf:/Users/orsonxu/Zotero/storage/2DFZWPP8/Muandet et al. - Domain Generalization via Invariant Feature Repres.pdf:application/pdf}
}

@article{vapnik1999overview,
  title={An overview of statistical learning theory},
  author={Vapnik, Vladimir N},
  journal={IEEE transactions on neural networks},
  volume={10},
  number={5},
  pages={988--999},
  year={1999},
  publisher={IEEE}
}


@Article{pan_survey_2010,
  author   = {Pan, Sinno Jialin and Yang, Qiang},
  journal  = {{IEEE} {TRANSACTIONS} {ON} {KNOWLEDGE} {AND} {DATA} {ENGINEERING}},
  title    = {A Survey on Transfer Learning},
  year     = {2010},
  number   = {10},
  pages    = {1345--1359},
  volume   = {22},
  abstract = {A major assumption in many machine learning and data mining algorithms is that the training and future data must be in the same feature space and have the same distribution. However, in many real-world applications, this assumption may not hold. For example, we sometimes have a classification task in one domain of interest, but we only have sufficient training data in another domain of interest, where the latter data may be in a different feature space or follow a different data distribution. In such cases, knowledge transfer, if done successfully, would greatly improve the performance of learning by avoiding much expensive data-labeling efforts. In recent years, transfer learning has emerged as a new learning framework to address this problem. This survey focuses on categorizing and reviewing the current progress on transfer learning for classification, regression, and clustering problems. In this survey, we discuss the relationship between transfer learning and other related machine learning techniques such as domain adaptation, multitask learning and sample selection bias, as well as covariate shift. We also explore some potential future issues in transfer learning research. Index},
  file     = {Pan_Yang_2010_A Survey on Transfer Learning.pdf:/Users/orsonxu/Desktop/HCI/Literature Management/Zotero/Pan_Yang_2010_A Survey on Transfer Learning.pdf:application/pdf},
}

@Article{zhang_transfer_2011,
  author = {Zhang, Jing and Li, Wanqing and Ogunbona, Philip},
  title  = {A Transfer Learning For Cross-Dataset Recognition: A Survey},
  year   = {2011},
  volume = {V},
  file   = {Zhang et al_2011_A Transfer Learning For Cross-Dataset Recognition.pdf:/Users/orsonxu/Desktop/HCI/Literature Management/Zotero/Zhang et al_2011_A Transfer Learning For Cross-Dataset Recognition.pdf:application/pdf},
  issue  = {July},
}


@Article{daume_frustratingly_2007,
  author   = {Daumé, Hal},
  journal  = {{ACL} 2007 - Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics},
  title    = {Frustratingly easy domain adaptation},
  year     = {2007},
  note     = {{ISBN}: 9781932432862},
  pages    = {256--263},
  abstract = {We describe an approach to domain adaptation that is appropriate exactly in the case when one has enough "target" data to do slightly better than just using only "source" data. Our approach is incredibly simple, easy to implement as a preprocessing step (10 lines of Perl!) and outperforms stateof- the-art approaches on a range of datasets. Moreover, it is trivially extended to a multidomain adaptation problem, where one has data from a variety of different domains. © 2007 Association for Computational Linguistics.},
  file     = {Daumé_2007_Frustratingly easy domain adaptation.pdf:/Users/orsonxu/Desktop/HCI/Literature Management/Zotero/Daumé_2007_Frustratingly easy domain adaptation.pdf:application/pdf},
}

@Article{sun_return_2016,
  author   = {Sun, Baochen and Saenko, Kate},
  journal  = {Proceedings of the Thirtieth {AAAI} Conference on Artificial Intelligence},
  title    = {Return of frustratingly easy domain adaptation},
  year     = {2016},
  number   = {1},
  pages    = {2058--2065},
  file     = {Sun_Saenko_2016_Return of frustratingly easy domain adaptation.pdf:/Users/orsonxu/Desktop/HCI/Literature Management/Zotero/Sun_Saenko_2016_Return of frustratingly easy domain adaptation.pdf:application/pdf},
  keywords = {Technical Papers: Machine Learning Methods},
  url      = {https://ojs.aaai.org/index.php/AAAI/article/view/10306},
}

@Article{tzeng_deep_2014,
  author        = {Tzeng, Eric and Hoffman, Judy and Zhang, Ning and Saenko, Kate and Darrell, Trevor},
  journal       = {{arXiv}:1412.3474 [cs]},
  title         = {Deep Domain Confusion: Maximizing for Domain Invariance},
  year          = {2014},
  month         = dec,
  abstract      = {Recent reports suggest that a generic supervised deep {CNN} model trained on a large-scale dataset reduces, but does not remove, dataset bias on a standard benchmark. Fine-tuning deep models in a new domain can require a significant amount of data, which for many applications is simply not available. We propose a new {CNN} architecture which introduces an adaptation layer and an additional domain confusion loss, to learn a representation that is both semantically meaningful and domain invariant. We additionally show that a domain confusion metric can be used for model selection to determine the dimension of an adaptation layer and the best position for the layer in the {CNN} architecture. Our proposed adaptation method offers empirical performance which exceeds previously published results on a standard benchmark visual domain adaptation task.},
  archiveprefix = {arxiv},
  eprint        = {1412.3474},
  file          = {Tzeng et al_2014_Deep Domain Confusion.pdf:/Users/orsonxu/Desktop/HCI/Literature Management/Zotero/Tzeng et al_2014_Deep Domain Confusion.pdf:application/pdf},
  shorttitle    = {Deep Domain Confusion},
  url           = {http://arxiv.org/abs/1412.3474},
  urldate       = {2021-12-18},
}


@inproceedings{guo2017deep,
  title={Deep clustering with convolutional autoencoders},
  author={Guo, Xifeng and Liu, Xinwang and Zhu, En and Yin, Jianping},
  booktitle={International conference on neural information processing},
  pages={373--382},
  year={2017},
  organization={Springer}
}

@book{cox1994cultural,
  title={Cultural diversity in organizations: Theory, research and practice},
  author={Cox, Taylor},
  year={1994},
  publisher={Berrett-Koehler Publishers}
}

@article{milliken1996searching,
  title={Searching for common threads: Understanding the multiple effects of diversity in organizational groups},
  author={Milliken, Frances J and Martins, Luis L},
  journal={Academy of management review},
  volume={21},
  number={2},
  pages={402--433},
  year={1996},
  publisher={Academy of Management Briarcliff Manor, NY 10510}
}

@article{nettle2006evolution,
  title={The evolution of personality variation in humans and other animals.},
  author={Nettle, Daniel},
  journal={American Psychologist},
  volume={61},
  number={6},
  pages={622},
  year={2006},
  publisher={American Psychological Association}
}

@article{stanovich1998individual,
  title={Individual differences in rational thought.},
  author={Stanovich, Keith E and West, Richard F},
  journal={Journal of experimental psychology: general},
  volume={127},
  number={2},
  pages={161},
  year={1998},
  publisher={American Psychological Association}
}


@Article{banovic_modeling_2016,
  author   = {Banovic, Nikola and Buzali, Tofi and Chevalier, Fanny and Mankoff, Jennifer and Dey, Anind K.},
  journal  = {Proceedings of the {SIGCHI} Conference on Human Factors in Computing Systems},
  title    = {Modeling and Understanding Human Routine Behavior},
  year     = {2016},
  note     = {{ISBN}: 9781450333627},
  pages    = {248--260},
  abstract = {Human routines are blueprints of behavior, which allow people to accomplish purposeful repetitive tasks at many levels, ranging from the structure of their day to how they drive through an intersection. People express their routines through actions that they perform in the particular situations that triggered those actions. An ability to model routines and understand the situations in which they are likely to occur could allow technology to help people improve their bad habits, inexpert behavior, and other suboptimal routines. However, existing routine models do not capture the causal relationships between situations and actions that describe routines. Our main contribution is the insight that byproducts of an existing activity prediction algorithm can be used to model those causal relationships in routines. We apply this algorithm on two example datasets, and show that the modeled routines are meaningful—that they are predictive of people's actions and that the modeled causal relationships provide insights about the routines that match findings from previous research. Our approach offers a generalizable solution to model and reason about routines.},
  doi      = {10.1145/2858036.2858557},
  file     = {Banovic et al_2016_Modeling and Understanding Human Routine Behavior.pdf:/Users/orsonxu/Desktop/HCI/Literature Management/Zotero/Banovic et al_2016_Modeling and Understanding Human Routine Behavior.pdf:application/pdf},
  url      = {http://dl.acm.org/citation.cfm?doid=2858036.2858557},
}


@article{hodgson1997ubiquity,
  title={The ubiquity of habits and rules},
  author={Hodgson, Geoffrey M},
  journal={Cambridge journal of economics},
  volume={21},
  number={6},
  pages={663--684},
  year={1997},
  publisher={Oxford University Press}
}


@inproceedings{noroozi2016unsupervised,
  title={Unsupervised learning of visual representations by solving jigsaw puzzles},
  author={Noroozi, Mehdi and Favaro, Paolo},
  booktitle={European conference on computer vision},
  pages={69--84},
  year={2016},
  organization={Springer}
}

@article{chawla2002smote,
  title={SMOTE: synthetic minority over-sampling technique},
  author={Chawla, Nitesh V and Bowyer, Kevin W and Hall, Lawrence O and Kegelmeyer, W Philip},
  journal={Journal of artificial intelligence research},
  volume={16},
  pages={321--357},
  year={2002}
}

@inproceedings{brodersen2010balanced,
  title={The balanced accuracy and its posterior distribution},
  author={Brodersen, Kay Henning and Ong, Cheng Soon and Stephan, Klaas Enno and Buhmann, Joachim M},
  booktitle={2010 20th international conference on pattern recognition},
  pages={3121--3124},
  year={2010},
  organization={IEEE}
}

@article{padmanabhan2019human,
title = {A Human Depression Circuit Derived From Focal Brain Lesions},
journal = {Biological Psychiatry},
volume = {86},
number = {10},
pages = {749-758},
year = {2019},
note = {Cortical Pathology and Depression},
issn = {0006-3223},
doi = {https://doi.org/10.1016/j.biopsych.2019.07.023},
url = {https://www.sciencedirect.com/science/article/pii/S0006322319315574},
author = {Jaya L. Padmanabhan and Danielle Cooke and Juho Joutsa and Shan H. Siddiqi and others},
keywords = {Depression, Functional connectivity, Functional MRI, Imaging, Lesion, Network, Stroke}
}

@article{riester2014risk,
  title={Risk prediction for late-stage ovarian cancer by meta-analysis of 1525 patient samples},
  author={Riester, Markus and Wei, Wei and Waldron, Levi and Culhane, Aedin C and and others},
  journal={Journal of the National Cancer Institute},
  volume={106},
  number={5},
  pages={dju048},
  year={2014},
  publisher={Oxford University Press US}
}

@article{loshchilov2016sgdr,
  title={Sgdr: Stochastic gradient descent with warm restarts},
  author={Loshchilov, Ilya and Hutter, Frank},
  journal={arXiv preprint arXiv:1608.03983},
  year={2016}
}

@incollection{csurka_domain-adversarial_2017,
	location = {Cham},
	title = {Domain-Adversarial Training of Neural Networks},
	isbn = {978-3-319-58346-4 978-3-319-58347-1},
	url = {http://link.springer.com/10.1007/978-3-319-58347-1_10},
	abstract = {We introduce a new representation learning approach for domain adaptation, in which data at training and test time come from similar but diﬀerent distributions. Our approach is directly inspired by the theory on domain adaptation suggesting that, for eﬀective domain transfer to be achieved, predictions must be made based on features that cannot discriminate between the training (source) and test (target) domains.},
	pages = {189--209},
	booktitle = {Domain Adaptation in Computer Vision Applications},
	publisher = {Springer International Publishing},
	author = {Ganin, Yaroslav and Ustinova, Evgeniya and Ajakan, Hana and Germain, Pascal and Larochelle, Hugo and Laviolette, François and Marchand, Mario and Lempitsky, Victor},
	editor = {Csurka, Gabriela},
	urldate = {2022-03-27},
	year = {2017},
	langid = {english},
	doi = {10.1007/978-3-319-58347-1_10},
	note = {Series Title: Advances in Computer Vision and Pattern Recognition},
	file = {Ganin et al. - 2017 - Domain-Adversarial Training of Neural Networks.pdf:/Users/orsonxu/Zotero/storage/RNDG9IYJ/Ganin et al. - 2017 - Domain-Adversarial Training of Neural Networks.pdf:application/pdf}
}

@article{crawford2004positive,
  title={The Positive and Negative Affect Schedule (PANAS): Construct validity, measurement properties and normative data in a large non-clinical sample},
  author={Crawford, John R and Henry, Julie D},
  journal={British journal of clinical psychology},
  volume={43},
  number={3},
  pages={245--265},
  year={2004},
  publisher={Wiley Online Library}
}

@article{lowe20104,
  title={A 4-item measure of depression and anxiety: validation and standardization of the Patient Health Questionnaire-4 (PHQ-4) in the general population},
  author={L{\"o}we, Bernd and Wahl, Inka and Rose, Matthias and Spitzer, Carsten and Glaesmer, Heide and Wingenfeld, Katja and Schneider, Antonius and Br{\"a}hler, Elmar},
  journal={Journal of affective disorders},
  volume={122},
  number={1-2},
  pages={86--95},
  year={2010},
  publisher={Elsevier}
}

@inproceedings{chen2013unobtrusive,
  title={Unobtrusive sleep monitoring using smartphones},
  author={Chen, Zhenyu and Lin, Mu and Chen, Fanglin and Lane, Nicholas D and Cardone, Giuseppe and Wang, Rui and Li, Tianxing and Chen, Yiqiang and Choudhury, Tanzeem and Campbell, Andrew T},
  booktitle={2013 7th International Conference on Pervasive Computing Technologies for Healthcare and Workshops},
  pages={145--152},
  year={2013},
  organization={IEEE}
}

@article{vega2021reproducible,
  title={Reproducible Analysis Pipeline for Data Streams: Open-Source Software to Process Data Collected With Mobile Devices},
  author={Vega, Julio and Li, Meng and Aguillera, Kwesi and Goel, Nikunj and Joshi, Echhit and Khandekar, Kirtiraj and Durica, Krina C and Kunta, Abhineeth R and Low, Carissa A},
  journal={Frontiers in Digital Health},
  volume={3},
  year={2021},
  publisher={Frontiers Media SA}
}

@article{chen2020depression,
  title={Depression and anxiety among adolescents during COVID-19: A cross-sectional study},
  author={Chen, Fangping and Zheng, Dan and Liu, Jing and Gong, Yi and Guan, Zhizhong and Lou, Didong},
  journal={Brain, behavior, and immunity},
  volume={88},
  pages={36},
  year={2020},
  publisher={Elsevier}
}

@article{nickels2021toward,
  title={Toward a mobile platform for real-world digital measurement of depression: User-centered design, data quality, and behavioral and clinical modeling},
  author={Nickels, Stefanie and Edwards, Matthew D and Poole, Sarah F and Winter, Dale and Gronsbell, Jessica and Rozenkrants, Bella and Miller, David P and Fleck, Mathias and McLean, Alan and Peterson, Bret and others},
  journal={JMIR mental health},
  volume={8},
  number={8},
  pages={e27589},
  year={2021},
  publisher={JMIR Publications Inc., Toronto, Canada}
}

@article{ben2017crosscheck,
  title={CrossCheck: Integrating self-report, behavioral sensing, and smartphone use to identify digital indicators of psychotic relapse.},
  author={Ben-Zeev, Dror and Brian, Rachel and Wang, Rui and Wang, Weichen and Campbell, Andrew T and Aung, Min SH and Merrill, Michael and Tseng, Vincent WS and Choudhury, Tanzeem and Hauser, Marta and others},
  journal={Psychiatric rehabilitation journal},
  volume={40},
  number={3},
  pages={266},
  year={2017},
  publisher={Educational Publishing Foundation}
}

@article{marazziti2010cognitive,
  title={Cognitive impairment in major depression},
  author={Marazziti, Donatella and Consoli, Giorgio and Picchetti, Michela and Carlini, Marina and Faravelli, Luca},
  journal={European journal of pharmacology},
  volume={626},
  number={1},
  pages={83--86},
  year={2010},
  publisher={Elsevier}
}

@article{roshanaei2009longitudinal,
  title={The longitudinal effects of depression on physical activity},
  author={Roshanaei-Moghaddam, Babak and Katon, Wayne J and Russo, Joan},
  journal={General hospital psychiatry},
  volume={31},
  number={4},
  pages={306--315},
  year={2009},
  publisher={Elsevier}
}

@article{camacho1991physical,
  title={Physical activity and depression: evidence from the Alameda County Study},
  author={Camacho, Terry C and Roberts, Robert E and Lazarus, Nancy B and Kaplan, George A and Cohen, Richard D},
  journal={American journal of epidemiology},
  volume={134},
  number={2},
  pages={220--231},
  year={1991},
  publisher={Oxford University Press}
}

@article{gotlib2010cognition,
  title={Cognition and depression: current status and future directions},
  author={Gotlib, Ian H and Joormann, Jutta},
  journal={Annual review of clinical psychology},
  volume={6},
  pages={285--312},
  year={2010},
  publisher={Annual Reviews}
}

@inproceedings{sun2016deep,
  title={Deep coral: Correlation alignment for deep domain adaptation},
  author={Sun, Baochen and Saenko, Kate},
  booktitle={European conference on computer vision},
  pages={443--450},
  year={2016},
  organization={Springer}
}

@article{sagawa2019distributionally,
  title={Distributionally robust neural networks for group shifts: On the importance of regularization for worst-case generalization},
  author={Sagawa, Shiori and Koh, Pang Wei and Hashimoto, Tatsunori B and Liang, Percy},
  journal={arXiv preprint arXiv:1911.08731},
  year={2019}
}


@article{parascandolo2020learning,
  title={Learning explanations that are hard to vary},
  author={Parascandolo, Giambattista and Neitz, Alexander and Orvieto, Antonio and Gresele, Luigi and Sch{\"o}lkopf, Bernhard},
  journal={arXiv preprint arXiv:2009.00329},
  year={2020}
}

@inproceedings{mattingly2019tesserae,
  title={The Tesserae project: Large-scale, longitudinal, in situ, multimodal sensing of information workers},
  author={Mattingly, Stephen M and Gregg, Julie M and Audia, Pino and Bayraktaroglu, Ayse Elvan and Campbell, Andrew T and Chawla, Nitesh V and Das Swain, Vedant and De Choudhury, Munmun and D'Mello, Sidney K and Dey, Anind K and others},
  booktitle={Extended Abstracts of the 2019 CHI Conference on Human Factors in Computing Systems},
  pages={1--8},
  year={2019}
}

@inproceedings{wang2015smartgpa,
  title={SmartGPA: how smartphones can assess and predict academic performance of college students},
  author={Wang, Rui and Harari, Gabriella and Hao, Peilin and Zhou, Xia and Campbell, Andrew T},
  booktitle={Proceedings of the 2015 ACM international joint conference on pervasive and ubiquitous computing},
  pages={295--306},
  year={2015}
}

@inproceedings{koh2021wilds,
  title={Wilds: A benchmark of in-the-wild distribution shifts},
  author={Koh, Pang Wei and Sagawa, Shiori and Marklund, Henrik and Xie, Sang Michael and Zhang, Marvin and Balsubramani, Akshay and Hu, Weihua and Yasunaga, Michihiro and Phillips, Richard Lanas and Gao, Irena and others},
  booktitle={International Conference on Machine Learning},
  pages={5637--5664},
  year={2021},
  organization={PMLR}
}

@inproceedings{sagawa2022extending,
title={Extending the {WILDS} Benchmark for Unsupervised Adaptation},
author={Shiori Sagawa and Pang Wei Koh and Tony Lee and Irena Gao and Sang Michael Xie and Kendrick Shen and Ananya Kumar and Weihua Hu and Michihiro Yasunaga and Henrik Marklund and Sara Beery and Etienne David and Ian Stavness and Wei Guo and Jure Leskovec and Kate Saenko and Tatsunori Hashimoto and Sergey Levine and Chelsea Finn and Percy Liang},
booktitle={International Conference on Learning Representations},
year={2022},
url={https://openreview.net/forum?id=z7p2V6KROOV}
}

@inproceedings{gong2019metasense,
  title={MetaSense: few-shot adaptation to untrained conditions in deep mobile sensing},
  author={Gong, Taesik and Kim, Yeonsu and Shin, Jinwoo and Lee, Sung-Ju},
  booktitle={Proceedings of the 17th Conference on Embedded Networked Sensor Systems},
  pages={110--123},
  year={2019}
}

@article{gong2021dapper,
  title={DAPPER: Performance Estimation of Domain Adaptation in Mobile Sensing},
  author={Gong, Taesik and Kim, Yewon and Orzikulova, Adiba and Liu, Yunxin and Hwang, Sung Ju and Shin, Jinwoo and Lee, Sung-Ju},
  journal={arXiv preprint arXiv:2111.11053},
  year={2021}
}

@article{ramponi2020neural,
  title={Neural Unsupervised Domain Adaptation in NLP---A Survey},
  author={Ramponi, Alan and Plank, Barbara},
  journal={arXiv:2006.00632},
  year={2020}
}

@article{he2020assessing,
  title={Assessing the relationship between routine and schizophrenia symptoms with passively sensed measures of behavioral stability},
  author={He-Yueya, Joy and Buck, Benjamin and Campbell, Andrew and Choudhury, Tanzeem and Kane, John M and Ben-Zeev, Dror and Althoff, Tim},
  journal={NPJ schizophrenia},
  volume={6},
  number={1},
  pages={1--8},
  year={2020},
  publisher={Nature Publishing Group}
}


@article{adler_machine_2022,
	title = {Machine learning for passive mental health symptom prediction: {Generalization} across different longitudinal mobile sensing studies},
	language = {en},
	journal = {PLOS ONE},
	author = {Adler, Daniel A and Wang, Fei and Mohr, David C and Choudhury, Tanzeem},
	year = {2022},
	pages = {20},
	file = {Adler et al. - Machine learning for passive mental health symptom.pdf:/Users/orsonxu/Zotero/storage/3SRU9EBZ/Adler et al. - Machine learning for passive mental health symptom.pdf:application/pdf},
}


@article{yao2007early,
  title={On early stopping in gradient descent learning},
  author={Yao, Yuan and Rosasco, Lorenzo and Caponnetto, Andrea},
  journal={Constructive Approximation},
  volume={26},
  number={2},
  pages={289--315},
  year={2007},
  publisher={Springer}
}

@article{fried2022revisiting,
  title={Revisiting the theoretical and methodological foundations of depression measurement},
  author={Fried, Eiko I and Flake, Jessica K and Robinaugh, Donald J},
  journal={Nature Reviews Psychology},
  pages={1--11},
  year={2022},
  publisher={Nature Publishing Group}
}

@article{huckins2020causal,
  title={Causal factors of anxiety and depression in college students: longitudinal ecological momentary assessment and causal analysis using Peter and Clark momentary conditional independence},
  author={Huckins, Jeremy F and DaSilva, Alex W and Hedlund, Elin L and Murphy, Eilis I and Rogers, Courtney and Wang, Weichen and Obuchi, Mikio and Holtzheimer, Paul E and Wagner, Dylan D and Campbell, Andrew T},
  journal={JMIR mental health},
  volume={7},
  number={6},
  pages={e16684},
  year={2020},
  publisher={JMIR Publications Inc., Toronto, Canada}
}

@article{huckins2020mental,
  title={Mental health and behavior of college students during the early phases of the COVID-19 pandemic: Longitudinal smartphone and ecological momentary assessment study},
  author={Huckins, Jeremy F and DaSilva, Alex W and Wang, Weichen and Hedlund, Elin and Rogers, Courtney and Nepal, Subigya K and Wu, Jialing and Obuchi, Mikio and Murphy, Eilis I and Meyer, Meghan L and others},
  journal={Journal of medical Internet research},
  volume={22},
  number={6},
  pages={e20185},
  year={2020},
  publisher={JMIR Publications Inc., Toronto, Canada}
}

@inproceedings{10.1145/3491102.3502043,
author = {Nepal, Subigya and Wang, Weichen and Vojdanovski, Vlado and Huckins, Jeremy F and daSilva, Alex and Meyer, Meghan and Campbell, Andrew},
title = {COVID Student Study: A Year in the Life of College Students during the COVID-19 Pandemic Through the Lens of Mobile Phone Sensing},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3502043},
doi = {10.1145/3491102.3502043},
abstract = { The COVID-19 pandemic continues to affect the daily life of college students, impacting their social life, education, stress levels and overall mental well-being. We study and assess behavioral changes of N=180 undergraduate college students one year prior to the pandemic as a baseline and then during the first year of the pandemic using mobile phone sensing and behavioral inference. We observe that certain groups of students experience the pandemic very differently. Furthermore, we explore the association of self-reported COVID-19 concern with students’ behavior and mental health. We find that heightened COVID-19 concern is correlated with increased depression, anxiety and stress. We evaluate the performance of different deep learning models to classify student COVID-19 concerns with an AUROC and F1 score of 0.70 and 0.71, respectively. Our study spans a two-year period and provides a number of important insights into the life of college students during this period.},
booktitle = {CHI Conference on Human Factors in Computing Systems},
articleno = {42},
numpages = {19},
keywords = {COVID-19, Mental health, Pandemic, Mobile Sensing, Digital Phenotyping},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{lin2017focal,
  title={Focal loss for dense object detection},
  author={Lin, Tsung-Yi and Goyal, Priya and Girshick, Ross and He, Kaiming and Doll{\'a}r, Piotr},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={2980--2988},
  year={2017}
}

@article{barnett2020inferring,
  title={Inferring mobility measures from GPS traces with missing data},
  author={Barnett, Ian and Onnela, Jukka-Pekka},
  journal={Biostatistics},
  volume={21},
  number={2},
  pages={e98--e112},
  year={2020},
  publisher={Oxford University Press}
}

@article{doryab2018extraction,
  title={Extraction of behavioral features from smartphone and wearable data},
  author={Doryab, Afsaneh and Chikarsel, Prerna and Liu, Xinwen and Dey, Anind K},
  journal={arXiv preprint arXiv:1812.10394},
  year={2018}
}

@article{vega2022detecting,
  title={Detecting Mental Health Behaviors Using Mobile Interactions: Exploratory Study Focusing on Binge Eating},
  author={Vega, Julio and Bell, Beth T and Taylor, Caitlin and Xie, Jue and Ng, Heidi and Honary, Mahsa and McNaney, Roisin and others},
  journal={JMIR mental health},
  volume={9},
  number={4},
  pages={e32146},
  year={2022},
  publisher={JMIR Publications Inc., Toronto, Canada}
}

@article{yan2022exploratory,
  title={Exploratory machine learning modeling of adaptive and maladaptive personality traits from passively sensed behavior},
  author={Yan, Runze and Ringwald, Whitney R and Vega, Julio and Kehl, Madeline and Bae, Sang Won and Dey, Anind K and Low, Carissa A and Wright, Aidan GC and Doryab, Afsaneh},
  journal={Future Generation Computer Systems},
  volume={132},
  pages={266--281},
  year={2022},
  publisher={Elsevier}
}

@article{neyshabur2017exploring,
  title={Exploring generalization in deep learning},
  author={Neyshabur, Behnam and Bhojanapalli, Srinadh and McAllester, David and Srebro, Nati},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@book{mitchell1997machine,
  title={Machine learning},
  author={Mitchell, Tom M and Mitchell, Tom M},
  volume={1},
  number={9},
  year={1997},
  publisher={McGraw-hill New York}
}

@article{yang2022machine,
  title={Machine learning generalizability across healthcare settings: insights from multi-site COVID-19 screening},
  author={Yang, Jenny and Soltan, Andrew AS and Clifton, David A},
  journal={npj Digital Medicine},
  volume={5},
  number={1},
  pages={1--8},
  year={2022},
  publisher={Nature Publishing Group}
}

@inproceedings{gundersen2018state,
  title={State of the art: Reproducibility in artificial intelligence},
  author={Gundersen, Odd Erik and Kjensmo, Sigbj{\o}rn},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={32},
  number={1},
  year={2018}
}

@article{mcdermott2021reproducibility,
  title={Reproducibility in machine learning for health research: Still a ways to go},
  author={McDermott, Matthew BA and Wang, Shirly and Marinsek, Nikki and Ranganath, Rajesh and Foschini, Luca and Ghassemi, Marzyeh},
  journal={Science Translational Medicine},
  volume={13},
  number={586},
  pages={eabb1655},
  year={2021},
  publisher={American Association for the Advancement of Science}
}

@article{confalonieri2021historical,
  title={A historical perspective of explainable Artificial Intelligence},
  author={Confalonieri, Roberto and Coba, Ludovik and Wagner, Benedikt and Besold, Tarek R},
  journal={Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery},
  volume={11},
  number={1},
  pages={e1391},
  year={2021},
  publisher={Wiley Online Library}
}

@article{hess1964pupil,
  title={Pupil size in relation to mental activity during simple problem-solving},
  author={Hess, Eckhard H and Polt, James M},
  journal={Science},
  volume={143},
  number={3611},
  pages={1190--1192},
  year={1964},
  publisher={American Association for the Advancement of Science}
}

@inproceedings{chong2018connecting,
  title={Connecting gaze, scene, and attention: Generalized attention estimation via joint modeling of gaze and scene saliency},
  author={Chong, Eunji and Ruiz, Nataniel and Wang, Yongxin and Zhang, Yun and Rozga, Agata and Rehg, James M},
  booktitle={Proceedings of the European conference on computer vision (ECCV)},
  pages={383--398},
  year={2018}
}

@inproceedings{stappen2020x,
  title={X-aware: Context-aware human-environment attention fusion for driver gaze prediction in the wild},
  author={Stappen, Lukas and Rizos, Georgios and Schuller, Bj{\"o}rn},
  booktitle={Proceedings of the 2020 International Conference on Multimodal Interaction},
  pages={858--867},
  year={2020}
}

@inproceedings{huang2018predicting,
  title={Predicting gaze in egocentric video by learning task-dependent attention transition},
  author={Huang, Yifei and Cai, Minjie and Li, Zhenqiang and Sato, Yoichi},
  booktitle={Proceedings of the European conference on computer vision (ECCV)},
  pages={754--769},
  year={2018}
}

@inproceedings{fathi2011understanding,
  title={Understanding egocentric activities},
  author={Fathi, Alireza and Farhadi, Ali and Rehg, James M},
  booktitle={2011 international conference on computer vision},
  pages={407--414},
  year={2011},
  organization={IEEE}
}

@incollection{schroder2017deep,
  title={Deep learning for action recognition in augmented reality assistance systems},
  author={Schr{\"o}der, Matthias and Ritter, Helge},
  booktitle={ACM SIGGRAPH 2017 Posters},
  pages={1--2},
  year={2017}
}

@inproceedings{grauman2022ego4d,
  title={Ego4d: Around the world in 3,000 hours of egocentric video},
  author={Grauman, Kristen and Westbury, Andrew and Byrne, Eugene and Chavis, Zachary and Furnari, Antonino and Girdhar, Rohit and Hamburger, Jackson and Jiang, Hao and Liu, Miao and Liu, Xingyu and others},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={18995--19012},
  year={2022}
}

@inproceedings{redmon2016you,
  title={You only look once: Unified, real-time object detection},
  author={Redmon, Joseph and Divvala, Santosh and Girshick, Ross and Farhadi, Ali},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={779--788},
  year={2016}
}

@inproceedings{singh2016first,
  title={First person action recognition using deep learned descriptors},
  author={Singh, Suriya and Arora, Chetan and Jawahar, CV},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={2620--2628},
  year={2016}
}

@article{liu2020deep,
  title={Deep learning for generic object detection: A survey},
  author={Liu, Li and Ouyang, Wanli and Wang, Xiaogang and Fieguth, Paul and Chen, Jie and Liu, Xinwang and Pietik{\"a}inen, Matti},
  journal={International journal of computer vision},
  volume={128},
  number={2},
  pages={261--318},
  year={2020},
  publisher={Springer}
}

@article{pan2019content,
  title={Content-based visual summarization for image collections},
  author={Pan, Xingjia and Tang, Fan and Dong, Weiming and Ma, Chongyang and Meng, Yiping and Huang, Feiyue and Lee, Tong-Yee and Xu, Changsheng},
  journal={IEEE transactions on visualization and computer graphics},
  volume={27},
  number={4},
  pages={2298--2312},
  year={2019},
  publisher={IEEE}
}

@article{bolanos2016toward,
  title={Toward storytelling from visual lifelogging: An overview},
  author={Bolanos, Marc and Dimiccoli, Mariella and Radeva, Petia},
  journal={IEEE Transactions on Human-Machine Systems},
  volume={47},
  number={1},
  pages={77--90},
  year={2016},
  publisher={IEEE}
}

@inproceedings{miech2020end,
  title={End-to-end learning of visual representations from uncurated instructional videos},
  author={Miech, Antoine and Alayrac, Jean-Baptiste and Smaira, Lucas and Laptev, Ivan and Sivic, Josef and Zisserman, Andrew},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={9879--9889},
  year={2020}
}

@article{elliott2017living,
  title={Living systematic review: 1. Introduction—the why, what, when, and how},
  author={Elliott, Julian H and Synnot, Anneliese and Turner, Tari and Simmonds, Mark and Akl, Elie A and McDonald, Steve and Salanti, Georgia and Meerpohl, Joerg and MacLehose, Harriet and Hilton, John and others},
  journal={Journal of clinical epidemiology},
  volume={91},
  pages={23--30},
  year={2017},
  publisher={Elsevier}
}

@inproceedings{kapoor2015just,
  title={Just in time recommendations: Modeling the dynamics of boredom in activity streams},
  author={Kapoor, Komal and Subbian, Karthik and Srivastava, Jaideep and Schrater, Paul},
  booktitle={Proceedings of the eighth ACM international conference on web search and data mining},
  pages={233--242},
  year={2015}
}

@inproceedings{mehrotra2019jointly,
  title={Jointly leveraging intent and interaction signals to predict user satisfaction with slate recommendations},
  author={Mehrotra, Rishabh and Lalmas, Mounia and Kenney, Doug and Lim-Meng, Thomas and Hashemian, Golli},
  booktitle={The World Wide Web Conference},
  pages={1256--1267},
  year={2019}
}

@inproceedings{bhattacharya2017intent,
  title={Intent-aware contextual recommendation system},
  author={Bhattacharya, Biswarup and Burhanuddin, Iftikhar and Sancheti, Abhilasha and Satya, Kushal},
  booktitle={2017 IEEE International Conference on Data Mining Workshops (ICDMW)},
  pages={1--8},
  year={2017},
  organization={IEEE}
}

@inproceedings{stumpf2016explanations,
  title={Explanations considered harmful? user interactions with machine learning systems},
  author={Stumpf, Simone and Bussone, Adrian and O’sullivan, Dympna},
  booktitle={Proceedings of the ACM SIGCHI Conference on Human Factors in Computing Systems (CHI)},
  year={2016}
}

@article{robbins2019misdirected,
  title={A misdirected principle with a catch: explicability for AI},
  author={Robbins, Scott},
  journal={Minds and Machines},
  volume={29},
  number={4},
  pages={495--514},
  year={2019},
  publisher={Springer}
}

@inproceedings{chazette2019end,
  title={Do end-users want explanations? Analyzing the role of explainability as an emerging aspect of non-functional requirements},
  author={Chazette, Larissa and Karras, Oliver and Schneider, Kurt},
  booktitle={2019 IEEE 27th International Requirements Engineering Conference (RE)},
  pages={223--233},
  year={2019},
  organization={IEEE}
}

@inproceedings{wagner2020regulating,
  title={Regulating transparency? Facebook, twitter and the German network enforcement act},
  author={Wagner, Ben and Rozgonyi, Krisztina and Sekwenz, Marie-Therese and Cobbe, Jennifer and Singh, Jatinder},
  booktitle={Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency},
  pages={261--271},
  year={2020}
}


@article{mahbooba2021explainable,
  title={Explainable artificial intelligence (XAI) to enhance trust management in intrusion detection systems using decision tree model},
  author={Mahbooba, Basim and Timilsina, Mohan and Sahal, Radhya and Serrano, Martin},
  journal={Complexity},
  volume={2021},
  year={2021},
  publisher={Hindawi}
}

@article{kenny2021explaining,
  title={Explaining black-box classifiers using post-hoc explanations-by-example: The effect of explanations and error-rates in XAI user studies},
  author={Kenny, Eoin M and Ford, Courtney and Quinn, Molly and Keane, Mark T},
  journal={Artificial Intelligence},
  volume={294},
  pages={103459},
  year={2021},
  publisher={Elsevier}
}

@article{da2020recommendation,
  title={Recommendation system based on deep learning methods: a systematic review and new directions},
  author={Da’u, Aminu and Salim, Naomie},
  journal={Artificial Intelligence Review},
  volume={53},
  number={4},
  pages={2709--2748},
  year={2020},
  publisher={Springer}
}

@inproceedings{ma2020temporal,
  title={Temporal-contextual recommendation in real-time},
  author={Ma, Yifei and Narayanaswamy, Balakrishnan and Lin, Haibin and Ding, Hao},
  booktitle={Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery \& Data Mining},
  pages={2291--2299},
  year={2020}
}

@inproceedings{manotumruksa2018contextual,
  title={A contextual attention recurrent architecture for context-aware venue recommendation},
  author={Manotumruksa, Jarana and Macdonald, Craig and Ounis, Iadh},
  booktitle={The 41st international ACM SIGIR conference on research \& development in information retrieval},
  pages={555--564},
  year={2018}
}

@article{qian2013personalized,
  title={Personalized recommendation combining user interest and social circle},
  author={Qian, Xueming and Feng, He and Zhao, Guoshuai and Mei, Tao},
  journal={IEEE transactions on knowledge and data engineering},
  volume={26},
  number={7},
  pages={1763--1777},
  year={2013},
  publisher={IEEE}
}

@article{cui2020personalized,
  title={Personalized recommendation system based on collaborative filtering for IoT scenarios},
  author={Cui, Zhihua and Xu, Xianghua and Fei, XUE and Cai, Xingjuan and Cao, Yang and Zhang, Wensheng and Chen, Jinjun},
  journal={IEEE Transactions on Services Computing},
  volume={13},
  number={4},
  pages={685--695},
  year={2020},
  publisher={IEEE}
}

@inproceedings{lakkaraju2019faithful,
  title={Faithful and customizable explanations of black box models},
  author={Lakkaraju, Himabindu and Kamar, Ece and Caruana, Rich and Leskovec, Jure},
  booktitle={Proceedings of the 2019 AAAI/ACM Conference on AI, Ethics, and Society},
  pages={131--138},
  year={2019}
}

@article{felzmann2019robots,
  title={Robots and transparency: The multiple dimensions of transparency in the context of robot technologies},
  author={Felzmann, Heike and Fosch-Villaronga, Eduard and Lutz, Christoph and Tamo-Larrieux, Aurelia},
  journal={IEEE Robotics \& Automation Magazine},
  volume={26},
  number={2},
  pages={71--78},
  year={2019},
  publisher={IEEE}
}

@inproceedings{miller2014delegation,
  title={Delegation and transparency: Coordinating interactions so information exchange is no surprise},
  author={Miller, Christopher A},
  booktitle={International Conference on Virtual, Augmented and Mixed Reality},
  pages={191--202},
  year={2014},
  organization={Springer}
}

@inproceedings{zhao2007earpod,
  title={Earpod: eyes-free menu selection using touch input and reactive audio feedback},
  author={Zhao, Shengdong and Dragicevic, Pierre and Chignell, Mark and Balakrishnan, Ravin and Baudisch, Patrick},
  booktitle={Proceedings of the SIGCHI conference on Human factors in computing systems},
  pages={1395--1404},
  year={2007}
}

@inproceedings{fan2021just,
  title={Just Speak It: Minimize Cognitive Load for Eyes-Free Text Editing with a Smart Voice Assistant},
  author={Fan, Jiayue and Xu, Chenning and Yu, Chun and Shi, Yuanchun},
  booktitle={The 34th Annual ACM Symposium on User Interface Software and Technology},
  pages={910--921},
  year={2021}
}

@inproceedings{chen2017multimodal,
  title={Multimodal interaction in augmented reality},
  author={Chen, Zhaorui and Li, Jinzhu and Hua, Yifan and Shen, Rui and Basu, Anup},
  booktitle={2017 IEEE international conference on systems, man, and cybernetics (SMC)},
  pages={206--209},
  year={2017},
  organization={IEEE}
}

@article{nizam2018review,
  title={A review of multimodal interaction technique in augmented reality environment},
  author={Nizam, SS Muhammad and Abidin, Rimaniza Zainal and Hashim, Nurhazarifah Che and Lam, Meng Chun and Arshad, Haslina and Majid, NAA},
  journal={Int. J. Adv. Sci. Eng. Inf. Technol},
  volume={8},
  number={4-2},
  pages={1460},
  year={2018}
}

@inproceedings{bonanni2005attention,
  title={Attention-based design of augmented reality interfaces},
  author={Bonanni, Leonardo and Lee, Chia-Hsun and Selker, Ted},
  booktitle={CHI'05 extended abstracts on Human factors in computing systems},
  pages={1228--1231},
  year={2005}
}

@book{laviola20173d,
  title={3D user interfaces: theory and practice},
  author={LaViola Jr, Joseph J and Kruijff, Ernst and McMahan, Ryan P and Bowman, Doug and Poupyrev, Ivan P},
  year={2017},
  publisher={Addison-Wesley Professional}
}

@inproceedings{dai2017scannet,
  title={Scannet: Richly-annotated 3d reconstructions of indoor scenes},
  author={Dai, Angela and Chang, Angel X and Savva, Manolis and Halber, Maciej and Funkhouser, Thomas and Nie{\ss}ner, Matthias},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={5828--5839},
  year={2017}
}

@inproceedings{diverdi2004level,
  title={Level of detail interfaces},
  author={DiVerdi, Stephen and Hollerer, Tobias and Schreyer, Richard},
  booktitle={Third IEEE and ACM International Symposium on Mixed and Augmented Reality},
  pages={300--301},
  year={2004},
  organization={IEEE}
}

@article{esteva2017dermatologist,
  title={Dermatologist-level classification of skin cancer with deep neural networks},
  author={Esteva, Andre and Kuprel, Brett and Novoa, Roberto A and Ko, Justin and Swetter, Susan M and Blau, Helen M and Thrun, Sebastian},
  journal={nature},
  volume={542},
  number={7639},
  pages={115--118},
  year={2017},
  publisher={Nature Publishing Group}
}

@inproceedings{coppers2018intellingo,
  title={Intellingo: An intelligible translation environment},
  author={Coppers, Sven and Van den Bergh, Jan and Luyten, Kris and Coninx, Karin and Van der Lek-Ciudin, Iulianna and Vanallemeersch, Tom and Vandeghinste, Vincent},
  booktitle={Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
  pages={1--13},
  year={2018}
}

@article{qoc_1999,
author = {MacLean, Allan and Young, Richard M. and Bellotti, Victoria M. E. and Moran, Thomas P.},
title = {Questions, Options, and Criteria: Elements of Design Space Analysis},
year = {1991},
issue_date = {September 1991},
publisher = {L. Erlbaum Associates Inc.},
address = {USA},
volume = {6},
number = {3},
issn = {0737-0024},
url = {https://doi.org/10.1207/s15327051hci0603%264_2},
doi = {10.1207/s15327051hci0603%264_2},
abstract = {Design Space Analysis is an approach to representing design rationale. It uses a semiformal notation, called QOC (Questions, Options, and Criteria), to represent the design space around an artifact. The main constituents of QOC are Questions identifying key design issues, Options providing possible answers to the Questions, and Criteria for assessing and comparing the Options. Design Space Analysis also takes account of justifications for the design (and possible alternative designs) that reflect considerations such as consistency, models and analogies, and relevant data and theory. A Design Space Analysis does not produce a record of the design process but is instead a coproduct of design and has to be constructed alongside the artifact itself. Our work is motivated by the notion that a Design Space Analysis will repay the investment in its creation by supporting both the original process of design and subsequent work on redesign and reuse by (a) providing an explicit representation to aid reasoning about the design and about the consequences of changes to it and (b) serving as a vehicle for communication, for example, among members of the design team or among the original designers and later maintainers of a system. Our work to date emphasises the nature of the QOC representation over processes for creating it, so these claims serve as goals rather than objectives we have achieved. This article describes the elements of Design Space Analysis and illustrates them by reference to analyses of existing designs and to studies of the concepts and arguments used by designers during design discussions.},
journal = {Hum.-Comput. Interact.},
month = {sep},
pages = {201–250},
numpages = {50}
}

@article{arya2019one,
  title={One explanation does not fit all: A toolkit and taxonomy of ai explainability techniques},
  author={Arya, Vijay and Bellamy, Rachel KE and Chen, Pin-Yu and Dhurandhar, Amit and Hind, Michael and Hoffman, Samuel C and Houde, Stephanie and Liao, Q Vera and Luss, Ronny and Mojsilovi{\'c}, Aleksandra and others},
  journal={arXiv preprint arXiv:1909.03012},
  year={2019}
}

@misc{meta_ai,
title={AI system cards},
url={https://ai.facebook.com/tools/system-cards/},
journal={Meta AI},
year = {2022}
}

@misc{google_cloud_model_cards,
title={Google Cloud Model Cards},
url={https://modelcards.withgoogle.com/},
journal={Google Cloud},
publisher={Google},
year = {2022}
} 

@misc{gdpr_2019,
title={General Data Protection Regulation (GDPR)},
url={https://gdpr-info.eu/},
journal={Official Legal Text},
year={2019},
author={European Union},
month={Sep}
} 

@article{gunning2019darpa,
  title={DARPA’s explainable artificial intelligence (XAI) program},
  author={Gunning, David and Aha, David},
  journal={AI magazine},
  volume={40},
  number={2},
  pages={44--58},
  year={2019}
}

@article{gunning2017explainable,
  title={Explainable artificial intelligence (xai)},
  author={Gunning, David},
  journal={Defense advanced research projects agency (DARPA), nd Web},
  volume={2},
  number={2},
  pages={1},
  year={2017}
}

@article{lipton2018mythos,
  title={The mythos of model interpretability: In machine learning, the concept of interpretability is both important and slippery.},
  author={Lipton, Zachary C},
  journal={Queue},
  volume={16},
  number={3},
  pages={31--57},
  year={2018},
  publisher={ACM New York, NY, USA}
}

@article{samek2017explainable,
  title={Explainable artificial intelligence: Understanding, visualizing and interpreting deep learning models},
  author={Samek, Wojciech and Wiegand, Thomas and M{\"u}ller, Klaus-Robert},
  journal={arXiv preprint arXiv:1708.08296},
  year={2017}
}

@article{yuan2019adversarial,
  title={Adversarial examples: Attacks and defenses for deep learning},
  author={Yuan, Xiaoyong and He, Pan and Zhu, Qile and Li, Xiaolin},
  journal={IEEE transactions on neural networks and learning systems},
  volume={30},
  number={9},
  pages={2805--2824},
  year={2019},
  publisher={IEEE}
}

@article{louizos2017causal,
  title={Causal effect inference with deep latent-variable models},
  author={Louizos, Christos and Shalit, Uri and Mooij, Joris M and Sontag, David and Zemel, Richard and Welling, Max},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@inproceedings{pope2019explainability,
  title={Explainability methods for graph convolutional neural networks},
  author={Pope, Phillip E and Kolouri, Soheil and Rostami, Mohammad and Martin, Charles E and Hoffmann, Heiko},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={10772--10781},
  year={2019}
}

@inproceedings{belle2017logic,
  title={Logic meets Probability: Towards Explainable AI Systems for Uncertain Worlds.},
  author={Belle, Vaishak},
  booktitle={IJCAI},
  pages={5116--5120},
  year={2017}
}

@inproceedings{dovsilovic2018explainable,
  title={Explainable artificial intelligence: A survey},
  author={Do{\v{s}}ilovi{\'c}, Filip Karlo and Br{\v{c}}i{\'c}, Mario and Hlupi{\'c}, Nikica},
  booktitle={2018 41st International convention on information and communication technology, electronics and microelectronics (MIPRO)},
  pages={0210--0215},
  year={2018},
  organization={IEEE}
}

@inproceedings{chander2018working,
  title={Working with beliefs: AI transparency in the enterprise},
  author={Chander, Ajay and Srinivasan, Ramya and Chelian, Suhas and Wang, Jun and Uchino, Kanji},
  booktitle={IUI Workshops},
  year={2018}
}

@article{tickle1998truth,
  title={The truth will come to light: Directions and challenges in extracting the knowledge embedded within trained artificial neural networks},
  author={Tickle, Alan B and Andrews, Robert and Golea, Mostefa and Diederich, Joachim},
  journal={IEEE Transactions on Neural Networks},
  volume={9},
  number={6},
  pages={1057--1068},
  year={1998},
  publisher={IEEE}
}

@article{edwards2017slave,
  title={Slave to the algorithm: Why a right to an explanation is probably not the remedy you are looking for},
  author={Edwards, Lilian and Veale, Michael},
  journal={Duke L. \& Tech. Rev.},
  volume={16},
  pages={18},
  year={2017},
  publisher={HeinOnline}
}

@article{doshi2017towards,
  title={Towards a rigorous science of interpretable machine learning},
  author={Doshi-Velez, Finale and Kim, Been},
  journal={arXiv preprint arXiv:1702.08608},
  year={2017}
}

@inproceedings{holliday2016user,
  title={User trust in intelligent systems: A journey over time},
  author={Holliday, Daniel and Wilson, Stephanie and Stumpf, Simone},
  booktitle={Proceedings of the 21st international conference on intelligent user interfaces},
  pages={164--168},
  year={2016}
}

@inproceedings{pu2006trust,
  title={Trust building with explanation interfaces},
  author={Pu, Pearl and Chen, Li},
  booktitle={Proceedings of the 11th international conference on Intelligent user interfaces},
  pages={93--100},
  year={2006}
}

@article{huysmans2011empirical,
  title={An empirical evaluation of the comprehensibility of decision table, tree and rule based predictive models},
  author={Huysmans, Johan and Dejaeger, Karel and Mues, Christophe and Vanthienen, Jan and Baesens, Bart},
  journal={Decision Support Systems},
  volume={51},
  number={1},
  pages={141--154},
  year={2011},
  publisher={Elsevier}
}

@article{burrell2016machine,
  title={How the machine ‘thinks’: Understanding opacity in machine learning algorithms},
  author={Burrell, Jenna},
  journal={Big data \& society},
  volume={3},
  number={1},
  pages={2053951715622512},
  year={2016},
  publisher={Sage Publications Sage UK: London, England}
}

@misc{google_map_match_rate_2018,
title={Explore and eat your way around town with google maps}, url={https://www.blog.google/products/maps/explore-around-town-google-maps/}, journal={Google},
publisher={Google}, author={Lin, Sophia}, year={2018}, month={May}} 

@misc{google_glass,
title={Glass Glass},
url={https://www.google.com/glass/start/},
journal={Google},
publisher={Google},
year = {2022},
} 
 
@misc{microsoft_hololens,
title={Microsoft hololens: Mixed Reality Technology for Business}, url={https://www.microsoft.com/en-us/hololens}, journal={Microsoft HoloLens}, publisher={Microsoft},
year = {2022}
}

@misc{snap_spectacle,
 title={Spectacles by snap inc. - the next generation of spectacles}, url={https://www.spectacles.com/},
 journal={Spectacles by Snap Inc. The Next Generation of Spectacles},
 year = {2022}} 
 
@misc{magic_leap,
title={Enterprise augmented reality (AR) platform designed for business: Magic leap}, url={https://www.magicleap.com/en-us/}, journal={Enterprise augmented reality (AR) platform designed for business | Magic Leap},
year={2022}} 

@incollection{adomavicius2011context,
  title={Context-aware recommender systems},
  author={Adomavicius, Gediminas and Tuzhilin, Alexander},
  booktitle={Recommender systems handbook},
  pages={217--253},
  year={2011},
  publisher={Springer}
}

@inproceedings{admoni2016predicting,
  title={Predicting user intent through eye gaze for shared autonomy},
  author={Admoni, Henny and Srinivasa, Siddhartha},
  booktitle={2016 AAAI Fall Symposium Series},
  year={2016}
}

@inproceedings{xu2019explainable,
  title={Explainable AI: A brief survey on history, research areas, approaches and challenges},
  author={Xu, Feiyu and Uszkoreit, Hans and Du, Yangzhou and Fan, Wei and Zhao, Dongyan and Zhu, Jun},
  booktitle={CCF international conference on natural language processing and Chinese computing},
  pages={563--574},
  year={2019},
  organization={Springer}
}

@techreport{scott1977explanation,
  title={Explanation capabilities of production-based consultation systems},
  author={Scott, A Carlisle and Clancey, William J and Davis, Randall and Shortliffe, Edward H},
  year={1977},
  institution={STANFORD UNIV CA DEPT OF COMPUTER SCIENCE}
}

@incollection{swartout1985explaining,
  title={Explaining and justifying expert consulting programs},
  author={Swartout, William R},
  booktitle={Computer-assisted medical decision making},
  pages={254--271},
  year={1985},
  publisher={Springer}
}


@article{gregor1999explanations,
  title={Explanations from intelligent systems: Theoretical foundations and implications for practice},
  author={Gregor, Shirley and Benbasat, Izak},
  journal={MIS quarterly},
  pages={497--530},
  year={1999},
  publisher={JSTOR}
}

@inproceedings{poulin2006visual,
  title={Visual explanation of evidence with additive classifiers},
  author={Poulin, Brett and Eisner, Roman and Szafron, Duane and Lu, Paul and Greiner, Russell and Wishart, David S and Fyshe, Alona and Pearcy, Brandon and MacDonell, Cam and Anvik, John},
  booktitle={Proceedings of the National Conference on Artificial Intelligence},
  volume={21},
  number={2},
  pages={1822},
  year={2006},
  organization={Menlo Park, CA; Cambridge, MA; London; AAAI Press; MIT Press; 1999}
}

@article{preece2018stakeholders,
  title={Stakeholders in explainable AI},
  author={Preece, Alun and Harborne, Dan and Braines, Dave and Tomsett, Richard and Chakraborty, Supriyo},
  journal={arXiv preprint arXiv:1810.00184},
  year={2018}
}

@article{letham2015interpretable,
  title={Interpretable classifiers using rules and bayesian analysis: Building a better stroke prediction model},
  author={Letham, Benjamin and Rudin, Cynthia and McCormick, Tyler H and Madigan, David},
  journal={The Annals of Applied Statistics},
  volume={9},
  number={3},
  pages={1350--1371},
  year={2015},
  publisher={Institute of Mathematical Statistics}
}

@inproceedings{caruana2015intelligible,
  title={Intelligible models for healthcare: Predicting pneumonia risk and hospital 30-day readmission},
  author={Caruana, Rich and Lou, Yin and Gehrke, Johannes and Koch, Paul and Sturm, Marc and Elhadad, Noemie},
  booktitle={Proceedings of the 21th ACM SIGKDD international conference on knowledge discovery and data mining},
  pages={1721--1730},
  year={2015}
}

@inproceedings{selvaraju2017grad,
  title={Grad-cam: Visual explanations from deep networks via gradient-based localization},
  author={Selvaraju, Ramprasaath R and Cogswell, Michael and Das, Abhishek and Vedantam, Ramakrishna and Parikh, Devi and Batra, Dhruv},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={618--626},
  year={2017}
}

@article{taylor2021artificial,
  title={Artificial cognition: How experimental psychology can help generate explainable artificial intelligence},
  author={Taylor, J Eric T and Taylor, Graham W},
  journal={Psychonomic Bulletin \& Review},
  volume={28},
  number={2},
  pages={454--475},
  year={2021},
  publisher={Springer}
}

@article{yarkoni2017choosing,
  title={Choosing prediction over explanation in psychology: Lessons from machine learning},
  author={Yarkoni, Tal and Westfall, Jacob},
  journal={Perspectives on Psychological Science},
  volume={12},
  number={6},
  pages={1100--1122},
  year={2017},
  publisher={Sage Publications Sage CA: Los Angeles, CA}
}

@article{hoffman2018metrics,
  title={Metrics for explainable AI: Challenges and prospects},
  author={Hoffman, Robert R and Mueller, Shane T and Klein, Gary and Litman, Jordan},
  journal={arXiv preprint arXiv:1812.04608},
  year={2018}
}

@article{miller2019explanation,
  title={Explanation in artificial intelligence: Insights from the social sciences},
  author={Miller, Tim},
  journal={Artificial intelligence},
  volume={267},
  pages={1--38},
  year={2019},
  publisher={Elsevier}
}

@article{lepri2018fair,
  title={Fair, transparent, and accountable algorithmic decision-making processes},
  author={Lepri, Bruno and Oliver, Nuria and Letouz{\'e}, Emmanuel and Pentland, Alex and Vinck, Patrick},
  journal={Philosophy \& Technology},
  volume={31},
  number={4},
  pages={611--627},
  year={2018},
  publisher={Springer}
}

@article{amershi2014power,
  title={Power to the people: The role of humans in interactive machine learning},
  author={Amershi, Saleema and Cakmak, Maya and Knox, William Bradley and Kulesza, Todd},
  journal={Ai Magazine},
  volume={35},
  number={4},
  pages={105--120},
  year={2014}
}

@article{vavra2017recent,
  title={Recent development of augmented reality in surgery: a review},
  author={V{\'a}vra, Petr and Roman, Jan and Zon{\v{c}}a, Pavel and Ihn{\'a}t, Peter and N{\v{e}}mec, Martin and Kumar, Jayant and Habib, Nagy and El-Gendi, Ahmed},
  journal={Journal of healthcare engineering},
  volume={2017},
  year={2017},
  publisher={Hindawi}
}

@article{nee2012augmented,
  title={Augmented reality applications in design and manufacturing},
  author={Nee, Andrew YC and Ong, SK and Chryssolouris, George and Mourtzis, Dimitris},
  journal={CIRP annals},
  volume={61},
  number={2},
  pages={657--679},
  year={2012},
  publisher={Elsevier}
}

@article{cipresso2018past,
  title={The past, present, and future of virtual and augmented reality research: a network and cluster analysis of the literature},
  author={Cipresso, Pietro and Giglioli, Irene Alice Chicchi and Raya, Mariano Alca{\~n}iz and Riva, Giuseppe},
  journal={Frontiers in psychology},
  pages={2086},
  year={2018},
  publisher={Frontiers}
}

@article{rese2017augmented,
  title={How augmented reality apps are accepted by consumers: A comparative analysis using scales and opinions},
  author={Rese, Alexandra and Baier, Daniel and Geyer-Schulz, Andreas and Schreiber, Stefanie},
  journal={Technological Forecasting and Social Change},
  volume={124},
  pages={306--319},
  year={2017},
  publisher={Elsevier}
}

@article{graesser1992mechanisms,
  title={Mechanisms that generate questions},
  author={Graesser, Arthur C and Person, Natalie and Huber, John},
  journal={Questions and information systems},
  volume={2},
  pages={167--187},
  year={1992}
}

@inproceedings{herlocker2000explaining,
  title={Explaining collaborative filtering recommendations},
  author={Herlocker, Jonathan L and Konstan, Joseph A and Riedl, John},
  booktitle={Proceedings of the 2000 ACM conference on Computer supported cooperative work},
  pages={241--250},
  year={2000}
}

@article{amini2022discovering,
  title={Discovering injury severity risk factors in automobile crashes: A hybrid explainable AI framework for decision support},
  author={Amini, Mostafa and Bagheri, Ali and Delen, Dursun},
  journal={Reliability Engineering \& System Safety},
  volume={226},
  pages={108720},
  year={2022},
  publisher={Elsevier}
}

@article{damen2022rescaling,
  title={Rescaling egocentric vision: collection, pipeline and challenges for epic-kitchens-100},
  author={Damen, Dima and Doughty, Hazel and Farinella, Giovanni Maria and Furnari, Antonino and Kazakos, Evangelos and Ma, Jian and Moltisanti, Davide and Munro, Jonathan and Perrett, Toby and Price, Will and others},
  journal={International Journal of Computer Vision},
  volume={130},
  number={1},
  pages={33--55},
  year={2022},
  publisher={Springer}
}

@inproceedings{bonanni2005attention,
  title={Attention-based design of augmented reality interfaces},
  author={Bonanni, Leonardo and Lee, Chia-Hsun and Selker, Ted},
  booktitle={CHI'05 extended abstracts on Human factors in computing systems},
  pages={1228--1231},
  year={2005}
}

@article{samadiani2019review,
  title={A review on automatic facial expression recognition systems assisted by multimodal sensor data},
  author={Samadiani, Najmeh and Huang, Guangyan and Cai, Borui and Luo, Wei and Chi, Chi-Hung and Xiang, Yong and He, Jing},
  journal={Sensors},
  volume={19},
  number={8},
  pages={1863},
  year={2019},
  publisher={MDPI}
}

@INPROCEEDINGS{lu_glanceable_2021,
  author={Lu, Feiyu},
  booktitle={2021 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)}, 
  title={Glanceable AR: Towards an Always-on Augmented Reality Future}, 
  year={2021},
  volume={},
  number={},
  pages={717-718},
  doi={10.1109/VRW52623.2021.00241}}
  
  
@inproceedings{feiner1993windows,
  title={Windows on the world: 2D windows for 3D augmented reality},
  author={Feiner, Steven and MacIntyre, Blair and Haupt, Marcus and Solomon, Eliot},
  booktitle={Proceedings of the 6th annual ACM symposium on User interface software and technology},
  pages={145--155},
  year={1993}
}

@inproceedings{reitmayr2001mobile,
  title={Mobile collaborative augmented reality},
  author={Reitmayr, Gerhard and Schmalstieg, Dieter},
  booktitle={Proceedings IEEE and ACM International Symposium on Augmented Reality},
  pages={114--123},
  year={2001},
  organization={IEEE}
}

@article{lee1992trust,
  title={Trust, control strategies and allocation of function in human-machine systems},
  author={Lee, John and Moray, Neville},
  journal={Ergonomics},
  volume={35},
  number={10},
  pages={1243--1270},
  year={1992},
  publisher={Taylor \& Francis}
}

@article{buchner2022impact,
  title={The impact of augmented reality on cognitive load and performance: A systematic review},
  author={Buchner, Josef and Buntins, Katja and Kerres, Michael},
  journal={Journal of Computer Assisted Learning},
  volume={38},
  number={1},
  pages={285--303},
  year={2022},
  publisher={Wiley Online Library}
}

@inproceedings{ribeiro2018anchors,
  title={Anchors: High-precision model-agnostic explanations},
  author={Ribeiro, Marco Tulio and Singh, Sameer and Guestrin, Carlos},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={32},
  number={1},
  year={2018}
}

@article{lombrozo2009explanation,
  title={Explanation and categorization: How “why?” informs “what?”},
  author={Lombrozo, Tania},
  journal={Cognition},
  volume={110},
  number={2},
  pages={248--253},
  year={2009},
  publisher={Elsevier}
}

@article{van2008visualizing,
  title={Visualizing data using t-SNE.},
  author={Van der Maaten, Laurens and Hinton, Geoffrey},
  journal={Journal of machine learning research},
  volume={9},
  number={11},
  year={2008}
}

@inproceedings{lakkaraju2016interpretable,
  title={Interpretable decision sets: A joint framework for description and prediction},
  author={Lakkaraju, Himabindu and Bach, Stephen H and Leskovec, Jure},
  booktitle={Proceedings of the 22nd ACM SIGKDD international conference on knowledge discovery and data mining},
  pages={1675--1684},
  year={2016}
}

@article{schoonderwoerd2021human,
  title={Human-centered XAI: Developing design patterns for explanations of clinical decision support systems},
  author={Schoonderwoerd, Tjeerd AJ and Jorritsma, Wiard and Neerincx, Mark A and Van Den Bosch, Karel},
  journal={International Journal of Human-Computer Studies},
  volume={154},
  pages={102684},
  year={2021},
  publisher={Elsevier}
}

@inproceedings{cai2019human,
  title={Human-centered tools for coping with imperfect algorithms during medical decision-making},
  author={Cai, Carrie J and Reif, Emily and Hegde, Narayan and Hipp, Jason and Kim, Been and Smilkov, Daniel and Wattenberg, Martin and Viegas, Fernanda and Corrado, Greg S and Stumpe, Martin C and others},
  booktitle={Proceedings of the 2019 chi conference on human factors in computing systems},
  pages={1--14},
  year={2019}
}

@inproceedings{keane2019case,
  title={How case-based reasoning explains neural networks: A theoretical analysis of XAI using post-hoc explanation-by-example from a survey of ANN-CBR twin-systems},
  author={Keane, Mark T and Kenny, Eoin M},
  booktitle={International Conference on Case-Based Reasoning},
  pages={155--171},
  year={2019},
  organization={Springer}
}

@inproceedings{cai2019effects,
  title={The effects of example-based explanations in a machine learning interface},
  author={Cai, Carrie J and Jongejan, Jonas and Holbrook, Jess},
  booktitle={Proceedings of the 24th international conference on intelligent user interfaces},
  pages={258--262},
  year={2019}
}

@book{molnar2020interpretable,
  title={Interpretable machine learning},
  author={Molnar, Christoph},
  year={2020},
  publisher={Lulu. com}
}

@inproceedings{lim2019these,
  title={Why these explanations? Selecting intelligibility types for explanation goals.},
  author={Lim, Brian Y and Yang, Qian and Abdul, Ashraf M and Wang, Danding},
  booktitle={IUI Workshops},
  year={2019}
}

@article{liao2021human,
  title={Human-centered explainable ai (xai): From algorithms to user experiences},
  author={Liao, Q Vera and Varshney, Kush R},
  journal={arXiv preprint arXiv:2110.10790},
  year={2021}
}

@misc{dalex,
 title={Model interpretability with DALEX}, url={http://uc-r.github.io/dalex},
 journal={Model Interpretability with DALEX · UC Business Analytics R Programming Guide},
 year={2022}} 
 
@misc{h2oai,title={H2O driverless AI}, url={https://h2o.ai/platform/ai-cloud/make/h2o-driverless-ai/},
journal={H2O Driverless AI | H2O.ai}, year={2022}} 

@article{baumeister2017cognitive,
  title={Cognitive cost of using augmented reality displays},
  author={Baumeister, James and Ssin, Seung Youb and ElSayed, Neven AM and Dorrian, Jillian and Webb, David P and Walsh, James A and Simon, Timothy M and Irlitti, Andrew and Smith, Ross T and Kohler, Mark and others},
  journal={IEEE transactions on visualization and computer graphics},
  volume={23},
  number={11},
  pages={2378--2388},
  year={2017},
  publisher={IEEE}
}

@article{schneider2019personalized,
  title={Personalized explanation in machine learning: A conceptualization},
  author={Schneider, Johanes and Handali, Joshua},
  journal={arXiv preprint arXiv:1901.00770},
  year={2019}
}

@inproceedings{kouki2019personalized,
  title={Personalized explanations for hybrid recommender systems},
  author={Kouki, Pigi and Schaffer, James and Pujara, Jay and O'Donovan, John and Getoor, Lise},
  booktitle={Proceedings of the 24th International Conference on Intelligent User Interfaces},
  pages={379--390},
  year={2019}
}

@inproceedings{frauenberger2007survey,
  title={A survey on common practice in designing audio in the user interface},
  author={Frauenberger, Christopher and Stockman, Tony and Bourguet, Marie-Luce},
  booktitle={Proceedings of HCI 2007 The 21st British HCI Group Annual Conference University of Lancaster, UK 21},
  pages={1--9},
  year={2007}
}

@article{frauenberger2009auditory,
  title={Auditory display design—an investigation of a design pattern approach},
  author={Frauenberger, Christopher and Stockman, Tony},
  journal={International Journal of Human-Computer Studies},
  volume={67},
  number={11},
  pages={907--922},
  year={2009},
  publisher={Elsevier}
}

@inproceedings{kern2009design,
  title={Design space for driver-based automotive user interfaces},
  author={Kern, Dagmar and Schmidt, Albrecht},
  booktitle={Proceedings of the 1st International Conference on Automotive User Interfaces and Interactive Vehicular Applications},
  pages={3--10},
  year={2009}
}

@article{simonyan2013deep,
  title={Deep inside convolutional networks: Visualising image classification models and saliency maps},
  author={Simonyan, Karen and Vedaldi, Andrea and Zisserman, Andrew},
  journal={arXiv preprint arXiv:1312.6034},
  year={2013}
}

@inproceedings{zeiler2014visualizing,
  title={Visualizing and understanding convolutional networks},
  author={Zeiler, Matthew D and Fergus, Rob},
  booktitle={European conference on computer vision},
  pages={818--833},
  year={2014},
  organization={Springer}
}

@inproceedings{myers2006answering,
  title={Answering why and why not questions in user interfaces},
  author={Myers, Brad A and Weitzman, David A and Ko, Amy J and Chau, Duen H},
  booktitle={Proceedings of the SIGCHI conference on Human Factors in computing systems},
  pages={397--406},
  year={2006}
}


@inproceedings{evangelista2021xrgonomics,
  title={Xrgonomics: Facilitating the creation of ergonomic 3d interfaces},
  author={Evangelista Belo, Jo{\~a}o Marcelo and Feit, Anna Maria and Feuchtner, Tiare and Gr{\o}nb{\ae}k, Kaj},
  booktitle={Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
  pages={1--11},
  year={2021}
}

@inproceedings{zagermann2018studying,
  title={Studying eye movements as a basis for measuring cognitive load},
  author={Zagermann, Johannes and Pfeil, Ulrike and Reiterer, Harald},
  booktitle={Extended Abstracts of the 2018 CHI conference on human factors in computing systems},
  pages={1--6},
  year={2018}
}

@article{joseph2020potential,
  title={Potential eye tracking metrics and indicators to measure cognitive load in human-computer interaction research},
  author={Joseph, Antony William and Murugesh, Ramaswamy},
  journal={J. Sci. Res},
  volume={64},
  number={1},
  pages={168--175},
  year={2020}
}

@incollection{gjoreski2021head,
  title={Head-ar: Human activity recognition with head-mounted imu using weighted ensemble learning},
  author={Gjoreski, Hristijan and Kiprijanovska, Ivana and Stankoski, Simon and Kalabakov, Stefan and Broulidakis, John and Nduka, Charles and Gjoreski, Martin},
  booktitle={Activity and Behavior Computing},
  pages={153--167},
  year={2021},
  publisher={Springer}
}

@inproceedings{windau2016walking,
  title={Walking compass with head-mounted IMU sensor},
  author={Windau, Jens and Itti, Laurent},
  booktitle={2016 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={5542--5547},
  year={2016},
  organization={IEEE}
}

@inproceedings{leelasawassuk2015estimating,
  title={Estimating visual attention from a head mounted IMU},
  author={Leelasawassuk, Teesid and Damen, Dima and Mayol-Cuevas, Walterio W},
  booktitle={Proceedings of the 2015 ACM International Symposium on Wearable Computers},
  pages={147--150},
  year={2015}
}

@article{antonenko2010using,
  title={Using electroencephalography to measure cognitive load},
  author={Antonenko, Pavlo and Paas, Fred and Grabner, Roland and Van Gog, Tamara},
  journal={Educational psychology review},
  volume={22},
  number={4},
  pages={425--438},
  year={2010},
  publisher={Springer}
}

@article{vortmann2019eeg,
  title={EEG-based classification of internally-and externally-directed attention in an augmented reality paradigm},
  author={Vortmann, Lisa-Marie and Kroll, Felix and Putze, Felix},
  journal={Frontiers in human neuroscience},
  volume={13},
  pages={348},
  year={2019},
  publisher={Frontiers Media SA}
}

@article{xu2018review,
  title={Review on portable EEG technology in educational research},
  author={Xu, Jiahui and Zhong, Baichang},
  journal={Computers in Human Behavior},
  volume={81},
  pages={340--349},
  year={2018},
  publisher={Elsevier}
}

@inproceedings{yan2022emoglass,
  title={EmoGlass: an End-to-End AI-Enabled Wearable Platform for Enhancing Self-Awareness of Emotional Health},
  author={Yan, Zihan and Wu, Yufei and Zhang, Yang and Chen, Xiang'Anthony'},
  booktitle={CHI Conference on Human Factors in Computing Systems},
  pages={1--19},
  year={2022}
}

@inproceedings{yong2019emotion,
  title={Emotion recognition in gamers wearing head-mounted display},
  author={Yong, Hwanmoo and Lee, Jisuk and Choi, Jongeun},
  booktitle={2019 IEEE Conference on Virtual Reality and 3D User Interfaces (VR)},
  pages={1251--1252},
  year={2019},
  organization={IEEE}
}

@article{wan2021wearable,
  title={A Wearable Head Mounted Display Bio-Signals Pad System for Emotion Recognition},
  author={Wan, Chunting and Chen, Dongyi and Huang, Zhiqi and Luo, Xi},
  journal={Sensors},
  volume={22},
  number={1},
  pages={142},
  year={2021},
  publisher={MDPI}
}

@article{soleymani2015analysis,
  title={Analysis of EEG signals and facial expressions for continuous emotion detection},
  author={Soleymani, Mohammad and Asghari-Esfeden, Sadjad and Fu, Yun and Pantic, Maja},
  journal={IEEE Transactions on Affective Computing},
  volume={7},
  number={1},
  pages={17--28},
  year={2015},
  publisher={IEEE}
}

@article{tsai2018augmented,
  title={Augmented reality display based on user behavior},
  author={Tsai, Chung-Hsien and Huang, Jiung-Yao},
  journal={Computer Standards \& Interfaces},
  volume={55},
  pages={171--181},
  year={2018},
  publisher={Elsevier}
}

@article{kim2016understanding,
  title={Understanding users’ continuance intention toward smartphone augmented reality applications},
  author={Kim, Keesung and Hwang, Jiyeon and Zo, Hangjung and Lee, Hwansoo},
  journal={Information development},
  volume={32},
  number={2},
  pages={161--174},
  year={2016},
  publisher={SAGE Publications Sage UK: London, England}
}

@inproceedings{park2018high,
  title={High-precision depth estimation with the 3d lidar and stereo fusion},
  author={Park, Kihong and Kim, Seungryong and Sohn, Kwanghoon},
  booktitle={2018 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={2156--2163},
  year={2018},
  organization={IEEE}
}


@article{dey_understanding_2001,
	title = {Understanding and {Using} {Context}},
	journal = {Proceedings of the 1st international symposium on Handheld and Ubiquitous Computing},
	author = {Dey, Anind K.},
	year = {2001},
	keywords = {context-awareness, application support, context, situation-awareness},
	pages = {304--307},
	file = {Dey_2001_Understanding and Using Context.pdf:/Users/orsonxu/Zotero/storage/LKW3IBPF/Dey_2001_Understanding and Using Context.pdf:application/pdf;Dey_2001_Understanding and Using Context.pdf:/Users/orsonxu/Zotero/storage/EASZ2FA4/Dey_2001_Understanding and Using Context.pdf:application/pdf},
}

@inproceedings{gotz2009behavior,
  title={Behavior-driven visualization recommendation},
  author={Gotz, David and Wen, Zhen},
  booktitle={Proceedings of the 14th international conference on Intelligent user interfaces},
  pages={315--324},
  year={2009}
}



@incollection{samek2019towards,
  title={Towards explainable artificial intelligence},
  author={Samek, Wojciech and M{\"u}ller, Klaus-Robert},
  booktitle={Explainable AI: interpreting, explaining and visualizing deep learning},
  pages={5--22},
  year={2019},
  publisher={Springer}
}

@inproceedings{brown1998utility,
  title={Utility theory-based user models for intelligent interface agents},
  author={Brown, Scott M and Santos, Eugene and Banks, Sheila B},
  booktitle={Conference of the Canadian Society for Computational Studies of Intelligence},
  pages={378--392},
  year={1998},
  organization={Springer}
}


@inproceedings{bercher2014plan,
  title={Plan, repair, execute, explain—how planning helps to assemble your home theater},
  author={Bercher, Pascal and Biundo, Susanne and Geier, Thomas and Hoernle, Thilo and Nothdurft, Florian and Richter, Felix and Schattenberg, Bernd},
  booktitle={Proceedings of the International Conference on Automated Planning and Scheduling},
  volume={24},
  pages={386--394},
  year={2014}
}

@inproceedings{das2021explainable,
  title={Explainable ai for robot failures: Generating explanations that improve user assistance in fault recovery},
  author={Das, Devleena and Banerjee, Siddhartha and Chernova, Sonia},
  booktitle={Proceedings of the 2021 ACM/IEEE International Conference on Human-Robot Interaction},
  pages={351--360},
  year={2021}
}

@inproceedings{brennen2020people,
  title={What Do People Really Want When They Say They Want" Explainable AI?" We Asked 60 Stakeholders.},
  author={Brennen, Andrea},
  booktitle={Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
  pages={1--7},
  year={2020}
}

@article{bertossi2020data,
  title={Data quality and explainable AI},
  author={Bertossi, Leopoldo and Geerts, Floris},
  journal={Journal of Data and Information Quality (JDIQ)},
  volume={12},
  number={2},
  pages={1--9},
  year={2020},
  publisher={ACM New York, NY, USA}
}

@inproceedings{antifakos2005towards,
  title={Towards improving trust in context-aware systems by displaying system confidence},
  author={Antifakos, Stavros and Kern, Nicky and Schiele, Bernt and Schwaninger, Adrian},
  booktitle={Proceedings of the 7th international conference on Human computer interaction with mobile devices \& services},
  pages={9--14},
  year={2005}
}

@inproceedings{zhang2020effect,
  title={Effect of confidence and explanation on accuracy and trust calibration in AI-assisted decision making},
  author={Zhang, Yunfeng and Liao, Q Vera and Bellamy, Rachel KE},
  booktitle={Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency},
  pages={295--305},
  year={2020}
}

@inproceedings{das2021explainable,
  title={Explainable ai for robot failures: Generating explanations that improve user assistance in fault recovery},
  author={Das, Devleena and Banerjee, Siddhartha and Chernova, Sonia},
  booktitle={Proceedings of the 2021 ACM/IEEE International Conference on Human-Robot Interaction},
  pages={351--360},
  year={2021}
}

@inproceedings{bunt2012explanations,
  title={Are explanations always important? A study of deployed, low-cost intelligent interactive systems},
  author={Bunt, Andrea and Lount, Matthew and Lauzon, Catherine},
  booktitle={Proceedings of the 2012 ACM international conference on Intelligent User Interfaces},
  pages={169--178},
  year={2012}
}

@article{shin2021effects,
  title={The effects of explainability and causability on perception, trust, and acceptance: Implications for explainable AI},
  author={Shin, Donghee},
  journal={International Journal of Human-Computer Studies},
  volume={146},
  pages={102551},
  year={2021},
  publisher={Elsevier}
}

@inproceedings{berkovsky2017recommend,
  title={How to recommend? User trust factors in movie recommender systems},
  author={Berkovsky, Shlomo and Taib, Ronnie and Conway, Dan},
  booktitle={Proceedings of the 22nd international conference on intelligent user interfaces},
  pages={287--300},
  year={2017}
}

@inproceedings{bussone2015role,
  title={The role of explanations on trust and reliance in clinical decision support systems},
  author={Bussone, Adrian and Stumpf, Simone and O'Sullivan, Dympna},
  booktitle={2015 international conference on healthcare informatics},
  pages={160--169},
  year={2015},
  organization={IEEE}
}

@inproceedings{ribera2019can,
  title={Can we do better explanations? A proposal of user-centered explainable AI.},
  author={Ribera, Mireia and Lapedriza, Agata},
  booktitle={IUI Workshops},
  volume={2327},
  pages={38},
  year={2019}
}

@article{rai2020explainable,
  title={Explainable AI: From black box to glass box},
  author={Rai, Arun},
  journal={Journal of the Academy of Marketing Science},
  volume={48},
  number={1},
  pages={137--141},
  year={2020},
  publisher={Springer}
}


@inproceedings{gervasio2018explanation,
  title={Explanation to Avert Surprise.},
  author={Gervasio, Melinda T and Myers, Karen L and Yeh, Eric and Adkins, Boone},
  booktitle={IUI Workshops},
  volume={2068},
  year={2018}
}

@article{manheim2019artificial,
  title={Artificial intelligence: Risks to privacy and democracy},
  author={Manheim, Karl and Kaplan, Lyric},
  journal={Yale JL \& Tech.},
  volume={21},
  pages={106},
  year={2019},
  publisher={HeinOnline}
}

@article{datta2014automated,
  title={Automated experiments on ad privacy settings: A tale of opacity, choice, and discrimination},
  author={Datta, Amit and Tschantz, Michael Carl and Datta, Anupam},
  journal={arXiv preprint arXiv:1408.6491},
  year={2014}
}


@inproceedings{rader2018explanations,
  title={Explanations as mechanisms for supporting algorithmic transparency},
  author={Rader, Emilee and Cotter, Kelley and Cho, Janghee},
  booktitle={Proceedings of the 2018 CHI conference on human factors in computing systems},
  pages={1--13},
  year={2018}
}

@inproceedings{eslami2015always,
  title={" I always assumed that I wasn't really that close to [her]" Reasoning about Invisible Algorithms in News Feeds},
  author={Eslami, Motahhare and Rickman, Aimee and Vaccaro, Kristen and Aleyasen, Amirhossein and Vuong, Andy and Karahalios, Karrie and Hamilton, Kevin and Sandvig, Christian},
  booktitle={Proceedings of the 33rd annual ACM conference on human factors in computing systems},
  pages={153--162},
  year={2015}
}

@article{li2020survey,
  title={A survey of data-driven and knowledge-aware explainable ai},
  author={Li, Xiao-Hui and Cao, Caleb Chen and Shi, Yuhan and Bai, Wei and Gao, Han and Qiu, Luyu and Wang, Cong and Gao, Yuanyuan and Zhang, Shenjia and Xue, Xun and others},
  journal={IEEE Transactions on Knowledge and Data Engineering},
  volume={34},
  number={1},
  pages={29--49},
  year={2020},
  publisher={IEEE}
}

@inproceedings{lage2019human,
  title={Human evaluation of models built for interpretability},
  author={Lage, Isaac and Chen, Emily and He, Jeffrey and Narayanan, Menaka and Kim, Been and Gershman, Samuel J and Doshi-Velez, Finale},
  booktitle={Proceedings of the AAAI Conference on Human Computation and Crowdsourcing},
  volume={7},
  pages={59--67},
  year={2019}
}

@inproceedings{binns2018s,
  title={'It's Reducing a Human Being to a Percentage' Perceptions of Justice in Algorithmic Decisions},
  author={Binns, Reuben and Van Kleek, Max and Veale, Michael and Lyngs, Ulrik and Zhao, Jun and Shadbolt, Nigel},
  booktitle={Proceedings of the 2018 Chi conference on human factors in computing systems},
  pages={1--14},
  year={2018}
}

@inproceedings{krause2016interacting,
  title={Interacting with predictions: Visual inspection of black-box machine learning models},
  author={Krause, Josua and Perer, Adam and Ng, Kenney},
  booktitle={Proceedings of the 2016 CHI conference on human factors in computing systems},
  pages={5686--5697},
  year={2016}
}

@article{gedikli2014should,
  title={How should I explain? A comparison of different explanation types for recommender systems},
  author={Gedikli, Fatih and Jannach, Dietmar and Ge, Mouzhi},
  journal={International Journal of Human-Computer Studies},
  volume={72},
  number={4},
  pages={367--382},
  year={2014},
  publisher={Elsevier}
}


@misc{ttc_labs,
 title={People-centric approaches to algorithmic explainability}, url={https://www.ttclabs.net/report/people-centric-approaches-to-algorithmic-explainability},
 journal={TTC Labs},
 author={TTC Labs},
 year={2022},
} 
 
@article{liu2017analyzing,
  title={Analyzing the training processes of deep generative models},
  author={Liu, Mengchen and Shi, Jiaxin and Cao, Kelei and Zhu, Jun and Liu, Shixia},
  journal={IEEE transactions on visualization and computer graphics},
  volume={24},
  number={1},
  pages={77--87},
  year={2017},
  publisher={IEEE}
}

@article{strobelt2017lstmvis,
  title={Lstmvis: A tool for visual analysis of hidden state dynamics in recurrent neural networks},
  author={Strobelt, Hendrik and Gehrmann, Sebastian and Pfister, Hanspeter and Rush, Alexander M},
  journal={IEEE transactions on visualization and computer graphics},
  volume={24},
  number={1},
  pages={667--676},
  year={2017},
  publisher={IEEE}
}

@inproceedings{ribeiro2018anchors,
  title={Anchors: High-precision model-agnostic explanations},
  author={Ribeiro, Marco Tulio and Singh, Sameer and Guestrin, Carlos},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={32},
  number={1},
  year={2018}
}


@inproceedings{danry2020wearable,
  title={Wearable Reasoner: towards enhanced human rationality through a wearable device with an explainable AI assistant},
  author={Danry, Valdemar and Pataranutaporn, Pat and Mao, Yaoli and Maes, Pattie},
  booktitle={Proceedings of the Augmented Humans International Conference},
  pages={1--12},
  year={2020}
}

@article{ahmed2022artificial,
  title={From artificial intelligence to explainable artificial intelligence in industry 4.0: a survey on what, how, and where},
  author={Ahmed, Imran and Jeon, Gwanggil and Piccialli, Francesco},
  journal={IEEE Transactions on Industrial Informatics},
  volume={18},
  number={8},
  pages={5031--5042},
  year={2022},
  publisher={IEEE}
}

@article{zimmermann2022enhancing,
  title={Enhancing brick-and-mortar store shopping experience with an augmented reality shopping assistant application using personalized recommendations and explainable artificial intelligence},
  author={Zimmermann, Robert and Mora, Daniel and Cirqueira, Douglas and Helfert, Markus and Bezbradica, Marija and Werth, Dirk and Weitzl, Wolfgang Jonas and Riedl, Ren{\'e} and Auinger, Andreas},
  journal={Journal of Research in Interactive Marketing},
  year={2022},
  publisher={Emerald Publishing Limited}
}

@inproceedings{xie2020chexplain,
  title={CheXplain: enabling physicians to explore and understand data-driven, AI-enabled medical imaging analysis},
  author={Xie, Yao and Chen, Melody and Kao, David and Gao, Ge and Chen, Xiang'Anthony'},
  booktitle={Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
  pages={1--13},
  year={2020}
}

@inproceedings{ehsan2021expanding,
  title={Expanding explainability: Towards social transparency in ai systems},
  author={Ehsan, Upol and Liao, Q Vera and Muller, Michael and Riedl, Mark O and Weisz, Justin D},
  booktitle={Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
  pages={1--19},
  year={2021}
}

@inproceedings{ehsan2019automated,
  title={Automated rationale generation: a technique for explainable AI and its effects on human perceptions},
  author={Ehsan, Upol and Tambwekar, Pradyumna and Chan, Larry and Harrison, Brent and Riedl, Mark O},
  booktitle={Proceedings of the 24th International Conference on Intelligent User Interfaces},
  pages={263--274},
  year={2019}
}

@article{ehsan2021explainable,
  title={The who in explainable ai: How ai background shapes perceptions of ai explanations},
  author={Ehsan, Upol and Passi, Samir and Liao, Q Vera and Chan, Larry and Lee, I and Muller, Michael and Riedl, Mark O and others},
  journal={arXiv preprint arXiv:2107.13509},
  year={2021}
}

@article{wintersberger2018fostering,
  title={Fostering user acceptance and trust in fully automated vehicles: Evaluating the potential of augmented reality},
  author={Wintersberger, Philipp and Frison, Anna-Katharina and Riener, Andreas and Sawitzky, Tamara von},
  journal={PRESENCE: Virtual and Augmented Reality},
  volume={27},
  number={1},
  pages={46--62},
  year={2018},
  publisher={MIT Press One Rogers Street, Cambridge, MA 02142-1209, USA journals-info~…}
}

@inproceedings{chatzopoulos2016readme,
  title={Readme: A real-time recommendation system for mobile augmented reality ecosystems},
  author={Chatzopoulos, Dimitris and Hui, Pan},
  booktitle={Proceedings of the 24th ACM international conference on Multimedia},
  pages={312--316},
  year={2016}
}

@misc{spotify_blend_taste,
title={How Spotify's newest personalized experience, blend, creates a playlist for you and your bestie}, url={https://newsroom.spotify.com/2021-08-31/how-spotifys-newest-personalized-experience-blend-creates-a-playlist-for-you-and-your-bestie/},
journal={Spotify}, author={Spotify}, year={2022}, month={Jul}} 

@article{liu2021ai,
  title={In AI we trust? Effects of agency locus and transparency on uncertainty reduction in human--AI interaction},
  author={Liu, Bingjie},
  journal={Journal of Computer-Mediated Communication},
  volume={26},
  number={6},
  pages={384--402},
  year={2021},
  publisher={Oxford University Press}
}

@article{ibili2019effect,
  title={Effect of Augmented Reality Environments on Cognitive Load: Pedagogical Effect, Instructional Design, Motivation and Interaction Interfaces.},
  author={{\.I}bili, Emin},
  journal={International Journal of Progressive Education},
  volume={15},
  number={5},
  pages={42--57},
  year={2019},
  publisher={ERIC}
}

@article{arguel2017inside,
  title={Inside out: detecting learners’ confusion to improve interactive digital learning environments},
  author={Arguel, Ama{\"e}l and Lockyer, Lori and Lipp, Ottmar V and Lodge, Jason M and Kennedy, Gregor},
  journal={Journal of Educational Computing Research},
  volume={55},
  number={4},
  pages={526--551},
  year={2017},
  publisher={Sage Publications Sage CA: Los Angeles, CA}
}

@article{umemuro2003detection,
  title={Detection of user's confusion and surprise based on pupil dilation},
  author={Umemuro, Hiroyuki and Yamashita, Jun},
  journal={The Japanese Journal of Ergonomics},
  volume={39},
  number={4},
  pages={153--161},
  year={2003},
  publisher={Japan Ergonomics Society}
}

@inproceedings{abrash2021creating,
  title={Creating the future: augmented reality, the next human-machine interface},
  author={Abrash, Michael},
  booktitle={2021 IEEE International Electron Devices Meeting (IEDM)},
  pages={1--2},
  year={2021},
  organization={IEEE}
}


@inproceedings{li2020artificial,
  title={Artificial intelligence for HCI: a modern approach},
  author={Li, Yang and Kumar, Ranjitha and Lasecki, Walter S and Hilliges, Otmar},
  booktitle={Extended Abstracts of the 2020 CHI conference on human factors in computing systems},
  pages={1--8},
  year={2020}
}

@article{riedl2019human,
  title={Human-centered artificial intelligence and machine learning},
  author={Riedl, Mark O},
  journal={Human Behavior and Emerging Technologies},
  volume={1},
  number={1},
  pages={33--36},
  year={2019},
  publisher={Wiley Online Library}
}

@inproceedings{bhatt2020explainable,
  title={Explainable machine learning in deployment},
  author={Bhatt, Umang and Xiang, Alice and Sharma, Shubham and Weller, Adrian and Taly, Ankur and Jia, Yunhan and Ghosh, Joydeep and Puri, Ruchir and Moura, Jos{\'e} MF and Eckersley, Peter},
  booktitle={Proceedings of the 2020 conference on fairness, accountability, and transparency},
  pages={648--657},
  year={2020}
}

@article{cherry2014quantifying,
  title={Quantifying the creativity support of digital tools through the creativity support index},
  author={Cherry, Erin and Latulipe, Celine},
  journal={ACM Transactions on Computer-Human Interaction (TOCHI)},
  volume={21},
  number={4},
  pages={1--25},
  year={2014},
  publisher={ACM New York, NY, USA}
}


@article{bangor2008empirical,
  title={An empirical evaluation of the system usability scale},
  author={Bangor, Aaron and Kortum, Philip T and Miller, James T},
  journal={Intl. Journal of Human--Computer Interaction},
  volume={24},
  number={6},
  pages={574--594},
  year={2008},
  publisher={Taylor \& Francis}
}

@inproceedings{gupta2019lvis,
  title={Lvis: A dataset for large vocabulary instance segmentation},
  author={Gupta, Agrim and Dollar, Piotr and Girshick, Ross},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={5356--5364},
  year={2019}
}

@inproceedings{shao2019objects365,
  title={Objects365: A large-scale, high-quality dataset for object detection},
  author={Shao, Shuai and Li, Zeming and Zhang, Tianyuan and Peng, Chao and Yu, Gang and Zhang, Xiangyu and Li, Jing and Sun, Jian},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={8430--8439},
  year={2019}
}

@inproceedings{radford2021learning,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle={International Conference on Machine Learning},
  pages={8748--8763},
  year={2021},
  organization={PMLR}
}

@article{zhou2022detecting,
  title={Detecting twenty-thousand classes using image-level supervision},
  author={Zhou, Xingyi and Girdhar, Rohit and Joulin, Armand and Kr{\"a}henb{\"u}hl, Phillip and Misra, Ishan},
  journal={arXiv preprint arXiv:2201.02605},
  year={2022}
}

@inproceedings{he2017mask,
  title={Mask r-cnn},
  author={He, Kaiming and Gkioxari, Georgia and Doll{\'a}r, Piotr and Girshick, Ross},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={2961--2969},
  year={2017}
}

@misc{spoonacular,
title={Free meal planner, food tracker, and Recipe Saver}, 
url={https://spoonacular.com/}, journal={spoonacular}, year={2022}} 

@inproceedings{gilpin2018explaining,
  title={Explaining explanations: An overview of interpretability of machine learning},
  author={Gilpin, Leilani H and Bau, David and Yuan, Ben Z and Bajwa, Ayesha and Specter, Michael and Kagal, Lalana},
  booktitle={2018 IEEE 5th International Conference on data science and advanced analytics (DSAA)},
  pages={80--89},
  year={2018},
  organization={IEEE}
}

@inproceedings{mittelstadt2019explaining,
  title={Explaining explanations in AI},
  author={Mittelstadt, Brent and Russell, Chris and Wachter, Sandra},
  booktitle={Proceedings of the conference on fairness, accountability, and transparency},
  pages={279--288},
  year={2019}
}

@article{chen2020review,
  title={A review: Knowledge reasoning over knowledge graph},
  author={Chen, Xiaojun and Jia, Shengbin and Xiang, Yang},
  journal={Expert Systems with Applications},
  volume={141},
  pages={112948},
  year={2020},
  publisher={Elsevier}
}

@article{pielot2017beyond,
  title={Beyond interruptibility: Predicting opportune moments to engage mobile phone users},
  author={Pielot, Martin and Cardoso, Bruno and Katevas, Kleomenis and Serr{\`a}, Joan and Matic, Aleksandar and Oliver, Nuria},
  journal={Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies},
  volume={1},
  number={3},
  pages={1--25},
  year={2017},
  publisher={ACM New York, NY, USA}
}

@article{fogarty2005predicting,
  title={Predicting human interruptibility with sensors},
  author={Fogarty, James and Hudson, Scott E and Atkeson, Christopher G and Avrahami, Daniel and Forlizzi, Jodi and Kiesler, Sara and Lee, Johnny C and Yang, Jie},
  journal={ACM Transactions on Computer-Human Interaction (TOCHI)},
  volume={12},
  number={1},
  pages={119--146},
  year={2005},
  publisher={ACM New York, NY, USA}
}

@book{braun2012thematic,
  title={Thematic analysis.},
  author={Braun, Virginia and Clarke, Victoria},
  year={2012},
  publisher={American Psychological Association}
}

@inproceedings{luo2022should,
  title={Where Should We Put It? Layout and Placement Strategies of Documents in Augmented Reality for Collaborative Sensemaking},
  author={Luo, Weizhou and Lehmann, Anke and Widengren, Hjalmar and Dachselt, Raimund},
  booktitle={CHI Conference on Human Factors in Computing Systems},
  pages={1--16},
  year={2022}
}

@inproceedings{muller2016taxonomy,
  title={A taxonomy for information linking in augmented reality},
  author={M{\"u}ller, Tobias and Dauenhauer, Ralf},
  booktitle={International Conference on Augmented Reality, Virtual Reality and Computer Graphics},
  pages={368--387},
  year={2016},
  organization={Springer}
}

@inproceedings{rzayev2020effects,
  title={Effects of position and alignment of notifications on AR glasses during social interaction},
  author={Rzayev, Rufat and Korbely, Susanne and Maul, Milena and Schark, Alina and Schwind, Valentin and Henze, Niels},
  booktitle={Proceedings of the 11th Nordic Conference on Human-Computer Interaction: Shaping Experiences, Shaping Society},
  pages={1--11},
  year={2020}
}

@inproceedings{yeh2022guide,
  title={How to Guide Task-oriented Chatbot Users, and When: A Mixed-methods Study of Combinations of Chatbot Guidance Types and Timings},
  author={Yeh, Su-Fang and Wu, Meng-Hsin and Chen, Tze-Yu and Lin, Yen-Chun and Chang, XiJing and Chiang, You-Hsuan and Chang, Yung-Ju},
  booktitle={CHI Conference on Human Factors in Computing Systems},
  pages={1--16},
  year={2022}
}

@article{yang_cross-domain_2007,
	title = {Cross-domain video concept detection using adaptive svms},
	doi = {10.1145/1291233.1291276},
	abstract = {Many multimedia applications can benefit from techniques for adapting existing classifiers to data with different distributions. One example is cross-domain video concept detection which aims to adapt concept classifiers across various video domains. In this paper, we explore two key problems for classifier adaptation: (1) how to transform existing classifier(s) into an effective classifier for a new dataset that only has a limited number of labeled examples, and (2) how to select the best existing classifier(s) for adaptation. For the first problem, we propose Adaptive Support Vector Machines (A-SVMs) as a general method to adapt one or more existing classifiers of any type to the new dataset. It aims to learn the "delta function" between the original and adapted classifier using an objective function similar to SVMs. For the second problem, we estimate the performance of each existing classifier on the sparsely-labeled new dataset by analyzing its score distribution and other meta features, and select the classifiers with the best estimated performance. The proposed method outperforms several baseline and competing methods in terms of classification accuracy and efficiency in cross-domain concept detection in the TRECVID corpus. Copyright 2007 ACM.},
	journal = {Proceedings of the ACM International Multimedia Conference and Exhibition},
	author = {Yang, Jun and Yan, Rong and Hauptmann, Alexander G.},
	year = {2007},
	note = {ISBN: 9781595937025},
	keywords = {Adaptive SVMs, Classifier adaptation, Cross-domain video concept detection},
	pages = {188--197},
	file = {Yang et al_2007_Cross-domain video concept detection using adaptive svms.pdf:/Users/orsonxu/Desktop/HCI/Literature Management/Zotero/Yang et al_2007_Cross-domain video concept detection using adaptive svms.pdf:application/pdf},
}


@article{gao_knowledge_2008,
	title = {Knowledge transfer via multiple model local structure mapping},
	doi = {10.1145/1401890.1401928},
	abstract = {The effectiveness of knowledge transfer using classification algorithms depends on the difference between the distribution that generates the training examples and the one from which test examples are to be drawn. The task can be especially difficult when the training examples are from one or several domains different from the test domain. In this paper, we propose a locally weighted ensemble framework to combine multiple models for transfer learning, where the weights are dynamically assigned according to a model's predictive power on each test example. It can integrate the advantages of various learning algorithms and the labeled information from multiple training domains into one unified classification model, which can then be applied on a different domain. Importantly, different from many previously proposed methods, none of the base learning method is required to be specifically designed for transfer learning. We show the optimality of a locally weighted ensemble framework as a general approach to combine multiple models for domain transfer. We then propose an implementation of the local weight assignments by mapping the structures of a model onto the structures of the test domain, and then weighting each model locally according to its consistency with the neighborhood structure around the test example. Experimental results on text classification, spam filtering and intrusion detection data sets demonstrate significant improvements in classification accuracy gained by the framework. On a transfer learning task of newsgroup message categorization, the proposed locally weighted ensemble framework achieves 97\% accuracy when the best single model predicts correctly only on 73\% of the test examples. In summary, the improvement in accuracy is over 10\% and up to 30\% across different problems. Copyright 2008 ACM.},
	journal = {Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
	author = {Gao, Jing and Fan, Wei and Jiang, Jing and Han, Jiawei},
	year = {2008},
	note = {ISBN: 9781605581934},
	keywords = {Algorithms},
	pages = {283--291},
	file = {Gao et al_2008_Knowledge transfer via multiple model local structure mapping.pdf:/Users/orsonxu/Desktop/HCI/Literature Management/Zotero/Gao et al_2008_Knowledge transfer via multiple model local structure mapping.pdf:application/pdf},
}

@article{dai_boosting_2007,
	title = {Boosting for transfer learning},
	volume = {227},
	doi = {10.1145/1273496.1273521},
	abstract = {Traditional machine learning makes a basic assumption: the training and test data should be under the same distribution. However, in many cases, this identical-distribution assumption does not hold. The assumption might be violated when a task from one new domain comes, while there are only labeled data from a similar old domain. Labeling the new data can be costly and it would also be a waste to throw away all the old data. In this paper, we present a novel transfer learning framework called TrAdaBoost, which extends boosting-based learning algorithms (Freund \& Schapire, 1997). TrAdaBoost allows users to utilize a small amount of newly labeled data to leverage the old data to construct a high-quality classification model for the new data. We show that this method can allow us to learn an accurate model using only a tiny amount of new data and a large amount of old data, even when the new data are not sufficient to train a model alone. We show that TrAdaBoost allows knowledge to be effectively transferred from the old data to the new. The effectiveness of our algorithm is analyzed theoretically and empirically to show that our iterative algorithm can converge well to an accurate model.},
	journal = {ACM International Conference Proceeding Series},
	author = {Dai, Wenyuan and Yang, Qiang and Xue, Gui Rong and Yu, Yong},
	year = {2007},
	pages = {193--200},
	file = {Dai et al_2007_Boosting for transfer learning.pdf:/Users/orsonxu/Desktop/HCI/Literature Management/Zotero/Dai et al_2007_Boosting for transfer learning.pdf:application/pdf},
}

@article{cai_generalizability_2020,
	title = {Generalizability of machine learning for classification of schizophrenia based on resting-state functional {MRI} data},
	volume = {41},
	issn = {10970193},
	doi = {10.1002/hbm.24797},
	abstract = {Machine learning has increasingly been applied to classification of schizophrenia in neuroimaging research. However, direct replication studies and studies seeking to investigate generalizability are scarce. To address these issues, we assessed within-site and between-site generalizability of a machine learning classification framework which achieved excellent performance in a previous study using two independent resting-state functional magnetic resonance imaging data sets collected from different sites and scanners. We established within-site generalizability of the classification framework in the main data set using cross-validation. Then, we trained a model in the main data set and investigated between-site generalization in the validated data set using external validation. Finally, recognizing the poor between-site generalization performance, we updated the unsupervised algorithm to investigate if transfer learning using additional unlabeled data were able to improve between-site classification performance. Cross-validation showed that the published classification procedure achieved an accuracy of 0.73 using majority voting across all selected components. External validation found a classification accuracy of 0.55 (not significant) and 0.70 (significant) using the direct and transfer learning procedures, respectively. The failure of direct generalization from one site to another demonstrates the limitation of within-site cross-validation and points toward the need to incorporate efforts to facilitate application of machine learning across multiple data sets. The improvement in performance with transfer learning highlights the importance of taking into account the properties of data when constructing predictive models across samples and sites. Our findings suggest that machine learning classification result based on a single study should be interpreted cautiously.},
	number = {1},
	journal = {Human Brain Mapping},
	author = {Cai, Xin Lu and Xie, Dong Jie and Madsen, Kristoffer H. and Wang, Yong Ming and Bögemann, Sophie Alida and Cheung, Eric F.C. and Møller, Arne and Chan, Raymond C.K.},
	year = {2020},
	keywords = {machine learning, generalizability, reproducibility, schizophrenia spectrum disorders},
	pages = {172--184},
	file = {Cai et al_2020_Generalizability of machine learning for classification of schizophrenia based on resting-state functional MRI data.pdf:/Users/orsonxu/Desktop/HCI/Literature Management/Zotero/Cai et al_2020_Generalizability of machine learning for classification of schizophrenia based on resting-state functional MRI data.pdf:application/pdf},
}

@article{wu_negations_2014,
	title = {Negation's not solved: {Generalizability} versus optimizability in clinical natural language processing},
	volume = {9},
	issn = {19326203},
	doi = {10.1371/journal.pone.0112774},
	abstract = {A review of published work in clinical natural language processing (NLP) may suggest that the negation detection task has been ''solved.'' This work proposes that an optimizable solution does not equal a generalizable solution. We introduce a new machine learning-based Polarity Module for detecting negation in clinical text, and extensively compare its performance across domains. Using four manually annotated corpora of clinical text, we show that negation detection performance suffers when there is no in-domain development (for manual methods) or training data (for machine learning-based methods). Various factors (e.g., annotation guidelines, named entity characteristics, the amount of data, and lexical and syntactic context) play a role in making generalizability difficult, but none completely explains the phenomenon. Furthermore, generalizability remains challenging because it is unclear whether to use a single source for accurate data, combine all sources into a single model, or apply domain adaptation methods. The most reliable means to improve negation detection is to manually annotate in-domain training data (or, perhaps, manually modify rules); this is a strategy for optimizing performance, rather than generalizing it. These results suggest a direction for future work in domain-adaptive and task-adaptive methods for clinical NLP. Copyright:},
	number = {11},
	journal = {PLoS ONE},
	author = {Wu, Stephen and Miller, Timothy and Masanz, James and Coarr, Matt and Halgrim, Scott and Carrell, David and Clark, Cheryl},
	year = {2014},
	file = {Wu et al_2014_Negation's not solved.pdf:/Users/orsonxu/Desktop/HCI/Literature Management/Zotero/Wu et al_2014_Negation's not solved.pdf:application/pdf},
}

@article{wah_generalization_1999,
	title = {Generalization and generalizability measures},
	volume = {11},
	issn = {10414347},
	doi = {10.1109/69.755626},
	abstract = {In this paper, we define the generalization problem, summarize various approaches in generalization, identify the credit assignment problem, and present the problem and some solutions in measuring generalizability. We discuss anomalies in the ordering of hypotheses in a subdomain when performance is normalized and averaged, and show conditions under which anomalies can be eliminated. To generalize performance across subdomains, we present a measure called probability of win that measures the probability whether one hypothesis is better than another. Finally, we discuss some limitations in using probabilities of win and illustrate their application in finding new parameter values for TimberWolf, a package for VLSI cell placement and routing.},
	number = {1},
	journal = {IEEE Transactions on Knowledge and Data Engineering},
	author = {Wah, Benjamin W.},
	year = {1999},
	pages = {175--186},
	file = {Wah_1999_Generalization and generalizability measures.pdf:/Users/orsonxu/Desktop/HCI/Literature Management/Zotero/Wah_1999_Generalization and generalizability measures.pdf:application/pdf},
}

@article{daume_frustratingly_2007,
	title = {Frustratingly easy domain adaptation},
	abstract = {We describe an approach to domain adaptation that is appropriate exactly in the case when one has enough "target" data to do slightly better than just using only "source" data. Our approach is incredibly simple, easy to implement as a preprocessing step (10 lines of Perl!) and outperforms stateof- the-art approaches on a range of datasets. Moreover, it is trivially extended to a multidomain adaptation problem, where one has data from a variety of different domains. © 2007 Association for Computational Linguistics.},
	journal = {ACL 2007 - Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics},
	author = {Daumé, Hal},
	year = {2007},
	note = {ISBN: 9781932432862},
	pages = {256--263},
	file = {Daumé_2007_Frustratingly easy domain adaptation.pdf:/Users/orsonxu/Desktop/HCI/Literature Management/Zotero/Daumé_2007_Frustratingly easy domain adaptation.pdf:application/pdf},
}

@article{qin_cross-dataset_2019,
	title = {Cross-{Dataset} {Activity} {Recognition} via {Adaptive} {Spatial}-{Temporal} {Transfer} {Learning}},
	volume = {3},
	issn = {2474-9567},
	url = {https://dl.acm.org/doi/10.1145/3369818},
	doi = {10.1145/3369818},
	abstract = {Human activity recognition (HAR) aims at recognizing activities by training models on the large quantity of sensor data. Since it is time-consuming and expensive to acquire abundant labeled data, transfer learning becomes necessary for HAR by transferring knowledge from existing domains. However, there are two challenges existing in cross-dataset activity recognition. The first challenge is source domain selection. Given a target task and several available source domains, it is difficult to determine how to select the most similar source domain to the target domain such that negative transfer can be avoided. The second one is accurately activity transfer. After source domain selection, how to achieve accurate knowledge transfer between the selected source and the target domain remains another challenge. In this paper, we propose an Adaptive Spatial-Temporal Transfer Learning (ASTTL) approach to tackle both of the above two challenges in cross-dataset HAR. ASTTL learns the spatial features in transfer learning by adaptively evaluating the relative importance between the marginal and conditional probability distributions. Besides, it captures the temporal features via incremental manifold learning. Therefore, ASTTL can learn the adaptive spatial-temporal features for cross-dataset HAR and can be used for both source domain selection and accurate activity transfer. We evaluate the performance of ASTTL through extensive experiments on 4 public HAR datasets, which demonstrates its effectiveness. Furthermore, based on ASTTL, we design and implement an adaptive cross-dataset HAR system called Client-Cloud Collaborative Adaptive Activity Recognition System (3C2ARS) to perform HAR in the real environment. By collecting activities in the smartphone and transferring knowledge in the cloud server, ASTTL can significantly improve the performance of source domain selection and accurate activity transfer.},
	number = {4},
	journal = {Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies},
	author = {Qin, Xin and Chen, Yiqiang and Wang, Jindong and Yu, Chaohui},
	month = dec,
	year = {2019},
	keywords = {Transfer learning, Human activity recognition, Cross-dataset recognition, Domain adaptation},
	pages = {1--25},
	file = {Qin et al_2019_Cross-Dataset Activity Recognition via Adaptive Spatial-Temporal Transfer Learning.pdf:/Users/orsonxu/Desktop/HCI/Literature Management/Zotero/Qin et al_2019_Cross-Dataset Activity Recognition via Adaptive Spatial-Temporal Transfer Learning.pdf:application/pdf},
}

@article{thambawita_extensive_2020,
	title = {An {Extensive} {Study} on {Cross}-{Dataset} {Bias} and {Evaluation} {Metrics} {Interpretation} for {Machine} {Learning} {Applied} to {Gastrointestinal} {Tract} {Abnormality} {Classification}},
	volume = {1},
	issn = {2691-1957},
	url = {https://dl.acm.org/doi/10.1145/3386295},
	doi = {10.1145/3386295},
	abstract = {Precise and efficient automated identification of Gastrointestinal (GI) tract diseases can help doctors treat more patients and improve the rate of disease detection and identification. Currently, automatic analysis of diseases in the GI tract is a hot topic in both computer science and medical-related journals. Nevertheless, the evaluation of such an automatic analysis is often incomplete or simply wrong. Algorithms are often only tested on small and biased datasets, and cross-dataset evaluations are rarely performed. A clear understanding of evaluation metrics and machine learning models with cross datasets is crucial to bring research in the field to a new quality level. Towards this goal, we present comprehensive evaluations of five distinct machine learning models using Global Features and Deep Neural Networks that can classify 16 different key types of GI tract conditions, including pathological findings, anatomical landmarks, polyp removal conditions, and normal findings from images captured by common GI tract examination instruments. In our evaluation, we introduce performance hexagons using six performance metrics such as recall, precision, specificity, accuracy, F1-score, and Matthews Correlation Coefficient to demonstrate how to determine the real capabilities of models rather than evaluating them shallowly. Furthermore, we perform cross-dataset evaluations using different datasets for training and testing. With these cross-dataset evaluations, we demonstrate the challenge of actually building a generalizable model that could be used across different hospitals. Our experiments clearly show that more sophisticated performance metrics and evaluation methods need to be applied to get reliable models rather than depending on evaluations of the splits of the same dataset, i.e., the performance metrics should always be interpreted together rather than relying on a single metric.},
	number = {3},
	journal = {ACM Transactions on Computing for Healthcare},
	author = {Thambawita, Vajira and Jha, Debesh and Hammer, Hugo Lewi and Johansen, Håvard D. and Johansen, Dag and Halvorsen, Pål and Riegler, Michael A.},
	month = jul,
	year = {2020},
	keywords = {Deep Learning, Computer Aided Diagnosis, Cross-dataset evaluations, CVC-12K, CVC-356, CVC-612, Gastrointestinal Tract Diseases, Global Features, Kvasir, Medical, Multi-class classification, Nerthus, Polyp classification},
	pages = {1--29},
	file = {Thambawita et al_2020_An Extensive Study on Cross-Dataset Bias and Evaluation Metrics Interpretation for Machine Learning Applied to Gastrointestinal Tract Abnormality Classification.pdf:/Users/orsonxu/Desktop/HCI/Literature Management/Zotero/Thambawita et al_2020_An Extensive Study on Cross-Dataset Bias and Evaluation Metrics Interpretation for Machine Learning Applied to Gastrointestinal Tract Abnormality Classification.pdf:application/pdf},
}

@incollection{tommasi_testbed_2015,
	title = {A {Testbed} for {Cross}-{Dataset} {Analysis}},
	volume = {8927},
	isbn = {978-3-319-16198-3},
	url = {http://link.springer.com/10.1007/978-3-319-16199-0_2},
	abstract = {Despite the increasing interest towards domain adaptation and transfer learning techniques to generalize over image collections and overcome their biases, the visual community misses a large scale testbed for cross-dataset analysis. In this paper we discuss the challenges faced when aligning twelve existing image databases in a unique corpus, and we propose two cross-dataset setups that introduce new interesting research questions. Moreover, we report on a first set of experimental domain adaptation tests showing the effectiveness of iterative self-labeling for large scale problems.},
	booktitle = {Lecture {Notes} in {Computer} {Science} (including subseries {Lecture} {Notes} in {Artificial} {Intelligence} and {Lecture} {Notes} in {Bioinformatics})},
	author = {Tommasi, Tatiana and Tuytelaars, Tinne},
	year = {2015},
	doi = {10.1007/978-3-319-16199-0_2},
	note = {ISSN: 16113349},
	keywords = {Domain adaptation, Dataset bias, Iterative self-labeling},
	pages = {18--31},
	file = {Tommasi_Tuytelaars_2015_A Testbed for Cross-Dataset Analysis.pdf:/Users/orsonxu/Desktop/HCI/Literature Management/Zotero/Tommasi_Tuytelaars_2015_A Testbed for Cross-Dataset Analysis.pdf:application/pdf},
}

@article{baltrusaitis_cross-dataset_2015,
	title = {Cross-dataset learning and person-specific normalisation for automatic {Action} {Unit} detection},
	volume = {2015-Janua},
	doi = {10.1109/FG.2015.7284869},
	abstract = {Automatic detection of Facial Action Units (AUs) is crucial for facial analysis systems. Due to the large individual differences, performance of AU classifiers depends largely on training data and the ability to estimate facial expressions of a neutral face. In this paper, we present a real-time Facial Action Unit intensity estimation and occurrence detection system based on appearance (Histograms of Oriented Gradients) and geometry features (shape parameters and landmark locations). Our experiments show the benefits of using additional labelled data from different datasets, which demonstrates the generalisability of our approach. This holds both when training for a specific dataset or when a generic model is needed. We also demonstrate the benefits of using a simple and efficient median based feature normalisation technique that accounts for person-specific neutral expressions. Finally, we show that our results outperform the FERA 2015 baselines in all three challenge tasks - AU occurrence detection, fully automatic AU intensity and pre-segmented AU intensity estimation.},
	journal = {2015 11th IEEE International Conference and Workshops on Automatic Face and Gesture Recognition, FG 2015},
	author = {Baltrušaitis, Tadas and Mahmoud, Marwa and Robinson, Peter},
	year = {2015},
	note = {ISBN: 9781479960262},
	file = {Baltrušaitis et al_2015_Cross-dataset learning and person-specific normalisation for automatic Action Unit detection.pdf:/Users/orsonxu/Desktop/HCI/Literature Management/Zotero/Baltrušaitis et al_2015_Cross-dataset learning and person-specific normalisation for automatic Action Unit detection.pdf:application/pdf},
}

@article{zhang_recent_2019,
	title = {Recent {Advances} in {Transfer} {Learning} for {Cross}-{Dataset} {Visual} {Recognition}},
	volume = {52},
	issn = {0360-0300},
	url = {https://dl.acm.org/doi/10.1145/3291124},
	doi = {10.1145/3291124},
	abstract = {This paper takes a problem-oriented perspective and presents a comprehensive review of transfer learning methods, both shallow and deep, for cross-dataset visual recognition. Specifically, it categorises the cross-dataset recognition into seventeen problems based on a set of carefully chosen data and label attributes. Such a problem-oriented taxonomy has allowed us to examine how different transfer learning approaches tackle each problem and how well each problem has been researched to date. The comprehensive problem-oriented review of the advances in transfer learning with respect to the problem has not only revealed the challenges in transfer learning for visual recognition, but also the problems (e.g. eight of the seventeen problems) that have been scarcely studied. This survey not only presents an up-to-date technical review for researchers, but also a systematic approach and a reference for a machine learning practitioner to categorise a real problem and to look up for a possible solution accordingly.},
	number = {1},
	journal = {ACM Computing Surveys},
	author = {Zhang, Jing and Li, Wanqing and Ogunbona, Philip and Xu, Dong},
	month = feb,
	year = {2019},
	pages = {1--38},
	file = {Zhang et al_2019_Recent Advances in Transfer Learning for Cross-Dataset Visual Recognition.pdf:/Users/orsonxu/Desktop/HCI/Literature Management/Zotero/Zhang et al_2019_Recent Advances in Transfer Learning for Cross-Dataset Visual Recognition.pdf:application/pdf},
}

@incollection{saenko_adapting_2010,
	title = {Adapting {Visual} {Category} {Models} to {New} {Domains}},
	volume = {6314 LNCS},
	isbn = {3-642-15560-X},
	url = {http://link.springer.com/10.1007/978-3-642-15561-1_16},
	abstract = {Domain adaptation is an important emerging topic in computer vision. In this paper, we present one of the first studies of domain shift in the context of object recognition. We introduce a method that adapts object models acquired in a particular visual domain to new imaging conditions by learning a transformation that minimizes the effect of domain-induced changes in the feature distribution. The transformation is learned in a supervised manner and can be applied to categories for which there are no labeled examples in the new domain. While we focus our evaluation on object recognition tasks, the transform-based adaptation technique we develop is general and could be applied to non-image data. Another contribution is a new multi-domain object database, freely available for download. We experimentally demonstrate the ability of our method to improve recognition on categories with few or no target domain labels and moderate to large changes in the imaging conditions. © 2010 Springer-Verlag.},
	booktitle = {Lecture {Notes} in {Computer} {Science} (including subseries {Lecture} {Notes} in {Artificial} {Intelligence} and {Lecture} {Notes} in {Bioinformatics})},
	author = {Saenko, Kate and Kulis, Brian and Fritz, Mario and Darrell, Trevor},
	year = {2010},
	doi = {10.1007/978-3-642-15561-1_16},
	note = {Issue: PART 4
ISSN: 16113349},
	pages = {213--226},
	file = {Saenko et al_2010_Adapting Visual Category Models to New Domains.pdf:/Users/orsonxu/Desktop/HCI/Literature Management/Zotero/Saenko et al_2010_Adapting Visual Category Models to New Domains.pdf:application/pdf},
}

@article{fernando_unsupervised_2013,
	title = {Unsupervised visual domain adaptation using subspace alignment},
	doi = {10.1109/ICCV.2013.368},
	abstract = {In this paper, we introduce a new domain adaptation (DA) algorithm where the source and target domains are represented by subspaces described by eigenvectors. In this context, our method seeks a domain adaptation solution by learning a mapping function which aligns the source subspace with the target one. We show that the solution of the corresponding optimization problem can be obtained in a simple closed form, leading to an extremely fast algorithm. We use a theoretical result to tune the unique hyper parameter corresponding to the size of the subspaces. We run our method on various datasets and show that, despite its intrinsic simplicity, it outperforms state of the art DA methods. © 2013 IEEE.},
	journal = {Proceedings of the IEEE International Conference on Computer Vision},
	author = {Fernando, Basura and Habrard, Amaury and Sebban, Marc and Tuytelaars, Tinne},
	year = {2013},
	note = {ISBN: 9781479928392},
	keywords = {object recognition, domain adaptation, subspace alignment},
	pages = {2960--2967},
	file = {Fernando et al_2013_Unsupervised visual domain adaptation using subspace alignment.pdf:/Users/orsonxu/Desktop/HCI/Literature Management/Zotero/Fernando et al_2013_Unsupervised visual domain adaptation using subspace alignment.pdf:application/pdf},
}

@inproceedings{boqing_gong_geodesic_2012,
	title = {Geodesic flow kernel for unsupervised domain adaptation},
	isbn = {978-1-4673-1228-8},
	url = {http://ieeexplore.ieee.org/document/6247911/},
	doi = {10.1109/CVPR.2012.6247911},
	abstract = {In real-world applications of visual recognition, many factors such as pose, illumination, or image quality can cause a significant mismatch between the source domain on which classifiers are trained and the target domain to which those classifiers are applied. As such, the classifiers often perform poorly on the target domain. Domain adaptation techniques aim to correct the mismatch. Existing approaches have concentrated on learning feature representations that are invariant across domains, and they often do not directly exploit low-dimensional structures that are intrinsic to many vision datasets. In this paper, we propose a new kernel-based method that takes advantage of such structures. Our geodesic flow kernel models domain shift by integrating an infinite number of subspaces that characterize changes in geometric and statistical properties from the source to the target domain. Our approach is computationally advantageous, automatically inferring important algorithmic parameters without requiring extensive cross-validation or labeled data from either domain. We also introduce a metric that reliably measures the adaptability between a pair of source and target domains. For a given target domain and several source domains, the metric can be used to automatically select the optimal source domain to adapt and avoid less desirable ones. Empirical studies on standard datasets demonstrate the advantages of our approach over competing methods. © 2012 IEEE.},
	booktitle = {2012 {IEEE} {Conference} on {Computer} {Vision} and {Pattern} {Recognition}},
	publisher = {IEEE},
	author = {{Boqing Gong} and {Yuan Shi} and {Fei Sha} and Grauman, Kristen},
	month = jun,
	year = {2012},
	note = {ISSN: 10636919},
	pages = {2066--2073},
	file = {Boqing Gong et al_2012_Geodesic flow kernel for unsupervised domain adaptation.pdf:/Users/orsonxu/Desktop/HCI/Literature Management/Zotero/Boqing Gong et al_2012_Geodesic flow kernel for unsupervised domain adaptation.pdf:application/pdf},
}

@article{sun_return_2016,
	title = {Return of frustratingly easy domain adaptation},
	url = {https://ojs.aaai.org/index.php/AAAI/article/view/10306},
	number = {1},
	journal = {Proceedings of the Thirtieth AAAI Conference on Artificial Intelligence},
	author = {Sun, Baochen and Saenko, Kate},
	year = {2016},
	keywords = {Technical Papers: Machine Learning Methods},
	pages = {2058--2065},
	file = {Sun_Saenko_2016_Return of frustratingly easy domain adaptation.pdf:/Users/orsonxu/Desktop/HCI/Literature Management/Zotero/Sun_Saenko_2016_Return of frustratingly easy domain adaptation.pdf:application/pdf},
}

@inproceedings{church_understanding_2015,
	address = {New York, NY, USA},
	title = {Understanding the {Challenges} of {Mobile} {Phone} {Usage} {Data}},
	isbn = {978-1-4503-3652-9},
	url = {https://dl.acm.org/doi/10.1145/2785830.2785891},
	doi = {10.1145/2785830.2785891},
	abstract = {Driven by curiosity and our own three diverse smartphone application usage datasets, we sought to unpack the nuances of mobile device use by revisiting two recent Mobile HCI studies [1, 17]. Our goal was to add to our broader understanding of smartphone usage by investigating if differences in mobile device usage occurred not only across our three datasets, but also in relation to prior work. We found differences in the top-10 apps in each dataset, in the durations and types of interactions as well as in micro-usage patterns. However, it proved very challenging to attribute such differences to a specific factor or set of factors: Was it the time frame in which the studies were executed? The recruitment procedure? The experimental method? Using our somewhat troubled analysis, we discuss the challenges and issues of conducting mobile research of this nature and reflect on caveats related to the replicability and generalizability of such work.},
	booktitle = {Proceedings of the 17th {International} {Conference} on {Human}-{Computer} {Interaction} with {Mobile} {Devices} and {Services}},
	publisher = {ACM},
	author = {Church, Karen and Ferreira, Denzil and Banovic, Nikola and Lyons, Kent},
	month = aug,
	year = {2015},
	keywords = {Device usage, Evaluation, Generalizability, Methodology, Micro-usage, Mobile hci, Mobile usage, Replication, Smartphone usage, User studies},
	pages = {504--514},
	file = {Church et al_2015_Understanding the Challenges of Mobile Phone Usage Data.pdf:/Users/orsonxu/Desktop/HCI/Literature Management/Zotero/Church et al_2015_Understanding the Challenges of Mobile Phone Usage Data.pdf:application/pdf},
}


@inproceedings{tzeng_adversarial_2017,
	address = {Honolulu, HI},
	title = {Adversarial {Discriminative} {Domain} {Adaptation}},
	isbn = {978-1-5386-0457-1},
	url = {http://ieeexplore.ieee.org/document/8099799/},
	doi = {10.1109/CVPR.2017.316},
	abstract = {Adversarial learning methods are a promising approach to training robust deep networks, and can generate complex samples across diverse domains. They can also improve recognition despite the presence of domain shift or dataset bias: recent adversarial approaches to unsupervised domain adaptation reduce the difference between the training and test domain distributions and thus improve generalization performance. However, while generative adversarial networks (GANs) show compelling visualizations, they are not optimal on discriminative tasks and can be limited to smaller shifts. On the other hand, discriminative approaches can handle larger domain shifts, but impose tied weights on the model and do not exploit a GAN-based loss. In this work, we ﬁrst outline a novel generalized framework for adversarial adaptation, which subsumes recent state-of-the-art approaches as special cases, and use this generalized view to better relate prior approaches. We then propose a previously unexplored instance of our general framework which combines discriminative modeling, untied weight sharing, and a GAN loss, which we call Adversarial Discriminative Domain Adaptation (ADDA). We show that ADDA is more effective yet considerably simpler than competing domainadversarial methods, and demonstrate the promise of our approach by exceeding state-of-the-art unsupervised adaptation results on standard domain adaptation tasks as well as a difﬁcult cross-modality object classiﬁcation task.},
	language = {en},
	urldate = {2021-06-11},
	booktitle = {2017 {IEEE} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} ({CVPR})},
	publisher = {IEEE},
	author = {Tzeng, Eric and Hoffman, Judy and Saenko, Kate and Darrell, Trevor},
	month = jul,
	year = {2017},
	keywords = {Unread},
	pages = {2962--2971},
	file = {Tzeng et al_2017_Adversarial Discriminative Domain Adaptation.pdf:/Users/orsonxu/Desktop/HCI/Literature Management/Zotero/Tzeng et al_2017_Adversarial Discriminative Domain Adaptation.pdf:application/pdf},
}

@article{wang_exploring_2021,
	title = {Exploring the {Generalizability} of {Spatio}-{Temporal} {Traffic} {Prediction}: {Meta}-{Modeling} and an {Analytic} {Framework}},
	issn = {1558-2191},
	shorttitle = {Exploring the {Generalizability} of {Spatio}-{Temporal} {Traffic} {Prediction}},
	doi = {10.1109/TKDE.2021.3130762},
	abstract = {The Spatio-Temporal Traffic Prediction (STTP) problem is a classical problem with plenty of prior research efforts that benefit from traditional statistical learning and recent deep learning approaches. While STTP can refer to many real-world problems, most existing studies focus on quite specific applications, such as the prediction of taxi demand, ridesharing order, traffic speed, and so on. This hinders the STTP research as the approaches designed for different applications are hardly comparable, and thus how an application-driven approach can be generalized to other scenarios is unclear. To fill in this gap, this paper makes three efforts: (i) we propose an analytic framework, called STAnalytic, to qualitatively investigate STTP approaches regarding their design considerations on various spatial and temporal factors, aiming to make different application-driven approaches comparable; (ii) we design a spatio-temporal meta-model, called STMeta, which can flexibly integrate generalizable temporal and spatial knowledge identified by STAnalytic, (iii) we build an extensively large-scale STTP benchmark platform including ten datasets with five scenarios to quantitatively measure the generalizability of STTP approaches. In particular, we implement STMeta with different deep learning techniques, and STMeta demonstrates better generalizability than state-of-the-art approaches by achieving lower prediction error on average across all the datasets.},
	journal = {IEEE Transactions on Knowledge and Data Engineering},
	author = {Wang, Leye and Chai, Di and Liu, Xuanzhe and Chen, Liyue and Chen, Kai},
	year = {2021},
	note = {Conference Name: IEEE Transactions on Knowledge and Data Engineering},
	pages = {1--1},
	file = {Wang et al_2021_Exploring the Generalizability of Spatio-Temporal Traffic Prediction.pdf:/Users/orsonxu/Desktop/HCI/Literature Management/Zotero/Wang et al_2021_Exploring the Generalizability of Spatio-Temporal Traffic Prediction.pdf:application/pdf},
}

@incollection{leibe_deep_2016,
	address = {Cham},
	title = {Deep {Reconstruction}-{Classification} {Networks} for {Unsupervised} {Domain} {Adaptation}},
	volume = {9908},
	isbn = {978-3-319-46492-3 978-3-319-46493-0},
	url = {http://link.springer.com/10.1007/978-3-319-46493-0_36},
	abstract = {In this paper, we propose a novel unsupervised domain adaptation algorithm based on deep learning for visual object recognition. Speciﬁcally, we design a new model called Deep ReconstructionClassiﬁcation Network (DRCN), which jointly learns a shared encoding representation for two tasks: (i) supervised classiﬁcation of labeled source data, and (ii) unsupervised reconstruction of unlabeled target data. In this way, the learnt representation not only preserves discriminability, but also encodes useful information from the target domain. Our new DRCN model can be optimized by using backpropagation similarly as the standard neural networks.},
	language = {en},
	urldate = {2021-12-18},
	booktitle = {Computer {Vision} – {ECCV} 2016},
	publisher = {Springer International Publishing},
	author = {Ghifary, Muhammad and Kleijn, W. Bastiaan and Zhang, Mengjie and Balduzzi, David and Li, Wen},
	editor = {Leibe, Bastian and Matas, Jiri and Sebe, Nicu and Welling, Max},
	year = {2016},
	doi = {10.1007/978-3-319-46493-0_36},
	note = {Series Title: Lecture Notes in Computer Science},
	pages = {597--613},
	file = {Ghifary et al. - 2016 - Deep Reconstruction-Classification Networks for Un.pdf:/Users/orsonxu/Zotero/storage/JMBAWMU6/Ghifary et al. - 2016 - Deep Reconstruction-Classification Networks for Un.pdf:application/pdf},
}

@article{tzeng_deep_2014,
	title = {Deep {Domain} {Confusion}: {Maximizing} for {Domain} {Invariance}},
	shorttitle = {Deep {Domain} {Confusion}},
	url = {http://arxiv.org/abs/1412.3474},
	abstract = {Recent reports suggest that a generic supervised deep CNN model trained on a large-scale dataset reduces, but does not remove, dataset bias on a standard benchmark. Fine-tuning deep models in a new domain can require a significant amount of data, which for many applications is simply not available. We propose a new CNN architecture which introduces an adaptation layer and an additional domain confusion loss, to learn a representation that is both semantically meaningful and domain invariant. We additionally show that a domain confusion metric can be used for model selection to determine the dimension of an adaptation layer and the best position for the layer in the CNN architecture. Our proposed adaptation method offers empirical performance which exceeds previously published results on a standard benchmark visual domain adaptation task.},
	urldate = {2021-12-18},
	journal = {arXiv:1412.3474 [cs]},
	author = {Tzeng, Eric and Hoffman, Judy and Zhang, Ning and Saenko, Kate and Darrell, Trevor},
	month = dec,
	year = {2014},
	note = {arXiv: 1412.3474},
	file = {Tzeng et al_2014_Deep Domain Confusion.pdf:/Users/orsonxu/Desktop/HCI/Literature Management/Zotero/Tzeng et al_2014_Deep Domain Confusion.pdf:application/pdf},
}


@incollection{hutchison_undoing_2012,
	address = {Berlin, Heidelberg},
	title = {Undoing the {Damage} of {Dataset} {Bias}},
	volume = {7572},
	isbn = {978-3-642-33717-8 978-3-642-33718-5},
	url = {http://link.springer.com/10.1007/978-3-642-33718-5_12},
	abstract = {The presence of bias in existing object recognition datasets is now well-known in the computer vision community. While it remains in question whether creating an unbiased dataset is possible given limited resources, in this work we propose a discriminative framework that directly exploits dataset bias during training. In particular, our model learns two sets of weights: (1) bias vectors associated with each individual dataset, and (2) visual world weights that are common to all datasets, which are learned by undoing the associated bias from each dataset. The visual world weights are expected to be our best possible approximation to the object model trained on an unbiased dataset, and thus tend to have good generalization ability. We demonstrate the eﬀectiveness of our model by applying the learned weights to a novel, unseen dataset, and report superior results for both classiﬁcation and detection tasks compared to a classical SVM that does not account for the presence of bias. Overall, we ﬁnd that it is beneﬁcial to explicitly account for bias when combining multiple datasets.},
	language = {en},
	urldate = {2021-12-22},
	booktitle = {Computer {Vision} – {ECCV} 2012},
	publisher = {Springer Berlin Heidelberg},
	author = {Khosla, Aditya and Zhou, Tinghui and Malisiewicz, Tomasz and Efros, Alexei A. and Torralba, Antonio},
	editor = {Hutchison, David and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M. and Mattern, Friedemann and Mitchell, John C. and Naor, Moni and Nierstrasz, Oscar and Pandu Rangan, C. and Steffen, Bernhard and Sudan, Madhu and Terzopoulos, Demetri and Tygar, Doug and Vardi, Moshe Y. and Weikum, Gerhard and Fitzgibbon, Andrew and Lazebnik, Svetlana and Perona, Pietro and Sato, Yoichi and Schmid, Cordelia},
	year = {2012},
	doi = {10.1007/978-3-642-33718-5_12},
	note = {Series Title: Lecture Notes in Computer Science},
	pages = {158--171},
	file = {Khosla et al. - 2012 - Undoing the Damage of Dataset Bias.pdf:/Users/orsonxu/Zotero/storage/EAF7RLGJ/Khosla et al. - 2012 - Undoing the Damage of Dataset Bias.pdf:application/pdf},
}

@inproceedings{ismail_fawaz_transfer_2018,
	title = {Transfer learning for time series classification},
	doi = {10.1109/BigData.2018.8621990},
	abstract = {Transfer learning for deep neural networks is the process of first training a base network on a source dataset, and then transferring the learned features (the network’s weights) to a second network to be trained on a target dataset. This idea has been shown to improve deep neural network’s generalization capabilities in many computer vision tasks such as image recognition and object localization. Apart from these applications, deep Convolutional Neural Networks (CNNs) have also recently gained popularity in the Time Series Classification (TSC) community. However, unlike for image recognition problems, transfer learning techniques have not yet been investigated thoroughly for the TSC task. This is surprising as the accuracy of deep learning models for TSC could potentially be improved if the model is fine-tuned from a pre-trained neural network instead of training it from scratch. In this paper, we fill this gap by investigating how to transfer deep CNNs for the TSC task. To evaluate the potential of transfer learning, we performed extensive experiments using the UCR archive which is the largest publicly available TSC benchmark containing 85 datasets. For each dataset in the archive, we pre-trained a model and then fine-tuned it on the other datasets resulting in 7140 different deep neural networks. These experiments revealed that transfer learning can improve or degrade the models predictions depending on the dataset used for transfer. Therefore, in an effort to predict the best source dataset for a given target dataset, we propose a new method relying on Dynamic Time Warping to measure inter-datasets similarities. We describe how our method can guide the transfer to choose the best source dataset leading to an improvement in accuracy on 71 out of 85 datasets.},
	booktitle = {2018 {IEEE} {International} {Conference} on {Big} {Data} ({Big} {Data})},
	author = {Ismail Fawaz, Hassan and Forestier, Germain and Weber, Jonathan and Idoumghar, Lhassane and Muller, Pierre-Alain},
	month = dec,
	year = {2018},
	pages = {1367--1376},
	file = {Ismail Fawaz et al_2018_Transfer learning for time series classification.pdf:/Users/orsonxu/Desktop/HCI/Literature Management/Zotero/Ismail Fawaz et al_2018_Transfer learning for time series classification.pdf:application/pdf},
}

@article{volpi_generalizing_2018,
	title = {Generalizing to {Unseen} {Domains} via {Adversarial} {Data} {Augmentation}},
	url = {http://arxiv.org/abs/1805.12018},
	abstract = {We are concerned with learning models that generalize well to different {\textbackslash}emph\{unseen\} domains. We consider a worst-case formulation over data distributions that are near the source domain in the feature space. Only using training data from a single source distribution, we propose an iterative procedure that augments the dataset with examples from a fictitious target domain that is "hard" under the current model. We show that our iterative scheme is an adaptive data augmentation method where we append adversarial examples at each iteration. For softmax losses, we show that our method is a data-dependent regularization scheme that behaves differently from classical regularizers that regularize towards zero (e.g., ridge or lasso). On digit recognition and semantic segmentation tasks, our method learns models improve performance across a range of a priori unknown target domains.},
	urldate = {2022-01-07},
	journal = {arXiv:1805.12018 [cs]},
	author = {Volpi, Riccardo and Namkoong, Hongseok and Sener, Ozan and Duchi, John and Murino, Vittorio and Savarese, Silvio},
	month = nov,
	year = {2018},
	note = {arXiv: 1805.12018},
	file = {Volpi et al_2018_Generalizing to Unseen Domains via Adversarial Data Augmentation.pdf:/Users/orsonxu/Desktop/HCI/Literature Management/Zotero/Volpi et al_2018_Generalizing to Unseen Domains via Adversarial Data Augmentation.pdf:application/pdf},
}

@article{shankar_generalizing_2018,
	title = {Generalizing {Across} {Domains} via {Cross}-{Gradient} {Training}},
	url = {http://arxiv.org/abs/1804.10745},
	abstract = {We present CROSSGRAD, a method to use multi-domain training data to learn a classifier that generalizes to new domains. CROSSGRAD does not need an adaptation phase via labeled or unlabeled data, or domain features in the new domain. Most existing domain adaptation methods attempt to erase domain signals using techniques like domain adversarial training. In contrast, CROSSGRAD is free to use domain signals for predicting labels, if it can prevent overfitting on training domains. We conceptualize the task in a Bayesian setting, in which a sampling step is implemented as data augmentation, based on domain-guided perturbations of input instances. CROSSGRAD parallelly trains a label and a domain classifier on examples perturbed by loss gradients of each other's objectives. This enables us to directly perturb inputs, without separating and re-mixing domain signals while making various distributional assumptions. Empirical evaluation on three different applications where this setting is natural establishes that (1) domain-guided perturbation provides consistently better generalization to unseen domains, compared to generic instance perturbation methods, and that (2) data augmentation is a more stable and accurate method than domain adversarial training.},
	urldate = {2022-01-09},
	journal = {arXiv:1804.10745 [cs, stat]},
	author = {Shankar, Shiv and Piratla, Vihari and Chakrabarti, Soumen and Chaudhuri, Siddhartha and Jyothi, Preethi and Sarawagi, Sunita},
	month = may,
	year = {2018},
	note = {arXiv: 1804.10745},
	file = {Shankar et al_2018_Generalizing Across Domains via Cross-Gradient Training.pdf:/Users/orsonxu/Desktop/HCI/Literature Management/Zotero/Shankar et al_2018_Generalizing Across Domains via Cross-Gradient Training.pdf:application/pdf},
}


@inproceedings{balaji_metareg_2018,
	title = {{MetaReg}: {Towards} {Domain} {Generalization} using {Meta}-{Regularization}},
	volume = {31},
	shorttitle = {{MetaReg}},
	url = {https://proceedings.neurips.cc/paper/2018/hash/647bba344396e7c8170902bcf2e15551-Abstract.html},
	urldate = {2022-01-16},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates, Inc.},
	author = {Balaji, Yogesh and Sankaranarayanan, Swami and Chellappa, Rama},
	year = {2018},
	file = {Balaji et al_2018_MetaReg.pdf:/Users/orsonxu/Desktop/HCI/Literature Management/Zotero/Balaji et al_2018_MetaReg.pdf:application/pdf},
}

@inproceedings{li_feature-critic_2019,
	title = {Feature-{Critic} {Networks} for {Heterogeneous} {Domain} {Generalization}},
	url = {https://proceedings.mlr.press/v97/li19l.html},
	abstract = {The well known domain shift issue causes model performance to degrade when deployed to a new target domain with different statistics to training. Domain adaptation techniques alleviate this, but need some instances from the target domain to drive adaptation. Domain generalisation is the recently topical problem of learning a model that generalises to unseen domains out of the box, and various approaches aim to train a domain-invariant feature extractor, typically by adding some manually designed losses. In this work, we propose a learning to learn approach, where the auxiliary loss that helps generalisation is itself learned. Beyond conventional domain generalisation, we consider a more challenging setting of heterogeneous domain generalisation, where the unseen domains do not share label space with the seen ones, and the goal is to train a feature representation that is useful off-the-shelf for novel data and novel categories. Experimental evaluation demonstrates that our method outperforms state-of-the-art solutions in both settings.},
	language = {en},
	urldate = {2022-01-16},
	booktitle = {Proceedings of the 36th {International} {Conference} on {Machine} {Learning}},
	publisher = {PMLR},
	author = {Li, Yiying and Yang, Yongxin and Zhou, Wei and Hospedales, Timothy},
	month = may,
	year = {2019},
	note = {ISSN: 2640-3498},
	pages = {3915--3924},
	file = {Li et al_2019_Feature-Critic Networks for Heterogeneous Domain Generalization.pdf:/Users/orsonxu/Desktop/HCI/Literature Management/Zotero/Li et al_2019_Feature-Critic Networks for Heterogeneous Domain Generalization.pdf:application/pdf},
}

@article{muandet_domain_2013,
	title = {Domain {Generalization} via {Invariant} {Feature} {Representation}},
	abstract = {This paper investigates domain generalization: How to take knowledge acquired from an arbitrary number of related domains and apply it to previously unseen domains? We propose Domain-Invariant Component Analysis (DICA), a kernel-based optimization algorithm that learns an invariant transformation by minimizing the dissimilarity across domains, whilst preserving the functional relationship between input and output variables. A learning-theoretic analysis shows that reducing dissimilarity improves the expected generalization ability of classiﬁers on new domains, motivating the proposed algorithm. Experimental results on synthetic and real-world datasets demonstrate that DICA successfully learns invariant features and improves classiﬁer performance in practice.},
	language = {en},
	journal = {Proceedings of the 30 th International Conference on Machine Learning},
	author = {Muandet, Krikamol and Balduzzi, David and Scholkopf, Bernhard},
	year = {2013},
	pages = {9},
	file = {Muandet et al. - Domain Generalization via Invariant Feature Repres.pdf:/Users/orsonxu/Zotero/storage/2DFZWPP8/Muandet et al. - Domain Generalization via Invariant Feature Repres.pdf:application/pdf},
}

@inproceedings{li_domain_2018,
	address = {Salt Lake City, UT},
	title = {Domain {Generalization} with {Adversarial} {Feature} {Learning}},
	isbn = {978-1-5386-6420-9},
	url = {https://ieeexplore.ieee.org/document/8578664/},
	doi = {10.1109/CVPR.2018.00566},
	abstract = {In this paper, we tackle the problem of domain generalization: how to learn a generalized feature representation for an “unseen” target domain by taking the advantage of multiple seen source-domain data. We present a novel framework based on adversarial autoencoders to learn a generalized latent feature representation across domains for domain generalization. To be speciﬁc, we extend adversarial autoencoders by imposing the Maximum Mean Discrepancy (MMD) measure to align the distributions among different domains, and matching the aligned distribution to an arbitrary prior distribution via adversarial feature learning. In this way, the learned feature representation is supposed to be universal to the seen source domains because of the MMD regularization, and is expected to generalize well on the target domain because of the introduction of the prior distribution. We proposed an algorithm to jointly train different components of our proposed framework. Extensive experiments on various vision tasks demonstrate that our proposed framework can learn better generalized features for the unseen target domain compared with state-of-the-art domain generalization methods.},
	language = {en},
	urldate = {2022-02-02},
	booktitle = {2018 {IEEE}/{CVF} {Conference} on {Computer} {Vision} and {Pattern} {Recognition}},
	publisher = {IEEE},
	author = {Li, Haoliang and Pan, Sinno Jialin and Wang, Shiqi and Kot, Alex C.},
	month = jun,
	year = {2018},
	pages = {5400--5409},
	file = {Li et al. - 2018 - Domain Generalization with Adversarial Feature Lea.pdf:/Users/orsonxu/Zotero/storage/NKAX356P/Li et al. - 2018 - Domain Generalization with Adversarial Feature Lea.pdf:application/pdf},
}

@incollection{ferrari_deep_2018,
	address = {Cham},
	title = {Deep {Domain} {Generalization} via {Conditional} {Invariant} {Adversarial} {Networks}},
	volume = {11219},
	isbn = {978-3-030-01266-3 978-3-030-01267-0},
	url = {http://link.springer.com/10.1007/978-3-030-01267-0_38},
	abstract = {Domain generalization aims to learn a classiﬁcation model from multiple source domains and generalize it to unseen target domains. A critical problem in domain generalization involves learning domaininvariant representations. Let X and Y denote the features and the labels, respectively. Under the assumption that the conditional distribution P (Y {\textbar}X) remains unchanged across domains, earlier approaches to domain generalization learned the invariant representation T (X) by minimizing the discrepancy of the marginal distribution P (T (X)). However, such an assumption of stable P (Y {\textbar}X) does not necessarily hold in practice. In addition, the representation learning function T (X) is usually constrained to a simple linear transformation or shallow networks. To address the above two drawbacks, we propose an end-to-end conditional invariant deep domain generalization approach by leveraging deep neural networks for domain-invariant representation learning. The domain-invariance property is guaranteed through a conditional invariant adversarial network that can learn domain-invariant representations w.r.t. the joint distribution P (T (X), Y ) if the target domain data are not severely class unbalanced. We perform various experiments to demonstrate the eﬀectiveness of the proposed method.},
	language = {en},
	urldate = {2022-02-02},
	booktitle = {Computer {Vision} – {ECCV} 2018},
	publisher = {Springer International Publishing},
	author = {Li, Ya and Tian, Xinmei and Gong, Mingming and Liu, Yajing and Liu, Tongliang and Zhang, Kun and Tao, Dacheng},
	editor = {Ferrari, Vittorio and Hebert, Martial and Sminchisescu, Cristian and Weiss, Yair},
	year = {2018},
	doi = {10.1007/978-3-030-01267-0_38},
	note = {Series Title: Lecture Notes in Computer Science},
	pages = {647--663},
	file = {Li et al. - 2018 - Deep Domain Generalization via Conditional Invaria.pdf:/Users/orsonxu/Zotero/storage/YXYLRSHK/Li et al. - 2018 - Deep Domain Generalization via Conditional Invaria.pdf:application/pdf},
}


@inproceedings{eldele_time-series_2021,
	address = {Montreal, Canada},
	title = {Time-{Series} {Representation} {Learning} via {Temporal} and {Contextual} {Contrasting}},
	isbn = {978-0-9992411-9-6},
	url = {https://www.ijcai.org/proceedings/2021/324},
	doi = {10.24963/ijcai.2021/324},
	abstract = {Learning decent representations from unlabeled time-series data with temporal dynamics is a very challenging task. In this paper, we propose an unsupervised Time-Series representation learning framework via Temporal and Contextual Contrasting (TS-TCC), to learn time-series representation from unlabeled data. First, the raw timeseries data are transformed into two different yet correlated views by using weak and strong augmentations. Second, we propose a novel temporal contrasting module to learn robust temporal representations by designing a tough cross-view prediction task. Last, to further learn discriminative representations, we propose a contextual contrasting module built upon the contexts from the temporal contrasting module. It attempts to maximize the similarity among different contexts of the same sample while minimizing similarity among contexts of different samples. Experiments have been carried out on three real-world time-series datasets. The results manifest that training a linear classiﬁer on top of the features learned by our proposed TS-TCC performs comparably with the supervised training. Additionally, our proposed TS-TCC shows high efﬁciency in few-labeled data and transfer learning scenarios. The code is publicly available at https://github.com/emadeldeen24/TS-TCC.},
	language = {en},
	urldate = {2022-02-11},
	booktitle = {Proceedings of the {Thirtieth} {International} {Joint} {Conference} on {Artificial} {Intelligence}},
	publisher = {International Joint Conferences on Artificial Intelligence Organization},
	author = {Eldele, Emadeldeen and Ragab, Mohamed and Chen, Zhenghua and Wu, Min and Kwoh, Chee Keong and Li, Xiaoli and Guan, Cuntai},
	month = aug,
	year = {2021},
	pages = {2352--2359},
	file = {Eldele et al. - 2021 - Time-Series Representation Learning via Temporal a.pdf:/Users/orsonxu/Zotero/storage/IBDJENHN/Eldele et al. - 2021 - Time-Series Representation Learning via Temporal a.pdf:application/pdf},
}


@article{ester_density-based_1996,
	title = {A {Density}-{Based} {Algorithm} for {Discovering} {Clusters} in {Large} {Spatial} {Databases} with {Noise}},
	abstract = {Clusteringalgorithmasreattractivefor the taskof classidentification in spatial databases.Howevetrh, e applicationto large spatial databasesrises the followingrequirementfsor clustering algorithms: minimalrequirementsof domain knowledgteo determinethe input parameters,discoveryof clusters witharbitraryshapeandgoodefficiencyonlarge databases. Thewell-knowcnlusteringalgorithmsoffer nosolution to the combinatioonf theserequirementsI.n this paper, wepresent the newclustering algorithmDBSCAreNlying on a density-basednotionof clusters whichis designedto discoverclusters of arbitrary shape.DBSCrAeNquiresonly one input parameterandsupportsthe user in determiningan appropriatevaluefor it. Weperformeadn experimentaelvaluation of the effectiveness and efficiency of DBSCAusNing synthetic data and real data of the SEQUO2IA000benchmark.Theresults of our experimentsdemonstratethat (1) DBSCiAsNsignificantlymoreeffective in discoveringclusters of arbitrary shapethan the well-knowanlgorithmCLARANS,and that (2) DBSCAoNutperforms CLARANbyS factorof morethan100in termsof efficiency.},
	language = {en},
	journal = {Proceedings of the Second International Conference on Knowledge Discovery and Data Mining},
	author = {Ester, Martin and Kriegel, Hans-Peter and Xu, Xiaowei},
	year = {1996},
	pages = {6},
	file = {Ester et al. - A Density-Based Algorithm for Discovering Clusters.pdf:/Users/orsonxu/Zotero/storage/86LZH6LU/Ester et al. - A Density-Based Algorithm for Discovering Clusters.pdf:application/pdf},
}

@article{campello_hierarchical_2015,
	title = {Hierarchical {Density} {Estimates} for {Data} {Clustering}, {Visualization}, and {Outlier} {Detection}},
	volume = {10},
	issn = {1556-4681, 1556-472X},
	url = {https://dl.acm.org/doi/10.1145/2733381},
	doi = {10.1145/2733381},
	abstract = {An integrated framework for density-based cluster analysis, outlier detection, and data visualization is introduced in this article. The main module consists of an algorithm to compute hierarchical estimates of the level sets of a density, following Hartigan’s classic model of density-contour clusters and trees. Such an algorithm generalizes and improves existing density-based clustering techniques with respect to different aspects. It provides as a result a complete clustering hierarchy composed of all possible density-based clusters following the nonparametric model adopted, for an infinite range of density thresholds. The resulting hierarchy can be easily processed so as to provide multiple ways for data visualization and exploration. It can also be further postprocessed so that: (i) a normalized score of “outlierness” can be assigned to each data object, which unifies both the global and local perspectives of outliers into a single definition; and (ii) a “flat” (i.e., nonhierarchical) clustering solution composed of clusters extracted from local cuts through the cluster tree (possibly corresponding to different density thresholds) can be obtained, either in an unsupervised or in a semisupervised way. In the unsupervised scenario, the algorithm corresponding to this postprocessing module provides a global, optimal solution to the formal problem of maximizing the overall stability of the extracted clusters. If partially labeled objects or instance-level constraints are provided by the user, the algorithm can solve the problem by considering both constraints violations/satisfactions and cluster stability criteria. An asymptotic complexity analysis, both in terms of running time and memory space, is described. Experiments are reported that involve a variety of synthetic and real datasets, including comparisons with state-of-the-art, density-based clustering and (global and local) outlier detection methods.},
	language = {en},
	number = {1},
	urldate = {2021-08-07},
	journal = {ACM Transactions on Knowledge Discovery from Data},
	author = {Campello, Ricardo J. G. B. and Moulavi, Davoud and Zimek, Arthur and Sander, Jörg},
	month = jul,
	year = {2015},
	pages = {1--51},
	file = {Campello et al. - 2015 - Hierarchical Density Estimates for Data Clustering.pdf:/Users/orsonxu/Zotero/storage/R6Y3MVQ6/Campello et al. - 2015 - Hierarchical Density Estimates for Data Clustering.pdf:application/pdf},
}

@article{Russell:1996,
  title={UCLA Loneliness Scale (Version 3): Reliability, validity, and factor structure},
  author={Russell, Daniel W},
  journal={Journal of personality assessment},
  volume={66},
  number={1},
  pages={20--40},
  year={1996},
  publisher={Taylor \& Francis}
}

@article{walton2007question,
  title={A question of belonging: race, social fit, and achievement.},
  author={Walton, Gregory M and Cohen, Geoffrey L},
  journal={Journal of personality and social psychology},
  volume={92},
  number={1},
  pages={82},
  year={2007},
  publisher={American Psychological Association}
}

@article{radloff1977ces,
  title={The CES-D scale: A self-report depression scale for research in the general population},
  author={Radloff, Lenore Sawyer},
  journal={Applied psychological measurement},
  volume={1},
  number={3},
  pages={385--401},
  year={1977},
  publisher={Sage Publications Sage CA: Thousand Oaks, CA}
}

@article{williams1997racial,
  title={Racial differences in physical and mental health: Socio-economic status, stress and discrimination},
  author={Williams, David R and Yu, Yan and Jackson, James S and Anderson, Norman B},
  journal={Journal of health psychology},
  volume={2},
  number={3},
  pages={335--351},
  year={1997},
  publisher={Sage Publications Sage CA: Thousand Oaks, CA}
}


@article{blevins2015posttraumatic,
  title={The posttraumatic stress disorder checklist for DSM-5 (PCL-5): Development and initial psychometric evaluation},
  author={Blevins, Christy A and Weathers, Frank W and Davis, Margaret T and Witte, Tracy K and Domino, Jessica L},
  journal={Journal of traumatic stress},
  volume={28},
  number={6},
  pages={489--498},
  year={2015},
  publisher={Wiley Online Library}
}

@article{rammstedt2007measuring,
  title={Measuring personality in one minute or less: A 10-item short version of the Big Five Inventory in English and German},
  author={Rammstedt, Beatrice and John, Oliver P},
  journal={Journal of research in Personality},
  volume={41},
  number={1},
  pages={203--212},
  year={2007},
  publisher={Elsevier}
}

@article{kahler2005toward,
  title={Toward efficient and comprehensive measurement of the alcohol problems continuum in college students: The Brief Young Adult Alcohol Consequences Questionnaire},
  author={Kahler, Christopher W and Strong, David R and Read, Jennifer P},
  journal={Alcoholism: Clinical and Experimental Research},
  volume={29},
  number={7},
  pages={1180--1189},
  year={2005},
  publisher={Wiley Online Library}
}

@book{bobo2000prismatic,
  title={Prismatic metropolis: inequality in Los Angeles},
  author={Bobo, Lawrence D and Oliver, Melvin L and Johnson, Jr James H and Abel Jr, Valenzuela},
  year={2000},
  publisher={Russell Sage Foundation}
}

@misc{williams2016measuring,
 howpublished = {\url{https://scholar.harvard.edu/files/davidrwilliams/files/measuring_discrimination_resource_june_2016.pdf}},
 key = {{}},
 title = {{Measuring Discrimination Resource}},
 year = {2016}
}

@misc{panas,
 howpublished = {\url{https://ogg.osu.edu/media/documents/MB\%20Stream/PANAS.pdf}},
 key = {{}},
 title = {Positive and Negative Affect Schedule (PANAS-SF)},
 year = {}
}

@article{watson1988development,
  title={Development and validation of brief measures of positive and negative affect: the PANAS scales.},
  author={Watson, David and Clark, Lee Anna and Tellegen, Auke},
  journal={Journal of personality and social psychology},
  volume={54},
  number={6},
  pages={1063},
  year={1988},
  publisher={American Psychological Association}
}

@misc{williams2016phq4,
 howpublished = {\url{https://www.oregonpainguidance.org/app/content/uploads/2016/05/PHQ-4.pdf}},
 key = {{}},
 title = {{PHQ-4: THE FOUR-ITEM PATIENT HEALTH QUESTIONNAIRE FOR ANXIETY AND DEPRESSION}},
 year = {2016}
}

@misc{cohenpss4,
 howpublished = {\url{http://www.ohnurses.org/wp-content/uploads/2015/05/Perceived-Stress-Scale-41.pdf}},
 key = {{}},
 title = {{Perceived Stress Scale 4 (PSS-4)}},
 year = {}
}

@article{diener2010new,
  title={New well-being measures: Short scales to assess flourishing and positive and negative feelings},
  author={Diener, Ed and Wirtz, Derrick and Tov, William and Kim-Prieto, Chu and Choi, Dong-won and Oishi, Shigehiro and Biswas-Diener, Robert},
  journal={Social indicators research},
  volume={97},
  number={2},
  pages={143--156},
  year={2010},
  publisher={Springer}
}

@article{mccullough2002grateful,
  title={The grateful disposition: a conceptual and empirical topography.},
  author={McCullough, Michael E and Emmons, Robert A and Tsang, Jo-Ann},
  journal={Journal of personality and social psychology},
  volume={82},
  number={1},
  pages={112},
  year={2002},
  publisher={American Psychological Association}
}

@article{carver1997you,
  title={You want to measure coping but your protocol’too long: Consider the brief cope},
  author={Carver, Charles S},
  journal={International journal of behavioral medicine},
  volume={4},
  number={1},
  pages={92--100},
  year={1997},
  publisher={Springer}
}

@article{trapnell1999private,
  title={Private self-consciousness and the five-factor model of personality: distinguishing rumination from reflection.},
  author={Trapnell, Paul D and Campbell, Jennifer D},
  journal={Journal of personality and social psychology},
  volume={76},
  number={2},
  pages={284},
  year={1999},
  publisher={American Psychological Association}
}

@article{beck1996comparison,
  title={Comparison of Beck Depression Inventories-IA and-II in psychiatric outpatients},
  author={Beck, Aaron T and Steer, Robert A and Ball, Roberta and Ranieri, William F},
  journal={Journal of personality assessment},
  volume={67},
  number={3},
  pages={588--597},
  year={1996},
  publisher={Taylor \& Francis}
}

@article{brown2003benefits,
  title={The benefits of being present: mindfulness and its role in psychological well-being.},
  author={Brown, Kirk Warren and Ryan, Richard M},
  journal={Journal of personality and social psychology},
  volume={84},
  number={4},
  pages={822},
  year={2003},
  publisher={American Psychological Association}
}

@article{cole2004development,
  title={Development and validation of a Rasch-derived CES-D short form.},
  author={Cole, Jason C and Rabin, Adele S and Smith, Tom L and Kaufman, Alan S},
  journal={Psychological assessment},
  volume={16},
  number={4},
  pages={360},
  year={2004},
  publisher={American Psychological Association}
}

@article{bieling1998state,
  title={The State--Trait Anxiety Inventory, Trait version: structure and content re-examined},
  author={Bieling, Peter J and Antony, Martin M and Swinson, Richard P},
  journal={Behaviour research and therapy},
  volume={36},
  number={7-8},
  pages={777--788},
  year={1998},
  publisher={Elsevier}
}

@article{kabacoff1997psychometric,
  title={Psychometric properties and diagnostic utility of the Beck Anxiety Inventory and the State-Trait Anxiety Inventory with older adult psychiatric outpatients},
  author={Kabacoff, Robert I and Segal, Daniel L and Hersen, Michel and Van Hasselt, Vincent B},
  journal={Journal of anxiety disorders},
  volume={11},
  number={1},
  pages={33--47},
  year={1997},
  publisher={Elsevier}
}

@article{cohen1983positive,
  title={Positive events and social supports as buffers of life change stress 1},
  author={Cohen, Sheldon and Hoberman, Harry M},
  journal={Journal of applied social psychology},
  volume={13},
  number={2},
  pages={99--125},
  year={1983},
  publisher={Wiley Online Library}
}


@article{gross2003individual,
  title={Individual differences in two emotion regulation processes: implications for affect, relationships, and well-being.},
  author={Gross, James J and John, Oliver P},
  journal={Journal of personality and social psychology},
  volume={85},
  number={2},
  pages={348},
  year={2003},
  publisher={American Psychological Association}
}

@article{cohen1983global,
  title={A global measure of perceived stress},
  author={Cohen, Sheldon and Kamarck, Tom and Mermelstein, Robin},
  journal={Journal of health and social behavior},
  pages={385--396},
  year={1983},
  publisher={JSTOR}
}

@article{shakespeare2011development,
  title={The development of the 2-way social support scale: A measure of giving and receiving emotional and instrumental support},
  author={Shakespeare-Finch, Jane and Obst, Patricia L},
  journal={Journal of personality assessment},
  volume={93},
  number={5},
  pages={483--490},
  year={2011},
  publisher={Taylor \& Francis}
}

@article{antoniou2017data,
  title={Data augmentation generative adversarial networks},
  author={Antoniou, Antreas and Storkey, Amos and Edwards, Harrison},
  journal={arXiv preprint arXiv:1711.04340},
  year={2017}
}

@inproceedings{bach2004multiple,
  title={Multiple kernel learning, conic duality, and the SMO algorithm},
  author={Bach, Francis R and Lanckriet, Gert RG and Jordan, Michael I},
  booktitle={Proceedings of the twenty-first international conference on Machine learning},
  pages={6},
  year={2004}
}

@article{gretton2009covariate,
  title={Covariate shift by kernel mean matching},
  author={Gretton, Arthur and Smola, Alex and Huang, Jiayuan and Schmittfull, Marcel and Borgwardt, Karsten and Sch{\""o}lkopf, Bernhard},
  journal={Dataset shift in machine learning},
  volume={3},
  number={4},
  pages={5},
  year={2009}
}

@inproceedings{pan2010cross,
  title={Cross-domain sentiment classification via spectral feature alignment},
  author={Pan, Sinno Jialin and Ni, Xiaochuan and Sun, Jian-Tao and Yang, Qiang and Chen, Zheng},
  booktitle={Proceedings of the 19th international conference on World wide web},
  pages={751--760},
  year={2010}
}

@inproceedings{wang2017balanced,
  title={Balanced distribution adaptation for transfer learning},
  author={Wang, Jindong and Chen, Yiqiang and Hao, Shuji and Feng, Wenjie and Shen, Zhiqi},
  booktitle={2017 IEEE international conference on data mining (ICDM)},
  pages={1129--1134},
  year={2017},
  organization={IEEE}
}

@article{motiian2017few,
  title={Few-shot adversarial domain adaptation},
  author={Motiian, Saeid and Jones, Quinn and Iranmanesh, Seyed and Doretto, Gianfranco},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}


@article{zhu2020deep,
  title={Deep subdomain adaptation network for image classification},
  author={Zhu, Yongchun and Zhuang, Fuzhen and Wang, Jindong and Ke, Guolin and Chen, Jingwu and Bian, Jiang and Xiong, Hui and He, Qing},
  journal={IEEE transactions on neural networks and learning systems},
  volume={32},
  number={4},
  pages={1713--1722},
  year={2020},
  publisher={IEEE}
}

@inproceedings{yu2019transfer,
  title={Transfer learning with dynamic adversarial adaptation network},
  author={Yu, Chaohui and Wang, Jindong and Chen, Yiqiang and Huang, Meiyu},
  booktitle={2019 IEEE International Conference on Data Mining (ICDM)},
  pages={778--786},
  year={2019},
  organization={IEEE}
}

@inproceedings{dai2007boosting,
  title={Boosting for transfer learning},
  author={Dai Wenyuan, Yang Qiang and Guirong, Xue and Yong, Yu},
  booktitle={Proceedings of the 24th International Conference on Machine Learning, Corvallis, USA},
  pages={193--200},
  year={2007}
}

@inproceedings{yang2007adapting,
  title={Adapting SVM classifiers to data with shifted distributions},
  author={Yang, Jun and Yan, Rong and Hauptmann, Alexander G},
  booktitle={Seventh IEEE international conference on data mining workshops (ICDMW 2007)},
  pages={69--76},
  year={2007},
  organization={IEEE}
}

@article{hsu2018unsupervised,
  title={Unsupervised learning via meta-learning},
  author={Hsu, Kyle and Levine, Sergey and Finn, Chelsea},
  journal={arXiv preprint arXiv:1810.02334},
  year={2018}
}

@article{ren2018meta,
  title={Meta-learning for semi-supervised few-shot classification},
  author={Ren, Mengye and Triantafillou, Eleni and Ravi, Sachin and Snell, Jake and Swersky, Kevin and Tenenbaum, Joshua B and Larochelle, Hugo and Zemel, Richard S},
  journal={arXiv preprint arXiv:1803.00676},
  year={2018}
}

@article{perski2017conceptualising,
  title={Conceptualising engagement with digital behaviour change interventions: a systematic review using principles from critical interpretive synthesis},
  author={Perski, Olga and Blandford, Ann and West, Robert and Michie, Susan},
  journal={Translational behavioral medicine},
  volume={7},
  number={2},
  pages={254--267},
  year={2017},
  publisher={Oxford University Press}
}

@article{kramer2019investigating,
  title={Investigating intervention components and exploring states of receptivity for a smartphone app to promote physical activity: Protocol of a microrandomized trial},
  author={Kramer, Jan-Niklas and K{\"u}nzler, Florian and Mishra, Varun and Presset, Bastien and Kotz, David and Smith, Shawna and Scholz, Urte and Kowatsch, Tobias},
  journal={JMIR research protocols},
  volume={8},
  number={1},
  pages={e11540},
  year={2019},
  publisher={JMIR Publications Inc., Toronto, Canada}
}

@inproceedings{khot2015tastybeats,
  title={Tastybeats: Designing palatable representations of physical activity},
  author={Khot, Rohit Ashok and Lee, Jeewon and Aggarwal, Deepti and Hjorth, Larissa and Mueller, Florian'Floyd'},
  booktitle={Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
  pages={2933--2942},
  year={2015}
}

@inproceedings{lochtefeld_appdetox_2013,
	address = {New York, NY, USA},
	series = {{MUM} '13},
	title = {{AppDetox}: helping users with mobile app addiction},
	isbn = {978-1-4503-2648-3},
	shorttitle = {{AppDetox}},
	url = {https://doi.org/10.1145/2541831.2541870},
	doi = {10.1145/2541831.2541870},
	abstract = {With the increasing adoption of smartphones also a problematic phenomena become apparent: People are changing their habits and become addicted to different services that these devices provide. In this paper we present AppDetox: an app that allows users to purposely create rules that keep them from using certain apps. We describe our deployment of the app on a mobile application store, and present initial findings gained through observation of about 11,700 users of the application. We find that people are rather rigorous when restricting their app use, and that mostly they suppress use of social networking and messaging apps.},
	urldate = {2021-01-22},
	booktitle = {Proceedings of the 12th {International} {Conference} on {Mobile} and {Ubiquitous} {Multimedia}},
	publisher = {Association for Computing Machinery},
	author = {Löchtefeld, Markus and Böhmer, Matthias and Ganev, Lyubomir},
	month = dec,
	year = {2013},
	keywords = {smartphone use, 干预, apps, digital detox, technology addiction},
	pages = {1--2},
	file = {Löchtefeld 等。 - 2013 - AppDetox helping users with mobile app addiction.pdf:/Users/yanzhang/Zotero/storage/BIGT29CJ/Löchtefeld 等。 - 2013 - AppDetox helping users with mobile app addiction.pdf:application/pdf},
}

@article{frankish_dual-process_2010,
	title = {Dual-{Process} and {Dual}-{System} {Theories} of {Reasoning}},
	volume = {5},
	issn = {1747-9991},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1747-9991.2010.00330.x},
	doi = {https://doi.org/10.1111/j.1747-9991.2010.00330.x},
	abstract = {Dual-process theories hold that there are two distinct processing modes available for many cognitive tasks: one (type 1) that is fast, automatic and non-conscious, and another (type 2) that is slow, controlled and conscious. Typically, cognitive biases are attributed to type 1 processes, which are held to be heuristic or associative, and logical responses to type 2 processes, which are characterised as rule-based or analytical. Dual-system theories go further and assign these two types of process to two separate reasoning systems, System 1 and System 2 – a view sometimes described as ‘the two minds hypothesis’. It is often claimed that System 2 is uniquely human and the source of our capacity for abstract and hypothetical thinking. This study is an introduction to dual-process and dual-system theories. It looks at some precursors, surveys key work in the fields of learning, reasoning, social cognition and decision making, and identifies some recent trends and philosophical applications.},
	language = {en},
	number = {10},
	urldate = {2021-04-07},
	journal = {Philosophy Compass},
	author = {Frankish, Keith},
	year = {2010},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1747-9991.2010.00330.x},
	pages = {914--926},
}

@article{locke2006new,
  title={New directions in goal-setting theory},
  author={Locke, Edwin A and Latham, Gary P},
  journal={Current directions in psychological science},
  volume={15},
  number={5},
  pages={265--268},
  year={2006},
  publisher={SAGE Publications Sage CA: Los Angeles, CA}
}

@article{yardley2016understanding,
  title={Understanding and promoting effective engagement with digital behavior change interventions},
  author={Yardley, Lucy and Spring, Bonnie J and Riper, Heleen and Morrison, Leanne G and Crane, David H and Curtis, Kristina and Merchant, Gina C and Naughton, Felix and Blandford, Ann},
  journal={American journal of preventive medicine},
  volume={51},
  number={5},
  pages={833--842},
  year={2016},
  publisher={Elsevier}
}

@article{sawesi2016impact,
  title={The impact of information technology on patient engagement and health behavior change: a systematic review of the literature},
  author={Sawesi, Suhila and Rashrash, Mohamed and Phalakornkule, Kanitha and Carpenter, Janet S and Jones, Josette F},
  journal={JMIR medical informatics},
  volume={4},
  number={1},
  pages={e4514},
  year={2016},
  publisher={JMIR Publications Inc., Toronto, Canada}
}

@article{orji2018persuasive,
  title={Persuasive technology for health and wellness: State-of-the-art and emerging trends},
  author={Orji, Rita and Moffatt, Karyn},
  journal={Health informatics journal},
  volume={24},
  number={1},
  pages={66--91},
  year={2018},
  publisher={SAGE Publications Sage UK: London, England}
}

@article{gulcehre2017integrating,
  title={On integrating a language model into neural machine translation},
  author={Gulcehre, Caglar and Firat, Orhan and Xu, Kelvin and Cho, Kyunghyun and Bengio, Yoshua},
  journal={Computer Speech \& Language},
  volume={45},
  pages={137--148},
  year={2017},
  publisher={Elsevier}
}

@article{brants2007large,
  title={Large language models in machine translation},
  author={Brants, Thorsten and Popat, Ashok C and Xu, Peng and Och, Franz J and Dean, Jeffrey},
  year={2007}
}

@article{omar2023chatgpt,
  title={Chatgpt versus traditional question answering for knowledge graphs: Current status and future directions towards knowledge graph chatbots},
  author={Omar, Reham and Mangukiya, Omij and Kalnis, Panos and Mansour, Essam},
  journal={arXiv preprint arXiv:2302.06466},
  year={2023}
}

@inproceedings{
robinson2023leveraging,
title={Leveraging Large Language Models for Multiple Choice Question Answering},
author={Joshua Robinson and David Wingate},
booktitle={The Eleventh International Conference on Learning Representations },
year={2023},
url={https://openreview.net/forum?id=yKbprarjc5B}
}


@article{eichstaedt2018facebook,
  title={Facebook language predicts depression in medical records},
  author={Eichstaedt, Johannes C and Smith, Robert J and Merchant, Raina M and Ungar, Lyle H and Crutchley, Patrick and Preo{\c{t}}iuc-Pietro, Daniel and Asch, David A and Schwartz, H Andrew},
  journal={Proceedings of the National Academy of Sciences},
  volume={115},
  number={44},
  pages={11203--11208},
  year={2018},
  publisher={National Acad Sciences}
}


@article{tadesse2019detection,
  title={Detection of depression-related posts in reddit social media forum},
  author={Tadesse, Michael M and Lin, Hongfei and Xu, Bo and Yang, Liang},
  journal={IEEE Access},
  volume={7},
  pages={44883--44893},
  year={2019},
  publisher={IEEE}
}

@inproceedings{guntuku2019understanding,
  title={Understanding and measuring psychological stress using social media},
  author={Guntuku, Sharath Chandra and Buffone, Anneke and Jaidka, Kokil and Eichstaedt, Johannes C and Ungar, Lyle H},
  booktitle={Proceedings of the international AAAI conference on web and social media},
  volume={13},
  pages={214--225},
  year={2019}
}

@article{nijhawan2022stress,
  title={Stress detection using natural language processing and machine learning over social interactions},
  author={Nijhawan, Tanya and Attigeri, Girija and Ananthakrishna, T},
  journal={Journal of Big Data},
  volume={9},
  number={1},
  pages={1--24},
  year={2022},
  publisher={SpringerOpen}
}

@article{coppersmith2018natural,
  title={Natural language processing of social media as screening for suicide risk},
  author={Coppersmith, Glen and Leary, Ryan and Crutchley, Patrick and Fine, Alex},
  journal={Biomedical informatics insights},
  volume={10},
  pages={1178222618792860},
  year={2018},
  publisher={SAGE Publications Sage UK: London, England}
}

@inproceedings{sharma2018mental,
  title={Mental health support and its relationship to linguistic accommodation in online communities},
  author={Sharma, Eva and De Choudhury, Munmun},
  booktitle={Proceedings of the 2018 CHI conference on human factors in computing systems},
  pages={1--13},
  year={2018}
}

@inproceedings{gkotsis2016language,
  title={The language of mental health problems in social media},
  author={Gkotsis, George and Oellrich, Anika and Hubbard, Tim and Dobson, Richard and Liakata, Maria and Velupillai, Sumithra and Dutta, Rina},
  booktitle={Proceedings of the third workshop on computational linguistics and clinical psychology},
  pages={63--73},
  year={2016}
}

@article{graham2019artificial,
  title={Artificial intelligence for mental health and mental illnesses: an overview},
  author={Graham, Sarah and Depp, Colin and Lee, Ellen E and Nebeker, Camille and Tu, Xin and Kim, Ho-Cheol and Jeste, Dilip V},
  journal={Current psychiatry reports},
  volume={21},
  pages={1--18},
  year={2019},
  publisher={Springer}
}

@inproceedings{patel2018psyheal,
  title={PsyHeal: An Approach to Remote Mental Health Monitoring System},
  author={Patel, Vivek and Mishra, Piyush and Patni, JC},
  booktitle={2018 International Conference on Advances in Computing and Communication Engineering (ICACCE)},
  pages={384--393},
  year={2018},
  organization={IEEE}
}

@article{denecke2020mental,
  title={A mental health chatbot for regulating emotions (SERMO)-concept and usability test},
  author={Denecke, Kerstin and Vaaheesan, Sayan and Arulnathan, Aaganya},
  journal={IEEE Transactions on Emerging Topics in Computing},
  volume={9},
  number={3},
  pages={1170--1182},
  year={2020},
  publisher={IEEE}
}

@article{abd2021perceptions,
  title={Perceptions and opinions of patients about mental health chatbots: scoping review},
  author={Abd-Alrazaq, Alaa A and Alajlani, Mohannad and Ali, Nashva and Denecke, Kerstin and Bewick, Bridgette M and Househ, Mowafa},
  journal={Journal of medical Internet research},
  volume={23},
  number={1},
  pages={e17828},
  year={2021},
  publisher={JMIR Publications Inc., Toronto, Canada}
}

@article{taori2023stanford,
  title={Stanford alpaca: An instruction-following llama model},
  author={Taori, Rohan and Gulrajani, Ishaan and Zhang, Tianyi and Dubois, Yann and Li, Xuechen and Guestrin, Carlos and Liang, Percy and Hashimoto, Tatsunori B},
  journal={GitHub repository},
  year={2023}
}

@article{wei2021finetuned,
  title={Finetuned language models are zero-shot learners},
  author={Wei, Jason and Bosma, Maarten and Zhao, Vincent Y and Guu, Kelvin and Yu, Adams Wei and Lester, Brian and Du, Nan and Dai, Andrew M and Le, Quoc V},
  journal={arXiv preprint arXiv:2109.01652},
  year={2021}
}

@article{dang2022prompt,
  title={How to prompt? Opportunities and challenges of zero-and few-shot learning for human-AI interaction in creative applications of generative models},
  author={Dang, Hai and Mecke, Lukas and Lehmann, Florian and Goller, Sven and Buschek, Daniel},
  journal={arXiv preprint arXiv:2209.01390},
  year={2022}
}

@inproceedings{agrawal2022large,
  title={Large language models are few-shot clinical information extractors},
  author={Agrawal, Monica and Hegselmann, Stefan and Lang, Hunter and Kim, Yoon and Sontag, David},
  booktitle={Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing},
  pages={1998--2022},
  year={2022}
}

@article{xu2021raise,
  title={Raise a child in large language model: Towards effective and generalizable fine-tuning},
  author={Xu, Runxin and Luo, Fuli and Zhang, Zhiyuan and Tan, Chuanqi and Chang, Baobao and Huang, Songfang and Huang, Fei},
  journal={arXiv preprint arXiv:2109.05687},
  year={2021}
}

@article{huang2022large,
  title={Large language models can self-improve},
  author={Huang, Jiaxin and Gu, Shixiang Shane and Hou, Le and Wu, Yuexin and Wang, Xuezhi and Yu, Hongkun and Han, Jiawei},
  journal={arXiv preprint arXiv:2210.11610},
  year={2022}
}

@article{ahmed2022machine,
  title={Machine learning models to detect anxiety and depression through social media: A scoping review},
  author={Ahmed, Arfan and Aziz, Sarah and Toro, Carla T and Alzubaidi, Mahmood and Irshaidat, Sara and Serhan, Hashem Abu and Abd-Alrazaq, Alaa A and Househ, Mowafa},
  journal={Computer Methods and Programs in Biomedicine Update},
  pages={100066},
  year={2022},
  publisher={Elsevier}
}

@article{saifullah2021comparison,
  title={Comparison of machine learning for sentiment analysis in detecting anxiety based on social media data},
  author={Saifullah, Shoffan and Fauziah, Yuli and Aribowo, Agus Sasmito},
  journal={arXiv preprint arXiv:2101.06353},
  year={2021}
}

@article{nguyen2014affective,
  title={Affective and content analysis of online depression communities},
  author={Nguyen, Thin and Phung, Dinh and Dao, Bo and Venkatesh, Svetha and Berk, Michael},
  journal={IEEE transactions on affective computing},
  volume={5},
  number={3},
  pages={217--226},
  year={2014},
  publisher={IEEE}
}

@article{moreno2011feeling,
  title={Feeling bad on Facebook: Depression disclosures by college students on a social networking site},
  author={Moreno, Megan A and Jelenchick, Lauren A and Egan, Katie G and Cox, Elizabeth and Young, Henry and Gannon, Kerry E and Becker, Tara},
  journal={Depression and anxiety},
  volume={28},
  number={6},
  pages={447--455},
  year={2011},
  publisher={Wiley Online Library}
}

@article{birnbaum2017collaborative,
  title={A collaborative approach to identifying social media markers of schizophrenia by employing machine learning and clinical appraisals},
  author={Birnbaum, Michael L and Ernala, Sindhu Kiranmai and Rizvi, Asra F and De Choudhury, Munmun and Kane, John M},
  journal={Journal of medical Internet research},
  volume={19},
  number={8},
  pages={e7956},
  year={2017},
  publisher={JMIR Publications Inc., Toronto, Canada}
}

@article{ji2018supervised,
  title={Supervised learning for suicidal ideation detection in online user content},
  author={Ji, Shaoxiong and Yu, Celina Ping and Fung, Sai-fu and Pan, Shirui and Long, Guodong},
  journal={Complexity},
  volume={2018},
  year={2018},
  publisher={Hindawi}
}

@inproceedings{sawhney2018exploring,
  title={Exploring and learning suicidal ideation connotations on social media with deep learning},
  author={Sawhney, Ramit and Manchanda, Prachi and Mathur, Puneet and Shah, Rajiv and Singh, Raj},
  booktitle={Proceedings of the 9th workshop on computational approaches to subjectivity, sentiment and social media analysis},
  pages={167--175},
  year={2018}
}

@inproceedings{jiang2020detection,
  title={Detection of mental health from reddit via deep contextualized representations},
  author={Jiang, Zheng Ping and Levitan, Sarah Ita and Zomick, Jonathan and Hirschberg, Julia},
  booktitle={Proceedings of the 11th international workshop on health text mining and information analysis},
  pages={147--156},
  year={2020}
}


@article{nguyen2022improving,
  title={Improving the generalizability of depression detection by leveraging clinical questionnaires},
  author={Nguyen, Thong and Yates, Andrew and Zirikly, Ayah and Desmet, Bart and Cohan, Arman},
  journal={arXiv preprint arXiv:2204.10432},
  year={2022}
}

@article{han2022hierarchical,
  title={Hierarchical attention network for explainable depression detection on Twitter aided by metaphor concept mappings},
  author={Han, Sooji and Mao, Rui and Cambria, Erik},
  journal={arXiv preprint arXiv:2209.07494},
  year={2022}
}

@article{qin2023chatgpt,
  title={Is ChatGPT a general-purpose natural language processing task solver?},
  author={Qin, Chengwei and Zhang, Aston and Zhang, Zhuosheng and Chen, Jiaao and Yasunaga, Michihiro and Yang, Diyi},
  journal={arXiv preprint arXiv:2302.06476},
  year={2023}
}

@article{kocon2023chatgpt,
  title={ChatGPT: Jack of all trades, master of none},
  author={Koco{\'n}, Jan and Cichecki, Igor and Kaszyca, Oliwier and Kochanek, Mateusz and Szyd{\l}o, Dominika and Baran, Joanna and Bielaniewicz, Julita and Gruza, Marcin and Janz, Arkadiusz and Kanclerz, Kamil and others},
  journal={Information Fusion},
  pages={101861},
  year={2023},
  publisher={Elsevier}
}

@article{zhong2023can,
  title={Can chatgpt understand too? a comparative study on chatgpt and fine-tuned bert},
  author={Zhong, Qihuang and Ding, Liang and Liu, Juhua and Du, Bo and Tao, Dacheng},
  journal={arXiv preprint arXiv:2302.10198},
  year={2023}
}

@article{regier2013dsm,
  title={The DSM-5: Classification and criteria changes},
  author={Regier, Darrel A and Kuhl, Emily A and Kupfer, David J},
  journal={World psychiatry},
  volume={12},
  number={2},
  pages={92--98},
  year={2013},
  publisher={Wiley Online Library}
}

@article{posner2008columbia,
  title={Columbia-suicide severity rating scale (C-SSRS)},
  author={Posner, K and Brent, D and Lucas, C and Gould, M and Stanley, B and Brown, G and Fisher, P and Zelazny, J and Burke, A and Oquendo, MJNY and others},
  journal={New York, NY: Columbia University Medical Center},
  volume={10},
  pages={2008},
  year={2008}
}

@article{otsukadiagnosing,
  title={Diagnosing Psychiatric Disorders from History of Present Illness Using a Large-Scale Linguistic Model},
  author={Otsuka, Norio and Kawanishi, Yuu and Doi, Fumimaro and Takeda, Tsutomu and Okumura, Kazuki and Yamauchi, Takahira and Yada, Shuntaro and Wakamiya, Shoko and Aramaki, Eiji and Makinodan, Manabu},
  journal={Psychiatry and Clinical Neurosciences},
  publisher={Wiley Online Library}
}

@misc{Hoover_2023, title={An eating disorder chatbot is suspended for giving harmful advice}, url={https://www.wired.com/story/tessa-chatbot-suspended/}, journal={Wired}, publisher={Conde Nast}, author={Hoover, Amanda}, year={2023}, month={Jun}} 

@article{rumshisky2016predicting,
  title={Predicting early psychiatric readmission with natural language processing of narrative discharge summaries},
  author={Rumshisky, Anna and Ghassemi, Marzyeh and Naumann, Tristan and Szolovits, Peter and Castro, VM and McCoy, TH and Perlis, RH},
  journal={Translational psychiatry},
  volume={6},
  number={10},
  pages={e921--e921},
  year={2016},
  publisher={Nature Publishing Group}
}

@article{ntoutsi2020bias,
  title={Bias in data-driven artificial intelligence systems—An introductory survey},
  author={Ntoutsi, Eirini and Fafalios, Pavlos and Gadiraju, Ujwal and Iosifidis, Vasileios and Nejdl, Wolfgang and Vidal, Maria-Esther and Ruggieri, Salvatore and Turini, Franco and Papadopoulos, Symeon and Krasanakis, Emmanouil and others},
  journal={Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery},
  volume={10},
  number={3},
  pages={e1356},
  year={2020},
  publisher={Wiley Online Library}
}

@inproceedings{gemalmaz2021accounting,
  title={Accounting for Confirmation Bias in Crowdsourced Label Aggregation.},
  author={Gemalmaz, Meric Altug and Yin, Ming},
  booktitle={IJCAI},
  pages={1729--1735},
  year={2021}
}

@article{pessach2022review,
  title={A review on fairness in machine learning},
  author={Pessach, Dana and Shmueli, Erez},
  journal={ACM Computing Surveys (CSUR)},
  volume={55},
  number={3},
  pages={1--44},
  year={2022},
  publisher={ACM New York, NY}
}

@article{benton2017multi,
  title={Multi-task learning for mental health using social media text},
  author={Benton, Adrian and Mitchell, Margaret and Hovy, Dirk},
  journal={arXiv preprint arXiv:1712.03538},
  year={2017}
}

@inproceedings{sarkar2022predicting,
  title={Predicting depression and anxiety on reddit: a multi-task learning approach},
  author={Sarkar, Shailik and Alhamadani, Abdulaziz and Alkulaib, Lulwah and Lu, Chang-Tien},
  booktitle={2022 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining (ASONAM)},
  pages={427--435},
  year={2022},
  organization={IEEE}
}

@article{ghosh2023chatgpt,
  title={ChatGPT Perpetuates Gender Bias in Machine Translation and Ignores Non-Gendered Pronouns: Findings across Bengali and Five other Low-Resource Languages},
  author={Ghosh, Sourojit and Caliskan, Aylin},
  journal={arXiv preprint arXiv:2305.10510},
  year={2023}
}

@inproceedings{abid2021persistent,
  title={Persistent anti-muslim bias in large language models},
  author={Abid, Abubakar and Farooqi, Maheen and Zou, James},
  booktitle={Proceedings of the 2021 AAAI/ACM Conference on AI, Ethics, and Society},
  pages={298--306},
  year={2021}
}

@article{timmons2022call,
  title={A Call to Action on Assessing and Mitigating Bias in Artificial Intelligence Applications for Mental Health},
  author={Timmons, Adela C and Duong, Jacqueline B and Simo Fiallo, Natalia and Lee, Theodore and Vo, Huong Phuc Quynh and Ahle, Matthew W and Comer, Jonathan S and Brewer, LaPrincess C and Frazier, Stacy L and Chaspari, Theodora},
  journal={Perspectives on Psychological Science},
  pages={17456916221134490},
  year={2022},
  publisher={SAGE Publications Sage CA: Los Angeles, CA}
}

@article{lovejoy2019technology,
  title={Technology and mental health: the role of artificial intelligence},
  author={Lovejoy, Christopher A},
  journal={European Psychiatry},
  volume={55},
  pages={1--3},
  year={2019},
  publisher={Cambridge University Press}
}

@article{10.1145/3130960,
author = {Saha, Koustuv and Chan, Larry and De Barbaro, Kaya and Abowd, Gregory D. and De Choudhury, Munmun},
title = {Inferring Mood Instability on Social Media by Leveraging Ecological Momentary Assessments},
year = {2017},
issue_date = {September 2017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {1},
number = {3},
url = {https://doi.org/10.1145/3130960},
doi = {10.1145/3130960},
abstract = {Active and passive sensing technologies are providing powerful mechanisms to track, model, and understand a range of health behaviors and well-being states. Despite yielding rich, dense and high fidelity data, current sensing technologies often require highly engineered study designs and persistent participant compliance, making them difficult to scale to large populations and to data acquisition tasks spanning extended time periods. This paper situates social media as a new passive, unobtrusive sensing technology. We propose a semi-supervised machine learning framework to combine small samples of data gathered through active sensing, with large-scale social media data to infer mood instability (MI) in individuals. Starting from a theoretically-grounded measure of MI obtained from mobile ecological momentary assessments (EMAs), we show that our model is able to infer MI in a large population of Twitter users with 96\% accuracy and F-1 score. Additionally, we show that, our model predicts self-identifying Twitter users with bipolar and borderline personality disorder to exhibit twice the likelihood of high MI, compared to that in a suitable control. We discuss the implications and the potential for integrating complementary sensing capabilities to address complex research challenges in precision medicine.},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = {sep},
articleno = {95},
numpages = {27},
keywords = {Twitter, Affect, Health, Affective Instability, Mood, Ecological Momentary Assessments, Social media, Mental Well-Being, EMA, Mood Instability}
}