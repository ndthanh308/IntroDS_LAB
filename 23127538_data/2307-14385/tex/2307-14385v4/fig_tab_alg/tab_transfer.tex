
\begin{table}[b]
\centering
\caption{
Balanced Accuracy Cross-Dataset Performance Summary of Mental-Alpaca Finetuning on Single Dataset.
\fbox{Numbers} indicate the results of the model finetuned and tested on the same dataset.
The bottom few rows are related Alpaca versions for reference. \upgreen{$\uparrow$}/\downred{$\downarrow$} marks the ones with better/worse cross-dataset performance compared to the zero-shot version Alpaca$_{ZS}$.
}
\vspace{-0.3cm}
\label{tab:results_transfer}
\resizebox{0.75\textwidth}{!}{
\begin{tabular}{lcccccc}
\thickhlinespace
\makecell[r]{\textbf{Test Dataset}} & \textbf{Dreaddit} & \multicolumn{2}{c}{\textbf{DepSeverity}} & \textbf{SDCNL} & \multicolumn{2}{c}{\textbf{CSSRS-Suicide}} \\ \addlinespace[1ex]
\textbf{Finetune Dataset}   & \textbf{Task \#1}       & \textbf{Task \#2}             & \textbf{Task \#3}             & \textbf{Task \#4}    & \textbf{Task \#5}     & \textbf{Task \#6} \\ \thickhlinespace
Dreaddit & \fbox{0.823} & \upgreen{ $\uparrow$}  0.720 & \upgreen{ $\uparrow$} 0.623                      & \downred{ $\downarrow$} 0.474 & \upgreen{ $\uparrow$} 0.720                      & \downred{ $\downarrow$}  0.156                      \\ 
DepSeverity                   & \upgreen{ $\uparrow$}  0.618 & \fbox{0.733} & \fbox{0.769} & $|$ 0.493 & \upgreen{ $\uparrow$} 0.753                      & \downred{ $\downarrow$} 0.156                      \\ 
SDCNL                         & \downred{ $\downarrow$} 0.468                      & \downred{ $\downarrow$} 0.461 & \upgreen{ $\uparrow$} 0.623 & \fbox{0.730} & \upgreen{ $\uparrow$} 0.573 & \downred{ $\downarrow$} 0.156                      \\
CSSRS-Suicide                 & \downred{ $\downarrow$} 0.500                      & \downred{ $\downarrow$} 0.500 & \upgreen{ $\uparrow$} 0.622                      & \upgreen{ $\uparrow$}  0.500 & \fbox{0.753} & \fbox{0.578} \\  \hdashlinespace
\textit{Reference:} & &&&&&\\
Alpaca$_{ZS}$       & 0.593 & 0.522 & 0.431 & 0.493 & 0.518 & 0.232 \\ 
% GPT-3.5$_{ZS}$ & 0.685 & 0.642 & 0.603 & 0.460 & 0.570  & 0.233 \\
% Mental-RoBERTa    & 0.831 & 0.790  & 0.736 & 0.723 & 0.853 & 0.373 \\
Mental-Alpaca    & 0.816 & 0.775 & 0.746 & 0.724 & 0.730 & 0.403 \\
\thickhlinespace
\end{tabular}
}
\end{table}