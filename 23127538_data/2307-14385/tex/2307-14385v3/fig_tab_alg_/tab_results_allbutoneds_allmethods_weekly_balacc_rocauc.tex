% \renewcommand{\arraystretch}{1.3}
\begin{table}[b]
\centering
\caption{Model Performance of Predicting Weekly Depression Status across Datasets. Models are tested on one dataset after being trained on all other datasets. The Adv column indicates the advantage compared to the majority baseline. \review{$+$ or $-$ indicates the algorithm has at least one or no metric better than the baseline, with t-test statistical significance: $p< 0.1$\footnotesize{$^{\bullet}$}\normalsize{ (marginal significance), $<0.05^{*}$, $<0.01^{**}$, and $<0.001^{***}$.}}}
% \begin{minipage}[t]{0.48\textwidth}
\resizebox{1\textwidth}{!}{
\begin{tabular}[t]{l|ccccc|ccccc|l}

%%% Holder of the title columns %%%
% \multirow{2}{*}{\textbf{Model}} & \multicolumn{5}{c|}{\textbf{Balanced Accuracy}} & \multicolumn{5}{c}{\textbf{ROC AUC}}\\ \cline{2-11}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\hline \hline
\multirow{2}{*}{\textbf{Model}} & \multicolumn{5}{c|}{\textbf{Balanced Accuracy}} & \multicolumn{5}{c|}{\textbf{ROC AUC}} & \multicolumn{1}{c}{\multirow{2}{*}{\textbf{Adv}}} \\ \cline{2-11}
& \textbf{DS1} & \textbf{DS2} & \textbf{DS3} & \textbf{DS4} & \textbf{Avg} & \textbf{DS1} & \textbf{DS2} & \textbf{DS3} & \textbf{DS4} & \textbf{Avg} &\\
\hline
\textit{Majority Baseline}  & 0.500 & 0.500 & 0.500 & 0.500 & 0.500 & 0.500 & 0.500 & 0.500 & 0.500 & 0.500 & \\ \hdashline
Canzian \etal~\cite{canzian_trajectories_2015} & 0.499 & 0.500 & 0.500 & 0.500 & 0.500 & 0.490 & 0.493 & 0.457 & 0.537 & 0.494 & $-$ \\
Saeb \etal~\cite{saeb_mobile_2015} & 0.500 & 0.500 & 0.498 & 0.500 & 0.500 & 0.555 & 0.553 & 0.543 & 0.472 & 0.531 & $+$ \\
Farhan \etal~\cite{farhan_behavior_2016} & 0.517 & 0.489 & 0.509 & 0.489 & 0.501 & 0.509 & 0.472 & 0.483 & 0.493 & 0.489 & $+$ \\
Wahle \etal~\cite{wahle_mobile_2016} & 0.501 & 0.510 & 0.500 & 0.505 & 0.504 & 0.496 & 0.550 & 0.502 & 0.503 & 0.513 & $+$ \\
Lu \etal~\cite{lu_joint_2018} & 0.538 & 0.496 & 0.438 & 0.492 & 0.491 & 0.557 & 0.505 & 0.443 & 0.449 & 0.488 & $+$ \\
Wang \etal~\cite{wang_tracking_2018} & 0.501 & 0.502 & 0.500 & 0.500 & 0.501 & 0.536 & 0.539 & 0.500 & 0.500 & 0.519 & $+$ \\
Xu \etal - Interpretable~\cite{xu_leveraging_2019} & 0.501 & 0.498 & 0.478 & 0.502 & 0.495 & 0.457 & 0.507 & 0.461 & 0.496 & 0.480 & $+$ \\
Xu \etal - Personalized~\cite{xu_leveraging_2021} & 0.502 & 0.491 & 0.500 & 0.513 & 0.501 & 0.511 & 0.485 & 0.479 & 0.536 & 0.503 & $+$ \\
Chikersal \etal~\cite{chikersal_detecting_2021} & 0.545 & 0.503 & 0.523 & 0.508 & 0.520 & 0.590 & 0.525 & 0.526 & 0.523 & 0.541 & $+^{*}$ \\ \hdashline
ERM - 1D-CNN~\cite{vapnik1999overview} & 0.503 & 0.510 & 0.522 & 0.520 & 0.514 & 0.511 & 0.530 & 0.512 & 0.511 & 0.516 & $+^{*}$ \\
ERM - 2D-CNN~\cite{vapnik1999overview} & 0.507 & 0.504 & 0.523 & 0.534 & 0.517 & 0.508 & 0.509 & 0.535 & 0.542 & 0.523 & $+^{*}$\\
ERM - LSTM~\cite{vapnik1999overview} & 0.511 & 0.502 & 0.528 & 0.502 & 0.511 & 0.518 & 0.516 & 0.536 & 0.511 & 0.520 & $+^{*}$\\
ERM - Transformer~\cite{vapnik1999overview} & 0.513 & 0.474 & 0.510 & 0.488 & 0.496 & 0.508 & 0.464 & 0.527 & 0.486 & 0.496 & $-$\\
ERM - Mixup~\cite{zhang_mixup_2018} & 0.517 & 0.505 & 0.519 & 0.513 & 0.514 & 0.512 & 0.522 & 0.513 & 0.520 & 0.517 & $+^{***}$\\
IRM~\cite{arjovsky_invariant_2020} & 0.532 & 0.513 & 0.524 & 0.510 & 0.520 & 0.546 & 0.514 & 0.518 & 0.507 & 0.521 & $+^{**}$\\
DANN - Dataset as Domain~\cite{csurka_domain-adversarial_2017} & 0.499 & 0.500 & 0.500 & 0.500 & 0.500 & 0.501 & 0.510 & 0.465 & 0.506 & 0.496 & $-$\\
DANN - Person as Domain~\cite{csurka_domain-adversarial_2017} & 0.500 & 0.500 & 0.500 & 0.500 & 0.500 & 0.512 & 0.511 & 0.470 & 0.507 & 0.500 & $-$\\
CSD - Dataset as Domain~\cite{piratla_efficient_2020} & 0.517 & 0.530 & 0.504 & 0.494 & 0.511 & 0.519 & 0.530 & 0.516 & 0.504 & 0.517 & $+^{*}$\\
CSD - Person as Domain~\cite{piratla_efficient_2020} & 0.500 & 0.513 & 0.523 & 0.522 & 0.514 & 0.510 & 0.521 & 0.524 & 0.536 & 0.523 & $+^{**}$\\
MLDG - Dataset as Domain~\cite{li_learning_2017} & 0.501 & 0.470 & 0.523 & 0.501 & 0.499 & 0.495 & 0.475 & 0.519 & 0.496 & 0.496 & $-$\\
MLDG - Person as Domain~\cite{li_learning_2017} & 0.499 & 0.522 & 0.498 & 0.483 & 0.501 & 0.509 & 0.539 & 0.512 & 0.488 & 0.512  & $+$ \\
MASF - Dataset as Domain~\cite{dou_domain_2019} & 0.496 & 0.499 & 0.509 & 0.499 & 0.501 & 0.505 & 0.514 & 0.506 & 0.522 & 0.512 & $+^{*}$\\
MASF - Person as Domain~\cite{dou_domain_2019} & 0.507 & 0.507 & 0.489 & 0.498 & 0.500 & 0.508 & 0.502 & 0.485 & 0.523 & 0.504 & $+$\\
Siamese Network~\cite{koch_siamese_2015} & 0.512 & 0.509 & 0.488 & 0.508 & 0.504 & 0.512 & 0.509 & 0.488 & 0.508 & 0.504 & $+$\\ \hdashline
Clustering & 0.518 & 0.505 & 0.499 & 0.517 & 0.510 & 0.522 & 0.502 & 0.497 & 0.521 & 0.511 & $+$\footnotesize{$^{\bullet}$}\\
\textbf{Reorder} & \textbf{0.570} & \textbf{0.546} & \textbf{0.558} & \textbf{0.535} & \textbf{0.552} & \textbf{0.584} & \textbf{0.588} & \textbf{0.580} & \textbf{0.548} & \textbf{0.575} & $+^{***}$\\
\hline \hline
\end{tabular}
}
\label{tab:results_allbutoneds_allmethods_weekly}
% \end{minipage}

% \vspace{0.1cm}
\end{table}
\renewcommand{\arraystretch}{1.0}