% \renewcommand{\arraystretch}{1.3}
\begin{table}[t]
\centering
\caption{Balanced Accuracy Summary of Multiple Evaluation Setups on The Weekly Depression Detection Task. The first column indicates the "optimal" setup. For traditional depression detection models, it is 20-fold cross validation on single dataset. For deep learning models, it is the best epoch selected based on the target dataset.}
\resizebox{1\textwidth}{!}{
\begin{tabular}[t]{L{4.8cm}|C{2.6cm}C{2.6cm}C{2cm}C{2cm}C{2cm}}
\hline \hline
\textbf{Model} & \makecell{\textbf{"Optimal" Setup} \\ \textbf{Single Dataset}} & \makecell{\textbf{Leave-One-}\\\textbf{Dataset-Out}} & \makecell{\textbf{Cross}\\\textbf{Institute}} & \makecell{\textbf{Cross Year}\\\text{ }} & \makecell{\textbf{Cross Year}\\\textbf{Overlapping}} \\
\hline
Canzian \etal~\cite{canzian_trajectories_2015} & 0.525 & 0.500 & 0.498 & 0.499 & 0.518 \\
Saeb \etal~\cite{saeb_mobile_2015} & 0.522 & 0.500 & 0.500 & 0.500 & 0.556 \\
Farhan \etal~\cite{farhan_behavior_2016} & 0.572 & 0.501 & 0.\textbf{510} & 0.505 & 0.492 \\
Wahle \etal~\cite{wahle_mobile_2016} & 0.550 & 0.504 & 0.500 & 0.500 & 0.499 \\
Lu \etal~\cite{lu_joint_2018} & 0.542 & 0.491 & 0.506 & 0.491 & 0.521 \\
Wang \etal~\cite{wang_tracking_2018} & 0.527 & 0.501 & 0.499 & 0.500 & 0.525 \\
Xu \etal - Interpretable~\cite{xu_leveraging_2019} & 0.716 & 0.495 & 0.488 & 0.515 & \textbf{0.581} \\
Xu \etal - Personalized~\cite{xu_leveraging_2021} & 0.733 & 0.501 & 0.506 & \textbf{0.526} & 0.536 \\
Chikersal \etal~\cite{chikersal_detecting_2021} & \textbf{0.749} & \textbf{0.520} & 0.495 & 0.505 & 0.577 \\
\hline \hline
% \end{tabular}
% }
% \\
% \resizebox{1\textwidth}{!}{
% \begin{tabular}[t]{L{4.8cm}|C{2.5cm}C{2.5cm}C{2.5cm}C{2.5cm}C{2.5cm}}
% \hline \hline
\textbf{Model} & \makecell{\textbf{"Optimal" Setup} \\ \textbf{Best Epoch}} & \makecell{\textbf{Leave-One-}\\\textbf{Dataset-Out}} & \makecell{\textbf{Cross}\\\textbf{Institute}} & \makecell{\textbf{Cross Year}\\\text{ }} & \makecell{\textbf{Cross Year}\\\textbf{Overlapping}} \\
\hline
ERM - 1dCNN~\cite{vapnik1999overview} & 0.536 & 0.514 & 0.501 & 0.511 & 0.508 \\
ERM - 2dCNN~\cite{vapnik1999overview} & 0.541 & 0.517 & 0.499 & 0.503 & 0.532 \\
ERM - LSTM~\cite{vapnik1999overview} & 0.531 & 0.511 & 0.507 & 0.520 & 0.531 \\
ERM - Transformer~\cite{vapnik1999overview} & 0.521 & 0.496 & 0.505 & 0.496 & 0.501 \\
ERM - Mixup~\cite{zhang_mixup_2018} & 0.531 & 0.514 & 0.501 & 0.506 & 0.508 \\
IRM~\cite{arjovsky_invariant_2020} & 0.535 & 0.520 & 0.494 & 0.514 & 0.517 \\
DANN - Dataset as Domain~\cite{csurka_domain-adversarial_2017} & 0.500 & 0.500 & 0.500 & 0.500 & 0.525 \\
DANN - Person as Domain~\cite{csurka_domain-adversarial_2017} & 0.500 & 0.500 & 0.500 & 0.500 & 0.511 \\
CSD - Dataset as Domain~\cite{piratla_efficient_2020} & 0.519 & 0.511 & 0.505 & 0.515 & 0.553 \\
CSD - Person as Domain~\cite{piratla_efficient_2020} & 0.534 & 0.514 & 0.513 & 0.506 & 0.544 \\
MLDG - Dataset as Domain~\cite{li_learning_2017} & 0.516 & 0.499 & 0.500 & 0.495 & 0.522 \\
MLDG - Person as Domain~\cite{li_learning_2017} & 0.524 & 0.501 & 0.495 & 0.502 & 0.505 \\
MASF - Dataset as Domain~\cite{dou_domain_2019} & 0.508 & 0.501 & 0.502 & 0.500 & 0.522 \\
MASF - Person as Domain~\cite{dou_domain_2019} & 0.509 & 0.500 & 0.506 & 0.499 & 0.514 \\
Siamese Network~\cite{koch_siamese_2015} & 0.522 & 0.504 & 0.495 & 0.504 & 0.501 \\
Clustering & \textbf{0.595} & 0.510 & 0.515 & 0.492 & 0.483 \\
Reorder & 0.556 & \textbf{0.552} & \textbf{0.519} & \textbf{0.528} & \textbf{0.596} \\
\hline \hline
\end{tabular}
}
\label{tab:results_combined}
% \end{minipage}

% \vspace{0.1cm}
\end{table}
\renewcommand{\arraystretch}{1.0}