@article{akaike1973maximum,
  title={Maximum likelihood identification of Gaussian autoregressive moving average models},
  author={Akaike, Htrotugu},
  journal={Biometrika},
  volume={60},
  number={2},
  pages={255--265},
  year={1973},
  publisher={Oxford University Press}
}

@article{benjamin2003generalized,
  title={Generalized autoregressive moving average models},
  author={Benjamin, Michael A and Rigby, Robert A and Stasinopoulos, D Mikis},
  journal={Journal of the American Statistical association},
  volume={98},
  number={461},
  pages={214--223},
  year={2003},
  publisher={Taylor \& Francis}
}

@ARTICLE{hmm,
  author={Rabiner, L. and Juang, B.},
  journal={IEEE ASSP Magazine}, 
  title={An introduction to hidden Markov models}, 
  year={1986},
  volume={3},
  number={1},
  pages={4-16},
  doi={10.1109/MASSP.1986.1165342}
}
  
 @inproceedings{schuller2003hidden,
  title={Hidden Markov model-based speech emotion recognition},
  author={Schuller, Bj{\"o}rn and Rigoll, Gerhard and Lang, Manfred},
  booktitle={2003 IEEE International Conference on Acoustics, Speech, and Signal Processing, 2003. Proceedings.(ICASSP'03).},
  volume={2},
  pages={II--1},
  year={2003},
  organization={Ieee}
}

@article{
doi:10.1073/pnas.79.8.2554,
author = {J J Hopfield },
title = {Neural networks and physical systems with emergent collective computational abilities.},
journal = {Proceedings of the National Academy of Sciences},
volume = {79},
number = {8},
pages = {2554-2558},
year = {1982},
doi = {10.1073/pnas.79.8.2554},
URL = {https://www.pnas.org/doi/abs/10.1073/pnas.79.8.2554},
eprint = {https://www.pnas.org/doi/pdf/10.1073/pnas.79.8.2554},
abstract = {Computational properties of use of biological organisms or to the construction of computers can emerge as collective properties of systems having a large number of simple equivalent components (or neurons). The physical meaning of content-addressable memory is described by an appropriate phase space flow of the state of a system. A model of such a system is given, based on aspects of neurobiology but readily adapted to integrated circuits. The collective properties of this model produce a content-addressable memory which correctly yields an entire memory from any subpart of sufficient size. The algorithm for the time evolution of the state of the system is based on asynchronous parallel processing. Additional emergent collective properties include some capacity for generalization, familiarity recognition, categorization, error correction, and time sequence retention. The collective properties are only weakly sensitive to details of the modeling or the failure of individual devices.}}

@article{giles1992learning,
  title={Learning and extracting finite state automata with second-order recurrent neural networks},
  author={Giles, C Lee and Miller, Clifford B and Chen, Dong and Chen, Hsing-Hen and Sun, Guo-Zheng and Lee, Yee-Chun},
  journal={Neural Computation},
  volume={4},
  number={3},
  pages={393--405},
  year={1992},
  publisher={MIT Press One Rogers Street, Cambridge, MA 02142-1209, USA journals-info~…}
}
@article{de1992gamma,
  title={The gamma model—A new neural model for temporal processing},
  author={De Vries, Bert and Principe, Jose C},
  journal={Neural networks},
  volume={5},
  number={4},
  pages={565--576},
  year={1992},
  publisher={Elsevier}
}

@article{cho2014properties,
  title={On the properties of neural machine translation: Encoder-decoder approaches},
  author={Cho, Kyunghyun and Van Merri{\"e}nboer, Bart and Bahdanau, Dzmitry and Bengio, Yoshua},
  journal={arXiv preprint arXiv:1409.1259},
  year={2014}
}

@article{ma2019taxonomy,
  title={A taxonomy for neural memory networks},
  author={Ma, Ying and Principe, Jose C},
  journal={IEEE transactions on neural networks and learning systems},
  volume={31},
  number={6},
  pages={1780--1793},
  year={2019},
  publisher={IEEE}
}

@article{hochreiter1997long,
  title={Long short-term memory},
  author={Hochreiter, Sepp and Schmidhuber, J{\"u}rgen},
  journal={Neural computation},
  volume={9},
  number={8},
  pages={1735--1780},
  year={1997},
  publisher={MIT Press}
}


@article{grefenstette2015learning,
  title={Learning to transduce with unbounded memory},
  author={Grefenstette, Edward and Hermann, Karl Moritz and Suleyman, Mustafa and Blunsom, Phil},
  journal={Advances in neural information processing systems},
  volume={28},
  year={2015}
}

@article{graves2014neural,
  title={Neural turing machines},
  author={Graves, Alex and Wayne, Greg and Danihelka, Ivo},
  journal={arXiv preprint arXiv:1410.5401},
  year={2014}
}

@article{graves2016hybrid,
  title={Hybrid computing using a neural network with dynamic external memory},
  author={Graves, Alex and Wayne, Greg and Reynolds, Malcolm and Harley, Tim and Danihelka, Ivo and Grabska-Barwi{\'n}ska, Agnieszka and Colmenarejo, Sergio G{\'o}mez and Grefenstette, Edward and Ramalho, Tiago and Agapiou, John and others},
  journal={Nature},
  volume={538},
  number={7626},
  pages={471--476},
  year={2016},
  publisher={Nature Publishing Group}
}

@inproceedings{kumar2016ask,
  title={Ask me anything: Dynamic memory networks for natural language processing},
  author={Kumar, Ankit and Irsoy, Ozan and Ondruska, Peter and Iyyer, Mohit and Bradbury, James and Gulrajani, Ishaan and Zhong, Victor and Paulus, Romain and Socher, Richard},
  booktitle={International conference on machine learning},
  pages={1378--1387},
  year={2016},
  organization={PMLR}
}

@article{sukhbaatar2015end,
  title={End-to-end memory networks},
  author={Sukhbaatar, Sainbayar and Weston, Jason and Fergus, Rob and others},
  journal={Advances in neural information processing systems},
  volume={28},
  year={2015}
}

@article{sun2017neural,
  title={The neural network pushdown automaton: Model, stack and learning simulations},
  author={Sun, Guo-Zheng and Giles, C Lee and Chen, Hsing-Hen and Lee, Yee-Chun},
  journal={arXiv preprint arXiv:1711.05738},
  year={2017}
}

@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@ARTICLE{193206,

  author={Principe, J.C. and de Vries, B. and de Oliveira, P.G.},

  journal={IEEE Transactions on Signal Processing}, 

  title={The gamma-filter-a new class of adaptive IIR filters with restricted feedback}, 

  year={1993},

  volume={41},

  number={2},

  pages={649-656},

  doi={10.1109/78.193206}}
@article{Liu2006CorrentropyAL,
  title={Correntropy: A Localized Similarity Measure},
  author={Weifeng Liu and Puskal P. Pokharel and Jos{\'e} Carlos Pr{\'i}ncipe},
  journal={The 2006 IEEE International Joint Conference on Neural Network Proceedings},
  year={2006},
  pages={4919-4924}
}

@article{weston2015towards,
  title={Towards ai-complete question answering: A set of prerequisite toy tasks},
  author={Weston, Jason and Bordes, Antoine and Chopra, Sumit and Rush, Alexander M and Van Merri{\"e}nboer, Bart and Joulin, Armand and Mikolov, Tomas},
  journal={arXiv preprint arXiv:1502.05698},
  year={2015}
}

@article{banino2020memo,
  title={Memo: A deep network for flexible combination of episodic memories},
  author={Banino, Andrea and Badia, Adria Puigdomenech and K{\"o}ster, Raphael and Chadwick, Martin J and Zambaldi, Vinicius and Hassabis, Demis and Barry, Caswell and Botvinick, Matthew and Kumaran, Dharshan and Blundell, Charles},
  journal={arXiv preprint arXiv:2001.10913},
  year={2020}
}