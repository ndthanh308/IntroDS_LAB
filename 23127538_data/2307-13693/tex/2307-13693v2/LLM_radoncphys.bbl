\begin{thebibliography}{100}

\bibitem{liu2023summary}
Yiheng Liu, Tianle Han, Siyuan Ma, Jiayue Zhang, Yuanyuan Yang, Jiaming Tian,
  Hao He, Antong Li, Mengshen He, Zhengliang Liu, et~al.
\newblock Summary of chatgpt/gpt-4 research and perspective towards the future
  of large language models.
\newblock {\em arXiv preprint arXiv:2304.01852}, 2023.

\bibitem{zhou2023comprehensive}
Ce~Zhou, Qian Li, Chen Li, Jun Yu, Yixin Liu, Guangjing Wang, Kai Zhang, Cheng
  Ji, Qiben Yan, Lifang He, et~al.
\newblock A comprehensive survey on pretrained foundation models: A history
  from bert to chatgpt.
\newblock {\em arXiv preprint arXiv:2302.09419}, 2023.

\bibitem{holmes2023evaluating}
Jason Holmes, Zhengliang Liu, Lian Zhang, Yuzhen Ding, Terence~T Sio, Lisa~A
  McGee, Jonathan~B Ashman, Xiang Li, Tianming Liu, Jiajian Shen, et~al.
\newblock Evaluating large language models on a highly-specialized topic,
  radiation oncology physics.
\newblock {\em arXiv preprint arXiv:2304.01938}, 2023.

\bibitem{wu2023exploring}
Zihao Wu, Lu~Zhang, Chao Cao, Xiaowei Yu, Haixing Dai, Chong Ma, Zhengliang
  Liu, Lin Zhao, Gang Li, Wei Liu, et~al.
\newblock Exploring the trade-offs: Unified large language models vs local
  fine-tuned models for highly-specific radiology nli task.
\newblock {\em arXiv preprint arXiv:2304.09138}, 2023.

\bibitem{li2023artificial}
Xiang Li, Lu~Zhang, Zihao Wu, Zhengliang Liu, Lin Zhao, Yixuan Yuan, Jun Liu,
  Gang Li, Dajiang Zhu, Pingkuan Yan, et~al.
\newblock Artificial general intelligence for medical imaging.
\newblock {\em arXiv preprint arXiv:2306.05480}, 2023.

\bibitem{rezayi2023exploring}
Saed Rezayi, Zhengliang Liu, Zihao Wu, Chandra Dhakal, Bao Ge, Haixing Dai,
  Gengchen Mai, Ninghao Liu, Chen Zhen, Tianming Liu, et~al.
\newblock Exploring new frontiers in agricultural nlp: Investigating the
  potential of large language models for food applications.
\newblock {\em arXiv preprint arXiv:2306.11892}, 2023.

\bibitem{liu2022survey}
Zhengliang Liu, Mengshen He, Zuowei Jiang, Zihao Wu, Haixing Dai, Lian Zhang,
  Siyi Luo, Tianle Han, Xiang Li, Xi~Jiang, et~al.
\newblock Survey on natural language processing in medical image analysis.
\newblock {\em Zhong nan da xue xue bao. Yi xue ban= Journal of Central South
  University. Medical Sciences}, 47(8):981--993, 2022.

\bibitem{zhao2023brain}
Lin Zhao, Lu~Zhang, Zihao Wu, Yuzhong Chen, Haixing Dai, Xiaowei Yu, Zhengliang
  Liu, Tuo Zhang, Xintao Hu, Xi~Jiang, et~al.
\newblock When brain-inspired ai meets agi.
\newblock {\em arXiv preprint arXiv:2303.15935}, 2023.

\bibitem{brown2020language}
Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared~D Kaplan, Prafulla
  Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell,
  et~al.
\newblock Language models are few-shot learners.
\newblock {\em Advances in neural information processing systems},
  33:1877--1901, 2020.

\bibitem{lund2023chatting}
Brady~D Lund and Ting Wang.
\newblock Chatting about chatgpt: how may ai and gpt impact academia and
  libraries?
\newblock {\em Library Hi Tech News}, 40(3):26--29, 2023.

\bibitem{sallam2023chatgpt}
Malik Sallam.
\newblock Chatgpt utility in healthcare education, research, and practice:
  systematic review on the promising perspectives and valid concerns.
\newblock In {\em Healthcare}, volume~11, page 887. MDPI, 2023.

\bibitem{sallam2023utility}
Malik Sallam.
\newblock The utility of chatgpt as an example of large language models in
  healthcare education, research and practice: Systematic review on the future
  perspectives and potential limitations.
\newblock {\em medRxiv}, pages 2023--02, 2023.

\bibitem{scao2022bloom}
Teven~Le Scao, Angela Fan, Christopher Akiki, Ellie Pavlick, Suzana Ili{\'c},
  Daniel Hesslow, Roman Castagn{\'e}, Alexandra~Sasha Luccioni, Fran{\c{c}}ois
  Yvon, Matthias Gall{\'e}, et~al.
\newblock Bloom: A 176b-parameter open-access multilingual language model.
\newblock {\em arXiv preprint arXiv:2211.05100}, 2022.

\bibitem{touvron2023llama}
Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne
  Lachaux, Timoth{\'e}e Lacroix, Baptiste Rozi{\`e}re, Naman Goyal, Eric
  Hambro, Faisal Azhar, et~al.
\newblock Llama: Open and efficient foundation language models.
\newblock {\em arXiv preprint arXiv:2302.13971}, 2023.

\bibitem{peng2023rwkv}
Bo~Peng, Eric Alcaide, Quentin Anthony, Alon Albalak, Samuel Arcadinho, Huanqi
  Cao, Xin Cheng, Michael Chung, Matteo Grella, Kranthi~Kiran GV, Xuzheng He,
  Haowen Hou, Przemyslaw Kazienko, Jan Kocon, Jiaming Kong, Bartlomiej Koptyra,
  Hayden Lau, Krishna Sri~Ipsit Mantri, Ferdinand Mom, Atsushi Saito, Xiangru
  Tang, Bolun Wang, Johan~S. Wind, Stansilaw Wozniak, Ruichong Zhang, Zhenyuan
  Zhang, Qihang Zhao, Peng Zhou, Jian Zhu, and Rui-Jie Zhu.
\newblock Rwkv: Reinventing rnns for the transformer era, 2023.

\bibitem{eggmann2023implications}
Florin Eggmann, Roland Weiger, Nicola~U Zitzmann, and Markus~B Blatz.
\newblock Implications of large language models such as chatgpt for dental
  medicine.
\newblock {\em Journal of Esthetic and Restorative Dentistry}, 2023.

\bibitem{lievin2022can}
Valentin Li{\'e}vin, Christoffer~Egeberg Hother, and Ole Winther.
\newblock Can large language models reason about medical questions?
\newblock {\em arXiv preprint arXiv:2207.08143}, 2022.

\bibitem{wang2023large}
Yuqing Wang, Yun Zhao, and Linda Petzold.
\newblock Are large language models ready for healthcare? a comparative study
  on clinical language understanding.
\newblock {\em arXiv preprint arXiv:2304.05368}, 2023.

\bibitem{taylor2022galactica}
Ross Taylor, Marcin Kardas, Guillem Cucurull, Thomas Scialom, Anthony
  Hartshorn, Elvis Saravia, Andrew Poulton, Viktor Kerkez, and Robert Stojnic.
\newblock Galactica: A large language model for science.
\newblock {\em arXiv preprint arXiv:2211.09085}, 2022.

\bibitem{singhal2023towards}
Karan Singhal, Tao Tu, Juraj Gottweis, Rory Sayres, Ellery Wulczyn, Le~Hou,
  Kevin Clark, Stephen Pfohl, Heather Cole-Lewis, Darlene Neal, et~al.
\newblock Towards expert-level medical question answering with large language
  models.
\newblock {\em arXiv preprint arXiv:2305.09617}, 2023.

\bibitem{ufuk2023role}
Furkan Ufuk.
\newblock The role and limitations of large language models such as chatgpt in
  clinical settings and medical journalism.
\newblock {\em Radiology}, 307(3):e230276, 2023.

\bibitem{yunxiang2023chatdoctor}
Li~Yunxiang, Li~Zihan, Zhang Kai, Dan Ruilong, and Zhang You.
\newblock Chatdoctor: A medical chat model fine-tuned on llama model using
  medical domain knowledge.
\newblock {\em arXiv preprint arXiv:2303.14070}, 2023.

\bibitem{haupt2023ai}
Claudia~E Haupt and Mason Marks.
\newblock Ai-generated medical advice—gpt and beyond.
\newblock {\em Jama}, 329(16):1349--1350, 2023.

\bibitem{liao2023differentiate}
Wenxiong Liao, Zhengliang Liu, Haixing Dai, Shaochen Xu, Zihao Wu, Yiyang
  Zhang, Xiaoke Huang, Dajiang Zhu, Hongmin Cai, Tianming Liu, et~al.
\newblock Differentiate chatgpt-generated and human-written medical texts.
\newblock {\em arXiv preprint arXiv:2304.11567}, 2023.

\bibitem{dai2023chataug}
Haixing Dai, Zhengliang Liu, Wenxiong Liao, Xiaoke Huang, Zihao Wu, Lin Zhao,
  Wei Liu, Ninghao Liu, Sheng Li, Dajiang Zhu, et~al.
\newblock Chataug: Leveraging chatgpt for text data augmentation.
\newblock {\em arXiv preprint arXiv:2302.13007}, 2023.

\bibitem{liu2023deid}
Zhengliang Liu, Xiaowei Yu, Lu~Zhang, Zihao Wu, Chao Cao, Haixing Dai, Lin
  Zhao, Wei Liu, Dinggang Shen, Quanzheng Li, et~al.
\newblock Deid-gpt: Zero-shot medical text de-identification by gpt-4.
\newblock {\em arXiv preprint arXiv:2303.11032}, 2023.

\bibitem{ma2023impressiongpt}
Chong Ma, Zihao Wu, Jiaqi Wang, Shaochen Xu, Yaonai Wei, Zhengliang Liu, Lei
  Guo, Xiaoyan Cai, Shu Zhang, Tuo Zhang, et~al.
\newblock Impressiongpt: An iterative optimizing framework for radiology report
  summarization with chatgpt.
\newblock {\em arXiv preprint arXiv:2304.08448}, 2023.

\bibitem{rezayi2022clinicalradiobert}
Saed Rezayi, Haixing Dai, Zhengliang Liu, Zihao Wu, Akarsh Hebbar, Andrew~H
  Burns, Lin Zhao, Dajiang Zhu, Quanzheng Li, Wei Liu, et~al.
\newblock Clinicalradiobert: Knowledge-infused few shot learning for clinical
  notes named entity recognition.
\newblock In {\em Machine Learning in Medical Imaging: 13th International
  Workshop, MLMI 2022, Held in Conjunction with MICCAI 2022, Singapore,
  September 18, 2022, Proceedings}, pages 269--278. Springer, 2022.

\bibitem{pons2016natural}
Ewoud Pons, Loes~MM Braun, MG~Myriam Hunink, and Jan~A Kors.
\newblock Natural language processing in radiology: a systematic review.
\newblock {\em Radiology}, 279(2):329--343, 2016.

\bibitem{casey2021systematic}
Arlene Casey, Emma Davidson, Michael Poon, Hang Dong, Daniel Duma, Andreas
  Grivas, Claire Grover, V{\'\i}ctor Su{\'a}rez-Paniagua, Richard Tobin,
  William Whiteley, et~al.
\newblock A systematic review of natural language processing applied to
  radiology reports.
\newblock {\em BMC medical informatics and decision making}, 21(1):179, 2021.

\bibitem{adams2023leveraging}
Lisa~C Adams, Daniel Truhn, Felix Busch, Avan Kader, Stefan~M Niehues, Marcus~R
  Makowski, and Keno~K Bressem.
\newblock Leveraging gpt-4 for post hoc transformation of free-text radiology
  reports into structured reporting: a multilingual feasibility study.
\newblock {\em Radiology}, 307(4):e230725, 2023.

\bibitem{doshi2023utilizing}
Rushabh Doshi, Kanhai Amin, Pavan Khosla, Simar Bajaj, Sophie Chheang, and
  Howard~P Forman.
\newblock Utilizing large language models to simplify radiology reports: a
  comparative analysis of chatgpt3. 5, chatgpt4. 0, google bard, and microsoft
  bing.
\newblock {\em medRxiv}, pages 2023--06, 2023.

\bibitem{lyu2023translating}
Qing Lyu, Josh Tan, Mike~E Zapadka, Janardhana Ponnatapuram, Chuang Niu,
  Ge~Wang, and Christopher~T Whitlow.
\newblock Translating radiology reports into plain language using chatgpt and
  gpt-4 with prompt learning: Promising results, limitations, and potential.
\newblock {\em arXiv preprint arXiv:2303.09038}, 2023.

\bibitem{ali2023using}
Stephen~R Ali, Thomas~D Dobbs, Hayley~A Hutchings, and Iain~S Whitaker.
\newblock Using chatgpt to write patient clinic letters.
\newblock {\em The Lancet Digital Health}, 5(4):e179--e181, 2023.

\bibitem{balagopal2021psa}
Anjali Balagopal, Howard Morgan, Michael Dohopolski, Ramsey Timmerman, Jie
  Shan, Daniel~F Heitjan, Wei Liu, Dan Nguyen, Raquibul Hannan, Aurelie Garant,
  et~al.
\newblock Psa-net: Deep learning--based physician style--aware segmentation
  network for postoperative prostate cancer clinical target volumes.
\newblock {\em Artificial Intelligence in Medicine}, 121:102195, 2021.

\bibitem{liu2023radiology}
Zhengliang Liu, Aoxiao Zhong, Yiwei Li, Longtao Yang, Chao Ju, Zihao Wu, Chong
  Ma, Peng Shu, Cheng Chen, Sekeun Kim, et~al.
\newblock Radiology-gpt: A large language model for radiology.
\newblock {\em arXiv preprint arXiv:2306.08666}, 2023.

\bibitem{zhang2023segment}
Lian Zhang, Zhengliang Liu, Lu~Zhang, Zihao Wu, Xiaowei Yu, Jason Holmes,
  Hongying Feng, Haixing Dai, Xiang Li, Quanzheng Li, et~al.
\newblock Segment anything model (sam) for radiation oncology.
\newblock {\em arXiv preprint arXiv:2306.11730}, 2023.

\bibitem{zhang2023differentiating}
Shu Zhang, Enze Shi, Lin Wu, Ruoyang Wang, Sigang Yu, Zhengliang Liu, Shaochen
  Xu, Tianming Liu, and Shijie Zhao.
\newblock Differentiating brain states via multi-clip random fragment
  strategy-based interactive bidirectional recurrent neural network.
\newblock {\em Neural Networks}, 2023.

\bibitem{zhang2023beam}
Lian Zhang, Jason~M Holmes, Zhengliang Liu, Sujay~A Vora, Terence~T Sio,
  Carlos~E Vargas, Nathan~Y Yu, Sameer~R Keole, Steven~E Schild, Martin Bues,
  et~al.
\newblock Beam mask and sliding window-facilitated deep learning-based accurate
  and efficient dose prediction for pencil beam scanning proton therapy.
\newblock {\em arXiv preprint arXiv:2305.18572}, 2023.

\bibitem{zhou2023fine}
Mengyue Zhou, Xu~Liu, David Liu, Zihao Wu, Zhengliang Liu, Lin Zhao, Dajiang
  Zhu, Lei Guo, Junwei Han, Tianming Liu, et~al.
\newblock Fine-grained artificial neurons in audio-transformers for
  disentangling neural auditory encoding.
\newblock In {\em Findings of the Association for Computational Linguistics:
  ACL 2023}, pages 7943--7956, 2023.

\bibitem{dai2023samaug}
Haixing Dai, Chong Ma, Zhengliang Liu, Yiwei Li, Peng Shu, Xiaozheng Wei, Lin
  Zhao, Zihao Wu, Dajiang Zhu, Wei Liu, et~al.
\newblock Samaug: Point prompt augmentation for segment anything model.
\newblock {\em arXiv preprint arXiv:2307.01187}, 2023.

\bibitem{bi2023community}
Xia-An Bi, Ke~Chen, Siyu Jiang, Sheng Luo, Wenyan Zhou, Zhaoxu Xing, Luyun Xu,
  Zhengliang Liu, and Tianming Liu.
\newblock Community graph convolution neural network for alzheimer’s disease
  classification and pathogenetic factors identification.
\newblock {\em IEEE Transactions on Neural Networks and Learning Systems},
  2023.

\bibitem{ding2023deep}
Yuzhen Ding, Hongying Feng, Yunze Yang, Jason Holmes, Zhengliang Liu, David
  Liu, William~W Wong, Nathan~Y Yu, Terence~T Sio, Steven~E Schild, et~al.
\newblock Deep-learning based fast and accurate 3d ct deformable image
  registration in lung cancer.
\newblock {\em Medical Physics}, 2023.

\bibitem{ding2022accurate}
Y~Ding, Z~Liu, H~Feng, J~Holmes, Y~Yang, N~Yu, T~Sio, S~Schild, B~Li, and
  W~Liu.
\newblock Accurate and efficient deep neural network based deformable image
  registration method in lung cancer.
\newblock In {\em MEDICAL PHYSICS}, volume~49, pages E148--E148. WILEY 111
  RIVER ST, HOBOKEN 07030-5774, NJ USA, 2022.

\bibitem{qiang4309357deep}
Ning Qiang, Qinglin Dong, Jie Gao, Jin Li, Shu Zhang, Hongtao Liang, Yifei Sun,
  Bao Ge, Zhengliang Liu, Zihao Wu, et~al.
\newblock A deep learning method for autism spectrum disorder identification
  based on interactions of hierarchical brain networks.
\newblock {\em Available at SSRN 4309357}.

\bibitem{dai2022graph}
Haixing Dai, Qing Li, Lin Zhao, Liming Pan, Cheng Shi, Zhengliang Liu, Zihao
  Wu, Lu~Zhang, Shijie Zhao, Xia Wu, et~al.
\newblock Graph representation neural architecture search for optimal
  spatial/temporal functional brain network decomposition.
\newblock In {\em International Workshop on Machine Learning in Medical
  Imaging}, pages 279--287. Springer, 2022.

\bibitem{zhang2023huatuogpt}
Hongbo Zhang, Junying Chen, Feng Jiang, Fei Yu, Zhihong Chen, Jianquan Li,
  Guiming Chen, Xiangbo Wu, Zhiyi Zhang, Qingying Xiao, Xiang Wan, Benyou Wang,
  and Haizhou Li.
\newblock Huatuogpt, towards taming language model to be a doctor, 2023.

\bibitem{muennighoff2023crosslingual}
Niklas Muennighoff, Thomas Wang, Lintang Sutawika, Adam Roberts, Stella
  Biderman, Teven~Le Scao, M~Saiful Bari, Sheng Shen, Zheng-Xin Yong, Hailey
  Schoelkopf, Xiangru Tang, Dragomir Radev, Alham~Fikri Aji, Khalid Almubarak,
  Samuel Albanie, Zaid Alyafeai, Albert Webson, Edward Raff, and Colin Raffel.
\newblock Crosslingual generalization through multitask finetuning, 2023.

\bibitem{luo2022biogpt}
Renqian Luo, Liai Sun, Yingce Xia, Tao Qin, Sheng Zhang, Hoifung Poon, and
  Tie-Yan Liu.
\newblock Biogpt: generative pre-trained transformer for biomedical text
  generation and mining.
\newblock {\em Briefings in Bioinformatics}, 23(6), 2022.

\bibitem{wu2023pmc}
Chaoyi Wu, Xiaoman Zhang, Ya~Zhang, Yanfeng Wang, and Weidi Xie.
\newblock Pmc-llama: Further finetuning llama on medical papers.
\newblock {\em arXiv preprint arXiv:2304.14454}, 2023.

\bibitem{singhal2023large}
Karan Singhal, Shekoofeh Azizi, Tao Tu, S~Sara Mahdavi, Jason Wei, Hyung~Won
  Chung, Nathan Scales, Ajay Tanwani, Heather Cole-Lewis, Stephen Pfohl, et~al.
\newblock Large language models encode clinical knowledge.
\newblock {\em Nature}, pages 1--9, 2023.

\bibitem{J1}
Rishi Bommasani, Drew~A Hudson, Ehsan Adeli, Russ Altman, Simran Arora, Sydney
  von Arx, Michael~S Bernstein, Jeannette Bohg, Antoine Bosselut, Emma
  Brunskill, et~al.
\newblock On the opportunities and risks of foundation models.
\newblock {\em arXiv preprint arXiv:2108.07258}, 2021.

\bibitem{J2}
Wayne~Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang, Xiaolei Wang, Yupeng Hou,
  Yingqian Min, Beichen Zhang, Junjie Zhang, Zican Dong, et~al.
\newblock A survey of large language models.
\newblock {\em arXiv preprint arXiv:2303.18223}, 2023.

\bibitem{J3}
Ce~Zhou, Qian Li, Chen Li, Jun Yu, Yixin Liu, Guangjing Wang, Kai Zhang, Cheng
  Ji, Qiben Yan, Lifang He, et~al.
\newblock A comprehensive survey on pretrained foundation models: A history
  from bert to chatgpt.
\newblock {\em arXiv preprint arXiv:2302.09419}, 2023.

\bibitem{rezayi2022agribert}
Saed Rezayi, Zhengliang Liu, Zihao Wu, Chandra Dhakal, Bao Ge, Chen Zhen,
  Tianming Liu, and Sheng Li.
\newblock Agribert: knowledge-infused agricultural language models for matching
  food and nutrition.
\newblock In {\em Proceedings of the Thirty-First International Joint
  Conference on Artificial Intelligence}, volume~7, pages 5150--5156, 2022.

\bibitem{liu2023context}
Zhengliang Liu, Xinyu He, Lei Liu, Tianming Liu, and Xiaoming Zhai.
\newblock Context matters: A strategy to pre-train language model for science
  education.
\newblock {\em arXiv preprint arXiv:2301.12031}, 2023.

\bibitem{dai2023ad}
Haixing Dai, Yiwei Li, Zhengliang Liu, Lin Zhao, Zihao Wu, Suhang Song,
  Ye~Shen, Dajiang Zhu, Xiang Li, Sheng Li, et~al.
\newblock Ad-autogpt: An autonomous gpt for alzheimer's disease infodemiology.
\newblock {\em arXiv preprint arXiv:2306.10095}, 2023.

\bibitem{cai2022coarse}
Homgmin Cai, Wenxiong Liao, Zhengliang Liu, Xiaoke Huang, Yiyang Zhang, Siqi
  Ding, Sheng Li, Quanzheng Li, Tianming Liu, and Xiang Li.
\newblock Coarse-to-fine knowledge graph domain adaptation based on
  distantly-supervised iterative training.
\newblock {\em arXiv preprint arXiv:2211.02849}, 2022.

\bibitem{liao2023mask}
Wenxiong Liao, Zhengliang Liu, Haixing Dai, Zihao Wu, Yiyang Zhang, Xiaoke
  Huang, Yuzhong Chen, Xi~Jiang, Dajiang Zhu, Tianming Liu, et~al.
\newblock Mask-guided bert for few shot text classification.
\newblock {\em arXiv preprint arXiv:2302.10447}, 2023.

\bibitem{cai2023exploring}
Hongmin Cai, Xiaoke Huang, Zhengliang Liu, Wenxiong Liao, Haixing Dai, Zihao
  Wu, Dajiang Zhu, Hui Ren, Quanzheng Li, Tianming Liu, et~al.
\newblock Exploring multimodal approaches for alzheimer's disease detection
  using patient speech transcript and audio data.
\newblock {\em arXiv preprint arXiv:2307.02514}, 2023.

\bibitem{zhao2022embedding}
Lin Zhao, Zihao Wu, Haixing Dai, Zhengliang Liu, Tuo Zhang, Dajiang Zhu, and
  Tianming Liu.
\newblock Embedding human brain function via transformer.
\newblock In {\em International Conference on Medical Image Computing and
  Computer-Assisted Intervention}, pages 366--375. Springer, 2022.

\bibitem{zhao2023generic}
Lin Zhao, Zihao Wu, Haixing Dai, Zhengliang Liu, Xintao Hu, Tuo Zhang, Dajiang
  Zhu, and Tianming Liu.
\newblock A generic framework for embedding human brain function with
  temporally correlated autoencoder.
\newblock {\em Medical Image Analysis}, page 102892, 2023.

\bibitem{J4}
OpenAI.
\newblock Gpt-4 technical report, 2023.

\bibitem{J5}
Harsha Nori, Nicholas King, Scott~Mayer McKinney, Dean Carignan, and Eric
  Horvitz.
\newblock Capabilities of gpt-4 on medical challenge problems.
\newblock {\em arXiv preprint arXiv:2303.13375}, 2023.

\bibitem{J6}
Jason Holmes, Zhengliang Liu, Lian Zhang, Yuzhen Ding, Terence~T Sio, Lisa~A
  McGee, Jonathan~B Ashman, Xiang Li, Tianming Liu, Jiajian Shen, et~al.
\newblock Evaluating large language models on a highly-specialized topic,
  radiation oncology physics.
\newblock {\em arXiv preprint arXiv:2304.01938}, 2023.

\bibitem{J8}
Yan Zhuang, Qi~Liu, Yuting Ning, Weizhe Huang, Rui Lv, Zhenya Huang, Guanhao
  Zhao, Zheng Zhang, Qingyang Mao, Shijin Wang, et~al.
\newblock Efficiently measuring the cognitive ability of llms: An adaptive
  testing perspective.
\newblock {\em arXiv preprint arXiv:2306.10512}, 2023.

\bibitem{J7}
Qi~Liu.
\newblock Towards a new generation of cognitive diagnosis.
\newblock In {\em IJCAI}, pages 4961--4964, 2021.

\bibitem{J9}
Qinkai Zheng, Xiao Xia, Xu~Zou, Yuxiao Dong, Shan Wang, Yufei Xue, Zihan Wang,
  Lei Shen, Andi Wang, Yang Li, et~al.
\newblock Codegeex: A pre-trained model for code generation with multilingual
  evaluations on humaneval-x.
\newblock {\em arXiv preprint arXiv:2303.17568}, 2023.

\bibitem{sun2023moss}
Tianxiang Sun, Xiaotian Zhang, Zhengfu He, Peng Li, Qinyuan Cheng, Hang Yan,
  Xiangyang Liu, Yunfan Shao, Qiong Tang, Xingjian Zhao, Ke~Chen, Yining Zheng,
  Zhejian Zhou, Ruixiao Li, Jun Zhan, Yunhua Zhou, Linyang Li, Xiaogui Yang,
  Lingling Wu, Zhangyue Yin, Xuanjing Huang, and Xipeng Qiu.
\newblock Moss: Training conversational language models from synthetic data.
\newblock 2023.

\bibitem{vaswani2017attention}
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,
  Aidan~N Gomez, {\L}ukasz Kaiser, and Illia Polosukhin.
\newblock Attention is all you need.
\newblock {\em Advances in neural information processing systems}, 30, 2017.

\bibitem{huang2023ceval}
Yuzhen Huang, Yuzhuo Bai, Zhihao Zhu, Junlei Zhang, Jinghan Zhang, Tangjun Su,
  Junteng Liu, Chuancheng Lv, Yikai Zhang, Jiayi Lei, Yao Fu, Maosong Sun, and
  Junxian He.
\newblock C-eval: A multi-level multi-discipline chinese evaluation suite for
  foundation models.
\newblock {\em arXiv preprint arXiv:2305.08322}, 2023.

\bibitem{hendrycks2021measuring}
Dan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika, Dawn
  Song, and Jacob Steinhardt.
\newblock Measuring massive multitask language understanding, 2021.

\bibitem{du2022glm}
Zhengxiao Du, Yujie Qian, Xiao Liu, Ming Ding, Jiezhong Qiu, Zhilin Yang, and
  Jie Tang.
\newblock Glm: General language model pretraining with autoregressive blank
  infilling.
\newblock In {\em Proceedings of the 60th Annual Meeting of the Association for
  Computational Linguistics (Volume 1: Long Papers)}, pages 320--335, 2022.

\bibitem{ouyang2022training}
Long Ouyang, Jeff Wu, Xu~Jiang, Diogo Almeida, Carroll~L Wainwright, Pamela
  Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, et~al.
\newblock Training language models to follow instructions with human feedback.
\newblock {\em arXiv preprint arXiv:2203.02155}, 2022.

\bibitem{ChatGLM-Med}
Haochun Wang, Chi Liu, Sendong Zhao, Bing Qin, and Ting Liu.
\newblock Chatglm-med.
\newblock \url{https://github.com/SCIR-HI/Med-ChatGLM}, 2023.

\bibitem{YuLan-Chat}
YuLan-Chat-Team.
\newblock Yulan-chat: An open-source bilingual chatbot.
\newblock \url{https://github.com/RUC-GSAI/YuLan-Chat}, 2023.

\bibitem{lehman2023}
Eric Lehman and Alistair Johnson.
\newblock Clinical-t5: Large language models built using mimic clinical text
  (version 1.0.0).
\newblock {\em PhysioNet}, 2023.

\bibitem{Harskamp2023.03.25.23285475}
Ralf~E. Harskamp and Lukas~De Clercq.
\newblock Performance of chatgpt as an ai-assisted decision support tool in
  medicine: a proof-of-concept study for interpreting symptoms and management
  of common cardiac conditions (amstelheart-2).
\newblock {\em medRxiv}, 2023.

\bibitem{RAO2023}
Arya Rao, John Kim, Meghana Kamineni, Michael Pang, Winston Lie, Keith~J.
  Dreyer, and Marc~D. Succi.
\newblock Evaluating gpt as an adjunct for radiologic decision making: Gpt-4
  versus gpt-3.5 in a breast imaging pilot.
\newblock {\em Journal of the American College of Radiology}, 2023.

\bibitem{lyu2023macawllm}
Chenyang Lyu, Minghao Wu, Longyue Wang, Xinting Huang, Bingshuai Liu, Zefeng
  Du, Shuming Shi, and Zhaopeng Tu.
\newblock Macaw-llm: Multi-modal language modeling with image, audio, video,
  and text integration, 2023.

\bibitem{nov2023putting}
Oded Nov, Nina Singh, and Devin Mann.
\newblock Putting chatgpt's medical advice to the (turing) test, 2023.

\bibitem{liu2023radiologygpt}
Zhengliang Liu, Aoxiao Zhong, Yiwei Li, Longtao Yang, Chao Ju, Zihao Wu, Chong
  Ma, Peng Shu, Cheng Chen, Sekeun Kim, Haixing Dai, Lin Zhao, Dajiang Zhu, Jun
  Liu, Wei Liu, Dinggang Shen, Xiang Li, Quanzheng Li, and Tianming Liu.
\newblock Radiology-gpt: A large language model for radiology, 2023.

\bibitem{latif2023artificial}
Ehsan Latif, Gengchen Mai, Matthew Nyaaba, Xuansheng Wu, Ninghao Liu, Guoyu Lu,
  Sheng Li, Tianming Liu, and Xiaoming Zhai.
\newblock Artificial general intelligence (agi) for education, 2023.

\bibitem{wang2023prompt}
Jiaqi Wang, Enze Shi, Sigang Yu, Zihao Wu, Chong Ma, Haixing Dai, Qiushi Yang,
  Yanqing Kang, Jinru Wu, Huawen Hu, Chenxi Yue, Haiyang Zhang, Yiheng Liu,
  Xiang Li, Bao Ge, Dajiang Zhu, Yixuan Yuan, Dinggang Shen, Tianming Liu, and
  Shu Zhang.
\newblock Prompt engineering for healthcare: Methodologies and applications,
  2023.

\bibitem{zhang2023biomedgpt}
Kai Zhang, Jun Yu, Zhiling Yan, Yixin Liu, Eashan Adhikarla, Sunyang Fu, Xun
  Chen, Chen Chen, Yuyin Zhou, Xiang Li, et~al.
\newblock Biomedgpt: A unified and generalist biomedical generative pre-trained
  transformer for vision, language, and multimodal tasks.
\newblock {\em arXiv preprint arXiv:2305.17100}, 2023.

\bibitem{liu2023pharmacygpt}
Zhengliang Liu, Zihao Wu, Mengxuan Hu, Bokai Zhao, Lin Zhao, Tianyi Zhang,
  Haixing Dai, Xianyan Chen, Ye~Shen, Sheng Li, et~al.
\newblock Pharmacygpt: The ai pharmacist.
\newblock {\em arXiv preprint arXiv:2307.10432}, 2023.

\bibitem{zhong2023chatabl}
Tianyang Zhong, Yaonai Wei, Li~Yang, Zihao Wu, Zhengliang Liu, Xiaozheng Wei,
  Wenjun Li, Junjie Yao, Chong Ma, Xiang Li, et~al.
\newblock Chatabl: Abductive learning via natural language interaction with
  chatgpt.
\newblock {\em arXiv preprint arXiv:2304.11107}, 2023.

\bibitem{wang2023review}
Jiaqi Wang, Zhengliang Liu, Lin Zhao, Zihao Wu, Chong Ma, Sigang Yu, Haixing
  Dai, Qiushi Yang, Yiheng Liu, Songyao Zhang, et~al.
\newblock Review of large vision models and visual prompt engineering.
\newblock {\em arXiv preprint arXiv:2307.00855}, 2023.

\bibitem{guan2023cohortgpt}
Zihan Guan, Zihao Wu, Zhengliang Liu, Dufan Wu, Hui Ren, Quanzheng Li, Xiang
  Li, and Ninghao Liu.
\newblock Cohortgpt: An enhanced gpt for participant recruitment in clinical
  study.
\newblock {\em arXiv preprint arXiv:2307.11346}, 2023.

\bibitem{dai2023auggpt}
Haixing Dai, Zhengliang Liu, Wenxiong Liao, Xiaoke Huang, Yihan Cao, Zihao Wu,
  Lin Zhao, Shaochen Xu, Wei Liu, Ninghao Liu, Sheng Li, Dajiang Zhu, Hongmin
  Cai, Lichao Sun, Quanzheng Li, Dinggang Shen, Tianming Liu, and Xiang Li.
\newblock Auggpt: Leveraging chatgpt for text data augmentation, 2023.

\bibitem{dai2023adautogpt}
Haixing Dai, Yiwei Li, Zhengliang Liu, Lin Zhao, Zihao Wu, Suhang Song,
  Ye~Shen, Dajiang Zhu, Xiang Li, Sheng Li, Xiaobai Yao, Lu~Shi, Quanzheng Li,
  Zhuo Chen, Donglan Zhang, Gengchen Mai, and Tianming Liu.
\newblock Ad-autogpt: An autonomous gpt for alzheimer's disease infodemiology,
  2023.

\bibitem{luotuo}
Qiyuan~Chen Ziang~Leng and Cheng Li.
\newblock Luotuo: An instruction-following chinese language model, lora tuning
  on llama.
\newblock \url{https://github.com/LC1332/Luotuo-Chinese-LLM}, 2023.

\bibitem{wang2022fengshenbang}
Junjie Wang, Yuxiang Zhang, Lin Zhang, Ping Yang, Xinyu Gao, Ziwei Wu, Xiaoqun
  Dong, Junqing He, Jianheng Zhuo, Qi~Yang, et~al.
\newblock Fengshenbang 1.0: Being the foundation of chinese cognitive
  intelligence.
\newblock {\em arXiv preprint arXiv:2209.02970}, 2022.

\bibitem{li-etal-2022-easy}
Gongzheng Li, Yadong Xi, Jingzhen Ding, Duan Wang, Ziyang Luo, Rongsheng Zhang,
  Bai Liu, Changjie Fan, Xiaoxi Mao, and Zeng Zhao.
\newblock Easy and efficient transformer: Scalable inference solution for large
  {NLP} model.
\newblock In {\em Proceedings of the 2022 Conference of the North American
  Chapter of the Association for Computational Linguistics: Human Language
  Technologies: Industry Track}, pages 62--68, Hybrid: Seattle, Washington +
  Online, July 2022. Association for Computational Linguistics.

\bibitem{wang2023huatuo}
Haochun Wang, Chi Liu, Nuwa Xi, Zewen Qiang, Sendong Zhao, Bing Qin, and Ting
  Liu.
\newblock Huatuo: Tuning llama model with chinese medical knowledge, 2023.

\bibitem{wang2023XrayGLM}
Rongsheng Wang, Yaofei Duan, Junrong Li, Patrick Pang, and Tao Tan.
\newblock Xrayglm: The first chinese medical multimodal model that chest
  radiographs summarization.
\newblock \url{https://github.com/WangRongsheng/XrayGLM}, 2023.

\bibitem{knox2011augmenting}
W~Bradley Knox and Peter Stone.
\newblock Augmenting reinforcement learning with human feedback.
\newblock In {\em ICML 2011 Workshop on New Developments in Imitation Learning
  (July 2011)}, volume 855, page~3, 2011.

\bibitem{zeng2022glm}
Aohan Zeng, Xiao Liu, Zhengxiao Du, Zihan Wang, Hanyu Lai, Ming Ding, Zhuoyi
  Yang, Yifan Xu, Wendi Zheng, Xiao Xia, et~al.
\newblock Glm-130b: An open bilingual pre-trained model.
\newblock {\em arXiv preprint arXiv:2210.02414}, 2022.

\bibitem{QiZhenGPT23ZJU}
Zhejiang University.
\newblock Qizhengpt.
\newblock \url{https://github.com/CMKRG/QiZhenGPT}, 2023.

\bibitem{chinese-llama-alpaca}
Yiming Cui, Ziqing Yang, and Xin Yao.
\newblock Efficient and effective text encoding for chinese llama and alpaca.
\newblock {\em arXiv preprint arXiv:2304.08177}, 2023.

\bibitem{githubGitHubCVISZULinly}
Chinese-llama 1 \& 2 and chinese-falcon 1 \& 2.
\newblock \url{https://github.com/CVI-SZU/Linly}.
\newblock [Accessed 26-07-2023].

\bibitem{zhao2022tencentpretrain}
Zhe Zhao, Yudong Li, Cheng Hou, Jing Zhao, Rong Tian, Weijie Liu, Yiren Chen,
  Ningyuan Sun, Haoyan Liu, Weiquan Mao, et~al.
\newblock Tencentpretrain: A scalable and flexible toolkit for pre-training
  models of different modalities.
\newblock {\em arXiv preprint arXiv:2212.06385}, 2022.

\bibitem{li2022csl}
Yudong Li, Yuqing Zhang, Zhe Zhao, Linlin Shen, Weijie Liu, Weiquan Mao, and
  Hui Zhang.
\newblock Csl: A large-scale chinese scientific literature dataset.
\newblock In {\em Proceedings of the 29th International Conference on
  Computational Linguistics}, pages 3917--3923, 2022.

\bibitem{githubGitHubOpenBMBCPMBee}
{G}it{H}ub - {O}pen{B}{M}{B}/{C}{P}{M}-{B}ee.
\newblock \url{https://github.com/OpenBMB/CPM-Bee}.
\newblock [Accessed 26-07-2023].

\bibitem{agrawal2022large}
Monica Agrawal, Stefan Hegselmann, Hunter Lang, Yoon Kim, and David Sontag.
\newblock Large language models are zero-shot clinical information extractors.
\newblock {\em arXiv preprint arXiv:2205.12689}, 2022.

\bibitem{baichuan2023bai}
Baichuan~Intelligent Technology.
\newblock A large-scale 7b pretraining language model developed by
  baichuan-inc.
\newblock \url{https://github.com/baichuan-inc/Baichuan-7B}, 2023.

\bibitem{AtomGPT23Atomecho}
Atomecho.
\newblock Atomgpt.
\newblock \url{ https://github.com/AtomEcho/AtomGPT }, 2023.

\bibitem{de2023evaluation}
Adrian de~Wynter, Xun Wang, Alex Sokolov, Qilong Gu, and Si-Qing Chen.
\newblock An evaluation on large language model outputs: Discourse and
  memorization.
\newblock {\em arXiv preprint arXiv:2304.08637}, 2023.

\bibitem{clueai2023chatyuan}
Liang~Xu Xuanwei~Zhang and Kangkang Zhao.
\newblock Chatyuan: A large language model for dialogue in chinese and english,
  December 2022.

\bibitem{chen2023bianque1}
Yirong Chen, Zhenyu Wang, Xiaofen Xing, Zhipei Xu, Kai Fang, Sihang Li, Junhong
  Wang, and Xiangmin Xu.
\newblock Bianque-1.0: Improving the "question" ability of medical chat model
  through finetuning with hybrid instructions and multi-turn doctor qa
  datasets.
\newblock 2023.

\bibitem{AquilaChat23BeijingAcademyofArtificialIntelligence}
Beijing~Academy of~Artificial~Intelligence.
\newblock Aquilachat.
\newblock \url{ https://model.baai.ac.cn/model-detail/100101}, 2023.

\bibitem{Aquila23BeijingAcademyofArtificialIntelligence}
Beijing~Academy of~Artificial~Intelligence.
\newblock Aquila.
\newblock \url{ https://model.baai.ac.cn/model-detail/100101}, 2023.

\bibitem{TigerBot23TigerResearch}
TigerResearch.
\newblock Tigerbot.
\newblock \url{
  https://github.com/TigerResearch/TigerBot/blob/main/README_en.md}, 2023.

\bibitem{XrayPULSE23OpenMEDLab}
OpenMEDLab.
\newblock Xraypulse.
\newblock \url{ https://github.com/openmedlab/XrayPULSE}, 2023.

\bibitem{xiong2023doctorglm}
Honglin Xiong, Sheng Wang, Yitao Zhu, Zihao Zhao, Yuxiao Liu, Qian Wang, and
  Dinggang Shen.
\newblock Doctorglm: Fine-tuning your chinese doctor is not a herculean task.
\newblock {\em arXiv preprint arXiv:2304.01097}, 2023.

\bibitem{lmflow}
Shizhe Diao, Rui Pan, Hanze Dong, KaShun Shum, Jipeng Zhang, Wei Xiong, and
  Tong Zhang.
\newblock Lmflow: An extensible toolkit for finetuning and inference of large
  foundation models.
\newblock \url{https://optimalscale.github.io/LMFlow/}, 2023.

\bibitem{le2015compositional}
Phong Le and Willem Zuidema.
\newblock Compositional distributional semantics with long short term memory.
\newblock {\em arXiv preprint arXiv:1503.02510}, 2015.

\bibitem{devlin2018bert}
Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova.
\newblock Bert: Pre-training of deep bidirectional transformers for language
  understanding.
\newblock {\em arXiv preprint arXiv:1810.04805}, 2018.

\bibitem{SenseNova23SenseTime}
SenseTime.
\newblock Sensenova.
\newblock https://www.sensetime.com/en/news-detail/51166397?categoryId=1072,
  2023.

\bibitem{bai2022constitutional}
Yuntao Bai, Saurav Kadavath, Sandipan Kundu, Amanda Askell, Jackson Kernion,
  Andy Jones, Anna Chen, Anna Goldie, Azalia Mirhoseini, Cameron McKinnon,
  et~al.
\newblock Constitutional ai: Harmlessness from ai feedback.
\newblock {\em arXiv preprint arXiv:2212.08073}, 2022.

\bibitem{bayling}
Shaolei Zhang, Qingkai Fang, Zhuocheng Zhang, Zhengrui Ma, Yan Zhou, Langlin
  Huang, Mengyu Bu, Shangtong Gui, Yunji Chen, Xilin Chen, and Yang Feng.
\newblock Bayling: Bridging cross-lingual alignment and instruction following
  through interactive translation for large language models.
\newblock {\em arXiv preprint arXiv:2306.10968}, 2023.

\end{thebibliography}
