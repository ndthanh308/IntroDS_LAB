

Robots have become ubiquitous in various applications ranging from pick-and-place operations in manufacturing to facilitating the detection of disorders in healthcare settings.~\cite{ahangar2019design, su15107790}. However, challenges remain in working in complex and unpredictable environments. Multi-robot collaboration offers a promising approach to tackling these challenges. By allowing robots to work together and share information, we can create more flexible, adaptable, and effective systems.

Recent research has demonstrated that reinforcement learning (RL) which is a type of machine learning technique, is particularly well-suited for multi-robot  collaboration~\cite{TereshchukSBPDB19,AgrawalABM22iros,GaoWZYWXWLXG22iros,ZhangQQXWZWC0ZL22iros}. RL enables robots to learn from their experiences and optimize their performance even in highly complex and dynamic environments. Utilizing RL algorithms to coordinate the actions of multiple robots can enable sophisticated systems to tackle more intricate problems than those that can be handled by a single robot alone.
%
One particular area where multi-robot collaboration through RL can have a significant impact is space exploration. Space exploration tasks are multifaceted and require a range of skills that no single robot may possess.
Building and maintaining a colony on Mars, for example, would require collaborative efforts from multiple robots with diverse capabilities, such as excavation, construction, maintenance, and repair. In such complex missions, traditional approaches may not be sufficient, while multi-robot collaboration through RL can play a vital role in achieving objectives. By enabling robots to work together in a way that mimics human teamwork, we can create systems that are capable of performing complex tasks in a more efficient and effective manner.
%

\noindent\textbf{Overview of related work.} Reinforcement learning (RL) has received much attention in many fields~\cite{guo2023backdoor,BaiZLZ21iros, siedler2022dynamic, zhang2020decentralized}. Recent research has demonstrated the potential benefits of multi-robot collaboration through RL in various real-world applications~\cite{BaiZLZ21iros, siedler2022dynamic, zhang2020decentralized}. For example, RL-based collaboration among drones in a reforestation task led to faster completion times and better overall performance~\cite{siedler2022dynamic}. Similarly, RL-based collaboration has been effective in object transportation scenarios~\cite{zhang2020decentralized}. These examples highlight the potential of multi-robot collaboration through RL to improve performance in real-world applications.

However, the emulation of human teamwork in multi-robot systems is not without its challenges. One such challenge lies in the occurrence of dilemmas often faced in human collaboration. As with human teams, robots may encounter situations where individual goals conflict with collective ones, or where coordination and cooperation come at a cost.
A particularly interesting perspective of multi-robot collaboration is social dilemmas, where individual robots face a trade-off between self-interests and collective benefits. These dilemmas can arise in various scenarios, such as task allocation, resource sharing, and navigation, and can lead to suboptimal outcomes, reduced efficiency, and conflicts~\cite{stimpson2003learning,yu2020distributed}. To address these challenges, several approaches, including game theory, machine learning, and communication strategies, have been proposed~\cite{10.5555/3237383.3237408, 10.5555/3495724.3496999, han2022solution, he2022robust}. For instance, an Admission-based hierarchical multi-agent RL strategy has been used to address cooperation and equality~\cite{app13031807}, while an adherence-based multi-agent reinforcement learning algorithm enhances the performance of RL agents by rewarding adherence to increase coordination and collaboration~\cite{yuan2022adherence}. These studies emphasize the importance of effective communication and coordination strategies to mitigate the effects of social dilemmas and improve overall performance in various applications, such as robotics, transportation, manufacturing, and environmental monitoring.




\noindent\textbf{This work.} Although recent research has investigated how communication can mitigate social dilemmas and improve performance in multi-robot systems, there is still much to learn about how environmental factors such as miscommunication and conflicting intentions can affect cooperation. Self-interested or even adversarial robots can further complicate collaboration, making it crucial to explore possible ways adversaries can manipulate the situation to achieve their intentions.



This paper examines how manipulating multi-robot communication can (either positively or negatively) impact the performance of multi-robot systems within social dilemmas. Specifically, we focus on two distinct forms of manipulation: policy and incentive  manipulation of the reward function. 
%
Through incentive reward manipulation, we control the flow of reward communication, in terms of both sending/receiving rewards to/from other robots; while through policy manipulation, we can interact with the environment with malicious policies to manipulate the behaviors.
%
Our analysis demonstrates the possibility of both positive and negative impacts on the task outcome. Positive impacts include faster convergence to the global optimum reward, which can guarantee to maximization of collective rewards for chosen robots. Conversely, negative impacts can reduce the success rate of the overall task performance. Our work thus introduces a new angle for manipulation in recent multi-agent reinforcement learning social dilemmas that utilize a unique reward function for incentivization.




 
To evaluate our proposed approach, we employ two social dilemma environments, the Escape room (ER)~\cite{10.5555/3495724.3496999} and Iterative Prisoners Dilemma (IPD)~\cite{10.5555/3237383.3237408}.
We use the Gazebo simulator to conduct experiments and demonstrate the effectiveness of our approach in these environments. 

Our contributions can be summarized as follows:

\begin{itemize}
\item This paper presents a novel approach to manipulating the collaborative behavior of multi-robot reinforcement learning (RL) systems in a social dilemma configuration by manipulating inter-robot communication. Two manipulation methods, referred to as policy and incentive reward manipulation, have been designed and implemented to effectively yield both negative and positive impacts on other agents and the final task results. 
\item The efficacy of our approach has been comprehensively evaluated in two different environments in Gazebo, and experimental results have been presented to demonstrate the impact of these manipulations on the performance of multi-robot systems, including 1) faster convergence to the global optimum, 2) maximizing collective reward for a chosen robot, and 3) reducing the success rate of task completion due to certain adversarial robots.
\item This work presents one of the first attempts to investigate the manipulation of multi-robot collaboration through RL and provides insights into the impact of manipulation on task performance in social dilemmas. The proposed approach has implications for various real-world applications, such as robotics, transportation, and manufacturing, where multi-robot collaboration is becoming increasingly important.
\end{itemize}
