

\begin{table}[t]
    \vspace{-0.\intextsep}
    \centering
    \begin{small}
    \begin{tabular}{l@{\hspace{2mm}}l@{\hspace{2mm}}l@{\hspace{2mm}}l@{\hspace{2mm}}l@{\hspace{2mm}}l@{\hspace{2mm}}l@{\hspace{2mm}}r}
    \toprule
    Architecture   & Gluon         &   Light quark & $W$-boson & $Z$-boson & Top quark & \# Params\\
    \midrule
    \multicolumn{7}{c}{\textbf{AUC}} \\
    JEDI-net    &   0.9529     &   0.9301      & 0.9739  & 0.9679 & 0.9683 &   34k    \\
    PCT     &   0.9623    &   0.9414   & 0.9789  &  0.9814 &  0.9757  &  193k          \\
    LorentzNet &   0.9681(3)    &   0.9479(4)   & 0.9837(2)  & 0.9813(3) & 0.9793(3) &   224k    \\
    $\text{PELICAN}$  &   \textbf{0.9693(1)}  &   \textbf{0.9493(1)}   &  \textbf{0.9840(1)} &  \textbf{0.9816(1)} &  \textbf{0.9803(1)} &   208k     \\ 
    \midrule
    \multicolumn{7}{c}{\textbf{TPR at FPR=0.10}} \\
    JEDI-net     &   0.878(1)  &   0.822(1)  & 0.938(1)  & 0.910(1) & 0.930(1)  &   34k  \\
    PCT     &   0.891(1)    &   0.833(1)   & 0.932(1)  &  \textbf{0.946(1)} &  0.941(1)   &  193k        \\
    LorentzNet  &   0.912(1)    &   0.855(1)   & 0.952(1)  & 0.939(1) & 0.949(1)  &   224k   \\
    $\text{PELICAN}$  &   \textbf{0.916(1)}  &   \textbf{0.860(1)}   & \textbf{0.953(1)}  & 0.940(1)  &\textbf{ 0.951(1)}   &   208k   \\ 
    \midrule
    \multicolumn{7}{c}{\textbf{TPR at FPR=0.01}} \\
    JEDI-net      &   0.485(1)  &   0.302(1)  & 0.704(1)  & 0.769(1) & 0.633(1)  &   34k  \\
    PCT    &   0.513(2)    &   0.298(2)   & \textbf{0.834(1)}  &  0.781(1) &  0.700(3)  &  193k       \\
    LorentzNet  &   0.557(4)    &   0.319(2)   &  0.800(3)  & 0.850(3) & 0.753(3)  &   224k  \\
    $\text{PELICAN}$  &   \textbf{0.567(1) } &   \textbf{0.320(1)}   &  0.804(1) & \textbf{0.850(1)}  & \textbf{0.761(1)}   &   208k  \\ 
    \bottomrule
    \end{tabular}
    \end{small} 
    \caption{Three metrics of the receiver-operator curves for each jet category in the HLS4ML Jet dataset (in the ``one-vs-rest'' strategy), compared across architectures: area under the curve and the values of signal efficiencies (true positive rate, or TPR) at background efficiencies (false positive rate, or FPR) of 10\% and 1\%. LorentzNet and PELICAN results are averaged over 5 random initializations and the uncertainties are given by the standard deviation. The results for JEDI-net and PCT were taken from refs.~\cite{JEDI-net,Mikuni21}.\label{tab_hls}}
\end{table}


In this section we consider a final, more advanced jet tagging task. It involves identifying jets that are produced by the decays of five different types of particles: gluons, light quarks, $W$-bosons, $Z$-bosons, and top quarks. We compare the performance of PELICAN models of three different widths to previously published architectures.

\subsection{HLS4ML LHC jet dataset}

The HLS4ML dataset consists of jets produced by simulated $\sqrt{s}=13\,\text{TeV}$ proton-proton collisions using the parameters of a typical LHC detector as detailed in ref.~\cite{Duarte18}. The jets are clustered using the anti-$k_T$ algorithm~\cite{Cacciari:2008gp} with jet radius $R=0.8$, and the jet transverse momentum is required to be around $1\,\text{TeV}$. There are 5 categories of jets: $g,q,W,Z,t$, labeled using a one-hot vector (e.g.~$Z$ is labeled $(0,0,0,1,0)$). We use the version of the dataset that includes up to 100 constituents per jet, which can be downloaded from ref.~\cite{HLS100dataset}. The original dataset includes 16 features per constituent, 4 of them being the Cartesian components of the 4-momentum, and the rest are various representations of the 4-momentum in cylindrical coordinates relative either to the beam axis or the jet axis. In addition, it includes a number of jet-level scalar features. For PELICAN, we need only the 4-momentum of each constituent. This simplified version of the dataset appropriate for our dataloader can be found at ref.~\cite{HLS100datasetConverted}. To avoid any potential bias, the original training set was split into a fully balanced set of 567k jets and an unbalanced validation set of 63k jets (matching the sizes in ref.~\cite{Mikuni21}). The final testing dataset consists of 240k jets.


\begin{table}[t]
    \vspace{-0.\intextsep}
    \centering
    \begin{small}
    \begin{tabular}{l@{\hspace{2mm}}l@{\hspace{2mm}}l@{\hspace{2mm}}l@{\hspace{2mm}}l@{\hspace{2mm}}l@{\hspace{2mm}}l@{\hspace{2mm}}r}
    \toprule
    Width  & Gluon         &   Light quark & $W$-boson & $Z$-boson & Top quark & \# Params\\
    \midrule
    \multicolumn{7}{c}{\textbf{AUC}}\\
    132/78  &   0.9693(1)  &   0.9493(1)   &  0.9840(1) &  0.9816(1) &  0.9803(1) &   208k     \\ 
    60/35  &   0.9683(1)   &   0.9483(1)   & 0.9835(2)  & 0.9811(2)  & 0.9795(2)  &   48k     \\ 
     25/15  &  0.9652(2)   &   0.9441(3)   & 0.9821(2)  & 0.9795(3)  & 0.9769(3)  &   11k     \\ 
    \midrule    
    \multicolumn{7}{c}{\textbf{TPR at FPR=0.10}} \\
    132/78  &   0.916(1)  &   0.860(1)   & 0.953(1)  & 0.940(1)  & 0.951(1)    &   208k  \\ 
     60/35  &   0.912(1)   &   0.856(1)   & 0.952(1)  & 0.938(1)  & 0.949(1)   &   48k \\ 
    25/15  & 0.902(1)  &   0.841(1)   & 0.948(1)  & 0.934(1)  & 0.942(1)       &   11k  \\ 
    \midrule
    \multicolumn{7}{c}{\textbf{TPR at FPR=0.01}} \\
    132/78  &   0.567(1)  &   0.320(1)   &  0.804(1) & 0.850(1)  & 0.761(1)  &   208k  \\ 
    60/35  &   0.562(1)   &   0.316(2)   & 0.801(2)  & 0.849(1)  & 0.750(2)  &   48k \\ 
    25/15  &   0.538(2)   & 0.307(3)  & 0.794(3)  & 0.840(2) & 0.719(2)      &   11k \\ 
    \bottomrule
    \end{tabular}
    \end{small} 
    \caption{Comparison of three PELICAN models of different widths on the multi-class jet tagging task. The width for PELICAN is defined as in~\tabref{tab_pelican_model_size}. \label{tab_hls_sizes}}
\end{table}

\subsection{Multi-class jet tagging results}

We use the same PELICAN classifier architecture as above, but this time producing 5 classification scores. All other hyperparameters and the training procedure were left unchanged. In addition, we trained LorentzNet \cite{LorentzNet22} on this dataset without modifying the default hyperparameters (other than the number of target classes) or the training procedure. In \tabref{tab_hls} we compare the receiver-operator curves of different architectures using three metrics: area under the curve (AUC), and the signal efficiencies (a.k.a.~TPR -- true positive rate) at background efficiencies (FPR -- false positive rate) of 10\% and 1\%. On net, both PELICAN and LorentzNet (the only two Lorentz-invariant architectures applied to this task) provide a significant improvement over older architectures, yet PELICAN surpasses even LorentzNet despite its similar model size.

Finally, we trained three PELICAN models of different widths and compared their performance in \tabref{tab_hls_sizes}. Even the small PELICAN model with only 11k parameters achieves state-of-the-art performance in 4 out of the 5 jet categories. Meanwhile the medium model with 48k parameters is on par with the much larger LorentzNet. We see similar (small) changes in performance as the model size is changed for this task compared to the other tasks described above. 
