
Identifying, reconstructing, and measuring the properties and dynamics of high-energy, short-distance particle phenomena is inherently an inference task, since direct access to the fundamental processes is often impossible due to the time and length scales at which they occur. The suite of detection techniques, pattern recognition algorithms, and measurement approaches used to perform this task inevitably imposes constraints on both the nature of the information used as well as on the form and structure of the results. Such constraints play a crucial role in the context of jet substructure measurements, in which detailed analysis is performed on the long-distance features of Lorentz-boosted particle decays, parton showering, and radiation patterns found in the collimated sprays of particles that form the jets themselves. In this work, we present a comprehensive analysis of a new approach to multiple jet substructure-based inference tasks using a machine learning (ML) architecture that fundamentally  respects permutation and Lorentz-group symmetries: PELICAN, the permutation equivariant and Lorentz invariant or covariant aggregator network. Our approach thus imposes explicit physics-informed constraints on the system and consequently yields new insights and capabilities.

Decades of jet substructure research have yielded a wide range of approaches to performing inference tasks such as: distinguishing quark-initiated from gluon-initiated jets~\cite{gallicchio_quark_2013,Larkoski:2014pca,Komiske:2016rsd,10.3389/frai.2022.852970,10.21468/SciPostPhys.6.6.069}; discriminating jets formed from Lorentz-boosted top quarks, Higgs and $W$-bosons, from the continuum background of jets formed from light-quarks and gluons~\cite{Butterworth:2008iy,Kaplan:2008ie,KasiePlehn19,Thaler:2008ju}; dissecting and measuring the parton-shower structure of light-quark and gluon jets themselves~\cite{Soper:2012pb,Feige:2012vc,Chien:2014nsa,Marzani:2017kqd,Dreyer:2018nbf,kogler_advances_2021}. Many approaches have been adopted to perform these tasks, including the direct use of discriminating high-level observables and multi-variate methods~\cite{Thaler:2010tr,CMS:2011usu,EFP}, as well as a growing number of ML architectures using a variety of latent-space representations. For a comprehensive overview of jet substructure measurements, see Refs.~\cite{Kogler:2018hem,Marzani:2019hun}, as well as Ref.~\cite{hepmllivingreview} for a general review of ML methods in high-energy physics (including substructure measurements). As the model complexity has grown, so too have questions regarding the relationship of both the methods and the constraints that they impose to the fundamental physical processes that they are used to model. In particular, the use of observables, architectures, and latent space representations that adhere closely to the structure and dynamics of the physics processes under study have been found to provide not only enhanced performance, but also significant insights and improvements in interpreting the results~\cite{Butter:2017cot,Erdmann:2018shi,EFP}. Imbuing these models with knowledge of, or even fundamental respect for, the symmetry group structures of the system under study has thus become increasingly impactful in the study of jet substructure, especially in the context of ML models and various neural network (NN) architectures~\cite{EFN,Bogatskiy:2020tje,LorentzNet22}.

There are several common approaches to enforcing continuous symmetries in NNs. Data augmentation can be used to train a model to have a particular sparsity structure and become approximately symmetric. However, when model complexity and interpretability are of concern, as is the case in particle physics and jet substructure analyses, a different approach is helpful. Similar issues arise with approaches that use preprocessing/normalization, which moreover come with inherent ambiguities and discontinuities that can be detrimental for sufficiently complex tasks. 

Traditionally, ML algorithms are evaluated based on basic performance metrics such as accuracy and computational cost. However, in contexts where the trained algorithms are treated not only as predictors or generators, but as actual models for some process, -- which is especially true in scientific applications -- other metrics of model quality are valuable. Model complexity (defined as e.g.~the number of parameters), explainability and interpretability can be important for making a viable physics model out of an ML algorithm. Further, certain problem-specific properties such as symmetries can be critical as well. Symmetries in ML are known to produce less complex models which respect basic geometrical rules and arguably provide more opportunities for interpretability and explainability (e.g.~convolutional neural network (CNN) kernels are often interpreted as visual features). Even in realistic settings where the symmetries are merely approximate, symmetry-constrained architectures often outperform more general architectures in terms of pure accuracy (see e.g.~Section~\ref{toptagging}), but even in cases when that is not true symmetric architectures should not be discounted due to their other benefits. For these reasons, as advocated for in Ref.~\cite{Snowmass21}, we have adopted an approach of building all symmetries directly into the PELICAN network architecture itself, similar to the inherent translational symmetry of CNNs. 

\subsection*{Summary of results}

In Section \ref{equivariance} we discuss equivariance in jet physics and introduce the tools we need to build an efficient equivariant architecture. In Section \ref{architecture} we describe the architectures of PELICAN classifiers and regressors. Now we briefly summarize the main results presented in this work, corresponding to Sections \ref{toptagging} through \ref{irc}.

\paragraph{Top-tagging with a PELICAN classifier}
We train PELICAN top taggers using a public benchmark dataset, to distinguish between top quark jets, and light quark and gluon jets. These taggers achieve state-of-the-art performance on the benchmark with fewer learnable parameters than the previous highest-performing network. PELICAN top taggers with as few as $11\text{k}$ parameters outperform all non-equivariant networks in the benchmark. See Section~\ref{toptagging} for details.

\paragraph{$W$-boson 4-momentum reconstruction with PELICAN}
We train a PELICAN model using a custom dataset~\cite{btW6} of fully-hadronic top decays to reconstruct the full 4-momentum of the intermediate $W$-bosons. Specifically, PELICAN uses  4-momenta of the top quark jet constituents as inputs. PELICAN performs favorably in reconstructing the full $W$ momentum when compared with the Johns Hopkins (JH) top tagger~\cite{Kaplan:2008ie}, which produces $W$ candidates for the subset of jets that pass its tagging. PELICAN achieves better $p_T$, mass, and angular resolutions on JH top-tagged jets -- and achieves comparable resolutions to the JH tagger even when evaluated on the full dataset. 
Additionally, we train a PELICAN model to reconstruct the 4-momentum of only the products of the $W\rightarrow q q'$ decay which are contained within the jet. We discuss differences in performance and effects of this choice in reconstruction targets in Section~\ref{Wreco}.

\paragraph{$W$-boson mass reconstruction with PELICAN}
Mass reconstruction is a common particle physics analysis task, and any reconstruction algorithm should be robust and relatively free of bias. In Section~\ref{Wmass} we discuss the nuances of PELICAN mass reconstruction targeting the $W$-bosons in the above-mentioned dataset~\cite{btW6} as an example. The results show that eliminating bias in the underlying dataset is required to produce an unbiased final algorithm. In the case of $W$ mass reconstruction, this is achieved by training PELICAN on a dataset with multiple values of $m_W$.

\paragraph{Explaining PELICAN weights}
PELICAN's respect of the particle permutation and Lorentz symmetries inherent to particle datasets provides it with explainability and interpretability rarely found in particle physics machine learning applications. In Section~\ref{Weights} we investigate the rich penultimate layer of PELICAN and its discriminatory power. In particular, we discuss interpretations of PELICAN as a soft clustering and detector-unfolding algorithm of sorts.

\paragraph{IRC-safety and PELICAN}
In particle physics, IRC-safety is an algorithmic concern which restricts tools to be robust with respect to soft-particle emissions (infrared -- IR) and collinear (C) splits due to divergences in perturbative quantum chromodynamics (QCD). In Section~\ref{irc} we modify PELICAN into IR-safe and IRC-safe versions and discuss their relative performances.
    
    % Neural networks in HEP: remind the reader that there is history & ongoing work here.

    % % Reminder of the problem: why do we want to tag top quarks?
    % The identification of the top quark is naturally an essential task for performing Standard Model measurements that involve the quark's mass \cite{Aad:2019mkw,Sirunyan:2019rfa}, and spin correlation and charge asymmetry in $t\bar{t}$ pair production \cite{Aaboud:2019hwz, CMS:2018jcg, Sirunyan:2017lvd}, as well as $W$-boson helicity \cite{Aad:2020jvx} and measurements of cross-sections of final states containing top quarks \cite{Aad:2020klt, Sirunyan:2019nxl, Aaboud:2018eki, Sirunyan:2019jud} (to name a few). Additionally, the top quark signature plays an important role in a number of beyond-Standard Model searches, including searches for top squarks \cite{Aaboud:2017aeu, Sirunyan:2021mrs} and vector-like quarks \cite{Aaboud:2018pii, Sirunyan:2019sza}. 
 
    % %at the ATLAS\cite{ATLAS2008} and CMS\cite{CMS2008} experiments at the Large Hadron Collider\cite{Bruning:2004ej}.
    
    % %TODO: I'd like to avoid using the footnote if possible -- I think overuse of footnotes can look funny since I don't see them so often in papers and we're only on the first page -- but while the info in the footnote is useful for completeness it may also take away from the flow of this paragraph if simply inserted in its current form. (Jan)
    % As with other quarks and gluons, the top quark's signature in the detector consists of a \textit{jet}, a highly-collimated stream of hadrons resulting from the the quark's showering and subsequent hadronization of shower products\footnote{To be precise, a jet should be thought of as an analysis \textit{object} that we create to represent this underlying stream of hadrons. The exact properties of the jet depends on the \textit{jet clustering algorithm} that one chooses, so that a single such stream may be represented using multiple jet definitions.}. The most massive of all the quarks, the top quark has the unusual property that it first decays to a bottom quark and $W$-boson: The $b$-quark undergoes this showering and hadronization, and the $W$-boson may decay hadronically to a light quark-antiquark pair whose constituents also form jets. If the original top quark was highly \textit{boosted} -- at a high momentum with respect to the lab frame -- the jets from the $b$-quark and $W$-boson decay products may merge to form a large-radius jet. The presence of this merged jets has motivated the study of \textit{jet substructure}\cite{Marzani:2019hun}, whereby one may attempt to identify a merged jet's initiator particle species by identifying features of its constituent particles' clustering. %Existing methods of characterizing substructure have shown that these observables can function as powerful discriminators in multivariate analyses\cite{Kaplan:2008ie,Thaler:2008ju,Thaler:2010tr,EFP} .
    
    % Machine learning has played an important role in detector operation and physics analysis tasks for decades -- such as in cluster and track-finding\cite{Lindsey1992RealTT, Denby:1987rk, Aaboud:2017all}, calorimeter shower classification\cite{Abramowicz:1995zi, deOliveira:2018lqd}, and detector triggering\cite{Gligorov:2012qt} -- and \textit{jet tagging}, the identification of a jet's initiator particle, is no exception. The use of neural networks in jet classification was first demonstrated in the early 1990's \cite{LONNBLAD1991675, PETERSON1994185}, and more sophisticated tagging networks have since been developed as general interest in leveraging neural networks in high-energy physics tasks continues to grow \cite{Albertsson:2018maf}. Top quarks, owing to their aforementioned properties and importance in measurements and searches, are the focus of significant attention in this domain and numerous machine learning tools have been developed specifically for their identification\cite{KasiePlehn19}.
    
    % %What is the state of the art in the field and what has been the evolution to that point?
    
    % A number of jet taggers \cite{Aaboud:2018psm, CMS:2017gin} make use of \textit{jet substructure variables} as inputs  -- these are high-level observables that describe features of a jet's structure, such as how many sub-clusters it contains \cite{Thaler:2010tr}. However, continuing developments in the realm of machine learning have also inspired neural networks in HEP that forego these high-level variables in favor of low-level information from the detector, such as collections of measured 4-momenta \cite{Pearkes:2017hku} or even more fundamental information like tracks and cell-level calorimeter energy deposits \cite{Cogan:2014oua, deOliveira:2015xxd, Macaluso:2018tck, Belayneh:2019vyx}. Many such networks operate by treating jet (or particle) tagging as analogous to image recognition, and making use of architectures designed for computer vision tasks. In this approach, jets can be represented as two-dimensional images whose pixels correspond with calorimeter cells or towers in the (pseudo)rapidity-azimuth plane $(\eta,\phi)$, with intensities given by deposited energy, and these images are used as inputs to a convolutional neural network (CNN).
    
    % These image-based networks show improved jet-tagging performance compared to many earlier methods that used only high-level observables. However, the physical interpretability of the operations that these networks perform is limited, as is the analogy between jet-tagging and computer vision. CNNs inherently exploit translational symmetries of images -- and architectures such as "group CNNs" exploit rotational symmetries \cite{CohenWelli16} -- but "jet images" do not fundamentally exhibit these symmetries. In other words, CNNs exploit a symmetry group that is well-suited to typical image recognition problems, but this is not the same symmetry group governing the underlying physics behind jet images. For example, translating a CNN's input image should not affect output, but translating a jet image in $\eta$ will change the jet's invariant mass -- so while a CNN will treat the translated image identically to the original one, in principle one would \textit{want} the network to distinguish between these two. Such issues can be circumvented via clever pre-processing of the jet images, but this problem begs a more fundamental question: Can we build a network that does not exhibit this problem in the first place? Or, phrased differently, can we design a network architecture that exploits the physically relevant \textit{symmetry group} for this task? Besides removing the need for complicated pre-processing, which can speed up network deployment, such an architecture may provide increased robustness and interpretability by better respecting the underlying physics of the data itself.
    
    % %For the task of classifying jets, what role does the Lorentz-group play?
    % In this paper, we present the development and testing of such a network -- one that respects the symmetries of the Lorentz group, which governs particle physics. We will demonstrate the performance of our network in top-tagging, a Lorentz-invariant task, while noting that this architecture is general enough to support regression tasks targeting Lorentz-covariant quantities as well. We will first provide a brief overview of covariant (or equivariant) networks -- a companion paper provides more details on the underlying principles \cite{Bogatskiy:2020tje} -- followed by a more detailed discussion of the network in the context of top-tagging.