
% Journals

% First the Full Name is given, then the abbreviation used in the AMS Math
% Reviews, with an indication if it could not be found there.
% Note the 2nd overwrites the 1st, so swap them if you want the full name.

 %{AMS}
 @String{AMSTrans = "American Mathematical Society Translations" }
 @String{AMSTrans = "Amer. Math. Soc. Transl." }
 @String{BullAMS = "Bulletin of the American Mathematical Society" }
 @String{BullAMS = "Bull. Amer. Math. Soc." }
 @String{ProcAMS = "Proceedings of the American Mathematical Society" }
 @String{ProcAMS = "Proc. Amer. Math. Soc." }
 @String{TransAMS = "Transactions of the American Mathematical Society" }
 @String{TransAMS = "Trans. Amer. Math. Soc." }

 %ACM
 @String{CACM = "Communications of the {ACM}" }
 @String{CACM = "Commun. {ACM}" }
 @String{CompServ = "Comput. Surveys" }
 @String{JACM = "J. ACM" }
 @String{ACMMathSoft = "{ACM} Transactions on Mathematical Software" }
 @String{ACMMathSoft = "{ACM} Trans. Math. Software" }
 @String{SIGNUM = "{ACM} {SIGNUM} Newsletter" }
 @String{SIGNUM = "{ACM} {SIGNUM} Newslett." }

 @String{AmerSocio = "American Journal of Sociology" }
 @String{AmerStatAssoc = "Journal of the American Statistical Association" }
 @String{AmerStatAssoc = "J. Amer. Statist. Assoc." }
 @String{ApplMathComp = "Applied Mathematics and Computation" }
 @String{ApplMathComp = "Appl. Math. Comput." }
 @String{AmerMathMonthly = "American Mathematical Monthly" }
 @String{AmerMathMonthly = "Amer. Math. Monthly" }
 @String{BIT = "{BIT}" }
 @String{BritStatPsych = "British Journal of Mathematical and Statistical
          Psychology" }
 @String{BritStatPsych = "Brit. J. Math. Statist. Psych." }
 @String{CanMathBull = "Canadian Mathematical Bulletin" }
 @String{CanMathBull = "Canad. Math. Bull." }
 @String{CompApplMath = "Journal of Computational and Applied Mathematics" }
 @String{CompApplMath = "J. Comput. Appl. Math." }
 @String{CompPhys = "Journal of Computational Physics" }
 @String{CompPhys = "J. Comput. Phys." }
 @String{CompStruct = "Computers and Structures" }
 @String{CompStruct = "Comput. \& Structures" }
 @String{CompJour = "The Computer Journal" }
 @String{CompJour = "Comput. J." }
 @String{CompSysSci = "Journal of Computer and System Sciences" }
 @String{CompSysSci = "J. Comput. System Sci." }
 @String{Computing = "Computing" }
 @String{ContempMath = "Contemporary Mathematics" }
 @String{ContempMath = "Contemp. Math." }
 @String{Crelle = "Crelle's Journal" }
 @String{GiornaleMath = "Giornale di Mathematiche" }
 @String{GiornaleMath = "Giorn. Mat." } % didn't find in AMS MR., ibid.

 %IEEE
 @String{Computer = "{IEEE} Computer" }
 @String{IEEETransComp = "{IEEE} Transactions on Computers" }
 @String{IEEETransComp = "{IEEE} Trans. Comput." }
 @String{IEEETransAC = "{IEEE} Transactions on Automatic Control" }
 @String{IEEETransAC = "{IEEE} Trans. Automat. Control" }
 @String{IEEESpec = "{IEEE} Spectrum" } % didn't find in AMS MR
 @String{ProcIEEE = "Proceedings of the {IEEE}" }
 @String{ProcIEEE = "Proc. {IEEE}" } % didn't find in AMS MR
 @String{IEEETransAeroElec = "{IEEE} Transactions on Aerospace and Electronic
     Systems" }
 @String{IEEETransAeroElec = "{IEEE} Trans. Aerospace Electron. Systems" }

 @String{IMANumerAna = "{IMA} Journal of Numerical Analysis" }
 @String{IMANumerAna = "{IMA} J. Numer. Anal." }
 @String{InfProcLet = "Information Processing Letters" }
 @String{InfProcLet = "Inform. Process. Lett." }
 @String{InstMathApp = "Journal of the Institute of Mathematics and
     its Applications" }
 @String{InstMathApp = "J. Inst. Math. Appl." }
 @String{IntControl = "International Journal of Control" }
 @String{IntControl = "Internat. J. Control" }
 @String{IntNumerEng = "International Journal for Numerical Methods in
     Engineering" }
 @String{IntNumerEng = "Internat. J. Numer. Methods Engrg." }
 @String{IntSuper = "International Journal of Supercomputing Applications" }
 @String{IntSuper = "Internat. J. Supercomputing Applic." } % didn't find
%% in AMS MR
 @String{Kibernetika = "Kibernetika" }
 @String{JResNatBurStand = "Journal of Research of the National Bureau
     of Standards" }
 @String{JResNatBurStand = "J. Res. Nat. Bur. Standards" }
 @String{LinAlgApp = "Linear Algebra and its Applications" }
 @String{LinAlgApp = "Linear Algebra Appl." }
 @String{MathAnaAppl = "Journal of Mathematical Analysis and Applications" }
 @String{MathAnaAppl = "J. Math. Anal. Appl." }
 @String{MathAnnalen = "Mathematische Annalen" }
 @String{MathAnnalen = "Math. Ann." }
 @String{MathPhys = "Journal of Mathematical Physics" }
 @String{MathPhys = "J. Math. Phys." }
 @String{MathComp = "Mathematics of Computation" }
 @String{MathComp = "Math. Comp." }
 @String{MathScand = "Mathematica Scandinavica" }
 @String{MathScand = "Math. Scand." }
 @String{TablesAidsComp = "Mathematical Tables and Other Aids to Computation" }
 @String{TablesAidsComp = "Math. Tables Aids Comput." }
 @String{NumerMath = "Numerische Mathematik" }
 @String{NumerMath = "Numer. Math." }
 @String{PacificMath = "Pacific Journal of Mathematics" }
 @String{PacificMath = "Pacific J. Math." }
 @String{ParDistComp = "Journal of Parallel and Distributed Computing" }
 @String{ParDistComp = "J. Parallel and Distrib. Comput." } % didn't find
%% in AMS MR
 @String{ParComputing = "Parallel Computing" }
 @String{ParComputing = "Parallel Comput." }
 @String{PhilMag = "Philosophical Magazine" }
 @String{PhilMag = "Philos. Mag." }
 @String{ProcNAS = "Proceedings of the National Academy of Sciences
                    of the USA" }
 @String{ProcNAS = "Proc. Nat. Acad. Sci. U. S. A." }
 @String{Psychometrika = "Psychometrika" }
 @String{QuartMath = "Quarterly Journal of Mathematics, Oxford, Series (2)" }
 @String{QuartMath = "Quart. J. Math. Oxford Ser. (2)" }
 @String{QuartApplMath = "Quarterly of Applied Mathematics" }
 @String{QuartApplMath = "Quart. Appl. Math." }
 @String{RevueInstStat = "Review of the International Statisical Institute" }
 @String{RevueInstStat = "Rev. Inst. Internat. Statist." }

 %SIAM
 @String{JSIAM = "Journal of the Society for Industrial and Applied
     Mathematics" }
 @String{JSIAM = "J. Soc. Indust. Appl. Math." }
 @String{JSIAMB = "Journal of the Society for Industrial and Applied
     Mathematics, Series B, Numerical Analysis" }
 @String{JSIAMB = "J. Soc. Indust. Appl. Math. Ser. B Numer. Anal." }
 @String{SIAMAlgMeth = "{SIAM} Journal on Algebraic and Discrete Methods" }
 @String{SIAMAlgMeth = "{SIAM} J. Algebraic Discrete Methods" }
 @String{SIAMAppMath = "{SIAM} Journal on Applied Mathematics" }
 @String{SIAMAppMath = "{SIAM} J. Appl. Math." }
 @String{SIAMComp = "{SIAM} Journal on Computing" }
 @String{SIAMComp = "{SIAM} J. Comput." }
 @String{SIAMMatrix = "{SIAM} Journal on Matrix Analysis and Applications" }
 @String{SIAMMatrix = "{SIAM} J. Matrix Anal. Appl." }
 @String{SIAMNumAnal = "{SIAM} Journal on Numerical Analysis" }
 @String{SIAMNumAnal = "{SIAM} J. Numer. Anal." }
 @String{SIAMReview = "{SIAM} Review" }
 @String{SIAMReview = "{SIAM} Rev." }
 @String{SIAMSciStat = "{SIAM} Journal on Scientific and Statistical
     Computing" }
 @String{SIAMSciStat = "{SIAM} J. Sci. Statist. Comput." }

 @String{SoftPracExp = "Software Practice and Experience" }
 @String{SoftPracExp = "Software Prac. Experience" } % didn't find in AMS MR
 @String{StatScience = "Statistical Science" }
 @String{StatScience = "Statist. Sci." }
 @String{Techno = "Technometrics" }
 @String{USSRCompMathPhys = "{USSR} Computational Mathematics and Mathematical
     Physics" }
 @String{USSRCompMathPhys = "{U. S. S. R.} Comput. Math. and Math. Phys." }
 @String{VLSICompSys = "Journal of {VLSI} and Computer Systems" }
 @String{VLSICompSys = "J. {VLSI} Comput. Syst." }
 @String{ZAngewMathMech = "Zeitschrift fur Angewandte Mathematik und
     Mechanik" }
 @String{ZAngewMathMech = "Z. Angew. Math. Mech." }
 @String{ZAngewMathPhys = "Zeitschrift fur Angewandte Mathematik und Physik" }
 @String{ZAngewMathPhys = "Z. Angew. Math. Phys." }

% Publishers % ================================================= |

 @String{Academic = "Academic Press" }
 @String{ACMPress = "{ACM} Press" }
 @String{AdamHilger = "Adam Hilger" }
 @String{AddisonWesley = "Addison-Wesley" }
 @String{AllynBacon = "Allyn and Bacon" }
 @String{AMS = "American Mathematical Society" }
 @String{Birkhauser = "Birkha{\"u}ser" }
 @String{CambridgePress = "Cambridge University Press" }
 @String{Chelsea = "Chelsea" }
 @String{ClaredonPress = "Claredon Press" }
 @String{DoverPub = "Dover Publications" }
 @String{Eyolles = "Eyolles" }
 @String{HoltRinehartWinston = "Holt, Rinehart and Winston" }
 @String{Interscience = "Interscience" }
 @String{JohnsHopkinsPress = "The Johns Hopkins University Press" }
 @String{JohnWileySons = "John Wiley and Sons" }
 @String{Macmillan = "Macmillan" }
 @String{MathWorks = "The Math Works Inc." }
 @String{McGrawHill = "McGraw-Hill" }
 @String{NatBurStd = "National Bureau of Standards" }
 @String{NorthHolland = "North-Holland" }
 @String{OxfordPress = "Oxford University Press" }  %address Oxford or London?
 @String{PergamonPress = "Pergamon Press" }
 @String{PlenumPress = "Plenum Press" }
 @String{PrenticeHall = "Prentice-Hall" }
 @String{SIAMPub = "{SIAM} Publications" }
 @String{Springer = "Springer-Verlag" }
 @String{TexasPress = "University of Texas Press" }
 @String{VanNostrand = "Van Nostrand" }
 @String{WHFreeman = "W. H. Freeman and Co." }

%Entries


@inproceedings{layoutlm,
  title={Layoutlm: Pre-training of text and layout for document image understanding},
  author={Xu, Yiheng and Li, Minghao and Cui, Lei and Huang, Shaohan and Wei, Furu and Zhou, Ming},
  booktitle={Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery \& Data Mining},
  pages={1192--1200},
  year={2020}
}

@article{layoutlmv2,
  title={Layoutlmv2: Multi-modal pre-training for visually-rich document understanding},
  author={Xu, Yang and Xu, Yiheng and Lv, Tengchao and Cui, Lei and Wei, Furu and Wang, Guoxin and Lu, Yijuan and Florencio, Dinei and Zhang, Cha and Che, Wanxiang and others},
  journal={arXiv preprint arXiv:2012.14740},
  year={2020}
}

@inproceedings{layoutlmv3,
  title={Layoutlmv3: Pre-training for document ai with unified text and image masking},
  author={Huang, Yupan and Lv, Tengchao and Cui, Lei and Lu, Yutong and Wei, Furu},
  booktitle={Proceedings of the 30th ACM International Conference on Multimedia},
  pages={4083--4091},
  year={2022}
}

@article{layoutxlm,
  title={Layoutxlm: Multimodal pre-training for multilingual visually-rich document understanding},
  author={Xu, Yiheng and Lv, Tengchao and Cui, Lei and Wang, Guoxin and Lu, Yijuan and Florencio, Dinei and Zhang, Cha and Wei, Furu},
  journal={arXiv preprint arXiv:2104.08836},
  year={2021}
}

@inproceedings{xylayoutlm,
  title={Xylayoutlm: Towards layout-aware multimodal networks for visually-rich document understanding},
  author={Gu, Zhangxuan and Meng, Changhua and Wang, Ke and Lan, Jun and Wang, Weiqiang and Gu, Ming and Zhang, Liqing},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={4583--4592},
  year={2022}
}

@inproceedings{docformer,
  title={Docformer: End-to-end transformer for document understanding},
  author={Appalaraju, Srikar and Jasani, Bhavan and Kota, Bhargava Urala and Xie, Yusheng and Manmatha, R},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={993--1003},
  year={2021}
}

@inproceedings{docparser,
  title={Docparser: Hierarchical document structure parsing from renderings},
  author={Rausch, Johannes and Martinez, Octavio and Bissig, Fabian and Zhang, Ce and Feuerriegel, Stefan},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={35},
  number={5},
  pages={4328--4338},
  year={2021}
}

@article{xdoc,
  title={XDoc: Unified Pre-training for Cross-Format Document Understanding},
  author={Chen, Jingye and Lv, Tengchao and Cui, Lei and Zhang, Cha and Wei, Furu},
  journal={arXiv preprint arXiv:2210.02849},
  year={2022}
}

@inproceedings{markuplm,
  title={MarkupLM: Pre-training of Text and Markup Language for Visually Rich Document Understanding},
  author={Li, Junlong and Xu, Yiheng and Cui, Lei and Wei, Furu},
  booktitle={Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages={6078--6087},
  year={2022}
}

@inproceedings{lilt,
  title={LiLT: A Simple yet Effective Language-Independent Layout Transformer for Structured Document Understanding},
  author={Wang, Jiapeng and Jin, Lianwen and Ding, Kai},
  booktitle={Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages={7747--7757},
  year={2022}
}

@article{udoc,
  title={Unidoc: Unified pretraining framework for document understanding},
  author={Gu, Jiuxiang and Kuen, Jason and Morariu, Vlad I and Zhao, Handong and Jain, Rajiv and Barmpalios, Nikolaos and Nenkova, Ani and Sun, Tong},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={39--50},
  year={2021}
}

@inproceedings{selfdoc,
  title={Selfdoc: Self-supervised document representation learning},
  author={Li, Peizhao and Gu, Jiuxiang and Kuen, Jason and Morariu, Vlad I and Zhao, Handong and Jain, Rajiv and Manjunatha, Varun and Liu, Hongfu},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={5652--5660},
  year={2021}
}

@inproceedings{lambert,
  title={Lambert: Layout-aware language modeling for information extraction},
  author={Garncarek, {\L}ukasz and Powalski, Rafa{\l} and Stanis{\l}awek, Tomasz and Topolski, Bartosz and Halama, Piotr and Turski, Micha{\l} and Grali{\'n}ski, Filip},
  booktitle={Document Analysis and Recognition--ICDAR 2021: 16th International Conference, Lausanne, Switzerland, September 5--10, 2021, Proceedings, Part I},
  pages={532--547},
  year={2021},
  organization={Springer}
}

@inproceedings{structext,
  title={Structext: Structured text understanding with multi-modal transformers},
  author={Li, Yulin and Qian, Yuxi and Yu, Yuechen and Qin, Xiameng and Zhang, Chengquan and Liu, Yan and Yao, Kun and Han, Junyu and Liu, Jingtuo and Ding, Errui},
  booktitle={Proceedings of the 29th ACM International Conference on Multimedia},
  pages={1912--1920},
  year={2021}
}

@article{bros,
  title={BROS: A pre-trained language model for understanding texts in document},
  author={Hong, Teakgyu and Kim, DongHyun and Ji, Mingi and Hwang, Wonseok and Nam, Daehyun and Park, Sungrae},
  year={2021}
}

@inproceedings{tilt,
  title={Going full-tilt boogie on document understanding with text-image-layout transformer},
  author={Powalski, Rafa{\l} and Borchmann, {\L}ukasz and Jurkiewicz, Dawid and Dwojak, Tomasz and Pietruszka, Micha{\l} and Pa{\l}ka, Gabriela},
  booktitle={Document Analysis and Recognition--ICDAR 2021: 16th International Conference, Lausanne, Switzerland, September 5--10, 2021, Proceedings, Part II 16},
  pages={732--747},
  year={2021},
  organization={Springer}
}

@inproceedings{donut,
  title={Ocr-free document understanding transformer},
  author={Kim, Geewook and Hong, Teakgyu and Yim, Moonbin and Nam, JeongYeon and Park, Jinyoung and Yim, Jinyeong and Hwang, Wonseok and Yun, Sangdoo and Han, Dongyoon and Park, Seunghyun},
  booktitle={Computer Vision--ECCV 2022: 17th European Conference, Tel Aviv, Israel, October 23--27, 2022, Proceedings, Part XXVIII},
  pages={498--517},
  year={2022},
  organization={Springer}
}

@article{ernie-mmlayout,
  title={ERNIE-mmLayout: Multi-grained MultiModal Transformer for Document Understanding},
  author={Wang, Wenjin and Huang, Zhengjie and Luo, Bin and Chen, Qianglong and Peng, Qiming and Pan, Yinxu and Yin, Weichong and Feng, Shikun and Sun, Yu and Yu, Dianhai and others},
  journal={arXiv preprint arXiv:2209.08569},
  year={2022}
}

@article{graphdoc,
  title={Multimodal pre-training based on graph attention network for document understanding},
  author={Zhang, Zhenrong and Ma, Jiefeng and Du, Jun and Wang, Licheng and Zhang, Jianshu},
  journal={IEEE Transactions on Multimedia},
  year={2022},
  publisher={IEEE}
}

@article{e3net,
  title={Document image layout analysis via explicit edge embedding network},
  author={Wu, Xingjiao and Zheng, Yingbin and Ma, Tianlong and Ye, Hao and He, Liang},
  journal={Information Sciences},
  volume={577},
  pages={436--448},
  year={2021},
  publisher={Elsevier}
}

@inproceedings{dit,
  title={Dit: Self-supervised pre-training for document image transformer},
  author={Li, Junlong and Xu, Yiheng and Lv, Tengchao and Cui, Lei and Zhang, Cha and Wei, Furu},
  booktitle={Proceedings of the 30th ACM International Conference on Multimedia},
  pages={3530--3539},
  year={2022}
}

@inproceedings{vsr,
  title={VSR: a unified framework for document layout analysis combining vision, semantics and relations},
  author={Zhang, Peng and Li, Can and Qiao, Liang and Cheng, Zhanzhan and Pu, Shiliang and Niu, Yi and Wu, Fei},
  booktitle={Document Analysis and Recognition--ICDAR 2021: 16th International Conference, Lausanne, Switzerland, September 5--10, 2021, Proceedings, Part I 16},
  pages={115--130},
  year={2021},
  organization={Springer}
}

@inproceedings{layoutreader,
  title={LayoutReader: Pre-training of Text and Layout for Reading Order Detection},
  author={Wang, Zilong and Xu, Yiheng and Cui, Lei and Shang, Jingbo and Wei, Furu},
  booktitle={Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing},
  pages={4735--4744},
  year={2021}
}

@inproceedings{vibertgrid,
  title={ViBERTgrid: a jointly trained multi-modal 2D document representation for key information extraction from documents},
  author={Lin, Weihong and Gao, Qifang and Sun, Lei and Zhong, Zhuoyao and Hu, Kai and Ren, Qin and Huo, Qiang},
  booktitle={Document Analysis and Recognition--ICDAR 2021: 16th International Conference, Lausanne, Switzerland, September 5--10, 2021, Proceedings, Part I 16},
  pages={548--563},
  year={2021},
  organization={Springer}
}

@inproceedings{structurallm,
  title={StructuralLM: Structural Pre-training for Form Understanding},
  author={Li, Chenliang and Bi, Bin and Yan, Ming and Wang, Wei and Huang, Songfang and Huang, Fei and Si, Luo},
  booktitle={Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)},
  pages={6309--6318},
  year={2021}
}

@article{pramanik2020towards,
  title={Towards a multi-modal, multi-task learning based pre-training framework for document representation learning},
  author={Pramanik, Subhojeet and Mujumdar, Shashank and Patel, Hima},
  journal={arXiv preprint arXiv:2009.14457},
  year={2020}
}

@inproceedings{layoutparser,
  title={LayoutParser: A unified toolkit for deep learning based document image analysis},
  author={Shen, Zejiang and Zhang, Ruochen and Dell, Melissa and Lee, Benjamin Charles Germain and Carlson, Jacob and Li, Weining},
  booktitle={Document Analysis and Recognition--ICDAR 2021: 16th International Conference, Lausanne, Switzerland, September 5--10, 2021, Proceedings, Part I 16},
  pages={131--146},
  year={2021},
  organization={Springer}
}

@inproceedings{mtl-foun,
  title={Mtl-foun: A multi-task learning approach to form understanding},
  author={Prabhu, Nishant and Jain, Hiteshi and Tripathi, Abhishek},
  booktitle={Document Analysis and Recognition--ICDAR 2021 Workshops: Lausanne, Switzerland, September 5--10, 2021, Proceedings, Part II 16},
  pages={377--388},
  year={2021},
  organization={Springer}
}

@article{nguyen2022improving,
  title={Improving Document Image Understanding with Reinforcement Finetuning},
  author={Nguyen, Bao-Sinh and Le, Dung Tien and Vu, Hieu M and Nguyen, Tuan Anh D and Nguyen, Minh-Tien and Le, Hung},
  journal={arXiv preprint arXiv:2209.12561},
  year={2022}
}

@inproceedings{kata,
  title={Extracting zero-shot structured information from form-like documents: Pretraining with keys and triggers},
  author={Cao, Rongyu and Luo, Ping},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={35},
  number={14},
  pages={12612--12620},
  year={2021}
}

@article{vila,
  title={VILA: Improving structured content extraction from scientific PDFs using visual layout groups},
  author={Shen, Zejiang and Lo, Kyle and Wang, Lucy Lu and Kuehl, Bailey and Weld, Daniel S and Downey, Doug},
  journal={Transactions of the Association for Computational Linguistics},
  volume={10},
  pages={376--392},
  year={2022},
  publisher={MIT Press}
}

@article{lame,
  title={LAME: Layout Aware Metadata Extraction Approach for Research Articles},
  author={Choi, Jongyun and Kong, Hyesoo and Yoon, Hwamook and Oh, Heung-Seon and Jung, Yuchul},
  journal={arXiv preprint arXiv:2112.12353},
  year={2021}
}

@inproceedings{visualfudge,
  title={Visual fudge: Form understanding via dynamic graph editing},
  author={Davis, Brian and Morse, Bryan and Price, Brian and Tensmeyer, Chris and Wiginton, Curtis},
  booktitle={Document Analysis and Recognition--ICDAR 2021: 16th International Conference, Lausanne, Switzerland, September 5--10, 2021, Proceedings, Part I 16},
  pages={416--431},
  year={2021},
  organization={Springer}
}

@article{bertgrid,
  title={Bertgrid: Contextualized embedding for 2d document representation and understanding},
  author={Denk, Timo I and Reisswig, Christian},
  journal={arXiv preprint arXiv:1909.04948},
  year={2019}
}

@inproceedings{palm2019attend,
  title={Attend, copy, parse end-to-end information extraction from documents},
  author={Palm, Rasmus Berg and Laws, Florian and Winther, Ole},
  booktitle={2019 International Conference on Document Analysis and Recognition (ICDAR)},
  pages={329--336},
  year={2019},
  organization={IEEE}
}

@inproceedings{chargrid,
  title={Chargrid: Towards Understanding 2D Documents},
  author={Katti, Anoop R and Reisswig, Christian and Guder, Cordula and Brarda, Sebastian and Bickel, Steffen and H{\"o}hne, Johannes and Faddoul, Jean Baptiste},
  booktitle={Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing},
  pages={4459--4469},
  year={2018}
}

@inproceedings{vs2,
  title={Visual segmentation for information extraction from heterogeneous visually rich documents},
  author={Sarkhel, Ritesh and Nandi, Arnab},
  booktitle={Proceedings of the 2019 international conference on management of data},
  pages={247--262},
  year={2019}
}

@inproceedings{liu2019graph,
  title={Graph Convolution for Multimodal Information Extraction from Visually Rich Documents},
  author={Liu, Xiaojing and Gao, Feiyu and Zhang, Qiong and Zhao, Huasha},
  booktitle={Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 2 (Industry Papers)},
  pages={32--39},
  year={2019}
}

@inproceedings{majumder2020representation,
  title={Representation learning for information extraction from form-like documents},
  author={Majumder, Bodhisattwa Prasad and Potti, Navneet and Tata, Sandeep and Wendt, James Bradley and Zhao, Qi and Najork, Marc},
  booktitle={proceedings of the 58th annual meeting of the Association for Computational Linguistics},
  pages={6495--6504},
  year={2020}
}

@inproceedings{vies,
  title={Towards robust visual information extraction in real world: New dataset and novel solution},
  author={Wang, Jiapeng and Liu, Chongyu and Jin, Lianwen and Tang, Guozhi and Zhang, Jiaxin and Zhang, Shuaitao and Wang, Qianying and Wu, Yaqiang and Cai, Mingxiang},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={35},
  number={4},
  pages={2738--2745},
  year={2021}
}

@inproceedings{pick,
  title={PICK: processing key information extraction from documents using improved graph learning-convolutional networks},
  author={Yu, Wenwen and Lu, Ning and Qi, Xianbiao and Gong, Ping and Xiao, Rong},
  booktitle={2020 25th International Conference on Pattern Recognition (ICPR)},
  pages={4363--4370},
  year={2021},
  organization={IEEE}
}

@inproceedings{trie,
  title={TRIE: end-to-end text reading and information extraction for document understanding},
  author={Zhang, Peng and Xu, Yunlu and Cheng, Zhanzhan and Pu, Shiliang and Lu, Jing and Qiao, Liang and Niu, Yi and Wu, Fei},
  booktitle={Proceedings of the 28th ACM International Conference on Multimedia},
  pages={1413--1422},
  year={2020}
}

@article{aetnet,
  title={Alignment-Enriched Tuning for Patch-Level Pre-trained Document Image Models},
  author={Wang, Lei and He, Jiabang and Xu, Xing and Liu, Ning and Liu, Hui},
  journal={arXiv preprint arXiv:2211.14777},
  year={2022}
}

@article{udop,
  title={Unifying Vision, Text, and Layout for Universal Document Processing},
  author={Tang, Zineng and Yang, Ziyi and Wang, Guoxin and Fang, Yuwei and Liu, Yang and Zhu, Chenguang and Zeng, Michael and Zhang, Cha and Bansal, Mohit},
  journal={arXiv preprint arXiv:2212.02623},
  year={2022}
}

@article{wukong,
  title={Wukong-Reader: Multi-modal Pre-training for Fine-grained Visual Document Understanding},
  author={Bai, Haoli and Liu, Zhiguang and Meng, Xiaojun and Li, Wentao and Liu, Shuang and Xie, Nian and Zheng, Rongfu and Wang, Liangwei and Hou, Lu and Wei, Jiansheng and others},
  journal={arXiv preprint arXiv:2212.09621},
  year={2022}
}

@inproceedings{montero2022multilevel,
  title={Multilevel Hypernode Graphs for Effective and Efficient Entity Linking},
  author={Montero, David and Mart{\'\i}nez, Javier and Yebes, Javier},
  booktitle={Proceedings of TextGraphs-16: Graph-based Methods for Natural Language Processing},
  pages={1--10},
  year={2022}
}

@inproceedings{hwang2021spatial,
  title={Spatial Dependency Parsing for Semi-Structured Document Information Extraction},
  author={Hwang, Wonseok and Yim, Jinyeong and Park, Seunghyun and Yang, Sohee and Seo, Minjoon},
  booktitle={Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021},
  pages={330--343},
  year={2021}
}

@inproceedings{carbonell2021named,
  title={Named entity recognition and relation extraction with graph neural networks in semi structured documents},
  author={Carbonell, Manuel and Riba, Pau and Villegas, Mauricio and Forn{\'e}s, Alicia and Llad{\'o}s, Josep},
  booktitle={2020 25th International Conference on Pattern Recognition (ICPR)},
  pages={9622--9627},
  year={2021},
  organization={IEEE}
}
@article{docstruct,
  title={Docstruct: A multimodal method to extract hierarchy structure in document for general form understanding},
  author={Wang, Zilong and Zhan, Mingjie and Liu, Xuebo and Liang, Ding},
  journal={arXiv preprint arXiv:2010.11685},
  year={2020}
}

@inproceedings{wei2020robust,
  title={Robust layout-aware IE for visually rich documents with pre-trained language models},
  author={Wei, Mengxi and He, Yifan and Zhang, Qiong},
  booktitle={Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval},
  pages={2367--2376},
  year={2020}
}

@article{gao2022field,
  title={Field Extraction from Forms with Unlabeled Data},
  author={Gao, Mingfei and Chen, Zeyuan and Naik, Nikhil and Hashimoto, Kazuma and Xiong, Caiming and Xu, Ran},
  journal={Spa-NLP 2022},
  pages={30},
  year={2022}
}

@article{pix2struct,
  title={Pix2Struct: Screenshot parsing as pretraining for visual language understanding},
  author={Lee, Kenton and Joshi, Mandar and Turc, Iulia and Hu, Hexiang and Liu, Fangyu and Eisenschlos, Julian and Khandelwal, Urvashi and Shaw, Peter and Chang, Ming-Wei and Toutanova, Kristina},
  journal={arXiv preprint arXiv:2210.03347},
  year={2022}
}

@inproceedings{docgcn,
  title={Doc-GCN: Heterogeneous Graph Convolutional Networks for Document Layout Analysis},
  author={Luo, Siwen and Ding, Yihao and Long, Siqu and Poon, Josiah and Han, Soyeon Caren},
  booktitle={Proceedings of the 29th International Conference on Computational Linguistics},
  pages={2906--2916},
  year={2022}
}
@inproceedings{fastrcnn,
  title={Fast r-cnn},
  author={Girshick, Ross},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={1440--1448},
  year={2015}
}

@inproceedings{maskrcnn,
  title={Mask r-cnn},
  author={He, Kaiming and Gkioxari, Georgia and Doll{\'a}r, Piotr and Girshick, Ross},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={2961--2969},
  year={2017}
}
%previsou related tutorials
@inproceedings{pujara2021tables,
  title={From tables to knowledge: Recent advances in table understanding},
  author={Pujara, Jay and Szekely, Pedro and Sun, Huan and Chen, Muhao},
  booktitle={Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery \& Data Mining},
  pages={4060--4061},
  year={2021}
}

@article{wang2018modern,
  title={Modern Natural Language Processing Techniques for Scientific Web Mining: Tasks, Data, and Tools},
  author={Wang, Xuan and Wang, Hongwei and Ji, Heng and Han, Jiawei},
  year={2018}
}

@inproceedings{dong2020multi,
  title={Multi-modal information extraction from text, semi-structured, and tabular data on the web},
  author={Dong, Xin Luna and Hajishirzi, Hannaneh and Lockard, Colin and Shiralkar, Prashant},
  booktitle={Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery \& Data Mining},
  pages={3543--3544},
  year={2020}
}

% Dataset papers

@inproceedings{sroie,
  title={Icdar2019 competition on scanned receipt ocr and information extraction},
  author={Huang, Zheng and Chen, Kai and He, Jianhua and Bai, Xiang and Karatzas, Dimosthenis and Lu, Shijian and Jawahar, CV},
  booktitle={2019 International Conference on Document Analysis and Recognition (ICDAR)},
  pages={1516--1520},
  year={2019},
  organization={IEEE}
}

@inproceedings{cord,
  title={CORD: a consolidated receipt dataset for post-OCR parsing},
  author={Park, Seunghyun and Shin, Seung and Lee, Bado and Lee, Junyeop and Surh, Jaeheung and Seo, Minjoon and Lee, Hwalsuk},
  booktitle={Workshop on Document Intelligence at NeurIPS 2019},
  year={2019}
}

@inproceedings{publaynet,
  title={Publaynet: largest dataset ever for document layout analysis},
  author={Zhong, Xu and Tang, Jianbin and Yepes, Antonio Jimeno},
  booktitle={2019 International Conference on Document Analysis and Recognition (ICDAR)},
  pages={1015--1022},
  year={2019},
  organization={IEEE}
}

@inproceedings{nda,
  title={Kleister: key information extraction datasets involving long documents with complex layouts},
  author={Stanis{\l}awek, Tomasz and Grali{\'n}ski, Filip and Wr{\'o}blewska, Anna and Lipi{\'n}ski, Dawid and Kaliska, Agnieszka and Rosalska, Paulina and Topolski, Bartosz and Biecek, Przemys{\l}aw},
  booktitle={Document Analysis and Recognition--ICDAR 2021: 16th International Conference, Lausanne, Switzerland, September 5--10, 2021, Proceedings, Part I},
  pages={564--579},
  year={2021},
  organization={Springer}
}

@inproceedings{docvqa,
  title={Docvqa: A dataset for vqa on document images},
  author={Mathew, Minesh and Karatzas, Dimosthenis and Jawahar, CV},
  booktitle={Proceedings of the IEEE/CVF winter conference on applications of computer vision},
  pages={2200--2209},
  year={2021}
}

@inproceedings{visualmrc,
  title={Visualmrc: Machine reading comprehension on document images},
  author={Tanaka, Ryota and Nishida, Kyosuke and Yoshida, Sen},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={35},
  number={15},
  pages={13878--13888},
  year={2021}
}

@inproceedings{docbank,
  title={DocBank: A Benchmark Dataset for Document Layout Analysis},
  author={Li, Minghao and Xu, Yiheng and Cui, Lei and Huang, Shaohan and Wei, Furu and Li, Zhoujun and Zhou, Ming},
  booktitle={Proceedings of the 28th International Conference on Computational Linguistics},
  pages={949--960},
  year={2020}
}

@inproceedings{formnlu,
  title={Form-NLU: Dataset for the Form Natural Language Understanding},
  author={Ding, Yihao and Long, Siqu and Huang, Jiabin and Ren, Kaixuan and Luo, Xingxiang and Chung, Hyunsuk and Han, Soyeon Caren},
  booktitle={Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval},
  pages={2807--2816},
  year={2023}
}


@inproceedings{funsd,
  title={Funsd: A dataset for form understanding in noisy scanned documents},
  author={Jaume, Guillaume and Ekenel, Hazim Kemal and Thiran, Jean-Philippe},
  booktitle={2019 International Conference on Document Analysis and Recognition Workshops (ICDARW)},
  volume={2},
  pages={1--6},
  year={2019},
  organization={IEEE}
}

@inproceedings{xfund,
  title={XFUND: A Benchmark Dataset for Multilingual Visually Rich Form Understanding},
  author={Xu, Yiheng and Lv, Tengchao and Cui, Lei and Wang, Guoxin and Lu, Yijuan and Florencio, Dinei and Zhang, Cha and Wei, Furu},
  booktitle={Findings of the Association for Computational Linguistics: ACL 2022},
  pages={3214--3224},
  year={2022}
}

@article{pdfvqa,
  title={PDFVQA: A New Dataset for Real-World VQA on PDF Documents},
  author={Ding, Yihao and Luo, Siwen and Chung, Hyunsuk and Han, Soyeon Caren},
  journal={arXiv preprint arXiv:2304.06447},
  year={2023}
}

@inproceedings{vdoc,
  title={V-Doc: Visual questions answers with Documents},
  author={Ding, Yihao and Huang, Zhe and Wang, Runlin and Zhang, YanHang and Chen, Xianru and Ma, Yuzhong and Chung, Hyunsuk and Han, Soyeon Caren},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={21492--21498},
  year={2022}
}

@inproceedings{rdvqa,
  title={A Region-based Document VQA},
  author={Wu, Xinya and Zheng, Duo and Wang, Ruonan and Sun, Jiashen and Hu, Minzhen and Feng, Fangxiang and Wang, Xiaojie and Jiang, Huixing and Yang, Fan},
  booktitle={Proceedings of the 30th ACM International Conference on Multimedia},
  pages={4909--4920},
  year={2022}
}

@inproceedings{piggyback,
  title={PiggyBack: Pretrained Visual Question Answering Environment for Backing up Non-deep Learning Professionals},
  author={Zhang, Zhihao and Luo, Siwen and Chen, Junyi and Lai, Sijia and Long, Siqu and Chung, Hyunsuk and Han, Soyeon Caren},
  booktitle={Proceedings of the Sixteenth ACM International Conference on Web Search and Data Mining},
  pages={1152--1155},
  year={2023}
}