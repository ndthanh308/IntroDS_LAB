{
  "title": "Prompt Guided Transformer for Multi-Task Dense Prediction",
  "authors": [
    "Yuxiang Lu",
    "Shalayiding Sirejiding",
    "Yue Ding",
    "Chunlin Wang",
    "Hongtao Lu"
  ],
  "submission_date": "2023-07-28T07:25:57+00:00",
  "revised_dates": [],
  "abstract": "Task-conditional architecture offers advantage in parameter efficiency but falls short in performance compared to state-of-the-art multi-decoder methods. How to trade off performance and model parameters is an important and difficult problem. In this paper, we introduce a simple and lightweight task-conditional model called Prompt Guided Transformer (PGT) to optimize this challenge. Our approach designs a Prompt-conditioned Transformer block, which incorporates task-specific prompts in the self-attention mechanism to achieve global dependency modeling and parameter-efficient feature adaptation across multiple tasks. This block is integrated into both the shared encoder and decoder, enhancing the capture of intra- and inter-task features. Moreover, we design a lightweight decoder to further reduce parameter usage, which accounts for only 2.7% of the total model parameters. Extensive experiments on two multi-task dense prediction benchmarks, PASCAL-Context and NYUD-v2, demonstrate that our approach achieves state-of-the-art results among task-conditional methods while using fewer parameters, and maintains a significant balance between performance and parameter size.",
  "categories": [
    "cs.CV"
  ],
  "primary_category": "cs.CV",
  "doi": null,
  "journal_ref": null,
  "arxiv_id": "2307.15362",
  "pdf_url": "https://arxiv.org/pdf/2307.15362v1",
  "comment": "10 pages",
  "num_versions": null,
  "size_before_bytes": 4917802,
  "size_after_bytes": 61891
}