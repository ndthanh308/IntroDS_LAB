% Generated by IEEEtranS.bst, version: 1.14 (2015/08/26)
\begin{thebibliography}{10}
\providecommand{\url}[1]{#1}
\csname url@samestyle\endcsname
\providecommand{\newblock}{\relax}
\providecommand{\bibinfo}[2]{#2}
\providecommand{\BIBentrySTDinterwordspacing}{\spaceskip=0pt\relax}
\providecommand{\BIBentryALTinterwordstretchfactor}{4}
\providecommand{\BIBentryALTinterwordspacing}{\spaceskip=\fontdimen2\font plus
\BIBentryALTinterwordstretchfactor\fontdimen3\font minus
  \fontdimen4\font\relax}
\providecommand{\BIBforeignlanguage}[2]{{%
\expandafter\ifx\csname l@#1\endcsname\relax
\typeout{** WARNING: IEEEtranS.bst: No hyphenation pattern has been}%
\typeout{** loaded for the language `#1'. Using the pattern for}%
\typeout{** the default language instead.}%
\else
\language=\csname l@#1\endcsname
\fi
#2}}
\providecommand{\BIBdecl}{\relax}
\BIBdecl

\bibitem{vp}
H.~Bahng, A.~Jahanian, S.~Sankaranarayanan, and P.~Isola, ``Exploring visual
  prompts for adapting large-scale models,'' \emph{arXiv preprint
  arXiv:2203.17274}, 2022.

\bibitem{sfg}
F.~J. Bragman, R.~Tanno, S.~Ourselin, D.~C. Alexander, and J.~Cardoso,
  ``Stochastic filter groups for multi-task cnns: Learning specialist and
  generalist convolution kernels,'' in \emph{ICCV}, 2019, pp. 1385--1394.

\bibitem{bmtas}
D.~Brüggemann, M.~Kanakis, S.~Georgoulis, and L.~Van~Gool, ``Automated search
  for resource-efficient branched multi-task networks,'' in \emph{BMVC}, 2020,
  p. 359.

\bibitem{atrc}
D.~Brüggemann, M.~Kanakis, A.~Obukhov, S.~Georgoulis, and L.~Van~Gool,
  ``Exploring relational context for multi-task dense prediction,'' in
  \emph{ICCV}, 2021, pp. 15\,869--15\,878.

\bibitem{detr}
N.~Carion, F.~Massa, G.~Synnaeve, N.~Usunier, A.~Kirillov, and S.~Zagoruyko,
  ``End-to-end object detection with transformers,'' in \emph{ECCV}, 2020, pp.
  213--229.

\bibitem{mtl1}
R.~Caruana, ``Multitask learning,'' \emph{Machine learning}, vol.~28, no.~1,
  pp. 41--75, 1997.

\bibitem{ipt}
H.~Chen, Y.~Wang, T.~Guo, C.~Xu, Y.~Deng, Z.~Liu, S.~Ma, C.~Xu, C.~Xu, and
  W.~Gao, ``Pre-trained image processing transformer,'' in \emph{CVPR}, 2021,
  pp. 12\,299--12\,310.

\bibitem{mtl3}
M.~Crawshaw, ``Multi-task learning with deep neural networks: A survey,''
  \emph{arXiv preprint arXiv:2009.09796}, 2020.

\bibitem{vit}
A.~Dosovitskiy, L.~Beyer, A.~Kolesnikov, D.~Weissenborn, X.~Zhai,
  T.~Unterthiner, M.~Dehghani, M.~Minderer, G.~Heigold, S.~Gelly \emph{et~al.},
  ``An image is worth 16x16 words: Transformers for image recognition at
  scale,'' in \emph{ICLR}, 2021.

\bibitem{voc}
M.~Everingham, L.~Van~Gool, C.~K. Williams, J.~Winn, and A.~Zisserman, ``The
  pascal visual object classes (voc) challenge,'' \emph{International Journal
  of Computer Vision}, vol.~88, no.~2, pp. 303--338, 2010.

\bibitem{tmm_mt2}
Y.~Fang, S.~Cai, Y.~Cao, Z.~Li, and Z.~Zhang, ``Adversarial learning guided
  task relatedness refinement for multi-task deep learning,'' \emph{IEEE
  Transactions on Multimedia}, pp. 1--12, 2022.

\bibitem{nddr-cnn}
Y.~Gao, J.~Ma, M.~Zhao, W.~Liu, and A.~L. Yuille, ``Nddr-cnn: Layerwise feature
  fusing in multi-task cnns by neural discriminative dimensionality
  reduction,'' in \emph{CVPR}, 2019, pp. 3205--3214.

\bibitem{videotr}
R.~Girdhar, J.~Carreira, C.~Doersch, and A.~Zisserman, ``Video action
  transformer network,'' in \emph{CVPR}, 2019, pp. 244--253.

\bibitem{ltb}
P.~Guo, C.-Y. Lee, and D.~Ulbricht, ``Learning to branch for multi-task
  learning,'' in \emph{ICML}, 2020, pp. 3854--3863.

\bibitem{resnet}
K.~He, X.~Zhang, S.~Ren, and J.~Sun, ``Deep residual learning for image
  recognition,'' in \emph{CVPR}, 2016, pp. 770--778.

\bibitem{hyperprompt}
Y.~He, S.~Zheng, Y.~Tay, J.~Gupta, Y.~Du, V.~Aribandi, Z.~Zhao, Y.~Li, Z.~Chen,
  D.~Metzler \emph{et~al.}, ``Hyperprompt: Prompt-based task-conditioning of
  transformers,'' in \emph{ICML}, 2022, pp. 8678--8690.

\bibitem{vpt_prompt}
M.~Jia, L.~Tang, B.-C. Chen, C.~Cardie, S.~Belongie, B.~Hariharan, and S.-N.
  Lim, ``Visual prompt tuning,'' in \emph{ECCV}, 2022, pp. 709--727.

\bibitem{tmm_tr2}
J.~Jiao, Y.-M. Tang, K.-Y. Lin, Y.~Gao, J.~Ma, Y.~Wang, and W.-S. Zheng,
  ``Dilateformer: Multi-scale dilated transformer for visual recognition,''
  \emph{IEEE Transactions on Multimedia}, pp. 1--14, 2023.

\bibitem{rcm}
M.~Kanakis, D.~Bruggemann, S.~Saha, S.~Georgoulis, A.~Obukhov, and L.~V. Gool,
  ``Reparameterizing convolutions for incremental multi-task learning without
  task interference,'' in \emph{ECCV}, 2020, pp. 689--707.

\bibitem{pt1}
B.~Lester, R.~Al-Rfou, and N.~Constant, ``The power of scale for
  parameter-efficient prompt tuning,'' in \emph{EMNLP}, 2021, pp. 3045--3059.

\bibitem{pt2}
X.~L. Li and P.~Liang, ``Prefix-tuning: Optimizing continuous prompts for
  generation,'' in \emph{ACL}, 2021, pp. 4582--4597.

\bibitem{tmm_tr1}
X.~Lin, S.~Sun, W.~Huang, B.~Sheng, P.~Li, and D.~D. Feng, ``Eapt: Efficient
  attention pyramid transformer for image processing,'' \emph{IEEE Transactions
  on Multimedia}, vol.~25, pp. 50--61, 2023.

\bibitem{prompt_survey}
P.~Liu, W.~Yuan, J.~Fu, Z.~Jiang, H.~Hayashi, and G.~Neubig, ``Pre-train,
  prompt, and predict: A systematic survey of prompting methods in natural
  language processing,'' \emph{ACM Computing Surveys}, vol.~55, no.~9, pp.
  1--35, 2023.

\bibitem{mtan}
S.~Liu, E.~Johns, and A.~J. Davison, ``End-to-end multi-task learning with
  attention,'' in \emph{CVPR}, 2019, pp. 1871--1880.

\bibitem{pt3}
X.~Liu, K.~Ji, Y.~Fu, Z.~Du, Z.~Yang, and J.~Tang, ``P-tuning v2: Prompt tuning
  can be comparable to fine-tuning universally across scales and tasks,''
  \emph{arXiv preprint arXiv:2110.07602}, 2021.

\bibitem{swin}
Z.~Liu, Y.~Lin, Y.~Cao, H.~Hu, Y.~Wei, Z.~Zhang, S.~Lin, and B.~Guo, ``Swin
  transformer: Hierarchical vision transformer using shifted windows,'' in
  \emph{ICCV}, 2021, pp. 10\,012--10\,022.

\bibitem{mrn}
M.~Long, Z.~Cao, J.~Wang, and P.~S. Yu, ``Learning multiple tasks with
  multilinear relationship networks,'' \emph{NeurIPS}, vol.~30, 2017.

\bibitem{sgdr}
I.~Loshchilov and F.~Hutter, ``Sgdr: Stochastic gradient descent with warm
  restarts,'' in \emph{ICLR}, 2017.

\bibitem{adamw}
------, ``Decoupled weight decay regularization,'' in \emph{ICLR}, 2019.

\bibitem{fafs}
Y.~Lu, A.~Kumar, S.~Zhai, Y.~Cheng, T.~Javidi, and R.~Feris, ``Fully-adaptive
  feature sharing in multi-task networks with applications in person attribute
  classification,'' in \emph{CVPR}, 2017, pp. 5334--5343.

\bibitem{astmt}
K.-K. Maninis, I.~Radosavovic, and I.~Kokkinos, ``Attentive single-tasking of
  multiple tasks,'' in \emph{CVPR}, 2019, pp. 1851--1860.

\bibitem{cross-stitch}
I.~Misra, A.~Shrivastava, A.~Gupta, and M.~Hebert, ``Cross-stitch networks for
  multi-task learning,'' in \emph{CVPR}, 2016, pp. 3994--4003.

\bibitem{pc}
R.~Mottaghi, X.~Chen, X.~Liu, N.-G. Cho, S.-W. Lee, S.~Fidler, R.~Urtasun, and
  A.~Yuille, ``The role of context for object detection and semantic
  segmentation in the wild,'' in \emph{CVPR}, 2014, pp. 891--898.

\bibitem{pytorch}
A.~Paszke, S.~Gross, F.~Massa, A.~Lerer, J.~Bradbury, G.~Chanan, T.~Killeen,
  Z.~Lin, N.~Gimelshein, and L.~Antiga, ``Pytorch: An imperative style,
  high-performance deep learning library,'' \emph{NeurIPS}, vol.~32, 2019.

\bibitem{composite}
N.~Popovic, D.~P. Paudel, T.~Probst, G.~Sun, and L.~Van~Gool,
  ``Compositetasking: Understanding images by spatial composition of tasks,''
  in \emph{CVPR}, 2021, pp. 6870--6880.

\bibitem{dpt}
R.~Ranftl, A.~Bochkovskiy, and V.~Koltun, ``Vision transformers for dense
  prediction,'' in \emph{ICCV}, 2021, pp. 12\,179--12\,188.

\bibitem{mtl2}
S.~Ruder, ``An overview of multi-task learning in deep neural networks,''
  \emph{arXiv preprint arXiv:1706.05098}, 2017.

\bibitem{sluice}
S.~Ruder, J.~Bingel, I.~Augenstein, and A.~Søgaard, ``Latent multi-task
  architecture learning,'' in \emph{AAAI}, vol.~33, 2019, pp. 4822--4829.

\bibitem{nyud}
N.~Silberman, D.~Hoiem, P.~Kohli, and R.~Fergus, ``Indoor segmentation and
  support inference from rgbd images,'' in \emph{ECCV}, 2012, pp. 746--760.

\bibitem{segmentor}
R.~Strudel, R.~Garcia, I.~Laptev, and C.~Schmid, ``Segmenter: Transformer for
  semantic segmentation,'' in \emph{ICCV}, 2021, pp. 7262--7272.

\bibitem{tsn}
G.~Sun, T.~Probst, D.~P. Paudel, N.~Popović, M.~Kanakis, J.~Patel, D.~Dai, and
  L.~Van~Gool, ``Task switching network for multi-task learning,'' in
  \emph{ICCV}, 2021, pp. 8291--8300.

\bibitem{branched}
S.~Vandenhende, S.~Georgoulis, B.~De~Brabandere, and L.~Van~Gool, ``Branched
  multi-task networks: Deciding what layers to share,'' in \emph{BMVC}, 2019.

\bibitem{mti-net}
S.~Vandenhende, S.~Georgoulis, and L.~V. Gool, ``Mti-net: Multi-scale task
  interaction networks for multi-task learning,'' in \emph{ECCV}, 2020, pp.
  527--543.

\bibitem{survey}
S.~Vandenhende, S.~Georgoulis, W.~Van~Gansbeke, M.~Proesmans, D.~Dai, and
  L.~Van~Gool, ``Multi-task learning for dense prediction tasks: A survey,''
  \emph{TPAMI}, vol.~44, no.~7, pp. 3614--3633, 2021.

\bibitem{transformer}
A.~Vaswani, N.~Shazeer, N.~Parmar, J.~Uszkoreit, L.~Jones, A.~N. Gomez,
  {\L}.~Kaiser, and I.~Polosukhin, ``Attention is all you need,''
  \emph{NeurIPS}, vol.~30, 2017.

\bibitem{pt_cont1}
A.~Villa, J.~L. Alcázar, M.~Alfarra, K.~Alhamoud, J.~Hurtado, F.~C. Heilbron,
  A.~Soto, and B.~Ghanem, ``Pivot: Prompting for video continual learning,''
  \emph{arXiv preprint arXiv:2212.04842}, 2022.

\bibitem{taps}
M.~Wallingford, H.~Li, A.~Achille, A.~Ravichandran, C.~Fowlkes, R.~Bhotika, and
  S.~Soatto, ``Task adaptive parameter sharing for multi-task learning,'' in
  \emph{CVPR}, 2022, pp. 7561--7570.

\bibitem{hrnet}
J.~Wang, K.~Sun, T.~Cheng, B.~Jiang, C.~Deng, Y.~Zhao, D.~Liu, Y.~Mu, M.~Tan,
  X.~Wang \emph{et~al.}, ``Deep high-resolution representation learning for
  visual recognition,'' \emph{TPAMI}, vol.~43, no.~10, pp. 3349--3364, 2020.

\bibitem{pvt}
W.~Wang, E.~Xie, X.~Li, D.-P. Fan, K.~Song, D.~Liang, T.~Lu, P.~Luo, and
  L.~Shao, ``Pyramid vision transformer: A versatile backbone for dense
  prediction without convolutions,'' in \emph{ICCV}, 2021, pp. 568--578.

\bibitem{videotr2}
Y.~Wang, Z.~Xu, X.~Wang, C.~Shen, B.~Cheng, H.~Shen, and H.~Xia, ``End-to-end
  video instance segmentation with transformers,'' in \emph{CVPR}, 2021, pp.
  8741--8750.

\bibitem{pt_cont2}
Z.~Wang, Z.~Zhang, C.-Y. Lee, H.~Zhang, R.~Sun, X.~Ren, G.~Su, V.~Perot, J.~Dy,
  and T.~Pfister, ``Learning to prompt for continual learning,'' in
  \emph{CVPR}, 2022, pp. 139--149.

\bibitem{evp}
J.~Wu, X.~Li, C.~Wei, H.~Wang, A.~Yuille, Y.~Zhou, and C.~Xie, ``Unleashing the
  power of visual prompting at the pixel level,'' \emph{arXiv preprint
  arXiv:2212.10556}, 2022.

\bibitem{pad-net}
D.~Xu, W.~Ouyang, X.~Wang, and N.~Sebe, ``Pad-net: Multi-tasks guided
  prediction-and-distillation network for simultaneous depth estimation and
  scene parsing,'' in \emph{CVPR}, 2018, pp. 675--684.

\bibitem{mtformer}
X.~Xu, H.~Zhao, V.~Vineet, S.-N. Lim, and A.~Torralba, ``Mtformer: Multi-task
  learning via transformer and cross-task reasoning,'' in \emph{ECCV}, 2022,
  pp. 304--321.

\bibitem{mqt}
Y.~Xu, X.~Li, H.~Yuan, Y.~Yang, J.~Zhang, Y.~Tong, L.~Zhang, and D.~Tao,
  ``Multi-task learning with multi-query transformer for dense prediction,''
  \emph{arXiv preprint arXiv:2205.14354}, 2022.

\bibitem{demt}
Y.~Xu, Y.~Yang, and L.~Zhang, ``Demt: Deformable mixer transformer for
  multi-task learning of dense prediction,'' \emph{arXiv preprint
  arXiv:2301.03461}, 2023.

\bibitem{tmm_mt1}
S.~Yang, Y.~Wang, K.~Chen, W.~Zeng, and Z.~Fei, ``Attribute-aware feature
  encoding for object recognition and segmentation,'' \emph{IEEE Transactions
  on Multimedia}, vol.~24, pp. 3611--3623, 2022.

\bibitem{dmtrl}
Y.~Yang and T.~Hospedales, ``Deep multi-task representation learning: A tensor
  factorisation approach,'' in \emph{ICLR}, 2017.

\bibitem{invpt}
H.~Ye and D.~Xu, ``Inverted pyramid multi-task transformer for dense scene
  understanding,'' in \emph{ECCV}, 2022, pp. 514--530.

\bibitem{taskprompter}
------, ``Taskprompter: Spatial-channel multi-task prompting for dense scene
  understanding,'' in \emph{ICLR}, 2023.

\bibitem{tet}
X.~Zhang, S.~Zhang, Z.~Cui, Z.~Li, J.~Xie, and J.~Yang, ``Tube-embedded
  transformer for pixel prediction,'' \emph{IEEE Transactions on Multimedia},
  pp. 1--1, 2022.

\bibitem{vpt1}
X.~Zhang, L.~Zhou, Y.~Li, Z.~Cui, J.~Xie, and J.~Yang, ``Transfer vision
  patterns for multi-task pixel learning,'' in \emph{ACM MM}, 2021, pp.
  97--106.

\bibitem{jtrl}
Z.~Zhang, Z.~Cui, C.~Xu, Z.~Jie, X.~Li, and J.~Yang, ``Joint task-recursive
  learning for semantic segmentation and depth estimation,'' in \emph{ECCV},
  2018, pp. 235--251.

\bibitem{pap-net}
Z.~Zhang, Z.~Cui, C.~Xu, Y.~Yan, N.~Sebe, and J.~Yang, ``Pattern-affinitive
  propagation across depth, surface normal and semantic segmentation,'' in
  \emph{CVPR}, 2019, pp. 4106--4115.

\bibitem{psd}
L.~Zhou, Z.~Cui, C.~Xu, Z.~Zhang, C.~Wang, T.~Zhang, and J.~Yang,
  ``Pattern-structure diffusion for multi-task learning,'' in \emph{CVPR},
  2020, pp. 4514--4523.

\bibitem{deformabledetr}
X.~Zhu, W.~Su, L.~Lu, B.~Li, X.~Wang, and J.~Dai, ``Deformable detr: Deformable
  transformers for end-to-end object detection,'' in \emph{ICLR}, 2021.

\end{thebibliography}
