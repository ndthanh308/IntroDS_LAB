\section{Related Work}
% \han{(1) refer to the related work of the paper: https://arxiv.org/abs/2104.02416.}

% \han{(2) introduce existing Android GUI datasets. refer to the relate work of rico paper: https://dl.acm.org/doi/10.1145/3126594.3126651. refer to Chi2022 paper: https://arxiv.org/pdf/2201.04100.pdf}

\subsection{Android GUI dataset}
The research community has collected datasets to facilitate diverse deep learning-based applications in the realm of mobile app design.
Rico~\cite{deka2017rico} is the largest publicly available Android GUI dataset containing 72,219 screenshots from 9,772 apps.
It was built by the combination of crowdsourcing and automation and has been widely used as the primary data source for GUI modeling research.
However, several weaknesses~\cite{deka2021early,lee2020guicomp}, such as noise and erroneous labeling, have been identified in Rico.
To tackle these issues, a series of Android GUI datasets curated utilizing filtering and repairing mechanisms are introduced.
Enrico~\cite{leiva2020enrico} is the first enhanced dataset drawn from Rico, which is used for mobile layout design categorization and consists of 1460 high-quality screenshots produced by human revision, covering 20 different GUI design topics.
The VINS dataset~\cite{bunian2021vins}, developed specifically for detecting GUI elements, comprises 2,740 Android screenshots manually collected from various sources including Rico and Google Play.
Since the data cleaning process for both the Enrico and VINS datasets involves humans, adopting such approaches to improve existing Android GUI datasets at scale is expensive and time-consuming.
To this end, CLAY~\cite{li2022learning} employs deep learning models to automatically denoise Android screen layouts and create a large-scale GUI dataset with 59,555 screenshots on the basis of Rico. 
Apart from these Rico-based GUI datasets, several works~\cite{chen2018ui,chen2019gallery,chen2020wireframe,chen2020unblind,wang2021screen2words, hu2019code, hu2023automated, hu2023look, hu2023pairwise, hu2023first, chen2021my, huang2021robustness} also build their datasets for various GUI-related tasks such as Skeleton Generation, search and component prediction.

Despite improvements in recent Android GUI datasets, they are lack of updates so that some of their GUI styles are out-of-date.
More importantly, none of the datasets provides pairwise GUI pages between different mobile devices.
To fill the current gaps, we first introduce a pairwise dataset consisting of 10,035 phone-tablet GUI page pairs collected from 5,593 phone-tablet app pairs~\cite{hu2023pairwise}, which can be used for GUI conversion, retrieval, and recommendation between Android phones and tablets.




\subsection{Layout Generation}
As one of the main goals for our dataset is to facilitate the GUI conversion between Android and tablet apps, we apply layout generation techniques to our dataset.
Here we present a succinct review of existing layout generation techniques.
LayoutGAN~\cite{li2019layoutgan} is the first approach that utilizes a generative model (i.e., Generative Adversarial Network) to generate layouts.
In particular, it adopts self-attention layers to generate a realistic layout and proposes a novel differentiable wireframe rendering layer to enable Convolutional Neural Network (CNN)-based discrimination.
LayoutVAE~\cite{jyothi2019layoutvae} is an autoregressive generative model, which uses Long Short-Term Memory~\cite{hochreiter1997long} to consolidate the information from multiple UI elements and leverages Variational Autoencoders (VAEs)~\cite{kingma2013auto} to generate layouts.
Recently, VTN~\cite{arroyo2021variational} also exploits VAE architecture but both encoder and decoder are substituted with Transformers~\cite{vaswani2017attention}.
Equipped with self-attention layers, VTN possesses the capacity to learn appropriate layout arrangements without annotations.
At the same time, LayoutTransformer~\cite{gupta2021layouttransformer}, a purely Transformer-based framework, is proposed for layout generation.
It captures co-occurrences and implicit relationships among elements in layouts and uses such captured features to produce layouts with bounding boxes as units.
Based on our experiment results, we find that current layout generation models have limited capacity for GUI conversion between Android and tablet layouts, suggesting the potential research direction in automated GUI development.

 


\subsection{GUI Design Search}
Another goal of our dataset is to support the GUI retrieval that searches and recommends the comparable tablet GUI design in accordance with an Android GUI design.
We thus employ GUI design search techniques for our dataset.
Many research efforts have been made in GUI design search in recent years.
Rico~\cite{deka2017rico} is a neural-based training framework that aims to facilitate query-by-example search.
It provides a layout-encoding vector representation for each UI and offers a variety of visual representations for search engines.
GUIFetch~\cite{behrang2018guifetch} searches GUI design by leveraging a code-search technique, which retrieves the most similar GUI code for users based on their provided sketches.
WAE~\cite{chen2020wireframe} is a wireframe-based searching model that utilizes image autoencoder architecture to address the challenge of labeling large-scale GUI designs.
In light of the experiment results, deep learning-based approaches are able to achieve satisfactory performance.
Moreover, we anticipate the research community can dedicate more effort to the GUI retrieval between Android and tablet apps as this area is yet under-explored.





