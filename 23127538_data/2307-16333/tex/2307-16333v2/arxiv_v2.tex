\documentclass[12pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[margin=1in]{geometry}
\usepackage{amsmath}
\usepackage{amssymb}  

%% using times for now 
\usepackage{times}             %%%%%%%%%%%%%%%%%%

\usepackage{enumerate}
\usepackage{amsthm}
\usepackage{comment}
\usepackage{appendix}
\usepackage{subcaption}
\usepackage{tikz-cd}
\usepackage{algorithm}
\usepackage{url}
\usepackage{xcolor}
\usetikzlibrary{shadows}
\usepackage{algpseudocode}
\makeatother
\usepackage{graphicx}
\graphicspath{ {./Figures/} }
\usepackage{thm-restate}



\usepackage{hyperref}
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    filecolor=magenta,      
    urlcolor=cyan,
    citecolor=blue,
    }





\usepackage{framed}
\usepackage[normalem]{ulem}

\newcommand{\R}{\mathbb{R}}
\newcommand{\Z}{\mathbb{Z}}

\newcommand\norm[1]{\left\lVert#1\right\rVert}
\newcommand\shrunk[1]{\text{shrunk}(#1)}
\newcommand\troot[1]{\text{root}(#1)}
\newcommand\vr{\mathcal{V}}
\newcommand\myceil[1]{\left \lceil #1 \right \rceil }
\newcommand\length[1]{\text{length}(#1)}
\newcommand\compo[1]{\text{compo}(#1)}
\newcommand{\union}[2]{\text{union}(#1,#2).}
\newcommand\dist[1]{\text{dist}(#1)}
\newcommand\neighbor[1]{\text{neighbor}(#1)}
\newcommand\ph[1]{\text{PH}_{#1}}
\newcommand\sort{\mathrm{sort}}
\newcommand\lune{\mathrm{lune}}
\newcommand
\lume{\mathrm{lume}}
\newcommand
\lens{\mathrm{lens}}
\newcommand\rng{\mathrm{RNG}}
\newcommand\id{\mathrm{id}}
\newcommand\diam{\mathrm{diam}}

\newcommand\mst{\mathrm{MST}}
\newcommand\mrng{\mathrm{MRNG}}
\newcommand\bd{\mathrm{bd}}
\newcommand\hull{\mathrm{hull}}
\newcommand\capp{\mathrm{cap}}
\newcommand\rvr{\mathcal{R}}
\newcommand\gabg{\mathrm{GG}}
\newcommand\Angle{\mathrm{Angle}}
\newcommand\sktwo{\mathrm{SK}_{2}}
\newcommand
\skone{\mathrm{SK}_{1}}
\newcommand
\sk{\mathrm{SK}}
\newcommand\inc{\mathrm{inc}_{r_1^{r_2}}}
\newcommand\incr{_{R}\mathrm{inc}_{r_1}^{r_2}}

%\newtheorem{theorem}{Theorem}[section]
%\newtheorem{example}{Example}[section]
%\newtheorem{lemma}{Lemma}[section]
%\newtheorem{definition}{Definition}[section]

\theoremstyle{plain}
\newtheorem*{theorem*}{Theorem}
\newtheorem{theorem}{Theorem}[section]
%\newtheorem{theorem}{Theorem}%[section]
%\renewcommand\thetheorem{\Alph{theorem}}

\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{cor}[theorem]{Corollary}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{prop}[theorem]{Proposition}
\newtheorem{thm}[theorem]{Theorem}
\newtheorem{lem}[theorem]{Lemma}

%
\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{defn}[theorem]{Definition}
\newtheorem{example}[theorem]{Example}
\newtheorem{remark}[theorem]{Remark}
\newtheorem{proposition}[theorem]{Proposition}

\newcommand\VR[1]{\textcolor{green}{#1}}
\newcommand\MK[1]{\textcolor{magenta}{#1}}
\newcommand\facundo[1]{\textcolor{red}{#1}}



\title{Faster computation of degree-1 persistent homology using the reduced Vietoris-Rips filtration}
\author{Musashi Koyama, Facundo M\'emoli, Vanessa Robins, Katharine Turner}
\date{\today}

\begin{document}

\maketitle

\begin{abstract}
Computing Vietoris-Rips persistent homology on a point cloud is computationally expensive, making it unsuitable for analysis of large datasets. In this paper, we present an alternative method for computing Vietoris-Rips persistent homology on point clouds in Euclidean space. We introduce a Reduced Vietoris-Rips complex, which contains an order of magnitude fewer simplices but has the same persistent homology as the Vietoris-Rips filtration. By using the Reduced Vietoris-Rips complex and leveraging the geometry of Euclidean space, we are able to compute the Vietoris-Rips persistent homology for significantly larger point clouds than current implementations. 
\end{abstract}

\subsubsection*{Keywords:} Persistent homology, Vietoris-Rips filtration, Relative neighborhood graph. 

\subsubsection*{MSC:} 
Primary: 55N31 Persistent homology and applications, topological data analysis \\
Secondary: 68T09 Computational aspects of data analysis and big data


\subsubsection*{Acknowledgements}

    F.M. was supported
by the NSF through grants  IIS-1901360, CCF-1740761, CCF-
2310412, DMS-2301359 and by the BSF under grant 2020124.
K.T. was suppported by the ARC through DECRA Fellowship DE200100056.
 
\clearpage
\tableofcontents

\section{Introduction}
\label{Introduction}

Persistent homology is the study of how topological features evolve in a filtration of topological spaces. One of the most fundamental structures in persistent homology is the persistence barcode which summarises the parameter lifespan of topological features in the filtration.  The beginnings of persistent homology can be traced back to \cite{frosini_1990} where size theory, equivalent to modern day zero-dimensional persistent homology was introduced by Frosini. Modern persistent homology was developed fairly simultaneously by Robins \cite{vanessa_robins_article}, and Edelsbrunner, Letscher and Zomorodian \cite{edelsbrunner_original}. Since then, persistent homology has been employed in several disciplines such as health \cite{BIO21010LungCancerSurvivalisAssociatedWithPersistentHomologyofTumorImaging} and materials science \cite{nearly_hexagonal_lattice}. 



In this paper we are interested in the shape approximated by a finite set of points, which we call a point cloud. To apply persistent homology to a point cloud we must construct a filtration of topological spaces. Popular choices include the Alpha-shape filtration \cite{alpha_shape_reference} and the Vietoris-Rips filtration \cite{vietoris1927hoheren}. For point clouds in $\mathbb{R}^2$ and $\mathbb{R}^3$, there are efficient algorithms to compute persistent homology of the Alpha-shape filtration, but at the time of writing there is no software capable of computing Vietoris-Rips persistent homology (VRPH) for large point clouds in a personal computer. In the digital age, data sets consisting of billions of data points are not uncommon, meaning if persistent homology is to be adopted by the greater science community then there is a necessity for software that can compute persistent homology for such large point clouds.

Currently, the most popular software for computing VRPH is Ripser \cite{Ripser} and its GPU accelerated version Ripser++ \cite{zhang2020gpu}. At the time of writing, neither implementation has the capability to compute degree-1 VRPH of point clouds with $10^6$ points on a desk-top computer. 

Degree-1 Vietoris-Rips persistent homology is difficult to compute  because the filtration contains a large number of simplices. 
Given a point cloud with $n$ points,  the standard filtration constructs $O(n^3)$ simplices to compute the degree-1 VRPH. 
Even for a method which computes persistent homology  in linear time on the number of simplices, this computational complexity is simply too high for widespread adoption of VRPH. 



In this paper we present a new algorithm for computing the degree-1 VRPH of a point cloud $X$ by constructing a filtration, called the \emph{reduced Vietoris-Rips fltration} of $X$ and denoted $\rvr_\bullet(X)$, containing a greatly reduced number of 2-simplices with respect to the standard Vietoris-Rips filtration $\vr_\bullet(X)$. This reduced filtration can be constructed for any finite metric space. Our main result proves that the reduced Vietoris-Rips filtration has degree-1 persistent homology isomorphic to that of  the standard Vietoris-Rips filtration.

\begin{restatable}[Main Theorem]{theorem}{isotheorem}\label{theorem-VR-RVR-isomorphism}
Consider a finite metric space $X$.   
Then there exists a family of isomorphisms $\theta_{\bullet}$ such that the following diagram commutes

 

\begin{equation}
 \begin{tikzcd}[ampersand replacement=\&]
  H_{1}(\rvr_{r_1}(X)) \arrow[r, "f_{r_1}^{r_2}"] \arrow[d, "\theta_{r_1}"'] \& H_{1}(\rvr_{r_2}(X)) \arrow[d, "\theta_{r_2}"] \\
  H_{1}(\vr_{r_1}(X)) \arrow[r, "g_{r_1}^{r_2}"] \& H_{1}(\vr_{r_2}(X))
  \end{tikzcd} 
\end{equation}

\noindent for all $r_1$ and $r_2$ such that $0 \leq  r_1 < r_2$.  Above, $f_{r_1}^{r_2}$ and $g_{r_1}^{r_2}$ are the maps at homology level induced by the natural inclusions. 
\end{restatable}



In devising an efficient implementation of the reduced Vietoris-Rips filtration we restrict to point clouds in Euclidean space as this enables the use of geometric data structures that speed up location searching, specifically the $kd$-tree.  
The experiments presented in this paper work with data in $\R^2$ and $\R^3$ and the code package is optimised for these settings, however there is no theoretical obstacle to extending our implementation  to higher-dimensional Euclidean spaces. 




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%




\section{Preliminaries}
\label{Preliminaries}

In this section we briefly review notation and  preliminary concepts necessary for content later in the paper.

\subsection{Notation and terminology}
\label{Notation}



The primary object of study is a finite set of points $X$ (a point cloud) embedded as a subset of $D$-dimensional Euclidean space $\mathbb{R}^{D}$ with a bijection $\psi: X \rightarrow \{1,....|X|\}$ which assigns each point a natural number from $1$ to $n = |X|$.
The distance between two points in $x_1, x_2 \in \R^D$ will be written $d(x_1,x_2)$. In this paper, $n$ will exclusively be used to denote the size of a point cloud, that is $n = |X|$. 
A $q$-simplex consisting of the vertices $x_0,\ldots,x_q$ will be denoted as $\langle x_0\ldots x_q \rangle$. 


\subsection{Homology}

Here we will give a terse introduction to simplicial homology, its main purpose is to establish notation. We present only what is absolutely necessary and do not state the results in their utmost generality. The reader who desires more details is directed towards Munkres' textbook \emph{Elements of Algebraic Topology}  \hspace{0.5pt}\cite{munkres2018elements}.

First we will define the notion of a simplicial complex.



\begin{definition}[Simplicial complex]
    A simplicial complex with vertex set $V = \{v_{1},...,v_{n}\}$ is a set $K \subset 2^{V}$ which satisfies the following properties. 

    \begin{itemize}
        \item $\emptyset \in K$
        
        \item $\{v_{i}\} \in K$ for all $i\in \{1,...,n\}$. 

        \item If $\sigma \in K$, then all subsets of $\sigma$ are also in $K$. 

        \item If $\tau \in K$ and $\sigma \in K$ then $\tau \cap \sigma \in K$. 
    \end{itemize}
\end{definition}

Next we define the notion of a simplex. 

\begin{definition}[$p$-simplex]
    Consider a simplicial complex $K$ with vertex set $V = \{v_1,...,v_n\}$. Then let $\sigma$ be a subset of $V$ with $q+1$ elements. Then we refer to $\sigma$ as a $q$-simplex.
\end{definition}

We will make reference to the dimension of a simplex in Definition \ref{binary-relation-on-simplices}. 

\begin{definition}[Dimension of a simplex]
    Consider a simplicial complex $K$. Let $\sigma$ be a $q$-simplex, then we say that $\sigma$ has dimension $q$ and denote this by $\dim (\sigma) = q$
\end{definition}

It will be convenient later on to have a special term for when one simplex is a subset of another simplex. 

\begin{definition}[Faces and cofaces]
    Consider a simplicial complex $K$ with simplices $\sigma, \tau$ with $\sigma \subset \tau$. Then we say that $\sigma$ is a face of $\tau$ and $\tau$ is a coface of $\sigma$. 
\end{definition}



From here on in we write $\sigma = \{w_0,...,w_q\}$ as $\langle w_0...w_{q}\rangle$, following  standard notation for oriented simplices. Since we are working with $\mathbb{Z}_{2}$-coefficients we can effectively ignore the orientation of the simplices. This means that we can refer to a given simplex using any permutation of its vertices. For example, the $2$-simplex $\langle xyz \rangle$ can equally be referred to as $\langle xzy \rangle = \langle zxy \rangle = \langle zyx \rangle = \langle yzx \rangle = \langle yxz \rangle$.  

The addition of simplices is formalised in the next definition. 



\begin{definition}[Simplicial $q$-chain]
    A simplicial $q$-chain is a finite formal sum of $q$ simplices,  
    \begin{equation}
        \sum_{ i = 1}^{N}c_i\sigma_i
    \end{equation}
    In this paper, the coefficients $c_i$ are taken from $\mathbb{Z}_2$. 
\end{definition}

We now define three important vector spaces. 

\begin{definition}[Chain group]
    $C_{q}(K)$ is the free abelian group with coefficients in $\mathbb{Z}_2$ with generating set consisting of all $q$-simplices. It is customary to set $C_{-1}(K) = \mathbb{Z}_{2}$. 
\end{definition}

\begin{remark}
    It is worth noting that $C_{q}(K)$ is actually a vector space since $\mathbb{Z}_{2}$ is a field and that from this point on, any time the word ``group" is mentioned it could be replaced with ``vector space". We continue to use the word group to adhere to the ``traditional" presentation of persistent homology, though the reader unfamiliar with groups can replace them with vector spaces for the purposes of this paper. 
\end{remark}

\begin{definition}[Boundary map]
    Let $K$ be a simplicial complex. Consider the map $\partial_{q+1}^{K}: C_{q+1}(K)\rightarrow C_{q}(K)$ defined as follows. Let $\sigma = \langle v_{0},...,v_{q}\rangle$. Then we define $\partial_{q+1}^{K} (\sigma)$ as follows:

    \begin{equation}
        \partial_{q+1}^{K} (\sigma) = \sum_{i=0}^{q}\langle v_{0}...\hat{v_i}...v_q \rangle 
    \end{equation}
    We extend this linearly to a map on $C_{q+1}(K)$.
    Here $\hat{v_i}$ means that $v_i$ is to be omitted from $\langle v_0...v_i...v_q\rangle$. When it is clear what $K$ is, we may write $\partial_{q+1}^K$ as $\partial_{q+1}$. When $q$ is also clear, we may simply write $\partial_{q+1}$ as $\partial$. 
    The map $\partial_{0}^K: C_{0}(K) \rightarrow C_{-1}(K) = \mathbb{Z}_{2}$ acts in the following fashion:

    \begin{equation}
        \partial_{0}^{K} (\langle v_0 \rangle) = 1
    \end{equation}

    $\partial_{0}^{K}$ takes a simplicial $0$-chain and maps it to the parity of the number of $0$-simplices in the chain. 
\end{definition}

\begin{definition}[$q$-cycles]
    Consider a simplicial complex $K$. We denote $\mathrm{ker}(\partial_q^K) = Z_{q}(K)$. We call a $q$-chain $c \in Z_{q}(K)$ a $q$-cycle. $Z_{q}(K)$ will be referred to as the group of $q$-cycles. 
\end{definition}

\begin{definition}[$q$-boundaries]
    Consider a simplicial complex $K$. We denote $\mathrm{im}(\partial_{q+1}) = B_{q}(K)$. We call a $q$-chain $c \in B_{q}(K)$ a $q$-boundary. $B_{q}(K)$ will be referred to as the group of $q$-boundaries. 
\end{definition}

We are now ready to define the homology groups of a simplicial complex $K$, but before we do, we state an extremely easy to verify lemma. 

\begin{lemma}
\label{boundary-of-boundary}
    Consider a simplicial complex $K$. Then we have $B_{q}(K) \subset Z_{q}(K)$. 
\end{lemma}

\begin{definition}[Homology groups of a simplicial complex]
Consider a simplicial complex $K$. Then the $q$th homology group is defined as $H_{q}(K) = Z_{q}(K)/B_{q}(K)$ 
\end{definition}

Note that Lemma $\ref{boundary-of-boundary}$ is necessary to show that $B_{q}(K)$ is indeed a subgroup of $Z_{q}(K)$ and hence the quotient group can be taken. It is here that we note that elements of $H_{q}(K)$ will be written as $[\gamma]$ to denote the fact that $\gamma$ is a representative of the class $[\gamma] \in H_{q}(K)$. Sometimes we will also use coset notation and write $[\gamma]$ as $\gamma + H_{q}(K)$. 

\subsection{Persistent Homology}


The following is a brief summary of some basic definitions in persistent homology. The reader who desires more context and details is directed towards chapter 7 of \emph{Computational Topology} \cite{book}, where the definitions below come from. 

\begin{definition}[Filtration of simplicial complexes]
Given an index set $\mathcal{I}$ and a set of simplicial complexes $(K_{i})_{i\in \mathcal{I}}$, if for $i \leq j$ in $\mathcal{I}$ we have $K_{i} \subset K_{j}$, we call the collection $(K_{i})_{i\in \mathcal{I}}$ a filtration of simplicial complexes.
\end{definition}

In the algorithm for computing persistent homology, we require 
a particular type of filtration.


\begin{definition}[Simplex-wise filtrations]
\label{def-simplex-wise-filtrations}
$(K_{i})_{i\in \mathcal{I}}$ is a simplex-wise filtration when $\mathcal{I} = \{0,...,m\} \subset \Z$ and $K_{i} = K_{i-1}\cup \sigma_{i}$  for $i \leq m$ where $\sigma_{i}$ is a single simplex and it is understood that $K_{0} = \emptyset$.
\end{definition}
%
As per this definition, $m$ will always denote the number of simplices of all possible dimensions in the filtration. 

Consider a simplex-wise filtration. For $i<j$ we apply the degree $q$ homology functor $H_{q}(-)$ to the inclusion $K_{i} \subset K_{j}$ to obtain a linear homomorphism $f_{i}^{j}: H_{q}(K_{i})\rightarrow H_{q}(K_j)$. Persistent homology quantifies how the homology changes across the parameter range. 



\begin{definition}[Birth index and giving birth]
Consider a simplex-wise filtration $(K_{i})_{i\in \{0,...,m\}}$. A homology class $[\gamma] \in H_{q}(K_{j})$ is said to be born at index $j$ if $j$ is the smallest index such that for all $j' < j$ there is no $[\beta] \in H_{q}(K_{j'})$ with  $f_{j'}^{j}([\beta ]) = [\gamma]$. The simplex $\sigma_j$ is said to give birth to the homology class $\gamma$. 
\end{definition}

\begin{definition}[Death index and killing]
\label{definition-of-death}
Consider a simplex-wise filtration $(K_{i})_{i\in \{0,...,m\}}$. A homology class $[\gamma]$ born at $j$ is said to die at index $k$ if $k$ is the smallest index such that $f_{j}^{k}([\gamma]) = f_{j'}^{k}([\beta])$ for some $j' < j$ and some $[\beta] \in H_{q}(K_{j'})$. The simplex $\sigma_{k}$, such that $K_{k} = K_{k-1}\cup \sigma_{k}$, is said to kill the homology class $[\gamma]$. 
\end{definition}

An important fact to establish is that for a simplex-wise filtration $(K_{i})_{i\in \{0,...,m\}}$ each simplex can only give birth to a homology class or kill a homology class. We prove this fact by first establishing some lemmas. 

\begin{lemma}
\label{can-only-birth}
    Let $(K_{i})_{i\in \{0,...,m\}}$ be a simplex-wise filtration and consider the change in homology between $K_{i-1}$ and $K_{i} = K_{i-1} \cup \sigma_{i}$, where $\sigma_{i}$ is a $q$-simplex. Then $\partial \sigma_{i} \in B_{q-1}(K_{i-1})$ if and only if $\sigma_{i}$ gives birth to a degree-$q$ homology class. 
\end{lemma}

\begin{proof}
    Suppose $\partial \sigma_{i} \in B_{q-1}(K_{i-1})$. Then we must have that $\partial \sigma_{i} = \sum_{j\in A} \partial \sigma_{j}$ where $A \subset \{0,...,i-1\}$. Then we have that $\partial \sigma_{i} - \sum_{j\in A}\partial \sigma_{j} = 0$ and thus $\partial (\sigma_{i} - \sum_{j \in A} \sigma_{j}) = 0$. Then we have that $\sigma_{i} - \sum_{j\in A}\tau_{j} + B_{q}(K_{i})$ is a homology class which is born at $i$. Note that $\sigma_{i} - \sum_{j\in A} \tau_{j} + B_{q}(K_{i})$ cannot possibly be  expressed in the form $f_{j}^{i}(\gamma + B_{q}(K_{j})) = \sigma_{i} - \sum_{j\in A}\tau_{j} + B_{q}(K_{i})$ since this would require $\gamma + \sum_{j \in A}\tau_{j} - \sigma_{i} \in B_{q-1}(K_{i})$, this cannot occur since all elements of $\gamma + \sum_{j \in A}\tau_{j}$ must be in $K_{i-1}$. Now we prove the converse, that is suppose that the addition of $\sigma_{i}$ entering the filtration gives birth to a degree-$q$ homology class $\gamma_1 + B_{q}(K_{i}) \in H_{q}(K_{i})$. We can show that $\gamma_{1}$ must be of the form $\sum_{k \in B}\sigma_{k} + \sigma_{i}$, where $B \subset \{0,...,i-1\}$. If this was not the case, i.e $\gamma_{1}$ was of the form $\sum_{k\in B}\sigma_{k}$ then we would have $\gamma_{1} + B_{q}(K_{\max(B)}) \in H_{q}(K_{\max (B)})$ meaning $f_{\max (B)}^{i}(\gamma_{1} + B_{q}(K_{\max(B)})) = \gamma_{1} + B_{q}(K_{i})$ contradicting the fact that $\gamma_1 + B_{q}(K_{i})$ was born upon the addition of $\sigma_{i}$. Since we know that $\partial (\gamma_{1}) = 0$ we have that $\partial (\sigma_{i} + \sum_{k \in B} \sigma_{k}) = 0$ which means that $ \partial \sigma_{i} = \sum_{k\in B}\partial \sigma_{k}$. Hence we have $\partial \sigma_{i} \in B_{q-1}(K_{i-1})$. 
\end{proof}

\begin{lemma}
\label{can-only-kill}
    Let $(K_{i})_{i\in \{0,...,m\}}$ be a simplex-wise filtration and consider the change in homology between $K_{i-1}$ and $K_{i} = K_{i-1} \cup \sigma_{i}$, where $\sigma_{i}$ is a $q$-simplex. Then $\partial \sigma_{i} \notin B_{q-1}(K_{i-1})$ if and only if $\sigma_{i}$ kills a degree-$(q-1)$ homology class. 
\end{lemma}

\begin{proof}
    First we will show that if the addition of $\sigma_{i}$ to the filtration kills a degree-$(q-1)$ homology class then we have $\partial \sigma_{i} \notin B_{q-1}(K_{i-1})$. To this end suppose that $\sigma_{i}$ kills a degree $(q-1)$ homology class $\gamma + B_{q-1}(K_{j})$ born at index $j$. Then that must mean we have some $\beta + B_{q-1}(K_{j'})$ with $j' < j$ such that $f_{j'}^{i}(\beta + B_{q-1}(K_{j'})) = f_{j}^{i}(\gamma + B_{q-1}(K_{j}))$. Then we have that $\beta + B_{q-1}(K_{i}) = \gamma + B_{q-1}(K_{i})$ and thus we have $\beta - \gamma \in B_{q-1}(K_{i})$. By Definition \ref{definition-of-death} we also know that $\beta - \gamma \notin B_{q-1}(K_{i-1})$. Now suppose $\partial \sigma_{i} \in B_{q-1}(K_{i-1})$, then we would have $B_{q-1}(K_{i-1}) = B_{q-1}(K_{i})$, implying $\beta -\gamma \in B_{q-1}(K_{i-1})$ a contadicition. Hence $\partial \sigma_{i} \notin B_{q-1}(K_{i-1})$. Now we prove the converse, suppose now that $\partial \sigma_{i} \notin B_{q-1}(K_{i-1})$. Since $\sigma_{i}$ is a $q$-simplex it follows that $Z_{q-1}(K_{i}) = Z_{q-1}(K_{i-1})$. Since all boundaries are cycles, we have $\partial \sigma_{i} \in Z_{q-1}(K_{i-1})$. We then have that $f_{0}^{i}(0+ B_{q-1}(K_{0})) = f_{i-1}^{i}(\partial \sigma_{i} + B_{q-1}(K_{i-1}))$ and $i$ is the lowest index such that this is the case since $f_{0}^{i-1}(0+ B_{q-1}(K_{0})) = 0 + B_{q-1}(K_{i-1}) \neq f_{i-1}^{i-1}(\partial \sigma_{i} + B_{q-1}(K_{i-1})) = \partial \sigma_{i} + B_{q-1}(K_{i-1})$
\end{proof}

\begin{lemma}
\label{can-only-birth-or-kill}
Let $(K_{i})_{i\in \{0,...,m\}}$ be a simplex-wise filtration and consider the change in homology between $K_{i-1}$ and $K_{i} = K_{i-1} \cup \sigma_{i}$, where $\sigma_i$ is a $q$-simplex.  Then one, and only one, of the following must occur. 

    \begin{itemize}
        \item $\sigma_i$ kills a homology class of degree $q-1$

        \item $\sigma_i$ gives birth to a homology class of degree $q$. 
    \end{itemize}
\end{lemma}

\begin{proof}

    Either $\partial \sigma_{i} \in B_{q-1}(K_{i-1})$ or $\partial \sigma_{i} \notin B_{q-1}(K_{i-1})$. Only one of these statements can be true and one of these statements must be true. By Lemma \ref{can-only-birth} the case  $\partial \sigma_{i} \in B_{q-1}(K_{i-1})$ corresponds to a birth of a degree-$q$ homology class and the case $\partial \sigma_{i} \notin B_{q-1}(K_{i-1})$ corresponds to a death of a degree $q-1$ homology class by Lemma \ref{can-only-kill}. 
\end{proof}

\begin{definition}[Persistence pair]
Consider a simplex-wise filtration $(K_{i})_{i\in \{0,...,m\}}$. If $[\gamma] \in H_{q}(K_{i})$ was born at index $i$ and died at index $j$ then $(i,j)$ is said to be a degree-$q$ persistence pair. If there is no confusion as to what the value of $q$ is, sometimes we will refer to $(i,j)$ simply as a persistence pair. 
\end{definition}



\subsection{Vietoris-Rips complexes and filtrations}

In this section we briefly discuss one of the main structures of interest for this paper. Before doing so, we define a measure of size for a simplex. 


\begin{definition}[Diameter of a simplex]
    Consider a finite point set $A \in \mathbb{R}^D$. Then the diameter $A$, denoted $\diam (A)$ is defined as $\max_{x,y\in A} d(x, y)$. For a simplex $\sigma = \langle x_{0}...x_{p}\rangle $, we have $\diam (\sigma) := \max_{i,j \in \{0,...,p\}}d(x_{i}, x_{j})$. 
\end{definition}

Vietoris-Rips complexes first appeared in \cite{vietoris1927hoheren} and were originally called Vietoris complexes. Vietoris-Rips complexes are also often referred to as Rips complexes in the TDA literature. 

\begin{definition}[Vietoris-Rips complex at scale $r$]
Let $X$ be a point cloud. For $r\in [0,\infty)$ we construct the Vietoris-Rips complex at scale $r$, $\vr _{r} (X)$, as follows. If $\{x_0,...,x_p\} \subset X$ is such that $\diam(\{x_0,...,x_p\}) \leq r$ then $\langle x_0...x_p \rangle $ is a $p$-simplex in $\vr_{r} (X)$. 
\end{definition}

In order to construct a filtration of simplicial complexes, we state an extremely easy to prove lemma without proof. 

\begin{lemma}
    \label{vr-is-actually-a-filtration}
    Let $X$ be a point cloud and let $0 \leq r_1 \leq r_2$. Then we have $\vr_{r_1}(X) \subseteq \vr_{r_2}(X)$. 
\end{lemma}

\begin{definition}[Vietoris-Rips filtration]
    The Vietoris-Rips filtration on $X$ is the nested collection of spaces   $\vr _{\bullet} (X) := \{\vr_{r_1}(X)\subseteq \vr_{r_2}(X)\}_{0 \leq r_1 \leq r_2}$. 
\end{definition}

\begin{remark}
    $\vr_{\infty}(X)$ will consist of the $(|X|-1)$-simplex spanning  all points of $X$ and all lower-degree faces. It is the simplicial complex built from the power set (i.e., the set of all subsets, denoted $2^{X}$) of $X$. 
\end{remark}



The Vietoris-Rips filtration is not a simplex-wise filtration, but is easily modified to be so. We follow the method described in \cite{Ripser}.  

We first extend the function $\psi: X \rightarrow \{1,...,|X|\}$ which indexes the vertices, to a function that labels each simplex in $\vr_{\infty}(X)$. 

\begin{definition}[Extension of $\psi$]
\label{extention-of-psi}
    Given $\psi: X \rightarrow \{1,...,|X|\}$ we extend its domain and range to $\psi: \vr_{\infty}(X)\rightarrow 2^{\{1,...,|X|\}}$ in the following fashion. Consider a simplex $\sigma = \langle x_{0}...x_{p}\rangle$, then $\psi(\sigma)$ is the set of vertex labels $\{\psi(x_{0}),...,\psi(x_{p})\}$.
\end{definition}


Next, we define a function that sorts the integer labels in an element of $2^{\{1,...,|X|\}}$ so they are listed in increasing order. 


\begin{definition}
\label{sort-definition}
Let $A(n)$ be the set of \emph{ordered} subsets of $\{1,...,n\}$. 
That is, $S = \{s_1, \ldots, s_k\} \subset \{1,...,n\} $ is in $A(n)$ if and only if $s_1 < s_2 < \cdots < s_k$. 
We write $\sort(S)$ for the function that maps a set of integers to its ordered version. 
To shorten notation we will also write $\sort(\sigma)$ when we really mean $\sort(\psi(\sigma))$. 

\end{definition}

We now ``stretch out'' the Vietoris-Rips filtration and turn it into a simplex-wise filtration by using a length-lexicographic ordering on simplices with the same diameter. 

\begin{definition}
    \label{binary-relation-on-simplices}
    We define a binary relation $ <$ on $\vr_{\infty}(X)$ as follows. 

\begin{itemize}
    \item $\sigma <\tau$ if $\diam (\sigma) < \diam(\tau)$. 

    \item If $\diam(\sigma) = \diam(\tau)$ then $\sigma < \tau$ if $\dim (\sigma) < \dim (\tau)$. 

    \item If $\diam(\sigma) = \diam(\tau)$ and $\dim(\sigma) = \dim(\tau)$ then $\sigma < \tau$ if $\sort (\sigma) <_{lex} \sort(\tau)$ according to lexicographical order, $<_{lex}$. 
\end{itemize}
\end{definition}


Recall lexicographical ordering on elements of $A(n)$ with the same cardinality is defined as follows. 
Given $S, T \in A(n)$ we have $S = \{s_1 < s_2 \cdots < s_k\}$ and $T = \{t_1 < t_2 \cdots < t_k\}$. Then $S <_{lex} T$ in lexicographic ordering if there is some $1 \leq j \leq k$ such that $s_i = t_i$ for $i < j$, and $s_j < t_j$.   

The following lemma can be readily verified as length-lexicographic ordering is known to be a total order for finite sequences. The fact that $<$ defines a total order will be used to define what will be called the ``simplex-wise Vietoris-Rips filtration". 

\begin{lemma}
    The binary relation $<$ given in Definition \ref{binary-relation-on-simplices} is a total order on $\vr_{\infty}(X)$. 
\end{lemma}

\begin{definition}[Simplex-wise Vietoris-Rips filtration]
\label{def-VR-total-order}
Let $X$ be a point cloud. Suppose there are $m$ simplices in $\vr _{\infty} (X)$. We use the total order $<$ on $\vr_{\infty}(X)$ to construct a bijection $\phi:\vr_{\infty}(X) \rightarrow \{1,...,m\}$ by mapping the lowest element according to $<$ to $1$, the next lowest element to $2$ and so on. The filtration $(K_{i})_{i \in \{0,...,m\}}$ where $K_{0} = \emptyset$ and $K_{i} = \cup_{j=1}^{i}\phi ^{-1}(j)$ for $i>0$ is referred to as the simplex-wise Vietoris-Rips filtration on $X$.
\end{definition}

\begin{remark}
    It is customary to write $\phi^{-1}(j)$ as $\sigma_j$. Thus we write $K_{i} = \cup_{j=1}^{i}\sigma_j$
\end{remark}


\begin{definition}[Birth and death values for  Vietoris-Rips filtrations]
Consider the collection $\vr_{\bullet}(X)$ and its corresponding simplex-wise filtration. Let $(i,j)$ be a persistence pair for the simplex-wise filtration. Then $\mathrm{diam}(\sigma_i)$ is said to be the birth value of the homology class that is born when $\sigma_i$ is added and $\mathrm{diam}(\sigma_j)$ is said to be the death value of this homology class. 
\end{definition}

\begin{definition}[Persistence]
Consider $\vr_{\bullet}(X)$ with its corresponding simplex-wise filtration. Let $(i,j)$ be a persistence pair for the simplex-wise filtration. Then the persistence of $(i,j)$ is defined as $\mathrm{diam}(\sigma_j) - \mathrm{diam}(\sigma_i)$.
\end{definition}

Note that the persistence may be zero. In this case we say that the persistence pair $(i,j)$ has trivial persistence.  


\begin{definition}[Persistence barcode, $\ph{q}(X)$]
Consider a point cloud $X$. The multiset of all left-closed, right-open intervals $\left[\mathrm{diam}(\sigma_i), \mathrm{diam}(\sigma_j)\right)$ such that $(i,j)$ is a degree-$q$ persistence pair of the simplex-wise Vietoris-Rips filtration with non-trivial persistence is called the degree-$q$ Vietoris-Rips persistence barcode of $X$. We will denote it by $\ph{q}(X)$. 


\end{definition}

The persistence barcode may be visualised by drawing each interval stacked above the real line as in Figure \ref{circle_of_circle_diag}. 
An alternative visualisation is the persistence diagram, where the points $(\mathrm{diam}(\sigma_i), \mathrm{diam}(\sigma_j))$ are plotted on cartesian axes for each persistence pair $(i,j)$. 


% Figure environment removed


Throughout this paper we focus on the case $q=1$. We will sometimes say we are ``calculating the persistent homology of $X$'' and it should be understood that we mean we are calculating degree-$1$ persistent homology of the Vietoris-Rips filtration of $X$. 



\subsection{The matrix reduction algorithm for computing persistent homology}
\label{matrix-reduction-algorithm}

In this section, we briefly review the standard matrix reduction algorithm for computing the persistent homology of a simplex-wise filtration. The reader wishing for more details and generality is directed towards \cite{book}. 

We start by defining the boundary matrix $\partial$. If there are $m$ simplices in the filtration then the boundary matrix will be an $m \times m$ matrix with the $i$th column encoding the boundary of $\sigma_i$.  If $\sigma_i$ is a $q$-simplex, then column-$i$ of $\partial$ has a 1 in each row corresponding to the index of a $(q-1)$-simplex that is a face of $\sigma_i$.  
The \emph{lowest 1} of a column is the entry with largest row-index. The filtration ordering ensures this row index is smaller than the column index. 




% Figure environment removed

\newpage
\begin{example}
In this example we consider the simplex-wise filtration depicted in Figure \ref{fig:simplex-wise}. We have labelled the 0-simplices with the integers $1, 2, 3$. 
The 1-simplices are added in the order $\langle 12 \rangle, \langle 13 \rangle, \langle 23 \rangle$ and the 2-simplex $\langle 123 \rangle$ is added last. 

For this filtration the corresponding boundary matrix $\partial$ is given by 

\begin{equation}
\partial = 
\begin{bmatrix}
0 & 0 & 0 & 1 & 1 & 0 & 0\\
0 & 0 & 0 & 1 & 0 & 1 & 0\\
0 & 0 & 0 & 0 & 1 & 1 & 0\\
0 & 0 & 0 & 0 & 0 & 0 & 1\\
0 & 0 & 0 & 0 & 0 & 0 & 1\\
0 & 0 & 0 & 0 & 0 & 0 & 1\\
0 & 0 & 0 & 0 & 0 & 0 & 0\\
\end{bmatrix}
\end{equation}

Note that in column 7, corresponding to the addition of the 2-simplex, we have non-zero entries in rows 4,5 and 6, corresponding to the 1-simplices which form the boundary of the 2-simplex. 
\end{example}


To find the persistence barcode from the boundary matrix $\partial$ we reduce each column of $\partial$ in order of increasing $i$, but only  allow the addition of columns with smaller index. 
When we reduce $\partial$ in this way we obtain a matrix $R$ which has the property that no two columns have their lowest 1 in the same row. From $R$, we can extract the persistence pairs of the simplex-wise filtration. 

\begin{lemma}[Pairing lemma \cite{book}]
Consider the boundary matrix $\partial$ for a simplex-wise filtration and let $R$ be the result of reducing $\partial$. Suppose column $j$ has its lowest 1 in row $i$. Then $(i,j)$ is a persistence pair. 
\end{lemma}
Note that in terms of the filtration $(i,j)$ being a persistence pair means that $\sigma_{j}$ killed the homology class which was born when $\sigma_{i}$ was added to the filtration. 

Some persistence pairs can be obtained from $\partial$ without the need for any reduction. In \cite{Ripser}, these are referred to as apparent pairs and a method to identify them was used to speed up the computation of Vietoris-Rips persistent homology. 

\begin{definition}[Apparent pair]
\label{apparent-pair}
Suppose that $(i,j)$ is a degree-q persistence pair which satisfies the following conditions: 
\begin{itemize}
\item $\sigma_{i}$ is the $q$-simplex face of $\sigma_{j}$ which is last added to the filtration, 
\item $\sigma_{j}$ is the $(q+1)$-simplex coface of $\sigma_{i}$ which is first added to the filtration.
\end{itemize}
Then, following \cite{Ripser}, we call $(i,j)$ an apparent pair. 
\end{definition}

Indeed, if $\sigma_{i}$ is the last added face of $\sigma_{j}$ then this means that the lowest 1 in the $j$th column is at row $i$. The second condition means that $\sigma_{j}$ is the first coface to be added which has $\sigma_{i}$ as a face meaning that no column to the left of column $j$ will have its lowest 1 in row $i$. 

It should be noted that this method to calculate persistence barcodes applies to all degrees of homology. However, for Vietoris-Rips filtrations the matrix $\partial$ would be enormous. 
Since we are only interested in computing $\ph{1}(X)$ we only need columns which correspond to 2-simplices and rows which correspond to 1-simplices. This means a boundary matrix for computing $\ph{1}(X)$ has $O(n^3)$ columns and $O(n^2)$ rows. 
Note also that for Vietoris-Rips filtrations, some persistence pairs $(i,j)$ will correspond to homology classes with zero persistence, when $\textrm{diam}(\sigma_{i}) = \textrm{diam}(\sigma_{j})$. 
Apparent pairs are particularly useful in computing $\ph{1}(X)$ because they help us identify those persistence pairs which have trivial persistence. The following is Theorem 3.10 from \cite{Ripser}. 



\begin{lemma}
\label{unique-distances-lemma}
Consider a point cloud $X$ with unique pairwise distances. Then the degree-1 apparent pairs for the Vietoris-Rips filtration $\vr _{\bullet} (X)$ are precisely the persistence pairs with trivial persistence. 
\end{lemma}




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{The Reduced Vietoris-Rips Complex}

In this section we cover a new result on degree-1 Vietoris-Rips persistent homology of a point cloud $X$. The result proved here will be used extensively in later sections. The main benefit is that we reduce the number of 2-simplices to be examined from $O(n^3)$ to $O(n^2)$.

Although this may seem like a minor improvement it will prove to have far reaching effects on the computation of Vietoris-Rips persistent homology. 




\subsection{Construction of the Reduced Vietoris-Rips Complex}

We first introduce the notion of the lune of a $1$-simplex. It differs from the geometric definition of the lune (given in Definition \ref{definition-traditional-lune}) by being a definition that depends on the total order $<$ rather than geometry. 

\begin{definition}[Lune]
\label{def-lune}
Consider two points $y$ and $z$ in a point cloud $X$. The lune of a 1-simplex $\langle yz \rangle $, denoted by $\lune (\langle yz \rangle)$ is defined as the subset 
\begin{equation}
\{ x \in X \;|\; \langle yx \rangle < \langle yz \rangle \text{ and } \langle zx \rangle < \langle yz \rangle \}
\end{equation} 
\end{definition}

Recall that the symbol `$<$' refers to the total order for the simplices in the filtration as per Definition~\ref{binary-relation-on-simplices}. 
It should be noted that if one assumes pairwise unique distances then the above reduces to the geometric definition of the lune given by Toussaint in \cite{ToussaintRNG} and is repeated in Definition \ref{definition-traditional-lune}.  Note that in \cite{ToussaintRNG} the lune is only defined for point clouds with unique pairwise distances. 

\begin{definition}[Geometric definition of the lune]
\label{definition-traditional-lune}
    Consider a point cloud $X$ where $X$ has unique pairwise distances. Then for a given 1-simplex $\langle yz \rangle$ we define $\lune (\langle yz \rangle)$ as the following subset of $X$. 
    \begin{equation}
    \{ x \in X \;|\; d(x,y) < d(y,z) \text{ and } d(x,z) < d(y,z)\}
    \end{equation} 
    
\end{definition}

We can visualise the geometric definition of the lune using the intersection of two open balls of radius $d(y,z)$ centred at $y$ and $z$. This is shown in Figure \ref{lune-diagram}. It should be noted that with our definition of the lune there may be points of $X$ on the boundary of this region. 

% Figure environment removed

We quantify structure in this subset by its connectivity. 

\begin{definition}[Connected Components of a Lune]
\label{def-connected-components-of-lune}
Let $V = \lune (\langle yz \rangle)$ for two points $y,z \in X$, and construct a graph on $V$ by joining two points $p, q \in V$ if $\langle pq \rangle  < \langle yz \rangle$. Suppose this graph has $c$ connected components, then we say that the $\lune (\langle yz \rangle)$ has $c$ connected components. 

\end{definition}



In Section~\ref{algorithm}, we need to quickly determine if a lune has only one connected component. To facilitate this, we introduce the lens of a lune. 

\begin{definition}[Lens]
\label{lens}
Consider a point cloud $X$. Let $\langle yz \rangle$ be a 1-simplex. Then we define the $\lens (\langle yz \rangle)$ to be all points $x \in X$ such that $\Angle (yxz) > \frac{5\pi}{6}$. In Figure \ref{lens-diagram-after-definition}, the red region shows which points of $X$ would be contained in $\lens(\langle yz \rangle)$. 
\end{definition}

% Figure environment removed


Using this definition of the lens of a $1$-simplex we give a lemma that provides a sufficient condition for the lune to have a single connected component.


\begin{lemma}
\label{lens-lemma}
Consider a 1-simplex $\langle yz \rangle $. If there is a point that $x$ such that $\Angle (yxz) > \frac{5\pi}{6}$ then $\lune (\langle yz \rangle)$ consists of only one connected component. 
\end{lemma}

\begin{proof}
Consider a 1-simplex $\langle yz \rangle$ and let $x$ be a point such that $\Angle (yxz) > \frac{5\pi}{6}$ and let $d(y,z) = r$. If $x$ is the only point in the lune then we are done, otherwise let $w$ be any other point in the lune. We want to show that $\langle wx \rangle  < \langle yz \rangle$. Let $C$ be the circle of points that are of distance $r$ from both $y$ and $z$. Let $w'$ be the point of $C$ closest to $w$ that that is in the intersection of $C$ and the plane that contains the points $y,z,w$. Out of all possible positions of $x$, the case when $x$ is the furthest distance away from $w$ will occur when $x$ and $w$ are in the same plane. Thus we can reduce the higher dimensional case to the two dimensional case. In this two dimensional case $x$ will be in the region bounded by the arcs $w'y, w'z$ and the arc beginning from $y$ and ending at $z$. The point $w$ may also occupy this region but it may lie on the interior of the arcs $zw'$ and $yw'$ as well. See Figure \ref{appendix-lemma-pic} below. All points in this region are within $r$ of each other and thus $d(w,x) < r$ implying $\langle wx \rangle < \langle yz \rangle$.  
\end{proof}

% Figure environment removed


We now describe how to build the reduced Vietoris-Rips complex. First we define a Lune function that records the selection of a single point per connected component of a lune. 

\begin{definition}[Lune function]
\label{lune-function}
    Let $\vr^{1}_{\infty}(X)$ be the set of $1$-simplices in $\vr_{\infty}(X)$. We define a lune function $L:\vr^{1}_{\infty}(X)\rightarrow 2^{X}$ as a function that takes a one simplex $\langle yz \rangle$, with $c_{yz}$ connected components in its lune, to a set $\{x_{1},...,x_{c_{yz}}\}$. The points $x_{1},...,x_{c_{yz}}$ are chosen from the connected components of $\langle yz \rangle$, one point from each connect component. 
\end{definition}


\begin{definition}[Reduced Vietoris-Rips complex]
\label{def-reduced-vietoris-rips-complex}
Consider a point cloud $X$ and a lune function $L$. A reduced Vietoris-Rips complex of $X$ with scale $r$, 
denoted $\mathcal{R}^{L}_r(X)$ 
is the simplicial complex such that 

\begin{itemize}
    \item 0-simplices are all points of $X$,
    

    \item 1-simplices are edges $\langle yz \rangle $ with $d(y,z) \leq r$, 
    

    \item 2-simplices are $\langle yzx \rangle$, where $\diam(\langle yzx \rangle) \leq r$ and $x\in L(\langle yz \rangle)$. 

\end{itemize}

\end{definition}

Since $\rvr_r^{L}(X)$ is a simplicial complex and $\rvr^{L}_{r'}(X) \subset \rvr^{L}_{r}(X)$ for $r' <r$ it follows that we 
have a filtration for increasing scale $r$.   
\begin{definition} 
\label{def-reduced-vietoris-rips-filtration}
A reduced Vietoris-Rips filtration on $X$ is any filtration of the form $\rvr^{L}_{\bullet}(X)$, where $L$ is a lune function for $X$.
\end{definition}


When $r$ is the diameter of $X$, $\rvr^{L}_{r}(X)$ will have $O(n)$ 0-simplices and $O(n^2)$ 1-simplices. 
The following Lemma~\ref{bounded-connected-components-proof} shows that when $X$ is a subset of Euclidean space $\mathbb{R}^D$, the number of connected components of a lune is bounded by a constant independent of $n$. It follows that at most $O(1)$ 2-simplices will be added in each lune and thus there will be $O(n^2)$ 2-simplices in $\mathcal{R}^{L}_{r}(X)$. 



\begin{lemma}
\label{bounded-connected-components-proof}
    Consider a point cloud, $X$, in $\mathbb{R}^{D}$. The number of connected components a lune can have is bounded above by a constant dependent on $D$. 
\end{lemma}

\begin{proof}
Consider a $1$-simplex $\langle yz \rangle$ and let $r = d(y,z)$. Consider the following subset:
\begin{equation}
    Q_1 := \{x\in \R^D \;|\; d(x,y) \leq r \text{ and } d(x,z) \leq r \}. 
\end{equation}


Then finding the maximum number of connected components in $\lune(\langle yz \rangle)$ is bounded by the maximum number of disjoint open balls of radius $\frac{r}{2}$ with centres in $Q_1$.  We can put an upper bound on this number by considering a ball of radius $2r$, $Q_2$, centred at the midpoint of $y$ and $z$ as depicted in Figure \ref{connected-components-proof}. Certainly, the number of open balls with radius $\frac{r}{2}$ that can be placed inside $Q_2$ is more than the maximum number of connected components in $\lune(\langle yz \rangle)$. To see this, consider a set of open balls of radius $\frac{r}{2}$ with centres in $Q_1$ such that all the balls are mutually disjoint. All these balls are contained in $Q_{2}$ and we can always place one more ball centred $\frac{3r}{2}$ away from the midpoint of $y$ of $z$. This means that the number of mutually disjoint balls of radius $\frac{r}{2}$ with centres in $Q_1$ is bounded by the number of disjoint balls of radius $\frac{r}{2}$ that can be packed inside $Q_2$. 
 
This number is bounded by dividing the volume of $Q_2$ with the volume of a ball with radius $\frac{r}{2}$. It follows that the number of connected components of a $\lune (\langle yz \rangle)$ is bounded by $4^D$. It should be said that this is a rather crude overestimate of the maximum number of connected components.  
\end{proof}

% Figure environment removed



In the interest of reducing clutter from here on in, we will drop the $L$ from $\rvr_{\bullet}^{L}(X)$ and simply write $\rvr_{\bullet}(X)$ with the implicit understanding that a specific $L$ has been chosen. 


\subsection{The Relationship between Vietoris-Rips complexes and their reduced counterparts}

So far we have detailed what a Reduced Vietoris-Rips complex is but we have not shown why they are useful. Here we state and prove a new result 
which relates the degree-1 persistent homology of the Vietoris-Rips filtration of $X$ with the degree-1 persistent homology of the Reduced Vietoris-Rips filtration of $X$. There is also a higher degree version of this result in the appendix. 


\isotheorem*


Here $f_{r_1}^{r_2}$ and $g_{r_1}^{r_2}$ are the maps obtained by applying $H_{1}(-)$ to the inclusions $\rvr_{r_1}(X) \subset \rvr_{r_2}(X)$ and $\vr_{r_1}(X) \subset \vr_{r_1}(X)$. 



\paragraph{The proof of Theorem 1.1} 

% In this version of the proof we will assume non-unique distances from the beginning. 

Let $r$ be an arbitrary non-negative number. We first define $\theta_{r}$ and then show it is an isomorphism. Let $\gamma + B_{1}(\rvr_{r}(X))$ be an element in $H_{1}(\rvr_{r}(X))$. Then we define $\theta_{r}$ as follows:

\begin{equation}
\theta_{r}(\gamma + B_{1}(\rvr_{r}(X))) := \gamma + B_{1}(\vr_{r}(X))
\end{equation}

This mapping is well defined because $B_{1}(\rvr_{r}(X)) \subset B_{1}(\vr_{r}(X))$.

\begin{lemma}
\label{theta-is-surjective}
    $\theta_{r}$ is surjective for all $r \geq 0$. 
\end{lemma}

\begin{proof}
    Let $\gamma + B_{1}(\vr_{r}(X)) \in H_{1}(\vr_{r}(X))$. 
    Since $\gamma \in C_1(\vr_{r}(X))$ and all 1-simplices of $\vr_{r}(X)$ are also in $\rvr_{r}(X)$, it follows that $\gamma + B_{1}(\rvr_{r}(X))$ is mapped to $\gamma + B_{1}(\vr_{r}(X))$ by $\theta_{r}$.
\end{proof}

In order to show that $\theta_{r}$ is an isomorphism for all $r$ we neeed to show that $\theta_{r}$ is injective for all $r$. Before we do so, we will need the following preliminary lemmas. 

\begin{lemma}
\label{isomorphism-inclusions}
    If $\theta_{s}$ is an isomorphism, then it follows that $B_{1}(\vr_{s}(X)) = B_{1}(\rvr_{s}(X))$. 
\end{lemma}

\begin{proof}
The inclusion $B_{1}(\rvr_{s}(X)) \subset B_{1}(\vr_{s}(X))$ follows from the fact that $\rvr_{s}(X) \subset \vr_{s}(X)$. To get the reverse inclusion let $\gamma \in B_{1}(\vr_{s}(X))$. Then, as the cycles are the same for $\vr_s(X)$ and $\rvr_s(X)$, we have $\theta_{s}(\gamma + B_{1}(\rvr_{s}(X))) = \gamma + B_{1}(\vr_{s}(X)) = 0 + B_{1}(\vr_{s}(X))$. Since $\theta_{s}$ is an isomorphism it follows that $\gamma \in \rvr_{s}(X)$. Thus we have the reverse inclusion $B_{1}(\vr_{s}(X)) \subset B_{1}(\rvr_{s}(X))$.
\end{proof}

\begin{lemma}
\label{first-edge-proof}
    Consider arbitrary $r>0$ and suppose that $\theta_{s}$ is injective for all $s<r$. Let all the $1$-simplices of diameter $r$ be $\langle y_1z_1 \rangle < \cdots < \langle y_{m_{r}} z_{m_{r}} \rangle $. Then 

    \begin{equation}
    \label{same-edges-equation-1}
         \{ \partial (\langle x y_1 z_1 \rangle)| x\in \lune (\langle y_1 z_1\rangle) \} \subset B_{1}(\rvr_{r}(X)).
    \end{equation}

\begin{proof}
    First observe that by Lemma \ref{theta-is-surjective} that $\theta_s$ is an isomorphism for all $s < r$. This means that $B_{1}(\rvr_{s}(X)) = B_{1}(\vr_{s}(X))$ by Lemma \ref{isomorphism-inclusions}. 

    We note that any point $x \in \lune (\langle y_1 z_1 \rangle)$ must necessarily have $\max\big(d(x,y_1), d(x,z_1)\big) < r$. To see why this is so, suppose $d(x,y_1) = r$, then since $x\in \lune (\langle y_1 z_1 \rangle)$ it follows that $ \langle x y_1 \rangle < \langle y_1 z_1 \rangle $, but this is a contradiction since there should be no $1$-simplex of diameter $r$ that appears in the filtration before $ \langle y_1 z_1 \rangle$. An analogous argument can be used to show that $d(x,z_1) < r$. 

To this end, let $x$ be any point in $\lune (\langle y_1 z_1 \rangle)$ and consider the $2$-simplex $\sigma = \langle x y_1 z_1 \rangle$. 
Let $w \in L(\langle y_1 z_1 \rangle)$ be in the same connected component as $x$.

If $x = w$ then there is nothing to prove since $\sigma \in \rvr_{r}((X))$ by definition and thus $\partial \sigma \in B_{1}(\rvr_{r}(X))$. 
Otherwise, since $x$ and $w$ are in the same component we know there exist $v_0, ..., v_{q} \in \lune(\langle y_{1} z_{1} \rangle)$ such that $x = v_0,v_1,...,v_{q}=w$ forms a path with $\langle v_{i} v_{i+1} \rangle < \langle y_{1} z_{1} \rangle$,  $d(v_i, y_1) < r$ and $d(v_i, z_1) < r$. 
Using the fact that $\langle y_1 z_1 \rangle$ is the first $1$-simplex of diameter $r$ to appear in the filtration, it also follows that $d(v_{i}, v_{i+1}) < r$ for $i = 1,...,q-1$. Using the fact that $\partial (\partial (\langle y_1 z_1 v_{i} v_{i+1} \rangle)) = 0$ we see that 
\begin{equation}
\label{proof-equation}
\partial (\langle y_1 z_1 v_{i} \rangle )  = \partial (\langle y_1 z_1 v_{i+1} \rangle ) + \partial (\langle v_{i} v_{i+1} y_1 \rangle) + \partial (\langle v_{i} v_{i+1} z_1 \rangle). 
\end{equation}

%\vspace{12pt}

\medskip
\noindent
The 2-simplex $\langle v_{i}v_{i+1}y_1 \rangle$ must have diameter less than $r$ because all three edges have diameter less than $r$. 

Similarly, $\diam (\langle v_{i} v_{i+1} z_1 \rangle) < r$. Since $\theta_{\diam(\langle v_{i} v_{i+1} y_1 \rangle)}$ and $\theta_{\diam (\langle v_{i} v_{i+1} z_1 \rangle)}$ are isomorphisms, it follows that 

\begin{equation}
\partial (\langle v_{i} v_{i+1} y_1 \rangle ) \in B_{1}(\vr_{\diam(\langle v_{i} v_{i+1} y_1 \rangle)}(X)) = B_{1}(\rvr_{\diam(\langle v_{i} v_{i+1} y_1 \rangle)}(X)) \subset \rvr_{r}(X)
\end{equation}

and 

\begin{equation}
\partial (\langle v_{i}v_{i+1}z_1 \rangle) \in B_{1}(\vr_{\diam (\langle v_{i} v_{i+1} z_1 \rangle)}(X)) = B_{1}(\rvr_{\diam (\langle v_{i} v_{i+1} z_1 \rangle)}(X)) \subset \rvr_{r} (X)
\end{equation}

by Lemma \ref{isomorphism-inclusions}. 

Plugging in $i = q-1$ into equation \ref{proof-equation} we obtain the following. 

\begin{equation}
\label{second-proof-equation}
    \partial (\langle y_1 z_1 v_{q-1} \rangle )  = \partial (\langle y_1 z_1 v_{q} \rangle ) + \partial (\langle v_{q-1} v_{q} y_1 \rangle) + \partial (\langle v_{q-1} v_{q} z_1 \rangle). 
\end{equation}
We have already shown that the second and third term on the right hand side of Equation \ref{second-proof-equation} are in $\rvr_{r}(X)$. 
The first term on the right hand side of \ref{second-proof-equation} is in $B_{1}(\rvr_{r}(X))$ because $v_q = w \in L(\langle y_1 z_1 \rangle)$, meaning the $2$-simplex $\langle y_1 z_1 v_{q} \rangle \in \rvr_{r}(X)$. Thus it follows that $\partial (\langle y_1 z_1 v_{q-1} \rangle) \in B_{1}(\rvr_{r}(X))$. Using Equation \ref{proof-equation} repeatedly by letting $i = q-2, q-3, ...,0$ we can subsequently show that $\partial (\langle y_1 z_1 v_{q-2}\rangle), ..., \partial (\langle y_1 z_1 v_{0}\rangle) \in B_{1}(\rvr_{r}(X))$. Remembering that $v_{0} = x$ we thus have that $\partial \sigma =\partial( \langle x y_{1} z_{1} \rangle) \in B_{1}(\rvr_{r}(X))$.
\end{proof}

    
\end{lemma}

\begin{lemma}
\label{the-big-lemma}
    Consider $r>0$ arbitrary and suppose that $\theta_{s}$ is injective for all $s<r$. Let $\sigma$ be a $2$-simplex in $\vr_{r}(X)$ such that $\diam (\sigma) = r$, then we have that $\partial \sigma \in B_{1}(\rvr_{r}(X))$.
\end{lemma}

\begin{proof}
    First observe by Lemma \ref{theta-is-surjective} that $\theta_s$ is an isomorphism for all $s < r$. This means that $B_{1}(\rvr_{s}(X)) = B_{1}(\vr_{s}(X))$ by Lemma \ref{isomorphism-inclusions}. 
    
    Let all the $1$-simplices of diameter $r$ be $\langle y_1z_1 \rangle < \cdots < \langle y_{m_{r}} z_{m_{r}} \rangle $. We wish to show that all $2$-simplices $\sigma$, with $\diam(\sigma) = r$ are such that $\partial \sigma \in B_{1}(\rvr_{r}(X))$. This is equivalent to showing that 

    \begin{equation}
    \label{same-edges-equation}
         \{ \partial (\langle x y_j z_j \rangle)| x\in \lune (\langle y_j z_j \rangle) \} \subset B_{1}(\rvr_{r}(X))
    \end{equation}

for $j = 1,...,m_{r}$. We will prove that Equation \ref{same-edges-equation} holds for $j = 1,...,m_{r}$ by induction. That is, we will show the following:

\begin{itemize}
    \item Equation \ref{same-edges-equation} holds for $j=1$. This is just Lemma \ref{first-edge-proof}.

    \item If Equation \ref{same-edges-equation} holds for $j=1,...,k$, then it holds for $j = k+1$. 
\end{itemize}

The proof of the second statement is similar to that of Lemma \ref{first-edge-proof} but has some subtle differences as described below. 

Let $x$ be any point in $\lune (\langle y_{k+1} z_{k+1} \rangle)$ and consider the $2$-simplex $\langle x y_{k+1} z_{k+1} \rangle$. 
Let $w \in L(\langle y_{k+1}z_{k+1} \rangle)$ belong to the same connected component as $x$. If $x=w$ then there is nothing to prove since $\sigma \in \rvr_{r}(X))$ by definition and thus $\partial \sigma \in B_{1}(\rvr_{r}(X))$. Otherwise, since $x$ and $w$ are in the same component we know there exists $v_{0},...,v_{q} \in \lune (\langle y_1 z_1 \rangle)$ such that $x = v_0, v_1, ..., v_q = w$ forms a path such that $\langle v_{i}v_{i+1} \rangle < \langle y_{k+1} z_{k+1} \rangle $ for $i = 0,...,q-1$. We know that $\partial (\partial (\langle y_{k+1} z_{k+1} v_{i}v_{i+1} \rangle )) = 0$ and thus 

\begin{equation}
\label{equation-general-proof}
    \partial (\langle y_{k+1}z_{k+1} v_{i} \rangle ) = \partial (\langle y_{k+1}z_{k+1} v_{i+1} \rangle) + \partial (\langle v_{i}v_{i+1}y_{k+1} \rangle) + \partial (\langle v_{i}v_{i+1}z_{k+1} \rangle).
\end{equation}

We now show that $\partial (\langle v_{i}v_{i+1}y_{k+1} \rangle) \in B_{1}(\rvr_{r}(X))$:

\begin{itemize}
    \item We already established that $\langle v_{i}v_{i+1} \rangle < \langle y_{k+1}z_{k+1} \rangle$. %from $x$ and $w$ being in the same connected component. 

    \item $\langle v_{i} y_{k+1} \rangle < \langle y_{k+1}z_{k+1} \rangle$ since $v_{i} \in \lune (\langle y_{k+1}z_{k+1} \rangle)$. 

    \item $\langle v_{i+1}y_{k+1} \rangle < \langle y_{k+1}z_{k+1} \rangle$ since $v_{i+1} \in \lune (\langle y_{k+1}z_{k+1} \rangle)$. 
\end{itemize}

Since all faces of $\langle v_{i}v_{i+1}y_{k+1} \rangle$ appear in the filtration before $\langle y_{k+1}z_{k+1} \rangle$ it follows that 
either $\diam(\langle v_{i}v_{i+1}y_{k+1} \rangle) < r$, or one of the edges has diameter equal to $r$, in which case that edge must be one of $\langle y_jz_j \rangle$ for $j= 1, \ldots, k$. 
By our inductive assumption, it follows that $ \partial (\langle v_{i}v_{i+1}y_{k+1} \rangle) \in B_1(\rvr_r(X))$.  
Similarly, $ \partial (\langle v_{i}v_{i+1}z_{k+1} \rangle) \in B_1(\rvr_r(X))$.


Plugging $i = q-1$ into Equation \ref{equation-general-proof} we obtain the following.
\begin{equation}
\label{equation-general-proof-q-1}
    \partial (\langle y_{k+1}z_{k+1} v_{q-1} \rangle ) = \partial (\langle y_{k+1}z_{k+1} v_{q} \rangle) + \partial (\langle v_{q-1}v_{q}y_{k+1} \rangle) + \partial (\langle v_{q-1}v_{q}z_{k+1} \rangle).
\end{equation}

We have just shown that the second and third term on the right hand side of Equation \ref{equation-general-proof-q-1} are in $\rvr_{r}(X)$. Remembering that $v_{q} = w \in L(\langle y_{k+1}z_{k+1} \rangle)$, the first term on the right hand side of Equation \ref{equation-general-proof-q-1} is in $B_{1}(\rvr_{r}(X))$ because $\langle y_{k+1}z_{k+1}v_{q} \rangle$ is a $2$-simplex in $\rvr_{r}(X)$ by the definition of $L(\cdot)$. Thus it follows that $\partial (\langle y_{k+1}z_{k+1}v_{q-1} \rangle) \in B_{1}(\rvr_{r}(X))$. 
Using Equation \ref{equation-general-proof} repeatedly by letting $i = q-2, q-3, ...,0$ we can subsequently show that $\partial (\langle y_{k+1}z_{k+1}v_{q-2}),...,\partial(\langle y_{k+1}z_{k+1}v_{0}\rangle) \in B_{1}(\rvr_{r}(X))$. Remembering that $v_{0} = x$ we thus have that $\partial \sigma = \partial (\langle xy_{k+1}z_{k+1} \rangle ) \in B_{1}(\rvr_{r}(X))$. 


\end{proof}

We are finally in a position to show that $\theta_{r}$ is injective for all $r \geq 0$. 


\begin{lemma}
    $\theta_{r}$ is injective for all $r\geq 0$.
\end{lemma}
%We now show that $\theta_{r}$ is injective for all values of $r$. 
We will use a proof by induction by inducting on the value of $r$. That is to say, we will prove the following.

\begin{itemize}
    \item $\theta_{0}$ is injective. 

    \item If $\theta_{s}$ is injective for all $s<r$, then $\theta_{r}$ is injective. 
\end{itemize}

Since $H_{1}(\vr_{0}(X))$ and $H_{1}(\rvr_{0}(X))$ are the zero homology group the injectivity of $\theta_{0}$ is trivial. Now we show that if $\theta_{s}$ is injective for all $s<r$, then $\theta_{r}$ is injective. Suppose that $\theta_{r}(\gamma + B_{1}(\rvr_{r}(X))) = \gamma + B_{1}(\vr_{r}(X)) = 0 + B_{1}(\vr_{r}(X))$. If we can show that $\gamma \in B_{1}(\rvr_{r}(X))$ then it would follow that $\theta_{r}$ is injective. Since $\gamma + B_{1}(\vr_{r}(X)) = 0 + B_{1}(\vr_{r}(X))$ it follows that $\gamma \in B_{1}(\vr_{r}(X))$. Thus we can write $\gamma = \partial c$ for some $c\in C_{2}(\vr_{r}(X))$. Let us write $c = \sum_{i}\sigma_{i}$ where each $\sigma_{i}$ is a $2$-simplex in $\vr_{r}(X)$. We can write 

\begin{equation}
c = \sum_{\{i |\text{diam}(\sigma_{i}) < r\}} \sigma_{i} + \sum_{\{i |\text{diam}(\sigma_{i}) = r\}} \sigma_{i}
\end{equation}

Letting 

\begin{equation}
\gamma_{<r}  := \partial \left( \sum_{\{i |\diam(\sigma_{i}) < r\}} \sigma_{i} \right)
\end{equation}

and

\begin{equation}
\gamma_{r} := \partial \left(\sum_{\{i |\diam (\sigma_{i}) = r\}} \sigma_{i} \right)
\end{equation}

we then write 

\begin{equation}
\gamma = \gamma_{<r} + \gamma_{r} = \partial \left( \sum_{\{i |\diam(\sigma_{i}) < r\}} \sigma_{i} \right) + \partial \left(\sum_{\{i |\diam (\sigma_{i}) = r\}} \sigma_{i} \right)
\end{equation}

%\facundo{M: please check} \MK{checked}
Choose $r^{*} < r$ such that $\gamma_{<r}\in B_{1}(\vr_{r^{*}}(X))$. Then, by the induction hypothesis $\theta_{r^{*}}$ is an isomorphism and thus it follows that $\gamma_{<r} \in B_{1}(\rvr_{r^{*}}(X))$ since we have:

\begin{equation}
\theta_{r^{*}}(\gamma_{<r_1} + B_{1}(\rvr_{r^{*}}(X))) =\partial \left(\sum_{\{i |\diam (\sigma_{i}) < r\}} \sigma_{i}\right) + B_{1}(\vr_{r^{*}}(X)) = 0 + B_{1}(\vr_{r^{*}}(X)).
\end{equation}

Since $r^{*} < r$, we have $B_{1}(\rvr_{r^{*}}(X) \subset B_{1}(\rvr_{r}(X))$ and thus $\gamma_{<r} \in B_{1}(\rvr_{r}(X))$. 

Thus we can assume that $\gamma = \partial (\sum_{i}\sigma_{i})$ where $\diam (\sigma_i) = r$ for all $i$. Since we also have $\gamma = \sum_{i}\partial \sigma_{i}$, we merely need to show that $\partial \sigma_{i} \in B_{1}(\rvr_{r}(X)$ for each $2$-simplex in the sum and then we are done. But this is shown in Lemma \ref{the-big-lemma}, and so the proof of the present Lemma is complete.  

Finally, we show that the diagram in Theorem \ref{theorem-VR-RVR-isomorphism} is commutative to complete the proof of Theorem $\ref{theorem-VR-RVR-isomorphism}$. 

\begin{lemma}
    The diagram in Theorem \ref{theorem-VR-RVR-isomorphism} is commutative.
\end{lemma}

\begin{proof}
    Let $0 < r_1 < r_2$ since the case where $r_1 = 0$ is trivial. Let $\gamma + B_{1}(\rvr_{r_1}(X))$ be an element of $H_{1}(\rvr_{r_1}(X))$. Then $g_{r_1}^{r_2}(\theta_{r_1} (\gamma + B_{1}(\rvr_{r_1}(X))) = g_{r_1}^{r_2}(\gamma + B_{1}(\vr_{r_1}(X))) = \gamma + B_{1}(\vr_{r_2}(X))$ and $\theta_{r_2}(f_{r_1}^{r_2}(\gamma + B_{1}(\rvr_{r_1}(X))) = \theta_{r_2}(\gamma + B_{1}(\rvr_{r_2}(X))) = \gamma + B_{1}(\vr_{r_2}(X))$. Thus commutativity is proven.
\end{proof}

 




\section{Geometric data structures}

In this section we introduce some geometric data structures used to implement our method for computing VRPH. These data structures are frequently utilised in algorithms working with finite sets of points in Euclidean spaces and finite metric spaces more generally. 


\subsection{Minimum Spanning Trees}

Minimum Spanning trees are fundamental structures used in the study of graphs. For us, they are useful because the edges are the 1-simplices that correspond to deaths of degree-0 homology classes in the Vietoris-Rips filtration. We briefly go over the definition of a minimum spanning tree and state some results about their relation to Vietoris-Rips persistent homology. Whilst we will be working in the context of Euclidean point clouds, these results hold for arbitrary finite metric spaces. As in Definition \ref{lune-function}, let $\vr_{\infty}^{1}(X)$ be the set of $1$-simplices in $\vr_{\infty}(X)$ and, in a similar fashion, let $\vr_{\infty}^{0}(X)$ be the set of $0$-simplices in $\vr_{\infty}(X)$. 

\begin{definition}
Consider a point cloud $X$. Then a subset of $1$-simplices $S \subset \vr_{\infty}^{1}(X)$ is said to be acyclic if $H_{1}(S\cup \vr_{\infty}^{0}(X)) = 0$. 
\end{definition}
 
\begin{definition}
Consider a point cloud $X$. Then a subset of $1$-simplices $S \subset \vr_{\infty}^{1}(X)$ is said to be spanning if $H_{0}(S\cup \vr_{\infty}^{0}(X))=1$.
\end{definition}

\begin{definition}
Consider a point cloud $X$. Then a subset of $1$-simplices $S \subset \vr_{\infty}^{1}(X)$ is said to be a spanning tree of $X$ if it is both acyclic and spanning.     
\end{definition}

We now define the notion of the weight of a graph so that we can then define a \emph{minimum} spanning tree. 

\begin{definition}
Consider a graph $G$ consisting of edges from $\vr_{\infty}^{1}(X)$ and vertices from $\vr_{\infty}^{0}(X)$.  For $\sigma \in G$, let $w(\sigma) = \diam (\sigma)$ and define 

\begin{equation}
w(G) := \sum_{\sigma \in G} w (\sigma)
\end{equation}

We call $w(G)$ the weight of the graph. 
\end{definition}

\begin{definition}
A minimum spanning tree is a spanning tree $S$ for $X$ with minimum value of $w(S)$ out of all spanning trees on $X$.  
\end{definition}

It should be noted that if all pairwise distances are unique then we can talk about \emph{the} minimum spanning tree for $X$ which we denote as $\mst (X)$. If $X$ does not have unique pairwise distances, we use Definition \ref{def-second-mst-definition} to select a specific minimum spanning tree. 

\begin{definition}
\label{def-second-mst-definition}
    Consider a point cloud $X$, the labelling of its points $\psi: X \rightarrow \{1,...,n\}$
    %where the pairwise distances may not be unique 
    and the Vietoris-Rips simplex-wise filtration of $\vr_{\bullet}(X)$ defined by the ordering $\phi$ given in Definition~\ref{def-VR-total-order}. 
    Then we construct a graph, $G$, with vertex set $X$ and edges chosen as all 1-simplices that correspond to the death of a degree-0 homology class in $\vr_{\bullet}(X)$. 
\end{definition}

We now show that $G$ is a minimum spanning tree for $X$. 

\begin{lemma}
    \label{second-def-is-actually-a-mst}
    The construction of $G$ in Definition \ref{def-second-mst-definition} is indeed a minimum spanning tree for $X$. 
\end{lemma}

\begin{proof}
    Let $X$ be a point cloud and consider the Vietoris-Rips filtration $\vr_{\bullet}(X)$. Adding a $1$-simplex $\sigma$ that kills a degree-$0$ homology class means that it joins two distinct components that are now merged. 
    By Lemma \ref{can-only-birth-or-kill} this means a $1$-cycle is not formed and by Kruskal's algorithm \cite{kruskal1956shortest} for building a minimum spanning tree, $\sigma$ would be added to the $\mst(X)$. Thus the $\mst(X)$ described in Definition \ref{def-second-mst-definition} is just the minimum spanning tree that would be constructed from Kruskal's algorithm, and thus is indeed a minimum spanning tree. 
\end{proof}

From now on we refer to the graph $G$ as `the' minimum spanning tree $\mst(X)$.
We know the edges of $\mst (X)$ correspond to the deaths of degree-0 homology classes we also know that every 1-simplex \emph{not} in $\mst (X)$ corresponds to the birth of a degree-1 homology class. from Lemma \ref{can-only-birth-or-kill} we know every $1$-simplex must give birth to a degree-$1$ homology class or kill a degree-$0$ homology class. It should be said however, that most of these homology classes have trivial persistence. 



\subsection{Relative Neighborhood Graph and friends}
\label{section-rng}

In this section we discuss the Relative Neighborhood Graph and some related geometric structures, starting with the Delaunay triangulation~\cite{toth2017handbook}. 

\begin{definition}[Delaunay triangulation]
\label{def-delaunay-triangulation}
Consider a point cloud $X \subset \R^D$. The Delaunay triangulation of $X$, denoted by $\mathrm{DT}(X)$, is the simplicial complex with vertex set $X$,  $D$-simplices $\langle x_0 x_1 \ldots x_D \rangle$ that satisfy the following property, together with all their faces.  
The vertices $\{ x_0, x_1, \ldots, x_D \} \subset X$ form a $D$-simplex in  $ \mathrm{DT}(X)$  if there exists an open $D$-ball $B(z,\rho)$ such that  
$ \{ x_0, x_1, \ldots, x_D\} \in \partial B(z, \rho)$  and  $B(z, \rho) \cap X = \emptyset$. 
\end{definition}

It should be noted that Definition \ref{def-delaunay-triangulation} may not give an embedded triangulation. For example, if $X$ consists of four points that lie on the same circle in $\mathbb{R}^2$, then $\mathrm{DT} (X)$ is the simplicial complex consisting of the four 2-simplices formed by each subset of three points. 
Any robust implementation of Delaunay triangulations resolves this by using a consistent choice of two of the four triangles. 
For our purposes, a non-embedded triangulation does not present a problem because we only check the 1-simplices of $\mathrm{DT}(X)$ to see if they belong to $\rng(X)$.  

It should be noted that Definition \ref{def-delaunay-triangulation} may not give an embedded triangulation. Such an example is given in Example \ref{delaunay-triangulation-example}

\begin{example}
\label{delaunay-triangulation-example}
    Consider $X = \{x_{1}, x_{2}, x_{3}, x_{4} \}$ be a point cloud with $4$ points that lie on a cyclic quadrilateral. Then in this case $\mathrm{DT}(X)$ would be the simplicial complex consisting of the simplex $\langle x_{1}x_{2}x_{3}x_{4} \rangle$ and its subsimplices. This is not a triangulation and any robust implementation of Delaunay triangulations obtains a triangulation by choosing two of the four $2$-simplex faces on the $3$-simplex $\langle x_{1}x_{2}x_{3}x_{4} \rangle$. This raises concerns since we may be potentially missing edges of $\rng (X)$ by making one particular choice of diagonal over the other. This is shown in Figure \ref{delaunay-example}. 

    % Figure environment removed

    
\end{example}


We for now, assert that cases like Example \ref{delaunay-triangulation-example} do not present an issue and will prove in Lemma \ref{DT-its-all-good} that neither of the diagonals are in $\rng (X)$.  

The Gabriel graph \cite{gabriel1969new} has a similar definition to the Delaunay triangulation, only including the 1-simplices that satisfy an empty circumsphere test:  

\begin{definition}[Gabriel graph]
Consider a point cloud $X \subset \mathbb{R}^D$. The Gabriel graph of $X$, denoted by $\mathrm{GG}(X)$ is the graph with vertex set $X$ and edges $\langle yz \rangle$ that satisfy the following property. 

\begin{equation} 
\Biggl\{x\in X \;\bigg|\; d\left(x,\frac{y+z}{2}\right) < \frac{d(y,z)}{2}\Biggr\}=\emptyset
\label{GGcondition}
\end{equation} 
\end{definition}

It should be noted that the Gabriel graph and Delaunay triangulations cannot be defined for arbitrary finite metric spaces.  

The third structure we describe, and one we make use of when computing homology, is similar to the Gabriel graph, but includes an edge only if it has an empty lune.  

\begin{definition}[Relative neighborhood graph]
\label{def-rng}
Consider a point cloud $X \in \mathbb{R}^D$. The Relative Neighborhood Graph of $X$, denoted $\rng (X)$ is the graph with vertices $X$ and edges $E =\{\langle yz \rangle \;|\; \lune (\langle yz \rangle ) = \emptyset\}$.

\end{definition}

The following lemma is an extension of Theorem 1 and 2 from \cite{ToussaintRNG} which only apply to point clouds with unique pairwise distances in the plane. 
In \cite{jaromczyk1992relative} they claimed Lemma \ref{lemma-mst-in-rng} holds for any Euclidean point cloud, even those with non-unique pairwise distances. However, the definition of $\rng (X)$ in \cite{jaromczyk1992relative} differs from the definition we give as it  uses Definition \ref{definition-traditional-lune} for the lune but replaces $<$ with $\leq$. Here, we give a proof using our modified definition of the relative neighborhood graph. 


\begin{lemma}
\label{lemma-mst-in-rng}
Consider a point cloud $X \subset \R^D$, then 

\begin{equation}
\mst (X) \subset \rng (X) \subset \mathrm{GG}(X) \subset \mathrm{DT}(X)
\end{equation}

\end{lemma}

\begin{proof}
The last inclusion is not affected by a change in the definition of $\rng (X)$ and thus still holds. For the middle inclusion: given any $\langle y z \rangle$, if a point $x\in X$ satisfies $ d\left(x,\frac{y+z}{2}\right) < \frac{d(y,z)}{2}$
then $d(x,y) \leq d(x,\frac{y+z}{2}) + d(\frac{y+z}{2}, y) < 2 \frac{d(y,z)}{2} = d(y,z)$.  Similarly, $d(x,z) < d(y,z)$ and it follows that $x \in \lune (\langle yz \rangle)$. In other words, an empty lune implies that (\ref{GGcondition}) holds and we see that $\rng(X) \subset \mathrm{GG}(X)$. 

Finally, we establish that $ \mst (X) \subset \rng (X)$ by showing the contrapositive. 
Suppose the edge $ \langle yz \rangle \notin \rng (X)$.
This means there is a point $x\in X$ with  $x \in \lune (\langle yz \rangle )$.
From our definition of $\lune (\langle yz \rangle)$ we have that $\langle xz \rangle, \langle xy \rangle < \langle yz \rangle$ in the filtration ordering. 
This means that $y$ and $z$ are part of the same connected component before $ \langle yz \rangle$ is added to the filtration and  it follows that $\langle yz \rangle$ cannot be part of $\mst (X)$.  
\end{proof}

Note that both the $\mst (X)$ and $\rng (X)$ can be defined when $X$ is any finite metric space, and that the inclusion $\mst (X) \subset \rng (X)$ still holds in this setting. 

\bigskip 
The next lemma, which is a new result, establishes the importance of edges which are in $\rng (X)$ but are not in $\mst (X)$. 


\begin{lemma}
\label{RNG-lemma-3}
Consider a finite metric space $X$. Then $\rng (X)$  contains all $1$-simplices that give birth to a degree-1 homology class corresponding to a persistence pair which is \emph{not} an apparent pair. Furthermore there is a one-to-one correspondence between the $1$-simplices in $\rng (X) \setminus \mst (X)$ and the homology classes that correspond to a persistence pair which is \emph{not} an apparent pair.  
\end{lemma}

\begin{proof}
Since $\mst (X)$ consists of all the 1-simplices that correspond to the death of a degree-0 homology class it follows that the $1$-simplices of $\rng (X) \setminus \mst (X)$ correspond to births. Thus we  need to show that these $1$-simplices cannot be part of an apparent pair. Consider a $1$-simplex $\langle yz \rangle \in \rng (X) \setminus \mst (X)$. Suppose for contradiction that $\langle yz \rangle$ was part of an apparent pair $(\langle yz \rangle, \sigma)$. From Definition \ref{apparent-pair} we know that $\sigma$ must take the form $\langle xyz \rangle$ since $\langle yz \rangle$ needs to be the face of $\sigma$ added last to the filtration. From the Definition of the simplex-wise Vietoris-Rips filtration this means that $\langle xy \rangle, \langle xz \rangle < \langle yz \rangle$. Thus $x \in \lune (\langle yz \rangle)$ which contradicts the fact that $\langle yz \rangle \in \rng (X)$. 
\end{proof}

Lemma \ref{RNG-lemma-3} combined with Lemma \ref{unique-distances-lemma} means that we know the birth values for degree-1 Vietoris-Rips persistence intervals of non-apparent pairs simply by constructing the $\rng (X)$ and $\mst (X)$. The birth values of the degree-1 Vietoris-Rips persistence intervals of the non apparent pairs will be the diameters of the $1$-simplices in $\rng(X)\setminus \mst(X)$.  In the case of unique pairwise distances, this means we have the birth values for all intervals of positive length.  In the case of non-unique pairwise distances, there can be non-apparent pairs of simplices with the same birth and death values. 
In either case, knowing the number of non-apparent birth values gives us a stopping criterion when building the reduced Vietoris-Rips complex: once the correct number of death simplices is found, no further edges need to be analysed when computing degree-1 persistent homology. 

We now provide the promised justification for why ambiguous Delaunay triangulations do not pose problems for our purposes. However we will also need a small topological lemma which we prove first. In what follows, if $A$ is a set then we denote the boundary of $A$ as $\bd (A)$. 

\begin{lemma}
\label{small-top-lemma}
    Consider two closed sets $A$ and $B$ in $\mathbb{R}^d$ with $A \subset B$. Let $F \subset \bd (B)$ and suppose that $F \subset A$. Then it follows that $F \subset \bd (A)$. 
\end{lemma}

\begin{proof}
    Suppose for contradiction that $F \not\subset \bd (A)$. Since $F \subset A$ it follows that there must be a point $f\in F$ that is an interior point of $A$. Thus there exists an open ball $B_{f}$ centred at $f$ such that $B_{f} \subset A$. But then $B_{f} \subset B$ which means $f$ is an interior point of $B$, which contradicts the fact that $F \subset \bd (B)$. Hence we have $F \subset \bd (A)$. 
\end{proof}

\begin{lemma}
\label{DT-its-all-good}
    Consider a point set $X \in \mathbb{R}^D$ such that the points of $X$ lie on the boundary of a $D$-ball $B$. Let $\hull(X)$ be the convex hull of $X$. Let $\partial \hull (X)$ be the boundary of $\hull (X)$. Then we have that $\mst (X) \subset \rng (X) \subset \partial \hull (X)$.  
\end{lemma}

\begin{proof}
If $|X| = 2,3$ then the proof is trivial so we assume that $|X| \geq 4$. 

Given any two points $y, z \in B$ we can define the cap generated by $y$ and $z$ of $B$ as follows. Let $b$ denote the centre of the ball $B$ and let $b'$ be the point on the line segment $yz$ that is closest to $b$. We will for now, assume that $y$ and $z$ are not antipodal, meanining that $b\neq b'$. Consider the plane $P_{yz}$ which is perpendicular to the line segment $bb'$. We can use $P_{yz}$ to split the ball $B$ into two three disjoint sets $B_{1}, B_{2}$ and $B_{3}$. Let $B_{2} = P_{yz} \cap B$. Then let $B_{1}$ and $B_{3}$ be the remainder of $B$ that is split by $P_{yz}$, let $B_{3}$ be the part of $B$ that contains $b$ and let $B_{1}$ be the part of $B$ that does not contain $b$. We will define the cap generated by $y$ and $z$ of $B$ as $B_{1}$ and denote it as $\capp _{yz}(B)$. 

With this definition in place, we can now prove that $\rng (X) \subset \partial \hull (X)$. Consider $y,z \in X$ not antipodal such that the line segment $yz$ is not contained in $\partial \hull (X)$. Consider the two sets $\capp_{yz}(B)$ and $B^{-} = B \setminus \capp_{yz}(B)$. Note that $B^{-}$ is a convex subset of $\mathbb{R}^{D}$ and that the line segment $yz$ lies on the boundary of this subset. This means that there must exist a point $w \in X$ that is contained in $\capp_{yz}(B)$, otherwise since $\hull (X)$ is the smallest convex set containing $X$ it follows that $\hull (X) \subset B^{-}$. Since the line segment $yz$ is contained in the boundary of $B^{-}$ it follows that $yz$ must be contained in the boundary of $\hull (X)$ by Lemma \ref{small-top-lemma}, a contradiction. Let $B_{yz}$ be the ball with diameter $d(y,z)$ centred at the midpoint of $yz$. The set $B_{yz}$ contains $\capp_{yz}(X)$ which we know contains some $w\in X$. This means that $\langle yz \rangle$ is not contained in $\gabg (X)$ meaning by \ref{lemma-mst-in-rng} it follows that $\langle yz \rangle$ is not containing in $\rng (X)$. 

Next, we address the case where $y$ and $z$ are antipodal points. In this case since $B = B_{yz}$ and all points of $X$ lie on the boundary of $B$ it follows that for all $x\in X$ with $x \neq y, z$ that $\max \{ d(x,y), d(x,z) \} < d(y,z)$. Thus it follows that for all $x\in X$ with $x \neq y$ that $\langle xy \rangle, \langle xz \rangle < \langle yz \rangle$. Thus $\lune (\langle yz \rangle) \neq \emptyset$ and hence $\langle yz \rangle$ is not in $\rng (X)$. 

Hence $\rng(X) \subset \partial \hull (X)$. Using Lemma \ref{lemma-mst-in-rng} we have $\mst (X) \subset \rng (X) \subset \partial \hull (X)$. 
\end{proof}

In the context of Example \ref{delaunay-example} Lemma \ref{DT-its-all-good} says that neither of the diagonals will be part of $\rng(X)$, meaning it is irrelevant which diagonal a particular robust implementation of the Delaunay triangulation chooses. 




\subsection{$kd$-Trees}

In this section we briefly recall the notion of a $kd$-tree data structure and the reader who desires more details is directed towards \cite{toth2017handbook}. 
The use of $kd$-trees is restricted to point sets in Euclidean space and is one reason we have introduced this assumption for $X$ in this paper.  

Given a point cloud $X \subset \R^D$, a $kd$-tree is a data structure that facilitates efficient geometric searching within $X$. A $kd$-tree of $X$ is a balanced binary tree with nodes formed by the points of $X$. Each node of the $kd$-tree partitions its descendants according to their coordinate values along a given axis, changing the ordinate used as we progress through layers of the tree. $kd$-trees are particularly useful for answering ``nearest neighbor queries" and ``radius search queries", as required when testing whether there points in the lune of an edge.   
Recall that a nearest neighbor query is one where a point $z \in \R^D$ is given and the point from $X$ closest to $z$ is returned. A radius search is when a point $z$ and a search radius $R$ are given and all points $x\in X$ such that $d(x,z) < R$ are returned. 


\subsection{Algorithms and complexity analysis }
\label{algorithms-and-complexity-analysis}

Delaunay triangulations for $X \subset \mathbb{R}^2$ can be constructed in $O(n\log (n))$ time using the divide-and-conquer algorithm developed in \cite{divide-delaunay} and have $O(n)$ 1-simplices. For $X \subset \mathbb{R}^D$ where $D \geq 3$ we can employ the randomised incremental algorithm described in \cite{toth2017handbook} which has worst case time complexity $O(n^{\lceil \frac{D}{2} \rceil})$ and produces a Delaunay triangulation with at most $O(n^2)$ 1-simplices. 

For point clouds $X \subset \mathbb{R}^2$ it is shown in \cite{matula1980properties} that the Gabriel graph can be computed in $O(n\log (n))$ time complexity. In higher dimensions it can be constructed in $O(n^3)$ time using a naive algorithm which simply looks at all edges and for each edge, checks if a point lies in the ball of interest. 

Now let us examine the algorithms for $\rng (X)$ and their complexities. Supowit \cite{supowit_RNG} presents an algorithm which finds $\rng (X)$ in $O\left(n \log (n)\right)$ time if $X\subset \mathbb{R}^2$ by first computing $\mathrm{DT} (X)$.  Supowit also presents another algorithm which finds $\rng (X)$ in $O(n^2)$ time if $X \subset \mathbb{R}^D$ for $D \geq 3$. For the latter algorithm, there is an implicit dependence on the dimension $D$. Let $c(D)$ be the minimum number of radius-$\frac{1}{2}$ balls needed to cover the unit sphere $S^{D-1}$. Then  the complexity of Supowit's second algorithm is actually $O(c(D)n^2)$. A lower bound $c(D) > D^{\frac{3}{2}} \cdot (2)^{D-1}$ was given in \cite{verger2005covering} and thus, despite its quadratic dependence on $n$, the complexity is at least exponential  in the dimension  $D$. In \cite{Agarwal1992RelativeNG}, a randomised algorithm is given which computes the $\rng (X)$ in expected time $O(n^{2(1-\frac{1}{D+1})+\epsilon})$ where $\epsilon > 0$ is arbitrarily small. 

For a point cloud $X \subset \mathbb{R}^2$ finding $\mst (X)$ from $\rng (X)$ or $\mathrm{DT}(X)$ can be done via Kruskal's algorithm in $O(n\log (n))$ time since  $\rng (X)$ and $\mathrm{DT} (X)$ have $O(n)$ edges. For higher dimensions, $\mst (X)$ can always be found in $O(n^2 \log (n))$ time since there are $O(n^2)$ edges in the complete graph with vertex set $X$. 

Lastly, we discuss the algorithms for $kd$-trees and their complexities. For a point cloud $X \subset \mathbb{R}^D$ the complexity of building the $kd$-tree is $O(Dn\log (n))$ \cite{Brown2015kdtree}. Searching for the $k$ nearest neighbors of a given query point has an average complexity $O(k\log (n))$. 



\section{An algorithm for computing degree-1 Vietoris-Rips persistent homology}
\label{algorithm}

In this section we discuss our algorithm, $\mathsf{EuclideanPH1}$ to compute $\ph{1}(X)$ for a point cloud $X$ in Euclidean space, using the reduced Vietoris-Rips complex. We will first briefly describe some differences between $\mathsf{EuclideanPH1}$ and Ripser. 
Then we will give a high level description of our algorithm, highlighting the main components and then we  give a detailed explanation of the implementation used for each part of the algorithm. 

There are a few main differences between $\mathsf{EuclideanPH1}$ and Ripser \cite{Ripser}. One of the biggest differences is that $\mathsf{EuclideanPH1}$ does not compute cohomology, instead computing homology directly. Another difference is Ripser will analyse all $1$-simplices up to the radius of the bounding sphere of the point cloud (or up to a user chosen maximum parameter value), even if there are no more non-apparent pairs to be found. In the case of $\mathsf{EuclideanPH1}$, it stops after finding the last persistent pair corresponding to a non-apparent pair. There is also a difference in the number of simplices utilized in each Algorithm. Ripser utilizes an indexing system which assigns a natural number to each simplex in the filtration up to the maximum diameter. With larger point clouds, the largest such index can be $O(n^3)$, and this can cause issues since it can lead to numbers larger than the machine can deal with. In the case of $\mathsf{EuclideanPH1}$, we also assign an index to simplices, but since we only use $O(n^2)$ simplices, this is less of an issue for $\mathsf{EuclideanPH1}$. 

\subsection{Outline of $\mathsf{EuclideanPH1}$}
\label{high-level-description-of-the-algorithm}

$\mathsf{EuclideanPH1}$ proceeds by analysing each 1-simplex in order of increasing length with ties broken using Definition~\ref{binary-relation-on-simplices}. For each 1-simplex, we find its lune and select a point to represent each connected component, in effect constructing the lune function; these are used to build the reduced Vietoris-Rips complex. The matrix reduction and persistence pairing is performed as each 2-simplex is added.  The iteration ceases when we have found the pre-determined number of homology classes that do not correspond to apparent pairs.


\subsubsection*{Initialise data structures}

The input is a list of $n$ points, $X \subset \R^D$, and an integer $k$. 
The value of $k$ can be set by the user, but defaults to $\sqrt{n}$. 
Guidelines on what constitutes an ideal value of $k$ are discussed further in Section \ref{implementation-details}. Considerations on choosing the value of $k$ are discussed further in Section \ref{implementation-details}

The first procedure is building the $kd$-tree for $X$. 
We then use this to initialise two further data structures that assist in enumerating 1-simplices by increasing length. These are a table, $N$, listing up to $k$ nearest neighbors for each point in $X$ and a minimum heap, $H$, for efficient sorting of 1-simplices. Details about minimum heap data structures are given in~\cite{williamsalgorithm}.
 

\subsubsection*{Build the RNG}

We next compute $\rng(X)$ of the point cloud $X$ to establish the stopping condition for the main loop. 
The quantity $\mathsf{total\_bars}$ is calculated as the number of edges in $\rng(X)$ minus $(n-1)$, the number of edges that must be in any $\mst(X)$; this 
tells us the number of persistence intervals that do not correspond to an apparent pair. 

Initialise $\mathsf{death\_count} = 0$ to count the number of non-apparent pairs found while iterating the main loop. 

\subsubsection*{Start of Main Loop}

\subsubsection*{Step 1: Find the next 1-simplex}

  
Find the next 1-simplex $\langle yz \rangle$ in the simplex-wise filtration ordering. This is facilitated by the minimum heap $H$ which contains the next candidate 1-simplex for each point, and stores these sorted by the total order of Definition \ref{binary-relation-on-simplices}. 

\subsubsection*{Step 2: Find the lune and compute its connected components}

Find the lune of the 1-simplex $\langle yz \rangle$ from Step 1. 
If the lune is empty return to Step 1, otherwise continue. 
Now find $c$, the number of connected components of $\lune (\langle yz \rangle)$ and define the lune function $L$. 
That is, for $i=1,...,c$, choose a point $x_{i}$ from each connected component and set $L(\langle yz \rangle) = \{x_1,...,x_c\}$. 

\subsubsection*{Step 3: Construct a ``column" for each connected component}

If $\mathrm{lune}(\langle yz \rangle)$ has $c=1$ then we add one column to the boundary matrix corresponding to the boundary of $\langle yzx_{1} \rangle$. This column does not need to be reduced as its lowest~1  corresponds to the row-index of $\langle yz \rangle$ which has only just been added to the filtration. 
Return to Step 1. 

Otherwise, if $\mathrm{lune}(\langle yz \rangle)$ has $c\geq 2$ then we need to add one column for each 2-simplex $\langle yzx_i  \rangle$, in increasing lexicographic order.  With the exception of the first column added, all other columns need to be reduced.   Proceed to Step 4. 

As will be elaborated in Section~\ref{implementation-details}, we don't actually construct a matrix but store columns that require reduction in a self balancing binary search tree. 
 

\subsubsection*{Step 4: Perform matrix reduction and persistence pairing}

In the case that $c\geq 2$, each of $c-1$ matrix columns must be reduced. 
If a column reduces to zero, that 2-simplex has given birth to a degree-2 homology class so $\mathsf{death\_count}$ remains the same.
Otherwise, if a lowest~1 remains then its location in the matrix at row-$i$ and column-$j$ defines a non-apparent persistence pair and we increment $\mathsf{death\_count}$ by 1. 

The barcode interval end points are found as the diameters of the appropriate birth and death simplices (i.e., $\sigma_i$ and $\sigma_j$). If the persistence of this interval is 0 then it is not added to the persistence barcode. 

\subsubsection*{Iteration test}

If $\mathsf{death\_count} = \mathsf{total\_ bars}$ then end the iteration, otherwise proceed to Step 1 and execute the main loop again.  
 
\subsubsection*{Output}

Once all non-apparent pairs are found, the list of barcode intervals with non-trivial persistence is returned.  


\subsection{Implementation details}
\label{implementation-details}

In this section we document our implementation of the Reduced Rips algorithm in the $C^{++}$ code, $\mathsf{EuclideanPH1}$ \cite{EuclideanPH1} which accepts point clouds $X \in \mathbb{R}^D$ where $D=2,3$.
We also briefly discuss the computational time complexity of each step. In what follows, $B(x,r)$ denotes the open ball centred at $x$ with radius $r$. For a set $A$, $\overline{A}$ denotes the closure of $A$. The reader who is uninterested in the technical details of implementation may skip this section and refer to it when more details are desired. 

\paragraph{Initialize Data Structures}
\label{initialize-data-structures}
We first construct a $kd$-tree on the points of $X$; this has a time complexity of $O(Dn\log (n))$. 
In $\mathsf{EuclideanPH1}$ we use the package nanoflann~\cite{blanco2014nanoflann}. 
We then construct a table $N$ with row-$i$ containing near neighbors of $\psi^{-1}(i) = x \in X$. 
To populate row-$i$, we start by listing the $k$ closest neighbors to $x$ and then  
remove those points $y$ having $\psi(y) < \psi(x)$. 
The remaining points in this row are then sorted by increasing distance from $x$, with ties ordered by their index. 
Note that the last row in this table is empty.
The parameter $k$ has a default value of $\sqrt{n}$, but its optimisation is left to the user; we discuss some heuristics below.

Building the table $N$ has time complexity  $O(kn\log (n))$. If one chooses $k = n$, then the construction of $N$ will have complexity bounded by $O(n^2\log (n))$. 

To facilitate the execution of the main loop we need a method that returns the next $1$-simplex in the filtration ordering.
Enumerating and sorting all $1$-simplices by diameter has a complexity of $O(n^2 \log (n))$, which is rather costly. 
Instead, we use the table $N$ and a minimum heap data structure, $H$. Elements of the heap $H$ are tuples $(\psi(y),\psi(z),t,r)$ with $\psi(y) < \psi(z)$. The variable $t$ records the location of $z$ in the $\psi(y)$-row of the table $N$, i.e., $N[\psi(y)][t] = \psi(z)$, and $r = \diam(\langle yz \rangle) = d(y,z)$. The heap is initialised with $n-1$ elements 
$(i, N[i][1] , 1 , r)$, where $r$ is distance between point $\psi^{-1}(i)$ and $\psi^{-1}(N[i][1])$, the nearest neighbor with larger index. Constructing the initialised minimum heap has complexity $O(n\log (n))$. 

During the main loop we remove the element with smallest value of $r$ (and point indices) and then insert the next candidate 1-simplex from $N$. Inserting a new element into the minimum heap has $O(\log (n))$ complexity. The point of creating and maintaining the table $N$ and the heap $H$ is that they  \emph{may} allow us to avoid computing all pairwise distances. This is an opportune point to discuss the choice of $k$. 
Recall that the table $N$ has at most $k$ points listed in each row. 
Suppose that at some point in the iteration of the main loop, we pop the element $(\psi(y),\psi(z),t,r)$ from the heap and find that there are no further neighbors of $y$ stored in $N$. 
We must now supplement the table by finding and sorting further pairwise distances from $y$. 
In our current implementation, if we reach this situation for a given $y$, we compute and sort all additional pairwise distances $d(y, z)$ with $\psi(y) < \psi(z)$. 
If we have to do this for every row, we incur a computational complexity of $O(n^2 \log (n))$ and a memory cost of $O(n^2)$, which we would like to avoid. Thus one wants to choose $k$ large enough so that $N$ includes the longest critical 1-simplex. 
 
Without prior knowledge of the structure of $X$, we do not have any way to determine an optimal value of $k$ except by trial and error. 
In practice, if a given run of the code seems to be using too much memory, it could be that the chosen value of $k$ is too small, causing many extra extensions of the table $N$. 
Conversely, one does not want to choose $k$ \emph{too} large, otherwise $N$ will use more storage than actually required to complete the calculation of $\ph{1}(X)$. 



\paragraph{Build the RNG}
For $D=2,3$, we first build the Delaunay triangulation $\mathrm{DT}(X)$ using the CGAL package~\cite{cgal:pt-t3-23b}. 
We then build $\rng(X)$ from $\mathrm{DT}(X)$ by testing the lune of each edge as follows.  
For each $1$-simplex $\langle yz \rangle$ of $\mathrm{DT}(X)$ we use the $kd$-tree constructed on $X$ to find all points in the closed balls $\overline{B}(y,d(y,z))$ and $\overline{B}(z,d(y,z))$. 
Any points lying on the boundary of the intersection $\overline{B}(y,d(y,z)) \cap \overline{B}(z,d(y,z))$ are analysed using the total order on simplices to decide if they belong to $\lune \langle yz \rangle$. Note that in practice this case seldom arises.
If $\lune \langle yz \rangle$ is empty it is added to $\rng(X)$.  

Recall that $\rng(X)$ is used to establish the stopping condition for the main loop via the value of $\mathsf{total\_bars}$, the number of non-$\mst(X)$ edges in $\rng(X)$. Note that we do not need to find $\mst(X)$ as it must always contain $n-1$ edges. 

Building the Delaunay triangulation of $X \subset \mathbb{R}^2$ has complexity $O(n \log (n))$ and for $X \subset \mathbb{R}^3$ it has a complexity of $O(n^2)$. For $X \subset \mathbb{R}^2$ we check $O(n)$ $1$-simplices and for each $1$-simplex, examine at most $O(n)$ points. 
For the case $X \subset\mathbb{R}^3$ we  check at most $O(n^2)$ edges and then still examine at most $O(n)$ points per $1$-simplex. 
Thus finding $\rng (X)$ has complexity $O(n^2)$ in $\mathbb{R}^2$ and $O(n^3)$ in $\mathbb{R}^3$. The reader may wonder why we use these algorithms when ones with lower complexities exist. This is because whilst the worst case complexities are rather high the complexities for a typical point set are significantly better. 
As we use $kd$-trees to find the lunes, in practice we examine much fewer than $O(n)$ points for each edge in $\mathrm{DT} (X)$.  


\paragraph{Start of Main Loop}
Here we discuss the implementation details of the main loop. 

\paragraph{Step 1: Find the next 1 simplex}
At the start of each iteration, we pop the top element of the minimum heap $H$, $(\psi (y), \psi (z), t, r)$. This element has the smallest value of $r$, with ties broken by lexicographic order of the pair ($\psi(y)$, $\psi(z)$).  
We then insert $(\psi(y), \psi(z'), t+1, r')$ where $z'$ is the $(t+1)$th neighbor of $y$ in the table $N$ and $r' = d(y,z') \geq r$. 
As described above, if $(t+1)$ is larger than the number of neighbors currently stored in $N$, then we extend the row $N[\psi(y)]$ by finding and sorting all points $x$ with $\psi(x) > \psi(y)$. 
Once we have exhausted all possible pairs with $\psi(x) > \psi(y)$ nothing is inserted. 



\paragraph{Step 2: Find the lune and compute its connected components}
Just as when building $\rng(X)$, we find $\lune (\langle y z \rangle)$ by using the $kd$-tree to return the points of $X$ in $\overline{B}(y,d(y,z)) \cap \overline{B}(y,d(y,z))$. 
We then find the number of connected components of $\lune (\langle yz \rangle)$.
To do this, we construct the Delaunay triangulation on the points of $\lune (\langle y z \rangle)$ and keep the subgraph containing edges $\langle y'z' \rangle $ that satisfy $ \langle y'z' \rangle < \langle yz \rangle$ (in the total order on simplices).  We then apply the union-find algorithm to this subgraph to determine its connected components.

Let us look at the complexity of this part of the algorithm. At worse, we examine $O(n)$ points to check if they are in $\lune (yz)$. Since there will be at most $O(n)$ points in $\lune ( \langle yz \rangle)$, constructing the Delaunay triangulation will take $O(n\log (n))$ time if $X \subset \mathbb{R}^2$ and take $O(n^2)$ time if $ X \subset \mathbb{R}^3$. The union-find algorithm takes $O(n \alpha (n))$ for $X \subset \mathbb{R}^2$ and will take $O(n^2 \alpha (n))$ for $X \subset \mathbb{R}^3$. 
Recall that $\alpha$ is the inverse Ackermann function, which for all intents and purposes, may be treated as a constant. 
Thus, for a given $1$-simplex the complexity of finding the connected components of its lune is bounded by $O(n^3)$. 
Although this is very much a worst case complexity it is rather high and applies to \emph{each} $1$-simplex we analyse. 
Thus it is worth some effort to speed up the analysis of lunes, especially since the overwhelming majority of $1$-simplices will have a lune with one connected component. To speed things up we conduct some preliminary tests based on Lemma~\ref{lens-lemma} which will guarantee that there is only one connected component in the lune.

For a given 1-simplex $\langle yz \rangle$ the first test we do is to check the ball of radius $\frac{1}{2}(2-\sqrt{3})r$ centred at the midpoint $(y+z)/2$. 
This is the ball circumscribed by the boundary of the region  $\{x\in \mathbb{R}^D \;|\; \Angle (yxz) > \frac{5\pi}{6} \}$.
Points of $X$ in this region are in $\lens(\langle yz \rangle)$ (Definition~\ref{lens}), and  Lemma~\ref{lens-lemma} guarantees that $\lune(\langle yz \rangle)$ has a single connected component if $\lens(\langle yz \rangle) \neq \emptyset$.  
Listing points of $X$ that are in this ball is considerably faster than finding all points of $\lune(\langle yz \rangle)$, and can provide a significant short-cut.  
To define the lune function in this case, we simply take one of the points found within the ball, $x$ say, and form the 2-simplex $\langle xyz \rangle$. 

The next test we implement requires us to find all points within the lune. We then test each point $x$ within the lune to see if $\Angle (yxz) > \frac{5\pi}{6}$. If we find a point $x$ satisfying this condition then we know that $\lens(\langle yz \rangle) \neq \emptyset$ and again deduce that  $\lune (\langle yz \rangle)$ has one connected component. Therefore we stop at the first such point found and form the 2-simplex $\langle xyz \rangle$. 

If both of these lens tests come back negative, then we proceed to build the Delaunay triangulation and determine its connected components as described above. 
Neither of the lens tests will increase the worst case complexity of $O(n^3)$ as both tests have worst case complexity of $O(n)$.

\paragraph{Step 3: Construct a ``column" for each connected component}
Here we discuss $\mathsf{EuclideanPH1}$'s implementation of the boundary matrix for the simplex-wise filtration 
and explain why the word ``columns" appears in quotation marks. 

If we \emph{were} building a matrix, then each time 
a two simplex $\langle xyz \rangle$ is added to the filtration we would need to create a column vector with non-zero entries at rows $\phi(\langle xy \rangle), \phi (\langle yz \rangle)$ and $\phi (\langle xz \rangle)$.
The subsequent matrix reduction step searches the previous columns to determine the correct persistence pairing. 
Since this is the only operation required of the boundary matrix, our implementation makes use of a self balancing binary search tree $T$ to improve the efficiency of the matrix reduction process.   
We use AVL trees \cite{AdelsonVelskii1963ANAF} in our code package but any other self balancing binary search tree would be suitable. 

So, a ``column'' of the boundary matrix is instead represented by a node of $T$. Each node consists of the following fields: left, right, height, key and column. The first four of these are standard fields necessary for the AVL tree to function. The values of the column field and the key field depend on how many connected components $\lune (\langle yz \rangle)$ has.
Ultimately, at the end of the algorithm $T$ will consist of the same information as the reduced boundary matrix, albeit in a slightly different form.  

\paragraph{Step 4: Perform matrix reduction and persistence pairing}

We now discuss what we are actually adding to $T$. If $\lune (\langle yz \rangle)$ is empty, then no node is added to $T$. Suppose $\lune (\langle yz \rangle)$ has only one connected component and let $L(\langle yz \rangle)$, the lune function of $\langle yz \rangle$, be $\{x \}$. We then add a node to $T$ whose column field is $\{ \phi(\langle xy \rangle), \phi (\langle yz \rangle), \phi (\langle xz \rangle) \}$ and set its key field to  the highest index of the three 1-simplices. This must be $\phi (\langle yz \rangle)$ because $\langle xy \rangle, \langle xz \rangle < \langle yz \rangle$. 
In other words, the column field stores only the non-zero row-indices and the key field stores the row index of the lowest 1. 
In this case of  $\lune (\langle yz \rangle)$ having one component, we do not need to perform any matrix reduction as no previous columns can have a lowest $1$ in the $\phi(\langle yz \rangle)$-th row.

Now suppose that $\lune (\langle yz \rangle)$ has more than one connected component, $|L(\langle yz \rangle)| \geq 2$. 
For each element, $x \in L(\langle yz \rangle)$ we add a node to $T$ as follows. 
First, we create a node $g_{x}$ which sets the column field as $\{\phi(\langle xy \rangle, \phi (\langle xz \rangle), \phi(\langle yz \rangle) \}$ and the key field as $\phi(\langle yz \rangle)$. 
Before we add this node to $T$ we perform the matrix reduction procedure as follows. 
We search $T$ to see if there are any columns with the same lowest one (key value) as $g_x$. 
This is where the benefit of using AVL trees is realised.  If $\langle yzx \rangle$ is the $j$th two-simplex added to the filtration, then we need only search $O(\log (j))$ nodes of $T$ as opposed to standard matrix reduction where one would potentially have to check $O(j)$ columns. 
If we find a node with the same key (lowest one) then we ``add" the column field of this node to the column field of $g_x$. 
Since we are working with coefficients in $\mathbb{Z}_{2}$, ``adding" in this context is  simply taking the symmetric difference of the two sets of indices. 
We then set the key field of $g_x$ to be the maximum element of the reduced column field. 
We repeat this process until either the key of $g_x$ cannot be found in $T$ or the column field of $g_x$ is empty. 
The first case is equivalent to reducing the column in the standard matrix reduction algorithm until the column has lowest 1 different from all the columns reduced thus far; we add this reduced $g_x$ to $T$. 
In the case that the column field is empty, this means a degree-2 homology class was created by adding the 2-simplex $\langle yzx \rangle$ to the filtration; we do not add anything to $T$ in this case. We will discuss the complexities of constructing and searching $T$ in Section \ref{complexity-analysis}.

\subsection{Overall complexity analysis}
\label{complexity-analysis}

In this section we find an upper bound on the complexity of the algorithm described in sections \ref{high-level-description-of-the-algorithm} and \ref{implementation-details}. 

\paragraph{Worst time complexity bound for  Euclidean point clouds.} We now bound the overall worst case time complexity for the algorithm in the case $X \subset \mathbb{R}^D$ using the discussion in Section \ref{implementation-details}. 
\begin{prop}
\label{overall-time-complexity}
    For a finite point cloud $X\subset \R^D$ with $n$ points the overall time complexity of \textsf{EuclideanPH1} can be bounded above by $O(n^6)$.
\end{prop}

\begin{proof}

First we find the complexity of constructing $N$ and $\rng(X)$. The time complexity of constructing $N$ is bounded above by $O(n^2\log (n))$ and the time complexity of constructing $\rng(X)$ is bounded above by $O(n^3)$. Thus the ``Initialise data structures" and ``Build the RNG" parts of Section \ref{implementation-details} is bounded by $O(n^3)$. 

Now let us analyse the complexity of the main loop. 
Consider the $j$-th 1-simplex $\langle yz \rangle$ analysed in the algorithm. Popping the $j$-th element from the heap $H$ can be done in $O(1)$ time and inserting a new element into the heap  takes $O(\log(j))$ time. Since $j$ is bounded above by $O(n^2)$ it follows this step is bounded by $O(\log (n))$. 

Finding $\lune (\langle yz \rangle)$ has complexity bounded by $O(n)$ and finding the connected components of the lune has complexity $O(n^2 \alpha(n))$, where $\alpha(n)$ is the inverse Ackerman function. Thus Step 2 of Section \ref{implementation-details} has complexity bounded by $O(n^2 \alpha (n))$. 

The complexity of Steps 3 and 4 depend on the number of connected components of $\lune(\langle yz \rangle)$.

If $\lune (\langle yz \rangle)$ is empty then there is nothing more for us to do and we move onto the next iteration of the main loop. 

If $\lune (\langle yz \rangle)$ has one connected component and $L(\langle yz \rangle) = \{x\}$ then we only need to add a node to $T$, the AVL tree \cite{AdelsonVelskii1963ANAF} introduced in Step 4 of Section \ref{implementation-details}. This has complexity $O(\log (j))$. Since $j$ is bounded by $O(n^2)$ this step has complexity bounded by $O(\log (n))$ for all $j$.

If $\lune(\langle yz \rangle)$ has more than one connected component then we need to search $T$ up to $j$ times. Each time we search and find another node with the same lowest 1 we add the column fields of the respective nodes, which has complexity bounded by $O(j)$. This results in an overall complexity of $O(j(\log (j) + j))$. If $\lune (\langle yz \rangle)$ has $c$ connected components then we need to do this step $c-1$ times. However, for fixed $D$, $c$ is bounded by a constant by Lemma \ref{bounded-connected-components-proof}, so it follows that the overall complexity for inserting a node in this case is still $O(j(\log(j) + j))$. Since $j$ is no more than $O(n^2)$ it follows that we can bound the complexity of Steps 3 and 4 by $O(n^2(\log (n^2) + n^2)) = O(n^4)$. 

Regardless of how many connected components the lune has, the complexity of the main loop is bounded by $O(n^4)$. Since the main loop will be executed a maximum of $O(n^2)$ times it follows that the complexity of the whole algorithm can be bounded by $O(n^6)$.
\end{proof}

\paragraph{Better bounds for time complexity in $\mathbb{R}^2$} Whilst the bound $O(n^6)$ on worst case time complexity is enormous it is not what we observe in the experimental results (presented in Section~\ref{sec:experiments}). 
The reason for this is that some of the time complexities given above are extremely crude overestimates. 

To get a better feel for the typical complexity let $b(X)$ be the number of degree-1 persistent pairs which are \emph{not} apparent pairs in the Vietoris-Rips filtration of $X$. Typically, $b(X)$ will be no more than $O(n)$; the reader interested in more details on bounding $b(X)$ is directed towards to the appendix. Then the complexity can be more accurately bounded as follows. 

\begin{prop}
\label{bound-for-point-cloud-in-r2}
For a finite point cloud $X\subset \R^2$ with $n$ points the overall time complexity of \textsf{EuclideanPH1} can be bounded above by $O(n \log (n)(n^2-b(X)) + n^4 \,b(X))$. 
\end{prop}

\begin{proof}
For $X\subset \mathbb{R}^2$ finding $\rng(X)$ can be bounded by $O(n\log (n))$, but $N$ will still be bounded by $O(n^2\log (n))$. Thus the ``initialise data structures" and ``Build the RNG" parts of \ref{implementation-details} are bounded by $O(n^2\log (n))$. 

Now we begin our analysis of the main loop. Consider the $j$th $1$-simplex $\langle yz \rangle$ analysed in the algorithm. Popping the $j$th element still takes $O(1)$ time and inserting a new element into the heap will still take $O(\log(j))$ time and thus we can still bound this part of the algorithm by $O(\log (n))$. 

Finding $\lune(\langle yz \rangle)$ will still be bounded by $O(n)$ but finding the number of connected components will be bounded by $O(n\log (n))$ since we can construct the Delaunay Triangulation on the points in the lune in $O(n\log (n))$ time and thus finding the number of connected components of $\lune(\langle yz \rangle)$ will take $O(n\alpha(n))$ time since in $\mathbb{R}^2$, $\mathrm{DT}(X)$ will have $O(n)$ edges. Thus if $X\subset \mathbb{R}^2$ Step 3 in Section \ref{implementation-details} can be bounded by $O(n\log (n))$. 

The analysis of Steps 3 and 4 are exactly the same as in Proposition \ref{overall-time-complexity}. That is, when $\lune(\langle yz \rangle)$ has one connected component the complexity of Steps 3 and 4 is bounded by $O(\log (n))$ and when $\lune(\langle yz \rangle)$ has more than one connected component then the complexity is bounded above by $O(n^4)$. There will overall, be $O(n^2)$ $1$-simplices to analyse, meaning that there will be $O(n^2-b(X))$ $1$-simplices with no more than one connected component in their lune and $b(X)$ $1$-simplices with more than $1$-connected component in their lune. Thus the overall complexity can be written as $O(n\log (n)(n^2-b(X)) + n^4 b(X))$.
\end{proof}

This is still a significant overestimate since the $n^4$ component of the complexity comes from estimating a need to search the trees $O(n^2)$ times and that each time we find a node with matching lowest 1 we will need to perform a symmetric difference on two sets with $O(n^2)$ elements. Both of these are enormous overestimates since in practice the algorithm will not typically need to search the trees $O(n^2)$ times and the symmetric differences of the column fields will not typically incur a $O(n^2)$ complexity. 

\paragraph{Better bounds for time complexity in $\mathbb{R}^3$ and beyond} Whilst we have not implemented the algorithm in dimensions higher than three, we can bound the worst-case complexity.
For $X \subset \mathbb{R}^D, D \geq 3$ we have a a result that is similar to Proposition \ref{bound-for-point-cloud-in-r2}.

\begin{prop}
For $D\geq 3$ and any finite point cloud $X\subset \R^D$ with $n$ points the overall time complexity of \textsf{EuclideanPH1} can be bounded above by  $O(\alpha(n)n^{2}(n^2-b(X)) +n^4\,b(X))$.
\end{prop}

\begin{proof}
    The analysis is identical to proposition \ref{bound-for-point-cloud-in-r2}. The only difference is that the computation of $\rng(X)$ is bounded by $O(n^3)$ and finding the number of connected components of a lune is bounded by $O(n^2 \alpha (n))$. Thus the overall complexity can be written as 
    $O(\alpha(n)n^2(n^2-b(X)) + n^4 b(X))$
\end{proof}

\section{Experiments}
\label{sec:experiments}

Here we present timing results for computing $\ph{1}(X)$ of various Euclidean point clouds processed using Ripser~\cite{Ripser} and $\mathsf{EuclideanPH1}$.
All results in this section were obtained using a computer with the following specifications. 

\begin{itemize}
            \item AMD Ryzen 5 3400G with integrated Vega 11 graphics

            \item 2 $\times$ 8GB DDR4 RAM

            \item OS: 64bit Ubuntu 22.04.2 LTS 
        \end{itemize}

In some experiments, for the machine used, Ripser was unable to compute $\ph{1}(X)$ for the point clouds listed. This was due to Ripser exhausting the memory of the machine. 

\subsection{ Results for point clouds in $\mathbb{R}^2$}

\subsubsection{Results on points sampled from a uniform random distribution in a square}

For this set of experiments we compare Ripser with $\mathsf{EuclideanPH1}$ on point clouds of size $n = |X|$ ranging from $10^3$ to $10^6$. Each point cloud was generated by identical independent sampling from the uniform distribution over a $10 \times 10$ square. For each point cloud size, we generated five different point clouds and the value of $k$ was set according to Table \ref{k-values-r2-uniform}. Our results are given in Figure~\ref{fig:2dunitsquare}.

% Figure environment removed

\subsubsection{Results for point clouds on a 2D annulus}

For this set of experiments we compare  Ripser with $\mathsf{EuclideanPH1}$ on point clouds $X$ generated on a 2D annulus with inner radius 2 and outer radius 3. 
The point coordinates are generated in polar form $(r,\theta)$ with values of $r$ sampled from a uniform distribution on the interval $[2,3]$ and values of $\theta$ from a uniform distribution on  $[0,2\pi)$. 
Each coordinate is independent of the other.
For each $n = 1000, 2500, 5000, 10000$, we generated five point clouds. 
The value of $k$ was set according to Table \ref{k-values-r2-donut}.
Execution times are plotted in Figure~\ref{fig:2dannulus} along with its corresponding log-log graph in Figure \ref{fig:2dannulus-log}. 

% Figure environment removed


\subsection{Results for point clouds in $\mathbb{R}^3$}

\subsubsection{Results for points uniformly distributed in a cube}

We again compare Ripser with $\mathsf{EuclideanPH1}$ on uniform random points in a $10 \times 10 \times 10$ cubical region of $\R^3$, with the number of points ranging from $10^3$ to $10^6$. As before, we generate five point clouds for each value of $n$. 
The value of $k$ was set according to Table \ref{k-values-r3-uniform}. Our results are presented in Figure~\ref{fig:3dcube}.


% Figure environment removed


\subsubsection{Results for points uniformly distributed in a solid Torus}

In this section we took point clouds $X$ of size $n=1000, 2500, 5000$ and $10000$ from a solid torus with major radius $R=3$ and minor radius $r=1$. The value of $k$ was set as detailed in Table \ref{k-values-r3-donut}. For each value of $n$ we generated five point clouds. 

Cartesian coordinates for a point in the solid torus can be given as
$x = \big( R + r\cos (\theta) \big) \cos(\phi), \,  y= \big(R+r\cos(\theta)\big) \sin (\phi), \, z = r \sin (\theta)$.
For each point cloud, the values of $r$ are taken from a uniform distribution over $[0,1]$, and the values of $\theta$ and $\phi$ are independently sampled  from a uniform distribution over $[0,2\pi)$. An example point cloud with  1000 points is shown in Figure~\ref{thousand-torus}, and execution times of Ripser and $\mathsf{EuclideanPH1}$ are in Figure~\ref{fig:3dtorus} with the corresponding log-log plot in Figure \ref{fig:3dtorus}. 

% Figure environment removed

% Figure environment removed

\subsubsection{Results for the dragon dataset}

In \cite{Ripser}, Ripser's performance was compared with several other programs on various datasets. Several of these comparisons computed higher than degree-1 persistent homology or used datasets which were not point clouds in $\mathbb{R}^2$ or $\mathbb{R}^3$. There was one data set where Ripser was used to compute degree-1 persistent homology and this was the ``dragon" data set \cite{otter2017roadmap}. This data set consists of points in $\mathbb{R}^3$ subsampled from the laser  scan of a dragon in The Stanford 3D Scanning Repository which first appeared in \cite{curless1996volumetric}. For our dragon data sets we first took a random permutation of all the points ($>566K$) in the Standford data set and then formed point clouds of size $ n= 1000, 2000, 3000, ..., 40000$ by using the first $n$ points of this permuted dragon data set. We stopped at $40000$ because the execution time was becoming excessively large but $\mathsf{EuclideanPH1}$ could potentially have been pushed a few thousand points further. 

The 1000- and 10000-point subsamples of the dragon data set are depicted in Figure \ref{dragon-point-cloud} and the execution times of Ripser and EuclideanPH1 are given in Figure \ref{dragon-data}. The corresponding log-log graph is given in Figure \ref{dragon-data-log}. The values of $k$ used for each size point cloud are given in Table \ref{table-of-k-dragon} in section C of the appendix. 

% Figure environment removed

% Figure environment removed

\subsection{Discussion}
\label{discussion-section}
The experiments show that for point clouds within $\mathbb{R}^2$ and $\mathbb{R}^3$ \textsf{EuclideanPH1} certainly shows some promise. Figures \ref{ratio-simplices-r2-uniform}, \ref{ratio-simplices-r3-uniform}, \ref{ratio-simplices-r2-donut}, \ref{ratio-simplices-r3-donut} and \ref{ratio-dragon-simplices} also demonstrate that the number of $2$-simplices used in the calculations of $\ph{1}(X)$ scale similarly to the $1$-simplices. This is in agreement with Theorem \ref{theorem-VR-RVR-isomorphism} which shows that $O(n^2)$ $1$-simplices and $2$-simplices would be used as opposed to $O(n^2)$ $1$-simplices and $O(n^3)$ $2$-simplices that would be used in the standard Vietoris-Rips filtration. In the case of uniform point clouds in $\mathbb{R}^2$ and $\mathbb{R}^3$ \textsf{EuclideanPH1} offers considerable improvement over Ripser. In the case of point clouds on an annulus and on a solid torus \textsf{EuclideanPH1} offers some improvement over Ripser. In this case, for lower sized point clouds the run times of \textsf{EuclideanPH1} don't differ from Ripser that much but for larger point clouds we outperform Ripser simply because we could compute $\ph{1}(X)$ where Ripser could not since it exhausted the memory of the machine. This is also true for the ``dragon" data set, where Ripser outperforms $\mathsf{EuclideanPH1}$ until it can no longer compute $\ph{1}(X)$. 

The values of $k$ were chosen to start at $100$, and were increased if the memory usage was observed to increase significantly in an attempt to conserve memory as discussed in Section \ref{initialize-data-structures}. For the one case (Figure \ref{fig:3dcube}) where $\mathsf{EuclideanPH1}$ could not compute $\ph{1}(X)$ for a point cloud with $10^{6}$ points in $\mathbb{R}^3$, several values of $k$ were tested, but unfortunately $\mathsf{EuclideanPH1}$ could still not compute $\ph{1}(X)$ with the memory of the machine used for these experiments. It should be noted, for the rest of the point clouds with $10^{6}$ points in Figure \ref{fig:3dcube}, nearly all the memory of the machine was used. This suggests that when using $\mathsf{EuclideanPH1}$ to compute $\ph{1}(X)$ for point clouds taken from uniform point distributions on a $10\times 10\times 10$ cube, point clouds of size $10^{6}$ are close to the upper limit of what this machine can compute $\ph{1}(X)$ for. 

We now offer explanations for the trends observed in the results. The results on uniform point clouds in $\mathbb{R}^2$ and $\mathbb{R}^3$ show that execution time seems to scale almost linearly. We can explain this phenomenon by analysing the various parts of the algorithm. 

\subsubsection{Discussion of computing $\rng(X)$ for uniform point clouds}
\label{discussion-of-computing-rng}

For point clouds in $\mathbb{R}^3$ the theoretical worst case complexity for computing the Delaunay triangulation is $O(n^2)$. However, in practice the observed complexity of computing the Delaunay triangulation for a point set in $\mathbb{R}^3$ is $O(n)$ and the triangulation itself has $O(n)$ edges \cite{erickson2001nice}. For point clouds in $\mathbb{R}^2$, as stated in Section \ref{algorithms-and-complexity-analysis} the worst case complexity of computing the Delaunay triangulation is $O(n\log (n))$. Thus in practice, for point clouds in $\mathbb{R}^2$ and $\mathbb{R}^3$ the time complexity of computing the Delaunay triangulation is $O(n\log (n))$. 
The  Delaunay triangulation of points uniformly distributed on a square or cube will generally not contain many ``long" edges. This means that most edges are significantly smaller than the diameter of the space \cite{okabe2009spatial}.  Thus when we compute the lune of each edge of the Delaunay triangulation the complexity of doing so is essentially constant, since each radius search will in practice only come back with at most some bounded number of points. Thus in practice, computing $\rng (X)$ for a point cloud arising from a uniform distribution on a square or cube will have complexity $O(n \log (n))$. 

% Figure environment removed

% Figure environment removed



\subsubsection{Point clouds arising from uniform distributions have small death values}
Point clouds arising from uniform distributions generally give rise to 1-cycles with low death times for larger values of $n$. We can see this in Theorem 6.5 from \cite{kahle2011random}, restated below in our notation. 

\begin{theorem}
\label{mathew-kahle-theorem}
    For a smoothly bounded convex body $K$ in $\mathbb{R}^D$, let $X_{n}$ be a point cloud consisting of $n$ points from the uniform distribution over $K$. Fix $l\geq 0$ then we have $\mathbb{P}(\tilde{H_{l}}(\vr_{r}(X_{n}))=0)\rightarrow 1 $ as $n\rightarrow \infty$ if $r \geq c_{l}(\frac{\log (n)}{n})^{\frac{1}{D}}$. Here, $\tilde{H_{l}}(\vr_{r}(X_n))$ refers to the degree-$l$ reduced homology of $\vr_{r}(X_n)$ and $c_{l}$ is a constant that depends on $l$ and the volume of $K$. 
\end{theorem}

Thus if we have large $n$ then the value of $r$ required to achieve $r \geq c_{l}(\frac{\log (n)}{n})^{\frac{1}{D}}$ will be smaller. Using Theorem \ref{mathew-kahle-theorem} we can then conclude that as $n$ becomes larger, the largest death time for $\ph{1}(X)$, where $X$ is a point cloud generated from the uniform distribution, becomes smaller. Therefore, we need to analyse only a small fraction of the total 1-simplices to obtain $\ph{1}(X)$. To put this into perspective, when computing $\ph{1}(X)$ using $\mathsf{EuclideanPH1}$ for the point clouds of size $10^{6}$ we generally needed to analyse around $3 \times 10^7$ 1-simplices, see Figure \ref{simplices-r2-uniform} and Figure \ref{simplices-r3-uniform}. While this sounds like a lot, the total number of possible 1-simplices for a point cloud of size $10^6$ is approximately $5 \times 10^{11}$. This means we are analysing less than $0.01 \%$ of the total possible one-simplices. From Figure \ref{simplices-r2-uniform} and Figure \ref{simplices-r3-uniform} we can see that the number of 1-simplices used to compute $\ph{1}(X)$ appears to be $O(n)$. 

\subsubsection{Explaining the near linear runtime for point clouds arising from uniform distributions}
Let us analyse the main loop of the algorithm. Each time an edge is added, we first need to calculate its lune. As discussed in Section \ref{discussion-of-computing-rng}, since the point cloud arises from a uniform distribution, the number of points in the lune will typically be low in comparison to the size of the point cloud and can be treated as constant. Since the number of points in the lune is practically constant the complexity of computing the number of connected components will also practically be a constant. In \cite{Ripser}, it is shown that the overwhelming majority of persistence pairs are apparent pairs. In the context of our algorithm this means that the overwhelming majority of 1-simplices will have one connected component in their lune. This can also be seen from Figures \ref{ratio-simplices-r2-uniform} and \ref{ratio-simplices-r3-uniform} by observing that the ratio of $1$-simplices to $2$-simplices is always very close to one, suggesting that the number of $1$-simplices and $2$-simplices used in the filtration is roughly the same. Thus, most of the time we will add a single node to the self balancing binary search tree and this has complexity bounded by $O(\log (n))$. Thus, the bulk of the algorithm will be dominated by performing an operation that takes $\log (n)$ time $O(n)$ times. This is why we see an overall near linear trend in Figures \ref{fig:2dunitsquare} and \ref{fig:3dcube}. 

We now discuss the results of the execution times for computing $\ph{1}(X)$ for the point clouds on an annulus and point clouds on a solid torus. 

\subsubsection{Discussion of computing $\rng(X)$ for Annulus and solid torus point clouds}

In these cases, the discussion about typical run times for Delaunay triangulations still holds, that is, computing $\mathrm{DT}(X)$ in practice has $O(n \log (n))$ complexity. 
The majority of edges in $\mathrm{DT}(X)$ are short compared to the diameter of $X$, so computing the lune of each edge is effectively constant.  It follows that the effective computational complexity of computing $\rng (X)$ is $O(n\log (n))$. 

\subsubsection{Point clouds on the annulus and the solid torus do not have small death values}

Unlike point clouds arising from uniform distributions, the death times for the annulus and solid torus will not all be small. We can see this from the geometry of $\rng(X)$.   
For point clouds on the annulus and solid torus, $\rng (X)$ consists of a large cycle corresponding to the overall loop structure of the point cloud. The scale $r$ for which this cycle dies is significantly larger than all other cycles and as a result we  need to analyse significantly more edges. 
For context, in the case of point clouds on the annulus with $n=10^4$, approximately $2.5\times 10^7$ 1-simplices are analysed when iterating the main loop. For a point cloud of size $10^4$ there are in total about  $5\times 10^7$ edges. This means the algorithm analyses close to $50\%$ of all possible $1$-simplices, a significant increase from the fraction of $0.01 \%$ for the uniform point cloud. See Figure \ref{simplices-r2-donut} and Figure \ref{simplices-r3-donut}.


% Figure environment removed



% Figure environment removed

\subsubsection{Explaining the apparent runtime for point clouds on the annulus and solid torus}

Now let us analyse the ``practical" complexity of the main loop. Once the edge lengths become large enough, finding the lunes has considerably higher complexity. 
Remember that we find the lune of a $1$-simplex by performing a radius search around each of the endpoints of the 1-simplex. 
Since that radius will be the length of the $1$-simplex, it follows that when we analyse $1$-simplices with lengths close to the diameter of the space the search may return $O(n)$ points. 
This means that computing the lune is no longer practically a constant, but $O(n)$. 
Once we have the lune, we need to compute the number of connected components. Since this requires computing the Delaunay triangulation on the points in the lune, this means that we incur a \emph{practical} complexity of $O(n)$.  Computing the number of connected components using a union-find algorithm, also has an effective complexity of $O(n)$. 
Since the self balancing binary search trees will contain up to $O(n^2)$ nodes it follows that inserting a node still has complexity $O(\log(n^2)) = O(\log (n))$. Thus the overall complexity in a single iteration of the main loop is $O(n)$. 
We must analyse $O(n^2)$ edges so the overall practical complexity can be estimated as $O(n^3)$. 
It should be noted that by using the log-log graphs in  Figures \ref{fig:2dannulus-log} and \ref{fig:3dtorus-log} we  observe a the complexities $O(n^{2.73})$ and $O(n^{2.10})$ respectively. This is explained by the fact that the shorter 1-simplices analysed earlier in the algorithm do not have lunes with $O(n)$ points. 

\subsubsection*{Discussion of the results of the dragon data set}

The dragon data set yields some interesting results when the performance of $\mathsf{EuclideanPH1}$ is compared against Ripser. Up until $n=25000$, Ripser outperforms $\mathsf{EuclideanPH1}$. 
For larger point samples, Ripser runs out of memory on the machine used, while 
$\mathsf{EuclideanPH1}$ is able to continue computing $\ph{1}(X)$ for point clouds of size up to $40000$. Looking at Figure \ref{dragon-data}, $\mathsf{EuclideanPH1}$ and Ripser have almost the same run time up to $n=10000$. Then Ripser scales with a slower growth rate when compared to $\mathsf{EuclideanPH1}$. From the log-log graph in Figure \ref{dragon-data-log} Ripser seems to grow with $O(n^{2.51})$ and $\mathsf{EuclideanPH1}$ seems to grow with $O(n^{2.67})$. The ``dragon" data set is a good example of how $\mathsf{EuclideanPH1}$ still has merit even if it runs slower than Ripser for smaller point clouds, since $\mathsf{EuclideanPH1}$ can at least compute $\ph{1}(X)$ for larger point clouds. The number of simplices used for computation is shown in Figure \ref{dragon-simplices}. 

% Figure environment removed





\section{Conclusion and Future Work}

In this paper we have defined the notion of Reduced Vietoris-Rips complexes and filtrations on a point cloud $X$ and have shown in Theorem \ref{theorem-VR-RVR-isomorphism} that they give the same degree-1 persistent homology as the standard Vietoris-Rips filtration. We also provide a higher degree analogue of Theorem \ref{theorem-VR-RVR-isomorphism} in the appendix in the form of Theorem \ref{deg-q-theorem-VR-RVR-isomorphism}. We have also designed and implemented code as the $\mathsf{EuclideanPH1}$ package \cite{EuclideanPH1} which can compute $\ph{1}(X)$ for a point cloud in $\mathbb{R}^2$ and $\mathbb{R}^3$. An output analysis of this code has been presented in Section \ref{sec:experiments} . We have shown that for small to moderate point clouds the runtimes of $\mathsf{EuclideanPH1}$ are similar to that of Ripser. For larger point clouds the lower memory requirements of $\mathsf{EuclideanPH1}$ mean that $\mathsf{EuclideanPH1}$ is able to compute $\ph{1}(X)$ while Ripser is unable to do so due to running out of memory. 

There are several avenues for future work. The first would be producing code which computes $\ph{1}(X)$ for point clouds in $\mathbb{R}^D$ where $D\geq 4$. The main difficulty here is that the Delaunay triangulation is no longer practical to use since the maximal complexity of computing it is bounded below by $O(n^{\lceil \frac{D}{2} \rceil})$ \cite{seidel1995upper}. 
The first place we use the Delaunay triangulation is in building $\rng(X)$, to give us a stopping condition for the algorithm. 
An alternative is for the user to provide an upper limit for $r$. This means sacrificing the certainty of computing the full barcode for $\ph{1}(X)$, or iterating through many long edges unnecessarily (if the given $r$ threshold is large). However, even if one sacrifices computing $\rng(X)$, there is still the issue of computing the connected components of the lune since using the Delaunay triangulation for that will also no longer be practical.  
Potential solutions involve using the algorithm in \cite{supowit_RNG} to compute $\rng (X)$ in $O(n^2)$ time and computing connected components from a minimum spanning tree using the algorithm from  \cite{agarwal1990euclidean} which has complexity $O\left(n^{2-\frac{2}{\lceil \frac{D}{2} \rceil +1} + \epsilon}\right)$. Although the algorithms mentioned have rather favourable theoretical complexity, there are no implementations of these algorithms as far as the authors know. 


Another potential avenue of future work is to develop an algorithm for $\ph{q}(X)$ where $q \geq 2$. It is possible to extend Theorem \ref{theorem-VR-RVR-isomorphism} to higher dimensions, but the benefits diminish as the degree of homology increases. The extension to Theorem \ref{theorem-VR-RVR-isomorphism} is given in Appendix~\ref{appendix-extension}.

This work focuses on point clouds in Euclidean space, so another avenue of future work is to find alternative algorithms for point clouds in non-Euclidean metric spaces.  
Theorem $\ref{theorem-VR-RVR-isomorphism}$ does apply to point clouds in general metric spaces but it may not lead to such significant computational efficiencies without the use of a $kd$-tree. One would need to find some way of finding the lune of each 1-simplex without resorting to testing all points to see if they are in the lune. It might be more fruitful to restrict oneself to a certain class of metric spaces rather than find an algorithm which can be applied to all metric spaces. One such class might be the set of doubling metric spaces. These metric spaces are useful since the number of connected components in a lune is  bounded above. This means that we can still assert that the use of Theorem \ref{theorem-VR-RVR-isomorphism} will reduce the overall number of 2-simplices from $O(n^3)$ to $O(n^2)$. 

\appendix 

\section{Extension into higher degree homologies}
\label{appendix-extension}

In this section we present the higher degree homology equivalent of Theorem \ref{theorem-VR-RVR-isomorphism}. Before we do so, we will need to define the higher degree notions of lunes and Reduced Vietoris-Rips complexes. First we define the notion of a lune for higher degree homology. 

\begin{definition}[Lune]
Consider a point cloud $X$ with its corresponding Vietoris-Rips filtration $\vr _{\bullet}(X)$. Then for a simplex $\sigma = \langle y_0....y_{p}\rangle$ we define $\lune (\sigma)$ in the following fashion. 

\begin{equation}
    \lune (\sigma) = \{x \in X| \langle x,y_0...\hat{y_i}...y_{p} \rangle < \langle y_0...y_{p} \rangle \; \forall i\in \{0,...,p\} \}
\end{equation}

\end{definition}

Here $\hat{y_i}$ denotes the omission of $y_i$ from $\langle xy_{0}...\hat{y_i}...y_p\rangle$. Note that if $p = 1$ the definition reduces to the definition of a lune for an edge. Having defined the lune we define the number of connected components of the lune. 

\begin{definition}[Connected components of a lune]
\label{def-connected-components-of-lune-appendix}
Consider a $q$-simplex $\sigma = \langle y_{0}...y_{q} \rangle$. Consider a graph with vertices consisting of the points in $\lune (\sigma)$. Join two points $p,q \in \lune ( \sigma )$ by an edge if $\langle pq y_{0}...\hat{y}_{i}...\hat{y}_{j}...y_{q} \rangle  < \sigma $ for all $0 \leq i < j \leq q$. Suppose this graph has $c$ connected components, then we say that $\lune (\sigma)$ has $c$ connected components. 
\end{definition}

We will also need a degree-$q$ lune function. 

\begin{definition}[Degree-$q$ lune function]
\label{lune-function-appendix}
    Let $\vr^{q}_{\infty}(X)$ be the set of $q$-simplices in $\vr_{\infty}(X)$. We define a Lune function $L^{q}:\vr^{q}_{\infty}(X)\rightarrow 2^{X}$ as a function that takes a  $q$-simplex $\sigma$, with $c_{\sigma}$ connected components in its lune, to a set $\{x_{1},...,x_{c_{\sigma}}\}$. The points $x_{1},...,x_{c_{\sigma}}$ are chosen from the connected components of $\sigma$, one point from each connect component. 
\end{definition}

We are now ready to define the higher degree analogue to Definition \ref{def-reduced-vietoris-rips-complex}. 

\begin{definition}[Degree-$q$ reduced Vietoris-Rips complex]
\label{deg-q-def-reduced-vietoris-rips-complex}
Consider a finite metric space $(X,d)$. The degree-$q$ Reduced Vietoris-Rips Complex of $X$ with scale $r$, 
denoted $\mathcal{R}^{q}_r(X)$ 
is the simplicial complex which consists of the following:
\end{definition}

\begin{itemize}
    \item All $i$-simplices for $i = 0,...,q$. 

    \item ($q+1$)-simplices are as follows. 
    For each $q$-simplex $\sigma = \langle y_{0}...y_{q} \rangle \in \mathcal{R}^{q}_{r}(X)$ the $(q+1)$-simplices $\langle y_0...y_{q} x\rangle, x\in L^{q}(\sigma)$ are in $\mathcal{R}^{q}_{r}(X)$. 
\end{itemize}

Now we will present the higher degree analogue of Theorem \ref{theorem-VR-RVR-isomorphism}. 

\begin{theorem}
\label{deg-q-theorem-VR-RVR-isomorphism}
Consider a finite metric space $X$.   
Then there exists a family of isomorphisms $\theta_{\bullet}$ such that the following diagram commutes. 

\begin{equation}
\begin{tikzcd}
H_{q}(\rvr^{q}_{r_1}(X)) \arrow[r, "f_{r_1}^{r_2}"] \arrow[d, "\theta_{r_1}"'] & H_{q}(\rvr^{q}_{r_2}(X)) \arrow[d, "\theta_{r_2}"] \\
H_{q}(\vr_{r_1}(X)) \arrow[r, "g_{r_1}^{r_2}"] & H_{q}(\vr_{r_2}(X))
\end{tikzcd}
\end{equation}

for all $r_1$ and $r_2$ such that $0 \leq  r_1 < r_2$.  Above, $f_{r_1}^{r_2}$ and $g_{r_1}^{r_2}$ are the maps at homology level obtained by applying $H_{1}(-)$ to the inclusions $\rvr_{r_1}^{q}(X) \subset \rvr_{r_2}^{q}(X)$ and $\vr_{r_1}(X) \subset \vr_{r_2}(X)$. 

\end{theorem}

\paragraph{The revised proof of Theorem A.5} 

Let $r$ be arbitrary. We first define $\theta_{r}$ and then show it is an isomorphism. Let $\gamma + B_{q}(\rvr_{r}(X))$ be an element in $H_{q}(\rvr_{r}(X))$. Then we define $\theta_{r}$ as follows:

\begin{equation}
\theta_{r}(\gamma + B_{q}(\rvr_{r}^{q}(X))) := \gamma + B_{q}(\vr_{r}(X))
\end{equation}

This mapping is well defined because $B_{q}(\rvr_{r}^{q}(X)) \subset B_{q}(\vr_{r}(X))$.

\begin{lemma}
\label{q-theta-is-surjective}
    $\theta_{r}$ is surjective for all $r \geq 0$. 
\end{lemma}

\begin{proof}
    Let $\gamma + B_{q}(\vr_{r}(X)) \in H_{q}(\vr_{r}(X))$. 
    Since $\gamma \in C_{q}(\vr_{r}(X))$ and all $q$-simplices of $\vr_{r}(X)$ are also in $\rvr_{r}^{q}(X)$, it follows that $\gamma + B_{q}(\rvr_{r}^{q}(X))$ is mapped to $\gamma + B_{q}(\vr_{r}(X))$ by $\theta_{r}$.
\end{proof}

In order to show that $\theta_{r}$ is an isomorphism for all $r$ we neeed to show that $\theta_{r}$ is injective for all $r$. Before we do so, we will need the following preliminary lemmas and new notation. 

\begin{definition}
    Let a point $x$ and let $\sigma$ be the $q$-simplex denoted by $\langle x y_{0}...y_{q} \rangle$. Then we define the $q+1$ simplex $\langle x \sigma \rangle$ as $\langle xy_{0}...y_{q} \rangle$. 
\end{definition}

\begin{lemma}
\label{q-isomorphism-inclusions}
    If $\theta_{s}$ is an isomorphism, then it follows that $B_{q}(\vr_{s}(X)) = B_{q}(\rvr_{s}(X))$. 
\end{lemma}

\begin{proof}
The inclusion $B_{q}(\rvr_{s}^{q}(X)) \subset B_{q}(\vr_{s}^{q}(X))$ follows from the fact that $\rvr_{s}^{q}(X) \subset \vr_{s}^{q}(X)$. To get the reverse inclusion let $\gamma \in B_{q}(\vr_{s}^{q}(X))$. Then we have $\theta_{s}(\gamma + B_{q}(\rvr_{s}^{q}(X))) = \gamma + B_{q}(\vr_{s}^{q}(X)) = 0 + B_{q}(\vr_{s}^{q}(X))$. Since $\theta_{s}$ is an isomorphism it follows that $\gamma \in \rvr_{s}^{q}(X)$. Thus we have the reverse inclusion $B_{q}(\vr_{s}^{q}(X)) \subset B_{q}(\rvr_{s}^{q}(X))$.
\end{proof}



\begin{lemma}
\label{q-first-edge-proof}
    Consider $r$ arbitrary and suppose that $\theta_{s}$ is injective for all $s<r$. Let all the $q$-simplices of diameter $r$ be $\tau_{1}  < \cdots < \tau_{m_r} $. Then $\lune (\tau_{1}) = \emptyset$ and thus

    \begin{equation}
    \label{q-same-edges-equation-1}
         \{ \partial (\langle  x \tau_{1} \rangle)| x\in \lune (\tau_{1}) \} = \emptyset 
    \end{equation}

    and thus we trivially have 

    \begin{equation}
    \label{q-same-edges-equation-1-1}
         \{ \partial (\langle  x \tau_{1} \rangle)| x\in \lune (\tau_{1}) \} \subset B_{q}(\rvr_{r}^{q}(X)).
    \end{equation}

\end{lemma}

\begin{proof}
    Denote $\tau_{1}$ by $\langle y_{01} y_{11} ... y_{q1} \rangle.$ Suppose for contradiction that $\lune (\tau_{1}) \neq \emptyset$. Let $x\in \lune(\tau_{1})$, then by the definition of of $\lune(\tau_{1})$ we must have that $\langle x y_{01} ...\hat{y_{i1}}...y_{q1} \rangle < \tau_{1}$. At least one of these simplices must have diameter $r$, which contradicts the fact that $\tau_{1}$ is the first $q$-simplex with diameter $r$. Thus we must have $\lune(\tau_{1}) = \emptyset$.  
\end{proof}

\begin{lemma}
\label{q-the-big-lemma}
    Consider $r$ arbitrary and suppose that $\theta_{s}$ is injective for all $s<r$. Let $\sigma$ be a $(q+1)$-simplex in $\vr_{r}(X)$ such that $\diam (\sigma) = r$, then we have that $\partial \sigma \in B_{q}(\rvr_{r}^{q}(X))$.
\end{lemma}

\begin{proof}
    First observe that by Lemma \ref{q-theta-is-surjective} that $\theta_s$ is an isomorphism for all $s < r$. This means that $B_{q}(\rvr_{s}^{q}(X)) = B_{q}(\vr_{s}(X))$ by Lemma \ref{q-isomorphism-inclusions}. 
    
    Let all the $q$-simplices of diameter $r$ be $ \tau_{1}  < \cdots <  \tau_{m_{r}} $ and denote $\tau_{k} = \langle y_{0k}....,y_{qk} \rangle$. We wish to show that all $(q+1)$-simplices $\sigma$, with $\diam(\sigma) = r$ are such that $\partial \sigma \in B_{q}(\rvr_{r}^{q}(X))$. This is equivalent to showing that 

    \begin{equation}
    \label{q-same-edges-equation}
         \{ \partial ( \langle  x \tau_{j} \rangle)| x\in \lune (\tau_{j}) \} \subset B_{q}(\rvr_{r}^{q}(X))
    \end{equation}

for $j = 1,...,m_{r}$. We will prove that Equation \ref{q-same-edges-equation} holds for $j = 1,...,m_{r}$ by induction. That is we will show the following:

\begin{itemize}
    \item Equation \ref{q-same-edges-equation} holds for $j=1$. This is just Lemma \ref{q-first-edge-proof}. 

    \item If Equation \ref{q-same-edges-equation} holds for $j=1,...,k$, then it holds for $j = k+1$. 
\end{itemize}



We now show that if Equation \ref{q-same-edges-equation} holds for $j = 1,...,k$, then it holds for $j = k+1$. 

Let $x$ be any point in $\lune (\langle y_{0 (k+1)}...y_{q (k+1)} \rangle)$ and consider the $(q+1)$-simplex $\langle x y_{0(k+1)}...y_{q(k+1)} \rangle$. Let $w$ be the point in the connected component of $\lune (\langle y_{0(k+1)}...y_{q(k+1)} \rangle)$ that $x$ resides in such that $w\in L(\langle y_{0(k+1)}...y_{q(k+1)}\rangle)$. If $x=w$ then there is nothing to prove since $\sigma \in \rvr_{r}(X))$ by definition and thus $\partial \sigma \in B_{1}(\rvr_{r}^{q}(X))$. Otherwise, since $x$ and $w$ are in the same component we know there exists $v_{0},...,v_{q} \in \lune (\langle y_{0(q+1)}...y_{q(k+1)} \rangle)$ such that $x = v_0, v_1, ..., v_q = w$ forms a path such that $\langle v_{i}v_{i+1}y_{0(k+1)}...\hat{y}_{l_1(k+1)}...\hat{y}_{l_2(k+1)}...y_{q} \rangle < \langle y_{0(k+1)}...y_{q(k+1)} \rangle $ for all $0 \leq l_1 < l_2 \leq q$. We know that $\partial (\partial (\langle y_{0(k+1)}...y_{q(k+1)} v_{i}v_{i+1} \rangle )) = 0$ and thus 

\begin{equation}
\label{q-equation-general-proof}
    \partial (\langle y_{0(k+1)}...y_{q(k+1)} v_{i} \rangle ) = \partial (\langle y_{0(k+1)}...y_{q(k+1)} v_{i+1} \rangle) + \sum_{l=0}^{q}\partial (\langle v_{i}v_{i+1}y_{0(k+1)}...\hat{y}_{l(k+1)}...y_{q(k+1)} \rangle)
\end{equation}

We now show that $\partial (\langle v_{i}v_{i+1}y_{0(k+1)}...\hat{y}_{l(k+1)}...y_{q(k+1)} \rangle) \in B_{q}(\rvr_{r}^{q}(X))$ for $l = 0,...,q$ :

\begin{itemize}
    \item $\langle v_{i}v_{i+1}y_{0(k+1)}...\hat{y}_{l_{1}(k+1)}...\hat{y}_{l_{2}(k+2)}...y_{q(k+1)} \rangle < \langle y_{0(k+1)}...y_{q(k+1)} \rangle$ for all $0 \leq l_1 < l_2 \leq q$ from above.

    \item $\langle v_{i} y_{0(k+1)}...\hat{y}_{l(k+1)}...y_{q(k+1)} \rangle < \langle y_{0(k+1)}...y_{q(k+1)} \rangle $ for $l =0,...,q$ since 
    
    \vspace{3pt}
    $v_{i} \in \lune (\langle y_{0(k+1)}...y_{q(k+1)} \rangle)$. 

    \item $\langle v_{i+1} y_{0(k+1)}...\hat{y}_{l(k+1)}...y_{q(k+1)} \rangle < \langle y_{0(k+1)}...y_{q(k+1)} \rangle $ for $l =0,...,q$ since 
    
    \vspace{3pt}
    $v_{i+1} \in \lune (\langle y_{0(k+1)}...y_{q(k+1)} \rangle)$.
    
\end{itemize}

For $l= 0,...,q$, all faces of $\langle v_{i}v_{i+1}y_{0(k+1)}...\hat{y}_{l(k+1)}...y_{q(k+1)} \rangle$ appear in the filtration before $\langle y_{0(k+1)}...y_{q(k+1)} \rangle$. For each $l=0,...,q$ we either have all faces of $\langle v_{i}v_{i+1}y_{0(k+1)}...\hat{y}_{l(k+1)}...y_{q(k+1)} \rangle$ have diameter less than $r$ or at least one of them has diameter $r$. If they all have diameter less than $r$ then $\partial (\langle v_{i}v_{i+1}y_{0(k+1)}...\hat{y}_{l(k+1)}...y_{q(k+1)} \rangle) \in B_{1}(\vr_{s}(X)) = B_{1}(\rvr_{s}(X))$ for $s < r$. If at least one of the faces of $\langle v_{i}v_{i+1}y_{0(k+1)}...\hat{y}_{l(k+1)}...y_{q(k+1)} \rangle$ has diameter $r$ then let $\eta$ be the face with diameter $r$ that appears latest in the filtration. Let $z$ be the point in $\langle v_{i}v_{i+1}y_{0(k+1)}...\hat{y}_{l(k+1)}...y_{q(k+1)} \rangle$ that does not appear in $\eta$, then we have that $z\in \lune(\eta)$. Thus $\partial (\langle v_{i}v_{i+1}y_{0(k+1)}...\hat{y}_{l(k+1)}...y_{q(k+1)} \rangle) = \partial(\langle z \eta)$. Since $\eta$ comes before $\tau_{k+1}$ in the filtration it follows that $\partial (\langle v_{i}v_{i+1}y_{0(k+1)}...\hat{y}_{l(k+1)}...y_{q(k+1)} \rangle) \in \{\partial (\langle x \tau_{j} \rangle) | x \in \lune (\tau_{j})\}$ for some $j = 1,...,k$

Plugging $i = q-1$ into Equation \ref{q-equation-general-proof} we obtain the following.

\begin{equation}
\label{q-equation-general-proof-q-1}
    \partial (\langle y_{0(k+1)}...y_{q(k+1)} v_{q-1} \rangle ) = \partial (\langle y_{0(k+1)}...y_{q(k+1)} v_{q} \rangle) + \sum_{l=0}^{q}\partial (\langle v_{q-1}v_{q}y_{0(k+1)}...\hat{y}_{l(k+1)}...y_{q(k+1)} \rangle)
\end{equation}

We have already shown that summation on the right hand side of Equation \ref{q-equation-general-proof-q-1} are in $\rvr_{r}^{q}(X)$. Remembering that $v_{q} = w$ the first term on the right hand side of Equation \ref{q-equation-general-proof-q-1} is in $B_{q}(\rvr_{r}^{q}(X))$ follows from the fact that $\langle v_{q}\tau_{k+1}\rangle$ is a $(q+1)$-simplex in $\rvr_{r}^{q}(X)$ by the definition of $\rvr_{r}^{q}(X)$. Thus it follows that $\partial (\langle v_{q-1} \tau_{k+1} \rangle) \in B_{1}(\rvr_{r}^{q}(X))$. Using Equation \ref{q-equation-general-proof} repeatedly by letting $i = q-2, q-3, ...,0$ we can subsequently show that $\partial (\langle \tau_{k+1}v_{q-2}),...,\partial(\langle \tau_{k+1}v_{0}\rangle) \in B_{q}(\rvr_{r}^{q}(X))$. Remembering that $v_{0} = x$ we thus have that $\partial (\langle x\tau_{k+1} \rangle)   \in B_{q}(\rvr_{r}^{q}(X))$. 


\end{proof}

We are finally in a position to show that $\theta_{r}$ is injective for all $r \geq 0$. 



\begin{lemma}
    $\theta_{r}$ is injective for all $r\geq 0$.
\end{lemma}
We now show that $\theta_{r}$ is injective for all values of $r$. We will use a proof by induction by inducting on the value of $r$. That is to say, we will prove the following.

\begin{itemize}
    \item $\theta_{0}$ is injective. 

    \item If $\theta_{s}$ is injective for all $s<r$, then $\theta_{r}$ is injective. 
\end{itemize}

Since $H_{q}(\vr_{0}(X))$ and $H_{q}(\rvr_{0}^{q}(X))$ are the zero homology group the injectivity of $\theta_{0}$ is trivial. Now we show that if $\theta_{s}$ is injective for all $s<r$, then $\theta_{r}$ is injective. Suppose that $\theta_{r}(\gamma + B_{q}(\rvr_{r}^{q}(X))) = \gamma + B_{q}(\vr_{r}(X)) = 0 + B_{1}(\vr_{r}(X))$. If we can show that $\gamma \in B_{q}(\rvr_{r}^{q}(X))$ then it would show that $\theta_{r}$ is injective. Since $\gamma + B_{q}(\vr_{r}(X)) = 0 + B_{q}(\vr_{r}(X))$ it follows that $\gamma \in B_{q}(\vr_{r}(X))$. Thus we can write $\gamma = \partial c$ for some $c\in C_{q+1}(\vr_{r}(X))$. Let us write $c = \sum_{i}\sigma_{i}$ where each $\sigma_{i}$ is a $(q+1)$-simplex in $\vr_{r}(X)$. We can write 

\begin{equation}
c = \sum_{\{i |\text{diam}(\sigma_{i}) < r\}} \sigma_{i} + \sum_{\{i |\text{diam}(\sigma_{i}) = r\}} \sigma_{i}
\end{equation}

Letting 

\begin{equation}
\gamma_{<r}  = \partial \left( \sum_{\{i |\diam(\sigma_{i}) < r\}} \sigma_{i} \right)
\end{equation}

and

\begin{equation}
\gamma_{r} = \partial \left(\sum_{\{i |\diam (\sigma_{i}) = r\}} \sigma_{i} \right)
\end{equation}

we then write 

\begin{equation}
\gamma = \gamma_{<r} + \gamma_{r} = \partial \left( \sum_{\{i |\diam(\sigma_{i}) < r\}} \sigma_{i} \right) + \partial \left(\sum_{\{i |\diam (\sigma_{i}) = r\}} \sigma_{i} \right)
\end{equation}

Choose $r^{*} < r$ such that $\gamma_{<r}\in C_{q}(\vr_{r^{*}}(X))$, then it follows that $\gamma_{<r} \in B_{q}(\vr_{r^{*}}(X))$ we have that 

\begin{equation}
\theta_{r^{*}}(\gamma_{<r_1} + B_{q}(\rvr_{r^{*}}^{q}(X))) =\partial \left(\sum_{\{i |\diam (\sigma_{i}) < r\}} \sigma_{i}\right) + B_{q}(\vr_{r^{*}}^{q}(X)) = 0 + B_{q}(\vr_{r^{*}}^{q}(X)).
\end{equation}

Thus we have by the induction hypothesis, that is the assumption that $\theta_{r^{*}}$ is an isomorphism, that it must be that $\gamma_{<r} \in B_{1}(\rvr_{r^{*}}(X))$. Since $r^{*} < r$, we have $B_{q}(\rvr_{r^{*}}^{q}(X) \subset B_{q}(\rvr_{r}^{q}(X))$ and thus $\gamma_{<r} \in B_{1}(\rvr_{r}^{q}(X))$. 

Thus we can assume that $\gamma = \partial (\sum_{i}\sigma_{i})$ where $\diam (\sigma_i) = r$ for all $i$. Since we also have $\gamma = \sum_{i}\partial \sigma_{i}$, we merely need to show that $\partial \sigma_{i} \in B_{q}(\rvr_{r}^{q}(X)$ for each $(q+1)$-simplex in the sum and then we are done. But this is shown in Lemma \ref{q-the-big-lemma}, and so the proof of this Lemma is complete.  

Finally, we show that the diagram in Theorem \ref{theorem-VR-RVR-isomorphism} is commutative to complete the proof of Theorem $\ref{theorem-VR-RVR-isomorphism}$. 

\begin{lemma}
    The diagram in Theorem \ref{theorem-VR-RVR-isomorphism} is commutative.
\end{lemma}

\begin{proof}
    Let $0 < r_1 < r_2$ since the case where $r_1 = 0$ is trivial. Let $\gamma + B_{q}(\rvr_{r_1}(X))$ be an element of $H_{q}(\rvr_{r_1}(X))$. Then $g_{r_1}^{r_2}(\theta_{r_1} (\gamma + B_{q}(\rvr_{r_1}(X))) = g_{r_1}^{r_2}(\gamma + B_{q}(\vr_{r_1}(X))) = \gamma + B_{q}(\vr_{r_2}(X))$ and $\theta_{r_2}(f_{r_1}^{r_2}(\gamma + B_{q}(\rvr_{r_1}(X))) = \theta_{r_2}(\gamma + B_{q}(\rvr_{r_2}(X))) = \gamma + B_{q}(\vr_{r_2}(X))$. Thus commutativity is proven.
\end{proof}

\section{Bounds on the value of $b(X)$}

In this section, we give upper bounds on the value of $b(X)$ for $X$ a Euclidean point cloud. Recall that $b(X)$ refers to the number of bars in $\ph{1}(X)$. The reader is reminded of Lemma \ref{RNG-lemma-3} which says that we can find $b(X)$ by computing $|\rng(X) \setminus \mst(X)|$. We first discuss the case where $X\subset \mathbb{R}^2$. Toussaint showed in \cite{ToussaintRNG} that $\rng(X)$ is a subset of $\mathrm{DT}(X)$, the Delaunay triangulation of $X$. In $\mathbb{R}^2$, the Delaunay triangulation has $O(n)$ edges meaning that we have the following. 

\begin{lemma}
    If $X\subset \mathbb{R}^2$. Then $b(X)$ is bounded above by $O(n)$. 
\end{lemma}

We now analyse the situation if $X\subset \mathbb{R}^D$ with $D\geq 3$. Let $R(D)$ be a set of points in $\mathbb{R}^D$ such that for every point $x$ on the unit sphere $S^{D-1}$ there exists $y\in R(D)$ such that $d(x,y) < \frac{1}{2}$. 
Then Supowit showed in section 7 of \cite{supowit_RNG} the following. 

\begin{theorem}
Let $X \in \mathbb{R}^D$ such that no three points of $X$ form an isosceles triangle. Then $|\rng(X)|$ is bounded above by $O(n|R(D)|)$. 
\end{theorem}

The following lemma is then a simple consequence of Lemma \ref{RNG-lemma-3}. 

\begin{lemma}
    Consider $X\in \mathbb{R}^D$ and suppose no three points in $X$ form an isosceles triangle. Then $b_{d}(X)$ is bounded above by $O(n|R(D)|)$. 
\end{lemma}

Thus one can conclude that for most practical applications, $b(X)$ will be bounded by above by $O(n)$, though there is an implicit dependency on the dimension $D$. If one does not have the assumption that any three points in $X$ do not form an isosceles triangle then $|\rng(X)|$ can be $O(n^2)$ for $D \geq 4$ \cite{Agarwal1992RelativeNG}.  We do however, have a result for $X\subset \mathbb{R}^3$. The following is Theorem 2.4 from \cite{Agarwal1992RelativeNG}. 

\begin{theorem}
    Let $X\subset \mathbb{R}^3$. Then $|\rng(X)|$ is bounded above by $O(n^{\frac{4}{3}})$.
\end{theorem}

This in turn leads to the following lemma. 

\begin{lemma}
    Let $X\subset \mathbb{R}^3$. Then $b(X)$ is bounded above by $O(n^{\frac{4}{3}})$. 
\end{lemma}


\section{Tables}
\label{appendix-table}

\begin{table}
\caption{Values of $k$ used for the dragon data set}
\begin{center}
\begin{tabular}{ |c|c||c|c| } 
 \hline
 $n$ & $k$ & $n$ & $k$\\
 \hline 
 1000 & 100 & 21000 & 1000\\ 
 2000 & 100 & 22000 & 1000\\ 
 3000 & 100 & 23000 & 1000\\
 4000 & 100 & 24000 & 1000\\
 5000 & 100 & 25000 & 1000\\
 6000 & 100 & 26000 & 1000\\
 7000 & 200 & 27000 & 1000\\
 8000 & 200 & 28000 & 1000\\
 9000 & 200 & 29000 & 1000\\
 10000 & 200 & 30000 & 1000\\
 11000 & 500 & 31000 & 1000\\
 12000 & 500 & 32000 & 1500\\
 13000 & 500 & 33000 & 1500\\
 14000 & 500 & 34000 & 2000\\
 15000 & 500 & 35000 & 2000\\
 16000 & 500 & 36000 & 3000\\
 17000 & 500 & 37000 & 3000\\
 18000 & 500 & 38000 & 3000\\
 19000 & 1000 & 39000 & 3000\\
 20000 & 1000 & 40000 & 3000\\
\hline
\end{tabular}
\end{center}
\label{table-of-k-dragon}
\end{table}

\begin{table}
\caption{Values of $k$ used for data sets taken from points uniformly distributed on a $10\times 10$ square in $\mathbb{R}^2$}
    \begin{center}
\begin{tabular}{ |c|c| } 
 \hline
$n$ & $k$ \\ 
\hline
 1000 & 100 \\ 
 10000 & 100 \\ 
 50000 & 100 \\
 100000 & 100 \\
 250000 & 100 \\
 500000 & 100 \\
 1000000 & 300 \\
 \hline
\end{tabular}
\end{center}
\label{k-values-r2-uniform}
\end{table}

\begin{table}
\caption{Values of $k$ used for data sets taken from points on an annulus in $\mathbb{R}^2$}
    \begin{center}
\begin{tabular}{ |c|c|c| } 
 \hline
$n$ & $k$ \\ 
\hline
 1000 & 100 \\ 
 2500 & 100 \\ 
 5000 & 200 \\
 10000 & 1000 \\
 \hline
\end{tabular}
\end{center}
\label{k-values-r2-donut}
\end{table}

\begin{table}
\caption{Values of $k$ used for data sets taken from points uniformly distributed on a $10\times 10\times 10$ cube in $\mathbb{R}^3$}
    \begin{center}
\begin{tabular}{ |c|c| } 
 \hline
$n$ & $k$ \\ 
\hline
 1000 & 100 \\ 
 10000 & 100 \\ 
 50000 & 100 \\
 100000 & 300 \\
 250000 & 1000 \\
 500000 & 1000 \\
 1000000 & 1000 \\
 \hline
\end{tabular}
\end{center}
\label{k-values-r3-uniform}
\end{table}

\begin{table}
\caption{Values of $k$ used for data sets taken from a solid  torus in $\mathbb{R}^3$}
    \begin{center}
\begin{tabular}{ |c|c|c| } 
 \hline
$n$ & $k$ \\ 
\hline
 1000 & 100 \\ 
 2500 & 500 \\ 
 5000 & 1000 \\
 10000 & 1000 \\
 \hline
\end{tabular}
\end{center}
\label{k-values-r3-donut}
\end{table}




\newpage


\bibliography{references}
\bibliographystyle{ieeetr}

\end{document}
