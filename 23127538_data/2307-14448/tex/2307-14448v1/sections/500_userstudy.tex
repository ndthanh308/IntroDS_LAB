\section{Controlled User Experiment}\label{sec:userstudy} 
% \toRtwo{Justifications for experiment choice. E.g., why college application example, rationale behind this selection? Dataset size, task difficulty were representative of what the intended users encounter on a daily basis?}

We designed and conducted a controlled user experiment to evaluate \vispur's ability to support a variety of tasks in face of spurious association and Simpson's paradox. We compared \vispur with a contingency table augmented with bar charts as the baseline (see Table S2 in Supplementary Materials~\ref{sec:appendix}), which is a traditional visualization method that has been widely used in describing Simpson's paradox \cite{lesser200111}. We first describe the within-subject study design and then report the results and discuss our quantitative and qualitative findings.

\subsection{Study Design}\label{sec:userstudy:design}
{\bf Participants and procedure.}
We recruited 21 participants, 10 females, 11 males, in our study. Among them, 19 were self-reported to between 25 and 34 years old, 12 hold a Master's degree, and 7 Bachelor's. The participants have a basic knowledge of statistics and are familiar with topics such as correlation, randomized experiments, as well as linear regression. During a 60-minutes of virtual session, we first gave participants a background and system tutorial (20 minutes). We then allowed participants to explore the system and verbally answer four questions for practice (15 minutes).\footnote{{The practices are designed only to ensure that participants fully understand \vispur's interactive features.}}  Afterwards, each participant was given two task scenarios (described below). As we conducted a within-subject study, each participant used \vispur and baseline tool in a random order, and the two task scenarios are randomly shuffled as well. For each task scenario, participants were asked to answer four questions through Qualtrics platform\footnote{\url{https://www.qualtrics.com/}}. At last, we debriefed the participants to learn about their comments or suggestions.


{\bf Tasks and questions.}\label{sec:userstudy:tasks} \tocomments{Existing works have identified Simpson's paradox in a number of application domains, such as college admission \cite{bickel1975sex}, online education \cite{lerman2018computational}, and employment \cite{lalonde1986evaluating,dehejia2002propensity,dehejia1999causal}. Inspired by those examples, we formulate two task scenarios in similar high-stake social settings}: (1) In a high school, a college application training program was developed to help students in getting admitted into colleges. Participants were asked to explore whether the association between ``taking college application training'' and ``being admitted into colleges'' is spurious. (2) An online course was launched to help students to achieve better grades in an exam. Participants were asked to explore whether the association between ``taking online course'' and ``passing the exam'' is spurious. \tocomments{To ensure that the simulated datasets closely resemble what a domain expert might encounter, we constructed two datasets with 6 features and 1500 data records.} In each task scenario, participants needed to answer 4 questions ({\bf Q1---Q4}) with 15 sub-questions in total, designed based on the proposed four design requirements ({\bf R1---R4}):
\begin{enumerate}
    \item[{\bf Q1.}] Identifying confounders ({\bf R1}).
    \item[{\bf Q2.}] Characterizing subgroup difference ({\bf R2}).
    \item[{\bf Q3.}] Interpreting spurious associations or/and Simpson's paradox ({\bf R3}).
    \item[{\bf Q4.}] Making a final decision in face of spuriousness ({\bf R4}).
\end{enumerate}
For example, to test {\bf Q2} we asked: ``{\it how do you agree with the description that on average students from high education family are more likely to be admitted into colleges than students from low education family?''} Questions are listed in Table S3 and S4, Supplementary Materials~\ref{sec:appendix}. In each sub-problem, participants were asked to select the answers in a Likert scale from 1 (strongly disagree or very unlikely), to 5 (strongly agree or very likely). We measured students' performance in terms of both {\bf accuracy} and {\bf certainty} (to what extent participants were confident about their answers when using a tool to search for answers). For our within-subject study, we conducted a paired Wilcoxon signed-rank test (alternative hypothesis is ``one-sided'') to determine whether there was a significant performance margin between participants using \vispur against using baseline.

% {We measured students' performance in terms of both {\bf accuracy} and {\bf certainty} (to what extent participants were confident about their answers when using a tool to search for answers). To measure {accuracy}, we encoded 5 Likert scores into three labels (positive, negative, unknown). Specifically, the scores 1 (strongly disagree or very unlikely) and 2 (somewhat disagree/unlikely) were labeled as negative, 4 (somewhat agree/likely) and 5 (strongly agree or very likely) as positive, and 3 as unknown. To measure {certainty}, we labeled Likert scores 1,5 as certain, and 2,3,4 as uncertain. We measured {\bf accuracy} as the percentage of correct answers among all the 15 sub-questions, and {\bf certainty} as the percentage of certain answers among all the 15 sub-questions. To examine how \vispur, compared to baseline, could improve participants' performance in different types of tasks ({\bf Q1---Q4}), we also computed question-specific accuracy and certainty. For our within-subject study, we conducted a paired Wilcoxon signed-rank test (alternative hypothesis is ``one-sided'') to determine whether there is a significant performance margin between participants using \vispur against using baseline.}


\input{images/results_caption}
\input{images/Qst_Tool_Agnostic_updated_caption}

\subsection{Results: Accuracy and Certainty}\label{sec:userstudy:results}
{\bf Result 1. Participants obtained a higher accuracy using \vispur than baseline.} {As shown in Fig.~\ref{fig:results}A, the overall accuracy of \vispur (85.0\%, CI: [78.2\%, 89.0\%]) is significantly higher than that of baseline (70.0\%,  CI: [64.2\%, 75.1\%]) ($V=149.4, p < 0.001$).} {The question-wise accuracy values of \vispur are also higher than that of baseline. Particularly, \vispur has a higher accuracy with a significant margin in {\bf Q1}, {\bf Q2}, and {\bf Q4}.}

{\bf Result 2. Participants were more confident in their answers when using \vispur than using baseline.} {Fig.~\ref{fig:results}B shows that the average certainty score for \vispur is 72.3\% (CI: [58.5\%, 83.3\%]), while for baseline it is 53.0\% (CI: [42.5\%, 62.9\%]). A Wilcoxon signed-rank test suggests a significant difference ($V = 126.5, p < 0.01$). Fig.~\ref{fig:results}B demonstrates a decline in participants' certainty while answering questions from {\bf Q1} to {\bf Q4}, but \vispur are more effective than baseline in boosting participants' certainty over all four questions ($p < 0.05$).}

% {In summary, the evaluation results offer evidence that \vispur, compared to the baseline visualization, was more effective in assisting participants in answering four tasks ({\bf Q1---Q4}) in identifying confounders, characterizing subgroup differences, interpreting spurious associations, as well as making good decisions.}


\subsection{Behavioral Patterns and Qualitative Feedback} We also analyzed the behavioral patterns of participants in using two systems, and gathered qualitative feedback (verbal) from them. \tocomments{Our observations suggest several potential findings that indicate how the design of \vispur might have facilitated} a more intuitive, comprehensive, and interactive exploration of spurious associations, as well as a better understanding of the emergence of paradoxical phenomena.


{\bf Finding 1. \tocomments{\vispur has the potential to reduce cognitive burdens for participants by providing clear and straightforward visualizations.}} 
\tocomments{Participants found \vispur to be a ``{\it useful and simple interface system}'' compared to the baseline, as it reduced their cognitive load. Unlike the baseline tables requiring mental computations, over two-thirds of participants reported faster answer retrieval and increased confidence using \vispur. They appreciated how \vispur presented information simply through positions, directions, and sizes.}
% {Many participants agreed that \vispur is a ``useful and simple interface system'' compared to baseline, as it greatly reduced their cognitive burdens. Based on our observation, nearly 100\% participants have done some mental computations given the raw numbers in baseline tables. In contrast, more than two thirds of participants reported that, in \vispur, they were able to find question answers in a much faster way, and they felt much more confident about their answers, e.g., ``{\it \vispur is easy to use because I had to search for where to look at in baseline tables, but \vispur can directly show me what I need through positions, directions, and sizes.}''}

% {``{\it \vispur helps me find information faster}'', ``{\it \vispur saved time for computing by myself, make me more certain when answering a question by seeing the clear visualizations,}''}

{\bf Finding 2. \tocomments{\vispur has the potential to enhance participants' awareness of} confounding bias and subgroup patterns.} 
Participants reflected on the causal relationships among variables while selecting confounders. They actively compared and analyzed the glyphs, circles, and slopes of different subgroups in the \subgroupviewer and examined the flow charts in the \reasoningstoryboard. A participant commented: ``{\it The baseline visualization is not reliable because hidden information might be overlooked in this table,}'' but ``{\it \vispur provides more functionalities and richer analyses}.''
% {When answering {\bf Q1}, most \vispur users explained how they thought of the causal relationships among variables before clicking to select confounders. For {\bf Q2}, participants actively compared the glyphs, circles, slopes of different subgroups in \subgroupviewer, and inspected the flow charts of those subgroups in \reasoningstoryboard. Through interactions and multiple views, they reported to have obtain a richer understanding with respect to distortion factors and subgroup structure. A participant commented: ``{\it The baseline visualization is not reliable because hidden information might be overlooked in this table,}'' but ``{\it \vispur provides more functionalities and richer analyses}.''}

{\bf Finding 3. \tocomments{Participants found the task of making causal decisions ({\bf Q4}) more challenging compared to {\bf Q1, Q2, Q3}.}}
Some participants expressed difficulty in making a decision for {\bf Q4} and selected ``neither agree nor disagree.'' To further investigate this observation, we computed the aggregated performance scores (accuracy and certainty) for all four questions using both \vispur and the baseline. Fig.~\ref{fig:qst_comparison} reveals that the accuracy of {\bf Q4} is significantly lower than that of other questions {\bf Q1---Q3} ($p < 0.001$), and participants' certainty for {\bf Q4} is also significantly lower than that of {\bf Q1, Q2} ($p < 0.05$).

% In our user study, a few participants admitted to us that they were not able to make a decision for {\bf Q4}, so they chose ``neither agree nor disagree.'' To further examine this observation, we computed the aggregated performance score (accuracy and certainty) of four questions by combining the results of both tools (\vispur and baseline). Fig.~\ref{fig:qst_comparison} reveals that the accuracy of {\bf Q4} is significantly lower than that of other questions {\bf Q1---Q3} ($p < 0.001$), and participants' certainty for {\bf Q4} is also significantly lower than that of {\bf Q1, Q2} ($p < 0.05$).

% {However, another participant felt more comfortable when using the cause-effect space rather than flows, as they has been ``extremely familiar'' with the two-dimensional coordinate space through their prior study experience, but the flow-based visualization was ``something new.''}

% {When asked about learning to use \vispur, some participants expressed that the tool was unique, and therefore they needed some time and exercise to get used to it. A participant commented: ``{\it I have never used \vispur but I am quite familiar with baseline table, I could do better if I had more time getting to explore the system.}'' However, those participants also felt that by the end of the study they were proficient in using the tool. As one participant said: ``{\it The system is simple to learn, it is not like you have to take hours or days to master it.}''}

% {Some limitations of the current design were also identified during the study. One participant pointed out that the multiple sets of covariates used in different places, e.g., those shown in confounder table, used in data partition, selected in radar chart and imbalance chart, were somewhat confusing. They were not sure whether it was necessary to select a variable as a confounder prior to using it to do partition. Besides, five participants pointed out that the notion of imbalance is hard to understand, particularly for beginners. The current design of imbalance chart is good at triggering warnings but does not fully explain the definition of imbalance. Furthermore, participants also suggested ideas to make the system more self-contained and generalizable on cloud. For example, to avoid watching long tutorial videos, visual hints of interactions or textual guidelines could be embedded into the system to guide users in self-exploration and data analysis. To apply the system in scenarios where a large number of subgroups are produced, functionalities such as subgroup filtering, zooming in/out could be useful to avoid visualization clustering and heavy information overload. An extended discussion is provided in the next section.}
