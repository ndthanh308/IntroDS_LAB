\section{Methods: Causal Framework, Metrics, Algorithms}\label{sec:methodology}
We present the problem setup, metrics of confounding bias and imbalance, as well as a propensity tree algorithm to discover subgroups.

\subsection{Setup}\label{sec:methodology:diagram}
% {Our study builds upon the causal framework that include mechanisms and assumptions about spurious associations and causal inference. First, the analysis of spurious associations is designed to explore its two mechanisms: i) The divergence of association against causal effect. In theory, a causal effect depicts how outcome may differ under treatment conditions (e.g., treated vs control), where any other ``risk'' factors of outcome are {comparable} between treatment arms. However, in observational studies, this prerequisite is almost never satisfied when studying associations. Taking an aforementioned motivating example as shown in Fig.~\ref{fig:teaser}B, ethnicity is a confounder that not only affects a subject's choice of participation ({\it propensity}), but also plays as a ``risk'' factor that influences a subject's annual income ({\it base effect}). The distortion due to confounders is referred as {\it confounder bias}, where the outcome difference might trace back to ethnicity difference instead of to treatment difference. ii) The mixed effect of {subgroups}. As shown in Fig.~\ref{fig:teaser}B, subgroups might have various patterns in the space of causality, reflected by the three causal arrows ({\it propensity}, {\it base effect}, {\it causal effect}) and an observable cause-outcome association. An overall pattern does not generalize to subgroups.}

\tocomments{Following the potential outcome framework \cite{imbens2010rubin}, we postulate the existence of a pair of potential outcomes for each subject $(Y_i(1), Y_i(0))$, with the individual causal effect defined as $\tau_i=Y_i(1)-Y_i(0)$ and the ATE defined as $\tau = \mathrm{mean}_{i}[Y_i(1)-Y_i(0)]$. Let $X_i$ be the binary indicator for the treatment, with $X_i=0$ indicating that subject $i$ received the control treatment and $X_i=1$ indicating that $i$ received the active treatment. The realized outcome for subject $i$ is the potential outcome corresponding to the treatment received: $Y_i = X_iY_i(1)+(1-X_i)Y_i(0)$. The pair of $(Y_i(1), Y_i(0))$ could never be observed at the same time. Let $\mathbf{Z}_i$ to be the $K$-dimensional vector of covariates, or pretreatment variables, known not to be affected by the treatment.}

\tocomments{For the purpose of illustration, we plot an ``adapted'' directed acyclic graph (DAG) \cite{pearl1995causal} in Fig.~\ref{fig:teaser}B, where vertices represent variables $(X,Y,\mathbf{Z})$, dashed directed arrows represent causal relations, and solid double-ended arrows represent associations. The causal arrow $\mathbf{Z}\rightarrow X$ represents {\bf treatment propensity} \cite{rosenbaum1983central}, indicating the inclination of subjects or a subset defined by $\mathbf{Z}$ to receive a specific treatment. The causal arrow $\mathbf{Z}\rightarrow Y$ represents the {\bf base effect}, capturing subjects' inherent tendency to have a particular outcome without receiving active treatment. The arrow $X\rightarrow Y$ represents the true {\bf causal effect}. The double-ended arrow $X\leftrightarrow Y$ represents the {\bf cause-outcome association}.}

\tocomments{In Fig.~\ref{fig:teaser}B, {\bf confounding bias} means that $\mathbf{Z} \not\!\perp\!\!\!\perp X$ since $\mathbf{Z}$ affects $X$, hence the feature distributions, $\mathbf{Z}|X=0$ and $\mathbf{Z}|X=1$, are not the same ({\bf imbalanced}). Therefore, the outcome difference of two treatment arms might trace back to difference in $\mathbf{Z}$ instead of to $X$. The other mechanism {\bf heterogeneous subgroups} suggests that subgroups hold very distinct {propensity}, {base effect}, {causal effect}, as well as {cause-outcome associations} in the space of causality (e.g., two sets of arrows colored as red and blue). An overall pattern does not generalize to subgroups. }

\tocomments{The problem setup generalizes to a continuous treatment. The potential outcome framework assumes the existence of a set of potential outcomes $Y_i(x), x\in\Omega$, where $\Omega$ denotes the set of all possible values of treatment \cite{austin2019assessing}. Typically, a ``dose-response'' function will be estimated $Y=g_{\theta}(X)$ where $\theta$ depicts causal effect. We fit a regression model to estimate $g_{\theta}$ based on outcome data type, e.g., a linear model for continuous outcomes and a logistic model for binary outcomes.}


% There might exist confounders distorting a cause-outcome relationship. As shown in Fig.~\ref{fig:teaser}B, race is a confounder that not only affects a subject's choice of participation ({\it propensity}), but also plays as a ``risk'' factor that influences a subject's annual income ({\it base effect}). The distortion due to confounders is referred as {confounder bias}, where the outcome difference might trace back to ethinicity, making it questionable to endow association with a causal interpretation. The second reason lies in the mixed effect of {subgroups}. As shown in Fig.~\ref{fig:teaser}B, subgroups might have various patterns in the space of causality, reflected by the three causal arrows (propensity, base effect, causal effect) and an observable cause-outcome association. In the Lalonde example (ref. Section~\ref{sec:introduction}), Black/non-Black individuals showed distinct interests in participating the job training program, as well as different earnings. It is also likely that two subgroups of individuals benefited from the program at different extents. It is problematic to generalize an overall association to any subset of data.}

% Besides, our work maintains several traditional assumptions in causal inference literature \toRone{R1 mentioned that writing is dense and assumes background. Experimental setup should be explained}, including SUTVA \cite{vanderweele2013causal,rubin1980randomization,cole2009consistency}, i.e., subjects are independent and no hidden variations of treatment that might lead to distinct outcomes, unconfoundedness \cite{barnow1980issues,rosenbaum1983central}, i.e., there are no unmeasured confounding variables, as well as the overlap assumption \cite{heckman1997matching}, i.e., any subject should have a non-zero probability of taking the alternative treatment options.

\subsection{Measuring Confounding Bias}\label{sec:methodology:cf_metrics}
% In order to facilitate the identification of confounding variable $Z$, we formulate a quantitative metric called {\bf confounding tendency (CT) score}. Basically, CF compares to what extent the cause-outcome relationship would change before and after controlling for $Z$ \cite{norton2015simpson}. Without loss of generality, we focus on a continuous cause $X$ and a binary outcome $Y$. We fit two logistic regression models: $\mathrm{logit}[p(Y=1)] = \beta_0 + \beta_1 X$, versus, $\mathrm{logit}[p(Y=1)] = \beta_0^\prime + \beta_1^\prime X + \beta_z Z$. Then we compute the change of odds ratio estimate as $\mathrm{CF}({Z}) = |e^{\beta_1^\prime} - e^{\beta_1}| / e^{\beta_1}$ to indicator how strong $Z$ confounds the cause-outcome relationship.

In order to facilitate the identification of a potential \tocomments{confounding variable $Z$ (one dimension from $\mathbf{Z}$), we follow \cite{norton2015simpson} quantitatively compute the extent to which the cause-outcome relationship would change before and after controlling for $Z$, and refer it as {\bf \underline{c}on\underline{f}ounding score} (CF score)}. \tocomments{Suppose the outcome $Y$ is binary, we then fit two logistic regression models: (a) one with just the treatment as a predictor $\mathrm{logit}[p(Y=1)] = \beta_0 + \beta_1 X$, and (b) the other with the potential confounder included as a covariate $\mathrm{logit}[p(Y=1)] = \beta_0^\prime + \beta_1^\prime X + \beta_z Z$.} Then we compute the change of odds ratio \tocomments{for the treatment between the two models} $\mathrm{CF}({Z}) = |e^{\beta_1^\prime} - e^{\beta_1}| / e^{\beta_1}$ to indicate how strong $Z$ confounds the cause-outcome relationship.

\subsection{Measuring Covariate Imbalance}\label{sec:methodology:imbalance}
% The notion of {\bf covariate (im)balance} is proposed to capture how comparable the treated/untreated groups are in terms of other pretreatment variables \cite{belitser2011measuring,austin2015moving,austin2009balance,austin2019assessing}. A high imbalance score given by $Z$ (e.g., age) suggests that the treated/untreated subjects hold very different age distributions, therefore their differences in outcome might be largely explained by the gap in $Z$.

\tocomments{To measure to what extent the $\mathbf{Z}$ are imbalanced, existing works have proposed a range of metrics to measure {\bf covariate (im)balance} \cite{austin2015moving,austin2019assessing}.} A high imbalance score given by $Z$ (e.g., age) suggests that the treated/untreated subjects hold very different age distributions, therefore their differences in outcome might be largely explained by the gap in $Z$. \tocomments{When $X$ is dichotomous, existing works \cite{imai2014covariate,fong2018covariate} have shown that an ideal covariate balance could be operationalized as $\mathrm{E}[f(\mathbf{Z})|X=1]=\mathrm{E}[f(\mathbf{Z})|X=0]$, where $f$ is an arbitrary vector-valued measurable function whose expectation exists. When $X$ is continuous, the ideal balance can be operationalized as $\mathrm{E}[\mathbf{Z}]\mathrm{E}[X]=0$ \cite{fong2018covariate}. For practical computation, when $X$ is binary we use the standardized mean difference proposed in \cite{austin2015moving} to measure imbalance:} $d = {(\bar{Z}_1 - \bar{Z}_0}) / {\sqrt{0.5(s_1^2 + s_0^2)}}$, where $\bar{Z}_1, \bar{Z}_0$ are covariate means for $X=1$ and $X=0$, $s_1^2, s_0^2$ are their variances accordingly. When $X$ is continuous, we use correlation-based metrics proposed in \cite{fong2018covariate}, $d = \mathrm{Spearman}(Z,X)$, to measure the per-feature imbalance.


\subsection{Algorithm for Subgroup Discovery}\label{sec:methodology:algorithm}
Our visual analytic system incorporates ML methods to automatically discover subgroups to be shown on the visualization interfaces. Several existing works have used tree-based methods for searching and estimating subgroup-level treatment effects \cite{athey2016recursive,wager2018estimation}. These methods start by recursively splitting the feature space until they have partitioned data into a set of leaves (subgroups) $\mathcal{L}$, each of which, $l \in \mathcal{L}$, contains a subset of data points. One might consider that the data points belonging to the same leaf, $i \in l$, act as if they had come from a randomized experiment. Then a leaf-specific effect size $\tau(l)$ is computed by comparing the difference of outcomes $\tau(l) = \bar{Y}_{l,1}-\bar{Y}_{l,0}$, or learning a dose-response relation $Y_{l}=g_{\theta}(X_{l})$. \tocomments{Suppose $g_{\theta}$ takes a logistic regression form $g_{\theta}(X_{l}) = 1/(1+e^{-(\beta_0(l) + \beta_1(l)X_{l})})$, the coefficient $\beta_1(l)$ could be used to represent the effect size $\tau(l)$ for the leaf $l$.} \vispur exploits the state-of-the-art subgroup partition algorithm: propensity tree \cite{wager2018estimation,athey2016recursive}. It combines decision tree techniques with propensity scores in causal inference. It partitions data based on features $\mathbf{Z}$ while using $X$ as the target to ensure a balanced distribution of treated and control units within each subgroup. This approach helps address confounding and enables reliable estimation of causal effects within specific subgroups. It is different from decision tree in a way that an estimated effect size is attached to each of the leaves rather than predicted values of treatment. We adopt the propensity tree algorithm because: (i) It is particularly useful in observational studies, where we want to minimize confounding bias due to variance in treatment propensity; (ii) It is able to handle a large size of features by automatically selecting the most ``important'' features to split on.
