\section{Design Requirements and Tasks}\label{sec:designguideline}

% In this section, we highlight challenges in reasoning about spurious associations and present design guidelines for building an analytic tool.
\tocomments{{\bf Target Users and Interviews.} Our target users are data practitioners, specifically those who are not experts in the field of causality. They may need to explore causal questions or provide empirical evidence to decision makers. For instance, one of our domain experts sought to understand the extent to which their educational system improved students' programming skills. While they may not possess causality knowledge or use causal inference tools, they should have a basic understanding of statistics and apply statistical techniques (such as tests, associations, and regression analysis) in their daily jobs. To ensure our system meets their needs, we interviewed three expert users from diverse backgrounds, including a social worker ({\bf P1}), a trading analyst ({\bf P2}), and an educational system designer ({\bf P3}).}
% {Through interviews, we identified four major challenges (prefixed with {\bf C}), each raised by at least two persons ({\bf P}). To tackle those challenges, we derived four design requirements ({\bf R}) and corresponding design tasks ({\bf T}).}
% {In this section, we highlight challenges in reasoning about spurious associations and present design guidelines for building an analytic tool. It has been pointed out \cite{pearl2014comment} that human intuition tends to attribute causal interpretation to statistical associations, yet there has been efforts in integrating causality theory into empirical data analysis pipelines. To better understand the practical obstacles and needs of data analysts and domain experts investigating causal relationships, we interviewed three expert users from diverse backgrounds. Based on their feedback, we identified four major challenges (prefixed with {\bf C}), each raised by at least two interviewed persons ({\bf P}). To tackle those challenges, we derived four design requirements ({\bf R}) and corresponding design tasks ({\bf T}).}
% {In this section, we identify and summarize several challenges in inspecting and reasoning about spurious associations in practical data analysis task. It has been pointed out that human intuition is governed by causal calculus, and human has a persistent tendency to attribute causal interpretation to statistical associations \cite{pearl2014comment}. However, little effort has been made to investigate how to integrate causality theory into an empirical data analysis pipeline. To bridge the gap and to formulate the design guidelines for building an analytic tool, we interview expert users with different backgrounds to understand their practical obstacles and needs. Specifically, we assume this tool will be used by data analysts and domain experts who would like to investigate the casual relationships in a dataset. By compiling interviewees' feedbacks, we discovered four major challenges (indicated by the prefix {\bf C}), each of which was raised by at least two interviewed persons ({\bf P}). Driven by those challenges, we derived our design requirements ({\bf R}) which consists of five specific design tasks ({\bf T}).}
% \input{tables/interviews.tex}
% In this section, we propose a set of design requirements of analyzing associations between an independent factor and a dependent factor based on observational data for the purposes of data-driven decision making. We collect the feedback and thoughts from potential users in using existing tools. We assume that such tools will be used by data analysts and domain experts who conduct association analysis in different domains. We conduct an interview study with three potential users, identify the limitations of their practical workflows, and collect their design needs. Based on the findings of the pilot study, our design guideline, which consists of four design requirements and six specific tasks, was formulated by compiling common aspects across the interviewees' comments.
Each section lasted about an hour in the form of a semi-structured interview. {To understand the interviewees' knowledge/experience of statistics and causality, as well as their obstacles in addressing counterintuitive associations and/or paradox phenomenon, we engaged them to} consider a task where they perform association analysis using empirical data. We encouraged them to apply their current practices/tools, and reflect on the limitations of those methods and expectations for future systems.  More details of interviews are provided in Supplementary Materials~\ref{sec:appendix}.
% {\begin{itemize}
%     \item {\bf Expertise.} What is your expertise? What do you think about your expertise level in statistics, causality, and visualization?
%     \item {\bf Awareness of Simpson's paradox.} Are you familiar with Simpson's paradox? Can you give a brief description about this phenomenon? Can you describe 1-2 scenarios of Simpson's paradox, or/and counterintuitive associations you have encountered in your work? Can you explain why they occur in your data? What are the reasons?
%     \item {\bf Workflow.} What are the typical practices and tools, such as statistical tests, analytic tools, algorithms, models, visualizations, interactive analytic systems, you apply to tackle this phenomenon?
%     \item {\bf Challenges.} How do the existing practices/tools fail to meet all your needs? What are your expectations for a novel system that aims to tackle the issue of Simpson's paradox or counterintutive associations?
% \end{itemize}}
% {While interviewees reported a set of goals, typical practices, challenges/limitations in their own context of association and causal analysis, we were able to find that they had experienced similar difficulties in their goals and tasks.}
% {By exploring observational data, interviewees hope to understand how and to what extent a cause variable (e.g., usage of educational system) influences an outcome of interest (e.g., students' performance).}
% {However, the interviewees currently apply association analysis methods (e.g., statistical test, regression models) using R or Python libraries to capture their relationship, which cannot be used to claim strong causal conclusion.}
% {The tools they currently used in their workflow, such as R, Python, SPSS, are good at outputting coefficients, p-values, or statistical test results, but do not fully support subgroup analysis as well as the interpretation of Simpson's paradox.}
% {Finally, all of our interviewees expressed the desire for a user-friendly and interactive tool, embedded with intuitive visualization, to assist their empirical data analysis, as well as result communication and delivery.}

{\bf Common Challenges.} Expressed by interviewees, they all have encountered counterintuitive or paradoxical associations in different studies. 
\tocomments{For example, the educational system designer {\bf P3} reported an {\it unexpected} association -- the more engaged students have been, the worse their performance were in skill evaluation.}
% For example, {\bf P3} reported an {\it unexpected} association from their education data, showing that the more code samples students have studied, the worse their performance were in skill evaluation.
However, the current common strategies (e.g., statistical tests, regressions using R, Python libraries) fail to detect spurious associations or help understand the reasons why paradoxical/spurious associations emerge. The identified four major challenges are (see Table S1 in Supplementary Materials~\ref{sec:appendix} for more details):
\begin{enumerate}
    \item[\conebox{\bf C1.}] {\bf Unable to \underline{identify} possible covariates that might distort a cause-outcome relationship} (mentioned by {\bf P1, P2}). Interviewees have admitted that their current strategies were arbitrary in choosing the covariates to adjust/control in data analysis (e.g., regression). There is no or little reflection of causal relationships among a rich set of variables in their current workflow.
    \item[\ctwobox{\bf C2.}] {\bf Unable to \underline{detect} subgroups and \underline{examine} their characteristics in face of a rich set of variables} (mentioned by {\bf P1, P2, P3}). 
    Our interviewees attempted to conduct subgroup analysis to reveal data heterogeneity. For instance, {\bf P2} hypothesized that different students might engage with the educational system differently, thereafter their skill could be affected by the system at distinct extents. But no tools could help test this hypothesis. They choose either not to execute subgroup analysis, or to rely on prior experiences for manual partition. Systematic and automatic methods to discover subgroups are still lacking.
    \item[\cthreebox{\bf C3.}] {\bf Unable to \underline{interpret} the changes of associations, the counterintuitive associations, as well as the emergence of a Simpson's paradox, given different data partition or regression scenarios} (mentioned by {\bf P2, P3}). Interviewees acknowledged that ``associations do not necessarily imply causation,'' but they were still bringing causal explanations to make sense of the derived coefficients (and $p-$values). If an association went against their causal expectation, they would feel confused. They often got further confused by inconsistent coefficients obtained from multiple trials of testing different possible regression models with distinct subsets of data.
    \item[\cfourbox{\bf C4.}] \tocomments{\bf Unable to \underline{make} a confident decision because a given association (even obtained from a subset of data) may be distorted and contain mixed subgroups.} (mentioned by {\bf P1-P3}).
    % {\bf Hard to \underline{make} a confident decision, given inconsistent, paradoxical, and counterintuitive associations} (mentioned by {\bf P1, P2}).
    When drawing a conclusion, such as whether or not the designed educational system is beneficial for students, \tocomments{{\bf P3} admitted they cannot confidently make a claim regarding their system's effectiveness, ``{\it it is hard to trust any associations, even after dividing data into subsets.}''}
\end{enumerate}
\tocomments{In summary, {\bf C1-C2} are concerned with the challenges of identifying and discovering confounding bias and heterogeneous subgroups from data, whereas {\bf C3-C4} are concerned with how to interpret and make informed decisions for a given use scenario. The challenges thus result in different design requirements.}
% \tocomments{To summarize, {\bf C1-C2} care about {\it identification} and {\it discovery} of confounding bias and heterogeneous effects, whereas {\bf C3-C4} focus on {\it understanding} and {\it decision-making} (or {\it drawing conclusions}).}
%  {In other words, the first two are about taking a deeper data analysis, and the latter are about taking actions after obtaining good understanding.}
% The above four challenges are closely related to the three undesirable consequences regarding equity, fairness, and efficacy. Without addressing {\bf C1}, data analysts may render a misleading, spurious association as causal interpretation, and make countereffective decisions (i.e., efficacy). Take {\bf P3}'s scenario as an instance, it is unwise to decide that the developed educational system in JAVA programming class has weakened students' performance, simply based on the counterintuitve ``more-engagement-worse-performance'' association. Besides, without addressing {\bf C2}, unfairness might remain to exist without early detection and rectification. Take {\bf P1}'s scenario as an example, the problem how crime severity impact sentence across different subpopulations holds significant justice implications for our society. Take {\bf P3}'s scenario as an example, addressing {\bf C2} -- subgroup analysis -- could help developers understand to what extent different student groups engage with the system (equity). Addressing challenges {\bf C3, C4} are critical because data practitioners -- those hold a certain level of power in making the final decisions -- should have a deep understanding of spurious association, such as why it emerges, whether or not to trust a association, so as to make reliable and responsible decisions.

{\bf Design Requirements} \label{sec:designguideline:requirement}
To solve the above challenges ({\bf C}), we identified four major requirements ({\bf R}), with five specific design tasks ({\bf T}).
\begin{enumerate}
    \item[{\bf R1.}] {\bf Facilitate identification of confounders (motivated by \conebox{\bf C1}).}
    {\bf (T1)} As a cause-outcome relationship might be spurious when additional confounders are involved (Fig.~\ref{fig:teaser}B), a visual analytic tool should guide users in reflecting causal relationships among variables, i.e., which covariates might simultaneously affect the preference for treatment and for outcome. It should also provide quantitative measurements and intuitive visualizations for human users to locate the most likely confounders.
    \item[{\bf R2.}] {\bf Support the discovery, characterization and examination of subgroup heterogeneity (motivated by \ctwobox{\bf C2}).}
    
    {\bf (T2)} The system should facilitate both manual (hypothesis-driven) and automatic (data-driven) subgroup discovery. Users should be able to define subgroups manually using one or multiple covariates. It should also incorporate algorithms to automatically search for subgroups that are internally homogeneous but differ from each other.
    
    {\bf (T3)} The system should enable users to examine the heterogeneity of subgroups from a variety of aspects, such as feature properties, to what extent a subgroup is likely to take certain treatment actions ({\it propensity}), to what extent a subgroup is to take certain outcome scenarios ({\it base effect}), what are the subgroup-level {\it associations}, whether they are distorted because of nested confounding bias ({\it causal effect}).
    
    \item[{\bf R3.}] {\bf Enable the interpretation of a spurious association and/or Simpson's paradox (motivated by \cthreebox{\bf C3}).}
    
    {\bf (T4)} The visual analytic system should enable users to understand why the aggregation of subgroups with different characteristics could lead to a paradoxical phenomenon. \tocomments{In particular, the two causal mechanisms -- confounding bias, and subgroup heterogeneity -- should be explained in a clear and intuitive way.}
    
    \item[{\bf R4.}] \tocomments{\bf Facilitate ``spuriousness'' diagnosis for any given association as well as accountable decision-making (motivated by \cfourbox{\bf C4}).}
    
    {\bf (T5)} The system should enable users to make adequate judgements regarding whether a chosen association is spurious or not. It should also provide quantitative information and visual encodings to assist users in making accountable decisions about how the cause might influence the target outcome, overall or given a certain subgroup.
\end{enumerate}