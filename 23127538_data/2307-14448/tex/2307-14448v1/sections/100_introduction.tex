% {Decision making in a diversity of domains usually involves estimates of causal impacts to answer a what-if question about shift in policy, such as changes in product pricing for business or new treatments for health professionals. Big data and machine learning tools have jointly powered humans in making data-driven decisions. However, most common data practices and ML methods are designed to capture associations from real data, but cannot be used to estimate the unobservable causal impacts in a counterfactual world. Empirical associations could be {\it spurious} in many ways: it might simply reflect underlying societal inequalities \cite{park2021comparison}, an overall trend might mask subgroup heterogeneity \cite{von2021simpson}, or paradoxical/conflicting associations -- Simpson's paradox -- cause confusion and difficulty in decision-making \cite{lerman2018computational,kievit2013simpson}. The lack of causal insights in association analysis has raised many societal and public health risk regarding {efficacy} \cite{erica2021nearly,jeffrey2021israeli}, {equity} \cite{obermeyer2019dissecting,park2021comparison} and {fairness} \cite{verma2022impacts,cookson2021equity}. \rvtwo{To illustrate this viewpoint, consider an example of social inequality, illustrated in Fig.~\ref{fig:teaser}A, data adapted from \cite{lalonde1986evaluating}, that concerns whether a government-funded training program is effective in helping people earning more money. Overall, data shows people who have participated in the program make surprisingly less money than those who have. Although counterintutive, it makes the government consider terminating this program. However, when the data is divided into two subgroups based on race (black/non-black), Simpson's paradox emerges: participants make more money than non-participants in both subgroups. The hidden fact behind this spurious association is that, black workers -- those who were also likely to be low-income citizens -- were more willing than non-black people to participate in this program. Terminating the program based on the spurious overall trend could further entrench social inequality.}}
\section{Introduction}\label{sec:introduction}
{Decision-making processes in a variety of domains concern estimates of causal impacts of a shift in policy via what-if question, such as changes in product pricing for business or new treatments for health professionals \cite{cookson2021equity,kievit2013simpson}.}
{Despite the ample capability of big data and machine learning tools available for data-driven decisions, many data analysis practices and ML methods often pick up on {\it spurious associations} (referred as ``shortcuts'' in ML models) instead of learning the true {\it causal relationships} \cite{degrave2021ai,joshi2022all,park2021comparison}.}
{The lack of causal insights in empirical association analysis can cause confusion and difficulty in decision-making process \cite{lerman2018computational,kievit2013simpson}, and even pose a risk on societal efficacy \cite{jeffrey2021israeli}, equity \cite{obermeyer2019dissecting,park2021comparison}, and fairness \cite{lerman2018computational,cookson2021equity}.}
% an overall association might mask heterogeneous patterns among subgroups \cite{von2021simpson}, and paradoxical/conflicting associations (e.g., Simpson's paradox) might cause confusion and difficulty in decision-making \cite{lerman2018computational,kievit2013simpson}.}
% it might reflect social disparity in accessing health resources \cite{park2021comparison},
% {The lack of causal insights in association analysis would raise societal and public health risk regarding {efficacy} \cite{erica2021nearly,jeffrey2021israeli}, {equity} \cite{obermeyer2019dissecting,park2021comparison} and {fairness} \cite{verma2022impacts,cookson2021equity}.}

% about the Lalonde data
% The National Supported Work (NSW) Demonstration was a federally-funded program implemented in the mid-1970s, with the objective of providing work experience for a period of 12 to 18 months to individuals who had faced economic and social problems prior to enrollment in the program.
% The National Supported Work Demon- stration (NSW) was a temporary employment program designed to help disad- vantaged workers lacking basic job skills move into the labor market by giving them work experience and counseling in a sheltered environment.

{\bf Motivating Example.} To illustrate this issue, consider an example of an educational dataset\footnote{The Lalonde dataset (1986) \cite{lalonde1986evaluating,dehejia2002propensity,dehejia1999causal} is from the National Supported Work Demonstration, concerning a government-funded job training program that aimed at help citizens to increase their earnings. More information can be seen at \url{https://users.nber.org/~rdehejia/nswdata2.html}.}, illustrated in Fig.~\ref{fig:teaser}A, which concerns whether a government-funded training program is effective in helping individuals earn more money  \cite{lalonde1986evaluating,dehejia2002propensity,dehejia1999causal}. 
{In the data, program participants earn less money than non-participants, which may raise doubts about the program's effectiveness and lead to its termination. However, a closer look reveals Simpson's paradox when considering ethnicity. When looking at Black and non-Black subgroups separately, program participants actually earn more than non-participants. This paradox arises probably because Black participants face greater disadvantages, leading to lower earnings but a higher participation rate driven by their need for financial improvement. Combining the subgroups creates an overall negative trend due to participants' lower earnings. This example highlights the importance of investigating the spurious program-earning association and avoiding hasty program termination that could further disadvantage already marginalized groups.}
% {According to the data, it appears that individuals who participate in the program actually earn less money than those who do not. This finding is somewhat counterintuitive and may lead some to question the effectiveness of the program. As a result, the government may consider terminating the program. However, when the data is divided into two subgroups based on ethnicity (Black/non-Black), Simpson's paradox emerges: program participants make more money than non-participants in both subgroups. The reasons for this paradox phenomenon is that, Black individuals who participate in the program are more disadvantaged than non-Black individuals who participate, and this disadvantage is associated with lower earnings yet a higher participation rate, possibly due to their stronger needs to improve financial status. When putting two subgroups together, it leads to an overall negative trend as individuals who need the training are those who earn less money. This example suggests that, without a careful investigation of the overall ``spurious'' program-earning association, making a decision of terminating the program could further deprive resource from already disadvantaged groups.}


% {High-stake examples include (a) questioning COVID-19 vaccination effectiveness by quoting the data that a large proportion of hospitalized patients were fully vaccinated \cite{erica2021nearly,jeffrey2021israeli}, (b) a widely used algorithm favors White patients over Black patients, as it was trained to predict health care costs -- a reflection of unequal access to care -- rather than illness \cite{obermeyer2019dissecting,park2021comparison}, (c) mainstream health services research tends to prioritise average effectiveness but providing little or no information about how impacts are distributed, i.e. who benefits most and who bears the largest burdens \cite{verma2022impacts,cookson2021equity}.}

% {Unfortunately, many data analysts, decision makers, and even researchers, might intentionally or unintentionally render an association a causal interpretation and make undesirable decisions.}

{Like this example, many spurious (possibly paradoxical) associations are hard for humans to analyze and reason about. In recent years, causal machine learning has made progress in estimate individualized and subgroup-level causal responses (e.g., Black/non-Black) by incorporating ML models into causal framework \cite{athey2019generalized,kunzel2019metalearners,oprescu2019orthogonal,syrgkanis2019machine}
% \cite{wager2018estimation,athey2019generalized,kunzel2019metalearners,mackey2018orthogonal,oprescu2019orthogonal,syrgkanis2019machine}
{However, these methods tend to have strong structural assumptions imposed on data generation process, which poses a challenge for decision-makers and data practitioners to choose the best model as well as to make a valid judgement on the estimated results.} 
{Besides, these models encapsulate causal computations into a black box without an explanation on how covariates influence treatment or how treatment/covariates affect outcome, thus providing little insights on  subgroups that may have conflicting associations.}
{Recent visual analytic systems have been developed to promote interpretability for causal analysis on multidimensional data \cite{jin2020visual,xie2020visual,xie2020causalflow}. But they neither detect spurious associations, nor explain -- for a target causal relation -- what are the causal reasons behind paradoxical associations among subgroups.}}
% neither rigorously inspect or explain spuriousness under a causal framework, nor reveal varied subgroup behaviors in the space of causal space.}}

% {To tackle this problem, there have been two lines of works: (1) visualization interfaces for causal or/and subgroup analysis, (2) causal machine learning.}
% {The first category of works develop visual interfaces to let users explore causal relationships, clusters, or model behaviors over subsets of data. But they neither specify a formal causal model to locate and explain spurious associations, nor investigate subgroup characteristics in the space of causality.} 
% {The second category is method-oriented. They incorporate ML models into causal framework to estimate individualized (or conditional) causal responses from data. Such algorithms encapsulates causal computations into a black box, making it for humans to fully understand and trust the results.}
% {Overall, existing works provide little insight to identify a spurious association (depends on humans to locate through domain knowledge), reveal/interpret the causal root of its emergence, and they do not investigate subgroup characteristics in the scope of causality.}

{% a summary of task
Given the profound impact of spurious association and the  research gap, we propose a systematic causal analysis of spurious associations on the basis of a formal causal model \cite{imbens2010rubin} by developing an interactive visual system.}
{% a high-level summary of our work
By allowing users to see contrastive patterns -- features or causality-related behaviors -- between treatment arms and among different subgroups of data, the workflow guides practitioners to detect, reason about causal sources of a spurious association, and to overcome common pitfalls in data-driven decision-making.}
{% Specifically, the causal diagram depicts ...
Specifically, we focus on two causal mechanisms: {\bf confounding bias} and {\bf subgroup heterogeneity}, as they widely exist in observational studies \cite{lerman2018computational,kievit2013simpson} and have significant decision implications (e.g., the job training program example). As shown in Fig.~\ref{fig:teaser}B, confounding bias indicates the distortion effect from confounding variables (e.g., ethnicity) that might simultaneously affect cause and outcome. Subgroup heterogeneity refers to subgroup patterns in the space of causality including the {\it propensity} towards treatment \cite{rosenbaum1983central}, {\it base effect} towards outcome, along with subgroup-level {\it causal effects}.}
To transform causal theory into practical use, we interview three domain experts, including an educational system designer, a social worker, and a financial data scientist to identify a set of design requirements that existing tools/practices fail to support. We further propose a ``de-paradox'' workflow with four major components shown in Fig.~\ref{fig:teaser}C. 
The workflow allows users to identify possible confounding factors (Fig.~\ref{fig:teaser}C.1), compare subgroup patterns (Fig.~\ref{fig:teaser}C.2), hypothesize and reason about paradoxical phenomena (Fig.~\ref{fig:teaser}C.3), and perform responsible decision-making such as whether to impose a treatment or not (Fig.~\ref{fig:teaser}C.4).

%These include (C.1) a \confounderdashboard, which can automatically identify possible confounding factors involved in a cause-outcome relationship, and (C.2) a \subgroupviewer, which allows for the visualization and comparison of diverse subgroup patterns in both attribute and causality space (e.g., propensity, base effects, etc). Additionally, we have designed (C.3) a flow-based \reasoningstoryboard, by illustrating the pathways from treatments to outcome to allow human users to hypothesize and reason about paradoxical phenomena, as well as (C.4) an interactive \decisiondiagnosis panel that helps ensure responsible decision-making such as whether to impose a treatment or not.}

{% VISPUR
To facilitate such a workflow, we develop \vispur\footnote{The code is available at: \url{https://github.com/picsolab/VISPUR}}, \textbf{\underline{vis}}ualizing s\textbf{\underline{pur}}ious associations, a visual analytic system to enable causal analysis of spurious associations. The system incorporates a suite of statistical techniques, algorithms, and visual components to help identify causal roots of spurious associations, as well as modules to reason about association reversal/paradox and to make informed decisions. To summarize, our contributions include:
}
% {How can analytic tools facilitate causal analysis in terms of spurious associations for the purpose of reliable data-driven decision-making? We address this larger question by answering two sub-questions: (1) What causal models and concepts are needed to tackle the phenomenon of association spuriousness? (2) What are the design requirements for developing a practical visual tool? Relying on a formal causal model \cite{rubin1980randomization}, we first identified two major causal mechanisms that cause association spuriousness, i.e., confounding bias and heterogeneous casual effects. We next interviewed real-world domain experts, including an educational system designer, a social worker, and a financial data scientist to identify a set of design guidelines for causal analysis of spurious associations.}

%  By investigating empirical associations in the framework of causality, our system could answer many spuriousness-related questions, e.g., whether an association of interest is spurious or not, how it is demonstrated across a diversity of subgroups, what confounders could be distorting the association, as well as how to make decisions given such an empirical association?

% {Taking Fig. 1(a) as an example, suppose a data analyst is studying whether a newly developed feature in an online product helps improve user satisfaction. Data shows that 68\% of users who have used this feature (i.e., the treated) are satisfied, but the satisfaction rate is only 38\% among those who didn't (i.e., the untreated). The data analyst might wonder: {\it Is the positive association spurious, what other factors might distort the association?} The first step of our system framework is to identify such factors, the so-called {\it confonders}, that might simultaneously influence both treatment and outcome, and cause the observed cause-outcome relationship deviating from true causality. As an aggregated association might mask local patterns, the data analyst might also ask: {\it Does the association remain consistent over subsets of users?} Our system facilitates flexible data partition and compares subgroup patterns in the space of causality. It displays rich information including which subgroups like to use the feature (i.e., propensity) and which ones tend to be satisfied (i.e., base effect), as well as how subgroup-level associations differ from each other, see Fig.~\ref{fig:teaser}(b). As shown in Fig.~\ref{fig:teaser}(a), an simple disaggregation based on education reveals two conflicting effects: educated group displays an increase in satisfaction rate, whereas less-educated group a decline. At this point, the data analyst might ask: {\it Why two conflicting trends lead to an overall positive?} Our system utilizes visual techniques to explain the underlying mechanisms how a paradox emerges. Lastly, the data analyst needs to make a decision: {\it Should I recommend the new feature to users? Which association to trust? The overall association, or the subgroup-level, or neither?} \vispur has a diagnosis module to help data analysts to locate spuriousness of a chosen association, as well as to inform where the distortion comes from. Fig.~\ref{fig:teaser}(c) summarizes the main steps in our system design framework: (1) confounder identification, (2) subgroup heterogeneity, (3) reasoning, and (4) decision-making.}
\begin{itemize}
    \item {{\bf A systematic workflow that incorporates the design needs of our target users to help them navigate the causal analysis of spurious associations.}} \tocomments{Our target users are data practitioners or domain experts who need to answer a causal question but lack causal inference knowledge.} We close the gap between causal theory and practical use by identifying a set of design guidelines and proposing a systematic workflow. \tocomments{Our work explores the visual analytic design issues concerning causal analysis and interpretation of spurious associations from empirical data.}
    \item {{\bf \vispur, a visual analytic system that investigates the causal sources of spurious associations or paradoxes by utilizing visualizations that reduce human's cognitive burdens.} {We present two visual views: \subgroupviewer produces glyphs (``visual signatures'') that encode multidimensional data features; It also incorporates a causal space where key causal concepts are simultaneously revealed and compared; \reasoningstoryboard communicates causal stories through event pathways to support humans users in the process of paradox reasoning.}}
    \item {{\bf Evaluations to demonstrate the utility of our system.}} We conduct a controlled user study and an expert interview study, showing that \vispur not only enables users to better locate causal roots of a spurious association (confounders and causal behaviors among subsets of data), but also allows them to better understand why a paradoxical association emerges whilst aggregating subgroups. These observations from \vispur together lead to a richer understanding of the data.
\end{itemize}

% {The remainder of this paper is organized as follows. Section~\ref{sec:relatedwork} provides a review of related works. Section~\ref{sec:designguideline} highlights design challenges and requirements. Section~\ref{sec:methodology} describes our causal framework, metrics, and algorithms. The \vispur system design is discussed in Section~\ref{sec:systemdesign}. We report evaluation results in Section~\ref{sec:userstudy} and give an extended discussion in Section ~\ref{sec:discussion}. Finally, we conclude this work in Section~\ref{sec:conclusion}.}

\input{images/teaser_caption}
