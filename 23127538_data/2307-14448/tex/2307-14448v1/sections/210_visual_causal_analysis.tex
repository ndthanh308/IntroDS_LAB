\subsection{Visual Causal Analysis}

% {Researchers have been developing visual analytic tools to support causal reasoning to overcome the lack of decision support in practice with raw data and statistical results \toRone{alone} \cite{chen2011data}. Existing works focus on several aspects, including (a) human causality perception from general-purpose visualization \cite{yen2019exploratory, xiong2019illusion, kale2021causal, kadaba2007visualizing}, (b) design of novel visual representations \cite{baker2001good,rum1980magic,armstrong2014visualizing, rucker2008simpson,friendly2013elliptical}, (b) visual analytic systems for exploratory analysis of complex causal relations \cite{wang2015visual,wang2017visual,xie2020visual,jin2020visual,dang2015reactionflow,wongsuphasawat2012exploring,lu2017visual,xie2020causalflow}.}

Researchers have been developing visual analytic tools to support causal reasoning to overcome the lack of decision support in practice with raw data and statistical results \tocomments{alone} \cite{chen2011data}. Existing works focus on various aspects such as (a) human causality perception from general-purpose visualization \cite{yen2019exploratory, kale2021causal}, (b) design of new visual representations \cite{baker2001good,rum1980magic,armstrong2014visualizing, rucker2008simpson,friendly2013elliptical}, (b) visual analytic systems for causal discovery \cite{dang2015reactionflow, wang2015visual, xie2020causalflow, xie2020visual, jin2020visual}, as well as \tocomments{(c) open-source visual tools and libraries for causal inference \cite{greifer2020covariate,shimoni2019evaluation,chen2020causalml,econml,guo2023causalvis,guo2021vaine}.} 

Researchers have found that general-purpose visualizations can lead to error-prone perceived causality due to confirmation bias and information overload \cite{yen2019exploratory}. Different visual encodings, such as bar charts and icon arrays, do not significantly enhance causal inferences beyond contingency tables \cite{kale2021causal}. Given the limitations of general-purpose visualizations, researchers have designed new representations by focusing on Simpson's paradox. These designs include B-K diagram \cite{baker2001good}, platform scale representation \cite{rum1980magic}, comet chart \cite{armstrong2014visualizing}, circle-line plots \cite{rucker2008simpson} and data ellipse diagram \cite{friendly2013elliptical} mainly for pedagogical purpose. Recent advancements in visual interfaces have facilitated exploratory analysis of complex causal relations, specifically in large-scale multidimensional  \cite{wang2015visual, wang2017visual, xie2020visual} and sequence data \cite{dang2015reactionflow,xie2020causalflow,jin2020visual}, incorporating state-of-the-art automatic causality discovery algorithms.
% {For example, Causality Explorer \cite{xie2020visual} applied causal graph detection algorithms on big data, designed an uncertainty-aware node-link causal graph, and provides interactive what-if analysis and simulations of potential actions (e.g., change of variable values). The seqCausal \cite{jin2020visual} designed a flow-based visualization with the Granger causality algorithm \cite{granger1969investigating} to show how event sequences progress among key events in the causal graph.}
% {Causal Structure Investigator (CSI) \cite{wang2017visual} further addressed the subgroup analysis problem where users could explore data partition (either manual partition or clustering algorithms) and infer various causal models. Users could pool all causal models to summarize common causal relations as well as compare to recognize pattern differences.}
{However, those systems lack interpretability and do not locate spuriousness, or reason about the causal roots of a misleading association.}
% \tocomments{Recent years have witnessed the development of open-source visual tools and packages to support causal inference, such as Causalvis \cite{guo2023causalvis}, VAINE \cite{guo2021vaine}, and a Causal AI Suite \cite{kiciman2022causal} integrating DoWhy \cite{sharma2020dowhy}, EconML \cite{econml}, Causica \cite{geffner2022deep}, and ShowWhy \cite{microsoft2022introduction}. Causalvis \cite{guo2023causalvis} and the Causal AI components (EconML, Causica, DoWhy) \cite{kiciman2022causal} mainly support the end-to-end causal inference pipeline within computational environments (e.g., Jupyter notebooks). Although the functionalities supported by these tools overlap with our system, such as confounder estimation, covariate balance checking, and subgroup visualizations, their intended audience and goals are different from ours. They serve causal inference experts for supporting the iterative causal inference process ranging from causal discovery, to causal effect estimation, and validation and report. But our intended users are those without causal inference knowledge. {our target users are not aware of or not using any causal inference tools or packages. They are not aware of the techniques of propensity score weighting or matching techniques in solving spurious associations. \vispur is a more friendly interface for users who might encounter distortion and paradox, but have no toolkits to understand causal concepts.} Similar to \vispur, ShowWhy \cite{microsoft2022introduction} is codeless user interfaces that empower a broader audience who may not be familiar with specific machine learning estimators or causal inference, but it does not focus on explaining Simpson's paradox by revealing the causal mechanisms. VAINE \cite{guo2021vaine} is a visual analytics interface closely related to our system since it identifies Simpson's paradox by running clustering algorithms and offers cluster-wise cause-outcome view and covariates view. A contrasting difference of \vispur to VAINE is that it cares about causal reasoning of Simpson's paradox and also incorporates a balancing diagnosis chart to prevent users from taking the overlaid regression lines as causal effects.} Different from existing interfaces, we closely investigate and explain the causal mechanisms why an association is spurious and why a paradox emerges through flexible interactions, statistical assessments, along with automatic subgroup discovery algorithms.
\tocomments{In recent years, various open-source visual tools and packages have emerged to support causal inference. These include Causalvis \cite{guo2023causalvis}, VAINE \cite{guo2021vaine}, and a Causal AI Suite \cite{kiciman2022causal} integrating DoWhy \cite{sharma2020dowhy}, EconML \cite{econml}, Causica\footnote{Causica: \url{https://github.com/microsoft/causica/}}, and ShowWhy \cite{microsoft2022introduction}. While these tools have similar functionalities with our system, such as confounder estimation, covariate balance checking, and subgroup visualizations, their intended audience and goals differ from ours. They primarily target causal inference experts and support the iterative causal inference process ranging from confounder investigation, matching and weighting, inference and reporting. In contrast, our target users are data analysts and domain experts who might lack causal inference knowledge and experience in utilizing causal inference packages. Our \vispur interface is designed to provide a user-friendly platform for those encountering distortion and paradox without causality background. While ShowWhy \cite{microsoft2022introduction} offers a codeless user interface for a broader audience, it does not focus on explaining Simpson's paradox by revealing causal mechanisms. VAINE \cite{guo2021vaine}, closely related to our system, detects Simpson's paradox through clustering algorithms and provides cause-outcome and covariate views on a cluster level. In contrast, our \vispur system distinguishes itself by its capability of interpreting Simpson's paradox in terms of two causal mechanisms: confounding bias and heterogeneous subgroups. By incorporating causal analysis components, such as confounder identification and diagnosis component, our system enables users to gain a better understanding of the paradox, and prevent them from mistakenly interpreting overlaid regression lines as causal effects.}

% Our tool is designed in the context of RCM framework, allowing users to investigate the spurious association in observational studies. In recent years, we have witnessed a number of visualization (or partially visual) packages being developed in the CRM context, such as Cobalt \cite{greifer2020covariate}, causallib \cite{shimoni2019evaluation}, CausalML \cite{chen2020causalml}, DoWhy, EconML, and ShowWhy \cite{kiciman2022causal}. However, they serve different target users and goals. The above tools mainly serve causal inference experts for the goal of estimating causal effects, while our target users are regular data scientists/analysts who might not have much causality knowledge and our goal is to address the confusion caused by spurious associations. Another difference is that, \vispur supports a different analysis workflow from that of existing solutions. Existing packages provide holistic or fragmented supports for the typical causal analysis workflow, e.g., causallib and DoWhy support matching/weighting, Cobalt supports balance checking, EconML supports conditional causal effect estimation. The proposed \vispur is a more friendly interface for users who might encounter distortion and paradox, but have no toolkits to understand such causal concepts.

% {\toRone{R1 asked: Is that true?} Different from existing interfaces, our work targets at an elemental causal induction -- a single causal relation in the presence of many other factors -- by formulating the problem in a clearly defined causal diagram. We closely investigate and explain the causal mechanisms why an association is spurious and why a paradox emerges through flexible interactions, statistical assessments, along with automatic subgroup discovery algorithms.}

% Researchers have demonstrated the usefulness of visualization in causality reasoning and association analysis, as direct interaction with raw data, or statistical and machine learning methods alone cannot convey a clear and adequate amount of information for humans to make decisions \cite{chen2011data}. However, existing studies have found that humans face certain difficulties in making association or causal reasoning using conventional visualizations (e.g., contingency table, bar chart, scatter plots etc). For example, prior studies have found that students have difficulty in identifying the semantics of associations (positive, negative or independent) or understand the reversal in Simpson's paradox using contingency tables \cite{batanero1996intuitive,lesser200111}, participants expressed a higher tendency to perceive a (wrong) causal relation from a correlation when data is presented by a higher level of data aggregation, in line or dot visual encodings than bar encodings \cite{xiong2019illusion}. Two recent studies \cite{yen2019exploratory,kale2021causal} have tested whether normal people are able to detect a treatment effect and a confounding relationship, or a mediator, through a variety of visualization designs (e.g., bar charts, scatter plots, icon arrays etc). The experiments revealed that people make more errors when the causal model becomes more complicated with mediators and confounders, different encodings do not appear to improve much causal reasoning beyond contingency tables. Given the limitation of conventional visualizations, researchers have also employed new visual representations to represent associations and causal relations, such as animations showing event sequences \cite{elmqvist2003causality}, directed acyclic graphs (DAGs) through a node-link diagrams to illustrate the complex causal relations and strengths among a variety of factors \cite{wang2015visual,xie2020visual}, ``diff bar chart'' through layered bars showing counterfactual outcomes under different conditions \cite{xie2020visual}. The most relevant works, including Outflow \cite{wongsuphasawat2012exploring}, seqCausal \cite{jin2020visual}, both proposed a flow-based visual structure to illustrate event progression pathways, which are connected with outcomes to model how alternative chains of events may lead to different results.

% When it comes to visualizing Simpson's paradox, standard visualizations are unable to well represent all the elements, e.g., subgroups, treatment, outcome, per-subgroup prognostic tendency, treatment propensity, as well as mixed causal effects, that are crucial to portray confounding bias and heterogeneous effects to facilitate paradoxical phenomenon. Our literature review finds five good visual representations of Simpson's paradox, including the B-K diagram \cite{baker2001good}, the platform scale representation \cite{rum1980magic}, comet chart \cite{armstrong2014visualizing}, triplet plot \cite{rucker2008simpson} and data ellipse diagram \cite{friendly2013elliptical}. Often diagrams of Simpson's paradox are created for pedagogical reasons. For example, the B-K diagram and platform scale aim to clarify intuition, but less suitable for analyzing complex data sets with a large number of subgroups or confounders. The comet chart has advantageous in representing subgroups and facilitating comparison among subgroups or between subgroups and the aggregated pattern, however, the strong sense of motion conveyed by comets only works well for time-based data rather than continuous or categorical treatment. Two additional examples that contribute to our visual analytic system are triplet plot and ellipse diagram. Both diagrams use x- and y-axis to represent treatment and outcome, along with slope to indicate per-subgroup associations, except that triplet is designed for discrete treatment, whereas ellipse is for continuous treatment. 

% Prior studies provide design implications for our visual analytic system. We have employed triplet and ellipse to represent the key elements in a Simpson's paradox, however, beyond static visualizations, our system supports disaggregation interactions so that users are able to generate and investigate/compare subgroups, as well as prompting warning messages to draw users' attention to easily ignored information. Besides, we repurpose existing flow-based visualization to illustrate a story pattern depicting how people take distinct treatment actions and end up at different outcomes in a dataset. The system, by incorporating a rich set of visual representations, algorithm support, and interaction functionalities, enables real data analysis and interpretation of data patterns in practical settings.

