% Generated by IEEEtran.bst, version: 1.14 (2015/08/26)
\begin{thebibliography}{10}
\providecommand{\url}[1]{#1}
\csname url@samestyle\endcsname
\providecommand{\newblock}{\relax}
\providecommand{\bibinfo}[2]{#2}
\providecommand{\BIBentrySTDinterwordspacing}{\spaceskip=0pt\relax}
\providecommand{\BIBentryALTinterwordstretchfactor}{4}
\providecommand{\BIBentryALTinterwordspacing}{\spaceskip=\fontdimen2\font plus
\BIBentryALTinterwordstretchfactor\fontdimen3\font minus \fontdimen4\font\relax}
\providecommand{\BIBforeignlanguage}[2]{{%
\expandafter\ifx\csname l@#1\endcsname\relax
\typeout{** WARNING: IEEEtran.bst: No hyphenation pattern has been}%
\typeout{** loaded for the language `#1'. Using the pattern for}%
\typeout{** the default language instead.}%
\else
\language=\csname l@#1\endcsname
\fi
#2}}
\providecommand{\BIBdecl}{\relax}
\BIBdecl

\bibitem{dosovitskiy2020image}
A.~Dosovitskiy, L.~Beyer, A.~Kolesnikov, D.~Weissenborn, X.~Zhai, T.~Unterthiner, M.~Dehghani, M.~Minderer, G.~Heigold, S.~Gelly \emph{et~al.}, ``An image is worth 16x16 words: Transformers for image recognition at scale,'' \emph{arXiv preprint arXiv:2010.11929}, 2020.

\bibitem{redmon2018yolov3}
J.~Redmon and A.~Farhadi, ``Yolov3: An incremental improvement,'' \emph{arXiv preprint arXiv:1804.02767}, 2018.

\bibitem{radford2021learning}
A.~Radford, J.~W. Kim, C.~Hallacy, A.~Ramesh, G.~Goh, S.~Agarwal, G.~Sastry, A.~Askell, P.~Mishkin, J.~Clark \emph{et~al.}, ``Learning transferable visual models from natural language supervision,'' in \emph{International Conference on Machine Learning}.\hskip 1em plus 0.5em minus 0.4em\relax PMLR, 2021, pp. 8748--8763.

\bibitem{laine2016temporal}
S.~Laine and T.~Aila, ``Temporal ensembling for semi-supervised learning,'' \emph{arXiv preprint arXiv:1610.02242}, 2016.

\bibitem{park2019relational}
W.~Park, D.~Kim, Y.~Lu, and M.~Cho, ``Relational knowledge distillation,'' in \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, 2019, pp. 3967--3976.

\bibitem{zhang2019your}
L.~Zhang, J.~Song, A.~Gao, J.~Chen, C.~Bao, and K.~Ma, ``Be your own teacher: Improve the performance of convolutional neural networks via self distillation,'' in \emph{Proceedings of the IEEE/CVF international conference on computer vision}, 2019, pp. 3713--3722.

\bibitem{he2022masked}
K.~He, X.~Chen, S.~Xie, Y.~Li, P.~Doll{\'a}r, and R.~Girshick, ``Masked autoencoders are scalable vision learners,'' in \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, 2022, pp. 16\,000--16\,009.

\bibitem{yang2024towards3}
D.~Yang, K.~Yang, H.~Kuang, Z.~Chen, Y.~Wang, and L.~Zhang, ``Towards context-aware emotion recognition debiasing from a causal demystification perspective via de-confounded training,'' \emph{arXiv preprint arXiv:2407.04963}, 2024.

\bibitem{liu2023amp}
Y.~Liu, J.~Liu, K.~Yang, B.~Ju, S.~Liu, Y.~Wang, D.~Yang, P.~Sun, and L.~Song, ``Amp-net: Appearance-motion prototype network assisted automatic video anomaly detection system,'' \emph{IEEE Transactions on Industrial Informatics}, 2023.

\bibitem{wang2024self}
Y.~Wang, Z.~Chen, D.~Yang, Y.~Sun, and L.~Qi, ``Self-cooperation knowledge distillation for novel class discovery,'' \emph{arXiv preprint arXiv:2407.01930}, 2024.

\bibitem{yang2023context}
D.~Yang, Z.~Chen, Y.~Wang, S.~Wang, M.~Li, S.~Liu, X.~Zhao, S.~Huang, Z.~Dong, P.~Zhai, and L.~Zhang, ``Context de-confounded emotion recognition,'' in \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, June 2023, pp. 19\,005--19\,015.

\bibitem{yang2023aide}
D.~Yang, S.~Huang, Z.~Xu, Z.~Li, S.~Wang, M.~Li, Y.~Wang, Y.~Liu, K.~Yang, Z.~Chen \emph{et~al.}, ``Aide: A vision-driven multi-view, multi-modal, multi-tasking dataset for assistive driving perception,'' in \emph{Proceedings of the IEEE/CVF International Conference on Computer Vision}, 2023, pp. 20\,459--20\,470.

\bibitem{liu2023stochastic}
Y.~Liu, D.~Yang, G.~Fang, Y.~Wang, D.~Wei, M.~Zhao, K.~Cheng, J.~Liu, and L.~Song, ``Stochastic video normality network for abnormal event detection in surveillance videos,'' \emph{Knowledge-Based Systems}, vol. 280, p. 110986, 2023.

\bibitem{yang2024towards2}
D.~Yang, D.~Xiao, K.~Li, Y.~Wang, Z.~Chen, J.~Wei, and L.~Zhang, ``Towards multimodal human intention understanding debiasing via subject-deconfounding,'' \emph{arXiv preprint arXiv:2403.05025}, 2024.

\bibitem{devlin2018bert}
J.~Devlin, M.-W. Chang, K.~Lee, and K.~Toutanova, ``Bert: Pre-training of deep bidirectional transformers for language understanding,'' \emph{arXiv preprint arXiv:1810.04805}, 2018.

\bibitem{karras2019style}
T.~Karras, S.~Laine, and T.~Aila, ``A style-based generator architecture for generative adversarial networks,'' in \emph{Proceedings of the IEEE/CVF conference on computer vision and pattern recognition}, 2019, pp. 4401--4410.

\bibitem{liu2021swin}
Z.~Liu, Y.~Lin, Y.~Cao, H.~Hu, Y.~Wei, Z.~Zhang, S.~Lin, and B.~Guo, ``Swin transformer: Hierarchical vision transformer using shifted windows,'' in \emph{Proceedings of the IEEE/CVF International Conference on Computer Vision}, 2021, pp. 10\,012--10\,022.

\bibitem{ramesh2022hierarchical}
A.~Ramesh, P.~Dhariwal, A.~Nichol, C.~Chu, and M.~Chen, ``Hierarchical text-conditional image generation with clip latents,'' \emph{arXiv preprint arXiv:2204.06125}, 2022.

\bibitem{tarvainen2017mean}
A.~Tarvainen and H.~Valpola, ``Mean teachers are better role models: Weight-averaged consistency targets improve semi-supervised deep learning results,'' \emph{Advances in neural information processing systems}, vol.~30, 2017.

\bibitem{chen2022towards}
Z.~Chen, B.~Li, J.~Xu, S.~Wu, S.~Ding, and W.~Zhang, ``Towards practical certifiable patch defense with vision transformer,'' in \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 2022, pp. 15\,148--15\,158.

\bibitem{yang2023target}
D.~Yang, Y.~Liu, C.~Huang, M.~Li, X.~Zhao, Y.~Wang, K.~Yang, Y.~Wang, P.~Zhai, and L.~Zhang, ``Target and source modality co-reinforcement for emotion understanding from asynchronous multimodal sequences,'' \emph{Knowledge-Based Systems}, p. 110370, 2023.

\bibitem{wang2023adversarial}
Y.~Wang, Z.~Chen, D.~Yang, Y.~Liu, S.~Liu, W.~Zhang, and L.~Qi, ``Adversarial contrastive distillation with adaptive denoising,'' in \emph{ICASSP 2023-2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}.\hskip 1em plus 0.5em minus 0.4em\relax IEEE, 2023, pp. 1--5.

\bibitem{yang2024how2comm}
D.~Yang, K.~Yang, Y.~Wang, J.~Liu, Z.~Xu, R.~Yin, P.~Zhai, and L.~Zhang, ``How2comm: Communication-efficient and collaboration-pragmatic multi-agent perception,'' \emph{Advances in Neural Information Processing Systems (NeurIPS)}, vol.~36, 2024.

\bibitem{liu2023improving}
S.~Liu, Z.~Chen, Y.~Liu, Y.~Wang, D.~Yang, Z.~Zhao, Z.~Zhou, X.~Yi, W.~Li, W.~Zhang \emph{et~al.}, ``Improving generalization in visual reinforcement learning via conflict-aware gradient agreement augmentation,'' in \emph{Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)}, 2023, pp. 23\,436--23\,446.

\bibitem{yang2024towards}
D.~Yang, M.~Li, D.~Xiao, Y.~Liu, K.~Yang, Z.~Chen, Y.~Wang, P.~Zhai, K.~Li, and L.~Zhang, ``Towards multimodal sentiment analysis debiasing via bias purification,'' \emph{arXiv preprint arXiv:2403.05023}, 2024.

\bibitem{liu2023learning}
Y.~Liu, Z.~Xia, M.~Zhao, D.~Wei, Y.~Wang, S.~Liu, B.~Ju, G.~Fang, J.~Liu, and L.~Song, ``Learning causality-inspired representation consistency for video anomaly detection,'' in \emph{Proceedings of the 31st ACM International Conference on Multimedia (ACM MM)}, 2023, pp. 203--212.

\bibitem{burton2015data}
P.~R. Burton, M.~J. Murtagh, A.~Boyd, J.~B. Williams, E.~S. Dove, S.~E. Wallace, A.-M. Tasse, J.~Little, R.~L. Chisholm, A.~Gaye \emph{et~al.}, ``Data safe havens in health research and healthcare,'' \emph{Bioinformatics}, vol.~31, no.~20, pp. 3241--3248, 2015.

\bibitem{sun2017revisiting}
C.~Sun, A.~Shrivastava, S.~Singh, and A.~Gupta, ``Revisiting unreasonable effectiveness of data in deep learning era,'' in \emph{Proceedings of the IEEE international conference on computer vision}, 2017, pp. 843--852.

\bibitem{wang2023explicit}
Y.~Wang, Z.~Ge, Z.~Chen, X.~Liu, C.~Ma, Y.~Sun, and L.~Qi, ``Explicit and implicit knowledge distillation via unlabeled data,'' in \emph{ICASSP 2023-2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}.\hskip 1em plus 0.5em minus 0.4em\relax IEEE, 2023, pp. 1--5.

\bibitem{wang2024out}
Y.~Wang, Z.~Chen, D.~Yang, P.~Guo, K.~Jiang, W.~Zhang, and L.~Qi, ``Out of thin air: Exploring data-free adversarial robustness distillation,'' in \emph{Proceedings of the AAAI Conference on Artificial Intelligence}, vol.~38, no.~6, 2024, pp. 5776--5784.

\bibitem{wang2024confounded}
Y.~Wang, D.~Yang, Z.~Chen, Y.~Liu, S.~Liu, W.~Zhang, L.~Zhang, and L.~Qi, ``De-confounded data-free knowledge distillation for handling distribution shifts,'' in \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, 2024, pp. 12\,615--12\,625.

\bibitem{lopes2017data}
R.~G. Lopes, S.~Fenu, and T.~Starner, ``Data-free knowledge distillation for deep neural networks,'' \emph{arXiv preprint arXiv:1710.07535}, 2017.

\bibitem{chen2019}
H.~Chen, Y.~Wang, C.~Xu, Z.~Yang, C.~Liu, B.~Shi, C.~Xu, C.~Xu, and Q.~Tian, ``Data-free learning of student networks,'' in \emph{Proceedings of the IEEE/CVF International Conference on Computer Vision}, 2019, pp. 3514--3522.

\bibitem{fang2019}
G.~Fang, J.~Song, C.~Shen, X.~Wang, D.~Chen, and M.~Song, ``Data-free adversarial distillation,'' \emph{arXiv preprint arXiv:1912.11006}, 2019.

\bibitem{micaelli2019zero}
P.~Micaelli and A.~J. Storkey, ``Zero-shot knowledge transfer via adversarial belief matching,'' \emph{Advances in Neural Information Processing Systems}, vol.~32, 2019.

\bibitem{hao2021data}
Z.~Hao, Y.~Luo, H.~Hu, J.~An, and Y.~Wen, ``Data-free ensemble knowledge distillation for privacy-conscious multimedia model compression,'' in \emph{Proceedings of the 29th ACM International Conference on Multimedia}, 2021, pp. 1803--1811.

\bibitem{do2022momentum}
K.~Do, H.~Le, D.~Nguyen, D.~Nguyen, H.~Harikumar, T.~Tran, S.~Rana, and S.~Venkatesh, ``Momentum adversarial distillation: Handling large distribution shifts in data-free knowledge distillation,'' \emph{Advances in neural information processing systems}, 2022.

\bibitem{zhang2022dense}
J.~Zhang, C.~Chen, B.~Li, L.~Lyu, S.~Wu, S.~Ding, C.~Shen, and C.~Wu, ``Dense: Data-free one-shot federated learning,'' \emph{Advances in Neural Information Processing Systems}, vol.~35, pp. 21\,414--21\,428, 2022.

\bibitem{deng2009imagenet}
J.~Deng, W.~Dong, R.~Socher, L.-J. Li, K.~Li, and L.~Fei-Fei, ``Imagenet: A large-scale hierarchical image database,'' in \emph{2009 IEEE conference on computer vision and pattern recognition}.\hskip 1em plus 0.5em minus 0.4em\relax Ieee, 2009, pp. 248--255.

\bibitem{luo2020large}
L.~Luo, M.~Sandler, Z.~Lin, A.~Zhmoginov, and A.~Howard, ``Large-scale generative data-free distillation,'' \emph{arXiv preprint arXiv:2012.05578}, 2020.

\bibitem{fang2022up}
G.~Fang, K.~Mo, X.~Wang, J.~Song, S.~Bei, H.~Zhang, and M.~Song, ``Up to 100x faster data-free knowledge distillation,'' in \emph{Proceedings of the AAAI Conference on Artificial Intelligence}, vol.~36, no.~6, 2022, pp. 6597--6604.

\bibitem{binici2022preventing}
K.~Binici, N.~T. Pham, T.~Mitra, and K.~Leman, ``Preventing catastrophic forgetting and distribution mismatch in knowledge distillation via synthetic data,'' in \emph{Proceedings of the IEEE/CVF winter conference on applications of computer vision}, 2022, pp. 663--671.

\bibitem{patel2023learning}
G.~Patel, K.~R. Mopuri, and Q.~Qiu, ``Learning to retain while acquiring: Combating distribution-shift in adversarial data-free knowledge distillation,'' in \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, 2023, pp. 7786--7794.

\bibitem{chen2021learning}
H.~Chen, T.~Guo, C.~Xu, W.~Li, C.~Xu, C.~Xu, and Y.~Wang, ``Learning student networks in the wild,'' in \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, 2021, pp. 6428--6437.

\bibitem{yim2017gift}
J.~Yim, D.~Joo, J.~Bae, and J.~Kim, ``A gift from knowledge distillation: Fast optimization, network minimization and transfer learning,'' in \emph{Proceedings of the IEEE conference on computer vision and pattern recognition}, 2017, pp. 4133--4141.

\bibitem{yin2020dreaming}
H.~Yin, P.~Molchanov, J.~M. Alvarez, Z.~Li, A.~Mallya, D.~Hoiem, N.~K. Jha, and J.~Kautz, ``Dreaming to distill: Data-free knowledge transfer via deepinversion,'' in \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, 2020, pp. 8715--8724.

\bibitem{fang2021contrastive}
G.~Fang, J.~Song, X.~Wang, C.~Shen, X.~Wang, and M.~Song, ``Contrastive model inversion for data-free knowledge distillation,'' \emph{arXiv preprint arXiv:2105.08584}, 2021.

\bibitem{choi2020data}
Y.~Choi, J.~Choi, M.~El-Khamy, and J.~Lee, ``Data-free network quantization with adversarial knowledge distillation,'' in \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops}, 2020, pp. 710--711.

\bibitem{ye2019unsupervised}
M.~Ye, X.~Zhang, P.~C. Yuen, and S.-F. Chang, ``Unsupervised embedding learning via invariant and spreading instance feature,'' in \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, 2019, pp. 6210--6219.

\bibitem{wu2018unsupervised}
Z.~Wu, Y.~Xiong, S.~X. Yu, and D.~Lin, ``Unsupervised feature learning via non-parametric instance discrimination,'' in \emph{Proceedings of the IEEE conference on computer vision and pattern recognition}, 2018, pp. 3733--3742.

\bibitem{he2020momentum}
K.~He, H.~Fan, Y.~Wu, S.~Xie, and R.~Girshick, ``Momentum contrast for unsupervised visual representation learning,'' in \emph{Proceedings of the IEEE/CVF conference on computer vision and pattern recognition}, 2020, pp. 9729--9738.

\bibitem{chen2020simclr}
T.~Chen, S.~Kornblith, M.~Norouzi, and G.~Hinton, ``A simple framework for contrastive learning of visual representations,'' in \emph{International conference on machine learning}.\hskip 1em plus 0.5em minus 0.4em\relax PMLR, 2020, pp. 1597--1607.

\bibitem{grill2020bootstrap}
J.-B. Grill, F.~Strub, F.~Altch{\'e}, C.~Tallec, P.~Richemond, E.~Buchatskaya, C.~Doersch, B.~Avila~Pires, Z.~Guo, M.~Gheshlaghi~Azar \emph{et~al.}, ``Bootstrap your own latent-a new approach to self-supervised learning,'' \emph{Advances in neural information processing systems}, vol.~33, pp. 21\,271--21\,284, 2020.

\bibitem{caron2021emerging}
M.~Caron, H.~Touvron, I.~Misra, H.~J{\'e}gou, J.~Mairal, P.~Bojanowski, and A.~Joulin, ``Emerging properties in self-supervised vision transformers,'' in \emph{Proceedings of the IEEE/CVF International Conference on Computer Vision}, 2021, pp. 9650--9660.

\bibitem{tian2019contrastive}
Y.~Tian, D.~Krishnan, and P.~Isola, ``Contrastive representation distillation,'' in \emph{International Conference on Learning Representations}, 2020.

\bibitem{johnson2019billion}
J.~Johnson, M.~Douze, and H.~J{\'e}gou, ``Billion-scale similarity search with {GPUs},'' \emph{IEEE Transactions on Big Data}, vol.~7, no.~3, pp. 535--547, 2019.

\bibitem{hinton2015distilling}
G.~Hinton, O.~Vinyals, J.~Dean \emph{et~al.}, ``Distilling the knowledge in a neural network,'' \emph{arXiv preprint arXiv:1503.02531}, vol.~2, no.~7, 2015.

\bibitem{seung2000manifold}
H.~S. Seung and D.~D. Lee, ``The manifold ways of perception,'' \emph{science}, vol. 290, no. 5500, pp. 2268--2269, 2000.

\bibitem{ALGAN2021106771}
\BIBentryALTinterwordspacing
G.~Algan and I.~Ulusoy, ``Image classification with deep learning in the presence of noisy labels: A survey,'' \emph{Knowledge-Based Systems}, vol. 215, p. 106771, 2021. [Online]. Available: \url{https://www.sciencedirect.com/science/article/pii/S0950705121000344}
\BIBentrySTDinterwordspacing

\bibitem{hornmatrix}
R.~Horn and C.~Johnson, ``Matrix analysis cambridge university press, 1985,'' \emph{Citation on}, p.~92.

\bibitem{krizhevsky2009learning}
A.~Krizhevsky, G.~Hinton \emph{et~al.}, ``Learning multiple layers of features from tiny images,'' 2009.

\bibitem{silberman2012indoor}
N.~Silberman, D.~Hoiem, P.~Kohli, and R.~Fergus, ``Indoor segmentation and support inference from rgbd images,'' in \emph{European conference on computer vision}.\hskip 1em plus 0.5em minus 0.4em\relax Springer, 2012, pp. 746--760.

\bibitem{paszke2019pytorch}
A.~Paszke, S.~Gross, F.~Massa, A.~Lerer, J.~Bradbury, G.~Chanan, T.~Killeen, Z.~Lin, N.~Gimelshein, L.~Antiga \emph{et~al.}, ``Pytorch: An imperative style, high-performance deep learning library,'' \emph{Advances in neural information processing systems}, vol.~32, 2019.

\bibitem{chen2017rethinking}
L.-C. Chen, G.~Papandreou, F.~Schroff, and H.~Adam, ``Rethinking atrous convolution for semantic image segmentation,'' \emph{arXiv preprint arXiv:1706.05587}, 2017.

\bibitem{he2016deep}
K.~He, X.~Zhang, S.~Ren, and J.~Sun, ``Deep residual learning for image recognition,'' in \emph{Proceedings of the IEEE conference on computer vision and pattern recognition}, 2016, pp. 770--778.

\bibitem{sandler2018mobilenetv2}
M.~Sandler, A.~Howard, M.~Zhu, A.~Zhmoginov, and L.-C. Chen, ``Mobilenetv2: Inverted residuals and linear bottlenecks,'' in \emph{Proceedings of the IEEE conference on computer vision and pattern recognition}, 2018, pp. 4510--4520.

\bibitem{yu2023data}
S.~Yu, J.~Chen, H.~Han, and S.~Jiang, ``Data-free knowledge distillation via feature exchange and activation region constraint,'' in \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, 2023, pp. 24\,266--24\,275.

\bibitem{van2008visualizing}
L.~Van~der Maaten and G.~Hinton, ``Visualizing data using t-sne.'' \emph{Journal of machine learning research}, vol.~9, no.~11, 2008.

\end{thebibliography}
