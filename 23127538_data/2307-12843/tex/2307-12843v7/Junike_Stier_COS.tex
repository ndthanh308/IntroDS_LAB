\documentclass{article}
\usepackage{lmodern}
\renewcommand{\sfdefault}{lmss}
\renewcommand{\ttdefault}{lmtt}
\usepackage[T1]{fontenc}
\usepackage[latin9]{inputenc}
\usepackage{geometry}
\geometry{verbose,tmargin=1in,bmargin=1in,lmargin=1in,rmargin=1in}
\usepackage[american,english]{babel}
\usepackage{array}
\usepackage{float}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{graphicx}


\usepackage[unicode=true,pdfusetitle,
 bookmarks=true,bookmarksnumbered=false,bookmarksopen=false,
 breaklinks=false,pdfborder={0 0 0},pdfborderstyle={},backref=false,colorlinks=false]
 {hyperref}
 
 \usepackage[round]{natbib}
\usepackage{breakurl}
\hypersetup{breaklinks=true, colorlinks=false, pdfusetitle=true }

\makeatletter


\providecommand{\tabularnewline}{\\}

\theoremstyle{plain}
\newtheorem{thm}{\protect\theoremname}[section]
\theoremstyle{remark}
\newtheorem{rem}[thm]{\protect\remarkname}
\theoremstyle{plain}
\newtheorem{prop}[thm]{\protect\propositionname}
\theoremstyle{definition}
\newtheorem{defn}[thm]{\protect\definitionname}
\theoremstyle{plain}
\newtheorem{cor}[thm]{\protect\corollaryname}
\theoremstyle{plain}
\newtheorem{lem}[thm]{\protect\lemmaname}
\theoremstyle{definition}
\newtheorem{example}[thm]{\protect\examplename}

\newtheorem{assumption}{Assumption} 

\renewcommand\theassumption{A\arabic{assumption}}

\usepackage{stmaryrd}

\makeatother

\addto\captionsamerican{\renewcommand{\corollaryname}{Corollary}}
\addto\captionsamerican{\renewcommand{\definitionname}{Definition}}
\addto\captionsamerican{\renewcommand{\examplename}{Example}}
\addto\captionsamerican{\renewcommand{\lemmaname}{Lemma}}
\addto\captionsamerican{\renewcommand{\propositionname}{Proposition}}
\addto\captionsamerican{\renewcommand{\remarkname}{Remark}}
\addto\captionsamerican{\renewcommand{\theoremname}{Theorem}}
\addto\captionsenglish{\renewcommand{\corollaryname}{Corollary}}
\addto\captionsenglish{\renewcommand{\definitionname}{Definition}}
\addto\captionsenglish{\renewcommand{\examplename}{Example}}
\addto\captionsenglish{\renewcommand{\lemmaname}{Lemma}}
\addto\captionsenglish{\renewcommand{\propositionname}{Proposition}}
\addto\captionsenglish{\renewcommand{\remarkname}{Remark}}
\addto\captionsenglish{\renewcommand{\theoremname}{Theorem}}
\providecommand{\corollaryname}{Corollary}
\providecommand{\definitionname}{Definition}
\providecommand{\examplename}{Example}
\providecommand{\lemmaname}{Lemma}
\providecommand{\propositionname}{Proposition}
\providecommand{\remarkname}{Remark}
\providecommand{\theoremname}{Theorem}

\begin{document}
\title{From characteristic functions to multivariate distribution functions
and European option prices by the damped COS method}
\author{Gero Junike\thanks{Corresponding author. Carl von Ossietzky Universitt, Institut fr
Mathematik, 26129 Oldenburg, Germany, ORCID: 0000-0001-8686-2661,
E-mail: gero.junike@uol.de}, Hauke Stier\thanks{Carl von Ossietzky Universitt, Institut fr Mathematik, 26129 Oldenburg,
Germany.}}
\maketitle
\begin{abstract}
We provide a unified framework to obtain numerically certain quantities,
such as the distribution function, absolute moments and prices of
financial options, from the characteristic function of some (unknown)
probability density function using the Fourier-cosine expansion (COS)
method. The classical COS method is numerically very efficient in
one-dimension, but it cannot deal very well with certain integrands
in general dimensions. Therefore, we introduce the damped COS method,
which can handle a large class of integrands very efficiently. We
prove the convergence of the (damped) COS method and study its order
of convergence. The method converges exponentially if the characteristic
function decays exponentially. To apply the (damped) COS method, one
has to specify two parameters: a truncation range for the multivariate
density and the number of terms to approximate the truncated density
by a cosine series. We provide an explicit formula for the truncation
range and an implicit formula for the number of terms. Numerical experiments
up to five dimensions confirm the theoretical results.

\textbf{Keywords: }Fourier-transform, numerical integration, inversion
theorem, COS method, CDF, rainbow options\\
 \textbf{Mathematics Subject Classification} 65D30  65T40  60E10
62P05
\end{abstract}

\section{Introduction}

We aim to solve the following integral numerically:
\begin{equation}
\int_{\mathbb{R}^{d}}w(\boldsymbol{x})g(\boldsymbol{x})d\boldsymbol{x}.\label{eq:int}
\end{equation}
The function $g$ is usually a density and the function $w$ is called
\emph{function of interest.} Integrals as in (\ref{eq:int}) appear
in a wide range of applications: The integral is equal to the cumulative
distribution function (CDF) of the density $g$ if $w$ is an indicator
function. CDFs appear in many scientific disciplines. 

If $w$ is the absolute value, the integral describes the absolute
moment of the density $g$, which plays an important role in various
disciplines but is not easy to obtain, see \cite{von1965convergence, brown1972formulae, barndorff2005absolute}
and references therein. 

In a financial context, the function $w$ might also describe some
\emph{rainbow option}, which depends on several assets, and $w$ is
also called the \emph{payoff function}. The function $g$ is then
the density of the logarithmic returns of the assets and the integral
describes the price of the rainbow option. 

In many cases, the precise structure of $g$ is unknown, but the Fourier
transform $\widehat{g}$ is often given in closed form. For example:
while the joint density of the sum of two independent random variables
can only be expressed as a convolution and is usually not given explicitly,
the joint characteristic function is much simpler to obtain (it is
just the product of the marginal characteristic functions). Moreover,
the characteristic function of a Lvy process at a particular time-point
is usually given explicitly thanks to the Lvy-Khinchin formula.

The integral in (\ref{eq:int}) can be solved numerically using various
techniques, including (quasi) Monte Carlo simulation, numerical quadrature
and Fourier inversion. Special Fourier-inversion methods exist in
the case of a CDF, e.g., the Gil-Pelaez formula, see \cite{gil1951note}
and extensions, e.g., \cite{schorr1975numerical,abate1992fourier,waller1995obtaining,hughett1998error}
in one-dimension and \cite{shephard1991characteristic,shephard1991numerical}
in $d$ dimensions.

The COS method, see \citet{fang2009novel} for $d=1$ and \cite{ruijter2012two}
for $d=2$, is a Fourier inversion technique. The COS method has been
applied extensively in computational finance, see \citet{fang2009pricing,fang2011fourier,grzelak2011heston,zhang2013efficient,leitao2018data,liu2019neural,liu2019pricing,oosterlee2019mathematical}
and \citet{bardgett2019inferring}.

The COS method has also been applied to solve backward stochastic
differential equations, see \cite{ruijter2015fourier} and \cite{andersson2023convergence}.

Other one-dimensional Fourier techniques to solve integrals as in
(\ref{eq:int}) can be found in \citet{carr1999option,lord2008fast,ortiz2013robust}
and \citet{ortiz2016highly}. The COS method compares favorably to
other Fourier inversion techniques, see \citet{fang2009novel}.

The main idea of the COS method is to truncate the integration range
in (\ref{eq:int}) to some finite hypercube and to approximate the
density $g$ on the finite truncation range by a classical Fourier-cosine
expansion. Formulas for the truncation range and the number of terms
of the Fourier cosine-series are given in \citet{junike2022precise}
and in \citet{junike2023handle} for the one-dimensional case. 

There is a clever trick to approximate the cosine coefficients for
$g$ in a very fast and robust way using $\widehat{g}$. The COS method
is particularly fast when the Fourier-cosine coefficients of the function
of interest $w$ are given analytically. For instance, in multivariate
dimensions, the Fourier-cosine coefficients of a CDF can be obtained
analytically. However, for many rainbow options the Fourier-cosine
coefficients are not given in closed form, e.g., in the case of arithmetic
basket options. \cite{ruijter2012two} propose in this case to obtain
the Fourier coefficients of the function of interest numerically by
a discrete cosine transform, but this approach slows the COS method
significantly. In this article, we introduce the \emph{damped COS
method}, which is able to avoid the expensive application of the discrete
cosine transform if the Fourier transform of the function of interest
is given in closed form. The Fourier transform $\widehat{w}$ is known
for many rainbow options, see \citet{hurd2010fourier} and \citet{eberlein2010analysis}.
The main idea is to damp $w$ by multiplying it by an exponential
function in order to make the damped function of interest integrable.
The idea of introducing a damping factor dates back at least to \cite{carr1999option}.
In multivariate dimensions, damping is also applied by \cite{eberlein2010analysis},
where the optimal damping factor is determined by \cite{bayer2022optimal}. 

In moderate dimensions, the COS method is a fast, robust and straightforward-to-implement
alternative to the $d$-dimensional Gil-Pelaez formula, see \cite{shephard1991characteristic,shephard1991numerical}
or the multivariate Lewis formula, see \citet{eberlein2010analysis},
in particular if $g$ is smooth and has semi-heavy tails. A useful
feature of the COS method is the fact that in important cases all
parameters necessary to tune the method can be obtained directly given
some error tolerance.

This article makes the following main contributions: We prove the
convergence of the multidimensional (damped) COS method, we analyze
the order of convergence of the (damped) COS method, and we provide
explicit and implicit formulas for the truncation range and the number
of terms, respectively. The new approach to find the number of terms
in $d$ dimensions is completely distinct from the one-dimensional
case discussed in \citet{junike2023handle}. Unlike \cite{ruijter2012two},
who analyze the classical COS method, we include in our analysis numerical
uncertainty on the characteristic function $\widehat{g}$ and on the
Fourier-cosine coefficients of the function of interest. This makes
it possible to understand how approximations on $\widehat{g}$ and
the Fourier-cosine coefficients of the function of interest affect
the total error of the COS method. 

This article is structured as follows: In Section \ref{sec:Notation}
we fix some notation. In Section \ref{sec:Damped-COS-method} we introduce
the multidimensional (damped) COS method, prove its convergence, analyze
the order of convergence and provide explicit and implicit formulas
for the truncation range and the number of terms. In Section \ref{sec:Characteristic-functions}
we discuss some examples for $g$ and $\widehat{g}$. In Section \ref{sec:Functions-of-interest}
we discuss some functions of interest, i.e., examples for $w$. In
Section \ref{sec:Numerical} we provide numerical experiments. Section
\ref{sec:Conclusions} concludes.

\section{\label{sec:Notation}Notation}

Let $d\in\mathbb{N}$. Let $\mathcal{L}^{1}$ and $\mathcal{L}^{2}$
denote the sets of integrable and square integrable functions from
$\mathbb{R}^{d}$ to $\mathbb{R}$ and by $\left\langle .,.\right\rangle $
and $\left\Vert .\right\Vert _{2}$ we denote the scalar product and
the (semi)norm on $\mathcal{L}^{2}$, respectively. The supremum norm
of a function $g:\mathbb{R}^{d}\to\mathbb{C}$ is defined by $\left\Vert g\right\Vert _{\infty}:=\sup_{\boldsymbol{x}\in\mathbb{R}^{d}}|g(\boldsymbol{x})|$.
By $\Re\{z\}$ and $\Im\{z\}$ we denote the real and imaginary parts
of a complex number $z\in\mathbb{C}$. The complex unit is denoted
by $i$. By $\Gamma$, we denote the Gamma function. The Euclidean
norm and the maximum norm on $\mathbb{R}^{d}$ are denoted by $|.|$
and by $|.|_{\infty}$, respectively. For $\boldsymbol{x},\boldsymbol{y}\in\mathbb{R}^{d}$
we define
\[
\boldsymbol{x}\geq\boldsymbol{y}:\Leftrightarrow x_{1}\geq y_{1},...,x_{d}\geq y_{d}
\]
and treat ``$\leq$'', ``$<$'', ``$>$'', ``$=$'' and ``$\neq$''
similarly. We set $\mathbb{R}_{+}^{d}:=\{\boldsymbol{x}\in\mathbb{R}^{d},\boldsymbol{x}>\boldsymbol{0}\}$.
For $\boldsymbol{a},\boldsymbol{b}\in\mathbb{R}^{d}$ with $\boldsymbol{a}\leq\boldsymbol{b}$,
two complex vectors $\boldsymbol{z},\boldsymbol{y}\in\mathbb{C}^{d}$
and $\lambda\in\mathbb{C}$ we define $\boldsymbol{z}+\boldsymbol{y}:=(z_{1}+y_{1},...,z_{d}+y_{d})\in\mathbb{C}^{d}$
and treat $\boldsymbol{zy}$ and $\frac{\boldsymbol{z}}{\boldsymbol{y}}$
similarly. We further define
\begin{align*}
\boldsymbol{z}\cdot\boldsymbol{y}:= & z_{1}y_{1}+...+z_{d}y_{d}\in\mathbb{C}\\
\lambda\boldsymbol{z}:= & (\lambda z_{1},...,\lambda z_{d})\in\mathbb{C}^{d}\\{}
[\boldsymbol{a},\boldsymbol{b}]:= & [a_{1},b_{1}]\times...\times[a_{d},b_{d}]\subset\mathbb{R}^{d}\\
(-\boldsymbol{\infty},\boldsymbol{b}]:= & (-\infty,b_{1}]\times...\times(-\infty,b_{d}]\subset\mathbb{R}^{d}\\
\exp(\boldsymbol{x}) & :=\left(\exp(x_{1}),....,\exp(x_{d})\right),\quad\boldsymbol{x}\in\mathbb{R}^{d}\\
\log(\boldsymbol{x}) & :=\left(\log(x_{1}),....,\log(x_{d})\right),\quad\boldsymbol{x}\in\mathbb{R}_{+}^{d}.
\end{align*}
For a subset $A\subset\mathbb{R}^{d},$ we define the indicator function
$1_{A}(\boldsymbol{x})$ by one if $\boldsymbol{x}\in A$ and by zero
otherwise. Let $\mathbb{N}_{0}=\mathbb{N}\cup\{0\}$. For $\boldsymbol{N}=(N_{1},...,N_{d})\in\mathbb{N}_{0}^{d}$
and a sequence $\left(a_{\boldsymbol{k}}\right)_{\boldsymbol{k}\in\mathbb{N}_{0}^{d}}\subset\mathbb{C}$,
we define
\begin{align*}
\sideset{}{'}\sum_{\boldsymbol{\boldsymbol{0}}\leq\boldsymbol{k}\leq\boldsymbol{N}}a_{\boldsymbol{k}} & :=\sum_{\boldsymbol{\boldsymbol{0}}\leq\boldsymbol{k}\leq\boldsymbol{N}}\frac{1}{2^{\Lambda(\boldsymbol{k})}}a_{\boldsymbol{k}},
\end{align*}
where $\Lambda(\boldsymbol{k})$ is the number of components of the
vector $\boldsymbol{k}$ that are equal to zero, i.e., $\Lambda(\boldsymbol{k}):=\sum_{h=1}^{d}1_{\{0\}}(k_{h})$.
For an integrable function $g:\mathbb{R}^{d}\to\mathbb{C}$ we define
its \emph{Fourier transform} by
\begin{equation}
\widehat{g}(\boldsymbol{u}):=\int_{\mathbb{R}^{d}}g(\boldsymbol{x})e^{i\boldsymbol{u}\cdot\boldsymbol{x}}d\boldsymbol{x},\quad\boldsymbol{u}\in\mathbb{R}^{d}.\label{eq:FourierTransform}
\end{equation}
This definition of the Fourier transform also appears in \citet[Def. 22.6]{bauer1996probability}
and in \cite{eberlein2010analysis}. Provided the integral in (\ref{eq:FourierTransform})
exists, the domain of $\widehat{g}$ may also be extended to parts
of the complex plane. If $g\geq0$ and $\int g(\boldsymbol{x})d\boldsymbol{x}=1$,
then $g$ is called \emph{density}, $\widehat{g}$ is called the \emph{characteristic
function} and the map $\boldsymbol{y}\mapsto\int_{(-\boldsymbol{\infty},\boldsymbol{y}]}g(\boldsymbol{x})d\boldsymbol{x}$
is called the \emph{cumulative distribution function }(CDF)\emph{.} 

\section{\label{sec:Damped-COS-method}Damped COS method}

Typically, the function of interest, $w$, is only locally integrable,
but $w\notin\mathcal{L}^{1}$. We provide two examples: The integral
in (\ref{eq:int}) is equal to the CDF of $g$ evaluated at $\boldsymbol{y}\in\mathbb{R}^{d}$
if $w(\boldsymbol{x})=1_{(\boldsymbol{-\infty},\boldsymbol{y}]}(\boldsymbol{x})$
for $\boldsymbol{x}\in\mathbb{R}^{d}$. A rainbow option such as an
arithmetic basket put option with strike $K>0$ is defined by $w(\boldsymbol{x})=\max(K-\sum_{h=1}^{d}e^{x_{h}},0)$,
$\boldsymbol{x}\in\mathbb{R}^{d}$. To introduce the \emph{damped
COS method}, we will consider a damped function of interest that is
assumed to be integrable. Note that for many models and many rainbow
options, both $\widehat{g}$ and $\widehat{w}$ are given in closed
form, see e.g., \cite{ruijter2012two,eberlein2010analysis} and references
therein. 

For a scaling factor $\lambda>0$, a shift parameter $\boldsymbol{\mu}\in\mathbb{R}^{d}$
and a damping factor $\boldsymbol{\alpha}\in\mathbb{R}^{d}$, we define
the \emph{damped} \emph{density} by 
\begin{equation}
f(\boldsymbol{x})=\lambda e^{\boldsymbol{\alpha}\cdot(\boldsymbol{x}+\boldsymbol{\mu})}g(\boldsymbol{x}+\boldsymbol{\mu}),\quad\boldsymbol{x}\in\mathbb{R}^{d}\label{eq:dampedf}
\end{equation}
and the\emph{ damped} \emph{function of interest} by
\begin{equation}
v(\boldsymbol{x})=\frac{1}{\lambda}e^{-\boldsymbol{\alpha}\cdot(\boldsymbol{x}+\boldsymbol{\mu})}w(\boldsymbol{x}+\boldsymbol{\mu}),\quad\boldsymbol{x}\in\mathbb{R}^{d}.\label{eq:dampedv}
\end{equation}
By definition, it follows that
\begin{equation}
\int_{\mathbb{R}^{d}}w(\boldsymbol{x})g(\boldsymbol{x})d\boldsymbol{x}=\int_{\mathbb{R}^{d}}v(\boldsymbol{x})f(\boldsymbol{x})d\boldsymbol{x}.\label{eq:wg=00003Dvf}
\end{equation}
Thanks to Proposition \ref{prop:centr}, $f$ is a density centered
at zero if we choose $\lambda$ and $\boldsymbol{\mu}$ carefully
and $\widehat{f}$ is given in closed form if $\widehat{g}$ is given
in closed form. 
\begin{rem}
In some applications it might be useful to know that $f$ is a density.
However, in the proofs, we use only that $f$ is nonnegative and integrable.
\end{rem}

\begin{prop}
\label{prop:centr}Let $g\in\mathcal{L}_{1}$ and $\boldsymbol{\alpha}\in\mathbb{R}^{d}$.
Assume that $g$ is a density and that $\boldsymbol{x}\mapsto|\boldsymbol{x}|e^{\boldsymbol{\alpha}\cdot\boldsymbol{x}}g(\boldsymbol{x})$
is integrable. Let $\lambda=(\widehat{g}(-i\boldsymbol{\alpha}))^{-1}$
then $\lambda\in(0,\infty)$. Choose $\boldsymbol{\mu}\in\mathbb{R}^{d}$
by
\begin{equation}
\mu_{h}=-\lambda i\left.\frac{\partial}{\partial u_{h}}\widehat{g}(\boldsymbol{u}-i\boldsymbol{\alpha})\right|_{\boldsymbol{u}=\boldsymbol{0}},\quad h=1,...,d.\label{eq:mu_lam_partial}
\end{equation}
Define $f(\boldsymbol{x})=\lambda e^{\boldsymbol{\alpha}\cdot(\boldsymbol{x}+\boldsymbol{\mu})}g(\boldsymbol{x}+\boldsymbol{\mu})$,
$\boldsymbol{x}\in\mathbb{R}^{d}$. Then $f$ is a density with characteristic
function 
\begin{equation}
\widehat{f}(\boldsymbol{u})=\lambda e^{-i\boldsymbol{u}\cdot\boldsymbol{\mu}}\widehat{g}(\boldsymbol{u}-i\boldsymbol{\alpha}),\quad\boldsymbol{u}\in\mathbb{R}^{d}.\label{eq:Fourier_f}
\end{equation}
Further, the moments of $f$ of first order are zero, i.e., $\int_{\mathbb{R}^{d}}f(\boldsymbol{x})x_{h}d\boldsymbol{x}=0$,
$h=1,...,d$.
\end{prop}

\begin{proof}
Use $\int|\boldsymbol{x}|e^{\boldsymbol{\alpha}\cdot\boldsymbol{x}}g(\boldsymbol{x})d\boldsymbol{x}<\infty$
and split the integration range into $\mathbb{R}^{d}\setminus B_{1}$
and $B_{1}$, where $B_{1}$ is the unit ball, to see that $\boldsymbol{x}\mapsto e^{\boldsymbol{\alpha}\cdot\boldsymbol{x}}g(\boldsymbol{x})$
is integrable. Since $\lambda=(\int_{\mathbb{R}^{d}}e^{\boldsymbol{\alpha}\cdot\boldsymbol{x}}g(\boldsymbol{x})d\boldsymbol{x})^{-1}$
and $g$ is a density we have $\lambda\in(0,\infty)$. By the definition
of $\lambda$, $f$ is a density. Since $f\in\mathcal{L}^{1}$, $\widehat{f}$
exists. A direct analysis shows (\ref{eq:Fourier_f}). By \citet[Thm 25.2]{bauer1996probability},
the partial derivatives in Equation (\ref{eq:mu_lam_partial}) exist
and it holds that $\mu_{h}=\lambda\int_{\mathbb{R}^{d}}e^{\boldsymbol{\alpha}\cdot\boldsymbol{x}}g(\boldsymbol{x})x_{h}d\boldsymbol{x}$.
Finally, we have that
\begin{align*}
\int_{\mathbb{R}^{d}}f(\boldsymbol{x})x_{h}d\boldsymbol{x}= & \int_{\mathbb{R}^{d}}\lambda e^{\boldsymbol{\alpha}\cdot(\boldsymbol{x}+\boldsymbol{\mu})}g(\boldsymbol{x}+\boldsymbol{\mu})x_{h}d\boldsymbol{x}=\lambda\int_{\mathbb{R}^{d}}e^{\boldsymbol{\alpha}\cdot\boldsymbol{x}}g(\boldsymbol{x})x_{h}d\boldsymbol{x}-\mu_{h}\lambda\int_{\mathbb{R}^{d}}e^{\boldsymbol{\alpha}\cdot\boldsymbol{x}}g(\boldsymbol{x})d\boldsymbol{x}=0.
\end{align*}
\end{proof}
In some cases $\widehat{g}$ needs to be approximated numerically;
e.g., in \cite{duffie2003affine}, $\widehat{g}$ is the solution
to some ordinary differential equation, which itself needs to be solved
numerically before applying the COS method. From now on, we assume
that $f\in\mathcal{L}_{1}$ and that $\widehat{f}$ is given explicitly
or can be efficiently approximated numerically by some function $\vartheta$
and that $v$ is (at least) locally integrable.\textbf{ }At several
places, we assume $v\in\mathcal{L}_{1}$, which can usually be achieved
by setting $\boldsymbol{\alpha}\neq\boldsymbol{0}$. We describe the
COS method in detail in order to approximate the right-hand side of
Equation (\ref{eq:wg=00003Dvf}). Let $\boldsymbol{M}\in\mathbb{R}_{+}^{d}$
large enough so that
\begin{equation}
\int_{\mathbb{R}^{d}}v(\boldsymbol{x})f(\boldsymbol{x})d\boldsymbol{x}\approx\int_{[-\boldsymbol{M},\boldsymbol{M}]}v(\boldsymbol{x})f(\boldsymbol{x})d\boldsymbol{x}.\label{eq:approx_integrate_M}
\end{equation}
Let $\boldsymbol{L}\geq\boldsymbol{M}$. If $f$ is centered at zero,
we truncate $f$ on $[-\boldsymbol{L},\boldsymbol{L}]$ and approximate
the truncated damped density using a Fourier-series. We intuitively
have that
\begin{equation}
f\approx f1_{[-\boldsymbol{L},\boldsymbol{L}]}\approx\sideset{}{'}\sum_{\boldsymbol{\boldsymbol{0}}\leq\boldsymbol{k}\leq\boldsymbol{N}}a_{\boldsymbol{k}}e_{\boldsymbol{k}}1_{[-\boldsymbol{L},\boldsymbol{L}]}\approx\sideset{}{'}\sum_{\boldsymbol{\boldsymbol{0}}\leq\boldsymbol{k}\leq\boldsymbol{N}}c_{\boldsymbol{k}}e_{\boldsymbol{k}}1_{[-\boldsymbol{L},\boldsymbol{L}]}\approx\sideset{}{'}\sum_{\boldsymbol{\boldsymbol{0}}\leq\boldsymbol{k}\leq\boldsymbol{N}}\tilde{c}_{\boldsymbol{k}}e_{\boldsymbol{k}}1_{[-\boldsymbol{L},\boldsymbol{L}]},\label{eq:f_approx}
\end{equation}
where we define the basis functions
\[
e_{\boldsymbol{k}}(\boldsymbol{x})=\prod_{h=1}^{d}\cos\left(k_{h}\pi\frac{x_{h}+L_{h}}{2L_{h}}\right),\quad\boldsymbol{x}\in\mathbb{R}^{d},\quad\boldsymbol{k}\in\mathbb{\mathbb{N}}_{0}^{d},
\]
and the classical Fourier-cosine coefficients of $f1_{[-\boldsymbol{L},\boldsymbol{L}]}$
are given for $\boldsymbol{k}\in\mathbb{\mathbb{N}}_{0}^{d}$ by

\begin{align}
a_{\boldsymbol{k}} & =\frac{1}{\prod_{h=1}^{d}L_{h}}\int_{[-\boldsymbol{L},\boldsymbol{L}]}f(\boldsymbol{x})e_{\boldsymbol{k}}(\boldsymbol{x})d\boldsymbol{x}\}\nonumber \\
 & \approx\frac{1}{\prod_{h=1}^{d}L_{h}}\int_{\mathbb{R}^{d}}f(\boldsymbol{x})e_{\boldsymbol{k}}(\boldsymbol{x})d\boldsymbol{x}\label{eq:integral_ck}\\
 & =\frac{1}{2^{d-1}\prod_{h=1}^{d}L_{h}}\sum_{\boldsymbol{s}=(1,\pm1,...,\pm1)\in\mathbb{R}^{d}}\Re\left\{ \widehat{f}\left(\frac{\pi}{2}\frac{\boldsymbol{sk}}{\boldsymbol{L}}\right)\exp\left(i\frac{\pi}{2}\boldsymbol{s}\cdot\boldsymbol{k}\right)\right\} =:c_{\boldsymbol{k}}\label{eq:ck}\\
 & \approx\frac{1}{2^{d-1}\prod_{h=1}^{d}L_{h}}\sum_{\boldsymbol{s}=(1,\pm1,...,\pm1)\in\mathbb{R}^{d}}\Re\left\{ \vartheta\left(\frac{\pi}{2}\frac{\boldsymbol{sk}}{\boldsymbol{L}}\right)\exp\left(i\frac{\pi}{2}\boldsymbol{s}\cdot\boldsymbol{k}\right)\right\} =:\tilde{c}_{\boldsymbol{k}}.\label{eq:ck_tilde}
\end{align}
Sometimes it is necessary to choose $\boldsymbol{L}>\boldsymbol{M}$
to ensure that $c_{\boldsymbol{k}}$ is close enough to $a_{\boldsymbol{k}}$.
The key insight of the COS method is the fact that the integral at
the right-hand side of Equation (\ref{eq:integral_ck}) can be solved
explicitly\footnote{We use $\prod_{h=1}^{d}\cos\theta_{h}=\frac{1}{2^{d-1}}\sum_{\boldsymbol{s}=(1,\pm1,...,\pm1)\in\mathbb{R}^{d}}\cos\left(\boldsymbol{s}\cdot\boldsymbol{\theta}\right)$,
$\boldsymbol{\theta}\in\mathbb{R}^{d}$, which follows by mathematical
induction, from the fact that the cosine is an even function and from
the trigonometric identities stated in \citet[Eqs. (4.3.17, 4.3.31)]{abramowitz1972handbook}.}. If $\widehat{f}$ needs to be approximated by some function $\vartheta$,
we use $\tilde{c}_{\boldsymbol{k}}$ instead of $c_{\boldsymbol{k}}$. 

The idea of the multidimensional COS method is to approximate $f$
as in (\ref{eq:f_approx}), and hence the right-hand side of Equation
(\ref{eq:approx_integrate_M}), by

\begin{align}
\int_{[-\boldsymbol{M},\boldsymbol{M}]}v(\boldsymbol{x})f(\boldsymbol{x})d\boldsymbol{x} & \approx\sideset{}{'}\sum_{\boldsymbol{\boldsymbol{0}}\leq\boldsymbol{k}\leq\boldsymbol{N}}\tilde{c}_{\boldsymbol{k}}\underbrace{\int_{[-\boldsymbol{M},\boldsymbol{M}]}v(\boldsymbol{x})e_{\boldsymbol{k}}(\boldsymbol{x})d\boldsymbol{x}}_{=:v_{\boldsymbol{k}}}\label{eq:vk}\\
 & \approx\sideset{}{'}\sum_{\boldsymbol{\boldsymbol{0}}\leq\boldsymbol{k}\leq\boldsymbol{N}}\tilde{c}_{\boldsymbol{k}}\underbrace{\int_{\mathbb{R}^{d}}v(\boldsymbol{x})e_{\boldsymbol{k}}(\boldsymbol{x})d\boldsymbol{x}}_{=:\tilde{v}_{\boldsymbol{k}}}.\label{eq:vk_tilde}
\end{align}

\emph{Classical COS method}: If $\boldsymbol{\alpha}=\boldsymbol{0}$,
we speak of the classical COS method. In important cases, the coefficients
$v_{\boldsymbol{k}}$ can be obtained explicitly, i.e., the integral
at right-hand side of Equation (\ref{eq:vk}) can be solved analytically.
Examples in finance include, in one-dimension, plain vanilla put and
call options and digital options, see \citet{fang2009novel} and,
in two dimensions, geometric basket options, call-on-maximum options
and put-on-minimum options, see \cite{ruijter2012two}. In general
dimensions, the coefficients $v_{\boldsymbol{k}}$ of a CDF are given
in closed form, see Example \ref{exa:CDF}. In the case that the integral
in Equation (\ref{eq:vk}) cannot be solved directly (e.g. for arithmetic
basket options), \cite{ruijter2012two} propose solving the integral
in Equation (\ref{eq:vk}) numerically to obtain $v_{\boldsymbol{k}}$,
e.g., by the discrete cosine transform or some quadrature rule. However,
solving the integral in (\ref{eq:vk}) numerically for each $\boldsymbol{k}$
is expensive and slows down the COS method significantly. 

\emph{Damped COS method}: If $\boldsymbol{\alpha}\neq\boldsymbol{0}$,
we speak of the damped COS method. Assume that $v$ is integrable,
which usually can be achieved by setting $\boldsymbol{\alpha}\neq\boldsymbol{0}$.
Then we propose to approximate $v_{\boldsymbol{k}}$ by $\tilde{v}_{\boldsymbol{k}}$.
This works if $\boldsymbol{M}$ is large enough. Similar to the solution
presented in Equation (\ref{eq:ck}), the coefficients $\tilde{v}_{\boldsymbol{k}}$
are given analytically:
\begin{equation}
\tilde{v}_{\boldsymbol{k}}=\frac{1}{2^{d-1}}\sum_{\boldsymbol{s}=(1,\pm1,...,\pm1)\in\mathbb{R}^{d}}\Re\left\{ \widehat{v}\left(\frac{\pi}{2}\frac{\boldsymbol{sk}}{\boldsymbol{L}}\right)\exp\left(i\frac{\pi}{2}\boldsymbol{s}\cdot\boldsymbol{k}\right)\right\} .\label{eq:vkTilde}
\end{equation}
In finance, the function $\hat{v}$ is known explicitly for many rainbow
options, e.g., arithmetic basket options, spread options and put and
call options on the minimum or maximum of $d$ assets.

In the remainder of the article, we will prove conditions under which
the integral (\ref{eq:int}) can be approximated by the (damped) COS
method. 
\begin{rem}
In the special case that $\widehat{f}$ only takes real values, the
computational cost of the COS method can be reduced by (about) a factor
of one half, since $c_{\boldsymbol{k}}=0$ if $\sum_{h=1}^{d}k_{h}$
is odd.
\end{rem}

In order to prove the convergence of the COS method in Theorem \ref{thm:approx f}
and Corollary \ref{cor:generalCase}, we need the concept of \emph{COS-admissibility},
which is introduced in Definition \ref{def:COS_admissible} and extends
\citet[Def. 1]{junike2022precise} to the multidimensional setting. 
\begin{defn}
\label{def:COS_admissible}Let $\boldsymbol{L}=(L_{1},...,L_{d})\in\mathbb{R}_{+}^{d}$.
A function $f\in\mathcal{L}^{1}$ is called \emph{COS-admissible}
if
\[
B_{f}(\boldsymbol{L}):=\sideset{}{'}\sum_{\boldsymbol{k}\in\mathbb{N}_{0}^{d}}\frac{1}{\prod_{h=1}^{d}L_{h}}\left|\int_{\mathbb{R}^{d}\setminus[-\boldsymbol{L},\boldsymbol{L}]}f(\boldsymbol{x})e_{\boldsymbol{k}}(\boldsymbol{x})d\boldsymbol{x}\right|^{2}\to0,\quad\min_{h=1,...,d}L_{h}\to\infty.
\]
\end{defn}

By Proposition \ref{prop:COSadmissible}, it follows that bounded
densities with existing moments are COS-admissible, which indicates
that the class of $d$-dimensional, COS-admissible densities is large.
\begin{prop}
\label{prop:COSadmissible}Assume $f\in\mathcal{L}^{1}\cap\mathcal{L}^{2}$
with 
\begin{equation}
\int_{\mathbb{R}^{d}}\left|\boldsymbol{x}\right|^{2d}|f(\boldsymbol{x})|^{2}d\boldsymbol{x}<\infty.\label{eq:propBed}
\end{equation}
Then $f$ is COS-admissible. Let $\boldsymbol{L}=(L_{1},...,L_{d})\in\mathbb{R}_{+}^{d}$;
then it holds that
\begin{align}
B_{f}(\boldsymbol{L}) & \leq\Xi\int_{\mathbb{R}^{d}\setminus[-\boldsymbol{L},\boldsymbol{L}]}\prod_{h=1}^{d}\max\left\{ x_{h}^{2}L_{h}^{-2},1\right\} |f(\boldsymbol{x})|^{2}d\boldsymbol{x}\label{eq:B(L)_1}\\
 & \leq\frac{\Xi}{d\underset{h=1,...,d}{\min}L_{h}^{2d}}\int_{\mathbb{R}^{d}\setminus[-\boldsymbol{L},\boldsymbol{L}]}\left|\boldsymbol{x}\right|^{2d}|f(\boldsymbol{x})|^{2}d\boldsymbol{x}+\Xi\int_{\mathbb{R}^{d}\setminus[-\boldsymbol{L},\boldsymbol{L}]}|f(\boldsymbol{x})|^{2}d\boldsymbol{x},\label{eq:B(L)_2}
\end{align}
where $\Xi=\frac{\pi^{2}}{3}\sum_{h=1}^{d}\left(\frac{\pi^{2}}{3}+1\right)^{h-1}$.
\end{prop}

\begin{proof}
Let $\boldsymbol{L}\in\mathbb{R}_{+}^{d}$ and $\boldsymbol{j}\in\mathbb{Z}^{d}$.
It follows by Parseval's identity
\begin{align}
\int_{[2\boldsymbol{jL}-\boldsymbol{L},2\boldsymbol{jL}+\boldsymbol{L}]}|f(\boldsymbol{x})|^{2}d\boldsymbol{x}= & \sideset{}{'}\sum_{\boldsymbol{k}\in\mathbb{N}_{0}^{d}}\frac{1}{\prod_{h=1}^{d}L_{h}}\bigg|\int_{[2\boldsymbol{jL}-\boldsymbol{L},2\boldsymbol{jL}+\boldsymbol{L}]}f(\boldsymbol{x})\prod_{h=1}^{d}\underbrace{\cos\left(k_{h}\pi\frac{x_{h}-(2j_{h}L_{h}-L_{h})}{2L_{h}}\right)}_{=(-1)^{j_{h}k_{h}}\cos\left(k_{h}\pi\frac{x_{h}+L_{h}}{2L_{h}}\right)}d\boldsymbol{x}\bigg|^{2}\nonumber \\
= & \sideset{}{'}\sum_{\boldsymbol{k}\in\mathbb{N}_{0}^{d}}\frac{1}{\prod_{h=1}^{d}L_{h}}\bigg|\int_{[2\boldsymbol{jL}-\boldsymbol{L},2\boldsymbol{jL}+\boldsymbol{L}]}f(\boldsymbol{x})e_{\boldsymbol{k}}(\boldsymbol{x})d\boldsymbol{x}\bigg|^{2}.\label{eq:parseval}
\end{align}
By the Cauchy-Schwarz inequality, we obtain with $g(\boldsymbol{j}):=\prod_{h=1}^{d}\max\{|j_{h}|,1\}$,
\begin{align}
\left|\int_{\mathbb{R}^{d}\setminus[-\boldsymbol{L},\boldsymbol{L}]}f(\boldsymbol{x})e_{\boldsymbol{k}}(\boldsymbol{x})d\boldsymbol{x}\right|^{2} & =\left|\sum_{\boldsymbol{j}\in\mathbb{Z}^{d}\setminus\{\boldsymbol{0}\}}\frac{g(\boldsymbol{j})}{g(\boldsymbol{j})}\int_{[2\boldsymbol{jL}-\boldsymbol{L},2\boldsymbol{jL}+\boldsymbol{L}]}f(\boldsymbol{x})e_{\boldsymbol{k}}(\boldsymbol{x})d\boldsymbol{x}\right|^{2}\nonumber \\
 & \leq\bigg(\underbrace{\sum_{\boldsymbol{j}\in\mathbb{Z}^{d}\setminus\{\boldsymbol{0}\}}\frac{1}{(g(\boldsymbol{j}))^{2}}}_{=\Xi}\bigg)\sum_{\boldsymbol{j}\in\mathbb{Z}^{d}\setminus\{\boldsymbol{0}\}}(g(\boldsymbol{j}))^{2}\left|\int_{[2\boldsymbol{jL}-\boldsymbol{L},2\boldsymbol{jL}+\boldsymbol{L}]}f(\boldsymbol{x})e_{\boldsymbol{k}}(\boldsymbol{x})d\boldsymbol{x}\right|^{2}.\label{eq:CS}
\end{align}
The fact that $\Xi=\frac{\pi^{2}}{3}\sum_{h=1}^{d}\left(\frac{\pi^{2}}{3}+1\right)^{h-1}$
can be shown by mathematical induction over $d$. Then it follows
that
\begin{align*}
B_{f}(\boldsymbol{L}) & \overset{(\ref{eq:CS})}{\leq}\,\Xi\sum_{\boldsymbol{j}\in\mathbb{Z}^{d}\setminus\{\boldsymbol{0}\}}(g(\boldsymbol{j}))^{2}\sideset{}{'}\sum_{\boldsymbol{k}\in\mathbb{N}_{0}^{d}}\frac{1}{\prod_{h=1}^{d}L_{h}}\left|\int_{[2\boldsymbol{jL}-\boldsymbol{L},2\boldsymbol{jL}+\boldsymbol{L}]}f(\boldsymbol{x})e_{\boldsymbol{k}}(\boldsymbol{x})d\boldsymbol{x}\right|^{2}\\
 & \overset{(\ref{eq:parseval})}{=}\Xi\sum_{\boldsymbol{j}\in\mathbb{Z}^{d}\setminus\{\boldsymbol{0}\}}(g(\boldsymbol{j}))^{2}\int_{[2\boldsymbol{jL}-\boldsymbol{L},2\boldsymbol{jL}+\boldsymbol{L}]}|f(\boldsymbol{x})|^{2}d\boldsymbol{x}.
\end{align*}
For $\boldsymbol{j}\in\mathbb{Z}^{d}$ and $\boldsymbol{x}\in[2\boldsymbol{jL}-\boldsymbol{L},2\boldsymbol{jL}+\boldsymbol{L}]$,
one has $|j_{h}|\leq\frac{|x_{h}|}{L_{h}}$, $h=1,...,d$. It follows
that $(g(\boldsymbol{j)})^{2}\leq\prod_{h=1}^{d}\max\left\{ x_{h}^{2}L_{h}^{-2},1\right\} $,
which implies Inequality (\ref{eq:B(L)_1}). By Young's inequality,
it holds that 
\begin{align*}
\prod_{h=1}^{d}\left(\max\left\{ x_{h}^{2d}L_{h}^{-2d},1\right\} \right)^{\frac{1}{d}} & \leq\frac{1}{d}\sum_{h=1}^{d}\max\left\{ x_{h}^{2d}L_{h}^{-2d},1\right\} \leq\frac{\left|\boldsymbol{x}\right|^{2d}}{d\underset{h=1,...,d}{\min}L_{h}^{2d}}+1.
\end{align*}
In the last inequality, we used $\max\{a,b\}\leq a+b$ for any $a,b\geq0$
and $\sum_{h=1}^{d}x_{h}^{2d}\leq\left|\boldsymbol{x}\right|^{2d}$,
which follows from the monotonicity of the $p$-norm. Hence, Inequality
(\ref{eq:B(L)_2}) holds. Assumption (\ref{eq:propBed}) and $f\in\mathcal{L}^{2}$
imply $B_{f}(\boldsymbol{L})\to0$, $\min_{h=1,...,d}L_{h}\to\infty$.
\end{proof}
The following theorem shows that multivariate densities can be approximated
by a cosine expansion. The theorem also includes numerical uncertainty
on the Fourier transform $\widehat{f}$.
\begin{thm}
\label{thm:approx f}Assume that $f\in\mathcal{L}^{1}\cap\mathcal{L}^{2}$
is COS-admissible. Let $\vartheta:\mathbb{R}^{d}\to\mathbb{C}$ and
define $\tilde{c}_{\boldsymbol{k}}$ as in Equation (\ref{eq:ck_tilde}).
For any $\varepsilon>0$ there is a $\boldsymbol{L}\in\mathbb{R}_{+}^{d}$,
a $\boldsymbol{N}\in\mathbb{N}^{d}$ and a $\gamma>0$ such that $\left\Vert \widehat{f}-\vartheta\right\Vert _{\infty}<\gamma$
implies
\[
\left\Vert f-\sideset{}{'}\sum_{\boldsymbol{\boldsymbol{0}}\leq\boldsymbol{k}\leq\boldsymbol{N}}\tilde{c}_{\boldsymbol{k}}e_{\boldsymbol{k}}1_{[-\boldsymbol{L},\boldsymbol{L}]}\right\Vert _{2}<\varepsilon.
\]
Note that $\boldsymbol{N}$ depends on $\boldsymbol{L}$ and that
$\gamma$ depends on both $\boldsymbol{L}$ and $\boldsymbol{N}$.
\end{thm}

\begin{proof}
Define $e_{\boldsymbol{k}}^{\boldsymbol{L}}=e_{\boldsymbol{k}}1_{[-\boldsymbol{L},\boldsymbol{L}]}$.
It holds for $\boldsymbol{l},\boldsymbol{k}\in\mathbb{N}_{0}^{d}$
that
\begin{align}
\left\langle e_{\boldsymbol{k}}^{\boldsymbol{L}},e_{\boldsymbol{l}}^{\boldsymbol{L}}\right\rangle  & =\begin{cases}
2^{\Lambda(\boldsymbol{k})}\prod_{h=1}^{d}L_{h} & ,\boldsymbol{k}=\boldsymbol{l},\\
0 & ,\text{otherwise,}
\end{cases}\label{eq:ekel}
\end{align}
where $\Lambda$ is defined Section \ref{sec:Notation}. For any $\boldsymbol{L}\in\mathbb{R}_{+}^{d}$
and $\boldsymbol{N}\in\mathbb{N}^{d}$, it holds that
\begin{align*}
\left\Vert f-\sideset{}{'}\sum_{\boldsymbol{\boldsymbol{0}}\leq\boldsymbol{k}\leq\boldsymbol{N}}\tilde{c}_{\boldsymbol{k}}e_{\boldsymbol{k}}^{\boldsymbol{L}}\right\Vert _{2}\leq & \underbrace{\left\Vert f-f1_{[-\boldsymbol{L},\boldsymbol{L}]}\right\Vert _{2}}_{=:A_{1}(\boldsymbol{L})}+\underbrace{\left\Vert f1_{[-\boldsymbol{L},\boldsymbol{L}]}-\sideset{}{'}\sum_{\boldsymbol{\boldsymbol{0}}\leq\boldsymbol{k}\leq\boldsymbol{N}}a_{\boldsymbol{k}}e_{\boldsymbol{k}}^{\boldsymbol{L}}\right\Vert _{2}}_{=:A_{2}(\boldsymbol{L},\boldsymbol{N})}\\
 & +\underbrace{\left\Vert \sideset{}{'}\sum_{\boldsymbol{\boldsymbol{0}}\leq\boldsymbol{k}\leq\boldsymbol{N}}(a_{\boldsymbol{k}}-c_{\boldsymbol{k}})e_{\boldsymbol{k}}^{\boldsymbol{L}}\right\Vert _{2}}_{=:A_{3}(\boldsymbol{L},\boldsymbol{N})}+\underbrace{\left\Vert \sideset{}{'}\sum_{\boldsymbol{\boldsymbol{0}}\leq\boldsymbol{k}\leq\boldsymbol{N}}(c_{\boldsymbol{k}}-\tilde{c}_{\boldsymbol{k}})e_{\boldsymbol{k}}^{\boldsymbol{L}}\right\Vert _{2}}_{=:A_{4}(\boldsymbol{L},\boldsymbol{N})}.
\end{align*}
Further,
\begin{align*}
A_{3}(\boldsymbol{L},\boldsymbol{N})^{2} & =\sum_{\boldsymbol{\boldsymbol{0}}\leq\boldsymbol{k}\leq\boldsymbol{N}}\sum_{\boldsymbol{\boldsymbol{0}}\leq\boldsymbol{l}\leq\boldsymbol{N}}\frac{1}{2^{\Lambda(\boldsymbol{k})+\Lambda(\boldsymbol{l})}}(a_{\boldsymbol{k}}-c_{\boldsymbol{k}})(a_{\boldsymbol{l}}-c_{\boldsymbol{l}})\left\langle e_{\boldsymbol{k}}^{\boldsymbol{L}},e_{\boldsymbol{l}}^{\boldsymbol{L}}\right\rangle \leq\sideset{}{'}\sum_{\boldsymbol{k}\in\mathbb{N}_{0}^{d}}\prod_{h=1}^{d}\{L_{h}\}\left|a_{\boldsymbol{k}}-c_{\boldsymbol{k}}\right|^{2}=B_{f}(\boldsymbol{L}),
\end{align*}
see Definition \ref{def:COS_admissible}. For $\varepsilon>0$, choose
$\boldsymbol{L}\in\mathbb{R}_{+}^{d}$ such that $A_{1}(\boldsymbol{L})<\frac{\varepsilon}{4}$
and $B_{f}(\boldsymbol{L})<\big(\frac{\varepsilon}{4}\big){}^{2}$.
Hence, $A_{3}(\boldsymbol{L},\boldsymbol{N})<\frac{\varepsilon}{4}$.
Then choose $\boldsymbol{N}\in\mathbb{N}^{d}$ such that $A_{2}(\boldsymbol{L},\boldsymbol{N})<\frac{\varepsilon}{4}$.
Such $\boldsymbol{N}$ exists by classical Fourier analysis. By the
definition of $c_{\boldsymbol{k}}$ and $\tilde{c}_{\boldsymbol{k}}$,
see Equation (\ref{eq:ck}), it follows that
\begin{align*}
|c_{\boldsymbol{k}}-\tilde{c}_{\boldsymbol{k}}| & \leq\frac{1}{2^{d-1}\prod_{h=1}^{d}L_{h}}\sum_{\boldsymbol{s}=(1,\pm1,...,\pm1)\in\mathbb{R}^{d}}\left|\widehat{f}\left(\frac{\pi}{2}\frac{\boldsymbol{sk}}{\boldsymbol{L}}\right)-\vartheta\left(\frac{\pi}{2}\frac{\boldsymbol{sk}}{\boldsymbol{L}}\right)\right|\leq\frac{\left\Vert \widehat{f}-\vartheta\right\Vert _{\infty}}{\prod_{h=1}^{d}L_{h}}.
\end{align*}
Similarly to the analysis of $A_{3}$, we have
\begin{align}
A_{4}(\boldsymbol{L},\boldsymbol{N}) & ^{2}\leq\sum_{\boldsymbol{\boldsymbol{0}}\leq\boldsymbol{k}\leq\boldsymbol{N}}\prod_{h=1}^{d}\{L_{h}\}\left|c_{\boldsymbol{k}}-\tilde{c}_{\boldsymbol{k}}\right|^{2}\leq\frac{\left\Vert \widehat{f}-\vartheta\right\Vert _{\infty}^{2}}{\prod_{h=1}^{d}L_{h}}\prod_{h=1}^{d}\{N_{h}+1\}.\label{eq:A4}
\end{align}
Choose $\gamma=\frac{\varepsilon}{4}\sqrt{\prod_{h=1}^{d}L_{h}}\left(\prod_{h=1}^{d}\{N_{h}+1\}\right)^{-\frac{1}{2}}.$
Then $\left\Vert \widehat{f}-\vartheta\right\Vert _{\infty}<\gamma$
implies $A_{4}(\boldsymbol{L},\boldsymbol{N})<\frac{\varepsilon}{4}$,
which concludes the proof.
\end{proof}
Corollary \ref{cor:generalCase} provides sufficient conditions to
ensure that the COS method approximates the price of a rainbow option
within a predefined error tolerance $\varepsilon>0$, including numerical
uncertainty on $\widehat{f}$ and numerical uncertainty on the cosine
coefficients of the function of interest $v$: either because the
$v_{\boldsymbol{k}}$ are approximated by solving the integral in
Equation (\ref{eq:vk}) numerically or because $v_{\boldsymbol{k}}$
are approximated by $\tilde{v}_{\boldsymbol{k}}$ defined in Equation
(\ref{eq:vk_tilde}).
\begin{cor}
\label{cor:generalCase}(Convergence of the COS method). Let $f\in\mathcal{L}^{1}\cap\mathcal{L}^{2}$
be COS-admissible and $v:\mathbb{R}^{d}\to\mathbb{R}$ be locally
in $\mathcal{L}^{2}$; that is, $v1_{[-\boldsymbol{M},\boldsymbol{M}]}\in\mathcal{L}^{2}$
for any $\boldsymbol{M}\in\mathbb{R}_{+}^{d}$. Assume $vf\in\mathcal{L}^{1}$;
then the integral of the product of $f$ and $v$ can be approximated
by a finite sum as follows: Let $\varepsilon>0$. Let $\boldsymbol{M}\in\mathbb{R}_{+}^{d}$
and $\xi>0$ such that
\begin{equation}
\int_{\mathbb{R}^{d}\setminus[-\boldsymbol{M},\boldsymbol{M}]}\left|v(\boldsymbol{x})f(\boldsymbol{x})\right|d\boldsymbol{x}\leq\frac{\varepsilon}{3},\quad\left\Vert v1_{[-\boldsymbol{M},\boldsymbol{M}]}\right\Vert _{2}\leq\xi.\label{eq:Mgeneral}
\end{equation}
Let $\boldsymbol{L}\geq\boldsymbol{M}$ such that
\begin{equation}
\left\Vert f-f1_{[-\boldsymbol{L},\boldsymbol{L}]}\right\Vert _{2}\leq\frac{\varepsilon}{12\xi}\label{eq:L1general}
\end{equation}
and
\begin{equation}
B_{f}(\boldsymbol{L})\leq\left(\frac{\varepsilon}{12\xi}\right)^{2}.\label{eq:L2general}
\end{equation}
Choose $\boldsymbol{N}\in\mathbb{N}^{d}$ large enough, so that 
\begin{equation}
\left\Vert f1_{[-\boldsymbol{L},\boldsymbol{L}]}-\sideset{}{'}\sum_{\boldsymbol{\boldsymbol{0}}\leq\boldsymbol{k}\leq\boldsymbol{N}}a_{\boldsymbol{k}}e_{\boldsymbol{k}}1_{[-\boldsymbol{L},\boldsymbol{L}]}\right\Vert _{2}\leq\frac{\varepsilon}{12\xi}.\label{eq:Nlargeenough}
\end{equation}
For some $\vartheta:\mathbb{R}^{d}\to\mathbb{C}$ assume
\begin{equation}
\left\Vert \widehat{f}-\vartheta\right\Vert _{\infty}\leq\frac{\varepsilon}{12\xi}\frac{\sqrt{\prod_{h=1}^{d}L_{h}}}{\sqrt{\prod_{h=1}^{d}\{N_{h}+1\}}}.\label{eq:phi_tilde}
\end{equation}
Let $\eta>0$ such that $\sideset{}{'}\sum_{\boldsymbol{\boldsymbol{0}}\leq\boldsymbol{k}\leq\boldsymbol{N}}|\tilde{c}_{\boldsymbol{k}}|^{2}\leq\eta.$
Let $(\tilde{v}_{\boldsymbol{k}})_{\boldsymbol{k}\in\mathbb{N}_{0}^{d}}\subset\mathbb{R}$
such that
\begin{equation}
\sideset{}{'}\sum_{\boldsymbol{\boldsymbol{0}}\leq\boldsymbol{k}\leq\boldsymbol{N}}|\tilde{v}_{\boldsymbol{k}}-v_{\boldsymbol{k}}|^{2}\leq\frac{\varepsilon^{2}}{9\eta}.\label{eq:v_l_v_l_tilde}
\end{equation}
Then it follows that
\begin{equation}
\left|\int_{\mathbb{R}^{d}}v(\boldsymbol{x})f(\boldsymbol{x})d\boldsymbol{x}-\sideset{}{'}\sum_{\boldsymbol{\boldsymbol{0}}\leq\boldsymbol{k}\leq\boldsymbol{N}}\tilde{c}_{\boldsymbol{k}}\tilde{v}_{\boldsymbol{k}}\right|\leq\varepsilon.\label{eq:Ngeneral}
\end{equation}
\end{cor}

\begin{proof}
Define $e_{\boldsymbol{k}}^{\boldsymbol{L}}=e_{\boldsymbol{k}}1_{[-\boldsymbol{L},\boldsymbol{L}]}$.
Let $A_{1}(\boldsymbol{L})$, $A_{2}(\boldsymbol{L},\boldsymbol{N})$
and $A_{4}(\boldsymbol{L},\boldsymbol{N})$ be as in the proof of
Theorem \ref{thm:approx f}. By Inequalities (\ref{eq:A4}, \ref{eq:phi_tilde})
it follows that $A_{4}(\boldsymbol{L},\boldsymbol{N})\leq\frac{\varepsilon}{12\xi}$.
Due to $v_{\boldsymbol{k}}=\langle v1_{[-\boldsymbol{M},\boldsymbol{M}]},e_{\boldsymbol{k}}^{\boldsymbol{L}}\rangle$
and applying Theorem \ref{thm:approx f} and the Cauchy-Schwarz inequality,
we have that
\begin{align*}
\Big|\int_{\mathbb{R}^{d}}v(\boldsymbol{x}) & f(\boldsymbol{x})d\boldsymbol{x}-\sideset{}{'}\sum_{\boldsymbol{\boldsymbol{0}}\leq\boldsymbol{k}\leq\boldsymbol{N}}\tilde{c}_{\boldsymbol{k}}\tilde{v}_{\boldsymbol{k}}\Big|\\
= & \bigg|\int_{\mathbb{R}^{d}\setminus[-\boldsymbol{M},\boldsymbol{M}]}v(\boldsymbol{x})f(\boldsymbol{x})d\boldsymbol{x}+\langle v1_{[-\boldsymbol{M},\boldsymbol{M}]},f\rangle-\sideset{}{'}\sum_{\boldsymbol{\boldsymbol{0}}\leq\boldsymbol{k}\leq\boldsymbol{N}}\tilde{c}_{\boldsymbol{k}}\langle v1_{[-\boldsymbol{M},\boldsymbol{M}]},e_{\boldsymbol{k}}^{\boldsymbol{L}}\rangle-\sideset{}{'}\sum_{\boldsymbol{\boldsymbol{0}}\leq\boldsymbol{k}\leq\boldsymbol{N}}\tilde{c}_{\boldsymbol{k}}(\tilde{v}_{\boldsymbol{k}}-v_{\boldsymbol{k}})\bigg|\\
\leq & \underbrace{\int_{\mathbb{R}^{d}\setminus[-\boldsymbol{M},\boldsymbol{M}]}|v(\boldsymbol{x})f(\boldsymbol{x})|d\boldsymbol{x}}_{=:D_{1}(\boldsymbol{M})}+\Big|\Big\langle v1_{[-\boldsymbol{M},\boldsymbol{M}]},f-\sideset{}{'}\sum_{\boldsymbol{\boldsymbol{0}}\leq\boldsymbol{k}\leq\boldsymbol{N}}\tilde{c}_{\boldsymbol{k}}e_{\boldsymbol{k}}^{\boldsymbol{L}}\Big\rangle\Big|+\underbrace{\sqrt{\sideset{}{'}\sum_{\boldsymbol{\boldsymbol{0}}\leq\boldsymbol{k}\leq\boldsymbol{N}}|\tilde{v}_{\boldsymbol{k}}-v_{\boldsymbol{k}}|^{2}\sideset{}{'}\sum_{\boldsymbol{\boldsymbol{0}}\leq\boldsymbol{k}\leq\boldsymbol{N}}|\tilde{c}_{\boldsymbol{k}}|^{2}}}_{=:D_{2}(\boldsymbol{N},\boldsymbol{L},\boldsymbol{M})}\\
< & \frac{\varepsilon}{3}+\|v1_{[-\boldsymbol{M},\boldsymbol{M}]}\|_{2}\,\Big\Vert f-\sideset{}{'}\sum_{\boldsymbol{\boldsymbol{0}}\leq\boldsymbol{k}\leq\boldsymbol{N}}\tilde{c}_{\boldsymbol{k}}e_{\boldsymbol{k}}^{\boldsymbol{L}}\Big\Vert_{2}+\frac{\varepsilon}{3}\\
< & \frac{\varepsilon}{3}+\xi\left(A_{1}(\boldsymbol{L})+A_{2}(\boldsymbol{L},\boldsymbol{N})+\sqrt{B_{f}(\boldsymbol{L})}+A_{4}(\boldsymbol{L},\boldsymbol{N})\right)+\frac{\varepsilon}{3}\\
\leq & \frac{\varepsilon}{3}+\xi\left(\frac{\varepsilon}{12\xi}+\frac{\varepsilon}{12\xi}+\frac{\varepsilon}{12\xi}+\frac{\varepsilon}{12\xi}\right)+\frac{\varepsilon}{3}=\varepsilon.
\end{align*}
\end{proof}
\cite{junike2022precise} and \cite{junike2023handle} assume that
$f$ has semi-heavy tails, i.e., $f$ decays exponentially or faster.
Here, we make the same assumption in multivariate dimensions in order
to be able to estimate $\boldsymbol{M}$, $\boldsymbol{L}$ and $\boldsymbol{N}$.
\begin{defn}
A function $f:\mathbb{R}^{d}\to\mathbb{R}$ \emph{decays exponentially}
if there are $C_{1},C_{2},m>0$ such that for $|\boldsymbol{x}|>m$
 it holds that $|f(\boldsymbol{x})|\leq C_{1}e^{-C_{2}|\boldsymbol{x}|}$. 
\end{defn}

\begin{lem}
\label{lem:fMinusAkEk}Let $f\in\mathcal{L}^{1}\cap\mathcal{L}^{2}$.
Let $\boldsymbol{M},\boldsymbol{L}\in\mathbb{R}_{+}^{d}$ with $\boldsymbol{M}\leq\boldsymbol{L}$;
then it holds that
\[
\Vert f1_{[-\boldsymbol{L},\boldsymbol{L}]}-\sideset{}{'}\sum_{\boldsymbol{\boldsymbol{0}}\leq\boldsymbol{k}\leq\boldsymbol{N}}a_{\boldsymbol{k}}e_{\boldsymbol{k}}1_{[-\boldsymbol{L},\boldsymbol{L}]}\Vert_{2}^{2}\leq\int_{\mathbb{R}^{d}}|f(\boldsymbol{x})|^{2}d\boldsymbol{x}-\prod_{h=1}^{d}L_{h}\sideset{}{'}\sum_{\boldsymbol{\boldsymbol{0}}\leq\boldsymbol{k}\leq\boldsymbol{N}}|c_{\boldsymbol{k}}|^{2}+G(\boldsymbol{L}),
\]
where 
\begin{equation}
G(\boldsymbol{L}):=B_{f}(\boldsymbol{L})+2\sqrt{B_{f}(\boldsymbol{L})\int_{\mathbb{R}^{d}}|f(\boldsymbol{x})|^{2}d\boldsymbol{x}}.\label{eq:eta_l}
\end{equation}
\end{lem}

\begin{proof}
Let
\[
\phi_{\boldsymbol{k}}:=\frac{1}{\prod_{h=1}^{d}L_{h}}\int_{\mathbb{R}^{d}\setminus[-\boldsymbol{L},\boldsymbol{L}]}f(\boldsymbol{x})e_{\boldsymbol{k}}(\boldsymbol{x})d\boldsymbol{x},\quad\boldsymbol{k}\in\mathbb{N}_{0}^{d}.
\]
It holds that $c_{\boldsymbol{k}}=a_{\boldsymbol{k}}+\phi_{\boldsymbol{k}}$.
It follows by the Cauchy-Schwarz inequality that
\begin{align}
\prod_{h=1}^{d}L_{h}\sideset{}{'}\sum_{\boldsymbol{\boldsymbol{0}}\leq\boldsymbol{k}\leq\boldsymbol{N}}|c_{\boldsymbol{k}}|^{2}= & \prod_{h=1}^{d}L_{h}\left(\sideset{}{'}\sum_{\boldsymbol{\boldsymbol{0}}\leq\boldsymbol{k}\leq\boldsymbol{N}}|a_{\boldsymbol{k}}|^{2}+\sideset{}{'}\sum_{\boldsymbol{\boldsymbol{0}}\leq\boldsymbol{k}\leq\boldsymbol{N}}|\phi_{\boldsymbol{k}}|^{2}+2\sideset{}{'}\sum_{\boldsymbol{\boldsymbol{0}}\leq\boldsymbol{k}\leq\boldsymbol{N}}|\phi_{\boldsymbol{k}}||a_{\boldsymbol{k}}|\right)\nonumber \\
\leq & \prod_{h=1}^{d}L_{h}\sideset{}{'}\sum_{\boldsymbol{\boldsymbol{0}}\leq\boldsymbol{k}\leq\boldsymbol{N}}|a_{\boldsymbol{k}}|^{2}+B_{f}(\boldsymbol{L})+2\prod_{h=1}^{d}L_{h}\sqrt{\sideset{}{'}\sum_{\boldsymbol{\boldsymbol{0}}\leq\boldsymbol{k}\leq\boldsymbol{N}}|\phi_{\boldsymbol{k}}|^{2}\sideset{}{'}\sum_{\boldsymbol{\boldsymbol{0}}\leq\boldsymbol{k}\leq\boldsymbol{N}}|a_{\boldsymbol{k}}|^{2}}\nonumber \\
\overset{(\ref{eq:parseval})}{\leq} & \prod_{h=1}^{d}L_{h}\sideset{}{'}\sum_{\boldsymbol{\boldsymbol{0}}\leq\boldsymbol{k}\leq\boldsymbol{N}}|a_{\boldsymbol{k}}|^{2}+\underbrace{B_{f}(\boldsymbol{L})+2\sqrt{B_{f}(\boldsymbol{L})\int_{\mathbb{R}^{d}}|f(\boldsymbol{x})|^{2}d\boldsymbol{x}}}_{=G(\boldsymbol{L})}\label{eq:a_k_c_k}\\
\text{\ensuremath{\overset{(\ref{eq:parseval})}{\leq}}} & \int_{\mathbb{R}^{d}}|f(\boldsymbol{x})|^{2}d\boldsymbol{x}+G(\boldsymbol{L}).\label{eq:bound_ck2}
\end{align}
Hence,
\begin{align*}
\Vert f1_{[-\boldsymbol{L},\boldsymbol{L}]}-\sideset{}{'}\sum_{\boldsymbol{\boldsymbol{0}}\leq\boldsymbol{k}\leq\boldsymbol{N}}a_{\boldsymbol{k}}e_{\boldsymbol{k}}1_{[-\boldsymbol{L},\boldsymbol{L}]}\Vert_{2}^{2}\overset{(\ref{eq:ekel})}{\leq} & \prod_{h=1}^{d}L_{h}\sideset{}{'}\sum_{k_{1}>N_{1}\text{ or}\dots\text{or }k_{d}>N_{d}}|a_{\boldsymbol{k}}|^{2}\\
=\,\,\, & \prod_{h=1}^{d}L_{h}\sideset{}{'}\sum_{\boldsymbol{k}\in\mathbb{N}_{0}^{d}}|a_{\boldsymbol{k}}|^{2}-\prod_{h=1}^{d}L_{h}\sideset{}{'}\sum_{\boldsymbol{\boldsymbol{0}}\leq\boldsymbol{k}\leq\boldsymbol{N}}|a_{\boldsymbol{k}}|^{2}\\
\overset{(\ref{eq:parseval},\ref{eq:a_k_c_k})}{\leq} & \int_{\mathbb{R}^{d}}|f(\boldsymbol{x})|^{2}d\boldsymbol{x}-\prod_{h=1}^{d}L_{h}\sideset{}{'}\sum_{\boldsymbol{\boldsymbol{0}}\leq\boldsymbol{k}\leq\boldsymbol{N}}|c_{\boldsymbol{k}}|^{2}+G(\boldsymbol{L}).
\end{align*}
\end{proof}
\begin{thm}
\emph{\label{thm:(Multidimensional-COS-method}(Classical COS method:
Find $\boldsymbol{M}$ and $\boldsymbol{L}$). }Let $f\in\mathcal{L}^{1}\cap\mathcal{L}^{2}$
be a nonnegative function satisfying Inequality (\ref{eq:propBed}).
Let $v:\mathbb{R}^{d}\to\mathbb{R}$ be bounded with $\left\Vert v\right\Vert _{\infty}\in(0,\infty)$.
Let $n\geq2$ be some even number and assume the moments of $f$ of
$n^{th}-$order exist, i.e.,
\begin{equation}
m_{h}(n):=\int_{\mathbb{R}^{d}}x_{h}^{n}f(\boldsymbol{x})d\boldsymbol{x}=i^{-n}\left.\frac{\partial^{n}}{\partial u_{h}^{n}}\widehat{f}(\boldsymbol{u})\right|_{\boldsymbol{u}=\boldsymbol{0}}\in(0,\infty),\quad h=1,...,d.\label{eq:moments}
\end{equation}
Assume that $f$ decays exponentially. Let $\varepsilon>0$ be small
enough. Define
\begin{equation}
M_{h}:=\left(\frac{3d\left\Vert v\right\Vert _{\infty}}{\varepsilon}m_{h}(n)\right)^{\frac{1}{n}},\quad h=1,...,d,\label{eq:m-1-1}
\end{equation}
and $\boldsymbol{L}=\boldsymbol{M}=(M_{1},...,M_{d})\in\mathbb{R}_{+}^{d}$.
There is a $\boldsymbol{N}\in\mathbb{N}_{0}^{d}$ such that
\begin{equation}
\left|\int_{\mathbb{R}^{d}}v(\boldsymbol{x})f(\boldsymbol{x})d\boldsymbol{x}-\sideset{}{'}\sum_{\boldsymbol{\boldsymbol{0}}\leq\boldsymbol{k}\leq\boldsymbol{N}}c_{\boldsymbol{k}}v_{\boldsymbol{k}}\right|\leq\varepsilon.\label{eq:endRes}
\end{equation}
\end{thm}

\begin{cor}
\label{cor:vk_tilde_M_N}\emph{(Damped COS method: Find $\boldsymbol{M}$
and $\boldsymbol{L}$).} Assume that all assumptions in Theorem \ref{thm:(Multidimensional-COS-method}
hold and that $v\in\mathcal{L}^{1}\cap\mathcal{L}^{2}$, $v$ satisfies
Inequality (\ref{eq:propBed}) and $v$ decays exponentially. Define
$\tilde{v}_{\boldsymbol{k}}$ as in (\ref{eq:vk_tilde}). There is
a $\boldsymbol{N}\in\mathbb{N}_{0}^{d}$ such that
\begin{equation}
\left|\int_{\mathbb{R}^{d}}v(\boldsymbol{x})f(\boldsymbol{x})d\boldsymbol{x}-\sideset{}{'}\sum_{\boldsymbol{\boldsymbol{0}}\leq\boldsymbol{k}\leq\boldsymbol{N}}c_{\boldsymbol{k}}\tilde{v}_{\boldsymbol{k}}\right|\leq\varepsilon.\label{eq:endRes-1}
\end{equation}
\end{cor}

\begin{cor}
\label{cor:NrTerms}\emph{(Find $\boldsymbol{N}$).} If the assumptions
in Theorem \ref{thm:(Multidimensional-COS-method}, respectively Corollary
\ref{cor:vk_tilde_M_N}, hold and if 
\begin{equation}
\left|(2\pi)^{-d}\int_{\mathbb{R}^{d}}|\widehat{f}(\boldsymbol{u})|^{2}d\boldsymbol{u}-\prod_{h=1}^{d}L_{h}\sideset{}{'}\sum_{\boldsymbol{\boldsymbol{0}}\leq\boldsymbol{k}\leq\boldsymbol{N}}|c_{\boldsymbol{k}}|^{2}\right|\leq\frac{\varepsilon^{2}}{162\left\Vert v1_{[-\boldsymbol{M},\boldsymbol{M}]}\right\Vert _{2}^{2}}\label{eq:f_l-akek}
\end{equation}
for some $\boldsymbol{N}\in\mathbb{N}_{0}^{d}$, then Inequality (\ref{eq:endRes}),
respectively Inequality (\ref{eq:endRes-1}), is satisfied.
\end{cor}

\begin{proof}
\emph{We first prove Theorem \ref{thm:(Multidimensional-COS-method}}:
Equation (\ref{eq:moments}) follows by \citet[Thm 25.2]{bauer1996probability}.
For $h\in\{1,...,d\}$ let $\pi_{h}:\mathbb{R}^{d}\to\mathbb{R}$,
$\boldsymbol{x}\mapsto x_{h}$. Let $\lambda^{d}$ be the Lebesgue
measure on $\mathbb{R}^{d}$ and define the finite and positive measure
$\mu:=f\lambda^{d}$. By Markov's inequality, it follows that
\[
\int_{\mathbb{R}^{d}\setminus[-\boldsymbol{M},\boldsymbol{M}]}\left|v(\boldsymbol{x})f(\boldsymbol{x})\right|d\boldsymbol{x}\leq\left\Vert v\right\Vert _{\infty}\sum_{h=1}^{d}\mu\left(\left\{ \boldsymbol{x}\in\mathbb{R}^{d}:|\pi_{h}(\boldsymbol{x})|\geq M_{h}\right\} \right)\leq\left\Vert v\right\Vert _{\infty}\sum_{h=1}^{d}\frac{m_{h}(n)}{M_{h}^{n}}=\frac{\varepsilon}{3}.
\]
The last equality follows by the definition of $\boldsymbol{M}$.
Define $\xi:=\left\Vert v\right\Vert _{\infty}\sqrt{2^{d}\prod_{h=1}^{d}M_{h}}$.
It holds that $\left\Vert v1_{[-\boldsymbol{M},\boldsymbol{M}]}\right\Vert _{2}\leq\xi.$
Hence, the inequalities in (\ref{eq:Mgeneral}) are satisfied. Next,
we use the following auxiliary result: \foreignlanguage{american}{Let
$s\geq0$, $a>0$ and $n\in\mathbb{N}_{0}$ and $d\in\mathbb{N}$.
Then it holds by mathematical induction over $n$ and \citet[Theorm 8.11 ]{amann2009analysis}
that
\begin{align}
\int_{\{\boldsymbol{x}\in\mathbb{R}^{d}:|\boldsymbol{x}|>s\}}e^{-a|\boldsymbol{x}|}|\boldsymbol{x}|^{n}d\boldsymbol{x} & =\frac{d\pi^{\frac{d}{2}}}{\Gamma\left(1+\frac{d}{2}\right)}e^{-as}\frac{(n+d-1)!}{a^{n+d}}\sum_{k=0}^{n+d-1}\frac{(as)^{k}}{k!}.\label{eq:amann}
\end{align}
}For $\varepsilon$ small enough, $\boldsymbol{L}$ is large enough.
Using that $f$ decays exponentially and applying Equation (\ref{eq:amann}),
we obtain with $\ell:=\min_{h=1,...,d}L_{h}$ that
\begin{align}
\left\Vert f-f1_{[-\boldsymbol{L},\boldsymbol{L}]}\right\Vert _{2} & \leq C_{1}\sqrt{\int_{\{\boldsymbol{x}\in\mathbb{R}^{d}:|\boldsymbol{x}|>\ell\}}e^{-2C_{2}|\boldsymbol{x}|}d\boldsymbol{x}}\leq\frac{\varepsilon}{12\xi}.\label{eq:||f-f_l}
\end{align}
The last inequality holds true if $\varepsilon$ is small enough because,
thanks to Inequality (\ref{eq:amann}), the term in the middle of
(\ref{eq:||f-f_l}) decreases exponentially in $\varepsilon$, while
the term at the right-hand side of (\ref{eq:||f-f_l}) goes to zero
like $\varepsilon^{1+\frac{d}{2n}}$ for $\varepsilon\searrow0$.
Hence, Inequality (\ref{eq:L1general}) holds. By Inequality (\ref{eq:B(L)_2})
it holds that $B_{f}(\boldsymbol{L})\leq\varepsilon^{2}(12\xi)^{-2}$
if $\varepsilon$ is small enough because $B_{f}(\boldsymbol{L})$
decreases exponentially in $\varepsilon$: to see this, use Inequality
(\ref{eq:||f-f_l}) and observe that the term $\int_{\mathbb{R}^{d}\setminus[-\boldsymbol{L},\boldsymbol{L}]}\left|\boldsymbol{x}\right|^{2d}|f(\boldsymbol{x})|^{2}d\boldsymbol{x}$
converges exponentially thanks to Inequality (\ref{eq:amann}). Hence,
Inequality (\ref{eq:L2general}) holds. By classical Fourier analysis,
there is a $\boldsymbol{N}\in\mathbb{N}_{0}^{d}$ such that Inequality
(\ref{eq:Nlargeenough}) is satisfied. By assumption we have $c_{\boldsymbol{k}}=\tilde{c}_{\boldsymbol{k}}$
and $v_{\boldsymbol{k}}=\tilde{v}_{\boldsymbol{k}}$. Inequalities
(\ref{eq:phi_tilde}) and (\ref{eq:v_l_v_l_tilde}) hold trivially.
Apply Corollary \ref{cor:generalCase} to finish the proof of Theorem
\ref{thm:(Multidimensional-COS-method}.

\emph{We prove Corollary \ref{cor:vk_tilde_M_N}}: We have to show
that Inequality (\ref{eq:v_l_v_l_tilde}) holds to proof Corollary
\ref{cor:vk_tilde_M_N}. Let $G(\boldsymbol{L})$ be as in Equality
(\ref{eq:eta_l}). Observe $G(\boldsymbol{L})\to0$, $\min_{h}L_{h}\to\infty$
because $f$ is COS-admissible by Proposition \ref{prop:COSadmissible}.
There is $\boldsymbol{P}\in\mathbb{R}_{+}^{d}$ and a $\gamma>0$
such that $G(\boldsymbol{L})\leq\gamma$ for all $\boldsymbol{L}\geq\boldsymbol{P}$.
By Inequality (\ref{eq:bound_ck2}), it follows for all $\boldsymbol{N}\in\mathbb{N}^{d}$
and all $\boldsymbol{L}\geq\boldsymbol{P}$ that
\begin{equation}
\sideset{}{'}\sum_{\boldsymbol{\boldsymbol{0}}\leq\boldsymbol{k}\leq\boldsymbol{N}}|c_{\boldsymbol{k}}|^{2}\leq\frac{\int_{\mathbb{R}^{d}}|f(\boldsymbol{x})|^{2}d\boldsymbol{x}+\gamma}{\prod_{h=1}^{d}P_{h}}=:\eta<\infty.\label{eq:eta}
\end{equation}
It follows by Proposition \ref{prop:COSadmissible} for all $\boldsymbol{N}\in\mathbb{N}^{d}$
that
\begin{align}
\sideset{}{'}\sum_{\boldsymbol{\boldsymbol{0}}\leq\boldsymbol{k}\leq\boldsymbol{N}}|\tilde{v}_{\boldsymbol{k}}-v_{\boldsymbol{k}}|^{2} & \leq\sideset{}{'}\sum_{\boldsymbol{k}\in\mathbb{N}_{0}^{d}}\left|\int_{\mathbb{R}^{d}\setminus[-\boldsymbol{M},\boldsymbol{M}]}v(\boldsymbol{x})e_{\boldsymbol{k}}(\boldsymbol{x})d\boldsymbol{x}\right|^{2}\leq\prod_{h=1}^{d}M_{h}B_{v}(\boldsymbol{M})\leq\frac{\varepsilon^{2}}{9\eta}\label{eq:v_tile-vk}
\end{align}
the last inequality holds true if $\varepsilon$ is small enough because
the term $M_{h}B_{v}(\boldsymbol{M})$ decreases exponentially in
$\varepsilon$ since $v$ decays exponentially, while the right-hand
side of (\ref{eq:v_tile-vk}) goes to zero like $\varepsilon^{2}$
for $\varepsilon\searrow0$. 

\emph{We prove Corollary \ref{cor:NrTerms}}: Let $G(\boldsymbol{L})$
be defined as in Equation (\ref{eq:eta_l}). By Lemma \ref{lem:fMinusAkEk}
and the Plancherel theorem, it follows that
\begin{align}
\Vert f1_{[-\boldsymbol{L},\boldsymbol{L}]}-\sideset{}{'}\sum_{\boldsymbol{\boldsymbol{0}}\leq\boldsymbol{k}\leq\boldsymbol{N}}a_{\boldsymbol{k}}e_{\boldsymbol{k}}1_{[-\boldsymbol{L},\boldsymbol{L}]}\Vert_{2}^{2}\leq & \left|(2\pi)^{-d}\int_{\mathbb{R}^{d}}|\widehat{f}(\boldsymbol{u})|^{2}d\boldsymbol{u}-\prod_{h=1}^{d}L_{h}\sideset{}{'}\sum_{\boldsymbol{\boldsymbol{0}}\leq\boldsymbol{k}\leq\boldsymbol{N}}|c_{\boldsymbol{k}}|^{2}\right|+G(\boldsymbol{L})\nonumber \\
\leq & \frac{\varepsilon^{2}}{162\left\Vert v1_{[-\boldsymbol{M},\boldsymbol{M}]}\right\Vert _{2}^{2}}+\frac{\varepsilon^{2}}{162\left\Vert v1_{[-\boldsymbol{M},\boldsymbol{M}]}\right\Vert _{2}^{2}}=\left(\frac{\varepsilon}{9\left\Vert v1_{[-\boldsymbol{M},\boldsymbol{M}]}\right\Vert _{2}}\right)^{2}.\label{eq:fakekPlan}
\end{align}
The last inequality holds because for $\varepsilon>0$ small enough,
$\boldsymbol{L}$ is large enough so that $G(\boldsymbol{L})\leq\frac{\varepsilon^{2}}{162\left\Vert v1_{[-\boldsymbol{M},\boldsymbol{M}]}\right\Vert _{2}^{2}}$
since $G(\boldsymbol{L})$ decreases exponentially. Note that we may
replace the term $\frac{\varepsilon}{12\xi}$ in Inequalities (\ref{eq:L1general},
\ref{eq:L2general}, \ref{eq:Nlargeenough}) in Corollary \ref{cor:generalCase}
by $\frac{\varepsilon}{9\left\Vert v1_{[-\boldsymbol{M},\boldsymbol{M}]}\right\Vert _{2}}$,
since $c_{\boldsymbol{k}}=\tilde{c}_{\boldsymbol{k}}$. Apply Inequality
(\ref{eq:fakekPlan}) to conclude.
\end{proof}
Assume the density $f$ in Corollary \ref{cor:NrTerms} is the density
of a Lvy process at a particular time point and $\widehat{f}$ is
real. The next Proposition \ref{prop:real} shows that the term $(2\pi)^{-d}\int_{\mathbb{R}^{d}}|\widehat{f}(\boldsymbol{u})|^{2}d\boldsymbol{u}$
is then given in closed form if $f$ is known. The densities of many
Lvy processes are given explicitly or in terms of specialized functions,
e.g., for the tempered Stable process, the Meixner process, the Normal
Inverse Gaussian process, the Variance Gamma process and the Generalized
Hyperbolic process, see \cite{barndorff1997normal,madan1998variance,schoutens2003levy}
and references therein. In the case that $\boldsymbol{\alpha}\neq\boldsymbol{0}$,
the Fourier transform $\widehat{f}$ is usually not real. However,
in some cases, such as the normal distribution, the integral $(2\pi)^{-d}\int_{\mathbb{R}^{d}}|\widehat{f}(\boldsymbol{u})|^{2}d\boldsymbol{u}$
can still be obtained in closed form. 
\begin{prop}
\label{prop:real}Let $(\boldsymbol{X}_{t})_{t\geq0}$ be a $d$-dimensional
Lvy process. Assume that the characteristic function $\widehat{f}_{\boldsymbol{X}_{t}}$
of $\boldsymbol{X}_{t}$ is real for all $t>0$ and that $\boldsymbol{X}_{t}$
has a density, denoted by $f_{\boldsymbol{X}_{t}}$. Let $T>0$. Then
\[
(2\pi)^{-d}\int_{\mathbb{R}^{d}}|\widehat{f}_{\boldsymbol{X}_{T}}(\boldsymbol{u})|^{2}d\boldsymbol{u}=f_{\boldsymbol{X}_{2T}}(\boldsymbol{0}).
\]
\end{prop}

\begin{proof}
Using that $\boldsymbol{X}$ has independent and stationary increments
and that $\widehat{f}_{X_{T}}$ is real, it follows that
\begin{align*}
(2\pi)^{-d}\int_{\mathbb{R}^{d}}|\widehat{f}_{\boldsymbol{X}_{T}}(\boldsymbol{u})|^{2}d\boldsymbol{u}= & (2\pi)^{-d}\int_{\mathbb{R}^{d}}\big(\widehat{f}_{\boldsymbol{X}_{T}}(\boldsymbol{u})\big)^{2}d\boldsymbol{u}=(2\pi)^{-d}\int_{\mathbb{R}^{d}}\widehat{f}_{\boldsymbol{X}_{2T}}(\boldsymbol{u})d\boldsymbol{u}=f_{\boldsymbol{X}_{2T}}(\boldsymbol{0}).
\end{align*}
\end{proof}
\begin{rem}
\label{rem:lessStable}Provided the expression $(2\pi)^{-d}\int_{\mathbb{R}^{d}}|\widehat{f}(\boldsymbol{u})|^{2}d\boldsymbol{u}$
can be obtained precisely, Inequality (\ref{eq:f_l-akek}) makes it
possible to define a stopping criterion for $\boldsymbol{N}$. In
particular, Inequality (\ref{eq:f_l-akek}) enables us to determine
$\boldsymbol{N}$ \emph{while} computing the coefficients $c_{\boldsymbol{k}}$:
incrementally increase $\boldsymbol{N}$ and compute $|c_{\boldsymbol{k}}|$
and $|c_{\boldsymbol{k}}|^{2}$ simultaneously. Stop when Inequality
(\ref{eq:f_l-akek}) is met. However, since the right-hand side of
Equation (\ref{eq:f_l-akek}) converges to zero at least like $O\left(\varepsilon^{2}\right)$,
rounding off errors makes it difficult to find $\boldsymbol{N}$ by
Inequality (\ref{eq:f_l-akek}) for very small $\varepsilon$. Using
arbitrary-precision arithmetic instead of fixed-precision arithmetic
should overcome this drawback.
\end{rem}

The next theorem implies that the COS method converges exponentially
if $\widehat{f}$ decays exponentially, i.e., if Inequality (\ref{eq:f_hat_p})
holds for all $p>0$. The cases (i) and (ii) in Theorem \ref{thm:order of convergence}
treat the classical and the damped COS method, respectively. The bound
for the order of convergence of the damped COS method is slightly
better.
\begin{thm}
\label{thm:order of convergence}(Order of convergence). Assume $f\in\mathcal{L}^{1}\cap\mathcal{L}^{2}$
satisfies Inequality (\ref{eq:propBed}) and decays exponentially.
Assume $v$ is bounded. Let $\gamma>0$ and $\beta\in(0,1)$. For
$n\in\mathbb{N}$, let \textbf{$\boldsymbol{N}=(n,...,n)\in\mathbb{N}^{d}$}
and $\boldsymbol{M}=\boldsymbol{L}=(\gamma n^{\beta},...,\gamma n^{\beta}).$
Assume for some $p>\frac{d}{2}$ that
\begin{equation}
|\widehat{f}(\boldsymbol{u})|\leq O\left(|\boldsymbol{u}|_{\infty}^{-p}\right),\quad|\boldsymbol{u}|_{\infty}\to\infty.\label{eq:f_hat_p}
\end{equation}
(i) Define $v_{\boldsymbol{k}}$ as in Equation (\ref{eq:vk}). Then
it holds that
\[
\left|\int_{\mathbb{R}^{d}}v(\boldsymbol{x})f(\boldsymbol{x})d\boldsymbol{x}-\sideset{}{'}\sum_{\boldsymbol{\boldsymbol{0}}\leq\boldsymbol{k}\leq\boldsymbol{N}}c_{\boldsymbol{k}}v_{\boldsymbol{k}}\right|\leq O\bigg(n^{-(1-\beta)p+\frac{d}{2}}\bigg),\quad n\to\infty.
\]
(ii) Assume that $v\in\mathcal{L}^{1}\cap\mathcal{L}^{2}$, $v$ satisfies
Inequality (\ref{eq:propBed}) and $v$ decays exponentially. Define
$\tilde{v}_{\boldsymbol{k}}$ as in Equation (\ref{eq:vk_tilde}).
Then it holds that
\[
\left|\int_{\mathbb{R}^{d}}v(\boldsymbol{x})f(\boldsymbol{x})d\boldsymbol{x}-\sideset{}{'}\sum_{\boldsymbol{\boldsymbol{0}}\leq\boldsymbol{k}\leq\boldsymbol{N}}c_{\boldsymbol{k}}\tilde{v}_{\boldsymbol{k}}\right|\leq O\bigg(n^{-(1-\beta)(p-\frac{d}{2})}\bigg),\quad n\to\infty.
\]
\end{thm}

\begin{proof}
Let $A_{1}(\boldsymbol{L})$, $A_{2}(\boldsymbol{L},\boldsymbol{N})$,
$D_{1}(\boldsymbol{M})$ and $D_{2}(\boldsymbol{N},\boldsymbol{L},\boldsymbol{M})$
be as in the proof of Corollary \ref{cor:generalCase}. Since $v_{\boldsymbol{k}}=\langle v1_{[-\boldsymbol{M},\boldsymbol{M}]},e_{\boldsymbol{k}}^{\boldsymbol{L}}\rangle$
and similarly to the proof of Corollary \ref{cor:generalCase} we
have that
\begin{align}
 & \bigg|\int_{\mathbb{R}^{d}}v(\boldsymbol{x})f(\boldsymbol{x})d\boldsymbol{x}-\sideset{}{'}\sum_{\boldsymbol{\boldsymbol{0}}\leq\boldsymbol{k}\leq\boldsymbol{N}}c_{\boldsymbol{k}}\tilde{v}_{\boldsymbol{k}}\bigg|\nonumber \\
\leq & D_{1}(\boldsymbol{M})+\|v1_{[-\boldsymbol{M},\boldsymbol{M}]}\|_{2}\,\bigg(A_{1}(\boldsymbol{L})+A_{2}(\boldsymbol{L},\boldsymbol{N})+\sqrt{B_{f}(\boldsymbol{L})}\bigg)+D_{2}(\boldsymbol{N},\boldsymbol{L},\boldsymbol{M}).\label{dsd}
\end{align}
We will analyze the order of convergence of each term at the right-hand
side of Inequality (\ref{dsd}): Since $v$ is bounded and $f$ decays
exponentially, $D_{1}(\boldsymbol{M})$, $A_{1}(\boldsymbol{L})$
and $\sqrt{B_{f}(\boldsymbol{L})}$ decay exponentially, i.e., can
be bounded by $O\big(\exp(-C_{3}n^{\beta})\big),$ $n\to\infty$,
for some $C_{3}$, see proof of Theorem \ref{thm:(Multidimensional-COS-method}.
By Inequality (\ref{eq:eta}), the term $\sideset{}{'}\sum|c_{\boldsymbol{k}}|^{2}$
is bounded. In case i), $D_{2}(\boldsymbol{N},\boldsymbol{L},\boldsymbol{M})=0$.
In case ii), $D_{2}(\boldsymbol{N},\boldsymbol{L},\boldsymbol{M})$
decays exponentially, see proof of Corollary \ref{cor:vk_tilde_M_N}.
Last, we treat $A_{2}(\boldsymbol{L},\boldsymbol{N})$. Let $j\in\{1,...,d\}$.
Let $n$ be large enough. Let $\boldsymbol{k}\in\mathbb{N}_{0}^{d}$
such that $k_{j}>n$. By Equation (\ref{eq:ck}) and Inequality (\ref{eq:f_hat_p}),
there is a constant $a_{1}>0$ so that
\begin{align*}
|c_{\boldsymbol{k}}|^{2}\overset{(\ref{eq:ck})}{\leq}\bigg(\frac{1}{2^{d-1}\prod_{h=1}^{d}L_{h}}\sum_{\boldsymbol{s}=(1,\pm1,...,\pm1)\in\mathbb{R}^{d}}\bigg|\widehat{f}\left(\frac{\pi}{2}\frac{\boldsymbol{sk}}{\boldsymbol{L}}\right)\bigg|\bigg)^{2}\overset{(\text{\ref{eq:f_hat_p}})}{\leq} & a_{1}n^{2\beta(p-d)}|\boldsymbol{k}|_{\infty}^{-2p}.
\end{align*}
By mathematical induction over $d$ and the applying the integral
test of convergence, one can show that
\begin{align}
\sum_{\boldsymbol{k}\in\mathbb{N}_{0}^{d},k_{j}>n}|\boldsymbol{k}|_{\infty}^{-2p} & \leq\frac{2^{d-1}}{(2p-d)n^{2p-d}}.\label{eq:induction}
\end{align}
It follows by Inequality (\ref{eq:induction}) for some $a_{2}>0$
that
\begin{align}
\prod_{h=1}^{d}L_{h}\sum_{\boldsymbol{k}\in\mathbb{N}_{0}^{d},k_{j}>n}|c_{\boldsymbol{k}}|^{2}\leq & a_{2}n^{-(1-\beta)(2p-d)}.\label{eq:k_j_N_j}
\end{align}
Let \textbf{$G(\boldsymbol{L})$ }be defined as in Equality (\ref{eq:eta_l}).
By Equality (\ref{eq:ekel}), the Cauchy-Schwarz (CS) inequality and
Inequality (\ref{eq:bound_ck2}), we obtain
\begin{align*}
A_{2}(\boldsymbol{L},\boldsymbol{N})^{2}\overset{(\ref{eq:ekel})}{\leq} & \prod_{h=1}^{d}L_{h}\sideset{}{'}\sum_{k_{1}>N_{1}\text{ or}\dots\text{or }k_{d}>N_{d}}|a_{\boldsymbol{k}}+c_{\boldsymbol{k}}-c_{\boldsymbol{k}}|^{2}\\
\overset{(\text{CS})}{\leq} & \prod_{h=1}^{d}L_{h}\sideset{}{'}\sum_{k_{1}>N_{1}\text{ or}\dots\text{or }k_{d}>N_{d}}|c_{\boldsymbol{k}}|^{2}+\prod_{h=1}^{d}L_{h}\sideset{}{'}\sum_{\boldsymbol{k}\in\mathbb{N}_{0}^{d}}|a_{\boldsymbol{k}}-c_{\boldsymbol{k}}|^{2}\\
 & +2\sqrt{\prod_{h=1}^{d}L_{h}\sideset{}{'}\sum_{\boldsymbol{k}\in\mathbb{N}_{0}^{d}}|c_{\boldsymbol{k}}|^{2}\prod_{h=1}^{d}L_{h}\sideset{}{'}\sum_{\boldsymbol{k}\in\mathbb{N}_{0}^{d}}|a_{\boldsymbol{k}}-c_{\boldsymbol{k}}|^{2}}\\
\overset{(\ref{eq:bound_ck2})}{\leq} & \sum_{j=1}^{d}\bigg(\prod_{h=1}^{d}L_{h}\sum_{\boldsymbol{k}\in\mathbb{N}_{0}^{d},k_{j}>n}|c_{\boldsymbol{k}}|^{2}\bigg)+B_{f}(\boldsymbol{L})+2\sqrt{\left(\int_{\mathbb{R}^{d}}|f(\boldsymbol{x})|^{2}d\boldsymbol{x}+G(\boldsymbol{L})\right)B_{f}(\boldsymbol{L})}\\
\overset{(\ref{eq:k_j_N_j})}{\leq} & O\left(n^{-(1-\beta)(2p-d)}\right),\quad n\to\infty,
\end{align*}
since $B_{f}(\boldsymbol{L})$ and $G(\boldsymbol{L})$, converge
exponentially to zero. Since $v$ is bounded, we have that $\|v1_{[-\boldsymbol{M},\boldsymbol{M}]}\|_{2}\leq O\left(n^{\frac{d\beta}{2}}\right)$,
$n\to\infty$. Noting that $\frac{-(1-\beta)(2p-d)+d\beta}{2}=-(1-\beta)p+\frac{d}{2}$,
shows (i). It holds $\|v1_{[-\boldsymbol{M},\boldsymbol{M}]}\|_{2}\leq\|v\|_{2}$
if $v\in\mathcal{L}_{2}$, which implies (ii).
\end{proof}

\section{\label{sec:Characteristic-functions}Characteristic functions}

In this section, in Examples \ref{exa:(Normal-distribution).-Let}
and \ref{exa:(Variance-Gamma-distribution).}, we recall the normal
and the Variance Gamma distributions from the literature. Remark \ref{rem:In-a-financial}
and Examples \ref{rem:BS} and \ref{rem:VG} provide a financial context.
\begin{example}
\label{exa:(Normal-distribution).-Let}(Normal distribution). Let
$\boldsymbol{X}$ be a multivariate normal random variable with location
$\boldsymbol{\eta}\in\mathbb{R}^{d}$ and covariance matrix $\Sigma\in\mathbb{R}^{d}\times\mathbb{R}^{d}$.
The random variable $\boldsymbol{X}$ has characteristic function
$\widehat{g}(\boldsymbol{u})=\exp\left(i\boldsymbol{\eta}\cdot\boldsymbol{u}-\frac{1}{2}\boldsymbol{u}\cdot\Sigma\boldsymbol{u}\right)$,
$\boldsymbol{u}\in\mathbb{R}^{d}$, which can be extended to $\mathbb{C}^{d}$,
i.e., $\widehat{g}(\boldsymbol{u}-i\boldsymbol{\alpha})$ exists for
all $\boldsymbol{\alpha}\in\mathbb{R}^{d}$. By Proposition \ref{prop:centr}
we set $\lambda=\exp\left(-\boldsymbol{\eta}\cdot\boldsymbol{\alpha}-\frac{1}{2}\boldsymbol{\alpha}\cdot\Sigma\boldsymbol{\alpha}\right)$
and $\boldsymbol{\mu}=\boldsymbol{\eta}+\Sigma\boldsymbol{\alpha}$.
The characteristic function of the damped density $f$, defined in
Equation (\ref{eq:dampedf}), is given by $\widehat{f}(\boldsymbol{u})=\exp\left(-\frac{1}{2}\boldsymbol{u}\cdot\Sigma\boldsymbol{u}\right)$.
A straightforward computation shows that
\begin{align*}
(2\pi)^{-d}\int_{\mathbb{R}^{d}}|\widehat{f}(\boldsymbol{u})|^{2}d\boldsymbol{u} & =\frac{2^{-d}}{\sqrt{\pi{}^{d}\det(\Sigma)}}.
\end{align*}
\end{example}

\begin{example}
\label{exa:(Variance-Gamma-distribution).}(Variance Gamma distribution).
Let $\boldsymbol{Z}$ be a $d$-dimensional, standard normal random
variable. Let $G$ be a Gamma distributed random variable, independent
of $\boldsymbol{Z}$, with shape $a>0$ and scale $s>0$. Let $\boldsymbol{\eta},\boldsymbol{\theta}\in\mathbb{R}^{d}$
and $\boldsymbol{\sigma}\in\mathbb{R}_{+}^{d}$. Consider $\boldsymbol{X}=\boldsymbol{\eta}+\boldsymbol{\theta}G+\sqrt{G}\boldsymbol{\sigma}\boldsymbol{Z}$.
The distribution of $\boldsymbol{X}$ is denoted by $\text{VG}(a,s,\boldsymbol{\eta},\boldsymbol{\theta},\boldsymbol{\sigma})$.
Define $\Sigma\in\mathbb{R}^{d}\times\mathbb{R}^{d}$ such that $\Sigma_{ii}=\sigma_{i}^{2}$
and $\Sigma_{ij}=0$ for $i\neq j$. Then $\boldsymbol{X}$ has the
characteristic function

\[
\widehat{g}(\boldsymbol{u})=\exp\left(i\boldsymbol{\eta}\cdot\boldsymbol{u}\right)\big(1-is\boldsymbol{\theta}\cdot\boldsymbol{u}+\frac{1}{2}s\boldsymbol{u}\cdot\Sigma\boldsymbol{u}\big)^{-a},
\]
see \citet{luciano2006multivariate}. The (extended) Fourier transform
$\widehat{g}(\boldsymbol{u}-i\boldsymbol{\alpha})$ exists for all
$\boldsymbol{\alpha}\in\mathbb{R}^{d}$ with $\zeta:=1-s\boldsymbol{\theta}\cdot\boldsymbol{\alpha}-\frac{1}{2}s\boldsymbol{\alpha}\cdot\Sigma\boldsymbol{\alpha}>0$,
see \citet{bayer2022optimal}. By Proposition \ref{prop:centr} we
set $\lambda=\exp\left(-\boldsymbol{\eta}\cdot\boldsymbol{\alpha}\right)\zeta^{a}$
and $\boldsymbol{\mu}=\boldsymbol{\eta}+as\zeta^{-1}(\boldsymbol{\theta}+\Sigma\boldsymbol{\alpha})$.
The characteristic function of the damped density $f$, defined in
Equation (\ref{eq:dampedf}), is given by 
\begin{align*}
\widehat{f}(\boldsymbol{u})= & \exp\left(-i\frac{as}{\zeta}\big(\boldsymbol{\theta}+\Sigma\boldsymbol{\alpha}\big)\cdot\boldsymbol{u}\right)\left(1-i\frac{s}{\zeta}\big(\boldsymbol{\theta}+\Sigma\boldsymbol{\alpha}\big)\cdot\boldsymbol{u}+\frac{1}{2}\frac{s}{\zeta}\boldsymbol{u}\cdot\Sigma\boldsymbol{u}\right)^{-a}.
\end{align*}
Apply the Courant--Fischer--Weyl min-max principle\footnote{We thank Alexey Chernov for pointing this out to us.}
to see that $|\widehat{f}(\boldsymbol{u})|\leq O\left(|\boldsymbol{u}|_{\infty}^{-2a}\right)$
for $|\boldsymbol{u}|_{\infty}\to\infty$.
\end{example}

\begin{rem}
\label{rem:In-a-financial}In a financial context, we model $d$ stock
prices over time by a $d$-dimensional positive semimartingale $(\boldsymbol{S}(t))_{t\geq0}$
on a filtered probability space $(\Omega,\mathcal{F},P,(\mathcal{F}_{t})_{t\geq0})$.
The filtration $(\mathcal{F}_{t})_{t\geq0}$ satisfies the usual conditions
with $\mathcal{F}_{0}=\{\Omega,\emptyset\}$. The logarithmic returns
are defined by $\boldsymbol{X}(t):=\log(\boldsymbol{S}(t))$, $t\geq0$.
There is a bank account paying continuous compound interest $r\in\mathbb{R}$.
There is a European rainbow option $w:\mathbb{R}^{d}\to\mathbb{R}$
with maturity $T>0$ and payoff $w\big(\boldsymbol{X}(T)\big)$ at
time $T$. We denote by $g$ the (risk-neutral) density of $\log(\boldsymbol{S}(T))$.
The time-0 price of the European option with payoff $w$ is then given
by $e^{-rT}\int_{\mathbb{R}}w(\boldsymbol{x})g(\boldsymbol{x})d\boldsymbol{x}.$
This integral can be approximated by the (damped) COS method.
\end{rem}

\begin{example}
\label{rem:BS}(BS model). Let $\Sigma\in\mathbb{R}^{d}\times\mathbb{R}^{d}$
be a symmetric positive definite matrix. For the Black-Scholes (BS)
model, the logarithmic returns $\boldsymbol{X}(T)$ are normally distributed
with location $\boldsymbol{\eta}:=\log(\boldsymbol{S}(0))+(\boldsymbol{r}-\frac{1}{2}\text{diag}(\Sigma))T$
and covariance matrix $T\Sigma$, where $\boldsymbol{r}=(r,...,r)\in\mathbb{R}^{d}$
and $\text{diag}(\Sigma)\in\mathbb{R}^{d}$ denotes the diagonal of
$\Sigma$.
\end{example}

\begin{example}
\label{rem:VG}(VG model). Let $\nu>0$, $\boldsymbol{\sigma}\in\mathbb{R}_{+}^{d}$
and $\boldsymbol{\theta}\in\mathbb{R}^{d}$. In the multivariate Variance
Gamma (VG) model, see \citet{luciano2006multivariate}, the logarithmic
returns $\boldsymbol{X}(T)$ follow a $\text{VG}(\frac{T}{\nu},\nu,\boldsymbol{\eta},\boldsymbol{\theta},\boldsymbol{\sigma})$
distribution, where
\[
\eta_{h}:=\log(S_{h}(0))+\big(r+\frac{1}{\nu}\log\big(1-\frac{1}{2}\sigma_{h}^{2}\nu-\theta_{h}\nu\big)\big)T,\quad h=1,\dots,d.
\]
\end{example}


\section{\label{sec:Functions-of-interest}Functions of interest}
\begin{example}
(Absolute moment). Assume for simplicity that $d=1$. Let $w(x)=|x|=w^{+}(x)+w^{-}(x)$,
where $w^{+}(x)=\max(x,0)$ and $w^{-}(x)=\max(-x,0)$. The integral
in (\ref{eq:int}) is equal to the absolute moment of the density
$g$. The coefficients $v_{\boldsymbol{k}}$, defined in Equation
(\ref{eq:vk}), can be obtained in closed form for any $\alpha\in\mathbb{R}$
by a computer algebra system. One may approximate the positive and
the negative part of $w$ separately by the COS method, using $\alpha>0$
for $w^{+}$ and $\alpha<0$ for $w^{-}$, to ensure that the damped
functions of interest, $v^{\pm}$, are bounded, respectively.
\end{example}

\begin{example}
\label{exa:CDF}(CDF). Let $w(\boldsymbol{x})=1_{(-\boldsymbol{\infty},\boldsymbol{y}]}(\boldsymbol{x})$,
$\boldsymbol{x}\in\mathbb{R}^{d}$ for some $\boldsymbol{y}\in\mathbb{R}^{d}$.
The integral in (\ref{eq:int}) is equal to the CDF of the density
$g$ evaluated at $\boldsymbol{y}$. The coefficients $v_{\boldsymbol{k}}$,
defined in Equation (\ref{eq:vk}), can be obtained in closed form
if $\boldsymbol{\alpha}=\boldsymbol{0}$. Let $\boldsymbol{M},\boldsymbol{L}\in\mathbb{R}_{+}^{d}$
as in Section \ref{sec:Damped-COS-method}. Let $\gamma_{h}:=\min(y_{h}-\mu_{h},M_{h})$,
$h=1,..,d$. It holds for $\boldsymbol{k}\in\mathbb{N}_{0}^{d}$ that
$v_{\boldsymbol{k}}=0$ if $\gamma_{h}<-M_{h}$ for any $h$, and
otherwise
\begin{align*}
v_{\boldsymbol{k}} & =\lambda^{-1}\prod_{\underset{k_{h}=0}{h=1}}^{d}\{\gamma_{h}+M_{h}\}\prod_{\underset{k_{h}>0}{h=1}}^{d}\bigg\{\frac{2L_{h}}{\pi k_{h}}\bigg(\sin\big(k_{h}\pi\frac{\gamma_{h}+L_{h}}{2L_{h}}\big)-\sin\big(k_{h}\pi\frac{-M_{h}+L_{h}}{2L_{h}}\big)\bigg)\bigg\}.
\end{align*}
It holds that $\left\Vert v\right\Vert _{\infty}\leq1$ and $\left\Vert v1_{[-\boldsymbol{M},\boldsymbol{M}]}\right\Vert _{2}^{2}\leq2^{d}\prod_{h=1}^{d}M_{h}$.
\end{example}

Next, we assume for some $\boldsymbol{\alpha}\in\mathbb{R}^{d}$ that
the map $\boldsymbol{x}\mapsto w(\boldsymbol{x})e^{-\boldsymbol{\alpha}\cdot\boldsymbol{x}}$
is integrable. The Fourier-transform of $w$ then exists at all points
$\boldsymbol{u}+i\boldsymbol{\alpha}\in\mathbb{C}^{d}$, $\boldsymbol{u}\in\mathbb{R}^{d}$.
Let $\lambda>0$ and $\boldsymbol{\mu}\in\mathbb{R}^{d}$. Let $v$
be as in Equation (\ref{eq:dampedv}). The Fourier-transform of $v$
is given by $\widehat{v}(\boldsymbol{u})=\lambda^{-1}e^{-i\boldsymbol{u}\cdot\boldsymbol{\mu}}\widehat{w}(\boldsymbol{u}+i\boldsymbol{\alpha})$.
Hence, a closed form expression for $\widehat{w}$ is sufficient to
obtain a closed form expression for $\widehat{v}$. We can then directly
obtain $\tilde{v}_{\boldsymbol{k}}$, defined in Equation (\ref{eq:vk_tilde})
via Equation (\ref{eq:vkTilde}). For many functions of interest,
$\widehat{w}$ is known in closed form in $d$ dimensions. We provide
some examples from finance, where the integral in (\ref{eq:int})
is then interpreted as a price: Digital cash-or-nothing put options
and arithmetic basket options are discussed in Examples \ref{exa:CDF}
and \ref{exa:w_hat_basket}, respectively. For put and call options
on the maximum or minimum of $d$ assets, see \cite{eberlein2010analysis};
for spread options, see \cite{hurd2010fourier}. 

Note that a digital cash-or-nothing put option with strike $\boldsymbol{K}$
is equal to the CDF of the density $g$ evaluated at $\log(\boldsymbol{K})$.
We include Example \ref{exa:(Digital-cash-or-nothing-put} in Section
\ref{sec:Numerical} to test the damped COS method for $\boldsymbol{\alpha}\neq\boldsymbol{0}$.
\begin{example}
\label{exa:(Digital-cash-or-nothing-put}(Digital cash-or-nothing
put option). The payoff function of a cash-or-nothing put option is
defined by $w(\boldsymbol{x})=1_{[0,\boldsymbol{K}]}(e^{\boldsymbol{x}})$,
$\boldsymbol{x}\in\mathbb{R}^{d}$ for some strikes $\boldsymbol{K}\in\mathbb{R}_{+}^{d}$;
compare with Remark \ref{rem:In-a-financial}. The option pays $1\$$
at maturity if $\boldsymbol{S}(T)\leq\boldsymbol{K}$ and nothing
otherwise. The integral $\int w(\boldsymbol{x})g(\boldsymbol{x})d\boldsymbol{x}$
is equal to $G\big(\log(\boldsymbol{K})\big)$, where $G$ is the
CDF of $g$. A simple calculation shows that the Fourier-transform
of $w$ exists for $\boldsymbol{z}\in\mathbb{C}^{d}$ such that $\Im\{z_{h}\}<0$,
$h=1,...,d$, and is given by $\widehat{w}(\boldsymbol{z})=\prod_{h=1}^{d}\frac{K_{h}^{iz_{h}}}{iz_{h}}.$
For $\lambda>0$ and $\boldsymbol{\mu}\in\mathbb{R}^{d}$, let $v$
be as in Equation (\ref{eq:dampedv}). It holds for $\boldsymbol{\alpha}<\boldsymbol{0}$
that $\left\Vert v\right\Vert _{\infty}\leq\lambda^{-1}e^{-\boldsymbol{\alpha}\cdot\log(\boldsymbol{K})}$
and
\begin{align*}
\left\Vert v\right\Vert _{2}^{2} & =\lambda^{-2}\prod_{h=1}^{d}\frac{\exp\left(-2\alpha_{h}\big(\log(K_{h})\big)\right)}{-2\alpha_{h}}.
\end{align*}
 
\end{example}

\begin{example}
\label{exa:w_hat_basket}(Arithmetic basket put option). The payoff
function of an arithmetic  basket put option is defined by $w(\boldsymbol{x})=\max(K-\sum_{h=1}^{d}e^{x_{h}},0)$,
$\boldsymbol{x}\in\mathbb{R}^{d}$ for some strike $K>0$; compare
with Remark \ref{rem:In-a-financial}. The Fourier-transform of $w$
exists for $\boldsymbol{z}\in\mathbb{C}^{d}$ such that $\Im\{z_{h}\}<0$,
$h=1,...,d$, and is given by
\begin{align}
\widehat{w}(\boldsymbol{z}) & =\int_{\mathbb{R}^{d}}e^{i\boldsymbol{z}\cdot\boldsymbol{x}}w(\boldsymbol{x})d\boldsymbol{x}=\frac{K^{(1+i\sum_{h=1}^{d}z_{h})}\prod_{h=1}^{d}\Gamma(iz_{h})}{\Gamma\bigg(i\sum_{h=1}^{d}z_{h}+2\bigg)}.\label{eq:w_fourier_basket}
\end{align}
Equation (\ref{eq:w_fourier_basket}) follows by an elementary substitution\footnote{We thank Friedrich Hubalek from TU Wien for pointing this out to us.}
from \citet[Eq. (5.14.1)]{olver2010nist} and is also mentioned in
a similar form in \cite{hubalek2003variance}. If $\boldsymbol{\alpha}<\boldsymbol{0}$,
it holds that $\left\Vert v\right\Vert _{\infty}\leq\lambda^{-1}K^{1-\sum_{h=1}^{d}\alpha_{h}}$
and, using \citet[Eq. (5.14.1)]{olver2010nist} once more, it follows
that
\[
\left\Vert v1_{[-\boldsymbol{M},\boldsymbol{M}]}\right\Vert _{2}^{2}\leq\left\Vert v\right\Vert _{2}^{2}\leq\frac{K^{2-2\sum_{h=1}^{d}\alpha_{h}}}{\lambda^{2}}\frac{\prod_{h=1}^{d}\Gamma\big(-2\alpha_{h}\big)}{\Gamma\big(1+\sum_{h=1}^{d}(-2\alpha_{h})\big)}.
\]
If $d=1$ and $\alpha=0$, we have that $\left\Vert v\right\Vert _{\infty}\leq K$
and $\left\Vert v1_{[-M,M]}\right\Vert _{2}^{2}\leq2MK^{2}$.
\end{example}


\section{\label{sec:Numerical}Numerical experiments}

We provide several numerical experiments to solve the integral in
(\ref{eq:int}) using the COS method. Reference values are obtained
by \citet[Theorem 3.2]{eberlein2010analysis}, who express the integral
in (\ref{eq:int}) by another integral involving the Fourier-transforms
$\widehat{g}$ and $\widehat{w}$. \citet{eberlein2010analysis} require
a damping factor, which we set to $\boldsymbol{R}=(-4,\dots,-4)$.
To compute the reference values, we use the command \emph{cubintegrate
}with the method \emph{cuhre} from the R-package \emph{cubature} with
relative tolerance $10^{-11}$. We confirm all reference values using
the COS method with $\boldsymbol{N}=(2000,\dots,2000)$ and a truncation
range obtained from Equation (\ref{eq:m-1-1}) with $\varepsilon=10^{-9}$
using $n=8$ moments. For the normal distribution, in the uncorrelated
case, reference values are also given in closed form for a CDF and
a digital cash-or-nothing put option. All experiments are performed
on a modern laptop with Intel i7-11850H processor and 32 GB RAM. The
COS method and Monte Carlo simulations are implemented in C++ using
for-loops without parallelization. The memory requirements are minimal.

First, we investigate the influence of the damping factor $\boldsymbol{\alpha}$
on the accuracy of the COS method to obtain the price of a cash-or-nothing
put option with strike $\boldsymbol{K}\in\mathbb{R}_{+}^{d}$ in the
BS model, which is just the CDF of a normal distribution evaluated
at $\log(\boldsymbol{K})$; hence, reference values can be obtained
in closed form. Figure \ref{fig:alpha} shows the behavior of the
COS method for different damping factors in dimensions $d\in\{2,3,4\}$.
If $\boldsymbol{\alpha}$ is too close to zero, almost no damping
takes place and the difference between $v_{\boldsymbol{k}}$ and $\tilde{v}_{\boldsymbol{k}}$
is large, which implies a relatively high error for the COS method.
If $|\boldsymbol{\alpha}|$ is too big, $\left\Vert v\right\Vert _{\infty}$
and $\left\Vert v\right\Vert _{2}$ become very large and the truncation
error increases. However, we observe in the example that a wide range
of damping factors work well in various dimensions. Further, fixing
the number of terms $\boldsymbol{N}$ and the truncation range $\boldsymbol{L}$,
the accuracy of the classical COS method with $\boldsymbol{\alpha}=\boldsymbol{0}$
and the damped COS method with $\boldsymbol{\alpha}\neq\boldsymbol{0}$
is very similar for some damping factors. 

We illustrate the order of convergence of the COS method for an arithmetic
basket put option in the VG model. We compare three different maturities.
In Figure \ref{fig:alpha} we can see that the theoretical bound from
Theorem \ref{thm:order of convergence} for the order of convergence
is sharp and close to the empirical order of convergence. 

% Figure environment removed


\subsection{On the choice of $\boldsymbol{N}$}

In this section, we approximate the CDF for the VG distribution and
the price of an arithmetic put option in the BS model (normal distribution).
We also discuss (see Table \ref{tab:Nopt}) arithmetic put options
in one-dimension, which are referred to simply as \emph{put options}.
No damping is necessary to price these options using the COS method,
see \citet{fang2009novel}. The methodology can also be applied to
other rainbow options or functions of interest. We compare different
strategies to choose the number of terms $\boldsymbol{N}$. For $d=1$
we also consider the bound for $N$ from \citet[Theorem 3.8]{junike2023handle},
which can be obtained as follows: If the (damped) density $f$ is
$J+1$ times differentiable with bounded derivatives, the number of
terms can be chosen by 

\begin{equation}
N\geq\left(\frac{2^{s+\frac{5}{2}}\left\Vert f^{(s+1)}\right\Vert _{\infty}L^{s+2}}{s\pi^{s+1}}\frac{12\left\Vert v\right\Vert _{\infty}}{\varepsilon}\right)^{\frac{1}{s}},\label{eq:N_Junike2023}
\end{equation}
where $s\in\{1,...,J\}$. The term $\left\Vert f^{(s+1)}\right\Vert _{\infty}$
can be bounded by
\begin{equation}
\|f^{(s+1)}\|_{\infty}\leq\frac{1}{2\pi}\int_{\mathbb{R}}|u|^{s+1}|\varphi(u)|du.\label{eq:boundf}
\end{equation}
For the BS model, the integral in Inequality (\ref{eq:boundf}) can
be solved explicitly, and we choose $s=40$. The density of the VG
distribution is given in terms of the Bessel function of the third
kind by \citet[Eq. (23)]{madan1998variance}. According to \citet{kuchler2008shapes},
the density of the VG distribution is $J+1$ times continuously differentiable
if $J$ is equal to the largest natural number less than $\frac{2T}{\nu}-2$.
For the VG distribution, we use $s=J$.

In Table \ref{tab:Nopt} one can see that Corollary \ref{cor:NrTerms}
provides a sharper bound for $\boldsymbol{N}$ than \citet{junike2023handle}.
This is particularly noticeable for the VG distribution, which is
less smooth than the normal distribution. However, the formula in
\citet{junike2023handle} is numerically more stable, compare with
Remark \ref{rem:lessStable}. The number of terms obtained by Corollary
\ref{cor:NrTerms} is roughly twice as large as the minimal number
of terms necessary to stay below the error tolerance. The CPU time
to solve the integral appearing in Corollary \ref{cor:NrTerms} is
of similar magnitude in one-dimension compared to the CPU time of
the COS method.

\begin{table}[H]
\begin{centering}
\begin{tabular}{|l|>{\raggedright}p{0.5cm}|>{\raggedright}p{1.8cm}|>{\raggedright}p{0.1cm}|l|>{\raggedright}p{1.3cm}|>{\raggedright}p{1cm}|>{\raggedright}p{5.8cm}|}
\hline 
{\small{}Choosing $\boldsymbol{N}$} & {\small{}$N$} & {\small{}CPU time COS} & {\small{}$d$} & {\small{}$\varepsilon$} & {\small{}$\boldsymbol{L}$} & {\small{}Ref. value} & {\small{}Function of interest/ model parameters}\tabularnewline
\hline 
\hline 
{\small{}Minimal $N$} & {\small{}20} & {\small{}0.009} & {\small{}1} & {\small{}$10^{-4}$} & {\small{}0.9} & {\small{}0.79193} & {\small{}CDF of VG distribution with $\nu=0.19$,}\tabularnewline
{\small{}Cor. \ref{cor:NrTerms}} & {\small{}46} & {\small{}0.016} &  &  &  &  & {\small{}$a=\frac{1}{\nu}$, $s=\nu,$ $\theta=\eta=0$, $\sigma=0.13$}\tabularnewline
{\small{}\citet{junike2023handle}} & {\small{}107} & {\small{}0.031 (0.28)} &  &  &  &  & \tabularnewline
\hline 
{\small{}Minimal $N$} & {\small{}20} & {\small{}0.013} & {\small{}1} & {\small{}$10^{-3}$} & {\small{}1.3} & {\small{}2.5978} & {\small{}Put option in VG model with }\tabularnewline
{\small{}Cor. \ref{cor:NrTerms}} & {\small{}64} & {\small{}0.030 (0.16)} &  &  &  &  & {\small{}$\sigma=0.1213$, $\theta=-0.1436$, $\nu=0.1686$}\tabularnewline
{\small{}\citet{junike2023handle}} & {\small{}152} & {\small{}0.065 (0.26)} &  &  &  &  & \tabularnewline
\hline 
{\small{}Minimal $N$} & {\small{}10} & {\small{}0.005} & {\small{}1} & {\small{}$10^{-2}$} & {\small{}1.2} & {\small{}3.9827} & {\small{}Put option in BS model with $\Sigma=0.2^{2}$}\tabularnewline
{\small{}Cor. \ref{cor:NrTerms}} & {\small{}16} & {\small{}0.006} &  &  &  &  & \tabularnewline
{\small{}\citet{junike2023handle}} & {\small{}20} & {\small{}0.007} &  &  &  &  & \tabularnewline
\hline 
{\small{}Minimal $\boldsymbol{N}$} & {\small{}40} & {\small{}2.32} & {\small{}2} & {\small{}$10^{-2}$} & {\small{}(3.9, 7.9)} & {\small{}10.5051} & {\small{}Basket put in BS model with $\Sigma_{11}=0.2^{2},$}\tabularnewline
{\small{}Cor. \ref{cor:NrTerms}} & {\small{}72} & {\small{}7.04} &  &  &  &  & {\small{}$\Sigma_{22}=0.4^{2}$, $\Sigma_{12}=\Sigma_{21}=\frac{1}{2}\sqrt{\Sigma_{11}\Sigma_{22}}$}\tabularnewline
\hline 
\end{tabular}
\par\end{centering}
\caption{\label{tab:Nopt}Comparison of different strategies to choose $\boldsymbol{N}$
to obtain the CDF for the $\text{VG}(a,s,\eta,\theta,\sigma)$ distribution
at $y=0.1$ without damping and the price of an arithmetic basket
put option in the BS and the VG models. For the (basket) put option,
we set $\boldsymbol{S}(0)=(50,...,50)$, $K=50d$, $T=1$, $r=0$
and $\boldsymbol{N}=(N,\dots,N)$. We obtain the truncation range
$\boldsymbol{L}=(L,...,L)$ from Inequality (\ref{eq:m-1-1}) using
$n=8$ moments. Damping is only necessary for the two-dimensional
basket option, where we set $\boldsymbol{\alpha}=(-4,-4)$. Reference
values are obtained by \citet{eberlein2010analysis}. We average over
ten runs to obtain the CPU time, which is measured in milliseconds.
The CPU times to solve the integrals in Inequality (\ref{eq:boundf})
and Corollary \ref{cor:NrTerms} for the VG model, using R's \emph{integrate}
function with default values, are reported in brackets.}
\end{table}


\subsection{Comparison with Monte Carlo}

We compare the COS method with a Monte Carlo (MC) simulation to obtain
the price of a cash-or-nothing put option in the BS model, which is
equal to the CDF of the normal distribution evaluated at $\log(\boldsymbol{K})$;
hence, reference values can be obtained in closed form. The computational
complexity of a MC simulation with $U\in\mathbb{N}$ runs scales like
$O(U)$. We estimate $U$ by the central limit theorem using a statistical
error of $0.99$. The COS method consists of $d$-nested sums. According
to Equation (\ref{eq:ck}), the computational complexity of the COS
method scales like $O\left(\prod_{h=1}^{d}\{N_{h}\}\right)$. A MC
simulation converges relatively slowly, but it scarcely depends on
the dimension. On the other hand, the complexity of the COS method
grows exponentially in the dimension; however, the COS method also
converges exponentially for the BS model. The choice between MC and
the COS method depends both on the dimension and on the error tolerance
$\varepsilon$: the higher $d$ the better MC compares to the COS
method, but the smaller $\varepsilon$, the faster the COS method
performs. 

In several numerical experiments, we observe that the COS method is
faster than MC for $d\leq4$ and $\varepsilon\leq10^{-3}$. For $d=5$,
the COS method outperforms MC for $\varepsilon\leq10^{-5}$; otherwise,
a MC simulation is faster. If $\varepsilon=10^{-9}$ and $d=4$, the
COS method needs $220$ terms in each dimension to stay below the
error tolerance, and the CPU time is about one hour. We estimate that
a MC simulation would take longer than $20,000$ years. Some experiments
are reported in Table \ref{tab:Monte-Carlo-vs-COS_empirical-closed-1}
and Figure \ref{fig:Computational-cost-of}.

\begin{table}[H]
\begin{centering}
\begin{tabular}{|c|c|c|r|r|r|c|}
\hline 
{\small{}$d$} & {\small{}$N$} & {\small{}$L$} & $U$ & {\small{}$\tau_{\text{COS}}$} & {\small{}$\tau_{\text{MC}}$} & {\small{}Reference value}\tabularnewline
\hline 
\hline 
{\small{}1} & {\small{}30} & {\small{}2.0} & 16481995016 & {\small{}8.9e-6} & {\small{}5.1e+3} & {\small{}0.539827}\tabularnewline
\hline 
{\small{}2} & {\small{}30} & {\small{}2.4} & 13700525367 & {\small{}3.7e-4} & {\small{}1.6e+4} & {\small{}0.291414}\tabularnewline
\hline 
{\small{}3} & {\small{}40} & {\small{}3.0} & 8795611829 & {\small{}4.9e-2} & {\small{}1.2e+4} & {\small{}0.157313}\tabularnewline
\hline 
{\small{}4} & {\small{}50} & {\small{}3.6} & 5156004587 & {\small{}1.1e+1} & {\small{}8.1e+3} & {\small{}0.084922}\tabularnewline
\hline 
{\small{}5} & {\small{}50} & {\small{}4.2} & 2902219256 & {\small{}1.4e+3} & {\small{}7.8e+3} & {\small{}0.045843}\tabularnewline
\hline 
\end{tabular}
\par\end{centering}
\caption{\label{tab:Monte-Carlo-vs-COS_empirical-closed-1}CPU time of the
COS method $(\tau_{\text{COS}})$ and CPU time of a MC simulation
$(\tau_{\text{MC}})$ for the BS model to price a cash-or-nothing
put option. We set $\varepsilon=10^{-5}$, $\boldsymbol{\alpha}=(-7,\dots,-7)$,
$\Sigma_{ii}=\sigma^{2}$, $\Sigma_{ij}=0$, $i\protect\neq j$, where
$\sigma=0.2$, $T=1$ and $\boldsymbol{S}(0)=\boldsymbol{K}=(100,\dots,100)$.
We set $N_{1}=\dots=N_{d}=N$. We obtain the truncation range $\boldsymbol{L}=(L,...,L)$
from Inequality (\ref{eq:m-1-1}) using $n=8$ moments. The reference
value can be obtained in closed form. CPU time is measured in seconds.}
\end{table}
% Figure environment removed


\section{\label{sec:Conclusions}Conclusions}

In this article we introduced and discussed the damped COS method,
which is a numerical tool to solve certain multidimensional integrals
numerically, e.g., to obtain a CDF from a characteristic function
or to price rainbow options in a financial context. The (damped) COS
method requires several parameters: In particular, one has to specify
a truncation range $\boldsymbol{L}$ for the density $f$ and the
number of terms $\boldsymbol{N}$ of cosine functions to approximate
the truncated density. Corollary \ref{cor:generalCase} provides sufficient
conditions on $\boldsymbol{L}$ and $\boldsymbol{N}$ to ensure the
convergence of the COS method within a given error tolerance $\varepsilon>0$.
Theorem \ref{thm:(Multidimensional-COS-method} and Corollary \ref{cor:NrTerms}
provide formulas for the truncation range $\boldsymbol{L}$ and the
number of terms $\boldsymbol{N}$, respectively. Theorem \ref{thm:order of convergence}
provides an upper bound of the order of convergence of the COS method.
Numerical experiments indicate that the bound is sharp. In particular,
the (damped) COS method converges exponentially if the Fourier transform
$\widehat{f}$ decays exponentially.

\bibliographystyle{plainnat}
\bibliography{biblio}

\end{document}
