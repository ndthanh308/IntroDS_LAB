%% LyX 2.3.6 created this file.  For more info, see http://www.lyx.org/.
%% Do not edit unless you really know what you are doing.
\documentclass{article}
\usepackage{lmodern}
\renewcommand{\sfdefault}{lmss}
\renewcommand{\ttdefault}{lmtt}
\usepackage[T1]{fontenc}
\usepackage[latin9]{inputenc}
\usepackage[english]{babel}
\usepackage{verbatim}
\usepackage{float}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage[unicode=true,pdfusetitle,
 bookmarks=true,bookmarksnumbered=false,bookmarksopen=false,
 breaklinks=false,pdfborder={0 0 0},pdfborderstyle={},backref=false,colorlinks=false]
 {hyperref}

\makeatletter

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% LyX specific LaTeX commands.
%% Because html converters don't know tabularnewline
\providecommand{\tabularnewline}{\\}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Textclass specific LaTeX commands.
\theoremstyle{plain}
\newtheorem{thm}{\protect\theoremname}[section]
\theoremstyle{definition}
\newtheorem{defn}[thm]{\protect\definitionname}
\theoremstyle{plain}
\newtheorem{cor}[thm]{\protect\corollaryname}
\theoremstyle{remark}
\newtheorem{rem}[thm]{\protect\remarkname}
\theoremstyle{plain}
\newtheorem{lem}[thm]{\protect\lemmaname}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% User specified LaTeX commands.
\newtheorem{assumption}{Assumption} 

\renewcommand\theassumption{A\arabic{assumption}}

\usepackage{stmaryrd}

\makeatother

\providecommand{\corollaryname}{Corollary}
\providecommand{\definitionname}{Definition}
\providecommand{\lemmaname}{Lemma}
\providecommand{\remarkname}{Remark}
\providecommand{\theoremname}{Theorem}
\usepackage[round]{natbib}
\usepackage{breakurl}
\hypersetup{breaklinks=true, colorlinks=false, pdfusetitle=true }

\begin{document}
\title{The multidimensional COS method for option pricing}
\author{Gero Junike\thanks{Corresponding author. Carl von Ossietzky Universitt, Institut fr
Mathematik, 26129 Oldenburg, Germany, ORCID: 0000-0001-8686-2661,
E-mail: gero.junike@uol.de}, Hauke Stier\thanks{Carl von Ossietzky Universitt, Institut fr Mathematik, 26129 Oldenburg,
Germany.}}
\maketitle
\begin{abstract}
The multidimensional COS method is a numerical tool to price financial
options, which depend on several underlyings. The method makes use
of the characteristic function $\varphi$ of the logarithmic returns
of the underlyings and it is advantageous if the Fourier-cosine coefficients
$v_{\boldsymbol{k}}$ of the payoff function are given in closed-form.
However, in important cases, neither $\varphi$ nor $v_{\boldsymbol{k}}$
are given analytically but need to be recovered numerically. In this
article, we prove the convergence of the multidimensional COS method
including numerical uncertainty on $\varphi$ and $v_{\boldsymbol{k}}$.
Our analysis helps to understand how the approximation errors on $\varphi$
and $v_{\boldsymbol{k}}$ propagate in the COS method.

\textbf{Keywords: }Fourier-transform, COS method, option pricing,
rainbow options, basket options\\
 \textbf{Mathematics Subject Classification} 65D30  65T40  60E10
 62P05%
\begin{comment}
91B25, 91G20, 91G60
\end{comment}
\end{abstract}

\section{Introduction}

Rainbow or basket options are financial contracts that depend on several
underlyings. The price of a rainbow option can be expressed by an
integral $\int_{\mathbb{R}^{d}}v(\boldsymbol{x})f(\boldsymbol{x})d\boldsymbol{x}$,
where $v$ is the payoff function describing the rainbow option and
$f$ is the density of the log-returns of the underlyings. The integral
can be solved numerically using different techniques such as Monte
Carlo, numerical quadrature and Fourier inversion, see \cite{ruijter2012two}
and references therein.

The COS method, see \citet{fang2009novel,junike2022precise}, is a
Fourier pricing technique. For most financial models, the density
$f$ is not known but only the characteristic function $\varphi$
of $f$ is given in closed-form. The COS method uses the characteristic
function in an efficient way to approximate the integral and compares
favourably to other Fourier pricing techniques, see \citet{fang2009novel}.
The COS method is particularly fast when not only $\varphi$ but also
the Fourier-cosine coefficients of the payoff functions $v$ are given
analytically. For instance, in multivariate dimensions, the Fourier-cosine
coefficients of geometric basket options or call-on-maximum options
can be obtained analytically, see \cite{ruijter2012two}. However,
for many rainbow options the Fourier-cosine coefficients are not given
in closed-form and need to be approximated numerically.

Furthermore, in some important cases, $\varphi$ must also be recovered
numerically and is approximated by some function $\tilde{\varphi}$.
This happens for example for some complex financial models, see, e.g.,
\cite{carr2004time}, where $\varphi$ is the solution of some ordinary
differential equation that has to be solved numerically before applying
the COS method.

This paper makes the following main contributions: We generalise \citet{junike2022precise}
to the multidimensional case. In particular, we prove the convergence
of the COS method in a multidimensional setting. Unlike \cite{ruijter2012two},
we include in our analysis numerical uncertainty on the characteristic
function $\varphi$ and on the Fourier-cosine coefficients of the
payoff function. This helps to understand how approximations on $\varphi$
and the Fourier-cosine coefficients of the payoff function affect
the total error of the COS method.

This article is structured as follows: In Section \ref{sec:Notation},
we fix some notation. In Section \ref{sec:Convergence-of-the} we
prove the convergence of the multidimensional COS method. Section
\ref{sec:Conclusions} concludes.

\global\long\def\Cov{}%

\global\long\def\COS{}%


\section{\label{sec:Notation}Notation}

Let $d\in\mathbb{N}$. Let $\mathcal{L}^{1}$ and $\mathcal{L}^{2}$
denote the sets of integrable and square integrable functions from
$\mathbb{R}^{d}$ to $\mathbb{R}$, and by $\left\langle .,.\right\rangle $
and $\left\Vert .\right\Vert _{2}$ we denote the scalar product and
the (semi)norm on $\mathcal{L}^{2}$. The supremum norm of a function
$g:\mathbb{R}^{d}\to\mathbb{C}$ is defined by $\left\Vert g\right\Vert _{\infty}:=\sup_{\boldsymbol{x}\in\mathbb{R}^{d}}|g(\boldsymbol{x})|$.
By $C^{J+1}(\mathbb{R}^{d})$ we denote the $J+1$ times partially
continuously differentiable functions from $\mathbb{R}^{d}$ to $\mathbb{R}$.
For $\boldsymbol{\alpha}\in\{0,...,J+1\}^{d}$ and $f\in C^{J+1}(\mathbb{R}^{d})$
we denote by
\[
f\boldsymbol{^{\alpha}}(\boldsymbol{x})=f^{(\alpha_{1},\dots,\alpha_{d})}(\boldsymbol{x})=\frac{\partial}{\partial x_{1}^{\alpha_{1}}}\dots\frac{\partial}{\partial x_{d}^{\alpha_{d}}}f(\boldsymbol{x}),\quad\boldsymbol{x}\in\mathbb{R}^{d}
\]
the partial derivatives of $f$.%
\begin{comment}
and define
\[
\llbracket f\rrbracket:=\max_{\boldsymbol{\alpha}\in\{0,...,J+1\}^{d}}\Vert f^{\boldsymbol{\alpha}}\Vert_{\infty}.
\]
\end{comment}
{} The Euclidean norm on $\mathbb{R}^{d}$ is denoted by $|.|$. For
$\boldsymbol{x},\boldsymbol{y}\in\mathbb{R}^{d}$ we define
\[
\boldsymbol{x}\geq\boldsymbol{y}:\Leftrightarrow x_{1}\geq y_{1},...,x_{d}\geq y_{d}
\]
and treat ``$\leq$'', ``$<$'' and ``$>$'' similarly. We set
$\mathbb{R}_{+}^{d}:=\{\boldsymbol{x}\in\mathbb{R}^{d},\boldsymbol{x}>\boldsymbol{0}\}$.
For $\boldsymbol{L}\in\mathbb{R}_{+}^{d}$, two complex vectors $\boldsymbol{x},\boldsymbol{y}\in\mathbb{C}^{d}$
and $\alpha\in\mathbb{C}$ we denote 
\begin{align*}
\boldsymbol{x}+\boldsymbol{y}:= & (x_{1}+y_{1},...,x_{d}+y_{d})\in\mathbb{C}^{d}\\
\boldsymbol{xy}:= & (x_{1}y_{1},...,x_{d}y_{d})\in\mathbb{C}^{d}\\
\boldsymbol{x}\cdot\boldsymbol{y}:= & x_{1}y_{1}+...+x_{d}y_{d}\in\mathbb{C}\\
\frac{\boldsymbol{x}}{\boldsymbol{y}}:= & \left(\frac{x_{1}}{y_{1}},...,\frac{x_{d}}{y_{d}}\right)\in\mathbb{C}^{d}\\
\alpha\boldsymbol{x}:= & (\alpha x_{1},...,\alpha x_{d})\in\mathbb{C}^{d}\\{}
[\boldsymbol{L},\boldsymbol{L}]:= & [-L_{1},L_{1}]\times...\times[-L_{d},L_{d}]\subset\mathbb{R}^{d}.
\end{align*}
By $\Re\{.\}$ we denote the real part of a complex number. $i$ is
the complex unit. For $\boldsymbol{N}=(N_{1},...,N_{d})\in\mathbb{N}^{d}$,
and a sequence $\left(\xi_{\boldsymbol{k}}\right)_{\boldsymbol{k}\in\mathbb{N}_{0}^{d}}\subset\mathbb{C}$,
we define
\begin{align*}
\sideset{}{'}\sum_{\boldsymbol{k}\in\mathbb{N}_{0}^{d},\boldsymbol{k}\leq\boldsymbol{N}}\xi_{\boldsymbol{k}} & :=\sum_{\boldsymbol{k}\in\mathbb{N}_{0}^{d},\boldsymbol{k}\leq\boldsymbol{N}}\frac{1}{2^{\Lambda(\boldsymbol{k})}}\xi_{\boldsymbol{k}},
\end{align*}
where
\begin{equation}
\Lambda(\boldsymbol{k}):=\sum_{h=1}^{d}1_{\{k_{h}=0\}},\quad\boldsymbol{k}\in\mathbb{N}_{0}^{d}.\label{eq:Lambda}
\end{equation}

\begin{comment}
vektoren fett

i komplexe zahl

$k,l\in\mathbb{N}_{0}^{d}$ fr $a_{k},c_{k},e_{k}$

h fr 1,...,d

j fr 1,...,J+1
\end{comment}


\section{\label{sec:Convergence-of-the}Convergence }

Let $f:\mathbb{R}^{d}\to\mathbb{R}$ be a density with characteristic
function
\[
\varphi(\boldsymbol{u})=\int_{\mathbb{R}^{d}}f(\boldsymbol{x})e^{i\boldsymbol{u}\cdot\boldsymbol{x}}d\boldsymbol{x},\quad\boldsymbol{u}\in\mathbb{R}^{d}.
\]
For many models in finance, $\varphi$ is given in closed-form, see
\cite{ruijter2012two}. However, for some models $\varphi$ need to
be approximated by a function $\tilde{\varphi}:\mathbb{R}^{d}\to\mathbb{C}$,
e.g., in \cite{carr2004time} $\varphi$ can be expressed as the solution
to some ordinary differential equation, which itself need to be solved
numerically. Let $v:\mathbb{R}^{d}\to\mathbb{R}$ be at least locally
integrable. We aim to compute the integral 
\begin{equation}
\int_{\mathbb{R}^{d}}v(\boldsymbol{x})f(\boldsymbol{x})d\boldsymbol{x}.\label{eq:int}
\end{equation}
The function $v$ might describe the payoff of some financial derivative.
The integral describes the price of the derivative. 

\begin{table}[H]
\begin{centering}
\begin{tabular}{|c|l|}
\hline 
Aim: & Approximate $\int_{\mathbb{R}^{d}}v(\boldsymbol{x})f(\boldsymbol{x})d\boldsymbol{x}$
by $\sideset{}{'}\sum\tilde{c}_{\boldsymbol{k}}\tilde{v}_{\boldsymbol{k}}$\tabularnewline
\hline 
\hline 
\textbf{$\boldsymbol{L}$}, $\boldsymbol{M}$ & Truncation range for $f$ and $v$\tabularnewline
\hline 
$f$, $f_{\boldsymbol{L}}$ & Density and truncated density function\tabularnewline
\hline 
$v$, $v_{\boldsymbol{M}}$ & Payoff and truncated payoff function\tabularnewline
\hline 
$\varphi$ & Characteristic function of $f$\tabularnewline
\hline 
$\tilde{\varphi}$ & Numerical approximation of $\varphi$\tabularnewline
\hline 
$a_{\boldsymbol{k}}$ & \multicolumn{1}{c|}{Classical Fourier-cosine coefficients of $f_{\boldsymbol{L}}$}\tabularnewline
\hline 
$c_{\boldsymbol{k}}$ & Approximation of $a_{\boldsymbol{k}}$ through $\varphi$\tabularnewline
\hline 
$\tilde{c}_{\boldsymbol{k}}$ & Numerical approximation of $c_{\boldsymbol{k}}$ through $\tilde{\varphi}$\tabularnewline
\hline 
$v_{\boldsymbol{k}}$ & (Scaled) Fourier-cosine coefficients of $v_{\boldsymbol{M}}$\tabularnewline
\hline 
$\tilde{v}_{\boldsymbol{k}}$ & Numerical approximation of $v_{\boldsymbol{k}}$\tabularnewline
\hline 
$e_{\boldsymbol{k}}$, $e_{\boldsymbol{k}}^{\boldsymbol{L}}$ & (Truncated) cosine basis functions\tabularnewline
\hline 
\end{tabular}
\par\end{centering}
\caption{Overview multidimensional COS method.}
\end{table}

Let $\boldsymbol{L}=(L_{1},...,L_{d})\in\mathbb{R}_{+}^{d}$, $\boldsymbol{x}=(x_{1},...,x_{d})\in\mathbb{R}^{d}$
and $\boldsymbol{k}=(k_{1},...,k_{d})\in\mathbb{\mathbb{N}}_{0}^{d}$.
Define the truncated density
\[
f_{\boldsymbol{L}}(\boldsymbol{x})=f(\boldsymbol{x})\prod_{h=1}^{d}1_{[-L_{h},L_{h}]}(x_{h}),
\]
and basis functions
\[
e_{\boldsymbol{k}}(\boldsymbol{x})=\prod_{h=1}^{d}\cos\left(k_{h}\pi\frac{x_{h}+L_{h}}{2L_{h}}\right),
\]
and
\[
e_{\boldsymbol{k}}^{\boldsymbol{L}}(\boldsymbol{x})=e_{\boldsymbol{k}}(\boldsymbol{x})\prod_{h=1}^{d}1_{[-L_{h},L_{h}]}(x_{h}).
\]
The classical Fourier-cosine coefficients of $f_{\boldsymbol{L}}$
are defined by
\[
a_{\boldsymbol{k}}=\frac{1}{\prod_{h=1}^{d}L_{h}}\int_{[\boldsymbol{L},\boldsymbol{L}]}f(\boldsymbol{x})e_{\boldsymbol{k}}(\boldsymbol{x})d\boldsymbol{x}
\]
and we approximate the coefficients $a_{\boldsymbol{k}}$ by integrating
over $\mathbb{R}^{d}$ instead of $[\boldsymbol{L},\boldsymbol{L}]$,
i.e.,
\[
c_{\boldsymbol{k}}=\frac{1}{\prod_{h=1}^{d}L_{h}}\int_{\mathbb{R}^{d}}f(\boldsymbol{x})e_{\boldsymbol{k}}(\boldsymbol{x})d\boldsymbol{x}.
\]
By Lemma \ref{lem:int fe} in the Appendix it follows that
\begin{align}
c_{\boldsymbol{k}} & =\frac{1}{2^{d-1}\prod_{h=1}^{d}L_{h}}\sum_{\boldsymbol{s}=(1,\pm1,...,\pm1)\in\mathbb{R}^{d}}\Re\left\{ \varphi\left(\frac{\pi}{2}\frac{\boldsymbol{sk}}{\boldsymbol{L}}\right)\exp\left(i\frac{\pi}{2}\boldsymbol{s}\cdot\boldsymbol{k}\right)\right\} .\label{eq:ck}
\end{align}
The coefficients $c_{\boldsymbol{k}}$ are given analytically, if
$\varphi$ is given in closed-form. If $\varphi$ need to be approximated
by some function $\tilde{\varphi}$, we define $\tilde{c}_{\boldsymbol{k}}$
by replacing $\varphi$ by $\tilde{\varphi}$ in Equation (\ref{eq:ck}).

For $\boldsymbol{M}=(M_{1},...,M_{d})\in\mathbb{R}_{+}^{d}$ such
that $\boldsymbol{M}\leq\boldsymbol{L}$, define the (scaled) Fourier-cosine
coefficients of the payoff function $v$ by
\begin{equation}
v_{\boldsymbol{k}}=\int_{[\boldsymbol{M},\boldsymbol{M}]}v(\boldsymbol{x})e_{\boldsymbol{k}}(\boldsymbol{x})d\boldsymbol{x}.\label{eq:vk}
\end{equation}
The truncated payoff function is defined by 
\[
v_{\boldsymbol{M}}(\boldsymbol{x})=v(\boldsymbol{x})\prod_{h=1}^{d}1_{[-M_{h},M_{h}]}(x_{h}).
\]
In some cases, the coefficients $v_{\boldsymbol{k}}$ can be obtained
explicitly. If $v_{\boldsymbol{k}}$ are not given analytically, the
integral in Equation (\ref{eq:vk}) can also be solved numerically
and the coefficients $v_{\boldsymbol{k}}$ are approximated by some
$\tilde{v}_{\boldsymbol{k}}$, see \cite{ruijter2012two}. The idea
of the multidimensional COS method is to approximate the integral
in (\ref{eq:int}) by
\[
\int_{\mathbb{R}^{d}}v(\boldsymbol{x})f(\boldsymbol{x})d\boldsymbol{x}\approx\sideset{}{'}\sum_{\boldsymbol{k}\in\mathbb{N}_{0}^{d},\boldsymbol{k}\leq\boldsymbol{N}}\tilde{c}_{\boldsymbol{k}}\tilde{v}_{\boldsymbol{k}},
\]
see \cite{ruijter2012two}. In the remainder of the article, we will
prove under which conditions the integral can be approximated by the
COS method. 
\begin{defn}
\label{def:COS_admissible}Let $\boldsymbol{L}=(L_{1},...,L_{d})\in\mathbb{R}_{+}^{d}$.
A function $f\in\mathcal{L}^{1}$ is called \emph{COS-admissible},
if
\[
B(\boldsymbol{L}):=\sum_{\boldsymbol{k}\in\mathbb{N}_{0}^{d}}\frac{1}{\prod_{h=1}^{d}L_{h}}\left|\int_{\mathbb{R}^{d}\setminus[-\boldsymbol{L},\boldsymbol{L}]}f(\boldsymbol{x})e_{\boldsymbol{k}}(\boldsymbol{x})d\boldsymbol{x}\right|^{2}\to0,\quad\min_{h=1,...,d}L_{h}\to\infty.
\]
\end{defn}

\begin{comment}
The assertion follows immediately from Proposition \ref{prop:COSadmissible}:
It holds $f\in\mathcal{L}^{1}\cap\mathcal{L}^{2}$ because $f$ is
a bounded density. We further have
\[
\int_{\mathbb{R}^{d}}|x|^{2}f^{2}(x)dx\leq\sup_{x\in\mathbb{R}^{d}}f(x)\int_{\mathbb{R}^{d}}|x|^{2}f(x)dx<\infty.
\]
\end{comment}
The following theorem generalizes \citet[Thm. 7]{junike2022precise}
to the multidimensional case including numerical uncertainty on the
characteristic function $\varphi$. It shows that multivariate densities
can be approximated by a cosine expansion.
\begin{thm}
\label{thm:approx f}Assume that $f\in\mathcal{L}^{1}\cap\mathcal{L}^{2}$
and that $f$ is COS-admissible. For any $\varepsilon>0$ there is
a $\boldsymbol{L}\in\mathbb{R}_{+}^{d}$, a $\boldsymbol{N}\in\mathbb{N}^{d}$
and a $\gamma>0$ so that $\left\Vert \varphi-\tilde{\varphi}\right\Vert _{\infty}<\gamma$
implies
\[
\left\Vert f-\sideset{}{'}\sum_{\boldsymbol{k}\in\mathbb{N}_{0}^{d},\boldsymbol{k}\leq\boldsymbol{N}}\tilde{c}_{\boldsymbol{k}}e_{\boldsymbol{k}}^{\boldsymbol{L}}\right\Vert _{2}<\varepsilon.
\]
Note that $\boldsymbol{N}$ depends on $\boldsymbol{L}$ and $\gamma$
depends on both $\boldsymbol{L}$ and $\boldsymbol{N}$.
\end{thm}

\begin{proof}
For $k,l\in\mathbb{N}_{0}$ and $L>0$, it holds that
\[
\int_{-L}^{L}\cos\left(k\pi\frac{x+L}{2L}\right)\cos\left(l\pi\frac{x+L}{2L}\right)dx=\begin{cases}
2L & ,k=l=0\\
L & ,k=l\neq0\\
0 & ,k\neq l.
\end{cases}
\]
Thereby, we obtain
\begin{align*}
\left\langle e_{\boldsymbol{k}}^{\boldsymbol{L}},e_{\boldsymbol{l}}^{\boldsymbol{L}}\right\rangle  & =\int_{-L_{1}}^{L_{1}}...\int_{-L_{d}}^{L_{d}}\prod_{h=1}^{d}\bigg\{\cos\big(k_{h}\pi\frac{x_{h}+L_{h}}{2L_{h}}\big)\cos\big(l_{h}\pi\frac{x_{h}+L_{h}}{2L_{h}}\big)\bigg\} dx_{d}...dx_{1}\\
 & =\begin{cases}
0 & ,k_{h}\neq l_{h}\text{ for any }h\\
2^{\Lambda(\boldsymbol{k})}\prod_{h=1}^{d}L_{h} & ,k_{1}=l_{1},...,k_{d}=l_{d},
\end{cases}
\end{align*}
where $\Lambda$ is defined as in Equation (\ref{eq:Lambda}). For
any $\boldsymbol{L}\in\mathbb{R}_{+}^{d}$ and $\boldsymbol{N}\in\mathbb{N}^{d}$,
it holds that
\begin{align*}
\left\Vert f-\sideset{}{'}\sum_{\boldsymbol{k}\in\mathbb{N}_{0}^{d},\boldsymbol{k}\leq\boldsymbol{N}}\tilde{c}_{\boldsymbol{k}}e_{\boldsymbol{k}}^{\boldsymbol{L}}\right\Vert _{2}\leq & \underbrace{\left\Vert f-f_{\boldsymbol{L}}\right\Vert _{2}}_{=:A_{1}(\boldsymbol{L})}+\underbrace{\left\Vert f_{\boldsymbol{L}}-\sideset{}{'}\sum_{k\in\mathbb{N}_{0}^{d},k\leq\boldsymbol{N}}a_{\boldsymbol{k}}e_{\boldsymbol{k}}^{\boldsymbol{L}}\right\Vert _{2}}_{=:A_{2}(\boldsymbol{L},\boldsymbol{N})}\\
 & +\underbrace{\left\Vert \sideset{}{'}\sum_{\boldsymbol{k}\in\mathbb{N}_{0}^{d},\boldsymbol{k}\leq\boldsymbol{N}}(a_{\boldsymbol{k}}-c_{\boldsymbol{k}})e_{\boldsymbol{k}}^{\boldsymbol{L}}\right\Vert _{2}}_{=:A_{3}(\boldsymbol{L},\boldsymbol{N})}+\underbrace{\left\Vert \sideset{}{'}\sum_{\boldsymbol{k}\in\mathbb{N}_{0}^{d},\boldsymbol{k}\leq\boldsymbol{N}}(c_{\boldsymbol{k}}-\tilde{c}_{\boldsymbol{k}})e_{\boldsymbol{k}}^{\boldsymbol{L}}\right\Vert _{2}}_{=:A_{4}(\boldsymbol{L},\boldsymbol{N})}.
\end{align*}
Further,
\begin{align*}
A_{3}(\boldsymbol{L},\boldsymbol{N})^{2} & =\left\langle \sideset{}{'}\sum_{\boldsymbol{k}\in\mathbb{N}_{0}^{d},\boldsymbol{k}\leq\boldsymbol{N}}(a_{\boldsymbol{k}}-c_{\boldsymbol{k}})e_{\boldsymbol{k}}^{\boldsymbol{L}},\sideset{}{'}\sum_{\boldsymbol{k}\in\mathbb{N}_{0}^{d},\boldsymbol{k}\leq\boldsymbol{N}}(a_{\boldsymbol{k}}-c_{\boldsymbol{k}})e_{\boldsymbol{k}}^{\boldsymbol{L}}\right\rangle \\
 & =\sum_{\boldsymbol{k}\in\mathbb{N}_{0}^{d},\boldsymbol{k}\leq\boldsymbol{N}}\sum_{\boldsymbol{l}\in\mathbb{N}_{0}^{d},\boldsymbol{l}\leq\boldsymbol{N}}\frac{1}{2^{\Lambda(\boldsymbol{k})+\Lambda(\boldsymbol{l})}}(a_{\boldsymbol{k}}-c_{\boldsymbol{k}})(a_{\boldsymbol{l}}-c_{\boldsymbol{l}})\left\langle e_{\boldsymbol{k}}^{\boldsymbol{L}},e_{\boldsymbol{l}}^{\boldsymbol{L}}\right\rangle \\
 & \leq\sum_{\boldsymbol{k}\in\mathbb{N}_{0}^{d}}\prod_{h=1}^{d}\{L_{h}\}\left|a_{\boldsymbol{k}}-c_{\boldsymbol{k}}\right|^{2}=B(\boldsymbol{L}),
\end{align*}
see Definition \ref{def:COS_admissible}. For $\varepsilon>0$, choose
$\boldsymbol{L}\in\mathbb{R}_{+}^{d}$ such that $A_{1}(\boldsymbol{L})<\frac{\varepsilon}{4}$
and $B(\boldsymbol{L})<\big(\frac{\varepsilon}{4}\big){}^{2}$. Hence,
$A_{3}(\boldsymbol{L},\boldsymbol{N})<\frac{\varepsilon}{4}$. Then
choose $\boldsymbol{N}\in\mathbb{N}^{d}$ such that $A_{2}(\boldsymbol{L},\boldsymbol{N})<\frac{\varepsilon}{4}$.
By the definition of $c_{\boldsymbol{k}}$ and $\tilde{c}_{\boldsymbol{k}}$,
see Equation (\ref{eq:ck}), it follows that
\begin{align*}
|c_{\boldsymbol{k}}-\tilde{c}_{\boldsymbol{k}}| & \leq\frac{1}{2^{d-1}\prod_{h=1}^{d}L_{h}}\sum_{\boldsymbol{s}=(1,\pm1,...,\pm1)\in\mathbb{R}^{d}}\left|\varphi\left(\frac{\pi}{2}\frac{\boldsymbol{sk}}{\boldsymbol{L}}\right)-\tilde{\varphi}\left(\frac{\pi}{2}\frac{\boldsymbol{sk}}{\boldsymbol{L}}\right)\right|\\
 & \leq\frac{\left\Vert \varphi-\tilde{\varphi}\right\Vert _{\infty}}{\prod_{h=1}^{d}L_{h}}.
\end{align*}
Similarly to the analysis of $A_{3}$, we have
\begin{align*}
A_{4}(\boldsymbol{L},\boldsymbol{N}) & ^{2}\leq\sum_{\boldsymbol{k}\in\mathbb{N}_{0}^{d},\boldsymbol{k}\leq\boldsymbol{N}}\prod_{h=1}^{d}\{L_{h}\}\left|c_{\boldsymbol{k}}-\tilde{c}_{\boldsymbol{k}}\right|^{2}\\
 & \leq\max_{\boldsymbol{k}\in\mathbb{N}_{0}^{d},\boldsymbol{k}\leq\boldsymbol{N}}\left|c_{\boldsymbol{k}}-\tilde{c}_{\boldsymbol{k}}\right|^{2}\prod_{h=1}^{d}\{L_{h}\}\prod_{h=1}^{d}\{N_{h}+1\}\\
 & \leq\frac{\left\Vert \varphi-\tilde{\varphi}\right\Vert _{\infty}^{2}}{\prod_{h=1}^{d}L_{h}}\prod_{h=1}^{d}\{N_{h}+1\}.
\end{align*}
Choose
\[
\gamma=\frac{\varepsilon}{4}\frac{\sqrt{\prod_{h=1}^{d}L_{h}}}{\sqrt{\prod_{h=1}^{d}\{N_{h}+1\}}}.
\]
Then $\left\Vert \varphi-\tilde{\varphi}\right\Vert _{\infty}<\gamma$
implies $A_{4}(\boldsymbol{L},\boldsymbol{N})\leq\frac{\varepsilon}{4}$,
which concludes the proof.
\end{proof}
The following Corollary generalizes \citet[Cor. 8]{junike2022precise}
to the multidimensional case including numerical uncertainty on the
characteristic function $\varphi$ and the cosine coefficients of
the payoff function $v$. The corollary provides sufficient conditions
in order to ensure that the COS method approximates the price of a
rainbow option within a predefined error tolerance $\varepsilon>0$.
\begin{cor}
\label{cor:generalCase}Let $f\in\mathcal{L}^{1}\cap\mathcal{L}^{2}$
be COS-admissible and $v:\mathbb{R}^{d}\to\mathbb{R}$ be locally
in $\mathcal{L}^{2}$, that is, $v_{\boldsymbol{M}}\in\mathcal{L}^{2}$
for any $\boldsymbol{M}\in\mathbb{R}_{+}^{d}$. Assume $vf\in\mathcal{L}^{1}$,
then the integral of the product of $f$ and $v$ can be approximated
by a finite sum as follows: Let $\varepsilon>0$. Let $\boldsymbol{M}\in\mathbb{R}_{+}^{d}$
and $\xi>0$ such that
\begin{equation}
\int_{\mathbb{R}^{d}\setminus[-\boldsymbol{M},\boldsymbol{M}]}\left|v(\boldsymbol{x})f(\boldsymbol{x})\right|d\boldsymbol{x}\leq\frac{\varepsilon}{3},\quad\left\Vert v_{\boldsymbol{M}}\right\Vert _{2}\leq\xi.\label{eq:Mgeneral}
\end{equation}
Let $\boldsymbol{L}\geq\boldsymbol{M}$ such that
\begin{equation}
\left\Vert f-f_{\boldsymbol{L}}\right\Vert _{2}\leq\frac{\varepsilon}{12\xi}\label{eq:L1general}
\end{equation}
and
\begin{equation}
B(\boldsymbol{L})\leq\left(\frac{\varepsilon}{12\xi}\right)^{2}.\label{eq:L2general}
\end{equation}
Choose $\boldsymbol{N}\in\mathbb{N}^{d}$ large enough, so that 
\[
\left\Vert f_{\boldsymbol{L}}-\sideset{}{'}\sum_{\boldsymbol{k}\in\mathbb{N}_{0}^{d},\boldsymbol{k}\leq\boldsymbol{N}}a_{\boldsymbol{k}}e_{\boldsymbol{k}}^{\boldsymbol{L}}\right\Vert _{2}\leq\frac{\varepsilon}{12\xi}.
\]
Assume
\begin{equation}
\left\Vert \varphi-\tilde{\varphi}\right\Vert _{\infty}\leq\frac{\varepsilon}{12\xi}\frac{\sqrt{\prod_{h=1}^{d}L_{h}}}{\sqrt{\prod_{h=1}^{d}\{N_{h}+1\}}}.\label{eq:phi_tilde}
\end{equation}
Let $\eta>0$ such that $\sideset{}{'}\sum_{\boldsymbol{k}\in\mathbb{N}_{0}^{d},\boldsymbol{k}\leq\boldsymbol{N}}|\tilde{c}_{\boldsymbol{k}}|\leq\eta.$
Assume
\[
|v_{\boldsymbol{l}}-\tilde{v}_{\boldsymbol{l}}|\leq\frac{\varepsilon}{3\eta},\quad\boldsymbol{l}\leq\boldsymbol{N}.
\]
Then it follows that
\begin{equation}
\left|\int_{\mathbb{R}^{d}}v(\boldsymbol{x})f(\boldsymbol{x})d\boldsymbol{x}-\sideset{}{'}\sum_{\boldsymbol{k}\in\mathbb{N}_{0}^{d},\boldsymbol{k}\leq\boldsymbol{N}}\tilde{c}_{\boldsymbol{k}}\tilde{v}_{\boldsymbol{k}}\right|\leq\varepsilon.\label{eq:Ngeneral}
\end{equation}
\end{cor}

\begin{proof}
Let $A_{1}(\boldsymbol{L})$, $A_{2}(\boldsymbol{L},\boldsymbol{N})$
and $A_{4}(\boldsymbol{L},\boldsymbol{N})$ be as in the proof of
Theorem \ref{thm:approx f}. By Inequality (\ref{eq:phi_tilde}) it
follows that $A_{4}(\boldsymbol{L},\boldsymbol{N})\leq\frac{\varepsilon}{12\xi}$.
Due to $v_{\boldsymbol{k}}=\langle v_{\boldsymbol{M}},e_{\boldsymbol{k}}^{\boldsymbol{L}}\rangle$
and by Theorem \ref{thm:approx f} we have that
\begin{align*}
\Big|\int_{\mathbb{R}^{d}}v(\boldsymbol{x}) & f(\boldsymbol{x})d\boldsymbol{x}-\sideset{}{'}\sum_{\boldsymbol{k}\in\mathbb{N}_{0}^{d},\boldsymbol{k}\leq\boldsymbol{N}}\tilde{c}_{\boldsymbol{k}}\tilde{v}_{\boldsymbol{k}}\Big|\\
= & \bigg|\int_{\mathbb{R}^{d}\setminus[-\boldsymbol{M},\boldsymbol{M}]}v(\boldsymbol{x})f(\boldsymbol{x})d\boldsymbol{x}+\langle v_{\boldsymbol{M}},f\rangle-\sideset{}{'}\sum_{\boldsymbol{k}\in\mathbb{N}_{0}^{d},\boldsymbol{k}\leq\boldsymbol{N}}\tilde{c}_{\boldsymbol{k}}\langle v_{\boldsymbol{M}},e_{\boldsymbol{k}}^{\boldsymbol{L}}\rangle\\
 & -\sideset{}{'}\sum_{\boldsymbol{k}\in\mathbb{N}_{0}^{d},\boldsymbol{k}\leq\boldsymbol{N}}\tilde{c}_{\boldsymbol{k}}(\tilde{v}_{\boldsymbol{k}}-v_{\boldsymbol{k}})\bigg|\\
\leq & \int_{\mathbb{R}^{d}\setminus[-\boldsymbol{M},\boldsymbol{M}]}|v(\boldsymbol{x})f(\boldsymbol{x})|d\boldsymbol{x}+\Big|\Big\langle v_{\boldsymbol{M}},f-\sideset{}{'}\sum_{\boldsymbol{k}\in\mathbb{N}_{0}^{d},\boldsymbol{k}\leq\boldsymbol{N}}\tilde{c}_{\boldsymbol{k}}e_{\boldsymbol{k}}^{\boldsymbol{L}}\Big\rangle\Big|\\
 & +\sideset{}{'}\sum_{\boldsymbol{k}\in\mathbb{N}_{0}^{d},\boldsymbol{k}\leq\boldsymbol{N}}|\tilde{c}_{\boldsymbol{k}}(\tilde{v}_{\boldsymbol{k}}-v_{\boldsymbol{k}})|\\
< & \frac{\varepsilon}{3}+\|v_{\boldsymbol{M}}\|_{2}\,\Big\Vert f-\sideset{}{'}\sum_{\boldsymbol{k}\in\mathbb{N}_{0}^{d},\boldsymbol{k}\leq\boldsymbol{N}}\tilde{c}_{\boldsymbol{k}}e_{\boldsymbol{k}}^{\boldsymbol{L}}\Big\Vert_{2}+\max_{\boldsymbol{l}\in\mathbb{N}_{0}^{d},\boldsymbol{l}\leq\boldsymbol{N}}|\tilde{v}_{\boldsymbol{l}}-v_{\boldsymbol{l}}|\sideset{}{'}\sum_{\boldsymbol{k}\in\mathbb{N}_{0}^{d},\boldsymbol{k}\leq\boldsymbol{N}}|\tilde{c}_{\boldsymbol{k}}|\\
< & \frac{\varepsilon}{3}+\xi\left(A_{1}(\boldsymbol{L})+A_{2}(\boldsymbol{L},\boldsymbol{N})+\sqrt{B(\boldsymbol{L})}+A_{4}(\boldsymbol{L},\boldsymbol{N})\right)+\frac{\varepsilon}{3}\\
\leq & \frac{\varepsilon}{3}+\xi\left(\frac{\varepsilon}{12\xi}+\frac{\varepsilon}{12\xi}+\frac{\varepsilon}{12\xi}+\frac{\varepsilon}{12\xi}\right)+\frac{\varepsilon}{3}=\varepsilon.
\end{align*}
\end{proof}
\begin{rem}
If there is no uncertainty on the characteristic function, i.e., $\varphi=\tilde{\varphi}$
and no uncertainty on the Fourier-cosine coefficients of the payoff
function $v$, i.e., $v_{\boldsymbol{k}}=\tilde{v}_{\boldsymbol{k}}$,
we may replace in Corollary \ref{cor:generalCase} the term $\frac{\varepsilon}{3}$
by $\frac{\varepsilon}{2}$ and the term $\frac{\varepsilon}{12\xi}$
by $\frac{\varepsilon}{6\xi}$.
\end{rem}


\section{\label{sec:Conclusions}Conclusions}

In this article, we provided sufficient conditions to approximate
certain integrals appearing in mathematical finance using the COS
method in multidimensions. The COS method requires several parameters:
In particular, one has to specify a truncation range $\boldsymbol{L}$
for the density $f$ of the logarithmic returns, a truncation range
$\boldsymbol{M}$ for the payoff function and the number $\boldsymbol{N}$
of cosine functions to approximate the truncated density. Corollary
\ref{cor:generalCase} provides sufficient conditions on $\boldsymbol{M}$,
$\boldsymbol{L}$ and $\boldsymbol{N}$ to ensure the convergence
of the COS method within a given error tolerance $\varepsilon>0$.

Furthermore, an error tolerance for approximating the characteristic
function $\varphi$ of $f$ by some function $\tilde{\varphi}$ in
the supremum norm need to be provided. This error tolerance depends
on $\boldsymbol{N}$, i.e., the higher the number of terms, the better
$\tilde{\varphi}$ has to approximate $\varphi$ to ensure the convergence
of the COS method. Finally, the Fourier-cosine coefficients of the
payoff function must also be approximated in applications and Corollary
\ref{cor:generalCase} provides conditions on the maximal tolerable
approximation error between the Fourier-cosine coefficients and their
numerical approximations.

\appendix

\section{Auxiliary results}

The following lemma generalizes some results in \cite{ruijter2012two}
for $d\leq3$ to arbitrary dimensions.
\begin{lem}
\label{lem:int fe}Let $f\in\mathcal{L}^{1}$, $\mathcal{A}\subset\mathbb{R}^{d}$
and $\boldsymbol{k}\in\mathbb{N}_{0}^{d}$. Then it holds that
\[
\int_{\mathcal{A}}f(\boldsymbol{x})e_{\boldsymbol{k}}(\boldsymbol{x})d\boldsymbol{x}=\frac{1}{2^{d-1}}\sum_{\boldsymbol{s}=(1,\pm1,...,\pm1)\in\mathbb{R}^{d}}\Re\bigg\{\int_{\mathcal{A}}f(\boldsymbol{x})e^{i\frac{\pi}{2}\boldsymbol{\frac{\boldsymbol{sk}}{\boldsymbol{L}}}\cdot\boldsymbol{x}}d\boldsymbol{x}\exp\big(i\frac{\pi}{2}\boldsymbol{s}\cdot\boldsymbol{k}\big)\bigg\}.
\]
\end{lem}

\begin{proof}
It follows by mathematical induction, the fact that cosine is an even
function and the well-known identity,
\[
\cos\theta_{1}\cos\theta_{2}=\frac{1}{2}\left(\cos(\theta_{1}+\theta_{2})+\cos(\theta_{1}-\theta_{2})\right),\quad\theta_{1},\theta_{2}\in\mathbb{R},
\]
see Equations (4.3.17) and (4.3.31) in \cite{abramowitz1972handbook},
that
\begin{align*}
\prod_{h=1}^{d}\cos\theta_{h} & =\frac{1}{2^{d-1}}\sum_{\boldsymbol{s}=(1,\pm1,...,\pm1)\in\mathbb{R}^{d}}\cos\left(\boldsymbol{s}\cdot\boldsymbol{\theta}\right),\quad\boldsymbol{\theta}\in\mathbb{R}^{d}.
\end{align*}
\begin{comment}
$d=2$, then
\begin{align*}
\prod_{i=1}^{d}\cos\theta_{i} & =\cos\theta_{1}\cos\theta_{2}=\frac{1}{2}\left(\cos(\theta_{1}+\theta_{2})+\cos(\theta_{1}-\theta_{2})\right)\\
 & =\frac{1}{2^{1}}\sum_{s_{2}=\pm1}\cos\left(\theta_{1}+s_{s}\theta_{2}\right)
\end{align*}

$d\to d+1$
\begin{align*}
 & \prod_{i=1}^{d+1}\cos\theta_{i}\\
 & =\prod_{i=1}^{d}\cos\theta_{i}\cos(\theta_{d+1})\\
 & =\left(\frac{1}{2^{d-1}}\sum_{s_{2}=\pm1,...,s_{d}=\pm1}\cos\left(\theta_{1}+s_{s}\theta_{2}+...+s_{d}\theta_{d}\right)\right)\cos(\theta_{d+1})\\
 & =\frac{1}{2^{d-1}}\sum_{s_{2}=\pm1,...,s_{d}=\pm1}\cos\left(\theta_{1}+s_{s}\theta_{2}+...+s_{d}\theta_{d}\right)\cos(\theta_{d+1})\\
 & =\frac{1}{2^{d-1}}\sum_{s_{2}=\pm1,...,s_{d}=\pm1}\frac{1}{2}\left(\cos\left(\theta_{1}+s_{s}\theta_{2}+...+s_{d}\theta_{d}+\theta_{d}\right)+\cos\left(\theta_{1}+s_{s}\theta_{2}+...+s_{d}\theta_{d}-\theta_{d}\right)\right)\\
 & =\frac{1}{2^{d}}\sum_{s_{2}=\pm1,...,s_{d}=\pm1.s_{d+1}=\pm1}\cos\left(\theta_{1}+s_{s}\theta_{2}+...+s_{d}\theta_{d}+s_{d+1}\theta_{d+1}\right)
\end{align*}
\end{comment}
Hence,
\begin{align*}
\int_{\mathcal{A}}f(\boldsymbol{x})e_{\boldsymbol{k}}(\boldsymbol{x})d\boldsymbol{x}= & \int_{\mathcal{A}}f(\boldsymbol{x})\prod_{h=1}^{d}\cos\left(k_{h}\frac{\pi}{2}\frac{x_{h}+L_{h}}{L_{h}}\right)d\boldsymbol{x}\\
= & \frac{1}{2^{d-1}}\sum_{\boldsymbol{s}=(1,\pm1,...,\pm1)\in\mathbb{R}^{d}}\int_{\mathcal{A}}f(\boldsymbol{x})\cos\left(\frac{\pi}{2}\boldsymbol{s}\cdot\big(\boldsymbol{k}\frac{\boldsymbol{x}+\boldsymbol{L}}{\boldsymbol{L}}\big)\right)d\boldsymbol{x}\\
= & \frac{1}{2^{d-1}}\sum_{\boldsymbol{s}=(1,\pm1,...,\pm1)\in\mathbb{R}^{d}}\Re\left\{ \int_{\mathcal{A}}f(\boldsymbol{x})e^{i\frac{\pi}{2}\boldsymbol{\frac{\boldsymbol{sk}}{\boldsymbol{L}}}\cdot\boldsymbol{x}}d\boldsymbol{x}\exp\left(i\frac{\pi}{2}\boldsymbol{s}\cdot\boldsymbol{k}\right)\right\} .
\end{align*}
\end{proof}
\bibliographystyle{plainnat}
\bibliography{biblio}

\end{document}
