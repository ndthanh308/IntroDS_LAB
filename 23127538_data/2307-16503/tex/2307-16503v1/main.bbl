\begin{thebibliography}{10}
\providecommand{\url}[1]{#1}
\csname url@rmstyle\endcsname
\providecommand{\newblock}{\relax}
\providecommand{\bibinfo}[2]{#2}
\providecommand\BIBentrySTDinterwordspacing{\spaceskip=0pt\relax}
\providecommand\BIBentryALTinterwordstretchfactor{4}
\providecommand\BIBentryALTinterwordspacing{\spaceskip=\fontdimen2\font plus
\BIBentryALTinterwordstretchfactor\fontdimen3\font minus
  \fontdimen4\font\relax}
\providecommand\BIBforeignlanguage[2]{{%
\expandafter\ifx\csname l@#1\endcsname\relax
\typeout{** WARNING: IEEEtran.bst: No hyphenation pattern has been}%
\typeout{** loaded for the language `#1'. Using the pattern for}%
\typeout{** the default language instead.}%
\else
\language=\csname l@#1\endcsname
\fi
#2}}

\bibitem{ras}
M.~Yip and N.~Das, ``Robot autonomy for surgery,'' in \emph{The Encyclopedia of
  MEDICAL ROBOTICS: Volume 1 Minimally Invasive Surgical Robotics}, 2019.

\bibitem{meli2021autonomous}
D.~Meli, E.~Tagliabue, D.~Dall’Alba, and P.~Fiorini, ``Autonomous tissue
  retraction with a biomechanically informed logic based framework,'' in
  \emph{International Symposium on Medical Robotics (ISMR)}, 2021.

\bibitem{ibarz2021train}
J.~Ibarz, J.~Tan, C.~Finn, M.~Kalakrishnan, P.~Pastor, and S.~Levine, ``How to
  train your robot with deep reinforcement learning: lessons we have learned,''
  \emph{The International Journal of Robotics Research (IJRR)}, 2021.

\bibitem{riedmiller2018learning}
M.~Riedmiller, R.~Hafner, T.~Lampe, M.~Neunert, J.~Degrave, T.~Wiele, V.~Mnih,
  N.~Heess, and J.~T. Springenberg, ``Learning by playing solving sparse reward
  tasks from scratch,'' in \emph{International Conference on Machine Learning
  (ICML)}, 2018.

\bibitem{ddpgher}
A.~Nair, B.~McGrew, M.~Andrychowicz, W.~Zaremba, and P.~Abbeel, ``Overcoming
  exploration in reinforcement learning with demonstrations,'' in \emph{IEEE
  International Conference on Robotics and Automation (ICRA)}, 2018.

\bibitem{lee2020learning}
Y.~Lee, J.~Yang, and J.~J. Lim, ``Learning to coordinate manipulation skills
  via skill behavior diversification,'' in \emph{International conference on
  learning representations (ICLR)}, 2020.

\bibitem{lee2019composing}
Y.~Lee, S.-H. Sun, S.~Somasundaram, E.~S. Hu, and J.~J. Lim, ``Composing
  complex skills by learning transition policies,'' in \emph{International
  Conference on Learning Representations (ICLR)}, 2019.

\bibitem{byun2022training}
J.-S. BYUN and A.~Perrault, ``Training transition policies via distribution
  matching for complex tasks,'' in \emph{International Conference on Learning
  Representations (ICLR)}, 2022.

\bibitem{lee2022adversarial}
Y.~Lee, J.~J. Lim, A.~Anandkumar, and Y.~Zhu, ``Adversarial skill chaining for
  long-horizon robot manipulation via terminal state regularization,'' in
  \emph{Conference on Robot Learning (CoRL)}, 2021.

\bibitem{clegg2018learning}
A.~Clegg, W.~Yu, J.~Tan, C.~K. Liu, and G.~Turk, ``Learning to dress:
  Synthesizing human dressing motion via deep reinforcement learning,''
  \emph{ACM Transactions on Graphics (TOG)}, 2018.

\bibitem{surrol}
J.~Xu, B.~Li, B.~Lu, Y.-H. Liu, Q.~Dou, and P.-A. Heng, ``Surrol: An
  open-source reinforcement learning centered and dvrk compatible platform for
  surgical robot learning,'' in \emph{IEEE/RSJ International Conference on
  Intelligent Robots and Systems (IROS)}, 2021.

\bibitem{cutting1}
B.~Thananjeyan, A.~Garg, S.~Krishnan, C.~Chen, L.~Miller, and K.~Goldberg,
  ``Multilateral surgical pattern cutting in 2d orthotropic gauze with deep
  reinforcement learning policies for tensioning,'' in \emph{IEEE International
  Conference on Robotics and Automation (ICRA)}, 2017.

\bibitem{nguyen2019new}
T.~Nguyen, N.~D. Nguyen, F.~Bello, and S.~Nahavandi, ``A new tensioning method
  using deep reinforcement learning for surgical pattern cutting,'' in
  \emph{2019 IEEE international conference on industrial technology (ICIT)},
  2019.

\bibitem{nguyen2019manipulating}
N.~D. Nguyen, T.~Nguyen, S.~Nahavandi, A.~Bhatti, and G.~Guest, ``Manipulating
  soft tissues by deep reinforcement learning for autonomous robotic surgery,''
  in \emph{IEEE International Systems Conference (SysCon)}, 2019.

\bibitem{flexml}
E.~Tagliabue, A.~Pore, D.~Dall’Alba, E.~Magnabosco, M.~Piccinelli, and
  P.~Fiorini, ``Soft tissue simulation environment to learn manipulation tasks
  in autonomous robotic surgery,'' in \emph{IEEE/RSJ International Conference
  on Intelligent Robots and Systems (IROS)}, 2020.

\bibitem{srl_reward}
A.~Pore, D.~Corsi, E.~Marchesini, D.~Dall’Alba, A.~Casals, A.~Farinelli, and
  P.~Fiorini, ``Safe reinforcement learning using formal verification for
  tissue retraction in autonomous robotic-assisted surgery,'' \emph{IEEE/RSJ
  International Conference on Intelligent Robots and Systems (IROS)}, 2021.

\bibitem{tissue_lfd}
A.~Pore, E.~Tagliabue, M.~Piccinelli, D.~Dall’Alba, A.~Casals, and
  P.~Fiorini, ``Learning from demonstrations for autonomous soft-tissue
  retraction,'' in \emph{International Symposium on Medical Robotics (ISMR)},
  2021.

\bibitem{zhang2022human}
D.~Zhang, Z.~Wu, J.~Chen, R.~Zhu, A.~Munawar, B.~Xiao, Y.~Guan, H.~Su, W.~Hong,
  Y.~Guo, \emph{et~al.}, ``Human-robot shared control for surgical robot based
  on context-aware sim-to-real adaptation,'' in \emph{IEEE International
  Conference on Robotics and Automation (ICRA)}, 2022.

\bibitem{huang2023guided}
T.~Huang, K.~Chen, B.~Li, Y.-H. Liu, and Q.~Dou, ``Guided reinforcement
  learning with efficient exploration for task automation of surgical robot,''
  in \emph{IEEE International Conference on Robotics and Automation (ICRA)},
  2023.

\bibitem{ginesi2019knowledge}
M.~Ginesi, D.~Meli, H.~Nakawala, A.~Roberti, and P.~Fiorini, ``A
  knowledge-based framework for task automation in surgery,'' in
  \emph{International Conference on Advanced Robotics (ICAR)}, 2019.

\bibitem{ginesi2020autonomous}
M.~Ginesi, D.~Meli, A.~Roberti, N.~Sansonetto, and P.~Fiorini, ``Autonomous
  task planning and situation awareness in robotic surgery,'' in
  \emph{International Conference on Intelligent Robots and Systems (IROS)},
  2020.

\bibitem{schwaner2021autonomous}
K.~L. Schwaner, I.~Iturrate, J.~K. Andersen, P.~T. Jensen, and T.~R.
  Savarimuthu, ``Autonomous bi-manual surgical suturing based on skills learned
  from demonstration,'' in \emph{International Conference on Intelligent Robots
  and Systems (IROS)}, 2021.

\bibitem{schwaner2021autonomous-suture}
K.~L. Schwaner, D.~Dall'Alba, P.~T. Jensen, P.~Fiorini, and T.~R. Savarimuthu,
  ``Autonomous needle manipulation for robotic surgical suturing based on
  skills learned from demonstration,'' in \emph{IEEE International Conference
  on Automation Science and Engineering (CASE)}, 2021.

\bibitem{srl_multistage}
V.~M. Varier, D.~K. Rajamani, N.~Goldfarb, F.~Tavakkolmoghaddam, A.~Munawar,
  and G.~S. Fischer, ``Collaborative suturing: A reinforcement learning
  approach to automate hand-off task in suturing for surgical robots,''
  \emph{IEEE International Conference on Robot and Human Interactive
  Communication}, 2020.

\bibitem{wilcox2022learning}
A.~Wilcox, J.~Kerr, B.~Thananjeyan, J.~Ichnowski, M.~Hwang, S.~Paradis, D.~Fer,
  and K.~Goldberg, ``Learning to localize, grasp, and hand over unmodified
  surgical needles,'' in \emph{IEEE International Conference on Robotics and
  Automation (ICRA)}, 2022.

\bibitem{konidaris2009skill}
G.~Konidaris and A.~Barto, ``Skill discovery in continuous reinforcement
  learning domains using skill chaining,'' \emph{Advances in Neural Information
  Processing Systems (NeurIPS)}, 2009.

\bibitem{konidaris2012robot}
G.~Konidaris, S.~Kuindersma, R.~Grupen, and A.~Barto, ``Robot learning from
  demonstration by constructing skill trees,'' \emph{The International Journal
  of Robotics Research (IJRR)}, 2012.

\bibitem{bagaria2020option}
A.~Bagaria and G.~Konidaris, ``Option discovery using deep skill chaining,'' in
  \emph{International Conference on Learning Representations (ICLR)}, 2020.

\bibitem{bagaria2021robustly}
A.~Bagaria, J.~Senthil, M.~Slivinski, and G.~Konidaris, ``Robustly learning
  composable options in deep reinforcement learning,'' in \emph{International
  Joint Conference on Artificial Intelligence (IJCAI)}, 2021.

\bibitem{ghoshdivide}
D.~Ghosh, A.~Singh, A.~Rajeswaran, V.~Kumar, and S.~Levine,
  ``Divide-and-conquer reinforcement learning,'' in \emph{International
  Conference on Learning Representations (ICLR)}, 2018.

\bibitem{nasiriany2019planning}
S.~Nasiriany, V.~Pong, S.~Lin, and S.~Levine, ``Planning with goal-conditioned
  policies,'' 2019.

\bibitem{andreas2017modular}
J.~Andreas, D.~Klein, and S.~Levine, ``Modular multitask reinforcement learning
  with policy sketches,'' in \emph{International Conference on Machine Learning
  (ICML)}, 2017.

\bibitem{schaul2015universal}
T.~Schaul, D.~Horgan, K.~Gregor, and D.~Silver, ``Universal value function
  approximators,'' in \emph{International Conference on Machine Learning
  (ICML)}, 2015.

\bibitem{oh2018self}
J.~Oh, Y.~Guo, S.~Singh, and H.~Lee, ``Self-imitation learning,'' in
  \emph{International Conference on Machine Learning (ICML)}, 2018.

\bibitem{awac}
A.~Nair, A.~Gupta, M.~Dalal, and S.~Levine, ``Awac: Accelerating online
  reinforcement learning with offline datasets,'' \emph{arXiv preprint
  arXiv:2006.09359}, 2020.

\bibitem{ding2019goal}
Y.~Ding, C.~Florensa, P.~Abbeel, and M.~Phielipp, ``Goal-conditioned imitation
  learning,'' in \emph{Advances in Neural Information Processing Systems
  (NeurIPS)}, 2019.

\bibitem{sac}
T.~Haarnoja, A.~Zhou, P.~Abbeel, and S.~Levine, ``Soft actor-critic: Off-policy
  maximum entropy deep reinforcement learning with a stochastic actor,'' in
  \emph{International Conference on Machine Learning (ICML)}, 2018.

\bibitem{adam}
D.~P. Kingma and J.~Ba, ``Adam: A method for stochastic optimization,'' in
  \emph{International Conference on Learning Representations (ICLR)}, 2015.

\end{thebibliography}
