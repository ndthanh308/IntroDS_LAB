% This must be in the first 5 lines to tell arXiv to use pdfLaTeX, which is strongly recommended.
\pdfoutput=1
% In particular, the hyperref package requires pdfLaTeX in order to break URLs across lines.
\newcommand{\ggrev}[2]{\textcolor{black}{#2}} 
\documentclass[11pt]{article}
\usepackage[table,xcdraw]{xcolor}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{graphicx}
% Remove the "review" option to generate the final version.
\usepackage[]{ACL2023}
\usepackage{cuted, ragged2e}
% Standard package includes
\usepackage{times}
\usepackage{latexsym}
\usepackage{svg}
\usepackage{lscape}
\usepackage{floatrow}
\usepackage{tabularx}
\usepackage{tabto}
\usepackage{listings}
\usepackage{multirow}
\def\rot{\rotatebox}
\usepackage{caption}
\usepackage{subcaption}
\definecolor{Mycolor1}{HTML}{004488}
\definecolor{Mycolor2}{HTML}{DDAA33}
\definecolor{Mycolor3}{HTML}{BB5566}

% For proper rendering and hyphenation of words containing Latin characters (including in bib files)
\usepackage[T1]{fontenc}


% This assumes your files are encoded as UTF8
\usepackage[utf8]{inputenc}
\usepackage{pgfplots}
\pgfplotsset{compat=1.9}

% This is not strictly necessary, and may be commented out.
% However, it will improve the layout of the manuscript,
% and will typically save some space.
\usepackage{microtype}
%\usepackage{subfig}
% This is also not strictly necessary, and may be commented out.
% However, it will improve the aesthetics of text in
% the typewriter font.
\usepackage{inconsolata}
\usepackage{capt-of}
\usepackage{adjustbox}
\usepackage{caption}
\usepackage{subcaption}
\definecolor{Mycolor1}{HTML}{004488}
\definecolor{Mycolor2}{HTML}{DDAA33}
\definecolor{Mycolor3}{HTML}{BB5566}


\usepackage{todonotes}

\title{Metric-Based In-context Learning: A Case Study in Text Simplification}

\author{Subha Vadlamannati \\
  Mercer Island High School \\
  Seattle, USA\\
  \texttt{subhavee2@gmail.com} \\\And
  Gözde Gül Şahin \\
  Computer Engineering Department \\
  Koç University, Istanbul, Turkey \\ 
  \texttt{gosahin@ku.edu.tr} }

\begin{document} 
\maketitle
\begin{abstract}
In-context learning (ICL) for large language models has proven to be a powerful approach for many natural language processing tasks. However, determining the best method to select examples for ICL is nontrivial as the results can vary greatly depending on the quality, quantity, and order of examples used. In this paper, we conduct a case study on text simplification (TS) to investigate how to select the best and most robust examples for ICL. We propose \textbf{M}etric-\textbf{B}ased in-context \textbf{L}earning~(MBL) method that utilizes commonly used TS metrics such as SARI, compression ratio, and BERT-Precision for selection. Through an extensive set of experiments with various-sized GPT models on standard TS benchmarks such as TurkCorpus and ASSET, we show that examples selected by the top SARI scores perform the best on larger models such as GPT-175B, while the compression ratio generally performs better on smaller models such as GPT-13B and GPT-6.7B. Furthermore, we demonstrate that MBL is generally robust to example orderings and out-of-domain test sets, and outperforms strong baselines and state-of-the-art finetuned language models. Finally, we show that the behaviour of large GPT models can be \textit{implicitly controlled} by the chosen metric. Our research provides a new framework for selecting examples in ICL, and demonstrates its effectiveness in text simplification tasks, breaking new ground for more accurate and efficient NLG systems.
\end{abstract}

\section{Introduction}
\input{sections/intro}


\section{Related Work}
\label{sec:rel_work}
\input{sections/relatedWork}


\section{Metric-based In-Context Learning}
\input{sections/method}


\section{Experimental Setup}
\label{sec:setup}
\input{sections/setup}


\section{Experiments and Results}
\input{sections/ggresults}


\section{Qualitative Analysis}
\label{sec:discussion}
\input{sections/discussion.tex}


\section{Conclusion and Future Work}
In conclusion, we propose a novel and robust method for selecting examples in the TS domain, evaluating its effectiveness on multiple well-known TS datasets and even on downstream tasks like cognitive simplification. Our experiments demonstrate state-of-the-art results in the field of TS and CS, reaching scores of 44.86 on FestAbility, 47.94 on ASSET and 43.46 on TurkCorpus. We hope that future work will generalize our findings in other text generation tasks and other domains. %Future research can also explore the effect of other example selection metrics based on the TS domain and their respective effects on model performance. 

\section*{Limitations}

Our approach is computationally and financially intensive, especially on the GPT-175B model, which limits its scalability to smaller, open-source models. While our approach has shown strong results in the TS domain, we are not yet sure whether using domain-specific selection methods is widely applicable. Our approach also is not applicable in true few-shot settings in which a large validation set is not available to select examples from. Also, our approaches' scalability to other downstream TS tasks outside of cognitive simplification is yet to be tested, especially in different domains. We tested on two well-known TS datasets (ASSET and TurkCorpus), and we did not test on another known TS dataset, Newsela, due to its restrictive licensing. Additionally, we have tested our approach on example numbers up to $15$ due to financial constraints, and testing on higher numbers of examples may show additional insights and we leave this for future researchers.


\section*{Ethics Statement}
%We do not see immediate risks that our approach poses, and alternatively, we believe further research in text simplification with individuals with cognitive disabilities can help improve equity in this field. %We take considerations from \citet{gooding-2022-ethical} into account when acknowledging the ethical limitations of our work, and 
We acknowledge that while our approach reaches high scores on datasets aimed for individuals with disabilities, further research and evaluation from humans with specific disabilities listed in this paper is crucial to determine the true effectiveness of our approach in these scenarios.


\section*{Acknowledgements}
This work has been supported by the Scientific and Technological Research Council of Türkiye~(TÜBİTAK) as part of the project ``Automatic Learning of Procedural Language from Natural Language Instructions for Intelligent Assistance'' with the number 121C132. We also gratefully acknowledge the Fatima Fellowship and KUIS AI Lab for providing support. We thank our anonymous reviewers and the members of GGLab who helped us improve this paper. 


% Entries for the entire Anthology, followed by custom entries
\bibliography{custom}
\bibliographystyle{acl_natbib}

\clearpage
\appendix

\section{Optimal Settings}
\label{sec:optimalsettings}

In this section, we provide full optimal settings in Table~\ref{tab:bestsettings} for the ``Random Best'' and ``MBL Best'' models. These settings are all in-domain (i.e., ASSET Validation, ASSET Tune; MTurk Validation, MTurk Tune) and include model size, $k$ (number of examples), and ordering (high/low, low/high, and random).



\begin{table}[!htp]
\scalebox{0.65}{
\begin{tabular}{l|l|l|l|l} \toprule
Metric and Dataset  & Model & Metric   & k  & Ordering \\ \midrule
MBL Best TurkCorpus   & GPT-175B & SARI & 6  & High/Low \\
Random Best TurkCorpus & GPT-175B & SARI & 8  & Low/High \\
MBL Best ASSET        & GPT-175B & SARI & 15 & Random   \\
Random Best ASSET      & GPT-175B & SARI & 10 & Random  \\
\bottomrule
\end{tabular}
}
\caption{MBL-Best and Random-Best settings for results}
\label{tab:bestsettings}
\end{table}

\section{BLEU Results}
\label{sec:bleuresults}

In this section, we include full BLEU results in Figure \ref{fig:dataset_all_models_bleu} including all model sizes ($175$B, $13$B, $6.7$B), datasets (TurkCorpus and ASSET) and selection techniques. 

% Figure environment removed


\section{Top ASSET Examples}
\label{sec:topasset}

In this section, we include extended results from \ref{tab:top2examples}, with the top $3$-$10$ results from the ASSET Validation dataset based on top SARI (Section \ref{ssec:top10sari}), CR, and BERTPrec (Section \ref{ssec:top10bertprec}) scores.

\subsection{SARI}
\label{ssec:top10sari}

In this section, we include the top $3$ to $10$ examples based on SARI score selected from the ASSET Validation dataset in Table~\ref{tab:3to10sari}.

\begin{table*}[htbp]
\centering
\small
\renewcommand{\arraystretch}{1.5}
\begin{tabular}{p{0.05\linewidth} p{0.75\linewidth}} \toprule
k & Example \\ \midrule
3 & \textbf{Complex Sentence} It is adjacent to Lord Wandsworth College. \newline \textbf{Simple Sentence} it is next to Lord Wandsworth College.\\
\midrule
4 & \textbf{Complex Sentence} He took the post of chief conductor of the Netherlands Radio Philharmonic in 1957. \newline \textbf{Simple Sentence} He became the chief conductor of the Netherlands Radio Philharmonic in 1957.\\
\midrule
5 & \textbf{Complex Sentence} It was discovered on February 27, 1995. \newline \textbf{Simple Sentence} It was found on February 27, 1995.\\
\midrule
6 & \textbf{Complex Sentence} Surnames Aaron Schock, member of the U. S. House of Representatives representing the 18th district of Illinois. \newline \textbf{Simple Sentence} Surnames Aaron Schock is a member of the U. S. House of Representatives. He represents the 18th district of Illinois.\\
\midrule
7 & \textbf{Complex Sentence} Mork holds a Professorship at the Norwegian Academy of Music, Oslo. \newline \textbf{Simple Sentence} Mork is a Professor at the Norwegian Academy of Music.\\
\midrule
    8   & \textbf{Complex Sentence} The Hubble Space Telescope observed Fortuna in 1993.  \newline                                   \textbf{Simple Sentence}  The Hubble Space Telescope saw Fortuna in 1993.\\
    \midrule

    9   & \textbf{Complex Sentence} The lithosphere is underlain by the asthenosphere, the weaker, hotter, and deeper part of the upper mantle.  \newline                                   \textbf{Simple Sentence} The lithosphere is supported by the asthenosphere, the weaker, hotter, and deeper part of the upper mantle.\\
    \midrule

    10   & \textbf{Complex Sentence} The Beatles famously included his face on the cover of Sgt. Pepper's Lonely Hearts Club Band (Guy and Llewelyn-Jones 2004, 111).
  \newline                                   \textbf{Simple Sentence} The Beatles put his face on the cover of Sgt. Pepper's Lonely Hearts Club Band.\\ 
    \bottomrule
    \end{tabular}
    \caption{Top 3-10 Examples from SARI, ASSET Validation dataset.} 
    \label{tab:3to10sari}
\end{table*}

\subsection{BERTPrec}
\label{ssec:top10bertprec}

In this section, we include the top $3$ to $10$ examples based on SARI score selected from the ASSET Validation dataset in Table~\ref{tab:bertprecexamples}.

\begin{table*}[htbp]
\centering
\small
\renewcommand{\arraystretch}{1.5}
\begin{tabular}{p{0.05\linewidth} p{0.75\linewidth}} \toprule
k & Example \\ \midrule
3 & \textbf{Complex Sentence} The Convent has been the official residence of the Governor of Gibraltar since 1728. \newline \textbf{Simple Sentence} The Convent has been the residence of the Governor of Gibraltar since 1728.\\
\midrule
4 & \textbf{Complex Sentence} Scholarships, Academic Awards, Flying Eagle Awards and Improvement Awards are given to students with outstanding academic achievements. \newline \textbf{Simple Sentence} Scholarships, Academic Awards, Flying Eagle Awards and Improvement Awards are given to students with academic achievements.\\
\midrule
5 & \textbf{Complex Sentence} The blood vessels in the human body include arteries, veins and capillaries. \newline \textbf{Simple Sentence} The blood vessels in the human body are called arteries, veins and capillaries.\\
\midrule
6 & \textbf{Complex Sentence} Frederick had a summer residence built there for Sophie Charlotte by the architect Johann Arnold Nering between 1695 and 1699. \newline \textbf{Simple Sentence} Frederick had a summer residence built for Sophie Charlotte by the architect Johann Arnold Nering between 1695 and 1699.\\
\midrule
7 & \textbf{Complex Sentence} The film stars Al Pacino, John Cazale, Chris Sarandon, James Broderick, and Charles Durning. \newline \textbf{Simple Sentence} The movie stars Al Pacino, John Cazale, Chris Sarandon, James Broderick, and Charles Durning.\\
\midrule
8 & \textbf{Complex Sentence} According to an interview in the UK newspaper The Sun, Heyman wrote the brand's weekly scripts and submitted them to writers for possible changes, and then Vince McMahon for final approval. \newline \textbf{Simple Sentence} According to an interview in the UK newspaper The Sun, Heyman wrote the brand's weekly scripts and sent them to writers for possible changes, and then Vince McMahon for final approval.\\
\midrule
9 & \textbf{Complex Sentence} In March 2001, the World Wrestling Federation purchased World Championship Wrestling. \newline \textbf{Simple Sentence} In March 2001, the World Wrestling Federation bought World Championship Wrestling.\\
\midrule
10 & \textbf{Complex Sentence} Becker defeated Jim Courier in straight sets to win the 1992 year-end ATP Tour World Championships in Frankfurt. \newline \textbf{Simple Sentence} Becker defeated Jim Courier in straight sets to win the 1992 year-end ATP Tour World Championships.\\
\bottomrule
\end{tabular}
\caption{Top 3-10 Examples from BERTPrec, ASSET Validation dataset.}
\label{tab:bertprecexamples}
\end{table*}

\section{Selected Model Generated Outputs}
\label{sec:modeloutputs}

In this section, we analyze select model generated outputs on 4 (5 for GPT-175B) different example-selection methods (Random, SARI, CR, BERTPrec and optionally KATE-GPT) on different models for in-domain configurations of the ASSET dataset. The original sentence in all of these is "OEL manga series Graystripe's Trilogy There is a three volume original English-language manga series following Graystripe, between the time that he was taken by Twolegs in Dawn until he returned to ThunderClan in The Sight." This sentence was specifically picked from the ASSET/TurkCorpus test dataset based on three reasons: 1) complexity (potentially confusing abbreviations and unconventional sentence structure) 2) length 3) unfamiliar/domain-specific terms from "Warrior Cats" (e.g. "ThunderClan" and "Twolegs"). \S\ref{ssec:curieasset} includes generations on GPT-$13$B, \S\ref{ssec:babbageasset} includes generatons on GPT-$6.7$B, and \S\ref{ssec:dv3asset} includes generations on GPT-$175$B.

\subsection{Selected GPT-13B Generations}
\label{ssec:curieasset}
In this section, we include generations from the original sentence mentioned in \ref{sec:modeloutputs} on GPT-$13$B on the ASSET Test set.

\begin{table*}[htbp]
         \centering
            \small
             \renewcommand{\arraystretch}{1.5}
        \begin{tabular}{p{0.1\linewidth} p{0.75\linewidth}} \toprule
        Metric   & Curie Simplifications \\   \midrule                                                                                                     
        Random   &  there is a three volume manga series following graystripe between the time that he was taken by twolegs in dawn and he returned to thunderclan in the sight .\\
        \midrule
        SARI   &  There is a three-volume original English-language manga series following graystripe, between the time he was taken by twolegs in dawn and he returned to thunderclan in the sight.\\
        \midrule
        CR   &  There is a three volume manga series following graystripe between the time he was taken by twolegs in dawn and he returned to thunderclan in the sight.\\
        \midrule
        BERTPrec   &  There is a three volume original English-language manga series following graystripe , between the time that he was taken by twolegs in dawn and he returned to thunderclan in the sight .\\ 
        \bottomrule
        \end{tabular}
        \caption{Curie Simplifications for a selected complex sentence, ran on ASSET.} 
         \label{tab:curie}
    \end{table*}

\subsection{Selected GPT-6.7B Generations}
\label{ssec:babbageasset}
In this section, we include generations from the original sentence mentioned in \ref{sec:modeloutputs} on GPT-$6.7$B on the ASSET Test set.

\begin{table*}[htbp]
            \small  
             \renewcommand{\arraystretch}{1.5}
        \begin{tabular}{p{0.1\linewidth} p{0.75\linewidth}} \toprule
        Metric   & Curie Simplifications \\   \midrule                                                                                                     
        Random   &  oel manga series graystripe 's trilogy there is a three volume original english-language manga series following graystripe between the time that he was taken by twolegs in dawn until he returned to thunderclan in the sight .\\
        \midrule
        SARI   &  oel manga series graystripe 's trilogy there is a three volume original english-language manga series following graystripe , between the time that he was taken by twolegs in dawn until he returned to thunderclan in the sight .\\
        \midrule
        CR   &  OEL manga series, Graystripe 's Trilogy, has a three volume original English-language manga series following Graystripe, between the time that he was taken by twolegs in dawn until he returned to thunderclan in the sight.
\\
        \midrule
        BERTPrec   &  oel manga series graystripe 's trilogy there is a three volume original english-language manga series following graystripe , between the time that he was taken by twolegs in dawn until he returned to thunderclan in the sight .\\ 
        \bottomrule
        \end{tabular}
        \caption{Babbage Simplifications for a selected complex sentence, ran on ASSET.} 
        \label{tab:babbage}
    \end{table*}


\subsection{Selected GPT-175B Generations}
\label{ssec:dv3asset}
In this section, we include generations from the original sentence mentioned in \ref{sec:modeloutputs} on GPT-$175$B on the ASSET Test set. Text in \textcolor{Mycolor3}{red} indicates text that has been successfully been changed from the abbreviation "OEL" to an interpretable phrase (either "English-language" or "original English-language"). 

\begin{table*}[t]
\centering \small
\renewcommand{\arraystretch}{2}
\begin{tabular}{@{}lp{0.80\textwidth}@{}}
\toprule
{\bf Original}    & OEL manga series Graystripe's Trilogy There is a three volume original English-language manga series following Graystripe, between the time that he was taken by Twolegs in Dawn until he returned to ThunderClan in The Sight.\\
{\bf Reference Simplification}      & There is a three volume \textcolor{Mycolor3}{original English-language} manga following Graystripe, between the time that he was taken by Twolegs in Dawn until he returned to ThunderClan in The Sight.\\
\hline
 \\
\midrule
{\bf k=2}    &  \\
{\bf KATE-GPT}      & Graystripe's Trilogy is a three volume \textcolor{Mycolor3}{original English-language} manga series following Graystripe from when he was taken by Twolegs to his return to ThunderClan.\\
\hline
{\bf BERTPrec}      & Graystripe's trilogy is a three-volume \textcolor{Mycolor3}{English-language} manga series about his time between being taken by twolegs in Dawn and returning to ThunderClan in The Sight.\\
\hline
{\bf SARI}      & Graystripe's trilogy is a three-volume \textcolor{Mycolor3}{original English-language} manga series. It follows Graystripe between the time he was taken by Twolegs in Dawn and when he returned to ThunderClan in The Sight.
\\
\hline
 \\
\midrule
{\bf k=8}    &  \\
{\bf KATE-GPT}      & The Graystripe's Trilogy is an OEL manga series that follows Graystripe's journey between the time he was taken by Twolegs in Dawn and his return to ThunderClan in The Sight.
\\
\hline
{\bf BERTPrec}      & Oel manga series Graystripe's trilogy follows Graystripe between being taken by twolegs in Dawn and returning to ThunderClan in The Sight. \\
\hline
{\bf SARI}      & Graystripe's trilogy is a three volume \textcolor{Mycolor3}{English-language} manga series about his time away from ThunderClan in Dawn. \\
\hline
 \\
\midrule
{\bf k=15}    &  \\
{\bf KATE-GPT}      & The OEL manga series Graystripe's Trilogy follows Graystripe between the time he was taken by Twolegs in Dawn and when he returned to ThunderClan in The Sight.\\
\hline
{\bf BERTPrec}      & Oel manga series graystripe's trilogy is a three-volume English-language manga series following Graystripe between his capture by twolegs in Dawn and his return to ThunderClan in The Sight.\\
\hline
{\bf SARI}      & Graystripe's trilogy is a three-volume \textcolor{Mycolor3}{English-language} manga series. It covers the time Graystripe was taken by twolegs in Dawn until he returned to ThunderClan in The Sight.
\\
\bottomrule
\end{tabular}
\caption{Model-generated simplifications on ASSET, GPT-$175$B.}
\label{tab:examples}
\end{table*}


\end{document}

