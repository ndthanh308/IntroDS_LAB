\section{Related work} \label{sec:related}
In recent years, numerous attempts have been made to explore the capabilities of QNNs using various techniques. In this section, we will discuss some notable works that focus primarily on the classification task, which is the central theme of this article.

First of all, there are several suggested concepts for the design of QNN-based classifiers \cite{farhi2018classification, cong2019quantum, henderson2020quanvolutional, wu2022wpscalable}. \cite{farhi2018classification} and \cite{cong2019quantum} concentrate on the ansatz design of QNNs. They are the fundamentals of current popular QNNs that use parametric unitary transformations to process data efficiently. However, scalability is a crucial concern for QNNs, particularly on NISQ devices, where the limited number of qubits restricts the quantum circuit's size and performance. Quanvolutional NN \cite{henderson2020quanvolutional} employs the quantum circuit of modest size as kernels of quantum convolution NN, rather than building the entire QNN. And SQNN \cite{wu2022wpscalable} scales up QNNs by constructing large-scale QNNs modularly and leveraging quantum computation resources from multiple quantum machines. All of these studies focus on binary classification tasks and demonstrate the advantages of QNNs. In addition to model scalability, the ability to scale the problem size is essential for improving the capacity of QNNs. In this article, we propose an approach that aims to expand the problem size that a QNN can handle without having to scale up its quantum circuit.





Many prior efforts have attempted to enhance the problem size that QNN classifiers can address \cite{bokhan2022multiclass, li2021vsql, nghiem2021unified, wu2020end, blank2020quantum, schuld2017implementing, yun2022projection, chalumuri2021hybrid, yang2020entanglement}. A QNN classifier with four ancilla qubits for 4-class classification is built in \cite{bokhan2022multiclass}. The capability of the solution is restricted by the quantum hardware, as larger problem sizes require additional ancilla qubits, which are not currently available on NISQ machines. \cite{chalumuri2021hybrid, yang2020entanglement} also address milt-classification problems by using ancilla qubits. An alternative solution is QuClassi proposed in \cite{stein2022quclassi}. It breaks down a multi-classification into several binary classifications. For each binary classification, the cost function is constructed based on quantum state fidelity by using SWAP, and only one ancilla qubit is needed for measurement to get the readout. The measurement results of all classes are softmaxed to obtain the final classification result. Despite the quantum computing resources being limited in this method, the training and inference processes are complicated and time-consuming. Similarly, a fidelity-based QNN classifier is proposed in \cite{schuld2017implementing}, but its QNN ansatz can only solve binary classification tasks. Moreover, VSQL \cite{li2021vsql} slides a predefined partial observable ``xx" across the qubits to get the classical shadows of the quantum state prepared by a QNN, and then feeds the local shadows to a classical fully-connected layer for decision making. Yet, the computationally demanding classical fully-connected layer may counteract the quantum speedup. A unified quantum classifier is presented in \cite{nghiem2021unified}. This approach investigates the connection between class labels and quantum states. In our study, we further investigate the distribution of quantum labels in Hilbert space based on interclass correlations and demonstrate its significance by highlighting the superior performance of our approach. Additionally, we introduce a loss adjuster during supervised learning to ensure optimal performance when dealing with multiple classes in the task at hand.














% Because the outcome of QNN is given by binary measurement results, some multi-classifiers use extra ancillary qubits to represent a label out of multiple classes \cite{chalumuri2021hybrid, yang2020entanglement}. 







% \cite{hur2022quantum} presents an comprehensive benchmark of the QCNN classifier for binary classification, including various quantum data encoding techniques, VQC structures, cost functions and optimizers.






% Measurement-based: \cite{yun2022projection}, QCNN with positive operator-valued measure(POVM) for feature extraction. QNN with projection-valued measure (PVM) for classification. The advantage is that the number of classes investigated can be increased. The drawback is that the approach frequently transforms the data between quantum and classical form, as well as a large number of  measurements, which hindered quantum speedup.





