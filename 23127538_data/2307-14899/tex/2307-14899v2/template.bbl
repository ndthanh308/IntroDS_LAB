\begin{thebibliography}{10}

\bibitem{pustejovsky2012natural}
James Pustejovsky and Amber Stubbs.
\newblock {\em Natural Language Annotation for Machine Learning: A guide to corpus-building for applications}.
\newblock O'Reilly Media, Inc., 2012.

\bibitem{atance2001episodic}
Cristina~M Atance and Daniela~K O'Neill.
\newblock Episodic future thinking.
\newblock {\em Trends in cognitive sciences}, 5(12):533--539, 2001.

\bibitem{bruch2022reneuir}
Sebastian Bruch, Claudio Lucchese, and Franco~Maria Nardini.
\newblock Reneuir: Reaching efficiency in neural information retrieval.
\newblock In {\em Proceedings of the 45th International ACM SIGIR Conference on Research and Development in Information Retrieval}, pages 3462--3465, 2022.

\bibitem{bast2016semantic}
Hannah Bast, Bj{\"o}rn Buchhold, Elmar Haussmann, et~al.
\newblock Semantic search on text and knowledge bases.
\newblock {\em Foundations and Trends{\textregistered} in Information Retrieval}, 10(2-3):119--271, 2016.

\bibitem{kenton2019bert}
Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova.
\newblock {BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding}.
\newblock In {\em Proceedings of NAACL-HLT}, pages 4171--4186, 2019.

\bibitem{karpukhin2020dense}
Vladimir Karpukhin, Barlas Oguz, Sewon Min, Patrick Lewis, Ledell Wu, Sergey Edunov, Danqi Chen, and Wen-tau Yih.
\newblock Dense passage retrieval for open-domain question answering.
\newblock In {\em Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)}, pages 6769--6781, 2020.

\bibitem{reimers2019sentence}
Nils Reimers and Iryna Gurevych.
\newblock {Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks}.
\newblock In {\em Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)}, pages 3982--3992, 2019.

\bibitem{thakur-etal-2021-augmented}
Nandan Thakur, Nils Reimers, Johannes Daxenberger, and Iryna Gurevych.
\newblock Augmented {SBERT}: Data augmentation method for improving bi-encoders for pairwise sentence scoring tasks.
\newblock In {\em Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies}, pages 296--310, Online, June 2021. Association for Computational Linguistics.

\bibitem{song2020mpnet}
Kaitao Song, Xu~Tan, Tao Qin, Jianfeng Lu, and Tie-Yan Liu.
\newblock {MPNet: Masked and Permuted Pre-training for Language Understanding}.
\newblock {\em Advances in Neural Information Processing Systems}, 33:16857--16867, 2020.

\bibitem{liu2019roberta}
Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, and Veselin Stoyanov.
\newblock {RoBERTa: A Robustly Optimized BERT Pretraining Approach}.
\newblock {\em arXiv [cs.CL] preprint arXiv:1907.11692}, 2019.

\bibitem{reimers2020making}
Nils Reimers and Iryna Gurevych.
\newblock Making monolingual sentence embeddings multilingual using knowledge distillation.
\newblock In {\em Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)}, pages 4512--4525, 2020.

\bibitem{chidambaram2019learning}
Muthu Chidambaram, Yinfei Yang, Daniel Cer, Steve Yuan, Yunhsuan Sung, Brian Strope, and Ray Kurzweil.
\newblock Learning cross-lingual sentence representations via a multi-task dual-encoder model.
\newblock In {\em Proceedings of the 4th Workshop on Representation Learning for NLP (RepL4NLP-2019)}, pages 250--259, 2019.

\bibitem{yang2020multilingual}
Yinfei Yang, Daniel Cer, Amin Ahmad, Mandy Guo, Jax Law, Noah Constant, Gustavo~Hernandez Abrego, Steve Yuan, Chris Tar, Yun-Hsuan Sung, et~al.
\newblock Multilingual universal sentence encoder for semantic retrieval.
\newblock In {\em Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics: System Demonstrations}, pages 87--94, 2020.

\bibitem{thakurbeir}
Nandan Thakur, Nils Reimers, Andreas R{\"u}ckl{\'e}, Abhishek Srivastava, and Iryna Gurevych.
\newblock {BEIR: A Heterogeneous Benchmark for Zero-shot Evaluation of Information Retrieval Models}.
\newblock In {\em Thirty-fifth Conference on Neural Information Processing Systems Datasets and Benchmarks Track}, 2021.

\bibitem{elasticsearch}
Elasticsearch.
\newblock Elasticsearch.
\newblock \url{https://www.elastic.co/}, 2010.
\newblock Accessed: April 6, 2023.

\bibitem{prasad2020enhancement}
Akshar Prasad, Sourabh~S Badhya, YS~Yashwanth, Rohan Shetty, G~Shobha, and N~Deepamala.
\newblock Enhancement of natural language to sql query conversion using machine learning techniques.
\newblock {\em International Journal of Advanced Computer Science and Applications}, 11(12), 2020.

\bibitem{lu2020auto}
Zhenyan Lu, Chao Chen, Jinhan Xin, and Zhibin Yu.
\newblock {On the Auto-Tuning of Elastic-Search based on Machine Learning}.
\newblock In {\em Proceedings of the 2020 1st International Conference on Control, Robotics and Intelligent System}, pages 150--156, 2020.

\bibitem{kim2022suggestion}
Mi~Kim and Dosung Kim.
\newblock A suggestion on the lda-based topic modeling technique based on elasticsearch for indexing academic research results.
\newblock {\em Applied Sciences}, 12(6):3118, 2022.

\bibitem{dong2022table}
Yuyang Dong and Masafumi Oyamada.
\newblock Table enrichment system for machine learning.
\newblock In {\em Proceedings of the 45th International ACM SIGIR Conference on Research and Development in Information Retrieval}, pages 3267--3271, 2022.

\bibitem{zamfir2019systems}
Vlad-Andrei Zamfir, Mihai Carabas, Costin Carabas, and Nicolae Tapus.
\newblock {Systems Monitoring and Big Data Analysis using the Elasticsearch System}.
\newblock In {\em 2019 22nd International Conference on Control Systems and Computer Science (CSCS)}, pages 188--193. IEEE, 2019.

\bibitem{liu2021document}
Zhiqiang Liu, Jingkun Feng, Zhihao Yang, and Lei Wang.
\newblock Document retrieval for precision medicine using a deep learning ensemble method.
\newblock {\em JMIR Medical Informatics}, 9(6):e28272, 2021.

\bibitem{johnson2019survey}
Justin~M Johnson and Taghi~M Khoshgoftaar.
\newblock Survey on deep learning with class imbalance.
\newblock {\em Journal of Big Data}, 6(1):1--54, 2019.

\bibitem{liu2008exploratory}
Xu-Ying Liu, Jianxin Wu, and Zhi-Hua Zhou.
\newblock Exploratory undersampling for class-imbalance learning.
\newblock {\em IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)}, 39(2):539--550, 2008.

\bibitem{japkowicz2002class}
Nathalie Japkowicz and Shaju Stephen.
\newblock The class imbalance problem: A systematic study.
\newblock {\em Intelligent data analysis}, 6(5):429--449, 2002.

\bibitem{japkowicz2000class}
Nathalie Japkowicz.
\newblock The class imbalance problem: Significance and strategies.
\newblock In {\em Proc. of the Int’l Conf. on artificial intelligence}, volume~56, pages 111--117, 2000.

\bibitem{stein2016unstuck}
Jeffrey~S Stein, A~George Wilson, Mikhail~N Koffarnus, Tinuke~Oluyomi Daniel, Leonard~H Epstein, and Warren~K Bickel.
\newblock Unstuck in time: episodic future thinking reduces delay discounting and cigarette smoking.
\newblock {\em Psychopharmacology}, 233:3771--3778, 2016.

\bibitem{stein2018episodic}
Jeffrey~S Stein, Allison~N Tegge, Jamie~K Turner, and Warren~K Bickel.
\newblock Episodic future thinking reduces delay discounting and cigarette demand: an investigation of the good-subject effect.
\newblock {\em Journal of behavioral medicine}, 41:269--276, 2018.

\bibitem{mturk_website}
Amazon.
\newblock Amazon mechanical turk.
\newblock \url{https://www.mturk.com/}, 2023.
\newblock Accessed April 24, 2023.

\bibitem{yang2019xlnet}
Zhilin Yang, Zihang Dai, Yiming Yang, Jaime Carbonell, Russ~R Salakhutdinov, and Quoc~V Le.
\newblock {XLNet}: Generalized autoregressive pretraining for language understanding.
\newblock {\em Advances in neural information processing systems}, 32, 2019.

\bibitem{sanh2019distilbert}
Victor Sanh, Lysandre Debut, Julien Chaumond, and Thomas Wolf.
\newblock Distilbert, a distilled version of bert: smaller, faster, cheaper and lighter.
\newblock {\em arXiv preprint arXiv:1910.01108}, 2019.

\bibitem{Jones1}
Nils Reimers.
\newblock \url{https://www.sbert.net/docs/pretrained_models.html}, 2022.
\newblock Accessed April 24, 2023.

\bibitem{johnson2019billion}
Jeff Johnson, Matthijs Douze, and Herv{\'e} J{\'e}gou.
\newblock {Billion-scale similarity search with GPUs}.
\newblock {\em IEEE Transactions on Big Data}, 7(3):535--547, 2019.

\bibitem{10.5555/3295222.3295230}
Scott~M. Lundberg and Su-In Lee.
\newblock A unified approach to interpreting model predictions.
\newblock In {\em Proceedings of the 31st International Conference on Neural Information Processing Systems}, NIPS'17, page 4768–4777, Red Hook, NY, USA, 2017. Curran Associates Inc.

\bibitem{robertson2009probabilistic}
Stephen Robertson, Hugo Zaragoza, et~al.
\newblock The probabilistic relevance framework: Bm25 and beyond.
\newblock {\em Foundations and Trends{\textregistered} in Information Retrieval}, 3(4):333--389, 2009.

\bibitem{huggingface}
Thomas Wolf, Victor Sanh, Julien Chaumond, and Clement Delangue.
\newblock Hugging face: State-of-the-art natural language processing.
\newblock [software], 2019.
\newblock Accessed: April 6, 2023.

\end{thebibliography}
