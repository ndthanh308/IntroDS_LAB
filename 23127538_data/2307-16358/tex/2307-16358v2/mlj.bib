@inproceedings{kingma2014stochastic,
  title={Stochastic gradient VB and the variational auto-encoder},
  author={Kingma, Diederik P and Welling, Max},
  booktitle={Second international conference on learning representations, ICLR},
  volume={19},
  pages={121},
  year={2014}
}
@article{goodfellow2020generative,
  title={Generative adversarial networks},
  author={Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
  journal={Communications of the ACM},
  volume={63},
  number={11},
  pages={139--144},
  year={2020},
  publisher={ACM New York, NY, USA}
}

@article{gronwall1919note,
  title={Note on the derivatives with respect to a parameter of the solutions of a system of differential equations},
  author={Gronwall, Thomas Hakon},
  journal={Annals of Mathematics},
  pages={292--296},
  year={1919},
  publisher={JSTOR}
}


@article{otto2001geometry,
  title={The geometry of dissipative evolution equations: the porous medium equation},
  author={Otto, Felix},
  year={2001},
  publisher={Taylor \& Francis}
}


@inproceedings{arjovsky2017wasserstein,
  title={Wasserstein generative adversarial networks},
  author={Arjovsky, Martin and Chintala, Soumith and Bottou, L{\'e}on},
  booktitle={International conference on machine learning},
  pages={214--223},
  year={2017},
  organization={PMLR}
}

@article{kingma2014adam,
  title={Adam: A method for stochastic optimization},
  author={Kingma, Diederik P and Ba, Jimmy},
  journal={arXiv preprint arXiv:1412.6980},
  year={2014}
}

@book{villani2009optimal,
  title={Optimal transport: old and new},
  author={Villani, C{\'e}dric and others},
  volume={338},
  year={2009},
  publisher={Springer}
}

@inproceedings{cheng2018underdamped,
  title={Underdamped Langevin MCMC: A non-asymptotic analysis},
  author={Cheng, Xiang and Chatterji, Niladri S and Bartlett, Peter L and Jordan, Michael I},
  booktitle={Conference on learning theory},
  pages={300--323},
  year={2018},
  organization={PMLR}
}


@book{villani2021topics,
  title={Topics in optimal transportation},
  author={Villani, C{\'e}dric},
  volume={58},
  year={2021},
  publisher={American Mathematical Soc.}
}
@article{park2008bayesian,
  title={The bayesian lasso},
  author={Park, Trevor and Casella, George},
  journal={Journal of the American Statistical Association},
  volume={103},
  number={482},
  pages={681--686},
  year={2008},
  publisher={Taylor \& Francis}
}
@article{pereyra2016proximal,
  title={Proximal markov chain monte carlo algorithms},
  author={Pereyra, Marcelo},
  journal={Statistics and Computing},
  volume={26},
  pages={745--760},
  year={2016},
  publisher={Springer}
}

@article{durmus2018efficient,
  title={Efficient bayesian computation by proximal markov chain monte carlo: when langevin meets moreau},
  author={Durmus, Alain and Moulines, Eric and Pereyra, Marcelo},
  journal={SIAM Journal on Imaging Sciences},
  volume={11},
  number={1},
  pages={473--506},
  year={2018},
  publisher={SIAM}
}

@article{rudin1992nonlinear,
  title={Nonlinear total variation based noise removal algorithms},
  author={Rudin, Leonid I and Osher, Stanley and Fatemi, Emad},
  journal={Physica D: nonlinear phenomena},
  volume={60},
  number={1-4},
  pages={259--268},
  year={1992},
  publisher={Elsevier}
}

@inproceedings{10.5555/3157096.3157340,
author = {Chen, Xi and Duan, Yan and Houthooft, Rein and Schulman, John and Sutskever, Ilya and Abbeel, Pieter},
title = {InfoGAN: interpretable representation learning by information maximizing generative adversarial nets},
year = {2016},
isbn = {9781510838819},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {This paper describes InfoGAN, an information-theoretic extension to the Generative Adversarial Network that is able to learn disentangled representations in a completely unsupervised manner. InfoGAN is a generative adversarial network that also maximizes the mutual information between a small subset of the latent variables and the observation. We derive a lower bound of the mutual information objective that can be optimized efficiently. Specifically, InfoGAN successfully disentangles writing styles from digit shapes on the MNIST dataset, pose from lighting of 3D rendered images, and background digits from the central digit on the SVHN dataset. It also discovers visual concepts that include hair styles, presence/absence of eyeglasses, and emotions on the CelebA face dataset. Experiments show that InfoGAN learns interpretable representations that are competitive with representations learned by existing supervised methods. For an up-to-date version of this paper, please see https://arxiv.org/abs/1606.03657.},
booktitle = {Proceedings of the 30th International Conference on Neural Information Processing Systems},
pages = {2180â€“2188},
numpages = {9},
location = {Barcelona, Spain},
series = {NIPS'16}
}
@inproceedings{liu2021infinite,
  title={Infinite-Dimensional Optimization for Zero-Sum Games via Variational Transport},
  author={Liu, Lewis and Zhang, Yufeng and Yang, Zhuoran and Babanezhad, Reza and Wang, Zhaoran},
  booktitle={International Conference on Machine Learning},
  pages={7033--7044},
  year={2021},
  organization={PMLR}
}
@article{nguyen2021learning,
  title={Learning subtree pattern importance for Weisfeiler-Lehman based graph kernels},
  author={Nguyen, Dai Hai and Nguyen, Canh Hao and Mamitsuka, Hiroshi},
  journal={Machine Learning},
  volume={110},
  pages={1585--1607},
  year={2021},
  publisher={Springer}
}
@article{nguyen2023linear,
  title={On a linear fused Gromov-Wasserstein distance for graph structured data},
  author={Nguyen, Dai Hai and Tsuda, Koji},
  journal={Pattern Recognition},
  pages={109351},
  year={2023},
  publisher={Elsevier}
}
@article{santambrogio2015optimal,
  title={Optimal transport for applied mathematicians},
  author={Santambrogio, Filippo},
  journal={Birk{\"a}user, NY},
  volume={55},
  number={58-63},
  pages={94},
  year={2015},
  publisher={Springer}
}

@article{nguyen2023mirror,
  title={Mirror variational transport: a particle-based algorithm for distributional optimization on constrained domains},
  author={Nguyen, Dai Hai and Sakurai, Tetsuya},
  journal={Machine Learning},
  pages={1--25},
  year={2023},
  publisher={Springer}
}

@article{petric2019got,
  title={GOT: an optimal transport framework for graph comparison},
  author={Petric Maretic, Hermina and El Gheche, Mireille and Chierchia, Giovanni and Frossard, Pascal},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}

@inbook{10.5555/3454287.3455532,
author = {Maretic, Hermina Petric and El Gheche, Mireille and Chierchia, Giovanni and Frossard, Pascal},
title = {GOT: an optimal transport framework for graph comparison},
year = {2019},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {We present a novel framework based on optimal transport for the challenging problem of comparing graphs. Specifically, we exploit the probabilistic distribution of smooth graph signals defined with respect to the graph topology. This allows us to derive an explicit expression of the Wasserstein distance between graph signal distributions in terms of the graph Laplacian matrices. This leads to a structurally meaningful measure for comparing graphs, which is able to take into account the global structure of graphs, while most other measures merely observe local changes independently. Our measure is then used for formulating a new graph alignment problem, whose objective is to estimate the permutation that minimizes the distance between two graphs. We further propose an efficient stochastic algorithm based on Bayesian exploration to accommodate for the non-convexity of the graph alignment problem. We finally demonstrate the performance of our novel framework on different tasks like graph alignment, graph classification and graph signal prediction, and we show that our method leads to significant improvement with respect to the state-of-art algorithms.},
booktitle = {Proceedings of the 33rd International Conference on Neural Information Processing Systems},
articleno = {1245},
numpages = {12}
}
@incollection{NIPS2019_9539,
title = {GOT: An Optimal Transport framework for Graph comparison},
author = {Petric Maretic, Hermina and El Gheche, Mireille and Chierchia, Giovanni and Frossard, Pascal},
booktitle = {Advances in Neural Information Processing Systems 32},
editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
pages = {13876--13887},
year = {2019},
publisher = {Curran Associates, Inc.},
url = {http://papers.nips.cc/paper/9539-got-an-optimal-transport-framework-for-graph-comparison.pdf}
}

@article{denny2010unique,
  title={A unique solution to a nonlinear elliptic equation},
  author={Denny, D},
  journal={Journal of mathematical analysis and applications},
  volume={365},
  number={2},
  pages={467--482},
  year={2010},
  publisher={Elsevier}
}

@article{marchuk1990splitting,
  title={Splitting and alternating direction methods},
  author={Marchuk, Guri I},
  journal={Handbook of numerical analysis},
  volume={1},
  pages={197--462},
  year={1990},
  publisher={Elsevier}
}

@article{wang2016learning,
  title={Learning to draw samples: With application to amortized mle for generative adversarial learning},
  author={Wang, Dilin and Liu, Qiang},
  journal={arXiv preprint arXiv:1611.01722},
  year={2016}
}

@article{feng2017learning,
  title={Learning to draw samples with amortized stein variational gradient descent},
  author={Feng, Yihao and Wang, Dilin and Liu, Qiang},
  journal={arXiv preprint arXiv:1707.06626},
  year={2017}
}

@book{rockafellar2009variational,
  title={Variational analysis},
  author={Rockafellar, R Tyrrell and Wets, Roger J-B},
  volume={317},
  year={2009},
  publisher={Springer Science \& Business Media}
}

@article{wahlberg2012admm,
  title={An ADMM algorithm for a class of total variation regularized estimation problems},
  author={Wahlberg, Bo and Boyd, Stephen and Annergren, Mariette and Wang, Yang},
  journal={IFAC Proceedings Volumes},
  volume={45},
  number={16},
  pages={83--88},
  year={2012},
  publisher={Elsevier}
}

@article{tibshirani1996regression,
  title={Regression shrinkage and selection via the lasso},
  author={Tibshirani, Robert},
  journal={Journal of the Royal Statistical Society Series B: Statistical Methodology},
  volume={58},
  number={1},
  pages={267--288},
  year={1996},
  publisher={Oxford University Press}
}

@article{beck2003mirror,
  title={Mirror descent and nonlinear projected subgradient methods for convex optimization},
  author={Beck, Amir and Teboulle, Marc},
  journal={Operations Research Letters},
  volume={31},
  number={3},
  pages={167--175},
  year={2003},
  publisher={Elsevier}
}

@inproceedings{dai2017learning,
  title={Learning from conditional distributions via dual embeddings},
  author={Dai, Bo and He, Niao and Pan, Yunpeng and Boots, Byron and Song, Le},
  booktitle={Artificial Intelligence and Statistics},
  pages={1458--1467},
  year={2017},
  organization={PMLR}
}