\section*{Background \& Summary}
\label{Sec: Background}
Medical image segmentation has shown tremendous success ever since the advent of Deep Learning within the medical field which can be dated back to the introduction of the U-Net~\cite{ronneberger2015u}. While there has been a lot of architectural advancement of models to generalize U-Net architectures to the prevalent 3D medical imaging modalities~\cite{cciccek20163d,milletari2016v} such as Computed Tomography (CT), Magnetic Resonance Imaging (MRI) or  Positron Emission Tomography (PET), there has been less effort in providing a holistic view on the entire human body and its anatomy. 
Current models for medical data predominantly specialize in partially annotated datasets on sub-areas of the human body. 
These datasets range from single organ annotations such as the segmentation of spleen or pancreas~\cite{simpson2019large} to multi-organ datasets such as the BTCV~\cite{landman2015miccai} containing annotations for 13 abdominal organs. The recently introduced Medical Segmentation Decathlon~\cite{antonelli2022medical} aims at generalizing models to multiple tasks. Each of the individual tasks is however still limited to a specific body region and a certain organ of interest which does not address a complete anatomical view.  % and even proceeding towards a comprehensive view of the human body~\cite{} providing 50 organs-at-risk-annotations. 
%Why is it bad to treat the human body in a partially annotated and subpar fashion? Provide an intutition
Focusing on only a subsection of the entire anatomy has multiple downsides. From a technical point of view, it limits potential downstream applications which could be used within clinical settings. Additionally, it is a well-known fact that the human body consists of multiple systems and structures which are in constant interaction with each other to maintain a homeostatic state. Thus also from a medical point of view, it appears beneficial to look at interactions between structures instead of treating them in an isolated fashion. This requires overcoming the current constrained setting and striving towards a holistic view of anatomical structures which is a limitation of the current literature.
%Homeostasis. Wechselwirkung zwischen Organen kann besser erkannt werden. 


%Describe the problem of more and more labels
A common problem for Deep Learning applications is the need for large annotated datasets. The medical domain is no exception and poses additional difficulties due to the required expertise to annotate medical images combined with the labor-intensive annotation process for common 3D imaging modalities. While this is already cumbersome for a small number of labels, it is effectively impossible to find a team of radiologists willing to annotate the combination of hundreds of categories for hundreds of CTs. For example, the recently proposed ATM-dataset~\cite{zhang2023multi}, comparable in size with the proposed Dense Anatomical Prediction (DAP) Atlas dataset, utilizes three expert radiologists working on a single label with each CT volume requiring about 60-90 minutes~\cite{zhang2023multi}. Assuming an average time of $75$ minutes per CT volume, this single-label dataset requires almost $80$ days of work, assuming $8$h of uninterrupted work per day. Scaling to more labels is infeasible as it will not only increase the workload but also might cause the radiologist to lose track due to the higher complexity of the task. 

%MOOSE
The creators of MOOSE~\cite{sundar2022fully}, a multi-organ segmentation model use a hybrid approach consisting of expert annotation and automated annotations. The experts annotate on a small dataset of $50$ CT images $13$ organ structures, $20$ bone segments, and $4$ tissue structures which were semi-automatically extracted. For the majority of their labels which are $83$ cerebral structures, the authors use an automatic segmentation approach by leveraging the Hammersmith atlas~\cite{hammers2003three}.


%Describe the approach of chen2021 deep and total segmentation and how we are different from them
TotalSegmentator~\cite{wasserthal2022totalsegmentator}  approaches this problem via active learning in which an expert improves model predictions which are again fed to the model to improve the predictions. While this procedure noticeably reduces an expert's time spent on annotation, it still relies on direct interaction with experts for multiple weeks to generate a dataset of 104 anatomical structures. It also has to be acknowledged that large datasets with this many labels face a concrete challenge when evaluating the label quality since it becomes increasingly infeasible to have pixel-wise alignments checked for all anatomical structures. As such, TotalSegmentor~\cite{wasserthal2022totalsegmentator} relied upon quality insurance via 3D renderings instead of manual voxel-wise alignment checks. 

% pseudo-label filtering
When we compare this to the natural image domain, several works utilize entirely automated annotation for classification and segmentation purposes\cite{xie2020self,zhai2022scaling,kirillov2023segment}. One example is the recent \textit{Segment Anything}-dataset~\cite{kirillov2023segment}. Here, the authors train a base model on manually annotated data and make predictions on unlabeled images through multi-scale inference and filter predictions via non-maximum suppression leading to 11 million annotated images. The general concept of pseudo-label filtering from weak annotations like image-level class labels improves the unlabeled training data and leads to more stable models\cite{reiss2023decoupled,wang2022omni,bae2022one,mlynarski2019deep,qu2023annotating}.  
Other works~\cite{hu2023label} have shown the successful application of pseudo-generated tumor labels on CT data of the liver leading to accurate segmentation results on real liver tumors.

%Describe your approach
Motivated by these recent advancements and the difficulty to scale expert annotations to multi-label large-scale medical datasets, we want to develop a dataset that enables the training of models suitable to serve a variety of clinically relevant downstream tasks which profit from extensive anatomical knowledge like body composition analysis, surgery planning or cancer treatment monitoring. 

We build upon this core idea of pseudo-label filtering and refinement to employ an expert-free dataset generation approach that aggregates the scattered anatomical knowledge of multiple source datasets and aggregates them into a single dataset. 
We combine anatomical information from various sources through pseudo-label-based label aggregation and pseudo-label-refinement in post-processing strategies that leverage anatomical textbook knowledge to assert the anatomical plausibility of the labels. 
%By integrating these steps into self-training concepts, we generate our Dense Anatomical Prediction (DAP) Atlas dataset with anatomical labels. 
Our dataset has been approved by experts, despite not having contributed to its creation.  
The dataset consists of $533$ whole-body CT images with labels for $142$ anatomical structures containing information ranging from body composition, organs to various vessels. We are the first to release a dataset containing dense annotations for every voxel in a full-body human CT. We show an example of the dataset in Fig.~\ref{fig:intro_fig}. 
%The dataset enables the training of models which can serve a variety of clinically relevant downstream tasks which profit from extensive anatomical knowledge like a body composition analysis, surgery planning or cancer treatment monitoring. 

% Figure environment removed

%Summary of the dataset and the contributions

The remainder of this paper is structured as follows: Section \textit{Methods} discusses how the full-body CT data and the labels are acquired and how they are processed to generate our Atlas dataset. In Section \textit{Data Records} we briefly discuss the structure and availability of the dataset to ease the usage for the community. This is followed by Section \textit{Technical Validation} in which the quality of the dataset is examined. We conclude the paper with the final chapter \textit{Discussion and Conclusion}. 