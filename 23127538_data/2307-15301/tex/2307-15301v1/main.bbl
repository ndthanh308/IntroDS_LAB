% Generated by IEEEtran.bst, version: 1.14 (2015/08/26)
\begin{thebibliography}{10}
\providecommand{\url}[1]{#1}
\csname url@samestyle\endcsname
\providecommand{\newblock}{\relax}
\providecommand{\bibinfo}[2]{#2}
\providecommand{\BIBentrySTDinterwordspacing}{\spaceskip=0pt\relax}
\providecommand{\BIBentryALTinterwordstretchfactor}{4}
\providecommand{\BIBentryALTinterwordspacing}{\spaceskip=\fontdimen2\font plus
\BIBentryALTinterwordstretchfactor\fontdimen3\font minus
  \fontdimen4\font\relax}
\providecommand{\BIBforeignlanguage}[2]{{%
\expandafter\ifx\csname l@#1\endcsname\relax
\typeout{** WARNING: IEEEtran.bst: No hyphenation pattern has been}%
\typeout{** loaded for the language `#1'. Using the pattern for}%
\typeout{** the default language instead.}%
\else
\language=\csname l@#1\endcsname
\fi
#2}}
\providecommand{\BIBdecl}{\relax}
\BIBdecl

\bibitem{Raft-3D}
Z.~Teed and J.~Deng, ``{Raft-3d: Scene flow using rigidmotion embeddings},'' in
  \emph{Proceedings of the IEEE Conference on Computer Vision and Pattern
  Recognition (CVPR)}, June 2021.

\bibitem{FusionSLAM2020}
T.~Zhang, H.~Zhang, Y.~Li, Y.~Nakamura, and L.~Zhang, ``{FlowFusion: Dynamic
  Dense RGB-D SLAM Based on Optical Flow},'' in \emph{Proceedings of IEEE
  International Conference on Robotics and Automation (ICRA)}, Paris, Fr, June
  2020.

\bibitem{navigation}
G.~de~Croon, C.~De-Wagter, and T.~Seidl, ``Enhancing optical-flow-based control
  by learning visual appearance cues for flying robots,'' \emph{Nature Machine
  Intelligence}, vol.~3, no.~1, pp. 33--41, 2021.

\bibitem{action_recognition1}
L.~Sevilla-Lara, Y.~Liao, F.~Guney, V.~Jampani, A.~Geiger, and M.~J. Black,
  ``{On the integration of optical flow and action recognition},'' in
  \emph{Proceedings of German Conference on Pattern Recognition (GCPR)},
  Stuttgart, Ger, October 2018.

\bibitem{action_recognition2}
S.~Sun, Z.~Kuang, L.~Sheng, W.~Ouyang, and W.~Zhang, ``{Optical flow guided
  feature: A fast and robust motion representation for video action
  recognition},'' in \emph{Proceedings of the IEEE Conference on Computer
  Vision and Pattern Recognition (CVPR)}, Utah, US, June 2018.

\bibitem{Flow_Net}
A.~Dosovitskiy, P.~Fischer, , E.~Ilg, P.~Hausser, C.~Hazirbas, V.~Golkov,
  P.~der Smagt, D.~Cremers, and T.~Brox, ``{FlowNet: Learning Optical Flow with
  Convolutional Networks},'' in \emph{Proceedings of the IEEE International
  Conference on Computer Vision (ICCV)}, Santiago, Chile, Dec 2015.

\bibitem{Flow_Net2.0}
E.~Ilg, N.~Mayer, T.~Saikia, M.~Keuper, A.~Dosovitskiy, and T.~Brox, ``{Flownet
  2.0: Evolution of optical flow estimation with deep networks},'' in
  \emph{Proceedings of the IEEE Conference on Computer Vision and Pattern
  Recognition (CVPR)}, Hawaii, US, July 2017.

\bibitem{Flow_fields}
C.~Bailer, B.~Taetz, and D.~Stricker, ``{Flow fields: Dense correspondence
  fields for highly accurate large displacement optical flow estimation},'' in
  \emph{Proceedings of the IEEE International Conference on Computer Vision
  (ICCV)}, Santiago, Chi, August 2015.

\bibitem{Flow_fields++}
R.~Schuster, C.~Bailer, O.~Wasenm, and D.~Stricker, ``{Flowfields++: Accurate
  optical flow correspondences meet robust interpolation},'' in
  \emph{Proceedings of the IEEE International Conference on Image Processing
  (ICIP)}, Athens, GR, October 2018.

\bibitem{Raft}
Z.~Teed and J.~Deng, ``{Raft: Recurrent all-pairs field transforms for optical
  flow},'' in \emph{Proceedings of the European conference on computer vision
  European (ECCV)}, August 2020.

\bibitem{CRaft}
X.~Sui, S.~Li, X.~Geng, Y.~Wu, X.~Xu, Y.~Liu, R.~Goh, and H.~Zhu, ``{CRAFT:
  Cross-Attentional Flow Transformer for Robust Optical Flow},'' in
  \emph{Proceedings of the IEEE Conference on Computer Vision and Pattern
  Recognition (CVPR)}, Louisiana, US, June 2022.

\bibitem{CamLiFlow}
H.~Liu, T.~Lu, Y.~Xu, J.~Liu, W.~Li, and L.~Chen, ``{CamLiFlow: Bidirectional
  Camera-LiDAR Fusion for Joint Optical Flow and Scene Flow Estimation},'' in
  \emph{Proceedings of the IEEE Conference on Computer Vision and Pattern
  Recognition (CVPR)}, New Orleans, US, June 2022.

\bibitem{DeepLiDARFlow}
R.~Rishav, R.~Battrawy, R.~Schuster, O.~Wasenmuller, and D.~Stricker,
  ``{DeepLiDARFlow: A Deep Learning Architecture For Scene Flow Estimation
  Using Monocular Camera and Sparse LiDAR},'' in \emph{Proceedings of IEEE
  International Conference on Intelligent Robots and Systems (IROS)}, Las
  Vegas, US, June 2020.

\bibitem{Murphy2009}
R.~Murphy, J.~Kravitz, S.~Stover, and R.~Shoureshi, ``Mobile robots in mine
  rescue and recovery,'' \emph{IEEE Robotics \& Automation Magazine}, 2009.

\bibitem{flythings}
N.~Mayer, E.~Ilg, P.~Hausser, and P.~Fischer, ``{A large dataset to train
  convolutional networks for disparity, optical flow, and scene flow
  estimation},'' in \emph{Proceedings of the IEEE Conference on Computer Vision
  and Pattern Recognition (CVPR)}, Las Vegas, US, June 2016.

\bibitem{kitti}
A.~Geiger, P.~Lenz, C.~Stiller, and R.~Urtasun, ``Vision meets robotics: The
  kitti dataset,'' \emph{The International Journal of Robotics Research},
  vol.~32, no.~11, pp. 1231--1237, 2013.

\bibitem{PWC-Net}
D.~Sun, X.~Yang, M.~Liu, and J.~Kautz, ``{PWC-Net: CNNs for optical flow using
  pyramid, warping, and cost volume},'' in \emph{Proceedings of the IEEE
  Conference on Computer Vision and Pattern Recognition (CVPR)}, Utah, US, June
  2018.

\bibitem{Maskflownet}
S.~Zhao, Y.~Sheng, Y.~Dong, E.~Chang, and Y.~Xu, ``{Maskflownet: Asymmetric
  feature matching with learnable occlusion mask},'' in \emph{Proceedings of
  the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}, June
  2020.

\bibitem{LiteFlowNet3}
T.~Hui and C.~Change, ``{LiteFlowNet3: Resolving Correspondence Ambiguity for
  More Accurate Optical Flow Estimation},'' in \emph{Proceedings of the
  European conference on computer vision European (ECCV)}, August 2020.

\bibitem{GMA}
S.~Jiang, D.~Campbell, Y.~Lu, H.~Li, and R.~Hartley, ``{Learning to estimate
  hidden motions with global motion aggregation},'' in \emph{Proceedings of the
  IEEE International Conference on Computer Vision (ICCV)}, 2021.

\bibitem{early-fusion}
J.~Wagner, V.~Fischer, M.~Herman, and S.~Behnke, ``{Multispectral pedestrian
  detection using deep fusion convolutional neural networks},'' in
  \emph{Proceedings of European Symposium on Artificial Neural Networks
  (ESANN)}, Bruges, BEL, April 2016.

\bibitem{mid-fusion1}
D.~Konig, M.~Adam, C.~Jarvers, G.~Layher, H.~Neumann, and M.~Teutsch, ``{Fully
  convolutional region proposal networks for multispectral person detection},''
  in \emph{Proceedings of the IEEE Conference on Computer Vision and Pattern
  Recognition (CVPR)}, Hawaii, US, July 2017.

\bibitem{mid-fusion2}
J.~Liu, S.~Zhang, S.~Wang, and D.~Metaxas, ``{Multispectral deep neural
  networks for pedestrian detection},'' in \emph{Proceedings of the British
  Machine Vision Conference (BMVC)}, York, UK, September 2016.

\bibitem{late-fusion}
Y.~Chen, J.~Shi, Z.~Ye, C.~Mertz, S.~Kong, and D.~Ramanan, ``{Multimodal Object
  Detection via Probabilistic Ensembling},'' in \emph{Proceedings of the
  European conference on computer vision (ECCV)}, Tel Aviv, Israel, October
  2022.

\bibitem{camliraft2023}
H.~Liu, T.~Lu, Y.~Xu, J.~Liu, and L.~Wang, ``Learning optical flow and scene
  flow with bidirectional camera-lidar fusion,'' \emph{arXiv preprint
  arXiv:2303.12017}, 2023.

\bibitem{MMTM}
H.~Reza, A.~Shaban, M.~L. Iuzzolino, and K.~Koishida, ``{MMTM: Multimodal
  Transfer Module for CNN Fusion},'' in \emph{Proceedings of the IEEE
  Conference on Computer Vision and Pattern Recognition (CVPR)}, June 2020.

\bibitem{ulyanov2016instance}
D.~Ulyanov, A.~Vedaldi, and V.~Lempitsky, ``Instance normalization: The missing
  ingredient for fast stylization,'' \emph{arXiv preprint arXiv:1607.08022},
  2016.

\bibitem{xu2015empirical}
B.~Xu, N.~Wang, T.~Chen, and M.~Li, ``Empirical evaluation of rectified
  activations in convolutional network,'' \emph{arXiv}, 2015.

\bibitem{Ga-net}
F.~Zhang, V.~Prisacariu, R.~Yang, and P.~Torr, ``{GA-Net: Guided Aggregation
  Net for End-To-End Stereo Matching},'' in \emph{Proceedings of the IEEE
  Conference on Computer Vision and Pattern Recognition (CVPR)}, Long Beach,
  US, June 2019.

\bibitem{Flownet3d++}
Z.~Wang, S.~Li, H.~Howard-Jenkins, V.~Prisacariu, and M.~Chen, ``{Flownet3d++:
  Geometric losses for deep scene flow estimation},'' in \emph{Proceedings of
  IEEE Winter Conference on Applications of Computer Vision (WACV)}, Waikoloa,
  US, March 2020.

\bibitem{Separable_flow}
F.~Zhang, O.~J-Woodford, V.~Prisacariu, and P.~Torr, ``{Separable flow:
  Learning motion cost volumes for optical flow estimation},'' in
  \emph{Proceedings of the IEEE International Conference on Computer Vision
  (ICCV)}, March 2021.

\end{thebibliography}
