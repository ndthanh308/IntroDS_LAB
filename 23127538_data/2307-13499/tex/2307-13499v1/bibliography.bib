
@inproceedings{pareja2020evolvegcn,
  title={Evolvegcn: Evolving graph convolutional networks for dynamic graphs},
  author={Pareja, Aldo and Domeniconi, Giacomo and Chen, Jie and Ma, Tengfei and Suzumura, Toyotaro and Kanezashi, Hiroki and Kaler, Tim and Schardl, Tao and Leiserson, Charles},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={34},
  number={04},
  pages={5363--5370},
  year={2020}
}


@inproceedings{alarab2020competence,
  title={Competence of graph convolutional networks for anti-money laundering in bitcoin blockchain},
  author={Alarab, Ismail and Prakoonwit, Simant and Nacer, Mohamed Ikbal},
  booktitle={Proceedings of the 2020 5th international conference on machine learning technologies},
  pages={23--27},
  year={2020}
}

@article{lo2023inspection,
  title={Inspection-L: self-supervised {GNN} node embeddings for money laundering detection in bitcoin},
  author={Lo, Wai Weng and Kulatilleke, Gayan K and Sarhan, Mohanad and Layeghy, Siamak and Portmann, Marius},
  journal={Applied Intelligence},
  pages={1--12},
  year={2023},
  publisher={Springer}
}

@article{alarab2022graph,
  title={Graph-based {LSTM} for anti-money laundering: Experimenting temporal graph convolutional network with bitcoin data},
  author={Alarab, Ismail and Prakoonwit, Simant},
  journal={Neural Processing Letters},
  pages={1--19},
  year={2022},
  publisher={Springer}
}

@inproceedings{chen2018fastgcn,
  title={Fast{GCN}: Fast learning with graph convolutional networks via importance sampling},
  author={Chen, Jie and Ma, Tengfei and Xiao, Cao},
  booktitle={International Conference on Learning Representations},
  year={2018},
  organization={International Conference on Learning Representations, ICLR}
}

@article{hochreiter1997long,
  title={Long short-term memory},
  author={Hochreiter, Sepp and Schmidhuber, J{\"u}rgen},
  journal={Neural computation},
  volume={9},
  number={8},
  pages={1735--1780},
  year={1997},
  publisher={MIT press}
}



% 1-2 trillion US dollars (or 2-5% of GDP) is being laundered each year.
@misc{UNODC,
  title={Estimating illicit financial flows resulting from drug trafficking and other transnational organized crime},
  author={{United Nations -- Office on Drugs and Crime}},
  year={2011},
}

% With millions of customers, banks have fielded automated transaction monitoring systems, which use money laundering detection scenarios known as rules, to alert firms to certain customers for potential violations. Current industry detection logic has proven flawed and inefficient at identifying financial crime, resulting in record-breaking regulatory fines for financial institutions that fail to detect terrorists, drug cartels, and sanctioned state actors exploiting the U.S. financial system.
@misc{REUTERS,
  title = {Anti-money laundering controls failing to detect terrorists, cartels, and sanctioned states},
  author={Fruth, Joshua},
  howpublished = {\url{https://www.reuters.com/article/bc-finreg-laundering-detecting-idUSKCN1GP2NV}},
  note = {Accessed: 2022-07-14},
  year = {2018}
}

@article{POL2020,
  title={Anti-money laundering: The world's least effective policy experiment? Together, we can fix it},
  author={Pol, Ronald F},
  journal={Policy Design and Practice},
  volume={3},
  number={1},
  pages={73--94},
  year={2020},
  publisher={Taylor \& Francis}
}

% Danske bank scandal
@article{BJERREGAARD2019,
  title={The Danske Bank money laundering scandal: A case study},
  author={Bjerregaard, Elisabetta and Kirchmaier, Tom},
  journal={Available at SSRN 3446636},
  year={2019}
}

@article{CHO2014,
  title={On the properties of neural machine translation: Encoder-decoder approaches},
  author={Cho, Kyunghyun and Van Merri{\"e}nboer, Bart and Bahdanau, Dzmitry and Bengio, Yoshua},
  journal={arXiv preprint arXiv:1409.1259},
  year={2014}
}

@inproceedings{LI2016,
  author    = {Yujia Li and
               Daniel Tarlow and
               Marc Brockschmidt and
               Richard S. Zemel},
  editor    = {Yoshua Bengio and
               Yann LeCun},
  title     = {Gated Graph Sequence Neural Networks},
  booktitle = {4th International Conference on Learning Representations, {ICLR} 2016,
               San Juan, Puerto Rico, May 2-4, 2016, Conference Track Proceedings},
  year      = {2016},
  url       = {http://arxiv.org/abs/1511.05493},
  timestamp = {Thu, 25 Jul 2019 14:25:40 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/LiTBZ15.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

% PyG
@article{Fey2019FastGR,
  title={Fast graph representation learning with PyTorch Geometric},
  author={Fey, Matthias and Lenssen, Jan Eric},
  journal={arXiv preprint arXiv:1903.02428},
  year={2019}
}


% Adam
@article{Kingma2015Adam,
  title={Adam: A method for stochastic optimization},
  author={Kingma, Diederik P and Ba, Jimmy},
  journal={arXiv preprint arXiv:1412.6980},
  year={2014}
}

% Pytorch
@incollection{NEURIPS2019_9015,
title = {PyTorch: An Imperative Style, High-Performance Deep Learning Library},
author = {Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and Desmaison, Alban and Kopf, Andreas and Yang, Edward and DeVito, Zachary and Raison, Martin and Tejani, Alykhan and Chilamkurthy, Sasank and Steiner, Benoit and Fang, Lu and Bai, Junjie and Chintala, Soumith},
booktitle = {Advances in Neural Information Processing Systems 32},
editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
pages = {8024--8035},
year = {2019},
publisher = {Curran Associates, Inc.}
}
%url = {http://papers.neurips.cc/paper/9015-pytorch-an-imperative-style-high-performance-deep-learning-library.pdf}
%}



%Metapath2vec
@inproceedings{DONG2017,
  title={metapath2vec: Scalable representation learning for heterogeneous networks},
  author={Dong, Yuxiao and Chawla, Nitesh V and Swami, Ananthram},
  booktitle={Proceedings of the 23rd ACM SIGKDD international conference on knowledge discovery and data mining},
  pages={135--144},
  year={2017}
}

%Node2vec
@inproceedings{GROVER2016,
  title={node2vec: Scalable feature learning for networks},
  author={Grover, Aditya and Leskovec, Jure},
  booktitle={Proceedings of the 22nd ACM SIGKDD international conference on Knowledge discovery and data mining},
  pages={855--864},
  year={2016}
}

% Deepwalk
@inproceedings{PEROZZI2014,
  title={Deepwalk: Online learning of social representations},
  author={Perozzi, Bryan and Al-Rfou, Rami and Skiena, Steven},
  booktitle={Proceedings of the 20th ACM SIGKDD international conference on Knowledge discovery and data mining},
  pages={701--710},
  year={2014}
}

% Spectral graph theory
@book{chung1997spectral,
  title={Spectral graph theory},
  author={Chung, Fan RK and Graham, Fan Chung},
  volume={92},
  year={1997},
  publisher={American Mathematical Soc.}
}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Survey Papers
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Survey Paper on ML + AML
% "Currently, most banks rely on rule-based systems to filter out any suspicious trans- actions based on pre-generated static rules. "
@article{CHEN2018,
  title={Machine learning techniques for anti-money laundering (AML) solutions in suspicious transaction detection: a review},
  author={Chen, Zhiyuan and Van Khoa, Le Dinh and Teoh, Ee Na and Nazir, Amril and Karuppiah, Ettikan Kandasamy and Lam, Kim Sim},
  journal={Knowledge and Information Systems},
  volume={57},
  number={2},
  pages={245--285},
  year={2018},
  publisher={Springer}
}

% Survey paper on ML on Heterogeneous graphs
@article{YANG2020,
  title={Heterogeneous network representation learning: A unified framework with survey and benchmark},
  author={Yang, Carl and Xiao, Yuxin and Zhang, Yu and Sun, Yizhou and Han, Jiawei},
  journal={IEEE Transactions on Knowledge and Data Engineering},
  year={2020},
  publisher={IEEE}
}

% Survey paper on GNNs
@article{WU2020,
  title={A comprehensive survey on graph neural networks},
  author={Wu, Zonghan and Pan, Shirui and Chen, Fengwen and Long, Guodong and Zhang, Chengqi and Philip, S Yu},
  journal={IEEE transactions on neural networks and learning systems},
  volume={32},
  number={1},
  pages={4--24},
  year={2020},
  publisher={IEEE}
}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Supervised learning + AML
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% use machine learning to detect suspicious transactions sequences. Using a sequences similarity measure, they first calculate the similarity between different sequences, where some are known to be suspicious. The sequences similar to those known to be suspicious, can then be classified as suspicious.
% Citations: 38
@inproceedings{LIU2008,  
  title={Sequence matching for suspicious activity detection in anti-money laundering},
  author={Liu, Xuan and Zhang, Pengzhu and Zeng, Dajun},
  booktitle={International conference on intelligence and security informatics},
  pages={50--61},
  year={2008},
  organization={Springer}, 
}

% introduce a sequential active learning approach, where the learner sequentially determines the next bank account to be manually investigated from a pool of unlabelled accounts. The account will afterwards receive a label, and the information will go back to the learner to determine the next account for investigation. 
% Citations: 39
@article{DENG2009, 
  title={Active learning through sequential design, with applications to detection of money laundering},
  author={Deng, Xinwei and Joseph, V Roshan and Sudjianto, Agus and Wu, CF Jeff},
  journal={Journal of the American Statistical Association},
  volume={104},
  number={487},
  pages={969--981},
  year={2009},
  publisher={Taylor \& Francis}
}

%fits  a gradient boosted trees model using the \textit{XGBoost}-library on historic transactions where some are known to be suspicious. The model is then used to predict future transactions with high suspicion. To make the prediction, the model uses generated features summarizing earlier transactions for the sending and receiving parties, in addition to background information on the sender and receiver themselves. 
% Citations: 55
@article{JULLUM2020, 
  title={Detecting money laundering transactions with machine learning},
  author={Jullum, Martin and L{\o}land, Anders and Huseby, Ragnar Bang and {\AA}nonsen, Geir and Lorentzen, Johannes},
  journal={Journal of Money Laundering Control},
  year={2020},
  publisher={Emerald Publishing Limited}
}

% XGBoost and Light gradient boosting were used to detect tax evasion, and find that they both outperforms random forests  by a significant margin.
% Citations: 8
@article{AHMED2021, 
  title={Anti-Money Laundering Recognition through the Gradient Boosting Classifier},
  author={Ahmed, Alim Al Ayub},
  journal={Academy of Accounting and Financial Studies Journal},
  volume={25},
  number={5},
  year={2021}
}

% propose a new gradient boosting method, Adaptive Stacked eXtreme Gradient Boosting, for better handling of concept drift, and apply it on detecting suspicious activities in cryptocurrencies. 
% Citations: 9
@article{VASSALLO2021, 
  title={Application of gradient boosting algorithms for anti-money laundering in cryptocurrencies},
  author={Vassallo, Dylan and Vella, Vincent and Ellul, Joshua},
  journal={SN Computer Science},
  volume={2},
  number={3},
  pages={1--15},
  year={2021},
  publisher={Springer}
}

% use a set of custom-made features to detect suspicious transactions, and vouch for Random Forest. 
% Citations: 0
@inproceedings{TUNDIS2021, 
  title={Fighting organized crime by automatically detecting money laundering-related financial transactions},
  author={Tundis, Andrea and Nemalikanti, Soujanya and M{\"u}hlh{\"a}user, Max},
  booktitle={The 16th International Conference on Availability, Reliability and Security},
  pages={1--10},
  year={2021}
}

% compare five popular machine learning techniques for classifying suspicious transactions: Bayes logistic regression, decision tree, random forest, support vector machine, and artificial neural network. In addition, they introduce sampling strategies to mitigate the problem of class imbalance. The best performance is achieved by artificial neural network.
% Citations: 34
@article{ZHANG2019, 
  title={Machine learning and sampling scheme: An empirical study of money laundering detection},
  author={Zhang, Yan and Trubey, Peter},
  journal={Computational Economics},
  volume={54},
  number={3},
  pages={1043--1063},
  year={2019},
  publisher={Springer}
}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Unsupervised learning + AML
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% propose using clustering algorithms (\textit{strict competitive learning}, \textit{self-organizing-map}, C-means and \textit{neural gas clustering}) to divide the customers into multiple clusters. Then, they identified the cluster with the highest risk, before anomalies in this cluster are identified based on high variance of the variables. The approach builds on both self-comparisons and group-comparisons, meaning that an anomaly is identify both by comparing the entity with its own previous history and by peer group comparison. They conclude that this approach gives significantly higher accuracy compared to regular rule-based system. They also stress the importance of non-transnational features, such as inherent customer data. 
% Citations: 16
@article{ROCHA2021,
  title={Money laundering and terrorism financing detection using neural networks and an abnormality indicator},
  author={Jos{\'e} de Jes{\'u}s Rocha-Salazar and Mar{\'\i}a Jes{\'u}s Segovia-Vargas and Mar{\'\i}a del Mar Camacho-Mi{\~n}ano},
  journal={Expert Systems with Applications},
  volume={169},
  pages={114470},
  year={2021},
  publisher={Elsevier}
}


%  demonstrate the shortcomings of seven different unsupervised techniques on a dataset of bitcoin transactions. They continue by opting for an active learning strategy, as \cite{deng2009}, which outperforms fully supervised methods. 
% Citations: 28
@article{LORENZ2020,
  title={Machine learning methods to detect money laundering in the Bitcoin blockchain in the presence of label scarcity},
  author={Lorenz, Joana and Silva, Maria In{\^e}s and Apar{\'\i}cio, David and Ascens{\~a}o, Jo{\~a}o Tiago and Bizarro, Pedro},
  journal={arXiv preprint arXiv:2005.14635},
  year={2020}
}

% explore clustering algorithms on a synthetic AML dataset. Here, they also use the connections between accounts to detect groups of suspicious accounts. They compare the two anomaly detection algorithms of \textit{One Class SVM} and \textit{Isolation Forest}, and report better results using Isolation Forest. 
% Citations: 4
@inproceedings{SHOKRY2020,
  title={Counter terrorism finance by detecting money laundering hidden networks using unsupervised machine learning algorithm},
  author={Shokry, Amr Ehab Muhammed and Rizka, Mohammed Abo and Labib, Nevine Makram},
  booktitle={International Conferences ICT, Society, and Human Beings},
  year={2020}
}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Network + AML
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% construct a network from large cash deposits and international transfers, from which they extract small communities of interacting parties using a bottom-up community detection algorithm. These communities are then treated as observations to be classified. Features that capture the community characteristics are created and used to train a model to classify a community as suspicious or not using supervised learning, including \textit{support vector machine} and \textit{random forest}.
% Citations: 33
@article{SAVAGE2016,
  title={Detection of money laundering groups using supervised learning in networks},
  author={Savage, David and Wang, Qingmai and Chou, Pauline and Zhang, Xiuzhen and Yu, Xinghuo},
  journal={arXiv preprint arXiv:1608.00708},
  year={2016}
}

% explore using social network metrics in the monitoring system. The data is from a medium-sized Italian factoring company and consists of 559 nodes. They introduce multiple ways of creating networks, each of which aim at revealing a specific aspect. Here, they use expert domain knowledge to achieve this. They illustrate that the graphs were able to identify clusters of parties involved in court trials and could be suitable for triggering alerts. They also conclude that network centrality measures are useful for distinguishing between normal and high-risk entities. 
% Citations: 169
@article{COLLADON2017,
  title={Using social network analysis to prevent money laundering},
  author={Colladon, Andrea Fronzetti and Remondi, Elisa},
  journal={Expert Systems with Applications},
  volume={67},
  pages={49--58},
  year={2017},
  publisher={Elsevier}
}

% identify suspicious communities in a transaction network using, among other techniques, \textit{the Louvain method}. They corroborate the importance of network analysis to detect criminal groups, and claim that their techniques can help detect them in massive transaction networks. 
% Citations: 17
@inproceedings{LI2017,
  title={Intelligent anti-money laundering solution based upon novel community detection in massive transaction networks on spark},
  author={Li, Xurui and Cao, Xiang and Qiu, Xuetao and Zhao, Jintao and Zheng, Jianbin},
  booktitle={2017 fifth international conference on advanced cloud and big data (CBD)},
  pages={176--181},
  year={2017},
  organization={IEEE}
}
 
% use a combination of network comparison and \textit{spectral analysis} to create features that are used in a downstream learning algorithm to classify anomalies. 
% Citations: 13
@article{ELLIOTT2019,
  title={Anomaly detection in networks with application to financial transaction networks},
  author={Elliott, Andrew and Cucuringu, Mihai and Luaces, Milton Martinez and Reidy, Paul and Reinert, Gesine},
  journal={arXiv preprint arXiv:1901.00402},
  year={2019}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% GNN + AML
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%  provide a first look at applying graph neural networks on the AML use case. They create a synthetic graph dataset named \textit{AMLSim}, consisting of one million nodes and nine million edges, with accounts as nodes and transactions as edges. A small number of these accounts were conducting suspicious activities as modelled on real-world patterns. They then use semi-supervised learning to train a model to predict the suspiciousness of each node. Here, they use GNNs to create features that are used in the downstream machine learning task. They further focus on the scalability and efficiency of GNNs. They compare the original GNN algorithm GCN (\cite{GCNConv}) to \textit{fastGCN} (\cite{chen2018}), and conclude that fastGCN is more efficient.  They state that their results support the hypothesis that GNNs show great promise as a tool for AML. 
% Citations: 50
@article{weber2018,
  title={Scalable graph learning for anti-money laundering: A first look},
  author={Weber, Mark and Chen, Jie and Suzumura, Toyotaro and Pareja, Aldo and Ma, Tengfei and Kanezashi, Hiroki and Kaler, Tim and Leiserson, Charles E and Schardl, Tao B},
  journal={arXiv preprint arXiv:1812.00076},
  year={2018}
}

% \cite{weber2019} present the Elliptic Data set, consisting of  200k nodes and 234k edges, which is made publicly available. The data set is a graph generated from bitcoin transactions. The nodes are labeled, with about 2\% labeled as illicit, 21\% as licit, and the remaining are unlabelled. They continue by comparing logistic regression, random forest and Multilayer Perceptrons learning techniques to classify the nodes, using intrinsic node features and graph-generated features that contain information about the node neighborhood. They find that random forest outperforms the others, and that the graph features increase performance. They also test GCN, and finds that it performs better than logistic regression, but is still outperformed by random forest. 
% Citations: 162
@article{weber2019,
  title={Anti-money laundering in bitcoin: Experimenting with graph convolutional networks for financial forensics},
  author={Weber, Mark and Domeniconi, Giacomo and Chen, Jie and Weidele, Daniel Karl I and Bellei, Claudio and Robinson, Tom and Leiserson, Charles E},
  journal={arXiv preprint arXiv:1908.02591},
  year={2019}
}

% \cite{alarab2020} build on the work done in \cite{weber2019}, using GCN on the elliptic dataset, and where the task and the dataset are the same. To achieve better results, they concatenate node embeddings obtained from GCN with another set of embeddings obtained from a linear transformation of the original node features. The resulting concatenated features are then taken as inputs into a multilayer perceptron that outputs the final prediction. They have also replaced the original GCN method with a modified method which they state works better on directed graphs. They find that this approach performs better compared to solely using GCN, and achieve better results than what is produced using GCN in \cite{weber2019}. This indicates that there is much that can be done to improve the performance of using graph neural networks on these types of problem. In particular, it motivates to experiment with newer and more sophisticated GNN methods than GCN. 
% Citations: 19
@inproceedings{alarab2020,
  title={Competence of graph convolutional networks for anti-money laundering in bitcoin blockchain},
  author={Alarab, Ismail and Prakoonwit, Simant and Nacer, Mohamed Ikbal},
  booktitle={Proceedings of the 2020 5th International Conference on Machine Learning Technologies},
  pages={23--27},
  year={2020}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% GNNs
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


% GCN
@article{KIPF2016,
  title={Semi-supervised classification with graph convolutional networks},
  author={Kipf, Thomas N and Welling, Max},
  journal={arXiv preprint arXiv:1609.02907},
  year={2016}
}

% GraphSAGE
@inproceedings{HAMILTON2017,
  title={Inductive representation learning on large graphs},
  author={Hamilton, William L and Ying, Rex and Leskovec, Jure},
  booktitle={Proceedings of the 31st International Conference on Neural Information Processing Systems},
  pages={1025--1035},
  year={2017}
}

% GAT
@article{VELIVCKOVIC2017,
  title={Graph attention networks},
  author={Veli{\v{c}}kovi{\'c}, Petar and Cucurull, Guillem and Casanova, Arantxa and Romero, Adriana and Lio, Pietro and Bengio, Yoshua},
  journal={arXiv preprint arXiv:1710.10903},
  year={2017}
}


% MPNN
@inproceedings{GILMER2017,
  title={Neural message passing for quantum chemistry},
  author={Gilmer, Justin and Schoenholz, Samuel S and Riley, Patrick F and Vinyals, Oriol and Dahl, George E},
  booktitle={International conference on machine learning},
  pages={1263--1272},
  year={2017},
  organization={PMLR}
}

@article{SUN2013,
  title={Mining heterogeneous information networks: a structural analysis approach},
  author={Sun, Yizhou and Han, Jiawei},
  journal={Acm Sigkdd Explorations Newsletter},
  volume={14},
  number={2},
  pages={20--28},
  year={2013},
  publisher={ACM New York, NY, USA}
}

% Link Prediction
@article{ZHANG2018,
  title={Link prediction based on graph neural networks},
  author={Zhang, Muhan and Chen, Yixin},
  journal={Advances in neural information processing systems},
  volume={31},
  year={2018}
}

% Graph Clustering
@inproceedings{WANG2017,
  title={Mgae: Marginalized graph autoencoder for graph clustering},
  author={Wang, Chun and Pan, Shirui and Long, Guodong and Zhu, Xingquan and Jiang, Jing},
  booktitle={Proceedings of the 2017 ACM on Conference on Information and Knowledge Management},
  pages={889--898},
  year={2017}
}

% Graph Similarity
@inproceedings{BAI2019,
  title={Simgnn: A neural network approach to fast graph similarity computation},
  author={Bai, Yunsheng and Ding, Hao and Bian, Song and Chen, Ting and Sun, Yizhou and Wang, Wei},
  booktitle={Proceedings of the Twelfth ACM International Conference on Web Search and Data Mining},
  pages={384--392},
  year={2019}
}

% Graph Representation / unsupervised embeding with GNNs
@article{KIPF2016variational,
  title={Variational graph auto-encoders},
  author={Kipf, Thomas N and Welling, Max},
  journal={arXiv preprint arXiv:1611.07308},
  year={2016}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Hetero GNNs
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% RGCN
@inproceedings{SCHLICHTKRULL2018,
  title={Modeling relational data with graph convolutional networks},
  author={Schlichtkrull, Michael and Kipf, Thomas N and Bloem, Peter and Berg, Rianne van den and Titov, Ivan and Welling, Max},
  booktitle={European semantic web conference},
  pages={593--607},
  year={2018},
  organization={Springer}
}

% HAN
@inproceedings{WANG2019,
  title={Heterogeneous graph attention network},
  author={Wang, Xiao and Ji, Houye and Shi, Chuan and Wang, Bai and Ye, Yanfang and Cui, Peng and Yu, Philip S},
  booktitle={The world wide web conference},
  pages={2022--2032},
  year={2019}
}


% MAGNN
@article{FU2020MAGNN,
  title={MAGNN: Metapath Aggregated Graph Neural Network for Heterogeneous Graph Embedding},
  author={Xinyu Fu and Jiani Zhang and Ziqiao Meng and Irwin King},
  journal={Proceedings of The Web Conference 2020},
  year={2020}
}

% HGT
@article{HU2020HGT,
  title={Heterogeneous Graph Transformer},
  author={Ziniu Hu and Yuxiao Dong and Kuansan Wang and Yizhou Sun},
  journal={Proceedings of The Web Conference 2020},
  year={2020}
}

% HetGNN
@article{ZHANG2019HetGNN,
  title={Heterogeneous Graph Neural Network},
  author={Chuxu Zhang and Dongjin Song and Chao Huang and Ananthram Swami and N. Chawla},
  journal={Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery \& Data Mining},
  year={2019}
}