%File: anonymous-submission-latex-2024.tex
\documentclass[letterpaper]{article} % DO NOT CHANGE THIS

%  add your own packages  --------------
\usepackage{subfigure}
\usepackage{color,xcolor}
\usepackage{amsmath}
\usepackage{amssymb,amsthm}
\usepackage{bm}
\usepackage{multirow}
\usepackage{enumitem}
\usepackage{booktabs}
\usepackage{newfloat}
\usepackage{listings}
%  add your own packages  --------------

\usepackage{aaai24}  % DO NOT CHANGE THIS
%\usepackage[submission]{aaai24}  % DO NOT CHANGE THIS
\usepackage{times}  % DO NOT CHANGE THIS
\usepackage{helvet}  % DO NOT CHANGE THIS
\usepackage{courier}  % DO NOT CHANGE THIS
\usepackage[hyphens]{url}  % DO NOT CHANGE THIS
\usepackage{graphicx} % DO NOT CHANGE THIS
\urlstyle{rm} % DO NOT CHANGE THIS
\def\UrlFont{\rm}  % DO NOT CHANGE THIS
\usepackage{natbib}  % DO NOT CHANGE THIS AND DO NOT ADD ANY OPTIONS TO IT
\usepackage{caption} % DO NOT CHANGE THIS AND DO NOT ADD ANY OPTIONS TO IT
\frenchspacing  % DO NOT CHANGE THIS
\setlength{\pdfpagewidth}{8.5in} % DO NOT CHANGE THIS
\setlength{\pdfpageheight}{11in} % DO NOT CHANGE THIS
%
% These are recommended to typeset algorithms but not required. See the subsubsection on algorithms. Remove them if you don't have algorithms in your paper.
\usepackage{algorithm}
\usepackage{algorithmic}

%
% These are are recommended to typeset listings but not required. See the subsubsection on listing. Remove this block if you don't have listings in your paper.

\DeclareCaptionStyle{ruled}{labelfont=normalfont,labelsep=colon,strut=off} % DO NOT CHANGE THIS
\lstset{%
	basicstyle={\footnotesize\ttfamily},% footnotesize acceptable for monospace
	numbers=left,numberstyle=\footnotesize,xleftmargin=2em,% show line numbers, remove this entire line if you don't want the numbers.
	aboveskip=0pt,belowskip=0pt,%
	showstringspaces=false,tabsize=2,breaklines=true}
\floatstyle{ruled}
\newfloat{listing}{tb}{lst}{}
\floatname{listing}{Listing}
%
% Keep the \pdfinfo as shown here. There's no need
% for you to add the /Title and /Author tags.
\pdfinfo{
/TemplateVersion (2024.1)
}

% DISALLOWED PACKAGES
% \usepackage{authblk} -- This package is specifically forbidden
% \usepackage{balance} -- This package is specifically forbidden
% \usepackage{color (if used in text)
% \usepackage{CJK} -- This package is specifically forbidden
% \usepackage{float} -- This package is specifically forbidden
% \usepackage{flushend} -- This package is specifically forbidden
% \usepackage{fontenc} -- This package is specifically forbidden
% \usepackage{fullpage} -- This package is specifically forbidden
% \usepackage{geometry} -- This package is specifically forbidden
% \usepackage{grffile} -- This package is specifically forbidden
% \usepackage{hyperref} -- This package is specifically forbidden
% \usepackage{navigator} -- This package is specifically forbidden
% (or any other package that embeds links such as navigator or hyperref)
% \indentfirst} -- This package is specifically forbidden
% \layout} -- This package is specifically forbidden
% \multicol} -- This package is specifically forbidden
% \nameref} -- This package is specifically forbidden
% \usepackage{savetrees} -- This package is specifically forbidden
% \usepackage{setspace} -- This package is specifically forbidden
% \usepackage{stfloats} -- This package is specifically forbidden
% \usepackage{tabu} -- This package is specifically forbidden
% \usepackage{titlesec} -- This package is specifically forbidden
% \usepackage{tocbibind} -- This package is specifically forbidden
% \usepackage{ulem} -- This package is specifically forbidden
% \usepackage{wrapfig} -- This package is specifically forbidden
% DISALLOWED COMMANDS
% \nocopyright -- Your paper will not be published if you use this command
% \addtolength -- This command may not be used
% \balance -- This command may not be used
% \baselinestretch -- Your paper will not be published if you use this command
% \clearpage -- No page breaks of any kind may be used for the final version of your paper
% \columnsep -- This command may not be used
% \newpage -- No page breaks of any kind may be used for the final version of your paper
% \pagebreak -- No page breaks of any kind may be used for the final version of your paperr
% \pagestyle -- This command may not be used
% \tiny -- This is not an acceptable font size.
% \vspace{- -- No negative value may be used in proximity of a caption, figure, table, section, subsection, subsubsection, or reference
% \vskip{- -- No negative value may be used to alter spacing above or below a caption, figure, table, section, subsection, subsubsection, or reference

\setcounter{secnumdepth}{2} %May be changed to 1 or 2 if section numbers are desired.

% The file aaai24.sty is the style file for AAAI Press
% proceedings, working notes, and technical reports.
%

% Title

% Your title must be in mixed case, not sentence case.
% That means all verbs (including short verbs like be, is, using,and go),
% nouns, adverbs, adjectives should be capitalized, including both words in hyphenated terms, while
% articles, conjunctions, and prepositions are lower case unless they
% directly follow a colon or long dash
\title{Towards Automatic Boundary Detection for Human-AI Collaborative Hybrid Essay in Education}
\author{
    %Authors
    % All authors must be in the same font size and format.
    %Written by AAAI Press Staff\textsuperscript{\rm 1}\thanks{With help from the AAAI Publications Committee.}\\
    %AAAI Style Contributions by Pater Patel Schneider,
    Zijie Zeng,
    Lele Sha,
    Yuheng Li,
    Kaixun Yang,
    Dragan Ga\v{s}evi\'{c} \text{and}
    Guanliang Chen\thanks{Corresponding author}
}
\affiliations{
    %Afiliations
    \textsuperscript{\rm }Centre for Learning Analytics, Monash University, Australia\\
    \{Zijie.Zeng, Lele.Sha1, Yuheng.Li, Kaixun.Yang1, Dragan.Gasevic, Guanliang.Chen\}@monash.edu}

%Example, Single Author, ->> remove \iffalse,\fi and place them surrounding AAAI title to use it
\iffalse
\title{My Publication Title --- Single Author}
\author {
    Author Name
}
\affiliations{
    Affiliation\\
    Affiliation Line 2\\
    name@example.com
}
\fi

\iffalse
%Example, Multiple Authors, ->> remove \iffalse,\fi and place them surrounding AAAI title to use it
\title{My Publication Title --- Multiple Authors}
\author {
    % Authors
    First Author Name\textsuperscript{\rm 1},
    Second Author Name\textsuperscript{\rm 2},
    Third Author Name\textsuperscript{\rm 1}
}
\affiliations {
    % Affiliations
    \textsuperscript{\rm 1}Affiliation 1\\
    \textsuperscript{\rm 2}Affiliation 2\\
    firstAuthor@affiliation1.com, secondAuthor@affilation2.com, thirdAuthor@affiliation1.com
}
\fi


% REMOVE THIS: bibentry
% This is only needed to show inline citations in the guidelines document. You should not need it and can safely delete it.
\usepackage{bibentry}
% END REMOVE bibentry

\begin{document}

\maketitle

\begin{abstract}

The recent large language models (LLMs), e.g., ChatGPT, have been able to generate human-like and fluent responses when provided with specific instructions. While admitting the convenience brought by technological advancement, educators also have concerns that students might leverage LLMs to complete their writing assignments and pass them off as their original work. Although many AI content detection studies have been conducted as a result of such concerns, most of these prior studies modeled AI content detection as a classification problem, assuming that a text is either entirely human-written or entirely AI-generated. In this study, we investigated AI content detection in a rarely explored yet realistic setting where the text to be detected is collaboratively written by human and generative LLMs (termed as hybrid text for simplicity). We first formalized the detection task as identifying the transition points between human-written content and AI-generated content from a given hybrid text (boundary detection). We constructed a hybrid essay dataset by partially and randomly removing sentences from the original student-written essays and then instructing ChatGPT to fill in for the incomplete essays. Then we proposed a two-step detection approach where we (1) separated AI-generated content from human-written content during the encoder training process; and (2) calculated the distances between every two adjacent prototypes (a prototype is the mean of a set of consecutive sentences from the hybrid text in the embedding space) and assumed that the boundaries exist between the two adjacent prototypes that have the furthest distance from each other. Through extensive experiments, we observed the following main findings: (1) the proposed approach consistently outperformed the baseline methods across different experiment settings; (2) the encoder training process (i.e., step 1 of the above two-step approach) can significantly boost the performance of the proposed approach; (3) when detecting boundaries for single-boundary hybrid essays, the proposed approach could be enhanced by adopting a relatively large prototype size (i.e., the number of sentences needed to calculate a prototype), leading to a $22$\% improvement (against the best baseline method) in the In-Domain evaluation and an $18$\% improvement in the Out-of-Domain evaluation.

\end{abstract}

\section{Introduction}\label{sec:intro}

The recent advancements in large language models (LLMs) have enabled them to generate human-like and fluent responses when provided with specific instructions. However, the growing generative abilities of LLM have arguably been a sword with two blades. As pointed out by \citet{ma2023abstract,zellers2019defending}, LLMs can potentially be used to generate seemingly correct but unverifiable texts that may be maliciously used to sway public opinion in a variety of ways, e.g., fake news \citep{zellers2019defending}, fake app reviews \citep{martens2019towards}, fake social media posts\citep{fagni2021tweepfake}, and others\citep{weidinger2021ethical, abid2021persistent, gehman2020realtoxicityprompts}. Particularly, concerns have been raised among educators that students may be tempted to leverage the powerful generative capability of LLMs to complete their writing assessments (e.g., essay writing \citep{choi2023chatgpt} and reflective writings \citep{li2023can}), thereby wasting the valuable learning activities that were purposefully designed for developing students' analytical and critical thinking skills \citep{ma2023abstract,dugan2023real,mitchell2023detectgpt}. At the same time, teachers also wasted their effort in grading and providing feedback to artificially generated answers. 
Driven by the above concerns, many studies focused on differentiating human-written content from AI-generated content have been conducted~\citep{mitchell2023detectgpt, ma2023abstract, zellers2019defending, uchendu-etal-2020-authorship, fagni2021tweepfake, ippolito2020automatic}. For example, to advance the techniques for detecting AI-generated content on social media (e.g., Twitter and Facebook), \citet{fagni2021tweepfake} constructed the TweepFake dataset, based on which they evaluated $13$ widely known detection methods. 

% Figure environment removed

While most existing studies \citep{ma2023abstract, clark2021all, mitchell2023detectgpt, jawahar2020automatic, martens2019towards} formalized the AI-content detection as a binary classification problem and assumed that a sample text is either entirely human-written or entirely AI-generated, \citet{dugan2023real} noticed the trends in human-AI collaborative writing \citep{buschek2021impact,lee2022coauthor} and reflected on the binary classification setting, pointing out that a text (or passage) could begin as human-written and end with AI content generated by LLMs (i.e., hybrid text). They argued that due to the collaborative nature of such text, simply yielding the probability of a text being human-written or AI-generated is less informative than identifying from it the possible AI-generated content. Similar phenomena were observed (illustrated in Figure \ref{fig1}) when we tested a commercial AI content detector called GPTzero\footnote{https://gptzero.me/} with a hybrid essay written first by human (sentences 1-3) and then by ChatGPT (sentences 4-7), the detector suggested that the hybrid input essay was human-written but with mere confidence of 51\% and failed to correctly indicate the AI-generated sentences (sentences 4-7), i.e., none of the sentences were identified as AI-generated. We argue that as human-AI collaborative writing is becoming increasingly popular, a more fine-grained level of AI content detection (i.e., detecting exactly the AI-generated parts) will be of more significance. For example, educators might need to know exactly which parts of the text are AI-generated so that they can extract the suspicious parts for further examination. Therefore, in this study, we investigated AI content detection in a rarely explored yet realistic setting where the text to be detected is collaboratively written by human and generative LLMs (i.e., hybrid text). As pointed out by \citet{wang2018lstm,wang2021hierarchical}, texts of shorter length (e.g., sentences) are more difficult to classify than longer texts due to the lack of context information (e.g., in Figure \ref{fig1}, GPTZero failed to identify any AI content from the sentence-level). Therefore, instead of addressing AI content detection as a sentence-by-sentence classification problem, we instead followed \citet{dugan2023real} to formalize the AI content detection from hybrid text as identifying the transition points between human-written content and AI-generated content (i.e., boundary detection). We formally defined our research question (RQ) as:
\begin{itemize}
    \item To what extent can the boundaries between human-written content and AI-generated content be automatically detected from essays written collaboratively by students and generative large language models?
\end{itemize}


To investigate this RQ, we first constructed a human-AI collaborative hybrid essay dataset by partially and randomly removing sentences from the student-written essays of an open-sourced dataset\footnote{https://www.kaggle.com/c/asap-aes} and by leveraging ChatGPT to fill in for the incomplete essays. Then we proposed our two-step approach (also elaborated in Section \ref{sec:our approach}) to (1) separate AI-generated content from human-written content during the encoder training process; and (2) calculate the distances between every two adjacent prototypes (a prototype \citep{snell2017prototypical} means the average embeddings of a set of consecutive sentences from the hybrid text) and assumed that the boundaries exist between the two adjacent prototypes that have the furthest distance from each other. Through extensive experiments, we summarized the following main findings: (1) The proposed approach consistently outperformed the baseline methods (including a fine-tuned BERT-based method and an online AI detector GPTZero) across the in-domain evaluation and the out-of-domain evaluation; (2) the encoder training process (i.e., step 1 of the above two-step approach) can significantly boost the performance of the proposed approach; (3) when detecting boundaries for single-boundary hybrid essays, the performance of the proposed approach could be enhanced by adopting a relatively large prototype size, resulting in a $22$\% improvement (against the best baseline method) in the In-Domain setting and a $18$\% improvement in the Out-of-Domain setting. 
%Our dataset and the codes are available via Github\footnote{Codes and the constructed dataset are temporarily submitted as supplementary material during the blind review stage.}.

%\footnote{This link is temporarily hidden as per the double-blind review requirement.}.

%\footnote{In the In-Domain (or Out-of-Domain) evaluation setting, training essays and testing essays are from the same set of prompts (or from different prompts).}





\section{Related Work}\label{sec:background}
%\subsection{Large Language Model and AI content Detection, Human-AI Collaborative Writing, and Boundary Detection} 

\smallskip
\noindent\textbf{Large Language Models and AI Content Detection.}
The recent LLMs have been able to generate fluent and natural-sounding text. Among all LLMs, the Generative Pre-trained Transformer (GPT) \citep{radford2018improving, radford2019language,brown2020language} series of language models developed by OpenAI, are known to be the state of the art and have achieved great success in NLP tasks. ChatGPT, a variant of GPT, is specifically optimized for conversational response generation \citep{hassani2023role} and could generate human-like responses to specific input text (i.e., prompt text) in different styles or tones, according to the role we require it to play \citep{aljanabi2023chatgpt}. 
Along with the advancement of LLMs are concerns over the potential misuse of its powerful generative ability. For example, \citet{ma2023abstract,zellers2019defending} pointed out that LLMs can be used to generate misleading information that might affect public opinion, e.g., fake news \citep{zellers2019defending}, fake app reviews \citep{martens2019towards}, fake social media text \citep{fagni2021tweepfake}, and other harmful text \citep{weidinger2021ethical}. Education practitioners are also concerned about students' leveraging LLMs to complete writing assignments, without developing writing and critical thinking skills \citep{ma2023abstract,dugan2023real,mitchell2023detectgpt}. Driven by the need to identify AI content, many online detecting tools have been developed, e.g., WRITER\footnote{https://writer.com/ai-content-detector/}, Copyleaks\footnote{https://copyleaks.com/ai-content-detector}, and GPTZero. Concurrent with these tools are the AI content detection studies, which have been focused on either (a) investigating humans' abilities to detect AI content \citep{ippolito2020automatic, clark2021all, brown2020language, ethayarajh2022human, dugan2023real}, e.g., \citet{ethayarajh2022human} reported an interesting finding that human annotators rated GPT-3 generated text more human-like than the authentic human-written text; or (b) automating the detection of AI content \citep{ma2023abstract, clark2021all, mitchell2023detectgpt, jawahar2020automatic, martens2019towards}. For example, \citet{ma2023abstract} investigated features for detecting AI-generated scientific text, i.e., writing style, coherence, consistency, and argument logistics. They found that AI-generated scientific text significantly differentiated from human-written scientific text in terms of writing style. 

\smallskip
\noindent\textbf{Human-AI Collaborative Hybrid text and Boundary Detection.}
With modern LLMs, human-AI collaborative writing is becoming more and more convenient. For example, \citet{buschek2021impact} attempted to leverage GPT-2 to generate phrase-level suggestions for human writers in their email writing tasks. Similar studies were conducted in \citet{lee2022coauthor}, where they alternatively used the more powerful GPT-3 for providing sentence-level suggestions for human-AI interactive essay writing. The trends in human-AI collaborative writing also pose a new challenge to the AI content detection research community: \textit{How to detect AI content from a hybrid text collaboratively written by human and LLMs?} As a response to this question, \citet{dugan2023real} proposed to formalize the AI content detection from hybrid text as a boundary detection problem. Specifically, they investigated human's ability to detect the boundary from hybrid texts with one boundary and found that, although humans' abilities to detect boundaries could be boosted after certain training processes, the overall detecting performance was hardly satisfactory, i.e., the human participants could only correctly identify the boundary $23.4\%$ of the time. Similar to \citet{dugan2023real}, our study also targeted boundary detection, but with the following differences: (1) we studied automatic approaches for boundary detection; (2) the hybrid texts considered in this study were of multiple boundaries while \citet{dugan2023real} focused only on single-boundary hybrid texts.

%Driven by the trends in Human-AI collaborative writing, and the need for education practitioners to identify AI content from hybrid texts in real-world scenarios, in this study, we investigated the automatic detection of hybrid essays in education and formalized the detection of hybrid text as a boundary detection problem, considering its collaborative nature involving multiple authors.
% \citet{cutler2021automatic} addressed boundary detection as a classification problem and trained a series of classifiers to predict the boundaries. However, their approaches were restricted to single-boundary hybrid texts and required the number of sentences to be fixed across all hybrid texts, preventing their application to hybrid texts in real-world scenarios\footnote{Hybrid texts in real-world scenarios can contain an arbitrary number of sentences and boundaries.}. 

\section{Method}

\subsection{Hybrid Essay Dataset Construction}\label{sec:data}
To the best of our knowledge, there appear to be no available datasets containing hybrid educational texts suitable for investigating our research question (described in Section \ref{sec:intro}). In this section, we set out to construct a hybrid text dataset of educational essays.

\smallskip
\noindent\textbf{Source Data and Pre-processing.}
%\subsubsection{}
We identified the essay dataset for the Automated Student Essay Assessment competition\footnote{https://www.kaggle.com/c/asap-aes} as the suitable source material to construct our educational hybrid essay dataset. This source dataset recorded essays from eight question prompts that spanned various topics. These source essays were written by junior high school students (Grade 7 to 10) in the US. To ensure a level of quality and informativeness, we only preserved the source essays with more than 100 words. We noticed that for some source essays, entities such as dates, locations, and the names of the persons had been anonymized and replaced with strings starting with `@' for the sake of privacy protection. For example, the word `Boston' in the original source essay was replaced with `@LOCATION'. We filtered out essays containing such anonymized entities to prevent our model from incorrectly associating data bias \citep{lyu2023feature} with the label, i.e., associating the presence of `@' with the authorship (human-written or AI-generated) of the text. 
%Finally, we obtained a total of 4082 essays for the later hybrid essay generation.

\begin{table*}[!htb]
 \caption{Descriptions of the fill-in tasks. \textbf{H} and \textbf{G} in Hybrid Text Structure are short for \textbf{H}uman-written text and \textbf{G}enerated text, respectively. For example, $<$H$\rightarrow$G$\rightarrow$H$>$ in Task 3 means that the expected hybrid essay should be started/ended with human-written sentences, while the text in between the starting and the ending should be generated by ChatGPT.} \label{table1}
 \begin{center}

\resizebox{0.93\textwidth}{!}{
     
     \begin{tabular}{l|p{4.7cm}|p{4.7cm}|p{4.7cm}p{4.7cm}} 
    \toprule
     & Task 1 & Task 2 & Task 3 \\ 
    \midrule
    Description & Task 1 requires ChatGPT to generate continuation based on the specified beginning
     text. & Task 2 requires ChatGPT to generate the essay using the specified ending. & Task 3
     requires ChatGPT to fill in between the specified beginning and specified ending. \\ 
    \midrule
    Hybrid Text Structure & H$\rightarrow$G & G$\rightarrow$H & H$\rightarrow$G$\rightarrow$H \\ 
    \midrule
    \#Boundaries & 1 & 1 & 2 \\ 
    \midrule
     & Task 4 & Task 5 & Task 6 \\ 
    \midrule
    Description & Task 4
     requires that the generated essay should include the specified human-written
     text between the beginning and the ending. & Task
     5 requires ChatGPT to fill in for the incompleted essay where some in-between
     text and the ending text have been removed. & Task
     6 requires ChatGPT to fill in for the incompleted essay where some in-between
     text and the beginning text have been removed. \\ 
    \midrule
    Hybrid Text Structure & G$\rightarrow$H$\rightarrow$G & H$\rightarrow$G$\rightarrow$H$\rightarrow$G & G$\rightarrow$H$\rightarrow$G$\rightarrow$H \\ 
    \midrule
    \#Boundaries & 2 & 3 & 3 \\
    \bottomrule
    \end{tabular}

}
 \end{center}
\end{table*}

%\subsubsection{}
\smallskip
\noindent\textbf{Hybrid Essay Generation.}
We employed ChatGPT as the generative AI agent for hybrid essay generation, considering its outstanding generative ability \citep{latif2023artificial, xiao2023evaluating} and easy accessibility. To construct a hybrid essay from a source essay $R$, we randomly removed a few sentences\footnote{For a source essay with $k$ sentences, the number of sentences to be removed was randomly selected from $[1, k-1]$.} from $R$ and instructed ChatGPT to perform a fill-in task over the incomplete essay $R'$. Specifically, We designed six fill-in tasks with different prompting texts in order to generate hybrid essays with varying numbers of boundaries, as shown in Table \ref{table1}. 
%For example, in task 1, ChatGPT was prompted to continue writing the essay based on the given beginning text; in task 3, ChatGPT was required to fill in between the specified beginning text and ending text.

%We acknowledge that this is not the only way to generate hybrid text, e.g., a hybrid essay could be generated by a student and ChatGPT through multi-turn interaction.
%%, the missing parts that ChatGPT was required to fill were different from task to task.
%to cover some possible use cases of leveraging ChatGPT to generate hybrid essays in real-life circumstances.

\smallskip
\noindent\textbf{Prompt Engineering.}
For each hybrid essay, the adopted prompting text generally consisted of two parts: (1) the instructions\footnote{https://www.kaggle.com/competitions/asap-aes/data.} that a writer should refer to when compositing the essay. We directly adopted these instructions as the first part of the prompting text; (2) the second part was the task-relevant prompting text that detailed the specific requirements regarding the structure of the hybrid essay:
\begin{itemize}
    \item Task 1: \textit{Please begin with $<$BEGINNING TEXT$>$.}
    \item Task 2: \textit{Please ensure to use $<$ENDING TEXT$>$ as the ending.}
    \item Task 3: \textit{Please begin with $<$BEGINNING TEXT$>$ and continue writing the second part. For the ending, please use $<$ENDING TEXT$>$ as the ending.}
    \item Task 4: \textit{Please ensure to include $<$IN-BETWEEN TEXT$>$ in between the starting text and the ending text.}
\end{itemize}

Based on the above prompting texts for basic tasks 1--4, we could complete the relatively complex tasks (i.e., Tasks 5 and 6 because multiple missing text pieces needed to be filled to complete these tasks) following two steps:

%We found that ChatGPT can generate the hybrid essays as expected when simple instructions (prompting text for task 1, 2, 3, and 4) were given. However, for complicated tasks (task 5 and 6) where multiple missing text pieces needed to be filled (e.g., task 5 required ChatGPT to fill for the in-between text and the ending text), ChatGPT tended to generate unexpected output (failing to correctly fill in at the expected space) with a single and unified prompt. Therefore, for task 5 and 6, we alternatively broke the fill-in task into two steps, where we found the chance of generating unexpected output could be significantly reduced. The prompting text for each step is as follows:

\begin{itemize}
    \item Step 1: We follow the prompting text of task 3 to generate an initial hybrid essay, which is denoted as $H_1\rightarrow G\rightarrow H_2$, meaning that the first part ($H_1$) and the third part ($H_2$) are \textbf{H}uman-written while the second part ($G$) is \textbf{G}enerated by ChatGPT.
    \item Step 2: We randomly remove\footnote{The number of sentences to be removed from $H_1$ is randomly selected from $[1, k-1]$, where $k$ is the number of sentences of $H_1$.} the first few sentences from $H_1$ and obtain $H_1'$. Then we use the prompt '\textit{Please use $H_1'\rightarrow G\rightarrow H_2$ as the ending}' to obtain the final hybrid essay as required by task 6, which could be denoted as $G'\rightarrow H_1'\rightarrow G\rightarrow H_2$. Similarly, when we remove the last few sentences from $H_2$ and obtain $H_2'$, we can prompt ChatGPT with '\textit{Please begin with $H_1\rightarrow G\rightarrow H_2'$} to obtain the hybrid essay as required by task 5, denoted as $H_1\rightarrow G\rightarrow H_2'\rightarrow G'$.
\end{itemize} 

Due to the randomness\footnote{The extent of the randomness of the ChatGPT-generated output can be controlled by adjusting the hyperparameter `Temperature' (ranging from $[0,1]$), which enables the output to be creative and diverse when set to be high. We used the default value of $0.7$.} of the generative nature of ChatGPT \citep{castro2023large,lyu2023translating}, we could occasionally get invalid\footnote{When the generated output failed to match the expected format as described in Table \ref{fig1}, or contained duplicate sentences, it is considered invalid.} output. To deal with this, we simply discarded the invalid output and instructed ChatGPT to generate a hybrid essay (again) for a maximum of five attempts. If all attempts failed for a specific source essay, we skipped this essay. The statistics of the final hybrid essay dataset are described in Table \ref{table2}.

%To ensure the authenticity of the human-written text, we still preserved the typo\footnote{We noticed that ChatGPT tended to automatically fix typos within the human-written text.} within the human-written part of the hybrid essay and ignore the typo-fixing modification.

\begin{table}[!htb]
 \caption{Statistics of the hybrid essay dataset.} \label{table2}
 \begin{center}

\resizebox{0.43\textwidth}{!}{
     
     %\begin{tabular}{l|p{3.7cm}|p{3.7cm}|p{3.7cm}p{3.7cm}} 
    \begin{tabular}{l|ccc|c} %{l|p{3.7cm}|p{3.7cm}|p{3.7cm}p{3.7cm}} 
    %\begin{tabular}{p{3.0cm}|ccc|c} 
        \toprule
        \multirow{2}{*}{} & \multicolumn{3}{c|}{\#Boundaries} & \multirow{2}{*}{All} \\ 
        \cline{2-4}
         & 1 & 2 & 3 & \\ 
         %\midrule
        %\#Source essay & 4034 & 3880 & 2510 & 4049 \\ 
        \midrule
        \#Hybrid essay & 7488 & 6429 & 3219 & 17136 \\ 
        \midrule
        \#Words per essay & 275.3 & 279.5 & 332.6 & 287.6 \\ 
        \midrule
        \#Sentences
         per essay & 12.9 & 13.4 & 16.1 & 13.7 \\ 
        \midrule
        \begin{tabular}[c]{@{}l@{}}Average length\\ of AI-generated\\ sentences\end{tabular} & 22.7 & 21.8 & 21.7 & 22.2 \\ 
        \midrule
        \begin{tabular}[c]{@{}l@{}}Average length\\ of human-written\\ sentences\end{tabular} & 22.7 & 22.6 & 21.2 & 22.4 \\ 
        \midrule
        \begin{tabular}[c]{@{}l@{}}Ratio of AI-generated\\ sentences per essay\end{tabular} & 67.4\% & 58.8\% & 73.2\% & 65.3\% \\
        \bottomrule
    \end{tabular}

}
 \end{center}
\end{table}



\subsection{Task and Evaluation}

For a given hybrid text $<s_{1}, s_{2},...,s_{n}>$ consisting of $n$ sentences where each sentence is either human-written or AI-generated, the automatic boundary detection task requires an algorithm to identify all indexes $i$ (i.e., boundaries), where sentence $s_i$ and sentence $s_{i+1}$ are written by different authors, e.g., the former sentence by human and the later sentence by generative language model (e.g., ChatGPT), or vice versa. To evaluate the ability of an algorithm to detect boundaries from a hybrid text, we first describe the following two concepts: (1) $L_{topK}$: The list of top-K boundaries suggested by an algorithm; and (2) $L_{Gt}$: The ground-truth list that contains the actual boundaries. We adopted the \textit{F1} score as the evaluation metric because it considers both \textit{precision} and \textit{recall} in its calculation (i.e., \textit{F1} is the harmonic mean \citep{lipton2014thresholding} of \textit{precision} and \textit{recall}). The \textit{F1} score can be calculated as:

\begin{equation}\label{eq:1}
    F1@K = 2\cdot  \dfrac{|L_{topK}\cap L_{Gt}|}{ |L_{topK}|+ |L_{Gt}| }.
\end{equation}
Note that $K$ denotes the number of boundary candidates proposed by the algorithm. We set $K=3$ in our study due to the maximum number of boundaries in our dataset being 3. 

\subsection{Boundary Detection Approaches}\label{sec:our approach}

To the best of our knowledge, there are no existing approaches for automatically detecting boundaries from hybrid text with an arbitrary number of sentences and boundaries. Inspired by \citet{perone2018evaluation,liu2020survey}, who pointed out that the quality of representations (embeddings) can significantly affect the performance of downstream tasks, we introduce the following two-step automatic boundary detection approach (also illustrated in Figure \ref{fig2}):

%The only relevant study was conducted by \citet{cutler2021automatic}, in which the evaluated approaches were restricted to single-boundary hybrid texts and required a fixed number of sentences across all hybrid texts\footnote{We did not include the approaches in \citet{cutler2021automatic} as baselines because they have not been peer-reviewed and cannot be applied to hybrid essays with an arbitrary number of sentences and boundaries.}.

%We considered that such approaches can not be adapted to general hybrid text in real-world scenarios and thus we did not include them as baseline methods.
%For example, they trained a classifier on the hybrid text dataset where each text contained exactly $10$ sentences and this classifier can only predict the boundary for the hybrid text with exactly $10$ sentences.

 

\begin{itemize}
    \item \textbf{TriBert (Our two-step approach)}: 
    \begin{enumerate}
        \item We first adopt the pre-trained sentence encoder implemented in the Python package SentenceTransformers\footnote{https://www.sbert.net/} as the initial encoder. We then fine-tune the initial encoder with the triplet BERT-networks \citep{Schroff_2015_CVPR} architecture, which is described as follows: for a sentence triplet $(a, x^+, x^-)$, where $a$ is the anchor sentence whose label is the same as that of sentence $x^+$, but different from the label of sentence $x^-$. The network (i.e., BERT encoder) is trained such that the distance between the embeddings of $a$ and $x^+$ ($d_1$ in step $1$ in Figure \ref{fig2}) is smaller than the distance between the embeddings of $a$ and $x^-$ ($d_2$ in step $1$ in Figure \ref{fig2}). Step 1 aims to separate AI-generated content from human-written content during the encoder training process.
        \item Let $S_i^{p-}$ be the averaged embeddings (also termed as prototype \citep{snell2017prototypical}) of sentence $s_i$ and its $(p-1)$ preceding sentences and $S_{i+1}^{p+}$ be the averaged embeddings of sentence $s_{i+1}$ and its $(p-1)$ following sentences. To identify the possible boundaries, we first calculate the (Euclidean) distances between every two adjacent prototypes $S_i^{p-}$ and $S_{i+1}^{p+}$, where $i\in\{1,2,...,k\}$ and hyperparameter $p$ denotes the number of sentences used to calculate the prototype, i.e., the prototype size. Note that $k+1$ is the number of sentences of the hybrid text. Then we assume that the boundaries exist between the two adjacent prototypes that have the furthest distance from each other. We searched the learning rate from $ \{ 1e-6, 5e-6, 1e-5\}$ and reported the results of prototype size $ p$ in $\{ 1, 2, 3, 4, 5, 6\}$.

    \end{enumerate}
    
\end{itemize}

% Figure environment removed
We describe all the other baseline boundary detection approaches as follows:

\begin{itemize}
    
    \item \textbf{BERT}: This method jointly fine-tunes the pre-trained BERT-base encoder and the final dense classification layer. Then the trained model is used to classify each sentence from the hybrid input text. Finally, $i$ is predicted as a boundary if sentence $s_i$ and sentence $s_{i+1}$ are of different predicted labels, e.g., if $s_i$ is predicted as human-written while $s_{i+1}$ is predicted as AI-generated, then this method assumes that $i$ is a possible boundary. This Bert-based classifier was adapted from the pre-trained Bert-based model implemented in the Transformers\footnote{https://github.com/huggingface/transformers} package.
    
    %For this method, we searched the learning rate from $ \{ 1e-6, 5e-6, 1e-5\}$.
    
    \item \textbf{LR}: This method directly employs the sentence encoder implemented in SentenceTransformers for generating sentence embeddings. Then, with the embeddings of each sentence from the hybrid text as input, this method trains a logistic regression binary classifier. Finally, we follow the same process as described in the \textit{BERT} approach to identify the possible boundaries.

    \item \textbf{GPTZero}: We opted for GPTZero due to its API accessibility and its ability to detect on a sentence-by-sentence basis within an input text. This feature facilitates its utilization as a foundational boundary detection benchmark. Specifically, it predicts a label (human-written or AI-generated) for each sentence of the hybrid text. Then, we followed the same process as described in the \textit{BERT} approach to identify the possible boundaries.
    
    \item \textbf{RANDOM}: This method randomly suggests a list of candidate boundaries, serving as a baseline showing the boundary detection performance using random guessing.
\end{itemize}


\section{Experiments}
We conducted both the in-domain evaluation (where models were trained and tested on the same prompts) and the out-of-domain evaluation (where training prompts had no overlap with the testing prompts).

\subsection{Training, Validating, and Testing}

\smallskip
\noindent\textbf{In-Domain Study.} For the hybrid essays of each prompt, we first grouped the hybrid essays by the source essays from eight prompts. Then we specified that 70\% groups of hybrid essays from each prompt were assigned to the training set. The remaining groups were equally assigned to validation and testing with ratios of 15\% and 15\%, respectively. The process of grouping by source essays was meant to ensure that the source essays for testing would not overlap with the source essays for training, avoiding the situation that essays $E_1$ and $E_2$ were generated from the same source essay $E$ but happened to be assigned to the training set and test set, respectively. Note that in this case, $E_1$ and $E_2$ could theoretically share some common human-written sentences, leading to testing data being exposed in the training stage. 

\smallskip
\noindent\textbf{Out-of-Domain Study.} We followed \citet{jin2018tdnn} to adopt the prompt-wise cross-validation for out-of-domain evaluation, i.e., eight-fold cross-validation in the case of our study because we had hybrid essays from eight different prompts. For each fold, we had the hybrid essays from the target prompt as testing data while hybrid essays from the remaining seven prompts were used for model training. Additionally, 30\% of the training data were held for validation.

\subsection{Parameters, Implementation, and Other Details.} For simplicity, we defined the completion of training $n$ samples (in our study we used $n=5000$) as one training epoch and we tested the models on the validation data after each training epoch. Note that the learning rate was reduced by $20\%$ after each epoch and early stopping was triggered at epoch $t$ (i.e., after epoch $t$ but before starting epoch $t+1$) if the model performance on epoch $t$ showed no improvement as compared to epoch $t-1$. Then, we used the best models (selected based on validation results) to predict on the testing data and reported the results using the F1 metric as described in Equation (\ref{eq:1}). All experiments were run on NVIDIA Tesla T4 GPU with 16 GB RAM.


\section{Results}

We presented the experiment results in Table \ref{table3}, based on which we structured the following analysis and findings.

\begin{table}[!htb]
 \caption{Results of different methods on the boundary detection task. The evaluation metric adopted here is \textbf{F1} score. Note that 'NT' in \textit{TriBert} (NT, $p=k$) is short for '\textbf{N}ot \textbf{T}rained', which means the encoder was used without fine-tuning. We use \#Bry to denote the number of boundaries. Each reported entry is a mean over \textbf{three} independent runs with the same hyperparameters. The best results are in \textbf{bold}.} \label{table3}
 \begin{center}

\resizebox{0.42\textwidth}{!}{

\begin{tabular}{l|c|c|c|c} 
\toprule
\multicolumn{5}{c}{\textbf{In-Domain}} \\ 
\midrule
\textbf{Method} & \#\textbf{Bry=1} & \#\textbf{Bry=2} & \#\textbf{Bry=3} & \textbf{All} \\ 
\midrule
\textbf{BERT} & 0.398 & 0.601 & 0.730 & 0.536 \\
\textbf{LR} & 0.265 & 0.377 & 0.404 & 0.332 \\ 
\midrule
\textbf{TriBERT} (p=1) & 0.430 & 0.646 & \textbf{0.752} & 0.571 \\
\textbf{TriBERT} (p=2) & 0.455 & \textbf{0.692} & 0.622 & \textbf{0.575} \\
\textbf{TriBERT} (p=3) & 0.477 & 0.672 & 0.565 & 0.566 \\
\textbf{TriBERT} (p=4) & \textbf{0.486} & 0.641 & 0.514 & 0.549 \\
\textbf{TriBERT} (p=5) & 0.480 & 0.586 & 0.487 & 0.519 \\
\textbf{TriBERT} (p=6) & 0.477 & 0.526 & 0.466 & 0.492 \\ 
\midrule
\multicolumn{5}{c}{\textbf{Out-of-Domain}} \\ 
\midrule
\textbf{Method} & \#\textbf{Bry=1} & \#\textbf{Bry=2} & \#\textbf{Bry=3} & \textbf{All} \\ 
\midrule
\textbf{BERT} & 0.369 & 0.545 & 0.632 & 0.486 \\
\textbf{LR} & 0.159 & 0.248 & 0.241 & 0.208 \\
\textbf{GPTZero} & 0.163 & 0.224 & 0.241 & 0.202 \\ 
\midrule
\textbf{TriBERT} (p=1) & 0.379 & 0.559 & \textbf{0.640} & 0.497 \\
\textbf{TriBERT} (p=2) & 0.417 & \textbf{0.597} & 0.545 & \textbf{0.510} \\
\textbf{TriBERT} (p=3) & 0.421 & 0.567 & 0.463 & 0.484 \\
\textbf{TriBERT} (p=4) & \textbf{0.436} & 0.551 & 0.428 & 0.477 \\
\textbf{TriBERT} (p=5) & 0.424 & 0.511 & 0.402 & 0.452 \\
\textbf{TriBERT} (p=6) & 0.419 & 0.487 & 0.395 & 0.439 \\ 
\midrule
\textbf{TriBERT} (NT,
 p=1) & 0.188 & 0.278 & 0.306 & 0.244 \\
\textbf{TriBERT} (NT,
 p=2) & 0.205 & 0.316 & 0.302 & 0.266 \\
\textbf{TriBERT} (NT,
 p=3) & 0.206 & 0.305 & 0.288 & 0.259 \\
\textbf{TriBERT} (NT,
 p=4) & 0.201 & 0.292 & 0.265 & 0.248 \\
\textbf{TriBERT} (NT,
 p=5) & 0.191 & 0.287 & 0.262 & 0.240 \\
\textbf{TriBERT} (NT,
 p=6) & 0.189 & 0.276 & 0.249 & 0.233 \\ 
\midrule
\textbf{RANDOM} & 0.130 & 0.204 & 0.209 & 0.173 \\
\bottomrule
\end{tabular}

}
 \end{center}
\end{table}




% \begin{table*}[!htb]
%  \caption{Results of different methods on the boundary detection task. The evaluation metric adopted here is \textbf{F1} score. Note that 'NT' in \textit{TriBert} (NT, $p=k$) is short for '\textbf{N}ot \textbf{T}rained', which means the encoder was directly used without fine-tuning. We use \#Bry to denote the number of boundaries. Each reported entry is a mean over \textbf{three} independent runs with the same hyperparameters. The best results are in \textbf{bold}.} \label{table3}
%  \begin{center}

% \resizebox{0.88\textwidth}{!}{

% \begin{tabular}{l|c|c|c|c|c|c|c|c|c|c} 
% \toprule
% Method & \multirow{16}{*}{In-Domain} & \#Bry=1 & \#Bry=2 & \#Bry=3 & All & \multirow{16}{*}{Out-of-Domain} & \#Bry=1 & \#Bry=2 & \#Bry=3 & All \\ 
% \cmidrule{1-1}\cmidrule{3-6}\cmidrule{8-11}
% BERT & & 0.398 & 0.601 & 0.730 & 0.536 & & 0.369 & 0.545 & 0.632 & 0.486 \\
% LR & & 0.265 & 0.377 & 0.404 & 0.332 & & 0.159 & 0.248 & 0.241 & 0.208 \\
% GPTZero & & --- & --- & --- & --- & & 0.163 & 0.224 & 0.241 & 0.202 \\
% \cmidrule{1-1}\cmidrule{3-6}\cmidrule{8-11}
% TriBert (p=1) & & 0.430 & 0.646 & \textbf{0.752} & 0.571 & & 0.379 & 0.559 & \textbf{0.640} & 0.497 \\
% TriBert (p=2) & & 0.455 & \textbf{0.692} & 0.622 & \textbf{0.575} & & 0.417 & \textbf{0.597} & 0.545 & \textbf{0.510} \\
% TriBert (p=3) & & 0.477 & 0.672 & 0.565 & 0.566 & & 0.421 & 0.567 & 0.463 & 0.484 \\
% TriBert (p=4) & & \textbf{0.486} & 0.641 & 0.514 & 0.549 & & \textbf{0.436} & 0.551 & 0.428 & 0.477 \\
% TriBert (p=5) & & 0.480 & 0.586 & 0.487 & 0.519 & & 0.424 & 0.511 & 0.402 & 0.452 \\
% TriBert (p=6) & & 0.477 & 0.526 & 0.466 & 0.492 & & 0.419 & 0.487 & 0.395 & 0.439 \\ 
% \cmidrule{1-1}\cmidrule{3-6}\cmidrule{8-11}
% TriBert (NT, p=1) & & --- & --- & --- & --- & & 0.188 & 0.278 & 0.306 & 0.244 \\
% TriBert (NT, p=2) & & --- & --- & --- & --- & & 0.205 & 0.316 & 0.302 & 0.266 \\
% TriBert (NT, p=3) & & --- & --- & --- & --- & & 0.206 & 0.305 & 0.288 & 0.259 \\
% TriBert (NT, p=4) & & --- & --- & --- & --- & & 0.201 & 0.292 & 0.265 & 0.248 \\
% TriBert (NT, p=5) & & --- & --- & --- & --- & & 0.191 & 0.287 & 0.262 & 0.240 \\
% TriBert (NT, p=6) & & --- & --- & --- & --- & & 0.189 & 0.276 & 0.249 & 0.233 \\
% %\cmidrule{1-1}\cmidrule{3-6}\cmidrule{8-11}

% \cmidrule{1-1}\cmidrule{3-6}\cmidrule{8-11}
% RANDOM & & --- & --- & --- & --- & & 0.130 & 0.204 & 0.209 & 0.173  \\
% \bottomrule
% \end{tabular}

% }
%  \end{center}
% \end{table*}

\smallskip
\noindent\textbf{In-Domain (ID) and Out-of-Domain (OOD) Detection. }
We observed that for \textit{LR}, \textit{BERT}, and \textit{TriBert} ($p=1,2,...$), the ID performance was generally higher than the OOD performance. This observation is not surprising because, in the ID setting, the domains of the test data had all been seen during the training while in the OOD setting, all test domains were unseen during the training stage. Note that for methods involving no training (or fine-tuning) process, i.e., \textit{RANDOM}, \textit{TriBert} (NT\footnote{We use 'NT' to denote 'Not Trained'.}, $p=1,2,..$) and \textit{GPTZero}, we only reported the OOD performance because all test domains were unseen for these methods.

\smallskip
\noindent\textbf{TriBERT v.s. Baseline Approaches. }
We noticed that \textit{LR} was of similar performance with \textit{GPTZero}, which was better than \textit{RANDOM}, but poorer when compared to \textit{BERT} and \textit{TriBERT} ($p=1,2,...$). Our explanation is that the shallow structure (only one output layer) of \textit{LR} and the limited number of learnable parameters (i.e., 768 parameters) hampered \textit{LR} from further learning complex concepts from the input sentences. Besides, \textit{TriBERT} ($p=1$) outperformed \textit{BERT} across all levels, i.e., the overall level (\textit{All}) and breakdown levels (\#Bry$=1,2,3$), which demonstrated the advantage of \textit{TriBERT}'s idea of calculating the dissimilarity (Euclidean distance) between every two adjacent prototypes and assuming that the boundaries exist between the most dissimilar (i.e., having the largest distance from each other) adjacent prototypes. 
%By contrast, Bert treated the sentences individually and simply performed binary classification over each sentence of the hybrid text, ignoring the information that can be obtained through comparing adjacent sentences.

\smallskip
\noindent\textbf{The Effect of Learning Embeddings through Separating AI-Content from Human-written Content. }
We observed that \textit{TriBERT} (NT, $p=1, 2, ...$), which went through no further encoder training and relied only on the pre-trained encoder from SentenceTransformers for sentence embedding, performed better than \textit{RANDOM}. However, we also noticed a significant performance improvement from the untrained \textit{TriBERT} (NT, $p=1, 2, ...$) to the fine-tuned \textit{TriBERT} ($p=1, 2, ...$), which demonstrated the necessity of fine-tuning the encoder through separating AI-Content from human-written content before applying the encoder for boundary detection.

\smallskip
\noindent\textbf{The Effect of Varying the Prototype Size of TriBERT. }
To better understand the role of prototype size $p$ in \textit{TriBERT}, we first introduce two effects that can enhance/degrade the prototype in \textit{TriBERT} when varying the prototype size $p$. Let us suppose that we have a set of $k$ consecutive sentences (sharing the same authorship) based on which the prototype will be calculated, denoted as $<s_{i}, s_{i+1},...,s_{i+k-1}>$. Then we would like to introduce a new adjacent sentence $s_{i+k}$ to this sentence pool, i.e., $p$ is growing from $k$ to $k+1$. Note that in this case, the introduction of the new adjacent sentence $s_{i+k}$ can either benefit the prototype (enhancing effect) or degrade the prototype (degrading effect):

\begin{itemize}
    \item \textbf{Enhancing Effect}: If the newly introduced adjacent sentence $s_{i+k}$ shares the same authorship with the existing sentences from the pool, the prototype is enhanced and can yield better representation, increasing \textit{TriBERT}'s performance.
    \item \textbf{Degrading Effect}: If the authorship of $s_{i+k}$ is different from that of the existing sentences, $s_{i+k}$ is considered as noise because the prototype calculated based on hybrid content can represent neither AI content nor human-written content, i.e., the quality of the prototype is degraded.
\end{itemize}  
From the results of the overall level (i.e., column \textit{All}), we observed that \textit{TriBERT} achieved the best performance with prototype size $p=2$, for which we have the following explanation: when $p<2$, the benefit of increasing $p$ outweighs the risk of bringing noise to the prototype calculation, i.e., the enhancing effect overcomes the degrading effect and plays the dominant role as $p$ grows; however, when $p>=2$, the degrading effect overcomes the enhancing effect and plays the dominant role as $p$ grows, which means \textit{TriBERT}'s performance declines as $p$ grows.

Furthermore, when we dived into the results of the breakdown level (The results of \#Bry $=1,2,3$), we noticed that the best prototype size $p$ tended to be large (or small) if the number of boundaries was small (or large), i.e., the best $p$ for \#Bry $=1,2,3$ were $4$, $2$, and $1$, respectively. Our explanation for this observation is as follows: when we try to sample a set of consecutive sentences $S_k$ (Note that the prototype will be calculated based on $S_k$) from a hybrid text $T$, the more boundaries there are within $T$, the more likely we are to find hybrid content from the selected sentences. For example, consider the hybrid essay $A=<H-H-H-G-G>$ (Here $H$ denotes a human-written sentence and $G$ denotes an AI-generated sentence) with one boundary ($b=1$) located between the third and the fourth sentence. Let $s_i$ and $s_{i+1}$ be two consecutive sentences randomly sampled from $A$ and the probability of $s_i$'s authorship being different from $s_{i+1}$'s is $1/4=25\%$. Similarly, this probability is $4/4=100\%$ for the hybrid essay $B=<H-G-H-G-H>$ sharing the same length with $A$ but with three more boundaries ($b=4$). As a result, \textit{TriBERT} has a higher chance to sample hybrid content (which triggers the degrading effect) for prototype calculation when predicting for hybrid text groups of \#Bry=$2,3$ compared to when predicting for the group with a small boundary number, i.e., \#Bry=$1$. It is also noteworthy that one could alleviate the degrading effect by using a smaller $p$. As can be seen, the best $p$ for the group of \#Bry=$2,3$ is $1$ and $2$, respectively. However, when predicting for the group with a small boundary number (the \#Bry=$1$ group), \textit{TriBERT} is more likely to sample sentences sharing consistent authorship (which triggers the enhancing effect) for prototype calculation, i.e., the prototype is calculated based on purely AI-content (or purely human-written content). In this case, a large prototype size $p$ is preferred for \textit{TriBERT} to improve the detecting performance. As we can see, the best $p$ for \#Bry=$1$ group is when $p=4$, i.e., the proposed \textit{TriBERT} with $p=4$ outperformed the best baseline \textit{BERT} by an improvement of $22$\% in the In-Domain setting and $18\%$ in the Out-of-Domain setting, respectively.




\section{Conclusion and Future Work}\label{sec:conclusion 5}

%However, the detection techniques for detecting AI content from hybrid text have rarely been explored, raising concerns among educators that students might leverage LLM to partially complete their writing assignments without being detected
% Human-AI collaborative writing is becoming more accessible with the assistance of modern LLM (e.g., ChatGPT). This technological advancement, along with the hybrid nature of the collaborative text, presents a new challenge to the AI content detection research community, as they need to develop methods to detect AI-generated content from hybrid texts that are collaboratively written by humans and LLM. 

% using LLMs to partially generate the written work which would result in hybrid text authored by both humans and LLMs. Such hybrid use case of LLM

% %Through extensive empirical experiments, we demonstrated that:

% %We argued that detecting AI content from such hybrid text calls for alternative detection approaches different from the binary classification-based ones \citep{jawahar2020automatic, clark2021all, mitchell2023detectgpt}.

% including a method based on fine-tuned Bert classifier and an online AI detector GPTZero;

%Given the widespread access of generative LLMs (e.g., GPT models), educators are facing unprecedented challenges of moderating the undesirable use of LLMs by students in completing written assessments. 

With the widespread access to generative LLMs (e.g., GPT models), educators are facing unprecedented challenges in moderating the undesirable use of LLMs by students when completing written assessments. Although many prior research efforts have been devoted to the automatic detection of machine-generated text \citep{jawahar2020automatic, clark2021all, mitchell2023detectgpt}, these studies have limited consideration about text data of hybrid nature (i.e., containing both human-written and AI-generated content). To add to the existing studies, we conducted a pioneer investigation into the problem of automatic boundary detection of human-AI hybrid texts in educational scenarios. Specifically, we proposed a two-step boundary detection approach (\textit{TriBERT}) to (1) separate AI-generated content from human-written content during the encoder training process; (2) calculate the (dis)similarity between adjacent prototypes and assume that the boundaries exist between the most dissimilar adjacent prototypes. Our empirical experiments demonstrated that: (1) \textit{TriBERT} outperformed other baseline methods, including a method based on fine-tuned Bert classifier and an online AI detector GPTZero; (2) we further noticed that for hybrid texts with fewer boundaries (e.g., one boundary), \textit{TriBERT} performed well with a large prototype size; When the number of boundaries is large or unclear, a small prototype size is preferred. The above findings can shed light on how to exploit \textit{TriBERT} for better detection performance, e.g., if the hybrid texts are known to be written first by students and then by generative language models (with only one boundary), it will be beneficial to start with a relatively large prototype size. Besides, given the significant advantage of \textit{TriBERT} over the commercial AI detector GPTZero in boundary detection, our \textit{TriBERT} can serve as a supplementary module for AI content detection systems, offering assistance to users who require precise identification of AI-generated content within hybrid text, enabling them to take subsequent actions such as modifying suspicious AI content to reduce its AI-generated appearance, or utilizing the detected text span as preliminary evidence of potential misuse of generative LLMs (or other AI tools). We acknowledge that our hybrid essay generation scheme (Section \ref{sec:data}) is not the only solution to generate hybrid text, e.g., a hybrid text could also be generated collaboratively by humans and generative LLMs through multi-turn interaction\citep{lee2022coauthor}. It is also noteworthy that, boundaries do not exist only BETWEEN sentences (but our study held to this assumption), e.g., a boundary can exist WITHIN a sentence that begins as human-written and ends with AI-generated content. As a starter for future work, we would like to investigate boundary detection from hybrid texts generated through multi-turn interaction by students and ChatGPT.

%%our proposed approach can be considered as an additional module of the AI content detection systems, which facilitates users whoever needs to accurately locate AI content from hybrid text for further actions, e.g., rewriting the suspicious AI content so that it is less like AI-generated, or as primitive evidence of cheating. 

%For future work, we would like to evaluate the performance of the proposed boundary detection approach to hybrid texts with more than $3$ boundaries. 
%%limitation that the number of boundaries in our hybrid text dataset is $1-3$. 
%Another direction for future work is to evaluate the proposed method on hybrid text from other domains, e.g., scientific text \citep{ma2023abstract}.

\bibliography{aaai24}

\end{document}
