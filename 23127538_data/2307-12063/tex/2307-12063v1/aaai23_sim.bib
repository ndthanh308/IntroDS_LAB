@article{eysenbach2019search,
  title={Search on the replay buffer: Bridging planning and reinforcement learning},
  author={Eysenbach, Ben and Salakhutdinov, Russ R and Levine, Sergey},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}
@inproceedings{savinov2018semi,
  title={Semi-parametric topological memory for navigation},
  author={Savinov, Nikolay and Dosovitskiy, Alexey and Koltun, Vladlen},
  booktitle={International Conference on Learning Representations},
  year={2018}
}
@inproceedings{haarnoja2018soft,
  title={Soft actor-critic: Off-policy maximum entropy deep reinforcement learning with a stochastic actor},
  author={Haarnoja, Tuomas and Zhou, Aurick and Abbeel, Pieter and others},
  booktitle={International Conference on Machine Learning},
  pages={1861--1870},
  year={2018},
  _organization={PMLR}
}
@inproceedings{li2020learning,
  title={Learning subgoal representations with slow dynamics},
  author={Li, Siyuan and Zheng, Lulu and Wang, Jianhao and others},
  booktitle={International Conference on Learning Representations},
  year={2020}
}
@article{kim2021landmark,
  title={Landmark-guided subgoal generation in hierarchical reinforcement learning},
  author={Kim, Junsu and Seo, Younggyo and Shin, Jinwoo},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={28336--28349},
  year={2021}
}
@inproceedings{chopra2005learning,
  title={Learning a similarity metric discriminatively, with application to face verification},
  author={Chopra, Sumit and others},
  booktitle={IEEE Computer Society Conference on Computer Vision and Pattern Recognition },
  _volume={1},
  pages={539--546},
  year={2005},
  _organization={IEEE}
}
@article{florensa2017stochastic,
  title={Stochastic neural networks for hierarchical reinforcement learning},
  author={Florensa, Carlos and others},
  journal={arXiv:1704.03012},
  year={2017}
}
@inproceedings{machado2020count,
  title={Count-based exploration with the successor representation},
  author={Machado, Marlos C and Bellemare, Marc G and Bowling, Michael},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={34},
  number={04},
  pages={5125--5133},
  year={2020}
}
@article{kulkarni2016deep,
  title={Deep successor reinforcement learning},
  author={Kulkarni, Tejas D and others},
  journal={arXiv:1606.02396},
  year={2016}
}
@article{barreto2017successor,
  title={Successor features for transfer in reinforcement learning},
  author={Barreto, Andr{\'e} and Dabney, Will and Munos, R{\'e}mi and Hunt, Jonathan J and Schaul, Tom and van Hasselt, Hado P and Silver, David},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}
@article{zhang2019scheduled,
  title={Scheduled intrinsic drive: A hierarchical take on intrinsically motivated exploration},
  author={Zhang, Jingwei and Wetzel, Niklas and Dorka, Nicolai and others},
  journal={ arXiv:1903.07400},
  year={2019}
}
@inproceedings{li2020focal,
  title={Focal: {E}fficient fully-offline meta-reinforcement learning via distance metric learning and behavior Regularization},
  author={Li, Lanqing and Yang, Rui and Luo, Dijun},
  booktitle={International Conference on Learning Representations},
  year={2020}
}
@article{dilokthanakul2019feature,
  title={Feature control as intrinsic motivation for hierarchical reinforcement learning},
  author={Dilokthanakul, Nat and Kaplanis, Christos and Pawlowski, Nick and others},
  journal={IEEE {T}ransactions on {N}eural {N}etworks and {L}earning {S}ystems},
  volume={30},
  number={11},
  pages={3409--3418},
  year={2019},
  publisher={IEEE}
}
@inproceedings{li2021active,
  title={Active hierarchical exploration with stable subgoal representation learning},
  author={Li, Siyuan and Zhang, Jin and Wang, Jianhao and others},
  booktitle={International Conference on Learning Representations},
  year={2021}
}
@article{tang2017exploration,
  title={\# exploration: A study of count-based exploration for deep reinforcement learning},
  author={Tang, Haoran and Houthooft, Rein and Foote, Davis and others},
  journal={Advances in {N}eural {I}nformation {P}rocessing {S}ystems},
  volume={30},
  year={2017}
}
@article{lawrance1977exponential,
  title={An exponential moving-average sequence and point process (EMA1)},
  author={Lawrance, AJ and Lewis, PAW},
  journal={Journal of Applied Probability},
  volume={14},
  number={1},
  pages={98--113},
  year={1977},
  publisher={Cambridge University Press}
}
@inproceedings{levy2019learning,
  title={Learning multi-level hierarchies with hindsight},
  author={Levy, Andrew and Konidaris, George and Platt, Robert and others},
  booktitle={International Conference on Learning Representations},
  year={2019}
}
@inproceedings{martin2017count,
  title={Count-based exploration in feature space for reinforcement learning},
  author={Martin, Jarryd and Narayanan, S Suraj and Everitt, Tom and Hutter, Marcus},
  booktitle={Proceedings of the 26th International Joint Conference on Artificial Intelligence},
  pages={2471--2478},
  year={2017}
}
@inproceedings{vassilvitskii2006k,
  title={k-means++: The advantages of careful seeding},
  author={Vassilvitskii, Sergei and Arthur, David},
  booktitle={Proceedings of the Eighteenth Annual ACM-SIAM Symposium on Discrete Algorithms},
  pages={1027--1035},
  year={2006}
}
@article{devlin2018bert,
  title={Bert: Pre-training of deep bidirectional transformers for language understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  journal={arXiv preprint arXiv:1810.04805},
  year={2018}
}
@article{radford2018improving,
  title={Improving language understanding by generative pre-training},
  author={Radford, Alec and Narasimhan, Karthik and Salimans, Tim and Sutskever, Ilya and others},
  year={2018},
  publisher={OpenAI}
}
@inproceedings{he2020momentum,
  title={Momentum contrast for unsupervised visual representation learning},
  author={He, Kaiming and Fan, Haoqi and Wu, Yuxin and Xie, Saining and Girshick, Ross},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={9729--9738},
  year={2020}
}
@inproceedings{chen2020simple,
  title={A simple framework for contrastive learning of visual representations},
  author={Chen, Ting and Kornblith, Simon and Norouzi, Mohammad and Hinton, Geoffrey},
  booktitle={International conference on machine learning},
  pages={1597--1607},
  year={2020},
  organization={PMLR}
}
@article{linsker1988self,
  title={Self-organization in a perceptual network},
  author={Linsker, Ralph},
  journal={Computer},
  _volume={21},
  _number={3},
  pages={105--117},
  year={1988},
  publisher={IEEE}
}
@article{oord2018representation,
  title={Representation learning with contrastive predictive coding},
  author={Oord, Aaron van den and others},
  journal={arXiv preprint arXiv:1807.03748},
  year={2018}
}

@inproceedings{he2020momentum,
  title={Momentum contrast for unsupervised visual representation learning},
  author={He, Kaiming and Fan, Haoqi and Wu, Yuxin and Xie, Saining and Girshick, Ross},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={9729--9738},
  year={2020}
}

@article{shang2019learning,
  title={Learning world graphs to accelerate hierarchical reinforcement learning},
  author={Shang, Wenling and Trott, Alex and Zheng, Stephan and Xiong, Caiming and Socher, Richard},
  journal={arXiv:1907.00664},
  year={2019}
}

@article{emmons2020sparse,
  title={Sparse graphical memory for robust planning},
  author={Emmons, Scott and Jain, Ajay and Laskin, Misha and others},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={5251--5262},
  year={2020}
}
@article{nasiriany2019planning,
  title={Planning with goal-conditioned policies},
  author={Nasiriany, Soroush and Pong, Vitchyr and Lin, Steven and Levine, Sergey},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}
@inproceedings{agarwal2019model,
  title={Model learning for look-ahead exploration in continuous control},
  author={Agarwal, Arpit and Muelling, Katharina and Fragkiadaki, Katerina},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={33},
  number={01},
  pages={3151--3158},
  year={2019}
}

@article{ha2018world,
  title={World models},
  author={Ha, David and Schmidhuber, J{\"u}rgen},
  journal={arXiv:1803.10122},
  year={2018}
}
@article{ghosh2018learning,
  title={Learning actionable representations with goal-conditioned policies},
  author={Ghosh, Dibya and Gupta, Abhishek and Levine, Sergey},
  journal={arXiv preprint arXiv:1811.07819},
  year={2018}
}
@article{ecoffet2019go,
  title={Go-explore: a new approach for hard-exploration problems},
  author={Ecoffet, Adrien and Huizinga, Joost and Lehman, Joel and Stanley, Kenneth O and Clune, Jeff},
  journal={arXiv preprint arXiv:1901.10995},
  year={2019}
}
@article{huang2019mapping,
  title={Mapping state space using landmarks for universal goal reaching},
  author={Huang, Zhiao and Liu, Fangchen and Su, Hao},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}
@article{yamamoto2018hierarchical,
  title={Hierarchical reinforcement learning with abductive planning},
  author={Yamamoto, Kazeto and Onishi, Takashi and Tsuruoka, Yoshimasa},
  journal={arXiv preprint arXiv:1806.10792},
  year={2018}
}
@article{klissarov2020reward,
  title={Reward propagation using graph convolutional networks},
  author={Klissarov, Martin and Precup, Doina},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={12895--12908},
  year={2020}
}
@article{jin2021graph,
  title={Graph-enhanced exploration for goal-oriented reinforcement learning},
  author={Jin, Jiarui and Zhou, Sijin and Zhang, Weinan and He, Tong and Yu, Yong and Fakoor, Rasool},
  year={2021}
}
@article{kotsiantis2006discretization,
  title={Discretization techniques: A recent survey},
  author={Kotsiantis, Sotiris and Kanellopoulos, Dimitris},
  journal={GESTS International Transactions on Computer Science and Engineering},
  volume={32},
  number={1},
  pages={47--58},
  year={2006},
  publisher={Citeseer}
}

@inproceedings{gupta2020relay,
  title={Relay policy learning: {S}olving long-horizon tasks via imitation and reinforcement learning},
  author={Gupta, Abhishek and Kumar, Vikash and Lynch, Corey and Levine, Sergey and Hausman, Karol},
  booktitle={Conference on Robot Learning},
  pages={1025--1037},
  year={2020},
  _organization={PMLR}
}
@article{li2022hierarchical,
  title={Hierarchical planning through goal-conditioned offline reinforcement learning},
  author={Li, Jinning and Tang, Chen and Tomizuka, Masayoshi and others},
  journal={arXiv:2205.11790},
  year={2022}
}
@article{zhang2020generating,
  title={Generating adjacency-constrained subgoals in hierarchical reinforcement learning},
  author={Zhang, Tianren and Guo, Shangqi and Tan, Tian and others},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={21579--21590},
  year={2020}
}
@article{oord2018representation,
  title={Representation learning with contrastive predictive coding},
  author={Oord, Aaron van den and Li, Yazhe and Vinyals, Oriol},
  journal={arXiv preprint arXiv:1807.03748},
  year={2018}
}
@article{wiskott2002slow,
  title={Slow feature analysis: Unsupervised learning of invariances},
  author={Wiskott, Laurenz and Sejnowski, Terrence J},
  journal={Neural computation},
  volume={14},
  number={4},
  pages={715--770},
  year={2002},
  publisher={MIT Press}
}
@inproceedings{todorov2012mujoco,
  title={Mujoco: A physics engine for model-based control},
  author={Todorov, Emanuel and Erez, Tom and Tassa, Yuval},
  booktitle={IEEE/RSJ International Conference on Intelligent Robots and Systems},
  pages={5026--5033},
  year={2012},
  _organization={IEEE}
}
@article{kulkarni2016hierarchical,
  title={Hierarchical deep reinforcement learning: Integrating temporal abstraction and intrinsic motivation},
  author={Kulkarni, Tejas D and Narasimhan, Karthik and Saeedi, Ardavan and others},
  journal={Advances in neural information processing systems},
  volume={29},
  year={2016}
}
@inproceedings{vezhnevets2017feudal,
  title={Feudal networks for hierarchical reinforcement learning},
  author={Vezhnevets, Alexander Sasha and Osindero, Simon and Schaul, Tom and others},
  booktitle={International {C}onference on {M}achine {L}earning},
  pages={3540--3549},
  year={2017},
  _organization={PMLR}
}
@article{nachum2018data,
  title={Data-efficient hierarchical reinforcement learning},
  author={Nachum, Ofir and Gu, Shixiang Shane and Lee, Honglak and others},
  journal={Advances in {N}eural {I}nformation {P}rocessing {S}ystems},
  volume={31},
  year={2018}
}
@inproceedings{zhang2021world,
  title={World model as a graph: Learning latent landmarks for planning},
  author={Zhang, Lunjun and Yang, Ge and Stadie, Bradly C},
  booktitle={International Conference on Machine Learning},
  pages={12611--12620},
  year={2021},
}
@article{wang2008robot,
  title={Robot navigation by waypoints},
  author={Wang, Yang and Mulvaney, David and Sillitoe, Ian and Swere, Erick},
  journal={Journal of Intelligent and Robotic Systems},
  volume={52},
  pages={175--207},
  year={2008},
  publisher={Springer}
}
@article{pere2018unsupervised,
  title={Unsupervised learning of goal spaces for intrinsically motivated goal exploration},
  author={P{\'e}r{\'e}, Alexandre and Forestier, S{\'e}bastien and Sigaud, Olivier and others},
  journal={arXiv preprint arXiv:1803.00781},
  year={2018}
}
@article{andrychowicz2017hindsight,
  title={Hindsight experience replay},
  author={Andrychowicz, Marcin and Wolski, Filip and Ray, Alex and others},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}
@inproceedings{charikar2002similarity,
  title={Similarity estimation techniques from rounding algorithms},
  author={Charikar, Moses S},
  booktitle={Proceedings of the {T}hiry-fourth {A}nnual ACM {S}ymposium on Theory of {C}omputing},
  pages={380--388},
  year={2002}
}
@article{bellemare2016unifying,
  title={Unifying count-based exploration and intrinsic motivation},
  author={Bellemare, Marc and Srinivasan, Sriram and Ostrovski, Georg and Schaul, Tom and Saxton, David and Munos, Remi},
  journal={Advances in {N}eural {I}nformation {P}rocessing {S}ystems},
  volume={29},
  year={2016}
}
@inproceedings{schaul2015universal,
  title={Universal value function approximators},
  author={Schaul, Tom and Horgan, Daniel and Gregor, Karol and others},
  booktitle={International Conference on Machine Learning},
  pages={1312--1320},
  year={2015},
  _organization={PMLR}
}
@article{mcquillan1977arpa,
  title={The ARPA network design decisions},
  author={McQuillan, John M and Walden, David C},
  journal={Computer Networks},
  volume={1},
  number={5},
  pages={243--289},
  year={1977},
  publisher={Elsevier}
}
@article{hussein2017imitation,
  title={Imitation learning: A survey of learning methods},
  author={Hussein, Ahmed and others},
  journal={ACM Computing Surveys (CSUR)},
  volume={50},
  number={2},
  pages={1--35},
  year={2017},
  publisher={ACM New York, NY, USA}
}
@inproceedings{schroff2015facenet,
  title={Facenet: A unified embedding for face recognition and clustering},
  author={Schroff, Florian and Kalenichenko, Dmitry and Philbin, James},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={815--823},
  year={2015}
}
@article{barto2003recent,
  title={Recent advances in hierarchical reinforcement learning},
  author={Barto, Andrew G and Mahadevan, Sridhar},
  journal={Discrete event dynamic systems},
  volume={13},
  number={1},
  pages={41--77},
  year={2003},
  publisher={Springer}
}
@article{nair2019hierarchical,
  title={Hierarchical foresight: Self-supervised learning of long-horizon tasks via visual subgoal generation},
  author={Nair, Suraj and Finn, Chelsea},
  journal={arXiv preprint arXiv:1909.05829},
  year={2019}
}
@article{nachum2019does,
  title={Why does hierarchy (sometimes) work so well in reinforcement learning?},
  author={Nachum, Ofir and Tang, Haoran and Lu, Xingyu and others},
  journal={arXiv:1909.10618},
  year={2019}
}
@article{kingma2013auto,
  title={Auto-encoding variational bayes},
  author={Kingma, Diederik P and Welling, Max},
  journal={arXiv preprint arXiv:1312.6114},
  year={2013}
}
@article{sukhbaatar2018learning,
  title={Learning goal embeddings via self-play for hierarchical reinforcement learning},
  author={Sukhbaatar, Sainbayar and Denton, Emily and Szlam, Arthur and Fergus, Rob},
  journal={arXiv preprint arXiv:1811.09083},
  year={2018}
}
@inproceedings{roder2020curious,
  title={Curious hierarchical actor-critic reinforcement learning},
  author={R{\"o}der, Frank and Eppe, Manfred and Nguyen, Phuong DH and others},
  booktitle={International Conference on Artificial Neural Networks},
  pages={408--419},
  year={2020},
  _organization={Springer}
}
@article{dwiel2019hierarchical,
  title={Hierarchical policy learning is sensitive to goal space design},
  author={Dwiel, Zach and Candadai, Madhavun and Phielipp, Mariano and Bansal, Arjun K},
  journal={arXiv:1905.01537},
  year={2019}
}
@article{dayan1992feudal,
  title={Feudal reinforcement learning},
  author={Dayan, Peter and Hinton, Geoffrey E},
  journal={Advances in {N}eural {I}nformation {P}rocessing {S}ystems},
  volume={5},
  year={1992}
}
@article{sutton1999between,
  title={Between MDPs and semi-MDPs: A framework for temporal abstraction in reinforcement learning},
  author={Sutton, Richard S and Precup, Doina and Singh, Satinder},
  journal={Artificial intelligence},
  volume={112},
  number={1-2},
  pages={181--211},
  year={1999},
  publisher={Elsevier}
}
@article{nachum2018near,
  title={Near-optimal representation learning for hierarchical reinforcement learning},
  author={Nachum, Ofir and Gu, Shixiang and Lee, Honglak and Levine, Sergey},
  journal={arXiv:1810.01257},
  year={2018}
}
@article{zahavy2018learn,
  title={Learn what not to learn: Action elimination with deep reinforcement learning},
  author={Zahavy, Tom and Haroush, Matan and Merlis, Nadav and Mankowitz, Daniel J and Mannor, Shie},
  journal={Advances in neural information processing systems},
  volume={31},
  year={2018}
}
@inproceedings{khetarpal2020can,
  title={What can I do here? A Theory of Affordances in Reinforcement Learning},
  author={Khetarpal, Khimya and Ahmed, Zafarali and Comanici, Gheorghe and Abel, David and Precup, Doina},
  booktitle={International Conference on Machine Learning},
  pages={5243--5253},
  year={2020},
  organization={PMLR}
}
@article{wen2020efficiency,
  title={On efficiency in hierarchical reinforcement learning},
  author={Wen, Zheng and Precup, Doina and Ibrahimi, Morteza and Barreto, Andre and Van Roy, Benjamin and Singh, Satinder},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={6708--6718},
  year={2020}
}
@book{puterman2014markov,
  title={Markov decision processes: {D}iscrete stochastic dynamic programming},
  author={Puterman, Martin L},
  year={2014},
  publisher={John Wiley \& Sons}
}