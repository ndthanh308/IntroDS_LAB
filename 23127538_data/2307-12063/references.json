{
  "2205-11790": {
    "title": "Hierarchical Planning Through Goal-Conditioned Offline Reinforcement Learning",
    "authors": [
      "Jinning Li",
      "Chen Tang",
      "M. Tomizuka",
      "Wei Zhan"
    ],
    "submission_date": "2022-05-24",
    "semantic_scholar_id": "f593dc96b20ce8427182e773e3b2192d707706a8"
  },
  "2105-14750": {
    "title": "Active Hierarchical Exploration with Stable Subgoal Representation Learning",
    "authors": [
      "Siyuan Li",
      "Jin Zhang",
      "Jianhao Wang",
      "Yang Yu",
      "Chongjie Zhang"
    ],
    "submission_date": "2021-05-31",
    "semantic_scholar_id": "3a56dc25b3cba2cb438be8b5b95f4ff63f8c02ff"
  },
  "2011-12491": {
    "title": "World Model as a Graph: Learning Latent Landmarks for Planning",
    "authors": [
      "Lunjun Zhang",
      "Ge Yang",
      "Bradly C. Stadie"
    ],
    "submission_date": "2020-11-25",
    "semantic_scholar_id": "5cf549e26b4dce19d5bc783de83047479ce6218a"
  },
  "2006-11485": {
    "title": "Generating Adjacency-Constrained Subgoals in Hierarchical Reinforcement Learning",
    "authors": [
      "Tianren Zhang",
      "Shangqi Guo",
      "Tian Tan",
      "Xiaolin Hu",
      "Feng Chen"
    ],
    "submission_date": "2020-06-20",
    "semantic_scholar_id": "361ccae6cb40343c8824c9d64104ff8261a7c089"
  },
  "2005-03420": {
    "title": "Curious Hierarchical Actor-Critic Reinforcement Learning",
    "authors": [
      "Frank Röder",
      "Manfred Eppe",
      "Phuong D. H. Nguyen",
      "Stefan Wermter"
    ],
    "submission_date": "2020-05-07",
    "semantic_scholar_id": "94d02cb4a0901f4f336ffa939f6b9991f287948c"
  },
  "2003-06417": {
    "title": "Sparse Graphical Memory for Robust Planning",
    "authors": [
      "M. Laskin",
      "Scott Emmons",
      "Ajay Jain",
      "Thanard Kurutach",
      "P. Abbeel",
      "Deepak Pathak"
    ],
    "submission_date": "2020-03-13",
    "semantic_scholar_id": "c50b9bf34bdd4b564712e29213056bb7955ff7f7"
  },
  "1909-10618": {
    "title": "Why Does Hierarchy (Sometimes) Work So Well in Reinforcement Learning?",
    "authors": [
      "Ofir Nachum",
      "Haoran Tang",
      "Xingyu Lu",
      "S. Gu",
      "Honglak Lee",
      "S. Levine"
    ],
    "submission_date": "2019-09-23",
    "semantic_scholar_id": "35257ba97d193f23f15e71a633a34e94dd3f5777"
  },
  "1909-05829": {
    "title": "Hierarchical Foresight: Self-Supervised Learning of Long-Horizon Tasks via Visual Subgoal Generation",
    "authors": [
      "Suraj Nair",
      "Chelsea Finn"
    ],
    "submission_date": "2019-09-12",
    "semantic_scholar_id": "4d40f7df809576d4db22b95c4ca9cc4c66e6928d"
  },
  "1907-00664": {
    "title": "Learning World Graphs to Accelerate Hierarchical Reinforcement Learning",
    "authors": [
      "Wenling Shang",
      "Alexander R. Trott",
      "Stephan Zheng",
      "Caiming Xiong",
      "R. Socher"
    ],
    "submission_date": "2019-07-01",
    "semantic_scholar_id": "66605b6ceae9847156526e46ca9fe467804fca54"
  },
  "1906-05253": {
    "title": "Search on the Replay Buffer: Bridging Planning and Reinforcement Learning",
    "authors": [
      "Benjamin Eysenbach",
      "R. Salakhutdinov",
      "S. Levine"
    ],
    "submission_date": "2019-06-12",
    "semantic_scholar_id": "e0889fcee1acd985af76a3907d5d0029bf260be9"
  },
  "1903-07400": {
    "title": "Scheduled Intrinsic Drive: A Hierarchical Take on Intrinsically Motivated Exploration",
    "authors": [
      "Jingwei Zhang",
      "Niklas Wetzel",
      "Nicolai Dorka",
      "Joschka Boedecker",
      "Wolfram Burgard"
    ],
    "submission_date": "2019-03-18",
    "semantic_scholar_id": "048459fcf6befce76d277a31ead3f58e1b2de32d"
  },
  "1811-07819": {
    "title": "Learning Actionable Representations with Goal-Conditioned Policies",
    "authors": [
      "Dibya Ghosh",
      "Abhishek Gupta",
      "S. Levine"
    ],
    "submission_date": "2018-09-27",
    "semantic_scholar_id": "c46d80f83813fba0e8363a0ab36a19fba062540e"
  },
  "1807-11622": {
    "title": "Count-Based Exploration with the Successor Representation",
    "authors": [
      "Marlos C. Machado",
      "Marc G. Bellemare",
      "Michael H. Bowling"
    ],
    "submission_date": "2018-07-31",
    "semantic_scholar_id": "9f67b3edc67a35c884bd532a5e73fa3a7f3660d8"
  },
  "1806-10792": {
    "title": "Hierarchical Reinforcement Learning with Abductive Planning",
    "authors": [
      "Kazeto Yamamoto",
      "Takashi Onishi",
      "Yoshimasa Tsuruoka"
    ],
    "submission_date": "2018-06-28",
    "semantic_scholar_id": "9a34153662c4053ed2ba6fe9e11f2628749c7b18"
  },
  "1805-08296": {
    "title": "Data-Efficient Hierarchical Reinforcement Learning",
    "authors": [
      "Ofir Nachum",
      "S. Gu",
      "Honglak Lee",
      "S. Levine"
    ],
    "submission_date": "2018-05-21",
    "semantic_scholar_id": "39b7007e6f3dd0744833f292f07ed77973503bfd"
  },
  "1803-00781": {
    "title": "Unsupervised Learning of Goal Spaces for Intrinsically Motivated Goal Exploration",
    "authors": [
      "Alexandre Péré",
      "Sébastien Forestier",
      "Olivier Sigaud",
      "Pierre-Yves Oudeyer"
    ],
    "submission_date": "2018-02-15",
    "semantic_scholar_id": "330d56c3641cddd8c78440e768cd80795f23cab4"
  },
  "1801-01290": {
    "title": "Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor",
    "authors": [
      "Tuomas Haarnoja",
      "Aurick Zhou",
      "P. Abbeel",
      "S. Levine"
    ],
    "submission_date": "2018-01-04",
    "semantic_scholar_id": "811df72e210e20de99719539505da54762a11c6d"
  },
  "1707-01495": {
    "title": "Hindsight Experience Replay",
    "authors": [
      "Marcin Andrychowicz",
      "Dwight Crow",
      "Alex Ray",
      "Jonas Schneider",
      "Rachel Fong",
      "Peter Welinder",
      "Bob McGrew",
      "Joshua Tobin",
      "P. Abbeel",
      "Wojciech Zaremba"
    ],
    "submission_date": "2017-07-05",
    "semantic_scholar_id": "429ed4c9845d0abd1f8204e1d7705919559bc2a2"
  },
  "1705-06769": {
    "title": "Feature Control as Intrinsic Motivation for Hierarchical Reinforcement Learning",
    "authors": [
      "Nat Dilokthanakul",
      "Christos Kaplanis",
      "Nick Pawlowski",
      "M. Shanahan"
    ],
    "submission_date": "2017-05-18",
    "semantic_scholar_id": "9d528f7e641c922bddd83f4af687806d685490d6"
  },
  "1703-01161": {
    "title": "FeUdal Networks for Hierarchical Reinforcement Learning",
    "authors": [
      "A. Vezhnevets",
      "Simon Osindero",
      "T. Schaul",
      "N. Heess",
      "Max Jaderberg",
      "David Silver",
      "K. Kavukcuoglu"
    ],
    "submission_date": "2017-03-03",
    "semantic_scholar_id": "049c6e5736313374c6e594c34b9be89a3a09dced"
  },
  "1611-04717": {
    "title": "#Exploration: A Study of Count-Based Exploration for Deep Reinforcement Learning",
    "authors": [
      "Haoran Tang",
      "Rein Houthooft",
      "Davis Foote",
      "Adam Stooke",
      "Xi Chen",
      "Yan Duan",
      "John Schulman",
      "F. Turck",
      "P. Abbeel"
    ],
    "submission_date": "2016-11-15",
    "semantic_scholar_id": "0fcb2034e31a2bc2f12a2b1363d0d77baf445fdf"
  },
  "1604-06057": {
    "title": "Hierarchical Deep Reinforcement Learning: Integrating Temporal Abstraction and Intrinsic Motivation",
    "authors": [
      "Tejas D. Kulkarni",
      "Karthik Narasimhan",
      "A. Saeedi",
      "J. Tenenbaum"
    ],
    "submission_date": "2016-04-20",
    "semantic_scholar_id": "d37620e6f8fe678a43e12930743281cd8cca6a66"
  }
}