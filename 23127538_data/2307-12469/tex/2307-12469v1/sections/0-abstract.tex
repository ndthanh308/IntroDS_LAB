Fuzz drivers are a necessary component of API fuzzing.
However, automatically generating correct and robust fuzz drivers is a difficult task.
Compared to existing approaches, LLM-based (Large Language Model) generation is a promising direction due to its ability to operate with low requirements on consumer programs, leverage multiple dimensions of API usage information, and generate human-friendly output code.
Nonetheless, the challenges and effectiveness of LLM-based fuzz driver generation remain unclear.

To address this, we conducted a study on the effects, challenges, and techniques of LLM-based fuzz driver generation.
Our study involved building a quiz with 86 fuzz driver generation questions from 30 popular C projects, constructing precise effectiveness validation criteria for each question, and developing a framework for semi-automated evaluation.
We designed five query strategies, evaluated 36,506 generated fuzz drivers.
Furthermore, the drivers were compared with manually written ones to obtain practical insights.
Our evaluation revealed that:
\ding{182} while the overall performance was promising (passing 91\% of questions), there were still practical challenges in filtering out the ineffective fuzz drivers for large scale application;
\ding{183} basic strategies achieved a decent correctness rate (53\%), but struggled with complex API-specific usage questions.
In such cases, example code snippets and iterative queries proved helpful;
\ding{184} while LLM-generated drivers showed competent fuzzing outcomes compared to manually written ones, there was still significant room for improvement, such as incorporating semantic oracles for logical bugs detection.

% Fuzzing are de-facto standard for finding zero-day vulnerabilities.
% Fuzz drivers are necessary for fuzzing the API targets.
% For fuzzing API targets which are not directly executable, fuzz drivers have to be introduced.
% They act as bridges which first accept the mutated input from fuzzer and then executes the target APIs accordingly.
% Fuzz drivers are necessary for fuzzing API targets.
% Automatic fuzz driver generation is hard due to the high requirements on driver's correctness and robustness.
% Comparing with existing fuzz driver generation approaches, LLM-based (Large Language Model) generation is a promising direction since it has low requirements on consumer programs, native support for utilizing multiple dimensions of API usage information, and human-friendly output code.
% However, there still lacks an understanding on the challenges and effects for LLM-based fuzz driver generation.

% In this work, we studied the effects, challenges, and techniques of LLM-based fuzz driver generation.
% We first built a quiz containing 86 fuzz driver questions and their effectiveness validation criteria from 30 popular C projects.
% Then a framework was developed to maximize the automation of evaluation.
% Five query strategies are designed and their generated xxx fuzz drivers are studied.
% Besides, the generated fuzz drivers are compared with manually written drivers to obtain practical implications.
% Our evaluation reveals that:
% \ding{182} though the overall performance is quite promising (pass xx\% questions), its practical application still faces challenges such as how to precisely filter out ineffective fuzz drivers;
% \ding{183} while basic strategies can already achieve a decent correct rate (xx\%), it cannot solve the questions require a complex API specific usage.
% Adding example snippets and query iteratively can help in this scenario;
% \ding{184} LLM-generated drivers can show competent fuzzing outcomes comparing with manually-written ones.
% However, it still has large improvement space such as adding semantic oracles.

% the precise effectiveness validation standard is the major concern for its practical application;
% \ding{183} carefully designed basic strategies which only use fundamental information and non-iterative conversation can reach good results (xx\%), while the enhanced ones 
% based on fundamental information and non-iterative conversations can reach xx\% results while adding example snippets and iterative queries can solve more;
% \ding{184} LLM-generated drivers can reach comparable fuzzing outcomes as manually written ones 

% different query strategies show their unique pros and cons.

% the basic challenges of LLM-based generation are the API-specific semantic constraints and indirectly dependent usages;
% \ding{183} combining all strategies, current LLMs can provide effective fuzz drivers for xx\% questions, showing certain practicality;
% \ding{184} LLM-generated drivers are complement with manually-written drivers. besides, it can still be improved in oracles, usage extending, etc.
