\begin{thebibliography}{10}\itemsep=-1pt

\bibitem{alsentzer2019publicly}
Emily Alsentzer, John~R Murphy, Willie Boag, Wei-Hung Weng, Di Jin, Tristan
  Naumann, and Matthew McDermott.
\newblock Publicly available clinical bert embeddings.
\newblock {\em arXiv preprint arXiv:1904.03323}, 2019.

\bibitem{carion2020end}
Nicolas Carion, Francisco Massa, Gabriel Synnaeve, Nicolas Usunier, Alexander
  Kirillov, and Sergey Zagoruyko.
\newblock End-to-end object detection with transformers.
\newblock In {\em European conference on computer vision}, pages 213--229.
  Springer, 2020.

\bibitem{chen2019self}
Liang Chen, Paul Bentley, Kensaku Mori, Kazunari Misawa, Michitaka Fujiwara,
  and Daniel Rueckert.
\newblock Self-supervised learning for medical image analysis using image
  context restoration.
\newblock {\em Medical image analysis}, 58:101539, 2019.

\bibitem{chen2020simple}
Ting Chen, Simon Kornblith, Mohammad Norouzi, and Geoffrey Hinton.
\newblock A simple framework for contrastive learning of visual
  representations.
\newblock In {\em International conference on machine learning}, pages
  1597--1607. PMLR, 2020.

\bibitem{chen2020improved}
Xinlei Chen, Haoqi Fan, Ross Girshick, and Kaiming He.
\newblock Improved baselines with momentum contrastive learning.
\newblock {\em arXiv preprint arXiv:2003.04297}, 2020.

\bibitem{chen2021exploring}
Xinlei Chen and Kaiming He.
\newblock Exploring simple siamese representation learning.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 15750--15758, 2021.

\bibitem{chen2021empirical}
Xinlei Chen, Saining Xie, and Kaiming He.
\newblock An empirical study of training self-supervised vision transformers.
\newblock In {\em Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pages 9640--9649, 2021.

\bibitem{chen2019weakly}
Zhenfang Chen, Lin Ma, Wenhan Luo, and Kwan-Yee~Kenneth Wong.
\newblock Weakly-supervised spatio-temporally grounding natural sentence in
  video.
\newblock In {\em Proceedings of the 57th Annual Meeting of the Association for
  Computational Linguistics}, pages 1884--1894, Florence, Italy, July 2019.
  Association for Computational Linguistics.

\bibitem{deng2009imagenet}
Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei.
\newblock Imagenet: A large-scale hierarchical image database.
\newblock In {\em 2009 IEEE conference on computer vision and pattern
  recognition}, pages 248--255. Ieee, 2009.

\bibitem{dosovitskiy2020image}
Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn,
  Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg
  Heigold, Sylvain Gelly, et~al.
\newblock An image is worth 16x16 words: Transformers for image recognition at
  scale.
\newblock {\em arXiv preprint arXiv:2010.11929}, 2020.

\bibitem{falcon2019pytorch}
William {Falcon et al.}
\newblock Pytorch lightning.
\newblock {\em GitHub. Note:
  https://github.com/PyTorchLightning/pytorch-lightning}, 3, 2019.

\bibitem{fang2022transferring}
Han Fang, Pengfei Xiong, Luhui Xu, and Wenhan Luo.
\newblock Transferring image-clip to video-text retrieval via temporal
  relations.
\newblock {\em IEEE Transactions on Multimedia}, 2022.

\bibitem{grill2020bootstrap}
Jean-Bastien Grill, Florian Strub, Florent Altch{\'e}, Corentin Tallec, Pierre
  Richemond, Elena Buchatskaya, Carl Doersch, Bernardo Avila~Pires, Zhaohan
  Guo, Mohammad Gheshlaghi~Azar, et~al.
\newblock Bootstrap your own latent-a new approach to self-supervised learning.
\newblock {\em Advances in neural information processing systems},
  33:21271--21284, 2020.

\bibitem{he2022masked}
Kaiming He, Xinlei Chen, Saining Xie, Yanghao Li, Piotr Doll{\'a}r, and Ross
  Girshick.
\newblock Masked autoencoders are scalable vision learners.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 16000--16009, 2022.

\bibitem{he2020momentum}
Kaiming He, Haoqi Fan, Yuxin Wu, Saining Xie, and Ross Girshick.
\newblock Momentum contrast for unsupervised visual representation learning.
\newblock In {\em Proceedings of the IEEE/CVF conference on computer vision and
  pattern recognition}, pages 9729--9738, 2020.

\bibitem{he2016deep}
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
\newblock Deep residual learning for image recognition.
\newblock In {\em Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 770--778, 2016.

\bibitem{huang2021gloria}
Shih-Cheng Huang, Liyue Shen, Matthew~P Lungren, and Serena Yeung.
\newblock Gloria: A multimodal global-local representation learning framework
  for label-efficient medical image recognition.
\newblock In {\em Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pages 3942--3951, 2021.

\bibitem{Iakubovskii:2019}
Pavel Iakubovskii.
\newblock Segmentation models pytorch.
\newblock \url{https://github.com/qubvel/segmentation_models.pytorch}, 2019.

\bibitem{irvin2019chexpert}
Jeremy Irvin, Pranav Rajpurkar, Michael Ko, Yifan Yu, Silviana Ciurea-Ilcus,
  Chris Chute, Henrik Marklund, Behzad Haghgoo, Robyn Ball, Katie Shpanskaya,
  et~al.
\newblock Chexpert: A large chest radiograph dataset with uncertainty labels
  and expert comparison.
\newblock In {\em Proceedings of the AAAI conference on artificial
  intelligence}, volume~33, pages 590--597, 2019.

\bibitem{jang2016categorical}
Eric Jang, Shixiang Gu, and Ben Poole.
\newblock Categorical reparameterization with gumbel-softmax.
\newblock {\em arXiv preprint arXiv:1611.01144}, 2016.

\bibitem{johnson2019mimic}
Alistair~EW Johnson, Tom~J Pollard, Nathaniel~R Greenbaum, Matthew~P Lungren,
  Chih-ying Deng, Yifan Peng, Zhiyong Lu, Roger~G Mark, Seth~J Berkowitz, and
  Steven Horng.
\newblock Mimic-cxr-jpg, a large publicly available database of labeled chest
  radiographs.
\newblock {\em arXiv preprint arXiv:1901.07042}, 2019.

\bibitem{kingma2014adam}
Diederik~P Kingma and Jimmy Ba.
\newblock Adam: A method for stochastic optimization.
\newblock {\em arXiv preprint arXiv:1412.6980}, 2014.

\bibitem{kuhn1955hungarian}
Harold~W Kuhn.
\newblock The hungarian method for the assignment problem.
\newblock {\em Naval research logistics quarterly}, 2(1-2):83--97, 1955.

\bibitem{larsson2017colorproxy}
Gustav Larsson, Michael Maire, and Gregory Shakhnarovich.
\newblock Colorization as a proxy task for visual understanding.
\newblock In {\em CVPR}, 2017.

\bibitem{li2019knowledge}
Christy~Y Li, Xiaodan Liang, Zhiting Hu, and Eric~P Xing.
\newblock Knowledge-driven encode, retrieve, paraphrase for medical image
  report generation.
\newblock In {\em Proceedings of the AAAI Conference on Artificial
  Intelligence}, volume~33, pages 6666--6673, 2019.

\bibitem{li2022blip}
Junnan Li, Dongxu Li, Caiming Xiong, and Steven Hoi.
\newblock Blip: Bootstrapping language-image pre-training for unified
  vision-language understanding and generation.
\newblock {\em arXiv preprint arXiv:2201.12086}, 2022.

\bibitem{li2022grounded}
Liunian~Harold Li, Pengchuan Zhang, Haotian Zhang, Jianwei Yang, Chunyuan Li,
  Yiwu Zhong, Lijuan Wang, Lu Yuan, Lei Zhang, Jenq-Neng Hwang, et~al.
\newblock Grounded language-image pre-training.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 10965--10975, 2022.

\bibitem{li2018hybrid}
Yuan Li, Xiaodan Liang, Zhiting Hu, and Eric~P Xing.
\newblock Hybrid retrieval-generation reinforced agent for medical image report
  generation.
\newblock {\em Advances in neural information processing systems}, 31, 2018.

\bibitem{liu2021cptr}
Wei Liu, Sihan Chen, Longteng Guo, Xinxin Zhu, and Jing Liu.
\newblock Cptr: Full transformer network for image captioning.
\newblock {\em arXiv preprint arXiv:2101.10804}, 2021.

\bibitem{lu2019vilbert}
Jiasen Lu, Dhruv Batra, Devi Parikh, and Stefan Lee.
\newblock Vilbert: Pretraining task-agnostic visiolinguistic representations
  for vision-and-language tasks.
\newblock {\em Advances in neural information processing systems}, 32, 2019.

\bibitem{marcel2010torchvision}
S{\'e}bastien Marcel and Yann Rodriguez.
\newblock Torchvision the machine-vision package of torch.
\newblock In {\em Proceedings of the 18th ACM international conference on
  Multimedia}, pages 1485--1488, 2010.

\bibitem{mu2022slip}
Norman Mu, Alexander Kirillov, David Wagner, and Saining Xie.
\newblock Slip: Self-supervision meets language-image pre-training.
\newblock In {\em European Conference on Computer Vision}, pages 529--544.
  Springer, 2022.

\bibitem{muller2021joint}
Philip M{\"u}ller, Georgios Kaissis, Congyu Zou, and Daniel R{\"u}ckert.
\newblock Joint learning of localized representations from medical images and
  reports.
\newblock {\em arXiv preprint arXiv:2112.02889}, 2021.

\bibitem{ngiam2018domain}
Jiquan Ngiam, Daiyi Peng, Vijay Vasudevan, Simon Kornblith, Quoc~V Le, and
  Ruoming Pang.
\newblock Domain adaptive transfer learning with specialist models.
\newblock {\em arXiv preprint arXiv:1811.07056}, 2018.

\bibitem{oord2018representation}
Aaron van~den Oord, Yazhe Li, and Oriol Vinyals.
\newblock Representation learning with contrastive predictive coding.
\newblock {\em arXiv preprint arXiv:1807.03748}, 2018.

\bibitem{paredes2021back}
Federico Paredes-Vall{\'e}s and Guido~CHE de Croon.
\newblock Back to event basics: Self-supervised learning of image
  reconstruction for event cameras via photometric constancy.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 3446--3455, 2021.

\bibitem{pathak2016context}
Deepak Pathak, Philipp Krahenbuhl, Jeff Donahue, Trevor Darrell, and Alexei~A
  Efros.
\newblock Context encoders: Feature learning by inpainting.
\newblock In {\em Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 2536--2544, 2016.

\bibitem{pathak2020deep}
Yadunath Pathak, Prashant~Kumar Shukla, Akhilesh Tiwari, Shalini Stalin, and
  Saurabh Singh.
\newblock Deep transfer learning based classification model for covid-19
  disease.
\newblock {\em Irbm}, 2020.

\bibitem{radford2021learning}
Alec Radford, Jong~Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh,
  Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark,
  et~al.
\newblock Learning transferable visual models from natural language
  supervision.
\newblock In {\em International Conference on Machine Learning}, pages
  8748--8763. PMLR, 2021.

\bibitem{raghu2019transfusion}
Maithra Raghu, Chiyuan Zhang, Jon Kleinberg, and Samy Bengio.
\newblock Transfusion: Understanding transfer learning for medical imaging.
\newblock {\em Advances in neural information processing systems}, 32, 2019.

\bibitem{ramesh2022hierarchical}
Aditya Ramesh, Prafulla Dhariwal, Alex Nichol, Casey Chu, and Mark Chen.
\newblock Hierarchical text-conditional image generation with clip latents.
\newblock {\em arXiv preprint arXiv:2204.06125}, 2022.

\bibitem{ren2015faster}
Shaoqing Ren, Kaiming He, Ross Girshick, and Jian Sun.
\newblock Faster r-cnn: Towards real-time object detection with region proposal
  networks.
\newblock {\em Advances in neural information processing systems}, 28, 2015.

\bibitem{ronneberger2015u}
Olaf Ronneberger, Philipp Fischer, and Thomas Brox.
\newblock U-net: Convolutional networks for biomedical image segmentation.
\newblock In {\em International Conference on Medical image computing and
  computer-assisted intervention}, pages 234--241. Springer, 2015.

\bibitem{shih2019augmenting}
George Shih, Carol~C Wu, Safwan~S Halabi, Marc~D Kohli, Luciano~M Prevedello,
  Tessa~S Cook, Arjun Sharma, Judith~K Amorosa, Veronica Arteaga, Maya
  Galperin-Aizenberg, et~al.
\newblock Augmenting the national institutes of health chest radiograph dataset
  with expert annotations of possible pneumonia.
\newblock {\em Radiology. Artificial intelligence}, 1(1), 2019.

\bibitem{sowrirajan2021moco}
Hari Sowrirajan, Jingbo Yang, Andrew~Y Ng, and Pranav Rajpurkar.
\newblock Moco pretraining improves representation and transferability of chest
  x-ray models.
\newblock In {\em Medical Imaging with Deep Learning}, pages 728--744. PMLR,
  2021.

\bibitem{taleb20203d}
Aiham Taleb, Winfried Loetzsch, Noel Danz, Julius Severin, Thomas Gaertner,
  Benjamin Bergner, and Christoph Lippert.
\newblock 3d self-supervised methods for medical imaging.
\newblock {\em Advances in Neural Information Processing Systems},
  33:18158--18172, 2020.

\bibitem{tewari2018self}
Ayush Tewari, Michael Zollh{\"o}fer, Pablo Garrido, Florian Bernard, Hyeongwoo
  Kim, Patrick P{\'e}rez, and Christian Theobalt.
\newblock Self-supervised multi-level face model learning for monocular
  reconstruction at over 250 hz.
\newblock In {\em Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 2549--2559, 2018.

\bibitem{van2017neural}
Aaron Van Den~Oord, Oriol Vinyals, et~al.
\newblock Neural discrete representation learning.
\newblock {\em Advances in neural information processing systems}, 30, 2017.

\bibitem{van2008visualizing}
Laurens Van~der Maaten and Geoffrey Hinton.
\newblock Visualizing data using t-sne.
\newblock {\em Journal of machine learning research}, 9(11), 2008.

\bibitem{vaswani2017attention}
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,
  Aidan~N Gomez, {\L}ukasz Kaiser, and Illia Polosukhin.
\newblock Attention is all you need.
\newblock {\em Advances in neural information processing systems}, 30, 2017.

\bibitem{2020SciPy-NMeth}
Pauli Virtanen and Ralf~etal Gommers.
\newblock {{SciPy} 1.0: Fundamental Algorithms for Scientific Computing in
  Python}.
\newblock {\em Nature Methods}, 17:261--272, 2020.

\bibitem{wang2022multi}
Fuying Wang, Yuyin Zhou, Shujun Wang, Varut Vardhanabhuti, and Lequan Yu.
\newblock Multi-granularity cross-modal alignment for generalized medical
  visual representation learning.
\newblock {\em Advances in Neural Information Processing Systems}, 2022.

\bibitem{wang2022aesthetic}
Yizhi Wang, Guo Pu, Wenhan Luo, Yexin Wang, Pengfei Xiong, Hongwen Kang, and
  Zhouhui Lian.
\newblock Aesthetic text logo synthesis via content-aware layout inferring.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 2436--2445, 2022.

\bibitem{wang2022end}
Yiyu Wang, Jungang Xu, and Yingfei Sun.
\newblock End-to-end transformer based model for image captioning.
\newblock {\em arXiv preprint arXiv:2203.15350}, 2022.

\bibitem{wolf-etal-2020-transformers}
Thomas Wolf and Lysandre~Debut et al.
\newblock Transformers: State-of-the-art natural language processing.
\newblock pages 38--45, Online, Oct. 2020. Association for Computational
  Linguistics.

\bibitem{yang2021writing}
Xingyi Yang, Muchao Ye, Quanzeng You, and Fenglong Ma.
\newblock Writing by memorizing: Hierarchical retrieval-based medical report
  generation.
\newblock {\em arXiv preprint arXiv:2106.06471}, 2021.

\bibitem{yao2021filip}
Lewei Yao, Runhui Huang, Lu Hou, Guansong Lu, Minzhe Niu, Hang Xu, Xiaodan
  Liang, Zhenguo Li, Xin Jiang, and Chunjing Xu.
\newblock Filip: Fine-grained interactive language-image pre-training.
\newblock {\em arXiv preprint arXiv:2111.07783}, 2021.

\bibitem{yu2022coca}
Jiahui Yu, Zirui Wang, Vijay Vasudevan, Legg Yeung, Mojtaba Seyedhosseini, and
  Yonghui Wu.
\newblock Coca: Contrastive captioners are image-text foundation models.
\newblock {\em arXiv preprint arXiv:2205.01917}, 2022.

\bibitem{zhang2020contrastive}
Yuhao Zhang, Hang Jiang, Yasuhide Miura, Christopher~D Manning, and Curtis~P
  Langlotz.
\newblock Contrastive learning of medical visual representations from paired
  images and text.
\newblock {\em arXiv preprint arXiv:2010.00747}, 2020.

\bibitem{zhuang2020comprehensive}
Fuzhen Zhuang, Zhiyuan Qi, Keyu Duan, Dongbo Xi, Yongchun Zhu, Hengshu Zhu, Hui
  Xiong, and Qing He.
\newblock A comprehensive survey on transfer learning.
\newblock {\em Proceedings of the IEEE}, 109(1):43--76, 2020.

\end{thebibliography}
