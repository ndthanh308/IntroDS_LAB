\section{Dynamic $k$-Center Algorithms Queries}\label{apx:queries}

The dynamic algorithms for $k$-center we give in this paper can simply and efficiently answer queries of the following types:
\begin{enumerate}[topsep=0pt,itemsep=-1ex,partopsep=1ex,parsep=1ex]
    \item Return a set $S$ of at most $k$ centers and the corresponding radius $r$.
    \item Given a vertex $v \in V$, return the center $c \in S$ of the cluster $v$ belongs to.
    %\item Given a center $c \in S$, return the set of vertices which are within distance $r$ from $c$.
\end{enumerate}
The first type of queries simply returns the independent sets which have size $\le k$. 
The corresponding radius in the first query and the second type of queries can be answered using the dynamic shortest path data structures that we use. When maintaining distances from a super-source, the data structures let us keep the parent nodes along shortest paths which can be used for finding the closest source. The partially dynamic algorithms that we use are based on structures with $n^{o(1)}$ layers, such that we have a parent along the shortest path on each of these levels. Therefore without additional overhead we can keep track of the first parents along the path.



In our fully dynamic algorithm, we can keep track of the cluster center of each vertex by explicitly checking for each vertex whether its distance to the ``super-source'' changes with each iteration of the simulated Gonzalez's algorithm; the additional $ O(k n) $ overhead is already accounted for in our update time.





\section{Reduction from $2$-Approximate $k$-Center to $k$-Bounded Ruling Set: Omitted Proofs of Section~\ref{sec:reduction}}
\label{apx:reduction proofs}

This section is devoted to the omitted proofs of Section~\ref{sec:reduction}.


\kmisrtR*{}
\begin{proof}
    Consider an optimal solution $S^* = \{c^*_1, \dots, c^*_{k'}\}$ 
    of the $k$-center instance with $k' \leq k$, and let 
    $C_1^*, \dots, C_{k'}^*$ be the corresponding clusters, each of radius $R^*$. Let $M$ be an arbitrary 
    \tbrs in $G_r$, with $r \geq 2R^*$. We can assume w.l.o.g. that the set
    $M$ is ordered. The proof is by induction on the number of vertices of $M$. 
    The goal is to prove that for any $i \leq k'$, every vertex $v \in C_i^*$ is a neighbor
    of the $i_{th}$ vertex of $M$ in $G_r$. 
    This would imply then that $|M| \leq k' \leq k$, as otherwise
    there would be two vertices in $M$ which are neighbors in $G_r$, violating the
    fact that $M$ is a \tbrs in $G_r$ with $\beta \geq 1$
   
    As a base case, let $v_1$ be the first vertex of $M$, and
    assume w.l.o.g. that $v_1 \in C_1^*$. 
    Since all vertices in $C_1^*$ are within distance $R^*$ from $c_1^*$ in $G$, 
    by triangle inequality it holds that $d_G(v_1, u) \leq 2R^*$, for every vertex $u \in C_1^*$. 
    Hence as $r \geq 2R^*$, we have that every vertex $u \in C_1^*$ is a neighbor of $v_1$ in $G_r$. 

    Let $v_i \in M$ be the $i_\text{th}$ vertex of $M$.
    Since $M$ is a \tbrs in $G_r$ with $\beta \geq 1$, $v_i$ cannot be a neighbor of any other vertex that belongs to $M$.
    By inductive hypothesis, every vertex 
    $u \in C_1^* \cup \dots \cup C_{i-1}^*$ has a neighbor in $M$, and so $v_i$ cannot be part of
    $C_1^* \cup \dots \cup C_{i-1}^*$. As a result, we can assume w.l.o.g. that $v_i \in C_i^*$. By following the same approach as in the base case, we have that every vertex $u \in C_i^*$
    is a neighbor of $v_i$ in $G_r$, and so the claim follows.
\end{proof}



\noIStRGr*{}
\begin{proof}
    Suppose to the contrary that there is an IS $M$ in $G_r$ of size at least $k + 1$,
    and let $M'$ be an MIS on $G_r$ such that 
    $M \subseteq M'$. Then clearly it holds that $|M'| \geq k + 1$. Also since $\beta \geq 1$,
    we have that $M'$ is a \tbrs in $G_r$ of size at least $k + 1$. However based
    on Lemma~\ref{lem:k-MIS_r>=2R^*}, as $r \geq 2R^*$ and $\beta \geq 1$, the size
    of $M'$ must be at most $k$, and this yields a contradiction.
\end{proof} 



\tbapproxGr*{}
\begin{proof}
Let $r'$ be the smallest $r \in \{(1 + \epsilon)^i \mid (1 + \epsilon)^i \leq nW, i \in \mathbb{N}\}$ such that a \kbtbrs algorithm running on $G_r$ returns a \tbrs $M_r$ of size at most $k$. 
Let $S = M_{r'}$ be the solution we return for the $k$-center instance.

Since $M_{r'}$ is a \tbrs in $G_{r'}$, then every vertex is within 
distance $\beta r'$ from its closest center in $G$. Thus, the returned solution $S$ has radius at most $\beta r'$.
We show now that $r'$ is at most $2(1+\epsilon)$ times larger than $R^*$.
Based on Observation~\ref{obs:noIStRGr}, for the fixed choice of $r = 2R^*$,
any \kbtbrs algorithm $\mathcal{A}$ running on the $r$-threshold graph $G_r$
always returns a \tbrs $M_r$ of size at most $k$.
By definition of $r'$, and since the possible values of $r$ are powers of $(1 + \epsilon)$,
we have that $r' \leq 2(1 + \epsilon)R^*$.
Therefore, the radius of the returned solution $S$ is at most $2\beta(1+\epsilon)R^*$.
\end{proof}


\section{Incremental $(1+\epsilon)$-SSSP}\label{app:incremental}
\newcommand{\dist}{d}

Most of the existing work on partially dynamic $(1+\epsilon)$-SSSP \cite{bernstein2009, HKN2014hopsets, chechik2018, LackiN22} is presented for the decremental setting, but while not explicitly written, the techniques extend to the incremental setting as well with the same running time. At a high-level these techniques first maintain a hopset (or similar objects like low-hop emulators) of size $\tilde{O}(m^{1+{o(1)}})$ and hopbound $h=n^{o(1)}$, and maintain an $h$-hop limited (ES) Even-Schiloach tree \cite{ES}. 

The $h$-hop limited ES tree algorithm \cite{bernstein2009} allows us to maintain $(1+\epsilon)$-approximate single-source shortest path up to $h$-hops (which finds the approximate shortest path using at most $h$ hops) in $\tilde{O}(mh)$ time. 

To use this subroutine several works utilize a hopset~\cite{HKN2014hopsets, chechik2018, LackiN22}. A $(\beta, \epsilon)$-hopset $H'$ for $G=(V,E)$ is a set of weighted edges such that for all $u,v \in V$, we have that $\dist_G(u,v) \leq \dist^{(\beta)}_{G\cup H'}(u,v)  \leq (1+ \epsilon)\dist_G(u,v)$, where $\dist^{(\beta)}_{G\cup H'}(u,v) $ refers to a shortest path that uses at most $\beta$ hops. 


Much of the technical difficulty in the decremental setting is due to the fact that we have to insert hopset/emulator edges in a decremental data structure.
The existing decremental structures use an algorithm called monotone ES tree data structure \cite{HenzingerKN14} to handle this, however in the incremental setting a monotone ES tree is not needed. In an incremental setting, an update may require to decrease the weight of an edge or remove it from a hopset/emulator to keep the size small. Handling weight decreases is easy, as we can simply add a new edge with the smaller weight and keep the previous edges in place and this will only impact the number of edges by a logarithmic factor over the sequence of updates. The second issue of removing edges from a hopset/emulator, will also not impact the over all performance of the algorithm for the following reason: In these data structure we would only remove an auxiliary edge $e \in E(H)$ if the weight $w^{(t)}(e)$ (which corresponds to the length of a path in the original input graph $G$ at time $t$), is reduced by more than a constant factor so that it is within a factor of $(1- \epsilon')w^{(t-1)}(e)$. It is easy to see that in the incremental setting it will add a logarithmic factor in the size if we keep all of these edges and simply add new parallel edges and thus keep the data structures completely incremental. 
