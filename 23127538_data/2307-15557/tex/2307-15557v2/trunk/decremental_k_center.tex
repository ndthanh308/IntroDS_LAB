\section{Decremental $k$-Center on Graphs}\label{sec:decremental}
In the decremental setting, the input graph of the $k$-center instance is subject to edge deletions.
Based on Lemma~\ref{lem:2b-approx_Gr}, in order to get a $(2 + \epsilon)$-approximation decremental
algorithm for the $k$-center problem, it is sufficient to develop a decremental algorithm for the 
\kbtors problem on $r$-threshold graphs. To maintain the necessary information for the $r$-threshold
graphs, we use a decremental SSSP algorithm on $G$.

\subsection{Decremental $k$-Bounded $(2, 1)$-Ruling Set on $G_r$}
For the sake of efficiency, in order to maintain the necessary information
for the $r$-threshold graphs, we make use of the approximate SSSP algorithm of 
Theorem~\ref{th:decr_appr_sssp}. Thus, we obtain instead the following theorem
which is a slight relaxation of the decremental \kbtors problem on $r$-threshold graphs.
This is still sufficient for the $k$-center problem, as Lemma~\ref{lem:2b_Gr_H}
suggests.

\begin{theorem} \label{th:res_dec_tors}
    Consider a weighted undirected graph $G = (V, E, w)$ subject to edge deletions, an integer $k \geq 1$, a positive parameter $r$ and a positive constant $\epsilon < 1$. 
    Let $r' := (1+\epsilon)r$ and consider the threshold graphs $G_r$ and $G_{r'}$.
    There is a deterministic algorithm which:
    \begin{itemize}[topsep=0pt,itemsep=-1ex,partopsep=1ex,parsep=1ex]
        \item either reports that there is an independent set in $G_r$ of size at least $k + 1$,
        \item or runs a decremental \kbtors algorithm $\mathcal{B}$ on an edge-subgraph $H$ of $G_{r'}$ with
        the following condition: whenever $\mathcal{B}$ reports that
        there is an independent set in $H$ of size at least $k + 1$, then
        there is an independent set in $G_r$ of size at least $k + 1$.
    \end{itemize}
    The total update time of the algorithm is $km^{1+o(1)}$.
\end{theorem}


Recall that in the definition of an \abrs, the first property is that the distance between any two vertices
in the \abrs is at least $\alpha$. The crucial observation here is that under edge deletions, the distance between any 
two vertices is non-decreasing. Hence the first property is preserved in the decremental setting, and this is the major
ingredient for the algorithm.

\subsubsection{Overview of the Algorithm}
For a fixed value of $r$ and $\epsilon$, let $r' := (1 + \epsilon)r$.
In the beginning of the algorithm of Theorem~\ref{th:res_dec_tors}, we execute a static \kbtors algorithm $\mathcal{B}$ on $G_r$.
One simple algorithm for this problem is to run $k$ times the Dijkstra's algorithm on $G$.
In particular, at each iteration we choose a vertex $s$ which has not been covered yet, 
and we run Dijkstra's algorithm on $G$ with source $s$. Then, 
every vertex $v$ of distance at most $r$ from $s$ is set as covered, and the same process is repeated at most $k$
times. The running time of this algorithm is clearly $\tilde{O}(mk)$.


%For the problem of finding an MIS on $r$-threshold graphs, there are also
%faster algorithms~\cite{abboud2023fine, thorup2005quick} with $\tilde{O}(m)$ expected time. 

Assume that algorithm $\mathcal{B}$ returns a \tors $M$ in $G_r$ of size at most $k$.
Next, we initialize a decremental approximate SSSP algorithm $\mathcal{A}$ with super-source $M$ on $G$, providing distance 
estimates $\delta(\cdot)$.\footnote{Namely, we introduce a fake root $x$ and 
add an edge $(x, v)$ of zero weight, for every $v \in M$. Then, we run a decremental approximate SSSP algorithm
with source $x$ on $G$.}
Specifically, we use the $(1 + \epsilon)$-approximate SSSP algorithm of Theorem~\ref{th:decr_appr_sssp}.
Also let $H$ be a graph whose edge set  contains all the edges $(u, v) \in V \times V$ such that
$\delta(v) \leq r'$ and $u \in M$ is the corresponding vertex for the distance estimate $\delta(v)$.
%\antonis{explain how we find $u$.}
The graph $H$ can be explicitly constructed during the previous step.


Whenever there is an edge deletion in $G$, we pass this update to $\mathcal{A}$. In turn,
this update can possibly increase the distance estimate $\delta(\cdot)$ of some vertices. 
In particular, whenever the distance estimate $\delta(v)$ of a vertex $v \in V$ becomes greater
than $r'$, we add $v$ to $M$, and the algorithm $\mathcal{A}$ is restarted with super-source the
modified set $M$. Moreover, the graph $H$ is recomputed from scratch as before.

At any moment, if the size of $M$ has exceeded $k$, the algorithm reports that there is an independent set
in $G_r$ of size at least $k + 1$, and we do not restart the algorithm $\mathcal{A}$ anymore.

\subsubsection{Analysis of the Algorithm}

Our goal here is to prove Theorem~\ref{th:res_dec_tors}.
Initially the static algorithm produces a \tors $M$ in $G_r$.
At any moment, if the size of $M$ becomes at least $k + 1$, the algorithm reports
that there is an independent set in $G_r$ of size at least $k + 1$.
The next lemma shows the correctness of this step.

\begin{lemma} \label{lem:dist_alpha_IS}
    If the size of $M$ is at least $k + 1$, then there is
    an independent set in $G_r$ of size at least $k + 1$.
\end{lemma}
\begin{proof}
    Initially the set $M$ is a \tors in $G_r$, and by definition $M$ is 
    also an independent set in $G_r$. Thus, if the size of $M$
    is at least $k + 1$ after the execution of the static algorithm, 
    the set $M$ remains an independent set in $G_r$ under edge deletions, and the claim holds.

    Hence, we can assume that the size of $M$ became at least $k + 1$ after some edge deletions.
    We prove the claim by contradiction. 
    Suppose to the contrary that $M$ is not an independent set in $G_r$ after an edge deletion. 
    In this case, the algorithm must have added 
    a vertex $v$ to $M$ which has a neighbor $u \in M$ in $G_r$ (i.e., $d_G(u, v) \leq r$). 
    Since $u \in M$, in the algorithm
    we maintain the decremental $(1+\epsilon)$-SSSP algorithm with super-source $M$, and by 
    Theorem~\ref{th:decr_appr_sssp} it holds that
    $\delta(v) \leq (1+\epsilon)d_G(u, v) \leq r'$.
    But then, the algorithm does not add $v$ to $M$ which yields a contradiction.
\end{proof}

Assume that the size of the solution $M$ is at most $k$. The next lemma shows that
the algorithm maintains a decremental \kbtors algorithm on an edge-subgraph $H$ of $G_{r'}$. 

\begin{lemma} \label{lem:dec_M_tors}
    The graph $H$ is a subgraph of $G_{r'}$. 
    Moreover, if $|M| \leq k$, then the set $M$ is always a \tors in $H$.
\end{lemma}
\begin{proof}
    Let $(u, v) \in E(H)$ be an edge in $H$. 
    Then, w.l.o.g. it must be the case that $u \in M$ and $\delta(v) \leq r'$.
    Based on Theorem~\ref{th:decr_appr_sssp}, the distance estimate $\delta(\cdot)$ does not underestimate the distances,
    and so we have that $d_G(u, v) \leq \delta(v) \leq r'$. 
    Thus by definition, the edge $(u, v)$ is part of $G_{r'}$ as well.
    
    The algorithm adds the vertex $v$ to $M$ only if the distance estimate $\delta(v)$ becomes
    greater than $r'$, while the edge $(u, v)$ is part of $H$ only if $\delta(v)$ is at most $r'$. This implies that the set $M$ is an independent set in $H$.
    Furthermore, whenever the distance estimate $\delta(v)$ of a vertex $v \in V \setminus M$ becomes
    greater than $r'$, the set $M$ and the graph $H$ are recomputed. 
    This implies that the distance estimate of any vertex $v \in V \setminus M$ is at most $r'$.
    By construction of $H$, there must exist an edge $(u, v)$ in $H$, where $u \in M$ is the corresponding vertex of $\delta(v)$.
    Hence, we can conclude that the set $M$ is a \tors in $H$.
\end{proof}

\subparagraph{Running time.} The running time of the simple static algorithm is $\tilde{O}(mk)$.
By Theorem~\ref{th:decr_appr_sssp}, the total time of the decremental approximate SSSP algorithm is $m^{1+o(1)}$.
As the decremental approximate SSSP algorithm is restarted at most $k$ times,
the total update time of the algorithm is $km^{1+o(1)}$. Notice that the time to detect whether
a distance estimate is greater than $r' = (1+\epsilon) r$ is incorporated in the update time of the decremental approximate SSSP algorithm. 

\vspace{1em}

Finally, Theorem~\ref{th:res_dec_tors} follows by combining 
Lemma~\ref{lem:dist_alpha_IS} and Lemma~\ref{lem:dec_M_tors} together with the analysis of the running time.

\subsection{Decremental $k$-Center on Graphs: Putting It Together}
We combine Theorem~\ref{th:res_dec_tors} with Lemma~\ref{lem:2b_Gr_H}
to obtain the next theorem for the decremental $k$-center problem on graphs.
A pseudocode of the algorithm of Theorem~\ref{th:dec_kcent_2appr} is provided in Algorithm~\ref{alg:dec_kcenter}. 

\begin{algorithm}[ht!]
\DontPrintSemicolon
\caption{\textsc{decremental $(2 + \epsilon)$-approximation algorithm for $k$-center}{}}
\label{alg:dec_kcenter}
\SetKwFunction{FMaximalDistrIS}{MaximalDistrIS}
\SetKwProg{Fn}{Function}{:}{\KwRet}

\setcounter{AlgoLine}{0}
\SetAlgoLined

\Fn{\FMaximalDistrIS{}} {
    $i \gets 0$
    
    \While {$G \setminus \bigcup_{j=1}^i C_j \neq \emptyset$ and $i \leq k$} {
        $u \gets $ arbitrary vertex from $G \setminus \bigcup_{j=1}^i C_j$
    
        $i \gets i+1$
    
        $c_i \gets u$

        $C_i \gets$ cluster with center $c_i$ and radius $r$
    }

    \KwRet i
}

\vspace{1em}

\SetKwProg{Fn}{Procedure}{:}{\KwRet}
\SetKwFunction{FFindRadius}{FindRadius}
\Fn{\FFindRadius{}} {
    \While {\FMaximalDistrIS{} > k} {
        $r \gets (1 + \epsilon) \cdot r$
    }
}

\vspace{1em}

\SetKwProg{Fn}{Procedure}{:}{\KwRet}
\SetKwFunction{FPreprocessing}{Preprocessing}
\Fn{\FPreprocessing{}} {
    $r \gets 1$
    
    \FFindRadius{}

    $M \gets \{c_1, \dots, c_i\}$
    
    $\mathcal{A}.initialize(G, M)$
    \tcp*{$\mathcal{A}$ is decremental approx. SSSP algorithm with distance estimates $\delta(\cdot)$}
}

\vspace{1em}

\SetKwProg{Fn}{Procedure}{:}{\KwRet}
\SetKwFunction{FUpdate}{Update}
\Fn{\FUpdate{$u$, $v$}} {
    $G \gets (V, E \setminus (u,v))$

    $\mathcal{A}.delete(u,v)$

    \While{$\exists x \in V$ such that $\delta(x) > (1+\epsilon) r$} {
        \If{$i < k$} {
            $i \gets i + 1$

            $c_i \gets x$

            $M \gets \{c_1, \dots, c_i\}$
            
            $C_i \gets$ cluster with center $c_i$ and radius $r$
        }
        \Else {
            $r \gets (1 + \epsilon) \cdot r$
            
            \FFindRadius{}
        }

        $\mathcal{A}.restart(G, M)$
    }
}
\end{algorithm}


\deckcenttappr*
\begin{proof}
    Observe that algorithm $\mathcal{A}$ inside Lemma~\ref{lem:2b_Gr_H} with $\beta = 1$, 
    has the same properties of the algorithm in Theorem~\ref{th:res_dec_tors}. Hence, 
    let $\mathcal{A}$ be the algorithm of Theorem~\ref{th:res_dec_tors}, and 
    $\epsilon_1 = \frac{\epsilon}{6}$. Based on Lemma~\ref{lem:2b_Gr_H},
    by running $\mathcal{A}$ with input $G, r, \epsilon_1$, for each
    $r \in \{(1 + \epsilon_1)^i \mid (1 + \epsilon_1)^i \leq nW, i \in \mathbb{N}\}$, we get a
    deterministic decremental $2(1+\epsilon_1)(1+\epsilon_1)$-approximation algorithm for the
    $k$-center problem. As $\epsilon < 1$ and $\epsilon_1 = \frac{\epsilon}{6}$, the approximation
    ratio is $(2 + \epsilon)$.

    Regarding the running time, by Theorem~\ref{th:res_dec_tors} the total update time of $\mathcal{A}$ is $km^{1+o(1)}$. Since we run $\mathcal{A}$ for at most $O(\log_{1+\epsilon_1}(nW))$ different values of $r$, the total update time
    of the algorithm remains $km^{1+o(1)}$. 
\end{proof}






%\begin{lemma} \label{lem:greedy_2r-approx}
%    For $r \geq 2r^*$ the number of clusters returned by the function \FGreedy{} is at most $k$.
%\end{lemma}
%\begin{proof}
%    Consider an optimal partition of the graph with clusters $C_1^*, \dots, C_k^*$, each of radius $r^*$ with centers $c_1^*, \dots, c_k^*$ respectively.
%    Let $c_1$ be the first vertex \FGreedy{} chooses and assume without loss of generality that $c_1 \in C_1^*$. Since all the vertices in $C_1^*$
%    are within distance $r^*$ from $c_1^*$, from triangle inequality it holds that $dist_G(c_1, u) \leq 2r^*$, for all $u \in C_1^*$. This implies that with $c_1$ as the first choice,
%    the cluster $C_1^*$ is fully covered with $r \geq 2r^*$, namely $C_1^* \subseteq C_1$. The choice of the next center is disjoint from all the previous clusters created by the algorithm, and so, it is also
%    disjoint from all the previous optimal clusters. Hence, by applying the same argument inductively, we can conclude that the whole graph is covered with at most $k$ clusters.
%\end{proof}
%\begin{lemma} \label{lem:greedy_runtime}
%    The running time of the function \FGreedy{} is $\tilde{O}(mk)$.
%\end{lemma}

%\begin{lemma}
%    The algorithm maintains a $2(1+\epsilon)$-approximate solution.
%\end{lemma}
%\begin{proof}
%    Initially in the preprocessing step, we find the smallest $r$ for which the greedy approach returns at most $k$ clusters. By Lemma~\ref{lem:greedy_2r-approx} we know that $2r^*$
%    is such a choice, and since each level is of distance $(1 + \epsilon)$ from each other, we can conclude that the algorithm in the beginning maintains a 
%    $2(1+\epsilon)$-approximate solution. Under edge deletions the distances are non-decreasing which means that the optimal radius $r^*$ is non-decreasing as well.
%    Thus as long as the distance of each vertex from the super-source containing all the centers is at most $r$ (for a fixed one), the solution is still $2(1+\epsilon)$-approximate.
%    Consider the situation where after an edge deletion there exists a vertex $u$ whose distance from the super-source is more than $r$. Then the algorithm
%    either remains in the same level and creates new clusters (where the total number of them is at most $k$), or moves to a next level.
%    In the first case, since the value of $r$ has not increased, we have a $2(1+\epsilon)$-approximate solution with at most $k$ clusters. To analyze the second case, let us
%    consider the previous level $r' = \frac{r}{1+\epsilon}$. To prove our claim, it is enough to show that $r' < 2r^*$, because then $r < 2(1+\epsilon)r^*$.
%    Suppose to the contrary that $r' \geq 2r^*$. Since the algorithm moved to the next level $r$, it must be the case that with $r'$, the number of clusters
%    returned by the greedy choice of the centers was more than $k$. By the greedy approach, the centers are disjoint from the previous clusters, and the same holds for the chosen centers during the updates.
%    As the distances are non-decreasing, this condition holds the whole time for a fixed level. But then the proof of Lemma~\ref{lem:greedy_2r-approx}, implies that
%    the number of the returned clusters with $r'$ must be at most $k$, which is a contradiction. Therefore it holds that $r' < 2r^*$ which means that $r < 2(1+\epsilon)r^*$,
%    and the claim follows.
%\end{proof}

%\begin{lemma}
%    The total running time of the algorithm is $O(t(m, n) \cdot k \cdot \log_{(1+\epsilon)}nW)$
%\end{lemma}
%\begin{proof}
%    For every fixed value of $r$ (namely, a fixed level), we run the function \FGreedy{} one time and we
%    rebuild the SSSP-tree at most $k$ times. By Lemma~\ref{lem:greedy_runtime} the total time per level is $O(t(m, n) \cdot k)$.
%    Since there are $\log_{(1+\epsilon)}nW$ levels, the claims follows.
%\end{proof}
