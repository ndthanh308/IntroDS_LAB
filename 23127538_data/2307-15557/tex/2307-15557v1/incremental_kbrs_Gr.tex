\subsection{Incremental \kbttrs on $G_r$}
Our goal here is to extend Theorem~\ref{th:res_kbmis} to $r$-threshold graphs 
so that we can apply Lemma~\ref{lem:2b-approx_Gr} and maintain an incremental $k$-center solution. 
At a high level, our intention is to simulate the two phases of Algorithm~\ref{alg:2_k_MIS} on an $r$-threshold graph $G_r$.
Recall by Definition~\ref{def:threshold_graph} that for any pair of vertices $u,v \in V \times V$, there is an edge in $G_r$
if and only if the distance between $u$ and $v$ in $G$ is at most $r$.
The main challenges in the incremental setting are the following ones.
% 
\begin{itemize}[topsep=0pt,itemsep=-1ex,partopsep=1ex,parsep=1ex]
    \item We cannot afford to explicitly maintain all the edges of $G_r$ in the incremental setting, because it is very expensive to run an incremental All-Pairs Shortest Paths algorithm on $G$.
    
    \item A single edge insertion in the original graph $G$ could introduce multiple edge insertions in the $r$-threshold graph $G_r$.
\end{itemize}
% 
Note that Algorithm~\ref{alg:2_k_MIS} does not need access to all edges of $G_r$ in order to process $G_r$.
Thus, our aim is to describe how to maintain all the necessary information 
that Algorithm~\ref{alg:2_k_MIS} needs, so as to run with implicit input the $r$-threshold graph $G_r$.

To extract the relevant information for the $r$-threshold graph $G_r$, we make use of the
incremental $(1+\epsilon)$-SSSP algorithm of Theorem \ref{th:incr_appr_sssp}. 
We note that using partially dynamic \emph{exact} SSSP algorithms for this step would be too slow for our purposes, as even in unweighted 
graphs we would require $\Omega(mr)$ time and $r$ could be very large (i.e., as big as $n$).
Consequently, rather than explicitly maintaining $G_r$, we maintain an edge-subgraph $H$ of the 
$r'$-threshold graph $G_{r'}$, with $r':=(1+\epsilon)r$.
However, whenever the algorithm reports that there is an independent set of size at least $k+1$ in $H$,
we guarantee that this is also true for the $r$-threshold graph $G_r$.

We exploit the fact that Algorithm~\ref{alg:2_k_MIS} guarantees that the size of the kernel-set is small.
Hence, as only the edges in the graph induced by the kernel-set are needed, we argue 
based on Lemma~\ref{lem:dep_S_size} that during the whole second phase of the algorithm
we maintain $\tilde{O}(k)$ incremental $(1+\epsilon)$-approximate SSSP instances. Furthermore again by
Lemma~\ref{lem:dep_S_size}, we argue that during the whole first phase of the algorithm,
we maintain $\tilde{O}(1)$ incremental $(1+\epsilon)$-approximate SSSP instances. 
As a result, in total we maintain only $\tilde{O}(k)$ incremental $(1+\epsilon)$-approximate SSSP instances over the course of the algorithm,
and this is the main ingredient for the efficiency of the algorithm.

\begin{restatable}{theorem}{reskbmisGr}\label{thm:res_kbmisGr}
    Consider a graph $G = (V, E, w)$ subject to edge insertions, an integer $k \geq 1$, a positive parameters $r$ and a positive constant $\epsilon<1$. 
    Let $r' := (1+\epsilon)r$ and consider the threshold graphs $G_r$ and $G_{r'}$. Then, there is a randomized algorithm which:
    \begin{itemize}[topsep=0pt,itemsep=-1ex,partopsep=1ex,parsep=1ex]
       \item either reports that there is an independent set in $G_r$ of size at least $k + 1$, and this is correct w.h.p.,
       \item or finds a kernel-set $S \subseteq V$ of size $\tilde{O}(k)$ in an edge-subgraph $H$ of $G_{r'}$ and runs a \kbtors algorithm
       $\mathcal{B}$ on $H[S]$ with the following condition: whenever $\mathcal{B}$ reports that there is an independent
       set in $H$ of size at least $k + 1$, then there is an independent set in $G_r$ of size at least $k + 1$.
    \end{itemize} 
    The total update time of the algorithm is w.h.p.\ $\tilde{O}(m^{1+o(1)}k)$.
\end{restatable}

\noindent
By definition of a kernel-set (see Definition~\ref{def:kern_set}), the next corollary immediately follows.

\begin{corollary}\label{cor:res_kbmisGr}
Consider the setting of Theorem~\ref{thm:res_kbmisGr}. Then,
there is a randomized algorithm which:
\begin{itemize}[topsep=0pt,itemsep=-1ex,partopsep=1ex,parsep=1ex]
   \item either reports that there is an independent set in $G_r$ of size at least $k + 1$, and this is correct w.h.p.,
   \item or runs a \kbttrs algorithm $\mathcal{B}$ on an edge-subgraph $H$ of $G_{r'}$ with the following condition:
    whenever $\mathcal{B}$ reports that there is an independent
    set in $H$ of size at least $k + 1$, then there is an independent set in $G_r$ of size at least $k + 1$.
\end{itemize}
The total update time of the algorithm is w.h.p.\ $\tilde{O}(m^{1+o(1)}k)$.
\end{corollary}

In the following, we describe the algorithm of Theorem~\ref{thm:res_kbmisGr}, which is an adaptation of Algorithm~\ref{alg:2_k_MIS} on approximate threshold graphs.

\paragraph{Overview of the algorithm.}
A pseudocode of the algorithm is provided in Algorithm~\ref{alg:incr_kbttrs_Gr}.
We adapt Algorithm~\ref{alg:2_k_MIS} to process the $r$-threshold graph $G_r$ implicitly.

\begin{algorithm}[ht!]
\DontPrintSemicolon
\caption{\textsc{\kbttrs on $G_r$}}
\label{alg:incr_kbttrs_Gr}
\SetKwProg{Fn}{Procedure}{:}{\KwRet}
\SetKwFunction{FKBRS}{$k$-Bounded-Ruling-Set}
\SetKwFunction{FUpdate}{Insert}

\setcounter{AlgoLine}{0}

\tcp{In the preprocessing $i = 0$, $L_0 = V$, and $\FKBRS{}$ is called with no edge}

$r' \gets (1+\epsilon)r$

\Fn{\FKBRS{$u,v$}}{
    \If(\tcp*[h]{first phase}){$|L_i| < 4k$}{
        \If{$i=0$ or $|L_i|\le \frac{|L_{i-1}|}{2}$}{
            $i \gets i+1$

            $\gamma_i \gets \frac{|L_{i-1}|}{2k} - 1$

            $S_i \gets$ sample vertices of $L_{i-1}$ independently with prob. $\min(10\ln(n) / \gamma_i, 1)$

            $S^{(i)} \gets \bigcup_{j=1}^{i} S_j$

            $\mathcal{A}_{S^{(i)}}.initialize(G, S^{(i)})$
            \tcp*{$\mathcal{A}_{S^{(i)}}$ is incremental approx. SSSP algorithm}
            \tcp*{$\mathcal{A}_{S^{(i)}}$ provides approx. distance $\delta_{S^{(i)}}(\cdot)$}

            $L_i \gets \{x \in V : \delta_{S^{(i)}}(x) > r'\}$

            $\FKBRS{u,v}$
        }
        \Else{
            \textbf{report} there exists an IS in $G_r$ of size at least $k+1$
        }
    }
    \Else(\tcp*[h]{second phase}){
        \If(\tcp*[h]{$\mathcal{B}$ is dynamic \kbtors algorithm (Theorem~\ref{th:fully_dyn_mis})}){$\mathcal{B}$ not initialized}{
            $d \gets i$
            
            $S \gets \bigcup_{j=1}^d S_j$
    
            \For{$s \in S$}{
                $\mathcal{A}_s.initialize(G,s)$
                \tcp*{$\mathcal{A}_s$ is incremental approx. SSSP algorithm}
            }

            $H \gets (S, E_{S})$ s.t.~$E_{S} \gets \{(u, v) \in S \times S : \delta_u(v) \le r'\}$

            
            
            $\mathcal{B}.initialize(H)$
        }
        \Else{
            \For{$s \in S$}{
                $\mathcal{A}_s.insert(G, u,v)$
            }
            
            \While {$\exists\, a, b \in S$ s.t. $(a, b) \notin E_{S}$ and $\delta_a(b) \leq r'$} {
                $\mathcal{B}.insert(H, a,b)$
            }
        }
    }
}

\vspace{1em}

\Fn{\FUpdate{$G, u, v$}}{
   

    $\mathcal{A}_{S^{(i)}}.insert(G, u,v)$

    \If {$\exists\, x \in L_i$ s.t. $\delta_{S^{(i)}}(x) \leq r'$} {
        $L_i \gets L_i \setminus x$
    }

    $\FKBRS{u,v}$
}
\end{algorithm}

Consider a recursive call $i \geq 1$ of Algorithm~\ref{alg:2_k_MIS} during the first phase. 
The sampling step for obtaining the set $S_i$ does not need access to the edges of the input graph,
but only to the vertices of the input graph. Thus, each hitting set $S_i$ can be explicitly constructed. In turn, 
the union of the sampled sets $S^{(i)} = S_1 \cup \cdots \cup S_i$ is explicitly constructed as well.

The next step of Algorithm~\ref{alg:2_k_MIS} is to compute the size of $L_i$, 
and decide how to proceed with the recursion depending on the sizes of $L_{i-1}$ and $L_i$.
A simulation of Algorithm~\ref{alg:2_k_MIS} on $G_r$, would construct the set $L_i$ as the set
of vertices which are of distance more than $r$ in $G$ from the closest vertex in $S_i$. 
Nevertheless, as we use an approximate SSSP algorithm, we construct the set $L_i$ in a slightly
different way as follows.
% 
In the beginning of the recursive call, we set $S = S^{(i)}$ and $L_i = L_{i-1} \setminus S_i$.
At this point, we maintain the incremental $(1+\epsilon)$-SSSP algorithm of Theorem~\ref{th:incr_appr_sssp}
with super-source $S$ on $G$, providing distance estimates $\delta_S(\cdot)$.\footnote{Namely, we introduce a fake root $x$ and 
add an edge $(x, v)$ of zero weight, for every $v \in S$. Then, we run the approximate SSSP algorithm
with source $x$ on $G$.} 
Whenever the distance estimate $\delta_S(v)$ of a vertex $v \in V$ becomes smaller than $(1+\epsilon)r$,
we remove $v$ from $L_i$ and add the edge $(a, v)$ to $H$, where $a$ is the corresponding vertex of $S$ for the distance estimate $\delta_S(v)$ 

Therefore, we continue with the recursion as in Algorithm~\ref{alg:2_k_MIS}
by constructing the set $L_i$ in this way, and in turn computing its size.

Moreover, since at every new recursive call the set $S^{(i)}$ is modified (i.e., we sample more vertices), at every new recursive call we set $S = S^{(i)}$
and we restart the incremental 
$(1+\epsilon)$-SSSP algorithm with super-source $S$ on $G$.

\smallskip
As in Algorithm~\ref{alg:2_k_MIS}, the second phase begins when the size of $L_i$ is at most $4k$, and at this moment the recursion ends.
We denote by $d$ the index of the last recursive call in the first phase,
and $S$ is updated to $S := S^{(d)} \cup L_d$.
% 
During the second phase, Algorithm~\ref{alg:2_k_MIS} has to maintain an incremental \kbtors 
algorithm on $G_r[S]$. Instead, we maintain an incremental \kbtors algorithm on a subgraph $H[S]$ of $G_{r'}[S]$. The subgraph $H[S]$ is maintained explicitly, as follows.
Let $E_S$ be the initially empty set consisting of the edges in $H[S]$.
For each vertex $v \in S$, we maintain the incremental $(1+\epsilon)$-SSSP algorithm of 
Theorem~\ref{th:incr_appr_sssp} with source $v$ on $G$,
providing distance estimates $\delta_v(\cdot)$. Then for any two vertices $u, v \in S$, 
whenever we have that $\delta_u(v) \leq (1+\epsilon)r$ or $\delta_v(u) \leq (1+\epsilon)r$,
the edge $(u, v)$ is added to $E_S$. 

Thus during the second phase, we maintain the incremental \kbtors algorithm $\mathcal{B}$ of Theorem~\ref{th:fully_dyn_mis} on
$(S, E_S)$. Whenever $\mathcal{B}$ reports that there is an independent set in $(S, E_S)$ of size at least $k + 1$,
we report that there is an independent set in $G_r$ of size at least $k + 1$.
In the analysis we argue that $S$ is a kernel-set in $H$. Hence by definition, this implies
that $\mathcal{B}$ solves the incremental \kbttrs problem in $H$.

\paragraph{Edge insertions.}
Consider an edge insertion to $G$, and let $i$ be the current recursive call of the algorithm before 
the update arrives. While the algorithm is in the first phase, the update is passed
to the incremental $(1+\epsilon)$-SSSP algorithm with super-source $S^{(i)}$. If the algorithm is in the second phase after an insertion, 
then for every vertex $v \in S$, the inserted edge is passed as an update to the incremental 
$(1+\epsilon)$-SSSP algorithm with source $v$.
Notice that an edge insertion in the original graph $G$ could introduce multiple updates to $E_S$. Thus whenever an edge $(a, b)$ is added to $E_S$, the edge $(a, b)$ is passed as an update to the incremental \kbtors algorithm $\mathcal{B}$.


\paragraph{Proof of Theorem~\ref{thm:res_kbmisGr}.}
If we had access to exact distances and we removed a vertex $v$ from $L_i$ whenever its distance estimate is at most $r$, then the correctness would follow from the arguments of the previous section. 
However, since for efficiency purposes we are utilizing approximate distances, the analysis has to be adapted.
In our case we remove a vertex $v$ from $L_i$ whenever its approximate distance estimate is at most $r'=(1+\epsilon)r$.
The next lemma is similar to Lemma~\ref{lem:kvert_nomis} but now applied to the $r$-threshold graph $G_r$.

\begin{lemma} \label{lem:kvert_nomis_Gr}
    At any stage of the algorithm with $i \geq 1$, if $|L_i| > \frac{|L_{i-1}|}{2}$, then w.h.p.\ there is an independent in $G_r$ of size at least $k + 1$.
\end{lemma}
\begin{proof}
    The threshold $\gamma_i$ is set to $\frac{|L_{i-1}|}{2k} - 1$,
    and $S_i$ is obtained by sampling each vertex of $L_{i-1}$ independently  
    with probability $\min(c\ln(n) / \gamma_i, 1)$, for a sufficiently large constant $c$.
    Then by Lemma~\ref{lem:sampling}, it holds that w.h.p.\ every vertex $v$
    in $L_{i-1}$ of degree more than $\gamma_i$ in the induced subgraph $G_r[L_{i-1}]$ has a neighbor in $S_i$. 
    This is equivalent of saying that w.h.p.~every vertex $v$ of degree more than $\gamma_i$ in $G_r[L_{i-1}]$ is within distance $r$ from a vertex of $S_i$ in $G$, that is, $d_G(v, S_i) \leq r$. Then, by Theorem~\ref{th:incr_appr_sssp}
    we have that $\delta_S(v) \leq (1 + \epsilon)r$, which means that $v$ has been removed from $L_i$.
    In turn, this implies that w.h.p.~every vertex in $L_i$ is of
    degree at most $\gamma_i$ in $G_r[L_{i-1}]$. 
    As $G_r[L_i]$ is a subgraph of $G_r[L_{i-1}]$, w.h.p.~every vertex of $G_r[L_i]$ is of degree at most $\gamma_i$ in $G_r[L_i]$ as well.
    
    Since w.h.p.~the maximum degree in $G_r[L_i]$ is bounded by $\gamma_i$, the claim follows by applying the same process of the second paragraph of Lemma~\ref{lem:kvert_nomis} on $G_r[L_i]$.
\end{proof}

Notice that after computing the size of $L_i$, the recursion continues in the same way as in Algorithm~\ref{alg:2_k_MIS}. The next lemma says that Lemma~\ref{lem:dep_S_size} holds in this algorithm as well. Recall that $d$ is the recursive call after the first phase has ended and just before the second phase begins (i.e., $d$ is the final depth of the recursion). 

\begin{lemma} \label{lem:dep_S_size_Gr}
    Over the sequence of updates, there are $d=O(\log n)$ recursive calls. Moreover, the size of $S$ is w.h.p.~$O(k \log^2 n)$.
\end{lemma}

Remember that we want to use Algorithm~\ref{alg:incr_kbttrs_Gr} as a subroutine in the
incremental $k$-center algorithm. By using the next property of $H$, we argue that only an extra $(1 + \epsilon)$ factor 
shows up in the approximation ratio of the $k$-center algorithm.

\begin{lemma}
    The graph $H$ is a subgraph of the $r'$-threshold graph $G_{r'}$, where $r'= (1+\epsilon)r$. 
\end{lemma}
\begin{proof}
    Let $(u, v) \in E(H)$ be an edge of the graph $H$. Suppose that the edge has been 
    added during the first phase of the algorithm. Then, WLOG it must be the case that 
    $u \in S$ and $\delta_S(v) \leq r'$.
    Based on Theorem~\ref{th:incr_appr_sssp}, 
    the distance estimate $\delta_S(\cdot)$ does not underestimate the distances, and so
    we have that $d_G(u, v) \leq \delta_S(v) \leq r'$. 
    Thus by definition, the edge $(u, v)$ is part of $G_{r'}$ as well.

    Similarly, suppose that the edge has been added during the second phase of the algorithm. Then, WLOG it must be the case that $u, v \in S$ and $\delta_u(v) \leq r'$.
    Using a similar argument as before, we conclude that every edge of $H$ is part of $G_{r'}$.
\end{proof}

During the second phase, whenever the incremental \kbtors algorithm $\mathcal{B}$ reports that there is an
independent set in $H$ of size at least $k+1$, we report that there is an independent set in $G_r$ 
of size at least $k + 1$. Since algorithm $\mathcal{B}$ is running on $H[S]$, the following
lemma states that in this case, there is definitely an independent set in $G_r$
(and not just with high probability) of size at least $k + 1$.

\begin{lemma}
    Any independent set in $H[S]$ is also an independent set in $G_r[S]$.
\end{lemma}
\begin{proof}
    Let $M$ be an independent set in $H[S]$, and suppose to the contrary that $M$ is not an independent
    set in $G_r[S]$. Then there must exist two vertices $u, v \in S \cap M$, such that 
    the edge $(u, v)$ belongs to $G_r[S]$ but not to $H[S]$. Since $(u, v)$ belongs to $G_r$, the distance between $u$ and $v$ in $G$ is at most $r$ (i.e., $d_G(u, v) \leq r$). Also as $u \in S$, in the algorithm
    we maintain the incremental $(1+\epsilon)$-SSSP algorithm with source $u$ on $G$, and by Theorem~\ref{th:incr_appr_sssp} it holds that $\delta_u(v) \leq (1+\epsilon)d_G(u, v) \leq (1+\epsilon)r$.
    Hence as $v \in S$, the algorithm must have added the edge $(u, v)$ to $H$, which contradicts
    the assumption that the edge $(u, v)$ does not belong to $H[S]$.
\end{proof}

\begin{lemma} \label{lem:kern_set_H}
    The set $S$ is a kernel-set in $H$.
\end{lemma}
\begin{proof}
    The claim follows by applying the 
    proof of Lemma~\ref{lem:S_kern_G} on $H$.
\end{proof}

\paragraph{Running Time.}
During the first phase, the incremental $(1+\epsilon)$-SSSP algorithm with super-source $S^{(i)}$ on $G$, is restarted as many times
as the number of the recursive calls. By Lemma~\ref{lem:dep_S_size_Gr}, there are at most $O(\log n)$ recursive calls in total,
and by Theorem~\ref{th:incr_appr_sssp}, the total update time of the incremental $(1+\epsilon)$-SSSP algorithm is $\tilde{O}(m^{1 + o(1)})$. 
Thus, the total update time charged for the first phase of the algorithm is $\tilde{O}(m^{1 + o(1)})$.

During the second phase, for every vertex $v \in S$, we maintain an incremental 
$(1+\epsilon)$-SSSP algorithm of Theorem~\ref{th:incr_appr_sssp} with source $v$ on $G$.
By Lemma~\ref{lem:dep_S_size_Gr}, the size of $S$ is w.h.p.\ $\tilde{O}(k)$, and so the total
update time for maintaining the edge set $E_S$ is $\tilde{O}(m^{1 + o(1)}k)$.

\begin{observation} \label{obs:E_S_nondec}
    Since $G$ is subject to edge insertion, the edge set $E_S$ of $H$ is non-descreasing.
\end{observation}

The \kbtors algorithm $\mathcal{B}$ of Theorem~\ref{th:fully_dyn_mis} is running on 
$(S, E_S)$ (i.e., the induced subgraph $H[S]$). Also, 
as the edge set $E_S$ contains only edges between vertices in $S$, the maximum size of $E_S$ is w.h.p.\
$\tilde{O}(k^2)$.
Then based on Theorem~\ref{th:fully_dyn_mis} and Observation~\ref{obs:E_S_nondec}, 
the total update time charged for $\mathcal{B}$ is $\tilde{O}(k^2)$, which 
(when amortized over the $\Omega(k^2)$ total edge insertions to $E_s$) amounts to 
an amortized update time of $\tilde{O}(1)$.

This concludes the running time analysis of Theorem \ref{thm:res_kbmisGr}.