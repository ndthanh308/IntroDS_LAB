\section{Technical Overview}\label{sec:overview}

In this section, we give a high-level overview of our algorithms and discuss several technical challenges that we need to handle for dynamically maintaining $k$-center on graphs rather than metrics.


\paragraph{Reduction to $k$-bounded maximal independent set on threshold graphs.} We start by reviewing a known reduction from $2$-approximate $k$-center to $k$-bounded maximal independent set (MIS)~\cite{HochbaumS86} which is also the basis of some of the fully dynamic $k$-center algorithms on \textit{metrics}~\cite{bateni2023optimal, chan2018fully}. The idea for obtaining a $2$-approximation is to guess the optimal value $R^*$ of the $k$-center instance via a binary search, and return
any maximal distance-$2R^*$ independent set $M$ of size at most $k$. Recall that $M$ is a maximal subset of vertices such that no two vertices $u,v \in M$ are within distance $2R^*$ of each other. The vertices of $M$ then correspond to the centers of the $k$-center instance. 

For utilizing this idea in the dynamic setting, rather than guessing the value of $R^*$, we maintain the MIS on each \textit{$r$-threshold graph} $G_r$, for every distance range $r \leq (1+\epsilon)^{i}$, where $i \in [0, \log_{1+\epsilon} (nW)]$. This general framework has been used in the dynamic $k$-center algorithms in metric spaces \cite{bateni2023optimal, chan2018fully}. Actually, they  maintain a relaxation of the MIS,
called a $k$-bounded MIS. The observation is that it is sufficient to either return an MIS of size of at most $k$ on each $r$-threshold graph $G_r$, or to simply report that there is an independent set of size at least $k+1$ as a witness that the distance $r$ is not the correct guess.

\paragraph{Technical challenges in graphs vs metrics.}
As discussed before there are several important technical differences between the graph and metric settings. The first difference is that, unlike the metric settings, in graphs we do not have direct access to distances. Thus, we also need to maintain the appropriate distances simultaneously while the dynamic MIS is modified on the $r$-threshold graphs.
For this, we would like to combine a dynamic MIS maintenance algorithm with partially dynamic (approximate) shortest paths algorithms. At a high-level, our goal is to maintain a $k$-bounded MIS $M$ dynamically on each $r$-threshold graph $G_r$ and at the same time maintain a dynamic (approximate) SSSP algorithm from a super-source connecting to all the vertices in the dynamic set $M$. Hence the efficiency of the algorithm will depend on the number of times a new vertex is added to $M$ over all the updates. Equivalently, the efficiency will depend on the number of times we restart the SSSP
algorithm. 


In both metrics and graph settings, we need to bound the \textit{recourse}, where by recourse we mean the number of times a new center is introduced by the algorithm. However, we argue that we need a \textit{stronger recourse guarantee} for graphs. Recall that another important difference between these two settings is that in the metric setting adding or removing points has a more local impact, whereas in a graph an update may impact the distances between many vertices. 
In other words, in the graph setting an edge update may \textit{distort} the metric itself. This difference in graphs also requires our algorithm to have an overall recourse guarantee, as opposed to an amortized one that suffices for the metric settings. 
Thus an amortized recourse of $\tilde{O}(k)$ \emph{per update} is not enough, and we need the stronger guarantee that the recourse is $\tilde{O}(k)$ \emph{over all updates}. 
More concretely, this total bound on recourse will let us argue that in total we need to re-initialize a dynamic $(1+\epsilon)$-SSSP algorithm $\tilde{O}(k)$ times from each center, and an amortized guarantee would not be enough for getting our desired update bound. We will see that maintaining this stronger recourse guarantee is more challenging in incremental settings than in decremental settings. 

Note that this type of recourse guarantee has been studied in metric spaces under the name \emph{consistent} clustering~\cite{LattanziV17,FichtenbergerLNS21,LackiHGRJ23}.
However, we would like to emphasize that the known sublinear bounds on the total recourse in the point-insertion setting for metric spaces do not carry over to the incremental setting in graphs.

\paragraph{Decremental $k$-center.} 
We can obtain a decremental $(2+\epsilon)$-approximation for $k$-center by maintaining a decremental $(1+\epsilon)$-SSSP algorithm from each added center in each of the $O(\log nW)$ threshold graphs. Bounding the recourse in the decremental setting is relatively straightforward based on the following observation. When a new center forms a cluster due to a distance increase in a given threshold graph, it stays disjoint of other clusters throughout the algorithm and thus it stays a valid center. On the other hand, as soon as we get more than $k$ centers, we move to the next distance threshold and thus we have at most $k$ new centers in total for each threshold. This allows us to simply bound the recourse to $k$ on each threshold graph and thus to $O(k \log nW)$ overall. This combined with the time needed for maintaining partially dynamic $(1+\epsilon)$-approximate SSSP leads to our desired $kn^{o(1)}$ amortized update time.

\paragraph{Incremental low recourse ruling sets.} Bounding the recourse in incremental settings is more challenging since, unlike the decremental settings, after an insertion in a given $r$-threshold graph $G_r$ a cluster center $c_1$ may come within the radius $r$ distance of another existing center $c_2$. We cannot simply merge the corresponding clusters in some way and still maintain a $2$-approximation, as some vertices in such a merged cluster would go beyond the desired threshold after each update. Hence we need a new technical idea to keep the recourse low. The idea is to maintain a small subset of vertices (of size $\tilde{O}(k)$) in $G$ which we call a \textit{kernel-set} $S$ such that, at a high-level, maintaining a maximal independent set on $S$ will give us an \textit{approximate} maximal independent set on $G$. More formally, by maintaining a $k$-bounded MIS $M$ on a kernel set $S$ we can show that $M$ is also a $k$-bounded $(2,2)$-ruling set\footnote{While our $k$-center algorithms work for weighted graphs, the ruling set subroutines always perform on unweighted graphs regardless on the input to the $k$-center problem.} in $G$, namely a subset of vertices of $M$ of size at most $k$ such that: (i) the distance between any pair of vertices in $M$ is at least $2$, and (ii) for each vertex $u \in V$ there exists a vertex in $M$ within distance $2$.
Introducing this small kernel-set allows us to maintain a dynamic bounded maximal independent set $M$ on the smaller subgraph $S$ more efficiently, at the cost of losing a factor $2$ in the approximation due to the fact that $M$ is only a $(2,2)$-ruling set on $G$. 
For maintaining such a kernel-set we use a recursive algorithm that maintains a union of hitting sets on a sequence of sparsified subgraphs of $G$. The hitting sets are obtained by a standard sampling procedure on the subgraphs corresponding to each recursive call. Informally, the sampling rate of the hitting sets is tuned depending on the densities of these subgraphs and the recursion continues until the remaining set of low degree vertices is sufficiently small. 
Since we have an incremental graph, the set of \textit{low degree vertices defined based on a specific degree threshold} that are not covered by the hitting sets shrinks over time and this allows us to bound the recursion depth by $O(\log n)$.


\paragraph{Challenges of working with the threshold graphs.} 
The high-level idea described above will give us an algorithm for maintaining a $k$-bounded $(2,2)$-ruling set on an incremental graph in $\tilde{O}(k)$ amortized time and crucially will have an overall recourse of $\tilde{O}(k)$. Similar to the decremental algorithm, our goal is to maintain such a ruling set on all threshold graphs. This, combined with an incremental $(1+\epsilon)$-SSSP algorithm, will lead to an incremental $(4+\epsilon)$-approximation algorithm for $k$-center. The main remaining challenge is that an insertion into a graph $G$ could lead to many insertion in the threshold graph and the threshold graphs could have density $n^2 \geq m$. To overcome this challenge, we do not explicitly store the threshold graphs, but again utilize a small kernel-set for each threshold graph to ensure that only \textit{relevant} insertions, i.e., those that cause a conflict, are processed and passed to the shortest path algorithms. 
Overall, by bounding the number centers added and the number of edges processed, we ensure that we only need to re-initialize $\tilde{O}(k)$ incremental $(1+\epsilon)$-approximate shortest path algorithms, which leads to an amortized update time of $O(kn^{o(1)})$.





