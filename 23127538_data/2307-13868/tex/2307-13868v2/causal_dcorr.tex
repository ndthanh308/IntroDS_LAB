\documentclass[onefignum, onetabnum,onealgnum,onethmnum, oneeqnum]{siamonline190516}
\input{nd_preamble.tex}  
\usepackage[symbol]{footmisc}
\renewcommand{\thefootnote}{\arabic{footnote}}
\usepackage{ericmath}
\usepackage[createShortEnv]{proofs}


\definecolor{fig1green}{rgb}{0.01, .7, 0.1}
\definecolor{fig1orange}{rgb}{0.7, 0.34, 0.005}

\newcommand{\dowhy}{\sct{doWhy}}
\newcommand{\anova}{\sct{anova}}
\newcommand{\vm}{\sct{VM}}
\newcommand{\hsic}{\sct{Hsic}}
\newcommand{\cdcorr}{\sct{cDcorr}}
\newcommand{\pdcorr}{\sct{pDcorr}}
\newcommand{\Noccco}{\sct{Noc3o}}
\newcommand{\Manova}{\sct{manova}}
\newcommand{\manova}{\sct{manova}}
\newcommand{\cmanova}{\sct{cManova}}
\newcommand{\whell}{\sct{wHell}}
\newcommand{\kcd}{\sct{kernelCDTest}}
\newcommand{\causal}{\sct{Causal}}
\newcommand{\gcm}{\sct{GCM}}
\newcommand{\rcit}{\sct{RCIT}}
\newcommand{\rcot}{\sct{RCoT}}
\newcommand{\ccdcorr}{\causal~\cdcorr}

\title{
Learning sources of variability from high-dimensional observational studies
}

\author{
    Eric W.~Bridgeford$^{1,\dagger}$, 
    Jaewon Chung$^1$,
    Brian Gilbert$^1$,
    Sambit Panda$^1$,
    Adam Li$^3$,
    Cencheng Shen$^2$,
    Alexandra Badea$^4$,
    Brian Caffo$^1$,
    Joshua T.~Vogelstein$^1$.
    \thanks{
     $^1$ Johns Hopkins University, $^2$ University of Delaware, $^3$ Columbia University, $^4$ Duke University
    $^\dagger$ Corresponding author:
      Eric W.~Bridgeford (\email{ebridge2@jhu.edu}).}
}


\makeatletter
\def\thanks#1{\protected@xdef\@thanks{\@thanks
        \protect\footnotetext{#1}}}
\makeatother
\makeatletter
\renewcommand\@biblabel[1]{#1.}
\makeatother
\begin{document}

\maketitle

\begin{abstract}
Causal inference studies whether the presence of a variable influences an observed outcome. As measured by quantities such as the ``average treatment effect,'' this paradigm is employed across numerous biological fields, from vaccine and drug development to policy interventions. Unfortunately, the majority of these methods are often limited to univariate outcomes. Our work generalizes causal estimands to outcomes with any number of dimensions or any measurable space, and formulates traditional causal estimands for nominal variables as causal discrepancy tests. We propose a simple framework under which universally consistent conditional independence tests are universally consistent causal discrepancy tests. Numerical experiments illustrate that our method, \ccdcorr, leads to improvements in both finite sample validity and power when compared to existing strategies when the assumptions of this framework are violated. %We provide real data examples from neuroimaging and genomics datasets to demonstrate the utility and flexibility of our proposed methodologies. 
Our methods are all open source and available at \href{github.com/ebridge2/cdcorr}{github.com/ebridge2/cdcorr}.
% We believe that the results in this paper suggest the utility of the framework described for causal structure learning and conditional discrepancy testing in observational data.% We provide all of our code and results open source in a leading package for causal inference, called \dowhy.
\end{abstract}


\input{Content/intro}
\input{Content/prelims}
\input{Content/methods}
\input{Content/results}
\input{Content/discussion}
% look to https://rdrr.io/cran/extracat/man/dcor.html for guidance for weighted distance correlation analogues that could be used for ``doubly-robuxst'' k-sample testing?

\begin{comment}
Notes - Adam Li (02/02/23)

- Add 1-2 paragraphs on implications wrt causal discovery

\section{Notes and Comments - 01/04/23}
I had meant to read this and provide some thoughts as Jovo suggested, but just got around to it. I held off on suggesting direct edits to not be rude :p.

Current Claims: A new method for estimating average treatment effect, that overcomes the major limitation of univariate outcomes.
\begin{enumerate}
    \item I think the claim can be stronger
    \item A new method for estimating average treatment effects that not only overcomes major limitations of univariate outcomes, but also serves as a conditional discrepancy test with applications to constraint-based causal discovery.
\end{enumerate}


Preliminaries: Lemma 4 basically enables us to test $P_t(y | x) = P_{t'}(y | x)$ even when T is categorical and Y and X are continuous(?). Note that you call this "Theorem 4" in the text.

Lemma 4 can also be stated using a graphical model with a graphical proof. I'm happy to try to provide an analagous proof, which I think could be an insightful appendix item. I would probably need to loop in a co-author with me to help write it though if that is fine with you. If it's too crowded, lmk.

2198q   109
Methods: As we discussed, I think it would be important to highlight the practical pros of using the causal d-corr vs conditional d-corr: I.e. better performance on finite samples? Also would be nice to explicitly state the difference between the two. And also state the difference compared to the CODiTE scholkopf paper.

% L2 penalty MANOVA?
% something like a permutation test, preserving uninteresting structure
% just unconditionally switching labels will destroy structure
% fit the model, take the residuals, allocate nk residuals to K groups, refit, and redo, and then compute the statistic for each permutation. just permuting the error distribution (if the model is right!)
% permutation version of residual bootstrap
% residual bootstrap, using permutation rather than a bootstrap (Efron book?)
\end{comment}

\bibliographystyle{IEEEtranSN}
\bibliography{batch}

\newpage

\appendix
\input{Content/appendix}

\end{document}



