\section{Results of Numerical Experiments}

\subsection{\ccdcorr~provides a substantial improvement in finite-sample validity over \cdcorr}

In Corollary \ref{cor:cond_ind}, we made the observation that if ignorability and positivity hold along with the assumptions of Setup \ref{setup}, then a consistent conditional independence test is a test for a $k$-sample causal discrepancy test. Conceptually, what this means is that as the sample size grows, the $k$-sample causal conditional discrepancy test is informative for differentiating whether or not the data provides sufficient information to reject the null hypothesis of interest in Definition \ref{def:hypo_causal_kst} for an acceptable type I error threshold $\alpha$. In an observational dataset, however, we simply observe the data: we do not have any information as to whether the positivity criterion is satisfied, and we do know whether sample size is sufficient for our causal conditional discrepancy test to be informative. Therefore, the ability to conduct valid inference in the absence of omniscent knowledge about the positivity condition and for datasets with a finite number of samples is imperative. We turn to simulation to investigate the implications of a lack of covariate balance on the empirical validity. To investigate the empirical validity, we run all simulations with an effect size $\Delta = 0$ (the outcome distributions conditional on the covariates are identical, and $H_0$ is true) and decrease the covariate balance from $1$ (the covariate distributions are identical across \textit{all} groups) to $0.2$ (the covariate distribution differs for one of the groups for all but $20\%$ of samples). Under this framework, empirically valid tests for causal conditional discrepancies will reject the null hypothesis in favor of the alternative at a rate $\leq \alpha$ irrespective of the level of covariate balance (the \textit{Type I Error Rate} for a given simulation at a given level of covariate balance). Conceptually, when covariate balance is low, it may not be possible to ascertain whether differences between the groups are due to the covariate distribution asymmetries \textit{or} the group assignment due to confounding by the covariate. Tests which make a type I error at a rate $>\alpha$ may be \textit{aliasing} the outcome/group effect (conditional on the covariate) with the outcome/covariate effect.

In Figure \ref{fig:validity}, we explore the statistical validity of all proposed conditional independence tests in various $k$-sample causal discrepancy testing settings by examining the type I error rate with the effect size $\Delta = 0$ (\textit{no effect} is present). Empirically valid statistical tests will make a type I error at a rate $\leq \alpha = 0.05$. We decrease the balance between the groups from $1.0$ to $0.2$, and compute estimates of the type I error rate. For each statistic, we also assess the frequency of type I errors by computing the number of times that the lower limit of a 90\% confidence interval (Wald test) is not $\leq \alpha = 0.05$. As the balance between the different groups decreases, \cdcorr~tends to make type I errors at an increasing rate (and, indeed, although the plots have been ``cut-off'' at a type I error rate of $0.3$ in favor of increased resolution near $\alpha = 0.05$ for the other techniques, the ``cut-off'' lines all reach a power of $1.0$ at or before the balance reaches its minimum value of $0.2$). \cmanova, \rcit, and \rcot~ frequently make type I errors at a rate $> \alpha$ over $25\%$ of the time. \gcm~makes type I errors infrequently (about 10\% of the time). By augmenting \cdcorr~with \vm~to produce \ccdcorr, the validity improves markedly: \cdcorr~goes from frequently making type I errors (53 of 80 possible settings) to never making type I errors (0 of 80 settings). \kcd~also never makes type I errors, but is not amenable to $K$-group settings.

% Figure environment removed

\subsection{Causal \cdcorr~ empirically dominates other techniques for causal conditional discrepancy testing}

These simulations were conducted under two balance contexts (high and low balance) in which the covariate distribution is equal for a high portion ($80\%$) and a low portion ($40\%$) of the samples, with the remaining samples collected from asymmetric covariate distributions. In the low balance case (shown in Figure \ref{fig:simsetup}A) this induces group-specific imbalance in which the treatment groups being compared do not have common support. For Causal~strategies, the samples are first filtered using \vm, as described in Methods \ref{sec:matching}. The effects of this pre-processing step are indicated in Figure \ref{fig:simsetup}B.

For a given effect size and simulation setting, statistical power is estimated over $R=200$ repetitions at $\alpha = 0.05$ and is shown in Figure \ref{fig:powers}. Validity (Effect size $\Delta = 0.0$) is investigated thoroughly in Figure \ref{fig:validity}. \cdcorr~and \Dcorr~(which can be used as tests for unconditional causal discrepancies, rather than causal conditional discrepancies; Appendix \ref{app:udice}) are invalid in numerous contexts, such as Figure \ref{fig:powers}\textbf{.I.} and Figure \ref{fig:powers}\textbf{.III.}, the sigmoidal and $K$-group settings. In these cases, type I error can be ascertained from the statistical power with an effect size of $\Delta = 0$. In particular, note that the \Dcorr~power curves appear particularly puzzling: the power is maximal at $\Delta = 0.5$, and falls for larger or smaller effect sizes. These simulations were constructed such that at $\Delta = 1.0$, the \textit{unconditional} causal discrepancy was minimized, despite the fact that the distributions are conditionally (on the covariates) maximally dissimilar. At $\Delta = 0.0$, an \textit{unconditional} effect appears to be present at a rate $\geq \alpha$ simply because the group conditional covariate distributions are different. This can be conceptualized as the unconditional effect (between the outcome and group) being \textit{aliased} with the outcome/covariate effect due to the disparate covariate distributions. Appendix \ref{app:sims} provides further clarity as to \textit{why} the the unconditional distributions are identical across all groups when $\Delta = 1.0$ for the sigmoidal and $K$-group settings. Causal \cdcorr, both variations of \cmanova, and \kcd~are the only approaches which are valid under all contexts. This result provides significant caution to the use of unconditional effect tests in data with conditional effects, as this unanticipated ``effect aliasing'' may arise.

Of the remaining tests, \gcm~has almost no power in any of the simulations except for the non-monotone simulation. \rcit~and \rcot~have almost no power in the $k$-group settings, and have low power in the sigmoidal and non-monotone setting when dimensionality is high. \kcd~tends to be overly conservative in contexts in which an effect is present, and generally has much lower power than Causal \cdcorr~(As shown in Figure \ref{fig:powers}\textbf{.I.}, Figure \ref{fig:powers}\textbf{.II.}, and Figure \ref{fig:powers}\textbf{.IV.}) across all but Figure \ref{fig:powers}\textbf{.I.(A)}, Figure \ref{fig:powers}\textbf{.I.(B)}, and Figure \ref{fig:powers}\textbf{.IV.(B)} where their disparity is relatively minor. In particular, Causal \cdcorr~is \textit{always} more powerful in high dimensional regimes of Figure \ref{fig:powers}\textbf{.(C)-(D)}. Further, Causal \cdcorr~flexibly operates in the $K$-group regime Figure \ref{fig:powers}\textbf{.III.}, for which there is no analogous extension of \kcd. \cmanova~approaches have no power in regimes in which the causal conditional discrepancy can be categorized as a difference in higher order moments, as in \textbf{IV.}, in which the two groups differ only in their second moment. Finally, \cmanova~approaches cannot be natively extended to the HDLSS regimes of Figure \ref{fig:powers}\textbf{.(C)-(D)} without further considerations, as-noted in Section \ref{sec:statistics}. Taken together with the results of Figure \ref{fig:validity}, this suggests that augmentation of \cdcorr~with \vm~to produce \ccdcorr~provides a flexible, valid, and powerful test for uncovering $k$-sample causal conditional discrepancies across a range of contexts, including when the covariate/outcome relationship is non-linear or non-monotone, and when the relationship across groups manifests in higher-order moments.

% Figure environment removed

%\subsection{Causal \cdcorr~facilitates novel insights on high-dimensional datasets}

%Through simulation supported by theoretical insight, we have demonstrated that \ccdcorr~facilitates consistent, empirically valid, powerful strategies for detecting causal effects in low and high dimensional settings. Our final question is the extent to which the methods proposed herein can be leveraged by researchers to infer novel causal insights in high-dimensional datasets.

%\paragraph{Causal \cdcorr~facilitates the identification of areas of the mouse connectome most affected by alzheimers}


%\paragraph{Causal \cdcorr~identifies genomic biomarkers}

% Carlo mtg notes
% 100 donors, several lines of pleuripotent stem cells, 2-3 replicates of each donor
% high dimensional output for each of those
% 

% https://academic.oup.com/biostatistics/article-abstract/22/3/629/5680453
% https://onlinelibrary.wiley.com/doi/pdf/10.1002/hbm.26112