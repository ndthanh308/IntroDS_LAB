
\section{Background}

The average treatment effect \cite{Rubin1974,Athey2017May} forms the backbone of many investigations in causal inference. We obtain the observed data $(y_i, t_i,  x_i)$, where $y_i \in \mathbb R$ is the outcome, $t_i \in \{1, 2\}$ is the (binary) treatment/intervention of interest (either treated or untreated), and $ x_i$ are the vector of baseline covariates (potential confounders), for individuals $i \in [n]$. To investigate this problem, we assume the existence of three random variables, $(\mathbf y_i, \mathbf t_i, {\mathbf x}_i)$, which are sampled independently and identically from some unknown data-generating distribution $F_{\mathbf y_i, \mathbf t_i, \mathbf x_i}$. Additionally, we assume the existence of two counterfactual random variables, $\mathbf y_i(1)$ and $\mathbf y_i(2)$, which represent the \textit{potential} outcomes under the two possible treatments. Conceptually, the theory of causal inference rests on the \textbf{consistency} assumption, which asserts that there is a single \textit{version} of each treatment level; e.g., if $\mathbf t_i = t$, then $\mathbf y_i = \mathbf y_i(t)$ \cite{Cole2009Jan}. Under this framework, the observed outcome is:
\begin{align*}
    \mathbf y_i &= \mathbf y_i(1) \indicator{\mathbf t_i = 1} + \mathbf y_i(2) \indicator{\mathbf t_i = 2},
\end{align*}
where only one of the potential outcomes will actually be realized in the observed data. The average treatment effect ($ATE$) is given by:
\begin{align}
    \gamma \triangleq ATE = \expect{\mathbf y_i(2) - \mathbf y_i(1)} = \expect{\mathbf y_i(2)} - \expect{\mathbf y_i(1)}
\end{align}
To test whether there is an $ATE$ implies the following hypothesis test:
\begin{align}
    H_0 : \gamma = 0 \text{ against }H_A: \gamma \neq 0.
\end{align}

The most obvious issue regarding the ATE is that, in practice, we observe realizations of $\mathbf y_i$ (the observed data), and \textit{not} $\mathbf y_i(t)$ (the counterfactual data); this is known as the ``fundamental problem of causal inference.'' When is $\expect{\mathbf y_i(t)}$ identifiable from the observed data, and how do we identify it?

The identifiability of $\expect{\mathbf y_i(t)}$ is ensured by the \textit{ignorability}, \textit{consistency}, \textit{positivity}, and the \textit{no interference} constraints. \textbf{Ignorability} is said to hold provided that $(\mathbf y_i(2), \mathbf y_i(1)) \indep \mathbf t_i \cond {\mathbf x}_i$; that is, the treatment is independent with respect to the observed baseline covariates. This condition will hold if the study executes it by design (such as in a perfect randomized trial) or all confounders have been recorded with the baseline covariates \cite{Holland1986}. The \textit{consistency} assumption is described above. \textbf{Positivity} holds if, for each possible treatment $t$, $Pr(\mathbf t_i = t \cond  {\mathbf x}_i =  x) > 0$ for any $ x$ in the support of ${\mathbf x}_i$ \cite{Rosenbaum1985,Rosenbaum2010}. Conceptually, any possible individual with a given covariate level \textit{could} have been observed in either the treated or untreated group. \textbf{No interference} asserts that there is no impact between the treatment assignments of \textit{other} participants on the potential outcomes of a given participant; this allows $\mathbf y_i(k)$ to be well-defined without reference to other individuals' treatment assignments \cite{Hernán2006}. When the consistency and no interference assumptions hold, these two assumptions are collectively referred to as the \textbf{Stable-Unit Treatment Value Assumption} (SUTVA) \cite{Hernán2006,Imbens2015,Rubin1980}. 

Under the $G$-computation formula \cite{Robins1986Jan}, if these assumptions hold, then:
\begin{align*}
    \expect{\mathbf y_i(t)} &= \expect{\expect{\mathbf y_i \cond \mathbf t_i = t,  {\mathbf x}_i}},
\end{align*}
and the ATE can be expressed as
\begin{align}
    \gamma &= \expect{\expect{\mathbf y_i \cond \mathbf t_i = 2,  {\mathbf x}_i}} - \expect{ \expect{\mathbf y_i \cond \mathbf t_i = 1, {\mathbf x}_i}}.
    \label{eqn:g_comp}
\end{align}
% Su/White? Weighted hellinger distance stuff? conditional ch.f. stuff? max nlin conditional corr?
As a general measure of treatment effects, the average treatment effect, as defined above, is rather limiting. First, treatment effects aren't necessarily constant across all individuals. One could conceptualize an intervention which has a strongly positive effect on younger people, but has a negative effect on older people. The average treatment effect ends up "averaging away" the heterogeneous effect of treatment on younger and older people, with the average treatment effect ending up being zero. This has been overcome by study of conditional (on baseline covariates, such as age) average treatment effects (the $CATE$) \cite{hahn1998role}: 
\begin{align*}
    \gamma_x \triangleq CATE(x) = \expect{\mathbf y_i(2) - \mathbf y_i(1) \cond \mathbf x_i = x} = \expect{\mathbf y_i(2) \cond \mathbf x_i = x} - \expect{\mathbf y_i(1) \cond \mathbf x_i = x}
\end{align*}
and a relevant test is whether, for each possible $x$:
\begin{align}
    H_0 : \gamma_x = 0 \text{ against }H_A: \gamma_x \neq 0,
    \label{eqn:hypo_cate}
\end{align}
but these too are not without limitations. 
