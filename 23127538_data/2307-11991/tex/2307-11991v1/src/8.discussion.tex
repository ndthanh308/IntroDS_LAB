


\section{Discussion}

The discussion section provides a comprehensive analysis of the project outcome, product perspective, website perspective, model perspective, and evaluation perspective.


\subsection{Project Outcome}

We have successfully developed and implemented an effective chatbot for mental health counselling. Through the training and fine-tuning of large-scale Chinese pre-training models on mental health datasets, the chatbot has acquired valuable knowledge in the field of psychology, enhancing its ability to provide counselling services. The deployment of the chatbot on a website interface has created a convenient and accessible platform for users seeking mental health support. Although the chatbot is currently in its prototype stage, our project demonstrates the feasibility of building an AI-based counselling system and serves as a valuable reference for future research and development in this area.

From a model perspective, our evaluation results clearly demonstrate the superiority of the \emph{PanGu} model over the \emph{WenZhong} model, as expected due to its larger size and advanced architecture. The \emph{PanGu} model's design, particularly its incremental learning ability and enhanced natural language understanding capabilities, contributes to its outperformance. However, both models fall short of achieving human-level performance, which can be attributed to the quality of the training dataset and the inherent limitations of autoregressive language models. Enhancing the dataset quality and exploring alternative language model architectures hold promise for addressing these limitations and further improving performance.


\subsection{Evaluation Perspective}

The human evaluation results indicate that both the \emph{PanGu} model and the \emph{WenZhong} model have not yet reached human-level performance. Despite training the models on our dataset crawled from websites, the predicted answers exhibit a strong focus on psychological content but lack logical coherence. One potential reason for this is the quality of our dataset, which may not be high enough to provide comprehensive and reliable training examples. Although we conducted human evaluation during the data cleaning stage, the sheer volume of data made it challenging to cover every instance. To address this, we recommend performing a thorough evaluation of the website data prior to crawling to ensure a higher-quality dataset.

Another factor impacting human evaluation is the limited computing conditions during model training. Our model requires a specific training environment and numerous parameters, making it time-consuming to adjust and fine-tune the model effectively. With our current resources, we were unable to optimize the parameters and achieve optimal testing results. Consequently, the model's performance may have been hindered by these limitations.
Furthermore, the autoregressive nature of both the \emph{PanGu} model and the \emph{WenZhong} model poses challenges in comprehending contextual information. As autoregressive language models, their training processes are unidirectional, focused on modelling the joint probability from left to right. The next predicted word is solely based on the preceding predicted word, limiting their ability to capture information from broader contexts. This lack of contextual background reference makes it difficult for language models to handle reading comprehension tasks in a manner similar to humans.

In summary, the evaluation results shed light on the areas where improvements can be made. Enhancing the dataset quality through pre-evaluation and addressing the limitations of our computing conditions are crucial steps toward advancing the model's performance. Additionally, exploring alternative language model architectures that can effectively capture contextual information may contribute to bridging the gap between model-generated responses and human-level performance.

\subsection{Product and Practicality Perspective}

The performance of the online consultation service indicates its significant potential for streamlining mental health support with minimal resources. The user experience has been a priority in the product design, and the deployment of the cloud infrastructure ensures easy access via mobile devices. As part of our future improvements, we plan to incorporate an automatic emotion recognition system into the website, enabling the identification of users in distress and facilitating timely intervention. The design and development of our product hold substantial societal value in the field of mental health support, providing a promising avenue for further exploration and refinement.

In terms of the website, we have designed and implemented a modern, cloud-based network architecture that boasts lightweight, scalable, and highly secure features. This architecture allows for low-cost, large-scale model computing sites, enabling widespread accessibility to AI-based question-and-answer services. Our approach serves as a reference for small organisations and enterprises with limited resources, showcasing the possibilities of deploying AI capabilities effectively.


