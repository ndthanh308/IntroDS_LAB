

\section{Limitations and Future Works}

While we have presented promising results with our Psy-LLM model for usage in assisting mental health workers, our study is exploratory in nature, and hence, there exist numerous limitations that we would like to raise in the following.

\subsection{Model Capability and Usage in Real-World}
While there are numerous benefits in deploying an AI-powered Large Language Model for supporting the demand in the mental health sector, one should consider several ethical and practical issues.
Firstly, as a language-based model, the model's output is based purely on the input text. 
However, studies have shown that nonverbal communication is one of the key factors in counselling outcome~\citep{hill1981nonverbal}.
In fact, a well-trained counsellor can often pick up subtle cues even when there is a lack of response from the patient.
Standalone LLM models like Psy-LLM cannot address such an issue (unless techniques like facial emotion detection from the computer vision community are integrated as a unified system~\citep{jaiswal2020facial}).
Furthermore, rapport-building with clients is often a crucial step in clinical psychology.
However, an AI-based model would face severe difficulties in building trusted client relationships.
As a result, it is critical to realise that such an AI-powered system cannot replace real-world counselling setups.
A practical approach would be to pair the model output under the supervision of a trained counsellor as a good psychoeducational tool.
The model output can be used as an initial guideline or suggestion for assisting human counsellors in providing useful and trusted consultations with patients.

\subsection{Data Collections}

Several strategies can be implemented in future work to overcome the limitations in data collection. Firstly, to address the issue of anti-crawler rules on different websites, developing a more robust and adaptable crawler that can handle different anti-crawler mechanisms would be beneficial. The access limitation could involve implementing dynamic IP rotation or utilising proxies to avoid IP blocking. Machine learning techniques, such as automatic rule extraction or rule adaptation, could also help automate handling anti-crawler mechanisms.

Incorporating more advanced data-cleaning techniques can also improve the quality of the crawled data. More advanced data-cleaning procedures may involve NLP methods, such as entity recognition, part-of-speech tagging, and named entity recognition to identify and filter out irrelevant or noisy data. Additionally, leveraging machine learning algorithms, such as anomaly detection or outlier detection, can aid in identifying and removing low-quality or erroneous data points.
In terms of dataset standardisation, establishing a unified standard for data generation in the online domain would greatly facilitate the cleaning process. This could involve collaborating with website administrators or data providers to develop guidelines or formats for data representation. Furthermore, using human annotators or experts in the domain to manually review and clean a subset of the dataset can provide valuable insights and ensure a higher-quality dataset.

However, it is important to acknowledge that achieving a completely clean dataset is challenging, particularly when dealing with large-scale datasets. As such, future work should strike a balance between the manual review and automated cleaning techniques while also considering the cost and scalability of the data cleaning process.

\subsection{Model Improvement}

Increasing the scale of model training by utilising larger models or ensembles of models can enhance the performance and capabilities of the chatbot. Larger models can capture more nuanced patterns and relationships in the data, leading to more accurate and coherent responses.
Exploring different model architectures beyond autoregressive language models may provide valuable insights. Bidirectional models (e.g. Transformer-XL) or models that incorporate external knowledge sources (e.g. knowledge graphs) can improve the chatbot's contextual understanding and generate more informative responses.
Moreover, integrating feedback mechanisms into the training process can help iteratively improve the chatbot's performance. This could involve collecting user feedback on the generated responses and incorporating it into the model training through reinforcement learning or active learning.

Several disadvantages were also identified in the LLM architecture. Firstly, the maximum likelihood training approach of the \emph{WenZhong} model is susceptible to exposure bias, which occurs when samples are drawn from the target language distribution. This bias can lead to errors for which researchers have yet to find effective solutions. Additionally, training the \emph{WenZhong} model multiple times can significantly decrease its quality.
Furthermore, the \emph{WenZhong} model follows an autoregressive architecture, which models joint probability from left to right. This unidirectional training process limits its ability to capture information from all contexts, particularly hindering its performance in tasks requiring reading comprehension that rely on contextual background references.
Similar to the \emph{WenZhong} model, the \emph{PanGu} model also exhibits autoregressive characteristics. Although it inherits the ability to estimate the joint probability of language models, it suffers from the same limitations of unidirectional modelling. It lacks bidirectional context information and may produce duplicate results requiring resolve deduplication.

We also have reservations about the Jieba tokeniser used in the \emph{PanGu} model. Its performance and tokenisation ability need to handle complex Chinese tokenisation accurately. Furthermore, as neural networks and pre-trained models advance, Chinese NLP tasks increasingly demonstrate that tokenisation is only sometimes necessary. Large models can effectively learn character-to-character relationships without word segmentation. For instance, Google is considering discarding tokenisation and using bytes directly. Adopting a more flexible tokeniser could make the model more suitable for various industrial applications, even when sacrificing some performance.


\subsection{User Experience and User Interface}
Enhancing the chatbot's user experience and user interface can significantly impact its adoption and effectiveness. Future work should focus on improving the simplicity, intuitiveness, and accessibility of the website interface. This includes optimising response times, refining the layout and design, and incorporating user-friendly features such as autocomplete suggestions or natural language understanding capabilities.

Furthermore, personalised recommendations and suggestions to users based on their preferences and previous interactions can enhance the user experience. Techniques like collaborative filtering or user profiling can enable the chatbot to understand better and cater to individual user needs.
Usability testing and user feedback collection should be conducted regularly to gather insights on user preferences, pain points, and suggestions for improvement. Iterative design and development based on user-centred principles can ensure that the chatbot meets user expectations and effectively addresses their mental health support needs.


\subsection{Ethical Considerations and User Privacy}
As with any AI-based system, ethical considerations and user privacy are paramount. Future work should address these concerns by implementing robust privacy protection mechanisms and ensuring transparency in data usage. This includes obtaining explicit user consent for data collection and usage, anonymising sensitive user information, and implementing strict data access controls.
Developing mechanisms to handle potentially sensitive or harmful user queries is crucial. The chatbot should have appropriate safeguards and guidelines to avoid providing inaccurate or harmful advice. Integrating a reporting system where users can report problematic responses or seek human intervention can help mitigate potential risks.
Furthermore, monitoring and auditing the chatbot's performance and behaviour can help identify and rectify biases or discriminatory patterns. Regular evaluations by domain experts and user feedback analysis can improve the chatbot's reliability, fairness, and inclusivity.



While this project has made significant progress in developing an AI-based chatbot for mental health support, there are various limitations and areas for improvement. Overcoming challenges related to data quality, model performance, ethical considerations, and user experience will contribute to the overall effectiveness and reliability of the chatbot. By addressing these limitations and exploring future research directions, we can continue to advance the field of AI-powered mental health support systems and provide valuable assistance to individuals in need.


\section{Conclusion}

In conclusion, our project on Psy-LLM, an exploratory study on using Large Language Models as an assistive mental health tool, has been successfully completed and implemented. While there are areas identified for improvement based on specific evaluation indicators, we are confident that with improved equipment conditions, we can enhance the performance of this platform. The experimental results obtained from this project hold significant potential to contribute to the fields of supportive natural language generation and psychology, driving advancements at the intersection of these domains. The deployment of such a system offers a practical approach to promoting the overall mental well-being of our society by providing timely responses and support to those in need.





