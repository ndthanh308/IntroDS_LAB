\section{Methodology}

%%%AAA: Sto section ths methodologias den kaneis kamia anafora sto Figure 3 poy deixnei to overview ths methodou. Mia tetoia anafora einai apolytws aparaithth. Epishs, tha eprepe to figure 3 na einai kai "odhgos" sthn peigrafi ths methodou: ayth twra einai flat - ena reon keimeno apo thn arxh ws to telos. Antitheta, to figure diakrinei stages ta opoia tha antistoixousan poly fysika se ypoenothtes ths perigrafhs, oi opoies tha eishgagan xrhsimi domi sthn parousiasi.  

% Figure environment removed


%\vspace*{0.2cm}\noindent\textbf{Problem formulation.} 
% Let $O$ be the set of Objects,  $S$ be the set of
%  States and $\textit{I}$ the set of
%   Images which consists of the disjoint sets ${I^{S}}$ and ${I^{U}}$ that are used during the training and testing phase respectively. 
%    Each image $i_{k} \in \textit{I}$  contains an object $o_{i} \in O$ which  is situated in a state $s_{j} \in S$. The OSC task deals with the yielding  of a  predicted state label $sp_{j} \in S$ for an image $i_{k} \in {I^U}$ that has been given as an input. In the zero-shot variation of OSC, ${S^{S}} 
%   \not \supseteq {S^{U}}$, i.e. some of the states contained in the testing images do not appear in the training images. 
Let $O$ denote the set of objects, $S$ denote the set of states, and $I$ denote the set of images, which is partitioned into the training set $I^T$ and the testing set $I^U$. Each image $i \in I$ contains an object $o \in O$ that is in a state $s \in S$. The goal of OSC is to predict the state label $s \in S$, given an object $o$ appearing in an image $i \in I^U$ as input. In the zero-shot variation of OSC, the set of states in the testing images $S^U$ is  not a subset of the set of states in the training images $S^S$, i.e., there exists some states in the testing set that do not appear in the training set. It is important to note that although the set of object classes does not directly affect the task, its size is proportional to the complexity of the problem. 

% \vspace*{0.2cm}\noindent\textbf{Approach.}

\subsection{Overview}
% Our method is inspired by works which address the problem of zero-shot object classification \cite{}. The main idea behind this line of work is that the necessary information for the classification of the unseen classes can be found in a Knowledge Graph (KG) if processed appropriately by  a Graph Neural Network (GNN). Obviously, the most crucial component of this approach lies in the combination of the visual information stemming from the training images  and referring to the seen classes  with the semantic information  stemming from the KG  and referring to the unseen classes.
The proposed method draws inspiration from prior research on zero-shot object classification and leverages the potential of KGs and GNNs to classify previously unseen objects. The fundamental idea behind this approach is that the semantic information stored in the KG can be processed by the GNN and then used in conjunction with visual information from training images. This technique enables the model to generalize to new object classes by leveraging the semantic information encoded in the KG.



% More in detail, the GNN architecture is adopted to the architecture of the Classifier  that is used for the training on seen classes, the GNN last layer has the same size  with the Classifier last layer. This way the GNN can produce semantic embedding features that correspond to all the classes, both seen and unseen, that will be encountered during the inference. These embedding features  replace the last layer of the Classifier. Holding this layer fixed, the body of the Classifier is then fine-tuned with the training images.

GNNs  are designed by default to operate on graph-structured data, such as KGs~\cite{Monka2022}. KGs are typically represented as  labeled multi-graphs, where nodes correspond to entities, and edges represent the relationships between them. GNNs process this graph by iteratively aggregating information from neighboring nodes, using neural network-based operations.

At each iteration, a GNN receives a feature vector for each node in the graph, which is initially set to the node's embedding vector. Then, the GNN performs a message-passing step, where it aggregates information from neighboring nodes, based on the edge weights and the features of the nodes. This message-passing operation can be formulated as a neural network layer, which applies a learnable function to the features of the neighboring nodes and returns an aggregated message for each node.

After the message-passing step, the GNN updates the node features by applying a learnable transformation that takes into account the original features of the node and the received messages from its neighbors. This updated feature vector is then passed to the next iteration of the message-passing step. The process continues until a fixed number of epochs or convergence is achieved.
%%%AAA: Endexetai na mas rwthsoun gia tis times aytwn twn parametrwn?


In the method that we are proposing,  a GNN architecture is incorporated into the classifier that is for trained on seen classes. In particular, the last layer of the GNN is designed to have the same size as the last layer of the classifier. This enables the GNN to generate semantic embedding features that correspond to all classes, including both seen and unseen classes that will be encountered during the inference phase. Subsequently, the semantic embedding features replace the last layer of the classifier, while keeping this layer fixed. The body of the classifier is then fine-tuned with the training images to optimize the overall model for state recognition.


% \vspace*{0.2cm}\noindent\textbf{GNN Details.} 
The graph neural network  that we utilize is the
Transformer Graph Convolutional network (Tr-GCN)\cite{nayak:tmlr22} which is capable of combining input sets non-linearly by utilizing multilayer perceptrons and self-attention.  Overall, we experimented with four different architectural frameworks. Further details are provided in \autoref{sec:abl} and in the supplementary material.
We leverage the aforementioned property of Tr-GCN to train a permutation invariant non-linear aggregator that captures the intricate structure of a common sense knowledge graph. Tr-GCN is an inductive model that learns node representations by aggregating local neighborhood features. This allows  the learned model  to make predictions on new graph structures without retraining, rendering it well-suited for zero-shot learning. It is worth noting that a similar network architecture has been effectively employed for zero-shot object classification~\cite{nayak:tmlr22}.

% A critical aspect of the proposed method involves calibrating the weights of the GNN in a manner that its predictions in the semantic space are useful for the classifier deployed in the visual space. To accomplish this, we adopt an approach based on prior research \cite{Kampffmeyer2019, Wang2018b, nayak:tmlr22} that involves learning the semantic class representations by minimizing the L2 distance between the learned class representations and the weights of a fully connected layer in a ResNet classifier pre-trained on the ILSVRC 2012 dataset \cite{russakovsky2015imagenet}. Once the class representations are learned, we fix them and fine-tune the ResNet backbone using the training images from the dataset.




% \vspace*{0.2cm}\noindent\textbf{Building of the KG.}
% The KG is created by the querying  of a common sense repository. The repositories that we are ConceptNet \cite{} and WordNet\cite{}. The procedure takes place as follows. Initially we create a set of nodes that correspond to the target stace classes. Subsequently, the repository is queried for each of these nodes and its neighbours in the repository of  added to the KG if  certain criteria are met (see ablation section for more details). This procedure is repeated for the newly added nodes and henceforth until a number of hops has been reached.  

\subsection{The proposed OaSC pipeline}
Overall, the proposed pipeline (see \autoref{fig:pipeline}) consists of four stages: (1) the creation of the KG, (2) the production of the semantic embeddings, (3) the fine-tuning of the classifier and, (4) the deployment of the fine-tuned classifier.

\vspace*{0.2cm}\noindent\textbf{Construction of the KG (Stage 1)}:
To create the KG we query a common sense repository. The goal is to offer a solution that can generalize,  instead of having to create our own KG tailored to the entities at hand and the relationships they have.  The process begins by generating a set of nodes that correspond to the target state classes. Then, we query the repository for each of these nodes and add their neighbors to the knowledge graph if they meet specific criteria (see the ablation section for further information). We repeat this process for the newly added nodes until we reach a specified number of hops.

Building a KG in this manner offers a number of advantages in comparison to  custom-made approaches. First,  being more problem-agnostic this approach is more generic than hand-crafted methods, and allows the same KG to be used for different variations of the task at hand. Second, this property enables transfer learning since KGs can be reused  in related problems. Moreover, their creation does not rely on expert knowledge which is expensive and time-consuming.  The trade-off is that KGs of this type are prone to the introduction of noisy information. Besides, the structured representation of relationships between entities and concepts that KGs provide  can be leveraged to generate robust embeddings for zero-shot learning.

% In comparison, language models, such as BERT~\cite{devlin2018bert}, often rely on large amounts of unstructured text data to generate embeddings. While language models are highly effective at capturing semantic relationships between words and phrases, they can also be prone to create associations between concepts that are not actually related. This can lead to noisy or unreliable embeddings, which can in turn degrade the performance of zero-shot learning models. By contrast, the structured nature of KGs allows for more accurate and precise capture of relationships between entities and concepts, leading to more robust embeddings that can improve the accuracy and reliability of zero-shot learning models~\cite{brown2020language}.


\vspace*{0.2cm}\noindent\textbf{Computation of semantic embeddings (Stage 2)}:
The KG that was created in the Stage 1 is passed to  a GNN and processed in the manner described previously. The procedure results in the computation of semantic embeddings for all target state classes. These embeddings serve as the last layer of the CNN classifier that is utilized during Stages 3 and 4.

A critical aspect of this procedure involves calibrating the weights of the GNN in a manner that its predictions in the semantic space, i.e. semantic embeddings, are useful for the classifier deployed in the visual space during Stage 3 and 4. To accomplish this, we adopt an approach based on prior research~\cite{Kampffmeyer2019, Wang2018b, nayak:tmlr22} that involves learning the semantic class representations by minimizing the L2 distance between the learned class representations and the weights of a fully connected layer in a ResNet classifier pre-trained on the ILSVRC 2012 dataset~\cite{russakovsky2015imagenet}.  


\vspace*{0.2cm}\noindent\textbf{Fine-tuning of the Classifier (Stage 3)}:
The semantic embeddings that were computed in Stage 2 are incorporated  in  a classifier pre-trained on object classification that uses a  ResNet backbone. Namely,  they constitute the last layer of the network, i.e. the part which corresponds to the  representations of the target classes that are used for the prediction. Consequently, the classifier is re-trained for the classification  of the target state classes with the input images that are passed on  containing solely states belonging to the training set (seen states).  During this fine-tuning procedure the weights of the last layer of the classifier remain fixed so that the learned representations of Stage 2 can not be altered. As a consequence, the weights of the previous layers, which are not fixed, are updated in order to adapt to the ``frozen'' weights of the last layer.
 

\vspace*{0.2cm}\noindent\textbf{Deployment (Stage 4)}:
After the procedure of the fine-tuning is completed, the classifier can be utilized for  prediction. It should be noted that the classifier is suitable for  the prediction of either only unseen classes, i.e. zero-shot classification, or both seen and unseen classes, i.e. generalized zero-shot classification.

% \subsection{Pipeline}

% Overall, the pipeline of our method consists of four stages (\autoref{fig:pipeline}}). During \textbf{Stage 1}, the KG is constructed.

% \vspace*{0.2cm}\noindent\textbf{Construction of the KG (Stage 1)}:
% The KG creation process involves querying a common sense repository to enable generalization instead of creating a custom KG tailored to specific entities and relationships. Initially, nodes corresponding to the target state classes are generated. The repository is then queried for each node, and neighbors meeting specific criteria are added to the knowledge graph. This process continues for the newly added nodes until a specified number of hops is reached. More details can be found in the ablation section.


% \vspace*{0.2cm}\noindent\textbf{Computation of semantic embeddings (Stage 2)}:


% \vspace*{0.2cm}\noindent\textbf{Finetuning of the Classfier (Stage 3)}:

% \vspace*{0.2cm}\noindent\textbf{Deployment  (Stage 4)}: