\section{Experimental Evaluation}

\newcommand{
  \pbt}{\color{blue}{}
}

\begin{table*}[t]
    \centering

    \begin{tabular}{|l|rrr|rrrrrr|}

\hline\hline 
\textbf{Dataset} & \textbf{Train}  &  \textbf{Val}   &  \textbf{Test} & \textbf{Seen} & \textbf{Unseen} & \textbf{Objects} & \textbf{VOSC} & \textbf{TOSC} & \textbf{S\textbackslash O} \\ \hline \hline

OSDD \cite{gouidis2022} &   6,977 & 1,124  & 5,275 & 5 & 4 & 14 & 35 &126 &2.36 \\ \hline 
CGQA-states \cite{Mancini2022} &   244 & 46 & 806 & 2 & 3 & 17  &41 & 75 & 1.71  \\ \hline
MIT-states \cite{Isola2015} &  170 & 34 & 274 & 2 & 3 & 14 & 20 &  70  & 1.57 \\ 
 
   \hline\hline 
  \end{tabular}
 

  
   \caption{Dataset details. Train/Val/Test: Number of Training/Validation/Testing Images. Seen/Unseen: Number of seen/unseen State classes. Objects: Number of Object classes. VOSC/TOSC: Valid/Total Object-State combinations. S\textbackslash O: Average number of states than an Object can be situated in.}
    \label{tab:datasets}
\end{table*}


Our study involves a sequence of experiments that entail comparing our approach to another SoA model, as well as conducting an extensive ablation study to investigate various aspects of the problem. Specifically, we aim at an in depth exploration of three Hypotheses. First, we examine the degree to which the KG contributes to the success of the OSC task. Second, we evaluate the impact of the GNN architecture on the method's overall performance. Additionally, we investigate whether knowledge of the object class has an effect on the performance of the OSC task. The previous hypotheses can be formulated as follows:

\vspace*{0.1cm}\noindent\textbf{Hypothesis 1}: The KG is beneficial to the task. Its impact depends primarily on the type of the knowledge it contains. 

\vspace*{0.1cm}\noindent\textbf{Hypothesis 2}: The GNN architecture is crucial  to the performance of the method. 

\vspace*{0.1cm}\noindent\textbf{Hypothesis 3}:\label{hyp:3} The knowledge of an object class is not decisive for the prediction of its state. Therefore, a method that is agnostic to the object class, can perform equally well to  a method that relies on it.
%%%AAA: To "or better" alougetai too much... To na ksereis to antikeimeno mporei na mhn voitha. Wstoso, giati na dyskoleyei thn katastasi???



\subsection{Implementation and evaluation issues}

\noindent\textbf{Implementation details}: 
The GNN was trained following the method outlined in Nayak et al. \cite{nayak:tmlr22}. The model was trained for 1000 epochs on 950 randomly selected classes from the ILSVRC 2012 dataset \cite{russakovsky2015imagenet}, while the remaining 50 classes were held out for validation. The model with the lowest validation loss was chosen to generate the seen and unseen class embeddings using the graph. For the seen classes, the embeddings were frozen, and a pre-trained ResNet101-backbone was fine-tuned on the individual datasets for 50 epochs using stochastic gradient descent  with a learning rate of 0.0001 and momentum of 0.9.

% For the training of the  GNN we follow the strategy propose in \cite{nayak:tmlr22} and train the model for 1000 epochs on 950 random classes
% from the ILSVRC 2012 \cite{russakovsky2015imagenet} while the remaining 50 classes are used for validation. The model with
% the least loss on the validation classes is used to generate the seen and unseen class embeddings with
% the graph.  We freeze the class embeddings for the seen classes and fine-tune a pretrained ResNet101-backbone on the individual datasets for 50 epochs using SGD with a learning rate 0.0001 and
% momentum of 0.9. 


% Currently with the exception of the OSDD dataset \cite{},  there are not exclusive object states dataset available, but rather attributes  dataset which include among their classes and object states. Therefore, we adopt two of the most popular attributes  datasets \cite{Isola2015} \cite{Mancini2022}  to our needs by taking the subsets that refer to object states in order to be used in the context of the experimental evaluation.

\begin{table*}[t]
	\small
    \centering
     % \resizebox{1\textwidth}{!}
     % {\begin{minipage}{\textwidth} 
     \begin{threeparttable}
    \begin{tabular}{|cc|c|c|c|c|c|c|c|c|c|c|c|c|c|c|}
    
   \hline \hline 

      
 % \diagbox[innerleftsep=.5cm,innerrightsep=0pt]{{\bf \multirow{2}{*}{Method}}}{{\bf \multirow{2}{*}{Dataset}}} 
 
 


 
 \multirow{2}{*}{\textbf{\centering  Method}}  & \multirow{2}{*}{\textbf{\centering  Version}}  &\multicolumn{4}{|c|}{\textbf{OSDD}}  & \multicolumn{4}{|c|}{\textbf{CGQA-States}}  & \multicolumn{4}{|c|}{\textbf{MIT-States}}  \\      \cline{3-14} 

& &\textbf{Seen} & \textbf{Unseen}   & \textbf{HM} & \textbf{AUC} & \textbf{Seen} & \textbf{Unseen}   & \textbf{HM} & \textbf{AUC}
& \textbf{Seen} &\textbf{Unseen}  & \textbf{HM} & \textbf{AUC}
 \\ \hline \hline
 

   



\hline  

&OO & 84.2 &  18.2  & 14.0 &  6.7
 & 93.2 & 45.7 & 33.9 & 24.7
& 97.8 &  55.5 &  37.5 &  30.6 \\ 

AoP\cite{nagarajan2018attributes}  &OW\tnote{\dag} & 69.7 &  33.3  & 21.6 &  9.2
 & 90.3 & 40.1 & 22.5 & 13.2
& 38.7 &  12.3 &  7.2 &  1.3 \\ 

 &CW\tnote{\dag} & 75.9 &  41.1  & 28.7 & 13.4
 & 95.5 & 50.0 & 35.6 & 27.7
& 48.5 &  20.8 &  15.1 &  4.1\\  \hline


 & OO & 31.2 &     39.8  &  23.8 & 9.2
     & 96.7 & 13.0 & 14.0 & 6.2
 & 99.8 & 20.7 &   20.7 & 10.3 \\  
LE+\cite{misra2017red}&   OW\tnote{\dag} & 71.6 &     14.3 &  20.8 & 6.5
     & 76.7 & 11.1 & 9.5 & 3.0
 & 63.6 & 14.6 &   20.3 & 7.1 \\  

 & CW\tnote{\dag} & 68.6 &     31.7  &  34.5 & 16.9
     & 93.5 & 16.1 & 16.1 & 8.1
 & 99.4 & 20.5 &   19.4 & 10.0 \\    \hline

 &OO & 85.5 &  67.2  & 38.5 &  27.5
 & 99.0 & 17.1 & 16.5 & 8.5
& 99.2 &  9.5 & 17.2 &  8.9 \\ 

 TMN\cite{purushwalkam2019task} &OW\tnote{\dag} & 73.4 &  43.6 & 33.7 &  19.0
 & 99.0 & 17.1 & 16.5 & 8.5
& 69.7&  18.4 & 22.4 & 6.3 \\ 


 &CW\tnote{\dag} & 71.5 &  49.8  & 34.9 &  20.7
 & 97.0 & 76.0 & 39.9 & 32.3
& 84.9 &  30.7 & 27.4 &  16.1 \\   \hline
 
 &OO & 83.2 &     36.7  &  28.3 & 16.3 
     & 98.5 & 66.4 & 34.3 & 27.2
 & 97.3 & 29.1 &   29.6 & 17.3 \\  

 SymNet\cite{Li2020}& OW\tnote{\dag} & 77.7 &     14.0  &  21.1 & 7.5 
     & 94.0 & 7.1 & 13.2 & 6.1
 & 79.3 & 17.2 &   10.2 & 5.1 \\  

  & CW\tnote{\dag} & 77.7 &     59.4 &  44.2 & 31.1
     & 95.5 & 27.4 & 39.4 & 24.4
 & 96.9 & 27.5 &   26.8 & 15.7 \\    \hline

\hline  

 &OO & 76.1 &  51.1  & 35.9 &  25.4
 & 95.7 & 72.8 & 21.9 & 10.1
& 97.6 &  49.4 &  21.8 &  10.2 \\ 


  Compcos\cite{Mancini2022}    &OW\tnote{\dag} & 79.9 &     3.7  &  30.1 & 22.1 
     & 86.8 & 42.8 & 7.7 & 3.4
 & 97.3 & 29.1 &   28.3 & 16.9 \\  


  & CW\tnote{\dag} &   81.7 &  33.2  & 38.7 & 23.8
   & 94.2 & 73.9 & 48.1 & 41.5  
   &   94.6 & 33.7 &   44.9 &  23.8 \\
%      Compcos OW& 79.9 &     3.7  &  6.9  & 2.5 
%      & 86.8 & 42.8 & 29.8 & 17.0
%  & 97.3 & 29.1 &   28.3 & 16.9 \\  

%  Compcos (Object-Oracle ) & 76.1 &  51.1  & 27.1 &  18.7 
%  & 95.7 & 72.8 & 41.1 & 35.4 
% & 97.6 &  49.4 &  42.4 &  33.2 \\ 

%   Compcos CW\tnote{\dag} &   81.7 &  33.2  & 22.9 & 13.4 
%    & 94.2 & 73.9 & 38.7 & 32.6  
%    &   94.6 & 33.7 &   27.7 & 18.2\\  
  
    \hline  \hline 
 % \multicolumn{2}{|c|}{\centering  OaSC CN+WN\_H2\_TH} 
 % & 86.5 & 64.2 & 45.6 & \textbf{35.4} & 97.1 & 68.6 & \bf 43.0 & \bf 35.0 & 85.7 & 69.6 & 52.7 & 40.9 \\ 

 %  \multicolumn{2}{|c|}{\centering  OaSC  CN+WN\_H3\_TH} 
 % &  85.8 & 65.8 & \textbf{47.3} & 32.3 & 81.2 & 59.7 & 38.8 & 28.6 & 83.9 & 66.9 & \bf 57.2 &  \bf 46.5  \\ \hline  
  \multicolumn{2}{|c|}{\centering  OaSC } 
  & 86.5 & 64.2 & \bf 45.6 & \textbf{35.4} & 97.1 & 68.6 & \bf 43.0 & \bf 35.0 & 85.7 & 69.6 & \bf 52.7 & \bf 40.9 \\  \hline 


% CN+WN\_H3\_TH & 87.1 & 56.3 & 44.6 & 31.9 & 97.1 & 60.5 & 41.0 & 32.5 & 83.3 & 68.6 & 55.9 & 41.0 \\ 
% CN\_H2\_TH & 85.7 & 63.7 & 45.6 & 34.5 & 97.1 & 70.0 & 43.5 & 35.6 & 85.7 & 70.2 & 51.6 & 40.5 \\ 
% CN\_H2 & 86.4 & 60.6 & 45.1 & 34.3 & 97.1 & 73.4 & \textbf{46.3} & \textbf{39.5} & 88.1 & 69.6 & \textbf{56.2} & \textbf{43.5} \\ 

 



  
  
  \end{tabular}
  

   \caption{   \label{tab:table_aggr}Aggregate results. Seen: Best Accuracy on seen classes. Unseen: Best accuracy on unseen classes. HM: Best harmonic mean. AUC: Area under curve for the  pairs of accuracy for seen and unseen classes.  OO: Object-Oracle version. OO: Open-World Vversion. CO: Closed-World version.
   % CN: ConceptNet-based model. WN: WordNet-based model. H2(3): Maximum number of hops equal to 2(3). TH: Thresholding policy for the nodes of the KG.
   }

\footnotesize
\begin{tablenotes}

\item[\dag] Serves as external reference but is not considered a baseline due to violation of experiment assumption.

\end{tablenotes}
        \end{threeparttable}

     % \end{minipage}}
   
\end{table*}

\vspace*{0.2cm}\noindent\textbf{Datasets}: 
At present, there is a lack of datasets exclusively dedicated to object states, with the exception of the OSDD~\cite{gouidis2022} which is a dataset tailored for state detection. Instead, existing attribute datasets include object states among their classes. To address this, we utilized two of the most widely used attribute datasets~\cite{Isola2015, Mancini2022} and extracted subsets that specifically relate to object states for use in our experimental evaluation. Regarding the OSDD, we extracted the bounding boxes of the original images in order to create images suitable for the OSC task.  The complexity of each dataset can be assessed primarily  by (a)~the number of unseen state classes and (b)~the average number of states per object class. 
The details for the three  datasets are presented in  \autoref{tab:datasets}. 

\vspace*{0.1cm}\noindent\textbf{Metrics}: 
Our evaluation protocol follows the standard generalized zero-shot evaluation described in~\cite{Purushwalkam}:  we calculate the Area Under the Curve (AUC)   measuring the accuracy on both seen and unseen compositions at different operating points based on the bias term that is added to the scores of the unseen classes.  The optimal zero-shot performance occurs when the bias term is positive, leading the classifier to prioritize the unseen labels. Conversely, the best seen performance is achieved with a negative bias term, which result in a focus on the seen labels. Additionally, we report the best harmonic mean (HM) which expresses balance between the seen and unseen accuracy, respectively.

\vspace*{0.1cm}\noindent\textbf{Comparison with SoA methods}: 
% Since there are no actual zero-shot state classifiers, we utilize SoA methods from the fields of  czsl and zero-shot attribute classification. In the case of czsl, they only method that can be used for ZS-OSC is  Compcos  which also exhibits the best performance in the czsl task. 
% As there are currently no pure zero-shot state classifiers available, we utilize  the state-of-the-art method from the field of CZSL\cite{Mancini2022} which involves both the prediction of object and state label for an image is  the most related field to to OSC.  We report the methods performance for three different settings: closed world, open world and object-oracle. For the first setting the method has to predict only among the valid object-state pairs, whereas for the second the method has to predict among all object-state pairs. For the third setting, all object labels are set to the generic term \'object\' enabling thus the method to predict only the state label. Although the closed world setting violates the zero-shot assumptions we include it as a baseline.
Given that there are currently no zero-shot state classifiers available, we resort to employing   5 state-of-the-art models \cite{misra2017red,nagarajan2018attributes,purushwalkam2019task,Li2020,Mancini2022}
  from the field of CZSL that deal with predicting both object and state labels and are, therefore, closely related to OSC. As these models are capable of producing state labels, they can be used in the context of OSC without any modifications.
We evaluate the performance of this approach on three different versions: closed world, open world, and object-oracle: 
\begin{itemize}
    \item {\bf Closed World (CW) version}: the method is tasked with predicting only among the valid object-state pairs.
    \item  {\bf Open World (OW) version}: the method is tasked with predicting  among all object-state pairs. 
    \item {\bf Object Oracle (OO) version}: all object labels are replaced with the generic term ``object'', allowing the method to solely predict the state label.
\end{itemize}
 While the closed world version setting violates the zero-shot conditions since it assumes that the valid states for each object are known in advance, we include it as a baseline for comparison. Moreover, the open world version is less generic than our approach since it presupposes that the set of object labels to which the states corresponds is closed, i.e. the same during training and inference, whereas our method is totally agnostic to this parameter. In addition, both the closed and the open world versions of the models make use of the information corresponding to the object categories, something that violates the object-agnostic assumption. Therefore, the most fair comparison to our method is the object oracle version of the models. However, we report  the results of the  closed  and open world version of each model as frames of reference. 
% Specifically, in the former case we can only use the Compcos method \cite{Mancini2022}, which has demonstrated the best performance in the context of czsl.


% The best zero-shot performance is achieved when the bias term is large, predicting only the unseen labels. The best seen performance is achieved when the bias term is negative, predicting only the seen labels.

% % Figure environment removed


\subsection{Results}


\autoref{tab:table_aggr} summarizes the results of the evaluation for the three employed datasets. We report the performance of the version of
our model that was selected by the ablation study described in the next version. It should be noted that this version of the model does not
exhibit the best performance in all categories.
% (further information about the specific characteristics of the two models are provided in the next section).
% Each model is based on a different KG and/or a different calibration. Further information about the specific characteristics of the four models are provided in the next section.   
The results indicate that under the Object Oracle version, our method clearly outperforms the competing methods in both metrics, namely AUC  and HM, across  all three datasets. Furthermore, our method achieves superior performance than the Closed-World setting of all the competing methods in most cases (it   scores best 14 out of 15 cases, e.g.  5 competing models X 3 datasets, in the AUC  metric and  13 out of 15 times in the HM metric,  respectively). This attests to the robustness of our method, since the Closed-World setting makes use of additional information regarding the object classes  and the valid object-state combinations. In the following, we refer only to the performance of the object oracle versions of the competing methods.

The largest performance margin in favor of our method is observed in the MIT-states dataset, with an increase of  10.3\%/ for AUC  and  15.2\% for HM   in comparison to the scores of the best performed competing method (AoP). In the case of the OSDD dataset, there is a difference of  7.9\% for AUC and 7.1\% for HM in favor of our method w.r.t.  TMN method which is the competing method that performs best in this dataset. Finally, for the CGQA-States dataset  a difference of   7.8\%   for AUC and for 8.7\%  HM is observed between our method and the SymNEt model which scores best among the competing methods in this setting.   

% The largest performance margin in favor of our method is observed in the MIT-states dataset, with an increase of 15.2\%/19.7\% for HM  and   10.3\%/15.9\% for AUC between the two versions method and the best of the competing methods (TMN). In the case of the OSDD dataset, there is an increase of  7.9\%/4.8\% for AUC and 8.8\%/7.1\%  for HM. Finally, for the CGQA-States dataset  a difference of 24.9\% for AUC and 9.7\%/5.5\%  for HM is observed. 
% This pattern indicates that our method performs even better than the competing method as the complexity of the dataset increases. 
  % Regarding the absolute performance of the method across the three datasets we see that  it is proportional to  the complexity of each dataset with the greater scores achieved for the MIT-states and the lowest for the CGQA-states respectively. This behavior is also observed in the performance of the majority of the competing methods.
% Overall, the best performance for the OSDD is achieved by the model CN+WN\_H2\_TH, while the model CN\_H2 scores best for the two other datasets.  


The substantial margin by which our proposed object-agnostic OaSC method outperforms the competing object-based method in every experiment supports strongly  the {\bf Hypothesis 3}, namely that that object information does not provide any advantages in the context of zero-shot OSC.
Additionally, the behavior of the three  versions of the competing  models provides further insights regarding the problem. Specifically, the Open-World version performs very poorly, while the performance of the Object-Oracle version can be deemed only average, given the significantly smaller search space (i.e., set of states) in comparison to the search spaces of the Closed (i.e., set of valid object-state pairs) and Open (i.e., set of all object-state pairs) Worlds, respectively.



% Finally, examining the  performance of the models across the three datasets we can see that for  most of the models the scores achieved are proportional to  the complexity of each dataset with the greater scores achieved for the MIT-states and the lowest for the OSDD respectively. 


% The results strongly support \textbf{Hypothesis 3}, which suggests that object information does not confer any advantages in the context of zero-shot Object State Classification, as evidenced by the clear margin of outperformance of our object-agnostic method over the competing object-based method in all experiments.



% Furthermore, the behavior of the three different versions of CompCos provides further insights regarding the problem. Specifically, we observe that the performance of the object-oracle version  

\subsection{Ablation Study}\label{sec:abl}


% We ablate our method across the following categories: the GNN architecture, the KG source, the number of max hops that were used for the creation of the KG and the policy that were followed w.r.t. the inclusion of nodes to the KG. For each ablated model we report the best accuracy achieved on seen and unseen classes, the best harmonic mean and the best AUC for each of the three datasets. The results are presented in \autoref{tab:ablation}.

We conducted a host of ablation experiments across several problem dimensions with  the purpose of selecting the optimal parameters for our model and of 
 investigating more thoroughly the three hypotheses stated previously.  Specifically, we explored the impact of varying the GNN architecture, the KG source, the maximum number of hops used for KG creation, and the policy for including nodes in the KG. Due to space consideration, it is not possible to present the performance exhibited by every ablated  model  that was tested. Instead, we present  aggregated means of all models across each of the ablated dimensions  reporting the  best harmonic mean and the AUC for each of the three datasets, respectively. 
% The results of these experiments are presented in \autoref{tab:abl1} - \autoref{tab:abl3}.

%%%AAA: Parakatw, prwta parousiazeis oles tis diastaseis tou ablation, kai meta ola ta relevant results. Gia na veltiwseis to locality of reference kanto alliws: ablation diastasi 1 - results 1, ablation diastasi 2 - results 2...
 


\vspace*{0.2cm}\noindent\textbf{GNN architecture}:
We experiment with 4 different GNN architectures:  GCN \cite{kipf2016semi}, R-GCN \cite{schlichtkrull2018modeling},   LSTM \cite{hamilton2017inductive} and Tr-GCN \cite{nayak:tmlr22}.The ablation results for the different  architectures are presented in \autoref{tab:abl1}. 
We can see that   the Tr-GCN framework  outperforms the other frameworks in all datasets w.r.t. AUC metric. whereas it scores best w.r.t. HM metric in the OSSD and comes second in the two other datasets. The R-GCN framework exhibits the second-best performance, while the GCN framework comes in third and the LSTM framework exhibits the worst performance respectively. These findings are consistent with prior research in the domain of zero-shot object classification and  substantiate   \textbf{Hypothesis 2}.



\vspace*{0.2cm}\noindent\textbf{KG source}:
% The KG sources that we use are: ConceptNet\cite{speer2017conceptnet} and WordNet\cite{fellbaum2010wordnet}. We also include in our experiments some KGs that were created using information from both sources. We mention also that we attempted to utilize other sources such as Dbpedia\cite{} and WikiData\cite{} but did not succeed at finding the necessary information for the creation of a KG.
We employed two KG sources, namely ConceptNet~\cite{speer2017conceptnet} and WordNet~\cite{fellbaum2010wordnet}, and also experimented with combining information from both sources. Other sources such as Dbpedia~\cite{auer2007dbpedia} and WikiData~\cite{vrandevcic2014wikidata} were also considered, but the necessary information for constructing a KG could not be obtained. Moreover, to assess more accurately the contribution of the KGs we include a ConceptNet-based model in which the target states classes were mapped to other unrelated state embeddings of the KG and a random model  where the embeddings corresponding to the target state classes were generated by a random process. 

Consulting the results in \autoref{tab:abl2}, we can observe that ConceptNet outperforms WordNet in all three datasets, while combining both sources results in  performance gains for the HM metric in all three datasets and for the AUC metric in two of the datasets. The difference in favor of ConceptNet can be attributed to the difference between the type of information that each KG holds. Specifically, ConceptNet contains mainly common-sense knowledge and also includes some lexicographic information, in contrast to WordNet which contains only lexicographic information.  Nonetheless, the fact that the best results are achieved by a model that uses both sources suggests that they may be complementary to each other.  Taken together, these findings offer substantial support for \textbf{Hypothesis 1}.  

Furthermore, we can see that the performance of the model using the random embeddings is very low, whereas the  ConceptNet-based model using unrelated state embeddings achieves a clearly better performance which yet remains significantly lower than that of the other CN-based models. 
The distinction between these approaches can be attributed to the
distribution of their embeddings: the former model employs a balanced and representative distribution enabled by GNN which permits the model to map the learned  representations to the visual information of seen classes during the fine-tuning procedure. In contrast, the latter
model has a completely random distribution which cannot be mapped to the semantic representations. The unrelated embeddings do not provide leverage for the recognition of unseen classes, thus resulting in the overall mediocre performance of the model.  
% The distinction between these approached lies in their
% distribution: the former model employs a balanced and rep-
% resentative distribution enabled by GNN, while the latter
% model has a completely random distribution. This suggests
% that the fine-tuning process can yield competitive seen accuracy even with unrelated embeddings to the target labels as long as the distribution is appropriate. In contrast, achieving accuracy for unseen classes requires an exact mapping
% between the embeddings and the target states







\vspace*{0.2cm}\noindent\textbf{Number of max hops}:
We experiment with a hop equal to 2 and to 3 for both KGs. The results are shown in the first two columns of \autoref{tab:abl3}. We can observe that no consistent pattern can be identified.  The best average performance is achieved for the OSDD dataset at a hop count of 2, while best average performance is exhibited for  the CGQA-State dataset   at a hop count of 3. In the case of MIT-States, there is no clear winner, as hop 2 shows superior AUC and hop 3 exhibits superior HM. This suggests that introducing additional nodes beyond a certain limit may introduce noise, potentially  impacting negatively overall performance in specific cases, as observed in the OSDD dataset. This outcome is consistent with the \textbf{Hypothesis 1}.

\vspace*{0.2cm}\noindent\textbf{Node policy}:
We investigate two strategies for adding nodes to our knowledge graph: indiscriminate inclusion of all neighboring nodes and selective inclusion of only relevant nodes. To determine relevance in ConceptNet, we use the edge weight between the queried node and its neighbors as the inclusion criterion. In WordNet, we use the Wu-Palmer Similarity metric~\cite{wu1994verb} 
between the two nodes. Additionally, in WordNet, we explore a hierarchical policy of accepting candidate nodes only if their ancestors belong to certain generic categories, such as attributes or objects. 

From the results (as shown in the last two columns of \autoref{tab:abl3})   it is evident that adopting this policy leads to significant performance improvements across all three datasets. This finding complements the previous observation regarding the number of hops and further strengthens the notion that the presence of noisy nodes can have a detrimental effect on model performance. These results align with \textbf{Hypothesis 1}.
 

% More details about the characteristics of the different KGs that were used during the ablation  can be found in \autoref{tab:KGS}.

% \begin{table*}[t]
% %	\small
%     % \centering
%       \resizebox{0.73\textwidth}{!}{\begin{minipage}{\textwidth} 
%     \begin{tabular}{|c|cccc|cccc|cccc|}

% \hline\hline
%  \bf \multirow{2}{*}{Method}& \multicolumn{4}{|c|}{\textbf{OSDD}}  & \multicolumn{4}{|c|}{\textbf{CGQA-States}}  & \multicolumn{4}{|c|}{\textbf{MIT-States}}  \\      \cline{2-13} 
%  & \textbf{LSTM}& \textbf{GCN}   & \textbf{R-GCN}& \textbf{Tr-GCN}& \textbf{LSTM}& \textbf{GCN}   & \textbf{R-GCN}& \textbf{Tr-GCN}& \textbf{LSTM}& \textbf{GCN}   & \textbf{R-GCN}& \textbf{Tr-GCN} \\
 
% \cline{2-13}
% \hline

% \textbf{H2\_WN}  &   33.0/18.1 &   30.8/15.4  &   35.1/21.5 &  28.6/13.0  & 
%  37.7/27.5 &   39.9/32.9 &  40.4/31.5 &  38.2/28.1 & 
% 31.1/11.4  &  35.2/22.3 & 43.0/20.0 & 39.7/27.3 \\ 

% \textbf{H2\_CN}  
%  & 38.1/24.6 &  44.0/31.0 &  42.2/29.2 &   40.2/27.7
%  & 43.0/34.0 &   36.2/26.7 & 34.5/24.5 &   39.2/28.8 
% & 44.0/20.1 & 59.2/29.3  & 51.2/30.3 &  53.6/43.7 \\

% \textbf{H2\_CNWN} & 38.4/27.8 & 47.7/35.0 &  37.9/25.2 &  47.1/33.4 & 
%  43.0/32.2&42.6/35.2 &   43.5/33.7 &  35.8/24.5 & 

% 54.0/47.1& 53.8/2.1 &  47.8/37.2 &  52.7/42.7 \\  

% \textbf{H2\_RN}  & 15.7 / 7.1 &  12.3 / 5.4 &  16.9 / 8.0 & 19.4 / 9.3 & 
%  33.7 / 19.0 &   13.1 / 6.8 &     12.8 / 5.8 &   20.1 / 9.0 & 
% 23.0 / 4.3  &   34.7 / 22.1 &  24.7 / 17.6  &  33.8 / 21.1 \\   \hline \hline  

% \textbf{Aggr} & 39.0/25.7 & 40.0/27.0 & 42.9/29.9 &  43.2/30.3 & 28.3/37.8 & 30.6/40.2 &  29.0/38.1 &28.2/38.5 & 47.7/30.7 & 50.7/34.3  & 53.7/36.6 & 51.2/39.8  \\   \hline


    
% \hline
% \end{tabular}
% \end{minipage}}
% \label{tab:abl1}
% \caption{Ablation results for the framework architecture. The first four rows present the performance of four different models for each architecture, whereas the last row presents the aggregated average of all models. The first (second) value in each cell corresponds to the HM(AUC).}

% \end{table*}


\begin{table}[t]
%	\small

       \resizebox{0.81\textwidth}{!}{\begin{minipage}{\textwidth} 
    \begin{tabular}{|c|cccc|}

\hline\hline
 \bf \diagbox[innerleftsep=.05cm,innerrightsep=4pt]{{\bf {Dataset}}}{{\bf {Arch}}} & 
  \textbf{LSTM}& \textbf{GCN}   & \textbf{R-GCN}& \textbf{Tr-GCN} \\
 
%\cline{2-13}
\hline

\textbf{OSDD}  & 39.0/25.7 & 40.0/27.0 & 42.9/29.9 & \bf 43.2/30.3  \\
\hline  
\textbf{CGQA-States}  & 28.3/37.8 & 30.6/40.2 &  \textbf{29.0}/38.1 &28.2/\textbf{38.5} 
  \\ \hline  



\textbf{MIT-States} & 47.7/30.7 & 50.7/34.3  & \textbf{53.7}/36.6 & 51.2/\textbf{39.8}  \\   \hline  



    
\hline
\end{tabular}
\end{minipage}}

\caption{Ablation results for the framework architecture.  The first (second) value in each cell corresponds to the best HM (AUC). } 
% All values are aggregate averages.}
\label{tab:abl1}
\end{table}



\begin{table}[t]
%	\small
    % \centering
       \resizebox{0.72\textwidth}{!}{\begin{minipage}{\textwidth} 
    \begin{tabular}{|c|ccccc|}

\hline\hline
 \bf \diagbox[innerleftsep=.05cm,innerrightsep=4pt]{{\bf {Dataset}}}{{\bf {KG }}} & 
  \textbf{CN}& \textbf{WN}   & \textbf{CN+WN}&  \textbf{IE}&   \textbf{RN} \\ 
 

\hline

\textbf{OSDD}  &43.5/30.5 & 32.6/18.5 &  \bf 45.4/34.7  & 19.4/9.3   & 8.2/3.1\\ \hline

\textbf{CGQA-States}  &  39.2/29.1  & 37.9/27.4 & \bf 44.5/34.7 &  20.1/9.0  & 11.1/5.7 
  \\ \hline



\textbf{MIT-States} & 53.3/\textbf{42.6} & 38.5/26.6  & \textbf{54.0}/42.1    & 33.8/22.1 & 18.6/13.0 \\   \hline  
% \textbf{AGR} & 43.5/30.5 & 32.6/18.5 &  45.4/34.7 & 39.2/29.1  & 37.9/27.4 & 44.5/34.7 & 53.3/42.6 & 38.5/26.6  & 54.0/42.1 \\     


\end{tabular}
\end{minipage}}
\caption{Ablation results for the KG source. The first (second) value in each cell corresponds to the best HM (AUC). CN: ConceptNet. WN: WordNet, WN+CN: Model based on both ConceptNet and WordNet. IE: ConceptNet-Based Model with irrelevant embeddings.  RN:  Model with random embeddings. }
% The values in the three fist columns are aggregate averages.}
\label{tab:abl2}
\end{table}


% \begin{table*}[t]
%	\small
    % \centering
%       \resizebox{0.74\textwidth}{!}{\begin{minipage}{\textwidth} 
%     \begin{tabular}{|c|cccc|cccc|cccc|}

% \hline\hline
%  \bf \multirow{2}{*}{Method}& \multicolumn{4}{|c|}{\textbf{OSDD}}  & \multicolumn{4}{|c|}{\textbf{CGQA-States}}  & \multicolumn{4}{|c|}{\textbf{MIT-States}}  \\      \cline{2-13} 
%  & \textbf{H2\_NP}& \textbf{H2\_TH}   & \textbf{H3\_NP}&  \textbf{H3\_TH}&  \textbf{H2\_NP}& \textbf{H2\_TH}   & \textbf{H3\_NP}
%  &   \textbf{H3\_TH}&\textbf{H2\_NP}& \textbf{H2\_TH}   & \textbf{H3\_NP} & \textbf{H3\_TH} \\
 
% \cline{2-13}
% \hline
% \textbf{CN} & 
% 39.2 /25.5 &   43.0 /28.5 &  40.7 /26.1 & 43.5/31.5
% & 43.0 /32.2 &  38.8 /31.9 & 39.6 /31.5 &  38.5/26.4  &
%  42.5 /17.4 &   48.2 /25.3 & 52.4 /26.1  & 49.2/38.7 \\ 
% \textbf{WN}  & 43.5/30.6 & 43.7/30.7 &   42.4/28.2 &   40.1/26.3 & 
%  42.6/35.2 & 40.5/32.0  &  37.0/27.6 & 36.4/27.1 &
%  59.0/29.7 & 56.6/29.4 & 56.9/27.2   & 54.8/25.6  \\
% \textbf{CN+WN}  & 41.2/28.7 &   41.2/28.5 &   40.0/27.3 & 47.3/32.3 & 
% 43.5/33.7 &   41.6/31.6 &     46.2/39.2 &    38.8/28.6 &
% 51.2/30.2 &  51.8/30.0  &  58.4/28.4  & 57.2/46.5 \\  \hline 
% \textbf{Aggr} &42.3/29.6  &  43.2/30.4 & 39.6/26.6  & 41.0/27.6 &
% 30.1/39.8  & 28.4/37.7 & 22.1/32.3  &  31.4/41.0 &
% 51.7/35.5 & 52.5/36.8 & 44.0/32.1 & 54.8/36.5 \\
% \hline
% \end{tabular}
% \label{tab:abl3}
% \end{minipage}}
% \caption{Ablation results for the number of hops and the threshold policy. The first three rows present the average performance of each KG source combination for each option, whereas the last row presents the aggregated average of all models. The first (second) value in each cell corresponds to the best HM (AUC).}
% \end{table*}


% \begin{table}[t]
% %	\small
%     % \centering
%        \resizebox{0.86\textwidth}{!}{\begin{minipage}{\textwidth} 
%     \begin{tabular}{|c|cc||cc|}

% \hline\hline
%  \bf \diagbox[innerleftsep=.05cm,innerrightsep=4pt]{{\bf {Dataset}}}{{\bf {Arch}}} & 
%   \textbf{H2\_NP}& \textbf{H2\_THR}   &  \textbf{H3\_NP}& \textbf{H3\_THR}
 
% \cline{2-13}
% \hline

% \textbf{OSDD}  & 42.3/29.6  &  \bf 43.2/30.4 & 39.6/26.6  & 41.0/27.6 \\
% \hline
% \textbf{CGQA-States}  &30.1/39.8  & 28.4/37.7 & 22.1/32.3  &  \bf 31.4/41.0 
%   \\ \hline



% \textbf{MIT-States} & 51.7/35.5 & 52.5/\textbf{36.8} & 44.0/32.1 & \textbf{54.8}/36.5 \\   \hline  

% % \textbf{Aggr} &42.3/29.6  &  43.2/30.4 & 39.6/26.6  & 41.0/27.6 &
% % 30.1/39.8  & 28.4/37.7 & 22.1/32.3  &  31.4/41.0 &
% % 51.7/35.5 & 52.5/36.8 & 44.0/32.1 & 54.8/36.5 \\
% \hline
% \end{tabular}
% \label{tab:abl3}
% \end{minipage}}
% \caption{Ablation results for the number of hops and the threshold policy. The first three rows present the average performance of each KG source combination for each option, whereas the last row presents the aggregated average of all models. The first (second) value in each cell corresponds to the best HM (AUC).}
% \end{table*}




\begin{table}[t]
%	\small
    % \centering
       \resizebox{0.75\textwidth}{!}{\begin{minipage}{\textwidth} 
    \begin{tabular}{|c|cc||cc|}

\hline\hline
 \bf \diagbox[innerleftsep=.05cm,innerrightsep=3pt]{{\bf {Dataset}}}{{\bf {Hops/Policy}}} & 
  \textbf{H2}& \textbf{H3}   &  \textbf{NP}& \textbf{THR}
 
\\
\hline

\textbf{OSDD}  & \bf 43.1/30.6  &   41.0/27.6 & 38.8/25.3   & \bf 42.5/28.5 \\
\hline
\textbf{CGQA-States}  &30.3/39.5 & \bf 31.4/41.0 &  25.9/36.0  &   \bf 29.8/39.5
  \\ \hline



\textbf{MIT-States} & 52.3/\textbf{36.9} &  \textbf{54.8}/36.5 & 45.9/31.7 & \bf 56.0/42.3 \\   \hline  






% \textbf{Aggr} &42.3/29.6  &  43.2/30.4 & 39.6/26.6  & 41.0/27.6 &
% 30.1/39.8  & 28.4/37.7 & 22.1/32.3  &  31.4/41.0 &
% 51.7/35.5 & 52.5/36.8 & 44.0/32.1 & 54.8/36.5 \\
\hline
\end{tabular}
\end{minipage}}
\caption{Ablation results for the number of hops (column 1 and 2) and the threshold policy (column 3 and 4). The first (second) column refers to the average performance of  models which are based   on a KG with hop equal to 2 (3). The third (fourth) column refers to the average performance of  models which are based  on a KG created without (with) threshold policy. The first (second) value in each cell corresponds to the best HM (AUC).}
% All values are aggregate averages.}
\label{tab:abl3}

\end{table}


% \vspace*{0.2cm}\noindent\textbf{Results Analysis}:
% Regarding the GNN architecture, we can see that the Tr-GCN framework outperforms the rest of the framework for every different model combination by a clear margin in every dataset.
% The ablation for the different GNN architectures is presented in \autoref{tab:abl1}. We can see that   the Tr-GCN framework  outperforms the other frameworks in all datasets w.r.t. AUC metric. whereas it scores best w.r.t. HM metric in the OSSD and comes second in the two other datasets. The R-GCN framework exhibits the second-best performance, while the GCN framework comes in third and the LSTM framework exhibits the worst performance respectively. These findings are consistent with prior research in the domain of zero-shot object classification and  substantiate   \textbf{Hypothesis 2}.



% Furthermore, we can see that the model with the unrelated embeddings (CN\_H3\_UN\_Tr-GCN) achieves an accuracy in seen classes a performance similar to the model of the same characteristics and standard embeddings (CN\_H3\_Tr-GCN). However, CN\_H3\_UN\_Tr-GCN accuracy in unseen classes and its HM and AUC score is about three to four times inferior to CN\_H3\_Tr-GCN. In contrast, the random model performs poor in all four metrics.  The difference between the embeddings of the CN\_H3\_UN\_Tr-GCN and the random model concerns their distribution: in the former case the GNN allows a balanced and representative distribution, whereas in the latter case it is totally random.
% This indicates that the fine-tuning process can result in competing seen accuracy even if the embeddings utilized are unrelated to the target labels  as long as they are  distributed adequately. In contrast, the accuracy for the unseen classes depends on an exact mapping between the embeddings and the target states. 
% Additionally, it can be observed that the model employing irrelevant embeddings (CN\_H3\_UN\_Tr-GCN) performs similarly to the model using standard embeddings (CN\_H3\_Tr-GCN) in terms of accuracy for seen classes. However, the accuracy for unseen classes, as well as HM and AUC scores, are three to four times lower in CN\_H3\_UN\_Tr-GCN compared to CN\_H3\_Tr-GCN. On the other hand, the random model exhibits poor performance in all four metrics. The distinction between the embeddings of CN\_H3\_UN\_Tr-GCN and the random model lies in their distribution: the former model employs a balanced and representative distribution enabled by GNN, while the latter model has a completely random distribution. This suggests that the fine-tuning process can yield competitive seen accuracy even with unrelated embeddings to the target labels as long as the distribution is appropriate. In contrast, achieving accuracy for unseen classes requires an exact mapping between the embeddings and the target states. 


% Regarding the maximum number of hops (as shown in the first two columns of \autoref{tab:abl3}), no consistent pattern can be identified.  The best average performance is achived for the OSDD dataset at a hop count of 2, while best average performance is exhibited for  the CGQA-State dataset   at a hop count of 3. In the case of MIT-States, there is no clear winner, as hop 2 shows superior AUC and hop 3 exhibits superior HM. This suggests that introducing additional nodes beyond a certain limit may introduce noise, potentially  impacting negatively overall performance in specific cases, as observed in the OSDD dataset. This outcome is consistent with the \textbf{Hypothesis 1}.

% In terms of the maximum number of hops (first two columns of \autoref{tab:abl3}),  no consistent pattern detect can be detected , since in the case of OSDD the best average performance is achieved for hop equal to 2, while in the case of CGQA-State  the best average performance is achieved for hop equal to 3 and in the case of MIT-States there is no obvious winner(superior AUC for hop 2 and superior HM for hop 3). This outcome suggests that the introduction of additional nodes beyond a certain limit introduces noise that could affect adversely overall performance in some instances(in our case, this happens for OSDD dataset). 


% Concerning the node inclusion policy (as shown in the last two columns of \autoref{tab:abl3}),   it is evident that adopting this policy leads to significant performance improvements across all three datasets. This finding complements the previous observation regarding the number of hops and further strengthens the notion that the presence of noisy nodes can have a detrimental effect on model performance. These results align with the hypothesis stated earlier (\textbf{Hypothesis 1}).

% From the previous, it follows that the optimal version of our method should employ  the Tr-GCN arhictecture for its GNN module. Moreover, for the construction of its KG both  Concept and WordNet should be queried and a node inclusion policy should be followed during this process. Finally, regarding the number of maximum hops the optimal number seems to depend on the size of the KG and the type of the dataset. Determining the ideal number of hops may require experimentation and careful consideration of the specific requirements of the task at hand.

% Based on the previous findings, the optimal version of our method would utilize the Tr-GCN architecture for its GNN module. Additionally, for constructing the knowledge graph (KG), querying both Concept and WordNet would be beneficial. During this process, it is recommended to follow a node inclusion policy to ensure comprehensive representation.
% Regarding the number of maximum hops in the KG, the optimal value appears to be dependent on the size of the KG and the characteristics of the dataset. Finding the ideal number of hops may require experimentation and considering the specific requirements of the task at hand.


% Based on our previous findings, we recommend using the Tr-GCN architecture as the GNN module in our method, as it has demonstrated superior performance. Furthermore, querying both the Concept and WordNet repositories is advantageous for constructing the knowledge graph (KG). It is advisable to follow a node inclusion policy during the construction process to ensure a comprehensive representation of the data.
% Regarding the number of maximum hops in the KG, the optimal value depends on factors such as the size of the KG and the characteristics of the dataset. Determining the ideal number of hops may require experimentation and careful consideration of the specific requirements of the task at hand.


% \begin{table}[t]
	
%     \centering
%       \resizebox{0.7\textwidth}{!}{\begin{minipage}{\textwidth} 
%     \begin{tabular}{|l|r|r|r|l|}

% \hline\hline
% \textbf{KG} &   \textbf{N}  &  \textbf{E}   &  \textbf{RT} & \textbf{RC}\\ \hline\hline



% WN\_H2 & 70/54/49 &  321/223/105 &       5 &LX\\ \hline
% WN\_H3 & 429/311/295 &  873/680/655 &       5 &LX\\ \hline\hline


% CN\_H2 &   715/552/504  & 2,132/1,981/1,864  &    13 &CS    \\ \hline
% CN\_H3 & 2,139/1,872/1,788  &  2,542/2,194/2,103 &       24 &CS    \\ \hline 
% CN\_H2\_TH & 611/505/485 & 1710/1521/1415  &       12 &CS  \\ \hline
% CN\_H3\_TH & 12,733/9,839/9,212 &  29,794/25,105/24,292&       29 & CS \\ \hline \hline
  
  
% CN+WN\_H2 & 667/581/506 & 1,906/1,682/1,602  &       13 &CS \\ \hline
% CN+WN\_H2\_TH & 590/492/431 & 1,442/1,167/1,089 &       12 &CS/LX    \\ \hline
% CN+WN\_H3\_TH &  10,165/8,842/7,948 &  26,735/23,176/22,602   &       29 & CS/LX   \\ \hline 
%   \end{tabular}
  

   
%      \end{minipage}}
  
%    \caption{KGs Details. N: Number of Nodes. E: Number of Edges.  RN: Number of Different Relation Types between nodes. RC: Category of Relation Types. CS: Common-Sense. LX: Lexicographic. First/Second/Third number in the N and E columns refers to the KG for OSDD/CGQA-States/Mit-States dataset respectively.}

%     \label{tab:KGS}
        
% \end{table}


 



