\section{Introduction}

In our daily lives, we interact with objects regularly for various purposes and in various contexts, \textcolor{black}{
often bringing changes in object states. The object state change can be seen as the effect of the transformation induced by the interaction~\cite{wang2016actions}. %%%XXX: This change can be either temporary (i.e. a bottle of water is opened) or permanent/irreversible (i.e. an apple was chopped into slices) and may affect the appearance, shape, or functionality of the object.
}
% In our daily lives, we interact with objects regularly for various purposes and in various contexts.
%to use them in various goal-oriented contexts in workplaces, domestic, and other environments. 
% Objects may be in different states.
% that can be defined as a subset of perceptible attributes~\cite{Isola2015} that are closely related to potential changes in the appearance, shape, and functionality of objects as a precondition for or an effect of an action (e.g., unfolded, closed, full etc.)~\cite{liu2017jointly}. 
The recognition of object states and state changes is crucial for determining an object's condition and the interaction that was performed or a future one the object could afford~\cite{jamone2016affordances}. These cues highlight the significance of the \textcolor{black}{Object State Classification (OSC) task in computer vision that can leverage the functionality and performance of AI systems in tasks such as learning object affordances~\cite{chuang2018learning}, recognizing interactions~\cite{Wang2016b,Isola2015,liu2017jointly,Mancini2022}, reasoning to achieve an object state change~\cite{Farhadi2009}, recognizing the completion or failure of goals,  recovery from possible mistakes~\cite{schoonbeek2024industreal}, etc.}

%%%XXX during procedural activities

% In Computer Vision, object state classification (OSC) is an important task 
%for inferring an object's functionality 
% and is closely related to action recognition~\cite{Wang2016b}, object detection and classification~\cite{Farhadi2009} and affordance learning~\cite{chuang2018learning}. 

Despite the importance of OSC, the amount of research on this problem is notably limited, particularly when compared with the research on the related area of object classification.
% Given the importance of OSC, the research on state classification is disproportionately low, especially in comparison to the enormous effort that has been invested on the related field of object classification. 
However, this seems to have changed during the last few years as the number of works dedicated to this problem keeps growing~\cite{Isola2015,gouidis2022,Soucek2022,10376814}. \textcolor{black}{Large-scale video datasets~\cite{Grauman_2022_CVPR,10376814} of human-object interactions now offer rich annotation data related to object state changes and define new problems and establish benchmarks and challenges related to object state detection and classification~\cite{Grauman_2022_CVPR}.}


% Figure environment removed


% % Figure environment removed

% Then main motivation behind this line of work has to do with some of the assumptions and the methodology of these approaches.
% Namely, the vast majority of these methods shares the following  characteristics. First, they treat states as  attributes following the generic definition first proposed on \cite{} which considers as  attributes the properties of  objects  that a
% human has the ability  to detect. Second, they do not distinguish w.r.t.  category of the entities, e.g. household objects, faces, animals, etc, the attributes of which are to be inferred but propose a generalized method. Finally,   they attempt to address simultaneously the problems Object Classification and Attribute Classification following the insight that these two problems are interdependent and, therefore, this approach   can result to a mutual gain.


%%% The main motivation behind our research departs from the assumptions and methodology of prior works on zero-shot object classification. Most prior methods consider object states as attributes that can be detected by humans and propose a generalized approach that does not distinguish between different categories of entities. Additionally, these methods aim to address both  object classification and attribute classification simultaneously, assuming that the two problems are interdependent and can result in a mutual gain.

% In this paper, we depart from this approach. First, we consider that treating object states as mere attributes is  not an optimal
% strategy, since  states differ from  attributes in some important aspects,  and therefore   the efficient OSC  poses some unique challenges. More in detail,  attributes can be distinguished in primary and secondary: each object class can be defined by the presence of certain primary attributes (e.g. a bottle must have the form of a container), whereas the   presence or absence of any secondary attribute in a certain object does not affect its class but rather have to do with some of its characteristics which may affect its visual appearance. (e.g. a bottle can be either transparent or not). However, the presence or absence of state in a certain object does not affect the class to which this object belongs and, moreover, the presence or absence of a state can be less visually salient and  comparison to any secondary attribute. This  leads to the result that, typically,  both inter-object (i.e. the visual variation among different objects for the same state/attribute) and intra-object variation (i.e. the visual variation that a given object exhibits   as its state/attribute  changes)   is significantly greater in states than  in attributes and, therefore, much more difficult to be recognized correctly. 

%%% In contrast, this paper takes a different approach. We argue that treating object states as mere attributes is not an optimal strategy, as states differ from attributes in several critical aspects. 
%%% Specifically, attributes are relatively stable and unchanging characteristics of an object, while states refer to the current condition or situation of an object at a particular point in time. 
% In the context of visual recognition, states can be considered as a special subset of  attributes. In general, attributes are typically visual properties that can be observed directly from an object, such as color, shape, or texture. These properties are typically static and do not change over time.
% States, on the other hand, are typically dynamic and reflect the current condition or situation of an object.  
% Equally important,  states  are more difficult to recognize than attributes in  images because they involve a more complex representation of visual information. Attributes are usually defined based on visual properties that are relatively stable across different contexts and appearances. In contrast, states are defined based on changes in appearance or context, which are more subtle and can be affected by many factors. As a result, the accurate recognition of states pose some unique challenges (\autoref{fig:fig2}). 

In the context of visual object recognition, %states can also be viewed as a distinct subset of perceptible object attributes. 
states represent a unique subset of perceptible object attributes.
Attributes typically refer to static visual or other types of properties of objects, such as color, shape, or texture. In contrast, states are defined based on changes in appearance or context, which are more subtle and can be influenced by various factors. Moreover, states provide cues on the dynamic aspects and transformation of an object's physical and/or functional properties as a result of actions. 
% This information is also crucial towards accurate action recognition in images or videos~\cite{Isola2015,liu2017jointly,Mancini2022}. 
% Recognizing states in images is generally more challenging compared to attributes due to the complexity involved in representing visual information. 
% Attributes are typically defined based on visual properties that remain relatively stable across different contexts and appearances. In contrast, states are defined based on changes in appearance or context, which are more subtle and can be influenced by various factors.
Therefore, accurately recognizing states poses challenges such as capturing and modeling the dynamic nature of visual information, identifying subtle changes in appearance, and accounting for contextual variations across all possible objects that can be seen in each specific state.% (see \autoref{fig:fig2}). 
\textcolor{black}{To tackle these challenges, we seek inspiration from the notion and techniques of compositional learning and zero-shot classification~\cite{Saini_2022_CVPR} to attempt disentanglement of objects and the
states classes in images. In essence, we focus on learning prototypical representations of state classes regardless of the object classes to capture state-specific features of, e.g. anything open, closed, plugged, etc, in an open-world setting. 
% with improved generalization and cross-domain applicability against large image sets containing both known and new, previously unknown object categories
} %TODO: SHOULD WE MENTION OPEN-WORLD BUZZWORD HERE OR NOT?

% Addressing these challenges is crucial for achieving accurate state recognition in visual recognition tasks.
%Some examples of these challenges are shown in \autoref{fig:fig2}.

% The state of an object may not be immediately apparent from a single image, and may require additional context, such as the temporal sequence of images or additional sensor data.
% In summary, attributes are static visual properties, while states are dynamic visual properties that reflect the current condition of an object.
% attributes can be categorized as primary or secondary, where the presence of primary attributes defines the object class, while the presence or absence of secondary attributes affects the object's characteristics that may impact its visual appearance. On the other hand, the presence or absence of states does not affect the object's class and can be less visually salient than secondary attributes. 
% For example, an object can have different states depending on its position, orientation, or interaction with other objects, which can result in variations in its appearance, texture, or shape. Recognizing these changes requires a more nuanced understanding of the object's spatial and temporal relationships with its environment, as well as its functional and semantic properties.

%%% In addition, states are often more context-dependent and task-specific than attributes, which means that they may not be applicable or meaningful in all contexts. For instance, the state of "open" or "closed" may only be relevant for certain objects, such as doors, containers, or eyes, and may not make sense or be recognizable in other contexts. Therefore, recognizing states in  images involves more complex reasoning and inference than recognizing attributes, and requires models that can capture and integrate both visual and semantic information from the scene.

%%% A direct consequence of the previous is that states exhibit a significant amount of inter-object and intra-object variation. Inter-object variation means that different objects may exhibit similar states but have different visual appearances, which makes it difficult for a visual recognition system to learn a efficient representation for this state. Inter-object variation means that a single object may exhibit different visual appearances for different states, making it challenging for the system to recognize the correct state. Therefore, recognizing states often requires the model not only to be able to capture fine-grained visual details and subtle differences between similar appearances but also to be able to construct complex representations capturing the great visual variation amongst object situated on the same state (\autoref{imag:ex1}).
% usually, there is a significant amount of inter-object (i.e., the visual variation among different objects for the same state)  and intra-object variation  (i.e., the visual variation that a given object exhibits as its state  changes)  in states, making them more challenging to recognize correctly.

% At a practical level, this means that a classifier having learned the representation of a state for a set of objects might encounter  difficulties to recognize this state on a novel object class. Likewise, a classifier having learned the representation of a given object for a certain set of states might encounter difficulties having to recognize a novel state for this object.


% In practical terms, this means that a classifier trained to recognize a state representation for a set of objects may struggle to recognize this state for a novel object class. Similarly, a classifier trained to recognize a given object for a particular set of states may struggle to recognize a novel state for that object. Therefore, we propose a novel approach that addresses the challenges posed by recognizing object states in zero-shot object classification.

% For example, certain categories of attributes such as those pertaining to colour, texture, size, shape are more easily recognised that the attributes that have to do with the states of the object, such as whether an object is empty or whether it is open.

%%% Moreover,  we think that the grouping together of attributes  referring to widely diverse entities such as household objects, human faces, landscape scenes and animals  fails to acknowledge the enormous differences existing between these categories. Obviously, this approach holds the great advantage of  being able to cope with a great number of object classes. However, this comes at the cost of reduced performance. 
%%% Finally, although we recognize that the simultaneous study of object and state recognition has resulted in important results, we consider that more directed effort has to be invested towards the exclusive study  of state recognition. 

% % Figure environment removed
%and studying the important variation of zero-shot classification.  

% As a result, KGs can enhance the accuracy and robustness of OSC models.
%by providing a powerful tool for knowledge representation and inference.

% % Figure environment removed

Towards this end, we investigate a zero-shot variant for the OSC problem (see \autoref{imag:ex1}) by focusing on images containing household objects. Specifically, we developed and extensively evaluated a novel zero-shot object-agnostic State Classification method (OaSC) that does not rely on object class-related information. 
% (see~\autoref{imag:ex1}). 
Our approach explores the potential benefits of Knowledge Graphs (KGs) as a well-established, powerful tool for structuring and organizing external knowledge that can be applied to various fields, including zero-shot learning. We argue that KGs can enhance the accuracy and robustness of models for the OSC task as they provide structured representations of the relationships among different entities and concepts, enabling the inference of relationships among unseen and seen/known categories.  
The proposed method is the first zero-shot approach that focuses on this problem enabling the recognition of states of previously unseen object classes. Despite its potential practical merits, such a feature is currently not supported by zero-shot attribute classification methods. 
% This variation of OSC may provide important practical merits; i.e., enables a robotic helper to recognize the states of unknown objects. 

%The main advantage of the zero-shot object-aware methods is that the correct classification of an object class can help the recognition of its state. However, in cases where the object class is misclassified the accurate state classification becomes much more challenging if not impossible. The state classification for any object-aware method can either take place after the object class recognition or in parallel. The first approach is not computationally feasible, since it entails the utilization of different state classifiers for each object class. The second approach is less computationally expensive and is followed by most of the object-aware methods currently. A major drawback in this case is that in real-world scenarios when the valid object-state combinations are known beforehand the search space for the classifiers corresponds to the Cartesian product of the objects and the states classes which can be very large. Equally important, these methods require samples of every object and state class during the training, since they are zero-shot w.r.t.  object-state pairs and not w.r.t. states or the object classes per se. Therefore, in contrast to our method, these methods are not tailored to address state classification in an open-world setting for the object classes. 

Zero-shot object-aware methods excel in classifying object classes to facilitate state recognition, yet struggle when an object class is misidentified, making state classification difficult. These methods operate in two stages (classifying the object first and then its state) or in one stage (doing both simultaneously). 
%, which is computationally intensive, or by doing both simultaneously, which is more common and less demanding. 
In both cases, a major limitation is the expansive search space for classifiers in real scenarios, driven by a large set of combinations of object and state classes. Furthermore, such methods require training samples for all object and state classes, making them unsuitable for state classification that is open w.r.t. object classes, unlike object-agnostic approaches like our method.
Consider, for example, a scenario where $500$ different object classes can be situated in $20$ different states. If a two-stage object-aware method is used, 500 different state classifiers should be trained, whereas, in the case of a one-stage object-aware method, the classifier has to consider the $10,000$ labels of all the object/state pairs. In contrast, by following our approach, we employ a single classifier that considers the space of $20$ state labels.
%Besides, it is important to note that since the number of state classes is much more limited than that of object classes it is much easier to know them in advance.
%household objects' states and does not rely on object classification. This aspect of our approach enables the recognition of states in classes of objects that are not known beforehand, a property that current zero-shot attribute classification does not support. Our contributions can be summarized as follows:



Overall, our contributions can be summarized as follows:

\begin{itemize}[noitemsep,topsep=0pt]
%\begin{itemize}
\itemsep0em 
\item We introduce the problem of object-agnostic zero-shot state classification and we propose OaSC, a new method for solving it. In contrast to object-informed zero-shot methods, OaSC does not rely on prior accurate object classification, exhibiting thus greater robustness and applicability.
% We propose a novel zero-shot state classification method that outperforms existing state-of-the-art methods. 
% Notably, our approach is object-agnostic, i.e., its performance does not rely on prior accurate object classification, resulting in greater robustness than other competing methods. To the best of our knowledge, our method is the first of its kind. 
% Notably, our approach is object-agnostic, i.e., its performance does not rely on prior accurate object classification, resulting in greater robustness than other competing methods. To the best of our knowledge, our method is the first of its kind. 
\item 
An extensive experimental evaluation is conducted across 4 datasets and 11 state-of-the-art compositional zero-shot learning methods. Our method achieves a performance that is superior by a great margin.
\item  The ablation study reported explores the strengths and weaknesses of our proposed method in various settings. This analysis provides valuable insights related to the new problem and method.
%into the new OaSC problem towards developing further improvements.

\end{itemize}

%  Overall, our contribution is two-folded: 
% \begin{itemize}
%     \item First, we present a novel zero-shot state classification that achieves greater performance to other SoA methods. Moreover, to the best of our knowledge our method is the  first of its kind to be object-agnostic, i.e. its performance does not depend on a prior accurate object classification, being therefore more robust than the other competing methods.
%     \item Second, we perform an extensive ablation study across a variety of settings. This analysis allows us to assess  the strengths and shortcomings and provides useful hints towards its improvement.  Moreover, it can be proven useful to anyone interesting in extending our method.
% \end{itemize}


% Second, because the recognition of attributes apart from being a highly domain-dependent task also depends heavily on the type of the attributes that are to be inferred. 



% Moreover, we 






% The attribute classification and contextual zero-state generation methods treat states as typical examples of attributes. We constexter that this approach is not optimal since the pose a number of unique challenges. First, because grouping together widely diverse entities such as household objects, human faces, landscape scenes and animals and aiming to predict their equivalent attributes fail to acknowledge the differences between these categories. Obviously, these approaches hold the great advantage of being domain-independent. Second, because the recognition of attributes apart from being a highly domain-dependent task also depends heavily on the type of the attributes that are to be inferred. More in detail, certain categories of attributes such as those pertaining to colour, texture, size, shape are more easily recognised that the attributes that have to do with the states of the object.



% Open Vocabulary vs Zero-Shot


% We found that the performance of these models on attributes stays clearly behind their performance on
% objects revealing a direction for further research.
% Compared to zero-shot image classification, where
% foundation models report very good accuracy, the absolute performance on attributes is surprisingly
% low.

% (Open-vocabulary Attribute Detection)


% scene can be described using a vast number of attributes,
% many of which can exist independently of each other. Due
% to the variety of possible object and attribute combinations,
% it is a daunting task to curate a large-scale visual attribute
% prediction dataset. Existing works have largely ignored
% large-scale visual attribute prediction in-the-wild and have
% instead focused only on domain-specific attributes [19, 43],
% datasets consisting of very small number of attribute-object
% pairs [51], or are rife with label noise, ambiguity and la-
% bel sparsity [38]. Similarly, while attributes can form an
% important part of related tasks such as VQA, captioning, re-
% ferring expression, these works do not address the unique
% challenges of attribute prediction (Learning to Predict Visual Attributes in the Wild)









