\begin{thebibliography}{10}

\bibitem{sutton2018reinforcement}
Richard~S Sutton and Andrew~G Barto.
\newblock {\em Reinforcement learning: An introduction}.
\newblock MIT press, 2018.

\bibitem{zhang2019leveraging}
Ruohan Zhang, Faraz Torabi, Lin Guan, Dana~H Ballard, and Peter Stone.
\newblock Leveraging human guidance for deep reinforcement learning tasks.
\newblock In {\em Proceedings of the 28th International Joint Conference on
  Artificial Intelligence}, pages 6339--6346. AAAI Press, 2019.

\bibitem{littman2015reinforcement}
Michael~L Littman.
\newblock Reinforcement learning improves behaviour from evaluative feedback.
\newblock {\em Nature}, 521(7553):445--451, 2015.

\bibitem{lin2020review}
Jinying Lin, Zhen Ma, Randy Gomez, Keisuke Nakamura, Bo~He, and Guangliang Li.
\newblock A review on interactive reinforcement learning from human social
  feedback.
\newblock {\em IEEE Access}, 8:120757--120765, 2020.

\bibitem{nasiriany2022augmenting}
Soroush Nasiriany, Huihan Liu, and Yuke Zhu.
\newblock Augmenting reinforcement learning with behavior primitives for
  diverse manipulation tasks.
\newblock In {\em 2022 International Conference on Robotics and Automation
  (ICRA)}, pages 7477--7484. IEEE, 2022.

\bibitem{zhang2023dual}
Ruohan Zhang, Dhruva Bansal, Yilun Hao, Ayano Hiranaka, Jialu Gao, Chen Wang,
  Roberto Mart{\'\i}n-Mart{\'\i}n, Li~Fei-Fei, and Jiajun Wu.
\newblock A dual representation framework for robot learning with human
  guidance.
\newblock In {\em Conference on Robot Learning}, pages 738--750. PMLR, 2023.

\bibitem{zhu2020robosuite}
Yuke Zhu, Josiah Wong, Ajay Mandlekar, and Roberto Mart{\'\i}n-Mart{\'\i}n.
\newblock robosuite: A modular simulation framework and benchmark for robot
  learning.
\newblock {\em arXiv preprint arXiv:2009.12293}, 2020.

\bibitem{knox2009interactively}
W~Bradley Knox and Peter Stone.
\newblock Interactively shaping agents via human reinforcement: The tamer
  framework.
\newblock In {\em Proceedings of the fifth international conference on
  Knowledge capture}, pages 9--16. ACM, 2009.

\bibitem{thomaz2006reinforcement}
Andrea~L. Thomaz and Cynthia Breazeal.
\newblock Reinforcement learning with human teachers: Evidence of feedback and
  guidance with implications for learning performance.
\newblock In {\em Proceedings of the 21st National Conference on Artificial
  Intelligence - Volume 1}, pages 1000--1005. AAAI Press, 2006.

\bibitem{najar2020interactively}
Anis Najar, Olivier Sigaud, and Mohamed Chetouani.
\newblock Interactively shaping robot behaviour with unlabeled human
  instructions.
\newblock {\em Autonomous Agents and Multi-Agent Systems}, 34:1--35, 2020.

\bibitem{cui2018active}
Yuchen Cui and Scott Niekum.
\newblock Active reward learning from critiques.
\newblock In {\em 2018 IEEE International Conference on Robotics and Automation
  (ICRA)}, pages 6907--6914. IEEE, 2018.

\bibitem{isbell2001social}
Charles Isbell, Christian~R Shelton, Michael Kearns, Satinder Singh, and Peter
  Stone.
\newblock A social reinforcement learning agent.
\newblock In {\em Proceedings of the fifth international conference on
  Autonomous agents}, pages 377--384. ACM, 2001.

\bibitem{tenorio2010dynamic}
Ana~C Tenorio-Gonzalez, Eduardo~F Morales, and Luis Villase{\~n}or-Pineda.
\newblock Dynamic reward shaping: training a robot by voice.
\newblock In {\em Ibero-American conference on artificial intelligence}, pages
  483--492. Springer, 2010.

\bibitem{griffith2013policy}
Shane Griffith, Kaushik Subramanian, Jonathan Scholz, Charles~L Isbell, and
  Andrea~L Thomaz.
\newblock Policy shaping: Integrating human feedback with reinforcement
  learning.
\newblock In {\em Advances in neural information processing systems}, pages
  2625--2633, 2013.

\bibitem{akinola2020accelerated}
Iretiayo Akinola, Zizhao Wang, Junyao Shi, Xiaomin He, Pawan Lapborisuth,
  Jingxi Xu, David Watkins-Valls, Paul Sajda, and Peter Allen.
\newblock Accelerated robot learning via human brain signals.
\newblock In {\em 2020 IEEE International Conference on Robotics and Automation
  (ICRA)}, pages 3799--3805. IEEE, 2020.

\bibitem{warnell2018deep}
Garrett Warnell, Nicholas Waytowich, Vernon Lawhern, and Peter Stone.
\newblock Deep tamer: Interactive agent shaping in high-dimensional state
  spaces.
\newblock In {\em Proceedings of the Thirty-Second AAAI Conference on
  Artificial Intelligence}. AAAI Press, 2018.

\bibitem{macglashan2017interactive}
James MacGlashan, Mark~K Ho, Robert Loftin, Bei Peng, Guan Wang, David~L
  Roberts, Matthew~E Taylor, and Michael~L Littman.
\newblock Interactive learning from policy-dependent human feedback.
\newblock In {\em Proceedings of the 34th International Conference on Machine
  Learning-Volume 70}, pages 2285--2294. JMLR. org, 2017.

\bibitem{arumugam2019deep}
Dilip Arumugam, Jun~Ki Lee, Sophie Saskin, and Michael~L Littman.
\newblock Deep reinforcement learning from policy-dependent human feedback.
\newblock {\em arXiv preprint arXiv:1902.04257}, 2019.

\bibitem{knox2010combining}
W~Bradley Knox and Peter Stone.
\newblock Combining manual feedback with subsequent mdp reward signals for
  reinforcement learning.
\newblock In {\em Proceedings of the 9th International Conference on Autonomous
  Agents and Multiagent Systems: volume 1-Volume 1}, pages 5--12. International
  Foundation for Autonomous Agents and Multiagent Systems, 2010.

\bibitem{knox2012reinforcement}
W~Bradley Knox and Peter Stone.
\newblock Reinforcement learning from simultaneous human and mdp reward.
\newblock In {\em Proceedings of the 11th International Conference on
  Autonomous Agents and Multiagent Systems-Volume 1}, pages 475--482.
  International Foundation for Autonomous Agents and Multiagent Systems, 2012.

\bibitem{arakawa2018dqn}
Riku Arakawa, Sosuke Kobayashi, Yuya Unno, Yuta Tsuboi, and Shin-ichi Maeda.
\newblock Dqn-tamer: Human-in-the-loop reinforcement learning with intractable
  feedback.
\newblock {\em arXiv preprint arXiv:1810.11748}, 2018.

\bibitem{knox2013training}
W~Bradley Knox, Peter Stone, and Cynthia Breazeal.
\newblock Training a robot via human feedback: A case study.
\newblock In {\em Social Robotics: 5th International Conference, ICSR 2013,
  Bristol, UK, October 27-29, 2013, Proceedings 5}, pages 460--470. Springer,
  2013.

\bibitem{wang2021apple}
Zizhao Wang, Xuesu Xiao, Garrett Warnell, and Peter Stone.
\newblock Apple: Adaptive planner parameter learning from evaluative feedback.
\newblock {\em IEEE Robotics and Automation Letters}, 6(4):7744--7749, 2021.

\bibitem{najar2016training}
Anis Najar, Olivier Sigaud, and Mohamed Chetouani.
\newblock Training a robot with evaluative feedback and unlabeled guidance
  signals.
\newblock In {\em 2016 25th IEEE international symposium on robot and human
  interactive communication (RO-MAN)}, pages 261--266. IEEE, 2016.

\bibitem{chitnis2022learning}
Rohan Chitnis, Tom Silver, Joshua~B Tenenbaum, Tomas Lozano-Perez, and
  Leslie~Pack Kaelbling.
\newblock Learning neuro-symbolic relational transition models for bilevel
  planning.
\newblock In {\em 2022 IEEE/RSJ International Conference on Intelligent Robots
  and Systems (IROS)}, pages 4166--4173. IEEE, 2022.

\bibitem{zhu2021hierarchical}
Yifeng Zhu, Jonathan Tremblay, Stan Birchfield, and Yuke Zhu.
\newblock Hierarchical planning for long-horizon manipulation with geometric
  and symbolic scene graphs.
\newblock In {\em 2021 IEEE International Conference on Robotics and Automation
  (ICRA)}, pages 6541--6548. IEEE, 2021.

\bibitem{shridhar2022cliport}
Mohit Shridhar, Lucas Manuelli, and Dieter Fox.
\newblock Cliport: What and where pathways for robotic manipulation.
\newblock In {\em Conference on Robot Learning}, pages 894--906. PMLR, 2022.

\bibitem{shridhar2023perceiver}
Mohit Shridhar, Lucas Manuelli, and Dieter Fox.
\newblock Perceiver-actor: A multi-task transformer for robotic manipulation.
\newblock In {\em Conference on Robot Learning}, pages 785--799. PMLR, 2023.

\bibitem{xu2021deep}
Danfei Xu, Ajay Mandlekar, Roberto Mart{\'\i}n-Mart{\'\i}n, Yuke Zhu, Silvio
  Savarese, and Li~Fei-Fei.
\newblock Deep affordance foresight: Planning through what can be done in the
  future.
\newblock In {\em 2021 IEEE International Conference on Robotics and Automation
  (ICRA)}, pages 6206--6213. IEEE, 2021.

\bibitem{wang2022generalizable}
Chen Wang, Danfei Xu, and Li~Fei-Fei.
\newblock Generalizable task planning through representation pretraining.
\newblock {\em IEEE Robotics and Automation Letters}, 7(3):8299--8306, 2022.

\bibitem{cheng2022guided}
Shuo Cheng and Danfei Xu.
\newblock Guided skill learning and abstraction for long-horizon manipulation.
\newblock In {\em CoRL 2022 Workshop on Learning, Perception, and Abstraction
  for Long-Horizon Planning}, 2022.

\bibitem{agia2023stap}
Christopher Agia, Toki Migimatsu, Jiajun Wu, and Jeannette Bohg.
\newblock Stap: Sequencing task-agnostic policies.
\newblock In {\em 2023 IEEE International Conference on Robotics and Automation
  (ICRA)}, pages 7951--7958. IEEE, 2023.

\bibitem{li2023behavior}
Chengshu Li, Ruohan Zhang, Josiah Wong, Cem Gokmen, Sanjana Srivastava, Roberto
  Mart{\'\i}n-Mart{\'\i}n, Chen Wang, Gabrael Levine, Michael Lingelbach,
  Jiankai Sun, et~al.
\newblock Behavior-1k: A benchmark for embodied ai with 1,000 everyday
  activities and realistic simulation.
\newblock In {\em Conference on Robot Learning}, pages 80--93. PMLR, 2023.

\bibitem{lozano2014constraint}
Tom{\'a}s Lozano-P{\'e}rez and Leslie~Pack Kaelbling.
\newblock A constraint-based method for solving sequential manipulation
  planning problems.
\newblock In {\em 2014 IEEE/RSJ International Conference on Intelligent Robots
  and Systems (IROS)}, pages 3684--3691. IEEE, 2014.

\bibitem{toussaint2015logic}
Marc Toussaint.
\newblock Logic-geometric programming: An optimization-based approach to
  combined task and motion planning.
\newblock In {\em IJCAI}, pages 1930--1936, 2015.

\bibitem{garrett2020pddlstream}
Caelan~Reed Garrett, Tom{\'a}s Lozano-P{\'e}rez, and Leslie~Pack Kaelbling.
\newblock Pddlstream: Integrating symbolic planners and blackbox samplers via
  optimistic adaptive planning.
\newblock In {\em Proceedings of the International Conference on Automated
  Planning and Scheduling}, volume~30, pages 440--448, 2020.

\bibitem{garrett2021integrated}
Caelan~Reed Garrett, Rohan Chitnis, Rachel Holladay, Beomjoon Kim, Tom Silver,
  Leslie~Pack Kaelbling, and Tom{\'a}s Lozano-P{\'e}rez.
\newblock Integrated task and motion planning.
\newblock {\em Annual review of control, robotics, and autonomous systems},
  4:265--293, 2021.

\bibitem{zhu2023viola}
Yifeng Zhu, Abhishek Joshi, Peter Stone, and Yuke Zhu.
\newblock Viola: Imitation learning for vision-based manipulation with object
  proposal priors.
\newblock In {\em Conference on Robot Learning}, pages 1199--1210. PMLR, 2023.

\bibitem{khatib1987unified}
Oussama Khatib.
\newblock A unified approach for motion and force control of robot
  manipulators: The operational space formulation.
\newblock {\em IEEE Journal on Robotics and Automation}, 3(1):43--53, 1987.

\bibitem{haarnoja2018soft}
Tuomas Haarnoja, Aurick Zhou, Pieter Abbeel, and Sergey Levine.
\newblock Soft actor-critic: Off-policy maximum entropy deep reinforcement
  learning with a stochastic actor.
\newblock In {\em International conference on machine learning}, pages
  1861--1870. PMLR, 2018.

\bibitem{haarnoja2018soft2}
Tuomas Haarnoja, Aurick Zhou, Kristian Hartikainen, George Tucker, Sehoon Ha,
  Jie Tan, Vikash Kumar, Henry Zhu, Abhishek Gupta, Pieter Abbeel, et~al.
\newblock Soft actor-critic algorithms and applications.
\newblock {\em arXiv preprint arXiv:1812.05905}, 2018.

\bibitem{chawla2002smote}
Nitesh~V. Chawla, Kevin~W. Bowyer, Lawrence~O. Hall, and W.~Philip Kegelmeyer.
\newblock Smote: Synthetic minority over-sampling technique.
\newblock {\em Journal of Artificial Intelligence Research (JAIR)},
  16(1):321â€“357, jun 2002.

\bibitem{lane2012decision}
Peter~C.R. Lane, Daoud Clarke, and Paul Hender.
\newblock On developing robust models for favourability analysis: Model choice,
  feature sets and imbalanced data.
\newblock {\em Decision Support Systems}, 53(4):712--718, 2012.

\bibitem{schaul2016prioritized}
Tom Schaul, John Quan, Ioannis Antonoglou, and David Silver.
\newblock Prioritized experience replay.
\newblock In {\em 4th International Conference on Learning Representations,
  {ICLR}}, 2016.

\end{thebibliography}
