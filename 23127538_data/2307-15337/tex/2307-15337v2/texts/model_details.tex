\cref{tab:model} summarizes the models on which we evaluate \methodshort{}. We use \Remark{gpt4} in the main paper and \Remark{chatgpt} in \cref{app:quality_gpt3.5} as the judge in \fastchat{} and \llmzoo{} evaluation.
\begin{table}[H]
  \centering
  \caption{Model evaluated with \methodshort{}. All the open-source models are fine-tuned from \Remark{llama} models.}
    \label{tab:model}
    \begin{tabular}{c|c|c|c}
        \toprule
        Access & Model Name & Institution & Released Date \\\midrule
        \multirow{8}{*}{Open-Source} &
        \Remark{llamachat7B2} \citep{touvron2023llama2} & Meta \& Microsoft & 2023/07\\
        &
        \Remark{llamachat13B2} \citep{touvron2023llama2} & Meta \& Microsoft & 2023/07\\
        &\Remark{openchat13B}~\citep{openllms23} & Tsinghua & 2023/07\\ %
        & \Remark{vicuna7B1.3}~\citep{vicuna2023} & LMSYS & 2023/06\\
        & \Remark{vicuna13B1.3}~\citep{vicuna2023} & LMSYS & 2023/06\\
        & \Remark{vicuna33B1.3}~\citep{vicuna2023} & LMSYS & 2023/06\\
        & \Remark{stablevicuna13B}~\citep{stablevicuna2023}& CarperAI &2023/05 \\ %
        & \Remark{ultralm13B}~\citep{ding2023enhancing} & OpenBMB \& Tsinghua & 2023/05\\
        & \Remark{vicuna7B1.1}~\citep{vicuna2023} & LMSYS & 2023/03 \\\midrule
        \multirow{2}{*}{API-Based} & \Remark{claude}~\citep{claude} & Anthropic & 2023/05\\
        & \Remark{chatgpt} & OpenAI & 2022/11\\
        & \Remark{gpt4} & OpenAI & 2023/03\\
        \bottomrule
    \end{tabular}
  \end{table}
  
  \cref{tab:model_detail} shows sources of the models we use in the paper.
\begin{table}[H]
  \centering
      \caption{The Hugging Face or API endpoints of the models.}
    \label{tab:model_detail}
    \begin{tabular}{c|c|c}
        \toprule
        Access & Model Name & Hugging Face or API Endpoints \\\midrule
        \multirow{8}{*}{Open-Source} &
        \Remark{llamachat7B2} \citep{touvron2023llama2} & meta-llama/Llama-2-7b-chat-hf \\
        &
        \Remark{llamachat13B2} \citep{touvron2023llama2} & meta-llama/Llama-2-13b-chat-hf \\
        &\Remark{openchat13B}~\citep{openllms23} & openchat/openchat \\
        & \Remark{vicuna7B1.3}~\citep{vicuna2023} & lmsys/vicuna-7b-v1.3 \\
        & \Remark{vicuna13B1.3}~\citep{vicuna2023} & lmsys/vicuna-13b-v1.3\\
        & \Remark{vicuna33B1.3}~\citep{vicuna2023} & lmsys/vicuna-33b-v1.3\\
        & \Remark{stablevicuna13B}~\citep{stablevicuna2023}& CarperAI/stable-vicuna-13b-delta\tablefootnote{For convenience, we use the non-official endpoint TheBloke/stable-vicuna-13B-HF and TheBloke/UltraLM-13B-fp16 to get merged weights.\label{footnote:thebloke}} \\ 
        & \Remark{ultralm13B}~\citep{ding2023enhancing} & openbmb/UltraLM-13b\footref{footnote:thebloke} \\
        & \Remark{vicuna7B1.1}~\citep{vicuna2023} & lmsys/vicuna-7b-delta-v1.1 \\\midrule
        \multirow{2}{*}{API-Based} & \Remark{claude}~\citep{claude} & Claude extension on Slack\tablefootnote{\url{https://www.anthropic.com/claude-in-slack}} \\
        & \Remark{chatgpt} & Azure OpenAI, gpt-35-turbo 0301 version\tablefootnote{\url{https://azure.microsoft.com/en-us/products/ai-services/openai-service}}\\
        & \Remark{gpt4} & OpenAI, gpt-4-0613 version\\
        \bottomrule
    \end{tabular}
\end{table}
