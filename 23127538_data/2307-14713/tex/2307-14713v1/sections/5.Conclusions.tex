In this work, we presented GaitMorph, a novel method for modifying gait sequences into new walking variations. Our proposed approach entails firstly training a discrete latent model (in our case, a VQ-VAE) that compresses the walking sequences into a sequence of interpretable tokens, and learning an optimal latent transport map across variations. Our extensive experiments show that the trained VQ-VAE model preserves the walker's identity, achieving a marginal loss in performance when utilizing reconstructed sequences in gait recognition scenarios. Furthermore, we showed that the distribution of morphed sequences is similar to the real walk distribution. 
Our approach has the potential to be applied to self-supervised learning scenarios for gait recognition \cite{cosma22gaitformer}, which are heavily reliant \cite{chen2020simple,tian2020makes} on multiple strong augmentations / views for the same input.