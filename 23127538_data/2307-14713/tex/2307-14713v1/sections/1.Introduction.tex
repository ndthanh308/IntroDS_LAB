The way people walk, also known as gait, is a crucial biometric trait that has numerous applications in medicine \cite{medical-gait}, sports \cite{sports-gait}, and surveillance\cite{10.1145/3490235}. Most notably, in recent years, it has been successfully used as a unique biometric fingerprint to accurately identify individuals from a distance \cite{cosma22gaitformer}. 
The biggest challenge in gait analysis \cite{gait-survey} is disentangling confounding factors which significantly affect and obfuscate gait, such as the individual clothing, footwear, walking speed, injury, state of mind, and social environment. Moreover the extrinsic characteristics of gait sensors (such as camera viewpoint, distance and resolution) severely affect the quality of the captured gait. Developing a robust model, able to ignore these factors and represent the essential gait characteristics is still an open problem. Consequently, deploying highly accurate gait recognition systems in real-world unconstrained scenarios remains a difficult problem.

Previous works \cite{cosma22gaitformer,gait-vit} have shown that self-supervised pretraining is a promising new direction, but is still not enough to achieve high performance modelling. Self-supervised pre-training exposes the backbone model to a large variety of walking registers, increasing the robustness in downstream tasks. However, contrastive pre-training requires high degree of variation in the data \cite{chen2020simple,tian2020makes}, which is often hard to obtain automatically for gait. Fine-tuning is still necessary for effective gait recognition \cite{gait-vit}, especially in specific and uncommon environments. Currently, data variation for gait modelling systems is obtained by using data augmentation techniques \cite{cosma22gaitformer}, which have the goal to distort the gait sequence while preserving the person identity. However, heuristical augmentation procedures are not able to reliably produce novel viewpoints for a gait sequence, or to seamlessly change the walking variation as they only provide simple temporal and spatial distortions. For other similar tasks such as person re-identification \cite{reid-survey}, viewpoint variation is induced through learned methods such as approaches in human pose transfer \cite{sanyal2021learning}. 

We propose GaitMorph, a novel method that is able to modify skeleton gait sequences to synthesize novel views. We use a high-compression model for gait sequences that leverages large amounts of in-the-wild and unlabelled data to construct a discrete and interpretable latent space for skeleton gait sequences. Our model is based on the vector-quantized variational autoencoder (VQ-VAE) \cite{van2017neural}, and achieves a high degree of compression for skeleton sequences (up to 500$\times$ lower storage demands). We show that the model is able to reconstruct gait sequences with a high degree of fidelity, without losing identity-related features.

Furthermore, compressing gait sequences in a discrete latent space enables easy manipulation of codebook entries between walking variations. We propose to make use of optimal transport \cite{villani2009optimal} to learn transport maps between walking variations, allowing morphing gait sequences into a desired variation or viewpoint.

This work makes the following contributions:

\begin{enumerate}
    \item We demonstrate that compression of gait sequences into a discrete latent space is feasible, and can be achieved while preserving identity-related information of the underlying walker. We achieve a high degree (500$\times$) of compression without deteriorating downstream gait recognition performance (maximum of 3\% accuracy loss for normal walking). 
    
    \item We propose a novel method to morph gait sequences between variations. Using optimal transport theory, we learn transport maps between variations that generate realistic and novel views for a walk. Our experiments show that the distribution of morphed sequences is similar to the real walk distribution, potentially making our method useful for data augmentation.
    
    \item We perform extensive experiments on the core aspect of our proposed method: the VQ-VAE dictionary size. We show that, while a small dictionary size obtains good reconstruction error at a high compression level, the latent space is not sufficiently disentangled to allow easy morphing.
\end{enumerate}