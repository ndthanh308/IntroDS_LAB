% Figure environment removed

For our experiments, we used CASIA-B \cite{casia} and Front-View Gait (FVG) \cite{fvg} to evaluate the performance of our proposed method. CASIA-B is a popular gait recognition dataset, widely used to test the robustness of gait analysis model across multiple viewpoints and walking variations. It contains gait sequences from 124 subjects, captured in 11 different viewpoints, under three walking variations: normal walking (NM), clothing walking (CL) and walking with a bag (BG). For a walker, 6 sessions are captured under the normal walking variation, 2 sessions with clothing change and 2 sessions under the bag carrying variation. Each walk has its variation / viewpoint known. We use the standard \cite{casia} training / testing split, consisting of the first 62 training subjects, with all available walking sessions. FVG is another popular dataset for gait recognition that features walks from only the front facing viewpoint, which is considered the most challenging due to the reduced perceived movement variation. It is comprised of 226 subjects captured in 6 walking variations: normal walk (NM), walk speed (WS), change in clothing (CL), carrying bag (CB), cluttered background (CBG) and ALL. In our experiments, we omit the "ALL" variation to properly isolate confounding factors. We used the first 136 subjects as the training split, and the rest for testing. It is important to note that the VQ-VAE model is trained on the dataset described in Section \ref{sec:dataset}, and remains frozen throughout the rest of the experiments. Moreover, the transport maps are learned only on the training split of each dataset (CASIA-B / FVG) and are utilized as-is on the testing split.

\subsection{The effect of dictionary size on the reconstructed gait sequences}

% Figure environment removed

% Figure environment removed

We trained several VQ-VAE models with increasingly larger dictionary sizes ($|\mathcal{Z}| \in \{2, 8, 16, 32, 128, 512, 2048\}$) to gauge the effect on the reconstructed sequences. In Figure \ref{fig:casia-recons}, we showcase the reconstruction error for each model on CASIA-B evaluation set, for each walking variation. For $|\mathcal{Z}| = 2$, the results are significantly worse than other dictionary sizes, due to the extreme compression. The model with $|\mathcal{Z}| = 8$ achieves the best overall performance. We showcase qualitative reconstruction samples in Figure \ref{fig:recons} - the model can reliably reconstruct skeleton sequences and acts as a low-pass filter which dampens exaggerated movements caused by inaccurate pose extractions.

Our model achieves a high degree of compression for skeleton sequences - a skeleton sequence represented as a float32 sequence of 2304 numbers is equivalent to storing 73728 bits of information, but using a VQ-VAE approach, the storage space is reduced to only 144 bits for $|\mathcal{Z}| = 2$ and 432 bits for $|\mathcal{Z}| = 8$. This compression level potentially allows on-device storage of massive amounts of skeleton sequences. 

Figure \ref{fig:casia-usage} showcases the dictionary usage for each dictionary size. Increasing the dictionary size slightly decreases dictionary usage, which implies that some tokens are underutilized by the model. This effect is more pronounced for $|\mathcal{Z}| = 2048$, especially for non-normal walking variations. This is most likely due to the fact that the pretraining dataset for the VQ-VAE mostly contains in-the-wild walks, which make the BG and CL variations easier to reconstruct.  The reconstructed gait sequences are not detrimental to downstream gait recognition models. To gauge the faithfulness of the reconstructed skeletons to the real walking skeletons, in Table \ref{tab:recog-recons} we showcase gait recognition results for CASIA-B using reconstructed skeletons as training data. The performance loss by using reconstructed skeletons is marginal, and even beneficial in some cases. This result can be attributed to the fact that the VQ-VAE acts as a low-pass filter and can slightly improve data quality across training. Furthermore, performance on gait recognition is not correlated with the reconstruction error of the VQ-VAE: the model with $|\mathcal{Z}| = 2$ achieves comparable results with the baseline method using real skeletons.

\input{tables/recog-recons} 

\subsection{Evaluation of morphed gait sequences}

% Figure environment removed

% Figure environment removed

We first present a qualitative evaluation for gait morphing. Figure \ref{fig:casia-morphs} showcases selected gait sequences from three different viewpoints morphed to a common NM-36 variation. The model is able to morph sequences into the baseline sequence, properly handling limb switching (left and right limbs are properly swapped when the viewpoint is from behind the walker). For similar baseline / target pairs, the transport maps exhibit fewer changes. Transport maps from VQ-VAE models with a larger dictionary size exhibit more token changes, but the earth movers distance between variations is comparatively smaller. This implies that many smaller changes are performed with same effect. In Figure \ref{fig:mass} we showcase the average moved distance, the number of changes and the total mass moved across the walking variations for both CASIA-B and FVG. We define mass as the number of changes multiplied by the average change cost. The number of changes is larger when the dictionary size is larger, but the total mass moved remains constant after the $|\mathcal{Z}| = 128$. This implies that the tokens from the model with $|\mathcal{Z}| = 2048$ are more disentangled, since less mass is moved to achieve the same outcome. 

In terms of numeric evaluation, our goal is to compare the morphed walks to the real walks of a particular variation. In our experiments, our comparisons are made with regard to NM-36 variation for CASIA-B and NM for FVG. The most straightforward comparison is to use mean squared error between skeletons, but we have no guarantees of sequence alignment between variations in either dataset. As such, we propose a metric between walking distributions, similar to the FID \cite{heusel2017gans} distance. The Frechet Inception Distance (FID) was introduced by Heusel et al. \cite{heusel2017gans} to measure the generation quality of GANs compared to real images. The FID score is based on the Frechet Distance \cite{dowson1982frechet}, and measures the distance $d(\cdot)$ between two gaussian distributions $\phi = (\textbf{m}, \textbf{C})$ and $\phi_w = (\textbf{m}_w, \textbf{C}_w)$, corresponding to a distribution of real and synthetic samples, respectively: $d^2(\phi, \phi_w) = ||\textbf{m} - \textbf{m}_w||^2 + Tr(\textbf{C} + \textbf{C}_w - 2(\textbf{CC}_w)^{\frac{1}{2}})$. The means and standard deviations of the Gaussians are, for images, the means and standard deviations of a set of embedding vectors of an Inception network \cite{inception} pretrained on ImageNet. The metric captures levels of perceived disturbance between real and synthetic samples \cite{heusel2017gans}. 

For gait synthetisation, we propose a specialized variant of the FID score, which we name "\textit{Frechet Gait Distance (FGD)}", in which walks are processed by a pretrained GaitFormer network on DenseGait \cite{cosma22gaitformer}. FGD stands as a automatic measure of walking "naturalness", by measuring the similarity to a given real gait distribution. Variants have been proposed for measuring motion naturalness and are geared towards general action synthesis \cite{gopinath2020fairmotion,siyao2022bailando,maiorca2022evaluating}, but a specialized variant for gait has not yet been adopted.

\input{tables/fgd-casia}

\input{tables/fgd-fvg}

In Tables \ref{tab:fgd-casia} and \ref{tab:fgd-fvg}, we present our results for gait morphing for CASIA-B and FVG, respectively. We utilized the proposed FGD metric to compare the distance between the distribution of the morphed walks to the real baseline walking variation (NM-36 for CASIA-B and NM for FVG). For CASIA-B we focus our evaluation in terms of viewpoint, since it is the principal confounding factor, especially for 2D poses. Results show that the morphed walks are properly generated and are closer to the real NM-36 walking variation compared to the unmodified walk and for more extreme viewpoints, the effect is larger. Results are more correlated with the dictionary usage for each dictionary size, rather than reconstruction error (which is low for every dictionary size). Additionally, we compared morphed gaits with standard array of heuristic skeleton augmentations present in other works\cite{cosma22gaitformer,gaitgraph}: random pace with a time multiplier sampled from \{0.5, 0.75, 1, 1.25, 1.5, 1.75, 2.0\}, joint and point noise with standard deviation of 0.001, random mirroring and reversing the walk. While heuristic augmentations provide some variation in the vicinity of the original walk, the FGD across views are similar to the non-augmented walks. These results show that the morphed walks with our method represent a good way to augment existing walks to synthesize novel views. Since all the walks in FVG are from the same viewpoint, the differences between walking variations are not as evident. Consequently, the distance between distributions is comparatively smaller than in CASIA-B. 

% Figure environment removed

It is clear from results in Tables \ref{tab:fgd-casia} and \ref{tab:fgd-fvg} that models operating with a low dictionary size are not appropriate to be used for morphing. This is most likely due to the latent embeddings being severely entangled. Figure \ref{fig:failure} showcases a selected failure case for morphing a NM-180 walk from CASIA-B into NM-36 using a VQ-VAE with $|\mathcal{Z}| = 8$. The generated walk has severe artifacts and cannot be considered appropriate for downstream model training. Inherently, there is a trade-off between dictionary size and the manipulability of the latent codes: larger dictionary sizes have more disentangled representations which allow for more informed changes at the expense of lower data compression.