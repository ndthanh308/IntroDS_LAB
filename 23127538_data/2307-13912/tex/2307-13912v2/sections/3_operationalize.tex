\section{Societal Objective Functions}

\subsection{Operationalizing Anti-Democratic Attitudes into Social Media AIs}

We introduce the term \textit{societal objective function} to refer to our method of translating well-established social science constructs into an AI objective function.
In this work, the goal of our algorithmic objective is to reduce partisan animosity through social media feeds. 

\subsubsection{The anti-democratic attitudes construct}

Creating a societal objective function begins with anchoring to a construct in the social and behavioral sciences. In our case, as mentioned, we use anti-democratic attitudes. Detailed definitions and example measures of each of the eight variables are shown in Table ~\ref{tab:megastudy}. These variables were selected because they are important measurements related to psychology underlying polarization and democracy \cite{voelkel2023megastudy}.

\input{figures/megastudy}

\subsubsection{Dataset}
To generate the social media feed stimulus for our three studies, we source real-world posts drawn from CrowdTangle, a tool hosted by Meta that allows external parties to monitor public posts on Facebook \cite{fletcher2018measuring}. Given our focus on democratic values, we source political posts on CrowdTangle by filtering to several politics-related page categories\footnote{Page categories: political organization, political candidate, political ideology, political party, politics, politician, government organization, government official, public services government} and select those with the highest number of total interactions (likes, shares, comments, and reactions). Using this method, we gather $10,000$ political Facebook posts from CrowdTangle that were posted between January 1 and February 1, 2023. We then use the systematic random sampling method to select a final inventory of $n$ = 405 posts for manual labeling. Specifically, we split the CrowdTangle posts into buckets based on overall weighted engagement counts (e.g., Likes), and sample posts across these buckets to ensure a broad range of engagement in the posts in our study.


\subsubsection{Translating from manual coding to feed ranking interfaces}

Then, two members of the research team served as expert annotators to rate each political post using the anti-democratic attitude scale. For each anti-democratic outcome variable, a rating is given on a 3-point scale, with a score of 3 indicating strong presence of that variable (e.g., strong partisan animosity), a score of 2 indicating some presence (e.g., some partisan animosity), and a score of 1 indicating no presence (e.g., no evidence of partisan animosity). The two researchers adapted the existing construct from the literature deductively into a detailed coding scheme for each of the eight variables. Some new factors of the constructs, such as ``emotion or exaggeration,'' also emerged inductively in the process of creating the coding scheme. For instance, for partisan animosity, they tagged two factors in their rating procedure---factor A: partisan name-calling and factor B: emotion or exaggeration. 

In this case, a post was given a rating of 1 if neither factor applied, a rating of 2 if only one of the factors applied, and a rating of 3 if both factors applied. 

While our operationalization is anchored in the prior literature, we anticipate that future work will offer further refinements of the codebook --- our work is not dependent on the exact operationalization.

Each post is given a total of 8 ratings, one for each of the variables, which are then summed to arrive at a total \textit{democratic attitude} score (min = 8, max = 24).
The two independent coders achieved strong inter-coder reliability (Krippendorff's $\alpha$ = .895) and used the above process to code all 405 political Facebook posts in the inventory. Full inter-coder reliability results are shown in Table~\ref{tab:manual_irr}.

The manual democratic attitude scores are then used to re-rank social media feed interfaces. In Study 1, we use this approach to compare democratic attitude feeds with status quo feed ranking methods. For example, we sort our inventory of social media posts to produce feeds ranked by manually-rated democratic attitude scores or by total interaction scores from CrowdTangle. The total interaction score is a weighted sum of the following engagement metrics: Share, Comment, Like, Love, Wow, Haha, Sad, Angry, and Care. Each engagement metric is given equal weight. Our dataset includes posts with total interaction scores ranging from 24 (low interaction) to 92,520 (high interaction). Our full set of feed ranking conditions is described in Section~\ref{section:feed_ranking_conditions}.


\subsubsection{Using LLMs to replicate manual coding at scale} 

The final step of creating a societal objective function involves using LLMs to replicate the same social science construct at scale. In our work, we scale up the anti-democratic attitude construct by turning the eight variables into zero-shot classification prompts for a large language model. These prompts are built on the exact same coding scheme developed for the manual raters, and used as inputs to the GPT-4 large language model to output ratings. Specifically, we prompt GPT-4 to rate each social media post from our social media post inventory dataset (development set: $n$ = 205; test set: $n$ = 200) on all eight variables. The development set is used to refine and iterate on the prompts, and the test set is set aside to conduct final performance evaluations. The full prompts are included in Appendix~\ref{appendix:prompts}. Then, as with the manual rating procedure, we sum the eight anti-democratic attitude scores to produce the total anti-democratic attitude score. 

In Study 2, we first compare GPT-4's ratings with manual ratings. Then, in Study 3, we use ratings from GPT-4 to produce an LLM-ranked feed condition to compare against Study 1's manually-ranked and engagement-ranked feed conditions.


\subsection{Feed Ranking Conditions and Hypotheses}
 
We pre-registered our research questions and hypotheses on Open Science Framework (OSF) \cite{foster2017open} and conduct two online experiments (Study 1: $N$ = 1,380; Study 3: $N$ = 558) to measure the impact of democratic attitude feeds on US partisans' partisan animosity, support for undemocratic practices, feed-level satisfaction, and engagement.

\subsubsection{Feed ranking conditions}
\label{section:feed_ranking_conditions}

Past work has examined different approaches to reduce the societal harm caused by social media, such as using content moderation~\cite{kozyreva2023resolving}, downrankinging or removing harmful content or misinformation~\cite{epstein2020will}, placing content warnings to warn potential viewers that the content is sensitive or may bring up difficult emotions~\cite{haimson2020trans}, or displaying more balanced information in one's social media feed (e.g., ideologically balanced content from both liberal and conservative sources \cite{celis2019controlling}). 

Building on prior work, we propose three democratic attitude feeds, including:
\begin{enumerate}
    \item \textit{Downranking} feed (i.e., ranked by anti-democratic attitude score such that posts with stronger anti-democratic attitudes are placed at the bottom of the feed)

    \item \textit{Content Warning} feed where we are able to simulate the content moderation policies of real-world social media platforms (i.e., ranked by engagement, but anti-democratic posts are blurred out with content warnings)
    \item \textit{Remove-and-Replace} feed (i.e., ranked by engagement, but anti-democratic posts are replaced with pro-democratic posts sourced from our dataset inventory ($n$ = 405))
\end{enumerate}

Current feed ranking systems often focus on optimizing users' engagement to increase user retention \cite{wu2017returning} and maximize profit \cite{ciampaglia2018algorithmic}, which is likely to up-rank the most controversial content and thus increase partisan animosity. Many scholars have articulated their concerns about engagement-based feeds and often compare the impact of engagement-based feeds with reverse-chronologically ordered feeds that are free from algorithmic curation \cite{paek2010predicting, huszar2022algorithmic}. We thus compare our democratic attitude feeds against both engagement-based feeds that emulate the status quo of feed ranking and reverse-chronological feeds that serve as a control condition. In addition, we compare our democratic attitude feeds against the ideologically balanced approaches proposed by prior work \cite{celis2019controlling}. Then, to estimate the baseline level of partisan animosity, we include a null control condition where participants are not exposed to any social media feed. We thus arrive at four comparison conditions: (1)~an \textit{Engagement-Based} feed, (2)~an \textit{Ideologically Balanced} feed, (3)~a \textit{Control (Chronological)} feed, and (4)~a \textit{Null Control} condition with no feed shown. See Figure~\ref{fig:condition} for a detailed description of all feed ranking conditions.

\subsubsection{Research Questions and Hypotheses}

Our study intends to examine the following overarching research questions: 

\begin{enumerate}
    \item[\textbf{RQ1:}] How will partisans’ partisan animosity and support for undemocratic practices differ after exposure to different social media feeds?

    \item[\textbf{RQ2:}] How will partisans’ level of satisfaction and engagement with feeds differ after exposure to different social media feeds?
\end{enumerate}

Prior work found that current social media platforms' ranking algorithms amplify political content \cite{huszar2022algorithmic} and increase opinion polarization \cite{ciampaglia2018algorithmic, chitra2020analyzing, rowland2011filter}. There is a growing literature on the ways in which ranking algorithms trained on engagement data might facilitate the formation of ``echo chambers'' \cite{sunstein2001http} or ``filter bubbles'' \cite{rowland2011filter}. Recent work found that interventions such as changing public discourse and transforming political structures or correcting misconceptions and highlighting commonalities can decrease people's animosity \cite{voelkel2023megastudy, hartman2022interventions}. Following a large body of literature on partisan animosity, we also predict that our democratic attitude feed can effectively reduce partisan animosity. Thus, we predict \textbf{H1}:

\begin{enumerate}
    \item[\textbf{H1:}] Partisans exposed to the (a) downranking, (b) content warning, and (c) removal feed conditions on social media will reduce partisan animosity compared to partisans in the engagement feed and chronological feed (controls).
\end{enumerate}

\citet{voelkel2023megastudy} point out that many scholars are also concerned about Americans' support for undemocratic practices besides the level of dislike between rival partisans (i.e., partisan animosity) \cite{finkel2020political}. Given the increasing scholarly attention to the importance of support for undemocratic practices, we also predict \textbf{H2}:

\begin{enumerate}
    \item[\textbf{H2:}] Partisans exposed to the (a) downranking, (b) content warning, and (c) removal feed conditions on social media will reduce support for undemocratic practices compared to partisans in the engagement feed and chronological feed (controls).
\end{enumerate}

Recent prior work found that people's perceptions of content moderation depends on partisanship: Republicans were more likely to oppose content moderation than Democrats possibly because they consider it a threat to freedom of speech \cite{kozyreva2023resolving}. Other studies also found that content moderation may trigger people's concerns about platform censorship \cite{riedl2022antecedents}. Based on prior work, we predict that partisans exposed to the content warning feed will perceive a higher level of threat to freedom of speech compared to other feeds and propose \textbf{H3}.

\begin{enumerate}
    \item[\textbf{H3:}] Partisans exposed to the content warning feed will perceive a higher level of threat to freedom of speech compared to partisans exposed to other feeds.
\end{enumerate}