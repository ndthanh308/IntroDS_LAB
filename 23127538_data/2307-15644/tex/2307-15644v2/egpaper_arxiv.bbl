\begin{thebibliography}{10}\itemsep=-1pt

\bibitem{habitat2020sim2real}
{Abhishek Kadian}, {Joanne Truong}, Aaron Gokaslan, Alexander Clegg, Erik
  Wijmans, Stefan Lee, Manolis Savva, Sonia Chernova, and Dhruv Batra.
\newblock Are {W}e {M}aking {R}eal {P}rogress in {S}imulated {E}nvironments?
  {M}easuring the {S}im2{R}eal {G}ap in {E}mbodied {V}isual {N}avigation.
\newblock In {\em arXiv:1912.06321}, 2019.

\bibitem{an2021neighbor}
Dong An, Yuankai Qi, Yan Huang, Qi Wu, Liang Wang, and Tieniu Tan.
\newblock Neighbor-view enhanced model for vision and language navigation.
\newblock In {\em Proceedings of the 29th ACM International Conference on
  Multimedia}, pages 5101--5109, 2021.

\bibitem{an2022bevbert}
Dong An, Yuankai Qi, Yangguang Li, Yan Huang, Liang Wang, Tieniu Tan, and Jing
  Shao.
\newblock Bevbert: Topo-metric map pre-training for language-guided navigation.
\newblock {\em arXiv preprint arXiv:2212.04385}, 2022.

\bibitem{an2023etpnav}
Dong An, Hanqing Wang, Wenguan Wang, Zun Wang, Yan Huang, Keji He, and Liang
  Wang.
\newblock Etpnav: Evolving topological planning for vision-language navigation
  in continuous environments.
\newblock {\em arXiv preprint arXiv:2304.03047}, 2023.

\bibitem{an20221st}
Dong An, Zun Wang, Yangguang Li, Yi Wang, Yicong Hong, Yan Huang, Liang Wang,
  and Jing Shao.
\newblock 1st place solutions for rxr-habitat vision-and-language navigation
  competition (cvpr 2022).
\newblock {\em arXiv preprint arXiv:2206.11610}, 2022.

\bibitem{anderson2018spl}
Peter Anderson, Angel Chang, Devendra~Singh Chaplot, Alexey Dosovitskiy,
  Saurabh Gupta, Vladlen Koltun, Jana Kosecka, Jitendra Malik, Roozbeh
  Mottaghi, Manolis Savva, et~al.
\newblock On evaluation of embodied navigation agents.
\newblock {\em arXiv preprint arXiv:1807.06757}, 2018.

\bibitem{anderson2019chasing}
Peter Anderson, Ayush Shrivastava, Devi Parikh, Dhruv Batra, and Stefan Lee.
\newblock Chasing ghosts: Instruction following as bayesian state tracking.
\newblock {\em Advances in neural information processing systems}, 32, 2019.

\bibitem{anderson2020sim}
Peter Anderson, Ayush Shrivastava, Joanne Truong, Arjun Majumdar, Devi Parikh,
  Dhruv Batra, and Stefan Lee.
\newblock Sim-to-real transfer for vision-and-language navigation.
\newblock In {\em Conference on Robot Learning}, pages 671--681. PMLR, 2021.

\bibitem{anderson2021sim}
Peter Anderson, Ayush Shrivastava, Joanne Truong, Arjun Majumdar, Devi Parikh,
  Dhruv Batra, and Stefan Lee.
\newblock Sim-to-real transfer for vision-and-language navigation.
\newblock In {\em Conference on Robot Learning}, pages 671--681. PMLR, 2021.

\bibitem{anderson2018r2r}
Peter Anderson, Qi Wu, Damien Teney, Jake Bruce, Mark Johnson, Niko
  S{\"u}nderhauf, Ian Reid, Stephen Gould, and Anton van~den Hengel.
\newblock Vision-and-language navigation: Interpreting visually-grounded
  navigation instructions in real environments.
\newblock In {\em Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, pages 3674--3683, 2018.

\bibitem{batra2020rearrangement}
Dhruv Batra, Angel~X Chang, Sonia Chernova, Andrew~J Davison, Jia Deng, Vladlen
  Koltun, Sergey Levine, Jitendra Malik, Igor Mordatch, Roozbeh Mottaghi,
  et~al.
\newblock Rearrangement: A challenge for embodied ai.
\newblock {\em arXiv preprint arXiv:2011.01975}, 2020.

\bibitem{batra2020objectnav}
Dhruv Batra, Aaron Gokaslan, Aniruddha Kembhavi, Oleksandr Maksymets, Roozbeh
  Mottaghi, Manolis Savva, Alexander Toshev, and Erik Wijmans.
\newblock Object{N}av {R}evisited: {O}n {E}valuation of {E}mbodied {A}gents
  {N}avigating to {O}bjects.
\newblock In {\em arXiv:2006.13171}, 2020.

\bibitem{chang2017matterport3d}
Angel Chang, Angela Dai, Thomas Funkhouser, Maciej Halber, Matthias Niebner,
  Manolis Savva, Shuran Song, Andy Zeng, and Yinda Zhang.
\newblock Matterport3d: Learning from rgb-d data in indoor environments.
\newblock In {\em 2017 International Conference on 3D Vision (3DV)}, pages
  667--676. IEEE, 2017.

\bibitem{chen2022sevol}
Jinyu Chen, Chen Gao, Erli Meng, Qiong Zhang, and Si Liu.
\newblock Reinforced structured state-evolution for vision-language navigation.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 15450--15459, 2022.

\bibitem{chen2022weakly}
Peihao Chen, Dongyu Ji, Kunyang Lin, Runhao Zeng, Thomas~H Li, Mingkui Tan, and
  Chuang Gan.
\newblock Weakly-supervised multi-granularity map learning for
  vision-and-language navigation.
\newblock {\em arXiv preprint arXiv:2210.07506}, 2022.

\bibitem{chen2021hamt}
Shizhe Chen, Pierre-Louis Guhur, Cordelia Schmid, and Ivan Laptev.
\newblock History aware multimodal transformer for vision-and-language
  navigation.
\newblock {\em Advances in Neural Information Processing Systems},
  34:5834--5847, 2021.

\bibitem{chen2022hm3dlearning}
Shizhe Chen, Pierre-Louis Guhur, Makarand Tapaswi, Cordelia Schmid, and Ivan
  Laptev.
\newblock Learning from unlabeled 3d environments for vision-and-language
  navigation.
\newblock In {\em European Conference on Computer Vision}, pages 638--655.
  Springer, 2022.

\bibitem{chen2022duet}
Shizhe Chen, Pierre-Louis Guhur, Makarand Tapaswi, Cordelia Schmid, and Ivan
  Laptev.
\newblock Think global, act local: Dual-scale graph transformer for
  vision-and-language navigation.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 16537--16547, 2022.

\bibitem{de2018talk}
Harm De~Vries, Kurt Shuster, Dhruv Batra, Devi Parikh, Jason Weston, and Douwe
  Kiela.
\newblock Talk the walk: Navigating new york city through grounded dialogue.
\newblock {\em arXiv preprint arXiv:1807.03367}, 2018.

\bibitem{deitke2022procthor}
Matt Deitke, Eli VanderBilt, Alvaro Herrasti, Luca Weihs, Jordi Salvador, Kiana
  Ehsani, Winson Han, Eric Kolve, Ali Farhadi, Aniruddha Kembhavi, et~al.
\newblock Procthor: Large-scale embodied ai using procedural generation.
\newblock {\em arXiv preprint arXiv:2206.06994}, 2022.

\bibitem{deng2020evolving}
Zhiwei Deng, Karthik Narasimhan, and Olga Russakovsky.
\newblock Evolving graphical planner: Contextual global planning for
  vision-and-language navigation.
\newblock {\em Advances in Neural Information Processing Systems},
  33:20660--20672, 2020.

\bibitem{dosovitskiy2020vit}
Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn,
  Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg
  Heigold, Sylvain Gelly, et~al.
\newblock An image is worth 16x16 words: Transformers for image recognition at
  scale.
\newblock {\em arXiv preprint arXiv:2010.11929}, 2020.

\bibitem{dou2022foam}
Zi-Yi Dou and Nanyun Peng.
\newblock Foam: A follower-aware speaker model for vision-and-language
  navigation.
\newblock {\em arXiv preprint arXiv:2206.04294}, 2022.

\bibitem{ehsani2021manipulathor}
Kiana Ehsani, Winson Han, Alvaro Herrasti, Eli VanderBilt, Luca Weihs, Eric
  Kolve, Aniruddha Kembhavi, and Roozbeh Mottaghi.
\newblock Manipulathor: A framework for visual object manipulation.
\newblock In {\em Proceedings of the IEEE/CVF conference on computer vision and
  pattern recognition}, pages 4497--4506, 2021.

\bibitem{fried2018speaker}
Daniel Fried, Ronghang Hu, Volkan Cirik, Anna Rohrbach, Jacob Andreas,
  Louis-Philippe Morency, Taylor Berg-Kirkpatrick, Kate Saenko, Dan Klein, and
  Trevor Darrell.
\newblock Speaker-follower models for vision-and-language navigation.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  3314--3325, 2018.

\bibitem{fu2020counterfactual}
Tsu-Jui Fu, Xin~Eric Wang, Matthew~F Peterson, Scott~T Grafton, Miguel~P
  Eckstein, and William~Yang Wang.
\newblock Counterfactual vision-and-language navigation via adversarial path
  sampler.
\newblock In {\em European Conference on Computer Vision}, pages 71--86.
  Springer, 2020.

\bibitem{guhur2021airbert}
Pierre-Louis Guhur, Makarand Tapaswi, Shizhe Chen, Ivan Laptev, and Cordelia
  Schmid.
\newblock Airbert: In-domain pretraining for vision-and-language navigation.
\newblock In {\em Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pages 1634--1643, 2021.

\bibitem{hao2020prevalent}
Weituo Hao, Chunyuan Li, Xiujun Li, Lawrence Carin, and Jianfeng Gao.
\newblock Towards learning a generic agent for vision-and-language navigation
  via pre-training.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 13137--13146, 2020.

\bibitem{hong2020graph}
Yicong Hong, Cristian Rodriguez, Yuankai Qi, Qi Wu, and Stephen Gould.
\newblock Language and visual entity relationship graph for agent navigation.
\newblock {\em Advances in Neural Information Processing Systems}, 33, 2020.

\bibitem{hong2022bridging}
Yicong Hong, Zun Wang, Qi Wu, and Stephen Gould.
\newblock Bridging the gap between learning in discrete and continuous
  environments for vision-and-language navigation.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 15439--15449, 2022.

\bibitem{hong2020recurrent}
Yicong Hong, Qi Wu, Yuankai Qi, Cristian Rodriguez-Opazo, and Stephen Gould.
\newblock A recurrent vision-and-language bert for navigation.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition (CVPR)}, pages 1643--1653, June 2021.

\bibitem{hong2023ego2map}
Yicong Hong, Yang Zhou, Ruiyi Zhang, Franck Dernoncourt, Trung Bui, Stephen
  Gould, and Hao Tan.
\newblock Learning navigational visual representations with semantic map
  supervision.
\newblock {\em arXiv preprint arXiv: 2307.12335}, 2023.

\bibitem{ilharco2019ndtw}
Gabriel Ilharco, Vihan Jain, Alexander Ku, Eugene Ie, and Jason Baldridge.
\newblock General evaluation for instruction conditioned navigation using
  dynamic time warping.
\newblock {\em arXiv preprint arXiv:1907.05446}, 2019.

\bibitem{jain2021mural}
Aashi Jain, Mandy Guo, Krishna Srinivasan, Ting Chen, Sneha Kudugunta, Chao
  Jia, Yinfei Yang, and Jason Baldridge.
\newblock Mural: Multimodal, multitask representations across languages.
\newblock In {\em Findings of the Association for Computational Linguistics:
  EMNLP 2021}, pages 3449--3463, 2021.

\bibitem{jain2019stay}
Vihan Jain, Gabriel Magalhaes, Alexander Ku, Ashish Vaswani, Eugene Ie, and
  Jason Baldridge.
\newblock Stay on the path: Instruction fidelity in vision-and-language
  navigation.
\newblock In {\em Proceedings of the 57th Annual Meeting of the Association for
  Computational Linguistics}, pages 1862--1872, 2019.

\bibitem{li2023vlnsig}
Mohit~Bansal Jialu~Li.
\newblock Improving vision-and-language navigation by generating future-view
  image semantics.
\newblock In {\em CVPR}, 2023.

\bibitem{kamath2022marval}
Aishwarya Kamath, Peter Anderson, Su Wang, Jing~Yu Koh, Alexander Ku, Austin
  Waters, Yinfei Yang, Jason Baldridge, and Zarana Parekh.
\newblock A new path: Scaling vision-and-language navigation with synthetic
  instructions and imitation learning.
\newblock {\em arXiv preprint arXiv:2210.03112}, 2022.

\bibitem{ke2019tactical}
Liyiming Ke, Xiujun Li, Yonatan Bisk, Ari Holtzman, Zhe Gan, Jingjing Liu,
  Jianfeng Gao, Yejin Choi, and Siddhartha Srinivasa.
\newblock Tactical rewind: Self-correction via backtracking in
  vision-and-language navigation.
\newblock In {\em Proceedings of the IEEE/CVF conference on computer vision and
  pattern recognition}, pages 6741--6749, 2019.

\bibitem{kim2021ndh}
Hyounghun Kim, Jialu Li, and Mohit Bansal.
\newblock Ndh-full: Learning and evaluating navigational agents on full-length
  dialogue.
\newblock In {\em Proceedings of the 2021 Conference on Empirical Methods in
  Natural Language Processing}, 2021.

\bibitem{koh2022simple}
Jing~Yu Koh, Harsh Agrawal, Dhruv Batra, Richard Tucker, Austin Waters, Honglak
  Lee, Yinfei Yang, Jason Baldridge, and Peter Anderson.
\newblock Simple and effective synthesis of indoor 3d scenes.
\newblock {\em arXiv preprint arXiv:2204.02960}, 2022.

\bibitem{krantz2022iterative}
Jacob Krantz, Shurjo Banerjee, Wang Zhu, Jason Corso, Peter Anderson, Stefan
  Lee, and Jesse Thomason.
\newblock Iterative vision-and-language navigation.
\newblock {\em arXiv preprint arXiv:2210.03087}, 2022.

\bibitem{krantz2021waypoint}
Jacob Krantz, Aaron Gokaslan, Dhruv Batra, Stefan Lee, and Oleksandr Maksymets.
\newblock Waypoint models for instruction-guided navigation in continuous
  environments.
\newblock In {\em Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pages 15162--15171, 2021.

\bibitem{krantz2022sim}
Jacob Krantz and Stefan Lee.
\newblock Sim-2-sim transfer for vision-and-language navigation in continuous
  environments.
\newblock In {\em European Conference on Computer Vision}, pages 588--603.
  Springer, 2022.

\bibitem{krantz2020navgraph}
Jacob Krantz, Erik Wijmans, Arjun Majumdar, Dhruv Batra, and Stefan Lee.
\newblock Beyond the nav-graph: Vision-and-language navigation in continuous
  environments.
\newblock In {\em European Conference on Computer Vision}, 2020.

\bibitem{anderson2020rxr}
Alexander Ku, Peter Anderson, Roma Patel, Eugene Ie, and Jason Baldridge.
\newblock Room-across-room: Multilingual vision-and-language navigation with
  dense spatiotemporal grounding.
\newblock In {\em Proceedings of the 2020 Conference on Empirical Methods in
  Natural Language Processing (EMNLP)}, pages 4392--4412, 2020.

\bibitem{lamb2016professor}
Alex~M Lamb, Anirudh~Goyal ALIAS PARTH~GOYAL, Ying Zhang, Saizheng Zhang,
  Aaron~C Courville, and Yoshua Bengio.
\newblock Professor forcing: A new algorithm for training recurrent networks.
\newblock {\em Advances in neural information processing systems}, 29, 2016.

\bibitem{li2022envedit}
Jialu Li, Hao Tan, and Mohit Bansal.
\newblock Envedit: Environment editing for vision-and-language navigation.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 15407--15417, 2022.

\bibitem{lin2022multimodal}
Chuang Lin, Yi Jiang, Jianfei Cai, Lizhen Qu, Gholamreza Haffari, and Zehuan
  Yuan.
\newblock Multimodal transformer with variable-length memory for
  vision-and-language navigation.
\newblock In {\em Computer Vision--ECCV 2022: 17th European Conference, Tel
  Aviv, Israel, October 23--27, 2022, Proceedings, Part XXXVI}, pages 380--397.
  Springer, 2022.

\bibitem{lin2021scene}
Xiangru Lin, Guanbin Li, and Yizhou Yu.
\newblock Scene-intuitive agent for remote embodied visual grounding.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 7036--7045, 2021.

\bibitem{lin2021sia}
Xiangru Lin, Guanbin Li, and Yizhou Yu.
\newblock Scene-intuitive agent for remote embodied visual grounding.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 7036--7045, 2021.

\bibitem{liu2021envmixup}
Chong Liu, Fengda Zhu, Xiaojun Chang, Xiaodan Liang, Zongyuan Ge, and Yi-Dong
  Shen.
\newblock Vision-language navigation with random environmental mixup.
\newblock In {\em Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pages 1644--1654, 2021.

\bibitem{ma2019self}
Chih-Yao Ma, Jiasen Lu, Zuxuan Wu, Ghassan AlRegib, Zsolt Kira, Richard Socher,
  and Caiming Xiong.
\newblock Self-monitoring navigation agent via auxiliary progress estimation.
\newblock In {\em Proceedings of the International Conference on Learning
  Representations (ICLR)}, 2019.

\bibitem{magassouba2021crossmap}
Aly Magassouba, Komei Sugiura, and Hisashi Kawai.
\newblock Crossmap transformer: A crossmodal masked path transformer using
  double back-translation for vision-and-language navigation.
\newblock {\em IEEE Robotics and Automation Letters}, 6(4):6258--6265, 2021.

\bibitem{majumdar2020improving}
Arjun Majumdar, Ayush Shrivastava, Stefan Lee, Peter Anderson, Devi Parikh, and
  Dhruv Batra.
\newblock Improving vision-and-language navigation with image-text pairs from
  the web.
\newblock {\em In Proceedings of the European Conference on Computer Vision},
  2020.

\bibitem{mezghani2021imagenav}
Lina Mezghani, Sainbayar Sukhbaatar, Thibaut Lavril, Oleksandr Maksymets, Dhruv
  Batra, Piotr Bojanowski, and Karteek Alahari.
\newblock Memory-augmented reinforcement learning for image-goal navigation.
\newblock {\em arXiv preprint arXiv:2101.05181}, 2021.

\bibitem{padmakumar2022teach}
Aishwarya Padmakumar, Jesse Thomason, Ayush Shrivastava, Patrick Lange, Anjali
  Narayan-Chen, Spandana Gella, Robinson Piramuthu, Gokhan Tur, and Dilek
  Hakkani-Tur.
\newblock Teach: Task-driven embodied agents that chat.
\newblock In {\em Proceedings of the AAAI Conference on Artificial
  Intelligence}, volume~36, pages 2017--2025, 2022.

\bibitem{papineni2002bleu}
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu.
\newblock Bleu: a method for automatic evaluation of machine translation.
\newblock In {\em Proceedings of the 40th annual meeting of the Association for
  Computational Linguistics}, pages 311--318, 2002.

\bibitem{qi2021road}
Yuankai Qi, Zizheng Pan, Yicong Hong, Ming-Hsuan Yang, Anton van~den Hengel,
  and Qi Wu.
\newblock The road to know-where: An object-and-room informed sequential bert
  for indoor vision-language navigation.
\newblock In {\em Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pages 1655--1664, 2021.

\bibitem{qi2020object}
Yuankai Qi, Zizheng Pan, Shengping Zhang, Anton van~den Hengel, and Qi Wu.
\newblock Object-and-action aware model for visual language navigation.
\newblock In {\em European Conference on Computer Vision}, 2020.

\bibitem{qi2020reverie}
Yuankai Qi, Qi Wu, Peter Anderson, Xin Wang, William~Yang Wang, Chunhua Shen,
  and Anton van~den Hengel.
\newblock Reverie: Remote embodied visual referring expression in real indoor
  environments.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 9982--9991, 2020.

\bibitem{qiao2022hop}
Yanyuan Qiao, Yuankai Qi, Yicong Hong, Zheng Yu, Peng Wang, and Qi Wu.
\newblock Hop: History-and-order aware pre-training for vision-and-language
  navigation.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 15418--15427, 2022.

\bibitem{qiao2023hop+}
Yanyuan Qiao, Yuankai Qi, Yicong Hong, Zheng Yu, Peng Wang, and Qi Wu.
\newblock Hop+: History-enhanced and order-aware pre-training for
  vision-and-language navigation.
\newblock {\em IEEE Transactions on Pattern Analysis and Machine Intelligence},
  2023.

\bibitem{qin2021ensemble}
Wenda Qin, Teruhisa Misu, and Derry Wijaya.
\newblock Explore the potential performance of vision-and-language navigation
  model: a snapshot ensemble method.
\newblock {\em arXiv preprint arXiv:2111.14267}, 2021.

\bibitem{radford2021clip}
Alec Radford, Jong~Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh,
  Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark,
  et~al.
\newblock Learning transferable visual models from natural language
  supervision.
\newblock In {\em International Conference on Machine Learning}, pages
  8748--8763. PMLR, 2021.

\bibitem{radford2019gpt2}
Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya
  Sutskever, et~al.
\newblock Language models are unsupervised multitask learners.
\newblock {\em OpenAI blog}, 1(8):9, 2019.

\bibitem{ramakrishnan2021hm3d}
Santhosh~Kumar Ramakrishnan, Aaron Gokaslan, Erik Wijmans, Oleksandr Maksymets,
  Alexander Clegg, John~M Turner, Eric Undersander, Wojciech Galuba, Andrew
  Westbury, Angel~X Chang, et~al.
\newblock Habitat-matterport 3d dataset (hm3d): 1000 large-scale 3d
  environments for embodied ai.
\newblock In {\em Thirty-fifth Conference on Neural Information Processing
  Systems Datasets and Benchmarks Track (Round 2)}, 2021.

\bibitem{ramrakhya2022habweb}
Ram Ramrakhya, Eric Undersander, Dhruv Batra, and Abhishek Das.
\newblock Habitat-web: Learning embodied object-search strategies from human
  demonstrations at scale.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 5173--5183, 2022.

\bibitem{raychaudhuri2021law}
Sonia Raychaudhuri, Saim Wani, Shivansh Patel, Unnat Jain, and Angel~X Chang.
\newblock Language-aligned waypoint (law) supervision for vision-and-language
  navigation in continuous environments.
\newblock {\em arXiv preprint arXiv:2109.15207}, 2021.

\bibitem{ross2011dagger}
St{\'e}phane Ross, Geoffrey Gordon, and Drew Bagnell.
\newblock A reduction of imitation learning and structured prediction to
  no-regret online learning.
\newblock In {\em Proceedings of the fourteenth international conference on
  artificial intelligence and statistics}, pages 627--635. JMLR Workshop and
  Conference Proceedings, 2011.

\bibitem{savva2019habitat}
Manolis Savva, Abhishek Kadian, Oleksandr Maksymets, Yili Zhao, Erik Wijmans,
  Bhavana Jain, Julian Straub, Jia Liu, Vladlen Koltun, Jitendra Malik, et~al.
\newblock Habitat: A platform for embodied ai research.
\newblock In {\em Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pages 9339--9347, 2019.

\bibitem{shah2022lmnav}
Dhruv Shah, Blazej Osinski, Brian Ichter, and Sergey Levine.
\newblock Lm-nav: Robotic navigation with large pre-trained models of language,
  vision, and action.
\newblock {\em arXiv preprint arXiv:2207.04429}, 2022.

\bibitem{shen2021benefit}
Sheng Shen, Liunian~Harold Li, Hao Tan, Mohit Bansal, Anna Rohrbach, Kai-Wei
  Chang, Zhewei Yao, and Kurt Keutzer.
\newblock How much can clip benefit vision-and-language tasks?
\newblock In {\em International Conference on Learning Representations}, 2021.

\bibitem{tan2019lxmert}
Hao Tan and Mohit Bansal.
\newblock Lxmert: Learning cross-modality encoder representations from
  transformers.
\newblock In {\em Proceedings of the 2019 Conference on Empirical Methods in
  Natural Language Processing}, 2019.

\bibitem{tan2019envdrop}
Hao Tan, Licheng Yu, and Mohit Bansal.
\newblock Learning to navigate unseen environments: Back translation with
  environmental dropout.
\newblock In {\em Proceedings of NAACL-HLT}, pages 2610--2621, 2019.

\bibitem{thomason2020cvdn}
Jesse Thomason, Michael Murray, Maya Cakmak, and Luke Zettlemoyer.
\newblock Vision-and-dialog navigation.
\newblock In {\em Conference on Robot Learning}, pages 394--406, 2020.

\bibitem{wang2021structured}
Hanqing Wang, Wenguan Wang, Wei Liang, Caiming Xiong, and Jianbing Shen.
\newblock Structured scene memory for vision-language navigation.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 8455--8464, 2021.

\bibitem{wang2020active}
Hanqing Wang, Wenguan Wang, Tianmin Shu, Wei Liang, and Jianbing Shen.
\newblock Active visual information gathering for vision-language navigation.
\newblock In {\em European Conference on Computer Vision}, pages 307--322.
  Springer, 2020.

\bibitem{wang2022less}
Su Wang, Ceslee Montgomery, Jordi Orbay, Vighnesh Birodkar, Aleksandra Faust,
  Izzeddin Gur, Natasha Jaques, Austin Waters, Jason Baldridge, and Peter
  Anderson.
\newblock Less is more: Generating grounded navigation instructions from
  landmarks.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 15428--15438, 2022.

\bibitem{wang2019reinforced}
Xin Wang, Qiuyuan Huang, Asli Celikyilmaz, Jianfeng Gao, Dinghan Shen,
  Yuan-Fang Wang, William~Yang Wang, and Lei Zhang.
\newblock Reinforced cross-modal matching and self-supervised imitation
  learning for vision-language navigation.
\newblock In {\em Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, pages 6629--6638, 2019.

\bibitem{wang2020environment}
Xin~Eric Wang, Vihan Jain, Eugene Ie, William~Yang Wang, Zornitsa Kozareva, and
  Sujith Ravi.
\newblock Environment-agnostic multitask learning for natural language grounded
  navigation.
\newblock In {\em Computer Vision--ECCV 2020: 16th European Conference,
  Glasgow, UK, August 23--28, 2020, Proceedings, Part XXIV 16}, pages 413--430.
  Springer, 2020.

\bibitem{wang2022internvideo}
Yi Wang, Kunchang Li, Yizhuo Li, Yinan He, Bingkun Huang, Zhiyu Zhao, Hongjie
  Zhang, Jilan Xu, Yi Liu, Zun Wang, Sen Xing, Guo Chen, Junting Pan, Jiashuo
  Yu, Yali Wang, Limin Wang, and Yu Qiao.
\newblock Internvideo: General video foundation models via generative and
  discriminative learning.
\newblock {\em arXiv preprint arXiv:2212.03191}, 2022.

\bibitem{wijmans2020ddppo}
Erik Wijmans, Abhishek Kadian, Ari Morcos, Stefan Lee, Irfan Essa, Devi Parikh,
  Manolis Savva, and Dhruv Batra.
\newblock {DD-PPO}: {L}earning near-perfect pointgoal navigators from 2.5
  billion frames.
\newblock In {\em International Conference on Learning Representations (ICLR)},
  2020.

\bibitem{wu2021improvedspeaker}
Zongkai Wu, Zihan Liu, Ting Wang, and Donglin Wang.
\newblock Improved speaker and navigator for vision-and-language navigation.
\newblock {\em IEEE MultiMedia}, 28(4):55--63, 2021.

\bibitem{xia2018gibson}
Fei Xia, Amir~R Zamir, Zhiyang He, Alexander Sax, Jitendra Malik, and Silvio
  Savarese.
\newblock Gibson env: Real-world perception for embodied agents.
\newblock In {\em Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, pages 9068--9079, 2018.

\bibitem{xie2022beam}
Liang Xie, Meishan Zhang, You Li, Wei Qin, Ye Yan, and Erwei Yin.
\newblock Vision--language navigation with beam-constrained global
  normalization.
\newblock {\em IEEE Transactions on Neural Networks and Learning Systems},
  2022.

\bibitem{zhangdiagnosing}
Yubo Zhang, Hao Tan, and Mohit Bansal.
\newblock Diagnosing the environment bias in vision-and-language navigation.
\newblock {\em IJCAI}, 2020.

\bibitem{zhao2021comodgan}
Shengyu Zhao, Jonathan Cui, Yilun Sheng, Yue Dong, Xiao Liang, Eric~I Chang,
  and Yan Xu.
\newblock Large scale image completion via co-modulated generative adversarial
  networks.
\newblock {\em arXiv preprint arXiv:2103.10428}, 2021.

\bibitem{zhao2021large}
Shengyu Zhao, Jonathan Cui, Yilun Sheng, Yue Dong, Xiao Liang, Eric~I Chang,
  and Yan Xu.
\newblock Large scale image completion via co-modulated generative adversarial
  networks.
\newblock {\em arXiv preprint arXiv:2103.10428}, 2021.

\bibitem{zhao2022target}
Yusheng Zhao, Jinyu Chen, Chen Gao, Wenguan Wang, Lirong Yang, Haibing Ren,
  Huaxia Xia, and Si Liu.
\newblock Target-driven structured transformer planner for vision-language
  navigation.
\newblock In {\em Proceedings of the 30th ACM International Conference on
  Multimedia}, pages 4194--4203, 2022.

\bibitem{zhou2023navgpt}
Gengze Zhou, Yicong Hong, and Qi Wu.
\newblock Navgpt: Explicit reasoning in vision-and-language navigation with
  large language models.
\newblock {\em arXiv preprint arXiv:2305.16986}, 2023.

\bibitem{zhu2021soon}
Fengda Zhu, Xiwen Liang, Yi Zhu, Qizhi Yu, Xiaojun Chang, and Xiaodan Liang.
\newblock Soon: Scenario oriented object navigation with graph-based
  exploration.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 12689--12699, 2021.

\bibitem{zhu2020vision}
Fengda Zhu, Yi Zhu, Xiaojun Chang, and Xiaodan Liang.
\newblock Vision-language navigation with self-supervised auxiliary reasoning
  tasks.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 10012--10022, 2020.

\bibitem{zhu2021scoa}
Yi Zhu, Yue Weng, Fengda Zhu, Xiaodan Liang, Qixiang Ye, Yutong Lu, and Jianbin
  Jiao.
\newblock Self-motivated communication agent for real-world vision-dialog
  navigation.
\newblock In {\em Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pages 1594--1603, 2021.

\end{thebibliography}
