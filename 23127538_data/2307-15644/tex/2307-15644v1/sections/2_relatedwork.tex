\section{Related Works}
\label{sec:rel_works}

\paragraph{Vision-and-Language Navigation}
Learning to navigate in unvisited environments following natural language instructions is an important step toward intelligent robots that can assist humans with daily activities. In the past years, a great variety of scenarios have been proposed for VLN research, such as navigation with comprehensive language guidance~\cite{anderson2018r2r,jain2019stay,anderson2020rxr}, navigation by interpreting dialog history~\cite{de2018talk,padmakumar2022teach,thomason2020cvdn}, grounding remote objects with high-level instructions~\cite{qi2020reverie,zhu2021soon}, and navigation in continuous environments that closely approximate the real world~\cite{krantz2022iterative,krantz2020navgraph}. To address the problem, early research mainly focuses on developing task-specific models and training methods to better exploit visual-textual correspondence for decision making~\cite{an2021neighbor,anderson2019chasing,deng2020evolving,ke2019tactical,lin2022multimodal,ma2019self,qi2021road,qi2020object,wang2020active}.


\paragraph{Large-Scale Visual Navigation Learning}
Due to the expensive navigational data collection process, learning to navigate usually faces a data scarcity issue~\cite{habitat2020sim2real,anderson2018r2r,batra2020rearrangement, batra2020objectnav,ehsani2021manipulathor,anderson2020rxr,qi2020reverie,thomason2020cvdn}. Many works have been proposed to scale up the training data by collecting more human annotations~\cite{ramrakhya2022habweb} or creating new environments~\cite{deitke2022procthor,ramakrishnan2021hm3d}. Moreover, recent studies tend to establish a scalable regime, utilizing extensive automatically-generated data to push the limit of agent performance~\cite{chen2022hm3dlearning,kamath2022marval}, or introducing large-scale pre-training approaches to improve the generalizing ability~\cite{chen2021hamt,li2023vlnsig,qiao2023hop+}. In this paper, we create a simple paradigm for scaling VLN training, and through comprehensive analysis, we seek a valuable guideline for data acquisition and agent training for future research.
