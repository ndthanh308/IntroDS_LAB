\documentclass[10pt,twocolumn,letterpaper]{article}

\usepackage{iccv}
\usepackage{times}
\usepackage{epsfig}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}

% Include other packages here, before hyperref.
\usepackage{booktabs}
\usepackage{enumitem}
\usepackage{multirow}
\usepackage{soul}
\usepackage{pifont} % http://ctan.org/pkg/pifont
\usepackage[T1]{fontenc}
\usepackage{mathabx}
\usepackage{makecell}
\usepackage[dvipsnames]{xcolor}
\usepackage{color, colortbl}
\usepackage{caption}

\newcommand{\hao}[1]{\textcolor{brown}{\small{\bf [ #1 -- Hao ]}}}
\newcommand{\mbc}[1]{{\protect\color{blue}{[ #1 --Mohit ]}}}
\newcommand{\blue}[1]{{\textbf{\color{blue}#1}}}
\newcommand\Tstrut{\rule{0pt}{2.3ex}}         % = `top' strut
\newcommand\Bstrut{\rule[-0.9ex]{0pt}{0pt}}   % = `bottom' strut

\def\CircleArrowright{\ensuremath{%
  \rotatebox[origin=c]{310}{$\circlearrowright$}}}
\DeclareRobustCommand{\star}{%
  \begingroup\normalfont
  % Figure removed%
  \endgroup
}
\newcommand{\vlnbert}{VLN$\protect\CircleArrowright$BERT}
\newcommand{\ours}{ScaleVLN}

% If you comment hyperref and then uncomment it, you should delete
% egpaper.aux before re-running latex.  (Or just hit 'q' on the first latex
% run, let it finish, and you should be clear).
\usepackage[pagebackref=true,breaklinks=true,letterpaper=true,colorlinks,bookmarks=false]{hyperref}

\iccvfinalcopy % *** Uncomment this line for the final submission

\def\iccvPaperID{4534} % *** Enter the ICCV Paper ID here
\def\httilde{\mbox{\tt\raisebox{-.5ex}{\symbol{126}}}}

% Pages are numbered in submission mode, and unnumbered in camera-ready
\ificcvfinal\pagestyle{empty}\fi

\begin{document}

%%%%%%%%% TITLE
\title{Scaling Data Generation in Vision-and-Language Navigation}

\author{Zun Wang$^{*\spadesuit1,2}$ \quad Jialu Li$^{*3}$ 
\quad Yicong Hong$^{*\dag1}$ \\
Yi Wang$^2$ \quad Qi Wu$^4$ \quad Mohit Bansal$^3$ \quad Stephen Gould$^1$ \quad
Hao Tan$^5$ \quad Yu Qiao$^2$ \\
$^1$The Australian National University\quad$^2$OpenGVLab, Shanghai AI Laboratory\quad\\
$^3$UNC, Chapel Hill\quad$^4$University of Adelaide\quad
$^5$Adobe Research\\ 
{\tt\small wangzun@pjlab.org.cn, jialuli@cs.unc.edu, mr.yiconghong@gmail.com} \\ 
{\tt\small  Project URL: \url{https://github.com/wz0919/ScaleVLN}}
}

\maketitle
% Remove page # from the first page of camera-ready.
\ificcvfinal\thispagestyle{empty}\fi

%%%%%%%%% ABSTRACT
\begin{abstract}
Recent research in language-guided visual navigation has demonstrated a significant demand for the diversity of traversable environments and the quantity of supervision for training generalizable agents. To tackle the common data scarcity issue in existing vision-and-language navigation datasets, we propose an effective paradigm for generating large-scale data for learning, which applies 1200+ photo-realistic environments from HM3D and Gibson datasets and synthesizes 4.9 million instruction-trajectory pairs using fully-accessible resources on the web. Importantly, we investigate the influence of each component in this paradigm on the agent's performance and study how to adequately apply the augmented data to pre-train and fine-tune an agent. Thanks to our large-scale dataset, the performance of an existing agent can be pushed up (+11\% absolute with regard to previous SoTA) to a significantly new best of 80\% single-run success rate on the R2R test split by simple imitation learning. The long-lasting generalization gap between navigating in seen and unseen environments is also reduced to less than 1\% (versus 8\% in the previous best method). 
Moreover, our paradigm also facilitates different models to achieve new state-of-the-art navigation results on CVDN, REVERIE, and R2R in continuous environments.

{\let\thefootnote\relax\footnote{$^{*}$Equal contribution. $^{\dag}$Project lead.}}
{\let\thefootnote\relax\footnote{ $^{\spadesuit}$Research done during internship at Shanghai AI Lab.}}

\end{abstract}

%%%%%%%%% BODY TEXT

\input{sections/1_intro}
\input{sections/2_relatedwork}
\input{sections/3_method}
\input{sections/4_exp}
\input{sections/5_conclusion}
\input{sections/6_ack}

%% ----------------------------------------

{\small
\bibliographystyle{ieee_fullname}
\bibliography{egbib}
}

\clearpage
\appendix
\input{sections/7_supp}

\end{document}