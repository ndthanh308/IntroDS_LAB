%--------------------------------------------
\newpage
\begin{appendices}


\section{Proof that $\mathcal{Perm}(V, w)$ computes $\SWAP(V, w)$}

The proof is relatively simple given the well-known form of the irreducible representations of the Symmetric group.  For completeness we review the necessary background before proving the theorem at the end of the section.  

\subsection{Representation Theory}\label{sec:rep_theory}
Given a finite group $G$ a representation is a pair $(\rho, V)$ where $V$ is a vector space and $\rho: G\rightarrow GL(V)$ which is a homomorphism of groups.  As such, $\rho(g) \in GL(V)$ satisfies $\rho(g_1 g_2)=\rho(g_1) \rho(g_2)$ and $\rho(g^{-1})=\rho(g)^{-1}$.  We say two representations $(\rho_1, V)$ and $(\rho_2, W)$ are isomorphic if there is an isomorphism of vector spaces $T: V\rightarrow W$ which satisfies $T\rho_1(g) T^{-1} =\rho_2(g) $ for all $g\in G$.  If $(\rho, V)$ is a representation and $V'\subseteq V$ is a subspace satisfying $\rho(g) \ket{v'} \in V'$ for all $\ket{v'} \in V'$ and $g\in G$ then $V'$ is called a $G$-invariant subspace.  A representation $(\rho, V)$ is called irreducible if the only $G$-invariant subspaces are $V$ and $\{0\}$.  We will refer to an irreducible representation simply as an irrep. 
 We will often drop the function $\rho$ from a representation and talk about elements of the group as acting on vectors from $V$, i.e. $g \ket{v}:= \rho(g) \ket{v} $.  

The group algebra, denoted $\mathbb{C}[G]$, is a particular representation which fully captures the representation theory of a given group.  This is the vector space of formal complex linear combinations of the group elements $\mathbb{C}[G]=\{\sum_{g\in G} c_g g :\,\, c_g \in \mathbb{C} \,\, \forall g\}$.  $G$ acts on this space according to the multiplcation rule of the group: $g\sum_{g'\in G} c_{g'} g'=\sum_{g'\in G} c_{g'} g g' $.  The vector space is also an algebra with multiplication extended by linearity to the formal sums: $\left( \sum_{g\in G} b_g g \right) \left(\sum_{g'\in G} c_{g'} g' \right)=\sum_{g, g'\in G} b_g c_{g'} g g'$.

It is natural in the setting of representations to consider ``algebraic constraints''.  If $p=\sum_g c_g g \in \mathbb{C}[S_n]$, we say $(\rho, V)$ satisfies constraint $p$ if
$$
\sum_{g \in G} c_g \rho(g)=0.
$$
It is clear that if $(\rho_1, V)$ and $(\rho_2, W)$ are isomorphic representations then $(\rho_1, V)$ satisfies constraint $p$ if and only if $(\rho_2, W)$ satisfies constraint $p$:
$$
\sum_g c_g \rho_1(g)=0 \Leftrightarrow T\left( \sum_g c_g \rho_1(g)\right) T^{-1}=0 \Leftrightarrow \sum_g c_g \rho_2(g)=0.
$$
So, it well-defined to say a particular representation satisfies an algebraic constraint without reference to an explicit basis (any isomorphic representation also satisfies the constraint).  Similarly it is well-defined to talk about eigenvalues of a representation in abstraction since the characteristic polynomial is invariant under isomorphism:
\begin{align*}
\det\bigg(\lambda\mathbb{I}-\sum_g c_g \rho_1 (g)\bigg)=0 \Leftrightarrow \det(T) \det(T^{-1})\det\bigg(\lambda\mathbb{I}-\sum_g c_g \rho_1 (g)\bigg)=0 \\
\Leftrightarrow \det\bigg(T \left( \lambda\mathbb{I}-\sum_g c_g \rho_1 (g)\right)T^{-1}\bigg)=0\Leftrightarrow \det\bigg(\lambda\mathbb{I}-\sum_g c_g \rho_2 (g)\bigg)=0
\end{align*}

The central theorem of representation theory for finite groups is that an arbitrary representation $(\rho', V')$ is isomorphic to one which decomposes into irreps.  For every group $G$ there is some finite list of irreps $\{V_1, V_2, ... V_q\}$ such that an arbitrary finite dimensional representation $(\rho', V')$ is isomorphic to a representation $(\rho, V)$ where for a set of non-negative integers $\{m_i\}_{i=1}^q$ $V$, decomposes as $V=\bigoplus_{i=1}^q m_i V_i$ where $m_iV_i= \bigoplus_{j=0}^{m_i} V_i$ ($m_i$ copies of $V_i$).  Further it holds that $\rho(g)$ is block diagonal in this decomposition for all $g\in G$.  In this decomposition the block of $\rho(g)$ corresponding to a particular $V_i$ is simply $\rho_i(g)$ where $\rho_i$ is the representation corresponding to $V_i$.  

Now we may reinterpret the previous observations about the spectrum and constraints in the context of this decomposition.  Since $\rho(g)=\bigoplus_i m_i \rho_i(g)$ is block diagonal, a particular constraint is satisfied by $(\rho, V) \cong \bigg(\bigoplus_i m_i V_i, \bigoplus_i m_i \rho_i(g) \bigg)$ if and only if it is satisfied by all the irreps $V_i$ in the decomposition with $m_i \geq 1$.  We say an irrep $V_i$ is involved in $(\rho, V)$ if $m_i\geq 1 $.  Further we can find the smallest/largest eigenvalue of some $p \in \mathbb{C}[G]$ in $(\rho, V)$ by finding the smallest/largest eigenvalue of each irrep and taking the minimum/maximum of the set of eigenvalues. 

For any set $X$, $G=\langle X \rangle_F$ is the free group generated by strings of elements from $X$.  The product of two strings is defined as their concatenation and $x^{-1}$ is formally defined so that the set of strings composed of $x$ and $x^{-1}$ forms a group: $\langle X \rangle_F= \{x_1... x_p:  x_i \in X \text{ or } x_i^{-1} \in X \,\, \forall i\}$.  If $R\subseteq \langle X\rangle$ then $G=\langle X | R \rangle_F := \langle X \rangle_F/N $ where $N$ is the smallest normal subgroup of $\langle X \rangle_F$ containing $R$.  If $H$ is some group generated by $X$, then we say group $H$ has a finite presentation given by generators $X$ and relations $R$ if $H\cong \langle X|R\rangle_F$ (isomorphism of groups).  

\subsection{Specht Modules}\label{sec:specht}

Before presenting the proof of \Cref{thm:perm_is_opt} we will need a little background on the irreps of the Symmetric group.  This material is all standard, please see \cite{jam06} or \cite{ful13} for a reference.  Irreps of $S_n$ are parameterized by partitions of $n$.  Formally, $Part_n=\{(\lambda_1, \lambda_2, ..., \lambda_d): \,\, d\leq n, \,\, \lambda_i\in \mathbb{Z}_{ > 0}, \text{ and } \lambda_i \geq \lambda_{i+1} \forall i\}$.  We will designate a partition $(\lambda_1, ..., \lambda_d)$ simply as $\lambda$.  Partitions correspond uniquely to Young diagrams.  A Young diagram consists of rows of adjacent squares where the number of squares in row $i$ is $\lambda_i$:
\begin{center}
$(4, 2, 1) \leftrightarrow $\,\,\,\ydiagram{4, 2, 1}.
\end{center}
A Young Tableaux is a numbering of the boxes of a diagram using $[n]$, i.e.
\begin{center}
\begin{ytableau}
2 & 1 & 7 & 6 \\
3 & 5 \\
4
\end{ytableau}.
\end{center}
We say that a Young tableaux is of shape $\lambda\in Part_n$ if it is obtained by numbering the diagram corresponding to partition $\lambda$.  For $d\leq n$ we define a{\it Young fragment} as a labeling of a diagram from $Part_d$ using a subset of the letters, $A\subseteq [n]$.  This is simply a Young Tableaux for $S_d$ but with some of the letters replaced by elements of $[n]$, i.e.
\begin{center}
\begin{equation}\label{eq:young_frag_ex}
\begin{ytableau}
2 & 1 & 7 & 6 \\
3 
\end{ytableau}.
\end{equation}
\end{center}


A group action of $S_n$ on Young Tableaux can be naturally defined where $\sigma \in S_n$ acts on a tableaux by permuting the letters in each box according to $\sigma$.  Formally if $[a_1, ..., a_p]$ is a row of $t$ then the corresponding row of $\sigma \,t$ is $[\sigma(a_1), ..., \sigma(a_p)]$:
\begin{center}
\begin{equation}\label{eq:action_on_tab}
\begin{array}{|c|c|c|}
\hline
1 & 2 & 3\\
\hline
 4 & 5 & 6\\
\hline
 7&\multicolumn{2}{c}{}\\
\cline{1-1}
\end{array}
\xrightarrow[]{\sigma}
\begin{array}{|c|c|c|}
\hline
\sigma(1) & \sigma(2) & \sigma(3)\\
\hline
 \sigma(4) & \sigma(5) & \sigma(6)\\
\hline
 \sigma(7)&\multicolumn{2}{c}{}\\
\cline{1-1}
\end{array}.
\end{equation}
\end{center}
Given a tableaux $t$ we define $R_t$ and $C_t$ as the row and column stabilizer respectively.  Formally, $\sigma \in R_t$ if every row of $\sigma \,t$ has the same elements as the corresponding row of $t$ (possibly with a permuted order).  In the example in \Cref{eq:action_on_tab}, $R_t$ is the set of all permutations $\sigma\in S_7$ such that $\sigma(\{1, 2, 3\})=\{1, 2, 3\}$, $\sigma(\{4, 5, 6\})=\{4, 5, 6\}$ and $\sigma(7)=7$.  $C_t$ is defined analogously.  Given a Young fragment $f$ the row stabilizer $R_f$ is defined as the set of all permutations which stabilize the rows of $f$ as well as the letters not included in $f$.  For the example in \Cref{eq:young_frag_ex} $n=7$ so $\sigma \in R_f$ if $\sigma(\{2, 1, 7, 6\})=\{2, 1, 7, 6\}$, $\sigma(3)=3$, $\sigma(4)=4$ and $\sigma(5)=5$.  

Given a tableaux or fragment $f$ (note that tableau are also fragments) we can now define the{\it Young symmeterizer} as:
\begin{equation}
Y_f=\sum_{\sigma \in R_f} \sum_{\gamma \in C_f} sign(\gamma) \sigma \gamma \in \mathbb{C}[S_n].
\end{equation}
In general we will denote $a_f =\sum_{\sigma \in R_f} \sigma $ and $b_f=\sum_{\gamma \in C_f } sign(\gamma) \gamma$ so that $Y_f=a_f b_f$.

Young symmeterizers can be used to construct all the representations of $S_n$ as subspaces of $\mathbb{C}[S_n]$.  For $t$ some tableaux of shape $\lambda$ define the subspace
\begin{equation}
    V_t=\left\{\left(\sum_{g\in G} c_g g\right) Y_t: c_g \in \mathbb{C} \,\, \forall g\right\}\subseteq \mathbb{C}[S_n].
\end{equation}
We interpret $V_t$ as a representation of $S_n$ by acting from the left with elements of $S_n$ (a left $S_n-$module) and interpreting the resulting expression using multiplication in the group algebra.  If $t$ and $t'$ are tableau of the same shape $\lambda$ then $V_t \cong V_{t'}$, so we will often denote $V_t$ simply as $V_\lambda$.  The set of subspaces $\{V_\lambda\}$ form a complete set of representatives for irreps of the symmetric group:
\begin{theorem}[\cite{ful13} Theorem 4.3]
For each $\lambda\in Part_n$ let $t(\lambda)$ be some tableaux of shape $\lambda$.  $\{V_{t(\lambda)}\}_{\lambda\in Part_n}$ is a complete set of irreps for $S_n$.
\end{theorem}
The Young symmeterizers act in many ways as projectors onto the corresponding irreps.  Indeed, a crucial property (see \cite{ful13} Lemma 4.26) of $Y_t$ is that $V_t Y_t =V_t$ or equivalently that:
\begin{equation}\label{eq:square_young}
    Y_t^2= n_t Y_t
\end{equation}
with $n_t > 0$.

Let $t$ be a Young tableaux of shape $\lambda$ and let $f$ be a fragment.  We say that $f${\it fits inside} $\lambda$ if $f$ is contained in $t$ when we place the two diagrams on top of each other with the top left corners coincident (see \Cref{fig:fit_no_fit}).  In order to formally define this let $t$ have $k$ rows $r_1, ..., r_k$ with $s_i$ elements in $r_i$.  Let $f$ have $\ell$ rows $q_1, ..., q_\ell$ with row $q_i$ having $x_i$ elements.  We say that $f$ fits inside $\lambda$ or $t$ if $\ell \leq t$  and $x_i \leq s_i$ for all $i \in [\ell]$.  The main fact that we will need in this context is that inside a subspace $V_t$, $V_f=0$ for all fragments $f$ of a given shape (as a constraint) if and only if $f$ does not fit in $t$.  We will only use a special case of this known result (Pieri's rule), namely when $f$ is of shape $\lambda=(1, 1, 1)$, so we provide a simple proof of this fact for the readers convenience.  

\begin{theorem}[\cite{ful13} Exercise 4.44]\label{thm:fragment}
Let $t$ be some tableaux.  If $t$ is of shape $(n-d, d)$ then all fragments $f$ of shape $(1, 1, 1)$ evaluate to $0$ on $V_t$: $Y_f p Y_t=0$ for all $p\in \mathbb{C}[S_n]$.  If $t$ has more than two rows ($t$ is of shape $(\lambda_1, ... \lambda_d)$ for $d\geq 3$) then there exists a fragment $f$ of shape $(1, 1, 1)$ such that $Y_f\neq 0$ on $V_t$.   
\end{theorem}
\begin{proof}
Let $f$ be the fragment corresponding to a single column with the letters $f_1, f_2$ and $f_3$.  For the first part of the theorem by linearity it is sufficient to show $Y_f g Y_t=0 $ for all $g\in S_n$.  It is simple to verify that $gY_t g^{-1}=Y_{gt}$ so $Y_f g Y_t=Y_f Y_{t'} g$ for $t'$ the same shape as $t$.  Since $t$ has two rows, two of $\{f_1, f_2, f_3\}$ must be in the same row of $t'$.  WLOG assume $f_1$ and $f_2$ are in the same row of $t'$.  Since row and column stabilizers are subgroups of the $S_n$ and since $sign(\gamma (f_1, f_2))=-sign(\gamma)$ for all $\gamma \in S_n$, it holds that 
\begin{align}
a_{t'} =\frac{1+(f_1, f_2)}{2} a_{t'}  \,\,\,\,\,\, \text{and} \,\,\,\,\,\,  b_{f}=b_{f} \frac{1-(f_1, f_2)}{2},
\end{align}
where $(f_1, f_2)$ is the transposition of $f_1$ and $f_2$.
It follows that 
$$
Y_f g Y_t= b_f a_{t'} b_{t'}= b_f \frac{1-(f_1, f_2)}{2} \frac{1+(f_1, f_2)}{2} a_{t'} b_{t'} =0
$$

For the second part of the theorem given $t$ we want to give a fragment $f$ and $p\in \mathbb{C}[S_n]$ such that $Y_f p Y_t \neq 0$.  Let $f_1$, $f_2$ and $f_3$ be the first three numbers in the first column of $t$ and let $p=b_t a_t$.  Once again since $R_t$ is a subgroup of $S_n$ it holds that $a_t^2 = |R_t|\, a_t$.  By the definition of $f$ and the fact that $C_t$ is a subgroup it holds that: for any $\sigma \in C_f$, $sign(\sigma) \sigma b_t=b_t$.  Hence,
$$
Y_fp Y_t=b_f b_t a_t a_t b_t =|C_f| \,  b_t a_t a_t b_t= |C_f| \, |R_t|\, b_t a_t b_t. 
$$
Since $a_t (b_t a_t b_t) =Y_t^2 \neq 0$ by \Cref{eq:square_young}, $Y_fp Y_t= b_t a_t b_t\neq 0$.

\end{proof}



%For $\lambda$ a diagram of $n$ we define $\{\ket{t}\}=Tabx(\lambda)$ as the space of Young tableaux. It is natural to define a group action of $S_n$ on $Tabx(\lambda)$ by acting on the letters inside each of the boxes.  Formally $\sigma \ket{t} = \ket{\sigma t}$ where if box $i$ from tableuax $t$ has value $j$, then box $i$ in tableaux $\sigma t$ has value $\sigma(j)$.  Given a tableaux $t$ we define the row stabilizer $R_t$ as the set of permutations which leave the rows invariant, while the column stabilizer is the set of permutations which leave the columns invariant.  A tabloid is a equivalence class of Young Tableaux where we equate two Young Tablueax if they are equal up to a permutation of the rows.  We can represent this by taking Young Tableaux and removing the vertical lines:
%\ytableausetup{boxsize=normal,tabloids}
%\begin{center}
%\begin{ytableau}
%2 & 1 & 7 & 6 \\
%3 & 5 \\
%4
%\end{ytableau},
%\end{center}
%with the idea being that the tabloid is the same independent of the order in which we write the letters in the rows.  The tabloid constructed from tableaux $t$ will be denoted $\ket{\{t\}}$ and the space of tabloid vectors will be denoted $M^\lambda$ (this is generally called the permutation module).  The permutation group acts tabloids in the same way as tableaux, by permuting the letters in each of the rows.  This group action satisfies $\sigma\ket{\{t\}}=\ket{\{\sigma t\}}$.  Note that a permutation which permutes only the letters in a particular row acts as the identity on that particular tabloid.  

%We can also define the polytabloid associated to a particular tableaux as 
%$$
%|e_t\rangle =\sum_{\sigma \in C_t} sign(\sigma) \sigma \ket{\{t\}}.
%$$
%The group action satisfies 
%\begin{equation}\label{eq:polytabloid_relations}
%\sigma \ket{e_t}=\ket{e_{\sigma t}} \,\,\forall\,\, \sigma \in S_n; \,\,\,\,\, \sigma \ket{e_t}=sign(\sigma) \ket{e_t} \,\,\forall\,\, \sigma \in C_t.
%\end{equation}
%We further define $V_\lambda=span(\ket{e_t}: t\in Tabx(\lambda))$.  The previous discussion establishes that $V_\lambda$ is a representation of the symmetric group.  It is known that the subspaces $V_\lambda$ form a complete set of irreps for the symmetric group, so any irrep of $S_n$ must be isomorphic to $V_\lambda$ for some $\lambda\in Part_n$ and any representation must be isomorphic to $\bigoplus_{\lambda\in Part_n} m_{\lambda} V_{\lambda}$ for non-negative integers $m_\lambda$.  



The quantum permutation unitaries have a well known decomposition into irreps of $S_n$, we will need the decomposition here.  If $\sigma\in S_n$ is a permutation we can define the permutation unitary 
\begin{equation}
p(\sigma) \ket{x_1} \ket{x_2} ... \ket{x_n}=\ket{x_{\sigma^{-1}(1) }} \ket{x_{\sigma^{-1}(1) }}... \ket{x_{\sigma^{-1} (n)}}.
\end{equation}
$(p, (\mathbb{C}^2)^{\otimes n})$ is a representation of the symmetric group with known decomposition into irreps:
\begin{equation}\label{eq:quantum_irreps}
(\mathbb{C}^2)^{\otimes n} \cong \bigoplus_{\substack{\lambda\in Part_n:\\ \lambda=(n-d, d)}} (n+1-2 d) V_\lambda
\end{equation}

\subsection{Proof of \Cref{thm:perm_is_opt}}\label{sec:perm_conv}

Let $Q_{ij}$ be some feasible solution for $\mathcal{Perm}$.  The set of matrices generated by $\{Q_{ij}\}$ is naturally a group since $Q_{ij}$ is self-inverse.  Let this group be denoted $G'$.  We will demonstrate a homomorphism $\psi: S_n \rightarrow G'$ which implies the operators $\{Q_{ij}\}$ correspond to a representation of the Symmetric group.  Then we note that the final set of constraints, \Cref{eq:anti_comm}, is only valid if the representation can be decomposed into certain irreps of the symmetric group (exactly those in \Cref{eq:quantum_irreps}).  This then implies that the permutation programs gets the optimal quantum eigenvalue by the discussion in \Cref{sec:rep_theory}.

Let $E=\{ij: i, j \in [n] \text{ and } i<j\}$ be the set of all possible undirected edges.  Define $X=\{q_{ij}\}_{ij\in E}$.  Recall from \Cref{sec:rep_theory} that $\langle X \rangle_F$ is the group set of strings with elements from $X$ where multiplication is defined through concatenation.  Here we are treating the operator variables as formal symbols in the context of the free group.  Let $R_1, R_2, R_3 \subseteq \langle X \rangle_F$ be defined as 
\begin{gather*}
R_1=\{q_{ij}^2:\,\,ij \in E\},\\
R_2=\{(q_{ij}q_{kl})^2: \,\, ij, kl \in E \text{ and $i$, $j$, $k$, $l$ all distinct}\},\\
\text{ and }R_3=\{(q_{ij} q_{jk})^3: ij, jk \in E \text{ and $i$, $j$ $k$ all distinct}\}.
\end{gather*}
Using the self-inverse property of the operators $Q_{ij}$ it is clear that $(Q_{ij}Q_{kl})^2=\mathbb{I}$ and $(Q_{ij} Q_{jk})^3=\mathbb{I}$ are equivalent to sets of constraints \Cref{eq:sym_const_2} and \Cref{eq:sym_const_3} respectively.  Let $R=R_1 \cup R_2 \cup R_3$ and let $N$ be the smallest normal subgroup containing $R$. It is known \cite{C13} that $S_n$ has a finite presentation with generators $X$ and relations $R$ so $S_n \cong \langle X\rangle_F/N$.  In particular it is known that the map $\rho: S_n \rightarrow  \langle X\rangle_F/N$ defined by $ \rho((i, j)) = q_{ij} N$ (which is extended to $S_n$ by writing a permutation as a product of transpositions) is well-defined and an isomorphism of groups.  Let $\theta: \langle X \rangle_F \rightarrow G'$ be the map defined as 
\begin{gather*}
\theta(q_{i_1j_1}q_{i_2j_2} ...q_{i_qj_q}) = Q_{i_1j_1}\,\,Q_{i_2j_2} \,\,... \,\, Q_{i_qj_q},  \\
\theta(1) =\mathbb{I}.
\end{gather*}
Since $Q_{ij}$ is self-inverse it is clear that $\theta$ is a homomorphism of groups.  Since $N=\langle g r g^{-1} : \,\, r\in R, g\in \langle X \rangle_F\,\, \rangle $, 
$$
\theta((g_1 r_1 g_1^{-1})(g_2 r_2 g_2^{-1})... (g_q r_q g_q^{-1}))= \theta(g_1) \theta(r_1) \theta(g_1)^{-1}\theta(g_2) \theta(r_2) \theta(g_2)^{-1} ... \theta(g_q) \theta(r_q) \theta(g_q)^{-1}.
$$
The operators satisfy constraints from $R$ so $\theta(r_i)=\mathbb{I}$ for all $i$ and $\theta(n)=\mathbb{I}$ for all $n\in N$.  Let $b: \langle X \rangle_F\rightarrow \langle X \rangle_F/N $ be the homomorphism defined as $b(g)=g N$.  The ``Fundamental theorem on homomorphisms'' (Theorem 26 from \cite{M99}) implies the existence of a homomorphism $\phi: \langle X \rangle_F/N \rightarrow G'$ such that $\theta= \phi \circ b$.  Note that $\phi$ must map $q_{ij}N \rightarrow Q_{ij}$.  It follows that the map $\psi:=\phi\circ\rho: S_n \rightarrow G'$ is a homomorphism of groups and that the operators $Q_{ij}$ must correspond to a valid representation of $S_n$. Let this representation be denoted $(\psi, W)$ where $W$ is the Hilbert space on which the $Q_{ij}$ act.

By \Cref{sec:rep_theory} $(\psi, W)$ must be isomorphic to a decomposition of the form $\left(\bigoplus_\lambda m_\lambda \rho_\lambda, \bigoplus_\lambda m_\lambda V_\lambda\right) $ where $V_\lambda$ are the spaces defined in \Cref{sec:specht}.  We will demonstrate that $m_{\lambda}=0$ unless $\lambda=(n-d, d)$.  First note that the final set of constraints  \Cref{eq:anti_comm} all correspond to young fragments (see \Cref{sec:specht})
\begin{align}
    \mathbb{I}-Q_{ij}-Q_{jk} -Q_{ik}+Q_{ij}Q_{jk}+Q_{jk}Q_{ij}=0 \\ 
    \nonumber \Leftrightarrow \psi(1)-\psi((i, j))-\psi((j, k))-\psi((i, k))+\psi((i, j)(j, k))+\psi((j, k)(i, j))=0,
\end{align}
which is then equivalent to $Y_f=0$ for $f$ the fragment
\begin{center}
\begin{equation} 
f=\begin{ytableau}
i \\
j \\
k
\end{ytableau}.
\end{equation}
\end{center}
By \Cref{thm:fragment}, $Y_f=0$ for all such $f$ on a subspace $ V_\lambda$ if and only if $\lambda=(n-d, d)$.  It follows that $m_\lambda>0$ only for $\lambda=(n-d, d)$ so $\mathcal{Perm}(G, w) \leq \SWAP(G, w)$.  Taking the quantum swap operators and the optimal eigenstate as a feasible solution ($p_{ij}=P_{ij}$ from \Cref{eq:swap_def}) we can see that $\mathcal{Perm}(G, w) \geq \SWAP(G, w)$ hence $\mathcal{Perm}(G, w)=\SWAP(G, w)$.


% Figure environment removed

%Since isomorphic representations satisfy the same constraints by \Cref{sec:rep_theory}, we can examine the explicit representations defined in \Cref{sec:specht} to determine the irreps present in $V$.  In particular we will see that the constraint set \Cref{eq:anti_comm} implies that $m_\lambda >0$ if and only if $\lambda=(n-d, d)$.  First note that all $V_{(n-d, d)}$ satisfy constraints in \Cref{eq:anti_comm}.  We can see this by checking that the quantum swap operators satisfy this constraint when them implies all the irreps involved satisfy these constraints.  By \Cref{eq:quantum_irreps} this is all $V_{(n-d, d)}$.  Now let $V_\lambda$ be any irrep with at least three rows.  Consider a tablueax $t$ with $1$, $2$ and $3$ the first three entries in column $1$:
%\begin{center}
%\ytableausetup
%{mathmode, boxframe=normal, boxsize=2em, notabloids}
%\begin{ytableau}
%1 & \none[\dots] & $*$ & $*$ \\
%2 & \none[\dots] & $*$  \\
%3 & \none[\ddots]\\
%\none[\vdots]\\
%$*$ 
%\end{ytableau}
%\end{center}
%Consider the constraint of the form of \Cref{eq:anti_comm} corresponding to $\{1, 2, 3\}$:
%$$
%P_{12} P_{23} + P_{23}P_{12}- P_{12}-P_{23}-P_{13}+\mathbb{I}=0.
%$$
%Since all the above permutations belong to the column stabilizer of $t$, by \Cref{eq:polytabloid_relations}
%\begin{align*}
%\left( P_{12} P_{23} + P_{23}P_{12}- P_{12}-P_{23}-P_{13}+\mathbb{I}\right) \ket{e_t}\\
%= P_{12} P_{23}\ket{e_t} + P_{23}P_{12} \ket{e_t}- P_{12}\ket{e_t}-P_{23}\ket{e_t}-P_{13}\ket{e_t}+\ket{e_t}=6\ket{e_t}.
%\end{align*}
%Hence for any irrep with at least three rows there is a constraint of the form of \Cref{eq:anti_comm} which is not satisfied.  It follows that the optimization $\mathcal{Perm}$ is an optimization over representations of the symmetric group with irreps restricted to those which are present in the \Cref{eq:quantum_irreps}.  Hence the optimal eigenvalue of $\sum_{jk} w_{jk} (i, j)\in \mathbb{C}[S_n]$ in $\mathcal{Perm}$ is:
%$$
%\min_{\substack{\lambda \in Part_n}:\\ \lambda=(n-d, d)} \lambda_{min} \left( \sum_{jk} w_{jk} \rho_\lambda((i, j))\right),
%$$
%just as in $\SWAP(G, w)$.

\begin{comment}
\section{$C^*$-algebras}

The second relaxation we consider will be referred to as the projector SDP relaxation. For this, we will need the formalism of $C^*$-algebras.

\begin{definition}
A \emph{$C^*$-algebra} $\mathcal{A}$ is a complex vector space equipped with the following operations:
\begin{enumerate}
	\item Multiplication which is associative, distributes over vector space addition, and has a unit $\mathbb{I} \in \mathcal{A}$.
	\item Involution $a \rightarrow a^*$ satisfying $(a^*)^*=a$, $(ab)^* = b^*a^*$, $(\lambda a + \mu b)^* = \bar{\lambda} a^* + \bar{\mu} b^*$.
	\item Norm $||\cdot||$ satisfying $||ab|| \leq ||a||\cdot||b||$ and $||a^*a|| = ||a||^2$.
\end{enumerate}

An element $a \in \mathcal{A}$ is \emph{self-adjoint} if $a^* = a$.

An element $a \in \mathcal{A}$ is \emph{positive}, denoted $a \geq 0$, if there is $b \in \mathcal{A}$ with $b^*b=a$.

A \emph{$C^*$-subalgebra} $\mathcal{B} \leq \mathcal{A}$ is a vector subspace which is a $C^*$-algebra under the restrictions of the operations on $\mathcal{A}$.
\end{definition}

It should be noted that the existence of a multiplicative unit $\mathbb{I} \in \mathcal{A}$ is often not required, and such $C^*$-algebras are often called \emph{unital} $C^*$-algebras. We take all $C^*$-algebras to be unital.

Operators on a Hilbert space $\mathcal{H}$ is the canonical example of a $C^*$-algebra, denoted $\mathcal{L}(\mathcal{H})$. Involution is the adjoint, and the norm is the operator norm $||a|| = \text{sup}\{ \sqrt{\langle\psi|a^*a|\psi\rangle} : \langle\psi|\psi\rangle = 1\}$.

\begin{theorem} \label{subalgebra_SDP}
Let $\mathcal{A} \leq \mathcal{L}(\mathcal{H})$ be a $C^*$-subalgebra containing $H$. Then the positive semi-definite program
\begin{align*}
SDP = \max_{M : \mathcal{A} \times \mathcal{A} \rightarrow \mathbb{C}} \quad & M(\mathbb{I},H) \\
\textrm{s.t.} \quad & M \succeq 0, \\
&M(\mathbb{I}, \mathbb{I}) = 1, \\
&M(a,b) = M(a',b'), \ \forall \ a^*b = a'^*b',
\end{align*}
is equal to $||H||$.
\end{theorem}

This is implied by the following lemma.

\begin{lemma}\label{lemma}
Let $\mathcal{A} \leq \mathcal{L}(\mathcal{H})$ be a $C^*$-subalgebra, and $t \in \mathcal{A}$. Suppose $t$ is positive semi-definite on $\mathcal{L}(\mathcal{H})$. Then $t$ is positive in $\mathcal{A}$.
\end{lemma}
\begin{proof}
We want to show that there is an $s \in \mathcal{A}$ with $s^*s = t$. Loosely speaking, we want to take the square root of $t$ inside $\mathcal{A}$. The spectrum of $t$ is some finite subset $\spec{t} \subset [0,\infty)$. There will exist a real polynomial $P$ mapping $\lambda \rightarrow \sqrt{\lambda}$ for every $\lambda \in \spec{t}$. Then $P(t)$ is a self-adjoint element of $\mathcal{A}$ with $P(t)^2 = t$.
\end{proof}

\begin{proof} \emph{of Theorem \ref{subalgebra_SDP}.}

Let $|\psi\rangle \in \mathcal{H}$, $\langle\psi|\psi\rangle = 1$, $\langle\psi|H|\psi\rangle = ||H||$. Define bilinear form $M$ on $\mathcal{A}$ by $M(a,b) = \langle\psi|a^*b|\psi\rangle$. Then $M$ satisfies the SDP constraints, and $M(\mathbb{I},H) = ||H||$. Thus $SDP \geq ||H||$.

For the other inequality, observe that $||H|| \mathbb{I} - H \in \mathcal{A}$ is positive semi-definite in $\mathcal{L}(\mathcal{H})$. By Lemma \ref{lemma}, $||H|| \mathbb{I} - H$ is positive in $\mathcal{A}$. That is, there exists $S \in \mathcal{A}$ with $S^*S = ||H|| \mathbb{I} - H$. Let $M$ be any bilinear form on $\mathcal{A}$ satisfying the SDP constraints. We have $M(\mathbb{I}, ||H|| \mathbb{I} - H) = M(S,S) \geq 0$, so $M(\mathbb{I}, H) \leq ||H|| M(\mathbb{I}, \mathbb{I}) = ||H||$. Thus $SDP \leq ||H||$.
\end{proof}

\end{comment}

\section{Derivations of relations in $\mathcal{Proj}$ from the minimal constraints} \label{app:relationderivation}

In \cref{subsec:qmcop} we argued from \cref{thm:perm_is_opt} that all relations among singlet projectors are derivable just from the minimal relations, namely \cref{eq:anticommproj,eq:singprojnormalize,eq:singproj1,eq:singproj2,eq:singprojcomm}. 
Here, we give concrete examples of such derivation. %, since although the possibility of them is logically immediate from the theorem, the actual derivation can become nontrivial in general. 
Let us first look into the prominent fact that all Heisenberg Hamiltonians have total spin as a good quantum number. 


\begin{proposition}\label{prop:totalspincons}
Any {\scshape QMaxCut} Hamiltonian $H$ preserves the total spin, i.e., commutes with $\sum_{i<j}h_{ij}$.
\end{proposition}

\begin{proof}
    Since any Hamiltonian is a summation of individual projector terms, we can consider a particular $h_{12}$ WLOG, and then if we can show $[h_{12},\sum_{i<j}h_{ij}]=0$, the proof is complete.
    From \cref{eq:singprojcomm}, $[h_{12},h_{ij}]=0$ if $i,j\neq 1,2$, so what remains in the sum $\sum_{i<j}h_{ij}$ that do not trivially commute are $\sum_{j\neq 1,2}(h_{1j}+h_{2j})$. 
    Now we show $[h_{12},h_{1j}+h_{2j}]=0$ for any $j$, proving the proposition. 
    The anticommutation relation \cref{eq:anticommproj} allows expanding $h_{12}$ in terms of $h_{1j}$ and $h_{2j}$, giving us
    \begin{eqnarray}
        [h_{12},h_{1j}+h_{2j}] &=& 
        [h_{1j}+h_{2j}-2(h_{1j}h_{2j}+h_{2j}h_{1j}),h_{1j}+h_{2j}]\\
        &=& [h_{1j},h_{2j}]+[h_{2j},h_{1j}]-2[h_{1j}h_{2j},h_{1j}+h_{2j}]-2[h_{2j}h_{1j},h_{1j}+h_{2j}]\\
        &=& -2~\bigl\{
        h_{1j}h_{2j}h_{1j}-h_{1j}^2h_{2j}+h_{1j}h_{2j}^2-h_{2j}h_{1j}h_{2j}\nonumber\\
        &&~~~~~~~~~~~~~~~~~~~~
        +h_{2j}h_{1j}^2-h_{1j}h_{2j}h_{1j}+h_{2j}h_{1j}h_{2j}-h_{2j}^2h_{1j}
        \bigr\}=0,\label{eq:totalspinlastline}
    \end{eqnarray}
    where we used \cref{eq:singprojnormalize} for the last line. 
    Taking the sum over $j$ gives us the wanted expression. 
\end{proof}

Note again that the relation being derived here $[h_{12},h_{1j}+h_{2j}]=0$, 
like any other relation for singlet projectors, 
is 1. trivially verifiable by explicitly calculating matrices $H_{ij}$s, 
but 2. also derivable when $h_{ij}$s are regarded as abstract algebraic objects%purely defined by \cref{eq:anticommproj,eq:singprojnormalize,eq:singproj1,eq:singproj2,eq:singprojcomm}
, which was what we have shown here. 
In general, such derivation can become quite complex, since there are cases which require the order of the polynomial to become larger than the degree of the relation itself during the proof. 
%Just like any other relation for the singlet projectors, this relation could be easily verified by calculating all the operators as explicit matrices. 
%The point is that we can also treat $h_{ij}$s not as matrices but abstract algebraic objects purely defined by \cref{eq:anticommproj,eq:singprojnormalize,eq:singproj1,eq:singproj2,eq:singprojcomm}, and still derive these results as we did here.
%The example we provide above as well as \cref{prop:add_const} which we proved in Sec. \ref{subsec:qmcop} were both fairly short. However, in general the derivation may become rather complicated even when the relation seems superficially innocent since there are cases which require the order of the polynomial to become larger than the degree of the relation itself. 
In the above proof, the commutation $[h_{12},h_{1j}+h_{2j}]$ is a degree-2 expression, but the derivation required intermediate steps with a degree-3 polynomial as in Eq. (\ref{eq:totalspinlastline}).
To demonstrate how nontrivial the derivation can become, let us consider the following relation that reduces a degree-3 monomial into a degree-2 polynomial. This is one of the simplest cases with 4 qubits. 

\begin{proposition}\label{prop:line3reduce}
    For any distinct $i,j,k,$ and $l$, 
    \begin{equation}\label{eq:line3reduce}
        h_{ij}h_{jk}h_{kl}=\frac{1}{4}\left(h_{ij}h_{jk}+h_{jk}h_{kl}+h_{ij}h_{kl}+h_{ik}h_{jl}-h_{ij}h_{jl}-h_{ik}h_{kl}-h_{il}h_{jk}\right). 
    \end{equation}
\end{proposition}

\begin{proof}
    Similarly to the previous proof, we start by expanding $h_{jk}$ and $h_{kl}$ using the anticommutation relation \cref{eq:anticommproj}, with $l$ and $j$ as the ``pivot" respectively, obtaining
    \begin{equation}\label{eq:derivation1}
h_{ij}h_{jk}h_{kl}=\frac{1}{2}\left(\frac{1}{2}\left( h_{ij}h_{jk} + h_{ij}h_{kl}\right)-h_{ij}h_{jk}h_{jl} - h_{ij}h_{jl}h_{kl}\right)
    \end{equation}
    after organizing with \cref{eq:singprojnormalize}. 
    Since we can obtain
    \begin{equation}
        h_{jl}h_{jk}h_{ij}=\frac{1}{2}h_{jl}h_{ij}+h_{ij}h_{jl}h_{kl}-\frac{1}{2}(h_{ij}+h_{jl}-h_{il})h_{kl}, 
    \end{equation}
    by expanding $h_{jk}$ with $l$ and applying \cref{eq:anticommproj}, we can substitute the last term of \cref{eq:derivation1} to get 
    \begin{equation}\label{eq:derivation2}
    h_{ij}h_{jk}h_{kl}=\frac{1}{2}\left(\frac{1}{2} h_{ij}h_{jk} -h_{ij}h_{jk}h_{jl} - h_{jl}h_{jk}h_{ij} 
    +\frac{1}{2}\left(h_{jl}h_{ij}-h_{jl}h_{kl}+h_{il}h_{kl}\right)\right),
    \end{equation}
    after cancellation. 
    Thanks to the fact that the remaining degree-3 terms are exactly the same up to ordering, we can evaluate the sum of them by reordering $h_{jl}h_{jk}h_{ij}$ using the anticommutation relation \cref{eq:anticommproj} to make $h_{ij}h_{jk}h_{jl}$. If the reordering is done from right to left, we obtain 
    \begin{equation}\label{eq:treesum}
        h_{ij}h_{jk}h_{jl}+h_{jl}h_{jk}h_{ij}= \frac{1}{2}\left(h_{il}h_{jk}-h_{ij}h_{kl}-h_{jl}h_{ik}\right)
        +\frac{1}{4}\left(h_{ij}+h_{jl}-h_{il}\right). 
    \end{equation}
    Plugging this into \cref{eq:derivation2} gives us 
    \begin{equation}\label{eq:derivation3}
        h_{ij}h_{jk}h_{kl}=\frac{1}{4}\left(h_{ij}\left(h_{jk}-h_{jl}+h_{kl}\right)-h_{jl}h_{kl}+h_{il}h_{kl}+h_{jl}h_{ik}-h_{il}h_{jk}\right),
    \end{equation}
    after cancellation and using \cref{eq:anticommproj} to clean up the degree-1 terms. 
    Finally, we can use the relation 
    \begin{equation}
        (h_{ij}+h_{jk})h_{ik}=(h_{il}+h_{kl})h_{ik}
    \end{equation}
    obtainable by starting from \cref{eq:quarterformula} to have $h_{ik}(h_{ij}+h_{jk})h_{ik}=h_{ik}(h_{il}+h_{kl})h_{ik}$ and then reordering both sides again using \cref{eq:anticommproj}. 
    Applying this to \cref{eq:derivation3} results in \cref{eq:line3reduce}. 
    
\end{proof}

Of course from this proof alone we cannot completely conclude that {\it any} derivation of \cref{prop:line3reduce} must be at least this long.
However, it does show that a carefully designed sequence of formula application is needed to have the right cancellations to occur and finally enable us to use something like \cref{eq:treesum}, a somewhat easy degree-3 term to reduce. 
It is not hard to imagine that the derivation (purely by algebraic manipulations) of higher order relations such as 
$h_{13}h_{24}h_{14}h_{23}+h_{23}h_{14}h_{24}h_{13}=(h_{13}h_{24}+h_{14}h_{23}-h_{12}h_{34})/2$
quickly becomes intractable.


%\begin{proposition}\label{prop:linerelation}
%For any $i,j,k,l$ that are distinct, 
%\begin{equation}
%    h_{ij}h_{jk}h_{kl}=\frac{1}{4}\left(
%    h_{ij}h_{jk}+h_{jk}h_{kl}+h_{ij}h_{kl}-h_{ij}h_{jl}-%h_{ik}h_{kl}+h_{ik}h_{jl}-h_{il}h_{jk}
%    \right).
%\end{equation}
%\end{proposition}
%\begin{proof}
%    As we did in the previous example, we first use the anticommutation %%%   \begin{eqnarray}
%        h_{12}h_{23}h_{34}
%        &=&\frac{1}{2}
%        \bigl\{
%        %h_{12}h_{23}\bigl(h_{23}+h_{24}-2(h_{23}h_{24}+h_{24}h_{23})\bigr)\nonumber\\
 %       &&~~~~~~~~~~~~~~~~~~~~~~~~+h_{12}\bigl(
 %       h_{24}+h_{34}-2(h_{24}h_{34}+h_{34}h_{24})
 %       \bigr)h_{34}
 %       \bigr\}\\
 %       &=&\frac{1}{2}\left\{
 %       \frac{1}{2}\left(h_{12}h_{23}+h_{12}h_{34}\right)-h_{12}h_{23}h_{24}-%h_{12}h_{24}h_{34}
  %      \right\},
  %  \end{eqnarray}
  %  where we used \cref{eq:singprojnormalize} and \cref{eq:quarterformula}. 
  %  We also use 1,2,3,4 as labels WLOG. 
  %  We can simplify     
%\end{proof}



\section{Nonexactness proofs of $NPA_1(\mathcal{Proj})$ with eigenvalue enumeration}
In this section, we provide proofs that $NPA_1(\mathcal{Proj})$ cannot obtain the exact extremal eigenvalue for two different types of graphs. The first is a crown graph \cref{fig:SmallGraphs} with a specific weight, and the second is uniform complete graphs with odd number of vertices. 
For both proofs, the essence is that we can explicitly construct a PSD $NPA_1(\mathcal{Proj})$ moment matrix that has an exceedingly large cost function value compared to the true extremal eigenvalue. The most nontrivial part is always showing that the matrix PSD, which here we show by enumerating all eigenvalues explicitly. 
While for the odd complete graph case, we can show PSDness by constructing all the Gram vectors of the moment matrix analytically (which we do in \cref{subsec:complete}), that becomes too complicated for the crown graph case. Thus we provide proofs for both cases with eigenvalue enumeration for both cases here for completeness. 

\subsection{Nonexactness of $NPA_1(\mathcal{Proj})$ for certain weighted crown graphs}\label{app:crown}

Here, we prove that $NPA_1(\mathcal{Proj})$ fails to obtain the exact extremal eigenvalue for the crown graph 
\begin{equation}
    H=x h_{ab} + \sum_{j=1}^n \left( h_{aj}+h_{bj}\right) ,
\end{equation}
with certain range of the weight $x$ for the ``center edge" $h_{ab}$. Note that the $n+2$ vertices in total are labeled as $a, b, 1, 2, 3, \ldots, n$ and we assume $n\geq 3$. 
The true extremal eigenvalue of this Hamiltonian is 
\begin{equation}\label{eq:crownenergy}
    E_{\mathrm{GS}}=
    \begin{cases}
        n+1, & x\leq 1+\frac{n}{2},\\
        x+\frac{n}{2}, & x\geq 1+\frac{n}{2}.
    \end{cases},
\end{equation}
with two types of ground states for each $x$ range, depicted in Fig. \ref{fig:SmallGraphs} (b). 
As we proved in Sec. \ref{subsubsec:crown}, $\SoS$ obtains the exact ground state for ranges $x\leq (n+2)^2/4(n+1)$ and $x\geq n$. What we prove here is that $\SoS$ fails for the region $(n+2)/3<x<n$, i.e., that it gives a strictly larger value than the true extremal eigenvalue. We do this by explicitly constructing a moment matrix $M_1^{\mathbb{R}}$ that is a feasible solution for $NPA_1^\mathbb{R}(\mathcal{Proj})$ achieving the value $(3n^2 + 3(n-2)x)/4(n-1)$, which is strictly larger than the true value \cref{eq:crownenergy} in the aforementioned region. 
Note that the region we prove inexactness here matches the boundary where $\SoS$ fails/succeeds at $x=n$, but not for the $x=(n+2)^2/4(n+1)$ boundary. The intermediate region $(n+2)^2/4(n+1)<x<(n+2)/3$ is left as an open problem, although numerics strongly suggest that SDP indeed fails in that region. 


\begin{proof}
Consider the following symmetric moment matrix $M$ which has columns and rows labeled by the identity $\mathbb{I}$ and $h_{ai}, h_{bi}, h_{ab}, h_{ij}$ for $i, j\in [n]$ and $i<j$. 
%in the order of $\mathbb{I}, h_{ab}, h_{a1}, h_{a2}, \ldots, h_{an}, h_{b1}, \ldots, h_{bn}, h_{12}, h_{13}, \ldots, h_{n-1~n}$, with the following elements: 
We set the matrix elements as 
\begin{eqnarray}\label{eq:oddcompmm}
    M(\mathbb{I},h_{ab})&=&M(h_{ab},h_{ab})=\frac{3(n-2)}{4(n-1)},\\
    M(\mathbb{I},h_{ai})&=&M(h_{ai},h_{ai})=M(\mathbb{I},h_{bi})=M(h_{bi},h_{bi})=\frac{3n}{8(n-1)},\\
    M(h_{ai},h_{aj})&=&\frac{3n}{16(n-1)},\\
    M(h_{ai},h_{bi})&=&\frac{3}{8(n-1)},\\
    M(h_{ai},h_{bj})&=&\frac{3(n+2)}{16(n-1)},\\
    M(h_{ai},h_{ab})&=&M(h_{bi},h_{ab})=\frac{3(n-2)}{16(n-1)}\\
    M(\hat O,h_{ij})&=&0,
\end{eqnarray}
where $\hat O$ is any operator, i.e., the rows and columns for $h_{ij}$ are all 0. 
By construction, $M$ satisfies the requirements \cref{eq:singprojnormalize,eq:singprojcomm,eq:anticommproj,eq:singproj1,eq:singproj2}. 
The only nontrivial constraint that needs to be checked is $M\succeq 0$, which we show by listing all the eigenvalues and associated eigenvectors of $M$: 
\begin{enumerate}
    \item[(i)] $n(n-1)/2$ eigenvectors with eigenvalue ``trivially" 0.
    \item[(ii)] $(n-1)$-degenerate eigenvalues of $3n/8(n-1) >0$. 
    \item[(iii)] $(n+1)$-degenerate eigenvectors with eigenvalue nontrivially 0. 
    \item[(iv)] Two eigenvectors of the form $(\alpha,\beta,1,\ldots,1,0,\ldots,0)$ with positive eigenvalues. 
\end{enumerate}
Since these $n(n-1)/2+(n-1)+(n+1)+2=1+{n+2 \choose 2}$ eigenvalues exhaust all of the eigenvalues of $M$ (size $1+{n+2 \choose 2}$), confirming the above list concludes the proof. 
In the following we confirm the eigenvectors belonging to the eigenvalues $(\mathrm{i})$ - $(\mathrm{iv})$ above. The vector elements are labeled by the operators in the same way as the moment matrix. We use subscripts and superscripts for labeling the eigenvectors and use brackets for specifying the element. 


(i) The eigenvectors of the form 
\begin{equation}
    V^{\mathrm{(i)}}_{ij}(\hat O) = 
    \begin{cases}
    1,  & \hat{O}=h_{ij},\\
    0,  & \mathrm{otherwise},
    \end{cases}
\end{equation}
for all $i,j\in [n], i<j$. Such vectors have eigenvalue trivially 0 and all $n(n-1)/2$ of them are linearly independent. 

(ii) The eigenvectors of the form 
\begin{equation}
    V^{\mathrm{(ii)}}_{ij}(\hat O) = 
    \begin{cases}
    +1,  & \hat{O}=h_{ai} \mathrm{~or~} \hat{O}=h_{bj},\\
    -1,  & \hat{O}=h_{bi} \mathrm{~or~} \hat{O}=h_{aj},\\
    0,  & \mathrm{otherwise}. 
    \end{cases}
\end{equation}
It is straightforward to confirm that these vectors indeed have eigenvalue $3n/8(n-1)$, and there are $n-1$ linearly independent such vectors. One example of such a linearly independent set would be $\{ V^{\mathrm{(ii)}}_{12},V^{\mathrm{(ii)}}_{13},\ldots,V^{\mathrm{(ii)}}_{1n} \}$. Specifically, $V^{\mathrm{(ii)}}_{jk}$ is a linear combination of $V^{\mathrm{(ii)}}_{ij}$ and $V^{\mathrm{(ii)}}_{ik}$.

(iii) The eigenvectors of the form 
\begin{equation}
    V^{\mathrm{(iii)}}_{j}(\hat O) = 
    \begin{cases}
    +1,  & \hat{O}=h_{aj} \mathrm{~or~} \hat{O}=h_{bj} \mathrm{~or~} \hat{O}=h_{ab},\\
    -3/2, & \hat{O}=\mathbb{I},\\
    0,  & \mathrm{otherwise},
    \end{cases}
\end{equation}
for $j=1,2,\ldots,n$ and one other:
\begin{equation}
    V^{\mathrm{(iii)}}_{a}(\hat O) = 
    \begin{cases}
    +1,  & \hat{O}=h_{ai},\\
    -3n/4, & \hat{O}=\mathbb{I},\\
    n/2, & \hat{O}=h_{ab},\\
    0,  & \mathrm{otherwise}.
    \end{cases}
\end{equation}
It is again straightforward to confirm that these vectors indeed have eigenvalue 0, and there are $n+1$ linearly independent such vectors, namely $n$ of the form $V^{\mathrm{(iii)}}_{j}$ and a single $V^{\mathrm{(iii)}}_{a}$. 


(iv) The eigenvectors of the form 
\begin{equation}
    V^{\mathrm{(iv)}}_{\pm}(\hat O) = 
    \begin{cases}
    \alpha_{\pm}, & \hat{O}=\mathbb{I},\\
    \beta_{\pm}, & \hat{O}=h_{ab},\\
    1,  & \mathrm{otherwise}.
    \end{cases}
\end{equation}
The equation for this vector to be an eigenvector yields the following two solutions: 
\begin{eqnarray}
    \alpha_{\pm} &=& \frac{6n^2-34n+64\pm 2\sqrt{9n^4+24n^3+121n^2-368n+592}}{3(6-7n)}\\    
    \beta_{\pm} &=& \frac{3n^2-3n+20\pm\sqrt{9n^4+24n^3+121n^2-368n+592}}{6-7n}
\end{eqnarray}
where the $\pm$ sign in $\alpha$ and $\beta$ must be set the same. This gives two solutions $V^{\mathrm{(iv)}}_{+}$ and $V^{\mathrm{(iv)}}_{-}$, where the eigenvalues are
\begin{equation}\label{eq:crowneigen}
    \lambda_{\pm}=\frac{20-17n-3n^2\pm\sqrt{9n^4+24n^3+121n^2-368n+592}}{16(1-n)},
\end{equation}
again corresponding to the two solutions $V^{\mathrm{(iv)}}_{\pm}$. These two eigenvalues are always positive when $n\geq3$, which concludes the proof. 

\end{proof}






\subsection{List of all eigenvectors of odd complete graphs}\label{app:compeigen}

Here, we list up all the eigenvectors and eigenvalues of the $NPA_1(\mathcal{Proj})$ moment matrix constructed in Sec. \ref{subsec:complete} for the odd complete graphs. 
This would provide an alternative proof for the inexactness of $NPA_1(\mathcal{Proj})$ for odd complete graphs, with the same approach as Appendix \ref{app:crown}, but more importantly follows how the analgous {\it classical} case was proved more generally \cite{gri01lin,lau03low,kun22spec}. 
Using the same notation as in Sec. \ref{subsec:complete}, the eigenvalues are: 
\begin{enumerate}
    \item[(i)] $(n-1)$-degenerate eigenvalues of $an/4 - (n-3)b = 0$.
    \item[(ii)] $n(n-3)/2$-degenerate eigenvalues of $a/2 - b >0$. 
    \item[(iii)] Two eigenvectors of the form $(x,1,1,\ldots,1)$ with eigenvalues $0$ ($x<0$) and positive ($x>0$),  
\end{enumerate}
which adds up to $n-1+n(n-3)/2+2=1 + {n \choose 2}$ in total, matching the size of $M$. The explicit forms of each eigenvectors and their degeneracy (dimension of eigenspace) are shown in the following. 

(i) The eigenvectors of the form 
\begin{equation}
    V^{(\mathrm{i})}_{\alpha\beta}(\hat O) = 
    \begin{cases}
    0,  & \hat{O}=\mathbb{I} \mathrm{~or~} h_{\alpha\beta}\mathrm{~or~} h_{ij} \mathrm{~with~}(ij)\mathrm{~not~including~}\alpha\mathrm{~nor~}\beta,\\
    +1, & \hat{O}=h_{ij}, ~i=\alpha \mathrm{~or~} j=\alpha,\\
    -1, & \hat{O}=h_{ij}, ~i=\beta \mathrm{~or~} j=\beta,\\
    \end{cases}
\end{equation}
where $\alpha$ and $\beta$ are two distinct vertices chosen beforehand and the vector elements are labeled with the operators corresponding to rows and columns of the moment matrix. 
While there are superficially $n(n-1)$ different possible eigenvectors of the form $V_{\alpha\beta}$, 
many of them are not linearly independent, 
the most obvious ones being $V_{\alpha\beta}=-V_{\beta\alpha}$. 
It turns out that there are exactly $n-1$ of these eigenvectors that are linearly independent. 
Confirming linear independence of the set $\{ V_{1\beta}\}_{\beta=2,3,\ldots,n}$ is straightforward, as well as confirming that these are indeed eigenvectors and have eigenvalue 0. 

(ii) The eigenvectors of the form 
\begin{equation}
    V^{(\mathrm{ii})}_{C}(\hat O) = 
    \begin{cases}
    0,  & \hat{O}=\mathbb{I}\mathrm{~or~} h_{ij} \mathrm{~with~}(ij)\mathrm{~not~included~in~cycle~}C,\\
    +1, & \hat{O}=h_{ij}, ~(ij) \mathrm{~is~an~even~edge~in~cycle~} C,\\
    -1, & \hat{O}=h_{ij}, ~(ij) \mathrm{~is~an~odd~edge~in~cycle~} C,\\
    \end{cases}
\end{equation}
where $C$ is a simple cycle of any even length, with alternating signs associated to each edge it passes.  
Again, although there are many distinct cycles $C$, 
there are only $n(n-3)/2$ linearly independent $V_{C}$'s. 
Confirming the linear independence of the set $\{V_{C}\}_{C\in \mathcal{C}}$ is also easy when we set 
\begin{equation}
    \mathcal{C} = \bigl\{ (i,i+1,i+2,\ldots,i+k,i) ~|~ i=1,2,\ldots n ; ~k=4,6,\ldots ,n-1\bigr\}, 
\end{equation}
(notice that each even ``chord" of the complete graph $(i+k,i)$ appears exactly once)
as well as confirming that these are indeed eigenvectors that have eigenvalues $a/2-b$. 

(iii) Finally, it is straight forward to see that 
\begin{equation}
    V^{(\mathrm{iii})}_{x}(\hat O) = 
    \begin{cases}
    x,  & \hat{O}=\mathbb{I},\\
    1, & \hat{O}=h_{ij},\\
    \end{cases}
\end{equation}
is an eigenvector when either 
\begin{equation}
\begin{cases}
    x= -a {n \choose 2} &, \mathrm{~Eigenvalue~} 0,\\
    x= a^{-1} &, \mathrm{~Eigenvalue~} 1+\frac{n(n-2)^2}{32(n-1)}>0.\\
\end{cases}
\end{equation}





\section{Description of $NPA_1(\mathcal{Proj})$ for the hexagon}\label{app:hexagon}
Numerically, we observe clear evidence that both $NPA_1(\mathcal{Proj})$ and $NPA_2(\mathcal{Pauli})$ obtain the exact ground state for the cycle graph with $n=6$ qubits. 
While unfortunately we have not been able to obtain an analytic $\SoS$ that verifies the numerically observed solvability, we here present the structure of the Gram vectors corresponding to the optimal (exact) moment matrix. 

% Figure environment removed

The Gram vectors corresponding to all $1+{6 \choose 2}=16$ rows/columns of the moment matrix forms a 5-dimensional relation, which is shown in Fig. \ref{fig:5dHex}. 
When we break it down, the Gram vectors for $h_{i,i+1}, h_{i,i+2}, \text{ and } h_{i,i+3}$ form 3, 2, and 2-dimensional relation respectively as shown on the left side of the figure.
Note that the Gram vectors for $h_{i,i+2}$ and $h_{i+3,i+4}$ are exactly the same. 
All three kinds of Gram vectors combine to form a 5-dimensional relation, but we only show the three-dimensional subspace in the figure (right) for visualization. 

The actual values in the coordinates of the Gram vectors are 
\begin{eqnarray}
    \alpha = \frac{5+\sqrt{13}}{12}\approx0.717  &
    \beta = \frac{1}{4}(1-3\phi)\approx 0.042 &
    \gamma = \frac{2}{3} (1-2\phi)\approx 0.482  \nonumber \\
    a_1 = \frac{1}{6}\sqrt{\frac{1}{2}(5+\phi)}\approx0.271 &
    b_1 = \sqrt{\frac{1}{8}(1-3\phi)}\approx 0.145  &
    c_1 = \frac{1}{3}\sqrt{1+2\phi}\approx 0.416 \\
    a_2 = \sqrt{\frac{1}{12}(1+2\phi)}\approx0.360 &
    b_2 = \phi/2\approx 0.139  &
    c_2 = \phi \approx 0.278, \nonumber
\end{eqnarray}
where $\phi=1/\sqrt{13}$. 

The basis we chose here is the most simplest, which intuitively could be understood in the following way. We choose the Gram vector for the ground state (identity in the moment matrix) to be $(1,0,0,0,0)$ without loss of generality and for simplicity. 
Then the first coordinate for all of the remaining Gram vectors ($\alpha, \beta$ and $\gamma$) simply correspond to the the expectation value of each kind of projectors. The next three coordinates correspond to the nontrivial prism-shape the $\{h_{i,i+1}\}$s form, and the other Gram vectors happen to follow the same triangular pattern, but without the height dimension. 
The last coordinate $b_2$ and $c_2$ could be seen as an additional constant term in order to ensure the normalization $h_{ij}^2=h_{ij}$, i.e., each vector must square to become $\alpha, \beta$, and $\gamma$. 

Interestingly, the hexagon Hamiltonian admits a decomposition that was used heavily in this study: 
\begin{equation}
    H=\left(\frac{1}{2}h_{12}+h_{23}+h_{34}+\frac{1}{2}h_{45}\right)+
    \left(\frac{1}{2}h_{45}+h_{56}+h_{61}+\frac{1}{2}h_{12}\right),
\end{equation}and
\begin{equation}
    \lVert H\rVert=\Big\lVert\frac{1}{2}h_{12}+h_{23}+h_{34}+\frac{1}{2}h_{45}\Big\rVert+
    \Big\lVert\frac{1}{2}h_{45}+h_{56}+h_{61}+\frac{1}{2}h_{12}\Big\rVert 
\end{equation}
simultaneously, {\it however}, $NPA_1(\mathcal{Proj})$ fails for the decomposed sub-hamiltonians, which is only observed for this particular case. 
It is quite likely that the $\SoS$ for the hexagon becomes severely more complicated than any other $\SoS$ we provided in this work. 



\end{appendices}