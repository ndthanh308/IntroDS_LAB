
\section{Results}
% Please add the following required packages to your document preamble:
% \usepackage{booktabs}
\label{sect:4_results}
OSD and VAD results obtained on 5 single (DIHARD, ALLIES, AMI) and multi-channels (AMI$^\star$, CHIME-5$^\star$) datasets are presented in Table~\ref{tab:overview}.

%\vspace{-5pt}
\subsection{Single Channel}

%The results obtained on single channel are presented in the table~\ref{tab:overview}. 
%As we have multiple corpora and not any single baseline system to compare, we use different state-of-the-art results as point of comparison. 
%OSD results obtained on DIHARD (66.2~\%) with the 2-class approach overtakes the current state of the art (63.4\% in~\cite{lebourdais22_interspeech}). 
%Improvements from this work is due to another optimization in the training process. %is probably due to the use of another optimizer. 
%For the DIHARD corpus, we take the results obtained in a previous study~\cite{lebourdais22_interspeech},with a F1-score of 63.4\% as a baseline. 
%On this baseline we improve the results by 2.8 points for the mono task and 3.2 points for the joint training. 
So far, ALLIES corpus has only been studied for speaker diarization while discarding overlapping speech obtained in the manual reference~\cite{larcher:hal-03262914}. 
We provide the first evaluation of OSD for ALLIES data with a 71.6\% F1-score using the 2-class approach.
%VAD results are generally not published, thus making a comparison with the litterature impossible. However, 
%Table~\ref{tab:overview} shows that the 2-class approach reach a F1-score over 96.4\% (AMI$^\star$) whatever the dataset. 

%.
%The results on VAD are not usually published recently, to compare with older systems would be unfair. 
%However, we can compare the results between our two systems.
VAD performances are similar between the 2- and 3-class approaches except for the ALLIES data for which a strong F1-score degradation of 10.6\% is noticeable. 
%We can notice a strong degradation of 10.6\% for VAD on ALLIES, while on the other corpora, the performances are similar between 2- and 3-class approaches.
The 3-class approach improves OSD results in all single-channel datasets, particularly on ALLIES (+5.3\%).
Results on ALLIES should be treated cautiously as the average proportion of overlap is rather low, and we identified some issues in the manual segmentation.
In summary, except for ALLIES, the joint VAD+OSD system offers better performance than the two dedicated systems.
It even outperforms the previous state-of-the-art results on DIHARD and AMI data with a new F1-score at 66.8\% and 80.4\% respectively.

%The best results in OSD are obtain for DIHARD, ALLIES and AMI by the VAD+OSD system with 66.8~\% F1-score for DIHARD, 75.4~\% F1-score for ALLIES and 80.4~\% F1-score for AMI.
%The absolute improvement isn't always great, only 0.6~\% for DIHARD but is supporting a non regression of the results in joint-training. 
%For the corpora less suited for overlap detection, like ALLIES, the improvement is higher with 3.8~\% absolute improvement.
%The results on VAD are less consistent, the VAD+OSD performing better on AMI multi-channel but worst in other corpora, it even degrade heavily on ALLIES with a absolute loss of 10.6~\%.



\subsection{Domain adaptation}

\vspace{-5pt}
\begin{table}[htbp]
\centering
\caption{VAD and OSD F1-score~(\%) obtained on the ALLIES evaluation set. The model trained on DIHARD is fine-tuned on the subset ALLIES-clean.}
\begin{tabular}{@{}lccc@{}}
\toprule
Model                        & Task & DIHARD         & ALLIES        \\\midrule
\textit{Fine-tuning}                 &      & \textit{ALLIES-clean}       & \textit{No} \\                            
\midrule
\multirow{2}{*}{2-class }   & VAD  & 99.7           & \textbf{99.8} \\
                            & OSD  & 75.3           & 71.6          \\
                             \midrule
\multirow{2}{*}{3-class}    & VAD  & \textbf{99.8}  & 89.2          \\
                            & OSD  & 75.0           & \textbf{75.4} \\
                              \bottomrule
\end{tabular}

\label{tab:adapt}

\end{table}
The presence of errors in the reference segmentation of ALLIES introduces some noise during the training stage, and thus, degrades the performance of the 3-class approach especially regarding VAD.
To cope with this issue, we propose to use the model trained on DIHARD and fine-tune it with the clean subset ALLIES-clean.
Table~\ref{tab:adapt} shows that fine-tuning on ALLIES-clean brings a similar OSD performance (75.0\%) as a model trained with ALLIES data only (75.4\%). 
More interestingly, fine-tuning significantly improves the VAD performance with a relative +11.9\% gain on the F1-score, with only 6~h of in-domain speech.
This gain can be explained by the diversity and quality of the annotations in DIHARD.
We conclude that it is better to train the model on clean and diverse data and apply fine-tuning on in-domain data.




% Domain : Dihard (splitted by domain ?) AMI, ALLIES\\
% SOTA~\cite{bredin:hal-03257524}\\
% \begin{itemize}
%     \item Allies With adaptation and without adaptation
%     \item Adaptation don't degrade the results with far less data
%     \item Diversity $>$ Quantity
%     \item 
% \end{itemize}

%\vspace{-5pt}
\subsection{Multiple channels}

%Experiments on multi-microphone data are conducted on the AMI meeting corpus \cite{Mccowan05theami_short} and the CHiME-5 dataset \cite{watanabe2020chime_short}.
%VAD and OSD performance for each system are presented in table \ref{tab:overview}.
On the AMI meeting corpus, we notice lower performances on multi-channel data AMI$^\star$ in comparison to the close-talk recordings of AMI. 
Two factors can explain this degradation.
First, multi-channel signals are recorded under distant speech conditions.
This leads to lower quality recordings and thus performance degradation \cite{mariotte22_interspeech}.
Moreover, unlike single channels, the multi-channel feature extraction algorithm does not rely on pre-trained features.
Therefore, the SACC features are less optimized compared to WavLM features.
On AMI$^\star$, the joint VAD+OSD system offers similar VAD performance as the 2-class approach.
The same behavior is observed on the OSD task where the 3-class system degrades with a 0.5\% relative F1-score degradation. 
A single 3-class VAD+OSD system thus offers similar performance as two dedicated VAD and OSD systems on multi-channel audio from AMI$^{\star}$.
VAD and OSD performance are also evaluated on audio data recorded during dinner parties with the CHiME-5 dataset.
Again, the 3-class VAD+OSD system offers similar VAD and OSD performance as two dedicated VAD and OSD systems with about 0.5\% relative F1-score degradation on each task.
Results on these two multi-microphone datasets show that joint VAD+OSD is also adapted to the distant speech scenario with SACC features.




