\documentclass{INTERSPEECH2023}
%\documentclass[a4paper,12pt,]{article}

% 2023-01-06 modified by Simon King (Simon.King@ed.ac.uk)  

% **************************************
% *    DOUBLE-BLIND REVIEW SETTINGS    *
% **************************************
% Comment out \interspeechcameraready when submitting the 
% paper for review.
% If your paper is accepted, uncomment this to produce the
%  'camera ready' version to submit for publication.

\interspeechcameraready 


% **************************************
% *                                    *
% *      STOP !   DO NOT DELETE !      *
% *          READ THIS FIRST           *
% *                                    *
% * This template also includes        *
% * important INSTRUCTIONS that you    *
% * must follow when preparing your    *
% * paper. Read it BEFORE replacing    *
% * the content with your own work.    *
% **************************************

\usepackage{amsmath,graphicx}

% Example definitions.
% --------------------
\def\x{{\mathbf x}}
\def\L{{\cal L}}

% Title.
% ------
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{subcaption}
\usepackage[belowskip=0pt,aboveskip=0pt]{caption}
%\title{Diarisation subtasks are still tasks}
%\title{Joint speech and overlap detection: a comparative study on multiple datasets across speech domains}
\title{Joint speech and overlap detection: a benchmark over multiple audio setup and speech domains}
\name{Martin Lebourdais$^{1\star}$, Théo Mariotte$^{1,2\star}$,  Marie Tahon$^{1}$, Anthony Larcher$^{1}$, \\
\textit{Antoine Laurent$^{1}$, Silvio Montrésor$^{2}$,  Sylvain Meignier$^{1}$, Jean-Hugh Thomas$^{2}$}
\thanks{$^{\star}$ Both authors contributed equally.}
}
%The maximum number of authors in the author list is 20. If the number of contributing authors is more than this, they should be listed in a footnote or the acknowledgement section.
\address{$^{1}$LIUM, $^{2}$LAUM UMR 6613 IA-GS, Le Mans Université 
}
\email{\{first name\}.\{last name\}@univ-lemans.fr}


\begin{document}


\maketitle
 
\begin{abstract}
% 1000 characters. ASCII characters only. No citations.
Voice activity and overlapped speech detection (respectively VAD and OSD) are key pre-processing tasks for speaker diarization.
The final segmentation performance highly relies on the robustness of these sub-tasks.
Recent studies have shown VAD and OSD can be trained jointly using a multi-class classification model.
However, these works are often restricted to a specific speech domain, lacking information about the generalization capacities of the systems.
This paper proposes a complete and new benchmark of different VAD and OSD models, on multiple audio setups (single/multi-channel) and speech domains (e.g. media, meeting...). 
Our 2/3-class systems, which combine a Temporal Convolutional Network with speech representations adapted to the setup, outperform state-of-the-art results.
%(66.8\% F&-score on DiHard)
We show that the joint training of these two tasks offers similar performances in terms of F1-score to two dedicated VAD and OSD systems while reducing the training cost. This unique architecture can also be used for single and multi-channel speech processing.
\end{abstract}

\input{01_intro.tex}
\input{02_datasets.tex}
\input{03_system.tex}
\input{04_results.tex}
\vspace{-5pt}
\input{05_analysis.tex}
\input{06_Conclusion.tex}

\section{Acknowledgments}

This work was performed using HPC resources from GENCI–IDRIS (Grant 2022-AD011012565), the French ANR GEM (ANR-19-CE38-0012), and LMAC grant from Région Pays de la Loire.


\bibliographystyle{IEEEtran}
\bibliography{bib}

\end{document}
