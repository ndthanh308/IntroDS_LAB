\section{Datasets}
\label{sect:2_datasets}
Our benchmark datasets combine multiple speech domains including far-field audio recordings.
For each dataset, VAD and OSD labels are derived from the provided ground-truth segmentation. 
%The comparative study is conducted over several datasets covering multiple speech domains
%Experiments are conducted on several corpora covering multiple speech domains.
Table~\ref{tab:corpus_desc} summarizes corpus characteristics.
%Datasets are detailed in the following sections.

%Our system is evaluated on several datasets covering different domains.
\begin{table}[ht!]
\centering
\caption{Corpus characteristics. $^\star$multi-microphone data.}
\begin{tabular}{@{}lccc@{}}
\toprule
Corpus   & Domain & Duration & Overlap prop. \\ \midrule
DIHARD   & Multiple    & 34~h      & 11.6\%             \\
ALLIES   & Media    & 328~h     & 3.2\%              \\
ALLIES-clean & Media & 6~h      & 13.9\%             \\
AMI$^\star$      & Meeting   & 100~h     & 24.7\%                   \\
CHiME-5$^\star$  & Dinner party   & 60~h      & 22.9\%            \\ \bottomrule
\end{tabular}

\label{tab:corpus_desc}
\end{table}

%Each corpus is presented in the following sections.
\vspace{-15pt}

\subsection{Single Channel}
%
Single channel experiments are conducted on 3 datasets: ALLIES~\cite{larcher:hal-03262914}, DIHARD~\cite{ryant19_interspeech} and AMI~\cite{Mccowan05theami_short}.
The ALLIES corpus is a soon-to-be-available French meta-corpus designed to gather and extend previous French data collected for diarization and transcription evaluation campaigns.
It consists of 328~h of audio extracted from 1998 to 2014 in 1008 shows with 5901 different speakers. 
The overlap proportion (in duration) fluctuates widely between broadcast news with little to no interaction and debates (around 10\% of overlaps). 
Despite a harmonization effort, the data collected and annotated under different protocols introduces some homogeneity problems~\cite{lebourdais:hal-03660323}. 
15 debate shows, referred to as ALLIES-clean, 
%for which a manual segmentation of speaker activity including overlapping speech is provided, 
were selected in order to get a high overlap proportion, a manual and homogeneous speech segmentation, and diversity in the shows represented. 

%The DIHARD corpus was provided for the eponymous challenge in 2020. 
The DIHARD corpus contains data from 7 domains with various recording qualities, situations, and degrees of spontaneity from read speech to phone conversations.
Since spontaneous speech naturally contains a high proportion of overlapped speech, this corpus is well-suited for OSD. 
This corpus is partitioned as intended for the challenge and evaluated on the official evaluation partition.

The AMI meeting corpus contains recordings of realistic meetings involving up to 5 participants in various environments.
The \textit{headset-mix} is used for single-channel experiments on this dataset. 
The data partition follows the protocol proposed in \cite{landini_but_2020}.

\subsection{Multiple Channels}
%
Multiple-channel experiments are conducted on 2 corpora: AMI~\cite{Mccowan05theami_short} and CHiME-5~\cite{barker2018fifth}.
We select AMI audio data captured by the \textit{Array 1} as a distant multi-microphone signal.
It consists of a uniform circular array (UCA) composed of 8 omnidirectional microphones placed in the center of the table during meetings.

The CHiME-5 dataset contains 20 dinner-party sessions involving 4 participants in a real-home environment. 
Speakers were asked to move between 3 rooms during the party.
Audio signals thus feature a strong background noise diversity with varying acoustic conditions.
Audio signals are captured with 6 linear arrays composed of 4 microphones.
For our experiments, only the first microphone of each array is selected.
Finally, the resulting signal contains 6~channels.

% \subsection{ALLIES}
% The ALLIES corpus~\cite{larcher:hal-03262914_short} is a French metacorpus designed to gather and extend previous French data collected for diarization and transcription evaluation campaigns.
% %
% %from television and radio shows. 
% %It gathers data from diarization evaluation campaigns (Ester1\&2~\cite{galliano-etal-2006-corpus} and Repere\cite{giraudel_repere_2012_short}) and new data gathered for this corpus. 
% It consists of 307h of audio extracted from 1998 to 2014 in more than 1000 TV and radio shows with 5711 different speakers. 
% The overlap proportion (in duration) fluctuates widely between broadcast news in which there is mainly single speakers, and debates which contain around 10\% of overlaps in duration. Despite a harmonization effort, data collected and annotated under different protocols introduces homogeneity problems~\cite{lebourdais:hal-03660323}. 
% 15 debate shows, referred as ALLIES-clean, for which a manual segmentation of speaker activity including overlapping speech is provided, were selected in order to get a high overlap proportion,an homogeneous speech segmentation and the diversity in the shows represented.
% %We manually extract a sub-corpus designated as ALLIES-clean, composed of 15 shows selected to contain overlapping speech and to be representative of the corpus content.

% \subsection{AMI}

% The AMI meeting corpus \cite{Mccowan05theami_short} consists of 100~h of realistic meeting recordings involving up to 5 participants.
% This dataset features close-talk speech signals recorded using individual microphones (e.g. headset, lapel) and distant speech signals collected using microphone arrays.
% In this study, we will only consider the \textit{headset-mix} as close-talk signals and the \textit{array 1} recordings as multi-channel data (referred to as AMI$^\star$).
% The microphone array consists of a uniform circular array (UCA) composed of eight omnidirectional microphones placed in the center of the table during meetings.
% A manual annotation of the speaker activity is provided. VAD and OSD labels are then extracted from this ground truth segmentation.

% \subsection{CHiME-5}
% The CHiME-5 dataset \cite{watanabe2020chime_short} is over 60~h of dinner party recordings divided into 20 sessions.
% Each session involves 4 participants in a real-home environment. 
% Speakers were asked to move between 3 rooms during the party.
% Audio signals are captured with 6 linear arrays composed of 4 microphones.
% For our experiments, we only select the first channel of each microphone array.
% The resulting signal is thus composed of 6 channels.
% This corpus then features realistic recordings with a strong background noise diversity.
% Ground-truth segmentation obtained via manual annotation and forced-alignment is provided.
% VAD and OSD labels are extracted from those.


% \subsection{DIHARD}
% The DIHARD corpus~\cite{ryant19_interspeech} was provided for the eponymous challenge in 2020. 
% It contains data from 7 domains with various recording qualities, situations and degrees of spontaneity from read speech to phone conversations.
% Since spontaneous speech naturally contains a high proportion of overlapped speech, this corpus is well-suited for OSD. 
% This corpus is partitioned as intended for the challenge and evaluated on the official evaluation partition.
% The labels for OSD and VAD are extracted from the ground-truth speaker segmentation provided in the evaluation campaign.
