\vspace{-0.5cm}
\section{Conclusion}
\label{sect:6_ccl}
This article presents a benchmark on two speech segmentation tasks -- Voice Activity Detection and Overlapped Speech Detection -- over multi/mono channel and various domains in 5 datasets.
Two approaches are compared by solving jointly or independently VAD and OSD.
%Experiments have shown that the joint training of VAD+OSD offers similar performance as two dedicated systems.
%This behavior has been observed on both single-channel audio data and distant multi-microphone signals.
%proposition:
The VAD+OSD joint training offers similar performance as the traditional 2-class OSD or VAD approaches on both single-channel audio data and distant multi-microphone signals.
The proposed system reaches a new state-of-the-art for OSD on DIHARD (66.8\%) and AMI (80.4\%) data.
Particularly in the case of ALLIES data with domain adaptation, joint training brings an improvement of +11.8\% for VAD and +5.3\% for OSD.
Furthermore, joint training requires fewer resources as it reduces the training time on most of the datasets, especially in the case of multi-channel data.

%autre proposition (mais Ã§a ne rentre plus :( )
A deeper analysis demonstrates that background noise and face-to-face conversations are clearly hard to segment. We also visualize how the combination weights obtained with the SACC multi-channel feature extractor are prone to locate active speakers within a session.

%proposition by MT
Since VAD and OSD performances on multi-microphone data highly depend on the number of microphones during training, we intend to evaluate our system in a cross-domain scenario with different types of adaptation to go towards a robust multi-corpus segmentation model.
The impact of the proposed VAD+OSD system on diarization will also be evaluated.












%In further experiments, we intend to evaluate our system in a cross domain scenario with different types of adaptation to go towards a robust multi-corpus segmentation model.
%Furthermore, VAD and OSD performances on multi-microphone data highly depends on the number of microphones during training.
%Future work will focus on generalizing training to various microphone array set-up.


% This article presents a comparative study between two approaches for Voice Activity Detection (VAD) and Overlapped Speech Detection (OSD).
% The results shows that jointly training VAD and OSD offers similar performances as two dedicated systems, whatever the speech domain.
% This trend has been observed on both single channel and multiple channels audio data, with different types of feature extractors.
% Per-domain performance analysis has also shown that a joint system may perform better on some domains (e.g. phone calls) compared to others (e.g. face-to-face).
% Moreover, the use of multiple-class training requires less resources since the training time is reduced.

%In this article, we presented a benchmark on two segmentation tasks, for 5 corpora and 2 models per task. The results obtained overtake the current state of the art for both of the method in mono channel and achieve promising results in multi channel.
%We have also shown the interest of adaptation of an existing model to obtain results faster and with less data on new corpora. This conclusion has been made possible by a study of speech domain impact on overlapped speech detection.
