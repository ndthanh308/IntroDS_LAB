\begin{thebibliography}{10}
\providecommand{\url}[1]{\texttt{#1}}
\providecommand{\urlprefix}{URL }
\providecommand{\doi}[1]{https://doi.org/#1}

\bibitem{auer2002finite}
Auer, P., Cesa-Bianchi, N., Fischer, P.: Finite-time analysis of the multiarmed
  bandit problem. Machine learning  \textbf{47},  235--256 (2002)

\bibitem{best2019dec}
Best, G., Cliff, O.M., Patten, T., Mettu, R.R., Fitch, R.: Dec-mcts:
  Decentralized planning for multi-robot active perception. The International
  Journal of Robotics Research  \textbf{38}(2-3),  316--337 (2019)

\bibitem{browne2012survey}
Browne, C.B., Powley, E., Whitehouse, D., Lucas, S.M., Cowling, P.I.,
  Rohlfshagen, P., Tavener, S., Perez, D., Samothrakis, S., Colton, S.: A
  survey of monte carlo tree search methods. IEEE Transactions on Computational
  Intelligence and AI in games  \textbf{4}(1),  1--43 (2012)

\bibitem{dam2022monte}
Dam, T., Chalvatzaki, G., Peters, J., Pajarinen, J.: Monte-carlo robot path
  planning. IEEE Robotics and Automation Letters  \textbf{7}(4),  11213--11220
  (2022)

\bibitem{fawzi2022discovering}
Fawzi, A., Balog, M., Huang, A., Hubert, T., Romera-Paredes, B., Barekatain,
  M., Novikov, A., R~Ruiz, F.J., Schrittwieser, J., Swirszcz, G., et~al.:
  Discovering faster matrix multiplication algorithms with reinforcement
  learning. Nature  \textbf{610}(7930),  47--53 (2022)

\bibitem{ju2020path}
Ju, C., Luo, Q., Yan, X.: Path planning using an improved a-star algorithm. In:
  2020 11th International Conference on Prognostics and System Health
  Management (PHM-2020 Jinan). pp. 23--26. IEEE (2020)

\bibitem{kocsis2006bandit}
Kocsis, L., Szepesv{\'a}ri, C.: Bandit based monte-carlo planning. In: Machine
  Learning: ECML 2006: 17th European Conference on Machine Learning Berlin,
  Germany, September 18-22, 2006 Proceedings 17. pp. 282--293. Springer (2006)

\bibitem{lample2022hypertree}
Lample, G., Lacroix, T., Lachaux, M.A., Rodriguez, A., Hayat, A., Lavril, T.,
  Ebner, G., Martinet, X.: Hypertree proof search for neural theorem proving.
  Advances in Neural Information Processing Systems  \textbf{35},  26337--26349
  (2022)

\bibitem{nawaz2022multi}
Nawaz, F., Ornik, M.: Multi-agent multi-target path planning in markov decision
  processes. arXiv preprint arXiv:2205.15841  (2022)

\bibitem{noh2022adaptive}
Noh, D., Lee, W., Kim, H.R., Cho, I.S., Shim, I.B., Baek, S.: Adaptive coverage
  path planning policy for a cleaning robot with deep reinforcement learning.
  In: 2022 IEEE International Conference on Consumer Electronics (ICCE).
  pp.~1--6. IEEE (2022)

\bibitem{rashid2020monotonic}
Rashid, T., Samvelyan, M., De~Witt, C.S., Farquhar, G., Foerster, J., Whiteson,
  S.: Monotonic value function factorisation for deep multi-agent reinforcement
  learning. The Journal of Machine Learning Research  \textbf{21}(1),
  7234--7284 (2020)

\bibitem{schrittwieser2020mastering}
Schrittwieser, J., Antonoglou, I., Hubert, T., Simonyan, K., Sifre, L.,
  Schmitt, S., Guez, A., Lockhart, E., Hassabis, D., Graepel, T., et~al.:
  Mastering atari, go, chess and shogi by planning with a learned model. Nature
   \textbf{588}(7839),  604--609 (2020)

\bibitem{silver2017mastering}
Silver, D., Schrittwieser, J., Simonyan, K., Antonoglou, I., Huang, A., Guez,
  A., Hubert, T., Baker, L., Lai, M., Bolton, A., et~al.: Mastering the game of
  go without human knowledge. nature  \textbf{550}(7676),  354--359 (2017)

\bibitem{Skrynnik2022a}
Skrynnik, A., Andreychuk, A., Yakovlev, K., Panov, A.: Pathfinding in
  stochastic environments: learning vs planning. PeerJ Computer Science
  \textbf{8},  e1056 (2022). \doi{10.7717/peerj-cs.1056},
  \url{https://peerj.com/articles/cs-1056}

\bibitem{skrynnik2022pogema}
Skrynnik, A., Andreychuk, A., Yakovlev, K., Panov, A.I.: Pogema: partially
  observable grid environment for multiple agents. arXiv preprint
  arXiv:2206.10944  (2022)

\bibitem{skrynnik2021hybrid}
Skrynnik, A., Yakovleva, A., Davydov, V., Yakovlev, K., Panov, A.I.: Hybrid
  policy learning for multi-agent pathfinding. IEEE Access  \textbf{9},
  126034--126047 (2021)

\bibitem{standley2010finding}
Standley, T.: Finding optimal solutions to cooperative pathfinding problems.
  In: Proceedings of the AAAI Conference on Artificial Intelligence. vol.~24,
  pp. 173--178 (2010)

\bibitem{stern2019multi}
Stern, R., Sturtevant, N., Felner, A., Koenig, S., Ma, H., Walker, T., Li, J.,
  Atzmon, D., Cohen, L., Kumar, T., et~al.: Multi-agent pathfinding:
  Definitions, variants, and benchmarks. In: Proceedings of the International
  Symposium on Combinatorial Search. vol.~10, pp. 151--158 (2019)

\bibitem{sutton2018reinforcement}
Sutton, R.S., Barto, A.G.: Reinforcement learning: An introduction. MIT press
  (2018)

\bibitem{yakovlev2023planning}
Yakovlev, K., Andreychuk, A., Skrynnik, A., Panov, A.: Planning and learning in
  multi-agent path finding. In: Doklady Mathematics. pp.~1--6. Springer (2023)

\bibitem{ye2021mastering}
Ye, W., Liu, S., Kurutach, T., Abbeel, P., Gao, Y.: Mastering atari games with
  limited data. Advances in Neural Information Processing Systems  \textbf{34}
  (2021)

\bibitem{zerbel2019multiagent}
Zerbel, N., Yliniemi, L.: Multiagent monte carlo tree search. In: Proceedings
  of the 18th International Conference on Autonomous Agents and MultiAgent
  Systems. pp. 2309--2311 (2019)

\end{thebibliography}
