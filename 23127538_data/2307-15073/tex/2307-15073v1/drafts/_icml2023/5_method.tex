\vspace*{-3pt}
\section{Quantitative Structure-Activity VI}
\label{sec:method}

Consider the supervised learning setup outlined in~\Cref{sec:background}, with the objective of training a machine learning model on the experimental labels of $N$ independent and identically distributed samples drawn from a biased subset of chemical space, resulting in the data realizations \mbox{${\calD = \{\bx_i, \by_i\}_{i=1}^N} = (\bx_\calD, \by_\calD)$} of inputs \mbox{$\bx_i \in \calX'\subset\calX$} and labels \mbox{$\by_i \in \calY$}, where \mbox{$\calY \subseteq \real^K$} for regression and \mbox{$\calY \subseteq \{0, 1\}^K$} for classification tasks with $K$ labels.

Let $p_{\bY | f(\bX ; \bTheta)}$ be an observation model of the labels $\bY$ given a latent stochastic function $f(\bX ; \bTheta):\calX\times\R^P\to\calY$ induced by a set of stochastic parameters $\bTheta\in\R^P$ and evaluated at a set of input points $\bX\in\calX$. Additionally, let $p_{f(\bX ; \bTheta)}$ be a prior distribution over such latent stochastic functions.
$p_{\bY | f(\bX ; \bTheta)}(\by_{\calD} \vbar f(\bx_{\calD} ; \btheta))$ is then the likelihood of observing labels $\by_{\calD}$ under $f(\bx_{\calD} ; \btheta)$ --- a realization of the stochastic function evaluated at inputs $\bx_{\calD}$.

Instead of formulating the posterior inference problem as finding the posterior distribution over stochastic parameters $\bTheta$, we follow \citet{rudner2021tractable} and reframe variational inference in stochastic neural networks as finding a posterior distribution over the \textit{latent stochastic functions} $f(\bx_{\calD}; \bTheta)$ at the training points $\bx_{\calD}$.
In particular, while the parameter-space Bayesian inference problem is given by
\begin{align}
\label{eq:bayes_ps}
    p_{\bTheta | \calD}(\bTheta \vbar \calD)
    =
    \frac{p_{\bY | \bTheta, \bX}(\by_{\calD} \vbar \btheta, \bx_{\calD}) \, p_{\bTheta}(\btheta)}{p_{\bY | \bX}(\by_{\calD} \vbar \bx_{\calD})} ,
\end{align}
the inference problem over $f(\bx_{\calD} ; \btheta)$ is expressed by
\begin{align}
\begin{split}
\label{eq:bayes_fs}
    &
    p_{f(\bX ; \bTheta) | \calD}(f(\bx_{\calD} ; \btheta) \vbar \calD)
    \\
    &
    =
    \frac{p_{\bY | f(\bX ; \bTheta)}(\by_{\calD} \vbar f(\bx_{\calD} ; \btheta)) \, p_{f(\bX ; \bTheta)}(f(\bx_{\calD} ; \btheta))}{p_{\bY | \bX}(\by_{\calD} \vbar \bx_{\calD})},
\end{split}
\end{align}
which includes an explicit dependence on the function-space prior evaluated at the training points $p_{f(\bX ; \bTheta)}(f(\bx_{\calD} ; \btheta))$, which allows us to specify arbitrary preferences for suitable parametric function mappings $f$.

To show how the inference problem in~\Cref{eq:bayes_ps} and~\Cref{eq:bayes_fs} are related, note that for a prior distribution over parameters $p_{\bTheta}$, the prior distribution $p_{f(\bX ; \btheta)}$ over $f(\bx_{\calD} ; \btheta)$ induced by $p_{\bTheta}$ is given by
\begin{align}
%
\begin{split}
    &
    p_{f(\bX ; \bTheta)}(f(\bx_{\calD} ; \btheta))
    \\
    &
    =
    \int_{\R^{P}} p_{\bTheta}(\btheta') \, \delta( f(\bx_{\calD} ; \btheta) - f(\bx_{\calD} ; \btheta') ) \dee \btheta' ,
\end{split}
\end{align}
and, similarly, the posterior distribution $p_{f(\bX ; \bTheta) | \calD}$ over $f(\bx_{\calD} ; \btheta)$ induced by the posterior distribution over parameters $p_{\bTheta | \calD}$ is given by
\begin{align}
%
\begin{split}
    &
    p_{f(\bX ; \bTheta) | \calD}(f(\bx_{\calD} ; \btheta) \vbar \calD)
    \\
    &
    =
    \int_{\R^{P}} p_{\bTheta | \calD}(\btheta' \vbar \calD) \, \delta( f(\bx_{\calD} ; \btheta) - f(\bx_{\calD} ; \btheta') ) \dee \btheta' ,
\end{split}
\end{align}
where $\delta(\cdot)$ is the Dirac delta function~\citep{wolpert1993fsmap,Rudner2022fsvi}.
In the remainder of this section, subscripts will be dropped from probability density functions when the dependence is clear from context.

We will now extend this function-space formulation of Bayesian inference to define a probabilistic model that is able to integrate prior knowledge of the full input space $\calX$ beyond a biased subset of training points $\bx_\calD\subseteq\calX'$.
Specifically, we extend the probabilistic model above to the random variables $f(\{ \bX, \bX_{\calC} \}; \bTheta)$ and $\bX_{\calC}$, where $\bX_{\calC}\subseteq\calX\setminus\calX'$ is a set of \textit{context points}, yielding the posterior distribution
\begin{align}
%
\label{eq:bayes_fs_context}
    &
    p(f(\{ \bx_{\calD}, \bx_{\calC} \} ; \btheta), \bx_{\calC} \vbar \calD)
    \\
    &
    =
    \frac{p(\by_{\calD} \vbar f(\bx_{\calD} ; \btheta)) \, p(f( \{ \bx_{\calD}, \bx_{\calC} \} ; \btheta) \vbar \bx_{\calD}, \bx_{\calC} ) \, p(\bx_{\calC}) }{p(\by_{\calD} \vbar \bx_{\calD})}
    \nonumber
    %
    %
    %
    %
    %
    %
    %
    %
    %
    %
%
\end{align}
where, for a stochastic function evaluation $f(\{ \bx_{\calD}, \bx_{\calC} \} ; \btheta)$ defined by a valid stochastic process over $f(\cdot \,; \bTheta)$, the likelihood $p(\by_{\calD} \vbar f(\bx_{\calD} ; \btheta))$ and marginal likelihood $p_{\bY | \bX}(\by_{\calD} \vbar \bx_{\calD})$ are independent of $f( \bX_{\calC} ; \bTheta)$ and $\bX_{\calC}$ by marginal consistency.

For non-linear function mappings \mbox{$f : \calX \times \R^P \rightarrow \calY$} parameterized by high-dimensional $\bTheta \in \R^P$, the inference problem specified in~\Cref{eq:bayes_fs_context} is analytically intractable.
Instead, we may frame it variationally as
\begin{align}
%
    \min_{q_{\bTheta} \in \calQ_{q_{\bTheta}}} \DD_{\textrm{KL}}( q_{f(\{ \bX, \bX_{\calC} \} ; \bTheta), \bX_{\calC}} \,\|\, p_{f(\{ \bX, \bX_{\calC} \} ; \bTheta), \bX_{\calC} | \calD} )
\end{align}
for some variational distribution over parameters $q_{\bTheta}$ in a variational family $\calQ_{q_{\bTheta}}$~\citep{wainwright2008vi}.
Letting the variational distribution factorize as
\begin{align}
    q_{f(\{ \bX, \bX_{\calC} \} ; \bTheta), \bX_{\calC}}
    \defines
    q_{f(\{ \bX, \bX_{\calC} \} ; \bTheta)} q_{\bX_{\calC}}
    =
    q_{f(\{ \bX, \bX_{\calC} \} ; \bTheta)} p_{\bX_{\calC}} ,
\end{align}
and assuming that $q_{\bX_{\calC}} = p_{\bX_{\calC}}$, we can reformulate the inference problem above in a simplified form as
\begin{align}
%
    \min_{q_{\bTheta} \in \calQ_{q_{\bTheta}}} \E_{p_{\bX_{\calC}}} \left[ \DD_{\textrm{KL}}( q_{f(\bX ; \bTheta) | \bX_{\calC}} \,\|\, p_{f(\bX ; \bTheta) | \bX_{\calC}, \calD} ) \right] ,
\end{align}
which can in turn be equivalently expressed as
\begin{align}
\label{eq:objective}
\begin{split}    
    &
    \max_{q_{\bTheta} \in \calQ_{q_{\bTheta}}} \bigg\{ \E_{q_{\bTheta} p_{\bX_{\calC}}} \left[ \log p(\by_{\calD} \vbar f(\bx_{\calD} ; \btheta)) \right]
    \\
    &
    \qquad\qquad~~
    - \DKL{q_{f(\{ \bX, \bX_{\calC} \} ; \bTheta)}}{p_{f(\{ \bX, \bX_{\calC} \} ; \bTheta)}} \bigg\} .
\end{split}
\end{align}
If $p_{\bTheta}$ is chosen to be an isotropic Gaussian distribution and $\calQ_{q_{\bTheta}}$ is the family of mean-field Gaussian distributions, the prior and variational distributions in~\Cref{eq:objective} can be approximated using the local linearization scheme introduced in~\citet{Rudner2022fsvi}.
These approximations result in a factorized variational objective, making stochastic variational inference and stochastic gradient-based optimization techniques applicable~\citep{hinton1993keeping,graves2011practical,hoffman2013svi,blundell2015mfvi}.

By enabling the specification of the context point distribution $p_{\bX_{\calC}}$
and the prior distribution over functions $p_{f(\{ \bX, \bX_{\calC} \} ; \bTheta)}$, this framework enables us to explicitly encode 
arbitrary modeling preferences as distributions that place high probability mass on relevant regions of the input domain and specify prior knowledge of preferred parametric function mappings on unlabelled data points.

After optimizing the variational objective with respect to the parameters of $q_{\bTheta}$, we obtain samples from approximate posterior predictive distribution through
\begin{align}
%
\begin{split}
    %
    \hspace*{-3pt}q(\by_{\ast} \vbar \bx_{\ast})
    &
    \approx
    \frac{1}{M_{\ast}} \sum\nolimits_{j=1}^{M_{\ast}} p(\by_{\ast} \vbar f(\bx_{\ast} ; \btheta^{(j)})) ,
\end{split}
\end{align}%
with $\btheta^{(j)} \sim q_{\bTheta}$ and $M_{\ast}$ being the number of Monte Carlo samples used to estimate the predictive distribution.


