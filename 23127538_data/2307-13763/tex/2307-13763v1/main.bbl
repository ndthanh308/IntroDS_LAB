\begin{thebibliography}{}

\bibitem[Adams and Fournier, 2003]{adams2003sobolev}
Adams, R.~A. and Fournier, J.~J. (2003).
\newblock {\em Sobolev spaces}.
\newblock Elsevier.

\bibitem[Amari, 1998]{amari1998natural}
Amari, S.-I. (1998).
\newblock Natural gradient works efficiently in learning.
\newblock {\em Neural computation}, 10(2):251--276.

\bibitem[Bagnell, 2012]{bagnell12funcgrad}
Bagnell, D. (2012).
\newblock Functional gradient descent.
\newblock
  \url{https://www.cs.cmu.edu/~16831-f12/notes/F12/16831_lecture21_danielsm.pdf},.

\bibitem[Betancourt, 2017]{betancourt2017conceptual}
Betancourt, M. (2017).
\newblock A conceptual introduction to hamiltonian monte carlo.
\newblock {\em arXiv preprint arXiv:1701.02434}.

\bibitem[Campos et~al., 2016]{10.1007/s10618-015-0444-8}
Campos, G.~O., Zimek, A., Sander, J., Campello, R.~J., Micenkov\'{a}, B.,
  Schubert, E., Assent, I., and Houle, M.~E. (2016).
\newblock On the evaluation of unsupervised outlier detection: Measures,
  datasets, and an empirical study.
\newblock {\em Data Min. Knowl. Discov.}, 30(4):891–927.

\bibitem[Chen et~al., 2018]{chen2018neural}
Chen, R.~T., Rubanova, Y., Bettencourt, J., and Duvenaud, D.~K. (2018).
\newblock Neural ordinary differential equations.
\newblock {\em Advances in neural information processing systems}, 31.

\bibitem[Cui et~al., 2020]{cui2020nonparametric}
Cui, Z., Kirkby, J.~L., and Nguyen, D. (2020).
\newblock Nonparametric density estimation by b-spline duality.
\newblock {\em Econometric Theory}, 36(2):250--291.

\bibitem[Eggermont et~al., 2001]{eggermont2001maximum}
Eggermont, P. P.~B., LaRiccia, V.~N., and LaRiccia, V. (2001).
\newblock {\em Maximum penalized likelihood estimation. Volume I: Density
  Estimation}, volume~1.
\newblock Springer.

\bibitem[Ferraccioli et~al., 2021]{ferraccioli2021nonparametric}
Ferraccioli, F., Arnone, E., Finos, L., Ramsay, J.~O., Sangalli, L.~M., et~al.
  (2021).
\newblock Nonparametric density estimation over complicated domains.
\newblock {\em JOURNAL OF THE ROYAL STATISTICAL SOCIETY SERIES B STATISTICAL
  METHODOLOGY}, 83(2):346--368.

\bibitem[Good and Gaskins, 1971]{goodd1971nonparametric}
Good, I. and Gaskins, R.~A. (1971).
\newblock Nonparametric roughness penalties for probability densities.
\newblock {\em Biometrika}, 58(2):255--277.

\bibitem[Grafakos, 2008]{grafakos2008classical}
Grafakos, L. (2008).
\newblock {\em Classical fourier analysis}, volume~2.
\newblock Springer.

\bibitem[Grathwohl et~al., 2018]{grathwohl2018ffjord}
Grathwohl, W., Chen, R.~T., Bettencourt, J., Sutskever, I., and Duvenaud, D.
  (2018).
\newblock Ffjord: Free-form continuous dynamics for scalable reversible
  generative models.
\newblock {\em arXiv preprint arXiv:1810.01367}.

\bibitem[Guha et~al., 2016]{10.5555/3045390.3045676}
Guha, S., Mishra, N., Roy, G., and Schrijvers, O. (2016).
\newblock Robust random cut forest based anomaly detection on streams.
\newblock In {\em Proceedings of the 33rd International Conference on
  International Conference on Machine Learning - Volume 48}, ICML'16, page
  2712–2721. JMLR.org.

\bibitem[Han et~al., 2022]{han2022adbench}
Han, S., Hu, X., Huang, H., Jiang, M., and Zhao, Y. (2022).
\newblock Adbench: Anomaly detection benchmark.

\bibitem[H{\"a}rdle et~al., 2004]{hardle2004nonparametric}
H{\"a}rdle, W., M{\"u}ller, M., Sperlich, S., Werwatz, A., et~al. (2004).
\newblock {\em Nonparametric and semiparametric models}, volume~1.
\newblock Springer.

\bibitem[Hutchinson, 1989]{doi:10.1080/03610918908812806}
Hutchinson, M. (1989).
\newblock A stochastic estimator of the trace of the influence matrix for
  laplacian smoothing splines.
\newblock {\em Communications in Statistics - Simulation and Computation},
  18(3):1059--1076.

\bibitem[Hyv{\"a}rinen and Dayan, 2005]{hyvarinen2005estimation}
Hyv{\"a}rinen, A. and Dayan, P. (2005).
\newblock Estimation of non-normalized statistical models by score matching.
\newblock {\em Journal of Machine Learning Research}, 6(4).

\bibitem[Kakade, 2001]{kakade2001natural}
Kakade, S.~M. (2001).
\newblock A natural policy gradient.
\newblock {\em Advances in neural information processing systems}, 14.

\bibitem[Kerkyacharian and Picard, 1993]{kerkyacharian1993density}
Kerkyacharian, G. and Picard, D. (1993).
\newblock Density estimation by kernel and wavelets methods: optimality of
  besov spaces.
\newblock {\em Statistics \& Probability Letters}, 18(4):327--336.

\bibitem[Kirkby et~al., 2023]{kirkby2023spline}
Kirkby, J.~L., Leitao, {\'A}., and Nguyen, D. (2023).
\newblock Spline local basis methods for nonparametric density estimation.
\newblock {\em Statistic Surveys}, 17:75--118.

\bibitem[Klonias, 1984]{klonias1984class}
Klonias, V. (1984).
\newblock On a class of nonparametric density and regression estimators.
\newblock {\em The Annals of Statistics}, pages 1263--1284.

\bibitem[Kwon et~al., 2018]{8416441}
Kwon, D., Natarajan, K., Suh, S.~C., Kim, H., and Kim, J. (2018).
\newblock An empirical study on network anomaly detection using convolutional
  neural networks.
\newblock In {\em 2018 IEEE 38th International Conference on Distributed
  Computing Systems (ICDCS)}, pages 1595--1598.

\bibitem[Mason et~al., 1999]{mason1999boosting}
Mason, L., Baxter, J., Bartlett, P., and Frean, M. (1999).
\newblock Boosting algorithms as gradient descent.
\newblock {\em Advances in neural information processing systems}, 12.

\bibitem[Munkres, 2018]{munkres2018analysis}
Munkres, J.~R. (2018).
\newblock {\em Analysis on manifolds}.
\newblock CRC Press.

\bibitem[Novak et~al., 2018]{novak2018reproducing}
Novak, E., Ullrich, M., Wo{\'z}niakowski, H., and Zhang, S. (2018).
\newblock Reproducing kernels of sobolev spaces on rd and applications to
  embedding constants and tractability.
\newblock {\em Analysis and Applications}, 16(05):693--715.

\bibitem[Papamakarios et~al., 2021]{papamakarios2021normalizing}
Papamakarios, G., Nalisnick, E., Rezende, D.~J., Mohamed, S., and
  Lakshminarayanan, B. (2021).
\newblock Normalizing flows for probabilistic modeling and inference.
\newblock {\em The Journal of Machine Learning Research}, 22(1):2617--2680.

\bibitem[Rahimi and Recht, 2007]{rahimi2007random}
Rahimi, A. and Recht, B. (2007).
\newblock Random features for large-scale kernel machines.
\newblock {\em Advances in neural information processing systems}, 20.

\bibitem[Rudin, 2017]{rudin2017fourier}
Rudin, W. (2017).
\newblock {\em Fourier analysis on groups}.
\newblock Courier Dover Publications.

\bibitem[Saitoh and Sawano, 2016]{saitoh2016theory}
Saitoh, S. and Sawano, Y. (2016).
\newblock {\em Theory of reproducing kernels and applications}.
\newblock Springer.

\bibitem[Sch{\"o}lkopf et~al., 2002]{scholkopf2002learning}
Sch{\"o}lkopf, B., Smola, A.~J., Bach, F., et~al. (2002).
\newblock {\em Learning with kernels: support vector machines, regularization,
  optimization, and beyond}.
\newblock MIT press.

\bibitem[Shen et~al., 2020]{shen2020sinkhorn}
Shen, Z., Wang, Z., Ribeiro, A., and Hassani, H. (2020).
\newblock Sinkhorn barycenter via functional gradient descent.
\newblock {\em Advances in Neural Information Processing Systems}, 33:986--996.

\bibitem[Singh et~al., 2018]{singh2018nonparametric}
Singh, S., Uppal, A., Li, B., Li, C.-L., Zaheer, M., and P{\'o}czos, B. (2018).
\newblock Nonparametric density estimation under adversarial losses.
\newblock {\em Advances in Neural Information Processing Systems}, 31.

\bibitem[Song and Ermon, 2019]{song2019generative}
Song, Y. and Ermon, S. (2019).
\newblock Generative modeling by estimating gradients of the data distribution.
\newblock {\em Advances in neural information processing systems}, 32.

\bibitem[Song et~al., 2020]{song2020sliced}
Song, Y., Garg, S., Shi, J., and Ermon, S. (2020).
\newblock Sliced score matching: A scalable approach to density and score
  estimation.
\newblock In {\em Uncertainty in Artificial Intelligence}, pages 574--584.
  PMLR.

\bibitem[Song et~al., 2021]{song2021scorebased}
Song, Y., Sohl-Dickstein, J., Kingma, D.~P., Kumar, A., Ermon, S., and Poole,
  B. (2021).
\newblock Score-based generative modeling through stochastic differential
  equations.
\newblock In {\em International Conference on Learning Representations}.

\bibitem[Stein and Weiss, 1971]{stein1971introduction}
Stein, E.~M. and Weiss, G. (1971).
\newblock Introduction to fourier analysis on euclidean spaces (pms-32), volume
  32.
\newblock In {\em Introduction to Fourier Analysis on Euclidean Spaces
  (PMS-32), Volume 32}. Princeton university press.

\bibitem[Takada, 2008]{takada2008asymptotic}
Takada, T. (2008).
\newblock Asymptotic and qualitative performance of non-parametric density
  estimators: a comparative study.
\newblock {\em The Econometrics Journal}, 11(3):573--592.

\bibitem[Thomas-Agnan, 1996]{thomas1996computing}
Thomas-Agnan, C. (1996).
\newblock Computing a family of reproducing kernels for statistical
  applications.
\newblock {\em Numerical Algorithms}, 13(1):21--32.

\bibitem[Uppal et~al., 2019]{uppal2019nonparametric}
Uppal, A., Singh, S., and P{\'o}czos, B. (2019).
\newblock Nonparametric density estimation \& convergence rates for gans under
  besov ipm losses.
\newblock {\em Advances in neural information processing systems}, 32.

\bibitem[Wainwright, 2019]{wainwright2019high}
Wainwright, M.~J. (2019).
\newblock {\em High-dimensional statistics: A non-asymptotic viewpoint},
  volume~48.
\newblock Cambridge university press.

\bibitem[Wasserman, 2006]{wasserman2006all}
Wasserman, L. (2006).
\newblock {\em All of nonparametric statistics}.
\newblock Springer Science \& Business Media.

\bibitem[Williams and Rasmussen, 2006]{williams2006gaussian}
Williams, C.~K. and Rasmussen, C.~E. (2006).
\newblock {\em Gaussian processes for machine learning}.
\newblock MIT press Cambridge, MA.

\bibitem[Yao et~al., 2007]{yao2007early}
Yao, Y., Rosasco, L., and Caponnetto, A. (2007).
\newblock On early stopping in gradient descent learning.
\newblock {\em Constructive Approximation}, 26(2):289--315.

\end{thebibliography}
