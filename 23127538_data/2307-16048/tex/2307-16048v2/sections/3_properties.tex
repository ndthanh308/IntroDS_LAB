\section{Properties of $\mathcal{F}$-identifiable parents}
\label{Section_3}

Recall that we assume the data-generation process of $Y$ in the form 
\begin{equation}
Y=f_Y(\textbf{X}_{pa_Y}, \varepsilon_Y),\,\,\,\,\,\,\, f_Y\in\mathcal{F}, \,\,\,\,\,\,\,\varepsilon_Y\indep \textbf{X}_{pa_Y}, \,\,\,\,\,\,\,\varepsilon_Y\sim U(0,1).\tag{\ref{SCM_for_Y}}
\end{equation}
This assumption implies that $S=pa_Y$ is always  $\mathcal{F}$-plausible set, since $f_Y^{\leftarrow}(\textbf{X}_{pa_Y}, Y)\indep\textbf{X}_{pa_Y} $. Therefore, under ( \ref{SCM_for_Y}), it always holds that
\begin{equation}\label{subseteq_parents}
S_\mathcal{F}(Y) \subseteq pa_Y.
\end{equation}
However, the equality $S_\mathcal{F}(Y)= pa_Y$ does not need to hold. Observe that 
$\text{if }\mathcal{F}_1\subseteq \mathcal{F}_2, \text{ then }S_{\mathcal{F}_1}(Y)\supseteq S_{\mathcal{F}_2}(Y).$
This is not surprising, as the more restrictions we put on the data-generation process, the larger the set of identifiable parents. Note that ( \ref{SCM_for_Y}) inherently assumes local causal sufficiency for $Y$, but full observability of the variables is not required for (\ref{subseteq_parents}) to hold. 


The case where \( pa_Y = \emptyset \) needs to be addressed separately since an empty set cannot, by definition, be \(\mathcal{F}\)-plausible. In some untypical situations, such as when the full DAG is non-identifiable, this might even lead to an incorrect conclusion \( S_{\mathcal{F}}(Y) \neq \emptyset = pa_Y \).
This contrasts with the ICP framework \citep{Peters_invariance}, where the case \( pa_Y = \emptyset \) is testable. However, if we use ICP and find \( \widehat{pa}_Y = \emptyset \), we cannot distinguish between two possibilities: 1) \( pa_Y \) is indeed empty, or 2) the environments are not rich enough. Since our framework observes only one environment, we can never reject the second possibility without additional assumptions.

The case \(\mathcal{F} = \mathcal{F}_F\) offers an elegant option for assessing the validity of \( pa_Y = \emptyset \). If $F$ is the marginal distribution of \( Y \) with some (unknown but constant) parameters, we say that \( pa_Y = \emptyset \) is plausible. Although this elegantly corresponds to the \(\mathcal{F}_F\) framework, this does not imply it is a reasonable approach in practice.
Consequently, assuming \( pa_Y \neq \emptyset \) can often be justified either by expert knowledge about the problem or by employing other causal inference methods, such as conducting a do-intervention or orienting certain edges using Meek rules \citep{Meek}. 


In this section, we discuss which elements belong to $S_{\mathcal{F}}(Y)$ and we provide various identifiability results under which $S_{\mathcal{F}}(Y) = pa_Y$. We focus on the additive case $\mathcal{F} = \mathcal{F}_A$; however, several counterparts of the shown results for different restrictions such as $\mathcal{F}=\mathcal{F}_{LS}$ and $\mathcal{F}_F$ can be found in Appendix~\ref{Appendix_location_scale_definition}. 
Recall that we interchangeably use the notation $X_0=Y$ for the target variable.



\subsection{General (full) identifiability $\implies$ (local) $\mathcal{F}$-identifiability }
\label{section_general_implies_local_identifiability}
In the following, we demonstrate that classical identifiability results from the literature can be used to assess the $\mathcal{F}$-plausibility of a set $S$. Informally, we show that if all variables in the SCM follow an identifiable $\mathcal{F}_A$-model, then any set $S$ containing a child of $Y$ cannot be $\mathcal{F}_A$-plausible. 

To state the result, we use the notion of \textbf{restricted additive noise model} (restricted $\mathcal{F}_A$-model), introduced in \citep[Definition 27]{Peters2014}; a submodel of $\mathcal{F}_A$ such that the causal graph is identifiable. It is well known that a bivariate additive noise model is identifiable as long as $(f_j ,P_{X_i})$  does not solve a certain differential equation (leading to non-identifiable cases such as linear Gaussian case \citep{Zhang2009}). A restricted additive noise model consists of such $f\in\mathcal{F}_A$ that does not solve this differential equation for all marginals in the SCM. As an example, one can consider a SCM where $X_j = f_j(\textbf{X}_{pa_j})+\eta_j$, where $\eta_j$ are Gaussian and $f_j$ are non-linear in any component. For more details, see Appendix \ref{Appendix_restricted_additive_noise_model} or   \citep[Section 3.2]{Peters2014}. 



For simplicity, we focus on the case when $\textbf{X} = (X_1, \dots, X_p)$ are neighbors (either direct causes or direct effects) of $Y$ in the corresponding SCM. Using the classical conditional independence approach and d-separation \citep{Pearl_causal_diagrams_biometrika}, we can eliminate other variables from being potential parents of $X_0 = Y$. 

\begin{proposition}
\label{TheoremFidentifiabilityWithChild}
Let $(X_0, \textbf{X})$ follow an (identifiable) restricted $\mathcal{F}_A$-model with DAG $\mathcal{G}$, where all $\textbf{X}$ are neighbors of $X_0$ in $\mathcal{G}$.  Let $S \subseteq \{1, \dots, p\}$ contain a child of $X_0$ in $\mathcal{G}$.  Then, $S$ is not $\mathcal{F}_A$-plausible. 
\end{proposition}

The proof is in \hyperref[proof of TheoremFidentifiabilityWithChild]{Appendix} \ref{proof of TheoremFidentifiabilityWithChild}. Appendix~\ref{Appendix_pairwise_identifiability} provides an analogous result for general class $\mathcal{F}$. 


Following Example~\ref{example_3_variable_case_introduction}, consider $X_2 = f_2(Y) + \eta_2$, where $Y\indep\eta_2$. Combining Proposition~\ref{TheoremFidentifiabilityWithChild} with Theorem~1 in \cite{Zhang2009}, we find that $S=\{2\}$ is not $\mathcal{F}_A$-plausible for a ``typical'' combination of $(f_2, \eta_2)$; for example, if $f_2$ is non-linear and $\eta_2$ has the Gaussian distribution. Therefore, we get $S_{\mathcal{F}_A}(Y)=pa_Y=\{1\}$.



\subsection{Deriving assumptions under which \texorpdfstring{$S_{\mathcal{F}}(Y) = pa_Y$}{Complete set of identifiable parents}}\label{Subsection3.2}

In this section, we explore the $\mathcal{F}$-plausibility of a subset of parents $S\subsetneq pa_Y$. We show that if the function \(f_Y\) is ``sufficiently complicated'', then no subset \(S \subsetneq pa_Y\) is $\mathcal{F}_A$-plausible.
We focus on the additive case $\mathcal{F} = \mathcal{F}_A$; however, counterparts of the results for $\mathcal{F}_{LS}, \mathcal{F}_{F}$ can be found in Appendix~\ref{Appendix_location_scale_definition}. 


\begin{theorem}\label{Theorem_in_section2}

 Consider $(Y, \textbf{X})\in\mathbb{R}\times \mathbb{R}^p$ satisfying ( \ref{SCM_for_Y}) with  $pa_Y\neq \emptyset$ and $\mathcal{F} = \mathcal{F}_A$. 
 Let $\textbf{X}_{pa_Y}$ have full support and independent components. 
 
  \begin{itemize}
     \item If $f_Y$ has a form \begin{equation}\label{efaetgfas}
        f_Y(\textbf{x}_{pa_Y}, e) = h_1(\textbf{x}_S) + h_2(\textbf{x}_{pa_Y\setminus S}) + q^{-1}(e), \,\,\,\,\,\textbf{x}\in\mathbb{R}^{|pa_Y|}, e\in(0,1),
     \end{equation}
 for some non-empty $S\subset pa_Y$, where $h_1, h_2$ are measurable functions and $q^{-1}$ is a quantile function and $pa_Y\setminus S = \{i\in pa_Y: i\not\in S\}$. Then, $S_{\mathcal{F}_A}(Y) = \emptyset$.
     \item If $f_Y\in\mathcal{F}_A$ is continuous injective function that cannot be written as (\ref{efaetgfas}), then every $S\subsetneq pa_Y$ is not $\mathcal{F}_A$-plausible. In particular, if $pa_Y = \{1, \dots, p\}$ then $S_{\mathcal{F}_A}(Y) = pa_Y$. 
    \end{itemize}
\end{theorem}
\begin{hproof}
Full proof is in \hyperref[Proof of Theorem_in_section2]{Appendix} \ref{Proof of Theorem_in_section2}. Here, we show the main steps of the second bullet-point in the case when $p=2$ and $pa_Y = \{1,2\}$. 

Let us define \( Y = f_0(X_1, X_2) + q^{-1}(\varepsilon_Y) \), where \( \varepsilon_Y \indep \textbf{X}_{pa_Y} \) for some continuous function \( f_0 \) and quantile function \( q^{-1} \). For contradiction, assume that \( S = \{1\} \) is an \( \mathcal{F}_A \)-plausible set; hence there exists \( f \in \mathcal{F}_A \) such that \( f: \mathbb{R}^{2} \to \mathbb{R} \) satisfies the definition of \( \mathcal{F}_A \)-plausibility. Since \( f \in \mathcal{F}_A \), we can write \( f(x, e) = \mu(x) + \tilde{q}^{-1}(e) \) for \( x \in \mathbb{R}^{|S|} \) and \( e \in (0,1) \), where \( \mu \) is some function and \( \tilde{q}^{-1} \) is a quantile function. Additive functions have an inverse in the form \( f^{\leftarrow}(x, y) = \tilde{q}(y - \mu(x)) \) for \( x \in \mathbb{R}^{|S|} \) and \( y \in \mathbb{R} \) (see the discussion in Appendix~\ref{Appendix_A.1.}). We then have:
\[ \text{S is } \mathcal{F}_A\text{-plausible} \iff f^{\leftarrow}(X_1, Y) \indep X_1 \iff Y - \mu(X_1) \indep X_1 \iff     f_0(X_1, X_2) - \mu(X_1) \indep X_1.   \]
Fix \( a_0 \in \mathbb{R} \). The conditional distribution of \( f_0(X_1, X_2) - \mu(X_1) \mid X_1 = a_0 \) must be the same as \( f_0(X_1, X_2) - \mu(X_1) \mid X_1 = x \) for any \( x \in \mathbb{R} \). Thus,
\( f_0(x, X_2) - \mu(x) \overset{D}{=} f_0(a_0, X_2) - \mu(a_0), \)
which is equivalent to
\begin{equation*}
    f_0(x, X_2) \overset{D}{=} \underbrace{\mu(a_0) - \mu(x)}_{h_1(x)} + \underbrace{f_0(a_0, X_2)}_{h_2(X_2)}.
\end{equation*}
This is a contradiction with \eqref{efaetgfas}; although the equality is only in distribution, Lemma~\ref{lemma_additivity} extends it to equality everywhere under the injectivity assumption. Therefore, \( S = \{1\} \) is not an \( \mathcal{F}_A \)-plausible set. An analogous argument can be made for \( S = \{2\} \).
\end{hproof}

In Theorem~\ref{Theorem_in_section2}, the assumption of independent components of \(\textbf{X}_{pa_Y}\) can be relaxed by assuming a Gaussian distribution for \(\textbf{X}_{pa_Y}\) along with an additional technical assumption on \(f_Y\); see Lemma~\ref{lemma_Gaussian_parents} in Appendix~\ref{Appendix_location_scale_definition}.

Theorem~\ref{Theorem_in_section2} demonstrates that a subset \(S \subsetneq pa_Y\) is an $\mathcal{F}_A$-plausible set if and only if the influence of \(\textbf{X}_{pa_Y}\) on \(Y\) can be decomposed into two independent components, \(h_1(\textbf{X}_S)\) and \(h_2(\textbf{X}_{pa_Y \setminus S})\), such that  \(h_1(\textbf{X}_S) \indep h_2(\textbf{X}_{pa_Y \setminus S})\). If the function \(f_Y\) is ``sufficiently complicated'', in a sense that this decomposition is not feasible, then no subset \(S \subsetneq pa_Y\) is $\mathcal{F}_A$-plausible. 


\subsection{Issue with linear models }
\label{Section3.1}
The following lemma shows that linear models are not ``sufficiently complicated'' for identifying the parents of $Y$. We use the well-known notion of d-separation, defined in \cite{Pearl_book}.  

\begin{lemma}\label{LemmaAboutUnidentifiabilityFL}
Let $(Y, \textbf{X})\in\mathbb{R}\times \mathbb{R}^p$ follow an $\mathcal{F}_L$-model (linear structural causal model) with DAG $\mathcal{G}_0$ and $pa_Y(\mathcal{G}_0)\neq\emptyset$. Then, $|S_{\mathcal{F}_L}(Y)| \leq 1$. Moreover, if there are any $a,b\in an_Y(\mathcal{G}_0)$ that are d-separated in $\mathcal{G}_0$, then $S_{\mathcal{F}_L}(Y) = \emptyset$. 
\end{lemma}
The proof is in \hyperref[Proof of LemmaAboutUnidentifiabilityFL]{Appendix} \ref{Proof of LemmaAboutUnidentifiabilityFL}. 
Lemma~\ref{LemmaAboutUnidentifiabilityFL} assumes a causally sufficient model, but this can be relaxed to include hidden variables; see Appendix~\ref{Appendix_A_Lemma} (Lemma~\ref{LemmaAboutUnidentifiabilityFL2}).

 
Lemma~\ref{LemmaAboutUnidentifiabilityFL} shows a more general principle that goes beyond the linear models. If we can \textit{marginalize} a causal model to a smaller submodel without breaking $f_Y\in\mathcal{F}$, then only the submodel is relevant for inference about  $S_{\mathcal{F}}(Y)$. 

\begin{lemma}\label{lemma158}
 Let $\mathcal{F}\subseteq\mathcal{I}_m$. Let $(X_0, \textbf{X})\in\mathbb{R}\times \mathbb{R}^p$ follow an $\mathcal{F}$-model with DAG $\mathcal{G}_0$ and $pa_{X_0}(\mathcal{G}_0)\neq \emptyset$. Let  $S\subseteq \{1, \dots, p\}$ be a non-empty set. Let $(X_0, \textbf{X})$ be ``marginalizable'' to $S\cup\{0\}$; that is, $(X_0, \textbf{X}_S)$  can also be written as an $\mathcal{F}$-model with some underlying DAG $\mathcal{G}_S$.  Then $S_{\mathcal{F}}(X_0)\subseteq S$. 
\end{lemma}

\subsection{Hidden confounders}
\label{Section2_hidden_confounders}
We now discuss our framework under the presence of a hidden confounding. Let $\textbf{X} = (\textbf{X}^{obs}, \textbf{X}^{hid})$ denote observed and unobserved covariates, respectively, where $obs\cup hid=\{1, \dots, p\}, obs\cap hid = \emptyset$. 
By definition, the set of $\mathcal{F}$-identifiable parents of $Y$ can be written as
\begin{equation*}
S_\mathcal{F}(Y):= \bigcap_{\substack{S\subseteq obs , S\neq \emptyset\\{ \text{ S is an } \mathcal{F} \text{-plausible}}\\{\text{set of parents of Y}}  }}S.
\end{equation*}

In the presence of a hidden confounder, (\ref{subseteq_parents}) does not need to hold since $\textbf{X}^{hid}$ can create a spurious dependence between \(\varepsilon_Y\) and \(\textbf{X}_{pa_Y \cap obs}\). However, \(S_\mathcal{F}(Y)\) depends on the nature of this dependence, and (\ref{subseteq_parents}) might still hold, as suggested by the following lemma.



\begin{lemma}\label{lemma_hidden_confounder}

 Consider $(Y, \textbf{X})\in\mathbb{R}\times \mathbb{R}^p$  satisfy ( \ref{SCM_for_Y}) with  $\mathcal{F} = \mathcal{F}_A$. Consider $\emptyset\neq hid\subset pa_Y$. Let $S\subseteq pa_Y \cap obs$ and $\tilde{S}:=(pa_Y\cap obs)\setminus S$ such that
 $(\textbf{X}^{hid}, \textbf{X}_S)\indep \textbf{X}_{\tilde{S}}$ (one can consider that $\textbf{X}^{hid}$ cause $\textbf{X}_S$ and $Y$, but not $\textbf{X}_{\tilde{S}}$). 
 
 If $f_Y$ has a form \begin{equation*}
        f_Y(\textbf{x}, e) = h_1(\textbf{X}^{hid}, \textbf{X}_S) + h_2(\textbf{X}_{\tilde{S}}) + q^{-1}(e), \,\,\,\,\,\textbf{x}\in\mathbb{R}^{|pa_Y|}, e\in(0,1),
     \end{equation*}
for some continuous non-constant real functions  $h_1, h_2$ and a quantile function $q^{-1}$. Then, $S_{\mathcal{F}_A}(Y) \subseteq \tilde{S}\subset pa_Y$.
\end{lemma}

The proof is in \hyperref[Proof of lemma_hidden_confounder]{Appendix} \ref{Proof of lemma_hidden_confounder}.  Lemma~\ref{lemma_hidden_confounder} demonstrates that we still obtain $S_{\mathcal{F}_A}(Y) \subseteq pa_Y$ as long as $\textbf{X}^{hid}$ affect $Y$ in a ``sufficiently simple'' way. In this case, ``sufficiently simple'' means that $f_Y$ can be splitted into the part affected by $\textbf{X}^{hid}$ and a part that is not affected by $\textbf{X}^{hid}$. Notice the discrepacy between Theorem~\ref{Theorem_in_section2} and Lemma~\ref{lemma_hidden_confounder}. The function \(f_Y\) should be ``sufficiently complicated'' in order to identify the observed parents but ``sufficiently simple'' to handle hidden confounders. 

\subsection{Pareto example}\label{subsection3.3}


In many applications, the target variable of interest (e.g., income or salaries) follows a Pareto distribution \citep{AtkinsonBourguignon2000}. In such a case, assuming \( f_Y \in \mathcal{F}_F \) where \( F \) is the Pareto distribution can be a reasonable. This assumption, together with local causal sufficiency, is often enough for identifiability of the direct causes of $Y$. 


Consider, for instance, that the (unknown) ground truth is as follows: \( (Y, X_1, X_2, X_3) \) follows an SCM with the DAG in Figure~\ref{wfaef}. Assume that \( Y \mid \textbf{X}_{pa_Y} \) follows a Pareto distribution \( F \) with parameter \( \theta(\textbf{X}_{pa_Y}) \). Then \( S_{\mathcal{F}_F}(Y) \subseteq \{1,2\} = pa_Y \). 

\begin{wrapfigure}{r}{4cm}
% Figure removed
\caption{DAG corresponding to Section~\ref{subsection3.3}}
\label{wfaef}
\end{wrapfigure} 

Additionally, the equality \( S_{\mathcal{F}_F}(Y) = \{1,2\} = pa_Y \) holds if we assume the following:
\( \theta \) has the form \( \theta(X_1, X_2) = h_1(X_1) + h_2(X_2) \) for some continuous non-constant functions \( h_1 \) and \( h_2 \), and \( X_3 \) is of the form \( X_3 = \mu_3(Y) + \eta_3 \), where \( \eta_3 \indep Y \), \( \eta_3 \sim N(0,\sigma^2) \), and there do not exist \( a, b \in \mathbb{R} \) such that \( \mu(x) = a\log(x) + b \). This follows from Theorem~\ref{Theorem_in_section2} (in particular, its modification for \(\mathcal{F}_F\) located in Appendix~\ref{Appendix_location_scale_definition}, Proposition~\ref{LemmaOParetoinseparabilite}) and Proposition~\ref{TheoremFidentifiabilityWithChild} combined with Theorem~1 in \cite{bodik2023identifiability}.

We have demonstrated that assuming  ( \ref{SCM_for_Y}) typically allows us to identify the direct causes of $Y$. In the next section, we will show that, in practice, the identifiable direct causes can also be consistently estimated from a random sample. 













