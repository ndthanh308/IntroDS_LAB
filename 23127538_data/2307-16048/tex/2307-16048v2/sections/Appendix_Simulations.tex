\section{Simulations and application}
\label{section_appendix_simulations}

Appendix~\ref{Section_Additive} offers an illustrative  simulations to demonstrate the theoretical findings discussed in Section \ref{Section_3}. Appendix~\ref{Section_benchmarks} pertains to the evaluation of the algorithm's performance on three benchmark datasets.

To randomly generate a $d$-dimensional function, we use the concept of the Perlin noise generator \citep{PerlinNoise}. Examples of such generated functions can be found in Appendix~\ref{Appendix_D1}. The two algorithms presented in Section~\ref{section_algorithm}, all simulations, and the Perlin noise generator are coded in the programming language \texttt{R} \citep{Rstudio} and can be found in the supplementary package or at \url{https://github.com/jurobodik/Structural-restrictions-in-local-causal-discovery.git}.


\subsection{Highlighting the results from Section \ref{Section_3}}
\label{Section_Additive}

Consider a target variable $Y$ with two parents $X_1, X_2$, where $\textbf{X} = (X_1, X_2)$ is a centered normal random vector with correlation $c\in\mathbb{R}$. The generation process of $Y$ is as follows: \begin{equation}\label{eq576}
    Y = g_1(X_1)+g_2(X_2) + \gamma\cdot g_{1,2}(X_1, X_2)+\eta,\,\,\,\,\,\,\text{ with }\eta\sim N(0,1)\,\text{ and  }\gamma\in\mathbb{R},
\end{equation}
 where $g_1, g_2, g_{1,2}$ are fixed functions generated using the Perlin noise approach.

Theorem~\ref{Theorem_in_section2} suggests that if $c= \gamma= 0 $ then we should find that  $S_{\mathcal{F}}(Y) = \emptyset$. Moreover, if  $c\in\mathbb{R},$ and $\gamma\neq 0 $, then  $S_{\mathcal{F}}(Y) = pa_Y = \{1,2\}$. Moreover, the choice of $c$ can affect the finite sample properties. 

Figure~\ref{Plot_sim_additive} confirms these results. For a range of parameters $c\in[0,0.9], \gamma\in[0,1]$, we generate 50 times such a random dataset of size $n=500$ 
and estimate $S_{\mathcal{F}}(Y)$ using the ISD algorithm. If $\gamma$ is small, we discover direct causes of $Y$ only in a small number of cases. However, the larger the $\gamma$, the larger the number of discovered parents. Figure~\ref{Plot_sim_additive} also suggests that the correlation between the parents can actually be beneficial. The reason is that even if (\ref{eq576}) is additive in each component, the correlation between the components can create a bias in estimating $g_1$ (resp. $g_2$). This results in a dependency between the residuals and $X_1$ (resp. $X_2$) in the model where we regress $Y$ on $X_1$ (or on $X_2$), and we are more likely to reject the plausibility of $S = \{1\}$ (or $S = \{2\}$). 

% Figure environment removed



\subsection{Benchmarks}\label{Section_benchmarks}
We created three benchmark datasets to assess the performance of our methodology. Two of them correspond to additive noise models ($\mathcal{F}=\mathcal{F}_A$), and the third to $\mathcal{F}=\mathcal{F}_F$ with the Pareto distribution $F$.

The first benchmark dataset consists of $\textbf{X} = (X_1, X_2, X_3, X_4)^\top$ and the response variable $Y$, where $pa_Y = \{1\}$ with the corresponding graph drawn in Figure~\ref{Figure_DAG_for_sim1}A. The data-generation process is as follows: 
\begin{equation*}
 X_1 =\eta_1, \,\,\,Y = g_Y(X_1)+\eta_Y, \,\,\,X_i = g_i(Y,\eta_i),\,\,\, i=2,3,4,     
\end{equation*}
where $g_Y, g_2, g_3, g_4$ are fixed functions generated using the Perlin noise approach, $\eta_1, \eta_2, \eta_3, \eta_4$ are correlated uniformly distributed noise variables, and $\eta_Y\sim N(0,1)$ is independent of $\eta_1, \dots, \eta_4$. The challenge is to find the (one) direct cause among all variables. 
 
The second benchmark dataset consists of $\textbf{X} = (X_1, X_2, X_3)^\top$ and the response variable $Y$, where $pa_Y = \{1,2,3\}$ with the corresponding graph drawn in Figure~\ref{Figure_DAG_for_sim1}B. The data-generation process is as follows:
\begin{align*}
   \begin{pmatrix}
          X_1 \\
            X_2 \\
            X_3
         \end{pmatrix} &\sim N\bigg(\begin{pmatrix}
           0 \\
            0 \\
            0
         \end{pmatrix}, 
         \begin{pmatrix}
          1 ,   c , c \\
            c,   1, c\\
            c,c,1
         \end{pmatrix}\bigg),\,\,\,\, Y = g_Y(X_1, X_2, X_3) + \eta_Y, \,\,\,\text{ where }\eta_Y\overset{}{\sim} N(0,1),
 \end{align*}
for $c=0.5$ and a fixed function $g_Y$ generated using the Perlin noise approach. The challenge is to estimate as many direct causes of $Y$ as possible. 

The third benchmark dataset consists of $\textbf{X} = (X_1, X_2, X_3)^\top$ and the response variable $Y$ corresponding to the DAG C of Figure~\ref{Figure_DAG_for_sim1}. Here, every edge is randomly oriented; either  $\to$ or $\leftarrow$ with probability $\frac{1}{2}$. The source variables (variables without parents) are generated following the standard Gaussian distribution. $Y$ is generated as (\ref{CPCM_def}) with the Pareto distribution $F$ with a fixed function $\theta(\textbf{X}_{pa_Y})$ generated using the Perlin noise approach. Finally, if $X_i$ is the effect of $Y$, it is generated as $X_i = f_i(Y, \eta_i)$, where $\eta_i\sim U(0,1)$,  $ \eta_i\indep Y$ and $f_i$ is a fixed function generated as a combination of functions generated using the Perlin noise approach. 


In all datasets, we consider a sample size of $n=500$. 
% Figure environment removed




We compare our proposed algorithms with specific methods for causal discovery, which are: RESIT \citep{Peters2014}, CAM-UV \citep{maeda2021causal}, pairwise bQCD \citep{Natasa_Tagasovska}, pairwise IGCI with the Gaussian reference measure \citep{IGCI}, and pairwise slope \citep{Slope}. When we use the term ``pairwise,'' we are referring to orienting each edge between $(X_i, Y)$ separately, $i=1, \dots, p$. 

For evaluating the performance, we simulate 100 repetitions of each of the three benchmark datasets and use two metrics: ``percentage of discovered correct causes'' and ``percentage of no false positives'' which measures the percentage of cases with no incorrect variable in the set of estimated causes. As an example, consider $pa_Y = \{1,2,3\}$. If we estimate $\widehat{pa}_Y = \{1,2\}$ in $80\%$ of cases and  $\widehat{pa}_Y = \{1,4,5\}$ in $20\%$ of cases, the percentage of discovered correct causes is $\frac{2}{3}\frac{8}{10} + \frac{1}{3}\frac{2}{10} \approx 60\%$ and the percentage of no false positives is $80\%$. 

Table \ref{Table_results} shows the performance of all methodologies. As shown, our two algorithms outperform the other approaches by a significant margin. The IDE algorithm never includes a wrong covariate in the set of causes. On the other hand, although the scoring algorithm demonstrates better overall performance and power, it tends to include non-causal variables more frequently.




\subsection{Visualization of benchmark datasets}
\label{Appendix_Simulations}

\subsubsection{Functions generated using the Perlin noise approach}\label{Appendix_D1}
In the following, we provide examples of functions generated using the Perlin noise approach. For a one-dimensional case, let $X_1, \eta_Y\overset{iid}{\sim} N(0,1)$ and $Y = g(X_1)+\eta_Y$, where $g$ is generated using the Perlin noise approach. Such (typical) datasets are plotted in Figure~\ref{Figure_perlin_1}. 

For a two-dimensional case, let $X_1,X_2, \eta_Y\overset{iid}{\sim} N(0,1)$ and $Y = g(X_1, X_2)+\eta_Y$, where $g$ is generated using the Perlin noise approach. Such (typical) datasets are plotted in Figure~\ref{Figure_perlin_2}. 

For a three-dimensional case, let $X_1,X_2,X_3, \eta_Y\overset{iid}{\sim} N(0,1)$ and $Y = g(X_1, X_2,X_3)+\eta_Y$, where $g$ is generated using the Perlin noise approach. The visualisation of a four-dimensional dataset is a bit tricky; Figure~\ref{Figure_perlin_3} represents the three-dimensional slices of the function. 
% Figure environment removed






% Figure environment removed











% Figure environment removed









%\subsubsection{Application}\label{Appendix_Application}
%Figure~\ref{Figure_application_data_visualization} represents a visualization of the covariates from Section~\ref{section_simulations}. 

%% Figure environment removed
















