\section{Simulations and application}
\label{section_simulations}

In this section, we highlight some of the theoretical results on simulated data (Section~\ref{Section_Additive}), assess the performance of the algorithms on three benchmark datasets (Section~\ref{Section_benchmarks}), and apply our methodology on real data (Section~\ref{section_application}). 

To randomly generate a $d$-dimensional function, we use the concept of the Perlin noise generator \citep{PerlinNoise}. Examples of such generated functions can be found in Appendix~\ref{Appendix_D1}. The two algorithms presented in Section~\ref{section_algorithm}, all simulations, and the Perlin noise generator are coded in the programming language \texttt{R} \citep{Rstudio} and can be found in the supplementary package or at \url{https://github.com/jurobodik/Structural-restrictions-in-local-causal-discovery.git}.


\subsection{Additive case under Proposition~\ref{LemmaOAdditiveinseparabilite}}
\label{Section_Additive}

We conducted a simulation study highlighting the results from Proposition~\ref{LemmaOAdditiveinseparabilite}. Consider a target variable $Y$ with two parents $X_1, X_2$, where $\textbf{X} = (X_1, X_2)$ is a centered normal random vector with correlation $c\in\mathbb{R}$. The generation process of $Y$ is as follows: \begin{equation}\label{eq576}
    Y = g_1(X_1)+g_2(X_2) + \gamma\cdot g_{1,2}(X_1, X_2)+\eta,\,\,\,\,\,\,\text{ with }\eta\sim N(0,1)\,\text{ and  }\gamma\in\mathbb{R},
\end{equation}
 where $g_1, g_2, g_{1,2}$ are fixed functions generated using the Perlin noise approach.

Proposition~\ref{LemmaOAdditiveinseparabilite} suggests that if $c=\gamma = 0$, then  $S_{\mathcal{F}}(Y) = \emptyset$. Lemma~\ref{GaussianSeparabilita} suggests that if $c\in\mathbb{R}, \gamma\neq 0 $ then we should find that  $S_{\mathcal{F}}(Y) = pa_Y = \{1,2\}$. The case $c\in\mathbb{R}, \gamma= 0 $ is unclear and it depends on $g_1, g_2$; see Remark~\ref{example158}. Moreover, the choice of $c$ can affect the finite sample properties. 

Figure~\ref{Plot_sim_additive} confirms these results. For a range of parameters $c\in[0,0.9], \gamma\in[0,1]$, we generate such a random dataset of size $n=500$ 50 times and estimate $S_{\mathcal{F}}(Y)$ using the ISD algorithm. If $\gamma$ is small, we discover direct causes of $Y$ only in a small number of cases. However, the larger the $\gamma$, the larger the number of discovered parents. Figure~\ref{Plot_sim_additive} also suggests that the correlation between the parents can actually be beneficial. The reason is that even if (\ref{eq576}) is additive in each component, the correlation between the components can create a bias in estimating $g_1$ (resp. $g_2$). This results in a dependency between the residuals and $X_1$ (resp. $X_2$) in the model where we regress $Y$ on $X_1$ (or on $X_2$), and we are more likely to reject the plausibility of $S = \{1\}$ (or $S = \{2\}$). 

% Figure environment removed



\subsection{Benchmarks}\label{Section_benchmarks}
We created three benchmark datasets to assess the performance of our methodology. Two of them correspond to additive noise models ($\mathcal{F}=\mathcal{F}_A$), and the third to $\mathcal{F}=\mathcal{F}_F$ with the Pareto distribution $F$.

The first benchmark dataset consists of $\textbf{X} = (X_1, X_2, X_3, X_4)^\top$ and the response variable $Y$, where $pa_Y = \{1\}$ with the corresponding graph drawn in Figure~\ref{Figure_DAG_for_sim1}A. The data-generation process is as follows: 
\begin{equation*}
 X_1 =\eta_1, \,\,\,Y = g_Y(X_1)+\eta_Y, \,\,\,X_i = g_i(Y,\eta_i),\,\,\, i=2,3,4,     
\end{equation*}
where $g_Y, g_2, g_3, g_4$ are fixed functions generated using the Perlin noise approach, $\eta_1, \eta_2, \eta_3, \eta_4$ are correlated uniformly distributed noise variables, and $\eta_Y\sim N(0,1)$ is independent of $\eta_1, \dots, \eta_4$. The challenge is to find the (one) direct cause among all variables. 
 
The second benchmark dataset consists of $\textbf{X} = (X_1, X_2, X_3)^\top$ and the response variable $Y$, where $pa_Y = \{1,2,3\}$ with the corresponding graph drawn in Figure~\ref{Figure_DAG_for_sim1}B. The data-generation process is as follows:
\begin{align*}
   \begin{pmatrix}
          X_1 \\
            X_2 \\
            X_3
         \end{pmatrix} &\sim N\bigg(\begin{pmatrix}
           0 \\
            0 \\
            0
         \end{pmatrix}, 
         \begin{pmatrix}
          1 ,   c , c \\
            c,   1, c\\
            c,c,1
         \end{pmatrix}\bigg),\,\,\,\, Y = g_Y(X_1, X_2, X_3) + \eta_Y, \,\,\,\text{ where }\eta_Y\overset{}{\sim} N(0,1),
 \end{align*}
for $c=0.5$ and a fixed function $g_Y$ generated using the Perlin noise approach. The challenge is to estimate as many direct causes of $Y$ as possible. 

The third benchmark dataset consists of $\textbf{X} = (X_1, X_2, X_3)^\top$ and the response variable $Y$ corresponding to the DAG C of Figure~\ref{Figure_DAG_for_sim1}. Here, every edge is randomly oriented; either  $\to$ or $\leftarrow$ with probability $\frac{1}{2}$. The source variables (variables without parents) are generated following the standard Gaussian distribution. $Y$ is generated as (\ref{CPCM_def}) with the Pareto distribution $F$ with a fixed function $\theta(\textbf{X}_{pa_Y})$ generated using the Perlin noise approach. Finally, if $X_i$ is the effect of $Y$, it is generated as $X_i = f_i(Y, \eta_i)$, where $\eta_i\sim U(0,1)$,  $ \eta_i\indep Y$ and $f_i$ is a fixed function generated as a combination of functions generated using the Perlin noise approach. 


In all datasets, we consider a sample size of $n=500$. 
% Figure environment removed




We compare our proposed algorithms with specific methods for causal discovery, which are: RESIT \citep{Peters2014}, CAM-UV \citep{maeda2021causal}, pairwise bQCD \citep{Natasa_Tagasovska}, pairwise IGCI with the Gaussian reference measure \citep{IGCI}, and pairwise slope \citep{Slope}. When we use the term ``pairwise,'' we are referring to orienting each edge between $(X_i, Y)$ separately, $i=1, \dots, p$. 

For evaluating the performance, we simulate 100 repetitions of each of the three benchmark datasets and use two metrics: ``percentage of discovered correct causes'' and ``percentage of no false positives'' which measures the percentage of cases with no incorrect variable in the set of estimated causes. As an example, consider $pa_Y = \{1,2,3\}$. If we estimate $\widehat{pa}_Y = \{1,2\}$ in $80\%$ of cases and  $\widehat{pa}_Y = \{1,4,5\}$ in $20\%$ of cases, the percentage of discovered correct causes is $\frac{2}{3}\frac{8}{10} + \frac{1}{3}\frac{2}{10} \approx 60\%$ and the percentage of no false positives is $80\%$. 

Table \ref{Table_results} shows the performance of all methodologies. As shown, our two algorithms outperform the other approaches by a significant margin. The IDE algorithm never includes a wrong covariate in the set of causes. On the other hand, although the scoring algorithm demonstrates better overall performance and power, it tends to include non-causal variables more frequently.



% Please add the following required packages to your document preamble:
% \usepackage{multirow}
\begin{table}[h]
\begin{tabular}{|l|c|c|c|c}
\cline{1-4}
\multirow{2}{*}{}        & \textbf{First}     & \textbf{Second}                         & \textbf{Third}                          & \textbf{Total}  \\
                         & \textbf{Benchmark} & \multicolumn{1}{l|}{\textbf{Benchmark}} & \multicolumn{1}{l|}{\textbf{Benchmark}} & \textbf{(Mean)} \\ \hline
\textbf{IDE algorithm}   & 98\%/ 100\%        & 82\%/ 100\%                             & 72\%/ 100\%                             & 84\%/ 100\%     \\ \cline{1-4}
\textbf{Score algorithm} & 100\%/ 100\%       & 98\%/ 100\%                             & 92\%/ 88\%                              & 93\%/ 96\%      \\ \cline{1-4}
RESIT                    & 52\%/ 18\%         & 36\%/ 100\%                             & 2\%/ 94\%                               & 30\%/ 71\%      \\ \cline{1-4}
CAM-UV                      & 96\%/ 40\%         &  2\%/ 100\%                             & 0\%/ 100\%                              & 32\%/ 80\%      \\ \cline{1-4}
Pairwise bQCD            & 100\%/ 0\%         & 56\%/ 100\%                             & 80\%/ 26\%                              & 78\%/ 42\%      \\ \cline{1-4}
Pairwise IGCI            & 0\%/ 48\%          & 0\%/ 100\%                              & 70\%/ 34\%                              & 17\%/ 70\%      \\ \cline{1-4}
Pairwise Slope           & 100\%/ 2\%         & 100\%/ 100\%                            & 100\%/ 22\%                             & 100\%/ 41\%     \\ \cline{1-4}
\end{tabular}
\caption{Performance of different algorithms on the three benchmark datasets of Section \ref{Section_benchmarks}. The first number in each cell represents the ``percentage of discovered correct causes'', and the second is the ``percentage of no false positives''. }
\label{Table_results}
\end{table}












