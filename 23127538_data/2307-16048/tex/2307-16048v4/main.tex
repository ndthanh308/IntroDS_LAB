
%--------------- Personalize your document here ---------------

\author{} % Enter your name
\newcommand{\studentID}{} % enter your student ID
\newcommand{\supervisorone}{} % Enter your supervisor's name
\newcommand{\supervisortwo}{}% Leave it empty or enter your second supervisor's name 
\newcommand{\department}{}
\newcommand{\exam}{}

\title{} %Enter the title of your report 
\date{\today} % insert a specific date	

%--------------------------------------------------------------

% This document was adapted from the
% TEMPLATE FOR PHYS250 WORKSHEET created by Alastair McLean
% URL: https://www.overleaf.com/latex/templates/phys250-worksheet-template/xxftvfhmwqdt

% Jefferson Silveira
% Email: 19jdls1@queensu.ca
% Last update: 09-Jun-2021
% If you have any questions or concerns, do not hesitate to contact me.
%--------------------------------------------------------------

\documentclass[a4paper,11pt]{article}
\usepackage[left=30mm,top=30mm,right=30mm,bottom=30mm]{geometry}
\usepackage{etoolbox} %required for cover page
\usepackage{booktabs}
\usepackage[table,xcdraw]{xcolor}
\usepackage[usestackEOL]{stackengine}
\usepackage[round]{natbib}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{bm}
\usepackage{graphicx}
\usepackage{subcaption}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{mathtools}
\usepackage{xcolor}
\usepackage{float}
\usepackage{hyperref}
\usepackage[capitalise]{cleveref}
\usepackage{enumitem,kantlipsum}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{amsthm}
\usepackage{bbm}% theorems, definitions, etc.
\usepackage{pifont}
 \usepackage{multirow}
 \usepackage{footnote}
 \makesavenoteenv{tabular}
 \usepackage{url}
 \usepackage{eucal}
 \usepackage{wrapfig}
 
\usepackage[ruled,vlined]{algorithm2e}
\usepackage{listings}
\usepackage{dirtytalk}
\usepackage{graphicx}
\usepackage{multirow}

\usepackage{chngcntr}
\usepackage{apptools}
\AtAppendix{\counterwithin{lemma}{section}}
\AtAppendix{\counterwithin{theorem}{section}}
\AtAppendix{\counterwithin{proposition}{section}}
\AtAppendix{\counterwithin{consequence}{section}}

%\renewcommand{\listingscaption}{Algorithm}
%\renewcommand{\listoflistingscaption}{List of Algorithms}
\newcommand{\E}{\mathbb{E}}
\newcommand{\R}{\mathbb{R}}
\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\argmax}{arg\,max}
\newcommand{\F}{\mathcal{F}}
\newcommand{\M}{ (\mathcal{M}_1, \mathcal{M}_2)}


\newtheorem{proposition}{Proposition}
\newtheorem{definition}{Definition}

\newtheorem{example}{Example}
\newtheorem{remark}{Remark}
\newtheorem{assumption}{Assumption}
\newtheorem*{assumption*}{Assumption}
\newtheorem{observation}{Observation}
\newtheorem*{terminology}{Terminology}
\newtheorem{consequence}{Consequence}
\newtheorem{identity}{Identity}


\newtheorem{innercustomthm}{Theorem}
\newenvironment{customthm}[1]
  {\renewcommand\theinnercustomthm{#1}\innercustomthm}
  {\endinnercustomthm}
  

\newtheorem{innercustomlem}{Lemma}
\newenvironment{customlem}[1]
  {\renewcommand\theinnercustomlem{#1}\innercustomlem}
  {\endinnercustomlem}


\newtheorem{innercustomprop}{Proposition}
\newenvironment{customprop}[1]
  {\renewcommand\theinnercustomprop{#1}\innercustomprop}
  {\endinnercustomprop}


  
\newtheorem{innercustomremark}{Remark}
\newenvironment{customremark}[1]
  {\renewcommand\theinnercustomremark{#1}\innercustomremark}
  {\endinnercustomremark}


  
\newtheorem{innercustomconsequence}{Consequence}
\newenvironment{customconsequence}[1]
  {\renewcommand\theinnercustomconsequence{#1}\innercustomconsequence}
  {\endinnercustomconsequence}
  
  \newtheorem{theorem}{Theorem}
\newtheorem{lemma}{Lemma}
\newtheorem{notation}{Notation}

\def\b#1{{\color{red}\bf #1}}%

\def\lm#1{{\textcolor{purple}{LM: \bf #1}}}

\newenvironment{myproof}{
  \par\medskip\noindent
  \textit{Proof}.
}{
\newline
\rightline{$\qedsymbol$}
}

\newenvironment{hproof}{%
  \renewcommand{\proofname}{Idea of the proof}\proof}{\endproof}

\newcommand\independent{\protect\mathpalette{\protect\independenT}{\perp}}
\newcommand{\indep}{\perp \!\!\! \perp}
\def\independenT#1#2{\mathrel{\rlap{$#1#2$}\mkern2mu{#1#2}}}

\setlength{\bibsep}{1pt plus 0.1ex}

\bibliographystyle{plainnat}

\hypersetup{
    colorlinks,
    linkcolor={black},
    citecolor={blue!50!black},
    urlcolor={blue!80!black}
}
\newtheorem{condition}{Condition}
\linespread{1}

\graphicspath{{figures/}}	

% Keywords command
\providecommand{\keywords}[1]
{
  \small	
  \textbf{\textit{Keywords: }} #1
}
%----------------------------------TITLE PAGE -----------------------------------
\title{Structural restrictions in local causal discovery: identifying direct causes of a target variable} 
\author{Juraj Bodik$^{1 \footnote{ Email of the corresponding author: Juraj.Bodik@unil.ch. \\Published in \textit{Biometrika}, 2025, \href{https://doi.org/10.1093/biomet/asaf042}{10.1093/biomet/asaf042}}}$, Valérie Chavez-Demoulin$^1$}
\date{%
    $^1$ {\small HEC, Université de Lausanne, Switzerland} \\%
    }

%-------------------------------- END TITLE PAGE ----------------------------------

\begin{document}

\pagenumbering{gobble}% Remove page numbers (and reset to 1)

\maketitle
\begin{abstract}
We consider the problem of learning a set of direct causes of a target variable from an observational joint distribution. Learning directed acyclic graphs (DAGs) that represent the causal structure is a fundamental problem in science. Several results are known when the full DAG is identifiable from the distribution, such as assuming a nonlinear Gaussian data-generating process. Here, we are only interested in identifying the direct causes of one target variable (local causal structure), not the full DAG. This allows us to relax the identifiability assumptions and develop possibly faster and more robust algorithms. In contrast to the Invariance Causal Prediction framework, we only assume that we observe one environment without any interventions. We discuss different assumptions for the data-generating process of the target variable under which the set of direct causes is identifiable from the distribution. While doing so, we put essentially no assumptions on the variables other than the target variable. In addition to the novel identifiability results, we provide two practical algorithms for estimating the direct causes from a finite random sample and demonstrate their effectiveness on several benchmark and real datasets. 
\end{abstract}
%TC:ignore
\keywords{Causal discovery, Identifiability, Target variable, Local causal discovery, Structural causal models, Causal inference}
%TC:endignore
  
%\newpage
%\listoffigures
%\newpage
%\listoftables
%\newpage
%\listofalgorithms % List of algorithms in pseudocode format
%\newpage
%\listoflistings % List of algorithms in code format
%\newpage


\pagenumbering{arabic}% Arabic page numbers (and reset to 1)

% This is how you can organize your document
\input{0_introduction}
\input{3_properties}
\input{4_algorithm}
\input{5v2_Simulations}
\input{6_application}


\section{Discussion and future work}

In this work, we studied the problem of estimating the direct causes of a target variable \( Y \). We introduced a general framework that leverages identifiability theory for full causal graphs \( \mathcal{G} \) in a localized setting. This allows for more flexible and scalable applications of causal discovery. 

Several avenues for future work remain. It would be valuable to adapt other causal discovery methods, such as IGCI or those based on Kolmogorov complexity \citep{IGCI, Natasa_Tagasovska}, to the local setting. Similarly, extensions of our framework to time series data \citep{bodik, bodik2024grangercausalityextremes} are a natural next step. Ideas from recent advances in the invariance framework, such as defining sets and simultaneous false discovery bounds \citep{Christina, li2024simultaneousICP}, could also be incorporated into our ISD algorithm to improve its power and computational efficiency. Our local framework is also well-suited for prediction under distribution shift, such as covariate shift or extrapolation \citep{jin2024reweightingpredictiverolecovariate, bodik_extrapolation}, where identifying direct causes enables more robust predictions. Furthermore, leveraging tools such as instrumental variables \citep{Imbens2014} or anchor regression \citep{10.1111/rssb.12398} may offer a principled way to address unobserved confounding and improve robustness in complex settings. 

A central limitation of our approach lies in the choice of the functional class $\mathcal{F}$. As in most causal discovery methods, such as those based on LiNGAM, post-nonlinear models, or location-scale assumptions, the validity and interpretability of the results depend critically on how well the chosen model class matches the underlying data-generating process. While the computational complexity may increase with the dimensionality of $\textbf{X}$, especially when testing many subsets, this also opens opportunities for improvement through scalable algorithms, dimension reduction techniques, or regularization strategies tailored to the local setting.

Overall, the theory developed in this work contributes to a deeper understanding of causal structure and the fundamental limitations of purely data-driven approaches to causal inference. We believe that causal discovery on a local scale provides a promising path toward practical applications, particularly in high-dimensional settings, and this work takes an important step toward making such methods more accessible, interpretable, and robust.


\section*{Acknowledgment}
This study was supported by the Swiss National Science Foundation, grant number 201126. 


\section*{Supplementary material}
\label{SM}
The supplementary material contains some detailed definitions and more technical explanations of the theory omitted from the main text for clarity, simulation study, some auxiliary lemmas, and all the technical details and proofs.

The code and data are available in the online repository \url{https://github.com/jurobodik/Structural-restrictions-in-local-causal-discovery.git} or on request from the author.   


\bibliography{bibliography}
\newpage
\appendix
\input{Appendix_A_Speci}
\input{Appendix_Simulations}
\input{Appendix_B_Auxiliary_Results}
\input{Appendix_C_Proofs}

%\input{sections/ToErase}

\end{document}


