\section*{D. Appendix: Proofs}
\label{Section_proofs}


\begin{customprop}{
\ref{TheoremFidentifiabilityWithChild}}
Let $(X_0, \textbf{X})$ follow an (identifiable) restricted $\mathcal{F}_A$-model with DAG $\mathcal{G}$, such that all $\textbf{X}$ are neighbors of $X_0$ in $\mathcal{G}$.   Let $S \subseteq \{1, \dots, p\}$ contain a child of $X_0$ in $\mathcal{G}$.  Then, $S$ is not $\mathcal{F}_A$-plausible. 
\end{customprop}

\begin{proof}
 \label{proof of TheoremFidentifiabilityWithChild} 
    For a contradiction, let $S$ be $\mathcal{F}_A$-plausible. Without loss of generality, let $X_1$ be a childless child of $X_0$ such that $1\in S$ (the set of children of $X_0$ is nonempty by assumption, and one of them must be childless to avoid cycles). The idea of the proof is that we define two bivariate $\mathcal{F}_A$-models, one with $X_0\to X_1$ and one with $X_1\to X_0$, which will lead to a contradiction with the identifiability of the original restricted $\mathcal{F}_A$-model. 

Since $(X_0, \textbf{X})$ follow an $\mathcal{F}_A$-model, we can write  $X_i = f_i(\textbf{X}_{pa_i}) + \eta_i$, where $f_i$ are some measurable functions and $\eta_i$ are jointly independent, $i\in \{0, \dots, p\}$. Specifically, we have 
\begin{equation*}
    \begin{split}
        X_0 = f_0(\textbf{X}_{pa_0}) + \eta_0, \,\,\,\,\,\,\,X_1 = f_1(X_0, \textbf{X}_{pa_1\setminus\{1\}}) + \eta_1, 
    \end{split}
\end{equation*}
where $\eta_1 \indep \textbf{X}_{\{0, 2, 3, \dots, p\}}$ .Conditioning on $\textbf{X}_{\{ 2, 3, \dots, p\}} = \textbf{x}$, we obtain 
\begin{equation*}
    \begin{split}
\textbf{SCM\,1:} \,\,\,\,\,\,\,\,\,\,\,\,\,       X_0 = \tilde{\eta}_0, \,\,\,\,\,\,\,X_1 = f_1(X_0, \textbf{x}_{pa_1\setminus\{1\}}) + \eta_1, 
    \end{split}
\end{equation*}
where $\tilde{\eta}_0\sim X_0\mid\textbf{X}_{\{2, 3, \dots, p\}} = \textbf{x}$ and $\eta_1\indep X_0$. 


From the fact that $S$ is $\mathcal{F}_A$-plausible, we can find a function $f$ such that $\eta_S:=X_0 - f(\textbf{X}_S)$ satisfies $\eta_S\indep \textbf{X}_S$. Hence, we can write $$
X_0 =f(X_1, \textbf{X}_{S\setminus\{1\}}) + \eta_S,$$ where $\eta_S\indep \textbf{X}_S$.  Conditioning on  $\textbf{X}_{\{2, 3, \dots, p\}} = \textbf{x}$, we obtain
$$
\textbf{SCM\,2:} \,\,\,\,\,\,\,\,\,\,\,\,\,      X_1 = \tilde{\eta}_1, \,\,\,\,\,X_0 =f(X_1, \textbf{x}_{S\setminus\{1\}}) + \eta_S,$$ where $\tilde{\eta}_1\sim X_1\mid X_{\{2, 3, \dots, p\}} = \textbf{x}$  and $\eta_S\indep X_1$. 

Notice that in both Models 1 and 2, the joint distribution of $(X_0, X_1)$ is equal to $P_{X_0, X_1\mid (X_2, \dots, X_p)=\textbf{x}}$ and hence, we were able to find two additive noise models generating the same joint distribution, where the first model follows restricted additive noise model. This is a direct contradiction with the definition of restricted additive noise model. Therefore,  $S$ is not $\mathcal{F}_F$-plausible. 
\end{proof}











 
 
\begin{customlem}{\ref{pairwise_implies_global}}
Pairwise identifiable $\mathcal{F}$-model defined in Appendix~\ref{Appendix_pairwise_identifiability} is identifiable.  
\end{customlem}

 
\begin{proof}\label{Proof of pairwise_implies_global}
For a contradiction, let there be two $\mathcal{F}$-models with causal graphs $\mathcal{G}\neq \mathcal{G}'$ that both generate the same joint distribution $P_{(X_0, \textbf{X})}$.   Using Proposition 29 in \cite{Peters2014}, variables $L,K\in \{X_0, \dots, X_p\}$ exist, such that 
\begin{itemize}
\item $K\to L$ in $\mathcal{G}$ and $L\to K$ in $\mathcal{G}'$,
\item $S:=\underbrace{\big\{pa_L(\mathcal{G})\setminus\{K\}\big\}}_\text{\textbf{Q}}\cup\underbrace{\big\{pa_K(\mathcal{G}')\setminus\{L\}\big\}}_\text{\textbf{R}}\subseteq \big\{nd_L(\mathcal{G}) \cap nd_K(\mathcal{G}')\setminus\{K,L\}\big\} $. 
\end{itemize}
For this $S$, choose $x_S$ according to the condition in the definition of pairwise identifiability. We use the notation $x_S=(x_q, x_r)$, where $q\in \textbf{Q}, r\in \textbf{R}$, and we define $K^\star := K\mid \{X_S=x_S\}$ and $L^\star := L\mid \{X_S=x_S\}$.  Now we use Lemma 36 and Lemma 37 from \cite{Peters2014}.  Since $K\to L$ in $\mathcal{G}$, we get $$K^\star=\tilde{\varepsilon}_{K^\star},\,\,\,\,\,\,\,\,\,\, L^\star = f_{L^\star}(K^\star, \varepsilon_L),$$ 
where $\tilde{\varepsilon}_{K^\star} = K\mid \{X_S=x_S\}$ and $\varepsilon_L\indep K^\star$. We obtained a bivariate $\mathcal{F}$-model with $K^\star\to L^\star$. However, the same holds for the other direction; from $L\to K$ in $\mathcal{G}'$, we get $$L^\star=\tilde{\varepsilon}_{L^\star},\,\,\,\,\,\,\,\,\,\, K^\star = f_{K^\star}(L^\star, \varepsilon_K),$$ 
 where $\tilde{\varepsilon}_{L^\star} =L\mid \{X_S=x_S\}$ and $\varepsilon_K\indep L^\star$. We obtained a bivariate $\mathcal{F}$-model with $L^\star\to K^\star$, which is a contradiction. 
\end{proof}



 
\begin{customprop}{\ref{proposition_for_pairwise_F_model_identifiability}}
Let $(X_0, \textbf{X})$ follow a pairwise identifiable $\mathcal{F}$-model with DAG $\mathcal{G}$, such that all $\textbf{X}$ are neighbors of $X_0$ in $\mathcal{G}$.   Let $S \subseteq \{1, \dots, p\}$ contain a child of $X_0$ in $\mathcal{G}$.  Then, $S$ is not $\mathcal{F}$-plausible. 
\end{customprop}

 
\begin{proof}\label{Proof of proposition_for_pairwise_F_model_identifiability}
    For a contradiction, let $S$ be $\mathcal{F}_A$-plausible. Without loss of generality, let $X_1$ be a childless child of $X_0$ such that $1\in S$ (the set of children of $X_0$ is nonempty by assumption, and one of them must be childless to avoid cycles). The idea of the proof is that we define two bivariate $\mathcal{F}$-models, one with $X_0\to X_1$ and one with $X_1\to X_0$, which will lead to a contradiction with the pairwise identifiability. 

  Since $(X_0, \textbf{X})$ follow an $\mathcal{F}$-model, we can write  $X_i = f_i(\textbf{X}_{pa_i(\mathcal{G})}, \varepsilon_i)$, where $f_i\in\mathcal{F}$ and $\varepsilon_i$ are jointly independent, $i\in \{0, 1, \dots, p\}$. We use the  pairwise identifiability condition. For a specific choice $(X_0, X_1)$ and $\tilde{S} = nd_1(\mathcal{G})\setminus\{0,1\} = \{2, \dots, p\}$ (the second equality holds since $X_1$ is a childless child),  $\textbf{x}_{\tilde{S}}: p_{\tilde{S}}(\textbf{x}_{\tilde{S}})>0$ exists, satisfying the condition that a bivariate $\mathcal{F}$-model defined as
\begin{equation}\label{tyuiop}
\tilde{X}_0=\tilde{\varepsilon}_0, \tilde{X}_1 = \tilde{f}_1(\tilde{X}_0, \tilde{\varepsilon}_1)
\end{equation}
is identifiable, where  $P_{\tilde{\varepsilon}_0} = P_{X_0\mid \textbf{X}_{\tilde{S}} = x_{\tilde{S}}}    $ and $\tilde{f}_1(x, \varepsilon) =f(\textbf{x}_{pa_1\setminus\{0\}}, x, \varepsilon)$, $\tilde{\varepsilon}_1\indep \tilde{\varepsilon}_0$ . 

From the fact that $S$ is $\mathcal{F}$-plausible, $f\in\mathcal{F}$ exists, such that $\varepsilon_S:=f^\leftarrow(\textbf{X}_S, X_0)$ satisfies $\varepsilon_S\indep \textbf{X}_S, \varepsilon_S\sim U(0,1)$. Hence, we can define a model  $$\tilde{\tilde{X}}_1 = \tilde{\tilde{\varepsilon}}_1 , \tilde{\tilde{X}}_0 = \tilde{\tilde{f}}(\tilde{\tilde{X}}_1, \varepsilon_S),$$ where $P_{\tilde{\tilde{\varepsilon}}_1} = P_{X_1\mid \textbf{X}_{\tilde{S}} = x_{\tilde{S}}}    $ and $\tilde{\tilde{f}}(\textbf{x}, \varepsilon) =f(\textbf{x}_{\tilde{S}}, x, \varepsilon)$. In this model, $\varepsilon_S\indep \tilde{\tilde{\varepsilon}}_1$. 

Now, note that $(\tilde{X}_0,\tilde{X}_1)\overset{D}{=}(\tilde{\tilde{X}}_0, \tilde{\tilde{X}}_1)$, since both sides are distributed as $\big[(X_0, X_1)\mid X_{\tilde{S}}\big]$.  This is a contradiction with the identifiability of (\ref{tyuiop}). Therefore,  $S$ is not $\mathcal{F}_F$-plausible.
\end{proof}




\begin{customlem}{\ref{LemmaAboutUnidentifiabilityFL}}
Let $(Y, \textbf{X})\in\mathbb{R}\times \mathbb{R}^p$ follow an $\mathcal{F}_L$-model with DAG $\mathcal{G}_0$ and $pa_Y(\mathcal{G}_0)\neq\emptyset$. Then, $|S_{\mathcal{F}_L}(Y)| \leq 1$ ($|S|$ represents the number of elements of the set $S$). Moreover, if  $a,b\in an_Y(\mathcal{G}_0)$ that are d-separated in $\mathcal{G}_0$ exist, then $S_{\mathcal{F}_L}(Y) = \emptyset$. 
\end{customlem}

\begin{proof}\label{Proof of LemmaAboutUnidentifiabilityFL}
First, we show $|S_{\mathcal{F}_L}(Y)| \leq 1$. Let $a\in an_Y(\mathcal{G}_0)\cap Source(\mathcal{G}_0)$. Such $a$ exists since $pa_Y(\mathcal{G}_0)\neq\emptyset$. We show that $S = \{a\}$ is an $\mathcal{F}_L-$plausible set. 

Denote $X_0:= Y$.  Since $\mathcal{G}_0$ is acyclic, it is possible to express recursively each variable $X_j , j= 0, \dots, p, $ as a weighted sum of the noise terms $\varepsilon_0, \dots, \varepsilon_p$ that belong to the ancestors of $X_j$. Let us write the Linear SCM with notation 
\begin{equation*}
X_i = \sum_{j\in pa_i}\beta_{j,i}X_j + \varepsilon_i  = \sum_{j\in an_i}\beta_{j\to i}\varepsilon_j,
\end{equation*}
where $\beta_{j,i}$ are non-zero constants and $\beta_{j\to i}$ is the sum of distinct weighted directed paths from node $j$ to node $i$, with a convention $\beta_{j\to j} := 1$.\footnote{To provide an example of the notation, if $X_1 = \varepsilon_1, X_2 = 2X_1 + \varepsilon_2, X_3 = 3X_1 + 4X_2+\varepsilon_3$, then $X_3 = 11\varepsilon_1 + 4\varepsilon_2 + 1\varepsilon_3 = \beta_{1\to 3}\varepsilon_1 +\beta_{2\to 3}\varepsilon_2 + \beta_{3\to 3}\varepsilon_1 $.}

Using this notation, note that 
$$X_0 = \sum_{j\in an_0}\beta_{j\to i}\varepsilon_j = \beta_{a\to 0}\varepsilon_a + \sum_{j\in an_0\setminus \{a\}}\beta_{j\to i}\varepsilon_j =\beta_{a\to 0} X_a + \sum_{j\in an_0\setminus \{a\}}\beta_{j\to i}\varepsilon_j ,$$ where $X_a\indep \sum_{j\in an_i\setminus \{a\}}\beta_{j\to i}\varepsilon_j$ since $a\in Source(\mathcal{G}_0)$. Hence, $Y - \beta_{a\to 0} X_a\indep X_a$, which is almost the definition of $\mathcal{F}_L$-plausibility of set $S = \{a\}$. More rigorously, for  $S = \{a\}$, we can find $f\in\mathcal{F}_L$ such that  $f_Y^{\leftarrow}({X}_{S}, Y)\indep X_S$ and $f_Y^{\leftarrow}({X}_{S}, Y)\sim U(0,1)$. This function can be defined as 
$$
f(x, \varepsilon) = \beta_{a\to 0}x + g^{-1}(\varepsilon), \,\,\,x\in\mathbb{R}, \varepsilon\in (0,1),
$$
where $g$ is the distribution function of $(Y - \beta_{a\to 0}X_S)$. This function obviously satisfies $f\in\mathcal{F}_L$. Moreover, since $f_Y^{\leftarrow}(X_{S}, Y) = g(Y - \beta_{a\to 0}X_S)$, it holds that $f_Y^{\leftarrow}({X}_{S}, Y)\indep X_S$ and $f_Y^{\leftarrow}({X}_{S}, Y)\sim U(0,1)$, which is what we wanted to show. Hence,  $|S_{\mathcal{F}_L}(Y)|\leq 1$, since $S_{\mathcal{F}_L}(Y)\subseteq S = \{a\}$. 

Now, let $a,b\in an_Y(\mathcal{G}_0)$ that are d-separated in $\mathcal{G}_0$. Let $a', b'\in \mathcal{G}_0$ such that $a'\in \big\{an_a(\mathcal{G}_0)\cup \{a\}\big \}\cap Source(\mathcal{G}_0)$,   $b'\in \big\{an_b(\mathcal{G}_0)\cup \{b\}\big \}\cap Source(\mathcal{G}_0)$. They are well defined since the sets $an_a(\mathcal{G}_0)\cup \{a\}$,  $an_b(\mathcal{G}_0)\cup \{b\}$  must contain some source node. Since $a,b$ are d-separated,   $ \big\{an_a(\mathcal{G}_0)\cup \{a\}\big \}$ and $\big\{an_b(\mathcal{G}_0)\cup \{b\}\big \}$ are disjoint sets, $a'\neq b'$ (they are even d-separated in $\mathcal{G}_0$). 

Using the same argument as in the first part of the proof, since $a'\in an_Y(\mathcal{G}_0)\cap Source(\mathcal{G}_0)$, it holds that  $S = \{a\}$ is an $\mathcal{F}_L-$plausible set.  $S = \{b\}$ is also an $\mathcal{F}_L-$plausible set since $b'\in an_Y(\mathcal{G}_0)\cap Source(\mathcal{G}_0)$. Together, $S_{\mathcal{F}_L}(Y)\subseteq \{a\}$ and $S_{\mathcal{F}_L}(Y)\subseteq \{b\}$. We showed that  $S_{\mathcal{F}_L}(Y) = \emptyset$. 
\end{proof}


\begin{customlem}{\ref{lemma158}}
 Let $\mathcal{F}\subseteq\mathcal{I}_m$. Let $(X_0, \textbf{X})\in\mathbb{R}\times \mathbb{R}^p$ follow an $\mathcal{F}$-model with DAG $\mathcal{G}_0$ and $pa_{X_0}(\mathcal{G}_0)\neq \emptyset$. Let  $S\subseteq \{1, \dots, p\}$ be a non-empty set. If $(X_0, \textbf{X})$ is marginalizable to $S\cup\{0\}$, then $S_{\mathcal{F}}(X_0)\subseteq S$. 
\end{customlem}
\begin{proof}
 \label{Proof of lemma158}
 Since  $(X_0, \textbf{X})$ is marginalizable to $S\cup\{0\}$,  $(X_0, \textbf{X}_S)$ follows an $\mathcal{F}$-model. Therefore, $f_0\in\mathcal{F}$ exists, such that $X_0 = f_0(X_{\tilde{S}}, \varepsilon_0)$ for some $\tilde{S}\subseteq S$, $\varepsilon_0\indep X_{\tilde{S}}$, $\varepsilon_0\sim U(0,1)$. 
In other words, $ f_0^{\leftarrow}(X_{\tilde{S}}, X_0)\indep X_{\tilde{S}}$,  $f_0^{\leftarrow}(X_{\tilde{S}}, X_0)\sim U(0,1)$, which is exactly the definition of $\mathcal{F}$-plausibility. Hence, $\tilde{S}$ is $\mathcal{F}$-plausible and consequently,  $S_{\mathcal{F}}(X_0)\subseteq \tilde{S}\subseteq S$. 
 \end{proof}






























 
 
 
\begin{customprop}{\ref{Support_proposition}}
Let $(Y, \textbf{X})\in\mathbb{R}\times \mathbb{R}^p$ follow an SCM with DAG $\mathcal{G}_0$. Let $S\subseteq\{1, \dots, p\}$ be a non-empty set.

\begin{itemize}
    \item (Additive case) Let  $\underline{\Psi}: \mathbb{R}^{\mid S\mid}\to \mathbb{R}$ be a finite lower support of $ (Y\mid \textbf{X}_S=\textbf{x}_S)$. 
If
\begin{equation} \tag{\ref{eq9987_additive}}
Y - \underline{\Psi}(\textbf{X}_S)\not\indep \textbf{X}_S,
\end{equation}
then $S$ is not $\mathcal{F}_{A}$-plausible. 

 \item (Location-scale case) Let  $\underline{\Psi},\overline{\Psi}: \mathbb{R}^{\mid S\mid}\to \mathbb{R}$ be real functions such that
\begin{equation*} 
supp(Y\mid \textbf{X}_S=\textbf{x}) = \big(\underline{\Psi} (\textbf{x}),\overline{\Psi}(\textbf{x})\big), \,\,\,\,\,\,\, \forall \textbf{x}\in supp(\textbf{X}_S).
\end{equation*}
If
\begin{equation}\tag{\ref{eq9987}}
\frac{Y - \underline{\Psi}(\textbf{X}_S)}{\overline{\Psi}(\textbf{X}_S) - \underline{\Psi}(\textbf{X}_S)}\not\indep \textbf{X}_S,
\end{equation}
then $S$ is not $\mathcal{F}_{LS}$-plausible. 
\end{itemize}
\end{customprop}


\begin{proof}\label{Proof of Support_proposition}
\textbf{First bullet-point: }
For a contradiction, let $S$ be  $\mathcal{F}_{A}$-plausible. Hence, $f\in\mathcal{F}_{A}$ exists such that 
\begin{equation}\label{eq74_additive}
f^{\leftarrow}(\textbf{X}_S, Y)\indep\textbf{ X}_S.
\end{equation}
Since $f\in\mathcal{F}_{A}$, we can write $f^{\leftarrow}(\textbf{x},y) = q\big(y - \mu(\textbf{x})\big)$  for some function $\mu(\cdot)$ and for some  distribution function $q(\cdot)$. Using this notation, (\ref{eq74_additive}) is equivalent to
\begin{equation} \label{eq989_additive}
Y - {\mu}(\textbf{X}_S)\indep \textbf{X}_S.
\end{equation}
Denote $W_{\textbf{x}}:= (Y\mid \textbf{X}_S=\textbf{x})$. From (\ref{eq989_additive}), we get that for all $\textbf{x},\textbf{y}$ in the support of $\textbf{X}_S$, it must hold that
\begin{equation}\label{eq7285_additive}
W_\textbf{x} - {\mu}(\textbf{x})\overset{D}{=}W_\textbf{y} - {\mu}(\textbf{y}).
\end{equation}
Hence, supports must also match, i.e., (\ref{eq7285_additive}) implies
\begin{align*}
\ \underline{\Psi} (\textbf{x}) - {\mu}(\textbf{x})&\overset{}{=} \underline{\Psi} (\textbf{y}) - {\mu}(\textbf{y}),
\end{align*}
for all $\textbf{x},\textbf{y}$ in the support of $\textbf{X}_S$. Solving for $\mu$  gives us 
\begin{align*}
{\mu}(\textbf{x})&\overset{}{=}c_1+ \underline{\Psi} (\textbf{x}) , 
\end{align*}
where $c_1 \in  \mathbb{R}$ is some constant. Plugging this into (\ref{eq989_additive}) gives us a contradiction with (\ref{eq9987_additive}). 

\textbf{Second bullet-point:} For a contradiction, let $S$ be  $\mathcal{F}_{LS}$-plausible. Hence, $f\in\mathcal{F}_{LS}$ exists such that 
\begin{equation}\label{eq74}
f^{\leftarrow}(\textbf{X}_S, Y)\indep\textbf{ X}_S.
\end{equation}
Since $f\in\mathcal{F}_{LS}$, we can write $f^{\leftarrow}(\textbf{x},y) = q\big(\frac{y - \mu(\textbf{x})}{\sigma(\textbf{x})}\big)$  for some functions $\mu(\cdot), \sigma(\cdot)>0$ and for some (continuous) distribution function $q(\cdot)$. Using this notation, (\ref{eq74}) is equivalent to
\begin{equation} \label{eq989}
\frac{Y - {\mu}(\textbf{X}_S)}{{\sigma}(\textbf{X}_S)}\indep \textbf{X}_S.
\end{equation}
Denote $W_{\textbf{x}}:= (Y\mid \textbf{X}_S=\textbf{x})$. From (\ref{eq989}), we get that for all $\textbf{x},\textbf{y}$ in the support of $\textbf{X}_S$, it must hold that
\begin{equation}\label{eq7285}
\frac{W_\textbf{x} - {\mu}(\textbf{x})}{{\sigma}(\textbf{x})}\overset{D}{=}\frac{W_\textbf{y} - {\mu}(\textbf{y})}{{\sigma}(\textbf{y})}.
\end{equation}
Hence, supports must also match, i.e., (\ref{eq7285}) implies
\begin{align*}
\frac{ \underline{\Psi} (\textbf{x}) - {\mu}(\textbf{x})}{{\sigma}(\textbf{x})}&\overset{}{=}\frac{ \underline{\Psi} (\textbf{y}) - {\mu}(\textbf{y})}{{\sigma}(\textbf{y})}, \,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,
\frac{ \overline{\Psi}(\textbf{x}) - {\mu}(\textbf{x})}{{\sigma}(\textbf{x})}\overset{}{=}\frac{ \overline{\Psi}(\textbf{y}) - {\mu}(\textbf{y})}{{\sigma}(\textbf{y})},
\end{align*}
for all $\textbf{x},\textbf{y}$ in the support of $\textbf{X}_S$. Solving for $\mu, \sigma$  gives us 
\begin{align*}
{\mu}(\textbf{x})&\overset{}{=}c_1+ \underline{\Psi} (\textbf{x}) , \,\,\,\,\,\,\,\,\,\,\,
\sigma(\textbf{x})\overset{}{=}c_2\cdot [\overline{\Psi} (\textbf{x})-\underline{\Psi}(\textbf{x})],
\end{align*}
where $c_1 \in  \mathbb{R}, c_2 \in \mathbb{R}_{+}$ are some constants. Plugging this into (\ref{eq989}) gives us a contradiction with (\ref{eq9987}). 
\end{proof}


\begin{customprop}{\ref{LemmaOLocationScaleinseparabilite}}
Let \((Y, \mathbf{X}) \in \mathbb{R} \times \mathbb{R}^p\) is continuous and satisfy \eqref{SCM_for_Y} with \(pa_Y \neq \emptyset\) and $\mathcal{F} = \mathcal{F}_{LS}$. Then,  $S\subsetneq pa_Y$ is not $\mathcal{F}_{LS}$-plausible if $\textbf{X}_{pa_Y}$ has independent components and $f_Y$  have the form $$f_Y(\textbf{x}, \varepsilon)=\mu(\textbf{x}) + \sigma(\textbf{x})\varepsilon, $$where $\theta(\textbf{x}) = \big(\mu(\textbf{x}), \sigma(\textbf{x})\big)^\top$ is additive in both components, that is,  
$\mu(\textbf{x}) = h_{1, \mu}(x_1)+\dots + h_{k, \mu}(x_k)$ and 
$\sigma(\textbf{x}) =h_{1, \sigma}(x_1)+\dots + h_{k, \sigma}(x_k)$ for some continuous non-constant non-zero functions $h_{i,\cdot}$, where we also assume $h_{i,\sigma}>0$, $i=1, \dots, k$.  
\end{customprop}
\begin{proof}
\label{Proof of LemmaOLocationScaleinseparabilite}
For a contradiction, consider that $S$ is $\mathcal{F}_{LS}$-plausible. Without loss of generality, let $S=\{1, \dots, s\}$ for $s<k=|pa_Y|$. Then, $g\in\mathcal{F}_{LS}$ exist such that  $g^{\leftarrow}\big(\textbf{X}_S, Y\big)\indep \textbf{X}_S$. Since $g\in\mathcal{F}_{LS}$, we can write $g(\textbf{x}_S, e) = \mu_g(\textbf{x}_S) + \sigma_g(\textbf{x}_S)q^{-1}(e)$ for some function $\theta_g=(\mu_g, \sigma_g)$ that is minimal almost surely and hence non-constant in neither of the arguments. Inverse of such a function is in the form $g^{\leftarrow}(\textbf{x}_S, e) = q(\frac{e - \mu_g(\textbf{x}_S)}{\sigma_g(\textbf{x}_S)})$. 

Hence, simply rewriting   
$$\textbf{X}_S\indep g^{\leftarrow}\big(\textbf{X}_S, Y\big)
= q\bigg(\frac{Y - \mu_g(\textbf{X}_S)}{\sigma_g(\textbf{X}_S)}\bigg),$$
and using \eqref{trivial_identity} and $Y = \mu(\textbf{X}_{pa_Y}) + \sigma(\textbf{X}_{pa_Y})\varepsilon_Y$ we get 
\begin{equation}\label{dfrgeTRI}
\textbf{X}_S\indep \frac{\mu(\textbf{X}_{pa_Y}) + \sigma(\textbf{X}_{pa_Y})\varepsilon_Y - \mu_g(\textbf{X}_S)}{\sigma_g(\textbf{X}_S)}. 
\end{equation}
Equation (\ref{dfrgeTRI}) can be equivalently rewritten into
\begin{equation}\label{erty}
\textbf{X}_S\indep f_1(\textbf{X}_S)  + f_2(\textbf{X}_S)h(\textbf{X}_{S^c}, \varepsilon_Y),
\end{equation}
where $ S^c=pa_Y\setminus S$, and 
$$f_1(\textbf{x}) =\frac{ h_{1, \mu}(x_1)+\dots + h_{s, \mu}(x_s)- \mu_g(\textbf{x})}{\sigma_g(\textbf{x})},\,\,\,\,\,\,\,\,\,\,f_2(\textbf{x}) =  \frac{ h_{1, \mu}(x_1)+\dots + h_{s, \mu}(x_s)}{\sigma_g(\textbf{x})},$$
$$
h(\textbf{x}, \varepsilon) = h_{s+1, \mu}(x_{s+1})+\dots + h_{k, \mu}(x_k) + [h_{s+1, \sigma}(x_{s+1})+\dots + h_{k, \sigma}(x_k)]\varepsilon.
$$
However, independence (\ref{erty}) is a contradiction with Lemma \ref{CoolLemma} part 4. 
\end{proof}


\begin{customprop}{\ref{LemmaOParetoinseparabilite}}
 Consider $(Y, \textbf{X})\in\mathbb{R}\times \mathbb{R}^p$ satisfying \eqref{SCM_for_Y} with  $pa_Y\neq \emptyset$ and $\mathcal{F} = \mathcal{F}_{F}$. where $F$ be a distribution function whose parameter acts multiplicatively. 
 Let $\textbf{X}_{pa_Y}$ be a continuous random vector with full support and independent components. 
\begin{itemize}
\item Consider $f_Y\in\mathcal{F}_F$ in the form $f_Y(\textbf{x}, \varepsilon)=F^{-1}\big(\varepsilon, \theta(\textbf{x})\big)$ with additive function $\theta(x_1, \dots, x_k) = h_1(x_1)+\dots + h_k(x_k)$, where $h_i$ are continuous non-constant real functions. Then, then every $S\subsetneq pa_Y$ is not $\mathcal{F}_{F}$-plausible. 
\item Consider $f_Y\in\mathcal{F}_F$ in the form $f_Y(\textbf{x}, \varepsilon)=F^{-1}\big(\varepsilon, \theta(\textbf{x})\big)$ with multiplicative function   $\theta(x_1, \dots, x_k) = h_1(\textbf{x}_S)\cdot h_2(\textbf{x}_{\{1, \dots, k\}\setminus S})$ for some $S\subsetneq \{1, \dots, k\}$, where $h_1, h_2$ are continuous non-constant non-zero real functions. Then, $S_{\mathcal{F}_F}(Y)=\emptyset$.
\end{itemize}
\end{customprop}
\begin{proof}\label{Proof of LemmaOParetoinseparabilite}
\textbf{The first bullet-point}: For a contradiction, consider that $S=\{1, \dots, s\}\subset \{1, \dots, k\}$ is $\mathcal{F}_{F}$-plausible. Then for almost all $z\in(0,1)$, there exist $g\in\mathcal{F}_F$ such that  $g^{\leftarrow}\big(\textbf{X}_S, f(\textbf{X}, z)\big)\indep \textbf{X}_S$. Since $g\in\mathcal{F}_F$, we can write $g^{\leftarrow}(\textbf{x}_S, \cdot) = F\big(\cdot, \theta_g(\textbf{x}_S)\big)$ for some non-constant function $\theta_g$. Hence, 
$$\textbf{X}_S\indep g^{\leftarrow}\big(\textbf{X}_S, f(\textbf{X}, z)\big)
= F[F^{-1}\big(z, \theta(\textbf{X})\big), \theta_g(\textbf{X}_S)]
= f_1[z, f_2\big(\theta_g(\textbf{X}_S)\big) \cdot\theta(\textbf{X})].$$ 
We use identity (\ref{trivial_identity}). Since $f_1$ is invertible, we obtain 
\begin{equation}\label{dfrge}
\textbf{X}_S\indep f_2\big(\theta_g(\textbf{X}_S)\big) \cdot\theta(\textbf{X}).
\end{equation}
Define $\tilde{\theta}_g(\textbf{X}_S):=f_2\big(\theta_g(\textbf{X}_S)\big)$. Finally, since $\theta(\textbf{X})$ is an additive function from the assumptions, (\ref{dfrge}) is equivalent to
$$
\tilde{\theta}_g(\textbf{X}_S)[h_1(X_1) + \dots + h_k(X_k)]\indep \textbf{X}_S. 
$$
However, that is a contradiction with Lemma \ref{CoolLemma} part 2. 

\textbf{The second bullet-point}:  
We show that $S$ is $\mathcal{F}_F$-plausible set by finding an appropriate function $g\in\mathcal{F}_F$ such that $g^{\leftarrow}\big(\textbf{X}_S, f_Y(\textbf{X}, \varepsilon_Y)\big)\indep \textbf{X}_S$. Since it must hold that  $g\in\mathcal{F}_F$, we write  $g^{\leftarrow}(\textbf{x}_S, \cdot) = F\big(\cdot, \theta_g(\textbf{x}_S)\big)$ for some $\theta_g$. 

Rewrite 
 $$g^{\leftarrow}\big(\textbf{X}_S, f(\textbf{X}, \varepsilon_Y)\big) = F[F^{-1}\big(\varepsilon_Y, \theta(\textbf{X})\big)     ,\theta_g(\textbf{X}_S)]
 = f_1[\varepsilon_Y, f_2\big(\theta_g(\textbf{X}_S)\big) \cdot\theta(\textbf{X})],$$
where $f_1, f_2$ are from (\ref{postMultiplDefinition}). 
We choose $\theta_g$ such that $f_2\big(\theta_g(\textbf{x}_S)\big) = \frac{1}{h_1(\textbf{x}_S)}$. Obviously, $g\in\mathcal{F}_F$. Then, by extending $\theta$ to its multiplicative form, we get 
$$ f_1[\varepsilon_Y, f_2\big(\theta_g(\textbf{X}_S)\big) \cdot\theta(\textbf{X})] =  f_1[\varepsilon_Y,  h_2(\textbf{X}_{\{1, \dots, k\}\setminus S})]\indep \textbf{X}_S.$$
Together, we found $g\in\mathcal{F}_F$ defined by $g^{\leftarrow}(\textbf{x}_S, \cdot) = F\big(\cdot, f_2^{-1}(\frac{1}{h_1(\textbf{x}_S)})\big)$ that satisfy   $g^{\leftarrow}\big(\textbf{X}_S, f(\textbf{X}, \varepsilon_Y)\big)\indep \textbf{X}_S$. Hence, $S$ is $\mathcal{F}_F$-plausible. The analogous argument can be given for the set $\{1, \dots, k\}\setminus S$. Hence,  $S_{\mathcal{F}_F}(Y)\subseteq S\cap( \{1, \dots, k\}\setminus S) = \emptyset$.
\end{proof}




\begin{customthm}{\ref{Theorem_in_section2}}
Let \((Y, \mathbf{X}) \in \mathbb{R} \times \mathbb{R}^p\) be a continuous random vector that satisfy \eqref{SCM_for_Y}. Suppose  \(\mathcal{F} = \mathcal{F}_A\) and consider a non-empty set \(S \subsetneq pa_Y\). 

\begin{itemize}
 \item (Independent case) Assume that \(\mathbf{X}_{pa_Y}\) has independent components and \(f_Y\) is an injective function. Then, the set \(S\) is \(\mathcal{F}_A\)-plausible if and only if \(f_Y\) can be decomposed as follows:  
    \begin{equation}\tag{\ref{decomposition_condition_independent}}
        f_Y(\mathbf{x}, e) = h_1(\mathbf{x}_S) + h_2(\mathbf{x}_{pa_Y \setminus S}) + q^{-1}(e), \quad\quad \forall
        \mathbf{x} \in \mathbb{R}^{|pa_Y|}, \, e \in (0, 1),
    \end{equation}
    where \(h_1, h_2\) are measurable functions, \(q^{-1}\) is a quantile function, and \(pa_Y \setminus S = \{i \in pa_Y : i \not\in S\}\). 


    \item (General case) The set \(S\) is \(\mathcal{F}_A\)-plausible if and only if the function \(f_Y\) can be expressed as:
    \begin{equation}\tag{\ref{decomposition_condition}}
        f_Y(\mathbf{x}, e) = h_1(\mathbf{x}_S) + h_2(\mathbf{x}) + q^{-1}(e), \quad\quad \forall
        \mathbf{x} \in \mathbb{R}^{|pa_Y|}, \, e \in (0, 1),
    \end{equation}
    for some measurable function \(h_1\), quantile function \(q^{-1}\), and a function \(h_2\) such that 
    \[
    h_2 \in \mathcal{H}_{\mathbf{X}_{pa_Y}}(S) := \{f : \mathbb{R}^{|pa_Y|} \to \mathbb{R} \mid f(\mathbf{X}_{pa_Y}) \indep \mathbf{X}_S\}.
    \]


    \item As a consequence, \(S_{\mathcal{F}_A}(Y) = pa_Y\) if and only if:  
    \begin{enumerate}
        \item \(f_Y\) cannot be expressed in the form of \eqref{decomposition_condition} for any \(S \subsetneq pa_Y\), and  
        \item every set \(S\) that is neither a subset nor a superset of \(pa_Y\) (i.e., \(pa_Y \not\subseteq S \not\subseteq pa_Y\)) is not \(\mathcal{F}_A\)-plausible (e.g., under the assumptions of Proposition~\ref{TheoremFidentifiabilityWithChild}).  
    \end{enumerate}
\end{itemize}
\end{customthm}
 

\begin{proof}
\label{Proof of Theorem_in_section2}


    \textbf{The second bullet-point}:   ''$\impliedby$'' if $f_Y$ has a form \eqref{decomposition_condition}, then \( S \) is an \( \mathcal{F}_A \)-plausible set since we can find \( f \in \mathcal{F}_A \) such that $f^{\leftarrow}(X_S, Y) \indep X_S$. Such a choice is $f(\textbf{x}_S, e) = h_1(\textbf{x}_s) + q^{-1}(e)$, since $Y - f(\textbf{X}_S, \varepsilon_Y) =h_1(\textbf{X}_S)+  h_2(\textbf{X}_{pa_Y}) + q^{-1}(\varepsilon_Y) - h_1(\textbf{X}_S) - q^{-1}(\varepsilon_Y) =  h_2(\textbf{X}_{pa_Y})\indep \textbf{X}_S$. 
    
    ''$\implies$'':  Assume that \( S \) is an \( \mathcal{F}_A \)-plausible set; hence there exists \( f \in \mathcal{F}_A \) such that $f^{\leftarrow}(\textbf{X}_S, Y) \indep \textbf{X}_S$. We use the following notation: \( f(\textbf{x}, e) = \mu(\textbf{x}) + \tilde{q}^{-1}(e) \) for \( \textbf{x} \in \mathbb{R}^{|S|} \) and \( e \in (0,1) \), where \( \mu \) is some function and \( \tilde{q}^{-1} \) is a quantile function. Additive functions have an inverse in the form \( f^{\leftarrow}(x, y) = \tilde{q}(y - \mu(x)) \) for \( x \in \mathbb{R}^{|S|} \) and \( y \in \mathbb{R} \) (see the discussion in Appendix~\ref{Appendix_A.1.}). Notice that due to an assumption of continuity of $(Y, \textbf{X})$, $ \tilde{q}^{-1}$ must be injective on the support of $Y$ and we can use identity the \eqref{trivial_identity}. We therefore have:
\begin{equation*}
    \begin{split}
\text{S is } \mathcal{F}_A\text{-plausible}& \iff f^{\leftarrow}(\textbf{X}_S, Y) \indep\textbf{ X}_S \iff Y - \mu(\textbf{X}_S) \indep \textbf{X}_S \\&
\iff    f_0(\textbf{X}_{pa_Y}) + q^{-1}(\varepsilon_Y) - \mu(\textbf{X}_S) \indep\textbf{ X}_S        
\\&
\iff    f_0(\textbf{X}_{pa_Y})  - \mu(\textbf{X}_S) \indep\textbf{ X}_S,        
    \end{split}
\end{equation*}
where we used a notation \( Y = f_0(X_1, X_2) + q^{-1}(\varepsilon_Y) \), where \( \varepsilon_Y \indep \textbf{X}_{pa_Y} \). Therefore,  we directly obtain $f_0(x_1, x_2) - \mu(x_1)\in \mathcal{H}_{\textbf{X}}(S) $. Defining $h_1 = \mu, h_2 = f_0 - \mu$ we obtain precisely \eqref{decomposition_condition}.






    \textbf{The first bullet-point}:  ''$\impliedby$'' if $f_Y$ has a form \eqref{decomposition_condition_independent}, then \( S \) is an \( \mathcal{F}_A \)-plausible set since for $f(\textbf{x}_S, e) = h_1(\textbf{x}_S) + q^{-1}(e)$ trivially holds  $f^{\leftarrow}(\textbf{X}_S, Y)\indep \textbf{X}_S$. 
    
    ''$\implies$'':  Consider that $S$ is an  $\mathcal{F}_A$-plausible set; hence there exists \( f \in \mathcal{F}_A \) such that $f^{\leftarrow}(\textbf{X}_S, Y) \indep \textbf{X}_S$.  Let us write $$Y = f_0(X_1, \dots, X_{|pa_Y|}) + q^{-1}(\varepsilon_Y), \,\,\,\,\,\,\,\,\varepsilon_Y\indep \textbf{X}_{pa_Y},$$ for some injective function $f_0$ and injective quantile function $q^{-1}$, and let us write $$f(\textbf{x}, e) = \mu(\textbf{x}) + \tilde{q}^{-1}(e), \,\,\textbf{x}\in\mathbb{R}^{|S|}, e\in (0,1),$$ for some measurable function $\mu$ and quantile function $\tilde{q}^{-1}$. Additive functions have an inverse in a form $f^{\leftarrow}(\textbf{x}, y) = \tilde{q}\big(y-\mu(\textbf{x})\big),\,\,\textbf{x}\in\mathbb{R}^{|S|}, y\in\mathbb{R}$ (see discussion in Appendix~\ref{Appendix_A.1.}).   Using Definition~\ref{Definition1} and identity \eqref{trivial_identity}, we have $Y- \mu(\textbf{X}_S)\indep \textbf{X}_S$. 

Hence, we have
\begin{align*}
    Y- \mu(\textbf{X}_S)&\indep \textbf{X}_S 
    \\ f_0(X_1, \dots, X_{|pa_Y|}) + q^{-1}(\varepsilon_Y) - \mu(\textbf{X}_S) &\indep \textbf{X}_S 
    \\f_0(X_1, \dots, X_{|pa_Y|}) - \mu(\textbf{X}_S) &\indep \textbf{X}_S. 
\end{align*}
Lemma \ref{CoolLemma} part 1 (in particular, the negation of that statement) directly shows that this implies the form~\eqref{decomposition_condition_independent}.  

\textbf{The third bullet point} follows directly from Proposition~\ref{TheoremFidentifiabilityWithChild} and the previous bullet point. Specifically, \(S_{\mathcal{F}}(Y) = pa_Y \iff\) every set \(S\) with \(S \not\supseteq pa_Y\) is not \(\mathcal{F}\)-plausible. This is equivalent to stating that any set \(S\) such that either \(S \subsetneq pa_Y\) or \(pa_Y \not\subseteq S \not\supseteq pa_Y\) is not \(\mathcal{F}\)-plausible. The case \(S \subsetneq pa_Y\) follows from the first assumption, while \(pa_Y \not\subseteq S \not\supseteq pa_Y\) follows from the second.
\end{proof}





\begin{customthm}{\ref{theorem_consistency_ISD}}
Let $(Y, \mathbf{X})$ satisfy \eqref{SCM_for_Y} with $pa_Y \neq \emptyset$.  Assume that the estimator $\hat{S}_{\mathcal{F}}(Y)$ is constructed as described above, using $\hat{f}_{pa_Y} = f_Y$ and valid tests $H_{0, S}^I, H_{0, S}^S, H_{0, S}^D$  for all $S\subseteq \{1, \dots, p\}$ at level $\alpha$ in a sense that for all $S$, $\sup_{P: H_{0, S}^\cdot \text{is true}}P(H_{0, S}^\cdot \text{ is rejected})\leq \alpha$ for all $\cdot \in \{S, I, D\}$. Then
\begin{equation}\label{Theorem2_3alpha}
    P(\hat{S}_{\mathcal{F}}(Y) \subseteq pa_Y) \geq 1-3\alpha. 
\end{equation}

Furthermore, suppose ${S}_{\mathcal{F}}(Y) = pa_Y$, and assume that all tests have non-zero power, i.e., $lim_{n\to\infty}P(H_{0, S}^\cdot \text{ is rejected}\mid  H_{0, S}^\cdot \text{ is false})=1$ for all $\cdot \in \{S, I, D\}$ and all $S\not\supseteq pa_Y$. Then, there exists an integer $n_0$ such that for all $n \geq n_0$, it holds that
\begin{equation}\label{Theorem2_3alpha_eq2}
    P(\hat{S}_{\mathcal{F}}(Y) = pa_Y) \geq 1-3\alpha. 
\end{equation}
\end{customthm}
\begin{proof}
\label{Proof of theorem_consistency_ISD}
\eqref{Theorem2_3alpha} follows directly from the following computations:
\begin{align*}
    & P(\hat{S}_{\mathcal{F}}(Y) \subseteq pa_Y) \geq  P(H_{0, pa_Y}(\mathcal{F}) \text{ is not rejected}) =  P(H_{0, pa_Y}^I, H_{0, pa_Y}^S, H_{0, pa_Y}^D \text{ are not rejected})\\& \geq \prod_{\cdot \in \{I, S, D\} } P(H_{0, pa_Y}^\cdot\text{ is not rejected}) \geq (1-\alpha)^3 > 1-3\alpha \,\,\,\,\,\,\,\,for\,\,\alpha\in(0,1). 
\end{align*} 
As for \eqref{Theorem2_3alpha_eq2}, note that the identifiability of the parents  ${S}_{\mathcal{F}}(Y) =pa_Y$ implies that for any $S\not\supseteq pa_Y$, and any function $\hat{f}_S$, either $\hat{f}_S\not\in\mathcal{F}$, or $\hat{\varepsilon}_S \not\indep \textbf{X}_S$, or $\hat{\varepsilon}_S \not\sim U(0,1)$. In other words, either $H_{0,S}^S$, $H_{0, S}^I$ or $H_{0, S}^D$ is not true. Therefore, there exist $n_0$ such that  $H_{0, S}^\cdot$ will be rejected with large probability, where $\cdot \in \{I, S, D\}$ correspond to the non-true hypothesis. Therefore, 
\begin{align*}
        &\lim_{n\to\infty}P(\hat{S}_{\mathcal{F}}(Y) \neq pa_Y) \leq \lim_{n\to\infty}P(H_{0, pa_Y}(\mathcal{F}) \text{ is rejected, or }\exists S \not\supseteq pa_Y: H_{0, S}(\mathcal{F}) \text{ is not rejected})\\&
        \leq  1-(1-\alpha)^3 +    \lim_{n\to\infty} P(\exists S \not\supseteq pa_Y: H_{0, S}(\mathcal{F}) \text{ is not rejected})
        \\& =   1-(1-\alpha)^3 +    \lim_{n\to\infty} P(\exists S \not\supseteq pa_Y: H_{0, S}^I, H_{0, S}^S, H_{0, S}^D \text{ are not rejected})\\&
\leq 1-(1-\alpha)^3  +  \lim_{n\to\infty} P(\exists S \not\supseteq pa_Y: H_{0, S}^\cdot \text{ is not rejected}\mid  H_{0, S}^\cdot \text{ is false})\\&= 1-(1-\alpha)^3 + 0 <3\alpha.      
\end{align*}
\end{proof}





\begin{customlem}{\ref{lemma_hidden_confounder}}
 Consider $(Y, \textbf{X})\in\mathbb{R}\times \mathbb{R}^p$  satisfy \eqref{SCM_for_Y} with  $\mathcal{F} = \mathcal{F}_A$. Consider $\emptyset\neq hid\subset pa_Y$. Let $S\subseteq pa_Y \cap obs$ and $\tilde{S}:=(pa_Y\cap obs)\setminus S$ such that
 $(\textbf{X}^{hid}, \textbf{X}_S)\indep \textbf{X}_{\tilde{S}}$ (one can consider that $\textbf{X}^{hid}$ cause $\textbf{X}_S$ and $Y$, but not $\textbf{X}_{\tilde{S}}$). 
 
 If $f_Y$ has a form \begin{equation*}
        f_Y(\textbf{x}, e) = h_1(\textbf{X}^{hid}, \textbf{X}_S) + h_2(\textbf{X}_{\tilde{S}}) + q^{-1}(e), \,\,\,\,\,\textbf{x}\in\mathbb{R}^{|pa_Y|}, e\in(0,1),
     \end{equation*}
for some continuous non-constant real functions  $h_1, h_2$ and a quantile function $q^{-1}$. Then, $S_{\mathcal{F}_A}(Y) \subseteq \tilde{S}\subset pa_Y$.
\end{customlem}
\begin{proof}
\label{Proof of lemma_hidden_confounder}
The set $\tilde{S}$ is $\mathcal{F}_A$-plausible since  $Y - h_2(\textbf{X}_{\tilde{S}}) =h_1(\textbf{X}^{hid}, \textbf{X}_S) + q^{-1}(\varepsilon_Y)  \indep \textbf{X}_{\tilde{S}}$. Therefore $S_{\mathcal{F}_A}(Y)\subseteq\tilde{S}$. 
\end{proof} 

\begin{customprop}{\ref{Proposition_consistency}}
Consider $\mathcal{F} = \mathcal{F}_A$ and 
let $(Y, \textbf{X})\in\mathbb{R}\times \mathbb{R}^p$ follow an SCM with DAG $\mathcal{G}_0$ satisfying \eqref{SCM_for_Y}. Assume that every $S \neq pa_Y$ is not $\mathcal{F}$-plausible. 
Then,   

\begin{equation}
  \lim_{n\to\infty} \mathbb{P}(\widehat{pa}_Y  \neq pa_Y) = 0,
\end{equation}   
where $n$ is the size of the random sample and $\widehat{pa}_Y$ is our score-based estimate from Section~\ref{Section_algorithm2} with $\lambda_1, \lambda_2>0, \lambda_3 = 0$, suitable estimation procedure, and HSIC independence measure. 
\end{customprop}
\begin{proof}
\label{Proof of Proposition_consistency}
This result is a simple consequence of Theorem 20 in \cite{reviewANMMooij}. We use the same notation. For a rigorous definition of $HSIC$ and $\widehat{HSIC}$, see Appendix A.1 in \cite{reviewANMMooij}. 



We show that $score(S)> score(pa_Y)$ as $n\to\infty$ for any $S\neq pa_Y$. 
The $score(S)$ is defined as the weighted sum of  \textit{Independence} and \textit{Significance} terms. Let us first concentrate on the former. By definition, we write $\textit{Independence} = -\widehat{HSIC}(\textbf{X}_S, \hat{\varepsilon}_S)$. On a population level, it holds (Lemma~12 in \cite{reviewANMMooij}) that  ${HSIC}(\textbf{X}_S, {\varepsilon}_S) > 0 $ and ${HSIC}(\textbf{X}_{pa_Y}, {\varepsilon}_{pa_Y}) = 0$, since $\textbf{X}_S$ and ${\varepsilon}_S$ are not independent (because $S$ is not $\mathcal{F}$-plausible) and  $\textbf{X}_{pa_Y}$ and ${\varepsilon}_{pa_Y}$ are independent (by definition of the SCM). 
By Theorem~20 in \cite{reviewANMMooij}, we obtain $\widehat{HSIC}(\textbf{X}_{pa_Y}, \hat{\varepsilon}_{pa_Y})\to {HSIC}(\textbf{X}_{pa_Y}, {\varepsilon}_{pa_Y})=0$ and $\widehat{HSIC}(\textbf{X}_{S}, \hat{\varepsilon}_{S})\to {HSIC}(\textbf{X}_{S}, {\varepsilon}_{S})>0$, as $n\to\infty$. Therefore, the independence term is strictly smaller (for some large $n$) for $S$ than for $pa_Y$. 

Let us focus on \textit{Significance} term (We work with the \textit{Significance} term somewhat vaguely in this proof. However, we only need $Significance\to 0$ as $n\to\infty$ for $pa_Y$, which is satisfied for any reasonable method of assessing significance of covariates.). Since all $\textbf{X}_{pa_Y}$ are significant (otherwise $f_Y\notin\mathcal{I}_m$) we get that $Significance\to 0$ as $n\to\infty$ for $pa_Y$. Moreover, by definition, always $Significance\geq 0$.

Together, we find that $score(pa_Y)>score(S)$ for large $n$, since 
the \textit{Independence} term is strictly smaller (for large $n$) for $S$ than for $pa_Y$ and \textit{Significance} term converges to $0$ for $pa_Y$ and is non-negative.  
We showed that $pa_Y$ has the largest score among all $S\subseteq \{1, \dots, p\}$ (again, for $n$ large enough). 
\end{proof}

