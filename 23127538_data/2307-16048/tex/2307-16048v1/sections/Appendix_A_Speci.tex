\section{Appendix} \label{Speci_appendix}

\subsection{Class of invertible functions, invertible causal model, and causal minimality}
\label{Appendix_A.1.}

First, let us formally introduce a class of measurable functions $\mathcal{I}_m$ and a subclass of SCM called invertible causal models.

\begin{definition}\label{I}
Let $\mathcal{X}_x\subseteq\mathbb{R}^{p},\mathcal{X}_y\subseteq\mathbb{R}, \mathcal{X}_z\subseteq\mathbb{R}$ be measurable sets. A measurable function $f:\mathcal{X}_x\times\mathcal{X}_y\to \mathcal{X}_z$  is called \textbf{invertible for the last element}, notation $f\in \mathcal{I}$, if there exists a function $f^{\leftarrow}:\mathcal{X}_x\times\mathcal{X}_z\to \mathcal{X}_y$ that fulfills the following: $\forall \textbf{x}\in\mathcal{X}_x, \forall y\in\mathcal{X}_y,z\in\mathcal{X}_z$ such that $y=f(\textbf{x},z)$, then $z=f^{\leftarrow}(\textbf{x},y)$. Moreover, denote 
$$
\mathcal{I}_{m} = \{f\in\mathcal{I} : \text{ f is not constant in any of its arguments} \}.
$$
We define the \textbf{ICM} (invertible causal model) as a SCM (\ref{definition_general_SCM}) with structural equations satisfying $f_i\in\mathcal{I}_{m}$ for all $i=0, \dots, p$.  
\end{definition}
The previous definition indicates that the element $z$ in a relationship $y=f(\textbf{x},z)$ can be uniquely recovered from $(\textbf{x},y)$. To provide an example, for the function $f(x,z) = x+z$, it holds that $f^{\leftarrow}(x, y) = y-x$, since $f^{\leftarrow}(x, f(x,z)) = f(x,z) - x = z$. More generally, for the additive function defined as $f(\textbf{x},z) = g_1(\textbf{x})+ g_2(z)$, where $g_2$ is invertible, it holds that $f^{\leftarrow}(\textbf{x}, y) = g_2^{-1}(y - g_1(\textbf{x}))$, $\textbf{x}\in\mathbb{R}^d, y, z\in \mathbb{R}$. Overall, if $f$ is differentiable and the partial derivative of $f(\textbf{x},z)$ with respect to $z$ is monotonic, then $f\in\mathcal{I}$ (follows from inverse function theorem; \cite{Inverse_function_theorem}). 
Note that $f_i\in\mathcal{I}_{m}$ implies causal minimality of the ICM model, as the following lemma suggests. 

\begin{lemma}\label{Lemma_about_ICM_minimality}
Consider a distribution generated by \hyperref[I]{ICM} with graph $\mathcal{G}_0$ (see Definition  \ref{I}). Let all structural equations $f_j\in\mathcal{I}_{m}$, $\forall j=0, \dots, p$.  Then, the distribution is causally minimal with respect to  $\mathcal{G}_0$. Conversely, if $f_j\in\mathcal{I}\setminus\mathcal{I}_{m}$ for some $j\in\{0, \dots, p\}$, then the causal minimality is violated. 
\end{lemma}
\begin{proof}
The second claim follows directly from Proposition 4 in \cite{Peters2014}. For the first claim, we use a similar approach as in Proposition 17 from \cite{Peters2014}. 

Let $f_j\in\mathcal{I}_{m}$ for all $j=0, \dots, p$ and let the causal minimality be violated, i.e., let $\tilde{\mathcal{G}}$ be a subgraph of $\mathcal{G}_0$ such that the distribution is Markov wrt $\tilde{\mathcal{G}}$. Find $i,j\in\mathcal{G}_0$ such that $i\to j$ in $\mathcal{G}_0$ but $i\not\to j$ in $\tilde{\mathcal{G}}$. 

In graph $\mathcal{G}_0$ we have a structural equation  $X_j = f_j(\textbf{X}_{pa_j(\mathcal{G}_0)}, \varepsilon_j) = f_j(X_i, \textbf{X}_{pa_j(\mathcal{G}_0)\setminus\{i\}}, \varepsilon_j)$  but in $\tilde{\mathcal{G}}$ we have $X_j = \tilde{f}_j(\textbf{X}_{pa_j(\mathcal{G}_0)\setminus\{i\}}, \varepsilon_j)$. Hence, functions $f_j(X_i, \textbf{X}_{pa_j(\mathcal{G}_0)\setminus\{i\}}, \varepsilon_j)$ and $\tilde{f}_j( \textbf{X}_{pa_j(\mathcal{G}_0)\setminus\{i\}}, \varepsilon_j)$ have to be equal when we condition on $(X_i,\textbf{X}_{pa_j(\mathcal{G}_0)\setminus\{i\}})=(x_i,\textbf{x})$. Then, in order for functions $f_j(x_i, \textbf{x}, \varepsilon_j)$ and $\tilde{f}_j(\textbf{x},\varepsilon_j)$ to be equal (stressing out that $\varepsilon_j\indep \textbf{X}_{pa_j}$), $f_j$ cannot depend on its first argument. This contradicts $f\in\mathcal{I}_{m}$. 
\end{proof}

\subsection{Pairwise identifiability}
\label{Appendix_pairwise_identifiability}

In the following, we define the concept of pairwise identifiability of an $\mathcal{F}$-model. 

\begin{definition}
Let $(X_0, \textbf{X})\in\mathbb{R}\times \mathbb{R}^p$ follow a SCM (\ref{definition_general_SCM}) with DAG $\mathcal{G}_0$. Let $\mathcal{F}$ be a subset of all measurable functions. We say that the  $\mathcal{F}$-model is \textbf{identifiable}, if there does not exist a graph $\mathcal{G}'\neq \mathcal{G}_0$ and functions $f_i'\in\mathcal{F}, i=0, \dots, p$ generating the same joint distribution. 

We say that the $\mathcal{F}$-model is \textbf{pairwise identifiable}, if for all $i,j\in\mathcal{G}_0, i\in pa_j$ hold the following: $\forall S\subseteq V$ such that  $pa_j\setminus \{i\}\subseteq S \subseteq nd_j\setminus\{i,j\}$ there exist $\textbf{x}_{S}: p_S(\textbf{x}_S)>0$ satisfying that a bivariate model defined as $Z_1=\tilde{\varepsilon}_1, Z_2 = \tilde{f}(Z_1, {\varepsilon}_j)$ is identifiable, where $P_{\tilde{\varepsilon}_1} = P_{X_i\mid \textbf{X}_{S} =\textbf{ x}_S}$, $\tilde{f}(x, \varepsilon) = f(\textbf{x}_{pa_j\setminus\{i\}}, x, \varepsilon)$, $\tilde{\varepsilon}_1\indep {\varepsilon_j}$.  
\end{definition}

A similar notion was mentioned in the concept of additive noise models \citep[Definition 27]{Peters2014}. Here, we assume an arbitrary $\mathcal{F}$-model. In the bivariate case, the notion of identifiability and pairwise identifiability trivially coincides. Note the following observation. 

\begin{lemma}
Pairwise identifiable $\mathcal{F}$-model is identifiable.  
\end{lemma}

 \begin{proof}
 \label{Proof of thmMultivairateIdentifiability}
For a contradiction, let there be two $\mathcal{F}$-models with causal graphs $\mathcal{G}\neq \mathcal{G}'$ that both generate the same joint distribution $P_{(X_0, \textbf{X})}$.   Using Proposition 29 in \cite{Peters2014}, variables $L,K\in \{X_0, \dots, X_p\}$ exist, such that 
\begin{itemize}
\item $K\to L$ in $\mathcal{G}$ and $L\to K$ in $\mathcal{G}'$,
\item $S:=\underbrace{\big\{pa_L(\mathcal{G})\setminus\{K\}\big\}}_\text{\textbf{Q}}\cup\underbrace{\big\{pa_K(\mathcal{G}')\setminus\{L\}\big\}}_\text{\textbf{R}}\subseteq \big\{nd_L(\mathcal{G}) \cap nd_K(\mathcal{G}')\setminus\{K,L\}\big\} $. 
\end{itemize}
For this $S$, choose $x_S$ according to the condition in the definition of pairwise identifiability. We use the notation $x_S=(x_q, x_r)$, where $q\in \textbf{Q}, r\in \textbf{R}$, and we define $K^\star := K\mid \{X_S=x_S\}$ and $L^\star := L\mid \{X_S=x_S\}$.  Now we use Lemma 36 and Lemma 37 from \cite{Peters2014}.  Since $K\to L$ in $\mathcal{G}$, we get $$K^\star=\tilde{\varepsilon}_{K^\star},\,\,\,\,\,\,\,\,\,\, L^\star = f_{L^\star}(K^\star, \varepsilon_L),$$ 
where $\tilde{\varepsilon}_{K^\star} = K\mid \{X_S=x_S\}$ and $\varepsilon_L\indep K^\star$. We obtained a bivariate $\mathcal{F}$-model with $K^\star\to L^\star$. However, the same holds for the other direction; from $L\to K$ in $\mathcal{G}'$, we get $$L^\star=\tilde{\varepsilon}_{L^\star},\,\,\,\,\,\,\,\,\,\, K^\star = f_{K^\star}(L^\star, \varepsilon_K),$$ 
 where $\tilde{\varepsilon}_{L^\star} =L\mid \{X_S=x_S\}$ and $\varepsilon_K\indep L^\star$. We obtained a bivariate $\mathcal{F}$-model with $L^\star\to K^\star$, which is a contradiction. 
 \end{proof}
 

\subsection{Post-additive/post-multiplicative/location-scale distributions}
\label{Appendix_location_scale_definition}
Consider a distribution function $F$ with $q\in\mathbb{N}$ parameters $\theta = (\theta_1, \dots, \theta_q)^\top$. 


\begin{definition}\label{DefLS}
Let $F$ be a distribution function with one ($q=1$) parameter $\theta$. We say that the \textbf{parameter acts post-additively} in $F$, if an invertible real function $f_2$ and a function $f_1\in\mathcal{I}_m$ exist such that for all $\theta_1, \theta_2$ holds \footnote{Notation $F_{\theta_1}\big(F^{-1}_{\theta_2}(z)\big)$ is equivalent to $F(F^{-1}(z, \theta_2), \theta_1)$. We believe that this improves the readability.  } 
\begin{equation}\label{postAdditiveDefinition}
F_{\theta_1}\big(F^{-1}_{\theta_2}(z)\big) = f_1\big(z, f_2(\theta_1) + \theta_2\big), \,\,\,\forall z\in(0,1). 
\end{equation}

We say that the \textbf{parameter acts post-multiplicatively} in $F$ if an invertible real function $f_2$ and a function $f_1\in\mathcal{I}_m$ exist such that for all $\theta_1, \theta_2$ holds  \begin{equation}\label{postMultiplDefinition}
F_{\theta_1}\big(F^{-1}_{\theta_2}(z)\big) = f_1\big(z, f_2(\theta_1) \cdot\theta_2\big), \,\,\,\forall z\in(0,1).
\end{equation}

Let $F$ be a distribution function with two ($q=2$) parameters $\theta = (\mu, \sigma)^\top\in\mathbb{R}\times \mathbb{R}_+$. We say that $F$ is a \textbf{Location-Scale} distribution, if for all $\theta$ holds  
\begin{equation*}
F_{\theta}\left( \frac{x-\mu}{\sigma}\right) = F_{\theta_0}(x),\,\,\,\,\forall x\in\mathbb{R},
\end{equation*} 
where $F_{\theta_0}$ is called standard distribution and corresponds to a parameter $\theta_0 = (0,1)^\top$.  
\end{definition}
Examples of $F$ whose parameter acts post-additively include a Gaussian distribution with fixed variance or a Logistic distribution/Gumbel distribution with fixed scales.  Note that typically, $f_2(x) = -x$,  since $F_{\theta_1}\big(F^{-1}_{\theta_1}(z)\big)=z$ needs to hold.

Examples of $F$ whose parameter acts post-multiplicatively include a Gaussian distribution with the fixed expectation or a Pareto distribution (where $F_{\theta_1}\big(F^{-1}_{\theta_2}(z)\big) = z^{\frac{\theta_1}{\theta_2}}= f_1\big(z, f_2(\theta_1) \cdot\theta_2\big)$ for $f_1(z,x) = z^{-1/x}$ and $f_2(x)=-1/x$). Functions $ f_1, f_2$ are not necessarily uniquely defined. 

Examples of Location-Scale types of distributions include Gaussian distribution, logistic distribution, or Cauchy distribution, among many others.














