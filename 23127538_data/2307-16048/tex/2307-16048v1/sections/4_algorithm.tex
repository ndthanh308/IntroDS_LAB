\section{Estimation}
\label{section_algorithm}

In this section, we introduce two algorithms for estimating the set of direct causes of a target variable. One is based on estimating $S_{\mathcal{F}}(Y)$, and the second is a score-based algorithm that finds the best-fitting set for $pa_Y$. 

We consider a random sample of size $n\in\mathbb{N}$ from $(Y, \textbf{X})\in\mathbb{R}\times\mathbb{R}^p$, where $Y$ is the target variable, $\textbf{X}$ are the covariates, and $\mathcal{F}\subseteq\mathcal{I}_{m}$. 

\subsection{ISD algorithm for estimating $S_{\mathcal{F}}(Y)$ }
\label{ISD}
To determine the $\mathcal{F}$-plausibility of a non-empty set $S\subseteq \{1, \dots, p\}$, we follow the procedure below: First,
\begin{equation}\label{equation_SID}
    \text{estimate }\,\hat{\varepsilon}_S = \hat{f}^\leftarrow(Y, \textbf{X}_S) \text{ under constraint }\,\hat{f}\in\mathcal{F}.
\end{equation}
Then, answer the following questions:
\begin{enumerate}
    \item (\textbf{I}ndependence) Is $\hat{\varepsilon}_S \indep \textbf{X}_S$? 
    \item (\textbf{S}ignificance) Is every $X_i$ significant, $i\in S$? 
    \item (\textbf{D}istribution) Is $\hat{\varepsilon}_S \sim U(0,1)$? 

\end{enumerate}

We conclude that $S$ is $\mathcal{F}$-plausible if and only if all questions 1,2, and 3 have positive answers. Finally, we 
$$
\text{ define }\hat{S}_{\mathcal{F}}(Y) \text{ as an intersection of all sets that we marked as } \mathcal{F}\text{-plausible}.
$$
Estimating (\ref{equation_SID}) is a classical problem in machine learning. 
\begin{itemize}
    \item If $\mathcal{F}=\mathcal{F}_L$, we can use linear regression; regress $Y$ on $\textbf{X}_S$ in a linear model $Y = \beta_S\textbf{X}_S + \eta$ and output the residuals $\hat{\eta}:= Y - \hat{\beta}_S\textbf{X}_S$.  Possibly, re-scale the residuals $\hat{\varepsilon} := \hat{q}(\hat{\eta})$, where $\hat{q}$ is the empirical distribution function of $\hat{\eta}$. See the discussion about question 3 below. 
    \item If $\mathcal{F} = \mathcal{F}_A$, then we can apply random forest, neural networks, GAM, or other classical methods \citep{ho1995randomforest, GAM, ripley_1996}. Using one of these methods, we estimate the conditional mean $\hat{\mu}$ and output the residuals $\hat{\eta}:=Y -\hat{\mu}(\textbf{X}_S)$. Possibly, re-scale the residuals $\hat{\varepsilon} := \hat{q}(\hat{\eta})$.
    \item If  $\mathcal{F} = \mathcal{F}_{LS}$, we can apply GAMLSS  \citep{GAMLSS}, neural networks, or similar methods \citep{immer2022identifiability} to estimate the conditional mean and variance $\hat{\mu}, \hat{\sigma}$ and output $ \hat{\eta}:=\frac{Y -\hat{\mu}(\textbf{X}_S)}{\hat{\sigma}(\textbf{X}_S)}$. Possibly, re-scale $\hat{\varepsilon} := \hat{q}(\hat{\eta})$.
    \item If  $\mathcal{F} = \mathcal{F}_F$ for some distribution function $F$, we can use GAMLSS or GAM algorithms for estimating $\theta$ (the method depends on $F$. Often, we can also apply random forest). Then, we define $\hat{\varepsilon}:=F\big(Y, \hat{\theta}(\textbf{X}_S)\big)$.
\end{itemize}

For the test of independence (question 1), we can use a kernel-based HSIC test \citep{Kernel_based_tests} or a copula-based test \citep{copula_based_independence_test}. 

The assessment of significance (question 2) corresponds to the chosen regression method. Especially in the case of linear regression, we test if $\beta_i\neq0$ for every $i\in S$. For GAM or GAMLSS, we analogously use the corresponding p-values. If we use random forest, we can use a permutation test to assess the significance of the covariates \citep{Paul2014StatisticallyII}. 

For the test of $\hat{\varepsilon}\sim U(0,1)$ (question 3), we can use a Kolmogorov-Smirnov or Anderson-Darling test \citep{AD-KStest}. However, we typically skip this step. If $\mathcal{F} =\mathcal{F}_L, \mathcal{F}_A$, or $\mathcal{F}_{LS}$, the answer to question 3 is always positive since we can use a probability integral transform of the estimated noise to obtain $\hat{\varepsilon}\sim U(0,1)$. Note that $f\in\mathcal{F}$ if and only if $q\circ f\in\mathcal{F}$ where $q$ is a distribution function (which is not longer true in general if $\mathcal{F}=\mathcal{F}_F$). Applying a monotonic transformation on $\hat{\varepsilon}$ does not affect questions 1 and 2. Therefore, this question can be omitted if $\mathcal{F} = \mathcal{F}_L, \mathcal{F}_A$, or $\mathcal{F}_{LS}$. 

In our implementation, we opt for HSIC test, GAM estimation, and the Anderson-Darling test with level $\alpha = 0.05$. Some comparisons of the performance of GAM and a random forest can be found in the supplementary package. 

\subsection{Score-based estimation of $pa_Y$}\label{Section_algorithm2}
In the following, we propose a score-based algorithm for estimating the set of direct causes of $Y$. It is a counterpart of score-based algorithms for estimating the full DAG $\mathcal{G}_0$, following the ideas from \cite{Score-based_causal_learning}, \cite{Peters2014}, and \cite{bodik2023identifiability}. Recall that 
under (\ref{SCM_for_Y}), the set $S=pa_Y$ should satisfy that $\varepsilon_S\indep \textbf{X}_S$, every ${X}_i, i\in S$ is significant and $\varepsilon_S\sim U(0,1)$. 
Therefore, we use the following score function: 
\begin{equation*}
\begin{split}
\widehat{pa}_Y =  \argmax_{\substack{S\subseteq\{1, \dots, p\}\\
                  S\neq\emptyset}}score(S) &= \argmax_{\substack{S\subseteq\{1, \dots, p\}\\
                  S\neq\emptyset}}\lambda_1 (Independence) + \lambda_2(Significance)+ \lambda_3 (Distribution),
\end{split}
\end{equation*}
where $\lambda_1, \lambda_2, \lambda_3\in [0, \infty)$,  ``\textit{Independence}'' is a measure of independence between $ (\hat{\varepsilon}_S, \textbf{X}_S)$, ``\textit{Significance}'' is a measure of significance of covariates $\textbf{X}_S$, and ``\textit{Distribution}'' is a distance between the distribution of $\hat{\varepsilon}_S$ and $U(0,1)$, where $\hat{\varepsilon}_S$ is the noise estimate obtained from (\ref{equation_SID}). 

\textit{The measure of independence} can be chosen as the p-value of an independence test (such as the kernel-based HSIC test or the copula-based test). 
\textit{The measure of significance} corresponds to the estimation method analogously to the ISD case. For linear regression (similarly for GAM or GAMLSS), we compute the corresponding p-values for the hypotheses $\beta_i=0, i\in S$.  Then, \textit{Significance} is the minus of the maximum of the corresponding p-values (worst case option). We can also use a permutation test to assess the covariate's significance in terms of the predictability power and choose the largest p-value. 
\textit{The distance between the distribution of} $\hat{\varepsilon}_S$ \textit{and} $U(0,1)$ can be chosen as the p-value of the Anderson-Darling test. 

The choice of $\lambda_1, \lambda_2, \lambda_3$ describes weights we put on each of the three properties: if $\lambda_1>\lambda_2, \lambda_3$, then our estimate will be very sensitive against the violation of the independence $\varepsilon_S\indep \textbf{X}_S$, but not as sensitive against the violation of the other two properties. 

In our implementation, we opt for the following choices. The \textit{Independence} term is the logarithm of the p-value of the Kernel-based HSIC test, and the \textit{Distribution} term is the logarithm of the p-value of the Anderson-Darling test. We use GAM for the estimation in (\ref{equation_SID}) and minus the logarithm of the maximum of the corresponding p-values for the \textit{Significance} term. The logarithmic transformation of the three p-values is used to re-scale the values from $[0,1]$ to $(-\infty, 0]$. The practical choice for the weights is   $\lambda_1 = \lambda_2 = \lambda_3 =1 $ (unless $\mathcal{F}=\mathcal{F}_L,\mathcal{F}_A$, or $\mathcal{F}_{LS}$ when we put $\lambda_3 = 0$). 

\subsection{Consistency}

Consistency of the proposed algorithm follows directly from the results presented in \cite{reviewANMMooij}, who showed consistency of the score-based DAG estimation for additive noise models. In the following, we assume $\mathcal{F} = \mathcal{F}_A$, although it is straightforward to generalize these results for other types of $\mathcal{F}$ (for a discussion about $\mathcal{F} = \mathcal{F}_{LS}$, see \cite{sun2023causeeffect}, and for $\mathcal{F} = \mathcal{F}_F$, see \cite{bodik2023identifiability}). For simplicity, we assume that the measure of independence is the negative value of HSIC test itself (not the p-value as we use in our implementation), and the noise estimate $\hat{\varepsilon}$ is \textit{suitable} in the sense that
$$
\lim_{n\to\infty}\mathbb{E}_{}\bigg( \frac{1}{n}\sum_{i=1}^n(\varepsilon_i-\hat{\varepsilon}_i)^2   \bigg) = 0,
$$
where the expectation is taken with respect to the distribution of the random sample (see Appendix A.2 in \cite{reviewANMMooij}). 

\begin{proposition}\label{Proposition_consistency}
Consider $\mathcal{F} = \mathcal{F}_A$ and 
let $(Y, \textbf{X})\in\mathbb{R}\times \mathbb{R}^p$ follow an SCM with DAG $\mathcal{G}_0$ satisfying (\ref{SCM_for_Y}). Let $pa_Y\neq \emptyset$ and assume that every $S \neq pa_Y$ is not $\mathcal{F}$-plausible. 
Then,   

\begin{equation}
  \lim_{n\to\infty} \mathbb{P}(\widehat{pa}_Y  \neq pa_Y) = 0,
\end{equation}   
where $n$ is the size of the random sample and $\widehat{pa}_Y$ is our score-based estimate from Section~\ref{Section_algorithm2} with $\lambda_1, \lambda_2>0, \lambda_3 = 0$, suitable estimation procedure, and HSIC independence measure. 
\end{proposition}

The proof is in \hyperref[Proof of Proposition_consistency]{Appendix} \ref{Proof of Proposition_consistency}.  If several sets are $\mathcal{F}$-plausible, the score-based algorithm provides no guarantees that $pa_Y$ will have the best score among them (as opposed to the ISD algorithm that outputs their intersection). 

At the population level, similar results can be easily stated for the ISD algorithm. Given that we have infinite data, a consistent estimation method for (\ref{equation_SID}), and a perfect independence test (“independence oracle”), ISD is correct in the sense that it outputs  $\hat{S}_{\mathcal{F}_A}(Y) = S_{\mathcal{F}_A}(Y)$. This statement is made more precise in Lemma~\ref{lemmaISDconsistency} in \hyperref[lemmaISDconsistency]{Appendix} \ref{Section_proofs}. 

 

\subsection{What if $pa_Y=\emptyset$?}

The case $pa_Y=\emptyset$ has to be dealt with separately since an empty set cannot be (by definition) $\mathcal{F}$-plausible. Moreover, the score-based algorithm always returns a non-empty set.

Some choices of $\mathcal{F}$ lead to a fully unrestricted marginal distribution of $Y$ in the case of  $pa_Y=\emptyset$. For example, assuming $\mathcal{F}=\mathcal{F}_L$ or $\mathcal{F}_A$ gives us $Y=f_Y(\varepsilon_Y) = g^{-1}(\varepsilon_Y)$ for an unrestricted quantile function $g^{-1}$, which fits into every situation. One possibility is to define a subset $\mathcal{P}_{\emptyset} \subset \{P: P \text{ is a distribution function}\}$ and say that  $pa_Y=\emptyset$ is plausible if and only if $P_Y\in\mathcal{P}_{\emptyset}$, where $P_Y$ is the distribution of $Y$. However, defining $\mathcal{P}_{\emptyset}$ would be a troublesome step in most applications.

The case $\mathcal{F}=\mathcal{F}_F$ gives us an elegant option for assessing the validity of  $pa_Y=\emptyset$. If the marginal distribution of $Y$ is $F$ with some (unknown, but constant) parameters, we say that $pa_Y=\emptyset$ is plausible. In other words, we assess whether  $P_Y\in \mathcal{P}_{F, \emptyset} = \{ F_{\theta}: \theta\in\mathbb{R}^q\}$, which is  equivalent to assessing $f_Y\in \{f\in \mathcal{F}_F: f \text{ is a univariate}\} = \{f : f(\varepsilon) = F^{-1}(\varepsilon, \theta), \text{ for some constant }\theta\}$. 
Even though a marginal assessment $P_Y\in \mathcal{P}_{F, \emptyset}$ elegantly corresponds to the previous $\mathcal{F}_F$ framework, it does not mean that it is a reasonable approach. 

Sometimes, we encounter situations where we have a subset of covariates, and we know that one of the covariates acts as a parent of $Y$, although we are uncertain which one. Alternatively, we may have a covariate for which we know is a parent of $Y$. These scenarios can arise, for example, when conducting a do-intervention or when determining the orientation of certain edges using Meek rules  \citep{Meek}. Consequently, assuming that $pa_Y\neq\emptyset$ can often be justified either by expert knowledge about the problem or by employing other causal inference methods.

\subsection{How to select $\mathcal{F}$}

The choice of the class $\mathcal{F}$ is a crucial step in the algorithm. The choice of an appropriate model is a common problem in classical statistics; however, it is more subtle in causal discovery. It has been shown \citep{Peters2014} that methods based on restricted structural equation models can outperform traditional
constraint-based methods (when the problem is estimating the entire DAG). Even if assumptions such as additive noise or Gaussian distribution of the effect given the causes can appear to be strong, such methods have turned out to be rather useful, and small violations of the model still lead to a good estimation procedure. 

The size of  $\mathcal{F}$ is the most important part. If  $\mathcal{F}$ contains too many functions, we find that most sets are  $\mathcal{F}$-plausible. On the other hand, overly restrictive  $\mathcal{F}$ can lead to rejecting all sets as potential causes.  If we have knowledge about the data-generation process (such as when $Y$ is a sum of many small events), choosing $\mathcal{F}_F$ for a distribution function $F$ (such as Gaussian) is reasonable. If not, marginal distributions can be helpful for choosing an appropriate $F$. For a similar discussion about the choice of an appropriate model in causal discovery, see Section 5.4 in \cite{bodik2023identifiability}. 

Finding an automatic, data-driven choice of 
  $\mathcal{F}$ can lead to new and interesting results and broaden the applicability of this approach. In practice, we can try several different choices of $\mathcal{F}$ (choices based on, for example, marginal distributions) and observe the results. For the choices $\mathcal{F} = \mathcal{F}_A$ or $\mathcal{F}_{LS}$,  there are numerous papers justifying such assumptions (when estimating the full DAG, \cite{Peters2014}, \cite{Elements_of_Causal_Inference},  \cite{immer2022identifiability}, \cite{Khemakhem_autoregressive_flows}, \cite{sun2023causeeffect}). 

  






