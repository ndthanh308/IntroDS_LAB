\section{Properties of $\mathcal{F}$-identifiable parents}
\label{Section_3}

Recall that we assume the data-generation process of $Y$ in the form 
\begin{equation}\label{SCM_for_Y}
Y=f_Y(\textbf{X}_{pa_Y}, \varepsilon_Y),\,\,\,\,\,\,\, f_Y\in\mathcal{F}, \,\,\,\,\,\,\,\varepsilon_Y\indep \textbf{X}_{pa_Y}, \,\,\,\,\,\,\,\varepsilon_Y\sim U(0,1). \tag{\ding{170}} 
\end{equation}
The principle of independence of the cause and the mechanism directly implies that the set $S=pa_Y$ is always  $\mathcal{F}$-plausible; under (\ref{SCM_for_Y}), it always holds that
\begin{equation}\label{subseteq_parents}
S_\mathcal{F}(Y) \subseteq pa_Y.
\end{equation}
However, the equality $S_\mathcal{F}(Y)= pa_Y$ does not need to hold. Observe that 
$$\text{if }\mathcal{F}_1\subseteq \mathcal{F}_2, \text{ then }S_{\mathcal{F}_1}(Y)\supseteq S_{\mathcal{F}_2}(Y).$$
This is not surprising, as the more restrictions we put on the data-generation process, the larger the set of identifiable parents. 

In this section, we discuss which elements belong to $S_{\mathcal{F}}(Y)$. We find out that under linearity, we typically get $S_{\mathcal{F}_L}(Y)=\emptyset$, that is, if the link function $f_Y$ is linear, we cannot identify any parents of $Y$. However, if the link function $f_Y$ is ``ugly,'' it typically holds that $S_{\mathcal{F}}(Y) = pa_Y$ unless $\mathcal{F}$ contains too many functions.

In Section \ref{Section3.1}, our focus is on the case $\mathcal{F} = \mathcal{F}_L$. In Section \ref{Subsection3.2}, we focus mostly on the case where $\mathcal{F} = \mathcal{F}_F$ for different distribution functions $F$. Consequence~\ref{PropositionOAdditiveParents}  and Proposition \ref{Support_proposition} in Section \ref{Section3_children_case} discuss the modifications of these results for  $\mathcal{F}=\mathcal{F}_{A}$ and $\mathcal{F}=\mathcal{F}_{LS}$. 

Section~\ref{subsection3.3} includes several examples illustrating the results presented in Sections \ref{Section3.1} and \ref{Subsection3.2}.


\subsection{Case \texorpdfstring{$S_{\mathcal{F}}(Y) = \emptyset$}{Empty set of identifiable parents} and linear models }
\label{Section3.1}
The following remark shows why the concept of  $\mathcal{F}$-identifiable parents is usually not very interesting for linear SCM.   Recall that we interchangeably use the notation $X_0=Y$ for the target variable, and that an SCM follows an $\mathcal{F}$-model if each structural equation in the SCM satisfies $f_i\in\mathcal{F}, i=0, \dots, p$.  Following this definition, note that a statement ``$(Y, \textbf{X})$ follow a linear SCM'' is equivalent to a statement ``$(Y, \textbf{X})$ follow an $\mathcal{F}_L$-model.'' 

\begin{remark}\label{ExampleEasyDAG}
Consider $\mathcal{F}=\mathcal{F}_L$, where $(Y, \textbf{X})$ follow an $\mathcal{F}_L$-model with DAG drawn in Figure \ref{Mixed_Graph}A, and $$Y = \beta_1X_1+\beta_2X_2 + q^{-1}(\varepsilon_Y), \,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\varepsilon_Y\indep (X_1, X_2), \,\,\varepsilon_Y\sim U(0,1),$$ for some $\beta_1\neq 0, \beta_2\neq 0$ and a quantile function $q^{-1}$. Then $S_{\mathcal{F}_L}(Y) = \emptyset$. 
\end{remark}
\begin{proof}
We show that the set $S=\{1\}$  is $\mathcal{F}_L$-plausible. Intuitively, this holds since $Y - \beta_1 X_1 \indep X_1$, and we do not put any restrictions on the noise variable. More precisely, we find $f\in\mathcal{F}_L$ such that (\ref{Definition_F_plausible}) holds. Such $f$ can be defined as $f(x,\varepsilon) = \beta_1x + \tilde{q}^{-1}(\varepsilon)$ for $x\in\mathbb{R}, \varepsilon\in (0,1)$, where $\tilde{q}$ is the distribution function of $[\beta_2X_2 + q^{-1}(\varepsilon_Y)]$. Then trivially, $f\in\mathcal{F}_L$ and its inverse satisfies $f^\leftarrow(x,y) = \tilde{q}(y-\beta_1x)$ for $x,y\in\mathbb{R}$. Hence, $\varepsilon_{S} = f^{\leftarrow}(X_1, Y) = \tilde{q}(Y - \beta_1X_1) = \tilde{q}[\beta_2X_2 + q^{-1}(\varepsilon_Y)]\indep X_1$  and $\varepsilon_{S}\sim U(0,1)$. We have shown that $f$ satisfies (\ref{Definition_F_plausible}). 

With a similar reasoning, we get that  $S=\{2\}$ is also $\mathcal{F}_L$-plausible. Therefore, $S_{\mathcal{F}_L}(Y)\subseteq \{1\}\cap \{2\}=\emptyset$. 
\end{proof}
A similar argument can be used in a more general case. The following lemma demonstrates that in the linear structural causal models, $S_{\mathcal{F}_L}(Y)$ is usually empty, even if $pa_Y(\mathcal{G}_0)\neq \emptyset$. 

\begin{lemma}\label{LemmaAboutUnidentifiabilityFL}
Let $(Y, \textbf{X})\in\mathbb{R}\times \mathbb{R}^p$ follow an $\mathcal{F}_L$-model with DAG $\mathcal{G}_0$ and $pa_Y(\mathcal{G}_0)\neq\emptyset$. Then, $|S_{\mathcal{F}_L}(Y)| \leq 1$. Moreover, if there are any $a,b\in an_Y(\mathcal{G}_0)$ that are d-separated in $\mathcal{G}_0$, then $S_{\mathcal{F}_L}(Y) = \emptyset$. 
\end{lemma}

The proof is in \hyperref[Proof of LemmaAboutUnidentifiabilityFL]{Appendix} \ref{Proof of LemmaAboutUnidentifiabilityFL}. Lemma~\ref{LemmaAboutUnidentifiabilityFL} shows a more general principle that goes beyond the linear models. If we can \textit{marginalize} a causal model to a smaller submodel without breaking $f_Y\in\mathcal{F}$, then only the submodel is relevant for inference about  $S_{\mathcal{F}}(Y)$. We provide a more rigorous explanation of this.

\begin{definition}
Let $\mathcal{F}\subseteq\mathcal{I}_m$ and let $(X_0, \textbf{X})\in\mathbb{R}\times \mathbb{R}^p$ follow an $\mathcal{F}$-model with DAG $\mathcal{G}_0$. For a non-empty set $S\subseteq \{0, \dots, p\}$, we say that the $\mathcal{F}$-model is \textbf{marginalizable} to $S$ if  $\textbf{X}_{S}$ can also be written as an $\mathcal{F}$-model with some underlying DAG $\mathcal{G}_S$. 
%We say that an $\mathcal{F}$-model is \textbf{unmarginalizable} wrt $X_0$, if for all non-empty sets $ S\subseteq\{1, \dots, p\}$ holds that $\textbf{X}_{(0,S)}$ do not follow an $\mathcal{F}$-model. 
\end{definition}

We provide an illustration of the marginalizability on a specific example. 

\begin{remark}\label{example158}
Consider the following $\mathcal{F}_L$-model with DAG drawn in Figure \ref{Mixed_Graph}B: $X_1=\eta_1, X_2 = X_1 + \eta_2,  X_0 = X_1+X_2+\eta_0$, where the noise variables ($\eta_1, \eta_2, \eta_0$ are not necessary uniformly distributed) are jointly independent. 
\begin{itemize}
\item If $\eta_1, \eta_2, \eta_0\overset{iid}{\sim} N(0,\sigma^2)$, then the $\mathcal{F}_L$-model is marginalizable to $S = \{0,1\}$ and to $S=\{0,2\}$.
\item If $\eta_1, \eta_2, \eta_0$ are \textit{not} Gaussian, then the $\mathcal{F}_L$-model is marginalizable to $S = \{0,1\}$, but not to $S=\{0,2\}$.
\end{itemize}
\end{remark}
\begin{proof}
The marginalizability with respect to $S = \{0,1\}$ follows from the fact that we can rewrite $X_1=\eta_1, X_0=2X_1 + \tilde{\eta}_0$, where $\tilde{\eta}_Y = \eta_2 + \eta_0\indep \eta_1$. For  $S=\{0,2\}$ and Gaussian noise, we can rewrite $X_2=\tilde{\eta}_2, X_0= \frac{3}{2}X_2 +\tilde{\eta}_0$, where $\tilde{\eta}_2 = \eta_1 + \eta_2$ and $ \tilde{\eta}_0 =\frac{1}{2}\eta_1 -\frac{1}{2}\eta_2 + \eta_0\indep \tilde{\eta}_2$. 

For $S=\{0,2\}$ and non-Gaussian noise, we can never find $X_2=\tilde{\eta}_2, X_0= \beta X_2 +\tilde{\eta}_0$, where $ \tilde{\eta}_2 \indep \tilde{\eta}_0$ and $\beta\neq 0$, since for non-Gaussian variables, $a\eta_1 + b\eta_2 \not\indep c\eta_1 + d\eta_2$ always holds, for $a,b,c,d\in\mathbb{R}\setminus\{0\}$ (Darmois-SkitoviÄ theorem \citep{Skitovic}). 
\end{proof}


The following lemma states that marginalizable models typically have a small number of identifiable parents. 

\begin{lemma}\label{lemma158}
 Let $\mathcal{F}\subseteq\mathcal{I}_m$. Let $(X_0, \textbf{X})\in\mathbb{R}\times \mathbb{R}^p$ follow an $\mathcal{F}$-model with DAG $\mathcal{G}_0$ and $pa_{X_0}(\mathcal{G}_0)\neq \emptyset$. Let  $S\subseteq \{1, \dots, p\}$ be a non-empty set. If $(X_0, \textbf{X})$ is marginalizable to $S\cup\{0\}$, then $S_{\mathcal{F}}(X_0)\subseteq S$. 
\end{lemma}
\begin{proof}
 \label{Proof of lemma158}
 Since  $(X_0, \textbf{X})$ is marginalizable to $S\cup\{0\}$,  $(X_0, \textbf{X}_S)$ follows an $\mathcal{F}$-model. Therefore, $f_0\in\mathcal{F}$ exists, such that $X_0 = f_0(X_{\tilde{S}}, \varepsilon_0)$ for some $\tilde{S}\subseteq S$, $\varepsilon_0\indep X_{\tilde{S}}$, $\varepsilon_0\sim U(0,1)$. 
In other words, $ f_0^{\leftarrow}(X_{\tilde{S}}, X_0)\indep X_{\tilde{S}}$,  $f_0^{\leftarrow}(X_{\tilde{S}}, X_0)\sim U(0,1)$, which is exactly the definition of $\mathcal{F}$-plausibility. Hence, $\tilde{S}$ is $\mathcal{F}$-plausible and consequently,  $S_{\mathcal{F}}(X_0)\subseteq \tilde{S}\subseteq S$. 
 \end{proof}
Continuing with Example \ref{example158}, Lemma \ref{lemma158} gives us $S_{\mathcal{F}_L}(X_0)=\emptyset$ in the Gaussian case, and  $S_{\mathcal{F}}(X_0)=\{1\}$ in the non-Gaussian case. Merely assuming linearity is insufficient to determine whether $X_2$ is a parent of $X_0$.


% Figure environment removed








\subsection{Deriving assumptions under which \texorpdfstring{$S_{\mathcal{F}}(Y) = pa_Y$}{Complete set of identifiable parents}}\label{Subsection3.2}

We provide conditions under which all sets $S\subseteq \{1, \dots, p\}, S\neq pa_Y$ are not $\mathcal{F}$-plausible.
We focus on two main cases: when $S\cap ch_Y\neq\emptyset$ and $S\subset pa_Y$. We start with the case when  $S\cap ch_Y\neq\emptyset$.

\subsubsection{ \texorpdfstring{Case $S\cap ch_Y\neq\emptyset$}{Focusing on descendants}}
\label{Section3_children_case}
In the following, we show that we can use classical identifiability results from the literature for assessing $\mathcal{F}$-plausibility of a set $S$. Informally, if all variables in the SCM follow an identifiable $\mathcal{F}$-model, then any $S$ containing a child of $Y$ cannot be $\mathcal{F}$-plausible. We use a notion of pairwise identifiability of an $\mathcal{F}$-model, defined in Appendix \ref{Appendix_pairwise_identifiability}. Pairwise identifiability describes the identifiability of the causal relation between each pair of random variables, conditioned on any other variables. 

\begin{proposition}
\label{TheoremFidentifiabilityWithChild}
Let $(X_0, \textbf{X})\in\mathbb{R}\times \mathbb{R}^p$ follow an SCM with DAG $\mathcal{G}_0$. Let $S\subseteq\{1, \dots, p\}$ and denote $S_0 = S\cup \{0\}$. Assume that  $\mathcal{G}=\mathcal{G}_0[S_0]$, the projection of $\mathcal{G}_0$ on $S$ defined in Section \ref{section_notation}, is a DAG. Let $S$ contain a childless child of $X_0$, that is, $\exists j\in  ch_0(\mathcal{G})$ such that $ch_{j}(\mathcal{G})=\emptyset$. 

Let $\mathcal{F}\subseteq \mathcal{I}_{m}$ and let $(X_0, \textbf{X}_S)$ follow an  $\mathcal{F}$-model with graph $\mathcal{G}$, that is pairwise identifiable. Then, $S$ is not $\mathcal{F}$-plausible. 
\end{proposition}
The proof is in \hyperref[Proof of TheoremFidentifiabilityWithChild]{Appendix} \ref{Proof of TheoremFidentifiabilityWithChild}. To provide an example of the usage of Proposition~\ref{TheoremFidentifiabilityWithChild}, consider $\mathcal{F} = \mathcal{F}_A$ and $X_1\to Y\to X_2$. Let $X_2 = f_2(Y) + \eta_2$, where $Y\indep\eta_2$ and $\eta_2$ has the Gaussian distribution and $f_2$ is non-linear. Combining Proposition~\ref{TheoremFidentifiabilityWithChild} with Lemma 6 in \cite{Zhang2009}, we find that $S=\{2\}$ is not $\mathcal{F}_A$-plausible. Since $S=\{1\} = pa_Y$ is $\mathcal{F}_A$-plausible as long as $f_Y\in\mathcal{F}_A$, we get $S_{\mathcal{F}_A}(Y)=pa_Y=\{1\}$.

The following proposition discusses a different case when $\mathcal{F}$-implausibility results from restricting support of $Y$ by conditioning on the child of $Y$. This result is specific for a location-scale space of functions $\mathcal{F}_{LS}$, but can be modified for other types of $\mathcal{F}$. 

\begin{proposition}[Assuming bounded support]
\label{Support_proposition}
Let $(Y, \textbf{X})\in\mathbb{R}\times \mathbb{R}^p$ follow an SCM with DAG $\mathcal{G}_0$. Let $S\subseteq\{1, \dots, p\}$ be a non-empty set. Let  $\underline{\Psi},\overline{\Psi}: \mathbb{R}^{\mid S\mid}\to \mathbb{R}$ be real functions such that
\begin{equation*} 
supp(Y\mid \textbf{X}_S=\textbf{x}) = \big(\underline{\Psi} (\textbf{x}),\overline{\Psi}(\textbf{x})\big), \,\,\,\,\,\,\, \forall \textbf{x}\in supp(\textbf{X}_S).
\end{equation*}
Moreover, let
\begin{equation} \label{eq9987}
\frac{Y - \underline{\Psi}(\textbf{X}_S)}{\overline{\Psi}(\textbf{X}_S) - \underline{\Psi}(\textbf{X}_S)}\not\indep \textbf{X}_S.
\end{equation}
Then, $S$ is not $\mathcal{F}_{LS}$-plausible. 
\end{proposition}
The proof can be found in \hyperref[Proof of Support_proposition]{Appendix} \ref{Proof of Support_proposition}. Proposition \ref{Support_proposition} can be expressed as follows. If the support of $Y$ given $\textbf{X}_S = \textbf{x}_S$ is bounded, then $S$ can be  $\mathcal{F}_{LS}$-plausible only in a very specific case when (\ref{eq9987}) does not hold. 
Typically, (\ref{eq9987}) holds if $S$ contains a child of $Y$. 
\begin{example}\label{Example_o_Supporte}
Consider SCM where $Y$ is a parent of $X_1$ and $X_1 = Y + \eta$, where $Y\indep \eta$. Assume that  $Y, \eta$ are non-negative ($supp(Y) = supp(\eta) = (0, \infty)$). 
Then, $\underline{\Psi}(x)=0$ and  $\overline{\Psi}({x})=x$, since the support of $[Y\mid Y+\eta=x]$ is $(0,x)$. Hence, (\ref{eq9987}) reduces to $\frac{Y}{X_1} \not\indep X_1$. If $\frac{Y}{X_1} \not\indep X_1$, then $S=\{1\}$ is not $\mathcal{F}_{LS}$-plausible. 

How strong is the assumption $\frac{Y}{X_1} \not\indep X_1$? We claim that it holds in typical situations. A notable exception when  $\frac{Y}{X_1} \indep X_1$ holds is when $Y, \eta$ have Gamma distributions with equal scales. 
\end{example}

Proposition \ref{Support_proposition} is applicable only when $S$ contains a child of $Y$. If $S\subseteq pa_Y$, then (\ref{eq9987}) typically does not hold, as the following example illustrates.  
\begin{example}
Consider a bivariate SCM with $X_1\to Y$. Let $Y = X_1 + \eta$, where $X_1\indep \eta$. Assume that $supp(X) = supp(\eta) = (0, 1)$. Then, $\underline{\Psi}(x)=x$ and  $\overline{\Psi}({x})=1+x$. Hence, (\ref{eq9987}) reduces to $Y-X_1 \not\indep X_1$, which is not satisfied, so Proposition \ref{Support_proposition} is not applicable. 
\end{example}
Proposition \ref{Support_proposition} can be also stated for a case when  $\overline{\Psi}({x})=\infty$. In that case, we require stronger assumptions; we replace assumption (\ref{eq9987}) with  $Y - \underline{\Psi}(\textbf{X}_S)\not\indep \textbf{X}_S$ and replace $\mathcal{F}_{LS}$ with $\mathcal{F}_A$ (more restricted set where the scale is fixed). 

\subsubsection{Case \texorpdfstring{$S\subset pa_Y$}{Focusing on parents}}
In the following, we discuss the case when $S\subset pa_Y$. First, we introduce the notion of the inseparability of a real function. This is a fundamental notion since we will show that if $f_Y$ is inseparable, then every $S\subset pa_Y$ is not $\mathcal{F}$-plausible. Later, we provide a characterization of inseparable functions, which leaves us with a powerful tool for inferring  $\mathcal{F}$-plausible sets. For the characterization of inseparable functions, we mainly restrict our attention to sets $\mathcal{F} = \mathcal{F}_F$ for some distribution function $F$. 

\begin{definition}
Let $\textbf{X}=(X_1, \dots, X_k)$ be a random vector and $\mathcal{F}\subseteq\mathcal{I}_m$. A function $f\in\mathcal{I}_m {:}\,\, \mathbb{R}^{k+1}\to\mathbb{R}$ is called $\mathcal{F}-$\textbf{inseparable} \textbf{wrt} $\textbf{X}$, if for all $S\subset\{1, \dots, k\}$, $z\in \mathbb{R}$ exists such that 
\begin{equation}\label{Definitioninseparability}
\text{for all } g\in\mathcal{F}\,\, \text{ holds } \,\,g^{\leftarrow}\big(\textbf{X}_S, f(\textbf{X}, z)\big)\not\indep \textbf{X}_S.
\end{equation}
 \end{definition}
The notion of inseparability of a function means that we are not able to ``erase'' the effect of $\textbf{X}_S$ on $Y=f(\textbf{X}, z)$ without considering other variables. Note that the notion of $\mathcal{F}$-inseparability is a property of a real function; it does not depend on causal relations (only on the distribution of $\textbf{X}$). We provide an illustration of the notion of inseparability on the following example. 

\begin{remark}
Let $k=2$ and $\textbf{X}= (X_1, X_2)$ be continuous with independent components. Consider the function $f(x_1, x_2, z) = x_1x_2z$ and $\mathcal{F}_1, \mathcal{F}_2\subseteq\mathcal{I}_m$, such that $\mathcal{F}_1$ contains only linear functions and $\mathcal{F}_2$ contains only multiplicative functions, that is, $\mathcal{F}_1 = \mathcal{F}_L$ and 
\begin{align*}
    \mathcal{F}_2 = \{f\in\mathcal{I}_m&: f(\textbf{x}, \varepsilon) = g_1(x_1)\ldots g_k(x_k)q^{-1}(\varepsilon) \\&\text{ for some measurable functions }g_1, \dots, g_k \text{ and a quantile function 
 } q^{-1}\}.
\end{align*}
Then, $f$ is $\mathcal{F}_1-$inseparable wrt $\textbf{X}$ but is not $\mathcal{F}_2-$inseparable wrt $\textbf{X}$.
\end{remark}
\begin{proof}
 Intuitively, $f$ is $\mathcal{F}_1-$inseparable wrt $\textbf{X}$ because we cannot find $\beta\in\mathbb{R}$ such that $X_1X_2\varepsilon -\beta X_1 \indep X_1$. However, $f$ is not  $\mathcal{F}_2-$inseparable wrt $\textbf{X}$, since we can find $g$ such that $X_1X_2\varepsilon  g(X_1)\indep X_1$. We provide a more rigorous explanation of this. 
 
 First, we show that $f$ is not $\mathcal{F}_2-$inseparable wrt $\textbf{X}$. Take $S=\{1\}$. Choose a function $g\in\mathcal{F}_2$ such that  $g(x, z) = xz$. Its inverse has a form $g^{\leftarrow}(x, xz) = z$. Hence, $g^{\leftarrow}(X_S, f(\textbf{X}, z))=g^{\leftarrow}(X_1, X_1X_2z) = X_2z\indep X_1$. Hence, $f$ is not $\mathcal{F}_2-$inseparable wrt $\textbf{X}$, since we found a $g\in\mathcal{F}_2$ such that (\ref{Definitioninseparability}) is violated. 

Second, we  show that $f$ is $\mathcal{F}_1-$inseparable wrt $\textbf{X}$. Consider $S=\{1\}$ and consider any function $g\in\mathcal{F}_1$. Let us write $g$ in a form $g(x,z) = \beta x + {q}^{-1}(z)$ for some quantile function ${q}^{-1}$ and $\beta\neq 0$. The inverse of $g$ satisfies $g^{\leftarrow}(x, xz) ={q}(xz - \beta x)$. In order to show (\ref{Definitioninseparability}), we need to show that $q(X_1X_2z - \beta X_1)\not\indep X_1$. In the remainder of the section (and Appendix~\ref{Appendix_Auxiliary}), we develop a framework for proving statements such as this one. In particular, $X_1X_2z - \beta X_1\not\indep X_1$ holds due to Lemma \ref{CoolLemma} part 2. Hence, for $S=\{1\}$, (\ref{Definitioninseparability}) is satisfied. For $S=\{2\}$, the proof follows analogously. 
\end{proof}


The following lemma shows the connection between the  $\mathcal{F}$-inseparability and  $\mathcal{F}$-plausibility. It shows that the $\mathcal{F}$-inseparability implies the $\mathcal{F}$-inplausibility of all subsets of the parents. 


\begin{lemma}\label{lemma o inseparability=unplausibility}
Let $(Y, \textbf{X})\in\mathbb{R}\times \mathbb{R}^p$ follow an SCM with DAG $\mathcal{G}_0$ and $pa_Y(\mathcal{G}_0)\neq\emptyset$. Let $f_Y\in\mathcal{F}\subseteq\mathcal{I}_m$. If $f_Y$ is  $\mathcal{F}-$inseparable wrt $\textbf{X}_{pa_Y}$, then every $S\subset pa_Y(\mathcal{G}_0)$ is \textit{not} an $\mathcal{F}$-plausible set of parents of $Y$. 
\end{lemma}
\begin{proof}\label{proof of lemma o inseparability=unplausibility}
%"$\implies$": 
For a contradiction, let $S\subset pa_Y(\mathcal{G}_0)$ be an $\mathcal{F}$-plausible set of parents of $Y$. Then, we can find $f\in\mathcal{F} \text{ such that } f^{\leftarrow}(\textbf{X}_{S}, Y)\indep \textbf{X}_S.$ Since we have $Y = f_Y(\textbf{X}_{pa_Y}, \varepsilon_Y)$, we can rewrite $f^{\leftarrow}\big(\textbf{X}_{S}, f_Y(\textbf{X}_{pa_Y}, \varepsilon_Y)\big)\indep \textbf{X}_S.$ Since $\varepsilon_Y\indep \textbf{X}_{pa_Y}$, conditioning on $[\varepsilon_Y=z]$ for arbitrary $z\in(0,1)$ will give us $f^{\leftarrow}\big(\textbf{X}_S, f(\textbf{X}_{pa_Y}, z)\big)\indep \textbf{X}_S$, which is a contradiction with inseparability.
%"$\impliedby$" For a contradiction, let $S\subsetneq\{1, \dots, p\}$ and let there exist $g\in \mathcal{F}$ such that $g^{-1}(X_S, f_Y(\textbf{X}_{pa_Y}, z))\indep X_S$ for any $z\in (0,1)$. This implies (law of total probability) that for $\varepsilon_Y\indep X_{pa_Y}$ holds $g^{-1}(X_S, f_Y(\textbf{X}_{pa_Y}, \varepsilon_Y))\indep X_S$. Using $Y= f_Y(\textbf{X}_{pa_Y}, \varepsilon_Y)$ rewrite $g^{-1}(X_S, Y)\indep X_S$. Since $g\in \mathcal{F}\subset\mathcal{I}$, this is a contradiction with $\mathcal{F}$-plausibility. 
\end{proof}
In the following, we focus on characterizing the $\mathcal{F}_F$-inseparability for different distributions $F$. We show that some large classes of $f\in\mathcal{F}_F$ are indeed $\mathcal{F}_F$-inseparable. We will restrict our attention to specific types of $F$, where the parameters act \textbf{additively}/\textbf{multiplicatively}/\textbf{location-scale}. Rigorous definitions of these types can be found in Appendix \ref{Appendix_location_scale_definition}. The Gaussian distribution with fixed variance is an example of $F$ whose parameter acts additively. The Gaussian distribution with the fixed expectation or the Pareto distribution are examples of $F$ whose parameter acts multiplicatively. Examples of Location-Scale types of distributions include Gaussian distribution, logistic distribution, or Cauchy distribution, among many others.

First, we consider one parameter case ($q=1$ in (\ref{CPCM_def})). The following two propositions are the main results of this subsection. They characterize $\mathcal{F}_F-$inseparability (under some weak assumptions on the distribution function $F$). Combining these results with Lemma \ref{lemma o inseparability=unplausibility} gives us a powerful tool for inferring $\mathcal{F}_F-$plausible sets.  



\begin{proposition}\label{LemmaOParetoinseparabilite}
Let $F$ be a distribution function whose parameter acts post-multiplicatively. Let  $\textbf{X}=(X_1, \dots, X_k)$ be a continuous random vector with independent components.  
\begin{itemize}
\item Consider $f\in\mathcal{F}_F$ in the form $f(\textbf{x}, \varepsilon)=F^{-1}\big(\varepsilon, \theta(\textbf{x})\big)$ with additive function $\theta(x_1, \dots, x_k) = h_1(x_1)+\dots + h_k(x_k)$, where $h_i$ are continuous non-constant real functions. Then, $f$ is $\mathcal{F}_F-$inseparable wrt $\textbf{X}$. 
\item Consider $f\in\mathcal{F}_F$ in the form $f(\textbf{x}, \varepsilon)=F^{-1}\big(\varepsilon, \theta(\textbf{x})\big)$ with multiplicative function   $\theta(x_1, \dots, x_k) = h_1(\textbf{x}_S)\cdot h_2(\textbf{x}_{\{1, \dots, k\}\setminus S})$ for some $S\subsetneq \{1, \dots, k\}$, where $h_1, h_2$ are continuous non-constant non-zero real functions. Then, $f$ is not $\mathcal{F}_F-$inseparable wrt $\textbf{X}$. 
\end{itemize}
\end{proposition}
\begin{hproof}
Full proof is in \hyperref[Proof of LemmaOParetoinseparabilite]{Appendix} \ref{Proof of LemmaOParetoinseparabilite}. Here, we show the main steps of the first bullet-point in the case when $k=2$, $h_1(x)=h_2(x)=x$ and $F$ is the Pareto distribution function. Consider   $S=\{1\}$ (the case $S=\{2\}$ follows similarly). We show that for $S=\{1\}$ and any $z\in(0,1)$, there does not exist $g\in\mathcal{F}_F$ such that $g^{\leftarrow}\big(X_1, f(\textbf{X}, z)\big)\indep X_1.$ 

For a contradiction, assume that such $g$ exists and write $g^{\leftarrow}\big(x, \cdot) = F(\cdot, \theta_g(x)\big)$ for some non-constant positive function $\theta_g$. Using the form of the Pareto distribution, rewrite $X_1\indep g^{\leftarrow}\big(X_1, f(\textbf{X}, z)\big) = F\bigg(f(\textbf{X}, z),\theta_g(X_1)\bigg) =  F\bigg(F^{-1}[z, \theta(\textbf{X})],\theta_g(X_1)\bigg) = z^{-\frac{\theta(\textbf{X})}{\theta_g(X_1)}} = z^{-\frac{(X_1+X_2)}{\theta_g(X_1)}}$. Using the identity $Z_1\indep Z_2 \implies f(Z_1)\indep Z_2$ for any measurable function $f$ and random variables $Z_1, Z_2$, we get $$X_1\indep \theta_g(X_1)(X_1+X_2).$$ 
We show that this is not possible. Denote $\xi=\theta_g(X_1)(X_1+X_2)$ and choose \textit{distinct} $a,b,c$ in the support of $X_1$ such that $\theta_g(b)\neq 0$ (since $\theta_g$ is non-constant and $X_1$ is non-binary, this is possible). 

Since $\xi\indep X_1$, then $\xi\mid [X_1=a] \overset{D}{=}\xi\mid [X_1=b] \overset{D}{=}\xi\mid [X_1=c]$. Hence, 
\begin{equation}\label{asdf}
\theta_g(a)(a+X_2)\overset{D}{=}\theta_g(b)(b+X_2)\overset{D}{=}\theta_g(c)(c+X_2).
\end{equation}
By dividing by a non-zero constant $\theta_g(b)$ and subtracting $b$, we get
$$
\{\frac{\theta_g(a)}{\theta_g(b)}a-b\}+\frac{\theta_g(a)}{\theta_g(b)}X_2\overset{D}{=}X_2\overset{D}{=}\{\frac{\theta_g(c)}{\theta_g(b)}c-b\}+\frac{\theta_g(c)}{\theta_g(b)}X_2.
$$
It
holds that (see lemma \ref{distributionalequalitylemma}) if $z_1+z_2X_2\overset{D}{=}X_2$ for some constants $z_1, z_2$, then $z_2=\pm 1$. In our case, it leads to $\frac{\theta_g(a)}{\theta_g(b)}=\pm 1$ and  $\frac{\theta_g(c)}{\theta_g(b)}=\pm 1$. Therefore, at least two values of $\theta_g(a),\theta_g(b), \theta_g(c)$ have to be equal, and neither of them is zero. Without loss of generality, $\theta_g(a)= \theta_g(b)$. Plugging this into equation (\ref{asdf}), we get $a=b$, which is a contradiction since we chose them to be distinct. Therefore, the non-constant function $\theta_g$ does not exist, and $g$ also does not exist. 
\end{hproof}


\begin{proposition}\label{LemmaOAdditiveinseparabilite}
Let $F$ be a distribution function whose parameter acts post-additively. Let  $\textbf{X}=(X_1, \dots, X_k)$ be a continuous random vector with independent components.  
\begin{itemize}
\item Consider $f\in\mathcal{F}_F$ in the  $f(\textbf{x}, \varepsilon)=F^{-1}\big(\varepsilon, \theta(\textbf{x})\big)$ with an additive function $\theta(x_1, \dots, x_k) = h_1(\textbf{x}_S) + h_2(\textbf{x}_{\{1, \dots, k\}\setminus S})$ for some non-empty $S\subset \{1, \dots, k\}$, where $h_1, h_2$ are continuous non-constant non-zero real functions. Then, $f$ is not $\mathcal{F}_F-$inseparable wrt $\textbf{X}$. 
\item Consider $f\in\mathcal{F}_F$ in the form $f(\textbf{x}, \varepsilon)=F^{-1}\big(\varepsilon, \theta(\textbf{x})\big)$ with multiplicative function   $\theta(x_1, \dots, x_k) = h_1(x_1). h_2(x_2)\dots h_k(x_k)$, where $h_i$ are continuous non-constant non-zero real functions. Then, $f$ is $\mathcal{F}_F-$inseparable wrt $\textbf{X}$. 
\end{itemize}
\end{proposition}

 The proof follows similar steps as the proof of Proposition \ref{LemmaOParetoinseparabilite} and can be found in \hyperref[Proof of LemmaOAdditiveinseparabilite]{Appendix} \ref{Proof of LemmaOAdditiveinseparabilite}.  Proposition \ref{LemmaOParetoinseparabilite} and Proposition \ref{LemmaOAdditiveinseparabilite} reveal that to obtain  $\mathcal{F}_F$-inseparability, the form of the parameter cannot match how the parameter affects the distribution. If the parameter acts additively resp. multiplicatively, the parameter cannot have an additive resp. multiplicative form.  However,  $\mathcal{F}_F$-inseparability typically holds if the forms do not match. Note that the multiplicative assumption of $f_Y$ in the second bullet-point of Proposition~\ref{LemmaOAdditiveinseparabilite} is not necessary and is only technical for proving Lemma~\ref{CoolLemma}.  As long as $f_Y$ is not additive in any of its arguments, Lemma~\ref{CoolLemma} can be modified for much larger space of functions. 
 
 
Proposition \ref{LemmaOParetoinseparabilite} and Proposition \ref{LemmaOAdditiveinseparabilite} are formulated only for one-parameter cases (when $q=1$). The following proposition discusses the case when $q=2$, where we restrict ourselves to a location-scale family of distributions.


\begin{proposition}\label{LemmaOLocationScaleinseparabilite}
Let $F$ have a location-scale type with $q=2$ parameters. Let $\textbf{X}=(X_1, \dots, X_k)$ be a continuous random vector with independent components. Consider $f\in\mathcal{F}_F$ in the form $f(\textbf{x}, \varepsilon)=F^{-1}\big(\varepsilon, \theta(\textbf{x})\big)$, where $\theta(\textbf{x}) = \big(\mu(\textbf{x}), \sigma(\textbf{x})\big)^\top$ is additive in both components, that is,  
$\mu(\textbf{x}) = h_{1, \mu}(x_1)+\dots + h_{k, \mu}(x_k)$ and 
$\sigma(\textbf{x}) =h_{1, \sigma}(x_1)+\dots + h_{k, \sigma}(x_k)$ for some continuous non-constant non-zero functions $h_{i,\cdot}$, where we also assume $h_{i,\sigma}>0$, $i=1, \dots, k$.  Then, $f$ is $\mathcal{F}_F-$inseparable wrt $\textbf{X}$. 
\end{proposition}

The proof is in \hyperref[Proof of LemmaOLocationScaleinseparabilite]{Appendix}~\ref{Proof of LemmaOLocationScaleinseparabilite}. The crucial assumption lies in the additivity of $\sigma(\textbf{x})$; since this parameter acts multiplicatively in $F$ and has an additive form, a similar reasoning as in Proposition  \ref{LemmaOParetoinseparabilite} can be used (Proposition \ref{LemmaOLocationScaleinseparabilite} shows that even if another parameter $\mu$ depends on $\textbf{X}$, it does not ruin the results). Proposition \ref{LemmaOLocationScaleinseparabilite} can also be reformulated such that both parameters have a multiplicative form. 


The biggest drawback of Propositions \ref{LemmaOParetoinseparabilite}, \ref{LemmaOAdditiveinseparabilite}, and  \ref{LemmaOLocationScaleinseparabilite} lies in the fact that we assume independent components of $\textbf{X}$, which is rarely the case. This assumption is only a technical assumption that simplifies the proof and is not necessary. It allows us to explicitly express the conditional distributions $h(X_{i})\mid \textbf{X}_S$, that we used in the proof. However, an explicit form of a conditional distribution can also be found in other cases, such as when $\textbf{X}$ is Gaussian. 

\begin{lemma}\label{GaussianSeparabilita}
Let the assumptions from Proposition \ref{LemmaOLocationScaleinseparabilite} hold, and let $\textbf{X}=(X_1, \dots, X_k)$ be a non-degenerate Gaussian random vector (possibly with dependent components) and $h_{i,\sigma}$ be linear functions. Then, $f$ is $\mathcal{F}_F-$inseparable wrt $\textbf{X}$. 
\end{lemma}
\begin{proof}
The proof follows the same steps as the proof of Proposition \ref{LemmaOLocationScaleinseparabilite}, with the only difference being that we use  Lemma \ref{CoolLemma} part 4 instead of Lemma \ref{CoolLemma} part 3 in the last step. 
\end{proof}

The results of Propositions \ref{LemmaOParetoinseparabilite}, \ref{LemmaOAdditiveinseparabilite}, and  \ref{LemmaOLocationScaleinseparabilite} are not restricted for $\mathcal{F}_F$, but can be easily modified for the case $\mathcal{F}=\mathcal{F}_A$.

\begin{consequence}\label{PropositionOAdditiveParents}
 Consider $f_Y\in\mathcal{F}_A$ and let $(Y, \textbf{X})\in\mathbb{R}\times \mathbb{R}^p$ follow an SCM with DAG $\mathcal{G}_0$ where $pa_Y$ are $d$-separated.  
 \begin{itemize}
     \item If $f_Y$ has a form $f_Y(\textbf{x}, e) = h_1(\textbf{x}_S) + h_2(\textbf{x}_{pa_Y\setminus S}) + q^{-1}(e), \,\,\,\,\,\textbf{x}\in\mathbb{R}^{|pa_Y|}, e\in(0,1),$ for some non-empty $S\subset pa_Y$, where $h_1, h_2$ are continuous non-constant real functions and $q^{-1}$ is a quantile function. Then, $S_{\mathcal{F}_A}(Y) = \emptyset$.
     \item If $f_Y$ has a form $f_Y(\textbf{x}, e) = h_1(x_1) \dots h_{|pa_Y|}(x_{|pa_Y|}) + q^{-1}(e),\,\,\,\,\,\textbf{x}\in\mathbb{R}^{|pa_Y|}, e\in(0,1),$ where $h_i$ are continuous non-constant non-zero real functions and  $q^{-1}$ is a quantile function. Then every $S\subset pa_Y$ is not $\mathcal{F}_A$-plausible.
 \end{itemize}
\end{consequence}

The proof is in \hyperref[Proof of PropositionOAdditiveParents]{Appendix} \ref{Proof of PropositionOAdditiveParents}. As before, the assumption of $d$-separability can be replaced by assuming the normality of $\textbf{X}_{pa_Y}$, the assumption of multiplicative form of $f_Y$ in the second bullet-point can be weakened, and the statement can be modified for $\mathcal{F}=\mathcal{F}_{LS}$. 

\subsection{Some examples}\label{subsection3.3}

\begin{example}[Extending Example \ref{Pareto case}]\label{ExampleParetoFinal}
Consider an SCM with DAG drawn in Figure \ref{Mixed_Graph}A, where the structural equation corresponding to $Y$ is in the form (\ref{CPCM_def}) with $F$ being the Pareto distribution with $\theta(X_1, X_2) = h_1(X_1)+h_2(X_2)$ for some continuous non-constant functions  $h_1, h_2$. Moreover, let $X_3 = F^{-1}\big(\varepsilon_3, \theta_3(Y)\big)$, where $\theta_3(x)\neq a\log(x) + b$ for any $a,b\in\mathbb{R}$, $\varepsilon_3\indep Y$. Then $S_{\mathcal{F}_F}(Y) = \{1,2\}=pa_Y$. 

The reason is as follows: if $3\in S$, then $S$ is not $\mathcal{F}_F$-plausible (Proposition~\ref{TheoremFidentifiabilityWithChild} combined with results presented in Example \ref{Pareto case}). Cases $S=\{1\}$ or $S=\{2\}$ are also  not $\mathcal{F}_F$-plausible, since the function $\theta(x_1, x_2) = h_1(x_1)+h_2(x_2)$ is $\mathcal{F}_F$-inseparable wrt $(X_1, X_2)$ from Proposition \ref{LemmaOParetoinseparabilite}. Since $S=\{1,2\}$ is trivially $\mathcal{F}_F$-plausible from (\ref{subseteq_parents}), we get    $S_{\mathcal{F}_F}(Y) = \{1,2\}=pa_Y$.
\end{example}

\begin{example}[Additive noise models]\label{ANMexample}
Consider an SCM with DAG drawn in Figure \ref{Figure_DAG_for_teaser} and $\mathcal{F}=\mathcal{F}_A$. Let $(X_1, X_2, X_3)$ be normally distributed, 
 $$Y = \mu_Y(X_1, X_2, X_3) + \eta_Y,\,\,\, X_4 = \mu_1(Y)+ \mu_2(X_5, \eta_4),\,\,\,\,X_5 = \eta_5$$for some independent (not necessarily uniformly distributed) noise variables  $\eta_Y, \eta_4, \eta_5$, where $\mu_1, \mu_2$ are continuous non-zero functions. Let $(Y, X_4)$ follow an identifiable bivariate additive noise model (that is, $\mu_1$ does not satisfy a differential equation, described in Section 3.1 in \cite{Peters2014}). 

$S = \{5\}$ is not  $\mathcal{F}_A$-plausible, since $Y - f(X_3)\indep X_3$ can happen only if $f$ is a constant function (and constant functions do not belong to  $\mathcal{I}_m$). The same argument can be used whenever $5\in S\not\ni 4$. 

$S=\{4\}$ is not   $\mathcal{F}_A$-plausible since $(Y, {X}_4)$ follow an identifiable (additive) model, and Proposition~\ref{TheoremFidentifiabilityWithChild} can be used.
Sets $S \supseteq \{4, 5\}$ can be dealt with analogously.


If $\mu_Y$ is additive in the first component, that is, $\mu_Y(X_1, X_2, X_3) = h_1(X_1) + h(X_2, X_3)$ for some continuous non-constant functions $h_1, h$, then $S=\{1\}$ is  $\mathcal{F}_A$-plausible and hence $S_{\mathcal{F}_A}(Y)\subseteq \{1\}$. However, if  $\mu_Y$ is not additive in any of its components, then any $S\subset \{1,2,3\}$ is not  $\mathcal{F}_A$-plausible. 

If $\mu_Y$ does not satisfy the differential equation described in Section 3.1 in \cite{Peters2014}, we also get that every $S$ with $4\in S$ is not   $\mathcal{F}_A$-plausible since $(Y, {X}_4)$ follow an identifiable (additive) model and Proposition~\ref{TheoremFidentifiabilityWithChild} can be applied.

We do not have to pay attention to the sets $S = \{1,2,3,4\}, \{1,2,3,5\}, \{1,2,3,4,5\}$ since $pa_Y\subset S$ and the set of $\mathcal{F}_A$-identifiable parents remain the same, regardless of the plausibility of these sets.   
\end{example}


In Example \ref{ANMexample}, we considered a variable $X_5$, which is not a neighbor of $Y$. In general, we can directly discard this variable as a potential parent using the classical graphical argument of d-separation. However, if $X_i\indep Y$ for some $i\in\{1, \dots, p\}$, typically $i\not\in S_{\mathcal{F}}(Y)$. In particular, it is easy to see that if $X_i\indep Y$, then a set $S=\{i\}$ is not $\mathcal{F}$-plausible. 




