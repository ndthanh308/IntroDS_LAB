\begin{thebibliography}{42}
\expandafter\ifx\csname natexlab\endcsname\relax\def\natexlab#1{#1}\fi

\bibitem[{Achlioptas et~al.(2020)Achlioptas, Abdelreheem, Xia, Elhoseiny, and
  Guibas}]{achlioptas2020referit3d}
Panos Achlioptas, Ahmed Abdelreheem, Fei Xia, Mohamed Elhoseiny, and Leonidas
  Guibas. 2020.
\newblock Referit3d: Neural listeners for fine-grained 3d object identification
  in real-world scenes.
\newblock In \emph{European Conference on Computer Vision}, pages 422--440.
  Springer.

\bibitem[{Cai et~al.(2022)Cai, Zhao, Zhang, Sheng, and Xu}]{cai20223djcg}
Daigang Cai, Lichen Zhao, Jing Zhang, Lu~Sheng, and Dong Xu. 2022.
\newblock 3djcg: A unified framework for joint dense captioning and visual
  grounding on 3d point clouds.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pages 16464--16473.

\bibitem[{Chen et~al.(2020)Chen, Chang, and Nie{\ss}ner}]{chen2020scanrefer}
Dave~Zhenyu Chen, Angel~X Chang, and Matthias Nie{\ss}ner. 2020.
\newblock Scanrefer: 3d object localization in rgb-d scans using natural
  language.
\newblock In \emph{European Conference on Computer Vision}, pages 202--221.
  Springer.

\bibitem[{Chen et~al.(2022)Chen, Guhur, Tapaswi, Schmid, and
  Laptev}]{chen2022language}
Shizhe Chen, Pierre-Louis Guhur, Makarand Tapaswi, Cordelia Schmid, and Ivan
  Laptev. 2022.
\newblock Language conditioned spatial relation reasoning for 3d object
  grounding.
\newblock \emph{arXiv preprint arXiv:2211.09646}.

\bibitem[{Chen et~al.(2021)Chen, Gholami, Nie{\ss}ner, and
  Chang}]{chen2021scan2cap}
Zhenyu Chen, Ali Gholami, Matthias Nie{\ss}ner, and Angel~X Chang. 2021.
\newblock Scan2cap: Context-aware dense captioning in rgb-d scans.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pages 3193--3203.

\bibitem[{Dai et~al.(2017)Dai, Chang, Savva, Halber, Funkhouser, and
  Nie{\ss}ner}]{dai2017scannet}
Angela Dai, Angel~X Chang, Manolis Savva, Maciej Halber, Thomas Funkhouser, and
  Matthias Nie{\ss}ner. 2017.
\newblock Scannet: Richly-annotated 3d reconstructions of indoor scenes.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 5828--5839.

\bibitem[{Deng et~al.(2021)Deng, Yang, Chen, Zhou, and Li}]{deng2021transvg}
Jiajun Deng, Zhengyuan Yang, Tianlang Chen, Wengang Zhou, and Houqiang Li.
  2021.
\newblock Transvg: End-to-end visual grounding with transformers.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pages 1769--1779.

\bibitem[{He et~al.(2020)He, Liu, Gao, and Chen}]{he2020deberta}
Pengcheng He, Xiaodong Liu, Jianfeng Gao, and Weizhu Chen. 2020.
\newblock Deberta: Decoding-enhanced bert with disentangled attention.
\newblock \emph{arXiv preprint arXiv:2006.03654}.

\bibitem[{Hu et~al.(2018)Hu, Gu, Zhang, Dai, and Wei}]{hu2018relation}
Han Hu, Jiayuan Gu, Zheng Zhang, Jifeng Dai, and Yichen Wei. 2018.
\newblock Relation networks for object detection.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 3588--3597.

\bibitem[{Hu et~al.(2019)Hu, Zhang, Xie, and Lin}]{hu2019local}
Han Hu, Zheng Zhang, Zhenda Xie, and Stephen Lin. 2019.
\newblock Local relation networks for image recognition.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pages 3464--3473.

\bibitem[{Huang et~al.(2021)Huang, Lee, Chen, and Liu}]{huang2021text}
Pin-Hao Huang, Han-Hung Lee, Hwann-Tzong Chen, and Tyng-Luh Liu. 2021.
\newblock Text-guided graph neural networks for referring 3d instance
  segmentation.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial
  Intelligence}, volume~35, pages 1610--1618.

\bibitem[{Huang et~al.(2022)Huang, Chen, Jia, and Wang}]{huang2022multi}
Shijia Huang, Yilun Chen, Jiaya Jia, and Liwei Wang. 2022.
\newblock Multi-view transformer for 3d visual grounding.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pages 15524--15533.

\bibitem[{Kamath et~al.(2021)Kamath, Singh, LeCun, Synnaeve, Misra, and
  Carion}]{kamath2021mdetr}
Aishwarya Kamath, Mannat Singh, Yann LeCun, Gabriel Synnaeve, Ishan Misra, and
  Nicolas Carion. 2021.
\newblock Mdetr-modulated detection for end-to-end multi-modal understanding.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pages 1780--1790.

\bibitem[{Kazemzadeh et~al.(2014)Kazemzadeh, Ordonez, Matten, and
  Berg}]{kazemzadeh2014referitgame}
Sahar Kazemzadeh, Vicente Ordonez, Mark Matten, and Tamara Berg. 2014.
\newblock Referitgame: Referring to objects in photographs of natural scenes.
\newblock In \emph{Proceedings of the 2014 conference on empirical methods in
  natural language processing (EMNLP)}, pages 787--798.

\bibitem[{Kingma and Ba(2014)}]{kingma2014adam}
Diederik~P Kingma and Jimmy Ba. 2014.
\newblock Adam: A method for stochastic optimization.
\newblock \emph{arXiv preprint arXiv:1412.6980}.

\bibitem[{Li and Sigal(2021)}]{li2021referring}
Muchen Li and Leonid Sigal. 2021.
\newblock Referring transformer: A one-step approach to multi-task visual
  grounding.
\newblock \emph{Advances in Neural Information Processing Systems},
  34:19652--19664.

\bibitem[{Lin et~al.(2017)Lin, Goyal, Girshick, He, and
  Doll{\'a}r}]{lin2017focal}
Tsung-Yi Lin, Priya Goyal, Ross Girshick, Kaiming He, and Piotr Doll{\'a}r.
  2017.
\newblock Focal loss for dense object detection.
\newblock In \emph{Proceedings of the IEEE international conference on computer
  vision}, pages 2980--2988.

\bibitem[{Liu et~al.(2021{\natexlab{a}})Liu, Lin, Cao, Hu, Wei, Zhang, Lin, and
  Guo}]{liu2021swin}
Ze~Liu, Yutong Lin, Yue Cao, Han Hu, Yixuan Wei, Zheng Zhang, Stephen Lin, and
  Baining Guo. 2021{\natexlab{a}}.
\newblock Swin transformer: Hierarchical vision transformer using shifted
  windows.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pages 10012--10022.

\bibitem[{Liu et~al.(2021{\natexlab{b}})Liu, Zhang, Cao, Hu, and
  Tong}]{liu2021group}
Ze~Liu, Zheng Zhang, Yue Cao, Han Hu, and Xin Tong. 2021{\natexlab{b}}.
\newblock Group-free 3d object detection via transformers.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pages 2949--2958.

\bibitem[{Luo et~al.(2022)Luo, Fu, Kong, Gao, Ren, Shen, Xia, and
  Liu}]{luo20223d}
Junyu Luo, Jiahui Fu, Xianghao Kong, Chen Gao, Haibing Ren, Hao Shen, Huaxia
  Xia, and Si~Liu. 2022.
\newblock 3d-sps: Single-stage 3d visual grounding via referred point
  progressive selection.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pages 16454--16463.

\bibitem[{Misra et~al.(2021)Misra, Girdhar, and Joulin}]{misra2021end}
Ishan Misra, Rohit Girdhar, and Armand Joulin. 2021.
\newblock An end-to-end transformer model for 3d object detection.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pages 2906--2917.

\bibitem[{Plummer et~al.(2015)Plummer, Wang, Cervantes, Caicedo, Hockenmaier,
  and Lazebnik}]{plummer2015flickr30k}
Bryan~A Plummer, Liwei Wang, Chris~M Cervantes, Juan~C Caicedo, Julia
  Hockenmaier, and Svetlana Lazebnik. 2015.
\newblock Flickr30k entities: Collecting region-to-phrase correspondences for
  richer image-to-sentence models.
\newblock In \emph{Proceedings of the IEEE international conference on computer
  vision}, pages 2641--2649.

\bibitem[{Qi et~al.(2019)Qi, Litany, He, and Guibas}]{qi2019deep}
Charles~R Qi, Or~Litany, Kaiming He, and Leonidas~J Guibas. 2019.
\newblock Deep hough voting for 3d object detection in point clouds.
\newblock In \emph{proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pages 9277--9286.

\bibitem[{Qi et~al.(2017)Qi, Yi, Su, and Guibas}]{qi2017pointnet++}
Charles~Ruizhongtai Qi, Li~Yi, Hao Su, and Leonidas~J Guibas. 2017.
\newblock Pointnet++: Deep hierarchical feature learning on point sets in a
  metric space.
\newblock \emph{Advances in neural information processing systems}, 30.

\bibitem[{Radford et~al.(2021)Radford, Kim, Hallacy, Ramesh, Goh, Agarwal,
  Sastry, Askell, Mishkin, Clark et~al.}]{radford2021learning}
Alec Radford, Jong~Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh,
  Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark,
  et~al. 2021.
\newblock Learning transferable visual models from natural language
  supervision.
\newblock In \emph{International Conference on Machine Learning}, pages
  8748--8763. PMLR.

\bibitem[{Raffel et~al.(2020)Raffel, Shazeer, Roberts, Lee, Narang, Matena,
  Zhou, Li, Liu et~al.}]{raffel2020exploring}
Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael
  Matena, Yanqi Zhou, Wei Li, Peter~J Liu, et~al. 2020.
\newblock Exploring the limits of transfer learning with a unified text-to-text
  transformer.
\newblock \emph{J. Mach. Learn. Res.}, 21(140):1--67.

\bibitem[{Roh et~al.(2022)Roh, Desingh, Farhadi, and
  Fox}]{roh2022languagerefer}
Junha Roh, Karthik Desingh, Ali Farhadi, and Dieter Fox. 2022.
\newblock Languagerefer: Spatial-language model for 3d visual grounding.
\newblock In \emph{Conference on Robot Learning}, pages 1046--1056. PMLR.

\bibitem[{Savva et~al.(2019)Savva, Kadian, Maksymets, Zhao, Wijmans, Jain,
  Straub, Liu, Koltun, Malik et~al.}]{savva2019habitat}
Manolis Savva, Abhishek Kadian, Oleksandr Maksymets, Yili Zhao, Erik Wijmans,
  Bhavana Jain, Julian Straub, Jia Liu, Vladlen Koltun, Jitendra Malik, et~al.
  2019.
\newblock Habitat: A platform for embodied ai research.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pages 9339--9347.

\bibitem[{Scarselli et~al.(2008)Scarselli, Gori, Tsoi, Hagenbuchner, and
  Monfardini}]{scarselli2008graph}
Franco Scarselli, Marco Gori, Ah~Chung Tsoi, Markus Hagenbuchner, and Gabriele
  Monfardini. 2008.
\newblock The graph neural network model.
\newblock \emph{IEEE transactions on neural networks}, 20(1):61--80.

\bibitem[{Shaw et~al.(2018)Shaw, Uszkoreit, and Vaswani}]{shaw2018self}
Peter Shaw, Jakob Uszkoreit, and Ashish Vaswani. 2018.
\newblock Self-attention with relative position representations.
\newblock \emph{arXiv preprint arXiv:1803.02155}.

\bibitem[{Vaswani et~al.(2017)Vaswani, Shazeer, Parmar, Uszkoreit, Jones,
  Gomez, Kaiser, and Polosukhin}]{vaswani2017attention}
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,
  Aidan~N Gomez, {\L}ukasz Kaiser, and Illia Polosukhin. 2017.
\newblock Attention is all you need.
\newblock \emph{Advances in neural information processing systems}, 30.

\bibitem[{Wang et~al.(2019)Wang, Huang, Celikyilmaz, Gao, Shen, Wang, Wang, and
  Zhang}]{wang2019reinforced}
Xin Wang, Qiuyuan Huang, Asli Celikyilmaz, Jianfeng Gao, Dinghan Shen,
  Yuan-Fang Wang, William~Yang Wang, and Lei Zhang. 2019.
\newblock Reinforced cross-modal matching and self-supervised imitation
  learning for vision-language navigation.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pages 6629--6638.

\bibitem[{Wang et~al.(2023)Wang, Huang, Zhao, Li, Cheng, Zhu, Yin, and
  Zhao}]{wang2023distilling}
Zehan Wang, Haifeng Huang, Yang Zhao, Linjun Li, Xize Cheng, Yichen Zhu,
  Aoxiong Yin, and Zhou Zhao. 2023.
\newblock Distilling coarse-to-fine semantic matching knowledge for weakly
  supervised 3d visual grounding.
\newblock \emph{arXiv preprint arXiv:2307.09267}.

\bibitem[{Wu et~al.(2021)Wu, Peng, Chen, Fu, and Chao}]{wu2021rethinking}
Kan Wu, Houwen Peng, Minghao Chen, Jianlong Fu, and Hongyang Chao. 2021.
\newblock Rethinking and improving relative position encoding for vision
  transformer.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pages 10033--10041.

\bibitem[{Xia et~al.(2018)Xia, Zamir, He, Sax, Malik, and
  Savarese}]{xia2018gibson}
Fei Xia, Amir~R Zamir, Zhiyang He, Alexander Sax, Jitendra Malik, and Silvio
  Savarese. 2018.
\newblock Gibson env: Real-world perception for embodied agents.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 9068--9079.

\bibitem[{Yang et~al.(2022)Yang, Xu, Yuan, Liu, Li, and Hu}]{yang2022improving}
Li~Yang, Yan Xu, Chunfeng Yuan, Wei Liu, Bing Li, and Weiming Hu. 2022.
\newblock Improving visual grounding with visual-linguistic verification and
  iterative reasoning.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pages 9499--9508.

\bibitem[{Yang et~al.(2019)Yang, Gong, Wang, Huang, Yu, and Luo}]{yang2019fast}
Zhengyuan Yang, Boqing Gong, Liwei Wang, Wenbing Huang, Dong Yu, and Jiebo Luo.
  2019.
\newblock A fast and accurate one-stage approach to visual grounding.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pages 4683--4693.

\bibitem[{Yang et~al.(2021)Yang, Zhang, Wang, and Luo}]{yang2021sat}
Zhengyuan Yang, Songyang Zhang, Liwei Wang, and Jiebo Luo. 2021.
\newblock Sat: 2d semantics assisted training for 3d visual grounding.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pages 1856--1866.

\bibitem[{Yuan et~al.(2021)Yuan, Yan, Liao, Zhang, Wang, Li, and
  Cui}]{yuan2021instancerefer}
Zhihao Yuan, Xu~Yan, Yinghong Liao, Ruimao Zhang, Sheng Wang, Zhen Li, and
  Shuguang Cui. 2021.
\newblock Instancerefer: Cooperative holistic understanding for visual
  grounding on point clouds through instance multi-level contextual referring.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pages 1791--1800.

\bibitem[{Zhao et~al.(2021{\natexlab{a}})Zhao, Jiang, Jia, Torr, and
  Koltun}]{zhao2021point}
Hengshuang Zhao, Li~Jiang, Jiaya Jia, Philip~HS Torr, and Vladlen Koltun.
  2021{\natexlab{a}}.
\newblock Point transformer.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pages 16259--16268.

\bibitem[{Zhao et~al.(2021{\natexlab{b}})Zhao, Cai, Sheng, and
  Xu}]{zhao20213dvg}
Lichen Zhao, Daigang Cai, Lu~Sheng, and Dong Xu. 2021{\natexlab{b}}.
\newblock 3dvg-transformer: Relation modeling for visual grounding on point
  clouds.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pages 2928--2937.

\bibitem[{Zhu et~al.(2020)Zhu, Zhu, Chang, and Liang}]{zhu2020vision}
Fengda Zhu, Yi~Zhu, Xiaojun Chang, and Xiaodan Liang. 2020.
\newblock Vision-language navigation with self-supervised auxiliary reasoning
  tasks.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pages 10012--10022.

\end{thebibliography}
