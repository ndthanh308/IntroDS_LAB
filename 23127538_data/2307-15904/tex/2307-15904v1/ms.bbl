\begin{thebibliography}{10}

\bibitem{mokady2021clipcap}
R.~Mokady, A.~Hertz, and A.~H. Bermano, ``Clipcap: Clip prefix for image
  captioning,'' {\em arXiv preprint arXiv:2111.09734}, 2021.

\bibitem{salem2020learning}
T.~Salem, S.~Workman, and N.~Jacobs, ``Learning a dynamic map of visual
  appearance,'' in {\em Proceedings of the IEEE/CVF Conference on Computer
  Vision and Pattern Recognition}, pp.~12435--12444, 2020.

\bibitem{laffont2014transient}
P.-Y. Laffont, Z.~Ren, X.~Tao, C.~Qian, and J.~Hays, ``Transient attributes for
  high-level understanding and editing of outdoor scenes,'' {\em ACM
  Transactions on graphics (TOG)}, vol.~33, no.~4, pp.~1--11, 2014.

\bibitem{zhou2017places}
B.~Zhou, A.~Lapedriza, A.~Khosla, A.~Oliva, and A.~Torralba, ``Places: A 10
  million image database for scene recognition,'' {\em IEEE transactions on
  pattern analysis and machine intelligence}, vol.~40, no.~6, pp.~1452--1464,
  2017.

\bibitem{streltsov2020estimating}
A.~Streltsov, J.~M. Malof, B.~Huang, and K.~Bradbury, ``Estimating residential
  building energy consumption using overhead imagery,'' {\em Applied Energy},
  vol.~280, p.~116018, 2020.

\bibitem{bency2017beyond}
A.~J. Bency, S.~Rallapalli, R.~K. Ganti, M.~Srivatsa, and B.~Manjunath,
  ``Beyond spatial auto-regressive models: Predicting housing prices with
  satellite imagery,'' in {\em 2017 IEEE winter conference on applications of
  computer vision (WACV)}, pp.~320--329, IEEE, 2017.

\bibitem{radford2021learning}
A.~Radford, J.~W. Kim, C.~Hallacy, A.~Ramesh, G.~Goh, S.~Agarwal, G.~Sastry,
  A.~Askell, P.~Mishkin, J.~Clark, {\em et~al.}, ``Learning transferable visual
  models from natural language supervision,'' in {\em International conference
  on machine learning}, pp.~8748--8763, PMLR, 2021.

\bibitem{li2021align}
J.~Li, R.~Selvaraju, A.~Gotmare, S.~Joty, C.~Xiong, and S.~C.~H. Hoi, ``Align
  before fuse: Vision and language representation learning with momentum
  distillation,'' {\em Advances in neural information processing systems},
  vol.~34, pp.~9694--9705, 2021.

\bibitem{yao2021filip}
L.~Yao, R.~Huang, L.~Hou, G.~Lu, M.~Niu, H.~Xu, X.~Liang, Z.~Li, X.~Jiang, and
  C.~Xu, ``Filip: fine-grained interactive language-image pre-training,'' {\em
  arXiv preprint arXiv:2111.07783}, 2021.

\bibitem{thomee2016yfcc100m}
B.~Thomee, D.~A. Shamma, G.~Friedland, B.~Elizalde, K.~Ni, D.~Poland, D.~Borth,
  and L.-J. Li, ``Yfcc100m: The new data in multimedia research,'' {\em
  Communications of the ACM}, vol.~59, no.~2, pp.~64--73, 2016.

\bibitem{ilic2019deep}
L.~Ilic, M.~Sawada, and A.~Zarzelli, ``Deep mapping gentrification in a large
  canadian city using deep learning and google street view,'' {\em PloS one},
  vol.~14, no.~3, p.~e0212814, 2019.

\bibitem{behrens2018multi}
T.~Behrens, K.~Schmidt, R.~A. MacMillan, and R.~A. Viscarra~Rossel,
  ``Multi-scale digital soil mapping with deep learning,'' {\em Scientific
  reports}, vol.~8, no.~1, p.~15244, 2018.

\bibitem{zong2019deepdpm}
Z.~Zong, J.~Feng, K.~Liu, H.~Shi, and Y.~Li, ``Deepdpm: Dynamic population
  mapping via deep neural network,'' in {\em Proceedings of the AAAI Conference
  on Artificial Intelligence}, vol.~33, pp.~1294--1301, 2019.

\bibitem{onishi2021explainable}
M.~Onishi and T.~Ise, ``Explainable identification and mapping of trees using
  uav rgb image and deep learning,'' {\em Scientific reports}, vol.~11, no.~1,
  p.~903, 2021.

\bibitem{greenwell2018goes}
C.~Greenwell, S.~Workman, and N.~Jacobs, ``What goes where: Predicting object
  distributions from above,'' in {\em IGARSS 2018-2018 IEEE International
  Geoscience and Remote Sensing Symposium}, pp.~4375--4378, IEEE, 2018.

\bibitem{alhassan2020deep}
V.~Alhassan, C.~Henry, S.~Ramanna, and C.~Storie, ``A deep learning framework
  for land-use/land-cover mapping and analysis using multispectral satellite
  imagery,'' {\em Neural Computing and Applications}, vol.~32, pp.~8529--8544,
  2020.

\bibitem{9553499}
K.~Karra, C.~Kontgis, Z.~Statman-Weil, J.~C. Mazzariello, M.~Mathis, and S.~P.
  Brumby, ``Global land use / land cover with sentinel 2 and deep learning,''
  in {\em 2021 IEEE International Geoscience and Remote Sensing Symposium
  IGARSS}, pp.~4704--4707, 2021.

\bibitem{feizizadeh2023machine}
B.~Feizizadeh, D.~Omarzadeh, M.~Kazemi~Garajeh, T.~Lakes, and T.~Blaschke,
  ``Machine learning data-driven approaches for land use/cover mapping and
  trend analysis using google earth engine,'' {\em Journal of Environmental
  Planning and Management}, vol.~66, no.~3, pp.~665--697, 2023.

\bibitem{bickel2020deep}
V.~T. Bickel, S.~J. Conway, P.-A. Tesson, A.~Manconi, S.~Loew, and U.~Mall,
  ``Deep learning-driven detection and mapping of rockfalls on mars,'' {\em
  IEEE Journal of Selected Topics in Applied Earth Observations and Remote
  Sensing}, vol.~13, pp.~2831--2841, 2020.

\bibitem{zhang2021data}
S.~Zhang, E.~J.~M. Carranza, H.~Wei, K.~Xiao, F.~Yang, J.~Xiang, S.~Zhang, and
  Y.~Xu, ``Data-driven mineral prospectivity mapping by joint application of
  unsupervised convolutional auto-encoder network and supervised convolutional
  neural network,'' {\em Natural Resources Research}, vol.~30, pp.~1011--1031,
  2021.

\bibitem{workman2017understanding}
S.~Workman, R.~Souvenir, and N.~Jacobs, ``Understanding and mapping natural
  beauty,'' in {\em Proceedings of the IEEE International Conference on
  Computer Vision}, pp.~5589--5598, 2017.

\bibitem{workman2020dynamic}
S.~Workman and N.~Jacobs, ``Dynamic traffic modeling from overhead imagery,''
  in {\em Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern
  Recognition}, pp.~12315--12324, 2020.

\bibitem{zhang2022contrastive}
Y.~Zhang, H.~Jiang, Y.~Miura, C.~D. Manning, and C.~P. Langlotz, ``Contrastive
  learning of medical visual representations from paired images and text,'' in
  {\em Machine Learning for Healthcare Conference}, pp.~2--25, PMLR, 2022.

\bibitem{desai2021virtex}
K.~Desai and J.~Johnson, ``Virtex: Learning visual representations from textual
  annotations,'' in {\em Proceedings of the IEEE/CVF conference on computer
  vision and pattern recognition}, pp.~11162--11173, 2021.

\bibitem{yuan2021florence}
L.~Yuan, D.~Chen, Y.-L. Chen, N.~Codella, X.~Dai, J.~Gao, H.~Hu, X.~Huang,
  B.~Li, C.~Li, {\em et~al.}, ``Florence: A new foundation model for computer
  vision,'' {\em arXiv preprint arXiv:2111.11432}, 2021.

\bibitem{jia2021scaling}
C.~Jia, Y.~Yang, Y.~Xia, Y.-T. Chen, Z.~Parekh, H.~Pham, Q.~Le, Y.-H. Sung,
  Z.~Li, and T.~Duerig, ``Scaling up visual and vision-language representation
  learning with noisy text supervision,'' in {\em International Conference on
  Machine Learning}, pp.~4904--4916, PMLR, 2021.

\bibitem{yang2022unified}
J.~Yang, C.~Li, P.~Zhang, B.~Xiao, C.~Liu, L.~Yuan, and J.~Gao, ``Unified
  contrastive learning in image-text-label space,'' in {\em Proceedings of the
  IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pp.~19163--19173, 2022.

\bibitem{yang2022vision}
J.~Yang, J.~Duan, S.~Tran, Y.~Xu, S.~Chanda, L.~Chen, B.~Zeng, T.~Chilimbi, and
  J.~Huang, ``Vision-language pre-training with triple contrastive learning,''
  in {\em Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern
  Recognition}, pp.~15671--15680, 2022.

\bibitem{cho2022fine}
J.~Cho, S.~Yoon, A.~Kale, F.~Dernoncourt, T.~Bui, and M.~Bansal, ``Fine-grained
  image captioning with clip reward,'' {\em arXiv preprint arXiv:2205.13115},
  2022.

\bibitem{ramesh2022hierarchical}
A.~Ramesh, P.~Dhariwal, A.~Nichol, C.~Chu, and M.~Chen, ``Hierarchical
  text-conditional image generation with clip latents,'' {\em arXiv preprint
  arXiv:2204.06125}, 2022.

\bibitem{nichol2021glide}
A.~Nichol, P.~Dhariwal, A.~Ramesh, P.~Shyam, P.~Mishkin, B.~McGrew,
  I.~Sutskever, and M.~Chen, ``Glide: Towards photorealistic image generation
  and editing with text-guided diffusion models,'' {\em arXiv preprint
  arXiv:2112.10741}, 2021.

\bibitem{wang2022clip}
Z.~Wang, W.~Liu, Q.~He, X.~Wu, and Z.~Yi, ``Clip-gen: Language-free training of
  a text-to-image generator with clip,'' {\em arXiv preprint arXiv:2203.00386},
  2022.

\bibitem{hendriksen2022extending}
M.~Hendriksen, M.~Bleeker, S.~Vakulenko, N.~van Noord, E.~Kuiper, and
  M.~de~Rijke, ``Extending clip for category-to-image retrieval in
  e-commerce,'' in {\em Advances in Information Retrieval: 44th European
  Conference on IR Research, ECIR 2022, Stavanger, Norway, April 10--14, 2022,
  Proceedings, Part I}, pp.~289--303, Springer, 2022.

\bibitem{sain2023clip}
A.~Sain, A.~K. Bhunia, P.~N. Chowdhury, S.~Koley, T.~Xiang, and Y.-Z. Song,
  ``Clip for all things zero-shot sketch-based image retrieval, fine-grained or
  not,'' in {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pp.~2765--2775, 2023.

\bibitem{baldrati2022effective}
A.~Baldrati, M.~Bertini, T.~Uricchio, and A.~Del~Bimbo, ``Effective conditioned
  and composed image retrieval combining clip-based features,'' in {\em
  Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern
  Recognition}, pp.~21466--21474, 2022.

\bibitem{oord2018representation}
A.~v.~d. Oord, Y.~Li, and O.~Vinyals, ``Representation learning with
  contrastive predictive coding,'' {\em arXiv preprint arXiv:1807.03748}, 2018.

\bibitem{loshchilov2017decoupled}
I.~Loshchilov and F.~Hutter, ``Decoupled weight decay regularization,'' {\em
  arXiv preprint arXiv:1711.05101}, 2017.

\bibitem{loshchilov2016sgdr}
I.~Loshchilov and F.~Hutter, ``Sgdr: Stochastic gradient descent with warm
  restarts,'' {\em arXiv preprint arXiv:1608.03983}, 2016.

\bibitem{cubuk2020randaugment}
E.~D. Cubuk, B.~Zoph, J.~Shlens, and Q.~V. Le, ``Randaugment: Practical
  automated data augmentation with a reduced search space,'' in {\em
  Proceedings of the IEEE/CVF conference on computer vision and pattern
  recognition workshops}, pp.~702--703, 2020.

\end{thebibliography}
