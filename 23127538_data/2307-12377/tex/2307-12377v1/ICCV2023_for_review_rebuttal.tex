\documentclass[10pt,twocolumn,letterpaper]{article}

\usepackage{iccv_rebuttal}
\usepackage{times}
\usepackage{epsfig}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{comment}

% Include other packages here, before hyperref.

% If you comment hyperref and then uncomment it, you should delete
% egpaper.aux before re-running latex.  (Or just hit 'q' on the first latex
% run, let it finish, and you should be clear).
\usepackage[pagebackref=true,breaklinks=true,letterpaper=true,colorlinks,bookmarks=false]{hyperref}

%%%%%%%%% PAPER ID  - PLEASE UPDATE
\def\iccvPaperID{10655} % *** Enter the ICCV Paper ID here
\def\httilde{\mbox{\tt\raisebox{-.5ex}{\symbol{126}}}}

\begin{document}

%%%%%%%%% TITLE - PLEASE UPDATE
\title{4D Feet: Registering Walking Foot Shapes Using Attention Enhanced Dynamic-Synchronized Graph Convolutional LSTM Network}  % **** Enter the paper title here

\maketitle
\thispagestyle{empty}

\vspace{-0.5 cm}
We thank all the Reviewers (R) for their detailed reading of our manuscript. Here are our responses to Rs' comments.
\begin{comment}
 Based on our understanding, we classified the comments in the following sections, then discussed them in more detail accordingly:
 
\textbf{lack of positioning of the dataset with respect to other available data sets;}\\

\textbf{lack of discussing the usefulness of the dataset;}\\

\textbf{unsupported claims about the sync issues, frame drops, etc.;}\\

\textbf{Unclear which algorithm components are novel and crucial (cfr ablation study);}\\

\textbf{Possibly shift focus to the novel dataset instead of synchronisation algorithm;}\\

\textbf{Some missing related work on registration and possibly link to 4D hand scanning.}
\end{comment}

\textbf{\fbox{R1 (Borderline); }} Q1 - \textbf{Section 3.3.1 should be shortened}% and explained as an application of the existing method [35]}
: We agree with you and we will shorten the section 3.3.1 and more focus on the novel developed framework (Section 3), and presented feet dataset in the next revision of the paper.

Q2 - \textbf{Comparison with the existing datasets}: To the best of our knowledge, we could not find any article developed a 4D dataset based on a software-based frame time-synchroniser, while we recognised a few works with similar state-of the-art results summarised in Table~\ref{tab:table_comparision_datasets}. The works in \cite{tajdari2022dynamicregistrationRebuttal}, and \cite{boppana2021dynamic} present foot datasets; however, \cite{boppana2021dynamic} only can capture top of a foot contracry to our dataset that we could present a complete foot. Overall, our dataset outperforms the presented datasets in Table~\ref{tab:table_comparision_datasets} for number of objects, automatic time-delay synchronisation, and accuracy.
\begin{table}[b]
\vspace{-0.7 cm}
	%\renewcommand{\arraystretch}{1.3}
	\caption{Comparison of available datasets.}
 \label{tab:table_comparision_datasets}
	\centering
	\resizebox{\columnwidth}{!}{\input{table_comparision_datasets}}
 \vspace{-0.55 cm}
\end{table}

Q3 - \textbf{How important the asynchronous cameras is}% is in the context of the general human modeling research community}
: Commercial systems, such as 3DMD, can capture (nearly) synchronized 4D scans, however, with limited envelope (small movements), speed (6$\sim$10HZ) and high cost (150$\sim$200K). On the other side, dynamic DHMs are crucial for a better understanding of human movements and for product design, e.g. shoe design. Currently, there is limited 4D data for feet. The method we proposed is built on low-cost scanners, and it is able to scale up at affordable cost for capturing other human activities, e.g. sports.

Q4 - \textbf{Explaine the problem presented in the proposed dataset is general}% and it is worth doing research in this direction is important}
: Relevant literature on 3D reconstruction from asynchronise multi-views studied in \cite{kamble20223d, klose2010reconstructing, nakazawa2012dynamic, ma20233d, morimoto2019motion} show the importance of a general time-synchroniser method for collecting any 4D dataset through multiple cameras. 

Q5 - \textbf{How the proposed dataset can be used to facilitate the research in the field that cannot be achieved by using any of the existing datasets}: To the best of our knowledge there exist no high resolution (temporal and spatial) of 4D feet dataset exploiting software-based time-synchronisation, and our dataset is the first in this context.


\textbf{\fbox{R2 (Strong reject)}} Q1 - \textbf{Why the task is significant for the community}: Please see our response to R1-Q3.

Q2 - \textbf{If someone already has a 4D scanner which consists of multiple depth cameras, it should relatively straightforward to synchronize these cameras}: Referring to our response in R1-Q4, 3D reconstruction from multiple depth cameras is a very challenging and complicated task which is extensively explained in recent works \cite{kamble20223d, klose2010reconstructing, nakazawa2012dynamic, ma20233d, morimoto2019motion}.

Q3 - \textbf{the provided link is incorrect (gives 404)}: Thanks for mentioning, please find it in \href{https://learn.microsoft.com/en-us/azure/kinect-dk/multi-camera-sync}{link}.

Q4 - \textbf{There is no mention on the dropped frames}: We agree that we should explain this aspect better in the paper. In practice, the speed (fps) of capturing is in contrast with the waiting buffer time on the usb3 port for collecting the received data from all the cameras. To avoid having dropped frames we had to set the waiting time at 120 milliseconds to have the speed of 15 fps; however, this causes a nonlinear and undetectable huge delay of approximately 3 seconds in each experiment. Thus, we developed the time-synchronization framework to align the time of captured data while using the big waiting time employed to avoid dropped frames.   


%In our method, we are skipping the dropped frames as mentioned in lines 466-467 of our paper, which can be treated as one of the limitations of this work. % and we assume having limitations in submissions in such proceedings of ICCV is a common issue.  We also will add a limitation section in the revised version as "\textit{The performance of the ICFP method is sensitive to the missed frames and/ or very low density point clouds. The reason is that by reducing the density, many features will be disappeared and from the particular frame it might be difficult to reconstruct the features. Thus, we skipped the missed or low density frames of cameras. In addition, the complete process is offline due to the need computing time for synchronising frames. Furthermore, the presented data-set considered normal people and abnormal, or disabled people are not collected.}"

%"\textit{In the step of Construction of the Dynamic-Synchronised Graph based on the dynamic points, the performance of the ICFP method is very sensitive to the missed frames and/ or very low density point clouds. The reason is that by reducing the density, many features will be disappeared and from the particular frame it might be difficult to reconstruct the features. In this paper, we skipped the missed or low density frames of cameras. In addition, the complete process is offline due to the need computing time for synchronising frames. %However, our method does not use future frames for synchronisation. the current frame and this can be online, while the ADGC-LSTM networking learning process is time consuming. Furthermore, the presented data-set considered normal people and abnormal, or disabled people are not collected.}"

Q5 - \textbf{The paper is not properly supported by the references and not clearly motivated/discussed}: Please see our responses in R1-Q2, R1-Q3, and R1-Q4, which provides related references to show why the time-synchronisation is important, and a discussion on why the results and findings are valuable. 

Q6 - \textbf{It is unclear why the proposed method outperforms previous methods as the ablation analyses are missing}: We agree that we should explain this aspect better in the paper. our method outperforms the other methods because a transient stage of Dynamic-Synchronised Graph is used that allows the AGC-LSTM network [31] to perform way more efficiently. As a matter of fact, the transient stage passes more meaningful time-dependant information to the long-term memory of the LSTM part in AGC-LASTM network, which results in a better time alignment of the frames and thus less errors (the gains are more well-trained).

\textbf{\fbox{R3 (Borderline)}} Q1 - \textbf{Many related works on the registration and synchronization methods are missing}: Please look at our response to R1-Q4.

Q2 - \textbf{Can the proposed method be applied to 4D hand scans?}: Indeed yes, the framework is general (refer to R1-Q4) can be applied on any 3D shapes including moving hands that suffer from non-time-synchronization frames.


Q3 - \textbf{The compared methods are not necessarily suitable to the task}: Please look at our response to R2-Q6.


\begin{comment}
    

%%%%%%%%% BODY TEXT - ENTER YOUR RESPONSE BELOW
\section{Introduction}

After receiving paper reviews, authors may optionally submit a rebuttal to address the reviewers' comments, which will be limited to a {\bf one page} PDF file.  Please follow the steps and style guidelines outlined below for submitting your author response.

Note that the author rebuttal is optional and, following similar guidelines to previous ICCV conferences, it is meant to provide you with an opportunity to rebut factual errors or to supply additional information requested by the reviewers. It is NOT intended to add new contributions (theorems, algorithms, experiments) that were not included in the original submission and were not requested by the reviewers. You may optionally add a figure, graph or proof to your rebuttal to better illustrate your answer to the reviewers' comments.

The rebuttal must adhere to the same blind-submission as the original submission and must comply with this rebuttal-formatted template.

%-------------------------------------------------------------------------

\subsection{Response length}
Author responses must be no longer than 1 page in length including any references and figures.  Overlength responses will simply not be reviewed.  This includes responses where the margins and formatting are deemed to have been significantly altered from those laid down by this style guide.  Note that this \LaTeX\ guide already sets figure captions and references in a smaller font.

%------------------------------------------------------------------------
\section{Formatting your Response}

{\bf Make sure to update the paper title and paper ID in the appropriate place in the tex file.}

All text must be in a two-column format. The total allowable width of the text
area is $6\frac78$ inches (17.5 cm) wide by $8\frac78$ inches (22.54 cm) high.
Columns are to be $3\frac14$ inches (8.25 cm) wide, with a $\frac{5}{16}$ inch
(0.8 cm) space between them. The top margin should begin
1.0 inch (2.54 cm) from the top edge of the page.  The bottom margin should be
1-1/8 inches (2.86 cm) from the bottom edge of the page for $8.5 \times
11$-inch paper; for A4 paper, approximately 1-5/8 inches (4.13 cm) from the
bottom edge of the page.

Please number all of your sections and any displayed equations.  It is important
for readers to be able to refer to any particular equation.

Wherever Times is specified, Times Roman may also be used.  Main text should be
in 10-point Times, single-spaced. Section headings should be in 10 or 12 point
Times.  All paragraphs should be indented 1 pica (approx. 1/6 inch or 0.422
cm).  Figure and table captions should be 9-point Roman type as in
Figure~\ref{fig:onecol}.

%-------------------------------------------------------------------------
\subsection{References}

List and number all bibliographical references in 9-point Times, single-spaced,
at the end of your response. When referenced in the text, enclose the citation
number in square brackets, for example~\cite{Authors14}.  Where appropriate,
include the name(s) of editors of referenced books.

% Figure environment removed

%-------------------------------------------------------------------------
\subsection{Illustrations, graphs, and photographs}

All graphics should be centered.  Please ensure that any point you wish to make is resolvable in a printed copy of the response.  Resize fonts in figures to match the font in the body text, and choose line widths which render effectively in print.  Many readers (and reviewers), even of an electronic copy, will choose to print your response in order to read it.  You cannot insist that they do otherwise, and therefore must not assume that they can zoom in to see tiny details on a graphic.

When placing figures in \LaTeX, it's almost always best to use \verb+\includegraphics+, and to specify the  figure width as a multiple of the line width as in the example below
{\small\begin{verbatim}
   \usepackage[dvips]{graphicx} ...
   \includegraphics[width=0.8\linewidth]
                   {myfile.eps}
\end{verbatim}
}
\end{comment}

\vspace{-0.3 cm}
{%\small
%\scriptsize
%\tiny
\fontsize{5.7}{5.7} \selectfont
\bibliographystyle{ieee}
%\vspace{-0.3 cm}
\bibliography{mybibfile}
\vspace{-0.3 cm}
}

\end{document}
