% Generated by IEEEtran.bst, version: 1.14 (2015/08/26)
\begin{thebibliography}{10}
\providecommand{\url}[1]{#1}
\csname url@samestyle\endcsname
\providecommand{\newblock}{\relax}
\providecommand{\bibinfo}[2]{#2}
\providecommand{\BIBentrySTDinterwordspacing}{\spaceskip=0pt\relax}
\providecommand{\BIBentryALTinterwordstretchfactor}{4}
\providecommand{\BIBentryALTinterwordspacing}{\spaceskip=\fontdimen2\font plus
\BIBentryALTinterwordstretchfactor\fontdimen3\font minus \fontdimen4\font\relax}
\providecommand{\BIBforeignlanguage}[2]{{%
\expandafter\ifx\csname l@#1\endcsname\relax
\typeout{** WARNING: IEEEtran.bst: No hyphenation pattern has been}%
\typeout{** loaded for the language `#1'. Using the pattern for}%
\typeout{** the default language instead.}%
\else
\language=\csname l@#1\endcsname
\fi
#2}}
\providecommand{\BIBdecl}{\relax}
\BIBdecl

\bibitem{goodfellow2014generative}
I.~Goodfellow, J.~Pouget-Abadie, M.~Mirza, B.~Xu, D.~Warde-Farley, S.~Ozair, A.~Courville, and Y.~Bengio, ``Generative adversarial nets,'' \emph{Advances in Neural Information Processing Systems (NeurIPS)}, vol.~27, 2014.

\bibitem{kingma2014auto}
D.~P. Kingma and M.~Welling, ``Auto-encoding variational bayes,'' \emph{stat}, vol. 1050, p.~1, 2014.

\bibitem{nguyen2019deep}
T.~T. Nguyen, Q.~V.~H. Nguyen, C.~M. Nguyen, D.~Nguyen, D.~T. Nguyen, and S.~Nahavandi, ``Deep learning for deepfakes creation and detection: A survey,'' \emph{arXiv preprint arXiv:1909.11573}, 2019.

\bibitem{liu2023deepfacelab}
K.~Liu, I.~Perov, D.~Gao, N.~Chervoniy, W.~Zhou, and W.~Zhang, ``Deepfacelab: integrated, flexible and extensible face-swapping framework,'' \emph{Pattern Recognition}, p. 109628, 2023.

\bibitem{gupta2023towards}
A.~Gupta, R.~Mukhopadhyay, S.~Balachandra, F.~F. Khan, V.~P. Namboodiri, and C.~Jawahar, ``Towards generating ultra-high resolution talking-face videos with lip synchronization,'' in \emph{IEEE Winter Conference on Applications of Computer Vision (WACV)}, 2023, pp. 5209--5218.

\bibitem{akhtar2023deepfakes}
Z.~Akhtar, ``Deepfakes generation and detection: A short survey,'' \emph{Journal of Imaging}, vol.~9, no.~1, p.~18, 2023.

\bibitem{pantserev2020malicious}
K.~A. Pantserev, ``The malicious use of ai-based deepfake technology as the new threat to psychological security and political stability,'' \emph{Cyber defence in the age of AI, smart societies and augmented humanity}, pp. 37--55, 2020.

\bibitem{zhao2021multi}
H.~Zhao, W.~Zhou, D.~Chen, T.~Wei, W.~Zhang, and N.~Yu, ``Multi-attentional deepfake detection,'' in \emph{IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}, 2021, pp. 2185--2194.

\bibitem{li2020face}
L.~Li, J.~Bao, T.~Zhang, H.~Yang, D.~Chen, F.~Wen, and B.~Guo, ``Face x-ray for more general face forgery detection,'' in \emph{IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}, 2020, pp. 5001--5010.

\bibitem{qian2020thinking}
Y.~Qian, G.~Yin, L.~Sheng, Z.~Chen, and J.~Shao, ``Thinking in frequency: Face forgery detection by mining frequency-aware clues,'' in \emph{European Conference on Computer Vision (ECCV)}.\hskip 1em plus 0.5em minus 0.4em\relax Springer, 2020, pp. 86--103.

\bibitem{luo2021generalizing}
Y.~Luo, Y.~Zhang, J.~Yan, and W.~Liu, ``Generalizing face forgery detection with high-frequency features,'' in \emph{IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}, 2021, pp. 16\,317--16\,326.

\bibitem{li2021frequency}
J.~Li, H.~Xie, J.~Li, Z.~Wang, and Y.~Zhang, ``Frequency-aware discriminative feature learning supervised by single-center loss for face forgery detection,'' in \emph{IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}, 2021, pp. 6458--6467.

\bibitem{qiao2018statistical}
T.~Qiao, R.~Shi, X.~Luo, M.~Xu, N.~Zheng, and Y.~Wu, ``Statistical model-based detector via texture weight map: Application in re-sampling authentication,'' \emph{IEEE Transactions on Multimedia (TMM)}, vol.~21, no.~5, pp. 1077--1092, 2018.

\bibitem{chen2020serial}
B.~Chen, W.~Tan, G.~Coatrieux, Y.~Zheng, and Y.-Q. Shi, ``A serial image copy-move forgery localization scheme with source/target distinguishment,'' \emph{IEEE Transactions on Multimedia (TMM)}, vol.~23, pp. 3506--3517, 2020.

\bibitem{asnani2021reverse}
V.~Asnani, X.~Yin, T.~Hassner, and X.~Liu, ``Reverse engineering of generative models: Inferring model hyperparameters from generated images,'' \emph{arXiv preprint arXiv:2106.07873}, 2021.

\bibitem{gu2022exploiting}
Q.~Gu, S.~Chen, T.~Yao, Y.~Chen, S.~Ding, and R.~Yi, ``Exploiting fine-grained face forgery clues via progressive enhancement learning,'' in \emph{AAAI Conference on Artificial Intelligence (AAAI)}, vol.~36, no.~1, 2022, pp. 735--743.

\bibitem{wu2023interactive}
J.~Wu, B.~Zhang, Z.~Li, G.~Pang, Z.~Teng, and J.~Fan, ``Interactive two-stream network across modalities for deepfake detection,'' \emph{IEEE Transactions on Circuits and Systems for Video Technology (TCSVT)}, 2023.

\bibitem{guo2023rethinking}
Z.~Guo, G.~Yang, D.~Zhang, and M.~Xia, ``Rethinking gradient operator for exposing ai-enabled face forgeries,'' \emph{Expert Systems with Applications}, vol. 215, p. 119361, 2023.

\bibitem{yang2021faceguard}
Y.~Yang, C.~Liang, H.~He, X.~Cao, and N.~Z. Gong, ``Faceguard: Proactive deepfake detection,'' \emph{arXiv preprint arXiv:2109.05673}, 2021.

\bibitem{wang2021faketagger}
R.~Wang, F.~Juefei-Xu, M.~Luo, Y.~Liu, and L.~Wang, ``Faketagger: Robust safeguards against deepfake dissemination via provenance tracking,'' in \emph{ACM International Conference on Multimedia (ACMMM)}, 2021, pp. 3546--3555.

\bibitem{yu2021artificial}
N.~Yu, V.~Skripniuk, S.~Abdelnabi, and M.~Fritz, ``Artificial fingerprinting for generative models: Rooting deepfake attribution in training data,'' in \emph{IEEE International Conference on Computer Vision (ICCV)}, 2021, pp. 14\,448--14\,457.

\bibitem{asnani2022proactive}
V.~Asnani, X.~Yin, T.~Hassner, S.~Liu, and X.~Liu, ``Proactive image manipulation detection,'' in \emph{IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}, 2022, pp. 15\,386--15\,395.

\bibitem{yeh2020disrupting}
C.-Y. Yeh, H.-W. Chen, S.-L. Tsai, and S.-D. Wang, ``Disrupting image-translation-based deepfake algorithms with adversarial attacks,'' in \emph{IEEE Winter Conference on Applications of Computer Vision Workshops (WCACV)}, 2020, pp. 53--62.

\bibitem{ruiz2020disrupting}
N.~Ruiz, S.~A. Bargal, and S.~Sclaroff, ``Disrupting deepfakes: Adversarial attacks against conditional image translation networks and facial manipulation systems,'' in \emph{ECCV Workshops}, 2020, pp. 236--251.

\bibitem{segalis2020ogan}
E.~Segalis and E.~Galili, ``Ogan: Disrupting deepfakes with an adversarial attack that survives training,'' \emph{arXiv preprint arXiv:2006.12247}, 2020.

\bibitem{xue2022use}
M.~Xue, C.~Yuan, C.~He, Y.~Wu, Z.~Wu, Y.~Zhang, Z.~Liu, and W.~Liu, ``Use the spear as a shield: An adversarial example based privacy-preserving technique against membership inference attacks,'' \emph{IEEE Transactions on Emerging Topics in Computing(TETC)}, vol.~11, no.~1, pp. 153--169, 2022.

\bibitem{li2020celeb}
Y.~Li, X.~Yang, P.~Sun, H.~Qi, and S.~Lyu, ``Celeb-df: A large-scale challenging dataset for deepfake forensics,'' in \emph{IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}, 2020, pp. 3207--3216.

\bibitem{sun2022faketracer}
P.~Sun, Y.~Li, H.~Qi, and S.~Lyu, ``Faketracer: Exposing deepfakes with training data contamination,'' in \emph{IEEE International Conference on Image Processing (ICIP)}.\hskip 1em plus 0.5em minus 0.4em\relax IEEE, 2022, pp. 1161--1165.

\bibitem{liu2017unsupervised}
M.-Y. Liu, T.~Breuel, and J.~Kautz, ``Unsupervised image-to-image translation networks,'' \emph{Advances in Neural Information Processing Systems (NeurIPS)}, vol.~30, 2017.

\bibitem{karras2018progressive}
T.~Karras, T.~Aila, S.~Laine, and J.~Lehtinen, ``Progressive growing of gans for improved quality, stability, and variation,'' in \emph{International Conference on Learning Representations (ICLR)}, 2018.

\bibitem{karras2019style}
T.~Karras, S.~Laine, and T.~Aila, ``A style-based generator architecture for generative adversarial networks,'' in \emph{IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}, 2019, pp. 4401--4410.

\bibitem{peng2019cgr}
F.~Peng, L.-P. Yin, L.-B. Zhang, and M.~Long, ``Cgr-gan: Cg facial image regeneration for antiforensics based on generative adversarial network,'' \emph{IEEE Transactions on Multimedia (TMM)}, vol.~22, no.~10, pp. 2511--2525, 2019.

\bibitem{karras2020analyzing}
T.~Karras, S.~Laine, M.~Aittala, J.~Hellsten, J.~Lehtinen, and T.~Aila, ``Analyzing and improving the image quality of stylegan,'' in \emph{IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}, 2020, pp. 8110--8119.

\bibitem{agarwal2019protecting}
S.~Agarwal, H.~Farid, Y.~Gu, M.~He, K.~Nagano, and H.~Li, ``Protecting world leaders against deep fakes.'' in \emph{CVPR workshops}, vol.~1, 2019.

\bibitem{li2020identification}
H.~Li, B.~Li, S.~Tan, and J.~Huang, ``Identification of deep network generated images using disparities in color components,'' \emph{Signal Processing}, vol. 174, p. 107616, 2020.

\bibitem{afchar2018mesonet}
D.~Afchar, V.~Nozick, J.~Yamagishi, and I.~Echizen, ``Mesonet: a compact facial video forgery detection network,'' in \emph{2018 IEEE international workshop on information forensics and security (WIFS)}.\hskip 1em plus 0.5em minus 0.4em\relax IEEE, 2018, pp. 1--7.

\bibitem{wang2021representative}
C.~Wang and W.~Deng, ``Representative forgery mining for fake face detection,'' in \emph{IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}, 2021, pp. 14\,923--14\,932.

\bibitem{nataraj2019detecting}
L.~Nataraj, T.~M. Mohammed, B.~Manjunath, S.~Chandrasekaran, A.~Flenner, J.~H. Bappy, and A.~K. Roy-Chowdhury, ``Detecting gan generated fake images using co-occurrence matrices,'' \emph{Electronic Imaging}, vol. 2019, no.~5, pp. 532--1, 2019.

\bibitem{hernandez2020DeepFakeson}
J.~Hernandez-Ortega, R.~Tolosana, J.~Fierrez, and A.~Morales, ``Deepfakeson-phys: Deepfakes detection based on heart rate estimation,'' \emph{arXiv preprint arXiv:2010.00400}, 2020.

\bibitem{ciftci2020fakecatcher}
U.~A. Ciftci, I.~Demir, and L.~Yin, ``Fakecatcher: Detection of synthetic portrait videos using biological signals,'' \emph{IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)}, 2020.

\bibitem{zhao2021learning}
T.~Zhao, X.~Xu, M.~Xu, H.~Ding, Y.~Xiong, and W.~Xia, ``Learning self-consistency for deepfake detection,'' in \emph{IEEE International Conference on Computer Vision (ICCV)}, 2021, pp. 15\,023--15\,033.

\bibitem{zhang2018unreasonable}
R.~Zhang, P.~Isola, A.~A. Efros, E.~Shechtman, and O.~Wang, ``The unreasonable effectiveness of deep features as a perceptual metric,'' in \emph{IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}, 2018, pp. 586--595.

\bibitem{wang2020cnn}
S.-Y. Wang, O.~Wang, R.~Zhang, A.~Owens, and A.~A. Efros, ``Cnn-generated images are surprisingly easy to spot... for now,'' in \emph{IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}, 2020, pp. 8695--8704.

\end{thebibliography}
