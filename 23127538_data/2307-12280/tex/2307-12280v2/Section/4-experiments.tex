\section{Experiments}

\subsection{Experimental Setting}

 \noindent\textbf{Datasets and Models.} We use the publicly available pre-trained encoders from \emph{solo-learn}~\cite{JMLR:v23:21-1155}, an established SSL library, as victim encoders. 
 All the encoders are pre-trained on ImageNet~\cite{russakovsky2015imagenet} or CIFAR10~\cite{krizhevsky2009learning} with ResNet18 backbone. 
 For a comprehensive study, we  select fourteen SSL methods (Barlow Twins\cite{zbontar2021barlow}, BYOL\cite{grill2020bootstrap}, DeepCluster v2\cite{caron2020unsupervised}, DINO\cite{caron2021emerging},  MoCo v2+\cite{chen2020improved}, MoCo v3 \cite{chen2021empirical}, NNCLR\cite{dwibedi2021little}, ReSSL\cite{zheng2021ressl}, SimCLR \cite{chen2020simple}, SupCon\cite{khosla2020supervised}, SwAV\cite{caron2020unsupervised}, VIbCReg\cite{lee2021vibcreg}, VICReg\cite{bardes2021vicreg}, W-MSE\cite{ermolov2021whitening}). We make no strong assumptions about the attacker's knowledge, so we set the attacker's surrogate dataset to be CIFAR10 as the default setting. For different downstream tasks, we use the following four image datasets: STL10~\cite{coates2011analysis}, GTSRB~\cite{stallkamp2012man},  CIFAR10, and ImageNet.  


\noindent\textbf{Evaluation Metrics.} We use \textit{Malicious Accuracy} (MA) and \textit{Attack Success Rate} (ASR) to evaluate the attack performance of our AdvEncoder. 
MA denotes the accuracy of adversarial examples being correctly classified, and ASR indicates the attack success rate.


 % Figure environment removed




% Table generated by Excel2LaTeX from sheet 'Sheet2'
\begin{table*}[htbp]
\setlength{\abovecaptionskip}{2pt}
  \centering
  \caption{The ASR (\%) of Adv-PER under different settings.
  $\mathcal{S}_{1}$ - $\mathcal{S}_{4}$ denote the settings where the downstream datasets are CIFAR10, STL10, GTSRB, ImageNet, respectively, and all the attacker’s surrogate dataset is CIFAR10. $\mathcal{S}_{5}$ -  $\mathcal{S}_{8}$ use ImageNet as the attacker’s surrogate dataset, with the downstream datasets remained the same as $\mathcal{S}_{1}$ - $\mathcal{S}_{4}$. Barlow Twins and DeepCluster v2 are abbreviated as Barlow and DeepC2, respectively. }
  \scalebox{0.69}{
    \begin{tabular}{c|c|cccccccccccccc}
    \toprule[1.5pt]
    Dataset & Setting & Barlow & BYOL  & DeepC2   & DINO  & MoCo2+ & MoCo3 & NNCLR & ReSSL & SimCLR & SupCon & SwAV  & VIbCReg & VICReg & W-MSE \\
    \hline
     & $\mathcal{S}_{1}$    & 85.51  & 89.93  & 79.42  & 89.37  & 64.92  & \textbf{84.79}  & 88.48  & 87.85  & 57.07  & 93.62  & 87.71  & 87.15  & 90.04  & \textbf{89.26}  \\
   & $\mathcal{S}_{2}$    &  \textcolor[RGB]{169,169,169}{45.67}  & \textcolor[RGB]{169,169,169}{63.48}  &  \textcolor[RGB]{169,169,169}{58.25}  &  \textcolor[RGB]{169,169,169}{56.15}  &  \textcolor[RGB]{169,169,169}{32.08}  & 55.03  &  \textcolor[RGB]{169,169,169}{51.37}  &  \textcolor[RGB]{169,169,169}{51.60}  &  \textcolor[RGB]{169,169,169}{30.11}  &  \textcolor[RGB]{169,169,169}{71.88}  &  45.25  &  \textcolor[RGB]{169,169,169}{52.25}  &  \textcolor[RGB]{169,169,169}{68.38}  & \textcolor[RGB]{169,169,169}{55.10}  \\
    & $\mathcal{S}_{3}$    & 87.49  & 84.59  & 83.17  & 87.02  & \textbf{80.53}  & 80.40  & 91.09  & 92.73  & 69.30  & 91.26  & \textbf{92.11}  & 84.70  & 89.24  & 78.80  \\
          & $\mathcal{S}_{4}$    & 76.53  & 87.69  & 80.21  & 79.42  & 69.94  & 83.41  & 81.14  & 78.61  & 66.59  & 91.53  & 73.89  & 74.24  & 86.42  & 84.57  \\
       CIFAR10  & $\mathcal{S}_{5}$    & 90.46  & 85.94  & 87.42  & 89.99  & 58.00  & 76.44  & 90.10  & 88.23  & 72.20  & 89.43  & 72.28  & 89.41  & 89.03  & 78.87  \\
         & $\mathcal{S}_{6}$    & 85.85  & 74.93  & 88.96  & 70.64  & 33.51  &  \textcolor[RGB]{169,169,169}{43.35}  & 87.13  & 65.55  & 58.62  & 78.78  &  \textcolor[RGB]{169,169,169}{36.94}  & 80.44  & 74.89  & 60.68  \\
          & $\mathcal{S}_{7}$    & 97.19  & \textbf{95.52}  & 94.50  & \textbf{93.43}  & 79.59  & 82.98  & 91.59  & \textbf{93.45}  & \textbf{92.53}  & \textbf{95.96}  & 83.35  & 96.41  & \textbf{93.00}  & 73.07  \\
          & $\mathcal{S}_{8}$    & \textbf{97.42}  & 92.47  & \textbf{96.48}  & 90.31  & 69.60  & 75.19  & \textbf{96.30}  & 88.44  & 87.50  & 94.35  & 71.32  & \textbf{97.15}  & 90.93  & 82.74  \\
          & \textbf{AVG} & 83.26  & 84.32  & 83.55  & 82.04  & 61.02  & 72.70  & 84.65  & 80.81  & 66.74  & 88.35  & 70.36  & 82.72  & 85.24  & 75.39  \\

    \hline
     & $\mathcal{S}_{1}$    & 70.13  & 88.12  & \textbf{79.27}  & 83.29  & 82.33  & 72.52  & 70.91  & 87.86  & 71.94  & 76.37  & 84.00  & 82.77  & \textbf{82.51}  & 89.62  \\
          & $\mathcal{S}_{2}$    &  \textcolor[RGB]{169,169,169}{55.49}  &  \textcolor[RGB]{169,169,169}{58.67}  &  \textcolor[RGB]{169,169,169}{45.29}  &  \textcolor[RGB]{169,169,169}{61.67}  &  \textcolor[RGB]{169,169,169}{53.22}  &  \textcolor[RGB]{169,169,169}{59.51}  &  \textcolor[RGB]{169,169,169}{53.00}  &  \textcolor[RGB]{169,169,169}{59.63}  &  \textcolor[RGB]{169,169,169}{55.87}  &  \textcolor[RGB]{169,169,169}{48.73}  &  \textcolor[RGB]{169,169,169}{55.22}  &  \textcolor[RGB]{169,169,169}{61.01}  &  \textcolor[RGB]{169,169,169}{57.95}  &  \textcolor[RGB]{169,169,169}{67.96}  \\
           & $\mathcal{S}_{3}$    & 74.18  & 73.75  & 68.10  & 67.65  & 70.89  & 68.05  & 67.73  & 82.39  & 64.30  & 66.19  & 69.51  & 78.18  & 78.65  & 76.72  \\
           & $\mathcal{S}_{4}$    & 71.84  & 75.44  & 73.29  & 75.83  & 74.01  & 65.51  & 68.85  & 76.18  & 71.52  & 69.65  & 74.41  & 72.57  & 77.60  & 83.59  \\
         ImageNet & $\mathcal{S}_{5}$    & \textbf{87.94}  & \textbf{88.94}  & 77.28  & \textbf{83.97}  & \textbf{86.95}  & 76.11  & \textbf{86.32}  & \textbf{89.69}  & \textbf{88.95}  & \textbf{78.18}  & \textbf{86.54}  & \textbf{84.50}  & 81.64  & \textbf{90.61}  \\
         & $\mathcal{S}_{6}$    & 69.35  &  64.76  & 57.81  & 64.16  & 56.13  & 60.49  & 65.75  & 67.33  & 70.08  & 55.90  & 60.14  & 70.04  & 58.28  & 80.05  \\
         & $\mathcal{S}_{7}$    & 78.59  & 78.45  & 69.38  & 70.83  & 80.62  & \textbf{77.67}  & 74.05  & 86.13  & 83.70  & 69.05  & 81.17  & 81.65  & 79.76  & 85.56  \\
          & $\mathcal{S}_{8}$    & 80.02  & 80.28  & 77.48  & 77.52  & 76.74  & 75.72  & 74.73  & 81.36  & 79.68  & 71.01  & 80.20  & 80.33  & 78.32  & 90.03  \\
       & \textbf{AVG} & 73.44  & 76.05  & 68.49  & 73.12  & 72.61  & 69.45  & 70.17  & 78.82  & 73.26  & 66.88  & 73.90  & 76.38  & 74.34  & 83.02  \\
   \bottomrule[1.5pt]
    %  \vspace{-2mm}
    \end{tabular}%
}
  \label{tab:attack_performance_per}%
  
\end{table*}%


% Table generated by Excel2LaTeX from sheet 'Sheet2'
\begin{table*}[htbp]
\setlength{\abovecaptionskip}{2pt}
  \centering
  \caption{The ASR (\%) of Adv-PAT under different settings. $\mathcal{S}_{1}$ - $\mathcal{S}_{8}$ represent the same settings as mentioned in \cref{tab:attack_performance_per}.}
   \scalebox{0.69}{
    \begin{tabular}{c|c|cccccccccccccc}
    \toprule[1.5pt]
    Dataset & Setting & Barlow & BYOL  & DeepC2   & DINO  & MoCo2+ & MoCo3 & NNCLR & ReSSL & SimCLR & SupCon & SwAV  & VIbCReg & VICReg & W-MSE \\
    \hline
    & $\mathcal{S}_{1}$    & \textcolor[RGB]{169,169,169}{82.32}  & 88.20  & 90.88  & 81.77  &  \textcolor[RGB]{169,169,169}{81.52}  & 89.71  & 74.44  &  \textcolor[RGB]{169,169,169}{61.46}  & 89.87  & 69.19  & 89.31  & 63.32  & 82.15  & 89.13  \\
            & $\mathcal{S}_{2}$    & 88.16  &  \textcolor[RGB]{169,169,169}{80.08}  &  \textcolor[RGB]{169,169,169}{89.55}  & 77.95  & 84.03  &  \textcolor[RGB]{169,169,169}{82.10}  & 71.74  & 73.23  & 89.38  &  \textcolor[RGB]{169,169,169}{66.48}  &  \textcolor[RGB]{169,169,169}{85.60}  & 66.56  &  \textcolor[RGB]{169,169,169}{79.54}  & 82.56  \\
             & $\mathcal{S}_{3}$    & 93.89  & 92.02  & 94.43  & 89.98  & 98.40  & 90.21  & 89.84  & 89.15  & 96.22  & 91.19  & 97.09  & 89.88  & 90.65  & 89.22  \\
             & $\mathcal{S}_{4}$    & \textbf{97.86}  & 95.61  & 99.68  & 97.32  & 98.49  & 97.01  & 94.81  & 96.51  & \textbf{99.05}  & \textbf{96.81}  & \textbf{98.51}  & \textbf{96.25}  & 95.56  & \textbf{96.88}  \\
             CIFAR10 & $\mathcal{S}_{5}$    & 87.14  & 88.44  & 90.88  & 82.20  & 84.64  & 90.28  &  \textcolor[RGB]{169,169,169}{67.74}  & 66.53  & 89.90  & 76.34  & 89.31  & 62.79  & 84.68  & 89.25  \\
             & $\mathcal{S}_{6}$    & 88.00  & 86.12  & 89.71  &  \textcolor[RGB]{169,169,169}{76.61}  & 84.34  & 84.88  & 73.12  & 72.96  &  \textcolor[RGB]{169,169,169}{89.31}  & 67.63  & 86.84  &  \textcolor[RGB]{169,169,169}{56.24}  & 79.74  &  \textcolor[RGB]{169,169,169}{82.52}  \\
             & $\mathcal{S}_{7}$    & 93.91  & 91.76  & 94.69  & 87.15  & \textbf{99.20}  & 93.58  & 90.08  & 92.50  & 96.19  & 91.19  & 97.09  & 91.01  & 92.40  & 90.10  \\
             & $\mathcal{S}_{8}$    & 96.14  & \textbf{97.73}  & \textbf{99.69}  & \textbf{97.83}  & 98.40  & \textbf{98.44}  & \textbf{96.48}  & \textbf{98.11}  & \textbf{99.05}  & 96.27  & 98.03  & 95.28  & \textbf{96.65}  & 96.51  \\
           & \textbf{AVG}   & 90.93  & 89.99  & 93.69  & 86.35  & 91.13  & 90.78  & 82.28  & 81.31  & 93.62  & 81.89  & 92.72  & 77.67  & 87.67  & 89.52  \\
    \hline
    & $\mathcal{S}_{1}$    & 88.17  & 90.14  &  \textcolor[RGB]{169,169,169}{89.22}  & 89.41  &  \textcolor[RGB]{169,169,169}{89.90}  & 90.02  &  \textcolor[RGB]{169,169,169}{88.80}  & 92.01  & 90.30  & 90.50  &  \textcolor[RGB]{169,169,169}{90.06}  &  \textcolor[RGB]{169,169,169}{89.04}  & 89.49  & 91.21  \\
             & $\mathcal{S}_{2}$    &  \textcolor[RGB]{169,169,169}{82.35}  &  \textcolor[RGB]{169,169,169}{88.60}  & 89.98  &  \textcolor[RGB]{169,169,169}{89.07}  & 90.70  & 91.56  & 88.86  & 91.20  & 89.42  &  \textcolor[RGB]{169,169,169}{90.27}  & 90.48  & 89.66  & 85.14  &  \textcolor[RGB]{169,169,169}{89.86}  \\
            & $\mathcal{S}_{3}$    & 95.12  & \textbf{99.29}  & 96.89  & 94.67  & 94.01  & \textbf{98.49}  & 98.36  & 91.30  & 94.33  & 94.32  & 97.08  & 96.82  & 94.09  & 99.09  \\
             & $\mathcal{S}_{4}$    & \textbf{99.09}  & 98.18  & 99.16  & \textbf{98.79}  & \textbf{98.64}  & 98.29  & 98.34  & \textbf{98.51}  & \textbf{99.02}  & \textbf{99.10}  & 98.61  & \textbf{98.59}  & 98.56  & 98.51  \\
            ImageNet  & $\mathcal{S}_{5}$    & 89.00  & 90.14  &   \textcolor[RGB]{169,169,169}{89.22}  & 89.41  &  \textcolor[RGB]{169,169,169}{89.90}  &  \textcolor[RGB]{169,169,169}{88.83}  & 88.81  & 92.01  & 90.30  & 90.50  &  \textcolor[RGB]{169,169,169}{90.06}  &  \textcolor[RGB]{169,169,169}{89.04}  & 89.33  & 91.22  \\
             & $\mathcal{S}_{6}$    & 83.09  & 90.11  & 89.98  & 89.56  & 90.70  & 91.55  & 88.86  & 91.19  &  \textcolor[RGB]{169,169,169}{89.39}  & 90.70  & 90.38  & 90.78  &  \textcolor[RGB]{169,169,169}{84.42}  &  \textcolor[RGB]{169,169,169}{89.86}  \\
             & $\mathcal{S}_{7}$    & 95.37  & 95.64  & 97.38  & 93.18  & 91.19  & 98.20  & 98.36  &  \textcolor[RGB]{169,169,169}{90.19}  & 94.33  & 92.65  & 97.08  & 96.82  & 96.31  & \textbf{99.18}  \\
            & $\mathcal{S}_{8}$    & 98.89  & 98.19  & \textbf{99.21}  & 98.62  & \textbf{98.64}  & 98.47  & \textbf{98.70}  & 98.45  & \textbf{99.02} & 98.98  & \textbf{98.71}  & \textbf{98.59}  & \textbf{98.75}  & 98.47  \\
           & \textbf{AVG}   & 91.39  & 93.79  & 93.88  & 92.84  & 92.96  & 94.43  & 93.63  & 93.11  & 93.26  & 93.38  & 94.06  & 93.67  & 92.01  & 94.67  \\
    \bottomrule[1.5pt]
    \end{tabular}%
    }
  \label{tab:attack_performance_pat}%
 % \vspace{0.8cm}
\end{table*}%


\begin{table}[!h]
% \vspace{-3mm}
\setlength{\abovecaptionskip}{2pt}
% \setlength{\belowcaptionskip}{0pt}
  \centering
  \caption{Top-10 retrieval attack results. ``per-mAP'' represents the retrieval accuracy of the Adv-PER samples corresponding to clean samples, while ``pat-mAP'' denotes the accuracy of Adv-PAT samples.}
    \scalebox{0.65}{
    \begin{tabular}{c|c|c|c|c|c|c|c}
    \toprule[1.5pt]
      Dataset    & Metric & Barlow & BYOL  & DINO  & MoCo v2+ & NNCLR & SimCLR \\
     \hline
  \multirow{3}[2]{*}{STL10} & map   & 81.03 & 79.02 & 79.58 & 63.24 & 76.15 & 73.58 \\
          & per\_map & 23.26 & 21.76 & 22.95 & 22.77 & 24.99 & 21.76 \\
          & pat\_map & 21.15 & 19.64 & 21.12 & 26.89 & 26.22 & 23.59 \\
         \hline
    \multirow{3}[2]{*}{GTSRB} & map   & 93.92 & 85.68 & 88.49 & 84.37 & 83.83 & 88.53 \\
          & per\_map & 42.81 & 45.81 & 30.72 & 38.93 & 36.14 & 45.56 \\
          & pat\_map & 11.63 & 10.07 & 10.17 & 11.75 & 11.66 & 13.63 \\
    \bottomrule[1.5pt]
    \end{tabular}%
    }
  \label{tab:retrieval}%
   \vspace{-4mm}
\end{table}%



\subsection{Attack Performance }\label{sec:attack-performance}
\noindent\textbf{Implementation Details.} To demonstrate the effectiveness of AdvEncoder when the downstream task is unknowable, two types of downstream tasks, \emph{image classification} and \emph{image retrieval}, are chosen for testing.
Following~\cite{hu2021advhash,moosavi2017universal, mopuri2018nag}, we set $\epsilon$ (\ie, the perturbation budget of Adv-PER) to $10/255$ and the patch size (\ie, noise percentage of each sample) of  Adv-PAT to $0.03$.
We choose the bottom right corner of the image, which is not easily visible, to apply the patch. We set the hyper-parameters $\alpha= 1$, $\beta = 5$, $\lambda = 1$ and the training epoch to $20$ with batch size of $256$. 
The generator network is trained by Adam optimizer with the initial learning rate $0.0002$.


For the classification task, we attack fourteen types of SSL pre-trained encoders.
We evaluate AdvEncoder on each victim pre-trained encoder over four downstream tasks using two attacker's surrogate datasets, respectively.
As for the retrieval task, 
we attack six types of SSL encoders trained on CIFAR10 corresponding to the retrieval tasks of GTSRB and STL10.
We use mAP (\emph{mean average precision})~\cite{zuva2012evaluation}  to measure  the retrieval accuracy, and adapt per-mAP and pat-mAP to measure the retrieval accuracy for adversarial examples.
Adversarial examples generated by AdvEncoder are shown in~\cref{fig:demo}.


\noindent\textbf{Analysis.} Our experimental results on classification tasks reveal the severe vulnerability of downstream tasks based on pre-trained encoders.
Firstly, from \cref{tab:attack_performance_per} and \cref{tab:attack_performance_pat}, we can see that among the 224 attack settings, both Adv-PER and Adv-PAT perform well on all downstream tasks. In particular, Adv-PAT has a consistently high attack performance under different settings, with an average ASR of over 90\%.
Secondly, the attacker's surrogate dataset has an impact on the attack performance,  \eg, the ImageNet surrogate dataset outperforms CIFAR10. 
AdvEncoder performs better when the attacker's surrogate dataset is similar to the pre-training dataset and downstream dataset.
Thirdly, among the fourteen training methods, MoCo, SimCLR are more robust for adversarial examples, while BYOL, NNCLR, and SupCon are relatively weaker.
The  experimental results on image retrieval tasks in~\cref{tab:retrieval} also show that the adversarial examples generated by AdvEncoder can greatly affect the retrieval accuracy under different settings. 


% Figure environment removed



\subsection{Ablation Study} \label{sec:ablation}
In this section, we explore the effect of different  attacker’s surrogate datasets, modules, and attack strengths on AdvEncoder.
We choose encoders trained on ImageNet and select CIFAR10 as the surrogate and downstream dataset.


\noindent\textbf{The Effect of Amount of Surrogate Data.} 
We investigate the effect of the limited sample size of the attacker's surrogate dataset.
Specifically, we randomly select different numbers of CIFAR10 samples to constitute the surrogate dataset and choose SimCLR and MoCo v2+ encoders for the attack.
The results in \cref{fig:ablation results}(a) - (b) show that the performance of Adv-PER generally improves with the increase of the number of samples.
For Adv-PAT, it performs well with different numbers of surrogate dataset settings.

\noindent\textbf{The Effect of HFC \& $\mathcal{G}$.} 
We analyze the effect of the HFC module and the generator module on the effectiveness of the scheme.
 We choose the downstream dataset as STL10.
In \cref{fig:ablation results}(c) - (d), Opt-PER and  Opt-PAT represent optimization-based versions of the same loss function, ``$*$'' denotes the version without HFC loss. Experimental results show that each module plays an important role.

\noindent\textbf{The Effect of $\epsilon$ \& Patch Size.} 
We study the effect of four different perturbation upper bound  $\epsilon$  and patch size on the attack performance of Adv-PER and Adv-PAT, respectively. 
From~\cref{fig:ablation results}(e), we can see that different pre-trained encoders have different sensitivities to different perturbation budgets.
The curves in~\cref{fig:ablation results}(f) show that the downstream tasks are more vulnerable to adversarial patches.



% Figure environment removed


 \subsection{Transferability Study}

In this section, we choose Adv-PER as a representative to analyze the transferability of our scheme from two perspectives, namely, crossing pre-training datasets and SSL methods. To this end, we conduct experiments using CIFAR10 as the attacker's surrogate dataset and GTSRB as the downstream dataset. 
In~\cref{fig:trans}(a) - (b), CIFAR10-ImageNet represents we use CIFAR10 and ImageNet to train two encoders based on which adversarial examples and downstream tasks are made, respectively. ImageNet-ImageNet has the same definition. 
Each column represents different downstream models attacked with the same adversarial examples.
The results indicate that the Adv-PER method can effectively transfer attacks across different pre-training datasets and SSL methods, even without any prior knowledge of the pre-training and downstream datasets.


% Table generated by Excel2LaTeX from sheet 'Sheet2'
\begin{table}[htbp]
% \setlength{\abovecaptionskip}{2pt}
  \centering
  \caption{The ASR (\%) of comparison study}
  \scalebox{0.69}{
    \begin{tabular}{c|c|c|c|c|c|c}
    \toprule[1.5pt]
    Method & Barlow & BYOL  & DINO  & MoCo v2+ & NNCLR & SimCLR \\
    \hline
    % Zero-PER & 17.55  & 18.37  & 17.71  & 19.64  & 23.69  & 17.58 \\
    UAP~\cite{moosavi2017universal}   & 48.95  & 45.97  & 43.01  & 42.24  & 46.41  & 48.41  \\
    UPGD~\cite{deng2020universal} & 18.31  & 23.89  & \textcolor[RGB]{169,169,169}{18.59}  & 18.31  & \textcolor[RGB]{169,169,169}{17.57}  & 20.83  \\
    FFF~\cite{mopuri2017fast}  & 47.71  & 50.26  & 45.53  & 50.33  & 46.64  & 52.33 \\
    SSP~\cite{naseer2020self}   & 50.40  & 46.30  & 47.12  & 50.87  & 49.51  & 48.06  \\
    NAG~\cite{mopuri2018nag}   & \textcolor[RGB]{169,169,169}{8.98}  & \textcolor[RGB]{169,169,169}{10.91}  & 26.22  & \textcolor[RGB]{169,169,169}{14.34}  & 24.49  & \textcolor[RGB]{169,169,169}{6.76}  \\
    PAP-base~\cite{ban2022pre}   & 37.89  & 27.29  & 25.52  & 30.47  & 24.65  & 46.89 \\
    PAP-fuse~\cite{ban2022pre}   & 46.61  & 45.47  & 30.26  & 45.14  & 40.05  & 46.30 \\
    PAP-ugs~\cite{ban2022pre}   & 38.20  & 36.89  & 30.55  & 37.71  & 42.99  & 53.56  \\
    Adv-PER  & \textbf{55.49}  & \textbf{58.67}  & \textbf{61.67}  & \textbf{53.22}  & \textbf{53.00}  & \textbf{55.87}  \\
    \hline
    % Zero-PAT & 17.55  & 18.37  & 17.71  & 19.64  & 23.69  & 17.58 \\
    UA-PAT~\cite{brown2017adversarial} & \textcolor[RGB]{169,169,169}{58.20}  & \textcolor[RGB]{169,169,169}{34.62}  & \textcolor[RGB]{169,169,169}{46.12}  & \textcolor[RGB]{169,169,169}{79.04}  & \textcolor[RGB]{169,169,169}{49.73}  & \textcolor[RGB]{169,169,169}{50.35}  \\
    % Adv-PAT* & \textbf{82.82}  & 86.84  & 86.65  & \textbf{90.70}  & \textbf{88.86}  & \textbf{90.60} \\
    Adv-PAT & 82.35  & \textbf{88.60}  & \textbf{89.07}  & \textbf{90.70}  & \textbf{88.86}  & \textbf{89.42}  \\
    \bottomrule[1.5pt]
    \end{tabular}
}
  \label{tab:comparision}%
  % \vspace{-0.6cm}

\end{table}%

\subsection{Comparison Study}
\noindent\textbf{Implementation Details.} 
In this section, 
we compare Adv-Encoder with state-of-the-art adversarial attacks. 
PAP~\cite{ban2022pre} is the most similar work  with ours as it produces pre-trained perturbations from the perspective of model feature activation values. In contrast, we address the  attack inheritance of adversarial samples by directly changing the important 
 texture features of the samples themselves.
To further demonstrate our superiority, for perturbation we compare with classic optimized-based UAP schemes (\eg, UAP~\cite{moosavi2017universal}, UPGD~\cite{deng2020universal}, FFF~\cite{mopuri2017fast}, SSP~\cite{naseer2020self}, and PAP~\cite{ban2022pre}) and generative-based UAP scheme (\eg,  NAG~\cite{mopuri2018nag}).
For patch, we compare Adv-PAT with UA-PAT~\cite{brown2017adversarial}, an optimization-based adversarial patch method, which maintains the same experimental setup as the Adv-Encoder. 
Since the above supervised learning adversarial attacks can not be directly applied to attack the pre-trained encoder, 
we enable those UAP schemes to have complete pre-trained model (i.e., encoder connected with classification head trained under the same pre-training dataset).
For a comprehensive comparison under the pre-trained encoder to downstream task paradigm, we choose six encoders trained on ImageNet with CIFAR10 for the attacker’s surrogate dataset and STL10 for the downstream dataset.


\noindent\textbf{Analysis.} 
From \cref{tab:comparision}, we can see that AdvEncoder outperforms the other solutions without knowing the pre-training dataset and the downstream dataset.
Adv-PER shows superior performance compared to optimization-based and generative-based methods. Furthermore, AdvEncoder achieves better overall attack performance than the most relevant existing work, PAP, across six pre-trained encoders. Notably, Adv-PAT outperforms UA-PAT with an average ASR of over 85\%. Importantly, our method achieves these results without requiring additional classification headers, and instead directly leverages the pre-trained encoders for the attack. 



% Figure environment removed


\section{Defense}
In this section, we tailor four defensive measures trying to mitigate AdvEncoder from the perspective of the user and the model provider, respectively.
For users using pre-trained encoders, we adopt pre-processing the input data, fine-tuning the entire model using a small amount of data, and pruning the parameters to defend against adversarial attacks.
As for the model providers, the defender can perform adversarial training on pre-trained encoders.
In the following experiments, we use the default settings from \cref{sec:ablation}. 

\subsection{Corruption}
We defend against adversarial examples by corrupting the images through adding different degree of Gaussian noise to the samples. As illustrated in ~\cref{fig:defense}(a), 
the accuracy of the model decreases significantly as the degree of Gaussian noise added increases. 
In particular, Adv-PER only experiences a slight decrease in accuracy when the degree of Gaussian noise is increased to 0.03, while Adv-PAT is almost unaffected. 
% Adv-PER  starts to decrease slightly only when it is increased to 0.03, while Adv-PAT is almost unaffected.
These findings indicate that Adv-Encoder can effectively resist the corruption-based pre-processing defense.


\subsection{Fine-tuning \& Pruning}
% \noindent\textbf{Fine-tuning \& Pruning.} 
Fine-tuning~\cite{peng2022fingerprinting} and pruning~\cite{zhu2017prune} are two commonly used methods for downstream models to inherit pre-trained encoders, 
providing better adaptability to downstream tasks.
We first  
fully fine-tune pre-trained encoders based on MoCo v2+, using ten classes in CIFAR10, STL10, GSTRB, and ImageNet, respectively.
The results in ~\cref{fig:defense}(b) - (c) show that AdvEncoder still has excellent attack performance even after the encoder is fully fine-tuned.
Furthermore, 
we choose pruning rate in  $[0.1, 0.7]$, the results in~\cref{fig:defense}(d) show that AdvEncoder is able to resist the defenses based on model parameter pruning.
 

% \subsection{In-processing Defense}
\subsection{Adversarial Training}
% \noindent\textbf{Adversarial Training.} 
Adversarial training improves the robustness of the pre-trained encoder and poses a greater challenge to the adversarial examples.
Following~\cite{jiang2020robust}, we use the ImageNet dataset for adversarial training of the pre-trained encoder and choose CIFAR10 as downstream dateset. 
As demonstrated  in~\cref{fig:defense}(e) - (f),
we explore the degree of resistance to adversarial training for AdvEncoder of different attack strengths.
Adversarial training  slightly affects Adv-PER, but our attack can succeed after improving the attack strength. And Adv-PAT has not been affected at all.
