\section{Conclusion}
In this paper, we propose the first generative attack to construct downstream-agnostic adversarial examples in self-supervised learning. 
It is a flexible framework that can generate both universal adversarial perturbations and patches.
We verify the excellent attack performance of Adv-Encoder on four downstream tasks corresponding to fourteen publicly available SSL encoders over two pre-training datasets.
We tailor four popular defenses to mitigate Adv-Encoder. The results further prove the attack ability of AdvEncoder and highlight the needs of new defense mechanism to defend pre-trained encoders.

\noindent\textbf{Acknowledgments.} Shengshan's work is supported in part by the National Natural Science Foundation of China (Grant No.U20A20177) and Hubei Province Key R\&D Technology Special Innovation Project under Grant No.2021BAA032. 
Qian's work is supported in part by the National Natural Science Foundation of China under Grants U20B2049 and U21B2018.
Shengshan Hu is the corresponding author.