\appendix
\section{Appendix Contents}
\setcounter{table}{0}
\setcounter{figure}{0}
\renewcommand{\thetable}{A\arabic{table}}
\renewcommand{\thefigure}{A\arabic{figure}}

\begin{itemize}

\item Sec.~\ref{dataset}: 
Details of the datasets. 
% We provide details of the datasets and an explanation of how to use them in the main body.
\item Sec.~\ref{optimization}: 
Optimization procedure of AdvEncoder. 
We describe the optimization of our attack in detail.

\item Sec.~\ref{attack_performance}: 
Supplemental results of AdvEncoder's attack performance on \textbf{Image Classification \& Retrieval}, \textbf{Object Detection}, and  \textbf{Semantic Segmentation} tasks.


\item Sec.~\ref{ablation}: 
Supplemental ablation study about the effect of different backbones and random seeds on AdvEncoder.

\item Sec.~\ref{transferability}: 
Supplemental transferability results.


\item Sec.~\ref{Visualization}: 
Visualization of perturbations/patches generated by AdvEncoder.
\end{itemize} 



\section{Datasets}\label{dataset}

Our experiments are based on the following four datasets: CIFAR10~\cite{krizhevsky2009learning}, STL10~\cite{coates2011analysis}, GTSRB~\cite{stallkamp2012man}, and ImageNet~\cite{russakovsky2015imagenet}. 
Specifically, we use the above four datasets as the attacker’s surrogate datasets and the downstream datasets, respectively.
Following~\cite{jia2022badencoder}, we resize all examples to 64x64x3. The details of the datasets are as follows:

\noindent\textbf{CIFAR10.} CIFAR10 contains 50,000 training images and 10,000 testing images. Each image has a size of 32×32×3 and belongs to one of 10 classes. 

\noindent\textbf{STL10.} STL10 contains 5,000 labeled training images and 8,000 labeled testing images, each of which has a size of 96×96×3. Moreover, the dataset contains 10 classes and each image belongs to one of them.  

\noindent\textbf{GTSRB.} GTSRB contains 51,800 traffic sign images in 43 categories. Each image has a size of 32×32×3. The dataset is divided into 39,200 training images and 12,600 testing images. 

\noindent\textbf{ImageNet.} ImageNet contains $1.2M$ training samples and $50,000$ testing samples with $1000$ classes. Each image has a size of 256×256×3. We randomly select $100$ classes from ImageNet to build our dataset. 


\section{Optimization}\label{optimization}
In this section, we describe the optimization process of AdvEncoder in detail.
Given a random noise $z$, the generator generates a universal adversarial noise $\delta$ of the same size as the input image. 
We need to first crop the universal adversarial noise $\delta$ to within the imperceptibility constraint $\epsilon$. Then the universal adversarial noise can be converted into two forms of adversarial perturbation and adversarial patch by using \cref{eq:7} and \cref{eq:8}, respectively. 
By minimizing the objective function mentioned in \cref{eq:3}, we can optimize the generator to generate more generalized and transferable universal adversarial  perturbations or patches.
The whole optimization process is outlined in Algorithm.~\ref{optimization_advencoder}. 




% Table generated by Excel2LaTeX from sheet 'Sheet1'
\begin{table}[htbp]
\setlength{\abovecaptionskip}{2pt}
  \centering
   \caption{The clean retrieval accuracy (\%) of different downstream models based on pre-trained encoders over two datasets. PD denotes the pre-training dataset and DD represents the downstream dataset.}
      \scalebox{0.6375}{
    \begin{tabular}{c|c|c|c|c|c|c|c|c}
    \toprule[1.5pt]
    PD & DD & Model & top1  & top5  & top10 & top20 & top50 & top100 \\
    \hline
    \multirow{12}[4]{*}{CIFAR10} & \multirow{6}[2]{*}{STL10} & Barlow & 99.33  & 93.31  & 80.22  & 60.36  & 36.86  & 24.67 \\
          &       & BYOL  & 99.00  & 93.32  & 81.33  & 63.17  & 36.82  & 25.25 \\
          &       & DINO  & 100.00  & 93.62  & 82.79  & 64.45  & 38.72  & 25.67 \\
          &       & MoCo2+  & 99.67  & 93.74  & 82.74  & 63.56  & 37.21  & 25.4 \\
          &       & NNCLR & 100.00  & 94.21  & 82.83  & 63.99  & 36.34  & 25.01 \\
          &       & SimCLR & 99.67  & 94.45  & 80.55  & 62.16  & 38.06  & 25.28 \\
\cline{2-9}          & \multirow{6}[2]{*}{GTSRB} & Barlow & 96.67  & 97.43  & 96.39  & 94.52  & 92.38  & 90.42 \\
          &       & BYOL  & 95.33  & 94.65  & 92.24  & 89.66  & 85.99  & 82.54 \\
          &       & DINO  & 94.33  & 94.86  & 92.80  & 89.51  & 84.63  & 80.41 \\
          &       & MoCo2+  & 85.00  & 87.19  & 86.17  & 84.45  & 81.72  & 78.62 \\
          &       & NNCLR & 90.33  & 91.43  & 89.58  & 87.57  & 82.85  & 79.92 \\
          &       & SimCLR & 94.00  & 94.19  & 92.30  & 90.58  & 87.73  & 85.43 \\
    \hline
    \multirow{12}[4]{*}{ImageNet} & \multirow{6}[2]{*}{STL10} & Barlow & 99.67  & 94.07  & 81.03  & 62.26  & 36.67  & 25.02 \\
          &       & BYOL  & 93.33  & 90.53  & 79.02  & 61.63  & 37.58  & 24.92 \\
          &       & DINO  & 94.00  & 91.38  & 79.58  & 61.00  & 36.33  & 24.6 \\
          &       & MoCo2+  & 65.67  & 70.93  & 63.24  & 49.50  & 32.28  & 23.38 \\
          &       & NNCLR & 86.67  & 86.63  & 76.15  & 59.27  & 35.72  & 24.67 \\
          &       & SimCLR & 83.33  & 84.48  & 73.58  & 56.99  & 35.11  & 24.34 \\
\cline{2-9}          & \multirow{6}[2]{*}{GTSRB} & Barlow & 97.67  & 97.02  & 93.92  & 91.14  & 87.06  & 83.85 \\
          &       & BYOL  & 83.33  & 87.52  & 85.68  & 82.21  & 77.18  & 74.78 \\
          &       & DINO  & 87.33  & 90.45  & 88.49  & 86.14  & 83.17  & 80.59 \\
          &       & MoCo2+  & 82.00  & 85.24  & 84.37  & 82.06  & 78.10  & 75.37 \\
          &       & NNCLR & 77.67  & 85.13  & 83.83  & 81.75  & 78.23  & 75.37 \\
          &       & SimCLR & 90.67  & 91.81  & 88.53  & 84.78  & 80.20  & 77.26 \\
    \bottomrule[1.5pt]
    \end{tabular}%
    }
  \label{tab:clean_retrieval}%
     \vspace{-4mm}
\end{table}%


% Table generated by Excel2LaTeX from sheet '补充材料'
\begin{table*}[htbp]
\setlength{\abovecaptionskip}{2pt}
  \centering
  \caption{The clean accuracy (\%) of different downstream models based on pre-trained encoders over four datasets. PD denotes the pre-training dataset and DD represents the downstream dataset.}
  \scalebox{0.6855}{
    \begin{tabular}{c|c|cccccccccccccc}
    \toprule[1.5pt]
    PD & DD & Barlow & BYOL  & DeepC2 & DINO  & MoCo2+ & MoCo3 & NNCLR & ReSSL & SimCLR & SupCon & SwAV  & VIbCReg & VICReg & W-MSE \\
    \hline
    \multirow{4}[2]{*}{CIFAR10} & CIFAR10 & 93.61  & 94.47  & 90.59  & 91.60  & 95.10  & 94.67  & 93.91  & 92.67  & 93.63  & 96.23  & 92.32  & 92.35  & 93.17  & 90.13  \\
        & STL10 & 83.98  & 83.18  & 77.99  & 83.30  & 84.61  & 83.92  & 83.26  & 81.65  & 81.64  & 84.47  & 81.32  & 81.97  & 82.18  & 78.26  \\
          & GTSRB & 97.57  & 93.66  & 95.99  & 97.04  & 91.90  & 92.09  & 96.28  & 95.97  & 96.59  & 97.39  & 97.77  & 96.96  & 97.11  & 88.63  \\
          & ImageNet & 67.58  & 52.94  & 45.44  & 60.16  & 51.15  & 48.92  & 57.00  & 51.01  & 54.23  & 50.67  & 58.82  & 61.00  & 61.83  & 41.00  \\
    \hline
    \multirow{4}[2]{*}{ImageNet} & CIFAR10 & 72.31  & 72.44  & 69.06  & 73.14  & 73.12  & 72.86  & 73.89  & 72.22  & 69.51  & 70.71  & 71.48  & 72.90  & 73.21  & 68.64  \\
          & STL10 & 65.09  & 64.36  & 61.77  & 65.16  & 65.23  & 63.10  & 65.95  & 65.04  & 62.49  & 63.31  & 64.05  & 65.23  & 64.70  & 61.17  \\
          & GTSRB & 95.49  & 92.18  & 95.16  & 92.28  & 90.28  & 87.88  & 93.93  & 90.82  & 93.71  & 95.81  & 96.18  & 95.13  & 94.51  & 92.66  \\
          & ImageNet & 56.87  & 46.10  & 46.04  & 49.21  & 42.84  & 43.26  & 49.15  & 45.19  & 48.79  & 52.44  & 48.83  & 55.50  & 52.29  & 38.13  \\
    \bottomrule[1.5pt]
    \end{tabular}%
    }
  \label{tab:clean}%
\end{table*}%


\input{Section/algorithm-word}
% \vspace{-0.2cm}
\vspace{-4mm}

\section{Supplemental Attack Performance}\label{attack_performance}
In this section, we further investigate the attack performance of AdvEncoder in two types of downstream tasks, classification and retrieval.
We keep all the following experimental settings consistent with the main body.
% For the classification task,



\subsection{Attack Performance on Classification} \label{attack_performance_classification}
We first provide the normal accuracy of downstream models based on fourteen SSL pre-trained encodes on four different datasets. 
The results in \cref{tab:clean} prove that users using pre-trained encoders can achieve excellent performance on different datasets just by fine-tuning the linear layer.
Specifically, we evaluate AdvEncoder on fourteen victim pre-trained encoders over four downstream tasks using two attacker's surrogate datasets, \textbf{STL10} and \textbf{GTSRB}, respectively.
The performance of our attack using two additional attacker's surrogate datasets on the classification task further confirms that downstream tasks based on pre-trained encoders are exposed to significant security risks. The experimental results  in \cref{tab:attack_performance_per1} and \cref{tab:attack_performance_pat1} demonstrate that an attacker can achieve successful attacks even without prior knowledge of the pre-training dataset and the downstream dataset. 
These findings are in line with the results presented in the main body of the paper.


% Table generated by Excel2LaTeX from sheet '补充材料'
\begin{table*}[htbp]
\setlength{\abovecaptionskip}{2pt}
  \centering
  \caption{The attack success rate (\%) of Adv-PER under different settings.
  $\mathcal{S}_{1}$ - $\mathcal{S}_{4}$ denote the settings where the downstream datasets are CIFAR10, STL10, GTSRB, ImageNet, respectively, and all the attacker’s surrogate dataset is \textbf{STL10}. $\mathcal{S}_{5}$ -  $\mathcal{S}_{8}$ use \textbf{GTSRB} as the attacker’s surrogate dataset, with the downstream datasets remained the same as $\mathcal{S}_{1}$ - $\mathcal{S}_{4}$. Barlow Twins and DeepCluster v2 are abbreviated as Barlow and DeepC2, respectively.}
   \scalebox{0.7}{
    \begin{tabular}{c|c|cccccccccccccc}
    \toprule[1.5pt]
    Dataset & Setting & Barlow & BYOL  & DeepC2 & DINO  & MoCo2+ & MoCo3 & NNCLR & ReSSL & SimCLR & SupCon & SwAV  & VIbCReg & VICReg & W-MSE \\
    \hline
    \multirow{9}[2]{*}{CIFAR10} & $\mathcal{S}_{1}$    & 89.34  & 88.36  & 86.17  & 89.85  & 78.39  & 87.49  & 90.95  & 88.79  & 70.10 & 90.21  & 51.27  & 89.02  & 81.11  & 62.29  \\
          & $\mathcal{S}_{2}$    & 53.58  & 72.57  & 71.96  & 70.74  & 37.07  & 60.83  & 72.16  & 63.67  & 29.11  & 83.02  & \textcolor[RGB]{169,169,169}{28.52}  & 72.33  & 44.42  & 35.68  \\
          & $\mathcal{S}_{3}$    & \textbf{91.92}  & \textbf{92.05}  & \textbf{89.50}  & 92.96  & \textbf{83.93}  & 82.08  & 91.28  & \textbf{94.46}  & \textbf{70.72}  & 91.99  & 66.02  & 90.76  & \textbf{82.97}  & \textbf{72.55}  \\
          & $\mathcal{S}_{4}$    & 88.09  & 88.50  & 85.74  & 86.43  & 82.08  & \textbf{88.25}  & 87.55  & 85.76  & 68.86  & \textbf{94.48}  & 61.45  & 90.31  & 75.44  & 72.22  \\
          & $\mathcal{S}_{5}$    & 87.81  & 88.85  & 82.75  & 89.71  & 51.37  & 55.67  & 89.22  & 86.83  & 45.38  & 83.38  & 61.40  & 85.78  & 73.91  & 52.28  \\
          & $\mathcal{S}_{6}$    & \textcolor[RGB]{169,169,169}{50.83}  & \textcolor[RGB]{169,169,169}{67.82}  & \textcolor[RGB]{169,169,169}{52.01}  & \textcolor[RGB]{169,169,169}{64.50}  & \textcolor[RGB]{169,169,169}{30.79}  & \textcolor[RGB]{169,169,169}{25.16}  & \textcolor[RGB]{169,169,169}{60.46}  & \textcolor[RGB]{169,169,169}{52.69}  & \textcolor[RGB]{169,169,169}{26.54}  & \textcolor[RGB]{169,169,169}{48.44}  & 33.14  & \textcolor[RGB]{169,169,169}{57.67}  & \textcolor[RGB]{169,169,169}{35.60}  & \textcolor[RGB]{169,169,169}{29.48}  \\
          & $\mathcal{S}_{7}$    & 91.29  & 91.19  & 89.05  & \textbf{94.73}  & 78.57  & 61.55  & \textbf{91.86}  & 94.21  & 64.48  & 80.67  & \textbf{76.86}  & \textbf{91.32}  & 77.77  & 71.33  \\
          & $\mathcal{S}_{8}$    & 82.55  & 90.27  & 79.19  & 83.55  & 66.19  & 65.62  & 83.81  & 79.47  & 61.73  & 79.30  & 66.14  & 80.56  & 64.43  & 63.74  \\
          & AVG   & 79.43  & 84.95  & 79.55  & 84.06  & 63.55  & 65.83  & 83.41  & 80.74  & 54.62  & 81.44  & 55.60  & 82.22  & 66.96  & 57.44  \\
    \hline
    \multirow{9}[2]{*}{ImageNet} & $\mathcal{S}_{1}$    & 61.52  & 77.28  & 62.96  & 67.81  & 68.41  & 61.67  & \textbf{74.31}  & 77.48  & 69.80  & 67.26  & 69.17  & 68.42  & 64.65  & 79.24  \\
          & $\mathcal{S}_{2}$    & 58.01  & 54.82  & \textcolor[RGB]{169,169,169}{46.96}  & 49.93  & 52.23  & \textcolor[RGB]{169,169,169}{52.81}  & 52.77  & 60.24  & 57.91  & 51.44  & 52.33  & 48.33  & 53.47  & 67.53  \\
          & $\mathcal{S}_{3}$    & 62.95  & 72.76  & 63.47  & 71.51  & 71.24  & 68.84  & 65.11  & \textbf{80.42}  & 62.89  & \textbf{71.20}  & 61.69  & 59.40  & 68.19  & 76.03  \\
          & $\mathcal{S}_{4}$    & 69.63  & 71.88  & 69.26  & 66.18  & 67.59  & 64.52  & 67.89  & 73.20  & 72.20  & 68.19  & 71.24  & 64.83  & 69.47  & \textbf{80.28}  \\
          & $\mathcal{S}_{5}$    & \textbf{79.51}  & \textbf{83.14}  & 65.30  & 61.31  & 64.59  & 68.47  & 65.01  & 69.87  & 70.72  & 62.82  & 65.01  & 67.89  & 65.25  & 78.97  \\
          & $\mathcal{S}_{6}$    & \textcolor[RGB]{169,169,169}{55.21}  & \textcolor[RGB]{169,169,169}{50.13}  & 48.68  & \textcolor[RGB]{169,169,169}{46.01}  & \textcolor[RGB]{169,169,169}{49.08}  & 53.54  & \textcolor[RGB]{169,169,169}{49.67}  & \textcolor[RGB]{169,169,169}{49.94}  & \textcolor[RGB]{169,169,169}{51.10}  & \textcolor[RGB]{169,169,169}{44.63}  & \textcolor[RGB]{169,169,169}{49.34}  & \textcolor[RGB]{169,169,169}{46.33}  & \textcolor[RGB]{169,169,169}{48.85}  & \textcolor[RGB]{169,169,169}{58.65}  \\
          & $\mathcal{S}_{7}$    & 79.38  & 77.71  & \textbf{72.36}  & \textbf{77.26}  & \textbf{73.52}  & \textbf{76.74}  & 71.66  & 77.47  & \textbf{75.46}  & 69.55  & \textbf{71.38}  & \textbf{74.10}  & \textbf{70.98}  & 70.72  \\
          & $\mathcal{S}_{8}$    & 72.18  & 68.43  & 68.18  & 65.24  & 62.74  & 64.47  & 64.66  & 65.66  & 68.02  & 64.11  & 68.57  & 67.59  & 66.77  & 73.32  \\
          & AVG   & 67.30  & 69.52  & 62.15  & 63.16  & 63.68  & 63.88  & 63.88  & 69.28  & 66.01  & 62.40  & 63.59  & 62.11  & 63.45  & 73.10  \\
    \bottomrule[1.5pt]
    \end{tabular}%
    }
  \label{tab:attack_performance_per1}%
\end{table*}%

% Table generated by Excel2LaTeX from sheet '补充材料'
\begin{table*}[htbp]
\setlength{\abovecaptionskip}{2pt}
  \centering
  \caption{The attack success rate (\%) of Adv-PAT under different settings. $\mathcal{S}_{1}$ - $\mathcal{S}_{8}$ represent the same settings as mentioned in \cref{tab:attack_performance_per1}.}
   \scalebox{0.7}{
    \begin{tabular}{c|c|cccccccccccccc}
    \toprule[1.5pt]
    Dataset & Setting & Barlow & BYOL  & DeepC2 & DINO  & MoCo2+ & MoCo3 & NNCLR & ReSSL & SimCLR & SupCon & SwAV  & VIbCReg & VICReg & W-MSE \\
    \hline
    \multirow{9}[2]{*}{CIFAR10} & $\mathcal{S}_{1}$    & \textcolor[RGB]{169,169,169}{83.47}  & 79.55  & 90.88  & 88.61  & \textcolor[RGB]{169,169,169}{81.60}  & 88.83  & \textcolor[RGB]{169,169,169}{65.55}  & 73.08  & 89.91  & 80.03  & 89.30  & 57.27  & 87.58  & 88.61  \\
          & $\mathcal{S}_{2}$    & 88.78  & 80.98  & \textcolor[RGB]{169,169,169}{87.66}  & 79.87  & 82.51  & \textcolor[RGB]{169,169,169}{77.50}  & 75.83  & 73.19  & 89.32  & 69.42  & \textcolor[RGB]{169,169,169}{81.41}  & 56.82  & 82.36  & 81.32  \\
          & $\mathcal{S}_{3}$    & 93.14  & 89.95  & 95.44  & 86.40  & \textbf{99.08}  & 92.43  & 89.84  & 88.62  & 94.98  & 88.27  & 97.09  & 86.43  & 94.47  & 88.97  \\
          & $\mathcal{S}_{4}$    & 93.41  & \textbf{98.03}  & 99.53  & \textbf{98.16}  & 98.55  & 97.15  & 94.25  & \textbf{97.85}  & \textbf{98.97}  & \textbf{96.29}  & \textbf{98.53}  & \textbf{94.82}  & \textbf{97.76}  & \textbf{96.33}  \\
          & $\mathcal{S}_{5}$    & 83.58  & 87.64  & 90.88  & 82.59  & 86.05  & 89.83  & 67.80  & \textcolor[RGB]{169,169,169}{64.38}  & 89.90  & 77.01  & 89.30  & 53.89  & \textcolor[RGB]{169,169,169}{75.92}  & 87.02  \\
          & $\mathcal{S}_{6}$    & 83.79  & \textcolor[RGB]{169,169,169}{78.71}  & 89.67  & \textcolor[RGB]{169,169,169}{71.72}  & 82.41  & 83.64  & 66.58  & 75.40  & \textcolor[RGB]{169,169,169}{88.42}  & \textcolor[RGB]{169,169,169}{56.32}  & 83.92  & \textcolor[RGB]{169,169,169}{52.26}  & {78.69}  & \textcolor[RGB]{169,169,169}{79.55}  \\
          & $\mathcal{S}_{7}$    & 92.84  & 88.83  & 94.53  & 87.63  & 98.27  & 92.41  & 87.88  & 88.94  & 95.23  & 84.60  & 97.09  & 84.20  & 90.52  & 86.22  \\
          & $\mathcal{S}_{8}$    & \textbf{93.64}  & 96.68  & \textbf{99.70}  & 95.97  & 98.25  & \textbf{97.32}  & \textbf{94.45}  & 97.80  & 98.94  & 94.43  & 98.17  & 94.10  & 94.59  & 95.01  \\
          & AVG   & 89.08  & 87.55  & 93.53  & 86.37  & 90.84  & 89.89  & 80.27  & 82.41  & 93.21  & 80.80  & 91.85  & 72.47  & 87.74  & 87.88  \\
    \hline
    \multirow{9}[2]{*}{ImageNet} & $\mathcal{S}_{1}$    & 89.33  & 88.45  & \textcolor[RGB]{169,169,169}{89.22}  & 89.41  & \textcolor[RGB]{169,169,169}{87.28}  & \textcolor[RGB]{169,169,169}{88.80}  & 88.76  & 92.01  & 90.31  & 90.50  & \textcolor[RGB]{169,169,169}{90.06}  & 89.04  & 89.18  & 91.15  \\
          & $\mathcal{S}_{2}$    & \textcolor[RGB]{169,169,169}{83.53}  & 88.11  & 89.98  & \textcolor[RGB]{169,169,169}{89.09}  & 90.65  & 91.22  & 88.86  & 91.11  & \textcolor[RGB]{169,169,169}{89.26}  & 90.92  & 90.28  & \textcolor[RGB]{169,169,169}{86.13}  & 87.55  & \textcolor[RGB]{169,169,169}{89.84}  \\
          & $\mathcal{S}_{3}$    & 93.37  & \textbf{99.19}  & 97.04  & 94.95  & 95.54  & \textbf{98.47}  & 98.36  & 90.67  & 94.33  & 94.52  & 97.07  & 95.42  & 95.31  & 98.30  \\
          & $\mathcal{S}_{4}$    & \textbf{98.60}  & 98.63  & 99.21  & \textbf{98.79}  & 98.06  & 98.30  & \textbf{98.40}  & 98.17  & \textbf{99.02}  & \textbf{99.15}  & 98.66  & \textbf{98.59}  & \textbf{98.79}  & \textbf{98.49}  \\
          & $\mathcal{S}_{5}$    & 86.45  & 88.95  & \textcolor[RGB]{169,169,169}{89.22}  & 89.41  & 91.26  & 89.04  & 88.72  & 92.00  & 90.30  & 90.50  & \textcolor[RGB]{169,169,169}{90.06}  & 89.03  & 89.49  & 91.19  \\
          & $\mathcal{S}_{6}$    & 87.00  & \textcolor[RGB]{169,169,169}{87.15}  & 89.98  & 89.48  & 90.58  & 91.50  & \textcolor[RGB]{169,169,169}{88.15}  & 91.19  & 89.60  & \textcolor[RGB]{169,169,169}{90.21}  & 90.15  & 89.88  & \textcolor[RGB]{169,169,169}{87.54}  & 89.86  \\
          & $\mathcal{S}_{7}$    & 94.05  & 97.37  & 96.72  & 94.65  & 96.54  & 97.43  & 98.36  & \textcolor[RGB]{169,169,169}{90.65}  & 94.30  & 92.31  & 97.09  & 96.29  & 96.02  & 98.33  \\
          & $\mathcal{S}_{8}$    & 98.54  & 98.61  & \textbf{99.22}  & 98.43  & \textbf{98.30}  & 98.19  & 98.25  & \textbf{98.32}  & \textbf{99.02}  & 98.38  & \textbf{98.88}  & 98.56  & 98.77  & 98.43  \\
          & AVG   & 91.36  & 93.31  & 93.82  & 93.03  & 93.52  & 94.12  & 93.48  & 93.01  & 93.27  & 93.31  & 94.03  & 92.87  & 92.83  & 94.45  \\
    \bottomrule[1.5pt]
    \end{tabular}%
    }
  \label{tab:attack_performance_pat1}%
\end{table*}%


% Table generated by Excel2LaTeX from sheet 'Sheet1'
\begin{table*}[htbp]
\setlength{\abovecaptionskip}{2pt}
  \centering
   \caption{The retrieval attack performance (\%) of AdvEncoder under different settings on the pre-training dataset CIFAR10. PD denotes the pre-training dataset, SD indicates the attacker’s surrogate dataset  and DD represents the downstream dataset. }
        \scalebox{0.675}{
    \begin{tabular}{c|c|c|c|cccccccccccc}
    \toprule[1.5pt]
    \multirow{2}{*}{PD} & \multirow{2}{*}{SD} & \multirow{2}{*}{DD} & \multirow{2}{*}{Model} & \multicolumn{2}{c}{top1} & \multicolumn{2}{c}{top5} & \multicolumn{2}{c}{top10} & \multicolumn{2}{c}{top20} & \multicolumn{2}{c}{top50} & \multicolumn{2}{c}{top100} \\
          &       &       &       & p\_mAP & pat\_mAP & p\_mAP & pat\_mAP & p\_mAP & pat\_mAP & p\_mAP & pat\_mAP & p\_mAP & pat\_mAP & p\_mAP & pat\_mAP \\
     \hline
    \multirow{24}[8]{*}{CIFAR10} & \multirow{12}[4]{*}{CIFAR10} & \multirow{6}[2]{*}{STL10} & Barlow & 8.33  & 11.00  & 21.03  & 23.80  & 22.90  & 24.97  & 21.75  & 21.54  & 16.53  & 16.89  & 14.13  & 14.10  \\
          &       &       & BYOL  & 10.00  & 10.00  & 19.89  & 18.15  & 21.96  & 20.65  & 20.79  & 19.82  & 16.83  & 16.44  & 14.26  & 13.96  \\
          &       &       & DINO  & 10.00  & 9.00  & 19.13  & 19.26  & 20.85  & 21.39  & 20.07  & 20.22  & 16.50  & 16.45  & 13.61  & 14.27  \\
          &       &       & MoCo2+  & 12.00  & 9.33  & 21.88  & 21.00  & 22.74  & 23.28  & 20.96  & 23.05  & 16.61  & 17.08  & 14.22  & 14.25  \\
          &       &       & NNCLR & 9.00  & 9.33  & 18.29  & 20.31  & 20.49  & 21.85  & 19.46  & 21.51  & 16.13  & 16.99  & 13.85  & 14.13  \\
          &       &       & SimCLR & 10.67  & 9.67  & 21.55  & 17.14  & 23.39  & 20.40  & 21.16  & 19.69  & 17.05  & 16.22  & 14.22  & 14.13  \\
\cline{3-16}          &       & \multirow{6}[2]{*}{GTSRB} & Barlow & 18.33  & 10.00  & 21.57  & 10.00  & 22.21  & 10.00  & 21.83  & 10.05  & 21.30  & 10.06  & 20.92  & 10.07  \\
          &       &       & BYOL  & 14.33  & 14.33  & 15.64  & 17.41  & 15.56  & 17.43  & 15.61  & 17.66  & 15.17  & 17.91  & 14.83  & 17.77  \\
          &       &       & DINO  & 12.67  & 17.33  & 18.13  & 25.29  & 18.22  & 24.75  & 17.82  & 24.06  & 17.13  & 23.57  & 16.17  & 23.36  \\
          &       &       & MoCo2+  & 30.00  & 12.33  & 34.01  & 12.34  & 33.86  & 12.24  & 32.81  & 12.21  & 30.93  & 12.17  & 29.37  & 12.08  \\
          &       &       & NNCLR & 16.33  & 18.67  & 18.16  & 22.88  & 17.64  & 23.18  & 17.28  & 22.86  & 16.94  & 22.77  & 16.87  & 22.79  \\
          &       &       & SimCLR & 46.00  & 10.00  & 50.10  & 10.33  & 49.21  & 10.38  & 48.37  & 10.49  & 46.68  & 10.43  & 45.26  & 10.41  \\
\cline{2-16}          & \multirow{12}[4]{*}{ImageNet} & \multirow{6}[2]{*}{STL10} & Barlow & 11.00  & 11.00  & 20.03  & 21.01  & 23.10  & 22.43  & 21.75  & 20.77  & 17.43  & 16.64  & 14.45  & 14.20  \\
          &       &       & BYOL  & 12.67  & 10.00  & 23.25  & 17.04  & 24.60  & 18.83  & 22.69  & 20.95  & 17.37  & 17.14  & 14.55  & 14.25  \\
          &       &       & DINO  & 8.00  & 10.00  & 18.41  & 18.76  & 20.01  & 20.51  & 19.00  & 20.58  & 15.78  & 16.34  & 13.43  & 14.00  \\
          &       &       & MoCo2+  & 10.67  & 8.33  & 20.19  & 16.30  & 22.34  & 17.62  & 20.48  & 18.27  & 16.85  & 15.63  & 14.29  & 13.62  \\
          &       &       & NNCLR & 8.33  & 11.33  & 18.97  & 22.09  & 22.26  & 24.21  & 20.94  & 22.41  & 16.14  & 17.40  & 13.83  & 14.19  \\
          &       &       & SimCLR & 9.33  & 11.33  & 19.62  & 16.52  & 21.24  & 19.95  & 20.30  & 18.47  & 16.10  & 16.27  & 13.82  & 14.24  \\
\cline{3-16}          &       & \multirow{6}[2]{*}{GTSRB} & Barlow & 12.67  & 16.00  & 17.05  & 17.79  & 17.08  & 17.76  & 15.48  & 16.79  & 14.21  & 16.37  & 13.63  & 16.08  \\
          &       &       & BYOL  & 13.00  & 10.33  & 17.36  & 12.83  & 16.71  & 13.37  & 16.31  & 13.33  & 15.93  & 13.58  & 15.39  & 14.03  \\
          &       &       & DINO  & 14.00  & 26.00  & 19.37  & 32.69  & 19.17  & 33.77  & 18.78  & 33.33  & 18.57  & 32.10  & 18.39  & 31.49  \\
          &       &       & MoCo2+  & 27.67  & 15.00  & 31.15  & 15.04  & 31.58  & 14.81  & 31.37  & 14.76  & 30.86  & 14.54  & 30.42  & 14.24  \\
          &       &       & NNCLR & 8.67  & 20.33  & 10.18  & 24.39  & 10.32  & 24.19  & 10.55  & 23.32  & 11.17  & 22.67  & 11.22  & 22.30  \\
          &       &       & SimCLR & 13.00  & 10.00  & 21.82  & 10.00  & 22.07  & 10.04  & 22.14  & 10.04  & 22.05  & 10.04  & 21.58  & 10.11  \\
    \bottomrule[1.5pt]
    \end{tabular}%
    }
  \label{tab:retrieval_attack_cifar10}%
\end{table*}%
 
% Table generated by Excel2LaTeX from sheet 'Sheet1'
\begin{table*}[htbp]
\setlength{\abovecaptionskip}{2pt}
  \centering
   \caption{The retrieval attack performance (\%) of AdvEncoder under different settings on the pre-training dataset ImageNet}
     \scalebox{0.675}{
    \begin{tabular}{c|c|c|c|cccccccccccc}
    \toprule[1.5pt]
    \multirow{2}{*}{PD} & \multirow{2}{*}{SD} & \multirow{2}{*}{DD} & \multirow{2}{*}{Model} & \multicolumn{2}{c}{top1} & \multicolumn{2}{c}{top5} & \multicolumn{2}{c}{top10} & \multicolumn{2}{c}{top20} & \multicolumn{2}{c}{top50} & \multicolumn{2}{c}{top100} \\
          &       &       &       & p\_mAP & pat\_mAP & p\_mAP & pat\_mAP & p\_mAP & pat\_mAP & p\_mAP & pat\_mAP & p\_mAP & pat\_mAP & p\_mAP & pat\_mAP \\
    \hline
    \multirow{24}[8]{*}{ImageNet} & \multirow{12}[4]{*}{CIFAR10} & \multirow{6}[2]{*}{STL10} & Barlow & 11.67  & 9.00  & 21.70  & 19.44  & 23.26  & 21.15  & 21.55  & 20.68  & 17.02  & 16.36  & 14.27  & 13.76  \\
          &       &       & BYOL  & 9.67  & 8.00  & 20.25  & 18.01  & 21.76  & 19.64  & 21.03  & 19.26  & 16.36  & 16.84  & 13.97  & 14.03  \\
          &       &       & DINO  & 9.67  & 9.33  & 22.10  & 19.82  & 22.95  & 21.12  & 22.01  & 19.93  & 17.18  & 16.10  & 14.53  & 14.15  \\
          &       &       & MoCo2+  & 11.00  & 14.00  & 20.73  & 23.04  & 22.77  & 26.89  & 21.19  & 25.05  & 16.36  & 20.26  & 13.90  & 14.68  \\
          &       &       & NNCLR & 12.33  & 10.67  & 23.82  & 22.85  & 24.99  & 26.22  & 22.92  & 24.89  & 17.90  & 17.20  & 14.98  & 13.60  \\
          &       &       & SimCLR & 9.67  & 11.33  & 19.80  & 21.07  & 21.76  & 23.59  & 20.13  & 21.46  & 16.62  & 17.04  & 14.31  & 13.99  \\
\cline{3-16}          &       & \multirow{6}[2]{*}{GTSRB} & Barlow & 38.67  & 10.00  & 43.57  & 11.16  & 42.81  & 11.63  & 41.57  & 11.67  & 39.82  & 11.22  & 38.66  & 11.21  \\
          &       &       & BYOL  & 40.67  & 10.00  & 46.60  & 10.07  & 45.81  & 10.07  & 43.88  & 10.07  & 41.21  & 10.24  & 39.33  & 10.15  \\
          &       &       & DINO  & 26.67  & 10.00  & 30.54  & 10.07  & 30.72  & 10.17  & 29.85  & 10.24  & 29.45  & 10.55  & 28.69  & 10.60  \\
          &       &       & MoCo2+  & 32.33  & 7.00  & 39.30  & 11.07  & 38.93  & 11.75  & 37.79  & 12.25  & 35.51  & 11.55  & 34.81  & 11.23  \\
          &       &       & NNCLR & 30.67  & 9.00  & 36.07  & 11.96  & 36.14  & 11.66  & 35.22  & 11.97  & 33.33  & 12.04  & 32.50  & 12.16  \\
          &       &       & SimCLR & 40.33  & 10.00  & 45.80  & 10.42  & 45.56  & 13.63  & 44.11  & 15.75  & 42.12  & 14.76  & 40.88  & 14.68  \\
\cline{2-16}          & \multirow{12}[4]{*}{ImageNet} & \multirow{6}[2]{*}{STL10} & Barlow & 13.00  & 9.67  & 22.27  & 19.99  & 23.02  & 21.75  & 21.45  & 20.18  & 16.92  & 16.28  & 14.09  & 13.76  \\
          &       &       & BYOL  & 11.33  & 11.33  & 20.36  & 20.41  & 22.14  & 23.85  & 21.46  & 20.93  & 16.94  & 15.90  & 14.03  & 13.51  \\
          &       &       & DINO  & 9.00  & 9.33  & 19.75  & 20.21  & 21.46  & 22.75  & 21.04  & 20.28  & 16.44  & 16.29  & 13.90  & 14.45  \\
          &       &       & MoCo2+  & 9.67  & 8.00  & 20.40  & 19.23  & 21.12  & 22.28  & 20.02  & 23.67  & 16.33  & 17.06  & 13.82  & 13.80  \\
          &       &       & NNCLR & 11.00  & 11.33  & 20.59  & 19.96  & 22.82  & 24.91  & 20.74  & 23.10  & 16.89  & 16.33  & 14.17  & 13.62  \\
          &       &       & SimCLR & 9.33  & 9.00  & 19.36  & 21.31  & 21.43  & 23.91  & 20.83  & 20.59  & 16.84  & 16.37  & 14.15  & 13.64  \\
\cline{3-16}          &       & \multirow{6}[2]{*}{GTSRB} & Barlow & 28.67  & 9.33  & 34.08  & 10.68  & 34.65  & 11.10  & 34.38  & 11.61  & 34.14  & 11.99  & 33.92  & 12.08  \\
          &       &       & BYOL  & 35.33  & 10.00  & 41.06  & 10.00  & 41.40  & 10.00  & 38.94  & 10.12  & 36.42  & 10.30  & 34.38  & 10.22  \\
          &       &       & DINO  & 27.00  & 10.00  & 31.89  & 10.12  & 31.57  & 10.05  & 30.65  & 10.09  & 29.95  & 10.11  & 29.18  & 10.06  \\
          &       &       & MoCo2+  & 22.33  & 12.33  & 33.48  & 13.18  & 32.40  & 13.73  & 30.93  & 13.29  & 29.12  & 12.48  & 27.94  & 12.07  \\
          &       &       & NNCLR & 31.67  & 10.00  & 36.82  & 12.05  & 37.07  & 13.04  & 37.21  & 13.03  & 35.99  & 13.29  & 35.20  & 12.54  \\
          &       &       & SimCLR & 19.00  & 10.00  & 21.68  & 11.83  & 21.58  & 12.41  & 21.42  & 12.72  & 20.90  & 12.93  & 20.36  & 13.37  \\
    \bottomrule[1.5pt]
    \end{tabular}%
    }
  \label{tab:retrieval_attack_imagenet}%
\end{table*}%



\subsection{Attack Performance on Retrieval}  \label{attack_performance_retrieval}
% \noindent\textbf{Implementation Details.}

 We aim to investigate the impact of AdvEncoder on the retrieval accuracy of downstream tasks under different settings. 
 We select Barlow Twins\cite{zbontar2021barlow}, MoCo v2+\cite{chen2020improved}, BYOL\cite{grill2020bootstrap}, DINO\cite{caron2021emerging}, NNCLR\cite{dwibedi2021little}, and SimCLR \cite{chen2020simple} as pre-trained encoders to evaluate the performance of AdvEncoder in retrieval downstream tasks.
We use CIFAR10 and ImageNet as pre-training datasets for the victim models. As shown in \cref{tab:clean_retrieval}, we provide the precision (mAP) corresponding to their different settings on STL10 and GTSRB downstream retrieval tasks. We then use CIFAR10 and ImageNet as the surrogate datasets for the attacker to launch attacks on the downstream tasks.
We use per-mAP and pat-mAP metrics, where lower values indicate better attack performance. 
The results in ~\cref{tab:retrieval_attack_cifar10} and ~\cref{tab:retrieval_attack_imagenet} illustrate that AdvEncoder can successfully attack the downstream retrieval task without any knowledge of the pre-training and downstream datasets.

% Figure environment removed


% Figure environment removed



\subsection{Attack Performance on Object Detection \& Semantic Segmentation}  
We provide the attack performance of AdvEncoder in  \textbf{Object Detection} and \textbf{Semantic Segmentation} tasks using ImageNet as the surrogate dataset in \cref{fig:retriveal1}(a) - (b). 
We employe the official MOCOv2 model based on ResNet50 and fine-tune it on the COCO dataset using Mask R-CNN for the above two types of tasks.
The results in~\cref{fig:retriveal1}(a) - (b) illustrate that AdvEncoder can successfully attack the two types of downstream tasks.



\section{Supplemental Ablation Study} \label{ablation}
In this section, we explore the effect of different random seeds and backbones on the attack performance of AdvEncoder. 
The following experimental settings are consistent with the main body. 
We choose CIFAR10 as the surrogate dataset and GTSRB as the downstream dataset.

\noindent\textbf{The Effect of Random Seed.} 
The default random number seed for our experiments is 100, and we further provide results for different randomized seeds in \cref{fig:retriveal1}(c).

\noindent\textbf{The Effect of Backbone.}
We provide ASRs for downstream GTSRB tasks for five architectures of CLIP (ResNet50, ResNet101, ViT-B/16, ViT-B/32, ViT-L/14).
The results in \cref{fig:retriveal1}(d) show that AdvEncoder can successfully attack downstream tasks based on the pre-trained encoders with different backbones.
 \vspace{-4mm}


\section{Supplemental Transferability Study}  \label{transferability}

In this section, we aim to investigate the transferability of AdvEncoder from two distinct perspectives: pre-training datasets and crossing SSL methods. The experimental settings in this analysis are consistent with those outlined in the main body of the paper. 
From~\cref{fig:transfer}, we explore the attack performance of Adv-PAT and Adv-PER in different transportability scenarios.
C2I-GTS-PAT represents the two encoders we trained using CIFAR10 and ImageNet, on which we made adversarial examples of Adv-PAT and downstream tasks of GTSRB, respectively. I2I-STL-PER represents the two encoders we trained using ImageNet and ImageNet, on which we made adversarial examples of Adv-PER and downstream tasks of STL10, respectively.
The other captions have the same definition.
We can see that Adv-Encoder has good transferability between different downstream tasks based on different encoders.



\section{Visualization}\label{Visualization}
In this section, as shown in the \cref{fig:visualization_advencoder}, we show adversarial perturbations and patches generated by AdvEncoder using the attacker’s surrogate dataset CIFAR10 for each of the fourteen SSL encoders trained with ImageNet.



% Figure environment removed
