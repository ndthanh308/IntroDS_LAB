
@InProceedings{radford2021,
	title = 	 {Learning Transferable Visual Models From Natural Language Supervision},
	author =       {Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and Krueger, Gretchen and Sutskever, Ilya},
	booktitle = 	 {Proceedings of the 38th International Conference on Machine Learning},
	pages = 	 {8748--8763},
	year = 	 {2021},
	editor = 	 {Meila, Marina and Zhang, Tong},
	volume = 	 {139},
	series = 	 {Proceedings of Machine Learning Research},
	month = 	 {18--24 Jul},
	publisher =    {PMLR},
	pdf = 	 {http://proceedings.mlr.press/v139/radford21a/radford21a.pdf},
	url = 	 {https://proceedings.mlr.press/v139/radford21a.html},
}

@InProceedings{shih2022,
	doi = {10.48550/ARXIV.2210.00705},
	booktitle = {Proceedings of the IEEE Workshop on Spoken Language Technology 2022},
	author = {Shih, Yi-Jen and Wang, Hsuan-Fu and Chang, Heng-Jui and Berry, Layne and Lee, Hung-yi and Harwath, David},
	keywords = {Computation and Language (cs.CL), Sound (cs.SD), Audio and Speech Processing (eess.AS), FOS: Computer and information sciences, FOS: Computer and information sciences, FOS: Electrical engineering, electronic engineering, information engineering, FOS: Electrical engineering, electronic engineering, information engineering},
	title = {SpeechCLIP: Integrating Speech with Pre-Trained Vision and Language Model},
	year = {2022},
	copyright = {Creative Commons Attribution 4.0 International}
}


@inproceedings{wu2021,
	title = {Wav2CLIP: Learning Robust Audio Representations From CLIP},
    author = "Wu, {Ho Hsiang} and Prem Seetharaman and Kundan Kumar and Bello, {Juan Pablo}",
    year = "2022",
    doi = "10.1109/ICASSP43922.2022.9747669",
    language = "English (US)",
    pages = "4563--4567",
    booktitle = "2022 IEEE International Conference on Acoustics, Speech, and Signal Processing, ICASSP 2022 - Proceedings",
}


@INPROCEEDINGS{guzhov2021,
  author={Guzhov, Andrey and Raue, Federico and Hees, Jörn and Dengel, Andreas},
  booktitle={ICASSP 2022}, 
  title={Audioclip: Extending Clip to Image, Text and Audio}, 
  year={2022},
  volume={},
  number={},
  pages={976-980},
  doi={10.1109/ICASSP43922.2022.9747631}}

@ARTICLE{lekhac2020,
	author={Le-Khac, Phuc H. and Healy, Graham and Smeaton, Alan F.},
	journal={IEEE Access}, 
	title={Contrastive Representation Learning: A Framework and Review}, 
	year={2020},
	volume={8},
	number={},
	pages={193907-193934},
	doi={10.1109/ACCESS.2020.3031549}}

@INPROCEEDINGS{conde2021,
	author={Conde, Marcos V. and Turgutlu, Kerem},
	booktitle={IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)}, 
	title={CLIP-Art: Contrastive Pre-training for Fine-Grained Art Classification}, 
	year={2021},
	volume={},
	number={},
	pages={3951-3955},
	doi={10.1109/CVPRW53098.2021.00444}}

@INPROCEEDINGS{rombach2021,
  author={Rombach, Robin and Blattmann, Andreas and Lorenz, Dominik and Esser, Patrick and Ommer, Björn},
  booktitle={2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={High-Resolution Image Synthesis with Latent Diffusion Models}, 
  year={2022},
  volume={},
  number={},
  pages={10674-10685},
  doi={10.1109/CVPR52688.2022.01042}}

@INPROCEEDINGS{khandelwal2022,
	author={Khandelwal, Apoorv and Weihs, Luca and Mottaghi, Roozbeh and Kembhavi, Aniruddha},
	booktitle={2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 
	title={Simple but Effective: CLIP Embeddings for Embodied AI}, 
	year={2022},
	volume={},
	number={},
	pages={14809-14818},
	doi={10.1109/CVPR52688.2022.01441}}

@INPROCEEDINGS{urli2022,
	author={Urli, Federico and Versini, Emiliano and Snidaro, Lauro},
	booktitle={2022 25th International Conference on Information Fusion (FUSION)}, 
	title={Fusion of sentence embeddings for news retrieval}, 
	year={2022},
	volume={},
	number={},
	pages={1-7},
	doi={10.23919/FUSION49751.2022.9841228}}


@InProceedings{vanderoord2016,
  author    = {A{\"{a}}ron van den Oord and Sander Dieleman and Heiga Zen and Karen Simonyan and Oriol Vinyals and Alex Graves and Nal Kalchbrenner and Andrew W. Senior and Koray Kavukcuoglu},
  booktitle = {Proceedings of the 9th International Speech Communication Association ({ISCA}), Speech Synthesis Workshop, Sunnyvale, CA, USA},
  title     = {{WaveNet}: {A} {Generative} {Model} for {Raw} {Audio}},
  year      = {2016},
  month     = sep,
  pages     = {125},
  publisher = {{ISCA}},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  biburl    = {https://dblp.org/rec/conf/ssw/OordDZSVGKSK16.bib},
  timestamp = {Wed, 17 Jan 2018 11:53:23 +0100},
  url       = {http://www.isca-speech.org/archive/SSW\_2016/abstracts/ssw9\_DS-4\_van\_den\_Oord.html},
}

@inproceedings{garcia2019,
	title	= {Recurrent Neural Network Transducer for Audio-Visual Speech Recognition},
	author	= {Basi Garcia and Brendan Shillingford and Hank Liao and Olivier Siohan and Otavio de Pinho Forin Braga and Takaki Makino and Yannis Assael},
	year	= {2019},
	URL	= {https://arxiv.org/abs/1911.04890},
	booktitle	= {Proceedings of IEEE Automatic Speech Recognition and Understanding Workshop}
}

@INPROCEEDINGS{shen2018,
	author={Shen, Jonathan and Pang, Ruoming and Weiss, Ron J. and Schuster, Mike and Jaitly, Navdeep and Yang, Zongheng and Chen, Zhifeng and Zhang, Yu and Wang, Yuxuan and Skerrv-Ryan, Rj and Saurous, Rif A. and Agiomvrgiannakis, Yannis and Wu, Yonghui},
	booktitle={IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
	title={Natural TTS Synthesis by Conditioning Wavenet on MEL Spectrogram Predictions}, 
	year={2018},
	volume={},
	number={},
	pages={4779-4783},
	doi={10.1109/ICASSP.2018.8461368}}


@inproceedings{kharitonov2022,
	title = {Text-Free Prosody-Aware Generative Spoken Language Modeling},
	author = {Kharitonov, Eugene  and
	Lee, Ann  and
	Polyak, Adam  and
	Adi, Yossi  and
	Copet, Jade  and
	Lakhotia, Kushal  and
	Nguyen, Tu Anh  and
	Riviere, Morgane  and
	Mohamed, Abdelrahman  and
	Dupoux, Emmanuel  and
	Hsu, Wei-Ning},
	booktitle = {Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
	month = may,
	year = {2022},
	address = {Dublin, Ireland},
	doi = {10.18653/v1/2022.acl-long.593}
}

@inproceedings{radford2022,
	doi = {10.48550/ARXIV.2212.04356},
	url = {https://arxiv.org/abs/2212.04356},
	author = {Radford, Alec and Kim, Jong Wook and Xu, Tao and Brockman, Greg and McLeavey, Christine and Sutskever, Ilya},
	title = {Robust Speech Recognition via Large-Scale Weak Supervision},
	booktitle = {arXiv Preprint},
	year = {2022},
}

@inproceedings{cao2022,
    title = "Exploring the Impact of Negative Samples of Contrastive Learning: A Case Study of Sentence Embedding",
    author = "Cao, Rui  and
      Wang, Yihao  and
      Liang, Yuxin  and
      Gao, Ling  and
      Zheng, Jie  and
      Ren, Jie  and
      Wang, Zheng",
    booktitle = "Findings of the Association for Computational Linguistics: ACL 2022",
    month = may,
    year = "2022",
    address = "Dublin, Ireland",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.findings-acl.248",
    doi = "10.18653/v1/2022.findings-acl.248",
    pages = "3138--3152",
    abstract = "Contrastive learning is emerging as a powerful technique for extracting knowledge from unlabeled data. This technique requires a balanced mixture of two ingredients: positive (similar) and negative (dissimilar) samples. This is typically achieved by maintaining a queue of negative samples during training. Prior works in the area typically uses a fixed-length negative sample queue, but how the negative sample size affects the model performance remains unclear. The opaque impact of the number of negative samples on performance when employing contrastive learning aroused our in-depth exploration. This paper presents a momentum contrastive learning model with negative sample queue for sentence embedding, namely MoCoSE. We add the prediction layer to the online branch to make the model asymmetric and together with EMA update mechanism of the target branch to prevent the model from collapsing. We define a maximum traceable distance metric, through which we learn to what extent the text contrastive learning benefits from the historical information of negative samples. Our experiments find that the best results are obtained when the maximum traceable distance is at a certain range, demonstrating that there is an optimal range of historical information for a negative sample queue. We evaluate the proposed unsupervised MoCoSE on the semantic text similarity (STS) task and obtain an average Spearman{'}s correlation of 77.27{\%}. Source code is available here.",
}

@inproceedings{mcauliffe2017,
  author={McAuliffe, Michael and Socolof, Michaela and Mihuc, Sarah and Wagner, Michael and Sonderegger, Morgan},
  title={{Montreal Forced Aligner: Trainable Text-Speech Alignment Using Kaldi}},
  year=2017,
  booktitle={Proceedings of the Interspeech conference},
  pages={498--502},
  doi={10.21437/Interspeech.2017-1386}
}

@inproceedings{robinson2021,
  author    = {Joshua Robinson and
               Ching{-}Yao Chuang and
               Suvrit Sra and
               Stefanie Jegelka},
  title     = {Contrastive Learning with Hard Negative Samples},
  booktitle   = {Proceedings of the International Conference of Learning Representations (ICLR)},
  year      = {2021},
}

@Article{schmidhuber1997,
  author     = {Sepp Hochreiter and Jürgen Schmidhuber},
  journal    = {{Neural} {Computation}},
  title      = {{Long} {Short}-{Term} {Memory}},
  year       = {1997},
  issn       = {0899-7667},
  month      = nov,
  number     = {8},
  pages      = {1735--1780},
  volume     = {9},
  acmid      = {1246450},
  address    = {Cambridge, MA, USA},
  doi        = {10.1162/neco.1997.9.8.1735},
  issue_date = {November 15, 1997},
  numpages   = {46},
  publisher  = {{MIT} Press - Journals},
  url        = {http://dx.doi.org/10.1162/neco.1997.9.8.1735},
}

@inproceedings{indra2020,
	author    = {Genta Indra Winata and
	Guangsen Wang and
	Caiming Xiong and
	Steven C. H. Hoi},
	title     = {Adapt-and-Adjust: Overcoming the Long-Tail Problem of Multilingual
	Speech Recognition},
	booktitle   = {Proceedings of the Interspeech conference},
	volume    = {abs/2012.01687},
	year      = {2021},
	eprinttype = {arXiv},
	eprint    = {2012.01687},
	biburl    = {https://dblp.org/rec/journals/corr/abs-2012-01687.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}


@inproceedings{kinoshita2020,
	author = {Kinoshita, Keisuke and Ochiai, Tsubasa and Delcroix, Marc and Nakatani, Tomohiro},
	booktitle = {Proceedings of the IEEE ICASSP},
	title = {Improving noise robust automatic speech recognition with single-channel time-domain enhancement network},
	publisher = {arXiv},
	year = {2020},
	copyright = {arXiv.org perpetual, non-exclusive license}
}

@InProceedings{kingma14,
	author    = {Kingma, Diederik P. and Ba, Jimmy},
	booktitle = {{{Proceedings}} of the 3rd {International} {Conference} of {Learning} {Representations} ({ICLR})},
	title     = {{{Adam}}: A {{Method}} for {{Stochastic}} {{Optimization}}.},
	year      = {2014},
	month     = dec,
}

@article{chai2021,
author = {Junyi Chai and Hao Zeng and Anming Li and Eric W.T. Ngai},
title = {Deep learning in computer vision: A critical review of emerging techniques and application scenarios},
journal = {Machine Learning with Applications},
volume = {6},
pages = {100134},
year = {2021},
issn = {2666-8270},
doi = {https://doi.org/10.1016/j.mlwa.2021.100134},
}


@InProceedings{berry2022,
  doi = {10.48550/ARXIV.2211.01180},
  url = {https://arxiv.org/abs/2211.01180},
  author = {Berry, Layne and Shih, Yi-Jen and Wang, Hsuan-Fu and Chang, Heng-Jui and Lee, Hung-yi and Harwath, David},
  title = {M-SpeechCLIP: Leveraging Large-Scale, Pre-Trained Models for Multilingual Speech to Image Retrieval},
  booktitle = {arXiv Preprint, submitted to ICASSP 2023},
  year = {2022},
  copyright = {Creative Commons Attribution 4.0 International}
}

@InProceedings{vaswani2017,
  author    = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N. and Kaiser, \L{}ukasz and Polosukhin, Illia},
  booktitle = {{Proceedings} of the 31st {Neural} {Information} {Processing} {Systems} conference ({NIPS})},
  title     = {{Attention} is {All} You Need},
  year      = {2017},
  address   = {Red Hook, NY, USA},
  pages     = {6000–6010},
  publisher = {{Curran} {Associates} {Inc.}},
  series    = {NIPS'17},
  isbn      = {9781510860964},
  location  = {Long Beach, California, USA},
  numpages  = {11},
}

@inproceedings{naihan2019,
author = {Li, Naihan and Liu, Shujie and Liu, Yanqing and Zhao, Sheng and Liu, Ming},
title = {Neural Speech Synthesis with Transformer Network},
year = {2019},
isbn = {978-1-57735-809-1},
publisher = {AAAI Press},
doi = {10.1609/aaai.v33i01.33016706},
booktitle = {Proceedings of the 31st AAAI Conference on Artificial Intelligence},
articleno = {823},
numpages = {8},
location = {Honolulu, Hawaii, USA},
series = {AAAI'19/IAAI'19/EAAI'19}
}

@inbook{georgila2017, place={Cambridge}, title={Speech Synthesis: State of the Art and Challenges for the Future}, DOI={10.1017/9781316676202.019}, booktitle={Social Signal Processing}, publisher={Cambridge University Press}, author={Georgila, Kallirroi}, year={2017}, pages={257–272}}

@book{taylor2009, place={Cambridge}, title={Text-to-Speech Synthesis}, DOI={10.1017/CBO9780511816338}, publisher={Cambridge University Press}, author={Taylor, Paul}, year={2009}}

@Book{goodfellow2016,
	author    = {Goodfellow, Ian and Bengio, Joshua and Courville, Aaron},
	publisher = {{MIT} Press},
	title     = {{Deep} {Learning}},
	year      = {2016},
	isbn      = {9780262035613},
	month     = nov,
	ean       = {9780262035613},
	pagetotal = {800},
	url       = {http://www.deeplearningbook.org},
}


@Book{bishop2006,
	author    = {Bishop, Christopher M.},
	publisher = {Springer-Verlag New York Inc.},
	title     = {{Pattern} {Recognition} and {Machine} {Learning} ({Information} {Science} and {Statistics})},
	year      = {2011},
	isbn      = {0387310738},
	month     = apr,
	city      = {Berlin, Heidelberg},
	ean       = {9780387310732},
	pagetotal = {738},
	url       = {https://www.ebook.de/de/product/5324937/christopher_m_bishop_pattern_recognition_and_machine_learning.html},
}

@inproceedings{ploujnikov2022,
  author    = {Artem Ploujnikov and
               Mirco Ravanelli},
  editor    = {Hanseok Ko and
               John H. L. Hansen},
  title     = {SoundChoice: Grapheme-to-Phoneme Models with Semantic Disambiguation},
  booktitle = {Interspeech 2022, 23rd Annual Conference of the International Speech
               Communication Association, Incheon, Korea, 18-22 September 2022},
  pages     = {486--490},
  publisher = {{ISCA}},
  year      = {2022},
  url       = {https://doi.org/10.21437/Interspeech.2022-11066},
  doi       = {10.21437/Interspeech.2022-11066},
  timestamp = {Tue, 11 Oct 2022 19:11:50 +0200},
  biburl    = {https://dblp.org/rec/conf/interspeech/PloujnikovR22.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{ren2022,
    title = "Revisiting Over-Smoothness in Text to Speech",
    author = "Ren, Yi  and
      Tan, Xu  and
      Qin, Tao  and
      Zhao, Zhou  and
      Liu, Tie-Yan",
    booktitle = "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1)",
    month = may,
    year = "2022",
    address = "Dublin, Ireland",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.acl-long.564",
    doi = "10.18653/v1/2022.acl-long.564",
    pages = "8197--8213"
}

@misc{vcc_2018,
  doi = {10.48550/ARXIV.1804.04262},
  url = {https://arxiv.org/abs/1804.04262},
  author = {Lorenzo-Trueba, Jaime and Yamagishi, Junichi and Toda, Tomoki and Saito, Daisuke and Villavicencio, Fernando and Kinnunen, Tomi and Ling, Zhenhua},
  keywords = {Audio and Speech Processing (eess.AS), Computation and Language (cs.CL), Sound (cs.SD), Machine Learning (stat.ML), FOS: Electrical engineering, electronic engineering, information engineering, FOS: Electrical engineering, electronic engineering, information engineering, FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {The Voice Conversion Challenge 2018: Promoting Development of Parallel and Nonparallel Methods},
  publisher = {arXiv},
  year = {2018},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@INPROCEEDINGS{parrotron,
  author={Doshi, Rohan and Chen, Youzheng and Jiang, Liyang and Zhang, Xia and Biadsy, Fadi and Ramabhadran, Bhuvana and Chu, Fang and Rosenberg, Andrew and Moreno, Pedro J.},
  booktitle={ICASSP 2021 - 2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={Extending Parrotron: An End-to-End, Speech Conversion and Speech Recognition Model for Atypical Speech}, 
  year={2021},
  volume={},
  number={},
  pages={6988-6992},
  doi={10.1109/ICASSP39728.2021.9414644}}
  
@Inproceedings{isik2020,
 author = {Umut Isik and Ritwik Giri and Neerad Phansalkar and Jean-Marc Valin and Karim Helwani and Arvindh Krishnaswamy},
 title = {PoCoNet: Better speech enhancement with frequency-positional embeddings, semi-supervised conversational data, and biased loss},
 year = {2020},
 booktitle = {Interspeech 2020},
}

@ARTICLE{radford2022,
       author = {{Radford}, Alec and {Kim}, Jong Wook and {Xu}, Tao and {Brockman}, Greg and {McLeavey}, Christine and {Sutskever}, Ilya},
        title = "{Robust Speech Recognition via Large-Scale Weak Supervision}",
      journal = {arXiv e-prints},
     keywords = {Electrical Engineering and Systems Science - Audio and Speech Processing, Computer Science - Computation and Language, Computer Science - Machine Learning, Computer Science - Sound},
         year = 2022,
        month = dec,
          eid = {arXiv:2212.04356},
        pages = {arXiv:2212.04356},
          doi = {10.48550/arXiv.2212.04356},
archivePrefix = {arXiv},
       eprint = {2212.04356},
 primaryClass = {eess.AS},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2022arXiv221204356R},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@ARTICLE{elizalde2022,
       author = {{Elizalde}, Benjamin and {Deshmukh}, Soham and {Al Ismail}, Mahmoud and {Wang}, Huaming},
        title = "{CLAP: Learning Audio Concepts From Natural Language Supervision}",
      journal = {arXiv e-prints},
     keywords = {Computer Science - Sound, Electrical Engineering and Systems Science - Audio and Speech Processing},
         year = 2022,
        month = jun,
          eid = {arXiv:2206.04769},
        pages = {arXiv:2206.04769},
          doi = {10.48550/arXiv.2206.04769},
archivePrefix = {arXiv},
       eprint = {2206.04769},
 primaryClass = {cs.SD},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2022arXiv220604769E},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@inproceedings{ardila2020,
    title = "Common Voice: A Massively-Multilingual Speech Corpus",
    author = "Ardila, Rosana  and
      Branson, Megan  and
      Davis, Kelly  and
      Kohler, Michael  and
      Meyer, Josh  and
      Henretty, Michael  and
      Morais, Reuben  and
      Saunders, Lindsay  and
      Tyers, Francis  and
      Weber, Gregor",
    booktitle = "Proceedings of the 12th Language Resources and Evaluation Conference",
    month = may,
    year = "2020",
    address = "Marseille, France",
    publisher = "European Language Resources Association",
    pages = "4218--4222",
    ISBN = "979-10-95546-34-4",
}

@INPROCEEDINGS{gabrys2022,
  author={Gabryś, Adam and Huybrechts, Goeric and Ribeiro, Manuel Sam and Chien, Chung-Ming and Roth, Julian and Comini, Giulia and Barra-Chicote, Roberto and Perz, Bartek and Lorenzo-Trueba, Jaime},
  booktitle={ICASSP 2022 - 2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={Voice Filter: Few-Shot Text-to-Speech Speaker Adaptation Using Voice Conversion as a Post-Processing Module}, 
  year={2022},
  volume={},
  number={},
  pages={7902-7906},
  doi={10.1109/ICASSP43922.2022.9747239}
  }

@misc{wells1995,
  author = {Wells, J. C.},
  note   = {[Online resource; accessed 23-July-2023]},
  title  = {Computer-coding the {IPA}: a proposed extension of {SAMPA}},
  url    = {https://www.phon.ucl.ac.uk/home/sampa/ipasam-x.pdf},
  year   = {1995}
}