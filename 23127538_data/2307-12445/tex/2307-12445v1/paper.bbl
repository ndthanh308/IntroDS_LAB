\begin{thebibliography}{10}

\bibitem{ardila2020}
Rosana Ardila, Megan Branson, Kelly Davis, Michael Kohler, Josh Meyer, Michael
  Henretty, Reuben Morais, Lindsay Saunders, Francis Tyers, and Gregor Weber,
  `Common voice: A massively-multilingual speech corpus', in {\em Proceedings
  of the 12th Language Resources and Evaluation Conference}, pp. 4218--4222,
  Marseille, France, (May 2020). European Language Resources Association.

\bibitem{berry2022}
Layne Berry, Yi-Jen Shih, Hsuan-Fu Wang, Heng-Jui Chang, Hung-yi Lee, and David
  Harwath, `M-speechclip: Leveraging large-scale, pre-trained models for
  multilingual speech to image retrieval', in {\em arXiv Preprint, submitted to
  ICASSP 2023}, (2022).

\bibitem{bishop2006}
Christopher~M. Bishop, {\em {Pattern} {Recognition} and {Machine} {Learning}
  ({Information} {Science} and {Statistics})}, Springer-Verlag New York Inc.,
  April 2011.

\bibitem{cao2022}
Rui Cao, Yihao Wang, Yuxin Liang, Ling Gao, Jie Zheng, Jie Ren, and Zheng Wang,
  `Exploring the impact of negative samples of contrastive learning: A case
  study of sentence embedding', in {\em Findings of the Association for
  Computational Linguistics: ACL 2022}, pp. 3138--3152, Dublin, Ireland, (May
  2022). Association for Computational Linguistics.

\bibitem{chai2021}
Junyi Chai, Hao Zeng, Anming Li, and Eric~W.T. Ngai, `Deep learning in computer
  vision: A critical review of emerging techniques and application scenarios',
  {\em Machine Learning with Applications}, {\bf 6},  100134, (2021).

\bibitem{conde2021}
Marcos~V. Conde and Kerem Turgutlu, `Clip-art: Contrastive pre-training for
  fine-grained art classification', in {\em IEEE/CVF Conference on Computer
  Vision and Pattern Recognition Workshops (CVPRW)}, pp. 3951--3955, (2021).

\bibitem{parrotron}
Rohan Doshi, Youzheng Chen, Liyang Jiang, Xia Zhang, Fadi Biadsy, Bhuvana
  Ramabhadran, Fang Chu, Andrew Rosenberg, and Pedro~J. Moreno, `Extending
  parrotron: An end-to-end, speech conversion and speech recognition model for
  atypical speech', in {\em ICASSP 2021 - 2021 IEEE International Conference on
  Acoustics, Speech and Signal Processing (ICASSP)}, pp. 6988--6992, (2021).

\bibitem{elizalde2022}
Benjamin {Elizalde}, Soham {Deshmukh}, Mahmoud {Al Ismail}, and Huaming {Wang},
  `{CLAP: Learning Audio Concepts From Natural Language Supervision}', {\em
  arXiv e-prints},  arXiv:2206.04769, (June 2022).

\bibitem{gabrys2022}
Adam Gabryś, Goeric Huybrechts, Manuel~Sam Ribeiro, Chung-Ming Chien, Julian
  Roth, Giulia Comini, Roberto Barra-Chicote, Bartek Perz, and Jaime
  Lorenzo-Trueba, `Voice filter: Few-shot text-to-speech speaker adaptation
  using voice conversion as a post-processing module', in {\em ICASSP 2022 -
  2022 IEEE International Conference on Acoustics, Speech and Signal Processing
  (ICASSP)}, pp. 7902--7906, (2022).

\bibitem{garcia2019}
Basi Garcia, Brendan Shillingford, Hank Liao, Olivier Siohan, Otavio de~Pinho
  Forin~Braga, Takaki Makino, and Yannis Assael, `Recurrent neural network
  transducer for audio-visual speech recognition', in {\em Proceedings of IEEE
  Automatic Speech Recognition and Understanding Workshop}, (2019).

\bibitem{georgila2017}
Kallirroi Georgila, {\em Speech Synthesis: State of the Art and Challenges for
  the Future},  257–272, Cambridge University Press, 2017.

\bibitem{goodfellow2016}
Ian Goodfellow, Joshua Bengio, and Aaron Courville, {\em {Deep} {Learning}},
  {MIT} Press, November 2016.

\bibitem{guzhov2021}
Andrey Guzhov, Federico Raue, Jörn Hees, and Andreas Dengel, `Audioclip:
  Extending clip to image, text and audio', in {\em ICASSP 2022}, pp. 976--980,
  (2022).

\bibitem{schmidhuber1997}
Sepp Hochreiter and Jürgen Schmidhuber, `{Long} {Short}-{Term} {Memory}', {\em
  {Neural} {Computation}}, {\bf 9}(8),  1735--1780, (November 1997).

\bibitem{isik2020}
Umut Isik, Ritwik Giri, Neerad Phansalkar, Jean-Marc Valin, Karim Helwani, and
  Arvindh Krishnaswamy, `Poconet: Better speech enhancement with
  frequency-positional embeddings, semi-supervised conversational data, and
  biased loss', in {\em Interspeech 2020}, (2020).

\bibitem{khandelwal2022}
Apoorv Khandelwal, Luca Weihs, Roozbeh Mottaghi, and Aniruddha Kembhavi,
  `Simple but effective: Clip embeddings for embodied ai', in {\em 2022
  IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, pp.
  14809--14818, (2022).

\bibitem{kingma14}
Diederik~P. Kingma and Jimmy Ba, `{{Adam}}: A {{Method}} for {{Stochastic}}
  {{Optimization}}.', in {\em {{Proceedings}} of the 3rd {International}
  {Conference} of {Learning} {Representations} ({ICLR})}, (December 2014).

\bibitem{kinoshita2020}
Keisuke Kinoshita, Tsubasa Ochiai, Marc Delcroix, and Tomohiro Nakatani,
  `Improving noise robust automatic speech recognition with single-channel
  time-domain enhancement network', in {\em Proceedings of the IEEE ICASSP}.
  arXiv, (2020).

\bibitem{lekhac2020}
Phuc~H. Le-Khac, Graham Healy, and Alan~F. Smeaton, `Contrastive representation
  learning: A framework and review', {\em IEEE Access}, {\bf 8},
  193907--193934, (2020).

\bibitem{naihan2019}
Naihan Li, Shujie Liu, Yanqing Liu, Sheng Zhao, and Ming Liu, `Neural speech
  synthesis with transformer network', in {\em Proceedings of the 31st AAAI
  Conference on Artificial Intelligence}, AAAI'19/IAAI'19/EAAI'19. AAAI Press,
  (2019).

\bibitem{vcc_2018}
Jaime Lorenzo-Trueba, Junichi Yamagishi, Tomoki Toda, Daisuke Saito, Fernando
  Villavicencio, Tomi Kinnunen, and Zhenhua Ling.
\newblock The voice conversion challenge 2018: Promoting development of
  parallel and nonparallel methods, 2018.

\bibitem{mcauliffe2017}
Michael McAuliffe, Michaela Socolof, Sarah Mihuc, Michael Wagner, and Morgan
  Sonderegger, `{Montreal Forced Aligner: Trainable Text-Speech Alignment Using
  Kaldi}', in {\em Proceedings of the Interspeech conference}, pp. 498--502,
  (2017).

\bibitem{ploujnikov2022}
Artem Ploujnikov and Mirco Ravanelli, `Soundchoice: Grapheme-to-phoneme models
  with semantic disambiguation', in {\em Interspeech 2022, 23rd Annual
  Conference of the International Speech Communication Association, Incheon,
  Korea, 18-22 September 2022}, eds., Hanseok Ko and John H.~L. Hansen, pp.
  486--490. {ISCA}, (2022).

\bibitem{radford2021}
Alec Radford, Jong~Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh,
  Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark,
  Gretchen Krueger, and Ilya Sutskever, `Learning transferable visual models
  from natural language supervision', in {\em Proceedings of the 38th
  International Conference on Machine Learning}, eds., Marina Meila and Tong
  Zhang, volume 139 of {\em Proceedings of Machine Learning Research}, pp.
  8748--8763. PMLR, (18--24 Jul 2021).

\bibitem{ren2022}
Yi~Ren, Xu~Tan, Tao Qin, Zhou Zhao, and Tie-Yan Liu, `Revisiting
  over-smoothness in text to speech', in {\em Proceedings of the 60th Annual
  Meeting of the Association for Computational Linguistics (Volume 1)}, pp.
  8197--8213, Dublin, Ireland, (May 2022). Association for Computational
  Linguistics.

\bibitem{robinson2021}
Joshua Robinson, Ching{-}Yao Chuang, Suvrit Sra, and Stefanie Jegelka,
  `Contrastive learning with hard negative samples', in {\em Proceedings of the
  International Conference of Learning Representations (ICLR)}, (2021).

\bibitem{rombach2021}
Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Björn
  Ommer, `High-resolution image synthesis with latent diffusion models', in
  {\em 2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition
  (CVPR)}, pp. 10674--10685, (2022).

\bibitem{shen2018}
Jonathan Shen, Ruoming Pang, Ron~J. Weiss, Mike Schuster, Navdeep Jaitly,
  Zongheng Yang, Zhifeng Chen, Yu~Zhang, Yuxuan Wang, Rj~Skerrv-Ryan, Rif~A.
  Saurous, Yannis Agiomvrgiannakis, and Yonghui Wu, `Natural tts synthesis by
  conditioning wavenet on mel spectrogram predictions', in {\em IEEE
  International Conference on Acoustics, Speech and Signal Processing
  (ICASSP)}, pp. 4779--4783, (2018).

\bibitem{shih2022}
Yi-Jen Shih, Hsuan-Fu Wang, Heng-Jui Chang, Layne Berry, Hung-yi Lee, and David
  Harwath, `Speechclip: Integrating speech with pre-trained vision and language
  model', in {\em Proceedings of the IEEE Workshop on Spoken Language
  Technology 2022}, (2022).

\bibitem{taylor2009}
Paul Taylor, {\em Text-to-Speech Synthesis}, Cambridge University Press, 2009.

\bibitem{urli2022}
Federico Urli, Emiliano Versini, and Lauro Snidaro, `Fusion of sentence
  embeddings for news retrieval', in {\em 2022 25th International Conference on
  Information Fusion (FUSION)}, pp. 1--7, (2022).

\bibitem{vanderoord2016}
A{\"{a}}ron van~den Oord, Sander Dieleman, Heiga Zen, Karen Simonyan, Oriol
  Vinyals, Alex Graves, Nal Kalchbrenner, Andrew~W. Senior, and Koray
  Kavukcuoglu, `{WaveNet}: {A} {Generative} {Model} for {Raw} {Audio}', in {\em
  Proceedings of the 9th International Speech Communication Association
  ({ISCA}), Speech Synthesis Workshop, Sunnyvale, CA, USA}, p. 125. {ISCA},
  (September 2016).

\bibitem{vaswani2017}
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,
  Aidan~N. Gomez, \L{}ukasz Kaiser, and Illia Polosukhin, `{Attention} is {All}
  you need', in {\em {Proceedings} of the 31st {Neural} {Information}
  {Processing} {Systems} conference ({NIPS})}, NIPS'17, p. 6000–6010, Red
  Hook, NY, USA, (2017). {Curran} {Associates} {Inc.}

\bibitem{wells1995}
J.~C. Wells.
\newblock Computer-coding the {IPA}: a proposed extension of {SAMPA}, 1995.
\newblock [Online resource; accessed 23-July-2023].

\bibitem{indra2020}
Genta~Indra Winata, Guangsen Wang, Caiming Xiong, and Steven C.~H. Hoi,
  `Adapt-and-adjust: Overcoming the long-tail problem of multilingual speech
  recognition', in {\em Proceedings of the Interspeech conference}, volume
  abs/2012.01687, (2021).

\bibitem{wu2021}
{Ho Hsiang} Wu, Prem Seetharaman, Kundan Kumar, and {Juan Pablo} Bello,
  `Wav2clip: Learning robust audio representations from clip', in {\em 2022
  IEEE International Conference on Acoustics, Speech, and Signal Processing,
  ICASSP 2022 - Proceedings}, pp. 4563--4567, (2022).

\end{thebibliography}
