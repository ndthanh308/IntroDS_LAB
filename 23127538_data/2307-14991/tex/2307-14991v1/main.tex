
\documentclass[sigconf]{acmart}
\settopmatter{authorsperrow=4}
\bibliographystyle{ACM-Reference-Format}
\acmConference[ESEC/FSE 2023]{The 31st ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering}{11 - 17 November, 2023}{San Francisco, USA}

\copyrightyear{2023}
\acmYear{2023}
\setcopyright{acmlicensed}\acmConference[ASE '22]{37th IEEE/ACM International Conference on Automated Software Engineering}{October 10--14, 2022}{Rochester, MI, USA}
\acmBooktitle{37th IEEE/ACM International Conference on Automated Software Engineering (ASE '22), October 10--14, 2022, Rochester, MI, USA}
\acmPrice{15.00}
\acmDOI{10.1145/3551349.3556955}
\acmISBN{978-1-4503-9475-8/22/10}



\usepackage{booktabs}
\usepackage{xspace}
\usepackage{hyperref}
\usepackage{graphicx}
\usepackage{multirow}
\usepackage{listings}
\usepackage{makecell}
\usepackage{enumitem}
\usepackage{tikz}
\usepackage{subcaption}
\usepackage{caption}
\usepackage{balance}
\usepackage{microtype}


\newcommand{\ltrue}{\top} %
\newcommand{\lfalse}{\bot} %

\newcommand{\limply}{\rightarrow} %
\newcommand{\liff}{\leftrightarrow} %
\newcommand{\lcofactor}{\downarrow} %

\newcommand{\llimply}{\Rightarrow} %
\newcommand{\lliff}{\Leftrightarrow} %
\newcommand{\lsat}{\vDash} %
\newcommand{\lnsat}{\nvDash} %

\newcommand{\lqall}[1]{\forall #1.~} %
\newcommand{\lqexist}[1]{\exists #1.~} %
\newcommand{\lqallOnly}[1]{\forall #1 } %
\newcommand{\lqexistOnly}[1]{\exists #1 } %

\newcommand{\lAnd}[1]{\bigwedge_{\substack{#1}}} %
\newcommand{\lOr}[1]{\bigvee_{\substack{#1}}} %

\newcommand{\set}[1]{\{#1\}} %
\newcommand{\Set}[1]{\left\{#1\right\}} %
\newcommand{\tuple}[1]{\langle#1\rangle} %
\newcommand{\Tuple}[1]{\left\langle#1\right\rangle} %

\newcommand{\sunion}{\cup} %
\newcommand{\sinter}{\cap} %




\definecolor{gray}{RGB}{211,211,211}
\definecolor{javared}{rgb}{0.6,0,0} %
\definecolor{javagreen}{rgb}{0.25,0.5,0.35} %
\definecolor{javapurple}{rgb}{0.5,0,0.2} %
\definecolor{javadocblue}{rgb}{0.25,0.35,0.75} %
\newcommand{\jbasicstyle}{\small\sffamily} %
\newcommand{\textcode}[1]{{#1}}
\newcommand{\jnumberstyle}{\scriptsize}
\newcommand{\Hilight}{\makebox[0pt][l]{\color{gray}\rule[-3pt]{0.80\linewidth}{9pt}}}

\lstdefinelanguage{pseudo}
{
  morekeywords={},
  keywordstyle=\bfseries,
  lineskip=-0.1em,
  numbers=left, %
  numberstyle=\jnumberstyle,
  numbersep=4pt,
  basicstyle=\jbasicstyle,
  breaklines=true,
  breakautoindent=true,
  tabsize=2,
  columns=fullflexible,
  morecomment=*[l][\textsl]{//},
  mathescape=true,
  xleftmargin=10pt,
}

\lstdefinelanguage{todo-comment}
{
  morekeywords={},
  keywordstyle=\bfseries,
  lineskip=-0.1em,
  numbers=none,
  basicstyle=\jbasicstyle,
  breaklines=true,
  breakautoindent=true,
  tabsize=2,
  columns=fullflexible,
  morecomment=*[l][\textsl]{//},
  mathescape=true,
  xleftmargin=-10pt,
}

\lstdefinelanguage{java-pretty}
{
  language=java,
  basicstyle=\scriptsize\ttfamily,
  numberstyle=\scriptsize,
  breaklines=true,
  columns=fullflexible,
  %
  showstringspaces=false,
  keywordstyle=\bfseries\color{javadocblue},
  stringstyle=\color{javared},
  commentstyle=\color{javagreen},
  numbersep=-12pt,
  morecomment=[s][\color{javadocblue}]{/**}{*/},
  moredelim=[is][\color{red!50!black}]{(-W<)}{(>W-)},
  moredelim=[is][\bfseries\color{red!80!black}]{(-w<)}{(>w-)},
  moredelim=[is][\color{green!30!black}]{(+W<)}{(>W+)},
  moredelim=[is][\bfseries\color{green!60!black}]{(+w<)}{(>w+)},
}



\lstset{escapeinside={(*@}{@*)}}



\usepackage[inkscapeformat=png]{svg}


\usetikzlibrary{shapes,arrows,positioning,calc}

\tikzstyle{text_box} = [rectangle, text width=15em, text centered]
\tikzstyle{block} = [draw=black, thick, rectangle, text=black, text width=8em, text centered, rounded corners, minimum height=7ex] %
\tikzstyle{line} = [draw, line width=0.25mm, -latex']
\tikzstyle{long_text_box} = [rectangle, text width=15em, minimum size=2cm]
\newcommand*\circled[1]{\tikz[baseline=(char.base)]{
            \node[shape=circle, draw=black, minimum size=0.1, inner sep=0.8pt, fill=white, thick, text=black] (char) {#1};}}
\newcommand{\XSpace}[1]{}
\newcommand{\XComment}[1]{}
\newcommand{\Fix}[1]{\textcolor{red}{#1}}
\newcommand{\mg}[1]{\textcolor{purple}{[#1]}}
\newcommand{\jz}[1]{\textcolor{blue}{#1 --JZ}}
\newcommand{\jl}[1]{\textcolor{olive}{#1 --JL}}
\newcommand{\pn}[1]{\textcolor{orange}{[#1]}}
\newcommand{\jzcr}[1]{\textcolor{blue}{#1}}

\newcommand{\DefMacro}[2]{\expandafter\newcommand\csname rmk-#1\endcsname{#2}}
\newcommand{\UseMacro}[1]{\csname rmk-#1\endcsname}
\newcommand{\RQ}[2]{\vspace{3pt}\noindent\textbf{RQ#1:} #2}

\newcommand{\MyPara}[1]{\vspace{2pt}\noindent\textbf{#1}.}
\newcommand{\MyParaOnly}[1]{\noindent\textbf{#1}}
\newcommand{\reducedstrut}{\vrule width 0pt height .9\ht\strutbox depth .9\dp\strutbox\relax}
\newcommand{\InputWithSpace}[1]{\bgroup\def\arraystretch{1.3}\input{#1}\egroup}
\newcommand{\Code}[1]{{\ifmmode{\mathtt{#1}}\else$\mathtt{#1}$\fi}}
\newcommand{\CodeIn}[1]{{\ifmmode{\mathtt{#1}}\else$\mathtt{#1}$\fi}}
\newcommand{\ColorBack}[1]{%
  \begingroup
  \setlength{\fboxsep}{0pt}%
  \colorbox{purple!20}{\reducedstrut#1\/}%
  \endgroup
}

\usepackage{mdwlist}
\newenvironment{packed_itemize}{
	\begin{itemize*}
		\setlength{\itemsep}{1pt}
		\setlength{\parskip}{0pt}
		\setlength{\parsep}{0pt}
	}{\end{itemize*}}

\newcommand{\mycheckmark}{{\normalsize \checkmark}\xspace}
\newcommand{\mycross}{$\mathbin{\tikz [x=1.4ex,y=1.4ex,line width=.2ex] \draw (0,0) -- (1,1) (0,1) -- (1,0);}$\xspace\xspace}

\newenvironment{myquote}%
  {\list{}{\leftmargin=6pt\rightmargin=0pt}\item[]}%
  {\endlist}
\newcommand{\MyQuote}[1]{\begin{myquote} #1 \end{myquote}}


\newcommand{\bugfix}{bug fixing\xspace}                                                                                                                       
\newcommand{\codereview}{automated code review\xspace}                                                                                                        
\newcommand{\cupdate}{comment updating\xspace}

\newcommand{\Title}{Multilingual Code Co-Evolution Using Large Language Models}

\newcommand{\xMatch}{\textbf{xMatch}\xspace}
\newcommand{\BLEU}{\textbf{BLEU-4}\xspace}
\newcommand{\SARI}{\textbf{SARI}\xspace}
\newcommand{\GLEU}{\textbf{GLEU}\xspace}
\newcommand{\CodeBLEU}{\textbf{CodeBLEU}\xspace}
\newcommand{\METEOR}{\textbf{METEOR}\xspace}
\newcommand{\APIs}{APIs\xspace}
\newcommand{\API}{API\xspace}
\newcommand{\ML}{ML\xspace}
\newcommand{\LLM}{LLM\xspace}
\newcommand{\LLMs}{LLMs\xspace}

\newcommand{\DeltaTool}{\textsc{Codeditor}\xspace}
\newcommand{\Copy}{Copy\xspace}
\newcommand{\translationModel}{CodeT5-Translation\xspace}
\newcommand{\CopyEdits}{CopyEdits\xspace}
\newcommand{\edittranslation}{EditsTranslation\xspace}
\newcommand{\metaEdits}{MetaEdits\xspace}
\newcommand{\Codex}{Codex\xspace}
\DefMacro{CoditT5}{CoditT5\xspace}
\DefMacro{CodeT5Up}{CodeT5-Update\xspace}



\newcommand{\Insert}{\texttt{Insert}\xspace}
\newcommand{\Delete}{\texttt{Delete}\xspace}
\newcommand{\ReplaceOld}{\texttt{ReplaceOld}\xspace}
\newcommand{\ReplaceNew}{\texttt{ReplaceNew}\xspace}


\newcommand{\Train}{Train\xspace}
\newcommand{\Val}{Val\xspace}
\newcommand{\Test}{Test\xspace}
\newcommand{\Pretrained}{Pretrained\xspace}
\newcommand{\Finetuning}{Fine-tuning\xspace}
\newcommand{\CodeTf}{CodeT5\xspace}
\newcommand{\pretrained}{pretrained\xspace}
\newcommand{\pretraining}{pretraining\xspace}
\newcommand{\finetuning}{fine-tuning\xspace}
\newcommand{\finetuned}{fine-tuned\xspace}
\newcommand{\finetune}{fine-tune\xspace}
\newcommand{\Csharp}{C\#\xspace}
\newcommand{\inp}{\textit{inp}\xspace}
\newcommand{\out}{\textit{out}\xspace}
\newcommand{\noisyinp}{\textit{inp$'$}\xspace}
\newcommand{\deltatask}{multilingual co-editing\xspace}
\newcommand{\concise}{concise\xspace}  %
\newcommand{\Concise}{Concise\xspace}
\newcommand{\unambig}{unambiguous\xspace}
\newcommand{\Unambig}{Unambiguous\xspace}
\newcommand{\mode}{mode\xspace}
\newcommand{\modes}{modes\xspace}


\DefMacro{java2cs}{J2CS\xspace}
\DefMacro{cs2java}{CS2J\xspace}

\DefMacro{source}{\ensuremath{S}}
\DefMacro{target}{\ensuremath{T}}
\DefMacro{java_old}{\ensuremath{M_{\UseMacro{source};old}}}
\DefMacro{cs_old}{\ensuremath{M_{\UseMacro{target};old}}}
\DefMacro{java_new}{\ensuremath{M_{\UseMacro{source};new}}}
\DefMacro{cs_new}{\ensuremath{M_{\UseMacro{target};new}}}
\DefMacro{code_old}{\ensuremath{M_{old}}}
\DefMacro{code_new}{\ensuremath{M_{new}}}
\DefMacro{code_java}{\ensuremath{M_{\UseMacro{source}}}}
\DefMacro{code_cs}{\ensuremath{M_{\UseMacro{target}}}}
\DefMacro{java_edits}{\ensuremath{E_{\UseMacro{source}}}}
\DefMacro{cs_edits}{\ensuremath{E_{\UseMacro{target}}}}


\DefMacro{JavaExampleMethod}{\CodeIn{doc}\-\CodeIn{With}\-\CodeIn{Invalid}\-\CodeIn{Mapp}\-\CodeIn{ing02}\xspace}
\DefMacro{CsExampleMethod}{\CodeIn{Doc}\-\CodeIn{With}\-\CodeIn{Invalid}\-\CodeIn{Mapp}\-\CodeIn{ing02}\xspace}

\newcommand{\Java}{Java\xspace}
\newcommand{\Cs}{C\#\xspace}

\newcommand{\TrainRatio}{70\%}
\newcommand{\ValRatio}{10\%}
\newcommand{\TrainValRatio}{80\%\xspace}
\newcommand{\TestRatio}{20\%}
\newcommand{\TokenDiff}{4}
\newcommand{\EditAct}{3}
\newcommand{\ProjectsNum}{8}
\newcommand{\Datasize}{6,613}
\newcommand{\CombineImprove}{18\%}
\newcommand{\BestCodeBLEU}{96}
\newcommand{\CodeBLEUImproved}{25\%}
\newcommand{\BestImproved}{77\%}
\newcommand{\BestImprovedPct}{11.3\%}

\newcommand{\JavaInsertLineNumber}{7}
\newcommand{\JavaFirstReplaceLineNumber}{5}
\newcommand{\JavaSecondReplaceLineNumber}{6}

\newcommand{\JCthreshold}{201}
\newcommand{\CJthreshold}{212}

\DefMacro{TCap-edits-map}{The mappings between \concise edit sequence and \unambig edit sequence.  \label{tab:edit-sequence} \vspace{-0pt}}
\DefMacro{TCap-java2cs-translation-dataset}{Statistics of the Java to Csharp translation dataset.}
\DefMacro{TCap-significance-test}{The results with the same suffixes (e.g., $\beta$) are NOT statistically significantly different.}
\DefMacro{Models-Desciptions}{*-Translation models are machine translation models, given the new Java method, they are trained to translate to new C\# code; CoditT5-Translation generates edits that convert Java to C\#; CodeT5-Update generates new C\# based on new Java code and old C\# code; CoditT5 generates C\# edits together with new C\# based on old C\#, Java edits and new Java}
\DefMacro{TCap-java2cs-translation-models-results}{Results on the \UseMacro{java2cs} dataset. \UseMacro{TCap-significance-test} \label{tab:java2cstranslation-results} \vspace{-0pt}}
\DefMacro{TCap-cs2java-translation-models-results}{Results on the \UseMacro{cs2java} dataset. \UseMacro{TCap-significance-test} \label{tab:cs2javatranslation-results} \vspace{-0pt}}
\DefMacro{TCap-java2cs-ag-translation-models-results}{Results of the Java to Csharp translation task trained with augmented data.}
\DefMacro{TCap-java2cs-new-test-translation-models-results}{Results of the Java to C\# translation on jts project (unseen)}

\DefMacro{TCap-clean-test-java2cs-translation-models-results}{Results of models on the \textbf{Clean Test} set. \UseMacro{Models-Desciptions}}
\DefMacro{TCap-real-world-dataset-stats}{Open-source projects used in our dataset and number of examples from each project.\label{tab: real-world-dataset-stats}\vspace{-3pt}}
\DefMacro{TCap-dataset-edits-stats}{Statistics of our dataset. Number of examples of training, validation and test data; average number of tokens in the old version of method and new version of method; average number of edits for the code change; average number of added and deleted tokens.\label{tab: dataset-edits-stats}\vspace{-3pt}}

\DefMacro{TVspace-real-world-dataset-stats}{-0pt}
\DefMacro{TVspace-dataset-edits-stats}{-0pt}
\DefMacro{TVspace-java2cs-translation-models-results}{-0pt}
\DefMacro{TVspace-cs2java-translation-models-results}{-0pt}
\DefMacro{TVspace-edits-map}{-0pt}

\DefMacro{THead-train}{\Train\xspace}
\DefMacro{THead-valid}{\Val\xspace}
\DefMacro{THead-test}{\Test\xspace}
\DefMacro{THead-augment}{Extra\xspace}
\DefMacro{THead-cleaned-test}{Clean Test\xspace}
\DefMacro{THead-semi}{Synthetic \xspace}
\DefMacro{THead-test-clean}{Clean Test\xspace}
\DefMacro{THead-all}{All\xspace}

\DefMacro{THead-Acc-top-1}{xMatch\xspace}
\DefMacro{THead-BLEU}{BLEU-4\xspace}
\DefMacro{THead-CodeBLEU}{CodeBLEU\xspace}
\DefMacro{THead-SARI}{SARI\xspace}
\DefMacro{THead-GLEU}{GLEU\xspace}
\DefMacro{THead-ngram_match_score}{Corpus-BLEU}

\DefMacro{THead-models}{Models\xspace}
\DefMacro{THead-weighted_ngram_match_score}{W. N-gram}
\DefMacro{THead-syntax_match_score}{Syntax}
\DefMacro{THead-dataflow_match_score}{Dfg}

\DefMacro{THead-translation-CodeT5}{\translationModel\xspace}
\DefMacro{THead-translation-CodeT5-ag}{CodeT5-Translation-\emph{extra}\xspace}
\DefMacro{THead-update-CodeT5}{\UseMacro{CodeT5Up}\xspace}
\DefMacro{THead-CopyEdits}{\CopyEdits\xspace}
\DefMacro{THead-metaEdits}{\metaEdits\xspace}
\DefMacro{THead-edit-translation}{\edittranslation\xspace}
\DefMacro{THead-editModel}{Edit Model\xspace}
\DefMacro{THead-update-CodeT5-ag}{CodeT5-Update-\emph{extra}\xspace}
\DefMacro{THead-hybrid}{Hybrid}

\DefMacro{THead-translation-CoditT5}{CoditT5-Translation\xspace}
\DefMacro{THead-CoditT5}{CoditT5\xspace}
\DefMacro{THead-CoditT5-ag}{CoditT5-\emph{extra}\xspace}
\DefMacro{THead-copy}{Copy\xspace}
\DefMacro{THead-codex}{Codex\xspace}

\DefMacro{THead-count}{Count\xspace}
\DefMacro{THead-java-project}{Java Project\xspace}
\DefMacro{THead-cs-project}{C\# Project\xspace}
\DefMacro{THead-train-commit}{\Train commit dates\xspace}
\DefMacro{THead-valid-commit}{\Val commit dates\xspace}
\DefMacro{THead-test-commit}{\Test commit dates\xspace}
\DefMacro{THead-cs-edit-distance-mean}{Edit distance for C\#}
\DefMacro{THead-java-edit-distance-mean}{Edit distance for Java}

\DefMacro{THead-mean-old-method-size}{Avg. len(\UseMacro{code_old})}
\DefMacro{THead-mean-new-method-size}{Avg. len(\UseMacro{code_new})}
\DefMacro{THead-mean-edit-actions}{Avg. \# edits}
\DefMacro{THead-mean-edit-lines}{Avg. \# edited lines}
\DefMacro{THead-mean-edit-tokens}{Avg. \# tks}
\DefMacro{THead-mean-add-tokens}{Avg. \# add. tks}
\DefMacro{THead-mean-del-tokens}{Avg. \# del. tks}

\input{tables/numbers-java2cs-translation-dataset.tex}
\input{tables/numbers-java2cs-translation-models-results.tex}
\input{tables/numbers-java2cs-ag-translation-models-results.tex}
\input{tables/numbers-clean-test-java2cs-translation-models-results.tex}
\input{tables/numbers-real-world-dataset.tex}
\input{tables/numbers-synthetic-dataset.tex}
\input{tables/numbers-java2cs-new-test-translation-models-results.tex}
\input{tables/numbers-cs2java-translation-models-results.tex}
\input{tables/numbers-dataset-edits-stats.tex}


\DefMacro{FCap-model-figure}{Workflow of \DeltaTool for \deltatask.
\DeltaTool leverages the context of code change histories of multiple
programming languages from three sources: code changes on the source
programming language (\UseMacro{java_edits}), the old version of code
in the target programming language (\UseMacro{cs_old}), and the new
version of code in the source programming language
(\UseMacro{java_new}). \DeltaTool has two variants that both generate
the code changes in the target programming language
(\UseMacro{cs_edits}) but in different formats: \edittranslation
directly generates the code changes; \metaEdits generates the meta
edit plan which edits \UseMacro{java_edits} to \UseMacro{cs_edits},
followed by the code changes. Finally, we apply the code changes
(\UseMacro{cs_edits}) on the old version of code (\UseMacro{cs_old})
to obtain the new version of code (\UseMacro{cs_new}) in the target
programming language.  \label{fig:model-architecture}}
\DefMacro{FCap-xMatch-tokens-number}{Average percentage of model's predictions that exactly match the ground truth on examples that have different number of subtokens. The bands represent the 95\% confidence interval.}
\DefMacro{FCap-ref-tokens-number-dist}{Distribution of number of sub tokens in models' target outputs.}

\DefMacro{intro-example-java-method}{\texttt{doc\-With\-Invalid\-Mapp\-ing02}}
\DefMacro{intro-example-cs-method}{\texttt{Doc\-With\-Invalid\-Mapp\-ing02}}
\DefMacro{intro-example-old-edits}{\texttt{<ReplaceOld> PdfException <ReplaceNew> LayoutExceptionMessageConstant <ReplaceEnd>}}
\DefMacro{intro-example-java-edits}{\texttt{<ReplaceOldKeepBefore> format(PdfException}\\\texttt{<ReplaceNewKeepBefore> format(}\\\texttt{LayoutExceptionMessageConstant <ReplaceEnd>}}
\DefMacro{intro-example-cs-edits}{\texttt{<ReplaceOldKeepBefore> Format(PdfException}\\\texttt{<ReplaceNewKeepBefore> Format(}\\\texttt{LayoutExceptionMessageConstant <ReplaceEnd>}}
\DefMacro{intro-example-meta-edits}{\texttt{<ReplaceOld> format <ReplaceNew> Format <ReplaceEnd>}}
\DefMacro{intro-example-java-concise-edits}{\texttt{<ReplaceOld> PdfException <Replace\-New> LayoutExceptionMessageConstant <ReplaceEnd>}}

\DefMacro{git-add-color}{green!10}
\DefMacro{git-del-color}{red!10}



\settopmatter{printfolios=true, printccs=false, printacmref=false} %
\renewcommand\footnotetextcopyrightpermission[1]{} %
\pagestyle{plain} %

\title{\Title}


\author{Jiyang Zhang}
\affiliation{
  \institution{The University of Texas at Austin}
  \city{Austin}
  \state{TX}
  \country{USA}
}
\email{jiyang.zhang@utexas.edu}

\author{Pengyu Nie}
\affiliation{
  \institution{The University of Texas at Austin}
  \city{Austin}
  \state{TX}
  \country{USA}
}
\email{pynie@utexas.edu}

\author{Junyi Jessy Li}
\affiliation{
  \institution{The University of Texas at Austin}
  \city{Austin}
  \state{TX}
  \country{USA}
}
\email{jessy@austin.utexas.edu}

\author{Milos Gligoric}
\affiliation{
  \institution{The University of Texas at Austin}
  \city{Austin}
  \state{TX}
  \country{USA}
}
\email{gligoric@utexas.edu}


\begin{document}

\begin{abstract}
Many software projects implement \APIs and algorithms in multiple
programming languages.  Maintaining such projects is tiresome, as
developers have to ensure that any change (e.g., a bug fix or a new
feature) is being propagated, timely and without errors, to
implementations in other programming languages.
In the world of ever-changing software, using rule-based translation
tools (i.e., transpilers) or machine learning models for translating
code from one language to another provides limited value.  Translating
each time the entire codebase from one language to another is not the
way developers work.
In this paper, we target a novel task: translating code changes from
one programming language to another using large language models
(\LLMs).
We design and implement the first \LLM, dubbed \DeltaTool, to
tackle this task.  \DeltaTool explicitly models code changes as edit
sequences and learns to correlate changes across programming languages.
To evaluate \DeltaTool, we collect a corpus of \Datasize{} aligned
code changes from \ProjectsNum{} pairs of open-source software
projects implementing similar functionalities in two programming
languages (Java and \Cs).  Results show that \DeltaTool
outperforms the state-of-the-art approaches by a large margin on all
commonly used automatic metrics.
Our work also reveals that \DeltaTool is complementary to the
existing generation-based models, and their combination
ensures even greater performance.
\end{abstract}



\maketitle


\section{Introduction}

To ensure flexibility and a wide adoption of their software, companies
provide application programming interfaces (\APIs) for their services
in several programming languages.  Services, such as Google
Cloud~\cite{GoogleCloud} and MongoDB~\cite{MongoDB}, offer APIs
written in most popular programming languages, including C++, C\#,
Java, and Python.  Furthermore, popular software packages, like
Antlr~\cite{antlr} and Lucene~\cite{Lucene}, have options to target
different programming languages for the purpose of being used across
various platforms easily.

Maintaining software that offers the same functionality in multiple
programming languages is challenging.  Any code change, due to a
feature request or a bug fix, has to be propagated timely to all
programming languages.  At present, developers have to manually
\emph{co-evolve} code.  This requires developers to manually find the
correspondence between code snippets and apply necessary \emph{edits}.


% Figure environment removed

There has been work that could, in theory, help with translation.
Rule-based migration tools~\cite{java2csharp, c2rust, j2eif} have been
designed to translate between high-level programming languages (e.g.,
\Java{} and \Cs{}).  However, rule-based systems require developers
who have expertise with both programming languages to manually write
rules to specify the translation mappings.  And the rules need to be
updated with the evolution of programming languages themselves; they
quickly become outdated~\cite{BuiETAL18Hierarchical, java2csharp}.
Recent work on automatic code translation~\cite{RoziereETAL21TransCoderST,
  CodeXGLUE, TipirneniETAL22StructCoder, LachauxETAL20TransCoder, ZhuETAL22Multilingual} aim to directly
translate between a source and a target programming languages with the
help of \LLMs, which are 
\pretrained on multiple programming languages.  While these techniques
could be used to produce code snippets that look correct, they make
irrelevant changes that deviate substantially from the newly
introduced features in the source programming language, or they fail
to precisely infer the project-specific data types and class names.

Figure~\ref{fig:intro-example} illustrates the limitation of existing
models.  Developers changed \CodeIn{PdfException} to
\CodeIn{LayoutExceptionMessageConstant} in method
\UseMacro{intro-example-java-method} in the \Java project
\CodeIn{itext/}\-\CodeIn{itext7}.
In a later commit in the corresponding \Cs project
\CodeIn{itext/}\-\CodeIn{itext7\text{-}dotnet}, developers revised method
\UseMacro{intro-example-cs-method} with exactly the same edits while
keeping other parts of the method unchanged.
We provide the \Java code change, the prediction of an existing large
language model, \CodeTf~\cite{WangETAL21codet5}, \finetuned for code
translation, and the correct \Cs code change in
Figure~\ref{fig:intro-example}.  The added lines of code are
highlighted in green and the removed ones are highlighted in red.
Although the existing model is able to correctly translate the updated
exception type from \Java to \Cs, it misses the class name for the
field \CodeIn{HtmlRoles} and incorrectly infers the function call
\CodeIn{Assert.Catch} as it does \emph{not} use the prior version of
\Cs code for reference.

To build more robust and accurate techniques that help software
developers co-evolve projects implemented in different languages, we
explicitly model the \emph{changes} that need to be made.
We formulate a novel task:
automatically \emph{updating} code snippets in a target programming
language, based on the \emph{changes} made in the source programming
language.

Most of the existing models implicitly tackle the code evolution tasks
by generating tokens one by one in accordance with the underlying
learned probability instead of focusing on how the code should be
\emph{modified} or retained.  Prior work~\cite{ZhangETAL22CoditT5,
YaoETAL21Learning, ChakrabortyAndRay21Multi, Codit,
TufanoETAL19Learning, DingETAL20Patching, PanthaplackelETAL20Learning}
have shown that standard generation-based models underperform models
that explicitly model the edits on software-editing tasks.

To model code evolution across programming languages, we design a LLM, dubbed \DeltaTool, 
which learns to align the edits
across programming languages and explicitly performs edits on the old
version of the code in target programming language.
Following prior work~\cite{ZhangETAL22CoditT5,
  PanthaplackelETAL20Learning, DingETAL20Patching, stahlberg2020seq2edits}, we
enable the model to reason about necessary 
edits and learn to apply them by directly generating an edit sequence.

  
For training and evaluation, we collect the first dataset with aligned
\Java and \Cs code changes on the methods with similar functionality
and implementations.  Specifically, we extract \Datasize{} pairs of
code changes from \ProjectsNum{} open-source \Java{} projects and the
corresponding \Cs{} projects on GitHub by mining the commit histories.
This is the first dataset containing parallel code changes of two
programming languages.
We conduct the evaluation in two directions, updating \Cs method based
on the \Java changes (source language is \Java and target language is
\Cs) and updating \Java method based on the \Cs changes (source
language is \Cs and target language is \Java).

Our results show that \DeltaTool outperforms all existing models
across all the chosen automatic metrics, including the large \pretrained
generative model Codex~\cite{Codex}.  \DeltaTool achieves
\BestCodeBLEU{} (out of 100) CodeBLEU score on task of updating \Cs
code based on \Java changes, which is more than
\CodeBLEUImproved{} higher than the large \pretrained generation-based
model \finetuned on this task.

Further, we find that \DeltaTool and generation-based models are
complementary to each other as \DeltaTool is better at updating longer
code snippets while generation model is better at handling the shorter
ones.  Thus, we combine the two models by choosing either model's
prediction based on the size of the input code.
Our results show that the combination can further improve our
\DeltaTool model's exact-match accuracy by 6\%.

\vspace{3pt}
\noindent
The main contributions of this paper include:

\begin{itemize}[topsep=3pt,itemsep=1ex,partopsep=0ex,parsep=0ex,leftmargin=*]
\item \textbf{Task}. We formulate a novel task of automatically
updating code written in one programming language based on the changes
in the corresponding code in another programming language.
\item \textbf{Model}. We design and implement \DeltaTool, the first
\LLM for this task which learns to align the edits across programming
languages and explicitly performs edits on the old version of the code
in target programming language.
\item \textbf{Dataset}. We create the first dataset with aligned code
changes for two programming languages from \ProjectsNum{} open-source
project pairs.
\item \textbf{Results}. We show that \DeltaTool significantly
outperforms the existing LLMs \finetuned for code translation on exact-match accuracy by 
\BestImproved{}.
We also show
that \DeltaTool is complementary to generation-based \LLMs and the
combination can further improve \DeltaTool's exact-match accuracy by
6\%.
\end{itemize}

\noindent


\section{Task}

At a high level, we work on a system that is triggered when a software
developer, who maintains projects written in multiple programming
languages, makes changes to one method in one of the languages, i.e.,
the ``source'' language.
The system would automatically suggest updates to the methods with
identical functionality in other language(s), i.e., the ``target''
language(s).
To scope our work in this paper, we focus on \Java as the source
language, and \Cs as the target language.  However, our approach is
generalizable to other programming languages and we leave evaluation
that targets other programming languages as future work.


In Figure~\ref{fig:intro-example}, consider a method
\UseMacro{java_old} (\UseMacro{intro-example-java-method}) written in
the source language \UseMacro{source} and a method \UseMacro{cs_old}
(\UseMacro{intro-example-cs-method}) written in the target language
\UseMacro{target} with identical functionality (hence similar
implementation). 
Given the updated method \UseMacro{java_new} in \UseMacro{source}, we
define the
task to generate the new method \UseMacro{cs_new} in \UseMacro{target}
leveraging context provided by the code changes \UseMacro{java_edits},
such that its functionality is consistent with \UseMacro{java_new}.
Namely, we model the conditional probability distribution
\begin{center}
$P(\UseMacro{cs_new} | \UseMacro{cs_old},\: \UseMacro{java_new}, \UseMacro{java_edits})$
\end{center}
and generate \UseMacro{cs_new} by sampling
from the distribution.

% Figure environment removed



\section{Model}

We present the overview of the proposed \DeltaTool model in
Figure~\ref{fig:model-architecture}.  \DeltaTool is built upon the
encoder-decoder framework which consists of a transformer-based
encoder and a transformer-based decoder~\cite{VaswaniETAL17Attention}.
Many conditional generation tasks, including code summarization and
translation, are being addressed with encoder-decoder
models~\cite{WangETAL21codet5, PLBART, GuoETAL22Unixcoder, CodeT5Plus}.


We initialize \DeltaTool's parameters with the \pretrained language
model CoditT5~\cite{ZhangETAL22CoditT5}. CoditT5 has shown promising
results on various software-related editing tasks \emph{in a single
programming language}, but nonetheless would provide us with a
``warm-start'' that carries the necessary inductive biases towards
modeling edits.  To adapt to the \deltatask task, we then
fine-tune the \DeltaTool model exploring two key components: (i)~the
context fed into the model; (ii)~the output format of the model.

To encourage our \DeltaTool model to leverage the (synchronous) code
change histories of multiple programming languages in
its training data, we provide the model with context from three
sources as shown in Figure~\ref{fig:model-architecture}: (i)~code changes on source programming language
(\UseMacro{java_edits});
(ii)~old version of the code written in target programming language
(\UseMacro{cs_old});
(iii)~new version of the code written in source programming language
(\UseMacro{java_new}).

We explore two formats to represent the generated code changes:
(i)~the code edits in the target programming language (\UseMacro{cs_edits}); (ii)~a meta
edit sequence that translates the code edits from the source programming
language to the target programming language, followed by the code
edits in the target programming language (this is similar to the
output format of CoditT5).
\noindent
In both cases, we then apply the generated code edits in the target
programming language (\UseMacro{cs_edits}) to the old version of the
code (\UseMacro{cs_old}) to obtain the new version of the code
(\UseMacro{cs_new}).




\newcommand{\specialtwocell}[2][c]{%
  \begin{tabular}[#1]{@{}l@{}}#2\end{tabular}}

\newcommand{\specialthreecell}[2][c]{%
  \begin{tabular}[#1]{@{}l@{}l@{}}#2\end{tabular}}

\begin{small}
\begin{table}[t]
\begin{center}
\caption{\UseMacro{TCap-edits-map}}
\begin{tabular}{l l l}
    \toprule
    \textbf{Edit}
    & \textbf{\Concise}
    & \textbf{\Unambig}
    \\
    \midrule
    \multirow{2}{*}{Insertion}
    & \multirow{2}{*}{\texttt{<Insert>}}
    &
    \specialtwocell[t]{\texttt{<ReplaceKeepBefore>}\\ \texttt{<ReplaceKeepAfter>}}
    \\
    \midrule
    %
    \multirow{3}{*}{Deletion}
    & \multirow{3}{*}{\texttt{<Delete>}}
    & %
    \specialthreecell[t]{\texttt{<Delete>} \\ \texttt{<ReplaceKeepBefore>}\\ \texttt{<ReplaceKeepAfter>}}
    \\
    \midrule
    \multirow{3}{*}{Replacement}
    & \multirow{3}{*}{\texttt{<Replace>}}
    & \specialthreecell[t]{\texttt{<Replace>} \\ \texttt{<ReplaceKeepBefore>}\\ \texttt{<ReplaceKeepAfter>}}
    \\
    \bottomrule
\end{tabular}
\vspace{\UseMacro{TVspace-edits-map}}
\end{center}
\end{table}
\end{small}



\subsection{Edit Representations}
\label{sec:edits}

\subsubsection{\Concise Edit Sequence}
\label{sec:edits-sequence}
We first represent edits using a sequence of edits identical to that
used in CoditT5~\cite{ZhangETAL22CoditT5}, which we call \concise edit
sequence.  Each edit is represented as:
\MyQuote{
\texttt{<Operation> [token span] <OperationEnd>}
}
Here, \texttt{<Operation>} is either \CodeIn{Insert}, \CodeIn{Delete}
or \CodeIn{Replace}.  Note that the \CodeIn{Replace} is
represented in a slightly different structure since we must specify
both the old contents to be replaced and the new contents to replace
with:
\MyQuote{
\texttt{<ReplaceOld> [old contents] <ReplaceNew>}\\
\texttt{[new contents] <ReplaceEnd>}
}
For example, in Figure~\ref{fig:intro-example}, the code change on the
old \Java method can be represented by
``\UseMacro{intro-example-java-concise-edits}''.

We use \texttt{difflib}~\cite{difflib} to compute the set of minimal edit sequence from the old and new versions of code.

\subsubsection{\Unambig Edit Sequence}
\label{sec: unambiguous-edits}
One drawback of CoditT5~\cite{ZhangETAL22CoditT5}'s representation
specified above is that the \concise edit sequence can be ambiguous
due to the absence of positional information.  For example, the
\Java{} code change in Figure~\ref{fig:intro-example} can be
represented using \CodeIn{Replace} as:
``\UseMacro{intro-example-java-concise-edits}''.  Without further
specification, the edit does not contain any clues regarding which
\CodeIn{PdfException} should be replaced as there are two occurrences
of \CodeIn{PdfException} in the old code sequence.
For similar reasons, \CodeIn{Insert} is always ambiguous
because of not indicating where to add the new contents and
\CodeIn{Delete} is ambiguous in cases where multiple
occurrences of token spans can be removed.

To eliminate the potential ambiguity in the \concise edit sequence, we
design the format of \unambig edit sequence by adjusting the condensed
edit sequence proposed by~\citet{PanthaplackelETAL20Learning}, which
uses anchor tokens to specify the location to perform
edits.

\MyPara{Insertion}
We do not use \CodeIn{Insert} since it will always
introduce ambiguity without location information.  To represent
insertion, we first find unique anchor tokens that are the shortest
span of tokens that is either before or after the edit location and is
unique in the input sequence.  Then we use \CodeIn{ReplaceKeepBefore}
or \CodeIn{ReplaceKeep}\-\CodeIn{After}, which represents replacing the anchor tokens with
the inserted contents and the anchor tokens.
For example, in Figure~\ref{fig:intro-example}, suppose the \Java{}
code change entails adding a blank return statement after the
\CodeIn{assertEquals} statement on line \JavaInsertLineNumber.
The token span ``\CodeIn{getMessage());}'' will serve as the minimal span
of anchor tokens because it is unique among the old \Java{} code
sequence, and it occurs right before the edit to be performed.  We
disambiguate the edit sequence:
\MyQuote{
\texttt{<Insert> return; <InsertEnd>}
}
with the \unambig edit sequence:
\MyQuote{
\texttt{<ReplaceOldKeepBefore> getMessage());}\\
\texttt{<ReplaceNewKeepBefore> getMessage()); return;}\\
\texttt{<ReplaceEnd>}
}
This edit sequence indicates that ``\CodeIn{getMessage());}'' should
be replaced with ``\CodeIn{getMessage()); return;}''.
We introduce \CodeIn{ReplaceKeep}\-\CodeIn{Before} where the
tokens that follows the \texttt{<ReplaceOldKeep\-Before>} should be
removed and the tokens following
\texttt{<ReplaceNew\-Keep\-Before>} should be inserted.  Different from
\CodeIn{Replace}, there is some overlap between the tokens to be
removed and tokens to be inserted.
If anchor tokens do not exist before the edit location, we use
\CodeIn{ReplaceKeepAfter} with the tokens after the edit location
instead.

\MyPara{Replacement}
If the span of tokens to be replaced is unique in the old sequence,
regular \CodeIn{Replace} sequence is sufficient and deterministic; in
that case we will keep using it.  Otherwise, it is unclear which
occurrence of token span should be replaced.  As an example, in
Figure~\ref{fig:intro-example}, the \Java{} code change is changing
from \CodeIn{PdfException} to \CodeIn{LayoutExceptionMessageConstant}
in the \CodeIn{assertEquals} statement on line
\JavaSecondReplaceLineNumber.
The replacement in the \concise edit sequence is ambiguous because
there are two usages of \CodeIn{PdfException} (on
lines~\JavaFirstReplaceLineNumber{} and \JavaSecondReplaceLineNumber)
in the old \Java{} code sequence after tokenization.
To address this, similar to the insertion case, we search for the
minimal anchor tokens before or after the edit location that can form
a unique span in the old sequence.  For example, the \concise edit sequence:
\MyQuote{
\texttt{<ReplaceOld> PdfException <ReplaceNew>}\\
\texttt{LayoutExceptionMessageConstant <ReplaceEnd>}
}
can be disambiguate into the following \unambig edit sequence:
\MyQuote{
\texttt{<ReplaceOldKeepBefore> format(PdfException}\\
\texttt{<ReplaceNewKeepBefore> format(}\\
\texttt{LayoutExceptionMessageConstant <ReplaceEnd>}
}

\MyPara{Deletion}
Similar to replacement, if the span of tokens to be deleted is unique
across the old sequence, we will keep using \CodeIn{Delete} because it
is unambiguous.  Otherwise, it will be transformed to
\CodeIn{ReplaceKeepBefore} or \CodeIn{ReplaceKeepAfter}.  For example,
suppose the token ``\CodeIn{PdfException.}'' should be removed from
the old \Java{} method on line \JavaSecondReplaceLineNumber{} in
Figure~\ref{fig:intro-example}.  The \concise edit sequence:
\MyQuote{
\texttt{<Delete> PdfException. <DeleteEnd>}
}
will be transformed to:
\MyQuote{
\texttt{<ReplaceOldKeepBefore> format(PdfException.}\\
\texttt{<ReplaceNewKeepBefore> format( <ReplaceEnd>}
} This edit sequence indicates that ``\CodeIn{format(PdfException.}''
should be replaced with ``\CodeIn{format(}'', unambiguously implying
the deletion of ``\CodeIn{PdfException.}''.

To summarize, the \unambig edit sequence contains 4 types of edits:
\texttt{<Replace>}, \texttt{<Delete>}, \texttt{<ReplaceKeepBefore>}
and \texttt{<Re\-place\-KeepAfter>}.  The mappings between \concise
edit sequence and \unambig edit sequence are summarized in
Table~\ref{tab:edit-sequence}.  Given the \unambig edit sequence, we
can apply it to the old input sequence to derive the new edited
sequence deterministically.

\subsection{Model Input}
\label{sec:model-input}

We aim to build performant machine learning models for the \deltatask
task by providing the model with code evolution information, namely
the revisions of code of both source and target programming languages.
Instead of directly translating the entire code snippet between
programming languages, \DeltaTool translates the code \emph{changes}
between programming languages.

\subsubsection{Source Code Edits}
To encourage the model to learn the alignment between developer-made
changes in different programming languages, we provide \DeltaTool
with code changes in source programming languages.  To maintain both
precision and conciseness of the edits, we adopt the \unambig edit
sequence (Section~\ref{sec: unambiguous-edits}) to represent the code
changes.  As shown in Figure~\ref{fig:model-architecture}, the \Java{}
code changes (\UseMacro{java_edits}) of replacing the \CodeIn{PdfException} with
\CodeIn{LayoutExceptionMessageConstant} is structured in the form of
\MyQuote{
\UseMacro{intro-example-java-edits}
}

\subsubsection{History-Related Context}

In addition to the learned representation of code changes in source
programming language (\UseMacro{java_edits}), we provide \DeltaTool
with the old code in target programming language (\UseMacro{cs_old})
to better help the model to infer the correlated code changes in the
target programming language.  The intuition is that the model will
reason about how to transfer and tune the edits in source programming
language grounding the specific implementation of the method in target
programming language.

Furthermore, we append the new code in source programming language
(\UseMacro{java_new}) as one of the contexts.  We believe this will
give the model more context to understand the edits in source
programming language and promote the consistency of the updated
methods in two programming languages.

To sum up, we combine history-related context from three sources: code
changes in source programming language (\UseMacro{java_edits}), old
code in target programming language (\UseMacro{cs_old}), and new code
in source programming language (\UseMacro{java_new}).  We concatenate
them into a sequence separated by a special \emph{SEP} token as the
model input.

\subsection{Model output}
\label{sec:model-output}

We propose two formats as the model's target output which lead to two
\modes of \DeltaTool: \emph{\edittranslation} and \emph{\metaEdits}.
Both \modes use the same input and both \modes' target outputs entail
a sequence of edits on the target programming language.

\MyPara{\edittranslation} The output of \edittranslation \mode is the
\unambig edit sequence in target programming language which suggests
how the code in target programming language should be changed.  Note
that the model-generated \unambig edit sequence can be parsed and
applied to old version of code deterministically.  \edittranslation
essentially learns to translate the code edits from the source
programming language (\UseMacro{java_edits}) to the target programming
language (\UseMacro{cs_edits}) grounding the code history context.
\edittranslation \mode's target output for the \Cs example in
Figure~\ref{fig:intro-example} is:
\MyQuote{
\UseMacro{intro-example-cs-edits}
}

\MyPara{\metaEdits} 
In this \mode, we adopt the output format of
CoditT5~\cite{ZhangETAL22CoditT5} for \deltatask since our model is
built upon it, and it had showed promising performance on software editing
tasks.  CoditT5 is \pretrained to generate the following output
format: ``[Edit Plan] <SEP> [Target Sequence]''.  The edit plan is a
\concise edit sequence that represents the steps to edit the input
sequence; the target sequence is the edited sequence after applying
the proceeding edit plan.
We tailored this format to the \deltatask task; the edit plan
represents the edits on the code edits on source programming language
(\UseMacro{java_edits}) which we call the \emph{meta edit sequence}.
And the final target sequence should be the \unambig edit sequence on
the target programming language (\UseMacro{cs_edits}).  For the
example in Figure~\ref{fig:intro-example}, the expected meta edit
sequence is:
\MyQuote{
\UseMacro{intro-example-meta-edits}
}
The target sequence after applying the meta edit sequence is: 
\MyQuote{
\UseMacro{intro-example-cs-edits}
}
Note that during inference, we only use the target \unambig edit
sequence to get the updated code in target programming language as
\metaEdits mode's prediction.
  



\section{Dataset}

This is the first work to consider the history of software projects in
a multilingual task; hence, we also created a new dataset that
includes aligned code changes between programming languages.  As the
first step, we build the dataset by mining histories of the
open-source \Java and \Cs projects.   
We first collect the changed methods from the commits of the \Java and
\Cs projects.
We then design heuristics to pair (i.e., align) those changes on
methods with similar implementations and functionalities.
We consider two directions on our dataset:
\UseMacro{java2cs} (updating \Cs method based on \Java changes) and
\UseMacro{cs2java} (updating \Java method based on \Cs changes).  In this section,
we describe the approach we use to collect the data
(Section~\ref{sec:data-collect}), split and preprocess data
(Section~\ref{sec:data-split}), and finally present the statistics of
our dataset (Section~\ref{sec:data-stats}).




\begin{table}[t]
\begin{center}
\begin{small}
\caption{\UseMacro{TCap-real-world-dataset-stats}}
\begin{tabular}{l l  r }
\toprule
\textbf{\UseMacro{THead-java-project}}
 & \textbf{\UseMacro{THead-cs-project}}
 & \textbf{\UseMacro{THead-count}}
\\
\midrule
antlr/antlr4
& tunnelvisionlabs/antlr4cs
 & \UseMacro{antlr-antlr4-count}
\\
apache/lucene
& apache/lucenenet
 & \UseMacro{apache-lucene-count}
\\
apache/poi
&nissl-lab/npoi
 & \UseMacro{apache-poi-count}
\\
eclipse/jgit
& mono/ngit
 & \UseMacro{eclipse-jgit-count}
\\
formicary/fpml-toolkit-java
& formicary/fpml-toolkit-csharp
 & \UseMacro{formicary-fpml-toolkit-java-count}
\\
itext/itext7
& itext/itext7-dotnet
 & \UseMacro{itext-itext7-count}
 \\
quartz-scheduler/quartz
& quartznet/quartznet
 & \UseMacro{quartz-scheduler-quartz-count}
\\
terabyte/jgit
& mono/ngit
 & \UseMacro{terabyte-jgit-count}
\\
\midrule
\textbf{SUM}
&
& \Datasize\\
\bottomrule
\end{tabular}
\vspace{\UseMacro{TVspace-real-world-dataset-stats}}
\end{small}
\end{center}
\end{table}





\begin{table}[t]
\begin{center}
\caption{\UseMacro{TCap-dataset-edits-stats}}
\begin{tabular}{l  l | r  r  r }
\toprule
 & 
 & \textbf{\UseMacro{THead-train}}
 & \textbf{\UseMacro{THead-valid}}
 & \textbf{\UseMacro{THead-test}}
\\
\midrule
\multicolumn{2}{l|}{\UseMacro{THead-count}}
 & \UseMacro{ds-train-count}
 & \UseMacro{ds-valid-count}
 & \UseMacro{ds-test-count}
 \\
 \midrule
\multirow{5}{*}{Java}
& \UseMacro{THead-mean-old-method-size}
 & \UseMacro{train-java-mean-old-method-size}
 & \UseMacro{valid-java-mean-old-method-size}
 & \UseMacro{test-java-mean-old-method-size}
\\
&\UseMacro{THead-mean-new-method-size}
 & \UseMacro{train-java-mean-new-method-size}
 & \UseMacro{valid-java-mean-new-method-size}
 & \UseMacro{test-java-mean-new-method-size}
\\
&\UseMacro{THead-mean-edit-actions}
 & \UseMacro{train-java-mean-edit-actions}
 & \UseMacro{valid-java-mean-edit-actions}
 & \UseMacro{test-java-mean-edit-actions}
\\
&\UseMacro{THead-mean-add-tokens}
 & \UseMacro{train-java-mean-add-tokens}
 & \UseMacro{valid-java-mean-add-tokens}
 & \UseMacro{test-java-mean-add-tokens}
\\
&\UseMacro{THead-mean-del-tokens}
 & \UseMacro{train-java-mean-del-tokens}
 & \UseMacro{valid-java-mean-del-tokens}
 & \UseMacro{test-java-mean-del-tokens}
\\
\midrule
\multirow{5}{*}{C\#}
&\UseMacro{THead-mean-old-method-size}
 & \UseMacro{train-cs-mean-old-method-size}
 & \UseMacro{valid-cs-mean-old-method-size}
 & \UseMacro{test-cs-mean-old-method-size}
\\
&\UseMacro{THead-mean-new-method-size}
 & \UseMacro{train-cs-mean-new-method-size}
 & \UseMacro{valid-cs-mean-new-method-size}
 & \UseMacro{test-cs-mean-new-method-size}
\\
&\UseMacro{THead-mean-edit-actions}
 & \UseMacro{train-cs-mean-edit-actions}
 & \UseMacro{valid-cs-mean-edit-actions}
 & \UseMacro{test-cs-mean-edit-actions}
\\
&\UseMacro{THead-mean-add-tokens}
 & \UseMacro{train-cs-mean-add-tokens}
 & \UseMacro{valid-cs-mean-add-tokens}
 & \UseMacro{test-cs-mean-add-tokens}
\\
&\UseMacro{THead-mean-del-tokens}
 & \UseMacro{train-cs-mean-del-tokens}
 & \UseMacro{valid-cs-mean-del-tokens}
 & \UseMacro{test-cs-mean-del-tokens}
\\
\bottomrule
\end{tabular}
\vspace{\UseMacro{TVspace-dataset-edits-stats}}
\end{center}
\end{table}



\subsection{Data Collection}
\label{sec:data-collect}
To build the dataset, we extract aligned \Java and \Cs code changes at
the method level as pairs of the form (\Java old method; \Java new
method, \Cs old method; \Cs new method).  The code changes are mined
from the git commits.  We consider \ProjectsNum{} open-source projects
as listed in Table~\ref{tab: real-world-dataset-stats} which have both
\Java and \Cs implementations and are used in prior
work~\cite{NguyenETAL15Divide, CodeXGLUE, ChenETAL18Tree}.  All the
projects were first developed in \Java and then ported to \Cs.

To collect the paired changes, we first assign a unique identifier to
each method in the projects (for both \Java and \Cs projects) based on
the method signature, class name and path to the file where the method
is defined.  Similar to the strategy used by \citet{CodeXGLUE}, we
then pair the \Java methods and \Cs methods according to the
similarity of their unique identifiers.  This strategy is effective
because the ported \Cs project has very similar structure and naming
rules for classes and methods to the corresponding \Java project.

We use the following rules to extract the aligned code changes:
\begin{enumerate}[topsep=3pt,itemsep=1ex,partopsep=0ex,parsep=0ex,leftmargin=*]
\item For each \Java method change, we extract the code changes in the
paired \Cs method that happen no later than 90 days of the \Java
change as the \emph{possible matched code change}. We use the commit
date as the time of the change.
\item To filter those unrelated code changes, we subtokenize and normalize all the possible matched code
changes based on camelCase (e.g., \CodeIn{lastModified} to
\CodeIn{last}\ \CodeIn{modi}\-\CodeIn{fied}) and disregard those \Java and \Cs
matched changes that have the Jaccard similarity~\cite{Jaccard}
lower than predefined threshold in terms of added and removed
sub-tokens as well as the added and deleted lines of code.
\item For each \Java code change and \Cs code change, we only select
the most similar corresponding code change if there are multiple
possible matched code changes.
\end{enumerate}

\subsection{Data Splitting and Preprocessing}
\label{sec:data-split}
We envision the following use case for the machine learning model:
whenever a developer makes a change in the project written in source
programming language, the developer will use the model trained on the
existing historical aligned code changes to migrate that change to
projects written in other target programming languages.  To evaluate
the models under this use case, following the recommendations from prior
work~\cite{NieETAL22EvalMethodologies}, we split the dataset into
training, validation and test sets using the time-segmented approach.
Namely, the changes in the training set took place before the changes
in the validation set, which in turn took place before the changes in
the test set.  To be concrete, for each \Java and \Cs code change
pair, we first collect the time of the \Cs commit and then sort the
code change pairs in chronological order.  We then select the oldest
\TrainRatio{} of the code change pairs from each project as training
data, next oldest \ValRatio{} as validation data, the remaining as test
data.
For both \Java and \Cs methods, we remove the inline natural language
comments and tokenize the method into tokens using the
language-specific lexers generated by Antlr~\cite{antlr}.

\subsection{Statistics}
\label{sec:data-stats}
The statistics of the collected dataset are shown in Table~\ref{tab:
  dataset-edits-stats}.  We present the number of examples in the
training, validation, and test dataset.
We show the average number of tokens in the old methods (Avg.
len(\UseMacro{code_old})) and new methods (Avg.
len(\UseMacro{code_new})) after tokenization by the lexers.  To
measure the size of the code changes, we calculate the average number
of added tokens (Avg. \# add. tks) and deleted tokens (Avg. \# del.
tks) in the changed \Java and \Cs methods as well as the average
number of edits (Avg. \# edits) needed for those changes.  Note that
for computing these edit-related statistics, we represent the code
changes using \concise edit sequences
(Section~\ref{sec:edits-sequence}).

For both \Java and \Cs code changes, the difference between average
number of added tokens and deleted tokens is usually
small, fewer than \TokenDiff{} tokens.  Similarly, we find that the
average number of edits needed is fewer than \EditAct{} and the edits
happened in the newer commits are generally smaller
than prior ones.  This is expected as the software projects are
becoming more stable as they evolve, and thus there will be smaller code
changes to be made.  For evaluation, we run all the models and
baselines on this dataset in two directions: (1)~updating \Cs method based on \Java changes,
 and (2)~updating \Java method based on \Cs changes.  We denote the former
one as \UseMacro{java2cs} and the latter one as \UseMacro{cs2java}.


\section{Experiments}
In this section, we describe the baselines used to compared with our
\DeltaTool model (Section~\ref{sec: baselines}), the evaluation
metrics (Section~\ref{sec: metrics}) and the detailed experiment setup
(Section~\ref{sec: setup}).

\subsection{Baselines}
\label{sec: baselines}
We evaluate our approach against rule-based models, \pretrained
encoder-decoder models, the state-of-the-art code-editing model (which
targets a single programming language), and a large generative model \pretrained on
billions of lines of code.
For all the machine learning models, we use beam size 20 during inference.

\MyPara{\Copy}
This is a rule-based model which copies the old code in target
programming language (\UseMacro{cs_old}) as the prediction.  This is
not a trivial baseline since there are quite a few examples in the
dataset that entail small edits between two versions.  We include this
to benchmark the models that actually update the code.

\MyPara{\CopyEdits}
Based on our observations, there are cases where the code change in
source programming language (\UseMacro{java_edits}) is exactly the
same as the change in target programming language
(\UseMacro{cs_edits}) , such as changing the variable name or updating
the log message.  This rule-based model copies the
\UseMacro{java_edits} and directly applies it to the old code in target
programming language (\UseMacro{cs_old}).

\MyPara{\translationModel}
We consider a state-of-the-art model that does not have access to the
code change history. Namely, a code translation model that translates
code between the programming languages (from \UseMacro{java_new} to
\UseMacro{cs_new}).  We use CodeT5~\cite{WangETAL21codet5}, a \LLM
\pretrained on large amount of developer-written code from GitHub,
which we \finetune on our constructed dataset.

\MyPara{\UseMacro{CodeT5Up}}
This model has the same architecture as \translationModel except that
we supply it with code change history.  The model input is the same as
for our \DeltaTool models, i.e., with extra context of the old code in
target programming language (\UseMacro{cs_old}) and the code change in
source programming language (\UseMacro{java_edits}).  Different from
\DeltaTool model, it is trained to directly generate the new code in
target programming language (\UseMacro{cs_new}).

\MyPara{CoditT5}
This is the state-of-the-art model for software editing
tasks~\cite{ZhangETAL22CoditT5}.  We \finetune it on our dataset,
using the same input as \DeltaTool, while the output consists of the
edit plan to represent the edits on the target programming language
and the target sequence which represents the updated code
(\UseMacro{cs_new}) after applying the edit plan.

\MyPara{\Codex}
Large \pretrained generative models such as GPT-3~\cite{GPT3} have
shown impressive results under the context of \emph{few-shot learning}
or even \emph{zero-shot learning} on various generation tasks.
They are able to generalize to new tasks they have not seen during
\pretraining with only a few or even no labeled examples.  To compare
the \finetuned \DeltaTool model with generative models, we include
\Codex~\cite{Codex}, a large generative model built on GPT-3 and is
further \pretrained on billions of GitHub data.  Following prior
work~\cite{Ahmed22Few,Khan22Automatic}, for each example in test data,
we randomly select several labeled examples in the training data as
the context.  Note that the labeled examples are selected from the
same project as the test data.  For \UseMacro{java2cs} dataset, each
labeled example is formed as: ``\Java: \UseMacro{java_old} =>
\UseMacro{java_new} \Cs: \UseMacro{cs_old} => \UseMacro{cs_new}'' to
inform the model the aligned updates between two programming
languages.  The designed prompt for inference is ``\Java:
\UseMacro{java_old} => \UseMacro{java_new} \Cs: \UseMacro{cs_old} =>
''.  The model output is the prediction for the new code in target
programming language (\UseMacro{cs_new}).
To conform to the required input length limit, we include 2 labeled
examples in the prompt.

\subsection{Evaluation Metrics}
\label{sec: metrics}
Following prior work~\cite{WangETAL21codet5, ZhangETAL22CoditT5,
PanthaplackelETAL20Learning, ahmad-etal-2021-unified}, we use metrics for evaluating the
quality of code generation: BLEU~\cite{papineni2002bleu},
CodeBLEU~\cite{CodeBLEU}, xMatch, and metrics for evaluating the
quality of software editing: SARI~\cite{xu2016optimizing} and
GLEU~\cite{napoles2015ground}.  Note that for all the metrics we
report in this paper, they range from 0 to 100 and higher scores are
better.

\MyPara{xMatch}
When the generated code matches exactly with the expected code in
target programming language, this metric is 100; otherwise, this
metric is 0. This metric reflects the percentage of exact matches
among the models' predictions on test data.

\MyPara{BLEU}
It is a widely used metric originally proposed for evaluating the
quality of machine translation.  It measures the n-gram overlap
between the generated sequence and the expected one.  Concretely, we
report the 1$\sim$4-grams overlap between the tokens in the
predictions and tokens in the ground truth.

\MyPara{CodeBLEU}
The metric is proposed for evaluating the quality of code generation.
In addition to measuring the n-gram overlap, it considers the overlap
of the Abstract Syntax Tree (AST) and data flow graph between
generated code and the expected code.

\MyPara{SARI}
It measures quality of the systems that are designed to make edits.
Specifically, it is computed as the average of the F1 score for kept
and inserted spans of tokens, and the precision of deleted spans of
tokens.

\MyPara{GLEU}
It is a variant of BLEU.  It was originally proposed for grammatical
error correction and designed for rewarding the correct edits while
penalizing the incorrect ones.

\subsection{Experimental Setup}
\label{sec: setup}
We run all experiments on machines with 4 NVidia 1080-TI GPUs,
Intel(R) Xeon(R) CPU E5-2620 v4 @ 2.10GHz for training.  We implement
our models using PyTorch 1.9.0.  All the hyper-parameters of the
CodeT5 and CoditT5 baselines are set to the same values as in prior
work~\cite{WangETAL21codet5, ZhangETAL22CoditT5}.  We early stop the
training when the BLEU score on the validation set does not improve
for 5 epochs.



\section{Results}
\label{sec:eval}

We organize our evaluation around three main research questions:

\RQ{1}{What is the benefit of using code change history in
\deltatask?}

\RQ{2}{How does our edit-based model, \DeltaTool model, compare to
  generation-based models for the \deltatask?}

\RQ{3}{How can a generation-based model complement \DeltaTool model to
  further improve the performance?}

\subsection{Quantitative Analysis}
\label{sec:eval:quantitative}

In Table~\ref{tab:java2cstranslation-results} and
Table~\ref{tab:cs2javatranslation-results}, we present results for
baselines and our proposed \DeltaTool models on \UseMacro{java2cs} and
\UseMacro{cs2java} datasets, respectively.
We conducted statistical significance testing through bootstrap
tests~\cite{Berg-KirkpatrickETAL12Empirical} under confidence level
95\%.




\begin{table*}[t]
\begin{center}
\caption{\UseMacro{TCap-java2cs-translation-models-results}}
\begin{tabular}{l | c  c  c  c  c  c }
\toprule
\textbf{\UseMacro{THead-models}}
 & \textbf{\UseMacro{THead-Acc-top-1}}
 & \textbf{\UseMacro{THead-BLEU}}
 & \textbf{\UseMacro{THead-CodeBLEU}}
 & \textbf{\UseMacro{THead-SARI}}
 & \textbf{\UseMacro{THead-GLEU}}
\\
\midrule
\UseMacro{THead-copy}
 & \UseMacro{res-java2cs-copy-Acc-top-1}
 & \UseMacro{res-java2cs-copy-BLEU}
 & \UseMacro{res-java2cs-copy-CodeBLEU}
 & \UseMacro{res-java2cs-copy-SARI}
 & \UseMacro{res-java2cs-copy-GLEU}
\\
\UseMacro{THead-CopyEdits}
 & \UseMacro{res-java2cs-CopyEdits-Acc-top-1}$^{\beta}$
 & \UseMacro{res-java2cs-CopyEdits-BLEU}$^{\alpha}$$^{\chi}$
 & \UseMacro{res-java2cs-CopyEdits-CodeBLEU}
 & \UseMacro{res-java2cs-CopyEdits-SARI}
 & \UseMacro{res-java2cs-CopyEdits-GLEU}
\\
\midrule
\UseMacro{THead-translation-CodeT5}
 & \UseMacro{res-java2cs-translation-CodeT5-Acc-top-1}$^{\beta}$
 & \UseMacro{res-java2cs-translation-CodeT5-BLEU}
 & \UseMacro{res-java2cs-translation-CodeT5-CodeBLEU}
 & \UseMacro{res-java2cs-translation-CodeT5-SARI}
 & \UseMacro{res-java2cs-translation-CodeT5-GLEU}
\\
\UseMacro{THead-codex}
 & \UseMacro{res-java2cs-codex-Acc-top-1}
 & \UseMacro{res-java2cs-codex-BLEU}
 & \UseMacro{res-java2cs-codex-CodeBLEU}
 & \UseMacro{res-java2cs-codex-SARI}
 & \UseMacro{res-java2cs-codex-GLEU}
\\
\UseMacro{THead-CoditT5}
 & \UseMacro{res-java2cs-CoditT5-Acc-top-1}$^{\epsilon}$
 & \UseMacro{res-java2cs-CoditT5-BLEU}$^{\alpha}$$^{\eta}$
 & \UseMacro{res-java2cs-CoditT5-CodeBLEU}
 & \UseMacro{res-java2cs-CoditT5-SARI}
 & \UseMacro{res-java2cs-CoditT5-GLEU}
\\
\UseMacro{THead-update-CodeT5}
 & \UseMacro{res-java2cs-update-CodeT5-Acc-top-1}$^{\epsilon}$
 & \UseMacro{res-java2cs-update-CodeT5-BLEU}$^{\chi}$$^{\eta}$
 & \UseMacro{res-java2cs-update-CodeT5-CodeBLEU}
 & \UseMacro{res-java2cs-update-CodeT5-SARI}
 & \UseMacro{res-java2cs-update-CodeT5-GLEU}
\\
\midrule
\DeltaTool(\UseMacro{THead-metaEdits})
 & \UseMacro{res-java2cs-metaEdits-Acc-top-1}
 & \UseMacro{res-java2cs-metaEdits-BLEU}
 & \UseMacro{res-java2cs-metaEdits-CodeBLEU}
 & \UseMacro{res-java2cs-metaEdits-SARI}
 & \UseMacro{res-java2cs-metaEdits-GLEU}
\\
\DeltaTool(\UseMacro{THead-edit-translation})
 & \UseMacro{res-java2cs-edit-translation-Acc-top-1}
 & \UseMacro{res-java2cs-edit-translation-BLEU}
 & \UseMacro{res-java2cs-edit-translation-CodeBLEU}
 & \textbf{\UseMacro{res-java2cs-edit-translation-SARI}}$^{\delta}$
 & \UseMacro{res-java2cs-edit-translation-GLEU}
\\
\midrule
\UseMacro{THead-hybrid}
 & \textbf{\UseMacro{res-java2cs-hybrid-Acc-top-1}}
 & \textbf{\UseMacro{res-java2cs-hybrid-BLEU}}
 & \textbf{\UseMacro{res-java2cs-hybrid-CodeBLEU}}
 & \UseMacro{res-java2cs-hybrid-SARI}$^{\delta}$
 & \textbf{\UseMacro{res-java2cs-hybrid-GLEU}}
\\
\bottomrule
\end{tabular}
\vspace{\UseMacro{TVspace-java2cs-translation-models-results}}
\end{center}
\end{table*}





\begin{table*}[t]
\begin{center}
    \caption{\UseMacro{TCap-cs2java-translation-models-results}}
\begin{tabular}{l | c  c  c  c  c  c }
\toprule
\textbf{\UseMacro{THead-models}}
 & \textbf{\UseMacro{THead-Acc-top-1}}
 & \textbf{\UseMacro{THead-BLEU}}
 & \textbf{\UseMacro{THead-CodeBLEU}}
 & \textbf{\UseMacro{THead-SARI}}
 & \textbf{\UseMacro{THead-GLEU}}
\\
\midrule
\UseMacro{THead-copy}
 & \UseMacro{res-cs2java-copy-Acc-top-1}
 & \UseMacro{res-cs2java-copy-BLEU}
 & \UseMacro{res-cs2java-copy-CodeBLEU}
 & \UseMacro{res-cs2java-copy-SARI}
 & \UseMacro{res-cs2java-copy-GLEU}
\\
\UseMacro{THead-CopyEdits}
 & \UseMacro{res-cs2java-CopyEdits-Acc-top-1}
 & \UseMacro{res-cs2java-CopyEdits-BLEU}$^{\alpha}$
 & \UseMacro{res-cs2java-CopyEdits-CodeBLEU}$^{\beta}$
 & \UseMacro{res-cs2java-CopyEdits-SARI}
 & \UseMacro{res-cs2java-CopyEdits-GLEU}$^{\chi}$
\\
\midrule
\UseMacro{THead-translation-CodeT5}
 & \UseMacro{res-cs2java-translation-CodeT5-Acc-top-1}
 & \UseMacro{res-cs2java-translation-CodeT5-BLEU}$^{\alpha}$
 & \UseMacro{res-cs2java-translation-CodeT5-CodeBLEU}$^{\beta}$
 & \UseMacro{res-cs2java-translation-CodeT5-SARI}
 & \UseMacro{res-cs2java-translation-CodeT5-GLEU}$^{\chi}$
\\
\UseMacro{THead-codex}
 & \UseMacro{res-cs2java-codex-Acc-top-1}
 & \UseMacro{res-cs2java-codex-BLEU}
 & \UseMacro{res-cs2java-codex-CodeBLEU}
 & \UseMacro{res-cs2java-codex-SARI}
 & \UseMacro{res-cs2java-codex-GLEU}
\\
\UseMacro{THead-CoditT5}
 & \UseMacro{res-cs2java-CoditT5-Acc-top-1}
 & \UseMacro{res-cs2java-CoditT5-BLEU}
 & \UseMacro{res-cs2java-CoditT5-CodeBLEU}$^{\gamma}$
 & \UseMacro{res-cs2java-CoditT5-SARI}
 & \UseMacro{res-cs2java-CoditT5-GLEU}
\\
\UseMacro{THead-update-CodeT5}
 & \UseMacro{res-cs2java-update-CodeT5-Acc-top-1}
 & \UseMacro{res-cs2java-update-CodeT5-BLEU}
 & \UseMacro{res-cs2java-update-CodeT5-CodeBLEU}$^{\gamma}$
 & \UseMacro{res-cs2java-update-CodeT5-SARI}
 & \UseMacro{res-cs2java-update-CodeT5-GLEU}
\\
\midrule
\DeltaTool(\UseMacro{THead-metaEdits})
 & \textbf{\UseMacro{res-cs2java-metaEdits-Acc-top-1}}$^{\epsilon}$$^{\eta}$
 & \UseMacro{res-cs2java-metaEdits-BLEU}
 & \UseMacro{res-cs2java-metaEdits-CodeBLEU}
 & \UseMacro{res-cs2java-metaEdits-SARI}
 & \UseMacro{res-cs2java-metaEdits-GLEU}
\\
\DeltaTool(\UseMacro{THead-edit-translation})
 & \UseMacro{res-cs2java-edit-translation-Acc-top-1}$^{\delta}$$^{\epsilon}$
 & \UseMacro{res-cs2java-edit-translation-BLEU}
 & \UseMacro{res-cs2java-edit-translation-CodeBLEU}
 & \textbf{\UseMacro{res-cs2java-edit-translation-SARI}}
 & \UseMacro{res-cs2java-edit-translation-GLEU}
\\
\midrule
\UseMacro{THead-hybrid}
 & \UseMacro{res-cs2java-hybrid-Acc-top-1}$^{\delta}$$^{\eta}$
 & \textbf{\UseMacro{res-cs2java-hybrid-BLEU}}
 & \textbf{\UseMacro{res-cs2java-hybrid-CodeBLEU}}
 & \UseMacro{res-cs2java-hybrid-SARI}
 & \textbf{\UseMacro{res-cs2java-hybrid-GLEU}}
\\
\bottomrule
\end{tabular}
\vspace{\UseMacro{TVspace-cs2java-translation-models-results}}
\end{center}
\end{table*}



\RQ{1}{\textbf{Conntribution of code change histories.}}
We divide models into two categories with respect to whether it has
access to the information on code change histories: \Copy and
\translationModel are history-agnostic models, and the remaining are
history-aware models.  Overall, the history-aware models outperform
the history-agnostic ones.  The rule-based model \CopyEdits, which
directly applies the code change in source programming language
(\UseMacro{java_edits}) to the old code in target programming language
without any adaptation, has comparable performance to the
machine learning history-agnostic model \translationModel. This
emphasizes the importance of contextual information provided by code
change histories in \deltatask.
Interestingly, we find that \Codex, which is used under the few-shot
learning setting without \finetuning, performs better than \finetuned
\translationModel on xMatch, while worse than other history-aware
\finetuned machine learning models.  This again underlines the value
of code change histories and suggests that \finetuning will give
better performance by leveraging more code history contexts in the
training data.

% Figure environment removed

% Figure environment removed

\RQ{2}{\textbf{\DeltaTool vs. generation-based models.}}
Among all the history-aware models, machine learning models, such as
\UseMacro{CodeT5Up} and \UseMacro{CoditT5}, achieve much higher
performance than the rule-based \CopyEdits, which demonstrates that
the machine learning models effectively learns to reason about the
correlated code changes and adjust them to the target programming
language.  We observe that \DeltaTool (in both \edittranslation and
\metaEdits \modes), which is trained to first translate code changes
on source programming language to target programming language and then
apply the edits to the old code in target programming language,
achieve even higher performance across all the metrics than the large
\pretrained generation-based model (\UseMacro{CodeT5Up}) which
directly generates the new code in target programming language from scratch.
This highlights that the models that are trained to explicitly perform
edits by predicting the edit sequence are better suited for editing
tasks in the software domain than generation-based models.

% Figure environment removed

To further investigate the advantages of \DeltaTool over the best
generation-based model
(\UseMacro{CodeT5Up}), we break down the performance of
\edittranslation and \UseMacro{CodeT5Up} on each example in the test
data of \UseMacro{java2cs}.  In Figure~\ref{fig:xmatch-token-number},
we show the average percentage of \DeltaTool (\edittranslation) and
\UseMacro{CodeT5Up}'s predictions that exactly match the ground truth
with respect to the number of sub-tokens in the input old code
(\UseMacro{cs_old}).  Note that the code are subtokenized using the
Roberta tokenizer~\cite{Roberta}, which is used by all machine
learning models.  We exclude the examples that have more than 500
sub-tokens from being shown in this figure as those outliers only
account for less than 5\% of the test data.  We can see that the
performance of \UseMacro{CodeT5Up} drastically drops with the increase
of number of sub-tokens in the code to be edited (\UseMacro{cs_old}),
but \edittranslation's performance is rather stable.  This illustrates
another benefit of \DeltaTool in accurately handling longer input,
because of focusing on transforming the edits instead of generating
the entire new code like \UseMacro{CodeT5Up}.

Meanwhile, most of the existing transformer-based models have a length
limit for the input sequence because the naive self-attention has quadratic complexity with regard to the input length.
In Figure~\ref{fig:ref-token-number},
we present the distribution of the number of sub-tokens in the models'
target outputs for \DeltaTool (\edittranslation) and
\UseMacro{CodeT5Up} on the test data of \UseMacro{java2cs}.  We only
show the distribution of target outputs with fewer than 500 sub-tokens
for the same reason.  Most of \DeltaTool's target outputs (the
sequence of edit operations) are shorter than \UseMacro{CodeT5Up}'s
output (new code in target programming language).  This might explain
why \DeltaTool achieves better performance than generation-based
models on longer code as generating longer sequence are generally more
challenging to machine learning models.
Recent studies~\cite{longformer, flashattention, unlimiformer} have focused on exploring approaches to address the limitation of the model's input context window size. Future research should examine the performance difference between translating edit sequences and generating entirely new code using models capable of handling longer context.


\RQ{3}{\textbf{Combining generation-based model with \DeltaTool.}}
To exploit the superiority of generation-based model on short code
snippets, we combine our strongest generation
model---\UseMacro{CodeT5Up}---with the strongest \DeltaTool
\mode---\edittranslation---based on the size of the code snippet.
Specifically, we use \UseMacro{CodeT5Up} if the code to be updated has
fewer sub-tokens than a threshold and use \DeltaTool
(\edittranslation) otherwise.
To pick the threshold for combining two models, we performed a
grid-search on the validation set and selected the one that gives
optimal xMatch score.  The threshold we used is \JCthreshold{} on
\UseMacro{java2cs} and \CJthreshold{} on \UseMacro{cs2java}.  We refer to
the combined model as the \emph{Hybrid} model and provide its results
on the bottom row of Table~\ref{tab:java2cstranslation-results} and
Table~\ref{tab:cs2javatranslation-results}.
By combining generation-based model with \DeltaTool, we can achieve
improved performance on most of the reported automatic metrics.

\subsection{Qualitative Analysis}
\label{sec:eval:qualitative}
Figure~\ref{fig:results-example} shows an example in
\UseMacro{java2cs} dataset and the models' predictions. We show the
code changes from \Java project \CodeIn{itext/itext7} in the method
(\CodeIn{parseBodyFragment}).  The newly added code are highlighted in
green and removed code are highlighted in red.  We also present the
old version of the corresponding \Cs method
(\CodeIn{ParseBodyFragment}) from \CodeIn{itext/itext7\text{-}dotnet},
and the predicted code changes from three models: \DeltaTool
(\edittranslation), \UseMacro{CodeT5Up}, \translationModel.  Note that
\translationModel only has access to the new version of \Java{}
method.

Although \translationModel is able to correctly translate the code
change in \Java, it fails to infer the full name of the type
\CodeIn{Node} and makes an irrelevant edit, because it does not have
the context of the old version of \Cs code.  
\UseMacro{CodeT5Up} correctly captures the \Java change while making an extra
irrelevant edit on the \Cs code.
 Our proposed model, \DeltaTool
(\edittranslation) accurately identifies the position in the \Cs
method to make edits and correctly adjusts the \Java{} edits.


\section{Related Work}

In this section, we describe related work on the rule-based code
translation tools, existing machine learning models designed for code
translation, and the machine learning models that are proposed for
accelerating software evolution.

\MyPara{Rule-based Code Translation}
Researchers and practitioners have designed rule-based tools for
translating the source code of a program written in one programming
language to the equivalent program written in another programming
language.  Such tools, usually called transpilers, have been built for
pairs like \Java and \Cs{}~\cite{java2csharp}, C and
Rust~\cite{c2rust}, C and Go~\cite{c2go}.  \citet{NguyenETAL15Divide}
proposed PBSMT, a divide-and-conquer technique to adapt phrase-based
statistical machine translation models for source code translation.
This statistical approach has been shown to underperform the
learning-based approaches that are proposed recently.  

There are also transpilers designed for translating code between
different programming paradigms within the same programming language.
\citet{gyori2013crossing} proposed \textsc{LambdaFicator} to translate
imperative Java code to using the functional Stream APIs, e.g.,
converting anonymous inner classes and for loops to lambda
expressions.  \citet{radoi2014translating} presented the rule-based
model to translate sequential \Java code to MapReduce framework.  

Implementing these tools is usually tedious and time-consuming.
Developers have to get familiar with the grammars of both programming
languages and manually design rules to map the syntax between two
programming languages.  
With the evolution of the programming languages, new features and code
patterns are introduced, the rule-based tools could be
outdated~\cite{java2csharp}.  Prior work~\cite{mariano2022automated}
has shown that existing rule-based code refactoring tools can only
deal with stylized code snippets over common code patterns because it
is impossible to manually craft the rules for any patterns or language
pairs.  \DeltaTool does not have this limitation, as it can generalize
to new programming language features by learning from code evolution
history.

\MyPara{Learning-based Code Translation}
Researchers have proposed various machine learning models for the code
translation task.  \citet{ChenETAL18Tree} proposed a tree-to-tree
neural network with a tree-RNN encoder and a tree-RNN decoder.  The
encoder learns the embeddings for the nodes on the abstract syntax tree
of source code and decoder recursively expands the non-terminal nodes
on the new abstract syntax tree of the target code.  Compared to
\DeltaTool, this model does not generalize well to longer program as
the size of the abstract syntax tree for a code snippet can be very
large with thousands of nodes.  Moreover, RNN model suffers from the
out of vocabulary (OOV) problem when translating the real-world
project because of the limited number of parameters.

Motivated by the success of large \pretrained \LLMs for many Natural
Language Processing tasks, domain-specific models that are \pretrained
on source code and technical text have emerged.
Researchers have applied them to the code translation task.
\citet{CodeXGLUE} proposed CodeXGLUE, a benchmark including the code
translation dataset consisting of \Java and \Cs methods with
equivalent functionality from 4 open-source projects.  They \finetuned
and evaluated CodeBERT, a Bert-like language model \pretrained on code
and comments, on the translation dataset for two directions, i.e. from
\Java to \Cs and from \Cs to \Java.  Results showed that it produced
the best results among all the existing baselines.  More recently,
LLMs that are built on the encoder-decoder paradigm and \pretrained
with general unsupervised denoising auto-encoding objectives showed
promising results on wide range of code generation tasks including
code translation.  Such models include CodeT5~\cite{WangETAL21codet5},
PLBART~\cite{PLBART}, and UniXcoder~\cite{GuoETAL22Unixcoder}.  For
comparison of \DeltaTool with the state-of-the-art code translation
models, we include two variants of the CodeT5-based translation models
(with history context and without) in our evaluation.

Researchers have proposed LLMs which are \pretrained with the
objective tailored for code translation.
\citet{TipirneniETAL22StructCoder} embedded syntax and data flow into
the \pretrained language models by introducing tasks on predicting AST
paths and data flows during \pretraining.
\citet{LachauxETAL20TransCoder} proposed TransCoder which is
\pretrained to do code translation in an unsupervised approach.  In
addition to commonly-used masked language modeling and denoising
auto-encoding objective, TransCoder was further \pretrained with the
back-translation objective using unlabeled C++ and Python data.  
To improve the quality of \pretraining data used during
back-translation, \citet{RoziereETAL21TransCoderST} leveraged an
automated unit-testing system to filter out invalid generated programs
during back-translation, which improved the performance of previously
proposed TransCoder model in the code translation task.  \citet{ZhuETAL22Multilingual} proposed
MuST, which is a multilingual snippet translation \pretraining
objective designed for code translation between multiple programming
languages, and evaluated on a newly collected dataset with 7
programming languages.  None of the above work leverages the code
change history, which is the main contribution of our paper.  We leave
improving \DeltaTool with \pretraining objectives tailored for code
translation as future work.



\MyPara{Software Evolution and Machine Learning}
New research initiatives have emerged around building and evaluating
models that aid the process of software evolution.
\citet{PanthaplackelETAL20Learning} proposed to update the comment
given the changes in the associated method and build the model that
takes the code change as context to make edits on the outdated
comment.  \citet{NieETAL22EvalMethodologies} present different
approaches to split dataset into training, validation and test sets
and studied how different approaches affect the evaluation of machine
learning models.  We adopt the time-segmented approach to split the
data and evaluate the machine learning models as it is more
appropriate for our \deltatask task and the envisioned use case.
\citet{kamezawaETAL22RNSum} presented a dataset, RNSum, which consists
of more than 82K release notes and the associated commit message
collected from GitHub repositories. They designed models to generate
release notes based on the commit messages.
\citet{ZhangETAL22CoditT5} proposed a novel \pretraining objective
designed for software editing tasks and built CoditT5 \pretrained with
that objective.  CoditT5 was \finetuned on three downstream tasks
related to the software evolution, i.e. comment updating, automating
code review and bug fixing and showed improved performance over
standard generation-based LLMs.
\citet{LiETAL2022Automating, tufano2022using, ZhangETAL22Using}
proposed models that targeted on various tasks through the code review
process such as recommending code reviewers, generating review
comments and automatic updating the code under review.  The models are
trained on the historical data from the software developers'
activities and evaluated on the new pull requests submitted for code
review.  
Our \DeltaTool model incorporates the context from the code changes in
source programming language and the old version of method in target
programming languages to improve its performance on the \deltatask
task, which helps developers co-evolve the projects implemented in
different programming languages.





\section{Limitations}


\MyPara{Studied Programming Languages}.
We study the translation of code changes between various programming languages. 
In this paper, our scope specifically concentrates on open-source \Java and \Csharp projects due to the ease of locating corresponding changes using heuristics.
Nevertheless, it is important to note that our approach can be applied to other programming language pairs as well, and we leave the investigation of such pairs for future research.






\MyPara{Correspondence between Programming Languages}
Our \DeltaTool{} is intended for developers to migrate code changes from a project written in a source programming language to projects written in target programming languages, leveraging known correspondences (e.g., methods with similar functionalities) between the source and target programming languages. 
In this work, we adopt a similar strategy employed in~\cite{CodeXGLUE} to match \Java and \Csharp methods. 
In practice, a code retrieval system can be used as a first step to identify the locations where the code changes should be propagated.
We leave the combination of code retrieval tool and \DeltaTool as future work.

\MyPara{Empirical Evaluation}
This paper presents the empirical study results for internal metrics that are of interest to researchers. However, the external measurements of the impact on software engineering effort are not included in this study. These measurements will be addressed in future work, such as conducting a user study.







\section{Conclusion}

In this paper, we formulated a new task: translating code changes
across programming languages with the goal to synchronize projects
that provide the same \APIs or implementations in multiple programming
languages.
We proposed \DeltaTool, a model which uses code change history as
contextual information and learns to make edits on the existing
version of code written in the target programming language.
We showed that our model outperforms existing code translation models
and is better than the generation-based model even when both models
have historical context.
\DeltaTool is a significant advancement in supporting developers with the maintenance of their projects that incrementally offer identical functionality across multiple programming languages.










\section*{Acknowledgments}
We thank Nader Al Awar, Yu Liu, Sheena Panthaplackel, Aditya
Thimmaiah, Zhiqiang Zang, and the anonymous reviewers for their
comments and feedback.
We acknowledge the Texas Advanced Computing Center (TACC) at The
University of Texas at Austin for providing HPC resources that have
contributed to the research results reported within this paper.
This work is partially supported by the US National Science Foundation
under Grant Nos.~CCF-2107291, IIS-2107524, IIS-2145479, and
CCF-2217696.

\balance
\bibliography{bib}

\clearpage
\end{document}

