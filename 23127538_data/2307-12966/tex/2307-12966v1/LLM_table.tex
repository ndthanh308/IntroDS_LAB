

\begin{table*}[!ht]
    \centering
    \resizebox{\linewidth}{!}{
    \begin{tabular}{c|cccccccccc} \toprule
Aligned LLM & Size & Lang. & Initial LLMs & Training & Self Instruction & NLP Benchmarks & Human Annotations & Human Eval & Auto. Benchmark Eval         & LLM Eval                  \\ \midrule
Alpaca~\cite{alpaca} & 7B & EN & LLaMA & SFT & Text-Davinci-003 & \xmark & \xmark & Author Verification & \xmark & \xmark \\
Vicuna~\cite{vicuna2023} & 7B, 13B, 33B & EN & LLaMA & SFT & GPT-3.5 & \xmark & 70K ShareGPT & \xmark & \xmark & \emph{Vicuna-80} \\
GPT4ALL~\cite{gpt4all}     & 6B, 13B & EN & \makecell{LLaMA \\ GPT-J} & SFT & \xmark                & Bloomz-P3      & \makecell{OIG, ShareGPT, Dolly \\ Stack Overflow}                & \xmark     & Common Sense Reasoning & \xmark \\
LLaMA-GPT4~\cite{peng2023instruction} & 7B & EN, CN & LLaMA & SFT & \makecell{Text-Davinci-003 \\ GPT-4} & \xmark & \xmark & \makecell{\emph{User-Instructions-252} \\ Pairwise, AMT} &  Unnatural Instructions & \emph{Vicuna-80} \\
Phoenix~\cite{DBLP:journals/corr/abs-2304-10453} & 7B, 13B & Multilingual & \makecell{LLaMA \\ BLOOMZ} & SFT & \makecell{GPT-3.5 Multilingual \\ and Dialogue Data} & \xmark & ShareGPT & Volunteers & \xmark & GPT-3.5, GPT-4 \\
UltraLLaMA~\cite{ding2023enhancing} & 13B & EN &  LLaMA & SFT & GPT-3.5 Dialogue Data & \xmark & \xmark & \xmark & Truthful QA & \makecell{GPT 3.5 \emph{Vicuna-80} \\ 300 diverse questions} \\
Baize~\cite{DBLP:journals/corr/abs-2304-01196} & 7B, 13B, 30B & EN & LLaMA & Revision, LoRA & GPT-3.5 self-Chat Data & \xmark & Quora Questions & \xmark & \xmark & GPT-4 \\
WizardLM~\cite{xu2023wizardlm} & 7B, 13B, 30B & EN & LLaMA & SFT & \makecell{GPT-3.5, Alpaca \\ Complex Instructions} & \xmark & ShareGPT & \makecell{10 Annotators \\ Pairwise Comparison} & \xmark & GPT-4, \emph{WizedLM-218} \\
WizardCoder~\cite{luo2023wizardcoder} & 15B & EN, Code & StarCoder & SFT & \makecell{GPT-3.5, Code Alpaca \\ Complex Instructions} & \xmark & \xmark & \xmark & \makecell{HumanEval, MBPP \\ HumanEval+, DS-1000} & \xmark \\
OpenChat~\cite{openchat} & 13B & EN & LLaMA & Language & \xmark & \xmark & \makecell{GPT 3.5 \& GPT4 \\ ShareGPT} & \xmark & MMLU & GPT-4 \\
Guanaco~\cite{dettmers2023qlora} & 13B, 33B, 65B & EN & LLaMA & QLoRA & \makecell{Alpaca, SELF-INSTRUCT \\ Unnatural instructions} & FLAN & Chip2 & Elo, \emph{Vicuna-80} & MMLU & \makecell{Elo, \emph{Vicuna-80} \\ \emph{Open-Assistant-953}} \\
MPT-chat~\cite{MosaicML2023Introducing} & 13B, 30B & EN & MPT & SFT & \makecell{GPTeacher, Guanaco \\ Baize Instructions} & \xmark & Vicuna ShareGPT & \xmark & MMLU & GPT4, MT-bench \\
FLACUNA~\cite{ghosal2023flacuna} & 13B & EN & Vicuna & LoRA & Alpaca, Code Alpaca & FLAN & ShareGPT & \xmark & \makecell{MMLU, BBH, DROP \\ CRASS, HumanEval} & GPT 3.5, IMPACT \\
Bactrian-X~\cite{bactrian} & 7B & Multilingual & \makecell{LLaMA \\ BLOOMZ} & LoRA & \makecell{Alpaca \\ Google Translation} & \xmark & \xmark & \xmark & \makecell{XCOPA, XStoryCloze \\ XWinograd, SentimentX} & \makecell{GPT 4 \\ Multilingual \emph{Vicuna-80}}  \\
Ocra~\cite{mukherjee2023orca} & 13B & EN & LLaMA & SFT & \xmark & FLAN & \xmark & \xmark & AGIEval, BBH & \makecell{GPT-4, \emph{Vicuna-80} \\ \emph{WizedLM-218}, \emph{Awesome-164}} \\
Phi-1~\cite{gunasekar2023textbooks} & 350M, 1.3B & EN, Code & Phi-1-base & SFT & \makecell{GPT-3.5 \\ Synthetic Textbook} & \xmark & \makecell{Python, The Stack \\ Stack Overflow} & \xmark & HumanEval & GPT-4 Grading \\
Chinese Alpaca~\cite{cui2023efficient} & 7B, 13B, 33B & EN, CN & Chinese LLaMA & LoRA & \makecell{STEM \\ Org. and Trans.  Alpaca} & pCLUE & \xmark & \xmark & C-Eval & \xmark \\
Lion~\cite{Jiang2023LionAD} & 7B, 13B & EN & LLaMA & SFT & \makecell{Alpaca \\ GPT 3.5 Adv. Instruction} & \xmark & \xmark & \makecell{HHH \\ \emph{User-Instructions-252}} & \xmark & GPT-4, \emph{Vicuna-80} \\
Stable Alignment~\cite{liu2023training} & 7B & EN & Alpaca & SFT & \makecell{GPT-3.5 \\ Social Aligned Instructions} & \xmark & \xmark & \xmark & \xmark & \makecell{GPT-4 \\ HHH, HHH-A} \\
Dromedary~\cite{Sun2023PrincipleDrivenSO} & 65B & EN & LLaMA & SFT & LLaMA-65B, Self-Align & \xmark & \makecell{175 Munnal Examples \\ 16 Principle Rules} & \xmark & TruthfulQA, BBH & GPT-4, \emph{Vicuna-80} \\
Dolly-v2~\cite{DatabricksBlog2023DollyV2} & 3B, 7B, 12B & EN & Pythia & SFT & \xmark & \xmark & \emph{databricks-dolly-15k} & \xmark & \emph{LLM Harness} & \xmark \\
Selfee~\cite{selfee2023} & 7B, 13B & EN & LLaMA & Revision & \makecell{GPT 3.5 Self-Improve \\ Alpaca} & FLAN, Maths, Code & ShareGPT & \xmark & \xmark & GPT-4, \emph{Vicuna-80} \\
\textsc{T\"ulu}~\cite{wang2023far} & 7B, 13B, 30B, 65B & EN & LLaMA & SFT & \makecell{Alpaca, Code Alpaca \\ GPT4-Alpaca, Self-instruct} & FLAN, CoT & \makecell{Dolly, ShareGPT \\ Open Assistant} & \makecell{Acceptability \\ Pairwise Comparison} & \makecell{MMLU, GSM, BBH \\ TydiQA, Codex-Eval} & \makecell{GPT4 on \emph{Vicuna-80}, Koala \\ Open Assistant Benchmarks}\\
Koala~\cite{koala_blogpost_2023} & 13B & EN & LLaMA & Language & Alpaca & \xmark & \makecell{OIG, HC3, Anthropic HH \\ OpenAI WebGPT, Summary} & \makecell{100 AMT Annotators \\ on \emph{Alpaca and Koala Test}} & \xmark & \xmark \\
Bayling~\cite{Zhang2023BayLingBC} & 7B, 13B & Multilingual & LLaMA & SFT & \makecell{Alpaca \\ GPT 3.5  Interactive Translation} & \xmark & ShareGPT & Translation Quality & \makecell{WMT22 Multilingual Translation \\  Lexically Constrained Translation} & \xmark \\
Wombat~\cite{yuan2023rrhf} & 7B & EN & Alpaca & Rank & \makecell{Alpaca \\ ChatGPT Ratings} & \xmark & \emph{Helpful and Harmless} & \xmark & \xmark & GPT-4, \emph{Vicuna-80} \\
Lamini-lm~\cite{DBLP:journals/corr/abs-2304-1440} & 0.7B & EN & T5-Flan & SFT & \makecell{Alpaca \\ Self-instruct} & P3, FLAN & \xmark & Human Rating & \emph{LLM harness} & \xmark \\
\bottomrule
\end{tabular}}
\caption{An overview of popular aligned LLMs, including their Size, supported languages, initial LLMs, alignment training method, alignment data, and alignment evaluation.}
\label{llmsummary}
\end{table*}