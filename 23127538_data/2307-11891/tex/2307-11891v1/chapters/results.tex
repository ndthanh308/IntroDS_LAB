\section{Results} 

\subsection{Performance on Simulated Signals}

Analysis of the generated signals revealed some variations in the predicted and actual mass parameters. For example, the signal simulated with a mass1 and mass2 of 90\_20 indicated a noticeable overestimation of mass1 while mass2 was underestimated. Despite this discrepancy, the total mass maintained a marginal deviation from the expected values, underscoring the balance between the mass estimations.

The precision exhibited across all simulated signals was remarkable, achieving a near-perfect alignment within $0.3\%$ of the forecasted values. This achievement validates GravAD's efficacy in accurately processing a diverse range of mass ratios. Notably, the signal with a 50\_40 mass ratio presented an anomaly, achieving only $35\%$ of the expected value.

% Figure environment removed

This reinforces our confidence in GravAD's ability to process real GW signals effectively. Figure \ref{fig:sim} illustrates GravAD's competence in processing an array of mass parameters, including high and low mass ratios, and simulated data sets. This proficiency underpins GravAD's robustness and wide-ranging applicability. 

\subsection{Effectiveness of the Optimisations}

Upon comparing the performance of various optimisation techniques (as depicted in Figure \ref{fig:optims}), we observe that standalone SGD can be somewhat slow yet effective, resulting in a high SNR. The incorporation of SA navigates the search away from local maxima, guiding it towards regions within the parameter space that are more likely to generate superior solutions. While this approach diminishes the average iterations per run, it also adversely affects the average SNR. The most effective strategy, on the whole, appears to be the combination of SGD, SA, and momentum (P), due to its high average SNR and reasonable average iterations. We can also see the ineffectiveness of Adam in our search with and without SA involvement. 

% Figure environment removed

\subsection{Significant Reduction in Template Usage}

Our refined methodology yielded a considerable reduction in the number of templates necessary for performing a search. Traditionally, an estimated $N \sim 500,000$ templates are utilised for such a task \cite{temp_num}. Our prior research, however, was able to cut down this number to a mere $N \sim 180$ templates. The current implementation advances this further, demanding on average only $N \sim 8.67$ templates per search, which signifies a remarkable efficiency gain, reducing the requirement by approximately $N \sim 60,000$ times.

Importantly, this reduction in template usage did not come at the expense of result quality. Despite the significant cut in templates, the SNR values exhibited only a minor decrease, with the results remaining within $2.5\%$ of the anticipated values relative to our prior model that necessitated $180$ templates. This outcome substantiates both the efficiency and effectiveness of our template reduction strategy.