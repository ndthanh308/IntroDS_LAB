\section{Methodology}

% Figure environment removed

\subsubsection{Overall Pipeline.}
% 
The proposed histology artifact restoration diffusion model \texttt{ArtiFusion}, comprises two stages, namely the training, and inference. 
% 
During the training stage, \texttt{ArtiFusion} learns to generate regional histology tissue structures based on the contextual information from artifact-free images.
% 
In the inference stage, \texttt{ArtiFusion} formulates the artifact restoration as a gradual denoising process.
% 
Specifically, it first replaces the artifact regions with Gaussian noise, and then gradually restores them to artifact-free images using the contextual information from nearby regions.




\subsubsection{Diffusion Training Stage.}
% 
The proposed \texttt{ArtiFusion} learns the capability of generating local tissue representation from contextual information during the training stage.
% 
To achieve this, we follow the formulations of DDPM~\cite{DDPM}, which involve a forward process that gradually injects Gaussian noise into an artifact-free image and a reverse process that aims to reconstruct images from noise. 
% 
During the forward process, we can obtain a noisy version of $\mathbf{x}_t$ for arbitrary timestep $t \in \mathbb{N}[0,T]$ using a Gaussian transition kernel $q(\mathbf{x}t|\mathbf{x}{t-1}) = \mathcal{N}(x_t;\sqrt{1-\beta_t}\mathbf{x}{t-1},\beta_t\mathbf{I})$, where $\beta_t \in (0,1)$ are predefined hyper-parameters~\cite{DDPM}. 
% 
Simultaneously, the reverse process trains a denoising network $p_{\theta}(\mathbf{x}_{t-1}|\mathbf{x}_{t}^{in})$, which is parameterized by $\theta$, to reverse the forward process $q(\mathbf{x}_{t}|\mathbf{x}_{t-1})$.
% 
The overall training objective $L$ is defined as the variational lower bound of the negative log-likelihood, given by:
\begin{equation}
    \mathbb{E}[-\log p_{\theta}(\mathbf{x}_{0})] 
    \leq 
    \mathbb{E}_{q}[-\log p(\mathbf{x}_{T})-\sum_{1\leq t \leq T}\log\frac{p_{\theta}(\mathbf{x}_{t-1}|\mathbf{x}_{t})}{q(\mathbf{x}_{t}|\mathbf{x}_{t-1})}] =L.
\end{equation}
% 
This formulation is extended in DDPM \cite{DDPM} to be further written as:
\begin{equation}
\small
\nonumber
    L=
    \mathbb{E}_{q}
    [\underbrace{D_{KL}(q(\mathbf{x}_{T}|x_{0}))||p(\mathbf{x}_{T})}_{L_{T}} 
    + \sum_{t>1}
    \underbrace{D_{KL}(q(\mathbf{x}_{t-1}|\mathbf{x}_{t},\mathbf{x}_{0}))||p_{\theta}(\mathbf{x}_{t-1}|\mathbf{x}_{t})}_{L_{t-1}}-\underbrace{\log p_{\theta}(\mathbf{x}_{0}|\mathbf{x}_{1})}_{L_{0}}],
\end{equation}
where $D_{KL}(\cdot||\cdot)$ is the KL divergence.



% Figure environment removed



\subsubsection{Artifact Restoration in Inference Stage.}
% 
During the inference stage, we first use a threshold method to detect the artifact region in the input image $\mathbf{x}_0$.
% 
Then, unlike the conventional diffusion models~\cite{DDPM} that aim to generate the entire image, \texttt{ArtiFusion} selectively performs denoising resampling only in the artifact region to maximally preserve the original morphology and stain style in the artifact-free region, as shown in Fig.~\ref{fig:inf}.
% 
Specifically, we represent the artifact-free region and the artifact region in the input image as $\mathbf{x}_0 \odot (1-\mathbf{m})$ and $\mathbf{x}_0 \odot \mathbf{m}$, respectively~\cite{repaint}, where $\mathbf{m}$ is a Boolean mask indicating the artifact region and $\odot$ is the pixel-wise multiplication operator.
% 
To perform the denoising resampling, we write the input image $ \mathbf{x}_{t}^{in}$ at each reverse step from $t$ to $t-1$ as the sum of the diffused artifact-free region and the denoised artifact region, \textit{i.e.,}
\begin{equation}
    \mathbf{x}_{t}^{in} = 
    % 
    \mathbf{x}_{t}^{sample} \odot (1-\mathbf{m})
    +
   \mathbf{x}_{t+1}^{out} \odot \mathbf{m}, 
    \label{eq:reverse}
\end{equation}
where $\mathbf{x}_{t}^{sample}o\odot (1-\mathbf{m})$ is artifact-free region diffused for $t$ times using the Gaussian transition kernel \textit{i.e.} $\mathbf{x}_{t}^{sample}\sim \mathcal{N}(\sqrt{\bar{\alpha}_t}\mathbf{x}_0, (1-\bar{\alpha}_t \mathbf{I}))$ with $\bar{\alpha}_t=\prod_{i=1}^t(1-\beta_i)$; 
and $\mathbf{x}_{t+1}^{out}$ is the output from the denoising network in the previous reverse step \textit{i.e.,} $p_{\theta}(\mathbf{x}_{t+1}^{out}|\mathbf{x}_{t+1}^{in})$.
% 
Consequently, the final restored image is obtained as $\mathbf{x}_{0} \odot (1-\mathbf{m})+\mathbf{x}_{0}^{out} \odot \mathbf{m}$.




\subsubsection{Swin-Transformer Denoising Network.}
% 
To capture the local-global correlation and enable the denoising network to effectively restore the artifact regions, we propose a novel Swin-Transformer-basedr~\cite{SwinTransformer} denoising network for \texttt{ArtiFusion}.
% 
As shown in Fig.~\ref{fig:model}, our network follows a U-shape architecture, where the encoder, bottleneck, and decoder modules all employ Swin-Transformer as the basic building block.
% 
Additionally, we introduce an innovative auxiliary time token to inject the time information.
% 
In an arbitrary time step $t$ during the training process, to obtain a time token, we first embed the scalar $t$ by learnable linear layers, with weights that are specific to each Swin-Transformer block.
% 
In contrast to existing U-Net based denoising networks~\cite{DDPM}, we propose a better interaction between hidden features and time information by concatenating the time token to feature tokens before passing them to the attention layers. 
% 
The resulting tokens are then processed by the attention layers, and the auxiliary time token is discarded to retain the original feature dimension to fit the Swin-Transformer block design after the attention layers.

