\section{Experiments}
\subsubsection{Dataset.}
To evaluate the performance of artifact restoration, a training set is curated from a subset of Camelyon17~\cite{litjens20181399} \footnote{Available at \url{https://camelyon17.grand-challenge.org}.}. 
% 
It comprises a total number of 2445 artifact-free images and another 2547 images with artifacts, where all histological images are scaled to the resolution of $256 \times 256$ pixels at the magnitude of $20\times$. 
%  
The test set uses another public histology image dataset~\cite{ClusterSeg} with 462 artifact-free images\footnote{Available at \url{https://github.com/lu-yizhou/ClusterSeg}.}, where we obtain the paired artifact images by the manually-synthesized artifacts~\cite{zhang2022benchmarking}. 


% Figure environment removed



\subsubsection{Implementations.}
We implement the proposed \texttt{ArtiFusion} and its counterpart in Python 3.8.10 and PyTorch 1.10.0.
% 
All experiments are carried out in parallel on two NVIDIA RTX A4000 GPU cards with 16 GiB memory. 
% 
Hyper-parameters are as follows: a learning rate of $10^{-4}$ with Adam optimizer, the total timesteps is set to $250$. 



\subsubsection{Compared Methods and Evaluation Metrics.}
% 
As a proof-of-concept attempt at a generative-models-based artifact restoration framework in the histology domain, currently, there are limited available literature works and open-sourced codes for comparison. 
% 
Consequently, we leverage the prevalent CycleGAN~\cite{cycleGAN} as the baseline for comparison, because of its excellent performance in the image transfer, and also its nature that requires no paired data can fit our circumstance. 
% 
Unlike CycleGAN which requires both artifact-free images and artifact images, \texttt{ArtiFusion} only relies on artifact-free images, leading to a size of the training set that is half that of CycleGAN.
% 
For a fair compaison, we train the CycleGAN with two configurations, namely (\#1) using the entire dataset, and (\#2) using only half the dataset, where the latter uses the same number of the training samples as \texttt{ArtiFusion}.
% 
Regarding the ablation, we compare the proposed Swin-Transformer denoising network with the conventional U-Net~\cite{DDPM} (denoted as `U-Net'), and the time token scheme with the direct summation scheme (denoted as `Add').
% 
We use the following metrics: $L_2$ distance (L2) with respect to the artifact region, the mean-squared error (MSE) over the whole image, structural similarity index (SSIM)~\cite{SSIM}, Peak signal-to-noise ratio (PSNR)~\cite{PSNR}, Feature-based similarity index (FSIM)~\cite{zhang2011fsim} and Signal to reconstruction error ratio (SRE)~\cite{SRE}.


\begin{table}[t!]
\centering
\caption{
Quantitative comparison of \texttt{ArtiFusion} with CycleGAN on artifact restoration performance. 
% 
The $\downarrow$ indicates the smaller value, the better performance; and vice versa. 
}
\label{tab:result}
\begin{tabular}{l|c|c|c|c|c|c}
% \hline
\toprule
Methods & L2~($\times10^4$) $\downarrow$ & MSE~$\downarrow$ & SSIM~$\uparrow$ & PSNR~$\uparrow$ & FSIM~$\uparrow$ & SRE~$\uparrow$ \\ 
\hline
CycleGAN (\#1)~\cite{cycleGAN} & $1.119$ & $0.5583$ &  $0.9656$     &  $42.37$   & $0.7188$ & $51.42$    \\
CycleGAN (\#2)~\cite{cycleGAN} & $1.893$ & $0.5936$ &  $0.9622$     &  $42.12$  & $0.7162$ & $50.21$     \\
\hline
\texttt{ArtiFusion} (U-Net) & $0.5027$ & $0.2508$ &  $0.9850$     &    $47.61$   & $0.8173$ &  $54.59$  \\
\texttt{ArtiFusion} (Add) &  $0.5007$   &  $0.2499$ &  $0.9850$    &   $47.79$  & $0.8184$ & $54.76$   \\ 
\texttt{ArtiFusion} (Full Settings)    &   \bm{$0.4940$}   & \bm{$0.2465$}  &  \bm{$0.9860$}    & \bm{$48.08$} & \bm{$0.8216$} & \bm{$55.43$}       \\ 

% \hline
\bottomrule
\end{tabular}
\end{table}


\begin{table}[b!]
\centering
\caption{
Comparison of the model complexity and efficiency in terms of the number of parameters, FLOPs, and averaged inference time.
% 
}
\label{tab:cost}
\begin{tabular}{l|c|c|c}
% \hline
\toprule
Methods & \#Params~($\times10^6$) & FLOPs~($\times10^9$) & Inference(s) \\ 
\hline
CycleGAN \cite{cycleGAN} & $28.28$ & $60.04$ & $1.065$ \\
\hline
\texttt{ArtiFusion} (UNet) & $108.41$ & $247.01$  & $112.37$ \\ 
\texttt{ArtiFusion} (Add)  & $27.74$ & $7.69$ & $30.14$\\ 
\texttt{ArtiFusion} (Full Settings) & $29.67$ & $7.73$ &  $30.71$\\ 

% \hline
\bottomrule
\end{tabular}
\end{table}

\subsubsection{Evaluations on Artifact Restoration.} 
% 
The quantitative comparison with CycleGAN and \texttt{ArtiFusion} are shown in Table~\ref{tab:result}, where some exemplary images are illustrated in Fig.~\ref{fig:result}. 
% 
Our results demonstrate the superiority of \texttt{ArtiFusion} over GAN in the context of artifact restoration, with a large margin observed in all evaluation metrics. 
% 
For instance, \texttt{ArtiFusion} can reduce the L2 and MSE by more than $50\%$, namely from $1\times 10 ^4$ to $0.5\times10 ^4$ and from $0.55$ to $0.25$ respectively.
% 
It implying that our method can to the large extent restore the artifact regions using the global information.
% 
In addition, \texttt{ArtiFusion}  can improve other metrics, including SSIM, PSNR, FSIM and SRE by $0.0204$, $5.72$, $0.1028$ and $4.02$ respectively,  indicating that it can preserve the stain style during the restoration process. 
% 
Moreover, our ablation study shows that the Swin-Transformer denoising network can outperform the conventional U-Net, highlighting the significance of capturing global correlation for local artifact restoration.
% 
Finally, the concatenating time token with feature tokens can bring an improvement in terms of all evaluation matrices, making it a better fit for the transformer architecture than the direct summation scheme in U-Net~\cite{DDPM}.
% 
In summary, our ablations confirm the effectiveness of all the components in our method.



\begin{table}[t!]
\centering
\caption{
The effectiveness of the proposed artifact restoration framework in the downstream task-tissue classification task.
% 
We report the classification accuracy on the test set (\%) with different network architectures including ResNet \cite{ResNet}, RexNet \cite{rexnet} and EfficientNet \cite{tan2020efficientnet}.
}
\label{tab:classification}
\resizebox{\linewidth}{!}{ 
\begin{tabular}{l|c|c|c|c|c}
% \hline
\toprule
Settings &  ResNet18   & ResNet34  & ResNet50 & RexNet100  & EfficientNetB0   \\ 
\hline
Clean  & $95.529$ & $93.538$ &    $94.833$  & $95.487$   &  $95.808$   \\
\hline
Artifacts & $80.302$ & $86.031$ &  $85.012$     &  $90.446$  & $90.626$  \\
\hline
Restored w CycleGAN  & $86.326$ & $88.273$& $87.994$ & $90.776$  & $91.811$\\
\hline
Restored w \texttt{ArtiFusion}  & $92.376$ &  $91.252 $&  $90.408$   &  $92.310$    &  $94.232$ \\
\bottomrule
\end{tabular}
}
\end{table}



 
\subsubsection{Comparisons of Model Complexity.}
% 
In Table~\ref{tab:cost}, we compare the model complexity in terms of the number of parameters, Floating Point Operations Per second (FLOPs), and averaged inference time on one image. 
% 
Our proposed model achieves a significant reduction in the number of parameters by $72.6\%$, namely from $108.41 \times 10^6$ to $29.67 \times 10^6$, compared with CycleGAN.
% 
This reduction in model size comes at the cost of longer inference time. 
% 
However, a smaller model size can facilitate easier deployment in real clinical practice.




\subsubsection{Evaluations by Downstream Classification Task.}
% 
We further evaluate the proposed artifact restoration framework on a downstream tissue classification task. 
% 
To this end, we use the public dataset NCT-CRC-HE-100K for training and CRC-VAL-HE-7K for testing, which together contains $100,000$ training samples and $7,180$ test samples. 
% 
We consider the performance on the original unprocessed data, denoted as `Clean', as the upper bound.
% 
Then, we manually synthesize the artifact (denoted as `Artifact') and evaluate the classification performance with restoration approaches CycleGAN and \texttt{ArtiFusion}.
% 
In Table~\ref{tab:classification}, comparisons show that the presence of artifacts can result in a significant performance decline of over 5\% across all five network architectures. 
% 
Importantly, the classification accuracy on images restored with \texttt{ArtiFusion} is consistently higher than those restored with CycleGAN, demonstrating the superiority of our model.
% 
These results highlight the effectiveness of \texttt{ArtiFusion} as a practical pre-processing method for histology analysis.

