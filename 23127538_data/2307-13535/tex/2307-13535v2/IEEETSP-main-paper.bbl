\begin{thebibliography}{64}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Alter et~al.(2000)Alter, Brown, and Botstein]{alter2000singular}
O.~Alter, P.~O. Brown, and D.~Botstein.
\newblock Singular value decomposition for genome-wide expression data processing and modeling.
\newblock \emph{Proceedings of the National Academy of Sciences}, 97\penalty0 (18):\penalty0 10101--10106, 2000.

\bibitem[Amini and Wainwright(2008)]{amini2008high}
A.~A. Amini and M.~J. Wainwright.
\newblock High-dimensional analysis of semidefinite relaxations for sparse principal components.
\newblock In \emph{2008 IEEE international symposium on information theory}, pages 2454--2458. IEEE, 2008.

\bibitem[Asteris et~al.(2015)Asteris, Kyrillidis, Dimakis, Yi, and Chandrasekaran]{asteris2015stay}
M.~Asteris, A.~Kyrillidis, A.~Dimakis, H.-G. Yi, and B.~Chandrasekaran.
\newblock Stay on path: {PCA} along graph paths.
\newblock In \emph{International Conference on Machine Learning}, pages 1728--1736. PMLR, 2015.

\bibitem[Bandeira et~al.(2019)Bandeira, Kunisky, and Wein]{bandeira2019computational}
A.~S. Bandeira, D.~Kunisky, and A.~S. Wein.
\newblock Computational hardness of certifying bounds on constrained pca problems.
\newblock \emph{arXiv preprint arXiv:1902.07324}, 2019.

\bibitem[Baraniuk et~al.(2010)Baraniuk, Cevher, Duarte, and Hegde]{baraniuk2010model}
R.~G. Baraniuk, V.~Cevher, M.~F. Duarte, and C.~Hegde.
\newblock Model-based compressive sensing.
\newblock \emph{IEEE Transactions on information theory}, 56\penalty0 (4):\penalty0 1982--2001, 2010.

\bibitem[Berthet and Rigollet(2013)]{berthet2013complexity}
Q.~Berthet and P.~Rigollet.
\newblock Complexity theoretic lower bounds for sparse principal component detection.
\newblock In \emph{Conference on learning theory}, pages 1046--1066. PMLR, 2013.

\bibitem[Bie et~al.(2004)Bie, Suykens, and Moor]{bie2004learning}
T.~D. Bie, J.~Suykens, and B.~D. Moor.
\newblock Learning from general label constraints.
\newblock In \emph{Joint IAPR International Workshops on Statistical Techniques in Pattern Recognition (SPR) and Structural and Syntactic Pattern Recognition (SSPR)}, pages 671--679. Springer, 2004.

\bibitem[Birnbaum et~al.(2013)Birnbaum, Johnstone, Nadler, and Paul]{birnbaum2013minimax}
A.~Birnbaum, I.~M. Johnstone, B.~Nadler, and D.~Paul.
\newblock Minimax bounds for sparse {PCA} with noisy high-dimensional data.
\newblock \emph{Annals of statistics}, 41\penalty0 (3):\penalty0 1055, 2013.

\bibitem[Brennan and Bresler(2019)]{brennan2019optimal}
M.~Brennan and G.~Bresler.
\newblock Optimal average-case reductions to sparse {PCA}: From weak assumptions to strong hardness.
\newblock In \emph{Conference on Learning Theory}, pages 469--470. PMLR, 2019.

\bibitem[Brennan and Bresler(2020)]{brennan2020reducibility}
M.~Brennan and G.~Bresler.
\newblock Reducibility and statistical-computational gaps from secret leakage.
\newblock In \emph{Conference on Learning Theory}, pages 648--847. PMLR, 2020.

\bibitem[Brennan et~al.(2018)Brennan, Bresler, and Huleihel]{brennan2018reducibility}
M.~Brennan, G.~Bresler, and W.~Huleihel.
\newblock Reducibility and computational lower bounds for problems with planted sparse structure.
\newblock In \emph{Conference On Learning Theory}, pages 48--166. PMLR, 2018.

\bibitem[Cadima and Jolliffe(1995)]{cadima1995loading}
J.~Cadima and I.~T. Jolliffe.
\newblock Loading and correlations in the interpretation of principle compenents.
\newblock \emph{Journal of applied Statistics}, 22\penalty0 (2):\penalty0 203--214, 1995.

\bibitem[Cai et~al.(2013)Cai, Ma, and Wu]{cai2013sparse}
T.~T. Cai, Z.~Ma, and Y.~Wu.
\newblock Sparse {PCA}: Optimal rates and adaptive estimation.
\newblock \emph{The Annals of Statistics}, 41\penalty0 (6):\penalty0 3074--3110, 2013.

\bibitem[Cai et~al.(2021)Cai, Li, and Ma]{cai2021optimal}
T.~T. Cai, H.~Li, and R.~Ma.
\newblock Optimal structured principal subspace estimation: Metric entropy and minimax rates.
\newblock \emph{J. Mach. Learn. Res.}, 22:\penalty0 46--1, 2021.

\bibitem[Cartis and Thompson(2013)]{cartis2013exact}
C.~Cartis and A.~Thompson.
\newblock An exact tree projection algorithm for wavelets.
\newblock \emph{IEEE Signal Processing Letters}, 20\penalty0 (11):\penalty0 1026--1029, 2013.

\bibitem[Chen et~al.(2020)Chen, Ma, Xue, and Zou]{chen2020alternating}
S.~Chen, S.~Ma, L.~Xue, and H.~Zou.
\newblock An alternating manifold proximal gradient method for sparse principal component analysis and sparse canonical correlation analysis.
\newblock \emph{INFORMS Journal on Optimization}, 2\penalty0 (3):\penalty0 192--208, 2020.

\bibitem[d'Aspremont et~al.(2004)d'Aspremont, Ghaoui, Jordan, and Lanckriet]{d2004direct}
A.~d'Aspremont, L.~Ghaoui, M.~Jordan, and G.~Lanckriet.
\newblock A direct formulation for sparse {PCA} using semidefinite programming.
\newblock \emph{Advances in neural information processing systems}, 17, 2004.

\bibitem[Deshpande and Montanari(2016)]{deshpande2016sparse}
Y.~Deshpande and A.~Montanari.
\newblock Sparse {PCA} via covariance thresholding.
\newblock \emph{The Journal of Machine Learning Research}, 17\penalty0 (1):\penalty0 4913--4953, 2016.

\bibitem[Deshpande et~al.(2014)Deshpande, Montanari, and Richard]{deshpande2014cone}
Y.~Deshpande, A.~Montanari, and E.~Richard.
\newblock Cone-constrained principal component analysis.
\newblock \emph{Advances in Neural Information Processing Systems}, 27, 2014.

\bibitem[Dey et~al.(2020)Dey, Molinaro, and Wang]{dey2020solving}
S.~S. Dey, M.~Molinaro, and G.~Wang.
\newblock Solving row-sparse principal component analysis via convex integer programs.
\newblock \emph{arXiv preprint arXiv:2010.11152}, 2020.

\bibitem[Dey et~al.(2021)Dey, Mazumder, and Wang]{dey2021using}
S.~S. Dey, R.~Mazumder, and G.~Wang.
\newblock Using l1-relaxation and integer programming to obtain dual bounds for sparse {PCA}.
\newblock \emph{Operations Research}, 2021.

\bibitem[Ding et~al.(2019)Ding, Kunisky, Wein, and Bandeira]{ding2019subexponential}
Y.~Ding, D.~Kunisky, A.~S. Wein, and A.~S. Bandeira.
\newblock Subexponential-time algorithms for sparse {PCA}.
\newblock \emph{arXiv preprint arXiv:1907.11635}, 2019.

\bibitem[d’Aspremont et~al.(2014)d’Aspremont, Bach, and Ghaoui]{d2014approximation}
A.~d’Aspremont, F.~Bach, and L.~E. Ghaoui.
\newblock Approximation bounds for sparse principal component analysis.
\newblock \emph{Mathematical Programming}, 148\penalty0 (1):\penalty0 89--110, 2014.

\bibitem[Erichson et~al.(2020)Erichson, Zheng, Manohar, Brunton, Kutz, and Aravkin]{erichson2020sparse}
N.~B. Erichson, P.~Zheng, K.~Manohar, S.~L. Brunton, J.~N. Kutz, and A.~Y. Aravkin.
\newblock Sparse principal component analysis via variable projection.
\newblock \emph{SIAM Journal on Applied Mathematics}, 80\penalty0 (2):\penalty0 977--1002, 2020.

\bibitem[Feng et~al.(2019)Feng, Xu, Liu, Gao, and Zheng]{feng2019supervised}
C.-M. Feng, Y.~Xu, J.-X. Liu, Y.-L. Gao, and C.-H. Zheng.
\newblock Supervised discriminative sparse {PCA} for com-characteristic gene selection and tumor classification on multiview biological data.
\newblock \emph{IEEE transactions on neural networks and learning systems}, 30\penalty0 (10):\penalty0 2926--2937, 2019.

\bibitem[Frusque et~al.(2019)Frusque, Jung, Borgnat, and Gon{\c{c}}alves]{frusque2019sparse}
G.~Frusque, J.~Jung, P.~Borgnat, and P.~Gon{\c{c}}alves.
\newblock Sparse tensor dimensionality reduction with application to clustering of functional connectivity.
\newblock In \emph{Wavelets and Sparsity XVIII}, volume 11138, page 111380N. International Society for Optics and Photonics, 2019.

\bibitem[Gao et~al.(2017)Gao, Ma, and Zhou]{gao2017sparse}
C.~Gao, Z.~Ma, and H.~H. Zhou.
\newblock Sparse {CCA}: Adaptive estimation and computational barriers.
\newblock \emph{The Annals of Statistics}, 45\penalty0 (5):\penalty0 2074--2101, 2017.

\bibitem[Hancock et~al.(1996)Hancock, Burton, and Bruce]{hancock1996face}
P.~J. Hancock, A.~M. Burton, and V.~Bruce.
\newblock Face processing: Human perception and principal components analysis.
\newblock \emph{Memory \& cognition}, 24\penalty0 (1):\penalty0 26--40, 1996.

\bibitem[Hastie et~al.(2000)Hastie, Tibshirani, Eisen, Alizadeh, Levy, Staudt, Chan, Botstein, and Brown]{hastie2000gene}
T.~Hastie, R.~Tibshirani, M.~B. Eisen, A.~Alizadeh, R.~Levy, L.~Staudt, W.~C. Chan, D.~Botstein, and P.~Brown.
\newblock 'gene shaving'as a method for identifying distinct sets of genes with similar expression patterns.
\newblock \emph{Genome biology}, 1\penalty0 (2):\penalty0 1--21, 2000.

\bibitem[Hastie et~al.(2009)Hastie, Tibshirani, Friedman, and Friedman]{hastie2009elements}
T.~Hastie, R.~Tibshirani, J.~H. Friedman, and J.~H. Friedman.
\newblock \emph{The elements of statistical learning: data mining, inference, and prediction}, volume~2.
\newblock Springer, 2009.

\bibitem[Hegde et~al.(2015)Hegde, Indyk, and Schmidt]{hegde2015nearly}
C.~Hegde, P.~Indyk, and L.~Schmidt.
\newblock A nearly-linear time framework for graph-structured sparsity.
\newblock In \emph{International Conference on Machine Learning}, pages 928--937. PMLR, 2015.

\bibitem[Johnstone and Lu(2009)]{johnstone2009consistency}
I.~M. Johnstone and A.~Y. Lu.
\newblock On consistency and sparsity for principal components analysis in high dimensions.
\newblock \emph{Journal of the American Statistical Association}, 104\penalty0 (486):\penalty0 682--693, 2009.

\bibitem[Jolliffe et~al.(2003)Jolliffe, Trendafilov, and Uddin]{jolliffe2003modified}
I.~T. Jolliffe, N.~T. Trendafilov, and M.~Uddin.
\newblock A modified principal component technique based on the lasso.
\newblock \emph{Journal of computational and Graphical Statistics}, 12\penalty0 (3):\penalty0 531--547, 2003.

\bibitem[Journ{\'e}e et~al.(2010)Journ{\'e}e, Nesterov, Richt{\'a}rik, and Sepulchre]{journee2010generalized}
M.~Journ{\'e}e, Y.~Nesterov, P.~Richt{\'a}rik, and R.~Sepulchre.
\newblock Generalized power method for sparse principal component analysis.
\newblock \emph{Journal of Machine Learning Research}, 11\penalty0 (2), 2010.

\bibitem[Kim et~al.(2019)Kim, Tawarmalani, and Richard]{kim2019convexification}
J.~Kim, M.~Tawarmalani, and J.~P.~P. Richard.
\newblock Convexification of permutation-invariant sets and applications.
\newblock \emph{Scanning Electron Microsc Meet at}, 2019.

\bibitem[Krauthgamer et~al.(2015)Krauthgamer, Nadler, and Vilenchik]{krauthgamer2015semidefinite}
R.~Krauthgamer, B.~Nadler, and D.~Vilenchik.
\newblock Do semidefinite relaxations solve sparse {PCA} up to the information limit?
\newblock \emph{The Annals of Statistics}, 43\penalty0 (3):\penalty0 1300--1322, 2015.

\bibitem[Li and Xie(2020)]{li2020exact}
Y.~Li and W.~Xie.
\newblock Exact and approximation algorithms for sparse {PCA}.
\newblock \emph{arXiv preprint arXiv:2008.12438}, 2020.

\bibitem[Liu et~al.(2021)Liu, Liu, Ghosh, Han, and Scarlett]{liu2021generative}
Z.~Liu, J.~Liu, S.~Ghosh, J.~Han, and J.~Scarlett.
\newblock Generative principal component analysis.
\newblock In \emph{International Conference on Learning Representations}, 2021.

\bibitem[Ma and Wigderson(2015)]{ma2015sum}
T.~Ma and A.~Wigderson.
\newblock Sum-of-squares lower bounds for sparse {PCA}.
\newblock \emph{arXiv preprint arXiv:1507.06370}, 2015.

\bibitem[Ma(2013)]{ma2013sparse}
Z.~Ma.
\newblock Sparse principal component analysis and iterative thresholding.
\newblock \emph{The Annals of Statistics}, 41\penalty0 (2):\penalty0 772--801, 2013.

\bibitem[Mackey(2008)]{mackey2008deflation}
L.~Mackey.
\newblock Deflation methods for sparse {PCA}.
\newblock \emph{Advances in neural information processing systems}, 21, 2008.

\bibitem[Mallat(1999)]{mallat1999wavelet}
S.~Mallat.
\newblock \emph{A wavelet tour of signal processing}.
\newblock Elsevier, 1999.

\bibitem[Moitra et~al.(2016)Moitra, Perry, and Wein]{moitra2016robust}
A.~Moitra, W.~Perry, and A.~S. Wein.
\newblock How robust are reconstruction thresholds for community detection?
\newblock In \emph{Proceedings of the forty-eighth annual ACM symposium on Theory of Computing}, pages 828--841, 2016.

\bibitem[Montanari and Richard(2015)]{montanari2015non}
A.~Montanari and E.~Richard.
\newblock Non-negative principal component analysis: Message passing algorithms and sharp asymptotics.
\newblock \emph{IEEE Transactions on Information Theory}, 62\penalty0 (3):\penalty0 1458--1484, 2015.

\bibitem[Tibshirani(1996)]{tibshirani1996regression}
R.~Tibshirani.
\newblock Regression shrinkage and selection via the lasso.
\newblock \emph{Journal of the Royal Statistical Society: Series B (Methodological)}, 58\penalty0 (1):\penalty0 267--288, 1996.

\bibitem[Tran et~al.(2020)Tran, Tran, Hoang, and Bui]{tran2020tensor}
L.~Tran, L.~Tran, T.~Hoang, and B.~Bui.
\newblock Tensor sparse {PCA} and face recognition: a novel approach.
\newblock \emph{SN Applied Sciences}, 2\penalty0 (7):\penalty0 1--7, 2020.

\bibitem[Verd{\'u}(1994)]{verdu1994generalizing}
S.~Verd{\'u}.
\newblock Generalizing the {F}ano inequality.
\newblock \emph{IEEE Transactions on Information Theory}, 40\penalty0 (4):\penalty0 1247--1251, 1994.

\bibitem[Vershynin(2018)]{vershynin2018high}
R.~Vershynin.
\newblock \emph{High-dimensional probability: An introduction with applications in data science}, volume~47.
\newblock Cambridge university press, 2018.

\bibitem[Vu and Lei(2012)]{vu2012minimax}
V.~Vu and J.~Lei.
\newblock Minimax rates of estimation for sparse {PCA} in high dimensions.
\newblock In \emph{Artificial intelligence and statistics}, pages 1278--1286. PMLR, 2012.

\bibitem[Vu and Lei(2013)]{vu2013minimax}
V.~Q. Vu and J.~Lei.
\newblock Minimax sparse principal subspace estimation in high dimensions.
\newblock \emph{The Annals of Statistics}, 41\penalty0 (6):\penalty0 2905--2947, 2013.

\bibitem[Vu et~al.(2013)Vu, Cho, Lei, and Rohe]{vu2013fantope}
V.~Q. Vu, J.~Cho, J.~Lei, and K.~Rohe.
\newblock Fantope projection and selection: A near-optimal convex relaxation of sparse {PCA}.
\newblock \emph{Advances in neural information processing systems}, 26, 2013.

\bibitem[Wainwright(2019)]{wainwright2019high}
M.~J. Wainwright.
\newblock \emph{High-dimensional statistics: {A} non-asymptotic viewpoint}, volume~48.
\newblock Cambridge University Press, 2019.

\bibitem[Wang et~al.(2016)Wang, Berthet, and Samworth]{wang2016statistical}
T.~Wang, Q.~Berthet, and R.~J. Samworth.
\newblock Statistical and computational trade-offs in estimation of sparse principal components.
\newblock \emph{The Annals of Statistics}, 44\penalty0 (5):\penalty0 1896--1930, 2016.

\bibitem[Wang et~al.(2021)Wang, Liu, Chen, Ma, Xue, and Zhao]{wang2021manifold}
Z.~Wang, B.~Liu, S.~Chen, S.~Ma, L.~Xue, and H.~Zhao.
\newblock A manifold proximal linear method for sparse spectral clustering with application to single-cell rna sequencing data analysis.
\newblock \emph{INFORMS Journal on Optimization}, 2021.

\bibitem[Witten et~al.(2009)Witten, Tibshirani, and Hastie]{witten2009penalized}
D.~M. Witten, R.~Tibshirani, and T.~Hastie.
\newblock A penalized matrix decomposition, with applications to sparse principal components and canonical correlation analysis.
\newblock \emph{Biostatistics}, 10\penalty0 (3):\penalty0 515--534, 2009.

\bibitem[Yang and Barron(1999)]{yang1999information}
Y.~Yang and A.~Barron.
\newblock Information-theoretic determination of minimax rates of convergence.
\newblock \emph{Annals of Statistics}, pages 1564--1599, 1999.

\bibitem[Yi and Neykov(2020)]{yi2020non}
Y.~Yi and M.~Neykov.
\newblock Non-sparse {PCA} in high dimensions via cone projected power iteration.
\newblock \emph{arXiv preprint arXiv:2005.07587}, 2020.

\bibitem[Yu(1997)]{yu1997assouad}
B.~Yu.
\newblock Assouad, {F}ano, and {L}e {C}am.
\newblock In \emph{Festschrift for Lucien Le Cam}, pages 423--435. Springer, 1997.

\bibitem[Yuan and Lin(2006)]{yuan2006model}
M.~Yuan and Y.~Lin.
\newblock Model selection and estimation in regression with grouped variables.
\newblock \emph{Journal of the Royal Statistical Society: Series B (Statistical Methodology)}, 68\penalty0 (1):\penalty0 49--67, 2006.

\bibitem[Yuan and Zhang(2013)]{yuan2013truncated}
X.-T. Yuan and T.~Zhang.
\newblock Truncated power method for sparse eigenvalue problems.
\newblock \emph{Journal of Machine Learning Research}, 14\penalty0 (4), 2013.

\bibitem[Zdeborov{\'a} and Krzakala(2016)]{zdeborova2016statistical}
L.~Zdeborov{\'a} and F.~Krzakala.
\newblock Statistical physics of inference: Thresholds and algorithms.
\newblock \emph{Advances in Physics}, 65\penalty0 (5):\penalty0 453--552, 2016.

\bibitem[Zhang et~al.(2012)Zhang, d’Aspremont, and Ghaoui]{zhang2012sparse}
Y.~Zhang, A.~d’Aspremont, and L.~E. Ghaoui.
\newblock Sparse {PCA}: Convex relaxations, algorithms and applications.
\newblock In \emph{Handbook on Semidefinite, Conic and Polynomial Optimization}, pages 915--940. Springer, 2012.

\bibitem[Zou and Hastie(2005)]{zou2005regularization}
H.~Zou and T.~Hastie.
\newblock Regularization and variable selection via the elastic net.
\newblock \emph{Journal of the royal statistical society: series B (statistical methodology)}, 67\penalty0 (2):\penalty0 301--320, 2005.

\bibitem[Zou et~al.(2006)Zou, Hastie, and Tibshirani]{zou2006sparse}
H.~Zou, T.~Hastie, and R.~Tibshirani.
\newblock Sparse principal component analysis.
\newblock \emph{Journal of computational and graphical statistics}, 15\penalty0 (2):\penalty0 265--286, 2006.

\end{thebibliography}
