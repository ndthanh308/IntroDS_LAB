%!TEX root = main-paper-template.tex

\section{General results} \label{sec:general-results}

In this section, we present our general results for union of linearly structured PCA, covering both fundamental limits of estimation and local convergence properties of a projected power method. Recall the notation $\rho(\bm{M}, S)$ from Eq.~\eqref{eqs:rho} for any symmetric matrix $\bm{M} \in \mathbb{R}^{d \times d}$ and set $S \subseteq \mathbb{R}^d$. We let
\begin{align}\label{exhaustive-search-estimator} 
    \ESest := \argmax_{\bm{v} \in \mathcal{M} \cap \mathcal{S}^{d-1}} \bm{v}^{\top} \widehat{\bm{\Sigma}} \bm{v}
\end{align} 
denote the general exhaustive search estimator.
%\apcomment{Put notation for $\rho$ here instead of above. Otherwise recall explicitly.}

\subsection{Fundamental limits of estimation} \label{sec:fund-limits}

\iffalse
\apcomment{Some pointers:
\begin{itemize}
    \item Is there a reason to have Prop 1 and Prop 2 stated in the main text? This is something you need only for the proof right?
    \item I would state the setup for the minimax lower bound up front (including Assumption 1) and then state a {\bf single theorem} for fundamental limits having two parts. Part (a) is the upper bound that does not need further assumptions. Part (b) is the lower bound, which holds under Assumption 1.
    \item After this, you can discuss both parts of the theorem and compare with existing literature/parallels with sparse PCA.
    \item If we state things in this fashion, we don't need two subsubsections here for upper and lower bounds.
\end{itemize}
}
\fi
We begin by studying the fundamental limits of estimation for linearly structured PCA, without computational considerations. These serve as baselines for the results to follow. We first introduce some notation before presenting main results. Recall $\mathcal{L} = \{L_1, \ldots, L_M\}$, the collection of $M$ linear subspaces, and subsets of bases $\mathcal{B}_m \subseteq \mathcal{B} = \{\phi_1, \ldots, \phi_d\}$ such that $L_m = \text{span}(\mathcal{B}_m)$. For each $m \in [M]$, define the characteristic vector $\bm{z}_{m} \in \{0,1\}^d$ of each subset $\mathcal{B}_m$ as follows
\begin{align}\label{definition-z-m}
    \bm{z}_{m}(i) := \left\{
    \begin{array}{lll}
        1 & \text{if } \quad \phi_i \in \mathcal{B}_m \\
        0 & \text{if } \quad \phi_i \notin \mathcal{B}_m
    \end{array}
    \right., \quad \text{for all} \; i \in [d],
\end{align}
where $\bm{z}_{m}(i)$ is the $i$-th entry of $\bm{z}_{m}$. We further define 
\begin{align}\label{definition-i-star}
    i_* := \argmax_{i \in [d]} \sum_{m=1}^{M}\bm{z}_{m}(i) 
\end{align}
as the index with the most ones among $\{\bm{z}_m\}_{m = 1}^M$, breaking ties lexicographically. In words, this is the index of the basis vector that appears in the most subspaces. Now let 
\begin{align}\label{definition-Z-star}
    \mathcal{Z}_{*} := \left\{ \bm{z}_{m} \in \{\bm{z}_1, \ldots, \bm{z}_M\} ~ | ~ \bm{z}_{m}(i_*) = 1 \right\}.
\end{align}
be the set of characteristic vectors with $\bm{z}_{m}(i_*) = 1$. For any fixed integer $r \geq 0$ and characteristic vector $\bm{z} \in \{\bm{z}_{m}\}_{m=1}^{M}$, we use
\begin{align*}
    \mathcal{N}_H(\bm{z}; r) := \left\{ \bm{z}' \in \mathcal{Z}_{*} \;|\; \delta_H(\bm{z}, \bm{z}') \leq r \right\} 
\end{align*} 
to denote the neighborhood of $\bm{z}$ in $\mathcal{Z}_{*}$ with Hamming ball distance $\delta_H(\bm{z}, \bm{z}') := |\{i: \bm{z}(i) \neq \bm{z}'(i) \}|$ at most $r$. We further state Assumption~\ref{assump:minimax-assumption} for the minimax lower bound.


\begin{assumption} \label{assump:minimax-assumption}
%\textbf{Additional Assumptions for the Linear Structure Condition~\ref{cond:linear-structure}.} Assume the following conditions hold.
This assumption has two parts:
\begin{description}
    \item[(a)] For some $k \leq d$, each linear subspace $L_m = \text{span}(\mathcal{B}_m) \in \mathcal{L}$ satisfies $|\mathcal{B}_m| = k$. 
    \item[(b)] There exists $\xi \in [3/4,1)$ such that
    \begin{align} 
        \frac{|\mathcal{Z}_{*}|}{\max_{\bm{z} \in \mathcal{Z}_{*}}|\mathcal{N}_H(\bm{z}; 2(1-\xi)k)|} \geq 16. \label{eq:minimax-assump}
    \end{align}
\end{description}
\end{assumption}

Assumption~\ref{assump:minimax-assumption}(a) is clearly satisfied by vanilla sparse PCA, tree-sparse PCA, and path-sparse PCA. For a general $\mathcal{L}$, one can always set $k = \max_{m \in [M]} |\mathcal{B}_m|$. Assumption~\ref{assump:minimax-assumption}(b), on the other hand, controls the ratio of the sizes between the largest neighborhood $\mathcal{N}_H(\bm{z};2(1-\xi) k)$ (among $\bm{z} \in \mathcal{Z}_*$) and $\mathcal{Z}_*$. Geometric intuition for this assumption will be provided shortly.
%Without such control (Inequality~\eqref{eq:minimax-assump}), there are at least $|\mathcal{Z}_*|/ 16$ linear subspaces overlapping on more than $2(1-\xi)k$ bases. As a result, the size of the packing set for $\mathcal{M}$ approaches the size of the packing set for these heavily overlapped bases, resulting in a decrease in the order of the minimax lower bounds. 
It is worth noting that the specific constant $16$ in Ineq.~\eqref{eq:minimax-assump} is arbitrary, and any constant greater than $2$ can be used. We choose $16$ for simplicity and convenience in presenting the subsequent theoretical results (Theorem~\ref{thm:fund-limits} part (b)). 
%Without such control (Inequality~\eqref{eq:minimax-assump}), there are at least $|\mathcal{Z}_*|/ 16$ linear subspaces overlapping on more than $2(1-\xi)k$ bases. As a result, the size of the packing set for $\mathcal{M}$ approaches the size of the packing set for these heavily overlapped bases, resulting in a decrease in the order of the minimax lower bounds. Moreover, we would like to point out that the right hand side term in Inequality~\eqref{eq:minimax-assump} can be changed to arbitrary constant greater than $2$. We pick $16$ in Inequality~\eqref{eq:minimax-assump} only for constant simplicity that will be presented later in part (b) of Theorem~\ref{thm:fund-limits}.


%Without Inequality~\eqref{eq:minimax-assump}, if the size of $|\mathcal{N}_H(\bm{z}; 2(1-\xi)k)|$ becomes excessively large, at least $|\mathcal{Z}_*|/ 16$ linear subspaces may overlap on more than $2(1-\xi)k$ bases. 
%\begin{itemize}
%	\item {\color{orange}Note that the right hand side term can be changed to arbitrary constant greater than $2$.  We pick $16$ here only for constant simplicity that will be presented later in part (b) of Theorem~\ref{thm:fund-limits}.}
%%	The right hand side term $16$ only influences the constant term of minimax lower bound provided in part (b) of Theorem~\ref{thm:fund-limits}. Indeed, such right hand side term can be taken any constant greater than $2$ to achieve similar minimax bounds aforementioned. We pick $16$ here only for constant simplicity presented in part (b) of Theorem~\ref{thm:fund-limits}.
%	\item  Without such control, if the size of $|\mathcal{N}_H(\bm{z}; 2(1-\xi)k)|$ becomes excessively large, at least $|\mathcal{Z}_*|/ 16$ linear subspaces may overlap on more than $2(1-\xi)k$ bases. As a result, the size of the packing set for $\mathcal{M}$ approaches the size of the packing set for these heavily overlapped bases, resulting in a decrease in the order of the minimax lower bounds.
%\end{itemize}

%\apcomment{I don't understand the following sentence.} \gwcomment{Trying to claim that these linear subspaces should not be clustered too close to each other.}

%Assumption~\text{A\ref{assump:minimax-assumption}.2} places a condition on the local structure around every linear subspace in $\mathcal{L}$; in particular, the size of the neighborhood $\mathcal{N}_H(\bm{z}; k/2)$.  If the size of neighborhoods $\mathcal{N}_H(\bm{z}; k/2)$ are too large, there exists inear subspaces that intersect most of the remaining linear subspaces on at least $k/2$ bases.
% {\color{orange}Thus, such intersections can be ``roughly'' viewed as ``clusters'' of linear subspaces in $\mathcal{L}$. Due to these clusters, intuitively, the size of the packing set for the the union of whole subspaces $\mathcal{M}$ is close to the size of the packing set for these clusters, which reduce the order of the resulting minimax lower bounds.}
% \apcomment{I don't understand the following sentence.} \gwcomment{Trying to claim that these linear subspaces should not be clustered too close to each other.} 
% {\color{orange}As a result, in the extreme case, the packing set of the above linear subspace becomes ``almost'' the packing set of $\mathcal{M}$.} \\
% As a result, it is unlikely to construct a packing set $\mathcal{V}_{\epsilon}$ presented later in Proposition~\ref{prop:g-fano-method} with desire cardinality to show lower bound. 

We are now poised to state the main result of this subsection. Recall that $L_*$ denotes the subspace containing the vector $\bm{v}_*$. Let $\widehat{L} \in \mathcal{L}$ be the linear subspace such that $\ESest \in \widehat{L}$ (once again breaking ties lexicographically) and let $\widehat{F} := \mathsf{conv}(\widehat{L} \cup L_*)$. 

\begin{theorem}\label{thm:fund-limits}
Suppose the linear structure condition in Definition~\ref{cond:linear-structure} holds.

\noindent (a) Let $\ESest$ be defined in equation~\eqref{exhaustive-search-estimator}. Without loss of generality, suppose $\langle \bm{v}_*, \widehat{\bm{v}}_{\mathsf{ES}} \rangle \geq 0$.  Then for all $\bm{v}_* \in \mathcal{S}^{d - 1} \cap \mathcal{M}$, we have
\begin{subequations}
    \begin{align} \label{eq:fund-limit-a}
        \|\widehat{\bm{v}}_{\mathsf{ES}} - \bm{v}_*\|_2 \leq \frac{2\sqrt{2}}{\lambda} \rho(\bm{W}, \widehat{F}).
    \end{align}

\noindent (b) Let $\xi \in [3/4,1)$ such that Assumption~\ref{assump:minimax-assumption} holds. 
%let $\mathcal{D}^{(n)}(\lambda; \bm{v}_*) := \mathcal{D}(\lambda; \bm{v}_*)^{\otimes n}$ be the product measure over the $n$ independent draws of samples from $\mathcal{D}(\lambda; \bm{v}_*)$. With the additional Assumption~\ref{assump:minimax-assumption}, for 
We have the minimax lower bound
%here exists $\bm{v}_* \in \mathcal{S}^{d - 1} \cap \mathcal{M}$ such that for any estimator $\widehat{\bm{v}}$, 
    \begin{align}
        &\inf_{\widehat{\bm{v}}} \; \sup_{\bm{v}_* \in \mathcal{S}^{d - 1} \cap \mathcal{M}} \mathbb{E} \left[ \left\| \widehat{\bm{v}} \widehat{\bm{v}}^{\top} - \bm{v}_* \bm{v}_*^{\top}  \right\|_F \right]  \notag\\
        & \qquad \geq \frac{\sqrt{2(1 - \xi)}}{4} \min\Bigg\{1, ~~ \sqrt{\frac{1 + \lambda}{8 \lambda^2}} \sqrt{\frac{ \log \left(|\mathcal{Z}_*|\right) - \log \big( \max_{\bm{z} \in \mathcal{Z}_{*}}|\mathcal{N}_H(\bm{z}; 2(1 - \xi) k)| \big)}{n}} \Bigg\}. \label{eq:fund-limit-b}
    \end{align}
    \end{subequations}
    Here, the infimum is taken over all measurable functions of the observations $\{ \bm{x}_i \}_{i = 1}^n$, which are drawn i.i.d. from the distribution $\mathcal{D}(\lambda; \bm{v}_*)$.
\end{theorem}

Theorem~\ref{thm:fund-limits}(a) provides a deterministic upper bound on the $\ell_2$ error between the estimate $\widehat{\bm{v}}_{\mathsf{ES}}$ and the ground truth $\bm{v}_*$, showing that this error can be bounded on the order $\rho(\bm{W}, \widehat{F})$ for any fixed $\lambda$. 
%The statement of the theorem should be compared with that of~\citet{yuan2013truncated} for vanilla sparse PCA---our contribution is to modify the proof technique to show that a projected power method for union-of-linear attains a similar guarantee. 
We provide the proof of this result in Section~\ref{app:fund-limits-up}. While the result is deterministic, we will see that Eq.~\eqref{eq:fund-limit-a} nearly matches the minimax lower bound Eq.~\eqref{eq:fund-limit-b} for our special cases of interest. Consequently, we use Theorem~\ref{thm:fund-limits}(a) as a heuristic baseline to assess the performance of efficient algorithms. 
 
%We will shortly use this result as a baseline to assess the performance of efficient algorithms.


%The proof of Part (b) of Theorem~\ref{thm:fund-limits} is presented in the Appendix~\ref{app:fund-limits-lb}. Comparing with existing minimax lower of classical sparse PCA and path-sparse PCA, 

On its own, Theorem~\ref{thm:fund-limits}(b) provides a minimax lower bound that depends on the local structure of $\mathcal{M}$ around any choice of ground truth $\bm{v}_*$. 
%-- the number of linear subspaces that shares at least $2(1 - \xi)k$ same bases -- of $\mathcal{L}$. 
The proof uses the generalized Fano inequality \citep{verdu1994generalizing}, and we construct a rich packing set $\mathcal{V}_{\epsilon}$ in $\mathcal{S}^{d - 1} \cap \mathcal{M}$ (i.e., $\mathcal{V}$ in Proposition~\ref{prop:g-fano-method} of Appendix~\ref{app:fund-limits-lb}) such that the points in $\mathcal{V}_{\epsilon}$ are $\mathcal{O}(\epsilon)$ separated in some appropriate distance measure. In contrast to existing proofs for sparse PCA \citep{vu2012minimax} and path PCA \citep{asteris2015stay}, the set $\mathcal{V}_{\epsilon}$ here is constructed so that there exists a common support index (i.e., the index $i_*$, defined in Eq~\eqref{definition-i-star}) for every point $\bm{v} \in \mathcal{V}_{\epsilon}$ that one can use to construct the packing. 
%(in the order of $O(\sqrt{1 - \epsilon^2})$) to ensure the condition~\eqref{cond:g-fano-method} in the generalized Fano method.  \apcomment{Wasn't there a structured subspace paper by Cai and Ma (with both upper and lower bounds) that we should compare to?} \gwcomment{Done, add as follows.} 
%
%\gwcomment{Very important, compare difference between (10b) and Cai et al. (2021)'s minimax result. Also compare with Tong Zhang upper bound for sparse PCA.}
%{\color{orange}
On a related note, a paper by \citet{cai2021optimal} studies the minimax risk of a general structured principal subspace estimation problem, including vanilla sparse PCA as a special case. These bounds are phrased in terms of critical inequalities that arise from local packing numbers (see~\cite{yang1999information,wainwright2019high}). Our lower bound instead takes a more global approach, which we show suffices for union-of-linear structure.
%In particular, the minimax lower bound presented in \cite{cai2021optimal} is characterized by the entropy measure of the size of some local packing set. 
%\gwcomment{(1) upper bound (2) Cai gives a minimax bound with local packing set, we can do the similar thing. But here, we consider in a more global perspective, ...}
In particular, the minimax lower bound~\eqref{eq:fund-limit-b} is controlled by the relative ratio between $|\mathcal{N}_H(\bm{z};2(1-\xi) k)|$ and $|\mathcal{Z}_*|$: Our assumption in Ineq.~\eqref{eq:minimax-assump} avoids the scenario that many linear subspaces heavily overlap on a few bases.  
%A recent paper by \cite{cai2021optimal} studies minimax lower bounds for structured principal subspace estimation. The key distinction in our case (under Definition~\ref{cond:linear-structure}) is that $\mathcal{N}_H(\bm{z}; r)$ emerges as a natural way to quantify how heavily clustered the linear subspaces are (see Ineq.~\eqref{eq:minimax-assump}). Without the Ineq.~\eqref{eq:minimax-assump}, there are at least $|\mathcal{Z}_*|/ 16$ linear subspaces overlapping on more than $2(1-\xi)k$ bases. As a result, the size of the packing set for $\mathcal{M}$ approaches the size of the packing set for these heavily overlapped bases, resulting in a decrease in the order of the minimax lower bounds. 
%}



Finally, it is instructive to note that Theorem~\ref{thm:fund-limits}(b) recovers the existing minimax lower bound for vanilla sparse PCA [Theorem 2.1, \cite{vu2012minimax}]. 
% the minimax lower bound in Theorem~\ref{thm:fund-limits}(b) with the existing minimax lower bound for sparse PCA [Theorem 2.1, \cite{vu2012minimax}]. 
 Indeed, supposing that $d \gg k$ and applying Theorem~\ref{thm:fund-limits}(b) for sparse PCA, we obtain the known lower bound
\begin{align} \label{eq:SPCA-known}
    \inf_{\widehat{\bm{v}}} \; \sup_{ \bm{v_*} \in \mathcal{S}^{d - 1}: \| \bm{v_*} \|_0 \leq k} \mathbb{E} \;\left[ \left\| \widehat{\bm{v}} \widehat{\bm{v}}^{\top} - \bm{v}_* \bm{v}_*^{\top}  \right\|_F \right] \gtrsim  \min\bigg\{1,  \sqrt{\frac{1 + \lambda}{8 \lambda^2}} \sqrt{\frac{k \log d}{n}} \bigg\}. 
\end{align}
The proof of inequality~\eqref{eq:SPCA-known} (from Theorem~\ref{thm:fund-limits}(b)) is provided in Section~\ref{min-max-pca-proof} for completeness. In Section~\ref{sec:specific-examples}, we provide novel corollaries for tree-sparse PCA and path-sparse PCA.

%\apcomment{No need to state the following as formal corollary. Just state in text.} \gwcomment{Done.}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



