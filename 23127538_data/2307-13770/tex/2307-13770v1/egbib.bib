@inproceedings{dosovitskiy2020image,
  title={An image is worth 16x16 words: Transformers for image recognition at scale},
  author={Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and others},
  booktitle={ICLR},
  year={2021}
}

@inproceedings{liu2021swin,
  title={Swin transformer: Hierarchical vision transformer using shifted windows},
  author={Liu, Ze and Lin, Yutong and Cao, Yue and Hu, Han and Wei, Yixuan and Zhang, Zheng and Lin, Stephen and Guo, Baining},
  booktitle={ICCV},
  year={2021}
}

@inproceedings{he2016deep,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={CVPR},
  year={2016}
}

@inproceedings{mahajan2018exploring,
  title={Exploring the limits of weakly supervised pretraining},
  author={Mahajan, Dhruv and Girshick, Ross and Ramanathan, Vignesh and He, Kaiming and Paluri, Manohar and Li, Yixuan and Bharambe, Ashwin and Van Der Maaten, Laurens},
  booktitle={ECCV},
  year={2018}
}

@inproceedings{jia2021exploring,
  title={Exploring visual engagement signals for representation learning},
  author={Jia, Menglin and Wu, Zuxuan and Reiter, Austin and Cardie, Claire and Belongie, Serge and Lim, Ser-Nam},
  booktitle={ICCV},
  year={2021}
}

@inproceedings{chen2021empirical,
  title={An empirical study of training self-supervised vision transformers},
  author={Chen, Xinlei and Xie, Saining and He, Kaiming},
  booktitle={ICCV},
  year={2021}
}

@inproceedings{cai2020tinytl,
  title={Tinytl: Reduce memory, not parameters for efficient on-device learning},
  author={Cai, Han and Gan, Chuang and Zhu, Ligeng and Han, Song},
  booktitle={NeurIPS},
  year={2020}
}

@inproceedings{rebuffi2017learning,
  title={Learning multiple visual domains with residual adapters},
  author={Rebuffi, Sylvestre-Alvise and Bilen, Hakan and Vedaldi, Andrea},
  booktitle={NeurIPS},
  year={2017}
}

@inproceedings{zhang2020side,
  title={Side-tuning: a baseline for network adaptation via additive side networks},
  author={Zhang, Jeffrey O and Sax, Alexander and Zamir, Amir and Guibas, Leonidas and Malik, Jitendra},
  booktitle={ECCV},
  year={2020}
}

@inproceedings{jia2022visual,
  title={Visual prompt tuning},
  author={Jia, Menglin and Tang, Luming and Chen, Bor-Chun and Cardie, Claire and Belongie, Serge and Hariharan, Bharath and Lim, Ser-Nam},
  booktitle={ECCV},
  year={2022}
}

@inproceedings{ju2022prompting,
  title={Prompting visual-language models for efficient video understanding},
  author={Ju, Chen and Han, Tengda and Zheng, Kunhao and Zhang, Ya and Xie, Weidi},
  booktitle={ECCV},
  year={2022}
}

@article{zang2022unified,
  title={Unified vision and language prompt learning},
  author={Zang, Yuhang and Li, Wei and Zhou, Kaiyang and Huang, Chen and Loy, Chen Change},
  journal={arXiv preprint arXiv:2210.07225},
  year={2022}
}

@inproceedings{lin2021traceability,
  title={Traceability transformed: Generating more accurate links with pre-trained bert models},
  author={Lin, Jinfeng and Liu, Yalin and Zeng, Qingkai and Jiang, Meng and Cleland-Huang, Jane},
  booktitle={ICSE},
  year={2021}
}

@article{tajbakhsh2016convolutional,
  title={Convolutional neural networks for medical image analysis: Full training or fine tuning?},
  author={Tajbakhsh, Nima and Shin, Jae Y and Gurudu, Suryakanth R and Hurst, R Todd and Kendall, Christopher B and Gotway, Michael B and Liang, Jianming},
  journal={IEEE Transactions on Medical Imaging},
  year={2016},
}

@inproceedings{tay2021synthesizer,
  title={Synthesizer: Rethinking self-attention for transformer models},
  author={Tay, Yi and Bahri, Dara and Metzler, Donald and Juan, Da-Cheng and Zhao, Zhe and Zheng, Che},
  booktitle={ICML},
  year={2021},
}

@article{han2022survey,
  title={A survey on vision transformer},
  author={Han, Kai and Wang, Yunhe and Chen, Hanting and Chen, Xinghao and Guo, Jianyuan and Liu, Zhenhua and Tang, Yehui and Xiao, An and Xu, Chunjing and Xu, Yixing and others},
  journal={IEEE TPAMI},
  year={2022}
}

@inproceedings{mao2022towards,
  title={Towards robust vision transformer},
  author={Mao, Xiaofeng and Qi, Gege and Chen, Yuefeng and Li, Xiaodan and Duan, Ranjie and Ye, Shaokai and He, Yuan and Xue, Hui},
  booktitle={CVPR},
  year={2022}
}

@inproceedings{zhu2021long,
  title={Long-short transformer: Efficient transformers for language and vision},
  author={Zhu, Chen and Ping, Wei and Xiao, Chaowei and Shoeybi, Mohammad and Goldstein, Tom and Anandkumar, Anima and Catanzaro, Bryan},
  booktitle={NeurIPS},
  year={2021}
}

@inproceedings{yang2021transformer,
  title={Transformer-based attention networks for continuous pixel-wise prediction},
  author={Yang, Guanglei and Tang, Hao and Ding, Mingli and Sebe, Nicu and Ricci, Elisa},
  booktitle={ICCV},
  year={2021}
}

@article{zhai2019large,
  title={A large-scale study of representation learning with the visual task adaptation benchmark},
  author={Zhai, Xiaohua and Puigcerver, Joan and Kolesnikov, Alexander and Ruyssen, Pierre and Riquelme, Carlos and Lucic, Mario and Djolonga, Josip and Pinto, Andre Susano and Neumann, Maxim and Dosovitskiy, Alexey and others},
  journal={arXiv preprint arXiv:1910.04867},
  year={2019}
}

@inproceedings{frankle2018lottery,
  title={The lottery ticket hypothesis: Finding sparse, trainable neural networks},
  author={Frankle, Jonathan and Carbin, Michael},
  booktitle={ICLR},
  year={2019}
}

@article{liang2021super,
  title={Super tickets in pre-trained language models: From model compression to improving generalization},
  author={Liang, Chen and Zuo, Simiao and Chen, Minshuo and Jiang, Haoming and Liu, Xiaodong and He, Pengcheng and Zhao, Tuo and Chen, Weizhu},
  journal={arXiv preprint arXiv:2105.12002},
  year={2021}
}

@inproceedings{lecun1989optimal,
  title={Optimal brain damage},
  author={LeCun, Yann and Denker, John and Solla, Sara},
  booktitle={NeurIPS},
  year={1989}
}

@inproceedings{hassibi1992second,
  title={Second order derivatives for network pruning: Optimal brain surgeon},
  author={Hassibi, Babak and Stork, David},
  booktitle={NeurIPS},
  year={1992}
}

@article{han2015learning,
  title={Learning both weights and connections for efficient neural network},
  author={Han, Song and Pool, Jeff and Tran, John and Dally, William},
  journal={NeurIPS},
  year={2015}
}

@article{li2016pruning,
  title={Pruning filters for efficient convnets},
  author={Li, Hao and Kadav, Asim and Durdanovic, Igor and Samet, Hanan and Graf, Hans Peter},
  journal={arXiv preprint arXiv:1608.08710},
  year={2016}
}

@article{xu2021human,
  title={Human parity on commonsenseqa: Augmenting self-attention with external attention},
  author={Xu, Yichong and Zhu, Chenguang and Wang, Shuohang and Sun, Siqi and Cheng, Hao and Liu, Xiaodong and Gao, Jianfeng and He, Pengcheng and Zeng, Michael and Huang, Xuedong},
  journal={arXiv preprint arXiv:2112.03254},
  year={2021}
}

@article{ahmad2020transformer,
  title={A transformer-based approach for source code summarization},
  author={Ahmad, Wasi Uddin and Chakraborty, Saikat and Ray, Baishakhi and Chang, Kai-Wei},
  journal={arXiv preprint arXiv:2005.00653},
  year={2020}
}

@article{guo2022visual,
  title={Visual attention network},
  author={Guo, Meng-Hao and Lu, Cheng-Ze and Liu, Zheng-Ning and Cheng, Ming-Ming and Hu, Shi-Min},
  journal={arXiv preprint arXiv:2202.09741},
  year={2022}
}

@inproceedings{glorot2010understanding,
  title={Understanding the difficulty of training deep feedforward neural networks},
  author={Glorot, Xavier and Bengio, Yoshua},
  booktitle={AISTATS},
  year={2010}
}

@inproceedings{he2015delving,
  title={Delving deep into rectifiers: Surpassing human-level performance on imagenet classification},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={ICCV},
  year={2015}
}

@article{vinuesa2020role,
  title={The role of artificial intelligence in achieving the Sustainable Development Goals},
  author={Vinuesa, Ricardo and Azizpour, Hossein and Leite, Iolanda and Balaam, Madeline and Dignum, Virginia and Domisch, Sami and Fell{\"a}nder, Anna and Langhans, Simone Daniela and Tegmark, Max and Fuso Nerini, Francesco},
  journal={Nature Communications},
  year={2020},
}

@article{wu2022sustainable,
  title={Sustainable ai: Environmental implications, challenges and opportunities},
  author={Wu, Carole-Jean and Raghavendra, Ramya and Gupta, Udit and Acun, Bilge and Ardalani, Newsha and Maeng, Kiwan and Chang, Gloria and Aga, Fiona and Huang, Jinshi and Bai, Charles and others},
  journal={Proceedings of Machine Learning and Systems},
  year={2022}
}

@article{van2021sustainable,
  title={Sustainable AI: AI for sustainability and the sustainability of AI},
  author={Van Wynsberghe, Aimee},
  journal={AI and Ethics},
  year={2021},
}

@article{nishant2020artificial,
  title={Artificial intelligence for sustainability: Challenges, opportunities, and a research agenda},
  author={Nishant, Rohit and Kennedy, Mike and Corbett, Jacqueline},
  journal={International Journal of Information Management},
  year={2020}
}

@article{wah2011caltech,
  title={The caltech-ucsd birds-200-2011 dataset},
  author={Wah, Catherine and Branson, Steve and Welinder, Peter and Perona, Pietro and Belongie, Serge},
  year={2011},
  publisher={California Institute of Technology}
}

@inproceedings{van2015building,
  title={Building a bird recognition app and large scale dataset with citizen scientists: The fine print in fine-grained dataset collection},
  author={Van Horn, Grant and Branson, Steve and Farrell, Ryan and Haber, Scott and Barry, Jessie and Ipeirotis, Panos and Perona, Pietro and Belongie, Serge},
  booktitle={CVPR},
  year={2015}
}

@inproceedings{nilsback2008automated,
  title={Automated flower classification over a large number of classes},
  author={Nilsback, Maria-Elena and Zisserman, Andrew},
  booktitle={Indian Conference on Computer Vision, Graphics \& Image Processing},
  year={2008},
}

@inproceedings{khosla2011novel,
  title={Novel dataset for fine-grained image categorization: Stanford dogs},
  author={Khosla, Aditya and Jayadevaprakash, Nityananda and Yao, Bangpeng and Li, Fei-Fei},
  booktitle={CVPR Workshop},
  year={2011},
}

@inproceedings{gebru2017fine,
  title={Fine-grained car detection for visual census estimation},
  author={Gebru, Timnit and Krause, Jonathan and Wang, Yilun and Chen, Duyun and Deng, Jia and Fei-Fei, Li},
  booktitle={AAAI},
  year={2017}
}

@inproceedings{he2022masked,
  title={Masked autoencoders are scalable vision learners},
  author={He, Kaiming and Chen, Xinlei and Xie, Saining and Li, Yanghao and Doll{\'a}r, Piotr and Girshick, Ross},
  booktitle={CVPR},
  year={2022}
}

@article{lin2022survey,
  title={A survey of transformers},
  author={Lin, Tianyang and Wang, Yuxin and Liu, Xiangyang and Qiu, Xipeng},
  journal={AI Open},
  year={2022},
}

@article{khan2022transformers,
  title={Transformers in vision: A survey},
  author={Khan, Salman and Naseer, Muzammal and Hayat, Munawar and Zamir, Syed Waqas and Khan, Fahad Shahbaz and Shah, Mubarak},
  journal={ACM Computing Surveys},
  volume={54},
  number={10s},
  pages={1--41},
  year={2022},
}

@inproceedings{ren2023prepare,
  title={How to prepare your task head for finetuning},
  author={Ren, Yi and Guo, Shangmin and Bae, Wonho and Sutherland, Danica J},
  booktitle={ICLR},
  year={2023}
}

@article{he2022parameter,
  title={Parameter-efficient fine-tuning for vision transformers},
  author={He, Xuehai and Li, Chunyuan and Zhang, Pengchuan and Yang, Jianwei and Wang, Xin Eric},
  journal={arXiv preprint arXiv:2203.16329},
  year={2022}
}

@inproceedings{sandler2018mobilenetv2,
  title={Mobilenetv2: Inverted residuals and linear bottlenecks},
  author={Sandler, Mark and Howard, Andrew and Zhu, Menglong and Zhmoginov, Andrey and Chen, Liang-Chieh},
  booktitle={CVPR},
  year={2018}
}

@inproceedings{davison2019commonsense,
  title={Commonsense knowledge mining from pretrained models},
  author={Davison, Joe and Feldman, Joshua and Rush, Alexander M},
  booktitle={EMNLP},
  year={2019}
}

@article{gong2021prompt,
  title={Prompt-based Zero-shot Relation Classification with Semantic Knowledge Augmentation},
  author={Gong, Jiaying and Eldardiry, Hoda},
  journal={arXiv preprint arXiv:2112.04539},
  year={2021}
}

@article{radford2019language,
  title={Language models are unsupervised multitask learners},
  author={Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya and others},
  journal={OpenAI Blog},
  year={2019}
}

@inproceedings{wang2021transprompt,
  title={TransPrompt: Towards an automatic transferable prompting framework for few-shot text classification},
  author={Wang, Chengyu and Wang, Jianing and Qiu, Minghui and Huang, Jun and Gao, Ming},
  booktitle={EMNLP},
  year={2021}
}

@article{khashabi2020unifiedqa,
  title={Unifiedqa: Crossing format boundaries with a single qa system},
  author={Khashabi, Daniel and Min, Sewon and Khot, Tushar and Sabharwal, Ashish and Tafjord, Oyvind and Clark, Peter and Hajishirzi, Hannaneh},
  journal={arXiv preprint arXiv:2005.00700},
  year={2020}
}

@inproceedings{ma2022xprompt,
  title={XPrompt: Exploring the Extreme of Prompt Tuning},
  author={Ma, Fang and Zhang, Chen and Ren, Lei and Wang, Jingang and Wang, Qifan and Wu, Wei and Quan, Xiaojun and Song, Dawei},
  booktitle={EMNLP},
  year={2022}
}

@inproceedings{he2022hyperprompt,
  title={Hyperprompt: Prompt-based task-conditioning of transformers},
  author={He, Yun and Zheng, Steven and Tay, Yi and Gupta, Jai and Du, Yu and Aribandi, Vamsi and Zhao, Zhe and Li, YaGuang and Chen, Zhao and Metzler, Donald and others},
  booktitle={ICML},
  year={2022},
}

@article{xing2022class,
  title={Class-aware visual prompt tuning for vision-language pre-trained model},
  author={Xing, Yinghui and Wu, Qirui and Cheng, De and Zhang, Shizhou and Liang, Guoqiang and Zhang, Yanning},
  journal={arXiv preprint arXiv:2208.08340},
  year={2022}
}

@article{gao2022visual,
  title={Visual Prompt Tuning for Test-time Domain Adaptation},
  author={Gao, Yunhe and Shi, Xingjian and Zhu, Yi and Wang, Hao and Tang, Zhiqiang and Zhou, Xiong and Li, Mu and Metaxas, Dimitris N},
  journal={arXiv preprint arXiv:2210.04831},
  year={2022}
}

@inproceedings{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  booktitle={NeurIPS},
  year={2017}
}

@inproceedings{devlin2018bert,
  title={Bert: Pre-training of deep bidirectional transformers for language understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  booktitle={NAACL-HLT},
  year={2018}
}

@inproceedings{liu2019roberta,
  title={Roberta: A robustly optimized bert pretraining approach},
  author={Liu, Yinhan and Ott, Myle and Goyal, Naman and Du, Jingfei and Joshi, Mandar and Chen, Danqi and Levy, Omer and Lewis, Mike and Zettlemoyer, Luke and Stoyanov, Veselin},
  booktitle={ICLR},
  year={2020}
}

@inproceedings{carion2020end,
  title={End-to-end object detection with transformers},
  author={Carion, Nicolas and Massa, Francisco and Synnaeve, Gabriel and Usunier, Nicolas and Kirillov, Alexander and Zagoruyko, Sergey},
  booktitle={ECCV},
  year={2020},
}

@inproceedings{zhu2020deformable,
  title={Deformable detr: Deformable transformers for end-to-end object detection},
  author={Zhu, Xizhou and Su, Weijie and Lu, Lewei and Li, Bin and Wang, Xiaogang and Dai, Jifeng},
  booktitle={ICLR},
  year={2021}
}

@article{beal2020toward,
  title={Toward transformer-based object detection},
  author={Beal, Josh and Kim, Eric and Tzeng, Eric and Park, Dong Huk and Zhai, Andrew and Kislyuk, Dmitry},
  journal={arXiv preprint arXiv:2012.09958},
  year={2020}
}

@article{yuan2021temporal,
  title={Temporal-channel transformer for 3d lidar-based video object detection for autonomous driving},
  author={Yuan, Zhenxun and Song, Xiao and Bai, Lei and Wang, Zhe and Ouyang, Wanli},
  journal={IEEE Transactions on Circuits and Systems for Video Technology},
  year={2021},
}

@inproceedings{pan20213d,
  title={3d object detection with pointformer},
  author={Pan, Xuran and Xia, Zhuofan and Song, Shiji and Li, Li Erran and Huang, Gao},
  booktitle={CVPR},
  year={2021}
}

@inproceedings{zheng2021rethinking,
  title={Rethinking semantic segmentation from a sequence-to-sequence perspective with transformers},
  author={Zheng, Sixiao and Lu, Jiachen and Zhao, Hengshuang and Zhu, Xiatian and Luo, Zekun and Wang, Yabiao and Fu, Yanwei and Feng, Jianfeng and Xiang, Tao and Torr, Philip HS and others},
  booktitle={CVPR},
  year={2021}
}

@inproceedings{wang2021max,
  title={Max-deeplab: End-to-end panoptic segmentation with mask transformers},
  author={Wang, Huiyu and Zhu, Yukun and Adam, Hartwig and Yuille, Alan and Chen, Liang-Chieh},
  booktitle={CVPR},
  year={2021}
}

@inproceedings{wang2021end,
  title={End-to-end video instance segmentation with transformers},
  author={Wang, Yuqing and Xu, Zhaoliang and Wang, Xinlong and Shen, Chunhua and Cheng, Baoshan and Shen, Hao and Xia, Huaxia},
  booktitle={CVPR},
  year={2021}
}

@inproceedings{huang2020hand,
  title={Hand-transformer: non-autoregressive structured modeling for 3d hand pose estimation},
  author={Huang, Lin and Tan, Jianchao and Liu, Ji and Yuan, Junsong},
  booktitle={ECCV},
  year={2020}
}

@inproceedings{huang2020hot,
  title={Hot-net: Non-autoregressive transformer for 3d hand-object pose estimation},
  author={Huang, Lin and Tan, Jianchao and Meng, Jingjing and Liu, Ji and Yuan, Junsong},
  booktitle={ACMMM},
  year={2020}
}

@inproceedings{lin2021end,
  title={End-to-end human pose and mesh reconstruction with transformers},
  author={Lin, Kevin and Wang, Lijuan and Liu, Zicheng},
  booktitle={CVPR},
  year={2021}
}

@inproceedings{yang2021transpose,
  title={Transpose: Keypoint localization via transformer},
  author={Yang, Sen and Quan, Zhibin and Nie, Mu and Yang, Wankou},
  booktitle={ICCV},
  year={2021}
}

@article{raffel2020exploring,
  title={Exploring the limits of transfer learning with a unified text-to-text transformer},
  author={Raffel, Colin and Shazeer, Noam and Roberts, Adam and Lee, Katherine and Narang, Sharan and Matena, Michael and Zhou, Yanqi and Li, Wei and Liu, Peter J},
  journal={The Journal of Machine Learning Research},
  year={2020},
}

@inproceedings{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  booktitle={NeurIPS},
  year={2020}
}

@inproceedings{liu2022swin,
  title={Swin transformer v2: Scaling up capacity and resolution},
  author={Liu, Ze and Hu, Han and Lin, Yutong and Yao, Zhuliang and Xie, Zhenda and Wei, Yixuan and Ning, Jia and Cao, Yue and Zhang, Zheng and Dong, Li and others},
  booktitle={CVPR},
  year={2022}
}

@inproceedings{strudel2021segmenter,
  title={Segmenter: Transformer for semantic segmentation},
  author={Strudel, Robin and Garcia, Ricardo and Laptev, Ivan and Schmid, Cordelia},
  booktitle={ICCV},
  year={2021}
}

@inproceedings{bao2021beit,
  title={Beit: Bert pre-training of image transformers},
  author={Bao, Hangbo and Dong, Li and Piao, Songhao and Wei, Furu},
  booktitle={ICLR},
  year={2022}
}

@inproceedings{wang2019superglue,
  title={Superglue: A stickier benchmark for general-purpose language understanding systems},
  author={Wang, Alex and Pruksachatkun, Yada and Nangia, Nikita and Singh, Amanpreet and Michael, Julian and Hill, Felix and Levy, Omer and Bowman, Samuel},
  booktitle={NeurIPS},
  year={2019}
}

@article{liu2021p,
  title={P-tuning v2: Prompt tuning can be comparable to fine-tuning universally across scales and tasks},
  author={Liu, Xiao and Ji, Kaixuan and Fu, Yicheng and Du, Zhengxiao and Yang, Zhilin and Tang, Jie},
  journal={arXiv preprint arXiv:2110.07602},
  year={2021}
}

@inproceedings{lester2021power,
  title={The power of scale for parameter-efficient prompt tuning},
  author={Lester, Brian and Al-Rfou, Rami and Constant, Noah},
  booktitle={EMNLP},
  year={2021}
}

@inproceedings{zhang2022patchformer,
  title={Patchformer: An efficient point transformer with patch attention},
  author={Zhang, Cheng and Wan, Haocheng and Shen, Xinyi and Wu, Zizhao},
  booktitle={CVPR},
  year={2022}
}

@article{fournier2021practical,
  title={A practical survey on faster and lighter transformers},
  author={Fournier, Quentin and Caron, Ga{\'e}tan Marceau and Aloise, Daniel},
  journal={arXiv preprint arXiv:2103.14636},
  year={2021}
}

@article{islam2022recent,
  title={Recent advances in vision transformer: A survey and outlook of recent work},
  author={Islam, Khawar},
  journal={arXiv preprint arXiv:2203.01536},
  year={2022}
}

@article{narkhede2022review,
  title={A review on weight initialization strategies for neural networks},
  author={Narkhede, Meenal V and Bartakke, Prashant P and Sutaone, Mukul S},
  journal={Artificial Intelligence Review},
  year={2022},
}

@inproceedings{ganea2018hyperbolic,
  title={Hyperbolic neural networks},
  author={Ganea, Octavian and B{\'e}cigneul, Gary and Hofmann, Thomas},
  booktitle={NeurIPS},
  year={2018}
}

@inproceedings{ermolov2022hyperbolic,
  title={Hyperbolic vision transformers: Combining improvements in metric learning},
  author={Ermolov, Aleksandr and Mirvakhabova, Leyla and Khrulkov, Valentin and Sebe, Nicu and Oseledets, Ivan},
  booktitle={CVPR},
  year={2022}
}

@inproceedings{khrulkov2020hyperbolic,
  title={Hyperbolic image embeddings},
  author={Khrulkov, Valentin and Mirvakhabova, Leyla and Ustinova, Evgeniya and Oseledets, Ivan and Lempitsky, Victor},
  booktitle={CVPR},
  year={2020}
}

@inproceedings{atigh2022hyperbolic,
  title={Hyperbolic image segmentation},
  author={Atigh, Mina Ghadimi and Schoep, Julian and Acar, Erman and Van Noord, Nanne and Mettes, Pascal},
  booktitle={CVPR},
  year={2022}
}

@article{peng2021hyperbolic,
  title={Hyperbolic deep neural networks: A survey},
  author={Peng, Wei and Varanka, Tuomas and Mostafa, Abdelrahman and Shi, Henglin and Zhao, Guoying},
  journal={IEEE TPAMI},
  year={2021}
}

@inproceedings{iofinova2022well,
  title={How well do sparse imagenet models transfer?},
  author={Iofinova, Eugenia and Peste, Alexandra and Kurtz, Mark and Alistarh, Dan},
  booktitle={CVPR},
  year={2022}
}

@inproceedings{chen2020improved,
  title={Improved baselines with momentum contrastive learning},
  author={Chen, Xinlei and Fan, Haoqi and Girshick, Ross and He, Kaiming},
  booktitle={CVPR},
  year={2020}
}

@inproceedings{yosinski2014transferable,
  title={How transferable are features in deep neural networks?},
  author={Yosinski, Jason and Clune, Jeff and Bengio, Yoshua and Lipson, Hod},
  booktitle={NeurIPS},
  year={2014}
}

@inproceedings{zhang2016colorful,
  title={Colorful image colorization},
  author={Zhang, Richard and Isola, Phillip and Efros, Alexei A},
  booktitle={ECCV},
  year={2016},
}

@inproceedings{noroozi2016unsupervised,
  title={Unsupervised learning of visual representations by solving jigsaw puzzles},
  author={Noroozi, Mehdi and Favaro, Paolo},
  booktitle={ECCV},
  year={2016},
}

@inproceedings{NEURIPS2019_9015,
title = {PyTorch: An Imperative Style, High-Performance Deep Learning Library},
author = {Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and Desmaison, Alban and Kopf, Andreas and Yang, Edward and DeVito, Zachary and Raison, Martin and Tejani, Alykhan and Chilamkurthy, Sasank and Steiner, Benoit and Fang, Lu and Bai, Junjie and Chintala, Soumith},
booktitle = {NeurIPS},
year = {2019},
}

@inproceedings{katharopoulos2020transformers,
  title={Transformers are rnns: Fast autoregressive transformers with linear attention},
  author={Katharopoulos, Angelos and Vyas, Apoorv and Pappas, Nikolaos and Fleuret, Fran{\c{c}}ois},
  booktitle={ICML},
  year={2020},
}

@article{li2021prefix,
  title={Prefix-tuning: Optimizing continuous prompts for generation},
  author={Li, Xiang Lisa and Liang, Percy},
  journal={arXiv preprint arXiv:2101.00190},
  year={2021}
}

@article{liu2021gpt,
  title={GPT understands, too},
  author={Liu, Xiao and Zheng, Yanan and Du, Zhengxiao and Ding, Ming and Qian, Yujie and Yang, Zhilin and Tang, Jie},
  journal={arXiv preprint arXiv:2103.10385},
  year={2021}
}

@inproceedings{michel2019sixteen,
  title={Are sixteen heads really better than one?},
  author={Michel, Paul and Levy, Omer and Neubig, Graham},
  booktitle={NeurIPS},
  year={2019}
  }

  @inproceedings{renda2020comparing,
  title={Comparing rewinding and fine-tuning in neural network pruning},
  author={Renda, Alex and Frankle, Jonathan and Carbin, Michael},
  booktitle={ICLR},
  year={2020}
}

@inproceedings{li2022automated,
  title={Automated progressive learning for efficient training of vision transformers},
  author={Li, Changlin and Zhuang, Bohan and Wang, Guangrun and Liang, Xiaodan and Chang, Xiaojun and Yang, Yi},
  booktitle={CVPR},
  year={2022}
}

@article{zhuang2023survey,
  title={A Survey on Efficient Training of Transformers},
  author={Zhuang, Bohan and Liu, Jing and Pan, Zizheng and He, Haoyu and Weng, Yuetian and Shen, Chunhua},
  journal={arXiv preprint arXiv:2302.01107},
  year={2023}
}

@article{mcinnes2018umap,
  title={Umap: Uniform manifold approximation and projection for dimension reduction},
  author={McInnes, Leland and Healy, John and Melville, James},
  journal={arXiv preprint arXiv:1802.03426},
  year={2018}
}

@inproceedings{loshchilov2017decoupled,
  title={Decoupled weight decay regularization},
  author={Loshchilov, Ilya and Hutter, Frank},
  booktitle={ICML},
  year={2017}
}

@article{krizhevsky2009learning,
  title={Learning multiple layers of features from tiny images},
  author={Krizhevsky, Alex and Hinton, Geoffrey and others},
  year={2009},
  publisher={Toronto, ON, Canada}
}

@inproceedings{xiao2010sun,
  title={Sun database: Large-scale scene recognition from abbey to zoo},
  author={Xiao, Jianxiong and Hays, James and Ehinger, Krista A and Oliva, Aude and Torralba, Antonio},
  booktitle={CVPR},
  year={2010}
}

@inproceedings{cimpoi14describing,
  Author    = {M. Cimpoi and S. Maji and I. Kokkinos and S. Mohamed and and A. Vedaldi},
  Title     = {Describing Textures in the Wild},
  booktitle = {CVPR},
  Year      = {2014}
  }

  @article{netzer2011reading,
  title={Reading digits in natural images with unsupervised feature learning},
  author={Netzer, Yuval and Wang, Tao and Coates, Adam and Bissacco, Alessandro and Wu, Bo and Ng, Andrew Y},
  year={2011}
}

@inproceedings{arnab2021vivit,
  title={Vivit: A video vision transformer},
  author={Arnab, Anurag and Dehghani, Mostafa and Heigold, Georg and Sun, Chen and Lu{\v{c}}i{\'c}, Mario and Schmid, Cordelia},
  booktitle={ICCV},
  year={2021}
}

@inproceedings{chen2021crossvit,
  title={Crossvit: Cross-attention multi-scale vision transformer for image classification},
  author={Chen, Chun-Fu Richard and Fan, Quanfu and Panda, Rameswar},
  booktitle={ICCV},
  year={2021}
}

@inproceedings{wang2021pyramid,
  title={Pyramid vision transformer: A versatile backbone for dense prediction without convolutions},
  author={Wang, Wenhai and Xie, Enze and Li, Xiang and Fan, Deng-Ping and Song, Kaitao and Liang, Ding and Lu, Tong and Luo, Ping and Shao, Ling},
  booktitle={ICCV},
  year={2021}
}

@article{innes2019differentiable,
  title={A differentiable programming system to bridge machine learning and scientific computing},
  author={Innes, Mike and Edelman, Alan and Fischer, Keno and Rackauckas, Chris and Saba, Elliot and Shah, Viral B and Tebbutt, Will},
  journal={arXiv preprint arXiv:1907.07587},
  year={2019}
}

@article{sanh2019distilbert,
  title={DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter},
  author={Sanh, Victor and Debut, Lysandre and Chaumond, Julien and Wolf, Thomas},
  journal={arXiv preprint arXiv:1910.01108},
  year={2019}
}

@inproceedings{you2019large,
  title={Large batch optimization for deep learning: Training bert in 76 minutes},
  author={You, Yang and Li, Jing and Reddi, Sashank and Hseu, Jonathan and Kumar, Sanjiv and Bhojanapalli, Srinadh and Song, Xiaodan and Demmel, James and Keutzer, Kurt and Hsieh, Cho-Jui},
  booktitle={ICLR},
  year={2020}
}

@inproceedings{guo2020parameter,
  title={Parameter-efficient transfer learning with diff pruning},
  author={Guo, Demi and Rush, Alexander M and Kim, Yoon},
  booktitle={ICML},
  year={2021}
}

@inproceedings{kaiser2017one,
  title={One model to learn them all},
  author={Kaiser, Lukasz and Gomez, Aidan N and Shazeer, Noam and Vaswani, Ashish and Parmar, Niki and Jones, Llion and Uszkoreit, Jakob},
  booktitle={ICML},
  year={2017}
}

@misc{diabetic-retinopathy-detection,
    author={Emma Dugas, Jared Jorge, Will Cukierski},
    title = {Diabetic Retinopathy Detection},
    publisher = {Kaggle},
    year = {2015},
    url = {https://kaggle.com/competitions/diabetic-retinopathy-detection}
}

@inproceedings{li2021improved,
  title={MViTv2: Improved multiscale vision transformers for classification and detection},
  author={Li, Yanghao and Wu, Chao-Yuan and Fan, Haoqi and Mangalam, Karttikeya and Xiong, Bo and Malik, Jitendra and Feichtenhofer, Christoph},
  booktitle={CVPR},
  year={2022}
}

@inproceedings{riquelme2021scaling,
  title={Scaling vision with sparse mixture of experts},
  author={Riquelme, Carlos and Puigcerver, Joan and Mustafa, Basil and Neumann, Maxim and Jenatton, Rodolphe and Susano Pinto, Andr{\'e} and Keysers, Daniel and Houlsby, Neil},
  booktitle={NeurIPS},
  year={2021}
}

@inproceedings{zhai2022scaling,
  title={Scaling vision transformers},
  author={Zhai, Xiaohua and Kolesnikov, Alexander and Houlsby, Neil and Beyer, Lucas},
  booktitle={CVPR},
  year={2022}
}

@inproceedings{parkhi2012cats,
  title={Cats and dogs},
  author={Parkhi, Omkar M and Vedaldi, Andrea and Zisserman, Andrew and Jawahar, CV},
  booktitle={CVPR},
  year={2012}
}

@inproceedings{nabirds,
  author={Van Horn, Grant and Branson, Steve and Farrell, Ryan and Haber, Scott and Barry, Jessie and Ipeirotis, Panos and Perona, Pietro and Belongie, Serge},
  booktitle={CVPR}, 
  title={Building a bird recognition app and large scale dataset with citizen scientists: The fine print in fine-grained dataset collection}, 
  year={2015}}

@inproceedings{tan2022enhancing,
  title={Enhancing recommendation with automated tag taxonomy construction in hyperbolic space},
  author={Tan, Yanchao and Yang, Carl and Wei, Xiangyu and Chen, Chaochao and Li, Longfei and Zheng, Xiaolin},
  booktitle={ICDE},
  year={2022}
}

@inproceedings{nickel2017poincare,
  title={Poincar{\'e} embeddings for learning hierarchical representations},
  author={Nickel, Maximillian and Kiela, Douwe},
  booktitle={NeurIPS},
  year={2017}
}

@inproceedings{nickel2018learning,
  title={Learning continuous hierarchies in the lorentz model of hyperbolic geometry},
  author={Nickel, Maximillian and Kiela, Douwe},
  booktitle={ICML},
  year={2018}
}

@inproceedings{fang2021kernel,
  title={Kernel methods in hyperbolic spaces},
  author={Fang, Pengfei and Harandi, Mehrtash and Petersson, Lars},
  booktitle={CVPR},
  year={2021}
}

@inproceedings{gao2021curvature,
  title={Curvature generation in curved spaces for few-shot learning},
  author={Gao, Zhi and Wu, Yuwei and Jia, Yunde and Harandi, Mehrtash},
  booktitle={ICCV},
  year={2021}
}

@inproceedings{liu2020hyperbolic,
  title={Hyperbolic visual embedding learning for zero-shot recognition},
  author={Liu, Shaoteng and Chen, Jingjing and Pan, Liangming and Ngo, Chong-Wah and Chua, Tat-Seng and Jiang, Yu-Gang},
  booktitle={CVPR},
  year={2020}
}

@article{rudin2019stop,
  title={Stop explaining black box machine learning models for high stakes decisions and use interpretable models instead},
  author={Rudin, Cynthia},
  journal={Nature Machine Intelligence},
  volume={1},
  number={5},
  pages={206--215},
  year={2019},
}

@article{rudin2022interpretable,
  title={Interpretable machine learning: Fundamental principles and 10 grand challenges},
  author={Rudin, Cynthia and Chen, Chaofan and Chen, Zhi and Huang, Haiyang and Semenova, Lesia and Zhong, Chudi},
  journal={Statistic Surveys},
  volume={16},
  pages={1--85},
  year={2022}
}

@inproceedings{laugel2019dangers,
  title={The dangers of post-hoc interpretability: Unjustified counterfactual explanations},
  author={Laugel, Thibault and Lesot, Marie-Jeanne and Marsala, Christophe and Renard, Xavier and Detyniecki, Marcin},
  booktitle={IJCAI},
  year={2019}
}

@article{arrieta2020explainable,
  title={Explainable Artificial Intelligence (XAI): Concepts, taxonomies, opportunities and challenges toward responsible AI},
  author={Arrieta, Alejandro Barredo and D{\'\i}az-Rodr{\'\i}guez, Natalia and Del Ser, Javier and Bennetot, Adrien and Tabik, Siham and Barbado, Alberto and Garc{\'\i}a, Salvador and Gil-L{\'o}pez, Sergio and Molina, Daniel and Benjamins, Richard and others},
  journal={Information Fusion},
  volume={58},
  pages={82--115},
  year={2020},
}

@article{biehl2016prototype,
  title={Prototype-based models in machine learning},
  author={Biehl, Michael and Hammer, Barbara and Villmann, Thomas},
  journal={Wiley Interdisciplinary Reviews: Cognitive Science},
  volume={7},
  number={2},
  pages={92--111},
  year={2016}
}

@inproceedings{liu2021sg,
  title={Sg-net: Spatial granularity network for one-stage video instance segmentation},
  author={Liu, Dongfang and Cui, Yiming and Tan, Wenbo and Chen, Yingjie},
  booktitle={CVPR},
  year={2021}
}

@article{liu2020video,
  title={Video object detection for autonomous driving: Motion-aid feature calibration},
  author={Liu, Dongfang and Cui, Yiming and Chen, Yingjie and Zhang, Jiyong and Fan, Bin},
  journal={Neurocomputing},
  volume={409},
  pages={1--11},
  year={2020}
}

@inproceedings{yang2023mixpave,
  title={MixPAVE: Mix-Prompt Tuning for Few-shot Product Attribute Value Extraction},
  author={Yang, Li and Wang, Qifan and Wang, Jingang and Quan, Xiaojun and Feng, Fuli and Chen, Yu and Khabsa, Madian and Wang, Sinong and Xu, Zenglin and Liu, Dongfang},
  booktitle={ACL},
  year={2023}
}

@inproceedings{lu2023transflow,
  title={Transflow: Transformer as flow learner},
  author={Lu, Yawen and Wang, Qifan and Ma, Siqi and Geng, Tong and Chen, Yingjie Victor and Chen, Huaijin and Liu, Dongfang},
  booktitle={CVPR},
  year={2023}
}

@article{liang2023clustseg,
  title={CLUSTSEG: Clustering for Universal Segmentation},
  author={Liang, James and Zhou, Tianfei and Liu, Dongfang and Wang, Wenguan},
  journal={arXiv preprint arXiv:2305.02187},
  year={2023}
}

@inproceedings{wang2022learning,
  title={Learning equivariant segmentation with instance-unique querying},
  author={Wang, Wenguan and Liang, James and Liu, Dongfang},
  booktitle={NeurIPS},
  year={2022}
}

@inproceedings{wang2022visual,
  title={Visual recognition with deep nearest centroids},
  author={Wang, Wenguan and Han, Cheng and Zhou, Tianfei and Liu, Dongfang},
  booktitle={ICLR},
  year={2022}
}