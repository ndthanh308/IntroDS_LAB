%!TEX root = ../main.tex

\section{Challenges of automated insect monitoring}
\label{sec:challenges}

As we worked with the images captured by our \emph{moth~scanner}, we faced some challenges that may interest others.
First, we obtained many images in a short period, and each image contains many insects of different sizes.
Annotating this huge amount of gathered data is very time-consuming.
Especially the manual species identification that requires expert knowledge is still ongoing, even though we use an annotation tool that supports with automatically inferred suggestions.
We further encountered typical challenges in real-world datasets like a long-tailed species distribution.

In our experiments, we also observed that current state-of-the-art detection models have problems with detecting tiny objects, as mentioned in Sect.~\ref{sub:detection_results}.
Although the uniform background might suggest that insect detection is an easy task in this scenario, fallen leaves and dirt on the surface and the large variability of insect sizes pose further challenges.
In contrast to the images recorded by citizen scientists with hand-held cameras that can focus on individual resting insects, automatically captured images of the light-based camera trap also contain motion blur and insects flying around that also (partially) occlude others.


Finally, the most challenging task is to perform the detection directly at the \emph{moth~scanner} (edge computing).
As mentioned previously in Sect.~\ref{sec:methods}, we plan to operate the camera traps autonomously in the field.
To reduce the amount of transmitted data, it is desirable to transfer only the small image patches instead of the entire image.
Unfortunately, this implies that current CNN-based state-of-the-art detection methods cannot be deployed on the hardware of the \emph{moth~scanner} with limited computational power and restricted energy budgets.
Hence, we will need to consider detection methods based on basic computer vision algorithms, like the blob detector presented by Bjerge~\etal~\cite{bjerge2021automated}.

\section{Conclusions}
\label{sec:conclusions}
In this paper, we presented a prototype of an automatic light-based camera trap for monitoring nocturnal insects.
The so-called \emph{moth~scanner} allows for capturing large-scale image datasets that can be used for moth localization and fine-grained species recognition.
Hence, this application domain can become an important area for research on fine-grained recognition with a large impact on ecology.
Besides the presented datasets, we also provided baseline results of a two-stage pipeline for detecting and classifying insects in images.

%In the context of the AMMOD project, the camera trap, also called \emph{moth~scanner}, will be used to observe the population trends of moths.
%The moth scanner consists of a camera that automatically takes images of an illuminated white surface, on which the attracted insects rest.

%In preliminary work, we used a manually collected dataset to develop and evaluate a two-stage pipeline for detecting and classifying insects in images captured by the moth scanner.
%This dataset contains approximately \num{2200} images of \num{200} moth species and bounding box annotations for all images.

%After the operation of the prototype for five months, we gathered more than \num{27000} images.
%For bootstrapping and evaluation purposes, we annotated \num{834} images with bounding boxes locating the insects in the images.

%Finally, we presented first baseline results and enlisted challenges we faced while working with the data.
