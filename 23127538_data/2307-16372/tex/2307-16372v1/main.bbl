% Generated by IEEEtran.bst, version: 1.14 (2015/08/26)
\begin{thebibliography}{10}
\providecommand{\url}[1]{#1}
\csname url@samestyle\endcsname
\providecommand{\newblock}{\relax}
\providecommand{\bibinfo}[2]{#2}
\providecommand{\BIBentrySTDinterwordspacing}{\spaceskip=0pt\relax}
\providecommand{\BIBentryALTinterwordstretchfactor}{4}
\providecommand{\BIBentryALTinterwordspacing}{\spaceskip=\fontdimen2\font plus
\BIBentryALTinterwordstretchfactor\fontdimen3\font minus
  \fontdimen4\font\relax}
\providecommand{\BIBforeignlanguage}[2]{{%
\expandafter\ifx\csname l@#1\endcsname\relax
\typeout{** WARNING: IEEEtran.bst: No hyphenation pattern has been}%
\typeout{** loaded for the language `#1'. Using the pattern for}%
\typeout{** the default language instead.}%
\else
\language=\csname l@#1\endcsname
\fi
#2}}
\providecommand{\BIBdecl}{\relax}
\BIBdecl

\bibitem{manco2021muscaps}
I.~Manco, E.~Benetos, E.~Quinton, and G.~Fazekas, ``Muscaps: Generating
  captions for music audio,'' in \emph{International Joint Conference on Neural
  Networks (IJCNN)}.\hskip 1em plus 0.5em minus 0.4em\relax IEEE, 2021.

\bibitem{cai2020music}
T.~Cai, M.~I. Mandel, and D.~He, ``Music autotagging as captioning,'' in
  \emph{Proceedings of the 1st Workshop on NLP for Music and Audio (NLP4MusA)},
  2020.

\bibitem{choi2016towards}
K.~Choi, G.~Fazekas, B.~McFee, K.~Cho, and M.~Sandler, ``Towards music
  captioning: Generating music playlist descriptions,'' in \emph{International
  Society for Music Information Retrieval Conference (ISMIR),
  Late-Breaking/Demo}, 2016.

\bibitem{doh2021music}
S.~Doh, J.~Lee, and J.~Nam, ``Music playlist title generation: A
  machine-translation approach,'' in \emph{Proceedings of the 2nd Workshop on
  NLP for Music and Spoken Audio (NLP4MuSA)}, 2021.

\bibitem{gabbolini2022data}
G.~Gabbolini, R.~Hennequin, and E.~Epure, ``Data-efficient playlist captioning
  with musical and linguistic knowledge,'' in \emph{Proceedings of the 2022
  Conference on Empirical Methods in Natural Language Processing (EMNLP)},
  2022.

\bibitem{kim2023music}
H.~Kim, S.~Doh, J.~Lee, and J.~Nam, ``Music playlist title generation using
  artist information,'' in \emph{Proceedings of the AAAI-23 Workshop on
  Creative AI Across Modalities}, 2023.

\bibitem{bahdanau2014neural}
D.~Bahdanau, K.~Cho, and Y.~Bengio, ``Neural machine translation by jointly
  learning to align and translate,'' in \emph{Proceedings of the International
  Conference on Learning Representations (ICLR)}, 2014.

\bibitem{won2020data}
M.~Won, S.~Chun, O.~Nieto, and X.~Serrc, ``Data-driven harmonic filters for
  audio representation learning,'' in \emph{ICASSP 2020-2020 IEEE International
  Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 2020.

\bibitem{brown2020language}
T.~Brown, B.~Mann, N.~Ryder, M.~Subbiah, J.~D. Kaplan, P.~Dhariwal,
  A.~Neelakantan, P.~Shyam, G.~Sastry, A.~Askell \emph{et~al.}, ``Language
  models are few-shot learners,'' in \emph{Proceedings of the Advances in
  neural information processing systems (NeurIPS)}, 2020.

\bibitem{huang2022mulan}
Q.~Huang, A.~Jansen, J.~Lee, R.~Ganti, J.~Y. Li, and D.~P. Ellis, ``Mu{L}an: A
  joint embedding of music audio and natural language,'' in \emph{International
  Conference on Music Information Retrieval (ISMIR)}, 2022.

\bibitem{manco2022song}
I.~Manco, B.~Weck, P.~Tovstogan, M.~Won, and D.~Bogdanov, ``Song describer: a
  platform for collecting textual descriptions of music recordings,'' in
  \emph{International Conference on Music Information Retrieval (ISMIR),
  Late-Breaking/Demo session}, 2022.

\bibitem{agostinelli2023musiclm}
A.~Agostinelli, T.~I. Denk, Z.~Borsos, J.~Engel, M.~Verzetti, A.~Caillon,
  Q.~Huang, A.~Jansen, A.~Roberts, M.~Tagliasacchi \emph{et~al.}, ``Music{LM}:
  Generating music from text,'' \emph{arXiv preprint arXiv:2301.11325}, 2023.

\bibitem{doh2022toward}
S.~Doh, M.~Won, K.~Choi, and J.~Nam, ``Toward universal text-to-music
  retrieval,'' in \emph{IEEE International Conference on Acoustics, Speech and
  Signal Processing (ICASSP)}, 2023.

\bibitem{chen2022learning}
T.~Chen, Y.~Xie, S.~Zhang, S.~Huang, H.~Zhou, and J.~Li, ``Learning music
  sequence representation from text supervision,'' in \emph{IEEE International
  Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 2022.

\bibitem{choi2017effects}
K.~Choi, G.~Fazekas, K.~Cho, and M.~Sandler, ``The effects of noisy labels on
  deep convolutional neural networks for music tagging,'' \emph{IEEE
  Transactions on Emerging Topics in Computational Intelligence}, 2018.

\bibitem{10.5555/3455716.3455856}
C.~Raffel, N.~Shazeer, A.~Roberts, K.~Lee, S.~Narang, M.~Matena, Y.~Zhou,
  W.~Li, and P.~J. Liu, ``Exploring the limits of transfer learning with a
  unified text-to-text transformer,'' \emph{J. Mach. Learn. Res.}, vol.~21,
  no.~1, jan 2020.

\bibitem{gao2020pile}
L.~Gao, S.~Biderman, S.~Black, L.~Golding, T.~Hoppe, C.~Foster, J.~Phang,
  H.~He, A.~Thite, N.~Nabeshima, S.~Presser, and C.~Leahy, ``The pile: An 800gb
  dataset of diverse text for language modeling,'' 2020.

\bibitem{mei2023wavcaps}
X.~Mei, C.~Meng, H.~Liu, Q.~Kong, T.~Ko, C.~Zhao, M.~D. Plumbley, Y.~Zou, and
  W.~Wang, ``Wav{C}aps: A {C}hat{GPT}-assisted weakly-labelled audio captioning
  dataset for audio-language multimodal research,'' \emph{arXiv preprint
  arXiv:2303.17395}, 2023.

\bibitem{huang2023noise2music}
Q.~Huang, D.~S. Park, T.~Wang, T.~I. Denk, A.~Ly, N.~Chen, Z.~Zhang, Z.~Zhang,
  J.~Yu, C.~Frank \emph{et~al.}, ``Noise2music: Text-conditioned music
  generation with diffusion models,'' \emph{arXiv preprint arXiv:2302.03917},
  2023.

\bibitem{gilardi2023chatgpt}
F.~Gilardi, M.~Alizadeh, and M.~Kubli, ``Chat{GPT} outperforms crowd-workers
  for text-annotation tasks,'' \emph{arXiv preprint arXiv:2303.15056}, 2023.

\bibitem{thoppilan2022lamda}
R.~Thoppilan, D.~De~Freitas, J.~Hall, N.~Shazeer, A.~Kulshreshtha, H.-T. Cheng,
  A.~Jin, T.~Bos, L.~Baker, Y.~Du \emph{et~al.}, ``Lamda: Language models for
  dialog applications,'' \emph{arXiv preprint arXiv:2201.08239}, 2022.

\bibitem{wu2022large}
Y.~Wu, K.~Chen, T.~Zhang, Y.~Hui, T.~Berg-Kirkpatrick, and S.~Dubnov,
  ``Large-scale contrastive language-audio pretraining with feature fusion and
  keyword-to-caption augmentation,'' in \emph{IEEE International Conference on
  Acoustics, Speech and Signal Processing (ICASSP)}, 2023.

\bibitem{ouyang2022training}
L.~Ouyang, J.~Wu, X.~Jiang, D.~Almeida, C.~Wainwright, P.~Mishkin, C.~Zhang,
  S.~Agarwal, K.~Slama, A.~Ray \emph{et~al.}, ``Training language models to
  follow instructions with human feedback,'' in \emph{Proceedings of the
  Advances in neural information processing systems (NeurIPS)}, 2022.

\bibitem{christiano2017deep}
P.~F. Christiano, J.~Leike, T.~Brown, M.~Martic, S.~Legg, and D.~Amodei, ``Deep
  reinforcement learning from human preferences,'' in \emph{Proceedings of the
  Advances in neural information processing systems (NeurIPS)}, 2017.

\bibitem{Ji_2023}
Z.~Ji, N.~Lee, R.~Frieske, T.~Yu, D.~Su, Y.~Xu, E.~Ishii, Y.~J. Bang,
  A.~Madotto, and P.~Fung, ``Survey of hallucination in natural language
  generation,'' \emph{{ACM} Computing Surveys}, 2023.

\bibitem{papineni2002bleu}
K.~Papineni, S.~Roukos, T.~Ward, and W.-J. Zhu, ``Bleu: a method for automatic
  evaluation of machine translation,'' in \emph{Proceedings of the 40th annual
  meeting of the Association for Computational Linguistics (ACL)}, 2002.

\bibitem{banerjee2005meteor}
S.~Banerjee and A.~Lavie, ``Meteor: An automatic metric for mt evaluation with
  improved correlation with human judgments,'' in \emph{Proceedings of the ACL
  workshop on intrinsic and extrinsic evaluation measures for machine
  translation and/or summarization}, 2005.

\bibitem{lin2004rouge}
C.-Y. Lin, ``Rouge: A package for automatic evaluation of summaries,'' in
  \emph{Text summarization branches out}, 2004.

\bibitem{zhang2019bertscore}
T.~Zhang, V.~Kishore, F.~Wu, K.~Q. Weinberger, and Y.~Artzi, ``Bertscore:
  Evaluating text generation with bert,'' in \emph{International Conference on
  Learning Representations (ICLR)}, 2020.

\bibitem{kim2019audiocaps}
C.~D. Kim, B.~Kim, H.~Lee, and G.~Kim, ``Audio{C}aps: Generating captions for
  audios in the wild,'' in \emph{Proceedings of the 2019 Conference of the
  North American Chapter of the Association for Computational Linguistics:
  Human Language Technologies}, 2019.

\bibitem{law2009evaluation}
E.~Law, K.~West, M.~I. Mandel, M.~Bay, and J.~S. Downie, ``Evaluation of
  algorithms using games: The case of music tagging.'' in \emph{International
  Conference on Music Information Retrieval (ISMIR)}, 2009.

\bibitem{bertin2011million}
T.~Bertin-Mahieux, D.~P. Ellis, B.~Whitman, and P.~Lamere, ``The million song
  dataset,'' in \emph{International Conference on Music Information Retrieval
  (ISMIR)}, 2011.

\bibitem{lewis2019bart}
M.~Lewis, Y.~Liu, N.~Goyal, M.~Ghazvininejad, A.~Mohamed, O.~Levy, V.~Stoyanov,
  and L.~Zettlemoyer, ``Bart: Denoising sequence-to-sequence pre-training for
  natural language generation, translation, and comprehension,'' in
  \emph{Proceedings of the 58th Annual Meeting of the Association for
  Computational Linguistics (ACL)}, 2020.

\bibitem{zhang2022interpreting}
Y.~Zhang, J.~Jiang, G.~Xia, and S.~Dixon, ``Interpreting song lyrics with an
  audio-informed pre-trained language model,'' in \emph{International
  Conference on Music Information Retrieval (ISMIR)}, 2022.

\bibitem{radford2022robust}
A.~Radford, J.~W. Kim, T.~Xu, G.~Brockman, C.~McLeavey, and I.~Sutskever,
  ``Robust speech recognition via large-scale weak supervision,'' \emph{arXiv
  preprint arXiv:2212.04356}, 2022.

\bibitem{hendrycks2016gaussian}
D.~Hendrycks and K.~Gimpel, ``Gaussian error linear units ({GELU}s),''
  \emph{arXiv preprint arXiv:1606.08415}, 2016.

\bibitem{stefanini2022show}
M.~Stefanini, M.~Cornia, L.~Baraldi, S.~Cascianelli, G.~Fiameni, and
  R.~Cucchiara, ``From show to tell: a survey on deep learning-based image
  captioning,'' \emph{IEEE transactions on pattern analysis and machine
  intelligence}, 2022.

\bibitem{won2021multimodal}
M.~Won, S.~Oramas, O.~Nieto, F.~Gouyon, and X.~Serra, ``Multimodal metric
  learning for tag-based music retrieval,'' in \emph{ICASSP 2021-2021 IEEE
  International Conference on Acoustics, Speech and Signal Processing
  (ICASSP)}, 2021.

\end{thebibliography}
