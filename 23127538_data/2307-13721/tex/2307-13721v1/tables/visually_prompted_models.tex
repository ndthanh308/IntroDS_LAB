\begin{table*}[t]
	\centering\setlength{\tabcolsep}{10pt}
			\resizebox{1\textwidth}{!}{
			\begin{tabular}{clccccx{5cm}x{5cm}}
				\toprule
				\textbf{Type} & \textbf{Foundational Model} &  
                    \textbf{Public} & \textbf{[\url{Link}]}  & \textbf{Prompts} & \textbf{Training} & \textbf{Data Type} & \textbf{Data Size}\\
                \toprule
                \multirow{45}{*}{\rotatebox{90}{\shortstack{Visually Prompted Models}}} & CLIPSeg \cite{luddecke2022image} & \cmark & \href{https://github.com/timojl/clipseg}{Link} & Text, Image & \cmark & PhraseCut \cite{wu2020phrasecut} & 0.34M Images\\
                \cmidrule{2-8}
                &  SegGPT \cite{wang2023seggpt} & \cmark & \href{https://github.com/baaivision/Painter/tree/main/SegGPT}{Link} & Learnable Image Prompt & \cmark & Curation of Twelve Modalities  \cite{wang2023seggpt} & $\approx$ 0.3M Images\\
                \cmidrule{2-8}
                &  SAM \cite{kirillov2023segment} & \cmark & \href{https://github.com/facebookresearch/segment-anything}{Link}& Points, Box, Text & \cmark & SA-1B \cite{kirillov2023segment} & 11M Images, 1.1B Masks\\
                \cmidrule{2-8}
                &  SEEM \cite{zou2023segment} & \cmark & \href{https://github.com/UX-Decoder/Segment-Everything-Everywhere-All-At-Once}{Link} & Text, Points, Scribbles, Boxes, Images & \cmark & COCO \cite{lin2014microsoft} & 118K Images\\
                \cmidrule{2-8}
                &  CAT \cite{wang2023caption} & \cmark & \href{Caption
anything: Interactive image description with diverse mul-
timodal control}{Link} & Text, Points, Boxes, Mask & \xmark & -- & -- \\
                \cmidrule{2-8}
                &  TAM \cite{yang2023track} & \cmark & \href{https://github.com/gaomingqi/Track-Anything}{Link} & Points, Boxes, Clicks & \xmark & -- & -- \\
                \cmidrule{2-8}
                &  SAM-Track \cite{cheng2023segment} & \cmark & \href{https://github.com/z-x-yang/Segment-and-Track-Anything}{Link} & Text & \xmark & --& -- \\
                \cmidrule{2-8}
                &  SAM-PT \cite{sam-pt} & \cmark & \href{https://github.com/SysCV/sam-pt}{Link} & Points & \xmark & --& -- \\
                \cmidrule{2-8}
                &  SAM-DA \cite{sam_da} & \cmark & \href{https://github.com/vision4robotics/SAM-DA}{Link} & Boxes & \cmark & NAT2021 \cite{ye2022unsupervised}  & 0.27M Images \\
                \cmidrule{2-8}
                &  RsPrompter \cite{chen2023rsprompter} & \cmark & \href{https://github.com/KyanChen/RSPrompter}{Link} & Learnable Prompter & \cmark & WHU  \cite{ji2018fully}, NWPU \cite{cheng2014multi}, and SSDD \cite{zhang2021sar} & $\approx$ 6.6K Images\\
                \cmidrule{2-8}
                & MedSAM \cite{ma2023segment} & \cmark & \href{https://github.com/bowang-lab/MedSAM}{Link} & Boxes & \cmark & Curation of Eleven Modalities \cite{ma2023segment} & 200k Masks  \\
                \cmidrule{2-8}
                &  AutoSAM \cite{shaharabany2023autosam} & \xmark & -- & Learnable Prompt &  \cmark & MoNuSeg \cite{kumar2019multi}, GlaS \cite{sirinukunwattana2017gland}, Polyp \cite{jha2020kvasir, bernal2015wm, tajbakhsh2015automated, silva2014toward}, Sun-Seg \cite{ji2022video} & $\approx$ 1.5K Images, 1.1K Videos\\
                \cmidrule{2-8}
                & DSAM-adapter \cite{Gong20233DSAMadapterHA} & \cmark & \href{https://github.com/med-air/3DSAM-adapter}{Link}& Points &  \cmark & KiTS21 \cite{heller2021state}, LiTS17 \cite{bilic2023liver}, Pancreas \cite{antonelli2022medical}, Colon \cite{antonelli2022medical}   & $\approx$ 600 CT scans \\
                \cmidrule{2-8}
                &  DeSAM \cite{gao2023desam} & \cmark & \href{https://github.com/yifangao112/DeSAM}{Link} & Points, Boxes & \cmark & Prostate datasets (NCI-ISBI, I2CVB,  PROMISE12) \cite{gao2023desam} &   --   \\
                \cmidrule{2-8}
                &  MedLAM \cite{Lei2023medlam} & \cmark & \href{https://github.com/openmedlab/MedLSAM}{Link} & Boxes & \cmark & Curation of Sixteen Modalities  \cite{Lei2023medlam}  & $\approx$ 14l CT Sans\\
                \cmidrule{2-8}
                &  FasterSAM \cite{zhang2023faster} & \cmark & \href{https://github.com/ChaoningZhang/MobileSAM}{Link} & Points, Box, Text & \cmark & Subset of SA-1B \cite{kirillov2023segment} & 11K Images   \\
                \cmidrule{2-8}
                &  Fast Segment \cite{zhao2023fast} & \cmark & \href{https://github.com/CASIA-IVA-Lab/FastSAM}{Link} &  Points, Box, Text & \cmark & Subset of SA-1B \cite{kirillov2023segment} & 22K Images  \\
                \cmidrule{2-8}
                &  RefSAM \cite{refsam} & \cmark & \href{https://github.com/LancasterLi/RefSAM}{Link}& Points, Boxes &\cmark & Ref-Youtu-VOS \cite{seo2020urvos}, Ref-DAVIS17 \cite{khoreva2019video} & $\approx$ 4k Videos\\
                \cmidrule{2-8}
                &  Painter \cite{wang2023images} & \cmark & \href{https://github.com/baaivision/Painter/tree/main/Painter}{Link} & Task-specific Prompts & \cmark & NYUv2 \cite{silberman2012indoor}, ADE20K \cite{zhou2019semantic}, COCO \cite{lin2014microsoft}, SIDD \cite{abdelhamed2018high}, LOL \cite{wei2018deep} & $\approx$ 162K Images \\
                \cmidrule{2-8}
                &  VisionLLM \cite{wang2023visionllm} & \cmark & \href{https://github.com/OpenGVLab/VisionLLM}{Link} & Task Descriptions and Categories & \cmark &  COCO \cite{lin2014microsoft}, RefCOCO+ \cite{yu2016modeling}, RefCOCOg \cite{mao2016generation} & 238K Images \\
                \cmidrule{2-8}
                &  Prismer \cite{liu2023prismer} & \cmark & \href{https://github.com/NVlabs/prismer}{Link} & Text & \cmark & COCO \cite{lin2014microsoft}, Visual Genome \cite{krishna2017visual}, Captions \cite{sharma2018conceptual}, SBU-captions \cite{ordonez2011im2text}, Conceptual12M \cite{changpinyo2021conceptual} & 11M Images, 12.7M (Image, Text) \\
                \midrule
                \multirow{6}{*}{\rotatebox{90}{\shortstack{Heterogeneous Modalities \\ based Models}}} &  CLIP2Video \cite{fang2021clip2video} & \cmark & \href{https://github.com/CryhanFang/CLIP2Video}{Link} &  Text & \cmark & MSR-VTT \cite{xu2016msr}, MSVD \cite{chen2011collecting}, VATEX \cite{wang2019vatex} & $\approx$ 33.7K Videos \\
                \cmidrule{2-8}
                &  AudioCLIP \cite{guzhov2021audioclip} & \cmark & \href{https://github.com/AndreyGuzhov/AudioCLIP}{Link} & Text, Audio & \cmark & AudioSet \cite{gemmeke2017audio} & 1.8M (Video, Audio)  \\
                \cmidrule{2-8}
                &  Image Bind \cite{girdhar2023imagebind} & \cmark & \href{https://github.com/facebookresearch/ImageBind}{Link} & Text, Depth, Audio, Thermal & \cmark & Audioset \cite{gemmeke2017audio},  SUN RGB-D \cite{song2015sun}, LLVIP \cite{jia2021llvip},  Ego4D \cite{grauman2022ego4d} &   1.8M (Video, Audio),  10.3K (Image, Depth), 15.4K (Image, Thermal),  3,670 hours of (Video, IMU) \\
                \cmidrule{2-8}
                &  MACAW-LLM  \cite{Macaw-LLM} & \cmark & \href{https://github.com/lyuchenyang/Macaw-LLM}{Link} & Text generated using GPT4  & \cmark & Multi-turn Dialogue & 69K (Image, Text), 50k (Video, Text) \\
                \cmidrule{2-8}
                &  COSA  \cite{chen2023cosa} & \cmark & \href{https://github.com/TXH-mercury/COSA}{Link} & Text & \cmark & CC14M \cite{chen2023cosa}, LAION \cite{schuhmann2021laion}, WebVid \cite{wang2022object} & From 5M to 514M (Image, Text)  \\
                \cmidrule{2-8}
                &  Valley \cite{luo2023valley} & \cmark & \href{https://github.com/RupertLuo/Valley}{Link} & Text generated using ChatGPT & \cmark & Video Conversation and QA \cite{luo2023valley} & 42K Conversations and 5.8K QA about Videos \\
				\midrule
                \multirow{5}{*}{\rotatebox{90}{\shortstack{Embodied Foundational \\ Agents}}} & Palm-E \cite{driess2023palme} & \xmark & -- & Multi-modal (Image, Text) & \cmark & Language-Table \cite{lynch2022interactive}, SayCan \cite{ahn2022can} &  Pushing Dynamics, Tasks in a Kitchen Environment,\\
                \cmidrule{2-8}
                &  ViMA \cite{jiang2022vima} & \cmark & \href{https://github.com/vimalabs/VIMA}{Link} & Multi-modal (Image, Text) & \cmark & VIMA-BENCH \cite{jiang2022vima} & 600K+ expert trajectories for learning\\
                \cmidrule{2-8}
                &  MineDojo \cite{fan2022minedojo} & \cmark & \href{https://github.com/MineDojo/MineDojo}{Link} & Text & \cmark &  Data collected from Minecraft & 730k Videos, 6k Transcripts, 340K Reddit Posts \\
                \cmidrule{2-8}
                &  VOYAGER \cite{wang2023voyager} & \cmark & \href{https://github.com/MineDojo/Voyager}{Link} & Iterative Prompting with Feedback & \cmark & Collected from within Minecraft & Minecraft items, Library storing behavior \\
                \cmidrule{2-8}
                &  LM-Nav \cite{shah2022lmnav} & \cmark & \href{https://github.com/blazejosinski/lm_nav}{Link} & LandMarks, Text & \xmark & -- & -- \\
			\bottomrule
		\end{tabular}}
		\vspace{0.3em}
	\caption{A summary of publicly available information about visually prompted, heterogeneous modality-based models and embodied foundational agents, their prompt design differences, and the nature of their training data type and size.}%\vspace{-1em}
    \label{tab:visually_prompted_models_insights}
\end{table*}