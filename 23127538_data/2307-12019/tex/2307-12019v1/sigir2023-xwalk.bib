@article{vaswani2017,
  author    = {Ashish Vaswani and
               Noam Shazeer and
               Niki Parmar and
               Jakob Uszkoreit and
               Llion Jones and
               Aidan N. Gomez and
               Lukasz Kaiser and
               Illia Polosukhin},
  title     = {Attention Is All You Need},
  journal   = {CoRR},
  volume    = {abs/1706.03762},
  year      = {2017},
  url       = {http://arxiv.org/abs/1706.03762},
  eprinttype = {arXiv},
  eprint    = {1706.03762},
  timestamp = {Sat, 23 Jan 2021 01:20:40 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/VaswaniSPUJGKP17.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{nigam2019,
  author    = {Priyanka Nigam and
               Yiwei Song and
               Vijai Mohan and
               Vihan Lakshman and
               Weitian Ding and
               Ankit Shingavi and
               Choon Hui Teo and
               Hao Gu and
               Bing Yin},
  title     = {Semantic Product Search},
  journal   = {CoRR},
  volume    = {abs/1907.00937},
  year      = {2019},
  url       = {http://arxiv.org/abs/1907.00937},
  eprinttype = {arXiv},
  eprint    = {1907.00937},
  timestamp = {Mon, 08 Jul 2019 14:12:33 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1907-00937.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{matsakis2014rust,
  title={The rust language},
  author={Matsakis, Nicholas D and Klock II, Felix S},
  booktitle={ACM SIGAda Ada Letters},
  volume={34},
  number={3},
  pages={103--104},
  year={2014},
  organization={ACM}
}

@INPROCEEDINGS{Lin_etal_SIGIR2021_Pyserini,
   author = "Jimmy Lin and Xueguang Ma and Sheng-Chieh Lin and Jheng-Hong Yang and Ronak Pradeep and Rodrigo Nogueira",
   title = "{Pyserini}: A {Python} Toolkit for Reproducible Information Retrieval Research with Sparse and Dense Representations",
   booktitle = "Proceedings of the 44th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR 2021)",
   year = 2021,
   pages = "2356--2362",
}

@article{paudel_updatable_2016,
	title = {Updatable, {Accurate}, {Diverse}, and {Scalable} {Recommendations} for {Interactive} {Applications}},
	volume = {7},
	issn = {2160-6455},
	url = {https://doi.org/10.1145/2955101},
	doi = {10.1145/2955101},
	abstract = {Recommender systems form the backbone of many interactive systems. They incorporate user feedback to personalize the user experience typically via personalized recommendation lists. As users interact with a system, an increasing amount of data about a user’s preferences becomes available, which can be leveraged for improving the systems’ performance. Incorporating these new data into the underlying recommendation model is, however, not always straightforward. Many models used by recommender systems are computationally expensive and, therefore, have to perform offline computations to compile the recommendation lists. For interactive applications, it is desirable to be able to update the computed values as soon as new user interaction data is available: updating recommendations in interactive time using new feedback data leads to better accuracy and increases the attraction of the system to the users. Additionally, there is a growing consensus that accuracy alone is not enough and user satisfaction is also dependent on diverse recommendations. In this work, we tackle this problem of updating personalized recommendation lists for interactive applications in order to provide both accurate and diverse recommendations. To that end, we explore algorithms that exploit random walks as a sampling technique to obtain diverse recommendations without compromising on efficiency and accuracy. Specifically, we present a novel graph vertex ranking recommendation algorithm called RP3β that reranks items based on three-hop random walk transition probabilities. We show empirically that RP3β provides accurate recommendations with high long-tail item frequency at the top of the recommendation list. We also present approximate versions of RP3β and the two most accurate previously published vertex ranking algorithms based on random walk transition probabilities and show that these approximations converge with an increasing number of samples. To obtain interactively updatable recommendations, we additionally show how our algorithm can be extended for online updates at interactive speeds. The underlying random walk sampling technique makes it possible to perform the updates without having to recompute the values for the entire dataset. In an empirical evaluation with three real-world datasets, we show that RP3β provides highly accurate and diverse recommendations that can easily be updated with newly gathered information at interactive speeds (≪ 100ms).},
	number = {1},
	urldate = {2022-05-06},
	journal = {ACM Trans. Interact. Intell. Syst.},
	author = {Paudel, Bibek and Christoffel, Fabian and Newell, Chris and Bernstein, Abraham},
	month = dec,
	year = {2016},
	keywords = {bipartite graph, diversity, evolving graphs, item ranking, long-tail, random walks, Recommender systems, sampling, top-N recommendation, updating recommendations},
	pages = {1:1--1:34},
	file = {Accepted Version:/Users/ykim/Zotero/storage/7R34HD68/Paudel et al. - 2016 - Updatable, Accurate, Diverse, and Scalable Recomme.pdf:application/pdf},
}

@inproceedings{zhao_joint_2022,
	address = {Virtual Event AZ USA},
	title = {Joint {Learning} of {E}-commerce {Search} and {Recommendation} with a {Unified} {Graph} {Neural} {Network}},
	isbn = {978-1-4503-9132-0},
	url = {https://dl.acm.org/doi/10.1145/3488560.3498414},
	doi = {10.1145/3488560.3498414},
	abstract = {Click-through rate (CTR) prediction plays an important role in search and recommendation, which are the two most prominent scenarios in e-commerce. A number of models have been proposed to predict CTR by mining user behaviors, especially users’ interactions with items. But the sparseness of user behaviors is an obstacle to the improvement of CTR prediction. Previous works only focused on one scenario, either search or recommendation. However, on a practical e-commerce platform, search and recommendation share the same set of users and items, which means joint learning of both scenarios may alleviate the sparseness of user behaviors. In this paper, we propose a novel Search and Recommendation Joint Graph (SRJGraph) neural network to jointly learn a better CTR model for both scenarios. A key question of joint learning is how to e ectively share information across search and recommendation, in spite of their di erences. A notable di erence between search and recommendation is that there are explicit queries in search, whereas no query exists in recommendation. We address this difference by constructing a uni ed graph to share representations of users and items across search and recommendation, as well as represent user-item interactions uniformly. In this graph, users and items are heterogeneous nodes, and search queries are incorporated into the user-item interaction edges as attributes. For recommendation where no query exists, a special attribute is attached on user-item interaction edges. We further propose an intention and upstream-aware aggregator to explore useful information from high-order connections among users and items. We conduct extensive experiments on a large-scale dataset collected from Taobao.com, the largest e-commerce platform in China. Empirical results show that SRJGraph signi cantly outperforms the state-of-the-art approaches of CTR prediction in both search and recommendation tasks.},
	language = {en},
	urldate = {2022-05-26},
	booktitle = {Proceedings of the {Fifteenth} {ACM} {International} {Conference} on {Web} {Search} and {Data} {Mining}},
	publisher = {ACM},
	author = {Zhao, Kai and Zheng, Yukun and Zhuang, Tao and Li, Xiang and Zeng, Xiaoyi},
	month = feb,
	year = {2022},
	pages = {1461--1469},
	file = {Zhao et al. - 2022 - Joint Learning of E-commerce Search and Recommenda.pdf:/Users/ykim/Zotero/storage/8NAL7TUZ/Zhao et al. - 2022 - Joint Learning of E-commerce Search and Recommenda.pdf:application/pdf},
}

@inproceedings{zamani_learning_2020,
	address = {Houston TX USA},
	title = {Learning a {Joint} {Search} and {Recommendation} {Model} from {User}-{Item} {Interactions}},
	isbn = {978-1-4503-6822-3},
	url = {https://dl.acm.org/doi/10.1145/3336191.3371818},
	doi = {10.1145/3336191.3371818},
	language = {en},
	urldate = {2022-05-26},
	booktitle = {Proceedings of the 13th {International} {Conference} on {Web} {Search} and {Data} {Mining}},
	publisher = {ACM},
	author = {Zamani, Hamed and Croft, W. Bruce},
	month = jan,
	year = {2020},
	pages = {717--725},
	file = {Zamani and Croft - 2020 - Learning a Joint Search and Recommendation Model f.pdf:/Users/ykim/Zotero/storage/9DEJDTYQ/Zamani and Croft - 2020 - Learning a Joint Search and Recommendation Model f.pdf:application/pdf},
}

@inproceedings{jiang_learning_2016,
	address = {New York, NY, USA},
	series = {{SIGIR} '16},
	title = {Learning {Query} and {Document} {Relevance} from a {Web}-scale {Click} {Graph}},
	isbn = {978-1-4503-4069-4},
	url = {https://doi.org/10.1145/2911451.2911531},
	doi = {10.1145/2911451.2911531},
	abstract = {Click-through logs over query-document pairs provide rich and valuable information for multiple tasks in information retrieval. This paper proposes a vector propagation algorithm on the click graph to learn vector representations for both queries and documents in the same semantic space. The proposed approach incorporates both click and content information, and the produced vector representations can directly improve ranking performance for queries and documents that have been observed in the click log. For new queries and documents that are not in the click log, we propose a two-step framework to generate the vector representation, which significantly improves the coverage of our vectors while maintaining the high quality. Experiments on Web-scale search logs from a major commercial search engine demonstrate the effectiveness and scalability of the proposed method. Evaluation results show that NDCG scores are significantly improved against multiple baselines by using the proposed method both as a ranking model and as a feature in a learning-to-rank framework.},
	urldate = {2022-06-16},
	booktitle = {Proceedings of the 39th {International} {ACM} {SIGIR} conference on {Research} and {Development} in {Information} {Retrieval}},
	publisher = {Association for Computing Machinery},
	author = {Jiang, Shan and Hu, Yuening and Kang, Changsung and Daly, Tim and Yin, Dawei and Chang, Yi and Zhai, Chengxiang},
	month = jul,
	year = {2016},
	keywords = {click-through bipartite graph, query-document relevance, vector generation, vector propagation, web search},
	pages = {185--194},
	file = {Full Text PDF:/Users/ykim/Zotero/storage/P5DCRXLX/Jiang et al. - 2016 - Learning Query and Document Relevance from a Web-s.pdf:application/pdf},
}

@inproceedings{christoffel_blockbusters_2015,
	address = {New York, NY, USA},
	series = {{RecSys} '15},
	title = {Blockbusters and {Wallflowers}: {Accurate}, {Diverse}, and {Scalable} {Recommendations} with {Random} {Walks}},
	isbn = {978-1-4503-3692-5},
	shorttitle = {Blockbusters and {Wallflowers}},
	url = {https://doi.org/10.1145/2792838.2800180},
	doi = {10.1145/2792838.2800180},
	abstract = {User satisfaction is often dependent on providing accurate and diverse recommendations. In this paper, we explore scalable algorithms that exploit random walks as a sampling technique to obtain diverse recommendations without compromising on accuracy. Specifically, we present a novel graph vertex ranking recommendation algorithm called RP{\textasciicircum}3\_beta that re-ranks items based on 3-hop random walk transition probabilities. We show empirically, that RP{\textasciicircum}3\_beta provides accurate recommendations with high long-tail item frequency at the top of the recommendation list. We also present scalable approximate versions of RP{\textasciicircum}3\_beta and the two most accurate previously published vertex ranking algorithms based on random walk transition probabilities and show that these approximations converge with increasing number of samples.},
	urldate = {2023-01-13},
	booktitle = {Proceedings of the 9th {ACM} {Conference} on {Recommender} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Christoffel, Fabian and Paudel, Bibek and Newell, Chris and Bernstein, Abraham},
	month = sep,
	year = {2015},
	keywords = {bipartite graph, diversity, item ranking, long-tail, random walks, sampling, top-n recommendation},
	pages = {163--170},
	file = {Full Text PDF:/Users/ykim/Zotero/storage/PFIDLJCK/Christoffel et al. - 2015 - Blockbusters and Wallflowers Accurate, Diverse, a.pdf:application/pdf},
}

@inproceedings{eksombatchai_pixie_2018,
	address = {Republic and Canton of Geneva, CHE},
	series = {{WWW} '18},
	title = {Pixie: {A} {System} for {Recommending} 3+ {Billion} {Items} to 200+ {Million} {Users} in {Real}-{Time}},
	isbn = {978-1-4503-5639-8},
	shorttitle = {Pixie},
	url = {https://doi.org/10.1145/3178876.3186183},
	doi = {10.1145/3178876.3186183},
	abstract = {User experience in modern content discovery applications critically depends on high-quality personalized recommendations. However, building systems that provide such recommendations presents a major challenge due to a massive pool of items, a large number of users, and requirements for recommendations to be responsive to user actions and generated on demand in real-time. Here we present Pixie, a scalable graph-based real-time recommender system that we developed and deployed at Pinterest. Given a set of user-specific pins as a query, Pixie selects in real-time from billions of possible pins those that are most related to the query. To generate recommendations, we develop Pixie Random Walk algorithm that utilizes the Pinterest object graph of 3 billion nodes and 17 billion edges. Experiments show that recommendations provided by Pixie lead up to 50\% higher user engagement when compared to the previous Hadoop-based production system. Furthermore, we develop a graph pruning strategy at that leads to an additional 58\% improvement in recommendations. Last, we discuss system aspects of Pixie, where a single server executes 1,200 recommendation requests per second with 60 millisecond latency. Today, systems backed by Pixie contribute to more than 80\% of all user engagement on Pinterest.},
	urldate = {2023-01-13},
	booktitle = {Proceedings of the 2018 {World} {Wide} {Web} {Conference}},
	publisher = {International World Wide Web Conferences Steering Committee},
	author = {Eksombatchai, Chantat and Jindal, Pranav and Liu, Jerry Zitao and Liu, Yuchen and Sharma, Rahul and Sugnet, Charles and Ulrich, Mark and Leskovec, Jure},
	month = apr,
	year = {2018},
	pages = {1775--1784},
	file = {Full Text PDF:/Users/ykim/Zotero/storage/TMCZXJPC/Eksombatchai et al. - 2018 - Pixie A System for Recommending 3+ Billion Items .pdf:application/pdf},
}

@inproceedings{zhang_neural_2019,
	address = {New York, NY, USA},
	series = {{WWW} '19},
	title = {Neural {IR} {Meets} {Graph} {Embedding}: {A} {Ranking} {Model} for {Product} {Search}},
	isbn = {978-1-4503-6674-8},
	shorttitle = {Neural {IR} {Meets} {Graph} {Embedding}},
	url = {https://doi.org/10.1145/3308558.3313468},
	doi = {10.1145/3308558.3313468},
	abstract = {Recently, neural models for information retrieval are becoming increasingly popular. They provide effective approaches for product search due to their competitive advantages in semantic matching. However, it is challenging to use graph-based features, though proved very useful in IR literature, in these neural approaches. In this paper, we leverage the recent advances in graph embedding techniques to enable neural retrieval models to exploit graph-structured data for automatic feature extraction. The proposed approach can not only help to overcome the long-tail problem of click-through data, but also incorporate external heterogeneous information to improve search results. Extensive experiments on a real-world e-commerce dataset demonstrate significant improvement achieved by our proposed approach over multiple strong baselines both as an individual retrieval model and as a feature used in learning-to-rank frameworks.},
	urldate = {2023-01-13},
	booktitle = {The {World} {Wide} {Web} {Conference}},
	publisher = {Association for Computing Machinery},
	author = {Zhang, Yuan and Wang, Dong and Zhang, Yan},
	month = may,
	year = {2019},
	keywords = {Graph Embedding, Neural Information Retrieval, Product Search},
	pages = {2390--2400},
	file = {Full Text PDF:/Users/ykim/Zotero/storage/5NBNU9G4/Zhang et al. - 2019 - Neural IR Meets Graph Embedding A Ranking Model f.pdf:application/pdf},
}

@inproceedings{park_comparative_2017,
	title = {A comparative study of matrix factorization and random walk with restart in recommender systems},
	doi = {10.1109/BigData.2017.8257991},
	abstract = {Between matrix factorization or Random Walk with Restart (RWR), which method works better for recommender systems? Which method handles explicit or implicit feedback data better? Does additional information help recommendation? Recommender systems play an important role in many ecommerce services such as Amazon and Netflix to recommend new items to a user. Among various recommendation strategies, collaborative filtering has shown good performance by using rating patterns of users. Matrix factorization and random walk with restart are the most representative collaborative filtering methods. However, it is still unclear which method provides better recommendation performance despite their extensive utility. In this paper, we provide a comparative study of matrix factorization and RWR in recommender systems. We exactly formulate each correspondence of the two methods according to various tasks in recommendation. Especially, we newly devise an RWR method using global bias term which corresponds to a matrix factorization method using biases. We describe details of the two methods in various aspects of recommendation quality such as how those methods handle cold-start problem which typically happens in collaborative filtering. We extensively perform experiments over real-world datasets to evaluate the performance of each method in terms of various measures. We observe that matrix factorization performs better with explicit feedback ratings while RWR is better with implicit ones. We also observe that exploiting global popularities of items is advantageous in the performance and that side information produces positive synergy with explicit feedback but gives negative effects with implicit one.},
	booktitle = {2017 {IEEE} {International} {Conference} on {Big} {Data} ({Big} {Data})},
	author = {Park, Haekyu and Jung, Jinhong and Kang, U.},
	month = dec,
	year = {2017},
	keywords = {Bipartite graph, Collaboration, Computer science, Electronic mail, matrix factorization, Motion pictures, random walk with restart, recommender systems, Recommender systems},
	pages = {756--765},
	file = {arXiv Fulltext PDF:/Users/ykim/Zotero/storage/FF3BUBMB/Park et al. - 2017 - A Comparative Study of Matrix Factorization and Ra.pdf:application/pdf;IEEE Xplore Abstract Record:/Users/ykim/Zotero/storage/HDZ24JXS/8257991.html:text/html},
}

@inproceedings{xia_searchgcn_2021,
	address = {New York, NY, USA},
	series = {{SIGIR} '21},
	title = {{SearchGCN}: {Powering} {Embedding} {Retrieval} by {Graph} {Convolution} {Networks} for {E}-{Commerce} {Search}},
	isbn = {978-1-4503-8037-9},
	shorttitle = {{SearchGCN}},
	url = {https://doi.org/10.1145/3404835.3464927},
	doi = {10.1145/3404835.3464927},
	abstract = {Graph convolution networks (GCN), which recently becomes new state-of-the-art method for graph node classification, recommendation and other applications, has not been successfully applied to industrial-scale search engine yet. In this proposal, we introduce our approach, namely SearchGCN, for embedding-based candidate retrieval in one of the largest e-commerce search engine in the world. Empirical studies demonstrate that SearchGCN learns better embedding representations than existing methods, especially for long tail queries and items. Thus, SearchGCN has been deployed into JD.com's search production since July 2020.},
	urldate = {2023-01-13},
	booktitle = {Proceedings of the 44th {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}},
	publisher = {Association for Computing Machinery},
	author = {Xia, Xinlin and Wang, Shang and Zhang, Han and Wang, Songlin and Xu, Sulong and Xiao, Yun and Long, Bo and Yang, Wen-Yun},
	month = jul,
	year = {2021},
	keywords = {graph convolution networks, neural networks, representation learning, search},
	pages = {2633--2634},
	file = {Full Text PDF:/Users/ykim/Zotero/storage/Z9MXVA9Q/Xia et al. - 2021 - SearchGCN Powering Embedding Retrieval by Graph C.pdf:application/pdf},
}

@inproceedings{li_learning_2020,
	address = {Virtual Event Ireland},
	title = {Learning {Better} {Representations} for {Neural} {Information} {Retrieval} with {Graph} {Information}},
	isbn = {978-1-4503-6859-9},
	url = {https://dl.acm.org/doi/10.1145/3340531.3411957},
	doi = {10.1145/3340531.3411957},
	abstract = {Neural ranking models have recently gained much attention in information retrieval (IR) community and obtain good ranking performance. However, most of these retrieval models focus on capturing the textual matching signals between query and document but do not consider user behavior information that may be helpful for the retrieval task. Specifically, users’ click and query reformulation behavior can be represented by a click-through bipartite graph and a session-flow graph, respectively. Such graph representations contain rich user behavior information and may help us better understand users’ search intent beyond the textual information. In this study, we aim to incorporate this rich information encoded in these two graphs into existing neural ranking models.},
	language = {en},
	urldate = {2022-05-26},
	booktitle = {Proceedings of the 29th {ACM} {International} {Conference} on {Information} \& {Knowledge} {Management}},
	publisher = {ACM},
	author = {Li, Xiangsheng and de Rijke, Maarten and Liu, Yiqun and Mao, Jiaxin and Ma, Weizhi and Zhang, Min and Ma, Shaoping},
	month = oct,
	year = {2020},
	pages = {795--804},
	file = {Li et al. - 2020 - Learning Better Representations for Neural Informa.pdf:/Users/ykim/Zotero/storage/7PAH837A/Li et al. - 2020 - Learning Better Representations for Neural Informa.pdf:application/pdf},
}

@inproceedings{Wang2011SIGIR,
author = {Wang, Lidan and Lin, Jimmy and Metzler, Donald},
title = {A Cascade Ranking Model for Efficient Ranked Retrieval},
year = {2011},
isbn = {9781450307574},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2009916.2009934},
doi = {10.1145/2009916.2009934},
abstract = {There is a fundamental tradeoff between effectiveness and efficiency when designing retrieval models for large-scale document collections. Effectiveness tends to derive from sophisticated ranking functions, such as those constructed using learning to rank, while efficiency gains tend to arise from improvements in query evaluation and caching strategies. Given their inherently disjoint nature, it is difficult to jointly optimize effectiveness and efficiency in end-to-end systems. To address this problem, we formulate and develop a novel cascade ranking model, which unlike previous approaches, can simultaneously improve both top k ranked effectiveness and retrieval efficiency. The model constructs a cascade of increasingly complex ranking functions that progressively prunes and refines the set of candidate documents to minimize retrieval latency and maximize result set quality. We present a novel boosting algorithm for learning such cascades to directly optimize the tradeoff between effectiveness and efficiency. Experimental results show that our cascades are faster and return higher quality results than comparable ranking models.},
booktitle = {Proceedings of the 34th International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {105–114},
numpages = {10},
keywords = {effectiveness, learning to rank, efficiency},
location = {Beijing, China},
series = {SIGIR '11}
}


@inproceedings{robertson_okapi_1995,
	title = {Okapi at {TREC}-3},
	url = {https://www.microsoft.com/en-us/research/publication/okapi-at-trec-3/},
	abstract = {The Okapi software used for TREC-3 was similar to that used in previous TRECs, comprising a low level basic search system and a user interface for the manual search experiments, together with data conversion and inversion utilities. There were also various scripts and programs for generating query terms, running batches of trials and performing evaluation. […]},
	language = {en-US},
        booktitle= {Overview of the Third Text REtrieval Conference (TREC-3)},
	urldate = {2023-02-01},
	author = {Robertson, Stephen and Walker, S. and Jones, S. and Hancock-Beaulieu, M. M. and Gatford, M.},
	month = jan,
	year = {1995},
	pages = {109--126},
	file = {Full Text PDF:/Users/ykim/Zotero/storage/F6NV3IFY/Robertson et al. - 1995 - Okapi at TREC-3.pdf:application/pdf},
}


@inproceedings{chen_out--domain_2022,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Out-of-{Domain} {Semantics} to the {Rescue}! {Zero}-{Shot} {Hybrid} {Retrieval} {Models}},
	isbn = {978-3-030-99736-6},
	doi = {10.1007/978-3-030-99736-6_7},
	abstract = {The pre-trained language model (eg, BERT) based deep retrieval models achieved superior performance over lexical retrieval models (eg, BM25) in many passage retrieval tasks. However, limited work has been done to generalize a deep retrieval model to other tasks and domains. In this work, we carefully select five datasets, including two in-domain datasets and three out-of-domain datasets with different levels of domain shift, and study the generalization of a deep model in a zero-shot setting. Our findings show that the performance of a deep retrieval model is significantly deteriorated when the target domain is very different from the source domain that the model was trained on. On the contrary, lexical models are more robust across domains. We thus propose a simple yet effective framework to integrate lexical and deep retrieval models. Our experiments demonstrate that these two models are complementary, even when the deep model is weaker in the out-of-domain setting. The hybrid model obtains an average of 20.4\% relative gain over the deep retrieval model, and an average of 9.54\% over the lexical model in three out-of-domain datasets.},
	language = {en},
	booktitle = {Advances in {Information} {Retrieval}},
	publisher = {Springer International Publishing},
	author = {Chen, Tao and Zhang, Mingyang and Lu, Jing and Bendersky, Michael and Najork, Marc},
	editor = {Hagen, Matthias and Verberne, Suzan and Macdonald, Craig and Seifert, Christin and Balog, Krisztian and Nørvåg, Kjetil and Setty, Vinay},
	year = {2022},
	keywords = {deep retrieval, hybrid model, lexical retrieval, zero-shot learning},
	pages = {95--110},
	file = {arXiv Fulltext PDF:/Users/ykim/Zotero/storage/8MP748LC/Chen et al. - 2022 - Out-of-Domain Semantics to the Rescue! Zero-Shot H.pdf:application/pdf;Submitted Version:/Users/ykim/Zotero/storage/JDYFLHBU/Chen et al. - 2022 - Out-of-Domain Semantics to the Rescue! Zero-Shot H.pdf:application/pdf},
}

@inproceedings{wang_bert-based_2021,
	address = {New York, NY, USA},
	series = {{ICTIR} '21},
	title = {{BERT}-based {Dense} {Retrievers} {Require} {Interpolation} with {BM25} for {Effective} {Passage} {Retrieval}},
	isbn = {978-1-4503-8611-1},
	url = {https://doi.org/10.1145/3471158.3472233},
	doi = {10.1145/3471158.3472233},
	abstract = {The integration of pre-trained deep language models, such as BERT, into retrieval and ranking pipelines has shown to provide large effectiveness gains over traditional bag-of-words models in the passage retrieval task. However, the best setup for integrating such deep language models is still unclear. When BERT is used to re-rank passages (i.e., BERT re-ranker), previous work has empirically shown that, while in practice BERT re-ranker cannot act as initial retriever due to BERT's high query time costs, and thus a bag-of-words model such as BM25 is required. It is not necessary to interpolate BERT re-ranker and bag-of-words scores to generate the final ranking. In fact, the BERT re-ranker scores alone can be used by the re-ranker: the BERT re-ranker score appears to already capture the relevance signal provided by BM25. In this paper, we further investigate the topic of interpolating BM25 and BERT-based rankers. Unlike previous work that considered the BERT re-ranker, however, here we consider BERT-based dense retrievers (RepBERT and ANCE). Dense retrievers encode queries and documents into low dimensional BERT-based embeddings. These methods overcome BERT's high computational costs at query time, and can thus be feasibly used in practice as whole-collection retrievers, rather than just as re-rankers. Our novel empirical findings suggest that, unlike for BERT re-ranker, interpolation with BM25 is necessary for BERT-based dense retrievers to perform effectively; and the gains provided by the interpolation are significant. Further analysis reveals why this is so: dense retrievers are very effective at encoding strong relevance signals, but they fail in identifying weaker relevance signals -- a task that the interpolation with BM25 is able to make up for.},
	urldate = {2023-02-01},
	booktitle = {Proceedings of the 2021 {ACM} {SIGIR} {International} {Conference} on {Theory} of {Information} {Retrieval}},
	publisher = {Association for Computing Machinery},
	author = {Wang, Shuai and Zhuang, Shengyao and Zuccon, Guido},
	month = aug,
	year = {2021},
	keywords = {BERT ranking, dense retrievers, neural IR, passage retrieval},
	pages = {317--324},
	file = {Full Text PDF:/Users/ykim/Zotero/storage/827M2P3Z/Wang et al. - 2021 - BERT-based Dense Retrievers Require Interpolation .pdf:application/pdf},
}


@inproceedings{xiong_approximate_2021,
	title = {Approximate {Nearest} {Neighbor} {Negative} {Contrastive} {Learning} for {Dense} {Text} {Retrieval}},
	url = {https://openreview.net/forum?id=zeFrfgyZln},
	abstract = {Conducting text retrieval in a learned dense representation space has many intriguing advantages. Yet dense retrieval (DR) often underperforms word-based sparse retrieval. In this paper, we first theoretically show the bottleneck of dense retrieval is the domination of uninformative negatives sampled in mini-batch training, which yield diminishing gradient norms, large gradient variances, and slow convergence. We then propose Approximate nearest neighbor Negative Contrastive Learning (ANCE), which selects hard training negatives globally from the entire corpus. Our experiments demonstrate the effectiveness of ANCE on web search, question answering, and in a commercial search engine, showing ANCE dot-product retrieval nearly matches the accuracy of BERT-based cascade IR pipeline. We also empirically validate our theory that negative sampling with ANCE better approximates the oracle importance sampling procedure and improves learning convergence.},
	language = {en},
	urldate = {2023-02-01},
        booktitle = {International Conference on Learning Representations},
	author = {Xiong, Lee and Xiong, Chenyan and Li, Ye and Tang, Kwok-Fung and Liu, Jialin and Bennett, Paul N. and Ahmed, Junaid and Overwijk, Arnold},
	year = {2021},
	file = {Full Text PDF:/Users/ykim/Zotero/storage/6E2XTMHV/Xiong et al. - 2023 - Approximate Nearest Neighbor Negative Contrastive .pdf:application/pdf},
}

@inproceedings{karpukhin_dense_2020,
	address = {Online},
	title = {Dense {Passage} {Retrieval} for {Open}-{Domain} {Question} {Answering}},
	url = {https://aclanthology.org/2020.emnlp-main.550},
	doi = {10.18653/v1/2020.emnlp-main.550},
	abstract = {Open-domain question answering relies on efficient passage retrieval to select candidate contexts, where traditional sparse vector space models, such as TF-IDF or BM25, are the de facto method. In this work, we show that retrieval can be practically implemented using dense representations alone, where embeddings are learned from a small number of questions and passages by a simple dual-encoder framework. When evaluated on a wide range of open-domain QA datasets, our dense retriever outperforms a strong Lucene-BM25 system greatly by 9\%-19\% absolute in terms of top-20 passage retrieval accuracy, and helps our end-to-end QA system establish new state-of-the-art on multiple open-domain QA benchmarks.},
	urldate = {2023-02-01},
	booktitle = {Proceedings of the 2020 {Conference} on {Empirical} {Methods} in {Natural} {Language} {Processing} ({EMNLP})},
	publisher = {Association for Computational Linguistics},
	author = {Karpukhin, Vladimir and Oguz, Barlas and Min, Sewon and Lewis, Patrick and Wu, Ledell and Edunov, Sergey and Chen, Danqi and Yih, Wen-tau},
	month = nov,
	year = {2020},
	pages = {6769--6781},
	file = {Full Text PDF:/Users/ykim/Zotero/storage/CVNZ9Z9K/Karpukhin et al. - 2020 - Dense Passage Retrieval for Open-Domain Question A.pdf:application/pdf},
}

@inproceedings{lee_latent_2019,
	address = {Florence, Italy},
	title = {Latent {Retrieval} for {Weakly} {Supervised} {Open} {Domain} {Question} {Answering}},
	url = {https://aclanthology.org/P19-1612},
	doi = {10.18653/v1/P19-1612},
	abstract = {Recent work on open domain question answering (QA) assumes strong supervision of the supporting evidence and/or assumes a blackbox information retrieval (IR) system to retrieve evidence candidates. We argue that both are suboptimal, since gold evidence is not always available, and QA is fundamentally different from IR. We show for the first time that it is possible to jointly learn the retriever and reader from question-answer string pairs and without any IR system. In this setting, evidence retrieval from all of Wikipedia is treated as a latent variable. Since this is impractical to learn from scratch, we pre-train the retriever with an Inverse Cloze Task. We evaluate on open versions of five QA datasets. On datasets where the questioner already knows the answer, a traditional IR system such as BM25 is sufficient. On datasets where a user is genuinely seeking an answer, we show that learned retrieval is crucial, outperforming BM25 by up to 19 points in exact match.},
	urldate = {2023-02-01},
	booktitle = {Proceedings of the 57th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics}},
	publisher = {Association for Computational Linguistics},
	author = {Lee, Kenton and Chang, Ming-Wei and Toutanova, Kristina},
	month = jul,
	year = {2019},
	pages = {6086--6096},
	file = {Full Text PDF:/Users/ykim/Zotero/storage/BKBNMG56/Lee et al. - 2019 - Latent Retrieval for Weakly Supervised Open Domain.pdf:application/pdf},
}

@inproceedings{yang_random_2021,
	address = {Virtual Event Germany},
	title = {Random {Walks} on {Huge} {Graphs} at {Cache} {Efficiency}},
	isbn = {978-1-4503-8709-5},
	url = {https://dl.acm.org/doi/10.1145/3477132.3483575},
	doi = {10.1145/3477132.3483575},
	language = {en},
	urldate = {2023-02-06},
	booktitle = {Proceedings of the {ACM} {SIGOPS} 28th {Symposium} on {Operating} {Systems} {Principles} {CD}-{ROM}},
	publisher = {ACM},
	author = {Yang, Ke and Ma, Xiaosong and Thirumuruganathan, Saravanan and Chen, Kang and Wu, Yongwei},
	month = oct,
	year = {2021},
	pages = {311--326},
}

@inproceedings{yates_tiberi_2007,
author = {Baeza-Yates, Ricardo and Tiberi, Alessandro},
title = {Extracting Semantic Relations from Query Logs},
year = {2007},
isbn = {9781595936097},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1281192.1281204},
doi = {10.1145/1281192.1281204},
abstract = {In this paper we study a large query log of more than twenty million queries with the goal of extracting the semantic relations that are implicitly captured in the actions of users submitting queries and clicking answers. Previous query log analyses were mostly done with just the queries and not the actions that followed after them. We first propose a novel way to represent queries in a vector space based on a graph derived from the query-click bipartite graph. We then analyze the graph produced by our query log, showing that it is less sparse than previous results suggested, and that almost all the measures of these graphs follow power laws, shedding some light on the searching user behavior as well as on the distribution of topics that people want in the Web. The representation we introduce allows to infer interesting semantic relationships between queries. Second, we provide an experimental analysis on the quality of these relations, showing that most of them are relevant. Finally we sketch an application that detects multitopical URLs.},
booktitle = {Proceedings of the 13th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
pages = {76–85},
numpages = {10},
keywords = {graph mining, query log analysis},
location = {San Jose, California, USA},
series = {KDD '07}
}