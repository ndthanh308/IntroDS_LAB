\section{Introduction}

Modern large-scale search systems are tiered~\cite{Wang2011SIGIR} with at least two layers. The \emph{candidate retrieval} layer generates a small subset of potentially relevant documents from a corpus many orders of magnitude larger in size, while emphasizing efficiency and recall. The \emph{re-ranking} layer uses more computationally expensive methods to re-rank the candidates generated by the retrieval stage to produce a high-precision final result list. Better recall in candidate retrieval leads to better overall accuracy. In this paper, we focus on improve search through improving recall in the candidate retrieval layer.

Most evaluations for search systems use an evaluation query set in which every query is assumed to be equally important and has equal impact on the accuracy metric. However, in reality, query frequency distributions are exponential~\cite{yates_tiberi_2007}. Consequently, in e-commerce, head queries account for the vast majority of gross merchandise sales and head query performance is far more impactful to business metrics than torso or tail performance. 
State-of-the-art supervised neural dense retrievers \cite{lee_latent_2019,karpukhin_dense_2020,xiong_approximate_2021,chen_out--domain_2022,wang_bert-based_2021} typically perform better in head queries than tail, due to the higher availability of training data in the head region. However, we show that further substantial improvements to head query performance are possible. We borrow ideas from the recommendation systems community and propose XWalk, a graph-based approach to candidate retrieval.

Historically, graph-based approaches in search were used to create features (e.g. PageRank, click graphs~\cite{jiang_learning_2016,zhang_neural_2019}) for the re-ranker layer, but have not been used directly for retrieval.
Recently, graph neural networks (GNNs) have achieved state of the art performance in recommendation and are being adapted for search \cite{li_learning_2020,zamani_learning_2020,xia_searchgcn_2021,zhao_joint_2022}. However, large-scale GNNs are complex and slow to train.  

The recommendation systems have long used implicit interaction graphs to directly generate recommendations. Commonly, users and product listings are represented as nodes in a graph and edges represent a logged interaction between a user and product listing (e.g. the user purchasing the listing). 
Random walks in graphs is a powerful technique used to generate recommendations from interaction graphs \cite{park_comparative_2017,christoffel_blockbusters_2015,eksombatchai_pixie_2018,paudel_updatable_2016}.
Random walk based approaches are frequently used in large, real-time recommendation systems due to their effectiveness and efficiency \cite{paudel_updatable_2016,eksombatchai_pixie_2018}. In addition, when using implicit feedback (e.g. logged interaction data such as user clicks) Park et al. \cite{park_comparative_2017} showed that random walk based approaches can perform better than matrix factorization approaches. 

XWalk uses a random walk based approach to perform candidate retrieval for product search. In XWalk, we cast search as a query-to-listing recommendation problem (as opposed to user-to-listing), that is, we transform our query log into a implicit interaction graph between queries and product listings, and perform candidate retrieval by ``recommending'' listings to queries. Our approach trains using a fraction of the time and resources used by neural dense retrievers and GNNs, and is highly efficient in inference -- XWalk scales to real-time search over graphs of billions of nodes and tens of billions of edges. XWalk also excels in head queries, where implicit feedback signals are plentiful. 

While XWalk on its own suffers in tail and novel queries, we show that when results from XWalk are ensembled with a typical retriever that uses text similarity, even one as basic as plain BM25, it substantially improves overall candidate retrieval accuracy compared to strong neural dense retrieval and hybrid retrieval baselines, especially over the head query region, which is responsible for the overwhelming majority of sales in e-commerce. Furthermore, we show that XWalk is complementary to \emph{both} dense retrieval and BM25, and demonstrate the strength of ensembling all three approaches.

To summarize, our novel contributions are: a) showing that XWalk substantially improves performance in the head query region, which accounts for the overwhelming majority of sales in e-commerce;
b) presenting an efficient random walk inference algorithm that can effectively serve queries at scale;
c) showing that XWalk is complementary to other common retrieval methods and showing the strength of a simple ensemble approach that combines XWalk, BM25, and dense retrieval.
%\begin{itemize}
%    \item We show that XWalk substantially improves performance in the head query region, which accounts for the overwhelming majority of sales in e-commerce
%    \item We present an efficient random walk inference algorithm that can effectively serve queries at scale  
%    \item We demonstrate that XWalk is complementary to other common retrieval methods and show the strength of a simple ensemble approach that combines XWalk, BM25, and dense retrieval
%\end{itemize}

%
%Historically, graph-based approaches in information retrieval were used to create features (e.g. PageRank, click graphs~\cite{jiang_learning_2016,zhang_neural_2019}) for the re-ranker layer. Recently, graph neural networks (GNNs) have achieved state of the art performance in recommendation tasks and are being adapted for search \cite{li_learning_2020,zamani_learning_2020,xia_searchgcn_2021,zhao_joint_2022}. However, large-scale GNNs are often complex and slow to train. 
%
%
%In this paper, we cast search as a query to product listing recommendation problem and propose XWalk, a simple and efficient random walk based graph approach to search candidate retrieval that trains in a fraction of the time of GNNs and is highly efficient in inference, scaling to graphs of billions of nodes and tens of billions of edges.
%XWalk excels in realistic industry settings, where implicit user feedback is plentiful (in the form of query logs) and query popularity has a highly skewed distribution.
%
%While XWalk when used alone has cold start problems for novel queries, we show that when results from XWalk are fused with that of basic BM25, it substantially improves overall search accuracy compared to strong neural dense retrieval and hybrid retrieval baselines, especially over the head query region, which is responsible for the lion's share of revenue in an e-commerce setting. Furthermore, we show that XWalk is complementary to \emph{both} dense retrieval and BM25, and demonstrate the strength of ensembling all three approaches. 

%XWalk is complementary to \emph{both} lexical and dense retrieval.

%In search, graph-based techniques are far less commonly used. Previously, click graphs \cite{jiang_learning_2016} have been used as features into a ranking model. More recently, in neural retrieval techniques, graph embeddings have been used as features into a neural ranking model \cite{zhang_neural_2019} and complex GNN-based frameworks are being proposed to jointly learn search and recommendation problems \cite{zhao_joint_2022,li_learning_2020,xia_searchgcn_2021}.


% Novel contributions to emphasize:
% \begin{itemize}
%     \item Fast training (aka graph construction) time, fast inference (emphasize that this is for \emph{candidate retrieval} in practical large-scale search settings)
%     \item Guidance on how best to use XWalk: i.e. analysis on types of queries/users?/items? where XWalk helps the most. How to best construct the query-item graph
%     \item Experiments on how to best do data fusion between XWalk + BM25 (+ potentially nueral IR)
% \end{itemize}
