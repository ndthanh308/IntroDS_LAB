\documentclass[twocolumn]{aastex62}
\usepackage[utf8]{inputenc}
%\usepackage{pgfplots}
%\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{acronym}
\usepackage{hyperref}
\usepackage{xcolor}
%%% remove if dont work
%\hypersetup{breaklinks,colorlinks,allcolors=blue}

%\usepackage{fullpage}
%%%%%%%%%%%%%%%%
\usepackage{mathtools} % http://ctan.org/pkg/mathtools
%\usepackage{xparse} % http://ctan.org/pkg/xparse
\makeatletter
\newcommand{\raisemath}[1]{\mathpalette{\raisem@th{#1}}}% \raisemath{<len>}{...}
\newcommand{\raisem@th}[3]{\raisebox{#1}{$#2#3$}}
\makeatother
\NewDocumentCommand{\newbbar}{O{0pt} O{0pt}}{% \newhbar[<horz len>][<vert len>]
  \ensuremath{\mathrlap{\raisemath{#2}{\hspace*{#1}{\mathchar'26\mkern-9mu}}}b}%
}

\newcommand{\msun}{\ensuremath{M_\odot}}

\acrodef{GW}[GW]{gravitational-wave}
\acrodef{BBH}[BBH]{Binary black hole}  % First occurs at beginning of sentence :/
%\acrodef{}[]{}

%%%%%%%%%%%%%%%%%%%%%%
%\usepackage{geometry}
% \geometry{
% a4paper,
% total={170mm,257mm},
% left=20mm,
% right=20mm,
% top=10mm,
% bottom=15mm
% }
% By default, an article has some vary large margins to fit the smaller page format.  This allows us to use more standard margins.
%\setlength{\parskip}{1em}

% MG:
\usepackage[normalem]{ulem} 
\usepackage{soul}
%\usepackage[dvipsnames]{xcolor}
\def\mg#1#2{\textcolor{red}{{\xout{#1}}}{\,{\textcolor{green}{#2}}}}
\def\mgq#1{{\it\textcolor{magenta}{MG:#1}}}
\def\hb#1{{\it\textcolor{red}{HB:#1}}}
\def\mgadd#1{{\textcolor{green}{#1}}}
\begin{document}

\title{Binary vision: The merging black hole binary mass distribution via iterative density estimation}

\correspondingauthor{Jam Sadiq}
\email{jam.sadiq@usc.es}  % check/change if needed
\author[0000-0001-5931-3624]{Jam Sadiq}
\affil{Instituto Galego de F\'{i}sica de Altas Enerx\'{i}as, Universidade de Santiago de Compostela, Santiago de Compostela, Galicia, Spain}
\affil{SISSA, Via Bonomea 265, 34136 Trieste, Italy and INFN Sezione di Trieste}
\author[0000-0003-1354-7809]{Thomas Dent}
\affil{Instituto Galego de F\'{i}sica de Altas Enerx\'{i}as, Universidade de Santiago de Compostela, Santiago de Compostela, Galicia, Spain}
\author[0000-0002-9716-1868]{Mark Gieles}
\affil{ICREA, Pg. Lu\'{i}s Companys 23, E08010 Barcelona, Spain}
\affil{Institut de Ci\`{e}ncies del Cosmos (ICCUB), Universitat de Barcelona (IEEC-UB), Mart\'{i} Franqu\`{e}s 1, E08028 Barcelona, Spain}
%\affil{Institut de Ci{\` e}ncies del Cosmos (ICCUB), Universitat de Barcelona, Mart{\' i} i Franqu{\` e}s 1, E-08028 Barcelona, Spain \& ICREA, Pg. Lluis Companys 23, E-08010 Barcelona, Spain}
\date{\today}

\begin{abstract} 
  \ac{BBH} systems detected via \ac{GW} emission are a recently opened astrophysical frontier with many unknowns and uncertainties.  Accurate reconstruction of the binary distribution with as few assumptions as possible is desirable for inference on formation channels and environments.  Most population analyses have, though, assumed a power law %distribution 
  in binary mass ratio $q$, and/or assumed a universal $q$ distribution regardless of primary mass.  
  Kernel density estimation (KDE)-based methods allow us to dispense with such assumptions and directly estimate the joint binary mass distribution.  %accessing information which may give clues towards sub-populations with different formation channels. 
  We deploy a self-consistent iterative method to estimate this full \ac{BBH} mass distribution, finding local maxima in primary mass consistent with previous investigations and a secondary mass distribution with a partly independent structure, inconsistent with both power laws and with a constant function of $q$.  We find a weaker preference for near-equal mass binaries than in most previous investigations; instead, the secondary mass has its own ``spectral lines'' at slightly lower values than the primary, and we observe an anti-correlation between primary and secondary masses around the $\sim\!10\,\msun$ peak. 
  %The emerging two-dimensional mass function has potential implications both for \ac{BBH} formation and for inferences on other quantities, in particular component spins. 
\end{abstract}

\keywords{Compact binaries, stellar-mass black holes, gravitational waves, density estimation}


\section{Introduction}
Ever since the first \ac{GW} detection revealed a binary black hole source with the---previously unsuspected---component masses of around 35\,\msun\ \citep{LIGOScientific:2016aoc,LIGOScientific:2016vpg}, 
LIGO-Virgo-KAGRA  
% TD .. Kagra as a detector has not observed anything yet, but we are 'data sharing'  
observations of compact binaries have continued to yield surprises, of which the binary mass distribution arguably contains the most information bearing on formation environments and channels.  In the first three observing runs of Advanced LIGO~\citep{LIGOScientific:2014pky} and Advanced Virgo~\citep{VIRGO:2014yos} the better part of 100 detections of binary compact object mergers via gravitational wave (GW) emission were made, as catalogued in the GWTC releases~\citep{LIGOScientific:2018mvr,LIGOScientific:2020ibl,LIGOScientific:2021djp,LIGOScientific:2021usb}.  Having a set of detected events it is possible to study population properties of these compact binaries and eventually draw implications from these properties on binary astrophysical formation and evolution.  Detailed investigations of the population properties of \ac{BBH} mergers, the most commonly detected source type, were undertaken in \citet{Abbott:2020gyp,KAGRA:2021duu}, focusing on several population characteristics including their component masses and spins and possible dependence on redshift. 

Among parameters estimated and studied in connection with the population properties of binary compact objects, the component masses are obtained with least uncertainty. 
%Understanding collectively the population distribution of masses can eventually give insights into the astrophysics of binary compact object formation and evolution. 
Many parameterized and semi- or non-parametric models have been proposed to study the mass-dependence of the compact binary merger rate or the mass distribution of the merger population~\citep[see][and references therein]{KAGRA:2021duu}.  In parametric models, Bayesian hierarchical techniques are used to infer model hyper-parameter posteriors, and thus the population distribution~\citep[e.g.][]{Mandel:2009pc,Thrane:2018qnx}.  On the other hand, non-parametric models are data driven methods which learn population properties either without requiring any specific functional form, or (for semi-parametric models) allowing for generalised deviations from a given parametric model~\citep{Powell:2019nmw,Tiwari:2020otp,Tiwari:2020vym,Tiwari:2021yvr,Veske:2021qis,Rinaldi:2021bhm,Edelman:2021zkw,Edelman:2022ydv,Callister:2023tgi,Ray:2023upk,Toubiana:2023egi}.

In \cite{Sadiq:2021fin} we introduced a fast and flexible adaptive width kernel density estimation (awKDE) as a non-parametric estimation method for population reconstructions of binary black hole distribution from observed gravitational wave data.  A limitation of this method arose from the measurement uncertainty in each individual event's parameters.  Given the relatively low signal-to-noise ratios, the observed component masses have significant uncertainties~\citep[e.g.][]{Veitch:2014wba} that can bias the overall population distribution if not properly accounted for. 

In this work we are proposing a new method to reduce this uncertainty estimate in our populations distribution by using iterative re-weighting scheme of samples for each observed events using the awKDE density estimates as a probability for re-weighting of samples. The idea is similar to the standard expectation-maximization algorithm \citep{10.2307/2984875}. 

As an application of this new method, we estimate the full 2-dimensional component mass distribution without assumptions (aside from the use of Gaussian kernels) on its functional form. While attention has often focused on the primary component mass or on the more precisely measured chirp mass \citep[see among others][]{Dominik:2014yma,Tiwari:2020otp,Tiwari:2021yvr,Tiwari:2023xff,Edelman:2022ydv,Schneider:2023mxe,Farah:2023vsc},
less attention has been paid to the full binary distribution, either considered via the secondary $m_2$ or mass ratio $q\equiv m_2/m_1$.  We expect these parameters to bear traces of the possible BBH formation channels~\citep{Kovetz:2016kpi}, in that for dynamical (cluster) formation the two masses may be independent variates, up to a factor modelling probability of binary formation and merger~\citep{Fishbach:2019bbm,2023MNRAS.522..466A} that typically favors near-equal masses~\citep[e.g.][]{2016PhRvD..93h4029R,OLeary:2016ayz}; whereas for isolated binary evolution, some nontrivial though probably highly model-dependent correlation of component masses may arise~\citep[e.g.][]{2022ApJ...940..184V}. 

Typically, parametric models have assumed power-law $m_2$ dependence at fixed $m_1$~\citep{Kovetz:2016kpi,Fishbach:2017zga,Talbot:2018cva,LIGOScientific:2018jsj}, recovering mildly positive powers indicating a preference for equal masses.  A more detailed study using GWTC-1 events concluded that the two BHs of a given binary prefer to be of comparable mass~\citep{Fishbach:2019bbm}.  More recent non-parametric or semi-parametric studies have relaxed these assumptions, either through allowing the power-law index to vary over chirp mass~\citep{Tiwari:2021yvr}, or allowing $p(q)$ to be a free (data-driven) function~\citep{Edelman:2022ydv,Callister:2023tgi} though enforcing the same dependence over all primary masses.  \cite{Tiwari:2023xff} introduced a more flexible approach with $p(q)$ modelled by a truncated Gaussian whose parameters depend on chirp mass, finding some significant variation.  \cite{Ray:2023upk} measured the full 2-d distribution with a binned (piecewise-constant) model over $m_1$, $m_2$ (including possible redshift dependence), although they did not consider the $q$ distribution. 
Note that the mass ratio distribution presents nontrivial technical issues since (at least for lower mass \ac{BBH}) typical event measurement errors are both large, and correlated with the BH orbit-aligned spin components~\citep{Cutler:1994ys,Baird:2012cu}. 
Concerning measurement errors, we expect our iterative reweighting scheme to yield a significant advance in reconstructing the full mass distribution. 

The remainder of the paper is organized as follows: in section 2 we explain our method and demonstrate it using simple one-dimensional mock data.  In section 3 we apply our method to detected \ac{BBH} in GWTC-3, compare the result with our previous studies and further use our new method in two mass dimensions. In section 4 we discuss the implications of our results and consider extensions of the method.  We also describe additional mock data tests and supplementary results in appendices. 


\section{Method}
%We construct adaptive KDE. as a population model for BBH, using randomly selecting parameter estimation (PE) samples obtained from PE for each observed gravitational wave events. We use the publically available data  \citep{ RICHABBOTT2021100658, LIGOScientific:2023vdi} by LVK collaboration. These PE samples involve uncertainty. Roughly this mean that for each event we get samples that if follow a Gaussian distribution its median and standard deviations will not be the true one and involve uncertainties. When we compute our population distribution from these samples of all the observed events, our estimation will be affected by these uncertainties of PE samples. In this work we are proposing an iterative reweighting scheme to handle this uncertainty issue and get a more accurate estimate of our population model via AwKDE. 

\subsection{Statistical framework}

Our general approach to population inference can be considered as similar to maximum likelihood, with uncertainties quantified via empirical bootstrap methods~\citep{bootstrapcitation}.  Given a set of observed events, if we neglect measurement uncertainty in each event's parameters, our population 
%and uncertainty due to finite event counts, 
estimate is a KDE where the kernel bandwidth for each event is adjusted \citep{Breiman1977,Abramson1982,TerrellScott,SainScott} 
using an adaptive scheme to maximize the cross-validated likelihood~\citep{Sadiq:2021fin}.  Note that a ``maximum likelihood'' KDE is not well defined, as the likelihood increases indefinitely in the limit of small bandwidth kernels centered on the observations; in this limit, the variance of the density estimate over realizations of the data becomes infinitely large.  The bias-variance tradeoff is then addressed by adaptive kernel bandwidth, with a choice of hyperparameters---global bandwidth $h$ and sensitivity parameter $\alpha$, see \cite{wang2011bandwidth}---optimized by grid search using leave-out-one cross-validation to calculate a figure of merit. 
%particularly for sparsely populated regions of parameter space.  
We then quantify counting uncertainties for the underlying inhomogeneous Poisson process using generalized bootstrap resampling~\cite{google_bootstrap}. 
% cite https://research.google/pubs/pub43157/ 
%  Estimating Uncertainty for Massive Data Streams
%   Nicholas Chamandy, Omkar Muralidharan, Amir Najmi, Siddartha Naidu 
% Google (2012)

We noted in~\cite{Sadiq:2021fin} that for nontrivial measurement errors this method, in addition to possible intrinsic biases due to the choice of a Gaussian KDE, will be biased towards an over-dispersed estimate of the true distribution.  Here we motivate and present our strategy for correcting this bias.  Our motivation is linked to Bayesian hierarchical population inference \citep{Mandel:2009pc}, where measurement errors are treated by considering the true event properties $\vec{\theta_i}$ for events labelled $i=1,\ldots,N$ as nuisance parameters in the likelihood:
\begin{equation}
 p(\{d\}|\vec{\lambda}) = \prod_{i=1}^N \int p(d_i|\vec{\theta}_i) p(\vec{\theta}_i|\vec{\lambda}) \, d\vec{\theta}_i, 
\end{equation}
where $\{d\}$ is the set of data segments $d_i$ corresponding to the events and $\vec{\lambda}$ are population model hyperparameters (here for simplicity we omit selection effects).  Inference is implemented using parameter estimation (PE) samples which were generated using a standard or fiducial prior $p_{\rm PE}(\vec{\theta})$, often chosen as uniform over parameters of interest \citep[see e.g.][]{Veitch:2014wba,Thrane:2018qnx}.  Samples (labelled by $k$) are distributed as the posterior density using this prior, hence
\begin{equation}
  \vec{\theta}_i^k \sim p(\vec{\theta}_i|d_i,p_{\rm PE}(\vec{\theta})) 
  \propto p(d_i|\vec{\theta}_i) p(\vec{\theta}_i|\vec{\lambda}) \cdot
  \frac{p_{\rm PE}(\vec{\theta})}{p(\vec{\theta}_i|\vec{\lambda})},
\end{equation}
hence the integrals may be performed (up to a constant factor) by summing over samples \emph{re-weighted} by the ratio of the population distribution to the PE prior, $p(\vec{\theta}_i|\vec{\lambda})/p_{\rm PE}(\vec{\theta})$. 

Here, while not making use of this hierarchical likelihood, we remark that PE samples give a \emph{biased} estimate of each event's properties if the true population distribution $p_{\rm pop}(\vec{\theta})$ (corresponding to $p(\vec{\theta}|\vec{\lambda})$ in the parameterised case) is not equal to $p_{\rm PE}(\vec{\theta})$.  Then, if we have access to an estimated population distribution $\hat{p}_{\rm pop}(\vec{\theta})$ that is more accurate than the PE prior is, we will obtain more accurate estimates of event properties by drawing samples weighted proportional to $\hat{p}_{\rm pop}(\vec{\theta})/p_{\rm PE}(\vec{\theta})$, as described in more detail below,
%, the closer the estimated distribution is to the true population, the more accurately will we estimate event properties.

To summarize, a KDE obtained by drawing from PE samples will be biased because these samples are themselves biased, due to the PE prior not being equal to the true population distribution.  However, the more accurate an estimate of the true distribution we are able to obtain, the smaller will be the bias in event parameters using reweighted PE samples, and ultimately the smaller will be the bias of the KDE. 


\subsection{Iterative Reweighting}
\label{ss:iterkde}
The above discussion suggests an iterative procedure where, beginning with both biased PE samples and a biased population KDE, one may be improved in turn using the other, until -- ideally -- reaching a stationary state, where both the sample draws and the corresponding population estimates are unbiased (up to more fundamental limitations of PE and of our KDE). 
This iterative strategy is similar to the Expectation-Maximization (EM) algorithm~\citep{10.2307/2984875}, a popular method to estimate parameters for statistical models when there are missing or incomplete data.  

Our basic algorithm follows these steps: 
\begin{enumerate}
\item For each GW event, draw Poisson distributed (with mean 1) PE samples weighted by the current estimate of population density $\hat{p}_{\rm pop}$
\item Create an awKDE from this sample set, optimizing the global bandwidth (and sensitivity parameter $\alpha$, if not fixed)
\item Update the current population estimate using one or more KDEs and the selection function, and go to step 1. 
\end{enumerate}
In more detail, in step 1 we draw PE samples with probability proportional to the ratio of $\hat{p}_{\rm pop}(\vec{\theta}_i^k)$ to the PE prior distribution.  Step 2 reproduces our previous awKDE method.  Step 3 relates the KDE of \emph{detected} events to an estimate of the true population distribution, hence in general it requires us to compensate for the selection function over the event parameter space: i.e.\ we estimate the true distribution by the KDE of detected events divided by the probability of detection, as detailed in \citep[section 3.1]{Sadiq:2021fin}. 

In step 3 we may choose to derive the updated population density $\hat{p}_{\rm pop}(\vec{\theta})$ from only the most recently calculated KDE: then the iterative process is a Markov chain,\footnote{Although it may be thought of as a Markov chain Monte Carlo, our method is entirely unrelated to the Metropolis-Hastings algorithm.} and we may characterize it via the autocorrelation of various scalar quantities computed at each iteration.  We use the optimized global bandwidth $h$ (and adaptive sensitivity parameter $\alpha$, if not fixed to unity) for this purpose. 

After discarding a small number of initial iterations and then accumulating a number significantly greater than the autocorrelation time, we expect the collection of iterations to provide unbiased (though not necessarily independent) estimates of the population distribution.  For subsequent iterations we then use the median of $\hat{p}_{\rm pop}(\vec{\theta}_i^k)$ over a buffer of previous iterations (usually the previous 100) to determine the sample draw probabilities for the next iteration.  This population estimate should be more precise than one using only a single previous KDE;
%the Markov chain (i.e.\ using only a single KDE) 
and in addition using the buffer estimate the samples for each successive iteration are essentially independent. 


\subsection{One-dimensional mock data demonstration}

% Figure environment removed
We first test this iterative reweighting method on a simple mock dataset. 
We generate true event parameters drawing 30 event each from a truncated power law and a Gaussian distribution respectively;  
%such that half of the samples belong to each;
%the peak and other half are from Gaussian distribution. We use a 
the power law is $p(x) \sim x^{-0.5}$ and the Gaussian has mean (s.d.) of $\mu =35$ ($\sigma_p=3$).  
%If we take this random samples and compute AwKDE, we recover the peak of Gaussian distribution and power-law distribution. 
We then add measurement errors to our true parameters with a s.d.\ $\sigma_m = 5$, hence broader than the true Gaussian peak; 100 mock parameter samples with the same uncertainty are then generated around each ``measured'' value.   
% TD - say something about generating PE samples for each errored point [DONE] and then correctly describe what was done for the first plot 
First, applying awKDE as in \citet{Sadiq:2021fin} to random draws from these mock parameter samples, as expected we find an over-dispersed estimate around the peak (Fig.~\ref{fig:mockdatatest}, top). 

The second (bottom) plot of Fig.~\ref{fig:mockdatatest} shows the awKDE applying our iterative reweighting algorithm.  Here the Gaussian height and s.d.\ are accurately reconstructed and the true distribution is well within the 90\% percentiles of iteration samples, except at the step-function truncation of the power law which cannot be accurately represented by a Gaussian KDE. 
%
% Figure environment removed

We verify that the initial Markov process has accumulated several independent samples by plotting the autocorrelation of the optimized global bandwidth $h$ vs.\ lag (separation along the chain) in Fig.~\ref{fig:onedmockdata_autocorr}.  (We fix the adaptive sensitivity parameter $\alpha$ to unity for 1-d data.)  The autocorrelation drops near zero by a lag of $\lesssim\!10$ iterations, thus a buffer of 100 iterations contains several independent population estimates.  The estimate is more noisy for larger lags as fewer iterations are available. 

More detailed tests of iterative reweighting with a Gaussian KDE in two dimensions in the presence of correlated parameter errors are given in Appendix~\ref{app:2dmock}. 

%This example provide us confidence that this  iterative reweighting algorithm works on a simple test and can help reduce uncertainty issue incorporated in individual events. 
%We also try this idea on other mock dataset and getting some confidence with the results we apply this idea on our GW events sample to reconstruct AwKDE for observed GW BBH. 

%\textcolor{green}{ Should I describe it here of later in result? In terms of computational time we find that the construction of AwKDE is pretty fast and most time n computation is taken in optimzed bandwidth and smoothing parameter that is used for constructing AwKDE. }

%\subsection{Mock data tests of iterated reweighting}


\section{Results from GWTC-3}

As in \cite{Sadiq:2021fin}, as input to our analysis we use parameter estimation samples~\citep{ligo_scientific_collaboration_and_virgo_2021_5546663} for the set of \ac{BBH} events catalogued in GWTC-3~\citep{LIGOScientific:2021djp,LIGOScientific:2023vdi} with false alarm rate below 1 per year.  For the sensitivity estimate we employ a fit to search injection (simulated signal) results~\citep{2019dan,sensitivityDan} released with the catalog~\citep{ligo_scientific_collaboration_and_virgo_2021_5636816}. 


\subsection{One-dimensional mass distribution}
We start by evaluating the effect of the iterative reweighting method on the 1-d primary mass distribution, taking 100 random PE samples for each of the 69 \ac{BBH} events; here, we assume a power-law distribution for secondary mass $p(m_2) \sim q^{1.5}$.  We reproduce the awKDE results from~\cite{Sadiq:2021fin} 
%with semianalytic $VT$ estimates from~\citep{2019dan}. 
and use this estimate to seed the reweighted iteration algorithm.
%
%We follow our described algorithm of iterative reweighting on PE samples %for each event 
%and compute rate estimates at each step. 
After $\sim$1000 reweighting iterations 
%(ignoring the first few) reweighting 
we compute the median and symmetric 90\% interval from the last 900 rate estimates (the first 100 are used to set up a buffer for population weighting, as above): results are presented in Fig.~\ref{fig:iterativerate_1d}. 
%
% Figure environment removed

Our estimate is generally consistent with other non-parametric or semi-parametric approaches, represented by the \textsc{Flexible mixtures}, and \textsc{Power Law + Spline} models in \cite{KAGRA:2021duu}, and does not show the over-dispersion apparent in Figure 8 of \cite{Sadiq:2021fin}; specifically, we find a slightly higher and narrower peak around $35\,\msun$, but no identifiable feature around $20\,\msun$ \citep[compare][]{Tiwari:2021yvr,Toubiana:2023egi}. 
%
% TD - this discussion is now in the methods section
% 
%In order to construct the rate estimates, the AwKDE uses an optimized bandwidth and a smoothing (local) bandwidth parameter based on leave-one-out cross validation~\citep{Sadiq:2021fin}. Our iterative rate estimate depends of these optimized parameters for AwKDE and we can compute correlation for the successive iterative rate estimates using correlation in successive optimized bandwidth to check how our iterative schemes are related to each other. To compute correlation coefficient we use \textsc{NUMPY} \citep{harris2020array} module \textsc{corrcoeff}. This function takes arrays of optimized bandwidth for our iterative rate estimates and compute correlation coefficient matrix, 
%based on Pearson product-moment correlation coefficients \citep{1895RSPS...58..240P} 
%on consecutive iteration results. 


\subsection{Two—dimensional Mass Reconstruction}

Next, we apply our reweighting scheme on PE samples for both component masses and compute the two-dimensional (2-d) merger rate, using the estimated sensitive volume$\times$time (VT) as a function of the two masses.  We will first discuss various technical aspects of extending the 1-d calculation without assuming any power-law dependence for $m_2$. 
%and hence we did not assume any power-law for mass ratio to get rate as function of $m_1$ (
%as in our previous paper\citep{Sadiq:2021fin}). 
%We will use these two dimensional rate estimate to compute rate as function of component masses with numerically integrating 2D data. %This will make computations faster and without assuming any power-law assumption. 

\paragraph{Binary exchange symmetry}
Typically when presenting binary parameter estimates, the convention $m_1>m_2$ is applied.  However, all aspects of binary formation physics and event detection and parameter estimation will be invariant under swapping the component labels, i.e.\ exchanging $m_1 \leftrightarrow m_2$ (and at the same time exchanging the spins).  Thus, considering the differential merger rate $\mathcal R(m_1,m_2)$ as a function over the whole plane, it must also have a reflection symmetry about the line $m_1=m_2$.  To respect this symmetry and remove biases resulting from the apparent lack of support at $m_2>m_1$, we train and evaluate KDEs on \emph{reflected} sample sets which contain both the released PE samples, and copies of them with swapped components.   Note also that a power-law $m_2$ distribution implies the rate is a non-differentiable function at the equal mass line, whereas a KDE by construction is smooth and differentiable everywhere.

\paragraph{Choice of KDE parameters}
In previous work \citep{Sadiq:2021fin}, we mainly considered a KDE constructed over linear mass (or distance) parameters; however, here we choose the logarithms of component masses.  While this choice is not expected to have a large impact on the results, since the kernel bandwidth is free to locally adapt in either case, it is technically preferable for a few reasons: we avoid any possible KDE support at negative masses; there is a generally higher density of events towards lower masses considering the entire $3-100\,\msun$ range; the density of observed events also shows less overall variation over log coordinates; and when evaluating the KDE on a grid with equal spacing, fewer points are required to maintain precision for the low-mass region. 

For a 2-d KDE we also have a choice of kernel parameters, i.e.\ the Gaussian covariance matrix: given the similar or identical physical interpretation and range of values between $\ln m_1$ and $\ln m_2$, we choose a covariance proportional to the unit matrix, with an overall factor determined by the local adaptive bandwidth for each event. 

\paragraph{PE prior}
%Since we will apply integration to get rate in one dimensions we use log of masses for constructing our AwKDE and rate estimate. This will allow us to integrate properly even for small masses without having issues of lower number of sample points at lower mass values. 
%It is important to note that 
The PE samples released by LVK use a prior uniform in component masses~\citep{ligo_scientific_collaboration_and_virgo_2021_5546663} up to a factor dependent on cosmological redshift; we currently do not consider reweighting relative to the default PE cosmological model. 
As the prior is a density, it transforms with a Jacobian factor when changing variables to $\ln m_1, \ln m_2$, thus, we must divide the estimated rate $\mathcal{R}(\ln m_1, \ln m_2)$ by a prior $\propto m_1 m_2$ when obtaining reweighted draw probabilities. 
%
 % Figure environment removed

With these technical choices, we perform 1500 reweighting iterations in total, the first 600 using the Markov chain (i.e.\ the immediately preceding rate estimate) for sample draw weights, and the remaining 900 using the buffer median estimate. 
%
% Figure environment removed
%
Fig.~\ref{fig:twod_iterativerate} shows the rate estimate computed with iterative reweighting for BBH events in GWTC-3. 
%with log of masses is used.  
The autocorrelations of optimal global bandwidth and sensitivity parameter $\alpha$ for the first 600 iterations are shown in Fig.~\ref{fig:correlationbwd}: the correlation drops close to $0$ at a lag of $\sim\,$30 iterations. 

The mass distribution shows several interesting features in addition to the expected peaks (overdensities) around primary masses of $\sim\!10\,\msun$ and $\sim\!35\,\msun$, with corresponding peaks over secondary mass. 
For primary masses $\sim\!35\,\msun$ up to $80\,\msun$, the most likely secondary mass is 
%\mgq{perhaps a bit misleading, the m2 peak in Fig. 6 is at 25 Msun (typo?):}
% TD : no, this is read off from Fig.4 and the second panel of Fig.7.  The green curve in Fig 6 is integrated over all m1 and it is not just the 'second peak' that contributes. 
$\sim\!30\,$--$\,35\,\msun$.  Thus, over this range the two component masses appear almost independently chosen.  Around the $m_1 \sim 10\,\msun$ peak, there appears to be some \emph{anti-correlation} of the two components, i.e.\ higher $m_1$ favors lower $m_2$.  Between the two peaks the distribution of mass ratios appears broader than at either one \citep[as hinted at in][]{Tiwari:2023xff}, although the apparent trend is based on a small number of events.  We also see a narrow lower density region just above the $\sim\!10\,\msun$ peak (cf.\ the local minimum at chirp mass $\sim\!11\,\msun$ in \citealt{Tiwari:2023xff}). 

%\subsubsection{Binary to single parameters results}
% Figure environment removed
%
We also integrated the 2-d KDE rate estimate numerically over both $m_1$ and $m_2$ to obtain merger rates over component mass.  As shown in Fig.~\ref{fig:m1m21Drates}, we recover features consistent with the 2-d estimates and with other methods.  Each component mass distribution appears well modelled by a combination of two Gaussian peaks and (broken) power laws. 

%Note that this way of computing rate is a faster estimate and we reduce an order of magnitude computational time in these results.  % TD- here we would have to explain what other method it is faster *than*
%As shown in Fig.~\ref{fig:m1m21Drates}, the rate estimates as function of component masses, 
%We can see clear peak at $10\, \msun$ and $35\,\msun$ for primary mass and a bit shifted peaks $\sim 8\, \msun$ and $\sim32\,\msun$ for secondary masses.
% TD - I am not sure if this q=1 plot is worth showing or discussing - I made it just in order to see if we got a similar behaviour to the Callister/Farr autoregressive process paper
% 
%We also compute the rate from log masses fixing mass ratio to be 1 $q=1$ and  use the sliced data where this mass ratio was 1 and find that this rate estimates shows clear features that we see from two dimensional rate. As shown in Figure~\ref{fig:rate_lnm1lnm2_fixedq1}, the rate density in terms of log of masses 
%$\frac{d^2\mathcal{R}}{d ln\, m_1 d ln\,m_2}$  where we integrate rate estimate  with respect to secondary mass only for values for which mass ratio $q =1$. 
%
%% Figure environment removed

% Figure environment removed
% 
To elucidate features in the 2-d distribution, we choose various representative values of primary mass to plot the distribution of $m_2$ in Fig.~\ref{fig:secondarymassfixedm1}.  The similarity between secondary distributions for $m_1 \gtrsim 35\,\msun$ is evident.

% Figure environment removed
%
We may also derive the distribution of mass ratio $q$ from our 2-d rate estimate. 
%Since we are not assuming any power law distribution of mass ratio in our 2D estimates which is the assumption usually used in LVK analysis so we want to check if we can get consistent results with LVK assumption. 
We plot this for various representative values of primary mass in Fig.~\ref{fig:massratio}, and compare to a typical power law $\propto q^{1.5}$.  First, we see that the $q$ distribution varies over primary mass; hence, models where it is forced to the same form over the whole mass range are likely to have nontrivial bias.  For some primary masses, $p(q)$ is consistent with a monotonic increasing function such as a positive power, but for others it clearly decreases over some of the range.  Roughly, if $m_1$ is close to a peak then $p(q)$ is consistent with an increasing power law, but for other values the mass ratio rather shows a maximum at intermediate values, down to $q\sim 0.5$ for $m_1=15$ or $m_1=70$.

This behaviour may suggest that the primary and secondary masses are independently drawn from similar distributions, modulo a $q$-dependent ``pairing factor''~\citep{Fishbach:2019bbm} which influences the relative probability of binary merger.  However the preference towards $q\sim 1$ seen in previous work is not confirmed here.  \cite{Callister:2023tgi} reached a similar conclusion although assuming a ``universal'' $p(q)$ over all primary masses. 

\paragraph{Results including GW190814}
We also estimate the 2-d and 1-d integrated merger rates using our iterative reweighted KDE method when the outlier event GW190814~\citep{LIGOScientific:2020zkf}, which has a mass ratio $\mathcal{O}(10)$ and a secondary mass barely above the likely neutron star maximum mass, is included in the BBH population.  Detailed results are presented in Appendix~\ref{app:190814}: roughly summarizing the trends seen there, the bulk of the estimated distribution remains little changed by the addition of the extra event, although the peak in secondary mass below $10\,\msun$ is shifted towards lower values and both higher and broader; this is likely due to a general increase in KDE bandwidth when optimized with cross-validation.  (In parameterized models  the estimated mass distribution is also highly sensitive to inclusion of GW190814~\citep{Abbott:2020gyp,KAGRA:2021duu}.)  It is not clear whether other methods for bandwidth choice would yield more accurate estimates; higher event statistics in the low $m_2$ regime are clearly desirable. 

%Finally we compute rate as function of m1 and and compare our results with the power law spline and flexible mixture models reported in O3b Pop paper. We see our iterative method provide results in good agreement with other models.
%% Figure environment removed


\section{Discussion}

\paragraph{Summary of results}
In this work we undertook a detailed investigation of the full 2-d mass distribution of merging compact binary black holes observed by LIGO-Virgo-KAGRA up to the O3 run without assuming any specific functional form for the secondary mass or mass ratio, enabled by a new method of iterative density estimation to address mass measurement uncertainties.  Although we reproduce the broad features and local maxima seen in other parametric and non-parametric analyses, we find significantly less preference for near-equal masses than in most previous works; we also find that the mass ratio distribution cannot be described by a single function over the whole population \citep[compare][]{Tiwari:2023xff}.  For a range of primary masses, we find non-monotonically varying secondary and mass ratio distributions, thus a power-law dependence is ruled out. 
%This may arise from the very small count of detections with significantly unequal masses, which under an assumed power law dependence will imply a distribution peaking at $q=1$.  %TD - Not sure if this is really true given VT, and whether it fits into the discussion at this point
Furthermore, we find that for primary masses above $35\,\msun$ the secondary mass distribution is nearly independent of $m_1$, with a ``preferred partner'' mass of $m_2 \simeq 30-35\,\msun$.  Conversely, near the low-mass peak $m_1\simeq 10\,\msun$ we observe an anticorrelation between the two components, i.e.\ higher $m_1$ implies lower $m_2$. 

\paragraph{Possible astrophysical interpretations}
Our new estimate of the joint $m_1$--$m_2$ distribution may be compared to model predictions in the literature; because our individual component marginal distributions are similar to previous findings, we focus here on the mass ratio. Broadly speaking, we can distinguish model predictions from the isolated binary and dynamical channels.

The isolated binary channel predicts relatively flat $p(q)$ distributions \citep[e.g.][]{2020A&A...636A.104B,2021A&A...651A.100O} compared to the dynamical channel (see Fig. 2 in \citealt{Baibhav:2022qxm} and Fig.~1 in \citealt{Zevin2021}). Our estimates show in general flatter $q$ distributions than the GWTC-3 results presented in \citet{KAGRA:2021duu}. 

Because predictions for $p(q)$ in the isolated binary channel depend strongly on the adopted parameters \citep[see e.g.][]{2022MNRAS.516.5737B}, our results provide an important step towards constraining astrophysical parameters with GWs.  For example, the steep $p(q)$ found for very small common envelope efficiency parameter \citep[$\alpha_{\rm CE} \simeq 0.2$,][]{Baibhav:2022qxm} and the chemically homogeneous evolution model \citep{2016MNRAS.458.2634M} seem disfavoured, implying that these routes cannot account for the majority of the observed population. 

The stable mass transfer channel is efficient for primary masses near $\sim\!10\,\msun$. \cite{2022ApJ...940..184V} predicts a dearth of near-equal mass mergers, which is because the binary needs to be relatively unequal in mass during the second mass transfer phase for the orbit to shrink, but not too unequal to avoid unstable mass transfer.  This is only partly supported by our Fig.~\ref{fig:twod_iterativerate} in that the low-mass peak has support from equal mass out to $q\simeq 0.5$.  For some parameter choices their models predict bi-modality in $p(q)$, with peaks at $q\simeq0.35$ and $q\simeq0.75$: our results suggest a peak at $q\simeq0.8$ for $m_1\simeq10\,\msun$ and at $q\simeq0.45$ for $m_1\simeq15\,\msun$ (see Fig.~\ref{fig:massratio}), suggesting that a more detailed comparison may yield interesting constraints.
%These findings may provide interesting constraints on the parameters in the stable mass transfer model.

%% TODO MGi: Triple (Stegmann+), 
% Comparison different channels (Baibhav+)\\
For the dynamical channel, it is interesting to consider whether models now predict $q$ distributions that are too steeply rising.  \citet{2016PhRvD..93h4029R} modelled BBH mergers that formed dynamically in globular clusters: they find a median mass ratio of 0.87, with 68\% of sources having mass ratios $q>0.8$.  As shown in Fig.~\ref{fig:massratio} we find comparable support for near-equal mass only at $m_1 \sim 10\,\msun$ or $\sim\!35\,\msun$;  elsewhere our median $q$ is significantly lower.  

\citet{2023MNRAS.522..466A} model BBH merger in globular clusters in comparison to the GWTC-3 $q$ distribution: their model distributions are flatter and underestimate the power-law LVK fits by an order of magnitude at $q\simeq1$. 
%, with the exact difference slightly dependent on the adopted initial-final mass relation for BHs and the supernova details. 
% TD - I don't see this caveat as crucial to emphasize and it interrupts the flow IMO 
They find a final $q$ distribution flatter than the $q$ distribution of dynamically formed BBHs ($p(q)\propto q^4$ for metal-poor clusters) because the BH mass function is not always sufficiently sampled, such that a secondary BH with a mass similar to the primary is present in a cluster; and due to a slight bias against equal-mass BBH due to their lower inspiral probability. 
% TD - people should read the paper for an explanation with all details and caveats! 
%(for a given semi-major axis, eccentricity and $m_1$.
The reported $p(q)$ in their Fig.~1 is relatively flat for $q\gtrsim0.7$, qualitatively in agreement with our findings for $m_1\gtrsim 20\,\msun$ (Fig.~\ref{fig:massratio}, lower panel; their models cannot reproduce observed rates for lower-mass primaries.)  Due to the predicted pair instability gap, all BBH mergers in their models with $m_1\gtrsim50\,\msun$  are hierarchical mergers, i.e.\ a BBH in which at least one of the components is a BBH merger remnants that was retained in the cluster \citep[e.g.][]{Antonini2016,Rodriguez:2019huv,Kimball:2020qyd}.  Mergers with second-generation primaries are expected to have a mass ratio $q\simeq 0.5$, which is supported  by our distribution for $m_1=70\,\msun$ (Fig.~\ref{fig:massratio}). 

The $p(q)$ distribution is expected to be slightly flatter for dynamically formed BBHs in young (open) star clusters, because they have fewer BHs per cluster and their higher metallicities lead to steeper BH mass functions and therefore lower companion masses \citep[e.g.][]{2021MNRAS.503.3371B}. 
%
A accurate picture of the mass ratio distribution is therefore important to understand the relative contribution of dynamically formed BBHs in young (and metal-rich) and old (and metal-poor) star clusters; and also more generally for understanding the relative contributions of isolated and dynamically formed binaries in the population as a whole \citep{Zevin:2020gbd,Baibhav:2022qxm}. 
% papers which consider both isolated and dynamical channels at once - ArcaSedda ?
% We agree that all channels cannot have a q distribution peaked towards 1 ! 

An intriguing apparent feature in our reconstruction, the anticorrelation between $m_1$ and $m_2$ in the low-mass ($m\sim 10\,\msun$) peak, suggests a connection to isolated binary dynamics, though it would be premature to link it with a specific mechanism.

\paragraph{Technical issues and biases}
As noted in the introduction, measurement errors of the binary mass ratio are correlated with those in (orbit-aligned) spins.  Since we have so far not attempted to reconstruct or estimate the merging binary spin distribution, we implicitly assume that distribution is equal to the prior used for parameter estimation (uniform in magnitude and isotropic in direction): this is a potential source of bias which remains to be addressed by future work. The distribution of aligned spins has been found to be concentrated near zero, with a slight preference for positive aligned spin~\citep{Miller:2020zox,Abbott:2020gyp,KAGRA:2021duu}; hence, the degree of bias may be limited.  \cite{Callister:2021fpo} also note the intriguing possibility that the \emph{true} mass ratio and aligned spin (after allowing for measurement errors) are anti-correlated. 

A converse question concerns inferences on BH spin distributions which either assume a specific distribution in $q$, or a power law with index as a hyperparameter: if the $p(q)$ model is significantly inaccurate, are such spin inferences biased? (\citealt{Ng:2018neg} and~\citealt{Miller:2020zox} contain detailed discussion of potential biases in aligned spin population estimates.)  The effect may not be large, as most \ac{BBH} events by necessity have parameter values close to the observed peaks, for which we find a $q$ distribution which is not far from power-law. 

\paragraph{Extensions of the method}
As already noted, here we restricted the application of our KDE to the binary mass distribution; component spins, and distance or redshift are then the next relevant parameters for population analysis.  We expect to encounter a technical issue in optimizing the Gaussian kernel for a multi-dimensional data set, where it will not be appropriate (or even meaningful, given the different units) to impose equal variances over different parameters as we currently do for (log) $m_1$ and $m_2$.  For more than two dimensions a grid search may not be practicable; more sophisticated methods may be required in order to realize the potential of iterative KDE over a full set of population parameters. 


\section*{Acknowledgements}
We thank Daniel Wysocki for making available fitted sensitivity estimates for binary mergers in the O1-O3 data. 
We also benefited from conversations with Lieke van Son, Floor Broekgaarden and Fabio Antonini, and with Will Farr, Thomas Callister, Amanda Farah, Vaibhav Tiwari and others in the LVK Binary Rates \& Populations group. 
This work has received financial support from Xunta de Galicia (CIGUS Network of research centers), by European Union ERDF 
and by the ``María de Maeztu'' Units of Excellence program CEX2020-001035-M and the Spanish Research State Agency.  TD and JS are supported by research grant PID2020-118635GB-I00 from the Spanish Ministerio de Ciencia e Innovaci{\'o}n.  JS also acknowledges support from the European Union’s H2020 ERC Consolidator Grant ``GRavity from Astrophysical to Microscopic Scales'' (GRAMS-815673) and the EU Horizon 2020 Research and Innovation Programme under the Marie Sklodowska-Curie Grant Agreement No.\ 101007855. MG acknowledges support from the Ministry of Science and Innovation (EUR2020-112157, PID2021-125485NB-C22, CEX2019-000918-M funded by MCIN/AEI/10.13039/501100011033) and from AGAUR (SGR-2021-01069). 

The authors are grateful for computational resources provided by the LIGO Laboratory and supported by National Science Foundation Grants PHY-0757058 and PHY-0823459. This research has made use of data or software obtained from the Gravitational Wave Open Science Center (gwosc.org), a service of the LIGO Scientific Collaboration, the Virgo Collaboration, and KAGRA. This material is based upon work supported by NSF's LIGO Laboratory which is a major facility fully funded by the National Science Foundation, as well as the Science and Technology Facilities Council (STFC) of the United Kingdom, the Max-Planck-Society (MPS), and the State of Niedersachsen/Germany for support of the construction of Advanced LIGO and construction and operation of the GEO600 detector. Additional support for Advanced LIGO was provided by the Australian Research Council. Virgo is funded, through the European Gravitational Observatory (EGO), by the French Centre National de Recherche Scientifique (CNRS), the Italian Istituto Nazionale di Fisica Nucleare (INFN) and the Dutch Nikhef, with contributions by institutions from Belgium, Germany, Greece, Hungary, Ireland, Japan, Monaco, Poland, Portugal, Spain. KAGRA is supported by Ministry of Education, Culture, Sports, Science and Technology (MEXT), Japan Society for the Promotion of Science (JSPS) in Japan; National Research Foundation (NRF) and Ministry of Science and ICT (MSIT) in Korea; Academia Sinica (AS) and National Science and Technology Council (NSTC) in Taiwan.
%This paper has LIGO document number LIGO-P2300226.

\bibliography{reference}


\appendix

\section{Two-dimensional mock data test of iterative reweighting}
\label{app:2dmock}

% Figure environment removed
%
We here demonstrate iterative reweighted KDE over 2D mock data sets. We start with 60 mock events, 50\% from a two-dimensional uniform distribution and 50\% from a bi-variate normal (Gaussian) distribution. The normal distribution mean is $\mu = (50, 50)$ (in arbitrary units) and we take the two dimensions to be uncorrelated each with a variance of $9$.  
%covariance matrix with $\Sigma_p= = \begin{pmatrix} 9& 0 \\ 0 & 9\end{pmatrix}$) which shows the two dimensions are not correlated.
%This analytic distribution  is shown in top panel of Fig \ref{fig:mock2D}. 
We added error in our mock data values with an anti-correlation between the two dimensions using covariance $\Sigma_p= \bigl(\begin{smallmatrix} 32.5 & -31.5\\-31.5 & 32.5 \end{smallmatrix}\bigr)$, corresponding to an error ellipse with 8:1 axes at $45^\circ$, to mimic the anticorrelation between $m_1$ and $m_2$ along a contour of constant chirp mass.  
%We obtain this covariance matrix by rotating  covariance matrix $\Sigma_p=\begin{pmatrix} 64 &  0\\ 0 & 1\end{pmatrix}$ with a rotation of 45 degree. 
100 mock parameter samples with the same error covariance are then generated around each measured value.
We construct KDE on our errored data points and apply our reweighting scheme. The main idea we want to check if our scheme can reduce this artificial correlation we added in true distribution.  The left panel of Fig.~\ref{fig:mock2D} is the KDE estimate on errored data before applying iterative reweighting. We can clearly see an anti-correlation we added into our true distribution around the peaks $(50, 50)$. The right panel of Fig \ref{fig:mock2D} is the results after we apply our iterative reweighting scheme and use the last 900 iterations to get median curves. We can see that anti-correlation is removed and our method recovered the true distribution. This example shows that our method can reduce effect of artificial correlation in the real data.  We also compute 1-d results from these 2-d  iterative reweighted average results and compared this corresponding true distribution in 1-d that we expect from true 2-d distribution. Note that our 2-d distribution can be a union of two 1-d uniform distribution with a Gaussian peak $\mu= 50$.  Fig.~\ref{fig:1dfrom2dmockdata} shows the true distribution in 1d (black dashed) where the red curves are results of numerical integration of iterative reweighted KDE estimates for the last 900 iterations. The median (solid) red curve matched very closely to the true distribution and recover the peak height and width of Gaussian peak in true distribution.
% Figure environment removed

\section{Results including GW190814}
\label{app:190814}

% Figure environment removed
%
In addition to our main results from significant \ac{BBH} events in GWTC-3, we examine the effect of including the outlier event GW190814 \citep{LIGOScientific:2020zkf} with low secondary mass $m_2= 2.59\,\msun$ $(q=0.112)$.  We slightly extend the range of $m_2$ over which the KDE is evaluated in order to include the additional event. 
%to check if this asymmetric mass ratio event can affect the correlation between the masses in our estimate. 
Fig.~\ref{fig:twod_iterativeratewithgw190814} summarizes our results, which are also briefly discussed in the main text. 

\end{document}


%We implement this idea and find out that we have issues with shifting the data and hence new $f_{pop}$ do not converge to previous ones with reweighted values from itertive scheme.

%We follow these steps in our code
 
%\begin{itemize}
%    \item First we do have all PE samples file of detected GW events. Using python we will compute means $\Tilde{x}_i$ and standard deviations $\sigma_i$ of all those events PE-samples. 
%    \item If we want, using means and standard deviations we can compute $p(x_i)$ for each event. we will see these cancel outs below 
%    \item From the mean values (from all events) we get $f_{pop}$. One possible $f_{pop}$ choice can be  AwKDE  as we did in paper \href{https://arxiv.org/abs/2112.12659}{awkde}. Gaussian Kernel KDE. We can also use rate estimate as $f_{pop}$ by using VT corrections as function of m1 (as in  paper \href{https://arxiv.org/abs/2112.12659}{awkde}) and  will compute rate using $rate \sim KDE/VT(m1)$ 
%    \item For each event we can get $P_{rw}(x_i) = f(g_1, g_2,\Tilde{x}_i,\sigma_i)$
%    \item Now we will compute $g_1$ and $g_2$ for each event  using     




%\begin{equation*}
%   P_{rw} = \exp \left(  g_1 (x- x_i) + \frac{1}{2} g_2 (x-x_i)^2 \right) * p = f_{pop} * p
%\end{equation*}
%where $f_{pop} =$ rate or kde. we can cancel $p$  and taking $\log$ of equation, we get 

%$$\begin{equation*}
%   g_1 (x- x_i) + 1/2 g_2 (x-x_i)^2 = \ln\{f_{pop}\}  
%\end{equation*}
%Taking derivative with respect to x and g is already independent of x because it is value at $x=x_i$ (we normalized it)
%\begin{equation*}
 %   g_1  = \frac{d ln\{f_{pop(x)}\}}{dx} \bigg|_{x_i}  
%\end{equation*}
%another derivative gives
%\begin{equation*}
%    g_2  = \frac{d^2 ln\{f_{pop(x)}\}}{dx^2}  \bigg|_{x_i}
%\end{equation*}

%\item From the first and second derivatives of $f_{pop}$, we can compute $g_1$ and  %$g_2$ which are function of $x_i$ and  we can get their value at specific x (specific GW event) using  and this can be used to get new-mean and new-sigma for each event of GW.
%\item Using new mean values of each event we can get new $f_{pop}$ and repeat this procedure. Note that in each iteration new-mean and new sigma will be obtained from updated g1 and g2 but the  we always use original mean and sigma values from PE samples. 
%\item If $f_{pop}$ converges from one iteration to next several one we get a success.
%\end{itemize}


%\subsection{Results and Issues}
%When we use $f_{pop}$ to be rate (or KDE) their numerical derivative make $g_1$ and $g_2$ to be not normalize or smoothed and that can cause huge shifts in shifted mean values both in negative and positive. One of reason can be second derivatives issues at peaks and troughs. To overcome such issues we tried to apply running averages for (first only) $g_2$ and (than also of) $g_1$   at each event values following this procedure
%\begin{itemize}
%    \item We compute $g_2$ ($g_1$) with second (first) derivative of $\ln f_{pop}$
%    \item For each event we have a $g_2$ value and we also have sigma. Using a sigma window we compute average of g2 using 
%    \begin{equation*}
%        g_{2}^{smooth} = \frac{\sum_{i=x_i-\sigma_i}^{x_i+\sigma_i }g_2}{N}
%    \end{equation*}
    
%    where N is total points between $x_i-\sigma_i$ and $x_i+\sigma_i$
%   \item Use this $g_{2}^{smooth}$ values in the shifted formula \eqref{eq:shifted_mean}
%\end{itemize}


%This did not solve issue as we see a large shifts in the mean value which can be due to $\frac{1}{\sigma^2}$ to be larger than $g_2$. 

%\subsection{Modification: Product of $f_{pop}$ with a Gaussian Distribution }
%We Try new idea to avoid huge shifts in reweighting sample 
%\begin{itemize}
%    \item  For each event  we have its mean and (fixed) standard deviation. We multiply $f_pop$ with some (random) gaussian sample created using mean and sigma of each event to get reweighted samples
    
%    \begin{equation*}
%        P_{rw}(x_i) = f_{pop} \,* \, p(x_i) 
%    \end{equation*}
%    and compute the mean of this new reweighted sample $P_{rw}$ as shifted mean and follow this procedure iteratively.

%    \item To compute median of this $P_{rw}$ (product), we  compute the index of our grid (onto which we compute $f_{pop}$) at the 50\% area under curve and value of grid at that index gives us the shifted mean
%\end{itemize}

%\subsection{Modification: Re-weighting based on median of  previous 100 iterative %$f_{pop}$ results}
%\subsubsection{Using a mockdata samples}
%   Although we need to fix iterative procedure but we also need to show the robustness of this method for which we can try a mock data test. We have mock data of 60 values in each of 10 thousands datasets which is data for uniform distribution with a gaussian peak. We need both mean (that is those 60 values in each dataset)  and sigma. For sigma we will follow what we tried in peak analysis that is we tried error estimate from 90\% credible intervals of real distribution of GW events and use it to compute sigma in each of 60 values of each dataset. We will save this mock dataset with mean and sigma in hdf file and apply our method for each 10 thousand datasets and see if this iterative procedure can find KDE to converge to exact gaussian peak as we obtained in first data. This is to show this algorithm is robust.

%\newpage


%section{Optimization over bandwidth and location Variable}

% nice \href{https://www.sciencedirect.com/science/article/pii/S0167947309001261?via%3Dihub}{article} that hints on improving adaptive KDE is . Here we worked on algebraic expressions to get maximized bandwidth and location variables. 
%More details will be added later
%$The likelihood for Gaussian Kernels with inverse bandwidths $\newbbar$ and locations $m_i$
%is given by
%\begin{equation*}
%   \mathcal{L} = \frac{1}{(\sqrt{2\pi})^N}\prod_{k=1}^{N} \left[ \sum_{i=1}^{N} \newbbar_i \, \exp{\left(\frac{-(x_k-m_i)^2 \,  \newbbar_{i}^{2}}{2 } \right)} \right]
%end{equation*}
%log Likehood with some amendments can be written as 
%\begin{equation}
%\label{likelihoodbandwidthandlocation}
%   \log\, \mathcal{L} =  \frac{-N}{2} \log(2\pi) +  \sum_{k=1}^{N} \log \left[  \sum_{i=1}^{N} \left( \newbbar_i \, \exp{\left(\frac{-(x_k-m_i)^2 \,  \newbbar_{i}^{2}}{2 } \right)}   \right) \right]
%\end{equation}
%Now for maximizing this likelihood with respect to inverse bandwidth and locations we need 
%\begin{equation*}
%   \frac{d}{d\newbbar_i}\, \log\, \mathcal{L} =  0, \,\,\,\,
%   \frac{d}{dm_i}\, \log\, \mathcal{L} =  0,  
%\end{equation*}


%So lets first try simple case for just one location variable function as in the %paper and then generalize it to 2 variable case
%\\
%In paper we have 
%\begin{equation*}
%   \hat{f}_m (x)  = n^{-1} \sum_{i=1}^{n} K_h(x - m_i)
%\end{equation*}
%where $K_h(x - m_i) = \exp{(-(x-m_i)^2/2)}$

%The Loglikelihood function is  (product to sum with log)
%\begin{equation*}
%    \log \mathcal{L} = \sum_{k=1}^{n} \log \hat{f}_m (X_k)
%\end{equation*}
%Now they take derivative with respect to $m_l$ where $l=1,2,3 ...$
%\begin{equation*}
%    \frac{d}{dm_l} \log \mathcal{L} = \sum_{k=1}^{n} \frac{1} {\hat{f}_m (X_k)} \frac{d (\hat{f}_m (X_k))}{dm_l}
%\end{equation*}
%Now 

%\begin{equation*}
%    \frac{d}{dm_l} (\hat{f}_m (X_k)) =   \frac{d}{dm_l}  \sum_{i=1}^{n} %\exp{\left(\frac{-1}{2} (X_k - m_i)^2 \right)}
%\end{equation*}

%Now in the sum only $l=i$ term will be non zero and rest will be zero


%\begin{equation*}
%    \frac{d}{dm_l} (\hat{f}_m (X_k)) =      \exp{\left(\frac{-1}{2} (X_k - m_l)^2 \right)} \frac{d  (\frac{-1}{2} (X_k - m_l)^2) }{dm_l}
%\end{equation*}

%which gives

%\begin{equation*}
%    \frac{d}{dm_l} (\hat{f}_m (X_k)) = ( X_k - m_l)     \exp{\left(\frac{-1}{2} (X_k - m_l)^2 \right)} 
%\end{equation*} 


%4we finally get
%\%begin{equation*}
%    \frac{d}{dm_l} \log \mathcal{L} = \sum_{k=1}^{n} \frac{1} {\hat{f}_m (X_k)} ( X_k - m_l)     \exp{\left(\frac{-1}{2} (X_k - m_l)^2 \right)}
%\end{equation*}


%\section{Analytical Formulation for PE Error Correction}
%Our goal is to make KDE a self consistent scheme. In order to do it, we will follow the idea what is done in Bayesian Hierarchical analysis. Note that we cannot do exactly what Bayesian hiearchical analysis do with hyperparameters priors etc. See a nice review by Thrane and Talbot \href{https://arxiv.org/abs/1809.02293}{Bayesian analysis}.

%We want to extend AwKDE to work like hierarchical method in population analysis. 
%This first step is to get new median of PE samples by some error corrections using a probability density or population function representing all events (a KDE or rate distribution from all events median KDE). To correct these medians  we can start of with a simple idea with some idea let all events PE sample follows a Gaussian distribution with a mean and fixed standard distribution and we can reweighted PE samples by using a trick as below which requires some algebraic calculation.

%Lets assume that PE samples of each event follows a Gaussian distribution
%\begin{equation*}
%    p(x, \Tilde{x}_i, \Tilde{\sigma}_i) = \exp\left( -  \frac{(x-\tilde{x}_i)^2}{2 \Tilde{\sigma_i}^2}\right). 
%\end{equation*}
%Lets a population of all events follow some function $f_{pop}$
%which have a form 
%\begin{equation*}
%   f_{pop}(x, x_i) = K\,*\, \exp\left(g_{pop} (x, x_i) \right), 
%\end{equation*}
%where  K is constant which we can define as 

%\begin{equation*}
%K = \frac{1}{f_{pop}(x=x_i)} = \exp \left( - g(x=x_i) \right)
% \end{equation*}
%and that 
%\begin{equation*}
%g_{pop}(x)= g(x=x_i) + \frac{\partial g}{\partial x}|_{x_i} (x - x_i) + \frac{1}{2}\frac{\partial^2 g}{\partial x^2}|_{x_i} (x - x_i)^2+ ...
%\end{equation*}

%Siplify with constant we can write normalized $f_{pop}$ as 
%\begin{equation}
 %  f_{pop}(x) =  \exp \left( \frac{\partial g}{\partial x}|_{x_i} (x - x_i) + \frac{1%}{2}\frac{\partial^2 g}{\partial x^2}|_{x_i} (x - x_i)^2+ ... \right) , 
%\end{equation}
%lets use  $X = x - x_i, \, g_1 = \frac{\partial g}{\partial x}|_{x = x_i}, , \, g_2 = %\frac{\partial^2 g}{\partial x^2}|_{x = x_i}$
% 
%\begin{equation}
%   f_{pop}(x) =  \exp \left(  g_1 X +  g_2 \frac{X^2}{2}+ ... \right) , 
%\end{equation}
%and 
%\begin{equation*}
%    p(x, \Tilde{x}_i, \Tilde{\sigma}_i) = \exp\left( -  \frac{X^2}{2 \Tilde{\sigma_i}^2}\right). 
%\end{equation*}

%Now we can have likelihood of \textbf{an event} using Bayes theorem
%\begin{equation}
%    P_{rw}( \mathbf{x_i} | x, f_{pop}) = K_c * f_{pop} *p(x)
%\end{equation}
% where $K_c$ is a constant term and we can also write  
%\begin{equation}
%\label{eq:6}
%    P_{rw}(x_i| x, f_{pop}) = K_c \, * \exp \left(  g_1 X  +  g_2 \frac{X^2}{2} - \frac{ X^2}{2\sigma^2} + ... \right)
%\end{equation}


%Now the goal is to write above equation \eqref{eq:6} in Gaussian distribution form to find its mean and standard deviation in terms of given $g_{pop}$ and this will give us re-weighted PE samples that can reach close to true distribution. Let's ignore this constant and use upto $X^2$ terms in the exponential we get RHS of above equation as
 
%\begin{equation*}
%    RHS = \exp\left(Xg_1 + \frac{X^2 g_2}{2} -  \frac{X^2}{2\sigma^2} \right)
%\end{equation*}
%where $X = x - x_i, \, g_1 = \frac{\partial g}{\partial x}|_{x = x_i}$, $g_2 = \frac{\partial^2 g}{\partial x^2}|_{x = x_i}$,

%\begin{equation*}
%    RHS = \exp\left( - \left( \frac{ 1 -g_2 \sigma^2}{2\sigma^2} X^2 - g_1 X \right) \right)
%\end{equation*}
%
%Using  $a = \frac{1 - g_2 \sigma^2}{2\sigma^2}$ and $b = g_1$
%and using 
%\begin{equation*}
%    aX^2 - bX =  a \left( \left(X - \frac{b}{2a}\right)^2 - 
%    \left(\frac{b}{2a}\right)^2 \right)
%\end{equation*}
%W$e can write 


%\begin{equation}
%$$  P_{rw}(x_i)  = K_c \, * \exp\left( \frac{b^2}{4a}  \right) \exp \left( -a\left(X - \frac{b}{2a} \right)^2 \right)
%\end{equation}
%or
%\begin{equation}
%P_{rw}(x_i)    = K_c \, * \exp\left( \frac{b^2}{4a}  \right) \exp \left( - \frac{(X - b/2a)^2}{1/a} \right)
%\end{equation}

%Plug back   $a = \frac{1 - g_2 \sigma^2}{2\sigma^2}$ and $b = g_1$
%\begin{equation}
%    P_{rw}(x_i) = K_c\, *\exp \left( \frac{(g_1 \sigma)^2}{2(1- g_2 \sigma^2)} \right)  \exp\left(- \frac{(x- (x_i + \frac{g_1 \sigma^2}{1-g_2\sigma^2})^2}{2\sigma^2/(1 - g_2 \sigma^2)} \right)
%\end{equation}

%Simplifying and put into equation \eqref{eq:6}
%we get
%\begin{equation*}
%    P_{rw} =K_c \,* \exp \left(  \frac{(g_1 \sigma)^2}{2(1- g_2 \sigma^2)}  \right) \exp \left(  -  \frac{(x- (x_i + \frac{g_1 \sigma^2}{1-g_2 \sigma^2})^2}{2\sigma^2/(1 - g_2 \sigma^2)} \right), 
%\end{equation*}
%so re-weighted median of a PE sample for an event can be 
%\begin{equation}
%\label{eq:shifted_mean}
%\color{blue}
%\Tilde{x}_{new} = x_i  + \frac{g_1 \sigma^2}{1-g_2\sigma^2}
%\end{equation}
%and standard deviation is
%\begin{equation}
%\color{blue}
%\Tilde{\sigma}^2 _{new} = \frac{\sigma^2}{(1 - g_2 \sigma^2) } 
%\end{equation}
%and constant is 
%\begin{equation*}
%const =  K_c \, * \exp\left( \frac{(g_1 \sigma)^2}{2(1- g_2 \sigma^2)} \right)
%\end{equation*}

%So now we can use this idea for an iterative scheme and for each iteration we can get a new $f_{pop}$ and see it it converges that can take us to true distribution as close as possible.
%which is what is given in paper section 2

%\begin{equation*}
%    \sum_{k=1}^{n} \frac{1} {\hat{f}_m (X_k)} ( X_k - m_l)     \exp{\left(\frac{-1}{2} (X_k - m_l)^2 \right)} = 0 , \, \, \, \, l=1,2,...,n
%\end{equation*}

%\begin{equation*}
%    \sum_{k=1}^{n} \frac{1} {\hat{f}_m (X_k)}  X_k *  \exp{\left(\frac{-1}{2} (X_k - m_l)^2 \right)}    - \,  \textcolor{blue}{m_l} \, \sum_{k=1}^{n} \frac{1} {\hat{f}_m (X_k)} \,  * \,    \exp{\left(\frac{-1}{2} (X_k - m_l)^2 \right)} = 0 , \, \, \, \, l=1,2,...,n
%\end{equation*}


%\textcolor{red}{They get Iterative formula solving for $m_l$ but somehow in the %paper they do not take into account $m_l$ in the  exponential function and in main $\hat{f}_m(X_k)$. 
%They have iterative scheme}

%\begin{equation*}
%\color{blue}
%    m_{l}^{new} =  \frac{1} { \sum_{k=1}^{n} \frac{1} {\hat{f}_m (X_k)} \,      \exp{\left(\frac{-1}{2} (X_k - m_l)^2 \right)} } *\, \sum_{k=1}^{n} \frac{1} {\hat{f}_m (X_k)} ( X_k *  \exp{\left(\frac{-1}{2} (X_k - m_l)^2 \right)})
%\end{equation*}


%If we follow same for the generic case $\hat{f}_{m \, , \, b}$ and maximize for both variables we can get similar formulae


%\begin{equation*}
%   \hat{f}_{m,\newbbar} (x)  = n^{-1} \sum_{i=1}^{n} K_h[(x - m_i )*\newbbar_i]
%\end{equation*}
%where $K_h[(x - m_i)*\newbbar_i] = \newbbar_i \, \exp{\left( \frac{-(x-m_i)^2\newbbar_i^2}{2} \right)}$

%The log likelihood function is  (product to sum with log)
%\begin{equation*}
%    \log \mathcal{L} = \sum_{k=1}^{n} \log \hat{f}_{m\, ,\, \newbbar} (X_k)
%\end{equation*}
%Now they take derivative with respect to $m_l$ or $\newbbar_l$ where $l=1,2,3 ...$
%\begin{equation*}
%    \frac{d}{dm_l} \log \mathcal{L} = \sum_{k=1}^{n} \frac{1} {\hat{f}_{m\, ,\, \newbbar} (X_k)} \frac{d (\hat{f}_{m\, ,\, \newbbar} (X_k))}{dm_l}
%\end{equation*}

%\begin{equation*}
%    \frac{d}{d\newbbar_l} \log \mathcal{L} = \sum_{k=1}^{n} \frac{1} {\hat{f}_{m\, , \, \newbbar} (X_k)} \frac{d (\hat{f}_{m\, ,\, \newbbar} (X_k))}{d\newbbar_l}
%\end{equation*}

%ow 
%\begin{equation*}
%    \frac{d}{dm_l} (\hat{f}_{m \, , \, \newbbar} (X_k)) =   \frac{d}{dm_l}  \sum_{i=1}^{n} \newbbar_i \exp{\left(\frac{-1}{2} (X_k - m_i)^2 \, \newbbar_i^2 \right)}
%\end{equation*}

%which, after simplifying and having only term in sum ith index $l$ survived, gives

%\begin{equation*}
%    \frac{d}{dm_l} (\hat{f}_{m \, , \, \newbbar} (X_k)) =   \newbbar_l %\exp{\left(\frac{-1}{2} (X_k - m_l)^2 \, \newbbar_l^2 \right)}  \, * \, \left( %\newbbar_l^2 \, (X_k -m_l)  \right)
%\end{equation*}

%So now we get
%\begin{equation*}
%     \frac{d}{dm_l} \log \mathcal{L} = \sum_{k=1}^{n} \frac{1} {\hat{f}_{m\, ,\, \newbbar} (X_k)}  \, \, \newbbar_l \exp{\left(\frac{-1}{2} (X_k - m_l)^2 \, \newbbar_l^2 \right)}  \, * \, \left( \newbbar_l^2 \, (X_k -m_l)  \right)  = 0 \,\, , \,\,\,\, l = 1,2,3...,n
%\end{equation*}
%Solving above for $m_l$  as for simple case assuming $m_l$ inside exponential and $\hat{f}$ is old we get iterative scheme


%\begin{equation*}
%    m_{l}^{new} = \frac{ \sum_{k=1}^{n} \frac{1} {\hat{f}_{m\, ,\, \newbbar} (X_k)}  \, \, \newbbar_l \exp{\left(\frac{-1}{2} (X_k - m_l)^2 \, \newbbar_l^2 \right)}  \, * \, \left( \newbbar_l^2 \, X_k  \right) } { \sum_{k=1}^{n} \frac{1} {\hat{f}_{m\, ,\, \newbbar} (X_k)}  \, \, \newbbar_l \exp{\left(\frac{-1}{2} (X_k - m_l)^2 \, \newbbar_l^2 \right)}  \, * \, \left( \newbbar_l^2   \right)}
%\end{equation*}

%This looks same as in simple case as we can cancel $\newbbar_l^2$ term
%So final expression looks like

%\begin{equation*}
%\color{blue}
%    m_{l}^{new} = \frac{ \sum_{k=1}^{n} \frac{1} {\hat{f}_{m\, ,\, \newbbar} (X_k)}  \, \, \newbbar_l \exp{\left(\frac{-1}{2} (X_k - m_l)^2 \, \newbbar_l^2 \right)}  \, * \,  X_k  } { \sum_{k=1}^{n} \frac{1} {\hat{f}_{m\, ,\, \newbbar} (X_k)}  \, \, \newbbar_l \exp{\left(\frac{-1}{2} (X_k - m_l)^2 \, \newbbar_l^2 \right)}  \, }  \,\, , \,\,\,\, l = 1,2,3...,n
%\end{equation*}
%Repeating above with maximization with respect to $\newbbar_l$
%4\begin{equation*}
 %$$   \frac{d}{d\newbbar_l} (\hat{f}_{m \, , \, \newbbar} (X_k)) =   \frac{d}{d\newbbar_l}  \sum_{i=1}^{n} \newbbar_i \exp{\left(\frac{-1}{2} (X_k - m_i)^2 \, \newbbar_i^2 \right)}
%\%end{equation*}
%Again in sum only term $l=i$ survives and we need now product of terms in derivative
%\begin{equation*}
%    \frac{d}{d\newbbar_l} (\hat{f}_{m \, , \, \newbbar} (X_k)) =  [1]*  \exp{\left(\frac{-1}{2} (X_k - m_l)^2 \, \newbbar_l^2 \right)} + \newbbar_l \, [\exp{\left(\frac{-1}{2} (X_k - m_l)^2 \, \newbbar_l^2 \right)} \, *  2\,\newbbar_l \frac{-1}{2} (X_k - m_l)^2 ]
%\end{equation*}
%which gives 
%\begin{equation*}
%    \frac{d}{d\newbbar_l} (\hat{f}_{m \, , \, \newbbar} (X_k)) =    \newbbar_l \,\exp{\left(\frac{-1}{2} (X_k - m_l)^2 \, \newbbar_l^2 \right)} \left(  \frac{1}{\newbbar_l} - \newbbar_l \, *  (X_k - m_l)^2  \right) 
%\end{equation*}

%We have now 

%\begin{equation*}
%     \frac{d}{d\newbbar_l} \log \mathcal{L} = \sum_{k=1}^{n} \frac{1} {\hat{f}_{m\, ,\, \newbbar} (X_k)}  \, \, \newbbar_l \exp{\left(\frac{-1}{2} (X_k - m_l)^2 \, \newbbar_l^2 \right)}  \, * \, \left(\frac{1}{\newbbar_l} - \newbbar_l \, *  (X_k - m_l)^2  \right)  = 0 \,\, , \,\,\,\, l = 1,2,3...,n
%\end{equation*}
% or 
% \begin{equation*}
%      \sum_{k=1}^{n} \frac{1} {\hat{f}_{m\, ,\, \newbbar} (X_k)}  \,  \exp{\left(\frac{-1}{2} (X_k - m_l)^2 \, \newbbar_l^2 \right)}  \, * \, \left( 1 - \newbbar_l^2 \, *  (X_k - m_l)^2  \right)  = 0 \,\, , \,\,\,\, l = 1,2,3...,n
%\end{equation*}



%If we simplify this we have expressions for $\newbbar_l$ as
%\begin{equation*}
%\color{blue}
%    \newbbar_l^{new}=  \sqrt{ \frac{  \sum_{k=1}^{n} \frac{1} {\hat{f}_{m\, ,\, \newbbar} (X_k)}  \,  \exp{\left(\frac{-1}{2} (X_k - m_l)^2 \, \newbbar_l^2 \right)}} {  \sum_{k=1}^{n} \frac{1} {\hat{f}_{m\, ,\, \newbbar} (X_k)}  \, \,  \exp{\left(\frac{-1}{2} (X_k - m_l)^2 \, \newbbar_l^2 \right)}  \, \, *  (X_k - m_l)^2 } }    \,\, , \,\,\,\, l = 1,2,3...,n
%\end{equation*}
