

\section{Introduction}  \label{sec:1}
\vspace{-1.5mm}

Segmentation is a critical task in medical image analysis.
%Contemporary 
Known approaches mainly utilize \textit{discrete} data representations (e.g., rasterized label masks) with convolutional neural networks (CNNs) \cite{isensee2021nnu,fan2020pranet,ronneberger2015unet,gu2021kcbac} or Transformers \cite{hatamizadeh2022unetr,hassani2021CCT} to classify image entities in a bottom-up manner.
While undeniably effective, this paradigm suffers from \textit{two primary limitations}.
(1) These approaches have limited spatial flexibility and poor computational scaling.
Retrieving predictions at higher resolutions would require either increasing the input size, which decreases performance and incurs quadratic or cubic memory increases, or interpolating output predictions, which introduces discretization artifacts.
(2) Per-pixel or voxel learning inadequately models object shapes/boundaries, which are central to both robust computer vision methods and our own visual cortical pathways~\cite{pasupathy2015neuralprimatebasis}. 
This often results in predictions with unrealistic object shapes and locations~\cite{raju2022dissm}, especially in settings with limited annotations and out-of-distribution data.

Instead of segmenting structures with \textit{discrete} grids, we explore the use of Implicit Neural Representations (INRs) which employ \textit{continuous} representations to compactly capture coordinate-based signals (e.g., objects in images). 
INRs represent object shapes with a parameterized function $f_\theta: (\textbf{p}, \textbf{z}) \rightarrow [0, 1]$ that maps continuous spatial coordinates $\textbf{p} = (x, y, z)$, $x, y, z \in [-1,1]$ and a shape embedding vector $\textbf{z}$ to occupancy scores.
This formulation enables direct modeling of object contours as the decision boundary of $f_\theta$, superior memory efficiency~\cite{dupont2021coincompressionINR}, and smooth predictions at arbitrary resolutions that are invariant to input size. 
INRs have been adopted in the vision community for shape reconstruction~\cite{Chibane2020IFNet,Park2019DeepSDF,Mescheder2018OccNet,chabra2020deeplocalshape}, texture synthesis~\cite{oechsle2019texture}, novel view synthesis~\cite{Mildenhall2020NeRFRS}, and segmentation~\cite{hu2022ifanet}.
Medical imaging studies have also used INRs to learn organ templates \cite{yang2022implicitatlas}, synthesize cell shapes \cite{wiesner2022inrCellShape}, and reconstruct radiology images \cite{shen2022nerp}.

The adoption of INRs for medical image segmentation, however, has been limited where most existing approaches directly apply pipelines designed for 3D reconstruction to images.
These works emphasize either global embeddings $\textbf{z}$ or point-wise ones.
OSSNet \cite{Reich2021OSSNetME} encodes a global embedding from an entire volume and an auxiliary local image patch to guide voxel-wise occupancy prediction. 
Although global shape embeddings facilitate overall shape coherence, they neglect the fine-grained details needed to delineate local boundaries.
The local patches partially address this issue but lack contextual understanding beyond the patches and neglect mid-scale information. 
% Small image patch encodings are also incorporated since global embeddings cannot accurately model local details (e.g., boundaries).
% Using cropped patches, however, fails to leverage neighboring context.
% However, inputting small image patches fails to leverage neighboring context and may not adequately encode mid-scale information. 
In an effort to enhance local acuity and contextual modeling, IFA~\cite{hu2022ifanet}, IOSNet~\cite{Khan2022IOSNet}, and NUDF~\cite{Srensen2022NUDF} each extract a separate embedding for every input coordinate by concatenating point-wise features from multi-scale CNN feature maps.
Although more expressive, point-wise features still lack sufficient global contextual understanding and suffer from the same unconstrained prediction issues observed in discrete segmentation methods.
Moreover, these methods use components designed for shape reconstruction---a domain where synthetic data is abundant and the modeling of texture, multi-class discrimination, and multi-scale contexts are less crucial.
% Further, DISSM~\cite{raju2022dissm} takes a separate approach and uses INRs in a Statistical Shape Model schema to construct templates to be non-rigidly aligned and refined. 
% Although effective, this approach is not end-to-end and contains components such as non-rigid alignment and boundary refinement that are difficult to train and operate expensively in discrete space.


To address these limitations, we propose \textbf{SwIPE (\underline{S}egmentation \underline{w}ith \underline{I}mplicit \underline{P}atch \underline{E}mbeddings)} which learns continuous representations of foreground shapes at the patch level. 
% Operating on patches rather than the entire image or points better enables both local boundary details and global shape coherence.
By decomposing objects into parts (i.e., patches), we aim to enable both accurate local boundary delineation and global shape coherence. 
This also improves model generalizability and training efficiency since local curvatures often reoccur across classes or images. 
%(see Table~\autoref{tab:2}). 
% which decomposes images into a uniform grid of patches and objects into parts. 
% Our method decomposes images into a uniform grid of patches and objects into parts, enabling more accurate local boundary delineation and regional shape coherence.
% This also improves model generalization since 
% and avoid polarization of patch embeddings toward either local or global features
SwIPE first encodes an image into descriptive patch embeddings and then decodes the point-wise occupancies using these embeddings.
To avoid polarization of patch embeddings toward either local or global features in the encoding step, we introduce a context aggregation mechanism that fuses multi-scale feature maps and propose a \textbf{Multi-stage Embedding Attention (MEA)} module to dynamically extract relevant features from all scales. 
This is driven by the insight that different object parts necessitate variable focus on either global/abstract (important for object interiors) or local/fine-grained information (essential around object boundaries). 
To enhance global shape coherence across patches in the decoding step, we augment local embeddings with global information and propose \textbf{Stochastic Patch Overreach (SPO)} to improve continuity around patch boundaries.
Comprehensive evaluations are conducted on two tasks (2D polyp and 3D abdominal organ segmentation) across four datasets.
SwIPE outperforms the best-known implicit methods (+6.7\% \& +4.5\% F1 on polyp and abdominal, resp.) and beats task-specific discrete approaches (+2.5\% F1 on polyp) with 10x fewer parameters.
We also demonstrate SwIPE's superior model \& data efficiency in terms of network size \& annotation budgets, and greater robustness to data shifts across image resolutions and datasets. Our main \textbf{contributions} are as follows.
\vspace*{-2.4mm}
\begin{enumerate}
    \item Away
    %Deviating 
    from discrete representations, we are the first to showcase the merits of patch-based implicit neural representations for medical image segmentation. 
    % Our method, SwIPE (\underline{S}egmentation \underline{w}ith \underline{I}mplicit \underline{P}atch \underline{E}mbeddings), can output predictions of arbitrary resolutions with favorable memory scaling and directly model object shapes.
    % , and makes significant design improvements over previous implicit-based segmentation methods.
    \item We propose a new efficient attention mechanism, Multi-stage Embedding Attention (MEA), to improve contextual understanding during the encoding step, and Stochastic Patch Overreach (SPO) to address boundary continuities during occupancy decoding.
    % demonstrate the importance of contextual understanding for modeling local shapes and introduce an efficient attention mechanism, multi-stage embedding attention (MEA), that dynamically extracts information from multiple feature abstraction levels.
    % For accurate decoding, we propose Stochastic Patch Overreach (SPO) that enhances boundary continuity and cross-patch understanding.
    \item We perform detailed evaluations of SwIPE and its components on two tasks (2D polyp segmentation and 3D abdominal organ segmentation). We not only outperform 
    %recent 
    state-of-the-art implicit and discrete methods, but also 
    %demonstrate 
    yield improved data \& model efficiency and better robustness to data shifts.
\end{enumerate}


% To obtain descriptive patch embeddings, we introduce a context aggregation module to fuse multi-scale feature maps and propose an efficient attention mechanism to dynamically weigh multi-scale features.
% This is driven by the insight that different parts of an object necessitate different degrees of attention on global/abstract and local/fine-grained details.
% Further, to augment global shape coherence across patches, we adopt three mechanisms to improve continuity at patch boundaries and regularize the global shape.
% For robust patch prediction with adequate global shape regularization, we propose three mechansisms to help achieve this.
% We introduce a stochastic patch overreach scheme to alleviate boundary discontinuity between patches and faciliate contextual understanding beyond a local scope. 
% We also condition local patches on global embeddings. 












