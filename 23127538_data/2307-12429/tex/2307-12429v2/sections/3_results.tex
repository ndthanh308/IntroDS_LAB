
\vspace{-3mm}
\section{Experiments and Results} \label{sec:3}
\vspace{-1mm}

This section presents quantitative results from \textbf{four main studies}, analyzing overall performance, robustness to data shifts, model \& data efficiency, and ablation \& component studies.
For more implementation details, experimental settings, and qualitative results, we refer readers to the Supplementary Material. 

% This section presents quantitative and qualitative results with \textbf{four main studies}.
% 1) Overall performance compared to state-of-the-art implicit and discrete methods.
% 2) Robustness to data shifts across different image resolutions, datasets, and modalities. 
% 3) Model and data efficiency with varying backbone sizes and annotation availability.
% 4) Ablations and component choices to study the contributions and design choices for each proposed component.




\vspace{-4mm}
\subsection{Datasets, Implementations, and Baselines} \label{sec:3-1}
\vspace{-1.5mm}

We evaluate performance on two tasks: 2D binary polyp segmentation and 3D multi-class abdominal organ segmentation. 
For polyp segmentation, we train on the challenging \textbf{Kvasir-Sessile} dataset \cite{jha2021sessilecomprehensive} (196 colored images of small sessile polyps), and use \textbf{CVC-ClinicDB} \cite{bernal2015cvc} to test model robustness.  
For 3D organ segmentation, we train on \textbf{BCV} \cite{bcv2015} (30 CT scans, 13 annotated organs), and
use the diverse CT images in \textbf{AMOS} \cite{ji2022amos} (200 training CTs, the same setting used in~\cite{zhang2022spade}) to evaluate model robustness. 
% given its diverse acquisition profile.
All the datasets are split with a 60:20:20 train:validation:test ratio. 
For each image in Sessile [in BCV, resp.], we obtain 4000 [20,000] background points and sample 2000 [4000] foreground points for each class with half of every class' foreground points lying within 10 pixels [voxels] of the boundary.

2D Sessile Polyp training uses a modified Res2Net \cite{gao2019res2net} backbone with 28 layers, [256, 256, 256] latent MLP dimensions for $D^\mathbb{P}$, [256, 128] latent dimensions for $D^\mathbb{I}$, $d=128$, $S=32$, and $con=8$.
3D BCV training uses a Res2Net-50 backbone, [256, 256, 256, 256] latent MLP dimensions for $D^\mathbb{P}$, [256, 256, 128] latent MLP dimensions for $D^\mathbb{I}$, $d=512$, $S=8$, and $con=6$ (all adjoining patches in 3D).
The losses for both tasks are optimized with AdamW~\cite{Loshchilov2017DecoupledWDAdamW} and use $\alpha$=$0.5$, $\beta$=$0.1$, and $\lambda$=$0.0001$.
For inference, we adopt MISE like prior works~\cite{Mescheder2018OccNet,Khan2022IOSNet,Reich2021OSSNetME} and evaluate on a reconstructed prediction mask equal in size to the input image.
$D^\mathbb{P}$ segments boundaries better than $D^\mathbb{I}$, and is used to produce final predictions. 
% We refer readers to the supplementary section for more details.

For fair comparisons, all the methods are trained using the same equally-weighted Dice and Cross Entropy loss for 30,000 and 50,000 iterations on 2D Sessile and 3D BCV, resp.
The test score at the best validation epoch is reported. 
Image input sizes were $384\times384$ for Sessile and $96\times96\times96$ for BCV.
All the implicit methods utilize the same pre-sampled points for each image.
For IOSNet~\cite{Khan2022IOSNet}, both 2D and 3D backbones were upgraded from three downsampling stages to five for fair comparisons and empirically confirmed to outperform the original. 
We omit comparisons against IFA~\cite{hu2022ifanet} to focus on medical imaging approaches; plus, IFA did not outperform IOSNet~\cite{Khan2022IOSNet} on either task. 


\input{tables/table2}

\vspace{-4mm}
\subsection{Study 1: Performance Comparisons} \label{sec:3-2}
\vspace{-1.5mm}

The results for 2D Polyp Sessile and 3D CT BCV organ segmentation are presented in Table~\ref{tab:1}.
FLOPs are reported from the forward pass on a single image during training. 

On the smaller polyp dataset, we observe notable improvements over the best-known implicit approaches (+6.7\% Dice) and discrete methods (+2.5\% Dice) with much fewer parameters (9\% of PraNet~\cite{fan2020pranet} and 66\% of IOSNet~\cite{Khan2022IOSNet}).
For BCV, the performance gains are more muted; however, we still marginally outperform UNETR~\cite{hatamizadeh2022unetr} with over 20x fewer parameters and comparable FLOPs.


\vspace*{-5mm}
\subsection{Study 2: Robustness to Data Shifts} \label{sec:3-3}
\vspace*{-1.5mm}

% We explore the robustness of different methods to image resolution changes and dataset distribution shifts (see left and middle of Table~\ref{tab:2})
In this study, we explore the robustness of various methods to specified target resolutions and dataset shifts.
The left-most table in Table~\ref{tab:2} contains results for the former study conducted on 2D Sessile, where we first analyze the effect of directly resizing outputs (Tab.~\ref{tab:2} left, rows 1 to 6) when given an input image that is standard during training ($384\times384$). 
The discrete method, PraNet, outputs $384\times384$ predictions which are interpolated to the target size (Tab.~\ref{tab:2} left, rows 1 \& 4).
This causes more performance drop-offs than the implicit methods which can naturally vary the output size by changing the resolution of the input coordinates.
We also vary the input size so that no manipulations of predictions are required (Tab.~\ref{tab:2} left, rows 7 \& 8), which results in steep accuracy drops.

The results for the dataset shift study are given in the middle of Table~\ref{tab:2}, where CVC is another binary poly segmentation task and the liver class is evaluated on all CT scans in AMOS.
Both discrete methods outperform IOSNet, which may indicate that point-based features are more prone to overfitting due to a lack of contextual regularization. 
Also, we highlight our method's consistent outperformance over both discrete methods and IOSNet in all of the settings.

% , we study the robustness of the best discrete and implicit method on the Polyp Sessile task to varying prediction resolutions.
% First, we analyze the effect of resizing outputs (rows 1 to 6) and input the standard $384\times384$ image size seen during training.
% For PraNet, $384\times384$ predictions are outputted and then resized to the desired output size, while implicit methods vary output size by changing the number of predicted coordinates.
% Implicit methods demonstrate their spacial flexibility and maintain high performances.
% Between implicit approaches, our patch-based schema yields better performance across the board.
% Second, we analyze the effect of varying the input size to match the target output size.
% We omit implicit methods here since they can predict masks at arbitrary resolutions using their training resolution.
% We observe steep performance declines with the discrete method probably due to drastic content differences in usual receptive fields.

% Further we study robustness to data shifts in the same task across datasets.
% For polyp segmentation, we see general outperformance of PraNet over IOSNet.
% Limitations of point-wise feature aggregation over those that aggregate features specially (i.e. convolutions).
% For 3D segmentation, we predict the liver class in AMOS CT images to gauge shape realism. 


\input{tables/table3}


\vspace*{-4mm}
\subsection{Study 3: Model Efficiency and Data Efficiency} \label{sec:3-4}
\vspace*{-1.5mm}

% In medical image segmentation, model efficiency is important due to the limited computation budgets of many clinics or labs while data efficiency is paramount given the scarcity of annotation in medical data. 
To analyze the model efficiency (the right-most column of charts in Table~\ref{tab:2}), we report on 2D Sessile and vary the backbone size in terms of depth and width.
For data efficiency, we train using 10\%, 25\%, 50\%, and 100\% of annotations. 
% Experiments were conducted on 2D polyp sessile segmentation which often involves an examination using devices with limited compute and where labels are expensive to obtain.
Not only do we observe outperformance across the board in model sizes \& annotation amounts, but the performance drop-off is more tapered with our method.

\vspace*{-4mm}
\subsection{Study 4: Component Studies and Ablations} \label{sec:3-5}
\vspace*{-1.5mm}

%Finally, 
The left side of Table~\ref{tab:3} presents our ablation studies, showing the benefits enabled by context aggregation within $E_n$, global information conditioning, and adoption of MEA \& SPO. 
We also explore alternative designs on the right side of Table~\ref{tab:3} for our three 
%most important 
key components, and affirm their contributions 
%toward 
on achieving superior performance.




