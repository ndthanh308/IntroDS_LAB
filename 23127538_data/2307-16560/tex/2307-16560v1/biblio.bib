@article{abel2020witness,
  author    = {Zachary Abel and
               Jeffrey Bosboom and
               Michael J. Coulombe and
               Erik D. Demaine and
               Linus Hamilton and
               Adam Hesterberg and
               Justin Kopinsky and
               Jayson Lynch and
               Mikhail Rudoy and
               Clemens Thielen},
  title     = {Who witnesses The Witness? Finding witnesses in The Witness is hard
               and sometimes impossible},
  journal   = {Theor. Comput. Sci.},
  volume    = {839},
  pages     = {41--102},
  year      = {2020},
  _url       = {https://doi.org/10.1016/j.tcs.2020.05.031},
  _doi       = {10.1016/j.tcs.2020.05.031},
  _timestamp = {Fri, 04 Sep 2020 10:49:37 +0200},
  _biburl    = {https://dblp.org/rec/journals/tcs/AbelBCDHHKLRT20.bib},
  _bibsource = {dblp computer science bibliography, https://dblp.org}
}

@InProceedings{Culberson1999,
	author = 	 {Joseph C. Culberson},
	title = 	 {{S}okoban is {PSPACE}-{C}omplete},
	booktitle =	 {Fun With Algorithms},
	pages =	 {65--76},
	year =	 {1999}
}

@Article{hutter2005adaptive,
  author =       "Marcus Hutter and Jan Poland",
  title =        "Adaptive Online Prediction by Following the Perturbed Leader",
  volume =       "6",
  _month =        apr,
  year =         "2005",
  pages =        "639--660",
  journal =      "Journal of Machine Learning Research",
  publisher =    "Microtome",
  _issn =         "1532-4435",
}

@Article{veness2011mcaixi,
  author =       "J. Veness and K. S. Ng and M. Hutter and W. Uther and D. Silver",
  title =        "A {M}onte-{C}arlo {AIXI} Approximation",
  journal =      "Journal of Artificial Intelligence Research",
  volume =       "40",
  pages =        "95--142",
  _publisher =    "AAAI Press",
  _month =        jan,
  year =         "2011",
  _doi =          "10.1613/jair.3125",
  _issn =         "1076-9757",
}

@InProceedings{veness2012ensemble,
  author =       "Joel Veness and Peter Sunehag and Marcus Hutter",
  title =        "On Ensemble Techniques for {AIXI} Approximation",
  booktitle =    "Proc. 5th Conf. on Artificial General Intelligence ({AGI'12})",
  series =       "LNAI",
  volume =       "7716",
  pages =        "341--351",
  _editor =       "J. Bach and B. Goertzel and M. Ikle",
  publisher =    "Springer, Heidelberg",
  _address =      "Oxford, UK",
  _month =        dec,
  year =         "2012",
  _bibtex =       "http://www.hutter1.net/official/bib.htm#aixiens",
  _pdf =          "http://www.hutter1.net/publ/aixiens.pdf",
  _slides =       "http://www.hutter1.net/publ/saixiens.pdf",
  _project =      "http://www.hutter1.net/official/projects.htm#uai",
  _doi =          "10.1007/978-3-642-35506-6_35",
  _issn =         "0302-9743",
  _isbn =         "978-3-642-35505-9",
  _support =      "ARC grant DP120100950",
  _for =          "080401(20%),010404(30%),080101(30%)",
  _seo =          "970108(100%)",
  _znote =        "Acceptance rate: 34/80 = 42\%.",
}

@inproceedings{veness2013partition,
  author    = {J. Veness and
               M. White and
               M. Bowling and
               A. Gy{\"{o}}rgy},
  title     = {Partition Tree Weighting},
  booktitle = {2013 Data Compression Conference, {DCC} 2013, Snowbird, UT, USA, March
               20-22, 2013},
  year      = {2013},
  pages     = {321--330},
  crossref  = {DBLP:conf/dcc/2013},
  _doi       = {10.1109/DCC.2013.40},
}

@proceedings{DBLP:conf/dcc/2013,
  editor    = {Ali Bilgin and
               Michael W. Marcellin and
               Joan Serra{-}Sagrist{\`{a}} and
               James A. Storer},
  title     = {2013 Data Compression Conference, {DCC} 2013, Snowbird, UT, USA, March
               20-22, 2013},
  year      = {2013},
  publisher = {{IEEE}},
  _isbn      = {978-1-4673-6037-1},
  timestamp = {Tue, 21 Oct 2014 19:50:13 +0200},
  biburl    = {http://dblp.uni-trier.de/rec/bib/conf/dcc/2013},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}

@inproceedings{orseau2012memory,
  author    = {L. Orseau and
               M. Ring},
  title     = {Memory Issues of Intelligent Agents},
  booktitle = {Artificial General Intelligence - 5th International Conference, {AGI}
               2012, Oxford, UK, December 8-11, 2012. Proceedings},
  pages     = {219--231},
  year      = {2012},
  crossref  = {DBLP:conf/agi/2012},
  _timestamp = {Wed, 05 Dec 2012 13:06:56 +0100},
  _biburl    = {http://dblp.uni-trier.de/rec/bib/conf/agi/OrseauR12a},
  _bibsource = {dblp computer science bibliography, http://dblp.org}
}

@proceedings{DBLP:conf/agi/2012,
  _editor    = {Joscha Bach and
               Ben Goertzel and
               Matthew Ikl{\'{e}}},
  title     = {Artificial General Intelligence - 5th International Conference, {AGI}
               2012, Oxford, UK, December 8-11, 2012. Proceedings},
  series    = {Lecture Notes in Computer Science},
  volume    = {7716},
  publisher = {Springer},
  _doi       = {10.1007/978-3-642-35506-6},
  _isbn      = {978-3-642-35505-9},
  _timestamp = {Wed, 05 Dec 2012 12:56:42 +0100},
  _biburl    = {http://dblp.uni-trier.de/rec/bib/conf/agi/2012},
  _bibsource = {dblp computer science bibliography, http://dblp.org},
  year      = {2012}
}

@Book{Hutter2004uaibook,
  author =       "Marcus Hutter",
  title =        "Universal Artificial Intelligence:
                  Sequential Decisions based on Algorithmic Probability",
  _series =       "EATCS",
  publisher =    "Springer",
  address =      "Berlin",
  year =         "2005",
  _isbn =         "3-540-22139-5",
  _isbn-online =  "978-3-540-26877-2",
  support =      "SNF grant 2000-61847",
}

@Article{lattimore2011time,
  author =       "Tor Lattimore and Marcus Hutter",
  title =        "General Time Consistent Discounting",
  journal =      "Theoretical Computer Science",
  volume =       "519",
  pages =        "140--154",
  publisher =    "Elsevier",
  _month =        jan,
  year =         "2014",
  _issn =         "0304-3975",
}

@inproceedings{glasmachers2011optimal,
  author    = {Tobias Glasmachers and Juergen Schmidhuber},
  title     = {Optimal Direct Policy Search},
  booktitle = {Artificial General Intelligence - 4th International Conference, {AGI}
               2011, Mountain View, CA, USA, August 3-6, 2011. Proceedings},
  pages     = {52--61},
  year      = {2011},
  crossref  = {DBLP:conf/agi/2011},
}


@inproceedings{orseau2011self,
  author    = {Laurent Orseau and Mark Ring},
  title     = {Self-Modification and Mortality in Artificial Agents},
  booktitle = {Artificial General Intelligence - 4th International Conference, {AGI}
               2011, Mountain View, CA, USA, August 3-6, 2011. Proceedings},
  pages     = {1--10},
  year      = {2011},
  crossref  = {DBLP:conf/agi/2011},
}

@inproceedings{ring2011delusion,
  author    = {Mark B. Ring and
               Laurent Orseau},
  title     = {Delusion, Survival, and Intelligent Agents},
  booktitle = {Artificial General Intelligence - 4th International Conference, {AGI}
               2011, Mountain View, CA, USA, August 3-6, 2011. Proceedings},
  pages     = {11--20},
  year      = {2011},
  crossref  = {DBLP:conf/agi/2011},
  _url       = {http://dx.doi.org/10.1007/978-3-642-22887-2_2},
  _doi       = {10.1007/978-3-642-22887-2_2},
  _timestamp = {Tue, 10 Jan 2012 07:35:36 +0100},
  _biburl    = {http://dblp.uni-trier.de/rec/bib/conf/agi/RingO11},
  _bibsource = {dblp computer science bibliography, http://dblp.org}
}

@proceedings{DBLP:conf/agi/2011,
  _editor    = {J{\"{u}}rgen Schmidhuber and
               Kristinn R. Th{\'{o}}risson and
               Moshe Looks},
  title     = {Artificial General Intelligence - 4th International Conference, {AGI}
               2011, Mountain View, CA, USA, August 3-6, 2011. Proceedings},
  series    = {Lecture Notes in Computer Science},
  volume    = {6830},
  publisher = {Springer},
  year      = {2011},
  _url       = {http://dx.doi.org/10.1007/978-3-642-22887-2},
  _doi       = {10.1007/978-3-642-22887-2},
  _isbn      = {978-3-642-22886-5},
  _timestamp = {Thu, 04 Aug 2011 08:38:04 +0200},
  _biburl    = {http://dblp.uni-trier.de/rec/bib/conf/agi/2011},
  _bibsource = {dblp computer science bibliography, http://dblp.org}
}

@techreport{armstrong2010utility,
  AUTHOR =        {Stuart Armstrong},
  TITLE =         {Utility Indifference},
  NUMBER =        {\#2010-1},
  INSTITUTION =   {Future of Humanity Institute, Oxford University},
  YEAR  =         {2010},
  PAGES =         {1--5},
  FILE  =         {http://www.fhi.ox.ac.uk/utility-indifference.pdf},
}

@article{veness2014cnf:arxiv,
  author    = {Joel Veness and
               Marcus Hutter},
  title     = {Online Learning of k-CNF Boolean Functions},
  journal   = {CoRR},
  volume    = {abs/1403.6863},
  year      = {2014},
  _url       = {http://arxiv.org/abs/1403.6863},
  _timestamp = {Tue, 01 Apr 2014 11:56:46 +0200},
  _biburl    = {http://dblp.uni-trier.de/rec/bib/journals/corr/VenessH14},
  _bibsource = {dblp computer science bibliography, http://dblp.org}
}

@paper{veness2015online,
    author = {Joel Veness and Marcus Hutter and Laurent Orseau and Marc Bellemare},
    title = {Online Learning of k-CNF Boolean Functions},
    conference = {International Joint Conference on Artificial Intelligence},
    year = {2015},
    keywords = {},
    _abstract = {This paper revisits the problem of learning a k-CNF Boolean function from examples, for fixed k, in the context of online learning under the logarithmic loss. We give a Bayesian interpretation to one of Valiant’s classic PAC learning algorithms, which we then build upon to derive three efficient, online, probabilistic, supervised learning algorithms for predicting the output of an unknown k-CNF Boolean function. We analyze the loss of our methods, and show that the cumulative log-loss can be upper bounded by a polynomial function of the size of each example.},
    _url = {http://www.aaai.org/ocs/index.php/IJCAI/IJCAI15/paper/view/11221}
}

@article{aji2000generalized,
  title={The generalized distributive law},
  author={Aji, Srinivas M and McEliece, Robert J},
  journal={Information Theory, IEEE Transactions on},
  volume={46},
  number={2},
  pages={325--343},
  year={2000},
  publisher={IEEE}
}

@inproceedings{veness2012context,
  title={Context tree switching},
  author={Veness, Joel and Ng, Kee Siong and Hutter, Marcus and Bowling, Michael},
  booktitle={Data Compression Conference (DCC), 2012},
  pages={327--336},
  year={2012},
  organization={IEEE}
}

@TechReport{veness2012ssdc,
  author =       "Joel Veness and Marcus Hutter",
  title =        "Sparse Sequential {D}irichlet Coding",
  institution =  "UoA and ANU",
  number =       "arXiv:1206.3618",
  _month =        jun,
  year =         "2012",
  _bibtex =       "http://www.hutter1.net/official/bib.htm#ssdc",
  _url =          "http://arxiv.org/abs/1206.3618",
  _pdf =          "http://www.hutter1.net/publ/ssdc.pdf",
  _latex =        "http://www.hutter1.net/publ/ssdc.tex",
  _slides =       "http://www.hutter1.net/publ/ssad.pdf",
  _project =      "http://www.hutter1.net/official/projects.htm#compress",
  _keywords =     "Dirichlet prior; KT estimator; sparse coding;
                  small/large alphabet; data compression.",
  _abstract =     "This short paper describes a simple coding technique, Sparse
                  Sequential Dirichlet Coding, for multi-alphabet memoryless
                  sources. It is appropriate in situations where only a small,
                  unknown subset of the possible alphabet symbols can be expected
                  to occur in any particular data sequence. We provide a
                  competitive analysis which shows that the performance of Sparse
                  Sequential Dirichlet Coding will be close to that of a
                  Sequential Dirichlet Coder that knows in advance the exact
                  subset of occurring alphabet symbols. Empirically we show that
                  our technique can perform similarly to the more computationally
                  demanding Sequential Sub-Alphabet Estimator, while using less
                  computational resources.",
  _for =          "080401(100%)",
  _seo =          "970108(80%),890205(20%)",
}

@book{steele2004cauchy,
  title={The Cauchy-Schwarz Master Class: An Introduction to the Art of Mathematical Inequalities},
  author={Steele, J.M.},
  isbn={9780521546775},
  lccn={2004040402},
  series={MAA problem books series},
  url={https://books.google.co.uk/books?id=7GDyRMrlgDsC},
  year={2004},
  publisher={Cambridge University Press}
}

@InProceedings{hutter2014off2on,
  author =       "Marcus Hutter",
  title =        "Offline to Online Conversion",
  booktitle =    "Proc. 25th International Conf. on Algorithmic Learning Theory ({ALT'14})",
  _address =      "Bled, Slovenia",
  series =       "LNAI",
  volume =       "8776",
  _editor =       "Peter Auer and Alexander Clark",
  publisher =    "Springer",
  pages =        "230--244",
  _month =        oct,
  year =         "2014",
  _bibtex =       "http://www.hutter1.net/official/bib.htm#off2on",
  _url =          "http://arxiv.org/abs/1407.3334",
  _pdf =          "http://www.hutter1.net/publ/off2on.pdf",
  _latex =        "http://www.hutter1.net/publ/off2on.tex",
  _slides =       "http://www.hutter1.net/publ/soff2on.pdf",
  _project =      "http://www.hutter1.net/official/projects.htm#infoth",
  _issn =         "0302-9743",
  _isbn =         "978-3-319-11661-7",
  _doi =          "10.1007/978-3-319-11662-4_17",
}

@INPROCEEDINGS{tjalkens1993saw,
    author = {Tjalling J. Tjalkens and Yuri M. Shtarkov and Frans M. J. Willems},
    title = {Sequential weighting algorithms for multialphabet sources},
    booktitle = {6th Joint Swedish-Russian Int. Worksh. Inform. Theory},
    year = {1993},
    pages = {22--27}
}

@ARTICLE{orlitsky2004universal,
    author={A. Orlitsky and N. P. Santhanam and Junan Zhang},
    journal={IEEE Transactions on Information Theory},
    title={Universal compression of memoryless sources over unknown alphabets},
    year={2004},
    volume={50},
    number={7},
    pages={1469-1481},
    _doi={10.1109/TIT.2004.830761},
    _ISSN={0018-9448},
    month={July},
}

@proceedings{DBLP:conf/dcc/2015,
  title     = {2015 Data Compression Conference, {DCC} 2015, Snowbird, UT, USA, April
               7-9, 2015},
  publisher = {{IEEE}},
  year      = {2015},
  _url       = {http://ieeexplore.ieee.org/xpl/mostRecentIssue.jsp?punumber=7147631},
  _isbn      = {978-1-4799-8430-5},
  _timestamp = {Wed, 08 Jul 2015 13:21:46 +0200},
  _biburl    = {http://dblp2.uni-trier.de/rec/bib/conf/dcc/2015},
  _bibsource = {dblp computer science bibliography, http://dblp.org}
}

@Article{li2011kwik,
    author="Li, Lihong and Littman, Michael L. and Walsh, Thomas J. and Strehl, Alexander L.",
    title="Knows what it knows: {A} framework for self-aware learning",
    journal="Machine Learning",
    year="2011",
    volume="82",
    number="3",
    pages="399--443",
    issn="1573-0565",
    _doi="10.1007/s10994-010-5225-4",
    _url="http://dx.doi.org/10.1007/s10994-010-5225-4"
}

@InProceedings{lattimore2011evenbits,
  author =       "Tor Lattimore and Marcus Hutter and Vaibhav Gavane",
  title =        "Universal Prediction of Selected Bits",
  booktitle =    "Proc. 22nd International Conf. on Algorithmic Learning Theory ({ALT'11})",
  _address =      "Espoo, Finland",
  series =       "LNAI",
  volume =       "6925",
  _editor =       "J. Kivinen and C. Szepesv{\'a}ri and E. Ukkonen and T. Zeugmann",
  publisher =    "Springer",
  pages =        "262--276",
  _month =        oct,
  year =         "2011",
  _bibtex =       "http://www.hutter1.net/official/bib.htm#evenbits",
  _conf =         "http://www-alg.ist.hokudai.ac.jp/~thomas/ALT11/alt11c.html",
  _url =          "http://arxiv.org/abs/1107.5531",
  _pdf =          "http://www.hutter1.net/publ/evenbits.pdf",
  _latex =        "http://www.hutter1.net/publ/evenbits.tex",
  _slides =       "http://www.hutter1.net/publ/sevenbits.pdf",
  _project =      "http://www.hutter1.net/official/projects.htm#ait",
  _doi =          "10.1007/978-3-642-24412-4_22",
  _issn =         "0302-9743",
  _isbn =         "3-642-24411-4",
}

@article{auer2002adaptive,
    author = "Peter Auer and Nicolò Cesa-Bianchi and Claudio Gentile",
    title = "Adaptive and Self-Confident On-Line Learning Algorithms",
    journal = "Journal of Computer and System Sciences",
    volume = "64",
    number = "1",
    pages = "48 - 75",
    year = "2002",
    note = "",
    _issn = "0022-0000",
    _doi = "http://dx.doi.org/10.1006/jcss.2001.1795",
    _url = "http://www.sciencedirect.com/science/article/pii/S0022000001917957",
    _pdf = "http://homes.dsi.unimi.it/~cesabian/Pubblicazioni/jcss-02.pdf",
    _keywords = "on-line prediction",
    _keywords = "linear regression",
    _keywords = "quasi-additive algorithms",
    _keywords = "learning rate"
}

@article{amodei2016concrete,
   author = {{Amodei}, Dario and {Olah}, Christopher and {Steinhardt}, Jacob and {Christiano}, Paul and {Schulman}, John and {Man{\'e}}, Dan},
    title = "{Concrete Problems in AI Safety}",
  journal = {ArXiv e-prints},
archivePrefix = "arXiv",
   eprint = {1606.06565},
 primaryClass = "cs.AI",
 keywords = {Computer Science - Artificial Intelligence, Computer Science - Learning},
     year = 2016,
    month = jun,
   adsurl = {http://adsabs.harvard.edu/abs/2016arXiv160606565A},
  adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

% Use published version instead
article{everitt2016self:arxiv,
  title={Self-Modification of Policy and Utility Function in Rational Agents},
  author={Everitt, Tom and Filan, Daniel and Daswani, Mayank and Hutter, Marcus},
  journal={arXiv preprint arXiv:1605.03142},
  year={2016}
}

@inproceedings{everitt2016self,
  author    = {Tom Everitt and
               Daniel Filan and
               Mayank Daswani and
               Marcus Hutter},
  title     = {Self-Modification of Policy and Utility Function in Rational Agents},
  booktitle = {Artificial General Intelligence - 9th International Conference, {AGI}
               2016, New York, NY, USA, July 16-19, 2016, Proceedings},
  pages     = {1--11},
  crossref  = {DBLP:conf/agi/2016},
  _url       = {http://dx.doi.org/10.1007/978-3-319-41649-6_1},
  _doi       = {10.1007/978-3-319-41649-6_1},
  _timestamp = {Mon, 27 Jun 2016 15:18:37 +0200},
  _biburl    = {http://dblp.uni-trier.de/rec/bib/conf/agi/EverittFDH16},
  _bibsource = {dblp computer science bibliography, http://dblp.org},
  year      = {2016},
}

@inproceedings{everitt2016wireheading,
  author    = {Tom Everitt and
               Marcus Hutter},
  title     = {Avoiding Wireheading with Value Reinforcement Learning},
  booktitle = {Artificial General Intelligence - 9th International Conference, {AGI}
               2016, New York, NY, USA, July 16-19, 2016, Proceedings},
  pages     = {12--22},
  year      = {2016},
  crossref  = {DBLP:conf/agi/2016},
  _url       = {http://dx.doi.org/10.1007/978-3-319-41649-6_2},
  _doi       = {10.1007/978-3-319-41649-6_2},
  _timestamp = {Mon, 27 Jun 2016 15:18:37 +0200},
  _biburl    = {http://dblp.uni-trier.de/rec/bib/conf/agi/EverittH16},
  _bibsource = {dblp computer science bibliography, http://dblp.org}
}

@proceedings{DBLP:conf/agi/2016,
  _editor    = {Bas R. Steunebrink and
               Pei Wang and
               Ben Goertzel},
  title     = {Artificial General Intelligence - 9th International Conference, {AGI}
               2016, New York, NY, USA, July 16-19, 2016, Proceedings},
  series    = {Lecture Notes in Computer Science},
  volume    = {9782},
  publisher = {Springer},
  _url       = {http://dx.doi.org/10.1007/978-3-319-41649-6},
  _doi       = {10.1007/978-3-319-41649-6},
  _isbn      = {978-3-319-41648-9},
  _timestamp = {Mon, 27 Jun 2016 15:11:46 +0200},
  _biburl    = {http://dblp.uni-trier.de/rec/bib/conf/agi/2016},
  _bibsource = {dblp computer science bibliography, http://dblp.org},
  year      = {2016}
}

@article{hibbard2012model,
  title = {Model-based Utility Functions},
  author = {Bill Hibbard},
  _doi = {10.2478/v10229-011-0013-5},
  _url = {http://dx.doi.org/10.2478/v10229-011-0013-5},
  year  = {2012},
  _month = {jan},
  publisher = {Walter de Gruyter {GmbH}},
  volume = {3},
  number = {1},
  pages = {1--24},
  journal = {Journal of Artificial General Intelligence}
}

@Inbook{orseau2012space,
    author="Orseau, Laurent and Ring, Mark",
    _editor="Bach, Joscha
    and Goertzel, Ben
    and Ikl{\'e}, Matthew",
    title="Space-Time Embedded Intelligence",
    bookTitle="Artificial General Intelligence: 5th International Conference, AGI 2012, Oxford, UK, December 8-11, 2012. Proceedings",
    year="2012",
    publisher="Springer Berlin Heidelberg",
    address="Berlin, Heidelberg",
    pages="209--218",
    _isbn="978-3-642-35506-6",
    _doi="10.1007/978-3-642-35506-6_22",
    _url="http://dx.doi.org/10.1007/978-3-642-35506-6_22"
}

@article{erven2012catching,
    author = {{van} Erven, Tim and Grünwald, Peter and {de} Rooij, Steven},
    title = {Catching up faster by switching sooner: a predictive approach to adaptive estimation with an application to the AIC–BIC dilemma},
    journal = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
    volume = {74},
    number = {3},
    publisher = {Blackwell Publishing Ltd},
    _issn = {1467-9868},
    _url = {http://dx.doi.org/10.1111/j.1467-9868.2011.01025.x},
    _doi = {10.1111/j.1467-9868.2011.01025.x},
    pages = {361--417},
    _keywords = {Adaptive estimation, AIC, Bayesian model averaging, BIC, Model selection, Risk convergence},
    year = {2012},
}

@article{koolen2013universal,
    author = {Koolen, Wouter M. and {de} Rooij, Steven},
    title = {Universal Codes From Switching Strategies},
    journal = {IEEE Trans. Inf. Theor.},
    issue_date = {November 2013},
    volume = {59},
    number = {11},
    month = nov,
    year = {2013},
    _issn = {0018-9448},
    pages = {7168--7185},
    _numpages = {18},
    _url = {http://dx.doi.org/10.1109/TIT.2013.2273353},
    _doi = {10.1109/TIT.2013.2273353},
    _acmid = {2690600},
    publisher = {IEEE Press},
    _address = {Piscataway, NJ, USA},
}

% Adahedge with doubling trick
@inproceedings{erven2011adaptive,
  title={Adaptive hedge},
  author={{van} Erven, Tim and Koolen, Wouter M and {de} Rooij, Steven and Gr{\"u}nwald, Peter},
  booktitle={Advances in Neural Information Processing Systems},
  pages={1656--1664},
  year={2011}
}

% AdaHedge without the doubling trick
% https://jmlr.org/papers/volume15/rooij14a/rooij14a.pdf
@article{derooij2014follow,
 author = {{de} Rooij, Steven and {van} Erven, Tim and Gr\"{u}nwald, Peter D. and Koolen, Wouter M.},
 title = {Follow the Leader if You Can, {H}edge if You Must},
 journal = {J. Mach. Learn. Res.},
 _issue_date = {January 2014},
 volume = {15},
 number = {1},
 month = jan,
 year = {2014},
 _issn = {1532-4435},
 pages = {1281--1316},
 _numpages = {36},
 _url = {http://dl.acm.org/citation.cfm?id=2627435.2638576},
 _acmid = {2638576},
 _publisher = {JMLR.org},
 _keywords = {hedge, learning rate, mixability, online learning, prediction with expert advice},
}

@inproceedings{vanerven2016metagrad,
 author = {van Erven, Tim and Koolen, Wouter M},
 booktitle = {Advances in Neural Information Processing Systems},
 _editor = {D. Lee and M. Sugiyama and U. Luxburg and I. Guyon and R. Garnett},
 pages = {},
 _publisher = {Curran Associates, Inc.},
 title = {MetaGrad: Multiple Learning Rates in Online Learning},
 _url = {https://proceedings.neurips.cc/paper/2016/file/14cfdb59b5bda1fc245aadae15b1984a-Paper.pdf},
 volume = {29},
 year = {2016}
}



@inproceedings{volf1998switching,
    title={Switching between two universal source coding algorithms},
    author={Volf, Paul AJ and Willems, Frans MJ},
    booktitle={Data Compression Conference, 1998. DCC'98. Proceedings},
    pages={491--500},
    year={1998},
    organization={IEEE}
}

@article{baker2009action,
  title={Action understanding as inverse planning},
  author={Baker, Chris L and Saxe, Rebecca and Tenenbaum, Joshua B},
  journal={Cognition},
  volume={113},
  number={3},
  pages={329--349},
  year={2009},
  publisher={Elsevier}
}

@book{dennett1989intentional,
  Author = {Daniel C. Dennett},
  Title = {The Intentional Stance (MIT Press)},
  Publisher = {A Bradford Book},
  Year = {1989},
  ISBN = {0-262-54053-3},
  _URL = {https://www.amazon.com/Intentional-Stance-MIT-Press-ebook/dp/B004A16KOK%3FSubscriptionId%3D0JYN1NVW651KCA56C102%26tag%3Dtechkie-20%26linkCode%3Dxm2%26camp%3D2025%26creative%3D165953%26creativeASIN%3DB004A16KOK}
}

@book{ahmed2014evidence,
  Author = {Arif Ahmed},
  Title = {Evidence, Decision and Causality},
  Publisher = {Cambridge University Press},
  Year = {2014},
  ISBN = {1107020891},
  _URL = {https://www.amazon.com/Evidence-Decision-Causality-Arif-Ahmed/dp/1107020891%3FSubscriptionId%3D0JYN1NVW651KCA56C102%26tag%3Dtechkie-20%26linkCode%3Dxm2%26camp%3D2025%26creative%3D165953%26creativeASIN%3D1107020891}
}

@Article{wolpert2013lesson,
    author="Wolpert, David H.and Benford, Gregory",
    title="The lesson of Newcomb's paradox",
    journal="Synthese",
    year="2013",
    volume="190",
    number="9",
    pages="1637--1646",
    _abstract="In Newcomb's paradox you can choose to receive either the contents of a particular closed box, or the contents of both that closed box and another one. Before you choose though, an antagonist uses a prediction algorithm to accurately deduce your choice, and uses that deduction to fill the two boxes. The way they do this guarantees that you made the wrong choice. Newcomb's paradox is that game theory's expected utility and dominance principles appear to provide conflicting recommendations for what you should choose. Here we show that the conflicting recommendations assume different probabilistic structures relating your choice and the algorithm's prediction. This resolves the paradox: the reason there appears to be two conflicting recommendations is that the probabilistic structure relating the problem's random variables is open to two, conflicting interpretations. We then show that the accuracy of the prediction algorithm in Newcomb's paradox, the focus of much previous work, is irrelevant. We end by showing that Newcomb's paradox is time-reversal invariant; both the paradox and its resolution are unchanged if the algorithm makes its `prediction' after you make your choice rather than before.",
    issn="1573-0964",
    _doi="10.1007/s11229-011-9899-3",
    _url="http://dx.doi.org/10.1007/s11229-011-9899-3"
}

@article{krichevsky1981performance,
  title={The performance of universal encoding},
  author={Krichevsky, R and Trofimov, V},
  journal={IEEE Transactions on Information Theory},
  volume={27},
  number={2},
  pages={199--207},
  year={1981},
  publisher={IEEE}
}

@inproceedings{ng2000irl,
    _abstract = {This paper addresses the problem of inverse reinforcement learning (IRL) in Markov decision processes, that is, the problem of extracting a reward function given observed, optimal behaviour. IRL may be useful for apprenticeship learning to acquire skilled behaviour, and for ascertaining the reward function being optimized by a natural system. We rst characterize the set of all reward functions for which a given policy is optimal. We then derive three algorithms for IRL. The rst two deal with the case where the entire policy is known; we handle tabulated reward functions on a nite state space and linear functional approximation of the reward function over a potentially in- nite state space. The third algorithm deals with the more realistic case in which the policy is known only through a nite set of observed trajectories. In all cases, a key issue is degeneracythe existence of a large set of reward functions for which the observed policy is optimal. To remove...},
    author = {Ng, Andrew and Russell, Stuart},
    booktitle = {Proceedings of the Seventeenth International Conference on Machine Learning},
    _doi = {10.2460/ajvr.67.2.323},
    _editor = {{De Sousa}, Jorge Pinho},
    _file = {:C$\backslash$:/Users/valko/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Ng, Russell - 2000 - Algorithms for inverse reinforcement learning(2).pdf:pdf},
    _issn = {00029645},
    pages = {663--670},
    _pmid = {16454640},
    publisher = {Morgan Kaufmann Publishers Inc.},
    title = {{Algorithms for inverse reinforcement learning}},
    _url = {http://www-cs.stanford.edu/people/ang/papers/icml00-irl.pdf},
    year = {2000}
}

@article{ramachandran2007birl,
    _abstract = {Inverse Reinforcement Learning (IRL) is the problem of learning the reward function underlying a Markov Decision Process given the dynamics of the system and the behaviour of an expert. IRL is motivated by situations where knowledge of the rewards is a goal by itself (as in preference elicitation) and by the task of apprenticeship learning (learning policies from an expert). In this paper we show how to combine prior knowledge and evidence from the expert's actions to derive a probability distribution over the space of reward functions. We present efficient algorithms that find solutions for the reward learning and apprenticeship learning tasks that generalize well over these distributions. Experimental results show strong improvement for our methods over previous heuristic-based approaches.},
    author = {Ramachandran, Deepak and Amir, Eyal},
    journal = {Proceedings of the 20th International Joint Conference on Artificial Intelligence},
    _keywords = {markov decision processes,reinforcement learning},
    pages = {2586--2591},
    title = {{Bayesian Inverse Reinforcement Learning}},
    _url = {http://www.aaai.org/Papers/IJCAI/2007/IJCAI07-416.pdf},
    volume = {51},
    year = {2007}
}

@Book{sutton1998reinforcement,
  Title                    = {Reinforcement Learning : An Introduction},
  Author                   = {Richard S. Sutton and Andrew G. Barto},
  Publisher                = {MIT Press},
  Year                     = {1998}
}

@book{russell2003aima,
 author = {Russell, Stuart J. and Norvig, Peter},
 title = {Artificial Intelligence: A Modern Approach},
 year = {2003},
 _isbn = {0137903952},
 edition = {2},
 publisher = {Pearson Education},
}

@inproceedings{russell1998learning,
 author = {Russell, Stuart},
 title = {Learning Agents for Uncertain Environments (Extended Abstract)},
 booktitle = {Proceedings of the Eleventh Annual Conference on Computational Learning Theory},
 series = {COLT' 98},
 year = {1998},
 _isbn = {1-58113-057-0},
 _location = {Madison, Wisconsin, USA},
 pages = {101--103},
 numpages = {3},
 _url = {http://doi.acm.org/10.1145/279943.279964},
 _doi = {10.1145/279943.279964},
 _acmid = {279964},
 publisher = {ACM},
 address = {New York, NY, USA},
}

@InProceedings{rothkopf2011preference,
  author =       {Constantin A. Rothkopf and Christos Dimitrakakis},
  title =        {Preference Elicitation and Inverse Reinforcement Learning},
  booktitle = {ECML/PKDD (3)},
  year =      {2011},
  series    = {LNCS},
  volume    = {6913},
  pages = {34-48},
  _keywords = {Inverse reinforcement learning, apprenticeship learning, Bayesian inference,  behavioural modelling, machine learning}
}

@article{mnih2015dqn,
    Author = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A. and Veness, Joel and Bellemare, Marc G. and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K. and Ostrovski, Georg and Petersen, Stig and Beattie, Charles and Sadik, Amir and Antonoglou, Ioannis and King, Helen and Kumaran, Dharshan and Wierstra, Daan and Legg, Shane and Hassabis, Demis},
    _Day = {26},
    Journal = {Nature},
    Month = {02},
    Number = {7540},
    Pages = {529--533},
    Title = {Human-level control through deep reinforcement learning},
    _Url = {http://dx.doi.org/10.1038/nature14236},
    Volume = {518},
    Year = {2015},
}

@Article{dijkstra1959note,
    author="Dijkstra, E. W.",
    title="A note on two problems in connexion with graphs",
    journal="Numerische Mathematik",
    year="1959",
    volume="1",
    number="1",
    pages="269--271",
    _issn="0945-3245",
    _doi="10.1007/BF01386390",
    _url="http://dx.doi.org/10.1007/BF01386390"
}

@ARTICLE{choi2015hbirl,
    author={J. Choi and K. E. Kim},
    journal={IEEE Transactions on Cybernetics},
    title={Hierarchical Bayesian Inverse Reinforcement Learning},
    year={2015},
    volume={45},
    number={4},
    pages={793-805},
    _doi={10.1109/TCYB.2014.2336867},
    _ISSN={2168-2267},
    _month={April}
}

@book{li2008introduction,
    author = {Li, Ming and Vitanyi, Paul},
    booktitle = {Science},
    edition = {third},
    _isbn = {9780387339986},
    pages = {814},
    publisher = {Springer},
    title = {{An introduction to Kolmogorov complexity and its applications}},
    _url = {http://books.google.com/books?hl=en\&amp;lr=\&amp;id=25fue3UYDN0C\&amp;oi=fnd\&amp;pg=PR3\&amp;dq=An+Introduction+to+Kolmogorov+Complexity+and+its+applications\&amp;ots=U55hfgSbbk\&amp;sig=7EB705KounVf\_bfzl82WeRZYhxU http://books.google.com/books?hl=en\&amp;lr=\&amp;id=25fue3UYDN0C\&amp;oi=fnd\&amp;pg=PR3\&amp;dq=An+introduction+to+Kolmogorov+complexity+and+its+applications\&amp;ots=U55hfgSbdn\&amp;sig=TvYmcT1mxEpispN5R70iMlVv3sc},
    year = {2008}
}

@inproceedings{legg2006elegant,
    author = {Legg, Shane},
    month = oct,
    pages = {274--287},
    publisher = {Springer},
    series = {Lecture Notes in Artificial Intelligence},
    title = {{Is There an Elegant Universal Theory of Prediction?}},
    _url = {http://dx.doi.org/10.1007/11894841\_23 http://www.springerlink.com/content/4743x01400nk42m1/ http://www.vetta.org/documents/IDSIA-12-06-1.pdf},
    volume = {4264},
    year = {2006}
}

@phdthesis{legg2008machine,
    address = {Lugano, Switzerland},
    author = {Shane Legg},
    school = {Department of Informatics, University of Lugano},
    title = {{Machine Super Intelligence}},
    _url = {http://www.vetta.org/documents/Machine\_Super\_Intelligence.pdf},
    year = {2008}
}

@article{solomonoff1964formal,
    author = {Solomonoff, R. J.},
    journal = {Information and Control},
    number = {1},
    pages = {1--22},
    title = {{A Formal Theory of Inductive Inference. Part I}},
    volume = {7},
    year = {1964}
}

@inproceedings{schmidhuber2002speed,
    _abstract = {Solomonoff’s optimal but noncomputable method for inductive inference assumes that observation sequences x are drawn from an recursive prior distribution $\mu$(x). Instead of using the unknown $\mu$(x) he predicts using the celebrated universal enumerable prior M(x) which for all x exceeds any recursive $\mu$(x), save for a constant factor independent of x. The simplicity measure M(x) naturally implements “Occam’s razor” and is closely related to the Kolmogorov complexity of x. However, M assigns high probability to certain data x that are extremely hard to compute. This does not match our intuitive notion of simplicity. Here we suggest a more plausible measure derived from the fastest way of computing data. In absence of contrarian evidence, we assume that the physical world is generated by a computational process, and that any possibly infinite sequence of observations is therefore computable in the limit (this assumption is more radical and stronger than Solomonoff’s). Then we replace M by the novel Speed Prior S, under which the cumulative a priori probability of all data whose computation through an optimal algorithm requires more than O(n) resources is 1/n. We show that the Speed Prior allows for deriving a computable strategy for optimal prediction of future y, given past x. Then we consider the case that the data actually stem from a nonoptimal, unknown computational process, and use Hutter’s recent results to derive excellent expected loss bounds for S-based inductive inference. We conclude with several nontraditional predictions concerning the future of our universe.},
    author = {Schmidhuber, Juergen},
    booktitle = {Proceedings of the 15th Annual Conference on Computational Learning Theory},
    pages = {216--228},
    publisher = {Springer},
    series = {Lecture Notes in Artificial Intelligence},
    _shorttitle = {The Speed Prior},
    title = {{The Speed Prior: A New Simplicity Measure Yielding Near-Optimal Computable Predictions}},
    _url = {ftp://ftp.idsia.ch/pub/juergen/coltspeed.pdf http://dx.doi.org/10.1007/3-540-45435-7\_15 http://www.idsia.ch/~juergen/computeruniverse.html http://www.springerlink.com/content/0fn2np32b03dcdx6/},
    volume = {2375},
    year = {2002}
}

@article{chambon2011what,
    author = {Chambon, Valerian AND Domenech, Philippe AND Pacherie, Elisabeth AND Koechlin, Etienne AND Baraduc, Pierre AND Farrer, Chlöé},
    journal = {PLOS ONE},
    publisher = {Public Library of Science},
    title = {What Are They Up To? The Role of Sensory Evidence and Prior Knowledge in Action Understanding},
    year = {2011},
    month = {02},
    volume = {6},
    _url = {http://dx.doi.org/10.1371%2Fjournal.pone.0017133},
    pages = {1-17},
    _abstract = {Explaining or predicting the behaviour of our conspecifics requires the ability to infer the intentions that motivate it. Such inferences are assumed to rely on two types of information: (1) the sensory information conveyed by movement kinematics and (2) the observer's prior expectations – acquired from past experience or derived from prior knowledge. However, the respective contribution of these two sources of information is still controversial. This controversy stems in part from the fact that “intention” is an umbrella term that may embrace various sub-types each being assigned different scopes and targets. We hypothesized that variations in the scope and target of intentions may account for variations in the contribution of visual kinematics and prior knowledge to the intention inference process. To test this hypothesis, we conducted four behavioural experiments in which participants were instructed to identify different types of intention: basic intentions (i.e. simple goal of a motor act), superordinate intentions (i.e. general goal of a sequence of motor acts), or social intentions (i.e. intentions accomplished in a context of reciprocal interaction). For each of the above-mentioned intentions, we varied (1) the amount of visual information available from the action scene and (2) participant's prior expectations concerning the intention that was more likely to be accomplished. First, we showed that intentional judgments depend on a consistent interaction between visual information and participant's prior expectations. Moreover, we demonstrated that this interaction varied according to the type of intention to be inferred, with participant's priors rather than perceptual evidence exerting a greater effect on the inference of social and superordinate intentions. The results are discussed by appealing to the specific properties of each type of intention considered and further interpreted in the light of a hierarchical model of action representation.},
    number = {2},
    _doi = {10.1371/journal.pone.0017133}
}

@inproceedings{filan2016loss,
  author    = {Daniel Filan and
               Jan Leike and
               Marcus Hutter},
  title     = {Loss Bounds and Time Complexity for Speed Priors},
  booktitle = {Proceedings of the 19th International Conference on Artificial Intelligence
               and Statistics, {AISTATS} 2016, Cadiz, Spain, May 9-11, 2016},
  pages     = {1394--1402},
  year      = {2016},
  crossref  = {DBLP:conf/aistats/2016},
  _url       = {http://jmlr.org/proceedings/papers/v51/filan16.html},
  _timestamp = {Tue, 02 Aug 2016 20:16:08 +0200},
  _biburl    = {http://dblp.uni-trier.de/rec/bib/conf/aistats/FilanLH16},
  _bibsource = {dblp computer science bibliography, http://dblp.org}
}
@proceedings{DBLP:conf/aistats/2016,
  editor    = {Arthur Gretton and
               Christian C. Robert},
  title     = {Proceedings of the 19th International Conference on Artificial Intelligence
               and Statistics, {AISTATS} 2016, Cadiz, Spain, May 9-11, 2016},
  series    = {{JMLR} Workshop and Conference Proceedings},
  volume    = {51},
  publisher = {JMLR.org},
  year      = {2016},
  _url       = {http://jmlr.org/proceedings/papers/v51/},
  _timestamp = {Tue, 02 Aug 2016 20:16:08 +0200},
  _biburl    = {http://dblp.uni-trier.de/rec/bib/conf/aistats/2016},
  _bibsource = {dblp computer science bibliography, http://dblp.org}
}

@article{silver2016alphago,
    title = {Mastering the game of Go with deep neural networks and tree search},
    author  = {David Silver and Aja Huang and Christopher J. Maddison and Arthur Guez and Laurent Sifre and George van den Driessche and Julian Schrittwieser and Ioannis Antonoglou and Veda Panneershelvam and Marc Lanctot and Sander Dieleman and Dominik Grewe and John Nham and Nal Kalchbrenner and Ilya Sutskever and Timothy Lillicrap and Madeleine Leach and Koray Kavukcuoglu and Thore Graepel and Demis Hassabis},
    year  = 2016,
    _URL = {http://www.nature.com/nature/journal/v529/n7587/full/nature16961.html},
    journal = {Nature},
    pages = {484--503},
    volume  = {529}
}

% suffix-history based RL
@INPROCEEDINGS{mccallum1995instance,
    author = {R. Andrew Mccallum},
    title = {Instance-Based Utile Distinctions for Reinforcement Learning with Hidden State},
    booktitle = {In Proceedings of the Twelfth International Conference on Machine Learning},
    year = {1995},
    pages = {387--395},
    publisher = {Morgan Kaufmann}
}

@inproceedings{neu2007apprenticeship,
 author = {Neu, Gergely and Szepesv\'{a}ri, Csaba},
 title = {Apprenticeship Learning Using Inverse Reinforcement Learning and Gradient Methods},
 booktitle = {Proceedings of the Twenty-Third Conference on Uncertainty in Artificial Intelligence},
 series = {UAI'07},
 year = {2007},
 _isbn = {0-9749039-3-0},
 _location = {Vancouver, BC, Canada},
 pages = {295--302},
 numpages = {8},
 _url = {http://dl.acm.org/citation.cfm?id=3020488.3020524},
 _acmid = {3020524},
 publisher = {AUAI Press},
 _address = {Arlington, Virginia, United States},
}

@article{zvonkin1970complexity,
    author = {{Zvonkin, A K and Levin}, L A},
    _file = {:home/orseau/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zvonkin, Levin - 1970 - The complexity of finite objects and the development of the concepts of information and randomness by means of the theory of algorithms.pdf:pdf},
    journal = {Russian Mathematical Surveys},
    number = {6},
    pages = {83--124},
    title = {{The complexity of finite objects and the development of the concepts of information and randomness by means of the theory of algorithms}},
    _url = {http://iopscience.iop.org/0036-0279/25/6/R05},
    volume = {25},
    year = {1970}
}

% MLProd
@inproceedings{gaillard2014secondorder,
  author    = {Pierre Gaillard and
               Gilles Stoltz and
               Tim {van} Erven},
  _editor    = {Maria{-}Florina Balcan and
               Vitaly Feldman and
               Csaba Szepesv{\'{a}}ri},
  title     = {A second-order bound with excess losses},
  booktitle = {Proceedings of The 27th Conference on Learning Theory, {COLT}},
  series    = {{JMLR} Workshop and Conference Proceedings},
  volume    = {35},
  pages     = {176--196},
  _publisher = {JMLR.org},
  year      = {2014},
  _url       = {http://jmlr.org/proceedings/papers/v35/gaillard14.html},
  _timestamp = {Tue, 12 Jul 2016 21:51:13 +0200},
  _biburl    = {http://dblp.uni-trier.de/rec/bib/conf/colt/GaillardSE14},
  _bibsource = {dblp computer science bibliography, http://dblp.org}
}

@Article{hutter2013sad,
  author =       "Marcus Hutter",
  title =        "Sparse Adaptive {D}irichlet-Multinomial-like Processes",
  journal =      "Journal of Machine Learning Research, W\&CP: COLT",
  volume =       "30",
  pages =        "432--459",
  _month =        jun,
  year =         "2013",
  _bibtex =       "http://www.hutter1.net/official/bib.htm#sad",
  _url =          "http://arxiv.org/abs/1305.3671",
  _pdf =          "http://www.hutter1.net/publ/sad.pdf",
  _latex =        "http://www.hutter1.net/publ/sad.tex",
  _slides =       "http://www.hutter1.net/publ/ssad.pdf",
  _audio =        "http://vmc.aarnet.edu.au/userdata/0b/0b4d5c6f-e775-4d48-8b47-32dc95d19b8b/ingest1685426376076922317.asf",
  project =      "http://www.hutter1.net/official/projects.htm#infoth",
  _issn =         "1532-4435",
  _keywords =     "sparse coding; adaptive parameters; Dirichlet-Multinomial;
                  Polya urn; data-dependent redundancy bound;
                  small/large alphabet; data compression.",
  _abstract =     "Online estimation and modelling of i.i.d. data for short
                  sequences over large or complex ``alphabets'' is a ubiquitous
                  (sub)problem in machine learning, information theory, data
                  compression, statistical language processing, and document
                  analysis. The Dirichlet-Multinomial distribution (also called
                  Polya urn scheme) and extensions thereof are widely applied for
                  online i.i.d. estimation. Good a-priori choices for the
                  parameters in this regime are difficult to obtain though. I
                  derive an optimal adaptive choice for the main parameter via
                  tight, data-dependent redundancy bounds for a related model. The
                  1-line recommendation is to set the 'total mass' = 'precision' =
                  'concentration' parameter to m/2ln[(n+1)/m], where n
                  is the (past) sample size and m the number of different symbols
                  observed (so far). The resulting estimator is simple, online,
                  fast, and experimental performance is superb.",
  _for =          "080401(70%),010405(30%)",
  _seo =          "970108(100%)",
  _znote =        "26th Annual Conf. on Learning Theory. Acceptance rate: 47/98 = 48\%",
}

@ARTICLE{willems1995ctw,
    author = {Frans M. J. Willems and Yuri M. Shtarkov and Tjalling J. Tjalkens},
    title = {The Context Tree Weighting Method: Basic Properties},
    journal = {IEEE Transactions on Information Theory},
    year = {1995},
    volume = {41},
    pages = {653--664}
}

% Original prod algorithm
@Article{cesabianchi2007prod,
  author =  "Nicol{\`{o}} Cesa-Bianchi and Yishay Mansour and
         Gilles Stoltz",
  title =   "Improved second-order bounds for prediction with
         expert advice",
  journal = "Machine Learning",
  volume =  "66",
  number =  "2-3",
  year =    "2007",
  pages =   "321--352",
  publisher =   "Kluwer Academic Publishers, Boston",
  annote =  "Special Issue on Learning Theory",
  ee =      "http://dx.doi.org/10.1007/s10994-006-5001-7",
}

@inproceedings{Zin03,
 author = {Zinkevich, Martin},
 title = {Online Convex Programming and Generalized Infinitesimal Gradient Ascent},
 booktitle = {Proceedings of the Twentieth International Conference on Machine Learning},
 _series = {ICML'03},
 year = {2003},
 _isbn = {1-57735-189-4},
 _location = {Washington, DC, USA},
 pages = {928--935},
 numpages = {8},
 _url = {http://dl.acm.org/citation.cfm?id=3041838.3041955},
 _acmid = {3041955},
 _publisher = {AAAI Press},
}

%article{Zin03,
  title={Online convex programming and generalized infinitesimal gradient ascent},
  author={Zinkevich, Martin},
  year={2003},
  publisher={School of Computer Science, Carnegie Mellon University}
}

@inproceedings{VSH12,
  title={On ensemble techniques for {AIXI} approximation},
  author={Veness, Joel and Sunehag, Peter and Hutter, Marcus},
  booktitle={International Conference on Artificial General Intelligence},
  pages={341--351},
  year={2012},
  organization={Springer}
}

@inproceedings{DSSC08,
  title={Efficient projections onto the l 1-ball for learning in high dimensions},
  author={Duchi, John and Shalev-Shwartz, Shai and Singer, Yoram and Chandra, Tushar},
  booktitle={Proceedings of the 25th international conference on machine learning},
  pages={272--279},
  year={2008},
  organization={ACM}
}

@Article{hutter2013sad,
  author =       "Marcus Hutter",
  title =        "Sparse Adaptive {D}irichlet-Multinomial-like Processes",
  journal =      "Journal of Machine Learning Research, W\&CP: COLT",
  volume =       "30",
  pages =        "432--459",
  _month =        jun,
  year =         "2013",
  _bibtex =       "http://www.hutter1.net/official/bib.htm#sad",
  _url =          "http://arxiv.org/abs/1305.3671",
  _pdf =          "http://www.hutter1.net/publ/sad.pdf",
  _latex =        "http://www.hutter1.net/publ/sad.tex",
  _slides =       "http://www.hutter1.net/publ/ssad.pdf",
  _audio =        "http://vmc.aarnet.edu.au/userdata/0b/0b4d5c6f-e775-4d48-8b47-32dc95d19b8b/ingest1685426376076922317.asf",
  project =      "http://www.hutter1.net/official/projects.htm#infoth",
  _issn =         "1532-4435",
}

InProceedings{auer2000adaptive,
  author =  "Peter Auer and Claudio Gentile",
  title =   "Adaptive and Self-Confident On-Line Learning Algorithms",
  booktitle =   "Proceedings of COLT'00",
  _publisher =  "Morgan Kaufmann, San Francisco",
  year =    "2000",
  pages =   "107--117",
}




@inproceedings{SNL14,
  title={Exploiting easy data in online optimization},
  author={Sani, Amir and Neu, Gergely and Lazaric, Alessandro},
  booktitle={Advances in Neural Information Processing Systems},
  pages={810--818},
  year={2014}
}


@article{hazan2016oco,
  title={Introduction to online convex optimization},
  author={Hazan, Elad},
  journal={Foundations and Trends{\textregistered} in Optimization},
  volume={2},
  number={3-4},
  pages={157--325},
  year={2016},
  publisher={Now Publishers, Inc.}
}

@article{HSSW98,
  title={On-Line Portfolio Selection Using Multiplicative Updates},
  author={Helmbold, David P and Schapire, Robert E and Singer, Yoram and Warmuth, Manfred K},
  journal={Mathematical Finance},
  volume={8},
  number={4},
  pages={325--347},
  year={1998},
  publisher={Wiley Online Library}
}

@inproceedings{LACL16,
  title={Efficient second order online learning by sketching},
  author={Luo, Haipeng and Agarwal, Alekh and Cesa-Bianchi, Nicol{\`o} and Langford, John},
  booktitle={Advances in Neural Information Processing Systems},
  pages={902--910},
  year={2016}
}

@article{KV02,
  title={Efficient algorithms for universal portfolios},
  author={Kalai, Adam and Vempala, Santosh},
  journal={Journal of Machine Learning Research},
  volume={3},
  number={Nov},
  pages={423--440},
  year={2002}
}

@article{HAK07,
  title={Logarithmic regret algorithms for online convex optimization},
  author={Hazan, Elad and Agarwal, Amit and Kale, Satyen},
  journal={Machine Learning},
  volume={69},
  number={2},
  pages={169--192},
  year={2007},
  publisher={Springer}
}

@article{Cov91,
  title={Universal portfolios},
  author={Cover, Thomas M},
  journal={Mathematical finance},
  volume={1},
  number={1},
  pages={1--29},
  year={1991},
  publisher={Wiley Online Library}
}

@book{cesabianchi2006prediction,
 author = {Cesa-Bianchi, Nicolo and Lugosi, Gabor},
 title = {Prediction, Learning, and Games},
 year = {2006},
 _isbn = {0521841089},
 publisher = {Cambridge University Press},
 address = {New York, NY, USA}
}

%
inproceedings{FSSW97,
  title={Using and combining predictors that specialize},
  author={Freund, Yoav and Schapire, Robert E and Singer, Yoram and Warmuth, Manfred K},
  booktitle={Proceedings of the twenty-ninth annual ACM symposium on Theory of computing},
  pages={334--343},
  year={1997},
  organization={ACM}
}

@inproceedings{freund1997combining,
 author = {Freund, Yoav and Schapire, Robert E. and Singer, Yoram and Warmuth, Manfred K.},
 title = {Using and Combining Predictors That Specialize},
 booktitle = {Proceedings of the Twenty-ninth Annual ACM Symposium on Theory of Computing},
 series = {STOC '97},
 year = {1997},
 _isbn = {0-89791-888-6},
 _location = {El Paso, Texas, USA},
 pages = {334--343},
 numpages = {10},
 _url = {http://doi.acm.org/10.1145/258533.258616},
 _doi = {10.1145/258533.258616},
 _acmid = {258616},
 publisher = {ACM},
 _address = {New York, NY, USA},
}

% Hedge algorithm
@article{freund1997decision,
 author = {Freund, Yoav and Schapire, Robert E},
 title = {A Decision-Theoretic Generalization of On-Line Learning and an Application to Boosting},
 journal = {J. Comput. Syst. Sci.},
 issue_date = {Aug. 1997},
 volume = {55},
 number = {1},
 month = aug,
 year = {1997},
 issn = {0022-0000},
 pages = {119--139},
 numpages = {21},
 url = {http://dx.doi.org/10.1006/jcss.1997.1504},
 doi = {10.1006/jcss.1997.1504},
 acmid = {261549},
 publisher = {Academic Press, Inc.},
 address = {Orlando, FL, USA},
}


@proceedings{DBLP:conf/dcc/2013,
  _editor    = {Ali Bilgin and
               Michael W. Marcellin and
               Joan Serra{-}Sagrist{\`{a}} and
               James A. Storer},
  title     = {2013 Data Compression Conference, {DCC} 2013, Snowbird, UT, USA, March
               20-22, 2013},
  year      = {2013},
  publisher = {{IEEE}},
  _isbn      = {978-1-4673-6037-1},
  _timestamp = {Tue, 21 Oct 2014 19:50:13 +0200},
  _biburl    = {http://dblp.uni-trier.de/rec/bib/conf/dcc/2013},
  _bibsource = {dblp computer science bibliography, http://dblp.org}
}

@inproceedings{veness2015cnf,
  author    = {Joel Veness and
               Marcus Hutter and
               Laurent Orseau and
               Marc G. Bellemare},
  title     = {Online Learning of k-CNF Boolean Functions},
  booktitle = {Proceedings of the Twenty-Fourth International Joint Conference on
               Artificial Intelligence},
  pages     = {3865--3873},
  year      = {2015},
  crossref  = {DBLP:conf/ijcai/2015},
  _url       = {http://ijcai.org/Abstract/15/543},
  _timestamp = {Wed, 20 Jul 2016 15:18:06 +0200},
  _biburl    = {http://dblp.uni-trier.de/rec/bib/conf/ijcai/VenessHOB15},
  _bibsource = {dblp computer science bibliography, http://dblp.org}
}

@proceedings{DBLP:conf/ijcai/2015,
  _editor    = {Qiang Yang and
               Michael Wooldridge},
  title     = {Proceedings of the Twenty-Fourth International Joint Conference on
               Artificial Intelligence},
  publisher = {{AAAI} Press},
  year      = {2015},
  _url       = {http://ijcai.org/proceedings/2015},
  _isbn      = {978-1-57735-738-4},
  _timestamp = {Wed, 20 Jul 2016 15:18:06 +0200},
  _biburl    = {http://dblp.uni-trier.de/rec/bib/conf/ijcai/2015},
  _bibsource = {dblp computer science bibliography, http://dblp.org}
}

@inproceedings{koolen2012putting,
  author    = {Wouter M. Koolen and
               Dmitry Adamskiy and
               Manfred K. Warmuth},
  title     = {Putting Bayes to sleep},
  booktitle = {Advances in Neural Information Processing Systems},
  pages     = {135--143},
  year      = {2012},
  _crossref  = {DBLP:conf/nips/2012},
  _url       = {http://papers.nips.cc/paper/4557-putting-bayes-to-sleep},
  _timestamp = {Thu, 11 Dec 2014 17:34:07 +0100},
  _biburl    = {http://dblp.uni-trier.de/rec/bib/conf/nips/KoolenAW12},
  _bibsource = {dblp computer science bibliography, http://dblp.org}
}

@proceedings{DBLP:conf/nips/2012,
  _editor    = {Peter L. Bartlett and
               Fernando C. N. Pereira and
               Christopher J. C. Burges and
               L{\'{e}}on Bottou and
               Kilian Q. Weinberger},
  title     = {Advances in Neural Information Processing Systems 25: 26th Annual
               Conference on Neural Information Processing Systems 2012. Proceedings
               of a meeting held December 3-6, 2012, Lake Tahoe, Nevada, United States},
  year      = {2012},
  _url       = {http://papers.nips.cc/book/advances-in-neural-information-processing-systems-25-2012},
  _timestamp = {Thu, 11 Dec 2014 17:34:07 +0100},
  _biburl    = {http://dblp.uni-trier.de/rec/bib/conf/nips/2012},
  _bibsource = {dblp computer science bibliography, http://dblp.org}
}

@article{littlestone1994wma,
    author = "N. Littlestone and M.K. Warmuth",
    title = "The Weighted Majority Algorithm",
    journal = "Information and Computation",
    volume = "108",
    number = "2",
    pages = "212 - 261",
    year = "1994",
    _note = "",
    _issn = "0890-5401",
    _doi = "http://dx.doi.org/10.1006/inco.1994.1009",
    _url = "http://www.sciencedirect.com/science/article/pii/S0890540184710091",
}

% Doubling trick
@article{cesabianchi1997expert,
 author = {Cesa-Bianchi, Nicol\`{o} and Freund, Yoav and Haussler, David and Helmbold, David P. and Schapire, Robert E. and Warmuth, Manfred K.},
 title = {How to Use Expert Advice},
 journal = {J. ACM},
 _issue_date = {May 1997},
 volume = {44},
 number = {3},
 month = may,
 year = {1997},
 _issn = {0004-5411},
 pages = {427--485},
 _numpages = {59},
 _url = {http://doi.acm.org/10.1145/258128.258179},
 _doi = {10.1145/258128.258179},
 _acmid = {258179},
 publisher = {ACM},
 _address = {New York, NY, USA},
 _keywords = {algorithms},
}

% Fixed-share
@article{herbster1998tracking,
 author = {Herbster, Mark and Warmuth, Manfred K.},
 title = {Tracking the Best Expert},
 journal = {Machine Learning},
 _issue_date = {Aug. 1998},
 volume = {32},
 number = {2},
 month = aug,
 year = {1998},
 _issn = {0885-6125},
 pages = {151--178},
 _numpages = {28},
 _url = {http://dx.doi.org/10.1023/A:1007424614876},
 _doi = {10.1023/A:1007424614876},
 _acmid = {296382},
 publisher = {Kluwer Academic Publishers},
 _address = {Hingham, MA, USA},
 _keywords = {amortized analysis, experts, multiplicative updates, on-line learning, shifting},
}

@article{love1980log,
 _ISSN = {00255572},
 _URL = {http://www.jstor.org/stable/3615890},
 author = {E. R. Love},
 journal = {The Mathematical Gazette},
 number = {427},
 pages = {55-57},
 publisher = {The Mathematical Association},
 title = {64.4 {S}ome Logarithm Inequalities},
 volume = {64},
 year = {1980}
}


@article{perks1947indifference,
    title={Some observations on inverse probability including a new indifference rule},
    volume={73},
    _DOI={10.1017/S0020268100012270},
    number={2},
    journal={Journal of the Institute of Actuaries},
    publisher={Cambridge University Press},
    author={Perks, Wilfred},
    year={1947},
    pages={285--334}
}

% arithmetic encoding
@techreport{said2004arithmetic,
    author = {Said, A.},
    citeulike-article-id = {513402},
    keywords = {arithmetic, compression},
    posted-at = {2006-02-20 15:23:55},
    priority = {0},
    series = {HPL-2004-76},
    title = {{Introduction to Arithmetic Coding: theory and practice}},
    year = {2004}
}

@article{mattern2013geomix,
author = {Mattern, Christopher},
year = {2013},
month = {02},
pages = {301--310},
title = {Linear and Geometric Mixtures - Analysis},
journal = {Proceedings of the Data Compression Conference},
_doi = {10.1109/DCC.2013.38}
}

﻿@PhdThesis{mattern2016phd,
  author =  {Christopher Mattern},
  title =   {On Statistical Data Compression},
  school = {Technische Universit\"at Ilmenau, Fakult\"at f\"ur Informatik und Automatisierung},
  year =    {2016},
  month =   {Feb},
  day =     {17},
  _keywords =   {statistical data compression model mixer logistic mixing paq ppm ctw},
  _url =    {https://www.db-thueringen.de/receive/dbt_mods_00027239},
  _url =    {http://uri.gbv.de/document/gvk:ppn:847800245}
}

@InProceedings{chernov2009prediction,
  author =  "Alexey Chernov and Vladimir Vovk",
  title =   "Prediction with Expert Evaluators' Advice",
  booktitle =   "Algorithmic Learning Theory",
  _editor = "Ricard Gavald{\`{a}} and G{\'{a}}bor Lugosi and Thomas
         Zeugmann and Sandra Zilles",
  series =  "Lecture Notes in Artificial Intelligence",
  volume =  "5809",
  publisher =   "Springer",
  _address =    "Berlin/Heidelberg",
  year =    "2009",
  pages =   "8--22",
  _ee =     "http://dx.doi.org/10.1007/978-3-642-04414-4_6",
}

@article{tsuruoka02game,
  author    = {Yoshimasa Tsuruoka and
               Daisaku Yokoyama and
               Takashi Chikayama},
  title     = {Game-tree Search Algorithm based on Realization Probability},
  journal   = {{ICGA} Journal},
  volume    = {25},
  number    = {3},
  pages     = {145--152},
  year      = {2002},
  _pdf      = {https://www.researchgate.net/publication/220174478_Game-Tree_Search_Algorithm_Based_On_Realization_Probability}
}

@inproceedings{bellemare2016increasing,
 author = {Bellemare, Marc G. and Ostrovski, Georg and Guez, Arthur and Thomas, Philip S. and Munos, R{\'e}mi},
 title = {Increasing the Action Gap: New Operators for Reinforcement Learning},
 booktitle = {Proceedings of the Thirtieth AAAI Conference on Artificial Intelligence},
 _series = {AAAI'16},
 year = {2016},
 _location = {Phoenix, Arizona},
 pages = {1476--1483},
 numpages = {8},
 _url = {http://dl.acm.org/citation.cfm?id=3016100.3016105},
 _acmid = {3016105},
 _publisher = {AAAI Press},
 _pdf = {http://www.marcgbellemare.info/static/publications/bellemare16increasing.pdf},
}

% Iterative Deepening Depth First Search
@article{korf1985depth,
    author = "Richard E. Korf",
    title = "Depth-first iterative-deepening",
    journal = "Artificial Intelligence",
    volume = "27",
    number = "1",
    pages = "97 - 109",
    year = "1985",
    note = "",
    _issn = "0004-3702",
    _doi = "http://dx.doi.org/10.1016/0004-3702(85)90084-0",
    _url = "http://www.sciencedirect.com/science/article/pii/0004370285900840",
}

@article{korf2001time,
    title = "Time complexity of iterative-deepening-A∗",
    journal = "Artificial Intelligence",
    volume = "129",
    number = "1",
    pages = "199 - 218",
    year = "2001",
    _issn = "0004-3702",
    _doi = "http://dx.doi.org/10.1016/S0004-3702(01)00094-7",
    _url = "http://www.sciencedirect.com/science/article/pii/S0004370201000947",
    author = "Richard E. Korf and Michael Reid and Stefan Edelkamp",
    _keywords = "Problem solving",
    _keywords = "Heuristic search",
    _keywords = "Iterative-deepening-A",
    _keywords = "Time complexity",
    _keywords = "Branching factor",
    _keywords = "Heuristic branching factor",
    _keywords = "Sliding-tile puzzles",
    _keywords = "Eight Puzzle",
    _keywords = "Fifteen Puzzle",
    _keywords = "Rubik's Cube"
}

@book{jaynes2003probability,
  Author = {E. T. Jaynes},
  Title = {Probability Theory: The Logic of Science: Principles and Elementary Applications Vol 1},
  Publisher = {Cambridge University Press},
  Year = {2003},
  _ISBN = {},
  _URL = {https://www.amazon.com/Probability-Theory-Principles-Elementary-Applications-ebook/dp/B00AKE1Q40?SubscriptionId=0JYN1NVW651KCA56C102&tag=techkie-20&linkCode=xm2&camp=2025&creative=165953&creativeASIN=B00AKE1Q40}
}

@inproceedings{bellemare2015ale,
 author = {Bellemare, Marc G. and Naddaf, Yavar and Veness, Joel and Bowling, Michael},
 title = {The Arcade Learning Environment: An Evaluation Platform for General Agents},
 booktitle = {Proceedings of the 24th International Conference on Artificial Intelligence},
 series = {IJCAI'15},
 year = {2015},
 _isbn = {978-1-57735-738-4},
 _location = {Buenos Aires, Argentina},
 pages = {4148--4152},
 _numpages = {5},
 _url = {http://dl.acm.org/citation.cfm?id=2832747.2832830},
 _acmid = {2832830},
 publisher = {AAAI Press},
}

@inproceedings{sharon2014eda,
  author    = {Guni Sharon and Ariel Felner and Nathan Sturtevant},
  title     = {Exponential Deepening A* for Real-Time Agent-Centered Search},
  booktitle = {AAAI Conference on Artificial Intelligence},
  year      = {2014},
  pages     = {871--877},
}

@incollection{silver2010monte,
  title = {Monte-Carlo Planning in Large POMDPs},
  author = {Silver, David and Veness, Joel},
  booktitle = {Advances in Neural Information Processing Systems 23},
  _editor = {J. D. Lafferty and C. K. I. Williams and J. Shawe-Taylor and R. S. Zemel and A. Culotta},
  pages = {2164--2172},
  year = {2010},
  _publisher = {Curran Associates, Inc.},
  _url = {http://papers.nips.cc/paper/4031-monte-carlo-planning-in-large-pomdps.pdf}
}

@article{ozkural2011teraflop,
  author    = {Eray {\"{O}}zkural},
  title     = {Teraflop-scale Incremental Machine Learning},
  journal   = {CoRR},
  volume    = {abs/1103.1003},
  year      = {2011},
  _url       = {http://arxiv.org/abs/1103.1003},
  timestamp = {Wed, 07 Jun 2017 14:42:32 +0200},
  _biburl    = {http://dblp.uni-trier.de/rec/bib/journals/corr/abs-1103-1003},
  _bibsource = {dblp computer science bibliography, http://dblp.org}
}

% Updated version of ozkural2011teraflop
@ARTICLE{ozkural2017giga,
   author = {{{\"O}zkural}, E.},
    title = "{Gigamachine: incremental machine learning on desktop computers}",
  journal = {ArXiv e-prints},
archivePrefix = "arXiv",
   eprint = {1709.03413},
 primaryClass = "cs.AI",
 keywords = {Computer Science - Artificial Intelligence, Computer Science - Learning},
     year = 2017,
    month = sep,
   adsurl = {http://adsabs.harvard.edu/abs/2017arXiv170903413O},
  adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}


@inproceedings{ozkural2011towards,
    author="{\"O}zkural, Eray",
    _editor="Schmidhuber, J{\"u}rgen
    and Th{\'o}risson, Kristinn R.
    and Looks, Moshe",
    title="Towards Heuristic Algorithmic Memory",
    bookTitle="Artificial General Intelligence: 4th International Conference",
    year="2011",
    _publisher="Springer Berlin Heidelberg",
    _address="Berlin, Heidelberg",
    pages="382--387",
    _isbn="978-3-642-22887-2",
    _doi="10.1007/978-3-642-22887-2_47",
    _url="https://doi.org/10.1007/978-3-642-22887-2_47"
}

@INPROCEEDINGS{solomonoff86application,
    author = {Ray J. Solomonoff},
    title = {The Application Of Algorithmic Probability to Problems in Artificial Intelligence},
    booktitle = {in Uncertainty in Artificial Intelligence, Kanal, L.N. and Lemmer, J.F. (Eds), Elsevier Science Publishers B.V},
    year = {1986},
    pages = {473--491},
    _publisher = {Elsevier Science Publishers}
}

@article{schmidhuber2004oops,
    author="Schmidhuber, J{\"u}rgen",
    title="Optimal Ordered Problem Solver",
    journal="Machine Learning",
    year="2004",
    _month="Mar",
    _day="01",
    volume="54",
    number="3",
    pages="211--254",
    _abstract="We introduce a general and in a certain sense time-optimal way of solving one problem after another, efficiently searching the space of programs that compute solution candidates, including those programs that organize and manage and adapt and reuse earlier acquired knowledge. The Optimal Ordered Problem Solver (OOPS) draws inspiration from Levin's Universal Search designed for single problems and universal Turing machines. It spends part of the total search time for a new problem on testing programs that exploit previous solution-computing programs in computable ways. If the new problem can be solved faster by copy-editing/invoking previous code than by solving the new problem from scratch, then OOPS will find this out. If not, then at least the previous solutions will not cause much harm. We introduce an efficient, recursive, backtracking-based way of implementing OOPS on realistic computers with limited storage. Experiments illustrate how OOPS can greatly profit from metalearning or metasearching, that is, searching for faster search procedures.",
    _issn="1573-0565",
    _doi="10.1023/B:MACH.0000015880.99707.b2",
    _url="https://doi.org/10.1023/B:MACH.0000015880.99707.b2"
}

% Levin Search
@article{levin1973search,
    title = {Universal sequential search problems},
    author = {Levin, L. A.},
  _citeulike-article-id = {2381372},
  _interhash = {13aa87c780a3329a367d1ddc095ab77d},
  _intrahash = {bc9c4448c30a00bf4f684a7f3da0cbd5},
  journal = {Problems of Information Transmission},
  number = 3,
  pages = {265--266},
  _priority = {2},
  volume = 9,
  year = 1973
}
% Translation of Levin's paper on levin search (and NP-completeness)
% in the appendix of the following paper:
@ARTICLE{trakhtenbrot1984survey,
    author={B. A. Trakhtenbrot},
    title={A Survey of Russian Approaches to Perebor (Brute-Force Searches) Algorithms},
    journal={Annals of the History of Computing},
    year={1984},
    volume={6},
    number={4},
    pages={384-400},
    _keywords={Artificial intelligence;Complexity theory;Information processing;Polynomials;Search methods;Software algorithms},
    _doi={10.1109/MAHC.1984.10036},
    _ISSN={0164-1239},
    _month={Oct},
}

@Misc{solomonoff2003progress,
  author =       "Ray J. Solomonoff",
  title =        "Progress in Incremental Machine Learning; Revision 2.0, 30 Oct. 2003",
  howpublished = "Given at NIPS Workshop on Universal Learning Algorithms and Optimal Search",
  year =         "2002",
  month =        "14 Dec. ",
  _keywords =     "genetic algorithms, genetic programming",
  _URL =          "http://world.std.com/~rjs/nips02.ps",
  _size =         "27 pages",
  _notes =        "wide ranging. Section 5 deals with GP",
}

% Rat wireheading
@article{milner55positive,
    author = {Olds, James and Milner, Peter},
    year = {1955},
    month = {01},
    pages = {419-27},
    title = {Positive reinforcement produced by electrical stimulation of septal area and other regions of the rat brain},
    volume = {47},
    booktitle = {Journal of comparative and physiological psychology}
}

@InProceedings{orseau2017softbayes,
  title =    {Soft-Bayes: Prod for Mixtures of Experts with Log-Loss},
  author =   {Laurent Orseau and Tor Lattimore and Shane Legg},
  booktitle =    {Proceedings of the 28th International Conference on Algorithmic Learning Theory},
  pages =    {372--399},
  year =     {2017},
  _editor =   {Steve Hanneke and Lev Reyzin},
  volume =   {76},
  series =   {Proceedings of Machine Learning Research},
  _address =      {Kyoto University, Kyoto, Japan},
  _month =    {15--17 Oct},
  _publisher =    {PMLR},
  _pdf =      {http://proceedings.mlr.press/v76/orseau17a/orseau17a.pdf},
  _url =      {http://proceedings.mlr.press/v76/orseau17a.html},
  _abstract =     {We consider prediction with expert advice under the log-loss with the goal of deriving efficient and robust algorithms. We argue that existing algorithms such as exponentiated gradient, online gradient descent and online Newton step do not adequately satisfy both requirements. Our main contribution is an analysis of the Prod algorithm that is robust to any data sequence and runs in linear time relative to the number of experts in each round. Despite the unbounded nature of the log-loss, we derive a bound that is independent of the largest loss and of the largest gradient, and depends only on the number of experts and the time horizon. Furthermore we give a Bayesian interpretation of Prod and adapt the algorithm to derive a tracking regret.}
}

@article{luby1993speedup,
 author = {Luby, Michael and Sinclair, Alistair and Zuckerman, David},
 title = {Optimal Speedup of {L}as {V}egas Algorithms},
 journal = {Inf. Process. Lett.},
 issue_date = {Sept. 27, 1993},
 volume = {47},
 number = {4},
 month = sep,
 year = {1993},
 _issn = {0020-0190},
 pages = {173--180},
 _numpages = {8},
 _url = {http://dx.doi.org/10.1016/0020-0190(93)90029-9},
 _doi = {10.1016/0020-0190(93)90029-9},
 _acmid = {173184},
 _publisher = {Elsevier North-Holland, Inc.},
 _address = {Amsterdam, The Netherlands, The Netherlands},
 _keywords = {Las Vegas algorithms, design of algorithms, expected running time, optimal strategy, proof search, randomized algorithms, theorem-proving},
}

@inproceedings{mourtada2017growing,
    Author = {Mourtada, Jaouad and Maillard, Odalric-Ambrym},
    Booktitle = {Proceedings of the 28th International Conference on Algorithmic Learning Theory {(ALT)}},
    Pages = {517--539},
    _Pdf = {http://proceedings.mlr.press/v76/mourtada17a/mourtada17a.pdf},
    Series = {Proceedings of Machine Learning Research},
    Title = {Efficient tracking of a growing number of experts},
    _Url = {http://proceedings.mlr.press/v76/mourtada17a.html},
    Volume = {76},
    Year = {2017}
}


% Extended version in orabona2018solo
% @article{orabona2018scalefree,
title = "Scale-free online learning",
journal = "Theoretical Computer Science",
volume = "716",
pages = "50 - 69",
year = "2018",
note = "Special Issue on ALT 2015",
issn = "0304-3975",
doi = "https://doi.org/10.1016/j.tcs.2017.11.021",
url = "http://www.sciencedirect.com/science/article/pii/S0304397517308514",
author = "Francesco Orabona and D\'avid P\'al",
}

@article{orabona2018solo,
author = {Francesco Orabona and Dávid Pál},
title = {Scale-free online learning},
journal = {Theoretical Computer Science},
volume = {716},
pages = {50-69},
year = {2018},
_note = {Special Issue on ALT 2015},
_issn = {0304-3975},
_doi = {https://doi.org/10.1016/j.tcs.2017.11.021},
_url = {https://www.sciencedirect.com/science/article/pii/S0304397517308514},
_keywords = {Online algorithms, Optimization, Regret bounds, Online learning},
}

@inproceedings{bartlett2007adaptive,
  author    = {Peter L. Bartlett and Elad Hazan and Alexander Rakhlin},
  _editor    = {John C. Platt and Daphne Koller and Yoram Singer and Sam T. Roweis},
  title     = {Adaptive Online Gradient Descent},
  booktitle = {Advances in Neural Information Processing Systems 20},
  pages     = {65--72},
  _publisher = {Curran Associates, Inc.},
  year      = {2007},
  _url       = {https://proceedings.neurips.cc/paper/2007/hash/afd4836712c5e77550897e25711e1d96-Abstract.html},
  _timestamp = {Thu, 21 Jan 2021 15:15:24 +0100},
  _biburl    = {https://dblp.org/rec/conf/nips/BartlettHR07.bib},
  _bibsource = {dblp computer science bibliography, https://dblp.org}
}

% http://www.lamda.nju.edu.cn/wanggh/pdf/AAAI2020.pdf
@article{wang2020smoothness,
    author={Wang, Guanghui and Lu, Shiyin and Hu, Yao and Zhang, Lijun}, 
    title={Adapting to Smoothness: A More Universal Algorithm for Online Convex Optimization},
    volume={34},
    _url={https://ojs.aaai.org/index.php/AAAI/article/view/6081},
    _fullpdf={http://www.lamda.nju.edu.cn/wanggh/pdf/AAAI2020.pdf},
    _DOI={10.1609/aaai.v34i04.6081}, 
    number={04},
    journal={Proceedings of the AAAI Conference on Artificial Intelligence},
    year={2020}, 
    _month={Apr.}, 
    pages={6162-6169}
}


@InProceedings{pogodin20first,
  title = 	 {On First-Order Bounds, Variance and Gap-Dependent Bounds for Adversarial Bandits},
  author =       {Pogodin, Roman and Lattimore, Tor},
  booktitle = 	 {Proceedings of The 35th Uncertainty in Artificial Intelligence Conference},
  pages = 	 {894--904},
  year = 	 {2020},
  _editor = 	 {Adams, Ryan P. and Gogate, Vibhav},
  volume = 	 {115},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {22--25 Jul},
  publisher =    {PMLR},
  _pdf = 	 {http://proceedings.mlr.press/v115/pogodin20a/pogodin20a.pdf},
  _url = 	 {http://proceedings.mlr.press/v115/pogodin20a.html},
  _abstract = 	 {We make three contributions to the theory of k-armed adversarial bandits. First, we prove a first-order bound for a modified variant of the INF strategy by Audibert and Bubeck [2009], without sacrificing worst case optimality or modifying the loss estimators. Second, we provide a variance analysis for algorithms based on follow the regularised leader, showing that without adaptation the variance of the regret is typically {\Omega}(n^2) where n is the horizon. Finally, we study bounds that depend on the degree of separation of the arms, generalising the results by Cowan and Katehakis [2015] from the stochastic setting to the adversarial and improving the result of Seldin and Slivkins [2014] by a factor of log(n)/log(log(n)).}
}

@article{wintenberger2016bernstein,
  title = {Optimal learning with Bernstein online aggregation},
  author = {Olivier Wintenberger},
  _doi = {10.1007/s10994-016-5592-6},
  _url = {https://doi.org/10.1007/s10994-016-5592-6},
  year = {2016},
  _month = oct,
  publisher = {Springer Science and Business Media {LLC}},
  volume = {106},
  number = {1},
  pages = {119--141},
  journal = {Machine Learning}
}

@ARTICLE{gyorfi2007sequential,
    author = {Gy\"orfi, L\'aszl\'o and Ottucs\'ak, Gy\"orgy},
    journal={IEEE Transactions on Information Theory},
    title={Sequential Prediction of Unbounded Stationary Time Series},
    year={2007},
    volume={53},
    number={5},
    pages={1866-1872},
    _doi={10.1109/TIT.2007.894660},
    _ISSN={0018-9448},
    _month={May}
}

@article{mcmahan2017survey,
  author  = {H. Brendan McMahan},
  title   = {A survey of Algorithms and Analysis for Adaptive Online Learning},
  journal = {Journal of Machine Learning Research},
  year    = {2017},
  volume  = {18},
  number  = {90},
  pages   = {1-50},
  _url     = {http://jmlr.org/papers/v18/14-428.html}
}

@book{lattimore2020book,
    author={Lattimore, Tor and Szepesvári, Csaba}, 
    place={Cambridge}, 
    title={Bandit Algorithms}, 
    DOI={10.1017/9781108571401}, 
    publisher={Cambridge University Press}, 
    year={2020}
}

@misc{besson2018doubling,
      title={What Doubling Tricks Can and Can't Do for Multi-Armed Bandits}, 
      author={Lilian Besson and Emilie Kaufmann},
      year={2018},
      eprint={1803.06971},
      archivePrefix={arXiv},
      _primaryClass={stat.ML}
}

% Doubling trick
@INPROCEEDINGS{auer1995gambling,
    author={Auer, P. and Cesa-Bianchi, N. and Freund, Y. and Schapire, R.E.},  
    booktitle={Proceedings of IEEE 36th Annual Foundations of Computer Science},
    title={Gambling in a rigged casino: The adversarial multi-armed bandit problem},
    year={1995},
    _volume={},
    _number={},
    pages={322-331},
    doi={10.1109/SFCS.1995.492488}
}

% skipping steps
@InProceedings{gyorgy2021delays,
  title = 	 {Adapting to Delays and Data in Adversarial Multi-Armed Bandits},
  author =       {Gy\"orgy, Andras and Joulani, Pooria},
  booktitle = 	 {Proceedings of the 38th International Conference on Machine Learning},
  pages = 	 {3988--3997},
  year = 	 {2021},
  _editor = 	 {Meila, Marina and Zhang, Tong},
  volume = 	 {139},
  _series = 	 {Proceedings of Machine Learning Research},
  _month = 	 {18--24 Jul},
  publisher =    {PMLR},
  _pdf = 	 {http://proceedings.mlr.press/v139/gyorgy21a/gyorgy21a.pdf},
  _url = 	 {https://proceedings.mlr.press/v139/gyorgy21a.html},
  _abstract = 	 {We consider the adversarial multi-armed bandit problem under delayed feedback. We analyze variants of the Exp3 algorithm that tune their step size using only information (about the losses and delays) available at the time of the decisions, and obtain regret guarantees that adapt to the observed (rather than the worst-case) sequences of delays and/or losses. First, through a remarkably simple proof technique, we show that with proper tuning of the step size, the algorithm achieves an optimal (up to logarithmic factors) regret of order $\sqrt{\log(K)(TK + D)}$ both in expectation and in high probability, where $K$ is the number of arms, $T$ is the time horizon, and $D$ is the cumulative delay. The high-probability version of the bound, which is the first high-probability delay-adaptive bound in the literature, crucially depends on the use of implicit exploration in estimating the losses. Then, following Zimmert and Seldin (2019), we extend these results so that the algorithm can “skip” rounds with large delays, resulting in regret bounds of order $\sqrt{TK\log(K)} + |R| + \sqrt{D_{\bar{R}}\log(K)}$, where $R$ is an arbitrary set of rounds (which are skipped) and $D_{\bar{R}}$ is the cumulative delay of the feedback for other rounds. Finally, we present another, data-adaptive (AdaGrad-style) version of the algorithm for which the regret adapts to the observed (delayed) losses instead of only adapting to the cumulative delay (this algorithm requires an a priori upper bound on the maximum delay, or the advance knowledge of the delay for each decision when it is made). The resulting bound can be orders of magnitude smaller on benign problems, and it can be shown that the delay only affects the regret through the loss of the best arm.}
}


@InProceedings{cutkosky18reductions,
  title = 	 {Black-Box Reductions for Parameter-free Online Learning in Banach Spaces},
  author =       {Cutkosky, Ashok and Orabona, Francesco},
  booktitle = 	 {Proceedings of the 31st  Conference On Learning Theory},
  pages = 	 {1493--1529},
  year = 	 {2018},
  _editor = 	 {Bubeck, Sébastien and Perchet, Vianney and Rigollet, Philippe},
  volume = 	 {75},
  series = 	 {Proceedings of Machine Learning Research},
  _month = 	 {06--09 Jul},
  _publisher =    {PMLR},
  _pdf = 	 {http://proceedings.mlr.press/v75/cutkosky18a/cutkosky18a.pdf},
  _url = 	 {https://proceedings.mlr.press/v75/cutkosky18a.html},
  _abstract = 	 {We introduce several new black-box reductions that significantly improve the design of adaptive and parameter-free online learning algorithms by simplifying analysis, improving regret guarantees, and sometimes even improving runtime. We reduce parameter-free online learning to online exp-concave optimization, we reduce optimization in a Banach space to one-dimensional optimization, and we reduce optimization over a constrained domain to unconstrained optimization. All of our reductions run as fast as online gradient descent. We use our new techniques to improve upon the previously best regret bounds for parameter-free learning, and do so for arbitrary norms.}
}


@InProceedings{cutkosky2019hints,
  title = 	 {Artificial Constraints and Hints for Unbounded Online Learning},
  author =       {Cutkosky, Ashok},
  booktitle = 	 {Proceedings of the Thirty-Second Conference on Learning Theory},
  pages = 	 {874--894},
  year = 	 {2019},
  _editor = 	 {Beygelzimer, Alina and Hsu, Daniel},
  volume = 	 {99},
  series = 	 {Proceedings of Machine Learning Research},
  _month = 	 {25--28 Jun},
  publisher =    {PMLR},
  _pdf = 	 {http://proceedings.mlr.press/v99/cutkosky19a/cutkosky19a.pdf},
  _url = 	 {https://proceedings.mlr.press/v99/cutkosky19a.html},
  _abstract = 	 {We provide algorithms that guarantees regret $R_T(u)\le \tilde O(G\|u\|^3 +  G(\|u\|+1)\sqrt{T})$ or $R_T(u)\le \tilde O(G\|u\|^3T^{1/3} + GT^{1/3}+ G\|u\|\sqrt{T})$ for online convex optimization with $G$-Lipschitz losses for any comparison point $u$ without prior knowledge of either $G$ or $\|u\|$. Previous algorithms dispense with the $O(\|u\|^3)$ term at the expense of knowledge of one or both of these parameters, while a lower bound shows that some additional penalty term over $G\|u\|\sqrt{T}$ is necessary. Previous penalties were \emph{exponential} while our bounds are polynomial in all quantities. Further, given a known bound $\|u\|\le D$, our same techniques allow us to design algorithms that adapt optimally to the unknown value of $\|u\|$ without requiring knowledge of $G$.}
}


% Adagrad MD
@article{duchi2011adaptive,
  author  = {John Duchi and Elad Hazan and Yoram Singer},
  title   = {Adaptive Subgradient Methods for Online Learning and Stochastic Optimization},
  journal = {Journal of Machine Learning Research},
  year    = {2011},
  volume  = {12},
  number  = {61},
  pages   = {2121-2159},
  _url     = {http://jmlr.org/papers/v12/duchi11a.html}
}

@phdthesis{shalev2007online,
    author = {Shai Shalev-{S}hwartz},
    title = {Online learning: Theory, algorithms, and applications},
    school = {Hebrew University},
    address = {Jerusalem},
    year = {2007}
}

@article{beck2003mirror,
author = {Amir Beck and Marc Teboulle},
title = {Mirror descent and nonlinear projected subgradient methods for convex optimization},
journal = {Operations Research Letters},
volume = {31},
number = {3},
pages = {167-175},
year = {2003},
_issn = {0167-6377},
_doi = {https://doi.org/10.1016/S0167-6377(02)00231-6},
_url = {https://www.sciencedirect.com/science/article/pii/S0167637702002316},
_keywords = {Nonsmooth convex minimization, Projected subgradient methods, Nonlinear projections, Mirror descent algorithms, Relative entropy, Complexity analysis, Global rate of convergence},
abstract = {The mirror descent algorithm (MDA) was introduced by Nemirovsky and Yudin for solving convex optimization problems. This method exhibits an efficiency estimate that is mildly dependent in the decision variables dimension, and thus suitable for solving very large scale optimization problems. We present a new derivation and analysis of this algorithm. We show that the MDA can be viewed as a nonlinear projected-subgradient type method, derived from using a general distance-like function instead of the usual Euclidean squared distance. Within this interpretation, we derive in a simple way convergence and efficiency estimates. We then propose an Entropic mirror descent algorithm for convex minimization over the unit simplex, with a global efficiency estimate proven to be mildly dependent in the dimension of the problem.}
}

% delayed feedback with skipping steps. Subsumed below
article{zimmert2019delays,
  author    = {Julian Zimmert and
               Yevgeny Seldin},
  title     = {An Optimal Algorithm for Adversarial Bandits with Arbitrary Delays},
  journal   = {CoRR},
  volume    = {abs/1910.06054},
  year      = {2019},
  _url       = {http://arxiv.org/abs/1910.06054},
  _eprinttype = {arXiv},
  _eprint    = {1910.06054},
  _timestamp = {Wed, 16 Oct 2019 16:25:53 +0200},
  _biburl    = {https://dblp.org/rec/journals/corr/abs-1910-06054.bib},
  _bibsource = {dblp computer science bibliography, https://dblp.org}
}
@InProceedings{zimmert2020delays,
  title = 	 {An Optimal Algorithm for Adversarial Bandits with Arbitrary Delays},
  author =       {Zimmert, Julian and Seldin, Yevgeny},
  booktitle = 	 {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},
  pages = 	 {3285--3294},
  year = 	 {2020},
  _editor = 	 {Chiappa, Silvia and Calandra, Roberto},
  volume = 	 {108},
  series = 	 {Proceedings of Machine Learning Research},
  _month = 	 {26--28 Aug},
  publisher =    {PMLR},
  _pdf = 	 {http://proceedings.mlr.press/v108/zimmert20a/zimmert20a.pdf},
  _url = 	 {https://proceedings.mlr.press/v108/zimmert20a.html},
  abstract = 	 {We propose a new algorithm for adversarial multi-armed bandits with unrestricted delays. The algorithm is based on a novel hybrid regularizer applied in the Follow the Regularized Leader (FTRL) framework. It achieves $\mathcal{O}(\sqrt{kn}+\sqrt{D\log(k)})$ regret guarantee, where $k$ is the number of arms, $n$ is the number of rounds, and $D$ is the total delay. The result matches the lower bound within constants and requires no prior knowledge of $n$ or $D$. Additionally, we propose a refined tuning of the algorithm, which achieves $\mathcal{O}(\sqrt{kn}+\min_{S}(|S|+\sqrt{D_{\bar S}\log(k)}))$ regret guarantee, where $S$ is a set of rounds excluded from delay counting, $\bar S = [n]\setminus S$ are the counted rounds, and $D_{\bar S}$ is the total delay in the counted rounds. If the delays are highly unbalanced, the latter regret guarantee can be significantly tighter than the former. The result requires no advance knowledge of the delays and resolves an open problem of Thune et al. (2019). The new FTRL algorithm and its refined tuning are anytime and require no doubling, which resolves another open problem of Thune et al. (2019).}
}

@inproceedings{thune2019delays,
  author    = {Tobias Sommer Thune and
               Nicol{\`{o}} Cesa{-}Bianchi and
               Yevgeny Seldin},
  _editor    = {Hanna M. Wallach and
               Hugo Larochelle and
               Alina Beygelzimer and
               Florence d'Alch{\'{e}}{-}Buc and
               Emily B. Fox and
               Roman Garnett},
  title     = {Nonstochastic Multiarmed Bandits with Unrestricted Delays},
  booktitle = {Advances in Neural Information Processing Systems 32},
  pages     = {6538--6547},
  year      = {2019},
  _url       = {https://proceedings.neurips.cc/paper/2019/hash/0e4f5cc9f4f3f7f1651a6b9f9214e5b1-Abstract.html},
  _timestamp = {Thu, 21 Jan 2021 15:15:19 +0100},
  _biburl    = {https://dblp.org/rec/conf/nips/ThuneCS19.bib},
  _bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{huang2021delays,
  author    = {Jiatai Huang and
               Yan Dai and
               Longbo Huang},
  title     = {Scale-Free Adversarial Multi-Armed Bandit with Arbitrary Feedback
               Delays},
  journal   = {CoRR},
  volume    = {abs/2110.13400},
  year      = {2021},
  _url       = {https://arxiv.org/abs/2110.13400},
  _eprinttype = {arXiv},
  _eprint    = {2110.13400},
  _timestamp = {Thu, 28 Oct 2021 15:25:31 +0200},
  _biburl    = {https://dblp.org/rec/journals/corr/abs-2110-13400.bib},
  _bibsource = {dblp computer science bibliography, https://dblp.org}
}

@InProceedings{lattimore2020monitoring,
  title = 	 {Exploration by Optimisation in Partial Monitoring},
  author =       {Lattimore, Tor and Szepesv{\'a}ri, Csaba},
  booktitle = 	 {Proceedings of Thirty Third Conference on Learning Theory},
  pages = 	 {2488--2515},
  year = 	 {2020},
  _editor = 	 {Abernethy, Jacob and Agarwal, Shivani},
  volume = 	 {125},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {09--12 Jul},
  _publisher =    {PMLR},
  _pdf = 	 {http://proceedings.mlr.press/v125/lattimore20a/lattimore20a.pdf},
  _url = 	 {https://proceedings.mlr.press/v125/lattimore20a.html},
  _abstract = 	 { We provide a novel algorithm for adversarial k-action d-outcome partial monitoring that is adaptive, intuitive and efficient. The highlight is that for the non-degenerate locally observable games, the n-round minimax regret is bounded by 6m k^(3/2) sqrt(n log(k)), where m is the number of signals. This matches the best known information-theoretic upper bound derived via Bayesian minimax duality. The same algorithm also achieves near-optimal regret for full information, bandit and globally observable games. High probability bounds and simple experiments are also provided.}
}

@article{adamcik2014bregman,
  author = {Martin Adam{\v{c}}{\'{\i}}k},
  title = {The Information Geometry of Bregman Divergences and Some Applications in Multi-Expert Reasoning},
  journal = {Entropy},
  _doi = {10.3390/e16126338},
  _url = {https://doi.org/10.3390/e16126338},
  year = {2014},
  _month = dec,
  publisher = {{MDPI} {AG}},
  volume = {16},
  number = {12},
  pages = {6338--6381}
}

% Proof of projection with Bregman divergence (and references within)
@InProceedings{herbster1998regressor,
author = "Mark Herbster and Manfred K. Warmuth",
title = "Tracking the best regressor",
booktitle = "Proc. 11th Annu. Conf. on Comput. Learning Theory",
publisher = "ACM Press, New York, NY",
year = "1998",
pages = "24--31",
}


@InProceedings{mhammedi2019squint,
  title = 	 {Lipschitz Adaptivity with Multiple Learning Rates in Online Learning},
  author =       {Mhammedi, Zakaria and Koolen, Wouter M and Van Erven, Tim},
  booktitle = 	 {Proceedings of the Thirty-Second Conference on Learning Theory},
  pages = 	 {2490--2511},
  year = 	 {2019},
  _editor = 	 {Beygelzimer, Alina and Hsu, Daniel},
  volume = 	 {99},
  series = 	 {Proceedings of Machine Learning Research},
  _month = 	 {25--28 Jun},
  _publisher =    {PMLR},
  _pdf = 	 {http://proceedings.mlr.press/v99/mhammedi19a/mhammedi19a.pdf},
  _url = 	 {https://proceedings.mlr.press/v99/mhammedi19a.html},
  _abstract = 	 {We aim to design adaptive online learning algorithms that take advantage of any special structure that might be present in the learning task at hand, with as little manual tuning by the user as possible. A fundamental obstacle that comes up in the design of such adaptive algorithms is to calibrate a so-called step-size or learning rate hyperparameter depending on variance, gradient norms, etc. A recent technique promises to overcome this difficulty by maintaining multiple learning rates in parallel. This technique has been applied in the MetaGrad algorithm for online convex optimization and the Squint algorithm for prediction with expert advice. However, in both cases the user still has to provide in advance a Lipschitz hyperparameter that bounds the norm of the gradients. Although this hyperparameter is typically not available in advance, tuning it correctly is crucial: if it is set too small, the methods may fail completely; but if it is taken too large, performance deteriorates significantly. In the present work we remove this Lipschitz hyperparameter by designing new versions of MetaGrad and Squint that adapt to its optimal value automatically. We achieve this by dynamically updating the set of active learning rates. For MetaGrad, we further improve the computational efficiency of handling constraints on the domain of prediction, and we remove the need to specify the number of rounds in advance.}
}


@InProceedings{mhammedi2020freerange,
  title = 	 {Lipschitz and Comparator-Norm Adaptivity in Online Learning},
  author =       {Mhammedi, Zakaria and Koolen, Wouter M.},
  booktitle = 	 {Proceedings of Thirty Third Conference on Learning Theory},
  pages = 	 {2858--2887},
  year = 	 {2020},
  _editor = 	 {Abernethy, Jacob and Agarwal, Shivani},
  volume = 	 {125},
  series = 	 {Proceedings of Machine Learning Research},
  _month = 	 {09--12 Jul},
  publisher =    {PMLR},
  _pdf = 	 {http://proceedings.mlr.press/v125/mhammedi20a/mhammedi20a.pdf},
  _url = 	 {https://proceedings.mlr.press/v125/mhammedi20a.html},
  abstract = 	 { We study Online Convex Optimization in the unbounded setting where neither predictions nor gradient are constrained. The goal is to simultaneously adapt to both the sequence of gradients and the comparator. We first develop parameter-free and scale-free algorithms for a simplified setting with hints. We present two versions: the first adapts to the squared norms of both comparator and gradients separately using $O(d)$ time per round, the second adapts to their squared inner products (which measure variance only in the comparator direction) in time $O(d^3)$ per round. We then generalize two prior reductions to the unbounded setting; one to not need hints, and a second to deal with the range ratio problem (which already arises in prior work). We discuss their optimality in light of prior and new lower bounds. We apply our methods to obtain sharper regret bounds for scale-invariant online prediction with linear models. }
}


@InProceedings{chen2021impossible,
  title = 	 {Impossible Tuning Made Possible: A New Expert Algorithm and Its Applications},
  author =       {Chen, Liyu and Luo, Haipeng and Wei, Chen-Yu},
  booktitle = 	 {Proceedings of Thirty Fourth Conference on Learning Theory},
  pages = 	 {1216--1259},
  year = 	 {2021},
  _editor = 	 {Belkin, Mikhail and Kpotufe, Samory},
  volume = 	 {134},
  _series = 	 {Proceedings of Machine Learning Research},
  month = 	 {15--19 Aug},
  publisher =    {PMLR},
  _pdf = 	 {http://proceedings.mlr.press/v134/chen21f/chen21f.pdf},
  _url = 	 {https://proceedings.mlr.press/v134/chen21f.html},
  _abstract = 	 {We resolve the long-standing "impossible tuning" issue for the classic expert problem and show that, it is in fact possible to achieve regret $O\left(\sqrt{(\ln d)\sum_t \ell_{t,i}^2}\right)$ simultaneously for all expert $i$ in a $T$-round $d$-expert problem where $\ell_{t,i}$ is the loss for expert $i$ in round $t$. Our algorithm is based on the Mirror Descent framework with a correction term and a weighted entropy regularizer. While natural, the algorithm has not been studied before and requires a careful analysis. We also generalize the bound to $O\left(\sqrt{(\ln d)\sum_t (\ell_{t,i}-m_{t,i})^2}\right)$ for any prediction vector $m_t$ that the learner receives, and recover or improve many existing results by choosing different $m_t$. Furthermore, we use the same framework to create a master algorithm that combines a set of base algorithms and learns the best one with little overhead. The new guarantee of our master allows us to derive many new results for both the expert problem and more generally Online Linear Optimization.}
}

% A,B-Prod
@inproceedings{sani2014abprod,
 author = {Sani, Amir and Neu, Gergely and Lazaric, Alessandro},
 booktitle = {Advances in Neural Information Processing Systems},
 _editor = {Z. Ghahramani and M. Welling and C. Cortes and N. Lawrence and K. Q. Weinberger},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Exploiting easy data in online optimization},
 _url = {https://proceedings.neurips.cc/paper/2014/file/01f78be6f7cad02658508fe4616098a9-Paper.pdf},
 volume = {27},
 year = {2014}
}

@MISC {orangeskid2020logsumexp,
    TITLE = {Why is log-of-sum-of-exponentials $f(x)=\log\left(\sum_{i=1}^n e^ {x_i}\right)$ a convex function for $x \in\mathcal{R}^n$?},
    AUTHOR = {orangeskid (https://math.stackexchange.com/users/168051/orangeskid)},
    HOWPUBLISHED = {Mathematics Stack Exchange},
    _NOTE = {URL:https://math.stackexchange.com/q/3621413 (version: 2020-04-12)},
    _EPRINT = {https://math.stackexchange.com/q/3621413},
    URL = {https://math.stackexchange.com/q/3621413},
    year={2020}
}

@BOOK{Heath2001scicomp,
  title     = "Scientific Computing",
  author    = "Heath, Michael T",
  publisher = "McGraw Hill Higher Education",
  edition   =  2,
  month     =  aug,
  year      =  2001,
  address   = "Maidenhead, England",
  language  = "en"
}

@inproceedings{orseau2018single,
 author = {Orseau, Laurent and Lelis, Levi and Lattimore, Tor and Weber, Theophane},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {S. Bengio and H. Wallach and H. Larochelle and K. Grauman and N. Cesa-Bianchi and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Single-Agent Policy Tree Search With Guarantees},
 url = {https://proceedings.neurips.cc/paper/2018/file/52c5189391854c93e8a0e1326e56c14f-Paper.pdf},
 volume = {31},
 year = {2018}
}

@book{pearl1984heuristics,
author = {Pearl, Judea},
title = {Heuristics: Intelligent Search Strategies for Computer Problem Solving},
year = {1984},
isbn = {0201055945},
publisher = {Addison-Wesley Longman Publishing Co., Inc.},
address = {USA}
}

@article{hinton2002poe,
    author = {Hinton, Geoffrey E.},
    title = "{Training Products of Experts by Minimizing Contrastive Divergence}",
    journal = {Neural Computation},
    volume = {14},
    number = {8},
    pages = {1771-1800},
    year = {2002},
    month = {08},
    _abstract = "{It is possible to combine multiple latent-variable models of the same data by multiplying their probability distributions together and then renormalizing. This way of combining individual “expert” models makes it hard to generate samples from the combined model but easy to infer the values of the latent variables of each expert, because the combination rule ensures that the latent variables of different experts are conditionally independent when given the data. A product of experts (PoE) is therefore an interesting candidate for a perceptual system in which rapid inference is vital and generation is unnecessary. Training a PoE by maximizing the likelihood of the data is difficult because it is hard even to approximate the derivatives of the renormalization term in the combination rule. Fortunately, a PoE can be trained using a different objective function called “contrastive divergence” whose derivatives with regard to the parameters can be approximated accurately and efficiently. Examples are presented of contrastive divergence learning using several types of expert on several types of data.}",
    _issn = {0899-7667},
    _doi = {10.1162/089976602760128018},
    _url = {https://doi.org/10.1162/089976602760128018},
    _eprint = {https://direct.mit.edu/neco/article-pdf/14/8/1771/815447/089976602760128018.pdf},
}



@InProceedings{lazic2019politex,
  title = 	 {{POLITEX}: Regret Bounds for Policy Iteration using Expert Prediction},
  author =       {Abbasi-Yadkori, Yasin and Bartlett, Peter and Bhatia, Kush and Lazic, Nevena and Szepesvari, Csaba and Weisz, Gellert},
  booktitle = 	 {Proceedings of the 36th International Conference on Machine Learning},
  pages = 	 {3692--3702},
  year = 	 {2019},
  editor = 	 {Chaudhuri, Kamalika and Salakhutdinov, Ruslan},
  volume = 	 {97},
  series = 	 {Proceedings of Machine Learning Research},
  _month = 	 {09--15 Jun},
  publisher =    {PMLR},
  _pdf = 	 {http://proceedings.mlr.press/v97/lazic19a/lazic19a.pdf},
  _url = 	 {https://proceedings.mlr.press/v97/lazic19a.html},
  _abstract = 	 {We present POLITEX (POLicy ITeration with EXpert advice), a variant of policy iteration where each policy is a Boltzmann distribution over the sum of action-value function estimates of the previous policies, and analyze its regret in continuing RL problems. We assume that the value function error after running a policy for $\tau$ time steps scales as $\epsilon(\tau) = \epsilon_0 + O(\sqrt{d/\tau})$, where $\epsilon_0$ is the worst-case approximation error and $d$ is the number of features in a compressed representation of the state-action space. We establish that this condition is satisfied by the LSPE algorithm under certain assumptions on the MDP and policies. Under the error assumption, we show that the regret of POLITEX in uniformly mixing MDPs scales as $O(d^{1/2}T^{3/4} + \epsilon_0T)$, where $O(\cdot)$ hides logarithmic terms and problem-dependent constants. Thus, we provide the first regret bound for a fully practical model-free method which only scales in the number of features, and not in the size of the underlying MDP. Experiments on a queuing problem confirm that POLITEX is competitive with some of its alternatives, while preliminary results on Ms Pacman (one of the standard Atari benchmark problems) confirm the viability of POLITEX beyond linear function approximation.}
}

@article{ArfaeeZH11,
  author    = {S. {Jabbari Arfaee} and
               S. Zilles and
               R. C. Holte},
  title     = {Learning heuristic functions for large state spaces},
  journal   = {Artificial Intelligence},
  volume    = {175},
  number    = {16-17},
  year      = {2011},
  pages     = {2075-2098},
}

@article{orseau2021policy, 
title={Policy-Guided Heuristic Search with Guarantees}, 
volume={35},
_url={https://ojs.aaai.org/index.php/AAAI/article/view/17469}, _DOI={10.1609/aaai.v35i14.17469}, 
number={14},
journal={Proceedings of the AAAI Conference on Artificial Intelligence},
author={Orseau, Laurent and Lelis, Levi H. S.}, 
year={2021},
month={May},
pages={12382-12390}
}


@InProceedings{aygun2022proving,
  title = 	 {Proving Theorems using Incremental Learning and Hindsight Experience Replay},
  author =       {Ayg{\"u}n, Eser and Anand, Ankit and Orseau, Laurent and Glorot, Xavier and Mcaleer, Stephen M and Firoiu, Vlad and Zhang, Lei M and Precup, Doina and Mourad, Shibl},
  booktitle = 	 {Proceedings of the 39th International Conference on Machine Learning},
  pages = 	 {1198--1210},
  year = 	 {2022},
  _editor = 	 {Chaudhuri, Kamalika and Jegelka, Stefanie and Song, Le and Szepesvari, Csaba and Niu, Gang and Sabato, Sivan},
  volume = 	 {162},
  series = 	 {Proceedings of Machine Learning Research},
  _month = 	 {17--23 Jul},
  publisher =    {PMLR},
  _pdf = 	 {https://proceedings.mlr.press/v162/aygun22a/aygun22a.pdf},
  _url = 	 {https://proceedings.mlr.press/v162/aygun22a.html},
}

@misc{veness2017gln,
  _doi = {10.48550/ARXIV.1712.01897},
  _url = {https://arxiv.org/abs/1712.01897},
  author = {Veness, Joel and Lattimore, Tor and Bhoopchand, Avishkar and Grabska-Barwinska, Agnieszka and Mattern, Christopher and Toth, Peter},
  _keywords = {Machine Learning (cs.LG), Information Theory (cs.IT), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Online Learning with Gated Linear Networks}, 
  publisher = {arXiv},
  year = {2017},  
  _copyright = {arXiv.org perpetual, non-exclusive license}
}

@article{veness2021gln, 
title={Gated Linear Networks}, 
volume={35},
_url={https://ojs.aaai.org/index.php/AAAI/article/view/17202},
_DOI={10.1609/aaai.v35i11.17202}, 
number={11},
journal={Proceedings of the AAAI Conference on Artificial Intelligence}, 
author={Veness, Joel and Lattimore, Tor and Budden, David and Bhoopchand, Avishkar and Mattern, Christopher and Grabska-Barwinska, Agnieszka and Sezener, Eren and Wang, Jianan and Toth, Peter and Schmitt, Simon and Hutter, Marcus}, 
year={2021}, 
month={May}, 
pages={10015-10023} }


% DeepCube
@inproceedings{mcaleer2018solving,
title={Solving the Rubik's Cube with Approximate Policy Iteration},
author={Stephen McAleer and Forest Agostinelli and Alexander Shmakov and Pierre Baldi},
booktitle={International Conference on Learning Representations (ICRL)},
year={2019},
_url={https://openreview.net/forum?id=Hyfn2jCcKm},
}

% DeepCubeA
@article{agostinelli2019rubik,
author = {Agostinelli, Forest and McAleer, Stephen and Shmakov, Alexander and Baldi, Pierre},
year = {2019},
month = {07},
pages = {},
title = {Solving the Rubik’s cube with deep reinforcement learning and search},
volume = {1},
journal = {Nature Machine Intelligence},
_doi = {10.1038/s42256-019-0070-z}
}

@inproceedings{feng2022left,
title={Left Heavy Tails and the Effectiveness of the Policy and Value Networks in {DNN}-based best-first search for Sokoban Planning},
author={Dieqiao Feng and Carla P Gomes and Bart Selman},
booktitle={Advances in Neural Information Processing Systems},
_editor={Alice H. Oh and Alekh Agarwal and Danielle Belgrave and Kyunghyun Cho},
year={2022},
_url={https://openreview.net/forum?id=b6to5kfFhQh}
}

@article{cox1958regression,
  title={The regression analysis of binary sequences},
  author={Cox, David R},
  journal={Journal of the Royal Statistical Society: Series B (Methodological)},
  volume={20},
  number={2},
  pages={215--232},
  year={1958},
  publisher={Wiley Online Library}
}
@ARTICLE{rissanen1983universal,
    author={Rissanen, J.},
    journal={IEEE Transactions on Information Theory},
    title={A universal data compression system},
    year={1983},
    volume={29},
    number={5},
    pages={656-664},
    _doi={10.1109/TIT.1983.1056741}
}
@ARTICLE{willems1996context,
    author={Willems, F.M.J. and Shtarkov, Y.M. and Tjalkens, T.J.},  
    journal={IEEE Transactions on Information Theory},   
    title={Context weighting for general finite-context sources},   
    year={1996},
    volume={42},
    number={5},
    pages={1514-1520},
    _doi={10.1109/18.532891}
}
@article{nielsen2018montecarlo,
  author    = {Frank Nielsen and
               Ga{\"{e}}tan Hadjeres},
  title     = {Monte Carlo Information Geometry: The dually flat case},
  journal   = {CoRR},
  volume    = {abs/1803.07225},
  year      = {2018},
  url       = {http://arxiv.org/abs/1803.07225},
  _eprinttype = {arXiv},
  _eprint    = {1803.07225},
  _timestamp = {Mon, 13 Aug 2018 16:48:58 +0200},
  _biburl    = {https://dblp.org/rec/journals/corr/abs-1803-07225.bib},
  _bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{truong2021backtracking,
author = {Truong, Tuyen and Nguyen, Hang-Tuan},
year = {2021},
month = {12},
pages = {1-30},
title = {Backtracking Gradient Descent Method and Some Applications in Large Scale Optimisation. Part 2: Algorithms and Experiments},
volume = {84},
journal = {Applied Mathematics \& Optimization},
_doi = {10.1007/s00245-020-09718-8}
}

@misc{orseau2021isotuning,
  _doi = {10.48550/ARXIV.2112.14586},
  _url = {https://arxiv.org/abs/2112.14586},
  author = {Orseau, Laurent and Hutter, Marcus},
  _keywords = {Machine Learning (cs.LG), Artificial Intelligence (cs.AI), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Isotuning With Applications To Scale-Free Online Learning},
  publisher = {arXiv},
  year = {2021},  
  _copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{mittal2022expose,
  author = {Mittal, Dixant and Aravindan, Siddharth and Lee, Wee Sun},
  title = {ExPoSe: Combining State-Based Exploration with Gradient-Based Online Search},
  _doi = {10.48550/ARXIV.2202.01461},
  _url = {https://arxiv.org/abs/2202.01461},
  _keywords = {Artificial Intelligence (cs.AI), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  publisher = {arXiv},
  year = {2022},  
  _copyright = {Creative Commons Attribution 4.0 International}
}

@misc{boxobanlevels,
author = {Arthur Guez and Mehdi Mirza and Karol Gregor and Rishabh Kabra and Sebastien Racaniere and Theophane Weber and David Raposo and Adam Santoro and Laurent Orseau and Tom Eccles and Greg Wayne and David Silver and Timothy Lillicrap and Victor Valdes},
title = {An investigation of Model-free planning: boxoban levels},
howpublished= {https://github.com/deepmind/boxoban-levels/},
year = "2018"
}

@misc{agostinelli2021expansions,
  author = {Agostinelli, Forest and Shmakov, Alexander and McAleer, Stephen and Fox, Roy and Baldi, Pierre},
  title = {A* Search Without Expansions: Learning Heuristic Functions with Deep Q-Networks},
  _doi = {10.48550/ARXIV.2102.04518},
  _url = {https://arxiv.org/abs/2102.04518},
  _keywords = {Artificial Intelligence (cs.AI), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  publisher = {arXiv},
  year = {2021},  
  _copyright = {Creative Commons Attribution 4.0 International}
}

@inproceedings{liang2016atari,
author = {Liang, Yitao and Machado, Marlos C. and Talvitie, Erik and Bowling, Michael},
title = {State of the Art Control of Atari Games Using Shallow Reinforcement Learning},
year = {2016},
isbn = {9781450342391},
publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
_address = {Richland, SC},
_abstract = {The recently introduced Deep Q-Networks (DQN) algorithm has gained attention as one of the first successful combinations of deep neural networks and reinforcement learning. Its promise was demonstrated in the Arcade Learning Environment (ALE), a challenging framework composed of dozens of Atari 2600 games used to evaluate general competency in AI. It achieved dramatically better results than earlier approaches, showing that its ability to learn good representations is quite robust and general. This paper attempts to understand the principles that underlie DQN's impressive performance and to better contextualize its success. We systematically evaluate the importance of key representational biases encoded by DQN's network by proposing simple linear representations that make use of these concepts. Incorporating these characteristics, we obtain a computationally practical feature set that achieves competitive performance to DQN in the ALE. Besides offering insight into the strengths and weaknesses of DQN, we provide a generic representation for the ALE, significantly reducing the burden of learning a representation for each game. Moreover, we also provide a simple, reproducible benchmark for the sake of comparison to future work in the ALE.},
booktitle = {Proceedings of the 2016 International Conference on Autonomous Agents \& Multiagent Systems},
pages = {485–493},
numpages = {9},
_keywords = {deep q-networks, reinforcement learning, function approximation, representation learning, arcade learning environment},
_location = {Singapore, Singapore},
series = {AAMAS '16}
}

@article{matthew2005adaptive,
  title={Adaptive weighing of context models for lossless data compression},
  author={Matthew, V Mahoney},
  journal={Florida Institute of Technology CS Dept, Technical Report CS-2005-16, https://www. cs. fit. edu/Projects/tech\_reports/cs-2005-16. pdf},
  year={2005}
}

@article{culberson1998pattern,
title = {Pattern Databases},
author = {Culberson, Joseph C. and Schaeffer, Jonathan},
journal = {Computational Intelligence},
volume = {14},
number = {3},
pages = {318-334},
_keywords = {single-agent search, A*, IDA*, pattern databases},
_doi = {https://doi.org/10.1111/0824-7935.00065},
_url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/0824-7935.00065},
_eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1111/0824-7935.00065},
_abstract = {The efficiency of A* searching depends on the quality of the lower bound estimates of the solution cost. Pattern databases enumerate all possible subgoals required by any solution, subject to constraints on the subgoal size. Each subgoal in the database provides a tight lower bound on the cost of achieving it. For a given state in the search space, all possible subgoals are looked up in the pattern database, with the maximum cost over all lookups being the lower bound. For sliding tile puzzles, the database enumerates all possible patterns containing N tiles and, for each one, contains a lower bound on the distance to correctly move all N tiles into their correct final location. For the 15-Puzzle, iterative-deepening A* with pattern databases(N ='8) reduces the total number of nodes searched on a standard problem set of 100 positions by over 1000-fold.},
year = {1998}
}

@BOOK{boyd2004convex,
  title     = "Convex Optimization",
  author    = "Boyd, Stephen and Vandenberghe, Lieven",
  publisher = "Cambridge University Press",
  _month     =  mar,
  year      =  2004,
  address   = "Cambridge, England",
  _language  = "en"
}



@InProceedings{joulani2013delayed,
  title = 	 {Online Learning under Delayed Feedback},
  author = 	 {Joulani, Pooria and Gyorgy, Andras and Szepesvari, Csaba},
  booktitle = 	 {Proceedings of the 30th International Conference on Machine Learning},
  pages = 	 {1453--1461},
  year = 	 {2013},
  _editor = 	 {Dasgupta, Sanjoy and McAllester, David},
  volume = 	 {28(3)},
  _number =       {3},
  series = 	 {Proceedings of Machine Learning Research},
  _address = 	 {Atlanta, Georgia, USA},
  _month = 	 {17--19 Jun},
  publisher =    {PMLR},
  _pdf = 	 {http://proceedings.mlr.press/v28/joulani13.pdf},
  _url = 	 {https://proceedings.mlr.press/v28/joulani13.html},
  abstract = 	 {Online learning with delayed feedback has received increasing attention recently due to its several applications in distributed, web-based learning problems. In this paper we provide a systematic study of the topic, and analyze the effect of delay on the regret of online learning algorithms. Somewhat surprisingly, it turns out that delay increases the regret in a multiplicative way in adversarial problems, and in an additive way in stochastic problems. We give meta-algorithms that transform, in a black-box fashion, algorithms developed for the non-delayed case into ones that can handle the presence of delays in the feedback loop. Modifications of the well-known UCB algorithm are also developed for the bandit problem with delayed feedback, with the advantage over the meta-algorithms that they can be implemented with lower complexity.}
}

@inproceedings{kulis2010implicit,
  title={Implicit Online Learning},
  author={Brian Kulis and Peter L. Bartlett},
  booktitle={International Conference on Machine Learning},
  year={2010}
}

@inproceedings{allen2021focused_macros,
  title={Efficient Black-Box Planning Using Macro-Actions with Focused Effects},
  author={Allen, Cameron and Katz, Michael and Klinger, Tim and Konidaris, George and Riemer, Matthew and Tesauro, Gerald},
  booktitle={Proceedings of the Thirtieth International Joint Conference on Artificial Intelligence},
  pages={4024--4031},
  year={2021},
}

@inproceedings{budden2020gated,
 author = {Budden, David and Marblestone, Adam and Sezener, Eren and Lattimore, Tor and Wayne, Gregory and Veness, Joel},
 booktitle = {Advances in Neural Information Processing Systems},
 _editor = {H. Larochelle and M. Ranzato and R. Hadsell and M.F. Balcan and H. Lin},
 pages = {16508--16519},
 publisher = {Curran Associates, Inc.},
 title = {Gaussian Gated Linear Networks},
 _url = {https://proceedings.neurips.cc/paper/2020/file/c0356641f421b381e475776b602a5da8-Paper.pdf},
 volume = {33},
 year = {2020}
}


@InProceedings{jaggi2013duality,
  title = 	 {Revisiting {Frank-Wolfe}: Projection-Free Sparse Convex Optimization},
  author = 	 {Jaggi, Martin},
  booktitle = 	 {Proceedings of the 30th International Conference on Machine Learning},
  pages = 	 {427--435},
  year = 	 {2013},
  _editor = 	 {Dasgupta, Sanjoy and McAllester, David},
  volume = 	 {28(1)},
  _number =       {1},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {Atlanta, Georgia, USA},
  month = 	 {17--19 Jun},
  publisher =    {PMLR},
  _pdf = 	 {http://proceedings.mlr.press/v28/jaggi13.pdf},
  _url = 	 {https://proceedings.mlr.press/v28/jaggi13.html},
  _abstract = 	 {We provide stronger and more general primal-dual convergence results for Frank-Wolfe-type algorithms (a.k.a. conditional gradient) for constrained convex optimization, enabled by a simple framework of duality gap certificates. Our analysis also holds if the linear subproblems are only solved approximately (as well as if the gradients are inexact), and is proven to be worst-case optimal in the sparsity of the obtained solutions.    On the application side, this allows us to unify a large variety of existing sparse greedy methods, in particular for optimization over convex hulls of an atomic set, even if those sets can only be approximated, including sparse (or structured sparse) vectors or matrices, low-rank matrices, permutation matrices, or max-norm bounded matrices.    We present a new general framework for convex optimization over matrix factorizations, where every Frank-Wolfe iteration will consist of a low-rank update, and discuss the broad application areas of this approach.}
}

@inproceedings{buchner2022a,
title={A Comparison of Abstraction Heuristics for Rubik's Cube},
author={Clemens B{\"u}chner and Patrick Ferber and Jendrik Seipp and Malte Helmert},
booktitle={ICAPS 2022 Workshop on Heuristics and Search for Domain-independent Planning },
year={2022},
_url={https://openreview.net/forum?id=8lb-ifAeeZw}
}


@InProceedings{guez2019planning,
  title = 	 {An Investigation of Model-Free Planning},
  author =       {Guez, Arthur and Mirza, Mehdi and Gregor, Karol and Kabra, Rishabh and Racaniere, Sebastien and Weber, Theophane and Raposo, David and Santoro, Adam and Orseau, Laurent and Eccles, Tom and Wayne, Greg and Silver, David and Lillicrap, Timothy},
  booktitle = 	 {Proceedings of the 36th International Conference on Machine Learning},
  pages = 	 {2464--2473},
  year = 	 {2019},
  _editor = 	 {Chaudhuri, Kamalika and Salakhutdinov, Ruslan},
  volume = 	 {97},
  series = 	 {Proceedings of Machine Learning Research},
  _month = 	 {09--15 Jun},
  publisher =    {PMLR},
  _pdf = 	 {http://proceedings.mlr.press/v97/guez19a/guez19a.pdf},
  _url = 	 {https://proceedings.mlr.press/v97/guez19a.html},
  abstract = 	 {The field of reinforcement learning (RL) is facing increasingly challenging domains with combinatorial complexity. For an RL agent to address these challenges, it is essential that it can plan effectively. Prior work has typically utilized an explicit model of the environment, combined with a specific planning algorithm (such as tree search). More recently, a new family of methods have been proposed that learn how to plan, by providing the structure for planning via an inductive bias in the function approximator (such as a tree structured neural network), trained end-to-end by a model-free RL algorithm. In this paper, we go even further, and demonstrate empirically that an entirely model-free approach, without special structure beyond standard neural network components such as convolutional networks and LSTMs, can learn to exhibit many of the characteristics typically associated with a model-based planner. We measure our agent’s effectiveness at planning in terms of its ability to generalize across a combinatorial and irreversible state space, its data efficiency, and its ability to utilize additional thinking time. We find that our agent has many of the characteristics that one might expect to find in a planning algorithm. Furthermore, it exceeds the state-of-the-art in challenging combinatorial domains such as Sokoban and outperforms other model-free approaches that utilize strong inductive biases toward planning.}
}
@inproceedings{korf1997cube,
author = {Korf, Richard E.},
title = {Finding Optimal Solutions to Rubik's Cube Using Pattern Databases},
year = {1997},
isbn = {0262510952},
publisher = {AAAI Press},
_abstract = {We have found the first optimal solutions to random instances of Rubik's Cube. The median optimal solution length appears to be 18 moves. The algorithm used is iterative-deepening-A* (IDA*), with a lower-bound heuristic function based on large memory-based lookup tables, or "pattern databases" (Culberson and Schaeffer 1996). These tables store the exact number of moves required to solve various subgoals of the problem, in this case subsets of the individual movable cubies. We characterize the effectiveness of an admissible heuristic function by its expected value, and hypothesize that the overall performance of the program obeys a relation in which the product of the time and space used equals the size of the state space. Thus, the speed of the program increases linearly with the amount of memory available. As computer memories become larger and cheaper, we believe that this approach will become increasingly cost-effective.},
booktitle = {Proceedings of the Fourteenth National Conference on Artificial Intelligence and Ninth Conference on Innovative Applications of Artificial Intelligence},
pages = {700–705},
numpages = {6},
_location = {Providence, Rhode Island},
series = {AAAI'97/IAAI'97}
}

@article{frank1956quadratic,
author = {Frank, Marguerite and Wolfe, Philip},
title = {An algorithm for quadratic programming},
journal = {Naval Research Logistics Quarterly},
volume = {3},
number = {1-2},
pages = {95-110},
_doi = {https://doi.org/10.1002/nav.3800030109},
_url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/nav.3800030109},
_eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/nav.3800030109},
year = {1956}
}

% Weighted A*
@article{pohl1970heuristic,
author = "Ira Pohl",
title = "Heuristic search viewed as path finding in a graph",
journal = "Artificial Intelligence",
volume = "1",
number = "3",
pages = "193 - 204",
year = "1970",
_issn = "0004-3702",
_doi = "https://doi.org/10.1016/0004-3702(70)90007-X",
_url = "http://www.sciencedirect.com/science/article/pii/000437027090007X",
_abstract = "This paper presents a particular model of heuristic search as a path-finding problem in a directed graph. A class of graph-searching procedures is described which uses a heuristic function to guide search. Heuristic functions are estimates of the number of edges that remain to be traversed in reaching a goal node. A number of theoretical results for this model, and the intuition for these results, are presented. They relate the efficiency of search to the accuracy of the heuristic function. The results also explore efficiency as a consequence of the reliance or weight placed on the heuristics used."
}

% Weighted A* review
@article{ebendt2009weighted,
title = "Weighted A* search – unifying view and application",
author = "R{\"u}diger Ebendt and Rolf Drechsler",
journal = "Artificial Intelligence",
volume = "173",
number = "14",
pages = "1310 - 1342",
year = "2009",
_issn = "0004-3702",
_doi = "https://doi.org/10.1016/j.artint.2009.06.004",
_url = "http://www.sciencedirect.com/science/article/pii/S000437020900068X",
}

@article{cortes2006ngd,
author = {Jorge Cortés},
title = {Finite-time convergent gradient flows with applications to network consensus},
journal = {Automatica},
volume = {42},
number = {11},
pages = {1993-2000},
year = {2006},
issn = {0005-1098},
_doi = {https://doi.org/10.1016/j.automatica.2006.06.015},
_url = {https://www.sciencedirect.com/science/article/pii/S000510980600269X},
_keywords = {Gradient flows, Nonsmooth analysis, Finite-time convergence, Network consensus, Multi-agent systems},
_abstract = {This paper introduces the normalized and signed gradient dynamical systems associated with a differentiable function. Extending recent results on nonsmooth stability analysis, we characterize their asymptotic convergence properties and identify conditions that guarantee finite-time convergence. We discuss the application of the results to consensus problems in multi-agent systems and show how the proposed nonsmooth gradient flows achieve consensus in finite time.}
}

@article{nesterov1983agd,
  title={A method for solving the convex programming problem with convergence rate $O(1/k^2)$},
  author={Yurii Nesterov},
  journal={Proceedings of the USSR Academy of Sciences},
  year={1983},
  volume={269},
  pages={543-547}
}

@article{armijo1966minimization,
author = {Larry Armijo},
title = {{Minimization of functions having Lipschitz continuous first partial derivatives.}},
volume = {16},
journal = {Pacific Journal of Mathematics},
number = {1},
publisher = {Pacific Journal of Mathematics, A Non-profit Corporation},
pages = {1 -- 3},
year = {1966},
}

@inproceedings{pedregosa2020linearly,
    title={Linearly Convergent Frank-Wolfe with Backtracking Line-Search},
    author={Pedregosa, Fabian and Negiar, Geoffrey and Askari, Armin and Jaggi, Martin},
    booktitle={International Conference on Artificial Intelligence and Statistics},
    series = {Proceedings of Machine Learning Research},
    year={2020},
    _url={https://fa.bianp.net/blog/2022/adaptive_fw/}
  }