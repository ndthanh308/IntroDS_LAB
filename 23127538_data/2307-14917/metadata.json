{
  "title": "NSA: Naturalistic Support Artifact to Boost Network Confidence",
  "authors": [
    "Abhijith Sharma",
    "Phil Munz",
    "Apurva Narayan"
  ],
  "submission_date": "2023-07-27T15:00:31+00:00",
  "revised_dates": [],
  "abstract": "Visual AI systems are vulnerable to natural and synthetic physical corruption in the real-world. Such corruption often arises unexpectedly and alters the model's performance. In recent years, the primary focus has been on adversarial attacks. However, natural corruptions (e.g., snow, fog, dust) are an omnipresent threat to visual AI systems and should be considered equally important. Many existing works propose interesting solutions to train robust models against natural corruption. These works either leverage image augmentations, which come with the additional cost of model training, or place suspicious patches in the scene to design unadversarial examples. In this work, we propose the idea of naturalistic support artifacts (NSA) for robust prediction. The NSAs are shown to be beneficial in scenarios where model parameters are inaccessible and adding artifacts in the scene is feasible. The NSAs are natural looking objects generated through artifact training using DC-GAN to have high visual fidelity in the scene. We test against natural corruptions on the Imagenette dataset and observe the improvement in prediction confidence score by four times. We also demonstrate NSA's capability to increase adversarial accuracy by 8\\% on average. Lastly, we qualitatively analyze NSAs using saliency maps to understand how they help improve prediction confidence.",
  "categories": [
    "cs.CV",
    "cs.LG"
  ],
  "primary_category": "cs.CV",
  "doi": null,
  "journal_ref": null,
  "arxiv_id": "2307.14917",
  "pdf_url": "https://arxiv.org/pdf/2307.14917v1",
  "comment": null,
  "num_versions": null,
  "size_before_bytes": 6993602,
  "size_after_bytes": 71973
}