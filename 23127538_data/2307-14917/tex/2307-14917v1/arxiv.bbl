\begin{thebibliography}{10}

\bibitem{taigman2014deepface}
Yaniv Taigman, Ming Yang, Marc'Aurelio Ranzato, and Lior Wolf.
\newblock Deepface: Closing the gap to human-level performance in face
  verification.
\newblock In {\em Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 1701--1708, 2014.

\bibitem{mnih2015human}
Volodymyr Mnih, Koray Kavukcuoglu, David Silver, Andrei~A Rusu, Joel Veness,
  Marc~G Bellemare, Alex Graves, Martin Riedmiller, Andreas~K Fidjeland, Georg
  Ostrovski, et~al.
\newblock Human-level control through deep reinforcement learning.
\newblock {\em nature}, 518(7540):529--533, 2015.

\bibitem{gu2019survey}
Yating Gu, Yantian Wang, and Yansheng Li.
\newblock A survey on deep learning-driven remote sensing image scene
  understanding: Scene classification, scene retrieval and scene-guided object
  detection.
\newblock {\em Applied Sciences}, 9(10):2110, 2019.

\bibitem{guo2021survey}
Zhiyang Guo, Yingping Huang, Xing Hu, Hongjian Wei, and Baigan Zhao.
\newblock A survey on deep learning based approaches for scene understanding in
  autonomous driving.
\newblock {\em Electronics}, 10(4):471, 2021.

\bibitem{fang2020rethinking}
Tongtong Fang, Nan Lu, Gang Niu, and Masashi Sugiyama.
\newblock Rethinking importance weighting for deep learning under distribution
  shift.
\newblock {\em Advances in Neural Information Processing Systems},
  33:11996--12007, 2020.

\bibitem{hendrycks2021many}
Dan Hendrycks, Steven Basart, Norman Mu, Saurav Kadavath, Frank Wang, Evan
  Dorundo, Rahul Desai, Tyler Zhu, Samyak Parajuli, Mike Guo, et~al.
\newblock The many faces of robustness: A critical analysis of
  out-of-distribution generalization.
\newblock In {\em Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pages 8340--8349, 2021.

\bibitem{hendrycks2019benchmarking}
Dan Hendrycks and Thomas Dietterich.
\newblock Benchmarking neural network robustness to common corruptions and
  perturbations.
\newblock {\em arXiv preprint arXiv:1903.12261}, 2019.

\bibitem{kopestinsky25astonishing}
Alex Kopestinsky.
\newblock astonishing self-driving car statistics for 2021.
\newblock {\em Policy Advice}, 25.

\bibitem{madry2017towards}
Aleksander Madry, Aleksandar Makelov, Ludwig Schmidt, Dimitris Tsipras, and
  Adrian Vladu.
\newblock Towards deep learning models resistant to adversarial attacks.
\newblock {\em arXiv preprint arXiv:1706.06083}, 2017.

\bibitem{ilyas2019adversarial}
Andrew Ilyas, Shibani Santurkar, Dimitris Tsipras, Logan Engstrom, Brandon
  Tran, and Aleksander Madry.
\newblock Adversarial examples are not bugs, they are features.
\newblock {\em Advances in neural information processing systems}, 32, 2019.

\bibitem{szegedy2013intriguing}
Christian Szegedy, Wojciech Zaremba, Ilya Sutskever, Joan Bruna, Dumitru Erhan,
  Ian Goodfellow, and Rob Fergus.
\newblock Intriguing properties of neural networks.
\newblock {\em arXiv preprint arXiv:1312.6199}, 2013.

\bibitem{tsipras2018robustness}
Dimitris Tsipras, Shibani Santurkar, Logan Engstrom, Alexander Turner, and
  Aleksander Madry.
\newblock Robustness may be at odds with accuracy.
\newblock {\em arXiv preprint arXiv:1805.12152}, 2018.

\bibitem{eykholt2018robust}
Kevin Eykholt, Ivan Evtimov, Earlence Fernandes, Bo~Li, Amir Rahmati, Chaowei
  Xiao, Atul Prakash, Tadayoshi Kohno, and Dawn Song.
\newblock Robust physical-world attacks on deep learning visual classification.
\newblock In {\em Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 1625--1634, 2018.

\bibitem{athalye2018synthesizing}
Anish Athalye, Logan Engstrom, Andrew Ilyas, and Kevin Kwok.
\newblock Synthesizing robust adversarial examples.
\newblock In {\em International conference on machine learning}, pages
  284--293. PMLR, 2018.

\bibitem{goodfellow2014explaining}
Ian~J Goodfellow, Jonathon Shlens, and Christian Szegedy.
\newblock Explaining and harnessing adversarial examples.
\newblock {\em arXiv preprint arXiv:1412.6572}, 2014.

\bibitem{carlini2017towards}
Nicholas Carlini and David Wagner.
\newblock Towards evaluating the robustness of neural networks.
\newblock In {\em 2017 ieee symposium on security and privacy (sp)}, pages
  39--57. Ieee, 2017.

\bibitem{brown2017adversarial}
Tom~B Brown, Dandelion Man{\'e}, Aurko Roy, Mart{\'\i}n Abadi, and Justin
  Gilmer.
\newblock Adversarial patch.
\newblock {\em arXiv preprint arXiv:1712.09665}, 2017.

\bibitem{10.1145/3579988.3585054}
Abhijith Sharma, Yijun Bian, Vatsal Nanda, Phil Munz, and Apurva Narayan.
\newblock Vulnerability of cnns against multi-patch attacks.
\newblock In {\em Proceedings of the 2023 ACM Workshop on Secure and
  Trustworthy Cyber-Physical Systems}, page 23â€“32, 2023.

\bibitem{akhtar2018threat}
Naveed Akhtar and Ajmal Mian.
\newblock Threat of adversarial attacks on deep learning in computer vision: A
  survey.
\newblock {\em Ieee Access}, 6:14410--14430, 2018.

\bibitem{sharma2022adversarial}
Abhijith Sharma, Yijun Bian, Phil Munz, and Apurva Narayan.
\newblock Adversarial patch attacks and defences in vision-based tasks: A
  survey.
\newblock {\em arXiv preprint arXiv:2206.08304}, 2022.

\bibitem{icaart22}
Abhijith Sharma. and Apurva Narayan.
\newblock Soft adversarial training can retain natural accuracy.
\newblock In {\em Proceedings of the 14th International Conference on Agents
  and Artificial Intelligence - Volume 3: ICAART,}, pages 621--628, 2022.

\bibitem{chou2020sentinet}
Edward Chou, Florian Tramer, and Giancarlo Pellegrino.
\newblock Sentinet: Detecting localized universal attacks against deep learning
  systems.
\newblock In {\em 2020 IEEE Security and Privacy Workshops (SPW)}, pages
  48--54. IEEE, 2020.

\bibitem{xiang2022patchcleanser}
Chong Xiang, Saeed Mahloujifar, and Prateek Mittal.
\newblock $\{$PatchCleanser$\}$: Certifiably robust defense against adversarial
  patches for any image classifier.
\newblock In {\em 31st USENIX Security Symposium (USENIX Security 22)}, pages
  2065--2082, 2022.

\bibitem{shorten2019survey}
Connor Shorten and Taghi~M Khoshgoftaar.
\newblock A survey on image data augmentation for deep learning.
\newblock {\em Journal of big data}, 6(1):1--48, 2019.

\bibitem{rebuffi2021data}
Sylvestre-Alvise Rebuffi, Sven Gowal, Dan~Andrei Calian, Florian Stimberg,
  Olivia Wiles, and Timothy~A Mann.
\newblock Data augmentation can improve robustness.
\newblock {\em Advances in Neural Information Processing Systems},
  34:29935--29948, 2021.

\bibitem{rebuffi2021fixing}
Sylvestre-Alvise Rebuffi, Sven Gowal, Dan~A Calian, Florian Stimberg, Olivia
  Wiles, and Timothy Mann.
\newblock Fixing data augmentation to improve adversarial robustness.
\newblock {\em arXiv preprint arXiv:2103.01946}, 2021.

\bibitem{salman2021unadversarial}
Hadi Salman, Andrew Ilyas, Logan Engstrom, Sai Vemprala, Aleksander Madry, and
  Ashish Kapoor.
\newblock Unadversarial examples: Designing objects for robust vision.
\newblock {\em Advances in Neural Information Processing Systems},
  34:15270--15284, 2021.

\bibitem{wang2022defensive}
Jiakai Wang, Zixin Yin, Pengfei Hu, Aishan Liu, Renshuai Tao, Haotong Qin,
  Xianglong Liu, and Dacheng Tao.
\newblock Defensive patches for robust recognition in the physical world.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 2456--2465, 2022.

\bibitem{li2022collaborative}
Qizhang Li, Yiwen Guo, Wangmeng Zuo, and Hao Chen.
\newblock Collaborative adversarial training.
\newblock {\em arXiv preprint arXiv:2205.11156}, 2022.

\bibitem{gulrajani2017improved}
Ishaan Gulrajani, Faruk Ahmed, Martin Arjovsky, Vincent Dumoulin, and Aaron~C
  Courville.
\newblock Improved training of wasserstein gans.
\newblock {\em Advances in neural information processing systems}, 30, 2017.

\bibitem{doan2022tnt}
Bao~Gia Doan, Minhui Xue, Shiqing Ma, Ehsan Abbasnejad, and Damith~C
  Ranasinghe.
\newblock Tnt attacks! universal naturalistic adversarial patches against deep
  neural network systems.
\newblock {\em IEEE Transactions on Information Forensics and Security},
  17:3816--3830, 2022.

\bibitem{simonyan2014very}
Karen Simonyan and Andrew Zisserman.
\newblock Very deep convolutional networks for large-scale image recognition.
\newblock {\em arXiv preprint arXiv:1409.1556}, 2014.

\bibitem{he2016deep}
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
\newblock Deep residual learning for image recognition.
\newblock In {\em Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 770--778, 2016.

\bibitem{krizhevsky2017imagenet}
Alex Krizhevsky, Ilya Sutskever, and Geoffrey~E Hinton.
\newblock Imagenet classification with deep convolutional neural networks.
\newblock {\em Communications of the ACM}, 60(6):84--90, 2017.

\bibitem{Pal2021}
Avik Pal and Aniket Das.
\newblock Torchgan: A flexible framework for gan training and evaluation.
\newblock {\em Journal of Open Source Software}, 6(66):2606, 2021.

\bibitem{michaelis2019dragon}
Claudio Michaelis, Benjamin Mitzkus, Robert Geirhos, Evgenia Rusak, Oliver
  Bringmann, Alexander~S. Ecker, Matthias Bethge, and Wieland Brendel.
\newblock Benchmarking robustness in object detection: Autonomous driving when
  winter is coming.
\newblock {\em arXiv preprint arXiv:1907.07484}, 2019.

\bibitem{selvaraju2017grad}
Ramprasaath~R Selvaraju, Michael Cogswell, Abhishek Das, Ramakrishna Vedantam,
  Devi Parikh, and Dhruv Batra.
\newblock Grad-cam: Visual explanations from deep networks via gradient-based
  localization.
\newblock In {\em Proceedings of the IEEE international conference on computer
  vision}, pages 618--626, 2017.

\end{thebibliography}
