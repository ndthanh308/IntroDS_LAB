\vspace{-0.05in}
\section{Experiments}
\label{sec:exps}
\vspace{-0.1in}

\subsection{Experimental Setup}
\label{sec:setup}
\vspace{-0.1in}

\noindent\textbf{Datasets}.
We evaluate Text-CRS on three textual datasets, AG’s News (AG)~\cite{zhang2015character}, Amazon~\cite{mcauley2013hidden}, and IMDB~\cite{maas2011learning}. The AG dataset collects news articles (sentence-level), covering four topic classes. The Amazon dataset consists of positive and negative product reviews (document level). %Reviews with a rating of 1 or 2 are labeled negative sentiments, and those with 4 or 5 are labeled positive. 
The IMDB dataset contains document-level movie reviews with positive and negative sentiments. %reviews scoring $\geq 7$ and negative reviews scoring $\leq 4$. 
The average sample lengths of them are $43$, $81$, and $215$, respectively. 
% Dataset statistics are summarized in Table~\ref{tab:dataset}. (see Table~\ref{tab:dataset})

\vspace{0.03in}

\noindent\textbf{Models and Embedding Layers}.
We conduct experiments on two common NLP models, LSTM \cite{LSTM} and BERT \cite{devlin-etal-2019-bert} with the pre-trained embedding layers. For LSTM, we use a 1-layer bidirectional LSTM with $150$ hidden units and the $300$-dimensional Glove word embeddings trained on $42$ billion tokens of web data from Common Crawl \cite{pennington2014glove}. For BERT, we use a pre-trained $12$-layer bert-base-uncased model with $12$ attention heads. The pre-trained embedding layer in BERT outputs $768$-dimensional hidden features for each token. We freeze the pre-trained embedding layer in both LSTM and BERT and only update the parameters of the classification models.

%\BW{Which embedding/pre-trained models are used?}\xy{added}
\vspace{0.03in}

\noindent\textbf{Evaluation Metric}. We report the model accuracy on the clean test set for vanilla training (\emph{Clean vanilla}) and certified robust training (\emph{Clean Acc.}) (see Table~\ref{tab:clean_acc}). Under robust training, we also evaluate the \emph{certified accuracy}, defined as the fraction of the test set classified correctly and certified robust. 
% We compare certified accuracy under different radii. 
{We uniformly select $500$ examples from the clean test set of each dataset. For each example, we use $N_0=100$ samples for selecting the most likely class $y_A$ and $N=10^5$ samples for estimating confidence lower bound $\underline{p_A}$.} We set $\alpha=0.001$ for certification with at least 99.9\% confidence. 
To test the model's robustness against unseen attacks,
we evaluated Text-CRS against five real-world attacks (TextFooler\cite{jin2020bert}, WordReorder\cite{moradi2021evaluating}, SynonymInsert\cite{morris2020textattack}, BAE-Insert\cite{garg2020bae}, and InputReduction\cite{feng2018pathologies} w.r.t. four word-level adversarial operations)\footnote{BAE-Insert attacks on BERT, and other attacks are model-agnostic. 
Similar to Jin et al.\cite{jin2020bert}, we use Universal Sentence Encoder~\cite{cer2018universal} to encode text as high-dimensional vectors and constrain the similarity of the adversarial vector to the original vector to ensure that all generated adversarial examples are semantically similar to the original texts. 
}, and generate $1,000$ successful adversarial examples for each dataset and model. We calculate the \emph{attack accuracy} of the vanilla model under attack as the percent of unsuccessful adversarial examples divided by the number of attempted examples (see Table~\ref{tab:attack_acc}). For Text-CRS against these attacks, we uniformly select 500 successful adversarial examples for each attack and evaluate the \emph{certified accuracy} with $N=2\times 10^4$. 
Since the baselines can only certify against substitution operations, we evaluate their \emph{certified accuracy} against TextFooler. For the other attacks, we evaluate their \emph{empirical accuracy}, the percent of adversarial examples correctly classified (no certification).
 % with $N=2\times 10^4$. 


% and evaluate the impact of different $N$ on certified accuracy
% Following the setup in~\cite{cohen2019certified}, 
% report the attack performance to the vanilla training model. 


\vspace{0.03in}

\noindent\textbf{Noise Parameters}. 
We use three levels of noise (i.e., Low, Medium (Med.), and High) for the four smoothing methods (see Table~\ref{tab:params}). Synonym substitution based on the Staircase PDF uses the size of the lexicon ($s$) to control the PDF's sensitivity, i.e., $\epsilon=5/s$. For other parameters in the staircase PDF, we fix the interval size of a word as $\Delta=1$ and set an equal probability within each interval, i.e., $\gamma=1$. Uniform-based permutation specifies the noise with the length of the reordering group, i.e., the noise PDF of $\CU[-\lambda, \lambda]$ is $1/2\lambda$. 
% In the low level, $2\lambda=n/4$, which means we randomly and uniformly divide the entire text into four groups. 
While using uniform permutation in word insertion and deletion, we set the noise level to $n$, i.e., reordering the entire text. Gaussian-based embedding insertion uses the standard deviation $\sigma$ to specify the noise. We set different $\sigma$ in LSTM and BERT models due to different embedding dimensions and magnitudes. %(which can tolerate different levels of Gaussian noise). 
Bernoulli-based smoothing uses the deletion probability $p$ of each word as the noise.



\begin{table}[!t]
%\vspace{-0.1in}
\centering
\setlength\tabcolsep{3pt}
\caption{Noise parameters for adversarial operations}
\vspace{-0.05in}
\begin{tabular}{|c|c|c|cc|cc|}
\hline
Operations & Substitution & Reordering & \multicolumn{2}{c|}{Insertion} & \multicolumn{2}{c|}{Deletion} \\ \hline
Noise & $s$ & $2\lambda$ & $2\lambda$ & $\sigma$(LSTM, BERT) & $2\lambda$ & $p$  \\ \hline
Low & $50$ & $n/4$ & $n$ & \ $0.1$,\quad $0.5$  & $n$ & $0.3$ \\
Med. & $100$ & $n/2$ & $n$ & \ $0.2$,\quad $1.0$ & $n$ & $0.5$  \\
High & $250$ & $n$ & $n$ & \ $0.3$,\quad $1.5$ & $n$ & $0.7$  \\ \hline
\end{tabular}
\label{tab:params}
\vspace{-4mm}
\end{table}


\vspace{0.03in}

\noindent\textbf{Training Toolkit}. 
\ding{172} In OGN, we use the average of the parameters of the pre-trained embedding layers (i.e., Glove word embeddings for LSTM and BERT's pre-trained embedding layer for BERT) as the mean value of Gaussian noise in each dimension ($\mu_i$). 
\ding{173} In ESR, we utilize two fully-connected layers as the encoder-decoder for LSTM. 
\ding{174} In PLM, we set the learning rate to $0.00003$, training epochs to $10$, and the Gaussian noise level to $\sigma=0.1$ for training the pre-trained BERT model with Gaussian noise.


%\noindent\textbf{Real-world Adversarial Attacks}. 
\vspace{0.03in}

\noindent\textbf{Baselines}. 
We compare our methods with two SOTA randomized smoothing-based certified defenses, SAFER~\cite{ye2020safer} and CISS~\cite{zhao2022certified}. 1) \emph{SAFER} certifies against synonym substitution. 
% We set the noise level (i.e., the size of the lexicon) in SAFER the same as our substitution method.
Following the same setting~\cite{ye2020safer,jia2019certified} for the synonym substitution, we construct synonym sets by the cosine similarity of Glove word embeddings~\cite{pennington2014glove} and sort all synonyms in the descending order of similarity.
2) \emph{CISS} is an IBP and randomized smoothing-based method against word substitution. CISS provides only the training and certification pipelines for the BERT model. Thus, we only compare our Text-CRS with CISS under the BERT model. 
% We set the noise parameter as 



% For fair comparisons, we used the same training pipeline for each method. We train LSTM from scratch (without a pre-trained classification model) for 50 epochs with a learning rate of $lr=3\times 10^{-5}$ and BERT from the bert-base-uncased model for 50 epochs with $lr=1\times 10^{-3}$. 



% \subsubsection{Code and implementation}
% We implement our framework based on PyTorch. 
% All experiments were run on 16-core Intel Xeon Gold 6226R CPUs and NVIDIA GeForce RTX 3090 GPUs with 24GB RAM. 
% TextAttack\cite{morris2020textattack}

% Substitution, reordering, and deletion operations are directly trained with noise, without employing any training toolkits. Note that toolkits can further improve their certification performance.

Note that the smoothed models against substitution, reordering, and deletion operations are trained without the use of training toolkits. The training toolkits can further improve their certification performance.

% Using toolkits can improve accuracy even more.

\vspace{-0.1in}
\subsection{Experimental Results}
\label{sec:results}
\vspace{-0.1in}

\subsubsection{Evaluating Adversarial Examples using ChatGPT}

We assess the practical significance of textual adversarial examples by evaluating whether ChatGPT (version ``gpt-3.5-turbo-0301'') can determine if a successful adversarial example is semantically similar to the original text. Specifically, we request ChatGPT to assess the semantic similarity (categorized as ``Yes'' or ``No'') and calculate the cosine similarity between the adversarial and original texts. Table~\ref{tab:chatgpt_results} shows the deception rate, which represents the percent of successful adversarial examples that ChatGPT considered semantically similar to the original texts, as well as the cosine similarity of total successful examples, and the cosine similarity of the examples that deceive ChatGPT. The results show an average of $73\%$ of all successful adversarial examples can deceive ChatGPT, highlighting the severe threat posed by textual adversarial examples. Furthermore, we observe that longer texts, such as those in Amazon and IMDB, are easier to fool ChatGPT, due to the challenges in detecting small perturbations in longer texts. Finally, the cosine similarities of all our successful adversarial examples are high, particularly in the case of SynonymInsert and BAE-Insert attacks, unveiling that word insertion can effectively fool the vanilla model with minimal perturbations. 
% and the higher the similarity, the better the effect of deceiving ChatGPT.


\begin{table}[!h]
\setlength\tabcolsep{3pt}
\centering
\scriptsize
\caption{Evaluation on adversarial examples by ChatGPT.}
\vspace{-0.05in}
% \resizebox{\linewidth}{!}{
\begin{tabular}{lcccccc}
\toprule
Metric & \multicolumn{3}{c}{Deception rate} & \multicolumn{3}{c}{Cosine similarity (success / deception)} \\
\cmidrule(r){2-4} \cmidrule(r){5-7}
Attack type & AG & Amazon & IMDB & AG & Amazon & IMDB \\
\midrule
TextFooler & 58\% & 78\% & 85\% & 0.92 / 0.97 & 0.81 / 0.94 & 0.97 / 0.99 \\
WordReorder & 63\% & 53\% & 60\% & 0.84 / 0.95 & 0.79 / 0.91 & 0.90 / 0.97 \\
SynonymInsert & 75\% & 89\% & 85\% & 0.97 / 0.98 & 0.95 / 0.98 & 0.98 / 0.99 \\
BAE-Insert & 66\% & 88\% & 71\% & 0.96 / 0.97 & 0.91 / 0.97 & 0.97 / 0.99 \\
InputReduction & 75\% & 78\% & 73\% & 0.89 / 0.96 & 0.85 / 0.93 & 0.94 / 0.98 \\
\midrule
Average & 67\% & 77\% & 75\% & 0.92 / 0.97 & 0.86 / 0.95 & 0.95 / 0.98 \\
\bottomrule
\end{tabular}
% }
\vspace{-1mm}
\label{tab:chatgpt_results}
\end{table}


\vspace{-0.1in}
\subsubsection{Certified Robustness of Text-CRS}


\begin{table}[]
\centering
\setlength\tabcolsep{2pt}
\scriptsize
\caption{Certified accuracy under adversarial operations. We compare the substitution with SAFER\cite{ye2020safer} and CISS\cite{zhao2022certified}, and provide a benchmark for other operations.}
\vspace{-0.05in}
\resizebox{\linewidth}{!}{
\begin{tabular}{ccccccccc}
\toprule
\multirow{2}{*}{\begin{tabular}[c]{@{}c@{}}Dataset\\ (Model) \end{tabular}} & \multirow{2}{*}{\begin{tabular}[c]{@{}c@{}} \emph{Clean}\\ \emph{vanilla}  \end{tabular}} & \multirow{2}{*}{\begin{tabular}[c]{@{}c@{}} Noise  \end{tabular}} & \multicolumn{3}{c}{\begin{tabular}[c]{@{}c@{}} Synonym substitution\end{tabular}} & \begin{tabular}[c]{@{}c@{}} Reordering\end{tabular} & \begin{tabular}[c]{@{}c@{}} Insertion\end{tabular} & \begin{tabular}[c]{@{}c@{}} Deletion\end{tabular} \\
\cmidrule(r){4-6} \cmidrule(r){7-7} \cmidrule(r){8-8} \cmidrule(r){9-9}
 & & & SAFER & CISS & Ours & Ours & Ours & Ours \\
\midrule
\multirow{3}{*}{\begin{tabular}[c]{@{}c@{}}AG\\ (LSTM)\end{tabular}} & & Low & 86.4\% &  & \textbf{88.8\%} & \textbf{92.4\%} & \textbf{88.6\%} & \textbf{91.2\%} \\
& 91.79\% & Med. & 85.2\% & - & 88.6\% & 91.6\% & 88.2\% & 90.2\% \\
& & High & 83.2\% &  & 87.0\% & \textbf{92.4\%} & 82.8\% & 88.4\% \\
\midrule
 \multirow{3}{*}{\begin{tabular}[c]{@{}c@{}}AG\\ (BERT)\end{tabular}} &  & Low & 92.0\% & 85.6\% & \textbf{92.8\%} & \textbf{95.6\%} & \textbf{93.6\%} & \textbf{94.6\%} \\
& 93.68\% & Med. & 89.2\% & 86.8\% & 92.0\% & 93.6\% & 93.0\% & 93.3\% \\
& & High & 87.2\% & 85.6\% & 91.2\% & 94.4\% & 91.2\% & 92.8\% \\
 \midrule
 \multirow{3}{*}{\begin{tabular}[c]{@{}c@{}}Amazon\\ (LSTM)\end{tabular}} &  & Low & 82.8\% &  & 82.6\% & 87.2\% & \textbf{85.2\%} & \textbf{88.8\%} \\
& 89.82\% & Med. & 80.0\% & - & 82.4\% & 85.8\% & 79.0\% & \textbf{88.8\%} \\
& & High & 80.2\% &  & \textbf{83.6\%} & \textbf{88.4\%} & 75.6\% & 87.2\% \\
\midrule
\multirow{3}{*}{\begin{tabular}[c]{@{}c@{}}Amazon\\ (BERT)\end{tabular}} &  & Low & 90.2\% & 84.4\% & \textbf{93.6\%} & \textbf{94.8\%} & \textbf{94.4\%} & \textbf{93.8\%} \\
& 94.35\% & Med. & 86.4\% & 83.4\% & 90.2\% & 93.6\% & 92.6\% & 91.8\% \\
& & High & 86.2\% & 83.2\% & 87.6\% & 93.8\% & 89.0\% & 88.6\% \\
 \midrule
\multirow{3}{*}{\begin{tabular}[c]{@{}c@{}}IMDB\\ (LSTM)\end{tabular}} &  & Low & 77.8\% &  & \textbf{84.0\%} & \textbf{88.8\%} & \textbf{82.2\%} & \textbf{86.0\%} \\
& 86.17\% & Med. & 77.6\% & - & 81.6\% & 84.6\% & 79.2\% & 85.4\% \\
& & High & 77.0\% &  & 78.8\% & 83.4\% & 71.4\% & 84.8\% \\
\midrule
\multirow{3}{*}{\begin{tabular}[c]{@{}c@{}}IMDB\\ (BERT)\end{tabular}} &  & Low & 86.4\% & 84.8\% & \textbf{89.6\%} & 92.2\% & \textbf{90.8\%} & \textbf{91.4\%} \\
& 91.52\% & Med. & 82.8\% & 82.4\% & 83.6\% & \textbf{92.4\%} & 88.4\% & 90.2\% \\
& & High & 75.8\% & 84.0\% & 78.8\% & 91.8\% & 84.0\% & 89.2\% \\
\bottomrule
\end{tabular}
}
\vspace{-4mm}
\label{tab:certi_acc_benchmark}
\end{table}


Table~\ref{tab:certi_acc_benchmark} summarizes the certified accuracy of Text-CRS against four word-level operations on different datasets, models, and noise. For synonym substitution, we use the same synonym set and noise parameters as SAFER. The results demonstrate that Text-CRS outperforms SAFER for all noise levels under three datasets and two models. Specifically, Text-CRS is more accurate than SAFER (under LSTM and BERT) and CISS (under BERT) in all the settings. To our best knowledge, Text-CRS is the first to provide certified robustness for word reordering, insertion, and deletion. Compared to \emph{Clean vanilla}, Text-CRS sacrifices only a small fraction of accuracy. Across all $24$ settings, including $4\ \textrm{operations} \times\! \ 3\ \textrm{datasets} \times\! \ 2\ \textrm{models}$, Text-CRS provides an average best certified accuracy of $90.2\%$ (bold), with a small drop compared to the average vanilla accuracy of $91.22\%$. 

Moreover, our methods for substitution, insertion, and deletion achieve the best certified accuracy with low noise, indicating that smaller noise has less impact on model performance. Conversely, the best certified accuracy for reordering can be achieved at low, medium, or high noise levels, as the results suggest that robust training with reordering operations has little effect on the model accuracy. Regarding model structures, Text-CRS outperforms SOTA methods under LSTM and achieves superior performance under BERT, with a certified accuracy that is closer to or exceeds that of \emph{Clean vanilla}. Regarding the dataset, Text-CRS demonstrates better performance on large-scale datasets, such as IMDB, where the substitution method outperforms SAFER by $1.6\%$ and $4.7\%$ on AG and IMDB, and CISS by $6.0\%$ and $4.8\%$ on AG and IMDB, respectively.

% We report the certified accuracy of the clean test set of each dataset under different smoothing parameters in Table~\ref{}. 

% 1. compare: safer, ciss
% 2. compare: clean vanilla
% 3. from  params, model structure, dataset



\vspace{-0.1in}
\subsubsection{Certified Accuracy under Different Radii} \label{sec:acc_radii}


We examine the effect of certified radii with different noise levels on the certified accuracy against four adversarial operations, as depicted in Figure~\ref{fig:noise5_certify_result} to \ref{fig:noise4_certify_result}. The results indicate that the certified accuracy declines as the radius increases, and it abruptly drops to zero at a certain radius threshold, consistent with the results in the image domain~\cite{cohen2019certified}. Moreover, the impact of noise level on certified accuracy increases with the magnitude of the noise, while a large noise level can improve the certified radius. In other words, selecting a larger noise is necessary while aiming for a wider certification range. Thus, it is crucial to choose an appropriate smoothing magnitude for each specific setting carefully. 
% We also observe that BERT performs better than LSTM overall, especially on the Amazon and IMDB datasets. This is due to the fact that the Bert model provides a higher \emph{clean vanilla} accuracy and 


% Figure environment removed


% Figure environment removed


% Figure environment removed



\begin{table*}[]
\setlength\tabcolsep{3pt}
\scriptsize %footnotesize 
\caption{Comparison of certified accuracy of Text-CRS, SAFER~\cite{ye2020safer} and CISS~\cite{zhao2022certified} under different attacks. “$*$” indicates that SAFER and CISS cannot certify operations other than substitution, resulting in a certified accuracy of $0\%$ for these attacks, so we report their empirical accuracy. “-” indicates that BAE-Insert and CISS cannot be performed on LSTM. } %  does not provide an LSTM training pipeline
\vspace{-0.05in}
\resizebox{\linewidth}{!}{
\begin{tabular}{lcccccccccccccccc}
\toprule
 & \multicolumn{1}{l}{} & \multicolumn{3}{c}{TextFooler\cite{jin2020bert}} & \multicolumn{3}{c}{WordReorder\cite{moradi2021evaluating}} & \multicolumn{3}{c}{SynonymInsert\cite{morris2020textattack}} & \multicolumn{3}{c}{BAE-Insert\cite{garg2020bae}} & \multicolumn{3}{c}{InputReduction\cite{feng2018pathologies}} \\
 \cmidrule(r){3-5} \cmidrule(r){6-8} \cmidrule(r){9-11} \cmidrule(r){12-14} \cmidrule(r){15-17} 
Dataset (Model) & \multicolumn{1}{l}{\emph{Vanilla}} & \multicolumn{1}{c}{SAFER} & \multicolumn{1}{c}{CISS} & \multicolumn{1}{c}{Ours} & \multicolumn{1}{c}{SAFER$^*$} & \multicolumn{1}{c}{CISS$^*$} & \multicolumn{1}{c}{Ours} & \multicolumn{1}{c}{SAFER$^*$} & \multicolumn{1}{c}{CISS$^*$} & \multicolumn{1}{c}{Ours} & \multicolumn{1}{c}{SAFER$^*$} & \multicolumn{1}{c}{CISS$^*$} & \multicolumn{1}{c}{Ours} & \multicolumn{1}{c}{SAFER$^*$} & \multicolumn{1}{c}{CISS$^*$} & \multicolumn{1}{c}{Ours} \\
\midrule
AG (LSTM) & 0\% & 90.4\% & -  & \textbf{91.2\%} & 75.4\% & - & \textbf{89.2\%} & 77.6\% & - & \textbf{84.2\%} & - & - & - & 65.8\% & - & \textbf{78.4\%} \\
AG (BERT) & 0\% & 93.2\% & 71.4\% & \textbf{93.6\%} & 86.8\% & 83.8\% & \textbf{87.6\%} & 77.8\% & 74.6\% & \textbf{83.6\%} & \textbf{79.8\%} & 74.0\% & 79.4\% & 55.8\% & 59.0\% & \textbf{68.4\%} \\
Amazon (LSTM) & 0\% & 82.4\% & - & \textbf{83.4\%} & 78.0\% & - & \textbf{91.2\%} & 64.0\% & - & \textbf{71.8\%} & - & - & - & 71.2\% & - & \textbf{74.2\%} \\
Amazon (BERT) & 0\% & 87.0\% & 75.4\% & \textbf{90.8\%} & 82.0\% & \textbf{88.0\%} & 84.6\% & 67.8\% & 67.8\% & \textbf{80.6\%} & 70.4\% & 70.4\% & \textbf{71.2\%} & 68.6\% & 74.0\% & \textbf{82.0\%} \\
IMDB   (LSTM) & 0\% & 82.0\% & - & \textbf{84.6\%} & 77.8\% & - & \textbf{86.0\%} & 66.8\% & - & \textbf{69.6\%} & - & - & - & 68.8\% & - & \textbf{77.0\%} \\
IMDB   (BERT) & 0\% & 83.8\% & 25.6\% & \textbf{84.4\%} & 80.2\% & 24.8\% & \textbf{83.0\%} & 76.8\% & 31.6\% & \textbf{86.2\%} & 77.0\% & 33.0\% & \textbf{80.6\%} & 70.6\% & 29.8\% & \textbf{82.8\%} \\
\midrule
Average & 0\% & 86.5\% & 57.5\% & \textbf{88.0\%} & 80.0\% & 65.5\% & \textbf{86.9\%} & 71.8\% & 58.0\% & \textbf{79.3\%} & 75.7\% & 59.1\% & \textbf{77.1\%} & 66.8\% & 54.3\% & \textbf{77.1\%} \\
\bottomrule
\end{tabular}
}
\vspace{-4mm}
\label{tab:certi_acc_attacks}
\end{table*}


% Figure environment removed


Figure~\ref{fig:noise5_certify_result} depicts the certified accuracy with different sizes of synonym sets. A radius of $\rad_S \!=\! 200$ for a sentence with a length of 50 implies that each word can be substituted with its four closest synonyms in the thesaurus. In such cases, the prediction results of the smoothed classifier remain the same as the original sentence. Figure~\ref{fig:noise8_certify_result} depicts the certified accuracy under different sizes of shuffling groups. The radius $\rad_R \!=\! 100$ indicates that Text-CRS certifies a text in which the sum of all word positions changes is less than $100$. Figure~\ref{fig:noise3_certify_result} presents the certified accuracy under different Gaussian noise. The radius $\rad_I$ denotes the cumulative embedding $\ell_2$ distances between the original and the inserted word. To illustrate the practical significance of our radius, we calculate the $\ell_2$ distance between $65,713$ words and their closest top-$k$ embeddings under Glove embedding space and BERT embedding space (see Figure~\ref{fig:top-k_closest_embedding}). The results indicate that under $\rad_I \!=\! 0.2$, the LSTM model (using GloVe embedding space) could withstand $\sim$7\% of random word insertions among all the top-3 closest words. The BERT model performs better than LSTM, which can withstand $\sim$53\% and $\sim$11\% of random word insertions among the top-5 and top-50 closest embeddings, respectively, under $\rad_I \!=\! 2$. 
% The results demonstrate that Text-CRS can provide certified robustness against multiple random word insertions. 
Figure~\ref{fig:noise4_certify_result} shows the certified accuracy under different word deletion probabilities, where a radius $\rad_D \!=\! 2$ indicates that up to two words can be deleted while ensuring the certified robustness of the text. Note that Figure~\ref{fig:noise8_certify_result} also shows the certified radius on word position changes in word insertion and deletion operations. 



% Figure environment removed


Furthermore, regarding the word reordering, the noise level has little effect on the certified accuracy, particularly for the BERT, which uses a transformer structure to represent each word as a weighted sum of all input word embeddings~\cite{vaswani2017attention}. Consequently, the prediction of BERT contains information about every word, and the reordering of words has a reduced effect on the resultant output of BERT. This implies that we can choose a large noise level to achieve high certified accuracy while obtaining the largest certified radius simultaneously. It is consistent with our reordering strategies in word insertion and deletion operations. 



 % The perturbation of word reordering ($\delta_{R}$) represents the cumulative distance between each word's coordinate between the original and modified sentence. $\rad_R = 100$ means that 10 words in the sentence can be moved to a position within 10 range from the original coordinates.

% We can observe that for synonym substitution and word insertion operations, BERT achieves higher certified accuracy overall than LSTM. On the other hand, the certified accuracy of the AG and Amazon datasets is higher than the IMDB dataset. This is because, in the case of the vanilla model, the Bert model and AG and Amazon datasets are more accurate. We can observe that the smoothing parameter (i.e, $s, \sigma$) controls a robustness/accuracy trade-off. When $s$ is low, small radii can be certified with high accuracy, but large radii cannot. When $s$ is high, larger radii can be certified, but smaller radii are certified at lower accuracy. 

% For the word reordering operation, the smoothing parameter $\lambda$ controls the boundaries of the radius. When approaching the radius boundary, the certified accuracy decreases rapidly. However, within the radius bound, the certified accuracy remains almost constant as the radius gradually increases, especially for the AG dataset and BERT. There are two reasons for this: on the one hand, the Amazon and IMDB datasets are large in length, and LSTM suffers from information forgetting. Therefore the accuracy decreases more. On the other hand, the output of each word of BERT contains the information of other words. Therefore the swap order has little effect on the resultant output of BERT.



\begin{table}[]
\setlength\tabcolsep{1pt}
\centering
\scriptsize
\caption{Certified accuracy of word insertion smoothing method against different attacks. } %“-” denotes the BAE-Insert attack cannot be performed on LSTM.
\vspace{-0.05in}
\resizebox{\linewidth}{!}{
% \begin{tabular}{ccccccc}
% \toprule
% \multicolumn{1}{c}{\begin{tabular}[c]{@{}c@{}} Dataset \\ (Model)\end{tabular}}  & Param. & \multicolumn{1}{c}{\begin{tabular}[c]{@{}c@{}}Text-\\ Fooler\cite{jin2020bert} \end{tabular}} & \multicolumn{1}{c}{\begin{tabular}[c]{@{}c@{}}Word-\\ Reorder \cite{moradi2021evaluating}\end{tabular}} & \multicolumn{1}{c}{\begin{tabular}[c]{@{}c@{}} Synonym-\\ Insert\cite{morris2020textattack}\end{tabular}} & \multicolumn{1}{c}{\begin{tabular}[c]{@{}c@{}}BAE-\\ Insert \cite{garg2020bae}\end{tabular}} & \multicolumn{1}{c}{\begin{tabular}[c]{@{}c@{}}Input-\\ Reduction\cite{feng2018pathologies}\end{tabular}} \\
% \midrule
% \multirow{3}{*}{\begin{tabular}[c]{@{}c@{}}AG\\ (LSTM)\end{tabular}} & Low & 80.8\% & \textbf{85.8\%} & \textbf{84.8\%} & - & 69.4\% \\
%    & Med. & \textbf{83.0\%} & 76.0\% & 84.0\% & - & \textbf{73.6\%} \\
%    & High & 79.6\% & 68.6\% & 80.4\% & - & 68.6\% \\
%  \midrule
% \multirow{3}{*}{\begin{tabular}[c]{@{}c@{}}AG\\ (BERT)\end{tabular}} & Low & 80.4\% & 80.8\% & 75.4\% & 68.6\% & \textbf{60.2\%} \\
%   & Med. & \textbf{83.8\%} & \textbf{90.4\%} & \textbf{84.2\%} & 78.2\% & 59.6\% \\
%    & High & 80.8\% & 88.8\% & 80.6\% & \textbf{79.6\%} & 58.6\% \\
%  \midrule
% \multirow{3}{*}{\begin{tabular}[c]{@{}c@{}}Amazon\\ (LSTM)\end{tabular}} & Low & \textbf{77.4\%} & \textbf{84.2\%} & \textbf{74.2\%} & - & \textbf{72.2\%} \\
%    & Med. & 75.2\% & 77.6\% & 65.8\% & - & 71.4\% \\
%    & High & 71.0\% & 70.6\% & 62.4\% & - & 67.2\% \\
%  \midrule
% \multirow{3}{*}{\begin{tabular}[c]{@{}c@{}}AG\\ (LSTM)\end{tabular}} & Low & \textbf{83.0\%} & 77.2\% & \textbf{80.6\%} & 71.8\% & 74.4\% \\
%    & Med. & 82.0\% & \textbf{87.2\%} & 78.4\% & \textbf{75.4\%} & \textbf{74.8\%} \\
%    & High & 73.4\% & 86.6\% & 72.8\% & 70.2\% & 71.8\% \\
%  \midrule
% \multirow{3}{*}{\begin{tabular}[c]{@{}c@{}}IMDB\\ (LSTM)\end{tabular}} & Low & \textbf{66.6\%} & \textbf{87.2\%} & 69.6\% & - & \textbf{72.4\%} \\
%    & Med. & 65.6\% & 80.8\% & \textbf{68.6\%} & - & 66.2\% \\
%    & High & 63.4\% & 71.0\% & 61.6\% & - & 63.8\% \\
%  \midrule
% \multirow{3}{*}{\begin{tabular}[c]{@{}c@{}}IMDB\\ (BERT)\end{tabular}} & Low & 82.0\% & 78.2\% & 82.6\% & 71.6\% & 78.8\% \\
%    & Med. & \textbf{83.2\%} & \textbf{87.4\%} & \textbf{87.0\%} & \textbf{84.6\%} & \textbf{80.8\%} \\
%    & High & 75.2\% & 84.2\% & 75.0\% & 78.6\% & 72.4\% \\
%  \bottomrule
% \end{tabular}
\begin{tabular}{lccccc}
\toprule
\begin{tabular}[c]{@{}c@{}}Dataset (Model)\end{tabular} & \multicolumn{1}{c} {\begin{tabular}[c]{@{}c@{}}Text-\\ Fooler\cite{jin2020bert} \end{tabular}} & \multicolumn{1}{c}{\begin{tabular}[c]{@{}c@{}}Word-\\ Reorder \cite{moradi2021evaluating}\end{tabular}} & \multicolumn{1}{c}{\begin{tabular}[c]{@{}c@{}} Synonym-\\ Insert\cite{morris2020textattack}\end{tabular}} & \multicolumn{1}{c}{\begin{tabular}[c]{@{}c@{}}BAE-\\ Insert \cite{garg2020bae}\end{tabular}} & \multicolumn{1}{c}{\begin{tabular}[c]{@{}c@{}}Input-\\ Reduction\cite{feng2018pathologies}\end{tabular}} \\
\midrule
AG (LSTM) & 81.6\% & 85.0\% & 84.2\% & - & 70.0\% \\
AG (BERT) & 83.4\% & 90.2\% & 83.6\% & 79.4\% & 58.4\% \\
Amazon (LSTM) & 75.4\% & 83.6\% & 71.8\% & - & 70.4\% \\
Amazon (BERT) & 82.8\% & 84.4\% & 80.6\% & 71.2\% & 74.4\% \\
IMDB (LSTM) & 64.2\% & 87.2\% & 69.6\% & - & 68.8\% \\
IMDB (BERT) & 81.4\% & 87.0\% & 86.2\% & 80.6\% & 77.4\% \\
\midrule
Average & 78.1\% & 86.2\% & 79.3\% & 77.1\% & 69.9\% \\
\bottomrule
\end{tabular}
}
\vspace{-4mm}
\label{tab:universe_certi_acc}
\end{table}


\vspace{-0.1in}
\subsubsection{Certified Accuracy against Unseen Attacks}

We select the noise parameters w.r.t. the highest certified accuracy for the three methods and evaluate the robustness under these noises. Table~\ref{tab:certi_acc_attacks} displays the certified accuracy of three methods against five types of attacks. The `\emph{Vanilla}' column shows that the accuracy is $0\%$ for all successful adversarial examples on the vanilla models. Text-CRS demonstrates an average certified accuracy that is 64\% and 70\% higher than SAFER and CISS, respectively, across all attacks.
Specifically, our method achieves the highest certified accuracy for the TextFooler attack, surpassing SAFER and CISS in all settings. SAFER and CISS only provide certification against substitution attacks, resulting in $0\%$ certified accuracy for WordReorder to InputReduction attacks. Therefore, we evaluate their empirical accuracy against these attacks. It is important to note that empirical accuracy is generally higher than certified accuracy under the same setting. 
On average, our certified accuracy is still $5.5\%$ and $22.8\%$ higher than the empirical accuracy of SAFER and CISS, respectively. 



% \begin{table*}[]
% \setlength\tabcolsep{5pt}
% \scriptsize %footnotesize
% \caption{Comparison of clean vanilla and benign accuracy of four word-level operations on the clean test set. Certified accuracy against five SOTA adversarial attacks, in which attack performance is represented as attack vanilla. “-” denotes the BAE-Insert attack cannot be performed on LSTM.}
% \begin{tabular}{llcl||rrr|rrr|rrrrr|rrr}
% \toprule
% % \multicolumn{1}{c}{} & \multicolumn{1}{c}{} & \multicolumn{2}{c}{\begin{tabular}[c]{@{}c@{}} Operations \end{tabular}} & \multicolumn{3}{c}{\begin{tabular}[c]{@{}c@{}} Synonym Substitution\end{tabular}} & \multicolumn{3}{c}{\begin{tabular}[c]{@{}c@{}}Word Reordering\end{tabular}} & \multicolumn{5}{c}{Word Insertion} & \multicolumn{3}{c}{Word Deletion} \\
% % \midrule
% \multicolumn{1}{c}{} & \multicolumn{1}{c}{} & \multicolumn{2}{c}{Attack Type} & \multicolumn{3}{c}{TextFooler\cite{jin2020bert}} & \multicolumn{3}{c}{WordReorder\cite{moradi2021evaluating}} & \multicolumn{3}{c}{SynonymInsert\cite{morris2020textattack}} & \multicolumn{2}{c}{BAE-Insert\cite{garg2020bae}} & \multicolumn{3}{c}{InputReduction\cite{feng2018pathologies}} \\
% \midrule
% \begin{tabular}[c]{@{}c@{}}Data-\\ set \end{tabular} & \multicolumn{1}{c}{Model} & \begin{tabular}[c]{@{}c@{}}Clean\\  vanilla\end{tabular} & \multicolumn{1}{c}{Param.} & \multicolumn{1}{c}{\begin{tabular}[c]{@{}c@{}}Clean \\ Acc.\end{tabular}} & \multicolumn{1}{c}{\begin{tabular}[c]{@{}c@{}}Cert.\\ Acc.\end{tabular}} & \multicolumn{1}{c}{\begin{tabular}[c]{@{}c@{}}Attack \\ Acc. \end{tabular}} & \multicolumn{1}{c}{\begin{tabular}[c]{@{}c@{}}Clean \\      Acc.\end{tabular}} & \multicolumn{1}{c}{\begin{tabular}[c]{@{}c@{}}Cert.\\ Acc.\end{tabular}} & \multicolumn{1}{c}{\begin{tabular}[c]{@{}c@{}}Attack \\ Acc. \end{tabular}} & \multicolumn{1}{c}{\begin{tabular}[c]{@{}c@{}}Clean \\ Acc.\end{tabular}} & \multicolumn{1}{c}{\begin{tabular}[c]{@{}c@{}}Cert.\\ Acc.\end{tabular}} & \multicolumn{1}{c}{\begin{tabular}[c]{@{}c@{}}Attack \\ Acc. \end{tabular}} & \multicolumn{1}{c}{\begin{tabular}[c]{@{}c@{}}Cert.\\ Acc.\end{tabular}} & \multicolumn{1}{c}{\begin{tabular}[c]{@{}c@{}}Attack \\ Acc. \end{tabular}} & \multicolumn{1}{c}{\begin{tabular}[c]{@{}c@{}}Clean \\ Acc.\end{tabular}} & \multicolumn{1}{c}{\begin{tabular}[c]{@{}c@{}}Cert.\\ Acc.\end{tabular}} & \multicolumn{1}{c}{\begin{tabular}[c]{@{}c@{}}Attack \\ Acc. \end{tabular}} \\
% \midrule

% \multirow{6}{*}{AG} & \multirow{3}{*}{LSTM} & \multirow{3}{*}{91.79} & Low & 90.12 & 91.20 & \multirow{3}{*}{2.46} & 91.67 & 90.12 & \multirow{3}{*}{76.38} & 90.38 & 84.80 & \multirow{3}{*}{70.55} & - & \multirow{3}{*}{-} & 91.53 & 79.40 & \multirow{3}{*}{40.85} \\
%  &  &  & Med. & 89.59 & 90.60 &  & 91.21 & 87.90 &  & 86.66 & 84.00 &  & - &  & 91.01 & 82.20 &  \\
%  &  &  & High & 88.82 & 89.40 &  & 91.40 & 89.52 &  & 84.83 & 80.40 &  & - &  & 90.38 & 81.20 &  \\
% \cmidrule{2-18}
% & \multirow{3}{*}{BERT} & \multirow{3}{*}{93.68} & Low & 93.24 & 95.20 & \multirow{3}{*}{6.67} & 93.62 & 86.20 & \multirow{3}{*}{49.36} & 93.43 & 75.40 & \multirow{3}{*}{75.07} & 68.60 & \multirow{3}{*}{28.53} & 93.70 & 75.40 & \multirow{3}{*}{56.59} \\
%  &  &  & Med. & 92.75 & 93.40 &  & 93.55 & 88.40 &  & 93.05 & 84.20 &  & 78.20 &  & 93.71 & 71.80 &  \\
%  &  &  & High & 92.63 & 92.40 &  & 93.43 & 87.20 &  & 91.78 & 80.60 &  & 79.50 &  & 93.51 & 74.80 &  \\
% \midrule
% \multirow{6}{*}{\begin{tabular}[c]{@{}c@{}}Ama-\\ zon\end{tabular}} & \multirow{3}{*}{LSTM} & \multirow{3}{*}{89.82} & Low & 87.86 & 83.20 & \multirow{3}{*}{0.09} & 88.59 & 87.40 & \multirow{3}{*}{54.16} & 88.51 & 74.20 & \multirow{3}{*}{61.25} & - & \multirow{3}{*}{-} & 88.71 & 75.60 & \multirow{3}{*}{30.85} \\
%  &  &  & Med. & 87.29 & 82.40 &  & 88.44 & 86.20 &  & 83.61 & 65.80 &  & - &  & 88.62 & 76.40 &  \\
%  &  &  & High & 86.23 & 83.20 &  & 88.36 & 90.80 &  & 79.53 & 62.40 &  & - &  & 88.10 & 79.60 &  \\
% \cmidrule{2-18}
%  & \multirow{3}{*}{BERT} & \multirow{3}{*}{94.35} & Low & 93.91 & 93.00 & \multirow{3}{*}{15.38} & 94.11 & 84.20 & \multirow{3}{*}{5.29} & 94.64 & 80.60 & \multirow{3}{*}{66.39} & 71.80 & \multirow{3}{*}{9.30} & 94.73 & 80.60 & \multirow{3}{*}{41.68} \\
%  &  &  & Med. & 93.07 & 90.60 &  & 94.27 & 82.60 &  & 94.43 & 78.40 &  & 75.40 &  & 94.49 & 81.40 &  \\
%  &  &  & High & 91.62 & 87.60 &  & 94.30 & 84.60 &  & 92.89 & 72.80 &  & 70.20 &  & 93.84 & 80.40 &  \\
% \midrule
% \multirow{6}{*}{IMDB} & \multirow{3}{*}{LSTM} & \multirow{3}{*}{86.17} & Low & 83.39 & 83.40 & \multirow{3}{*}{0.00} & 86.85 & 85.60 & \multirow{3}{*}{40.20} & 84.86 & 69.60 & \multirow{3}{*}{58.12} & - & \multirow{3}{*}{-} & 86.33 & 72.00 & \multirow{3}{*}{30.65} \\
%  &  &  & Med. & 82.58 & 86.60 &  & 86.08 & 86.20 &  & 80.45 & 68.60 &  & - &  & 86.32 & 75.20 &  \\
%  &  &  & High & 81.07 & 80.80 &  & 86.11 & 87.20 &  & 77.96 & 61.60 &  & - &  & 84.76 & 72.80 &  \\
%  \cmidrule{2-18}
%  & \multirow{3}{*}{BERT} & \multirow{3}{*}{91.52} & Low & 91.52 & 87.00 & \multirow{3}{*}{21.81} & 92.08 & 82.20 & \multirow{3}{*}{7.54} & 91.88 & 83.60 & \multirow{3}{*}{57.03} & 71.50 & \multirow{3}{*}{18.66} & 92.46 & 82.47 & \multirow{3}{*}{36.03} \\
%  &  &  & Med. & 90.42 & 84.20 &  & 91.92 & 78.60 &  & 91.68 & 87.00 &  & 84.50 &  & 92.17 & 83.30 &  \\
%  &  &  & High & 88.68 & 76.60 &  & 91.99 & 80.60 &  & 87.49 & 75.20 &  & 78.50 &  & 90.55 & 81.44 & \\ 
% \bottomrule
% \label{tab:certi_acc}
% \end{tabular}
% \end{table*}


% \subsubsection{Comparison with SOTA Certified Defense}

% % Figure environment removed

% \subsubsection{Comparison with State-of-the-art Empirical Adversarial Training}
% Certified accuracy 
% Benign accuracy




\vspace{-0.1in}
\subsubsection{Word Insertion Smoothing vs. All Attacks (Universality)}
We evaluate the certified accuracy of the word insertion smoothing against all aforementioned attacks (universality), as shown in Table~\ref{tab:universe_certi_acc}. On average, our word insertion smoothing achieves a certified accuracy of $78.1\%$. It can certify against all attacks, though with a slight performance drop compare to the operation-specific methods in our Text-CRS. However, its certified accuracy is still higher than the empirical accuracy of SAFER and CISS, except the SAFER against TextFooler (substitution operation-specific). %However, the word insertion method shows a slight degradation of 5.9\% on average compared to our operation-specific methods. 
Therefore, the word insertion smoothing in Text-CRS is suitable for providing high certified accuracy when the attack type is unknown (due to its high universality), while higher certified accuracy can be achieved using specific methods in Text-CRS to defend known attacks. 
% 
% Comparing the average accuracy of SAFER and CISS in Table~\ref{tab:certi_acc_attacks}, our method not only achieves an accuracy higher than the empirical accuracy of the comparison methods but also provides certified robustness. On the other hand, the word insertion method is less accurate than the method we designed for specific operations, but the accuracy is reduced to within 5\%. Thus when faced with an attack on an unknown operation, our word insertion smoothing method can provide an acceptable certified accuracy of 79.7\%.


% % Figure environment removed


% Figure environment removed


% We investigate the impact of the number of samples ($N$) on the certified accuracy against adversarial attacks when the noise level is high. 

% Figure~\ref{fig:impact_N} (top and bottom) illustrates the changes in certified accuracy of Text-CRS against the SynonymInsert attack for different datasets and models, as well as Text-CRS against different attacks. The results show that as $N$ increases, certified accuracy also increases, as the estimate for $\underline{p_A}$ approaches the actual lower bound. The impact of $N$ on the certified accuracy of the LSTM is greater than that of the BERT, as the high accuracy of BERT leads to a more precise estimation of $\underline{p_A}$ even with smaller values of $N$. Additionally, we observe that $N$ has little impact on the certified accuracy of the WordReorder attack due to the limited noise space of word reordering compared to the other three attacks. As a result, $N=10000$ is sufficient to evaluate accurate $\underline{p_A}$.

\vspace{-0.1in}
\subsubsection{Impact of the Number of Samples ($N$)} 
Figure~\ref{fig:impact_N_1} show that as the number of samples for estimation ($N$) increases, the certified accuracy also increases and the certified radius becomes larger, since the estimation for $\underline{p_A}$ and $\overline{p_B}$ becomes tighter. The impact of $N$ on the certified accuracy of the IMDB dataset is greater than that of the AG dataset, since longer inputs have a larger noise space, necessitating more samples to approximate $\underline{p_A}$ and $\overline{p_B}$. 


% the high accuracy of BERT leads to a more precise estimation of $\underline{p_A}$ even with smaller values of $N$. 





% \subsubsection{Runtime Analysis}






% We answer the ChatGPT using the following questions:
% \begin{center}
% \fcolorbox{darkblue}{lightblue!30}{\parbox{.95\linewidth}{\textbf{\textcolor{darkblue}{Questions:}}. 
%     \item (1) Please answer if the following two sentences have similar semantical information despite the grammatical errors. Please first choose Yes or No. 
%     \item (2) Then summarize the differences between the meaning of the two sentences by points. 
%     \item (3) Finally, please calculate the cosine similarity between these two sentences.}}
% \end{center}


% \begin{table*}[]
% \caption{Query-answer examples from ChatGPT}
%     \centering
%     \begin{tabular}{c|ccc}
%     \toprule
%     Sentences (Red indicates substitution or insertion of words) & Semantically similar & Differences summarized by ChatGPT & Cosine Similarity \\
%     \midrule
%     Sentences & Yes & Differences summarized by ChatGPT & 0.91 \\
%     Sentences  & No & Differences summarized by ChatGPT & 0.891 \\
%     \bottomrule
%     \end{tabular}
%     \label{tab:chatgpt_q_a}
% \end{table*}

