\section{Understanding the visual language of fabrics}
\label{sec:dataset-analysis}

 % Figure environment removed


We conduct a comprehensive analysis of our dataset to understand how people describe fabrics, and explore relevant questions about its characteristics. From these questions, around which this section is structured, we gather insights which help the design of tools to describe, retrieve, classify, label or edit fabrics, among others. 


  % Figure environment removed


\subsection{Is there a common lexicon when describing fabrics?}
\label{subsec:data-analysis-vocabulary}
The existence of a common vocabulary when describing fabrics is a necessary condition for any text-to-fabric application to be practical and successful. Ideally, we would like to identify a reduced set of lemmas or root words (see Section~\ref{subsubsec:postpro}) which would be sufficient for the majority of fabric descriptions.


We begin by computing the \emph{absolute frequency per lemma} $\absfreq(\word)$ in the full corpus of descriptions, where, for each lemma $\word$, the count includes occurrences of all the single words or types belonging to it. 
Prominence of lemmas, however, is not only determined by their absolute frequency, but also by their distribution; for instance, if a describer uses words belonging to a lemma often, but other describers do not, the lemma may not be prominent. We therefore complement absolute frequency with a measure of dispersion, indicating how evenly the occurrences of the lemma are distributed within the corpus. We measure this with the \textit{average reduced frequency} ($\arf(\word)$)~\cite{Savicky2002,Brezina2018}, which modulates $\absfreq(\word)$ with the dispersion of $\word$ (\fillin{details on the computation can be found in the supplemental material}). The histogram of $\arf(\word)$ (Figure~\ref{fig:dataset:frequency} (left)) 
shows how over one third of the lemmas have an $\arf$ value below $2$, meaning that they are seldom used, or used by a single describer. This confirms the intuition that a reduced subset of lemmas should suffice for fabric description. 

 
We next examine how small this reduced lexicon can be. 
We first use $\arf(\word)$ as ranking criterion to find the subset $\mathcal{W}_k$ of the most prominent $k$ lemmas, for increasing values of $k \in [1..N_\word]$, with $N_\word=\nblemmaspostpro$ the number of lemmas in our corpus. 
%
For each $\mathcal{W}_k$, we then compute the \textit{coverage} of a description $d$ as
%
\begin{equation}
\nonumber
\coverage_k(d) = \frac{n_k(d)}{n_{tot}(d)},
\end{equation}
% 
where $n_k$ is the number of lemmas from subset $\mathcal{W}_k$ present in description $d$, and $n_{tot}(d)$ is the total number of lemmas of such description. 
As the plot in Figure~\ref{fig:dataset:frequency} (right) shows, a common lexicon of 84 lemmas is enough to cover 75\% of the fabric descriptions, while to cover 95\% we only need 524 lemmas, which we define as our fabric-specific lexicon \new{(examples of these lemmas can be found in the supplemental material).}



\subsection{Are there key attributes in the descriptions?}
\label{subsec:data-analysis-attributes}


Finding common attributes is useful to understand how we internally represent and think about fabrics. From our reduced 524-lemma lexicon, we seek now to identify common attributes that these lemmas may relate to. We approach this as a clustering problem, and develop a methodology based on affinity propagation and similarity between lemmas. In particular, we leverage embeddings of the lemmas 
provided by \textit{ConceptNet Numberbatch}~\cite{speer2017conceptnet}, which combines both distributional semantics and relational knowledge\footnote{~We use the implementation from \url{https://github.com/commonsense/conceptnet-numberbatch}. We refer the reader to the original ConceptNet paper~\cite{liu2004conceptnet}, as well the ConceptNet Numberbatch extension~\cite{speer2017conceptnet} for more details.}.
%
This leads to the identification of the main attributes that people focus on when describing fabrics, as well as a distribution of our lexicon into those attributes (\fillin{we provide a description of this process in the supplemental material}). 
This results in eleven key attributes describing fabrics: \emph{color}, \emph{lightness}, \emph{metallic}, \emph{pattern}, \emph{fabric\_type}, \emph{sewing}, \emph{touch}, \emph{weight}, \emph{use}, \emph{weathering}, and \emph{military}\footnote{~This last attribute reflects the significant amount of samples of a military nature in our dataset and may not generalize to others, see also Section~\ref{sec:discussion}.}, 
%
and are shown in Figure~\ref{fig:dataset:attributes} (left) using t-SNE dimensionality reduction~\cite{tsne}. 



In Figure~\ref{fig:dataset:attributes} (center), we show the probability of occurrence $p(a_i), i \in [1..\nattr]$ of each attribute $a_i$, where $\nattr=11$ is the number of attributes. It expresses the probability that 
there is at least one occurrence of a lemma belonging to the attribute  
%
in any given description. This illustrates the relative importance of each attribute: for instance, it reveals that \emph{color}, \emph{pattern}, \emph{touch} and \emph{fabric\_type} are present in more than 70\% of the descriptions.
%

Moreover, we look into whether certain attributes tend to appear together in the descriptions; to that end we compute 
$p(a_i|a_j)$, $i,j \in [1..\nattr], i \neq j $, i.e., the probability of attribute $a_i$ being present in a description that contains attribute $a_j$. 
%
Figure~\ref{fig:dataset:attributes} (right) plots these probabilities for all attributes (note that the resulting matrix is non-symmetric, since $p(a_i|a_j) \neq p(a_j|a_i)$). We observe that, in general, the presence of a given attribute in a description is not heavily dependent on the presence of any other attribute. This is indicated by the relatively uniform values along each column,  
%
and is a result of the large variety of appearances present in our dataset, exhibiting many different combinations of attributes.



\subsection{Do descriptions follow a common structure?}
\label{subsec:data-analysis-structure}

We next look at the structure of descriptions by analyzing the order of appearance of the different attributes. 
Specifically, we compute a \emph{rank product} for each attribute as 
%
\begin{equation}
\nonumber
\Psi(a) = (\prod_{i=1}^{\ndescr}r_{a,i})^{1/\ndescr},
\end{equation}
%
where $r_{a,i}$ is the \emph{rank} of attribute $a$ in description $d_i, i \in [1..\ndescr]$~\cite{Rubinstein_SA2010}. The rank is given by the first appearance of a lemma belonging to an attribute in a description; thus, lower rank products indicate that the attribute tends to appear earlier in the descriptions. 

Table~\ref{tab:dataset:rank-product} shows the resulting ranking of attributes. To evaluate whether the differences in ordering are significant, we perform a Kruskal-Wallis test (a non-parametric extension of ANOVA, since rankings are an ordinal value and typically cannot be assumed to follow a normal distribution), which shows that there is a significant difference between attributes ($H(10)=8235.53$, $p<.0001$). 
%
A subsequent pairwise comparisons test allows us to identify groups of attributes where  there is no significant difference between their mean ranks (also shown in Table~\ref{tab:dataset:rank-product}).
%
\fillin{The rank histograms per attribute can be found in the supplemental material}. 


\begin{table*}
\caption{Attributes sorted by rank product, indicative of their order of appearance within a description. Lower rank products indicate that the attribute tends to appear earlier in the descriptions. Attributes grouped together in the table yield no significant difference between their mean ranks.} 
\begin{tabular}{|l|c|c|ccc|cc|c|c|c|c|}
\hline
Attribute $a$  & color & lightness & sewing & metallic & pattern & weight & military & fabric\_type & weathering & touch & use \\ 
Rank product $\Psi(a)$ & 2.25  & 2.39      & 2.75   & 2.77     & 2.86    & 2.95   & 3.06     & 3.17         & 3.46   & 3.73  & 4.25   \\ \hline
\end{tabular}
 \label{tab:dataset:rank-product}
\end{table*}



\subsection{Does the same fabric elicit similar descriptions?}
\label{subsec:dataset-analysis-similarity}


We measure similarity between descriptions using two state-of-the-art NLP models that have been shown to work well on Semantic Textual Similarity (STS): sentence-T5~\cite{ni2021sentenceT5}, designed to provide sentence embeddings from text-to-text  transformers,
%
and MPNet~\cite{song2020mpnet}, shown to work well for semantic search using sentence embeddings~\cite{reimers2019sbert}. Specifically, we compute cosine similarity between the embeddings of our full descriptions, as in the original publications.
%

To compute the \emph{intra-image} description similarity (similarity between descriptions of the same fabric), we average over all pairwise comparisons  
%
in our whole corpus, provided that the two members of a pair belong to the same image. To compute the
\emph{inter-image} description similarity (similarity between descriptions of different fabrics), we average over all pairwise comparisons in our whole corpus, provided that the two members of a pair belong to different images. 

The results, shown in Table~\ref{tab:dataset:intra-inter}, yield a high intra-image similarity (cosine similarities are bounded between -1 and 1), suggesting that the same fabric does indeed elicit similar descriptions by different people. Compared to the inter-image similarity (which one may treat as a baseline), the average intra-image similarity is larger for both models. 
%
To test whether these differences are  statistically significant, we resort to ANOSIM (analysis of similarities)~\cite{clarke1993anosim, warton2012anosim}. ANOSIM works on all pairwise similarities (or distances) between points (descriptions), and is designed to test the null hypothesis that the similarity between groups (inter-image) is greater than or equal to the similarity within groups (intra-image). We use a p-value of $0.05$ to indicate significance
%
\new{and the test statistic as the measure of effect size~\cite{somerfield2021analysis}. This value is constrained to $[-1,1]$, with $1$ indicating very high intra-image similarity with respect to inter-image similarity, and negative values indicating higher inter-image similarity. Results of this analysis show reasonably high intra-image similarity with respect to inter-image similarity, 
%
confirming that the difference is statistically significant (see Table~\ref{tab:dataset:intra-inter}).} 

\begin{table}
\caption{Similarity between descriptions of the same image (intra-image) and descriptions of different images (inter-image). We report, for two state-of-the-art sentence embeddings (sentence-T5 and MPNet): average intra-image and inter-image similarities (and associated standard deviations), test statistics for ANOSIM, and associated p-value (we use a p-value of 0.05 to indicate significance). The descriptions in our dataset exhibit high intra-image similarity, and the statistical test shows that intra-image similarities are significantly larger than the inter-image ones.
 }
\small
\begin{tabular}{rcccc}
\cline{2-3}
\multicolumn{1}{l|}{}             & \multicolumn{2}{c|}{Similarity}                                              & \multicolumn{1}{l}{}                & \multicolumn{1}{l}{} \\ \cline{2-5} 
\multicolumn{1}{c|}{}             & \multicolumn{1}{c|}{Intra-image}     & \multicolumn{1}{c|}{Inter-image}     & \multicolumn{1}{c|}{Test Statistic} & \multicolumn{1}{c|}{p-value}              \\ \hline
\multicolumn{1}{|r|}{sentence-T5} & \multicolumn{1}{c|}{0.874 (0.037)} & \multicolumn{1}{c|}{0.822 (0.037)} & \multicolumn{1}{c|}{0.694}         & \multicolumn{1}{c|}{0.001}                 \\ %\hline
\multicolumn{1}{|r|}{MPNet}    & \multicolumn{1}{c|}{0.704 (0.087)} & \multicolumn{1}{c|}{0.627 (0.083)} & \multicolumn{1}{c|}{0.497}         & \multicolumn{1}{c|}{0.001}               \\ \hline
\end{tabular}
\label{tab:dataset:intra-inter}
\end{table}
