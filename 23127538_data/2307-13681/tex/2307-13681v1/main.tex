%\documentclass[acmtog,anonymous,review]{acmart}
\documentclass[acmtog]{acmart}
\acmSubmissionID{461}

\usepackage{booktabs} % For formal tables
\usepackage{diagbox}
\usepackage{subfig}
\usepackage{multirow}
\usepackage{mathrsfs}
\usepackage{graphicx}
\usepackage{enumitem}
\usepackage{soul}
\usepackage{url}
\usepackage[normalem]{ulem}
\usepackage[skip=3pt]{caption}
\setlength{\belowcaptionskip}{0pt}
% TOG prefers author-name bib system with square brackets
\citestyle{acmauthoryear}
\setcitestyle{square} % was nosort, square ;nosort to allow for manual chronological ordering

\usepackage[ruled]{algorithm2e} % For algorithms
\renewcommand{\algorithmcfname}{ALGORITHM}
\SetAlFnt{\small}
\SetAlCapFnt{\small}
\SetAlCapNameFnt{\small}
\SetAlCapHSkip{0pt}

\newcommand{\new}[1]{\textcolor{black}{#1}} %\textcolor{red}{#1}}
\newcommand{\fillin}[1]{\textcolor{black}{#1}}


\setcopyright{rightsretained}
\acmDOI{XXXX} \acmVolume{XX} \acmNumber{XX}

% DOI
\begin{document}

% author list
\author{Valentin Deschaintre*}
\affiliation{%
	\institution{Adobe Research}
	\country{UK}
}
\email{deschain@adobe.com}

\author{Julia Guerrero-Viu*}
\affiliation{%
	\institution{Universidad de Zaragoza - I3A}
	\country{Spain}
}
\email{juliagviu@unizar.es}

\author{Diego Gutierrez}
\affiliation{%
	\institution{Universidad de Zaragoza - I3A}
	\country{Spain}
}
\email{diegog@unizar.es}

\author{Tamy Boubekeur}
\affiliation{%
	\institution{Adobe Research}
	\country{France}
}
\email{boubek@adobe.com}

\author{Belen Masia}
\affiliation{%
	\institution{Universidad de Zaragoza - I3A}
	\country{Spain}
}
\email{bmasia@unizar.es}

% For Equal contribution footnote without numbering
\newcommand\blfootnote[1]{%
  \begingroup
  \renewcommand\thefootnote{}\footnote{#1}%
  \addtocounter{footnote}{-1}%
  \endgroup
}


\title{The Visual Language of Fabrics}


\begin{abstract}
\blfootnote{* Joint first authors}
We introduce text2fabric, a novel dataset that links free-text descriptions to various fabric materials. 
The dataset comprises 15,000 natural language descriptions associated to 3,000 corresponding images of fabric materials. 
Traditionally, material descriptions come in the form of tags/keywords, which limits their expressivity, induces pre-existing knowledge of the appropriate vocabulary, and ultimately leads to a chopped description system. 
Therefore, we study the use of free-text as a more appropriate way to describe material appearance, taking the use case of fabrics as a common item that non-experts may often deal with. 
Based on the analysis of the dataset, we identify a compact lexicon, set of attributes and key structure that emerge from the descriptions. 
This allows us to accurately understand how people describe fabrics and draw directions for generalization to other types of materials. 
We also show that our dataset enables specializing large vision-language models such as CLIP, creating a meaningful latent space for fabric appearance, and significantly improving applications such as fine-grained material retrieval and automatic captioning.
 \end{abstract}

\ccsdesc[500]{Computing methodologies~Appearance and texture representations}

\keywords{material appearance, perception, descriptions}

 \begin{teaserfigure}
 % Figure removed
\caption{
Our text2fabric dataset links high-quality renderings of a large variety of fabric materials 
%
to natural language descriptions of their appearance. 
% 
We conduct a thorough analysis of this dataset, and leverage it to fine-tune large-scale vision-language models for a variety of tasks.
%
We show here examples of such tasks: (i) image-based search, even using real photographs as input, yields relevant results from our dataset (the magenta square in the photographs marks the input crop, and the corresponding search results can be found in each row); (ii) text-based queries (green) result in successful fine-grained retrieval within the dataset; and, (iii) given an input image, we can generate detailed and rich descriptions of appearance (blue).
Our work not only derives interesting insights regarding how people describe (fabric) appearance, but also demonstrates that a relatively small amount of high-quality data enables successful application of large vision-language models to specialized domains.}
 \label{fig:teaser}
 \end{teaserfigure}
\maketitle

\input{00-notation-and-constants}
\input{01-introduction}
\input{02-relatedwork}
\input{03-dataset_creation}
\input{04-dataset_analysis}
\input{05-applications}
\input{06-discussion}
\input{acks}

\bibliographystyle{ACM-Reference-Format}
\bibliography{bibliography}
\end{document}
