\begin{thebibliography}{10}

\bibitem{karniadakis2021physics}
G.~E. Karniadakis, I.~G. Kevrekidis, L.~Lu, P.~Perdikaris, S.~F. Wang, and
  L.~Yang.
\newblock Physics-informed machine learning.
\newblock {\em Nature Reviews Physics}, 3(6):422--440, 2021.

\bibitem{lu2021learning}
L.~Lu, P.~Z. Jin, G.~F. Pang, Z.~Q. Zhang, and G.~E. Karniadakis.
\newblock {Learning nonlinear operators via DeepONet based on the universal
  approximation theorem of operators}.
\newblock {\em Nature machine intelligence}, 3(3):218--229, 2021.

\bibitem{geneva2022transformers}
N.~Geneva and N.~Zabaras.
\newblock Transformers for modeling physical systems.
\newblock {\em Neural Networks}, 146:272--289, 2022.

\bibitem{parussini2017multi}
L.~Parussini, D.~Venturi, P.~Perdikaris, and G.~E. Karniadakis.
\newblock {Multi-fidelity Gaussian process regression for prediction of random
  fields}.
\newblock {\em Journal of Computational Physics}, 336:36--50, 2017.

\bibitem{yang2021b}
L.~Yang, X.~H. Meng, and G.~E. Karniadakis.
\newblock {B-PINNs: Bayesian physics-informed neural networks for forward and
  inverse PDE problems with noisy data}.
\newblock {\em Journal of Computational Physics}, 425:109913, 2021.

\bibitem{yang2020physics}
L.~Yang, D.~K. Zhang, and G.~E. Karniadakis.
\newblock {Physics-informed generative adversarial networks for stochastic
  differential equations}.
\newblock {\em SIAM Journal on Scientific Computing}, 42(1):A292--A317, 2020.

\bibitem{wang2023generative}
T.~Wang, P.~Plechac, and J.~Knap.
\newblock Generative diffusion learning for parametric partial differential
  equations.
\newblock {\em arXiv preprint arXiv:2305.14703}, 2023.

\bibitem{marzouk2016sampling}
Y.~Marzouk, T.~Moselhy, M.~Parno, and A.~Spantini.
\newblock Sampling via measure transport: An introduction.
\newblock {\em Handbook of uncertainty quantification}, 1:2, 2016.

\bibitem{kobyzev2020normalizing}
I.~Kobyzev, S.~J.~D. Prince, and M.~A. Brubaker.
\newblock Normalizing flows: An introduction and review of current methods.
\newblock {\em IEEE transactions on pattern analysis and machine intelligence},
  43(11):3964--3979, 2020.

\bibitem{papamakarios2021normalizing}
G.~Papamakarios, E.~Nalisnick, D.~J. Rezende, S.~Mohamed, and
  B.~Lakshminarayanan.
\newblock Normalizing flows for probabilistic modeling and inference.
\newblock {\em The Journal of Machine Learning Research}, 22(1):2617--2680,
  2021.

\bibitem{zhong2023pi}
W.~H. Zhong and H.~Meidani.
\newblock {PI-VAE}: Physics-informed variational auto-encoder for stochastic
  differential equations.
\newblock {\em Computer Methods in Applied Mechanics and Engineering},
  403:115664, 2023.

\bibitem{kaipio2006statistical}
J.~Kaipio and E.~Somersalo.
\newblock {\em Statistical and computational inverse problems}, volume 160.
\newblock Springer Science \& Business Media, 2006.

\bibitem{benning_burger_2018}
M.~Benning and M.~Burger.
\newblock Modern regularization methods for inverse problems.
\newblock {\em Acta Numerica}, 27:1–111, 2018.

\bibitem{stuart_2010}
A.~M. Stuart.
\newblock {Inverse problems: A Bayesian perspective}.
\newblock {\em Acta Numerica}, 19:451–559, 2010.

\bibitem{arridge_maass_oktem_schonlieb_2019}
S.~Arridge, P.~Maass, O.~Öktem, and C.~B. Schönlieb.
\newblock Solving inverse problems using data-driven models.
\newblock {\em Acta Numerica}, 28:1–174, 2019.

\bibitem{ghattas_willcox_2021}
O.~Ghattas and K.~Willcox.
\newblock Learning physics-based models from data: perspectives from inverse
  problems and model reduction.
\newblock {\em Acta Numerica}, 30:445–554, 2021.

\bibitem{kirsch2011introduction}
A.~Kirsch et~al.
\newblock {\em An introduction to the mathematical theory of inverse problems},
  volume 120.
\newblock Springer, 2011.

\bibitem{cotter2010approximation}
S.~L. Cotter, M.~Dashti, and A.~M. Stuart.
\newblock {Approximation of Bayesian inverse problems for PDEs}.
\newblock {\em SIAM journal on numerical analysis}, 48(1):322--345, 2010.

\bibitem{Knapik_2011}
B.~T. Knapik, A.~W. van~der Vaart, and J.~H. van Zanten.
\newblock {Bayesian inverse problems with Gaussian priors}.
\newblock {\em The Annals of Statistics}, 39(5), oct 2011.

\bibitem{li2020nett}
H.~S. Li, J.~Schwab, S.~Antholzer, and M.~Haltmeier.
\newblock {NETT: Solving inverse problems with deep neural networks}.
\newblock {\em Inverse Problems}, 36(6):065005, 2020.

\bibitem{WANG2022111454}
Y.~Wang, F.~Liu, and D.E. Schiavazzi.
\newblock Variational inference with {NoFAS}: {N}ormalizing flow with adaptive
  surrogate for computationally expensive models.
\newblock {\em Journal of Computational Physics}, 467:111454, 2022.

\bibitem{cao2023residual}
L.~H. Cao, T.~O'Leary-Roseberry, P.~K. Jha, J.~T. Oden, and O.~Ghattas.
\newblock Residual-based error correction for neural operator accelerated
  infinite-dimensional bayesian inverse problems.
\newblock {\em Journal of Computational Physics}, 486:112104, 2023.

\bibitem{cobian2023adaann}
E.~R. Cobian, J.~D. Hauenstein, F.~Liu, and D.~E. Schiavazzi.
\newblock Adaann: Adaptive annealing scheduler for probability density
  approximation.
\newblock {\em International Journal for Uncertainty Quantification}, 13, 2023.

\bibitem{goh2019solving}
H.~Goh, S.~Sheriffdeen, J.~Wittmer, and T.~Bui-Thanh.
\newblock Solving {B}ayesian inverse problems via variational autoencoders.
\newblock {\em arXiv preprint arXiv:1912.04212}, 2019.

\bibitem{vadeboncoeur2022deep}
A.~Vadeboncoeur, {\"O}.~D. Akyildiz, I.~Kazlauskaite, M.~Girolami, and
  F.~Cirak.
\newblock Deep probabilistic models for forward and inverse problems in
  parametric {PDE}s.
\newblock {\em arXiv preprint arXiv:2208.04856}, 2022.

\bibitem{tait2020variational}
D.~J. Tait and T.~Damoulas.
\newblock {Variational autoencoding of PDE inverse problems}.
\newblock {\em arXiv preprint arXiv:2006.15641}, 2020.

\bibitem{almaeen2021variational}
M.~Almaeen, Y.~Alanazi, N.~Sato, W~Melnitchouk, M.~P. Kuchera, and Y.~H. Li.
\newblock {Variational Autoencoder Inverse Mapper: An End-to-End Deep Learning
  Framework for Inverse Problems}.
\newblock In {\em 2021 International Joint Conference on Neural Networks
  (IJCNN)}, pages 1--8. IEEE, 2021.

\bibitem{10069126}
M.~Almaeen, Y.~Alanazi, N.~Sato, W.~Melnitchouk, and Y.~H. Li.
\newblock {Point Cloud-based Variational Autoencoder Inverse Mappers (PC-VAIM)
  - An Application on Quantum Chromodynamics Global Analysis}.
\newblock In {\em 2022 21st IEEE International Conference on Machine Learning
  and Applications (ICMLA)}, pages 1151--1158, 2022.

\bibitem{cranmer2020frontier}
K.~Cranmer, J.~Brehmer, and G.~Louppe.
\newblock The frontier of simulation-based inference.
\newblock {\em Proceedings of the National Academy of Sciences},
  117(48):30055--30062, 2020.

\bibitem{qin2019data}
T.~Qin, K.~L. Wu, and D.~B. Xiu.
\newblock Data driven governing equations approximation using deep neural
  networks.
\newblock {\em Journal of Computational Physics}, 395:620--635, 2019.

\bibitem{fu2022modeling}
X.~H. Fu, W.~Z. Mao, L.~B. Chang, and D.~B. Xiu.
\newblock Modeling unknown dynamical systems with hidden parameters.
\newblock {\em Journal of Machine Learning for Modeling and Computing}, 3(3),
  2022.

\bibitem{tong2023data}
G.~G. Tong and D.~E. Schiavazzi.
\newblock {Data-driven synchronization-avoiding algorithms in the explicit
  distributed structural analysis of soft tissue}.
\newblock {\em Computational Mechanics}, 71(3):453--479, 2023.

\bibitem{stevens2020finitenet}
B.~Stevens and T.~Colonius.
\newblock {FiniteNet: A Fully Convolutional LSTM Network Architecture for
  Time-Dependent Partial Differential Equations}, 2020.

\bibitem{sanchez2020learning}
A.~Sanchez-Gonzalez, J.~Godwin, T.~Pfaff, R.~Ying, J.~Leskovec, and
  P.~Battaglia.
\newblock Learning to simulate complex physics with graph networks.
\newblock In {\em International conference on machine learning}, pages
  8459--8468. PMLR, 2020.

\bibitem{hamilton2020graph}
W.~L. Hamilton.
\newblock Graph representation learning.
\newblock {\em Synthesis Lectures on Artifical Intelligence and Machine
  Learning}, 14(3):1--159, 2020.

\bibitem{dinh2016density}
L.~Dinh, J.~Sohl-Dickstein, and S.~Bengio.
\newblock Density estimation using real {NVP}.
\newblock {\em arXiv preprint arXiv:1605.08803}, 2016.

\bibitem{rezende2015variational}
D.~Rezende and S.~Mohamed.
\newblock Variational inference with normalizing flows.
\newblock In {\em International conference on machine learning}, pages
  1530--1538. PMLR, 2015.

\bibitem{smith2013uncertainty}
R.~C. Smith.
\newblock {\em Uncertainty quantification: theory, implementation, and
  applications}, volume~12.
\newblock Siam, 2013.

\bibitem{ardizzone2018analyzing}
L.~Ardizzone, J.~Kruse, S.~Wirkert, D.~Rahner, E.W. Pellegrini, R.S. Klessen,
  L.~Maier-Hein, C.~Rother, and U.~K{\"o}the.
\newblock Analyzing inverse problems with invertible neural networks.
\newblock {\em arXiv preprint arXiv:1808.04730}, 2018.

\bibitem{whitney1936differentiable}
H.~Whitney.
\newblock Differentiable manifolds.
\newblock {\em Annals of Mathematics}, pages 645--680, 1936.

\bibitem{kingma2013auto}
D.P. Kingma and M.~Welling.
\newblock Auto-encoding variational {B}ayes.
\newblock {\em arXiv preprint arXiv:1312.6114}, 2013.

\bibitem{kingma2019introduction}
D.P. Kingma, M.~Welling, et~al.
\newblock An introduction to variational autoencoders.
\newblock {\em Foundations and Trends{\textregistered} in Machine Learning},
  12(4):307--392, 2019.

\bibitem{goodfellow2016deep}
I.~Goodfellow, Y.~Bengio, and A.~Courville.
\newblock {\em Deep learning}.
\newblock MIT press, 2016.

\bibitem{doersch2016tutorial}
C.~Doersch.
\newblock Tutorial on variational autoencoders.
\newblock {\em arXiv preprint arXiv:1606.05908}, 2016.

\bibitem{zhao2018infovae}
S.~J. Zhao, J.~M. Song, and S.~Ermon.
\newblock {InfoVAE: Information Maximizing Variational Autoencoders}, 2018.

\bibitem{chen2017variational}
X.~Chen, D.~P. Kingma, T.~Salimans, Y.~Duan, P.~Dhariwal, J.~Schulman,
  I.~Sutskever, and P.~Abbeel.
\newblock {Variational Lossy Autoencoder}, 2017.

\bibitem{havrylov2020preventing}
S.~Havrylov and I.~Titov.
\newblock {Preventing Posterior Collapse with Levenshtein Variational
  Autoencoder}, 2020.

\bibitem{fu2019cyclical}
H.~Fu, C.~Y. Li, X.~D. Liu, J.F. Gao, A.~Celikyilmaz, and L.~Carin.
\newblock {Cyclical Annealing Schedule: A Simple Approach to Mitigating KL
  Vanishing}, 2019.

\bibitem{lucas2019don}
J.~Lucas, G.~Tucker, R.~B. Grosse, and M.~Norouzi.
\newblock {Don't blame the ELBO! a linear vae perspective on posterior
  collapse}.
\newblock {\em Advances in Neural Information Processing Systems}, 32, 2019.

\bibitem{razavi2019preventing}
A.~Razavi, A.~van~den Oord, B.~Poole, and O.~Vinyals.
\newblock {Preventing Posterior Collapse with delta-VAEs}, 2019.

\bibitem{wang2021posterior}
Y.~X. Wang, D.~Blei, and J.~P. Cunningham.
\newblock Posterior collapse and latent variable non-identifiability.
\newblock {\em Advances in Neural Information Processing Systems},
  34:5443--5455, 2021.

\bibitem{liberzon2011calculus}
D.~Liberzon.
\newblock {\em Calculus of variations and optimal control theory: a concise
  introduction}.
\newblock Princeton university press, 2011.

\bibitem{brehmer2020flows}
J.~Brehmer and K.~Cranmer.
\newblock Flows for simultaneous manifold learning and density estimation,
  2020.

\bibitem{morrow2020variational}
R.~Morrow and W.~C. Chiu.
\newblock {Variational Autoencoders with Normalizing Flow Decoders}, 2020.

\bibitem{shi2011review}
Y.B. Shi, P.~Lawford, and R.~Hose.
\newblock {Review of zero-D and 1-D models of blood flow in the cardiovascular
  system}.
\newblock {\em Biomedical engineering online}, 10:1--38, 2011.

\bibitem{harrod2021predictive}
K.K. Harrod, J.L. Rogers, J.A. Feinstein, A.L. Marsden, and D.E. Schiavazzi.
\newblock Predictive modeling of secondary pulmonary hypertension in left
  ventricular diastolic dysfunction.
\newblock {\em Frontiers in physiology}, page 654, 2021.

\bibitem{sparrow2012lorenz}
C.~Sparrow.
\newblock {\em The Lorenz equations: bifurcations, chaos, and strange
  attractors}, volume~41.
\newblock Springer Science \& Business Media, 2012.

\bibitem{PDEBench2022}
M.~Takamoto, T.~Praditia, R.~Leiteritz, D.~MacKinlay, F.~Alesiani, D.~Pflüger,
  and M.~Niepert.
\newblock {PDEBench: An Extensive Benchmark for Scientific Machine Learning}.
\newblock In {\em 36th Conference on Neural Information Processing Systems
  (NeurIPS 2022) Track on Datasets and Benchmarks}, 2022.

\bibitem{kingma2014adam}
D.P. Kingma and J.~Ba.
\newblock Adam: A method for stochastic optimization.
\newblock {\em arXiv preprint arXiv:1412.6980}, 2014.

\bibitem{ramachandran2017searching}
P.~Ramachandran, B.~Zoph, and Q.~V. Le.
\newblock Searching for activation functions.
\newblock {\em arXiv preprint arXiv:1710.05941}, 2017.

\end{thebibliography}
