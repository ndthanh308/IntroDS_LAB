\newpage

\appendix

%\renewcommand{\thesection}{S\arabic{section}}
%\renewcommand{\thesection}{S\arabic{section}}



\section{Details of the Paper} \label{sec:supp:Detail}

\subsection{Inconsistency of the Ordinary Least Squares Estimator}	\label{sec:supp:OLS}

Following \citet{FermanPinto2021}, we provide details on why synthetic controls obtained from the ordinary least squares (OLS) may be inconsistent. For simplicity, we consider an unconstrained case, in which equation \eqref{eq-OLS} of the main paper reduces to:
\begin{align}
\tag{\ref{eq-OLS}}
\widehat{\bgamma}_{\text{OLS}}
=
\argmin_{\bgamma}
Q(\bgamma)
\ , &&
Q(\bgamma)
= 
\frac{1}{T_0}
\sum_{t=1}^{T_0}
\big(
Y_t - \bW_{ t}\T \bgamma
\big)^2
\ .
\end{align}
For a fixed $\bgamma=(\gamma_{1},\ldots,\gamma_{N}) \T$, the probability limit of $Q(\bgamma)$ as $T_0 \rightarrow \infty$  is given as follows: 
\begin{align}
\nonumber
\lim_{T_0 \rightarrow \infty}
Q(\bgamma)
&=
\lim_{T_0 \rightarrow \infty}
\frac{1}{T_0}
\sum_{t=1}^{T_0} 
\big(
Y_t - 
\bW_{ t}\T \bgamma
\big)^2
\\
\nonumber
& 
=
\lim_{T_0 \rightarrow \infty}
\frac{1}{T_0}
\sum_{t=1}^{T_0} \Big\{
\bW_{ t}\T (\bgamma^\dagger - \bgamma)
+ 
e_{0t} 
-
\sum_{i =1}^{N} \gamma_i^{\dagger} e_{it} 
\Big\}^2
\\
\nonumber
& 
=
\lim_{T_0 \rightarrow \infty}
\frac{1}{T_0}
\sum_{t=1}^{T_0} 
\bigg\{
\sum_{i =1}^{N}
(\gamma_i^\dagger - \gamma_i) \bmu_i\T 
\blambda_t
+ 
e_{0t}
-
\sum_{i=1}^{N} \gamma_i e_{it} 		
\bigg\} ^2
\\
\label{eq-problimit}
&
=
\sum_{i =1}^{N}
(\gamma_i^\dagger - \gamma_i)^2 \bmu_i\T \Lambda	\bmu_i
+
\bigg( 1+ \sum_{i =1}^{N} \gamma_i^2 \bigg) \sigma_e^2
\ .
\end{align}
where the second and third lines hold from \eqref{eq-SC Equation} and \eqref{eq-IFEM} of the main paper, respectively, which are restated below:
\begin{align}	\tag{\ref{eq-IFEM}}
Y_{t}
&
=
\text{\makebox[1.25cm]{$ \tau_{t}^* A_t + $}}
\bmu_{0} \T
\blambda_t
+
e_{0t}
\ ,
&&
\EXP \big( e_{0t} \cond \blambda_t ) = 0
\nonumber
\\
W_{it}
&
=
\text{\makebox[1.25cm]{}}
\bmu_{i} \T
\blambda_t
+
e_{it}
\ , 
&&
\EXP \big( e_{it} \cond \blambda_t ) = 0
\ , 
&&
i \in \{1,\ldots,N\} \ ,
&&
t \in \{1,\ldots,T\} \ .
\nonumber
\end{align}
and
\begin{align}		\tag{\ref{eq-SC Equation}}
\potY{t}{0}
=
\bW_{ t} \T \bgamma^\dagger
+ 
e_{0t} 
-
\sum_{i =1}^{N} \gamma_i^{\dagger} e_{it} 
\ , 
\quad \quad
t \in \{1,\ldots, T\}
\ .
\end{align}
The last line holds under the following additional assumptions on $\blambda_t$ and $e_{it}$ as $T_0 \rightarrow \infty$:
\begin{align*}
& 
\frac{1}{T_0} \sum_{t=1}^{T_0} \blambda_t = o_P(1) \ ,
&&
\frac{1}{T_0} \sum_{t=1}^{T_0} \blambda_t \blambda_t \T = \Lambda + o_P(1)
\\
&
\frac{1}{T_0} \sum_{t=1}^{T_0} {e}_{it} = o_P(1) \ ,
&&
\frac{1}{T_0} \sum_{t=1}^{T_0} {e}_{it} {e}_{jt} = \ind(i=j) \sigma_e^2 
\ , 
&&
\frac{1}{T_0} \sum_{t=1}^{T_0} e_{it} \blambda_t = o_P(1) 
\ .
\end{align*}
where $\Lambda$ is positive semidefinite. Clearly, $\gamma_i^\dagger$ is not the minimizer of \eqref{eq-problimit} unless $\sigma_e^2 = 0$, i.e., a noiseless setting. Therefore, the OLS weights defined in \eqref{eq-OLS} converge to the minimizer of $Q(\bgamma)$ as $T_0 \rightarrow \infty$, which is different from the true synthetic control weights $\bgamma^\dagger$ satisfying $\bm{\mu}_{0} = \sum_{i =1}^{N} \gamma_i^{\dagger} \bm{\mu}_i$. This implies that the OLS estimator is inconsistent for $\bgamma^\dagger$ unless $\sigma_e^2=0$.


\subsection{Choice of the Regularization Parameter $\rho$} \label{sec:supp:CV}

We choose the regularization parameter $\rho$ based on leave-one-out cross-validation; see Algorithm \ref{alg:LOOCV} below.
\begin{algorithm}[!htb]
\begin{algorithmic}[1]
\REQUIRE Length of the pre-treatment periods $T_0$
\FOR{$t \in \{1,\ldots,T_0\}$}

\STATE Let $\widehat{\bG}_{YW,(-t),\rho}$ and $\widehat{\bG}_{YY,(-t),\rho}$ be
\begin{align*}
&
\widehat{\bG}_{YW,(-t),\rho} =
\frac{1}{T_0-1} 
\sum_{s \leq T_0, s \neq t} \bg(s, Y_s \con \widehat{\Beta}) \bW_{ s}\T \in \R^{(d+p) \times d}
\ , 
\\
&
\widehat{\bG}_{YY,(-t),\rho} = 
\frac{1}{T_0-1} 
\sum_{s \leq T_0, s \neq t} \bg(s, Y_s \con \widehat{\Beta}) Y_s \in \R^{d+p} 
\end{align*}
where $\widehat{\Beta}
=
\big( \sum_{t=1}^{T_0} \bD_t\bD_t\T \big)^{-1} 
\big( \sum_{t=1}^{T_0} \bD_tY_t \big) $.

\STATE Let $\widehat{\bgamma}_{(-t),\rho}
=
\big\{ \widehat{\bG}_{YW,(-t),\rho}\T \widehat{\Omega}_{\bg} \widehat{\bG}_{YW,(-t),\rho} + \rho I_{\dim(\bg)\times\dim(\bg)} \big\}^{-1}
\big\{ \widehat{\bG}_{YW,(-t),\rho}\T \widehat{\Omega}_{\bg} \widehat{\bG}_{YY,(-t),\rho} \big\}$

\STATE Calculate the leave-one-out residual $
\widehat{e}_{t,\rho} = Y_t - \bW_{ t} \T \widehat{\bgamma}_{(-t),\rho}$

\ENDFOR

\STATE Obtain the squared error based on the leave-one-out residuals $
\widehat{MSE}_{\rho} = \sum_{t=1}^{T_0} \widehat{e}_{t,\rho}^2 / T_0$

\RETURN Obtain the optimal $\rho$ that minimizes the squared error:
\begin{align*}
\rho_{\text{opt}} = \argmin_{\rho} 
\widehat{MSE}_{\rho}
\end{align*}
\end{algorithmic}
\caption{Leave-one-out Cross-validation for Choosing the Regularization Parameter $\rho$}
\label{alg:LOOCV}
\end{algorithm}


\subsection{A Heteroskedasticity and Autocorrelation Consistent Covariance Matrix Estimator}		\label{sec:supp:HAC}

We provide details of a heteroskedasticity and autocorrelation consistent (HAC) covariance matrix estimator, which are obtained by following approaches of \citet{NW1987} and \citet{Andrews1991}. Let $\big( \widehat{\Beta}, \widehat{\bgamma}_{\rho}, \widehat{\bbeta} \big) $ and $\Psi (\bO_t \con \Beta, \bgamma , \bbeta)$ be the GMM estimators used in Theorem \ref{thm:AN} and the corresponding estimating function, respectively. Then, for a given bandwidth $\omega >0$ and a kernel function $\mathcal{K}(z)$, a heteroskedasticity and autocorrelation consistent estimator of $\Sigma_2^* =
\lim_{T \rightarrow \infty} \VAR \big\{ \sqrt{T} \cdot \widehat{\Psi}(\Beta^*, \bgamma_0^*, \bbeta^*) \big\}$ is given as 
\begin{align*}
\widehat{\Sigma}_2
=
\frac{1}{T}
\sum_{t=1}^{T}
\left[
\begin{array}{l}
\big\{
\Psi( \bO_t \con \widehat{\Beta}, \widehat{\bgamma}_{\rho} , \widehat{\bbeta} )
\big\}
\big\{
\Psi( \bO_t \con \widehat{\Beta}, \widehat{\bgamma}_{\rho} , \widehat{\bbeta} )
\big\}\T
\\
+
\sum_{s=1}^{T} 
\mathcal{K} \big( s / \omega \big)
\big\{
\Psi( \bO_t \con \widehat{\Beta}, \widehat{\bgamma}_{\rho} , \widehat{\bbeta} )
\big\}
\big\{
\Psi( \bO_{t+s} \con \widehat{\Beta}, \widehat{\bgamma}_{\rho} , \widehat{\bbeta} )
\big\}\T
\\
+
\sum_{s=1}^{T} 
\mathcal{K} \big( s / \omega \big)
\big\{
\Psi( \bO_{t+s} \con \widehat{\Beta}, \widehat{\bgamma}_{\rho} , \widehat{\bbeta} )
\big\}
\big\{
\Psi( \bO_{t} \con \widehat{\Beta}, \widehat{\bgamma}_{\rho} , \widehat{\bbeta} )
\big\}\T
\end{array}
\right] \ .
\end{align*} 

Popular choices for the kernel function are Bartlett and quadratic spectral functions, which are defined as follows:
\begin{itemize}[itemsep=0cm,leftmargin=1cm]
\item Bartlett kernel: $\mathcal{K}(z) = \big\{ 1- |z| \big\} \ind\big\{ |z| \leq 1 \big\}$
\item Quadratic spectral kernel: $\mathcal{K}(z) = \big\{ {25}/{(12 \pi^2 z^2)} \big\} \cdot \big\{ \sin (6\pi z/5) / (6\pi z/5) - \cos (6\pi z/5) \big\} $
\end{itemize}

For these two kernel functions, the bandwidth parameter $\omega$ can be chosen based on the approximation to the first-order autoregressive model; see Algorithm \ref{alg:bandwidth} for details. We use the quadratic spectral kernel function for the simulation studies and the data analysis of the main paper.

\begin{algorithm}[!htb]
\begin{algorithmic}[1]
\STATE Let $\big(  \widehat{\Beta}, \widehat{\bgamma}_{\rho} , \widehat{\bbeta} ) \big) $ and $\Psi (\bO_t \con \Beta, \bgamma , \bbeta)$ be the GMM estimators used in Theorem \ref{thm:AN} and the corresponding estimating function related to $\bbeta$, respectively. 

\FOR{$s \in \{1,\ldots,\dim( \Psi_{\post} )\}$}

\STATE Fit AR(1) model for the $s$th component of the time series $\big\{ \Psi_{\post}(\bO_t \con \widehat{\Beta}, \widehat{\bgamma}_{\rho}, \widehat{\bbeta} ) \big\}_{t \in \{1,\ldots,T\}}$. 
\STATE Let $\widehat{\kappa}_s$ and $\widehat{\sigma}_s^2$ be the estimated coefficient of the autoregressive coefficient and the estimated variance of the error from the AR(1) model above, respectively.
\ENDFOR

\STATE For Barlett and quadratic spectral kernel functions, we choose the bandwidth as
\begin{align*}
&
\omega_{\text{Bartlett}} 
=
1.1447 \big\{ \alpha_1 \cdot T \big\}^{1/3}
, 
&&
\hspace*{-0.25cm}
\alpha_1
=
\bigg\{ \sum_{s=1}^{b} \frac{ \widehat{\sigma}_s^4 }{ (1-\widehat{\kappa}_s)^4 } \bigg\}^{-1}
\bigg\{ \sum_{s=1}^{b} \frac{ 4 \widehat{\kappa}_s^2 \widehat{\sigma}_s^4 }{ (1-\widehat{\kappa}_s)^6 (1+\widehat{\kappa}_s)^2} \bigg\} 		
\\
&
\omega_{\text{QS}} 
=
1.3221 \big\{ \alpha_2 \cdot T \big\}^{1/5} 		
,
&&
\hspace*{-0.25cm}
\alpha_2
=
\bigg\{ \sum_{s=1}^{b} \frac{ \widehat{\sigma}_s^4 }{ (1-\widehat{\kappa}_s)^4 } \bigg\}^{-1}
\bigg\{ \sum_{s=1}^{b} \frac{ 4 \widehat{\kappa}_s^2 \widehat{\sigma}_s^4 }{ (1-\widehat{\kappa}_s)^8} \bigg\} \ .
\end{align*}

\RETURN Bandwidth parameters $\omega_{\text{Bartlett}}$ and $\omega_{\text{QS}}$.
\end{algorithmic}
\caption{Choice of Bandwidth Parameters for Bartlett and Quadratic Spectral Kernel Functions}
\label{alg:bandwidth}
\end{algorithm}



\subsection{Block Bootstrap} \label{sec:supp:BB}

In this section, we provide a moving block bootstrap method \citep{Kunsch1989,Liu1992} adapted to our setting. Algorithm \ref{alg:MBB} provides details of the block bootstrap implementation. We remark that other block bootstrap methods can be adopted with minor modifications; see \citet{Lahiri1999} for examples of block bootstrap methods.

\begin{algorithm}[!htb]
\begin{algorithmic}[1]
\REQUIRE Length of the block $L < T_0$, Number of bootstrap repetitions $B$

\STATE Let the pre- and post-treatment blocks be
\begin{align*}
&
B_{\pre,1} = \big\{ \bO_1,\ldots,\bO_L \big\} , 
&& \ldots \ , 
&& B_{\pre,T_0-L+1} = \big\{ \bO_{T_0-L+1},\ldots,\bO_{T_0} \big\} 	
\\
&
B_{\post,1} = \big\{ \bO_{T_0+1},\ldots, \bO_{T_0+L} \big\} , 
&& \ldots \ , 
&& B_{\post,T_0-L+1} = \big\{ \bO_{T-L+1},\ldots, \bO_{T} \big\} 	
\end{align*} 	

\FOR{$b \in \{1,\ldots,B\}$}

\STATE Randomly sample $K_{\pre} = \lceil T_0/L \rceil$ pre-treatment blocks and $K_{\post} = \lceil T_1/L \rceil$ post-treatment blocks with replacement, respectively; we denote these blocks as $\big\{ B_{\pre,1}^{(b)} ,\ldots, B_{\pre,K_{\pre}}^{(b)} \big\}$ and $\big\{ B_{\post,1}^{(b)} ,\ldots, B_{\post,K_{\post}}^{(b)} \big\}$

\STATE Choose the first $T_0$ and $T_1$ observations from the resampled blocks, i.e.,
\begin{align*}
&
\big\{ \bO_1^{(b)},\ldots,\bO_{T_0} ^{(b)} \big\}
=
\text{first $T_0$ observations of } \big\{ B_{\pre,1}^{(b)} ,\ldots, B_{\pre,K_{\pre}}^{(b)} \big\}
\\
&
\big\{ \bO_{T_0+1}^{(b)},\ldots,\bO_{T} ^{(b)} \big\}
=
\text{first $T_1$ observations of } \big\{ B_{\post,1}^{(b)} ,\ldots, B_{\post,K_{\post}}^{(b)} \big\}
\end{align*}

\STATE Calculate $\widehat{\bbeta}^{(b)}$ from the GMM in Section \ref{sec:Estimation} using $\big\{ \bO_1^{(b)},\ldots,\bO_{T_0} ^{(b)} , \bO_{T_0+1}^{(b)},\ldots,\bO_{T} ^{(b)} \big\}$. 	

\ENDFOR

\RETURN Report the variance of the bootstrap estimates $\big\{ \widehat{\bbeta}^{(1)}, \ldots, \widehat{\bbeta}^{(B)} \big\}$
\end{algorithmic}
\caption{Moving Block Bootstrap in Single Proxy Synthetic Control Framework}
\label{alg:MBB}
\end{algorithm}


The choice of block length $L$ is critical to the performance of block bootstrap methods. The optimal choice of $L$ for minimizing mean square error is known to be $O(T^{1/3})$. In the simulation studies in Section \ref{sec:Sim}, we use the bandwidth of the Bartlett kernel function $\omega_{\text{Bartlett}}$ in Algorithm \ref{alg:bandwidth} of which the rate is $O(T^{1/3})$. As discussed, this choice seems reasonable based on the simulation results reported in Section \ref{sec:supp:Simulation}. 

\subsection{Examples Where Assumption \ref{assumption:SC} Holds But Condition \ref{assumption:SC-structural} Is Violated} \label{sec:supp:IFEM}

We provide an example that violation of Condition \ref{assumption:SC-structural} does not necessarily imply violation of Assumption \ref{assumption:SC}. Consider the following interactive fixed effects model (IFEM): 
\begin{align}
&
\potY{t}{0}
= \bm{\mu}_0\T \blambda_t + e_{0t}	
\ , \quad
W_{it}
=
\bm{\mu}_i\T \blambda_t + e_{it}
\ , \quad
i \in \{1,\ldots,N\}
\ , \quad 
t \in \{1,\ldots, T\} \ ,
\nonumber
\\
& \text{where }
\quad
\blambda_t \stackrel{iid}{\sim} N (\bm{\nu}_t, \Sigma_{\rho})
\quad , \quad 
\big( 
e_{0t} \ , \ e_{1t} \ , \ \cdots \ , \ e_{Nt}
\big)\T
\stackrel{iid}{\sim}
N( 0_{(N+1) \times 1} , 
\Sigma_e ) \ .
\label{eq-IFEM-supp}
\end{align}
Note that the model allows for non-stationarity behaviors, as $\bm{\nu}_t$ can be time-varying. The model also allows for $\sigma_{ij}=0$ for $i\neq j$, i.e., independent errors, where $\sigma_{ij}$ for $i,j \in \{0,1,\ldots,N\}$ is the components of $\Sigma_e$. Therefore, for any $\bgamma \in \R^{N}$, we find
\begin{align*}
\bW_t\T \bgamma
=
\bigg( \sum_{i=1}^{N} \gamma_i \bm{\mu}_i\T \bigg) \blambda_t + \bigg( \sum_{i=1}^{N} \gamma_i e_{it} \bigg) 
\quad \Rightarrow \quad 
\EXP \big( \bW_t\T \bgamma \cond \blambda_t, e_{0t} \big)
=
\bigg( \sum_{i=1}^{N} \gamma_i \bm{\mu}_i\T \bigg) \blambda_t \ .
\end{align*}
Note that $\EXP \big( \bW_t\T \bgamma \cond \blambda_t, e_{0t} \big)$ does not depend on $e_{0t}$  for any $\bgamma$ where as $\potY{t}{0} =  	\bm{\mu}_0\T\blambda_t + e_{0t}$ depends on $e_{0t}$. Therefore, there is no $\bgamma$ satisfying Condition \ref{assumption:SC-structural} when errors are independent, unless $\sigma_{00}=\VAR(e_{0t})$ is zero. 


However, one can still find $\bm{\gamma}$ such that Assumption \ref{assumption:SC} is satisfied despite independent errors, i.e., there exists a weight vector $\bgamma^*$ satisfying
\begin{align*}
\EXP \big\{ \bW_t\T \bgamma^* \cond 
\potY{t}{0} \big\}
=
\EXP \big( \bW_t\T \bgamma^* \cond \bm{\mu}_0\T \bm{\lambda}_t + e_{0t} \big) 
= 
\bm{\mu}_0\T \bm{\lambda}_t + e_{0t}
=
\potY{t}{0}
\ .
\end{align*}
Specifically, let $\bm{\gamma}^*=(\gamma_1^*,\cdots,\gamma_N^*)$ be a vector that solves the following two equations:
\begin{align}
&
\bm{\mu_0}
=
\sum_{i=1}^{N} \gamma_i^*  \bm{\mu}_i
\label{eq-IFEM-SPSC-1}
\ , \\
&
\bm{\mu}_0\T \Sigma_{\rho}
\bm{\mu}_0 + \sigma_{00}
=
\sum_{i=1}^{N} \gamma_{i}^* ( \bm{\mu}_0\T \Sigma_{\rho} \bm{\mu}_i + \sigma_{0i} )   \ .
\label{eq-IFEM-SPSC-2}
\end{align}
Again, note that $\sigma_{0i}=0$ for all $i \in \{1,\ldots,N\}$ when errors are independent.

From a property of joint normal distributions, we can represent the conditional distribution of $e_{it}$ given $e_{0t}$ as follows:
\begin{align*}
e_{it} \cond e_{0t}
\stackrel{D}{=}
\frac{\sigma_{0i}}{\sigma_{00}} e_{0t}
+ \xi_{it} \ ,
\quad
\xi_{it} \sim N \bigg( 0, \sigma_{ii}^2 - \bigg( \frac{\sigma_{0i}}{\sigma_{00}} \bigg)^2
\bigg) 
\ , 
\quad 
e_{0t} \indep \xi_{it}
\end{align*} 
Therefore, we find the joint distribution of $(\bW_t\T \bgamma^*,\potY{t}{0})$ is represented as follows:
\begin{align*}
&
\begin{pmatrix}
\bW_t\T \bgamma^*
\\
\potY{t}{0}
\end{pmatrix}  
\\
& 
\stackrel{D}{=}
\begin{pmatrix}
\sum_{i=1}^{N} \gamma_{i}^* 
(\bm{\mu}_i\T \bm{\lambda}_t +
\frac{\sigma_{0i}}{\sigma_{00}}
\epsilon_0
+
\xi_i
)
\\
\bm{\mu}_0\T \bm{\lambda}_t + \epsilon_0
\end{pmatrix} 
\\
&
\sim 
N
\left(
\begin{pmatrix}
\sum_{i=1}^{N} \gamma_{i}^* 
(\bm{\mu}_i\T \bm{\nu}_t) \\ 
\bm{\mu}_0\T \bm{\nu}_t
\end{pmatrix}
,
\begin{pmatrix}
(*) & \sum_{i=1}^{N} \gamma_{i}^* (\bm{\mu}_0\T \Sigma_{\rho} \bm{\mu}_i
+
\sigma_{0i})
\\
\sum_{i=1}^{N} \gamma_{i}^* (\bm{\mu}_0\T \Sigma_{\rho} 
\bm{\mu}_i
+
\sigma_{0i})
&
\bm{\mu}_0\T \Sigma_{\rho}
\bm{\mu}_0 + \sigma_{00}
\end{pmatrix}
\right)  ,
\end{align*}
where $(*)$ denotes a generic variance. This implies that the conditional distribution $\bW_t\T \bgamma^* \cond \potY{t}{0}$ is given by 
\begin{align}
\bW_t\T \bm{\gamma}^* \cond ( \potY{t}{0} =y )
&
=
\bW_t\T \bm{\gamma}^* \cond ( \bm{\mu}_0\T \bm{\lambda}_t + \epsilon_0 = y )
\nonumber
\\
&
\sim 
N
\Bigg(
\underbrace{
\sum_{i=1}^{N} \gamma_{i}^* \bm{\mu}_i\T \bm{\nu}_{t}
+
\frac{ \sum_{i=1}^{N} \gamma_{i}^* (\bm{\mu}_0\T \Sigma_{\rho} \bm{\mu}_i
+ \sigma_{0i})} { \bm{\mu}_0\T \Sigma_{\rho} 
\bm{\mu}_0 + \sigma_{00} }
( y - \bm{\mu}_0\T \bm{\nu}_{t})}_{=y} , (*)
\Bigg) \ ,    
\label{eq-IFEM-SPSC-3}
\end{align}
where the last line holds from \eqref{eq-IFEM-SPSC-1} and \eqref{eq-IFEM-SPSC-2}. 
Therefore, we get $ \EXP \big\{ \bW_t\T \bm{\gamma}^* \cond \potY{t}{0}\big\} = \potY{t}{0}$ almost surely, implying that Assumption \ref{assumption:SC} is satisfied with $h^*(\bW_t) = \bW_t\T \bm{\gamma}^*$. Note that the synthetic control weight vector $\bgamma^*$ exists even when errors are independent and the outcomes are non-stationary.

Assumption \ref{assumption:SC} can be satisfied for non-continuous outcomes. To illustrate this, consider the following latent variable model for count data:
\begin{align*}
&
\potY{t}{0} = \bm{\mu}_0\T \bm{\blambda}_t + V_{0t} 
\sim \text{Poisson} \bigg( \sum_{j=1}^{r} \mu_{j0} + \kappa_0 \bigg)
\ , \quad 
\\
&
W_{it} = \bm{\mu}_i\T \bm{\blambda}_t + V_{it} 
\sim \text{Poisson} \bigg( \sum_{j=1}^{r} \mu_{ji} + \kappa_i \bigg)
\ , \quad i \in \{1,\ldots,N\} \ , 
\\
&
\bm{\lambda}_t = (\lambda_{1t},\ldots,\lambda_{rt})\T \text{ where }  \lambda_{jt} \sim \text{Poisson}(\nu_{jt}) \text{ for } j \in \{1,\ldots,r\} \ , \\
&
V_{it} \sim \text{Poisson}(\kappa_{i}) \text{ for } i \in \{0,1,\ldots,N\} \ , \\
& 
\lambda_{1t} \indep \ldots \indep \lambda_{rt} \indep V_{0t} \indep V_{1t} \indep \ldots \indep V_{Nt} \ .
\end{align*}
Note that $(\potY{t}{0},\bW_{t})$ can be non-stationary because $\bm{\nu}_t=(\nu_{1t},\ldots,\nu_{rt})\T$ is allowed to be time-varying. 

Let $\bgamma^* = (\gamma_1^*,\ldots,\gamma_N^*)\T$ be a vector that satisfies $
\bm{\mu}_0 
= 
\sum_{i=1}^N \gamma_i^* \bm{\mu}_i$. Then, we find
\begin{align*}
& \bW_t\T \bgamma^*
\cond \potY{t}{0}
\\
&
\stackrel{D}{=}
\bigg( \sum_{i=1}^{N} \gamma_i^* \bm{\mu}_i\T \blambda_{t}  + \sum_{i=1}^{N} \bgamma_i^* V_{it}\bigg) 
\, \bigg| \, (  \bm{\mu}_0\T \blambda_t + V_{0t} )
\\
&
\stackrel{D}{=}
\bigg( \sum_{i=1}^{N} \gamma_i^* \bm{\mu}_i\T \blambda_{t} \bigg) 
\, \bigg| \, ( \bm{\mu}_0\T \blambda_t + V_{0t} )
\oplus \sum_{i=1}^{N} \gamma_i^* V_{it}
&&
\Leftarrow
\quad (V_{1t},\ldots,V_{Nt}) \indep (\blambda_t, V_{0t})
\\
&
\stackrel{D}{=}
\bm{\mu}_0 \blambda_{t}
\, \big| \, ( \bm{\mu}_0\T \blambda_t + V_{0t} )
\oplus 
\text{Poisson} \bigg( \sum_{i=1}^{N} \gamma_i^*\kappa_{i} \bigg)
&&
\Leftarrow
\quad 
\bm{\mu}_0=\sum_{i=1}^{N} \gamma_i^* \bm{\mu}_i
\\
&
\stackrel{D}{=}
\text{Bin}
\bigg(
\bm{\mu}_0\T \blambda_t + V_{0t} 
, 
\frac{ \sum_{j=1}^{r} \mu_{ji} }{\sum_{j=1}^{r} \mu_{ji} + \kappa_0}
\bigg)
\oplus 
\text{Poisson} \bigg( \sum_{i=1}^{N} \gamma_i^*\kappa_{i} \bigg)
&&
\Leftarrow
\quad 
\text{see \eqref{eq-Pois-Binom}}
\\
&
\stackrel{D}{=}
\text{Bin}
\bigg(
\potY{t}{0}
, 
\frac{ \sum_{j=1}^{r} \mu_{ji} }{\sum_{j=1}^{r} \mu_{ji} + \kappa_0}
\bigg)
\oplus 
\text{Poisson} \bigg( \sum_{i=1}^{N} \gamma_i^*\kappa_{i} \bigg)
\end{align*}

Note that the fourth line holds from
\begin{align}
\label{eq-Pois-Binom}
V_i \stackrel{\text{indep}}{\sim} \text{Poisson}(\mu_i) \ , \ i=1,2 \ ,
\quad \Rightarrow \quad 
V_1 \cond (V_1+V_2) \stackrel{D}{=} \text{Bin} \bigg( V_1+V_2 , \frac{\mu_1}{\mu_1+\mu_2} \bigg) \ .
\end{align}
Consequently, we find
\begin{align*}
&
\EXP \big\{ \bW_t\T \bgamma^*
\cond \potY{t}{0} \big\}
=
\frac{ \sum_{j=1}^{r} \mu_{ji} }{\sum_{j=1}^{r} \mu_{ji} + \kappa_0}
\potY{t}{0}
+
\sum_{i=1}^{N} \gamma_i^*\kappa_{i} 
\\
& \Leftrightarrow \quad 
\EXP \bigg\{ 
\underbrace{
\frac{\sum_{j=1}^{r} \mu_{ji} + \kappa_0}{ \sum_{j=1}^{r} \mu_{ji} }
( \bW_t - \bm{\kappa})\T  \bgamma^*
}_{=:h^*(\bW_t)}
\, \bigg| \, \potY{t}{0} \bigg\}
=
\potY{t}{0} \quad \Leftarrow \quad 
\bm{\kappa}=(\kappa_1,\ldots,\kappa_N)\T
\ . 
\end{align*} 
Therefore, we can find a synthetic control bridge function $h^*(\bW_t)$.
% ETT THIS IS VERY INTERESTING I WONDER HOW IT RELATES TO THE JOHANNSON PAPER I EMAILED YOU SEE HIS POISSON EXAMPLE, IF RELATED MIGHT BE GOOD TO CITE IT AS FURTHER THEORETICAL FOUNDATION FOR OUR METHODS 


\subsection{Details on Accommodating Time-varying Components}		\label{sec:supp:DT}


We provide a rationale that accommodating time-varying components can improve the performance of the SPSC approach. Specifically, we consider the IFEM \eqref{eq-IFEM-supp}, where $\EXP(\blambda_t) = \bm{\nu}_t$ is assumed to lie within the space spanned by $\bD_t$, i.e.,
\begin{align*}
\bm{\nu}_t=\EXP(\blambda_t)
=
\mathcal{E}\sT \bD_t \ , \quad \mathcal{E}^* \in \R^{d \times r} \ .
\end{align*}
This assumption is reasonable if $\bD_t$ is defined as a set of rich basis functions, such as polynomials, trigonometric functions, splines, or wavelets. 

\subsubsection{Using the Time-invariant Estimating Equation}

Suppose that the synthetic control weights are estimated by the time-invariant pre-treatment estimating equation:
\begin{align*}	
\widehat{\bgamma}_{\rho}
=
\argmin_{\bgamma}
\Bigg[ 
\bigg\|
\frac{1}{T_0}
\sum_{t=1}^{T_0}
\bh (Y_t)
\big( Y_t - \bW_{ t} \T \bgamma \big)
\bigg\|_2^2
+ \rho \big\| \bgamma \big\|_2^2
\Bigg]
\ . 
\end{align*}
For simplicity, we choose $\bh(y)=(1,y)\T$. Then, it is straightforward to show that the regularized GMM estimator of $\bgamma$ is given by
\begin{align*}
\widehat{\bgamma}_{\rho}
=
\big(
\widehat{\bG}_{YW} \T \widehat{\bG}_{YW}
+
\rho I_{N \times N} 
\big)^{-1}
\big( 
\widehat{\bG}_{YW} \T \widehat{\bG}_{YY}
\big)
\end{align*}
where 
\begin{align*}
&
\widehat{\bG}_{YW} =
\frac{1}{T_0} 
\sum_{t=1}^{T_0} \begin{pmatrix}
\bW_{ t}\T \\ Y_t \bW_{ t}\T
\end{pmatrix}   \in \R^{2 \times N}
\ , 
&&
\widehat{\bG}_{YY} = 
\frac{1}{T_0} \sum_{t=1}^{T_0} \begin{pmatrix}
Y_t \\ Y_t^2
\end{pmatrix} \in \R^{2} \ .
\end{align*}
From the law of large numbers, we find
\begin{align*}
&
\widehat{\bG}_{YW} \stackrel{P}{\rightarrow} 
{\bG}_{YW}^*
=
\begin{pmatrix}	
\overline{\bm{\nu}}\T
\mathfrak{M} 
\\
\bm{\mu}_0\T  
\Lambda
\mathfrak{M} 
+
\Sigma_{0,(-0)}
\end{pmatrix}
\ , 
\quad 
&&
\hspace*{-1cm}
\widehat{\bG}_{YY}
\stackrel{P}{\rightarrow} 
{\bG}_{YY}^*
=
\begin{pmatrix}	
\overline{\bm{\nu}}\T
\bm{\mu}_0
\\
\bm{\mu}_0\T  
\Lambda
\bm{\mu}_0
+\sigma_{00}
\end{pmatrix}
\ , 
\\
&
\mathfrak{M} =	\big[ \bm{\mu}_1 \ , \ \cdots \ , \ \bm{\mu}_{N} \big]
\in \R^{r \times N}
\ , \quad 
&&
\hspace*{-1cm}
\Sigma_{0,(-0)} = (\sigma_{01},\cdots,\sigma_{0N}) \in \R^{1 \times N}
\\
&
\overline{\bm{\nu}}
=
\lim_{T_0 \rightarrow \infty}
\frac{1}{T_0} \sum_{t=1}^{T_0} \EXP \big( \blambda_t) 
=
\lim_{T_0 \rightarrow \infty}
\frac{1}{T_0} \sum_{t=1}^{T_0} \bm{\nu}_t
\in \R^{r}
\ , \\
&
\Lambda
=
\lim_{T_0 \rightarrow \infty}
\frac{1}{T_0} \sum_{t=1}^{T_0} \EXP \big( \blambda_t \blambda_t\T \big)  
=
\Sigma_{\rho} + 
\lim_{T_0 \rightarrow \infty}
\frac{1}{T_0} \sum_{t=1}^{T_0} \bm{\nu}_t  \bm{\nu}_t\T
\in \R^{r \times r}
\ .
\end{align*}
Therefore, the limit of $\widehat{\bgamma}_{\rho}$ is $\bgamma^\dagger = \big( \bG_{YW}^* \big)^+ \bG_{YY}^*$, which is the minimum-norm solution of the equation $ \bG_{YY}^*
=
\bG_{YW}^* \bgamma $. Therefore, $\bgamma^\dagger$ satisfies
\begin{align*}
\bG_{YY}^*
=
\bG_{YW}^* \bgamma^\dagger
\quad \Leftrightarrow \quad 
\left\{
\begin{array}{l}	
\overline{\bm{\nu}}\T \bm{\mu}_0
=
\overline{\bm{\nu}}\T \mathfrak{M}
\bgamma^\dagger
=
\overline{\bm{\nu}}\T
\sum_{i=1}^{N} \bm{\mu}_i \gamma_i^\dagger
\
\\
\bm{\mu}_0\T \Lambda \bm{\mu}_0 + \sigma_{00}
=
\big\{ \bm{\mu}_0\T \Lambda \mathfrak{M} + \Sigma_{0,(-0)} \big\} \bgamma^\dagger
=	
\sum_{i=1}^{N}
\big(
\bm{\mu}_0\T
\Lambda \bm{\mu}_i + \sigma_{0i} \big) \gamma_i^\dagger
\end{array}
\right. 
\ .
\end{align*}

If  $\bm{\nu}_t=\bm{\nu}$ for all $t$, i.e., the mean of $\blambda_t$ is time-invariant, we have 
\begin{align}
&
\overline{\bm{\nu}}\T \bm{\mu}_0 
=
\overline{\bm{\nu}}\T
\sum_{i=1}^{N} \bm{\mu}_i \gamma_i^\dagger
\quad \Rightarrow \quad 
\bm{\mu}_0\T \bm{\nu}
=
\sum_{i=1}^{N} \gamma_{i}^\dagger \bm{\mu}_i\T \bm{\nu}
\label{eq-time-invariant-IFEM-1}
\end{align}	
and
\begin{align}
&
\bm{\mu}_0\T \Lambda \bm{\mu}_0 + \sigma_{00} 
=	
\sum_{i=1}^{N}
\big(
\bm{\mu}_0\T
\Lambda \bm{\mu}_i + \sigma_{0i} \big) \gamma_i^\dagger   
\nonumber
\\
&
\Rightarrow \quad
\bm{\mu}_0\T \bigg( \Sigma_{\rho} + \lim_{T_0 \rightarrow \infty} \sum_{t=1}^{T_0} \bm{\nu}_t\bm{\nu}_t\T \bigg)
\bm{\mu}_0 + \sigma_{00}
=
\sum_{i=1}^{N} \gamma_{i}^\dagger \bigg\{ \bm{\mu}_0\T \bigg( \Sigma_{\rho} + \lim_{T_0 \rightarrow \infty} \sum_{t=1}^{T_0} \bm{\nu}_t\bm{\nu}_t\T \bigg) \bm{\mu}_i + \sigma_{0i} \bigg\}
\nonumber
\\
&
\Rightarrow \quad
\bm{\mu}_0\T \big( \Sigma_{\rho} +  \bm{\nu}\bm{\nu}\T \big)
\bm{\mu}_0 + \sigma_{00}
=
\sum_{i=1}^{N} \gamma_{i}^\dagger \big\{ \bm{\mu}_0\T \big( \Sigma_{\rho} +  \bm{\nu}\bm{\nu}\T \big) \bm{\mu}_i + \sigma_{0i} \big\}
\nonumber
\\
&
\stackrel{\eqref{eq-time-invariant-IFEM-1}}{\Rightarrow} \quad
\bm{\mu}_0\T \Sigma_{\rho} 
\bm{\mu}_0 + \sigma_{00}
=
\sum_{i=1}^{N} \gamma_{i}^\dagger  \bm{\mu}_0\T \Sigma_{\rho} \bm{\mu}_i + \sigma_{0i} \ . 
\label{eq-time-invariant-IFEM-2}
\end{align}
Therefore, $\bW\T \bgamma^\dagger$ satisfies \eqref{eq-IFEM-SPSC-3}, implying that it is a valid synthetic control satisfying Assumption \ref{assumption:SC}. Therefore, $\bW_t\T \widehat{\bgamma}_{\rho}$ can be used to obtain a consistent estimate for the ATT. 


However, the solution $\bgamma^\dagger$ in general does not satisfy \eqref{eq-IFEM-SPSC-1} when $\EXP(\blambda_t)=\bm{\nu}_t$ is time-varying. This is because conditions \eqref{eq-time-invariant-IFEM-1} and \eqref{eq-time-invariant-IFEM-2} are not generally satisfied. 	Therefore, $\bW\T \bgamma^\dagger$ fails to satisfy \eqref{eq-IFEM-SPSC-3}. Therefore, the synthetic control $\bW_t\T \widehat{\bgamma}_{\rho}$ converges to a invalid synthetic control that fails to satisfy Assumption \ref{assumption:SC}, leading to an inconsistent estimate for the ATT.


\subsubsection{Using the Time-varying Estimating Equation}

Suppose that the synthetic control weights are estimated by the time-varying pre-treatment estimating equation:
\begin{align*}	
\widehat{\bgamma}_{\rho}
=
\argmin_{\bgamma}
\Bigg[ 
\bigg\|
\frac{1}{T_0}
\sum_{t=1}^{T_0}
\bigg[ 
\begin{array}{c}
\bD_t
\\[-0.2cm]
\bh (Y_t - \bD_t\T \Beta^*)
\end{array}
\bigg]
\big( Y_t - \bW_{ t} \T \bgamma \big)
\bigg\|_2^2
+ \rho \big\| \bgamma \big\|_2^2
\Bigg]
\ ,
\end{align*}
where $\Beta^*$ satisfies $\EXP(Y_t) = \bm{\mu}_0\T \bm{\nu}_t = \bD_t\T \Beta^*$ for $t \in \{1,\ldots,T_0\}$. Note that $\bm{\eta}^* = \mathcal{E}^* \bm{\mu}_0$. For simplicity, we choose $\bh(y)=y$. Then, it is straightforward to show that the regularized GMM estimator of $\bgamma$ is given by
\begin{align*}
\widehat{\bgamma}_{\rho}
=
\big(
\widehat{\bG}_{YW} \T \widehat{\bG}_{YW}
+
\rho I_{N \times N} 
\big)^{-1}
\big( 
\widehat{\bG}_{YW} \T \widehat{\bG}_{YY}
\big)
\end{align*}
where 
\begin{align*}
&
\widehat{\bG}_{YW} =
\frac{1}{T_0} 
\sum_{t=1}^{T_0} \begin{pmatrix}
\bD_t \bW_{ t}\T 
\\
(Y_t - \bD_t\T \Beta^*) \bW_{ t}\T
\end{pmatrix}   \in \R^{(d+1) \times N}
\ , 
&&
\widehat{\bG}_{YY} = 
\frac{1}{T_0} \sum_{t=1}^{T_0} \begin{pmatrix}
\bD_t Y_t  
\\
(Y_t - \bD_t\T \Beta^*) Y_t
\end{pmatrix} \in \R^{d+1} \ .
\end{align*}	
Note that $Y_t - \bD_t\T \Beta^* = \bm{\mu}_0\T (\blambda_t - \bm{\nu}_t) + e_{0t}$, which results in
\begin{align*}
\EXP \big\{ \big( Y_t - \bD_t\T \Beta^* ) \bW_t\T \big\}
&
=
\EXP \big[ \big\{  \bm{\mu}_0\T (\blambda_t - \bm{\nu}_t) + e_{0t} \big\} 
\big( \blambda_t\T \mathfrak{M} + \bm{e}_t\T \big) \big]
\\
&
=
\bm{\mu}_0\T \EXP \big\{ (\blambda_t-\bm{\nu}_t) \blambda_t\T \big\} \mathfrak{M}
+ \Sigma_{0,(-0)}
\ , 
&&
\Leftarrow \quad 
\Sigma_{0,(-0)} = (\sigma_{01},\cdots,\sigma_{0N}) \in \R^{1 \times N}
\\
&
=
\bm{\mu}_0\T \Sigma_{\rho} \mathfrak{M}
+ \Sigma_{0,(-0)} \ ,
\\
\EXP \big\{ \big( Y_t - \bD_t\T \Beta^* ) Y_t \big\}
&
=
\EXP \big[ \big\{  \bm{\mu}_0\T (\blambda_t - \bm{\nu}_t) + e_{0t} \big\} 
\big( \blambda_t\T \bm{\mu}_0 + e_{0t} \big) \big]
\\
&
=
\bm{\mu}_0\T \EXP \big\{ (\blambda_t-\bm{\nu}_t) \blambda_t\T \big\} \bm{\mu}_0
+ \sigma_{00}
\\
&
=
\bm{\mu}_0\T \Sigma_{\rho} \bm{\mu}_0
+ \sigma_{00}
\ .
\end{align*}
From the law of large numbers, we find
\begin{align*}
&
\widehat{\bG}_{YW} \stackrel{P}{\rightarrow} 
{\bG}_{YW}^*
=
\begin{pmatrix}	
(\overline{\bm{D} \bm{\nu}}\T)
\mathfrak{M} 
\\
\bm{\mu}_0\T  
\Sigma_{\rho}
\mathfrak{M} 
+
\Sigma_{0,(-0)}
\end{pmatrix}
\ , 
\quad 
&&
\hspace*{-1cm}
\widehat{\bG}_{YY}
\stackrel{P}{\rightarrow} 
{\bG}_{YY}^*
=
\begin{pmatrix}	
(\overline{\bm{D} \bm{\nu}}\T)
\bm{\mu}_0
\\
\bm{\mu}_0\T  
\Sigma_{\rho}
\bm{\mu}_0
+\sigma_{00}
\end{pmatrix}
\ , 
\\
&
\mathfrak{M} =	\big[ \bm{\mu}_1 \ , \ \cdots \ , \ \bm{\mu}_{N} \big]
\in \R^{r \times N}
\ , \quad 
&&
\hspace*{-1cm}
\Sigma_{0,(-0)} = (\sigma_{01},\cdots,\sigma_{0N}) \in \R^{1 \times N}
\\
&
(\overline{\bm{D} \bm{\nu}}\T)
=
\lim_{T_0 \rightarrow \infty}
\frac{1}{T_0} \sum_{t=1}^{T_0}  
(\bm{D}_t \bm{\nu}_t\T)
\in \R^{d \times r}
\ , \quad 
&&
\hspace*{-1cm}
\overline{\bm{\nu}}
=
\lim_{T_0 \rightarrow \infty}
\frac{1}{T_0} \sum_{t=1}^{T_0} \bm{\nu}_t
\in \R^{r}
\ .
\end{align*}
Since $\bm{\nu}_t = \mathcal{E}\sT \bD_t$, we have $(\overline{\bm{D} \bm{\nu}}\T) = (\overline{\bm{D} \bm{D}}\T)
\mathcal{E}^*$ where
\begin{align*}
&
(\overline{\bm{D} \bm{D}}\T)
=
\lim_{T_0 \rightarrow \infty}
\frac{1}{T_0} \sum_{t=1}^{T_0}  
(\bm{D}_t \bm{D}_t\T) 
\in \R^{d \times d}
\ .
\end{align*}
We can re-define $\bm{D}_t$ so that $(\overline{\bm{D} \bm{D}}\T)$ is of full rank. Therefore, the limit of $\widehat{\bgamma}_{\rho}$ is $\bgamma^\dagger = \big( \bG_{YW}^* \big)^+ \bG_{YY}^*$, which is the minimum-norm solution of the equation $ \bG_{YY}^*
=
\bG_{YW}^* \bgamma $. Therefore, $\bgamma^\dagger$ satisfies
\begin{align*}
\bG_{YY}^*
=
\bG_{YW}^* \bgamma^\dagger
\quad \Leftrightarrow \quad 
\left\{
\begin{array}{l}	
(\overline{\bm{D} \bm{D}}\T)
\mathcal{E}^* \bm{\mu}_0
=	
(\overline{\bm{D} \bm{D}}\T)
\mathcal{E}^* \mathfrak{M}
\bgamma^\dagger 
\\
\bm{\mu}_0\T \Sigma_{\rho} \bm{\mu}_0 + \sigma_{00}
=
\sum_{i=1}^{N}
\big(
\bm{\mu}_0\T
\Sigma_{\rho} \bm{\mu}_i + \sigma_{0i} \big) \gamma_i^\dagger
\end{array}
\right. 
\ .
\end{align*}
Consequently, we further obtain
\begin{align}
(\overline{\bm{D} \bm{D}}\T)
\mathcal{E}^* \bm{\mu}_0
=	
(\overline{\bm{D} \bm{D}}\T)
\mathcal{E}^* \mathfrak{M}
\bgamma^\dagger
\quad 
& 
\Leftrightarrow
\quad
\mathcal{E}^* \bm{\mu}_0
=
\sum_{i=1}^{N} \mathcal{E}^* \bm{\mu}_i \gamma_i^\dagger
\nonumber
\\
&
\Rightarrow \quad 
\bD_t\T
\mathcal{E}^* \bm{\mu}_0
=
\sum_{i=1}^{N} \bD_t\T \mathcal{E}^* \bm{\mu}_i
\nonumber
\\
&
\Leftrightarrow \quad 
\bm{\nu}_t\T \bm{\mu}_0
=
\sum_{i=1}^{N} \bm{\nu}_t\T \bm{\mu}_i \gamma_i^\dagger
\label{eq-time-invariant-IFEM-3}
\end{align}	
and
\begin{align}
&
\bm{\mu}_0\T \Sigma_{\rho} \bm{\mu}_0 + \sigma_{00}
=
\sum_{i=1}^{N}
\big(
\bm{\mu}_0\T
\Sigma_{\rho} \bm{\mu}_i + \sigma_{0i} \big) \gamma_i^\dagger \ .
\label{eq-time-invariant-IFEM-4}
\end{align}
Therefore, $\bW\T \bgamma^\dagger$ satisfies \eqref{eq-IFEM-SPSC-3}, implying that $\bW\T \bgamma^\dagger$ is a valid synthetic control satisfying Assumption \ref{assumption:SC}. Therefore, $\bW_t\T \widehat{\bgamma}_{\rho}$ can be used to obtain a consistent estimate for the ATT. 	







\subsection{Extension: Covariate Adjustment}		\label{sec:Cov}

In practice, a rich collection of measured exogenous covariates may be available. One may want to incorporate these covariates in the synthetic control analysis because using these covariates may improve efficiency. In this Section, we provide details on the SPSC framework by incorporating measured covariates. Specifically, we denote $q$-dimensional measured exogenous covariates for unit $i  \in \{ 0,\ldots,N\}$ at time $t \in \{1,\ldots,T\}$ as $\bX_{it} \in \R^{q}$; we remind the readers that $i=0$ is the treated unit and $i \in \{1,\ldots,N\}$ are the untreated units. Let $\bX_{t} = ( \bX_{1 t}\T,\ldots,\bX_{N t}\T)\T \in \R^{Nq}$ be the collection of all measured covariates of donors at time $t$. To account for covariates, we modify Assumptions \ref{assumption:valid proxy} and \ref{assumption:SC} as follows:



\begin{assumption}[Proxy \& Existence of a Synthetic Control Bridge Function] \label{assumption:valid proxy Cov}
There exists a function $h: \R^{N(q+1)} \rightarrow \R$ satisfying 
\begin{align}
&
h^*(\bW_{ t}, \bX_{0t}, \bX_{ t} ) \nindep \potY{t}{0} \cond ( \bX_{0t}, \bX_t )
\ , 
&&
t \in \{1, \ldots, T_0\} \ ,
\\
& 
\potY{t}{0} = \EXP \big\{
h^*(\bW_{ t}, \bX_{0t}, \bX_{t} )
\cond
\potY{t}{0}, \bX_{0t}, \bX_{t}
\big\} \ \ \text{almost surely} 
\ , 
&&
t \in \{1, \ldots, T\} \ .
\label{eq-relevant Cov}
\end{align}
\end{assumption} 

\begin{theorem}	\label{thm:Extension NP Cov}

Suppose that Assumptions \ref{assumption:consistency}, \ref{assumption:noitf}, \ref{assumption:valid proxy Cov} are satisfied. Then, for $t \in \{1,\ldots,T_0\}$, the synthetic control bridge function $h^*$ satisfies 
\begin{align}
\EXP \big\{ Y_t - h^*(\bW_{ t},\bX_{0t}, \bX_{t} ) \cond Y_t, \bX_{0t}, \bX_{t} \big\} = 0 \ \text{ almost surely } \ .
\label{eq-Fredholm}
\end{align}
Moreover, for $t \in \{1,\ldots,T\}$, we have 
\begin{align*}
\EXP \big\{ \potY{t}{0} - h^*(\bW_{ t},\bX_{0t}, \bX_{t} ) \big\} = 0 \ .
\end{align*}
Lastly, the ATT at time $t  \in \{ T_0+1,\ldots,T\}$ is identified as 
\begin{align*}
\tau_t^*
=
\EXP
\big\{
Y_t - h^*(\bW_{ t}, \bX_{0t},\bX_{t} ) 
\big\} \ .
\end{align*}
\end{theorem}


Leveraging the result of the Theorem, estimation and inference of the ATT with covariate adjustment can be established, which is a straightforward extension of Section \ref{sec:Estimation}. Consider that the bridge function is linear as follows:
\begin{align*}
h^*(\bW_{ t}, \bX_{0t}, \bX_{t} )
=
\bW_{ t}\T \bgamma^*
-
\bX_{0 t} \T \bdelta_{0}^*
+
\bX_{ t} \T \bdelta^* \ .
\end{align*}
Following \ref{sec:Estimation}, we define the following estimating function:
\begin{align}			\label{eq-Moment-Cov}
&
\Psi_{\text{Cov}}( \bO_t \con \Beta, \bgamma, \bdelta_0, \bdelta, \bbeta )
\\
&
=
\begin{bmatrix}
(1-A_t)
\bD_t \big( Y_t - \bX_{0t}\T \bdelta_{0} - \bD_t\T \Beta \big)
\\
(1-A_t)
\bg (t,Y_t, \bX_{0t}, \bX_{t} \con \Beta, \bdelta_0, \bdelta)
\big\{ \big( Y_t - \bX_{0t}\T \bdelta_{0} \big)  - \big( \bW_{ t} \T \bgamma - \bX_{t}\T \bdelta  \big) \big\}
\\
A_t 
\frac{\partial \tau(t \con \bbeta) }{\partial \bbeta }  
\big\{ \big( Y_t - \bX_{0t}\T \bdelta_{0} \big)  - \big( \bW_{ t} \T \bgamma - \bX_{t}\T \bdelta  \big)  - \tau (t \con \bbeta)
\big\}
\end{bmatrix}
\in \R^{2d+p+q+b} \ ,
\nonumber
\end{align}
where $\bO_t = (Y_t,\bW_{ t}, \bX_{0t}, \bX_{t}, A_t)$ is the collection of the observed data at time $t$, $\bg(\cdot)$ is a $(d+p+q)$-dimensional user-specified function of $(t, Y_t,\bX_{0t},\bX_{ t})$, and $\tau(t \con \bbeta)$ is a user-specified treatment effect function. A example for $\bg(\cdot)$ includes:
\begin{align*}
\bg (t,y, \bx_0, \bx \con \Beta, \bdelta_0, \bdelta)
=
\begin{bmatrix}
\bD_t 
\\ \bh(y - \bx_0\T \bdelta_0 - \bD_t\T \Beta)
\\ \bx_{0t}
\\ \bx_{t}
\end{bmatrix}
\in \R^{d+p+(N+1)q} \ .
\end{align*}
We allow $\dim(\bg)$ to be smaller than $\dim(\Beta,\bgamma,\bbeta,\bdelta_0,\bdelta)$. Let $\bgamma_0^*$ be the minimum-norm solution for $\EXP \big\{ \Psi_{\text{Cov}} (\bO_t \con  \Beta^*, \bgamma, \bdelta_0^*, \bdelta^*, \bbeta^* ) \big\} = 0$.


We assume that the treatment effect function is chosen so that the associated error process is weakly dependent:
\begin{assumption}[Weakly Dependent Error in the Presence of Covariates] \label{assumption:weakdep Cov}
Let $\epsilon_t$ be $\epsilon_t = \big(
Y_t
-
\bX_{0 t} \T \bdelta_{0}^*
\big)
-
\big(
\bW_{ t}\T \bgamma_{0}^*
-
\bX_{ t} \T \bdelta^*
\big) - \tau (t \con \bbeta^*) $. Then, the error process $\big\{ \epsilon_1,\ldots,\epsilon_{T} \big\}$ satisfies Assumption \ref{assumption:weakdep}, i.e., $\text{corr}(\epsilon_{t}, \epsilon_{t+t'})$ converges to 0 as $t' \rightarrow \pm \infty$.
\end{assumption}	

We then establish the asymptotic normality of the regularized GMM estimators $(\widehat{\Beta}, \widehat{\bgamma}_{\rho}, \widehat{\bdelta}_0, \widehat{\bdelta}, \widehat{\bbeta} ) $; see the formal statement below:
\begin{theorem}	\label{thm:AN Cov}
Suppose that Assumptions \ref{assumption:consistency}, \ref{assumption:noitf}, \ref{assumption:valid proxy Cov}, and \ref{assumption:weakdep Cov} hold, $(\Beta^*,\bdelta_0^*,\bdelta^*,\bbeta^*)$ are unique, and Regularity Conditions in Section \ref{sec:supp:AN} hold. Let $( \widehat{\Beta},\widehat{\bgamma}_{\rho}, \widehat{\bdelta}_0, \widehat{\bdelta}, \widehat{\bbeta} ) $ be the regularized GMM estimators where the estimating function \eqref{eq-Moment-Cov} is used, i.e., 
\begin{align*}
\big(
\widehat{\Beta}
,
\widehat{\bgamma}_{\rho}
, 
\widehat{\bdelta}_0
,
\widehat{\bdelta} 
,
\widehat{\bbeta}
\big)
=
\argmin_{(\Beta,\bgamma,\bdelta_0,\bdelta,\bbeta)}
\Big[
\big\{ \widehat{\Psi}_{\text{Cov}}( \Beta,\bgamma, \bdelta_0, \bdelta, \bbeta) \big\} \T
\widehat{\Omega}_{\text{Cov}}
\big\{ \widehat{\Psi}_{\text{Cov}}( \Beta,\bgamma, \bdelta_0, \bdelta, \bbeta) \big\} 
+ \rho \big\| \bgamma \big\|^2
\Big]
\ ,
\end{align*}
where $	\widehat{\Psi}_{\text{Cov}}(\Beta,\bgamma, \bdelta_0, \bdelta, \bbeta)
= T^{-1}
\sum_{t=1}^{T} \Psi_{\text{Cov}} (\bO_t \con \bgamma, \bdelta_0, \bdelta, \bbeta)$ is the empirical mean of the estimating function and $\widehat{\Omega}_{\text{Cov}} = \text{diag}(I_{d \times d}, \widehat{\Omega}_{\bg}, \widehat{\Omega}_{\post})$ is a user-specified symmetric, block-diagonal positive definite matrix. Then, as $T \rightarrow \infty$, we have
\begin{align*}
\sqrt{ T }
\left\{
\begin{pmatrix}
\widehat{\Beta}
\\
\widehat{\bgamma}_{\rho}
\\
\widehat{\bdelta}_0
\\
\widehat{\bdelta} 
\\
\widehat{\bbeta}
\end{pmatrix}
-
\begin{pmatrix}
\Beta^*
\\
\bgamma_0^*
\\
\bdelta_0^*
\\
\bdelta^*
\\
\bbeta^* 
\end{pmatrix}
\right\}
\text{ converges in distribution to }
N \big( 0, \Sigma_{\text{Cov},1}^* \Sigma_{\text{Cov},2}^* \Sigma_{\text{Cov},1}\sT \big) \ ,
\end{align*}
where
\begin{align*}
&
\Sigma_{\text{Cov},1}^* 
=
\bigg[ \Omega^{*1/2}
\lim_{T \rightarrow \infty} 
\frac{\partial \EXP \big\{ \widehat{\Psi} (\Beta,\bgamma,\bdelta_0,\bdelta,\bbeta) \big\} }{ \partial (\Beta,\bgamma,\bdelta_0,\bdelta,\bbeta)\T }
\bigg|_{ \Beta=\Beta^*, \bgamma=\bgamma_0^* , \bbeta=\bbeta^* }
\bigg]^{+} 
\Omega^{*1/2}
\ , 
\\
&
\Sigma_{\text{Cov},2}^* 
=
\lim_{T \rightarrow \infty} 
\VAR \Big\{ \sqrt{T} \cdot  \widehat{\Psi} (\Beta^*,\bgamma_0^*, \bbeta^*) \Big\} \ .
\end{align*} 
Here, $\Omega^{*1/2}$ is a symmetric positive-definite matrix satisfying $\big( \Omega^{*1/2} \big)^2 = \lim_{T \rightarrow \infty} \widehat{\Omega}$.
\end{theorem}
Estimators of $\Sigma_{\text{Cov},1}^*$ and $\Sigma_{\text{Cov},2}^*$ can be similarly defined as in Section \ref{sec:Estimation}, thus we omit the details here.





\subsection{Additional Simulation Studies} \label{sec:supp:Simulation}

We restate the data generating process of the simulation studies in Section \ref{sec:Sim}. The length of pre- and post-treatment periods were given by $T_0 = T_1 \in \{ 50, 100, 250, 500 \}$ and the number of donors were given by $N = 16$. 






First, for each $t \in \{1,\ldots,T\}$, we independently generated 4-dimensional latent factors $\blambda_t = (\lambda_{1t},\cdots,\lambda_{4t})\T$ from $N(\bm{\nu}_t,0.25\cdot I_{4\times 4})$, with $\blambda_t$ being independent across time periods. For the mean vector $\bm{\nu}_t=(\nu_{1t},\cdots,\nu_{4t})\T$, we considered the following four specifications for $j \in \{1,\ldots,4\}$:
\begin{align*}
& (\textit{No trend with no intercept}): && \nu_{jt} = 0; 	\quad 
&& (\textit{No trend with intercept}): && \nu_{jt} = 1;
\\
& (\textit{Linear trend with no intercept}): &&\nu_{jt} = t/T_0;	\quad 
&& (\textit{Linear trend with intercept}): && \nu_{jt} = 1+t/T_0 \ .
\end{align*} 

The latent factor loadings $\bm{\mu}_{i}$ for $i \in \{1,\ldots,16\}$, i.e., latent factor loadings of untreated units,  were specified as follows:
\begin{align*}
\mathfrak{M}
=
\begin{bmatrix}
\bm{\mu}_1 & \cdots & \bm{\mu}_{16}
\end{bmatrix}
=
\begin{bmatrix}
2 & 1.75 & 1.5 & 1.25 & 1 & 0.75 & 0.5 & 0.25 & 0_{1 \times 8} \\
0.8 & 0.8 & 0.6 & 0.6 & 0.4 & 0.4 & 0.2 & 0.2 & 0_{1 \times 8} \\
0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 1_{1 \times 8} \\
0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 &  0.5 \cdot 1_{1 \times 8} 
\end{bmatrix}
\in \R^{4 \times 16} \ .
\end{align*}
The latent factor loading $\bm{\mu}_{0}$, i.e., latent factor loading of the treated unit, was specified from either one of the followings:
\begin{align*}
& (\textit{Simplex}): && \bm{\mu}_{0} = (1.125,0.5,0,0)\T = \sum_{i=1}^{8}  \bm{\mu}_{i}/8 ; \quad \quad \quad 
&& (\textit{Non-simplex}): && \bm{\mu}_{0} = (2,1.5,0,0)\T \ .
\end{align*}


The errors $\bm{e}_t = (e_{0t} ,  e_{1t} , \cdots,  e_{16 t})\T$ were generated independently across time periods from $\bm{e}_t \sim N \big( 0_{16 \times 1} , 0.25 \cdot \text{diag} (\Sigma_{e}, I_{8 \times 8}) \big)$ where $\Sigma_e \in \R^{9 \times 9}$ were chosen from one of the following three matrices with the corresponding $\omega_i$ values in \eqref{eq-LinearModel-System}:
\begin{align*}
&
(\textit{Independent errors}):
&&
\Sigma_{e} = I_{9 \times 9}   \ ;
\\
&
&&
\omega_0 = 1 , \ 
\omega_1=\cdots=\omega_{16}=0     \ ;
\\
&
(\textit{Correlated errors}):
&&
\Sigma_{e} = 
0.1 \cdot I_{9 \times 9} + 0.9  \cdot 1_{9 \times 9}    \ ;
\\
&
&&
\omega_0 = 1 , \ 
\omega_1=\cdots=\omega_{8}=0.9 , \
\omega_9=\cdots=\omega_{16}=0    \ ;
\\
&
(\textit{No $Y$ error}):
&&
\Sigma_{e} = \text{diag}(0,I_{8 \times 8})   \ ;
\\
&
&&
\omega_0 =\cdots=\omega_{16}=0 \ .
\end{align*} 

With these generated variables, $\potY{t}{a}$ and $W_{it}$ at $t \in \{1,\ldots,T\}$ were generated as 
\begin{align*}
\potY{t}{0} 
&
= \bm{\mu}_0\T \bm{\lambda}_t + e_{0t}
\ , \quad 
&&
&&
\potY{t}{1} 
= \potY{t}{0} + 3 A_t + \epsilon_{t} \ , 
&&
\epsilon_{t} \stackrel{iid}{\sim} N(0,0.25) \ , 
\\
W_{it} 
&
= \bm{\mu}_i\T \bm{\lambda}_t + e_{it}
\ , 
&&
i \in \{1,\ldots,N\} \ .
\end{align*} 

We review the six approaches employed for the analysis:
\begin{itemize}[leftmargin=1cm,itemsep=0cm,parsep=0cm]
\item[](\textit{OLS-NoReg}) 
OLS-based approach based on \eqref{eq-ExistSC-Abadie} with no regularization.
\item[](\textit{OLS-Standard}) 
The standard synthetic control approach proposed by \citet{Abadie2010}; we used \texttt{synth} R-package \citep{Synth2011}.
\item[] (\textit{ASC}) 
The augmented synthetic control approach proposed by \citet{ASCM2021}; we used \texttt{augsynth} \citep{ASCM2023package} R-package.
\item[] (\textit{SCPI}) 
The synthetic control prediction interval approach proposed by \citet{Cattaneo2021}; we used \texttt{scpi} \citep{scpiPackage2023} R-package. 
\item[] (\textit{SPSC-NoDT}) 
The single proxy synthetic control approach with no time-varying component; we used \texttt{SPSC} \citep{SPSC2024package} R-package.
\item[] (\textit{SPSC-DT}) 
The single proxy synthetic control approach with time-varying components \texttt{SPSC} \citep{SPSC2024package} R-package.
\end{itemize}
For the two SPSC estimators, we set $\bh(y) = y$ and, for SPSC-DT, we additionally set $\bD_t=\mathcal{B}_6(t)$, 6-dimensional cubic B-spline bases functions. 

We first estimated the ATT $\tau_t^*=3$. Figures \ref{Fig:Supp:Sim:L0}-\ref{Fig:Supp:Sim:L3} summarize the empirical distribution of the estimators graphically. Each figure is drawn in the following format:
\begin{itemize}[leftmargin=1cm,itemsep=0cm,parsep=0cm]
\item The vertical segments represent 95\% Monte Carlo confidence interval for each estimator obtained from 500 estimates.
\item The dots represent the empirical mean of 500 estimates.
\item The colors (light gray, gray, and black) and line types (solid and dashed) encode a corresponding estimator
\item The shape of the dots encode the length of the pre-treatment period, respectively. 
\item The $y$-axis represents the magnitude of bias.
\end{itemize}
We find that the results are similar to those in Figure \ref{fig:Sim:Constant} of the main paper. When $\bm{\mu}_0$ is generated from (Non-simplex) and $\blambda_t$ has non-zero mean, we find the OLS-Standard, ASC, and SCPI estimators appear to have significant magnitudes of biases even under a large sample size.  


\newpage

% Figure environment removed

% Figure environment removed

\newpage

% Figure environment removed

% Figure environment removed

\newpage

In Tables \ref{Tab:Supp:Sim:T0} and \ref{Tab:Supp:Sim:T1}, we first present numerical summaries of the simulation studies considered in the main paper. Each table is written in the following format:
\begin{itemize}[leftmargin=1cm,itemsep=0cm,parsep=0cm]
\item Bias row shows the empirical bias of 500 estimates;
\item ASE row shows the asymptotic standard error obtained from the sandwich variance estimator;
\item BSE row shows the bootstrap standard error obtained from the approach in Section \ref{sec:supp:BB} of the Supplementary Material;
\item ESE row shows the standard deviation of 500 estimates;
\item MSE row shows the mean squared error of 500 estimates;
\item Cover (ASE) and Cover (BSE) show the empirical coverage rates of 95\% confidence intervals based on the asymptotic and bootstrap standard errors, respectively;
\item Bias, standard errors, and mean squared error are scaled by factors of 10, 10, and 100, respectively, for readability.	
\end{itemize}
We remark that the results in Tables \ref{Tab:Supp:Sim:T0}-\ref{Tab:Supp:Sim:T3} are similar to those in Table \ref{tab:Sim:ATT} of the main text. In particular, when $\bm{\mu}_0$ is generated from (Non-simplex) and $\blambda_t$ has a non-zero mean, we find the OLS-Standard, ASC, and SCPI estimators yield significant magnitudes of biases even under a large sample size. Moreover, these biases are not negligible compared to the magnitude of the empirical standard errors. Consequently, we can deduce that the failure of the ASC and SCPI approaches to attain the nominal coverage rate can be attributed to the non-diminishing bias.

\newpage

\begin{table}[!htp]
\renewcommand{\arraystretch}{1.3} \centering
\scriptsize
\setlength{\tabcolsep}{1pt}  


\begin{tabular}{|c|c|c|c|cccccccccccc|}
\hline
\multirow{3}{*}{$\bm{\lambda}_t$}                                                                   & \multirow{3}{*}{$\bm{\mu}_0$} & \multirow{3}{*}{$\bm{e}_t$}                                                    & \multirow{3}{*}{Statistics} & \multicolumn{12}{c|}{Estimators and $T_0$}                                                                                                                                                                                                                                                                                                       \\ \cline{5-16}

&                                &                                                                                &                             & \multicolumn{2}{c|}{OLS-NoReg}                            & \multicolumn{2}{c|}{OLS-Standard}                         & \multicolumn{2}{c|}{ASC}                                  & \multicolumn{2}{c|}{SCPI}                                 & \multicolumn{2}{c|}{SPSC-NoDT}                            & \multicolumn{2}{c|}{SPSC-DT}         \\ \cline{5-16} 
&                                &                                                                                &                             & \multicolumn{1}{c|}{100}    & \multicolumn{1}{c|}{500}    & \multicolumn{1}{c|}{100}    & \multicolumn{1}{c|}{500}    & \multicolumn{1}{c|}{100}    & \multicolumn{1}{c|}{500}    & \multicolumn{1}{c|}{100}    & \multicolumn{1}{c|}{500}    & \multicolumn{1}{c|}{100}    & \multicolumn{1}{c|}{500}    & \multicolumn{1}{c|}{100}    & 500    \\ \hline



\multirow{42}{*}{\begin{tabular}[c]{@{}c@{}}No\\ trend \\ with \\ no \\ intercept\end{tabular}} & \multirow{21}{*}{Simplex}      & \multirow{7}{*}{\begin{tabular}[c]{@{}c@{}}Independent \\ errors\end{tabular}} & Bias $(\times 10)$          & \multicolumn{1}{c|}{0.015}  & \multicolumn{1}{c|}{0.021}  & \multicolumn{1}{c|}{-0.008} & \multicolumn{1}{c|}{0.033}  & \multicolumn{1}{c|}{0.009}  & \multicolumn{1}{c|}{0.023}  & \multicolumn{1}{c|}{0.008}  & \multicolumn{1}{c|}{0.023}  & \multicolumn{1}{c|}{0.007}  & \multicolumn{1}{c|}{0.022}  & \multicolumn{1}{c|}{0.006}  & 0.022  \\ \cline{4-16} 
&                                &                                                                                & ASE $(\times 10)$           & \multicolumn{1}{c|}{0.779}  & \multicolumn{1}{c|}{0.329}  & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{0.727}  & \multicolumn{1}{c|}{0.325}  & \multicolumn{1}{c|}{0.728}  & 0.325  \\ \cline{4-16} 
&                                &                                                                                & BSE $(\times 10)$           & \multicolumn{1}{c|}{0.838}  & \multicolumn{1}{c|}{0.338}  & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{0.728}  & \multicolumn{1}{c|}{0.325}  & \multicolumn{1}{c|}{0.730}  & 0.324  \\ \cline{4-16} 
&                                &                                                                                & ESE $(\times 10)$           & \multicolumn{1}{c|}{0.730}  & \multicolumn{1}{c|}{0.319}  & \multicolumn{1}{c|}{0.836}  & \multicolumn{1}{c|}{0.377}  & \multicolumn{1}{c|}{0.722}  & \multicolumn{1}{c|}{0.319}  & \multicolumn{1}{c|}{0.722}  & \multicolumn{1}{c|}{0.318}  & \multicolumn{1}{c|}{0.716}  & \multicolumn{1}{c|}{0.316}  & \multicolumn{1}{c|}{0.714}  & 0.316  \\ \cline{4-16} 
&                                &                                                                                & MSE $(\times 100)$          & \multicolumn{1}{c|}{0.532}  & \multicolumn{1}{c|}{0.102}  & \multicolumn{1}{c|}{0.697}  & \multicolumn{1}{c|}{0.143}  & \multicolumn{1}{c|}{0.520}  & \multicolumn{1}{c|}{0.102}  & \multicolumn{1}{c|}{0.520}  & \multicolumn{1}{c|}{0.102}  & \multicolumn{1}{c|}{0.512}  & \multicolumn{1}{c|}{0.100}  & \multicolumn{1}{c|}{0.509}  & 0.100  \\ \cline{4-16} 
&                                &                                                                                & Coverage (ASE)              & \multicolumn{1}{c|}{0.954}  & \multicolumn{1}{c|}{0.952}  & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{0.950}  & \multicolumn{1}{c|}{0.954}  & \multicolumn{1}{c|}{0.948}  & 0.954  \\ \cline{4-16} 
&                                &                                                                                & Coverage (BSE)              & \multicolumn{1}{c|}{0.966}  & \multicolumn{1}{c|}{0.954}  & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{0.946}  & \multicolumn{1}{c|}{0.950}  & \multicolumn{1}{c|}{0.946}  & 0.948  \\ \cline{3-16} 
&                                & \multirow{7}{*}{\begin{tabular}[c]{@{}c@{}}Correlated \\ errors\end{tabular}}  & Bias $(\times 10)$          & \multicolumn{1}{c|}{0.010}  & \multicolumn{1}{c|}{0.006}  & \multicolumn{1}{c|}{-0.018} & \multicolumn{1}{c|}{0.022}  & \multicolumn{1}{c|}{0.010}  & \multicolumn{1}{c|}{0.006}  & \multicolumn{1}{c|}{0.009}  & \multicolumn{1}{c|}{0.006}  & \multicolumn{1}{c|}{0.014}  & \multicolumn{1}{c|}{0.004}  & \multicolumn{1}{c|}{0.015}  & 0.004  \\ \cline{4-16} 
&                                &                                                                                & ASE $(\times 10)$           & \multicolumn{1}{c|}{0.534}  & \multicolumn{1}{c|}{0.237}  & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{0.533}  & \multicolumn{1}{c|}{0.238}  & \multicolumn{1}{c|}{0.533}  & 0.238  \\ \cline{4-16} 
&                                &                                                                                & BSE $(\times 10)$           & \multicolumn{1}{c|}{0.551}  & \multicolumn{1}{c|}{0.241}  & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{0.529}  & \multicolumn{1}{c|}{0.237}  & \multicolumn{1}{c|}{0.529}  & 0.237  \\ \cline{4-16} 
&                                &                                                                                & ESE $(\times 10)$           & \multicolumn{1}{c|}{0.568}  & \multicolumn{1}{c|}{0.242}  & \multicolumn{1}{c|}{0.688}  & \multicolumn{1}{c|}{0.298}  & \multicolumn{1}{c|}{0.565}  & \multicolumn{1}{c|}{0.243}  & \multicolumn{1}{c|}{0.565}  & \multicolumn{1}{c|}{0.243}  & \multicolumn{1}{c|}{0.565}  & \multicolumn{1}{c|}{0.243}  & \multicolumn{1}{c|}{0.564}  & 0.243  \\ \cline{4-16} 
&                                &                                                                                & MSE $(\times 100)$          & \multicolumn{1}{c|}{0.322}  & \multicolumn{1}{c|}{0.059}  & \multicolumn{1}{c|}{0.473}  & \multicolumn{1}{c|}{0.089}  & \multicolumn{1}{c|}{0.319}  & \multicolumn{1}{c|}{0.059}  & \multicolumn{1}{c|}{0.319}  & \multicolumn{1}{c|}{0.059}  & \multicolumn{1}{c|}{0.318}  & \multicolumn{1}{c|}{0.059}  & \multicolumn{1}{c|}{0.318}  & 0.059  \\ \cline{4-16} 
&                                &                                                                                & Coverage (ASE)              & \multicolumn{1}{c|}{0.940}  & \multicolumn{1}{c|}{0.944}  & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{0.934}  & \multicolumn{1}{c|}{0.954}  & \multicolumn{1}{c|}{0.936}  & 0.954  \\ \cline{4-16} 
&                                &                                                                                & Coverage (BSE)              & \multicolumn{1}{c|}{0.940}  & \multicolumn{1}{c|}{0.952}  & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{0.922}  & \multicolumn{1}{c|}{0.946}  & \multicolumn{1}{c|}{0.936}  & 0.946  \\ \cline{3-16} 
&                                & \multirow{7}{*}{\begin{tabular}[c]{@{}c@{}}No \\ $Y$ error\end{tabular}}       & Bias $(\times 10)$          & \multicolumn{1}{c|}{-0.016} & \multicolumn{1}{c|}{0.012}  & \multicolumn{1}{c|}{-0.008} & \multicolumn{1}{c|}{0.007}  & \multicolumn{1}{c|}{-0.021} & \multicolumn{1}{c|}{0.011}  & \multicolumn{1}{c|}{-0.021} & \multicolumn{1}{c|}{0.011}  & \multicolumn{1}{c|}{-0.020} & \multicolumn{1}{c|}{0.011}  & \multicolumn{1}{c|}{-0.020} & 0.011  \\ \cline{4-16} 
&                                &                                                                                & ASE $(\times 10)$           & \multicolumn{1}{c|}{0.527}  & \multicolumn{1}{c|}{0.234}  & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{0.525}  & \multicolumn{1}{c|}{0.234}  & \multicolumn{1}{c|}{0.525}  & 0.234  \\ \cline{4-16} 
&                                &                                                                                & BSE $(\times 10)$           & \multicolumn{1}{c|}{0.542}  & \multicolumn{1}{c|}{0.238}  & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{0.523}  & \multicolumn{1}{c|}{0.233}  & \multicolumn{1}{c|}{0.522}  & 0.233  \\ \cline{4-16} 
&                                &                                                                                & ESE $(\times 10)$           & \multicolumn{1}{c|}{0.541}  & \multicolumn{1}{c|}{0.231}  & \multicolumn{1}{c|}{0.626}  & \multicolumn{1}{c|}{0.275}  & \multicolumn{1}{c|}{0.539}  & \multicolumn{1}{c|}{0.229}  & \multicolumn{1}{c|}{0.539}  & \multicolumn{1}{c|}{0.229}  & \multicolumn{1}{c|}{0.536}  & \multicolumn{1}{c|}{0.231}  & \multicolumn{1}{c|}{0.536}  & 0.231  \\ \cline{4-16} 
&                                &                                                                                & MSE $(\times 100)$          & \multicolumn{1}{c|}{0.292}  & \multicolumn{1}{c|}{0.053}  & \multicolumn{1}{c|}{0.391}  & \multicolumn{1}{c|}{0.076}  & \multicolumn{1}{c|}{0.290}  & \multicolumn{1}{c|}{0.052}  & \multicolumn{1}{c|}{0.290}  & \multicolumn{1}{c|}{0.052}  & \multicolumn{1}{c|}{0.287}  & \multicolumn{1}{c|}{0.053}  & \multicolumn{1}{c|}{0.287}  & 0.053  \\ \cline{4-16} 
&                                &                                                                                & Coverage (ASE)              & \multicolumn{1}{c|}{0.944}  & \multicolumn{1}{c|}{0.954}  & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{0.948}  & \multicolumn{1}{c|}{0.954}  & \multicolumn{1}{c|}{0.948}  & 0.952  \\ \cline{4-16} 
&                                &                                                                                & Coverage (BSE)              & \multicolumn{1}{c|}{0.946}  & \multicolumn{1}{c|}{0.956}  & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{0.946}  & \multicolumn{1}{c|}{0.948}  & \multicolumn{1}{c|}{0.948}  & 0.950  \\ \cline{2-16} 
& \multirow{21}{*}{Non-simplex}  & \multirow{7}{*}{\begin{tabular}[c]{@{}c@{}}Independent \\ errors\end{tabular}} & Bias $(\times 10)$          & \multicolumn{1}{c|}{0.022}  & \multicolumn{1}{c|}{-0.009} & \multicolumn{1}{c|}{0.042}  & \multicolumn{1}{c|}{0.000}  & \multicolumn{1}{c|}{0.028}  & \multicolumn{1}{c|}{-0.010} & \multicolumn{1}{c|}{0.032}  & \multicolumn{1}{c|}{-0.011} & \multicolumn{1}{c|}{0.031}  & \multicolumn{1}{c|}{-0.009} & \multicolumn{1}{c|}{0.027}  & -0.008 \\ \cline{4-16} 
&                                &                                                                                & ASE $(\times 10)$           & \multicolumn{1}{c|}{0.895}  & \multicolumn{1}{c|}{0.373}  & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{0.837}  & \multicolumn{1}{c|}{0.373}  & \multicolumn{1}{c|}{0.837}  & 0.372  \\ \cline{4-16} 
&                                &                                                                                & BSE $(\times 10)$           & \multicolumn{1}{c|}{0.970}  & \multicolumn{1}{c|}{0.383}  & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{0.845}  & \multicolumn{1}{c|}{0.374}  & \multicolumn{1}{c|}{0.839}  & 0.372  \\ \cline{4-16} 
&                                &                                                                                & ESE $(\times 10)$           & \multicolumn{1}{c|}{0.920}  & \multicolumn{1}{c|}{0.373}  & \multicolumn{1}{c|}{1.248}  & \multicolumn{1}{c|}{0.506}  & \multicolumn{1}{c|}{0.905}  & \multicolumn{1}{c|}{0.387}  & \multicolumn{1}{c|}{0.918}  & \multicolumn{1}{c|}{0.392}  & \multicolumn{1}{c|}{0.888}  & \multicolumn{1}{c|}{0.371}  & \multicolumn{1}{c|}{0.889}  & 0.371  \\ \cline{4-16} 
&                                &                                                                                & MSE $(\times 100)$          & \multicolumn{1}{c|}{0.845}  & \multicolumn{1}{c|}{0.139}  & \multicolumn{1}{c|}{1.556}  & \multicolumn{1}{c|}{0.256}  & \multicolumn{1}{c|}{0.817}  & \multicolumn{1}{c|}{0.150}  & \multicolumn{1}{c|}{0.841}  & \multicolumn{1}{c|}{0.154}  & \multicolumn{1}{c|}{0.788}  & \multicolumn{1}{c|}{0.137}  & \multicolumn{1}{c|}{0.789}  & 0.138  \\ \cline{4-16} 
&                                &                                                                                & Coverage (ASE)              & \multicolumn{1}{c|}{0.950}  & \multicolumn{1}{c|}{0.958}  & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{0.932}  & \multicolumn{1}{c|}{0.956}  & \multicolumn{1}{c|}{0.934}  & 0.956  \\ \cline{4-16} 
&                                &                                                                                & Coverage (BSE)              & \multicolumn{1}{c|}{0.962}  & \multicolumn{1}{c|}{0.962}  & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{0.934}  & \multicolumn{1}{c|}{0.958}  & \multicolumn{1}{c|}{0.930}  & 0.960  \\ \cline{3-16} 
&                                & \multirow{7}{*}{\begin{tabular}[c]{@{}c@{}}Correlated\\ errors\end{tabular}}   & Bias $(\times 10)$          & \multicolumn{1}{c|}{-0.046} & \multicolumn{1}{c|}{-0.023} & \multicolumn{1}{c|}{0.022}  & \multicolumn{1}{c|}{-0.024} & \multicolumn{1}{c|}{-0.037} & \multicolumn{1}{c|}{-0.025} & \multicolumn{1}{c|}{-0.031} & \multicolumn{1}{c|}{-0.028} & \multicolumn{1}{c|}{-0.028} & \multicolumn{1}{c|}{-0.017} & \multicolumn{1}{c|}{-0.026} & -0.019 \\ \cline{4-16} 
&                                &                                                                                & ASE $(\times 10)$           & \multicolumn{1}{c|}{0.630}  & \multicolumn{1}{c|}{0.274}  & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{0.660}  & \multicolumn{1}{c|}{0.295}  & \multicolumn{1}{c|}{0.667}  & 0.297  \\ \cline{4-16} 
&                                &                                                                                & BSE $(\times 10)$           & \multicolumn{1}{c|}{0.668}  & \multicolumn{1}{c|}{0.280}  & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{0.665}  & \multicolumn{1}{c|}{0.295}  & \multicolumn{1}{c|}{0.679}  & 0.300  \\ \cline{4-16} 
&                                &                                                                                & ESE $(\times 10)$           & \multicolumn{1}{c|}{0.619}  & \multicolumn{1}{c|}{0.278}  & \multicolumn{1}{c|}{1.049}  & \multicolumn{1}{c|}{0.497}  & \multicolumn{1}{c|}{0.630}  & \multicolumn{1}{c|}{0.277}  & \multicolumn{1}{c|}{0.644}  & \multicolumn{1}{c|}{0.284}  & \multicolumn{1}{c|}{0.670}  & \multicolumn{1}{c|}{0.293}  & \multicolumn{1}{c|}{0.666}  & 0.296  \\ \cline{4-16} 
&                                &                                                                                & MSE $(\times 100)$          & \multicolumn{1}{c|}{0.385}  & \multicolumn{1}{c|}{0.077}  & \multicolumn{1}{c|}{1.098}  & \multicolumn{1}{c|}{0.247}  & \multicolumn{1}{c|}{0.398}  & \multicolumn{1}{c|}{0.077}  & \multicolumn{1}{c|}{0.415}  & \multicolumn{1}{c|}{0.081}  & \multicolumn{1}{c|}{0.449}  & \multicolumn{1}{c|}{0.086}  & \multicolumn{1}{c|}{0.443}  & 0.088  \\ \cline{4-16} 
&                                &                                                                                & Coverage (ASE)              & \multicolumn{1}{c|}{0.948}  & \multicolumn{1}{c|}{0.942}  & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{0.938}  & \multicolumn{1}{c|}{0.944}  & \multicolumn{1}{c|}{0.936}  & 0.940  \\ \cline{4-16} 
&                                &                                                                                & Coverage (BSE)              & \multicolumn{1}{c|}{0.960}  & \multicolumn{1}{c|}{0.948}  & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{0.940}  & \multicolumn{1}{c|}{0.948}  & \multicolumn{1}{c|}{0.936}  & 0.946  \\ \cline{3-16} 
&                                & \multirow{7}{*}{\begin{tabular}[c]{@{}c@{}}No\\ $Y$ error\end{tabular}}        & Bias $(\times 10)$          & \multicolumn{1}{c|}{-0.017} & \multicolumn{1}{c|}{0.019}  & \multicolumn{1}{c|}{-0.038} & \multicolumn{1}{c|}{0.003}  & \multicolumn{1}{c|}{-0.009} & \multicolumn{1}{c|}{0.016}  & \multicolumn{1}{c|}{-0.009} & \multicolumn{1}{c|}{0.015}  & \multicolumn{1}{c|}{-0.009} & \multicolumn{1}{c|}{0.018}  & \multicolumn{1}{c|}{-0.011} & 0.017  \\ \cline{4-16} 
&                                &                                                                                & ASE $(\times 10)$           & \multicolumn{1}{c|}{0.693}  & \multicolumn{1}{c|}{0.293}  & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{0.665}  & \multicolumn{1}{c|}{0.293}  & \multicolumn{1}{c|}{0.665}  & 0.293  \\ \cline{4-16} 
&                                &                                                                                & BSE $(\times 10)$           & \multicolumn{1}{c|}{0.737}  & \multicolumn{1}{c|}{0.301}  & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{0.673}  & \multicolumn{1}{c|}{0.292}  & \multicolumn{1}{c|}{0.670}  & 0.292  \\ \cline{4-16} 
&                                &                                                                                & ESE $(\times 10)$           & \multicolumn{1}{c|}{0.712}  & \multicolumn{1}{c|}{0.290}  & \multicolumn{1}{c|}{1.023}  & \multicolumn{1}{c|}{0.437}  & \multicolumn{1}{c|}{0.717}  & \multicolumn{1}{c|}{0.303}  & \multicolumn{1}{c|}{0.730}  & \multicolumn{1}{c|}{0.311}  & \multicolumn{1}{c|}{0.695}  & \multicolumn{1}{c|}{0.291}  & \multicolumn{1}{c|}{0.699}  & 0.291  \\ \cline{4-16} 
&                                &                                                                                & MSE $(\times 100)$          & \multicolumn{1}{c|}{0.506}  & \multicolumn{1}{c|}{0.084}  & \multicolumn{1}{c|}{1.045}  & \multicolumn{1}{c|}{0.191}  & \multicolumn{1}{c|}{0.513}  & \multicolumn{1}{c|}{0.092}  & \multicolumn{1}{c|}{0.532}  & \multicolumn{1}{c|}{0.097}  & \multicolumn{1}{c|}{0.482}  & \multicolumn{1}{c|}{0.085}  & \multicolumn{1}{c|}{0.488}  & 0.085  \\ \cline{4-16} 
&                                &                                                                                & Coverage (ASE)              & \multicolumn{1}{c|}{0.936}  & \multicolumn{1}{c|}{0.954}  & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{0.936}  & \multicolumn{1}{c|}{0.946}  & \multicolumn{1}{c|}{0.932}  & 0.948  \\ \cline{4-16} 
&                                &                                                                                & Coverage (BSE)              & \multicolumn{1}{c|}{0.952}  & \multicolumn{1}{c|}{0.958}  & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{0.936}  & \multicolumn{1}{c|}{0.948}  & \multicolumn{1}{c|}{0.930}  & 0.948  \\ \hline
\end{tabular}


\caption{Summary Statistics of the Estimation Results Under (No trend with no intercept) for $\blambda_t$.} 
\label{Tab:Supp:Sim:T0}

\end{table}


\newpage 


\begin{table}[!htp]
\renewcommand{\arraystretch}{1.3} \centering
\scriptsize
\setlength{\tabcolsep}{1pt}  


\begin{tabular}{|c|c|c|c|cccccccccccc|}
\hline
\multirow{3}{*}{$\bm{\lambda}_t$}                                                                   & \multirow{3}{*}{$\bm{\mu}_0$} & \multirow{3}{*}{$\bm{e}_t$}                                                    & \multirow{3}{*}{Statistics} & \multicolumn{12}{c|}{Estimators and $T_0$}                                                                                                                                                                                                                                                                                                       \\ \cline{5-16}

&                                &                                                                                &                             & \multicolumn{2}{c|}{OLS-NoReg}                            & \multicolumn{2}{c|}{OLS-Standard}                         & \multicolumn{2}{c|}{ASC}                                  & \multicolumn{2}{c|}{SCPI}                                 & \multicolumn{2}{c|}{SPSC-NoDT}                            & \multicolumn{2}{c|}{SPSC-DT}         \\ \cline{5-16} 
&                                &                                                                                &                             & \multicolumn{1}{c|}{100}    & \multicolumn{1}{c|}{500}    & \multicolumn{1}{c|}{100}    & \multicolumn{1}{c|}{500}    & \multicolumn{1}{c|}{100}    & \multicolumn{1}{c|}{500}    & \multicolumn{1}{c|}{100}    & \multicolumn{1}{c|}{500}    & \multicolumn{1}{c|}{100}    & \multicolumn{1}{c|}{500}    & \multicolumn{1}{c|}{100}    & 500    \\ \hline


\multirow{42}{*}{\begin{tabular}[c]{@{}c@{}}No\\ trend \\ with \\ intercept\end{tabular}} & \multirow{21}{*}{Simplex}      & \multirow{7}{*}{\begin{tabular}[c]{@{}c@{}}Independent \\ errors\end{tabular}} & Bias $(\times 10)$          & \multicolumn{1}{c|}{0.075}  & \multicolumn{1}{c|}{0.073}  & \multicolumn{1}{c|}{0.026}  & \multicolumn{1}{c|}{0.001}  & \multicolumn{1}{c|}{-0.141} & \multicolumn{1}{c|}{-0.107} & \multicolumn{1}{c|}{-0.142} & \multicolumn{1}{c|}{-0.107} & \multicolumn{1}{c|}{-0.683} & \multicolumn{1}{c|}{-0.925} & \multicolumn{1}{c|}{0.008}  & 0.005  \\ \cline{4-16} 
&                                &                                                                                & ASE $(\times 10)$           & \multicolumn{1}{c|}{0.916}  & \multicolumn{1}{c|}{0.399}  & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{0.924}  & \multicolumn{1}{c|}{0.418}  & \multicolumn{1}{c|}{0.886}  & 0.399  \\ \cline{4-16} 
&                                &                                                                                & BSE $(\times 10)$           & \multicolumn{1}{c|}{1.002}  & \multicolumn{1}{c|}{0.411}  & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{0.982}  & \multicolumn{1}{c|}{0.443}  & \multicolumn{1}{c|}{0.898}  & 0.400  \\ \cline{4-16} 
&                                &                                                                                & ESE $(\times 10)$           & \multicolumn{1}{c|}{0.930}  & \multicolumn{1}{c|}{0.390}  & \multicolumn{1}{c|}{1.022}  & \multicolumn{1}{c|}{0.467}  & \multicolumn{1}{c|}{0.909}  & \multicolumn{1}{c|}{0.387}  & \multicolumn{1}{c|}{0.907}  & \multicolumn{1}{c|}{0.388}  & \multicolumn{1}{c|}{1.115}  & \multicolumn{1}{c|}{0.466}  & \multicolumn{1}{c|}{0.921}  & 0.390  \\ \cline{4-16} 
&                                &                                                                                & MSE $(\times 100)$          & \multicolumn{1}{c|}{0.868}  & \multicolumn{1}{c|}{0.157}  & \multicolumn{1}{c|}{1.042}  & \multicolumn{1}{c|}{0.217}  & \multicolumn{1}{c|}{0.844}  & \multicolumn{1}{c|}{0.161}  & \multicolumn{1}{c|}{0.841}  & \multicolumn{1}{c|}{0.162}  & \multicolumn{1}{c|}{1.708}  & \multicolumn{1}{c|}{1.072}  & \multicolumn{1}{c|}{0.847}  & 0.152  \\ \cline{4-16} 
&                                &                                                                                & Coverage (ASE)              & \multicolumn{1}{c|}{0.944}  & \multicolumn{1}{c|}{0.940}  & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{0.842}  & \multicolumn{1}{c|}{0.400}  & \multicolumn{1}{c|}{0.938}  & 0.956  \\ \cline{4-16} 
&                                &                                                                                & Coverage (BSE)              & \multicolumn{1}{c|}{0.960}  & \multicolumn{1}{c|}{0.954}  & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{0.854}  & \multicolumn{1}{c|}{0.436}  & \multicolumn{1}{c|}{0.948}  & 0.960  \\ \cline{3-16} 
&                                & \multirow{7}{*}{\begin{tabular}[c]{@{}c@{}}Correlated \\ errors\end{tabular}}  & Bias $(\times 10)$          & \multicolumn{1}{c|}{-0.010} & \multicolumn{1}{c|}{-0.012} & \multicolumn{1}{c|}{0.016}  & \multicolumn{1}{c|}{0.003}  & \multicolumn{1}{c|}{-0.034} & \multicolumn{1}{c|}{-0.027} & \multicolumn{1}{c|}{-0.035} & \multicolumn{1}{c|}{-0.027} & \multicolumn{1}{c|}{-0.399} & \multicolumn{1}{c|}{-0.335} & \multicolumn{1}{c|}{-0.026} & -0.022 \\ \cline{4-16} 
&                                &                                                                                & ASE $(\times 10)$           & \multicolumn{1}{c|}{0.554}  & \multicolumn{1}{c|}{0.248}  & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{0.742}  & \multicolumn{1}{c|}{0.334}  & \multicolumn{1}{c|}{0.556}  & 0.251  \\ \cline{4-16} 
&                                &                                                                                & BSE $(\times 10)$           & \multicolumn{1}{c|}{0.577}  & \multicolumn{1}{c|}{0.252}  & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{0.763}  & \multicolumn{1}{c|}{0.345}  & \multicolumn{1}{c|}{0.554}  & 0.251  \\ \cline{4-16} 
&                                &                                                                                & ESE $(\times 10)$           & \multicolumn{1}{c|}{0.557}  & \multicolumn{1}{c|}{0.237}  & \multicolumn{1}{c|}{0.795}  & \multicolumn{1}{c|}{0.358}  & \multicolumn{1}{c|}{0.552}  & \multicolumn{1}{c|}{0.237}  & \multicolumn{1}{c|}{0.552}  & \multicolumn{1}{c|}{0.237}  & \multicolumn{1}{c|}{0.783}  & \multicolumn{1}{c|}{0.328}  & \multicolumn{1}{c|}{0.558}  & 0.240  \\ \cline{4-16} 
&                                &                                                                                & MSE $(\times 100)$          & \multicolumn{1}{c|}{0.310}  & \multicolumn{1}{c|}{0.056}  & \multicolumn{1}{c|}{0.631}  & \multicolumn{1}{c|}{0.128}  & \multicolumn{1}{c|}{0.306}  & \multicolumn{1}{c|}{0.057}  & \multicolumn{1}{c|}{0.305}  & \multicolumn{1}{c|}{0.057}  & \multicolumn{1}{c|}{0.772}  & \multicolumn{1}{c|}{0.220}  & \multicolumn{1}{c|}{0.311}  & 0.058  \\ \cline{4-16} 
&                                &                                                                                & Coverage (ASE)              & \multicolumn{1}{c|}{0.950}  & \multicolumn{1}{c|}{0.950}  & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{0.902}  & \multicolumn{1}{c|}{0.824}  & \multicolumn{1}{c|}{0.954}  & 0.944  \\ \cline{4-16} 
&                                &                                                                                & Coverage (BSE)              & \multicolumn{1}{c|}{0.958}  & \multicolumn{1}{c|}{0.954}  & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{0.898}  & \multicolumn{1}{c|}{0.842}  & \multicolumn{1}{c|}{0.950}  & 0.950  \\ \cline{3-16} 
&                                & \multirow{7}{*}{\begin{tabular}[c]{@{}c@{}}No \\ $Y$ error\end{tabular}}       & Bias $(\times 10)$          & \multicolumn{1}{c|}{0.113}  & \multicolumn{1}{c|}{0.079}  & \multicolumn{1}{c|}{0.098}  & \multicolumn{1}{c|}{0.004}  & \multicolumn{1}{c|}{-0.063} & \multicolumn{1}{c|}{-0.087} & \multicolumn{1}{c|}{-0.064} & \multicolumn{1}{c|}{-0.087} & \multicolumn{1}{c|}{-0.247} & \multicolumn{1}{c|}{-0.401} & \multicolumn{1}{c|}{0.042}  & 0.008  \\ \cline{4-16} 
&                                &                                                                                & ASE $(\times 10)$           & \multicolumn{1}{c|}{0.544}  & \multicolumn{1}{c|}{0.244}  & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{0.679}  & \multicolumn{1}{c|}{0.305}  & \multicolumn{1}{c|}{0.544}  & 0.244  \\ \cline{4-16} 
&                                &                                                                                & BSE $(\times 10)$           & \multicolumn{1}{c|}{0.566}  & \multicolumn{1}{c|}{0.248}  & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{0.678}  & \multicolumn{1}{c|}{0.305}  & \multicolumn{1}{c|}{0.542}  & 0.244  \\ \cline{4-16} 
&                                &                                                                                & ESE $(\times 10)$           & \multicolumn{1}{c|}{0.543}  & \multicolumn{1}{c|}{0.249}  & \multicolumn{1}{c|}{0.732}  & \multicolumn{1}{c|}{0.344}  & \multicolumn{1}{c|}{0.547}  & \multicolumn{1}{c|}{0.254}  & \multicolumn{1}{c|}{0.547}  & \multicolumn{1}{c|}{0.254}  & \multicolumn{1}{c|}{0.705}  & \multicolumn{1}{c|}{0.314}  & \multicolumn{1}{c|}{0.539}  & 0.249  \\ \cline{4-16} 
&                                &                                                                                & MSE $(\times 100)$          & \multicolumn{1}{c|}{0.307}  & \multicolumn{1}{c|}{0.068}  & \multicolumn{1}{c|}{0.545}  & \multicolumn{1}{c|}{0.118}  & \multicolumn{1}{c|}{0.302}  & \multicolumn{1}{c|}{0.072}  & \multicolumn{1}{c|}{0.302}  & \multicolumn{1}{c|}{0.072}  & \multicolumn{1}{c|}{0.557}  & \multicolumn{1}{c|}{0.259}  & \multicolumn{1}{c|}{0.292}  & 0.062  \\ \cline{4-16} 
&                                &                                                                                & Coverage (ASE)              & \multicolumn{1}{c|}{0.942}  & \multicolumn{1}{c|}{0.944}  & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{0.932}  & \multicolumn{1}{c|}{0.732}  & \multicolumn{1}{c|}{0.954}  & 0.956  \\ \cline{4-16} 
&                                &                                                                                & Coverage (BSE)              & \multicolumn{1}{c|}{0.950}  & \multicolumn{1}{c|}{0.948}  & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{0.928}  & \multicolumn{1}{c|}{0.736}  & \multicolumn{1}{c|}{0.952}  & 0.958  \\ \cline{2-16} 
& \multirow{21}{*}{Non-simplex}  & \multirow{7}{*}{\begin{tabular}[c]{@{}c@{}}Independent \\ errors\end{tabular}} & Bias $(\times 10)$          & \multicolumn{1}{c|}{0.381}  & \multicolumn{1}{c|}{0.351}  & \multicolumn{1}{c|}{7.010}  & \multicolumn{1}{c|}{6.987}  & \multicolumn{1}{c|}{2.540}  & \multicolumn{1}{c|}{1.375}  & \multicolumn{1}{c|}{7.358}  & \multicolumn{1}{c|}{7.308}  & \multicolumn{1}{c|}{-0.267} & \multicolumn{1}{c|}{-0.344} & \multicolumn{1}{c|}{0.036}  & 0.004  \\ \cline{4-16} 
&                                &                                                                                & ASE $(\times 10)$           & \multicolumn{1}{c|}{1.104}  & \multicolumn{1}{c|}{0.474}  & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{1.282}  & \multicolumn{1}{c|}{0.575}  & \multicolumn{1}{c|}{1.058}  & 0.476  \\ \cline{4-16} 
&                                &                                                                                & BSE $(\times 10)$           & \multicolumn{1}{c|}{1.223}  & \multicolumn{1}{c|}{0.489}  & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{1.321}  & \multicolumn{1}{c|}{0.596}  & \multicolumn{1}{c|}{1.086}  & 0.483  \\ \cline{4-16} 
&                                &                                                                                & ESE $(\times 10)$           & \multicolumn{1}{c|}{1.141}  & \multicolumn{1}{c|}{0.474}  & \multicolumn{1}{c|}{0.939}  & \multicolumn{1}{c|}{0.438}  & \multicolumn{1}{c|}{1.357}  & \multicolumn{1}{c|}{0.564}  & \multicolumn{1}{c|}{0.935}  & \multicolumn{1}{c|}{0.448}  & \multicolumn{1}{c|}{1.302}  & \multicolumn{1}{c|}{0.571}  & \multicolumn{1}{c|}{1.090}  & 0.485  \\ \cline{4-16} 
&                                &                                                                                & MSE $(\times 100)$          & \multicolumn{1}{c|}{1.444}  & \multicolumn{1}{c|}{0.347}  & \multicolumn{1}{c|}{50.020} & \multicolumn{1}{c|}{49.005} & \multicolumn{1}{c|}{8.289}  & \multicolumn{1}{c|}{2.208}  & \multicolumn{1}{c|}{55.011} & \multicolumn{1}{c|}{53.601} & \multicolumn{1}{c|}{1.762}  & \multicolumn{1}{c|}{0.443}  & \multicolumn{1}{c|}{1.187}  & 0.235  \\ \cline{4-16} 
&                                &                                                                                & Coverage (ASE)              & \multicolumn{1}{c|}{0.920}  & \multicolumn{1}{c|}{0.884}  & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{0.950}  & \multicolumn{1}{c|}{0.914}  & \multicolumn{1}{c|}{0.942}  & 0.930  \\ \cline{4-16} 
&                                &                                                                                & Coverage (BSE)              & \multicolumn{1}{c|}{0.948}  & \multicolumn{1}{c|}{0.894}  & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{0.946}  & \multicolumn{1}{c|}{0.922}  & \multicolumn{1}{c|}{0.948}  & 0.936  \\ \cline{3-16} 
&                                & \multirow{7}{*}{\begin{tabular}[c]{@{}c@{}}Correlated\\ errors\end{tabular}}   & Bias $(\times 10)$          & \multicolumn{1}{c|}{0.218}  & \multicolumn{1}{c|}{0.249}  & \multicolumn{1}{c|}{7.019}  & \multicolumn{1}{c|}{7.012}  & \multicolumn{1}{c|}{0.763}  & \multicolumn{1}{c|}{0.406}  & \multicolumn{1}{c|}{7.018}  & \multicolumn{1}{c|}{7.011}  & \multicolumn{1}{c|}{0.085}  & \multicolumn{1}{c|}{0.276}  & \multicolumn{1}{c|}{0.004}  & 0.020  \\ \cline{4-16} 
&                                &                                                                                & ASE $(\times 10)$           & \multicolumn{1}{c|}{0.728}  & \multicolumn{1}{c|}{0.317}  & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{1.084}  & \multicolumn{1}{c|}{0.485}  & \multicolumn{1}{c|}{0.827}  & 0.372  \\ \cline{4-16} 
&                                &                                                                                & BSE $(\times 10)$           & \multicolumn{1}{c|}{0.784}  & \multicolumn{1}{c|}{0.325}  & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{1.098}  & \multicolumn{1}{c|}{0.495}  & \multicolumn{1}{c|}{0.849}  & 0.384  \\ \cline{4-16} 
&                                &                                                                                & ESE $(\times 10)$           & \multicolumn{1}{c|}{0.749}  & \multicolumn{1}{c|}{0.321}  & \multicolumn{1}{c|}{0.680}  & \multicolumn{1}{c|}{0.286}  & \multicolumn{1}{c|}{0.880}  & \multicolumn{1}{c|}{0.324}  & \multicolumn{1}{c|}{0.680}  & \multicolumn{1}{c|}{0.286}  & \multicolumn{1}{c|}{1.237}  & \multicolumn{1}{c|}{0.477}  & \multicolumn{1}{c|}{0.816}  & 0.362  \\ \cline{4-16} 
&                                &                                                                                & MSE $(\times 100)$          & \multicolumn{1}{c|}{0.607}  & \multicolumn{1}{c|}{0.165}  & \multicolumn{1}{c|}{49.721} & \multicolumn{1}{c|}{49.244} & \multicolumn{1}{c|}{1.354}  & \multicolumn{1}{c|}{0.270}  & \multicolumn{1}{c|}{49.718} & \multicolumn{1}{c|}{49.241} & \multicolumn{1}{c|}{1.535}  & \multicolumn{1}{c|}{0.303}  & \multicolumn{1}{c|}{0.665}  & 0.131  \\ \cline{4-16} 
&                                &                                                                                & Coverage (ASE)              & \multicolumn{1}{c|}{0.944}  & \multicolumn{1}{c|}{0.854}  & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{0.892}  & \multicolumn{1}{c|}{0.926}  & \multicolumn{1}{c|}{0.956}  & 0.948  \\ \cline{4-16} 
&                                &                                                                                & Coverage (BSE)              & \multicolumn{1}{c|}{0.958}  & \multicolumn{1}{c|}{0.874}  & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{0.896}  & \multicolumn{1}{c|}{0.940}  & \multicolumn{1}{c|}{0.954}  & 0.962  \\ \cline{3-16} 
&                                & \multirow{7}{*}{\begin{tabular}[c]{@{}c@{}}No\\ $Y$ error\end{tabular}}        & Bias $(\times 10)$          & \multicolumn{1}{c|}{0.367}  & \multicolumn{1}{c|}{0.340}  & \multicolumn{1}{c|}{7.051}  & \multicolumn{1}{c|}{6.971}  & \multicolumn{1}{c|}{1.826}  & \multicolumn{1}{c|}{1.216}  & \multicolumn{1}{c|}{7.391}  & \multicolumn{1}{c|}{7.294}  & \multicolumn{1}{c|}{0.205}  & \multicolumn{1}{c|}{0.251}  & \multicolumn{1}{c|}{0.036}  & -0.002 \\ \cline{4-16} 
&                                &                                                                                & ASE $(\times 10)$           & \multicolumn{1}{c|}{0.815}  & \multicolumn{1}{c|}{0.353}  & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{1.103}  & \multicolumn{1}{c|}{0.495}  & \multicolumn{1}{c|}{0.797}  & 0.356  \\ \cline{4-16} 
&                                &                                                                                & BSE $(\times 10)$           & \multicolumn{1}{c|}{0.886}  & \multicolumn{1}{c|}{0.363}  & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{1.122}  & \multicolumn{1}{c|}{0.509}  & \multicolumn{1}{c|}{0.813}  & 0.361  \\ \cline{4-16} 
&                                &                                                                                & ESE $(\times 10)$           & \multicolumn{1}{c|}{0.840}  & \multicolumn{1}{c|}{0.326}  & \multicolumn{1}{c|}{0.788}  & \multicolumn{1}{c|}{0.345}  & \multicolumn{1}{c|}{0.975}  & \multicolumn{1}{c|}{0.387}  & \multicolumn{1}{c|}{0.797}  & \multicolumn{1}{c|}{0.350}  & \multicolumn{1}{c|}{1.244}  & \multicolumn{1}{c|}{0.484}  & \multicolumn{1}{c|}{0.811}  & 0.331  \\ \cline{4-16} 
&                                &                                                                                & MSE $(\times 100)$          & \multicolumn{1}{c|}{0.839}  & \multicolumn{1}{c|}{0.222}  & \multicolumn{1}{c|}{50.338} & \multicolumn{1}{c|}{48.716} & \multicolumn{1}{c|}{4.284}  & \multicolumn{1}{c|}{1.627}  & \multicolumn{1}{c|}{55.260} & \multicolumn{1}{c|}{53.321} & \multicolumn{1}{c|}{1.586}  & \multicolumn{1}{c|}{0.297}  & \multicolumn{1}{c|}{0.658}  & 0.109  \\ \cline{4-16} 
&                                &                                                                                & Coverage (ASE)              & \multicolumn{1}{c|}{0.922}  & \multicolumn{1}{c|}{0.856}  & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{0.916}  & \multicolumn{1}{c|}{0.930}  & \multicolumn{1}{c|}{0.942}  & 0.966  \\ \cline{4-16} 
&                                &                                                                                & Coverage (BSE)              & \multicolumn{1}{c|}{0.936}  & \multicolumn{1}{c|}{0.868}  & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{0.920}  & \multicolumn{1}{c|}{0.948}  & \multicolumn{1}{c|}{0.956}  & 0.968  \\ \hline
\end{tabular} 

\caption{Summary Statistics of the Estimation Results Under (No trend with intercept) for $\blambda_t$.} 
\label{Tab:Supp:Sim:T1}

\end{table}

\newpage

\begin{table}[!htp]
\renewcommand{\arraystretch}{1.3} \centering
\scriptsize
\setlength{\tabcolsep}{1pt}  


\begin{tabular}{|c|c|c|c|cccccccccccc|}
\hline
\multirow{3}{*}{$\bm{\lambda}_t$}                                                                   & \multirow{3}{*}{$\bm{\mu}_0$} & \multirow{3}{*}{$\bm{e}_t$}                                                    & \multirow{3}{*}{Statistics} & \multicolumn{12}{c|}{Estimators and $T_0$}                                                                                                                                                                                                                                                                                                       \\ \cline{5-16}

&                                &                                                                                &                             & \multicolumn{2}{c|}{OLS-NoReg}                            & \multicolumn{2}{c|}{OLS-Standard}                         & \multicolumn{2}{c|}{ASC}                                  & \multicolumn{2}{c|}{SCPI}                                 & \multicolumn{2}{c|}{SPSC-NoDT}                            & \multicolumn{2}{c|}{SPSC-DT}         \\ \cline{5-16} 
&                                &                                                                                &                             & \multicolumn{1}{c|}{100}    & \multicolumn{1}{c|}{500}    & \multicolumn{1}{c|}{100}    & \multicolumn{1}{c|}{500}    & \multicolumn{1}{c|}{100}    & \multicolumn{1}{c|}{500}    & \multicolumn{1}{c|}{100}    & \multicolumn{1}{c|}{500}    & \multicolumn{1}{c|}{100}    & \multicolumn{1}{c|}{500}    & \multicolumn{1}{c|}{100}    & 500    \\ \hline


\multirow{42}{*}{\begin{tabular}[c]{@{}c@{}}Linear\\ trend \\ with \\ no\\ intercept\end{tabular}} & \multirow{21}{*}{Simplex}      & \multirow{7}{*}{\begin{tabular}[c]{@{}c@{}}Independent \\ errors\end{tabular}} & Bias $(\times 10)$          & \multicolumn{1}{c|}{0.323} & \multicolumn{1}{c|}{0.274}  & \multicolumn{1}{c|}{0.127}   & \multicolumn{1}{c|}{-0.021}  & \multicolumn{1}{c|}{-0.498} & \multicolumn{1}{c|}{-0.420} & \multicolumn{1}{c|}{-0.507}  & \multicolumn{1}{c|}{-0.426}  & \multicolumn{1}{c|}{-1.212} & \multicolumn{1}{c|}{-0.971} & \multicolumn{1}{c|}{0.071}  & 0.006  \\ \cline{4-16} 
&                                &                                                                                & ASE $(\times 10)$           & \multicolumn{1}{c|}{1.425} & \multicolumn{1}{c|}{0.636}  & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{1.225}  & \multicolumn{1}{c|}{0.552}  & \multicolumn{1}{c|}{1.429}  & 0.649  \\ \cline{4-16} 
&                                &                                                                                & BSE $(\times 10)$           & \multicolumn{1}{c|}{1.628} & \multicolumn{1}{c|}{0.658}  & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{1.794}  & \multicolumn{1}{c|}{0.825}  & \multicolumn{1}{c|}{1.534}  & 0.683  \\ \cline{4-16} 
&                                &                                                                                & ESE $(\times 10)$           & \multicolumn{1}{c|}{1.482} & \multicolumn{1}{c|}{0.598}  & \multicolumn{1}{c|}{2.061}   & \multicolumn{1}{c|}{0.900}   & \multicolumn{1}{c|}{1.361}  & \multicolumn{1}{c|}{0.582}  & \multicolumn{1}{c|}{1.355}   & \multicolumn{1}{c|}{0.582}   & \multicolumn{1}{c|}{2.885}  & \multicolumn{1}{c|}{2.871}  & \multicolumn{1}{c|}{1.518}  & 0.645  \\ \cline{4-16} 
&                                &                                                                                & MSE $(\times 100)$          & \multicolumn{1}{c|}{2.298} & \multicolumn{1}{c|}{0.432}  & \multicolumn{1}{c|}{4.254}   & \multicolumn{1}{c|}{0.808}   & \multicolumn{1}{c|}{2.096}  & \multicolumn{1}{c|}{0.515}  & \multicolumn{1}{c|}{2.089}   & \multicolumn{1}{c|}{0.520}   & \multicolumn{1}{c|}{9.779}  & \multicolumn{1}{c|}{9.168}  & \multicolumn{1}{c|}{2.304}  & 0.415  \\ \cline{4-16} 
&                                &                                                                                & Coverage (ASE)              & \multicolumn{1}{c|}{0.926} & \multicolumn{1}{c|}{0.946}  & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{0.438}  & \multicolumn{1}{c|}{0.034}  & \multicolumn{1}{c|}{0.946}  & 0.952  \\ \cline{4-16} 
&                                &                                                                                & Coverage (BSE)              & \multicolumn{1}{c|}{0.960} & \multicolumn{1}{c|}{0.954}  & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{0.668}  & \multicolumn{1}{c|}{0.156}  & \multicolumn{1}{c|}{0.962}  & 0.968  \\ \cline{3-16} 
&                                & \multirow{7}{*}{\begin{tabular}[c]{@{}c@{}}Correlated \\ errors\end{tabular}}  & Bias $(\times 10)$          & \multicolumn{1}{c|}{0.006} & \multicolumn{1}{c|}{-0.009} & \multicolumn{1}{c|}{0.131}   & \multicolumn{1}{c|}{0.017}   & \multicolumn{1}{c|}{-0.105} & \multicolumn{1}{c|}{-0.074} & \multicolumn{1}{c|}{-0.110}  & \multicolumn{1}{c|}{-0.076}  & \multicolumn{1}{c|}{-1.945} & \multicolumn{1}{c|}{-1.347} & \multicolumn{1}{c|}{-0.079} & -0.088 \\ \cline{4-16} 
&                                &                                                                                & ASE $(\times 10)$           & \multicolumn{1}{c|}{0.654} & \multicolumn{1}{c|}{0.294}  & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{0.902}  & \multicolumn{1}{c|}{0.405}  & \multicolumn{1}{c|}{0.662}  & 0.301  \\ \cline{4-16} 
&                                &                                                                                & BSE $(\times 10)$           & \multicolumn{1}{c|}{0.703} & \multicolumn{1}{c|}{0.302}  & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{0.978}  & \multicolumn{1}{c|}{0.468}  & \multicolumn{1}{c|}{0.711}  & 0.320  \\ \cline{4-16} 
&                                &                                                                                & ESE $(\times 10)$           & \multicolumn{1}{c|}{0.701} & \multicolumn{1}{c|}{0.289}  & \multicolumn{1}{c|}{1.468}   & \multicolumn{1}{c|}{0.697}   & \multicolumn{1}{c|}{0.663}  & \multicolumn{1}{c|}{0.285}  & \multicolumn{1}{c|}{0.662}   & \multicolumn{1}{c|}{0.285}   & \multicolumn{1}{c|}{1.352}  & \multicolumn{1}{c|}{0.686}  & \multicolumn{1}{c|}{0.704}  & 0.332  \\ \cline{4-16} 
&                                &                                                                                & MSE $(\times 100)$          & \multicolumn{1}{c|}{0.491} & \multicolumn{1}{c|}{0.084}  & \multicolumn{1}{c|}{2.167}   & \multicolumn{1}{c|}{0.486}   & \multicolumn{1}{c|}{0.450}  & \multicolumn{1}{c|}{0.087}  & \multicolumn{1}{c|}{0.450}   & \multicolumn{1}{c|}{0.087}   & \multicolumn{1}{c|}{5.606}  & \multicolumn{1}{c|}{2.284}  & \multicolumn{1}{c|}{0.500}  & 0.118  \\ \cline{4-16} 
&                                &                                                                                & Coverage (ASE)              & \multicolumn{1}{c|}{0.922} & \multicolumn{1}{c|}{0.950}  & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{0.470}  & \multicolumn{1}{c|}{0.176}  & \multicolumn{1}{c|}{0.922}  & 0.926  \\ \cline{4-16} 
&                                &                                                                                & Coverage (BSE)              & \multicolumn{1}{c|}{0.948} & \multicolumn{1}{c|}{0.958}  & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{0.518}  & \multicolumn{1}{c|}{0.260}  & \multicolumn{1}{c|}{0.948}  & 0.942  \\ \cline{3-16} 
&                                & \multirow{7}{*}{\begin{tabular}[c]{@{}c@{}}No \\ $Y$ error\end{tabular}}       & Bias $(\times 10)$          & \multicolumn{1}{c|}{0.280} & \multicolumn{1}{c|}{0.288}  & \multicolumn{1}{c|}{0.105}   & \multicolumn{1}{c|}{0.036}   & \multicolumn{1}{c|}{-0.373} & \multicolumn{1}{c|}{-0.321} & \multicolumn{1}{c|}{-0.376}  & \multicolumn{1}{c|}{-0.321}  & \multicolumn{1}{c|}{-1.154} & \multicolumn{1}{c|}{-1.364} & \multicolumn{1}{c|}{0.028}  & 0.016  \\ \cline{4-16} 
&                                &                                                                                & ASE $(\times 10)$           & \multicolumn{1}{c|}{0.635} & \multicolumn{1}{c|}{0.285}  & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{0.858}  & \multicolumn{1}{c|}{0.388}  & \multicolumn{1}{c|}{0.642}  & 0.288  \\ \cline{4-16} 
&                                &                                                                                & BSE $(\times 10)$           & \multicolumn{1}{c|}{0.683} & \multicolumn{1}{c|}{0.292}  & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{0.851}  & \multicolumn{1}{c|}{0.374}  & \multicolumn{1}{c|}{0.664}  & 0.299  \\ \cline{4-16} 
&                                &                                                                                & ESE $(\times 10)$           & \multicolumn{1}{c|}{0.671} & \multicolumn{1}{c|}{0.286}  & \multicolumn{1}{c|}{1.391}   & \multicolumn{1}{c|}{0.633}   & \multicolumn{1}{c|}{0.662}  & \multicolumn{1}{c|}{0.293}  & \multicolumn{1}{c|}{0.663}   & \multicolumn{1}{c|}{0.294}   & \multicolumn{1}{c|}{1.040}  & \multicolumn{1}{c|}{0.383}  & \multicolumn{1}{c|}{0.705}  & 0.309  \\ \cline{4-16} 
&                                &                                                                                & MSE $(\times 100)$          & \multicolumn{1}{c|}{0.528} & \multicolumn{1}{c|}{0.165}  & \multicolumn{1}{c|}{1.941}   & \multicolumn{1}{c|}{0.401}   & \multicolumn{1}{c|}{0.577}  & \multicolumn{1}{c|}{0.189}  & \multicolumn{1}{c|}{0.580}   & \multicolumn{1}{c|}{0.189}   & \multicolumn{1}{c|}{2.411}  & \multicolumn{1}{c|}{2.006}  & \multicolumn{1}{c|}{0.497}  & 0.095  \\ \cline{4-16} 
&                                &                                                                                & Coverage (ASE)              & \multicolumn{1}{c|}{0.906} & \multicolumn{1}{c|}{0.820}  & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{0.648}  & \multicolumn{1}{c|}{0.062}  & \multicolumn{1}{c|}{0.920}  & 0.930  \\ \cline{4-16} 
&                                &                                                                                & Coverage (BSE)              & \multicolumn{1}{c|}{0.930} & \multicolumn{1}{c|}{0.832}  & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{0.642}  & \multicolumn{1}{c|}{0.054}  & \multicolumn{1}{c|}{0.926}  & 0.940  \\ \cline{2-16} 
& \multirow{21}{*}{Non-simplex}  & \multirow{7}{*}{\begin{tabular}[c]{@{}c@{}}Independent \\ errors\end{tabular}} & Bias $(\times 10)$          & \multicolumn{1}{c|}{1.302} & \multicolumn{1}{c|}{1.366}  & \multicolumn{1}{c|}{10.695}  & \multicolumn{1}{c|}{10.506}  & \multicolumn{1}{c|}{8.262}  & \multicolumn{1}{c|}{5.699}  & \multicolumn{1}{c|}{11.927}  & \multicolumn{1}{c|}{11.849}  & \multicolumn{1}{c|}{-1.421} & \multicolumn{1}{c|}{-1.612} & \multicolumn{1}{c|}{0.069}  & 0.083  \\ \cline{4-16} 
&                                &                                                                                & ASE $(\times 10)$           & \multicolumn{1}{c|}{1.760} & \multicolumn{1}{c|}{0.789}  & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{1.851}  & \multicolumn{1}{c|}{0.836}  & \multicolumn{1}{c|}{1.795}  & 0.814  \\ \cline{4-16} 
&                                &                                                                                & BSE $(\times 10)$           & \multicolumn{1}{c|}{2.021} & \multicolumn{1}{c|}{0.816}  & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{2.242}  & \multicolumn{1}{c|}{0.991}  & \multicolumn{1}{c|}{1.941}  & 0.865  \\ \cline{4-16} 
&                                &                                                                                & ESE $(\times 10)$           & \multicolumn{1}{c|}{1.823} & \multicolumn{1}{c|}{0.766}  & \multicolumn{1}{c|}{1.159}   & \multicolumn{1}{c|}{0.406}   & \multicolumn{1}{c|}{1.702}  & \multicolumn{1}{c|}{0.949}  & \multicolumn{1}{c|}{0.962}   & \multicolumn{1}{c|}{0.433}   & \multicolumn{1}{c|}{2.084}  & \multicolumn{1}{c|}{0.973}  & \multicolumn{1}{c|}{1.938}  & 0.847  \\ \cline{4-16} 
&                                &                                                                                & MSE $(\times 100)$          & \multicolumn{1}{c|}{5.013} & \multicolumn{1}{c|}{2.451}  & \multicolumn{1}{c|}{115.724} & \multicolumn{1}{c|}{110.539} & \multicolumn{1}{c|}{71.157} & \multicolumn{1}{c|}{33.373} & \multicolumn{1}{c|}{143.178} & \multicolumn{1}{c|}{140.580} & \multicolumn{1}{c|}{6.357}  & \multicolumn{1}{c|}{3.543}  & \multicolumn{1}{c|}{3.753}  & 0.723  \\ \cline{4-16} 
&                                &                                                                                & Coverage (ASE)              & \multicolumn{1}{c|}{0.872} & \multicolumn{1}{c|}{0.582}  & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{0.840}  & \multicolumn{1}{c|}{0.486}  & \multicolumn{1}{c|}{0.928}  & 0.940  \\ \cline{4-16} 
&                                &                                                                                & Coverage (BSE)              & \multicolumn{1}{c|}{0.934} & \multicolumn{1}{c|}{0.610}  & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{0.914}  & \multicolumn{1}{c|}{0.604}  & \multicolumn{1}{c|}{0.942}  & 0.958  \\ \cline{3-16} 
&                                & \multirow{7}{*}{\begin{tabular}[c]{@{}c@{}}Correlated\\ errors\end{tabular}}   & Bias $(\times 10)$          & \multicolumn{1}{c|}{1.002} & \multicolumn{1}{c|}{0.998}  & \multicolumn{1}{c|}{10.518}  & \multicolumn{1}{c|}{10.508}  & \multicolumn{1}{c|}{2.675}  & \multicolumn{1}{c|}{1.589}  & \multicolumn{1}{c|}{10.521}  & \multicolumn{1}{c|}{10.507}  & \multicolumn{1}{c|}{-0.096} & \multicolumn{1}{c|}{0.789}  & \multicolumn{1}{c|}{0.219}  & 0.098  \\ \cline{4-16} 
&                                &                                                                                & ASE $(\times 10)$           & \multicolumn{1}{c|}{1.033} & \multicolumn{1}{c|}{0.464}  & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{1.484}  & \multicolumn{1}{c|}{0.660}  & \multicolumn{1}{c|}{1.330}  & 0.614  \\ \cline{4-16} 
&                                &                                                                                & BSE $(\times 10)$           & \multicolumn{1}{c|}{1.162} & \multicolumn{1}{c|}{0.477}  & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{1.655}  & \multicolumn{1}{c|}{0.766}  & \multicolumn{1}{c|}{1.424}  & 0.650  \\ \cline{4-16} 
&                                &                                                                                & ESE $(\times 10)$           & \multicolumn{1}{c|}{1.088} & \multicolumn{1}{c|}{0.438}  & \multicolumn{1}{c|}{0.642}   & \multicolumn{1}{c|}{0.286}   & \multicolumn{1}{c|}{1.538}  & \multicolumn{1}{c|}{0.520}  & \multicolumn{1}{c|}{0.644}   & \multicolumn{1}{c|}{0.286}   & \multicolumn{1}{c|}{2.158}  & \multicolumn{1}{c|}{0.877}  & \multicolumn{1}{c|}{1.345}  & 0.584  \\ \cline{4-16} 
&                                &                                                                                & MSE $(\times 100)$          & \multicolumn{1}{c|}{2.185} & \multicolumn{1}{c|}{1.187}  & \multicolumn{1}{c|}{111.044} & \multicolumn{1}{c|}{110.490} & \multicolumn{1}{c|}{9.519}  & \multicolumn{1}{c|}{2.794}  & \multicolumn{1}{c|}{111.110} & \multicolumn{1}{c|}{110.482} & \multicolumn{1}{c|}{4.656}  & \multicolumn{1}{c|}{1.391}  & \multicolumn{1}{c|}{1.853}  & 0.350  \\ \cline{4-16} 
&                                &                                                                                & Coverage (ASE)              & \multicolumn{1}{c|}{0.824} & \multicolumn{1}{c|}{0.434}  & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{0.796}  & \multicolumn{1}{c|}{0.716}  & \multicolumn{1}{c|}{0.934}  & 0.960  \\ \cline{4-16} 
&                                &                                                                                & Coverage (BSE)              & \multicolumn{1}{c|}{0.864} & \multicolumn{1}{c|}{0.440}  & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{0.822}  & \multicolumn{1}{c|}{0.792}  & \multicolumn{1}{c|}{0.948}  & 0.968  \\ \cline{3-16} 
&                                & \multirow{7}{*}{\begin{tabular}[c]{@{}c@{}}No\\ $Y$ error\end{tabular}}        & Bias $(\times 10)$          & \multicolumn{1}{c|}{1.430} & \multicolumn{1}{c|}{1.373}  & \multicolumn{1}{c|}{10.681}  & \multicolumn{1}{c|}{10.492}  & \multicolumn{1}{c|}{6.747}  & \multicolumn{1}{c|}{4.740}  & \multicolumn{1}{c|}{11.887}  & \multicolumn{1}{c|}{11.833}  & \multicolumn{1}{c|}{0.163}  & \multicolumn{1}{c|}{0.670}  & \multicolumn{1}{c|}{0.199}  & 0.127  \\ \cline{4-16} 
&                                &                                                                                & ASE $(\times 10)$           & \multicolumn{1}{c|}{1.221} & \multicolumn{1}{c|}{0.544}  & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{1.562}  & \multicolumn{1}{c|}{0.696}  & \multicolumn{1}{c|}{1.253}  & 0.563  \\ \cline{4-16} 
&                                &                                                                                & BSE $(\times 10)$           & \multicolumn{1}{c|}{1.383} & \multicolumn{1}{c|}{0.561}  & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{1.830}  & \multicolumn{1}{c|}{0.841}  & \multicolumn{1}{c|}{1.353}  & 0.598  \\ \cline{4-16} 
&                                &                                                                                & ESE $(\times 10)$           & \multicolumn{1}{c|}{1.274} & \multicolumn{1}{c|}{0.560}  & \multicolumn{1}{c|}{1.095}   & \multicolumn{1}{c|}{0.368}   & \multicolumn{1}{c|}{1.671}  & \multicolumn{1}{c|}{0.649}  & \multicolumn{1}{c|}{0.805}   & \multicolumn{1}{c|}{0.345}   & \multicolumn{1}{c|}{2.253}  & \multicolumn{1}{c|}{0.788}  & \multicolumn{1}{c|}{1.306}  & 0.613  \\ \cline{4-16} 
&                                &                                                                                & MSE $(\times 100)$          & \multicolumn{1}{c|}{3.663} & \multicolumn{1}{c|}{2.197}  & \multicolumn{1}{c|}{115.286} & \multicolumn{1}{c|}{110.212} & \multicolumn{1}{c|}{48.307} & \multicolumn{1}{c|}{22.885} & \multicolumn{1}{c|}{141.959} & \multicolumn{1}{c|}{140.136} & \multicolumn{1}{c|}{5.093}  & \multicolumn{1}{c|}{1.069}  & \multicolumn{1}{c|}{1.742}  & 0.391  \\ \cline{4-16} 
&                                &                                                                                & Coverage (ASE)              & \multicolumn{1}{c|}{0.758} & \multicolumn{1}{c|}{0.300}  & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{0.832}  & \multicolumn{1}{c|}{0.822}  & \multicolumn{1}{c|}{0.930}  & 0.918  \\ \cline{4-16} 
&                                &                                                                                & Coverage (BSE)              & \multicolumn{1}{c|}{0.820} & \multicolumn{1}{c|}{0.328}  & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{0.880}  & \multicolumn{1}{c|}{0.898}  & \multicolumn{1}{c|}{0.942}  & 0.928  \\ \hline
\end{tabular}


\caption{Summary Statistics of the Estimation Results Under (Linear trend with no intercept) for $\blambda_t$.} 
\label{Tab:Supp:Sim:T2}

\end{table}

\newpage

\begin{table}[!htp]
\renewcommand{\arraystretch}{1.3} \centering
\scriptsize
\setlength{\tabcolsep}{1pt}  


\begin{tabular}{|c|c|c|c|cccccccccccc|}
\hline
\multirow{3}{*}{$\bm{\lambda}_t$}                                                                   & \multirow{3}{*}{$\bm{\mu}_0$} & \multirow{3}{*}{$\bm{e}_t$}                                                    & \multirow{3}{*}{Statistics} & \multicolumn{12}{c|}{Estimators and $T_0$}                                                                                                                                                                                                                                                                                                       \\ \cline{5-16}

&                                &                                                                                &                             & \multicolumn{2}{c|}{OLS-NoReg}                            & \multicolumn{2}{c|}{OLS-Standard}                         & \multicolumn{2}{c|}{ASC}                                  & \multicolumn{2}{c|}{SCPI}                                 & \multicolumn{2}{c|}{SPSC-NoDT}                            & \multicolumn{2}{c|}{SPSC-DT}         \\ \cline{5-16} 
&                                &                                                                                &                             & \multicolumn{1}{c|}{100}    & \multicolumn{1}{c|}{500}    & \multicolumn{1}{c|}{100}    & \multicolumn{1}{c|}{500}    & \multicolumn{1}{c|}{100}    & \multicolumn{1}{c|}{500}    & \multicolumn{1}{c|}{100}    & \multicolumn{1}{c|}{500}    & \multicolumn{1}{c|}{100}    & \multicolumn{1}{c|}{500}    & \multicolumn{1}{c|}{100}    & 500    \\ \hline


\multirow{42}{*}{\begin{tabular}[c]{@{}c@{}}Linear\\ trend \\ with\\ intercept\end{tabular}} & \multirow{21}{*}{Simplex}      & \multirow{7}{*}{\begin{tabular}[c]{@{}c@{}}Independent \\ errors\end{tabular}} & Bias $(\times 10)$          & \multicolumn{1}{c|}{0.091}  & \multicolumn{1}{c|}{0.079} & \multicolumn{1}{c|}{0.012}   & \multicolumn{1}{c|}{0.001}   & \multicolumn{1}{c|}{-0.173} & \multicolumn{1}{c|}{-0.134} & \multicolumn{1}{c|}{-0.169}  & \multicolumn{1}{c|}{-0.133}  & \multicolumn{1}{c|}{-0.547} & \multicolumn{1}{c|}{-0.621} & \multicolumn{1}{c|}{0.020}  & -0.005 \\ \cline{4-16} 
&                                &                                                                                & ASE $(\times 10)$           & \multicolumn{1}{c|}{1.131}  & \multicolumn{1}{c|}{0.498} & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{1.183}  & \multicolumn{1}{c|}{0.535}  & \multicolumn{1}{c|}{1.107}  & 0.502  \\ \cline{4-16} 
&                                &                                                                                & BSE $(\times 10)$           & \multicolumn{1}{c|}{1.261}  & \multicolumn{1}{c|}{0.514} & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{1.269}  & \multicolumn{1}{c|}{0.576}  & \multicolumn{1}{c|}{1.134}  & 0.506  \\ \cline{4-16} 
&                                &                                                                                & ESE $(\times 10)$           & \multicolumn{1}{c|}{1.198}  & \multicolumn{1}{c|}{0.494} & \multicolumn{1}{c|}{1.345}   & \multicolumn{1}{c|}{0.606}   & \multicolumn{1}{c|}{1.152}  & \multicolumn{1}{c|}{0.495}  & \multicolumn{1}{c|}{1.152}   & \multicolumn{1}{c|}{0.495}   & \multicolumn{1}{c|}{1.341}  & \multicolumn{1}{c|}{0.591}  & \multicolumn{1}{c|}{1.147}  & 0.507  \\ \cline{4-16} 
&                                &                                                                                & MSE $(\times 100)$          & \multicolumn{1}{c|}{1.441}  & \multicolumn{1}{c|}{0.249} & \multicolumn{1}{c|}{1.806}   & \multicolumn{1}{c|}{0.367}   & \multicolumn{1}{c|}{1.355}  & \multicolumn{1}{c|}{0.263}  & \multicolumn{1}{c|}{1.353}   & \multicolumn{1}{c|}{0.262}   & \multicolumn{1}{c|}{2.095}  & \multicolumn{1}{c|}{0.734}  & \multicolumn{1}{c|}{1.313}  & 0.257  \\ \cline{4-16} 
&                                &                                                                                & Coverage (ASE)              & \multicolumn{1}{c|}{0.928}  & \multicolumn{1}{c|}{0.942} & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{0.886}  & \multicolumn{1}{c|}{0.758}  & \multicolumn{1}{c|}{0.930}  & 0.958  \\ \cline{4-16} 
&                                &                                                                                & Coverage (BSE)              & \multicolumn{1}{c|}{0.948}  & \multicolumn{1}{c|}{0.958} & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{0.908}  & \multicolumn{1}{c|}{0.798}  & \multicolumn{1}{c|}{0.938}  & 0.950  \\ \cline{3-16} 
&                                & \multirow{7}{*}{\begin{tabular}[c]{@{}c@{}}Correlated \\ errors\end{tabular}}  & Bias $(\times 10)$          & \multicolumn{1}{c|}{-0.026} & \multicolumn{1}{c|}{0.015} & \multicolumn{1}{c|}{-0.002}  & \multicolumn{1}{c|}{-0.001}  & \multicolumn{1}{c|}{-0.066} & \multicolumn{1}{c|}{-0.006} & \multicolumn{1}{c|}{-0.064}  & \multicolumn{1}{c|}{-0.005}  & \multicolumn{1}{c|}{-0.697} & \multicolumn{1}{c|}{-0.450} & \multicolumn{1}{c|}{-0.035} & 0.012  \\ \cline{4-16} 
&                                &                                                                                & ASE $(\times 10)$           & \multicolumn{1}{c|}{0.594}  & \multicolumn{1}{c|}{0.265} & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{0.944}  & \multicolumn{1}{c|}{0.424}  & \multicolumn{1}{c|}{0.600}  & 0.271  \\ \cline{4-16} 
&                                &                                                                                & BSE $(\times 10)$           & \multicolumn{1}{c|}{0.626}  & \multicolumn{1}{c|}{0.271} & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{0.969}  & \multicolumn{1}{c|}{0.441}  & \multicolumn{1}{c|}{0.604}  & 0.272  \\ \cline{4-16} 
&                                &                                                                                & ESE $(\times 10)$           & \multicolumn{1}{c|}{0.612}  & \multicolumn{1}{c|}{0.259} & \multicolumn{1}{c|}{1.028}   & \multicolumn{1}{c|}{0.467}   & \multicolumn{1}{c|}{0.594}  & \multicolumn{1}{c|}{0.258}  & \multicolumn{1}{c|}{0.594}   & \multicolumn{1}{c|}{0.258}   & \multicolumn{1}{c|}{1.115}  & \multicolumn{1}{c|}{0.723}  & \multicolumn{1}{c|}{0.619}  & 0.265  \\ \cline{4-16} 
&                                &                                                                                & MSE $(\times 100)$          & \multicolumn{1}{c|}{0.374}  & \multicolumn{1}{c|}{0.067} & \multicolumn{1}{c|}{1.054}   & \multicolumn{1}{c|}{0.218}   & \multicolumn{1}{c|}{0.357}  & \multicolumn{1}{c|}{0.066}  & \multicolumn{1}{c|}{0.357}   & \multicolumn{1}{c|}{0.066}   & \multicolumn{1}{c|}{1.726}  & \multicolumn{1}{c|}{0.724}  & \multicolumn{1}{c|}{0.384}  & 0.070  \\ \cline{4-16} 
&                                &                                                                                & Coverage (ASE)              & \multicolumn{1}{c|}{0.948}  & \multicolumn{1}{c|}{0.954} & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{0.830}  & \multicolumn{1}{c|}{0.626}  & \multicolumn{1}{c|}{0.936}  & 0.954  \\ \cline{4-16} 
&                                &                                                                                & Coverage (BSE)              & \multicolumn{1}{c|}{0.956}  & \multicolumn{1}{c|}{0.954} & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{0.828}  & \multicolumn{1}{c|}{0.642}  & \multicolumn{1}{c|}{0.940}  & 0.950  \\ \cline{3-16} 
&                                & \multirow{7}{*}{\begin{tabular}[c]{@{}c@{}}No \\ $Y$ error\end{tabular}}       & Bias $(\times 10)$          & \multicolumn{1}{c|}{0.085}  & \multicolumn{1}{c|}{0.089} & \multicolumn{1}{c|}{0.025}   & \multicolumn{1}{c|}{0.021}   & \multicolumn{1}{c|}{-0.121} & \multicolumn{1}{c|}{-0.098} & \multicolumn{1}{c|}{-0.120}  & \multicolumn{1}{c|}{-0.099}  & \multicolumn{1}{c|}{-0.309} & \multicolumn{1}{c|}{-0.322} & \multicolumn{1}{c|}{0.002}  & 0.007  \\ \cline{4-16} 
&                                &                                                                                & ASE $(\times 10)$           & \multicolumn{1}{c|}{0.580}  & \multicolumn{1}{c|}{0.260} & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{0.826}  & \multicolumn{1}{c|}{0.372}  & \multicolumn{1}{c|}{0.582}  & 0.261  \\ \cline{4-16} 
&                                &                                                                                & BSE $(\times 10)$           & \multicolumn{1}{c|}{0.611}  & \multicolumn{1}{c|}{0.265} & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{0.830}  & \multicolumn{1}{c|}{0.373}  & \multicolumn{1}{c|}{0.587}  & 0.261  \\ \cline{4-16} 
&                                &                                                                                & ESE $(\times 10)$           & \multicolumn{1}{c|}{0.583}  & \multicolumn{1}{c|}{0.266} & \multicolumn{1}{c|}{0.925}   & \multicolumn{1}{c|}{0.419}   & \multicolumn{1}{c|}{0.603}  & \multicolumn{1}{c|}{0.273}  & \multicolumn{1}{c|}{0.603}   & \multicolumn{1}{c|}{0.273}   & \multicolumn{1}{c|}{0.844}  & \multicolumn{1}{c|}{0.388}  & \multicolumn{1}{c|}{0.578}  & 0.266  \\ \cline{4-16} 
&                                &                                                                                & MSE $(\times 100)$          & \multicolumn{1}{c|}{0.347}  & \multicolumn{1}{c|}{0.078} & \multicolumn{1}{c|}{0.855}   & \multicolumn{1}{c|}{0.176}   & \multicolumn{1}{c|}{0.378}  & \multicolumn{1}{c|}{0.084}  & \multicolumn{1}{c|}{0.377}   & \multicolumn{1}{c|}{0.084}   & \multicolumn{1}{c|}{0.806}  & \multicolumn{1}{c|}{0.254}  & \multicolumn{1}{c|}{0.333}  & 0.070  \\ \cline{4-16} 
&                                &                                                                                & Coverage (ASE)              & \multicolumn{1}{c|}{0.952}  & \multicolumn{1}{c|}{0.946} & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{0.924}  & \multicolumn{1}{c|}{0.858}  & \multicolumn{1}{c|}{0.956}  & 0.956  \\ \cline{4-16} 
&                                &                                                                                & Coverage (BSE)              & \multicolumn{1}{c|}{0.970}  & \multicolumn{1}{c|}{0.952} & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{0.922}  & \multicolumn{1}{c|}{0.850}  & \multicolumn{1}{c|}{0.954}  & 0.942  \\ \cline{2-16} 
& \multirow{21}{*}{Non-simplex}  & \multirow{7}{*}{\begin{tabular}[c]{@{}c@{}}Independent \\ errors\end{tabular}} & Bias $(\times 10)$          & \multicolumn{1}{c|}{0.383}  & \multicolumn{1}{c|}{0.424} & \multicolumn{1}{c|}{17.500}  & \multicolumn{1}{c|}{17.531}  & \multicolumn{1}{c|}{2.818}  & \multicolumn{1}{c|}{1.497}  & \multicolumn{1}{c|}{17.517}  & \multicolumn{1}{c|}{17.530}  & \multicolumn{1}{c|}{0.256}  & \multicolumn{1}{c|}{0.339}  & \multicolumn{1}{c|}{-0.009} & 0.040  \\ \cline{4-16} 
&                                &                                                                                & ASE $(\times 10)$           & \multicolumn{1}{c|}{1.394}  & \multicolumn{1}{c|}{0.608} & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{1.724}  & \multicolumn{1}{c|}{0.775}  & \multicolumn{1}{c|}{1.362}  & 0.613  \\ \cline{4-16} 
&                                &                                                                                & BSE $(\times 10)$           & \multicolumn{1}{c|}{1.571}  & \multicolumn{1}{c|}{0.629} & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{1.798}  & \multicolumn{1}{c|}{0.810}  & \multicolumn{1}{c|}{1.416}  & 0.621  \\ \cline{4-16} 
&                                &                                                                                & ESE $(\times 10)$           & \multicolumn{1}{c|}{1.470}  & \multicolumn{1}{c|}{0.627} & \multicolumn{1}{c|}{0.909}   & \multicolumn{1}{c|}{0.450}   & \multicolumn{1}{c|}{1.798}  & \multicolumn{1}{c|}{0.708}  & \multicolumn{1}{c|}{0.911}   & \multicolumn{1}{c|}{0.450}   & \multicolumn{1}{c|}{1.789}  & \multicolumn{1}{c|}{0.799}  & \multicolumn{1}{c|}{1.399}  & 0.638  \\ \cline{4-16} 
&                                &                                                                                & MSE $(\times 100)$          & \multicolumn{1}{c|}{2.303}  & \multicolumn{1}{c|}{0.572} & \multicolumn{1}{c|}{307.074} & \multicolumn{1}{c|}{307.536} & \multicolumn{1}{c|}{11.169} & \multicolumn{1}{c|}{2.743}  & \multicolumn{1}{c|}{307.689} & \multicolumn{1}{c|}{307.513} & \multicolumn{1}{c|}{3.260}  & \multicolumn{1}{c|}{0.751}  & \multicolumn{1}{c|}{1.953}  & 0.407  \\ \cline{4-16} 
&                                &                                                                                & Coverage (ASE)              & \multicolumn{1}{c|}{0.926}  & \multicolumn{1}{c|}{0.886} & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{0.934}  & \multicolumn{1}{c|}{0.928}  & \multicolumn{1}{c|}{0.934}  & 0.954  \\ \cline{4-16} 
&                                &                                                                                & Coverage (BSE)              & \multicolumn{1}{c|}{0.962}  & \multicolumn{1}{c|}{0.894} & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{0.938}  & \multicolumn{1}{c|}{0.934}  & \multicolumn{1}{c|}{0.946}  & 0.952  \\ \cline{3-16} 
&                                & \multirow{7}{*}{\begin{tabular}[c]{@{}c@{}}Correlated\\ errors\end{tabular}}   & Bias $(\times 10)$          & \multicolumn{1}{c|}{0.287}  & \multicolumn{1}{c|}{0.247} & \multicolumn{1}{c|}{17.548}  & \multicolumn{1}{c|}{17.488}  & \multicolumn{1}{c|}{1.028}  & \multicolumn{1}{c|}{0.440}  & \multicolumn{1}{c|}{17.547}  & \multicolumn{1}{c|}{17.487}  & \multicolumn{1}{c|}{-0.427} & \multicolumn{1}{c|}{-0.738} & \multicolumn{1}{c|}{0.023}  & -0.018 \\ \cline{4-16} 
&                                &                                                                                & ASE $(\times 10)$           & \multicolumn{1}{c|}{0.862}  & \multicolumn{1}{c|}{0.378} & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{1.472}  & \multicolumn{1}{c|}{0.662}  & \multicolumn{1}{c|}{1.020}  & 0.459  \\ \cline{4-16} 
&                                &                                                                                & BSE $(\times 10)$           & \multicolumn{1}{c|}{0.950}  & \multicolumn{1}{c|}{0.388} & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{1.475}  & \multicolumn{1}{c|}{0.665}  & \multicolumn{1}{c|}{1.067}  & 0.478  \\ \cline{4-16} 
&                                &                                                                                & ESE $(\times 10)$           & \multicolumn{1}{c|}{0.906}  & \multicolumn{1}{c|}{0.382} & \multicolumn{1}{c|}{0.661}   & \multicolumn{1}{c|}{0.300}   & \multicolumn{1}{c|}{1.138}  & \multicolumn{1}{c|}{0.394}  & \multicolumn{1}{c|}{0.661}   & \multicolumn{1}{c|}{0.300}   & \multicolumn{1}{c|}{1.696}  & \multicolumn{1}{c|}{0.806}  & \multicolumn{1}{c|}{1.012}  & 0.455  \\ \cline{4-16} 
&                                &                                                                                & MSE $(\times 100)$          & \multicolumn{1}{c|}{0.902}  & \multicolumn{1}{c|}{0.207} & \multicolumn{1}{c|}{308.369} & \multicolumn{1}{c|}{305.912} & \multicolumn{1}{c|}{2.349}  & \multicolumn{1}{c|}{0.349}  & \multicolumn{1}{c|}{308.345} & \multicolumn{1}{c|}{305.890} & \multicolumn{1}{c|}{3.052}  & \multicolumn{1}{c|}{1.193}  & \multicolumn{1}{c|}{1.022}  & 0.207  \\ \cline{4-16} 
&                                &                                                                                & Coverage (ASE)              & \multicolumn{1}{c|}{0.924}  & \multicolumn{1}{c|}{0.882} & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{0.902}  & \multicolumn{1}{c|}{0.734}  & \multicolumn{1}{c|}{0.934}  & 0.946  \\ \cline{4-16} 
&                                &                                                                                & Coverage (BSE)              & \multicolumn{1}{c|}{0.948}  & \multicolumn{1}{c|}{0.888} & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{0.906}  & \multicolumn{1}{c|}{0.736}  & \multicolumn{1}{c|}{0.940}  & 0.954  \\ \cline{3-16} 
&                                & \multirow{7}{*}{\begin{tabular}[c]{@{}c@{}}No\\ $Y$ error\end{tabular}}        & Bias $(\times 10)$          & \multicolumn{1}{c|}{0.385}  & \multicolumn{1}{c|}{0.388} & \multicolumn{1}{c|}{17.573}  & \multicolumn{1}{c|}{17.520}  & \multicolumn{1}{c|}{1.884}  & \multicolumn{1}{c|}{1.388}  & \multicolumn{1}{c|}{17.575}  & \multicolumn{1}{c|}{17.519}  & \multicolumn{1}{c|}{-0.421} & \multicolumn{1}{c|}{-0.506} & \multicolumn{1}{c|}{0.010}  & 0.014  \\ \cline{4-16} 
&                                &                                                                                & ASE $(\times 10)$           & \multicolumn{1}{c|}{0.983}  & \multicolumn{1}{c|}{0.435} & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{1.494}  & \multicolumn{1}{c|}{0.674}  & \multicolumn{1}{c|}{0.979}  & 0.439  \\ \cline{4-16} 
&                                &                                                                                & BSE $(\times 10)$           & \multicolumn{1}{c|}{1.092}  & \multicolumn{1}{c|}{0.449} & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{1.515}  & \multicolumn{1}{c|}{0.678}  & \multicolumn{1}{c|}{1.012}  & 0.446  \\ \cline{4-16} 
&                                &                                                                                & ESE $(\times 10)$           & \multicolumn{1}{c|}{1.091}  & \multicolumn{1}{c|}{0.432} & \multicolumn{1}{c|}{0.797}   & \multicolumn{1}{c|}{0.360}   & \multicolumn{1}{c|}{1.316}  & \multicolumn{1}{c|}{0.508}  & \multicolumn{1}{c|}{0.798}   & \multicolumn{1}{c|}{0.360}   & \multicolumn{1}{c|}{1.800}  & \multicolumn{1}{c|}{1.006}  & \multicolumn{1}{c|}{1.080}  & 0.439  \\ \cline{4-16} 
&                                &                                                                                & MSE $(\times 100)$          & \multicolumn{1}{c|}{1.336}  & \multicolumn{1}{c|}{0.337} & \multicolumn{1}{c|}{309.455} & \multicolumn{1}{c|}{307.081} & \multicolumn{1}{c|}{5.278}  & \multicolumn{1}{c|}{2.185}  & \multicolumn{1}{c|}{309.528} & \multicolumn{1}{c|}{307.059} & \multicolumn{1}{c|}{3.412}  & \multicolumn{1}{c|}{1.265}  & \multicolumn{1}{c|}{1.164}  & 0.192  \\ \cline{4-16} 
&                                &                                                                                & Coverage (ASE)              & \multicolumn{1}{c|}{0.900}  & \multicolumn{1}{c|}{0.846} & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{0.880}  & \multicolumn{1}{c|}{0.750}  & \multicolumn{1}{c|}{0.924}  & 0.960  \\ \cline{4-16} 
&                                &                                                                                & Coverage (BSE)              & \multicolumn{1}{c|}{0.932}  & \multicolumn{1}{c|}{0.866} & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}      & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{-}       & \multicolumn{1}{c|}{0.882}  & \multicolumn{1}{c|}{0.744}  & \multicolumn{1}{c|}{0.936}  & 0.962  \\ \hline
\end{tabular} 

\caption{Summary Statistics of the Estimation Results Under (Linear trend with intercept) for $\blambda_t$.} 
\label{Tab:Supp:Sim:T3}

\end{table}

\newpage


We report the performance of conformal inference in Section \ref{sec:Conformal} of the main paper under the simulation scenarios in Section \ref{sec:Sim} of the main paper. First, we obtain the pointwise 95\% pointwise prediction interval for the random treatment effect at 10 post-treatment times $t \in \mathcal{T} = \{ T_0 + 0.1 T_1, T_0 + 0.2 T_1, \ldots T_0 + 0.9 T_1 , T\}$, which are $\xi_{t}^* = 3 + \epsilon_{t}$. 


As competing methods, we construct 95\% pointwise prediction intervals using the ASC and SCPI approaches. For the ASC approach, we use the conformal approach to construct prediction intervals, which is the default option employed in \texttt{augsynth} package. For the SCPI approach, we use the prediction interval estimating out-of-sample uncertainty with sub-Gaussian bounds, which is stored in \texttt{CI.all.gaussian} object of a \texttt{scpi} output; see below for an example R-code:
\begin{itemize}[leftmargin=2cm,itemsep=0cm]
\item[] \texttt{scpi.est $\leftarrow$ scpi::scpi(SCD) \# SCD is a scdata object}
\item[] \texttt{scpi.PI \ $\leftarrow$ scpi.est\$inference.results\$CI.all.gaussian}
\end{itemize}
For each simulation repetition and each method, we calculate $\ind \big(\xi_{t} ^* \in \mathcal{C}_{t} \big)$ where $\mathcal{C}_{t}$ is a 95\% prediction interval obtained from each method, i.e., the indicator of whether a 95\% prediction interval at $t$ obtained from each method includes the random treatment effect. Ideally, the average of these indicators across simulation repetitions (i.e., the empirical coverage rate of 95\% prediction intervals) should be close to the nominal coverage rate of 0.95.

Table \ref{tab:supp:Table3} shows the empirical coverage rates obtained from 500 repetitions for each simulation scenario. We find that the conformal inference approach for the SPSC achieves the nominal coverage rate across all simulation scenarios in general. However, we find that the ASC approach fails to do so for all reported scenarios. Likewise, the SCPI approach appears to struggle to attain the desired nominal coverage rate, especially when the latent factor $\blambda_t$ has a trend. Next, we calculate the average length of the 95\% prediction intervals for $t \in \mathcal{T}$ across 500 repetitions.   The table also shows the average lengths of the prediction intervals. 
We find that the length of the prediction intervals decreases as the length of the pre-treatment periods increases. 
Notably, the SPSC-DT approach consistently yields prediction intervals that are not only comparable in length but often the shortest when compared to other estimators across all scenarios. In particular, the SPSC-DT estimator outperforms the others in terms of coverage and length, particularly when a linear trend is present. These findings demonstrate that the proposed conformal inference method for the SPSC framework is robust and broadly applicable, regardless of the data generating process.


\newpage

\begin{table}[!htp] 
\renewcommand{\arraystretch}{1.2} \centering
\scriptsize
\setlength{\tabcolsep}{7pt} 

\begin{tabular}{|c|c|c|c|cc|cc|cc|cc|}
\hline
\multirow{3}{*}{$\blambda_t$}                                                                                        & \multirow{3}{*}{$\bm{\mu}_0$} & \multirow{3}{*}{$\bm{e}_t$}                                                        & \multirow{3}{*}{Statistics} & \multicolumn{8}{c|}{Estimators and $T_0$}   \\ \cline{5-12} 
&                                &                                                                                    &                             & \multicolumn{2}{c|}{ASC}           & \multicolumn{2}{c|}{SCPI}          & \multicolumn{2}{c|}{SPSC-NoDT}     & \multicolumn{2}{c|}{SPSC-DT}       \\ \cline{5-12} 
&                                &                                                                                    &                             & \multicolumn{1}{c|}{100}   & 500   & \multicolumn{1}{c|}{100}   & 500   & \multicolumn{1}{c|}{100}   & 500   & \multicolumn{1}{c|}{100}   & 500   \\ \hline
\multirow{12}{*}{\begin{tabular}[c]{@{}c@{}}No\\      trend\\      with\\      no\\      intercept\end{tabular}}     & \multirow{6}{*}{Simplex}       & \multirow{2}{*}{\begin{tabular}[c]{@{}c@{}}Independent\\      errors\end{tabular}} & Coverage                    & \multicolumn{1}{c|}{0.925} & 0.918 & \multicolumn{1}{c|}{0.907} & 0.939 & \multicolumn{1}{c|}{0.963} & 0.954 & \multicolumn{1}{c|}{0.963} & 0.954 \\ \cline{4-12} 
&                                &                                                                                    & Length                      & \multicolumn{1}{c|}{2.009} & 1.850 & \multicolumn{1}{c|}{2.034} & 2.036 & \multicolumn{1}{c|}{2.249} & 2.055 & \multicolumn{1}{c|}{2.244} & 2.054 \\ \cline{3-12} 
&                                & \multirow{2}{*}{\begin{tabular}[c]{@{}c@{}}Correlated\\      errors\end{tabular}}  & Coverage                    & \multicolumn{1}{c|}{0.691} & 0.567 & \multicolumn{1}{c|}{0.972} & 0.954 & \multicolumn{1}{c|}{0.959} & 0.950 & \multicolumn{1}{c|}{0.960} & 0.950 \\ \cline{4-12} 
&                                &                                                                                    & Length                      & \multicolumn{1}{c|}{0.423} & 0.283 & \multicolumn{1}{c|}{0.872} & 0.706 & \multicolumn{1}{c|}{0.755} & 0.696 & \multicolumn{1}{c|}{0.766} & 0.696 \\ \cline{3-12} 
&                                & \multirow{2}{*}{\begin{tabular}[c]{@{}c@{}}No\\      $Y$ error\end{tabular}}       & Coverage                    & \multicolumn{1}{c|}{0.714} & 0.581 & \multicolumn{1}{c|}{0.986} & 0.961 & \multicolumn{1}{c|}{0.959} & 0.948 & \multicolumn{1}{c|}{0.960} & 0.948 \\ \cline{4-12} 
&                                &                                                                                    & Length                      & \multicolumn{1}{c|}{0.465} & 0.305 & \multicolumn{1}{c|}{0.951} & 0.680 & \multicolumn{1}{c|}{0.675} & 0.610 & \multicolumn{1}{c|}{0.681} & 0.610 \\ \cline{2-12} 
& \multirow{6}{*}{Non-simplex}   & \multirow{2}{*}{\begin{tabular}[c]{@{}c@{}}Independent\\      errors\end{tabular}} & Coverage                    & \multicolumn{1}{c|}{0.933} & 0.925 & \multicolumn{1}{c|}{0.935} & 0.912 & \multicolumn{1}{c|}{0.959} & 0.948 & \multicolumn{1}{c|}{0.961} & 0.948 \\ \cline{4-12} 
&                                &                                                                                    & Length                      & \multicolumn{1}{c|}{2.597} & 2.459 & \multicolumn{1}{c|}{2.848} & 2.407 & \multicolumn{1}{c|}{2.839} & 2.556 & \multicolumn{1}{c|}{2.824} & 2.554 \\ \cline{3-12} 
&                                & \multirow{2}{*}{\begin{tabular}[c]{@{}c@{}}Correlated\\      errors\end{tabular}}  & Coverage                    & \multicolumn{1}{c|}{0.904} & 0.906 & \multicolumn{1}{c|}{0.925} & 0.913 & \multicolumn{1}{c|}{0.962} & 0.952 & \multicolumn{1}{c|}{0.963} & 0.953 \\ \cline{4-12} 
&                                &                                                                                    & Length                      & \multicolumn{1}{c|}{1.326} & 1.229 & \multicolumn{1}{c|}{1.440} & 1.255 & \multicolumn{1}{c|}{1.859} & 1.701 & \multicolumn{1}{c|}{1.935} & 1.699 \\ \cline{3-12} 
&                                & \multirow{2}{*}{\begin{tabular}[c]{@{}c@{}}No\\      $Y$ error\end{tabular}}       & Coverage                    & \multicolumn{1}{c|}{0.922} & 0.910 & \multicolumn{1}{c|}{0.938} & 0.925 & \multicolumn{1}{c|}{0.964} & 0.951 & \multicolumn{1}{c|}{0.964} & 0.953 \\ \cline{4-12} 
&                                &                                                                                    & Length                      & \multicolumn{1}{c|}{1.704} & 1.608 & \multicolumn{1}{c|}{1.978} & 1.648 & \multicolumn{1}{c|}{1.852} & 1.668 & \multicolumn{1}{c|}{1.856} & 1.670 \\ \hline
\multirow{12}{*}{\begin{tabular}[c]{@{}c@{}}No\\      trend\\      with\\      intercept\end{tabular}}               & \multirow{6}{*}{Simplex}       & \multirow{2}{*}{\begin{tabular}[c]{@{}c@{}}Independent\\      errors\end{tabular}} & Coverage                    & \multicolumn{1}{c|}{0.921} & 0.917 & \multicolumn{1}{c|}{0.911} & 0.940 & \multicolumn{1}{c|}{0.962} & 0.953 & \multicolumn{1}{c|}{0.959} & 0.951 \\ \cline{4-12} 
&                                &                                                                                    & Length                      & \multicolumn{1}{c|}{1.998} & 1.861 & \multicolumn{1}{c|}{2.068} & 2.069 & \multicolumn{1}{c|}{2.599} & 2.410 & \multicolumn{1}{c|}{2.245} & 2.061 \\ \cline{3-12} 
&                                & \multirow{2}{*}{\begin{tabular}[c]{@{}c@{}}Correlated\\      errors\end{tabular}}  & Coverage                    & \multicolumn{1}{c|}{0.674} & 0.580 & \multicolumn{1}{c|}{0.969} & 0.958 & \multicolumn{1}{c|}{0.962} & 0.955 & \multicolumn{1}{c|}{0.961} & 0.948 \\ \cline{4-12} 
&                                &                                                                                    & Length                      & \multicolumn{1}{c|}{0.410} & 0.286 & \multicolumn{1}{c|}{0.868} & 0.704 & \multicolumn{1}{c|}{1.782} & 1.653 & \multicolumn{1}{c|}{0.762} & 0.700 \\ \cline{3-12} 
&                                & \multirow{2}{*}{\begin{tabular}[c]{@{}c@{}}No\\      $Y$ error\end{tabular}}       & Coverage                    & \multicolumn{1}{c|}{0.735} & 0.603 & \multicolumn{1}{c|}{0.985} & 0.954 & \multicolumn{1}{c|}{0.953} & 0.954 & \multicolumn{1}{c|}{0.968} & 0.946 \\ \cline{4-12} 
&                                &                                                                                    & Length                      & \multicolumn{1}{c|}{0.489} & 0.324 & \multicolumn{1}{c|}{0.935} & 0.666 & \multicolumn{1}{c|}{1.469} & 1.366 & \multicolumn{1}{c|}{0.693} & 0.618 \\ \cline{2-12} 
& \multirow{6}{*}{Non-simplex}   & \multirow{2}{*}{\begin{tabular}[c]{@{}c@{}}Independent\\      errors\end{tabular}} & Coverage                    & \multicolumn{1}{c|}{0.927} & 0.921 & \multicolumn{1}{c|}{0.898} & 0.877 & \multicolumn{1}{c|}{0.960} & 0.947 & \multicolumn{1}{c|}{0.958} & 0.946 \\ \cline{4-12} 
&                                &                                                                                    & Length                      & \multicolumn{1}{c|}{3.064} & 2.746 & \multicolumn{1}{c|}{2.741} & 2.410 & \multicolumn{1}{c|}{3.778} & 3.511 & \multicolumn{1}{c|}{2.887} & 2.638 \\ \cline{3-12} 
&                                & \multirow{2}{*}{\begin{tabular}[c]{@{}c@{}}Correlated\\      errors\end{tabular}}  & Coverage                    & \multicolumn{1}{c|}{0.911} & 0.907 & \multicolumn{1}{c|}{0.893} & 0.883 & \multicolumn{1}{c|}{0.965} & 0.953 & \multicolumn{1}{c|}{0.967} & 0.953 \\ \cline{4-12} 
&                                &                                                                                    & Length                      & \multicolumn{1}{c|}{1.435} & 1.266 & \multicolumn{1}{c|}{1.420} & 1.278 & \multicolumn{1}{c|}{3.043} & 2.831 & \multicolumn{1}{c|}{2.181} & 1.813 \\ \cline{3-12} 
&                                & \multirow{2}{*}{\begin{tabular}[c]{@{}c@{}}No\\      $Y$ error\end{tabular}}       & Coverage                    & \multicolumn{1}{c|}{0.917} & 0.918 & \multicolumn{1}{c|}{0.908} & 0.890 & \multicolumn{1}{c|}{0.964} & 0.947 & \multicolumn{1}{c|}{0.967} & 0.950 \\ \cline{4-12} 
&                                &                                                                                    & Length                      & \multicolumn{1}{c|}{2.198} & 1.958 & \multicolumn{1}{c|}{2.046} & 1.751 & \multicolumn{1}{c|}{3.130} & 2.901 & \multicolumn{1}{c|}{1.968} & 1.744 \\ \hline
\multirow{12}{*}{\begin{tabular}[c]{@{}c@{}}Linear\\      trend\\      with\\      no\\      intercept\end{tabular}} & \multirow{6}{*}{Simplex}       & \multirow{2}{*}{\begin{tabular}[c]{@{}c@{}}Independent\\      errors\end{tabular}} & Coverage                    & \multicolumn{1}{c|}{0.934} & 0.915 & \multicolumn{1}{c|}{0.926} & 0.951 & \multicolumn{1}{c|}{0.950} & 0.928 & \multicolumn{1}{c|}{0.962} & 0.941 \\ \cline{4-12} 
&                                &                                                                                    & Length                      & \multicolumn{1}{c|}{2.100} & 1.879 & \multicolumn{1}{c|}{2.372} & 2.252 & \multicolumn{1}{c|}{2.675} & 2.376 & \multicolumn{1}{c|}{2.288} & 2.074 \\ \cline{3-12} 
&                                & \multirow{2}{*}{\begin{tabular}[c]{@{}c@{}}Correlated\\      errors\end{tabular}}  & Coverage                    & \multicolumn{1}{c|}{0.744} & 0.593 & \multicolumn{1}{c|}{0.985} & 0.969 & \multicolumn{1}{c|}{0.919} & 0.935 & \multicolumn{1}{c|}{0.959} & 0.949 \\ \cline{4-12} 
&                                &                                                                                    & Length                      & \multicolumn{1}{c|}{0.490} & 0.300 & \multicolumn{1}{c|}{1.028} & 0.767 & \multicolumn{1}{c|}{1.603} & 1.421 & \multicolumn{1}{c|}{0.774} & 0.700 \\ \cline{3-12} 
&                                & \multirow{2}{*}{\begin{tabular}[c]{@{}c@{}}No\\      $Y$ error\end{tabular}}       & Coverage                    & \multicolumn{1}{c|}{0.780} & 0.620 & \multicolumn{1}{c|}{0.991} & 0.973 & \multicolumn{1}{c|}{0.941} & 0.930 & \multicolumn{1}{c|}{0.961} & 0.955 \\ \cline{4-12} 
&                                &                                                                                    & Length                      & \multicolumn{1}{c|}{0.553} & 0.353 & \multicolumn{1}{c|}{1.063} & 0.725 & \multicolumn{1}{c|}{1.392} & 1.225 & \multicolumn{1}{c|}{0.704} & 0.620 \\ \cline{2-12} 
& \multirow{6}{*}{Non-simplex}   & \multirow{2}{*}{\begin{tabular}[c]{@{}c@{}}Independent\\      errors\end{tabular}} & Coverage                    & \multicolumn{1}{c|}{0.795} & 0.846 & \multicolumn{1}{c|}{0.938} & 0.889 & \multicolumn{1}{c|}{0.959} & 0.944 & \multicolumn{1}{c|}{0.962} & 0.949 \\ \cline{4-12} 
&                                &                                                                                    & Length                      & \multicolumn{1}{c|}{2.969} & 2.719 & \multicolumn{1}{c|}{3.223} & 2.646 & \multicolumn{1}{c|}{3.755} & 3.336 & \multicolumn{1}{c|}{2.937} & 2.668 \\ \cline{3-12} 
&                                & \multirow{2}{*}{\begin{tabular}[c]{@{}c@{}}Correlated\\      errors\end{tabular}}  & Coverage                    & \multicolumn{1}{c|}{0.844} & 0.883 & \multicolumn{1}{c|}{0.907} & 0.843 & \multicolumn{1}{c|}{0.957} & 0.944 & \multicolumn{1}{c|}{0.967} & 0.948 \\ \cline{4-12} 
&                                &                                                                                    & Length                      & \multicolumn{1}{c|}{1.486} & 1.299 & \multicolumn{1}{c|}{1.678} & 1.432 & \multicolumn{1}{c|}{2.883} & 2.534 & \multicolumn{1}{c|}{2.207} & 1.820 \\ \cline{3-12} 
&                                & \multirow{2}{*}{\begin{tabular}[c]{@{}c@{}}No\\      $Y$ error\end{tabular}}       & Coverage                    & \multicolumn{1}{c|}{0.728} & 0.808 & \multicolumn{1}{c|}{0.920} & 0.852 & \multicolumn{1}{c|}{0.957} & 0.953 & \multicolumn{1}{c|}{0.957} & 0.946 \\ \cline{4-12} 
&                                &                                                                                    & Length                      & \multicolumn{1}{c|}{2.113} & 1.908 & \multicolumn{1}{c|}{2.384} & 1.897 & \multicolumn{1}{c|}{3.039} & 2.676 & \multicolumn{1}{c|}{1.976} & 1.756 \\ \hline
\multirow{12}{*}{\begin{tabular}[c]{@{}c@{}}Linear\\      trend\\      with\\      intercept\end{tabular}}           & \multirow{6}{*}{Simplex}       & \multirow{2}{*}{\begin{tabular}[c]{@{}c@{}}Independent\\      errors\end{tabular}} & Coverage                    & \multicolumn{1}{c|}{0.926} & 0.917 & \multicolumn{1}{c|}{0.917} & 0.949 & \multicolumn{1}{c|}{0.959} & 0.951 & \multicolumn{1}{c|}{0.962} & 0.949 \\ \cline{4-12} 
&                                &                                                                                    & Length                      & \multicolumn{1}{c|}{2.034} & 1.860 & \multicolumn{1}{c|}{2.281} & 2.168 & \multicolumn{1}{c|}{2.633} & 2.443 & \multicolumn{1}{c|}{2.278} & 2.069 \\ \cline{3-12} 
&                                & \multirow{2}{*}{\begin{tabular}[c]{@{}c@{}}Correlated\\      errors\end{tabular}}  & Coverage                    & \multicolumn{1}{c|}{0.693} & 0.580 & \multicolumn{1}{c|}{0.979} & 0.962 & \multicolumn{1}{c|}{0.961} & 0.948 & \multicolumn{1}{c|}{0.960} & 0.948 \\ \cline{4-12} 
&                                &                                                                                    & Length                      & \multicolumn{1}{c|}{0.436} & 0.288 & \multicolumn{1}{c|}{0.953} & 0.735 & \multicolumn{1}{c|}{1.928} & 1.767 & \multicolumn{1}{c|}{0.761} & 0.702 \\ \cline{3-12} 
&                                & \multirow{2}{*}{\begin{tabular}[c]{@{}c@{}}No\\      $Y$ error\end{tabular}}       & Coverage                    & \multicolumn{1}{c|}{0.755} & 0.606 & \multicolumn{1}{c|}{0.987} & 0.965 & \multicolumn{1}{c|}{0.955} & 0.952 & \multicolumn{1}{c|}{0.966} & 0.955 \\ \cline{4-12} 
&                                &                                                                                    & Length                      & \multicolumn{1}{c|}{0.516} & 0.335 & \multicolumn{1}{c|}{0.993} & 0.694 & \multicolumn{1}{c|}{1.555} & 1.424 & \multicolumn{1}{c|}{0.703} & 0.621 \\ \cline{2-12} 
& \multirow{6}{*}{Non-simplex}   & \multirow{2}{*}{\begin{tabular}[c]{@{}c@{}}Independent\\      errors\end{tabular}} & Coverage                    & \multicolumn{1}{c|}{0.921} & 0.919 & \multicolumn{1}{c|}{0.882} & 0.825 & \multicolumn{1}{c|}{0.958} & 0.950 & \multicolumn{1}{c|}{0.962} & 0.951 \\ \cline{4-12} 
&                                &                                                                                    & Length                      & \multicolumn{1}{c|}{3.119} & 2.769 & \multicolumn{1}{c|}{3.118} & 2.686 & \multicolumn{1}{c|}{3.945} & 3.607 & \multicolumn{1}{c|}{2.947} & 2.647 \\ \cline{3-12} 
&                                & \multirow{2}{*}{\begin{tabular}[c]{@{}c@{}}Correlated\\      errors\end{tabular}}  & Coverage                    & \multicolumn{1}{c|}{0.899} & 0.902 & \multicolumn{1}{c|}{0.874} & 0.817 & \multicolumn{1}{c|}{0.960} & 0.949 & \multicolumn{1}{c|}{0.966} & 0.952 \\ \cline{4-12} 
&                                &                                                                                    & Length                      & \multicolumn{1}{c|}{1.467} & 1.275 & \multicolumn{1}{c|}{1.584} & 1.352 & \multicolumn{1}{c|}{3.237} & 2.978 & \multicolumn{1}{c|}{2.245} & 1.814 \\ \cline{3-12} 
&                                & \multirow{2}{*}{\begin{tabular}[c]{@{}c@{}}No\\      $Y$ error\end{tabular}}       & Coverage                    & \multicolumn{1}{c|}{0.916} & 0.907 & \multicolumn{1}{c|}{0.841} & 0.770 & \multicolumn{1}{c|}{0.959} & 0.946 & \multicolumn{1}{c|}{0.967} & 0.949 \\ \cline{4-12} 
&                                &                                                                                    & Length                      & \multicolumn{1}{c|}{2.276} & 1.994 & \multicolumn{1}{c|}{2.430} & 2.121 & \multicolumn{1}{c|}{3.284} & 3.032 & \multicolumn{1}{c|}{2.010} & 1.747 \\ \hline
\end{tabular}



\caption{
Empirical Coverage Rates of 95\% Pointwise Prediction Intervals.}
\label{tab:supp:Table3}

\end{table}

\newpage

Lastly, we study the width of 95\% prediction intervals obtained from the SPSC-DT estimator. We use the same simulation setup as before, with the modification that $T_0=100$ and $T_1=400$, focusing only on cases where $\blambda_t$ does not have an intercept. We calculate the 95\% prediction intervals at $t \in \{120, 140, \ldots, 480, 500\}$ and compute the average prediction interval width over 500 simulation repetitions. As shown in Figure \ref{fig:supp:PI width wider}, the prediction intervals may or may not widen as the post-treatment period progresses. Specifically, the width of the SPSC prediction intervals remains stable or shows only a slight increase when there is no systematic drift in the outcomes, but it tends to widen when such drift is present. Note that such systematic drift can be empirically verified by examining the trend of the estimated synthetic control, $\bW_t\T \widehat{\bgamma}_{\rho}$. 

% Figure environment removed		





\subsection{Simulation Studies under the Scenario Given in \citet{Cattaneo2021}} \label{sec:supp:Simulation PI}



For a fair comparison, we adopt a simulation scenario setup in \citet{Cattaneo2021}. In particular, we consider the following data generating process. First, we consider the length of the pre- and post-treatment periods as $T_0 = 100$ and $T_1=1$. Second, we choose the number of donors as $N = 10$, which are generated from the following AR(1) model:
\begin{align*}
&
W_{it} = \kappa W_{i, t-1} + \eta_{it} 
\ , \
t \in \{1,\ldots,T_0\}
\ , \ 
i \in \{1,\ldots,d\} \ .
\end{align*}
Here, the autocorrelation coefficient $\kappa$ is chosen from $\kappa \in \{0,0.5,1\}$, $\eta$ are generated from the standard normal distribution and are independent and identically distributed, and the baseline value $W_{i0}$ is set to zero. For the post-treatment period, we consider the following model for donors:
\begin{align*}
& W_{1 , T_0+1} = \kappa W_{1 T_0} + \eta_{1 , T_0+1} + \zeta \texttt{sd} ( W_{11},\ldots,W_{1 T_0} ) 
\\
&
W_{i , T_0+1} = \kappa W_{i T_0} + \eta_{i , T_0+1} \ , \quad i \in \{2,\ldots,N\} \ ,
\end{align*}
where $\zeta \in \{ -1,-0.5,0,0.5,1 \}$ parameterizes the degree of the shift in the first donor's post-treatment outcome. The treatment-free potential outcome of the treated unit is given by
\begin{align*}
\potY{t}{0} = 0.3 W_{1t} + 0.4 W_{2t} + 0.3 W_{3t} + 0.5 e_{t} \ , \ t \in \{1,\ldots, T_0+T_1\} \ ,
\end{align*}
where $e_t$ are independently generated from a standard normal distribution. We consider $\potY{t}{0} = \potY{t}{1}$, i.e., no treatment effect. We remark that $\EXP \big\{ \potY{t}{0} \cond \bW_t \big\} = 0.3 W_{1t} + 0.4 W_{2t} + 0.3 W_{3t}$ is not a valid synthetic control for the SPSC framework because $\EXP \big\{ \potY{t}{0} - \big( 0.3 W_{1t} + 0.4 W_{2t} + 0.3 W_{3t} \big) \cond \potY{t}{0} \big\} \neq 0 $, thereby violating Assumption \ref{assumption:SC}. Therefore, the proposed conformal inference approach for the SPSC framework in Section \ref{sec:Conformal} may fail in this data generating process. 

For our methods, the time-invariant and time-varying pre-treatment estimating equations are given by
\begin{align*}
&
\Phi_{\pre} (\bO_t \con \bgamma)
= 
\bh(Y_t) \big( Y_t - \bW_t \T \bgamma \big) 
\ ,
\\
&
\Psi_{\pre} (\bO_t \con \Beta,  \bgamma)
=
\begin{bmatrix}
\bD_t \big( Y_t - \bD_t\T \Beta \big)
\\
\bg(t, Y_t \con \Beta) \big( Y_t - \bW_t \T \bgamma \big)
\end{bmatrix}
=
\begin{bmatrix}
\bD_t \big( Y_t - \bD_t\T \Beta \big)
\\
\begin{bmatrix}
\bD_t \\ \bh(Y_t - \bD_t\T \Beta)
\end{bmatrix}
\big( Y_t - \bW_t \T \bgamma \big)
\end{bmatrix} \ ,
\end{align*}
where $\bh(y) = y$ and $\bD_t 	= 	\mathcal{B}_6 (t) \in \R^{6} $ is the 6-dimensional cubic B-spline bases function. 

We repeat the simulation 500 times and calculate the empirical coverage rates of 95\% confidence intervals from these repetitions for each simulation scenario. The results are presented in Table \ref{tab:supp:Table10}. First, we find that the SCPI approach achieves the nominal coverage rate across all simulation scenarios in general. However, we find that the conformal inference approach for SPSC without time-varying components (i.e., SPSC-NoDT) fails to achieve the nominal coverage rate, especially when the autocorrelation coefficient is large (i.e., $\kappa=1$). We conjecture that the undercoverage observed in these cases may be attributed to the nonstationarity of $W_{it}$ and $\potY{t}{0}$. Nevertheless, even in these challenging cases, the conformal inference approach for SPSC with time-varying components (i.e., SPSC-DT) shows significant improvement, attaining the nominal coverage rate across all considered simulation scenarios. This result further confirms that accounting for time-varying components is both useful and necessary for improving the performance of the proposed conformal inference approach in the presence of nonstationarity. Second, regarding the length of the prediction intervals, the SPSC-DT estimator produces the shortest intervals when $\kappa=0$ and $\kappa=0.5$. For $\kappa=1$, the SCPI estimator yields the shortest intervals, although the SPSC-DT estimator remains highly competitive. 


\begin{table}[!htp]
\renewcommand{\arraystretch}{1.3} \centering
\scriptsize
\setlength{\tabcolsep}{3pt} 
\begin{tabular}{|c|c|ccccccccccccccc|}
\hline
\multirow{3}{*}{Statistics} & \multirow{3}{*}{Estimators} & \multicolumn{15}{c|}{$\kappa$ (second row) and $\zeta$ (third row)}                                                                                                                                                                                                                                                                                                                                                                                                             \\ \cline{3-17} 
&                             & \multicolumn{5}{c|}{0}                                                                                                                           & \multicolumn{5}{c|}{0.5}                                                                                                                       & \multicolumn{5}{c|}{1}                                                                                                         \\ \cline{3-17} 
&                             & \multicolumn{1}{c|}{-1}    & \multicolumn{1}{c|}{-0.5}  & \multicolumn{1}{c|}{0}     & \multicolumn{1}{c|}{0.5}    & \multicolumn{1}{c|}{1}      & \multicolumn{1}{c|}{-1}    & \multicolumn{1}{c|}{-0.5}  & \multicolumn{1}{c|}{0}     & \multicolumn{1}{c|}{0.5}   & \multicolumn{1}{c|}{1}     & \multicolumn{1}{c|}{-1}     & \multicolumn{1}{c|}{-0.5}   & \multicolumn{1}{c|}{0}      & \multicolumn{1}{c|}{0.5}    & 1      \\ \hline
\multirow{3}{*}{Coverage}   & SPSC-NoDT                   & \multicolumn{1}{c|}{0.958} & \multicolumn{1}{c|}{0.956} & \multicolumn{1}{c|}{0.964} & \multicolumn{1}{c|}{0.962}  & \multicolumn{1}{c|}{0.979}  & \multicolumn{1}{c|}{0.965} & \multicolumn{1}{c|}{0.957} & \multicolumn{1}{c|}{0.964} & \multicolumn{1}{c|}{0.967} & \multicolumn{1}{c|}{0.951} & \multicolumn{1}{c|}{0.860}  & \multicolumn{1}{c|}{0.860}  & \multicolumn{1}{c|}{0.851}  & \multicolumn{1}{c|}{0.847}  & 0.874  \\ \cline{2-17} 
& SPSC-DT                     & \multicolumn{1}{c|}{0.952} & \multicolumn{1}{c|}{0.954} & \multicolumn{1}{c|}{0.964} & \multicolumn{1}{c|}{0.962}  & \multicolumn{1}{c|}{0.974}  & \multicolumn{1}{c|}{0.961} & \multicolumn{1}{c|}{0.951} & \multicolumn{1}{c|}{0.952} & \multicolumn{1}{c|}{0.959} & \multicolumn{1}{c|}{0.943} & \multicolumn{1}{c|}{0.953}  & \multicolumn{1}{c|}{0.941}  & \multicolumn{1}{c|}{0.937}  & \multicolumn{1}{c|}{0.942}  & 0.947  \\ \cline{2-17} 
& SCPI                        & \multicolumn{1}{c|}{0.983} & \multicolumn{1}{c|}{0.971} & \multicolumn{1}{c|}{0.981} & \multicolumn{1}{c|}{0.978}  & \multicolumn{1}{c|}{0.986}  & \multicolumn{1}{c|}{0.980} & \multicolumn{1}{c|}{0.971} & \multicolumn{1}{c|}{0.979} & \multicolumn{1}{c|}{0.988} & \multicolumn{1}{c|}{0.976} & \multicolumn{1}{c|}{0.988}  & \multicolumn{1}{c|}{0.992}  & \multicolumn{1}{c|}{0.986}  & \multicolumn{1}{c|}{0.983}  & 0.991  \\ \hline
\multirow{3}{*}{Length}     & SPSC-NoDT                   & \multicolumn{1}{c|}{2.303} & \multicolumn{1}{c|}{2.317} & \multicolumn{1}{c|}{2.313} & \multicolumn{1}{c|}{2.321}  & \multicolumn{1}{c|}{2.325}  & \multicolumn{1}{c|}{2.445} & \multicolumn{1}{c|}{2.469} & \multicolumn{1}{c|}{2.462} & \multicolumn{1}{c|}{2.464} & \multicolumn{1}{c|}{2.449} & \multicolumn{1}{c|}{8.169}  & \multicolumn{1}{c|}{8.596}  & \multicolumn{1}{c|}{8.531}  & \multicolumn{1}{c|}{8.970}  & 8.346  \\ \cline{2-17} 
& SPSC-DT                     & \multicolumn{1}{c|}{2.283} & \multicolumn{1}{c|}{2.294} & \multicolumn{1}{c|}{2.292} & \multicolumn{1}{c|}{2.294}  & \multicolumn{1}{c|}{2.298}  & \multicolumn{1}{c|}{2.363} & \multicolumn{1}{c|}{2.381} & \multicolumn{1}{c|}{2.370} & \multicolumn{1}{c|}{2.370} & \multicolumn{1}{c|}{2.362} & \multicolumn{1}{c|}{3.547}  & \multicolumn{1}{c|}{3.576}  & \multicolumn{1}{c|}{3.553}  & \multicolumn{1}{c|}{3.508}  & 3.485  \\ \cline{2-17} 
& SCPI                        & \multicolumn{1}{c|}{2.546} & \multicolumn{1}{c|}{2.543} & \multicolumn{1}{c|}{2.582} & \multicolumn{1}{c|}{2.573}  & \multicolumn{1}{c|}{2.569}  & \multicolumn{1}{c|}{2.580} & \multicolumn{1}{c|}{2.569} & \multicolumn{1}{c|}{2.554} & \multicolumn{1}{c|}{2.588} & \multicolumn{1}{c|}{2.575} & \multicolumn{1}{c|}{2.985}  & \multicolumn{1}{c|}{2.999}  & \multicolumn{1}{c|}{2.966}  & \multicolumn{1}{c|}{2.962}  & 2.973  \\ \hline
\multirow{3}{*}{Bias}       & SPSC-NoDT                   & \multicolumn{1}{c|}{0.013} & \multicolumn{1}{c|}{0.012} & \multicolumn{1}{c|}{0.026} & \multicolumn{1}{c|}{-0.007} & \multicolumn{1}{c|}{-0.004} & \multicolumn{1}{c|}{0.047} & \multicolumn{1}{c|}{0.030} & \multicolumn{1}{c|}{0.007} & \multicolumn{1}{c|}{0.017} & \multicolumn{1}{c|}{0.005} & \multicolumn{1}{c|}{-0.064} & \multicolumn{1}{c|}{-0.042} & \multicolumn{1}{c|}{-0.063} & \multicolumn{1}{c|}{0.038}  & 0.082  \\ \cline{2-17} 
& SPSC-DT                     & \multicolumn{1}{c|}{0.015} & \multicolumn{1}{c|}{0.010} & \multicolumn{1}{c|}{0.025} & \multicolumn{1}{c|}{-0.002} & \multicolumn{1}{c|}{-0.005} & \multicolumn{1}{c|}{0.041} & \multicolumn{1}{c|}{0.028} & \multicolumn{1}{c|}{0.009} & \multicolumn{1}{c|}{0.011} & \multicolumn{1}{c|}{0.001} & \multicolumn{1}{c|}{0.014}  & \multicolumn{1}{c|}{-0.007} & \multicolumn{1}{c|}{0.004}  & \multicolumn{1}{c|}{-0.006} & -0.002 \\ \cline{2-17} 
& SCPI                        & \multicolumn{1}{c|}{0.009} & \multicolumn{1}{c|}{0.016} & \multicolumn{1}{c|}{0.026} & \multicolumn{1}{c|}{0.000}  & \multicolumn{1}{c|}{-0.005} & \multicolumn{1}{c|}{0.031} & \multicolumn{1}{c|}{0.028} & \multicolumn{1}{c|}{0.000} & \multicolumn{1}{c|}{0.001} & \multicolumn{1}{c|}{0.002} & \multicolumn{1}{c|}{0.009}  & \multicolumn{1}{c|}{-0.007} & \multicolumn{1}{c|}{0.019}  & \multicolumn{1}{c|}{-0.004} & -0.010 \\ \hline
\end{tabular}
\caption{Empirical Coverage Rates and Lengths of 95\% Pointwise Prediction Intervals.}
\label{tab:supp:Table10}
\end{table}







\subsection{Additional Results of the Data Analysis}		\label{sec:supp:Data}

In this Section, we provide additional results of the data analysis in Section \ref{sec:Data}. First,  Figure \ref{fig:supp:Diagnosis} presents graphical summaries of residuals $Y_t - \bW_t\T \widehat{\bgamma}$ over the pre-treatment periods. Note that the OLS-NoReg, SCPI, and SPSC-DT estimators produced residuals without a deterministic trend over time, while the other three estimators showed the opposite behavior. Notably, the SPSC-DT estimator appears to satisfy the zero mean condition of Assumption \ref{assumption:SC}, whereas the SPSC-NoDT estimator seems to violate this condition due to a non-zero deterministic trend over time. This again highlights the importance of accommodating time-varying components in the SPSC estimation procedure.


% Figure environment removed		




Next, we provide the width of the 95\% prediction intervals obtained from each method in Figure \ref{fig:supp:PI width}. We remark that the SPSC-DT estimator exhibits relatively stable prediction interval widths compared to the other two methods. It is important to highlight that the stable prediction interval width of the SPSC-DT estimator is specific to this particular dataset. Depending on the underlying data-generating process, the prediction interval width may exhibit greater variability over time. For instance, in some cases illustrated in Figure \ref{fig:supp:PI width wider}, prediction intervals tens to widen  as the post-treatment period progresses. Furthermore, Figure \ref{fig:supp:PI width wider} suggests that the width of the SPSC prediction intervals remains stable or shows only a slight increase when there is no systematic drift in the outcomes, but it tends to widen when such drift is present. This systematic drift can be empirically verified by examining the trend of the estimated synthetic control, $\bW_t\T \widehat{\bgamma}_{\rho}$.  As shown in Figure \ref{fig:data:1} of the main paper, the synthetic control does not exhibit a noticeable upward or downward trend. We hypothesize that this lack of trend explains the stable prediction interval width observed in Figure  \ref{fig:supp:PI width}.



% Figure environment removed		



Lastly, we provide the details of the placebo study. Figure \ref{fig:supp:Conformal Placebo} visually shows the synthetic controls under the placebo treatment. For the proposed SPSC approach, we find 95\% prediction intervals for $\potY{t}{0}$ include the true treatment-free potential outcome $\potY{t}{0}$ for all $T_1'=36$ placebo post-treatment periods. These results suggest that our SPSC approach seems reasonable for analyzing the effect of the 1907 panic on the stock price of the two trust companies. In contrast, the 95\% prediction intervals from the SCPI method cover the true treatment-free outcome for 29 placebo post-treatment periods, while the ASC estimator achieves coverage for only 17 periods.

% Figure environment removed		




Based on these additional analyses, we can further strengthen the causal conclusions established in the main paper especially those drawn from SPSC, i.e., the 1907 panic led to a decrease in the average log stock price of Knickerbocker and Trust Company of America. 

\newpage


\section{Nonparametric Single Proxy Synthetic Control Framework}		\label{sec:supp:nonparametric full}

\subsection{Overview} \label{sec:supp:nonparametric}

The SPSC framework can be generalized to the case in which the synthetic control is nonlinear and/or nonparametric, thus allowing the outcome to have arbitrary types such as binary, count, and continuous over a bounded interval. The estimation of inference of the synthetic control bridge function and the ATT is analogous to that established in the absence of covariates, so we suppress covariates for notational brevity. 

In Section \ref{sec:supp:Exist h}, sufficient conditions for the existence of the synthetic control bridge function $h^*$ is discussed. In Section \ref{sec:supp:Exist h}, we discuss sufficient conditions for the uniqueness of $h^*$ is discussed. Lastly, in Section \ref{sec:supp:nonparametric estimation}, we provide details about inference of the ATT without the uniqueness assumption. 

% The nonparametric identification of the synthetic control relies on the existence of the bridge function satisfying the following condition.
%\begin{assumption}[Existence of Nonparametric Bridge Function] \label{assumption:SC NP Cov}
%For all $t \in \{1,\ldots,T\}$, there exists a function $h^*: \R^d \rightarrow \R$ that satisfies $\potY{t}{0} = \EXP \big\{
%h^*(\bW_{ t})
%\cond
%\potY{t}{0}
%\big\}
%=
%0$ almost surely.
%\end{assumption}
%In words, there exists a function of donors $h^*$, possibly linear or nonlinear, of which conditional expectation given $\potY{t}{0}$ recovers $\potY{t}{0}$; the function $h^*$ is a kind of bridge functions \citep{TT2020_Intro, TTPR2023}, and we aptly refer to $h^*$ as the synthetic control bridge function in this paper. The synthetic control bridge function $h^*$ is a solution to a Fredholm integral equation of the first kind, and sufficient conditions for the existence of a solution are well studied in previous works such as \citet{Miao2018} and \citet{Cui2023}; see Section \ref{sec:supp:Exist h} of the Supplementary Material for details. We remark that Assumption \ref{assumption:SC} is a special case of Assumption \ref{assumption:valid proxy Cov} where the synthetic control bridge function is restricted to a linear form of $h( \bW_{ t} ) = \bW_{ t} \T \bgamma$. 
%
%Similar to the results established under the linear synthetic control, the synthetic control bridge function $h^*$ can be used as a basis for identifying the ATT; the following Theorem formally establishes the result.	
%\begin{theorem}	\label{thm:Extension NP}
%
%Under Assumptions \ref{assumption:consistency}--\ref{assumption:valid proxy} and \ref{assumption:valid proxy Cov}, the synthetic control bridge function $h^*$ satisfies the following equation:
%\begin{align}	\label{eq-Fredholm}
%\EXP \big\{ Y_t - h^*(\bW_{ t}) \cond Y_t \big\} = 0 \  \text{ almost surely} \ , \quad t \in \{1,\ldots,T_0\} \ .
%\end{align}
%Moreover, we have $
%\EXP \big\{ \potY{t}{0} - h^*(\bW_{ t}) \big\} = 0$ for any $t \in \{1,\ldots,T\}$. 
%Lastly, the ATT at time $t  \in \{ T_0+1,\ldots,T\}$ is identified as $\tau_t^*
%=
%\EXP
%\big\{
%Y_t - h^*(\bW_{ t}) 
%\big\}$. 	 
%\end{theorem}
%Theorem \ref{thm:Extension NP Cov} is a generalization of Theorems \ref{thm:SC} and \ref{thm:ATT} to nonparametric settings. If the synthetic control bridge function $h^*$ is unique, standard nonparametric or parametric estimation strategies can result in consistent estimators for $h^*$; the GMM estimator in Section \ref{sec:Estimation} is an example of the parametric estimation strategy. However, in general, the integral equation \eqref{eq-Fredholm} may have multiple solutions. Still, all solutions are valid synthetic controls and, consequently, result in the same ATT. When the bridge functions are not unique, we follow the approaches in \citet{Li2023} and \citet{Zhang2023} to obtain a nonparametric series estimator; see Section \ref{sec:supp:nonparametric estimation}. Given the synthetic control bridge function, the post-treatment residual process $Y_{t} - h^* (\bW_{ t})$ is equivalent to the ATT plus the post-treatment error, i.e., $Y_{t} - h^*(\bW_{ t}) = \tau_t^* + \epsilon_{t}$ where the ATT $\tau_t^*$ encodes the deterministic trend of the residual process via model $\tau_t^* = \tau(t \con \bbeta^*)$ and the error process $\epsilon_{t}$ satisfies the conditions in Assumption \ref{assumption:weakdep}. The estimation of the ATT parameter $\bbeta^*$ can be easily performed by following the results in the previous section with minor modifications.
%
%Lastly, we extend the results when exogenous covariates are available, which are parallel to Section \ref{sec:Cov}.
%
%
%\begin{assumption}[Existence of Bridge Function in the Presence of Covariates] \label{assumption:SC NP Cov} 
%For all $t \in \{1,\ldots,T\}$, there exists a function $h^*: \R^{d+q+dq} \rightarrow \R$ that satisfies $\potY{t}{0} = \EXP \big\{
%h^*(\bW_{ t}, \bX_{0t}, \bX_{ t} )
%\cond
%\potY{t}{0}, \bX_{0t}, \bX_{ t}
%\big\}$ almost surely.
%\end{assumption}	 
%
%\begin{theorem}	\label{thm:Extension NP Cov}
%
%Suppose Assumptions \ref{assumption:consistency}, \ref{assumption:noitf}, \ref{assumption:valid proxy Cov}, and \ref{assumption:valid proxy Cov} are satisfied. Then, the synthetic control bridge function $h^*$ satisfies $\EXP \big\{ Y_t - h^*(\bW_{ t}, \bX_{0t}, \bX_{ t}) \cond Y_t, \bX_{0t}, \bX_{ t} \big\} = 0$ for $t \in \{1,\ldots,T_0\}$. 	
%Moreover, we have $
%\EXP \big\{ \potY{t}{0} - h^*(\bW_{ t}, \bX_{0t}, \bX_{ t}) \big\} = 0$ for any $t \in \{1,\ldots,T\}$. 
%Lastly, the ATT at time $t  \in \{ T_0+1,\ldots,T\}$ is identified as $\tau_t^*
%=
%\EXP
%\big\{
%Y_t - h^*(\bW_{ t}, \bX_{0t}, \bX_{ t} ) 
%\big\}$. 	 
%\end{theorem}




\subsection{Sufficient Conditions for the Existence of the Synthetic Control Bridge Function} \label{sec:supp:Exist h}

In this Section, we provide sufficient conditions for the existence of the synthetic control bridge function $h^*$ satisfying Assumption \ref{assumption:valid proxy Cov}. We restate the assumption for readability after suppressing covariates:
\renewcommand{\theassumptionNew}{\ref{assumption:valid proxy Cov}}
\begin{assumptionNew}[Existence of Bridge Function in the Presence of Covariates] 
For all $t \in \{1,\ldots,T\}$, there exists a function $h^*: \R^{d} \rightarrow \R$ that satisfies 
\begin{align*}
\potY{t}{0} = \EXP \big\{
h^*(\bW_{ t} )
\cond
\potY{t}{0}
\big\} \ \ \text{almost surely} \ . 
\end{align*}
\end{assumptionNew}	

%Also, we focus on the case where $\potY{t}{0}$ and $\bW_t$ are stationary. In case $\potY{t}{0}$ and $\bW_t$ exhibit non-stationary behavior, say they have deterministic trends $\zeta_{Y,t}$ and $\bm{\zeta}_{W,t}$, respectively), then we may re-define $\widetilde{Y}_t^{(0)} := \potY{t}{0} - \zeta_{Y,t}$ and $\widetilde{\bW}_t\T := \bW_t - \bm{\zeta}_{W,t}$, and 


%Then, we find
%\begin{align*}
%&
%\exists \widetilde{h}^* \text{ s.t. }
%\widetilde{Y}_t^{(0)}   = \EXP \big\{
%\widetilde{h}^*( \widetilde{\bW}_t\T  )
%\cond
%\widetilde{Y}_t^{(0)} 
%\big\} 
%\\
%\Leftrightarrow
%\quad
%&
%\exists \widetilde{h}^* \text{ s.t. }
%\widetilde{Y}_t^{(0)} 
%+ \zeta_{Y,t}  = \EXP \big\{
%h^*( \widetilde{\bW}_t\T ) + \zeta_{Y,t}
%\cond
%\widetilde{Y}_t^{(0)} 
%+ \zeta_{Y,t}
%\big\} 
%\\
%\Leftrightarrow
%\quad
%&
%\exists h^* \text{ s.t. }
%Y_t^{(0)} 
%+ \zeta_{Y,t}  = \EXP \big\{
%h^*( {\bW}_t\T )
%\cond
%{Y}_t^{(0)}  
%\big\} 
%\end{align*}
%Where we defined $h^*(\bw):= \widetilde{h}^*(\bw-\bm{\zeta}_{W,t}) + \bm{\zeta}_{Y,t}$









In brief, we follow the approach in \citet{Miao2018}. The proof relies on Theorem 15.18 of \citet{Kress2014}, which is stated below for completeness.\\[0.25cm]
\noindent
\textbf{Theorem 15.18.} \citep{Kress2014}
Let $A:X \rightarrow Y$ be a compact operator with singular system $\big\{ \mu_n,\phi_n,g_n \big\}_{n \in \{1,2,\ldots\}}$. The integral equation of the first kind $A\phi = f$ is solvable if and only if 
\begin{align*}
& 1. \quad
\text{$f \in \mathcal{N}(A^{\text{adjoint}})^\perp = \big\{ f \, \big| \, A^{\text{adjoint}}(f) = 0 \big\}^{\perp}$}
\ , 
&&
2. \quad
\text{$\sum_{n=1}^{\infty} \mu_n^{-2} \big| \langle f,g_n \rangle |^2 < \infty$}
\end{align*}


To apply the Theorem, we introduce some additional notations. Let $\mathcal{L}_{W}$ and $\mathcal{L}_{ \potY{}{0} }$ be the spaces of square-integrable functions of $\bW_{ t}$ and $\potY{t}{0}$, respectively, which are equipped with the inner products $\langle h_1, h_2 \rangle_{W} = \int h_1(\bw) h_2(\bw) \, f_W (\bw) \, d\bw = \EXP \big\{ h_1(\bW_{ t}) h_2(\bW_{ t}) \big\} $ and $\langle g_1, g_2 \rangle_{\potY{}{0}} = \int g_1(y) g_2(y) \, f_{\potY{}{0}} (y) \, dy = \EXP \big\{ g_1(\potY{t}{0}) g_2(\potY{t}{0}) \big\} $, respectively. Let $\mathcal{K}: \mathcal{L}_{W} \rightarrow \mathcal{L}_{ \potY{}{0} }$ be the conditional expectation of $h(\bW_{ t} ) \in \mathcal{L}_{W}$ given $\potY{t}{0}$, i.e.,
\begin{align*}
\mathcal{K} (h) \in \mathcal{L}_{\potY{}{0}} 
\text{ satisfying }
\big( \mathcal{K}(h) \big) (y) 
=
\EXP \big\{ h(\bW_{ t}) \cond \potY{t}{0}=y \big\}
\text{ for } h \in \mathcal{L}_{W}
\end{align*}
Then, the synthetic control bridge function $h^* \in \mathcal{L}_{W}$ solves $\mathcal{K} ( h^* ) = [\text{identity map}] \in \mathcal{L}_{\potY{}{t}} $, i.e., 
\begin{align*}
\int h^*(\bw) f_{W | \potY{}{0} } (\bw \cond y ) \, d\bw = y , \ \forall y
\end{align*}


Now, we assume the following conditions:
\begin{itemize}[leftmargin=1cm, itemsep=0cm]
\item[] \HT{NPSC-1} The variables $(\potY{t}{0} , \bW_{ t})$ are stationary; 
\item[] \HT{NPSC-2} $\iint
f_{W | \potY{}{0} } (\bw \cond y )
f_{\potY{}{0} | W } (y \cond \bw )
\, d\bw \, d y
< \infty$;
\item[] \HT{NPSC-3} For $g \in \mathcal{L}_{\potY{}{0}}$, $\EXP \big\{ g(\potY{t}{0}) \cond \bW_{ t} \big\} = 0$ implies $g(\potY{t}{0})= 0$ almost surely;
\item[] \HT{NPSC-4} $\EXP \big[ \big\{ \potY{t}{0} \big\}^2 \big] < \infty$;
\item[] \HT{NPSC-5} Let the singular system of $\mathcal{K}$ be $\big\{ \mu_n,\phi_n,g_n \big\}_{n \in \{1,2,\ldots\}}$. \\Then, we have $\sum_{n=1}^{\infty} \mu_n^{-2} \big| \langle \potY{t}{0} ,g_n \rangle |^2 < \infty$.
\end{itemize}

We remark that the expectation can be defined without using $t$ under Condition \HL{NPSC-1}. First, we show that $\mathcal{K}$ is a compact operator under Condition \HL{NPSC-2}. Let $\mathcal{K}^{\text{adjoint}} : \mathcal{L}_{\potY{}{0}} \rightarrow \mathcal{L}_{W}$ be the conditional expectation of $g(\potY{t}{0}) \in \mathcal{L}_{\potY{}{0}}$ given $\bW_{ t}$, i.e., 
\begin{align*}
\mathcal{K}^{\text{adjoint}} (g) \in \mathcal{L}_{W} 
\text{ satisfying }
\big( \mathcal{K}(g) \big) (\bw) 
=
\EXP \big\{ g(\potY{t}{0}) \cond \bW_{ t}=\bw \big\}
\text{ for } g \in \mathcal{L}_{\potY{}{0}}
\end{align*}
Then, $\mathcal{K}$ and $\mathcal{K}^{\text{adjoint}}$ are the adjoint operator of each other as follows:
\begin{align*}
\langle \mathcal{K}(h) , g \rangle_{\potY{}{0}}
& =
\EXP
\big[
\EXP \big\{ h(\bW_{ t}) \cond \potY{t}{0} \big\}
g(\potY{t}{0})
\big]	
\\
& 
=
\EXP
\big[
h(\bW_{ t}) g(\potY{t}{0})
\big]	
\\
&
=
\EXP
\big[
h(\bW_{ t}) \EXP \big\{ g(\potY{t}{0}) \cond \bW_{ t} \big\}
\big]	
=
\langle h , \mathcal{K}^{\text{adjoint}}(g) \rangle_{W}
\end{align*}
Additionally, as shown in page 5659 of \citet{Carrasco2007}, $\mathcal{K}$ and $\mathcal{K}^{\text{adjoint}}$ are compact operators under Condition \HL{NPSC-2}. Moreover, by Theorem 15.16 of \citet{Kress2014}, there exists a singular value decomposition of $\mathcal{K}$ as $\big\{ \mu_n,\phi_n,g_n \big\}_{n \in \{1,2,\ldots\}}$. 

Second, we show that $\mathcal{N}(\mathcal{K}^{\text{adjoint}})^\perp = \mathcal{L}_{\potY{}{0}}$, which suffices to show $\mathcal{N}(\mathcal{K}^{\text{adjoint}}) = \big\{ 0 \big\} \subseteq \mathcal{L}_{\potY{}{0}}$. Under Condition \HL{NPSC-3}, we have 
\begin{align*}
g \in \mathcal{N}(\mathcal{K}^{\text{adjoint}})
\quad 
\Rightarrow 
\quad 
\EXP \big\{ g (\potY{t}{0}) \cond \bW_{ t} = \bw \big\}
=
0, \ \forall \bw
\quad \Rightarrow
\quad
g(\potY{t}{0}) = 0 
\end{align*}
where the first arrow is from the definition of the null space $\mathcal{N}$, and the second arrow is from Condition \HL{NPSC-3}. Therefore, any $g \in \mathcal{N}(\mathcal{K}^{\text{adjoint}})$ must satisfy $g(y) = 0 $ almost surely, i.e., $\mathcal{N}(\mathcal{K}^{\text{adjoint}})= \big\{ 0 \big\} \subseteq \mathcal{L}_{\potY{}{0}}$ almost surely. 

Third, from the definition of $\mathcal{L}_{W}$, $g(\potY{t}{0}) = \potY{t}{0} \in \mathcal{L}_{\potY{}{0}} = \mathcal{N}(\mathcal{K}^{\text{adjoint}})^\perp $ under Condition \HL{NPSC-4}. 


Combining the three results, we establish that $\potY{t}{0}$ satisfies the first condition of Theorem 15.18 of \citet{Kress2014}. The second condition of the Theorem is exactly the same as Condition \HL{NPSC-5}. Therefore, we establish that the Fredholm integral equation of the first kind $\mathcal{K} ( h ) = [\text{identity map}] $ is solvable under Conditions \HL{NPSC-1}-\HL{NPSC-5}.

Note that Conditions \HL{NPSC-1} through \HL{NPSC-5} are sufficient but not necessary. In particular, it is possible to conceive of a scenario where a synthetic control bridge function exists even without the stationarity assumption \HL{NPSC-1}. However, this generally requires an additional assumption on the data generating process for $(\potY{t}{0},\bW_t)$ (e.g., IFEM) and the form of $h^*$ (e.g., linearity) to ensure stationary behavior in $\potY{t}{0}-h^*(\bW_t)$; see Section \ref{sec:supp:IFEM} for a specific example. As a result, case-specific models and assumptions are needed to account for non-stationary behavior in the outcomes. Since the purpose of this section is to demonstrate the possibility of relaxing the linearity of the synthetic control bridge function under stationarity, we do not further explore other cases without stationarity here. We intend to pursue this direction in future research.




\subsection{Uniqueness of Synthetic Control Bridge Function Under Completeness}		\label{sec:supp:NP Unique}

%In Section \ref{sec:Cov}, we showed that \eqref{eq-Fredholm} is satisfied Assumptions \ref{assumption:consistency}, \ref{assumption:noitf}, \ref{assumption:valid proxy Cov}, and \ref{assumption:valid proxy Cov}; for readability, we restate Assumption \ref{assumption:valid proxy Cov} and \eqref{eq-Fredholm} below:
%\renewcommand{\theassumptionNew}{\ref{assumption:valid proxy Cov}}
%\begin{assumptionNew}[Existence of Bridge Function in the Presence of Covariates] 
%For all $t \in \{1,\ldots,T\}$, there exists a function $h^*: \R^{d} \rightarrow \R$ that satisfies 
%\begin{align*}
%\potY{t}{0} = \EXP \big\{
%h^*(\bW_{ t}  )
%\cond
%\potY{t}{0} 
%\big\} \ \ \text{almost surely} \ . 
%\end{align*}
%\end{assumptionNew}	
%and
%\begin{align}
%\EXP \big\{ Y_t - h^*(\bW_{ t} ) \cond Y_t  \big\} = 0 \ .
%\tag{\ref{eq-Fredholm}}
%\end{align}
%
%In this section, we show the reverse is satisfied. 
%Suppose a function $h^*$ satisfies \eqref{eq-Fredholm}. Then, we obtain the following result for $t \in \{1,\ldots,T_0\}$:
%\begin{align*}
%y 
%& =
%\EXP \big\{ h^* ( \bW_{ t} ) \cond Y_t=y \big\} 
%=
%\EXP \big\{ h^* (\bW_{ t}) \cond \potY{t}{0} = y \big\} \ ,
%\end{align*} 
%where the second equality holds from Assumption \ref{assumption:consistency}. 
%Therefore, $h^*$ satisfies Assumption \ref{assumption:valid proxy Cov}. 

We provide a sufficient condition for the uniqueness of the bridge function. Consider the following completeness assumption:
\begin{assumption}[Completeness] \label{assumption-complete}
For $t \in \{1,\ldots,T\}$, suppose $\EXP \big\{ q(\bW_{ t}) \cond \potY{t}{0} \big\} = 0$ almost surely for a square integrable function $q$. Then, $q(\bW_{ t} ) = 0$ almost surely for $t \in \{1,\ldots,T\}$.
\end{assumption}
The assumption states that $\potY{t}{0}$ should be $\bW_{ t}$-relevant for all time periods in the sense that any variation in $\bW_{ t}$ is captured by variation in $\potY{t}{0}$. 

Let $h_1^*$ and $h_2^*$ be the synthetic control bridge functions satisfying Assumptions \ref{assumption:consistency}, \ref{assumption:noitf}, \ref{assumption:valid proxy Cov}, and \ref{assumption:valid proxy Cov}, and \ref{assumption-complete}. We then find $\EXP \big\{ h_1^*(\bW_{ t}) - h_2^*(\bW_{ t}) \cond \potY{t}{0} \big\} = 0$, implying $h_1^*(\bW_{ t})$ and $h_2^*(\bW_{ t}) = 0$ for all $t$, implying that a function $h^*$ satisfying \ref{assumption:valid proxy Cov} is unique. 

We remark that Assumption \ref{assumption-complete} may not be satisfied if the cardinality of the support of $\bW_{ t}$ is strictly larger than that of $\potY{t}{0}$. For instance, suppose that the outcomes are binary and two donors are available, i.e., $\bW_{ t} \in \{0,1\}^2$ and $\potY{t}{0} \in \{0,1\}$. Then, the equation in Assumption \ref{assumption-complete} reduces to
\begin{align} \label{eq-underdetermine}
\begin{bmatrix}
p_{W|Y}( 0,0 \cond 0)
&
p_{W|Y}( 0,1 \cond 0)
&
p_{W|Y}( 1,0 \cond 0)
&
p_{W|Y}( 1,1 \cond 0)
\\
p_{W|Y}( 0,0 \cond 1)
&
p_{W|Y}( 0,1 \cond 1)
&
p_{W|Y}( 1,0 \cond 1)
&
p_{W|Y}( 1,1 \cond 1)
\end{bmatrix}
\begin{bmatrix}
q(0,0) \\ q(0,1) \\ q(1,0) \\ q(1,1) 
\end{bmatrix}
=
\begin{bmatrix}
0 \\ 0
\end{bmatrix}
\end{align}
where $p_{W|Y}(a,b \cond y) = \Pr\{ \bW_{ t}=(a,b) \cond \potY{t}{0} = y \}$. Since \eqref{eq-underdetermine} is an underdetermined system, there are multiple non-zero $q$ functions satisfying \eqref{eq-underdetermine}, indicating that Assumption \ref{assumption-complete} cannot be satisfied. 

In the following section, we introduce a nonparametric SPSC framework that accommodates non-unique synthetic control bridge functions.










\subsection{Single Proxy Synthetic Control Approach without the Uniqueness Assumption}		\label{sec:supp:nonparametric estimation}




The synthetic control bridge function $h$ is defined as a function satisfying \eqref{eq-Fredholm}; we restate the equation below for readability.
\begin{align}		\label{eq-Fredholm2}
\EXP \big\{ Y_t - h^*(\bW_{ t}) \cond Y_t \big\} = 0 \text{ almost surely} \ , \quad t \in \{1,\ldots,T_0\} \ .
\tag{\ref{eq-Fredholm}}
\end{align}
We consider the case where there are multiple synthetic control bridge functions $h$ satisfying \eqref{eq-Fredholm2}. Even so, identification of the ATT established in Theorem \ref{thm:Extension NP Cov} is satisfied regardless of the choice of the bridge function. However, estimation and inference of the ATT can be complicated in the presence of multiple synthetic control bridge functions. To resolve this issue, we use approaches proposed by a series of recent works \citep{Li2023, Zhang2023}. In brief, their approaches involve the following three stages. In the first stage, we estimate a set of synthetic control bridge functions based on a sieve estimator; see Stage 1 below. In the second stage, we define a criterion function, denoted by $M$, and focus on the estimation of the minimizer of $M$, denoted by $h_0$. Then, an estimator of the ATT can be constructed based on the estimator of $h_0$; see Stage 2 below. In the third stage, we consider a de-biasing procedure for the estimator obtained in the previous stage to attain the asymptotic normality; see Stage 3 below. The following sections present details under general nonparametric settings, but the method can be applied to the parametric synthetic controls, including cases where there are multiple synthetic control weights that satisfy Assumption \ref{assumption:SC}. We have included only the essential assumptions and notations in this work to ensure clarity. We refer the readers to \citet{Li2023} and \citet{Zhang2023} for additional details.\\[0.25cm]

\noindent \textbf{Stage 1}: Estimation of the Solution Set $\mathcal{H}_0$ \\

Let $\mathcal{H}$ be a collection of user-specified smooth functions, and let $\mathcal{H}_0$ be the collection of the solutions of \eqref{eq-Fredholm2}, i.e.,
\begin{align*}
\mathcal{H}_0
=
\Big\{ h \in \mathcal{H} \, \Big| \,
Y_t = \EXP \big\{ h(\bW_{ t}) \cond Y_t \big\}, \ t \in \{1,\ldots,T_0\}
\Big\}
\end{align*}
Alternatively, we can represent $\mathcal{H}_0$ using a criterion function. Let $\mathfrak{C}: \mathcal{H} \rightarrow \R$ be a criterion function having the following form:
\begin{align*}
\mathfrak{C} (h)
=
\EXP
\Big[
\big[
Y_t
-
\EXP \big\{ h(\bW_{ t}) \cond Y_t \big \}
\big]^2
\Big] 
\ , \ t \in \{1,\ldots,T_0\}
\ .
\end{align*}
It is straightforward to check that $\mathcal{H}_0 = \big\{ h \in \mathcal{H} \cond \mathfrak{C}(h) = 0 \big\}$.

We consider a sieve approach as follows. First, we choose a sequence of approximating bases functions of $\bW_{ t}$, denoted by $\big\{ \varphi_k(\bw) \big\}_{k \in \{1,2,\ldots\}}$. For this sequence, we define an approximating function space for $\mathcal{H}$ by using the first $k_T$ bases functions, i.e.,
\begin{align*}
\mathcal{H}_T
=
\bigg\{
h \in \mathcal{H}
\, \bigg| \,
h(\bw)
=
\sum_{\ell=1}^{k_T}
b_{\ell} \varphi_{\ell}(\bw) 
\bigg\} \ ,
\end{align*}
where $k_T$ is a known parameter and $b_1,\ldots,b_{k_T}$ are unknown scalar parameters.

A sample analogue of the criterion function $\mathfrak{C}$, denoted by $\mathfrak{C}_T$, can be obtained based on the sieve approach. We choose a sequence of approximating bases functions of $\potY{t}{0}$, denoted by $ \big\{ \phi_k (y) \big\}_{k \in \{1,2,\ldots\}}$. Then, we choose the first $k_T$ bases function and construct a $k_T$-dimensional function of $y$, denoted by $\bphi (y) = \big\{ \phi_1(y),\ldots,\phi_{k_T}(y) \big\}\T$. Using the pre-treatment observations, we construct a $(T_0 \times k_T)$ matrix as follows:
\begin{align*}
\Phi_{\pre}
=
\begin{bmatrix}
\bphi \T (Y_1)
\\
\vdots
\\
\bphi \T (Y_{T_0})
\end{bmatrix} 
\in \R^{T_0 \times k_T}
\ .
\end{align*}
For a given function $h$, a sieve estimator of the conditional expectation $\EXP \big\{ h(\bW_{ t}) \cond Y_t \big\}$ for $t \in \{1,\ldots,T_0\}$ can be obtained by regressing $h(\bW_{ t})$ on $ \bphi(Y_t) $, i.e., 
\begin{align*}
\widehat{\mu}_{\pre} (y \con h)
=
\texttt{sieve}
\Big(
\EXP \big\{ h(\bW_{ t}) \cond Y_t = y \big\}
\Big)
=
\bphi \T (y)
\big( \Phi_{\pre} \T \Phi_{\pre} \big)^{-1}
\bigg\{
\sum_{t=1}^{T_0}
h(\bW_{ t}) \bphi(Y_t)
\bigg\} \ .
\end{align*}
Therefore, $\mathfrak{C}_T$ can be obtained based on a sieve estimator, i.e.,
\begin{align*}
\mathfrak{C}_T (h)
=
\frac{1}{T_0} \sum_{t=1}^{T_0} 
\Big\{
Y_t
-
\widehat{\mu}_{\pre} (Y_t \con h)
\Big\}^2
\end{align*}
The proposed estimator of $\mathcal{H}_0$ is 
\begin{align*}
\widehat{\mathcal{H}}_0 = \Big\{ h \in \mathcal{H}_T \Cond \mathfrak{C}_T(h) \leq c_T \Big\} 
\end{align*}
where $c_T$ is an appropriately chosen sequence with $c_T \rightarrow 0$ as $T \rightarrow \infty$. Under regularity conditions, we have
\begin{align*}
d_{H} \big(\widehat{\mathcal{H}}_0, {\mathcal{H}}_0 , \big\| \cdot \big\|_{\infty} \big) = o_P(1)
\end{align*}
where $d_{H} (\mathcal{H}_1,\mathcal{H}_2, \big\| \cdot \big\| )$ is the Hausdorff distance between $\mathcal{H}_1$ and $\mathcal{H}_2$ with respect to a given norm $\big\| \cdot \big\|$; see Section 3.2 of \citet{Li2023} and Section 3.2 of \citet{Zhang2023} for details. \\



\noindent \textbf{Stage 2}: A Representer-based Estimator \\

After obtaining a consistent set estimator of $\mathcal{H}_0$ (i.e., $\widehat{\mathcal{H}}_0$), we select an estimator of $h$ from $\widehat{\mathcal{H}}_0$ so that it converges to a unique element in $\mathcal{H}_0$. Specifically, we define a function $M : \mathcal{H} \rightarrow \R$ that has a unique minimum $h_0$ on $\mathcal{H}_0$. Let $M_T$ be its sample analogue, and let $\widehat{h}_0$ be the minimum of $M_T(h)$ over $\widehat{\mathcal{H}}_0$, i.e.,
\begin{align*}
\widehat{h}_0 \in \argmin_{h \in \widehat{\mathcal{H}}_0} M_T(h) \ . 
\end{align*}
To obtain a unique minimum $\widehat{h}_0$, $\mathcal{H}$ and $M$ are chosen to satisfy the following assumption:
\begin{assumption} The following conditions are satisfied:
\begin{itemize}[leftmargin=1cm, itemsep=0cm]
\item[1.] The set $\mathcal{H}$ is convex;
\item[2.] The functional $M: \mathcal{H} \rightarrow \R$ is strictly convex, and have a unique minimum at $h_0$ on $\mathcal{H}_0$;
\item[3.] The sample analogue $M_T : \mathcal{H} \rightarrow \R$ is continuous and $\sup_{h \in \mathcal{H}} \big| M_T(h) - M(h) \big| = o_P(1)$.
\end{itemize}
\end{assumption}
Possible choices for $M$ and its sample analogue $M_T$ are 
\begin{align*}
&
M(h)
=
\EXP \big[ \big\{ h(\bW_{ t} ) \big\}^2 \big]
\ , \ t \in \{1,\ldots,T_0\}
\ , 
&&
M_T (h)
=
\frac{1}{T_0}
\sum_{t=1}^{T_0}
\big\{ h(\bW_{ t} ) \big\}^2
\end{align*}
Under regularity conditions, we have $\big\| \widehat{h}_0 - h_0 \big\|_{\infty} = o_P(1)$; see Theorem 3 of \citet{Li2023} and Proposition 3.2 of \citet{Zhang2023} for details. In turn, we obtain an estimator of the ATT as $\widehat{\tau}_t = Y_t - \widehat{h}_0(\bW_{ t})$ for $t \in \{T_0+1,\ldots,T\}$ where inference based on $\widehat{\tau}_t$ can be established by the conformal inference in Section \ref{sec:Conformal} in the Supplementary Material. Alternatively, we may posit a parametric form for the ATT as $\tau_t = \tau(t \con \bbeta)$. Considering $\widehat{h}_0$ as a fixed function, an estimator of $\bbeta$ can be obtained as a solution to the following equation:
\begin{align}	
&
\widehat{\bbeta} \text{ solves }
\frac{1}{T_1}
\sum_{t=T_0+1}^{T}
{\Psi}_{\post} (\bO_t \con \bbeta, \widehat{h}_0)
= 0
\ , 
\label{eq-betahat}
\\
&
{\Psi}_{\post} (\bO_t \con \bbeta, h)
=
\frac{\partial \tau(t \con \bbeta) }{\partial \bbeta}
\Big\{ Y_t - \tau(t \con {\bbeta}) - h (\bW_{ t} ) \Big\}
\in \R^{\text{dim}(\bbeta)}
\ , \ 
t \in \{T_0+1,\ldots,T\}
\ .
\label{eq-supp-postEE}
\end{align}
To characterize the asymptotic property of $\widehat{\bbeta}$, we additionally define the following objects. Let $\langle h_1, h_2 \rangle_w$ be
\begin{align*}
\langle h_1, h_2 \rangle_w
=
\EXP \big[
\EXP \big\{ h_1(\bW_{ t}) \cond \potY{t}{0} \big\}
\EXP \big\{ h_2(\bW_{ t}) \cond \potY{t}{0} \big\} 
\big] \ , \
t \in \{T_0+1,\ldots,T\} \ ,
\end{align*}
and $\overline{\mathcal{H}}$ be the closure of the linear span of $\mathcal{H}$ under $\big\| \cdot \big\|_w$. Then, we assume the following conditions.
\begin{assumption} 	\label{assumption:supp:g}
The following conditions are satisfied:
\begin{itemize}[leftmargin=1cm, itemsep=0cm]
\item[1.] For any $h \in \overline{\mathcal{H}}$, there exists a function $g_{0,h} \in \mathcal{H}$ satisfying $\langle g_{0,h}, h \rangle_w = \EXP \big\{ h(\bW_{ t}) \big\}$ for $t \in \{T_0+1,\ldots,T\}$. 
\item[2.] There exists a projection of $\mathcal{H}$ on $\mathcal{H}_T$, denoted by $\Pi_{T}: \mathcal{H} \rightarrow \mathcal{H}_T$, which satisfies
\begin{align*}
\sup_{h \in \mathcal{H}} \big\| h - \Pi_T h \big\| = O(\eta_T) \ .
\end{align*}
where $\eta_T=o(1)$ satisfies regularity conditions; see Assumptions 7-10 of \citet{Li2023} and Assumptions 4-7 of \citet{Zhang2023} for details.
\end{itemize}

\end{assumption}
We now characterize the asymptotic representation of $T_1^{1/2}
\big( \widehat{\bbeta} - \bbeta^* \big)$ under regularity conditions including stationarity and independent errors. Applying a first-order Taylor expansion, we find
\begin{align*}
0 
&
= 
\frac{1}{T_1} \sum_{t=T_0+1}^{T} {\Psi}_{\post} (\bO_t \con \widehat{\bbeta}, \widehat{h}_0)
\\
&
=
\frac{1}{T_1} \sum_{t=T_0+1}^{T}
\Bigg\{ {\Psi}_{\post} (\bO_t \con \bbeta^*, \widehat{h}_0)
+
\frac{\partial {\Psi}_{\post} (\bO_t \con \bbeta, \widehat{h}_0) }{\partial \bbeta\T} \bigg|_{\bbeta=\bbeta^*}
\cdot \big( \widehat{\bbeta} - \bbeta^* \big)
\Bigg\}
+
o_P(1) \ .
\end{align*}
Therefore, we find that \eqref{eq-betahat} has the following asymptotic representation for $t \in \{T_0+1,\ldots,T\}$:
\begin{align}
&
\sqrt{T_1} 
\big( \widehat{\bbeta} - \bbeta^* \big)
\nonumber
\\
& 
= 
\bigg[ 
\underbrace{
\frac{1}{T_1} \sum_{t=T_0+1}^{T} 
\frac{\partial {\Psi}_{\post} (\bO_t \con \bbeta, \widehat{h}_0) }{\partial \bbeta\T} \bigg|_{\bbeta=\bbeta^*} 
}_{=: V (\bbeta^*, \widehat{h}_0) }
\bigg]^{-1}
\nonumber 
\\
& \hspace*{1cm} \times 
\bigg[ \frac{1}{\sqrt{ T_1} } \sum_{t=T_0+1}^{T} 
\frac{\partial \tau(t \con \bbeta^*)}{\partial \bbeta}
\Big\{
Y_t - \tau(t \con {\bbeta}^*) - \widehat{h}_0(\bW_{ t} )
\Big\}
\bigg]
+
o_P(1)
\nonumber
\\
& 
=
V^{-1} (\bbeta^*, \widehat{h}_0)
\bigg[ \frac{1}{\sqrt{ T_1} } \sum_{t=T_0+1}^{T} 
\frac{\partial \tau(t \con \bbeta^*)}{\partial \bbeta}
\Big\{
Y_t 
- \tau(t \con \bbeta^*)
- \widehat{h}_0(\bW_{ t} )
\Big\}
\bigg]
+
o_P(1)
\nonumber
\\
& 
=
V^{-1} (\bbeta^*, \widehat{h}_0)
\bigg[ \frac{1}{\sqrt{ T_1} } \sum_{t=T_0+1}^{T} 
\frac{\partial \tau(t \con \bbeta^*)}{\partial \bbeta}
\Big\{
Y_t 
- \tau(t \con \bbeta^*)
- h_0(\bW_{ t}) 
\Big\}
\bigg]
\label{eq-supp-Asymp1}
\\
&
\quad +
V^{-1} (\bbeta^*, \widehat{h}_0)
\bigg[ \frac{1}{\sqrt{ T_1} } \sum_{t=T_0+1}^{T} 
\frac{\partial \tau(t \con \bbeta^*)}{\partial \bbeta}
\Big[
\EXP \big\{ h_0(\bW_{ t}) - \widehat{h}_0(\bW_{ t} ) \big\} 
\Big]
\bigg]
\label{eq-supp-Asymp2}
\\
&
\quad +
V^{-1} (\bbeta^*, \widehat{h}_0)
\Bigg[ \frac{1}{\sqrt{ T_1} } \sum_{t=T_0+1}^{T} 
\frac{\partial \tau(t \con \bbeta^*)}{\partial \bbeta}
\Bigg[
\begin{array}{l}
\big\{ h_0(\bW_{ t})
- \widehat{h}_0(\bW_{ t} )
\big\}
\\
- \EXP \big\{ h_0(\bW_{ t}) - \widehat{h}_0(\bW_{ t} ) \big\}
\end{array} 
\Bigg]
\Bigg]
\label{eq-supp-Asymp3}
\\
&
\quad
+
o_P(1) 
\nonumber
\ .
\end{align}
Following Theorem 4 of \citet{Li2023} and Supplementary Material of \citet{Zhang2023}, we establish that \eqref{eq-supp-Asymp3} is $o_P(1)$. In addition, for $t \in \{T_0+1,\ldots,T\}$, the numerator of \eqref{eq-supp-Asymp2} is equal to
\begin{align}
& 
\frac{1}{\sqrt{ T_1} } \sum_{t=T_0+1}^{T} 
\frac{\partial \tau(t \con \bbeta^*)}{\partial \bbeta}
\EXP \big\{ h_0(\bW_{ t}) - \widehat{h}_0(\bW_{ t} ) \big\} 
\nonumber
\\
&=
-
\frac{1}{\sqrt{ T_1} } \sum_{t=T_0+1}^{T} 
\frac{\partial \tau(t \con \bbeta^*)}{\partial \bbeta}
\EXP \big\{ g_{0,h_0} (\bW_{ t}) \cond \potY{t}{0} \big\} 
\big\{ \potY{t}{0} - h_0(\bW_{ t} ) \big\}
\nonumber
\\
&
\quad
+
\frac{1}{\sqrt{ T_1} } \sum_{t=T_0+1}^{T} 
\frac{\partial \tau(t \con \bbeta^*)}{\partial \bbeta}
\widehat{\EXP} \big\{ \Pi_T g_{0,h_0} (\bW_{ t}) \cond \potY{t}{0} \big\} 
\big[ \potY{t}{0} - \widehat{\EXP} \big\{ \widehat{h}_0(\bW_{ t}) \cond \potY{t}{0} \big\} \big]
+
o_P(1)	
\label{eq-asymptotic rep}
\ .
\end{align}
Here, $g_{0,h}$ and its projection $\Pi_T g_{0,h}$ are chosen to satisfy Assumption \ref{assumption:supp:g}, and $\widehat{\EXP}$ is a generic estimator of the conditional expectation operator of the distribution $\bW_{ t} | \potY{t}{0}$ having a fast convergence rate; see Stage 3 below for details on how these estimators are constructed. Combining all results, we have the following result for $t \in \{T_0+1,\ldots,T\}$:
\begin{align*}
&
\sqrt{T_1} 
\big( \widehat{\bbeta} - \bbeta^* \big)
\\
&
=
V^{-1} (\bbeta^*, \widehat{h}_0)
\bigg[ \frac{1}{\sqrt{ T_1} } \sum_{t=T_0+1}^{T} 
\frac{\partial \tau(t \con \bbeta^*)}{\partial \bbeta}
\left[ 
\begin{array}{l}
Y_t 
- \tau(t \con \bbeta^*)
- h_0(\bW_{ t}) 
\\
-
\EXP \big\{ g_{0,h_0} (\bW_{ t}) \cond \potY{t}{0} \big\}
\big\{ \potY{t}{0} - h_0(\bW_{ t} ) \big\} 
\end{array}
\right]
\bigg]
\\
&
\quad
+
V^{-1} (\bbeta^*, \widehat{h}_0)
\sqrt{T_1}
r_T(\widehat{h}_0)
+
o_P(1)
\end{align*}
where
\begin{align*}
r_T(\widehat{h}_0)
= 
\frac{1}{ T_1 } \sum_{t=T_0+1}^{T} 
\frac{\partial \tau(t \con \bbeta^*)}{\partial \bbeta}
\widehat{\EXP} \big\{ \Pi_T g_{0,h_0} (\bW_{ t}) \cond \potY{t}{0} \big\} 
\big[ \potY{t}{0} - \widehat{\EXP} \big\{ \widehat{h}_0(\bW_{ t}) \cond \potY{t}{0} \big\} \big] \ .
\end{align*}

\noindent\textbf{Stage 3}: A De-biased Estimator\\

To obtain the asymptotic normality of $\widehat{\bbeta}$, we need to de-bias $\widehat{\bbeta}$ by subtracting an estimated value of $r_T(\widehat{h}_0)$. To do so, we define a new criterion function and its sample analogue for $h \in \mathcal{H}$ as follows:
\begin{align*}
&
\mathcal{R} (h)
=
\EXP \Big[ \big[ \EXP \big\{ h(\bW_{ t}) \cond \potY{t}{0} \big\} \big]^2 \Big]
-
2 \EXP \big\{ h(\bW_{ t}) \big\}
\ , \ 
t \in \{T_0+1,\ldots,T\} \ ,
\\
&
\mathcal{R}_T (h)
=
\frac{1}{T_1} \sum_{t=T_0+1}^{T}
\big[ \widehat{\EXP} \big\{ h(\bW_{ t}) \cond \potY{t}{0} \big\} \big]^2
-
\frac{2}{T_1} \sum_{t=T_0+1}^{T} h(\bW_{ t}) \ .
\end{align*}
We obtain an estimator of $\Pi_T g_{0,h_0}$, denoted by $\widehat{g}$, as 
\begin{align*}
\widehat{g} \in \argmin_{\widehat{h}_0 \in \mathcal{H} } \mathcal{R}_T(\widehat{h}_0)
\end{align*}
and the resulting estimator of $r_T(\widehat{h}_0)$ is
\begin{align*}
\widehat{r}_T^{\text{inf}}(\widehat{h}_0)
= 
\frac{1}{ T_1 } \sum_{t=T_0+1}^{T} 
\frac{\partial \tau(t \con \widehat{\bbeta})}{\partial \bbeta}
\widehat{\EXP} \big\{ \widehat{g} (\bW_{ t}) \cond \potY{t}{0} \big\} 
\big[ \potY{t}{0} - \widehat{\EXP} \big\{ \widehat{h}_0(\bW_{ t}) \cond \potY{t}{0} \big\} \big] \ , \ 
t \in \{T_0+1,\ldots,T\} \ .
\end{align*}
Unfortunately, the above estimator $	\widehat{r}_T^{\text{inf}}$ is infeasible because it involves with counterfactual outcomes. Therefore, we use $Y_t - \tau(t \con \widehat{\bbeta}) $ as realizations of the treatment-free potential outcomes $\potY{t}{0}$ and construct a $(T_1 \times k_T)$ matrix as follows:
\begin{align*}
{\Phi}_{\post}
=
\begin{bmatrix}
\bphi \T \Big( Y_{T_0+1} - \tau(T_0+1 \con \widehat{\bbeta}) \Big)
\\
\vdots
\\
\bphi \T \Big( Y_{T} - \tau(T \con \widehat{\bbeta}) \Big)
\end{bmatrix}
\in \R^{T_1 \times k_T}
\ .
\end{align*}
We consider additional sieve estimators of ${\EXP} \big\{ \widehat{g} (\bW_{ t}) \cond \potY{t}{0} \big\} $ and ${\EXP} \big\{ \widehat{h}_0(\bW_{ t}) \cond \potY{t}{0} \big\}$ for $t \in \{T_0+1,\ldots,T\}$:
\begin{align*}
\widehat{\mu}_{\post} (y \con \widehat{g})
&
=
{ \texttt{sieve} }
\Big(
\EXP \big\{ \widehat{g} (\bW_{ t}) \cond \potY{t}{0} = y \big\} 
\Big)
\\
&
=
\bphi \T (y)
\big( \Phi_{\post} \T \Phi_{\post} \big)^{-1}
\bigg\{
\sum_{t=T_0+1}^{T}
\widehat{g}(\bW_{ t} ) \bphi \Big( Y_t - \tau(t \con \widehat{\bbeta}) \Big)
\bigg\}
\\
\widehat{\mu}_{\post}(y \con \widehat{h}_0 )
&
=
{ \texttt{sieve} }
\Big(
\EXP \big\{ \widehat{h}_0(\bW_{ t}) \cond \potY{t}{0} = y \big\}
\Big)
\\
&
=
\bphi \T (y)
\big( \Phi_{\post} \T \Phi_{\post} \big)^{-1}
\bigg\{
\sum_{t=T_0+1}^{T}
\widehat{h}_0(\bW_{ t} ) \bphi \Big( Y_t - \tau(t \con \widehat{\bbeta}) \Big)
\bigg\} \ .
\end{align*}
Using these sieve estimators, we obtain a feasible estimator of $r_T(\widehat{h}_0)$ as
\begin{align*}
\widehat{r}_T (\widehat{h}_0)
= 
\frac{1}{ T_1 } \sum_{t=T_0+1}^{T} 
\frac{\partial \tau(t \con \widehat{\bbeta})}{\partial \bbeta}
\bigg[
\widehat{\mu}_{\post} \big( Y_t - \tau(t \con \widehat{\bbeta}) \con \widehat{g} \big)
\Big\{
Y_t - \tau(t \con \widehat{\bbeta})
-
\widehat{\mu}_{\post} \big( Y_t - \tau(t \con \widehat{\bbeta}) \con \widehat{h}_0 \big)
\Big\}
\bigg] \ .
\end{align*}
Under regularity conditions, we establish that
\begin{align*}
\sup_{\widehat{h}_0 \in \widehat{\mathcal{H}}_0}
\sqrt{T_1}
\Big|
\widehat{r}_T(\widehat{h}_0) - {r}_T(\widehat{h}_0)
\Big| = o_P(1) \ ;
\end{align*} 
see Lemma 1 of \citet{Li2023} and Lemma 3.3 of \citet{Zhang2023} for details. Based on this result, we subtract $T_1^{1/2} \widehat{r}_T(\widehat{h}_0)$ in both hand sides of \eqref{eq-asymptotic rep}. We then obtain a de-biased estimator $\widehat{\bbeta}_{\text{db}}$ as
\begin{align*}
\widehat{\bbeta}_{\text{db}}
=
\widehat{\bbeta} 
-
V^{-1} (\widehat{\bbeta}, \widehat{h}_0)
\sqrt{T_1} \widehat{r}_T(\widehat{h}_0) \ ,
\end{align*}
which is asymptotically normal in that $T_{1}^{1/2} \big( \widehat{\bbeta}_{\text{db}} - \bbeta^* \big)$ converges in distribution to $
N \big( 0, S_1^* S_2^* S_1\sT \big)$ as $T \rightarrow \infty$ where $S_1^*$ and $S_2^*$ are given as follows:
\begin{align*}
&
S_1^*
=
\bigg[
\frac{\partial \EXP \big\{ {\Psi}_{\post} (\bO_t \con \bbeta^*, h_0) \big\} }{\partial \bbeta} 
\bigg]^{-1} 
\\
&
S_2^*
=
\VAR
\left[
{\Psi}_{\post} (\bO_t \con \bbeta^*, h_0)
-
\frac{\partial \tau(t \con \bbeta^*)}{\partial \bbeta} 
\EXP \big\{ g_{0,h_0} (\bW_{ t}) \cond \potY{t}{0} \big\} \big\{ \potY{t}{0} - h_0(\bW_{ t} ) \big\}
\right] \ ,
\end{align*}
Here, ${\Psi}_{\post} (\bO_t \con \bbeta,h )$ is defined in \eqref{eq-supp-postEE} for $t \in \{T_0+1,\ldots,T\}$. 
The ATT estimator is obtained from the plug-in formula $\widehat{\tau}_t = \tau(t \con \widehat{\bbeta}_{\text{db}})$. Consequently, inference of the ATT can be attained based on the standard delta-method applied to the asymptotic normal distribution of $\widehat{\bbeta}_{\text{db}}$.



\newpage

\section{Proof of Theorems}	\label{sec:supp:proof}


\subsection{Proof of Theorems \ref{thm:SC}, \ref{thm:ATT}, \ref{thm:Extension NP Cov}}

We first prove the most general case with a nonlinear bridge function $h^*$ and under the presence of covariates (i.e., Theorem \ref{thm:Extension NP Cov}). For the pre-treatment periods $t \in \{1,\ldots,T_0\}$, we establish
\begin{align*}
y 
=
\EXP \big\{ h^* (\bW_{ t}, \bX_{0t}, \bX_{ t}) \cond \potY{t}{0} = y, \bX_{0t}, \bX_{ t}  \big\} 
=
\EXP \big\{ h^* ( \bW_{ t}, \bX_{0t}, \bX_{ t} ) \cond Y_t=y, \bX_{0t}, \bX_{ t} \big\} \ .
\end{align*} 
The first equality holds from Assumption \ref{assumption:valid proxy Cov}. The second equality holds from Assumption \ref{assumption:consistency}.  

Furthermore, for any $t \in \{1,\ldots,T\}$, we establish
\begin{align*} 
\EXP \big\{ \potY{t}{0} \cond \bX_{0 t} , \bX_{ t} \big\} 
& = 
\EXP \big[
\EXP \big\{ h^*(\bW_{ t}, \bX_{0 t} , \bX_{ t}) \cond \potY{t}{0} , \bX_{0 t} , \bX_{ t} \big\}		
\cond \bX_{0 t} , \bX_{ t}
\big]
\nonumber 
\\
&
=		
\EXP \big\{ h^* (\bW_{ t}, \bX_{0 t} , \bX_{ t}) \cond \bX_{0 t} , \bX_{ t} \big\} \ .
\end{align*}	
The first equality holds from Assumption \ref{assumption:valid proxy Cov}, and the second equality holds from the law of iterated expectation. Therefore, we have 
\begin{align}
\label{eq-Identity1}
\EXP \big\{ \potY{t}{0} \big\} 
=
\EXP \big\{ h^* (\bW_{ t}, \bX_{0 t} , \bX_{ t}) \big\} \ .
\end{align}

Next, we prove the second result. For the post-treatment periods $t \in \{T_0+1,\ldots,T\}$, we have 
\begin{align*}
& \EXP \big\{ \potY{t}{1} - \potY{t}{0} \big\} = 
\EXP \big\{ Y_t - \potY{t}{0} \big\}
=
\EXP \big\{ Y_t - h^* (\bW_{ t}, \bX_{0 t} , \bX_{ t}) \big\}
\end{align*}
The first equality holds from Assumption \ref{assumption:consistency}. The second equality holds from \eqref{eq-Identity1}.

We remark that Theorems  \ref{thm:SC} and \ref{thm:ATT} can be shown in a similar manner. 

\subsection{Proof of Theorems \ref{thm:AN} and \ref{thm:AN Cov}}		\label{sec:supp:AN}

We denote the collection of parameters as $\btheta$. 
When there is no covariate as in Section \ref{sec:Estimation}, we have $\btheta = (\Beta, \bgamma, \bbeta)$; when there are covariates as in Section \ref{sec:Cov}, we have $\btheta = (\Beta, \bgamma, \bdelta, \bbeta)$. In what follows, we focus on the proof of Theorems \ref{thm:AN} (i.e., the case with no covariates), since the proof of Theorem \ref{thm:AN Cov} follows a similar approach.



\subsubsection{Notation}






Let the estimating function be $\Psi(\bO_t \con \btheta)$ where 
\begin{align}
\Psi (\bO_t \con \btheta)
&
=
\begin{bmatrix}
\Psi_{\pre} (\bO_t \con \Beta, \bgamma)
\\
\Psi_{\post} (\bO_t \con \bgamma , \bbeta)
\end{bmatrix}
\nonumber
\\
& 
=
\begin{bmatrix}
(1-A_t)
\bD_t
\big( Y_t - \bD_t\T \Beta \big)
\\
(1-A_t)
\bg(t,Y_t \con \Beta)
\big( Y_t - \bW_{ t} \T \bgamma \big)
\\
A_t 
\frac{ \partial \tau(t \con \bbeta) }{\partial \bbeta\T}
\big(
Y_t - \bW_{ t} \T \bgamma - \tau(t \con \bbeta)
\big)
\end{bmatrix} 
=
\begin{bmatrix}
(1-A_t)
\bD_t
\big( Y_t - \bD_t\T \Beta \big)
\\
(1-A_t)
\begin{bmatrix}
\bD_t \\ \bh(Y_t - \bD_t\T \Beta)
\end{bmatrix}
\big( Y_t - \bW_{ t} \T \bgamma \big)
\\
A_t 
\frac{ \partial \tau(t \con \bbeta) }{\partial \bbeta\T}
\big(
Y_t - \bW_{ t} \T \bgamma - \tau(t \con \bbeta)
\big)
\end{bmatrix} 
\label{eq-supp-EE-general}
\ .
\end{align}
The derivative of $\Psi$ is
\begin{align*}
&
\frac{\partial \Psi (\bO_t \con \Beta, \bgamma, \bbeta)}{\partial (\Beta, \bgamma, \bbeta)\T }
\\
&
=
-
\begin{bmatrix}
(1-A_t) \bD_t \bD_t\T
& 0_{d \times N}
& 0_{d \times b}
\\
0_{d \times d}
&
(1-A_t) \bD_t \bW_t\T 
&
0_{d \times b}
\\
(1-A_t) 
\bh'(Y_t - \bD_t \T \Beta)
(Y_t - \bW_t \T \bgamma) \bD_t\T
&
(1-A_t) \bh(Y_t - \bD_t\T \Beta) \bW_t\T 
&
0_{\dim(\bh) \times b}
\\
0_{b \times d}
& 
A_t  \tau'(t \con \bbeta)
& A_t
\big[
\tau''(t \con \bbeta) \tau(t \con \bbeta)
+
\tau'(t \con \bbeta)^{\otimes 2}
\big]
\end{bmatrix}
\\
&
\in \R^{(2d + \dim(\bh) + b) \times (d+N+b)}
\ ,
\end{align*}
where $\bh'(t) = \partial \bh(t) / \partial t \in \R^{\dim(\bh) \times 1}$, $\tau'(t \con \bbeta) = \partial \tau(t \con \bbeta)/\partial \bbeta\T \in \R^{b \times 1}$, $\tau''(t \con \bbeta) = \partial^2 \tau(t \con \bbeta)/(\partial \bbeta\partial \bbeta\T) \in \R^{b \times b}$.





We denote $ \mathcal{O}= \text{supp}(\bO_t)$, $\Theta = \text{supp}(\btheta)$, and the parameters of interest as $\btheta_{0}^* = (\Beta^*,\bgamma_0^*,\bdelta^*,\bbeta^*)$.
\begin{remark}
We will consider a simple case as an example to motivate the assumptions below. Specifically, suppose that $\bh(y)=y$ and $\tau(t \con \bbeta) = \bbeta$, i.e., constant treatment effect. Then, the estimating function is
\begin{align}		\label{eq-supp-simple}
\Psi (\bO_t \con \btheta)
=
\begin{bmatrix}
(1-A_t)
\bD_t
\big( Y_t - \bD_t\T \Beta \big)
\\
(1-A_t)
\bD_t
\big( Y_t - \bW_{ t} \T \bgamma \big)
\\
(1-A_t)
(Y_t - \bD_t\T \Beta)
\big( Y_t - \bW_{ t} \T \bgamma \big)
\\
A_t 
\big(
Y_t - \bW_{ t} \T \bgamma - \bbeta
\big)
\end{bmatrix}
\in \R^{2d+2}
\ .
\end{align}
Note that the derivative of \eqref{eq-supp-simple} is
\begin{align*}
\frac{\partial \Psi (\bO_t \con \Beta, \bgamma, \bbeta)}{\partial (\Beta, \bgamma, \bbeta)\T }
=
-
\begin{bmatrix}
(1-A_t) \bD_t \bD_t\T
& 0_{d \times N}
& 0_{d \times 1}
\\
0_{d \times d}
& (1-A_t) \bD_t \bW_t \T 
& 0_{d \times 1}
\\
(1-A_t) \bD_t\T (Y_t - \bW_t\T \bgamma)
&
(1-A_t) (Y_t - \bD_t\T \Beta) \bW_t\T
& 0
\\
0_{1 \times d}
& 
A_t \bW_{ t} \T & A_t
\end{bmatrix}
\in \R^{(2d+2) \times (d+N+1)}
\ .
\end{align*}
\end{remark}


\subsubsection{Assumptions}
  

We adapt the proof of Theorem S6 in \citet{Qiu2022} to our setting. First, we introduce regularity conditions that are applicable to general cases, without imposing strict requirements of strong stationarity and ergodicity.


\begin{GREG}[Sufficiently Long Pre- and Post-treatment Periods] 	\label{assumption-General-1}
As $T \rightarrow \infty$, $T_0, T_1 \rightarrow \infty$ and $T_a/T \rightarrow \pi_a \in (0,\infty)$ for $a=0,1$.
\end{GREG} 
Regularity Condition \ref{assumption-General-1} is reasonable if the pre- and post-treatment periods are of roughly the same size and sufficiently large.
\begin{GREG}[Compactness] 	\label{assumption-General-2}
The parameter space $\Theta$ is compact, and $\btheta_0 ^* \in \text{int} (\Theta)$; 
\end{GREG} 
Regularity Condition \ref{assumption-General-2} is standard in parametric estimation.
\begin{GREG}[Weighting Matrix] 	\label{assumption-General-3}
$\widehat{\Omega} = \text{diag} (I_{d \times d}, \widehat{\Omega}_{\bg}, \widehat{\Omega}_{\post})$ is a positive definite matrix, and converges to a non-random positive definite matrix $\Omega^* = \text{diag} (I_{d \times d}, {\Omega}_{\bg}^*, {\Omega}_{\post}^*)$ as $T \rightarrow \infty$.
\end{GREG}
Regularity Condition \ref{assumption-General-3} is easily satisfied if $\widehat{\Omega}$ is chosen as a fixed matrix such as the identity matrix.





\begin{GREG}[Population Moment Restriction \& Global Identification] 	\label{assumption-General-6}
Their exists unique $\btheta_0^* = (\Beta^*, \bgamma_0^*, \bbeta^*)$ where 
\begin{align*}
(i) 
& 
\quad 
\Beta^*
\text{ solves }
\lim_{T_0 \rightarrow \infty}
\frac{1}{T_0} \sum_{t=1}^{T_0}
\EXP \big[ \bm{D}_t \big\{ \potY{t}{0} - \bm{D}_t\T \Beta^* \big\} \big]
= 0 
\\
(ii) 
& 
\quad 
\bgamma_0^*
=
\argmin
\Bigg\{ \big\| \bgamma \big\|_2^2
\, \Bigg| \, 
\bgamma \text{ satisfies }
\lim_{T_0 \rightarrow \infty}
\frac{1}{T_0} \sum_{t=1}^{T_0}
\EXP
\big[
\bg(t, \potY{t}{0} \con \Beta^*)
\big\{ 
\potY{t}{0} -  \bW_t\T \bgamma
\big\} 
\big]
\Bigg\}
=
0
\\
(iii) 
& 
\quad 
\bbeta^*
\text{ solves }
\lim_{T_1 \rightarrow \infty}
\frac{1}{T_1} \sum_{t=T_0+1}^{T}
\EXP \bigg[ \frac{\partial \tau( t \con \bbeta^*) }{\partial \bbeta\T}
\big\{ \potY{t}{1} - \tau(t \con \bbeta^*) - \bW_t\T \bgamma_0^* \big\} \bigg]
= 0
\end{align*}
\end{GREG}
Regularity Condition \ref{assumption-General-6} (i) is satisfied if $[\lim_{T_0 \rightarrow \infty} T_0^{-1} \sum_{t=1}^{T_0} \bD_t \bD_t\T]$ is of full rank.  Regularity Condition \ref{assumption-General-6} (ii) is satisfied because the minimum norm solution is uniquely determined. Regularity Condition \ref{assumption-General-6} (iii) is satisfied if $\tau(t \con \bbeta^*)$ is specified based on an identifiable model.  




\begin{GREG}[Regularity Conditions for $\Psi$]
\label{assumption-General-4}
The estimating function $\Psi(\bO_{t} \con \btheta) : \mathcal{O} \otimes \Theta \rightarrow \R^{\dim(\Psi)}$ satisfies
\begin{itemize}[itemsep=0cm]
\item[(i)] $ \lim_{T\rightarrow \infty} \big\{ T^{-1} \sum_{t=1}^{T} \Psi(\bO_{t} \con \btheta) \big\} $ is continuous on $\Theta$ for each $\bO_{t} \in \mathcal{O}$;
\item[(ii)] $ \lim_{T\rightarrow \infty} \big[ T^{-1} \sum_{t=1}^{T} \EXP \big\{ \Psi(\bO_{t} \con \btheta) \big\} \big] $ exists and is finite for any $\btheta \in \Theta$;
\item[(iii)] $ \lim_{T\rightarrow \infty} \big[ T^{-1} \sum_{t=1}^{T} \EXP \big\{ \Psi(\bO_{t} \con \btheta) \big\} \big] $ is continuous on $\Theta$.
\end{itemize}
\end{GREG}
Regularity Condition \ref{assumption-General-4} is satisfied for estimating equation \eqref{eq-supp-simple} if the following vectors/matrices are finite and well-defined:
\begin{align}
& 
\text{For $t \in \{1,\ldots,T_0\}$: }
&&
\EXP \big( \bD_t Y_t \big) \ , 
&&
\EXP \big( \bD_t \bD_t\T \big) \ , 
&& 
\EXP \big( \bD_t \bW_t\T \big) \ , 
&& 
\EXP \big( Y_t^2 \big) \ , 
&& \EXP \big( Y_t \bW_t \T \big) \ , 
\nonumber
\\
&
\text{For $t \in \{T_0+1,\ldots,T\}$: }
&&
\EXP \big( Y_t \big) \ , 
&&
\EXP \big( \bW_t\T\big) \ . 
\label{eq-finitevectormatrix}
\end{align}


\begin{GREG}[Regularity for $\partial \Psi( \bO_{t} \con \btheta) / \partial \btheta \T$ \& Local Identification] 	\label{assumption-General-5}
The function $\partial \Psi( \bO_{t} \con \btheta) / \partial \btheta \T \in \R^{\dim(\Psi) \times \dim(\btheta)}$ satisfies:
\begin{itemize}[itemsep=0cm]
\item[(i)] $ \lim_{T\rightarrow \infty} \big\{ T^{-1} \sum_{t=1}^{T} \partial \Psi( \bO_{t} \con \btheta) / \partial \btheta \T \big\} $ exists and is continuous on $\Theta$ for each $\bO_{t} \in \mathcal{O}$;
\item[(ii)] $ T^{-1} \sum_{t=1}^{T} \partial \Psi( \bO_{t} \con \btheta) / \partial \btheta \T $ is uniformly bounded for all $T \in \{1,2,\ldots\}$
\item[(iii)] $ \lim_{T\rightarrow \infty} \big[ T^{-1} \sum_{t=1}^{T} \EXP \big\{ \partial \Psi( \bO_{t} \con \btheta) / \partial \btheta \T \big\} \big]
\big|_{\btheta=\btheta_0^*} $ exists and is finite;
\item[(iv)] The column rank of $\lim_{T\rightarrow \infty} \big[ T^{-1} \sum_{t=1}^{T} \EXP \big\{ \partial \Psi( \bO_{t} \con \btheta) / \partial (\Beta, \bbeta) \T \big\} \big] \big|_{\btheta=\btheta_0^*}$ is $\dim(\Beta) + \dim(\bbeta) = d + b$.
\end{itemize}
\end{GREG}
Regularity Condition \ref{assumption-General-5} (i)-(iii) are satisfied for estimating equation \eqref{eq-supp-simple} if the following vectors/matrices are uniformly bounded:
\begin{align}
& 
\text{For $t \in \{1,\ldots,T_0\}$: }
&&
\bD_t Y_t \ , 
&&
\bD_t \bD_t\T  \ , 
&& 
\bD_t \bW_t\T \ , 
&& 
Y_t^2 \ , 
&& 
Y_t \bW_t \T \ , 
\nonumber
\\
&
\text{For $t \in \{T_0+1,\ldots,T\}$: }
&&
Y_t \ ,
&&
\bW_t\T \ .  
\nonumber
\end{align}
Regularity Condition \ref{assumption-General-5} (iv) accounts for both underspecified cases (i.e., $\dim (\Psi) < \dim(\btheta)$) and standard cases (i.e., $\dim(\Psi) \geq \dim(\btheta))$. 
We have {\small
\begin{align*}
&
\lim_{T \rightarrow \infty}
\frac{1}{T}
\sum_{t=1}^{T}
\EXP 
\bigg[ 
\frac{\partial \Psi (\bO_t \con \btheta)}{\partial (\Beta, \bbeta)\T }
\bigg] \bigg|_{\btheta=\btheta_0^*}
\\
&
=
-
\lim_{T \rightarrow \infty}
\frac{1}{T}
\sum_{t=1}^{T}
\EXP 
\left.
\begin{bmatrix}
(1-A_t) \bD_t \bD_t\T
& 0_{d \times b}
\\
0_{d \times d}
&
0_{d \times b}
\\
(1-A_t) 
\bh'(Y_t - \bD_t \T \Beta)
(Y_t - \bW_t \T \bgamma) \bD_t\T
&
0_{\dim(\bh) \times b}
\\
0_{b \times d}
& A_t 
\big[
\tau''(t \con \bbeta) \tau(t \con \bbeta)
+
\tau'(t \con \bbeta)^{\otimes 2}
\big]
\end{bmatrix}
\right|_{\btheta=\btheta_0^*}
\\
&
=
-
\begin{bmatrix}
\EXP_{\pre}^{\infty} \big( \bD_t \bD_t\T \big)
& 0_{d \times b}
\\
0_{d \times d}
&
0_{d \times b}
\\
\pi_0
\EXP_{\pre}^{\infty} \big\{
\bh'(Y_t - \bD_t \T \Beta_0^* )
(Y_t - \bW_t \T \bgamma_0^* ) \bD_t\T
\big\}
&
0_{\dim(\bh) \times b}
\\
0_{b \times d}
& 
\pi_1
\EXP_{\post}^{\infty}
\big[
\tau''(t \con \bbeta^*) \tau(t \con \bbeta^*)
+
\tau'(t \con \bbeta^*)^{\otimes 2}
\big]
\end{bmatrix} 
\\
&
=
-
\begin{bmatrix}
\pi_0 \EXP_{\pre}^{\infty}
\big( \bD_t \bD_t\T \big)
& 0_{d \times b}
\\
0_{d \times d}
&
0_{d \times b}
\\
0_{\dim(\bh) \times d}
&
0_{\dim(\bh) \times b}
\\
0_{b \times d}
& 
\pi_1
\EXP_{\post}^{\infty}
\big[
\tau''(t \con \bbeta^*) \tau(t \con \bbeta^*)
+
\tau'(t \con \bbeta^*)^{\otimes 2}
\big]
\end{bmatrix} 
\\
&
\in \R^{(2d + \dim(\bh) + b) \times (d+b)}
\ ,
\end{align*} }%
where $\EXP_{\pre}^{\infty}(f) =  \lim_{T_0 \rightarrow \infty} T_0^{-1} \sum_{t=1}^{T_0} \EXP\{ f(\bO_t) \}$ and $\EXP_{\post}^{\infty}(f) =  \lim_{T_1 \rightarrow \infty} T_1^{-1} \sum_{t=T_0+1}^{T} \EXP\{ f(\bO_t) \}$. Note that the last equality holds from
\begin{align*}
&
\EXP \big\{
\bh'(Y_t - \bD_t \T \Beta^*)
(Y_t - \bW_t \T \bgamma_0^*) \bD_t\T
\big\}
=
\EXP \big\{
\bh'(Y_t - \bD_t \T \Beta^*)
\EXP \big(Y_t - \bW_t \T \bgamma_0^* \cond Y_t \big)
\bD_t\T
\big\}
= 0 \ , \quad t \in \{1,\ldots,T_0\} \ .
\end{align*}
Therefore, Regularity Condition \ref{assumption-General-5} (iv) holds if $\EXP_{\pre}^{\infty}
\big( \bD_t \bD_t\T \big)$ and $\EXP_{\post}^{\infty}
\big[
\tau''(t \con \bbeta^*) \tau(t \con \bbeta^*)
+
\tau'(t \con \bbeta^*)^{\otimes 2}
\big]$ are of column full rank. 











\begin{GREG}[Smoothness of $\bbeta$] 	\label{assumption-General-Continuous}
Let $\bbeta(\bgamma)$ be the solution to
\begin{align*}
\lim_{T_1 \rightarrow \infty}
\frac{1}{T_1} \sum_{t=T_0+1}^{T}
\EXP \bigg[ \frac{\partial \tau( t \con \bbeta) }{\partial \bbeta\T} \bigg|_{\bbeta = \bbeta(\bgamma)}
\big\{ \potY{t}{1} - \tau(t \con \bbeta(\bgamma)) - \bW_t\T \bgamma \big\} \bigg]
= 0 \ .
\end{align*}
Then, $\bbeta(\bgamma)$ is unique and uniformly bounded. Furthermore, its derivative with respect to $\bgamma$, i.e., $\partial{\bbeta(\bgamma)}/{\partial \bgamma\T}$, is continuous and uniformly bounded.
\end{GREG}

Regularity Condition \ref{assumption-General-Continuous} states that the parameter for the ATT is a smooth functional of the synthetic control weights $\bgamma$.


\begin{GREG}[Uniform Weak Law of Large Numbers for $\Psi$] 	\label{assumption-General-UWLLN}
\begin{align*}
\sup_{\btheta \in \Theta}
\bigg\|
\frac{1}{T} \sum_{t=1}^{T} \Psi(\bO_t \con \btheta) -
\lim_{T' \rightarrow \infty}
\frac{1}{T'} \sum_{t=1}^{T'} \EXP \big\{\Psi(\bO_t \con \btheta) \big\}
\bigg\|
=
o_P(1) \text{ as } T \rightarrow \infty \ .
\end{align*}
\end{GREG}

\begin{GREG}[Uniform Weak Law of Large Numbers for the Gradient of $\Psi$] 	\label{assumption-General-UWLLN2}
\begin{align*}
\sup_{\btheta \in \Theta}
\bigg\|
\frac{1}{T} \sum_{t=1}^{T} \frac{\partial}{\partial \btheta \T } \Psi(\bO_t \con \btheta) -
\lim_{T' \rightarrow \infty}
\frac{1}{T'} \sum_{t=1}^{T'} \EXP \bigg\{ \frac{\partial}{\partial \btheta \T } \Psi(\bO_t \con \btheta) \bigg\}
\bigg\|
=
o_P(1) \text{ as } T \rightarrow \infty \ .
\end{align*}
\end{GREG}
Regularity Conditions \ref{assumption-General-UWLLN} and \ref{assumption-General-UWLLN2} hold if the underlying process is strictly stationary, strongly mixing, or $\phi$-mixing processes; see \citet{Andrews1988}, \citet[Chapter 5]{PP1997} and \citet[Section S2]{Qiu2022} for details. 

\begin{GREG}[Asymptotic Normality]
\label{assumption-General-AN} 
As $T \rightarrow \infty$, we have
\begin{align*}
&
\frac{1}{\sqrt{T}} \sum_{t=1}^{T} \Psi(\bO_t \con \btheta^*)
\text{ converges in distribution to }
N (0, \Sigma_2^*)
\ , \\
&
\Sigma_2^* = \lim_{T \rightarrow \infty} \VAR \bigg\{ \frac{1}{\sqrt{T}} \sum_{t=1}^{T} \Psi (\bO_t \con \btheta^*) \bigg\} \ .
\end{align*}
Here, $\Sigma_2^*$ is a finite valued positive definite matrix. 
\end{GREG}
Assumption \ref{assumption-General-AN} directly assumes the asymptotic normality of the sample mean of the estimating function; see Section S2 of \citet{Qiu2022} for the plausibility of the assumption. We remark that Regularity Conditions \ref{assumption-General-UWLLN}--\ref{assumption-General-AN} are satisfied under standard assumptions for GMM; see Chapter 3 of \citet{Hall2004GMM} for details. 

\subsubsection{Proof}


Under Regularity Conditions \ref{assumption-General-1}--\ref{assumption-General-AN}, we establish the desired result. We simply denote $\widehat{\Psi}(\btheta) = T^{-1} \sum_{t=1}^T \Psi(\bO_t \con \btheta)$ and ${\Psi}(\btheta) = \lim_{T \rightarrow \infty} T^{-1} \sum_{t=1}^T \EXP \big\{ \Psi(\bO_t \con \btheta) \big\}$.  For a generic function $f$, we denote
\begin{align*}
&
\EXP_{\pre}^{\infty}(f) =  \lim_{T_0 \rightarrow \infty} \frac{1}{T_0} \sum_{t=1}^{T_0} \EXP\{ f(\bO_t) \}
&&
\AVER_{\pre}^{\infty}(f) =  \lim_{T_0 \rightarrow \infty} \frac{1}{T_0} \sum_{t=1}^{T_0} f(\bO_t)
\\
&
\EXP_{\post}^{\infty}(f) =  \lim_{T_1 \rightarrow \infty} \frac{1}{T_1} \sum_{t=T_0+1}^{T} \EXP\{ f(\bO_t) \}
&&
\AVER_{\post}^{\infty}(f) =  \lim_{T_1 \rightarrow \infty} \frac{1}{T_1} \sum_{t=T_0+1}^{T} f(\bO_t) \ .
\end{align*}

From the form of the estimating equation in \eqref{eq-supp-EE-general}, we find the following representations for $(\Beta^*,\bbeta^*)$:
\begin{align*}
&
\Beta^*
=
\big\{
\EXP_{\pre}^{\infty} ( \bD_t \bD_t\T )
\big\}^{-1}
\big\{
\EXP_{\pre}^{\infty} ( \bD_t Y_t )
\big\}^{-1}
\ , 
&&
\bbeta^* = \bbeta(\bgamma_0^*) 
\end{align*}
where $\bbeta( \cdot) $ is the function defined in Regularity Condition \ref{assumption-General-Continuous}. The synthetic control weight $\bgamma_0^*$ has the following representation. Let $ \bG_{YW}^{*} 
=
\EXP_{\pre}^{\infty} 
\big\{
\bg(t, Y_t \con \Beta)
\bW_t\T
\big\}$ and $
{\bG}_{YY}^*
=
\EXP_{\pre}^{\infty} 
\big\{ 
\bg(t, Y_t \con \Beta)
Y_t
\big\}$. Then, we find
\begin{align*}
&
\text{If $\bG_{YW}^{*}$ is of full row rank, }
&&
\text{then }
\bgamma_0^*
=
\big( \Omega_{\bg}^{*1/2} 
\bG_{YW}^* \big)^{+}
\big( 
\Omega_{\bg}^{*1/2} 
\bG_{YY}^*
\big)
\\
& \text{If $\bG_{YW}^{*}$ is of full column rank, }
&&
\text{then }
\bgamma_0^* 
=
(\bG_{YW}\sT \Omega_{\bg}^* \bG_{YW}^* )^{-1}
( \bG_{YW}\sT \Omega_{\bg}^* \bG_{YY}^* ) \ .
\end{align*}











Let $\btheta_{\rho}^*$ be the unique minimizer of 
\begin{align*}
& Q_\rho(\btheta)
\\
&
=
\bigg[
\lim_{T \rightarrow \infty}
\frac{1}{T} \sum_{t=1}^T \EXP \big\{ \Psi(\bO_t \con \btheta) \big\} \bigg]\T
\Omega^*
\bigg[
\lim_{T \rightarrow \infty}
\frac{1}{T} \sum_{t=1}^T \EXP \big\{ \Psi(\bO_t \con \btheta) \big\} \bigg]
+ \rho \big\| \bgamma \big\|_2^2 
\\
&
=
\left[ 
\begin{array}{l}
\pi_0^2
\big\| \EXP_{\pre}^{\infty}
\big\{ \bm{D}_t \big( Y_t - \bm{D}_t\T \Beta \big) \big\}
\big\|_2^2
\\
+
\pi_0^2
\big[ \EXP_{\pre}^{\infty}
\big\{ \bg(y, Y_t \con \Beta) \big( Y_t - \bW_t\T \bgamma \big) \big\} \big]\T \Omega_{\bg}^*
\big[ \EXP_{\pre}^{\infty}
\big\{ \bg(y, Y_t \con \Beta) \big( Y_t - \bW_t\T \bgamma \big) \big\} \big]
\\
+
\pi_1^2
\big[
\EXP_{\post}^{\infty} \big[ \tau' (t \con \bbeta)
\big\{ Y_t - \tau(t \con \bbeta) - \bW_t\T \bgamma \big\} \big]
\big]\T \Omega_{\post}^*
\big[
\EXP_{\post}^{\infty} \big[ \tau' (t \con \bbeta)
\big\{ Y_t - \tau(t \con \bbeta) - \bW_t\T \bgamma \big\} \big]
\big]
\end{array}
\right]     
+
\rho \big\| \bgamma \big\|_2^2 \ .
\end{align*}
From straightforward algebra, we find
\begin{align*}
&
\Beta_{\rho}^*
=
\big\{
\EXP_{\pre}^{\infty} ( \bD_t \bD_t\T )
\big\}^{-1}
\big\{
\EXP_{\pre}^{\infty} ( \bD_t Y_t )
\big\}^{-1}
\ , 
\\
&
\bgamma_{\rho}^* 
=
(\bG_{YW}\sT \Omega_{\bg}^* \bG_{YW}^* + \rho I_{N \times N} )^{-1}
( \bG_{YW}\sT \Omega_{\bg}^* \bG_{YY}^* ) 
\ , 
\\
&
\bbeta_{\rho}^* = \bbeta(\bgamma_\rho^*) \ .
\end{align*} 
As $\rho \downarrow 0$, we find
\begin{align*}
\Beta_{\rho}^*
&
\rightarrow
\Beta^*
\\
\bgamma_{\rho}^* 
&
=
(\bG_{YW}\sT \Omega_{\bg}^* \bG_{YW}^* + \rho I_{N \times N} )^{-1}
( \bG_{YW}\sT \Omega_{\bg}^* \bG_{YY}^* ) 
\\
&
\quad 
\rightarrow
\left\{
\begin{array}{ll}
\big( \Omega_{\bg}^{*1/2} 
\bG_{YW}^* \big)^{+}
\big( 
\Omega_{\bg}^{*1/2} 
\bG_{YY}^*
\big)
&
\text{ if $\bG_{YW}^*$ is of full row rank }
\\
(\bG_{YW}\sT \Omega_{\bg} \bG_{YW}^* )^{-1}
( \bG_{YW}\sT \Omega_{\bg} \bG_{YY}^* )
&
\text{ if $\bG_{YW}^*$ is of full column rank }
\end{array}
\right\}
=
\bgamma_0^*
\\
\bbeta_{\rho}^*
&
=
\bbeta(\bgamma_\rho^*) \rightarrow \bbeta(\bgamma_0^*) = \bbeta^* 
\end{align*}






























First, we establish consistency, i.e., $\widehat{\btheta}_{\rho} = (\widehat{\Beta},
\widehat{\bgamma}_{\rho}, \widehat{\bbeta}) = (\Beta^*, \bgamma_0^*, \bbeta^*) + o_P(1) = \btheta_0^* + o_P(1)$. Under Regularity Conditions \ref{assumption-General-3} and \ref{assumption-General-UWLLN}, we obtain
\begin{align} \label{eq-UWLLN-GMM2}
&
\sup_{\btheta \in \Theta}
\left\|
\big\{
\widehat{\Psi}(\btheta)
\big\}\T 
\widehat{\Omega}
\big\{
\widehat{\Psi}(\btheta)
\big\} 
+ 
\rho \big\| \bgamma \big\|_2^2
-
\big\{
{\Psi}(\btheta)
\big\}\T 
\Omega^*
\big\{
{\Psi}(\btheta)
\big\}
-
\rho \big\| \bgamma \big\|_2^2
\right\|
\nonumber
\\
&
=
\sup_{\btheta \in \Theta}
\left\|
\big\{
\widehat{\Psi}(\btheta)
\big\}\T 
\widehat{\Omega}
\big\{
\widehat{\Psi}(\btheta)
\big\} 
-
\big\{
{\Psi}(\btheta)
\big\}\T 
\Omega^*
\big\{
{\Psi}(\btheta)
\big\}
\right\| 
\nonumber
\\
&
= o_P(1) \ .
\end{align} 


Let $s > 0$ be an arbitrary positive constant. 
From \eqref{eq-UWLLN-GMM2} and the definition of $\widehat{\btheta}_{\rho}$, the following conditions hold with probability tending to one:
\begin{align*}
&
\left\|
\big\{
\widehat{\Psi}(\btheta_{\rho}^*)
\big\}\T 
\widehat{\Omega}
\big\{
\widehat{\Psi}(\btheta_{\rho}^*)
\big\} 
+
\rho \big\| \bgamma_{\rho}^* \big\|_2^2
-
\big\{
\Psi (\btheta_{\rho}^*)
\big\}\T 
\Omega^*
\big\{
\Psi (\btheta_{\rho}^*)
\big\}
-
\rho \big\| \bgamma_{\rho}^* \big\|_2^2
\right\| < s/2
\\
&
\left\|
\big\{
\widehat{\Psi}(\widehat{\btheta}_{\rho})
\big\}\T 
\widehat{\Omega}
\big\{
\widehat{\Psi}(\widehat{\btheta}_{\rho})
\big\} 
+
\rho \big\| \widehat{\bgamma}_{\rho} \big\|_2^2
-
\big\{
\Psi (\widehat{\btheta}_{\rho})
\big\}\T 
\Omega^*
\big\{
\Psi (\widehat{\btheta}_{\rho})
\big\}
-
\rho \big\| \widehat{\bgamma}_{\rho} \big\|_2^2
\right\| < s/2 
\\ 
&
\big\{
\widehat{\Psi} (\widehat{\btheta}_{\rho})
\big\}\T 
\widehat{\Omega}
\big\{
\widehat{\Psi} (\widehat{\btheta}_{\rho})
\big\}
+
\rho \big\| \widehat{\bgamma}_{\rho} \big\|_2^2
\leq
\big\{
\widehat{\Psi} (\btheta_{\rho}^*)
\big\}\T 
\widehat{\Omega}
\big\{
\widehat{\Psi} (\btheta_{\rho}^*)
\big\}
+
\rho \big\| \bgamma_{\rho}^* \big\|_2^2
\ .
\end{align*}
Note that the last inequality holds because  $\widehat{\btheta}_{\rho}$ is the minimizer of $\big\{
\widehat{\Psi}(\btheta)
\big\}\T 
\widehat{\Omega}
\big\{
\widehat{\Psi}(\btheta)
\big\} 
+ \rho \big\| \bgamma \big\|_2^2 $. 

These three inequalities imply that
\begin{align*}
\big\{
\Psi(\widehat{\btheta}_{\rho})
\big\}\T 
\Omega^*
\big\{
\Psi(\widehat{\btheta}_{\rho})
\big\} 
+
\rho \big\| \widehat{\bgamma}_{\rho} \big\|_2^2
<
\big\{
\Psi(\btheta_{\rho}^*)
\big\}\T 
\Omega^*
\big\{
\Psi(\btheta_{\rho}^*)
\big\} 
+
\rho \big\| {\bgamma}_{\rho}^* \big\|_2^2
+ s
=
m_\rho
+
s \ .
\end{align*} 
Here $m_\rho = \min_{\btheta} \big[ \big\{
\Psi(\btheta)
\big\}\T 
\Omega^*
\big\{
\Psi(\btheta)
\big\} 
+
\rho \big\| {\bgamma} \big\|_2^2 \big]$.

Let $\mathcal{N} \in \Theta$ be an arbitrary open set containing $\btheta_0^*$. Let us define the following quantity:
\begin{align*}
s_0
=
\inf_{\btheta \in \Theta \setminus \mathcal{N} }
\big[ 
\big\{ 
\Psi(\btheta)
\big\}\T
\Omega^*
\big\{ 
\Psi(\btheta)
\big\} +
\rho \big\| \bgamma \big\|_2^2
\big]
- m_{\rho}
\end{align*}
Note that $\Theta \setminus \mathcal{N}$ is compact under Regularity Condition \ref{assumption-General-2}. Also, for a fixed $\rho>0$, Regularity Conditions \ref{assumption-General-6} and \ref{assumption-General-4} imply that $s_0$ is positive. Therefore, by taking $s>s_0$, the event $\big\{ \big\{
\Psi(\widehat{\btheta}_{\rho})
\big\}\T 
\widehat{\Omega}
\big\{
\Psi(\widehat{\btheta}_{\rho})
\big\}
+
\rho \big\| \widehat{\bgamma}_{\rho} \big\|
< m_{\rho}+s_0 \big\}$ occurs with probability tending to one, which further implies that $\widehat{\btheta}_{\rho} \in \mathcal{N}$. Since $\mathcal{N}$ is arbitrary chosen, this establishes $\widehat{\btheta}_{\rho} = \btheta_{\rho}^* + o_P(1)$ as $T \rightarrow \infty$ for a fixed $\rho>0$. 

In addition, for any $T  \in \{ 1,2,\ldots\}$, we find $\widehat{\btheta}_{\rho} \rightarrow \widehat{\btheta}_0 $ as $\rho \downarrow 0$ where
\begin{align*} 
&
\widehat{\btheta}_0
=
\begin{bmatrix}
\widehat{\Beta}
\\
\widehat{\bgamma}_{0}
\\
\bbeta (  \widehat{\bgamma}_{0} )
\end{bmatrix}
\ , \quad
&&
\widehat{\bgamma}_0
=
\left\{
\begin{array}{ll}
\big( \widehat{\Omega}_{\bg}^{1/2}
\widehat{\bG}_{YW} \big)^{+}
\big( 
\widehat{\Omega}_{\bg}^{1/2}
\widehat{\bG}_{YY}
\big)
&
\text{if $\widehat{\bG}_{YW}$ is of full row rank}
\\
(\widehat{\bG}_{YW}\T \widehat{\Omega}_{\bg} \widehat{\bG}_{YW} )^{-1}
( \widehat{\bG}_{YW}\T \widehat{\Omega}_{\bg} \widehat{\bG}_{YY} )
&
\text{if $\widehat{\bG}_{YW}$ is of full column rank}
\end{array}
\right.\ .
\end{align*}
For $\rho,\rho'>0$, we get
\begin{align*}
&
\widehat{\btheta}_{\rho}
-
\widehat{\btheta}_{\rho'}=
\left[ 
\begin{array}{c}
0
\\
\widehat{\bgamma}_\rho
-
\widehat{\bgamma}_{\rho'}\\       
\bbeta(\widehat{\bgamma}_\rho)
-
\bbeta(\widehat{\bgamma}_{\rho'})
\end{array}
\right] \ .
\end{align*}
Consider a singular vector decomposition of $\widehat{\Omega}_{\bg}^{1/2} \widehat{\bG}_{YW} 
=
\widehat{\bm{\mathcal{U}}} \widehat{\bm{\mathcal{D}}} \widehat{\bm{\mathcal{V}}} \T$ where $\widehat{\bm{\mathcal{D}}} = \text{diag}(\widehat{d}_1,\ldots,d_{\dim(\bg)})$. Then, we find
\begin{align*}
\widehat{\bgamma}_{\rho} 
-
\widehat{\bgamma}_{\rho'} 
&
= \Big\{ \Big(
\widehat{\bG}_{YW}\T
\widehat{\Omega}_{\bg}
\widehat{\bG}_{YW}
+
\rho I_{N \times N}
\Big)^{-1}
-
\Big(
\widehat{\bG}_{YW}\T
\widehat{\Omega}_{\bg}
\widehat{\bG}_{YW}
+
\rho' I_{N \times N}
\Big)^{-1}
\Big\}
\Big( 
\widehat{\bG}_{YW}\T
\widehat{\Omega}_{\bg}
\widehat{\bG}_{YY}
\Big)
\\
&
=
\bigg\{
\widehat{\bm{\mathcal{V}}}
\text{diag} \bigg(
\frac{\widehat{d}_{j}}{\rho + \widehat{d}_{j}}
-
\frac{\widehat{d}_{j}}{\rho' + \widehat{d}_{j}}
\bigg) 
\widehat{\bm{\mathcal{U}}}\T
\bigg\} 
\Big( \widehat{\Omega}_{\bg}^{1/2} 
\widehat{\bG}_{YY}  
\Big)
\ .
\end{align*}
Therefore, $\big\| \widehat{\bgamma}_{\rho} 
-
\widehat{\bgamma}_{\rho'} \big\|
\leq 
C_1 \big\| \rho - \rho' \big\|$ where the constant $C_1$ does not depend on $T$ because $\widehat{\bG}_{YW}$ and $\widehat{\bG}_{YY}$ are uniformly bounded for any $T$ from Regularity Condition \ref{assumption-General-5} (ii).
Likewise, from the mean value theorem, there exists $\bgamma'$ satisfying 
\begin{align*}
\bbeta(\widehat{\bgamma}_\rho)
-
\bbeta(\widehat{\bgamma}_{\rho'})
=
\frac{ \partial \bbeta(\bgamma)}{\partial \bgamma\T}
\bigg|_{\bgamma=\bgamma'}
(\widehat{\bgamma}_{\rho} - \widehat{\bgamma}_{\rho'}) \ .
\end{align*}
Since $\partial \bbeta(\bgamma) / \partial \bgamma\T$ is uniformly bounded, we find the following result holds for any $T$:
\begin{align*}
\big\|
\bbeta(\widehat{\bgamma}_\rho)
-
\bbeta(\widehat{\bgamma}_{\rho'})
\big\|
\leq 
C_2 \big\| \widehat{\bgamma}_{\rho} 
-
\widehat{\bgamma}_{\rho'} \big\|
\leq 
C_1 C_2 \big\| \rho - \rho' \big\| \ .
\end{align*}
Therefore, for any $T$, we have
$\big\| \widehat{\btheta}_{\rho}
- \widehat{\btheta}_{\rho'}
\big\| \leq C \big\| \rho - \rho' \big\|$ for a constant $C$. This implies that the convergence $\widehat{\btheta}_{\rho} \rightarrow \widehat{\btheta}_0$ is uniform in $T$. Therefore, this implies the double in-probability limit of $\widehat{\btheta}_{\rho}$ is well-defined and converge to $\btheta_0^*$:
\begin{align*}
\plim_{\rho \downarrow 0}
\plim_{T \rightarrow \infty}
\widehat{\btheta}_{\rho}
=
\plim_{T \rightarrow \infty}
\plim_{\rho \downarrow 0}
\widehat{\btheta}_{\rho}
=
\plim_{T \rightarrow \infty,\rho \downarrow 0}
\widehat{\btheta}_{\rho}
=
\btheta_{0}^* \ .
\end{align*}
Therefore, taking $\rho = o(T^{-1/2})$, we find $\widehat{\btheta}_{\rho}=\btheta_0^*+o_P(1)$ as $T \rightarrow \infty$.


Next, we establish the asymptotic normality of $\widehat{\btheta}_{\rho}$. First, the following results hold from the assumptions and 
$\widehat{\btheta}_{\rho} = \btheta^*+o_P(1)$:
\begin{align} 
& 
\frac{\partial}{\partial \btheta\T} \widehat{\Psi}( \btheta) \bigg|_{\btheta=\widehat{\btheta}_\rho} 
= 
\frac{\partial}{\partial \btheta\T} \widehat{\Psi}( \btheta) \bigg|_{\btheta=\btheta^*} 
+
o_P(1) \ ,
\label{eq-proof-1}
\\
& 
\widehat{\Psi}( \widehat{\btheta}_{\rho})
=
\widehat{\Psi}( {\btheta}^*)
+
\bigg\{
\frac{\partial}{\partial \btheta\T} \widehat{\Psi}( \btheta) \bigg|_{\btheta=\btheta^*}
\bigg\}
(\widehat{\btheta}_{\rho}-\btheta^*)
+
o_P \Big( \big\| \widehat{\btheta}_{\rho} - \btheta^* \big\| \Big)
=
\widehat{\Psi}({\btheta}^*) 
+
o_P(1)
=
O_P(1)
\ . 
\label{eq-proof-2}
\end{align}
Specifically, \eqref{eq-proof-1} holds from Regularity Condition \ref{assumption-General-5}-(i) and the continuous mapping theorem. 
\eqref{eq-proof-2} holds from the first-order Taylor expansion, Regularity Condition \ref{assumption-General-AN}, and $\widehat{\btheta}_{\rho}-\btheta^* = o_P(1)$.






The first order condition of $\widehat{\btheta}_{\rho}$ along with Regularity Condition \ref{assumption-General-5} implies
\begin{align*}
0
& =
\frac{1}{2}
\frac{\partial}{\partial \btheta\T} 
\Big[
\big\{ \widehat{\Psi}( \btheta)
\big\}\T \widehat{\Omega} 
\big\{ \widehat{\Psi}( \btheta)
\big\}
+ \rho \big\| \bgamma \big\|_2^2
\Big] \Big|_{\btheta=\widehat{\btheta}_{\rho}}
\\
&
=
\bigg\{
\frac{\partial}{\partial \btheta\T} \widehat{\Psi}( \btheta) \bigg|_{\btheta=\widehat{\btheta}_\rho}
\bigg\}\T
\widehat{\Omega}
\big\{ \widehat{\Psi}( \widehat{\btheta}_{\rho})
\big\}
+ 
\rho 
\begin{bmatrix}
0_{\dim(\Beta)}
\\
\widehat{\bgamma}_{\rho}
\\
0_{\dim(\beta)}
\end{bmatrix}
\\
& =
\bigg\{
\frac{\partial}{\partial \btheta\T} \widehat{\Psi}( \btheta) \bigg|_{\btheta=\widehat{\btheta}_\rho}
\bigg\}\T
\widehat{\Omega}
\big\{ \widehat{\Psi}( \widehat{\btheta}_{\rho})
\big\} 
+ 
\rho 
\underbrace{
\begin{bmatrix}
0_{\dim(\Beta)} & 0_{\dim(\bgamma)} & 0_{\dim(\beta)}
\\
0_{\dim(\Beta)} & I_{\dim(\bgamma)} & 0_{\dim(\beta)}
\\
0_{\dim(\Beta)} & 0_{\dim(\bgamma)} & 0_{\dim(\beta)}
\end{bmatrix} }_{\mathcal{I}}
(\widehat{\btheta}_{\rho}
-
\btheta^*)
+
o_P(T^{-1/2})
\\
& =
\bigg\{
\frac{\partial}{\partial \btheta\T} \widehat{\Psi}( \btheta) \bigg|_{\btheta=\btheta^*}
\bigg\}\T
\widehat{\Omega}
\big\{ \widehat{\Psi}( \widehat{\btheta}_{\rho})
\big\} 
+
\rho \mathcal{I} (\widehat{\btheta}_{\rho}
-
\btheta^*)
+
o_P(T^{-1/2})
\\
&
=
\bigg\{
\frac{\partial}{\partial \btheta\T} \widehat{\Psi}( \btheta) \bigg|_{\btheta=\btheta^*}
\bigg\}\T
\widehat{\Omega}
\big\{ \widehat{\Psi}( \btheta^*)
\big\}
+
\Bigg[
\bigg\{
\frac{\partial}{\partial \btheta\T} \widehat{\Psi}( \btheta) \bigg|_{\btheta=\btheta^*}
\bigg\}\T
\widehat{\Omega}
\bigg\{
\frac{\partial}{\partial \btheta\T} \widehat{\Psi}( \btheta) \bigg|_{\btheta=\btheta^*}
\bigg\} 
+\rho \mathcal{I}
\Bigg]
(\widehat{\btheta}_{\rho}-\btheta^*)
\\
& 
\quad 
+
o_P
\Big(
\big\| \widehat{\btheta}_{\rho} - \btheta^* \big\|
+
T^{-1/2}
\Big) \ .
\end{align*} 
The third equality is from $T^{1/2} \rho \widehat{\bgamma}_{\rho}=o_P(1)$.
The fourth equality is from \eqref{eq-proof-1} and \eqref{eq-proof-2}. 
The last equality is from \eqref{eq-proof-2}.

By multiplying $T^{1/2}$, we get
\begin{align*}
0
&
=
\bigg\{
\frac{\partial}{\partial \btheta\T} \widehat{\Psi}( \btheta) \bigg|_{\btheta=\btheta^*}
\bigg\}\T
\widehat{\Omega}
\bigg\{
\frac{1}{T^{1/2}}
\sum_{t=1}^{T} \Psi(\bO_t \con \btheta^* )
\bigg\}
\\
&
\hspace*{0.3cm}
+
\Bigg[ 
\bigg\{
\frac{\partial}{\partial \btheta\T} \widehat{\Psi}( \btheta) \bigg|_{\btheta=\btheta^*}
\bigg\}\T
\widehat{\Omega}
\bigg\{
\frac{\partial}{\partial \btheta\T} \widehat{\Psi}( \btheta) \bigg|_{\btheta=\btheta^*}
\bigg\}
+
\rho 
\mathcal{I}
\Bigg]
T^{1/2}
(\widehat{\btheta}_{\rho} -\btheta^*)
+
o_P \Big( T^{1/2} \big\| \widehat{\btheta}_{\rho} - \btheta^* \big\|+ 1 \Big)
\\
&
=
\bigg\{
\underbrace{
\frac{\partial}{\partial \btheta\T} {\Psi}( \btheta) \bigg|_{\btheta=\btheta^*}
}_{=:G^*}
\bigg\}\T 
\Omega^*
\bigg\{
\lim_{T \rightarrow \infty}
\frac{1}{T^{1/2}}
\sum_{t=1}^{T} \Psi(\bO_t \con \btheta^* )
\bigg\}
\\
&
\hspace*{0.3cm}
+
\Bigg[
\bigg\{
\frac{\partial}{\partial \btheta\T} {\Psi}( \btheta) \bigg|_{\btheta=\btheta^*}
\bigg\}\T
\Omega^*
\bigg\{
\frac{\partial}{\partial \btheta\T} {\Psi}( \btheta) \bigg|_{\btheta=\btheta^*}
\bigg\} 
+
\rho 
\mathcal{I}
\Bigg]
T^{1/2}
(\widehat{\btheta}_{\rho}-\btheta^*)
+
o_P \Big( T^{1/2} \big\| \widehat{\btheta}_{\rho} - \btheta^* \big\| + 1 \Big) \ .
\end{align*}
The second equality holds from Regularity Condition \ref{assumption-General-UWLLN2}:
\begin{align*}
\frac{\partial}{\partial \btheta\T} \widehat{\Psi}( \btheta) \bigg|_{\btheta=\btheta^*}
=
\frac{\partial}{\partial \btheta\T} {\Psi}( \btheta) \bigg|_{\btheta=\btheta^*}
+
o_P(1)
\end{align*}
The last equality holds from Regularity Conditions \ref{assumption-General-3}, \ref{assumption-General-UWLLN}, and \ref{assumption-General-UWLLN2} and the consistency of $\widehat{\btheta}_{\rho}$. 

Therefore, we obtain
\begin{align*}
\Big\{ G\sT \Omega^* G^* + \rho \mathcal{I} + o_P(1) 
\Big\}
\Big\{
T^{1/2} \big( \widehat{\btheta}_{\rho} - \btheta^* \big)
\Big\}
=
-
G\sT \Omega^*
\bigg\{
\lim_{T \rightarrow \infty}
\frac{1}{T^{1/2}}
\sum_{t=1}^{T} \Psi(\bO_t \con \btheta^* )
\bigg\}
+ o_P(1) \ .
\end{align*}
This implies 
\begin{align*}
T^{1/2} \big( \widehat{\btheta}_{\rho} - \btheta^* \big)
=
\Big\{ G\sT \Omega^* G^* + \rho \mathcal{I} + o_P(1) 
\Big\}^{-1}
\Bigg[ 
G\sT \Omega^*
\bigg\{
\lim_{T \rightarrow \infty}
\frac{1}{T^{1/2}}
\sum_{t=1}^{T} \Psi(\bO_t \con \btheta^* )
\bigg\}
+ o_P(1)
\Bigg]  \ .
\end{align*}
Therefore, taking $\rho = o(T^{-1/2})$, we have 
\begin{align*}
\Big\{ 
G\sT \Omega^* G^* + \rho \mathcal{I}  
\Big\}^{-1}
G\sT \Omega^{*1/2}
\stackrel{\rho \downarrow 0}{\rightarrow}
\big( \Omega^{*1/2} G^*  \big)^{+} \ .
\end{align*}
As a side note, we have
\begin{align*}
\big( \Omega^{*1/2} G^*  \big)^{+}
\neq  
G^{*+} \Omega^{*-1/2} \ ,
\end{align*}
with a counterexample:
\begin{align*}
\Omega^{*1/2}
=
\begin{bmatrix}
2 & 1 \\ 1 & 1
\end{bmatrix} 
\ , \ 
G^{*+}
=
\begin{bmatrix}
1 \\ 0
\end{bmatrix} 
\quad \Rightarrow \quad 
\big( \Omega^{*1/2} G^*  \big)^{+}
=
\big[ 0.4 \ , \ 0.2 \big]
\neq 
\big[ 1 \ , \ -1 \big] 
=
G^{*+} \Omega^{*-1/2}
\ . 
\end{align*}

Consequently, we find
\begin{align*}
T^{1/2} \big( \widehat{\btheta}_{\rho} - \btheta^* \big)
& \text{ converges in distribution to }
N \big( 0, 
\big( \Omega^{*1/2} G^*  \big)^{+} \Omega^{*1/2}
\Sigma_2 
\Omega^{*1/2}
\big( \Omega^{*1/2} G^*  \big)^{+\intercal} \big)
\ . 
\end{align*}
This concludes the proof.

