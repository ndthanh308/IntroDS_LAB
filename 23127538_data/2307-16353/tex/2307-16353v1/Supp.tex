\newpage

\appendix

%\renewcommand{\thesection}{S\arabic{section}}
%\renewcommand{\thesection}{S\arabic{section}}

\section*{Supplementary Material}

This document provides details of ``Single Proxy Synthetic Control.''	In Section \ref{sec:supp:Detail}, we provide details of the paper. In Section \ref{sec:supp:nonparametric full}, we provide details on the nonparametric single proxy synthetic control framework. Lastly, we provide the proofs of the results in Section \ref{sec:supp:proof}. 

\section{Details of the Paper} \label{sec:supp:Detail}

\subsection{Inconsistency of the Ordinary Least Squares Estimator}	\label{sec:supp:OLS}

Following \citet{FermanPinto2021}, we provide details on why synthetic controls obtained from the ordinary least squares (OLS) may be inconsistent. For simplicity, we consider an unconstrained case, in which equation \eqref{eq-OLS} of the main paper reduces to:
\begin{align}
\tag{\ref{eq-OLS}}
\widehat{\bgamma}_{\text{OLS}}
=
\argmin_{\bgamma}
Q(\bgamma)
\ , &&
Q(\bgamma)
= 
\frac{1}{T_0}
\sum_{t=1}^{T_0}
\big(
Y_t - \bW_{\D t}\T \bgamma
\big)^2
\ .
\end{align}
For a fixed $\bgamma=(\gamma_{\D_1},\ldots,\gamma_{\D_d}) \T$, the probability limit of $Q(\bgamma)$ as $T_0 \rightarrow \infty$  is given as follows: 
\begin{align}
\nonumber
\lim_{T_0 \rightarrow \infty}
Q(\bgamma)
&=
\lim_{T_0 \rightarrow \infty}
\frac{1}{T_0}
\sum_{t=1}^{T_0} 
\big(
Y_t - 
\bW_{\D t}\T \bgamma
\big)^2
\\
\nonumber
& 
=
\lim_{T_0 \rightarrow \infty}
\frac{1}{T_0}
\sum_{t=1}^{T_0} \Big\{
\bW_{\D t}\T (\bgamma^\dagger - \bgamma)
+ 
e_{0t} 
-
\sum_{i \in \D} \gamma_i^{\dagger} e_{it} 
\Big\}^2
\\
\nonumber
& 
=
\lim_{T_0 \rightarrow \infty}
\frac{1}{T_0}
\sum_{t=1}^{T_0} 
\bigg\{
\sum_{i \in \D}
(\gamma_i^\dagger - \gamma_i) \bmu_i\T 
\blambda_t
+ 
e_{0t}
-
\sum_{i=1}^{N} \gamma_i e_{it} 		
\bigg\} ^2
\\
\label{eq-problimit}
&
=
\sum_{i \in \D} (\gamma_i^\dagger - \gamma_i)^2 \bmu_i\T \Lambda	\bmu_i
+
\bigg( 1+\sum_{i \in \D} \gamma_i^2 \bigg) \sigma_e^2
\ .
\end{align}
where the second and third lines hold from \eqref{eq-SC Equation} and \eqref{eq-IFEM} of the main paper, respectively, which are restated below:
\begin{align}	\tag{\ref{eq-IFEM}}
Y_{t}
&
=
\text{\makebox[1.25cm]{$ \tau_{t}^* A_t + $}}
\bmu_{0} \T
\blambda_t
+
e_{0t}
\ ,
&&
\EXP \big( e_{0t} \cond \blambda_t ) = 0
\nonumber
\\
W_{it}
&
=
\text{\makebox[1.25cm]{}}
\bmu_{i} \T
\blambda_t
+
e_{it}
\ , 
&&
\EXP \big( e_{it} \cond \blambda_t ) = 0
\ , 
&&
i=1,\ldots,N \ ,
&&
t=1,\ldots,T \ .
\nonumber
\end{align}
and
\begin{align}		\tag{\ref{eq-SC Equation}}
\potY{t}{0}
=
\bW_{\D t} \T \bgamma^\dagger
+ 
e_{0t} 
-
\sum_{i \in \D} \gamma_i^{\dagger} e_{it} 
\ , 
\quad \quad
t=1,\ldots, T
\ .
\end{align}
The last line holds under the following additional assumptions on $\blambda_t$ and $e_{it}$ as $T_0 \rightarrow \infty$:
\begin{align*}
& 
\frac{1}{T_0} \sum_{t=1}^{T_0} \blambda_t = o_P(1) \ ,
&&
\frac{1}{T_0} \sum_{t=1}^{T_0} \blambda_t \blambda_t \T = \Lambda + o_P(1)
\\
&
\frac{1}{T_0} \sum_{t=1}^{T_0} {e}_{it} = o_P(1) \ ,
&&
\frac{1}{T_0} \sum_{t=1}^{T_0} {e}_{it} {e}_{jt} = \ind(i=j) \sigma_e^2 
\ , 
&&
\frac{1}{T_0} \sum_{t=1}^{T_0} e_{it} \blambda_t = o_P(1) 
 \ .
\end{align*}
where $\Lambda$ is positive semidefinite. Clearly, $\gamma_i^\dagger$ is not the minimizer of \eqref{eq-problimit} unless $\sigma_e^2 = 0$, i.e., a noiseless setting. Therefore, the OLS weights defined in \eqref{eq-OLS} converge to the minimizer of $Q(\bgamma)$ as $T_0 \rightarrow \infty$, which is different from the true synthetic control weights $\bgamma^\dagger$ satisfying $ \mu_{0} = \sum_{i \in \mathcal{D}} \gamma_i^{\dagger} \mu_i$. This implies that the OLS estimator is inconsistent for $\bgamma^\dagger$ unless $\sigma_e^2=0$.

\subsection{A Synthetic Control Estimator based on Regularized Generalized Method of Moments} \label{sec:supp:Regularized GMM}

We consider the following $\ell_2$-regularized generalized method of moments (GMM) by including ridge regularization in GMM:
\begin{align}						\label{eq-GMM-L2}
\big(
\widehat{\bgamma}_{\lambda}
,
\widehat{\bbeta}_{\lambda}
\big)
&
=
\argmin_{(\bgamma,\bbeta)}
\Big[
\big\{ \widehat{\Psi}( \bgamma, \bbeta) \big\} \T 
\widehat{\Omega}
\big\{ \widehat{\Psi}( \bgamma, \bbeta) \big\} 
+ 
\lambda \big\| \bgamma \big\|_2^2
\Big] \ .
\end{align}
We remark that other forms of regularization, such as lasso regularization \citep{Lasso1996}, are possible.
However, there are several advantages of using ridge regularization. 
First, for given $\lambda$, we can obtain a closed-form solution of the synthetic control weights to \eqref{eq-GMM-L2} as follows:
\begin{align*}
&
\widehat{\bgamma}_{\lambda}
=
\Big( \widehat{\bG}_{YW}\T \widehat{\Omega} \widehat{\bG}_{YW } + \lambda \widehat{\Omega} \Big)^{-1}
\Big( \widehat{\bG}_{YW }\T \widehat{\Omega} \widehat{\bG}_{YY } \Big) \ , 
\\
&
\widehat{\bG}_{YW} = 
\frac{1}{T_0}
\sum_{t =1}^{T_0} \bg_t(Y_t) \bW_{\D t}\T
\ , \
\widehat{\bG}_{YY } = 
\frac{1}{T_0}
\sum_{t=1}^{T_0} \bg_t(Y_t) Y_t \ .
\end{align*}
Second, we can establish the asymptotic normality of the estimator in \eqref{eq-GMM-L2} when $\lambda$ is chosen at a certain rate:
\begin{theorem}	\label{thm:Reg GMM}
Suppose the conditions of Theorem \ref{thm:AN} of the main paper are satisfied. Additionally, suppose the regularization parameter has a rate of $\lambda = o(T^{-1/2})$. Then, $T \rightarrow \infty$, we have
\begin{align*}
\sqrt{ T }
\Bigg\{
\begin{pmatrix}
\widehat{\bgamma}_{\lambda}
\\
\widehat{\bbeta}_{\lambda}
\end{pmatrix}
-
\begin{pmatrix}
\bgamma^* 
\\
\bbeta^*
\end{pmatrix}
\Bigg\}
\text{ converges in distribution to }
N \Big( 0, \Sigma_1^* \Sigma_2^* \Sigma_1\sT \Big) \ .
\end{align*}
Here, $\Sigma_1^*
=
\big( G\sT \Omega^* G^* \big)^{-1} G\sT \Omega^* $ and $
\Sigma_2^* 
=
\lim_{T \rightarrow \infty} \VAR \big\{ \sqrt{T} \cdot \widehat{\Psi}(\bgamma^*, \bbeta^*) \big\}$ where
\begin{align*}
G^* 
=
\lim_{T \rightarrow \infty} \frac{1}{T} \sum_{t=1}^{T}
\EXP
\bigg\{
\frac{\partial \Psi( \bO_t \con \bgamma,\bbeta) }{ \partial (\bgamma,\bbeta)\T }
\bigg\}
\bigg|_{ \bgamma=\bgamma^* , \bbeta=\bbeta^* }
\ , \
\Omega^* = \lim_{T \rightarrow \infty} \widehat{\Omega} \ .
\end{align*}
\end{theorem}
We remark that similar results are established in \citet{FuKnight2000, Fu2003, Caner2009}. In addition, we can establish a similar result when covariates are included. 







Following  Theorem \ref{thm:AN}, we may use $\widehat{\Sigma}_1
=
\big( \widehat{G}\T \widehat{\Omega} \widehat{G} \big)^{-1} \widehat{G}\T \widehat{\Omega}$ as an estimator of $\Sigma_1^*$.  Alternatively, to incorporate ridge regularization, one can use $ \widehat{\Sigma}_1
=
\big( \widehat{G}_{\lambda} \T \widehat{\Omega} \widehat{G}_{\lambda} \big)^{-1} \widehat{G}_{\lambda}\T \widehat{\Omega}$ where $\widehat{G}_{\lambda} = T^{-1} \sum_{t=1}^{T} \partial \Psi_{\lambda} ( \bO_t \con \bgamma, \bbeta) / \partial (\bgamma, \bbeta)\T \big|_{\bgamma = \widehat{\bgamma}, \bbeta = \widehat{\bbeta}} $ where
\begin{align*}
\Psi_\lambda (\bO_t \con \bgamma, \bbeta) 
= 
\begin{bmatrix}
(1-A_t)
\bg_t(Y_t) \big( Y_t - \bW_{\D t} \T \bgamma \big) 
\\
A_t \frac{\partial \tau(t \con \bbeta)}{\partial \bbeta \T} \big\{ Y_t - \bW_{\D t} \T \bgamma - \tau(t \con \bbeta) \big\}
\\
\sqrt{\lambda} \cdot \bgamma
\end{bmatrix}
\in \R^{p+b+d}
\ .
\end{align*}
The matrix $\Sigma_2^*$ can be estimated by a heteroskedasticity and autocorrelation consistent estimator with or without incorporating ridge regularization. Or, one can use block bootstrap methods to construct a variance estimator; see Section \ref{sec:supp:BB} for details. Lastly, we choose $\lambda$ based on leave-one-out cross-validation; see Algorithm \ref{alg:LOOCV} below.
\begin{algorithm}[!htb]
\begin{algorithmic}[1]
\REQUIRE Length of the pre-treatment periods $T_0$
\FOR{$t=1,\ldots,T_0$}

\STATE Let $\widehat{\bG}_{YW,(-t)}$ and $\widehat{\bG}_{YY,(-t)}$ be
\begin{align*}
\widehat{\bG}_{YW,(-t)} = 
\frac{1}{T_0-1}
\sum_{s=1, s\neq t}^{T_0} \bg_t(Y_s) \bW_{\D s}\T
\ , \
\widehat{\bG}_{YY,(-t)} = 
\frac{1}{T_0-1}
\sum_{s=1, s\neq t}^{T_0} \bg_t(Y_s) Y_s
\end{align*}


\STATE Let $\widehat{\bgamma}_{(-t),\lambda}
=
\big\{ \widehat{\bG}_{YW,(-t)}\T \widehat{\Omega} \widehat{\bG}_{YW,(-t)} + \lambda \widehat{\Omega} \big\}^{-1}
\big\{ \widehat{\bG}_{YW,(-t)}\T \widehat{\Omega} \widehat{\bG}_{YY,(-t)} \big\}$

\STATE Calculate the leave-one-out residual $
\widehat{e}_{t,\lambda} = Y_t - \bW_{\D t} \T \widehat{\bgamma}_{(-t),\lambda}$

\ENDFOR

\STATE Obtain the mean on the leave-one-out residuals $
\overline{e}_{t,\lambda} = T_0^{-1} \sum_{t=1}^{T_0} \widehat{e}_{t,\lambda}$

\RETURN Obtain the optimal $\lambda$ that minimizes the absolute value of $\overline{e}_{t,\lambda}$:
\begin{align*}
\lambda_{\text{opt}} = \argmin_{\lambda} \big| \overline{e}_{t,\lambda} \big|
\end{align*}
\end{algorithmic}
\caption{Leave-one-out Cross-validation for Choosing the Regularization Parameter $\lambda$}
\label{alg:LOOCV}
\end{algorithm}

\subsection{A Heteroskedasticity and Autocorrelation Consistent Covariance Matrix Estimator}		\label{sec:supp:HAC}

We provide details of a heteroskedasticity and autocorrelation consistent (HAC) covariance matrix estimator, which are obtained by following approaches of \citet{NW1987} and \citet{Andrews1991}. Let $\big( \widehat{\bgamma}, \widehat{\bbeta} \big) $ and $\Psi (\bO_t \con \bgamma , \bbeta)$ be the GMM estimators used in Theorem \ref{thm:AN} and the corresponding estimating function, respectively. Then, for a given bandwidth $\omega >0$ and a kernel function $\mathcal{K}(z)$, a heteroskedasticity and autocorrelation consistent estimator of $\Sigma_2^* =
\lim_{T \rightarrow \infty} \VAR \big\{ \sqrt{T} \cdot \widehat{\Psi}(\bgamma^*, \bbeta^*) \big\}$ is given as 
\begin{align*}
\widehat{\Sigma}_2
=
\frac{1}{T}
\sum_{t=1}^{T}
\left[
\begin{array}{l}
\big\{
\Psi( \bO_t \con \widehat{\bgamma} , \widehat{\bbeta} )
\big\}
\big\{
\Psi( \bO_t \con \widehat{\bgamma} , \widehat{\bbeta} )
\big\}\T
\\
+
\sum_{s=1}^{T} 
\mathcal{K} \big( s / \omega \big)
\big\{
\Psi( \bO_t \con \widehat{\bgamma} , \widehat{\bbeta} )
\big\}
\big\{
\Psi( \bO_{t+s} \con \widehat{\bgamma} , \widehat{\bbeta} )
\big\}\T
\\
+
\sum_{s=1}^{T} 
\mathcal{K} \big( s / \omega \big)
\big\{
\Psi( \bO_{t+s} \con \widehat{\bgamma} , \widehat{\bbeta} )
\big\}
\big\{
\Psi( \bO_{s} \con \widehat{\bgamma} , \widehat{\bbeta} )
\big\}\T
\end{array}
\right] \ .
\end{align*} 

Popular choices for the kernel function are Bartlett and quadratic spectral functions, which are defined as follows:
\begin{itemize}[itemsep=0cm,leftmargin=0.4cm]
\item Bartlett kernel: $\mathcal{K}(z) = \big\{ 1- |z| \big\} \ind\big\{ |z| \leq 1 \big\}$
\item Quadratic spectral kernel: $\mathcal{K}(z) = \big\{ {25}/{(12 \pi^2 z^2)} \big\} \cdot \big\{ \sin (6\pi z/5) / (6\pi z/5) - \cos (6\pi z/5) \big\} $
\end{itemize}

For these two kernel functions, the bandwidth parameter $\omega$ can be chosen based on the approximation to the first-order autoregressive model; see Algorithm \ref{alg:bandwidth} for details. We use the quadratic spectral kernel function for the simulation studies and the data analysis of the main paper.

\begin{algorithm}[!htb]
\begin{algorithmic}[1]
\STATE Let $\big( \widehat{\bgamma}, \widehat{\bbeta} \big) $ and $\Psi_{\post} (\bO_t \con \bgamma , \bbeta) \in \R^b$ be the GMM estimators used in Theorem \ref{thm:AN} and the corresponding estimating function related to $\bbeta$, respectively. 

\FOR{$s=1,\ldots,b$}

\STATE Fit AR(1) model for the $s$th component of the time series $\big\{ \Psi_{\post}(\bO_t \con \widehat{\bgamma}, \widehat{\bbeta} ) \big\}_{t=1,\ldots,T}$. 
\STATE Let $\widehat{\rho}_s$ and $\widehat{\sigma}_s^2$ be the estimated coefficient of the autoregressive coefficient and the estimated variance of the error from the AR(1) model above, respectively.
\ENDFOR

\STATE For Barlett and quadratic spectral kernel functions, we choose the bandwidth as
\begin{align*}
&
\omega_{\text{Bartlett}} 
=
1.1447 \big\{ \alpha_1 \cdot T \big\}^{1/3}
, 
&&
\hspace*{-0.25cm}
\alpha_1
=
\bigg\{ \sum_{s=1}^{b} \frac{ \widehat{\sigma}_s^4 }{ (1-\widehat{\rho}_s)^4 } \bigg\}^{-1}
\bigg\{ \sum_{s=1}^{b} \frac{ 4 \widehat{\rho}_s^2 \widehat{\sigma}_s^4 }{ (1-\widehat{\rho}_s)^6 (1+\widehat{\rho}_s)^2} \bigg\} 		
\\
&
\omega_{\text{QS}} 
=
1.3221 \big\{ \alpha_2 \cdot T \big\}^{1/5} 		
,
&&
\hspace*{-0.25cm}
\alpha_2
=
\bigg\{ \sum_{s=1}^{b} \frac{ \widehat{\sigma}_s^4 }{ (1-\widehat{\rho}_s)^4 } \bigg\}^{-1}
\bigg\{ \sum_{s=1}^{b} \frac{ 4 \widehat{\rho}_s^2 \widehat{\sigma}_s^4 }{ (1-\widehat{\rho}_s)^8} \bigg\} \ .
\end{align*}

\RETURN Bandwidth parameters $\omega_{\text{Bartlett}}$ and $\omega_{\text{QS}}$.
\end{algorithmic}
\caption{Choice of Bandwidth Parameters for Bartlett and Quadratic Spectral Kernel Functions}
\label{alg:bandwidth}
\end{algorithm}



\subsection{Block Bootstrap} \label{sec:supp:BB}

In this section, we provide a moving block bootstrap method \citep{Kunsch1989,Liu1992} adapted to our setting. Algorithm \ref{alg:MBB} provides details of the block bootstrap implementation. We remark that other block bootstrap methods can be adopted with minor modifications; see \citet{Lahiri1999} for examples of block bootstrap methods.

\begin{algorithm}[!htb]
\begin{algorithmic}[1]
\REQUIRE Length of the block $L < T_0$, Number of bootstrap repetitions $B$

\STATE Let the pre- and post-treatment blocks be
\begin{align*}
&
B_{\pre,1} = \big\{ \bO_1,\ldots,\bO_L \big\} , 
&& \ldots \ , 
&& B_{\pre,T_0-L+1} = \big\{ \bO_{T_0-L+1},\ldots,\bO_{T_0} \big\} 	
\\
&
B_{\post,1} = \big\{ \bO_{T_0+1},\ldots, \bO_{T_0+L} \big\} , 
&& \ldots \ , 
&& B_{\post,T_0-L+1} = \big\{ \bO_{T-L+1},\ldots, \bO_{T} \big\} 	
\end{align*} 	

\FOR{$b=1,\ldots,B$}

\STATE Randomly sample $K_{\pre} = \lceil T_0/L \rceil$ pre-treatment blocks and $K_{\post} = \lceil T_1/L \rceil$ post-treatment blocks with replacement, respectively; we denote these blocks as $\big\{ B_{\pre,1}^{(b)} ,\ldots, B_{\pre,K_{\pre}}^{(b)} \big\}$ and $\big\{ B_{\post,1}^{(b)} ,\ldots, B_{\post,K_{\post}}^{(b)} \big\}$

\STATE Choose the first $T_0$ and $T_1$ observations from the resampled blocks, i.e.,
\begin{align*}
&
\big\{ \bO_1^{(b)},\ldots,\bO_{T_0} ^{(b)} \big\}
=
\text{first $T_0$ observations of } \big\{ B_{\pre,1}^{(b)} ,\ldots, B_{\pre,K_{\pre}}^{(b)} \big\}
\\
&
\big\{ \bO_{T_0+1}^{(b)},\ldots,\bO_{T} ^{(b)} \big\}
=
\text{first $T_1$ observations of } \big\{ B_{\post,1}^{(b)} ,\ldots, B_{\post,K_{\post}}^{(b)} \big\}
\end{align*}

\STATE Calculate $\widehat{\bbeta}^{(b)}$ from the GMM in Section \ref{sec:Estimation} using $\big\{ \bO_1^{(b)},\ldots,\bO_{T_0} ^{(b)} , \bO_{T_0+1}^{(b)},\ldots,\bO_{T} ^{(b)} \big\}$. 	

\ENDFOR

\RETURN Report the variance of the bootstrap estimates $\big\{ \widehat{\bbeta}^{(1)}, \ldots, \widehat{\bbeta}^{(B)} \big\}$
\end{algorithmic}
\caption{Moving Block Bootstrap in Single Proxy Synthetic Control Framework}
\label{alg:MBB}
\end{algorithm}


The choice of block length $L$ is critical to the performance of block bootstrap methods. The optimal choice of $L$ for minimizing mean square error is known to be $O(T^{1/3})$. In the simulation studies in Section \ref{sec:Sim}, we use the bandwidth of the Bartlett kernel function $\omega_{\text{Bartlett}}$ in Algorithm \ref{alg:bandwidth} of which the rate is $O(T^{1/3})$. As discussed, this choice seems reasonable based on the simulation results reported in Section \ref{sec:supp:Simulation}. 
 

\subsection{An Example of Time-varying $g_t$ Functions}	\label{sec:supp:time g function}

Suppose that $\potY{t}{0}$ in the pre-treatment period appears to be nonstationary based on statistical procedures, such as Box-Pierce and Ljung-Box tests \citep{BoxPierce1970, LjungBox1978}. Under this case, one may use time periods in estimation of the synthetic control, which may improve performance. In order to implement this, one can use a time-varying coefficient function $\bg_t$ in the pre-treatment estimating function $\Psi_\pre$. For example, one can specify $\bg_t$ as follows:
\begin{align}   \label{eq-example gt}
\bg_t(y)
=
\begin{bmatrix}
\bphi_{\potY{t}{0}} (y)
\\
\bphi_{\mathcal{T}} (t)
\end{bmatrix}
\in \R^{p_y + p_t}
\end{align}
where $\bphi_{\potY{t}{0}}: \text{supp} (\{ \potY{t}{0}\,| \, t=1,\ldots,T_0 \}) \rightarrow \R^{p_y}$ and $\bphi_{\mathcal{T}}: [0,T] \rightarrow \R^{p_t}$ are collections of $p_y$ and $p_t$ bases functions associated with $\potY{t}{0}$ and $t$, respectively. Using a time-varying $\bg_t$, one can obtain a synthetic control estimator and an ATT estimator by following the proposed approach in the main paper. 
The aforementioned adjustment is also applicable to the conformal inference discussed in Section \ref{sec:Conformal}. In particular, under null hypotheses $H_0: \xi_t^* = \xi_{0t}$ for $t\in \{T_0+1,\ldots,T\}$, the pre-treatment estimating function $\Psi_{\pre}$ is given as follows:
\begin{align*}
\Psi_{\pre} (\bO_t \con \bgamma, \xi_{0,T_0+1},\ldots,\xi_{0,T})
=
\left\{
\begin{array}{lll}
\bg_t (Y_t)
\big( Y_t - \bW_{\D t} \T \bgamma \big)
&
\quad
&
t = 1,\ldots,T_0
\\
\bg_t ( Y_t - \xi_{0t})
\big( Y_t - \xi_{0t} - \bW_{\D t} \T \bgamma \big)
&
\quad
&
t = T_0+1,\ldots,T
\end{array}
\right. 
\ ,
\end{align*}
where $g_t$ is specified as \eqref{eq-example gt}. The rest of the procedure remains the same as in Section \ref{sec:Conformal}. In Section \ref{sec:supp:Simulation PI}, we demonstrate that incorporating a time-varying $g_t$ improves the performance of the conformal approach in Section \ref{sec:Conformal} in the presence of nonstationarity. 



% Under this specification of $\bg_t$, the synthetic control weights are estimated from the modified GMM over the pre-treatment periods as follows:
% \begin{align*}
% &
% \widehat{\bgamma}
% =
% \argmin_{\bgamma}
% \big\{ 
% \widehat{\Psi}_{\pre} ( \bgamma ) 
% \big\} \T
% \widehat{\Omega}_{\pre}
% \big\{ 
% \widehat{\Psi}_{\pre} ( \bgamma ) 
% \big\}
% \ , \
% \Psi_{\pre} (\bO_t \con \bgamma)
% =
% \bg_t(Y_t , t)
% \big( Y_t - \bW_{\D t} \T \bgamma \big)
% \ , \
% t = 1,\ldots,T_0 \ .
% \end{align*}
% The predicted value of the treatment-free post-treatment potential outcome of the treated unit remains the same form as $\widehat{Y}_t^{(0)} = \bW_{\D t}\T \widehat{\bgamma}$ for $t=T_0+1,\ldots,T$. In the construction of the synthetic control, we remark that the post-treatment periods are not used. More specifically, although the pre-treatment periods $t=1,\ldots,T_0$ are used to construct the synthetic control weights by serving as an argument of $\bg_t$, the post-treatment periods $t=T_0+1,\ldots,T$ are not used in the prediction. 

% An alternative strategy is to use the time period as an exogenous covariate by considering the following pre-treatment estimating equation:
% \begin{align*}
% \Psi_{\pre} (\bO_t \con \bgamma, \bdelta)
% =
% \bg_t(Y_t)
% \big\{ Y_t - \bW_{\D t} \T \bgamma - \mu(t \con \bdelta) \big\} \ ,
% \end{align*}
% where $\mu(t \con \bdelta)$ is a user-specified function parametrized by $\bdelta$, which is employed to address nonstationary behavior of $Y_t$ and $\bW_{\D t}$. For instance, one can choose $\mu(t \con \bdelta) = \delta_0 + \delta_1 t$. Technically speaking, this requires an additional assumption that $\potY{t}{0} = \EXP \big\{ \bW_{\D t} \T \bgamma - \mu(t \con \bdelta) \cond \potY{t}{0} \big\}$ almost surely for all $t=1,\ldots,T$. Under this framework, the predicted value of the treatment-free post-treatment potential outcome of the treated unit has a form of $\widehat{Y}_t^{(0)} = \bW_{\D t}\T \widehat{\bgamma} + \mu(t \con \widehat{\bdelta})$ for $t=T_0+1,\ldots,T$. Unfortunately, choosing a good candidate for $\mu$ can be problematic in practice because, even though $\mu$ may be a good choice over the pre-treatment periods, it may not be a suitable choice for the post-treatment periods. In other words, the extrapolation of $\mu$ over the post-treatment periods could lead to a significant amount of bias, especially when $t$ is very far from $T_0$. Moreover, in numerous real-world datasets, a well-constructed synthetic control of donors $\bW_{\D t} \T \widehat{\bgamma}$ might already eliminate the nonstationary time trends of $\potY{t}{0}$. In such cases, introducing $\mu$ could result in non-diminishing bias. Hence, we suggest setting $\mu(t \con \bdelta)=0$ for all $t$.




\subsection{Selection of a Donor Pool} \label{sec:supp:Donors}

We provide a procedure for how to choose a donor pool when many donor candidates are available. In Algorithm \ref{alg:Donor Pool}, we present details of the procedure. The key idea of the procedure is to select donors that seem to satisfy Assumption \ref{assumption:valid proxy}, which is $\bW_{i t} \nindep \potY{t}{0}$ for all $i \in \D$ and $t=1,\ldots,T_0$. In other words, donor candidates that appear to be independent of $\potY{t}{0}$ are discarded. The approach is akin to the widely-used backward selection technique employed in linear regression models. 

% We provide additional reasons why we consider the regression model in line 4 of Algorithm \ref{alg:Donor Pool}. It is well-known that there may be spurious relationships among time series, especially in the presence of nonstationarity. Therefore, regressing a donor $W_{it}$ on $\potY{t}{0}$ without using other donors may exhibit a statistically significant relationship even if they are statistically independent. Therefore, using this marginal regression model may not be useful for selecting donors. To address this issue, we propose to include the other donors $\big\{W_{st} \cond s \in \D \setminus \{i\} \big\}$ as additional regressors. By doing so, we may account for spurious relationships and detect associations between $W_{it}$ and $\potY{t}{0}$ better.

\begin{algorithm}[!htb]
\begin{algorithmic}[1]
\REQUIRE Number of donor candidates $N$, Threshold p-value level $\alpha$ (e.g., $\alpha=0.05$)

\STATE Initiate with $\D = \{ 1,\ldots,N \}$
\WHILE{Until \texttt{break} in line 11}
\FOR{$i \in \D$}
\STATE Using pre-treatment periods $t=1,\ldots, T_0$, fit a linear regression model of $W_{it}$ on $(\potY{t}{0}, \{ W_{st} \}_{s \in \D \setminus \{i\} })$, i.e., $
W_{it} = b_{iY} \potY{t}{0} + \sum_{s \neq t} b_{i s} W_{st} + e_{it}$
\STATE Let $p_i$ be the p-value of testing $H_0: b_{iY}=0$ based on the ordinary least squares estimator
\ENDFOR 	
\STATE Find a donor associated with the largest p-value, i.e., $m = \argmax_{i \in \D} p_i$
\IF{$p_m > \alpha$}
\STATE Drop $m$ from the donor pool, i.e., $\D \leftarrow \D \setminus \{m \}$
\ELSE
\STATE \texttt{Break} the while loop
\ENDIF
\ENDWHILE

\RETURN A subset of donors $\mathcal{D} \subseteq \{1,\ldots,N \}$		

\end{algorithmic}
\caption{Choice of a Donor Pool}
\label{alg:Donor Pool}
\end{algorithm}


We provide some detailed explanations for each step. Initially, we include all $W_{it}$ for $i=1,\ldots,N$ in the donor pool, denoted by $\D$ (line 1). Next, we conduct regression models, treating each donor as a dependent variable, while considering $\potY{t}{0}$ and the other donors in $\D$ as independent variables (line 4). From each regression model, we calculate the p-value of the coefficient associated with $\potY{t}{0}$ (line 5). If the largest p-value exceeds the predetermined threshold level $\alpha$, we discard the donor associated with the largest p-value from $\D$ (line 9). This iterative process continues until all p-values are below the threshold level $\alpha$ (line 11), resulting in the selection of the remaining donors as the final donor pool (line 14).

We provide further justification for employing the regression model in line 4 of Algorithm \ref{alg:Donor Pool}. It is well-recognized that spurious relationships among time series (especially in the presence of nonstationarity) can lead to misleading results. In the context of synthetic control, regressing a donor $W_{it}$ solely on $\potY{t}{0}$ without adjusting other donors may exhibit a statistically significant relationship even if they are statistically independent. Thus, relying solely on this marginal regression model may not be sufficient for selecting appropriate donors. In order to address this concern, we propose including the other donors $\big\{W_{st} \cond s \in \D \setminus {i} \big\}$ as additional regressors. By doing so, we can account for potential spurious relationships and better detect genuine associations between $W_{it}$ and $\potY{t}{0}$. This refined approach improves the reliability and accuracy of the donor pool selection process.
 

\subsection{Extension: Covariate Adjustment}		\label{sec:Cov}

In practice, a rich collection of measured exogenous covariates may be available. One may want to incorporate these covariates in the synthetic control analysis because using these covariates may improve efficiency. In this Section, we provide details on the SPSC framework by incorporating measured covariates. Specifically, we denote $q$-dimensional measured exogenous covariates for unit $i = 0,\ldots,N$ at time $t=1,\ldots,T$ as $\bX_{it} \in \R^{q}$; we remind the readers that $i=0$ is the treated unit and $i=1,\ldots,N$ are the untreated units. Let $\bX_{\D t} = ( \bX_{\D_1 t}\T,\ldots,\bX_{\D_d t}\T)\T \in \R^{dq}$ be the collection of all measured covariates of donors $\D$ at time $t$. To account for covariates, we modify Assumptions \ref{assumption:valid proxy} and \ref{assumption:SC} as follows:
\begin{assumption}[Proxy in the Presence of Covariates] \label{assumption:valid proxy Cov}
There exists a set of control units $\D = \{ \D_1,\ldots,\D_d \} \subseteq \{1,\ldots,N \}$ satisfying
\begin{align*}
&
\bW_{i t} \nindep \potY{t}{0} \cond (\bX_{0t}, \bX_{\D t})
\ , \quad \quad
i \in \D
\ , \quad \quad
t = 1,\ldots,T_0 \ .
\end{align*}
\end{assumption}

\begin{assumption}[Existence of Synthetic Control in the Presence of Covariates]
\label{assumption:SC Cov}
For all $t=1,\ldots,T$, there exist $\bgamma^* = (\gamma_{\D_1}^*,\ldots,\gamma_{\D_d}^*)\T$, $\bdelta_{0}^{*} \in \R^q$, and $\bdelta_\D^* = ( \bdelta_{\D_1}\sT,\ldots,\bdelta_{\D_d}\sT)\T \in \R^{dq}$ that satisfy $\EXP \big[
\big\{
\potY{t}{0} 
-
\bX_{0 t} \T \bdelta_{0}^*
\big\}
-
\big\{
\bW_{\D t}\T \bgamma^*
-
\bX_{\D t} \T \bdelta_{\D}^*
\big\}
\cond
\potY{t}{0}, \bX_{0t} , 
\bX_{\D t}
\big]
=
0$.
\end{assumption}
Similar to the result established under the absence of covariates, we establish the following identification results under Assumptions \ref{assumption:valid proxy Cov} and \ref{assumption:SC Cov} when covariates are available:
\begin{theorem} \label{thm:identification cov}
Under Assumptions \ref{assumption:consistency}, \ref{assumption:noitf}, \ref{assumption:valid proxy Cov}, and \ref{assumption:SC Cov}, the synthetic control weights $\bgamma^*$ satisfy $\EXP \big \{ (Y_t - \bX_{0t}\T \bdelta_0^*) - ( \bW_{it}\T \bgamma^* - \bW_{\D t}\T \bdelta_\D^* ) \cond Y_t, \bX_{0t} , 
\bX_{\D t} \big\} = 0 $ for $t=1,\ldots,T_0$. Moreover, we have $
\EXP \big\{ \potY{t}{0} - \bX_{0t}\T \bdelta_0^* \big\} 
= \EXP \big( \bW_{\D t}\T \bgamma^* - \bX_{\D t}\T \bdelta_\D^* \big)$ for any $t=1,\ldots,T$. 
Lastly, the ATT is identified as $\tau_t^*
=
\EXP
\big\{
\big(
Y_t
-
\bX_{0 t} \T \bdelta_{0}^*
\big)
-
\big(
\bW_{\D t}\T \bgamma^*
-
\bX_{\D t} \T \bdelta_{\D}^*
\big) 
\big\}$ for $t = T_0+1,\ldots,T$. 
\end{theorem}
Leveraging the result of the Theorem, estimation and inference of the ATT with covariate adjustment can be established, which is a straightforward extension of Section \ref{sec:Estimation}. First, we define the following estimating function:
\begin{align}			\label{eq-Moment-Cov}
&
\Psi_{\text{Cov}}( \bO_t \con \bgamma, \bbeta, \bdelta_0, \bdelta_\D)
\\
&
=
\begin{bmatrix}
(1-A_t)
\bg_t(Y_t, \bX_{0t}, \bX_{\D t})
\big\{ 
\big(
Y_t
-
\bX_{0 t} \T \bdelta_{0}
\big)
-
\big(
\bW_{\D t}\T \bgamma
-
\bX_{\D t} \T \bdelta_{\D}
\big)
\big\}
\\
A_t 
\frac{\partial \tau(t \con \bbeta) }{\partial \bbeta } 
\big\{
\big(
Y_t
-
\bX_{0 t} \T \bdelta_{0}
\big)
-
\big(
\bW_{\D t}\T \bgamma
-
\bX_{\D t} \T \bdelta_{\D}
\big) - \tau (t \con \bbeta)
\big\}
\end{bmatrix}
\in \R^{p_x+b} \ ,
\nonumber
\end{align}
where $\bO_t = (Y_t,\bW_{\D t}, \bX_{0t}, \bX_{\D t}, A_t)$ is the collection of the observed data at time $t$, $\bg_t(\cdot)$ is a $p_x$-dimensional user-specified function of $(Y_t,\bX_{0t},\bX_{\D t})$ (which can be time-varying) with $p_x \geq \text{dim}(\bW_{\D t}, \bX_{0t} , \bX_{\D t}) = d+q+dq$, and $\tau(t \con \bbeta)$ is a user-specified treatment effect function. We assume that the treatment effect function is chosen so that the associated error process is weakly dependent:
\begin{assumption}[Weakly Dependent Error in the Presence of Covariates] \label{assumption:weakdep Cov}
Let $\epsilon_t$ be $\epsilon_t = \big(
Y_t
-
\bX_{0 t} \T \bdelta_{0}^*
\big)
-
\big(
\bW_{\D t}\T \bgamma^*
-
\bX_{\D t} \T \bdelta_\D^*
\big) - \tau (t \con \bbeta^*) $. Then, the error process $\big\{ \epsilon_t \cond t = 1,\ldots,T \big\}$ satisfies Assumption \ref{assumption:weakdep}, i.e., $\text{corr}(\epsilon_{t}, \epsilon_{t+t'})$ converges to 0 as $t' \rightarrow \pm \infty$.
\end{assumption}	
We then establish the asymptotic normality of the GMM estimators $( \widehat{\bgamma}, \widehat{\bbeta}, \widehat{\bdelta}_0, \widehat{\bdelta}_\D ) $; see the formal statement below:
\begin{theorem}	\label{thm:AN Cov}
Suppose Assumptions \ref{assumption:consistency}, \ref{assumption:noitf}, \ref{assumption:valid proxy Cov}, \ref{assumption:SC Cov}, and \ref{assumption:weakdep Cov} hold, $(\bgamma^*,\bbeta^*,\bdelta_0^*,\bdelta_{\D}^*)$ are unique, and Regularity Conditions in Section \ref{sec:supp:AN} hold. Let $( \widehat{\bgamma}, \widehat{\bbeta}, \widehat{\bdelta}_0, \widehat{\bdelta}_\D ) $ be the GMM estimators where the estimating function \eqref{eq-Moment-Cov} is used, i.e., 
\begin{align*}
\big(
\widehat{\bgamma}
,
\widehat{\bbeta}
, 
\widehat{\bdelta}_0
,
\widehat{\bdelta}_\D 
\big)
=
\argmin_{(\bgamma,\bbeta)}
\big\{ \widehat{\Psi}_{\text{Cov}}( \bgamma, \bbeta, \delta_0, \delta_{\D}) \big\} \T
\widehat{\Omega}_{\text{Cov}}
\big\{ \widehat{\Psi}_{\text{Cov}}( \bgamma, \bbeta, \delta_0, \delta_{\D}) \big\} \ ,
\end{align*}
where $	\widehat{\Psi}_{\text{Cov}}(\bgamma, \bbeta, \delta_0, \delta_{\D})
= T^{-1}
\sum_{t=1}^{T} \Psi_{\text{Cov}} (\bO_t \con \bgamma, \bbeta, \delta_0, \delta_{\D})$ is the empirical mean of the estimating function and $\widehat{\Omega}_{\text{Cov}} \in \R^{(p+b) \times (p+b)}$ a user-specified symmetric positive definite block-diagonal matrix as $\widehat{\Omega}_{\text{Cov}} = \text{diag}( \widehat{\Omega}_{\text{Cov},\pre} , \widehat{\Omega}_{\text{Cov},\post} )$. Then, as $T \rightarrow \infty$, we have
\begin{align*}
\sqrt{ T }
\left\{
\begin{pmatrix}
\widehat{\bgamma}
\\
\widehat{\bbeta}
\\
\widehat{\bdelta}_0
\\
\widehat{\bdelta}_\D 
\end{pmatrix}
-
\begin{pmatrix}
\bgamma^*
\\
\bbeta^* 
\\
\bdelta_0^*
\\
\bdelta_\D^*
\end{pmatrix}
\right\}
\text{ converges in distribution to }
N \big( 0, \Sigma_{\text{Cov},1}^* \Sigma_{\text{Cov},2}^* \Sigma_{\text{Cov},1}\sT \big) \ ,
\end{align*}
where
\begin{align*}
&
\Sigma_{\text{Cov},1}^*
=
\big( G_{\text{Cov}}\sT \Omega_{\text{Cov}}^* G_{\text{Cov}}^* \big)^{-1} G_{\text{Cov}}\sT \Omega_{\text{Cov}}^* 
\quad , \quad 
\Sigma_{\text{Cov},2}^* 
=
\lim_{T \rightarrow \infty} \VAR \big\{ \sqrt{T} \cdot \widehat{\Psi}_{\text{Cov}}(\bgamma^*, \bbeta^*,\delta_0^*,\delta_{\D}^*) \big\}
\\
&
G_{\text{Cov}}^* 
=
\lim_{T \rightarrow \infty} \frac{1}{T} \sum_{t=1}^{T}
\EXP
\bigg\{
\frac{\partial \Psi_{\text{Cov}}( \bO_t \con \bgamma,\bbeta,\delta_0,\delta_{\D}) }{ \partial (\bgamma,\bbeta,\delta_0,\delta_{\D})\T }
\bigg\}
\bigg|_{ \bgamma=\bgamma^* , \bbeta=\bbeta^*, \delta_0 = \delta_0^*,\delta_{\D}=\delta_{\D}^* }
\quad , \quad
\Omega_{\text{Cov}}^* = \lim_{T \rightarrow \infty} \widehat{\Omega}_{\text{Cov}} \ .
\end{align*}
\end{theorem}
Estimators of $\Sigma_{\text{Cov},1}^*$ and $\Sigma_{\text{Cov},2}^*$ can be similarly defined as in Section \ref{sec:Estimation}, thus we omit the details here.





\subsection{Additional Simulation Studies} \label{sec:supp:Simulation}

We restate the data generating process of the simulation studies in Section \ref{sec:Sim}. The length of pre- and post-treatment periods were given by $T_0 = T_1 \in \{ 50, 100, 250, 1000 \}$ and the number of donors were given by $d \in \{2,5,9\}$. For each value of $T_0$, $T_1$, and $d$, we generated all errors for $t=1,\ldots,T$ based on the AR(2):
\begin{align*}
&
\epsilon_{x_i,t} = 0.2 \epsilon_{x_i,t-1} + 0.1 \epsilon_{x_i,t-2} + \eta_{x_i,t}
\ , \ i=0,\ldots,d \ ,
&&
\epsilon_{y,t} = 0.2 \epsilon_{y,t-1} + 0.1 \epsilon_{y,t-2} + \eta_{y,t}
\\
&
\epsilon_{w_i,t} = 0.2 \epsilon_{w_i,t-1} + 0.1 \epsilon_{w_i,t-2} + \eta_{w_i,t}
\ , \ i=1,\ldots,d \ ,
&&
\epsilon_{\tau,t} = 0.2 \epsilon_{\tau,t-1} + 0.1 \epsilon_{\tau,t-2} + \eta_{\tau,t}
\end{align*}
where $\eta$ were generated from a standard normal distribution. The errors $\epsilon_{t}$ at $t=-1,0$ were initialized to equal zero. The exogenous covariates $\bX_t = \{ X_{0t}, X_{\D_1 t} , \ldots,X_{\D_d t} \}$ were generated as 
\begin{align*}
 X_{it} = 0.2 X_{i,t-1} + 0.1 X_{i,t-2} + \epsilon_{x_i,t} \ , \ i=0,\ldots,d \ .
\end{align*}
The treatment-free potential outcomes at $t=1,\ldots,T$ were generated as 
\begin{align*}
 \potY{t}{0} = 0.2 \potY{t-1}{0} + 0.1 \potY{t-2}{0} + t/T_0 + \delta X_{0t} + \epsilon_{y,t} \ .
\end{align*}
We considered two cases for $\delta \in \{0,1\}$, which encodes whether the covariates are predictive of $\potY{t}{0}$, in which case $\delta=1$, or not predictive, in which case $\delta=0$, respectively. The potential outcomes at $t=1,\ldots,T$ were under treatment were generated as 
\begin{align*}
 \potY{t}{1} = \potY{t}{0} + 3 A_t + \epsilon_{\tau,t} \ , \ 
 t=1,\ldots,T \ .
\end{align*}
Therefore, the ATT is $\tau_t^* = 3$ for all $t=T_0+1,\ldots,T$, and $\xi_t^* = \potY{t}{1} - \potY{t}{0} = 3 \ind(t \geq T_0) + \epsilon_{\tau,t}$. Lastly, we generated $\bW_{\D t} \in \R^{d}$ so that it satisfies Assumptions \ref{assumption:valid proxy} and \ref{assumption:SC} if $\delta=0$, and the corresponding assumptions made for incorporating covariates if $\delta=1$. Specifically, we considered the following data generating process for $\bW_{\D t}$ according to the number of donors $d \in \{2,5,9\}$:
\begin{itemize}[leftmargin=0cm, itemsep=0cm]
\item[($d=2$)] 
\begin{align*}
\bW_{\D t}
=
\begin{bmatrix}
2 & -1 \\
-1 & 2 
\end{bmatrix}
\begin{bmatrix}
1 \\ \potY{t}{0}
\end{bmatrix}
+
\delta
\bX_{\D t}
+ 
\bepsilon_{\D t}
\end{align*} 
The true synthetic control weights are $\bgamma^* = (1/3,2/3)$.


\item[($d=5$)] 
\begin{align*}
\bW_{\D t}
=
\begin{bmatrix}
2 & -1 & 0 & 0 & 0 
\\
0 & 2 & -1 & 0 & 0
\\
0 & 0 & 2 & -1 & 0
\\
0 & 0 & 0 & 2 & -1
\\
-1 & 0 & 0 & 0 & 2
\end{bmatrix}
\begin{bmatrix}
1 \\ \potY{t}{0} \\ 0.5 \big\{ \potY{t}{0} \big\}^2 \\ \ind \big\{ \potY{t}{0} > 3 \big\} \\ \ind \big\{ \potY{t}{0} < 0 \big\}
\end{bmatrix}
+
\delta 
\bX_{\D t}
+ 
\bepsilon_{\D t}
\end{align*} 
The true synthetic control weights are $\bgamma^* \simeq ( 0.26 , 0.52 , 0.03 , 0.06 , 0.13)$. 


\item[($d=9$)] 
\begin{align*}
\bW_{\D t}
=
\begin{bmatrix}
2 & -1 & 0 & 0 & 0 & 0 & 0 & 0 & 0
\\
0 & 2 & -1 & 0 & 0 & 0 & 0 & 0 & 0
\\
0 & 0 & 2 & -1 & 0 & 0 & 0 & 0 & 0
\\
0 & 0 & 0 & 2 & -1 & 0 & 0 & 0 & 0
\\
0 & 0 & 0 & 0 & 2 & -1 & 0 & 0 & 0
\\
0 & 0 & 0 & 0 & 0 & 2 & -1 & 0 & 0
\\
0 & 0 & 0 & 0 & 0 & 0 & 2 & -1 & 0
\\
0 & 0 & 0 & 0 & 0 & 0 & 0 & 2 & -1
\\
-1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 2
\end{bmatrix}
\begin{bmatrix}
1 \\ \potY{t}{0} \\ 0.5 \big\{ \potY{t}{0} \big\}^2 \\ 
\ind \big\{ \potY{t}{0} > 3 \big\} \\ \ind \big\{ \potY{t}{0} < 0 \big\}
\\
\ind \big\{ \potY{t}{0} \in [0,1) \big\} \\ \ind \big\{ \potY{t}{0} \in [1,2) \big\}
\\
\exp \big[ 0.4 \big\{ \potY{t}{0} - 1.5 \big\} \big]
\\
\exp \big[ -0.4 \big\{ \potY{t}{0} - 1.5 \big\} \big]
\end{bmatrix}
+
\delta 
\bX_{\D t}
+ 
\bepsilon_{\D t}
\end{align*} 
The true synthetic control weights are $\bgamma^* \simeq (0.25,0.501,0.002,0.004,0.008,0.016,0.031,0.063,0.125)$.
\end{itemize} 

We set $\bg_t(\potY{t}{0})$ as time-invariant cubic B-spline bases functions with dimensions equal to twice the number of donors, i.e., $\bg_t(y) = \mathfrak{b}_{2d}( \cdot )$ where $\mathfrak{b}_{k}( \cdot )$ the $k$-dimensional cubic B-spline bases function. The knots of the spline functions were chosen based on the empirical quantiles of the pre-treatment outcomes. 



In Table \ref{tab:supp:Table00}, we first present numerical summaries of the simulation studies considered in the main paper. Each table is written in the following format:
\begin{itemize}[itemsep=0cm,leftmargin=0cm]
\item Bias row shows the empirical bias of 500 estimates;
\item ASE row shows the asymptotic standard error obtained from the sandwich variance estimator;
\item BSE row shows the bootstrap standard error obtained from the approach in Section \ref{sec:supp:BB} of the Supplementary Material;
\item ESE row shows the standard deviation of 500 estimates;
\item MSE row shows the mean squared error of 500 estimates;
\item Cover (ASE) and Cover (BSE) show the empirical coverage rates of 95\% confidence intervals based on the asymptotic and bootstrap standard errors, respectively;
\item Bias, standard errors, and mean squared error are scaled by factors of 10, 10, and 100, respectively, for readability.	
\end{itemize}
We remark that the results in Table \ref{tab:supp:Table00} are similar to those in Table \ref{tab:Sim:Constant d9d0}.

% Figure environment removed

\begin{table}[!htp]
\renewcommand{\arraystretch}{1.05} \centering
\footnotesize
\setlength{\tabcolsep}{3pt} 
\hspace*{-0.25cm}
\begin{tabular}{|ccc|cccc|cccc|cccc|}
\hline
\multicolumn{3}{|c|}{Estimator} & \multicolumn{4}{c|}{OLS} & \multicolumn{4}{c|}{SPSC} & \multicolumn{4}{c|}{SPSC-Ridge} \\ \hline
\multicolumn{1}{|c|}{$\ \delta \ $} & \multicolumn{1}{c|}{$\ d \ $} & $T_0$ & \multicolumn{1}{c|}{50} & \multicolumn{1}{c|}{100} & \multicolumn{1}{c|}{250} & 1000 & \multicolumn{1}{c|}{50} & \multicolumn{1}{c|}{100} & \multicolumn{1}{c|}{250} & 1000 & \multicolumn{1}{c|}{50} & \multicolumn{1}{c|}{100} & \multicolumn{1}{c|}{250} & 1000 \\ \hline

\multicolumn{1}{|c|}{\multirow{21}{*}{0}} & \multicolumn{1}{c|}{\multirow{7}{*}{2}} & Bias ($\times$10) & \multicolumn{1}{c|}{$5.042$} & \multicolumn{1}{c|}{$4.987$} & \multicolumn{1}{c|}{$4.931$} & \multicolumn{1}{c|}{$4.918$} & \multicolumn{1}{c|}{$-0.204$} & \multicolumn{1}{c|}{$-0.107$} & \multicolumn{1}{c|}{$-0.165$} & \multicolumn{1}{c|}{$-0.003$} & \multicolumn{1}{c|}{$0.325$} & \multicolumn{1}{c|}{$0.170$} & \multicolumn{1}{c|}{$-0.032$} & \multicolumn{1}{c|}{$0.047$} \\ \cline{3-15}
\multicolumn{1}{|c|}{} & \multicolumn{1}{c|}{} & ASE ($\times$10) & \multicolumn{1}{c|}{$2.366$} & \multicolumn{1}{c|}{$1.749$} & \multicolumn{1}{c|}{$1.161$} & \multicolumn{1}{c|}{$0.605$} & \multicolumn{1}{c|}{$2.930$} & \multicolumn{1}{c|}{$2.116$} & \multicolumn{1}{c|}{$1.383$} & \multicolumn{1}{c|}{$0.706$} & \multicolumn{1}{c|}{$2.841$} & \multicolumn{1}{c|}{$2.086$} & \multicolumn{1}{c|}{$1.374$} & \multicolumn{1}{c|}{$0.705$} \\ \cline{3-15}
\multicolumn{1}{|c|}{} & \multicolumn{1}{c|}{} & BSE ($\times$10) & \multicolumn{1}{c|}{$2.620$} & \multicolumn{1}{c|}{$1.952$} & \multicolumn{1}{c|}{$1.332$} & \multicolumn{1}{c|}{$0.742$} & \multicolumn{1}{c|}{$3.385$} & \multicolumn{1}{c|}{$2.371$} & \multicolumn{1}{c|}{$1.611$} & \multicolumn{1}{c|}{$0.860$} & \multicolumn{1}{c|}{$3.127$} & \multicolumn{1}{c|}{$2.332$} & \multicolumn{1}{c|}{$1.577$} & \multicolumn{1}{c|}{$0.858$} \\ \cline{3-15}
\multicolumn{1}{|c|}{} & \multicolumn{1}{c|}{} & ESE ($\times$10) & \multicolumn{1}{c|}{$2.874$} & \multicolumn{1}{c|}{$1.979$} & \multicolumn{1}{c|}{$1.264$} & \multicolumn{1}{c|}{$0.605$} & \multicolumn{1}{c|}{$3.331$} & \multicolumn{1}{c|}{$2.430$} & \multicolumn{1}{c|}{$1.486$} & \multicolumn{1}{c|}{$0.741$} & \multicolumn{1}{c|}{$3.270$} & \multicolumn{1}{c|}{$2.403$} & \multicolumn{1}{c|}{$1.470$} & \multicolumn{1}{c|}{$0.742$} \\ \cline{3-15}
\multicolumn{1}{|c|}{} & \multicolumn{1}{c|}{} & MSE ($\times$100) & \multicolumn{1}{c|}{$33.665$} & \multicolumn{1}{c|}{$28.777$} & \multicolumn{1}{c|}{$25.914$} & \multicolumn{1}{c|}{$24.551$} & \multicolumn{1}{c|}{$11.113$} & \multicolumn{1}{c|}{$5.906$} & \multicolumn{1}{c|}{$2.231$} & \multicolumn{1}{c|}{$0.549$} & \multicolumn{1}{c|}{$10.779$} & \multicolumn{1}{c|}{$5.791$} & \multicolumn{1}{c|}{$2.157$} & \multicolumn{1}{c|}{$0.551$} \\ \cline{3-15}
\multicolumn{1}{|c|}{} & \multicolumn{1}{c|}{} & Cover (ASE) & \multicolumn{1}{c|}{$0.458$} & \multicolumn{1}{c|}{$0.230$} & \multicolumn{1}{c|}{$0.034$} & \multicolumn{1}{c|}{$0.000$} & \multicolumn{1}{c|}{$0.916$} & \multicolumn{1}{c|}{$0.904$} & \multicolumn{1}{c|}{$0.928$} & \multicolumn{1}{c|}{$0.940$} & \multicolumn{1}{c|}{$0.908$} & \multicolumn{1}{c|}{$0.902$} & \multicolumn{1}{c|}{$0.932$} & \multicolumn{1}{c|}{$0.940$} \\ \cline{3-15}
\multicolumn{1}{|c|}{} & \multicolumn{1}{c|}{} & Cover (BSE) & \multicolumn{1}{c|}{$0.512$} & \multicolumn{1}{c|}{$0.326$} & \multicolumn{1}{c|}{$0.048$} & \multicolumn{1}{c|}{$0.000$} & \multicolumn{1}{c|}{$0.920$} & \multicolumn{1}{c|}{$0.924$} & \multicolumn{1}{c|}{$0.958$} & \multicolumn{1}{c|}{$0.968$} & \multicolumn{1}{c|}{$0.916$} & \multicolumn{1}{c|}{$0.916$} & \multicolumn{1}{c|}{$0.954$} & \multicolumn{1}{c|}{$0.968$} \\ \cline{2-15}
\multicolumn{1}{|c|}{} & \multicolumn{1}{c|}{\multirow{7}{*}{5}} & Bias ($\times$10) & \multicolumn{1}{c|}{$1.871$} & \multicolumn{1}{c|}{$1.786$} & \multicolumn{1}{c|}{$2.050$} & \multicolumn{1}{c|}{$1.934$} & \multicolumn{1}{c|}{$0.004$} & \multicolumn{1}{c|}{$0.110$} & \multicolumn{1}{c|}{$0.376$} & \multicolumn{1}{c|}{$0.091$} & \multicolumn{1}{c|}{$-0.222$} & \multicolumn{1}{c|}{$-0.088$} & \multicolumn{1}{c|}{$0.221$} & \multicolumn{1}{c|}{$0.161$} \\ \cline{3-15}
\multicolumn{1}{|c|}{} & \multicolumn{1}{c|}{} & ASE ($\times$10) & \multicolumn{1}{c|}{$2.354$} & \multicolumn{1}{c|}{$1.721$} & \multicolumn{1}{c|}{$1.140$} & \multicolumn{1}{c|}{$0.586$} & \multicolumn{1}{c|}{$4.611$} & \multicolumn{1}{c|}{$2.896$} & \multicolumn{1}{c|}{$1.714$} & \multicolumn{1}{c|}{$0.772$} & \multicolumn{1}{c|}{$2.958$} & \multicolumn{1}{c|}{$2.081$} & \multicolumn{1}{c|}{$1.356$} & \multicolumn{1}{c|}{$0.673$} \\ \cline{3-15}
\multicolumn{1}{|c|}{} & \multicolumn{1}{c|}{} & BSE ($\times$10) & \multicolumn{1}{c|}{$2.855$} & \multicolumn{1}{c|}{$2.035$} & \multicolumn{1}{c|}{$1.361$} & \multicolumn{1}{c|}{$0.719$} & \multicolumn{1}{c|}{$5.633$} & \multicolumn{1}{c|}{$3.440$} & \multicolumn{1}{c|}{$2.223$} & \multicolumn{1}{c|}{$1.049$} & \multicolumn{1}{c|}{$3.589$} & \multicolumn{1}{c|}{$2.523$} & \multicolumn{1}{c|}{$1.702$} & \multicolumn{1}{c|}{$0.870$} \\ \cline{3-15}
\multicolumn{1}{|c|}{} & \multicolumn{1}{c|}{} & ESE ($\times$10) & \multicolumn{1}{c|}{$2.834$} & \multicolumn{1}{c|}{$2.021$} & \multicolumn{1}{c|}{$1.258$} & \multicolumn{1}{c|}{$0.629$} & \multicolumn{1}{c|}{$4.333$} & \multicolumn{1}{c|}{$2.955$} & \multicolumn{1}{c|}{$1.657$} & \multicolumn{1}{c|}{$0.759$} & \multicolumn{1}{c|}{$3.411$} & \multicolumn{1}{c|}{$2.236$} & \multicolumn{1}{c|}{$1.464$} & \multicolumn{1}{c|}{$0.693$} \\ \cline{3-15}
\multicolumn{1}{|c|}{} & \multicolumn{1}{c|}{} & MSE ($\times$100) & \multicolumn{1}{c|}{$11.518$} & \multicolumn{1}{c|}{$7.265$} & \multicolumn{1}{c|}{$5.780$} & \multicolumn{1}{c|}{$4.137$} & \multicolumn{1}{c|}{$18.740$} & \multicolumn{1}{c|}{$8.729$} & \multicolumn{1}{c|}{$2.882$} & \multicolumn{1}{c|}{$0.583$} & \multicolumn{1}{c|}{$11.659$} & \multicolumn{1}{c|}{$4.999$} & \multicolumn{1}{c|}{$2.189$} & \multicolumn{1}{c|}{$0.505$} \\ \cline{3-15}
\multicolumn{1}{|c|}{} & \multicolumn{1}{c|}{} & Cover (ASE) & \multicolumn{1}{c|}{$0.808$} & \multicolumn{1}{c|}{$0.782$} & \multicolumn{1}{c|}{$0.550$} & \multicolumn{1}{c|}{$0.106$} & \multicolumn{1}{c|}{$0.952$} & \multicolumn{1}{c|}{$0.960$} & \multicolumn{1}{c|}{$0.956$} & \multicolumn{1}{c|}{$0.958$} & \multicolumn{1}{c|}{$0.898$} & \multicolumn{1}{c|}{$0.922$} & \multicolumn{1}{c|}{$0.930$} & \multicolumn{1}{c|}{$0.942$} \\ \cline{3-15}
\multicolumn{1}{|c|}{} & \multicolumn{1}{c|}{} & Cover (BSE) & \multicolumn{1}{c|}{$0.868$} & \multicolumn{1}{c|}{$0.850$} & \multicolumn{1}{c|}{$0.686$} & \multicolumn{1}{c|}{$0.200$} & \multicolumn{1}{c|}{$0.962$} & \multicolumn{1}{c|}{$0.964$} & \multicolumn{1}{c|}{$0.984$} & \multicolumn{1}{c|}{$0.984$} & \multicolumn{1}{c|}{$0.928$} & \multicolumn{1}{c|}{$0.956$} & \multicolumn{1}{c|}{$0.974$} & \multicolumn{1}{c|}{$0.978$} \\ \cline{2-15}
\multicolumn{1}{|c|}{} & \multicolumn{1}{c|}{\multirow{7}{*}{9}} & Bias ($\times$10) & \multicolumn{1}{c|}{$1.305$} & \multicolumn{1}{c|}{$1.524$} & \multicolumn{1}{c|}{$1.479$} & \multicolumn{1}{c|}{$1.401$} & \multicolumn{1}{c|}{$-0.206$} & \multicolumn{1}{c|}{$0.055$} & \multicolumn{1}{c|}{$-0.037$} & \multicolumn{1}{c|}{$-0.098$} & \multicolumn{1}{c|}{$-0.175$} & \multicolumn{1}{c|}{$-0.035$} & \multicolumn{1}{c|}{$-0.046$} & \multicolumn{1}{c|}{$-0.128$} \\ \cline{3-15}
\multicolumn{1}{|c|}{} & \multicolumn{1}{c|}{} & ASE ($\times$10) & \multicolumn{1}{c|}{$2.356$} & \multicolumn{1}{c|}{$1.674$} & \multicolumn{1}{c|}{$1.098$} & \multicolumn{1}{c|}{$0.568$} & \multicolumn{1}{c|}{$4.461$} & \multicolumn{1}{c|}{$3.008$} & \multicolumn{1}{c|}{$1.927$} & \multicolumn{1}{c|}{$0.930$} & \multicolumn{1}{c|}{$3.245$} & \multicolumn{1}{c|}{$2.358$} & \multicolumn{1}{c|}{$1.487$} & \multicolumn{1}{c|}{$0.747$} \\ \cline{3-15}
\multicolumn{1}{|c|}{} & \multicolumn{1}{c|}{} & BSE ($\times$10) & \multicolumn{1}{c|}{$2.999$} & \multicolumn{1}{c|}{$1.990$} & \multicolumn{1}{c|}{$1.303$} & \multicolumn{1}{c|}{$0.700$} & \multicolumn{1}{c|}{$5.549$} & \multicolumn{1}{c|}{$3.433$} & \multicolumn{1}{c|}{$2.127$} & \multicolumn{1}{c|}{$1.107$} & \multicolumn{1}{c|}{$4.049$} & \multicolumn{1}{c|}{$2.777$} & \multicolumn{1}{c|}{$1.799$} & \multicolumn{1}{c|}{$0.938$} \\ \cline{3-15}
\multicolumn{1}{|c|}{} & \multicolumn{1}{c|}{} & ESE ($\times$10) & \multicolumn{1}{c|}{$2.956$} & \multicolumn{1}{c|}{$1.934$} & \multicolumn{1}{c|}{$1.149$} & \multicolumn{1}{c|}{$0.603$} & \multicolumn{1}{c|}{$4.182$} & \multicolumn{1}{c|}{$2.434$} & \multicolumn{1}{c|}{$1.614$} & \multicolumn{1}{c|}{$0.800$} & \multicolumn{1}{c|}{$3.578$} & \multicolumn{1}{c|}{$2.261$} & \multicolumn{1}{c|}{$1.455$} & \multicolumn{1}{c|}{$0.721$} \\ \cline{3-15}
\multicolumn{1}{|c|}{} & \multicolumn{1}{c|}{} & MSE ($\times$100) & \multicolumn{1}{c|}{$10.422$} & \multicolumn{1}{c|}{$6.054$} & \multicolumn{1}{c|}{$3.507$} & \multicolumn{1}{c|}{$2.325$} & \multicolumn{1}{c|}{$17.500$} & \multicolumn{1}{c|}{$5.916$} & \multicolumn{1}{c|}{$2.600$} & \multicolumn{1}{c|}{$0.648$} & \multicolumn{1}{c|}{$12.810$} & \multicolumn{1}{c|}{$5.104$} & \multicolumn{1}{c|}{$2.116$} & \multicolumn{1}{c|}{$0.536$} \\ \cline{3-15}
\multicolumn{1}{|c|}{} & \multicolumn{1}{c|}{} & Cover (ASE) & \multicolumn{1}{c|}{$0.854$} & \multicolumn{1}{c|}{$0.788$} & \multicolumn{1}{c|}{$0.710$} & \multicolumn{1}{c|}{$0.306$} & \multicolumn{1}{c|}{$0.956$} & \multicolumn{1}{c|}{$0.962$} & \multicolumn{1}{c|}{$0.980$} & \multicolumn{1}{c|}{$0.970$} & \multicolumn{1}{c|}{$0.922$} & \multicolumn{1}{c|}{$0.940$} & \multicolumn{1}{c|}{$0.958$} & \multicolumn{1}{c|}{$0.946$} \\ \cline{3-15}
\multicolumn{1}{|c|}{} & \multicolumn{1}{c|}{} & Cover (BSE) & \multicolumn{1}{c|}{$0.916$} & \multicolumn{1}{c|}{$0.842$} & \multicolumn{1}{c|}{$0.802$} & \multicolumn{1}{c|}{$0.480$} & \multicolumn{1}{c|}{$0.978$} & \multicolumn{1}{c|}{$0.980$} & \multicolumn{1}{c|}{$0.984$} & \multicolumn{1}{c|}{$0.982$} & \multicolumn{1}{c|}{$0.950$} & \multicolumn{1}{c|}{$0.958$} & \multicolumn{1}{c|}{$0.986$} & \multicolumn{1}{c|}{$0.986$} \\ \hline \hline
\multicolumn{1}{|c|}{\multirow{21}{*}{1}} & \multicolumn{1}{c|}{\multirow{7}{*}{2}} & Bias ($\times$10) & \multicolumn{1}{c|}{$4.175$} & \multicolumn{1}{c|}{$3.921$} & \multicolumn{1}{c|}{$3.928$} & \multicolumn{1}{c|}{$3.941$} & \multicolumn{1}{c|}{$-0.212$} & \multicolumn{1}{c|}{$-0.260$} & \multicolumn{1}{c|}{$-0.123$} & \multicolumn{1}{c|}{$-0.001$} & \multicolumn{1}{c|}{$0.197$} & \multicolumn{1}{c|}{$-0.086$} & \multicolumn{1}{c|}{$-0.044$} & \multicolumn{1}{c|}{$0.028$} \\ \cline{3-15}
\multicolumn{1}{|c|}{} & \multicolumn{1}{c|}{} & ASE ($\times$10) & \multicolumn{1}{c|}{$2.329$} & \multicolumn{1}{c|}{$1.674$} & \multicolumn{1}{c|}{$1.091$} & \multicolumn{1}{c|}{$0.566$} & \multicolumn{1}{c|}{$2.820$} & \multicolumn{1}{c|}{$1.995$} & \multicolumn{1}{c|}{$1.289$} & \multicolumn{1}{c|}{$0.663$} & \multicolumn{1}{c|}{$2.754$} & \multicolumn{1}{c|}{$1.973$} & \multicolumn{1}{c|}{$1.284$} & \multicolumn{1}{c|}{$0.662$} \\ \cline{3-15}
\multicolumn{1}{|c|}{} & \multicolumn{1}{c|}{} & BSE ($\times$10) & \multicolumn{1}{c|}{$2.485$} & \multicolumn{1}{c|}{$1.845$} & \multicolumn{1}{c|}{$1.275$} & \multicolumn{1}{c|}{$0.697$} & \multicolumn{1}{c|}{$4.281$} & \multicolumn{1}{c|}{$3.087$} & \multicolumn{1}{c|}{$2.089$} & \multicolumn{1}{c|}{$1.117$} & \multicolumn{1}{c|}{$4.178$} & \multicolumn{1}{c|}{$3.118$} & \multicolumn{1}{c|}{$2.063$} & \multicolumn{1}{c|}{$1.103$} \\ \cline{3-15}
\multicolumn{1}{|c|}{} & \multicolumn{1}{c|}{} & ESE ($\times$10) & \multicolumn{1}{c|}{$2.780$} & \multicolumn{1}{c|}{$1.854$} & \multicolumn{1}{c|}{$1.223$} & \multicolumn{1}{c|}{$0.581$} & \multicolumn{1}{c|}{$3.313$} & \multicolumn{1}{c|}{$2.125$} & \multicolumn{1}{c|}{$1.453$} & \multicolumn{1}{c|}{$0.677$} & \multicolumn{1}{c|}{$3.356$} & \multicolumn{1}{c|}{$2.120$} & \multicolumn{1}{c|}{$1.450$} & \multicolumn{1}{c|}{$0.673$} \\ \cline{3-15}
\multicolumn{1}{|c|}{} & \multicolumn{1}{c|}{} & MSE ($\times$100) & \multicolumn{1}{c|}{$25.141$} & \multicolumn{1}{c|}{$18.810$} & \multicolumn{1}{c|}{$16.921$} & \multicolumn{1}{c|}{$15.870$} & \multicolumn{1}{c|}{$10.998$} & \multicolumn{1}{c|}{$4.575$} & \multicolumn{1}{c|}{$2.122$} & \multicolumn{1}{c|}{$0.457$} & \multicolumn{1}{c|}{$11.278$} & \multicolumn{1}{c|}{$4.493$} & \multicolumn{1}{c|}{$2.100$} & \multicolumn{1}{c|}{$0.453$} \\ \cline{3-15}
\multicolumn{1}{|c|}{} & \multicolumn{1}{c|}{} & Cover (ASE) & \multicolumn{1}{c|}{$0.556$} & \multicolumn{1}{c|}{$0.358$} & \multicolumn{1}{c|}{$0.094$} & \multicolumn{1}{c|}{$0.000$} & \multicolumn{1}{c|}{$0.896$} & \multicolumn{1}{c|}{$0.946$} & \multicolumn{1}{c|}{$0.922$} & \multicolumn{1}{c|}{$0.940$} & \multicolumn{1}{c|}{$0.894$} & \multicolumn{1}{c|}{$0.938$} & \multicolumn{1}{c|}{$0.920$} & \multicolumn{1}{c|}{$0.942$} \\ \cline{3-15}
\multicolumn{1}{|c|}{} & \multicolumn{1}{c|}{} & Cover (BSE) & \multicolumn{1}{c|}{$0.574$} & \multicolumn{1}{c|}{$0.440$} & \multicolumn{1}{c|}{$0.142$} & \multicolumn{1}{c|}{$0.000$} & \multicolumn{1}{c|}{$0.970$} & \multicolumn{1}{c|}{$0.988$} & \multicolumn{1}{c|}{$0.990$} & \multicolumn{1}{c|}{$0.998$} & \multicolumn{1}{c|}{$0.964$} & \multicolumn{1}{c|}{$0.984$} & \multicolumn{1}{c|}{$0.980$} & \multicolumn{1}{c|}{$0.996$} \\ \cline{2-15}
\multicolumn{1}{|c|}{} & \multicolumn{1}{c|}{\multirow{7}{*}{5}} & Bias ($\times$10) & \multicolumn{1}{c|}{$1.646$} & \multicolumn{1}{c|}{$1.686$} & \multicolumn{1}{c|}{$1.620$} & \multicolumn{1}{c|}{$1.630$} & \multicolumn{1}{c|}{$-0.160$} & \multicolumn{1}{c|}{$-0.002$} & \multicolumn{1}{c|}{$-0.012$} & \multicolumn{1}{c|}{$0.006$} & \multicolumn{1}{c|}{$0.135$} & \multicolumn{1}{c|}{$0.096$} & \multicolumn{1}{c|}{$0.040$} & \multicolumn{1}{c|}{$0.032$} \\ \cline{3-15}
\multicolumn{1}{|c|}{} & \multicolumn{1}{c|}{} & ASE ($\times$10) & \multicolumn{1}{c|}{$2.387$} & \multicolumn{1}{c|}{$1.667$} & \multicolumn{1}{c|}{$1.078$} & \multicolumn{1}{c|}{$0.551$} & \multicolumn{1}{c|}{$3.696$} & \multicolumn{1}{c|}{$2.262$} & \multicolumn{1}{c|}{$1.312$} & \multicolumn{1}{c|}{$0.628$} & \multicolumn{1}{c|}{$2.791$} & \multicolumn{1}{c|}{$1.915$} & \multicolumn{1}{c|}{$1.219$} & \multicolumn{1}{c|}{$0.608$} \\ \cline{3-15}
\multicolumn{1}{|c|}{} & \multicolumn{1}{c|}{} & BSE ($\times$10) & \multicolumn{1}{c|}{$2.854$} & \multicolumn{1}{c|}{$1.935$} & \multicolumn{1}{c|}{$1.270$} & \multicolumn{1}{c|}{$0.678$} & \multicolumn{1}{c|}{$4.907$} & \multicolumn{1}{c|}{$3.543$} & \multicolumn{1}{c|}{$2.232$} & \multicolumn{1}{c|}{$1.102$} & \multicolumn{1}{c|}{$4.768$} & \multicolumn{1}{c|}{$3.347$} & \multicolumn{1}{c|}{$2.121$} & \multicolumn{1}{c|}{$1.070$} \\ \cline{3-15}
\multicolumn{1}{|c|}{} & \multicolumn{1}{c|}{} & ESE ($\times$10) & \multicolumn{1}{c|}{$2.919$} & \multicolumn{1}{c|}{$2.010$} & \multicolumn{1}{c|}{$1.151$} & \multicolumn{1}{c|}{$0.590$} & \multicolumn{1}{c|}{$4.111$} & \multicolumn{1}{c|}{$2.335$} & \multicolumn{1}{c|}{$1.326$} & \multicolumn{1}{c|}{$0.669$} & \multicolumn{1}{c|}{$3.775$} & \multicolumn{1}{c|}{$2.221$} & \multicolumn{1}{c|}{$1.324$} & \multicolumn{1}{c|}{$0.650$} \\ \cline{3-15}
\multicolumn{1}{|c|}{} & \multicolumn{1}{c|}{} & MSE ($\times$100) & \multicolumn{1}{c|}{$11.212$} & \multicolumn{1}{c|}{$6.875$} & \multicolumn{1}{c|}{$3.947$} & \multicolumn{1}{c|}{$3.005$} & \multicolumn{1}{c|}{$16.895$} & \multicolumn{1}{c|}{$5.441$} & \multicolumn{1}{c|}{$1.754$} & \multicolumn{1}{c|}{$0.446$} & \multicolumn{1}{c|}{$14.244$} & \multicolumn{1}{c|}{$4.930$} & \multicolumn{1}{c|}{$1.752$} & \multicolumn{1}{c|}{$0.423$} \\ \cline{3-15}
\multicolumn{1}{|c|}{} & \multicolumn{1}{c|}{} & Cover (ASE) & \multicolumn{1}{c|}{$0.822$} & \multicolumn{1}{c|}{$0.778$} & \multicolumn{1}{c|}{$0.660$} & \multicolumn{1}{c|}{$0.180$} & \multicolumn{1}{c|}{$0.946$} & \multicolumn{1}{c|}{$0.946$} & \multicolumn{1}{c|}{$0.940$} & \multicolumn{1}{c|}{$0.932$} & \multicolumn{1}{c|}{$0.884$} & \multicolumn{1}{c|}{$0.914$} & \multicolumn{1}{c|}{$0.938$} & \multicolumn{1}{c|}{$0.928$} \\ \cline{3-15}
\multicolumn{1}{|c|}{} & \multicolumn{1}{c|}{} & Cover (BSE) & \multicolumn{1}{c|}{$0.872$} & \multicolumn{1}{c|}{$0.820$} & \multicolumn{1}{c|}{$0.756$} & \multicolumn{1}{c|}{$0.316$} & \multicolumn{1}{c|}{$0.956$} & \multicolumn{1}{c|}{$0.978$} & \multicolumn{1}{c|}{$0.996$} & \multicolumn{1}{c|}{$0.996$} & \multicolumn{1}{c|}{$0.964$} & \multicolumn{1}{c|}{$0.982$} & \multicolumn{1}{c|}{$0.990$} & \multicolumn{1}{c|}{$0.992$} \\ \cline{2-15}
\multicolumn{1}{|c|}{} & \multicolumn{1}{c|}{\multirow{7}{*}{9}} & Bias ($\times$10) & \multicolumn{1}{c|}{$1.358$} & \multicolumn{1}{c|}{$1.188$} & \multicolumn{1}{c|}{$1.236$} & \multicolumn{1}{c|}{$1.277$} & \multicolumn{1}{c|}{$-0.164$} & \multicolumn{1}{c|}{$-0.329$} & \multicolumn{1}{c|}{$-0.231$} & \multicolumn{1}{c|}{$-0.092$} & \multicolumn{1}{c|}{$0.058$} & \multicolumn{1}{c|}{$-0.300$} & \multicolumn{1}{c|}{$-0.348$} & \multicolumn{1}{c|}{$-0.245$} \\ \cline{3-15}
\multicolumn{1}{|c|}{} & \multicolumn{1}{c|}{} & ASE ($\times$10) & \multicolumn{1}{c|}{$2.503$} & \multicolumn{1}{c|}{$1.720$} & \multicolumn{1}{c|}{$1.096$} & \multicolumn{1}{c|}{$0.577$} & \multicolumn{1}{c|}{$3.955$} & \multicolumn{1}{c|}{$2.684$} & \multicolumn{1}{c|}{$1.572$} & \multicolumn{1}{c|}{$0.714$} & \multicolumn{1}{c|}{$3.202$} & \multicolumn{1}{c|}{$2.167$} & \multicolumn{1}{c|}{$1.320$} & \multicolumn{1}{c|}{$0.623$} \\ \cline{3-15}
\multicolumn{1}{|c|}{} & \multicolumn{1}{c|}{} & BSE ($\times$10) & \multicolumn{1}{c|}{$3.033$} & \multicolumn{1}{c|}{$2.028$} & \multicolumn{1}{c|}{$1.293$} & \multicolumn{1}{c|}{$0.713$} & \multicolumn{1}{c|}{$5.646$} & \multicolumn{1}{c|}{$3.904$} & \multicolumn{1}{c|}{$2.478$} & \multicolumn{1}{c|}{$1.309$} & \multicolumn{1}{c|}{$5.437$} & \multicolumn{1}{c|}{$3.907$} & \multicolumn{1}{c|}{$2.439$} & \multicolumn{1}{c|}{$1.254$} \\ \cline{3-15}
\multicolumn{1}{|c|}{} & \multicolumn{1}{c|}{} & ESE ($\times$10) & \multicolumn{1}{c|}{$3.137$} & \multicolumn{1}{c|}{$1.990$} & \multicolumn{1}{c|}{$1.259$} & \multicolumn{1}{c|}{$0.613$} & \multicolumn{1}{c|}{$4.005$} & \multicolumn{1}{c|}{$2.573$} & \multicolumn{1}{c|}{$1.502$} & \multicolumn{1}{c|}{$0.714$} & \multicolumn{1}{c|}{$3.747$} & \multicolumn{1}{c|}{$2.304$} & \multicolumn{1}{c|}{$1.379$} & \multicolumn{1}{c|}{$0.675$} \\ \cline{3-15}
\multicolumn{1}{|c|}{} & \multicolumn{1}{c|}{} & MSE ($\times$100) & \multicolumn{1}{c|}{$11.665$} & \multicolumn{1}{c|}{$5.363$} & \multicolumn{1}{c|}{$3.109$} & \multicolumn{1}{c|}{$2.005$} & \multicolumn{1}{c|}{$16.036$} & \multicolumn{1}{c|}{$6.713$} & \multicolumn{1}{c|}{$2.304$} & \multicolumn{1}{c|}{$0.517$} & \multicolumn{1}{c|}{$14.018$} & \multicolumn{1}{c|}{$5.386$} & \multicolumn{1}{c|}{$2.019$} & \multicolumn{1}{c|}{$0.515$} \\ \cline{3-15}
\multicolumn{1}{|c|}{} & \multicolumn{1}{c|}{} & Cover (ASE) & \multicolumn{1}{c|}{$0.842$} & \multicolumn{1}{c|}{$0.832$} & \multicolumn{1}{c|}{$0.742$} & \multicolumn{1}{c|}{$0.396$} & \multicolumn{1}{c|}{$0.954$} & \multicolumn{1}{c|}{$0.970$} & \multicolumn{1}{c|}{$0.946$} & \multicolumn{1}{c|}{$0.956$} & \multicolumn{1}{c|}{$0.930$} & \multicolumn{1}{c|}{$0.940$} & \multicolumn{1}{c|}{$0.926$} & \multicolumn{1}{c|}{$0.908$} \\ \cline{3-15}
\multicolumn{1}{|c|}{} & \multicolumn{1}{c|}{} & Cover (BSE) & \multicolumn{1}{c|}{$0.874$} & \multicolumn{1}{c|}{$0.866$} & \multicolumn{1}{c|}{$0.830$} & \multicolumn{1}{c|}{$0.564$} & \multicolumn{1}{c|}{$0.974$} & \multicolumn{1}{c|}{$0.982$} & \multicolumn{1}{c|}{$0.990$} & \multicolumn{1}{c|}{$0.996$} & \multicolumn{1}{c|}{$0.970$} & \multicolumn{1}{c|}{$0.990$} & \multicolumn{1}{c|}{$0.996$} & \multicolumn{1}{c|}{$0.988$} \\ \hline

\end{tabular}
\caption{Summary Statistics of the Estimation Results Under the Constant ATT $\tau_t^*=3$ for $t=T_0+1,\ldots,T$.} 
\label{tab:supp:Table00}
\end{table}

\newpage



Next, we consider an additional case where the ATT is linear as $\potY{t}{1} = \potY{t}{0} + \beta_0^* \ind (T_0< t) + \beta_1^* \ind (t-T_0)_+/T_0 + \epsilon_{\tau,t} $ where $\beta_0^*=3$ and $\beta_1^*=3$, and $(a)_{+} = \max(a,0)$. As in the main paper, we first present plots for the empirical distributions of the estimators. The plots have the same format as Figure \ref{fig:Sim:Constant} of the main paper, i.e.,
\begin{itemize}[itemsep=0cm,leftmargin=0.4cm]
\item The left, center, and right columns are associated with the number of donors $(d=2,5,9)$;
\item The top and bottom plots are associated with whether covariates are excluded $(\delta=0)$ or not $(\delta=1)$;
\item The vertical solid segments represent the range of the central 95\% of 500 estimates obtained by each estimation method;
\item The dots represent the empirical mean of 500 estimates obtained by each estimation method;
\item The light gray, gray, and black colors show the estimator types and the shape of the dots show the length of the pre-treatment period, respectively;
\item The red horizontal line shows the zero bias.
\end{itemize}
Figures \ref{fig:Sim:Linear1} and \ref{fig:Sim:Linear2} visually summarize the result. We remark that the OLS estimator is biased, especially for the intercept $\beta_0^*=3$.

% Figure environment removed	



\newpage

Next, we present the numerical summaries in Table \ref{tab:supp:Table0} and Table \ref{tab:supp:Table1}. We find that the SPSC estimator with ridge regularization performs the best, agreeing with the findings in the main paper.
\begin{table}[!htp]
\renewcommand{\arraystretch}{1.05} \centering
\footnotesize
\setlength{\tabcolsep}{3pt} 
\hspace*{-0.25in}
\begin{tabular}{|ccc|cccc|cccc|cccc|}
\hline
\multicolumn{3}{|c|}{Estimator} & \multicolumn{4}{c|}{OLS} & \multicolumn{4}{c|}{SPSC} & \multicolumn{4}{c|}{SPSC-Ridge} \\ \hline
\multicolumn{1}{|c|}{$\ \delta \ $} & \multicolumn{1}{c|}{$\ d \ $} & $T_0$ & \multicolumn{1}{c|}{50} & \multicolumn{1}{c|}{100} & \multicolumn{1}{c|}{250} & 1000 & \multicolumn{1}{c|}{50} & \multicolumn{1}{c|}{100} & \multicolumn{1}{c|}{250} & 1000 & \multicolumn{1}{c|}{50} & \multicolumn{1}{c|}{100} & \multicolumn{1}{c|}{250} & 1000 \\ \hline

\multicolumn{1}{|c|}{\multirow{21}{*}{0}} & \multicolumn{1}{c|}{\multirow{7}{*}{2}} & Bias ($\times$10) & \multicolumn{1}{c|}{$4.230$} & \multicolumn{1}{c|}{$3.675$} & \multicolumn{1}{c|}{$3.992$} & \multicolumn{1}{c|}{$3.955$} & \multicolumn{1}{c|}{$0.065$} & \multicolumn{1}{c|}{$-0.416$} & \multicolumn{1}{c|}{$-0.008$} & \multicolumn{1}{c|}{$0.006$} & \multicolumn{1}{c|}{$0.405$} & \multicolumn{1}{c|}{$-0.231$} & \multicolumn{1}{c|}{$0.067$} & \multicolumn{1}{c|}{$0.036$} \\ \cline{3-15}
\multicolumn{1}{|c|}{} & \multicolumn{1}{c|}{} & ASE ($\times$10) & \multicolumn{1}{c|}{$3.733$} & \multicolumn{1}{c|}{$2.809$} & \multicolumn{1}{c|}{$1.888$} & \multicolumn{1}{c|}{$1.008$} & \multicolumn{1}{c|}{$4.289$} & \multicolumn{1}{c|}{$3.176$} & \multicolumn{1}{c|}{$2.120$} & \multicolumn{1}{c|}{$1.123$} & \multicolumn{1}{c|}{$4.221$} & \multicolumn{1}{c|}{$3.153$} & \multicolumn{1}{c|}{$2.114$} & \multicolumn{1}{c|}{$1.122$} \\ \cline{3-15}
\multicolumn{1}{|c|}{} & \multicolumn{1}{c|}{} & BSE ($\times$10) & \multicolumn{1}{c|}{$6.131$} & \multicolumn{1}{c|}{$5.021$} & \multicolumn{1}{c|}{$3.677$} & \multicolumn{1}{c|}{$2.373$} & \multicolumn{1}{c|}{$6.537$} & \multicolumn{1}{c|}{$5.148$} & \multicolumn{1}{c|}{$3.751$} & \multicolumn{1}{c|}{$2.330$} & \multicolumn{1}{c|}{$6.423$} & \multicolumn{1}{c|}{$5.013$} & \multicolumn{1}{c|}{$3.735$} & \multicolumn{1}{c|}{$2.342$} \\ \cline{3-15}
\multicolumn{1}{|c|}{} & \multicolumn{1}{c|}{} & ESE ($\times$10) & \multicolumn{1}{c|}{$4.475$} & \multicolumn{1}{c|}{$3.443$} & \multicolumn{1}{c|}{$2.059$} & \multicolumn{1}{c|}{$1.115$} & \multicolumn{1}{c|}{$4.841$} & \multicolumn{1}{c|}{$3.892$} & \multicolumn{1}{c|}{$2.348$} & \multicolumn{1}{c|}{$1.237$} & \multicolumn{1}{c|}{$4.788$} & \multicolumn{1}{c|}{$3.853$} & \multicolumn{1}{c|}{$2.339$} & \multicolumn{1}{c|}{$1.236$} \\ \cline{3-15}
\multicolumn{1}{|c|}{} & \multicolumn{1}{c|}{} & MSE ($\times$100) & \multicolumn{1}{c|}{$37.875$} & \multicolumn{1}{c|}{$25.339$} & \multicolumn{1}{c|}{$20.167$} & \multicolumn{1}{c|}{$16.880$} & \multicolumn{1}{c|}{$23.389$} & \multicolumn{1}{c|}{$15.293$} & \multicolumn{1}{c|}{$5.504$} & \multicolumn{1}{c|}{$1.527$} & \multicolumn{1}{c|}{$23.045$} & \multicolumn{1}{c|}{$14.871$} & \multicolumn{1}{c|}{$5.466$} & \multicolumn{1}{c|}{$1.527$} \\ \cline{3-15}
\multicolumn{1}{|c|}{} & \multicolumn{1}{c|}{} & Cover (ASE) & \multicolumn{1}{c|}{$0.738$} & \multicolumn{1}{c|}{$0.678$} & \multicolumn{1}{c|}{$0.436$} & \multicolumn{1}{c|}{$0.040$} & \multicolumn{1}{c|}{$0.916$} & \multicolumn{1}{c|}{$0.874$} & \multicolumn{1}{c|}{$0.912$} & \multicolumn{1}{c|}{$0.934$} & \multicolumn{1}{c|}{$0.906$} & \multicolumn{1}{c|}{$0.876$} & \multicolumn{1}{c|}{$0.906$} & \multicolumn{1}{c|}{$0.932$} \\ \cline{3-15}
\multicolumn{1}{|c|}{} & \multicolumn{1}{c|}{} & Cover (BSE) & \multicolumn{1}{c|}{$0.872$} & \multicolumn{1}{c|}{$0.874$} & \multicolumn{1}{c|}{$0.860$} & \multicolumn{1}{c|}{$0.668$} & \multicolumn{1}{c|}{$0.972$} & \multicolumn{1}{c|}{$0.976$} & \multicolumn{1}{c|}{$0.978$} & \multicolumn{1}{c|}{$0.994$} & \multicolumn{1}{c|}{$0.970$} & \multicolumn{1}{c|}{$0.972$} & \multicolumn{1}{c|}{$0.988$} & \multicolumn{1}{c|}{$0.994$} \\ \cline{2-15}
\multicolumn{1}{|c|}{} & \multicolumn{1}{c|}{\multirow{7}{*}{5}} & Bias ($\times$10) & \multicolumn{1}{c|}{$2.059$} & \multicolumn{1}{c|}{$1.842$} & \multicolumn{1}{c|}{$1.829$} & \multicolumn{1}{c|}{$1.776$} & \multicolumn{1}{c|}{$0.180$} & \multicolumn{1}{c|}{$0.034$} & \multicolumn{1}{c|}{$0.029$} & \multicolumn{1}{c|}{$-0.096$} & \multicolumn{1}{c|}{$0.441$} & \multicolumn{1}{c|}{$0.221$} & \multicolumn{1}{c|}{$0.120$} & \multicolumn{1}{c|}{$-0.053$} \\ \cline{3-15}
\multicolumn{1}{|c|}{} & \multicolumn{1}{c|}{} & ASE ($\times$10) & \multicolumn{1}{c|}{$3.619$} & \multicolumn{1}{c|}{$2.715$} & \multicolumn{1}{c|}{$1.811$} & \multicolumn{1}{c|}{$0.959$} & \multicolumn{1}{c|}{$6.162$} & \multicolumn{1}{c|}{$3.751$} & \multicolumn{1}{c|}{$2.243$} & \multicolumn{1}{c|}{$1.076$} & \multicolumn{1}{c|}{$4.177$} & \multicolumn{1}{c|}{$3.034$} & \multicolumn{1}{c|}{$1.968$} & \multicolumn{1}{c|}{$1.028$} \\ \cline{3-15}
\multicolumn{1}{|c|}{} & \multicolumn{1}{c|}{} & BSE ($\times$10) & \multicolumn{1}{c|}{$6.060$} & \multicolumn{1}{c|}{$4.690$} & \multicolumn{1}{c|}{$3.525$} & \multicolumn{1}{c|}{$2.238$} & \multicolumn{1}{c|}{$8.167$} & \multicolumn{1}{c|}{$5.751$} & \multicolumn{1}{c|}{$4.007$} & \multicolumn{1}{c|}{$2.382$} & \multicolumn{1}{c|}{$6.474$} & \multicolumn{1}{c|}{$5.047$} & \multicolumn{1}{c|}{$3.734$} & \multicolumn{1}{c|}{$2.328$} \\ \cline{3-15}
\multicolumn{1}{|c|}{} & \multicolumn{1}{c|}{} & ESE ($\times$10) & \multicolumn{1}{c|}{$4.621$} & \multicolumn{1}{c|}{$3.419$} & \multicolumn{1}{c|}{$2.052$} & \multicolumn{1}{c|}{$0.982$} & \multicolumn{1}{c|}{$5.795$} & \multicolumn{1}{c|}{$4.074$} & \multicolumn{1}{c|}{$2.292$} & \multicolumn{1}{c|}{$1.086$} & \multicolumn{1}{c|}{$4.931$} & \multicolumn{1}{c|}{$3.628$} & \multicolumn{1}{c|}{$2.147$} & \multicolumn{1}{c|}{$1.049$} \\ \cline{3-15}
\multicolumn{1}{|c|}{} & \multicolumn{1}{c|}{} & MSE ($\times$100) & \multicolumn{1}{c|}{$25.555$} & \multicolumn{1}{c|}{$15.060$} & \multicolumn{1}{c|}{$7.544$} & \multicolumn{1}{c|}{$4.116$} & \multicolumn{1}{c|}{$33.549$} & \multicolumn{1}{c|}{$16.563$} & \multicolumn{1}{c|}{$5.246$} & \multicolumn{1}{c|}{$1.186$} & \multicolumn{1}{c|}{$24.456$} & \multicolumn{1}{c|}{$13.184$} & \multicolumn{1}{c|}{$4.614$} & \multicolumn{1}{c|}{$1.100$} \\ \cline{3-15}
\multicolumn{1}{|c|}{} & \multicolumn{1}{c|}{} & Cover (ASE) & \multicolumn{1}{c|}{$0.814$} & \multicolumn{1}{c|}{$0.818$} & \multicolumn{1}{c|}{$0.788$} & \multicolumn{1}{c|}{$0.534$} & \multicolumn{1}{c|}{$0.924$} & \multicolumn{1}{c|}{$0.916$} & \multicolumn{1}{c|}{$0.942$} & \multicolumn{1}{c|}{$0.950$} & \multicolumn{1}{c|}{$0.866$} & \multicolumn{1}{c|}{$0.874$} & \multicolumn{1}{c|}{$0.928$} & \multicolumn{1}{c|}{$0.944$} \\ \cline{3-15}
\multicolumn{1}{|c|}{} & \multicolumn{1}{c|}{} & Cover (BSE) & \multicolumn{1}{c|}{$0.914$} & \multicolumn{1}{c|}{$0.928$} & \multicolumn{1}{c|}{$0.966$} & \multicolumn{1}{c|}{$0.970$} & \multicolumn{1}{c|}{$0.966$} & \multicolumn{1}{c|}{$0.980$} & \multicolumn{1}{c|}{$0.992$} & \multicolumn{1}{c|}{$1.000$} & \multicolumn{1}{c|}{$0.944$} & \multicolumn{1}{c|}{$0.982$} & \multicolumn{1}{c|}{$0.990$} & \multicolumn{1}{c|}{$1.000$} \\ \cline{2-15}
\multicolumn{1}{|c|}{} & \multicolumn{1}{c|}{\multirow{7}{*}{9}} & Bias ($\times$10) & \multicolumn{1}{c|}{$1.878$} & \multicolumn{1}{c|}{$1.713$} & \multicolumn{1}{c|}{$1.955$} & \multicolumn{1}{c|}{$1.940$} & \multicolumn{1}{c|}{$0.265$} & \multicolumn{1}{c|}{$0.043$} & \multicolumn{1}{c|}{$0.184$} & \multicolumn{1}{c|}{$0.120$} & \multicolumn{1}{c|}{$0.451$} & \multicolumn{1}{c|}{$0.139$} & \multicolumn{1}{c|}{$0.185$} & \multicolumn{1}{c|}{$0.130$} \\ \cline{3-15}
\multicolumn{1}{|c|}{} & \multicolumn{1}{c|}{} & ASE ($\times$10) & \multicolumn{1}{c|}{$3.701$} & \multicolumn{1}{c|}{$2.726$} & \multicolumn{1}{c|}{$1.807$} & \multicolumn{1}{c|}{$0.956$} & \multicolumn{1}{c|}{$5.473$} & \multicolumn{1}{c|}{$3.932$} & \multicolumn{1}{c|}{$2.505$} & \multicolumn{1}{c|}{$1.228$} & \multicolumn{1}{c|}{$4.394$} & \multicolumn{1}{c|}{$3.288$} & \multicolumn{1}{c|}{$2.122$} & \multicolumn{1}{c|}{$1.104$} \\ \cline{3-15}
\multicolumn{1}{|c|}{} & \multicolumn{1}{c|}{} & BSE ($\times$10) & \multicolumn{1}{c|}{$6.016$} & \multicolumn{1}{c|}{$4.761$} & \multicolumn{1}{c|}{$3.427$} & \multicolumn{1}{c|}{$2.223$} & \multicolumn{1}{c|}{$8.047$} & \multicolumn{1}{c|}{$5.700$} & \multicolumn{1}{c|}{$3.941$} & \multicolumn{1}{c|}{$2.407$} & \multicolumn{1}{c|}{$6.974$} & \multicolumn{1}{c|}{$5.252$} & \multicolumn{1}{c|}{$3.805$} & \multicolumn{1}{c|}{$2.299$} \\ \cline{3-15}
\multicolumn{1}{|c|}{} & \multicolumn{1}{c|}{} & ESE ($\times$10) & \multicolumn{1}{c|}{$4.094$} & \multicolumn{1}{c|}{$3.362$} & \multicolumn{1}{c|}{$1.972$} & \multicolumn{1}{c|}{$1.017$} & \multicolumn{1}{c|}{$4.964$} & \multicolumn{1}{c|}{$3.878$} & \multicolumn{1}{c|}{$2.328$} & \multicolumn{1}{c|}{$1.158$} & \multicolumn{1}{c|}{$4.548$} & \multicolumn{1}{c|}{$3.588$} & \multicolumn{1}{c|}{$2.187$} & \multicolumn{1}{c|}{$1.108$} \\ \cline{3-15}
\multicolumn{1}{|c|}{} & \multicolumn{1}{c|}{} & MSE ($\times$100) & \multicolumn{1}{c|}{$20.250$} & \multicolumn{1}{c|}{$14.215$} & \multicolumn{1}{c|}{$7.705$} & \multicolumn{1}{c|}{$4.795$} & \multicolumn{1}{c|}{$24.663$} & \multicolumn{1}{c|}{$15.007$} & \multicolumn{1}{c|}{$5.445$} & \multicolumn{1}{c|}{$1.353$} & \multicolumn{1}{c|}{$20.849$} & \multicolumn{1}{c|}{$12.869$} & \multicolumn{1}{c|}{$4.807$} & \multicolumn{1}{c|}{$1.243$} \\ \cline{3-15}
\multicolumn{1}{|c|}{} & \multicolumn{1}{c|}{} & Cover (ASE) & \multicolumn{1}{c|}{$0.882$} & \multicolumn{1}{c|}{$0.822$} & \multicolumn{1}{c|}{$0.770$} & \multicolumn{1}{c|}{$0.450$} & \multicolumn{1}{c|}{$0.948$} & \multicolumn{1}{c|}{$0.946$} & \multicolumn{1}{c|}{$0.946$} & \multicolumn{1}{c|}{$0.968$} & \multicolumn{1}{c|}{$0.920$} & \multicolumn{1}{c|}{$0.912$} & \multicolumn{1}{c|}{$0.940$} & \multicolumn{1}{c|}{$0.946$} \\ \cline{3-15}
\multicolumn{1}{|c|}{} & \multicolumn{1}{c|}{} & Cover (BSE) & \multicolumn{1}{c|}{$0.948$} & \multicolumn{1}{c|}{$0.934$} & \multicolumn{1}{c|}{$0.942$} & \multicolumn{1}{c|}{$0.968$} & \multicolumn{1}{c|}{$0.980$} & \multicolumn{1}{c|}{$0.974$} & \multicolumn{1}{c|}{$0.988$} & \multicolumn{1}{c|}{$0.998$} & \multicolumn{1}{c|}{$0.972$} & \multicolumn{1}{c|}{$0.972$} & \multicolumn{1}{c|}{$0.988$} & \multicolumn{1}{c|}{$1.000$} \\ \hline \hline
\multicolumn{1}{|c|}{\multirow{21}{*}{1}} & \multicolumn{1}{c|}{\multirow{7}{*}{2}} & Bias ($\times$10) & \multicolumn{1}{c|}{$3.722$} & \multicolumn{1}{c|}{$3.518$} & \multicolumn{1}{c|}{$3.430$} & \multicolumn{1}{c|}{$3.455$} & \multicolumn{1}{c|}{$-0.037$} & \multicolumn{1}{c|}{$-0.130$} & \multicolumn{1}{c|}{$-0.128$} & \multicolumn{1}{c|}{$-0.024$} & \multicolumn{1}{c|}{$0.291$} & \multicolumn{1}{c|}{$-0.009$} & \multicolumn{1}{c|}{$-0.073$} & \multicolumn{1}{c|}{$-0.004$} \\ \cline{3-15}
\multicolumn{1}{|c|}{} & \multicolumn{1}{c|}{} & ASE ($\times$10) & \multicolumn{1}{c|}{$3.904$} & \multicolumn{1}{c|}{$2.889$} & \multicolumn{1}{c|}{$1.936$} & \multicolumn{1}{c|}{$1.010$} & \multicolumn{1}{c|}{$4.460$} & \multicolumn{1}{c|}{$3.259$} & \multicolumn{1}{c|}{$2.157$} & \multicolumn{1}{c|}{$1.124$} & \multicolumn{1}{c|}{$4.396$} & \multicolumn{1}{c|}{$3.241$} & \multicolumn{1}{c|}{$2.152$} & \multicolumn{1}{c|}{$1.123$} \\ \cline{3-15}
\multicolumn{1}{|c|}{} & \multicolumn{1}{c|}{} & BSE ($\times$10) & \multicolumn{1}{c|}{$6.223$} & \multicolumn{1}{c|}{$4.843$} & \multicolumn{1}{c|}{$3.717$} & \multicolumn{1}{c|}{$2.356$} & \multicolumn{1}{c|}{$7.106$} & \multicolumn{1}{c|}{$5.507$} & \multicolumn{1}{c|}{$4.038$} & \multicolumn{1}{c|}{$2.418$} & \multicolumn{1}{c|}{$7.298$} & \multicolumn{1}{c|}{$5.545$} & \multicolumn{1}{c|}{$4.099$} & \multicolumn{1}{c|}{$2.451$} \\ \cline{3-15}
\multicolumn{1}{|c|}{} & \multicolumn{1}{c|}{} & ESE ($\times$10) & \multicolumn{1}{c|}{$4.501$} & \multicolumn{1}{c|}{$3.445$} & \multicolumn{1}{c|}{$2.166$} & \multicolumn{1}{c|}{$1.060$} & \multicolumn{1}{c|}{$5.086$} & \multicolumn{1}{c|}{$3.713$} & \multicolumn{1}{c|}{$2.454$} & \multicolumn{1}{c|}{$1.172$} & \multicolumn{1}{c|}{$5.068$} & \multicolumn{1}{c|}{$3.703$} & \multicolumn{1}{c|}{$2.448$} & \multicolumn{1}{c|}{$1.170$} \\ \cline{3-15}
\multicolumn{1}{|c|}{} & \multicolumn{1}{c|}{} & MSE ($\times$100) & \multicolumn{1}{c|}{$34.072$} & \multicolumn{1}{c|}{$24.224$} & \multicolumn{1}{c|}{$16.447$} & \multicolumn{1}{c|}{$13.061$} & \multicolumn{1}{c|}{$25.821$} & \multicolumn{1}{c|}{$13.778$} & \multicolumn{1}{c|}{$6.028$} & \multicolumn{1}{c|}{$1.371$} & \multicolumn{1}{c|}{$25.719$} & \multicolumn{1}{c|}{$13.687$} & \multicolumn{1}{c|}{$5.988$} & \multicolumn{1}{c|}{$1.366$} \\ \cline{3-15}
\multicolumn{1}{|c|}{} & \multicolumn{1}{c|}{} & Cover (ASE) & \multicolumn{1}{c|}{$0.790$} & \multicolumn{1}{c|}{$0.744$} & \multicolumn{1}{c|}{$0.564$} & \multicolumn{1}{c|}{$0.090$} & \multicolumn{1}{c|}{$0.900$} & \multicolumn{1}{c|}{$0.894$} & \multicolumn{1}{c|}{$0.916$} & \multicolumn{1}{c|}{$0.930$} & \multicolumn{1}{c|}{$0.896$} & \multicolumn{1}{c|}{$0.898$} & \multicolumn{1}{c|}{$0.914$} & \multicolumn{1}{c|}{$0.930$} \\ \cline{3-15}
\multicolumn{1}{|c|}{} & \multicolumn{1}{c|}{} & Cover (BSE) & \multicolumn{1}{c|}{$0.886$} & \multicolumn{1}{c|}{$0.880$} & \multicolumn{1}{c|}{$0.900$} & \multicolumn{1}{c|}{$0.756$} & \multicolumn{1}{c|}{$0.970$} & \multicolumn{1}{c|}{$0.982$} & \multicolumn{1}{c|}{$0.992$} & \multicolumn{1}{c|}{$1.000$} & \multicolumn{1}{c|}{$0.978$} & \multicolumn{1}{c|}{$0.978$} & \multicolumn{1}{c|}{$0.992$} & \multicolumn{1}{c|}{$1.000$} \\ \cline{2-15}
\multicolumn{1}{|c|}{} & \multicolumn{1}{c|}{\multirow{7}{*}{5}} & Bias ($\times$10) & \multicolumn{1}{c|}{$1.527$} & \multicolumn{1}{c|}{$1.462$} & \multicolumn{1}{c|}{$1.444$} & \multicolumn{1}{c|}{$1.469$} & \multicolumn{1}{c|}{$-0.140$} & \multicolumn{1}{c|}{$0.038$} & \multicolumn{1}{c|}{$-0.091$} & \multicolumn{1}{c|}{$-0.084$} & \multicolumn{1}{c|}{$0.297$} & \multicolumn{1}{c|}{$0.202$} & \multicolumn{1}{c|}{$0.052$} & \multicolumn{1}{c|}{$-0.031$} \\ \cline{3-15}
\multicolumn{1}{|c|}{} & \multicolumn{1}{c|}{} & ASE ($\times$10) & \multicolumn{1}{c|}{$3.913$} & \multicolumn{1}{c|}{$2.827$} & \multicolumn{1}{c|}{$1.876$} & \multicolumn{1}{c|}{$0.973$} & \multicolumn{1}{c|}{$5.415$} & \multicolumn{1}{c|}{$3.490$} & \multicolumn{1}{c|}{$2.115$} & \multicolumn{1}{c|}{$1.049$} & \multicolumn{1}{c|}{$4.338$} & \multicolumn{1}{c|}{$3.082$} & \multicolumn{1}{c|}{$2.004$} & \multicolumn{1}{c|}{$1.029$} \\ \cline{3-15}
\multicolumn{1}{|c|}{} & \multicolumn{1}{c|}{} & BSE ($\times$10) & \multicolumn{1}{c|}{$6.405$} & \multicolumn{1}{c|}{$4.794$} & \multicolumn{1}{c|}{$3.589$} & \multicolumn{1}{c|}{$2.273$} & \multicolumn{1}{c|}{$7.771$} & \multicolumn{1}{c|}{$5.668$} & \multicolumn{1}{c|}{$4.029$} & \multicolumn{1}{c|}{$2.363$} & \multicolumn{1}{c|}{$7.649$} & \multicolumn{1}{c|}{$5.481$} & \multicolumn{1}{c|}{$3.949$} & \multicolumn{1}{c|}{$2.389$} \\ \cline{3-15}
\multicolumn{1}{|c|}{} & \multicolumn{1}{c|}{} & ESE ($\times$10) & \multicolumn{1}{c|}{$4.941$} & \multicolumn{1}{c|}{$3.387$} & \multicolumn{1}{c|}{$2.002$} & \multicolumn{1}{c|}{$0.984$} & \multicolumn{1}{c|}{$5.933$} & \multicolumn{1}{c|}{$3.883$} & \multicolumn{1}{c|}{$2.215$} & \multicolumn{1}{c|}{$1.055$} & \multicolumn{1}{c|}{$5.303$} & \multicolumn{1}{c|}{$3.627$} & \multicolumn{1}{c|}{$2.163$} & \multicolumn{1}{c|}{$1.045$} \\ \cline{3-15}
\multicolumn{1}{|c|}{} & \multicolumn{1}{c|}{} & MSE ($\times$100) & \multicolumn{1}{c|}{$26.693$} & \multicolumn{1}{c|}{$13.584$} & \multicolumn{1}{c|}{$6.084$} & \multicolumn{1}{c|}{$3.124$} & \multicolumn{1}{c|}{$35.154$} & \multicolumn{1}{c|}{$15.049$} & \multicolumn{1}{c|}{$4.905$} & \multicolumn{1}{c|}{$1.117$} & \multicolumn{1}{c|}{$28.150$} & \multicolumn{1}{c|}{$13.168$} & \multicolumn{1}{c|}{$4.674$} & \multicolumn{1}{c|}{$1.090$} \\ \cline{3-15}
\multicolumn{1}{|c|}{} & \multicolumn{1}{c|}{} & Cover (ASE) & \multicolumn{1}{c|}{$0.850$} & \multicolumn{1}{c|}{$0.850$} & \multicolumn{1}{c|}{$0.852$} & \multicolumn{1}{c|}{$0.652$} & \multicolumn{1}{c|}{$0.920$} & \multicolumn{1}{c|}{$0.902$} & \multicolumn{1}{c|}{$0.936$} & \multicolumn{1}{c|}{$0.958$} & \multicolumn{1}{c|}{$0.876$} & \multicolumn{1}{c|}{$0.888$} & \multicolumn{1}{c|}{$0.930$} & \multicolumn{1}{c|}{$0.952$} \\ \cline{3-15}
\multicolumn{1}{|c|}{} & \multicolumn{1}{c|}{} & Cover (BSE) & \multicolumn{1}{c|}{$0.930$} & \multicolumn{1}{c|}{$0.946$} & \multicolumn{1}{c|}{$0.980$} & \multicolumn{1}{c|}{$0.992$} & \multicolumn{1}{c|}{$0.964$} & \multicolumn{1}{c|}{$0.984$} & \multicolumn{1}{c|}{$0.998$} & \multicolumn{1}{c|}{$0.998$} & \multicolumn{1}{c|}{$0.958$} & \multicolumn{1}{c|}{$0.986$} & \multicolumn{1}{c|}{$0.996$} & \multicolumn{1}{c|}{$1.000$} \\ \cline{2-15}
\multicolumn{1}{|c|}{} & \multicolumn{1}{c|}{\multirow{7}{*}{9}} & Bias ($\times$10) & \multicolumn{1}{c|}{$1.761$} & \multicolumn{1}{c|}{$1.705$} & \multicolumn{1}{c|}{$1.682$} & \multicolumn{1}{c|}{$1.605$} & \multicolumn{1}{c|}{$0.389$} & \multicolumn{1}{c|}{$0.120$} & \multicolumn{1}{c|}{$0.103$} & \multicolumn{1}{c|}{$-0.011$} & \multicolumn{1}{c|}{$0.625$} & \multicolumn{1}{c|}{$0.178$} & \multicolumn{1}{c|}{$0.129$} & \multicolumn{1}{c|}{$-0.017$} \\ \cline{3-15}
\multicolumn{1}{|c|}{} & \multicolumn{1}{c|}{} & ASE ($\times$10) & \multicolumn{1}{c|}{$4.131$} & \multicolumn{1}{c|}{$2.922$} & \multicolumn{1}{c|}{$1.908$} & \multicolumn{1}{c|}{$0.980$} & \multicolumn{1}{c|}{$5.894$} & \multicolumn{1}{c|}{$3.946$} & \multicolumn{1}{c|}{$2.362$} & \multicolumn{1}{c|}{$1.135$} & \multicolumn{1}{c|}{$4.914$} & \multicolumn{1}{c|}{$3.416$} & \multicolumn{1}{c|}{$2.110$} & \multicolumn{1}{c|}{$1.039$} \\ \cline{3-15}
\multicolumn{1}{|c|}{} & \multicolumn{1}{c|}{} & BSE ($\times$10) & \multicolumn{1}{c|}{$6.291$} & \multicolumn{1}{c|}{$4.825$} & \multicolumn{1}{c|}{$3.508$} & \multicolumn{1}{c|}{$2.245$} & \multicolumn{1}{c|}{$8.468$} & \multicolumn{1}{c|}{$6.127$} & \multicolumn{1}{c|}{$4.043$} & \multicolumn{1}{c|}{$2.477$} & \multicolumn{1}{c|}{$8.370$} & \multicolumn{1}{c|}{$6.053$} & \multicolumn{1}{c|}{$4.128$} & \multicolumn{1}{c|}{$2.467$} \\ \cline{3-15}
\multicolumn{1}{|c|}{} & \multicolumn{1}{c|}{} & ESE ($\times$10) & \multicolumn{1}{c|}{$4.764$} & \multicolumn{1}{c|}{$3.277$} & \multicolumn{1}{c|}{$2.084$} & \multicolumn{1}{c|}{$1.001$} & \multicolumn{1}{c|}{$5.822$} & \multicolumn{1}{c|}{$3.782$} & \multicolumn{1}{c|}{$2.252$} & \multicolumn{1}{c|}{$1.072$} & \multicolumn{1}{c|}{$5.183$} & \multicolumn{1}{c|}{$3.507$} & \multicolumn{1}{c|}{$2.216$} & \multicolumn{1}{c|}{$1.033$} \\ \cline{3-15}
\multicolumn{1}{|c|}{} & \multicolumn{1}{c|}{} & MSE ($\times$100) & \multicolumn{1}{c|}{$25.753$} & \multicolumn{1}{c|}{$13.625$} & \multicolumn{1}{c|}{$7.163$} & \multicolumn{1}{c|}{$3.578$} & \multicolumn{1}{c|}{$33.981$} & \multicolumn{1}{c|}{$14.289$} & \multicolumn{1}{c|}{$5.074$} & \multicolumn{1}{c|}{$1.146$} & \multicolumn{1}{c|}{$27.198$} & \multicolumn{1}{c|}{$12.308$} & \multicolumn{1}{c|}{$4.919$} & \multicolumn{1}{c|}{$1.066$} \\ \cline{3-15}
\multicolumn{1}{|c|}{} & \multicolumn{1}{c|}{} & Cover (ASE) & \multicolumn{1}{c|}{$0.878$} & \multicolumn{1}{c|}{$0.860$} & \multicolumn{1}{c|}{$0.836$} & \multicolumn{1}{c|}{$0.624$} & \multicolumn{1}{c|}{$0.942$} & \multicolumn{1}{c|}{$0.954$} & \multicolumn{1}{c|}{$0.942$} & \multicolumn{1}{c|}{$0.954$} & \multicolumn{1}{c|}{$0.920$} & \multicolumn{1}{c|}{$0.932$} & \multicolumn{1}{c|}{$0.914$} & \multicolumn{1}{c|}{$0.940$} \\ \cline{3-15}
\multicolumn{1}{|c|}{} & \multicolumn{1}{c|}{} & Cover (BSE) & \multicolumn{1}{c|}{$0.934$} & \multicolumn{1}{c|}{$0.964$} & \multicolumn{1}{c|}{$0.964$} & \multicolumn{1}{c|}{$0.986$} & \multicolumn{1}{c|}{$0.968$} & \multicolumn{1}{c|}{$0.990$} & \multicolumn{1}{c|}{$0.990$} & \multicolumn{1}{c|}{$0.998$} & \multicolumn{1}{c|}{$0.966$} & \multicolumn{1}{c|}{$0.992$} & \multicolumn{1}{c|}{$0.996$} & \multicolumn{1}{c|}{$1.000$} \\ \hline

\end{tabular}
\caption{Summary Statistics of the Estimation Results for $\beta_{0}^*=3$.} 
\label{tab:supp:Table0}
\end{table}


\newpage


\begin{table}[!htp]
\renewcommand{\arraystretch}{1.05} \centering
\footnotesize
\setlength{\tabcolsep}{3pt} 
\hspace*{-0.25in}
\begin{tabular}{|ccc|cccc|cccc|cccc|}
\hline
\multicolumn{3}{|c|}{Estimator} & \multicolumn{4}{c|}{OLS} & \multicolumn{4}{c|}{SPSC} & \multicolumn{4}{c|}{SPSC-Ridge} \\ \hline
\multicolumn{1}{|c|}{$\ \delta \ $} & \multicolumn{1}{c|}{$\ d \ $} & $T_0$ & \multicolumn{1}{c|}{50} & \multicolumn{1}{c|}{100} & \multicolumn{1}{c|}{250} & 1000 & \multicolumn{1}{c|}{50} & \multicolumn{1}{c|}{100} & \multicolumn{1}{c|}{250} & 1000 & \multicolumn{1}{c|}{50} & \multicolumn{1}{c|}{100} & \multicolumn{1}{c|}{250} & 1000 \\ \hline

\multicolumn{1}{|c|}{\multirow{21}{*}{0}} & \multicolumn{1}{c|}{\multirow{7}{*}{2}} & Bias ($\times$10) & \multicolumn{1}{c|}{$1.593$} & \multicolumn{1}{c|}{$2.404$} & \multicolumn{1}{c|}{$1.988$} & \multicolumn{1}{c|}{$1.990$} & \multicolumn{1}{c|}{$-0.527$} & \multicolumn{1}{c|}{$0.435$} & \multicolumn{1}{c|}{$-0.078$} & \multicolumn{1}{c|}{$-0.019$} & \multicolumn{1}{c|}{$-0.158$} & \multicolumn{1}{c|}{$0.648$} & \multicolumn{1}{c|}{$0.018$} & \multicolumn{1}{c|}{$0.023$} \\ \cline{3-15}
\multicolumn{1}{|c|}{} & \multicolumn{1}{c|}{} & ASE ($\times$10) & \multicolumn{1}{c|}{$6.261$} & \multicolumn{1}{c|}{$4.786$} & \multicolumn{1}{c|}{$3.213$} & \multicolumn{1}{c|}{$1.722$} & \multicolumn{1}{c|}{$6.967$} & \multicolumn{1}{c|}{$5.243$} & \multicolumn{1}{c|}{$3.516$} & \multicolumn{1}{c|}{$1.868$} & \multicolumn{1}{c|}{$6.880$} & \multicolumn{1}{c|}{$5.215$} & \multicolumn{1}{c|}{$3.508$} & \multicolumn{1}{c|}{$1.867$} \\ \cline{3-15}
\multicolumn{1}{|c|}{} & \multicolumn{1}{c|}{} & BSE ($\times$10) & \multicolumn{1}{c|}{$10.319$} & \multicolumn{1}{c|}{$8.607$} & \multicolumn{1}{c|}{$6.442$} & \multicolumn{1}{c|}{$4.203$} & \multicolumn{1}{c|}{$10.677$} & \multicolumn{1}{c|}{$8.659$} & \multicolumn{1}{c|}{$6.388$} & \multicolumn{1}{c|}{$4.107$} & \multicolumn{1}{c|}{$10.567$} & \multicolumn{1}{c|}{$8.509$} & \multicolumn{1}{c|}{$6.422$} & \multicolumn{1}{c|}{$4.138$} \\ \cline{3-15}
\multicolumn{1}{|c|}{} & \multicolumn{1}{c|}{} & ESE ($\times$10) & \multicolumn{1}{c|}{$7.815$} & \multicolumn{1}{c|}{$5.807$} & \multicolumn{1}{c|}{$3.529$} & \multicolumn{1}{c|}{$1.854$} & \multicolumn{1}{c|}{$8.576$} & \multicolumn{1}{c|}{$6.311$} & \multicolumn{1}{c|}{$3.843$} & \multicolumn{1}{c|}{$2.021$} & \multicolumn{1}{c|}{$8.525$} & \multicolumn{1}{c|}{$6.302$} & \multicolumn{1}{c|}{$3.843$} & \multicolumn{1}{c|}{$2.016$} \\ \cline{3-15}
\multicolumn{1}{|c|}{} & \multicolumn{1}{c|}{} & MSE ($\times$100) & \multicolumn{1}{c|}{$63.489$} & \multicolumn{1}{c|}{$39.435$} & \multicolumn{1}{c|}{$16.381$} & \multicolumn{1}{c|}{$7.391$} & \multicolumn{1}{c|}{$73.683$} & \multicolumn{1}{c|}{$39.942$} & \multicolumn{1}{c|}{$14.746$} & \multicolumn{1}{c|}{$4.075$} & \multicolumn{1}{c|}{$72.557$} & \multicolumn{1}{c|}{$40.052$} & \multicolumn{1}{c|}{$14.740$} & \multicolumn{1}{c|}{$4.059$} \\ \cline{3-15}
\multicolumn{1}{|c|}{} & \multicolumn{1}{c|}{} & Cover (ASE) & \multicolumn{1}{c|}{$0.866$} & \multicolumn{1}{c|}{$0.850$} & \multicolumn{1}{c|}{$0.866$} & \multicolumn{1}{c|}{$0.780$} & \multicolumn{1}{c|}{$0.880$} & \multicolumn{1}{c|}{$0.878$} & \multicolumn{1}{c|}{$0.924$} & \multicolumn{1}{c|}{$0.948$} & \multicolumn{1}{c|}{$0.878$} & \multicolumn{1}{c|}{$0.878$} & \multicolumn{1}{c|}{$0.922$} & \multicolumn{1}{c|}{$0.948$} \\ \cline{3-15}
\multicolumn{1}{|c|}{} & \multicolumn{1}{c|}{} & Cover (BSE) & \multicolumn{1}{c|}{$0.972$} & \multicolumn{1}{c|}{$0.974$} & \multicolumn{1}{c|}{$0.998$} & \multicolumn{1}{c|}{$1.000$} & \multicolumn{1}{c|}{$0.956$} & \multicolumn{1}{c|}{$0.974$} & \multicolumn{1}{c|}{$0.984$} & \multicolumn{1}{c|}{$0.994$} & \multicolumn{1}{c|}{$0.952$} & \multicolumn{1}{c|}{$0.966$} & \multicolumn{1}{c|}{$0.988$} & \multicolumn{1}{c|}{$0.994$} \\ \cline{2-15}
\multicolumn{1}{|c|}{} & \multicolumn{1}{c|}{\multirow{7}{*}{5}} & Bias ($\times$10) & \multicolumn{1}{c|}{$-0.370$} & \multicolumn{1}{c|}{$-0.075$} & \multicolumn{1}{c|}{$0.179$} & \multicolumn{1}{c|}{$0.291$} & \multicolumn{1}{c|}{$-0.345$} & \multicolumn{1}{c|}{$-0.093$} & \multicolumn{1}{c|}{$0.528$} & \multicolumn{1}{c|}{$0.332$} & \multicolumn{1}{c|}{$-1.301$} & \multicolumn{1}{c|}{$-0.679$} & \multicolumn{1}{c|}{$0.026$} & \multicolumn{1}{c|}{$0.384$} \\ \cline{3-15}
\multicolumn{1}{|c|}{} & \multicolumn{1}{c|}{} & ASE ($\times$10) & \multicolumn{1}{c|}{$6.275$} & \multicolumn{1}{c|}{$4.710$} & \multicolumn{1}{c|}{$3.164$} & \multicolumn{1}{c|}{$1.670$} & \multicolumn{1}{c|}{$11.299$} & \multicolumn{1}{c|}{$6.747$} & \multicolumn{1}{c|}{$4.183$} & \multicolumn{1}{c|}{$1.969$} & \multicolumn{1}{c|}{$7.370$} & \multicolumn{1}{c|}{$5.312$} & \multicolumn{1}{c|}{$3.472$} & \multicolumn{1}{c|}{$1.804$} \\ \cline{3-15}
\multicolumn{1}{|c|}{} & \multicolumn{1}{c|}{} & BSE ($\times$10) & \multicolumn{1}{c|}{$9.965$} & \multicolumn{1}{c|}{$7.980$} & \multicolumn{1}{c|}{$6.167$} & \multicolumn{1}{c|}{$3.946$} & \multicolumn{1}{c|}{$11.499$} & \multicolumn{1}{c|}{$8.774$} & \multicolumn{1}{c|}{$6.596$} & \multicolumn{1}{c|}{$4.068$} & \multicolumn{1}{c|}{$10.297$} & \multicolumn{1}{c|}{$8.257$} & \multicolumn{1}{c|}{$6.256$} & \multicolumn{1}{c|}{$4.011$} \\ \cline{3-15}
\multicolumn{1}{|c|}{} & \multicolumn{1}{c|}{} & ESE ($\times$10) & \multicolumn{1}{c|}{$8.016$} & \multicolumn{1}{c|}{$5.903$} & \multicolumn{1}{c|}{$3.377$} & \multicolumn{1}{c|}{$1.740$} & \multicolumn{1}{c|}{$9.887$} & \multicolumn{1}{c|}{$7.479$} & \multicolumn{1}{c|}{$4.133$} & \multicolumn{1}{c|}{$1.954$} & \multicolumn{1}{c|}{$8.509$} & \multicolumn{1}{c|}{$6.570$} & \multicolumn{1}{c|}{$3.658$} & \multicolumn{1}{c|}{$1.845$} \\ \cline{3-15}
\multicolumn{1}{|c|}{} & \multicolumn{1}{c|}{} & MSE ($\times$100) & \multicolumn{1}{c|}{$64.259$} & \multicolumn{1}{c|}{$34.787$} & \multicolumn{1}{c|}{$11.415$} & \multicolumn{1}{c|}{$3.107$} & \multicolumn{1}{c|}{$97.671$} & \multicolumn{1}{c|}{$55.828$} & \multicolumn{1}{c|}{$17.324$} & \multicolumn{1}{c|}{$3.919$} & \multicolumn{1}{c|}{$73.956$} & \multicolumn{1}{c|}{$43.544$} & \multicolumn{1}{c|}{$13.353$} & \multicolumn{1}{c|}{$3.543$} \\ \cline{3-15}
\multicolumn{1}{|c|}{} & \multicolumn{1}{c|}{} & Cover (ASE) & \multicolumn{1}{c|}{$0.866$} & \multicolumn{1}{c|}{$0.870$} & \multicolumn{1}{c|}{$0.926$} & \multicolumn{1}{c|}{$0.936$} & \multicolumn{1}{c|}{$0.936$} & \multicolumn{1}{c|}{$0.908$} & \multicolumn{1}{c|}{$0.958$} & \multicolumn{1}{c|}{$0.950$} & \multicolumn{1}{c|}{$0.898$} & \multicolumn{1}{c|}{$0.860$} & \multicolumn{1}{c|}{$0.936$} & \multicolumn{1}{c|}{$0.942$} \\ \cline{3-15}
\multicolumn{1}{|c|}{} & \multicolumn{1}{c|}{} & Cover (BSE) & \multicolumn{1}{c|}{$0.952$} & \multicolumn{1}{c|}{$0.962$} & \multicolumn{1}{c|}{$0.996$} & \multicolumn{1}{c|}{$1.000$} & \multicolumn{1}{c|}{$0.938$} & \multicolumn{1}{c|}{$0.946$} & \multicolumn{1}{c|}{$0.980$} & \multicolumn{1}{c|}{$1.000$} & \multicolumn{1}{c|}{$0.932$} & \multicolumn{1}{c|}{$0.948$} & \multicolumn{1}{c|}{$0.992$} & \multicolumn{1}{c|}{$0.998$} \\ \cline{2-15}
\multicolumn{1}{|c|}{} & \multicolumn{1}{c|}{\multirow{7}{*}{9}} & Bias ($\times$10) & \multicolumn{1}{c|}{$-1.123$} & \multicolumn{1}{c|}{$-0.472$} & \multicolumn{1}{c|}{$-1.026$} & \multicolumn{1}{c|}{$-0.910$} & \multicolumn{1}{c|}{$-0.923$} & \multicolumn{1}{c|}{$0.228$} & \multicolumn{1}{c|}{$-0.402$} & \multicolumn{1}{c|}{$-0.317$} & \multicolumn{1}{c|}{$-1.228$} & \multicolumn{1}{c|}{$-0.128$} & \multicolumn{1}{c|}{$-0.527$} & \multicolumn{1}{c|}{$-0.366$} \\ \cline{3-15}
\multicolumn{1}{|c|}{} & \multicolumn{1}{c|}{} & ASE ($\times$10) & \multicolumn{1}{c|}{$6.414$} & \multicolumn{1}{c|}{$4.778$} & \multicolumn{1}{c|}{$3.178$} & \multicolumn{1}{c|}{$1.678$} & \multicolumn{1}{c|}{$9.985$} & \multicolumn{1}{c|}{$7.101$} & \multicolumn{1}{c|}{$4.573$} & \multicolumn{1}{c|}{$2.255$} & \multicolumn{1}{c|}{$7.856$} & \multicolumn{1}{c|}{$5.851$} & \multicolumn{1}{c|}{$3.830$} & \multicolumn{1}{c|}{$1.982$} \\ \cline{3-15}
\multicolumn{1}{|c|}{} & \multicolumn{1}{c|}{} & BSE ($\times$10) & \multicolumn{1}{c|}{$9.928$} & \multicolumn{1}{c|}{$8.085$} & \multicolumn{1}{c|}{$5.942$} & \multicolumn{1}{c|}{$3.873$} & \multicolumn{1}{c|}{$11.289$} & \multicolumn{1}{c|}{$8.762$} & \multicolumn{1}{c|}{$6.386$} & \multicolumn{1}{c|}{$4.066$} & \multicolumn{1}{c|}{$10.404$} & \multicolumn{1}{c|}{$8.309$} & \multicolumn{1}{c|}{$6.250$} & \multicolumn{1}{c|}{$3.953$} \\ \cline{3-15}
\multicolumn{1}{|c|}{} & \multicolumn{1}{c|}{} & ESE ($\times$10) & \multicolumn{1}{c|}{$7.827$} & \multicolumn{1}{c|}{$5.755$} & \multicolumn{1}{c|}{$3.454$} & \multicolumn{1}{c|}{$1.698$} & \multicolumn{1}{c|}{$9.365$} & \multicolumn{1}{c|}{$6.819$} & \multicolumn{1}{c|}{$4.047$} & \multicolumn{1}{c|}{$1.965$} & \multicolumn{1}{c|}{$8.545$} & \multicolumn{1}{c|}{$6.305$} & \multicolumn{1}{c|}{$3.828$} & \multicolumn{1}{c|}{$1.831$} \\ \cline{3-15}
\multicolumn{1}{|c|}{} & \multicolumn{1}{c|}{} & MSE ($\times$100) & \multicolumn{1}{c|}{$62.394$} & \multicolumn{1}{c|}{$33.277$} & \multicolumn{1}{c|}{$12.960$} & \multicolumn{1}{c|}{$3.707$} & \multicolumn{1}{c|}{$88.380$} & \multicolumn{1}{c|}{$46.453$} & \multicolumn{1}{c|}{$16.510$} & \multicolumn{1}{c|}{$3.954$} & \multicolumn{1}{c|}{$74.376$} & \multicolumn{1}{c|}{$39.688$} & \multicolumn{1}{c|}{$14.904$} & \multicolumn{1}{c|}{$3.480$} \\ \cline{3-15}
\multicolumn{1}{|c|}{} & \multicolumn{1}{c|}{} & Cover (ASE) & \multicolumn{1}{c|}{$0.872$} & \multicolumn{1}{c|}{$0.884$} & \multicolumn{1}{c|}{$0.918$} & \multicolumn{1}{c|}{$0.906$} & \multicolumn{1}{c|}{$0.952$} & \multicolumn{1}{c|}{$0.940$} & \multicolumn{1}{c|}{$0.970$} & \multicolumn{1}{c|}{$0.980$} & \multicolumn{1}{c|}{$0.920$} & \multicolumn{1}{c|}{$0.912$} & \multicolumn{1}{c|}{$0.942$} & \multicolumn{1}{c|}{$0.952$} \\ \cline{3-15}
\multicolumn{1}{|c|}{} & \multicolumn{1}{c|}{} & Cover (BSE) & \multicolumn{1}{c|}{$0.948$} & \multicolumn{1}{c|}{$0.960$} & \multicolumn{1}{c|}{$0.984$} & \multicolumn{1}{c|}{$1.000$} & \multicolumn{1}{c|}{$0.952$} & \multicolumn{1}{c|}{$0.958$} & \multicolumn{1}{c|}{$0.980$} & \multicolumn{1}{c|}{$1.000$} & \multicolumn{1}{c|}{$0.948$} & \multicolumn{1}{c|}{$0.964$} & \multicolumn{1}{c|}{$0.976$} & \multicolumn{1}{c|}{$1.000$} \\ \hline \hline
\multicolumn{1}{|c|}{\multirow{21}{*}{1}} & \multicolumn{1}{c|}{\multirow{7}{*}{2}} & Bias ($\times$10) & \multicolumn{1}{c|}{$0.888$} & \multicolumn{1}{c|}{$0.807$} & \multicolumn{1}{c|}{$1.005$} & \multicolumn{1}{c|}{$0.979$} & \multicolumn{1}{c|}{$-0.344$} & \multicolumn{1}{c|}{$-0.143$} & \multicolumn{1}{c|}{$0.038$} & \multicolumn{1}{c|}{$-0.000$} & \multicolumn{1}{c|}{$-0.184$} & \multicolumn{1}{c|}{$-0.073$} & \multicolumn{1}{c|}{$0.082$} & \multicolumn{1}{c|}{$0.018$} \\ \cline{3-15}
\multicolumn{1}{|c|}{} & \multicolumn{1}{c|}{} & ASE ($\times$10) & \multicolumn{1}{c|}{$6.556$} & \multicolumn{1}{c|}{$4.877$} & \multicolumn{1}{c|}{$3.290$} & \multicolumn{1}{c|}{$1.726$} & \multicolumn{1}{c|}{$7.270$} & \multicolumn{1}{c|}{$5.341$} & \multicolumn{1}{c|}{$3.565$} & \multicolumn{1}{c|}{$1.867$} & \multicolumn{1}{c|}{$7.204$} & \multicolumn{1}{c|}{$5.322$} & \multicolumn{1}{c|}{$3.559$} & \multicolumn{1}{c|}{$1.866$} \\ \cline{3-15}
\multicolumn{1}{|c|}{} & \multicolumn{1}{c|}{} & BSE ($\times$10) & \multicolumn{1}{c|}{$10.532$} & \multicolumn{1}{c|}{$8.277$} & \multicolumn{1}{c|}{$6.463$} & \multicolumn{1}{c|}{$4.124$} & \multicolumn{1}{c|}{$10.970$} & \multicolumn{1}{c|}{$8.681$} & \multicolumn{1}{c|}{$6.591$} & \multicolumn{1}{c|}{$4.087$} & \multicolumn{1}{c|}{$10.960$} & \multicolumn{1}{c|}{$8.701$} & \multicolumn{1}{c|}{$6.621$} & \multicolumn{1}{c|}{$4.090$} \\ \cline{3-15}
\multicolumn{1}{|c|}{} & \multicolumn{1}{c|}{} & ESE ($\times$10) & \multicolumn{1}{c|}{$7.847$} & \multicolumn{1}{c|}{$5.732$} & \multicolumn{1}{c|}{$3.657$} & \multicolumn{1}{c|}{$1.846$} & \multicolumn{1}{c|}{$8.649$} & \multicolumn{1}{c|}{$6.106$} & \multicolumn{1}{c|}{$3.989$} & \multicolumn{1}{c|}{$2.014$} & \multicolumn{1}{c|}{$8.615$} & \multicolumn{1}{c|}{$6.087$} & \multicolumn{1}{c|}{$3.984$} & \multicolumn{1}{c|}{$2.014$} \\ \cline{3-15}
\multicolumn{1}{|c|}{} & \multicolumn{1}{c|}{} & MSE ($\times$100) & \multicolumn{1}{c|}{$62.241$} & \multicolumn{1}{c|}{$33.444$} & \multicolumn{1}{c|}{$14.359$} & \multicolumn{1}{c|}{$4.359$} & \multicolumn{1}{c|}{$74.777$} & \multicolumn{1}{c|}{$37.232$} & \multicolumn{1}{c|}{$15.883$} & \multicolumn{1}{c|}{$4.047$} & \multicolumn{1}{c|}{$74.097$} & \multicolumn{1}{c|}{$36.983$} & \multicolumn{1}{c|}{$15.844$} & \multicolumn{1}{c|}{$4.047$} \\ \cline{3-15}
\multicolumn{1}{|c|}{} & \multicolumn{1}{c|}{} & Cover (ASE) & \multicolumn{1}{c|}{$0.876$} & \multicolumn{1}{c|}{$0.878$} & \multicolumn{1}{c|}{$0.900$} & \multicolumn{1}{c|}{$0.888$} & \multicolumn{1}{c|}{$0.890$} & \multicolumn{1}{c|}{$0.890$} & \multicolumn{1}{c|}{$0.928$} & \multicolumn{1}{c|}{$0.926$} & \multicolumn{1}{c|}{$0.880$} & \multicolumn{1}{c|}{$0.890$} & \multicolumn{1}{c|}{$0.928$} & \multicolumn{1}{c|}{$0.926$} \\ \cline{3-15}
\multicolumn{1}{|c|}{} & \multicolumn{1}{c|}{} & Cover (BSE) & \multicolumn{1}{c|}{$0.960$} & \multicolumn{1}{c|}{$0.972$} & \multicolumn{1}{c|}{$0.994$} & \multicolumn{1}{c|}{$1.000$} & \multicolumn{1}{c|}{$0.962$} & \multicolumn{1}{c|}{$0.958$} & \multicolumn{1}{c|}{$0.988$} & \multicolumn{1}{c|}{$1.000$} & \multicolumn{1}{c|}{$0.958$} & \multicolumn{1}{c|}{$0.962$} & \multicolumn{1}{c|}{$0.992$} & \multicolumn{1}{c|}{$1.000$} \\ \cline{2-15}
\multicolumn{1}{|c|}{} & \multicolumn{1}{c|}{\multirow{7}{*}{5}} & Bias ($\times$10) & \multicolumn{1}{c|}{$0.233$} & \multicolumn{1}{c|}{$0.237$} & \multicolumn{1}{c|}{$0.373$} & \multicolumn{1}{c|}{$0.289$} & \multicolumn{1}{c|}{$-0.040$} & \multicolumn{1}{c|}{$-0.081$} & \multicolumn{1}{c|}{$0.251$} & \multicolumn{1}{c|}{$0.113$} & \multicolumn{1}{c|}{$-0.318$} & \multicolumn{1}{c|}{$-0.302$} & \multicolumn{1}{c|}{$0.058$} & \multicolumn{1}{c|}{$0.065$} \\ \cline{3-15}
\multicolumn{1}{|c|}{} & \multicolumn{1}{c|}{} & ASE ($\times$10) & \multicolumn{1}{c|}{$6.646$} & \multicolumn{1}{c|}{$4.836$} & \multicolumn{1}{c|}{$3.206$} & \multicolumn{1}{c|}{$1.663$} & \multicolumn{1}{c|}{$8.961$} & \multicolumn{1}{c|}{$5.860$} & \multicolumn{1}{c|}{$3.585$} & \multicolumn{1}{c|}{$1.772$} & \multicolumn{1}{c|}{$7.362$} & \multicolumn{1}{c|}{$5.229$} & \multicolumn{1}{c|}{$3.418$} & \multicolumn{1}{c|}{$1.742$} \\ \cline{3-15}
\multicolumn{1}{|c|}{} & \multicolumn{1}{c|}{} & BSE ($\times$10) & \multicolumn{1}{c|}{$10.576$} & \multicolumn{1}{c|}{$8.273$} & \multicolumn{1}{c|}{$6.267$} & \multicolumn{1}{c|}{$3.991$} & \multicolumn{1}{c|}{$11.565$} & \multicolumn{1}{c|}{$8.625$} & \multicolumn{1}{c|}{$6.510$} & \multicolumn{1}{c|}{$4.055$} & \multicolumn{1}{c|}{$11.463$} & \multicolumn{1}{c|}{$8.620$} & \multicolumn{1}{c|}{$6.365$} & \multicolumn{1}{c|}{$4.022$} \\ \cline{3-15}
\multicolumn{1}{|c|}{} & \multicolumn{1}{c|}{} & ESE ($\times$10) & \multicolumn{1}{c|}{$8.392$} & \multicolumn{1}{c|}{$5.998$} & \multicolumn{1}{c|}{$3.359$} & \multicolumn{1}{c|}{$1.649$} & \multicolumn{1}{c|}{$9.034$} & \multicolumn{1}{c|}{$6.635$} & \multicolumn{1}{c|}{$3.719$} & \multicolumn{1}{c|}{$1.778$} & \multicolumn{1}{c|}{$8.532$} & \multicolumn{1}{c|}{$6.377$} & \multicolumn{1}{c|}{$3.656$} & \multicolumn{1}{c|}{$1.739$} \\ \cline{3-15}
\multicolumn{1}{|c|}{} & \multicolumn{1}{c|}{} & MSE ($\times$100) & \multicolumn{1}{c|}{$70.342$} & \multicolumn{1}{c|}{$35.961$} & \multicolumn{1}{c|}{$11.400$} & \multicolumn{1}{c|}{$2.798$} & \multicolumn{1}{c|}{$81.459$} & \multicolumn{1}{c|}{$43.944$} & \multicolumn{1}{c|}{$13.870$} & \multicolumn{1}{c|}{$3.169$} & \multicolumn{1}{c|}{$72.748$} & \multicolumn{1}{c|}{$40.676$} & \multicolumn{1}{c|}{$13.346$} & \multicolumn{1}{c|}{$3.022$} \\ \cline{3-15}
\multicolumn{1}{|c|}{} & \multicolumn{1}{c|}{} & Cover (ASE) & \multicolumn{1}{c|}{$0.852$} & \multicolumn{1}{c|}{$0.896$} & \multicolumn{1}{c|}{$0.922$} & \multicolumn{1}{c|}{$0.954$} & \multicolumn{1}{c|}{$0.932$} & \multicolumn{1}{c|}{$0.898$} & \multicolumn{1}{c|}{$0.934$} & \multicolumn{1}{c|}{$0.948$} & \multicolumn{1}{c|}{$0.908$} & \multicolumn{1}{c|}{$0.882$} & \multicolumn{1}{c|}{$0.920$} & \multicolumn{1}{c|}{$0.948$} \\ \cline{3-15}
\multicolumn{1}{|c|}{} & \multicolumn{1}{c|}{} & Cover (BSE) & \multicolumn{1}{c|}{$0.960$} & \multicolumn{1}{c|}{$0.960$} & \multicolumn{1}{c|}{$0.992$} & \multicolumn{1}{c|}{$0.998$} & \multicolumn{1}{c|}{$0.962$} & \multicolumn{1}{c|}{$0.944$} & \multicolumn{1}{c|}{$0.998$} & \multicolumn{1}{c|}{$1.000$} & \multicolumn{1}{c|}{$0.968$} & \multicolumn{1}{c|}{$0.952$} & \multicolumn{1}{c|}{$0.992$} & \multicolumn{1}{c|}{$0.998$} \\ \cline{2-15}
\multicolumn{1}{|c|}{} & \multicolumn{1}{c|}{\multirow{7}{*}{9}} & Bias ($\times$10) & \multicolumn{1}{c|}{$-0.791$} & \multicolumn{1}{c|}{$-0.996$} & \multicolumn{1}{c|}{$-0.848$} & \multicolumn{1}{c|}{$-0.698$} & \multicolumn{1}{c|}{$-1.083$} & \multicolumn{1}{c|}{$-0.953$} & \multicolumn{1}{c|}{$-0.647$} & \multicolumn{1}{c|}{$-0.126$} & \multicolumn{1}{c|}{$-1.113$} & \multicolumn{1}{c|}{$-1.088$} & \multicolumn{1}{c|}{$-0.862$} & \multicolumn{1}{c|}{$-0.462$} \\ \cline{3-15}
\multicolumn{1}{|c|}{} & \multicolumn{1}{c|}{} & ASE ($\times$10) & \multicolumn{1}{c|}{$7.110$} & \multicolumn{1}{c|}{$5.063$} & \multicolumn{1}{c|}{$3.318$} & \multicolumn{1}{c|}{$1.734$} & \multicolumn{1}{c|}{$10.109$} & \multicolumn{1}{c|}{$6.788$} & \multicolumn{1}{c|}{$4.091$} & \multicolumn{1}{c|}{$1.955$} & \multicolumn{1}{c|}{$8.474$} & \multicolumn{1}{c|}{$5.868$} & \multicolumn{1}{c|}{$3.621$} & \multicolumn{1}{c|}{$1.797$} \\ \cline{3-15}
\multicolumn{1}{|c|}{} & \multicolumn{1}{c|}{} & BSE ($\times$10) & \multicolumn{1}{c|}{$10.357$} & \multicolumn{1}{c|}{$8.326$} & \multicolumn{1}{c|}{$6.151$} & \multicolumn{1}{c|}{$3.990$} & \multicolumn{1}{c|}{$12.310$} & \multicolumn{1}{c|}{$9.066$} & \multicolumn{1}{c|}{$6.505$} & \multicolumn{1}{c|}{$4.091$} & \multicolumn{1}{c|}{$12.003$} & \multicolumn{1}{c|}{$9.126$} & \multicolumn{1}{c|}{$6.420$} & \multicolumn{1}{c|}{$4.101$} \\ \cline{3-15}
\multicolumn{1}{|c|}{} & \multicolumn{1}{c|}{} & ESE ($\times$10) & \multicolumn{1}{c|}{$8.532$} & \multicolumn{1}{c|}{$5.691$} & \multicolumn{1}{c|}{$3.610$} & \multicolumn{1}{c|}{$1.830$} & \multicolumn{1}{c|}{$9.964$} & \multicolumn{1}{c|}{$6.548$} & \multicolumn{1}{c|}{$3.895$} & \multicolumn{1}{c|}{$1.867$} & \multicolumn{1}{c|}{$9.185$} & \multicolumn{1}{c|}{$6.135$} & \multicolumn{1}{c|}{$3.781$} & \multicolumn{1}{c|}{$1.848$} \\ \cline{3-15}
\multicolumn{1}{|c|}{} & \multicolumn{1}{c|}{} & MSE ($\times$100) & \multicolumn{1}{c|}{$73.267$} & \multicolumn{1}{c|}{$33.320$} & \multicolumn{1}{c|}{$13.729$} & \multicolumn{1}{c|}{$3.830$} & \multicolumn{1}{c|}{$100.256$} & \multicolumn{1}{c|}{$43.702$} & \multicolumn{1}{c|}{$15.558$} & \multicolumn{1}{c|}{$3.496$} & \multicolumn{1}{c|}{$85.438$} & \multicolumn{1}{c|}{$38.742$} & \multicolumn{1}{c|}{$15.014$} & \multicolumn{1}{c|}{$3.623$} \\ \cline{3-15}
\multicolumn{1}{|c|}{} & \multicolumn{1}{c|}{} & Cover (ASE) & \multicolumn{1}{c|}{$0.894$} & \multicolumn{1}{c|}{$0.908$} & \multicolumn{1}{c|}{$0.908$} & \multicolumn{1}{c|}{$0.910$} & \multicolumn{1}{c|}{$0.948$} & \multicolumn{1}{c|}{$0.960$} & \multicolumn{1}{c|}{$0.956$} & \multicolumn{1}{c|}{$0.952$} & \multicolumn{1}{c|}{$0.926$} & \multicolumn{1}{c|}{$0.930$} & \multicolumn{1}{c|}{$0.924$} & \multicolumn{1}{c|}{$0.940$} \\ \cline{3-15}
\multicolumn{1}{|c|}{} & \multicolumn{1}{c|}{} & Cover (BSE) & \multicolumn{1}{c|}{$0.942$} & \multicolumn{1}{c|}{$0.980$} & \multicolumn{1}{c|}{$0.990$} & \multicolumn{1}{c|}{$1.000$} & \multicolumn{1}{c|}{$0.960$} & \multicolumn{1}{c|}{$0.986$} & \multicolumn{1}{c|}{$0.984$} & \multicolumn{1}{c|}{$0.998$} & \multicolumn{1}{c|}{$0.956$} & \multicolumn{1}{c|}{$0.984$} & \multicolumn{1}{c|}{$0.990$} & \multicolumn{1}{c|}{$0.998$} \\ \hline

\end{tabular}
\caption{Summary Statistics of the Estimation Results for $\beta_{1}^*=3$.} 
\label{tab:supp:Table1}
\end{table}

 

We report the performance of the conformal inference in Section \ref{sec:Conformal} of the main paper under the simulation scenarios in Section \ref{sec:Sim} of the main paper. First, we obtain the pointwise 95\% pointwise prediction interval for the random treatment effect at the first post-treatment time $t=T_0+1$, which are
\begin{align*}
&
\text{Constant ATT} :
&&
\xi_{T_0+1}^* = 3 + \epsilon_{\tau,T_0+1} \ 
, 
&&
\text{Linear ATT} :
&&
\xi_{T_0+1}^* = 3 + 3/T_0 + \epsilon_{\tau,T_0+1}
\ .
\end{align*}
As a competing method, we construct 95\% pointwise prediction intervals using the approach proposed by \citet{Cattaneo2021}, which is implemented in \texttt{scpi} R-package \citep{scpiPackage2023}. In particular, we use the prediction interval estimating out-of-sample uncertainty with sub-Gaussian bounds, which is stored in \texttt{CI.all.gaussian} object of a \texttt{scpi} output; see below for an example R-code:
\begin{itemize}[leftmargin=2cm,itemsep=0cm]
\item[] \texttt{scpi.est $\leftarrow$ scpi::scpi(SCD) \# SCD is a scdata object}
\item[] \texttt{scpi.PI \ $\leftarrow$ scpi.est\$inference.results\$CI.all.gaussian}
\end{itemize}
For each simulation repetition and each method, we calculate $\ind \big(\xi_{T_0+1} ^* \in \mathcal{C}_{T_0+1} \big)$ where $\mathcal{C}_{T_0+1}$ is a 95\% prediction interval obtained from each method, i.e., the indicator of whether a 95\% prediction interval at $t=T_0+1$ obtained from each method includes the random treatment effect. Ideally, the average of these indicators across simulation repetitions (i.e., the empirical coverage rate of 95\% prediction intervals) should be close to the nominal coverage rate of 0.95.

Table \ref{tab:supp:Table3} shows the empirical coverage rates obtained from 500 repetitions for each simulation scenario. We find that the conformal inference approach for the SPSC achieves the nominal coverage rate across all simulation scenarios in general. However, we find that \texttt{scpi} approach fails to achieve the nominal coverage rate, especially when the number of donors is small (i.e., $d=2$), the time periods are long (i.e., $T_0=1000$), and the average treatment effect varies across time (i.e., linear treatment effects).



\begin{table}[!htp]
\renewcommand{\arraystretch}{1.05} \centering
\footnotesize
\setlength{\tabcolsep}{5pt}  
\begin{tabular}{|ccc|cccc|cccc|cccc|}
\hline
\multicolumn{3}{|c|}{Estimator} & \multicolumn{4}{c|}{SPSC} & \multicolumn{4}{c|}{SPSC-Ridge} & \multicolumn{4}{c|}{SCPI} \\ \hline
\multicolumn{1}{|c|}{\multirow{2}{*}{ATT}} & \multicolumn{1}{c|}{\multirow{2}{*}{$\ \delta \ $}} & \multirow{2}{*}{$ \ d \ $} & \multicolumn{4}{c|}{$T_0$} & \multicolumn{4}{c|}{$T_0$} & \multicolumn{4}{c|}{$T_0$} \\ \cline{4-15} 
\multicolumn{1}{|c|}{} & \multicolumn{1}{c|}{} & & \multicolumn{1}{c|}{50} & \multicolumn{1}{c|}{100} & \multicolumn{1}{c|}{250} & 1000 & \multicolumn{1}{c|}{50} & \multicolumn{1}{c|}{100} & \multicolumn{1}{c|}{250} & 1000 & \multicolumn{1}{c|}{50} & \multicolumn{1}{c|}{100} & \multicolumn{1}{c|}{250} & 1000 \\ \hline

\multicolumn{1}{|c|}{\multirow{6}{*}{Constant}} & \multicolumn{1}{c|}{\multirow{3}{*}{0}} & \multicolumn{1}{c|}{2} & \multicolumn{1}{c|}{$0.964$} & \multicolumn{1}{c|}{$0.946$} & \multicolumn{1}{c|}{$0.940$} & \multicolumn{1}{c|}{$0.948$} & \multicolumn{1}{c|}{$0.968$} & \multicolumn{1}{c|}{$0.950$} & \multicolumn{1}{c|}{$0.940$} & \multicolumn{1}{c|}{$0.948$} & \multicolumn{1}{c|}{$0.948$} & \multicolumn{1}{c|}{$0.924$} & \multicolumn{1}{c|}{$0.920$} & \multicolumn{1}{c|}{$0.904$} \\ \cline{3-15}
\multicolumn{1}{|c|}{} & \multicolumn{1}{c|}{} & \multicolumn{1}{c|}{5} & \multicolumn{1}{c|}{$0.962$} & \multicolumn{1}{c|}{$0.956$} & \multicolumn{1}{c|}{$0.956$} & \multicolumn{1}{c|}{$0.942$} & \multicolumn{1}{c|}{$0.956$} & \multicolumn{1}{c|}{$0.946$} & \multicolumn{1}{c|}{$0.960$} & \multicolumn{1}{c|}{$0.932$} & \multicolumn{1}{c|}{$0.980$} & \multicolumn{1}{c|}{$0.982$} & \multicolumn{1}{c|}{$0.978$} & \multicolumn{1}{c|}{$0.920$} \\ \cline{3-15}
\multicolumn{1}{|c|}{} & \multicolumn{1}{c|}{} & \multicolumn{1}{c|}{9} & \multicolumn{1}{c|}{$0.954$} & \multicolumn{1}{c|}{$0.948$} & \multicolumn{1}{c|}{$0.966$} & \multicolumn{1}{c|}{$0.944$} & \multicolumn{1}{c|}{$0.942$} & \multicolumn{1}{c|}{$0.942$} & \multicolumn{1}{c|}{$0.964$} & \multicolumn{1}{c|}{$0.952$} & \multicolumn{1}{c|}{$0.984$} & \multicolumn{1}{c|}{$0.990$} & \multicolumn{1}{c|}{$0.978$} & \multicolumn{1}{c|}{$0.954$} \\ \cline{2-15}
\multicolumn{1}{|c|}{} & \multicolumn{1}{c|}{\multirow{3}{*}{1}} & \multicolumn{1}{c|}{2} & \multicolumn{1}{c|}{$0.972$} & \multicolumn{1}{c|}{$0.940$} & \multicolumn{1}{c|}{$0.950$} & \multicolumn{1}{c|}{$0.954$} & \multicolumn{1}{c|}{$0.968$} & \multicolumn{1}{c|}{$0.942$} & \multicolumn{1}{c|}{$0.944$} & \multicolumn{1}{c|}{$0.962$} & \multicolumn{1}{c|}{$0.968$} & \multicolumn{1}{c|}{$0.944$} & \multicolumn{1}{c|}{$0.938$} & \multicolumn{1}{c|}{$0.894$} \\ \cline{3-15}
\multicolumn{1}{|c|}{} & \multicolumn{1}{c|}{} & \multicolumn{1}{c|}{5} & \multicolumn{1}{c|}{$0.956$} & \multicolumn{1}{c|}{$0.948$} & \multicolumn{1}{c|}{$0.956$} & \multicolumn{1}{c|}{$0.958$} & \multicolumn{1}{c|}{$0.954$} & \multicolumn{1}{c|}{$0.934$} & \multicolumn{1}{c|}{$0.960$} & \multicolumn{1}{c|}{$0.958$} & \multicolumn{1}{c|}{$0.980$} & \multicolumn{1}{c|}{$0.984$} & \multicolumn{1}{c|}{$0.966$} & \multicolumn{1}{c|}{$0.922$} \\ \cline{3-15}
\multicolumn{1}{|c|}{} & \multicolumn{1}{c|}{} & \multicolumn{1}{c|}{9} & \multicolumn{1}{c|}{$0.956$} & \multicolumn{1}{c|}{$0.950$} & \multicolumn{1}{c|}{$0.958$} & \multicolumn{1}{c|}{$0.938$} & \multicolumn{1}{c|}{$0.962$} & \multicolumn{1}{c|}{$0.946$} & \multicolumn{1}{c|}{$0.950$} & \multicolumn{1}{c|}{$0.946$} & \multicolumn{1}{c|}{$0.980$} & \multicolumn{1}{c|}{$0.992$} & \multicolumn{1}{c|}{$0.990$} & \multicolumn{1}{c|}{$0.944$} \\ \hline \hline
\multicolumn{1}{|c|}{\multirow{6}{*}{Linear}} & \multicolumn{1}{c|}{\multirow{3}{*}{0}} & \multicolumn{1}{c|}{2} & \multicolumn{1}{c|}{$0.964$} & \multicolumn{1}{c|}{$0.964$} & \multicolumn{1}{c|}{$0.948$} & \multicolumn{1}{c|}{$0.932$} & \multicolumn{1}{c|}{$0.968$} & \multicolumn{1}{c|}{$0.964$} & \multicolumn{1}{c|}{$0.946$} & \multicolumn{1}{c|}{$0.932$} & \multicolumn{1}{c|}{$0.866$} & \multicolumn{1}{c|}{$0.850$} & \multicolumn{1}{c|}{$0.866$} & \multicolumn{1}{c|}{$0.780$} \\ \cline{3-15}
\multicolumn{1}{|c|}{} & \multicolumn{1}{c|}{} & \multicolumn{1}{c|}{5} & \multicolumn{1}{c|}{$0.962$} & \multicolumn{1}{c|}{$0.940$} & \multicolumn{1}{c|}{$0.958$} & \multicolumn{1}{c|}{$0.954$} & \multicolumn{1}{c|}{$0.956$} & \multicolumn{1}{c|}{$0.954$} & \multicolumn{1}{c|}{$0.946$} & \multicolumn{1}{c|}{$0.954$} & \multicolumn{1}{c|}{$0.866$} & \multicolumn{1}{c|}{$0.870$} & \multicolumn{1}{c|}{$0.926$} & \multicolumn{1}{c|}{$0.936$} \\ \cline{3-15}
\multicolumn{1}{|c|}{} & \multicolumn{1}{c|}{} & \multicolumn{1}{c|}{9} & \multicolumn{1}{c|}{$0.954$} & \multicolumn{1}{c|}{$0.938$} & \multicolumn{1}{c|}{$0.964$} & \multicolumn{1}{c|}{$0.946$} & \multicolumn{1}{c|}{$0.942$} & \multicolumn{1}{c|}{$0.938$} & \multicolumn{1}{c|}{$0.954$} & \multicolumn{1}{c|}{$0.948$} & \multicolumn{1}{c|}{$0.872$} & \multicolumn{1}{c|}{$0.884$} & \multicolumn{1}{c|}{$0.918$} & \multicolumn{1}{c|}{$0.906$} \\ \cline{2-15}
\multicolumn{1}{|c|}{} & \multicolumn{1}{c|}{\multirow{3}{*}{1}} & \multicolumn{1}{c|}{2} & \multicolumn{1}{c|}{$0.972$} & \multicolumn{1}{c|}{$0.936$} & \multicolumn{1}{c|}{$0.954$} & \multicolumn{1}{c|}{$0.948$} & \multicolumn{1}{c|}{$0.968$} & \multicolumn{1}{c|}{$0.946$} & \multicolumn{1}{c|}{$0.954$} & \multicolumn{1}{c|}{$0.952$} & \multicolumn{1}{c|}{$0.876$} & \multicolumn{1}{c|}{$0.878$} & \multicolumn{1}{c|}{$0.900$} & \multicolumn{1}{c|}{$0.888$} \\ \cline{3-15}
\multicolumn{1}{|c|}{} & \multicolumn{1}{c|}{} & \multicolumn{1}{c|}{5} & \multicolumn{1}{c|}{$0.956$} & \multicolumn{1}{c|}{$0.948$} & \multicolumn{1}{c|}{$0.944$} & \multicolumn{1}{c|}{$0.936$} & \multicolumn{1}{c|}{$0.954$} & \multicolumn{1}{c|}{$0.934$} & \multicolumn{1}{c|}{$0.950$} & \multicolumn{1}{c|}{$0.930$} & \multicolumn{1}{c|}{$0.852$} & \multicolumn{1}{c|}{$0.896$} & \multicolumn{1}{c|}{$0.922$} & \multicolumn{1}{c|}{$0.954$} \\ \cline{3-15}
\multicolumn{1}{|c|}{} & \multicolumn{1}{c|}{} & \multicolumn{1}{c|}{9} & \multicolumn{1}{c|}{$0.956$} & \multicolumn{1}{c|}{$0.940$} & \multicolumn{1}{c|}{$0.954$} & \multicolumn{1}{c|}{$0.942$} & \multicolumn{1}{c|}{$0.962$} & \multicolumn{1}{c|}{$0.938$} & \multicolumn{1}{c|}{$0.950$} & \multicolumn{1}{c|}{$0.950$} & \multicolumn{1}{c|}{$0.894$} & \multicolumn{1}{c|}{$0.908$} & \multicolumn{1}{c|}{$0.908$} & \multicolumn{1}{c|}{$0.910$} \\ \hline

\end{tabular}
\caption{
Empirical Coverage Rates of 95\% Pointwise Prediction Intervals. The numbers in SPSC and SPSC-Ridge columns show the empirical coverage rates of 95\% pointwise prediction intervals obtained from the conformal inference approach in Section \ref{sec:Conformal}. The numbers in SCPI column show the empirical coverage rates of 95\% pointwise prediction intervals obtained from the approach proposed by \citet{Cattaneo2021} which is implemented in \texttt{scpi} R-package \citep{scpiPackage2023}.}
\label{tab:supp:Table3}
\vspace{-0.5cm}
\end{table}

Next, we calculate the average length of the 95\% prediction interval for $t=T_0+1$, i.e., the first post-treatment period, across 500 repetitions. 
Table \ref{tab:supp:Table4} shows the average lengths.
We find that the length of the prediction intervals decreases as the length of the pre-treatment periods increases. 
Additionally, we find that including ridge regularization in the estimation leads to shorter prediction intervals across all simulation scenarios. 
We remark that prediction intervals obtained from \texttt{scpi} are generally narrower than those obtained from the SPSC. 


\begin{table}[!htp]
\renewcommand{\arraystretch}{1.05} \centering
\footnotesize
\setlength{\tabcolsep}{5pt}  
\begin{tabular}{|ccc|cccc|cccc|cccc|}
\hline
\multicolumn{3}{|c|}{Estimator} & \multicolumn{4}{c|}{SPSC} & \multicolumn{4}{c|}{SPSC-Ridge} & \multicolumn{4}{c|}{SCPI} \\ \hline
\multicolumn{1}{|c|}{\multirow{2}{*}{ATT}} & \multicolumn{1}{c|}{\multirow{2}{*}{$\ \delta \ $}} & \multirow{2}{*}{$ \ d \ $} & \multicolumn{4}{c|}{$T_0$} & \multicolumn{4}{c|}{$T_0$} & \multicolumn{4}{c|}{$T_0$} \\ \cline{4-15} 
\multicolumn{1}{|c|}{} & \multicolumn{1}{c|}{} & & \multicolumn{1}{c|}{50} & \multicolumn{1}{c|}{100} & \multicolumn{1}{c|}{250} & 1000 & \multicolumn{1}{c|}{50} & \multicolumn{1}{c|}{100} & \multicolumn{1}{c|}{250} & 1000 & \multicolumn{1}{c|}{50} & \multicolumn{1}{c|}{100} & \multicolumn{1}{c|}{250} & 1000 \\ \hline
\multicolumn{1}{|c|}{\multirow{6}{*}{Constant}} & \multicolumn{1}{c|}{\multirow{3}{*}{0}} & \multicolumn{1}{c|}{2} & \multicolumn{1}{c|}{$3.377$} & \multicolumn{1}{c|}{$3.109$} & \multicolumn{1}{c|}{$3.094$} & \multicolumn{1}{c|}{$3.005$} & \multicolumn{1}{c|}{$3.296$} & \multicolumn{1}{c|}{$3.073$} & \multicolumn{1}{c|}{$3.076$} & \multicolumn{1}{c|}{$2.999$} & \multicolumn{1}{c|}{$1.919$} & \multicolumn{1}{c|}{$1.713$} & \multicolumn{1}{c|}{$1.534$} & \multicolumn{1}{c|}{$1.400$} \\ \cline{3-15}
\multicolumn{1}{|c|}{} & \multicolumn{1}{c|}{} & \multicolumn{1}{c|}{5} & \multicolumn{1}{c|}{$3.263$} & \multicolumn{1}{c|}{$2.834$} & \multicolumn{1}{c|}{$2.686$} & \multicolumn{1}{c|}{$2.466$} & \multicolumn{1}{c|}{$2.511$} & \multicolumn{1}{c|}{$2.281$} & \multicolumn{1}{c|}{$2.287$} & \multicolumn{1}{c|}{$2.263$} & \multicolumn{1}{c|}{$2.799$} & \multicolumn{1}{c|}{$2.415$} & \multicolumn{1}{c|}{$1.956$} & \multicolumn{1}{c|}{$1.583$} \\ \cline{3-15}
\multicolumn{1}{|c|}{} & \multicolumn{1}{c|}{} & \multicolumn{1}{c|}{9} & \multicolumn{1}{c|}{$3.189$} & \multicolumn{1}{c|}{$2.894$} & \multicolumn{1}{c|}{$2.809$} & \multicolumn{1}{c|}{$2.654$} & \multicolumn{1}{c|}{$2.617$} & \multicolumn{1}{c|}{$2.454$} & \multicolumn{1}{c|}{$2.349$} & \multicolumn{1}{c|}{$2.314$} & \multicolumn{1}{c|}{$2.750$} & \multicolumn{1}{c|}{$2.484$} & \multicolumn{1}{c|}{$2.105$} & \multicolumn{1}{c|}{$1.676$} \\ \cline{2-15}
\multicolumn{1}{|c|}{} & \multicolumn{1}{c|}{\multirow{3}{*}{1}} & \multicolumn{1}{c|}{2} & \multicolumn{1}{c|}{$3.459$} & \multicolumn{1}{c|}{$3.126$} & \multicolumn{1}{c|}{$3.091$} & \multicolumn{1}{c|}{$3.007$} & \multicolumn{1}{c|}{$3.387$} & \multicolumn{1}{c|}{$3.097$} & \multicolumn{1}{c|}{$3.078$} & \multicolumn{1}{c|}{$3.004$} & \multicolumn{1}{c|}{$2.189$} & \multicolumn{1}{c|}{$1.960$} & \multicolumn{1}{c|}{$1.729$} & \multicolumn{1}{c|}{$1.495$} \\ \cline{3-15}
\multicolumn{1}{|c|}{} & \multicolumn{1}{c|}{} & \multicolumn{1}{c|}{5} & \multicolumn{1}{c|}{$3.051$} & \multicolumn{1}{c|}{$2.570$} & \multicolumn{1}{c|}{$2.466$} & \multicolumn{1}{c|}{$2.426$} & \multicolumn{1}{c|}{$2.837$} & \multicolumn{1}{c|}{$2.385$} & \multicolumn{1}{c|}{$2.350$} & \multicolumn{1}{c|}{$2.334$} & \multicolumn{1}{c|}{$3.140$} & \multicolumn{1}{c|}{$2.780$} & \multicolumn{1}{c|}{$2.237$} & \multicolumn{1}{c|}{$1.748$} \\ \cline{3-15}
\multicolumn{1}{|c|}{} & \multicolumn{1}{c|}{} & \multicolumn{1}{c|}{9} & \multicolumn{1}{c|}{$3.184$} & \multicolumn{1}{c|}{$2.549$} & \multicolumn{1}{c|}{$2.446$} & \multicolumn{1}{c|}{$2.334$} & \multicolumn{1}{c|}{$2.948$} & \multicolumn{1}{c|}{$2.375$} & \multicolumn{1}{c|}{$2.272$} & \multicolumn{1}{c|}{$2.173$} & \multicolumn{1}{c|}{$3.098$} & \multicolumn{1}{c|}{$2.694$} & \multicolumn{1}{c|}{$2.246$} & \multicolumn{1}{c|}{$1.772$} \\ \hline \hline
\multicolumn{1}{|c|}{\multirow{6}{*}{Linear}} & \multicolumn{1}{c|}{\multirow{3}{*}{0}} & \multicolumn{1}{c|}{2} & \multicolumn{1}{c|}{$3.377$} & \multicolumn{1}{c|}{$3.119$} & \multicolumn{1}{c|}{$3.085$} & \multicolumn{1}{c|}{$3.006$} & \multicolumn{1}{c|}{$3.296$} & \multicolumn{1}{c|}{$3.081$} & \multicolumn{1}{c|}{$3.069$} & \multicolumn{1}{c|}{$3.000$} & \multicolumn{1}{c|}{$1.032$} & \multicolumn{1}{c|}{$0.861$} & \multicolumn{1}{c|}{$0.644$} & \multicolumn{1}{c|}{$0.420$} \\ \cline{3-15}
\multicolumn{1}{|c|}{} & \multicolumn{1}{c|}{} & \multicolumn{1}{c|}{5} & \multicolumn{1}{c|}{$3.263$} & \multicolumn{1}{c|}{$2.843$} & \multicolumn{1}{c|}{$2.631$} & \multicolumn{1}{c|}{$2.469$} & \multicolumn{1}{c|}{$2.511$} & \multicolumn{1}{c|}{$2.278$} & \multicolumn{1}{c|}{$2.250$} & \multicolumn{1}{c|}{$2.264$} & \multicolumn{1}{c|}{$0.997$} & \multicolumn{1}{c|}{$0.798$} & \multicolumn{1}{c|}{$0.617$} & \multicolumn{1}{c|}{$0.395$} \\ \cline{3-15}
\multicolumn{1}{|c|}{} & \multicolumn{1}{c|}{} & \multicolumn{1}{c|}{9} & \multicolumn{1}{c|}{$3.189$} & \multicolumn{1}{c|}{$2.879$} & \multicolumn{1}{c|}{$2.823$} & \multicolumn{1}{c|}{$2.619$} & \multicolumn{1}{c|}{$2.617$} & \multicolumn{1}{c|}{$2.421$} & \multicolumn{1}{c|}{$2.395$} & \multicolumn{1}{c|}{$2.324$} & \multicolumn{1}{c|}{$0.993$} & \multicolumn{1}{c|}{$0.809$} & \multicolumn{1}{c|}{$0.594$} & \multicolumn{1}{c|}{$0.387$} \\ \cline{2-15}
\multicolumn{1}{|c|}{} & \multicolumn{1}{c|}{\multirow{3}{*}{1}} & \multicolumn{1}{c|}{2} & \multicolumn{1}{c|}{$3.459$} & \multicolumn{1}{c|}{$3.122$} & \multicolumn{1}{c|}{$3.081$} & \multicolumn{1}{c|}{$3.012$} & \multicolumn{1}{c|}{$3.387$} & \multicolumn{1}{c|}{$3.095$} & \multicolumn{1}{c|}{$3.069$} & \multicolumn{1}{c|}{$3.008$} & \multicolumn{1}{c|}{$1.053$} & \multicolumn{1}{c|}{$0.828$} & \multicolumn{1}{c|}{$0.646$} & \multicolumn{1}{c|}{$0.412$} \\ \cline{3-15}
\multicolumn{1}{|c|}{} & \multicolumn{1}{c|}{} & \multicolumn{1}{c|}{5} & \multicolumn{1}{c|}{$3.051$} & \multicolumn{1}{c|}{$2.538$} & \multicolumn{1}{c|}{$2.478$} & \multicolumn{1}{c|}{$2.427$} & \multicolumn{1}{c|}{$2.837$} & \multicolumn{1}{c|}{$2.373$} & \multicolumn{1}{c|}{$2.356$} & \multicolumn{1}{c|}{$2.339$} & \multicolumn{1}{c|}{$1.058$} & \multicolumn{1}{c|}{$0.827$} & \multicolumn{1}{c|}{$0.627$} & \multicolumn{1}{c|}{$0.399$} \\ \cline{3-15}
\multicolumn{1}{|c|}{} & \multicolumn{1}{c|}{} & \multicolumn{1}{c|}{9} & \multicolumn{1}{c|}{$3.184$} & \multicolumn{1}{c|}{$2.551$} & \multicolumn{1}{c|}{$2.431$} & \multicolumn{1}{c|}{$2.331$} & \multicolumn{1}{c|}{$2.948$} & \multicolumn{1}{c|}{$2.398$} & \multicolumn{1}{c|}{$2.272$} & \multicolumn{1}{c|}{$2.173$} & \multicolumn{1}{c|}{$1.036$} & \multicolumn{1}{c|}{$0.833$} & \multicolumn{1}{c|}{$0.615$} & \multicolumn{1}{c|}{$0.399$} \\ \hline


\end{tabular}
\caption{Average Lengths of 95\% Pointwise Prediction Intervals at $t=T_0+1$. The numbers in SPSC and SPSC-Ridge columns show the average length of 95\% pointwise prediction intervals obtained from the conformal inference approach in Section \ref{sec:Conformal}. The numbers in SCPI column show the average length of 95\% pointwise prediction intervals obtained from the approach proposed by \citet{Cattaneo2021} which is implemented in \texttt{scpi} R-package \citep{scpiPackage2023}.}
\label{tab:supp:Table4}
\vspace{-0.5cm}
\end{table}

Lastly, we report the bias and the empirical standard error of the estimators for the average treatment effects on the treated (ATT) obtained from \texttt{scpi}. Specifically, the estimator is obtained as $\widehat{\tau}_{\text{ATT}} = T_1^{-1} \sum_{t=T_0+1}^{T} \big\{ Y_t - \widehat{Y}_{t}^{(0)} \big\}$ 
where $\widehat{Y}_{t}^{(0)} $ is a predicted value of the treatment-free potential outcome at time $t$. For simplicity, we only consider the constant treatment effect case $\tau_t^*=3$. Table \ref{tab:supp:Table5} summarizes the result. Compared with the two estimators obtained from the SPSC, we find the estimator obtained from \texttt{scpi} yields a significant magnitude of biases even under a large sample size. Moreover, compared to the empirical standard errors, these biases are not negligible. Therefore, we conclude that the undercoverage of \texttt{scpi} reported in Table \ref{tab:supp:Table3} is because of the non-diminishing bias. 


\begin{table}[!htp]
\renewcommand{\arraystretch}{1.05} \centering
\footnotesize
\setlength{\tabcolsep}{5pt} 
\begin{tabular}{|ccc|cccc|cccc|cccc|}
\hline
\multicolumn{3}{|c|}{Estimator} & \multicolumn{4}{c|}{SPSC} & \multicolumn{4}{c|}{SPSC-Ridge} & \multicolumn{4}{c|}{SCPI} \\ \hline
\multicolumn{1}{|c|}{\multirow{2}{*}{$ \ \delta \ $}} & \multicolumn{1}{c|}{\multirow{2}{*}{$\ d \ $}} & \multirow{2}{*}{Statistic} & \multicolumn{4}{c|}{$T_0$} & \multicolumn{4}{c|}{$T_0$} & \multicolumn{4}{c|}{$T_0$} \\ \cline{4-15} 
\multicolumn{1}{|c|}{} & \multicolumn{1}{c|}{} & & \multicolumn{1}{c|}{50} & \multicolumn{1}{c|}{100} & \multicolumn{1}{c|}{250} & 1000 & \multicolumn{1}{c|}{50} & \multicolumn{1}{c|}{100} & \multicolumn{1}{c|}{250} & 1000 & \multicolumn{1}{c|}{50} & \multicolumn{1}{c|}{100} & \multicolumn{1}{c|}{250} & 1000 \\ \hline


\multicolumn{1}{|c|}{\multirow{6}{*}{0}} & \multicolumn{1}{c|}{\multirow{2}{*}{2}} & Bias ($\times$10) & \multicolumn{1}{c|}{-0.527} & \multicolumn{1}{c|}{0.435} & \multicolumn{1}{c|}{-0.078} & \multicolumn{1}{c|}{-0.019} & \multicolumn{1}{c|}{-0.158} & \multicolumn{1}{c|}{0.648} & \multicolumn{1}{c|}{0.018} & \multicolumn{1}{c|}{0.023} & \multicolumn{1}{c|}{1.058} & \multicolumn{1}{c|}{1.046} & \multicolumn{1}{c|}{0.890} & \multicolumn{1}{c|}{0.982} \\ \cline{3-15}
\multicolumn{1}{|c|}{} & \multicolumn{1}{c|}{} & ESE ($\times$10) & \multicolumn{1}{c|}{8.576} & \multicolumn{1}{c|}{6.311} & \multicolumn{1}{c|}{3.843} & \multicolumn{1}{c|}{2.021} & \multicolumn{1}{c|}{8.525} & \multicolumn{1}{c|}{6.302} & \multicolumn{1}{c|}{3.843} & \multicolumn{1}{c|}{2.016} & \multicolumn{1}{c|}{3.116} & \multicolumn{1}{c|}{2.305} & \multicolumn{1}{c|}{1.431} & \multicolumn{1}{c|}{0.719} \\ \cline{2-15}
\multicolumn{1}{|c|}{} & \multicolumn{1}{c|}{\multirow{2}{*}{5}} & Bias ($\times$10) & \multicolumn{1}{c|}{-0.345} & \multicolumn{1}{c|}{-0.093} & \multicolumn{1}{c|}{0.528} & \multicolumn{1}{c|}{0.332} & \multicolumn{1}{c|}{-1.301} & \multicolumn{1}{c|}{-0.679} & \multicolumn{1}{c|}{0.026} & \multicolumn{1}{c|}{0.384} & \multicolumn{1}{c|}{0.361} & \multicolumn{1}{c|}{0.524} & \multicolumn{1}{c|}{0.763} & \multicolumn{1}{c|}{0.689} \\ \cline{3-15}
\multicolumn{1}{|c|}{} & \multicolumn{1}{c|}{} & ESE ($\times$10) & \multicolumn{1}{c|}{9.887} & \multicolumn{1}{c|}{7.479} & \multicolumn{1}{c|}{4.133} & \multicolumn{1}{c|}{1.954} & \multicolumn{1}{c|}{8.509} & \multicolumn{1}{c|}{6.570} & \multicolumn{1}{c|}{3.658} & \multicolumn{1}{c|}{1.845} & \multicolumn{1}{c|}{3.044} & \multicolumn{1}{c|}{2.089} & \multicolumn{1}{c|}{1.309} & \multicolumn{1}{c|}{0.642} \\ \cline{2-15}
\multicolumn{1}{|c|}{} & \multicolumn{1}{c|}{\multirow{2}{*}{9}} & Bias ($\times$10) & \multicolumn{1}{c|}{-0.923} & \multicolumn{1}{c|}{0.228} & \multicolumn{1}{c|}{-0.402} & \multicolumn{1}{c|}{-0.317} & \multicolumn{1}{c|}{-1.228} & \multicolumn{1}{c|}{-0.128} & \multicolumn{1}{c|}{-0.527} & \multicolumn{1}{c|}{-0.366} & \multicolumn{1}{c|}{0.676} & \multicolumn{1}{c|}{0.821} & \multicolumn{1}{c|}{0.776} & \multicolumn{1}{c|}{0.686} \\ \cline{3-15}
\multicolumn{1}{|c|}{} & \multicolumn{1}{c|}{} & ESE ($\times$10) & \multicolumn{1}{c|}{9.365} & \multicolumn{1}{c|}{6.819} & \multicolumn{1}{c|}{4.047} & \multicolumn{1}{c|}{1.965} & \multicolumn{1}{c|}{8.545} & \multicolumn{1}{c|}{6.305} & \multicolumn{1}{c|}{3.828} & \multicolumn{1}{c|}{1.831} & \multicolumn{1}{c|}{2.895} & \multicolumn{1}{c|}{1.925} & \multicolumn{1}{c|}{1.167} & \multicolumn{1}{c|}{0.599} \\ \hline \hline
\multicolumn{1}{|c|}{\multirow{6}{*}{1}} & \multicolumn{1}{c|}{\multirow{2}{*}{2}} & Bias ($\times$10) & \multicolumn{1}{c|}{-0.344} & \multicolumn{1}{c|}{-0.143} & \multicolumn{1}{c|}{0.038} & \multicolumn{1}{c|}{-0.000} & \multicolumn{1}{c|}{-0.184} & \multicolumn{1}{c|}{-0.073} & \multicolumn{1}{c|}{0.082} & \multicolumn{1}{c|}{0.018} & \multicolumn{1}{c|}{0.538} & \multicolumn{1}{c|}{0.377} & \multicolumn{1}{c|}{0.394} & \multicolumn{1}{c|}{0.479} \\ \cline{3-15}
\multicolumn{1}{|c|}{} & \multicolumn{1}{c|}{} & ESE ($\times$10) & \multicolumn{1}{c|}{8.649} & \multicolumn{1}{c|}{6.106} & \multicolumn{1}{c|}{3.989} & \multicolumn{1}{c|}{2.014} & \multicolumn{1}{c|}{8.615} & \multicolumn{1}{c|}{6.087} & \multicolumn{1}{c|}{3.984} & \multicolumn{1}{c|}{2.014} & \multicolumn{1}{c|}{3.046} & \multicolumn{1}{c|}{2.090} & \multicolumn{1}{c|}{1.458} & \multicolumn{1}{c|}{0.674} \\ \cline{2-15}
\multicolumn{1}{|c|}{} & \multicolumn{1}{c|}{\multirow{2}{*}{5}} & Bias ($\times$10) & \multicolumn{1}{c|}{-0.040} & \multicolumn{1}{c|}{-0.081} & \multicolumn{1}{c|}{0.251} & \multicolumn{1}{c|}{0.113} & \multicolumn{1}{c|}{-0.318} & \multicolumn{1}{c|}{-0.302} & \multicolumn{1}{c|}{0.058} & \multicolumn{1}{c|}{0.065} & \multicolumn{1}{c|}{0.336} & \multicolumn{1}{c|}{0.621} & \multicolumn{1}{c|}{0.593} & \multicolumn{1}{c|}{0.587} \\ \cline{3-15}
\multicolumn{1}{|c|}{} & \multicolumn{1}{c|}{} & ESE ($\times$10) & \multicolumn{1}{c|}{9.034} & \multicolumn{1}{c|}{6.635} & \multicolumn{1}{c|}{3.719} & \multicolumn{1}{c|}{1.778} & \multicolumn{1}{c|}{8.532} & \multicolumn{1}{c|}{6.377} & \multicolumn{1}{c|}{3.656} & \multicolumn{1}{c|}{1.739} & \multicolumn{1}{c|}{2.909} & \multicolumn{1}{c|}{2.064} & \multicolumn{1}{c|}{1.241} & \multicolumn{1}{c|}{0.628} \\ \cline{2-15}
\multicolumn{1}{|c|}{} & \multicolumn{1}{c|}{\multirow{2}{*}{9}} & Bias ($\times$10) & \multicolumn{1}{c|}{-1.083} & \multicolumn{1}{c|}{-0.953} & \multicolumn{1}{c|}{-0.647} & \multicolumn{1}{c|}{-0.126} & \multicolumn{1}{c|}{-1.113} & \multicolumn{1}{c|}{-1.088} & \multicolumn{1}{c|}{-0.862} & \multicolumn{1}{c|}{-0.462} & \multicolumn{1}{c|}{0.122} & \multicolumn{1}{c|}{0.226} & \multicolumn{1}{c|}{0.295} & \multicolumn{1}{c|}{0.358} \\ \cline{3-15}
\multicolumn{1}{|c|}{} & \multicolumn{1}{c|}{} & ESE ($\times$10) & \multicolumn{1}{c|}{9.964} & \multicolumn{1}{c|}{6.548} & \multicolumn{1}{c|}{3.895} & \multicolumn{1}{c|}{1.867} & \multicolumn{1}{c|}{9.185} & \multicolumn{1}{c|}{6.135} & \multicolumn{1}{c|}{3.781} & \multicolumn{1}{c|}{1.848} & \multicolumn{1}{c|}{2.744} & \multicolumn{1}{c|}{1.819} & \multicolumn{1}{c|}{1.237} & \multicolumn{1}{c|}{0.585} \\ \hline



\end{tabular}
\caption{Bias and Empirical Standard Errors of the Three ATT Estimators Obtained from Our Approach and the SCPI Approach Proposed by \citet{Cattaneo2021}. We remark that the results of the SPSC estimators are the same as those in Table \ref{tab:supp:Table00}.}
\label{tab:supp:Table5}
\vspace{-0.5cm}
\end{table}



\subsection{Simulation Studies under the Simulation Scenario Given in \citet{Cattaneo2021}} \label{sec:supp:Simulation PI}



For a fair comparison, we adopt a simulation scenario setup in \citet{Cattaneo2021}. In particular, we consider the following data generating process. First, we consider the length of the pre- and post-treatment periods as $T_0 = 100$ and $T_1=1$. Second, we choose the number of donors as $d = 10$, which are generated from the following AR(1) model:
\begin{align*}
&
W_{it} = \rho W_{i, t-1} + \eta_{it} 
\ , \
t=1,\ldots,T_0
\ , \ 
i=1,\ldots,d \ .
\end{align*}
Here, the autocorrelation coefficient $\rho$ is chosen from $\rho \in \{0,0.5,1\}$, $\eta$ are generated from the standard normal distribution and are independent and identically distributed, and the baseline value $W_{i0}$ is set to zero. For the post-treatment period, we consider the following model for donors:
\begin{align*}
& W_{1 , T_0+1} = \rho W_{1 T_0} + \eta_{1 , T_0+1} + \zeta \texttt{sd} ( W_{11},\ldots,W_{1 T_0} ) 
\\
&
W_{i , T_0+1} = \rho W_{i T_0} + \eta_{i , T_0+1} \ , \quad i=2,\ldots,d \ ,
\end{align*}
where $\zeta \in \{ -1,-0.5,0,0.5,1 \}$ parameterizes the degree of the shift in the first donor's post-treatment outcome. The treatment-free potential outcome of the treated unit is generated as follows:
\begin{align*}
\potY{t}{0} = 0.3 W_{1t} + 0.4 W_{2t} + 0.3 W_{3t} + 0.5 e_{t} \ , \ t=1,\ldots, T_0+T_1 \ ,
\end{align*}
where $e_t$ are independently generated from a standard normal distribution. We consider $\potY{t}{0} = \potY{t}{1}$, i.e., no treatment effect. We remark that the data generating process violates Assumption \ref{assumption:SC} because $\EXP \big\{ \potY{t}{0} - \big( 0.3 W_{1t} + 0.4 W_{2t} + 0.3 W_{3t} \big) \cond \potY{t}{0} \big\} \neq 0 $. Therefore, the proposed conformal inference approach for the SPSC framework in Section \ref{sec:Conformal} may fail in this data generating process. 

For our methods, we consider the SPSC estimators with ridge regularization. For function $\bg_t$, we consider the following two specifications: (i) time-invariant $\bg$ and (ii) time-varying $\bg_t$, which are given as follows:
\begin{align} \label{eq-compare-SCPI}
&
\bg(\potY{t}{0})
= 
\mathfrak{b}_{20}(\potY{t}{0}) 
\ , 
&&
\bg_t(\potY{t}{0})
=
\left\{
\begin{array}{ll}
\mathfrak{b}_{20}(\potY{t}{0}) 
&
\text{ if $\{Y_1,\ldots,Y_{T_0}\}$ is stationary}
\\[0.5cm]
\begin{bmatrix}
\mathfrak{b}_{20}(\potY{t}{0}) 
\\
\mathfrak{b}_{5}(t)
\end{bmatrix}
&
\text{ if $\{Y_1,\ldots,Y_{T_0}\}$ is not stationary}
\end{array}
\right.
\end{align}
Here, $\mathfrak{b}_{d}$ is chosen as the $d$-dimensional time-invariant cubic B-spline bases function. In order to check the stationarity of $Y_t$, we conduct Box-Pierce test \citep{BoxPierce1970} by using \texttt{Box.text} function implemented in the base R. If the p-value is less than 0.01, we conclude that $Y_t$ is nonstationary. Note that the dimension of $\mathfrak{b}_{5}(t)$ is chosen as the closest integer of $T_0^{1/3} = 100^{1/3} = 4.64$.

We repeat the simulation 500 times and calculate the empirical coverage rates of 95\% confidence intervals from these repetitions for each simulation scenario. The results are presented in Table \ref{tab:supp:Table10}, which exhibits somewhat opposite results compared to Table \ref{tab:supp:Table3}. More specifically, we find that the \texttt{scpi} approach achieves the nominal coverage rate across all simulation scenarios in general. However, we find that the conformal inference approach for the SPSC with time-invariant $\bg$ fails to achieve the nominal coverage rate, especially when the autocorrelation coefficient is large (i.e., $\rho=1$) and the first donor's post-treatment outcome is significantly different from its pre-treatment outcome (i.e., $\zeta=\pm 1$). We conjecture that the undercoverage observed in these cases may be attributed to the nonstationarity of $W_{it}$ and $\potY{t}{0}$. In these problematic cases, the conformal inference approach for the SPSC with time-varying $\bg_t$ appears to significantly improve the performance of our conformal inference approach. This confirms that the specification in Section \ref{sec:supp:time g function} is useful for improving the performance of the proposed conformal inference approach in the presence of nonstationarity. 



\begin{table}[!htp]
\renewcommand{\arraystretch}{1.1} \centering
\footnotesize
\setlength{\tabcolsep}{3pt} 
\hspace*{-0.5in}
\begin{tabular}{|cc|ccccc|ccccc|ccccc|}
\hline
\multicolumn{2}{|c|}{$\rho$} & \multicolumn{5}{c|}{0} & \multicolumn{5}{c|}{0.5} & \multicolumn{5}{c|}{1} \\ \hline
 \multicolumn{2}{|c|}{$\zeta$} & \multicolumn{1}{c|}{-1} & \multicolumn{1}{c|}{-0.5} & \multicolumn{1}{c|}{0} & \multicolumn{1}{c|}{0.5} & 1 & \multicolumn{1}{c|}{-1} & \multicolumn{1}{c|}{-0.5} & \multicolumn{1}{c|}{0} & \multicolumn{1}{c|}{0.5} & 1 & \multicolumn{1}{c|}{-1} & \multicolumn{1}{c|}{-0.5} & \multicolumn{1}{c|}{0} & \multicolumn{1}{c|}{0.5} & 1 \\ \hline
 \multicolumn{1}{|c|}{\multirow{2}{*}{SPSC-Ridge}} & Time-invariant $\bg$ & \multicolumn{1}{c|}{0.942} & \multicolumn{1}{c|}{0.946} & \multicolumn{1}{c|}{0.946} & \multicolumn{1}{c|}{0.944} & \multicolumn{1}{c|}{0.934} & \multicolumn{1}{c|}{0.920} & \multicolumn{1}{c|}{0.942} & \multicolumn{1}{c|}{0.956} & \multicolumn{1}{c|}{0.956} & \multicolumn{1}{c|}{0.946} & \multicolumn{1}{c|}{0.808} & \multicolumn{1}{c|}{0.852} & \multicolumn{1}{c|}{0.858} & \multicolumn{1}{c|}{0.856} & 0.824 \\ \cline{2-17}
 \multicolumn{1}{|c|}{} & Time-varying $\bg_t$ & \multicolumn{1}{c|}{0.942} & \multicolumn{1}{c|}{0.946} & \multicolumn{1}{c|}{0.946} & \multicolumn{1}{c|}{0.944} & \multicolumn{1}{c|}{0.934} & \multicolumn{1}{c|}{0.946} & \multicolumn{1}{c|}{0.954} & \multicolumn{1}{c|}{0.960} & \multicolumn{1}{c|}{0.958} & \multicolumn{1}{c|}{0.952} & \multicolumn{1}{c|}{0.914} & \multicolumn{1}{c|}{0.932} & \multicolumn{1}{c|}{0.942} & \multicolumn{1}{c|}{0.952} & 0.948 \\ \hline
 \multicolumn{2}{|c|}{SCPI} & \multicolumn{1}{c|}{0.974} & \multicolumn{1}{c|}{0.976} & \multicolumn{1}{c|}{0.974} & \multicolumn{1}{c|}{0.976} & \multicolumn{1}{c|}{0.978} & \multicolumn{1}{c|}{0.974} & \multicolumn{1}{c|}{0.970} & \multicolumn{1}{c|}{0.970} & \multicolumn{1}{c|}{0.978} & \multicolumn{1}{c|}{0.980} & \multicolumn{1}{c|}{0.984} & \multicolumn{1}{c|}{0.980} & \multicolumn{1}{c|}{0.978} & \multicolumn{1}{c|}{0.982} & 0.988 \\ \hline
\end{tabular}
\caption{Empirical Coverage Rates of 95\% Pointwise Prediction Intervals. 
The numbers in SPSC-Ridge columns show the results of the conformal inference approach in Section \ref{sec:Conformal}. 
Time-invariant $\bg$ and time-varying $\bg_t$ are chosen from \eqref{eq-compare-SCPI}.
The numbers in SCPI column show the results from the approach proposed by \citet{Cattaneo2021} which is implemented in \texttt{scpi} R-package \citep{scpiPackage2023}.}
\label{tab:supp:Table10}
\vspace*{-0.3cm}
\end{table}



% \begin{table}[!htp]
% \renewcommand{\arraystretch}{1.05} \centering
% \footnotesize
% \setlength{\tabcolsep}{5pt} 
% \hspace*{-0.25in}
% \begin{tabular}{|cc|ccc|ccc|ccc|ccc|}
% \hline
% \multicolumn{2}{|c|}{Estimator} & \multicolumn{3}{c|}{SPSC} & \multicolumn{3}{c|}{SPSC-Ridge} & \multicolumn{3}{c|}{SPSC-Ridge-Modified} & \multicolumn{3}{c|}{SCPI} \\ \hline
% \multicolumn{2}{|c|}{$\rho$} & \multicolumn{1}{c|}{0} & \multicolumn{1}{c|}{0.5} & 1 & \multicolumn{1}{c|}{0} & \multicolumn{1}{c|}{0.5} & 1 & \multicolumn{1}{c|}{0} & \multicolumn{1}{c|}{0.5} & 1 & \multicolumn{1}{c|}{0} & \multicolumn{1}{c|}{0.5} & 1 \\ \hline

% \multicolumn{1}{|c|}{\multirow{5}{*}{$\zeta$}} & -1 & \multicolumn{1}{c|}{0.888} & \multicolumn{1}{c|}{0.898} & \multicolumn{1}{c|}{0.794} & \multicolumn{1}{c|}{0.942} & \multicolumn{1}{c|}{0.920} & \multicolumn{1}{c|}{0.808} & \multicolumn{1}{c|}{0.920} & \multicolumn{1}{c|}{0.932} & \multicolumn{1}{c|}{0.906} & \multicolumn{1}{c|}{0.974} & \multicolumn{1}{c|}{0.974} & \multicolumn{1}{c|}{0.984} \\ \cline{2-14}
% \multicolumn{1}{|c|}{} & -0.5 & \multicolumn{1}{c|}{0.892} & \multicolumn{1}{c|}{0.906} & \multicolumn{1}{c|}{0.830} & \multicolumn{1}{c|}{0.946} & \multicolumn{1}{c|}{0.942} & \multicolumn{1}{c|}{0.852} & \multicolumn{1}{c|}{0.932} & \multicolumn{1}{c|}{0.946} & \multicolumn{1}{c|}{0.924} & \multicolumn{1}{c|}{0.976} & \multicolumn{1}{c|}{0.970} & \multicolumn{1}{c|}{0.980} \\ \cline{2-14}
% \multicolumn{1}{|c|}{} & 0 & \multicolumn{1}{c|}{0.886} & \multicolumn{1}{c|}{0.904} & \multicolumn{1}{c|}{0.832} & \multicolumn{1}{c|}{0.946} & \multicolumn{1}{c|}{0.956} & \multicolumn{1}{c|}{0.858} & \multicolumn{1}{c|}{0.938} & \multicolumn{1}{c|}{0.960} & \multicolumn{1}{c|}{0.928} & \multicolumn{1}{c|}{0.974} & \multicolumn{1}{c|}{0.970} & \multicolumn{1}{c|}{0.978} \\ \cline{2-14}
% \multicolumn{1}{|c|}{} & 0.5 & \multicolumn{1}{c|}{0.886} & \multicolumn{1}{c|}{0.916} & \multicolumn{1}{c|}{0.810} & \multicolumn{1}{c|}{0.944} & \multicolumn{1}{c|}{0.956} & \multicolumn{1}{c|}{0.856} & \multicolumn{1}{c|}{0.940} & \multicolumn{1}{c|}{0.952} & \multicolumn{1}{c|}{0.936} & \multicolumn{1}{c|}{0.976} & \multicolumn{1}{c|}{0.978} & \multicolumn{1}{c|}{0.982} \\ \cline{2-14}
% \multicolumn{1}{|c|}{} & 1 & \multicolumn{1}{c|}{0.868} & \multicolumn{1}{c|}{0.908} & \multicolumn{1}{c|}{0.788} & \multicolumn{1}{c|}{0.934} & \multicolumn{1}{c|}{0.946} & \multicolumn{1}{c|}{0.824} & \multicolumn{1}{c|}{0.928} & \multicolumn{1}{c|}{0.946} & \multicolumn{1}{c|}{0.934} & \multicolumn{1}{c|}{0.978} & \multicolumn{1}{c|}{0.980} & \multicolumn{1}{c|}{0.988} \\ \hline


% \end{tabular}
% \caption{Empirical Coverage Rates of 95\% Pointwise Prediction Intervals. 
% The numbers in SPSC and SPSC-Ridge columns show the results of the conformal inference approach in Section \ref{sec:Conformal}. 
% The numbers in SPSC-Ridge-Modified column show the results of the conformal inference approach in Section \ref{sec:Conformal} where the donor pool is chosen by following the approach in Section \ref{sec:supp:Donors} and the coefficient function $\bg_t$ is specified as \eqref{eq-compare-SCPI}. 
% The numbers in SCPI column show the results from the approach proposed by \citet{Cattaneo2021} which is implemented in \texttt{scpi} R-package \citep{scpiPackage2023}.}
% \label{tab:supp:Table10}
% \vspace*{-0.5cm}
% \end{table}

Next, we calculate the average length of the 95\% prediction interval for $t=T_0+1$, i.e., the first post-treatment period, across 500 repetitions. 
Table \ref{tab:supp:Table11} shows the average lengths.
We find that the prediction intervals obtained from \texttt{scpi} are generally narrower than those obtained from the SPSC, except for the cases where $\rho=1$ and $\zeta=\pm1$. 

\begin{table}[!htp]
\renewcommand{\arraystretch}{1.1} \centering
\footnotesize
\setlength{\tabcolsep}{3pt} 
\hspace*{-0.5in}
\begin{tabular}{|cc|ccccc|ccccc|ccccc|}
\hline
\multicolumn{2}{|c|}{$\rho$} & \multicolumn{5}{c|}{0} & \multicolumn{5}{c|}{0.5} & \multicolumn{5}{c|}{1} \\ \hline
 \multicolumn{2}{|c|}{$\zeta$} & \multicolumn{1}{c|}{-1} & \multicolumn{1}{c|}{-0.5} & \multicolumn{1}{c|}{0} & \multicolumn{1}{c|}{0.5} & 1 & \multicolumn{1}{c|}{-1} & \multicolumn{1}{c|}{-0.5} & \multicolumn{1}{c|}{0} & \multicolumn{1}{c|}{0.5} & 1 & \multicolumn{1}{c|}{-1} & \multicolumn{1}{c|}{-0.5} & \multicolumn{1}{c|}{0} & \multicolumn{1}{c|}{0.5} & 1 \\ \hline
 \multicolumn{1}{|c|}{\multirow{2}{*}{SPSC-Ridge}} & Time-invariant $\bg$ & \multicolumn{1}{c|}{3.018} & \multicolumn{1}{c|}{3.035} & \multicolumn{1}{c|}{3.040} & \multicolumn{1}{c|}{3.046} & \multicolumn{1}{c|}{3.052} & \multicolumn{1}{c|}{2.963} & \multicolumn{1}{c|}{2.967} & \multicolumn{1}{c|}{2.970} & \multicolumn{1}{c|}{2.991} & \multicolumn{1}{c|}{2.971} & \multicolumn{1}{c|}{3.262} & \multicolumn{1}{c|}{3.288} & \multicolumn{1}{c|}{3.272} & \multicolumn{1}{c|}{3.285} & 3.281 \\ \cline{2-17}
 \multicolumn{1}{|c|}{} & Time-varying $\bg_t$ & \multicolumn{1}{c|}{3.018} & \multicolumn{1}{c|}{3.035} & \multicolumn{1}{c|}{3.039} & \multicolumn{1}{c|}{3.045} & \multicolumn{1}{c|}{3.052} & \multicolumn{1}{c|}{2.904} & \multicolumn{1}{c|}{2.903} & \multicolumn{1}{c|}{2.902} & \multicolumn{1}{c|}{2.921} & \multicolumn{1}{c|}{2.931} & \multicolumn{1}{c|}{2.926} & \multicolumn{1}{c|}{2.900} & \multicolumn{1}{c|}{2.904} & \multicolumn{1}{c|}{2.931} & 2.979 \\ \hline
 \multicolumn{2}{|c|}{SCPI} & \multicolumn{1}{c|}{2.657} & \multicolumn{1}{c|}{2.596} & \multicolumn{1}{c|}{2.576} & \multicolumn{1}{c|}{2.597} & \multicolumn{1}{c|}{2.658} & \multicolumn{1}{c|}{2.654} & \multicolumn{1}{c|}{2.593} & \multicolumn{1}{c|}{2.574} & \multicolumn{1}{c|}{2.598} & \multicolumn{1}{c|}{2.662} & \multicolumn{1}{c|}{3.154} & \multicolumn{1}{c|}{3.024} & \multicolumn{1}{c|}{2.985} & \multicolumn{1}{c|}{3.035} & 3.165 \\ \hline
\end{tabular}
\caption{Average Lengths of 95\% Pointwise Prediction Intervals at $t=T_0+1$. Each column has the same specification as in Table \ref{tab:supp:Table10}.
}
\label{tab:supp:Table11}
\vspace*{-0.3cm}
\end{table}


Lastly, we report the bias and the empirical standard error of the estimators for the ATT obtained from \texttt{scpi}. Specifically, the estimator is obtained as $\widehat{\tau}_{\text{ATT}}
=
Y_t - \widehat{Y}_{t}^{(0)}$ where $\widehat{Y}_{t}^{(0)} $ is a predicted value of the treatment-free potential outcome at time $t=T_0+1$. Comparing the estimator derived from \texttt{scpi} to the SPSC estimator, we observe that the latter leads to larger biases. Nevertheless, when considering the empirical standard errors, these biases become negligible. As a result, we deduce that the ATT estimator from the SPSC approach exhibits a negligible bias, whereas the conformal inference approach can be anticonservative in the presence of nonstationarity.

\begin{table}[!htp]
\renewcommand{\arraystretch}{1.05} \centering
\footnotesize
\setlength{\tabcolsep}{3pt} 
\hspace*{-0.5in}
\begin{tabular}{|cc|ccccc|ccccc|ccccc|}
\hline
\multicolumn{2}{|c|}{$\rho$} & \multicolumn{5}{c|}{0} & \multicolumn{5}{c|}{0.5} & \multicolumn{5}{c|}{1} \\ \hline
 \multicolumn{2}{|c|}{$\zeta$} & \multicolumn{1}{c|}{-1} & \multicolumn{1}{c|}{-0.5} & \multicolumn{1}{c|}{0} & \multicolumn{1}{c|}{0.5} & 1 & \multicolumn{1}{c|}{-1} & \multicolumn{1}{c|}{-0.5} & \multicolumn{1}{c|}{0} & \multicolumn{1}{c|}{0.5} & 1 & \multicolumn{1}{c|}{-1} & \multicolumn{1}{c|}{-0.5} & \multicolumn{1}{c|}{0} & \multicolumn{1}{c|}{0.5} & 1 \\ \hline
 \multicolumn{1}{|c|}{\multirow{2}{*}{SPSC-Ridge}} & Time-invariant $\bg$ & \multicolumn{1}{c|}{-0.030} & \multicolumn{1}{c|}{-0.034} & \multicolumn{1}{c|}{-0.038} & \multicolumn{1}{c|}{-0.041} & \multicolumn{1}{c|}{-0.045} & \multicolumn{1}{c|}{-0.084} & \multicolumn{1}{c|}{-0.085} & \multicolumn{1}{c|}{-0.085} & \multicolumn{1}{c|}{-0.086} & \multicolumn{1}{c|}{-0.086} & \multicolumn{1}{c|}{-0.181} & \multicolumn{1}{c|}{-0.102} & \multicolumn{1}{c|}{-0.023} & \multicolumn{1}{c|}{0.055} & 0.134 \\ \cline{2-17}
 \multicolumn{1}{|c|}{} & Time-varying $\bg_t$ & \multicolumn{1}{c|}{-0.030} & \multicolumn{1}{c|}{-0.034} & \multicolumn{1}{c|}{-0.038} & \multicolumn{1}{c|}{-0.042} & \multicolumn{1}{c|}{-0.046} & \multicolumn{1}{c|}{-0.086} & \multicolumn{1}{c|}{-0.082} & \multicolumn{1}{c|}{-0.078} & \multicolumn{1}{c|}{-0.075} & \multicolumn{1}{c|}{-0.071} & \multicolumn{1}{c|}{-0.158} & \multicolumn{1}{c|}{-0.098} & \multicolumn{1}{c|}{-0.039} & \multicolumn{1}{c|}{0.021} & 0.080 \\ \hline
 \multicolumn{2}{|c|}{SCPI} & \multicolumn{1}{c|}{-0.063} & \multicolumn{1}{c|}{-0.051} & \multicolumn{1}{c|}{-0.038} & \multicolumn{1}{c|}{-0.025} & \multicolumn{1}{c|}{-0.013} & \multicolumn{1}{c|}{-0.062} & \multicolumn{1}{c|}{-0.048} & \multicolumn{1}{c|}{-0.035} & \multicolumn{1}{c|}{-0.021} & \multicolumn{1}{c|}{-0.008} & \multicolumn{1}{c|}{-0.068} & \multicolumn{1}{c|}{-0.048} & \multicolumn{1}{c|}{-0.028} & \multicolumn{1}{c|}{-0.008} & 0.012 \\ \hline
\end{tabular}\\
\vspace*{0.5cm}
\hspace*{-0.5in}
\begin{tabular}{|cc|ccccc|ccccc|ccccc|}
\hline
\multicolumn{2}{|c|}{$\rho$} & \multicolumn{5}{c|}{0} & \multicolumn{5}{c|}{0.5} & \multicolumn{5}{c|}{1} \\ \hline
 \multicolumn{2}{|c|}{$\zeta$} & \multicolumn{1}{c|}{-1} & \multicolumn{1}{c|}{-0.5} & \multicolumn{1}{c|}{0} & \multicolumn{1}{c|}{0.5} & 1 & \multicolumn{1}{c|}{-1} & \multicolumn{1}{c|}{-0.5} & \multicolumn{1}{c|}{0} & \multicolumn{1}{c|}{0.5} & 1 & \multicolumn{1}{c|}{-1} & \multicolumn{1}{c|}{-0.5} & \multicolumn{1}{c|}{0} & \multicolumn{1}{c|}{0.5} & 1 \\ \hline
 \multicolumn{1}{|c|}{\multirow{2}{*}{SPSC-Ridge}} & Time-invariant $\bg$ & \multicolumn{1}{c|}{0.774} & \multicolumn{1}{c|}{0.753} & \multicolumn{1}{c|}{0.748} & \multicolumn{1}{c|}{0.760} & \multicolumn{1}{c|}{0.789} & \multicolumn{1}{c|}{0.789} & \multicolumn{1}{c|}{0.765} & \multicolumn{1}{c|}{0.754} & \multicolumn{1}{c|}{0.757} & \multicolumn{1}{c|}{0.774} & \multicolumn{1}{c|}{1.152} & \multicolumn{1}{c|}{1.070} & \multicolumn{1}{c|}{1.037} & \multicolumn{1}{c|}{1.057} & 1.127 \\ \cline{2-17}
 \multicolumn{1}{|c|}{} & Time-varying $\bg_t$ & \multicolumn{1}{c|}{0.774} & \multicolumn{1}{c|}{0.753} & \multicolumn{1}{c|}{0.748} & \multicolumn{1}{c|}{0.760} & \multicolumn{1}{c|}{0.789} & \multicolumn{1}{c|}{0.756} & \multicolumn{1}{c|}{0.736} & \multicolumn{1}{c|}{0.728} & \multicolumn{1}{c|}{0.733} & \multicolumn{1}{c|}{0.752} & \multicolumn{1}{c|}{0.852} & \multicolumn{1}{c|}{0.786} & \multicolumn{1}{c|}{0.761} & \multicolumn{1}{c|}{0.780} & 0.840 \\ \hline
 \multicolumn{2}{|c|}{SCPI} & \multicolumn{1}{c|}{0.516} & \multicolumn{1}{c|}{0.512} & \multicolumn{1}{c|}{0.510} & \multicolumn{1}{c|}{0.509} & \multicolumn{1}{c|}{0.509} & \multicolumn{1}{c|}{0.517} & \multicolumn{1}{c|}{0.514} & \multicolumn{1}{c|}{0.512} & \multicolumn{1}{c|}{0.510} & \multicolumn{1}{c|}{0.510} & \multicolumn{1}{c|}{0.536} & \multicolumn{1}{c|}{0.533} & \multicolumn{1}{c|}{0.533} & \multicolumn{1}{c|}{0.535} & 0.540 \\ \hline
\end{tabular}

\caption{Biases (top table) and Empirical Standard Errors (bottom table) of the Three ATT Estimators Obtained from Our Approach and the SCPI Approach proposed by \citet{Cattaneo2021}. We remark that the results of the SPSC estimators are the same as those in Table \ref{tab:supp:Table00}.}
\label{tab:supp:Table12}
\vspace*{-0.3cm}
\end{table}



\subsection{Additional Results of the Data Analysis}		\label{sec:supp:Data}

In this Section, we provide additional results of the data analysis in Section \ref{sec:Data}. 
First, we provide details on how to choose the donor pool. 
As we briefly mentioned in the data analysis section, some donor candidates had severely different stock price values. In the most severe cases, the ranges of the pre- and post-treatment periods of the stock prices do not overlap. As a criterion for choosing the donor pools, we use the following overlap metric:
\begin{align*}
\text{Overlap}_{k}
=
\frac{1}{T_1} \sum_{t=T_0+1}^{T} \ind \Big\{ W_{kt} \in \text{range} \big( W_{k1},\ldots,W_{kT_0} \big) \Big\} \ , 
\ k=1,\ldots, 49 \ .
\end{align*}
Based on the overlap, we define the four groups of roughly equal size. Specifically, Group 1, 2, and 4 has 12 donors and Group 3 has 13 donors, respectively; see Figure \ref{fig:Sim:Group}. 
% Figure environment removed		

In addition to the four groups based on the overlap metric, we choose the donors based on lasso regularization \citep{Lasso1996}. Specifically, we solve the following GMM with $\ell_1$ regularization:	 
\begin{align*}
\widehat{\bgamma}_{\lambda}
& =
\argmin_{\bgamma}
\Big[
\big\{ 
\widehat{\Psi}_{\pre} ( \bgamma ) 
\big\} \T
\big\{ 
\widehat{\Psi}_{\pre} ( \bgamma ) 
\big\}
+
\lambda \big\| \bgamma \big\|_{1} 
\Big]
\\
& =
\argmin_{\bgamma}
\Big[
\big\| 
\widehat{\bG}_{YY }
-
\widehat{\bG}_{YW }\T 
\bgamma
\big\|_2^2
+
\lambda \big\| \bgamma \big\|_{1} 
\Big] 
\ ,
\end{align*}
where $\widehat{\bG}_{YW }$ and $\widehat{\bG}_{YY}$ are defined in \eqref{eq-Gyw Gyy}. The regularization parameter is chosen from cross-validation. We remark that the number of non-zero $\widehat{\bgamma}_{\lambda}$ depends on the dimension of $\bg_t( \potY{t}{0})$. Therefore, we vary the dimension of $\bg_t$ across a range from 2 to 98, which spans twice the number of donors. Nonetheless, as in Figure \ref{fig:Sim:Lasso}, we find the number of selected donors does not vary a lot across the dimension of $\bg_t( \potY{t}{0})$. In particular, five donors are selected when $\text{dim}(\bg_t)=10$, in alignment with the relationship $\text{dim}(\bg_t) = 2d$ specified in the simulation studies. Therefore, we define these five donors as Group 5.

% Figure environment removed		

Lastly, we follow the approach in Section \ref{sec:supp:Donors}, which yields 24 donors. We refer to this donor pool as Group 6. Of note, this group is reported in the main paper. 

For the coefficient function $\bg_t$, we consider the following two specifications $\bg_t$-(i) and $\bg_t$-(ii):
\begin{itemize}[leftmargin=0.5cm, itemsep=0cm]
\item[(i)] (\textit{Time-invariant $\bg$}) Following the approach in the main paper, we define $\bg(\potY{t}{0})$ as a time-invariant function as follows:
\begin{align*}
\bg (\potY{t}{0})
= 
\mathfrak{b}_{\ell}(\potY{t}{0})  
\ , \quad 
\ell \in \{ 24, 24, 24, 24, 10, 48 \} \text{ for Groups 1--6}
\end{align*}
where $\mathfrak{b}_{\ell}$ is the $\ell$-dimensional cubic B-spline bases function. In other words, for Groups 1--4, we define $\bg$ as the 24-dimensional cubic B-spline bases function. For Group 5, we define $\bg$ as the 10-dimensional cubic B-spline bases function. Lastly, for Group 6, we define $\bg$ as the 48-dimensional cubic B-spline bases function. 

\item[(ii)] (\textit{Time-varying $\bg_t$}) Next, we consider time-varying $\bg_t(\potY{t}{0})$ by following the specification in Section \ref{sec:supp:time g function}. In particular, we define
\begin{align*}
\bg_t(\potY{t}{0})
=
\begin{bmatrix}
\mathfrak{b}_{\ell}(\potY{t}{0})  
\\
\mathfrak{b}_{6}(t)
\end{bmatrix}
\ , \quad 
\ell \in \{ 24, 24, 24, 24, 10, 48 \} \text{ for Groups 1--6}
\end{align*}
where $\mathfrak{b}_{6}(t)$ is the 6-dimensional cubic B-spline bases function where the dimension is obtained by choosing the closest integer of $T_0^{1/3} = 217^{1/3} = 6.01$.
\end{itemize}



Using these six choices for the donor pool and the two choices for $\bg_t$, we focus on the estimation of the ATT. Table \ref{tab:supp:ATT} summarizes the result. We find that the results are similar to each other. In terms of the length of the 95\% confidence intervals, the SPSC with ridge regularization results in the narrowest confidence intervals in general, except for Group 2 with time-invariayt $\bg$. These additional analyses for the ATT corroborate the results in Table \ref{tab:data:ATT} of the main paper.

\begin{table}[!htp]
\renewcommand{\arraystretch}{1.3} \centering
\scriptsize
\setlength{\tabcolsep}{3pt} 
\hspace*{-0.8cm}
\begin{tabular}{|c|c|c|c|c|c|c|c|}
\hline
\multirow{2}{*}{Donor Pool} & \multirow{2}{*}{Statistic} & \multicolumn{3}{c|}{Time-invariant $\bg$} & \multicolumn{3}{c|}{Time-varying $\bg_t$} \\ \cline{3-8} 
& & \multicolumn{1}{c|}{OLS} & \multicolumn{1}{c|}{SPSC} & SPSC-Ridge & \multicolumn{1}{c|}{OLS} & \multicolumn{1}{c|}{SPSC} & SPSC-Ridge \\ \hline
 \multicolumn{1}{|c|}{\multirow{3}{*}{Group 1 (12)}} & Estimate & $-0.906$ & $-0.855$ & $-0.855$ & $-0.847$ & $-0.883$ & $-0.850$ \\ \cline{2-8}
 \multicolumn{1}{|c|}{} & ASE & $0.101$ & $0.115$ & $0.100$ & $0.117$ & $0.124$ & $0.094$ \\ \cline{2-8}
 \multicolumn{1}{|c|}{} & 95\% CI & $(-1.103, -0.709)$ & $(-1.081, -0.629)$ & $(-1.051, -0.660)$ & $(-1.076, -0.618)$ & $(-1.127, -0.639)$ & $(-1.034, -0.666)$ \\ \hline
 \multicolumn{1}{|c|}{\multirow{3}{*}{Group 2 (12)}} & Estimate & $-0.840$ & $-0.787$ & $-0.887$ & $-0.897$ & $-0.790$ & $-0.892$ \\ \cline{2-8}
 \multicolumn{1}{|c|}{} & ASE & $0.089$ & $0.104$ & $0.098$ & $0.132$ & $0.107$ & $0.097$ \\ \cline{2-8}
 \multicolumn{1}{|c|}{} & 95\% CI & $(-1.014, -0.667)$ & $(-0.991, -0.583)$ & $(-1.079, -0.696)$ & $(-1.156, -0.638)$ & $(-0.999, -0.580)$ & $(-1.082, -0.703)$ \\ \hline
 \multicolumn{1}{|c|}{\multirow{3}{*}{Group 3 (13)}} & Estimate & $-0.875$ & $-0.520$ & $-0.798$ & $-0.797$ & $-0.614$ & $-0.798$ \\ \cline{2-8}
 \multicolumn{1}{|c|}{} & ASE & $0.154$ & $0.235$ & $0.084$ & $0.184$ & $0.212$ & $0.084$ \\ \cline{2-8}
 \multicolumn{1}{|c|}{} & 95\% CI & $(-1.177, -0.574)$ & $(-0.982, -0.059)$ & $(-0.963, -0.633)$ & $(-1.158, -0.437)$ & $(-1.030, -0.198)$ & $(-0.963, -0.633)$ \\ \hline
 \multicolumn{1}{|c|}{\multirow{3}{*}{Group 4 (12)}} & Estimate & $-0.922$ & $-0.852$ & $-0.713$ & $-0.708$ & $-0.879$ & $-0.710$ \\ \cline{2-8}
 \multicolumn{1}{|c|}{} & ASE & $0.095$ & $0.138$ & $0.072$ & $0.259$ & $0.137$ & $0.073$ \\ \cline{2-8}
 \multicolumn{1}{|c|}{} & 95\% CI & $(-1.109, -0.735)$ & $(-1.122, -0.581)$ & $(-0.854, -0.571)$ & $(-1.216, -0.200)$ & $(-1.147, -0.610)$ & $(-0.854, -0.567)$ \\ \hline
 \multicolumn{1}{|c|}{\multirow{3}{*}{Group 5 (5)}} & Estimate & $-0.852$ & $-0.887$ & $-0.886$ & $-0.816$ & $-0.868$ & $-0.635$ \\ \cline{2-8}
 \multicolumn{1}{|c|}{} & ASE & $0.120$ & $0.111$ & $0.107$ & $0.102$ & $0.106$ & $0.080$ \\ \cline{2-8}
 \multicolumn{1}{|c|}{} & 95\% CI & $(-1.087, -0.616)$ & $(-1.105, -0.669)$ & $(-1.096, -0.677)$ & $(-1.016, -0.615)$ & $(-1.077, -0.660)$ & $(-0.791, -0.479)$ \\ \hline
 \multicolumn{1}{|c|}{\multirow{3}{*}{Group 6 (24)}} & Estimate & $-0.966$ & $-0.975$ & $-0.830$ & $-0.822$ & $-0.910$ & $-0.797$ \\ \cline{2-8}
 \multicolumn{1}{|c|}{} & ASE & $0.108$ & $0.101$ & $0.098$ & $0.134$ & $0.096$ & $0.086$ \\ \cline{2-8}
 \multicolumn{1}{|c|}{} & 95\% CI & $(-1.177, -0.755)$ & $(-1.172, -0.777)$ & $(-1.022, -0.638)$ & $(-1.084, -0.560)$ & $(-1.098, -0.722)$ & $(-0.965, -0.628)$ \\ \hline
\end{tabular}
\caption{Bias and Asymptotic Standard Errors of the Three ATT Estimators under time-invariant $\bg$ and time-varying $\bg_t$. 
The numbers in the parentheses show the number of donors in each group. We remark that the results of Group 6 under $\bg_t(\potY{t}{0})$ are the same as those in Table \ref{tab:data:ATT} of the main paper.}
\label{tab:supp:ATT}
\end{table}

Next, we conduct the conformal inference on the SPSC with ridge regularization. Following the main paper, we compare the proposed approach to the recent work by \citet{Cattaneo2021}. Of note, we increased \texttt{sims} parameter in \texttt{scpi} function from its default value of 200 to 2000. This adjustment was made to reduce variability in the results. Figure \ref{fig:supp:Conformal} visually summarizes the predicted treatment-free outcome $\widehat{Y}_{t}^{(0)}$ and the 95\% prediction intervals for all five donor pool groups. In general, two approaches produce similar $\widehat{Y}_{t}^{(0)}$ in terms of the shape. However, we find the average width of the prediction intervals over the post-treatment periods are significantly different, which is summarized in Table \ref{tab:supp:PIwidth}. Except for Groups 2 and 4, our approach produces narrower prediction intervals compared to the approach by \citet{Cattaneo2021}. These additional results from the conformal inference approaches certify the results in the main paper are robust to the choice of the donor pool.


\begin{table}[!htp]
\renewcommand{\arraystretch}{1.05} \centering
\footnotesize
\setlength{\tabcolsep}{5pt} 
\begin{tabular}{|cc|c|c|c|c|c|c|}
\hline
\multicolumn{2}{|c|}{Donor Pool}                                           & Group 1 (12) & Group 2 (12) & Group 3 (13) & Group 4 (12) & Group 5 (5) & Group 6 (24) \\ \hline
\multicolumn{2}{|c|}{SCPI}                                                 & 0.197        & 0.104        & 0.410        & 0.178        & 0.430       & 0.108        \\ \hline
\multicolumn{1}{|c|}{\multirow{2}{*}{SPSC-Ridge}} & Time-invariant $\bg$ & 0.054        & 0.108        & 0.149        & 0.205        & 0.119       & 0.046         \\ \cline{2-8} 
\multicolumn{1}{|c|}{}                            & Time-varying $\bg_t$   & 0.067        & 0.104        & 0.148        & 0.208        & 0.249       & 0.072         \\ \hline
\end{tabular}
\caption{Average Width of the 95\% Prediction Intervals over the Post-treatment Periods. The numbers in the parentheses show the number of donors in each group. The numbers in SCPI row show the average length of 95\% pointwise prediction intervals obtained from the approach proposed by \citet{Cattaneo2021} which is implemented in \texttt{scpi} R-package \citep{scpiPackage2023}. 
The numbers in SPSC-Ridge rows show the average length of 95\% pointwise prediction intervals obtained from the conformal inference approach in Section \ref{sec:Conformal} where $\bg_t$ is either time-invariant or time-varying. 
We remark that the results of Group 6 are the same as those in Figure \ref{fig:data:1} of the main paper.}
\label{tab:supp:PIwidth}

\end{table}



% Figure environment removed

\newpage

% Figure environment removed	


Lastly, we provide the details of the placebo study. Table \ref{tab:supp:ATT Placebo} shows the numerical summary of the analysis. We find that both placebo ATT estimators obtained from SPSC with and without ridge regularization suggest no effect across all donor specifications. Figure \ref{fig:supp:Conformal Placebo} visually shows the synthetic controls under the placebo treatment. Except for Group 1, we find 95\% prediction intervals for $\potY{t}{0}$ include the true treatment-free potential outcome $\potY{t}{0}$. These results suggest that our SPSC approach seems reasonable for analyzing the effect of the 1907 panic on the stock price of the two trust companies.

Based on these additional analyses, we can further strengthen the causal conclusions established in the main paper, i.e., the 1907 panic led to a decrease in the average log stock price of Knickerbocker and Trust Company of America. 


\newpage


\begin{table}[!htp]
\renewcommand{\arraystretch}{1.3} \centering
\scriptsize
\setlength{\tabcolsep}{3pt} 
\begin{tabular}{|c|c|c|c|c|}
\hline
\multirow{2}{*}{Donor Pool} & \multirow{2}{*}{Statistic} & \multicolumn{3}{c|}{Estimator} \\ \cline{3-5} 
& & \multicolumn{1}{c|}{OLS} & \multicolumn{1}{c|}{SPSC} & SPSC-Ridge \\ \hline


\multicolumn{1}{|c|}{\multirow{3}{*}{Group 1 (12)}} & Estimate & $-0.058$ & $-0.088$ & $-0.016$ \\ \cline{2-5}
\multicolumn{1}{|c|}{} & ASE & $0.025$ & $0.049$ & $0.013$ \\ \cline{2-5}
\multicolumn{1}{|c|}{} & 95\% CI & $(-0.107, -0.010)$ & $(-0.184, 0.009)$ & $(-0.042, 0.009)$ \\ \hline
\multicolumn{1}{|c|}{\multirow{3}{*}{Group 2 (12)}} & Estimate & $-0.023$ & $-0.015$ & $-0.001$ \\ \cline{2-5}
\multicolumn{1}{|c|}{} & ASE & $0.015$ & $0.023$ & $0.010$ \\ \cline{2-5}
\multicolumn{1}{|c|}{} & 95\% CI & $(-0.053, 0.006)$ & $(-0.061, 0.031)$ & $(-0.020, 0.018)$ \\ \hline
\multicolumn{1}{|c|}{\multirow{3}{*}{Group 3 (13)}} & Estimate & $-0.100$ & $-0.075$ & $0.002$ \\ \cline{2-5}
\multicolumn{1}{|c|}{} & ASE & $0.021$ & $0.044$ & $0.009$ \\ \cline{2-5}
\multicolumn{1}{|c|}{} & 95\% CI & $(-0.142, -0.058)$ & $(-0.160, 0.010)$ & $(-0.016, 0.020)$ \\ \hline
\multicolumn{1}{|c|}{\multirow{3}{*}{Group 4 (12)}} & Estimate & $-0.016$ & $0.028$ & $0.020$ \\ \cline{2-5}
\multicolumn{1}{|c|}{} & ASE & $0.014$ & $0.117$ & $0.012$ \\ \cline{2-5}
\multicolumn{1}{|c|}{} & 95\% CI & $(-0.044, 0.011)$ & $(-0.202, 0.258)$ & $(-0.003, 0.043)$ \\ \hline
\multicolumn{1}{|c|}{\multirow{3}{*}{Group 5 (5)}} & Estimate & $-0.002$ & $0.003$ & $0.018$ \\ \cline{2-5}
\multicolumn{1}{|c|}{} & ASE & $0.016$ & $0.021$ & $0.012$ \\ \cline{2-5}
\multicolumn{1}{|c|}{} & 95\% CI & $(-0.034, 0.029)$ & $(-0.037, 0.043)$ & $(-0.007, 0.042)$ \\ \hline
\multicolumn{1}{|c|}{\multirow{3}{*}{Group 6 (24)}} & Estimate & $-0.003$ & $0.030$ & $0.001$ \\ \cline{2-5}
\multicolumn{1}{|c|}{} & ASE & $0.009$ & $0.030$ & $0.005$ \\ \cline{2-5}
\multicolumn{1}{|c|}{} & 95\% CI & $(-0.020, 0.014)$ & $(-0.029, 0.089)$ & $(-0.009, 0.011)$ \\ \hline


\end{tabular}
\caption{Bias and Asymptotic Standard Errors of the Three ATT Estimators Under the Placebo Study. 
The numbers in the parentheses show the number of donors in each group. 
We remark that the results of Group 6 are the same as those in Section \ref{sec:Data} of the main paper.}
\label{tab:supp:ATT Placebo}
\end{table}
 
% Figure environment removed	

\newpage


\section{Nonparametric Single Proxy Synthetic Control Framework}		\label{sec:supp:nonparametric full}

\subsection{General Methodology} \label{sec:supp:nonparametric}

The SPSC framework can be generalized to the case in which the synthetic control is nonlinear and/or nonparametric, thus allowing the outcome to have arbitrary types such as binary, count, and continuous over a bounded interval. The nonparametric identification of the synthetic control relies on the existence of the bridge function satisfying the following condition.
\begin{assumption}[Existence of Nonparametric Bridge Function] \label{assumption:SC NP}
For all $t=1,\ldots,T$, there exists a function $h^*: \R^d \rightarrow \R$ that satisfies $\potY{t}{0} = \EXP \big\{
h^*(\bW_{\D t})
\cond
\potY{t}{0}
\big\}
=
0$ almost surely.
\end{assumption}
In words, there exists a function of donors $h^*$, possibly linear or nonlinear, of which conditional expectation given $\potY{t}{0}$ recovers $\potY{t}{0}$; the function $h^*$ is a kind of bridge functions \citep{TT2020_Intro, TTPR2023}, and we aptly refer to $h^*$ as the synthetic control bridge function in this paper. The synthetic control bridge function $h^*$ is a solution to a Fredholm integral equation of the first kind, and sufficient conditions for the existence of a solution are well studied in previous works such as \citet{Miao2018} and \citet{Cui2023}; see Section \ref{sec:supp:Exist h} of the Supplementary Material for details. We remark that Assumption \ref{assumption:SC} is a special case of Assumption \ref{assumption:SC NP} where the synthetic control bridge function is restricted to a linear form of $h( \bW_{\D t} ) = \bW_{\D t} \T \bgamma$. 

Similar to the results established under the linear synthetic control, the synthetic control bridge function $h^*$ can be used as a basis for identifying the ATT; the following Theorem formally establishes the result.	
\begin{theorem}	\label{thm:Extension NP}

Under Assumptions \ref{assumption:consistency}--\ref{assumption:valid proxy} and \ref{assumption:SC NP}, the synthetic control bridge function $h^*$ satisfies the following equation:
\begin{align}	\label{eq-Fredholm}
\EXP \big\{ Y_t - h^*(\bW_{\D t}) \cond Y_t \big\} = 0 \  \text{ almost surely} \ , \quad t=1,\ldots,T_0 \ .
\end{align}
Moreover, we have $
\EXP \big\{ \potY{t}{0} - h^*(\bW_{\D t}) \big\} = 0$ for any $t=1,\ldots,T$. 
Lastly, the ATT at time $t = T_0+1,\ldots,T$ is identified as $\tau_t^*
=
\EXP
\big\{
Y_t - h^*(\bW_{\D t}) 
\big\}$. 	 
\end{theorem}
Theorem \ref{thm:Extension NP} is a generalization of Theorems \ref{thm:SC} and \ref{thm:ATT} to nonparametric settings. If the synthetic control bridge function $h^*$ is unique, standard nonparametric or parametric estimation strategies can result in consistent estimators for $h^*$; the GMM estimator in Section \ref{sec:Estimation} is an example of the parametric estimation strategy. However, in general, the integral equation \eqref{eq-Fredholm} may have multiple solutions. Still, all solutions are valid synthetic controls and, consequently, result in the same ATT. When the bridge functions are not unique, we follow the approaches in \citet{Li2023} and \citet{Zhang2023} to obtain a nonparametric series estimator; see Section \ref{sec:supp:nonparametric estimation}. Given the synthetic control bridge function, the post-treatment residual process $Y_{t} - h^* (\bW_{\D t})$ is equivalent to the ATT plus the post-treatment error, i.e., $Y_{t} - h^*(\bW_{\D t}) = \tau_t^* + \epsilon_{t}$ where the ATT $\tau_t^*$ encodes the deterministic trend of the residual process via model $\tau_t^* = \tau(t \con \bbeta^*)$ and the error process $\epsilon_{t}$ satisfies the conditions in Assumption \ref{assumption:weakdep}. The estimation of the ATT parameter $\bbeta^*$ can be easily performed by following the results in the previous section with minor modifications.

Lastly, we extend the results when exogenous covariates are available, which are parallel to Section \ref{sec:Cov}.


\begin{assumption}[Existence of Bridge Function in the Presence of Covariates] \label{assumption:SC NP Cov} 
For all $t=1,\ldots,T$, there exists a function $h^*: \R^{d+q+dq} \rightarrow \R$ that satisfies $\potY{t}{0} = \EXP \big\{
h^*(\bW_{\D t}, \bX_{0t}, \bX_{\D t} )
\cond
\potY{t}{0}, \bX_{0t}, \bX_{\D t}
\big\}$ almost surely.
\end{assumption}	 

\begin{theorem}	\label{thm:Extension NP Cov}

Suppose Assumptions \ref{assumption:consistency}, \ref{assumption:noitf}, \ref{assumption:valid proxy Cov}, and \ref{assumption:SC NP Cov} are satisfied. Then, the synthetic control bridge function $h^*$ satisfies $\EXP \big\{ Y_t - h^*(\bW_{\D t}, \bX_{0t}, \bX_{\D t}) \cond Y_t, \bX_{0t}, \bX_{\D t} \big\} = 0$ for $t=1,\ldots,T_0$. 	
Moreover, we have $
\EXP \big\{ \potY{t}{0} - h^*(\bW_{\D t}, \bX_{0t}, \bX_{\D t}) \big\} = 0$ for any $t=1,\ldots,T$. 
Lastly, the ATT at time $t = T_0+1,\ldots,T$ is identified as $\tau_t^*
=
\EXP
\big\{
Y_t - h^*(\bW_{\D t}, \bX_{0t}, \bX_{\D t} ) 
\big\}$. 	 
\end{theorem}

The estimation of inference of the synthetic control bridge function and the ATT is analogous to that established in the absence of covariates, so we omit the details here.


\subsection{Sufficient Conditions for the Existence of the Synthetic Control Bridge Function} \label{sec:supp:Exist h}

In this Section, we provide sufficient conditions for the existence of the synthetic control bridge function $h^*$. In brief, we follow the approach in \citet{Miao2018}. The proof relies on Theorem 15.18 of \citet{Kress2014}, which is stated below for completeness.\\[0.25cm]
\noindent
\textbf{Theorem 15.18.} \citep{Kress2014}
Let $A:X \rightarrow Y$ be a compact operator with singular system $\big\{ \mu_n,\phi_n,g_n \big\}_{n=1,2,\ldots}$. The integral equation of the first kind $A\phi = f$ is solvable if and only if 
\begin{align*}
 & 1. \quad
 \text{$f \in \mathcal{N}(A^{\text{adjoint}})^\perp = \big\{ f \, \big| \, A^{\text{adjoint}}(f) = 0 \big\}^{\perp}$}
 \ , 
 &&
 2. \quad
 \text{$\sum_{n=1}^{\infty} \mu_n^{-2} \big| \langle f,g_n \rangle |^2 < \infty$}
\end{align*}


To apply the Theorem, we introduce some additional notations. Let $\mathcal{L}_{W}$ and $\mathcal{L}_{ \potY{}{0} }$ be the spaces of square-integrable functions of $\bW_{\D t}$ and $\potY{t}{0}$, respectively, which are equipped with the inner products $\langle h_1, h_2 \rangle_{W} = \int h_1(\bw) h_2(\bw) \, f_W (\bw) \, d\bw = \EXP \big\{ h_1(\bW_{\D t}) h_2(\bW_{\D t}) \big\} $ and $\langle g_1, g_2 \rangle_{\potY{}{0}} = \int g_1(y) g_2(y) \, f_{\potY{}{0}} (y) \, dy = \EXP \big\{ g_1(\potY{t}{0}) g_2(\potY{t}{0}) \big\} $, respectively. Let $\mathcal{K}: \mathcal{L}_{W} \rightarrow \mathcal{L}_{ \potY{}{0} }$ be the conditional expectation of $h(\bW_{\D t} ) \in \mathcal{L}_{W}$ given $\potY{t}{0}$, i.e.,
\begin{align*}
\mathcal{K} (h) \in \mathcal{L}_{\potY{}{0}} 
\text{ satisfying }
\big( \mathcal{K}(h) \big) (y) 
=
\EXP \big\{ h(\bW_{\D t}) \cond \potY{t}{0}=y \big\}
\text{ for } h \in \mathcal{L}_{W}
\end{align*}
Then, the synthetic control bridge function $h^* \in \mathcal{L}_{W}$ solves $\mathcal{K} ( h^* ) = [\text{identity map}] \in \mathcal{L}_{\potY{}{t}} $, i.e., 
\begin{align*}
\int h^*(\bw) f_{W | \potY{}{0} } (\bw \cond y ) \, d\bw = y , \ \forall y
\end{align*}


Now, we assume the following conditions:
\begin{itemize}[leftmargin=0.4cm, itemsep=0cm]
\item[] \HT{NPSC-1} The variables $(\potY{t}{0} , \bW_{\D t})$ are stationary; 
\item[] \HT{NPSC-2} $\iint
f_{W | \potY{}{0} } (\bw \cond y )
f_{\potY{}{0} | W } (y \cond \bw )
\, d\bw \, d y
< \infty$;
\item[] \HT{NPSC-3} For $g \in \mathcal{L}_{\potY{}{0}}$, $\EXP \big\{ g(\potY{t}{0}) \cond \bW_{\D t} \big\} = 0$ implies $g(\potY{t}{0})= 0$ almost surely;
\item[] \HT{NPSC-4} $\EXP \big[ \big\{ \potY{t}{0} \big\}^2 \big] < \infty$;
\item[] \HT{NPSC-5} Let the singular system of $\mathcal{K}$ be $\big\{ \mu_n,\phi_n,g_n \big\}_{n=1,2,\ldots}$. Then, we have $\sum_{n=1}^{\infty} \mu_n^{-2} \big| \langle \potY{t}{0} ,g_n \rangle |^2 < \infty$.
\end{itemize}

We remark that the expectation can be defined without using $t$ under Condition \HL{NPSC-1}. First, we show that $\mathcal{K}$ is a compact operator under Condition \HL{NPSC-2}. Let $\mathcal{K}^{\text{adjoint}} : \mathcal{L}_{\potY{}{0}} \rightarrow \mathcal{L}_{W}$ be the conditional expectation of $g(\potY{t}{0}) \in \mathcal{L}_{\potY{}{0}}$ given $\bW_{\D t}$, i.e., 
\begin{align*}
\mathcal{K}^{\text{adjoint}} (g) \in \mathcal{L}_{W} 
\text{ satisfying }
\big( \mathcal{K}(g) \big) (\bw) 
=
\EXP \big\{ g(\potY{t}{0}) \cond \bW_{\D t}=\bw \big\}
\text{ for } g \in \mathcal{L}_{\potY{}{0}}
\end{align*}
Then, $\mathcal{K}$ and $\mathcal{K}^{\text{adjoint}}$ are the adjoint operator of each other as follows:
\begin{align*}
\langle \mathcal{K}(h) , g \rangle_{\potY{}{0}}
& =
\EXP
\big[
\EXP \big\{ h(\bW_{\D t}) \cond \potY{t}{0} \big\}
g(\potY{t}{0})
\big]	
\\
& 
=
\EXP
\big[
h(\bW_{\D t}) g(\potY{t}{0})
\big]	
\\
&
=
\EXP
\big[
h(\bW_{\D t}) \EXP \big\{ g(\potY{t}{0}) \cond \bW_{\D t} \big\}
\big]	
=
\langle h , \mathcal{K}^{\text{adjoint}}(g) \rangle_{W}
\end{align*}
Additionally, as shown in page 5659 of \citet{Carrasco2007}, $\mathcal{K}$ and $\mathcal{K}^{\text{adjoint}}$ are compact operators under Condition \HL{NPSC-1}. Moreover, by Theorem 15.16 of \citet{Kress2014}, there exists a singular value decomposition of $\mathcal{K}$ as $\big\{ \mu_n,\phi_n,g_n \big\}_{n=1,2,\ldots}$. 

Second, we show that $\mathcal{N}(\mathcal{K}^{\text{adjoint}})^\perp = \mathcal{L}_{\potY{}{0}}$, which suffices to show $\mathcal{N}(\mathcal{K}^{\text{adjoint}}) = \big\{ 0 \big\} \subseteq \mathcal{L}_{\potY{}{0}}$. Under Condition \HL{NPSC-3}, we have 
\begin{align*}
g \in \mathcal{N}(\mathcal{K}^{\text{adjoint}})
\quad 
\Rightarrow 
\quad 
\EXP \big\{ g (\potY{t}{0}) \cond \bW_{\D t} = \bw \big\}
=
0, \ \forall \bw
\quad \Rightarrow
\quad
g(\potY{t}{0}) = 0 
\end{align*}
where the first arrow is from the definition of the null space $\mathcal{N}$, and the second arrow is from Condition \HL{NPSC-3}. Therefore, any $g \in \mathcal{N}(\mathcal{K}^{\text{adjoint}})$ must satisfy $g(y) = 0 $ almost surely, i.e., $\mathcal{N}(\mathcal{K}^{\text{adjoint}})= \big\{ 0 \big\} \subseteq \mathcal{L}_{\potY{}{0}}$ almost surely. 

Third, from the definition of $\mathcal{L}_{W}$, $g(\potY{t}{0}) = \potY{t}{0} \in \mathcal{L}_{\potY{}{0}} = \mathcal{N}(\mathcal{K}^{\text{adjoint}})^\perp $ under Condition \HL{NPSC-4}. 


Combining the three results, we establish that $\potY{t}{0}$ satisfies the first condition of Theorem 15.18 of \citet{Kress2014}. The second condition of the Theorem is exactly the same as Condition \HL{NPSC-5}. Therefore, we establish that the Fredholm integral equation of the first kind $\mathcal{K} ( h ) = [\text{identity map}] $ is solvable under Conditions \HL{NPSC-1}-\HL{NPSC-5}.

\subsection{Uniqueness of Synthetic Control Bridge Function Under Completeness}		\label{sec:supp:NP Unique}

In Section \ref{sec:supp:nonparametric}, we showed that \eqref{eq-Fredholm} is satisfied under Assumptions \ref{assumption:consistency}--\ref{assumption:valid proxy} and \ref{assumption:SC NP}; for readability, we restate Assumption \ref{assumption:SC NP} and \eqref{eq-Fredholm} below:\\[0.1cm] 
\textit{Assumption \ref{assumption:SC NP} (Existence of Nonparametric Bridge Function)
For all $t=1,\ldots,T$, there exists a function $h^*: \R^d \rightarrow \R$ that satisfies $\potY{t}{0} = \EXP \big\{
h^*(\bW_{\D t})
\cond
\potY{t}{0}
\big\}
=
0$ almost surely.}\\[0.1cm]
and
\begin{align}
\EXP \big\{ Y_t - h^*(\bW_{\D t}) \cond Y_t \big\} = 0 \ \text{ almost surely} \ , \quad t=1,\ldots,T_0 \ .
\tag{\ref{eq-Fredholm}}
\end{align}

In this section, we show the reverse is satisfied. 
Suppose a function $h^*$ satisfies \eqref{eq-Fredholm}. Then, we obtain the following result for $t=1,\ldots,T_0$:
\begin{align*}
y 
& =
\EXP \big\{ h^* ( \bW_{\D t} ) \cond Y_t=y \big\} 
=
\EXP \big\{ h^* (\bW_{\D t}) \cond \potY{t}{0} = y \big\} \ ,
\end{align*} 
where the second equality holds from Assumption \ref{assumption:consistency}. 
Therefore, $h^*$ satisfies Assumption \ref{assumption:SC NP}. 

We can further show that the bridge function $h^*$ is indeed unique under an additional assumption, namely the completeness assumption:
\begin{assumption}[Completeness] \label{assumption-complete}
For $t=1,\ldots,T_0$, suppose $\EXP \big\{ q(\bW_{\D t}) \cond Y_t \big\} = 0$ almost surely for a square integrable function $q$. Then, $q(\bW_{\D t} ) = 0$ almost surely. 	
\end{assumption}
The assumption states that $Y_t$ should be $\bW_{\D t}$-relevant over the pre-treatment periods in the sense that any variation in $\bW_{\D t}$ is captured by variation in $Y_t$ for the pre-treatment periods. 

Under Assumptions \ref{assumption:consistency}--\ref{assumption:valid proxy}, \ref{assumption:SC NP}, and \ref{assumption-complete}, the solution to \eqref{eq-Fredholm} is unique almost surely. To show this, let $h_1^*$ and $h_2^*$ be synthetic control bridge functions that satisfy \eqref{eq-Fredholm}. We then find $\EXP \big\{ h_1^*(\bW_{\D t}) - h_2^*(\bW_{\D t}) \cond Y_t \big\} = 0$ for $t=1,\ldots,T_0$, implying $h_1^*(\bW_{\D t})$ and $h_2^*(\bW_{\D t}) = 0$ almost surely from Assumption \ref{assumption-complete}. Therefore, the solution to \eqref{eq-Fredholm} must be unique almost surely, i.e., $ h_1^*(\bW_{\D t}) = h_2^*(\bW_{\D t})$ almost surely. Moreover, suppose $h_3^*$ be a synthetic control bridge function that satisfies Assumption \ref{assumption:SC NP}. Then, $h_3^*$ is a solution to \eqref{eq-Fredholm}, indicating that $ h_1^*(\bW_{\D t}) = h_3^*(\bW_{\D t})$ almost surely because of the same reasoning. Therefore, the unique solution to \eqref{eq-Fredholm} is also the unique function satisfying Assumption \ref{assumption:SC NP}. 

We remark that Assumption \ref{assumption-complete} may not be satisfied if the cardinality of the support of $\bW_{\D t}$ is strictly larger than that of $Y_t$. For instance, suppose that the outcomes are binary and two donors are available, i.e., $\bW_{\D t} \in \{0,1\}^2$ and $Y_t \in \{0,1\}$. Then, the equation in Assumption \ref{assumption-complete} reduces to
\begin{align} \label{eq-underdetermine}
    \begin{bmatrix}
        p_{W|Y}( 0,0 \cond 0)
        &
        p_{W|Y}( 0,1 \cond 0)
        &
        p_{W|Y}( 1,0 \cond 0)
        &
        p_{W|Y}( 1,1 \cond 0)
        \\
        p_{W|Y}( 0,0 \cond 1)
        &
        p_{W|Y}( 0,1 \cond 1)
        &
        p_{W|Y}( 1,0 \cond 1)
        &
        p_{W|Y}( 1,1 \cond 1)
    \end{bmatrix}
    \begin{bmatrix}
        q(0,0) \\ q(0,1) \\ q(1,0) \\ q(1,1) 
    \end{bmatrix}
    =
    \begin{bmatrix}
        0 \\ 0
    \end{bmatrix}
\end{align}
where $p_{W|Y}(a,b \cond y) = \Pr\{ \bW_{\D t}=(a,b) \cond \potY{t}{0} = y \}$. Since \eqref{eq-underdetermine} is an underdetermined system, there are multiple non-zero $q$ functions satisfying \eqref{eq-underdetermine}, indicating that Assumption \ref{assumption-complete} cannot be satisfied. 

In the following section, we introduce a nonparametric SPSC framework that accommodates non-unique synthetic control bridge functions.










\subsection{Single Proxy Synthetic Control Approach without the Uniqueness Assumption}		\label{sec:supp:nonparametric estimation}




The synthetic control bridge function $h$ is defined as a function satisfying \eqref{eq-Fredholm}; we restate the equation below for readability.
\begin{align}		\label{eq-Fredholm2}
\EXP \big\{ Y_t - h^*(\bW_{\D t}) \cond Y_t \big\} = 0 \text{ almost surely} \ , \quad t=1,\ldots,T_0 \ .
\tag{\ref{eq-Fredholm}}
\end{align}
We consider the case where there are multiple synthetic control bridge functions $h$ satisfying \eqref{eq-Fredholm2}. Even so, the identification of the ATT established in Theorem \ref{thm:Extension NP} is satisfied regardless of the choice of the bridge function. However, estimation and inference of the ATT can be complicated in the presence of multiple synthetic control bridge functions. To resolve this issue, we use approaches proposed by a series of recent works \citep{Li2023, Zhang2023}. In brief, their approaches involve the following three stages. In the first stage, we estimate a set of synthetic control bridge functions based on a sieve estimator; see Stage 1 below. In the second stage, we define a criterion function, denoted by $M$, and focus on the estimation of the minimizer of $M$, denoted by $h_0$. Then, an estimator of the ATT can be constructed based on the estimator of $h_0$; see Stage 2 below. In the third stage, we consider a de-biasing procedure for the estimator obtained in the previous stage to attain the asymptotic normality; see Stage 3 below. The following sections present details under general nonparametric settings, but the method can be applied to the parametric synthetic controls, including cases where there are multiple synthetic control weights that satisfy Assumption \ref{assumption:SC}. We have included only the essential assumptions and notations in this work to ensure clarity. We refer the readers to \citet{Li2023} and \citet{Zhang2023} for additional details.\\[0.25cm]

\noindent \textbf{Stage 1}: Estimation of the Solution Set $\mathcal{H}_0$ \\

Let $\mathcal{H}$ be a collection of user-specified smooth functions, and let $\mathcal{H}_0$ be the collection of the solutions of \eqref{eq-Fredholm2}, i.e.,
\begin{align*}
\mathcal{H}_0
=
\Big\{ h \in \mathcal{H} \, \Big| \,
Y_t = \EXP \big\{ h(\bW_{\D t}) \cond Y_t \big\}, \ t=1,\ldots,T_0
\Big\}
\end{align*}
Alternatively, we can represent $\mathcal{H}_0$ using a criterion function. Let $\mathfrak{C}: \mathcal{H} \rightarrow \R$ be a criterion function having the following form:
\begin{align*}
\mathfrak{C} (h)
=
\EXP
\Big[
\big[
Y_t
-
\EXP \big\{ h(\bW_{\D t}) \cond Y_t \big \}
\big]^2
\Big] 
\ , \ t=1,\ldots,T_0
\ .
\end{align*}
It is straightforward to check that $\mathcal{H}_0 = \big\{ h \in \mathcal{H} \cond \mathfrak{C}(h) = 0 \big\}$.

We consider a sieve approach as follows. First, we choose a sequence of approximating bases functions of $\bW_{\D t}$, denoted by $\big\{ \varphi_k(\bw) \big\}_{k=1,2,\ldots}$. For this sequence, we define an approximating function space for $\mathcal{H}$ by using the first $k_T$ bases functions, i.e.,
\begin{align*}
\mathcal{H}_T
=
\bigg\{
h \in \mathcal{H}
\, \bigg| \,
h(\bw)
=
\sum_{\ell=1}^{k_T}
b_{\ell} \varphi_{\ell}(\bw) 
\bigg\} \ ,
\end{align*}
where $k_T$ is a known parameter and $b_1,\ldots,b_{k_T}$ are unknown scalar parameters.

A sample analogue of the criterion function $\mathfrak{C}$, denoted by $\mathfrak{C}_T$, can be obtained based on the sieve approach. We choose a sequence of approximating bases functions of $\potY{t}{0}$, denoted by $ \big\{ \phi_k (y) \big\}_{k=1,2,\ldots}$. Then, we choose the first $k_T$ bases function and construct a $k_T$-dimensional function of $y$, denoted by $\bphi (y) = \big\{ \phi_1(y),\ldots,\phi_{k_T}(y) \big\}\T$. Using the pre-treatment observations, we construct a $(T_0 \times k_T)$ matrix as follows:
\begin{align*}
\Phi_{\pre}
=
\begin{bmatrix}
\bphi \T (Y_1)
\\
\vdots
\\
\bphi \T (Y_{T_0})
\end{bmatrix} 
\in \R^{T_0 \times k_T}
\ .
\end{align*}
For a given function $h$, a sieve estimator of the conditional expectation $\EXP \big\{ h(\bW_{\D t}) \cond Y_t \big\}$ for $t=1,\ldots,T_0$ can be obtained by regressing $h(\bW_{\D t})$ on $ \bphi(Y_t) $, i.e., 
\begin{align*}
\widehat{\mu}_{\pre} (y \con h)
=
\texttt{sieve}
\Big(
\EXP \big\{ h(\bW_{\D t}) \cond Y_t = y \big\}
\Big)
=
\bphi \T (y)
\big( \Phi_{\pre} \T \Phi_{\pre} \big)^{-1}
\bigg\{
\sum_{t=1}^{T_0}
h(\bW_{\D t}) \bphi(Y_t)
\bigg\} \ .
\end{align*}
Therefore, $\mathfrak{C}_T$ can be obtained based on a sieve estimator, i.e.,
\begin{align*}
\mathfrak{C}_T (h)
=
\frac{1}{T_0} \sum_{t=1}^{T_0} 
\Big\{
Y_t
-
\widehat{\mu}_{\pre} (Y_t \con h)
\Big\}^2
\end{align*}
The proposed estimator of $\mathcal{H}_0$ is 
\begin{align*}
\widehat{\mathcal{H}}_0 = \Big\{ h \in \mathcal{H}_T \Cond \mathfrak{C}_T(h) \leq c_T \Big\} 
\end{align*}
where $c_T$ is an appropriately chosen sequence with $c_T \rightarrow 0$ as $T \rightarrow \infty$. Under regularity conditions, we have
\begin{align*}
d_{H} \big(\widehat{\mathcal{H}}_0, {\mathcal{H}}_0 , \big\| \cdot \big\|_{\infty} \big) = o_P(1)
\end{align*}
where $d_{H} (\mathcal{H}_1,\mathcal{H}_2, \big\| \cdot \big\| )$ is the Hausdorff distance between $\mathcal{H}_1$ and $\mathcal{H}_2$ with respect to a given norm $\big\| \cdot \big\|$; see Section 3.2 of \citet{Li2023} and Section 3.2 of \citet{Zhang2023} for details. \\



\noindent \textbf{Stage 2}: A Representer-based Estimator \\

After obtaining a consistent set estimator of $\mathcal{H}_0$ (i.e., $\widehat{\mathcal{H}}_0$), we select an estimator of $h$ from $\widehat{\mathcal{H}}_0$ so that it converges to a unique element in $\mathcal{H}_0$. Specifically, we define a function $M : \mathcal{H} \rightarrow \R$ that has a unique minimum $h_0$ on $\mathcal{H}_0$. Let $M_T$ be its sample analogue, and let $\widehat{h}_0$ be the minimum of $M_T(h)$ over $\widehat{\mathcal{H}}_0$, i.e.,
\begin{align*}
\widehat{h}_0 \in \argmin_{h \in \widehat{\mathcal{H}}_0} M_T(h) \ . 
\end{align*}
To obtain a unique minimum $\widehat{h}_0$, $\mathcal{H}$ and $M$ are chosen to satisfy the following assumption:
\begin{assumption} The following conditions are satisfied:
\begin{itemize}[leftmargin=0.5cm, itemsep=0cm]
\item[1.] The set $\mathcal{H}$ is convex;
\item[2.] The functional $M: \mathcal{H} \rightarrow \R$ is strictly convex, and have a unique minimum at $h_0$ on $\mathcal{H}_0$;
\item[3.] The sample analogue $M_T : \mathcal{H} \rightarrow \R$ is continuous and $\sup_{h \in \mathcal{H}} \big| M_T(h) - M(h) \big| = o_P(1)$.
\end{itemize}
\end{assumption}
Possible choices for $M$ and its sample analogue $M_T$ are 
\begin{align*}
&
M(h)
=
\EXP \big[ \big\{ h(\bW_{\D t} ) \big\}^2 \big]
\ , \ t=1,\ldots,T_0
\ , 
&&
M_T (h)
=
\frac{1}{T_0}
\sum_{t=1}^{T_0}
\big\{ h(\bW_{\D t} ) \big\}^2
\end{align*}
Under regularity conditions, we have $\big\| \widehat{h}_0 - h_0 \big\|_{\infty} = o_P(1)$; see Theorem 3 of \citet{Li2023} and Proposition 3.2 of \citet{Zhang2023} for details. In turn, we obtain an estimator of the ATT as $\widehat{\tau}_t = Y_t - \widehat{h}_0(\bW_{\D t})$ for $t=T_0+1,\ldots,T$ where inference based on $\widehat{\tau}_t$ can be established by the conformal inference in Section \ref{sec:Conformal} in the Supplementary Material. Alternatively, we may posit a parametric form for the ATT as $\tau_t = \tau(t \con \bbeta)$. Considering $\widehat{h}_0$ as a fixed function, an estimator of $\bbeta$ can be obtained as a solution to the following equation:
\begin{align}	
&
\widehat{\bbeta} \text{ solves }
\frac{1}{T_1}
\sum_{t=T_0+1}^{T}
{\Psi}_{\post} (\bO_t \con \bbeta, \widehat{h}_0)
= 0
\ , 
\label{eq-betahat}
\\
&
{\Psi}_{\post} (\bO_t \con \bbeta, h)
=
\frac{\partial \tau(t \con \bbeta) }{\partial \bbeta}
\Big\{ Y_t - \tau(t \con {\bbeta}) - h (\bW_{\D t} ) \Big\}
\in \R^{\text{dim}(\bbeta)}
\ , \ 
t=T_0+1,\ldots,T
\ .
\label{eq-supp-postEE}
\end{align}
To characterize the asymptotic property of $\widehat{\bbeta}$, we additionally define the following objects. Let $\langle h_1, h_2 \rangle_w$ be
\begin{align*}
\langle h_1, h_2 \rangle_w
=
\EXP \big[
\EXP \big\{ h_1(\bW_{\D t}) \cond \potY{t}{0} \big\}
\EXP \big\{ h_2(\bW_{\D t}) \cond \potY{t}{0} \big\} 
\big] \ , \
t=T_0+1,\ldots,T \ ,
\end{align*}
and $\overline{\mathcal{H}}$ be the closure of the linear span of $\mathcal{H}$ under $\big\| \cdot \big\|_w$. Then, we assume the following conditions.
\begin{assumption} 	\label{assumption:supp:g}
The following conditions are satisfied:
\begin{itemize}[leftmargin=0.5cm, itemsep=0cm]
\item[1.] For any $h \in \overline{\mathcal{H}}$, there exists a function $g_{0,h} \in \mathcal{H}$ satisfying $\langle g_{0,h}, h \rangle_w = \EXP \big\{ h(\bW_{\D t}) \big\}$ for $t=T_0+1,\ldots,T$. 
\item[2.] There exists a projection of $\mathcal{H}$ on $\mathcal{H}_T$, denoted by $\Pi_{T}: \mathcal{H} \rightarrow \mathcal{H}_T$, which satisfies
\begin{align*}
\sup_{h \in \mathcal{H}} \big\| h - \Pi_T h \big\| = O(\eta_T) \ .
\end{align*}
where $\eta_T=o(1)$ satisfies regularity conditions; see Assumptions 7-10 of \citet{Li2023} and Assumptions 4-7 of \citet{Zhang2023} for details.
\end{itemize}

\end{assumption}
We now characterize the asymptotic representation of $T_1^{1/2}
\big( \widehat{\bbeta} - \bbeta^* \big)$ under regularity conditions including stationarity and independent errors. Applying a first-order Taylor expansion, we find
\begin{align*}
0 
&
= 
\frac{1}{T_1} \sum_{t=T_0+1}^{T} {\Psi}_{\post} (\bO_t \con \widehat{\bbeta}, \widehat{h}_0)
\\
&
=
\frac{1}{T_1} \sum_{t=T_0+1}^{T}
\Bigg\{ {\Psi}_{\post} (\bO_t \con \bbeta^*, \widehat{h}_0)
+
\frac{\partial {\Psi}_{\post} (\bO_t \con \bbeta, \widehat{h}_0) }{\partial \bbeta\T} \bigg|_{\bbeta=\bbeta^*}
\cdot \big( \widehat{\bbeta} - \bbeta^* \big)
\Bigg\}
+
o_P(1) \ .
\end{align*}
Therefore, we find that \eqref{eq-betahat} has the following asymptotic representation for $t=T_0+1,\ldots,T$:
\begin{align}
&
\sqrt{T_1} 
\big( \widehat{\bbeta} - \bbeta^* \big)
\nonumber
\\
& 
= 
\bigg[ 
\underbrace{
\frac{1}{T_1} \sum_{t=T_0+1}^{T} 
\frac{\partial {\Psi}_{\post} (\bO_t \con \bbeta, \widehat{h}_0) }{\partial \bbeta\T} \bigg|_{\bbeta=\bbeta^*} 
}_{=: V (\bbeta^*, \widehat{h}_0) }
\bigg]^{-1}
\nonumber 
\\
& \hspace*{1cm} \times 
\bigg[ \frac{1}{\sqrt{ T_1} } \sum_{t=T_0+1}^{T} 
\frac{\partial \tau(t \con \bbeta^*)}{\partial \bbeta}
\Big\{
Y_t - \tau(t \con {\bbeta}^*) - \widehat{h}_0(\bW_{\D t} )
\Big\}
\bigg]
+
o_P(1)
\nonumber
\\
& 
=
V^{-1} (\bbeta^*, \widehat{h}_0)
\bigg[ \frac{1}{\sqrt{ T_1} } \sum_{t=T_0+1}^{T} 
\frac{\partial \tau(t \con \bbeta^*)}{\partial \bbeta}
\Big\{
Y_t 
- \tau(t \con \bbeta^*)
- \widehat{h}_0(\bW_{\D t} )
\Big\}
\bigg]
+
o_P(1)
\nonumber
\\
& 
=
V^{-1} (\bbeta^*, \widehat{h}_0)
\bigg[ \frac{1}{\sqrt{ T_1} } \sum_{t=T_0+1}^{T} 
\frac{\partial \tau(t \con \bbeta^*)}{\partial \bbeta}
\Big\{
Y_t 
- \tau(t \con \bbeta^*)
- h_0(\bW_{\D t}) 
\Big\}
\bigg]
\label{eq-supp-Asymp1}
\\
&
\quad +
V^{-1} (\bbeta^*, \widehat{h}_0)
\bigg[ \frac{1}{\sqrt{ T_1} } \sum_{t=T_0+1}^{T} 
\frac{\partial \tau(t \con \bbeta^*)}{\partial \bbeta}
\Big[
\EXP \big\{ h_0(\bW_{\D t}) - \widehat{h}_0(\bW_{\D t} ) \big\} 
\Big]
\bigg]
\label{eq-supp-Asymp2}
\\
&
\quad +
V^{-1} (\bbeta^*, \widehat{h}_0)
\Bigg[ \frac{1}{\sqrt{ T_1} } \sum_{t=T_0+1}^{T} 
\frac{\partial \tau(t \con \bbeta^*)}{\partial \bbeta}
\Bigg[
\begin{array}{l}
\big\{ h_0(\bW_{\D t})
- \widehat{h}_0(\bW_{\D t} )
\big\}
\\
- \EXP \big\{ h_0(\bW_{\D t}) - \widehat{h}_0(\bW_{\D t} ) \big\}
\end{array} 
\Bigg]
\Bigg]
\label{eq-supp-Asymp3}
\\
&
\quad
+
o_P(1) 
\nonumber
\ .
\end{align}
Following Theorem 4 of \citet{Li2023} and Supplementary Material of \citet{Zhang2023}, we establish that \eqref{eq-supp-Asymp3} is $o_P(1)$. In addition, for $t=T_0+1,\ldots,T$, the numerator of \eqref{eq-supp-Asymp2} is equal to
\begin{align}
& 
\frac{1}{\sqrt{ T_1} } \sum_{t=T_0+1}^{T} 
\frac{\partial \tau(t \con \bbeta^*)}{\partial \bbeta}
\EXP \big\{ h_0(\bW_{\D t}) - \widehat{h}_0(\bW_{\D t} ) \big\} 
\nonumber
\\
&=
-
\frac{1}{\sqrt{ T_1} } \sum_{t=T_0+1}^{T} 
\frac{\partial \tau(t \con \bbeta^*)}{\partial \bbeta}
\EXP \big\{ g_{0,h_0} (\bW_{\D t}) \cond \potY{t}{0} \big\} 
\big\{ \potY{t}{0} - h_0(\bW_{\D t} ) \big\}
\nonumber
\\
&
\quad
+
\frac{1}{\sqrt{ T_1} } \sum_{t=T_0+1}^{T} 
\frac{\partial \tau(t \con \bbeta^*)}{\partial \bbeta}
\widehat{\EXP} \big\{ \Pi_T g_{0,h_0} (\bW_{\D t}) \cond \potY{t}{0} \big\} 
\big[ \potY{t}{0} - \widehat{\EXP} \big\{ \widehat{h}_0(\bW_{\D t}) \cond \potY{t}{0} \big\} \big]
+
o_P(1)	
\label{eq-asymptotic rep}
\ .
\end{align}
Here, $g_{0,h}$ and its projection $\Pi_T g_{0,h}$ are chosen to satisfy Assumption \ref{assumption:supp:g}, and $\widehat{\EXP}$ is a generic estimator of the conditional expectation operator of the distribution $\bW_{\D t} | \potY{t}{0}$ having a fast convergence rate; see Stage 3 below for details on how these estimators are constructed. Combining all results, we have the following result for $t=T_0+1,\ldots,T$:
\begin{align*}
&
\sqrt{T_1} 
\big( \widehat{\bbeta} - \bbeta^* \big)
\\
&
=
V^{-1} (\bbeta^*, \widehat{h}_0)
\bigg[ \frac{1}{\sqrt{ T_1} } \sum_{t=T_0+1}^{T} 
\frac{\partial \tau(t \con \bbeta^*)}{\partial \bbeta}
\left[ 
\begin{array}{l}
Y_t 
- \tau(t \con \bbeta^*)
- h_0(\bW_{\D t}) 
\\
-
\EXP \big\{ g_{0,h_0} (\bW_{\D t}) \cond \potY{t}{0} \big\}
\big\{ \potY{t}{0} - h_0(\bW_{\D t} ) \big\} 
\end{array}
\right]
\bigg]
\\
&
\quad
+
V^{-1} (\bbeta^*, \widehat{h}_0)
\sqrt{T_1}
r_T(\widehat{h}_0)
+
o_P(1)
\end{align*}
where
\begin{align*}
r_T(\widehat{h}_0)
= 
\frac{1}{ T_1 } \sum_{t=T_0+1}^{T} 
\frac{\partial \tau(t \con \bbeta^*)}{\partial \bbeta}
\widehat{\EXP} \big\{ \Pi_T g_{0,h_0} (\bW_{\D t}) \cond \potY{t}{0} \big\} 
\big[ \potY{t}{0} - \widehat{\EXP} \big\{ \widehat{h}_0(\bW_{\D t}) \cond \potY{t}{0} \big\} \big] \ .
\end{align*}

\noindent\textbf{Stage 3}: A De-biased Estimator\\

To obtain the asymptotic normality of $\widehat{\bbeta}$, we need to de-bias $\widehat{\bbeta}$ by subtracting an estimated value of $r_T(\widehat{h}_0)$. To do so, we define a new criterion function and its sample analogue for $h \in \mathcal{H}$ as follows:
\begin{align*}
&
\mathcal{R} (h)
=
\EXP \Big[ \big[ \EXP \big\{ h(\bW_{\D t}) \cond \potY{t}{0} \big\} \big]^2 \Big]
-
2 \EXP \big\{ h(\bW_{\D t}) \big\}
\ , \ 
t=T_0+1,\ldots,T \ ,
\\
&
\mathcal{R}_T (h)
=
\frac{1}{T_1} \sum_{t=T_0+1}^{T}
\big[ \widehat{\EXP} \big\{ h(\bW_{\D t}) \cond \potY{t}{0} \big\} \big]^2
-
\frac{2}{T_1} \sum_{t=T_0+1}^{T} h(\bW_{\D t}) \ .
\end{align*}
We obtain an estimator of $\Pi_T g_{0,h_0}$, denoted by $\widehat{g}$, as 
\begin{align*}
\widehat{g} \in \argmin_{\widehat{h}_0 \in \mathcal{H} } \mathcal{R}_T(\widehat{h}_0)
\end{align*}
and the resulting estimator of $r_T(\widehat{h}_0)$ is
\begin{align*}
\widehat{r}_T^{\text{inf}}(\widehat{h}_0)
= 
\frac{1}{ T_1 } \sum_{t=T_0+1}^{T} 
\frac{\partial \tau(t \con \widehat{\bbeta})}{\partial \bbeta}
\widehat{\EXP} \big\{ \widehat{g} (\bW_{\D t}) \cond \potY{t}{0} \big\} 
\big[ \potY{t}{0} - \widehat{\EXP} \big\{ \widehat{h}_0(\bW_{\D t}) \cond \potY{t}{0} \big\} \big] \ , \ 
t=T_0+1,\ldots,T \ .
\end{align*}
Unfortunately, the above estimator $	\widehat{r}_T^{\text{inf}}$ is infeasible because it involves with counterfactual outcomes. Therefore, we use $Y_t - \tau(t \con \widehat{\bbeta}) $ as realizations of the treatment-free potential outcomes $\potY{t}{0}$ and construct a $(T_1 \times k_T)$ matrix as follows:
\begin{align*}
{\Phi}_{\post}
=
\begin{bmatrix}
\bphi \T \Big( Y_{T_0+1} - \tau(T_0+1 \con \widehat{\bbeta}) \Big)
\\
\vdots
\\
\bphi \T \Big( Y_{T} - \tau(T \con \widehat{\bbeta}) \Big)
\end{bmatrix}
\in \R^{T_1 \times k_T}
\ .
\end{align*}
We consider additional sieve estimators of ${\EXP} \big\{ \widehat{g} (\bW_{\D t}) \cond \potY{t}{0} \big\} $ and ${\EXP} \big\{ \widehat{h}_0(\bW_{\D t}) \cond \potY{t}{0} \big\}$ for $t=T_0+1,\ldots,T$:
\begin{align*}
\widehat{\mu}_{\post} (y \con \widehat{g})
&
=
{ \texttt{sieve} }
\Big(
\EXP \big\{ \widehat{g} (\bW_{\D t}) \cond \potY{t}{0} = y \big\} 
\Big)
\\
&
=
\bphi \T (y)
\big( \Phi_{\post} \T \Phi_{\post} \big)^{-1}
\bigg\{
\sum_{t=T_0+1}^{T}
\widehat{g}(\bW_{\D t} ) \bphi \Big( Y_t - \tau(t \con \widehat{\bbeta}) \Big)
\bigg\}
\\
\widehat{\mu}_{\post}(y \con \widehat{h}_0 )
&
=
{ \texttt{sieve} }
\Big(
\EXP \big\{ \widehat{h}_0(\bW_{\D t}) \cond \potY{t}{0} = y \big\}
\Big)
\\
&
=
\bphi \T (y)
\big( \Phi_{\post} \T \Phi_{\post} \big)^{-1}
\bigg\{
\sum_{t=T_0+1}^{T}
\widehat{h}_0(\bW_{\D t} ) \bphi \Big( Y_t - \tau(t \con \widehat{\bbeta}) \Big)
\bigg\} \ .
\end{align*}
Using these sieve estimators, we obtain a feasible estimator of $r_T(\widehat{h}_0)$ as
\begin{align*}
\widehat{r}_T (\widehat{h}_0)
= 
\frac{1}{ T_1 } \sum_{t=T_0+1}^{T} 
\frac{\partial \tau(t \con \widehat{\bbeta})}{\partial \bbeta}
\bigg[
\widehat{\mu}_{\post} \big( Y_t - \tau(t \con \widehat{\bbeta}) \con \widehat{g} \big)
\Big\{
Y_t - \tau(t \con \widehat{\bbeta})
-
\widehat{\mu}_{\post} \big( Y_t - \tau(t \con \widehat{\bbeta}) \con \widehat{h}_0 \big)
\Big\}
\bigg] \ .
\end{align*}
Under regularity conditions, we establish that
\begin{align*}
 \sup_{\widehat{h}_0 \in \widehat{\mathcal{H}}_0}
 \sqrt{T_1}
 \Big|
\widehat{r}_T(\widehat{h}_0) - {r}_T(\widehat{h}_0)
 \Big| = o_P(1) \ ;
\end{align*} 
see Lemma 1 of \citet{Li2023} and Lemma 3.3 of \citet{Zhang2023} for details. Based on this result, we subtract $T_1^{1/2} \widehat{r}_T(\widehat{h}_0)$ in both hand sides of \eqref{eq-asymptotic rep}. We then obtain a de-biased estimator $\widehat{\bbeta}_{\text{db}}$ as
\begin{align*}
\widehat{\bbeta}_{\text{db}}
=
\widehat{\bbeta} 
-
V^{-1} (\widehat{\bbeta}, \widehat{h}_0)
\sqrt{T_1} \widehat{r}_T(\widehat{h}_0) \ ,
\end{align*}
which is asymptotically normal in that $T_{1}^{1/2} \big( \widehat{\bbeta}_{\text{db}} - \bbeta^* \big)$ converges in distribution to $
N \big( 0, S_1^* S_2^* S_1\sT \big)$ as $T \rightarrow \infty$ where $S_1^*$ and $S_2^*$ are given as follows:
\begin{align*}
&
S_1^*
=
\bigg[
\frac{\partial \EXP \big\{ {\Psi}_{\post} (\bO_t \con \bbeta^*, h_0) \big\} }{\partial \bbeta} 
\bigg]^{-1} 
\\
&
S_2^*
=
\VAR
\left[
{\Psi}_{\post} (\bO_t \con \bbeta^*, h_0)
-
\frac{\partial \tau(t \con \bbeta^*)}{\partial \bbeta} 
\EXP \big\{ g_{0,h_0} (\bW_{\D t}) \cond \potY{t}{0} \big\} \big\{ \potY{t}{0} - h_0(\bW_{\D t} ) \big\}
\right] \ ,
\end{align*}
Here, ${\Psi}_{\post} (\bO_t \con \bbeta,h )$ is defined in \eqref{eq-supp-postEE} for $t=T_0+1,\ldots,T$. 
The ATT estimator is obtained from the plug-in formula $\widehat{\tau}_t = \tau(t \con \widehat{\bbeta}_{\text{db}})$. Consequently, inference of the ATT can be attained based on the standard delta-method applied to the asymptotic normal distribution of $\widehat{\bbeta}_{\text{db}}$.



\newpage

\section{Proof of Theorems}	\label{sec:supp:proof}


\subsection{Proof of Theorems \ref{thm:SC}, \ref{thm:ATT}, \ref{thm:identification cov}, \ref{thm:Extension NP}, and \ref{thm:Extension NP Cov}}

We first prove the most general case with a nonlinear bridge function $h^*$ and under the presence of covariates (i.e., Theorem \ref{thm:Extension NP Cov}). For the pre-treatment periods $t=1,\ldots,T_0$, we establish
\begin{align*}
y 
=
\EXP \big\{ h^* (\bW_{\D t}, \bX_{0t}, \bX_{\D t}) \cond \potY{t}{0} = y, \bX_{0t}, \bX_{\D t}  \big\} 
=
\EXP \big\{ h^* ( \bW_{\D t}, \bX_{0t}, \bX_{\D t} ) \cond Y_t=y, \bX_{0t}, \bX_{\D t} \big\} \ .
\end{align*} 
The first equality holds from Assumption \ref{assumption:SC NP Cov}. The second equality holds from Assumption \ref{assumption:consistency}.  

Furthermore, for any $t=1,\ldots,T$, we establish
\begin{align*} 
\EXP \big\{ \potY{t}{0} \cond \bX_{0 t} , \bX_{\D t} \big\} 
& = 
\EXP \big[
\EXP \big\{ h^*(\bW_{\D t}, \bX_{0 t} , \bX_{\D t}) \cond \potY{t}{0} , \bX_{0 t} , \bX_{\D t} \big\}		
\cond \bX_{0 t} , \bX_{\D t}
\big]
\nonumber 
\\
&
=		
\EXP \big\{ h^* (\bW_{\D t}, \bX_{0 t} , \bX_{\D t}) \cond \bX_{0 t} , \bX_{\D t} \big\} \ .
\end{align*}	
The first equality holds from Assumption \ref{assumption:SC NP Cov}, and the second equality holds from the law of iterated expectation. Therefore, we have 
\begin{align}
    \label{eq-Identity1}
    \EXP \big\{ \potY{t}{0} \big\} 
    =
    \EXP \big\{ h^* (\bW_{\D t}, \bX_{0 t} , \bX_{\D t}) \big\} \ .
\end{align}

Next, we prove the second result. For the post-treatment periods $t=T_0+1,\ldots,T$, we have 
\begin{align*}
& \EXP \big\{ \potY{t}{1} - \potY{t}{0} \big\} = 
\EXP \big\{ Y_t - \potY{t}{0} \big\}
=
\EXP \big\{ Y_t - h^* (\bW_{\D t}, \bX_{0 t} , \bX_{\D t}) \big\}
\end{align*}
The first equality holds from Assumption \ref{assumption:consistency}. The second equality holds from \eqref{eq-Identity1}.

We remark that the other Theorems can be shown in a similar manner. Specifically, we take $h^*(\bW_{\D t}, \bX_{0t}, \bX_{\D t}) = \bX_{0t}\T \bdelta_{0}^* + \bW_{\D t}\T \bgamma^* - \bX_{\D t}\T \bdelta_{\D}^* $ for the linear bridge function case,  and we view covariates as empty sets when there is no covariate available. The results can then be established under Assumptions \ref{assumption:SC}, \ref{assumption:SC Cov}, and \ref{assumption:SC NP}. 

\subsection{Proof of Theorems \ref{thm:AN} and \ref{thm:AN Cov}}		\label{sec:supp:AN}

We denote the collection of parameters as $\btheta$. 
When there is no covariate as in Section \ref{sec:Estimation}, we have $\btheta = (\bgamma, \bbeta)$; when there are covariates as in Section \ref{sec:Cov}, we have $\btheta = (\bgamma, \bbeta, \bdelta)$. 
Let the moment function be $\Psi(\bO_t \con \btheta)$ where $\mathcal{O}= \text{supp}(\bO_t)$ and $\Theta = \text{supp}(\btheta)$. 
We denote the true parameters as $\btheta^*$.
\begin{remark}
We will consider a simple case as an example to motivate the assumptions below. Specifically, suppose the treatment effect function is constant, i.e., $\Psi(\bO_t \con \bbeta) = \bbeta$. Then, the moment function is
\begin{align}		\label{eq-supp-simple}
\Psi (\bO_t \con \bgamma, \bbeta)
=
\begin{bmatrix}
\Psi_{\pre} (\bO_t \con \bgamma)
\\
\Psi_{\post} (\bO_t \con \bgamma , \bbeta)
\end{bmatrix}
=
\begin{bmatrix}
(1-A_t)
\bg_t(Y_t)
\big( Y_t - \bW_{\D t} \T \bgamma \big)
\\
A_t 
\big(
Y_t - \bW_{\D t} \T \bgamma - \bbeta
\big)
\end{bmatrix}
\ .
\end{align}
Note that the derivative of \eqref{eq-supp-simple} is
\begin{align*}
\frac{\partial \Psi (\bO_t \con \bgamma, \bbeta)}{\partial (\bgamma, \bbeta)\T }
=
-
\begin{bmatrix}
(1-A_t) \bg_t(Y_t) \bW_{\D t} \T & \bzero_{p}
\\
A_t \bW_{\D t} \T & A_t
\end{bmatrix}
\in \R^{(p+1) \times (d+1)}
\ .
\end{align*}
\end{remark}


We present proofs for Theorem \ref{thm:AN} under different sets of regularity conditions. In the first proof, we establish the result using commonly employed conditions for time series data, such as strong stationarity and ergodicity. In the second proof, we establish the result under more general conditions, avoiding the need to rely on these strong assumptions of stationarity and ergodicity.

\vspace{0.5cm}
\noindent \textbf{Proof 1: Proof under Strong Stationarity and Ergodicity}
\vspace{0.5cm}

We first present regularity conditions, which are the extensions of assumptions in Chapter 3 of \citet{Hall2004GMM}.

\begin{REG}[Sufficiently Long Pre- and Post-treatment Periods] 	\label{assumption-reg-11}
As $T \rightarrow \infty$, $T_0, T_1 \rightarrow \infty$ and $T_1/T_0 \rightarrow r \in (0,\infty)$. 
\end{REG} 
Regularity Condition \ref{assumption-reg-11} is reasonable if the pre- and post-treatment periods are of roughly the same size and sufficiently large.


\begin{REG}[Compactness] 	\label{assumption-reg-7}
The parameter space $\Theta$ is compact.
\end{REG}
Regularity Condition \ref{assumption-reg-7} is standard in parametric estimation.

\begin{REG}[Weighting Matrix] 	\label{assumption-reg-5}
$\widehat{\Omega}$ is a positive semi-definite matrix, and converges to a non-random positive definite matrix $\Omega^*$ as $T \rightarrow \infty$.
\end{REG}
Regularity Condition \ref{assumption-reg-5} is easily satisfied if $\widehat{\Omega}$ is chosen as a fixed matrix such as the identity matrix.


\begin{REG}[Strict Stationarity]		\label{assumption-reg-1}
The process $\big\{ \bO_t \big\}_{t \in \mathbbm{Z}}$ is strictly stationary, i.e., for any subset $\{t_1,\ldots,t_n \} \subseteq \mathbbm{Z}$ and any $c$, we have $	\big\{ \bO_{t_1},\ldots,\bO_{t_n} \big\}
\stackrel{D}{=}
\big\{ \bO_{t_1+c},\ldots,\bO_{t_n+c} \big\}$.
\end{REG}
Regularity Condition \ref{assumption-reg-1} implies that any expectation of $\bO_t$ does not depend on $t$. Unfortunately, Regularity Condition \ref{assumption-reg-1} is insufficient to apply the law of large numbers and central limit theorem. Therefore, the following ergodicity assumption is required:

\begin{REG}[Ergodicity] 	\label{assumption-reg-6}
The process $\big\{ \bO_t \big\}_{t \in \mathbbm{Z}}$ is ergodic.
\end{REG}
Under Regularity Condition \ref{assumption-reg-1} and Regularity Condition \ref{assumption-reg-6}, the sample average of $f(\bO_t)$ converges to its expectation, i.e., $T^{-1} \sum_{t=1}^{T} f(\bO_t) \stackrel{P}{\rightarrow} \EXP \big\{ f(\bO_t) \big\}$.


\begin{REG}[Regularity Conditions for $\Psi$]		\label{assumption-reg-2}
The moment function $\Psi(\bO_{t} \con \btheta) : \mathcal{O} \otimes \Theta \rightarrow \R^{p+b}$ satisfies
\begin{itemize}[itemsep=0cm]
\item[(i)] $\Psi(\bO_{t} \con \btheta)$ is continuous on $\Theta$ for each $\bO_{t} \in \mathcal{O}$;
\item[(ii)] $\EXP \big\{ \Psi(\bO_{t} \con \btheta) \big\} $ exists and is finite for any $\btheta \in \Theta$;
\item[(iii)] $\EXP \big\{ \Psi(\bO_{t} \con \btheta) \big\}$ is continuous on $\Theta$.
\item[(iv)] $\bg_t$ is time-invariant, i.e., $\bg_t(y) = \bg(y)$ for all $t$.
\end{itemize}
\end{REG}
Under model \eqref{eq-supp-simple}, Regularity Condition \ref{assumption-reg-2} is satisfied if $ \EXP \big\{ \bg_t(Y_t) Y_t \big\}$ and $ \EXP \big\{ \bg_t(Y_t) \bW_{\D t}\T \big\} $ for $t=1,\ldots,T_0$ and $\EXP \big( Y_t \big)$ and $\EXP \big( \bW_{\D t} \big)$ for $t=T_0+1,\ldots,T$ are finite and well-defined. Hereafter, we assume that these vectors and matrices are finite and well-defined. 

\begin{REG}[Regularity for $\partial \Psi( \bO_{t} \con \btheta) / \partial \btheta \T$ \& Local Identification] 	\label{assumption-reg-3}
The function $\partial \Psi( \bO_{t} \con \btheta) / \partial \btheta \T \in \R^{(p+b) \times (d+b)}$ satisfies:
\begin{itemize}[itemsep=0cm]
\item[(i)] $\partial \Psi( \bO_{t} \con \btheta) / \partial \btheta \T$ exists and is continuous on $\Theta$ for each $\bO_{t} \in \mathcal{O}$;
\item[(ii)] $\btheta ^* \in \text{int} (\Theta)$; 
\item[(iii)] $\EXP \big\{ \partial \Psi( \bO_{t} \con \btheta) / \partial \btheta \T \big\}$ exists and is finite;
\item[(iv)] $\text{rank} \big( \EXP \big\{ \partial \Psi( \bO_{t} \con \btheta) / \partial \btheta \T \big\} \big) = d+b$.
\end{itemize}
\end{REG}
Under model \eqref{eq-supp-simple}, Regularity Condition \ref{assumption-reg-3} (iii) is satisfied if $\EXP \big\{ \bg_t(Y_t) \bW_{\D t}\T \big\}$ for $t=1,\ldots,T_0$ and $\EXP \big( \bW_{\D t} \big)$ for $t=T_0+1,\ldots,T$ are finite and well-defined. Condition (iv) is satisfied if the vectors $ \boldr_i = \EXP \big\{ \bg_t(Y_t) W_{it} \big\}/ \EXP \big( W_{it} \big) \in \R^{p}$ $(i \in \D_1,\ldots,\D_d)$ are linearly independent.

\begin{REG}[Population Moment Restriction \& Global Identification] 	\label{assumption-reg-4}
The true parameter
$\btheta^*$ is the unique parameter that satisfies $ \EXP \big\{ \Psi(\bO_{t} \con \btheta^* ) \big\} = 0$.
\end{REG}
Under model \eqref{eq-supp-simple}, Regularity Condition \ref{assumption-reg-4} is satisfied if $\bG_{YW}^* $ is of full column rank, i.e., $\text{rank}(\bG_{YW}^*) = d$.




\begin{REG}[Domination of $\Psi$] 	\label{assumption-reg-8}
The expectation of the moment function is uniformly bounded over $\Theta$, i.e., $\sup_{\btheta \in \Theta} \EXP \big\{ \big\| \Psi( \bO_{t} \con \btheta) \big\|_2 \big\} < \infty$.
\end{REG}
Under model \eqref{eq-supp-simple}, Regularity Condition \ref{assumption-reg-8} is satisfied if the second-order moments of $\bg_t(Y_t) Y_t$ and $\bg_t(Y_t) \bW_{\D t}$ for $t=1,\ldots,T_0$ and $Y_t$ and $\bW_{\D t}$ for $t=T_0+1,\ldots,T$ are finite.


\begin{REG}[Properties of the Variance] 	\label{assumption-reg-9}
Following conditions hold:
\begin{itemize}[itemsep=0cm]
\item[(i)] $\EXP \big\{ \Psi(\bO_t \con \btheta^*) \Psi (\bO_t \con \btheta^*) \T \big\}$ exists and finite
\item[(ii)] $\Sigma_2^* = \lim_{T \rightarrow \infty} \VAR \big\{ T^{-1/2} \sum_{t=1}^{T} \Psi (\bO_t \con \btheta^*) \big\}$ exists and is a finite valued positive definite matrix.
\end{itemize} 
\end{REG}
Under model \eqref{eq-supp-simple}, Regularity Condition \ref{assumption-reg-9} (i) is satisfied if the second-order moments of $\bg_t(Y_t) Y_t$, $\bg_t(Y_t) \bW_{\D t}$ for $t=1,\ldots,T_0$ and those of $Y_t$ and $\bW_{\D t}$ for $t=T_0+1,\ldots,T$ are finite. Condition (ii) is satisfied if $\big\{ \bO_t \big\}$ are weakly serially dependent (e.g., m-dependent).


\begin{REG}[Properties of Gradient] 	\label{assumption-reg-10}
Following conditions hold for $\Theta_N$, some neighborhood of $\btheta^*$:
\begin{itemize}[itemsep=0cm]
\item[(i)] $\EXP \big\{ \partial \Psi( \bO_t \con \btheta) / \partial \btheta \T \big\}$ is continuous on $\Theta_N$;
\item[(ii)] $\sup_{\btheta \in \Theta_N} \big\| T^{-1} \sum_{t=1}^{T} \partial \Psi( \bO_t \con \btheta) / \partial \btheta \T - \EXP \big\{ \partial \Psi( \bO_t \con \btheta) / \partial \btheta \T \big\} \big\|_2 = o_P(1)$.
\end{itemize}
\end{REG}
Under model \eqref{eq-supp-simple}, Regularity Condition \ref{assumption-reg-10} (i) is satisfied if $\EXP \big\{ \bg_t(Y_t) \bW_{\D t}\T \big\}$ for $t=1,\ldots,T_0$ and $\EXP \big( \bW_{\D t} \big)$ for $t=T_0+1,\ldots,T$ are finite and well-defined. Regularity Condition \ref{assumption-reg-10} (ii) is satisfied if 
\begin{align*}
& 
\frac{1}{T_0} \sum_{t=1}^{T_0} \bg_t(Y_t) \bW_{\D t} \T 
\stackrel{P}{\rightarrow} \EXP \big\{ \bg_t(Y_t) \bW_{\D t} \T \big\} 
\ , \ 
&&
t=1,\ldots,T_0
\\
&
\frac{1}{T_1} \sum_{t=T_0+1}^{T} \bW_{\D t} 
\stackrel{P}{\rightarrow} 
\EXP \big( \bW_{\D t} \big)
\ , \
&&
t=T_0+1,\ldots,T \ .
\end{align*}
Note that these two conditions are satisfied under the asymptotic regime in Regularity Condition \ref{assumption-reg-11}, stationarity (Regularity Condition \ref{assumption-reg-1}), and ergodicity (Regularity Condition \ref{assumption-reg-6}).

Under these assumptions, the asymptotic normality of $(\widehat{\bgamma} , \widehat{\bbeta})$ is achieved by Theorem 3.2 of \citet{Hall2004GMM}. 

\vspace{0.5cm}
\noindent \textbf{Proof 2: Proof without Strong Stationarity and Ergodicity}
\vspace{0.5cm}

We adapt the proof of Theorem S6 in \citet{Qiu2022} to our setting. First, we introduce regularity conditions that are applicable to general cases, without imposing strict requirements of strong stationarity and ergodicity.
 

\begin{GREG}[Sufficiently Long Pre- and Post-treatment Periods] 	\label{assumption-General-1}
As $T \rightarrow \infty$, $T_0, T_1 \rightarrow \infty$ and $T_1/T_0 \rightarrow r \in (0,\infty)$. 
\end{GREG} 
\begin{GREG}[Compactness] 	\label{assumption-General-2}
The parameter space $\Theta$ is compact.
\end{GREG} 
\begin{GREG}[Weighting Matrix] 	\label{assumption-General-3}
$\widehat{\Omega}$ is a positive semi-definite matrix, and converges to a non-random positive definite matrix $\Omega^*$ as $T \rightarrow \infty$.
\end{GREG}
General Regularity Conditions \ref{assumption-General-1}--\ref{assumption-General-3} are the same as Regularity Conditions \ref{assumption-reg-11}--\ref{assumption-reg-5}, respectively.




\begin{GREG}[Regularity Conditions for $\Psi$]
\label{assumption-General-4}
The moment function $\Psi(\bO_{t} \con \btheta) : \mathcal{O} \otimes \Theta \rightarrow \R^{p+b}$ satisfies
\begin{itemize}[itemsep=0cm]
\item[(i)] $ \lim_{T\rightarrow \infty} \big\{ T^{-1} \sum_{t=1}^{T} \Psi(\bO_{t} \con \btheta) \big\} $ is continuous on $\Theta$ for each $\bO_{t} \in \mathcal{O}$;
\item[(ii)] $ \lim_{T\rightarrow \infty} \big[ T^{-1} \sum_{t=1}^{T} \EXP \big\{ \Psi(\bO_{t} \con \btheta) \big\} \big] $ exists and is finite for any $\btheta \in \Theta$;
\item[(iii)] $ \lim_{T\rightarrow \infty} \big[ T^{-1} \sum_{t=1}^{T} \EXP \big\{ \Psi(\bO_{t} \con \btheta) \big\} \big] $ is continuous on $\Theta$.
\end{itemize}
\end{GREG}

\begin{GREG}[Regularity for $\partial \Psi( \bO_{t} \con \btheta) / \partial \btheta \T$ \& Local Identification] 	\label{assumption-General-5}
The function $\partial \Psi( \bO_{t} \con \btheta) / \partial \btheta \T \in \R^{(p+b) \times (d+b)}$ satisfies:
\begin{itemize}[itemsep=0cm]
\item[(i)] $ \lim_{T\rightarrow \infty} \big\{ T^{-1} \sum_{t=1}^{T} \partial \Psi( \bO_{t} \con \btheta) / \partial \btheta \T \big\} $ exists and is continuous on $\Theta$ for each $\bO_{t} \in \mathcal{O}$;
\item[(ii)] $ T^{-1} \sum_{t=1}^{T} \partial \Psi( \bO_{t} \con \btheta) / \partial \btheta \T $ is uniformly bounded for all $T=1,2,\ldots$
\item[(iii)] $\btheta ^* \in \text{int} (\Theta)$; 
\item[(iv)] $ \lim_{T\rightarrow \infty} \big[ T^{-1} \sum_{t=1}^{T} \EXP \big\{ \partial \Psi( \bO_{t} \con \btheta) / \partial \btheta \T \big\} \big] $ exists and is finite;
\item[(v)] $\text{rank} \big( \lim_{T\rightarrow \infty} \big[ T^{-1} \sum_{t=1}^{T} \EXP \big\{ \partial \Psi( \bO_{t} \con \btheta) / \partial \btheta \T \big\} \big] \big) = d+b$.
\end{itemize}
\end{GREG}
\begin{GREG}[Population Moment Restriction \& Global Identification] 	\label{assumption-General-6}
The true parameter
$\btheta^*$ is the unique parameter that satisfies $ \lim_{T\rightarrow \infty} \big[ T^{-1} \sum_{t=1}^{T} \EXP \big\{ \Psi(\bO_{t} \con \btheta^*) \big\} \big] = 0 $.
\end{GREG}
General Regularity Conditions \ref{assumption-General-4}--\ref{assumption-General-6} are similar to Regularity Conditions \ref{assumption-reg-2}--\ref{assumption-reg-4}. 

\begin{GREG}[Uniform Weak Law of Large Numbers for $\Psi$] 	\label{assumption-General-UWLLN}
\begin{align*}
\sup_{\btheta \in \Theta}
\bigg\|
\frac{1}{T} \sum_{t=1}^{T} \Psi(\bO_t \con \btheta) -
\lim_{T' \rightarrow \infty}
\frac{1}{T'} \sum_{t=1}^{T'} \EXP \big\{\Psi(\bO_t \con \btheta) \big\}
\bigg\|
=
o_P(1) \text{ as } T \rightarrow \infty \ .
\end{align*}
\end{GREG}

\begin{GREG}[Uniform Weak Law of Large Numbers for the Gradient of $\Psi$] 	\label{assumption-General-UWLLN2}
\begin{align*}
\sup_{\btheta \in \Theta}
\bigg\|
\frac{1}{T} \sum_{t=1}^{T} \frac{\partial}{\partial \btheta \T } \Psi(\bO_t \con \btheta) -
\lim_{T' \rightarrow \infty}
\frac{1}{T'} \sum_{t=1}^{T'} \EXP \bigg\{ \frac{\partial}{\partial \btheta \T } \Psi(\bO_t \con \btheta) \bigg\}
\bigg\|
=
o_P(1) \text{ as } T \rightarrow \infty \ .
\end{align*}
\end{GREG}
General Regularity Conditions \ref{assumption-General-UWLLN} and \ref{assumption-General-UWLLN2} hold if the underlying process is strictly stationary, strongly mixing, or $\phi$-mixing processes; see \citet{Andrews1988}, \citet[Chapter 5]{PP1997} and \citet[Section S2]{Qiu2022} for details. 

\begin{GREG}[Asymptotic Normality]
\label{assumption-General-AN} 
As $T \rightarrow \infty$, we have
\begin{align*}
&
\frac{1}{\sqrt{T}} \sum_{t=1}^{T} \Psi(\bO_t \con \btheta^*)
\text{ converges in distribution to }
N (0, \Sigma_2^*)
\ , \\
&
\Sigma_2^* = \lim_{T \rightarrow \infty} \VAR \bigg\{ \frac{1}{\sqrt{T}} \sum_{t=1}^{T} \Psi (\bO_t \con \btheta^*) \bigg\} \ .
\end{align*}
Here, $\Sigma_2^*$ is a finite valued positive definite matrix. 
\end{GREG}
Assumption \ref{assumption-General-AN} directly assumes the asymptotic normality of the sample mean of the estimating function; see Section S2 of \citet{Qiu2022} for the plausibility of the assumption. We remark that General Regularity Conditions \ref{assumption-General-UWLLN}--\ref{assumption-General-AN} are satisfied under Regularity Conditions \ref{assumption-reg-1}--\ref{assumption-reg-10}. 

Under General Regularity Conditions \ref{assumption-General-1}--\ref{assumption-General-AN}, we establish the desired result. We simply denote $\widehat{\Psi}(\btheta) = T^{-1} \sum_{t=1}^T \Psi(\bO_t \con \btheta)$ and ${\Psi}(\btheta) = \lim_{T \rightarrow \infty} T^{-1} \sum_{t=1}^T \EXP \big\{ \Psi(\bO_t \con \btheta) \big\}$. First, we establish consistency, i.e., $\widehat{\btheta} = (\widehat{\bgamma}, \widehat{\bbeta}) = (\bgamma^*, \bbeta^*) + o_P(1) = \btheta^* + o_P(1)$. From General Regularity Conditions \ref{assumption-General-3} and \ref{assumption-General-UWLLN}, we establish the following result as $T \rightarrow \infty$:
\begin{align}
&
\sup_{\btheta \in \Theta}
\left\|
\big\{
\widehat{\Psi}(\btheta)
\big\}\T 
\widehat{\Omega}
\big\{
\widehat{\Psi}(\btheta)
\big\} 
-
\big\{
\Psi (\btheta)
\big\}\T 
\Omega^*
\big\{
\Psi (\btheta)
\big\}
\right\|
=
o_P(1) \ .
\label{eq-UWLLN-GMM}
\end{align}
Note that $\widehat{\btheta}$ is the minimizer of $\big\{
\widehat{\Psi}(\btheta)
\big\}\T 
\widehat{\Omega}
\big\{
\widehat{\Psi}(\btheta)
\big\}$. 

Let $s > 0$ be an arbitrary positive constant. 
From \eqref{eq-UWLLN-GMM} and the definition of $\widehat{\btheta}$, the following conditions hold with probability tending to one:
\begin{align*}
&
\left\|
\big\{
\widehat{\Psi}(\btheta^*)
\big\}\T 
\widehat{\Omega}
\big\{
\widehat{\Psi}(\btheta^*)
\big\} 
-
\big\{
\Psi (\btheta^*)
\big\}\T 
\Omega^*
\big\{
\Psi (\btheta^*)
\big\}
\right\| < s/2
\\
&
\left\|
\big\{
\widehat{\Psi}(\widehat{\btheta})
\big\}\T 
\widehat{\Omega}
\big\{
\widehat{\Psi}(\widehat{\btheta})
\big\} 
-
\big\{
\Psi (\widehat{\btheta})
\big\}\T 
\Omega^*
\big\{
\Psi (\widehat{\btheta})
\big\}
\right\| < s/2 
\\ 
&
\big\{
\widehat{\Psi} (\widehat{\btheta})
\big\}\T 
\widehat{\Omega}
\big\{
\widehat{\Psi} (\widehat{\btheta})
\big\}
\leq
\big\{
\widehat{\Psi} (\btheta^*)
\big\}\T 
\widehat{\Omega}
\big\{
\widehat{\Psi} (\btheta^*)
\big\}
 \ .
\end{align*}
These three inequalities imply that
\begin{align*}
\big\{
\Psi(\widehat{\btheta})
\big\}\T 
\Omega^*
\big\{
\Psi(\widehat{\btheta})
\big\}
<
\big\{
\Psi(\btheta^*)
\big\}\T 
\Omega^*
\big\{
\Psi(\btheta^*)
\big\} + s
=
s \ .
\end{align*} 
The right hand side reduces to $s$ under General Regularity Condition \ref{assumption-General-6}. 

Let $\mathcal{N} \in \Theta$ be an arbitrary open set containing $\btheta^*$. Let us define the following quantity:
\begin{align*}
s_0
=
\inf_{\btheta \in \Theta \setminus \mathcal{N} }
\big\{ 
\Psi(\btheta)
\big\}\T
\Omega^*
\big\{ 
\Psi(\btheta)
\big\} .
\end{align*}
Combining the fact that $\Theta \setminus \mathcal{N}$ is compact under General Regularity Condition \ref{assumption-General-2}, and General Regularity Conditions \ref{assumption-General-2}, \ref{assumption-General-4}, \ref{assumption-General-6}, we establish $s_0$ is positive. Therefore, by taking $s>s_0$, the event $\big\{ \big\{
\Psi(\widehat{\btheta})
\big\}\T 
\widehat{\Omega}
\big\{
\Psi(\widehat{\btheta})
\big\}
< s_0 \big\}$ occurs with probability tending to one, which further implies that $\widehat{\btheta} \in \mathcal{N}$. Since $\mathcal{N}$ is arbitrary chosen, this establishes $\widehat{\btheta} = \btheta^* + o_P(1)$ as $T \rightarrow \infty$. 

Next, we establish the asymptotic normality of $\widehat{\btheta}$. Under General Regularity Condition \ref{assumption-General-5}, the following expansion holds from a first-order Taylor expansion and the consistency of $\widehat{\btheta}$:
\begin{align*}
&
\widehat{\Psi}( \widehat{\btheta})
=
\widehat{\Psi}( {\btheta}^*)
+
\bigg\{
\frac{\partial}{\partial \btheta\T} \widehat{\Psi}( \btheta) \bigg|_{\btheta=\btheta^*}
\bigg\}
(\widehat{\btheta}-\btheta^*)
+
o_P \Big( \big\| \widehat{\btheta} - \btheta^* \big\| \Big)
\ . 
\end{align*}
The first order condition of $\widehat{\btheta}$ along with General Regularity Condition \ref{assumption-General-5} implies
\begin{align*}
0
& =
\frac{1}{2}
\frac{\partial}{\partial \btheta\T} 
\Big[
\big\{ \widehat{\Psi}( \btheta)
\big\}\T \widehat{\Omega} 
\big\{ \widehat{\Psi}( \btheta)
\big\} \Big] \Big|_{\btheta=\widehat{\btheta}}
\\
&
=
\bigg\{
\frac{\partial}{\partial \btheta\T} \widehat{\Psi}( \btheta) \bigg|_{\btheta=\btheta^*}
\bigg\}\T
\widehat{\Omega}
\big\{ \widehat{\Psi}( \widehat{\btheta})
\big\}
\\
&
=
\bigg\{
\frac{\partial}{\partial \btheta\T} \widehat{\Psi}( \btheta) \bigg|_{\btheta=\btheta^*}
\bigg\}\T
\widehat{\Omega}
\big\{ \widehat{\Psi}( \btheta^*)
\big\}
+
\bigg\{
\frac{\partial}{\partial \btheta\T} \widehat{\Psi}( \btheta) \bigg|_{\btheta=\btheta^*}
\bigg\}\T
\widehat{\Omega}
\bigg\{
\frac{\partial}{\partial \btheta\T} \widehat{\Psi}( \btheta) \bigg|_{\btheta=\btheta^*}
\bigg\} 
(\widehat{\btheta}-\btheta^*)
\\
&
\hspace*{0.5cm}
+
o_P \Big( \big\| \widehat{\btheta} - \btheta^* \big\| \Big) \ .
\end{align*}
Therefore, by multiplying $T^{1/2}$, we get
\begin{align*}
0
& 
=
\bigg\{
\frac{\partial}{\partial \btheta\T} \widehat{\Psi}( \btheta) \bigg|_{\btheta=\btheta^*}
\bigg\}\T
\widehat{\Omega}
\bigg\{
\frac{1}{T^{1/2}}
\sum_{t=1}^{T} \Psi(\bO_t \con \btheta^* )
\bigg\}
\\
&
\hspace*{0.3cm}
+
\bigg\{
\frac{\partial}{\partial \btheta\T} \widehat{\Psi}( \btheta) \bigg|_{\btheta=\btheta^*}
\bigg\}\T
\widehat{\Omega}
\bigg\{
\frac{\partial}{\partial \btheta\T} \widehat{\Psi}( \btheta) \bigg|_{\btheta=\btheta^*}
\bigg\}
T^{1/2}
(\widehat{\btheta}-\btheta^*)
+
o_P \Big( T^{1/2} \big\| \widehat{\btheta} - \btheta^* \big\| \Big)
\\
&
=
\underbrace{
\bigg\{
\frac{\partial}{\partial \btheta\T} {\Psi}( \btheta) \bigg|_{\btheta=\btheta^*}
\bigg\}\T }_{=:G\sT}
\Omega^*
\bigg\{
\lim_{T \rightarrow \infty}
\frac{1}{T^{1/2}}
\sum_{t=1}^{T} \Psi(\bO_t \con \btheta^* )
\bigg\}
\\
&
\hspace*{0.3cm}
+
\bigg\{
\frac{\partial}{\partial \btheta\T} {\Psi}( \btheta) \bigg|_{\btheta=\btheta^*}
\bigg\}\T
\Omega^*
\bigg\{
\frac{\partial}{\partial \btheta\T} {\Psi}( \btheta) \bigg|_{\btheta=\btheta^*}
\bigg\} 
T^{1/2}
(\widehat{\btheta}-\btheta^*)
+
o_P \Big( T^{1/2} \big\| \widehat{\btheta} - \btheta^* \big\| + 1 \Big) \ .
\end{align*}
The last equality holds from General Regularity Conditions \ref{assumption-General-3}, \ref{assumption-General-UWLLN}, and \ref{assumption-General-UWLLN2} and the consistency of $\widehat{\btheta}$. This implies
\begin{align*}
T^{1/2} \big( \widehat{\btheta} - \btheta^* \big)
=
\Big ( G\sT \Omega^* G^* \Big)^{-1}
G\sT \Omega^* 
\bigg\{ 
\frac{1}{T^{1/2}}
\sum_{t=1}^{T} \Psi(\bO_t \con \btheta^* )
\bigg\}
+
o_P \Big( T^{1/2} \big\| \widehat{\btheta} - \btheta^* \big\| + 1 \Big) \ .
\end{align*}
From General Regularity Condition \ref{assumption-General-3} and \ref{assumption-General-AN}, we find $T^{1/2} \big( \widehat{\btheta} - \btheta^* \big) = O_P(1)$, implying that $o_P\big( T^{1/2} \big\| \widehat{\btheta} - \btheta^* \big\| + 1 \big) = o_P(1)$. Therefore, from Slutsky's theorem, we find 
\begin{align*}
T^{1/2} \big( \widehat{\btheta} - \btheta^* \big)
& \text{ converges in distribution to }
N \big( 0, \big \{ G\sT \Omega^* G^* \big\}^{-1}
G\sT \Omega^* \Sigma_2 G^* \Omega^*
\big \{ G\sT \Omega^* G^* \big\}^{-\T} \big)
\end{align*}
Note that $\big\{ G\sT \Omega^* G^* \big\}^{-1}
G\sT \Omega^* \Sigma_2 G^* \Omega^*
\big \{ G\sT \Omega^* G^* \big\}^{-\T} = \Sigma_1^* \Sigma_2 \Sigma_1\sT $. 
This concludes the proof.






 
 
\subsection{Proof of Theorem \ref{thm:Reg GMM}}		\label{sec:supp:Reg GMM Proof}

We denote the collection of parameters as $\btheta=(\bgamma,\bbeta)$ and the true parameters as $\btheta^* = (\bgamma^*,\bbeta^*)$. Similar to the proofs of Theorem \ref{thm:AN} in Section \ref{sec:supp:AN}, we present proofs under different sets of regularity conditions. 

\vspace{0.5cm}
\noindent \textbf{Proof 1: Proof under Strong Stationarity and Ergodicity}
\vspace{0.5cm}




The solution to $\ell_2$-penalized GMM is given as follows:
\begin{align*}
\widehat{\btheta}_{\lambda}
&
=
\argmin_{\btheta}
\Big[
\big\{ \widehat{\Psi}( \btheta) \big\} \T 
\widehat{\Omega}
\big\{ \widehat{\Psi}( \btheta) \big\} 
+ 
\lambda \big\| \bgamma \big\|_2^2
\Big] 
\ , \ 
\widehat{\Omega}
=
\begin{bmatrix}
 \widehat{\Omega}_{\pre} & 0 \\ 0 & \widehat{\Omega}_{\post}
\end{bmatrix}
\ .
\end{align*}
The solution to the minimization problem satisfies the following first order condition, i.e., 
\begin{align*}
 0
& =
\frac{1}{2}
\frac{\partial}{\partial \btheta\T} 
\Big[
\big\{ \widehat{\Psi}( \btheta)
\big\}\T \widehat{\Omega} 
\big\{ \widehat{\Psi}( \btheta)
\big\}
+ \lambda \big\| \bgamma \big\|_2^2
\Big] \Big|_{\btheta=\widehat{\btheta}_{\lambda}} \ .
\end{align*}
Therefore, from a few lines of algebra, we find $\widehat{\bgamma}_{\lambda}$ and $\bgamma^*$ are represented as
\begin{align*}
&
\widehat{\bgamma}_\lambda
=
\big( \widehat{\bG}_{YW} \T \widehat{\Omega}_{\pre} \widehat{\bG}_{YW} + \lambda \widehat{\Omega}_{\pre} \big)^{-1}
\big( \widehat{\bG}_{YW} \T \widehat{\Omega}_{\pre} \widehat{\bG}_{YY} \big)
\ , \
&&
{\bgamma} 
=
\big( {\bG}_{YW} \sT {\Omega}_{\pre}^* {\bG}_{YW}^* \big)^{-1}
\big( {\bG}_{YW} \sT {\Omega}_{\pre}^* {\bG}_{YY}^* \big)
\ .
\end{align*}
where $\bG_{YW}^*$, $\bG_{YY}^*$, $\widehat{\bG}_{YW}$, and $\widehat{\bG}_{YY}$ are defined in \eqref{eq-Gyw Gyy}, which is rewritten below for readability:
\begin{align}
&
\bG_{YW}^* = \frac{1}{T_0} 
\sum_{t=1}^{T_0} \EXP \big\{ \bg_t(Y_t) \bW_{\D t} \T \big\} \in \R^{p \times d}
\ , 
&&
\bG_{YY}^* = \frac{1}{T_0} 
\sum_{t=1}^{T_0} \EXP \big\{ \bg_t(Y_t) Y_t \big\} \in \R^{p}
\ ,
\nonumber
\\
\tag{\ref{eq-Gyw Gyy}}
&
\widehat{\bG}_{YW} =
\frac{1}{T_0} 
\sum_{t=1}^{T_0} \bg_t(Y_t) \bW_{\D t}\T \in \R^{p \times d}
\ , 
&&
\widehat{\bG}_{YY} = 
\frac{1}{T_0} \sum_{t=1}^{T_0} \bg_t(Y_t) Y_t \in \R^{p} \ .
\end{align}
The forms of $\widehat{\bbeta}_\lambda$ and $\bbeta_\lambda^*$ depend on $\tau(t \con \bbeta)$, which are defined as follows:
\begin{align*}
 &
 \widehat{\bbeta}_\lambda = \argmin_{\bbeta} 
 \big\{ \widehat{\Psi}_{\post}(\widehat{\bgamma}_{\lambda}, \bbeta) \big\} \T
 \widehat{\Omega}_{\post}
 \big\{ \widehat{\Psi}_{\post}(\widehat{\bgamma}_{\lambda}, \bbeta) \big\} 
 \ , \\
 &
 {\bbeta}^* = \argmin_{\bbeta} 
 \big\{ {\Psi}_{\post}(\bgamma^*, \bbeta) \big\} \T
 {\Omega}_{\post}^*
 \big\{ {\Psi}_{\post}(\bgamma^*, \bbeta) \big\}
\end{align*}
where
\begin{align*}
 &
 \widehat{\Psi}_{\post} (\bgamma,\bbeta)
 =
 \frac{1}{T_1} \sum_{t=T+0+1}^{T} \frac{\partial}{\partial \bbeta\T} \tau(t \con \bbeta) \big\{ Y_t - \bW_{\D t}\T \bgamma - \tau(t \con \bbeta) \big\} 
 \ , \\
 &
 {\Psi}_{\post} (\bgamma,\bbeta)
 =
 \frac{1}{T_1} \sum_{t=T+0+1}^{T}
 \EXP \bigg[ \frac{\partial}{\partial \bbeta\T} \tau(t \con \bbeta) \big\{ Y_t - \bW_{\D t}\T \bgamma - \tau(t \con \bbeta) \big\} \bigg]
 \ .
\end{align*}
In the constant treatment effect case, $\widehat{\bbeta}_{\lambda}$ and $\bbeta^*$ reduces to
\begin{align*}
&
\widehat{\bbeta}_{\lambda}
=
\frac{1}{T_1}
\sum_{t=T_0+1}^{T}
\big( Y_t - \bW_{\D t} \T \widehat{\bgamma}_\lambda \big)
\ , \
&&
\bbeta^*
=
\frac{1}{T_1} \sum_{t=T+0+1}^{T}
\EXP \big( Y_t - \bW_{\D t}\T \bgamma^* \big)
\ .
\end{align*}



First, we prove that $ (\widehat{\bgamma}_\lambda , \widehat{\bbeta}_\lambda ) \stackrel{P}{\rightarrow} ({\bgamma}^*, {\bbeta}^* )$. This is trivial because, under the asymptotic regime in Regularity Condition \ref{assumption-reg-11}, stationarity (Regularity Condition \ref{assumption-reg-1}), and ergodicity (Regularity Condition \ref{assumption-reg-6}), we have
\begin{align*}
&
\widehat{\bG}_{YY} \stackrel{P}{\rightarrow} \bG_{YY}^*
\ , \
\widehat{\bG}_{YW} \stackrel{P}{\rightarrow} \bG_{YW}^* 
\ , \
\frac{T_1}{T_0} \rightarrow r
\ , \\
&
\frac{1}{T_1} \sum_{t=T_0+1}^{T} Y_t \stackrel{P}{\rightarrow} \frac{1}{T_1} \sum_{t=T_0+1}^{T} \EXP \big( Y_{t} \big)
\ , \
\frac{1}{T_1} \sum_{t=T_0+1}^{T} \bW_{\D t} \stackrel{P}{\rightarrow} \frac{1}{T_1} \sum_{t=T_0+1}^{T} \EXP \big( \bW_{\D t} \big)
\ .
\end{align*}
We then have the following result from the continuous mapping theorem:
\begin{align*}
\widehat{\bgamma}_\lambda
& =
\big( \widehat{\bG}_{YW} \T \widehat{\Omega} \widehat{\bG}_{YW} + \lambda \widehat{\Omega} \big)^{-1}
\big( \widehat{\bG}_{YW} \T \widehat{\Omega} \widehat{\bG}_{YY} \big)
\stackrel{P}{\rightarrow}
\big( {\bG}_{YW} \sT {\Omega}^* {\bG}_{YW}^* \big)^{-1}
\big( {\bG}_{YW} \sT {\Omega}^* {\bG}_{YY}^* \big)
=
\bgamma^* 
\ .
\end{align*}	
Therefore, using the convergence of $\widehat{\bgamma}_\lambda \stackrel{P}{\rightarrow} \bgamma^* $, we can establish the convergence of $\widehat{\bbeta}_\lambda \stackrel{P}{\rightarrow} \bbeta^* $. For instance, under the constant treatment effect case, we have
\begin{align*}	
\widehat{\bbeta}_\lambda
& =
\bigg(
\frac{1}{T_1} \sum_{t=T_0+1}^{T} Y_t
-
\frac{1}{T_1} \sum_{t=T_0+1}^{T} W_{\D t}\T \widehat{\bgamma}_\lambda \bigg)
\stackrel{P}{\rightarrow}
\EXP \big( Y_t - \bW_{\D t}\T \bgamma^* \big)
=
{\bbeta}_\lambda^* \ .
\end{align*}
We can establish the consistency under nonlinear treatment effects using the uniform weak law of large numbers; see \textbf{Proof 2} below for details. 

To establish the asymptotic normality, we use the following Taylor expansion, which holds from the consistency of $\widehat{\btheta}$ and the Regularity Conditions \ref{assumption-reg-11}--\ref{assumption-reg-10}:
\begin{align*} 
&
\widehat{\Psi}( \widehat{\btheta}_{\lambda})
=
\widehat{\Psi}( {\btheta}^*)
+
\bigg\{
\frac{\partial}{\partial \btheta\T} \widehat{\Psi}( \btheta) \bigg|_{\btheta=\btheta^*}
\bigg\}
(\widehat{\btheta}_{\lambda}-\btheta^*)
+
o_P \Big( \big\| \widehat{\btheta}_{\lambda} - \btheta^* \big\| \Big)
\ . 
\end{align*}
Combining the first order condition of $\widehat{\btheta}_{\lambda}$ and regularity conditions on $\Psi(\bO_t \con \btheta)$ and $\partial \Psi(\bO_t \con \btheta)/\partial \btheta\T$, we get
\begin{align*}
0
& =
\frac{1}{2}
\frac{\partial}{\partial \btheta\T} 
\Big[
\big\{ \widehat{\Psi}( \btheta)
\big\}\T \widehat{\Omega} 
\big\{ \widehat{\Psi}( \btheta)
\big\}
+ \lambda \big\| \bgamma \big\|_2^2
\Big] \Big|_{\btheta=\widehat{\btheta}_{\lambda}}
\\
&
=
\bigg\{
\frac{\partial}{\partial \btheta\T} \widehat{\Psi}( \btheta) \bigg|_{\btheta=\btheta^*}
\bigg\}\T
\widehat{\Omega}
\big\{ \widehat{\Psi}( \widehat{\btheta}_{\lambda})
\big\}
+ 
\lambda \widehat{\gamma}_{\lambda}
\\
&
=
\bigg\{
\frac{\partial}{\partial \btheta\T} \widehat{\Psi}( \btheta) \bigg|_{\btheta=\btheta^*}
\bigg\}\T
\widehat{\Omega}
\big\{ \widehat{\Psi}( \btheta^*)
\big\}
+
\bigg\{
\frac{\partial}{\partial \btheta\T} \widehat{\Psi}( \btheta) \bigg|_{\btheta=\btheta^*}
\bigg\}\T
\widehat{\Omega}
\bigg\{
\frac{\partial}{\partial \btheta\T} \widehat{\Psi}( \btheta) \bigg|_{\btheta=\btheta^*}
\bigg\} 
(\widehat{\btheta}-\btheta^*)
\\
&
\hspace*{0.5cm}
+
o_P \Big( \big\| \widehat{\btheta}_{\lambda} - \btheta^* \big\| + T^{-1/2} \Big) \ .
\end{align*}
The last line is from $T^{1/2} \lambda \widehat{\gamma}_{\lambda} = T^{1/2} \lambda ( \widehat{\gamma}_{\lambda} + \gamma^* ) = o_P(1)$. Therefore, by multiplying $T^{1/2}$, we get
\begin{align*}
0
&
=
\bigg\{
\frac{\partial}{\partial \btheta\T} \widehat{\Psi}( \btheta) \bigg|_{\btheta=\btheta^*}
\bigg\}\T
\widehat{\Omega}
\bigg\{
\frac{1}{T^{1/2}}
\sum_{t=1}^{T} \Psi(\bO_t \con \btheta^* )
\bigg\}
\\
&
\hspace*{0.3cm}
+
\bigg\{
\frac{\partial}{\partial \btheta\T} \widehat{\Psi}( \btheta) \bigg|_{\btheta=\btheta^*}
\bigg\}\T
\widehat{\Omega}
\bigg\{
\frac{\partial}{\partial \btheta\T} \widehat{\Psi}( \btheta) \bigg|_{\btheta=\btheta^*}
\bigg\}
T^{1/2}
(\widehat{\btheta}_{\lambda} -\btheta^*)
+
o_P \Big( T^{1/2} \big\| \widehat{\btheta}_{\lambda} - \btheta^* \big\|+ 1 \Big)
\\
&
=
\bigg\{
\underbrace{
\frac{\partial}{\partial \btheta\T} {\Psi}( \btheta) \bigg|_{\btheta=\btheta^*}
}_{=:G^*}
\bigg\}\T 
\Omega^*
\bigg\{
\lim_{T \rightarrow \infty}
\frac{1}{T^{1/2}}
\sum_{t=1}^{T} \Psi(\bO_t \con \btheta^* )
\bigg\}
\\
&
\hspace*{0.3cm}
+
\bigg\{
\frac{\partial}{\partial \btheta\T} {\Psi}( \btheta) \bigg|_{\btheta=\btheta^*}
\bigg\}\T
\Omega^*
\bigg\{
\frac{\partial}{\partial \btheta\T} {\Psi}( \btheta) \bigg|_{\btheta=\btheta^*}
\bigg\} 
T^{1/2}
(\widehat{\btheta}_{\lambda}-\btheta^*)
+
o_P \Big( T^{1/2} \big\| \widehat{\btheta}_{\lambda} - \btheta^* \big\| + 1 \Big) \ .
\end{align*}
This implies
\begin{align*}
T^{1/2} \big( \widehat{\btheta}_{\lambda} - \btheta^* \big)
=
\Big ( G\sT \Omega^* G^* \Big)^{-1}
G\sT \Omega^* 
\bigg\{ 
\frac{1}{T^{1/2}}
\sum_{t=1}^{T} \Psi( \bO_t \con \btheta^* )
\bigg\}
+
o_P \Big( T^{1/2} \big\| \widehat{\btheta}_{\lambda} - \btheta^* \big\| + 1 \Big) \ .
\end{align*}
Since $T^{-1/2}
\sum_{t=1}^{T} \Psi( \bO_t \con \btheta^* )=O_P(1)$, we find $T^{1/2} \big( \widehat{\btheta}_{\lambda} - \btheta^* \big) = O_P(1)$, implying that $o_P\big( T^{1/2} \big\| \widehat{\btheta}_{\lambda} - \btheta^* \big\| + 1 \big) = o_P(1)$. Therefore, from Slutsky's theorem, we find 
\begin{align*}
T^{1/2} \big( \widehat{\btheta}_{\lambda} - \btheta^* \big)
& \text{ converges in distribution to }
N \big( 0, \big \{ G\sT \Omega^* G^* \big\}^{-1}
G\sT \Omega^* \Sigma_2 G^* \Omega^*
\big \{ G\sT \Omega^* G^* \big\}^{-\T} \big)
\ .
\end{align*}
Note that $\big\{ G\sT \Omega^* G^* \big\}^{-1}
G\sT \Omega^* \Sigma_2 G^* \Omega^*
\big \{ G\sT \Omega^* G^* \big\}^{-\T} = \Sigma_1^* \Sigma_2 \Sigma_1\sT $. 
This concludes the proof.





\vspace{0.5cm}
\noindent \textbf{Proof 2: Proof without Strong Stationarity and Ergodicity}
\vspace{0.5cm}



Under General Regularity Conditions \ref{assumption-General-1}--\ref{assumption-General-AN}, we establish the desired result. We simply denote $\widehat{\Psi}(\btheta) = T^{-1} \sum_{t=1}^T \Psi(\bO_t \con \btheta)$ and ${\Psi}(\btheta) = \lim_{T \rightarrow \infty} T^{-1} \sum_{t=1}^T \EXP \big\{ \Psi(\bO_t \con \btheta) \big\}$. First, we establish consistency, i.e., $\widehat{\btheta}_{\lambda} = (\widehat{\bgamma}_{\lambda}, \widehat{\bbeta}_{\lambda}) = (\bgamma^*, \bbeta^*) + o_P(1) = \btheta^* + o_P(1)$. From the triangle inequality, we find
\begin{align*}
&
\left\|
\big\{
\widehat{\Psi}(\btheta)
\big\}\T 
\widehat{\Omega}
\big\{
\widehat{\Psi}(\btheta)
\big\} 
+ \lambda \big\| \bgamma \big\|_2^2
-
\big\{
{\Psi}(\btheta)
\big\}\T 
\Omega^*
\big\{
{\Psi}(\btheta)
\big\}
\right\|
\\
&
\leq
\left\|
\big\{
\widehat{\Psi}(\btheta)
\big\}\T 
\widehat{\Omega}
\big\{
\widehat{\Psi}(\btheta)
\big\} 
-
\big\{
{\Psi}(\btheta)
\big\}\T 
\Omega^*
\big\{
{\Psi}(\btheta)
\big\}
\right\|
+
\lambda \big\| \bgamma \big\|_2^2 \ .
\end{align*}
Note that $\lambda = o(T^{-1/2})$ and $\big\| \bgamma \big\|_2 \leq \text{diam}(\Theta)$ for any $\bgamma$. which implies $\sup_{\btheta \in \Theta}
\lambda \big\| \bgamma \big\|_2^2 = o(1)$. Therefore, combining with \eqref{eq-UWLLN-GMM} which is valid under General Regularity Conditions \ref{assumption-General-3} and \ref{assumption-General-UWLLN}, we obtain
\begin{align} \label{eq-UWLLN-GMM2}
&
\sup_{\btheta \in \Theta}
\left\|
\big\{
\widehat{\Psi}(\btheta)
\big\}\T 
\widehat{\Omega}
\big\{
\widehat{\Psi}(\btheta)
\big\} 
+ \lambda \big\| \bgamma \big\|_2^2
-
\big\{
{\Psi}(\btheta)
\big\}\T 
\Omega^*
\big\{
{\Psi}(\btheta)
\big\}
\right\|
\nonumber
\\
&
\leq
\sup_{\btheta \in \Theta}
\left\|
\big\{
\widehat{\Psi}(\btheta)
\big\}\T 
\widehat{\Omega}
\big\{
\widehat{\Psi}(\btheta)
\big\} 
-
\big\{
{\Psi}(\btheta)
\big\}\T 
\Omega^*
\big\{
{\Psi}(\btheta)
\big\}
\right\|
+
\sup_{\btheta \in \Theta}
\lambda \big\| \bgamma \big\|_2^2
\nonumber
\\
&
= o_P(1) \ .
\end{align} 
Note that $\widehat{\btheta}_{\lambda}$ is the minimizer of $\big\{
\widehat{\Psi}(\btheta)
\big\}\T 
\widehat{\Omega}
\big\{
\widehat{\Psi}(\btheta)
\big\} 
+ \lambda \big\| \bgamma \big\|_2^2 $. 

Let $s > 0$ be an arbitrary positive constant. 
From \eqref{eq-UWLLN-GMM2} and the definition of $\widehat{\btheta}_{\lambda}$, the following conditions hold with probability tending to one:
\begin{align*}
&
\left\|
\big\{
\widehat{\Psi}(\btheta^*)
\big\}\T 
\widehat{\Omega}
\big\{
\widehat{\Psi}(\btheta^*)
\big\} 
+
\lambda \big\| \bgamma^* \big\|_2^2
-
\big\{
\Psi (\btheta^*)
\big\}\T 
\Omega^*
\big\{
\Psi (\btheta^*)
\big\}
\right\| < s/2
\\
&
\left\|
\big\{
\widehat{\Psi}(\widehat{\btheta}_{\lambda})
\big\}\T 
\widehat{\Omega}
\big\{
\widehat{\Psi}(\widehat{\btheta}_{\lambda})
\big\} 
+
\lambda \big\| \widehat{\bgamma}_{\lambda} \big\|_2^2
-
\big\{
\Psi (\widehat{\btheta}_{\lambda})
\big\}\T 
\Omega^*
\big\{
\Psi (\widehat{\btheta}_{\lambda})
\big\}
\right\| < s/2 
\\ 
&
\big\{
\widehat{\Psi} (\widehat{\btheta}_{\lambda})
\big\}\T 
\widehat{\Omega}
\big\{
\widehat{\Psi} (\widehat{\btheta}_{\lambda})
\big\}
+
\lambda \big\| \widehat{\bgamma}_{\lambda} \big\|_2^2
\leq
\big\{
\widehat{\Psi} (\btheta^*)
\big\}\T 
\widehat{\Omega}
\big\{
\widehat{\Psi} (\btheta^*)
\big\}
+
\lambda \big\| \bgamma^* \big\|_2^2
 \ .
\end{align*}
These three inequalities imply that
\begin{align*}
\big\{
\Psi(\widehat{\btheta}_{\lambda})
\big\}\T 
\Omega^*
\big\{
\Psi(\widehat{\btheta}_{\lambda})
\big\} 
<
\big\{
\Psi(\btheta^*)
\big\}\T 
\Omega^*
\big\{
\Psi(\btheta^*)
\big\} 
+ s
=
s \ .
\end{align*} 
The right hand side reduces to $s$ under General Regularity Condition \ref{assumption-General-6}. 

Let $\mathcal{N} \in \Theta$ be an arbitrary open set containing $\btheta^*$. Let us define the following quantity:
\begin{align*}
s_0
=
\inf_{\btheta \in \Theta \setminus \mathcal{N} }
\big\{ 
\Psi(\btheta)
\big\}\T
\Omega^*
\big\{ 
\Psi(\btheta)
\big\} .
\end{align*}
Combining the fact that $\Theta \setminus \mathcal{N}$ is compact under General Regularity Condition \ref{assumption-General-2}, and General Regularity Conditions \ref{assumption-General-2}, \ref{assumption-General-4}, \ref{assumption-General-6}, we establish $s_0$ is positive. Therefore, by taking $s>s_0$, the event $\big\{ \big\{
\Psi(\widehat{\btheta}_{\lambda})
\big\}\T 
\widehat{\Omega}
\big\{
\Psi(\widehat{\btheta}_{\lambda})
\big\}
< s_0 \big\}$ occurs with probability tending to one, which further implies that $\widehat{\btheta}_{\lambda} \in \mathcal{N}$. Since $\mathcal{N}$ is arbitrary chosen, this establishes $\widehat{\btheta}_{\lambda} = \btheta^* + o_P(1)$ as $T \rightarrow \infty$. 

Next, we establish the asymptotic normality of $\widehat{\btheta}_{\lambda}$. Under General Regularity Condition \ref{assumption-General-5}, the following expansion holds from a first-order Taylor expansion and the consistency of $\widehat{\btheta}$:
\begin{align*} 
&
\widehat{\Psi}( \widehat{\btheta}_{\lambda})
=
\widehat{\Psi}( {\btheta}^*)
+
\bigg\{
\frac{\partial}{\partial \btheta\T} \widehat{\Psi}( \btheta) \bigg|_{\btheta=\btheta^*}
\bigg\}
(\widehat{\btheta}_{\lambda}-\btheta^*)
+
o_P \Big( \big\| \widehat{\btheta}_{\lambda} - \btheta^* \big\| \Big)
\ . 
\end{align*}
The first order condition of $\widehat{\btheta}_{\lambda}$ along with General Regularity Condition \ref{assumption-General-5} implies
\begin{align*}
0
& =
\frac{1}{2}
\frac{\partial}{\partial \btheta\T} 
\Big[
\big\{ \widehat{\Psi}( \btheta)
\big\}\T \widehat{\Omega} 
\big\{ \widehat{\Psi}( \btheta)
\big\}
+ \lambda \big\| \bgamma \big\|_2^2
\Big] \Big|_{\btheta=\widehat{\btheta}_{\lambda}}
\\
&
=
\bigg\{
\frac{\partial}{\partial \btheta\T} \widehat{\Psi}( \btheta) \bigg|_{\btheta=\btheta^*}
\bigg\}\T
\widehat{\Omega}
\big\{ \widehat{\Psi}( \widehat{\btheta}_{\lambda})
\big\}
+ 
\lambda \widehat{\gamma}_{\lambda}
\\
&
=
\bigg\{
\frac{\partial}{\partial \btheta\T} \widehat{\Psi}( \btheta) \bigg|_{\btheta=\btheta^*}
\bigg\}\T
\widehat{\Omega}
\big\{ \widehat{\Psi}( \btheta^*)
\big\}
+
\bigg\{
\frac{\partial}{\partial \btheta\T} \widehat{\Psi}( \btheta) \bigg|_{\btheta=\btheta^*}
\bigg\}\T
\widehat{\Omega}
\bigg\{
\frac{\partial}{\partial \btheta\T} \widehat{\Psi}( \btheta) \bigg|_{\btheta=\btheta^*}
\bigg\} 
(\widehat{\btheta}-\btheta^*)
\\
&
\hspace*{0.5cm}
+
o_P \Big( \big\| \widehat{\btheta}_{\lambda} - \btheta^* \big\| + T^{-1/2} \Big) \ .
\end{align*}
The last line is from $T^{1/2} \lambda \widehat{\gamma}_{\lambda} = T^{1/2} \lambda ( \widehat{\gamma}_{\lambda} + \gamma^* ) = o_P(1)$. Therefore, by multiplying $T^{1/2}$, we get
\begin{align*}
0
&
=
\bigg\{
\frac{\partial}{\partial \btheta\T} \widehat{\Psi}( \btheta) \bigg|_{\btheta=\btheta^*}
\bigg\}\T
\widehat{\Omega}
\bigg\{
\frac{1}{T^{1/2}}
\sum_{t=1}^{T} \Psi(\bO_t \con \btheta^* )
\bigg\}
\\
&
\hspace*{0.3cm}
+
\bigg\{
\frac{\partial}{\partial \btheta\T} \widehat{\Psi}( \btheta) \bigg|_{\btheta=\btheta^*}
\bigg\}\T
\widehat{\Omega}
\bigg\{
\frac{\partial}{\partial \btheta\T} \widehat{\Psi}( \btheta) \bigg|_{\btheta=\btheta^*}
\bigg\}
T^{1/2}
(\widehat{\btheta}_{\lambda} -\btheta^*)
+
o_P \Big( T^{1/2} \big\| \widehat{\btheta}_{\lambda} - \btheta^* \big\|+ 1 \Big)
\\
&
=
\bigg\{
\underbrace{
\frac{\partial}{\partial \btheta\T} {\Psi}( \btheta) \bigg|_{\btheta=\btheta^*}
}_{=:G^*}
\bigg\}\T 
\Omega^*
\bigg\{
\lim_{T \rightarrow \infty}
\frac{1}{T^{1/2}}
\sum_{t=1}^{T} \Psi(\bO_t \con \btheta^* )
\bigg\}
\\
&
\hspace*{0.3cm}
+
\bigg\{
\frac{\partial}{\partial \btheta\T} {\Psi}( \btheta) \bigg|_{\btheta=\btheta^*}
\bigg\}\T
\Omega^*
\bigg\{
\frac{\partial}{\partial \btheta\T} {\Psi}( \btheta) \bigg|_{\btheta=\btheta^*}
\bigg\} 
T^{1/2}
(\widehat{\btheta}_{\lambda}-\btheta^*)
+
o_P \Big( T^{1/2} \big\| \widehat{\btheta}_{\lambda} - \btheta^* \big\| + 1 \Big) \ .
\end{align*}
The last equality holds from General Regularity Conditions \ref{assumption-General-3}, \ref{assumption-General-UWLLN}, and \ref{assumption-General-UWLLN2} and the consistency of $\widehat{\btheta}_{\lambda}$. This implies
\begin{align*}
T^{1/2} \big( \widehat{\btheta}_{\lambda} - \btheta^* \big)
=
\Big ( G\sT \Omega^* G^* \Big)^{-1}
G\sT \Omega^* 
\bigg\{ 
\frac{1}{T^{1/2}}
\sum_{t=1}^{T} \Psi( \bO_t \con \btheta^* )
\bigg\}
+
o_P \Big( T^{1/2} \big\| \widehat{\btheta}_{\lambda} - \btheta^* \big\| + 1 \Big) \ .
\end{align*}
From General Regularity Condition \ref{assumption-General-3} and \ref{assumption-General-AN}, we find $T^{1/2} \big( \widehat{\btheta}_{\lambda} - \btheta^* \big) = O_P(1)$, implying that $o_P\big( T^{1/2} \big\| \widehat{\btheta}_{\lambda} - \btheta^* \big\| + 1 \big) = o_P(1)$. Therefore, from Slutsky's theorem, we find 
\begin{align*}
T^{1/2} \big( \widehat{\btheta}_{\lambda} - \btheta^* \big)
& \text{ converges in distribution to }
N \big( 0, \big \{ G\sT \Omega^* G^* \big\}^{-1}
G\sT \Omega^* \Sigma_2 G^* \Omega^*
\big \{ G\sT \Omega^* G^* \big\}^{-\T} \big)
\ .
\end{align*}
Note that $\big\{ G\sT \Omega^* G^* \big\}^{-1}
G\sT \Omega^* \Sigma_2 G^* \Omega^*
\big \{ G\sT \Omega^* G^* \big\}^{-\T} = \Sigma_1^* \Sigma_2 \Sigma_1\sT $. 
This concludes the proof.






 