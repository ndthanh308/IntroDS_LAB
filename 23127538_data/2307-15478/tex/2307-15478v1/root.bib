@inproceedings{gastLightweightProbabilisticDeep2018a,
  title = {Lightweight {{Probabilistic Deep Networks}}},
  booktitle = {{{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}}},
  author = {Gast, Jochen and Roth, Stefan},
  date = {2018-06},
  year = {2018},
  pages = {3369--3378},
  location = {{Salt Lake City, UT}},
  doi = {10.1109/CVPR.2018.00355},
  urldate = {2022-09-02},
  abstract = {Even though probabilistic treatments of neural networks have a long history, they have not found widespread use in practice. Sampling approaches are often too slow already for simple networks. The size of the inputs and the depth of typical CNN architectures in computer vision only compound this problem. Uncertainty in neural networks has thus been largely ignored in practice, despite the fact that it may provide important information about the reliability of predictions and the inner workings of the network. In this paper, we introduce two lightweight approaches to making supervised learning with probabilistic deep networks practical: First, we suggest probabilistic output layers for classification and regression that require only minimal changes to existing networks. Second, we employ assumed density filtering and show that activation uncertainties can be propagated in a practical fashion through the entire network, again with minor changes. Both probabilistic networks retain the predictive power of the deterministic counterpart, but yield uncertainties that correlate well with the empirical error induced by their predictions. Moreover, the robustness to adversarial examples is significantly increased.},
  eventtitle = {2018 {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}} ({{CVPR}})},
  isbn = {978-1-5386-6420-9},
  langid = {english},
  keywords = {Anomaly Paper},
  file = {/home/cornelius/Zotero/storage/J7ETDGD4/Gast and Roth - 2018 - Lightweight Probabilistic Deep Networks.pdf}
}

@inproceedings{ukaiObstacleDetectionSequence2004,
  title = {Obstacle Detection with a Sequence of Ultra Telephoto Camera Images},
  booktitle = {Computers in {{Railways IX}}},
  author = {Ukai, M},
  year = {2004},
  pages = {10},
  abstract = {In order to detect obstacles on railway tracks, we have developed a forward monitoring system, which plays an important role to ensure the safety of train operation. In this paper, we propose a method of detecting obstacles with an image sequence taken by an ultra telephoto lens camera mounted on train which monitors the status of the track for 600m (brake distance) or over ahead of the train. We first discussed the railway track environment recognition. Particularly extraction of two parallel rails is a fundamental issue in applying image processing to railways. It is inevitable to limit the area where obstacles exist. A first detection algorithm is based on the analysis of optical flow which characteristically occurs in those moving obstacles. Assuming that pixels corresponding to the same object have similar flow vectors, we extract a connected region with similar flow vectors. Then we focused on the stationary obstacle edge and the brightness contrast difference from the background. Compensation for the flow field caused by camera blur was performed, so that our method works correctly even on running trains. Furthermore, we adopted a vibration-proofing device to reduce blurs of image, and a wide dynamic range camera so as not to be influenced by fluctuations such as outdoor lighting inconsistency. The experimental results using a real image sequence proves the effectiveness of our proposed method.},
  langid = {english},
  keywords = {Anomaly Paper,IMPORTANT,Sony Proposal},
  file = {/home/cornelius/Zotero/storage/FCHP6ZCS/Ukai - 2004 - Obstacle detection with a sequence of ultra teleph.pdf}
}


@article{durrant2022, 
title={Object-Level Data Augmentation for Deep Learning-Based Obstacle Detection in Railways}, 
volume={12}, 
ISSN={2076-3417}, 
DOI={10.3390/app122010625}, 
number={20}, 
journal={Applied Sciences}, 
publisher={MDPI AG}, 
author={Franke, Marten and Gopinath, Vaishnavi and Ristić-Durrant, Danijela and Michels, Kai}, 
year={2022}, 
month={Oct}, 
pages={10625} }

@article{voneinem2022, 
title={High-Precision Low-Cost Gimballing Platform for Long-Range Railway Obstacle Detection}, 
volume={22}, 
ISSN={1424-8220},  
DOI={10.3390/s22020474}, 
number={2}, 
journal={MDPI Sensors}, 
publisher={MDPI AG}, 
author={Assaf, Elio Hajj and von Einem, Cornelius and Cadena, Cesar and Siegwart, Roland and Tschopp, Florian}, 
year={2022}, 
pages={474} }



@inproceedings{kwonEmpiricalStudyNetwork2018,
  title = {An {{Empirical Study}} on {{Network Anomaly Detection Using Convolutional Neural Networks}}},
  booktitle = {{{IEEE}} {{International Conference}} on {{Distributed Computing Systems}}},
  author = {Kwon, Donghwoon and Natarajan, Kathiravan and Suh, Sang C. and Kim, Hyunjoo and Kim, Jinoh},
  date = {2018-07},
  year = {2018},
  pages = {1595--1598},
  location = {{Vienna}},
  urldate = {2022-09-02},
  abstract = {Recently, anomaly detection plays a vital role in many areas such as bank fraud, medical examinations, etc. to identify unexpected patterns or events. In particular, this technique in conjunction with deep learning has been applied to network anomaly detection to improve performance. In this research, we establish three different Convolution Neural Network (CNN) architectures based on structural scalability (i.e. shallow CNN, moderate CNN, and deep CNN). Three public traffic datasets are used to evaluate performance of the models, and the shallow CNN model mostly shows higher detection accuracy than other two models. Three models also show a relatively competitive detection accuracy compared to conventional machine learning classifiers. However, experimental results confirm that all three models may have variances in terms of detection accuracy. Furthermore, performance of the shallow CNN model is compared to other deep learning models based on Fully Connected Neural Networks (FCN), Variatinal AutoEncoder (VAE), and Sequenceto-Sequence structure with LSTM (Seq2Seq-LSTM) evaluated in our previous research. We observed that the shallow CNN model occasionally outperforms VAE models, but does not work better than FCN and Seq2Seq-LSTM.},
  eventtitle = {{{International Conference}} on {{Distributed Computing Systems}}},
  isbn = {978-1-5386-6871-9},
  langid = {english},
  keywords = {Anomaly Paper},
  file = {/home/cornelius/Zotero/storage/FNDFHWP8/Kwon et al. - 2018 - An Empirical Study on Network Anomaly Detection Us.pdf}
}

@article{ruffUnifyingReviewDeep2021,
  title = {A {{Unifying Review}} of {{Deep}} and {{Shallow Anomaly Detection}}},
  author = {Ruff, Lukas and Kauffmann, Jacob R. and Vandermeulen, Robert A. and Montavon, Gregoire and Samek, Wojciech and Kloft, Marius and Dietterich, Thomas G. and Muller, Klaus-Robert},
  date = {2021-05},
  year = {2021},
  journal = {Proceedings of the IEEE},
  shortjournal = {Proc. IEEE},
  volume = {109},
  number = {5},
  pages = {756--795},
  issn = {0018-9219, 1558-2256},
  doi = {10.1109/JPROC.2021.3052449},
  urldate = {2022-09-02},
  langid = {english},
  keywords = {Anomaly Paper},
  file = {/home/cornelius/Zotero/storage/GG47TCPR/Ruff et al. - 2021 - A Unifying Review of Deep and Shallow Anomaly Dete.pdf}
}





@article{oteguiSurveyTrainPositioning2017,
  title = {A {{Survey}} of {{Train Positioning Solutions}}},
  author = {Otegui, Jon and Bahillo, Alfonso and Lopetegi, Iban and Diez, Luis Enrique},
  date = {2017-10-15},
  year = {2017},
  journal = {IEEE Sensors Journal},
  shortjournal = {IEEE Sensors J.},
  volume = {17},
  number = {20},
  pages = {6788--6797},
  issn = {1530-437X, 1558-1748, 2379-9153},
  doi = {10.1109/JSEN.2017.2747137},
  urldate = {2021-07-01},
  abstract = {Positioning accurately and safely a train is nowadays a great challenge. That includes currently available railway sensors and new candidate sensors for data fusion. Global Navigation Satellite System and Inertial Measurement Unit sensors arise as prominent technologies to incorporate in railways. Although satellite-based train localization tests can be found in the scientific literature, there are no common criteria to evaluate the performance of the positioning achieved. In this paper, a series of criteria is defined and justified in order to be able to evaluate the most recent and relevant works related to train positioning. The results of this comparative analysis are gathered in tables, where the criteria defined are applied to the works compiled. According to the results obtained, a research gap in safety related applications is found. It is concluded that the economic viability of given solutions should be explored, so as to design an on-board train-integrated positioning system.},
  langid = {english},
  keywords = {Anomaly Paper},
  file = {/home/cornelius/Zotero/storage/S8Y3LVMG/Otegui et al. - 2017 - A Survey of Train Positioning Solutions.pdf}
}

@article{Wang2022,
  doi = {10.1007/s10489-022-03911-8},
  year = {2022},
  month = jul,
  publisher = {Springer Science and Business Media {LLC}},
  author = {Yao Wang and Zujun Yu and Liqiang Zhu},
  title = {Intrusion detection for high-speed railways based on unsupervised anomaly detection models},
  journal = {Applied Intelligence}
}

@article{tschoppExperimentalComparisonVisualAided2019,
  title = {Experimental {{Comparison}} of {{Visual-Aided Odometry Methods}} for {{Rail Vehicles}}},
  author = {Tschopp, Florian and Schneider, Thomas and Palmer, Andrew W. and Nourani-Vatani, Navid and Cadena, Cesar and Siegwart, Roland and Nieto, Juan},
  date = {2019-04},
  year = {2019},
  journal = {IEEE Robotics and Automation Letters},
  shortjournal = {IEEE Robot. Autom. Lett.},
  volume = {4},
  number = {2},
  pages = {1815--1822},
  issn = {2377-3766, 2377-3774},
  doi = {10.1109/LRA.2019.2897169},
  urldate = {2021-07-03},
  abstract = {Today, rail vehicle localization is based on infrastructure-side Balises (beacons) together with on-board odometry to determine whether a rail segment is occupied. Such a coarse locking leads to a sub-optimal usage of the rail networks. New railway standards propose the use of moving blocks centered around the rail vehicles to increase the capacity of the network. However, this approach requires accurate and robust position and velocity estimation of all vehicles. In this work, we investigate the applicability, challenges and limitations of current visual and visual-inertial motion estimation frameworks for rail applications. An evaluation against RTK-GPS ground truth is performed on multiple datasets recorded in industrial, sub-urban, and forest environments. Our results show that stereo visual-inertial odometry has a great potential to provide a precise motion estimation because of its complementing sensor modalities and shows superior performance in challenging situations compared to other frameworks.},
  langid = {english},
  keywords = {Anomaly Paper},
  file = {/home/cornelius/Zotero/storage/9FGB96SL/Tschopp et al. - 2019 - Experimental Comparison of Visual-Aided Odometry M.pdf}
}




@article{huFusionVisionGPS2006,
  title = {Fusion of Vision, {{GPS}} and {{3D}} Gyro Data in Solving Camera Registration Problem for Direct Visual Navigation},
  author = {Hu, Zhencheng and Uchimura, Keiichi},
  journal = {International Journal of ITS Research},
  date = {2006},
  year = {2006},
  volume = {4},
  number = {1},
  pages = {10},
  abstract = {This paper presents a precise and robust camera registration solution for the novel vision-based road navigation system - VICNAS, which superimposes virtual 3D navigation indicators and traffic signs upon the real road view in an Augmented Reality (AR) space. Traditional vision based or inertial sensor based solutions of registration problem are mostly designed for well-structured environment, which is however unavailable in a wide-open uncontrolled road environment for navigation purposes. This paper proposed a hybrid system that combines computer vision, GPS and 3D inertial gyroscope technologies to provide precise and robust camera pose estimation. The fusion approach is based on our PMM (parameterized model matching) algorithm, in which the road shape model is derived from the digital map data, and matched with road features extracted from real images. Inertial data estimates the initial possible motion, and also serves as relative tolerance to stable the pose output. The algorithms proposed in this paper are validated with the experimental results of real road tests under different road conditions.},
  langid = {english},
  keywords = {Anomaly Paper},
  file = {/home/cornelius/Zotero/storage/ME4YAB2Z/Hu and Uchimura - 2006 - Fusion of Vision, GPS and 3D Gyro Data in Solving .pdf}
}




@article{amaralLaserBasedObstacleDetection2016,
  title = {Laser-{{Based Obstacle Detection}} at {{Railway Level Crossings}}},
  author = {Amaral, Vítor and Marques, Francisco and Lourenço, André and Barata, José and Santana, Pedro},
  date = {2016},
  journal = {Journal of Sensors},
  shortjournal = {Journal of Sensors},
  volume = {2016},
  pages = {1--11},
  issn = {1687-725X, 1687-7268},
  doi = {10.1155/2016/1719230},
  url = {http://www.hindawi.com/journals/js/2016/1719230/},
  urldate = {2021-06-30},
  abstract = {This paper presents a system for obstacle detection in railway level crossings from 3D point clouds acquired with tilting 2D laser scanners. Although large obstacles in railway level crossings are detectable with current solutions, the detection of small obstacles remains an open problem. By relying on a tilting laser scanner, the proposed system is able to acquire highly dense and accurate point clouds, enabling the detection of small obstacles, like rocks laying near the rail. During an offline training phase, the system learns a background model of the level crossing from a set of point clouds. Then, online, obstacles are detected as occupied space contrasting with the background model. To reduce the need for manual on-site calibration, the system automatically estimates the pose of the level crossing and railway with respect to the laser scanner. Experimental results show the ability of the system to successfully perform on a set of 41 point clouds acquired in an operational one-lane level crossing.},
  langid = {english},
  file = {/home/cornelius/Zotero/storage/6R63SXDQ/Amaral et al. - 2016 - Laser-Based Obstacle Detection at Railway Level Cr.pdf}
}

@inproceedings{athiraImageProcessingBased2019,
  title = {Image {{Processing}} Based {{Real Time Obstacle Detection}} and {{Alert System}} for {{Trains}}},
  booktitle = {2019 3rd {{International}} Conference on {{Electronics}}, {{Communication}} and {{Aerospace Technology}} ({{ICECA}})},
  author = {Athira, S.},
  date = {2019-06},
  pages = {740--745},
  publisher = {{IEEE}},
  location = {{Coimbatore, India}},
  doi = {10.1109/ICECA.2019.8821816},
  url = {https://ieeexplore.ieee.org/document/8821816/},
  urldate = {2021-10-26},
  abstract = {In recent years, the occurrence of rail accidents due to the railway track obstacles are increasing at an unprecedented rate. Continuous efforts are carried out to ensure safety in rail tracks and reduces accidents. Detecting obstacle with high accuracy and low latency becomes very crucial in terms of rail safety. Existing Obstacle and Derailment Detector (ODD) detects obstacle only after obstacle is being struck and damage is made. A camera based technique is introduced to detect obstacle from a distance and alert TCMS system to stop the train. The system is embedded in car body for real time surveillance and obstacle detection. The system provides higher accuracy and timely obstacle detection in order to avoid accidents.},
  eventtitle = {2019 3rd {{International}} Conference on {{Electronics}}, {{Communication}} and {{Aerospace Technology}} ({{ICECA}})},
  isbn = {978-1-72810-167-5},
  langid = {english},
  file = {/home/cornelius/Zotero/storage/AMHTMAHX/Athira - 2019 - Image Processing based Real Time Obstacle Detectio.pdf}
}

@inproceedings{boussikRailwayObstacleDetection2021,
  title = {Railway {{Obstacle Detection Using Unsupervised Learning}}: {{An Exploratory Study}}},
  shorttitle = {Railway {{Obstacle Detection Using Unsupervised Learning}}},
  booktitle = {2021 {{IEEE Intelligent Vehicles Symposium}} ({{IV}})},
  author = {Boussik, Amine and Ben-Messaoud, Wael and Niar, Smail and Taleb-Ahmed, Abdelmalik},
  date = {2021-07-11},
  pages = {660--667},
  publisher = {{IEEE}},
  location = {{Nagoya, Japan}},
  doi = {10.1109/IV48863.2021.9575825},
  url = {https://ieeexplore.ieee.org/document/9575825/},
  urldate = {2022-06-21},
  eventtitle = {2021 {{IEEE Intelligent Vehicles Symposium}} ({{IV}})},
  isbn = {978-1-72815-394-0},
  keywords = {Anomaly Paper},
  file = {/home/cornelius/Zotero/storage/AT3S9DPL/Railway_Obstacle_Detection_Using_Unsupervised_Learning_An_Exploratory_Study.pdf}
}

@article{chenMRSIMultimodalProximity2021,
  title = {{{MRSI}}: {{A}} Multimodal Proximity Remote Sensing Data Set for Environment Perception in Rail Transit},
  shorttitle = {{{MRSI}}},
  author = {Chen, Yihao and Zhu, Ning and Wu, Qian and Wu, Cheng and Niu, Weilong and Wang, Yiming},
  date = {2021-12-29},
  journal = {International Journal of Intelligent Systems},
  shortjournal = {Int J of Intelligent Sys},
  pages = {int.22801},
  issn = {0884-8173, 1098-111X},
  doi = {10.1002/int.22801},
  url = {https://onlinelibrary.wiley.com/doi/10.1002/int.22801},
  urldate = {2022-05-04},
  langid = {english},
  file = {/home/cornelius/Zotero/storage/BWG3F4LF/Chen et al. - 2021 - MRSI A multimodal proximity remote sensing data s.pdf}
}



@inproceedings{dagvasumberelRailroadNearMissOccurrence2021,
  title = {Railroad {{Near-Miss Occurrence Detection}} and {{Risk Estimation System}} with {{Data}} from {{Camera Using Deep Learning}}},
  booktitle = {2021 5th {{International Conference}} on {{Imaging}}, {{Signal Processing}} and {{Communications}} ({{ICISPC}})},
  author = {Dagvasumberel, Amartuvshin and Myagmardulam, Bilguunmaa and Myagmar, Byambasuren and Luvsankhuu, Byambasuren and Nakayama, Tadachika},
  date = {2021-07},
  pages = {83--87},
  publisher = {{IEEE}},
  location = {{Kumamoto, Japan}},
  doi = {10.1109/ICISPC53419.2021.00023},
  url = {https://ieeexplore.ieee.org/document/9651192/},
  urldate = {2022-06-21},
  eventtitle = {2021 5th {{International Conference}} on {{Imaging}}, {{Signal Processing}} and {{Communications}} ({{ICISPC}})},
  isbn = {978-1-66542-425-7},
  file = {/home/cornelius/Zotero/storage/V9NNYHI5/Railroad_Near-Miss_Occurrence_Detection_and_Risk_Estimation_System_with_Data_from_Camera_Using_Deep_Learning.pdf}
}

@thesis{daoustInfrastructureFreeMappingLocalization,
  title = {Infrastructure-{{Free Mapping}} and {{Localization}} for {{Tunnel-Based Rail Applications Using 2D Lidar}}},
  author = {Daoust, Tyler},
  langid = {english},
  file = {/home/cornelius/Zotero/storage/ZXUSR8MN/Daoust - Infrastructure-Free Mapping and Localization for T.pdf}
}

@inproceedings{diyazitdinovProcessingMultidimensionalSignals2020,
  title = {Processing Multidimensional Signals of Video Surveillance for Recognition Railway Objects},
  booktitle = {Optical {{Technologies}} for {{Telecommunications}} 2019},
  author = {Diyazitdinov, Rinat R.},
  editor = {Burdin, Vladimir A. and Andreev, Vladimir A. and Morozov, Oleg G. and Bourdine, Anton V. and Sultanov, Albert H.},
  date = {2020-05-22},
  pages = {29},
  publisher = {{SPIE}},
  location = {{Kazan, Russian Federation}},
  doi = {10.1117/12.2566310},
  url = {https://www.spiedigitallibrary.org/conference-proceedings-of-spie/11516/2566310/Processing-multidimensional-signals-of-video-surveillance-for-recognition-railway-objects/10.1117/12.2566310.full},
  urldate = {2021-06-30},
  abstract = {The method of recognition rail fishplate was shown at this article. The method was developed for track geometry car. The automation the process of measuring is the one important thing, which improves the railway safety. The check of recognition object takes much less time than the viewing of all track video data. So the information about railway condition is quickly given to railway expert. The article is interested for developer of video data processing.},
  eventtitle = {{{XVII International Scientific}} and {{Technical Conference}} "{{Optical Technologies}} for {{Telecommunications}}"},
  isbn = {978-1-5106-3839-6 978-1-5106-3840-2},
  langid = {english},
  file = {/home/cornelius/Zotero/storage/2HDR3FPT/Diyazitdinov - 2020 - Processing multidimensional signals of video surve.pdf}
}

@article{durrantMultimodalSensorFusion,
  title = {Multimodal {{Sensor Fusion}} for {{Reliable Detection}} of {{Obstacles}} on {{Railway Tracks}}},
  author = {Ristić-Durrant, Danijela and Haseeb, Muhammad Abdul and Emami, Damon and Gräser, Axel},
  date = {2018},
  journal = {Journal of Mechatronics, Automation and Identification Technology},
  shortjournal = {Journal of Mechatronics, Automation and Identification Technology},
  volume = {3},
  number = {2},
  pages = {7},
  abstract = {In this paper, a conceptual solution and preliminary results regarding the integrated multi-sensory on-board obstacle detection (OD) system are presented. The presented system is under development within the project “SMART-SMart Automation of Rail Transport”, which is funded under the H2020-Shift2Rail funding scheme. The system combines different vision technologies (thermal camera, night vision sensor, multi stereo-vision system) with laser scanner in order to create a sensor fusion system for mid (up to 200 m) and long range (up to 1000 m) obstacle detection, which is independent of light and weather conditions. In this paper, preliminary results of the sensor fusion of two system modules, multi-baseline stereo system and laser scanner are given.},
  langid = {english},
  keywords = {Gimbal Paper},
  file = {/home/cornelius/Zotero/storage/HADYB88D/Durrant et al. - Multimodal Sensor Fusion for Reliable Detection of.pdf}
}

@inproceedings{fatihkaraApplicationIMMBased2020,
  title = {An {{Application}} of {{IMM Based Sensor Fusion Algorithm}} in {{Train Positioning System}}},
  booktitle = {2020 {{IEEE International Conference}} on {{Multisensor Fusion}} and {{Integration}} for {{Intelligent Systems}} ({{MFI}})},
  author = {Fatih Kara, Suleyman and Basaran, Burak},
  date = {2020-09-14},
  pages = {249--254},
  publisher = {{IEEE}},
  location = {{Karlsruhe, Germany}},
  doi = {10.1109/MFI49285.2020.9235250},
  url = {https://ieeexplore.ieee.org/document/9235250/},
  urldate = {2021-07-01},
  abstract = {With their serious impact on the safe and economic operation of railway domains, train positioning systems play a crucial part in railway signalling. In this paper, we present a solution for such a train positioning system by making use of a tachometer, a Doppler radar and a magnetic positioning sensor (a.k.a tag). An IMM (Interacting Multiple Model) filter based sensor fusion algorithm has been used to calculate the velocity and position of the train using the above sensors. The algorithm has been developed with SCADE (Safety Critical Application Development Environment) which is a tool frequently used for development in safety-critical systems because it drastically simplifies and accelerates the certification process required of EN 50128.},
  eventtitle = {2020 {{IEEE International Conference}} on {{Multisensor Fusion}} and {{Integration}} for {{Intelligent Systems}} ({{MFI}})},
  isbn = {978-1-72816-422-9},
  langid = {english},
  file = {/home/cornelius/Zotero/storage/2XE6GQ4G/Fatih Kara und Basaran - 2020 - An Application of IMM Based Sensor Fusion Algorith.pdf}
}

@inproceedings{fiorettiSingleCameraInspection2018,
  title = {A Single Camera Inspection System to Detect and Localize Obstacles on Railways Based on Manifold {{Kalman}} Filtering},
  booktitle = {2018 {{IEEE}} 23rd {{International Conference}} on {{Emerging Technologies}} and {{Factory Automation}} ({{ETFA}})},
  author = {Fioretti, Federica and Ruffaldi, Emanuele and Avizzano, Carlo Alberto},
  date = {2018-09},
  pages = {768--775},
  publisher = {{IEEE}},
  location = {{Turin}},
  doi = {10.1109/ETFA.2018.8502651},
  url = {https://ieeexplore.ieee.org/document/8502651/},
  urldate = {2021-10-26},
  abstract = {Railway line surveillance is important for providing safe and smooth travel of trains under effects of environmental or human-generated damages to the railway. This work presents a Structure from Motion pipeline specifically designed with the aim of supporting the monitoring operations of the railway infrastructure using a monocular camera mounted on the train’s tractor. Within this work we developed a dynamical reconstruction instrument based on the mathematics of the projective geometry for handling the problem of localization, by triangulation techniques of points, lines, whole objects and of other known elements. Exploiting the a-priori knowledge of the scene structure (known track gauge) and the camera intrinsic parameters it is possible to reconstruct in metric dimension the trajectory of the train and the position of the detected object. The approach proposed here combines Computer Vision techniques to detect the significant elements and to classify a set of features with Bayesian filtering. Algorithms for this specific purposes have been developed in order to identify the rail track geometry, and a line-based approach has been adopted to assess the camera poses. Starting from these first estimates, a manifold Unscented Kalman Filter operates on the set of robustly matched features, fusing heterogeneous cues about the camera orientation and using RANSAC to find the best solution. Consequently, the detected objects can be triangulated and localized. An analysis using real captures is reported to prove the quality of the results obtained.},
  eventtitle = {2018 {{IEEE}} 23rd {{International Conference}} on {{Emerging Technologies}} and {{Factory Automation}} ({{ETFA}})},
  isbn = {978-1-5386-7108-5},
  langid = {english},
  keywords = {Gimbal Paper},
  file = {/home/cornelius/Zotero/storage/LZYAXF2B/Fioretti et al. - 2018 - A single camera inspection system to detect and lo.pdf}
}

@inproceedings{fonsecarodriguezObstacleDetectionRails2012,
  title = {Obstacle Detection over Rails Using Hough Transform},
  booktitle = {Symposium of {{Image}}, {{Signal Processing}}, and {{Artificial Vision}}},
  author = {Fonseca Rodriguez, L. A. and Uribe, J. A. and Vargas Bonilla, J. F.},
  date = {2012-09},
  pages = {317--322},
  publisher = {{IEEE}},
  location = {{Medellin, Antioquia, Colombia}},
  doi = {10.1109/STSIVA.2012.6340602},
  url = {http://ieeexplore.ieee.org/document/6340602/},
  urldate = {2021-10-26},
  abstract = {Category (4). Autonomous systems can assist humans in the important task of safe driving. Such systems can warn people about possible risks, take actions to avoid accidents or guide the vehicle without human supervision. Whether in cars or trains or ships the artificial vision algorithms offer an alternative for the design and implementation of autonomous driving systems. In railway scenarios cameras in front of the train can assist drivers with the identification of obstacles or strange objects on the rails. Multiple factors add huge complexity to this task. The changing conditions create a scene where background is hard to detect, lighting varies and process speed must be fast. This article describes a first approximation to the problem where using the Hough transform, the rails and area of interest are detected. On this area a systematic search is done for finding and delimiting possible obstacles. Our system accomplished a real time performance when employed in the analysis of recorded videos from the driver perspective. Using digital added obstacles our algorithm detects mostly all of them and warns if the objects over the rail can create a danger to the safety travel of the train.},
  eventtitle = {2012 {{XVII Symposium}} of {{Image}}, {{Signal Processing}}, and {{Artificial Vision}} ({{STSIVA}})},
  isbn = {978-1-4673-2761-9 978-1-4673-2759-6 978-1-4673-2760-2},
  langid = {english},
  keywords = {Anomaly Paper,Gimbal Paper},
  file = {/home/cornelius/Zotero/storage/YNTMK9IQ/Fonseca Rodriguez et al. - 2012 - Obstacle detection over rails using hough transfor.pdf}
}

@inproceedings{garcia-dominguezMultisensorySystemObstacle2008,
  title = {Multi-Sensory System for Obstacle Detection on Railways},
  booktitle = {2008 {{IEEE Instrumentation}} and {{Measurement Technology Conference}}},
  author = {Garcia-Dominguez, Juan J. and Urena-Urena, Jesus and Hernandez-Alonso, Alvaro and Mazo-Quintas, Manuel and Vazquez, Juan F. and Diaz, Ma Jesus},
  date = {2008-05},
  pages = {2091--2096},
  publisher = {{IEEE}},
  location = {{Victoria, BC, Canada}},
  doi = {10.1109/IMTC.2008.4547393},
  url = {http://ieeexplore.ieee.org/document/4547393/},
  urldate = {2021-07-01},
  abstract = {In the current railway systems, it is becoming more necessary to have safety elements in order to avoid accidents. One of the causes that can provoke serious accidents is the existence of obstacles on the tracks. In this work, a multi-sensory barrier consisting of infrared (IR) and ultrasonic (US) sensors- and a vision system, is proposed in order to inform the monitoring system of the existence of obstacles. Due to the fact that any sensor has detection problems which are strongly dependent on meteorological conditions, the use of diferent sensors for the same task is justified so that the drawback of one sensor is compensatedfor by the others. The high degree of reliability needed in these environments, where the safety is fundamental, recommends the use of a multi-sensory system. Principal Components Analysis is applied to the data obtain from the barrier and from the vision system. The use of this technique with the barrier permits concluding if there are obstacles on the tracks; and with the vision system information about moving objects is obtained.},
  eventtitle = {2008 {{IEEE Instrumentation}} and {{Measurement Technology Conference}} - {{I2MTC}} 2008},
  isbn = {978-1-4244-1540-3},
  langid = {english},
  file = {/home/cornelius/Zotero/storage/HMV9SJ46/Garcia-Dominguez et al. - 2008 - Multi-sensory system for obstacle detection on rai.pdf}
}


@article{gliraPhotogrammetric3DMobile2022,
  title = {Photogrammetric {{3D}} Mobile Mapping of Rail Tracks},
  author = {Glira, P. and Ölsböck, K. and Kadiofsky, T. and Schörghuber, M. and Weichselbaum, J. and Zinner, C. and Fel, L.},
  date = {2022-01},
  journal = {ISPRS Journal of Photogrammetry and Remote Sensing},
  shortjournal = {ISPRS Journal of Photogrammetry and Remote Sensing},
  volume = {183},
  pages = {352--362},
  issn = {09242716},
  doi = {10.1016/j.isprsjprs.2021.09.006},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0924271621002380},
  urldate = {2022-05-04},
  abstract = {Recent developments in the field of rail vehicles increased the demand for accurate and up-to-date 3D maps of rail track networks. Collision avoidance systems, semi-automated, or fully autonomous rail vehicles strongly benefit from such high quality maps. In this work, we present a fully automatic, photogrammetric method for the 3D reconstruction of rail track segments. More specifically, the center line of the rail track is reconstructed as a georeferenced and continuous 3D cubic spline. The main data inputs are collected while driving the rail vehicle along the segment: (a) images from a front-looking camera and (b) observations from a low-cost GNSS receiver. Optional data inputs can be used to increase the reconstruction accuracy, namely (c) an a priori rail track (e.g. from OpenStreetMap), (d) a digital height model (DHM), and (e) ground control points (GCPs). The rail track is estimated in post processing (offline) by a weighted least squares adjustment (LSA). The core of the LSA is the bundle adjustment of images. It is extended by additional geometric constraints which exploit the geometric relations between the rail track, the rail vehicle, and the camera trajectory. As a consequence, in contrast to many related methods, the rails need not to be visible in the images to map the rail track. We applied the method to reconstruct a 13 km long tram line in Vienna (Austria). We found that the local geometry of the track can be well reconstructed from the image sequence. However, if the low-cost GNSS receiver is used as single georeferencing source, the track shows a strong drift behavior. This drift can significantly be minimized over the entire track if the above mentioned optional data inputs are used.},
  langid = {english},
  file = {/home/cornelius/Zotero/storage/DRNGLNA3/Glira et al. - 2022 - Photogrammetric 3D mobile mapping of rail tracks.pdf}
}

@article{gongAnomalyDetectionHighSpeed2022,
  title = {Anomaly {{Detection}} of {{High-Speed Railway Catenary Damage}}},
  author = {Gong, Yansheng and Jing, Wenfeng},
  date = {2022-04-07},
  journal = {IETE Journal of Research},
  shortjournal = {IETE Journal of Research},
  pages = {1--9},
  issn = {0377-2063, 0974-780X},
  doi = {10.1080/03772063.2022.2055667},
  url = {https://www.tandfonline.com/doi/full/10.1080/03772063.2022.2055667},
  urldate = {2022-04-29},
  abstract = {The Railway Catenary system is an integral and essential component of railway electrification. The working state of the catenary system can directly affect the normal operation of the locomotive. The section insulator (SI) in the catenary system is required for the electrical segregation of two feeds such as in a crossover while deciding the destined track from two adjacent tracks. We propose a deep learning-based approach for abnormal detection of insulator breakage in high-speed railway catenary. Semantic segmentation is an important theory in deep learning-based image segmentation. Aiming at the abnormal detection of insulator breakage in high-speed railway catenary, semantic segmentation technology is used to detect the abnormalities, which can quantitatively describe the area of insulator breakage or damage. Based on the DeepLab V3+ semantic segmentation network, the characteristics of the insulator’s data are retrieved. The Multi Feature DeepLab V3+ network and the Attention DeepLab V3+ networks are proposed to solve the anomaly detection problem of the damaged area from the insulator’s images. The results show that the improved two-folded semantic segmentation networks can better mark the contours of the damaged area of the insulator to safeguard the Catenary system. The outcomes are compared with the original DeepLab V3+ and the MIoU values of the two improved semantic segmentation networks have been improved to a remarkable extent that improves the overall performance of the deep learning-based segmentation of insulator’s images.},
  langid = {english},
  file = {/home/cornelius/Zotero/storage/AM6UUZTF/Gong und Jing - 2022 - Anomaly Detection of High-Speed Railway Catenary D.pdf}
}

@article{gongEnhancedFewShotLearning2021,
  title = {Enhanced {{Few-Shot Learning}} for {{Intrusion Detection}} in {{Railway Video Surveillance}}},
  author = {Gong, Xiao and Chen, Xi and Zhong, Zhangdui and Chen, Wei},
  date = {2021},
  journal = {IEEE Transactions on Intelligent Transportation Systems},
  shortjournal = {IEEE Trans. Intell. Transport. Syst.},
  pages = {1--13},
  issn = {1524-9050, 1558-0016},
  doi = {10.1109/TITS.2021.3102613},
  url = {https://ieeexplore.ieee.org/document/9511814/},
  urldate = {2022-05-04},
  abstract = {Video surveillance is gaining increasing popularity to assist in railway intrusion detection in recent years. However, efficient and accurate intrusion detection remains a challenging issue due to: (a) limited sample number: only small sample size (or portion) of intrusive video frames is available; (b) high inter-scene dissimilarity: various railway track area scenes are captured by cameras installed in different landforms; (c) high intra-scene similarity: the video frames captured by an individual camera share a same background. In this paper, an efficient few-shot learning solution is developed to address the above issues. In particular, an enhanced model-agnostic meta-learner is trained using both the original video frames and segmented masks of track area extracted from the video. Moreover, theoretical analysis and engineering solutions are provided to cope with the highly similar video frames in the meta-model training phase. The proposed method is tested on realistic railway video dataset. Numerical results show that the enhanced meta-learner successfully adapts unseen scene with only few newly collected video frame samples, and its intrusion detection accuracy outperforms that of the standard randomly initialised supervised learning.},
  langid = {english},
  file = {/home/cornelius/Zotero/storage/AQ39X82H/Gong et al. - 2021 - Enhanced Few-Shot Learning for Intrusion Detection.pdf}
}

@inproceedings{gunasekaraConvolutionalNeuralNetwork2021,
  title = {A {{Convolutional Neural Network Based Early Warning System}} to {{Prevent Elephant-Train Collisions}}},
  booktitle = {2021 {{IEEE}} 16th {{International Conference}} on {{Industrial}} and {{Information Systems}} ({{ICIIS}})},
  author = {Gunasekara, Shanaka and Jayasuriya, Maleen and Harischandra, Nalin and Samaranayake, Lilantha and Dissanayake, Gamini},
  date = {2021-09-12},
  pages = {271--276},
  publisher = {{IEEE}},
  location = {{Kandy, Sri Lanka}},
  doi = {10.1109/ICIIS53135.2021.9660651},
  url = {https://ieeexplore.ieee.org/document/9660651/},
  urldate = {2022-03-05},
  abstract = {One serious facet of the worsening Human-Elephant Conflict (HEC) in nations such as Sri Lanka involves elephanttrain collisions. Endangered Asian elephants are maimed or killed during such accidents, which also often results in orphaned or disabled elephants. Furthermore, railway services incur significant financial losses and disruptions to services annually due to such accidents.},
  eventtitle = {2021 {{IEEE}} 16th {{International Conference}} on {{Industrial}} and {{Information Systems}} ({{ICIIS}})},
  isbn = {978-1-66542-637-4},
  langid = {english},
  file = {/home/cornelius/Zotero/storage/MSTAUEA8/A_Convolutional_Neural_Network_Based_Early_Warning_System_to_Prevent_Elephant-Train_Collisions.pdf}
}

@article{guoHighSpeedRailwayIntruding2019,
  title = {High-{{Speed Railway Intruding Object Image Generating}} with {{Generative Adversarial Networks}}},
  author = {Guo, Baoqing and Geng, Gan and Zhu, Liqiang and Shi, Hongmei and Yu, Zujun},
  date = {2019-07-11},
  journal = {Sensors},
  shortjournal = {Sensors},
  volume = {19},
  number = {14},
  pages = {3075},
  issn = {1424-8220},
  doi = {10.3390/s19143075},
  url = {https://www.mdpi.com/1424-8220/19/14/3075},
  urldate = {2022-08-31},
  abstract = {Foreign object intrusion is a great threat to high-speed railway safety operations. Accurate foreign object intrusion detection is particularly important. As a result of the lack of intruding foreign object samples during the operational period, artificially generated ones will greatly benefit the development of the detection methods. In this paper, we propose a novel method to generate railway intruding object images based on an improved conditional deep convolutional generative adversarial network (C-DCGAN). It consists of a generator and multi-scale discriminators. Loss function is also improved so as to generate samples with a high quality and authenticity. The generator is extracted in order to generate foreign object images from input semantic labels. We synthesize the generated objects to the railway scene. To make the generated objects more similar to real objects, on scale in different positions of a railway scene, a scale estimation algorithm based on the gauge constant is proposed. The experimental results on the railway intruding object dataset show that the proposed C-DCGAN model outperforms several state-of-the-art methods and achieves a higher quality (the pixel-wise accuracy, mean intersection-over-union (mIoU), and mean average precision (mAP) are 80.46\%, 0.65, and 0.69, respectively) and diversity (the Fréchet-Inception Distance (FID) score is 26.87) of generated samples. The mIoU of the real-generated pedestrian pairs reaches 0.85, and indicates a higher scale of accuracy for the generated intruding objects in the railway scene.},
  langid = {english},
  file = {/home/cornelius/Zotero/storage/MMISSKYG/sensors-19-03075.pdf}
}

@article{guptaDeepVisionbasedSurveillance2022,
  title = {Deep Vision-Based Surveillance System to Prevent Train–Elephant Collisions},
  author = {Gupta, Surbhi and Mohan, Neeraj and Nayak, Padmalaya and Nagaraju, Krishna Chythanya and Karanam, Madhavi},
  date = {2022-04},
  year = {2022},
  journal = {Soft Computing},
  shortjournal = {Soft Comput},
  volume = {26},
  number = {8},
  pages = {4005--4018},
  issn = {1432-7643, 1433-7479},
  doi = {10.1007/s00500-021-06493-8},
  urldate = {2022-05-04},
  abstract = {Animal conservation is imperative, and technology can certainly assist in different ways. The extinction of endangered species like tigers and elephants has boosted the necessity for such efforts. Human–elephant collision (HEC) has been an active area of research for years. Apart from deforestation, the roads and rail tracks laid down through forest areas intervene a lot in wildlife. Collisions and tragedies are every day, especially in green belts in India and other Asian countries. Therefore, it is crucial to develop vision-based, automated, warning-generating systems to identify the animal/ elephant near-site. In the proposed work, different deep learning-based models are proposed to identify elephants in image/ video. Several convolutional neural network (CNN)-based models and three transfer learning (TL)-based models, i.e., ResNet50, MobileNet, Inception V3, have been experimented with and tuned for elephant detection. All the models are tested on a synthesized dataset having about 4200 images built using two public datasets, i.e., ELPephant and RailSem19. Two accurate CNN and transfer learning-based models are presented in detail. These highly accurate and precise models can alarm the trains and generate warning signals on site. The proposed CNN and inception network demonstrated high accuracy of 99.53\% and 99.91\%, respectively, and are remarkable in identifying elephants and hence preventing HEC. The same model can be trained for other animals for their preservation in similar scenarios.},
  langid = {english},
  file = {/home/cornelius/Zotero/storage/L8YLRF2N/Gupta et al. - 2022 - Deep vision-based surveillance system to prevent t.pdf}
}

@article{heObstacleDetectionRail2021,
  title = {Obstacle Detection of Rail Transit Based on Deep Learning},
  author = {He, Deqiang and Zou, Zhiheng and Chen, Yanjun and Liu, Bin and Yao, Xiaoyang and Shan, Sheng},
  date = {2021-05},
  journal = {Measurement},
  shortjournal = {Measurement},
  volume = {176},
  pages = {109241},
  issn = {02632241},
  doi = {10.1016/j.measurement.2021.109241},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0263224121002529},
  urldate = {2021-06-30},
  abstract = {Obstacle detection plays an important role in train automatic operation. To overcome the low accuracy and poor real-time performance of traditional detection methods, and better detect medium and long distances obstacles, the Improved-YOLOv4 network based on deep learning was proposed. The D-CSPDarknet was designed as feature extraction network. A combination of path aggregation and feature pyramid networks were used in feature fusion network, and a spatial pyramid pooling network was set up at each fusion layer. A method of dividing the ROI using a mask was proposed to improve the accuracy of the model while the processing speed can reach 0.004 s. Data augmentation, transfer learning and phased training strategies were used to improve model performance. Based on the data collected in the real operating environment of the train, Improved-YOLOv4 obtained the mAP of 93\% on NVIDIA Jetson AGX, which is more suitable for the obstacle detection of rail transit.},
  langid = {english},
  keywords = {Gimbal Paper},
  file = {/home/cornelius/Zotero/storage/3XFCWWK2/He et al. - 2021 - Obstacle detection of rail transit based on deep l.pdf}
}

@article{heUrbanRailTransit2022,
  title = {Urban Rail Transit Obstacle Detection Based on {{Improved R-CNN}}},
  author = {He, Deqiang and Ren, Ruochen and Li, Kai and Zou, Zhiheng and Ma, Rui and Qin, Yuliang and Yang, Weifeng},
  date = {2022-06},
  journal = {Measurement},
  shortjournal = {Measurement},
  volume = {196},
  pages = {111277},
  issn = {02632241},
  doi = {10.1016/j.measurement.2022.111277},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0263224122005206},
  urldate = {2022-05-11},
  abstract = {Excellent active obstacle detection capability is critical to operate fully automatic trains safely and reliably. There are some problems exist in the traditional sensor-based obstacle detection approaches, such as low detection accuracy, sluggish detection speed and a limited number of obstacle types. In this work, a fast and accurate object detector termed improved R-CNN is proposed by introducing new up-sampling parallel structure and context extraction module (CEM) into the architecture of R-CNN. Furthermore, transfer learning is applied to inherit the COCO dataset’s pre-training weight. The network is trained on track lines and test lines with nine types of ob­ stacles. The data is evaluated and statistically cleansed, and the fine-tuning anchor improves the network’s flexibility within the dataset. With the input size of 1330 px × 800 px, the test results show that the improved RCNN model achieves an accuracy of 90.6\% and a detection speed of 11 FPS. In comparison to other state-of-theart detectors, the model has great performance in obstacle identification of rail track and achieves a good balance between detection speed and accuracy.},
  langid = {english},
  file = {/home/cornelius/Zotero/storage/GBJYVB7M/He et al. - 2022 - Urban rail transit obstacle detection based on Imp.pdf}
}

@online{HinderniserkennungFahrerassistenzFur,
  title = {Hindernis-Erkennung : {{Fahrerassistenz}} Für Die {{Schiene}}},
  url = {https://mission-embedded.dev.ithelps-digital.com/fahrerassistenz-fuer-die-schiene/}
}

@inproceedings{jahanDeepNeuralNetworks2021,
  title = {Deep {{Neural Networks}} for {{Railway Switch Detection}} and {{Classification Using Onboard Camera Images}}},
  booktitle = {2021 {{IEEE Symposium Series}} on {{Computational Intelligence}} ({{SSCI}})},
  author = {Jahan, Kanwal and Niemeijer, Joshua and Kornfeld, Nils and Roth, Michael},
  date = {2021-12-05},
  pages = {01--07},
  publisher = {{IEEE}},
  location = {{Orlando, FL, USA}},
  doi = {10.1109/SSCI50451.2021.9659983},
  url = {https://ieeexplore.ieee.org/document/9659983/},
  urldate = {2022-05-04},
  abstract = {Recent years have seen major advances in Artificial Intelligence (AI) methods for environment perception in intelligent transportation systems. Although most of them have been achieved in the automotive sector there is a similar demand in the railway domain. This paper investigates Deep Neural Network (DNN) based environment perception using vehicle-borne camera images from the rail domain. Specifically, railway switch detection and classification are addressed as a relevant example for a DNN application with potential use for landmark positioning, environment perception, and condition monitoring. The lack of large training data sets in the railway sector (in contrast to the automotive domain) is compensated by an appropriate DNN architecture, an anchor box ratio optimization scheme, and transfer learning. The presented experimental results advocate for the adopted approach.},
  eventtitle = {2021 {{IEEE Symposium Series}} on {{Computational Intelligence}} ({{SSCI}})},
  isbn = {978-1-72819-048-8},
  langid = {english},
  file = {/home/cornelius/Zotero/storage/WM9LMINK/Jahan et al. - 2021 - Deep Neural Networks for Railway Switch Detection .pdf}
}

@article{kapoorDeepLearningBased2020,
  title = {Deep {{Learning Based Object}} and {{Railway Track Recognition Using Train Mounted Thermal Imaging System}}},
  author = {Kapoor, Rajiv and Goel, Rohini and Sharma, Avinash},
  date = {2020-11-01},
  journal = {Journal of Computational and Theoretical Nanoscience},
  shortjournal = {j comput theor nanosci},
  volume = {17},
  number = {11},
  pages = {5062--5071},
  issn = {1546-1955},
  doi = {10.1166/jctn.2020.9342},
  url = {https://www.ingentaconnect.com/content/10.1166/jctn.2020.9342},
  urldate = {2021-07-01},
  abstract = {An intelligent railways safety system is very essential to avoid the accidents. The motivation behind the problem is the large number of collisions between trains and various obstacles, resulting in reduced safety and high costs. Continuous research is being carried out by distinct researchers to ensure railway safety and to reduce accident rates. In this paper, a novel method is proposed for identifying objects (obstacles) on the railway tracks in front of a moving train using a thermal camera. This approach presents a novel way of detecting the railway tracks as well as a deep network based method to recognize obstacles on the track. A pre-trained network is used that provides the model understanding of real world objects and enables deep learning classifiers for obstacle identification. The validation data IisP:a1cq9u5ir.1ed76b.y11th2e.r1m7a1l Oimna:gTinugeu, s1in8gMnaigyht2v0i2si1on17IR:4c8a:2m6era. In this work, the Faster R-CNN is used thaCt eofpficyireignhtlyt: rAecmoegrniiczaenoSbsctiaecnletisficonPuthbelisrahielwrasy tracks. This process can be a great help for railways to reduceDaeclicvideerentds bayndInfigneanntcaial burdens. The result shows that the proposed method has good accuracy of approximately 83\% which helps to enhance the railway safety.},
  langid = {english},
  keywords = {Gimbal Paper},
  file = {/home/cornelius/Zotero/storage/WKFHM8N6/Kapoor et al. - 2020 - Deep Learning Based Object and Railway Track Recog.pdf}
}

@inproceedings{karadumanImageProcessingBased,
  title = {Image {{Processing Based Obstacle Detection}} with {{Laser Measurement}} in {{Railways}}},
  booktitle = {2017 10th {{International Conference}} on {{Electrical}} and {{Electronics Engineering}} ({{ELECO}})},
  author = {Karaduman, Mucahit},
  year = {30 Nov.-2 Dec. 2017},
  pages = {5},
  location = {{Bursa, Turkey}},
  url = {https://ieeexplore.ieee.org/document/8266253},
  abstract = {Intelligent transport and transportation systems are becoming indispensable systems of today. Continuous new investments and work are being carried out to ensure safety in all transport ways and to reduce accident rates. In this study, a simulation is designed to increase the safety of railways. Most of the railway accidents are caused by the obstacles on the rails. These obstacles means, trees, rocks and consists of similar structures. In this application, the railway has been developed on the detection of any obstacles on the rails, the introduction of the emergency system, and the transmission of information to the movement center. The camera and the laser distance meter installed on the train are used to scan the image with the image processing method, and the results are verified and the obstacle is detected. Emergency braking system, warning system is inserted into the circuit to prevent the obstacle from crashing. In addition to this, the main computer status message is sent to the movement center with the help of the created network. As a result, accident rates will be reduced, and intelligent train systems will be further developed.},
  eventtitle = {2017 10th {{International Conference}} on {{Electrical}} and {{Electronics Engineering}} ({{ELECO}})},
  langid = {english},
  keywords = {Gimbal Paper},
  file = {/home/cornelius/Zotero/storage/S9FMGDQL/Karaduman - Image Processing Based Obstacle Detection with Las.pdf}
}

@article{kimStudyTramPedestrianCollision2021,
  title = {A Study of Tram-Pedestrian Collision Prediction Method Using YOLOv5 and Motion Vector},
  author = {Kim, Young-Min and An, Hyeon-Uk and Jeon, Hee-gyun and Kim, Jin-Pyeong and Jang, Gyu-Jin and Hwang, Hyeon-Chyeol},
  date = {2021-12-31},
  journal = {KIPS Transactions on Software and Data Engineering},
  volume = {10},
  number = {12},
  pages = {561--568},
  doi = {10.3745/KTSDE.2021.10.12.561},
  url = {https://doi.org/10.3745/KTSDE.2021.10.12.561},
  urldate = {2022-08-30},
  abstract = {In recent years, autonomous driving technologies have become a high-value-added technology that attracts attention in the fields of science and industry. For smooth Self-driving, it is necessary to accurately detect an object and estimate its movement speed in real time. CNN-based deep learning algorithms and conventional dense optical flows have a large consumption time, making it difficult to detect objects and estimate its movement speed in real time. In this paper, using a single camera image, fast object detection was performed using the YOLOv5 algorithm, a deep learning algorithm, and fast estimation of the speed of the object was performed by using a local dense optical flow modified from the existing dense optical flow based on the detected object. Based on this algorithm, we present a system that can predict the collision time and probability, and through this system, we intend to contribute to prevent tram accidents.},
  langid = {korean-han},
  file = {/home/cornelius/Zotero/storage/4RTILTKF/Kim et al. - 2021 - A Study of Tram-Pedestrian Collision Prediction Me.pdf}
}

@online{KnorrBremseRailVision,
  title = {Knorr-{{Bremse}} and {{Rail Vision}} to Test Obstacle Detection Systems for {{SBB Cargo}}},
  url = {https://www.globalrailwayreview.com/news/109761/knorr-bremse-rail-vision-sbb-cargo-obstacle-detection/}
}

@inproceedings{kudinovPerspective2PointSolutionProblem2020,
  title = {Perspective-2-{{Point Solution}} in the {{Problem}} of {{Indirectly Measuring}} the {{Distance}} to a {{Wagon}}},
  booktitle = {2020 9th {{Mediterranean Conference}} on {{Embedded Computing}} ({{MECO}})},
  author = {Kudinov, Igor A. and Kholopov, Ivan S.},
  date = {2020-06},
  pages = {1--5},
  publisher = {{IEEE}},
  location = {{Budva, Montenegro}},
  doi = {10.1109/MECO49872.2020.9134258},
  url = {https://ieeexplore.ieee.org/document/9134258/},
  urldate = {2021-10-26},
  abstract = {The article considers an algorithm for solving the problem of indirectly measuring the distance to a wagon by reducing it to solving the Perspective-2-Point problem. It is shown that on a straight section of a railway track at distances up to 50 meters, an absolute error of measuring the distance to a locomotive or wagon is no more than 1..2 meters.},
  eventtitle = {2020 9th {{Mediterranean Conference}} on {{Embedded Computing}} ({{MECO}})},
  isbn = {978-1-72816-949-1},
  langid = {english},
  keywords = {Gimbal Paper},
  file = {/home/cornelius/Zotero/storage/LRJIUBTI/Kudinov and Kholopov - 2020 - Perspective-2-Point Solution in the Problem of Ind.pdf}
}

@inproceedings{landrifelODASAnticollisionAssistance2018,
  title = {{{ODAS}} – {{An}} Anti-Collision Assistance System for Light Rail Vehicles and Further Development},
  booktitle = {Proceedings of 7th {{Transport Research Arena TRA}} 2018},
  author = {Landri Fel and Zinner, Christian and Kadiofsky, Thomas and Pointner, Wolfgang and Weichselbaum, Johann and Reisner, Clemens},
  date = {2018-04-16},
  publisher = {{Zenodo}},
  location = {{Vienna, Austria}},
  doi = {10.5281/ZENODO.1451549},
  url = {https://zenodo.org/record/1451549},
  urldate = {2021-10-26},
  abstract = {In the last three years, Bombardier Transportation and its partners have developed and brought to market ODAS{$<$}br{$>$} (Obstacle Detection Assistance System), the world-wide first anti-collision system for light rail vehicles (LRV),{$<$}br{$>$} which is homologated and commercially operated on tramway fleets. The motivation was a further safety{$<$}br{$>$} increase in LRV operation by reducing the risk for collisions. Important milestones for the complex development{$<$}br{$>$} and industrialization process are presented. The ODAS system architecture and its assistive operating principle{$<$}br{$>$} are based on stereo vision as sensor input. Thus, the system is capable of deriving all information necessary for{$<$}br{$>$} detecting obstacles in the driveway of the LRV and estimating a level for collision risk solely from images that{$<$}br{$>$} are produced by three cameras mounted in the vehicle front. This makes the concept well suited for retro-fitting{$<$}br{$>$} existing tramway fleets. Current investigations are targeting new functions and applications derived from the{$<$}br{$>$} current ODAS technology such as cartography-based localization and automatic overspeed protection.},
  eventtitle = {7th {{Transport Research Arena TRA}} 2018},
  keywords = {collision avoidance; driver assistance; stereo vision; tramway; cartography; ODAS,Gimbal Paper},
  file = {/home/cornelius/Zotero/storage/IWJ6UMDJ/Contribution_10515_fullpaper.pdf}
}

@article{liRealWorldRailwayTraffic2018,
  title = {Real-{{World Railway Traffic Detection Based}} on {{Faster Better Network}}},
  author = {Li, Juan and Zhou, Fuqiang and Ye, Tao},
  date = {2018},
  year = {2018},
  journal = {IEEE Access},
  shortjournal = {IEEE Access},
  volume = {6},
  issn = {2169-3536},
  doi = {10.1109/ACCESS.2018.2879270},
  urldate = {2021-10-26},
  abstract = {Detection of railway shape and dangerous obstacles plays a critical role in the auxiliary driving of the train. Speed and accuracy are both of great significance to real-world railway traffic detection, which demands a higher efficiency and effectiveness. The goal of this paper is to design an architecture that achieves the right speed (for effectiveness)/accuracy (for effectiveness) balance for actual railway detection. Driven by this motivation and based on the advantages of some current algorithms, we propose FB-Net (faster better network), a robust end-to-end convolutional neural network. Detectors based on deep learning method are composed of feature extraction, candidate region generation,and classification. Specifically, our framework is focusing on with three embedded modules: 1) To improve efficiency, we replace standard convolutions with depthwise-pointwise convolutions in the feature extraction stage, aiming to red reduce model parameters; 2) To address the effectiveness, a priori module is added for candidate boxes to provide a coarse location for subsequent regressor and to reduce the searching space of objects significantly; 3) Meanwhile, we design a feature fusion module to enhance the semantic context interaction of adjacent feature maps for better detection of small objects. Experiments for railway traffic datasets on both computer device and mobile device demonstrate that FB-Net achieves good results when the input size is 320 pixels × 320 pixels.},
  langid = {english},
  keywords = {Anomaly Paper,Gimbal Paper}
}

@inproceedings{liSaliencyDetectionSide2018,
  title = {Saliency {{Detection}} with {{Side Information}} on {{Railway Transportation Dataset}}},
  booktitle = {2018 {{International Conference}} on {{Intelligent Rail Transportation}} ({{ICIRT}})},
  author = {Li, Qiuning and Li, Yidong and Lang, Congyan},
  date = {2018-12},
  pages = {1--5},
  publisher = {{IEEE}},
  location = {{Singapore}},
  doi = {10.1109/ICIRT.2018.8641630},
  url = {https://ieeexplore.ieee.org/document/8641630/},
  urldate = {2022-05-04},
  eventtitle = {2018 {{International Conference}} on {{Intelligent Rail Transportation}} ({{ICIRT}})},
  isbn = {978-1-5386-7528-1},
  langid = {english},
  file = {/home/cornelius/Zotero/storage/T5K7UZCM/Li et al. - 2018 - Saliency Detection with Side Information on Railwa.pdf}
}

@article{luyInitialResultsTesting2018,
  title = {Initial {{Results}} of {{Testing}} a {{Multilayer Laser Scanner}} in a {{Collision Avoidance System}} for {{Light Rail Vehicles}}},
  author = {Lüy, Murat and Çam, Ertuğrul and Ulamış, Faruk and Uzun, İbrahim and Akın, Salih},
  date = {2018-03-21},
  journal = {Applied Sciences},
  shortjournal = {Applied Sciences},
  volume = {8},
  number = {4},
  pages = {475},
  issn = {2076-3417},
  doi = {10.3390/app8040475},
  url = {http://www.mdpi.com/2076-3417/8/4/475},
  urldate = {2021-10-26},
  abstract = {This paper presents an application to detect and track obstacles using a multilayer laser scanner. The goal of the detection system is to develop collision avoidance for the Light Rail Vehicle (LRV). The laser scanner, which is mounted in front of the tram, collects information in a four-scan plane. The object recognition and tracking module, which is composed of a three sub-modules segmentation, classification, and Kalman Filter tracking, was carried out on the raw data. Thus, data were provided for collision avoidance module. The proposed system was applied to a tram named “Silkworm” which is manufactured by Durmazlar Machine Inc. (Bursa, Turkey) and initial experimental tests have been conducted at the facilities of Durmazlar Machine Inc. in the city of Bursa, Turkey. This study aims to illustrate parts of the possible tests that can be carried out and to share with the scientific community an important application of multilayer laser scanners, although in the initial implementation phase, in urban rail transportation.},
  langid = {english},
  file = {/home/cornelius/Zotero/storage/IN3ZFKES/Lüy et al. - 2018 - Initial Results of Testing a Multilayer Laser Scan.pdf}
}

@inproceedings{mahtaniPedestrianDetectionClassification2020,
  title = {Pedestrian {{Detection}} and {{Classification}} for {{Autonomous Train}}},
  booktitle = {{{IEEE}} {{International Conference}} on {{Image Processing}}, {{Applications}} and {{Systems}}},
  author = {Mahtani, Ankur and Ben-Messaoud, Wael and Taleb-Ahmed, Abdelmalik and Niar, Smail and Strauss, Clement},
  date = {2020-12-09},
  year = {2020},
  pages = {52--57},
  location = {{Genova, Italy}},
  doi = {10.1109/IPAS50080.2020.9334938},
  urldate = {2022-05-04},
  abstract = {In this paper, we present a combined approach for human localization and classification in Autonomous Train application. Our contribution is threefold. (a) The creation of a new dataset for workers wearing orange vests in a railway environment context. (b) A deep learning supervised YOLO object detector for persons detection combined with a linear SVM (Support Vector Machine) classifier for persons classification into workers wearing orange vests or travelers. (c) A realtime vision-based technique for the environment monitoring in a driverless train application. Experimental results evaluate the parameters of our two stages detection approach and show that our algorithm is robust in detecting and classifying railway workers for a real-time implementation on an embedded system. Our implementation on an embedded system allows a detection with a correct classification rate of 98.5\% of accuracy and a classification time of 1 ms per frame.},
  eventtitle = {2020 {{IEEE}} 4th {{International Conference}} on {{Image Processing}}, {{Applications}} and {{Systems}} ({{IPAS}})},
  isbn = {978-1-72817-574-4},
  langid = {english},
  file = {/home/cornelius/Zotero/storage/E2ENZ983/Mahtani et al. - 2020 - Pedestrian Detection and Classification for Autono.pdf}
}

@article{manikandanVISIONBASEDOBSTACLE,
  title = {{{VISION BASED OBSTACLE DETECTION ON RAILWAY TRACK}}},
  author = {Manikandan, R and Balasubramanian, M and Palanivel, S},
  journal = {International Journal of Pure and Applied Mathematics},
  volume = {116},
  number = {24},
  issn = {1311-8080},
  keywords = {Gimbal Paper},
  file = {/home/cornelius/Zotero/storage/76NHASUD/48.pdf}
}

@article{mauriRealTime3DMultiObject2021,
  title = {Real-{{Time 3D Multi-Object Detection}} and {{Localization Based}} on {{Deep Learning}} for {{Road}} and {{Railway Smart Mobility}}},
  author = {Mauri, Antoine and Khemmar, Redouane and Decoux, Benoit and Haddad, Madjid and Boutteau, Rémi},
  date = {2021-08-12},
  journal = {Journal of Imaging},
  shortjournal = {J. Imaging},
  volume = {7},
  number = {8},
  pages = {145},
  issn = {2313-433X},
  doi = {10.3390/jimaging7080145},
  url = {https://www.mdpi.com/2313-433X/7/8/145},
  urldate = {2022-06-21},
  abstract = {For smart mobility, autonomous vehicles, and advanced driver-assistance systems (ADASs), perception of the environment is an important task in scene analysis and understanding. Better perception of the environment allows for enhanced decision making, which, in turn, enables very high-precision actions. To this end, we introduce in this work a new real-time deep learning approach for 3D multi-object detection for smart mobility not only on roads, but also on railways. To obtain the 3D bounding boxes of the objects, we modified a proven real-time 2D detector, YOLOv3, to predict 3D object localization, object dimensions, and object orientation. Our method has been evaluated on KITTI’s road dataset as well as on our own hybrid virtual road/rail dataset acquired from the video game Grand Theft Auto (GTA) V. The evaluation of our method on these two datasets shows good accuracy, but more importantly that it can be used in real-time conditions, in road and rail traffic environments. Through our experimental results, we also show the importance of the accuracy of prediction of the regions of interest (RoIs) used in the estimation of 3D bounding box parameters.},
  langid = {english},
  file = {/home/cornelius/Zotero/storage/7PNVAQMS/jimaging-07-00145.pdf}
}

@inproceedings{mazlSensorDataFusion2003,
  title = {Sensor Data Fusion for Inertial Navigation of Trains in {{GPS-dark}} Areas},
  booktitle = {{{IEEE IV2003 Intelligent Vehicles Symposium}}. {{Proceedings}} ({{Cat}}. {{No}}.{{03TH8683}})},
  author = {Mazl, R. and Preucil, L.},
  date = {2003},
  pages = {345--350},
  publisher = {{IEEE}},
  location = {{Columbus, OH, USA}},
  doi = {10.1109/IVS.2003.1212934},
  url = {http://ieeexplore.ieee.org/document/1212934/},
  urldate = {2021-06-30},
  abstract = {The motivation of the presented work is to develop a robust navigation system for accurate localization of trains on railway tracks in the cases where the GPS-based navigation is not temporallyavailable. As the h a 1 solution of the train locator naturally takes into consideration the satellite-based navigation, the satellite signal needs not to be available all along the railway. The presented - contribution describes an approach to preprocessing and fusion of additional train onboard sensors the odometer and accelerometer, all targeted to serve as optional and temporary substitutionfor GPS navigation. The suggested solution is exploring a rule-based substitutions and mutual calibrations of the used sensors depending on actual conditions. The given approach relies on the GPS system only to provide position calibrations and serves a reference method for evaluation of the presented results. Suggested solutions have been experimentally tested with real-world data gathered with locomotive onboard inertial sensors.},
  eventtitle = {{{IEEE IV2003 Intelligent Vehicles Symposium}}. {{Proceedings}}},
  isbn = {978-0-7803-7848-3},
  langid = {english},
  file = {/home/cornelius/Zotero/storage/25KNHPXM/Mazl und Preucil - 2003 - Sensor data fusion for inertial navigation of trai.pdf}
}

@article{mikrutDetectionRecognitionSelected2014,
  title = {Detection and {{Recognition}} of {{Selected Class Railway Signs}}},
  author = {Mikrut, Sławomir and Mikrut, Zbigniew and Moskal, Agnieszka and Pastucha, Elżbieta},
  date = {2014-09-01},
  journal = {Image Processing \& Communications},
  volume = {19},
  number = {2-3},
  pages = {83--96},
  issn = {2300-8709},
  doi = {10.1515/ipc-2015-0013},
  url = {https://www.sciendo.com/article/10.1515/ipc-2015-0013},
  urldate = {2022-03-05},
  abstract = {The paper aims at presentation of results of research on detection and recognition of selected class railway signs (W11p). When conducting the research, the authors have proposed their own algorithm, which achieved about 90\% effectiveness at detecting W11p signs and 98\% effectiveness at classifying them. The processes of localisation, segmentation and recognition of W11p signs were considerably simplified thanks to the application of backpropagation neural network. The authors believe that two non-standard methods related to the use of the network deserve attention: the application of an interactive method of generating the training set, owing to which also pixels highly diversified in terms of their colours could be included, and the use of a full spectrum of neural network responses, which made it possible to accomplish a feedback. It consisted in an automatic adjusting of the network responses’ threshold to the results of segmentation and recognition.},
  langid = {english},
  file = {/home/cornelius/Zotero/storage/PDZWRNW3/Mikrut et al. - 2014 - Detection and Recognition of Selected Class Railwa.pdf}
}

@inproceedings{mockelMultisensorObstacleDetection2003,
  title = {Multi-Sensor Obstacle Detection on Railway Tracks},
  booktitle = {{{IEEE IV2003 Intelligent Vehicles Symposium}}. {{Proceedings}} ({{Cat}}. {{No}}.{{03TH8683}})},
  author = {Mockel, S. and Scherer, F. and Schuster, P.F.},
  date = {2003},
  pages = {42--46},
  publisher = {{IEEE}},
  location = {{Columbus, OH, USA}},
  doi = {10.1109/IVS.2003.1212880},
  url = {http://ieeexplore.ieee.org/document/1212880/},
  urldate = {2021-06-30},
  abstract = {A multi-sensor obstacle detection system for the use on railway track ivas specified, implemented and tested. The applied look-ahead sensors are: Video cameras (optical passive) and LIDAR (optical active). The objects delivered by the sensors were fused, classifred and their description is sent to the central vehicle unit.},
  eventtitle = {{{IEEE IV2003 Intelligent Vehicles Symposium}}. {{Proceedings}}},
  isbn = {978-0-7803-7848-3},
  langid = {english},
  keywords = {Gimbal Paper},
  file = {/home/cornelius/Zotero/storage/4QK9SM5B/Mockel et al. - 2003 - Multi-sensor obstacle detection on railway tracks.pdf}
}

@inproceedings{mukojimaMovingCameraBackgroundsubtraction2016,
  title = {Moving Camera Background-Subtraction for Obstacle Detection on Railway Tracks},
  booktitle = {{{IEEE International Conference}} on {{Image Processing}}},
  author = {Mukojima, Hiroki and Deguchi, Daisuke and Kawanishi, Yasutomo and Ide, Ichiro and Murase, Hiroshi and Ukai, Masato and Nagamine, Nozomi and Nakasone, Ryuta},
  date = {2016-09},
  year = {2016},
  pages = {3967--3971},
  location = {{Phoenix, AZ, USA}},
  doi = {10.1109/ICIP.2016.7533104},
  urldate = {2021-07-01},
  abstract = {We propose a method for detecting obstacles by comparing input and reference train frontal view camera images. In the field of obstacle detection, most methods employ a machine learning approach, so they can only detect pre-trained classes, such as pedestrian, bicycle, etc. This means that obstacles of unknown classes cannot be detected. To overcome this problem, we propose a background subtraction method that can be applied to moving cameras. First, the proposed method computes frame-by-frame correspondences between the current and the reference (database) image sequences. Then, obstacles are detected by applying image subtraction to corresponding frames. To confirm the effectiveness of the proposed method, we conducted an experiment using several image sequences captured on an experimental track. Its results showed that the proposed method could detect various obstacles accurately and effectively.},
  eventtitle = {2016 {{IEEE International Conference}} on {{Image Processing}} ({{ICIP}})},
  isbn = {978-1-4673-9961-6},
  langid = {english},
  keywords = {Anomaly Paper,Gimbal Paper},
  file = {/home/cornelius/Zotero/storage/6P9JJCII/Mukojima et al. - 2016 - Moving camera background-subtraction for obstacle .pdf}
}

@inproceedings{naiStudyAbsolutePositioning2016,
  title = {Study on {{Absolute Positioning Technique}} for {{Medium-Low Speed Maglev Train Based}} on {{Cross Coding Inductive Loop Wire}}},
  booktitle = {Proceedings of the 2nd {{International Conference}} on {{Advances}} in {{Mechanical Engineering}} and {{Industrial Informatics}} ({{AMEII}} 2016)},
  author = {Nai, Wei and Li, Xiang and Yu, Yi and Wang, ShaoYin},
  date = {2016},
  publisher = {{Atlantis Press}},
  location = {{Hangzhou, China}},
  doi = {10.2991/ameii-16.2016.124},
  url = {http://www.atlantis-press.com/php/paper-details.php?id=25854712},
  urldate = {2021-07-01},
  abstract = {During recent years, the medium-low speed maglev system brings new chances for the development of maglev train related techniques, and traditional operation and control standards have been applied in its signal system design. However, as there are no wheel sets on maglev train, the positioning function cannot be realized by the corresponding method in wheel-rail based urban rail transit. Many related research has already proved that the absolute positioning can be realized by parallel arranged cross coding inductive loop wires with different cross cycles itself without transponders; however, the performance and the precision of positioning for maglev system by using such positioning method still requires to be demonstrated. In this paper, based on a thorough study on cross inductive loop wire which have been applied in different areas, a system design for medium-low speed maglev train positioning based on cross coding inductive loop wire has been proposed, and the arrangement of address line has also been optimized. Performance analysis has shown that the feasibility of the system design and has proved that the optimization of radio arrangement can double the accuracy in train positioning.},
  eventtitle = {2nd {{International Conference}} on {{Advances}} in {{Mechanical Engineering}} and {{Industrial Informatics}} ({{AMEII}} 2016)},
  isbn = {978-94-6252-188-9},
  langid = {english},
  file = {/home/cornelius/Zotero/storage/AKIX3T7B/Nai et al. - 2016 - Study on Absolute Positioning Technique for Medium.pdf}
}

@article{nakasoneFrontalObstacleDetection2017,
  title = {Frontal {{Obstacle Detection Using Background Subtraction}} and {{Frame Registration}}},
  author = {Nakasone, Ryuta and Nagamine, Nozomi and Ukai, Masato and Mukojima, Hiroki and Deguchi, Daisuke and Murase, Hiroshi},
  date = {2017},
  year = {2017},
  journal = {Quarterly Report of RTRI},
  shortjournal = {Q. rep. RTRI},
  volume = {58},
  number = {4},
  pages = {298--302},
  issn = {0033-9008, 1880-1765},
  doi = {10.2219/rtriqr.58.4_298},
  urldate = {2021-10-26},
  abstract = {Systems such as Automatic Train Protection and moving block sections help prevent trains colliding, however collisions with unexpected obstacles in front of a train can only be avoided if seen by the driver. In an effort to reduce the possibility of this type of collision and to improve passenger safety, an obstacle detection method has been proposed using a monocular camera and image processing. The proposed method can detect obstacles by comparing live images from the camera with images obtained by other trains operating earlier along the same route. The difference between the two sets of images are defined as obstacles. The performance of the method was verified by conducting experiments using rolling stock and imitation obstacles.},
  langid = {english},
  keywords = {Gimbal Paper},
  file = {/home/cornelius/Zotero/storage/XM8GMISM/Nakasone et al. - 2017 - Frontal Obstacle Detection Using Background Sub.pdf}
}

@inproceedings{nassuAutomaticRecognitionRailway2010,
  title = {Automatic Recognition of Railway Signs Using {{SIFT}} Features},
  booktitle = {2010 {{IEEE Intelligent Vehicles Symposium}}},
  author = {Nassu, Bogdan Tomoyuki and Ukai, Masato},
  date = {2010-06},
  pages = {348--354},
  publisher = {{IEEE}},
  location = {{La Jolla, CA, USA}},
  doi = {10.1109/IVS.2010.5548127},
  url = {http://ieeexplore.ieee.org/document/5548127/},
  urldate = {2021-07-01},
  abstract = {Safety in railways is mostly achieved by automated operation using a specialized infrastructure. However, many tasks still rely on the decisions and actions of a human crew. Aiming at improving safety in such situations, we present an approach for recognizing railway signals and signs in video sequences taken by an in-vehicle camera. Our approach is based on a model automatically learned from examples, built from clusters of features extracted by a modified version of SIFT. It does not require the examples and inputs to be obtained under controlled conditions or with specific camera parameters/positioning, being robust to arbitrary weather and lighting, deterioration, motion blur and perspective distortion. We demonstrate the feasibility of our approach by showing that it performs better than a shape-based matching method when recognizing a railway signal with particularly challenging characteristics under realistic conditions.},
  eventtitle = {2010 {{IEEE Intelligent Vehicles Symposium}} ({{IV}})},
  isbn = {978-1-4244-7866-8},
  langid = {english},
  keywords = {Gimbal Paper},
  file = {/home/cornelius/Zotero/storage/N2EM6VG7/Nassu und Ukai - 2010 - Automatic recognition of railway signs using SIFT .pdf}
}

@report{ObstacleDetectionSystems,
  type = {Article},
  title = {Obstacle Detection Systems for {{SBB Cargo}} Shunting Locomotives},
  author = {Railway Pro},
  date = {2020-09-24},
  institution = {{RailwayPro}},
  url = {https://www.railwaypro.com/wp/obstacle-detection-systems-for-sbb-cargo-shunting-locomotives/},
  urldate = {2021-11-16},
  keywords = {Gimbal Paper}
}

@article{ohtaLevelCrossingsObstacle2005,
  title = {Level {{Crossings Obstacle Detection System Using Stereo Cameras}}},
  author = {Ohta, Masaru},
  date = {2005},
  journal = {Quarterly Report of RTRI},
  shortjournal = {QR of RTRI},
  volume = {46},
  number = {2},
  pages = {110--117},
  issn = {0033-9008, 1880-1765},
  doi = {10.2219/rtriqr.46.110},
  url = {http://www.jstage.jst.go.jp/article/rtriqr/46/2/46_2_110/_article},
  urldate = {2021-06-30},
  abstract = {A number of obstacle detection systems are now in operation at level crossings to prevent collisions between trains and large vehicles. However, these are not suitable for detecting people on two-wheeled vehicles or pedestrians, who are also frequently involved in accidents at level crossings. To address this problem, we have been developing a new obstacle detection system that utilizes stereo cameras and image processing technology. The stereo camera system is more effective than a single camera system because it measures the three-dimensional shape of obstacles on crossings. This paper describes the development of the new obstacle detection system and its field test results.},
  langid = {english},
  file = {/home/cornelius/Zotero/storage/GP855TL9/Ohta - 2005 - Level Crossings Obstacle Detection System Using St.pdf}
}

@article{pavlovicAdvancedThermalCamera2018,
  title = {Advanced Thermal Camera Based System for Object Detection on Rail Tracks},
  author = {Pavlovic, Milan and Ciric, Ivan and Ristic-Durrant, Danijela and Nikolic, Vlastimir and Simonovic, Milos and Ciric, Milica and Banic, Milan},
  date = {2018},
  journal = {Thermal Science},
  shortjournal = {Therm sci},
  volume = {22},
  pages = {1551--1561},
  issn = {0354-9836, 2334-7163},
  doi = {10.2298/TSCI18S5551P},
  url = {http://www.doiserbia.nb.rs/Article.aspx?ID=0354-983618551P},
  urldate = {2021-06-30},
  abstract = {In this paper, an advanced thermal camera-based system for detection of objects on rail tracks is presented. Developed system is powered by advanced image processing algorithm, in order to achieve greater reliability and robustness, and tested on set of infrared images captured at night conditions. The goal of this system is to detect objects on rail tracks and next to them and estimate distances between camera stand and detected objects. For that purpose, different edge detection methods are tested, and finally Canny edge detector is selected for rail track detection and for determination of region of interest, further used for analysis in object detection process. In determined region of interest, region-based segmentation is used for object detection. For estimation of distances between camera stand and detected objects, homography based method is used. Validation of estimated distances is done, in respect to real measured distances from camera stand to objects (humans) involved in experiment. Distances are estimated with a maximum error of 2\%. System can provide reliable object detection, as well as distance estimation, and for improved robustness and adaptability, artificial intelligence tools can be used.},
  issue = {Suppl. 5},
  langid = {english},
  keywords = {Gimbal Paper},
  file = {/home/cornelius/Zotero/storage/EMIQ4J39/EMIQ4J39.pdf}
}

@article{pavlovicNIGHTVISIONBASED,
  title = {{{NIGHT VISION BASED SYSTEM FOR ATO OBSTACLE DETECTION}}},
  author = {Pavlović, Milan and Ćirić, Ivan and Nikolić, Vlastimir and Petrović, Emina and Radovanović, Dušan},
  pages = {4},
  abstract = {This paper presents an obstacle detection system for autonomous train operation (ATO) based on night vision. Experimental setup with ICCD (Intensified CCD) camera, as night vision system, was used for image acquisition at night conditions. For obstacle detection, advanced image processing algorithm was developed and used. In order to achieve reliable detection, rail tracks were detected to define Region of Interest (ROI). In ROI, detected rail tracks were analyzed with goal to find any interruption which is caused by existence of an obstacle. Detection of obstacle was done using of image segmentation method. The algorithm was tested on great set of images captured in six specific cases for obstacle detection, which are quite characteristic for the field of railway. The results showed that system can provide good obstacle detection at night conditions.},
  langid = {english},
  file = {/home/cornelius/Zotero/storage/GCDZKLNJ/Pavlović et al. - NIGHT VISION BASED SYSTEM FOR ATO OBSTACLE DETECTI.pdf}
}

@inproceedings{pavlovicTHERMALIMAGEPROCESSING,
  title = {{{THERMAL IMAGE PROCESSING FOR AUTONOMOUS TRAIN OPERATION OBSTACLE DETECTION SYSTEM}}},
  booktitle = {Proceedings, {{XXVII MNTK}} "{{ADP-2018}}"},
  author = {Pavlović, M and Ćirić, I and Nikolić, V and Simonović, M and Stevanović, J},
  date = {2018},
  pages = {324--328},
  location = {{Sozopol, Bulgaria}},
  abstract = {This paper presents an obstacle detection system for autonomous train operation (ATO) based on using of thermal image processing. For detection of obstacles in low-light and night conditions, thermal camera with advanced image processing algorithm is used. In order to achieve reliable detection, at first, defining of Region of Interest (ROI) is performed, where rail tracks are detected. In defined ROI, region based segmentation algorithm is implemented for obstacle detection. The results showed that this system can successfully perform satisfying obstacle detection in low-light and night conditions.},
  eventtitle = {{{ADP-2018}}},
  langid = {english},
  keywords = {Gimbal Paper},
  file = {/home/cornelius/Zotero/storage/DHSA55SX/Pavlović et al. - THERMAL IMAGE PROCESSING FOR AUTONOMOUS TRAIN OPER.pdf}
}

@article{pavlovicTrainObstacleDetection2022,
  title = {Train {{Obstacle Detection System Stabilization}} and {{Stochastic Vibrations Analysis Using}} the {{Moment Lyapunov Exponent Method}}},
  author = {Pavlović, Ivan R and Stamenković, Dušan and Nikolić, Vlastimir and Miltenović, Aleksandar and Despenić, Nikola and Stamenković, Marija and Janevski, Goran},
  date = {2022},
  journal = {Acta Polytechnica Hungarica},
  volume = {19},
  number = {6},
  pages = {14},
  abstract = {This paper analyzes stochastic vibrations of a specialised onboard railway obstacle detection system (ODS). The observed system consists of several vision-based sensors mounted in a special housing attached to the locomotive front profile via rubber metal springs and a mounting plate. In this study, the experimental measurements of acceleration were performed in the vertical, longitudinal, and lateral direction for two positions, on the mounting plate rigidly connected to the vehicle body and inside the sensor housing. The ODS stabilization is presented with the results obtained by the moment Lyapunov exponent (MLE) method. Analytical and numerical determination of MLE is firstly presented on a simply supported Euler-Bernoulli beam. Further, the stochastic vibration analysis was performed using the experimentally obtained data. According to these values, the appropriate system parameters essential for the application of the Lyapunov theory to stochastic stability problems were firstly numerically calculated. By means of the Monte Carlo simulation method, whose example was previously shown on a simple beam, the bounds of the almost sure stability of the observed system are given according to the measured accelerations in all of the observed directions.},
  langid = {english},
  file = {/home/cornelius/Zotero/storage/JLPCNVZ5/Pavlović et al. - 2022 - Train Obstacle Detection System Stabilization and .pdf}
}

@article{pericDealingLowQuality2022,
  title = {Dealing with {{Low Quality Images}} in {{Railway Obstacle Detection System}}},
  author = {Perić, Staniša and Milojković, Marko and Stan, Sergiu-Dan and Banić, Milan and Antić, Dragan},
  date = {2022-03-16},
  journal = {Applied Sciences},
  shortjournal = {Applied Sciences},
  volume = {12},
  number = {6},
  pages = {3041},
  issn = {2076-3417},
  doi = {10.3390/app12063041},
  url = {https://www.mdpi.com/2076-3417/12/6/3041},
  urldate = {2022-04-29},
  abstract = {Object recognition and classification as well as obstacle distance calculation are of the utmost importance in today’s autonomous driving systems. One such system designed to detect obstacle and track intrusion in railways is considered in this paper. The heart of this system is the decision support system (DSS), which is in charge of making complex decisions, important for a safe and efficient autonomous train drive based on the information obtained from various sensors. DSS determines the object class and its distance from a running train by analyzing sensor images using machine learning algorithms. For the quality training of these machine learning models, it is necessary to provide training sets with images of adequate quality, which is often not the case in realworld railway applications. Furthermore, the images of insufficient quality should not be processed at all in order to save computational time. One of the most common types of distortion which occurs in real-world conditions (train movement and vibrations, movement of other objects, bad weather conditions, and day and night image differences) is blur. This paper presents an improved edgedetection method for the automatic detection and rejection of images of inadequate quality regarding the blur level. The proposed method, with its improvements convenient for railway application, is compared with several other state-of-the-art methods for blur detection, and its superior overall performance is demonstrated.},
  langid = {english},
  file = {/home/cornelius/Zotero/storage/42A6Y3FJ/Perić et al. - 2022 - Dealing with Low Quality Images in Railway Obstacl.pdf}
}

@inproceedings{pivaColorbasedVideoStabilization2003,
  title = {Color-Based Video Stabilization for Real-Time on-Board Object Detection on High-Speed Trains},
  booktitle = {Proceedings of the {{IEEE Conference}} on {{Advanced Video}} and {{Signal Based Surveillance}}, 2003.},
  author = {Piva, S. and Zara, M. and Gera, G. and Regazzoni, C.S.},
  date = {2003},
  pages = {299--304},
  publisher = {{IEEE Comput. Soc}},
  location = {{Miami, FL, USA}},
  doi = {10.1109/AVSS.2003.1217935},
  url = {http://ieeexplore.ieee.org/document/1217935/},
  urldate = {2021-06-30},
  abstract = {This paper is concerned with a particular application of image stabilization1. Image stabilization is a necessary step to reduce the effect of camera motion when, as in this case, image sequences are acquired from a mobile platform.},
  eventtitle = {{{IEEE Conference}} on {{Advanced Video}} and {{Signal Based Surveillance}}. {{AVSS}} 2003},
  isbn = {978-0-7695-1971-5},
  langid = {english},
  file = {/home/cornelius/Zotero/storage/8G6PDVSQ/Piva et al. - 2003 - Color-based video stabilization for real-time on-b.pdf}
}

@report{RailVisionIo,
  title = {{{RailVision}}.Io},
  author = {RailVision.io},
  date = {2021},
  institution = {{RailVision.IO}},
  url = {https://railvision.io},
  urldate = {2021-11-16},
  keywords = {Gimbal Paper}
}

@article{raoSiameseNeuralNetworks,
  title = {Siamese {{Neural Networks}} for {{One-shot}} Detection of {{Railway Track Switches}}},
  author = {Rao, Dattaraj J and Mittal, Shruti and Ritika, S},
  pages = {7},
  abstract = {Deep Learning methods have been extensively used to analyze video data to extract valuable information by classifying image frames and detecting objects. We describe a unique approach for using video feed from a moving Locomotive to continuously monitor the Railway Track and detect significant assets like Switches on the Track. The technique used here is called Siamese Networks – which uses 2 identical networks to learn the similarity between of 2 images. Here we will use a Siamese network to continuously compare Track images and detect any significant difference in the Track. Switch will be one of those images that will be different and we will find a mapping that clearly distinguishes the Switch from other possible Track anomalies. The same method will then be extended to detect any abnormalities on the Railway Track. Railway Transportation is unique in the sense that is has wheeled vehicles – Trains pulled by Locomotives - running on guided Rails at very high speeds nearing 200 mph. Multiple Tracks on the Rail network are connected to each other using an equipment called Switch or a Turnout. Switch is either operated manually or automatically through command from a Control center and it governs the movement of Trains on different Tracks of the network. Accurate location of these Switches is very important for the railroad and getting a true picture of their state in field is important. Modern trains use high definition video cameras facing the Track that continuously record video from track. Using a Siamese network and comparing to benchmark images – we describe a method to monitor the Track and highlight anomalies.},
  langid = {english},
  file = {/home/cornelius/Zotero/storage/QMQKP56Z/Rao et al. - Siamese Neural Networks for One-shot detection of .pdf}
}

@incollection{ristic-durrantArtificialIntelligenceObstacle2020a,
  title = {Artificial {{Intelligence}} for {{Obstacle Detection}} in {{Railways}}: {{Project SMART}} and {{Beyond}}},
  shorttitle = {Artificial {{Intelligence}} for {{Obstacle Detection}} in {{Railways}}},
  booktitle = {Dependable {{Computing}} - {{EDCC}} 2020 {{Workshops}}},
  author = {Ristić-Durrant, Danijela and Haseeb, Muhammad Abdul and Franke, Marten and Banić, Milan and Simonović, Miloš and Stamenković, Dušan},
  editor = {Bernardi, Simona and Vittorini, Valeria and Flammini, Francesco and Nardone, Roberto and Marrone, Stefano and Adler, Rasmus and Schneider, Daniel and Schleiß, Philipp and Nostro, Nicola and Løvenstein Olsen, Rasmus and Di Salle, Amleto and Masci, Paolo},
  date = {2020},
  series = {Communications in {{Computer}} and {{Information Science}}},
  volume = {1279},
  pages = {44--55},
  publisher = {{Springer International Publishing}},
  location = {{Cham}},
  doi = {10.1007/978-3-030-58462-7_4},
  url = {https://link.springer.com/10.1007/978-3-030-58462-7_4},
  urldate = {2021-10-26},
  abstract = {In this paper an AI-based system for detection and distance estimation of obstacles on rail tracks ahead of a moving train is presented, as developed within the H2020 Shift2Rail project SMART. The system software includes a novel machine learning-based method that is applicable to long range obstacle detection, the distinguishing challenge of railway applications. The development of this method used a novel long-range railway dataset, which was generated during the project lifetime as described in the paper. Evaluation results of reliable obstacle detection using SMART onboard cameras are presented. The paper also discusses the possible use of SMART software for obstacle detection in images taken by drone camera, for future extension of the SMART onboard system to a holistic system for obstacle detection in railways, as planned for SMART2, the follow-up project to SMART.},
  isbn = {978-3-030-58461-0 978-3-030-58462-7},
  langid = {english},
  keywords = {Gimbal Paper},
  file = {/home/cornelius/Zotero/storage/JJ78DAJ9/Ristić-Durrant et al. - 2020 - Artificial Intelligence for Obstacle Detection in .pdf}
}

@inproceedings{ristic-durrantAUTONOMOUSOBSTACLEDETECTION2016,
  title = {{{TOWARDS AUTONOMOUS OBSTACLE DETECTION IN FREIGHT RAILWAY}}},
  booktitle = {Proceedings of {{XVII International Scientific-Expert Conference}} on {{Railways}}},
  author = {Ristić-Durrant, Danijela and Ćirić, Ivan and Simonović, Miloš and Nikolić, Vlastimir and Leu, Adrian and Brindić, Branislav},
  date = {2016-10-13/2016-10-14},
  pages = {8},
  location = {{Serbia, Niš}},
  abstract = {In order to increase the quality of rail freight, as well as its effectiveness and capacity, a level of automation of railway cargo haul at European railways needs to be increased. An important part of the autonomous operation of cargo haul at European railways shall be a complete, safe and reliable obstacle detection system to be used mainly for initiation of long distance forward-looking braking and short distance wagon recognition for shunting onto buffers. Such obstacle detection system shall be integrated into Autonomous Train Operation (ATO) module and it shall be a multi sensory system in order to provide fail safe and reliable obstacle detection at short (up to 20 m) and long range (up to 1000 m) during day and night operation, as well as operation during impaired visibility (such as in the case of fog and bad weather condition). In this paper, the state-of-the art in obstacle detection in railway as well as problems and lacks that should be overcome to achieve such autonomous obstacle detection are presented.},
  eventtitle = {{{XVII International Scientific-Expert Conference}} on {{Railways}}},
  langid = {english},
  keywords = {Gimbal Paper,IMPORTANT},
  file = {/home/cornelius/Zotero/storage/W9EGY8W7/Ristić-Durrant et al. - 2016 - TOWARDS AUTONOMOUS OBSTACLE DETECTION IN FREIGHT R.pdf}
}

@inproceedings{ristic-durrantOBSTACLEDETECTIONRAILWAYS2020,
  title = {{{OBSTACLE DETECTION FOR RAILWAYS}}: {{LESSONS LEARNED FROM PROJECT SMART}}},
  booktitle = {Proceedings of {{XIX International Scientific-expert Conference}} on {{Railways}} – {{RAILCON}} 2020},
  author = {Ristić-Durrant, Danijela and Haseeb, Muhammad Abdul and Banić, Milan and Stamenković, Dušan and Simonović, Miloš and Miltenović, Aleksandar and Nikolić, Vlastimir and Nikolić, Dragan},
  date = {0015/2020-10-16},
  pages = {9},
  location = {{Niš, Serbia}},
  abstract = {In this paper, a novel integrated multi-sensor on-board obstacle detection (OD) system developed within the project “SMART-SMart Automation of Rail Transport”, which was funded under the H2020-Shift2Rail-RIA funding scheme, is presented. The SMART OD system combines different vision technologies: thermal camera, night vision sensor (camera augmented with image intensifier), three zoomed RGB cameras, and laser scanner in order to create a sensor fusion system for mid (up to 200 m) and long range (up to 1000 m) autonomous obstacle detection, which is independent of light and weather conditions. All SMART OD sensors were integrated into the sensor housing to enable easy mount and dismount onto/from different test vehicles in different evaluation tests. The integrated OD system prototype was evaluated in dynamic field tests, which were performed on Serbian railway test-site in July 2018 and in May 2019. In the dynamic field tests, the SMART on-board integrated OD system was mounted onto the SERBIA CARGO locomotive 444-017 pulling the freight train with 21 wagons on the Pan European corridor X to Thessaloniki in the length of 120 km. Innovative SMART hardware, supported with novel machine learning-based computer vision software, enabled reliable obstacle detection and fullfiment of functional requirements: frontal obstacle detection, object detection in different environmental and lighting conditions, and long-range obstacle detection. Regarding the latter, the SMART goal was to advance state-of-the-art by long-range object detection. In the first project phase the goal was to go beyond 200 m (mid-range), while in the second project phase the detection distance up to the range between 800 and 1000m (error ±10). Beside the evaluation positive results, this paper also discusses the limitations of SMART OD system and provides lessons learned regarding the additional requirements for autonomous obstacle detection in railways.},
  eventtitle = {{{XIX International Scientific-expert Conference}} on {{Railways}} – {{RAILCON}} 2020},
  langid = {english},
  keywords = {Gimbal Paper},
  file = {/home/cornelius/Zotero/storage/A4BR78BQ/Ristić-Durrant et al. - 2020 - OBSTACLE DETECTION FOR RAILWAYS LESSONS LEARNED F.pdf}
}

@article{ristic-durrantReviewVisionBasedOnBoard2021,
  title = {A {{Review}} of {{Vision-Based On-Board Obstacle Detection}} and {{Distance Estimation}} in {{Railways}}},
  author = {Ristić-Durrant, Danijela and Franke, Marten and Michels, Kai},
  date = {2021-05-15},
  year = {2021},
  journal = {MDPI Sensors},
  publisher = {MDPI},
  shortjournal = {Sensors},
  volume = {21},
  number = {10},
  pages = {3452},
  issn = {1424-8220},
  doi = {10.3390/s21103452},
  urldate = {2021-08-27},
  abstract = {This paper provides a review of the literature on vision-based on-board obstacle detection and distance estimation in railways. Environment perception is crucial for autonomous detection of obstacles in a vehicle’s surroundings. The use of on-board sensors for road vehicles for this purpose is well established, and advances in Artificial Intelligence and sensing technologies have motivated significant research and development in obstacle detection in the automotive field. However, research and development on obstacle detection in railways has been less extensive. To the best of our knowledge, this is the first comprehensive review of on-board obstacle detection methods for railway applications. This paper reviews currently used sensors, with particular focus on vision sensors due to their dominant use in the field. It then discusses and categorizes the methods based on vision sensors into methods based on traditional Computer Vision and methods based on Artificial Intelligence.},
  langid = {english},
  keywords = {Gimbal Paper,IMPORTANT},
  file = {/home/cornelius/Zotero/storage/HUZ7E4Y6/Ristić-Durrant et al. - 2021 - A Review of Vision-Based On-Board Obstacle Detecti.pdf}
}



@article{ristic-durrantSMARTOnboardMultisensor2021,
  title = {{{SMART}} On-Board Multi-Sensor Obstacle Detection System for Improvement of Rail Transport Safety},
  author = {Ristić-Durrant, Danijela and Haseeb, Muhammad Abdul and Banić, Milan and Stamenković, Dušan and Simonović, Miloš and Nikolić, Dragan},
  date = {2021-07-16},
  journal = {Proceedings of the Institution of Mechanical Engineers, Part F: Journal of Rail and Rapid Transit},
  shortjournal = {Proceedings of the Institution of Mechanical Engineers, Part F: Journal of Rail and Rapid Transit},
  pages = {095440972110327},
  issn = {0954-4097, 2041-3017},
  doi = {10.1177/09544097211032738},
  url = {http://journals.sagepub.com/doi/10.1177/09544097211032738},
  urldate = {2021-07-29},
  abstract = {This paper presents an on-board multi-sensor system which is able to detect obstacles and estimate their distances in railway scenes in different illumination conditions. The system was developed within the H2020 Shift2Rail project SMART (Smart Automation of Rail Transport) and aims at increasing the safety of rail transport by detecting obstacles on the rail tracks ahead of a moving train in order to reduce the number of collisions. The system hardware consists of cameras of different types integrated into a specially designed housing, mounted on the front of the train. Multiple vision sensors complement each other in order to handle different illumination and environmental conditions. The system software uses a novel machine learning-based method that is suited to a particular challenge of railway operations, the need for long-range obstacle detection and distance estimation. The development of this method used a long-range railway dataset, which was specifically generated for this project. Evaluation results of reliable obstacle detection in various environmental conditions using the SMART RGB camera in day light illumination conditions and using the SMART Night Vision sensor in poor (night) illumination conditions are presented. The results demonstrate both the potential of the on-board SMART obstacle detection system in the operational railway environment and the benefit of the use of different cameras to be more independent of light and environmental conditions.},
  langid = {english},
  keywords = {Anomaly Paper,Gimbal Paper},
  file = {/home/cornelius/Zotero/storage/3PCCDCDU/Ristić-Durrant et al. - 2021 - SMART on-board multi-sensor obstacle detection sys.pdf}
}

@inproceedings{ruderObstacleDetectionSystem2003,
  title = {An Obstacle Detection System for Automated Trains},
  booktitle = {{{IEEE IV2003 Intelligent Vehicles Symposium}}. {{Proceedings}} ({{Cat}}. {{No}}.{{03TH8683}})},
  author = {Ruder, M. and Mohler, N. and Ahmed, F.},
  date = {2003},
  pages = {180--185},
  publisher = {{IEEE}},
  location = {{Columbus, OH, USA}},
  doi = {10.1109/IVS.2003.1212905},
  url = {https://ieeexplore.ieee.org/document/1212905/},
  urldate = {2021-06-30},
  abstract = {Safety is an important topic for any railway system. If trains are running on a track, which is not guarded of o6jects by fences or other means, special care for obstacles in front of the train needs to be taken. On a normal tmin, this is the task of the train driver. When implementing automated trains, a substitute is needed to ensure the same safety level as in normal operations. Therefore an obstacle detection system is required for safe operations. During the KC)IMPAS project we developed a systim capable of monitoring the track and detecting objects in front of an auto-miteh:train.},
  eventtitle = {{{IEEE IV2003 Intelligent Vehicles Symposium}}. {{Proceedings}}},
  isbn = {978-0-7803-7848-3},
  langid = {english},
  keywords = {Anomaly Paper,Gimbal Paper},
  file = {/home/cornelius/Zotero/storage/A7APCVYA/Ruder et al. - 2003 - An obstacle detection system for automated trains.pdf}
}

@inproceedings{saikaAccuracyImprovementHuman2016,
  title = {Accuracy Improvement in Human Detection Using {{HOG}} Features on Train-Mounted Camera},
  booktitle = {2016 {{IEEE}} 5th {{Global Conference}} on {{Consumer Electronics}}},
  author = {Saika, Shintaro and Takahashi, Saki and Takeuchi, Masara and Katto, Jiro},
  date = {2016-10},
  pages = {1--2},
  publisher = {{IEEE}},
  location = {{Kyoto, Japan}},
  doi = {10.1109/GCCE.2016.7800373},
  url = {http://ieeexplore.ieee.org/document/7800373/},
  urldate = {2021-10-26},
  abstract = {Nowadays, researches on accident prevention using train-mounted cameras had been progressing. Our proposed method considers temporal continuity between frames by using motion vectors in addition to conventional thresholding on similarity values obtained by a human detection method using HOG features. Experiments show the effectiveness of our method as compared with a previous method using only HOG features.},
  eventtitle = {2016 {{IEEE}} 5th {{Global Conference}} on {{Consumer Electronics}}},
  isbn = {978-1-5090-2333-2},
  langid = {english},
  keywords = {Gimbal Paper},
  file = {/home/cornelius/Zotero/storage/P2KGSPL9/Saika et al. - 2016 - Accuracy improvement in human detection using HOG .pdf}
}

@article{soilanReviewLaserScanning2019,
  title = {Review of {{Laser Scanning Technologies}} and {{Their Applications}} for {{Road}} and {{Railway Infrastructure Monitoring}}},
  author = {{Soilán} and {Sánchez-Rodríguez} and {Río-Barral} and {Perez-Collazo} and {Arias} and {Riveiro}},
  date = {2019-09-20},
  journal = {Infrastructures},
  shortjournal = {Infrastructures},
  volume = {4},
  number = {4},
  pages = {58},
  issn = {2412-3811},
  doi = {10.3390/infrastructures4040058},
  url = {https://www.mdpi.com/2412-3811/4/4/58},
  urldate = {2022-03-05},
  abstract = {Improving the resilience of infrastructures is key to reduce their risk vulnerability and mitigate impact from hazards at different levels (e.g., from increasing extreme events, driven by climate change); or from human-made events such as: accidents, vandalism or terrorist actions. One of the most relevant aspects of resilience is preparation. This is directly related to: (i) the risk prediction capability; (ii) the infrastructure monitoring; and (iii) the systems contributing to anticipate, prevent and prepare the infrastructure for potential damage. This work focuses on those methods and technologies that contribute to more efficient and automated infrastructure monitoring. Therefore, a review that summarizes the state of the art of LiDAR (Light Detection And Ranging)-based data processing is presented, giving a special emphasis to road and railway infrastructure. The most relevant applications related to monitoring and inventory transport infrastructures are discussed. Furthermore, different commercial LiDAR-based terrestrial systems are described and compared to offer a broad scope of the available sensors and tools to remote monitoring infrastructures based on terrestrial systems.},
  langid = {english},
  file = {/home/cornelius/Zotero/storage/HF485R5I/Soilán et al. - 2019 - Review of Laser Scanning Technologies and Their Ap.pdf}
}

@article{stainoRealTimeDetectionRecognition2022,
  title = {Real-{{Time Detection}} and {{Recognition}} of {{Railway Traffic Signals Using Deep Learning}}},
  author = {Staino, Andrea and Suwalka, Akshat and Mitra, Pabitra and Basu, Biswajit},
  date = {2022-04},
  journal = {Journal of Big Data Analytics in Transportation},
  shortjournal = {J. Big Data Anal. Transp.},
  volume = {4},
  number = {1},
  pages = {57--71},
  issn = {2523-3556, 2523-3564},
  doi = {10.1007/s42421-022-00054-7},
  url = {https://link.springer.com/10.1007/s42421-022-00054-7},
  urldate = {2022-08-30},
  abstract = {Automated detection and recognition of traffic signals are of great significance in railway systems. Autonomous driving solutions are well established for urban rail transportation systems. Many metro lines in service worldwide have reached the highest grade of automation where the train is automatically operated without any staff on board. However, autonomous driving is still an open challenge for mainline trains, due to the complexity of the mainline environment. In this context, automated recognition of wayside signals can help to minimise the risk of human error owing to low visibility and fatigue. It represents a key step towards the fully autonomous train. In this article we present a deep learning based approach for the above task. The You Only Look Once (YOLOv5) is used for detection and recognition of wayside signals. A heuristic is used to recognise blinking states. We consider FRSign dataset, a large collection of over 100,000 images of traffic signals from some of the trains in French Railways. A distilled and cleaned version of the dataset curated by us is used for training. The trained network has low computational overhead and can recognise traffic signals in real time and under diverse field conditions. It has robust performance even for complex scenes having multiple signals and light sources, and in adverse circumstances such as rain and night environments. The refined version of the dataset is published as open for validation and further research and development.},
  langid = {english},
  file = {/home/cornelius/Zotero/storage/5YEJ8I34/Staino et al. - 2022 - Real-Time Detection and Recognition of Railway Tra.pdf}
}

@inproceedings{stalloGNSSbasedLocationDetermination2018,
  title = {{{GNSS-based}} Location Determination System Architecture for Railway Performance Assessment in Presence of Local Effects},
  booktitle = {2018 {{IEEE}}/{{ION Position}}, {{Location}} and {{Navigation Symposium}} ({{PLANS}})},
  author = {Stallo, Cosimo and Neri, Alessandro and Salvatori, Pietro and Coluccia, Andrea and Capua, Roberto and Olivieri, Giorgia and Gattuso, Luca and Bonenberg, Lukasz and Moore, Terry and Rispoli, Francesco},
  date = {2018},
  pages = {374--381},
  publisher = {{IEEE}}
}

@incollection{sujihelenObjectDetectionRailway2022,
  title = {Object {{Detection}} in {{Railway Track Using Industrial IoT}} ({{IIoT}})},
  booktitle = {Technology {{Innovation}} in {{Mechanical Engineering}}},
  author = {Sujihelen, L. and Kumar, Kota Vinodh and Srinivas, Madhav and Nagarajan, G.},
  editor = {Chaurasiya, Prem Kumar and Singh, Abhishek and Verma, Tikendra Nath and Rajak, Upendra},
  date = {2022},
  series = {Lecture {{Notes}} in {{Mechanical Engineering}}},
  pages = {381--387},
  publisher = {{Springer Nature Singapore}},
  location = {{Singapore}},
  doi = {10.1007/978-981-16-7909-4_35},
  url = {https://link.springer.com/10.1007/978-981-16-7909-4_35},
  urldate = {2022-05-11},
  abstract = {In railway track, more accidents occur due to the objects in the railway track. In train, everyday getting to thousands of passengers traveling by trains. Consequently, the protection of the travelers has to be safeguarded. The proposed system is used to sense the object in the railway track and intimate information to the control office and engine driver. So, this proposed work can observe the object using sensor, and the information about the object is transferred before the 10 min of the arrival of the train. The railroad is totally automated using Bluetooth, RFID, Wi-Fi, GPS, live video streaming, and GPS. The live video stream is transmitted to the cloud from the mobile application. To avoid the accidents, the train may be stopped.},
  isbn = {9789811679087 9789811679094},
  langid = {english},
  file = {/home/cornelius/Zotero/storage/U49T4KZB/Sujihelen et al. - 2022 - Object Detection in Railway Track Using Industrial.pdf}
}

@article{tongFullyDecoupledResidual2021,
  title = {Fully {{Decoupled Residual ConvNet}} for {{Real-Time Railway Scene Parsing}} of {{UAV Aerial Images}}},
  author = {Tong, Lei and Wang, Zhipeng and Jia, Limin and Qin, Yong and Wei, Yanbin and Yang, Huaizhi and Geng, Yixuan},
  date = {2021},
  journal = {IEEE Transactions on Intelligent Transportation Systems},
  shortjournal = {IEEE Trans. Intell. Transport. Syst.},
  pages = {1--14},
  issn = {1524-9050, 1558-0016},
  doi = {10.1109/TITS.2021.3134318},
  url = {https://ieeexplore.ieee.org/document/9655444/},
  urldate = {2022-05-04},
  abstract = {UAV-based automatic railway inspection is expected to have the potential to reform the inspection of railways. In this area, real-time railway scene parsing is quite essential. However, the limited computation resources of the UAV onboard computer pose a huge challenge for the algorithm to juggle a precise prediction with strong timeliness. Concerning this issue, this paper proposes a novel algorithm named deep fully decoupled residual convolutional network, which consists of fully decoupled residual blocks (Non-bottleneck-FDs) to deal with the dilemma between the high demand of real-time and limited resources. The residual block is constructed based on a new convolution which divides the standard convolution into three sequential convolutions to decouple the conventional operational correlations fully. Furthermore, a customized auxiliary line loss (LL) function is proposed to constrain the segmentation of railway and non-railway simultaneously without increasing the computation complexity. The proposed LL can force the predicted railway areas to concentrate in long strip areas precisely and inhibit their appearances in other impossible local areas. Subsequently, an integrated loss backpropagation strategy of the LL and crossentropy function is presented. A comprehensive set of experiments are conducted for verification. Experiments demonstrate the superior performance of our approach with a more than 2× reduction in parameters and computation cost. Moreover, our approach also has a faster inference speed than the most existing lightweight architectures while providing comparable or higher accuracy. It is proven that our approach can reconcile the precise prediction with strong timeliness for railway scene parsing within the limitation of onboard computers. Besides, the results also imply its highest performance in terms of local details and edges of railway areas.},
  langid = {english},
  file = {/home/cornelius/Zotero/storage/SBYXSU8V/Tong et al. - 2021 - Fully Decoupled Residual ConvNet for Real-Time Rai.pdf}
}

@article{ukaiNewSystemDetecting,
  title = {A {{New System}} for {{Detecting Obstacles}} in {{Front}} of a {{Train}}},
  author = {Ukai, Masato},
  date = {2006-03-20},
  journal = {Railway Technology Avalance},
  volume = {No 12},
  pages = {1},
  url = {https://www.rtri.or.jp/eng/publish/newsletter/pdf/12/RTA-12-73.pdf},
  langid = {english},
  keywords = {Gimbal Paper},
  file = {/home/cornelius/Zotero/storage/4UN85NGQ/Ukai - A New System for Detecting Obstacles in Front of a.pdf}
}

@inproceedings{ukaiObstacleDetectionRailway,
  title = {Obstacle {{Detection}} on {{Railway Track}} by {{Fusing Radar}} and {{Image Sensor}}},
  booktitle = {In {{Proceedings}} of the 9th {{World Congress}} on {{Railway Research}} ({{WCRR}})},
  author = {Ukai, Masato and Nassu, Bogdan Tomoyuki and Nagamine, Nozomi and Watanabe, Masato and Inaba, Takayuki},
  date = {2011-05-26},
  pages = {12},
  abstract = {Novel technology to recognize the situation in distant place is necessary to develop a railway safety monitoring system by which human being having fallen onto the tracks from a platform and obstacles in the level crossing can be detected. In this research, we propose a method for detecting a stationary or moving obstacle by the technology which employs the super resolution radar techniques, the image recognition techniques, and the technology to fuse these techniques. Our method is designed for detecting obstacles such as cars, bicycles, and human on the track in the range up to hundreds of meters ahead by using sensors mounted on a train.},
  eventtitle = {World {{Congress}} on {{Railway Research}}},
  langid = {english},
  keywords = {Gimbal Paper},
  file = {/home/cornelius/Zotero/storage/U3K7VNPS/Ukai et al. - Obstacle Detection on Railway Track by Fusing Rada.pdf}
}

@inproceedings{uribeVideoBasedSystem2012,
  title = {Video Based System for Railroad Collision Warning},
  booktitle = {{{IEEE International Carnahan Conference}} on {{Security Technology}}},
  author = {Uribe, Jonny A. and Fonseca, Luis and Vargas, J. F.},
  date = {2012-10},
  year = {2012},
  pages = {280--285},
  location = {{Newton, MA, USA}},
  doi = {10.1109/CCST.2012.6393573},
  urldate = {2021-07-01},
  abstract = {Autonomous systems can assist humans in the important task of safe driving. Such systems can warn people about possible risks, take actions to avoid accidents or guide the vehicle without human supervision. In railway scenarios a camera in front of the train can aid drivers with the identification of obstacles or strange objects that can pose danger to the route. Image processing in these applications is not easy of performing. The changing conditions create scenes where background is hard to detect, lighting varies and process speed must be fast. This article describes a first approximation to the solution of the problem where two complementary approaches are followed for detecting and tracking obstacles on videos captured from a train driver perspective. The first strategy is a simple-frame-based approach where every video frame is analyzed using the Hough transform for detecting the rails. On every rail a systematic search is done detecting obstacles that can be dangerous for the train course. The second approach uses consecutive frames for detecting the trajectory of moving objects. Analyzing the sparse optical flow the candidate objects are tracked and their trajectories computed in order to determine their possible route to collision. For testing the system we have used videos where preselected fixed and moving obstacles have been superimposed using the Chroma key effect. The system had shown a real time performance in detecting and tracking the objects. Future work includes the test of the system on real scenarios and the validation over changing weather conditions.},
  eventtitle = {2012 {{IEEE International Carnahan Conference}} on {{Security Technology}} ({{ICCST}})},
  isbn = {978-1-4673-2450-2 978-1-4673-2449-6},
  langid = {english},
  keywords = {Gimbal Paper},
  file = {/home/cornelius/Zotero/storage/DFI89Z8B/Uribe et al. - 2012 - Video based system for railroad collision warning.pdf}
}

@article{vhzquezDetectionMovingviOsib,
  title = {Detection of Moving Objects in Railway Using Vision},
  author = {Vhzquez, J and Cabello, J and Hierrezuelo, L},
  pages = {4},
  abstract = {In this paper, a new strategy to detect motion object in railway is presented, using vision and Principal -Components Analysis (PCA). For this purpose, a set of images of the railway static environment is first captured to obtain the transformation matrix that used in PCA. By means of this matrix, the successive images are projected in the transformation space and recovered. The motion detection is performed, evaluating the Euclidean distance between the original and recovered images. The image regions whose Euclidean distance are greater than a threshold, are considered like belonging to motion objects. The new of our system is the utilization of a method to obtain an adaptive threshold that allows to classify, within an image, zones without motion (background) and motion objects. A system with dynamic adjustment of this threshold is proposed, which it compensates to a great extent, illumination and others environmental conditions variations founded in outdoor spaces. Anyway, to show the validity and robustness of this method, the system has been implemented practically.},
  langid = {english},
  file = {/home/cornelius/Zotero/storage/3Q6GJJAF/Vhzquez et al. - Detection of movingvi.osib.ojnects in railway usin.pdf}
}

@unpublished{wallnerRGBDRailwayPlatform2021,
  title = {{{RGB-D Railway Platform Monitoring}} and {{Scene Understanding}} for {{Enhanced Passenger Safety}}},
  author = {Wallner, Marco and Steininger, Daniel and Widhalm, Verena and Schörghuber, Matthias and Beleznai, Csaba},
  date = {2021},
  volume = {12667},
  eprint = {2102.11730},
  eprinttype = {arxiv},
  primaryclass = {cs},
  pages = {656--671},
  doi = {10.1007/978-3-030-68787-8_47},
  url = {http://arxiv.org/abs/2102.11730},
  urldate = {2021-06-30},
  abstract = {Automated monitoring and analysis of passenger movement in safety-critical parts of transport infrastructures represent a relevant visual surveillance task. Recent breakthroughs in visual representation learning and spatial sensing opened up new possibilities for detecting and tracking humans and objects within a 3D spatial context. This paper proposes a flexible analysis scheme and a thorough evaluation of various processing pipelines to detect and track humans on a ground plane, calibrated automatically via stereo depth and pedestrian detection. We consider multiple combinations within a set of RGB- and depth-based detection and tracking modalities. We exploit the modular concepts of Meshroom [2] and demonstrate its use as a generic vision processing pipeline and scalable evaluation framework. Furthermore, we introduce a novel open RGB-D railway platform dataset with annotations to support research activities in automated RGB-D surveillance. We present quantitative results for multiple object detection and tracking for various algorithmic combinations on our dataset. Results indicate that the combined use of depth-based spatial information and learned representations yields substantially enhanced detection and tracking accuracies. As demonstrated, these enhancements are especially pronounced in adverse situations when occlusions and objects not captured by learned representations are present.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {/home/cornelius/Zotero/storage/6WTQ78RL/Wallner et al. - 2021 - RGB-D Railway Platform Monitoring and Scene Unders.pdf}
}

@article{wangAdaptiveTrackSegmentation2019,
  title = {An {{Adaptive Track Segmentation Algorithm}} for a {{Railway Intrusion Detection System}}},
  author = {Wang, Yang and Zhu, Liqiang and Yu, Zujun and Guo, Baoqing},
  date = {2019-06-06},
  journal = {Sensors},
  shortjournal = {Sensors},
  volume = {19},
  number = {11},
  pages = {2594},
  issn = {1424-8220},
  doi = {10.3390/s19112594},
  url = {https://www.mdpi.com/1424-8220/19/11/2594},
  urldate = {2021-07-01},
  abstract = {Video surveillance-based intrusion detection has been widely used in modern railway systems. Objects inside the alarm region, or the track area, can be detected by image processing algorithms. With the increasing number of surveillance cameras, manual labeling of alarm regions for each camera has become time-consuming and is sometimes not feasible at all, especially for pan-tilt-zoom (PTZ) cameras which may change their monitoring area at any time. To automatically label the track area for all cameras, video surveillance system requires an accurate track segmentation algorithm with small memory footprint and short inference delay. In this paper, we propose an adaptive segmentation algorithm to delineate the boundary of the track area with very light computation burden. The proposed algorithm includes three steps. Firstly, the image is segmented into fragmented regions. To reduce the redundant calculation in the evaluation of the boundary weight for generating the fragmented regions, an optimal set of Gaussian kernels with adaptive directions for each specific scene is calculated using Hough transformation. Secondly, the fragmented regions are combined into local areas by using a new clustering rule, based on the region’s boundary weight and size. Finally, a classification network is used to recognize the track area among all local areas. To achieve a fast and accurate classification, a simplified CNN network is designed by using pre-trained convolution kernels and a loss function that can enhance the diversity of the feature maps. Experimental results show that the proposed method finds an effective balance between the segmentation precision, calculation time, and hardware cost of the system.},
  langid = {english},
  file = {/home/cornelius/Zotero/storage/P7D32G6T/Wang et al. - 2019 - An Adaptive Track Segmentation Algorithm for a Rai.pdf}
}

@article{wangIntelligentRailwayForeign,
  title = {Intelligent {{Railway Foreign Object Detection}}: {{A Semi-supervised Convolutional Autoencoder Based Method}}},
  author = {Wang, Tiange and Zhang, Zijun and Yang, Fangfang and Tsui, Kwok-Leung},
  pages = {10},
  abstract = {Automated inspection and detection of foreign objects on railways is important for rail transportation safety as it helps prevent potential accidents and trains derailment. Most existing vision-based approaches focus on the detection of frontal intrusion objects with prior labels, such as categories and locations of the objects. In reality, foreign objects with unknown categories can appear anytime on railway tracks. In this paper, we develop a semi-supervised convolutional autoencoder based framework that only requires railway track images without prior knowledge on the foreign objects in the training process. It consists of three different modules, a bottleneck feature generator as encoder, a photographic image generator as decoder, and a reconstruction discriminator developed via adversarial learning. In the proposed framework, the problem of detecting the presence, location, and shape of foreign objects is addressed by comparing the input and reconstructed images as well as setting thresholds based on reconstruction errors. The proposed method is evaluated through comprehensive studies under different performance criteria. The results show that the proposed method outperforms some wellknown benchmarking methods. The proposed framework is useful for data analytics via the train Internet-of-Things (IoT) systems.},
  langid = {english},
  file = {/home/cornelius/Zotero/storage/VAYHVAY3/Wang et al. - Intelligent Railway Foreign Object Detection A Se.pdf}
}

@article{warnickeImplementationVisionSystem,
  title = {Implementation of a {{Vision System}} for an {{Autonomous Railway Maintenance Vehicle}}},
  author = {Warnicke, Albin and Jönsson, Jesper},
  pages = {58},
  abstract = {Railway infrastructure is often expensive to maintain. To improve efficiency and lower these costs, the use of autonomous railway vehicles for such maintenance has begun to be explored. A railway vehicle requires several components to achieve complete automation, including systems for navigation, decision-making, and sensors such as cameras. This project aims to develop the vision system used by an autonomous track trolley under development at Chalmers University of Technology. The proposed vision system can detect railway tracks and switches by a region-growing algorithm based on the image intensity gradient. Object detection is achieved by the use of a YOLOv4-tiny neural network and is developed to detect persons, vehicles, railway signs and signals, road crossings and catenary support poles. The signal and speed sign messages are further classified by additional convolutional neural networks. The vision system is implemented as a ROS node on a single-board computer, a NVIDIA Jetson Nano, and is running in real-time at up to 15 FPS.},
  langid = {english},
  file = {/home/cornelius/Zotero/storage/KGNZHNT3/Warnicke and Jönsson - Implementation of a Vision System for an Autonomou.pdf}
}

@thesis{warnickeImplementationVisionSystem2021,
  title = {Implementation of a {{Vision System}} for an {{Autonomous Railway Maintenance Vehicle}}: {{Track}} and {{Object Detection}} with {{YOLO}}, {{Neural Networks}} and {{Region Growing}}},
  author = {Warnicke, Albin and Jönsson, Jesper},
  date = {2021-06-27},
  institution = {{Chalmers}},
  url = {https://hdl.handle.net/20.500.12380/302722},
  abstract = {Railway infrastructure is often expensive to maintain. To improve efficiency and lower these costs, the use of autonomous railway vehicles for such maintenance has begun to be explored. A railway vehicle requires several components to achieve complete automation, including systems for navigation, decision-making, and sensors such as cameras. This project aims to develop the vision system used by an autonomous track trolley under development at Chalmers University of Technology. The proposed vision system can detect railway tracks and switches by a region-growing algorithm based on the image intensity gradient. Object detection is achieved by the use of a YOLOv4-tiny neural network and is developed to detect persons, vehicles, railway signs and signals, road crossings and catenary support poles. The signal and speed sign messages are further classified by additional convolutional neural networks. The vision system is implemented as a ROS node on a single-board computer, a NVIDIA Jetson Nano, and is running in real-time at up to 15 FPS. The vision system is accurate and robust enough to be used as a prototype in simple environments. The track that the vehicle is traveling on was detected in 98.4 \% of the evaluated video frames, with the sidetracks correctly identified in 70-80 \% of the time. Several of the considered objects were detected with 90-100 \% accuracy, for example vehicles and road crossings. Other objects, particularly railway switches and incoming tracks, were however only correctly recognized in about 60 \% of their occurrences. Signals and speed signs were detected with high accuracy. Some features can be improved or added before the vision system can be applied to a complete autonomous railway vehicle. The main limitation of the implemented object detection is the lack of large training datasets. With more available video data, datasets with an increased number of labeled objects and greater diversity could be created. Utilizing the full capabilities of larger datasets would eventually require the use of more complex neural networks. The currently used hardware however limits the possible methods to simpler algorithms. The track detection algorithm can serve as a base for further improvement, with the region growing based on the image intensity gradients not being robust enough to handle large variations in lighting and environment conditions. An approach with semantic segmentation neural networks is instead suggested to achieve robust track detection.},
  file = {/home/cornelius/Zotero/storage/W82AVKFD/2021-11 Albin Warnicke & Jesper Jönsson.pdf}
}

@article{weichselbaumAccurate3DvisionbasedObstacle2013,
  title = {Accurate {{3D-vision-based}} Obstacle Detection for an Autonomous Train},
  author = {Weichselbaum, Johann and Zinner, Christian and Gebauer, Oliver and Pree, Wolfgang},
  date = {2013-12},
  journal = {Computers in Industry},
  shortjournal = {Computers in Industry},
  volume = {64},
  number = {9},
  pages = {1209--1220},
  issn = {01663615},
  doi = {10.1016/j.compind.2013.03.015},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0166361513000687},
  urldate = {2021-06-30},
  langid = {english},
  keywords = {Gimbal Paper},
  file = {/home/cornelius/Zotero/storage/A5VMKZUP/Weichselbaum et al. - 2013 - Accurate 3D-vision-based obstacle detection for an.pdf}
}

@inproceedings{wuRailwaySignalIntelligent2021,
  title = {Railway {{Signal Intelligent Monitoring System Based}} on {{Data Mining}}},
  booktitle = {2021 {{IEEE Conference}} on {{Telecommunications}}, {{Optics}} and {{Computer Science}} ({{TOCS}})},
  author = {Wu, Jianjun},
  date = {2021-12-10},
  pages = {315--318},
  publisher = {{IEEE}},
  location = {{Shenyang, China}},
  doi = {10.1109/TOCS53301.2021.9688683},
  url = {https://ieeexplore.ieee.org/document/9688683/},
  urldate = {2022-03-04},
  abstract = {At present, the research invested by the railway department in the development of railway transportation is very huge. The railway transportation related technologies are constantly updated, and the equipment automation and intelligent level are constantly developing, which puts forward higher requirements for railway monitoring. Railway is an indispensable part of railway transportation. Railway signal equipment can reflect the real situation of railway in real time and carry out emergency treatment for the situation of railway, which ensures the safety on the railway transportation road. Therefore, higher standards and requirements should be put forward for the intelligent monitoring system of railway signal. This paper mainly studies the railway signal intelligent monitoring system based on data mining. This paper expounds the design principles of the railway signal intelligent monitoring system to standardize the design of the system, then designs the railway signal intelligent monitoring system, and then expounds the database design, put the collected railway signal equipment data into the database for comparative research, so as to realize fault diagnosis. This paper studies the railway signal intelligent monitoring system in collecting railway signal data samples, comparing them in the database using data mining technology, and comparing their acquaintance degree, so as to understand the actual operation of the monitoring system. The research results show that in the test and research of railway signal intelligent monitoring system, there is little difference in the monitoring time of samples. The average collection time of railway signal samples is about 4 seconds. The longer the comparison time, the higher the similarity between the samples and fault manifestation data. For example, the comparison time of sample 5 occupies 8.93 seconds, and its similarity estimation index is 13.91.},
  eventtitle = {2021 {{IEEE Conference}} on {{Telecommunications}}, {{Optics}} and {{Computer Science}} ({{TOCS}})},
  isbn = {978-1-66542-498-1},
  langid = {english},
  file = {/home/cornelius/Zotero/storage/DGUZ6SRA/Wu - 2021 - Railway Signal Intelligent Monitoring System Based.pdf}
}

@inproceedings{xingfangRailwayClearanceIntrusion2018,
  title = {Railway Clearance Intrusion Detection Method with Binocular Stereo Vision},
  booktitle = {Young {{Scientists Forum}} 2017},
  author = {Xingfang, Zhou and Baoqing, Guo and Wei, Wei},
  editor = {Zhuang, Songlin and Chu, Junhao and Pan, Jian-Wei},
  date = {2018-03-05},
  pages = {45},
  publisher = {{SPIE}},
  location = {{Shanghai, China}},
  doi = {10.1117/12.2315784},
  url = {https://www.spiedigitallibrary.org/conference-proceedings-of-spie/10710/2315784/Railway-clearance-intrusion-detection-method--with-binocular-stereo-vision/10.1117/12.2315784.full},
  urldate = {2021-06-30},
  abstract = {In the stage of railway construction and operation, objects intruding railway clearance greatly threaten the safety of railway operation. Real-time intrusion detection is of great importance. For the shortcomings of depth insensitive and shadow interference of single image method, an intrusion detection method with binocular stereo vision is proposed to reconstruct the 3D scene for locating the objects and judging clearance intrusion. The binocular cameras are calibrated with Zhang Zhengyou’s method. In order to improve the 3D reconstruction speed, a suspicious region is firstly determined by background difference method of a single camera’s image sequences. The image rectification, stereo matching and 3D reconstruction process are only executed when there is a suspicious region. A transformation matrix from Camera Coordinate System(CCS) to Track Coordinate System(TCS) is computed with gauge constant and used to transfer the 3D point clouds into the TCS, then the 3D point clouds are used to calculate the object position and intrusion in TCS. The experiments in railway scene show that the position precision is better than 10mm. It is an effective way for clearance intrusion detection and can satisfy the requirement of railway application.},
  eventtitle = {Young {{Scientists Forum}} 2017},
  isbn = {978-1-5106-1977-7 978-1-5106-1978-4},
  langid = {english},
  keywords = {Gimbal Paper},
  file = {/home/cornelius/Zotero/storage/M89LYY2B/Xingfang et al. - 2018 - Railway clearance intrusion detection method with .pdf}
}

@inproceedings{xunguDesignRailwayObstacle2017,
  title = {Design of Railway Obstacle Detection Prototype},
  booktitle = {2017 {{Pattern Recognition Association}} of {{South Africa}} and {{Robotics}} and {{Mechatronics}} ({{PRASA-RobMech}})},
  author = {Xungu, Sipho and Notununu, Lwando and Mbizeni, Asanda and Dickens, John},
  date = {2017-11},
  pages = {56--61},
  publisher = {{IEEE}},
  location = {{Bloemfontein, South Africa}},
  doi = {10.1109/RoboMech.2017.8261123},
  url = {http://ieeexplore.ieee.org/document/8261123/},
  urldate = {2021-10-26},
  abstract = {Locomotives are at risk to collisions and derailment due to obstacles on the track. Trains do not have the ability to steer around obstacles, they are confined to the track and depend on stopping to avoid hazards. These accidents often result in loss of life and revenue. Due to the great momentum of the locomotives stopping distance required exceeds the operator’s sight distance. The Mechatronics and Micro-Manufacturing (MMM) division of CSIR have researched, designed and developed a rail Survey Inspection Device (SID) test prototype platform to serve as an early warning system for locomotives and was to travel 2km ahead of a locomotive in order to inspect the railway for possible obstacles such as human beings, livestock and collisions between the locomotives and was semi-autonomously controlled to maintain the appropriate headway in front of the train. Testing was performed by placing simulated obstacles on a test track facility in Pyramid South and data received from a simulated environment is processed on board and transmitted from SID to the train operator. System engineering principles were implemented to integrate and streamline the platform subsystems such as driving system, sensor control system and body design. The results indicate that the introduction of SID to the railway industry has the potential to significantly reduce accidents, loss of lives and revenue.},
  eventtitle = {2017 {{Pattern Recognition Association}} of {{South Africa}} and {{Robotics}} and {{Mechatronics}} ({{PRASA-RobMech}})},
  isbn = {978-1-5386-2314-5},
  langid = {english},
  file = {/home/cornelius/Zotero/storage/JMUWQWRI/Xungu et al. - 2017 - Design of railway obstacle detection prototype.pdf}
}

@inproceedings{xuRealtimeObstacleDetection2019,
  title = {Real-Time {{Obstacle Detection Over Rails Using Deep Convolutional Neural Network}}},
  booktitle = {2019 {{IEEE Intelligent Transportation Systems Conference}} ({{ITSC}})},
  author = {Xu, Yuchuan and Gao, Chunhai and Yuan, Lei and Tang, Simon and Wei, Guodong},
  date = {2019-10},
  pages = {1007--1012},
  publisher = {{IEEE}},
  location = {{Auckland, New Zealand}},
  doi = {10.1109/ITSC.2019.8917091},
  url = {https://ieeexplore.ieee.org/document/8917091/},
  urldate = {2021-10-26},
  abstract = {In vision-based environment perceptive system of urban rail transit, cameras installed in the front of the train can assist people to identify obstacles on rails. Varying environment makes small targets like pedestrians and bags hard to identify, thus the real-time and accuracy performance of the detection need to be improved. Inspired by the achievements of Single Shot Multibox Detection (SSD) successfully applied on images recognition in recent years, we presented an obstacle detection algorithm which consists of two steps: main network and feature fusion. In the first part, the input image is converted into multi-scale feature maps based on the Residual Neural Network. Next, a series of convolution layers are added to extract features, and the network outputs a confidence score and bounding boxes for possible obstacles. Experiments showed that the proposed method can detect obstacles in various environment. Compared with traditional object detection algorithms and other deep learning algorithms, it runs at a faster detection speed (26 frames per second, FPS) and higher detection accuracy (91.61\% mean average precision, mAP) on our self-made dataset.},
  eventtitle = {2019 {{IEEE Intelligent Transportation Systems Conference}} - {{ITSC}}},
  isbn = {978-1-5386-7024-8},
  langid = {english},
  keywords = {Anomaly Paper,Gimbal Paper},
  file = {/home/cornelius/Zotero/storage/I5CMXYUK/Xu et al. - 2019 - Real-time Obstacle Detection Over Rails Using Deep.pdf}
}

@report{yamashitaDevelopmentRailwayObstacle1996,
  title = {Development of {{Railway Obstacle Detection System}}},
  author = {Yamashita, Hiroshi and Iida, Yasuhisa and Nakamoto, Jun and Koyama, Yasushi and Sato, Masanobu},
  date = {1996},
  institution = {{Mitsubishi Heavy Industries}},
  keywords = {Gimbal Paper},
  file = {/home/cornelius/Zotero/storage/E3TII3NZ/digidepo_8615945_po_e331016.pdf}
}

@article{yeApplicationLightweightRailway2021,
  title = {Application of {{Lightweight Railway Transit Object Detector}}},
  author = {Ye, Tao and Ren, Cong and Zhang, Xi and Zhai, Guodong and Wang, Rui},
  date = {2021-10},
  journal = {IEEE Transactions on Industrial Electronics},
  shortjournal = {IEEE Trans. Ind. Electron.},
  volume = {68},
  number = {10},
  pages = {10269--10280},
  issn = {0278-0046, 1557-9948},
  doi = {10.1109/TIE.2020.3021640},
  url = {https://ieeexplore.ieee.org/document/9194146/},
  urldate = {2022-08-03},
  abstract = {Intelligent traffic systems for railway object detection have become the focus of research in recent years. Accurate and fast object detection using a camera is an important but challenging problem in the railway industry. In this article, we propose an object detector with low power yet robust detection for collision warning in a train safety system. The proposed object detector comprises three modules. First, a stable sampling module is used to reduce the dimensions of the feature map and image information loss. Second, a lightweight feature extraction module utilizes a dynamic bottleneck structure to control the calculation load and enhance the expressive ability of the model. Third, a feature-fusion module combines highand low-level features to enhance the semantic information and improve the accuracy of detection of multiscale and small objects. Experimental results demonstrate that the proposed network achieves reasonable results for railway object detection and outperforms the current state-of-theart detectors. Finally, we design an obstacle-avoidance device that can be installed at the front of the train for real-time security warning in real-world conditions.},
  langid = {english},
  file = {/home/cornelius/Zotero/storage/66L2QY4R/Ye et al. - 2021 - Application of Lightweight Railway Transit Object .pdf}
}

@article{yeAutomaticRailwayTraffic2018,
  title = {Automatic {{Railway Traffic Object Detection System Using Feature Fusion Refine Neural Network}} under {{Shunting Mode}}},
  author = {Ye, Tao and Wang, Baocheng and Song, Ping and Li, Juan},
  date = {2018-06-12},
  journal = {Sensors},
  shortjournal = {Sensors},
  volume = {18},
  number = {6},
  pages = {1916},
  issn = {1424-8220},
  doi = {10.3390/s18061916},
  url = {http://www.mdpi.com/1424-8220/18/6/1916},
  urldate = {2021-10-26},
  abstract = {Many accidents happen under shunting mode when the speed of a train is below 45 km/h. In this mode, train attendants observe the railway condition ahead using the traditional manual method and tell the observation results to the driver in order to avoid danger. To address this problem, an automatic object detection system based on convolutional neural network (CNN) is proposed to detect objects ahead in shunting mode, which is called Feature Fusion Refine neural network (FR-Net). It consists of three connected modules, i.e., the depthwise-pointwise convolution, the coarse detection module, and the object detection module. Depth-wise-pointwise convolutions are used to improve the detection in real time. The coarse detection module coarsely refine the locations and sizes of prior anchors to provide better initialization for the subsequent module and also reduces search space for the classification, whereas the object detection module aims to regress accurate object locations and predict the class labels for the prior anchors. The experimental results on the railway traffic dataset show that FR-Net achieves 0.8953 mAP with 72.3 FPS performance on a machine with a GeForce GTX1080Ti with the input size of 320 × 320 pixels. The results imply that FR-Net takes a good tradeoff both on effectiveness and real time performance. The proposed method can meet the needs of practical application in shunting mode.},
  langid = {english},
  keywords = {Gimbal Paper},
  file = {/home/cornelius/Zotero/storage/HLJH9WYN/Ye et al. - 2018 - Automatic Railway Traffic Object Detection System .pdf}
}

@article{yeRailwayTrafficObject2021,
  title = {Railway {{Traffic Object Detection Using Differential Feature Fusion Convolution Neural Network}}},
  author = {Ye, Tao and Zhang, Xi and Zhang, Yi and Liu, Jie},
  date = {2021-03},
  year = {2021},
  journal = {IEEE Transactions on Intelligent Transportation Systems},
  shortjournal = {IEEE Trans. Intell. Transport. Syst.},
  volume = {22},
  number = {3},
  pages = {1375--1387},
  issn = {1524-9050, 1558-0016},
  doi = {10.1109/TITS.2020.2969993},
  urldate = {2021-10-26},
  abstract = {Railway shunting accidents, in which trains collide with obstacles, often occur because of human error or fatigue. It is therefore necessary to detect traffic objects in front of the trains and inform the driver to take timely action. To detect these objects in railways, we proposed an object-detection method using a differential feature fusion convolutional neural network (DFF-Net). DFF-Net includes two modules: the prior objectdetection module and the object-detection module. The prior module produces initial anchor boxes for the subsequent detection module. Taking the initial anchor boxes as input, the objectdetection module applies a differential feature fusion sub-module to enrich the sematic information for object detection, enhancing the detection performance, particularly for small objects. In experiments conducted on a railway traffic dataset, compared with the current state-of-the-art detectors, the proposed method exhibited significant higher performance and was more effective and more efficient than the other methods for object detection in railway tracks. Additionally, evaluation results based on PASCAL VOC2007 and VOC2012 indicated that the proposed method was significantly better than the state-of-the-art methods.},
  langid = {english},
  keywords = {Gimbal Paper},
  file = {/home/cornelius/Zotero/storage/4KIE5IV9/Ye et al. - 2021 - Railway Traffic Object Detection Using Differentia.pdf}
}

@article{yeStableLightweightAdaptive2022,
  title = {A {{Stable Lightweight}} and {{Adaptive Feature Enhanced Convolution Neural Network}} for {{Efficient Railway Transit Object Detection}}},
  author = {Ye, Tao and Zhao, Zongyang and Wang, Shouan and Zhou, Fuqiang and Gao, Xiaozhi},
  date = {2022},
  journal = {IEEE Transactions on Intelligent Transportation Systems},
  shortjournal = {IEEE Trans. Intell. Transport. Syst.},
  pages = {1--14},
  issn = {1524-9050, 1558-0016},
  doi = {10.1109/TITS.2022.3156267},
  url = {https://ieeexplore.ieee.org/document/9740479/},
  urldate = {2022-04-29},
  abstract = {Obstacles in front of a train pose a significant threat to traffic safety, and many accidents happen under shunting mode when the speed of a train is below 45 km/h. The existing track object–detection algorithms encounter difficulty in balancing the detection precision and speed in shunting mode. Additionally, their accuracy is insufficient, particularly for small objects in complex environments. To address these problems, we propose a stable lightweight feature extraction and adaptive feature fusion network for real-time detection of obstacles in railway traffic scenarios to ensure driving safety. The proposed network consists of three modules. The stable bottom feature extraction module reduces the computational load and extracts more image information stably. The lightweight feature extraction module improves feature extraction using a simple and effective network. The enhanced adaptive feature fusion module fuses the image and original features, improving the multiscale detection accuracy under complex environments, particularly in the case of small objects. With a default input size of 416 × 416 pixels (px), the proposed method achieves a detection speed of 81 FPS and a mean average precision of 94.75\% for the railway traffic dataset as well as a detection speed of 78 FPS (26 FPS faster and 0.47\% higher than those of YOLOv4, respectively) and a mean average precision of 42.5\% for MS COCO. This indicates its potential for real-world railway object detection and other multi-target detection tasks. Additionally, the experimental results based on PASCAL VOC2007 and VOC2012 indicate that the proposed approach is considerably better than the state-of-the-art models.},
  langid = {english},
  file = {/home/cornelius/Zotero/storage/PNRF2CT7/Ye et al. - 2022 - A Stable Lightweight and Adaptive Feature Enhanced.pdf}
}

@article{yokoyamaDetectionClassificationPolelike,
  title = {Detection and {{Classification}} of {{Pole-like Objects}} from {{Mobile Laser Scanning Data}} of {{Urban Environments}}},
  author = {Yokoyama, Hiroki and Date, Hiroaki and Kanai, Satoshi and Takeda, Hiroshi},
  date = {2013-01},
  journal = {International Journal of CAD/CAM},
  shortjournal = {International Journal of CAD/CAM},
  volume = {13},
  number = {1},
  pages = {10},
  url = {http://sdmwww.ssi.ist.hokudai.ac.jp/unofficialpapers/2012ACDDE_yokoyama.pdf},
  abstract = {The Mobile Laser Scanning (MLS) system can acquire point clouds of urban environments including roads, buildings, trees, lamp posts etc. and enables effective mapping of them. With the spread of the MLS system, the demands for the management of roads and facilities using MLS point clouds have increased. Especially, pole-like objects (PLOs) such as lamp posts, utility poles, street signs etc. are strongly expected to be managed efficiently. We propose a method for detecting PLOs from MLS point clouds and classifying them into three classes: utility poles, lamp posts, and street signs. Our detection method is based on the feature extraction using point classification by Principal Component Analysis (PCA). On the other hand, our classification method is based on not only shape features of the PLOs, but also context features which are derived from the surrounding PLOs distributions. In order to evaluate the accuracy of PLOs detection and classification through our method, we applied our method to MLS point clouds of urban environments.},
  langid = {english},
  keywords = {Gimbal Paper},
  file = {/home/cornelius/Zotero/storage/FT2P8MJE/Yokoyama et al. - Detection and Classification of Pole-like Objects .pdf}
}

@inproceedings{yuRailwayObstacleDetection2018,
  title = {Railway Obstacle Detection Algorithm Using Neural Network},
  booktitle = {{{AIP Conference Proceedings}}},
  author = {Yu, Mingyang and Yang, Peng and Wei, Sen},
  date = {2018},
  pages = {040017},
  location = {{Busan, South Korea}},
  doi = {10.1063/1.5039091},
  url = {http://aip.scitation.org/doi/abs/10.1063/1.5039091},
  urldate = {2021-10-26},
  eventtitle = {{{6TH INTERNATIONAL CONFERENCE ON COMPUTER-AIDED DESIGN}}, {{MANUFACTURING}}, {{MODELING AND SIMULATION}} ({{CDMMS}} 2018)},
  keywords = {Gimbal Paper},
  file = {/home/cornelius/Zotero/storage/WU287XY7/Yu et al. - 2018 - Railway obstacle detection algorithm using neural .pdf}
}

@inproceedings{zendelRailSem19DatasetSemantic2019,
  title = {{{RailSem19}}: {{A Dataset}} for {{Semantic Rail Scene Understanding}}},
  shorttitle = {{{RailSem19}}},
  booktitle = {2019 {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition Workshops}} ({{CVPRW}})},
  author = {Zendel, Oliver and Murschitz, Markus and Zeilinger, Marcel and Steininger, Daniel and Abbasi, Sara and Beleznai, Csaba},
  date = {2019-06},
  pages = {1221--1229},
  publisher = {{IEEE}},
  location = {{Long Beach, CA, USA}},
  doi = {10.1109/CVPRW.2019.00161},
  url = {https://ieeexplore.ieee.org/document/9025646/},
  urldate = {2021-07-01},
  abstract = {Solving tasks for autonomous road vehicles using computer vision is a dynamic and active research field. However, one aspect of autonomous transportation has received little contributions: the rail domain. In this paper, we introduce the first public dataset for semantic scene understanding for trains and trams: RailSem19. This dataset consists of 8500 annotated short sequences from the ego-perspective of trains, including over 1000 examples with railway crossings and 1200 tram scenes. Since it is the first image dataset targeting the rail domain, a novel label policy has been designed from scratch. It focuses on rail-specific labels not covered by any other datasets. In addition to manual annotations in the form of geometric shapes, we also supply dense pixel-wise semantic labeling. The dense labeling is a semantic-aware combination of (a) the geometric shapes and (b) weakly supervised annotations generated by existing semantic segmentation networks from the road domain. Finally, multiple experiments give a first impression on how the new dataset can be used to improve semantic scene understanding in the rail environment. We present prototypes for the image-based classification of trains, switches, switch states, platforms, buffer stops, rail traffic signs and rail traffic lights. Applying transfer learning, we present an early prototype for pixel-wise semantic segmentation on rail scenes. The resulting predictions show that this new data also significantly improves scene understanding in situations where cars and trains interact.},
  eventtitle = {2019 {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition Workshops}} ({{CVPRW}})},
  isbn = {978-1-72812-506-0},
  langid = {english},
  keywords = {Anomaly Paper},
  file = {/home/cornelius/Zotero/storage/VAY48HKG/Zendel et al. - 2019 - RailSem19 A Dataset for Semantic Rail Scene Under.pdf}
}

@article{zhangyuCameraLiDARData2021,
  title = {A {{Camera}} and {{LiDAR Data Fusion Method}} for {{Railway Object Detection}}},
  author = {Zhangyu, Wang and Guizhen, Yu and Xinkai, Wu and Haoran, Li and Da, Li},
  date = {2021-06-15},
  journal = {IEEE Sensors Journal},
  shortjournal = {IEEE Sensors J.},
  volume = {21},
  number = {12},
  pages = {13442--13454},
  issn = {1530-437X, 1558-1748, 2379-9153},
  doi = {10.1109/JSEN.2021.3066714},
  url = {https://ieeexplore.ieee.org/document/9380436/},
  urldate = {2021-07-01},
  langid = {english},
  keywords = {Gimbal Paper,IMPORTANT},
  file = {/home/cornelius/Zotero/storage/EBBYTIZP/Zhangyu et al. - 2021 - A Camera and LiDAR Data Fusion Method for Railway .pdf}
}

@book{ETCSEngineers2011,
  title = {{{ETCS}} for {{Engineers}}},
  author = {Stanley, Peter},
  year = {2011},
  edition = {1. Aufl},
  publisher = {{TZ-Verl. \& Print Gmbh}},
  address = {{Ro\ss dorf}},
  isbn = {978-3-96245-034-2},
  langid = {english}
}




@Article{s19143075,
AUTHOR = {Guo, Baoqing and Geng, Gan and Zhu, Liqiang and Shi, Hongmei and Yu, Zujun},
TITLE = {High-Speed Railway Intruding Object Image Generating with Generative Adversarial Networks},
JOURNAL = {MDPI Sensors},
Publisher = {{MDPI}},
VOLUME = {19},
YEAR = {2019},
NUMBER = {14},
ARTICLE-NUMBER = {3075},
ISSN = {1424-8220},
ABSTRACT = {Foreign object intrusion is a great threat to high-speed railway safety operations. Accurate foreign object intrusion detection is particularly important. As a result of the lack of intruding foreign object samples during the operational period, artificially generated ones will greatly benefit the development of the detection methods. In this paper, we propose a novel method to generate railway intruding object images based on an improved conditional deep convolutional generative adversarial network (C-DCGAN). It consists of a generator and multi-scale discriminators. Loss function is also improved so as to generate samples with a high quality and authenticity. The generator is extracted in order to generate foreign object images from input semantic labels. We synthesize the generated objects to the railway scene. To make the generated objects more similar to real objects, on scale in different positions of a railway scene, a scale estimation algorithm based on the gauge constant is proposed. The experimental results on the railway intruding object dataset show that the proposed C-DCGAN model outperforms several state-of-the-art methods and achieves a higher quality (the pixel-wise accuracy, mean intersection-over-union (mIoU), and mean average precision (mAP) are 80.46%, 0.65, and 0.69, respectively) and diversity (the Fr&eacute;chet-Inception Distance (FID) score is 26.87) of generated samples. The mIoU of the real-generated pedestrian pairs reaches 0.85, and indicates a higher scale of accuracy for the generated intruding objects in the railway scene.},
DOI = {10.3390/s19143075}
}

@article{He2016,
abstract = {Deeper neural networks are more difficult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We provide comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets with a depth of up to 152 layers - 8× deeper than VGG nets [40] but still having lower complexity. An ensemble of these residual nets achieves 3.57% error on the ImageNet test set. This result won the 1st place on the ILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100 and 1000 layers. The depth of representations is of central importance for many visual recognition tasks. Solely due to our extremely deep representations, we obtain a 28% relative improvement on the COCO object detection dataset. Deep residual nets are foundations of our submissions to ILSVRC & COCO 2015 competitions1, where we also won the 1st places on the tasks of ImageNet detection, ImageNet localization, COCO detection, and COCO segmentation.},
archivePrefix = {arXiv},
arxivId = {1512.03385},
author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
doi = {10.1109/CVPR.2016.90},
eprint = {1512.03385},
file = {:home/matthias/Documents/thesis_papers/related_work/1512.03385.pdf:pdf},
isbn = {9781467388504},
issn = {10636919},
journal = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
pages = {770--778},
title = {{Deep residual learning for image recognition}},
year = {2016}
}
@article{Luo2016,
abstract = {We study characteristics of receptive fields of units in deep convolutional networks. The receptive field size is a crucial issue in many visual tasks, as the output must respond to large enough areas in the image to capture information about large objects. We introduce the notion of an effective receptive field, and show that it both has a Gaussian distribution and only occupies a fraction of the full theoretical receptive field. We analyze the effective receptive field in several architecture designs, and the effect of nonlinear activations, dropout, sub-sampling and skip connections on it. This leads to suggestions for ways to address its tendency to be too small.},
archivePrefix = {arXiv},
arxivId = {1701.04128},
author = {Luo, Wenjie and Li, Yujia and Urtasun, Raquel and Zemel, Richard},
eprint = {1701.04128},
file = {:home/matthias/Documents/thesis_papers/related_work/1701.04128.pdf:pdf},
issn = {10495258},
journal = {Advances in Neural Information Processing Systems},
volume = {29},
pages = {4905--4913},
title = {{Understanding the effective receptive field in deep convolutional neural networks}},
year = {2016}
}
@article{Kraskov2008,
archivePrefix = {arXiv},
arxivId = {arXiv:q-bio/0311039v2},
author = {Kraskov, Alexander and St{\"{o}}gbauer, Harald and Andrzejak, Ralph G and Grassberger, Peter},
eprint = {0311039v2},
file = {:home/matthias/Documents/thesis_papers/related_work/Hierarchical_Clustering_Based_on_Mutual_Informatio.pdf:pdf},
journal = {EPL (Europhysics Letters)},
volume = {70},
number = {2},
primaryClass = {arXiv:q-bio},
title = {{Hierarchical Clustering Using Mutual Information}},
year = {2005}
}
@article{Rubner2000,
abstract = {We investigate the properties of a metric between two distributions, the Earth Mover's Distance (EMD), for content-based image retrieval. The EMD is based on the minimal cost that must be paid to transform one distribution into the other, in a precise sense, and was first proposed for certain vision problems by Peleg, Werman, and Rom. For image retrieval, we combine this idea with a representation scheme for distributions that is based on vector quantization. This combination leads to an image comparison framework that often accounts for perceptual similarity better than other previously proposed methods. The EMD is based on a solution to the transportation problem from linear optimization, for which efficient algorithms are available, and also allows naturally for partial matching. It is more robust than histogram matching techniques, in that it can operate on variable-length representations of the distributions that avoid quantization and other binning problems typical of histograms. When used to compare distributions with the same overall mass, the EMD is a true metric. In this paper we focus on applications to color and texture, and we compare the retrieval performance of the EMD with that of other distances.},
author = {Rubner, Yossi and Tomasi, Carlo and Guibas, Leonidas J.},
doi = {10.1023/A:1026543900054},
file = {:home/matthias/Documents/thesis_papers/related_work/Rubner2000_Article_TheEarthMoverSDistanceAsAMetri.pdf:pdf},
issn = {09205691},
journal = {International Journal of Computer Vision},
keywords = {color,earth mover,image retrieval,perceptual metrics,s distance,texture},
number = {2},
pages = {99--121},
title = {{The earth mover's distance as a metric for image retrieval}},
volume = {40},
year = {2000}
}
@article{Mirza2014,
abstract = {Generative Adversarial Nets [8] were recently introduced as a novel way to train generative models. In this work we introduce the conditional version of generative adversarial nets, which can be constructed by simply feeding the data, y, we wish to condition on to both the generator and discriminator. We show that this model can generate MNIST digits conditioned on class labels. We also illustrate how this model could be used to learn a multi-modal model, and provide preliminary examples of an application to image tagging in which we demonstrate how this approach can generate descriptive tags which are not part of training labels.},
archivePrefix = {arXiv},
journal = {arXiv 1411.1784},
author = {Mirza, Mehdi and Osindero, Simon},
eprint = {1411.1784},
file = {:home/matthias/Documents/thesis_papers/related_work/1411.1784.pdf:pdf},
title = {{Conditional Generative Adversarial Nets}},
year = {2014}
}
@article{Luo2019,
abstract = {Generative adversarial network(GAN) is an active branch of deep learning field, which has become a popular research direction in the field of artificial intelligence. GAN adopts an unsupervised learning method and automatically learns from the source data, which can produce amazing effects without artificially labeling data. In this paper, we present the background, basic idea of GAN and comb its related theory, training mechanism and state-of-the-art applications. We also summarize the common network architectures, training skills and model evaluation metrics, and compareGAN with other generative model VAE and GAN variants. Finally, we point out the advantages and disadvantages of the GAN and look forward to the further development direction.},
author = {Creswell, Antonia and White, Tom and Dumoulin, Vincent and Arulkumaran, Kai and Sengupta, Biswa and Bharath, Anil A.},
doi = {10.19650/j.cnki.cjsi.J1804413},
file = {:home/matthias/Documents/thesis_papers/related_work/Generative_Adversarial_Networks_An_Overview.pdf:pdf},
issn = {02543087},
journal = {IEEE Signal Processing Magazine},
keywords = {Adversarial training,Deep learning,Generative adversarial network,Machine learning,Unsupervised learning},
number = {1},
pages = {53--65},
publisher = {IEEE},
title = {{Generative adversarial networks: An overview}},
volume = {35},
year = {2018}
}
@article{Chen2017,
abstract = {In this work, we revisit atrous convolution, a powerful tool to explicitly adjust filter's field-of-view as well as control the resolution of feature responses computed by Deep Convolutional Neural Networks, in the application of semantic image segmentation. To handle the problem of segmenting objects at multiple scales, we design modules which employ atrous convolution in cascade or in parallel to capture multi-scale context by adopting multiple atrous rates. Furthermore, we propose to augment our previously proposed Atrous Spatial Pyramid Pooling module, which probes convolutional features at multiple scales, with image-level features encoding global context and further boost performance. We also elaborate on implementation details and share our experience on training our system. The proposed `DeepLabv3' system significantly improves over our previous DeepLab versions without DenseCRF post-processing and attains comparable performance with other state-of-art models on the PASCAL VOC 2012 semantic image segmentation benchmark.},
archivePrefix = {arXiv},
arxivId = {1706.05587},
author = {Chen, Liang-Chieh and Papandreou, George and Kokkinos, Iasonas and Murphy, Kevin and Yuille, Alan L.},
eprint = {1706.05587},
file = {:home/matthias/Documents/thesis_papers/related_work/1706.05587.pdf:pdf},
title = {{Deeplab: Semantic image segmentation with deep convolutional nets, atrous convolution, and fully connected crfs.}},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
volume = {40},
number = {4}, 
pages = {834--848},
year = {2017}
}
@article{Cohen2020,
abstract = {Nearest neighbor (kNN) methods utilizing deep pre-trained features exhibit very strong anomaly detection performance when applied to entire images. A limitation of kNN methods is the lack of segmentation map describing where the anomaly lies inside the image. In this work we present a novel anomaly segmentation approach based on alignment between an anomalous image and a constant number of the similar normal images. Our method, Semantic Pyramid Anomaly Detection (SPADE) uses correspondences based on a multi-resolution feature pyramid. SPADE is shown to achieve state-of-the-art performance on unsupervised anomaly detection and localization while requiring virtually no training time.},
archivePrefix = {arXiv},
journal = {arXiv 2005.02357},
author = {Cohen, Niv and Hoshen, Yedid},
eprint = {2005.02357},
file = {:home/matthias/Documents/thesis_papers/related_work/2005.02357.pdf:pdf},
keywords = {anomaly detection,feature pyramid,nearest-neighbors},
title = {{Sub-Image Anomaly Detection with Deep Pyramid Correspondences}},
year = {2020},
}
@article{Shi2021,
abstract = {Automatic detecting anomalous regions in images of objects or textures without priors of the anomalies is challenging, especially when the anomalies appear in very small areas of the images, making difficult-to-detect visual variations, such as defects on manufacturing products. This paper proposes an effective unsupervised anomaly segmentation approach that can detect and segment out the anomalies in small and confined regions of images. Concretely, we develop a multi-scale regional feature generator which can generate multiple spatial context-aware representations from pre-trained deep convolutional networks for every subregion of an image. The regional representations not only describe the local characteristics of corresponding regions but also encode their multiple spatial context information, making them discriminative and very beneficial for anomaly detection. Leveraging these descriptive regional features, we then design a deep yet efficient convolutional autoencoder and detect anomalous regions within images via fast feature reconstruction. Our method is simple yet effective and efficient. It advances the state-of-the-art performances on several benchmark datasets and shows great potential for real applications.},
author = {Shi, Yong and Yang, Jie and Qi, Zhiquan},
doi = {10.1016/j.neucom.2020.11.018},
file = {:home/matthias/Documents/thesis_papers/related_work/Shi20-Unsupervisedanomalysegmentationviadeepfeaturereconstruction-.pdf:pdf},
issn = {18728286},
journal = {Neurocomputing},
keywords = {Anomaly detection,Anomaly segmentation,Feature reconstruction,Regional representation},
pages = {9--22},
publisher = {Elsevier},
title = {{Unsupervised anomaly segmentation via deep feature reconstruction}},
volume = {424},
year = {2021}
}
@article{Schlegl2017,
abstract = {Obtaining models that capture imaging markers relevant for disease progression and treatment monitoring is challenging. Models are typically based on large amounts of data with annotated examples of known markers aiming at automating detection. High annotation effort and the limitation to a vocabulary of known markers limit the power of such approaches. Here, we perform unsupervised learning to identify anomalies in imaging data as candidates for markers. We propose AnoGAN, a deep convolutional generative adversarial network to learn a manifold of normal anatomical variability, accompanying a novel anomaly scoring scheme based on the mapping from image space to a latent space. Applied to new data, the model labels anomalies, and scores image patches indicating their fit into the learned distribution. Results on optical coherence tomography images of the retina demonstrate that the approach correctly identifies anomalous images, such as images containing retinal fluid or hyperreflective foci.},
archivePrefix = {arXiv},
arxivId = {1703.05921},
author = {Schlegl, Thomas and Seeb{\"{o}}ck, Philipp and Waldstein, Sebastian M. and Schmidt-Erfurth, Ursula and Langs, Georg},
doi = {10.1007/978-3-319-59050-9_12},
eprint = {1703.05921},
file = {:home/matthias/Documents/thesis_papers/related_work/1703.05921.pdf:pdf},
isbn = {9783319590493},
issn = {16113349},
journal = {International Conference on Information Processing in Medical Imaging},
pages = {146--157},
title = {{Unsupervised anomaly detection with generative adversarial networks to guide marker discovery}},
year = {2017}
}


@incollection{Akcay2019,
  doi = {10.1007/978-3-030-20893-6_39},
  year = {2019},
  publisher = {Springer International Publishing},
  pages = {622--637},
  author = {Samet Akcay and Amir Atapour-Abarghouei and Toby P. Breckon},
  title = {{GANomaly}: Semi-supervised Anomaly Detection via Adversarial Training},
  booktitle = {Computer Vision}
}


@article{Zenati2018,
abstract = {Generative adversarial networks (GANs) are able to model the complex highdimensional distributions of real-world data, which suggests they could be effective for anomaly detection. However, few works have explored the use of GANs for the anomaly detection task. We leverage recently developed GAN models for anomaly detection, and achieve state-of-the-art performance on image and network intrusion datasets, while being several hundred-fold faster at test time than the only published GAN-based method.},
archivePrefix = {arXiv},
arxivId = {1802.06222},
author = {Zenati, Houssam and Foo, Chuan Sheng and Lecouat, Bruno and Manek, Gaurav and Chandrasekhar, Vijay Ramaseshan},
eprint = {1802.06222},
file = {:home/matthias/Documents/thesis_papers/related_work/1802.06222.pdf:pdf},
title = {{Adversarially learned anomaly detection}},
year = {2018},
journal = {IEEE International Conference on Data Mining},
pages = {727--736}
}
@article{Pu2014,
abstract = {This study is designed to develop an advanced safety system that is able to detect the existence of moving obstacles at a railway crossing. In a miniature railway crossing, scaled 1:22.5, the authors installed a grayscale CCD camera and developed a graphical user interface to process the images of the crossing. To achieve this goal, the software was programmed to perform several image processing techniques such as image subtraction, binarization, morphological transformation and segmentation to track down the moving obstacles. In addition, portions of the monitored image around the rails were labeled as alert and alarm zones where detected obstacles would trigger the sirens of this system. Under various lighting conditions for the model cars with different colors in the indoor environment, the experiments on the developed system demonstrated that the level of illuminance was a significant factor affecting the average alert accuracy rate but the color of cars was not. Overall, the average alert accuracy rate reached 97.8%. The promising results of the system's capability to recognize obstacles that might pose threats, merit pursuit of full-scale development at railway crossing sites to provide effective protection against previously undetected, now preventable incidents.},
author = {Pu, Yong-Ren and Chen, Li-Wei and Lee, Su-Hsing},
journal = {Information Technology Journal},
pages = {2611--2618},
title = {{Study of Moving Obstacle Detection at Railway Crossing by Machine Vision}},
volume = {13},
year = {2014}
}
@article{Golan2018,
abstract = {We consider the problem of anomaly detection in images, and present a new detection technique. Given a sample of images, all known to belong to a “normal” class (e.g., dogs), we show how to train a deep neural model that can detect out-of-distribution images (i.e., non-dog objects). The main idea behind our scheme is to train a multi-class model to discriminate between dozens of geometric transformations applied on all the given images. The auxiliary expertise learned by the model generates feature detectors that effectively identify, at test time, anomalous images based on the softmax activation statistics of the model when applied on transformed images. We present extensive experiments using the proposed detector, which indicate that our technique consistently improves all known algorithms by a wide margin.},
archivePrefix = {arXiv},
arxivId = {1805.10917},
author = {Golan, Izhak and El-Yaniv, Ran},
eprint = {1805.10917},
file = {:home/matthias/Documents/thesis_papers/related_work/1805.10917.pdf:pdf},
issn = {10495258},
journal = {Advances in Neural Information Processing Systems},
pages = {9758--9769},
title = {{Deep anomaly detection using geometric transformations}},
volume = {31},
year = {2018}
}
@article{Zong2018,
abstract = {Unsupervised anomaly detection on multi- or high-dimensional data is of great importance in both fundamental machine learning research and industrial applications, for which density estimation lies at the core. Although previous approaches based on dimensionality reduction followed by density estimation have made fruitful progress, they mainly suffer from decoupled model learning with inconsistent optimization goals and incapability of preserving essential information in the low-dimensional space. In this paper, we present a Deep Autoencoding Gaussian Mixture Model (DAGMM) for unsupervised anomaly detection. Our model utilizes a deep autoencoder to generate a low-dimensional representation and reconstruction error for each input data point, which is further fed into a Gaussian Mixture Model (GMM). Instead of using decoupled two-stage training and the standard Expectation-Maximization (EM) algorithm, DAGMM jointly optimizes the parameters of the deep autoencoder and the mixture model simultaneously in an end-to-end fashion, leveraging a separate estimation network to facilitate the parameter learning of the mixture model. The joint optimization, which well balances autoencoding reconstruction, density estimation of latent representation, and regularization, helps the autoencoder escape from less attractive local optima and further reduce reconstruction errors, avoiding the need of pre-training. Experimental results on several public benchmark datasets show that, DAGMM significantly outperforms state-of-the-art anomaly detection techniques, and achieves up to 14% improvement based on the standard F1 score.},
author = {Zong, Bo and Song, Qi and Min, Martin Renqiang and Cheng, Wei and Lumezanu, Cristian and Cho, Daeki and Chen, Haifeng},
file = {:home/matthias/Documents/thesis_papers/related_work/deep_autoencoding_gaussian_mix.pdf:pdf},
journal = {International Conference on Learning Representations},
pages = {1--19},
title = {{Deep autoencoding Gaussian mixture model for unsupervised anomaly detection}},
year = {2018}
}
@article{Ruff2018,
abstract = {Despite the great advances made by deep learning in many machine learning problems, there is a relative dearth of deep learning approaches for anomaly detection. Those approaches which do exist involve networks trained to perform a task other than anomaly detection, namely generative models or compression, which are in turn adapted for use in anomaly detection; they are not trained on an anomaly detection based objective. In this paper we introduce a new anomaly detection method-Deep Support Vector Data Description-, which is trained on an anomaly detection based objective. The adaptation to the deep regime necessitates that our neural network and training procedure satisfy certain properties, which we demonstrate theoretically. We show the effectiveness of our method on MNIST and CIFAR-10 image benchmark dataseis as well as on the detection of adversarial examples of GT-SRB stop signs.},
author = {Ruff, Lukas and Vandermeulen, Robert A. and G{\"{o}}rnitz, Nico and Deecke, Lucas and Siddiqui, Shoaib A. and Binder, Alexander and M{\"{u}}ller, Emmanuel and Kloft, Marius},
file = {:home/matthias/Documents/thesis_papers/related_work/ruff18a.pdf:pdf},
isbn = {9781510867963},
journal = {35th International Conference on Machine Learning},
pages = {6981--6996},
title = {{Deep one-class classification}},
volume = {10},
year = {2018}
}
@article{Oza2019,
abstract = {We present a novel convolutional neural network (CNN) based approach for one-class classification. The idea is to use a zero centered Gaussian noise in the latent space as the pseudo-negative class and train the network using the cross-entropy loss to learn a good representation as well as the decision boundary for the given class. A key feature of the proposed approach is that any pre-trained CNN can be used as the base network for one-class classification. The proposed one-class CNN is evaluated on the UMDAA-02 Face, Abnormality-1001, and FounderType-200 datasets. These datasets are related to a variety of one-class application problems such as user authentication, abnormality detection, and novelty detection. Extensive experiments demonstrate that the proposed method achieves significant improvements over the recent state-of-the-art methods. The source code is available at: github.com/otkupjnoz/oc-cnn.},
archivePrefix = {arXiv},
arxivId = {1901.08688},
author = {Oza, Poojan and Patel, Vishal M.},
doi = {10.1109/LSP.2018.2889273},
eprint = {1901.08688},
file = {:home/matthias/Documents/thesis_papers/related_work/1901.08688.pdf:pdf},
issn = {10709908},
journal = {IEEE Signal Processing Letters},
keywords = {One class classification,convolutional neural networks,representation learning},
number = {2},
pages = {277--281},
title = {{One-Class Convolutional Neural Network}},
volume = {26},
year = {2019}
}
@article{GhasemiGol2009,
abstract = {This paper presents a novel Boundary-based approach in one-class classification that is inspired by support vector data description (SVDD). The SVDD is a popular kernel method which tries to fit a hypersphere around the target objects and of course more precise boundary is relied on selecting proper parameters for the kernel functions. Even with a flexible Gaussian kernel function, the SVDD could sometimes generate a loose decision boundary. Here we modify the structure of the SVDD by using a hyperellipse to specify the boundary of the target objects with more precision, in the input space. Due to the usage of a hyperellipse instead of a hypersphere as the decision boundary, we named it "Ellipse Support Vector Data Description" (ESVDD). We show that the ESVDD can generate a tighter data description in the kernel space as well as the input space. Furthermore the proposed algorithm boundaries on the contrary of SVDD boundaries are less influenced by change of the user defined parameters. {\textcopyright} 2009 Springer-Verlag.},
author = {GhasemiGol, Mohammad and Monsefi, Reza and Yazdi, Hadi Sadoghi},
doi = {10.1007/978-3-642-03969-0_24},
file = {:home/matthias/Documents/thesis_papers/related_work/Tax-Duin2004_Article_SupportVectorDataDescription.pdf:pdf},
isbn = {3642039685},
issn = {18650929},
journal = {Communications in Computer and Information Science},
keywords = {Mapping functions,One-class classification,Outlier detection,Support vector data description},
pages = {257--268},
title = {{Ellipse support vector data description}},
volume = {43 CCIS},
year = {2009}
}
@article{Scholkopf2001,
abstract = {Suppose you are given some data set drawn from an underlying probability distribution P and you want to estimate a "simple" subset S of input space such that the probability that a test point drawn from P lies outside of S equals some a priori specified value between 0 and 1. We propose a method to approach this problem by trying to estimate a function f that is positive on S and negative on the complement. The functional form of f is given by a kernel expansion in terms of a potentially small subset of the training data; it is regularized by controlling the length of the weight vector in an associated feature space. The expansion coefficients are found by solving a quadratic programming problem, which we do by carrying out sequential optimization over pairs of input patterns. We also provide a theoretical analysis of the statistical performance of our algorithm. The algorithm is a natural extension of the support vector algorithm to the case of unlabeled data.},
author = {Sch{\"{o}}lkopf, Bernhard and Platt, John C. and Shawe-Taylor, John and Smola, Alex J. and Williamson, Robert C.},
doi = {10.1162/089976601750264965},
file = {:home/matthias/Documents/thesis_papers/related_work/Estimating_Support_of_a_High-Dimensional_Distribut.pdf:pdf},
isbn = {0899766017502},
issn = {08997667},
journal = {Neural Computation},
number = {7},
pages = {1443--1471},
pmid = {11440593},
title = {{Estimating the support of a high-dimensional distribution}},
volume = {13},
year = {2001}
}
@article{Yang2021,
abstract = {Visual anomaly detection is an important and challenging problem in the field of machine learning and computer vision. This problem has attracted a considerable amount of attention in relevant research communities. Especially in recent years, the development of deep learning has sparked an increasing interest in the visual anomaly detection problem and brought a great variety of novel methods. In this paper, we provide a comprehensive survey of the classical and deep learning-based approaches for visual anomaly detection in the literature. We group the relevant approaches in view of their underlying principles and discuss their assumptions, advantages, and disadvantages carefully. We aim to help the researchers to understand the common principles of visual anomaly detection approaches and identify promising research directions in this field.},
author = {Yang, Jie and Xu, Ruijie and Qi, Zhiquan and Shi, Yong},
doi = {10.1016/j.procs.2022.01.057},
file = {:home/matthias/Documents/thesis_papers/unsupervised_anomaly_detection/anomaly_detection_review.pdf:pdf},
issn = {18770509},
journal = {Procedia Computer Science},
keywords = {Deep learning,Visual anomaly,Visual anomaly detection},
pages = {471--478},
publisher = {Elsevier B.V.},
title = {{Visual Anomaly Detection for Images: A Systematic Survey}},
volume = {199},
year = {2021}
}
@article{Kingma2014,
abstract = {How can we perform efficient inference and learning in directed probabilistic models, in the presence of continuous latent variables with intractable posterior distributions, and large datasets? We introduce a stochastic variational inference and learning algorithm that scales to large datasets and, under some mild differentiability conditions, even works in the intractable case. Our contributions is two-fold. First, we show that a reparameterization of the variational lower bound yields a lower bound estimator that can be straightforwardly optimized using standard stochastic gradient methods. Second, we show that for i.i.d. datasets with continuous latent variables per datapoint, posterior inference can be made especially efficient by fitting an approximate inference model (also called a recognition model) to the intractable posterior using the proposed lower bound estimator. Theoretical advantages are reflected in experimental results.},
archivePrefix = {arXiv},
arxivId = {1312.6114},
author = {Kingma, Diederik P. and Welling, Max},
eprint = {1312.6114},
file = {:home/matthias/Documents/thesis_papers/related_work/1312.6114.pdf:pdf},
journal = {International Conference on Learning Representations},
pages = {1--14},
title = {{Auto-encoding variational bayes}},
year = {2014}
}
@article{Nalisnick2019,
abstract = {A neural network deployed in the wild may be asked to make predictions for inputs that were drawn from a different distribution than that of the training data. A plethora of work has demonstrated that it is easy to find or synthesize inputs for which a neural network is highly confident yet wrong. Generative models are widely viewed to be robust to such mistaken confidence as modeling the density of the input features can be used to detect novel, out-of-distribution inputs. In this paper we challenge this assumption. We find that the density learned by flow-based models, VAEs, and PixelCNNs cannot distinguish images of common objects such as dogs, trucks, and horses (i.e. CIFAR-10) from those of house numbers (i.e. SVHN), assigning a higher likelihood to the latter when the model is trained on the former. Moreover, we find evidence of this phenomenon when pairing several popular image data sets: FashionMNIST vs MNIST, CelebA vs SVHN, ImageNet vs CIFAR-10 / CIFAR-100 / SVHN. To investigate this curious behavior, we focus analysis on flow-based generative models in particular since they are trained and evaluated via the exact marginal likelihood. We find such behavior persists even when we restrict the flows to constant-volume transformations. These transformations admit some theoretical analysis, and we show that the difference in likelihoods can be explained by the location and variances of the data and the model curvature. Our results caution against using the density estimates from deep generative models to identify inputs similar to the training distribution until their behavior for out-of-distribution inputs is better understood.},
archivePrefix = {arXiv},
arxivId = {1810.09136},
author = {Nalisnick, Eric and Matsukawa, Akihiro and Teh, Yee Whye and Gorur, Dilan and Lakshminarayanan, Balaji},
eprint = {1810.09136},
file = {:home/matthias/Documents/thesis_papers/related_work/1810.09136.pdf:pdf},
journal = {7th International Conference on Learning Representations, ICLR 2019},
pages = {1--19},
title = {{Do deep generative models know what they don't know?}},
year = {2019}
}
@article{Kingma2018,
abstract = {Flow-based generative models (Dinh et al., 2014) are conceptually attractive due to tractability of the exact log-likelihood, tractability of exact latent-variable inference, and parallelizability of both training and synthesis. In this paper we propose Glow, a simple type of generative flow using an invertible 1 × 1 convolution. Using our method we demonstrate a significant improvement in log-likelihood on standard benchmarks. Perhaps most strikingly, we demonstrate that a flow-based generative model optimized towards the plain log-likelihood objective is capable of efficient realistic-looking synthesis and manipulation of large images. The code for our model is available at https://github.com/openai/glow.},
archivePrefix = {arXiv},
arxivId = {1807.03039},
author = {Kingma, Diederik P. and Dhariwal, Prafulla},
eprint = {1807.03039},
file = {:home/matthias/Documents/thesis_papers/related_work/1807.03039-1.pdf:pdf},
issn = {10495258},
journal = {Advances in Neural Information Processing Systems},
pages = {10215--10224},
title = {{Glow: Generative flow with invertible 1×1 convolutions}},
year = {2018}
}
@article{Gong2019,
abstract = {Deep autoencoder has been extensively used for anomaly detection. Training on the normal data, the autoencoder is expected to produce higher reconstruction error for the abnormal inputs than the normal ones, which is adopted as a criterion for identifying anomalies. However, this assumption does not always hold in practice. It has been observed that sometimes the autoencoder 'generalizes' so well that it can also reconstruct anomalies well, leading to the miss detection of anomalies. To mitigate this drawback for autoencoder based anomaly detector, we propose to augment the autoencoder with a memory module and develop an improved autoencoder called memory-augmented autoencoder, i.e. MemAE. Given an input, MemAE firstly obtains the encoding from the encoder and then uses it as a query to retrieve the most relevant memory items for reconstruction. At the training stage, the memory contents are updated and are encouraged to represent the prototypical elements of the normal data. At the test stage, the learned memory will be fixed, and the reconstruction is obtained from a few selected memory records of the normal data. The reconstruction will thus tend to be close to a normal sample. Thus the reconstructed errors on anomalies will be strengthened for anomaly detection. MemAE is free of assumptions on the data type and thus general to be applied to different tasks. Experiments on various datasets prove the excellent generalization and high effectiveness of the proposed MemAE.},
archivePrefix = {arXiv},
arxivId = {1904.02639},
author = {Gong, Dong and Liu, Lingqiao and Le, Vuong and Saha, Budhaditya and Mansour, Moussa Reda and Venkatesh, Svetha and {Van Den Hengel}, Anton},
eprint = {1904.02639},
file = {:home/matthias/Documents/thesis_papers/unsupervised_anomaly_detection/Memorizing_Normality_to_Detect_Anomaly_Memory-Augmented_Deep_Autoencoder_for_Unsupervised.pdf:pdf},
isbn = {9781728148038},
issn = {15505499},
journal = {Proceedings of the IEEE International Conference on Computer Vision},
pages = {1705--1714},
title = {{Memorizing normality to detect anomaly（无监督重构法-MemAE-ICCV2019）}},
volume = {2019-Octob},
year = {2019}
}
@article{Lis2019,
abstract = {Classical semantic segmentation methods, including the recent deep learning ones, assume that all classes observed at test time have been seen during training. In this paper, we tackle the more realistic scenario where unexpected objects of unknown classes can appear at test time. The main trends in this area either leverage the notion of prediction uncertainty to flag the regions with low confidence as unknown, or rely on autoencoders and highlight poorly-decoded regions. Having observed that, in both cases, the detected regions typically do not correspond to unexpected objects, in this paper, we introduce a drastically different strategy: It relies on the intuition that the network will produce spurious labels in regions depicting unexpected objects. Therefore, resynthesizing the image from the resulting semantic map will yield significant appearance differences with respect to the input image. In other words, we translate the problem of detecting unknown classes to one of identifying poorly-resynthesized image regions. We show that this outperforms both uncertainty- and autoencoder-based methods.},
archivePrefix = {arXiv},
arxivId = {1904.07595},
author = {Lis, Krzysztof and Nakka, Krishna Kanth and Fua, Pascal and Salzmann, Mathieu},
doi = {10.1109/ICCV.2019.00224},
eprint = {1904.07595},
file = {:home/matthias/Documents/thesis_papers/image_resynthesis.pdf:pdf},
isbn = {9781728148038},
issn = {15505499},
journal = {Proceedings of the IEEE/CVF International Conference on Computer Vision},
pages = {2152--2161},
title = {{Detecting the unexpected via image resynthesis}},
year = {2019}
}
@article{Gast2018,
abstract = {Even though probabilistic treatments of neural networks have a long history, they have not found widespread use in practice. Sampling approaches are often too slow already for simple networks. The size of the inputs and the depth of typical CNN architectures in computer vision only compound this problem. Uncertainty in neural networks has thus been largely ignored in practice, despite the fact that it may provide important information about the reliability of predictions and the inner workings of the network. In this paper, we introduce two lightweight approaches to making supervised learning with probabilistic deep networks practical: First, we suggest probabilistic output layers for classification and regression that require only minimal changes to existing networks. Second, we employ assumed density filtering and show that activation uncertainties can be propagated in a practical fashion through the entire network, again with minor changes. Both probabilistic networks retain the predictive power of the deterministic counterpart, but yield uncertainties that correlate well with the empirical error induced by their predictions. Moreover, the robustness to adversarial examples is significantly increased.},
archivePrefix = {arXiv},
arxivId = {1805.11327},
author = {Gast, Jochen and Roth, Stefan},
doi = {10.1109/CVPR.2018.00355},
eprint = {1805.11327},
file = {:home/matthias/Documents/thesis_papers/lightweight_probabilistic_deep_networks.pdf:pdf},
isbn = {9781538664209},
issn = {10636919},
journal = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
pages = {3369--3378},
title = {{Lightweight Probabilistic Deep Networks}},
year = {2018}
}
@article{Wang2018a,
abstract = {Rail area detection is essential in active obstacle perception system of the train. This paper presents an efficient rail area detection method based on the convolutional neural network (CNN). The proposed method is divided into two main parts: extraction of the rail area and further optimization. First, a CNN architecture is established to achieve accurate rail area detection, enabling the pixel-level classification of the rail area. It is notable that the main improvement of our architecture is dilated cascade connection and cascade sampling. Second, an improved polygon fitting method is applied to optimize the contour of the extracted rail area and, thus, obtains a more elegant outline of the rail region. As shown by the experimental results, the excellent accuracy is obtained by using our method, i.e., 98.46% mean intersection-over-union and 99.15% mean pixel accuracy on the BH-rail-dataset, and verified the applicability of our detection method in a large-scale traffic scene video frames of Beijing metro Yanfang line and Shanghai metro line 6.},
author = {Wang, Zhangyu and Wu, Xinkai and Yu, Guizhen and Li, Mingxing},
doi = {10.1109/ACCESS.2018.2883704},
file = {:home/matthias/Documents/thesis_papers/railway_obstacle_detection/Efficient_Rail_Area_Detection_Using_Convolutional_Neural_Network.pdf:pdf},
issn = {21693536},
journal = {IEEE Access},
keywords = {Rail area detection,convolutional neural network,polygon fitting},
pages = {77656--77664},
publisher = {IEEE},
title = {{Efficient rail area detection using convolutional neural network}},
volume = {6},
year = {2018}
}
@article{Gasparini2020,
abstract = {The ability to detect, localize and classify objects that are anomalies is a challenging task in the computer vision community. In this paper, we tackle these tasks developing a framework to automatically inspect the railway during the night. Specifically, it is able to predict the presence, the image coordinates and the class of obstacles. To deal with the low-light environment, the framework is based on thermal images and consists of three different modules that address the problem of detecting anomalies, predicting their image coordinates and classifying them. Moreover, due to the absolute lack of publicly-released datasets collected in the railway context for anomaly detection, we introduce a new multi-modal dataset, acquired from a rail drone, used to evaluate the proposed framework. Experimental results confirm the accuracy of the framework and its suitability, in terms of computational load, performance, and inference time, to be implemented on a self-powered inspection system.},
author = {Gasparini, Riccardo and D'Eusanio, Andrea and Borghi, Guido and Pini, Stefano and Scaglione, Giuseppe and Calderara, Simone and Fedeli, Eugenio and Cucchiara, Rita},
doi = {10.1109/ICPR48806.2021.9412972},
file = {:home/matthias/Documents/thesis_papers/railway_obstacle_detection/anomaly_detection_localization_and_classification_for_railway_inspection.pdf:pdf},
isbn = {9781728188089},
issn = {10514651},
journal = {International Conference on Pattern Recognition},
pages = {3419--3426},
title = {{Anomaly detection, localization and classification for railway inspection}},
year = {2020}
}
@article{Chernov2020,
abstract = {The paper proposes an approach to the development of obstacle detection systems on railway tracks for yard locomotives. The proposed approach is illustrated by full-stack technology comprises of hardware construction and software implementation. Original video capture device with double cameras making stereoscopic image recording in the realtime mode has been developed. The novel modified edge detection algorithm recognizes railway tracks and obstacles with on-line noise filtering. Pretrained object detection model containing deep convolution neural network able to distinguish and classify obstacles by its type and size has been implemented. Thus, the yard locomotive equipped with a proposed system can be classified as an intelligent vehicle achieving an autonomous safe-operating unit.},
author = {Chernov, Andrey and Butakova, Maria and Guda, Alexander and Shevchuk, Petr},
file = {:home/matthias/Documents/thesis_papers/railway_obstacle_detection/Development_Of_Intelligent_Obstacle_Detection_System_on_railway_tracks_for_yard_locomotives_using_cnns.pdf:pdf},
isbn = {9783030584610},
issn = {18650937},
keywords = {Convolution neural network,Intelligent transportation system,Obstacle detection system,Railway industry},
pages = {33--43},
publisher = {Springer International Publishing},
title = {{Development of intelligent obstacle detection system on railway tracks for yard locomotives using CNN}},
journal = {European Dependable Computing Conference},
year = {2020}
}

@article{Qi2021,
abstract = {In order to improve the poor adaptability of a single sensor in detection and further improve the train's ability to perceive the running environment ahead, a railway obstacle detection method based on the fusion of microwave radar and image data was proposed. The environment in front of the train collected by the radar is preprocessed to eliminate false and out-of-bounds target signals, and the target within the safety limit is retained. At the same time, the frame difference method is used to detect the obstacles in the image sequence captured by the vehicle camera. The detection results of radar and camera are fused at the decision level. The experimental results show that this method can effectively realize the joint detection of obstacles by microwave radar and machine vision, which makes up for the deficiency of single sensor in obstacle detection.},
author = {Qi, Shuai and Yu, Dong},
doi = {10.1088/1742-6596/1965/1/012141},
file = {:home/matthias/Documents/thesis_papers/railway_obstacle_detection/Railway_obstacle_detection_based_on_radar_and_image_fusion.pdf:pdf},
issn = {17426596},
journal = {Journal of Physics: Conference Series},
number = {1},
title = {{Railway obstacle detection based on radar and image data fusion}},
volume = {1965},
year = {2021}
}
@article{Ristic-Durrant2021a,
abstract = {This paper presents an on-board multi-sensor system which is able to detect obstacles and estimate their distances in railway scenes in different illumination conditions. The system was developed within the H2020 Shift2Rail project SMART (Smart Automation of Rail Transport) and aims at increasing the safety of rail transport by detecting obstacles on the rail tracks ahead of a moving train in order to reduce the number of collisions. The system hardware consists of cameras of different types integrated into a specially designed housing, mounted on the front of the train. Multiple vision sensors complement each other in order to handle different illumination and environmental conditions. The system software uses a novel machine learning-based method that is suited to a particular challenge of railway operations, the need for long-range obstacle detection and distance estimation. The development of this method used a long-range railway dataset, which was specifically generated for this project. Evaluation results of reliable obstacle detection in various environmental conditions using the SMART RGB camera in day light illumination conditions and using the SMART Night Vision sensor in poor (night) illumination conditions are presented. The results demonstrate both the potential of the on-board SMART obstacle detection system in the operational railway environment and the benefit of the use of different cameras to be more independent of light and environmental conditions.},
author = {Risti{\'{c}}-Durrant, Danijela and Haseeb, Muhammad Abdul and Bani{\'{c}}, Milan and Stamenkovi{\'{c}}, Du{\v{s}}an and Simonovi{\'{c}}, Milo{\v{s}} and Nikoli{\'{c}}, Dragan},
doi = {10.1177/09544097211032738},
file = {:home/matthias/Documents/thesis_papers/railway_obstacle_detection/SMART_on-board_multi-sensor_obstacle_detection_system_for_improvement_of_rail_transport_safety.pdf:pdf},
issn = {20413017},
journal = {Proceedings of the Institution of Mechanical Engineers, Part F: Journal of Rail and Rapid Transit},
keywords = {Autonomous obstacle detection,digitization of rail transport,machine learning,vision-based object detection and distance estimat},
title = {{SMART on-board multi-sensor obstacle detection system for improvement of rail transport safety}},
year = {2021}
}
@article{Xu2019,
abstract = {In vision-based environment perceptive system of urban rail transit, cameras installed in the front of the train can assist people to identify obstacles on rails. Varying environment makes small targets like pedestrians and bags hard to identify, thus the real-time and accuracy performance of the detection need to be improved. Inspired by the achievements of Single Shot Multibox Detection (SSD) successfully applied on images recognition in recent years, we presented an obstacle detection algorithm which consists of two steps: main network and feature fusion. In the first part, the input image is converted into multi-scale feature maps based on the Residual Neural Network. Next, a series of convolution layers are added to extract features, and the network outputs a confidence score and bounding boxes for possible obstacles. Experiments showed that the proposed method can detect obstacles in various environment. Compared with traditional object detection algorithms and other deep learning algorithms, it runs at a faster detection speed (26 frames per second, FPS) and higher detection accuracy (91.61% mean average precision, mAP) on our self-made dataset.},
author = {Xu, Yuchuan and Gao, Chunhai and Yuan, Lei and Tang, Simon and Wei, Guodong},
doi = {10.1109/ITSC.2019.8917091},
file = {:home/matthias/Documents/thesis_papers/railway_obstacle_detection/Real-time_Obstacle_Detection_Over_Rails_Using_Deep_Convolutional_Neural_Network.pdf:pdf},
isbn = {9781538670248},
journal = {IEEE Intelligent Transportation Systems Conference},
pages = {1007--1012},
publisher = {IEEE},
title = {{Real-time Obstacle Detection Over Rails Using Deep Convolutional Neural Network}},
year = {2019}
}

@book{Bernardi2020,
author = {Bernardi, Simona and Vittorini, Valeria and Flammini, Francesco and Nardone, Roberto and Marrone, Stefano and Adler, Rasmus},
file = {:home/matthias/Documents/thesis_papers/railway_obstacle_detection/Workshop_on_Artificial_Intelligence_For_Railways_p14.pdf:pdf},
isbn = {978-3-030-58461-0},
title = {{Dependable Computing - EDCC 2020 Workshops}},
url = {http://link.springer.com/10.1007/978-3-030-58462-7},
volume = {1279},
year = {2020}
}
@article{Xiao2021,
abstract = {With the rapid development of urban rail transit, passenger traffic is increasing, and obstacle violations are more frequent, and the safety of train operation under high-density traffic conditions is becoming more and more thought-provoking. In order to monitor the train operating environment in real time, this paper first adopts multi-sensing technology based on machine vision and lidar, which is used to collect video images and ranging data of the track area in real time, and then it performs image preprocessing and division of regions of interest on the collected video. Then, the obstacles in the region of interest are detected to obtain the geometric characteristics and position information of the obstacles. Finally, according to the danger level of the obstacles, determine the degree of impact on train operation , the automatic response mode and manual response mode of the signal system are used to transmit the detection results to the corresponding train to control train operation. Through simulation analysis and experimental verification, the detection accuracy and control performance of the detection method are confirmed, which provides safety guarantee for the train operation.},
author = {Xiao, Tianwen and Xu, Yongneng and Yu, Huimin},
doi = {10.37965/jait.2020.0027},
file = {:home/matthias/Documents/thesis_papers/railway_obstacle_detection/Research_on_obstacle_detection_on_urban_rail_transit_using_multisensor_setup.pdf:pdf},
journal = {Journal of Artificial Intelligence and Technology},
keywords = {multisensor technology,obstacle detection,urban rail transit},
number = {1},
pages = {61--67},
title = {{Research on Obstacle Detection Method of Urban Rail Transit Based on Multisensor Technology}},
volume = {1},
year = {2021}
}
@article{Teng2016,
abstract = {Safety is one of the most concerned issues in traffic and transportation, among which railway detection is a fundamental and necessary research. In this paper, we propose a visual railway detection method based on superpixels rather than pixels. An SVM classifier is learned based on features, on which a TF-IDF like transform is applied, and it greatly improves the performance of the classification. The intracellular decision scheme is proposed to make decisions on a superpixel by using predictions of features within the superpixel. All the superpixels that are predicted as positive constitute the railway to be detected. The proposed railway detection method is evaluated on a number of challenging images and experiments demonstrate that the proposed method is an effective and detailed solution to railway detection, and is superior to other railway detection methods.},
author = {Teng, Zhu and Liu, Feng and Zhang, Baopeng},
doi = {10.1007/s11042-015-2654-x},
file = {:home/matthias/Documents/thesis_papers/railway_obstacle_detection/Visual_Railway_Detection_by_Superpixels.pdf:pdf},
isbn = {1104201526},
issn = {15737721},
journal = {Multimedia Tools and Applications},
keywords = {Intracellular decision scheme,Railway detection,Superpixel},
number = {5},
pages = {2473--2486},
title = {{Visual railway detection by superpixel based intracellular decisions}},
volume = {75},
year = {2016}
}
@article{He2021a,
abstract = {Obstacle detection plays an important role in train automatic operation. To overcome the low accuracy and poor real-time performance of traditional detection methods, and better detect medium and long distances obstacles, the Improved-YOLOv4 network based on deep learning was proposed. The D-CSPDarknet was designed as feature extraction network. A combination of path aggregation and feature pyramid networks were used in feature fusion network, and a spatial pyramid pooling network was set up at each fusion layer. A method of dividing the ROI using a mask was proposed to improve the accuracy of the model while the processing speed can reach 0.004 s. Data augmentation, transfer learning and phased training strategies were used to improve model performance. Based on the data collected in the real operating environment of the train, Improved-YOLOv4 obtained the mAP of 93% on NVIDIA Jetson AGX, which is more suitable for the obstacle detection of rail transit.},
author = {He, Deqiang and Zou, Zhiheng and Chen, Yanjun and Liu, Bin and Yao, Xiaoyang and Shan, Sheng},
doi = {10.1016/j.measurement.2021.109241},
file = {:home/matthias/Documents/thesis_papers/railway_obstacle_detection/Obstacle_Detection_of_Rail_Transit_Based_On_Deep_Learning.pdf:pdf},
issn = {02632241},
journal = {Measurement: Journal of the International Measurement Confederation},
keywords = {Deep learning,Feature reuse,Image processing,Obstacle detection,Train automatic operation},
number = {March},
pages = {109241},
publisher = {Elsevier Ltd},
title = {{Obstacle detection of rail transit based on deep learning}},
url = {https://doi.org/10.1016/j.measurement.2021.109241},
volume = {176},
year = {2021}
}
@article{Yu2018,
abstract = {Aiming at the difficulty of detection of obstacle in outdoor railway scene, a data-oriented method based on neural network to obtain image objects is proposed. First, we mark objects of images(such as people, trains, animals) acquired on the Internet. and then use the residual learning units to build Fast R-CNN framework. Then, the neural network is trained to get the target image characteristics by using stochastic gradient descent algorithm. Finally, a well-trained model is used to identify an outdoor railway image. if it includes trains and other objects, it will issue an alert. Experiments show that the correct rate of warning reached 94.85%.},
author = {Yu, Mingyang and Yang, Peng and Wei, Sen},
doi = {10.1063/1.5039091},
file = {:home/matthias/Documents/thesis_papers/railway_obstacle_detection/Railway_Obstacle_Detection_Algorith_Using_Neural_Network.pdf:pdf},
isbn = {9780735416727},
issn = {15517616},
journal = {AIP Conference Proceedings},
keywords = {Data-oriented model,Feature extraction,Neural network,Object detection,Railway obstacle detection},
number = {1},
title = {{Railway obstacle detection algorithm using neural network}},
volume = {1967},
year = {2018}
}
@article{He2021,
abstract = {With the continuous development of rail transit fully automatic operation, the urgent need to improve train operation safety makes obstacle detection become the research focus. In this work, a flexible and efficient multiscale one-stage object detector FE-YOLO was proposed for image obstacle detection. The feature extraction network is composed of attention module, downsampling module, residual block, spatial pyramid pooling (SPP) module, and so on. A repeatable bidirectional cross-scale path aggregation module was designed as the core of the feature fusion network. The dataset RT2021 of rail transit obstacles was constructed based on the real scene. The mean of average precision (mAP), detection time, iteration time, parameters, and anti-interference ability were used to compare FE-YOLO with other classic object detectors. The results showed that FE-YOLO has the best comprehensive performance. The mAP can reach 92.57%, and the single-frame detection time on the onboard embedded device is up to 0.0989 s. The ablation experiment verified the effectiveness of each module of FE-YOLO and has the best generalization performance on the PASCAL VOC dataset. Finally, a rail transit obstacle detection system was developed, and multiple sensors were used to improve the detection accuracy. Experiments showed that the detection system can work normally in different environments.},
author = {He, Deqiang and Zou, Zhiheng and Chen, Yanjun and Liu, Bin and Miao, Jian},
doi = {10.1109/TIM.2021.3116315},
file = {:home/matthias/Documents/thesis_papers/railway_obstacle_detection/Rail_Transit_Obstacle_Detection_Based_on_Improved_CNN.pdf:pdf},
issn = {15579662},
journal = {IEEE Transactions on Instrumentation and Measurement},
keywords = {Deep learning,feature reuse,image processing,obstacle detection,sensor fusion,train automatic operation},
publisher = {IEEE},
title = {{Rail Transit Obstacle Detection Based on Improved CNN}},
volume = {70},
year = {2021}
}
@article{Karaduman2018,
abstract = {Intelligent transport and transportation systems are becoming indispensable systems of today. Continuous new investments and work are being carried out to ensure safety in all transport ways and to reduce accident rates. In this study, a simulation is designed to increase the safety of railways. Most of the railway accidents are caused by the obstacles on the rails. These obstacles means, trees, rocks and consists of similar structures. In this application, the railway has been developed on the detection of any obstacles on the rails, the introduction of the emergency system, and the transmission of information to the movement center. The camera and the laser distance meter installed on the train are used to scan the image with the image processing method, and the results are verified and the obstacle is detected. Emergency braking system, warning system is inserted into the circuit to prevent the obstacle from crashing. In addition to this, the main computer status message is sent to the movement center with the help of the created network. As a result, accident rates will be reduced, and intelligent train systems will be further developed.},
author = {Karaduman, Mucahit},
file = {:home/matthias/Documents/thesis_papers/railway_obstacle_detection/Image_processing_based_obstacle_detection_with_laser_measurement_in_railways.pdf:pdf},
isbn = {9786050107371},
journal = {2017 10th International Conference on Electrical and Electronics Engineering, ELECO 2017},
keywords = {Railway,image processing,laser meter,obstacle detection,rail mask,train},
pages = {899--903},
title = {{Image processing based obstacle detection with laser measurement in railways}},
volume = {2018-Janua},
year = {2018}
}
@article{Haseeb2018,
author = {Haseeb, Muhammad Abdul and Gr{\"{a}}ser, Axel},
file = {:home/matthias/Documents/thesis_papers/railway_obstacle_detection/06-Long-range-obstacle-detection-from-a-monocular-camera.pdf:pdf},
journal = {ECCV, 2018 - ACM Computer Science in Cars Symposium (CSCS 2018)},
pages = {1--3},
title = {{Long-range obstacle detection from a monocular camera}},
year = {2018}
}
@article{He2021b,
abstract = {The obstacle detection in the dangerous area of railway track is an important research direction in the field of the driverless train. Traditional obstacle detection methods have many issues, such as complicated steps, low detection accuracy, and slow inspection speed. To overcome these defects, a detection network based on deep learning, named Mask R-CNN, was adopted, as described in this paper. The detection network uses the Mask-RCNN model with ResNet101 as its backbone feature extraction network, which has deeper network layers. Therefore, this network has high detection accuracy for small targets. Data from a subway obstacle test was used to train this network. In addition, data augmentation and transfer learning were adopted to improve the efficacy of the training. To improve the detection speed, the technical framework of the detection was also improved. The test results showed that the precision of the Mask-RCNN model with ResNet101 as its backbone feature extraction network reached 95.7% and that it required an average time of 0.18 s. The proposed model shows satisfactory performance when used for obstacle detection in the dangerous area of the railway track, compared with other networks.},
author = {He, Deqiang and Li, Kai and Chen, Yanjun and Miao, Jian and Li, Xianwang and Shan, Sheng and Ren, Ruochen},
doi = {10.1088/1361-6501/abfdde},
file = {:home/matthias/Documents/thesis_papers/railway_obstacle_detection/obstacle_detection_in_dangerous_railway_track_areas_by_CNN.pdf:pdf},
issn = {13616501},
journal = {Measurement Science and Technology},
keywords = {Mask R-CNN,deep learning,obstacle detection,rail transit,trajectory extraction},
number = {10},
title = {{Obstacle detection in dangerous railway track areas by a convolutional neural network}},
volume = {32},
year = {2021}
}
@article{Ristic-Durrant2021,
abstract = {This paper provides a review of the literature on vision-based on-board obstacle detection and distance estimation in railways. Environment perception is crucial for autonomous detection of obstacles in a vehicle's surroundings. The use of on-board sensors for road vehicles for this purpose is well established, and advances in Artificial Intelligence and sensing technologies have motivated significant research and development in obstacle detection in the automotive field. However, research and development on obstacle detection in railways has been less extensive. To the best of our knowledge, this is the first comprehensive review of on-board obstacle detection methods for railway applications. This paper reviews currently used sensors, with particular focus on vision sensors due to their dominant use in the field. It then discusses and categorizes the methods based on vision sensors into methods based on traditional Computer Vision and methods based on Artificial Intelligence.},
author = {Risti{\'{c}}-Durrant, Danijela and Franke, Marten and Michels, Kai},
doi = {10.3390/s21103452},
file = {:home/matthias/Documents/thesis_papers/railway_obstacle_detection/A_review_of_vision_based_onboard_obstacle_detection_on_railways.pdf:pdf},
issn = {14248220},
journal = {Sensors},
keywords = {AI-based vision,Autonomous obstacle detection,On-board vision sensors,Railways,Traditional computer vision},
number = {10},
pmid = {34063490},
title = {{A review of vision-based on-board obstacle detection and distance estimation in railways}},
volume = {21},
year = {2021}
}
@article{Li2021,
abstract = {Rail transit is developing towards intelligence which takes lots of computation resource to perform deep learning tasks. Among these tasks, object detection is the most widely used, like track obstacle detection, catenary wear, and defect detection and looseness detection of train wheel bolts. But the limited computation capability of the train onboard equipment prevents running deep and complex detection networks. The limited computation capability of the train onboard equipment prevents conducting complex deep learning tasks. Cloud computing is widely utilized to make up for the insufficient onboard computation capability. However, the traditional cloud computing architecture will bring in uncertain heavy traffic load and cause high transmission delay, which makes it fail to complete real-time computing intensive tasks. As an extension of cloud computing, edge computing (EC) can reduce the pressure of cloud nodes by offloading workloads to edge nodes. In this paper, we propose an edge computing-based method. The onboard equipment on a fast-moving train is responsible for acquiring real-time images and completing a small part of the inference task. Edge computing is used to help execute the object detection algorithm on the trackside and carry most of the computing power. YOLOv3 is selected as the object detection model, since it can balance between the real-time and accurate performance on object detection compared with two-stage models. To save onboard equipment computation resources and realize the edge-train cooperative interface, we propose a model segmentation method based on the existing YOLOv3 model. We implement the cooperative inference scheme in real experiments and find that the proposed EC-based object detection method can accomplish real-time object detection tasks with little onboard computation resources.},
author = {Li, Song and Zhao, Hongli and Ma, Jinmin},
doi = {10.1155/2021/7670724},
file = {:home/matthias/Documents/thesis_papers/railway_obstacle_detection/An Edge Computing-Enabled_Train _Obstacle_Detection_Method.pdf:pdf},
issn = {15308677},
journal = {Wireless Communications and Mobile Computing},
title = {{An Edge Computing-Enabled Train Obstacle Detection Method Based on YOLOv3}},
volume = {2021},
year = {2021}
}
@article{Zeiler2010,
author = {Zeiler, Matthew D. and Krishnan, Dilip and Taylor, Graham W. and Fergus, Rob},
doi = {10.1016/j.ins.2020.01.028},
file = {:home/matthias/Documents/thesis_papers/deconvolutionalnetworks.pdf:pdf},
issn = {00200255},
journal = {IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
pages = {2528--2535},
title = {{Deconvolutional Networks}},
year = {2010}
}
@article{Yao2019,
abstract = {Recognizing abnormal events such as traffic violations and accidents in natural driving scenes is essential for successful autonomous driving and advanced driver assistance systems. However, most work on video anomaly detection suffers from two crucial drawbacks. First, they assume cameras are fixed and videos have static backgrounds, which is reasonable for surveillance applications but not for vehicle-mounted cameras. Second, they pose the problem as one-class classification, relying on arduously hand-labeled training datasets that limit recognition to anomaly categories that have been explicitly trained. This paper proposes an unsupervised approach for traffic accident detection in first-person (dashboard-mounted camera) videos. Our major novelty is to detect anomalies by predicting the future locations of traffic participants and then monitoring the prediction accuracy and consistency metrics with three different strategies. We evaluate our approach using a new dataset of diverse traffic accidents, AnAn Accident Detection (A3D), as well as another publicly-available dataset. Experimental results show that our approach outperforms the state-of-the-art. Code and the dataset developed in this work are available at: https:llgithub.comlMoonBtvdltad-IROS2019},
archivePrefix = {arXiv},
arxivId = {1903.00618},
author = {Yao, Yu and Xu, Mingze and Wang, Yuchen and Crandall, David J. and Atkins, Ella M.},
doi = {10.1109/IROS40897.2019.8967556},
eprint = {1903.00618},
file = {:home/matthias/Documents/thesis_papers/railway_obstacle_detection/Unsupervised_traffic_accident_detection_in_first_person_videos.pdf:pdf},
isbn = {9781728140049},
issn = {21530866},
journal = {IEEE International Conference on Intelligent Robots and Systems},
pages = {273--280},
title = {{Unsupervised Traffic Accident Detection in First-Person Videos}},
year = {2019}
}
@article{Boussik2021,
abstract = {Autonomous Driving (AD) systems are heavily reliant on supervised models. In these approaches, a model is trained to detect only a predefined number of obstacles. However, for applications like railway obstacle detection, the training dataset is limited and not all possible obstacle classes are known beforehand. For such safety-critical applications, this situation is problematic and could limit the performance of obstacle detection in autonomous trains. In this paper, we propose an exploratory study using unsupervised models based on a large set of generated convolutional autoencoder models to detect obstacles on railway's track level. The study was conducted based on three components: loss functions, activations and optimizers. Existing works rely on fixing thresholds to judge the performance of the model. We propose instead a methodology based on Multi-Criteria Decision Making (MCDM) to evaluate the performance of all models. Furthermore, we introduce the notion of gap-score to evaluate each model by calculating the average difference between the reconstruction score on images with and without obstacles. The aim is to find models maximizing the average of gap-scores and rank them according to their performances. Experimental results show that the evaluated models can provide up to 68 % average gap-score.},
author = {Boussik, Amine and Ben-Messaoud, Wael and Niar, Smail and Taleb-Ahmed, Abdelmalik},
doi = {10.1109/IV48863.2021.9575825},
file = {:home/matthias/Documents/thesis_papers/railway_obstacle_detection/Railway_Obstacle_Detection_Using_Unsupervised_Learning_An_Exploratory_Study.pdf:pdf},
isbn = {9781728153940},
journal = {IEEE Intelligent Vehicles Symposium},
pages = {660--667},
publisher = {IEEE},
title = {{Railway obstacle detection using unsupervised learning: An exploratory study}},
year = {2021}
}
@article{Bergmann2020,
abstract = {We introduce a powerful student-Teacher framework for the challenging problem of unsupervised anomaly detection and pixel-precise anomaly segmentation in high-resolution images. Student networks are trained to regress the output of a descriptive teacher network that was pretrained on a large dataset of patches from natural images. This circumvents the need for prior data annotation. Anomalies are detected when the outputs of the student networks differ from that of the teacher network. This happens when they fail to generalize outside the manifold of anomaly-free training data. The intrinsic uncertainty in the student networks is used as an additional scoring function that indicates anomalies. We compare our method to a large number of existing deep learning based methods for unsupervised anomaly detection. Our experiments demonstrate improvements over state-of-The-Art methods on a number of real-world datasets, including the recently introduced MVTec Anomaly Detection dataset that was specifically designed to benchmark anomaly segmentation algorithms.},
archivePrefix = {arXiv},
arxivId = {1911.02357},
author = {Bergmann, Paul and Fauser, Michael and Sattlegger, David and Steger, Carsten},
doi = {10.1109/CVPR42600.2020.00424},
eprint = {1911.02357},
file = {:home/matthias/Documents/thesis_papers/unsupervised_anomaly_detection/student_teacher_anomaly_detection.pdf:pdf},
issn = {10636919},
journal = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
pages = {4183--4192},
title = {{Uninformed Students: Student-Teacher Anomaly Detection with Discriminative Latent Embeddings}},
year = {2020}
}
@article{Everingham2015,
abstract = {The Pascal Visual Object Classes (VOC) challenge consists of two components: (i) a publicly available dataset of images together with ground truth annotation and standardised evaluation software; and (ii) an annual competition and workshop. There are five challenges: classification, detection, segmentation, action classification, and person layout. In this paper we provide a review of the challenge from 2008–2012. The paper is intended for two audiences: algorithm designers, researchers who want to see what the state of the art is, as measured by performance on the VOC datasets, along with the limitations and weak points of the current generation of algorithms; and, challenge designers, who want to see what we as organisers have learnt from the process and our recommendations for the organisation of future challenges. To analyse the performance of submitted algorithms on the VOC datasets we introduce a number of novel evaluation methods: a bootstrapping method for determining whether differences in the performance of two algorithms are significant or not; a normalised average precision so that performance can be compared across classes with different proportions of positive instances; a clustering method for visualising the performance across multiple algorithms so that the hard and easy images can be identified; and the use of a joint classifier over the submitted algorithms in order to measure their complementarity and combined performance. We also analyse the community's progress through time using the methods of Hoiem et al. (Proceedings of European Conference on Computer Vision, 2012) to identify the types of occurring errors. We conclude the paper with an appraisal of the aspects of the challenge that worked well, and those that could be improved in future challenges.},
author = {Everingham, Mark and Eslami, S. M.Ali and {Van Gool}, Luc and Williams, Christopher K.I. and Winn, John and Zisserman, Andrew},
doi = {10.1007/s11263-014-0733-5},
file = {:home/matthias/Documents/thesis_papers/related_work/Everingham2015_Article_ThePascalVisualObjectClassesCh.pdf:pdf},
issn = {15731405},
journal = {International Journal of Computer Vision},
keywords = {Benchmark,Database,Object detection,Object recognition,Segmentation},
number = {1},
pages = {98--136},
title = {{The Pascal Visual Object Classes Challenge: A Retrospective}},
volume = {111},
year = {2015}
}
@book{Bharadwaj2021,
abstract = {.},
author = {Bishop, Christopher M. and Nasrabadi, N. M.},
booktitle = {EAI/Springer Innovations in Communication and Computing},
doi = {10.1007/978-3-030-57077-4_11},
file = {:home/matthias/Documents/thesis_papers/related_work/Bishop - Pattern Recognition And Machine Learning - Springer 2006.pdf:pdf;:home/matthias/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bharadwaj, Prakash, Kanagachidambaresan - 2021 - Pattern Recognition and Machine Learning.pdf:pdf},
isbn = {9780387310732},
issn = {25228609},
keywords = {Classifier,Multi-classification problems,SVM},
pages = {105--144},
title = {{Pattern Recognition and Machine Learning}},
publisher = {New York: Springer},
year = {2006}
}
@article{Blum2021a,
abstract = {Deep learning has enabled impressive progress in the accuracy of semantic segmentation. Yet, the ability to estimate uncertainty and detect failure is key for safety-critical applications like autonomous driving. Existing uncertainty estimates have mostly been evaluated on simple tasks, and it is unclear whether these methods generalize to more complex scenarios. We present Fishyscapes, the first public benchmark for anomaly detection in a real-world task of semantic segmentation for urban driving. It evaluates pixel-wise uncertainty estimates towards the detection of anomalous objects. We adapt state-of-the-art methods to recent semantic segmentation models and compare uncertainty estimation approaches based on softmax confidence, Bayesian learning, density estimation, image resynthesis, as well as supervised anomaly detection methods. Our results show that anomaly detection is far from solved even for ordinary situations, while our benchmark allows measuring advancements beyond the state-of-the-art. Results, data and submission information can be found at https://fishyscapes.com/.},
archivePrefix = {arXiv},
arxivId = {1904.03215},
author = {Blum, Hermann and Sarlin, Paul Edouard and Nieto, Juan and Siegwart, Roland and Cadena, Cesar},
doi = {10.1007/s11263-021-01511-6},
eprint = {1904.03215},
file = {:home/matthias/Documents/thesis_papers/fishyscapes.pdf:pdf},
issn = {15731405},
journal = {International Journal of Computer Vision},
keywords = {Anomaly detection,Autonomous driving,Out-of-distribution detection,Semantic segmentation,Uncertainty estimation},
number = {11},
pages = {3119--3135},
title = {{The Fishyscapes Benchmark: Measuring Blind Spots in Semantic Segmentation}},
volume = {129},
year = {2021}
}
@article{Deng2009,
abstract = {The explosion of image data on the Internet has the potential to foster more sophisticated and robust models and algorithms to index, retrieve, organize and interact with images and multimedia data. But exactly how such data can be harnessed and organized remains a critical problem. We introduce here a new database called &#x201C;ImageNet&#x201D;, a large-scale ontology of images built upon the backbone of the WordNet structure. ImageNet aims to populate the majority of the 80,000 synsets of WordNet with an average of 500-1000 clean and full resolution images. This will result in tens of millions of annotated images organized by the semantic hierarchy of WordNet. This paper offers a detailed analysis of ImageNet in its current state: 12 subtrees with 5247 synsets and 3.2 million images in total. We show that ImageNet is much larger in scale and diversity and much more accurate than the current image datasets. Constructing such a large-scale database is a challenging task. We describe the data collection scheme with Amazon Mechanical Turk. Lastly, we illustrate the usefulness of ImageNet through three simple applications in object recognition, image classification and automatic object clustering. We hope that the scale, accuracy, diversity and hierarchical structure of ImageNet can offer unparalleled opportunities to researchers in the computer vision community and beyond.},
author = {Deng, Jia and Dong, Wei and Socher, R. and Li, Li-Jia and Li, Kai and Fei-Fei, Li},
doi = {10.1109/cvprw.2009.5206848},
file = {:home/matthias/Documents/thesis_papers/related_work/ImageNet_A_large-scale_hierarchical_image_database.pdf:pdf},
isbn = {9781424439911},
pages = {248--255},
publisher = {IEEE},
title = {{ImageNet: A large-scale hierarchical image database}},
year = {2009},
journal = {2009 IEEE Conference on Computer Vision and Pattern Recognition}
}
@article{Zendel2019,
abstract = {Solving tasks for autonomous road vehicles using computer vision is a dynamic and active research field. However, one aspect of autonomous transportation has received little contributions: the rail domain. In this paper, we introduce the first public dataset for semantic scene understanding for trains and trams: RailSem19. This dataset consists of 8500 annotated short sequences from the ego-perspective of trains, including over 1000 examples with railway crossings and 1200 tram scenes. Since it is the first image dataset targeting the rail domain, a novel label policy has been designed from scratch. It focuses on rail-specific labels not covered by any other datasets. In addition to manual annotations in the form of geometric shapes, we also supply dense pixel-wise semantic labeling. The dense labeling is a semantic-aware combination of (a) the geometric shapes and (b) weakly supervised annotations generated by existing semantic segmentation networks from the road domain. Finally, multiple experiments give a first impression on how the new dataset can be used to improve semantic scene understanding in the rail environment. We present prototypes for the image-based classification of trains, switches, switch states, platforms, buffer stops, rail traffic signs and rail traffic lights. Applying transfer learning, we present an early prototype for pixel-wise semantic segmentation on rail scenes. The resulting predictions show that this new data also significantly improves scene understanding in situations where cars and trains interact.},
author = {Zendel, Oliver and Murschitz, Markus and Zeilinger, Marcel and Steininger, Daniel and Abbasi, Sara and Beleznai, Csaba},
doi = {10.1109/CVPRW.2019.00161},
file = {:home/matthias/Documents/thesis_papers/related_work/RailSem19_A_Dataset_for_Semantic_Rail_Scene_Understanding.pdf:pdf},
isbn = {9781728125060},
issn = {21607516},
journal = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops},
pages = {1221--1229},
title = {{RailSem19: A dataset for semantic rail scene understanding}},
year = {2019}
}
@article{Isola2017,
abstract = {We investigate conditional adversarial networks as a general-purpose solution to image-to-image translation problems. These networks not only learn the mapping from input image to output image, but also learn a loss function to train this mapping. This makes it possible to apply the same generic approach to problems that traditionally would require very different loss formulations. We demonstrate that this approach is effective at synthesizing photos from label maps, reconstructing objects from edge maps, and colorizing images, among other tasks. Moreover, since the release of the pix2pix software associated with this paper, hundreds of twitter users have posted their own artistic experiments using our system. As a community, we no longer hand-engineer our mapping functions, and this work suggests we can achieve reasonable results without hand-engineering our loss functions either.},
archivePrefix = {arXiv},
arxivId = {1611.07004},
author = {Isola, Phillip and Zhu, Jun Yan and Zhou, Tinghui and Efros, Alexei A.},
doi = {10.1109/CVPR.2017.632},
eprint = {1611.07004},
file = {:home/matthias/Documents/thesis_papers/gan/1611.07004.pdf:pdf},
isbn = {9781538604571},
journal = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
pages = {1125--1134},
title = {{Image-to-image translation with conditional adversarial networks}},
year = {2017}
}
@article{Goodfellow2014,
archivePrefix = {arXiv},
arxivId = {1908.08930},
author = {Goodfellow, Ian J and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
doi = {10.1109/ICCVW.2019.00369},
eprint = {1908.08930},
file = {:home/matthias/Documents/thesis_papers/related_work/NIPS-2014-generative-adversarial-nets-Paper.pdf:pdf},
isbn = {9781728150239},
journal = {Advances in Neural Information Processing Systems},
title = {{Generative Adversarial Nets}},
volume = {27},
year = {2014}
}
@article{Wang2018b,
abstract = {We present a new method for synthesizing high-resolution photo-realistic images from semantic label maps using conditional generative adversarial networks (conditional GANs). Conditional GANs have enabled a variety of applications, but the results are often limited to low-resolution and still far from realistic. In this work, we generate 2048 {\~{A}} - 1024 visually appealing results with a novel adversarial loss, as well as new multi-scale generator and discriminator architectures. Furthermore, we extend our framework to interactive visual manipulation with two additional features. First, we incorporate object instance segmentation information, which enables object manipulations such as removing/adding objects and changing the object category. Second, we propose a method to generate diverse results given the same input, allowing users to edit the object appearance interactively. Human opinion studies demonstrate that our method significantly outperforms existing methods, advancing both the quality and the resolution of deep image synthesis and editing.},
archivePrefix = {arXiv},
arxivId = {1711.11585},
author = {Wang, Ting Chun and Liu, Ming Yu and Zhu, Jun Yan and Tao, Andrew and Kautz, Jan and Catanzaro, Bryan},
doi = {10.1109/CVPR.2018.00917},
eprint = {1711.11585},
file = {:home/matthias/Documents/thesis_papers/gan/1711.11585.pdf:pdf},
isbn = {9781538664209},
issn = {10636919},
journal = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
pages = {8798--8807},
title = {{High-Resolution Image Synthesis and Semantic Manipulation with Conditional GANs}},
year = {2018}
}
@article{Wang2004,
abstract = {Objective methods for assessing perceptual image quality traditionally attempted to quantify the visibility of errors (differences) between a distorted image and a reference image using a variety of known properties of the human visual system. Under the assumption that human visual perception is highly adapted for extracting structural information from a scene, we introduce an alternative complementary framework for quality assessment based on the degradation of structural information. As a specific example of this concept, we develop a Structural Similarity Index and demonstrate its promise through a set of intuitive examples, as well as comparison to both subjective ratings and state-of-the-art objective methods on a database of images compressed with JPEG and JPEG2000.},
author = {Wang, Zhou and Bovik, Alan Conrad and Sheikh, Hamid Rahim and Simoncelli, Eero P.},
doi = {10.1109/TIP.2003.819861},
file = {:home/matthias/Documents/Semesterproject/wang03-preprint.pdf:pdf},
issn = {10577149},
journal = {IEEE Transactions on Image Processing},
keywords = {Error sensitivity,Human visual system (HVS),Image coding,Image quality assessment,JPEG,JPEG2000,Perceptual quality,Structural information,Structural similarity (SSIM)},
number = {4},
pages = {600--612},
pmid = {15376593},
title = {{Image quality assessment: From error visibility to structural similarity}},
volume = {13},
year = {2004}
}
@article{Bergmann2019,
abstract = {Convolutional autoencoders have emerged as popular methods for unsupervised defect segmentation on image data. Most commonly, this task is performed by thresholding a per-pixel reconstruction error based on an `p-distance. This procedure, however, leads to large residuals whenever the reconstruction includes slight localization inaccuracies around edges. It also fails to reveal defective regions that have been visually altered when intensity values stay roughly consistent. We show that these problems prevent these approaches from being applied to complex real-world scenarios and that they cannot be easily avoided by employing more elaborate architectures such as variational or feature matching autoencoders. We propose to use a perceptual loss function based on structural similarity that examines inter-dependencies between local image regions, taking into account luminance, contrast, and structural information, instead of simply comparing single pixel values. It achieves significant performance gains on a challenging real-world dataset of nanofibrous materials and a novel dataset of two woven fabrics over state-of-the-art approaches for unsupervised defect segmentation that use per-pixel reconstruction error metrics.},
archivePrefix = {arXiv},
arxivId = {1807.02011},
author = {Bergmann, Paul and L{\"{o}}we, Sindy and Fauser, Michael and Sattlegger, David and Steger, Carsten},
doi = {10.5220/0007364503720380},
eprint = {1807.02011},
file = {:home/matthias/Documents/thesis_papers/unsupervised_anomaly_detection/ImprovingUnsupervisedDefectSegmentationbyApplyingStructuralSimilarityToAutoencoders.pdf:pdf},
isbn = {9789897583544},
journal = {Proceedings of the International Joint Conference on Computer Vision, Imaging and Computer Graphics Theory and Applications},
keywords = {Anomaly Detection,Defect Segmentation,Unsupervised Learning},
pages = {372--380},
title = {{Improving unsupervised defect segmentation by applying structural similarity to autoencoders}},
volume = {5},
year = {2019}
}
@article{Avi-Aharon2020,
abstract = {We present the DeepHist - a novel Deep Learning framework for augmenting a network by histogram layers and demonstrate its strength by addressing image-to-image translation problems. Specifically, given an input image and a reference color distribution we aim to generate an output image with the structural appearance (content) of the input (source) yet with the colors of the reference. The key idea is a new technique for a differentiable construction of joint and color histograms of the output images. We further define a color distribution loss based on the Earth Mover's Distance between the output's and the reference's color histograms and a Mutual Information loss based on the joint histograms of the source and the output images. Promising results are shown for the tasks of color transfer, image colorization and edges $\rightarrow$ photo, where the color distribution of the output image is controlled. Comparison to Pix2Pix and CyclyGANs are shown.},
archivePrefix = {arXiv},
journal = {arXiv 2005.03995},
author = {Avi-Aharon, Mor and Arbelle, Assaf and Raviv, Tammy Riklin},
eprint = {2005.03995},
file = {:home/matthias/Documents/thesis_papers/unsupervised_anomaly_detection/Deephist.pdf:pdf},
keywords = {earth movers dis-,histogram layers,image-to-image translation,mutual information,tance},
title = {{DeepHist: Differentiable Joint and Color Histogram Layers for Image-to-Image Translation}},
year = {2020}
}

@article{Ruder2003,
abstract = {Safety is an important topic for any railway system. If trains are running on a track, which is not guarded of objects by fences or other means, special care for obstacles in front of the train needs to be taken. On a normal train, this is the task of the train driver. When implementing automated trains, a substitute is needed to ensure the same safety level as in normal operations. Therefore, an obstacle detection system is required for safe operations. During the KOMPAS project we developed a system capable of monitoring the track and detecting objects in front of an automated train.},
author = {R{\"{u}}der, Milan and M{\"{o}}hler, Nikolaus and Ahmed, Faruque},
doi = {10.1109/IVS.2003.1212905},
file = {:home/matthias/Documents/thesis_papers/railway_obstacle_detection/An_obstacle_detection_system_for_automated_trains.pdf:pdf},
isbn = {0780378482},
journal = {IEEE Intelligent Vehicles Symposium, Proceedings},
pages = {180--185},
title = {{An obstacle detection system for automated trains}},
year = {2003}
}
@article{Rodriguez2012,
abstract = {Autonomous systems can assist humans in the important task of safe driving. Such systems can warn people about possible risks, take actions to avoid accidents or guide the vehicle without human supervision. Whether in cars or trains or ships the artificial vision algorithms offer an alternative for the design and implementation of autonomous driving systems. In railway scenarios cameras in front of the train can assist drivers with the identification of obstacles or strange objects on the rails. Multiple factors add huge complexity to this task. The changing conditions create a scene where background is hard to detect, lighting varies and process speed must be fast. This article describes a first approximation to the problem where using the Hough transform, the rails and area of interest are detected. On this area a systematic search is done for finding and delimiting possible obstacles. Our system accomplished a real time performance when employed in the analysis of recorded videos from the driver perspective. Using digital added obstacles our algorithm detects mostly all of them and warns if the objects over the rail can create a danger to the safety travel of the train. {\textcopyright} 2012 IEEE.},
author = {Rodriguez, L. A.Fonseca and Uribe, J. A. and Bonilla, J. F.Vargas},
doi = {10.1109/STSIVA.2012.6340602},
file = {:home/matthias/Documents/thesis_papers/railway_obstacle_detection/Obstacle_Detection_Over_Rails_Using_Hough_Transform.pdf:pdf},
isbn = {9781467327619},
journal = {17th Symposium of Image, Signal Processing, and Artificial Vision (STSIVA)},
keywords = {Hough transform,Obstacle detection,autonomous train driving,digital image processing},
pages = {317--322},
publisher = {IEEE},
title = {{Obstacle detection over rails using hough transform}},
year = {2012}
}
@article{Tax2004,
author = {Tax, David MJ and Duin, Robert PW},
doi = {10.1023/B},
file = {:home/matthias/Documents/thesis_papers/related_work/Support_Vector_Data_Description.pdf:pdf},
journal = {Machine Learning},
pages = {45--66},
title = {{Support Vector Data Description}},
volume = {54},
year = {2004}
}
@article{Bergmann,
author = {Bergmann, Paul},
file = {:home/matthias/Documents/thesis_papers/unsupervised_anomaly_detection/Bergmann_MVTec_AD_--_A_Comprehensive_Real-World_Dataset_for_Unsupervised_Anomaly_CVPR_2019_paper.pdf:pdf},
pages = {9592--9600},
title = {{MVTec AD — A Comprehensive Real-World Dataset for Unsupervised Anomaly Detection}},
year = {2019},
journal = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}
}
@article{Gong2019a,
abstract = {Deep autoencoder has been extensively used for anomaly detection. Training on the normal data, the autoencoder is expected to produce higher reconstruction error for the abnormal inputs than the normal ones, which is adopted as a criterion for identifying anomalies. However, this assumption does not always hold in practice. It has been observed that sometimes the autoencoder 'generalizes' so well that it can also reconstruct anomalies well, leading to the miss detection of anomalies. To mitigate this drawback for autoencoder based anomaly detector, we propose to augment the autoencoder with a memory module and develop an improved autoencoder called memory-augmented autoencoder, i.e. MemAE. Given an input, MemAE firstly obtains the encoding from the encoder and then uses it as a query to retrieve the most relevant memory items for reconstruction. At the training stage, the memory contents are updated and are encouraged to represent the prototypical elements of the normal data. At the test stage, the learned memory will be fixed, and the reconstruction is obtained from a few selected memory records of the normal data. The reconstruction will thus tend to be close to a normal sample. Thus the reconstructed errors on anomalies will be strengthened for anomaly detection. MemAE is free of assumptions on the data type and thus general to be applied to different tasks. Experiments on various datasets prove the excellent generalization and high effectiveness of the proposed MemAE.},
archivePrefix = {arXiv},
arxivId = {1904.02639},
author = {Gong, Dong and Liu, Lingqiao and Le, Vuong and Saha, Budhaditya and Mansour, Moussa Reda and Venkatesh, Svetha and {Van Den Hengel}, Anton},
doi = {10.1109/ICCV.2019.00179},
eprint = {1904.02639},
file = {:home/matthias/Documents/thesis_papers/related_work/1904.02639.pdf:pdf},
isbn = {9781728148038},
issn = {15505499},
journal = {Proceedings of the IEEE International Conference on Computer Vision},
pages = {1705--1714},
title = {{Memorizing normality to detect anomaly: Memory-augmented deep autoencoder for unsupervised anomaly detection}},
year = {2019}
}

