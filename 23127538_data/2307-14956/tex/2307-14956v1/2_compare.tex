\section{Comparison of GRU4Rec implementations}\label{sec:compare}
In this section we compare the official GRU4Rec to six third-party reimplementations and answer RQ1, RQ2 and RQ3.

\subsection{Brief description of GRU4Rec}
GRU4Rec~\cite{hidasi2015session,hidasi2018recurrent} is a deep learning model originally proposed for session-based recommendations, and later utilized for other sequential recommendation tasks. The algorithm utilizes the Gated Recurrent Unit (GRU), a type of recurrent neural network. The model was released in 2015~\cite{hidasi2015session} and was improved upon in 2017~\cite{hidasi2018recurrent}. It revitalized the field of session-based~/~sequential recommendations and is considered to be one of the seminal works of the field.

The architecture of GRU4Rec is fairly simple. It receives an item of a session on its input and ranks every item based on how likely they are to be the next one. The inputted item is first embedded, then processed by one or more GRU layers. GRU layer(s) hold information on the state of the session, thus the model's inference is based on the whole sequence of events it observed so far in the session. Items are scored as the dot products between their embeddings and the hidden state. GRU4Rec has distinctive features adapting it to the specialties of recommender systems that distinguish it from simply processing behavior data with GRU. The official implementation contains all of the features including losses, embedding methods, negative sampling, etc., and it has many hyperparameters. The main features of GRU4Rec and the corresponding hyperparameters are listed below:
\begin{itemize}
    \item \textbf{Session-parallel mini-batches:} Since the length of sessions have a high variance and most of the sessions are short,~\cite{hidasi2015session} argues that (a) backpropagation through time (BPTT) is not necessary\footnote{It is hinted that a proprietary BPTT version exists for sequential tasks with longer sequences.}, and (b) events should be processed in a session-parallel way. A mini-batch is composed of input--target pairs from different sessions, each covering a single time step of its session. The next mini-batch is composed by shifting the input and the target to the next items respectively. When a session is fully  consumed, the next available training session fills its place, with its first and second items serving as the input and the target. The corresponding hidden state is also reset to zero. The size of the mini-batch is governed by the \texttt{batch\_size} parameter.
    \item \textbf{Negative sampling:} Scoring every item in every training step scales poorly, thus GRU4Rec utilizes two forms of negative item sampling.
    \begin{itemize}
        \item \textbf{Mini-batch based sampling:} Each example within a mini-batch uses the target items of the other examples as negative samples. This is a form of popularity based sampling that is very efficient to run on GPUs.
        \item \textbf{Extra shared sampling:} A number of \texttt{n\_sample} items are sampled for each mini-batch with sampling probabilities proportional to the items' relative frequency on the power of \texttt{sample\_alpha}. These negative samples are shared between the examples of a mini-batch.
    \end{itemize}
    \item \textbf{Losses:} Among the four available options (selected by \texttt{loss}), \cite{hidasi2018recurrent} deems two to be superior to the others.
    \begin{itemize}
        \item \textbf{Cross-entropy over softmax:} Item scores are passed through a softmax transformation\footnote{The final activation can be set to other than softmax, but it is not advised.}, before categorical cross-entropy loss is applied on them. LogQ correction~\cite{yi2019sampling} is available to offset the sampling bias affecting this loss specifically. Its strength is controlled by the \texttt{logq} parameter.
        \item \textbf{BPR-max:} Generalization of the BPR~\cite{rendle2012bpr} loss for multiple negative examples that fixes the vanishing gradient problem of using mean BPR. It also contains score regularization governed by \texttt{bpreg}. The final activation layer can be selected among linear, ReLU, ELU and sELU using the \texttt{final\_act} parameter.
    \end{itemize}
    \item \textbf{Embedding:} Items are embedded twice: for scoring, and as the input. There is one option for the former and three for the latter, which is governed by the \texttt{constrained\_embedding} and \texttt{embedding} parameters.
    \begin{itemize}
        \item \textbf{No embedding:} The input item is represented as a one-hot vector that is fed directly into the first GRU layer. For efficiency's sake, indexing is used instead of dense one-hot vectors and matrix multiplication.
        \item \textbf{Separate embedding:} A separate embedding is used for inputting and scoring the items.
        \item \textbf{Shared / constrained embedding:} The embedding on the input and the one used for scoring is the same.
    \end{itemize}
    \item \textbf{Training:} Multiple optimizers (AdaGrad, RMSprop, Adam, AdaDelta) are available for training (selected by \texttt{adapt}). The implementation defaults to Adagrad with Nesterov's momentum (\texttt{momentum} parameter). Learning rate is fixed during training and can be set by \texttt{learning\_rate}. The model is trained for \texttt{n\_epochs} number of epochs.
    \item \textbf{Regularization:} The algorithm uses dropout as the primary way of regularization, even though $\ell_2$ regularization is also available. The \texttt{dropout\_p\_hidden} parameter sets the drop probability for the GRU layers, and \texttt{dropout\_p\_embed} does the same on the input embedding. The latter has no effect in no embedding mode.
\end{itemize}
\subsection{Third-party reimplementations}
The selected set of third-party versions consists of the two Tensorflow and two PyTorch reimplementations, as well as two variants included in frameworks~/~algorithm collections.

\textbf{GRU4REC-pytorch}\footnote{\url{https://github.com/hungthanhpham94/GRU4REC-pytorch}, comparison is based on commit \texttt{666b84}} is a reimplementation in PyTorch. With 217 stars and 55 forks it is fairly popular. The first version was published in October 2018, and the last commit is from March 2021.

\textbf{Torch-GRU4Rec}\footnote{\url{https://github.com/yeganegi-reza/Torch-GRU4Rec}, comparison is based on commit \texttt{744f6b}} is another, less popular PyTorch reimplementation published in 2020.

\textbf{GRU4Rec\_Tensorflow}\footnote{\url{https://github.com/Songweiping/GRU4Rec_TensorFlow}, comparison is based on commit \texttt{d53fd9e}} is a relatively popular (213 stars, 89 forks) reimplementation in Tensorflow. Its updates were committed between March 2017 and June 2019.

\textbf{KerasGRU4Rec}\footnote{\url{https://github.com/paxcema/KerasGRU4Rec}, comparison is based on commit \texttt{239522}} is a Keras~/~Tensorflow reimplementation. The repository was forked from the official implementation in June 2018, but most of the code was rewritten before the Keras version was released in December 2018. The repository is still updated periodically by a bot, but the last meaningful update was committed in October 2020.

\textbf{Microsoft Recommenders}\footnote{\url{https://github.com/microsoft/recommenders}}~\cite{argyriou2020microsoft} is a popular collection of reimplementations of recommender algorithms, listed on the ACM RecSys github as one of the useful evaluation frameworks. According to its description, it contains examples and best practices for building recommender systems. It is often used for comparing algorithms. Its GRU4Rec version is reimplemented in Keras, and was last updated in October 2021. 

\textbf{Recpack}\footnote{\url{https://gitlab.com/recpack-maintainers/recpack}, comparison is based on commit \texttt{a83beb}}~\cite{10.1145/3523227.3551472} is an experimentation toolkit for top-N recommenders, listed on the ACM RecSys github as one of the useful evaluation frameworks. Its GRU4Rec is reimplemented in PyTorch.

\subsection{Comparison}

Five of the six third-party versions implement the same \emph{architecture} (RQ1) as the original. However, ``GRU4Rec'' of the Microsoft Recommenders collection only has two things in common with original: its name and that it uses GRU layers. The list of differences starts with the embedding layer, where this reimplementation utilizes extra information (item categories) besides the item ID. While changing the representation of the events within the session does not result in a new algorithm, it already undermines the goal of reproducing the original work. The list continues with the training of the GRU layer, where this algorithm requires sequences of equal length and processes multiple time steps in one forward pass, ignoring one of the distinctive features of the original. Scoring is also different and deeply flawed as well. In the reimplementation, a feedforward net scores hidden state--item pairs. This scoring function -- unlike that of the original -- can not be factorized into a sequence and an item dependent parts, thus the hidden state needs to be cloned as many times as the number of items to be ranked. This does not scale well beyond a few tens or maybe hundreds of items. Therefore, the number of negative item samples is severely limited, but more importantly, this algorithm can not rank items of even a small item catalog in a reasonable timeframe during inference. It seems that the authors are aware of these shortcomings, since the example showcasing this algorithm ranks only 50 items during evaluation, because full ranking would be impossible due to memory and time constraints. It is unclear why this completely different (and conceptually flawed) algorithm is called GRU4Rec in the Microsoft Recommenders framework that is supposed to be a curated collection of algorithms. Nevertheless, this reimplementation is excluded from further examination as it critically failed the first and most basic comparison.

Table~\ref{tab:features} showcases which reimplementation supports which \emph{features} of the original (RQ2). Surprisingly, no reimplementation supports shared embeddings, even though its usefulness on some datasets was highlighted in~\cite{hidasi2018recurrent}.

\begin{table*}
    \caption{Availability of GRU4Rec's main features in third-party versions: available (\cmark), missing (\xmark), or partially present~/~flawed (*).}
    \label{tab:features}
    \small
    \begin{tabular}{ll|ccccc}
      \toprule
      \multicolumn{2}{l|}{GRU4Rec feature} & GRU4REC-pytorch & Torch-GRU4Rec & GRU4Rec\_Tensorflow & KerasGRU4Rec & Recpack\\
      \midrule
      \multicolumn{2}{l|}{Session parallel mini-batches} & \cmark & \cmark & \cmark & \cmark & * \\
      \midrule
      \multirow{2}{*}{\shortstack[l]{Negative \\sampling}} & Mini-batch & \cmark & \cmark & \cmark & \xmark & * \\
      & Shared extra & \xmark & \cmark & \xmark & \xmark & * \\
      \midrule
      \multirow{2}{*}{Loss} & Cross-entropy & * & \cmark & \cmark & \cmark & \cmark \\
      & BPR-max & * & \cmark & \xmark & \xmark & \cmark \\
      \midrule
      \multirow{3}{*}{Embedding} & No embedding & \cmark & \cmark & \xmark & \cmark & \xmark \\
      & Separate & \cmark & \cmark & \cmark & \xmark & \cmark \\
      & Shared & \xmark & \xmark & \xmark & \xmark & \xmark \\
      \bottomrule
    \end{tabular}
    \end{table*}

Torch-GRU4Rec is the closest to the original as it supports all but the shared embedding feature. The other PyTorch implementation (GRU4REC-pytorch) has a limited feature set that is close to the base model from 2015, even though it is based on the improved model from 2017. The same is true for GRU4Rec\_Tensorflow, but with even more features missing. KerasGRU4Rec is the most basic one of the reimplementations, and it doesn't use negative item sampling. Instead, it computes the score for every item in every training step that makes it scale poorly. Recpack has two substantially different GRU4Rec implementations: the one with cross-entropy loss doesn't use negative sampling, the one with BPR-max does. Unfortunately, the implementation of the sampling is inefficient and also causes scalability problems (see Subsection~\ref{ssec:scaling}). Recpack also does not replicate session-parallel mini-batches correctly, as each of its batches lasts until every session within it is consumed. This increases training time, and also affects the loss.

Besides the hyperparameters corresponding to missing features, reimplementations might lack other ones as well. E.g., momentum with Adagrad and logQ correction is not available in any of the third-party versions. The former is missing due to the built-in Adagrad optimizers of PyTorch and Tensorflow lacking that feature. In some versions, dropout -- especially embedding dropout -- is also missing (or does not work). Hyperparameters are hard-coded in certain reimplementations, with KerasGRU4Rec being the most extreme example with hard-coded layer size and dropout probability.

Torch-GRU4Rec is mostly error free, but an easily noticeable typo prevents it from running as is. Other reimplementations contain a fair amount of \emph{bugs and errors} (RQ3). Some bugs are relatively easy to notice, while others are more insidious. The effort required for fixing the bugs varies widely. The nature of these bugs can be (a) incorrect implementation, e.g.~flawed losses or incorrect resetting of the hidden states; (b) ineffective or misleading hyperparameters, e.g.~dropout probability meaning keep probability or setting the dropout not actually enabling dropout; (c) inefficiencies, e.g.~negative sampling after score computations. The bugs of each reimplementation are discussed in Section~\ref{sec:quant}.