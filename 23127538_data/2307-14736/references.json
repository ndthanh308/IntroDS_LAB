{
  "2203-17247": {
    "title": "VL-InterpreT: An Interactive Visualization Tool for Interpreting Vision-Language Transformers",
    "authors": [
      "Estelle Aflalo",
      "Meng Du",
      "Shao-Yen Tseng",
      "Yongfei Liu",
      "Chenfei Wu",
      "Nan Duan",
      "Vasudev Lal"
    ],
    "submission_date": "2022-03-30",
    "semantic_scholar_id": "abc6e5b86406e87b09a9520e1757d6db4c7fa08a"
  },
  "2103-15679": {
    "title": "Generic Attention-model Explainability for Interpreting Bi-Modal and Encoder-Decoder Transformers",
    "authors": [
      "Hila Chefer",
      "Shir Gur",
      "Lior Wolf"
    ],
    "submission_date": "2021-03-29",
    "semantic_scholar_id": "7ec5f207263100ea2d45db595712f611a74bafd9"
  },
  "2004-11207": {
    "title": "Self-Attention Attribution: Interpreting Information Interactions Inside Transformer",
    "authors": [
      "Y. Hao",
      "Li Dong",
      "Furu Wei",
      "Ke Xu"
    ],
    "submission_date": "2020-04-23",
    "semantic_scholar_id": "1686203adc5f2dbc18627ce64f66d33eb81432a5"
  },
  "1811-01199": {
    "title": "Concerning the Neural Code.",
    "authors": [
      "C. Malsburg"
    ],
    "submission_date": "2018-11-03",
    "semantic_scholar_id": "6791fb59cee6adf6cb2dad87ce999abbb3b8da65"
  },
  "1706-03762": {
    "title": "Attention is All you Need",
    "authors": [
      "Ashish Vaswani",
      "Noam M. Shazeer",
      "Niki Parmar",
      "Jakob Uszkoreit",
      "Llion Jones",
      "Aidan N. Gomez",
      "Lukasz Kaiser",
      "I. Polosukhin"
    ],
    "submission_date": "2017-06-12",
    "semantic_scholar_id": "204e3073870fae3d05bcbc2f6a8e263d9b72e776"
  }
}