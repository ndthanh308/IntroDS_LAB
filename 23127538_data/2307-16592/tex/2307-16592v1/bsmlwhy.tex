To be able to specify and write BSML programs, we need BSML primitives in WhyML. BSML primitives are implemented in parallel on top of MPI~\cite{snir98} called throught OCaml's Foreign Function Interface (FFI). Therefore, we cannot provide BSML in WhyML as an implementation. We need to give a BSML \emph{theory}: a set of constant, \emph{axioms} and function \emph{declarations}. The axiomatization of BSML primitives can be found in Figure~\ref{fig:why:primitives}. The semantics of functions \w{mkpar}, \w{apply}, \w{proj} and \w{put} are expressed in their contract (lines 12--24) while the strict positivity condition on \w{bsp_p} is given as an axiom on line 4. The type of parallel vector is abstract. Still we need to be able to observe parallel vectors. That is the role of logic function \w{get} which is a \w{ghost} function: it can only be used in specifications. A parallel vector is fully defined by the values all the processors hold as expressed by the axiom \w{extensionnality} in lines 9-10.
% Figure environment removed
The axiomatization is very close to the informal semantics of Figure~\ref{fig:bsml:primitives}. Instead of considering the parallel vectors globally with the notation $\pvec{v_0}{v_{p-1}}$, we consider each value $v_i$ denoted by \w{get v i}.

It is possible to realize this theory by a sequential implementation, for example implementing parallel vectors with sequential lists or arrays. This ensures the consistency of this theory.

To illustrate the use of this theory, we now specify, implement and verify several of the functions provided in the BSML standard library. The first one is \w{replicate}:
\lstinputlisting[style=whystyle,firstline=27, lastline=29]{code/stdlib.mlw}
This verified function has only one post-condition: the result of replication is parallel vector which contains the same value everywhere.

In Section~\ref{sec:fbsp}, we mentioned the function "parfun" without defining it. Its implementation and specification follows, as well as the definition of function \w{parfun2}:
\lstinputlisting[style=whystyle,linerange={33-36,40-43}]{code/stdlib.mlw}
It shows how to use the \w{apply} primitive. There is also a \w{parfun3} function omitted here.

Next, we use the communication primitive \w{proj}. As we wrote in Section~\ref{sec:fbsp}, \w{proj} is essentially the inverse of \w{mkpar}. If we forget the cost of communication and synchronization, this function allows us to obtain the value of a vector \w{v} at a given processor \w{i}. However, it should not be used for such individual vector access, otherwise the performances would be extremely poor. The use of \w{proj} should be thought as a collective operation. Note that \w{proj} and \w{get} have the same semantics. However, the intent is very different: \w{get} is written only in specifications, can be thought as an indexed array access, and is used for \emph{local} reasoning,  while \w{proj} is used only in programs and requires a full super-step to execute. \w{proj} should rather be thought as a \emph{global} (i.e. concerning and involving all the processors) conversion of a parallel vector into a function.

To illustrate \w{proj}, we define the \w{list_of_par}. As we mentioned before this function requires a complete super-step to run. Again it should be seen as a \emph{global} conversion from parallel vectors to lists:
\lstinputlisting[style=whystyle,linerange={53-56}]{code/stdlib.mlw}

As in the BSML/OCaml version we call \w{procs} -- which needs to be a function  for \why to accept the code. \w{procs} returns the list of all processor identifiers. The definition of \w{procs} relies on a function \w{from_to} itself implemented using a \w{init} function. Our contribution does also contain a library of sequential functions, mostly on lists, as well as verified lemmas stating their properties. These functions can in most cases be used both in programs and in specifications.

Finally, the \w{put} primitive is illustrated to implement a broadcast function. This data exchange (and implicit global synchronization) function is more precise than \w{proj}. We remind that after a \w{put}, for all processors \w{d} and \w{s}, the result function at destination processor "d", applied to the identifier of source processor "s" retuns the value of the input function at source processor "s" applied to destination processor "d".

The definition of the "bcast_direct" function of the standard library follows. This function is used to broadcast a value from a \w{root} processor to all other processors. To do so, first, we prepare a function vector for the processors to make the messages to send to each other (local definitions \w{make_msg} and \w{to_send}). It is clear that only the \w{root} processor with send data. The other processors' message is \w{None} which is interpreted by the BSML/OCaml implementation as an empty message. Second, the local definition \w{received} proceeds with the data exchange and ends the super-step. \w{received} is a parallel vector of functions. What we are interested in is the value sent by processor \w{root}. That is why the local definition \w{optional_result} then applies this parallel vector of functions to the replicated value \w{root}. Of course, the obtained message is encapsulated in a \w{Some} constructor. Therefore, all the processors finally apply \w{remove_option} to yield the final result. The broadcast is meaningless if \w{root} is not a valid processor identifier. In this case, the exception \w{Bcast} is raised:

\lstinputlisting[style=whystyle,linerange={215-228}]{code/stdlib.mlw}

Our BSML theory allows us to write BSML programs and their specifications and is expressive enough for the \why3 framework to verify that they indeed satisfy their specifications.

We only presented a sub-set of the functions of the BSML standard library we implemented, and we refer to the companion artifact for the complete set of functions. For example, we also provide the "shift", "shift_right" and "shift_left" communication functions, which offer a different communication pattern than \w{bcast_direct}: Each data item is shifted by a certain number of processors.