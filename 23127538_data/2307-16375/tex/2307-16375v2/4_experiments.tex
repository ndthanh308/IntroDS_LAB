
\section{Experiment}
We conduct experiments on four different kinds of environments. \textsc{EnvA} refers to a node~(machine) with 1 Xeon 6248 CPU, 8 V100-SXM2 32GB GPUs, and 472GB memory. \textsc{EnvB} refers to two nodes interconnected with 10Gbps networks, where each node has 2 Xeon E5-2620 v4 CPUs, 4 TITAN Xp 12GB GPUs, and 125GB memory. \textsc{EnvC} refers to a node with 8 A100 40GB PCIe GPUs. \textsc{EnvD} has four nodes, each with the same configuration as that in \textsc{EnvB}.

\begin{table}[t]
     \caption{Summary of the evaluated models. PT: Pretraining; CG: Conditional Generation; IC: Image Classification; CLM: Causal Language Modeling.}
	\label{tab:summary-models}
 \vskip 0.15in
    \begin{center}
    \begin{small}
    \begin{sc}
	\begin{tabular}{cccc}
 \toprule
		Model     & Task  & \#params & Precision \\
  \midrule
		BERT-Huge & PT            & 672M    & FP32      \\
		T5-Large  & CG & 502M    & FP32      \\
		ViT-Huge  & IC   & 632M    & FP32      \\
		Swin-Huge & IC   & 1.02B   & FP32      \\
		LLaMA-7B  & CLM               & 7B      & FP16   \\
  \bottomrule
	\end{tabular}
     \end{sc}
\end{small}
\end{center}
\vskip -0.1in
\end{table}

We evaluate UniAP with five Transformer-based models, BERT-Huge~\citep{devlin_bert_2019}, T5-Large~\citep{raffel_exploring_2020}, ViT-Huge~\citep{dosovitskiy_image_2021}, Swin-Huge~\citep{liu_swin_2021}, and LLaMA~\citep{touvron_llama_2023,touvron_llama_2023-1}. We follow the common practice of training these transformer-based models. To eliminate factors that affect training throughput, we turn off techniques orthogonal to parallel strategies, such as activation checkpointing~\citep{chen_training_2016}. However, we integrate FP16 mixed precision training~\citep{micikevicius_mixed_2018} for the largest model, LLaMA, to successfully orchestrate the process. Table~\ref{tab:summary-models} summarizes these models.

The experimental evaluation concentrates on two primary metrics: training throughput and strategy optimization time. The former is calculated by averaging throughput from the 10th to the 60th iteration of training, while the latter is determined by measuring the time of the UOP. More details are provided in Appendix \ref{appendix:experiment-settings} of the supplementary material.  

\begin{table*}[ht]
    \caption{Training throughput and strategy optimization time on five Transformer-based models. The number following the model's name represents the number of hidden layers in the corresponding model. \texttt{MEM}$\times$ indicates out-of-memory~(OOM) exceptions during strategy optimization, and \texttt{CUDA}$\times$ indicates CUDA OOM exceptions during model training. Due to the absence of an official JAX implementation for Swin-Huge and LLaMA in HuggingFace Transformers~(v4.29), experiments involving these two models for Alpa have been excluded and denoted as \texttt{N/A}. The minimum and maximum training throughput speedups are calculated by dividing the average throughput of UniAP by the maximum and minimum average throughput of Galvatron and Alpa, respectively. Similarly, the minimum and maximum strategy optimization time speedup is calculated by dividing Galvatron and Alpa's minimum and maximum average optimization time by the average optimization time of UniAP, respectively.}
    \label{tab:throughput_and_optimization_time}
    \vskip 0.15in
    \begin{center}
    \begin{small}
    \begin{sc}
    \begin{tabular}{cccccccc}
    \toprule
     \multirow{2}[0]{*}{Env.} & \multirow{2}[0]{*}{Model} & \multicolumn{3}{c}{Training Throughput (samples/s)} & \multirow{2}[0]{*}{\makecell{Minimum\\Speedup}} & \multirow{2}[0]{*}{\makecell{Maximum\\Speedup}}\\
     \cmidrule(r){3-5}
    & & Galvatron & Alpa & UniAP &  \\
    \midrule
   \multirow{4}[0]{*}{EnvA} & BERT-Huge-32 &  \textbf{33.46~$\pm$~0.28 } &  31.56~$\pm$~0.04 &  \textbf{33.46~$\pm$~0.28 } & 1.00 &  1.06 \\
    & T5-Large-48 & \textbf{23.29~$\pm$~0.04} &  \texttt{MEM}$\times$ &  \textbf{23.29~$\pm$~0.04} & 1.00 &  1.00 \\
    & ViT-Huge-32 &   \textbf{109.51~$\pm$~0.07 } &  97.66~$\pm$~1.42 &  \textbf{109.51~$\pm$~0.07 } & 1.00 &  1.12 \\
    & Swin-Huge-48 & \verb+CUDA+$\times$ & \verb+N/A+  &  \textbf{67.96~$\pm$~0.12 } & \verb+N/A+ & \verb+N/A+\\
    \midrule
    \multirow{4}[0]{*}{EnvB}
    & BERT-Huge-32 &  6.27~$\pm$~0.17 &  8.95~$\pm$~0.06 &  \textbf{10.77~$\pm$~0.13} &  1.20 &  1.71 \\
    & T5-Large-32 &  \textbf{8.06~$\pm$~0.06} & \verb+MEM+$\times$  &  7.98~$\pm$~0.05 &  0.99  &  0.99\\
    & ViT-Huge-32  &  32.20~$\pm$~0.17 &  38.74~$\pm$~0.20 &  \textbf{45.58~$\pm$~0.54} &  1.18 &  1.41 \\
    & Swin-Huge-48 &  13.90~$\pm$~0.17 & \verb+N/A+ &  \textbf{19.08~$\pm$~0.10} &  1.37 &  1.37\\
    \midrule
    EnvC & LLaMA-7B-32 & 1.22~$\pm$~0.01 & \verb+N/A+ & \textbf{1.96~$\pm$~0.03} & 1.61 & 1.61 \\
    \midrule
    \midrule
    \multirow{2}[0]{*}{Env.} & \multirow{2}[0]{*}{Model} & \multicolumn{3}{c}{Strategy Optimization Time (min.)} & \multirow{2}[0]{*}{\makecell{Minimum\\ Speedup}} & \multirow{2}[0]{*}{\makecell{Maximum\\ Speedup}}\\
     \cmidrule(r){3-5}
    & & Galvatron & Alpa & UniAP &  \\
    \midrule
    \multirow{4}[0]{*}{EnvA}
    & BERT-Huge-32 &  6.44~$\pm$~0.588 &  $>$~40 &  \textbf{0.37~$\pm$~0.002} &  17.29 &  $>$~107.41\\
    & T5-Large-48 &  12.41~$\pm$~0.122 &  \texttt{MEM}$\times$ &  \textbf{0.89~$\pm$~0.007} &  13.98 &  13.98\\
    & ViT-Huge-32 &  6.29~$\pm$~0.464 &  $>$~40 &  \textbf{0.57~$\pm$~0.009} &  10.95 &  $>$~69.60 \\
    & Swin-Huge-48 &  11.88~$\pm$~0.666 & \verb+N/A+ &  \textbf{2.16~$\pm$~0.004} &  5.49 &  5.49 \\
    \midrule
    \multirow{4}[0]{*}{EnvB}
    & BERT-Huge-32 &  2.04~$\pm$~0.010 &  $>$~40 &  \textbf{1.51~$\pm$~0.005} &  1.34 &  $>$~26.32\\
    & T5-Large-32 &  2.64~$\pm$~0.110 & \verb+MEM+$\times$ &  \textbf{0.91~$\pm$~0.005} &  2.90 &  2.90\\
    & ViT-Huge-32 &  2.37~$\pm$~0.180 &  $>$~40 &  \textbf{1.11~$\pm$~0.011} &  2.14 &  $>$~36.01\\
    & Swin-Huge-48 &  4.29~$\pm$~0.320 & \verb+N/A+ &  \textbf{2.29~$\pm$~0.010} &  1.87 &  1.87\\
    \midrule
    EnvC & LLaMA-7B-32 & 6.84~$\pm$~0.055 & \verb+N/A+ & \textbf{0.49~$\pm$~0.007} & 14.0 & 14.0 \\
    \bottomrule
    \end{tabular}
    \end{sc}
\end{small}
\end{center}
\vskip -0.1in
\end{table*}


% Figure environment removed


\subsection{Training Throughput and Strategy Optimization Time}\label{subsec:experiment:optimization-time-and-throughput}
We compare the training throughput and strategy optimization time of UniAP with those of the baselines on \textsc{EnvA}, \textsc{EnvB}, and \textsc{EnvC}.
We choose Galvatron~\citep{miao_galvatron_2022} and Alpa~\citep{zheng_alpa_2022} as baselines because they have achieved SOTA performance.
Specifically, Galvatron has surpassed other methods, including PyTorch DDP~\citep{li_pytorch_2020}, Megatron-LM~\citep{narayanan_efficient_2021}, FSDP~\citep{rajbhandari_zero_2020,fairscale_authors_fairscale_2021}, GPipe~\citep{huang_gpipe_2019}, and DeepSpeed 3D~\citep{deepspeed-3d} in terms of training throughput, as reported in the original paper~\citep{miao_galvatron_2022}.
Furthermore, Alpa utilizes the Just-In-Time~(JIT) compilation feature in JAX and outperforms Megatron-LM and DeepSpeed.

 For experiments conducted on \textsc{EnvA}, we set the mini-batch size to be 32, 16, 128, and 128 for BERT, T5, ViT, and Swin, respectively. For experiments conducted on \textsc{EnvB}, we set the mini-batch size to be 16, 8, 64, and 32 for these four models, respectively. For the LLaMA model~\citep{touvron_llama_2023,touvron_llama_2023-1} run on \textsc{EnvC}, we set the mini-batch size to be 8.
 
Table~\ref{tab:throughput_and_optimization_time} shows the training throughput and strategy optimization time on \textsc{EnvA}, \textsc{EnvB}, and \textsc{EnvC}. On \textsc{EnvA}, UniAP and Galvatron get the same optimal strategy for BERT-Huge-32, T5-Large-48, and ViT-Huge-32, outperforming Alpa in terms of training throughput and strategy optimization time. In addition, UniAP finds a solution for Swin-Huge-48, while Galvatron encounters CUDA OOM problems. In particular, UniAP achieves a maximum optimization speedup that is 17$\times$ faster than Galvatron and hundreds of times faster than Alpa on BERT-Huge-32. This is mainly due to the ability of the MIQP solver to search for an optimal strategy on multiple threads, while the dynamic programming based methods like Galvatron and Alpa run on a single thread due to their strong data dependency.

On \textsc{EnvB}, UniAP consistently demonstrates competitive or larger training throughput compared to Galvatron and Alpa. We attribute the performance improvement to the larger strategy space in UniAP. A detailed study of the importance of strategy space is provided in Section~\ref{subsec:experiment:ablation-study}. Furthermore, the strategy optimization time of UniAP is also significantly shorter than the two baseline methods.


For LLaMA, UniAP shows an optimization speedup of 14.0$\times$ and a training speedup of 1.61$\times$, compared to Galvatron, on \textsc{EnvC}.


Moreover, we find that UniAP identifies superior solutions with higher model FLOPs utilization~(MFU)~\citep{chowdhery_palm_2023}, compared to Galvatron and Alpa. For example, the resulting MFUs for UniAP, Galvatron, and Alpa are 58.44\%, 58.44\%, and 55.10\% on \textsc{EnvA}, while 23.6\%, 13.7\%, and 19.6\% on \textsc{EnvB}. These results are due to the larger strategy space of UniAP, which is achieved by jointly optimizing inter- and intra-layer AP using an MIQP formulation. We provide a detailed case study of the optimal parallel strategy for BERT-Huge in Appendix~\ref{appendix:case-study} of the supplementary material.

\subsection{Scalability}\label{subsec:experiment:scalability}
We study the scalability of UniAP on \textsc{EnvD}, the result of which is shown in Figure~\ref{fig:scalability}. We can find that the training throughput of the optimal strategy and the corresponding strategy optimization time demonstrate near-linearity as the number of nodes and mini-batch size increase. This phenomenon reveals that UniAP is scalable and verifies the computational complexity analysis in Section~\ref{subsec:method:unified-optimization}.

\subsection{Estimation Accuracy}\label{subsec:experiment:performance_modeling}
Some variables in UniAP and other AP methods are estimated values rather than actual running values. The TPI~(inverse of training throughput) returned by UniAP and other AP methods is one of them. Accurate estimation for TPI or training throughput is crucial for evaluating candidate parallel strategies and ensuring the optimality of the solution. To quantify the accuracy of the estimated training throughput, we introduce a metric called \emph{relative estimation error~(REE)} $e$ for training throughput:
\begin{equation}
    e(T, \hat{T}) = \frac{|T - \hat{T}|}{T} \times 100\%,
\end{equation}
where $T$ is the actual training throughput and $\hat{T}$ is the estimated training throughput.


% Figure environment removed

We evaluate the optimal parallel strategies obtained from \textsc{EnvA} and \textsc{EnvB} and visualize the REE of UniAP in Figure~\ref{fig:performance-modeling}. The results show that UniAP achieves an average REE of 3.59\%, which is relatively small. In contrast, the average REE for Galvatron~\citep{miao_galvatron_2022} in our experiments is 11.17\%, which is larger than that of UniAP.


\subsection{Ablation Study}\label{subsec:experiment:ablation-study}
We investigate the importance of the strategy space for the optimality of parallel strategies with an ablation study. Specifically, we constrain the strategy space to inter-layer-only and intra-layer-only strategies and evaluate the training throughput of the resulting optimal strategy on \textsc{EnvB}. We set the mini-batch sizes to be 16, 12, 64, and 32, respectively. The results are shown in Figure~\ref{fig:ablation}. We can find that constraining the strategy space compromises the optimality of parallel strategies or gets strategies that encounter OOM across different models. 
Hence, unifying inter- and intra-layer AP for joint optimization is essential and necessary. 

% Figure environment removed