\section{Experiment}
UniAP utilizes the Gurobi Optimizer 10.1~\citep{gurobi_optimization_llc_gurobi_2023} to solve the MIQP problem. We conduct experiments on three kinds of hardware environments. \textit{EnvA} refers to a node with 1 Xeon(R) Gold 6248 CPU, 8 V100-SXM2 32GB GPUs, and 472GB main memory. \textit{EnvB} refers to two nodes interconnected with 10Gbps networks, where each node has 2 Xeon E5-2620 v4 CPUs, 4 TITAN Xp 12GB GPUs, and 125GB main memory. \textit{EnvC} has four nodes, each with the same configuration as that in \textit{EnvB}. We evaluate UniAP with four Transformer-like models, BERT-Huge~\citep{devlin_bert_2019}, T5-Large~\citep{raffel_exploring_2020}, ViT-Huge~\citep{dosovitskiy_image_2021}, and Swin-Huge~\citep{liu_swin_2021} with different mini-batch sizes. Overall, we follow the common practice of training these Transformer-like models. Our experimental evaluation focuses on two primary metrics: training throughput and strategy searching time. The former metric is computed by averaging throughput from the 10th to the 60th iteration of training, while the latter is determined by measuring the time of the UOP. Further elaborations on these experimental settings are available in Appendix \ref{appendix:experiment-settings} in the supplementary material. 


\subsection{Training throughput and strategy searching time}\label{subsec:experiment:search-time-and-throughput}
We compare the throughput of the optimal parallel strategy and UniAP's strategy searching time with the baseline approach. For experiments conducted on \textit{EnvA}, we select 32, 16, 128, and 128 as the mini-batch size for BERT, T5, ViT, and Swin, respectively. As for experiments conducted on \textit{EnvB}, we set the mini-batch size as 16, 8, 64, and 32 for these four models. 
We choose Galvatron~\citep{miao_galvatron_2022} as our baseline because it has been identified as the SOTA method. In particular, Galvatron has outperformed existing methods, including PyTorch DDP~\citep{li_pytorch_2020}, Megatron-LM~\citep{narayanan_efficient_2021}, FSDP~\citep{fairscale_authors_fairscale_2021,rajbhandari_zero_2020}, GPipe~\citep{huang_gpipe_2019}, and DeepSpeed 3D~\citep{deepspeed-3d}, in terms of training throughput, as reported in the original publication~\citep{miao_galvatron_2022}.

 
Table \ref{tab:enva} and Table \ref{tab:envb} show our results on \textit{EnvA} and \textit{EnvB}, respectively. The number immediately following the model's name in each table represents the number of hidden layers in the corresponding model. For example, ViT-Huge-32 represents a ViT-Huge model with 32 hidden layers. Besides, OOM denotes out-of-memory exceptions during our training process.


\begin{table}
  \centering
  \caption{Training throughput and strategy searching time on \textit{EnvA}.}
    \begin{tabular}{ccccccc}
    \toprule
    \multirow{2}[0]{*}{Model} & \multicolumn{3}{c}{Training throughput (samples/s)} & \multicolumn{3}{c}{Strategy searching time (s)} \\
    \cmidrule(r){2-4}\cmidrule(r){5-7}
          & Galvatron & UniAP & Speedup & Galvatron & UniAP & Speedup \\
    \midrule
    BERT-Huge-32 & \textbf{33.06 } & \textbf{33.06 } & 1.00 & 384.93  & \textbf{22.87 } & 16.83   \\
    T5-Large-48 & \textbf{21.89 } & \textbf{21.89 } & 1.00  & 707.96  & \textbf{66.69 } & 10.62  \\
    ViT-Huge-32 &  \textbf{90.30 } & \textbf{90.30 } & 1.00 & 424.68  & \textbf{33.52 } & 12.67   \\
    Swin-Huge-48 & OOM   & \textbf{35.63 } & N/A & 743.87  & \textbf{116.95 } & 6.36    \\
    \bottomrule
    \end{tabular}
  \label{tab:enva}
\end{table}

\begin{table}
  \centering
  \caption{Training throughput and strategy searching time on \textit{EnvB}.}
    \begin{tabular}{ccccccc}
    \toprule
    \multirow{2}[0]{*}{Model} & \multicolumn{3}{c}{Training throughput (samples/s)} & \multicolumn{3}{c}{Strategy searching time (s)} \\
    \cmidrule(r){2-4}\cmidrule(r){5-7}
          & Galvatron & UniAP & Speedup & Galvatron & UniAP & Speedup \\
    \midrule
    BERT-Huge-32 & 5.29  & \textbf{8.97 } & 1.70 & 123.14  & \textbf{93.68 } & 1.31 \\
    T5-Large-32 & 4.57  & \textbf{7.55 } & 1.65 & 163.79  & \textbf{58.03 } & 2.82   \\
    ViT-Huge-32  & 32.82  & \textbf{35.98 } & 1.10 & 136.91  & \textbf{67.94 } & 2.02  \\
    Swin-Huge-48 & 14.34  & \textbf{20.67 } & 1.44 & 250.10  & \textbf{174.94 } & 1.43  \\
    \bottomrule
    \end{tabular}
  \label{tab:envb}
\end{table}

On \textit{EnvA}, UniAP generates the same optimal strategy as Galvatron on BERT-Huge-32, T5-Large-48, and ViT-Huge-32 with a significantly shorter time. On Swin-Huge-48, UniAP finds a solution while Galvatron encounters OOM. Specifically, UniAP achieves a search speed that is 16$\times$ faster than Galvatron on BERT-Huge-32. On \textit{EnvB}, UniAP uses about half of the search time to find the optimal parallel strategies with an average speedup of 1.47$\times$ and a maximum speedup of 1.70$\times$. Overall, UniAP gains significant advantages from broadening its strategy space by unifying inter- and intra-layer automatic parallelism and using MIQP.

Furthermore, we can observe significant speedup differences between these two environments. For instance, UniAP cannot identify a parallel strategy with higher throughput on \textit{EnvA} but is able to do so on \textit{EnvB}. 
This phenomenon may be due to the higher interconnect bandwidth on \textit{EnvA} than \textit{EnvB}. Given the observation~\citep{tarnawski_piper_2021,zheng_alpa_2022,miao_galvatron_2022} that the communication volume for inter-layer parallelism is much smaller than that for intra-layer, both frameworks present a pure intra-layer parallelism strategy on \textit{EnvA} to maximize the bandwidth utilization ratio. However, tests on \textit{EnvB} always generate an inter- and intra-layer or an inter-layer-only parallelism strategy. UniAP, in this case, will identify a better parallel strategy because of its larger strategy space.

Meanwhile, UniAP obtains a higher search time speedup on \textit{EnvA} than \textit{EnvB}. 
The main reasons for this phenomenon are as follows: 
1) Galvatron takes a longer time to enumerate larger memory size in its dynamic programming algorithm on \textit{EnvA}; 
2) UniAP may take longer to confirm that the parallel strategies will fit into the tighter memory bounds on \textit{EnvB}. 
We can easily find evidence supporting the first reason in Galvatron~\citep{miao_galvatron_2022}. 
The second reason can be verified by the strategy searching time of BERT-Huge-32, ViT-Huge-32, and Swin-Huge-48. More specifically, although a smaller batch size leads to a more limited strategy space, UniAP takes longer to find the optima on \textit{EnvB} than on \textit{EnvA}.

\subsection{Scalability}\label{subsec:experiment:scalability}
In this section, we conduct a scalability study on \textit{EnvC} for UniAP. As Figure \ref{fig:scalability} shows, the training throughput of the optimal strategy and its strategy searching time on \textit{EnvC} exhibits near-linearity in a real-world system as the number of nodes and mini-batch size increase exponentially. This phenomenon verifies the computational complexity analysis in Section \ref{subsec:method:complexity-analysis}.

% Figure environment removed


\subsection{Ablation study}\label{subsec:experiment:ablation-study}
In this section, we study the importance of strategy space on the optimality of parallel strategies. Specifically, we reduce the strategy space to inter-layer-only and intra-layer-only strategies in UniAP and evaluate the training throughput of the resulting optimal strategy on \textit{EnvB}. We set the mini-batch size as 16, 12, 64, and 32, respectively. Table \ref{tab:ablation} shows that constraining the strategy space can compromise the optimality of parallel strategies or provide strategies that encounter OOM across different models. Therefore, holding a unified view of the automatic parallelism problem is essential.

\begin{table}
  \centering
  \caption{Ablation study on the importance of unifying strategy space.}
    \begin{tabular}{cccc}
    \toprule
    \multirow{2}[0]{*}{Model} & \multicolumn{3}{c}{Training throughput (samples/s)} \\
    \cmidrule(r){2-4}
          & UniAP (Inter-only) & UniAP (Intra-only) & UniAP \\
    \midrule
    BERT-Huge-32 & 2.44 & OOM   & \textbf{8.97} \\
    T5-Large-32 & OOM   & 2.9115 & \textbf{9.93} \\
    ViT-Huge-32 & \textbf{35.98} & OOM   & \textbf{35.98} \\
    Swin-Huge-48 & \textbf{20.67} & 4.6484 & \textbf{20.67} \\
    \bottomrule
    \end{tabular}
  \label{tab:ablation}
\end{table}
