\section{Details of experiments}\label{app:experiments}
\subsection{Experimental protocol}\label{app:experiments-protocol}
In Experiments 1-6, for each watermark we first generate a sequence tokens, decode the tokens 
into text (i.e., a string) using the appropriate tokenizer for the language model, and then 
encode the text back into tokens before running $\detect$.
Each generation is coditioned on a prompt; we obtain the prompts by sampling documents from the news-like 
subset of the C4 dataset and truncating the last $m$ tokens.
We enforce a minimum prompt size of $50$ tokens in all experiments; we skip over any document that is not long enough.
The retokenization is not always equal to the original tokens; in order to ensure $\detect$ always receives 
at least $m$ tokens, we pad its input with special pad tokens (specific to each model's tokenizer).
We also initially generate a number of buffer tokens beyond $m$, so in most cases the padding is unnecessary.
We set the number of buffer tokens to be $20$ in every experiment except for Experiment 5, where we set it to be 
$100$ in order to ensure that even after deleting tokens there are typically still at least $m$ tokens remaining.
We always truncate the number of tokens given to $\detect$ to be at most $m$, irrespective of the number of buffer tokens.

\subsection{Roundtrip translation}\label{app:experiments-roundtrip}
In Experiment 6, we perform round-trip translations from English to French and from English to Russian using the OPUS-MT collection of translation models \citep{tiedemann2020opus,tiedemann2022democratizing}. Specifically, we use the versions of these models hosted on the HuggingfaceHub\footnote{https://huggingface.co/}, associated with the identifiers:
\begin{itemize}
\item \texttt{Helsinki-NLP/opus-mt-tc-big-en-fr} - English to French,
\item \texttt{Helsinki-NLP/opus-mt-tc-big-fr-en} - French to English,
\item \texttt{Helsinki-NLP/opus-mt-en-ru} - English to Russian,
\item \texttt{Helsinki-NLP/opus-mt-ru-en} - Russian to English.
\end{itemize}

\subsection{Computing p-values}\label{app:experiments-pvals}
As we mention previously, to save computation we modify $\detect$ to use a fixed reference distribution to compute 
$p$-values.
For the sake of concreteness, we give the full pseudocode for the modified version of $\detect$ in Algorithm~\ref{algorithm:modified-detect};
in Experiments 1-6, we compute $p$-values using Algorithm~\ref{algorithm:reference} to construct the reference distribution using the news-like subset of
the C4 dataset as the text distribution.

\begin{algorithm}[h]
    \DontPrintSemicolon
    \SetKwInOut{Input}{Input}
    \SetKwInOut{Output}{Output}
    \SetKwInOut{Params}{Params}
    \SetKwInOut{Noise}{Noise}
    \caption{\label{algorithm:modified-detect}
        Watermarked text detection with fixed reference distribution}
    \Input{string $y \in \mc{V}^*$, seed sequence $\xi \in \Xi^*$}
    \Params{test statistic $\phi$; reference distribution $\{\phi_t\}_{t=1}^T$}
    \Output{p-value $\est{p} \in [0,1]$}
    $\est{p} \leftarrow \frac{1}{T} \sum_{t=1}^T \indic{\phi(y,\xi) < \phi_t}$\;
    \Return $\est{p}$\;
\end{algorithm}

\begin{algorithm}[h]
    \DontPrintSemicolon
    \SetKwInOut{Input}{Input}
    \SetKwInOut{Output}{Output}
    \SetKwInOut{Params}{Params}
    \SetKwInOut{Noise}{Noise}
    \caption{\label{algorithm:reference}
        Reference distribution construction}
    \Input{resample size $T \in \N$, text length $m \in \N$, watermark key sequence distribution $\nu \in \Delta(\Xi^n)$}
    \Params{test statistic $\phi$; text distribution $P$; minimum prompt length $m_0$}
    \Output{reference distribution $\{\phi_t\}_{t=1}^T \in \R^T$}
    $t \leftarrow 1$\;
    \While{$t \leq T$}{
        $Y \sim P$\;
        \If{$\len{Y} \leq m_0 + m$}{
            continue\;
        }
        $\xi \sim P_\xi$\;
        $\phi_t \leftarrow \phi(Y_{-m:},\xi)$\;
        $t \leftarrow t + 1$\;
    }
    \Return $\{\phi_t\}_{t=1}^T$\;
\end{algorithm}

As a sanity check, we include histograms of the $p$-values we compute for nonwatermarked text for each method to verify that 
they are roughly uniformly distributed on the interval $[0,1]$ (setting $m = 50$ and sampling prompts 
from the news-like subset of the C4 dataset, as in Experiment 1).
In the cases of {\kgwone} and {\kgwtwo}, the distribution is not quite uniform 
due to the discrete nature of their test statistics.

% note: actually the plots are from experiment 1, the name of the figure is just off
% Figure environment removed

% Figure environment removed

% Figure environment removed

% Figure environment removed

% Figure environment removed

% Figure environment removed


\subsection{Hyperparameter tuning}\label{app:experiments-hyperparam}
There are two hyperparameters involved in computing each of our watermark test statistics (i.e., Algorithm~\ref{algorithm:test}),
the block size $k$ and the alignment score $d$.
We do not tune the block size $k$ for our experiments, instead simply letting $k = m$, i.e., the text length, and the alignment score 
is also fixed for each of our watermarks, except for the hyperparameter $\gamma$ in both {\itsedit} and {\gumbedit}.
Smaller values of $\gamma$ (at least to a certain point) tend to make these watermarks more robust to insertion and deletion errors,
as Figure~\ref{fig:tuning-eps} illustrates,
but also hurts their statistical power for large values of $n$, i.e., the watermark key length, as Figure~\ref{fig:tuning-rng} illustrates.
We set $\gamma = 0.4$ for {\itsedit} and $\gamma = 0.0$ for {\gumbedit} to balance these two competing desiderata.

% Figure environment removed

% Figure environment removed

\subsection{Deferred results}\label{app:experiments-defer}
\subsubsection{Experiment 3}
% Figure environment removed

% Figure environment removed

% Figure environment removed

\subsubsection{Experiment 4}
% Figure environment removed

% Figure environment removed

% Figure environment removed

\subsubsection{Experiment 5}
% Figure environment removed

% Figure environment removed

% Figure environment removed

\subsubsection{Experiment 6}

% Figure environment removed

% Figure environment removed

\subsubsection{Instruction following case study}\label{app:experiments-instruct}
We give three examples of instructions for which hashing produces qualitatively worse responses 
than regular samples from the language model:
\begin{itemize}
  \item[1.] ``Give me 20 ideas for the title of a paper on watermarking language models.''
  \item[2.] ``Give me 20 ideas for startup names.''
  \item[3.] ``Give me a list of 20 movies.'' 
\end{itemize}
We format each of the instructions as described by \citet{taori23alpaca} before calling the model.

We compare samples from our {\gumb} watermark strategy,\footnote{
  Recall both {\gumb} and {\gumbedit} use the same $\generate$ method.
}
which are equivalent to regular samples from the language model,
to samples from {\kgwtwo} and the hashing-based version of {\gumb} we describe in the main text (i.e.,
the watermark of \citet{aaronson2023openai}), i.e., {\gumbhash}.
For both {\gumb} and {\kgwtwo}, we generate the samples using five different random seeds (the hash 
function in {\kgwtwo} is fixed in the implementation of \citet{kirchenbauer2023watermark}),
whereas in the case of {\gumbhash} we use five different hash functions (namely,
we let the previous $k$ tokens $\{y_i\}_{i=1}^k$ hash to $j + \sum_{i=1}^k y_i$ for $j \in \{0,\dots,4\}$).
We label each sample using the seed/hash we used to generate it.
We include samples from two versions of {\gumbhash}: one where we hash the previous tokens ($k = 1$) and another 
where we hash the previous four tokens ($k = 4$).
For {\kgwtwo}, we only hash the previous token since the public implementation of \citet{kirchenbauer2023watermark}
does not include the option to hash more tokens.

We find that {\gumbhash} with $k = 1$ often produces qualitatively worse responses that degenerate into 
repetition. With $k = 4$, the repetition is substantially less noticeable, though occasionally it still manifests.
In contrast, even when we only hash the previous token, the repetition of {\kgwtwo} is not nearly as noticeable as in {\gumbhash}.
We speculate this is due to stochasticity of {\kgwtwo} (i.e., {\kgwtwo} biases the distribution over the next token 
to a subset of tokens but still ultimately samples from this distribution randomly).
Of course, this stochasticity comes at a price: {\kgwtwo} was generally less powerful compared to the {\gumb} and {\gumbedit} strategies
in our other experiments.

We include sample sheets for all methods for the first instruction below. To avoid excessive clutter,
we defer the sample sheets for the remaining two instructions to our code release.

\begin{longtable}{|>{\centering\arraybackslash}m{0.1\textwidth}|>{\centering\arraybackslash}m{0.05\textwidth}|m{0.85\textwidth}|}
  \hline
  \textbf{Method} & \textbf{Seed} & \textbf{Response} \\
  \hline
  {\gumbhash} ($k = 1$) & 0 & 1. Watermarking Deep Learning Models: A Review
  2. Understanding and Evaluating Watermarking Techniques for Neural Networks
  3. Towards Unobtrusive and Invisible Watermarking for Neural Networks
  4. Customizable Watermarking for Neural Networks
  5. Reverse Engineering Watermarked Neural Networks
  6. Understanding and Exploiting Watermarking Attacks on Neural Networks
  7. Combatting Watermarking Attacks on Neural Networks
  8. Customizable Watermarking for Neural Networks
  9. Customizable Watermarking for Neural Networks
  10. Customizable Watermarking for Neural Networks
  11. Customizable Watermarking for Neural Networks
  12. Customizable Watermarking for Neural Networks
  13. Customizable Watermarking for Neural Networks
  14. Customizable Watermarking for Neural Networks
  15. Customizable Watermarking for Neural Networks
  16. Customizable Watermarking for Neural Networks
  17. Customizable Watermarking for Neural Networks
  18. Customizable Watermarking for Neural Networks
  19. Customizable Watermarking for Neural Networks \\
  \hline
  {\gumbhash} ($k = 1$) & 1 & 1. Exploiting Watermarks in Language Modeling 
  2. Watermarking Language Models: State of the Art 
  3. Keys to the Kingdom: Refining Watermarking Language Models 
  4. Exploiting Watermarks in Natural Language Processing 
  5. Keys to the Kingdom: Refining Watermarking Language Models 
  6. Keys to the Kingdom: Refining Watermarking Language Models 
  7. Keys to the Kingdom: Refining Watermarking Language Models 
  8. Keys to the Kingdom: Refining Watermarking Language Models 
  9. Keys to the Kingdom: Refining Watermarking Language Models 
  10. Keys to the Kingdom: Refining Watermarking Language Models 
  11. Keys to the Kingdom: Refining Watermarking Language Models 
  12. Keys to the Kingdom: Refining Watermarking Language Models 
  13. Keys to the Kingdom: Refining Watermarking Language Models 
  14. Keys to the Kingdom: Refining Watermarking Language Models 
  15. Keys to the Kingdom: Refining Watermarking Language Models 
  16. Keys to the Kingdom: Refining Watermarking Language Models 
  17. Keys to the Kingdom: Refining Watermarking Language Models 
  18. Keys to the Kingdom: Refining Watermarking Language Models 
  19. Keys to the Kingdom: Refining Watermarking Language Models 
  20. Keys to the Kingdom: Refining Watermarking Language Models \\
  \hline
  {\gumbhash} ($k = 1$) & 2 & 1. "Making Watermarks: Creative Approaches to Watermarking Language Models"
  2. "Making Watermarks: Creative Approaches to Watermarking Language Models"
  3. "Making Watermarks: Creative Approaches to Watermarking Language Models"
  4. "Making Watermarks: Creative Approaches to Watermarking Language Models"
  5. "Making Watermarks: Creative Approaches to Watermarking Language Models"
  6. "Making Watermarks: Creative Approaches to Watermarking Language Models"
  7. "Making Watermarks: Creative Approaches to Watermarking Language Models"
  8. "Making Watermarks: Creative Approaches to Watermarking Language Models"
  9. "Making Watermarks: Creative Approaches to Watermarking Language Models"
  10. "Making Watermarks: Creative Approaches to Watermarking Language Models"
  11. "Making Watermarks: Creative Approaches to Watermarking Language Models"
  12. "Making Watermarks: Creative Approaches to Watermarking Language Models"
  13. "Making Watermarks: Creative Approaches to Watermarking Language Models"
  14. "Making Watermarks: Creative Approaches to Watermarking Language Models"
  15. "Making Watermarks: Creative Approaches to Watermarking Language Models"
  16. "Making Watermarks: Creative Approaches to Watermarking Language Models"
  17. "Making Watermarks: Creative Approaches to Watermarking Language Models"
  18. "Making Watermarks: Creative Approaches to Watermarking Language Models"
  19. "Making Watermarks: Creative Approaches to Watermarking Language Models"
  20. "Making Watermarks: Creative Approaches to Watermarking Language Models" \\
  \hline
  {\gumbhash} ($k = 1$) & 3 & 1. Watermarking Language Models: A Review
  2. Watermarking Language Models for Copyright Protection
  3. Watermarking Language Models for Forensic Analysis
  4. Watermarking Language Models for Audio Signals
  5. Watermarking Language Models for Video Signals
  6. Watermarking Language Models for Documents
  7. Watermarking Language Models for Software
  8. Watermarking Language Models for Big Data
  9. Watermarking Language Models for Natural Language Processing
  10. Watermarking Language Models for Machine Learning
  11. Watermarking Language Models for Deep Learning
  12. Watermarking Language Models for Speech Recognition
  13. Watermarking Language Models for Audio Synthesis
  14. Watermarking Language Models for Computer Vision
  15. Watermarking Language Models for Robotics
  16. Watermarking Language Models for Autonomous Driving
  17. Watermarking Language Models for Medical Image Processing
  18. Watermarking Language Models for Medical Diagnostics
  19. Watermarking Language Models for Text Translation \\
  \hline
  {\gumbhash} ($k = 1$) & 4 & 1. Image based watermarking for language models
  2. Steganographic watermarking for language models
  3. Timestamps for language models
  4. Watermarking for language model improvisation
  5. Secure watermarking for language model sharing
  6. Image based watermarking for language model improvisation
  7. Timestamps for language model improvisation
  8. Watermarking for language model evolution
  9. Secure watermarking for language model evolution
  10. Image based watermarking for language model evolution
  11. Timestamps for language model evolution
  12. Watermarking for language model generation
  13. Image based watermarking for language model generation
  14. Timestamps for language model generation
  15. Watermarking for language model understanding
  16. Image based watermarking for language model understanding
  17. Timestamps for language model understanding
  18. Watermarking for language model improvisation and understanding
  19. Image based watermarking for language model improvisation and understanding \\
  \hline
  \caption{Responses from {\gumbhash} with $k = 1$ to the prompt: ``Give me 20 ideas for the title of a paper on watermarking language models.''}
\end{longtable}

\begin{longtable}{|>{\centering\arraybackslash}m{0.1\textwidth}|>{\centering\arraybackslash}m{0.05\textwidth}|m{0.85\textwidth}|}
  \hline
  \textbf{Method} & \textbf{Seed} & \textbf{Response} \\
  \hline
  {\gumbhash} ($k = 4$) & 0 & 1. "Safeguarding Language Models: Exploring Watermarking for Vertext and Image Models"
  2. "Watermarking Language Models: Protecting Your Creations"
  3. "The Future of Watermarking Language Models: Ethical and Practical Considerations"
  4. "Securing Language Models: Exploring Emerging Technologies"
  5. "Watermarking Language Models: Balancing Creativity and Security"
  6. "Watermarking Language Models: Balancing Security and Accessibility"
  7. "Watermarking Language Models: Defending your Creativity"
  8. "Watermarking Language Models: Defending your Creativity with Emerging Technologies"
  9. "Protecting Language Models: Exploring Emerging Technologies"
  10. "Securing Language Models: Balancing Security and Accessibility"
  11. "The Future of Watermarking Language Models: Ethical and Practical Considerations"
  12. "Watermarking Language Models: Balancing Security and Accessibility"
  13. "Watermarking Language Models: Balancing Security and Accessibility with Emerging Technologies"
  14. "Watermarking Language Models: Defending your Creativity with Emerging Technologies"
  15. "Watermarking Language Models: Defending your Creativity with Emerging Technologies"
  16. "Securing Language Models: Balancing Security and Accessibility with Emerging Technologies"
  17. "Exploring Watermarking for Vertext and Image Models"
  18. "Watermarking Language Models: Balancing Security and Accessibility with Emerging Technologies"
  19. "Defending your Creativity with Emerging Technologies" \\
  \hline
  {\gumbhash} ($k = 4$) & 1 & 1. Towards a New Era of Transparent Language Models 
  2. A Review of the State of Watermarking Language Models 
  3. The Benefits of Embedding Watermarks in Language Models 
  4. Protecting Language Models with Multiscale Watermarks 
  5. Impact of Watermarking on the Performance of Language Models
  6. A Survey on Watermarking for Language Models 
  7. Practical Perspectives on Watermarking for Language Models 
  8. A Comprehensive Study on Designing Watermarks for Language Models 
  9. Overview of Techniques for Adding Watermarks to Language Models 
  10. Exploring the Possibilities of Watermarking for Language Models 
  11. How to Incorporate Watermarks in Your Language Model 
  12. The Science behind Watermarking for Language Models 
  13. AI for Insertion of Watermarks in Language Models 
  14. The Role of Machine Learning in Watermarking for Language Models 
  15. Future Trends in Watermarking for Language Models 
  16. A Review on Watermarking for Language Models 
  17. Applications of Watermarking in Language Modeling 
  18. A Comprehensive Study on Designing Robust Watermarks for Language Models 
  19. A Novel Approach to Incorporate Watermarks in Your Language Model. \\
  \hline
  {\gumbhash} ($k = 4$) & 2 & 1. Securing Your Language Model
  2. Stamping Out Unauthorized Use
  3. Coloring Outside the Lines: Creative Watermarks
  4. Avoiding Watermarks: Best Practices
  5. Authentication Made Easy with Watermarks
  6. Defending Your Language Model
  7. Unique Identifiers: Adding Value to your Model
  8. Connected Learning: Leveraging Watermarks
  9. The Problem with Open Access
  10. How to Effectively Mark a Language Model
  11. Making a Splash with Creative Watermarks
  12. Understanding the Benefits of Watermarking
  13. Utilizing Watermarks for Better Attribution
  14. Stewarding Your Language Model
  15. The Role of Technology in Watermarking
  16. Beyond the Horizon: Adaptive Watermarking
  17. The Art of Discretion in Watermarking
  18. Harnessing the Power of Invisible Watermarks
  19. Practical Considerations for Watermarking \\
  \hline
  {\gumbhash} ($k = 4$) & 3 & 1. Elucidating Watermarking Strategies for Language Models 
  2. Innovative Techniques for Watermarking Language Models 
  3. Intelligent and Innovative Watermarking Strategies for Language Models 
  4. Overview of Watermarking Strategies for Language Models 
  5. Emerging Technologies in Watermarking for Language Models 
  6. Practical Perspectives on Watermarking Language Models 
  7. Reducing Watermarking Strategies for Language Models 
  8. Robust Techniques for Watermarking Language Models 
  9. Security Factors in Watermarking Language Models 
  10. Understanding Watermarking Strategies for Language Models 
  11. Evaluation of Watermarking Strategies for Language Models 
  12. Exploring Watermarking Strategies for Language Models 
  13. Innovations in Watermarking Language Models 
  14. Intelligent Techniques for Watermarking Language Models 
  15. Methods for Watermarking Language Models 
  16. Overlapping Security Factors in Watermarking Language Models 
  17. Understanding Watermarking Strategies for Language Models 
  18. Emerging Technologies in Watermarking Language Models 
  19. Exploring Watermarking Strategies for Language Models 
  20. Intelligent and Innovative Watermarking Strategies for Language Models \\
  \hline
  {\gumbhash} ($k = 4$) & 4 & 1. Securing Language Models 
  2. Extra Secure Language Models 
  3. Defending Language Models 
  4. Protecting Language Models 
  5. Cryptographic Language Models 
  6. Unique Language Models
  7. Robust Language Models
  8. Marking Language Models
  9. Preventing Language Models
  10. Hiding Language Models
  11. Invisible Language Models
  12. Steganographic Language Models
  13. Watermarking Language Models
  14. Preserving Language Models
  15. Uniquely Identifiable Language Models
  16. Characterizing Language Models
  17. Distinguishable Language Models
  18. Language Model Defence
  19. Ultra Defence Language Models \\
  \hline
  \caption{Responses from {\gumbhash} with $k = 4$ to the prompt: ``Give me 20 ideas for the title of a paper on watermarking language models.''}
\end{longtable}

\begin{longtable}{|>{\centering\arraybackslash}m{0.1\textwidth}|>{\centering\arraybackslash}m{0.05\textwidth}|m{0.85\textwidth}|}
    \hline
    \textbf{Method} & \textbf{Seed} & \textbf{Response} \\
    \hline
    {\kgwtwo} & 0 & 1. Steganography in Language Models: A Review
    2. Combating Model Piracy with Watermarking
    3. Techniques for Traceability and Watermarking
    4. Salient Features for Traceability and Watermarking
    5. Reflections on Model Security and Watermarking
    6. Insights on Model Security and Watermarking
    7. Protecting Models with Watermarking
    8. Techniques for Esoteric Traceability and Watermarking
    9. Ins and Outs of Steganography in Language Models
    10. Technologies for Efficient Watermarking
    11. Vision Beyond Model Piracy: Watermarking Perspectives
    12. Impact of Model Security on Watermarking
    13. Emerging Trends in Watermarking of Language Models
    14. Future of Watermarking Techniques for Language Models
    15. Drivers for Success in Watermarking Language Models
    16. Robustness of Models against Watermarking
    17. Taking Security beyond Watermarking
    18. Leveraging Model History and Watermarking
    19. Techniques for Secure Watermarking
    20. Comprehensive Overview of Model Security and Watermarking. \\
    \hline
    {\kgwtwo} & 1 & 1. Embedding Digital Signatures: Towards Traceable and Transparent Language Models
    2. Stamping Out Deception: Recording Attribution in Language Models 
    3. Defining Your Digital Dashboard: Watermarking for Traceability
    4. Scaling Trust in Language Models: Watermarking for Traceability and Transparency 
    5. Taking an East Asian Approach to Transparency in Language Models 
    6. Riding the Big Five: Towards Transparency in Language Models 
    7. Measuring the "Ps" of Language Models: Perceptual and Practical Transparency 
    8. Marking a Mark: Comprehensive Examination of Attribution in Language Models 
    9. Visualizing Deception: Comprehensive Examination of Deceptive Language Models 
    10. Peak Performance: Evaluating Language Models for Transparency 
    11. Closing the Loop: Examining the Long-term Impacts of Language Models 
    12. Diversifying Perspective: Impacts of Modelling Language 
    13. Disclosing the Hidden Layers: Understanding Transparency in Language Models 
    14. Auditable: Making Language Models Accountable 
    15. Labelling Human Language: Exploring the Capabilities of Language Models 
    16. Setting the Record: Estimating the Real-world Impacts of Language Models 
    17. Language Models: Towards Traceable, Transparent and Accountable Systems 
    18. Think Outside the Box: Exploring Future Trends in Language Models 
    19. Embedding Trust: Towards Traceable and Transparent Language Models.  \\
    \hline
    {\kgwtwo} & 2 & 1. Defending Latent Space with Secure Watermarks
    2. Emergent Waveforms: A Watermarking Approach
    3. Embedding Digital Identities in Neural Networks
    4. Marking up Models: A Survey on Watermarking
    5. Leveraging Linked Data for Watermarking
    6. Stamping Out Superfluous Models
    7. Inspecting and Marking Models 
    8. Rethinking Digital Identity with Watermarks
    9. Marking Up Models: A Usage-Driven Approach
    10. Bridge the Distance with Digital Watermarks
    11. Introducing Transparency in Model Formation 
    12. Unlocking Models with Secure Watermarks
    13. Giving Visible Identity to Models 
    14. Unveiling Dark Knowledge with Watermarks
    15. Linking Models: A Visual Approach 
    16. Visualizing Dark Knowledge through Watermarks
    17. Leveraging Physical World for Model Tracking 
    18. Augmented Reality for Model Tracking
    19. Securing Deep Models with Watermarks  \\
    \hline
    {\kgwtwo} & 3 & 1. Providing Type-Safe Watermarks
    2. Constructing Robust Watermarks for Multimedia Applications
    3. Adding Security Features to Text Vectors
    4. Stretching Visible Watermarks
    5. Embedding Watermarks in Natural Language Models
    6. Training Recurrent Neural Networks with Watermarks
    7. Detection of Unsupervised Watermarks in Text Sequences
    8. Interactive Visualization of Watermarks
    9. Observe Hidden Watermarks with Machine Learning
    10. Extracting Information from Unseen Watermarks
    11. Building Robust Watermarks for the Blockchain
    12. Adding Dynamic Watermarks to Video Streams
    13. Storing Watermarks in Individual Dataset Elements
    14. Extracting Pertinent Information from Unwanted Watermarks
    15. Decoding Hidden Digital Watermarks
    16. Introducing Watermarks to Secure Semi-honest Adversaries
    17. Genuine Components with Integrated Watermarks
    18. Intelligent Techniques for Steganography 
    19. Protecting Quality with Data-Driven Watermarks  \\
    \hline
    {\kgwtwo} & 4 & 1. Embedding Watermarks in Language Models 
    2. Secure Language Models using Watermarks
    3. Steganographic watermarking of natural language models 
    4. Exploring Watermarking Techniques for Natural Language Models 
    5. Analyzing Natural Language Models using Watermarking Techniques
    6. Detecting Watermarks in Natural Language Models
    7. Supervised Learning of Watermarks for Natural Language Models 
    8. Unsupervised Learning of Watermarks for Natural Language Models 
    9. Multiple watermarks for secure language models
    10. Generative watermarking techniques for natural language models
    11. Evaluation of watermarks for secure natural language models
    12. Efficacy of watermarks in preventing model poisoning
    13. Robustness of watermarks for natural language models 
    14. Comparison of watermarking techniques for natural language models 
    15. Linking of natural language models with watermarks
    16. Extraction of hidden information from natural language models 
    17. Universality of watermarks for different languages 
    18. Learning watermarked natural language models 
    19. Reduced Dimensionality Modeling using Watermarks  \\
    \hline
    \caption{Responses from {\kgwtwo} to the prompt: ``Give me 20 ideas for the title of a paper on watermarking language models.''}
\end{longtable}

\begin{longtable}{|>{\centering\arraybackslash}m{0.1\textwidth}|>{\centering\arraybackslash}m{0.05\textwidth}|m{0.85\textwidth}|}
  \hline
  \textbf{Method} & \textbf{Seed} & \textbf{Response} \\
  \hline
  {\gumb} & 0 & Here is the list of 20 ideas for the title of a paper on watermarking language models: 

  1. "Understanding Watermarking Techniques for Language Models" 
  2. "A Comprehensive Study on Watermarking for Language Models"
  3. "Watermarking Techniques for Optimizing Language Models"
  4. "A Survey of Watermarking Techniques for Language Models"
  5. "Exploring the Potential of Watermarking for Language Models"
  6. "Implementing Watermarking for Language Model Optimization"
  7. "Watermarking Strategies for Enhancing Language Models"
  8. "Investigating the Possibilities of Watermarking for Language Models"
  9. "Advanced Watermarking Approaches for Language Models"
  10. "Exploring the Use of Watermarking for Language Model Validation"
  11. "Understanding the Benefits of Watermarking for Language Model Ensemble"
  12. "Leveraging Watermarking Techniques for Enhanced Language Model Performance"
  13. "Enhancing Language Models with Watermarking"
  14. "Evaluating the Impact of Watermarking Techniques on Language Models"
  15. "Analyzing the Feasibility of Watermarking for Language Model Comparison"
  16. "Exploring the Possibilities of Watermarking for Optimizing Language Models"
  17. "Exploiting Watermarking to Enhance Language Model Accuracy"
  18. "Advantages of Using Watermarking for Validating Language Models"
  19. "The Promise of Watermarking for Evaluating Language Model Performance" \\
  \hline
  {\gumb} & 1 & Title ideas for a paper on watermarking language models:
  1. Hidden Messages: Protecting Language Models with Watermarking
  2. Securing Language Models with Watermarking
  3. Defending Language Models against Tampering
  4. Watermarking Language Models for Better Protection
  5. Verifying the Integrity of Language Models
  6. Utilizing Watermarking to Boost Language Model Security
  7. Ensuring the Authenticity of Language Models
  8. Safekeeping Language Models with Watermarking
  9. Defending Against Model Tampering with Watermarking
  10. A Review of Model Security Techniques: Watermarking
  11. Utilizing Watermarks to Protect Language Models
  12. Protective Techniques for Language Models: Watermarking
  13. Implementing Watermarks to Boost Language Model Security
  14. Preventing Model Tampering with Watermarking
  15. Methods for Verifying Language Model Integrity
  16. Analyzing the Security of Language Models
  17. Techniques for Securing Language Models
  18. Investigating Model Security with Watermarking
  19. Extending Language Model Security with Watermarking \\
  \hline
  {\gumb} & 2 & 1. "Deep Watermarks: Towards Pervasive Protection for Language Models" 
  2. "Adding Transparency to Language Models: A Watermarking Approach"
  3. "Watermarking Language Models for Traceability and Verification"
  4. "A Comprehensive Review on Watermarking Methods for Language Models"
  5. "The Power of Watermarking for Language Model Protection"
  6. "Attributing Authorship in Language Models with Watermarking"
  7. "Understanding the Promise of Watermarking for Language Model Security"
  8. "Watermarking Language Models: A Survey"
  9. "Watermarking Language Models for Better Security"
  10. "Mitigating Plagiarism in Language Models with Watermarking"
  11. "Watermarking Language Models: Exploring the Possibilities"
  12. "A Generative Approach to Watermarking Language Models"
  13. "Watermarking Strategies for Protecting Language Models"
  14. "Watermark Detection for Language Model Security"
  15. "Making Language Model Security Watertight with Watermarking"
  16. "Leveraging Watermarking for Enhancing Language Model Security"
  17. "Understanding the Role of Watermarking in Language Model Security"
  18. "A Novel Approach to Watermarking Language Models"
  19. "Exploring the Possibilities of Watermarking for Language Model Security" \\
  \hline
  {\gumb} & 3 & 1. A Comprehensive Review of Watermarking Techniques for Language Models
  2. A Survey of Watermarking Approaches for Language Modeling
  3. A Normative Analysis of Watermarking for Language Modeling
  4. Investigating Watermarking Techniques for Language Modeling
  5. An Overview of Watermarking Methods for Language Modeling
  6. Exploring Watermarking Solutions for Language Modeling
  7. A Taxonomy of Watermarking Methods for Language Modeling
  8. A Comparative Study of Watermarking Approaches for Language Modeling
  9. Evaluating Watermarking Methods for Language Modeling
  10. A Theoretical Analysis of Watermarking for Language Modeling
  11. Investigating Watermarking Techniques for Natural Language Modeling
  12. An Analytical Study of Watermarking for Language Modeling
  13. Exploring Watermarking Methods for Natural Language Modeling
  14. A Review of Watermarking Techniques for Natural Language Modeling
  15. A Comparative Study of Watermarking Approaches for Natural Language Modeling
  16. Investigating Watermarking Solutions for Natural Language Modeling
  17. A Survey of Watermarking Techniques for Natural Language Modeling
  18. Evaluating Watermarking Methods for Natural Language Modeling
  19. A Review of Watermarking for Natural Language Modeling
  20. Exploring Watermarking Solutions for Natural Language Modeling \\
  \hline
  {\gumb} & 4 & 1. Towards a Unified Watermarking Mechanism for Natural Language Processing Models
  2. A Review of Methods for Watermarking Natural Language Models
  3. Extracting Invariant Features for Watermarking Language Models
  4. The Use of Steganography for Watermarking Natural Language Models 
  5. Introducting Secure Watermarking Techniques for Natural Language Models
  6. A Comprehensive Study on Watermarking Techniques for Natural Language Models
  7. Toward Remarkably Visible Watermarks for Natural Language Models
  8. Analyzing the Impact of Watermarking on Natural Language Models
  9. A Practical Guide to Marking Language Models
  10. Enhancing the Accuracy of Watermarking Natural Language Models
  11. Evaluating Strategies for Watermarking Natural Language Models
  12. A Comparison of Watermarking Approaches for Natural Language Models
  13. Promising Solutions for Securely Watermarking Natural Language Models
  14. Generative and Discriminative Approaches for Watermarking Natural Language Models
  15. Exploring the Possibilities of Steganography for Natural Language Models
  16. Understanding the Challenges of Watermarking Natural Language Models
  17. Evaluating the Effectiveness of Watermarking Techniques for Natural Language Models
  18. Enhancing the Transparency of Watermarking Techniques for Natural Language Models
  19. Extending the Capabilities of Watermarking Techniques for Natural Language Models
  20. Assessing the Sophistication of Watermarking Techniques for Natural Language Models \\
  \hline
  \caption{Responses from {\gumb} to the prompt: ``Give me 20 ideas for the title of a paper on watermarking language models.''}
\end{longtable}