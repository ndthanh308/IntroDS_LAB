% \section{Proof of Lemma~\ref{lemma:lower-bound-ours}}\label{app:lb}
% \begin{proof}
%     For each $i \in [m]$, Jensen's inequality ($\star$) gives
%     \begin{align}
%         \exp(-H(p(\cdot \mid Y_{:i-1}))) 
%         & = \exp\left(\sum_{y=1}^N p(y \mid Y_{:i-1}) \log p(y \mid Y_{:i-1})\right) \nonumber \\
%         & \stackrel{(\star)}{\leq} \sum_{y=1}^N p(y \mid Y_{:i-1})^2 \nonumber \\
%         & = \norm{p(\cdot \mid Y_{:i-1})}_2^2. \label{eqn:lower-bound-ours-jensen}
%     \end{align}
%     Meanwhile, we have
%     \begin{align}
%         \Ep \left[\alpha(Y) \right] 
%         & = \Ep \left[\frac{1}{m} \sum_{i=1}^m 1 - p(Y_i \mid Y_{:i-1})\right] \nonumber \\
%         & = \frac{1}{m} \sum_{i=1}^m \Ep \left[ \Ep \left[1 - p(Y_i \mid Y_{:i-1}) \mid Y_{:i-1}\right]\right] \nonumber \\
%         & = 1 - \frac{1}{m} \sum_{i=1}^m \Ep \left[\norm{p(\cdot \mid Y_{:i-1})}_2^2 \right]. \label{eqn:lower-bound-ours-alpha}
%     \end{align}
%     Combining the displays~\eqref{eqn:lower-bound-ours-jensen} and~\eqref{eqn:lower-bound-ours-alpha} gives the result as
%     \begin{align*}
%         \Ep \left[\alpha(Y) \right]
%         & \leq 1 - \Ep \left[\frac{1}{m}\sum_{i=1}^m \exp(-H(p(\cdot \mid Y_{:i-1})))\right] \\
%         & \stackrel{(a)}{\leq} 1 - \Ep\left[\exp\left(-\frac{1}{m}\sum_{i=1}^m H(p(\cdot \mid Y_{:i-1}))\right)\right] \\
%         & \stackrel{(b)}{\leq} 1 - \exp\left(\Ep\left[-\frac{1}{m}\sum_{i=1}^m H(p(\cdot \mid Y_{:i-1}))\right]\right) \\
%         & = 1 - \exp\left(-\frac{1}{m}H(Y)\right),
%     \end{align*}
%     with both (a) and (b) following from Jensen's inequality.
% \end{proof}

\section{Proof of Lemma~\ref{lemma:lower-bound-all}}\label{app:lb}
\begin{proof}
    To show the claim, we first lower bound the probability that $Y = Y'$.
    In particular,
    \begin{align*}
        \P(Y = Y') & = \sum_y \P(Y = y) \P(Y' = y) \\
        % & = \sum_y \prod_{i \in [m]} \P(Y_i = y_i \mid Y_{:i-1}=y_{:i-1}) \P(Y_i' = y_i \mid Y_{:i-1}' = y_{:i-1}) \\
        & = \sum_y \P(Y = y) \prod_{i \in [m]} p(y_i \mid y_{:i-1}) \\
        & = \sum_y \P(Y = y) \prod_{i \in [m]} (1 - (1 - p(y_i \mid y_{:i-1}))) \\
        & \stackrel{(\star)}{\geq} \sum_{y\in \mc{V}_c} \P(Y = y) \exp\left(-c\sum_{i \in [m]} 1 - p(y_i \mid y_{:i-1})\right) \\
        & \geq \Ep \left[\exp\left(-c m\alpha(Y)\right) \indic{Y \in \mc{V}^c}\right],
    \end{align*}
    where ($\star$) follows from
    $\exp(-cx) \leq 1 - x$ for $0 \leq x \leq 1 - \exp(-c/2)$.
    It then follows immediately that we can bound the total variation distance 
    between the joint distributions of $(Y,\xi)$ and $(Y',\xi)$ by
    \begin{align*}
        D_{TV}((Y,\xi)||(Y',\xi)) & \leq \P((Y,\xi) \neq (Y',\xi)) \\
        & \leq 1 - \Ep \left[\exp\left(-c m\alpha(Y)\right)\indic{Y \in \mc{V}^c}\right].
    \end{align*}

    Observe for any event $A$ that
    \begin{align*}
        D_{TV}((Y,\xi)||(Y',\xi)) \geq \P((Y,\xi) \in A) - \P((Y',\xi) \in A),
    \end{align*}
    and thus, combining the previous two displays, we have
    \begin{align*}
        \P((Y,\xi) \in A) + \P((Y',\xi) \notin A) & \geq \P((Y,\xi) \in A) + \P((Y,\xi) \notin A) - D_{TV}((Y,\xi)||(Y',\xi)) \\
        & \geq \Ep \left[\exp\left(-c m\alpha(Y)\right)\indic{Y \in \mc{V}^c}\right].
    \end{align*}
    The desired result thus follows from letting $A$ be the event that $h$ predicts $-1$.
\end{proof}