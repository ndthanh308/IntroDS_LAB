\section{Methodology and theoretical analysis}\label{sec:results}
% Recall in our problem formulation a trusted LM provider and watermark detector share 
% a secret randomized watermark key, which the LM provider uses to sample watermarked text 
% from a language model by calling a method $\generate$ and the detector uses to identify 
% watermarked text by calling a method $\detect$.
% \pl{this is a run on sentence, split; also can just go directly into defining things}
Let $\mc{V}$ be a discrete set, i.e., the \textit{vocabulary}, and let 
$p \in \mc{V}^* \to \Delta(\mc{V})$ be an autoregressive \textit{language model}
which maps a string of arbitrary length to a distribution over the vocabulary, with
$p(\cdot \mid x)$ % \pl{can we do $p_x(y)$ or even $p(y \mid x)$? I find $p(x)$ extremely confusing if you're meant to condition on $x$} 
denoting the distribution of the next token given the prefix $x \in \mc{V}^*$. %\john{In this definition, $y$ is a token but in the Algorithms, $y$ is a string of tokens}.
Let $\Xi$ denote the space in which the elements of the watermark key sequence lie.
Recall the main protocol (Figure~\ref{fig:main-top}) which defines our problem setting:
\begin{itemize}
  \item[0.] The LM provider shares a random watermark key sequence $\xi \in \Xi^*$ with the detector;
    \item[1.] The user sends a prompt $x \in \mc{V}^*$ to the LM provider;
    \item[2.] The LM provider generates text $Y \in \mc{V}^*$ by $Y = \generate(x,\xi)$;
    % \item[3.] The user publishes $\wt{Y} \in \mc{V}^*$, which may be a perturbation $Y$ or may be independent;
    \item[3.] The user publishes text $\wt{Y} \in \mc{V}^*$, which may be either (i) (an edited version of) the generated text $Y$
      or (ii) text independent of $Y$ (e.g., text that they wrote themselves);
    \item[4.] The detector determines if $\wt{Y}$ is watermarked---i.e., if $\wt{Y}$ depends on the watermark key sequence---by computing 
                a $p$-value $\est{p} = \detect(\wt{Y},\xi)$ with respect to the null hypothesis 
                that $\wt{Y}$ is independent of $\xi$ (i.e., not watermarked).
    % estimates a $p$-value $\est{p} = \detect(\wt{Y},\xi)$ to determine whether or not $\wt{Y}$ is watermarked,
    %             i.e., whether or not $\wt{Y}$ is independent of the watermark key $\xi$.
    %             \pl{this is confusing and implicitly equates watermark with independence when it's the opposite;
    %             would rewrite to be determine whether it is watermarked (i.e., dependent) or not (i.e., independent);
    %             If you're talking about p-values, you should define the null hypothesis explicitly
    %             }
\end{itemize}

% We will use the term \emph{watermarking strategy} to refer to a particular instantiation of the $\generate$ and $\detect$ methods
% to be run by the LM provider and detector respectively.
\subsection{Protocol details}\label{sec:protocol}
In the protocol, the LM provider calls the $\generate$ method (Algorithm~\ref{algorithm:generate}) to autoregressively generate 
text from a language model using a \emph{decoder} function $\decode : \Xi \times \Delta(\mc{V}) \to \mc{V}$ which
maps an element $\xi_i$ of the watermark key and a distribution over the next token to a next token prediction.
By design, over the randomness of $\xi_i$ the prediction should constitute a sample from the distribution,
i.e., $\P(\decode(\xi_i,\mu) = y_i) = \mu(y_i)$.
\begin{definition}\label{defn:distortion-free}
    A decoder $\decode : \Xi \times \Delta(\mc{V}) \to \mc{V}$ is \emph{distortion-free} 
    with respect to (the distribution of) a random variable $\xi \in \Xi$ if for any $\mu \in \Delta(\mc{V})$ and $y \in \mc{V}$ it satisfies
    $\P(\decode(\xi,\mu) = y) = \mu(y)$.
\end{definition}
We relate Definition~\ref{defn:distortion-free} to our informal definition of distortion-free text 
in the introduction through the following simple lemma.
Essentially, so long as the watermark key sequence is long enough that we do not reuse any part of it to generate text, 
the only material difference between an LM provider using $\generate$ versus sampling directly from the language model 
is that the sequence $\xi$ is an input to the method rather than resampled i.i.d. within the method for each call.
We treat the language model $p$, the decoder $\decode$, and generation length $m$ as internal parameters of the $\generate$ method.
\begin{lemma}\label{lemma:dist-free-equiv}
    Let $m,n \in \N$ with $n \geq m$.
    Let $\decode$ be distortion free with respect to a distribution $\nu \in \Delta(\Xi)$
    and let $\{\xi_i\}_{i=1}^n \iid \nu$. Let $Y = \generate(\xi;m,p,\decode)$.
    Then $Y_i \sim p(\cdot \mid Y_{:i-1})$ for $i \in [m]$.
\end{lemma}
\begin{proof}
    As $n \geq m$, we have $\{\xi_i\}_{i=1}^m \iid \nu$.
    The claim then follows immediately from applying Definition~\ref{defn:distortion-free}
    to Line~\ref{line:generate} of $\generate$ for $i \in [m]$.
\end{proof}
% \pl{I think we should spell this out formally and talk about the full distribution $p(y_{1:m})$ - do we want the prompt in here? and crucially I would say here that it goes up to length $m$ text}

To simplify the remainder of the presentation, we do not pass a prompt as input to $\generate$.
As the language model $p$ is arbitrary and $\detect$ is model-agnostic, %\pl{this is undefined}, 
this simplification is without loss of generality since $p$ itself may model the distribution of 
text from some base model given an arbitrary prompt.
Also, unless stated otherwise, without loss of generality we let $\mc{V} = [N]$ throughout the paper,
where $N \in \N$ is the vocabulary size.

% \rck{put these side by side to save space}
\begin{algorithm}[h]
    \DontPrintSemicolon
    \SetKwInOut{Input}{Input}
    \SetKwInOut{Output}{Output}
    \SetKwInOut{Params}{Params}
    \SetKwInOut{Noise}{Noise}
    \caption{\label{algorithm:generate}
        Watermarked text generation ($\generate$)}
    \Input{watermark key sequence $\xi \in \Xi^n$}
    \Params{generation length $m$, language model $p$, decoder $\decode$
% \pl{decoder is undefined, not explained}
    }
    \Output{string $y \in \mc{V}^m$}
    \For{$i \in 1,\dots,m$}{ 
% \pl{haven't defined $\xi$ yet either}
        $y_i \leftarrow \decode(\xi_{i\%n},p(\cdot \mid y_{:i-1}))$ \label{line:generate} %\tcp{assume $\len{\xi} \geq m$ (otherwise, use $\xi_{i\%m}$)}
    }
    \Return $y$\;
\end{algorithm}

The detector calls the $\detect$ method (Algorithm~\ref{algorithm:detect}) to compute---via a permutation test with $T$ resamples---a $p$-value 
with respect to a test statistic $\phi : \mc{V}^* \times \Xi^* \to \R$ for the null 
hypothesis that $\wt{Y}$ is not watermarked, i.e., that $\wt{Y}$ is independent of $\xi$. %\pl{this should be defined clearly above - 'We say that $\tilde Y$ is watermarked if\dots', not done in passing; otherwise, there's a lot packed in here, since you also have to introduce the notion of a distribution over $\nu$}, which we assume is drawn from the distribution $\nu$.
The output $\est{p}$ of $\detect$ is a proper non-asymptotic $p$-value: if $\wt{Y}$ is not watermarked, 
then each $(\wt{Y},\xi^{(t)})$ constitutes an independent, identically distributed copy of $(\wt{Y},\xi)$ and therefore by symmetry $\est{p}$ is 
uniformly distributed over $\{1/(T+1),2/(T+1),\dots,1\}$ for any (non-atomic) test statistic.\footnote{
    By non-atomic, we mean for any $c \in \R$ that $\P(\phi(Y,\xi) = c) = 0$ so that almost surely we will not 
    have to break ties (meaning, if $\phi(y,\xi) = \phi_t$) when computing $\est{p}$.
    In case of ties (i.e., if the test statistic is atomic), we can either modify $\detect$ to break 
    ties uniformly at random, or simply report valid but conservative $p$-values by leaving $\detect$ as is.
}
If $\phi$ returns a small $p$-value (e.g., 0.0001) then the text is likely watermarked;
if the $p$-value is large (e.g., 0.25), then the text might not be.

% \pl{can we replace 'sampler' with 'decoder'}
\begin{algorithm}[h]
    \DontPrintSemicolon
    \SetKwInOut{Input}{Input}
    \SetKwInOut{Output}{Output}
    \SetKwInOut{Params}{Params}
    \SetKwInOut{Noise}{Noise}
    \caption{\label{algorithm:detect}
        Watermarked text detection ($\detect$)
        % \pl{$\xi_t$ notation is confusing since it looks like an element but it's in fact a sequence; i'd do $\xi^{(t)}$}
        } %\thc{This test seems not quite valid - shouldnt we be doing the finite-sample monte carlo corrections as in https://arxiv.org/pdf/1603.05766.pdf ?}}
    \Input{string $y \in \mc{V}^*$, watermark key sequence $\xi \in \Xi^n$}
    \Params{test statistic $\phi$; watermark key sequence distribution $\nu \in \Delta(\Xi^n)$; resample size $T$}
    \Output{p-value $\est{p} \in [0,1]$}
    \For{$t \in 1,\dots,T$}{
        $\xi^{(t)} \sim \nu$\;
        $\phi_t \leftarrow \phi(y,\xi^{(t)})$\;
    }
    $\est{p} \leftarrow \frac{1}{T+1} \left(1 + \sum_{t=1}^T \indic{\phi_t \leq \phi(y,\xi)}\right)$\;
    \Return $\est{p}$\;
\end{algorithm}

The goal then is to design the test statistic $\phi$ (Algorithm~\ref{algorithm:test}) such that $\est{p}$ will typically be small 
if $\wt{Y}$ is watermarked.
In particular, the goal is to identify an alignment cost $d : (\mc{V} \times \Xi)^* \to \R$, which measures the quality of a match between a subsequence of the input text and a subsequence of the watermark key, and use this to define $\phi$ as the minimum cost alignment between length $k$ subsequences of the text and key.

%even if $\wt{Y}$ is a corruption of $Y$ (e.g., by cropping, substituting or inserting/deleting tokens), the preserved tokens 
%will still match with the watermark key sequence.
%In the nonrobust case where $\wt{Y} = Y$, we can simply let $k = m$ (recall $m$ is the length of $Y$),
%in which case the value of the test statistic would be at most $d(Y,\xi_{1:m})$.\footnote{
%    The value of the statistic would be the minimum 
%    of $d(Y,\xi_{(j+1:j+m)\% \len{\xi}})$ over $j \in [\len{\xi}]$, which 
%    assuming $Y = \generate(\xi)$ will typically (but not always) obtain with the first $m$ elements of $\xi$.
%}
%In the general case, we use the alignment cost to find the closest matching subsequence of the watermark key $\xi$
%for each length $k$ substring of $\wt{Y}$.
%We ultimately return the cost of the best match among all blocks, 
%with the idea being that even if the user crops or otherwise corrupts $Y$,
This alignment-based detection strategy makes the watermark robust, since even if the user crops or otherwise corrupts $Y$, a single block of preserved watermarked text within
some larger body of unwatermarked text will suffice to trigger a low $p$-value from $\detect$.
The actual form of the alignment cost will be specific to each watermark---in particular, it will depend on the nature of 
the decoder $\decode$ in $\generate$.
Our most robust watermarks incorporate a soft notion of edit distance (i.e., Levenshtein distance) 
into the computation of the alignment cost via dynamic programming, 
with runtime scaling quadratically in the block size.
Thus, letting $m$ be the length of 
the input text $y$, $n$ be the length of the watermark key sequence $\xi$, and $k$ be the block size,
the cost of computing the test statistic is $O(m n k^2)$.

% \pl{I feel like this paragraph dives in too quickly to talk about all the
% implementation details (involving alignment and blocks, etc.);
% it would be better to start out with the big picture and build some intuition;
% we assume that $\tilde Y$ is $Y$ but with a bunch of insertions and deletions / crops (give people some intuition about how to think about it).;
% but the elements that are preserved are highly correlated with
% $\xi_i$, so we have to just find if these exist
% }
% \pl{also, I think it'd be simpler with a warmup to consider the case where there is no perturbation;
% then there is no alignment to be done and no block size; what should the test statistic be?
% then say that isn't robust, and that's why you need to do the alignment thing;
% whenever possible, I'd recommend building up in layers, starting with the core
% technical piece and then introducing complexity gradually
% }

\begin{algorithm}[h]
    \DontPrintSemicolon
    \SetKwInOut{Input}{Input}
    \SetKwInOut{Output}{Output}
    \SetKwInOut{Params}{Params}
    \SetKwInOut{Noise}{Noise}
    \caption{\label{algorithm:test}
        Test statistic ($\phi$)
        % \pl{would highly recommend that you give the types $\in \dots$ for each input and output variable}
        % \pl{use $\dots$ instead of $\dots$ everywhere}
        } %\thc{Took me a moment to realize $\min_j$ operated entrywise over rows of $\phi$ - might be cleaner if that min gets pulled inside the for loop rather than vectorizing it}}
    \Input{string $y \in \mc{V}^*$, watermark key sequence $\xi \in \Xi^n$}
    \Params{alignment cost $d$, block size $k$}
    \Output{test statistic value $\phi(y,\xi) \in \R$}
    \For{$i \in 1,\dots,\len{y}-k + 1$}{
        \For{$j \in 1,\dots,n$}{
            $y^i \leftarrow \{y_{i+\ell}\}_{\ell = 0}^{k-1}$,
            $\xi^j \leftarrow \{\xi_{(j+\ell) \% n}\}_{\ell=0}^{k-1}$\;
            $\est{d}_{i,j} \leftarrow d(y^i,\xi^j)$\;
        }
    }
    \Return $\min_{i,j} \est{d}_{i,j}$
\end{algorithm}
% \pl{I wouldn't use $\phi_{i,j}$ given the function is $\phi$ to avoid confusion}

To illustrate how the decoder and the alignment cost fit together, we give a simple example
for the toy setting of a binary vocabulary. \\

\begin{example}\label{example:binary}
    Consider a binary vocabulary $\mc{V} = \{0,1\}$.
      To generate $Y \in \{0,1\}^*$ from the model, 
      the LM provider shares
      $\{\xi_i\}_{i=1}^n \iid \txt{Unif}([0,1])$ with the detector
      and let $Y_i = 0$ if $\xi_i \leq p(0 \mid Y_{:i-1})$ and $Y_i = 1$ otherwise.
      In particular, defining the decoder $\decode$ 
      % \john{Maybe refer to the definition, remark that $\decode$ parameterizes the decoder? I had to go hunting to remind myself what $P$ is supposed to be.} 
      by
      \begin{align*}
          \decode(\xi_i,\mu) \defeq
              \begin{cases} 
                  0 & \xi_i \leq \mu(0) \\
                  1 & \xi_i > \mu(0),
              \end{cases}
      \end{align*}
      let $Y = \generate(\xi;m,p,\decode)$ for some $m \leq n$.
      Then $Y$ is a valid sample from the language model as 
      $\P(\xi_i \leq p(0 \mid Y_{:i-1})) = p(0 \mid Y_{:i-1})$,
      and crucially $Y$ and $\xi$ are correlated (i.e., if $\xi_i$ is sufficiently close to zero then $Y_i = 0$, 
      and likewise if $\xi_i$ is sufficiently close to one then $Y_i = 1$). %\thc{Many readers of this paper would probably appreciate spelling out the detector of the non-robust case (the distance below) and then really walk through the intuition (when y is zero, is xi small? when y is 1, is xi close to 1? if y and xi are uncorrealated, these two distances are going to be close to each other).}
      Thus, we can define the alignment cost $d(y,\xi) = \norm{y - \xi}_1$.

      Assuming for the sake of this example that $n = m$ and the user does not corrupt 
      the watermarked text from the LM provider, i.e., $\wt{Y} = Y$, the detector can run $\detect$
      to verify that $\wt{Y}$ is watermarked using the test statistic $\phi$ with alignment cost $d$ and
      block size $k = m$. The value of the test statistic will then be at most 
      the $\ell_1$ norm of $\wt{Y} - \xi$.
\end{example}

% \pl{need better transition / motivation: why are we talking about offsetting
% all of the sudden (beyond what are we offsetting? this needs to be explained
% more clearly)}
\subsection{Handling multiple queries}\label{sec:multi-query}
In the above example, the LM provider generates the same text each time from the watermark key sequence,
which is not ideal in practice.
One solution for avoiding reusing elements of the watermark key sequence across queries is to make $\generate$ stateful,
thus enabling the LM provider to generate a total of $\lfloor n/m \rfloor$ independent watermarked text samples of $m$ tokens each
from the language model.
Instead, to avoid persisting state, we provide a randomized 
wrapper $\shuffle$ (Algorithm~\ref{algorithm:shuffle}) around $\generate$ and
modify the watermarking protocol from the start of the section to allow the LM provider to call the $\shuffle$ 
instead of $\generate$ in the second step of the protocol.
The wrapper $\shuffle$ randomly shifts the watermark key sequence before passing the shifted sequence to $\generate$.
Shifting the watermark key sequence does not affect the value of the test statistic in $\detect$,
since to compute the test statistic the detector anyways searches over all subsequences of the watermark key sequence %\pl{this is not obvious - before we just said subsequence, not contiguous subsequence} 
to find the best match for each block of text.
There are $n$ possible shifts, each of which may produce a distinct text;
while in principle these $n$ texts will correlate with each other due to sharing elements of 
the watermark key sequence, in practice we find the effects of these correlations are not noticeable.
The so-called birthday paradox \cite{elfving1966selected} implies the LM provider can typically expect to call $\shuffle$ $\Omega(\sqrt{n})$ times,
each time producing a different text, before reusing the same offset twice.
In fact, the provider can expect call $\shuffle$ $\Omega(\sqrt{n/m})$ times before reusing a subsequence, in which case 
the constituent $\Omega(\sqrt{nm})$ tokens in these texts
will be indistinguishable from regular samples from the language model.

In general, we can bound the distortion (i.e., statistical distance from regular samples) of $\shuffle$ in the multi-query setting by 
the probability of reusing an element of the watermark key sequence.
Specifically, for $T$ queries and a maximum generation length of $m$ tokens per query,
we will achieve negligible, i.e., $o(1)$ distortion, so long as $n = \omega(mT^2)$.
Thus, similar to \citet{christ2023undetectable} we can achieve approximate distortion-freeness in the multi-query setting.
However, unlike \citet{christ2023undetectable}, to achieve approximate distortion-freeness in this setting the computational cost of our watermark detection procedure must 
grow with the target number of queries.
In principle, this trade-off between the degree of distortion and the runtime of watermark detection means at least in an asymptotic sense that the latter
effectively upper bounds the number of queries to the LM provider an attacker would require to learn information about the watermark key sequence.
In practice, we expect the cost per token of queries to the LM provider will be significant enough to make such attacks expensive to implement.
% The method $\shuffle$ is effectively a wrapper around $\generate$ that randomly shifts the watermark key sequence before 
% passing the shifted sequence to $\generate$.

% Thus, the LM provider can call $\shuffle$ (Algorithm~\ref{algorithm:shuffle}) 
% instead of $\generate$ without impacting the 
% performance of the detector.
% The so-called Birthday paradox \cite{elfving1966selected} implies the LM provider can typically expect to call $\shuffle$ on the order of ${\mathtt{len}(\xi)}^{1/2}$ times,
% each time generating a different text, before reusing the same offset twice.
% \pl{this is not right; it's not just using the same offset twice, but the key sequences can't overlap
% to guarantee independence;
% I think we should be absolutely clear about what we're guaranteeing:
% (i) we can get exactly $n$ distinct generations, but they will be correlated (in practice, this is not noticable - did we check this?);
% (ii) we can get $\lfloor n/m \rfloor$ independent generations if we make the key sequences not overlap;
% this is important to state properly
% }
% \pl{definitely move to later after the basic case has been fully defined (generate and detect);
% otherwise, really hard to make sense of this}

% \pl{this paragraph is pretty cryptic - need to motivate with the fact
% that under the current scheme, you'd get the same generation deterministically;
% so we need to randomize\dots}

\begin{algorithm}[h]
    \DontPrintSemicolon
    \SetKwInOut{Input}{Input}
    \SetKwInOut{Output}{Output}
    \SetKwInOut{Params}{Params}
    \SetKwInOut{Noise}{Noise}
    \caption{\label{algorithm:shuffle}
        Randomized watermarked text generation ($\shuffle$)}
    \Input{watermark key sequence $\xi \in \Xi^n$}
    \Params{generation length $m$, language model $p$, decoder $\decode$}
    \Output{string $y \in \mc{V}^m$}
    $\tau \sim \txt{Unif}([n])$,
    $\xi' \leftarrow \{\xi_{(i+\tau)\% n}\}_{i=1}^{m}$\;
    \Return $\generate(\xi';m,p,\decode)$\;
\end{algorithm}

% \footnote{
%     As the language model $p$ is arbitrary and we assume unknown to the detector, 
% this simplification is without loss of generality: $p$ itself may model the distribution of 
% text from some base model given an arbitrary prompt.
% }

% \john{The test needs more exposition, maybe a whole subsection. Handwaving the test with a comment about exchangeability is not enough. Many readers (including the engineers who we want to implement our watermark) won't even be familiar with the concept of exchangeability.} \\

% \pl{create paragraph heading for example}
% \pl{I still strongly suggest having a concrete example with actual numbers in a figure}
% \pl{this example reminds me that it would be good later to motivate
% that using the uniform variables is fine if you know $p$,
% but the random permutation is there to handle the case where you don't know it}

% \john{I like this example. Consider giving some eye-catching formatting. E.g. ``\textbf{Example:}''}  

% \pl{I think $i \in [n]$ is overused, for a for loop, more natural to write $i = 1, \dots, m$}

% \pl{you're using $\phi$ as a function in Algorithm 2, so don't overload it here}
% \pl{in general, define the types of variables more}

% \pl{need to provide more intuition for Algorithm 4 - say that we're
% trying to find any block of $k$ that roughly resembles some part of the watermark key sequence
% }

% \pl{why median? please justify}

% \thc{This comes out of nowhere - i think our treatment of shift is kind of unfortunate - its like an unloved child that you mention in passing. It's also not quite clear what shift is exactly -- is it still distortion free? is it a heuristic? i think we should put together a better high level narrative for shift}

\subsection{Terminology: watermark strategies and watermark potential}
Henceforth, we use the term \emph{watermarking strategy} to refer to a concrete instantiation of the 
$\shuffle$, $\generate$ and $\detect$ methods by specifying 
the internal parameters of both algorithms (i.e., the decoder $\decode$, the test statistic $\phi$ and the watermark key sequence distribution $\nu$).
We give concrete watermarking strategies in the following sections (Sections~\ref{sec:watermark} and \ref{sec:gumbel}).
For each watermarking strategy, we show two main results: we prove the decoder is distortion-free and also 
obtain high probability upper bounds on the $p$-values of watermarked text---as a function of the length 
of the text and the watermark key sequence.
We emphasize that only the former result (i.e., that the decoder is distortion-free) is critical 
to the validity of our main claims; we intend the latter collection of results 
to provide intuition for when we would expect the detector to have sufficient power and to anticipate the 
forthcoming experimental results in Section~\ref{sec:experiments}.
The strength of the $p$-value upper bounds will depend on the observed token probabilities of (watermarked) text,
through a quantity which we evocatively term the \textit{watermark potential}. 

\begin{definition}\label{defn:water-ent}
    (watermark potential) Define $\alpha : \mc{V}^* \to \R$ by 
    \begin{align*}
        \alpha(y) \defeq 1 - \frac{1}{\len{y}} \sum_{i = 1}^{\len{y}} p(y_i \mid y_{:i-1}).
    \end{align*}
    % $\alpha(y) \defeq 1 - \frac{1}{\len{y}} \sum_{i \in 1}^{\len{y}} P_f(y_i \mid y_{:i-1})$.
\end{definition}

The watermark potential of text from a deterministic language model will always be zero,
whereas for a high-entropy model it will approach one.
The degree to which it is possible for the detector to reliably distinguish watermarked text from unwatermarked 
text necessarily depends on the watermark potential of the LM provider's language model.
For example, if the language model is deterministic, then any distortion-free watermark will necessarily have zero statistical power.
We formalize this intuition by establishing the following general lower bound on the detection accuracy of any watermarking strategy
as a function of the watermark potential of the original language model.
In particular, we lower bound the error of any classifier $h : \mc{V}^* \times \Xi^* \to \{-1,+1\}$ 
that tries to distinguish watermarked (positive label) versus nonwatermarked text (negative label)
given some watermark key $\xi$ (we make no assumption on the distribution of $\xi$ except that it is independent 
of unwatermarked text by definition).
We defer the proof of Lemma~\ref{lemma:lower-bound-all} to Appendix~\ref{app:lb}.

\begin{lemma}\label{lemma:lower-bound-all}
%   \pl{define $Y$ to make this more self-contained}
    Let $Y_i' \sim p(\cdot \mid Y_{:i-1}')$ for $i \in [m]$.
    Let $Y \stackrel{d}{=} Y'$ and let $\xi \in \Xi^*$ be a random variable that is 
    independent of $Y'$. Let $h : \mc{V}^* \times \Xi^* \to \{-1,+1\}$ be a classifier.
    Let $c > 0$ and define the set $\mc{V}_c \subset \mc{V}^m$ by 
    \begin{align*}
        \mc{V}_c \defeq \{y : p(y_i \mid y_{:i-1}) \geq \exp(-c/2) \ \txt{for all} \ i \in [m]\}.
    \end{align*}
    Then
    \begin{align*}
        \P(h(Y,\xi) = -1) + \P(h(Y',\xi) = 1) \geq \Ep \left[\exp\left(-c m \alpha(Y)\right)\indic{Y \in \mc{V}_c}\right].
    \end{align*}
\end{lemma}
% \pl{should put the indicator symbol '1' in a different font}

Lemma~\ref{lemma:lower-bound-all} implies it is impossible to test between 
any watermarked and non-watermarked text (i.e., between $Y$ versus $Y'$) that are 
equal in distribution (i.e., distortion-free) if the text typically has low watermark potential,  
irrespective of the design of the watermark key;
in particular, the sum of the 
Type I and II (resp., false positive/negative) error rates of $h$ will be close to one if the watermark potential is close to zero.
The theorem is not tight: depending on the language model, its result may be vacuous for small 
values of $c$ 
(e.g., the constants which appear in our upper bounds) since only texts 
whose token likelihoods all exceed $\exp(-c/2)$ contribute to the lower bound.
Also our upper bounds scale inverse exponentially with the square of 
the watermark potential, which will always be smaller 
than the watermark potential itself since the watermark potential is bounded between 
zero and one.

% \pl{comment: hard to follow;
% again, I'd start by providing the intuition, setting up the elements (like the role of the classifier $h$)
% and then providing the formal statement;
% right now, it's flipped and there's a lot of random stuff that appears - like when $h$ is introduced (should be introduced in text first)
% }

The point of the forthcoming $p$-value upper bounds for the watermarking strategies in Sections~\ref{sec:watermark} and \ref{sec:gumbel} 
is to establish the existence of test statistics for each watermark such that
the statistical power of the watermark improves exponentially with the length of the text and decays at most 
linearly with the length of the watermark key sequence.
The test statistics we use to prove these upper bounds differ slightly from those we employ in our experiments: 
in the former case, we prioritize the simplicity of stating the bounds in terms of watermark potential, 
whereas in the latter case, we prioritize empirical performance. %\thc{The part below this feels weasely and apologetic - we should push on this more and say that while we make changes for computational efficiency, what we implement is quite similar to the bounds, and so we expect the high-level results to remain similar}
% We clarify the exact versions of the watermarking strategies we use in our subsequent experiments.

% \pl{I feel like more important than this caveat is the last sentence:
% what kind of results do we want; I'd lead with that, and then talk about
% the fact that we prove something about a different test statistic;
% but the two are close-ish, so we want to emphasize that;
% ``existence of test statistics'' feels too weak
% }

\subsection{Watermarking via inverse transform sampling}\label{sec:watermark}
Inverse transform sampling is a general technique for sampling from a univariate distribution 
by taking the pushforward of a uniform
random variable through its inverse cumulative distribution function (CDF).
Crucially, the technique is valid irrespective of the ordering of the CDF, a property which we presently leverage 
to construct a watermarking strategy in which $\generate$ is distortion-free and also $\detect$ is agnostic.
In particular, we implement $\generate$ with a decoder that maps a sequence of uniform random variables and permutations to 
tokens using inverse transform sampling.
To detect watermarked text, the detector correlates the sequence of permuted indices of the tokens in the text
with the sequence of uniform random variables to detect watermarked text.
Meanwhile, for any nonwatermarked text, the sequence of permuted token indices will be i.i.d. uniform irrespective of the 
text itself and thus not correlate with the sequence of uniform random variables.
% \pl{motivate why you need permutations since ITS has nothing to do with permutations;
% in particular, say you don't need it, but we want to assume the detector doesn't know $\mu$}
% We use inverse transform sampling to extend the watermark from our toy example in the previous section to vocabularies 
% of arbitrary size. \thc{I think narratively this is maybe not the right top level setup, since the example has happened so long ago. Something better might be to motivate this section and the next by saying that you're going to now instantiate both the generator and the test statistic, and then say - the first method extends the earlier example and uses ITS, the second one uses gumbel}

Formally, with $\Pi$ as the space of permutations over the vocabulary $[N]$,
% \pl{we include a random permutation in each element of the watermark key sequence;
% define things a bit more slowly
% }
for $\xi = (u,\pi) \in [0,1] \times \Pi =: \Xi$ and any distribution $\mu \in \Delta([N])$, define the decoder by
% \pl{=: looks ugly; don't do it}
% \pl{I'd use $\mu$ instead of $P$}
\begin{align}
  \decode(\xi,\mu ) \defeq \pi^{-1}\left(\min \left\{\pi(i) : 
    \mu(\{j:\pi(j)\leq\pi(i)\}) \geq u\right\}\right), \label{eqn:rho-defn}
\end{align}
i.e., $\decode(\xi,\mu)$ is the token with the smallest index in the permutation $\pi$ such that 
CDF of $\mu$ with respect to $\pi$ is at least $u$.
Generalizing the intuition from Example~\ref{example:binary}, we show 
this decoder is distortion-free in the following theorem.
% $\generate(\xi;m,p,\decode)$ is a valid sample from the language model 
% $p$ for $\xi \sim \txt{Unif}(\Xi^n) =: \nu$.
% \pl{define distortion-free up above and just say $\decode$ is distortion-free here}
% \begin{theorem}\label{thm:stealth}
%     Let $m,n \in \N$ with $n \geq m$. Define $\decode$ by equation~\eqref{eqn:rho-defn}.
%     Let $U_i \iid \txt{Unif}([0,1])$ and $\pi_i \in \Pi$ for $i \in [n]$, with 
%     $\xi \defeq \{(U_i,\pi_i)\}_{i=1}^n$.
%     Let $Y_i' \sim p(\cdot \mid Y_{:i-1}')$ for $i \in [m]$ and let $Y = \generate(\xi;m,p,\decode)$. 
%     Then $Y \stackrel{d}{=} Y'$.
% \end{theorem}
\begin{theorem}\label{thm:stealth}
    Define $\decode$ by equation~\eqref{eqn:rho-defn}.
    Let $\pi \in \Pi$ be arbitrary and let
    $U \sim \txt{Unif}([0,1])$, with 
    $\xi \defeq (U,\pi)$.
    Then $\decode$ is distortion-free with respect to $\xi$.
\end{theorem}
\begin{proof}
    Recalling Definition~\ref{defn:distortion-free}, the result follows from showing for any $\mu \in \Delta([N])$
    and $y \in [N]$ that $\P(\decode(\mu,\xi) = y) = \mu(y)$.
    To this end, by equation~\eqref{eqn:rho-defn},
    we have $\decode(\mu,\xi) = y$ 
    if and only if $U$ lies in the interval
    \begin{align*}
        \left[\mu(\{y':\pi(y')<\pi(y)\}),\mu(\{y':\pi(y')\leq\pi(y)\})\right).
    \end{align*}
    % \pl{technically upper bound should be open ')'}
    As the width of this interval is exactly $\mu(y)$, the result follows immediately.
\end{proof}

Having shown that the decoder is distortion-free, we now proceed to analyze the detectability of the watermark.
For convenience, define the normalization $\eta : [N] \to [0,1]$ by 
$\eta(i) \defeq (i-1)/(N-1)$.
% \pl{want to just say that expectation is 1/2?}
Analogous to the toy example, the sequences $\{\eta(\pi_i(Y_i))\}_{i=1}^m$ and $U$ are correlated.
Thus, for the sake of analysis, we define alignment cost $d : (\mc{V} \times \Xi)^* \to \R$ by
\begin{align}
    d(y,(u,\pi)) \defeq -\sum_{i=1}^{\len{y}} (u_i - 1/2) \cdot (\eta(\pi_i(y_i)) - 1/2) \label{eqn:d-defn},
\end{align}
i.e., the negative covariance (each $U_i$ and $\eta(\pi_i(Y_i))$ both have expectation $1/2$).

% \pl{need to have a sharper division between the algorithm definition (which really is important and shouldn't be missed)
% and the subsequent analysis; and noting that the theory is not critical for validity}

We exactly characterize in Lemma~\ref{lemma:sound-transform} the difference in the expected value of our alignment cost 
on some text assuming the text is watermarked (i.e., generated using the same key as the detector)
versus not watermarked in terms of the watermark potential of the text (Definition~\ref{defn:water-ent}).
To state the result, we define the constant 
$C_0 \defeq \txt{Var}(\eta(\txt{Unif}([N])))$, where we abuse notation slightly 
to temporarily treat $\eta$ as a pushforward map over distributions.\footnote{
    Note that $C_0 = \txt{Var}(\txt{Unif}([0,1])) + o_N(1) = 1/12 + o_N(1)$.
}
We defer the proof of Lemma~\ref{lemma:sound-transform} to Appendix~\ref{app:transform}.

% \john{Some inconsistencies throughout the section about when we use $i$ and $n$ versus $t$ and $T$.}
% \rck{where?}
\begin{lemma}\label{lemma:sound-transform}
    Let $m,n \in \N$ with $n \geq m$, where $m$ is the generation length and $n$ is the watermark key length. 
    Define the decoder $\decode$ by equation~\eqref{eqn:rho-defn} 
    and the alignment cost $d$ by equation~\eqref{eqn:d-defn}.
    Let $\xi,\xi' \iid \txt{Unif}(\Xi^n)$ with $Y = \generate(\xi;m,p,\decode)$.
    % Let $C_0$ be a sufficiently small constant. 
    Then almost surely for all $i \in [m]$ and $j \in [n]$ we have
    \begin{align*}
        \Ep[d(Y_i,\xi_j') - d(Y_i,\xi_i) \mid Y] = C_0 \cdot (1 - p(Y_i \mid Y_{:i-1})) = C_0 \alpha(Y_{i-1:i}).
    \end{align*}
\end{lemma}
% \pl{provide more intuition; this is assuming the alignment is perfect,
% what each token buys you in bumping up that difference}

% \pl{why do you define $d$ as the negative covariance and then have to negate again?}\rck{where do we negate again?}

% We again emphasize the role of the random permutations in ensuring the watermark is detectable 
% without knowing the language model distribution: the permuted token identities from any non-watermarked text
% will be i.i.d. uniform over $[N]$ irrespective of the text itself.
Summing the result of Lemma~\ref{lemma:sound-transform} over $i \in [m]$ implies
for any $j \in [n]$ that
\begin{align*}
    \Ep[d(Y,\xi_{(j+1:j+m)\% n}') - d(Y,\xi_{1:m}) \mid Y] = C_0 m \alpha(Y).
\end{align*}
Thus,
we can upper bound the $p$-value output by $\detect$ in Lemma~\ref{lemma:perm-test} 
using a standard concentration argument and taking a union bound over $j \in [n]$.
We defer the proof of Lemma~\ref{lemma:perm-test} to Appendix~\ref{app:transform}.
In fact, we actually prove a more general result for $k \leq m$ wherein we allow $\wt{Y}$ to be
a subsequence of $Y$ which the user may choose adaptively.
We defer this more general result to Appendix~\ref{app:transform} as it is more cumbersome to state.

% \rck{define $c_0$, update statement with new notation}
\begin{lemma}\label{lemma:perm-test}
    % \pl{why not just use $k$ directly instead of $m$?}
    % \pl{be more explicit in defining what $m$ and $n$ are}
    Let $m,n \in \N$ with $n \geq m$, where $m$ is the generation length and $n$ is the watermark key length. 
    Define the decoder $\decode$ by equation~\eqref{eqn:rho-defn}, alignment cost $d$ by equation~\eqref{eqn:d-defn},
    and $\phi$ by Algorithm~\ref{algorithm:test} with block size $k = m$.
    Let $\xi,\xi' \iid \txt{Unif}(\Xi^n)$ with $Y = \generate(\xi;n,p,\decode)$ and
    $\wt{Y} = Y$.
    % be a length $m$ substring of $Y$ that is conditionally independent of 
    % $\xi$ and $\xi'$ given $Y$.
    % Let $C_0$ be a sufficiently small numerical constant. 
    Then almost surely
    \begin{align*}
        \P(\phi(\wt{Y},\xi') \leq \phi(\wt{Y},\xi) \mid \wt{Y}) \leq 2n\exp(-k C_0^2 \alpha(\wt{Y})^2/2).
    \end{align*}
\end{lemma}
% \pl{wait, are $\xi$ and $\xi'$ flipped?  we would expect $\phi$ for the watermarked version to be smaller;
% so it's the probability of the complement that should vanish?}
Lemma~\ref{lemma:perm-test} implies that with high probability the value of the test statistic on watermarked text with the correct key 
will be lower than with a resampled key.
In particular, ignoring discretization errors due to the finite number of resamples $T$ in $\detect$, 
the lemma implies watermarked samples with watermark potential bounded 
away from zero (i.e., if the language model is not effectively deterministic) 
will have exponentially small expected $p$-values with respect to the length $m$ of the text.
% \pl{it's not clear that $m$ should be the length of the text because it's a substring of $Y$, and $Y$ we've thought about as the text}
The bound grows only linearly with the length $n$ of the random number sequence,
implying for moderately large $m$ (e.g., $m = 50$) an LM provider can generate plenty of distortion-free watermarked text
(i.e., $n = 2^{\Omega(m)}$ total tokens) while still enabling detection of the watermark from snippets of $m$ tokens (e.g.,
$50$ tokens typically amount to a couple sentences of text).
Of course, recall the computational complexity of detection scales linearly with $n$, 
which in practice may be a more relevant limitation than the statistical power of the watermark.\footnote{
    Note that both $\detect$ and the test statistic (Algorithm~\ref{algorithm:test}) are easily parallelizeable.
}
% Of course, in practice we may only observe a corruption of the original watermarked text (e.g.,
% a student might paraphrase parts of a plagiarized essay to avoid detection).
% \pl{would be useful to plug in some numbers motivated by practice to get a sense of how the bound evaluates,
% $m=1000$}

\subsubsection{Robustness to substitutions, insertions and deletions}
We show in Lemma~\ref{lemma:perm-test-subs} an analogous result to Lemma~\ref{lemma:perm-test} holds 
even if an adversary corrupts the original watermarked text by substituting tokens.
To state the lemma, we introduce a quantity $\wt{\alpha}$ which depends on both the corrupted and original watermarked text and 
accounts for the decrease in the expected value of 
the test statistic (which recall for the original text is equal up to a numerical constant to the watermark potential of the text)
due to token substitutions.
We defer the proof of Lemma~\ref{lemma:perm-test-subs} to Appendix~\ref{app:transform}.

% \pl{more intuition - why is $\tilde\alpha$ defined the way it is?}

\begin{lemma}\label{lemma:perm-test-subs}
    Let $m,n \in \N$ with $n \geq m$, where $m$ is the generation length and $n$ is the watermark key length.
    Define the decoder $\decode$ by equation~\eqref{eqn:rho-defn}, alignment cost $d$ by equation~\eqref{eqn:d-defn},
    and $\phi$ by Algorithm~\ref{algorithm:test} with $k = m$.
    Let $\xi,\xi' \iid \txt{Unif}(\Xi^n)$ with $Y = \generate(\xi;m,p,\decode)$
    and let $\wt{Y} \in \mc{V}^m$ be conditionally independent 
    of $\xi$ and $\xi'$ given $Y$. Define 
    \begin{align*}
        \wt{\alpha}(y,\wt{y}) \defeq \frac{1}{\len{y}} \sum_{i=1}^{\len{y}} \indic{y_i = \wt{y}_i} \left(1 - p(y_i \mid y_{:i-1}) \right) - \indic{y_i \neq \wt{y}_i} \frac{1}{N-1}.
    \end{align*}
    % Let $C_0$ be a sufficiently small numerical constant. 
    Then almost surely
    \begin{align*}
        \P(\phi(\wt{Y},\xi') \leq \phi(\wt{Y},\xi) \mid Y,\wt{Y}) \leq 2n\exp(-k C_0^2 \wt{\alpha}(Y,\wt{Y})^2/2).
    \end{align*}
\end{lemma}

Lemma~\ref{lemma:perm-test-subs} implies that even if an adversary replaces the vast 
majority of tokens in a watermarked text, detection with low $p$-values will still be possible 
so long as the remaining tokens have watermark potential bounded away from zero.
In particular, the permuted indices of the original tokens will still positively correlate with 
the corresponding uniform random variables from the watermark key sequence, while those of the substituted tokens 
will exhibit a small negative correlation scaling as $O(1/N)$.

To handle insertions and deletions, we can robustify our test statistic by incorporating
a soft notion of edit distance into our original alignment cost.
The parameter $\gamma$ in Definition~\ref{defn:levenshtein} assigns a cost to 
each insertion and deletion operation when aligning the tokens $y$ with the sequence $\xi$,
while the base alignment cost $d_0$ defines the quality of the alignment via a cost
function over substitutions.
In practice, we drop the minimizations over $y' \in \mc{V}$ and $\xi' \in \Xi$ in the second and third cases respectively 
of the definition;
we include them here to make our subsequent theoretical analysis cleaner.
\begin{definition}\label{defn:levenshtein}
    (Levenshtein cost) Let $\gamma \in \R$ and $d_0 : \mc{V} \times \Xi \to \R$.
    % \pl{wait, you're overloading $d$ here? this is not alignment cost, right? define to be something else}
    For $y \in \mc{V}^*$ and $\xi \in \Xi^*$, define the \textit{Levenshtein cost} $d_\gamma : \mc{V}^* \times \Xi^* \to \R$ by 
    % \john{I am confused: what are $y_i,\xi_i,y',\xi'$?}
    \begin{align*}
        d_\gamma(y,\xi) \defeq \min
        \begin{cases} 
            d_\gamma(y_{2:},\xi_{2:}) + d_0(y_1,\xi_1)  \\
            d_\gamma(y,\xi_{2:}) + \min_{y' \in \mc{V}}d_0(y',\xi_1) + \gamma \\
            d_\gamma(y_{2:},\xi) + \min_{\xi' \in \Xi}d_0(y_1,\xi') + \gamma,
        \end{cases}
    \end{align*}
    with $d_\gamma(y,(u,\pi)) \defeq \gamma \cdot \len{y}$ if $\xi$ is empty and vice versa (as base cases).\footnote{
        For $y \in \mc{V}^*$ (resp., $\xi \in \Xi^*$), we let $y_{\len{y}+1:}$ (resp., $\xi_{\len{\xi}+1}$)
        denote the empty string/sequence.
    }
\end{definition}

Redefining the test statistic $\phi$ using $d_\gamma$ as the alignment cost---using $d_0$ from equation~\eqref{eqn:d-defn}---ensures 
$\detect$ is robust not only to substituting tokens, 
but also inserting and deleting tokens from watermarked text,
as we show in Lemma~\ref{lemma:perm-test-indel}.
We defer the proof of Lemma~\ref{lemma:perm-test-indel} to Appendix~\ref{app:transform}.
To state the lemma, we first recursively define a notion of edit distance between two strings.
The definition is equivalent to the minimum number of insertion and/or deletion operations 
needed to transform one string into the other (see Lemma~\ref{obs:edit-dist-basic}).

% \john{How does this definition relate to the definition of $d_\gamma$? Oh is this Hamming distance? I am pretty confused\dots Needs more exposition.}
\begin{definition}\label{defn:edit-dist}
    (edit distance)
    For $y,\wt{y} \in \mc{V}^*$, define the \textit{edit distance} by 
    \begin{align*}
        d_\txt{edit}(y,\wt{y}) \defeq
        \begin{cases} 
            d_\txt{edit}(y_{2:},\wt{y}_{2:}) & y_1 = \wt{y}_1 \\
            1 + \min \{d_\txt{edit}(y_{2:},\wt{y}),d_\txt{edit}(y,\wt{y}_{2:})\} & y_1 \neq \wt{y}_1,
        \end{cases}
    \end{align*}
    with $d_\txt{edit}(y,\wt{y}) = \len{y}$ if $\wt{y}$ is empty and vice versa.
\end{definition}

% \begin{lemma}
%     $d_\txt{edit}$ is symmetric
% \end{lemma}
% \begin{proof}
%     For $x,x' \in \mc{V}^*$, by definition $d_\text{edit}(x,x')$ is equal to the minimum number 
%     of insertions and/or deletions required to obtain $x'$ from $x$.
%     The claim follows from the fact that both insertions and deletions are reversible (respectively, by a single 
%     deletion and insertion).
% \end{proof}

% \rck{TODO: fix bound}
\begin{lemma}\label{lemma:perm-test-indel}
    Let $n,m \in \N$ with $n \geq m$, where $m$ is the generation length and $n$ is the watermark key length.
    Define the decoder $\decode$ by equation~\eqref{eqn:rho-defn},
    alignment cost $d = d_\gamma$ with $d_0$ from equation~\eqref{eqn:d-defn} and $\gamma > 1/2$,
    and $\phi$ by Algorithm~\ref{algorithm:test} using block size $k \leq m$ that divides evenly into $m$.
    Let $\xi,\xi' \iid \txt{Unif}(\Xi^n)$ with $Y = \generate(\xi;m,p,\decode)$.
    Let $\wt{Y} \in \mc{V}^m$ be conditionally independent 
    of $\xi$ and $\xi'$ given $Y$, with $d_\txt{edit}(Y,\wt{Y}) \leq \eps m$.
    % Let $C_0$ be a sufficiently small numerical constant. 
    Then almost surely
    \begin{align*}
        \P(\phi(\wt{Y},\xi') \leq \phi(\wt{Y},\xi) \mid \wt{Y},Y) \leq m n(2k)^{k/(4\gamma-1)}\exp(-k C_0^2 (\alpha(Y) - \gamma\eps)_+^2/2).
    \end{align*}
\end{lemma}
% In practice, to reduce overhead, we modify $\generate$ to only use a single 
% random permutation, i.e., $\pi_i = \pi$ for all $i \in [n]$, with $\pi \sim \txt{Unif}(\Pi)$.
% We also find that letting the alignment cost be the $\ell_1$ distance, i.e.,
% Once again, we assume $n = m$ \pl{remind what these are} solely to simplify the presentation of the result.
% In fact, we can compose the results of Lemmas~\ref{lemma:perm-test}, \ref{lemma:perm-test-subs}
% and \ref{lemma:perm-test-indel} together to show we can detect cropped snippets of watermarked text 
% even after some amount of corruption via adversarially substituting, inserting and/or deleting tokens.

We prove the result by showing there must exist a length $k$ substring of the corrupted text $\wt{Y}$ 
within edit distance $k \eps$ of a substring of $Y$ that the detector will be able to distinguish as watermarked.
For fixed $k$, the set of strings within edit distance $\eps k$ of an original block
watermarked text blows up combinatorially with $\eps$.
To ensure we can detect the watermark, the result implies we must set $\gamma = \Omega(1/\eps)$,
which means our bound on the expected $p$-value is vacuous as soon as $\eps = \Omega(1/\log k)$.
Admittedly, our analysis is not tight; for example, as a preview of the experimental results to come, 
in practice we find smaller values of $\gamma$ (i.e., $\gamma < 1$) to perform 
significantly better.
However, one takeaway from the result is that using a block size $k < m$,
where here $m$ is the length of the input text, for detection can be an effective strategy
when the user has substantially corrupted the text.
The assumption that $k$ divides evenly into $m$ is an artifact of our analysis and not important in practice.
% \john{Sounds bad. Can we say anything to reassure people?}
% \rck{experiments seem more optimistic? I think it's fine to just not reassure---most people will care more about 
% what experiments say re: insertions/deletions. I added comment in the experiments section how the results are better than 
% the theory implies}

\subsubsection{What we run in practice}

% \pl{important to state that no matter what test statistic we run, the p-values that we get out are valid/exact;
% probably want to emphasize this point several times in the paper
% }

In practice, to reduce overhead in both $\generate$ and $\detect$, 
we use a single random permutation\footnote{
    In principle, with a single random permutation the permuted token indices of both watermarked and nonwatermarked text 
    are no longer conditionally independent of each other, and so the results of Lemmas~\ref{lemma:perm-test},
    \ref{lemma:perm-test-subs} and \ref{lemma:perm-test-indel} no longer apply.
    However, in practice we observe no degradation in statistical power. Also, irrespective of the lemmas,
    the $p$-values from $\detect$ are still valid by construction.
}
instead of a full sequence, i.e., we let
$\pi_i = \pi$ for all $i \in [n]$ for $\pi \sim \txt{Unif}(\pi)$. %\thc{a bit of a context switch since we have mostly been talking about detect - maybe add something about -- when implementing generate, we use .. }.
Recall Theorem~\ref{thm:stealth} makes no assumption about the distribution of the permutations;
thus, the watermark is still distortion-free.
Also, for the test statistic, we find using
\begin{align}
    d(y,(u,\pi)) \defeq \sum_{i=1}^{\len{y}} |u_i -  \eta(\pi_i(y_i))| \label{eqn:d-practice}
\end{align}
as the alignment cost performs better empirically than the alignment cost in equation~\eqref{eqn:d-defn}.
To reiterate, the output of $\detect$ is a valid $p$-value irrespective of the test statistic we use.

Henceforth, we refer to this version of the watermarking strategy as {\its},
and we refer to the corresponding Levenshtein version as {\itsedit}, wherein we define 
the base alignment cost $d_0$ by equation~\eqref{eqn:d-practice}
and use the following simplified notion of Levenshtein cost:

\begin{definition}\label{defn:levenshtein-simple}
    (simple Levenshtein cost) Let $\gamma \in \R$ and $d_0 : \mc{V} \times \Xi \to \R$.
    % \pl{wait, you're overloading $d$ here? this is not alignment cost, right? define to be something else}
    For $y \in \mc{V}^*$ and $\xi \in \Xi^*$, define the alignment cost function $d_\gamma : \mc{V}^* \times \Xi^* \to \R$ by 
    % \john{I am confused: what are $y_i,\xi_i,y',\xi'$?}
    \begin{align*}
        d_\gamma(y,\xi) \defeq \min
        \begin{cases} 
            d_\gamma(y_{2:},\xi_{2:}) + d_0(y_1,\xi_1)  \\
            d_\gamma(y,\xi_{2:}) + \gamma \\
            d_\gamma(y_{2:},\xi) + \gamma,
        \end{cases}
    \end{align*}
    with $d_\gamma(y,(u,\pi)) \defeq \gamma \cdot \len{y}$ if $\xi$ is empty and vice versa (as base cases).\footnote{
        For $y \in \mc{V}^*$ (resp., $\xi \in \Xi^*$), we let $y_{\len{y}+1:}$ (resp., $\xi_{\len{\xi}+1}$)
        denote the empty string/sequence.
    }
\end{definition}
In summary, for {\its} we use the decoder from equation~\eqref{eqn:rho-defn}, the test statistic 
from Algorithm~\ref{algorithm:test} with the alignment cost from equation~\eqref{eqn:d-practice}, and the watermark 
key distribution as the uniform distribution over $[0,1]^n \times \Pi$, where recall $n$ is the length of 
the watermark key sequence.
Meanwhile, {\itsedit} differs from {\its} only in that we define the test statistic using the Levenshtein cost from 
Definition~\ref{defn:levenshtein-simple} with the base cost again from equation~\eqref{eqn:d-practice}.

\subsection{Watermarking via exponential minimum sampling}\label{sec:gumbel}
\citet{aaronson2023openai} proposes mapping variables in $[0,1]^N$
to tokens in the vocabulary $[N]$ using exponential minimum sampling
to generate watermarked text.
Whereas \citet{aaronson2023openai} proposes the use of distortion-inducing hashes much like \citet{kirchenbauer2023watermark},
we use exponential minimum sampling to implement the decoder in $\generate$, which (after defining a suitable corresponding 
test statistic) enables an alternative distortion-free and robust watermarking strategy to inverse transform sampling.
In particular, for $\xi \in [0,1]^N =: \Xi$ and $\mu \in \Delta([N])$, define the decoder by
\begin{align}\label{eqn:rho-defn-gumbel}
    \decode(\xi,\mu) \defeq \argmin_{i \in [N]} \ -\log (\xi_i)/\mu(i).
\end{align}
We show this decoder is distortion-free in Theorem~\ref{thm:stealth-gumbel},
whose proof we defer to Appendix~\ref{app:gumbel}.
\begin{theorem}\label{thm:stealth-gumbel}
    Define the decoder $\decode$ by equation~\eqref{eqn:rho-defn-gumbel} and
    let $\xi \sim \txt{Unif}([0,1]^N)$.
    Then $\decode$ is distortion-free with respect to $\xi$.
\end{theorem}

For the sake of analysis, we define the alignment cost 
as a slight variation of the proposal of \citet{aaronson2023openai} (see Section~\ref{sec:gumbel-practice}) by
\begin{align}
    d(y,\xi) \defeq -\sum_{i=1}^{\len{y}} \log \xi_{i,y_i}, \label{eqn:d-defn-gumbel}
\end{align}
again defining the test statistic $\phi$ by Algorithm~\ref{algorithm:test}.
Similar to Lemma~\ref{lemma:sound-transform} for ITS, we exactly characterize 
the difference in the expected values of the alignment cost on watermarked versus non-watermarked
text in terms of the watermark potential of the text.
We defer the proof of Lemma~\ref{lemma:sound-gumbel} to Appendix~\ref{app:gumbel}.

\begin{lemma}\label{lemma:sound-gumbel}
    Let $n \in \N$. Define $\decode$ by equation~\eqref{eqn:rho-defn-gumbel} 
    and $d$ by equation~\eqref{eqn:d-defn-gumbel}.
    Let $\xi,\xi' \iid \txt{Unif}(\Xi^n)$ with $Y = \generate(\xi;n,p,\decode)$.
    Then almost surely for all $i \in [n]$ we have
    \begin{align*}
        \Ep[d(Y_i,\xi_i') - d(Y_i,\xi_i) \mid Y] = 1 - p(Y_i \mid Y_{:i-1}) = \alpha(Y_{i-1:i}). %1 - p(Y_i \mid Y_{:i-1}).
    \end{align*}
  \end{lemma}
%   \thc{is it clear that i should actually care about this expected difference? when you are testing you're looking at quantiles and not mean differences right?}
%   \pl{compare with ITS bound - get rid of $C_0 \approxeq 1/12$, which is pretty good}
%   \pl{intuitively, why is it better?}

Summing the result of Lemma~\ref{lemma:sound-gumbel} over $i \in [m]$ implies
for any $j \in [n]$ that
\begin{align*}
    \Ep[d(Y,\xi_{(j+1:j+m)\% n}') - d(Y,\xi_{1:m}) \mid Y] = m \alpha(Y).
\end{align*}
Thus, defining the test statistic $\phi$ 
by Algorithm~\ref{algorithm:test} with respect to the alignment cost $d$ from Eqn~\eqref{eqn:d-defn-gumbel},
we can again upper bound the $p$-value output by $\detect$ in Lemma~\ref{lemma:perm-test-gumbel} 
using a standard concentration argument and taking a union bound over $j \in [n]$.
We defer the proof of Lemma~\ref{lemma:perm-test-gumbel} to Appendix~\ref{app:gumbel}.
Once again, we actually prove a more general result that allows $\wt{Y}$ to be any length $k$ subsequence of $Y$.
% Defining the test statistic $\phi$ 
% by Algorithm~\ref{algorithm:test} with respect to the alignment cost $d$ from equation~\eqref{eqn:d-defn-gumbel},
% we can upper bound the $p$-value output by $\detect$ using a standard concentration argument.
% We defer the proof of Lemma~\ref{lemma:perm-test-gumbel} to Appendix~\ref{app:gumbel}.

\begin{lemma}\label{lemma:perm-test-gumbel}
    Let $m,n \in \N$ with $n \geq m$. Define $\decode$ by equation~\eqref{eqn:rho-defn-gumbel}, $d$ by equation~\eqref{eqn:d-defn-gumbel},
    and $\phi$ by Algorithm~\ref{algorithm:test} with $k = m$.
    Let $\xi,\xi' \iid \txt{Unif}(\Xi^n)$ with $Y = \generate(\xi;n,p,\decode)$ and $\wt{Y} = Y$.
    % and let $\wt{Y}$ be a length $m$ substring of $Y$ that is conditionally independent of 
    % $\xi$ and $\xi'$ given $Y$.
    % Let $C_0$ be a sufficiently small numerical constant. 
    Then almost surely
    \begin{align*}
        \P(\phi(\wt{Y},\xi') \leq \phi(\wt{Y},\xi) \mid \wt{Y}) \leq 2n\exp\left(-\min\{m\alpha(\wt{Y})^2/8,m\alpha(\wt{Y})/4\}\right).
    \end{align*}
\end{lemma}

% \rck{define $c_0$}

\subsubsection{Robustness to corruptions}
Showing high probability $p$-value upper bounds for corruptions of watermarked text 
that hold almost surely given the corrupted text---i.e., analogues of Lemmas~\ref{lemma:perm-test-subs} and \ref{lemma:perm-test-indel}---is more difficult, 
primarily due to the fact that the summands in the alignment metric from equation~\eqref{eqn:d-defn-gumbel} are no longer bounded and thus bounding the influence 
of each substitution and/or insertion operation on the test statistic requires more careful analysis.
Of course, we could in principle tweak the alignment metric 
by truncating the summands in order to prove the analogous results;
however, as the main intuitions would carry over from Lemmas~\ref{lemma:perm-test-subs} and \ref{lemma:perm-test-indel} 
and the results are not critical to the main thrust of the paper, we do not carry this plan out.

\subsubsection{What we run in practice}\label{sec:gumbel-practice}

As in the case of ITS, in practice we find using a slight variation of the 
alignment cost in equation~\eqref{eqn:d-defn-gumbel} performs better.
Namely, following the prescription of \citet{aaronson2023openai},
we modify the previous alignment cost to instead be
\begin{align}
    d(y,\xi) \defeq \sum_{i=1}^k \log (1 - \xi_{i,y_i}). \label{eqn:d-practice-gumbel}
\end{align}
Henceforth, we refer to this version of the watermarking strategy as {\gumb}, 
and we refer to the corresponding Levenshtein version wherein we define 
the base alignment cost $d_0$ by equation~\eqref{eqn:d-practice-gumbel} as {\gumbedit}.

In summary, for {\gumb} we use the decoder from equation~\eqref{eqn:rho-defn-gumbel}, the test statistic 
from Algorithm~\ref{algorithm:test} with the alignment cost from equation~\eqref{eqn:d-practice-gumbel}, and the watermark 
key distribution as the uniform distribution over $\Xi^n$, where recall $n$ is the length of 
the watermark key sequence and $\Xi = [0,1]^N$.
Meanwhile, {\gumbedit} differs from {\gumb} only in that we define the test statistic using the Levenshtein cost from 
Definition~\ref{defn:levenshtein-simple} with the base cost again from equation~\eqref{eqn:d-practice-gumbel}.
