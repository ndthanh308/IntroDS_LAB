\begin{thebibliography}{30}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Aaronson(2023)]{aaronson2023openai}
S.~Aaronson.
\newblock `{R}eform' {AI} {A}lignment with {S}cott {A}aronson.
\newblock AXRP - the AI X-risk Research Podcast, 2023.
\newblock URL \url{https://axrp.net/episode/2023/04/11/episode-20-reform-ai-alignment-scott-aaronson.html}.

\bibitem[Abdelnabi and Fritz(2021)]{abdelnabi2021adversarial}
S.~Abdelnabi and M.~Fritz.
\newblock Adversarial watermarking transformer: Towards tracing text provenance with data hiding.
\newblock In \emph{IEEE Symposium on Security and Privacy}, 2021.

\bibitem[Atallah et~al.(2001)Atallah, Raskin, Crogan, Hempelmann, Kerschbaum, Mohamed, and Naik]{atallah2001natural}
M.~J. Atallah, V.~Raskin, M.~Crogan, C.~Hempelmann, F.~Kerschbaum, D.~Mohamed, and S.~Naik.
\newblock Natural language watermarking: Design, analysis, and a proof-of-concept implementation.
\newblock In \emph{Information Hiding: 4th International Workshop, IH 2001 Pittsburgh, PA, USA, April 25--27, 2001 Proceedings 4}, pages 185--200. Springer, 2001.

\bibitem[Brown et~al.(2020)Brown, Mann, Ryder, Subbiah, Kaplan, Dhariwal, Neelakantan, Shyam, Sastry, Askell, et~al.]{brown2020language}
T.~Brown, B.~Mann, N.~Ryder, M.~Subbiah, J.~D. Kaplan, P.~Dhariwal, A.~Neelakantan, P.~Shyam, G.~Sastry, A.~Askell, et~al.
\newblock Language models are few-shot learners.
\newblock \emph{Advances in Neural Information Processing Systems 33}, 33:\penalty0 1877--1901, 2020.

\bibitem[Christ et~al.(2023)Christ, Gunn, and Zamir]{christ2023undetectable}
M.~Christ, S.~Gunn, and O.~Zamir.
\newblock Undetectable watermarks for language models.
\newblock \emph{arXiv preprint arXiv:2306.09194}, 2023.

\bibitem[Dai and Cai(2019)]{dai2019towards}
F.~Dai and Z.~Cai.
\newblock Towards near-imperceptible steganographic text.
\newblock In \emph{Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics}, pages 4303--4308, 2019.

\bibitem[Elfving et~al.(1966)Elfving, Birkhoff, and von Mises]{elfving1966selected}
G.~Elfving, G.~Birkhoff, and R.~von Mises.
\newblock Vol. 2. probability and statistics, {G}eneral.
\newblock In \emph{Selected Papers of {R}ichard von {M}ises}. American Mathematical Society, 1966.

\bibitem[He et~al.(2022{\natexlab{a}})He, Xu, Lyu, Wu, and Wang]{he2022protecting}
X.~He, Q.~Xu, L.~Lyu, F.~Wu, and C.~Wang.
\newblock Protecting intellectual property of language generation {API}s with lexical watermark.
\newblock In \emph{Proceedings of the Thirty-Sixth AAAI Conference on Artificial Intelligence}, 2022{\natexlab{a}}.

\bibitem[He et~al.(2022{\natexlab{b}})He, Xu, Zeng, Lyu, Wu, Li, and Jia]{he2022cater}
X.~He, Q.~Xu, Y.~Zeng, L.~Lyu, F.~Wu, J.~Li, and R.~Jia.
\newblock Cater: Intellectual property protection on text generation apis via conditional watermarks.
\newblock In \emph{Advances in Neural Information Processing Systems 35}, 2022{\natexlab{b}}.

\bibitem[Jawahar et~al.(2020)Jawahar, Abdul-Mageed, and Laks~Lakshmanan]{jawahar2020automatic}
G.~Jawahar, M.~Abdul-Mageed, and V.~Laks~Lakshmanan.
\newblock Automatic detection of machine generated text: A critical survey.
\newblock In \emph{International Conference on Computational Linguistics}, 2020.

\bibitem[Kamaruddin et~al.(2018)Kamaruddin, Kamsin, Por, and Rahman]{kamaruddin2018review}
N.~S. Kamaruddin, A.~Kamsin, L.~Y. Por, and H.~Rahman.
\newblock A review of text watermarking: theory, methods, and applications.
\newblock \emph{IEEE Access}, 2018.

\bibitem[Katzenbeisser and Petitcolas(2000)]{katzenbeisser2000digital}
S.~Katzenbeisser and F.~Petitcolas.
\newblock Digital watermarking.
\newblock \emph{Artech House, London}, 2:\penalty0 2, 2000.

\bibitem[Kirchenbauer et~al.(2023)Kirchenbauer, Geiping, Wen, Katz, Miers, and Goldstein]{kirchenbauer2023watermark}
J.~Kirchenbauer, J.~Geiping, Y.~Wen, J.~Katz, I.~Miers, and T.~Goldstein.
\newblock A watermark for large language models.
\newblock \emph{arXiv preprint arXiv:2301.10226}, 2023.

\bibitem[Mitchell et~al.(2023)Mitchell, Lee, Khazatsky, Manning, and Finn]{mitchell2023detectgpt}
E.~Mitchell, Y.~Lee, A.~Khazatsky, C.~D. Manning, and C.~Finn.
\newblock Detectgpt: Zero-shot machine-generated text detection using probability curvature.
\newblock \emph{arXiv preprint arXiv:2301.11305}, 2023.

\bibitem[Papandreou and Yuille(2011)]{papandreou2011perturbandmaprf}
G.~Papandreou and A.~L. Yuille.
\newblock Perturb-and-map random fields: Using discrete optimization to learn and sample from energy models.
\newblock \emph{2011 International Conference on Computer Vision}, pages 193--200, 2011.

\bibitem[Raffel et~al.(2020)Raffel, Shazeer, Roberts, Lee, Narang, Matena, Zhou, Li, and Liu]{raffel2020exploring}
C.~Raffel, N.~Shazeer, A.~Roberts, K.~Lee, S.~Narang, M.~Matena, Y.~Zhou, W.~Li, and P.~J. Liu.
\newblock Exploring the limits of transfer learning with a unified text-to-text transformer.
\newblock \emph{The Journal of Machine Learning Research}, 21\penalty0 (1):\penalty0 5485--5551, 2020.

\bibitem[Rizzo et~al.(2019)Rizzo, Bertini, and Montesi]{rizzo2019fine}
S.~G. Rizzo, F.~Bertini, and D.~Montesi.
\newblock Fine-grain watermarking for intellectual property protection.
\newblock \emph{EURASIP Journal on Information Security}, 2019.

\bibitem[Shen et~al.(2020)Shen, Ji, and Han]{shen2020near}
J.~Shen, H.~Ji, and J.~Han.
\newblock Near-imperceptible neural linguistic steganography via self-adjusting arithmetic coding.
\newblock In \emph{Proceedings of Empirical Methods for Natural Language Processing}, pages 303--313, 2020.

\bibitem[Taori et~al.(2023)Taori, Gulrajani, Zhang, Dubois, Li, Guestrin, Liang, and Hashimoto]{taori23alpaca}
R.~Taori, I.~Gulrajani, T.~Zhang, Y.~Dubois, X.~Li, C.~Guestrin, P.~Liang, and T.~B. Hashimoto.
\newblock Stanford alpaca: An instruction-following llama model.
\newblock \url{https://github.com/tatsu-lab/stanford_alpaca}, 2023.

\bibitem[Tiedemann and Thottingal(2020)]{tiedemann2020opus}
J.~Tiedemann and S.~Thottingal.
\newblock {OPUS-MT} â€” {B}uilding open translation services for the {W}orld.
\newblock In \emph{Proceedings of the 22nd Annual Conference of the European Association for Machine Translation}, 2020.

\bibitem[Tiedemann et~al.(2022)Tiedemann, Aulamo, Bakshandaeva, Boggia, Gr{\"o}nroos, Nieminen, Raganato, Scherrer, Vazquez, and Virpioja]{tiedemann2022democratizing}
J.~Tiedemann, M.~Aulamo, D.~Bakshandaeva, M.~Boggia, S.-A. Gr{\"o}nroos, T.~Nieminen, A.~Raganato, Y.~Scherrer, R.~Vazquez, and S.~Virpioja.
\newblock Democratizing machine translation with opus-mt.
\newblock \emph{arXiv preprint arXiv:2212.01936}, 2022.

\bibitem[Touvron et~al.(2023)Touvron, Lavril, Izacard, Martinet, Lachaux, Lacroix, Rozi{\`e}re, Goyal, Hambro, Azhar, et~al.]{touvron2023llama}
H.~Touvron, T.~Lavril, G.~Izacard, X.~Martinet, M.-A. Lachaux, T.~Lacroix, B.~Rozi{\`e}re, N.~Goyal, E.~Hambro, F.~Azhar, et~al.
\newblock Llama: Open and efficient foundation language models.
\newblock \emph{arXiv preprint arXiv:2302.13971}, 2023.

\bibitem[Ueoka et~al.(2021)Ueoka, Murawaki, and Kurohashi]{ueoka2021frustratingly}
H.~Ueoka, Y.~Murawaki, and S.~Kurohashi.
\newblock Frustratingly easy edit-based linguistic steganography with a masked language model.
\newblock In \emph{Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies}, 2021.

\bibitem[Venugopal et~al.(2011)Venugopal, Uszkoreit, Talbot, Och, and Ganitkevitch]{venugopal2011watermarking}
A.~Venugopal, J.~Uszkoreit, D.~Talbot, F.~J. Och, and J.~Ganitkevitch.
\newblock Watermarking the outputs of structured prediction with an application in statistical machine translation.
\newblock In \emph{Proceedings of Empirical Methods for Natural Language Processing}, 2011.

\bibitem[Vincent(2022)]{vincent23stackoverflow}
J.~Vincent.
\newblock {AI}-generated answers temporarily banned on coding {Q}\&{A} site {S}tack {O}verflow.
\newblock \emph{The Verge}, 2022.
\newblock URL \url{https://www.theverge.com/2022/12/5/23493932/chatgpt-ai-generated-answers-temporarily-banned-stack-overflow-llms-dangers}.

\bibitem[Wainwright(2019)]{wainwright19}
M.~J. Wainwright.
\newblock \emph{High-Dimensional Statistics: A Non-Asymptotic Viewpoint}.
\newblock Cambridge University Press, 2019.

\bibitem[Yang et~al.(2022)Yang, Zhang, Chen, Zhang, Ma, Wang, and Yu]{yang2022tracing}
X.~Yang, J.~Zhang, K.~Chen, W.~Zhang, Z.~Ma, F.~Wang, and N.~Yu.
\newblock Tracing text provenance via context-aware lexical substitution.
\newblock In \emph{Proceedings of the Thirty-Sixth AAAI Conference on Artificial Intelligence}, 2022.

\bibitem[Zhang et~al.(2022)Zhang, Roller, Goyal, Artetxe, Chen, Chen, Dewan, Diab, Li, Lin, et~al.]{zhang2022opt}
S.~Zhang, S.~Roller, N.~Goyal, M.~Artetxe, M.~Chen, S.~Chen, C.~Dewan, M.~Diab, X.~Li, X.~V. Lin, et~al.
\newblock Opt: Open pre-trained transformer language models.
\newblock \emph{arXiv preprint arXiv:2205.01068}, 2022.

\bibitem[Zhao et~al.(2023)Zhao, Wang, and Li]{zhao2023protecting}
X.~Zhao, Y.-X. Wang, and L.~Li.
\newblock Protecting language generation models via invisible watermarking.
\newblock \emph{arXiv preprint arXiv:2302.03162}, 2023.

\bibitem[Ziegler et~al.(2019)Ziegler, Deng, and Rush]{ziegler2019neural}
Z.~Ziegler, Y.~Deng, and A.~M. Rush.
\newblock Neural linguistic steganography.
\newblock In \emph{Proceedings of Empirical Methods for Natural Language Processing}, pages 1210--1215, 2019.

\end{thebibliography}
