\section{Analysis of exponential minimum sampling}\label{app:gumbel}
To prove the main theorems, we introduce the following supporting lemma.
The result is well known and we restate it here only for completeness.
\begin{lemma}\label{lemma:core-result-gumbel}
    Let $\mu \in \Delta([N])$ and $\xi \sim \txt{Unif}([0,1]^N)$. Then for any 
    $y \in [N]$ we have
    \begin{align*}
        \P(\decode(\xi,\mu) = y,-\log (\xi_y)/\mu(y) \geq t) = \mu(y) \exp(-t).
    \end{align*} 
\end{lemma}
\begin{proof}
    Suppose $\mu(y) > 0$ as otherwise the claim is trivial.
    Recalling $\xi_i \iid \txt{Unif}([0,1])$, for any $\lambda > 0$ we have
    $-\lambda \log \xi_i \iid \txt{Exp}(\lambda)$,
    i.e.,
    \begin{align*}
        \P(-\lambda \log \xi_i \geq t) = \P(\xi_i \leq \exp(-\lambda t)) = \exp(-\lambda t). %\label{eqn:gumbel-core}
    \end{align*}
    Thus, the claim follows as
    \begin{align*}
        & \P(\decode(\xi,\mu) = y,-\log (\xi_y)/\mu(y) \geq t) \\
        & = \P(y = \argmin_i -\log(\xi_i)/\mu(i),-\log (\xi_y)/\mu(y) \geq t) \\
        & \stackrel{(\star)}{=} \int_{u \geq t} \mu(y)\exp(-\mu(y) u) \cdot \Pi_{i \in \txt{supp}(\mu),i \neq y} \P(-\log (\xi_i)/\mu(i) > u) \\
        & = \int_{u \geq t} \mu(y)\exp(-\mu(y) u) \cdot \Pi_{i \in \txt{supp}(\mu),i \neq y} \exp(-\mu(i) u) \\
        & = \mu(y) \int_{u \geq t} \Pi_{i \in \txt{supp}(\mu)} \exp(-\mu(i) u) \\
        & = \mu(y) \int_{u \geq t} \exp(-u) \\
        & = \mu(y)\exp(-t),
    \end{align*}
    where in ($\star$) we use the fact that the density of $-\log (\xi_y)/\mu(y)$ at $u$ is $\mu(y) \exp(-\mu(y)u)$.
\end{proof}

\subsection{Proof of Theorem~\ref{thm:stealth-gumbel}}
\begin{proof}
    The result follows immediately from integrating the result of Lemma~\ref{lemma:core-result-gumbel}
    over $t \geq 0$.
\end{proof}

\subsection{Proof of Lemma~\ref{lemma:sound-gumbel}}
\begin{proof}
    Lemma~\ref{lemma:core-result-gumbel} implies 
    $-\log(\xi_i) / p(Y_i \mid Y_{:i-1}) \mid Y \sim \txt{Exp}(1)$,
    and thus $\Ep[-\log(\xi_i) \mid Y] = p(Y_i \mid Y_{:i-1})$.
    Meanwhile, as $\xi_i' \sim \txt{Unif}([0,1])$ independently of $Y$, 
    we have 
    \begin{align*}
        \P(- \log \xi_i' \geq t \mid Y) = \P(\xi_i' \leq \exp(-t)) = \exp(-t),
    \end{align*}
    implying $-\log(\xi_i') \mid Y \sim \txt{Exp}(1)$ and so $\Ep [-\log(\xi_i') \mid Y] = 1$.
    The result follows immediately, recalling $\alpha(Y_{i-1:i}) = 1 - p(Y_i \mid Y_{i-1})$
    by definition.
    % \begin{align*}
    %     \alpha(Y_{i-1:i}) = 1 - p(Y_i \mid Y_{i-1})
    % \end{align*}
\end{proof}

\subsection{Proof of Lemma~\ref{lemma:perm-test-gumbel}}
We prove the following general result, from which Lemma~\ref{lemma:perm-test-gumbel} follows as a corollary.
\begin{lemma}
    Let $m,n \in \N$ with $n \geq m$, where $m$ is the generation length and $n$ is the watermark key length. 
    Define the decoder $\decode$ by equation~\eqref{eqn:rho-defn-gumbel}, alignment score $d$ by equation~\eqref{eqn:d-defn-gumbel},
    and $\phi$ by Algorithm~\ref{algorithm:test} with block size $k \leq m$.
    Let $\xi,\xi' \iid \txt{Unif}(\Xi^n)$ with $Y = \generate(\xi;n,p,\decode)$.
    Let $\wt{Y}$ be a substring of $Y$ of length at least $k$ that is conditionally independent of 
    $\xi$ and $\xi'$ given $Y$, i.e., $\wt{Y} = Y_{\tau+1:\tau+\ell}$ for $\ell \geq k$.
    Then for $\est{\alpha} \defeq 1 - \frac{1}{k}\sum_{i=\tau+1}^{\tau+k} p(Y_i \mid Y_{:i-1})$, almost surely
    \begin{align*}
        \P(\phi(\wt{Y},\xi') \leq \phi(\wt{Y},\xi) \mid \wt{Y},Y) \leq 2n\exp\left(-\min\{k\est{\alpha}^2/8,k\est{\alpha}/4\}\right).
    \end{align*}
\end{lemma}
\begin{proof}
    % For convenience, define $\est{\alpha} \defeq 1 - \frac{1}{k}\sum_{i=\tau+1}^{\tau+k} p(Y_i \mid Y_{:i-1})$.
    Recall by definition
    \begin{align*}
        d(y,\xi) = -\sum_{i=1}^{\len{y}} \log \xi_{i,y_i}.
    \end{align*}
    Lemma~\ref{lemma:sound-gumbel} and the conditional independence of $\tau$ and $\xi$ given $Y$ 
    imply for any $j \in [n]$ that 
    \begin{align*}
        \Ep[d(\wt{Y},\xi_{(j+1:j+k)\% n}') \mid \wt{Y},Y] - \Ep[d(\wt{Y},\xi_{\tau+1:\tau+k}) \mid \wt{Y},Y] = k \est{\alpha}.
    \end{align*}
    
    From Lemma~\ref{lemma:core-result-gumbel}, we have $-\log \xi_{\tau+i,\wt{Y}_i} \mid \wt{Y},Y \sim \txt{Exp}(\gamma_i)$
    for some $\gamma_i \leq 1$ for all $i \in [m]$.
    Also, from the independence of $\wt{Y}$ and $\xi'$,
    we have $-\log \xi_{j,\wt{Y}_i}' \mid \wt{Y},Y \sim \txt{Exp}(1)$
    for all $i \in [m]$ and $j \in [n]$.
    The following observation thus implies
    $-\log \xi_{i,\wt{Y}_i} \mid \wt{Y},Y$ and $-\log \xi_{j,\wt{Y}_i}' \mid \wt{Y},Y$ 
    are both $(2,2)$-subexponential random variables.
    \begin{observation}\label{obs:gumbel-subexp}
        Let $X \sim \txt{Exp}(1)$. Then $X$ is a $(2,2)$ subexponential random variable.
    \end{observation}
    \begin{proof}[Proof of Observation~\ref{obs:gumbel-subexp}]
        For $t < 1/2$, we have
        \begin{align*}
            \Ep[e^{t (X-\Ep[X])}] & = \int_0^\infty e^{t(x-1)} e^{-x} \, dx \\
            % & = \int_0^\infty e^{(t-1)x - t} \, dx \\
            % & = e^{-t} \int_0^\infty e^{(t-1)x} \, dx \\
            %& = \evalat{\frac{e^{-t}}{t-1} e^{(t-1)x}}{x=0}^\infty \\
            % & = \frac{e^{-t}}{t-1} \cdot e^{(t-1)x} \Bigg|_{x=0}^\infty \\
            & \stackrel{(a)}{=} \frac{e^{-t}}{1-t} \\
            & \stackrel{(b)}{\leq} (1 - t + t^2)(1 + t + 2t^2) \\
            % & = (1 - t^2 + t^2 + t^3 + 2t^4 + 2t^2 -3t^3 + 2t^4) \\
            % & = (1 + 2t^2 - 2t^3 + 4t^4) \\
            & \stackrel{(c)}{\leq} (1 + 2t^2) \\
            & \leq e^{2t^2},
        \end{align*}
        where (a) follows from the fact that $t < 1$ 
        (otherwise, the integral would not be finite);
        (b) follows from Taylor expanding $e^{-t}$ and $1/(1-t)$
        and applying the fact that $t < 1/2$ to bound the higher-order terms;
        and (c) again follows from $t < 1/2$.
        The claim follows immediately.
    \end{proof}

    Thus, using the fact that $\xi_i$ is conditionally independent of $\xi_{-i}$ given $Y$,
    a standard Chernoff bound \cite[Proposition 2.9]{wainwright19} implies for each $j \in [n]$ that 
    \begin{align*}
        & \P\left(d(\wt{Y},\xi_{j+1:j+k}') \leq d(\wt{Y},\xi_{\tau+1:\tau+k})\mid \wt{Y},Y\right) \\
        & \leq \P\left(d(\wt{Y},\xi_{1:m}) - \Ep[d(\wt{Y},\xi_{1:m})] \geq k\est{\alpha}/2 \mid \wt{Y},Y\right) \\
        &  \qquad + \P\left(\Ep[d(\wt{Y},\xi_{j+1:j+m}')] - d(\wt{Y},\xi_{j+1:j+m}') \geq k \est{\alpha}/2 \mid \wt{Y},Y\right) \\
        & \leq 2\exp\left(-\min\{k\est{\alpha}^2/8,k\est{\alpha}/4\}\right).
    \end{align*}
    Recalling the definition of the test statistic $\phi$ via Algorithm~\ref{algorithm:test},
    the main claim then follows from taking a union bound over all $j \in [n]$.
\end{proof}