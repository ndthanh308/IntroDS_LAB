% \section{Preliminaries}
% \subsection{Notation}
% Let $\mc{V} = [n]$ be the \textit{vocabulary},
% where $n \in \N$ is the size of the vocabulary (i.e., number of tokens).
% Let $f : \(\emptyset \cup \mc{V}^*\) \to \Delta(\mc{V}) =: \mc{F}$
% denote an (autoregressive) \textit{language model} 
% that takes a prefix of arbitrary length as input and returns a 
% distribution over the vocabulary, i.e., an element of the $n$-dimensional 
% probabability simplex, and for $m \in N$ let $P_f^m(\cdot \mid p)$ denote the 
% distribution over sequences of length $m$ induced by 
% sampling autoregressively from the language model $f$ conditional 
% on the prefix $p$.

% \subsection{Problem formulation}
% Given an arbitrary language model $f$, our goal is to give a
% collection of watermarked language models $f_\xi := \(\emptyset \cup \mc{V}^*\)
% \to \Delta(\mc{V})$ indexed by $\xi \in \Xi$ along with a distribution $P_\xi$ over $\Xi$ 
% such that $\xi \sim P_\xi$ and $S \sim \P_{f_\xi}^m(\cdot \mid p)$
% satisfy the following conditions for any prefix 
% $p \in \(\emptyset \cup \mc{V}^*\)$ and sufficiently large sequence length $m$:
% \begin{itemize}
%     \item[(C.i)] $S \stackrel{d}{=} S'$ for $S' \sim P_f^m(\cdot \mid p)$,
%     \item[(C.ii)] $D_{TV}((S,\xi)||(S',\xi)) \geq 1-\delta$
%                     for $S' \sim P_f^m(\cdot \mid p)$.
% \end{itemize}

% Thinking of $\xi$ as a source of additional randomness, the
% (marginal) distribution over sequences induced by the collection of watermarked language models 
% should be the same as the distribution induced by the original language model,
% but anyone who observes $\xi$ should be able to easily distinguish between the watermarked 
% versus unwatermarked text.
% Eventually, we will replace the randomness in $P_\xi$ with pseudorandomness; 
% the idea is that so long 
% as the pseudorandomness is indistinguishable from the original randomness,
% the two conditions will still hold (at least approximately).
