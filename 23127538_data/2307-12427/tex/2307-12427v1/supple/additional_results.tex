\section{Additional Results}\label{sec:ar}
\subsection{Detailed Results for the Long Sequences}
\input{supple/table_55}
In \cref{tab:longseq}, we present the results of our experiments with long sequences on the PASCAL-VOC 2007 dataset. To simulate this scenario, we trained our detector on images from the first 5 classes and gradually added classes 6 to 20 in groups of five.

The table shows the class-wise average precision (AP)@0.5 and the corresponding mean average precision (mAP). The first row (JT) represents the upper-bound where the detector is trained on data from all 20 classes. The subsequent three pairs of rows demonstrate the results obtained when adding five new classes at a time. The notation (1-5)+6..10 is used to represent this setting. Our proposed ABR method outperforms the previous state-of-the-art method MMA~\cite{cermelli2022modeling} on all sequential tasks, as can be seen from the results in \cref{tab:longseq}. Therefore, the ABR method can be more useful in real-world scenarios where new object classes are frequently introduced. Additionally, the ABR method is a novel approach that may have implications for future research in object detection.

% \subsection{Additional qualitative results for False Positive}

% The experimental analysis focuses on the false positive errors in object detection, which are detections that do not correspond to the target category. The study focuses on three types of false positives: localization error, similar objects error, and confusion with the background in VOC 10-10, as described in~\cite{hoiem2012diagnosing}. To assess the performance of ABR, we compare it with other algorithms and show the pairwise statistics of false positives between ABR and other algorithms in~\cref{fig:fp}. 
% % The statistics represent the false positive difference between the other algorithm and ABR.
% % The paper mainly concentrates on these three types of errors and compares the proposed ABR algorithm with other algorithms to see its effectiveness in reducing false positives. 
% % The pairwise statistics of false positives between the ABR algorithm and other algorithms are shown in Figure~\cref{fig:fp}. 
% The statistics are the false positive difference between the other algorithm and the ABR algorithm. The results indicate that the ABR algorithm can significantly reduce background errors compared to other algorithms, including joint training. This is due to the mixup replay strategy used in ABR, which provides rich background information for both new and previous classes and improves the generalization ability of the overall model. The~\cref{fig:imageours} shows the performance of ABR in terms of localization and background errors on new categories and compares it with image playback methods. The results show that ABR outperforms image playback methods in terms of localization and background errors for new categories. This is because the augmented box replay strategy overcomes the problem of foreground drift caused by image replay.


% One major type of error is false positives, detection that do not correspond to the target category. There are different types of false positives which likely require different kinds of solutions. In this work, we mainly focus on three errors: localization error (loc), similar objects error (sim), confusion with background (bg), referencing to~\cite{hoiem2012diagnosing}. In~\cref{fig:fp}, we show the pairwise statistics of the false positives pairwise between our proposed ABR and different algorithms, which is the error-positive statistic of the other algorithm minus ours. Through observation, we can find that our algorithm can greatly reduce the generation of background errors, and even improves compared to joint training. This is due to the mixup playback strategy we adopted, which introduces rich background information beyond the original data for both new and previous classes, and improves the generalization ability of the overall model. ABR can achieve the better performance on new categories of localization and background errors than image replay methods. This is due to the replay technology of augmented box, which overcomes the problem of foreground drift caused by image replay.


\subsection{Visualization}
The inference results are presented in \cref{fig:addpred}, which demonstrate the effectiveness of our proposed ABR method in avoiding the forgetting of previous classes and improving adaptation to new classes. 
In the first two rows, our method is capable of accurately distinguishing new classes from similar classes in the previous classes, as seen in the detection of a \textit{bus} in the first row of images and a \textit{cow} in the second row of images. However, the popular MMA method misclassifies the \textit{bus} as a \textit{train} or \textit{bus} and the \textit{cow} as a \textit{dog} or \textit{cow}. In the third row, our algorithm successfully detects the new class, a \textit{dining table}, while also accurately locating a previous class, a \textit{chair}. In comparison to the MMA method, our method achieves more precise position detection, as demonstrated in the last two rows where \textit{person} and \textit{boat} are detected.

Overall, these results suggest that the proposed ABR method can more effectively handle the problem of incremental learning in object detection tasks, particularly in scenarios where new classes are similar to previous ones. The ability to avoid forgetting and adapt to new classes is crucial for practical applications, and the improved performance of our method is promising for future research in this area.



% \centering
% Figure environment removed