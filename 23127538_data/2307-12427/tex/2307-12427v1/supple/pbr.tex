\section{Additional Methods}
\subsection{Prototype Box Selection}\label{sec:pbs}

This method involves selecting the most representative boxes, as prototypes, from the current training data, which are then replayed along with the future training data. The memory buffer is commonly denoted as $B^t$, where $t$ represents the current task and the size $M$ of $B^t$ is limited. Therefore, the selection is an important factor that affects the performance. We employ a frozen trained model to generate the Region of Interest (RoI)-Aligned feature maps $\{F^{t}_g \in \mathbb{R}^{C\times S \times S}\}_{g=1}^{G^t_n}$ for $G^t_n$ groundtruth boxes in the current task $t$, where $C$ is the number of feature planes and $S$ is the spatial dimension. Then, a prototype feature map $\hat{F}^{t}_{c}$ for each class $c \in \mathcal{C}^{t}$ can be computed by:
\begin{equation}
\hat{F}^{t}_{c}=\frac{1}{|{F}^{t}_{c}|}\sum_{g=1}^{G^t_n} F^{t}_{g},\quad \forall c_g = c,
\label{eq:profm}
\end{equation}
The distance between each feature map $F^{t}_{g}$ and the prototype feature map $\hat{F}^{t}_{c}$ for class $c$ is computed using the Euclidean distance:
\begin{equation}
d(F^{t}_{g}, \hat{F}^{t}_{c}) = \sqrt{\sum (F^{t}_{g}-\hat{F}^{t}_{c})^2},\quad \forall c_g = c,
\label{eq:dis}
\end{equation}
Then we sort $\{d(F^{t}_{g}, \hat{F}^{t}_{c}),\forall c_g = c\}_{g=1}^{G^t_n}$ in ascending order, and select the top $M_c=\frac{M}{|\mathcal{C}^{1:t}|}$ boxes for that class to form the box buffer $B^{t}_{c}$. The final $B^{t}$ can focus on the most relevant information for each task and avoid redundant or irrelevant information, as shown in~\cref{alg:1}.

Additionally, since boxes are typically smaller than whole images, the computational cost of training and rehearsal can be reduced, making the approach more scalable to large datasets and complex models. The entire flow of our proposed method is shown in~\cref{algorithm2}.

    \renewcommand{\algorithmicrequire}{{\textbf{Input:}}}
    \renewcommand{\algorithmicensure}{{\textbf{Output:}}}
    \begin{algorithm}[ht]
    	\caption{Prototype Box Selection (PBR)}
	\begin{algorithmic}[1]
		\REQUIRE  The frozen trained model in $f_{\theta_t}(\cdot)$, the stream data $D^t$ at current task $t$, each image $I^t_n$ has $G_n^t$ groundtruth labels $\{y_g\}_{g=1}^{G_n^t}$, the box rehearsal memory $B^{t-1}$ after task $t-1$, the box rehearsal memory size $M$, the seen classes $\mathcal{C}^{1:t}$ until task $t$.
		\ENSURE The updated $B^{t}$ after task $t$. \\
		\STATE {\textbf{Initialize}}: $B^{t} = \{\}$, $m^t$ = ceil($M/|\mathcal{C}^{1:t}|$);
            \STATE $F^t_g$ = $f_{\theta_t}(I^t_n, y_g)$, $\forall{n} \in N^t$, $\forall{g} \in G^t_n$;
            \STATE $b_g=crop(I^t_n, y_g)$, 
            $\forall{n} \in N^t$, $\forall{g} \in G^t_n$;      
        \FOR {$c$ in $\mathcal{C}^{1:t}$}
        \IF{$c \in \mathcal{C}^{t}$}
            % \STATE $\hat{F}_c^t=\left\{F^t_g \mid c_g=c\right\}$;
            \STATE Compute $\hat{F}^{t}_{c}$ for each class $c$ based on~\cref{eq:profm};
            % \STATE $\hat{F}_c^t= mean(F_c^t)$;
            \STATE $D_c = \left\{(b_g, y_g)\mid c_g=c\right\}$;
            \STATE Sort ${D}_c$ following~\cref{eq:dis};
            \STATE $B^{t}+=D_c[0:m^t]$;
        \ELSE
            \FOR {$j=1, 2, ..., m^t$}
    		\STATE $i=j *\left|{B}_c^{t-1}\right| / ceil(M/|\mathcal{C}^{1:t-1}|)$;
    		\STATE ${B}^t+={B}_c^{t-1}[i]$;
    		\ENDFOR
       \ENDIF\ENDFOR
	\end{algorithmic}
	\label{alg:1}
    \end{algorithm}

    \renewcommand{\algorithmicrequire}{{\textbf{Input:}}}
    \renewcommand{\algorithmicensure}{{\textbf{Output:}}}
    \begin{algorithm}[ht]
    	\caption{Augmented Box Replay Method}
            % \scriptsize
    	\begin{algorithmic}[1]
    		\REQUIRE  $f_{\theta_{t-1}}(\cdot)$, $D^t$=$\{I^t_n, G_n^t\}_{n=1}^{N_t}$, $B^{t-1}$ and Rat=1:1:2.
    		\ENSURE The updated $B^{t}$ and $f_{\theta_t}(\cdot)$ after task $t$. \\
    		\STATE {\textbf{Initialize}}: $\theta_{t} = \theta_{t-1}$;
            \FOR {$n$ in $N_t$}
                \STATE MIX,MOS,NEW=GenerateReplayType(Rat);
                \IF{MIX}
                    \STATE Compute $\hat{I}^t_n, \hat{G}^t_n$ by MixupBoxReply($I^t_n, G_n^t$);
                \ELSIF{MOS}
                    \STATE Compute $\hat{I}^t_n, \hat{G}^t_n$ by MosaicBoxReply($I^t_n, G_n^t$);
                \ELSIF{NEW}
                    \STATE $\{\hat{I}^t_n, \hat{G}^t_n\} = \{I^t_n, G_n^t$\};
                \ENDIF
                \STATE $\mathcal{L}_{Dis}=$ DistiallationLosses($f_{\theta_{t-1}}(\cdot), f_{\theta_{t}}(\cdot), \hat{I}^t_n$);
                \STATE $\mathcal{L}_{Det}=$ DetectionLosses($f_{\theta_{t}}(\cdot), \{\hat{I}^t_n, \hat{G}^t_n\}$);
                \STATE Update $\theta_{t}$ by $\mathcal{L}_{Dis}+\mathcal{L}_{Det}$;
           \ENDFOR
           \STATE Update $B_t$ by PBS($f_{\theta_{t}}(\cdot), D^t, B^{t-1}$);
    	\end{algorithmic}
    	\label{algorithm2}
    \end{algorithm}

