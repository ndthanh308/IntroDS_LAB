{
  "title": "Feature Gradient Flow for Interpreting Deep Neural Networks in Head and Neck Cancer Prediction",
  "authors": [
    "Yinzhu Jin",
    "Jonathan C. Garneau",
    "P. Thomas Fletcher"
  ],
  "submission_date": "2023-07-24T18:25:59+00:00",
  "revised_dates": [],
  "abstract": "This paper introduces feature gradient flow, a new technique for interpreting deep learning models in terms of features that are understandable to humans. The gradient flow of a model locally defines nonlinear coordinates in the input data space representing the information the model is using to make its decisions. Our idea is to measure the agreement of interpretable features with the gradient flow of a model. To then evaluate the importance of a particular feature to the model, we compare that feature's gradient flow measure versus that of a baseline noise feature. We then develop a technique for training neural networks to be more interpretable by adding a regularization term to the loss function that encourages the model gradients to align with those of chosen interpretable features. We test our method in a convolutional neural network prediction of distant metastasis of head and neck cancer from a computed tomography dataset from the Cancer Imaging Archive.",
  "categories": [
    "eess.IV",
    "cs.LG"
  ],
  "primary_category": "eess.IV",
  "doi": "10.1109/ISBI52829.2022.9761674",
  "journal_ref": "Proceedings of 2022 IEEE 19th International Symposium on Biomedical Imaging (ISBI), 2022",
  "arxiv_id": "2307.13061",
  "pdf_url": null,
  "comment": null,
  "num_versions": null,
  "size_before_bytes": 1614014,
  "size_after_bytes": 100074
}