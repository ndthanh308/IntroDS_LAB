    % \subsection{Experimental Setup}
%%%%%%%%%%

%The experimental setup consists of the the \MSoRo~on a rubber garage mat, and two overhead webcams. Low-level robot control is performed by the \Arduino and is integrated with high-level planning and localization that is performed in MATLAB\textregistered. The first webcam is used to capture HD video of the experiments. The second webcam has its properties (e.g., contrast, brightness, etc.) adjusted to allow for better image segmentation of the four neon markers on the robot hub to facilitate tracking. Similarly, the obstacles, and goal are identified. The real-time robot pose is estimated as described in \Sec \ref{Subsec:Localization}. The Gait Library described in \Sec \ref{Subsec:GaitSynthesizer} informs path planning described in Sec. \ref{Subsec:TrajectoryPlanning}.

To validate the 
closed-loop path planner, we performed experiments with three world scenarios with obstacles: (1) World 1 where the robot has to perform a `zig' maneuver to go around the obstacle, (2) World 2 where the robot needs to perform a `zig' and `zag' motion to avoid obstacles and reach the goal, and (3) World 3 where the robot needs to go between two obstacles to reach the goal. All experiments are performed with the experimental setup and methodology discussed in \Sec \ref{Sec:Methodology}. A rubber garage mat is used as the substrate and paper cutouts are used for the obstacles. The \MSoRo~successfully maneuvers past the obstacles to reach the target position in all three scenarios. \textadded{The results discussed in this section are visualized in the multimedia attachment to this paper.}%The results are discussed \textadded{and also captured in the multimedia attachment to this paper.}\textadded{\st{, and the reader can also refer to the multimedia attachment to the paper for the videos.}}

World 1 consists of two obstacles where the robot is required to maneuver one obstacle to reach the target. The planner recalculates the path six times before it reaches the goal, as shown in \Fig \ref{Fig:ClosedLoop1}a. The path is recalculated after the execution of a gait sequence if the position error exceeds a threshold. From the error plot, sudden drops in the error indicate path re-planning.
%reaches the target/goal. 
% In world 3 the  robot has to traverse through a much narrow path in between the obstacles 
%
World 2 requires the robot to perform two obstacle-avoiding maneuvers to reach the goal as shown in \Fig \ref{Fig:ClosedLoop1}b. World 2 also triggers six path recalculations. In both World 1 and World 2, the position error both increases and decreases during the execution of gait sequences; it does not consistently monotonically increase before suddenly dropping at recalculation points. Thus, the robot is allowed to complete the current gait sequence, until the point of a gait switch. If the position error still exceeds the threshold, re-planning occurs.
%

% Figure environment removed



The World 3 scenario explores the ability of \MSoRo~to navigate narrow spaces, \Fig \ref{Fig:ClosedLoop1}c. Here, to perform this delicate maneuver, the path re-planning is triggered after every 20 gait cycles. As observed, the position errors are smaller relative to previous world scenarios. However, this scenario also involves thirty recalculations and does not appear to exploit the potential decreases in the error that were seen in the previous worlds.%

%\textadded{\st{The experiment shows repeatability on reaching the goal position in the World scenarios but does not follow the exact sequence as previous due to the variance in the twists of the gaits.}}
% \textadded{In subsequent trials in these same World scenarios, experiements exhibited repeatability in the successful traversal from start to target while avoiding the obstacles; however, the paths and executed sequences varied due to the variance in the twists of the gaits.}
% 
% \hl{Arun - Discussion on World 1, 2,3 experimental results}
% 
% The camera captures the initial setup of the test bed which includes the robot, obstacles, and the goal destination. This image used by the locomotion path planner to obtain the canned gait sequence that is supposed to aid the robot to its final goal destination. Similarly, there is a communication between MATLAB - Arduino and &tracking camera initialized in parallel&. The images taken by the tracking camera are sent to a pollable data queue. As the data queue gets populated these images are polled by tracker function in matlab and gives out the real time pose of the robot. Unlike open loop analysis performing the canned sequence completely, here the robot's pose is checked and path is recalculated for every minimum of 60 overall gait cycles performed. the tracker function reports the current pose of the robot for goal position reach check and if it is not then the path will be re-calculated and new gait sequence is been obtained using the current pose at that time as the initial pose of the robot. This process is repeated until the goal position is reached.  

%&Also these are written to file to capture the full-length video of the experiment.&

% Tracker: Code written in MATLAB to calculate the pose(x,y,theta) at every frame of the video captured by the tracking webcam. Image processing based on color threshold to identify markers, obstacles, &goal & and handles occlusion of markers on the frames captured by tracking webcam. The data of the markers are used to calculate the pose(x,y,theta) of the robot at every frame.  

% Offline analysis: The robot performing euler tour is captured initially. Later these videos are analysed in MATLAB tracker to find the pose of the robot. These pose datas are used to build the gait library which is a set of rich rotation gait and translation gait. &permutation&

% Open Loop analysis: For a specific scenario with obstacle, the path planner constructs a path for the robot to traverse from start to the x_goal goal position. &The path planner outputs a canned sequence of gaits with number of cycle each gait has to perform&. The high level controller MATLAB communicates the canned sequence to the low level controller Arduino. The tracking webcam is initialized in MATLAB using Parallel Computation Toolbox which operates in a seperate core to avoid disturbance between MATLAB and Arduino communication. The tracked video is then analysed using the MATLAB tracker. 
% * Algorithm chart *
% {Figure} - plot of open loop analysis
% From the open loop analysis, it was clear that the robot’s actual pose does not exactly match with the simulation pose. &drift& 

% Closed loop analysis: The tracking camera captures the initial setup of the test bed which includes the robot, obstacles, and the goal destination. This image is fed to the locomotion path planner to obtain the canned gait sequence that is supposed to aid the robot to its final goal destination. Similarly, there is a communication between MATLAB - Arduino and &tracking camera initialized in parallel&. The images taken by the tracking camera are sent to a pollable data queue. As the data queue gets populated these images are polled by tracker function in matlab and gives out the real time pose of the robot. Unlike open loop analysis performing the canned sequence completely, here the robot's pose is checked and path is recalculated for every minimum of 60 overall gait cycles performed. the tracker function reports the current pose of the robot for goal position reach check and if it is not then the path will be re-calculated and new gait sequence is been obtained using the current pose at that time as the initial pose of the robot. This process is repeated until the goal position is reached.  

% * Algorithm chart *
% {Figure} - plot of closed loop analysis - reaching target
% Thus the drift between the actual pose and simulation pose is rectified in this way.

% RESULT
% Write something to say that the robot reached the final target succesfully.
% Upload plots of Trial_12
% Discuss about Trial_27
% Upload 1st and last image(robot entering goal zone)
% Upload plots of Trial_27



% The architecture of the experiment includes MATLAB, Arduino, and 2 webcam placed overhead the robot test-bed.  For the robot test bed, a rubber garage mat was chosen whose frictional co-efficient is around $xx$. The 2 webcams have their own purpose. One of the webcam is used to capture video for tracking purposes in which the property of the camera is modified to capture video which makes the markers on the robot bright and easy to track. Another webcam captures HD video. Both videos are written in 2 different files to get the full-length videos of the experiment.  

% The tracking camera captures the initial setup of the test bed which includes the robot, obstacles, and the goal destination. This image is fed to the locomotion path planner to obtain the canned gait sequence that is supposed to aid the robot to its final goal destination. 

% Now the gait library is defined to the arduino before the experiment begins. Both the cameras are initialized in separate cores via matlab parallel processing toolbox. The images taken by the tracking camera are sent to a pollable data queue. As the data queue gets populated these images are polled by online tracker function in matlab and gives out the real time pose of the robot.  

% Matlab communicates with arduino for performing the gaits. Matlab sends one gait and number of cycle at a time and waits for arduino’s gait completion status feedback before sending the next gait details. From the open loop analysis, it was clear that the robot’s actual pose does not exactly match with the simulation pose \hl{[include figure]}. Therefore, after certain gait sequences are completed, the tracker function reports the current pose of the robot for goal position reach check and if it is not then the path will be re-calculated and new gait sequence is been obtained using the current pose at that time as the initial pose of the robot. This process is repeated until the goal position is reached.  

% \hl{camera tracking at 10fps and recording at 30fps}

%%%%%%%%%%
% \begin{itemize}
% \item Experimental Setup: (1) Hardware integration; (2) Software integration (parallel computing); (3) Webcam-based localization
% \item TerraSoRo Gait Library: (1) Rotation and translation gaits with permutations, (2) Repeatability of the gaits
% \item World scenarios and "receding horizon" path planning approach to calculate time-varying gait sequences.
% \item Tuning parameters for path recalculation (recalculation frequency, distance error, twist error)
% \end{itemize}

% % Figure environment removed