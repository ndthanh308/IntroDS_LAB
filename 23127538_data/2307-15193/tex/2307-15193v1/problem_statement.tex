\section{Preliminaries}

\subsection{Model}
\textbf{Auction format: Pay-as-bid.} Consider a setting with $N$ bidders and $M$ units to auction off in a pay-as-bid auction with reserve $r\ge 0$. Let ${\bf b}_n = (b_{n, m})_{n\in [N], m\in [M]}$  be the bids submitted by bidder $n$, where $b_{n, 1}\ge b_{n, 2}\ge b_{n, M}\ge 0$ and $b_{n, m}$ is the bid of bidder $n$ for the $m$-th unit. One can view $b_{n,m}$, $n\in [N]$ and $m\in [M]$, as a proxy for the bidder $n$'s (marginal) valuation for the $m$-th unit, denoted by $v_{n, m}$, where we assume that $v_{n, 1}\ge v_{n, 2}\ge \ldots \ge v_{n, M}$ to model the diminishing return of one additional unit.  
In a pay-as-bid auction with reserve $r$,  any  bid that is less than reserve price $r$ is first discarded. The remaining (cleared) bids are then sorted in decreasing order.  The $m$-th unit is allocated to the bidder with the $m$-th highest bid if the number of cleared bids is greater than or equal to $m$, charging him his bid.
 {\color{red}todo: briefly talk about the tie breaking rule.}  That is, if bidder $n$ is allocated $x_n(\mathbf b)$ units, he is charged $\sum_{m=1}^{x_n(\mathbf b)} b_{n,m}$ while his (total) valuation is $\sum_{m=1}^{x_n(\mathbf b)} v_{n,m}$, where $\mathbf b = ((\mathbf b_n)_{n\in [N]}; r)$ is the submitted bids by all the bidders and reserve price $r$ {\color{red} for now I combined the bids and reserve price}.  This leads to (quasi-linear) utility of 
\begin{align}\label{eq:mu}\mu_n(\mathbf b) = \sum_{m=1}^{x_n(\mathbf b)} \big(v_{n,m} -b_{n,m}\big)\,\end{align}
for bidder $n$.

%The auctioneer announces $\m$ units of a good for sale. Each player $i$ submits bids $\vec{b}_{i} = (b_{i,1}, \ldots, b_{i,\m})$, where $b_{i,j}$ 
 %is player $i$'s bid for $j$-th unit.
%	The auctioneer sorts  the bids in decreasing order. Then   for each $j = 1, \ldots, \m$,  the auctioneer allocates the $j$-th unit to the player that submitted the $j$-th highest bid, charging them a price equal to the $(\m+1)$-th highest bid.

\textbf{Repeated Setting.} In this work, we consider a repeated setting where the pay-as-bid auction is run over the course of $T$ rounds. We denote the bid of bidder $n$ in the $t$-th auction ($t\in [T]$) by ${\bf b}_n^t = (b_{n, m}^t)_{n\in [N], m\in [M]}$ and define $\mathbf b^t = ((\mathbf b_n^t)_{n\in [N]}; r^t)$, where $r^t$ is the reserve price in auction $t$. Similarly, we define $\mathbf b^t_{-n} = ((\mathbf b_i^t)_{i\in [N], i\ne n}; r^t)$ as the bids submitted by all the bidders expect bidder $n$ in auction $t$, and reserve prices $r_t$.



\textbf{Offline Setting.} In the offline setting, we aim to optimize the biding strategy of a bidder $n$ while having access to $H_T :=(\mathbf b^1_{-n}, \mathbf b^2_{-n}, \ldots , \mathbf b^T_{-n})$, which is the submitted bids by the other bidders and reserve prices in the past $T$ rounds. Mathematically speaking, we fix a bidder $n$, and we optimize  a bid vector $\mathbf b_n$ that maximizes the bidder $n$'s cumulative utility over $T$ rounds with competing bids and reserve prices are $H_T$:
\begin{align}\tag{Offline}\label{eq:offline}
    \max_{\mathbf b_n } \sum_{t=1}^T \mu_n ((\mathbf b_{-n}^t, \mathbf b_n)) \qquad  \text{s.t.} \qquad b_{n,1}\ge  \ldots \ge b_{n, M}\ge 0\,.\end{align}
{\color{red} todo: please motivate this setting and say what result we will have here and where}

\textbf{Online  Setting.} In the online setting, we again fix a bidder $n$, and we aim to 



{\color{red} discussion here should be written so that we can use it for both offline and online settings }
We consider $\Nround$ rounds of homogeneous multi-unit auctions, each with $\Nitem$ items to be allocated across $N$ agents. In round $\nround$, bidder $n$ is endowed with weakly decreasing marginal valuation profile $\bm{v}^{n, \nround} \in \{\bm{v}: 1 \geq v_1 \geq \ldots \geq v_\Nitem \geq 0\} \equiv [0, 1]^\Nitem$. {\color{red} we don't need discretization for the offline setting. So, I suggest we consider the continous setting here in the model section and when it comes to the learning section, we talk about discretization} Each bidder submits weakly decreasing bids $\bm{b}^{n, \nround} \in \{\bm{b}: 1 \geq b_1 \geq \ldots \geq b_\Nitem \geq 0, b_\nitem \in \mathcal{B} \forall \nitem \in [\Nitem]\}$, where the set of allowable bids $\mathcal{B} = \{B_1,\ldots,B_{|\mathcal{B}|}\}$ with $0 = B_1 < \ldots < B_{|\mathcal{B}|} = 1$ denotes some discretization of $[0, 1]$. We abuse notation and denote this set of non-decreasing $\mathcal{B}$-restricted bids as $\mathcal{B}^\Nitem$. The auctioneer selects anonymous reserve price $\pi^\nround \in \mathcal{B}$ which filters out all bids strictly below $\pi$ from consideration. Considering only bids at least $\pi^\nround$, agents are allocated some number of items $x(\bm{b}^{n, \nround}, \bm{b}^{-n, \nround}, \pi^\nround)$ equal to the number of bids within the $\Nitem$ largest bids. Here, $\bm{b}^{-n, \nround}$ denotes the largest $\Nitem$ bids among all other agents in decreasing order and we again abuse notation to let $\mathcal{B}^{-\Nitem}$ denote the set of possible $\bm{b}^{-n, \nround}$. We also assume tie-breaks are settled using a public knowledge, deterministic tie-breaking mechanism. Assuming agent $n$ wins $x^{n, \nround} = x(\bm{b}^{n, \nround}, \bm{b}^{-n, \nround}, \pi^\nround)$ items, the utility $\mu(\bm{v}^{n, \nround}, \bm{b}^{n, \nround}, \bm{b}^{-n, \nround}, \pi^\nround)$ is given by the difference in reward $\sum_{\nitem=1}^{x^{n, \nround}} v^{n, \nround}_\nitem$ and their payment $\sum_{\nitem=1}^{x^{n, \nround}}b^{n, \nround}_\nitem$. The welfare and revenue of the auction is equal to the sum over all agents' rewards and payments respectively. At the end of each auction $\nround$, the auctioneer reveals market clearing price $c^\nround = \max(b^{n, \nround}_{x^{n, \nround}}, b^{-n, \nround}_{x^{n, \nround}+1}, \pi^\nround)$, defined as the maximum of $\pi^\nround$ and the lowest winning bid round $\nround$. Agents additionally observe their own allocation $x^{n, \nround}$ for all $n \in [N]$. We define the set of information known to agent $n$ at round $\nround$ before submitting their bid to be $H^{n, \nround} = v^{n, \nround} \cup \{(v^{n, \tau}, x^{n, \tau}, c^\tau)\}_{\tau \in [\nround - 1]}$. The set of repeated auctions is described succinctly as follows:

% Algorithm
\begin{algorithm}[t]
	\KwIn{{\color{red} what is this? why do we have an algorithm  here?}Valuations $\{\bm{v}^{n, \nround}\}_{n \in [N], \nround \in [\Nround]}$ for $\bm{v}^{n, \nround} \in \{\bm{v}: 1 \geq v_1 \geq \ldots \geq v_\Nitem \geq 0\}$, Bids $\{\bm{b}^{n, \nround}\}_{n \in [N], \nround \in [\Nround]}$ for $\bm{b}^n \in \mathcal{B}^\Nitem,$ Reserves $\{\pi^\nround\}_{\nround \in [\Nround]}$}
	\KwOut{Aggregate utilities $\{\mu^n\}_{n \in [N]}$, aggregate welfare $\sum_{n = 1}^N \textsc{Reward}^n$, total revenue $\sum_{n = 1}^N \textsc{Payment}^n$.}
	$\mu^n, \textsc{Reward}^n, \textsc{Payment}^n \gets 0$ for all $n \in [N]$\;
        $H^{n, 1} = \{\bm{v}^{n, 1}\}$ for all $n \in [N]$
	\For{$\nround \in [\Nround]$:}{
            Bidders submit bids $\bm{b}^{n, \nround}$ for all $n \in [N]$\;
    	\For{$n \in [N]$:}{
                Observe allocation $x^{n, \nround}$ and clearing price $c^\nround = \max(b^{n, \nround}_{x^{n, \nround}}, b^{-n, \nround}_{x^{n, \nround}+1}, \pi^\nround)$\;
        		% $x^{n, \nround} \gets \sum_{\nitem=1}^\Nitem \textbf{1}_{b^{n, \nround}_\nitem \geq \max(\pi^\nround, b^{-n, \nround}_\nitem)}$\;
    		$\textsc{Reward}^n \gets \textsc{Reward}^n + \sum_{\nitem=1}^{x^{n, \nround}} v^{n, \nround}_\nitem$\;
    		$\textsc{Payment}^n \gets \textsc{Payment}^n + \sum_{\nitem=1}^{x^{n, \nround}} b^{n, \nround}_\nitem$\;
                $\mu^n \gets \mu^n + \textsc{Reward}^n - \textsc{Payment}^n$\;
                $H^{n, \nround + 1} \gets H^{n, \nround} \cup (\bm{v}^{n, \nround+1}, x^{n, \nround}, c^\nround)$
    	}
        }
        \textbf{Return} $\{\mu^n\}_{n \in [N]}, \sum_{n = 1}^N \textsc{Reward}^n, \sum_{n = 1}^N \textsc{Payment}^n$
	\caption{\textsc{MUA}$(\{\bm{v}^{n, \nround}, \bm{b}^{n, \nround}, \pi^\nround\}_{n \in [N], \nround \in [\Nround]})$}
	\label{alg:MUA}
\end{algorithm}

\rigel{Perhaps mention that our censored feedback setting is equivalent to Yanjun Han's} We explain two technicalities our model selection and description. First, the tiebreaks are implicitly handled within $x^{n, \nround}$ in a deterministic fashion known to each agent. To avoid dealing with indexing issues, we perturb each bidder $n$'s bid by $(N-n)\epsilon$ for some infinitesimal $\epsilon > 0$, which has the effect of prioritizing lower indexed bidders at a negligible increase in payment. For the remainder of the paper, we will implicitly assume as shorthand that the event $\{b^{n, \nround}_\nitem = B\}$ for $B \in \mathcal{B}$ actually means $\{b^{n, \nround}_\nitem = B + (N-n)\epsilon = B'\}$ for $B' \in \mathcal{B}_n$, where agent $n$'s bid set is defined as $\mathcal{B}_n \equiv \{B: B + (N-n)\epsilon\}_{B \in \mathcal{B}}$ as opposed to $\mathcal{B}$. Under this assumption, we can decompose $x^{n, \nround}$ as a function of $\bm{b}^{n, \nround}, \bm{b}^{-n, \nround}, \pi^\nround$ which greatly simplifies the offline and online learning algorithms and corresponding analyses. Second, we assume that information regarding the reserve price is only revealed after each auction via the clearing price. We will later consider variants of the auction where $H^{n, \nround} = (v^{n, \nround}, \pi^\nround) \cup \{(v^{n, \tau}, x^{n, \tau}, c^\tau)\}_{\tau \in [\nround - 1]}$ the reserve price is announced at the beginning of each auction, where the analysis is slightly more complicated. As reserve prices are selected adaptively by the auctioneer in many real world situations, from the point of view of the agents, we assume that reserve prices are be generated adversarially.
% We also discuss generalizations to discriminatory reserves $\{\pi^\nround_\nitem\}_{\nitem \in [\Nitem], \nround \in [\Nround]}$ or non-anonymous reserves $\{\pi^\nround_n\}_{n \in [N], \nround \in [\Nround]}$.

\subsection{Problem Statement}

The objective of each agent $n$ is to select a sequence of bid vectors $\{\bm{b}^{n, \nround}\}_{n \in [N], \nround \in [\Nround]}$ that maximizes their aggregate utility $\mu^n$. Optimizing $\mu^n$ is trivial in the offline setting where each of $\bm{b}^{-n, \nround}$ and $\pi^\nround$ are revealed to agent $n$ in advance and thus can correspondingly select the optimal $\bm{b}^{n, \nround}$ for each $\nround \in [\Nround]$. Rather than the optimal sequence of bid vectors, we can instead consider the optimal fixed bid vector which we show later can be computed using a dynamic program efficiently. Of course, $\bm{b}^{-n, \nround}$ and $\pi^\nround$ for all $\nround \in [\Nround]$ are not known beforehand and are instead revealed in an online fashion. As such, the agents must learn how to bid optimally during the sequence of auctions only given knowledge of historic auction results---which we will formalize shortly what this means---and their current valuation profile. The performance of an agent's learning strategy will be measured in terms of regret---the difference between their expected utility under their learning strategy and under the hindsight optimal fixed bid vector. In particular, agents will select a bid vector sampled from $F^{n, \nround}(H^{n, \nround}) = F^{n, \nround} \in \Delta(\mathcal{B}^\Nitem)$ where $\Delta(S)$ denotes the set of all valid probability measures over set $S$.
\begin{align*}
    \textsc{Regret}^{n, \Nround}(F^{n, \nround} \mid \{\bm{v}^{n, \nround}\}_{\nround \in [\Nround]} = \max_{\bm{b}^n \in \mathcal{B}^\Nitem} \sum_{\nround=1}^\Nround \mu(\bm{v}^{n, \nround}, \bm{b}^n, \bm{b}^{-n, \nround}, \pi^{\nround}) - \mathbb{E}_{\bm{b}^{n, \nround} \sim F^{n, \nround}} \sum_{\nround=1}^\Nround \mu (\bm{v}^{n, \nround}, \bm{b}^{n, \nround}, \bm{b}^{-n, \nround}, \pi^\nround)
\end{align*}
Where we assume that $\bm{v}^{n, \nround}$ (which can be thought of as a context as it is revealed at the start of each round), $\bm{b}^{-n, \nround}$ and $\pi^\nround$ can be selected by an adaptive adversary. In the bandit case, we assume that $\bm{v}^{n, \nround}$ are fixed to be $\bm{v}^\nround$. according to some known distribution. For simplicity, we omit the arguments when they are clear from context: $\textsc{Regret}^{n, \Nround} = \textsc{Regret}^{n, \Nround}(F^{n, \nround} \mid \{\bm{v}^{n, \nround}\}_{\nround \in [\Nround]}$. We wish to derive a learning algorithm---construct functions $F^{n, \nround}$---that achieves an upper bound on $\textsc{Regret}^{n, \Nround}$ that is polynomial (or better) in $\Nitem$ and sub-linear in $\Nround$. Assuming that all agents obey this learning algorithm, we derive bounds on the expected revenue and expected welfare for a sequence of reserves $\{\pi^{\nround}\}_{\nround \in [\Nround]}$ and compare these guarantees to the announced reserves setting.

\subsection{Contributions}

Our primary contribution is representing the allocation and utility functions in a form that enables maximal cross learning between bid vectors and valuations. In particular, we define $x^{n, \nround} = \sum_{\nitem=1}^\Nitem \textbf{1}_{b^{n, \nround}_\nitem \geq \max(\pi^\nround, b^{-n, \nround}_\nitem)}$ which decomposes the utility function as a sum over the the utilities per slot $\nitem$. 
We then construct an efficient $O(\Nitem |\mathcal{B}|^2)$ time and $O(\Nitem^2 |\mathcal{B}|)$ space complexity dynamic program that computes the hindsight optimal bid vector. In this dynamic program, we show a crucial (conditional) independence between agent $n$'s utility corresponding to their bid in the $\nitem$'th slot $b^{n, \nround}_\nitem$ and their bid in the $\nitem+1$'st slow $b^{n, \nround}_{\nitem + 1}$. With this, we decouple the aggregate utility of a bid vector $\bm{b}^{n}$ as a function of the per-slot aggregate utilities. This allows us to efficiently implement exponential weights in the full information setting, which achieves regret $O(\Nitem \sqrt{T \log |\mathcal{B}|}$, whilst allowing for adversarially generated valuation profiles $\{\bm{v}^{n, \nround}\}_{\nround \in [\Nround]}$. In the bandit setting, one may be hopeful to be able to apply the same decoupling argument to graph-feedback learning algorithms, such as $\textsc{Exp3.G}$ or $\textsc{Exp3.SET}$ \rigel{cite}, which would make use of side information in the form of $c^\nround$. Unfortunately, the learner never observes the entire feedback graph and therefore cannot construct meaningful, polynomially bounded variance utility estimates. Instead, we can implement Follow-the-Regularized-Leader (FTRL) style algorithms, such as $\textsc{O-REPS}$ or $\textsc{Component Hedge}$ \rigel{cite}, which achieves low regret $O(\Nitem |\mathcal{B}|\sqrt{T\log|\mathcal{B}|})$ and polynomial time and space complexity. However, these algorithms must assume a static valuation profile and require additional setup.

% We apply this idea again in the online learning setting. In particular, we derive a decoupled $\textsc{Exp3}$ algorithm that exploits cross learning (See algorithm $\textsc{Exp3.G}$ in \rigel{Cite paper}) which achieves small regret whilst retaining polynomial time and space complexities despite the combinatorially large bid space. We do this by upper bounding the independence number of any possible bid vector network by realizing that the utility function can be fully characterized by the $\Nitem$ largest bids amongst $\bm{b}^{-n, \nround}$. Lastly, we show how to convert the output of our decoupled $\textsc{Exp3.G}$ into a valid (weakly monotonic) bid vector.
