
% \newtheorem{definition}{Definition}
\newtheorem{observation}{Observation}
\newcommand{\prob}{\mathbb{P}}
\newcommand{\Nitem}{M}
%

\newcommand{\nitem}{m}
\newcommand{\Nround}{T}
\newcommand{\nround}{t}
% \newcommand{\rigel}[1]{{\color{blue}[\textsc{Rigel}: \emph{#1}]}}
% \newcommand{\negin}[1]{{\color{red}[\textsc{NG}: \emph{#1}]}}
\newcommand{\rigel}[1]{{[#1]}}
\newcommand{\negin}[1]{{[#1]}}
%\usepackage{natbib}
% \bibpunct[, ]{(}{)}{,}{a}{}{,}%
% \def\bibfont{\small}%
 %\def\bibsep{\smallskipamount}%
 %\def\bibhang{10pt}%
 %\def\newblock{\ }%
 %\def\BIBand{and}%

%\usepackage[utf8]{inputenc} % allow utf-8 input
%\usepackage[T1]{fontenc}  
%\documentclass[format=acmsmall, review=false]{acmart}
\documentclass[msom,nonblindrev]{informs3}
%\usepackage[toc,page]{appendix}
\usepackage{hyperref}
\usepackage{url}
 \usepackage{natbib}
 \bibpunct[, ]{(}{)}{,}{a}{}{,}%
 \def\bibfont{\small}%
 \def\bibsep{\smallskipamount}%
 \def\bibhang{24pt}%
 \def\newblock{\ }
%\documentclass[12pt]{report}
\usepackage{bm}
%\usepackage{setspace}
%\renewcommand{\baselinestretch}{1.5} 
\usepackage{zref-totpages}
\usepackage{booktabs} % For formal tables
\usepackage[ruled]{algorithm2e} % For algorithms
%\usepackage{graphicx}
%\usepackage{caption}
\usepackage{subcaption}
\renewcommand{\algorithmcfname}{ALGORITHM}
%\SetAlFnt{\small}
%\SetAlCapFnt{\small}
%\SetAlCapNameFnt{\small}
%\SetAlCapHSkip{0pt}
%\IncMargin{-\parindent}
%\pagenumbering{gobble}
% Choose a citation style by commenting/uncommenting the appropriate line:
%\setcitestyle{acmnumeric}
%\setcitestyle{authoryear}
\OneAndAHalfSpacedXI


\RequirePackage{amssymb,amsmath,ifthen,url,graphicx,color,array,theorem}
\TheoremsNumberedThrough     % Preferred (Theorem 1,
\ECRepeatTheorems

\begin{document}
% Title. Note the optional short title for running heads. In the interest of anonymization, please do not include any acknowledgements.

% Anonymized submission.
%\author{Submission XYZ}

% Abstract. Note that this must come before \maketitle.
\TITLE{Learning in Repeated Multi-Unit Pay-As-Bid Auctions}
\ARTICLEAUTHORS{%
\AUTHOR{Rigel Galgana}
\AFF{Operations Research Center, Massachusetts Institute of Technology, \EMAIL{rgalgana@mit.edu}, \URL{}}
\AUTHOR{Negin Golrezaei}
\AFF{Sloan School of Management, Massachusetts Institute of Technology,  \EMAIL{golrezaei@mit.edu}, \URL{}}
} 

\ABSTRACT{

Motivated by Carbon Emissions Trading Schemes, 
Treasury Auctions, Procurement
Auctions, and Wholesale Electricity Markets, which all involve the auctioning of homogeneous multiple units, 
we consider the problem of learning how to bid in repeated multi-unit pay-as-bid auctions. In each of these auctions, a large number of (identical) items are to be allocated to the largest submitted bids, where the price of each  of the winning bids is equal to the bid itself. In this work, we study the problem of optimizing bidding strategies from the perspective of a single bidder.


This problem is challenging due to the  combinatorial nature of the action space. We overcome this challenge by focusing on the offline setting, where the bidder optimizes their vector of bids while only having access to the past submitted bids by other bidders. We show that the optimal solution to  the offline problem can be obtained using a polynomial time dynamic programming (DP) scheme under which the bidder's utility is decoupled across units. We leverage the structure of the DP scheme to design online learning algorithms with polynomial time and space complexity under full information and bandit feedback settings. Under these two feedback structures, we achieve an upper bound on regret of $O(\Nitem \sqrt{\Nround \log |\mathcal{B}|})$ and $O(\Nitem\sqrt{|\mathcal{B}|\Nround\log |\mathcal{B}|})$ respectively, where $\Nitem$ is the number of units demanded by the bidder, $\Nround$ is the total number of auctions, and $|\mathcal{B}|$ is the size of the discretized bid space. We accompany these results with a regret lower bound, which match the linear dependency in $\Nitem$.

 Our numerical results suggest that when all agents behave according to our proposed no regret learning algorithms, the resulting market dynamics mainly converge to a welfare maximizing equilibrium where bidders submit uniform bids. We further show that added competition reduces the impact of strategization and bidders converge more rapidly to a
higher revenue and welfare steady state. Lastly,  our experiments  demonstrate that the pay-as-bid auction consistently generates significantly higher revenue compared to its popular alternative, the uniform price auction. This  advantage positions the pay-as-bid auction as an  appealing auction format in settings where earning high revenue holds significant social value, such as the Carbon Emissions Trading Scheme.
\noindent

\textbf{Keywords.} 
Multi-unit pay-as-bid auctions, Bidding strategies, Regret analysis, Market dynamics.



}

\maketitle

% Title page for title and abstract only.
%\begin{titlepage}

%\maketitle

%\end{titlepage}

% Paper body
\input{todo.tex}
\input{introduction.tex}
%\input{problem_statement.tex}
\input{problem_statement2.tex}
%\input{offline.tex}
% \input{offline2.tex}
% \input{online.tex}
% \input{online_reps2.tex}
\input{online_reps3.tex}
\input{experiments.tex}
%\input{discussion.tex}
% \input{conclusions.tex}
\input{conclusions_2.tex}
\footnotesize{
\bibliographystyle{ACM-Reference-Format}
\bibliography{ref.bib}
}
\newpage
% \begin{APPENDICES}
\input{appendix.tex}
% \section{Switching times}

% \section{Supplementary materials}
% \end{APPENDICES}
\end{document}
