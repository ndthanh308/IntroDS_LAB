\section{Bid Optimization: Offline Setting}

We first consider the offline full information setting, where we derive an algorithm that computes the global hindsight optimal bid vector; i.e. the learner is given $\bm{b}^{-n, \nround}$ and $\pi^\nround$ for all $\nround \in [\Nround]$. The full information offline algorithm not only serves as a way to compute the benchmark for regret, but also reveals how cross learning can be done efficiently in the online, bandit algorithm. Next, we show how the full information online learning problem can be solved efficiently with a decoupled exponential weights algorithm, where the learner at round $\nround$ is only given $\bm{v}^{n, \nround}$, and $\{\bm{b}^{-n, \tau}, \pi^\tau\}_{\tau < \nround}$. In the following section, we show how the bandit setting, where agents must determine their next bid $\bm{b}^{n, \nround}$ only as a function of the censored feedback $H^{\nround}$, can be solved efficiently using applying our decoupled exponential weights algorithm.

% To approach this learning problem, we first construct a family of feedback graphs, provide an upper bound on the independence number of all such graphs, and then apply a variant of $\textsc{Exp3}$ that operates on feedback graphs which has regret dependent on the independence number of the underlying graph. We first describe the full information offline algorithm.

\subsection{Offline Setting}

Agent $n$ can think must construct a utility maximizing bid vector $\bm{b}$ as a function of $(\bm{b}^{-n, \nround})_{\nround \in [\Nround]}$ and $(\pi^\nround)_{\nround \in [\Nround]}$ for a given valuation profile $\bm{v}$. Following such a strategy in the (full information) online setting would be equivalent to Follow-the-Leader. The aggregate utility for bidder $n$ with valuation profile $\bm{v}$ by bidding in all rounds with bid $\bm{B} \in \mathcal{B}^\Nitem$ is given by $\mu^{n, \Nround}(\bm{B}) = \sum_{\nround=1}^\Nround \mu(\bm{v}, \bm{B}, \bm{b}^{-n, \nround}, \pi^\nround) = \sum_{\nround=1}^\Nround \sum_{\nitem=1}^{x(\bm{b}, n, t)} (v_\nitem - B_\nitem)$, where $x(\bm{B}, n, t)$ is agent $n$'s allocation at round $\nround$ if they bid $\bm{B}$. We construct a dynamic programming solution that recovers the optimal bid vector $\bm{b}$ as a function of the previous rounds' outcomes. We define for each $\nround \in [\Nround]$:
\[
w^{\nround}_\nitem(B) = \textbf{1}_{B > \max(b^{-n, \nround}_{\nitem}, \pi^\nround)} (v_\nitem - B) \quad \text{and} \quad W^{\Nround}_\nitem(B) = \sum_{\nround=1}^\Nround w^{\nround}_\nitem(B)
\]
Here, $w^\nround_\nitem(B)$ is the marginal utility and $W^\Nround_\nitem(B)$ the aggregate utility gained across historical auctions from the winning the $\nitem$'th item with bid $b$ respectively. Note that we can rewrite $\mu^{n, \Nround}(\bm{b}) = \sum_{\nround=1}^\Nround \sum_{\nitem=1}^\Nitem w_\nitem^\nround(b_\nitem) = \sum_{\nitem=1}^\Nitem W_\nitem^\Nround(b_\nitem)$. We are now ready to construct our dynamic programming table(s).
\[
V^{\Nround}_\nitem(B) = \max_{B' \in \mathcal{B}; B' \leq B} W^{\Nround}_\nitem(B') + V^{\Nround}_{\nitem+1}(B') \quad \text{and} \quad U^{\Nround}_\nitem(B) = [b^{*, \Nround}_\nitem, U^{\Nround}_{\nitem+1}(B^{*, \Nround}_\nitem)]
\] 
$V_\nitem^\Nround$ denotes the optimal utility gained across all auctions from winning the $\nitem$'th item with bid $B$ and all items $\nitem+1,\ldots,\Nitem$ with base case $V^{\Nround}_\Nitem(B) = W^{\Nround}_\Nitem(B)$ and $U_\nitem^\Nround$ the corresponding optimal partial bid vector. Here, $B^{*, \Nround}_\nitem = \text{argmax}_{B' \in \mathcal{B}; B' \leq B} W^{\Nround}_\nitem(B') + V^{\Nround}_{\nitem+1}(B')$. The optimal utility is given by $V^{\Nround}_1(\max(\mathcal{B}))$. By using the recursive form for $V^{\Nround}_{\nitem}(B)$ and $U^{\Nround}_{\nitem}(B)$, computing tables $V^{\Nround}$ and $U^{\Nround}$ has time complexity of $O(\Nitem |\mathcal{B}|^2)$. As there are $\Nitem|\mathcal{B}|$ table entries, and each entry of $U^{\Nround}_\nitem$ is of length $O(\Nitem)$, the space complexity is $O(\Nitem^2|\mathcal{B}|)$. If we are computing these tables for each bidder, then the time and space complexities increase by a factor of $N$. 

\begin{algorithm}[t]
	\KwIn{Valuation $\bm{v}$ for $\bm{v} \in [0, 1]^\Nitem$, Other Bids $\{\bm{b}^{-n, \nround}\}_{\nround \in [\Nround]}$ for $\bm{b}^{-n, \nround} \in \mathcal{B}^{-\Nitem}$, Reserves $\{\pi^\nround\}_{\nround \in [\Nround]}$}
	\KwOut{Global optimal bid vector $\text{argmax}_{\bm{B} \in \mathcal{B}^\Nitem} \mu^{n, \Nround}(\bm{b})$ and its corresponding utility.}
	$W^{\Nround}_\nitem(B) \gets \sum_{\nround=1}^\Nround \textbf{1}_{B \geq \max(b^{-n, \nround}_{\nitem}, \pi^\nround)} (v_\nitem - b) \quad \forall B \in \mathcal{B}, \nitem \in [\Nitem]$\;
        $V^{\Nround}_{\Nitem+1}(B) \gets 0$ and $U^{\Nround}_{\Nitem+1}(B) \gets [ \hspace{2mm} ] \quad  \forall b \in \mathcal{B}$\;
	\For{$\nitem \in \{\Nitem,\ldots,1\}$:}{
    	\For{$B \in \mathcal{B}$:}{
                $B^* \gets \text{argmax}_{B' \in \mathcal{B}; B' \leq B}W^{\Nround}_\nitem(B') + V^{\Nround}_{\nitem+1}(B') \quad \forall B \in \mathcal{B}$\;
                $V^{\Nround}_\nitem(B) \gets W^{\Nround}_\nitem(B^*) + V^{\Nround}_{\nitem+1}(B^*)$\;
                $U^{\Nround}_\nitem(B) \gets [B^*, U^{\Nround}_{\nitem+1}(B^*)]$\;
    	}
        }
        \textbf{Return} $U^{\Nround}_1(\max(\mathcal{B}))$, $V^{\Nround}_1(\max(\mathcal{B}))$
	\caption{\textsc{OfflineFull}$(\bm{v}, \{\bm{b}^{-n, \nround}, \pi^\nround\}_{\nround \in [\Nround]})$}
	\label{alg: Offline Full}
\end{algorithm}

\begin{theorem}
    In the full information feedback setting, Algorithm~\ref{alg: Offline Full} returns the global utility maximizing bid vector for a bidder with valuations $\bm{v}$, other bids $\{\bm{b}^{-n, \nround}\}_{\nround \in [\Nround]}$, and reserves $\{\pi^{\nround}\}_{\nround \in [\Nround]}$.
\end{theorem}

\begin{proof}
    We proceed by noting that $w^{\nround}_{\nitem}(B)$, the utility obtained in auction $\nround$ from winning item $\nitem$, is independent of the utility gained from any other items, conditional on the weakly monotonic bids condition. As the aggregate utilities between auctions are also independent, the time-aggregate optimal utilities $V^{\nround}_{\nitem}(B)$ can be constructed as a recursively as a function of the sum of the per-slot time aggregate utilities. To show that we can obtain the optimal utilities, we have:
    \begin{align}
        V^{\Nround}_\nitem(B) &= \max_{B_\nitem\geq\ldots\geq B_\Nitem; B_j \leq B \forall j \in [\nitem,\ldots,\Nitem]} \sum_{\nitem' = \nitem}^\Nitem W^{\Nround}_{\nitem'}(B_{\nitem'})\\
        &= \max_{B_{\nitem}\geq\ldots\geq B_\Nitem; B_j \leq B \forall j \in [\nitem,\ldots,\Nitem]} W^{\Nround}_{\nitem}(B_\nitem ) +  \sum_{\nitem' = \nitem+1}^\Nitem W^{\Nround}_{\nitem'}(B_{\nitem'})\\
        &= \max_{B' \in \mathcal{B}; B' \leq B} W^{\Nround}_\nitem(B') + V^{\Nround}_{\nitem+1}(B')
    \end{align}
    Where the last equality follows from the conditional independence between utilities obtained per slot. Since we have that $V^{\nround}_{\Nitem}(B ) = W^{\Nround}_{\Nitem} (B )$ trivially correct from the base case, the optimality of $V^{\Nround}_\nitem(B)$ follows from induction.
\end{proof}

With this algorithm, we have established a method to obtain the hindsight optimal utility for which to gauge the efficacy of our online algorithms empirically. We note that the above algorithm generalizes to the full information, announced reserve setting, where we are optimizing the utility with respect to reserve $\pi$ by replacing all instances of $\pi^\nround$ with $\pi$.

\subsection{Online Setting}

Now we consider the problem of optimally learning how to bid in an online fashion under full information feedback. One obvious solution is applying exponential weights over the entire set of bid vectors, which has per-round rewards bounded in $[-\Nitem, \Nitem]$ (as $\sum_{\nitem=1}^\Nitem (v^n_\nitem - \max_{B \in \mathcal{B}} B) \geq -\Nitem$ and $\sum_{\nitem=1}^\Nitem (v^n_\nitem - \min_{B \in \mathcal{B}} B) \leq \Nitem$). While this achieves small regret $O(\Nitem \sqrt{T \log |\mathcal{B}|})$, the primary challenge here is that the bid space $\mathcal{B}^\Nitem$ is exponentially large and naively tracking and updating these weights is expensive. We apply ideas from solutions to the Stochastic Shortest Paths problem (SSP) to instead associate weights with each $(\nitem, B)$ pair. We then show how to sequentially sample $(\nitem+1, B')$ given $(\nitem, B)$ for $B' \geq B$ to recover the entire bid vector $\bm{b}^{n, \nround}$.  % One way to circumvent this issue is by modeling the space of bids $\mathcal{B}^\Nitem$ as a layered graph and then applying ideas from Stochastic Shortest Path (SSP) problem. We will afterwards show that we can save a factor of $|\mathcal{B}|$ time and memory by representing the policy over edges in a lower dimensional space. 
In exponential weights, the learner selects at round $\nround+1$ some action $\bm{B}$ proportional to its $\eta$-exponentially weighted historical utility $\mu^{n, \nround}(B)$. However, using our representation of $\mu^{n, \nround}(B)$ as a function $w_\nitem^{n, \tau}(B)$ from the previous section, we have:
\begin{align}
    \prob_{EW(\eta)}^{n, \nround}(\bm{B}) = \exp(\eta \mu^{n, \nround}(\bm{B})) = \exp(\eta \sum_{\tau=1}^\nround \sum_{\nitem=1}^\Nitem w_\nitem^\tau(B_\nitem)) = \exp(\eta \sum_{\nitem=1}^\Nitem W_\nitem^\nround(B_\nitem)) = \sum_{B \in \mathcal{B}} S_1(B)
\end{align}
Where $S_1(B)$ denotes the sum of exponentially weighted utilities over all bid vectors $\bm{b}$ such that $b_1 = B$. Now we go one step further to show the recursive nature of these bid vector utilities. Let $S_2(B)$ denote the sum of exponentially weighted utilities corresponding to slots $2$ through $\Nitem$ over all partial bid vectors $b_2,\ldots,b_\Nitem \in \mathcal{B}^{\Nitem - 1}$ satisfying monotonicity and also $b_2 = B$. Then we can write $S_1(B)$ in terms of $S_2(\cdot)$:
\begin{align}
    S_1(B) &= \sum_{\{\bm{b}: \bm{b} \in \mathcal{B}^\Nitem, b_1 = B\}} \exp(\eta \mu^{n, \nround}(\bm{b})) \\
    &= \sum_{\{\bm{b}: \bm{b} \in \mathcal{B}^\Nitem, b_1 = B\}} \exp(\eta \sum_{\nitem=1}^\Nitem W_\nitem^\nround(b_\nitem))\\
    &= \exp(\eta W_1^\nround(B)) \sum_{\{\bm{b}: \bm{b} \in \mathcal{B}^\Nitem, b_1 = B\}} \exp(\eta \sum_{\nitem=2}^\Nitem W_\nitem^\nround(b_\nitem))\\
    &= \exp(\eta W_1^\nround(B)) \sum_{B \geq b_2 \geq \ldots \geq b_\Nitem} \exp(\eta \sum_{\nitem=2}^\Nitem W_\nitem^\nround(b_\nitem))\\
    &= \exp(\eta W_1^\nround(B)) \sum_{B' \leq B} S_2(B')
\end{align}
With the following base case, we can generalize the above idea to slot $\nitem$ to obtain the key recursion.
\begin{align}
    S_\Nitem(B) = \exp(\eta W_\Nitem^\nround(B)) \quad \text{and} \quad S_\nitem(B) = \exp(\eta W_\nitem^\nround(B)) \sum_{B' \leq B} S_{\nitem + 1}(B') 
\end{align}
In conclusion, we can recover all of the exponentially weighted partial utilities $S_{\nitem}(B)$ given $\bm{W}^\nround$. Once we have computed $S_{\nitem}(B)$, we can sample $\bm{b}$ according to its exponentially weighted utility $\exp(\eta \mu{n, \nround}(\bm{b})$ by sequentially sampling each $b_1,\ldots,b_\Nitem$.

\begin{algorithm}[t]
	\KwIn{Learning rate $\eta > 0$, Aggregate per-slot utilities $\bm{W}^\nround \equiv \{W_\nitem^\nround(B)\}_{\nitem \in [\Nitem], B \in \mathcal{B}}$.}
	\KwOut{Bid vector $\bm{b}$ sampled with probability $\exp(\eta \mu^{n, \nround}(\bm{b})$}
	$S_\Nitem(B) \gets \exp{(\eta W^\nround_{\Nitem}(B))}$ for all $B \in \mathcal{B}$\;
	\For{$\nitem \in [\Nitem-1,\ldots,1], B \in \mathcal{B}$:}{
            $S_\nitem(B) \gets \exp(\eta W_\nitem^\nround(B)) \sum_{B' \leq B} S_{\nitem + 1}(B')$
        }
        $b_0 \gets \max_{B \in \mathcal{B}} B$\;
        \For{$\nitem \in [\Nitem]:$}{
            $b_\nitem \sim [S_\nitem(B)]_{B \in \mathcal{B}; B \leq b_{\nitem-1}}$
        }
        \textbf{Return} $\bm{b} = (b_1,\ldots,b_\Nitem)$
	\caption{\textsc{DecoupledSampler}$(\bm{W}^\nround, \eta)$}
	\label{alg: Decoupled Sampler}
\end{algorithm}

\begin{theorem}
    Algorithm \ref{alg: Decoupled Sampler} samples $\bm{b}$ with probabilities equal to the exponential weights distribution $\exp(\eta \mu^{n, \nround}(\bm{b})$.
\end{theorem}

\begin{proof}
    Let $b_0 = B_0 = \max_{B \in \mathcal{B}} B$. We have that $\prob_{\textsc{DS}}(\bm{B})$, the probability that our decoupled sampling Algorithm \ref{alg: Decoupled Sampler} returns bid vector $\bm{B} \in \mathcal{B}^\Nitem$, is given by:
    \begin{align}
        \prob_{\textsc{DS}}(\bm{B}) &= \prob(b_1 = B_1) \prob(\bm{b}_{2:\Nitem} = \bm{B}_{2:\Nitem} \mid b_1 = B_1)\\
        &= \frac{S_1(B_1)}{\sum_{B \leq B_0} S_1(B)} \prob(\bm{b}_{2:\Nitem} = \bm{B}_{2:\Nitem} \mid b_1 = B_1)\\
        &= \frac{S_1(B_1)}{\sum_{B \leq B_0} S_1(B)} \prob(b_2 = B_2 \mid b_1 = B_1) \prob(\bm{b}_{3:\Nitem} = \bm{B}_{3:\Nitem} \mid b_1 = B_1, b_2 = B_2) \\
        &= \frac{S_1(B_1)}{\sum_{B \leq B_0} S_1(B)} \frac{S_2(B_2)}{\sum_{B \leq B_1} S_2(B)} \prob(\bm{b}_{3:\Nitem} = \bm{B}_{3:\Nitem} \mid b_1 = B_1, b_2 = B_2) \\
        &= \frac{S_1(B_1)}{\sum_{B \leq B_0} S_1(B)} \frac{S_2(B_2)}{\sum_{B \leq B_1} S_2(B)} \prob(\bm{b}_{3:\Nitem} = \bm{B}_{3:\Nitem} \mid b_2 = B_2) \ldots
    \end{align}
    Continuing the above expansion and then applying the definition of $S_\nitem(B)$, we obtain:
    \begin{align}
        \prob_{\textsc{DS}}(\bm{B}) = \prod_{\nitem=1}^\Nitem \frac{S_\nitem(B_\nitem)}{\sum_{B \leq B_{\nitem-1}} S_\nitem(B)} = \prod_{\nitem=1}^\Nitem \frac{\exp(\eta W_\nitem^\nround(B_\nitem)) \sum_{B \leq B_{\nitem}} S_{\nitem+1}(B)}{\sum_{B \leq B_{\nitem-1}} S_\nitem(B)} = \prod_{\nitem=1}^\Nitem \exp(\eta W_\nitem^\nround(B_\nitem))
    \end{align}
    Here, the final term simplifies to $\prob_{EW(\eta)}^{n, \nround}(\bm{B}) = \exp(\eta \mu^{n, \nround}(\bm{B}))$ which is precisely the exponentially weighted utility associated with bid vector $\bm{B}$.
\end{proof}

Note that this decomposition is similar to the loop-free path kernels method for SSP as detailed in \rigel{Cite Takimoto Path kernels/multiplicative weights paper}. The primary difference is that we consider weights over nodes rather than over edges, as in our setting, the reward associated with selecting bid $B'$ in slot $\nitem+1$ is independent of selecting bid $B \geq B'$ in slot $\nitem$. By doing so, we save a factor of $|\mathcal{B}|$ time and space as we store and update weights corresponding to $O(\Nitem |\mathcal{B}|)$ possible $(\nitem, B)$ slot-bid pairs rather than $O(\Nitem |\mathcal{B}|^2)$ possible $(\nitem, B, B')$ slot-bid-next bid triplets. Now, we state the full decoupled exponential weights algorithm and its associated regret, run-time, and space complexity.

\begin{algorithm}[t]
	\KwIn{Learning rate $\eta > 0$, Adaptive Adversarial Environment $\textsc{Env}^\nround: \mathcal{H}^\nround \to [0, 1]^\Nitem \times \mathcal{B}^{-\Nitem} \times \mathcal{B}$ where $\mathcal{H}^\nround$ denotes the set of all possible historical auction results $H^\nround$ up to round $\nround$ for all $\nround \in [\Nround]$.}
	\KwOut{The aggregate utility $\sum_{\nround=1}^\Nround \mu(\bm{v}^{n, \nround}, \bm{b}^{n, \nround}, \bm{b}^{-n, \nround}, \pi^\nround)$ corresponding to a sequence of bid vectors $\bm{b}^{n, 1},\ldots,\bm{b}^{n, \Nround}$ sampled according to the exponential weights algorithm.}
	$W_\nitem^0(B) \gets 0, \textsc{NumberWon}_\nitem^0(B) \gets 0$ for all $\nitem \in [\Nitem], B \in \mathcal{B}$\;
        $H^0 \gets \emptyset$\;
	\For{$\nround \in [\Nround]$:}{
            $(\bm{v}^{n, \nround}, \bm{b}^{-n, \nround}, \pi^\nround) \gets \textsc{Env}^{\nround-1}(H^{\nround-1})$ and $\bm{b}^{n, \nround} \gets \textsc{DecoupledSampler}(\bm{W}^{\nround-1}, \eta)$\;
            Observe $\bm{v}^{n, \nround}$ and update utilities $\bm{W}^{\nround - 1} \gets \{W^{\nround-1}_{\nitem}(B) = \textsc{NumberWon}_\nitem^{\nround-1}(B) (v^{n, \nround}_\nitem - B)\}_{\nitem \in [\Nitem], B \in \mathcal{B}}$\;
            Observe $\bm{b}^{-n, \nround}, \pi^\nround$ and receive reward $\mu(\bm{v}^{n, \nround}, \bm{b}^{n, \nround}, \bm{b}^{-n, \nround}, \pi^\nround)$\;
            $\textsc{NumberWon}_\nitem^\nround(B) \gets \textsc{NumberWon}_\nitem^{\nround-1}(B) + \textbf{1}_{B > \max(b^{-n, \nround}_\nitem, \pi^\nround)}$ for all $\nitem \in [\Nitem], B \in \mathcal{B}$\;
        }
        \textbf{Return} $\sum_{\nround=1}^\Nround \mu(\bm{v}^{n, \nround}, \bm{b}^{n, \nround}, \bm{b}^{-n, \nround}, \pi^\nround)$
	\caption{\textsc{Decoupled Exponential Weights - Full Information}}
	\label{alg: Decoupled Exponential Weights}
\end{algorithm}

\begin{theorem}
    With $\eta \propto \sqrt{\frac{\log |\mathcal{B}|}{T}}$, Algorithm \ref{alg: Decoupled Exponential Weights} achieves regret $O(\Nitem \sqrt{ \Nround \log |\mathcal{B}|})$, with total time complexity $O(\Nitem |\mathcal{B}| \Nround)$ and space complexity $O(\Nitem |\mathcal{B}|)$.
\end{theorem}

\begin{proof}
    Assume a fixed valuation vector $\bm{v}$. As the rewards are bounded between $-\Nitem$ and $\Nitem$ and the state space is of size $O(|\mathcal{B}|^\Nitem)$, the exponential weights algorithm guarantees a regret upper bound $O(\eta \Nitem \Nround + \frac{\Nitem \log |\mathcal{B}|}{\eta})$ which achieves the desired regret bound with the state choice of $\eta$. Note that we can generalize this procedure to time-dependent valuations as we have full cross-learning across all possible valuation profiles $\bm{v}^{-n, \nround}$:
    \begin{align}
        W_\nitem^\nround(B) = \sum_{\tau=1}^\nround w_\nitem^\tau(B) = \sum_{\tau=1}^\nround \textbf{1}_{B \geq \max{b_\nitem^{-n, \tau}, \pi^\tau}} (v_\nitem^{n, \nround} - B) = \textsc{NumberWon}_\nitem^\nround(B)(v_\nitem^{n, \nround} - B) 
    \end{align}
    For the complexity analysis, updating and storing $\bm{W}^\nround$ and $\{\textsc{NumberWon}_\nitem^\nround(B)\}_{\nitem \in [\Nitem], B \in \mathcal{B}}$ at each $\nround$ requires $O(\Nitem |\mathcal{B}|)$ time and space. Similarly, each call to $\textsc{DecoupledSampler}$ requires computing $\{S_\nitem(B)\}_{\nitem \in [\Nitem], B \in \mathcal{B}}$, which can be done recursively in $O(\Nitem |\mathcal{B}|)$ time and space complexity (we save an additional factor of $|\mathcal{B}|$ by intermittently storing the values of $\sum_{B' \leq B} S_{\nitem+1}(B')$). Discarding old tables, the total time and space complexities of Algorithm \ref{alg: Decoupled Exponential Weights} are $O(\Nitem |\mathcal{B}| \Nround)$ and $O(\Nitem |\mathcal{B}|)$ respectively. 
\end{proof}

We remark that this algorithm works for any adversarially selected valuation profiles as the full information setting allows for perfect cross learning between valuations. While this is also true in the bandit setting, we will see that Hedge style algorithms break down.