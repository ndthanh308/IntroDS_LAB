

\section{Introduction}

%Total pages: \ztotpages

%\rigel{Things to shorten/delete: 1) Maybe remove proof of the decoupled exponential weights full information and just say how one would adapt the decoupled exponential weights bandit version to get the full information algorithm regret bound? We can keep the algorithm statements separate though. 2) Can we move/delete the proof of the path weight maximization in the offline setting and just say that it's doable in polynomial time, kind of like how you did with your other paper? 3) Also move the QSpace equivalence to the 16 page appendix? 4) We can move the stochastic setting experiment to the 16 page appendix/just remove it altogether? Might be easier just talking about market dynamics. 5) We can also remove the section with $N \in \{2, 3, 6, 12, 24, 48\}$, 6) 6) We can also remove the formal algorithm statements of the IX version and just say that we replaced the estimators $\hat{w}$ with this version that's normalized by an additional factor of $\gamma + p$. 7) If we're not comparing to uniform price auctions in this competition version, can we remove the relationship to uniform price auction section and just have a one liner referring to it in the related works?}

%Combinatorial auctions have received much recent attention in the algorithmic game theory and machine learning community. 
Homogeneous multi-unit auctions, a special case of combinatorial auctions, are commonly used to auction off large quantities of identical items, for example in  Carbon Emissions Trading Schemes \cite{CarbonTaxVsCapTrade2013, LessonsLearned2017, Kira2019},  US Treasury Auctions \cite{TreasuryAuction2005, TreasuryUnifOrDisc2000}, Procurement Auctions \cite{Procurement2006}, and Wholesale Electricity Markets \cite{WholesaleElectricityMarkets2008, BiddingElectricity2003, DesigningElectricityAuctions2006}. In these multi-unit auctions, bidders submit a bid vector and then are allocated their goods and charged payments according to the auction format. 

Of widespread use are the uniform price and pay-as-bid (PAB) mechanisms. As natural multi-unit generalizations of the second and first price sealed bid auctions, bidders are allocated units in decreasing order of bids and, for each unit won, are charged as payment the lowest winning bid (uniform price) or their own bid (PAB). {In this work, we focus on the PAB auction in light of the recent industry and research community-wide push towards first price auctions, which is mainly due to demand for price transparency and ease of revenue management \citep{fpadisplay2021, googlefpa2019}.} 

Nevertheless, it has been observed that participants find it challenging to determine how to bid effectively in PAB auctions, as highlighted by \cite{CombinatorialAuctionDesign2003}. Bidders face a fundamental dilemma: larger bids increase their chances of winning units but also lead to higher payments. This predicament is further complicated by the necessity  to submit  monotone bid vectors. Bidding too conservatively reduces the probability of winning units in subsequent slots, while bidding excessively may inflate the payment.


 In this paper, we address the issue of learning optimal bidding strategies in repeated multi-unit PAB auctions. As we will elaborate later, we develop efficient no-regret algorithms that simplify the bidding complexity associated with PAB auctions. Through simulating the market dynamics derived from these learning algorithms, we empirically analyze the equilibria of PAB auctions, which have been poorly understood prior to our research. Our empirical findings demonstrate that in the equilibria resulting from these market dynamics, bidders' winning bids converge to the same value, thus addressing concerns regarding price fairness in PAB auctions \citep{TreasuryUnifOrDisc2000, Trilemma2020}.





We also consistently observe high revenue from these equilibria, especially when compared to its uniform price counterpart. In the context of carbon markets, this additional revenue can be invested into clean-up efforts and green technology; see. e.g., phase 4 of the European Union Emissions Trading System (EU-ETS) \citep{gregor2023review}.


\subsection{Technical Contributions}

\textbf{New Framework to Study Learning How to Bid in PAB Auctions (Section \ref{sec:model}).} Let there be $N$ bidders/agents with $\Nitem$-unit demand in a PAB auction with $\overline{\Nitem}$ supply. Each bidder $n$ is endowed with valuation vector $\bm{v}_n = (v_{n, 1},\ldots,v_{n, \Nitem}) \in [0, 1]^\Nitem$ and submits a bid vector $\bm{b}_n = (b_{n, 1},\ldots,b_{n, \Nitem}) \in \mathcal{B}^{\Nitem}$, where $\mathcal{B}$ is some discretization of $[0, 1]$ that represents the set of all possible bids. Agents then receive allocation $x_n \in [\Nitem]$ and  utility $\sum_{\nitem=1}^{x_n} (v_{n, \nitem} - b_{n, \nitem})$ according to the PAB auction rule; see Section \ref{sec:model}. Repeating this auction across $\Nround$ rounds, each agent's goal is to minimize their regret with respect to their hindsight, utility maximizing bid vector.  Here, we refer to discretized regret as the regret incurred as a function of $\Nitem, \mathcal{B}, \Nround$ when restricting our bid space to $\mathcal{B}$. Conversely, we refer to continuous regret as the regret incurred as a function of only $\Nitem$ and $\Nround$ when optimizing for the discretization error. 

\textbf{Dynamic Programming  Scheme for Hindsight Optimal Offline Solution (Section \ref{sec:offline}).} To design low-regret bidding algorithms, we crucially leverage the structure of the hindsight optimal offline solution. In the offline/hindsight problem, the bidder has access to the (historical) dataset of submitted bids by competitors and seeks to find the utility maximizing bid vector on that dataset. (See \cite{RW16, derakhshan2019lp,golrezaei2021boosted,  derakhshan2021beating} for works that study similar problems from an auctioneer's perspective.) 


We show that the optimal solution to the offline problem---which is our benchmark in computing the regret of our online learning algorithms---can be solved  using a polynomial time Dynamic Programming (DP) scheme.  To do so, we make the following key observation:  
 to win $\nitem$ units (or equivalently, slots), an agent $n$ must have at least $\nitem$ bids larger than the smallest $\nitem$ among the largest $\overline{\Nitem}$ bids of all other bidders. This observation allows us to devise a DP where in each step of the DP, we decide about the bid for one unit, while considering the externality that this bid will impose on the bids and utilities for other units. This externality is precisely the fundamental tradeoff of PAB auctions aforementioned: bidding too small decreases the probability of winning the current or any subsequent units, however, bidding too large increases the payment of the current and previous units. 

\textbf{Decoupled Exponential Weights Algorithm (Section \ref{sec: decoupled exp weights section}).} We present our first set of algorithms to learn in the online setting, in both the full information and bandit feedback regimes. We leverage our DP scheme to obtain decoupled rewards, or reward estimates in the bandit setting, for each unit-bid value pair. In particular, we can obtain an exact expression for the utility estimate for bidding $b_\nitem$ for unit $\nitem$ that is independent of $b_1,\ldots,b_{\nitem-1}$ or $b_{\nitem+1},\ldots,b_\Nitem$, subject to bid vector monotonicity. This allows us to mimic the exponential weights algorithm on the exponentially large bid space in polynomial time and space complexity. We show that our decoupled exponential weights algorithm (Algorithm~\ref{alg: Decoupled Exponential Weights}) achieves time and space complexities of $O(\Nitem |\mathcal{B}| \Nround)$ and $O(\Nitem|\mathcal{B}|)$ respectively, with discretized regret $O(\Nitem^{\frac{3}{2}} \sqrt{T \log |\mathcal{B}|})$; see Theorem \ref{thm:full}.  Optimizing for the discretization error from using finite bid space $\mathcal{B}$, we show that in the full information setting, our algorithm achieves $O(\Nitem^{\frac{3}{2}} \sqrt{\Nround \log{\Nround}})$ regret.



\begin{theorem}[Informal]
    Under full information feedback, there exists an algorithm that achieves discretized and continuous regrets $O(\Nitem^{\frac{3}{2}} \sqrt{T \log |\mathcal{B}|})$ and $O(\Nitem^\frac{3}{2} \sqrt{\Nround \log \Nround})$ respectively in the repeated multi-unit PAB auction.
\end{theorem}

We also analyze the bandit version of our algorithm and show that it achieves discretized regret $O(\Nitem^{\frac{3}{2}} \sqrt{|\mathcal{B}|T \log |\mathcal{B}|})$; see Theorem \ref{thm:decoupled exp - bandit feedback}. Balancing with the discretization error, this algorithm achieves continuous regret of $O(M^{\frac{4}{3}}T^{\frac{2}{3}}\sqrt{\log T})$ (We defer the proofs of these and our other main results to the appendix unless otherwise stated).


\textbf{Online Mirror Descent Algorithm (Section \ref{sec:bandit}).} 
In this section, we present an alternative learning algorithm based on Online Mirror Descent (OMD) that improves the regret upper bounds of our decoupled exponential weight algorithm by a factor of $\sqrt{M}$ at the cost of additional computation. We once again leverage our DP scheme and in particular the graph induced by the DP (see Section \ref{sec:offline} for a formal definition). Given this DP graph, one idea is to maintain probability measures over the edges of the DP graph to learn how to bid. Such an idea, which has been studied in other contexts (see \cite{PathKernel2003, OREPS2013, CMAB2013}), leads to a sub-optimal $O(\Nitem |\mathcal{B}| \sqrt{\Nround \log |\mathcal{B}|})$ discretized regret and $O(\Nitem \Nround^{\frac{3}{4}}\sqrt{\log \Nround})$ continuous regret. We obtain an improved regret bound by making an important observation that the utility of a bid vector depends only on the \textit{nodes} of the DP graph and not the \textit{edges}. Leveraging this fact enables us to maintain probability measures over the nodes in the DP graph, rather than its edges, resulting in an algorithm that achieves time and space complexities polynomial in $\Nitem, |\mathcal{B}|, \Nround$, with discretized regrets $O(\Nitem \sqrt{T\log|\mathcal{B}|})$ and $O(\Nitem \sqrt{|\mathcal{B}| T \log |\mathcal{B}|})$ in the full information and bandit settings, respectively. See Theorem \ref{thm: OMD}. This algorithm achieves a factor of $\sqrt{M}$ better than the decoupled exponential weights algorithm. Optimizing for the discretization error from $\mathcal{B}$, we show that in the bandit feedback setting, we derive an algorithm that achieves $O(\Nitem \Nround^{\frac{2}{3}})$ regret. 

\begin{theorem}[Informal]
    Under bandit feedback, there exists an algorithm that achieves discretized and continuous regrets $O(\Nitem \sqrt{T \log |\mathcal{B}|})$ and $O(\Nitem \Nround^{\frac{2}{3}} \sqrt{\log \Nround})$ respectively in the repeated multi-unit PAB auction.
\end{theorem}



\textbf{Regret Lower Bound (Section~\ref{sec: lower bound}).} To complement our discretized regret upper bound, we construct a regret lower bound for the full information setting which matches our upper bound up to a factor of $\sqrt{\log |\mathcal{B}|}$. We do this by constructing two distributions over adversary bid vectors for which any learning agent is guaranteed to incur regret linear in $M$  when trying to learn the optimal bid under these distributions.

\subsection{Experimental Results and Managerial Implications}\label{sec:insights}




Our experiments yield valuable practical insights for both auction designers and participants. These insights are primarily derived from simulations of PAB market dynamics using the no-regret learning algorithms outlined in our paper. Additionally, we compare these results with the market dynamics of uniform price auctions using the algorithms described in \cite{brânzei2023online}. It is important to emphasize that conducting such systematic comparisons was previously challenging due to the inherent difficulty of characterizing equilibria in these auctions prior to our research.

\begin{enumerate}
    \item \textbf{Uniform Bidding in PAB Auctions is Optimal.} As shown in Figures \ref{fig:exp3_bids} and \ref{fig: bid ratios}, the market dynamics consistently yield convergence of the winning bids and largest losing bids to a common price across all bidders. This partially addresses one of the main concerns over the fairness of the PAB auction. That is, while the payment for each unit \textit{can} be different across units and across bidders, under a reasonable learning and bidding strategy, these payments across units and bidders converge to the same value in the long run.
    \item \textbf{Simplified Bidding Interface is Sufficient for PAB but not for Uniform Price.} In a recent trend of bidding simplification  and automation (e.g.,  \cite{aggarwal2019autobidding, deng2023multi, susan2023multi, lucier2023autobidders}), auctioneers may find it easier to restrict bidders' demand expressiveness by requiring only a single price and quantity, rather than a vector of bids. As per our previous insight, the bid value convergence of the market dynamics suggest appropriateness of this simplified bidding interface. In contrast, we show that the market dynamics of the uniform price auction  converge to a staggered bid vector (Figure \ref{fig: bid ratios}), suggesting that the simplified bidding interface may significantly damage the uniform price auction's welfare, revenue, or bidders' utility.
    \item \textbf{PAB Obtains High Revenue but Slightly Lower Welfare than Uniform Price.} From the insights provided by Figure \ref{fig:welfare_revenue_comparison_box_plot}, it is evident that the PAB auction surpasses the uniform price auction in terms of revenue generation. However, it slightly lags behind in welfare, though to a lesser extent. Consequently, auctioneers who prioritize revenue (resp. welfare) should favor the PAB (resp. uniform price) auction over uniform price (resp. PAB) auctions.
\end{enumerate}






\subsection{Other Related Works}


\textbf{Learning in Auctions.} Most of the recent learning-theory-flavored auction design research has either focused on the single unit setting \citep{LearningBidOptimallyAdversarialFPA2020, OptimalNoRegretFPA2020, ContextBanditsCrossLearning2019}, the perspective of the auctioneer setting reserve prices \citep{MorgensternR16, mohri2016learning, CaiD17, DudikHLSSV17,kanoria2014dynamic, golrezaei2019IC, golrezaei2018dynamic, golrezaei2021bidding},
%\rigel{Cite third set of citations in Negin's paragraph, TODO read abstracts to get better idea of what exactly to include and explain}
or uniform price auctions \citep{LearningRevOptSPA2013, mohri2016learning, OptReserveMyopic2018, LearningToBidRevenueMaximizing2019, OSPABidding2020}. However, in PAB auctions,  as the space of possible bid vectors is exponentially large, the task of learning how to bid optimally in these multi-unit auctions is more challenging, compared with the single unit setting. This is especially true when the number of units demanded is large which necessitates not only low-regret but also tractable algorithms to learn how to bid optimally. In this paper, we contribute to this line of works by proposing  a novel framework under which to analyze and derive efficient, low-regret learning algorithms for these inherently combinatorial multi-unit PAB auctions.
 
\textbf{PAB Mechanism.} There are several multi-unit auction formats that are commonly used in practice; e.g., uniform price \citep{TreasuryUnifOrDisc2000, LastAcceptedBid2020, ImprovedRevenuePPASPA2021, Kira2019}, PAB \citep{Homogeneous2020, FPACollusion2000, LargeMultiUnit2018}, Vickrey-Clarke-Groves (VCG) \citep{MechanismsMultiUnit2007, LonelyVickrey2006}, ascending price \citep{AscendingCramton1998, EfficientAscending2004}. The literature is divided as to which auction is appropriate for various settings. For example, while the PAB mechanism has desirable revenue and welfare guarantees compared to the uniform price auction \citep{Homogeneous2020}, the empirical revenue of the two auctions is often comparable \citep{Turkish2010}, and some argue that guess-the-clearing-price and other strategic behavior \citep{GermaryReserve2021} along with collusion \citep{WholesaleElectricityMarkets2008} can further damage its performance. Furthermore, there are ethical and fairness concerns regarding PAB auctions, as their discriminatory nature implies that agents pay unequally for the same unit. Despite this criticism, and other arguments for (and against) other auction formats \citep{CombinatorialAuctionDesign2003, CombinatorialAuctions2004, InefficiencyStandard2013, DemandReduction2014, Trilemma2020}, we focus on the PAB mechanism  due to the simplicity and transparency of its payment rule, as well as, its widespread use.



The economics literature has only recently addressed several of the questions regarding the equilibria, bidding dynamics, efficiency, and other key properties of multi-unit PAB mechanisms in the static or Bayesian setting. For example, the Bayesian optimal bidding strategy is known for the case of 2-unit demand and supply multi-unit auctions \citep{OptimalBidding1995}, for when valuations follow a class of parametric distributions \citep{Homogeneous2020}, or when the bidders have symmetric valuations \citep{DemandReduction2014}. The PAB mechanism is also known to be smooth \citep{syrgkanis2012composable}, which yields a number of desirable guarantees on the price of anarchy of the auction \citep{roughgarden2015smooth}, even with the presence of an aftermarket \citep{babaioff2022aftermarkets}. An additional attractive property of the PAB mechanism is complete transparency of payments, as given one's allocation, an agent knows precisely how much they will pay. This is in stark contrast to the uniform price auction, where shill bids can inflate payments by artificially increasing demand \citep{Trilemma2020}. 

\textbf{Relationship to Uniform Price Auctions.} The uniform price auction is an alternative mechanism of allocating multiple homogeneous goods. Closely related to the PAB auction, bidders are allocated units in decreasing order of bids, but instead of charging each bidder their corresponding winning bid, each bidder instead pays the smallest winning bid. The  EU-ETS carbon license auctions use the uniform price auction, rather than the PAB auction, largely due to fairness considerations, as each agent pays the same amount per unit allocated \citep{EUETS}. However, our work shows that price fairness is not a concern in the long term when bidders learn how to bid and converge to a common price.  


In a study closely aligned with our research, \cite{brânzei2023online} investigated the problem of learning optimal bidding strategies in multi-unit uniform pricing auctions. Since the uniform price auction employs a distinct payment rule, the bid optimization problem necessitates different approaches compared to the PAB auction. While \cite{brânzei2023online} reformulated the offline bid optimization problem as a path weight maximization problem over a directed acyclic graph (DAG), the construction of these DAGs differs fundamentally from those we constructed in our manuscript for PAB auctions. We also emphasize that the decoupling of utility across units is unique to the PAB setting, which enables improved regret guarantees. Consequently, the path kernel-based algorithms described in \cite{brânzei2023online} for both the full and bandit settings yield sub-optimal regret in terms of dependence on the number of units in the PAB mechanism. As previously mentioned, we introduce an alternative method based on OMD, which achieves regret matching the lower bound.


\textbf{Structured Bandits.} The crux of our paper is constructing time and space efficient no-regret bandit algorithms for bid optimization under a combinatorially large bid space for identical multi-unit PAB auctions. As such, naive implementations of bandit algorithms, such as $\textsc{Exp3}$, that consider each bid vector as its own arm in isolation incur exponential regret, computational and memory costs. It is similarly difficult to generalize existing efficient cross-learning based algorithms in the single-unit case \citep{OptimalNoRegretFPA2020, LearningBidOptimallyAdversarialFPA2020, ContextualizedFPA2021}. To combat this, we take from the expansive structured bandit literature, which includes linear bandits \citep{StochLinearOpt2008, LinStochBandits2011, ContextLinearPayoff2011, Lattimore2020} and combinatorial bandits \citep{CMAB2013, MinimaxCombinatorial2011, niazadeh2021online}, and convex uncertainty set bandit \citep{van2020optimal}. In particular, our algorithm most closely resembles existing algorithms exploiting both these combinatorial and linear aspects in episodic Markov Decision Processes \citep{OREPS2013} or cost minimization on graphs \citep{PathKernel2003}. The primary difference is that our algorithm seeks to minimize the sum of the costs of nodes in a path, rather than the edges. We describe how to efficiently perform negentropy regularized OMD updates in our setting.



\textbf{Multi-Agent Learning.} While we seek to derive efficient, low-regret algorithms for a single bidder, as we also explored, it is equally important to understand the implications of the bidding dynamics induced by such adaptive behavior. For example, it may be possible for these adaptive agents to learn to collude \citep{CollusionInAuctions1989, FPACollusion2000, BidRotation2003, AlgorithmicCollusion2021, GermaryReserve2021} which can significantly reduce revenue and welfare. %\rigel{Can get rid of several of these, since we don't talk too much about collusion; I think the point in previous sentence is made more clear in the next 2 sentences anyways}.
Precisely how much they do so is characterized in the Bayesian setting as the Price of Anarchy (PoA) \citep{Lucier2009PriceOA, InefficiencyStandard2013, PriceOfAnarchyRevenue2014, PriceOfAnarchyInAuctions2017}. The auction efficiency  in the dynamic setting is less well understood, though there have been several results for specific auctions and learning algorithms \citep{RegretMinPriceOfAnarchy2008, DynamicPopulation2016, LearningBayesianGames2015, ConsumerReferenceEffects2020, AuctionsBetweenRegretMinimizing2022}.
However, most of the standard learning theory literature takes the perspective of the auctioneer who optimizes revenue through reserves or supply.
More standard in literature is assuming that the auctioneer is an adaptive agent themselves, optimizing over the set of reserves or supply \citep{LearningRevOptSPA2013, RW16, Mohri2015RevenueOA}. % \rigel{This last sentence feels like it could be better phrased: However, most of the standard learning theory literature takes the perspective of the auctioneer who optimizes revenue through reserves or supply.}. 
This line of work is closely related to the vast and rapidly growing literature on multi-agent learning \citep{AuctionsEvolutionMARL2008, Buşoniu2010, OverviewMARLGameTheory2020, ConsumerReferenceEffects2020,golrezaei2021bidding, KaiqingZhangReinforcementLearning2021}. 

{The  multi-agent learning dynamics in the PAB auction (and also uniform price auction) is studied in our experiments section. To our knowledge, these experiments are the first systematic comparison between the equilibria of PAB and uniform price auctions, showing a noticeable revenue improvement of the PAB over the uniform price auction.}




 
