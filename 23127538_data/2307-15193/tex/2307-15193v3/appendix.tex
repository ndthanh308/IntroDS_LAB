\newpage 

\section{Appendix}
{\color{black}\subsection{Proof of Lemma \ref{lem: PNE uniform bidding}}\label{sec:proof:lem: PNE uniform bidding}
We prove this by contradiction. Suppose buyer \(n\) places any bid strictly greater than \(b_{(M)} + \delta\). Assume the bids of all other bidders are fixed. Any bid \(b\) by bidder \(n\) that equals or exceeds \(b_{(M)} + \delta\) still secures allocation, as \(b \geq b_{(M)} + \delta > b_{(M)}\), irrespective of tie-breaking. Therefore, bidder \(n\) can reduce all such bids to exactly \(b_{(M)} + \delta\) without losing any items, thereby lowering their total payment. Consequently, the largest bid cannot exceed \(b_{(M)} + \delta\).

\subsection{Proof of Lemma \ref{lem: near-uniform optimal bidding}}\label{sec:proof:lem: near-uniform optimal bidding}
    Consider any bid vector $\bm{b} \in \mathcal{B}^{+M}$. Assuming that bidder $n$'s  is allocated  $m$ under $\bm{b}$, then $b_m \geq \tilde{b}_{n,m}$, as $\tilde{b}_{n,m}$ is the smallest bid required for bidder $n$ to win the $m$'th item. Define $\bm{b}': b'_j = \min(\tilde{b}_{n,m}, b_j)$ which is $\bm{b}$ except setting the first $m$ bids to $\tilde{b}_m$.
    By monotonicity of $\bm{b}_{-n}$ and $\bm{b}$---i.e., $b_{-1} \leq \ldots \leq b_{-m} \leq \tilde{b}_{n,m} \leq b_m \leq \ldots \leq b_1$---the allocation is the same under $\bm{b}$ and under $\bm{b}': b'_j = \min(\tilde{b}_{n,m}, b_j)$. As the allocations are equal and the payment is smaller under $\bm{b}'$, which belongs to the set $\{\bm{b} \in \mathcal{B}^{+M}: b_j = (\tilde{b}_{n,m}) \forall j \in [m], b_{j} \leq v_j \forall j > m\}$, then $\bm{b}'$ must yield at least as much utility as $\bm{b}$. Thus, any optimal bid vector that is allocated $m$ units, conditioning on $\bm{b}_{-n}$ must have uniform $m$ highest bids at value $\tilde{b}_{n,m}$. Because we prohibit overbidding, we only consider $\bm{b}$ that win $m$ items for $m$ satisfying $\tilde{b}_{n, m} < v_m$.
    
{\color{black}
\subsection{Assumptions in Theorem \ref{thm: PNE existence}} \label{sec:discuss:assumption}
The validity of the PNE characterization in Theorem \ref{thm: PNE existence} depends on the premise that there is sufficient competition, ensuring that the clearing price $c$ remains constant even upon removing any single bidder. However, this assumption may not always hold true. To illustrate this, we initially provide an example where the assumption is met. However, a minor modification to the example leads to the failure of this assumption. In Figure~\ref{fig: bid cycling main body}, we illustrate how this impacts the convergence of our learning algorithms' final iterations.

In this figure, we plot the bid values over the course of the market dynamics induced by our full information decoupled exponential weights algorithm (Algorithm~\ref{alg: Decoupled Exponential Weights}) with $N=3$, $M=4$, $|\mathcal{B}|=10$, and $T=10^5$. In the left figure, we let $\bm{v}_1 = \bm{v}_2 = \bm{v}_3 = [1-\epsilon, 1-\epsilon]$, and thus there exists a PNE via satisfying the $c = c_{-n} = \lfloor 1-\epsilon \rfloor_{\delta=0.1} = 0.9$ condition from Theorem~\ref{thm: PNE existence}. Moreover, this PNE is characterized by all bidders submitting bids of $0.9$ for the first two units, which is precisely what the market dynamics converge to.\footnote{{We do not present theoretical guarantees on last iterate convergence for PAB. For a discussion in the $M=1$ unit setting, please refer to \cite{Deng_2022}.}} In the right figure, we assume that  bidder one only demands one unit at $1-\epsilon$, instead of two; that is $\bm v_1= [1-\epsilon, 0]$. The value of other bidders remain the same. Here, we do not satisfy the $c = c_{-n}$ condition as $ c_{-1} = 1-\epsilon \neq 0 = c_{-2} = c_{-3}$. In fact, one can verify that there exists no PNE in this auction and we observe cyclic bidding behavior from the 2nd and 3rd bidders.

To explain why the learning dynamics do not converge in cases where PNE is absent, we outline several observations:

\begin{enumerate}
    \item In the auction in Figure~\ref{fig: bid cycling main body} with no PNE, $\bm{v}_1 = [1-\epsilon, 0]$, so bidder 1 can submit at most one non-zero bid. Similarly, $\bm{v}_2 = \bm{v}_3 = [1-\epsilon, 1-\epsilon]$, so bidders 2 and 3 can submit at most two non-zero bids. Bidder 2 and bidder 3 can guarantee an allocation of at least 1 since among all other bidders, the demand is at most 3. However, they can guarantee an allocation of 2 if they can slightly outbid the 2nd largest bid among the other two bidders.
    \item In Figure~\ref{fig: bid cycling main body}, we observe that bidder 1's bid converges to 0.5. In contrast, bidder 2's bids cycle between 0.1 and 0.5, and bidder 3's bids cycle between 0 and 0.4. What happens is that bidder 3 will try to win one unit cheaply by bidding for both units at price $0$. Bidder 2 realizes that they can slightly outbid them at a price of 0.1, yielding utility $1.8 - 2\epsilon$. Then bidder 3 matches their bid, and because they are given tie-break priority, they win two units, yielding utility $1.8 - 2\epsilon$. Bidder 2, now only winning one unit, realizes that they can win 2 units by increasing their bid to 0.2, which bidder 3 then matches, and so on.
    \item Once bidder 2 submits two bids of 0.5, which yields a utility of $1 - 2\epsilon$, bidder 3 can either submit two bids of 0.5, which yields an allocation of 2 and a utility of $1 - 2\epsilon$, or they can submit a bid of 0, which only yields an allocation of 1 but a utility of $1 - \epsilon$. Thus, they submit bids of 0 as the best response to bidder 1 submitting a bid of 0 and bidder 2 submitting two bids of 0.5, after which the cycle repeats.
\end{enumerate}

% Figure environment removed

Despite this fragility of the $c = c_{-n}$ assumption in Theorem~\ref{thm: PNE existence}, this is merely a sufficient condition and not necessary for the existence of the PNE. At its core, this $c = c_{-n}$ assumption reflects the requirement that strategic bid shading cannot offset a decrease in allocation with a decrease in payment. For example, if we instead set $v_{1,2} = 0.8+\epsilon$ in Figure~\ref{fig: bid cycling main body}, a PNE still exists at $\bm{b}_1 = [0.9, 0.8]$ and $\bm{b}_2 = \bm{b}_3 = [0.8, 0.8]$ despite $ c_{-1} = 1 -\epsilon \neq 0.8 + \epsilon = c_{-2} = c_{-3}$. For practical understanding, PNE existence is satisfied when bidders are price-takers with minimal influence over the market price---a condition typically met in markets where the demand each bidder $n$ places on units $M$ is substantially smaller than the overall supply $\overline{M}$, and the total supply is less than the aggregate demand, i.e., $\sum_{n \in [N]} \overline{M}_n \gg M$.
}
}


{\color{black}\subsection{Proof of Lemma \ref{lem: CCE non uniform winning}}
    Consider the following $M=2$ item, $N=2$ bidder auction where bidder 1 and 2's valuations are $[1 + \epsilon, 1 + \epsilon], [1, 0]$ respectively, for some small $\epsilon > 0$. Let $\mathcal{B} = \{0, \frac{1}{|\mathcal{B}|}, \frac{2}{|\mathcal{B}|},\ldots, 1\}$ be an even discretization of $[0,1]$ with the discretization factor of $\delta =  \frac{1}{|\mathcal{B}|}$,  
    and assume that ties are broken in favor of bidder 2. 
    In this setting, we can show the existence of CCEs where the winning bids are \textit{never} uniform, even up to a discretization factor.
    
    To that end, we solve a linear program using the linear constraints formulation of CCEs and maximize the probability of drawing a joint action profile with non-uniform winning bids. We first define $b_{(m)} = b_{(m)}(\bm{b}_1,\ldots,\bm{b}_N)$ as the $m$'th largest bid among bid vectors $\bm{b}_1,\ldots,\bm{b}_N$. Now, we maximize the probability that the gap between $b_{(1)}$ and $b_{(M)}$ is more than one discretization factor $\delta = \frac{1}{|\mathcal{B}|}$ apart by maximizing the objective function $\max \sum_{\bm{b}_1,\ldots,\bm{b}_n} \bm{p}(\bm{b}_1,\ldots,\bm{b}_n) \mathbf{1}_{b_{(1)} > b_{(M)} + \delta}$. Under CCE constraints, the objective function is equal to 1 for all $|\mathcal{B}| \in [5, 10]$, meaning that there exist CCEs entirely supported on joint bidding profiles which have winning bids more than $\delta$ apart. Under CE constraints, the objective function is increasing in $|\mathcal{B}|$ but stabilizes around $0.6$ at $|\mathcal{B}| = 8$. In other words,  when $|\mathcal{B}|$ grows large, there exists a CCE (resp. CE) under which there is a 1.0 (resp 0.6) probability over joint strategy profiles that violate the winning bid uniformity. $\blacksquare$
    }

\subsection{Proof of Theorem \ref{thm:offline}: Offline Bid Optimization Algorithm}
\label{sec: offline proof}

We give a proof of correctness of the offline bid optimization algorithm used to compute the hindsight optimal bid vector across $T$ rounds of PAB auctions. Our proof shows that the variables $U_m(b)$ are path weights of the optimal partial bid vector with weights $W_m^{T+1}(b)$. Thus, $U_1(b)$ is the optimal bid vector and $b^*_m$'s can be used to back out the optimal bid vector recursively in polynomial time.

\begin{proof}{Proof of Theorem \ref{thm:offline}}
   By definition, we have that $U_\nitem(b)$ is given by:
    \begin{align*}
        \max_{ b\ge b_\nitem\geq\ldots\geq b_\Nitem} \sum_{\nitem' = \nitem}^\Nitem W^{\Nround+1}_{\nitem'}(b_{\nitem'}) = \max_{ b\ge b_\nitem\geq\ldots\geq b_\Nitem}  W^{\Nround+1}_{\nitem}(b_\nitem ) +  \sum_{\nitem' = \nitem+1}^\Nitem W^{\Nround+1}_{\nitem'}(b_{\nitem'}) = \max_{ b' \leq b} W^{\Nround+1}_\nitem(b') + U_{\nitem+1}(b')\,.
    \end{align*}
    Since we have that $U_{\Nitem}(b ) = W^{\Nround+1}_{\Nitem} (b )$ trivially correct from the base case, and the optimality of $U_\nitem(b)$ follows from induction. Consequently, optimality of $b_\nitem^*$ follows from induction. The base case trivially holds as $b_1^* = \text{argmax}_{b \in \mathcal{B}} U_1(b)$. The recursive case also follows straightforwardly by definition of $bb^*_\nitem = \text{argmax}_{b \leq b^*_{\nitem-1}} U_\nitem(b)$. As $b^*_{\nitem-1}$ was optimal by the induction hypothesis, then $b_\nitem^*$ must also be optimal.
    
    We finish this proof by discussing the time and space complexity of Algorithm \ref{alg: Offline Full}.  {Table $U$ is of size $O(\Nitem |\mathcal{B}|)$, with each entry requiring taking a maximum over $O(|\mathcal{B}|)$ terms, yielding time and space complexities of $O(\Nitem |\mathcal{B}|^2)$ and $O(\Nitem|\mathcal{B}|)$ respectively.}

 
\end{proof}


\subsection{Proof of Theorems \ref{thm:full} and \ref{thm:decoupled exp - bandit feedback}: Decoupled Exponential Weights Algorithm}
\label{sec: path kernels regret}

\begin{proof}{}
    We give the proofs of correctness, complexity analysis, and regret analysis for the decoupled exponential weights algorithms for both the full information (Algorithm~\ref{alg: Decoupled Exponential Weights}) and the bandit setting (Algorithm~\ref{alg: Decoupled Exponential Weights - Path Kernels}). Our proof comes in 5 parts. We first prove correctness of the bandit version of our algorithm. In particular, we show that defining the node and bid vector utility estimates to be $\widehat{w}_m^\nround(b) = 1 - \frac{1-(v_m-b)1_{b \geq b_{-m}^\nround}}{q_m^t(b)}1_{b = b^\nround_m}$ and $\widehat{\mu}^\nround(\bm{b}) = \sum_{\nitem=1}^\Nitem \widehat{w}_\nitem^\nround(b_m)$, our algorithm samples bid vector $\bm{b}^\nround$ with probability proportional to $\exp(\eta \sum_{\tau=1}^{t-1} \widehat{\mu}^\tau(\bm{b}))$ via the same recursive sampling procedure as in Algorithm~\ref{alg: Decoupled Exponential Weights}. In the second part and third parts, we derive a corresponding regret upper bound and obtain the time and space complexities of our algorithm with bandit feedback. In the fourth part, we optimize the continuous regret w.r.t. the selection of $\mathcal{B}$. In the fifth part, we show how to extend our algorithm and results to the full information setting.

    \textbf{Part 1: Algorithm Correctness.} In this part of the proof, we argue that our choice of estimator is unbiased and that Algorithm~\ref{alg: Decoupled Exponential Weights - Path Kernels} samples bid vectors with the same probability that the exponential weights algorithm would have, given the same node utility estimates $\widehat{w}_m^t(b)$. To show unbiasedness of $\widehat{w}_m^t(b)$, we have:
    \begin{align*}
        \mathbb{E}\left[\widehat{w}_m^{t}(b)\right] = \mathbb{E}\left[1 - \frac{1-w^t_m(b)}{q^t_m(b)} \textbf{1}_{b^t_m = b}\right] = \mathbb{E}\left[1 - \frac{\textbf{1}_{b^t_m = b}}{q^t_m(b)} + \frac{\textbf{1}_{b^t_m = b} \cdot w^t_m(b)}{q^t_m(b)}\right] = w^t_m(b)\,.
    \end{align*}
    Now, it remains to show that our sampling procedure $\textsc{Sample}-\bm{b}$ w.r.t. $\widehat{S}^\nround_m$ indeed samples bid vectors $\bm{b}$ with the same probability as the exponential weights algorithm under weights $\widehat{\mu}^\nround_n(\bm{b})$. In particular, we want to show that our algorithm samples bid vectors $\bm{b}^\nround$ with probability proportional to $\exp(\eta \sum_{\tau=1}^{t-1}\widehat{\mu}_m^\tau(b_m))$ for any $m\in [M]$. This follows from analyzing the dynamic programming variables that represent the sum of exponentiated (estimated) partial bid vector utilities, $\widehat{S}$.

    In exponential weights, the bidder selects at round $\nround+1$ some action $\bm{b}$ with probability $P^\nround(\bm{b})$ proportional to $\sum_{\tau=1}^{\nround} \widehat{\mu}_n^{\nround}(b)$. Using our representation of $\widehat{\mu}_n^{\nround}(\bm{b})$ as a function $\widehat{w}_\nitem^{\tau}(b)$, we have:
    \begin{align*}
        P^{\nround}(\bm{b}) = \frac{\exp(\eta \sum_{\tau=1}^{t-1} \widehat{\mu}_n^{\tau}(\bm{b}))}{\sum_{\bm{b}' \in \mathcal{B}^{+\Nitem}} \exp(\eta \sum_{\tau=1}^{t-1} \widehat{\mu}_n^\tau(\bm{b}'))} = \frac{\exp(\eta \sum_{\nitem=1}^\Nitem \widehat{W}_\nitem^\nround(b_\nitem))}{\sum_{\bm{b}' \in \mathcal{B}^{+\Nitem}} \exp(\eta \sum_{\nitem=1}^\Nitem \widehat{W}_\nitem^\nround(b'_\nitem))}\,.
    \end{align*}
    Hence, we wish to construct a sampler that samples $\bm{b}$ with the above probability. Defining $b_0 = \max_{b \in \mathcal{B}} b$, we begin by decomposing the denominator as follows:
    \begin{align*}
        &\sum_{\bm{b} \in \mathcal{B}^{+\Nitem}} \exp(\eta \sum_{\nitem=1}^\Nitem \widehat{W}_\nitem^\nround(b_\nitem)) = \sum_{b_1 \in \mathcal{B}, b_1 \leq b_0} \sum_{b_2 \in \mathcal{B}, b_2 \leq b_1} \ldots \sum_{b_\Nitem \in \mathcal{B}, b_\Nitem \leq b_{\Nitem-1}} \exp(\eta \sum_{\nitem=1}^\Nitem \widehat{W}_\nitem^\nround(b_\nitem))\\
        &= \sum_{b_1 \in \mathcal{B}, b_1 \leq b_0} \exp(\eta \widehat{W}_1^\nround(b_1)) \sum_{b_2 \in \mathcal{B}, b_2 \leq b_1}\exp(\eta \widehat{W}_2^\nround(b_2)) \ldots \sum_{b_\Nitem \in \mathcal{B}, b_\Nitem \leq b_{\Nitem-1}} \exp(\eta \widehat{W}_\Nitem^\nround(b_\Nitem))\,.
    \end{align*}
   Recall a key object $\widehat{S}^t_\nitem(b)$, which is the sum of exponentially weighted utilities of partial bid vectors $\bm{b}'_{\nitem:\Nitem} \in \mathcal{B}^{+(\Nitem - \nitem + 1)}$ over slots $\nitem,\ldots,\Nitem$ subject to $b_\nitem = b$.
    \begin{align*}
        \widehat{S}^t_\nitem(b) = \exp(\eta \widehat{W}_\nitem^\nround(b)) \sum_{\bm{b}'_{\nitem+1:\Nitem}:b'_{\nitem+1} \leq b'_\nitem = b} \exp(\eta \sum_{\nitem'=\nitem+1}^\Nitem \widehat{W}_{\nitem'}^\nround(b'_{\nitem'})) = \exp(\eta \widehat{W}_\nitem^\nround(b)) \sum_{b' \in \mathcal{B}; b' \leq b} \widehat{S}^t_{\nitem+1}(b')\,.
    \end{align*}
    With the trivial base case $\widehat{S}^t_\Nitem(b) = \exp(\eta \widehat{W}_\Nitem^\nround(b))$, we can recover all of the exponentially weighted partial utilities $\{\widehat{S}^t_{\nitem}(b)\}_{\nitem \in [\Nitem], b \in \mathcal{B}}$ given $\bm{W}^\nround$. Once we have computed $\{\widehat{S}^t_{\nitem}(b)\}_{\nitem \in [\Nitem], b \in \mathcal{B}}$, we can sample $\bm{b}$ according to its exponentially weighted utility $\exp(\eta \widehat{\mu}^{\nround}_\nitem(\bm{b}))$ by sequentially sampling each $b_1,\ldots,b_\Nitem$.
    
    Let $P_{\textsc{D}}^t(\bm{b})$ be the probability that our Algorithm \ref{alg: Decoupled Exponential Weights - Path Kernels} returns bid vector $\bm{b} \in \mathcal{B}^{+\Nitem}$ in round $t$. Recall that we sample $\bm{b}$ by setting $b_\nitem^\nround$ to $b \in \mathcal B, b \le b_{m-1}^t$ with probability $ \frac{\widehat{S}^t_\nitem(b)}{\sum_{b' \leq b_{\nitem-1}^t} \widehat{S}^t_{\nitem}(b')}$. Hence, the probability of selecting $\bm{b}$ is the product of $\nitem$ conditional probability mass functions (pmf's) and we have 
    \begin{align*}
        P_{\textsc{D}}^\nround(\bm{b}) = \prod_{\nitem=1}^\Nitem \frac{\widehat{S}^t_\nitem(b_\nitem)}{\sum_{b' \leq b_{\nitem-1}} \widehat{S}^t_{\nitem}(b')} = \left(\prod_{\nitem=1}^{M-1} \frac{\exp(\eta \widehat{W}_\nitem^\nround(b_\nitem)) \sum_{b \leq b_{\nitem}} \widehat{S}^t_{\nitem+1}(b)}{\sum_{b' \leq b_{\nitem-1}} \widehat{S}^t_{\nitem}(b')}\right)\left(\frac{\exp(\eta \widehat{W}_M^t(b_M))}{\sum_{b' \leq b_{M-1}} \widehat{S}_M^t(b')}\right)\,.
    \end{align*}
    Moving the $\exp(\eta \widehat{W}_m^t(b_m))$ outside of the product, we obtain:
    \begin{align*}
        P_{\textsc{D}}^\nround(\bm{b}) &= \left(\prod_{\nitem=1}^{\Nitem-1} \exp(\eta \widehat{W}_\nitem^\nround(b_\nitem)) \right) \left(\prod_{\nitem=1}^{M-1} \frac{\sum_{b \leq b_{\nitem}} \widehat{S}^t_{\nitem+1}(b)}{\sum_{b' \leq b_{\nitem-1}} \widehat{S}^t_{\nitem}(b')}\right)\left(\frac{\exp(\eta \widehat{W}_M^t(b_M))}{\sum_{b' \leq b_{M-1}} \widehat{S}_M^t(b')}\right)\\
        &= \left(\prod_{\nitem=1}^{\Nitem} \exp(\eta \widehat{W}_\nitem^\nround(b_\nitem)) \right) \left(\frac{\sum_{b \leq b_{M-1}} \widehat{S}^t_{M}(b)}{\sum_{b' \leq b_{0}} \widehat{S}^t_{1}(b')}\right)\left(\frac{1}{\sum_{b' \leq b_{M-1}} \widehat{S}_M^t(b')}\right) = \frac{\prod_{\nitem=1}^{\Nitem} \exp(\eta \widehat{W}_\nitem^\nround(b_\nitem))}{\sum_{b' \leq b_{0}} \widehat{S}_1^t(b')}\,.
    \end{align*}
    We now rearrange the last expression to recover the exponential weights algorithm probabilities:
    \begin{align*}
        P_{\textsc{D}}^\nround(\bm{b}) = \frac{\prod_{\nitem=1}^\Nitem \exp(\eta \widehat{W}_\nitem^\nround(b_\nitem))}{\sum_{b \leq b_0} S_1^t(b)} = \frac{\exp(\eta \sum_{\nitem=1}^\Nitem \widehat{W}_\nitem^\nround(b_\nitem))}{\sum_{\bm{b}' \in \mathcal{B}^{+\Nitem}} \exp(\eta \sum_{m=1}^M \widehat{W}_m^t(b'_m))} = P^\nround(\bm{b})\,.
    \end{align*}

    \textbf{Part 2: Regret Analysis.} We are now ready to derive the regret upper bound on Algorithm~\ref{alg: Decoupled Exponential Weights - Path Kernels}. First, we show that the bid vector utility estimators $\widehat{\mu}^\nround(\bm{b})$ are both unbiased and have a finite upper bound. To show the upper bound, we take expectation with respect to the bid vectors selected by our algorithm and observe that 
    \begin{align*}
        \mathbb{E}[\widehat{\mu}^\nround(\bm{b})] &= \sum_{m=1}^\Nitem \mathbb{E}[\widehat{w}_m^t(b_m)]= \sum_{m=1}^M \mathbb{E}\left[1 - \frac{1-(v_m-b_m)1_{b_m > b_{-m}^\nround}}{q_m^t(b_m)}1_{b_m = b^\nround_m}\right]
    \end{align*}
    As we are considering the expectation ex-post, keeping the $b_{-m}^t$'s fixed, we have independence between the two indicator functions and we obtain:
    \begin{align*}
        = \sum_{m=1}^M \mathbb{E}\left[1 - \frac{1-w^\nround_m(b_m)}{q_m^t(b_m)}1_{b_m = b^\nround_m}\right]= M - \sum_{m=1}^M \frac{1 - w^\nround_m(b_m)}{q_m^t(b_m)}\mathbb{E}\left[1_{b_m = b^\nround_m}\right]= \mu^\nround(\bm{b})\,.
    \end{align*}
 
    
    As for the finite upper bound, we have that $\widehat{\mu}^\nround(\bm{b}) = \sum_{m=1}^\Nitem \widehat{w}_m^t(b_m)$ is the sum over $M$ node utility estimators, each of which is upper bounded by 1. Hence, $\widehat{\mu}^\nround(\bm{b}) \leq \Nitem$ for all $\bm{b} \in \mathcal{B}^{+\Nitem}$. Now, we make the following claim:
    \begin{lemma}\label{lem:regret_bound}
        Let $\widehat{\mu}^\nround(\bm{b}) = \sum_{m=1}^M (1 - \frac{1-(v_m-b_m)1_{b_m > b_{-m}^\nround}}{q_m^t(b_m)}1_{b_m = b^\nround_m})$ be our bid vector utility estimate as discussed. Then, any algorithm which samples bid vectors $\bm{b}$ with probability proportional to $\exp(\eta \sum_{\tau=1}^{t-1} \widehat{\mu}^\nround(\bm{b}))$ at round $\nround$ for $\eta \leq \frac{1}{M}$ has regret upper bound
        \begin{align}
            \label{eq: ExpWeights Analysis 2}
            \textsc{Regret}_{\mathcal{B}} \lesssim \eta^{-1}M\log|\mathcal{B}| + \eta \sum_{\nround=1}^\Nround \sum_{\bm{b}} \prob(\bm{b}^\nround =\bm{b}) \mathbb{E}[(\sum_{m=1}^M \widehat{w}^\nround_m(b_m))^2]\,.
        \end{align}
    \end{lemma}
    \proof{Proof of Lemma \ref{lem:regret_bound}}
        We will closely follow the analysis of the $\textsc{Exp3}$ algorithm as presented in Chapter 11.4 of \cite{Lattimore2020}. In particular, we follow their regret analysis until Equation 11.13. Define $\Phi^t = \sum_{\bm{b} \in \mathcal{B}^{+\Nitem}} \exp(\eta \sum_{\tau=1}^{t} \widehat{\mu}^\tau(\bm{b}))$ to be the \textit{potential} at round $\nround$. As per our initial conditions in Algorithm~\ref{alg: Decoupled Exponential Weights - Path Kernels}, we have $\widehat{\mu}^0(\bm{b}) = 0$, and consequently, $\Phi^0 = |\mathcal{B}^{+\Nitem}|$. While it is not immediately apparent how the potentials $\Phi^\nround$ relate to the regret, we begin by upper bounding $\exp(\eta \sum_{t=1}^{T} \widehat{\mu}^t(\bm{b}))$ for a fixed $\bm{b}'$:
        \begin{align}
            \label{eq: Potentials}
            \exp(\eta \sum_{t=1}^{T} \widehat{\mu}^t(\bm{b}')) \leq \sum_{\bm{b} \in \mathcal{B}^{+\Nitem}} \exp(\eta \sum_{t=1}^{T} \widehat{\mu}^t(\bm{b})) = \Phi^T = \Phi^0 \prod_{t=1}^T \frac{\Phi^t}{\Phi^{t-1}}\,.
        \end{align}
        Now, we upper bound each $\frac{\Phi^t}{\Phi^{t-1}}$:
        \begin{align*}
            \frac{\Phi^t}{\Phi^{t-1}} = \sum_{\bm{b} \in \mathcal{B}^{+M}} \frac{\exp(\eta \sum_{\tau=1}^{t} \widehat{\mu}^\tau(\bm{b}))}{\Phi^{t-1}} = \sum_{\bm{b} \in \mathcal{B}^{+M}} \frac{\exp(\eta \sum_{\tau=1}^{t-1} \widehat{\mu}^\tau(\bm{b}))}{\Phi^{t-1}} \exp(\eta \widehat{\mu}^t(\bm{b})) = \sum_{\bm{b} \in \mathcal{B}^{+M}} \prob(\bm{b}^\nround = \bm{b}) \exp(\eta \widehat{\mu}^t(\bm{b}))\,,
        \end{align*}
        where in the last equality, we used the condition that our algorithm samples bid vector $\bm{b}$ with probability proportional to $\exp(\eta \sum_{\tau=1}^{t-1} \widehat{\mu}^\nround(\bm{b}))$ at round $\nround$. In order to continue the chain of inequalities, we note that for $\eta \leq \frac{1}{M}$, we have that the quantity $\eta \widehat{\mu}^t(\bm{b})$ is upper bounded by 1 as $\eta \widehat{\mu}^t(\bm{b}) \leq \eta M \leq 1$. In the first inequality, we used the fact that $\widehat{\mu}^\nround(\bm{b}) \leq \Nitem$. Now, we can apply the inequalities $\exp(x) \leq 1 + x + x^2$ and $1 + x \leq \exp(x)$ for all $x \leq 1$, with $x= \eta \widehat{\mu}^t(\bm{b})$ and $x = \eta \prob(\bm{b}^\nround = \bm{b}) \widehat{\mu}^t(\bm{b})$, respectively,  to obtain:
        \begin{align*}
            \frac{\Phi^t}{\Phi^{t-1}} &\leq \sum_{\bm{b} \in \mathcal{B}^{+M}} \prob(\bm{b}^\nround = \bm{b}) \exp(\eta \widehat{\mu}^t(\bm{b})) \leq \sum_{\bm{b} \in \mathcal{B}^{+M}} \prob(\bm{b}^\nround = \bm{b}) \left[1 + \eta\widehat{\mu}^t(\bm{b}) + \eta^2 \widehat{\mu}^t(\bm{b})^2 \right]\\
            &= 1+ \sum_{\bm{b} \in \mathcal{B}^{+M}} \prob(\bm{b}^\nround = \bm{b}) \left[\eta\widehat{\mu}^t(\bm{b}) + \eta^2 \widehat{\mu}^t(\bm{b})^2 \right] \leq \exp(\sum_{\bm{b} \in \mathcal{B}^{+M}} \prob(\bm{b}^\nround = \bm{b}) \left[\eta\widehat{\mu}^t(\bm{b}) + \eta^2 \widehat{\mu}^t(\bm{b})^2 \right])\,.
        \end{align*}
        Combining this with Equation~\eqref{eq: Potentials} and then taking logarithms, we obtain:
        \begin{align*}
            \eta \sum_{t=1}^{T} \widehat{\mu}^t(\bm{b}') \leq \log \Phi^0 + \eta \sum_{t=1}^{T} \sum_{\bm{b} \in \mathcal{B}^{+M}} \prob(\bm{b}^\nround = \bm{b}) \widehat{\mu}^t(\bm{b}) + \eta^2 \sum_{t=1}^T \sum_{\bm{b} \in \mathcal{B}^{+M}}\prob(\bm{b}^\nround = \bm{b}) \widehat{\mu}^t(\bm{b})^2\,.
        \end{align*}
        Dividing both sides by $\eta$, applying the upper bound on $\Phi^0$, and rearranging, we obtain that for any $\bm{b}' \in \mathcal{B}^{+M}$:
        \begin{align*}
            \sum_{t=1}^{T} \widehat{\mu}^t(\bm{b}') - \sum_{t=1}^{T} \sum_{\bm{b} \in \mathcal{B}^{+M}} \prob(\bm{b}^\nround = \bm{b})  \widehat{\mu}^t(\bm{b}) \lesssim \eta^{-1} \Nitem \log |\mathcal{B}| + \eta \sum_{t=1}^T \sum_{\bm{b} \in \mathcal{B}^{+M}}\prob(\bm{b}^\nround = \bm{b}) \widehat{\mu}^t(\bm{b})^2\,.
        \end{align*}
        Taking expectations of $\widehat{\mu}^\nround(\bm{b})$ with its definition in terms of $\widehat{w}^\nround_m(b_m)$, we obtain the right hand side of the lemma:
        \begin{align*}
            \mathbb{E}\left[\sum_{t=1}^{T} \widehat{\mu}^t(\bm{b}') - \sum_{t=1}^{T} \sum_{\bm{b} \in \mathcal{B}^{+M}} \prob(\bm{b}^\nround = \bm{b})  \widehat{\mu}^t(\bm{b})\right] \lesssim \eta^{-1}M\log|\mathcal{B}| + \eta \sum_{\nround=1}^\Nround \sum_{\bm{b}} \prob(\bm{b}^\nround =\bm{b}) \mathbb{E}[(\sum_{m=1}^M \widehat{w}^\nround_m(b_m))^2]\,.
        \end{align*}
        Replacing $\sum_{\bm{b} \in \mathcal{B}^{+M}} \prob(\bm{b}^\nround = \bm{b})  \widehat{\mu}^t(\bm{b})$ with $\mathbb{E}[\widehat{\mu}^\nround(\bm{b}^\nround)]$ and recalling that the bid vector utility estimates $\widehat{\mu}^\nround$ were unbiased, we have:
        \begin{align*}
            \sum_{t=1}^{T} \mu^t(\bm{b}') - \sum_{t=1}^{T} \mathbb{E}[\mu^t(\bm{b}^\nround)] \lesssim \eta^{-1}M\log|\mathcal{B}| + \eta \sum_{\nround=1}^\Nround \sum_{\bm{b}} \prob(\bm{b}^\nround =\bm{b}) \mathbb{E}[(\sum_{m=1}^M \widehat{w}^\nround_m(b_m))^2]\,.
        \end{align*}
        Notice that as this is true for any $\bm{b}'$, we can replace it with the bid vector that maximizes the true cumulative utility $\sum_{t=1}^T \mu^\nround(\bm{b}')$ and see that the left hand side becomes precisely $\textsc{Regret}_\mathcal{B}$, which completes the proof.
        \Halmos
    \endproof

    Now, it remains to show an upper bound on the second moment of the bid vector utility estimate $\mathbb{E}[(\sum_{m=1}^M \widehat{w}^\nround_m(b_m))^2]$. A crude attempt would be to say that $\mathbb{E}[(\sum_{m = 1}^M \widehat{w}^\nround_m(b_m))^2] \leq \Nitem \sum_{m = 1}^M \mathbb{E}[\widehat{w}^\nround_m(b_m)^2]$:
    \begin{align}
        &\sum_{\nround=1}^\Nround \sum_{\bm{b}} \prob(\bm{b}^\nround = \bm{b}) \mathbb{E}[(\sum_{m = 1}^M \widehat{w}^\nround_m(b_m))^2] \leq \Nitem \sum_{\nround=1}^\Nround \sum_{\bm{b}} \prob(\bm{b}^\nround = \bm{b}) \sum_{m = 1}^M \mathbb{E}[\widehat{w}^\nround_m(b_m)^2] \label{eq: full info difference}\\
        &= \Nitem \sum_{\nround=1}^\Nround \sum_{\nitem = 1}^\Nitem \sum_{b \in \mathcal{B}} \mathbb{E}[\widehat{w}^\nround_m(b)^2] \sum_{\bm{b}: b_m = b} \prob(\bm{b}^\nround = \bm{b}) = \Nitem \sum_{\nround=1}^\Nround \sum_{\nitem = 1}^\Nitem \sum_{b \in \mathcal{B}} \mathbb{E}[\widehat{w}^\nround_m(b)^2] q^\nround_m(b) \notag\\
        &\leq \Nitem \sum_{\nround=1}^\Nround \sum_{\nitem = 1}^\Nitem \sum_{b \in \mathcal{B}} \frac{2}{q_m^t(b)} q_m^t(b) = O(\Nitem^2 |\mathcal{B}| \Nround)\,. \notag
    \end{align}
    Where the last inequality follows from:
    \begin{align*}
        \mathbb{E}[\widehat{w}_m^t(b)^2] = \mathbb{E}\left[\left( 1 - \frac{1-w_m^t(b)}{q_m^t(b)} \textbf{1}_{b_m^t = b} \right)^2 \right] = 1 - 2\mathbb{E}\left[\frac{1-w_m^t(b)}{q_m^t(b)}\textbf{1}_{b_m^t=b}\right] + \mathbb{E}\left[\left(\frac{1-w_m^t(b; \bm{v})}{q_m^t(b)}\right)^2\textbf{1}_{b_m^t=b}\right]\,.
    \end{align*}
    Evaluating the expectations with $\mathbb{E}\left[\textbf{1}_{b_m^t = b}\right] = q_m^t(b)$, we have:
    \begin{align*}
        \mathbb{E}[\widehat{w}_m^t(b)^2] = 1 - \left[2 - 2w_m^t(b)\right] + \left[\frac{(1 - w_m^t(b))^2}{q_m^t(b)}\right] = 2w_m^t(b) - 1 + \frac{1}{q_m^t(b)} \leq 1 + \frac{1}{q_m^t(b)} \leq \frac{2}{q_m^t(b)}\,.
    \end{align*}    
    Plugging this back into our upper bound yields stated regret bound for $\eta = \Theta(\sqrt{\frac{\log |\mathcal{B}|}{M|\mathcal{B}|T}})$ such that $\eta < \frac{1}{M}$:
    
    \begin{align*}
        \textsc{Regret}_\mathcal{B} \lesssim \eta^{-1}\Nitem \log |\mathcal{B}| + \eta\Nitem^2 |\mathcal{B}|T = O(\Nitem^{\frac{3}{2}}\sqrt{|\mathcal{B}| \Nround \log |\mathcal{B}|})\,.
    \end{align*}

    \textbf{Part 3: Complexity Analysis.} We note that the time and space complexity analysis is identical to that of Algorithm~\ref{alg: Decoupled Exponential Weights}, as the only additional computational work being done is computing the normalization terms $q_m^\nround(b)$, which requires $O(M|\mathcal{B}|)$ space and $O(MT|\mathcal{B}|)$ time respectively. Hence, discarding old tables, the total time and space complexities of Algorithm \ref{alg: Decoupled Exponential Weights - Path Kernels} are $O(\Nitem |\mathcal{B}| \Nround)$ and $O(\Nitem |\mathcal{B}|)$ respectively. As this is polynomial in $\Nitem, |\mathcal{B}|, \Nround$, we have proven the claim of polynomial space and time complexities.

    \textbf{Part 4: Selecting $\mathcal{B}$.} We claim that the sub-optimality due to the discretization is on the order of $\frac{MT}{|\mathcal{B}|}$. Assume that $\mathcal{B} \equiv \{\frac{i}{|\mathcal{B}|}\}_{i \in [|\mathcal{B}|]}$ is an even discretization of $[0, 1]$, and recall the continuous regret benchmark:
    \begin{align*}
        \textsc{Regret} = \max_{\bm{b} \in [0, 1]^{+\Nitem}} \sum_{\nround=1}^\Nround \mu^\nround_n(\bm{b}) - \mathbb{E}\left[\sum_{\nround=1}^\Nround \mu^\nround_n(\bm{b}^\nround)\right],
    \end{align*}
    where the maximum is taken over the entire space $[0, 1]^{+\Nitem}$ rather than $\mathcal{B}^{+\Nitem}$. Let $\bm{b}^*$ denote the maximizer of the continuous regret. Then, bidder $n$ could have obtained at least the same allocation by rounding up each bid in $\bm{b}^*$ to the next largest multiple of $\frac{1}{|\mathcal{B}|}$. Let this rounded bid vector be denoted by $\bm{b}^+$. As their allocation, thus value for the set of items received, does not decrease, and their total payment increases by a maximum of $\frac{M}{|\mathcal{B}|}$ at each round, then we have that $\mu_n^t(\bm{b}^+) \geq \mu_n^t(\bm{b}^*) - \frac{M}{|\mathcal{B}|}$. Let $\bm{b}_{\mathcal{B}}^* \in \mathcal{B}^{+\Nitem}$ denote the hindsight optimal utility vector returned by our offline dynamic programming (Algorithm~\ref{alg: Offline Full}), which serves as the regret benchmark in the definition of discretized regret. Noting that $\bm{b}^+ \in \mathcal{B}^{+\Nitem}$, we have that the total utility of bidding $\bm{b}^*_{\mathcal{B}}$ must be at least that of $\bm{b}^+$. Thus,
    \begin{align*}
        \sum_{\nround=1}^\Nround \mu^\nround_n(\bm{b}_{\mathcal{B}}^*) \geq \sum_{\nround=1}^\Nround \mu^\nround_n(\bm{b}^+)\geq \sum_{\nround=1}^\Nround \mu^\nround_n(\bm{b}^*) - \frac{MT}{|\mathcal{B}|}
    \end{align*}
    We balance this with the discretized regret $O(\Nitem^{\frac{3}{2}}\sqrt{|\mathcal{B}| \Nround \log |\mathcal{B}|})$ with $|\mathcal{B}| = M^{-\frac{1}{3}}T^{\frac{1}{3}}$. This yields continuous regret $\textsc{Regret} = O(M^{\frac{4}{3}}T^{\frac{2}{3}} \sqrt{\log \Nround})$.

    \textbf{Part 5: Extending to the Full Information Setting.} Thus far, we have only discussed the bandit feedback algorithm. Fortunately, the full information setting algorithm is exactly the same except for two differences: 1) we do not need to compute $\bm{q}$ and 2) we can replace the reward estimates $\widehat{\mu}^t(\bm{b})$ with the true rewards $\mu^t(\bm{b})$ in Equation~\ref{eq: full info difference}. The first difference can only serve to improve the time and space complexity of our algorithm. The second difference allows us to improve the bound on $\sum_{\nround=1}^\Nround \sum_{\bm{b}} \prob(\bm{b}^\nround = \bm{b}) \mathbb{E}[(\sum_{m = 1}^M \widehat{w}^\nround_m(b_m))^2]$ in the left hand sight of Equation~\ref{eq: full info difference} by replacing $\widehat{w}^\nround_m(b_m))$ with $w^t_m(b_m)$:
    \begin{align*}
        \sum_{\nround=1}^\Nround \sum_{\bm{b}} \prob(\bm{b}^\nround = \bm{b}) \mathbb{E}[(\sum_{m = 1}^M \widehat{w}^\nround_m(b_m))^2] = \sum_{\nround=1}^\Nround \sum_{\bm{b}} \prob(\bm{b}^\nround = \bm{b}) \mathbb{E}[(\sum_{m = 1}^M \widehat{w}^\nround_m(b_m))^2] \leq M^2 \sum_{\nround=1}^\Nround \sum_{\bm{b}} \prob(\bm{b}^\nround = \bm{b}) = M^2T
    \end{align*}
    
    Notice that this bound is a factor of $|\mathcal{B}|$ improvement over that in the bandit setting. Consequently, we obtain our stated regret bound of $O(M^\frac{3}{2} \sqrt{T \log |\mathcal{B}|})$ with the choice of $\eta = \Theta(\sqrt{\frac{\log |\mathcal{B}|}{MT}})$. Balancing this regret with the error term, which is of order $O\left(\frac{M|\mathcal{B}|}{T}\right)$, the optimal choice of $|\mathcal{B}|$ is given by $\Theta(\sqrt{\frac{T}{M}})$. This yields corresponding continuous regret of $O(M^{\frac{3}{2}}\sqrt{T \log T})$.
    

\end{proof}









 

\section{Regret Lower Bounds}

In this section, we prove our stated regret lower bounds for both the full information and bandit feedback settings.

\subsection{Proof of Theorem \ref{thm:lower}: Regret Lower Bound (Full Information)}

To construct our lower bounds, we construct a stochastic adversary whose distribution across their bids makes it difficult for the bidder to determine their optimal bid, and thus, occurs $\Omega(M\sqrt{T})$ regret while doing so. We define $\bm{b}'_- = (0,\ldots,0,c,\ldots,c)$, where there are $k$ and $\Nitem - k$ values of 0 and $c$ each. We additionally define $\bm{b}"_- = (c,\ldots,c)$ as the $\Nitem$-vector of bids at $c$. Restricting the adversary's bid vectors to be in $\{\bm{b}'_-, \bm{b}"_-\}$, we construct two adversary bid vector distributions $F$ and $G$ over $\{\bm{b}'_-, \bm{b}"_-\}^\Nround$ such that   under $F$, we have $\prob(\bm{b}_-^\nround = \bm{b}'_-) = \frac{1}{2} + \delta$  and $\prob(\bm{b}_-^\nround = \bm{b}"_-) = \frac{1}{2} - \delta$ 
 and under $G$, we have $\prob(\bm{b}_-^\nround = \bm{b}'_-) = \frac{1}{2} - \delta$ and $\prob(\bm{b}_-^\nround = \bm{b}"_-) = \frac{1}{2} + \delta$  for some $\delta \in [0, \frac{1}{2}]$ to be optimized over later. 
 
 
 Assume that $\bm{v} = (1,\ldots,1)$, all tiebreaks are won for simplicity, and the competitors' bids over time are independent. Then, for certain choices of $c$ and $k$ (which we show below), the expected utility maximizing bid vector under $\{\bm{b}_-^\nround\}_{\nround \in [\Nround]} \sim F$ is $(0,\ldots,0)$ and under $\{\bm{b}_-^\nround\}_{\nround \in [\Nround]} \sim G$ is $(c,\ldots,c)$. 
 In particular, we can compute precisely the expected value of bidding $\bm{b}^\nround = \bm{b}$ for all $\nround \in [\Nround]$ under both $F$ and $G$. Note that as adversary bid values only take values in $\{0, c\}$ and bidder $n$ wins all tiebreaks, then the bidder only need consider bid vectors consisting only of all $0$ or $c$. Letting $\nitem$ denote the number of bids in $\bm{b}$ equal to $c$, we have:
    \begin{align*}
        \mathbb{E}_F\left[ \mu_n^\nround(\bm{b})\right] =  (\frac{1}{2} + \delta)\left((1 - c)m + \max(0, M - k - m)\right)  + (\frac{1}{2} - \delta)(1 - c)m  \,.
    \end{align*}
    Where $\mathbb{E}_F$ denotes the expectation with respect to the adversary bids drawn from $F$, namely $\{\bm{b}_-^\nround\}_{\nround \in [\Nround]} \sim F$ (and similarly for $\mathbb{E}_G$ below). In particular, we have that with probability $\frac{1}{2} + \delta$, the adversary will select bid $\bm{b}'_-$. We are then guaranteed to win $m$ units at a price of $c$, for a utility of $1 - c$ per unit. If $\nitem < k$, then $M - k - m$ of the items were won with price 0, for a utility of 1 per unit. With probability $\frac{1}{2}-\delta$, all of the adversary bids are $c$, and we obtain $\nitem$ units at a cost of $c$ each, which corresponds to utility $1 - c$. Similarly, we have: 
    \begin{align*}
        \mathbb{E}_G\left[\mu_n^\nround(\bm{b})\right] =  (\frac{1}{2} - \delta)\left((1 - c)m + \max(0, M - k - m)\right)  + (\frac{1}{2} + \delta)(1 - c)m \,.
    \end{align*}
    If we sample $\{\bm{b}^\nround_-\}_{\nround \in [\Nround]}$ according to the mixture $\frac{F+G}{2}$, this corresponds to the case where $\delta = 0$, i.e., the probability of observing either $\bm{b}'_-$ or $\bm{b}"_-$ is equal. We have for all $\bm{b}$:
    \begin{align*}
        \mathbb{E}_{(F+G)/2}[\mu_n^\nround(\bm{b})] = \frac{1}{2}((1 - c)m + \max(0, M-k-m)) + \frac{1}{2}(1 -c)m = (1-c)m + \frac{1}{2}\max(0, M-k-m) 
    \end{align*}
    Note that under $F$, the optimal occurs at the all 0's vector for $c > \frac{1}{2} - \delta$ and $(\frac{1}{2} + \delta)(M - k) > (1-c)m = 0$. Similarly, the optimal occurs at the all $c$'s vector for $c > \frac{1}{2} - \delta$ and $(\frac{1}{2} - \delta)(M - k) > (1 - c)M$. These obtain utilities of $(\frac{1}{2}+\delta)(M-k)$ and $M - Mc$ respectively. One choice of $c$ and $k$ is $\frac{2}{3}$ and $\frac{M}{3}$, with $0 < \delta < \frac{1}{6}$. Looking at the regret incurred each step of the algorithm by selecting any action $\bm{b}$, we have:
    \begin{align*}
        &\max_{\bm{b}'} \left(\mathbb{E}_F[ \mu_n^\nround(\bm{b}') - \mu_n^\nround(\bm{b})] \right) + \max_{\bm{b}'} \left(\mathbb{E}_G[ \mu_n^\nround(\bm{b}') - \mu_n^\nround(\bm{b})] \right) \\
        &\geq \max_{\bm{b}'} \mathbb{E}_F[\mu_n^\nround(\bm{b}')] + \max_{\bm{b}'} \mathbb{E}_G[\mu_n^\nround(\bm{b}')] - 2\max_{\bm{b}'} \mathbb{E}_{(F+G)/2}\left[  \mu_n^\nround(\bm{b}')\right]\\
        &\geq \mathbb{E}_F[ \mu_n^\nround((0,\ldots,0))] + \mathbb{E}_G[ \mu_n^\nround((c,\ldots,c))] - 2\max_{\bm{b}'} \mathbb{E}_{(F+G)/2}\left[  \mu_n^\nround(\bm{b}')\right]\\
        &= (\frac{1}{2}+\delta)(M-k) + \left(M - Mc\right) - 2\max_{\bm{b}'} \mathbb{E}_{(F+G)/2}\left[\mu_n^\nround(\bm{b}')\right]\\
        &\geq (\frac{1}{2}+\delta)(M-k) + \left(M - Mc\right) - \max_{m \in [M]} \left(2(1-c)m + \max(0, M-k-m) \right)
    \end{align*}
    Let $k = \frac{M}{3}$ and $c = \frac{2}{3}$, and the above expression simplifies to:
    \begin{align*}
        \frac{2M(1+\delta)}{3} - \max_{m \in [M]} \left(\frac{2m}{3} + \max(0, \frac{2M}{3}-m) \right) = \frac{2M(1+\delta)}{3} - \frac{2M}{3} = \frac{2M\delta}{3} = \Theta(M\delta)\,.
    \end{align*}     
    We can now invoke the useful lemma relating the regret under $(F+G)/2$ to the Kullback-Leilber divergence:
    \begin{lemma}[\cite{NonparametricEstimation2008} Theorem 2.2.]
        We have for any two discrete distributions $F$ and $G$:
        \begin{align}
            \mathbb{E}_{(F+G)/2} \left[\textsc{{Regret}}_\mathcal{B}(T)\right] = \Omega\left( \frac{\Delta}{2} \exp(-D_{\emph{KL}(F || G)}) \right)\,,
        \end{align}
        where $\Delta$ denotes the sum of the total regret incurred under $F$ or $G$.
    \end{lemma} 
    When $F$ and $G$ are independent Bernoulli processes with parameters $\frac{1}{2}+\delta$ and $\frac{1}{2}-\delta$ respectively, then $D_{\text{KL}}(F || G) \leq CT\delta^2$ for some constant $C$. Using $\Delta = \Theta(MT\delta)$ and $\delta = \Omega(\frac{1}{\sqrt{T}})$, we have that the previous lemma implies
    \begin{align}
        \textsc{Regret}_{\mathcal{B}}  = \Omega\left(\Nitem \sqrt{\Nround}\right)\,.
    \end{align}                 

\subsection{Proof of Theorem \ref{thm:lower_bound_bandit}: Regret Lower Bound (Bandit Feedback)}\label{sec:proof:lower:bandit}

  {\color{black}To construct the regret lower bound, we begin by establishing a base hypothesis concerning the distribution of the highest competing bids. Specifically, let \(H_{m}\) represent the marginal cumulative distribution function (CDF) of the \((M-m+1)\)'st highest competing bid, denoted by \(b_{-m}\):
    \[H_m(b) = \min(1,\frac{c_m}{1 - b}) \quad \text{for} \quad c_m = \frac{1}{2} - \frac{m}{4M}\] 
    and $b \in \mathcal{B}$. We note that larger $m$ implies smaller $c_m$, which implies a smaller CDF for the same value of $b$; i.e. $H_m(b) \geq H_{m+1}(b)$  for all $b \in \mathcal{B}$. Thus, this satisfies the stochastic dominance requirement on the highest other bids $b_{-1}\leq \ldots \leq b_{-M}$, and there exists a joint distribution over highest other bids such that their marginal distributions are precisely $H_m$ for all $m \in [M]$. 
        
    Assuming that the bidder's valuations are $\bm{v} = [1,\ldots,1]$ and they given tie-break priority, the expected utility for bidding $b$ for unit $m$ is equal to
    \[(1-b)\prob(b \geq b_{-m}) = (1-b)H_m(b) = c_m,\qquad b \in [0, 1-c_m]\,.\] That is, the expected utility from the $m$'th unit is precisely $c_m$ for any bid $b\in [0, 1-c_m]$. Here, the expected utility for any bid $b > 1 - c_m$ will be strictly smaller than $c_m$.

    Now, we construct a partitioning over the bid discretization space.  Assuming an even discretization $\mathcal{B} = \{\frac{i}{|\mathcal{B}|}\}_{i \in \mathcal{B}}$ with $|\mathcal{B}| = M^{\frac{1}{3}}T^{\frac{1}{3}}$, we partition $\mathcal{B}$ into $M$ disjoint buckets: 
    \[\mathcal{B}_m = \mathcal{B} \cap (\frac{1}{2} - \frac{m}{4M}, \frac{1}{2} - \frac{m-1}{4M}]\,.\]
    Here, each $\mathcal{B}_m$ is of size $\frac{|\mathcal{B}|}{4M}$, and notice that $\mathcal{B}_m$ lies entirely to the right of $\mathcal{B}_{m+1}$; i.e., $b > b'$ for any $b \in \mathcal{B}_m$ and  $b' \in \mathcal{B}_{m+1}$.  See Figure \ref{fig:partitions} for an illustration. We note that we are not restricting bids for the $m$'th unit to be within $\mathcal{B}_m$. We only construct this partition to generate a family of hypotheses the agent will have to differentiate between. 

Now, we construct the family of hypotheses \(\mathcal{H} = \{\times_{m=1}^M \mathcal{H}_m^{j_m}, j_m \in [|\mathcal{B}_m|], m\in [M]\}\) in a similar manner as \cite{DemandCurve2003}, where each hypothesis $(\mathcal{H}_m^{j_m})_{m\in [M]}$ can be described by \(M\) indices, \(j_m\), \(m\in [M]\). Here, index \(j_m\in [|\mathcal{B}_m|]\) is associated with \emph{the unit-\(m\) hypothesis}.
  
    
    In particular, for unit  $m$, we construct $|\mathcal{B}_m|$ possible hypotheses (i.e., $\mathcal{H}_m^{j_m}$, $j_m\in [|\mathcal{B}_m|]$), each indexed by $j_m$ where for hypothesis $\mathcal{H}^{j_m}_m$, 
    the utility of the bidder for unit $m$ from submitting bid $b^{j_m}_m$---defined as the ${j_m}$'th largest value in $\mathcal{B}_m$---is marginally larger than the remaining bid values in $\mathcal{B}_m$ by perturbing the base distribution $H_m(b^{j_m}_m)$ by $\gamma_m > 0$. More formally, define marginal CDF's $\{H_m^{j_m}\}_{j_m \in [|\mathcal{B}_m|]}$ for each $m \in [M]$, such that $H_m^{j_m}(b) = H_m(b)$ for all $b \in \mathcal{B}$, except at $b^j_m \in \mathcal{B}_m$, and $H_m^{j_m}(b_m^{j_m}) = H_m(b_m^{j_m}) + \gamma_m$. \footnote{The agent does not need to differentiate between every hypothesis in $\mathcal{H} = \{\times_{m=1}^M \mathcal{H}^{j_m}_m\}_{j_m \in |\mathcal{B}_m| \forall m}$, which is exponentially large. As the utility function for bidding $\bm{b}$ can be decomposed into the sum of utilities of each of the $M$ units, the agent only needs to differentiate between each of the $\mathcal{H}^{j}_m$.}
    Here, we require $\gamma_m$ to satisfy the following constraint: $$\gamma_m \leq \min\left(H_m(b_m^{j_m} + \frac{1}{|\mathcal{B}|}) - H_m(b_m^{j_m}), H_m(b_m^{j_m}) - H_{m+1}(b_m^{j_m})\right)\,.$$ The first term $H_m(b_m^{j_m} + \frac{1}{|\mathcal{B}|}) - H_m(b_m^{j_m})$ corresponds to the constraint that the CDF is non-decreasing. The second term $H_m(b_m^{j_m}) - H_{m+1}(b_m^{j_m})$ corresponds to the highest-other-bid monotonicity constraint. Using our precise definitions of $H_m$, we see that: \footnote{We also note another constraint requires that $H_m(b_m^j + \frac{1}{|\mathcal{B}|})$ and $ H_m(b_m^j)$ needs to be unique, specifically, that they are not both equal to 1. Since we defined the set $\mathcal{B}_m$ to be within $(\frac{1}{2} - \frac{m}{4M}, \frac{1}{2} - \frac{m-1}{4M}]$, the largest value in $\mathcal{B}_m$ is $\frac{1}{2} - \frac{m-1}{4M}$. Plugging this into $H_m^j$, we see that $H_m(\max(\mathcal{B}_m)) = \min(1, \frac{\frac{1}{2} - \frac{m}{4M}}{1 - \max(\mathcal{B}_m)} = \min(1, \frac{\frac{1}{2} - \frac{m}{4M}}{\frac{1}{2} + \frac{m-1}{4M}}) < 1$.}
    \begin{align*}H_m(b_m^{j_m} + \frac{1}{|\mathcal{B}|}) - H_m(b_m^{j_m})&= \frac{c_m}{|\mathcal{B}|(1 - b_m^{j_m})(1-b_m^{j_m} - |\mathcal{B}|^{-1})} \\
   & =
   \frac{\frac{1}{2} - \frac{m}{4M}}{|\mathcal{B}|(1 - b_m^{j_m})(1-b_m^{j_m} - |\mathcal{B}|^{-1})}
   \geq \frac{\frac{1}{2} - \frac{m}{4M}}{|\mathcal{B}|(  \frac{1}{2} + \frac{m}{4M})(\frac{1}{2} + \frac{m}{4M} - |\mathcal{B}|^{-1})}\,.
    \end{align*}
    This function is decreasing for any $0 \leq m \leq M$, as the term $\frac{m}{M}$ appears negatively in the numerator and positively in the denominator. Thus, we have
    \[\frac{\frac{1}{2} - \frac{m}{4M}}{|\mathcal{B}|(  \frac{1}{2} + \frac{m}{4M})(\frac{1}{2} + \frac{m}{4M} - |\mathcal{B}|^{-1})} \ge  \frac{\frac{1}{2} - \frac{1}{4}}{|\mathcal{B}|(  \frac{1}{2} + \frac{1}{4})(\frac{1}{2} + \frac{1}{4} - |\mathcal{B}|^{-1})} \ge 4/|\mathcal{B}| \]
    as desired.
Further, 
    $$H_m(b_m^j) - H_{m+1}(b_m^{j_m}) = \frac{c_{m} - c_{m+1}}{1-b_m^{j_m}}  =
    \frac{\frac{1}{4M}}{ \frac{1}{2} + \frac{m}{4M}}
    \geq \frac{\frac{1}{4M}}{ \frac{1}{2} + \frac{1}{4}} \ge \frac{1}{3M}\,.$$
    Combining these, we see that $\gamma_m$ is $O\left(\min(\frac{1}{|\mathcal{B}|}, \frac{1}{M})\right)$. We then see that the expected utility of bidding $b_m^{j_m} $ for unit $m$ is $c_m + \gamma_m(1-b_m^{j_m}) = c_m + O\left(\min(\frac{1}{|\mathcal{B}|}, \frac{1}{M})\right)$  as compared to the expected utility of bidding $b \neq b_m^j$ for unit $m$, which is precisely just $c_m$. This sub-optimality plays a direct role in the regret accumulated by item $m$, which is precisely the number of times that the optimal $b_m^{j_m}$ was \textit{not} selected times the difference between the reward of the optimal and sub-optimal arms, which is $O(\gamma_m)$.
    We will select $\gamma_m = \gamma = \frac{1}{48\max(|\mathcal{B}|, M)}$ for all $m$. Now, we rewrite the regret lower bound as a function of the number of times that the optimal bid $b_m^{j_m}$ was not selected for for the $m$'th bid. Let
    \[
    \mathcal{S}(m, t) = \{m' \in [M]: b_{m'}^t \in \mathcal{B}_m\} \quad \text{and} \quad T_m = \sum_{t=1}^T |\mathcal{S}(m, t)|
    \] 
    where $\mathcal{S}(m, t)$ denotes the set of bids at round $t$ that took on value in $\mathcal{B}_m$ for any unit $m'\in [M]$ (including unit $m$), and $T_m$ denotes the total number of times across all rounds that any bid was selected within $\mathcal{B}_m$. Assuming that all bids fall within one of the $M$ buckets, as bidding outside of these buckets is strictly utility sub-optimal and also cannot provide any information on distinguishing between the unit hypotheses, we have:
     \begin{align*}
        \textsc{Regret}_{\mathcal{B}} &= \sum_{t=1}^T \sum_{m=1}^M 1_{b_m^t \neq b_m^{j_m}} \gamma(1 - b_m^{j_m}) \overset{(a)}{\geq} \frac{\gamma}{2} \sum_{t=1}^T \sum_{m=1}^M 1_{b_m^t \neq b_m^{j_m}} \overset{(b)}{=} \frac{\gamma}{2} \sum_{t=1}^T \sum_{m=1}^M \sum_{i \in \mathcal{S}(m, t)} 1_{b_{i}^t \neq b_i^{j_i}}\\
        &\overset{(c)}{=} \frac{\gamma}{4} \sum_{m=1}^M \left[ \sum_{t=1}^T \sum_{i \in \mathcal{S}(m, t)} 1_{b_{i}^t \neq b_i^{j_i}} + \sum_{t=1}^T \sum_{i \in \mathcal{S}(m, t)} 1_{b_{i}^t \neq b_i^{j_i}} \right]\,.\\
       &{=}\frac{\gamma}{4} \sum_{m=1}^M \left[ \sum_{t=1}^T \sum_{i \in \mathcal{S}(m, t)} 1_{b_{i}^t \neq b_i^{j_i}} + \sum_{t=1}^T \sum_{i\in S(m, t)}(1- 1_{b_i^t = b_i^{j_i}}) \right]\\
       &{=}\frac{\gamma}{4} \sum_{m=1}^M \left[ \sum_{t=1}^T \sum_{i \in \mathcal{S}(m, t)} 1_{b_{i}^t \neq b_i^{j_i}} + \sum_{t=1}^T|S(m,t)|- \sum_{t=1}^T \sum_{i\in S(m,t)} 1_{b_i^t = b_i^{j_i}} \right]\\
        &\overset{(d)}{=}\frac{\gamma}{4} \sum_{m=1}^M \left[ \sum_{t=1}^T \sum_{i \in \mathcal{S}(m, t)} 1_{b_{i}^t \neq b_i^{j_i}} + \sum_{t=1}^T |\mathcal{S}(m, t)| - \sum_{t=1}^T 1_{b_m^t = b_m^{j_m}} \right]\,.
    \end{align*}
    
Here, the inequality (a) holds because  $b_m^{j_m}< 1/2$, and the  equality (b) holds because for any  $t$, $m,m'\in [M]$,  and $m\ne m'$, we have $S(m, t)\cap S(m', t)=\emptyset$.  The   equality (c) is a simple algebraic manipulation. The   equality (d) uses the fact that  any time a bid for item $i \neq m$ takes value in $\mathcal{B}_m$ (see the definition of $S(m, t)$), it cannot possibly be equal to $b_{i}^{j_i} \in \mathcal{B}_i$ since $\mathcal{B}_i$ and $\mathcal{B}_m$ are disjoint.
We then have 
    \begin{align}
        \textsc{Regret}_{\mathcal{B}}
        &\overset{(e)}{\geq} \frac{\gamma}{4} \sum_{m=1}^M \left[ \sum_{t=1}^T \sum_{i \in \mathcal{S}(m, t)} 1_{b_{i}^t \neq b_i^{j_i}} + \max(0, T_m - T) \right] 
        \\
        &\overset{(f)}{\geq} \frac{\gamma}{4} \sum_{m=1}^M \left[ \sum_{t=1}^T \sum_{i \in \mathcal{S}(m, t)} 1_{b_{i}^t \neq b_m^{j_m}} + \max(0, T_m - T) \right] 
        \\
        &\overset{(g)}{\geq} \frac{\gamma}{4} \sum_{m=1}^M \left[ \max(0, T_m - c\gamma T_m^{\frac{3}{2}}\sqrt{\frac{M}{|\mathcal{B}|}}) + \max(0, T_m - T) \right] 
    \end{align}
   Inequality (e) holds since the maximum number of times that the $m$'th bid is equal to its optimal is at most $T$---i.e. $\sum_{t=1}^T 1_{b_m^t = b_m^{j_m}} \leq T$.
   Inequality (f) follows as for any $i \neq m, i \in \mathcal{S}(m, t)$, we have that $1_{b_i^t \neq b_i^{j_i}} = 1 \geq 1_{b_i^t \neq b_m^{j_m}}$ as $b_i^t \in \mathcal{B}_m$ and $b_i^{j_i} \notin \mathcal{B}_m$ for $i \neq m$. 
    To obtain inequality (g), we notice that the term $\sum_{t=1}^T \sum_{i \in \mathcal{S}(m, t)} 1_{b_{i}^t \neq b_m^{j_m}}$ is precisely the number of times that the optimal price $b_m^{j_m}$ was \textit{not} selected out of $\sum_{t=1}^T \sum_{i \in \mathcal{S}(m, t)} 1 = T_m$ times. From Theorem 4.3 and Lemma 4.4 of \cite{DemandCurve2003}, the number of times that the optimal action (price in their context and bid in our context) \textit{was selected} (out of $K$ possible actions) over the course of $T_m$ draws is upper bounded by $c\epsilon T_m^{\frac{3}{2}} K^{-\frac{1}{2}}$ for some absolute constant $c \in (2/3,1)$ (for example, $c = \frac{2\sqrt{2}}{3}$ as in \cite{DemandCurve2003}) and perturbation of size $\epsilon$ (i.e, the cost of not choosing the correct hypothesis). Plugging in $K = |\mathcal{B}_m| = \frac{|\mathcal{B}|}{M}$ and $\epsilon = \gamma_m = \gamma$, we obtain inequality (g).

    In the paradigm with large $T$ and small $M$, more specifically with $T \geq M^2 \to |\mathcal{B}| = M^{\frac{1}{3}}T^{\frac{1}{3}} \geq M$, we have $\gamma = \frac{1}{32\max(|\mathcal{B}|, M)} = \Theta(\frac{1}{|\mathcal{B}|}) = \Theta(M^{-\frac{1}{3}}T^{-\frac{1}{3}})$. Plugging this in, we obtain:
    \begin{align}
        \textsc{Regret}_{\mathcal{B}} \geq \frac{M^{-\frac{1}{3}}T^{-\frac{1}{3}}}{4} \sum_{m=1}^M  T_m\left[ \max(0, 1 - c\sqrt{\frac{T_m}{T}}) + \max(0, T_m - T) \right]\,.\label{eq: tm to t 4}
    \end{align}
    Since the agent seeks to minimize regret, they take the minimum over $\bm{T} = (T_1,\ldots,T_M)$, subject to $MT = \sum_{m=1}^M T_m \in \mathbb{N}^M$ for $T_m \in \mathbb{N}$.
    \begin{align*}
        \textsc{Regret}_{\mathcal{B}} \geq \frac{M^{-\frac{1}{3}}T^{-\frac{1}{3}}}{4} \sum_{m=1}^M  T_m\left[ \max(0, 1 - c\sqrt{\frac{T_m}{T}}) + \max(0, T_m - T) \right]  \quad \text{s.t.} \quad \sum_{m=1}^M T_m = MT
    \end{align*}

\begin{lemma} \label{lem:optimization}
Consider the following optimization problem for any $c\in (0, 1)$: 
\[\min_{\{T_m\}_{m\in [M]}, T_m \ge 0}\sum_{m=1}^M  T_m\left[ \max(0, 1 - c\sqrt{\frac{T_m}{T}}) + \max(0, T_m - T) \right]  \quad \text{s.t.} \quad \sum_{m=1}^M T_m = MT\,.\]
where $T_m\in \in \mathbb{Z} $ are integers. 
Then, the optimal solution happens at $T_m= T$ for any $m\in [M]$.
\end{lemma}

The proof of the theorem is completed by applying Lemma  \ref{lem:optimization}. Plugging in $T_m = T$ into Equation~\ref{eq: tm to t 4}, we obtain a regret lower bound of $\textsc{Regret}_{\mathcal{B}} \geq \frac{1-c}{4} M^{\frac{2}{3}}T^{\frac{2}{3}} = \Omega(M^{\frac{2}{3}}T^{\frac{2}{3}})$.


$\blacksquare$ 


    \begin{proof}{Proof of Lemma \ref{lem:optimization}}
    To show that the optimal solution is precisely $\bm{T} = (T,\ldots,T)$, we minimize the objective function over the set of $T_m \in \mathbb{R}^+$ subject to $\sum_{m=1}^M T_m \geq MT$, which is subsumes the original equality constraint $\sum_{m=1}^M T_m = MT$ for integral $T_m \in \mathbb{Z}$. We show that $\bm{T} = (T,\ldots,T)$ is a solution to this relaxed problem, and since this satisfies the inequality and integrality constraints, it must be optimal for the original problem. We begin by finding first order conditions for the objective function: 
    \begin{align*}
        R(\bm{T}) \doteq \sum_{m=1}^M  \left[T_m \max(0, 1 - c\sqrt{\frac{T_m}{T}}) + \max(0, T_m - T) \right]\,.
    \end{align*}
    We consider the following cases:
    
    \begin{enumerate}
        \item If $1 \leq \frac{T_m}{T} \leq \frac{1}{c^2}$, the partial derivative of $R(\bm{T})$ with respect to $T_m= T(\frac{4}{3c})^2$  is zero; that is,  
        we have $0 = \delta_{T_m} R(\bm{T}) = 2 - \frac{3}{2}c\sqrt{\frac{T_m}{T}} \to T_m = T(\frac{4}{3c})^2$.
        However, this does not imply that  $T_m = T(\frac{4}{3c})^2$ is a minimizer as 
     it violates the second order optimality conditions. In particular,  for any value of $T_m > 0$, we have 
        \begin{align*}
            \delta_{T_m^2} R(\bm{T}) = -\frac{3}{4}c\sqrt{\frac{1}{T_mT}} < 0\,.
        \end{align*}
        Given that the second derivative is negative and the first derivative is positive for \( T_m < T \left( \frac{4}{3c} \right)^2 \) and negative for \( T_m > T \left( \frac{4}{3c} \right)^2 \), we only need to examine the boundary points \( T \) and \( \frac{T}{c^2} \). 

        \item If $\frac{T_m}{T} \leq 1 \leq \frac{1}{c^2}$, we have $0 = \delta_{T_m} R(\bm{T}) = 1$. This derivative is always positive. We then only need to check for the minimum boundary case, which is $T_m = 0$ as the derivative is positive.
        \item If $1 \leq \frac{1}{c^2} \leq \frac{T_m}{T}$, we have $0 = \delta_{T_m} R(\bm{T}) = 1 - \frac{3}{2}c\sqrt{\frac{T_m}{T}} \to T_m = T(\frac{2}{3c})^2$.  However, this does not imply that  $T_m = T(\frac{2}{3c})^2$ is a minimizer as 
     it violates second order optimality. In particular, for any value of $T_m > 0$, we have:
        \begin{align*}
            \delta_{T_m^2} R(\bm{T}) = -\frac{3}{4}c\sqrt{\frac{1}{T_mT}} < 0
        \end{align*}
        The first derivative is positive when $T_m < T(\frac{2}{3c})^2$ and negative when $T_m > T(\frac{2}{3c})^2$. This implies that we only need to check $T_m$ at the two boundary points, which are $T_m = \frac{T}{c^2}$ and $T_m = \infty$ (which is clearly sub-optimal). 
    \end{enumerate}
    In summary, we only need to check for the cases where $T_m \in \{0, T, \frac{T}{c^2}\}$. We check the value of the $m$'th summand for each of these cases:
    \begin{enumerate}
        \item $T_m = 0$: We have $T_m \max(0, 1 - c\sqrt{\frac{T_m}{T}}) + \max(0, T_m - T) = 0$.
        \item $T_m = T$: We have $T_m \max(0, 1 - c\sqrt{\frac{T_m}{T}}) + \max(0, T_m - T) = (1 - c)T$.
        \item $T_m = \frac{T}{c^2}$: We have $T_m \max(0, 1 - c\sqrt{\frac{T_m}{T}}) + \max(0, T_m - T) = \frac{T}{c^2} - T$.
    \end{enumerate}
   Let $x,y,z$ denote the number of $T_m$ equal to $0, T, \frac{T}{c^2}$ respectively. That is, $x =|\{m \in [M]: T_m = 0\}|$, $y =|\{m\in [M]: T_m = 0\}|$, $z =|\{m\in [M]: T_m = T/c^2\}|$.
    Then, we have that $x + y + z = M$ and $yT + z\frac{T}{c^2} \geq MT$. Rewriting $R(\bm{T})$:
    \begin{align*}
        R(\bm{T}) &= (1-c)Ty + (\frac{1}{c^2} - 1)Tz\,.
    \end{align*}
    We minimize over the set of $(x, y, z)$, yielding the following optimization problem:
    \begin{align*}
        \min_{x, y, z} (1-c)Ty + (\frac{1}{c^2} - 1)Tz \quad \text{s.t} \quad x + y + z = M, \quad x, y, z \geq 0, \quad Ty + \frac{Tz}{c^2} \geq MT\,.
    \end{align*}
    As $x$ does not appear in the objective function, it is effectively a slack variable, and we can rewrite this optimization problem over $(x, y, z)$ as one over $(y, z)$ only:
    \begin{align*}
        \min_{y, z} (1-c)Ty + (\frac{1}{c^2} - 1)Tz \quad \text{s.t} \quad y + z \leq M, \quad y, z \geq 0, \quad Ty + \frac{Tz}{c^2} \geq MT\,,
    \end{align*}
    where in the above optimization, we ignore integrality of $y, z$. If we can show that $(y, z) = (M, 0)$  is the optimal solution to the above optimization problem, then we are finished.  The constraints are linear in $y$ and $z$ and form a triangle with vertices at $(y, z) \in \{(M,0), (0, c^2M), (0, M)\}$. We note that the objective function is linear, thus all it remains to do is to compare the objective function values at each of the vertices. The objective function values corresponding to $(y, z) \in \{(M,0), (0, c^2M), (0, M)\}$ are $(1-c)MT, (1-c^2)MT, (\frac{1}{c}-1)MT$ respectively. Thus, for any $c \in (0, 1)$, the optimal solution is $(M, 0)$ as desired, showing that $\bm{T} = (T,\ldots,T)$ was optimal in the original equality constrained, integer constrained optimization problem.
\end{proof}}


\section{Additional Experiments}
\label{sec: additional experiments}

In this section, we run several additional experiments, including a comparison of the decoupled exponential weights algorithms (Algorithms~\ref{alg: Decoupled Exponential Weights} and \ref{alg: Decoupled Exponential Weights - Path Kernels}) and the OMD algorithms (Algorithm~\ref{alg: OMD}) under both full information and bandit feedback in the stochastic setting. We additionally provide more comprehensive experiments regarding the market dynamics of the PAB and uniform price auctions. In particular, we plot the evolution of the revenue, welfare, and winning bid gaps over time, as well compare the bandit feedback versions of the PAB and uniform price auctions.

\subsection{Stochastic Setting} \label{sec:stochastic}

To compare the regret incurred between our decoupled exponential weights and OMD based algorithms in a non-multi agent setting, we consider the setting where the bidder competes in a stochastic setting. Here, the bidder, endowed with valuation vector $\bm{v} = [1, 1, 1]$, will compete over the course of $T=10^4$ rounds for full information feedback ($T = 10^5$ rounds for bandit feedback) for $\overline{M}=M=3$ items. The competing bids are  $\bm{b}^{-1} = [0.1, 0.1, 0.1]$, $[0.3,0.3, 1.0]$, or $[0.4, 1.0, 1.0]$ with probabilities $\frac{1}{4}, \frac{1}{4}$, and $\frac{1}{2}$, respectively. Assuming that the bidder receives priority in tiebreaks, with $\mathcal{B} = \{\frac{i}{10}\}_{i \in [10]}$, the expected utility $\sum_{m=1}^3 \prob(b_m \geq b^{-1}_m) (1 - b_m)$ maximizing bid vector is given by $\bm{b} = [0.4, 0.3, 0.1]$, which yields utility $(1)(1-0.4) + (0.75)(1 - 0.3) + (0.5)(1-0.1) = 0.6 + 0.525 + 0.45 = 1.575$. We select learning rates $\eta = \sqrt{\tfrac{\log(|\mathcal{B}|)}{MT}}$ and $\eta = \sqrt{\tfrac{\log(|\mathcal{B}|)}{M|\mathcal{B}|T}}$ for the full information and bandit decoupled exponential weights algorithms, respectively. We select learning rates $\eta = \sqrt{\tfrac{\log(|\mathcal{B}|)}{T}}$ and $\eta = \sqrt{\tfrac{\log(|\mathcal{B}|)}{|\mathcal{B}|T}}$ for the full information and bandit OMD algorithms, respectively. For the uniform price algorithms, we select $\eta = \sqrt{\tfrac{\log(|\mathcal{B}|)}{MT}}$ and $\eta = \sqrt{\tfrac{\log(|\mathcal{B}|)}{M^3|\mathcal{B}|^2T}}$ for full information and bandit feedback, respectively.

% Figure environment removed

In Figure \ref{fig:exp2_bids}, we plot the average value of each bid over time. Here, the bidder's objective is to learn the optimal bid vector under each of our algorithms: decoupled exponential weights algorithm (Algorithms~\ref{alg: Decoupled Exponential Weights} and \ref{alg: Decoupled Exponential Weights - Path Kernels}), and the OMD algorithm  (Algorithm \ref{alg: OMD}) for both the full information and bandit settings. In this figure, we further compare the rate of convergence to the optimal bid vector of $[0.4, 0.3, 0.1]$ with our three algorithms. 

We observe that the full information OMD converges the fastest to the optimal bid, followed by full information decoupled exponential weights. Similarly, the bandit OMD converges faster than the bandit exponential weights algorithm, albeit slower than either full information variant. This behavior is consistent with our theoretical findings. 

We repeat this experiment for the algorithms to learn in uniform price auctions described in \cite{brnzei2023online}. Though we do not perform the calculations, the optimal bid vector in the uniform price setting is still $[0.4, 0.3, 0.1]$. We note that it takes noticeably longer for the bandit algorithm to converge as compared to either its full information variant or our Algorithms \ref{alg: Decoupled Exponential Weights - Path Kernels} or \ref{alg: OMD}, as predicted by the looser regret upper bounds:
\begin{theorem}[(Discrete) Regret in Uniform Price Auctions, \cite{brnzei2023online}] \label{thm: uniform price regret full}
    Under full information feedback (resp. bandit feedback), there exists an algorithm which achieves $O(M^{\frac{3}{2}}\sqrt{T \log |\mathcal{B}|})$ (resp. $O(M^{\frac{5}{2}}|\mathcal{B}|T^{\frac{1}{2}}\sqrt{\log |\mathcal{B}|} + M^2 \log |\mathcal{B}|)$) discrete regret.
\end{theorem}

\subsection{Market Dynamics over Time}\label{sec:market_dynamics_additional}

{\color{black} In this section, we run five additional batches of experiments to better understand the market dynamics. We first analyze the evolution of welfare and revenue over time for a fixed $M, N, |\mathcal{B}|, T$. In the second experiment, we look at the evolution of the ratios between the largest winning, smallest winning, and largest losing bids over time. In the last three experiments, we repeat the previous two experiments for the uniform price auction, as well as the first experiment in Section~\ref{sec: experiments} that shows the regret dependence on $M$ and $T$.}



{\color{black}
\textbf{First Experiment: Welfare and Revenue Over Time - PAB.} In this next set of experiments, we compare welfare and revenue over time. We use $M = 5, |\mathcal{B}| = 20, N = 3, T = 10^5$ for these simulations, though we note that our findings are consistent across parameterizations. In Figure \ref{fig:rev_wel_over_time}, we further compare the distribution of welfare and revenue over time showing the 10th, 25th, 50th, 75th, and 90th percentiles in different shades under Algorithms~\ref{alg: Decoupled Exponential Weights} and \ref{alg: Decoupled Exponential Weights - Path Kernels}. We normalize both welfare and revenue by the optimal welfare (sum of the largest $M$ valuations) in each instance. In comparison to the full information version, it takes longer for the bidders to settle to an approximately welfare maximizing steady state in the bandit setting. Furthermore, the revenue at the recovered steady state under bandit feedback is lower than that of the full information setting, albeit with lower variance.

Additionally, we observe that revenues initially converge for intermediate values of $t$ before decreasing and subsequently increasing in variance for larger $t$. To explain this, it's essential to understand the evolution of the ratios between the largest and smallest winning bids, as well as the largest losing bid (See Figure~\ref{fig: bid ratios PAB}). Specifically, the decrease in revenue coincides with when the winning bids are far apart. The sudden drop in revenue indicates that bidders have learned to strategically shade their winning bids down to the clearing price. Eventually, the bids converge to either the clearing price, which naturally has some variance as it is a random function of the valuations and input parameters $N, M, |\mathcal{B}|$, or a best response cycle where bidders undercut and subsequently slightly outbid one another indefinitely (See Figure~\ref{fig: bid cycling main body}).


% Figure environment removed

{\color{black}
\textbf{Second Experiment: Convergence of Winning Bids Over Time - PAB.}  In Figure \ref{fig: bid ratios PAB}, we compare the evolution of the ratio of the largest and smallest winning bids (top), as well as the ratio of the smallest winning bid to the largest losing bid (bottom). We find that the ratios both converge to approximately 1 over time, though somewhat faster  under full information feedback. Despite the existence of CCEs supported over joint bid profiles with large gaps between winning bids (see Lemma~\ref{lem: CCE non uniform winning}), the convergence of these ratios suggests near uniformity of the winning bids over the course of the learning dynamics induced by our decoupled exponential weights algorithms.}


% Figure environment removed
{\color{black}\textbf{Third Experiment: Regret as a Function of $M$ and $T$ - Uniform Price.} To better understand the impact of $M$ and $T$ on the continuous regret, we run the repeated auction setting with varying $T, M$ for the uniform price auction. From \cite{brnzei2023online}, the continuous regret of their no-regret learning algorithm is of order $O(M^\frac{3}{2}T^{\frac{1}{2}} \log T)$ and $O(\min(MT, M^\frac{7}{4}T^{\frac{3}{4}} \log T))$ in the full information and bandit feedback settings respectively. To obtain these regret guarantees, we select $|\mathcal{B}|$ and $\eta$ to balance the discretization error of order $O(\frac{MT}{|\mathcal{B}|})$ and discrete regret: for the full information setting specifically, we set $|\mathcal{B}| = \max(5, \sqrt{\frac{T}{M}})$ and $\eta = \sqrt{\frac{\log T}{MT}}$. For bandit feedback, we set $|\mathcal{B}| = \max(5, M^{-\frac{3}{4}}T^\frac{1}{4})$ and $\eta = \min(\frac{1}{M}, \sqrt{\frac{\log |\mathcal{B}|}{M^3 |\mathcal{B}|^2T}})$. We plot the $\log-\log$ sum of discrete regrets across all $N=3$ bidders, normalized by $NT$ to obtain the per-bidder, per-round average regret; see Figure \ref{fig:regret-plot-unif}. Running a linear regression on the median, we find that the slopes w.r.t. $T$ of the median regret are approximately $-\frac{1}{2}$ and $-\frac{1}{6}$ for the full information and bandit settings respectively. This accurately reflects the theoretical regret bound in the full information setting and similarly, the slope for the bandit setting falls between the predicted $-\frac{1}{4}$ and 0. Interestingly, the slopes of the median w.r.t. $M$ are approximately $\frac{5}{4}$ and $\frac{7}{4}$ for the full information and bandit feedback settings respectively. While the bandit feedback setting is consistent with theory, the full information feedback regret dependence on $M$ is $O(M^{\frac{1}{4}})$ faster than predicted.}

% Figure environment removed


{\color{black}\textbf{Fourth and Fifth Experiments: Welfare, Revenue, Bid Ratios over Time - Uniform Price.} 
In Figure \ref{fig: uniform price market dynamics}, we present the evolution-over-time of the welfare, max-welfare normalized revenue, and ratios of the largest bids for the uniform price auction, under full information feedback. We use parameterization $N=3, M = 5, |\mathcal{B}| = 20, T = 10^5$ (our insights are consistent across parameterizations, see next section). Under uniform price, the payment is determined by the lowest winning bid, thus, less incentive to manipulate the largest bids. This observation aligns with findings from other variants of discriminatory versus uniform pricing, such as generalized first and second price auctions \cite{kagel1986curse, nyborg1996discvsunif, bergemann2020winnerscurse}. This explains the lower revenue and bid ratio non-convergence, whereas the slightly improved welfare stems from the tie-breaking rule (see Section~\ref{sec: experiments}).}

% Figure environment removed




\subsection{Comparison of PAB and Uniform Price Auctions under Bandit Feedback}\label{sec:compare_additional}

{\color{black} In this section, we compare the regret, welfare, revenue, bid ratios, and competitive ratios of the equilibria under the bandit feedback version of both the PAB and uniform price no-regret learning algorithms. In particular, we run the same parameterizations with $N \in \{3, 5\}, M \in \{1, 5, 10\}, |\mathcal{B}| \in \{10, 20\}, T = 10^5$ as in Tables~\ref{table: learning dynamics full info} and \ref{table: learning dynamics full uniform}, except now for bandit feedback. We use $\eta = \sqrt{\frac{\log |\mathcal{B}|}{M|\mathcal{B}|T}}$ for PAB and $\eta = \sqrt{\frac{\log |\mathcal{B}|}{M^3|\mathcal{B}|^2T}}$ for uniform price. Our results are shown in Tables~\ref{table: learning dynamics bandit info} and \ref{table: learning dynamics bandit uniform}. While most of our findings are consistent with the full information market dynamics, it is clear that the market dynamics have not yet converged for larger $M, |\mathcal{B}|$, especially for the uniform price auction, as indicated by the large regret, bid ratios, competitive ratios, and revenue gaps. Consequently, we analyze the PAB and uniform price equilibria exclusively under full information, as presented in Section~\ref{sec: experiments}.}




\begin{table}[ht]
    \centering
    \begin{minipage}[t]{0.48\linewidth} % Left table
        \caption{Summary of the Bidding Dynamics (Bandit, Algorithm~\ref{alg: Decoupled Exponential Weights - Path Kernels})}
        \label{table: learning dynamics bandit info}
        \footnotesize
        \begin{tabular}{lcccc}
        \toprule
         & \multicolumn{2}{c}{$|\mathcal{B}| = 10$} & \multicolumn{2}{c}{$|\mathcal{B}| = 20$} \\
        \cmidrule(lr){2-3} \cmidrule(lr){4-5}
        Metric & $N = 3$ & $N = 5$ & $N = 3$ & $N = 5$ \\
        \midrule
        \multicolumn{5}{c}{\textbf{For \( M = 1 \)}} \\
        Regret  & .8/2.5 & .5/2.5 & .3/1.9 & .8/2.7 \\
        Welfare Gap  & .40/11 & .50/4 & .86/14 & 1.6/13 \\
        Revenue Gap  & 28/78 & 18/47 & 38/69 & 24/41 \\
        CR Gap  & 1.6/56 & 2.2/25 & 1.6/53 & 8.2/52 \\
        Runtime (sec) & 321 & 511 & 415 & 879 \\
        \midrule
        \multicolumn{5}{c}{\textbf{For \( M = 5 \)}} \\
        Regret  & .4/.7 & .6/1.2 & .5/1.2 & .9/1.4 \\
        Welfare Gap  & 2.5/7.7 & 2.7/5.4 & 2.1/5.8 & 2.6/5.1 \\
        Revenue Gap  & 37/49 & 21/27 & 37/47 & 22/28 \\
        $b_{(1)}/b_{(M)}$ & 1.17/1.26 & 1.12/1.17 & 1.10/1.17 & 1.06/1.11 \\
        CR Gap  & 3.6/23 & 13/20 & 8.7/21 & 12/23 \\
        Runtime (sec) & 1844 & 2843 & 2660 & 5123 \\
        \midrule
        \multicolumn{5}{c}{\textbf{For \( M = 10 \)}} \\
        Regret  & 3.9/16 & 2.3/5.8 & 9.6/20.5 & 4.3/8.6 \\
        Welfare Gap  & 3.2/6.9 & 2.6/4.4 & 3.2/6.6 & 2.6/4.4 \\
        Revenue Gap  & 34/44 & 20/25 & 37/43 & 21/26 \\
        $b_{(1)}/b_{(M)}$ & 1.21/1.26 & 1.14/1.18 & 1.12/1.16 & 1.08/1.1 \\
        CR Gap  & 4.6/18 & 6/15 & 9/23 & 10/20 \\
        Runtime (sec) & 3912 & 5222 & 5098 & 9731 \\
        \bottomrule
        \end{tabular}
    \end{minipage}\hfill
    \begin{minipage}[t]{0.48\linewidth} % Right table
        \caption{Summary of the Bidding Dynamics (Uniform Price, Bandit \cite{brnzei2023online})}
        \label{table: learning dynamics bandit uniform}
        \footnotesize
        \begin{tabular}{lcccc}
        \toprule
         & \multicolumn{2}{c}{$|\mathcal{B}| = 10$} & \multicolumn{2}{c}{$|\mathcal{B}| = 20$} \\
        \cmidrule(lr){2-3} \cmidrule(lr){4-5}
        Metric & $N = 3$ & $N = 5$ & $N = 3$ & $N = 5$ \\
        \midrule
        \multicolumn{5}{c}{\textbf{For \( M = 1 \)}} \\
        Regret&	5.1/13.3&	3.7/6.3&	6.3/12&	5.4/7.4\\
        Welfare Gap&	1.5/26&	.8/15&	3.1/33&	17/32\\
        Revenue Gap&	45/70&	38/50&	49/67&	38/45\\
        CR Gap&	39/72&	42/64&	35/72&	66/77\\
        Runtime (sec) & 166 & 241 & 317 & 466\\
        \midrule
        \multicolumn{5}{c}{\textbf{For \( M = 5 \)}} \\
        Regret&	22/35&	9.1/11&	12/13&	11/12\\
        Welfare Gap&	2.3/7.8&	3.5/5.7&	4.4/6.1&	5.6/7.3\\
        Revenue Gap&	80/85&	47/58&	60/66&	43/48\\
        $b_{(1)}/b_{(M)}$ &	7.1/16&	2.2/4.5&	3/3.9&	1.7/2\\
        CR Gap&	19/24&	19/23&	14/16&	26/30\\
        Runtime (sec) & 1531 & 2612 & 5323 & 8777\\
        \midrule
        \multicolumn{5}{c}{\textbf{For \( M = 10 \)}} \\
        Regret&	98/147&	36/39&	53/60&	40/43\\
        Welfare Gap&	4.6/9.3&	3.9/6.9&	5.3/9.2&	5.4/6.5\\
        Revenue Gap&	98/98&	59/63&	89/90&	56/60\\
        $b_{(1)}/b_{(M)}$ &	43/46&	4.8/5.5&	21/24&	3.4/3.6\\
        CR Gap&	29/34&	26/30&	19/21&	30/32\\
        Runtime (sec) & 2643 & 5000 & 9783 & 14532\\
        \bottomrule
        \end{tabular}
    \end{minipage}
\end{table}




