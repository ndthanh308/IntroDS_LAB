\section{Experiments}
\label{sec: experiments}


{\color{black} We run two experiments; the first exclusively to empirically verify the regret guarantees of our algorithms for PAB, and the second to compare between the market dynamics of no regret learning in PAB and uniform price auctions. In first experiment, we simulate the market dynamics induced by our decoupled exponential weights algorithms under full information (Algorithm~\ref{alg: Decoupled Exponential Weights}) and bandit feedback (Algorithm~\ref{alg: Decoupled Exponential Weights - Path Kernels}). We omit our OMD algorithm (Algorithm~\ref{alg: OMD}) due to the prohibitively large computational cost of running convex optimization algorithms for each bidder at each time step.\footnote{We do, however, compare the three algorithms in the stochastic setting in Section~\ref{sec:stochastic}.} Moreover, as we observe in our simulations (Figure \ref{fig:regret-plot}), the decoupled exponential weights algorithms achieve the same linear regret in $M$ as our OMD algorithm, despite the weaker theoretical regret guarantee of order $O(M^{3/2})$.

Our second suite of experiments explores the impact of $M, \mathcal{B}, N$, and $T$ on welfare, revenue, regret, and other statistics in the PAB and uniform price settings with full information. We run 50 trials of each possible parameterization for each experiment, where in each trial, all marginal valuations are drawn from a Unif(0, 1) distribution (and then sorted).

{In Section~\ref{sec: additional experiments}, we run additional experiments showing the evolution of the aforementioned quantities over the course of the market dynamics for both PAB and uniform price, as well as comparing the PAB and uniform price equilibria under bandit feedback.} \footnote{In our implementation of all algorithms, we impose that $b_{n, m}^t \leq v_{n, m}$ for all $t$, which prevents the learning dynamics from converging to an overbidding equilibrium, such as in \cite{inefficiency2013}.} }


{\color{black}\textbf{First Experiment: Regret as a Function of $M$ and $T$.} To better understand the impact of $M$ and $T$ on the continuous regret, we run the repeated auction setting with varying $T, M$. Recall that the discrete regret of PAB is of order $O(M^\frac{3}{2}\sqrt{T \log |\mathcal{B}|})$ and $O(M^\frac{3}{2}\sqrt{|\mathcal{B}| T \log |\mathcal{B}|})$ in the full information and bandit feedback settings respectively. As such, we set $|\mathcal{B}|$ to balance the discretization error and discrete regret: $|\mathcal{B}| = \max(5, \sqrt{\frac{T}{M}})$ and $\eta = \sqrt{\frac{\log|\mathcal{B}|}{MT}}$ (for the full information, PAB setting) and $|\mathcal{B}| = \max(5, M^\frac{1}{3}T^{\frac{1}{3}})$ and $\eta = \sqrt{\frac{\log|\mathcal{B}|}{M|\mathcal{B}|T}}$ (for the bandit, PAB setting). Recall that the continuous regret is the sum of the discrete regret and the corresponding discretization error. Here, we plot the $\log-\log$ sum of {discrete} regrets across all $N=3$ bidders, normalized by $NT$ to obtain the per-bidder, per-round average regret; see Figure \ref{fig:regret-plot}. Running a linear regression on the median, we find that the slopes w.r.t. $T$ of the median regret are approximately $-\frac{1}{2}$ and $-\frac{1}{3}$ for the full information and bandit settings, respectively. This confirms the $\sqrt{T}$ and $T^{\frac{2}{3}}$ regret dependence for Theorem~\ref{thm:full} and \ref{thm:decoupled exp - bandit feedback}. Interestingly, the slopes w.r.t. $M$ of the median regret is approximately equal to $1$, suggesting that the $M^\frac{3}{2}$ dependence in Theorems~\ref{thm:full} and \ref{thm:decoupled exp - bandit feedback} is not tight by a factor of $\sqrt{M}$. \footnote{For the values of $|\mathcal{B}|$ chosen to balance the discretization error (which is of order $O(\frac{MT}{|\mathcal{B}|})$) and \textit{theoretical} discretized regret upper bound, the discretization error would scale with $O(M^\frac{3}{2})$ and would eventually dominate the discretized regret plotted in Figure~\ref{fig:regret-plot}. However, after observing the $O(M)$ regret scaling, we scale $|\mathcal{B}| = \Theta(\sqrt{T})$ under full information (resp. $|\mathcal{B}| = \Theta(T^{\frac{1}{3}})$ under bandit) to improve the continuous regret to $O(M\sqrt{T})$ (resp. $O(MT^{\frac{2}{3}})$).} }

% Figure environment removed


{\color{black}\textbf{Second Experiment: Impact of $M, |\mathcal{B}|, N$ on Equilibrium Behavior for PAB and Uniform Price.} We compare the impacts of $M$, $|\mathcal{B}|$, and $N$ on welfare, revenue, regret, competitive ratio (which we will define shortly), and run-times\footnote{We ran all experiments on a Centos 6, 2x8 cores Intel Xeon 2.0 GHz, with 64 GB RAM.} of the market dynamic simulations for both PAB and uniform price. For the repeated auction parameters, we set $N \in \{3, 5\}$ bidders, $\overline{M} = M \in \{1, 5, 10\}$ items, with all valuations drawn from $\text{Unif}(0, 1)$ and then sorted. The bid space is either $\mathcal{B} =\{\frac{i}{10}\}_{i \in [10]}$ or $\mathcal{B} = \{\frac{i}{20}\}_{i \in [20]}$. We run the market dynamics using the decoupled exponential weights algorithm under full information (Algorithm~\ref{alg: Decoupled Exponential Weights} and the full information algorithm as described in \cite{brânzei2023online} with $T=10^5$, $\eta = \sqrt{\frac{\log |\mathcal{B}|}{MT}}$).}


\begin{table}[ht]
    \centering
    \begin{minipage}[t]{0.48\linewidth} % Left table
        \caption{Summary of the Bidding Dynamics (PAB, Full Information, Algorithm~\ref{alg: Decoupled Exponential Weights})}
        \label{table: learning dynamics full info}
        \footnotesize
        \begin{tabular}{lcccc}
        \toprule
         & \multicolumn{2}{c}{$|\mathcal{B}| = 10$} & \multicolumn{2}{c}{$|\mathcal{B}| = 20$} \\
        \cmidrule(lr){2-3} \cmidrule(lr){4-5}
        Metric & $N = 3$ & $N = 5$ & $N = 3$ & $N = 5$ \\
        \midrule
        \multicolumn{5}{c}{\textbf{For \( M = 1 \)}} \\
        Regret  & .02/.03 & .02/.02 & .03/.04 & .02/.03 \\
        Welfare Gap & .13/4.9 & .34/3.2 & .29/1.3 & .5/2.3 \\
        Revenue Gap & 32/61 & 12/49 & 30/63 & 18/33 \\
        CR Gap & .31/2.4 & 1.2/3.5 & .36/2 & .86/3.9 \\
        Runtime (sec) & 206 & 253 & 299 & 571 \\
        \midrule
        \multicolumn{5}{c}{\textbf{For \( M = 5 \)}} \\
        Regret  & .17/.19 & .12/.13 & .21/.23 & .14/.16 \\
        Welfare Gap  & 1.1/3.2 & 1.1/3.1 & .92/2.3 & 1/2.2 \\
        Revenue Gap  & 35/47 & 19/26 & 32/46 & 18/27 \\
        $b_{(1)}/b_{(M)}$ & 1.19/1.34 & 1.12/1.17 & 1.07/1.18 & 1.06/1.08 \\
        CR Gap  & .35/.69 & .75/1.2 & .46/.76 & .93/1.4 \\
        Runtime (sec) & 1370 & 1833 & 2419 & 4122 \\
        \midrule
        \multicolumn{5}{c}{\textbf{For \( M = 10 \)}} \\
        Regret  & 0.37/0.40 & 0.24/0.26 & 0.45/0.49 & 0.29/0.32 \\
        Welfare Gap  & 1.8/3.7 & 1.3/2.7 & 1.3/2.3 & 1.1/1.8 \\
        Revenue Gap  & 31/40 & 18/22 & 30/39 & 17/22 \\
        $b_{(1)}/b_{(M)}$ & 1.16/1.23 & 1.14/1.16 & 1.09/1.16 & 1.06/1.08 \\
        CR Gap  & 0.46/0.64 & 0.84/1.14 & 0.59/0.73 & 1.00/1.49 \\
        Runtime (sec) & 2512 & 3811 & 4679 & 8330 \\
        \bottomrule
        \end{tabular}
    \end{minipage}\hfill
    \begin{minipage}[t]{0.48\linewidth} % Right table
        \caption{Summary of the Bidding Dynamics (Uniform Price, Full Information \cite{brânzei2023online})}
        \label{table: learning dynamics full uniform}
        \footnotesize
        \begin{tabular}{lcccc}
        \toprule
         & \multicolumn{2}{c}{$|\mathcal{B}| = 10$} & \multicolumn{2}{c}{$|\mathcal{B}| = 20$} \\
        \cmidrule(lr){2-3} \cmidrule(lr){4-5}
        Metric & $N = 3$ & $N = 5$ & $N = 3$ & $N = 5$ \\
        \midrule
        \multicolumn{5}{c}{\textbf{For \( M = 1 \)}} \\
        Regret & .03/.04 &	.02/.03&	.03/.04&	.02/.03\\
        Welfare Gap  & .3/4 & .2/2.9 & .3/1.6 & .3/1.1 \\
        Revenue Gap  & 30/58 & 20/50 & 50/74 & 20/40 \\
        CR Gap & .4/1.2&	.8/1.4	&.6/2.7&	1/2.3\\
        Runtime (sec) & 181&	231	&316&	538 \\
        \midrule
        \multicolumn{5}{c}{\textbf{For \( M = 5 \)}} \\
        Regret & .19/.23	&.14/.18	&.21/.25	&.15/.17\\
        Welfare Gap  & .3/2.4 & .6/1.8 & .5/2.2 & .4/1.4 \\
        Revenue Gap  & 44/56 & 17/32 & 38/52 & 19/30 \\
        $b_{(1)}/b_{(M)}$ & 1.76/2.23 & 1.23/1.49 & 1.59/1.95 & 1.24/1.47 \\
        CR Gap & .3/.6&	.8/1.7&	.4/.6	&.8/1.3\\
        Runtime (sec) & 1932&	2850&	6976&	10883 \\
        \midrule
        \multicolumn{5}{c}{\textbf{For \( M = 10 \)}} \\
        Regret & .49/.66	&.41/1.3&	.5/.6	&.4/.5\\
        Welfare Gap  & .3/1.5 & .5/1.1 & 1/2.6 & .3/.6 \\
        Revenue Gap  & 37/57 & 19/26 & 40/50 & 19/23 \\
        $b_{(1)}/b_{(M)}$ & 1.86/2.39 & 1.33/1.42 & 1.81/2.17 & 1.28/1.36 \\
        CR Gap & .4/.9	&1.2/4.6&	.5/.7&	1.2/2.0\\
        Runtime (sec) & 3509&	6132&	13118&	20913\\
        \bottomrule
        \end{tabular}
    \end{minipage}
\end{table}





{\color{black}We report our results in Tables~\ref{table: learning dynamics full info} and ~\ref{table: learning dynamics full uniform}. In these tables, the regret is defined as the sum of {discrete} regrets across all bidders, normalized by $NT$, the number of bidders times the number of rounds. The welfare gap and revenue gap rows indicate the difference between the maximum welfare and the time-averaged welfare and revenue, respectively, normalized by the maximum welfare defined as the sum of the $M$ largest valuations. The ratio $b_{(1)}/b_{(M)}$ in the tables represents the ratio of the largest to the smallest winning bid, which is undefined for $M = 1$. This ratio is computed by taking the mean of the per-round bid ratios over the final 10\% of the time steps, as we are only concerned with long run bid convergence. The CR Gap in the tables represents the time-averaged competitive ratio subtracted from 1; that is, it is 1 minus the sum over the difference of each bidder's realized and hindsight optimal utilities, normalized by the sum over all bidders' hindsight optimal utility. Each entry of Tables \ref{table: learning dynamics full info} and \ref{table: learning dynamics full uniform} (except those regarding the runtime) denotes the median value across 50 trials with $T = 10^5$. The first number in each entry corresponds to the median, whereas the second corresponds to the 90th percentile for the first four rows. The runtime row denotes the median duration each trial was run for in seconds. Our main observations are as follows:}
{\color{black}
\begin{enumerate}
    
    \item \textbf{Regret Grows with $M, |\mathcal{B}|$.} Consistent with the regret guarantees from the aforementioned theorems, as well as Figure~\ref{fig:regret-plot}, the regret increases as a function of $M$ and $|\mathcal{B}|$. Intuitively, there are $O(M|\mathcal{B}|)$ weights that need to be learned in our algorithm, thus, requiring more exploration for larger $M$ and $|\mathcal{B}|$ leading to larger regret. Interestingly, the regret for uniform price only increases in $M$, despite requiring $O(M|\mathcal{B}|^2)$ weights to learn.

    \item \textbf{Welfare Worsens in $M$, Improves in $|\mathcal{B}|$ for PAB; not for Uniform Price. } For PAB, the welfare gap increases for larger $M$, but for lower $|\mathcal{B}|$, though this trend is not present under uniform price. This phenomenon occurs due to the deterministic tie-breaking rule. As $M$ increases and $|\mathcal{B}|$ decreases, there is an increased likelihood in PAB that low tie-break priority bidders with winning valuations will lose items to high tie-break priority bidders with marginally lower valuations. When $|\mathcal{B}|$ is small, the increase in price will disincentivize these bidders from trying to win these items by increasing their bid. In contrast, under uniform price, only the lowest winning bid affects payments, so these low tie-break priority bidders can still win their higher value items. As such, we find that the uniform price marginally outperforms PAB in welfare.

    \item \textbf{Revenue Improves in $|\mathcal{B}|$ and $N$. } As $|\mathcal{B}|$ increases, the auctioneer can extract larger payments for bidders, as seen in the decrease in revenue gap for larger $|\mathcal{B}|$, though it is more pronounced under PAB and less so for uniform price. The revenue gaps, in both PAB and uniform price, benefit from this increase $N$, as the increased competition decreases the impact of strategic bid shading. We find that PAB consistently outperforms uniform price in terms of revenue, and more importantly, to a larger degree than which uniform price outperforms PAB in welfare.
    
    \item \textbf{The Largest to Smallest Winning Bid Ratio Approximately Converges in PAB; not Uniform Price.} We see that the ratio $b_{(1)}/b_{(M)}$ is around 1.1 or 1.2 for PAB, but around 1.4 to 2 for uniform price, with this ratio decreasing in $N$ and $|\mathcal{B}|$. As $N$ increases, the increased competition turns bidders into price takers, yielding a tightened spread on the winning bid values. As for $|\mathcal{B}|$, in the case of PAB, we notice that the bid ratio is close to 1, suggesting that the difference between the largest and smallest bid ratio is approximately one discretization factor $\delta = \frac{1}{|\mathcal{B}|}$. With the revenue gap being approximately $\frac{1}{3}$ and $\frac{1}{5}$ for $N = 3, 5$ respectively, the clearing price would have been around $\frac{2}{3}$ and $\frac{4}{5}$. Taking the ratio of the two closest values in $\mathcal{B}$ to these yields 1.17 and 1.14 for $|\mathcal{B}| = 10$, or 1.08 and 1.07 for $|\mathcal{B}| = 20$, which is consistent with our empirical findings. The effect of $|\mathcal{B}|$ is less pronounced, but still present for the uniform price auction.

    \item \textbf{Competitive Ratio grows in $N$ despite Regret Shrinking in $N$.} We observe that the regret is generally smaller for larger $N$. One justification for this phenomenon is that individual bidders have a smaller impact on the market clearing price, and thus, have less of an incentive to strategically shade their bids leading to faster convergence towards equilibrium behavior. Taking a broader view, this trend suggests a sub-linear dependence of social regret on $N$, offering a possible improvement over recent literature characterizing improved convergence rates for multi-agent games with more players \cite{syrgkanis2015fast, foster2016robustnessconvergence}. Perhaps more interestingly, the competitive ratio \textit{grows} in $N$, despite its similarity to regret, with the exception that it is normalized by the hindsight optimal utility. This suggests that this hindsight optimal utility---i.e., the optimal consumer surplus---decreases as $N$ increases, showing that the bidders become more of price takers as $N$ increases.

    \item \textbf{Run-time Increases in $M, N, |\mathcal{B}|$.} The run-time of our algorithms is approximately linear in each of $M$ and $|\mathcal{B}|$, as predicted in Section~\ref{sec: path kernels regret}. The algorithm for uniform price is approximately linear in $M$ and quadratic in $|\mathcal{B}|$, consistent with \cite{brânzei2023online}. As there are $N$ agents running the learning algorithm in each trial, the run-time scales linearly in $N$.
\end{enumerate}
}