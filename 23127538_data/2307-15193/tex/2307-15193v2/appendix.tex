\newpage 

\section{Appendix}
{\color{black}\subsection{Proof of Lemma \ref{lem: PNE uniform bidding}}\label{sec:proof:lem: PNE uniform bidding}
We prove this by contradiction. Suppose buyer \(n\) places any bid strictly greater than \(b_{(M)} + \delta\). Assume the bids of all other bidders are fixed. Any bid \(b\) by bidder \(n\) that equals or exceeds \(b_{(M)} + \delta\) will still secure the allocation, as \(b \geq b_{(M)} + \delta > b_{(M)}\), irrespective of the tie-breaking rule. Therefore, bidder \(n\) can reduce all such bids to exactly \(b_{(M)} + \delta\) without losing any items, thereby lowering their total payment. Consequently, the highest possible bid cannot exceed \(b_{(M)} + \delta\).

\subsection{Proof of Lemma \ref{lem: near-uniform optimal bidding}}\label{sec:proof:lem: near-uniform optimal bidding}
    Consider any bid vector $\bm{b} \in \mathcal{B}^{+M}$. Assuming that bidder $n$'s  is allocated  $m$ under $\bm{b}$, then $b_m \geq \tilde{b}_{n,m}$, as $\tilde{b}_{n,m}$ is the smallest bid required for bidder $n$ to win the $m$'th item. Define $\bm{b}': b'_j = \min(\tilde{b}_{n,m}, b_j)$ which is $\bm{b}$ except setting the first $m$ bids to $\tilde{b}_m$.
    By monotonicity of $\bm{b}_{-n}$ and $\bm{b}$---i.e., $b_{-1} \leq \ldots \leq b_{-m} \leq \tilde{b}_{n,m} \leq b_m \leq \ldots \leq b_1$---the allocation is the same under $\bm{b}$ and under $\bm{b}': b'_j = \min(\tilde{b}_{n,m}, b_j)$. As the allocations are equal and the payment is smaller under $\bm{b}'$, which belongs to the set $\{\bm{b} \in \mathcal{B}^{+M}: b_j = (\tilde{b}_{n,m}) \forall j \in [m], b_{j} \leq v_j \forall j > m\}$, then $\bm{b}'$ must yield at least as much utility as $\bm{b}$. Thus, any optimal bid vector that is allocated $m$ units, conditioning on $\bm{b}_{-n}$ must have uniform $m$ highest bids at value $\tilde{b}_{n,m}$. Because we prohibiting overbidding, we only consider bid vectors that win $m$ items if $m$ is such that $\tilde{b}_{n, m} < v_m$.
\subsection{Proof of Theorem \ref{thm: PNE existence}: Existence of an Approximately Efficient PNE}
\label{sec: equilibrium proof}


{\color{black}
\begin{proof}{Proof of Lemma~\ref{thm: PNE existence}}

To prove Theorem~\ref{thm: PNE existence}, we proceed in two steps. First, we demonstrate that if all other bidders adhere to the three properties outlined in Theorem~\ref{thm: PNE existence}, then bidder $n$'s optimal bids must also satisfy these properties. Afterwards, using a monotonicity argument, we show that under our particular deterministic tie-breaking rule, there exists a specific configuration of bids—either $c$ or $c + \delta$—among each bidder’s winning bids that constitutes a PNE.

\textbf{First Part of the Proof.} {We first show the three properties. The first property implies that if for every bidder $i\ne n$, we have  bids of either all $c$ or all $c + \delta$ for units such that $v_{i,m} \geq c + \delta$, then bidder $n$ also submits bids of  either all $c$ or all $c + \delta$ for units such that $v_{n,m} \geq c + \delta$. This 
follows immediately from Lemma~\ref{lem: PNE uniform bidding} and recalling the definition of $c$.

 To demonstrate the second property, we argue that there is no incentive for bidder $n$ to decrease their winning bids below $c$, specifically for any unit $m$ with $v_{n, m} \in [c, c+\delta)$. Given that there are at least $M$ other valuations equal to or greater than $c = c_{-n}$, and considering the PNE characterization which states that for any bidder $i \neq n$, all units with a valuation at or above the clearing price (i.e., $v_{i, m} \geq c$, $i \in [N], i\ne n$) must be accompanied by a bid of either $c$ or $c + \delta$, it follows that there are at least $M$ bids of at least $c = c_{-n}$ submitted by other bidders. Therefore, reducing any of bidder's $n$ winning bids below $c$ would not result in winning a unit, making it sub-optimal.


Lastly, to show the final property, we show that there exists no incentive for bidder $n$ to increase their bid for the remaining items (i.e., any item $m$ with $v_{n, m}< c$) to at least $c$, we recall the definition of $c= c_{-n}$ being the $M$'th largest valuation among all bidders except bidder $n$. Thus, bidding above $c$ for these units violates the no-overbidding assumption.}

\textbf{Second Part of the Proof.} Now that we have shown the three properties, we fully characterize the PNE w.r.t. each bidders' largest bids. In particular, consider the perspective of bidder $n$, who has tie-break priority over bidders $1,\ldots,n-1$ but behind $n+1,\ldots,N$. Thus, any bids of $c+\delta$ submitted by the first $n-1$ bidders, and any bids of $c$ or $c + \delta$ submitted by bidders $n+1,\ldots,N$, take priority over any bids of $c$ submitted by bidder $n$. Let $M_n$ denote the number of bids of $c+\delta$ submitted by bidder $n$, which by our PNE characterization, is between $0$ and $\sum_{m=1}^M 1_{v_{n, m} \geq c + \delta}$. Fixing $M_{1:n-1}$ and $M_{n+1:N}$, we claim that the optimal $M_n$ is precisely either 0 or $\sum_{m=1}^M 1_{v_{n, m} \geq c + \delta}$---they either submit bids of all $c$ or all $c+\delta$ for all items they value at least $c + \delta$. 

To show this, notice that bidder $n$ can win all of the items they value at least $c + \delta$ by bidding at $c + \delta$, as there are fewer than $M$ values at least $c+\delta$ across all bidders. In addition to this, they can win some number of items by bidding at $c$ for all items with value at least $c$ via tie-break. To be more specific, 
there are $M$ items with $\sum_{n' \leq n} M_{n'}$ bids of $c + \delta$ and $\sum_{n' > n} \sum_{m=1}^M 1_{v_{n',m} \geq c}$ bids of at least $c$ (by the PNE characterization) that take priority over any bids of $c$ submitted by bidder $n$, where we note that the number of bids of $c$ submitted by bidder $n$ is at most $\sum_{m=1}^M 1_{v_{n,m} \geq c}$. Thus, bidder $n$'s allocation and utility as a function of $M_n$ for any fixed $\bm{M}_{-n} = (M_{-1},\ldots,M_{-(n-1)},M_{-(n+1)},\ldots,M_{-N})$ is given by:

\begin{align*}
    x_n(M_n | \bm{M}_{-n}) &= \min\left(\sum_{m=1}^M 1_{v_{n,m} \geq c}~,~ M_n + \max\big(0, \theta(\bm{M}_{-n}) - M_n\big)\right)\\
    \hspace{1mm} \mu_n(M_n | \bm{M}_{-n}) &= - M_n\delta +\sum_{m=1}^{x_n(M_n | \bm{M}_{-n})} (v_{n,m} - c)\,,
\end{align*}
where $\theta(\bm{M}_{-n}) = M - \sum_{n' < n} M_{n'} - \sum_{n' > n} \sum_{m=1}^M 1_{v_{n',m} \geq c}$. Here, $\min\left(\sum_{m=1}^M 1_{v_{n,m} \geq c}, \theta(\bm{M}_{-n})\right)$ denotes the number of units bidder $n$ would have won in tie-break by submitting $M_n = 0$ bids of $c + \delta$.
%In the case where $\theta(\bm{M}_{-n}) \geq \sum_{m=1}^M 1_{v_{n,m} \geq c}$, the allocation function is a constant $\sum_{m=1}^M 1_{v_{n,m} \geq c}$. 
Now, let's consider the general case where $M_n\ge 0$. For  all $M_n \geq \theta(\bm{M}_{-n})$, the $\max(0, \theta(\bm{M}_{-n}) - M_n)$ term in the allocation function is 0, and thus, the allocation function  increases linearly in $M_n$ until $M_n = \sum_{m=1}^M 1_{v_{n,m} \geq c+\delta}$. In contrast, for $M_n <\theta(\bm{M}_{-n})$, the second term (i.e., $\max(0, \theta(\bm{M}_{-n}) - M_n)$) is non-zero, and the $M_n$ within the summation of the second term cancels out with the first term of $M_n$. Thus, the allocation function $x_n(M_n | \bm{M}_{-n}) = \theta(\bm{M}_{-n})$ is constant for all $M_n \leq \theta(\bm{M}_{-n})$, at which point it becomes precisely $x_n(M_n | \bm{M}_{-n}) = \theta(\bm{M}_{-n}) = M_n$ until $M_n = \sum_{m=1}^M 1_{v_{n, m} \geq c + \delta}$. This reflects the fact that each additional bid at $c + \delta$ submitted by bidder $n$ consumes an item that could have been won in tie-break at price $c$, which we illustrate in Figure~\ref{fig: allocation visualization PNE}. From Figure~\ref{fig: allocation utility vs mn}, we see that the optimal $M_{-n}$ is always achieved at $M_{-n} \in \{0, \sum_{m=1}^M 1_{v_{n,m} \geq c + \delta}\}$.

% Figure environment removed



% Figure environment removed

    
    Now that we have shown that the optimal number of bids to submit at $c + \delta$ of each bidder is either $M_n = 0$ or $M_n = \sum_{m=1}^M 1_{v_{n, m} \geq c + \delta}$, we finish the argument by claiming that the utility corresponding to $M_n = 0$ is weakly decreasing in $\bm{M}_{-n}$. This is because $x_n(\cdot | \bm{M}_{-n})$, and similarly $\mu_n(\cdot | \bm{M}_{-n})$, are weakly decreasing in these quantities. Because of this monotonicity, agents can run best response dynamics beginning with $(M_1,\ldots,M_N) = (0, \ldots, 0)$ and converge to a PNE w.r.t. $M_1,\ldots,M_N$. That is, each agent that switches from $M_n = 0$ to $M_n = \sum_{m=1}^M 1_{v_{n, m} \geq c + \delta}$ can only incentivize other bidders to also switch away from 0 and never towards 0.
    
\end{proof}

}


%\negin{Let's finish up the proof first and then add any potential discussion about this PNE}
{\color{black}
\subsection{Assumptions in Theorem \ref{thm: PNE existence}} \label{sec:discuss:assumption}
The validity of the PNE characterization in Theorem \ref{thm: PNE existence} depends on the premise that there is sufficient competition, ensuring that the clearing price $c$ remains constant even upon removing any single bidder. However, this assumption may not always hold true. To illustrate this, we initially provide an example where the assumption is met. However, a minor modification to the example leads to the failure of this assumption. In Figure~\ref{fig: bid cycling main body}, we illustrate how this impacts the convergence of our learning algorithms' final iterations.

In this figure, we plot the bid values over the course of the market dynamics induced by our full information decoupled exponential weights algorithm (Algorithm~\ref{alg: Decoupled Exponential Weights}) with $N=3$, $M=4$, $|\mathcal{B}|=10$, and $T=10^5$. In the left figure, we let $\bm{v}_1 = \bm{v}_2 = \bm{v}_3 = [1-\epsilon, 1-\epsilon]$, and thus there exists a PNE via satisfying the $c = c_{-n} = \lfloor 1-\epsilon \rfloor_{\delta=0.1} = 0.9$ condition from Theorem~\ref{thm: PNE existence}. Moreover, this PNE is characterized by all bidders submitting bids of $0.9$ for the first two units, which is precisely what the market dynamics converge to.\footnote{{We do not present theoretical guarantees on last iterate convergence for PAB. For a discussion in the $M=1$ unit setting, please refer to \cite{Deng_2022}.}} In the right figure, we assume that  bidder one only demands one unit at $1-\epsilon$, instead of two; that is $\bm v_1= [1-\epsilon, 0]$. The value of other bidders remain the same. Here, we do not satisfy the $c = c_{-n}$ condition as $ c_{-1} = 1-\epsilon \neq 0 = c_{-2} = c_{-3}$. In fact, one can verify that there exists no PNE in this auction and we observe cyclic bidding behavior from the 2nd and 3rd bidders.

To explain why the learning dynamics do not converge in cases where PNE is absent, we outline several observations:

\begin{enumerate}
    \item %Consider the auction with $M=4$ units, $N=3$ bidders, $\mathcal{B} = \{\frac{i}{10}\}_{i \in [10]}$.
    In the auction in Figure~\ref{fig: bid cycling main body} with no PNE, $\bm{v}_1 = [1-\epsilon, 0]$, so bidder 1 can submit at most one non-zero bid. Similarly, $\bm{v}_2 = \bm{v}_3 = [1-\epsilon, 1-\epsilon]$, so bidders 2 and 3 can submit at most two non-zero bids. Bidder 2 and bidder 3 can guarantee an allocation of at least 1 since among all other bidders, the demand is at most 3. However, they can guarantee an allocation of 2 if they can slightly outbid the 2nd largest bid among the other two bidders.
    \item In Figure~\ref{fig: bid cycling main body}, we observe that bidder 1's bid converges to 0.5. In contrast, bidder 2's bids cycle between 0.1 and 0.5, and bidder 3's bids cycle between 0 and 0.4. What happens is that bidder 3 will try to win one unit cheaply by bidding for both units at price $0$. Bidder 2 realizes that they can slightly outbid them at a price of 0.1, yielding utility $1.8 - 2\epsilon$. Then bidder 3 matches their bid, and because they are given tie-break priority, they win two units, yielding utility $1.8 - 2\epsilon$. Bidder 2, now only winning one unit, realizes that they can win 2 units by increasing their bid to 0.2, which bidder 3 then matches, and so on.
    \item Once bidder 2 submits two bids of 0.5, which yields a utility of $1 - 2\epsilon$, bidder 3 can either submit two bids of 0.5, which yields an allocation of 2 and a utility of $1 - 2\epsilon$, or they can submit a bid of 0, which only yields an allocation of 1 but a utility of $1 - \epsilon$. Thus, they submit bids of 0 as the best response to bidder 1 submitting a bid of 0 and bidder 2 submitting two bids of 0.5, after which the cycle repeats.
\end{enumerate}

% Figure environment removed

Despite this fragility of the $c = c_{-n}$ assumption in Theorem~\ref{thm: PNE existence}, this is merely a sufficient condition and not necessary for the existence of the PNE. At its core, this $c = c_{-n}$ assumption reflects the requirement that strategic bid shading cannot offset a decrease in allocation with a decrease in payment. For example, if we instead set $v_{1,2} = 0.8+\epsilon$ in Figure~\ref{fig: bid cycling main body}, a PNE still exists at $\bm{b}_1 = [0.9, 0.8]$ and $\bm{b}_2 = \bm{b}_3 = [0.8, 0.8]$ despite $ c_{-1} = 1 -\epsilon \neq 0.8 + \epsilon = c_{-2} = c_{-3}$. For practical understanding, PNE existence is satisfied when bidders are price-takers with minimal influence over the market price---a condition typically met in markets where the demand each bidder $n$ places on units $M$ is substantially smaller than the overall supply $\overline{M}$, and the total supply is less than the aggregate demand, i.e., $\sum_{n \in [N]} \overline{M}_n \gg M$.
}
}


{\color{black}\subsection{Proof of Lemma \ref{lem: CCE non uniform winning}}
    Consider the following $M=2$ item, $N=2$ bidder auction where bidder 1 and 2's valuations are $[1 + \epsilon, 1 + \epsilon], [1, 0]$ respectively, for some small $\epsilon > 0$. Let $\mathcal{B} = \{0, \frac{1}{|\mathcal{B}|}, \frac{2}{|\mathcal{B}|},\ldots, 1\}$ be an even discretization of $[0,1]$ with the discretization factor of $\delta =  \frac{1}{|\mathcal{B}|}$,  
    and assume that ties are broken in favor of bidder 2. 
    % Running the full information market dynamics (Algorithm~\ref{alg: Decoupled Exponential Weights}) with $T = 10^4$ and $\eta = \sqrt{\frac{\log |\mathcal{B}|}{T}} \approx 0.01$, we observe that the winning bids were not uniform 58\% of the time. This suggests that the dynamics do not necessarily always converge to a CCE under which the winning bids are uniform. In addition to simply running the bid dynamics to recover one particular CCE, 
    In this setting, we can show the existence of CCEs where the winning bids are \textit{never} uniform, even up to a discretization factor.
    
    To that end, we solve a linear program using the linear constraints formulation of CCEs and maximize the probability of drawing a joint action profile with non-uniform winning bids. We first define $b_{(m)} = b_{(m)}(\bm{b}_1,\ldots,\bm{b}_N)$ as the $m$'th largest bid among bid vectors $\bm{b}_1,\ldots,\bm{b}_N$. Now, we maximize the probability that the gap between $b_{(1)}$ and $b_{(M)}$ is more than one discretization factor $\delta = \frac{1}{|\mathcal{B}|}$ apart by maximizing the objective function $\max \sum_{\bm{b}_1,\ldots,\bm{b}_n} \bm{p}(\bm{b}_1,\ldots,\bm{b}_n) \mathbf{1}_{b_{(1)} > b_{(M)} + \delta}$. Under CCE constraints, the objective function is equal to 1 for all $|\mathcal{B}| \in [5, 10]$, meaning that there exist CCEs entirely supported on joint bidding profiles which have winning bids more than $\delta$ apart. Under CE constraints, the objective function is increasing in $|\mathcal{B}|$ but stabilizes around $0.6$ at $|\mathcal{B}| = 8$. In other words,  when $|\mathcal{B}|$ grows large, there exists a CCE (resp. CE) under which there is a 1.0 (resp 0.6) probability over joint strategy profiles that violate the winning bid uniformity. $\blacksquare$% {\color{red} this is confusing because earlier you said $\mathcal B =\{0, 1/3, 2/3, 1\}$. Also, please explain what it means to get $0.6$ as the objective value.}
    }

\subsection{Proof of Theorem \ref{thm:offline}: Offline Bid Optimization Algorithm}
\label{sec: offline proof}

We give a proof of correctness of the offline bid optimization algorithm used to compute the hindsight optimal bid vector across $T$ rounds of PAB auctions. Our proof shows that the variables $U_m(b)$ are path weights of the optimal partial bid vector with weights $W_m^{T+1}(b)$. Thus, $U_1(b)$ is the optimal bid vector and $b^*_m$'s can be used to back out the optimal bid vector recursively in polynomial time.

\begin{proof}{Proof of Theorem \ref{thm:offline}}
   By definition, 
    \begin{align*}
        U_\nitem(b) &= \max_{ b\ge b_\nitem\geq\ldots\geq b_\Nitem} \sum_{\nitem' = \nitem}^\Nitem W^{\Nround+1}_{\nitem'}(b_{\nitem'})\\
        &= \max_{ b\ge b_\nitem\geq\ldots\geq b_\Nitem}  W^{\Nround+1}_{\nitem}(b_\nitem ) +  \sum_{\nitem' = \nitem+1}^\Nitem W^{\Nround+1}_{\nitem'}(b_{\nitem'})\\
        &= \max_{ b' \leq b} W^{\Nround+1}_\nitem(b') + U_{\nitem+1}(b')\,.
    \end{align*}
    Since we have that $U_{\Nitem}(b ) = W^{\Nround+1}_{\Nitem} (b )$ trivially correct from the base case, and the optimality of $U_\nitem(b)$ follows from induction. Consequently, optimality of $b_\nitem^*$ follows from induction. The base case trivially holds as $b_1^* = \text{argmax}_{b \in \mathcal{B}} U_1(b)$. The recursive case also follows straightforwardly by definition of $b^*_\nitem$:
    \begin{align*}
        b^*_\nitem = \text{argmax}_{b \leq b^*_{\nitem-1}} U_\nitem(b)\,.
    \end{align*}
    As $b^*_{\nitem-1}$ was optimal by the induction hypothesis, then $b_\nitem^*$ must also be optimal.
    



    
    We finish this proof by discussing the time and space complexity of Algorithm \ref{alg: Offline Full}.  {Table $U$ is of size $O(\Nitem |\mathcal{B}|)$, with each entry requiring taking a maximum over $O(|\mathcal{B}|)$ terms, yielding time and space complexities of $O(\Nitem |\mathcal{B}|^2)$ and $O(\Nitem|\mathcal{B}|)$ respectively.}

 
\end{proof}


\subsection{Proof of Theorems \ref{thm:full} and \ref{thm:decoupled exp - bandit feedback}: Decoupled Exponential Weights Algorithm}
\label{sec: path kernels regret}

\begin{proof}{}
    We give the proofs of correctness, complexity analysis, and regret analysis for the decoupled exponential weights algorithms for both the full information (Algorithm~\ref{alg: Decoupled Exponential Weights}) and the bandit setting (Algorithm~\ref{alg: Decoupled Exponential Weights - Path Kernels}). Our proof comes in 5 parts. We first prove correctness of the bandit version of our algorithm. In particular, we show that defining the node and bid vector utility estimates to be $\widehat{w}_m^\nround(b) = 1 - \frac{1-(v_m-b)1_{b \geq b_{-m}^\nround}}{q_m^t(b)}1_{b = b^\nround_m}$ and $\widehat{\mu}^\nround(\bm{b}) = \sum_{\nitem=1}^\Nitem \widehat{w}_\nitem^\nround(b_m)$, our algorithm samples bid vector $\bm{b}^\nround$ with probability proportional to $\exp(\eta \sum_{\tau=1}^{t-1} \widehat{\mu}^\tau(\bm{b}))$ via the same recursive sampling procedure as in Algorithm~\ref{alg: Decoupled Exponential Weights}. In the second part and third parts, we derive a corresponding regret upper bound and obtain the time and space complexities of our algorithm with bandit feedback. In the fourth part, we optimize the continuous regret w.r.t. the selection of $\mathcal{B}$. In the fifth part, we show how to extend our algorithm and results to the full information setting.

    \textbf{Part 1: Algorithm Correctness.} In this part of the proof, we argue that our choice of estimator is unbiased and that Algorithm~\ref{alg: Decoupled Exponential Weights - Path Kernels} samples bid vectors with the same probability that the exponential weights algorithm would have, given the same node utility estimates $\widehat{w}_m^t(b)$. To show unbiasedness of $\widehat{w}_m^t(b)$, we have:
    \begin{align*}
        \mathbb{E}\left[\widehat{w}_m^{t}(b)\right] = \mathbb{E}\left[1 - \frac{1-w^t_m(b)}{q^t_m(b)} \textbf{1}_{b^t_m = b}\right] = \mathbb{E}\left[1 - \frac{\textbf{1}_{b^t_m = b}}{q^t_m(b)} + \frac{\textbf{1}_{b^t_m = b} \cdot w^t_m(b)}{q^t_m(b)}\right] = w^t_m(b)\,.
    \end{align*}
    Now, it remains to show that our sampling procedure $\textsc{Sample}-\bm{b}$ w.r.t. $\widehat{S}^\nround_m$ indeed samples bid vectors $\bm{b}$ with the same probability as the exponential weights algorithm under weights $\widehat{\mu}^\nround_n(\bm{b})$. In particular, we want to show that our algorithm samples bid vectors $\bm{b}^\nround$ with probability proportional to $\exp(\eta \sum_{\tau=1}^{t-1}\widehat{\mu}_m^\tau(b_m))$ for any $m\in [M]$. This follows from analyzing the dynamic programming variables that represent the sum of exponentiated (estimated) partial bid vector utilities, $\widehat{S}$.

    In exponential weights, the bidder selects at round $\nround+1$ some action $\bm{b}$ with probability $P^\nround(\bm{b})$ proportional to $\sum_{\tau=1}^{\nround} \widehat{\mu}_n^{\nround}(b)$. Using our representation of $\widehat{\mu}_n^{\nround}(\bm{b})$ as a function $\widehat{w}_\nitem^{\tau}(b)$, we have:
    \begin{align*}
        P^{\nround}(\bm{b}) = \frac{\exp(\eta \sum_{\tau=1}^{t-1} \widehat{\mu}_n^{\tau}(\bm{b}))}{\sum_{\bm{b}' \in \mathcal{B}^{+\Nitem}} \exp(\eta \sum_{\tau=1}^{t-1} \widehat{\mu}_n^\tau(\bm{b}'))} = \frac{\exp(\eta \sum_{\nitem=1}^\Nitem \widehat{W}_\nitem^\nround(b_\nitem))}{\sum_{\bm{b}' \in \mathcal{B}^{+\Nitem}} \exp(\eta \sum_{\nitem=1}^\Nitem \widehat{W}_\nitem^\nround(b'_\nitem))}\,.
    \end{align*}
    Hence, we wish to construct a sampler that samples $\bm{b}$ with the above probability. Defining $b_0 = \max_{b \in \mathcal{B}} b$, we begin by decomposing the denominator as follows:
    \begin{align*}
        &\sum_{\bm{b} \in \mathcal{B}^{+\Nitem}} \exp(\eta \sum_{\nitem=1}^\Nitem \widehat{W}_\nitem^\nround(b_\nitem)) = \sum_{b_1 \in \mathcal{B}, b_1 \leq b_0} \sum_{b_2 \in \mathcal{B}, b_2 \leq b_1} \ldots \sum_{b_\Nitem \in \mathcal{B}, b_\Nitem \leq b_{\Nitem-1}} \exp(\eta \sum_{\nitem=1}^\Nitem \widehat{W}_\nitem^\nround(b_\nitem))\\
        &= \sum_{b_1 \in \mathcal{B}, b_1 \leq b_0} \exp(\eta \widehat{W}_1^\nround(b_1)) \sum_{b_2 \in \mathcal{B}, b_2 \leq b_1}\exp(\eta \widehat{W}_2^\nround(b_2)) \ldots \sum_{b_\Nitem \in \mathcal{B}, b_\Nitem \leq b_{\Nitem-1}} \exp(\eta \widehat{W}_\Nitem^\nround(b_\Nitem))\,.
    \end{align*}
   Recall a key object $\widehat{S}^t_\nitem(b)$, which is the sum of exponentially weighted utilities of partial bid vectors $\bm{b}'_{\nitem:\Nitem} \in \mathcal{B}^{+(\Nitem - \nitem + 1)}$ over slots $\nitem,\ldots,\Nitem$ subject to $b_\nitem = b$.
    \begin{align}
        \widehat{S}^t_\nitem(b) &= \exp(\eta \widehat{W}_\nitem^\nround(b)) \sum_{\bm{b}'_{\nitem+1:\Nitem} \in \mathcal{B}^{+(\Nitem-\nitem)}, b'_{\nitem+1} \leq b'_\nitem = b} \exp(\eta \sum_{\nitem'=\nitem+1}^\Nitem \widehat{W}_{\nitem'}^\nround(b'_{\nitem'}))\\
        &= \exp(\eta \widehat{W}_\nitem^\nround(b)) \sum_{b' \in \mathcal{B}; b' \leq b} \widehat{S}^t_{\nitem+1}(b')\,.
    \end{align}
    With the trivial base case $\widehat{S}^t_\Nitem(b) = \exp(\eta \widehat{W}_\Nitem^\nround(b))$, we can recover all of the exponentially weighted partial utilities $\{\widehat{S}^t_{\nitem}(b)\}_{\nitem \in [\Nitem], b \in \mathcal{B}}$ given $\bm{W}^\nround$. Once we have computed $\{\widehat{S}^t_{\nitem}(b)\}_{\nitem \in [\Nitem], b \in \mathcal{B}}$, we can sample $\bm{b}$ according to its exponentially weighted utility $\exp(\eta \widehat{\mu}^{\nround}_\nitem(\bm{b}))$ by sequentially sampling each $b_1,\ldots,b_\Nitem$.
    
    Let $P_{\textsc{D}}^t(\bm{b})$ be the probability that our Algorithm \ref{alg: Decoupled Exponential Weights - Path Kernels} returns bid vector $\bm{b} \in \mathcal{B}^{+\Nitem}$ in round $t$. Recall that we sample $\bm{b}$ by setting $b_\nitem^\nround$ to $b \in \mathcal B, b \le b_{m-1}^t$ with probability $ \frac{\widehat{S}^t_\nitem(b)}{\sum_{b' \leq b_{\nitem-1}^t} \widehat{S}^t_{\nitem}(b')}$. Hence, the probability of selecting $\bm{b}$ is the product of $\nitem$ conditional probability mass functions (pmf's) and we have 
    \begin{align*}
        P_{\textsc{D}}^\nround(\bm{b}) = \prod_{\nitem=1}^\Nitem \frac{\widehat{S}^t_\nitem(b_\nitem)}{\sum_{b' \leq b_{\nitem-1}} \widehat{S}^t_{\nitem}(b')} = \left(\prod_{\nitem=1}^{M-1} \frac{\exp(\eta \widehat{W}_\nitem^\nround(b_\nitem)) \sum_{b \leq b_{\nitem}} \widehat{S}^t_{\nitem+1}(b)}{\sum_{b' \leq b_{\nitem-1}} \widehat{S}^t_{\nitem}(b')}\right)\left(\frac{\exp(\eta \widehat{W}_M^t(b_M))}{\sum_{b' \leq b_{M-1}} \widehat{S}_M^t(b')}\right)\,.
    \end{align*}
    Moving the $\exp(\eta \widehat{W}_m^t(b_m))$ outside of the product, we obtain:
    \begin{align*}
        P_{\textsc{D}}^\nround(\bm{b}) &= \left(\prod_{\nitem=1}^{\Nitem-1} \exp(\eta \widehat{W}_\nitem^\nround(b_\nitem)) \right) \left(\prod_{\nitem=1}^{M-1} \frac{\sum_{b \leq b_{\nitem}} \widehat{S}^t_{\nitem+1}(b)}{\sum_{b' \leq b_{\nitem-1}} \widehat{S}^t_{\nitem}(b')}\right)\left(\frac{\exp(\eta \widehat{W}_M^t(b_M))}{\sum_{b' \leq b_{M-1}} \widehat{S}_M^t(b')}\right)\\
        &= \left(\prod_{\nitem=1}^{\Nitem} \exp(\eta \widehat{W}_\nitem^\nround(b_\nitem)) \right) \left(\frac{\sum_{b \leq b_{M-1}} \widehat{S}^t_{M}(b)}{\sum_{b' \leq b_{0}} \widehat{S}^t_{1}(b')}\right)\left(\frac{1}{\sum_{b' \leq b_{M-1}} \widehat{S}_M^t(b')}\right)\\
        &= \frac{\prod_{\nitem=1}^{\Nitem} \exp(\eta \widehat{W}_\nitem^\nround(b_\nitem))}{\sum_{b' \leq b_{0}} \widehat{S}_1^t(b')}\,.
    \end{align*}
    We now rearrange the last expression to see that our algorithm samples $\bm{b}$ with the same probability as the exponential weights algorithm: 
    \begin{align*}
        P_{\textsc{D}}^\nround(\bm{b}) = \frac{\prod_{\nitem=1}^\Nitem \exp(\eta \widehat{W}_\nitem^\nround(b_\nitem))}{\sum_{b \leq b_0} S_1^t(b)} = \frac{\exp(\eta \sum_{\nitem=1}^\Nitem \widehat{W}_\nitem^\nround(b_\nitem))}{\sum_{\bm{b}' \in \mathcal{B}^{+\Nitem}} \exp(\eta \sum_{m=1}^M \widehat{W}_m^t(b'_m))} = P^\nround(\bm{b})\,.
    \end{align*}

    \textbf{Part 2: Regret Analysis.} We are now ready to derive the regret upper bound on Algorithm~\ref{alg: Decoupled Exponential Weights - Path Kernels}. First, we show that the bid vector utility estimators $\widehat{\mu}^\nround(\bm{b})$ are both unbiased and have a finite upper bound. To show the upper bound, we take expectation with respect to the bid vectors selected by our algorithm and observe that 
    \begin{align*}
        \mathbb{E}[\widehat{\mu}^\nround(\bm{b})] &= \sum_{m=1}^\Nitem \mathbb{E}[\widehat{w}_m^t(b_m)]= \sum_{m=1}^M \mathbb{E}\left[1 - \frac{1-(v_m-b_m)1_{b_m > b_{-m}^\nround}}{q_m^t(b_m)}1_{b_m = b^\nround_m}\right]
    \end{align*}
    As we are considering the expectation ex-post, keeping the $b_{-m}^t$'s fixed, we have independence between the two indicator functions and we obtain:
    \begin{align*}
        = \sum_{m=1}^M \mathbb{E}\left[1 - \frac{1-w^\nround_m(b_m)}{q_m^t(b_m)}1_{b_m = b^\nround_m}\right]= M - \sum_{m=1}^M \frac{1 - w^\nround_m(b_m)}{q_m^t(b_m)}\mathbb{E}\left[1_{b_m = b^\nround_m}\right]= \mu^\nround(\bm{b})\,.
    \end{align*}
 
    
    As for the finite upper bound, we have that $\widehat{\mu}^\nround(\bm{b}) = \sum_{m=1}^\Nitem \widehat{w}_m^t(b_m)$ is the sum over $M$ node utility estimators, each of which is upper bounded by 1. Hence, $\widehat{\mu}^\nround(\bm{b}) \leq \Nitem$ for all $\bm{b} \in \mathcal{B}^{+\Nitem}$. Now, we make the following claim:
    \begin{lemma}\label{lem:regret_bound}
        Let $\widehat{\mu}^\nround(\bm{b}) = \sum_{m=1}^M (1 - \frac{1-(v_m-b_m)1_{b_m > b_{-m}^\nround}}{q_m^t(b_m)}1_{b_m = b^\nround_m})$ be our bid vector utility estimate as discussed. Then, any algorithm which samples bid vectors $\bm{b}$ with probability proportional to $\exp(\eta \sum_{\tau=1}^{t-1} \widehat{\mu}^\nround(\bm{b}))$ at round $\nround$ for $\eta \leq \frac{1}{M}$ has regret upper bound
        \begin{align}
            \label{eq: ExpWeights Analysis 2}
            \textsc{Regret}_{\mathcal{B}} \lesssim \eta^{-1}M\log|\mathcal{B}| + \eta \sum_{\nround=1}^\Nround \sum_{\bm{b}} \prob(\bm{b}^\nround =\bm{b}) \mathbb{E}[(\sum_{m=1}^M \widehat{w}^\nround_m(b_m))^2]\,.
        \end{align}
    \end{lemma}
    \proof{Proof of Lemma \ref{lem:regret_bound}}
        We will closely follow the analysis of the $\textsc{Exp3}$ algorithm as presented in Chapter 11.4 of \cite{Lattimore2020}. In particular, we follow their regret analysis until Equation 11.13. Define $\Phi^t = \sum_{\bm{b} \in \mathcal{B}^{+\Nitem}} \exp(\eta \sum_{\tau=1}^{t} \widehat{\mu}^\tau(\bm{b}))$ to be the \textit{potential} at round $\nround$. As per our initial conditions in Algorithm~\ref{alg: Decoupled Exponential Weights - Path Kernels}, we have $\widehat{\mu}^0(\bm{b}) = 0$, and consequently, $\Phi^0 = |\mathcal{B}^{+\Nitem}|$. While it is not immediately apparent how the potentials $\Phi^\nround$ relate to the regret, we begin by upper bounding $\exp(\eta \sum_{t=1}^{T} \widehat{\mu}^t(\bm{b}))$ for a fixed $\bm{b}'$:
        \begin{align}
            \label{eq: Potentials}
            \exp(\eta \sum_{t=1}^{T} \widehat{\mu}^t(\bm{b}')) \leq \sum_{\bm{b} \in \mathcal{B}^{+\Nitem}} \exp(\eta \sum_{t=1}^{T} \widehat{\mu}^t(\bm{b})) = \Phi^T = \Phi^0 \prod_{t=1}^T \frac{\Phi^t}{\Phi^{t-1}}\,.
        \end{align}
        Now, we upper bound each $\frac{\Phi^t}{\Phi^{t-1}}$:
        \begin{align*}
            \frac{\Phi^t}{\Phi^{t-1}} = \sum_{\bm{b} \in \mathcal{B}^{+M}} \frac{\exp(\eta \sum_{\tau=1}^{t} \widehat{\mu}^\tau(\bm{b}))}{\Phi^{t-1}} = \sum_{\bm{b} \in \mathcal{B}^{+M}} \frac{\exp(\eta \sum_{\tau=1}^{t-1} \widehat{\mu}^\tau(\bm{b}))}{\Phi^{t-1}} \exp(\eta \widehat{\mu}^t(\bm{b})) = \sum_{\bm{b} \in \mathcal{B}^{+M}} \prob(\bm{b}^\nround = \bm{b}) \exp(\eta \widehat{\mu}^t(\bm{b}))\,,
        \end{align*}
        where in the last equality, we used the condition that our algorithm samples bid vector $\bm{b}$ with probability proportional to $\exp(\eta \sum_{\tau=1}^{t-1} \widehat{\mu}^\nround(\bm{b}))$ at round $\nround$. In order to continue the chain of inequalities, we note that for $\eta \leq \frac{1}{M}$, we have that the quantity $\eta \widehat{\mu}^t(\bm{b})$ is upper bounded by 1 as $\eta \widehat{\mu}^t(\bm{b}) \leq \eta M \leq 1$. In the first inequality, we used the fact that $\widehat{\mu}^\nround(\bm{b}) \leq \Nitem$. Now, we can apply the inequalities $\exp(x) \leq 1 + x + x^2$ and $1 + x \leq \exp(x)$ for all $x \leq 1$, with $x= \eta \widehat{\mu}^t(\bm{b})$ and $x = \eta \prob(\bm{b}^\nround = \bm{b}) \widehat{\mu}^t(\bm{b})$, respectively,  to obtain:
        \begin{align*}
            \frac{\Phi^t}{\Phi^{t-1}} &\leq \sum_{\bm{b} \in \mathcal{B}^{+M}} \prob(\bm{b}^\nround = \bm{b}) \exp(\eta \widehat{\mu}^t(\bm{b}))\\
            &\leq \sum_{\bm{b} \in \mathcal{B}^{+M}} \prob(\bm{b}^\nround = \bm{b}) \left[1 + \eta\widehat{\mu}^t(\bm{b}) + \eta^2 \widehat{\mu}^t(\bm{b})^2 \right]\\
            &= 1+ \sum_{\bm{b} \in \mathcal{B}^{+M}} \prob(\bm{b}^\nround = \bm{b}) \left[\eta\widehat{\mu}^t(\bm{b}) + \eta^2 \widehat{\mu}^t(\bm{b})^2 \right]\\
            &\leq \exp(\sum_{\bm{b} \in \mathcal{B}^{+M}} \prob(\bm{b}^\nround = \bm{b}) \left[\eta\widehat{\mu}^t(\bm{b}) + \eta^2 \widehat{\mu}^t(\bm{b})^2 \right])\,.
        \end{align*}
        Combining this with Equation~\eqref{eq: Potentials} and then taking logarithms, we obtain:
        \begin{align*}
            \eta \sum_{t=1}^{T} \widehat{\mu}^t(\bm{b}') \leq \log \Phi^0 + \eta \sum_{t=1}^{T} \sum_{\bm{b} \in \mathcal{B}^{+M}} \prob(\bm{b}^\nround = \bm{b}) \widehat{\mu}^t(\bm{b}) + \eta^2 \sum_{t=1}^T \sum_{\bm{b} \in \mathcal{B}^{+M}}\prob(\bm{b}^\nround = \bm{b}) \widehat{\mu}^t(\bm{b})^2\,.
        \end{align*}
        Dividing both sides by $\eta$, applying the upper bound on $\Phi^0$, and rearranging, we obtain that for any $\bm{b}' \in \mathcal{B}^{+M}$:
        \begin{align*}
            \sum_{t=1}^{T} \widehat{\mu}^t(\bm{b}') - \sum_{t=1}^{T} \sum_{\bm{b} \in \mathcal{B}^{+M}} \prob(\bm{b}^\nround = \bm{b})  \widehat{\mu}^t(\bm{b}) \lesssim \eta^{-1} \Nitem \log |\mathcal{B}| + \eta \sum_{t=1}^T \sum_{\bm{b} \in \mathcal{B}^{+M}}\prob(\bm{b}^\nround = \bm{b}) \widehat{\mu}^t(\bm{b})^2\,.
        \end{align*}
        Replacing $\widehat{\mu}^\nround(\bm{b})$ with its definition in terms of $\widehat{w}^\nround_m(b_m)$ and taking expectations, we obtain the right hand side of the lemma:
        \begin{align*}
            \mathbb{E}\left[\sum_{t=1}^{T} \widehat{\mu}^t(\bm{b}') - \sum_{t=1}^{T} \sum_{\bm{b} \in \mathcal{B}^{+M}} \prob(\bm{b}^\nround = \bm{b})  \widehat{\mu}^t(\bm{b})\right] \lesssim \eta^{-1}M\log|\mathcal{B}| + \eta \sum_{\nround=1}^\Nround \sum_{\bm{b}} \prob(\bm{b}^\nround =\bm{b}) \mathbb{E}[(\sum_{m=1}^M \widehat{w}^\nround_m(b_m))^2]\,.
        \end{align*}
        Replacing $\sum_{\bm{b} \in \mathcal{B}^{+M}} \prob(\bm{b}^\nround = \bm{b})  \widehat{\mu}^t(\bm{b})$ with $\mathbb{E}[\widehat{\mu}^\nround(\bm{b}^\nround)]$ and recalling that the bid vector utility estimates $\widehat{\mu}^\nround$ were unbiased, we have:
        \begin{align*}
            \sum_{t=1}^{T} \mu^t(\bm{b}') - \sum_{t=1}^{T} \mathbb{E}[\mu^t(\bm{b}^\nround)] \lesssim \eta^{-1}M\log|\mathcal{B}| + \eta \sum_{\nround=1}^\Nround \sum_{\bm{b}} \prob(\bm{b}^\nround =\bm{b}) \mathbb{E}[(\sum_{m=1}^M \widehat{w}^\nround_m(b_m))^2]\,.
        \end{align*}
        Notice that as this is true for any $\bm{b}'$, we can replace it with the bid vector that maximizes the true cumulative utility $\sum_{t=1}^T \mu^\nround(\bm{b}')$ and see that the left hand side becomes precisely $\textsc{Regret}_\mathcal{B}$, which completes the proof.
        %\Halmos
    \endproof

    Now, it remains to show an upper bound on the second moment of the bid vector utility estimate $\mathbb{E}[(\sum_{m=1}^M \widehat{w}^\nround_m(b_m))^2]$. A crude attempt would be to say that $\mathbb{E}[(\sum_{m = 1}^M \widehat{w}^\nround_m(b_m))^2] \leq \Nitem \sum_{m = 1}^M \mathbb{E}[\widehat{w}^\nround_m(b_m)^2]$:
    \begin{align}
        &\sum_{\nround=1}^\Nround \sum_{\bm{b}} \prob(\bm{b}^\nround = \bm{b}) \mathbb{E}[(\sum_{m = 1}^M \widehat{w}^\nround_m(b_m))^2] \leq \Nitem \sum_{\nround=1}^\Nround \sum_{\bm{b}} \prob(\bm{b}^\nround = \bm{b}) \sum_{m = 1}^M \mathbb{E}[\widehat{w}^\nround_m(b_m)^2] \label{eq: full info difference}\\
        &= \Nitem \sum_{\nround=1}^\Nround \sum_{\nitem = 1}^\Nitem \sum_{b \in \mathcal{B}} \mathbb{E}[\widehat{w}^\nround_m(b)^2] \sum_{\bm{b}: b_m = b} \prob(\bm{b}^\nround = \bm{b}) = \Nitem \sum_{\nround=1}^\Nround \sum_{\nitem = 1}^\Nitem \sum_{b \in \mathcal{B}} \mathbb{E}[\widehat{w}^\nround_m(b)^2] q^\nround_m(b) \notag\\
        &\leq \Nitem \sum_{\nround=1}^\Nround \sum_{\nitem = 1}^\Nitem \sum_{b \in \mathcal{B}} \frac{2}{q_m^t(b)} q_m^t(b) = O(\Nitem^2 |\mathcal{B}| \Nround)\,. \notag
    \end{align}
    Where the last inequality follows from:
    \begin{align*}
        \mathbb{E}[\widehat{w}_m^t(b)^2] = \mathbb{E}\left[\left( 1 - \frac{1-w_m^t(b)}{q_m^t(b)} \textbf{1}_{b_m^t = b} \right)^2 \right] = 1 - 2\mathbb{E}\left[\frac{1-w_m^t(b)}{q_m^t(b)}\textbf{1}_{b_m^t=b}\right] + \mathbb{E}\left[\left(\frac{1-w_m^t(b; \bm{v})}{q_m^t(b)}\right)^2\textbf{1}_{b_m^t=b}\right]\,.
    \end{align*}
    Evaluating the expectations with $\mathbb{E}\left[\textbf{1}_{b_m^t = b}\right] = q_m^t(b)$, we have:
    \begin{align*}
        \mathbb{E}[\widehat{w}_m^t(b)^2] = 1 - \left[2 - 2w_m^t(b)\right] + \left[\frac{(1 - w_m^t(b))^2}{q_m^t(b)}\right] = 2w_m^t(b) - 1 + \frac{1}{q_m^t(b)} \leq 1 + \frac{1}{q_m^t(b)} \leq \frac{2}{q_m^t(b)}\,.
    \end{align*}    
    Plugging this back into our upper bound yields stated regret bound for $\eta = \Theta(\sqrt{\frac{\log |\mathcal{B}|}{M|\mathcal{B}|T}})$ such that $\eta < \frac{1}{M}$:
    
    \begin{align*}
        \textsc{Regret}_\mathcal{B} \lesssim \eta^{-1}\Nitem \log |\mathcal{B}| + \eta\Nitem^2 |\mathcal{B}|T = O(\Nitem^{\frac{3}{2}}\sqrt{|\mathcal{B}| \Nround \log |\mathcal{B}|})\,.
    \end{align*}

    \textbf{Part 3: Complexity Analysis.} We note that the time and space complexity analysis is identical to that of Algorithm~\ref{alg: Decoupled Exponential Weights}, as the only additional computational work being done is computing the normalization terms $q_m^\nround(b)$, which requires $O(M|\mathcal{B}|)$ space and $O(MT|\mathcal{B}|)$ time respectively. Hence, discarding old tables, the total time and space complexities of Algorithm \ref{alg: Decoupled Exponential Weights - Path Kernels} are $O(\Nitem |\mathcal{B}| \Nround)$ and $O(\Nitem |\mathcal{B}|)$ respectively. As this is polynomial in $\Nitem, |\mathcal{B}|, \Nround$, we have proven the claim of polynomial space and time complexities.

    \textbf{Part 4: Selecting $\mathcal{B}$.} We claim that the sub-optimality due to the discretization is on the order of $\frac{MT}{|\mathcal{B}|}$. Assume that $\mathcal{B} \equiv \{\frac{i}{|\mathcal{B}|}\}_{i \in [|\mathcal{B}|]}$ is an even discretization of $[0, 1]$, and recall the continuous regret benchmark:
    \begin{align*}
        \textsc{Regret} = \max_{\bm{b} \in [0, 1]^{+\Nitem}} \sum_{\nround=1}^\Nround \mu^\nround_n(\bm{b}) - \mathbb{E}\left[\sum_{\nround=1}^\Nround \mu^\nround_n(\bm{b}^\nround)\right],
    \end{align*}
    where the maximum is taken over the entire space $[0, 1]^{+\Nitem}$ rather than $\mathcal{B}^{+\Nitem}$. Let $\bm{b}^*$ denote the maximizer of the continuous regret. Then, bidder $n$ could have obtained at least the same allocation by rounding up each bid in $\bm{b}^*$ to the next largest multiple of $\frac{1}{|\mathcal{B}|}$. Let this rounded bid vector be denoted by $\bm{b}^+$. As their allocation, thus value for the set of items received, does not decrease, and their total payment increases by a maximum of $\frac{M}{|\mathcal{B}|}$ at each round, then we have that $\mu_n^t(\bm{b}^+) \geq \mu_n^t(\bm{b}^*) - \frac{M}{|\mathcal{B}|}$. Let $\bm{b}_{\mathcal{B}}^* \in \mathcal{B}^{+\Nitem}$ denote the hindsight optimal utility vector returned by our offline dynamic programming (Algorithm~\ref{alg: Offline Full}), which serves as the regret benchmark in the definition of discretized regret. Noting that $\bm{b}^+ \in \mathcal{B}^{+\Nitem}$, we have that the total utility of bidding $\bm{b}^*_{\mathcal{B}}$ must be at least that of $\bm{b}^+$. Thus,
    \begin{align*}
        \sum_{\nround=1}^\Nround \mu^\nround_n(\bm{b}_{\mathcal{B}}^*) \geq \sum_{\nround=1}^\Nround \mu^\nround_n(\bm{b}^+)\geq \sum_{\nround=1}^\Nround \mu^\nround_n(\bm{b}^*) - \frac{MT}{|\mathcal{B}|}
    \end{align*}
    We balance this with the discretized regret $O(\Nitem^{\frac{3}{2}}\sqrt{|\mathcal{B}| \Nround \log |\mathcal{B}|})$ with $|\mathcal{B}| = M^{-\frac{1}{3}}T^{\frac{1}{3}}$. This yields continuous regret $\textsc{Regret} = O(M^{\frac{4}{3}}T^{\frac{2}{3}} \sqrt{\log \Nround})$.

    \textbf{Part 5: Extending to the Full Information Setting.} Thus far, we have only discussed the bandit feedback algorithm. Fortunately, the full information setting algorithm is exactly the same except for two differences: 1) we do not need to compute $\bm{q}$ and 2) we can replace the reward estimates $\widehat{\mu}^t(\bm{b})$ with the true rewards $\mu^t(\bm{b})$ in Equation~\ref{eq: full info difference}. The first difference can only serve to improve the time and space complexity of our algorithm. The second difference allows us to improve the bound on $\sum_{\nround=1}^\Nround \sum_{\bm{b}} \prob(\bm{b}^\nround = \bm{b}) \mathbb{E}[(\sum_{m = 1}^M \widehat{w}^\nround_m(b_m))^2]$ in the left hand sight of Equation~\ref{eq: full info difference} by replacing $\widehat{w}^\nround_m(b_m))$ with $w^t_m(b_m)$:
    \begin{align*}
        \sum_{\nround=1}^\Nround \sum_{\bm{b}} \prob(\bm{b}^\nround = \bm{b}) \mathbb{E}[(\sum_{m = 1}^M \widehat{w}^\nround_m(b_m))^2] = \sum_{\nround=1}^\Nround \sum_{\bm{b}} \prob(\bm{b}^\nround = \bm{b}) \mathbb{E}[(\sum_{m = 1}^M \widehat{w}^\nround_m(b_m))^2] \leq M^2 \sum_{\nround=1}^\Nround \sum_{\bm{b}} \prob(\bm{b}^\nround = \bm{b}) = M^2T
    \end{align*}
    
    Notice that this bound is a factor of $|\mathcal{B}|$ improvement over that in the bandit setting. Consequently, we obtain our stated regret bound of $O(M^\frac{3}{2} \sqrt{T \log |\mathcal{B}|})$ with the choice of $\eta = \Theta(\sqrt{\frac{\log |\mathcal{B}|}{MT}})$. Balancing this regret with the error term, which is of order $O\left(\frac{M|\mathcal{B}|}{T}\right)$, the optimal choice of $|\mathcal{B}|$ is given by $\Theta(\sqrt{\frac{T}{M}})$. This yields corresponding continuous regret of $O(M^{\frac{3}{2}}\sqrt{T \log T})$.
    

\end{proof}



\subsection{Lemmas \ref{lem: QSpace Equivalence} and \ref{lem: Online Linear Optimization}, and their Proofs} \label{sec:QSpace Equivalence} 

In Algorithm~\ref{alg: OMD}, we require that the space of all possible node probability measure $\bm{q}$ encompasses the set of node probability measures that correspond to any policy $\bm{\pi}$ over our DP graph.

\begin{lemma}[$\mathcal{Q}$-Space Equivalence]
    \label{lem: QSpace Equivalence}
    Let \[\Pi = \Big\{{\pi} \in [0,1]^{M\times |\mathcal B|\times |\mathcal B|}: \pi((m, b), b') = 0 ~~\forall b' > b, m\in [M], \sum_{b' \leq b} \pi((m, b), b') = 1, m\in [M]\Big\}\] denote the space of policies on our DP graph. With a slight abuse of notation, for any $\pi\in  \Pi$, define 
    \[q(\pi) = \{\mathbf{q} \in [0, 1]^{M\times |\mathcal B|}: \forall b \in \mathcal{B},  q_1(b) =\pi((0, b_0), b), q_{m+1}(b) = \sum_{b' \in \mathcal B} q_m(b')\pi((m, b'), b), m\in[M-1]\}\,\] as the node probabilities induced by $\pi$. Here, $b_0= \max \mathcal B$. Let $\mathcal{Q}_{\Pi} = \cup_{\pi \in \Pi} q(\pi)$. Then,   $\mathcal{Q}_{\Pi}$ is equivalent to the set $\mathcal{Q}$ where $\mathcal{Q}$ is defined in Equation \eqref{eq:Q}. 
\end{lemma}


Lemma \ref{lem: QSpace Equivalence} establishes that during the execution of Algorithm \ref{alg: OMD}, we can focus on the node probabilities in set $\mathcal{Q}$ without loss of generality. We recall that within $\mathcal{Q}$, the stochastic dominance conditions are enforced solely over node probabilities across layers. %In other words, when determining $\mathbf{q}^t$ in Algorithm \ref{alg: OMD}, it is sufficient to consider the feasible set restricted to $\mathcal{Q}$, which is a convex set as  $\mathcal{Q}$ is a polyhedron. 
We now argue that we only need to consider optimizing over $\mathcal{Q}$ as opposed to the space of policies $\Pi$, as the regret can be rewritten strictly in terms of $\bm{q}$, independently of the corresponding $\bm{\pi}$.


\begin{lemma}
    \label{lem: Online Linear Optimization}
     Any sequence of policies $\bm{\pi}^1,\ldots,\bm{\pi}^\Nround$ over our DP graph with associated node probability measures $\bm{q}^1,\ldots,\bm{q}^\Nround$ has discretized regret $\textsc{Regret}_{\mathcal{B}} = \max_{\bm{q} \in \mathcal{Q}} \sum_{\nround=1}^\Nround \langle \bm{q} - \bm{q}^\nround, \bm{w}^\nround\rangle$. Here, $\bm{w}^\nround = \{w^\nround_m(b)\}_{m \in [M], b \in \mathcal{B}}$ represents vector of the round $\nround$ rewards for all possible $(m, b)$ unit-bid value pairs.
 \end{lemma}
      
\subsubsection{Proof of Lemma \ref{lem: QSpace Equivalence}}

In order to show equivalence, we show that (1) for any $\pi \in \Pi$, that $q(\pi) \in \mathcal{Q}$ and (2) for any $\bm{q} \in \mathcal{Q}$, there exists a $\pi \in \Pi$ such that $q(\pi) = \bm{q}$. We first prove (1). To do this, we simply need to check that for a given $\pi \in \Pi$, that $q^\pi = q(\pi)$ satisfies the constraints prescribed by $\mathcal{Q}$.

    The non-negativity constraint holds trivially as each $\pi((m, b), b')$ is non-negative. Since all $q^\pi_1(b) = \pi((0, \max\mathcal{B}), b) \geq 0$ for all $b \in \mathcal{B}$, by induction, $q^\pi_{m+1}(b) = \sum_{b" \geq b} q^\pi_m(b") \pi((m, b"), b)$ is also non-negative.
    
    Now we prove that each layer $m$ sums to 1, i.e., $\sum_{b \in \mathcal{B}} q^\pi_m(b) = 1$. Since $\sum_{b \in \mathcal{B}} q^\pi_1(b)$, the policy has total node probability 1 in the first layer, we can prove $\sum_{b \in \mathcal{B}} q^\pi_m(b) = 1$, that the policy has total node probability 1 in the $m$'th layer, via induction. This follows immediately from the fact that the DP graph is layered, i.e., edges exist only from nodes in layer $m$ to nodes in layer $m+1$, thus the only edges leading to layer $m+1$ are from layer $m$, in which there are no other edges. Hence, the total node probability in layer $m+1$ must be exactly that of layer $m$. More formally, we have:
    \begin{align*}
        \sum_{b \in \mathcal{B}} q^\pi_{m+1}(b) = \sum_{b \in \mathcal{B}} \sum_{b" \geq b} q^\pi_m(b") \pi((m, b"), b) = \sum_{b" \in \mathcal{B}} q^\pi_m(b") \sum_{b \leq b"} \pi((m, b"), b) = \sum_{b" \in \mathcal{B}} q^\pi_m(b")\,.
    \end{align*}

     To show the stochastic domination constraint $\sum_{b \leq b'} q^\pi_{m+1}(b) \geq \sum_{b \leq b'} q^\pi_m(b)$, we use the bid monotonicity constraint; i.e., the fact that the edges between layers are only from larger bids to (weakly) smaller bids. Recall that $\pi((m,b'), b")$ is the probability of transitioning from unit-bid value pair $(m, b')$ to $(m+1, b")$ and that the only edges leading to $(m+1, b")$ come from nodes $(m, b')$ for $b' \geq b"$. Then, we have:
     \begin{align*}
         \sum_{b \leq b'} q^\pi_{m+1}(b) &= \sum_{b \leq b'} \sum_{b" \geq b} q^\pi_m(b")\pi((m, b"), b) \\
         &=\sum_{b" > b'} q^\pi_m(b") \sum_{b \leq b'} \pi((m, b"), b) + \sum_{b" \leq b'} q^\pi_m(b") \sum_{b \leq b"} \pi((m, b"), b)\\
         &= \sum_{b" > b'} q^\pi_m(b") \sum_{b \leq b'} \pi((m, b"), b) + \sum_{b \leq b'} q^\pi_m(b)\\
         &\geq \sum_{b \leq b'} q^\pi_m(b)\,.
     \end{align*}
     Hence, we have shown that for any $\pi \in \Pi$, that the corresponding $q(\pi) \in \mathcal{Q}$.
     
     Now we show the other direction (2), that for any $\bm{q} \in \mathcal{Q}$, there exists a $\pi \in \Pi$ such that $q(\pi) = \bm{q}$. We proceed by showing that for all $m, b^*$, there exists $\{\pi((m, b), b')\}_{b, b' \in \mathcal{B}}$ such that the following conditions hold:
     \begin{enumerate}
         \item $\pi((m, b), b') \geq 0$ for all $b, b' \geq b^*$.
         \item $\pi((m, b), b') = 0$ for all $b' > b \geq b^*$.
         \item $\sum_{b' \leq b, b' \geq b^*} \pi((m, b), b') \leq 1$ for all $b^* \in \mathcal{B}$, with equality if and only if $b^* =  b_{\min}$ where $b_{\min} = \min \mathcal{B}$.
         \item $\sum_{b' \geq b^*} \sum_{b \geq b'} q_m(b)\pi((m, b), b') = \sum_{b' \geq b^*} q_{m+1}(b')$.
     \end{enumerate}
Let $\Pi(b^*; \mathbf{q})$, $b^*\in \mathcal B$, be the set of all policies under which the four conditions hold at $b^*$ and ${\mathbf q} \in \mathcal Q$. 
     
    These conditions trivially hold for $m = 0$, as we can set $\pi((0, \max \mathcal{B}), b) = q_1(b)$ and $\pi((0, b), b') = \textbf{1}_{b = b'}$. To solve for general $m$, we must show that there exists $\{\pi((m, b), b')\}_{b, b' \in \mathcal{B}}$ that satisfies the constraints prescribed by $\Pi$ and that $\sum_{b \geq b'} q_m(b)\pi((m, b), b') = q_{m+1}(b')$ for all $b' \in \mathcal{B}$. In order to do this, we show that conditions (1), (2), (3), and (4) for each $b^* \in \mathcal{B}$. In particular, if we show conditions (1) and (2) for $b^* = b_{\min}$, then we have already satisfied the first two conditions of $\Pi$. If we show that (3) holds for $b^* = b_{\min}$, then by condition (1), then (3) holds for all $b^* \in \mathcal{B}$ as well, as the summation only includes fewer terms as $b^*$ increases. Similarly, if we show condition (4) holds for two adjacent values of $b_-^* < b^*$, then we have that $\sum_{b \geq b' \geq b^*} q_m(b)\pi((m, b), b') = q_{m+1}(b^*)$. Thus, if condition (4) holds for all possible pairs of adjacent bid values, then we have that $\sum_{b \geq b'} q_m(b)\pi((m, b), b') = q_{m+1}(b')$ for all $b'$. These observations suggest use of induction over $b^*$, and indeed, we begin by showing that these conditions hold for $b^* = b_{\min}$. We then show that this implies that the conditions hold for the next smallest value of $b^*$, which would complete the induction proof.

    \textbf{Base Case}: Recall $b^* = b_{\min}$. We now show that there exists $\{\pi((m, b), b')\}_{b, b' \in \mathcal{B}}$ satisfying all four conditions. For any $m\in[M]$, let we set $\pi((m, b), b') = \textbf{1}_{b = b'}$. Then, 
 condition (4) is clearly satisfied: 
    \begin{align*}
        \sum_{b' \geq b^*} \sum_{b \geq b'} q_m(b)\pi((m, b), b') = \sum_{b' \geq b^*} q_{m+1}(b') \leftrightarrow \sum_{b \in \mathcal{B}} q_m(b) \sum_{b' \leq b} \pi((m, b), b') = \sum_{b \in \mathcal{B}} q_{m+1}(b) = 1\,.
    \end{align*}
    It is also easy to check that conditions (1)-(3) are also satisfied when we set $\pi((m, b), b') = \textbf{1}_{b = b'}$ for any $m$. This shows that $\Pi(b^*; {\mathbf{q}})$ is non-empty, as desired. 
   
    
    \textbf{Recursive Case}:
    For any $b\in \mathcal B$, let $b_-$ be the largest $b' \in \mathcal B$, which is strictly smaller than $b$. Here, we assume that 
    $\Pi(b^*_-; \bf{q})$ is not empty, and under this assumption, we show that set $\Pi(b^*; \bf{q})$ is not empty, where $\Pi(b^*; {\bf{q}}) \subseteq \Pi(b^*_-; \bf{q})$. 
    Let us start with condition (4). 
    We would like to show that there exists a $\bm{\pi}$ that satisfies condition (4) at $b^*$ along with the other three conditions. By the induction assumption, we have  
    \begin{align*}
        &\sum_{b' \geq b_-^*} \sum_{b \geq b'} q_m(b)\pi((m, b), b') = \sum_{b' \geq b_-^*} q_{m+1}(b') \to\\
        &\sum_{b' \geq b^*} \sum_{b \geq b'} q_m(b)\pi((m, b), b') + \sum_{b \geq b_-^*} q_m(b)\pi((m, b), b_-^*) = \sum_{b' \geq b^*} q_{m+1}(b') + q_{m+1}(b_-^*) \to\\
        &\sum_{b' \geq b^*} \sum_{b \geq b'} q_m(b)\pi((m, b), b') = \sum_{b' \geq b^*} q_{m+1}(b') + \left[q_{m+1}(b_-^*) - \sum_{b \geq b_-^*} q_m(b)\pi((m, b), b_-^*)\right] \to\\
        &\sum_{b \geq b^*} q_m(b) \sum_{b' \leq b; b' \geq b^*} \pi((m, b), b') = \sum_{b' \geq b^*} q_{m+1}(b') + \left[q_{m+1}(b_-^*) - \sum_{b \geq b_-^*} q_m(b)\pi((m, b), b_-^*)\right] 
    \end{align*}
    Thus, we can satisfy condition (4) if $q_{m+1}(b_-^*) = \sum_{b \geq b_-^*} q_m(b)\pi((m, b), b_-^*)$. We now observe that the latter summation depends linearly (and hence, continuously) in the values of $\pi((m, b), b_-^*)$. If we can show that there exists an assignment of these variables that satisfy $q_{m+1}(b_-^*) \geq \sum_{b \geq b_-^*} q_m(b)\pi((m, b), b_-^*)$ and also $q_{m+1}(b_-^*) \leq \sum_{b \geq b_-^*} q_m(b)\pi((m, b), b_-^*)$, then by the intermediate value theorem, there must be some assignment that achieves exact equality. 
    
    
    In order to show the first inequality, notice that if we set $\pi((m, b), b_-^*) = 1 - \sum_{b' < b_-^*} \pi((m, b), b')$ for all $b \geq b_-^*$ (this is required in order to guarantee conditions (1) and (3) are satisfied), then:
    \begin{align*}
        \sum_{b \geq b_-^*} q_m(b)\pi((m, b), b_-^*) &= \sum_{b \geq b_-^*} q_m(b) - \sum_{b \geq b_-^*} q_m(b)\sum_{b' < b_-^*} \pi((m, b), b') \\
        &= \sum_{b \geq b_-^*} q_{m}(b) - \sum_{b \in \mathcal{B}} q_m(b) \sum_{b' < b_-^*} \pi((m, b), b') + \sum_{b < b_-^*} q_m(b) \sum_{b' < b_-^*} \pi((m, b), b')\\
        &= \sum_{b \geq b_-^*} q_{m}(b) - \sum_{b' < b_-^*} q_{m+1}(b) + \sum_{b < b_-^*} q_m(b) \sum_{b' < b_-^*} \pi((m, b), b')\\
        &= \sum_{b \geq b_-^*} q_{m}(b) - \sum_{b' < b_-^*} q_{m+1}(b) + \sum_{b < b_-^*} q_m(b)\\
        &\geq \sum_{b \geq b_-^*} q_{m+1}(b) - \sum_{b' < b_-^*} q_{m+1}(b) + \sum_{b < b_-^*} q_{m+1}(b)\\
        &= \sum_{b \geq b_-^*} q_{m+1}(b)\\
        &\geq q_{m+1}(b_-^*)\,.
    \end{align*}
    Here, the third equality follows from the (strong) inductive hypothesis, and the first inequality is a result of the stochastic domination constraint in $\mathcal{Q}$. We also note that the values $\sum_{b' < b_-^*} \pi((m, b), b')$ have already been fixed
    as these were required to satisfy condition (4) in the previous iterates, and as condition (3) holds for $b^*_-$ by the inductive hypothesis, then $1 - \sum_{b' < b_-^*} \pi((m, b), b') \geq 0$. Conversely, if we set $\pi((m, b), b_-^*) = 0$ for all $b \geq b_-^*$, then:
    \begin{align*}
        \sum_{b \geq b_-^*} q_m(b)\pi((m, b), b_-^*) = 0 \leq q_{m+1}(b_-^*)\,.
    \end{align*}
    As the sum $\sum_{b \geq b_-^*} q_m(b)\pi((m, b), b_-^*)$ linearly (thus, continuously) depends on the values of $\pi((m, b), b_-^*)$, by the intermediate value theorem, there exists an assignment of $\{\pi((m, b), b_-^*)\}_{b \geq b_-^*}$ with each $\pi((m, b), b_-^*) \in [0, 1 - \sum_{b' < b_-^*} \pi((m, b), b')]$ such that the sum is precisely equal to $q_{m+1}(b_-^*) \in [0, 1]$. Now we observe that these values of $\pi((m, b), b_-^*) \in [0, 1 - \sum_{b' < b_-^*} \pi((m, b), b')]$ do not violate conditions (1), (2), or (3). Furthermore, note that any $\bm{\pi} \in \Pi$ also satisfied conditions (1), (2), and (3) under $b^*_-$ for $\{\pi((m, b), b')\}_{b \geq b_-^*, b' \leq b_-^*}$, then the assignment to $\{\pi((m, b), b')\}_{b \geq b_-^*, b' < b_-^*}$ will not violate these conditions as our new constraint on the variables $\{\pi((m, b), b_-^*)\}_{b \geq b_-^*}$ is independent of the values of $\{\pi((m, b), b')\}_{b \geq b_-^*, b' < b_-^*}$. Thus, the set $\Pi(b^*)$ is non-empty:
    \begin{align*}
        \Pi(b^*) = \{\{\pi((m, b), b')\}_{b, b' \in \mathcal{B}} \in \Pi(b_-^*): \sum_{b \geq b_-^*} q_m(b)\pi((m, b), b_-^*) = q_{m+1}(b_-^*)\} \neq \emptyset
    \end{align*}    
    With this, we have proven via induction that our four conditions hold for all $b^* \in \mathcal{B}$, implying that for a fixed $m$, every constraint in $\Pi$ pertaining to variables $\pi((m, b), b')$ is satisfied, as well as the node-measure constraints $\sum_{b \geq b'} q_m(b)\pi((m, b), b') = q_{m+1}(b')$ for all $b'$. By induction, this works for all $m \in [M]$, which concludes the proof.



\subsubsection{Proof of Lemma \ref{lem: Online Linear Optimization}}
We have by the definition of discretized regret:
\begin{align*}
    \textsc{Regret}_\mathcal{B} &= \max_{\bm{b} \in \mathcal{B}} \sum_{\nround=1}^\Nround \mu^\nround_n(\bm{b}) - \mathbb{E}\left[\sum_{\nround=1}^\Nround \mu^\nround_n(\bm{b}^\nround)\right] = \max_{\bm{q} \in \mathcal{Q}} \mathbb{E}\left[\sum_{\nround=1}^\Nround \langle \bm{q}, \bm{w}^\nround\rangle - \sum_{\nround=1}^\Nround \langle \bm{q}^\nround, \bm{w}^\nround\rangle\right]\,, 
\end{align*}
where in the first equality, we applied Equation~\eqref{eq: Loss of policy} which equated the dot product of utilities $\bm{w}^\nround$ and node probability weights $\bm{q}$ to the expected utility of bid vector $\bm{b} \sim \bm{\pi}$ with utilities $\{w_m^t(b)\}_{m \in [M], b \in \mathcal{B}} = \bm{w}^\nround$. Combining the two summations yields the desired result.

\subsection{Proof of Theorem~\ref{thm: OMD}: Online Mirror Descent Algorithm }

\label{sec: Proof of OMD}

\begin{proof}{Proof of Theorem~\ref{thm: OMD}: Online Mirror Descent Algorithm}

    The proof is divided into four parts, similar to the analysis of Algorithm~\ref{alg: Decoupled Exponential Weights}. In the first part, we rigorously show how our algorithm achieves the stated regret. In the second, we verify correctness of our procedure that recovers a policy $\bm{\pi}^\nround$ from $\bm{q}^\nround$. Then, we show the corresponding time and space complexity of our algorithm. Afterwards, we optimize over discretization error to obtain the continuous regret. %Lastly, we show the extension to the full information setting.
    

    \textbf{Part 1: Regret of Online Linear Optimization.} Recall that from Lemma~\ref{lem: Online Linear Optimization}, we have
    \begin{align}
        \textsc{Regret}_\mathcal{B} = \max_{\bm{q} \in \mathcal{Q}} \mathbb{E}\left[ \sum_{\nround=1}^\Nround \langle \bm{q} - \bm{q}^\nround, \bm{w}^\nround \rangle\right] = \max_{\bm{q} \in \mathcal{Q}} \mathbb{E}\left[\sum_{\nround=1}^\Nround \langle  \bm{q}^\nround - \bm{q}, -\bm{w}^\nround \rangle\right]\, ,
    \end{align}
    where we negate the utility function into a loss function to be consistent with the OLO convention. We follow a standard analysis of OMD, which shows that the optimization step can be solved efficiently and the resulting iterates have bounded regret. For the former, we show that solution to the $\bm{q}$ optimization step in our algorithm $\bm{q}^{\nround} = \text{argmin}_{\bm{q} \in \mathcal{Q}} \eta\langle \bm{q}, -\bm{w}^\nround\rangle + D(\bm{q} || \bm{q}^{\nround-1})$ can be obtained as the projection of the unconstrained minimizer of \[\tilde{q}^{\nround}= \text{argmin}_{\bm{q} \in [0, 1]^{M \times |\mathcal{B}|}} \eta\langle \bm{q}, -\bm{w}^\nround\rangle + D(\bm{q} || \bm{q}^{\nround-1})\] to the space $\mathcal{Q}$ (See Projection Lemma, Lemma 8.6 of \cite{BartokLecNotes2011}). 
    Having characterized the exact form of the OMD iterates, all that remains is to upper bound the regret of OMD with the regret of Be-the-regularized-leader.
    % that relates $\eta \bm{w}^t$ to $D(\bm{q}^\nround||\tilde{\bm{q}}^\nround)$
    \begin{lemma}[Lemma 9.2 of \cite{BartokLecNotes2011}]
        \label{lem: Be Regularized leader regret}
        Letting $D(\bm{q} || \bm{q}')$ denote the unnormalized KL divergence between $\bm{q}$ and $\bm{q}'$, we have:
        \begin{align*}
            \textsc{Regret}_\mathcal{B} \leq \max_{\bm{q} \in\mathcal{Q}} \mathbb{E}\Big[\eta^{-1} D(\bm{q} || \bm{q}^1) + \sum_{\nround=1}^\Nround \langle \bm{q}^\nround - \tilde{\bm{q}}^{\nround+1}, \bm{w}^\nround \rangle\Big]\,.
        \end{align*}
    \end{lemma} 
     The remainder of the regret analysis closely follows that of Theorem 1 in \cite{OREPS2013}. At a high level, we want to bound the regret of Online Mirror Descent by the regret of the unconstrained Be the
     (Negentropy) Regularized leader, via Lemma~\ref{lem: Be Regularized leader regret} (see Lemma 13 of \cite{LectureNotes2009} for the more general statement and proof of this lemma). 
     We then upper the contribution of the summation term by using the specific definition of the node weight estimators. Similarly, we upper bound the divergence term as a function of the dimension of the space $\mathcal{Q}$.
     
    
    
    To begin, note that our node utility estimators $\widehat{w}_\nitem^\nround(b)$ are unbiased:
    \begin{align}
        \mathbb{E}_{\bm{b} \sim \bm{\pi}^\nround}[\widehat{w}_\nitem^\nround(b)] = \mathbb{E}_{\bm{b} \sim \bm{\pi}^\nround}[\frac{w_\nitem^\nround(b)}{q^{\nround}_\nitem(b)} \textbf{1}_{b = b^{\nround}_\nitem}] = \frac{w_\nitem^\nround(b)}{q^{\nround}_\nitem(b)} \prob_{\bm{b} \sim \bm{\pi}^\nround} (b = b^\nround_\nitem) = \frac{w_\nitem^\nround(b)}{q^{\nround}_\nitem(b)} q^{\nround-1}_\nitem(b) = w_\nitem^\nround(b)\ .
        \label{proof: part1}
    \end{align}
    Now, consider the right hand side of the inequality in  Lemma \ref{lem: Be Regularized leader regret}. As the node utility estimators are unbiased, so we can replace $\bm{w}^\nround$ with $\widehat{\bm{w}}^\nround$. 
    Now, as per Lemma \ref{lem: Be Regularized leader regret}, we can upper bound the expected estimated regret as a function of the unconstrained optimizer $\tilde{\bm{q}}^{\nround+1}$ and the unregularized relative entropy  with respect to the initial state-edge occupancy measure $\bm{q}^1$. Applying the aforementioned lemma to Equation \eqref{proof: part1}, we obtain:
    \begin{align}
        \textsc{Regret}_\mathcal{B} = \max_{\bm{q} \in \mathcal{Q}} \mathbb{E}\left[\sum_{\nround=1}^\Nround \langle \bm{q}^{\nround} - \bm{q}, -\widehat{\bm{w}}^{\nround} \rangle \right] \leq \max_{\bm{q} \in \mathcal{Q}}\mathbb{E}\left[\sum_{\nround=1}^\Nround \langle \bm{q}^{\nround} - \tilde{\bm{q}}^{ \nround+1}, -\widehat{\bm{w}}^{\nround} \rangle + \eta^{-1}D(\bm{q} || \bm{q}^{1}) \right]
    \end{align}
    Applying $\exp(x) \geq 1 + x$ for $x = \exp(\eta \widehat{\bm{w}}^{\nround})$, we obtain $\tilde{\bm{q}}^{ \nround+1} = \bm{q}^\nround \exp(\eta \widehat{\bm{w}}^{\nround}) \geq \bm{q}^{\nround} + \eta \bm{q}^{\nround} \widehat{\bm{w}}^{\nround}$, which yields $\bm{q}^t - \bm{q}^t\exp(\eta\widehat{\bm{w}}^t) \ge  -\eta \bm{q}^t \widehat{\bm{w}}^t$. Plugging this back in:
    \begin{align}
        \textsc{Regret}_\mathcal{B} &\leq \max_{\bm{q} \in \mathcal{Q}} \mathbb{E}\left[\sum_{\nround=1}^\Nround \langle \bm{q}^{\nround} - \bm{q}^{\nround} \exp(\eta \widehat{\bm{w}}^{\nround}), -\widehat{\bm{w}}^{\nround} \rangle + \eta^{-1}D(\bm{q} || \bm{q}^{1}) \right]\\
        &\le  \max_{\bm{q} \in \mathcal{Q}} \mathbb{E}\left[\eta \sum_{\nround=1}^\Nround \sum_{\nitem = 1}^\Nitem \sum_{b \in \mathcal{B}} q^{\nround}_\nitem(b) \widehat{w}^{\nround}_\nitem(b)^2 + \eta^{-1}D(\bm{q} || \bm{q}^{1}) \right] \,.\label{eq: node diff}
    \end{align}
    Note that $\widehat{w}^{\nround}_\nitem(b) = \frac{w_\nitem^\nround(b)}{q^{\nround-1}_{\nitem}(b)} \textbf{1}_{b = b^{\nround}_{\nitem}}$ for all $\nitem \in [\Nitem]$ and $b \in \mathcal{B}$ by definition. Since $w^{\nround}_\nitem(b) \leq 1$ and $\textbf{1}_{b = b^{\nround}_{\nitem}} \leq 1$ we have $\widehat{w}^{\nround}_\nitem(b) \leq \frac{1}{q^{\nround}_\nitem(b)}$ and we continue the above chain of inequalities with:
    \begin{align}
        \textsc{Regret}_\mathcal{B} &\leq \max_{\bm{q} \in \mathcal{Q}} \mathbb{E}\left[\eta \sum_{\nround=1}^\Nround \sum_{\nitem = 1}^\Nitem \sum_{b \in \mathcal{B}} q^{\nround}_{\nitem}(b) \widehat{w}^{\nround}_\nitem(b) \frac{1}{q^{\nround}_{\nitem}(b)}  + \eta^{-1}D(\bm{q} || q^{1}) \right] \label{eq: full info difference appendix}\\
        &= \max_{\bm{q} \in \mathcal{Q}} \mathbb{E}\left[\eta \sum_{\nround=1}^\Nround \sum_{\nitem = 1}^\Nitem \sum_{b \in \mathcal{B}} \widehat{w}^{\nround}_\nitem(b)  + \eta^{-1}D(\bm{q} || \bm{q}^{1}) \right] \, .
    \end{align} 
    
    Recalling that $D(\bm{q} || \bm{q}^1) = \sum_{\nitem \in [\Nitem], b \in \mathcal{B}} q_\nitem(b)\log\frac{ q_\nitem(b)}{q^1_\nitem(b)} - (q_\nitem(b) - q^1_\nitem(b))$, we note that:
    
    \begin{align*}
        D(\bm{q} || \bm{q}^1) &= \sum_{m = 1}^M \sum_{b \in \mathcal{B}} q_m(b)\frac{\log q_m(b)}{\log q^1_m(b)} - q_m(b) + q^1_m(b) \\
        &= \sum_{\nitem=1}^\Nitem \sum_{b \in \mathcal{B}} q_{\nitem}(b)\log q_m(b) - q_m(b)\log q^1_m(b)\,,
    \end{align*} 
    where in the second equality, we used the fact that the elements both $\bm{q}$ and $\bm{q}^1$ all sum to $M$. Selecting $\bm{q}^1_m(\cdot)$ to be the uniform distribution over all $b \in \mathcal{B}$ and using the fact that the entropy of a discrete distribution over $|\mathcal{B}|$ items is $\log |\mathcal{B}|$, we obtain:
    \begin{align*}
        D(\bm{q} || \bm{q}^1) &= -\sum_{\nitem=1}^\Nitem H(\bm{q}_m) + \log |\mathcal{B}|\sum_{\nitem=1}^\Nitem \sum_{b \in \mathcal{B}} q_{\nitem}(b) \\
        &\leq \sum_{\nitem=1}^\Nitem \log |\mathcal{B}| + \log |\mathcal{B}|\sum_{\nitem=1}^\Nitem \sum_{b \in \mathcal{B}} q_{\nitem}(b) = \Theta(M\log|\mathcal{B}|)\,,
    \end{align*}
    where $H(\bm{x}) = -\sum_{x \in \bm{x}} x \log x $ denotes the discrete entropy function.  
    Plugging this back in:
    \begin{align*}
        \textsc{Regret}_\mathcal{B} \leq \mathbb{E}\left[\eta \sum_{\nround=1}^\Nround \sum_{\nitem = 1}^\Nitem \sum_{b \in \mathcal{B}} \widehat{w}^{\nround}_\nitem(b)  + \eta^{-1}\Nitem \log |\mathcal{B}| \right] \leq \eta \sum_{\nround=1}^\Nround \sum_{\nitem=1} \sum_{b \in \mathcal{B}} w^{\nround}_\nitem(b) + \eta^{-1}\Nitem \log |\mathcal{B}| = \eta \Nround \Nitem |\mathcal{B}| + \eta^{-1}\Nitem \log |\mathcal{B}|\,,
    \end{align*}
    where we used unbiasedness of $\widehat{\bm{w}}^{\nround}$. Setting $\eta = \sqrt{\frac{\log |\mathcal{B}|}{|\mathcal{B}|T}}$, we obtain $\textsc{Regret}_\mathcal{B}(\Nround) \leq \Nitem \sqrt{|\mathcal{B}| \Nround \log |\mathcal{B}|}$. 

    
    \textbf{Part 2: Determining Policy $\bm{\pi}$ from Node Probability Measures $\bm{q}$.} 
    Notice that in our regret analysis for both the bandit and full information setting, we do not require explicit knowledge of the policy $\bm{\pi}^t$, so long as it generates the desired node occupancy measure $\bm{q}^t$. In particular, we require a method of converting $\bm{q}^\nround$ to policy $\bm{\pi}^\nround$ which, in turn, is required in order to sample $\bm{b}^\nround$. Recall from Lemma~\ref{lem: QSpace Equivalence} that the mapping from the space of policies $\Pi$ to the space of node weight measures $\mathcal{Q}_\Pi = \mathcal{Q}$ is injective. Thus, for any $\bm{q} \in \mathcal{Q}$, there must exists a $\bm{\pi} \in \Pi$ such that $q(\bm{\pi}) = \bm{q}$. Moreover, the set $\Pi(\bm{q})$ of such $\bm{\pi}$ can be written as the intersection of two polyhedrons, and hence a polyhedron, from which a feasible solution can be computed efficiently (e.g., ellipsoid method), where  $ \Pi(\bm{q})$ is the set of policies $\pi \in [0,1]^{M\times |\mathcal B|\times |\mathcal B|}$ such that 
    \begin{itemize}
        \item $\pi((0, \max \mathcal{B}), b) = q_1(b)$, for any $b \in \mathcal{B}$;
        \item $\pi((0, b), b') = \textbf{1}_{b = b'}$ for any $b, b' < \max \mathcal{B}$;
        \item $q_{m+1}(b') = \sum_{b \in \mathcal{B}} q_m(b) \pi((m, b), b')\}$ for any $b'\in \mathcal B$ and $m \in [M-1]$.
    \end{itemize}



    \textbf{Part 3: Complexity analysis.} One may wonder how to efficiently update the state occupancy measures by computing the minimizer of $\eta\langle \bm{q}, -\widehat{\bm{w}}^\nround\rangle + D(\bm{q} || \bm{q}^{\nround-1})$. The idea is to first solve the unconstrained entropy regularized minimizer with $\tilde{\bm{q}}^{ \nround+1} = \bm{q}^{\nround} \exp(\eta \widehat{\bm{w}}^{\nround})$. We then project this unconstrained minimizer to $\mathcal{Q}$ with:
    \begin{align}
        \bm{q}^{\nround + 1} = \text{argmin}_{\bm{q} \in \mathcal{Q}} D(\bm{q}||\tilde{\bm{q}}^{\nround + 1})
    \end{align}
    Relegating the details to \cite{OREPS2013}, the above constrained optimization problem can be solved as the minimizer of an equivalent unconstrained convex optimization problem with a polynomial (in $\Nitem$ and $|\mathcal{B}|$) number of variables, and therefore, can be computed efficiently. Combining with finding an initial feasible solution to $\Pi(\bm{q})$ as well as the optimization step, we achieve polynomial in $\Nitem, |\mathcal{B}|, \Nround$ total time complexity. For the space complexity, we only need store the values of $\bm{\pi}^\nround$, $\bm{q}^\nround$, and $\widehat{\bm{w}}^\nround$, for a total space complexity of $O(\Nitem |\mathcal{B}|^2)$.   
    
    \textbf{Part 4: Continuous Regret.} To obtain the continuous regret, recall that the discretization error is $O(\frac{\Nitem \Nround}{|\mathcal{B}|})$. As the discretized regret is $O\left(\Nitem \sqrt{|\mathcal{B}| \Nround \log |\mathcal{B}|}\right)$ in the bandit feedback setting, the optimal choice of $|\mathcal{B}|$ is $\Theta(\Nround^{\frac{1}{3}})$, which achieves continuous regret $\textsc{Regret} = O(\Nitem \Nround^{\frac{2}{3}} \sqrt{\log \Nround})$.

\end{proof}

\subsubsection{Proof of Corollary \ref{cor}}
\label{sec: Proof of cor}

We can straightforwardly extend Algorithm~\ref{alg: OMD} to the full information setting. To do this, we note that we can improve Equation~\eqref{eq: full info difference appendix} by instead replacing $\widehat{\bm{w}}^{\nround}$ with $\bm{w}^{\nround}$ in Equation~\eqref{eq: node diff} to obtain:
\begin{align*}
    \sum_{\nround=1}^\Nround \sum_{\nitem=1}^\Nitem \sum_{b \in \mathcal{B}} q^{\nround}_\nitem(b) \widehat{w}^{\nround}_\nitem(b)^2 = \sum_{\nround=1}^\Nround \sum_{\nitem=1}^\Nitem \sum_{b \in \mathcal{B}} q^{\nround}_\nitem(b) w^{\nround}_\nitem(b)^2 \leq \sum_{\nround=1}^\Nround \sum_{\nitem=1}^\Nitem \sum_{b \in \mathcal{B}} q^{\nround}_\nitem(b) = \sum_{\nround=1}^\Nround \sum_{\nitem=1}^\Nitem 1 = \Nround \Nitem\,.
\end{align*}
Setting $\eta = \sqrt{\frac{ \log |\mathcal{B}|}{T}}$, we obtain in the full information setting $\textsc{Regret}_\mathcal{B} = O(\Nitem \sqrt{\Nround \log |\mathcal{B}|})$. We can also compute the optimal choice of $|\mathcal{B}|$ to obtain optimal continuous regret. Using the optimal choice of $|\mathcal{B}|$ being $\Theta(\sqrt{T})$, we achieve continuous regret of $\textsc{Regret} = O(\Nitem \sqrt{\Nround \log \Nround})$. Note that due to the complexity of the optimization sub-routine in the projection step of OMD, for the full information setting, it is preferable to use Algorithm~\ref{alg: Decoupled Exponential Weights} instead.










 

\section{Regret Lower Bounds}

In this section, we prove our stated regret lower bounds for both the full information and bandit feedback settings.

\subsection{Proof of Theorem \ref{thm:lower}: Regret Lower Bound (Full Information)}

To construct our lower bounds, we construct a stochastic adversary whose distribution across their bids makes it difficult for the bidder to determine their optimal bid, and thus, occurs $\Omega(M\sqrt{T})$ regret while doing so. We define $\bm{b}'_- = (0,\ldots,0,c,\ldots,c)$, where there are $k$ and $\Nitem - k$ values of 0 and $c$ each. We additionally define $\bm{b}"_- = (c,\ldots,c)$ as the $\Nitem$-vector of bids at $c$. Restricting the adversary's bid vectors to be in $\{\bm{b}'_-, \bm{b}"_-\}$, we construct two adversary bid vector distributions $F$ and $G$ over $\{\bm{b}'_-, \bm{b}"_-\}^\Nround$ such that   under $F$, we have $\prob(\bm{b}_-^\nround = \bm{b}'_-) = \frac{1}{2} + \delta$  and $\prob(\bm{b}_-^\nround = \bm{b}"_-) = \frac{1}{2} - \delta$ 
 and under $G$, we have $\prob(\bm{b}_-^\nround = \bm{b}'_-) = \frac{1}{2} - \delta$ and $\prob(\bm{b}_-^\nround = \bm{b}"_-) = \frac{1}{2} + \delta$  for some $\delta \in [0, \frac{1}{2}]$ to be optimized over later. 
 
 
 Assume that $\bm{v} = (1,\ldots,1)$, all tiebreaks are won for simplicity, and the competitors' bids over time are independent. Then, for certain choices of $c$ and $k$ (which we show below), the expected utility maximizing bid vector under $\{\bm{b}_-^\nround\}_{\nround \in [\Nround]} \sim F$ is $(0,\ldots,0)$ and under $\{\bm{b}_-^\nround\}_{\nround \in [\Nround]} \sim G$ is $(c,\ldots,c)$. 
 In particular, we can compute precisely the expected value of bidding $\bm{b}^\nround = \bm{b}$ for all $\nround \in [\Nround]$ under both $F$ and $G$. Note that as adversary bid values only take values in $\{0, c\}$ and bidder $n$ wins all tiebreaks, then the bidder only need consider bid vectors consisting only of all $0$ or $c$. Letting $\nitem$ denote the number of bids in $\bm{b}$ equal to $c$, we have:
    \begin{align*}
        \mathbb{E}_F\left[\sum_{\nround=1}^\Nround \mu_n^\nround(\bm{b})\right] = \Nround \left[ (\frac{1}{2} + \delta)\left((1 - c)m + \max(0, M - k - m)\right)  + (\frac{1}{2} - \delta)(1 - c)m   \right]\,.
    \end{align*}
    Where $\mathbb{E}_F$ denotes the expectation with respect to the adversary bids drawn from $F$, namely $\{\bm{b}_-^\nround\}_{\nround \in [\Nround]} \sim F$ (and similarly for $\mathbb{E}_G$ below). In particular, we have that with probability $\frac{1}{2} + \delta$, the adversary will select bid $\bm{b}'_-$. We are then guaranteed to win $m$ units at a price of $c$, for a utility of $1 - c$ per unit. If $\nitem < k$, then $M - k - m$ of the items were won with price 0, for a utility of 1 per unit. With probability $\frac{1}{2}-\delta$, all of the adversary bids are $c$, and we obtain $\nitem$ units at a cost of $c$ each, which corresponds to utility $1 - c$. Similarly, we have: 
    \begin{align*}
        \mathbb{E}_G\left[\sum_{\nround=1}^\Nround \mu_n^\nround(\bm{b})\right] = \Nround \left[ (\frac{1}{2} - \delta)\left((1 - c)m + \max(0, M - k - m)\right)  + (\frac{1}{2} + \delta)(1 - c)m   \right]
    \end{align*}
    For the case $m + k \leq M$, we have that $(1-c)m + \max(0, M - k - m) = M - k - mc$, and the above two equations simplify to:
    \begin{align*}
        \mathbb{E}_F[\sum_{\nround=1}^\Nround \mu_n^\nround(\bm{b})] = T\left[ (\frac{1}{2} + \delta)(M - k) + m(\frac{1}{2} - \delta - c) \right]\,;\\\mathbb{E}_G[\sum_{\nround=1}^\Nround \mu_n^\nround(\bm{b})] = T\left[ (\frac{1}{2} - \delta)(M - k) + m(\frac{1}{2} + \delta - c) \right]\,.
    \end{align*}
    In the case where $m + k \geq M$, we have that $(1-c)m + \max(0, M - k - m) = m - mc$ and we obtain:
    \begin{align*}
        \mathbb{E}_F\left[\sum_{\nround=1}^\Nround \mu_n^\nround(\bm{b})\right] = \mathbb{E}_G\left[\sum_{\nround=1}^\Nround \mu_n^\nround(\bm{b})\right] = T(1 - c)m\,.
    \end{align*}
    Note that in either case, in the case where we sample $\{\bm{b}^\nround_-\}_{\nround \in [\Nround]}$ according to the mixture $\frac{F+G}{2}$, this corresponds to the case where $\delta = 0$, i.e., the probability of observing either $\bm{b}'_-$ or $\bm{b}"_-$ is equal. We have for all $\bm{b}$:
    \begin{align*}
        \mathbb{E}_{(F+G)/2}[\sum_{\nround=1}^\Nround \mu_n^\nround(\bm{b})] = \frac{1}{2}((1 - c)m + \max(0, M-k-m)) + \frac{1}{2}(1 -c)m  \geq (1 - c)m
    \end{align*}
    Note that under $F$, the optimal occurs at the all 0's vector for $c > \frac{1}{2} - \delta$ and $(\frac{1}{2} + \delta)(M - k) > (1-c)m = 0$. Similarly, the optimal occurs at the all $c$'s vector for $c > \frac{1}{2} - \delta$ and $(\frac{1}{2} - \delta)(M - k) > (1 - c)M$. These obtain utilities of $(\frac{1}{2}+\delta)(M-k)$ and $M - Mc$ respectively. One choice of $c$ and $k$ is $\frac{2}{3}$ and $\frac{M}{3}$, with $0 < \delta < \frac{1}{6}$. Looking at the regret incurred each step of the algorithm by selecting any action $\bm{b}$, we have:
    \begin{align*}
        &\max_{\bm{b}'} \left(\mathbb{E}_F[\sum_{\nround=1}^\Nround \mu_n^\nround(\bm{b}') - \mu_n^\nround(\bm{b})] \right) + \max_{\bm{b}'} \left(\mathbb{E}_G[\sum_{\nround=1}^\Nround \mu_n^\nround(\bm{b}') - \mu_n^\nround(\bm{b})] \right) \\
        &\geq \max_{\bm{b}'} \left(\mathbb{E}_F[\sum_{\nround=1}^\Nround  \mu_n^\nround(\bm{b}')]\right) + \max_{\bm{b}'} \left(\mathbb{E}_G[\sum_{\nround=1}^\Nround  \mu_n^\nround(\bm{b}')]\right) - 2\max_{\bm{b}'} \mathbb{E}_{(F+G)/2}\left(\mathbb{E}_F[\sum_{\nround=1}^\Nround  \mu_n^\nround(\bm{b}')]\right)\\
        &\geq \mathbb{E}_F[\sum_{\nround=1}^\Nround  \mu_n^\nround((0,\ldots,0))] + \mathbb{E}_G[\sum_{\nround=1}^\Nround  \mu_n^\nround((c,\ldots,c))] - 2\max_{\bm{b}'} \mathbb{E}_{(F+G)/2}\left(\mathbb{E}_F[\sum_{\nround=1}^\Nround  \mu_n^\nround(\bm{b}')]\right)\\
        &= (\frac{1}{2}+\delta)(M-k) + \left(M - Mc\right) - 2\max_{\bm{b}'} \mathbb{E}_{(F+G)/2}\left(\mathbb{E}_F[\sum_{\nround=1}^\Nround  \mu_n^\nround(\bm{b}')]\right)\\
        &\geq (\frac{1}{2}+\delta)(M-k) + \left(M - Mc\right) - 2(1-c)M\,.
    \end{align*}
    Now, for example, we can set $k = \frac{M}{3}$ and $c = \frac{2}{3}$ to obtain a per step incurred regret of $\Theta(\Nitem \delta)$.     
    We invoke the useful lemma relating the regret under $(F+G)/2$ to the Kullback-Leilber divergence:
    \begin{lemma}[\cite{NonparametricEstimation2008} Theorem 2.2.]
        We have for any two discrete distributions $F$ and $G$:
        \begin{align}
            \mathbb{E}_{(F+G)/2} \left[\textsc{\emph{Regret}}_\mathcal{B}(T)\right] = \Omega\left( \frac{\Delta}{2} \exp(-D_{\emph{KL}(F || G)}) \right)\,,
        \end{align}
        where $\Delta$ denotes the sum of the total regret incurred under $F$ or $G$.
    \end{lemma} 
    When $F$ and $G$ are independent Bernoulli processes with parameters $\frac{1}{2}+\delta$ and $\frac{1}{2}-\delta$ respectively, then $D_{\text{KL}}(F || G) \leq cT\delta^2$ for some constant $c$. Using $\Delta \in \Theta(MT\delta)$, we have that the previous lemma implies:
    \begin{align}
        \textsc{Regret}_{\mathcal{B}} \in \Omega \left(\Nitem \sqrt{\Nround}\right)
    \end{align}                             
    where $\delta$ is chosen to be $\Omega(\frac{1}{\sqrt{T}})$.

\subsection{Proof of Theorem \ref{thm:lower_bound_bandit}: Regret Lower Bound (Bandit Feedback)}\label{sec:proof:lower:bandit}

    
    %The primary difficulty in establishing a regret lower bound is cross-learning between units, as mentioned above. However, we construct an instance in which cross-learning cannot help \textit{too} much, even in the stochastic highest-other-bids setting. % \rigel{Set $\gamma_m = \frac{\min(1/|\mathcal{B}|, 1/M)}{32}$ and just say that this choice of $\gamma_m$ satisfies the constraints}
    
  {\color{black}To construct the regret lower bound, we begin by establishing a base hypothesis concerning the distribution of the highest competing bids. Specifically, let \(H_{m}\) represent the marginal cumulative distribution function (CDF) of the \((M-m+1)\)'st highest competing bid, denoted by \(b_{-m}\):
    \[H_m(b) = \min(1,\frac{c_m}{1 - b}) \quad \text{for} \quad c_m = \frac{1}{2} - \frac{m}{4M}\] 
    and $b \in \mathcal{B}$. We note that larger $m$ implies smaller $c_m$, which implies a smaller CDF for the same value of $b$; i.e. $H_m(b) \geq H_{m+1}(b)$  for all $b \in \mathcal{B}$. Thus, this satisfies the stochastic dominance requirement on the highest other bids $b_{-1}\leq \ldots \leq b_{-M}$, and there exists a joint distribution over highest other bids such that their marginal distributions are precisely $H_m$ for all $m \in [M]$. 
        
    Assuming that the bidder's valuations are $\bm{v} = [1,\ldots,1]$ and they given tie-break priority, the expected utility for bidding $b$ for unit $m$ is equal to
    \[(1-b)\prob(b \geq b_{-m}) = (1-b)H_m(b) = c_m,\qquad b \in [0, 1-c_m]\,.\] That is, the expected utility from the $m$'th unit is precisely $c_m$ for any bid $b\in [0, 1-c_m]$. Here, the expected utility for any bid $b > 1 - c_m$ will be strictly smaller than $c_m$.

    Now, we construct a partitioning over the bid discretization space.  Assuming an even discretization $\mathcal{B} = \{\frac{i}{|\mathcal{B}|}\}_{i \in \mathcal{B}}$ with $|\mathcal{B}| = M^{\frac{1}{3}}T^{\frac{1}{3}}$, we partition $\mathcal{B}$ into $M$ disjoint buckets: 
    \[\mathcal{B}_m = \mathcal{B} \cap (\frac{1}{2} - \frac{m}{4M}, \frac{1}{2} - \frac{m-1}{4M}]\,.\]
    Here, each $\mathcal{B}_m$ is of size $\frac{|\mathcal{B}|}{4M}$, and notice that $\mathcal{B}_m$ lies entirely to the right of $\mathcal{B}_{m+1}$; i.e., $b > b'$ for any $b \in \mathcal{B}_m$ and  $b' \in \mathcal{B}_{m+1}$.  See Figure \ref{fig:partitions} for an illustration. We note that we are not restricting bids for the $m$'th unit to be within $\mathcal{B}_m$. We only construct this partition in order to construct a family of hypotheses which the agent will have to differentiate between. 

Now, we construct the family of hypotheses \(\mathcal{H} = \{\times_{m=1}^M \mathcal{H}_m^{j_m}, j_m \in [|\mathcal{B}_m|], m\in [M]\}\) in a similar manner as \cite{DemandCurve2003}, where each hypothesis $(\mathcal{H}_m^{j_m})_{m\in [M]}$ can be described by \(M\) indices, \(j_m\), \(m\in [M]\). Here, index \(j_m\in [|\mathcal{B}_m|]\) is associated with \emph{the unit-\(m\) hypothesis}.
  
    
    In particular, for unit  $m$, we construct $|\mathcal{B}_m|$ possible hypotheses (i.e., $\mathcal{H}_m^{j_m}$, $j_m\in [|\mathcal{B}_m|]$), each indexed by $j_m$ where for hypothesis $\mathcal{H}^{j_m}_m$, 
    the utility of the bidder for unit $m$ from submitting bid $b^{j_m}_m$---defined as the ${j_m}$'th largest value in $\mathcal{B}_m$---is marginally larger than the remaining bid values in $\mathcal{B}_m$ by perturbing the base distribution $H_m(b^{j_m}_m)$ by $\gamma_m > 0$. More formally, define marginal CDF's $\{H_m^{j_m}\}_{j_m \in [|\mathcal{B}_m|]}$ for each $m \in [M]$, such that $H_m^{j_m}(b) = H_m(b)$ for all $b \in \mathcal{B}$, except at $b^j_m \in \mathcal{B}_m$, and $H_m^{j_m}(b_m^{j_m}) = H_m(b_m^{j_m}) + \gamma_m$. \footnote{The agent does not need to differentiate between every hypothesis in $\mathcal{H} = \{\times_{m=1}^M \mathcal{H}^{j_m}_m\}_{j_m \in |\mathcal{B}_m| \forall m}$, which is exponentially large. As the utility function for bidding $\bm{b}$ can be decomposed into the sum of utilities of each of the $M$ units, the agent only needs to differentiate between each of the $\mathcal{H}^{j}_m$.}
    Here, we require $\gamma_m$ to satisfy the following constraint: $$\gamma_m \leq \min\left(H_m(b_m^{j_m} + \frac{1}{|\mathcal{B}|}) - H_m(b_m^{j_m}), H_m(b_m^{j_m}) - H_{m+1}(b_m^{j_m})\right)\,.$$ The first term $H_m(b_m^{j_m} + \frac{1}{|\mathcal{B}|}) - H_m(b_m^{j_m})$ corresponds to the constraint that the CDF is non-decreasing. The second term $H_m(b_m^{j_m}) - H_{m+1}(b_m^{j_m})$ corresponds to the highest-other-bid monotonicity constraint. Using our precise definitions of $H_m$, we see that: \footnote{We also note another constraint requires that $H_m(b_m^j + \frac{1}{|\mathcal{B}|})$ and $ H_m(b_m^j)$ needs to be unique, specifically, that they are not both equal to 1. Since we defined the set $\mathcal{B}_m$ to be within $(\frac{1}{2} - \frac{m}{4M}, \frac{1}{2} - \frac{m-1}{4M}]$, the largest value in $\mathcal{B}_m$ is $\frac{1}{2} - \frac{m-1}{4M}$. Plugging this into $H_m^j$, we see that $H_m(\max(\mathcal{B}_m)) = \min(1, \frac{\frac{1}{2} - \frac{m}{4M}}{1 - \max(\mathcal{B}_m)} = \min(1, \frac{\frac{1}{2} - \frac{m}{4M}}{\frac{1}{2} + \frac{m-1}{4M}}) < 1$.}
    \begin{align*}H_m(b_m^{j_m} + \frac{1}{|\mathcal{B}|}) - H_m(b_m^{j_m})&= \frac{c_m}{|\mathcal{B}|(1 - b_m^{j_m})(1-b_m^{j_m} - |\mathcal{B}|^{-1})} \\
   & =
   \frac{\frac{1}{2} - \frac{m}{4M}}{|\mathcal{B}|(1 - b_m^{j_m})(1-b_m^{j_m} - |\mathcal{B}|^{-1})}
   \geq \frac{\frac{1}{2} - \frac{m}{4M}}{|\mathcal{B}|(  \frac{1}{2} + \frac{m}{4M})(\frac{1}{2} + \frac{m}{4M} - |\mathcal{B}|^{-1})}\,.
    \end{align*}
    This function is decreasing for any $0 \leq m \leq M$, as the term $\frac{m}{M}$ appears negatively in the numerator and positively in the denominator. Thus, we have
    \[\frac{\frac{1}{2} - \frac{m}{4M}}{|\mathcal{B}|(  \frac{1}{2} + \frac{m}{4M})(\frac{1}{2} + \frac{m}{4M} - |\mathcal{B}|^{-1})} \ge  \frac{\frac{1}{2} - \frac{1}{4}}{|\mathcal{B}|(  \frac{1}{2} + \frac{1}{4})(\frac{1}{2} + \frac{1}{4} - |\mathcal{B}|^{-1})} \ge 4/|\mathcal{B}| \]
    as desired.
Further, 
    $$H_m(b_m^j) - H_{m+1}(b_m^{j_m}) = \frac{c_{m} - c_{m+1}}{1-b_m^{j_m}}  =
    \frac{\frac{1}{4M}}{ \frac{1}{2} + \frac{m}{4M}}
    \geq \frac{\frac{1}{4M}}{ \frac{1}{2} + \frac{1}{4}} \ge \frac{1}{3M}\,.$$
    Combining these, we see that $\gamma_m$ is $O\left(\min(\frac{1}{|\mathcal{B}|}, \frac{1}{M})\right)$. We then see that the expected utility of bidding $b_m^{j_m} $ for unit $m$ is $c_m + \gamma_m(1-b_m^{j_m}) = c_m + O\left(\min(\frac{1}{|\mathcal{B}|}, \frac{1}{M})\right)$  as compared to the expected utility of bidding $b \neq b_m^j$ for unit $m$, which is precisely just $c_m$. This sub-optimality plays a direct role in the regret accumulated by item $m$, which is precisely the number of times that the optimal $b_m^{j_m}$ was \textit{not} selected times the difference between the reward of the optimal and sub-optimal arms, which is $O(\gamma_m)$.
    We will select
    \[\gamma_m = \gamma = \frac{1}{48\max(|\mathcal{B}|, M)}\] for all $m$. Now, we rewrite the regret lower bound as a function of the number of times that the optimal bid $b_m^{j_m}$ was not selected for for the $m$'th bid. Let
    \[
    \mathcal{S}(m, t) = \{m' \in [M]: b_{m'}^t \in \mathcal{B}_m\} \quad \text{and} \quad T_m = \sum_{t=1}^T |\mathcal{S}(m, t)|
    \] 
    where $\mathcal{S}(m, t)$ denotes the set of bids at round $t$ that took on value in $\mathcal{B}_m$ for any unit $m'\in [M]$ (including unit $m$), and $T_m$ denotes the total number of times across all rounds that any bid was selected within $\mathcal{B}_m$. Assuming that all bids fall within one of the $M$ buckets, as bidding outside of these buckets is strictly utility sub-optimal and also cannot provide any information on distinguishing between the unit hypotheses, we have:
     \begin{align*}
        \textsc{Regret}_{\mathcal{B}} &= \sum_{t=1}^T \sum_{m=1}^M 1_{b_m^t \neq b_m^{j_m}} \gamma(1 - b_m^{j_m})\\
        &\overset{(a)}{\geq} \frac{\gamma}{2} \sum_{t=1}^T \sum_{m=1}^M 1_{b_m^t \neq b_m^{j_m}}\\
        &\overset{(b)}{=} \frac{\gamma}{2} \sum_{t=1}^T \sum_{m=1}^M \sum_{i \in \mathcal{S}(m, t)} 1_{b_{i}^t \neq b_i^{j_i}}\\
        &\overset{(c)}{=} \frac{\gamma}{4} \sum_{m=1}^M \left[ \sum_{t=1}^T \sum_{i \in \mathcal{S}(m, t)} 1_{b_{i}^t \neq b_i^{j_i}} + \sum_{t=1}^T \sum_{i \in \mathcal{S}(m, t)} 1_{b_{i}^t \neq b_i^{j_i}} \right]\,.\\
        %&\overset{(d)}{=}\frac{\gamma}{4} \sum_{m=1}^M \left[ \sum_{t=1}^T \sum_{i\in [M]} 1_{b_{i}^t \neq b_i^{j_i}} 1_{b_{i}^t  \in \mathcal{B}_m} +\sum_{t=1}^T \sum_{i \in \mathcal{S}(m, t)} 1_{b_{i}^t \neq b_i^{j_i}} 
       % \right] 
       &{=}\frac{\gamma}{4} \sum_{m=1}^M \left[ \sum_{t=1}^T \sum_{i \in \mathcal{S}(m, t)} 1_{b_{i}^t \neq b_i^{j_i}} + \sum_{t=1}^T \sum_{i\in S(m, t)}(1- 1_{b_i^t = b_i^{j_i}}) \right]\\
       &{=}\frac{\gamma}{4} \sum_{m=1}^M \left[ \sum_{t=1}^T \sum_{i \in \mathcal{S}(m, t)} 1_{b_{i}^t \neq b_i^{j_i}} + \sum_{t=1}^T|S(m,t)|- \sum_{t=1}^T \sum_{i\in S(m,t)} 1_{b_i^t = b_i^{j_i}} \right]\\
        &\overset{(d)}{=}\frac{\gamma}{4} \sum_{m=1}^M \left[ \sum_{t=1}^T \sum_{i \in \mathcal{S}(m, t)} 1_{b_{i}^t \neq b_i^{j_i}} + \sum_{t=1}^T |\mathcal{S}(m, t)| - \sum_{t=1}^T 1_{b_m^t = b_m^{j_m}} \right]\,.
    \end{align*}
Here, the inequality (a) holds because  $b_m^{j_m}< 1/2$, and the  equality (b) holds because for any  $t$, $m,m'\in [M]$,  and $m\ne m'$, we have $S(m, t)\cap S(m', t)=\emptyset$.  The   equality (c) is a simple algebraic manipulation. The   equality (d) uses the fact that  any time a bid for item $i \neq m$ takes value in $\mathcal{B}_m$ (see the definition of $S(m, t)$), it cannot possibly be equal to $b_{i}^{j_i} \in \mathcal{B}_i$ since $\mathcal{B}_i$ and $\mathcal{B}_m$ are disjoint.
We then have 
    \begin{align}
        \textsc{Regret}_{\mathcal{B}}
        &\overset{(e)}{\geq} \frac{\gamma}{4} \sum_{m=1}^M \left[ \sum_{t=1}^T \sum_{i \in \mathcal{S}(m, t)} 1_{b_{i}^t \neq b_i^{j_i}} + \max(0, T_m - T) \right] %\label{eq: tm to t}
        \\
        &\overset{(f)}{\geq} \frac{\gamma}{4} \sum_{m=1}^M \left[ \sum_{t=1}^T \sum_{i \in \mathcal{S}(m, t)} 1_{b_{i}^t \neq b_m^{j_m}} + \max(0, T_m - T) \right] %\label{eq: tm to t 2}
        \\
        &\overset{(g)}{\geq} \frac{\gamma}{4} \sum_{m=1}^M \left[ \max(0, T_m - c\gamma T_m^{\frac{3}{2}}\sqrt{\frac{M}{|\mathcal{B}|}}) + \max(0, T_m - T) \right] 
        %\label{eq: tm to t 3}
    \end{align}
   %Equation~\ref{eq: tm to t} uses the fact that any time a bid for item $i \neq m$ takes value in $\mathcal{B}_m$, it cannot possibly be equal to $b_{i}^{j_i} \in \mathcal{B}_i$ since $\mathcal{B}_i$ and $\mathcal{B}_m$ are disjoint. 
   Inequality (e) holds since the maximum number of times that the $m$'th bid is equal to its optimal is at most $T$---i.e. $\sum_{t=1}^T 1_{b_m^t = b_m^{j_m}} \leq T$. %Equation~\ref{eq: tm to t 2} 
   Inequality (f)
   follows as for any $i \neq m, i \in \mathcal{S}(m, t)$, we have that $1_{b_i^t \neq b_i^{j_i}} = 1 \geq 1_{b_i^t \neq b_m^{j_m}}$ as $b_i^t \in \mathcal{B}_m$ and $b_i^{j_i} \notin \mathcal{B}_m$ for $i \neq m$. 
    To obtain inequality (g), we notice that the term $\sum_{t=1}^T \sum_{i \in \mathcal{S}(m, t)} 1_{b_{i}^t \neq b_m^{j_m}}$ is precisely the number of times that the optimal price $b_m^{j_m}$ was \textit{not} selected out of $\sum_{t=1}^T \sum_{i \in \mathcal{S}(m, t)} 1 = T_m$ times. From Theorem 4.3 and Lemma 4.4 of \cite{DemandCurve2003}, the number of times that the optimal action (price in their context and bid in our context) \textit{was selected} (out of $K$ possible actions) over the course of $T_m$ draws is upper bounded by $c\epsilon T_m^{\frac{3}{2}} K^{-\frac{1}{2}}$ for some absolute constant $c \in (2/3,1)$ (for example, $c = \frac{2\sqrt{2}}{3}$ as in \cite{DemandCurve2003}) and perturbation of size $\epsilon$ (i.e, the cost of not choosing the correct hypothesis). Plugging in $K = |\mathcal{B}_m| = \frac{|\mathcal{B}|}{M}$ and $\epsilon = \gamma_m = \gamma$, we obtain inequality (g).

    In the paradigm with large $T$ and small $M$, more specifically with $T \geq M^2 \to |\mathcal{B}| = M^{\frac{1}{3}}T^{\frac{1}{3}} \geq M$, we have $\gamma = \frac{1}{32\max(|\mathcal{B}|, M)} = \Theta(\frac{1}{|\mathcal{B}|}) = \Theta(M^{-\frac{1}{3}}T^{-\frac{1}{3}})$. Plugging this in, we obtain:
    \begin{align}
        \textsc{Regret}_{\mathcal{B}} \geq \frac{M^{-\frac{1}{3}}T^{-\frac{1}{3}}}{4} \sum_{m=1}^M  T_m\left[ \max(0, 1 - c\sqrt{\frac{T_m}{T}}) + \max(0, T_m - T) \right]\,.\label{eq: tm to t 4}
    \end{align}
    Since the agent seeks to minimize regret, they take the minimum over $\bm{T} = (T_1,\ldots,T_M)$, subject to $MT = \sum_{m=1}^M T_m \in \mathbb{N}^M$ for $T_m \in \mathbb{N}$.
    \begin{align*}
        \textsc{Regret}_{\mathcal{B}} \geq \frac{M^{-\frac{1}{3}}T^{-\frac{1}{3}}}{4} \sum_{m=1}^M  T_m\left[ \max(0, 1 - c\sqrt{\frac{T_m}{T}}) + \max(0, T_m - T) \right]  \quad \text{s.t.} \quad \sum_{m=1}^M T_m = MT
    \end{align*}
    %{\color{red} There is always a feasible primal solution. So, the KKT condition holds. We faced a similar problem here \url{https://arxiv.org/abs/1905.01526} in this paper and we were able to solve this using the KKT condition. That problem seems more complex than what we have here. In any case, we cannot say we get this from a solver, we need to show what we are proposing in indeed an optimal solution.}

\begin{lemma} \label{lem:optimization}
Consider the following optimization problem for any $c\in (0, 1)$: 
\[\min_{\{T_m\}_{m\in [M]}, T_m \ge 0}\sum_{m=1}^M  T_m\left[ \max(0, 1 - c\sqrt{\frac{T_m}{T}}) + \max(0, T_m - T) \right]  \quad \text{s.t.} \quad \sum_{m=1}^M T_m = MT\,.\]
where $T_m\in \in \mathbb{Z} $ are integers. 
Then, the optimal solution happens at $T_m= T$ for any $m\in [M]$.
\end{lemma}

The proof of the theorem is completed by applying Lemma  \ref{lem:optimization}. Plugging in $T_m = T$ into Equation~\ref{eq: tm to t 4}, we obtain a regret lower bound of $\textsc{Regret}_{\mathcal{B}} \geq \frac{1-c}{4} M^{\frac{2}{3}}T^{\frac{2}{3}} = \Omega(M^{\frac{2}{3}}T^{\frac{2}{3}})$.


$\blacksquare$ 


    \begin{proof}{Proof of Lemma \ref{lem:optimization}}
    To show that the optimal solution is precisely $\bm{T} = (T,\ldots,T)$, we minimize the objective function over the set of $T_m \in \mathbb{R}^+$ subject to $\sum_{m=1}^M T_m \geq MT$, which is subsumes the original equality constraint $\sum_{m=1}^M T_m = MT$ for integral $T_m \in \mathbb{Z}$. We show that $\bm{T} = (T,\ldots,T)$ is a solution to this relaxed problem, and since this satisfies the inequality and integrality constraints, it must be optimal for the original problem. We begin by finding first order conditions for the objective function: 
    \begin{align*}
        R(\bm{T}) \doteq \sum_{m=1}^M  \left[T_m \max(0, 1 - c\sqrt{\frac{T_m}{T}}) + \max(0, T_m - T) \right]\,.
    \end{align*}
    We consider the following cases:
    
    \begin{enumerate}
        \item If $1 \leq \frac{T_m}{T} \leq \frac{1}{c^2}$, the partial derivative of $R(\bm{T})$ with respect to $T_m= T(\frac{4}{3c})^2$  is zero; that is,  
        we have $0 = \delta_{T_m} R(\bm{T}) = 2 - \frac{3}{2}c\sqrt{\frac{T_m}{T}} \to T_m = T(\frac{4}{3c})^2$.
        However, this does not imply that  $T_m = T(\frac{4}{3c})^2$ is a minimizer as 
     it violates the second order optimality conditions. In particular,  for any value of $T_m > 0$, we have 
        \begin{align*}
            \delta_{T_m^2} R(\bm{T}) = -\frac{3}{4}c\sqrt{\frac{1}{T_mT}} < 0\,.
        \end{align*}
        Given that the second derivative is negative and the first derivative is positive for \( T_m < T \left( \frac{4}{3c} \right)^2 \) and negative for \( T_m > T \left( \frac{4}{3c} \right)^2 \), we only need to examine the boundary points \( T \) and \( \frac{T}{c^2} \). 

        \item If $\frac{T_m}{T} \leq 1 \leq \frac{1}{c^2}$, we have $0 = \delta_{T_m} R(\bm{T}) = 1$. This derivative is always positive. We then only need to check for the minimum boundary case, which is $T_m = 0$ as the derivative is positive.
        \item If $1 \leq \frac{1}{c^2} \leq \frac{T_m}{T}$, we have $0 = \delta_{T_m} R(\bm{T}) = 1 - \frac{3}{2}c\sqrt{\frac{T_m}{T}} \to T_m = T(\frac{2}{3c})^2$.  However, this does not imply that  $T_m = T(\frac{2}{3c})^2$ is a minimizer as 
     it violates the second order optimality conditions. In particular,  for any value of $T_m > 0$, we have   
        \begin{align*}
            \delta_{T_m^2} R(\bm{T}) = -\frac{3}{4}c\sqrt{\frac{1}{T_mT}} < 0
        \end{align*}
        The first derivative is positive when $T_m < T(\frac{2}{3c})^2$ and negative when $T_m > T(\frac{2}{3c})^2$. This implies that we only need to check $T_m$ at the two boundary points, which are $T_m = \frac{T}{c^2}$ and $T_m = \infty$ (which is clearly sub-optimal). 
    \end{enumerate}
    In summary, we only need to check for the cases where $T_m \in \{0, T, \frac{T}{c^2}\}$. We check the value of the $m$'th summand for each of these cases:
    \begin{enumerate}
        \item $T_m = 0$: We have $T_m \max(0, 1 - c\sqrt{\frac{T_m}{T}}) + \max(0, T_m - T) = 0$.
        \item $T_m = T$: We have $T_m \max(0, 1 - c\sqrt{\frac{T_m}{T}}) + \max(0, T_m - T) = (1 - c)T$.
        \item $T_m = \frac{T}{c^2}$: We have $T_m \max(0, 1 - c\sqrt{\frac{T_m}{T}}) + \max(0, T_m - T) = \frac{T}{c^2} - T$.
    \end{enumerate}
   Let $x,y,z$ denote the number of $T_m$ equal to $0, T, \frac{T}{c^2}$ respectively. That is, $x =|\{m \in [M]: T_m = 0\}|$, $y =|\{m\in [M]: T_m = 0\}|$, $z =|\{m\in [M]: T_m = T/c^2\}|$.
    Then, we have that $x + y + z = M$ and $yT + z\frac{T}{c^2} \geq MT$. Hence, we can rewrite $R(\bm{T})$ as follows:
    \begin{align*}
        R(\bm{T}) &= (1-c)Ty + (\frac{1}{c^2} - 1)Tz\,.
    \end{align*}
    We minimize over the set of $(x, y, z)$, yielding the following optimization problem:
    \begin{align*}
        \min_{x, y, z} (1-c)Ty + (\frac{1}{c^2} - 1)Tz \quad \text{s.t} \quad x + y + z = M, \quad x, y, z \geq 0, \quad Ty + \frac{Tz}{c^2} \geq MT\,.
    \end{align*}
    As $x$ does not appear in the objective function, it is effectively a slack variable, and we can rewrite this optimization problem over $(x, y, z)$ as one over $(y, z)$ only:
    \begin{align*}
        \min_{y, z} (1-c)Ty + (\frac{1}{c^2} - 1)Tz \quad \text{s.t} \quad y + z \leq M, \quad y, z \geq 0, \quad Ty + \frac{Tz}{c^2} \geq MT\,,
    \end{align*}
    where in the above optimization, we ignore integrality of $y, z$. If we can show that $(y, z) = (M, 0)$  is the optimal solution to the above optimization problem, then we are finished.  The constraints are linear in $y$ and $z$ and form a triangle with vertices at $(y, z) \in \{(M,0), (0, c^2M), (0, M)\}$. We note that the objective function is linear, thus all it remains to do is to compare the objective function values at each of the vertices. The objective function values corresponding to $(y, z) \in \{(M,0), (0, c^2M), (0, M)\}$ are $(1-c)MT, (1-c^2)MT, (\frac{1}{c}-1)MT$ respectively. Thus, for any $c \in (0, 1)$, the optimal solution is $(M, 0)$ as desired, showing that $\bm{T} = (T,\ldots,T)$ was optimal in the original equality constrained, integer constrained optimization problem.
\end{proof}}


\section{Additional Experiments}
\label{sec: additional experiments}

In this section, we run several additional experiments, including a comparison of the decoupled exponential weights algorithms (Algorithms~\ref{alg: Decoupled Exponential Weights} and \ref{alg: Decoupled Exponential Weights - Path Kernels}) and the OMD algorithms (Algorithm~\ref{alg: OMD}) under both full information and bandit feedback in the stochastic setting. We additionally provide more comprehensive experiments regarding the market dynamics of the PAB and uniform price auctions. In particular, we plot the evolution of the revenue, welfare, and winning bid gaps over time, as well compare the bandit feedback versions of the PAB and uniform price auctions.

\subsection{Stochastic Setting} \label{sec:stochastic}

To compare the regret incurred between our decoupled exponential weights and OMD based algorithms in a non-multi agent setting, we consider the setting where the bidder competes in a stochastic setting. Here, the bidder, endowed with valuation vector $\bm{v} = [1, 1, 1]$, will compete over the course of $T=10^4$ rounds for full information feedback ($T = 10^5$ rounds for bandit feedback) for $\overline{M}=M=3$ items. The competing bids are  $\bm{b}^{-1} = [0.1, 0.1, 0.1]$, $[0.3,0.3, 1.0]$, or $[0.4, 1.0, 1.0]$ with probabilities $\frac{1}{4}, \frac{1}{4}$, and $\frac{1}{2}$, respectively. Assuming that the bidder receives priority in tiebreaks, with $\mathcal{B} = \{\frac{i}{10}\}_{i \in [10]}$, the expected utility $\sum_{m=1}^3 \prob(b_m \geq b^{-1}_m) (1 - b_m)$ maximizing bid vector is given by $\bm{b} = [0.4, 0.3, 0.1]$, which yields utility $(1)(1-0.4) + (0.75)(1 - 0.3) + (0.5)(1-0.1) = 0.6 + 0.525 + 0.45 = 1.575$. We select learning rates $\eta = \sqrt{\tfrac{\log(|\mathcal{B}|)}{MT}}$ and $\eta = \sqrt{\tfrac{\log(|\mathcal{B}|)}{M|\mathcal{B}|T}}$ for the full information and bandit decoupled exponential weights algorithms, respectively. We select learning rates $\eta = \sqrt{\tfrac{\log(|\mathcal{B}|)}{T}}$ and $\eta = \sqrt{\tfrac{\log(|\mathcal{B}|)}{|\mathcal{B}|T}}$ for the full information and bandit OMD algorithms, respectively. For the uniform price algorithms, we select $\eta = \sqrt{\tfrac{\log(|\mathcal{B}|)}{MT}}$ and $\eta = \sqrt{\tfrac{\log(|\mathcal{B}|)}{M^3|\mathcal{B}|^2T}}$ for full information and bandit feedback, respectively.

% Figure environment removed

In Figure \ref{fig:exp2_bids}, we plot the average value of each bid over time. Here, the bidder's objective is to learn the optimal bid vector under each of our algorithms: decoupled exponential weights algorithm (Algorithms~\ref{alg: Decoupled Exponential Weights} and \ref{alg: Decoupled Exponential Weights - Path Kernels}), and the OMD algorithm  (Algorithm \ref{alg: OMD}) for both the full information and bandit settings. In this figure, we further compare the rate of convergence to the optimal bid vector of $[0.4, 0.3, 0.1]$ with our three algorithms. 

We observe that the full information OMD converges the fastest to the optimal bid, followed by full information decoupled exponential weights. Similarly, the bandit OMD converges faster than the bandit exponential weights algorithm, albeit slower than either full information variant. This behavior is consistent with our theoretical findings. 

We repeat this experiment for the algorithms to learn in uniform price auctions described in \cite{brânzei2023online}. Though we do not perform the calculations, the optimal bid vector in the uniform price setting is still $[0.4, 0.3, 0.1]$. We note that it takes noticeably longer for the bandit algorithm to converge as compared to either its full information variant or our Algorithms \ref{alg: Decoupled Exponential Weights - Path Kernels} or \ref{alg: OMD}, as predicted by the looser regret upper bounds:
\begin{theorem}[(Discrete) Regret in Uniform Price Auctions, \cite{brânzei2023online}] \label{thm: uniform price regret full}
    Under full information feedback (resp. bandit feedback), there exists an algorithm which achieves $O(M^{\frac{3}{2}}\sqrt{T \log |\mathcal{B}|})$ (resp. $O(M^{\frac{5}{2}}|\mathcal{B}|T^{\frac{1}{2}}\sqrt{\log |\mathcal{B}|} + M^2 \log |\mathcal{B}|)$) discrete regret.
\end{theorem}

\subsection{Market Dynamics over Time}\label{sec:market_dynamics_additional}

{\color{black} In this section, we run five additional batches of experiments to better understand the market dynamics. In the first experiment, we analyze the evolution of welfare and revenue over time for a fixed $M, N, |\mathcal{B}|, T$. In the second experiment, we look at the evolution of the ratios between the largest winning, smallest winning, and largest losing bids over time for the same parameterization. In the third through fifth experiments, we repeat the previous two experiments for the uniform price auction, as well as the first experiment in Section~\ref{sec: experiments} that shows the regret dependence on $M$ and $T$.}



{\color{black}
\textbf{First Experiment: Welfare and Revenue Over Time - PAB.} In this next set of experiments, we compare the evolution of the welfare and revenue over the course of the market dynamics. We use $M = 5, |\mathcal{B}| = 20, N = 3, T = 10^5$ for these simulations, though we note that our findings are consistent across parameterizations. In Figure \ref{fig:rev_wel_over_time}, we further compare the distribution of welfare and revenue over time showing the 10th, 25th, 50th, 75th, and 90th percentiles in different shades under Algorithms~\ref{alg: Decoupled Exponential Weights} and \ref{alg: Decoupled Exponential Weights - Path Kernels}. We normalize both welfare and revenue by the maximum possible welfare (sum of the largest $M$ valuations) in each instance. In comparison to the full information version, it takes longer for the bidders to settle to an approximately welfare maximizing steady state in the bandit setting. Furthermore, the revenue at the recovered steady state under bandit feedback is lower than that of the full information setting, albeit with lower variance.

Additionally, we observe that revenues initially converge for intermediate values of $t$ before decreasing and subsequently increasing in variance for larger $t$. To explain this, it's essential to understand the evolution of the ratios between the largest and smallest winning bids, as well as the largest losing bid (See Figure~\ref{fig: bid ratios PAB}). Specifically, the decrease in revenue coincides with when the winning bids are far apart. The sudden drop in revenue indicates that bidders have learned to strategically shade their winning bids down to the clearing price. Eventually, the bids converge to either the clearing price, which naturally has some variance as it is a random function of the valuations and input parameters $N, M, |\mathcal{B}|$, or a best response cycle where bidders undercut and subsequently slightly outbid one another indefinitely (See Figure~\ref{fig: bid cycling main body}).


% Figure environment removed

{\color{black}
\textbf{Second Experiment: Convergence of Winning Bids Over Time - PAB.}  In Figure \ref{fig: bid ratios PAB}, we compare the evolution of the ratio of the largest and smallest winning bids, as well as the ratio of the smallest winning bid to the largest losing bid. We find that the ratios both converge to approximately 1 over time, though somewhat faster  under full information feedback. Despite the existence of CCEs supported over joint bid profiles with large gaps between winning bids (see Lemma~\ref{lem: CCE non uniform winning}), the convergence of these ratios suggests near uniformity of the winning bids over the course of the learning dynamics induced by our decoupled exponential weights algorithms.}


% Figure environment removed


{\color{black}\textbf{Third Experiment: Regret as a Function of $M$ and $T$ - Uniform Price.} To better understand the impact of $M$ and $T$ on the continuous regret, we run the repeated auction setting with varying $T, M$ for the uniform price auction. From \cite{brânzei2023online}, the continuous regret of their no-regret learning algorithm is of order $O(M^\frac{3}{2}T^{\frac{1}{2}} \log T)$ and $O(\min(MT, M^\frac{7}{4}T^{\frac{3}{4}} \log T))$ in the full information and bandit feedback settings respectively. To obtain these regret guarantees, we select $|\mathcal{B}|$ and $\eta$ to balance the discretization error of order $O(\frac{MT}{|\mathcal{B}|})$ and discrete regret: for the full information setting specifically, we set $|\mathcal{B}| = \max(5, \sqrt{\frac{T}{M}})$ and $\eta = \sqrt{\frac{\log T}{MT}}$. For bandit feedback, we set $|\mathcal{B}| = \max(5, M^{-\frac{3}{4}}T^\frac{1}{4})$ and $\eta = \min(\frac{1}{M}, \sqrt{\frac{\log |\mathcal{B}|}{M^3 |\mathcal{B}|^2T}})$. We plot the $\log-\log$ sum of discrete regrets across all $N=3$ bidders, normalized by $NT$ to obtain the per-bidder, per-round average regret; see Figure \ref{fig:regret-plot-unif}. Running a linear regression on the median, we find that the slopes w.r.t. $T$ of the median regret are approximately $-\frac{1}{2}$ and $-\frac{1}{6}$ for the full information and bandit settings respectively. This accurately reflects the theoretical regret bound in the full information setting and similarly, the slope for the bandit setting falls between the predicted $-\frac{1}{4}$ and 0. Interestingly, the slopes of the median w.r.t. $M$ are approximately $\frac{5}{4}$ and $\frac{7}{4}$ for the full information and bandit feedback settings respectively. While the bandit feedback setting is consistent with theory, the full information feedback regret dependence on $M$ is $O(M^{\frac{1}{4}})$ faster than predicted.}

% Figure environment removed


{\color{black}\textbf{Fourth and Fifth Experiments: Welfare, Revenue, Bid Ratios over Time - Uniform Price.}
In Figure \ref{fig: uniform price market dynamics}, we present the evolution-over-time of the welfare, revenue (normalized by maximum welfare), and ratios of the largest bids for the uniform price auction, under full information feedback. We use parameterization $N=3, M = 5, |\mathcal{B}| = 20, T = 10^5$ (though the insights are consistent across parameterizations as we will see in the following section). In the uniform price auction, the payment is determined by the lowest winning bid, and there is consequently less incentive to manipulate higher bids since they are less correlated with the payment as compared to PAB. This observation aligns with findings from other variants of discriminatory versus uniform pricing, such as generalized first and second price auctions \cite{kagel1986curse, nyborg1996discvsunif, bergemann2020winnerscurse}. This explains the lower revenue and bid ratio non-convergence, whereas the slightly improved welfare stems from the tie-breaking rule (see Section~\ref{sec: experiments}).}

% Figure environment removed




\subsection{Comparison of PAB and Uniform Price Auctions under Bandit Feedback}\label{sec:compare_additional}

{\color{black} In this section, we compare the regret, welfare, revenue, bid ratios, and competitive ratios of the equilibria under the bandit feedback version of both the PAB and uniform price no-regret learning algorithms. In particular, we run the same parameterizations with $N \in \{3, 5\}, M \in \{1, 5, 10\}, |\mathcal{B}| \in \{10, 20\}, T = 10^5$ as in Tables~\ref{table: learning dynamics full info} and \ref{table: learning dynamics full uniform}, except now for bandit feedback. We use $\eta = \sqrt{\frac{\log |\mathcal{B}|}{M|\mathcal{B}|T}}$ for PAB and $\eta = \sqrt{\frac{\log |\mathcal{B}|}{M^3|\mathcal{B}|^2T}}$ for uniform price. Our results are shown in Tables~\ref{table: learning dynamics bandit info} and \ref{table: learning dynamics bandit uniform}. While most of our findings are consistent with the full information market dynamics, it is clear that the market dynamics have not yet converged for larger $M, |\mathcal{B}|$, especially for the uniform price auction, as indicated by the large regret, bid ratios, competitive ratios, and revenue gaps. Consequently, we relegate drawing conclusions regarding the equilibria of PAB and uniform price in the bandit setting to the full information setting, as presented in Section~\ref{sec: experiments}.}




\begin{table}[ht]
    \centering
    \begin{minipage}[t]{0.48\linewidth} % Left table
        \caption{Summary of the Bidding Dynamics (Bandit, Algorithm~\ref{alg: Decoupled Exponential Weights - Path Kernels})}
        \label{table: learning dynamics bandit info}
        \footnotesize
        \begin{tabular}{lcccc}
        \toprule
         & \multicolumn{2}{c}{$|\mathcal{B}| = 10$} & \multicolumn{2}{c}{$|\mathcal{B}| = 20$} \\
        \cmidrule(lr){2-3} \cmidrule(lr){4-5}
        Metric & $N = 3$ & $N = 5$ & $N = 3$ & $N = 5$ \\
        \midrule
        \multicolumn{5}{c}{\textbf{For \( M = 1 \)}} \\
        Regret  & .8/2.5 & .5/2.5 & .3/1.9 & .8/2.7 \\
        Welfare Gap  & .40/11 & .50/4 & .86/14 & 1.6/13 \\
        Revenue Gap  & 28/78 & 18/47 & 38/69 & 24/41 \\
        CR Gap  & 1.6/56 & 2.2/25 & 1.6/53 & 8.2/52 \\
        Runtime (sec) & 321 & 511 & 415 & 879 \\
        \midrule
        \multicolumn{5}{c}{\textbf{For \( M = 5 \)}} \\
        Regret  & .4/.7 & .6/1.2 & .5/1.2 & .9/1.4 \\
        Welfare Gap  & 2.5/7.7 & 2.7/5.4 & 2.1/5.8 & 2.6/5.1 \\
        Revenue Gap  & 37/49 & 21/27 & 37/47 & 22/28 \\
        $b_{(1)}/b_{(M)}$ & 1.17/1.26 & 1.12/1.17 & 1.10/1.17 & 1.06/1.11 \\
        CR Gap  & 3.6/23 & 13/20 & 8.7/21 & 12/23 \\
        Runtime (sec) & 1844 & 2843 & 2660 & 5123 \\
        \midrule
        \multicolumn{5}{c}{\textbf{For \( M = 10 \)}} \\
        Regret  & 3.9/16 & 2.3/5.8 & 9.6/20.5 & 4.3/8.6 \\
        Welfare Gap  & 3.2/6.9 & 2.6/4.4 & 3.2/6.6 & 2.6/4.4 \\
        Revenue Gap  & 34/44 & 20/25 & 37/43 & 21/26 \\
        $b_{(1)}/b_{(M)}$ & 1.21/1.26 & 1.14/1.18 & 1.12/1.16 & 1.08/1.1 \\
        CR Gap  & 4.6/18 & 6/15 & 9/23 & 10/20 \\
        Runtime (sec) & 3912 & 5222 & 5098 & 9731 \\
        \bottomrule
        \end{tabular}
    \end{minipage}\hfill
    \begin{minipage}[t]{0.48\linewidth} % Right table
        \caption{Summary of the Bidding Dynamics (Uniform Price, Bandit \cite{brânzei2023online})}
        \label{table: learning dynamics bandit uniform}
        \footnotesize
        \begin{tabular}{lcccc}
        \toprule
         & \multicolumn{2}{c}{$|\mathcal{B}| = 10$} & \multicolumn{2}{c}{$|\mathcal{B}| = 20$} \\
        \cmidrule(lr){2-3} \cmidrule(lr){4-5}
        Metric & $N = 3$ & $N = 5$ & $N = 3$ & $N = 5$ \\
        \midrule
        \multicolumn{5}{c}{\textbf{For \( M = 1 \)}} \\
        Regret&	5.1/13.3&	3.7/6.3&	6.3/12&	5.4/7.4\\
        Welfare Gap&	1.5/26&	.8/15&	3.1/33&	17/32\\
        Revenue Gap&	45/70&	38/50&	49/67&	38/45\\
        CR Gap&	39/72&	42/64&	35/72&	66/77\\
        Runtime (sec) & 166 & 241 & 317 & 466\\
        \midrule
        \multicolumn{5}{c}{\textbf{For \( M = 5 \)}} \\
        Regret&	22/35&	9.1/11&	12/13&	11/12\\
        Welfare Gap&	2.3/7.8&	3.5/5.7&	4.4/6.1&	5.6/7.3\\
        Revenue Gap&	80/85&	47/58&	60/66&	43/48\\
        $b_{(1)}/b_{(M)}$ &	7.1/16&	2.2/4.5&	3/3.9&	1.7/2\\
        CR Gap&	19/24&	19/23&	14/16&	26/30\\
        Runtime (sec) & 1531 & 2612 & 5323 & 8777\\
        \midrule
        \multicolumn{5}{c}{\textbf{For \( M = 10 \)}} \\
        Regret&	98/147&	36/39&	53/60&	40/43\\
        Welfare Gap&	4.6/9.3&	3.9/6.9&	5.3/9.2&	5.4/6.5\\
        Revenue Gap&	98/98&	59/63&	89/90&	56/60\\
        $b_{(1)}/b_{(M)}$ &	43/46&	4.8/5.5&	21/24&	3.4/3.6\\
        CR Gap&	29/34&	26/30&	19/21&	30/32\\
        Runtime (sec) & 2643 & 5000 & 9783 & 14532\\
        \bottomrule
        \end{tabular}
    \end{minipage}
\end{table}









{\color{black}
\section{Proof of Theorem \ref{thm: time varying known finite}}
    %\negin{Can you review the proof carefully as referees will go over it.}
To begin, we can once again `decouple' the utility per unit-bid pair, but this time conditional on the valuation vector context. In particular, we have:
\begin{align*}
    \mu_n^t(\bm{b}; \bm{v}) =  \sum_{m=1}^M w_m^t(b_m; \bm{v}) = \sum_{m=1}^M (v_m - b_m)1_{b_m \geq b^t_{-m}} \quad \text{and} \quad \widehat{\mu}_n^t(\bm{b}; \bm{v}) =  \sum_{m=1}^M \widehat{w}_m^t(b_m; \bm{v})\,.
\end{align*}
As stated earlier, we define reward estimates based on Equation (6) of \cite{ContextBanditsCrossLearning2019} and our Algorithm~\ref{alg: Decoupled Exponential Weights - Path Kernels}:
\begin{align*}
    \widehat{w}_m^t(b; \bm{v}) = 1 - \frac{1 - w_m^t(b; \bm{v})}{\sum_{\bm{v} \in \mathcal{V}} \prob(\bm{v}^t = \bm{v}) q_m^t(b; \bm{v})} \textbf{1}_{b_m^t = b} = 1 - \frac{1 - w_m^t(b; \bm{v})}{Q_m^t(b)} \textbf{1}_{b_m^t = b}\,.
\end{align*}
Here, $q_m^t(b; \bm{v}) = \prob(b^t_m = b | \bm{v}^t = \bm{v}) = \sum_{\bm{b}: b^t_m = b} \prob(\bm{b}^t = \bm{b} | \bm{v}^t = \bm{v})$ is the probability of selecting bid $b$ in slot $m$ with valuation $\bm v$. Similarly, $Q_m^t(b)$ is the probability of selecting bid $b$ for unit $m$, averaged across all possible valuations. One can verify unbiasedness of this estimator $\mathbb{E}[\hat{w}_m^t(b; \bm{v})] = w_m^t(b; \bm{v})$ for all $m \in [M], b \in \mathcal{B}, \bm{v} \in \mathcal{V}$. The second moment can similarly be computed as:
\begin{align*}
    \mathbb{E}[\widehat{w}_m^t(b; \bm{v})^2] = \mathbb{E}\left[\left( 1 - \frac{1-w_m^t(b; \bm{v})}{Q_m^t(b)} \textbf{1}_{b_m^t = b} \right)^2 \right] = 1 - 2\mathbb{E}\left[\frac{1-w_m^t(b; \bm{v})}{Q_m^t(b)}\textbf{1}_{b_m^t=b}\right] + \mathbb{E}\left[\left(\frac{1-w_m^t(b; \bm{v})}{Q_m^t(b)}\right)^2\textbf{1}_{b_m^t=b}\right]\,.
\end{align*}

Evaluating the expectations and recalling that $\mathbb{E}[\textbf{1}_{b_m^t = b}] = Q_m^t(b)$, we have:
\begin{align*}
    \mathbb{E}[\widehat{w}_m^t(b; \bm{v})^2] = 1 - \left[2 - 2w_m^t(b; \bm{v})\right] + \left[\frac{(1 - w_m^t(b; \bm{v}))^2}{Q_m^t(b)}\right] = 2w_m^t(b; \bm{v}) - 1 + \frac{1}{Q_m^t(b)} \leq 1 + \frac{1}{Q_m^t(b)} \leq \frac{2}{Q_m^t(b)}\,.
\end{align*}

Using this, the proof largely follows that of Algorithm~\ref{alg: Decoupled Exponential Weights - Path Kernels} up until Equation (\ref{eq: full info difference}). In particular, we have that the contextual regret can be written as:
\begin{align*}
    \textsc{Regret}_\mathcal{B}(F_{\bm{v}}) &= \mathbb{E}_{F_{\bm{v}}}\left[\sum_{t=1}^{T} \mu_n^t(\bm{b}'; \bm{v}^t) - \sum_{t=1}^{T} \mathbb{E}[\mu^t(\bm{b}^\nround; \bm{v}^t)]\right]\\
    &\lesssim \eta^{-1}M\log|\mathcal{B}| + \eta \mathbb{E}_{F_{\bm{v}}}\left[\sum_{\nround=1}^\Nround \sum_{\bm{b}} \prob(\bm{b}^\nround =\bm{b}| \bm{v}^t = \bm{v}) \mathbb{E}[(\sum_{m=1}^M \widehat{w}^\nround_m(b_m; \bm{v}))^2]\right]\\
    &= \eta^{-1}M\log|\mathcal{B}| + \eta \left[\sum_{\nround=1}^\Nround \sum_{\bm{v} \in \mathcal{V}} \prob(\bm{v}^t = \bm{v})\sum_{\bm{b}} \prob(\bm{b}^\nround =\bm{b}| \bm{v}^t =  \bm{v}) \mathbb{E}[(\sum_{m=1}^M \widehat{w}^\nround_m(b_m; \bm{v}))^2]\right]\\
    &= \eta^{-1}M\log|\mathcal{B}| + \eta M\left[\sum_{\nround=1}^\Nround \sum_{m=1}^M \sum_{\bm{v} \in \mathcal{V}} \prob(\bm{v}^t = \bm{v})\sum_{b \in \mathcal{B}} \mathbb{E}[\widehat{w}_m^t(b; \bm{v})^2]  \sum_{\bm{b}: b_m = b} \prob(\bm{b}^\nround =\bm{b}| \bm{v}^t = \bm{v})\right]\\
    &= \eta^{-1}M\log|\mathcal{B}| + \eta M\left[\sum_{\nround=1}^\Nround \sum_{m=1}^M \sum_{\bm{v} \in \mathcal{V}} \prob(\bm{v}^t = \bm{v})\sum_{b \in \mathcal{B}} \mathbb{E}[\widehat{w}_m^t(b; \bm{v})^2]  q_m^t(b; \bm{v})\right]\\
    &= \eta^{-1}M\log|\mathcal{B}| + 2\eta M\left[\sum_{\nround=1}^\Nround \sum_{m=1}^M \sum_{\bm{v} \in \mathcal{V}} \prob(\bm{v}^t = \bm{v})\sum_{b \in \mathcal{B}} \frac{1}{Q_m^t(b)}  q_m^t(b; \bm{v})\right]\\
    &= \eta^{-1}M\log|\mathcal{B}| + 2\eta M\left[\sum_{\nround=1}^\Nround \sum_{m=1}^M \sum_{b \in \mathcal{B}} \frac{1}{Q_m^t(b)} \sum_{\bm{v} \in \mathcal{V}} \prob(\bm{v}^t = \bm{v}) q_m^t(b; \bm{v})\right]\\
    &= \eta^{-1}M\log|\mathcal{B}| + 2\eta M\left[\sum_{\nround=1}^\Nround \sum_{m=1}^M \sum_{b \in \mathcal{B}} \frac{1}{Q_m^t(b)} Q_m^t(b)\right]\\
    &\leq \eta^{-1}M\log|\mathcal{B}| + \eta M^2|\mathcal{B}|T\,.
\end{align*}
(We will show the first inequality shortly.)
With $\eta = \Theta(\sqrt{\frac{\log |\mathcal{B}|}{M|\mathcal{B}|T}})$,  this yields  the  discretized contextual regret upper bounds of $O(M^{\frac{3}{2}}\sqrt{|\mathcal{B}| T \log |\mathcal{B}|})$ under the bandit setting. Accounting for the rounding error of order $O(\frac{MT}{|\mathcal{B}|})$, we obtain the stated continuous contextual regret upper bounds by optimizing with $|\mathcal{B}| = M^{-\frac{1}{3}}T^{\frac{1}{3}}$. 
To obtain the full information results, we simply replace $\widehat{w}_m^t(b_m; {\bm v}^t)$ with $w_m^t(b_m; {\bm v}^t)$ in the second line of the above equations, which leads to  the discretized contextual regret upper bounds of $O(M^{\frac{3}{2}}\sqrt{ T \log |\mathcal{B}|})$, as desired.


Next, following the proof of Algorithm \ref{alg: Decoupled Exponential Weights - Path Kernels}, we show   the first inequality. 
We define the potentials with respect to a fixed valuation vector $\bm{v}$: $\Phi^t(\bm{v}) = \sum_{\bm{b} \in \mathcal{B}^{+\Nitem}} \exp(\eta \sum_{\tau=1}^{t} \widehat{\mu}^\tau(\bm{b}; \bm{v}^\tau))$. Taking the ratio of adjacent terms, we obtain:
\begin{align*}
    \frac{\Phi^t(\bm{v})}{\Phi^{t-1}(\bm{v})} = \sum_{\bm{b} \in \mathcal{B}^{+M}} \frac{\exp(\eta \sum_{\tau=1}^{t-1} \widehat{\mu}^\tau(\bm{b}; \bm{v}^\tau))}{\Phi^{t-1}(\bm{v})} \exp(\eta \widehat{\mu}^t(\bm{b}; \bm{v}^t)) = \sum_{\bm{b} \in \mathcal{B}^{+M}} \prob(\bm{b}^\nround = \bm{b} | \bm{v}^\nround = \bm{v}) \exp(\eta \widehat{\mu}^t(\bm{b}; \bm{v}^\nround))\,,
\end{align*}
Where in the last equality, we used the condition that our algorithm samples bid vector $\bm{b}$ with probability proportional to $\exp(\eta \sum_{\tau=1}^{t-1} \widehat{\mu}^\nround(\bm{b}; \bm{v}))$ at round $\nround$ with valuations $\bm{v}^t = \bm{v}$. Combining this with inequalities $\exp(x) \leq 1 + x + x^2$ and $1 + x \leq \exp(x)$ for all $x \leq 1$, we obtain:
\begin{align*}
    \frac{\Phi^t(\bm{v})}{\Phi^{t-1}(\bm{v})} \leq \sum_{\bm{b} \in \mathcal{B}^{+M}} \prob(\bm{b}^\nround = \bm{b} | \bm{v}^\nround = \bm{v}) \exp(\eta \widehat{\mu}^t(\bm{b}; \bm{v})) \leq \exp(\sum_{\bm{b} \in \mathcal{B}^{+M}} \prob(\bm{b}^\nround = \bm{b} | \bm{v}^\nround = \bm{v}) \left[\eta\widehat{\mu}^t(\bm{b}; \bm{v}) + \eta^2 \widehat{\mu}^t(\bm{b}; \bm{v})^2 \right])\,.
\end{align*}
Combining this with Equations~\eqref{eq: Potentials} and the fact that $\Phi^0(\bm{v}) = M\log |\mathcal{B}|$, for any fixed bid vector $\bm{b}'$, we have:
\begin{align*}
    \sum_{t=1}^{T} \widehat{\mu}^t(\bm{b}'; \bm{v}) - \sum_{t=1}^{T} \sum_{\bm{b}} \prob(\bm{b}^\nround = \bm{b}| \bm{v}^t = \bm{v})  \widehat{\mu}^t(\bm{b}; \bm{v}) &\lesssim \eta^{-1} \Nitem \log |\mathcal{B}| + \eta \sum_{t=1}^T \sum_{\bm{b}}\prob(\bm{b}^\nround = \bm{b} | \bm{v}^\nround = \bm{v}) \widehat{\mu}^t(\bm{b}; \bm{v})^2\\
    &= \eta^{-1} \Nitem \log |\mathcal{B}| + \eta \sum_{t=1}^T \sum_{\bm{b}}\prob(\bm{b}^\nround = \bm{b} | \bm{v}^\nround = \bm{v}) (\sum_{m=1}^M \widehat{w}_m^t(b_m; \bm{v}))^2\,.
\end{align*}
Taking expectations over $\bm{b}$ and the supremum over all $\bm{b}'$ yields the desired first crucial regret inequality.

As for the time and space complexity, notice that the only algorithmic difference between Algorithm~\ref{alg: Decoupled Exponential Weights - Time Varying Known Finite} and Algorithm~\ref{alg: Decoupled Exponential Weights - Path Kernels} is precisely in computing the estimator, which in the former, requires having to compute the weights $Q_m^t(b)$ by iterating over all $\bm{v} \in \mathcal{V}$. As we also have to store reward estimates for each possible valuations, both the time complexity and space complexity of Algorithm~\ref{alg: Decoupled Exponential Weights - Time Varying Known Finite} are a factor $|\mathcal{V}|$ larger than in Algorithm~\ref{alg: Decoupled Exponential Weights - Path Kernels}, which are $O(M|\mathcal{B}| |\mathcal{V}| T)$ and $O(M|\mathcal{B}| |\mathcal{V}|)$ respectively.


}
}


