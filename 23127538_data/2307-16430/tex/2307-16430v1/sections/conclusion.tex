\section{Conclusion}
\label{sec:Conclusion}
We propose VITS2, a single-stage text-to-speech model that can efficiently synthesize more natural speech. We improved the training and inference efficiency and naturalness by introducing adversarial learning into the duration predictor.
The transformer block was added to the normalizing flows to capture the long-term dependency when transforming the distribution.
The synthesis quality was improved by incorporating Gaussian noise into the alignment search.
The dependency on phoneme conversion, which was posing a challenge in achieving a fully end-to-end single-stage speech synthesis, was significantly reduced. The test results also show that overall intelligibility was improved. 
We demonstrated the validity of our proposed methods through experiments, quality evaluation, and computation speed measurement. Various problems still exist in the field of speech synthesis that must be addressed, and we hope that our work can be a basis for future research.