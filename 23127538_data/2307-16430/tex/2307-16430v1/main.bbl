% Generated by IEEEtran.bst, version: 1.13 (2008/09/30)
\begin{thebibliography}{10}
\providecommand{\url}[1]{#1}
\csname url@samestyle\endcsname
\providecommand{\newblock}{\relax}
\providecommand{\bibinfo}[2]{#2}
\providecommand{\BIBentrySTDinterwordspacing}{\spaceskip=0pt\relax}
\providecommand{\BIBentryALTinterwordstretchfactor}{4}
\providecommand{\BIBentryALTinterwordspacing}{\spaceskip=\fontdimen2\font plus
\BIBentryALTinterwordstretchfactor\fontdimen3\font minus
  \fontdimen4\font\relax}
\providecommand{\BIBforeignlanguage}[2]{{%
\expandafter\ifx\csname l@#1\endcsname\relax
\typeout{** WARNING: IEEEtran.bst: No hyphenation pattern has been}%
\typeout{** loaded for the language `#1'. Using the pattern for}%
\typeout{** the default language instead.}%
\else
\language=\csname l@#1\endcsname
\fi
#2}}
\providecommand{\BIBdecl}{\relax}
\BIBdecl

\bibitem{shen2018natural}
J.~Shen, R.~Pang, R.~J. Weiss, M.~Schuster, N.~Jaitly, Z.~Yang, Z.~Chen,
  Y.~Zhang, Y.~Wang, R.~Skerrv-Ryan \emph{et~al.}, ``Natural tts synthesis by
  conditioning wavenet on mel spectrogram predictions,'' in \emph{2018 IEEE
  International Conference on Acoustics, Speech and Signal Processing
  (ICASSP)}.\hskip 1em plus 0.5em minus 0.4em\relax IEEE, 2018, pp. 4779--4783.

\bibitem{li2019neural}
N.~Li, S.~Liu, Y.~Liu, S.~Zhao, and M.~Liu, ``Neural speech synthesis with
  transformer network,'' in \emph{Proceedings of the AAAI Conference on
  Artificial Intelligence}, vol.~33, no.~01, 2019, pp. 6706--6713.

\bibitem{ren2019fastspeech}
Y.~Ren, Y.~Ruan, X.~Tan, T.~Qin, S.~Zhao, Z.~Zhao, and T.-Y. Liu,
  ``Fast{S}peech: {F}ast, {R}obust and {C}ontrollable {T}ext to {S}peech,''
  vol.~32, 2019, pp. 3171--3180.

\bibitem{kim2020glow}
J.~Kim, S.~Kim, J.~Kong, and S.~Yoon, ``Glow-{TTS}: A {G}enerative {F}low for
  {T}ext-to-{S}peech via {M}onotonic {A}lignment {S}earch,'' \emph{Advances in
  Neural Information Processing Systems}, vol.~33, 2020.

\bibitem{valle2020flowtron}
R.~Valle, K.~J. Shih, R.~Prenger, and B.~Catanzaro, ``Flowtron: an
  autoregressive flow-based generative network for text-to-speech synthesis,''
  in \emph{International Conference on Learning Representations}, 2020.

\bibitem{popov2021grad}
V.~Popov, I.~Vovk, V.~Gogoryan, T.~Sadekova, and M.~Kudinov, ``Grad-tts: A
  diffusion probabilistic model for text-to-speech,'' in \emph{International
  Conference on Machine Learning}.\hskip 1em plus 0.5em minus 0.4em\relax PMLR,
  2021, pp. 8599--8608.

\bibitem{ren2021fastspeech}
\BIBentryALTinterwordspacing
Y.~Ren, C.~Hu, X.~Tan, T.~Qin, S.~Zhao, Z.~Zhao, and T.-Y. Liu, ``Fast{S}peech
  2: {F}ast and {H}igh-{Q}uality {E}nd-to-{E}nd {T}ext to {S}peech,'' in
  \emph{International Conference on Learning Representations}, 2021. [Online].
  Available: \url{https://openreview.net/forum?id=piLPYqxtWuA}
\BIBentrySTDinterwordspacing

\bibitem{oord2016wavenet}
A.~v.~d. Oord, S.~Dieleman, H.~Zen, K.~Simonyan, O.~Vinyals, A.~Graves,
  N.~Kalchbrenner, A.~Senior, and K.~Kavukcuoglu, ``Wavenet: A generative model
  for raw audio,'' \emph{arXiv preprint arXiv:1609.03499}, 2016.

\bibitem{kalchbrenner2018efficient}
N.~Kalchbrenner, E.~Elsen, K.~Simonyan, S.~Noury, N.~Casagrande, E.~Lockhart,
  F.~Stimberg, A.~Oord, S.~Dieleman, and K.~Kavukcuoglu, ``Efficient neural
  audio synthesis,'' in \emph{International Conference on Machine
  Learning}.\hskip 1em plus 0.5em minus 0.4em\relax PMLR, 2018, pp. 2410--2419.

\bibitem{prenger2019waveglow}
R.~Prenger, R.~Valle, and B.~Catanzaro, ``Waveglow: {A} flow-based generative
  network for speech synthesis,'' in \emph{ICASSP 2019-2019 IEEE International
  Conference on Acoustics, Speech and Signal Processing (ICASSP)}.\hskip 1em
  plus 0.5em minus 0.4em\relax IEEE, 2019, pp. 3617--3621.

\bibitem{kumar2019melgan}
K.~Kumar, R.~Kumar, T.~de~Boissiere, L.~Gestin, W.~Z. Teoh, J.~Sotelo,
  A.~de~Br\'{e}bisson, Y.~Bengio, and A.~C. Courville, ``Mel{GAN}: {G}enerative
  {A}dversarial {N}etworks for {C}onditional waveform synthesis,'' vol.~32,
  2019, pp. 14\,910--14\,921.

\bibitem{binkowski2019high}
M.~Bi{\'n}kowski, J.~Donahue, S.~Dieleman, A.~Clark, E.~Elsen, N.~Casagrande,
  L.~C. Cobo, and K.~Simonyan, ``High fidelity speech synthesis with
  adversarial networks,'' in \emph{International Conference on Learning
  Representations}, 2019.

\bibitem{yamamoto2020parallel}
R.~Yamamoto, E.~Song, and J.-M. Kim, ``Parallel wavegan: A fast waveform
  generation model based on generative adversarial networks with
  multi-resolution spectrogram,'' in \emph{International Conference on
  Acoustics, Speech and Signal Processing}, 2020, pp. 6199--6203.

\bibitem{kong2020hifi}
J.~Kong, J.~Kim, and J.~Bae, ``Hi{F}i-{GAN}: {G}enerative {A}dversarial
  networks for {E}fficient and {H}igh {F}idelity {S}peech {S}ynthesis,''
  \emph{Advances in Neural Information Processing Systems}, vol.~33, 2020.

\bibitem{chen2020wavegrad}
N.~Chen, Y.~Zhang, H.~Zen, R.~J. Weiss, M.~Norouzi, and W.~Chan, ``Wavegrad:
  Estimating gradients for waveform generation,'' in \emph{International
  Conference on Learning Representations}, 2020.

\bibitem{donahue2021endtoend}
\BIBentryALTinterwordspacing
J.~Donahue, S.~Dieleman, M.~Binkowski, E.~Elsen, and K.~Simonyan, ``End-to-end
  adversarial text-to-speech,'' in \emph{International Conference on Learning
  Representations}, 2021. [Online]. Available:
  \url{https://openreview.net/forum?id=rsf1z-JSj87}
\BIBentrySTDinterwordspacing

\bibitem{kim2021conditional}
J.~Kim, J.~Kong, and J.~Son, ``Conditional variational autoencoder with
  adversarial learning for end-to-end text-to-speech,'' in \emph{International
  Conference on Machine Learning}.\hskip 1em plus 0.5em minus 0.4em\relax PMLR,
  2021, pp. 5530--5540.

\bibitem{lim22_interspeech}
D.~Lim, S.~Jung, and E.~Kim, ``{JETS: Jointly Training FastSpeech2 and HiFi-GAN
  for End to End Text to Speech},'' in \emph{Proc. Interspeech 2022}, 2022, pp.
  21--25.

\bibitem{mao2017least}
X.~Mao, Q.~Li, H.~Xie, R.~Y. Lau, Z.~Wang, and S.~Paul~Smolley, ``Least squares
  generative adversarial networks,'' in \emph{Proceedings of the IEEE
  international conference on computer vision}, 2017, pp. 2794--2802.

\bibitem{ljspeech17}
K.~Ito, ``The {LJ} {S}peech {D}ataset,''
  \url{https://keithito.com/LJ-Speech-Dataset/}, 2017.

\bibitem{veaux2017cstr}
C.~Veaux, J.~Yamagishi, K.~MacDonald \emph{et~al.}, ``C{STR VCTK} corpus:
  {E}nglish multi-speaker corpus for {CSTR} voice cloning toolkit,''
  \emph{University of Edinburgh. The Centre for Speech Technology Research
  (CSTR)}, 2017.

\bibitem{phonemizer20}
M.~Bernard, ``Phonemizer,'' \url{https://github.com/bootphon/phonemizer}, 2021.

\bibitem{keithitotacotron}
K.~Ito, \url{https://github.com/keithito/tacotron}.

\bibitem{loshchilov2018decoupled}
\BIBentryALTinterwordspacing
I.~Loshchilov and F.~Hutter, ``Decoupled {W}eight {D}ecay {R}egularization,''
  in \emph{International Conference on Learning Representations}, 2019.
  [Online]. Available: \url{https://openreview.net/forum?id=Bkg6RiCqY7}
\BIBentrySTDinterwordspacing

\bibitem{jia2018transfer}
Y.~Jia, Y.~Zhang, R.~J. Weiss, Q.~Wang, J.~Shen, F.~Ren, Z.~Chen, P.~Nguyen,
  R.~Pang, I.~Lopez-Moreno \emph{et~al.}, ``Transfer {L}earning from {S}peaker
  {V}erification to {M}ultispeaker {T}ext-{T}o-{S}peech {S}ynthesis,'' in
  \emph{Advances in Neural Information Processing Systems}, 2018.

\bibitem{tan2022naturalspeech}
X.~Tan, J.~Chen, H.~Liu, J.~Cong, C.~Zhang, Y.~Liu, X.~Wang, Y.~Leng, Y.~Yi,
  L.~He \emph{et~al.}, ``Naturalspeech: End-to-end text to speech synthesis
  with human-level quality,'' \emph{arXiv preprint arXiv:2205.04421}, 2022.

\end{thebibliography}
