This section evaluates the performances of the proposed methods for scheduling one task and scheduling task sets.

\subsection{Evaluation of Scheduling One Task}
\label{sec:evaluation_one}

This subsection evaluates the response time bounds of one DAG task using the following methods.
\begin{itemize}
    \item \textsf{PATH}. The method in \cite{he2022bounding}, shown in Theorem \ref{thm:he_bound}.
    \item \textsf{OUR}. Our method presented in Section \ref{sec:method}.
\end{itemize}
The bound in \cite{he2022bounding} is the state-of-the-art regarding scheduling a DAG task under a work-conserving scheduler on an identical multi-core platform.
Both bounds are normalized with respect to Graham's bound in \cite{graham1969bounds} to compare the performances.

\textbf{Task Generation.}
The DAG tasks are generated using the Erd\"os-R\'enyi method \cite{cordeiro2010random}. The number of vertices $|V|$ is randomly chosen in a specified range. For each pair of vertices, it generates a random value in $[0, 1]$ and adds an edge to the graph if the generated value is less than a predefined \emph{parallelism factor} $\mathit{pf}$. The larger $\mathit{pf}$, which means that there are more edges, the more sequential the graph is. After the vertices and edges are generated, the WCET of each vertex is randomly chosen in a specified range.
The default settings for generating DAG tasks are as follows.
The WCETs of vertices $c(v)$, the vertex number $|V|$, and the parallelism factor $\mathit{pf}$ are randomly and uniformly chosen in $[50, 100]$, $[50, 250]$ and $[0, 0.5]$, respectively.
For each data point in Fig. \ref{fig:evaluation_one}, we randomly generate 500 tasks to compute the average normalized bound.

The experiment results are reported in Fig. \ref{fig:evaluation_one}.
Fig. \ref{fig:m} shows the results of changing the number of cores on which the DAG task is scheduled.
When $m=2$, since fewer vertices can execute in parallel, the execution of DAG tasks is more sequential.
Therefore, both bounds are close to the volume of the task. This is the reason why the data points of both bounds in Fig. \ref{fig:m} are relatively close to each other when $m=2$.
When $m$ gets larger gradually (i.e., $m \in [3, 7]$), the technique of adding edges, being able to construct longer paths and reduce the interference to the critical path, becomes more effective in reducing the bound.
This explains why the data points of \textsf{OUR} in Fig. \ref{fig:m} become decrease when $m \le 4$.
When $m$ is close to 10, since more vertices can execute immediately once being released, the response time will approach the length of the longest path. Therefore, both bounds are close to the length of the longest path.
This explains why the data points of \textsf{OUR} in Fig. \ref{fig:m} become increase when $m \ge 4$.
Compared to \textsf{PATH}, our method can reduce the normalized bound by 21.6\% when $m=4$.
We choose $m=4$ as a representative for the following two experiments.

% Figure environment removed

Fig. \ref{fig:pf} reports the results of changing the parallelism factor $\mathit{pf}$.
When $\mathit{pf}$ is close to 0, since there are fewer edges in the graph, all paths (including the longest path) are short.
For \textsf{PATH}, it is difficult to identify long paths; for \textsf{OUR}, it is difficult to construct long paths, since the longest path is also short and we do not increase the length of the longest path when adding edges.
Therefore, both normalized bounds become close to 1.
When $\mathit{pf}$ gets larger gradually, there are more edges in the graph.
In this stage, the lengths of paths in the graph are more diversified: some paths are short and some paths are long.
So it is relatively easy to connect short paths into long paths while keeping the length of the longest path unchanged.
Therefore, our method becomes more effective.
This explains why the data points of \textsf{OUR} in Fig. \ref{fig:pf} become decrease when $\mathit{pf} \le 0.2$.
When $\mathit{pf}$ is close to 0.5, the generated graph is more sequential.
In this stage, all paths in the graph are long.
It is difficult to connect paths by adding edges while keeping the length of the longest path unchanged.
Therefore, \textsf{OUR} becomes close to \textsf{PATH}.
This explains why the data points of \textsf{OUR} in Fig. \ref{fig:pf} become increase when $\mathit{pf} \ge 0.2$.
%However, as reported in \cite{wang2017benchmarking, he2019intra}, benchmarks and practical applications generally possess high parallelism, which renders our method effective in practice.
Compared to \textsf{PATH}, the maximum improvement for the normalized bound is 25\%.
Fig. \ref{fig:v} shows the results of changing the vertex number of DAG tasks.
Same as \textsf{PATH}, \textsf{OUR} is insensitive to the vertex number, which implies that our method can be applied to realistic applications with a large number of subtasks.
In this experiment, compared to \textsf{PATH}, the average improvement for the normalized bound is 21.6\%.




\subsection{Evaluation of Scheduling Task Sets}
\label{sec:evaluation_set}

This section evaluates the performance of the proposed approach for scheduling task sets.
The following approaches are compared.
\begin{itemize}
  \item \textsf{FED}. The original federated scheduling proposed in \cite{li2014analysis}.
  \item \textsf{PATH}. The federated scheduling approach in \cite{he2022bounding} by using the information of multiple long paths to reduce the number of cores required by an individual task.
  \item \textsf{OUR}. Our approach presented in Section \ref{sec:extension}.
\end{itemize}
As shown in \cite{he2022bounding}, \textsf{PATH} has the best performance among all existing scheduling approaches of different paradigms (federated, global, partitioned and decomposition-based, see Section \ref{sec:related}), so we only include \textsf{FED} and \textsf{PATH} in our comparison.

\textbf{Task Set Generation.}
DAG tasks are generated by the same method as Section \ref{sec:evaluation_one} with $c(v)$, $|V|$ and $\mathit{pf}$ randomly chosen in [50, 100], [50, 250], [0, 0.5], respectively.
The period $T$ (which equals $D$ in the experiment) is computed by $len(G)+\alpha(vol(G)-len(G))$, where $\alpha$ is a parameter. Same as the setting of \cite{he2022bounding}, we consider $\alpha$ in [0, 0.5] to let heavy tasks require at least two cores.
The number of cores $m$ is set to be 32 (but changing in Fig. \ref{fig:g_m}).
The \emph{utilization} of a task is defined to be $vol(G)/T$, and the utilization of a task set is the sum of all utilizations of tasks in this task set. 
The \emph{normalized utilization} of a task set is the utilization of this task set divided by the number of cores.
In the experiments, the normalized utilization $\mathit{nu}$ of task sets is randomly chosen in [0, 0.8].
To generate a task set with a specific utilization, we randomly generate DAG tasks and add them to the task set until the total utilization reaches the required value.
For each data point in Fig. \ref{fig:evaluation_set}, we randomly generate 1000 task sets to compute the average performance.

% Figure environment removed

We evaluate the schedulability of task sets using the acceptance ratio as the metric. The \emph{acceptance ratio} is the ratio between the number of schedulable task sets and the number of all task sets. The larger the acceptance ratio, the better the performance is.
The result of changing the number of cores on which task sets are scheduled is in Fig.~\ref{fig:g_m}, which shows that our approach and federated scheduling in general are insensitive to the number of cores. This is because in federated scheduling paradigm, heavy tasks are mostly allocated and executed on dedicated cores, thus different tasks cannot interfere with each other. This is important for scalability.
Compared to \textsf{PATH}, the average performance improvement of our approach is 22.2\% among all numbers of cores.
In the following, we choose $m=32$ as a representative for other experiments.

Fig. \ref{fig:g_nu} reports the results with different normalized utilizations.
Compared to \textsf{PATH}, the maximum improvement of acceptance ratio is 100\%, which means that there are task set configurations that all existing approaches cannot schedule but our approach can. This further demonstrates the effectiveness of the proposed approach.
Fig. \ref{fig:g_t} presents the result of changing $\alpha$. Different $\alpha$ means different deadlines. Fig. \ref{fig:g_t} shows similar trends as reported in \cite{he2022bounding}.
When $\alpha$ is close to 0, the deadline $D$ approaches $L$, which means that the tasks are more difficult to schedule. However, with the proposed technique of adding edges, the response time bound is greatly reduced and less likely to exceed the deadline. Therefore, tasks using our approach are more likely to be scheduled.
When $\alpha$ increases, the deadline $D$ becomes larger and close to the $vol(G)$. In this case, the performances of all scheduling approaches increase.
The maximum improvement in this experiment is 28.6\% with $\alpha=0.4$ compared to \textsf{PATH}.

Fig. \ref{fig:g_p} reports the result of changing the parallelism factor $\mathit{pf}$.
When $\mathit{pf}$ increases, there are more edges in the generated tasks, which means that the length of the longest path increases. \textsf{FED} assumes that other vertices in the task cannot execute in parallel with the longest path. When the length of the longest path increases, more computing resources are wasted and the performance of \textsf{FED} decreases. 
However, \textsf{PATH} can utilize the information of long paths and our approach can construct long paths such that different long paths can execute in parallel with each other, thus addressing this type of pessimism.
Therefore, the performances of \textsf{PATH} and \textsf{OUR} are not affected by $\mathit{pf}$.  
Due to space limitations, the results of changing the vertex number are not reported.
Same with the trends in Fig. \ref{fig:v}, our approach and federated scheduling in general, are insensitive to the number of vertices in DAG tasks.
Experiments show that the proposed approach consistently outperforms the state-of-the-art by a large margin, which is consistent with the theoretical result that our approach dominates \textsf{PATH}.

