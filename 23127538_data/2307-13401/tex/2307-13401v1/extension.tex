This section considers the scheduling of a task set.
In the task set, each sporadic parallel real-time task is specified as a tuple $(G, D, T)$, where $G$ is the DAG task model in Section \ref{sec:task}, $D$ is the relative deadline and $T$ is the period. We consider constrained deadline, i.e., $D \le T$.
The scheduling algorithm is the widely-used federated scheduling paradigm \cite{li2014analysis}.
In federated scheduling paradigm, parallel tasks are divided into two categories: the heavy tasks (tasks with $vol(G) \ge D$) and the light tasks (tasks with $vol(G) < D$).
Each heavy task is assigned and executed exclusively on a set of cores under a work-conserving scheduler.
All light tasks are treated as sequential sporadic tasks and are scheduled on the remaining cores by sequential multiprocessor scheduling algorithms such as global EDF \cite{baruah2007techniques} or partitioned EDF \cite{baruah2005partitioned}.


In federated scheduling paradigm, to apply the proposed technique, the only remaining question is how to decide the number of cores $m$ required by a heavy task such that its deadline can be satisfied.
In the following, Section \ref{sec:increase} develops a technique to optimize the required number of cores for a DAG task. And Section \ref{sec:task_set} presents the scheduling approach using the techniques in Section \ref{sec:method} and Section \ref{sec:increase}.


\subsection{Optimizing the Number of Cores}
\label{sec:increase}  %increase the length of the longest path

Section \ref{sec:method} considers how to optimize the response time bound for a DAG task given the number of cores.
In contrast, Section \ref{sec:extension} considers computing resource allocation. So the target of this subsection is to optimize the number of cores, instead of the response time bound.

Section \ref{sec:method} enforces that the longest path cannot be increased (i.e., Principle \ref{prp:longest}) when adding edges. Given the number of cores, to reduce the response time bound, this is a reasonable principle, since the length of the longest path has a large impact on the worst-case response time.
However, given the deadline, to reduce the number of cores required by a DAG task, it is possible that lifting the constraint of Principle \ref{prp:longest} can achieve better computing resource allocations.

\textbf{Motivation.}
We illustrate this using the DAG task $G$ in Fig. \ref{fig:dag_example3}. Let the deadline $D=7$.
In $G$, a generalized path list $(\chain_i)_0^2$ where $\chain_0=(v_0, v_1, v_4, v_5)$, $\chain_1=(v_3)$, $\chain_2=(v_2)$ can be identified. Since there are three generalized paths in $G$, if the allocated number of cores $m=3$, the worst-case response time will be the length of the longest path in $G$, which is 6.
If $m=2$, using this generalized path list, the response time bound of $G$ in (\ref{equ:he_bound}) can be computed as
$R(G) =\min\{6+(11-6)/2, 6+(11-6-3)/(2-1)\}=\min\{8.5, 8\}=8$,
which is larger than the deadline.
Also, due to Principle \ref{prp:longest}, no edges can be added using the method in Section \ref{sec:method}.
Therefore, to guarantee that the deadline is satisfied, the allocated number of cores $m$ should be 3.

However, if without Principle \ref{prp:longest}, we can add edge $(v_2, v_3)$ and transforms $G$ into $G'$ shown in Fig. \ref{fig:dag_example4}. In $G'$, a generalized path list $(\chain_i)_0^1$ where $\chain_0=(v_0, v_2, v_3, v_5)$, $\chain_1=(v_1, v_4)$ can be identified.  Since there are two generalized paths in $G'$, if the allocated number of cores $m=2$, the worst-case response time will be the length of the longest path in $G'$, which is 7, no larger than the deadline.
Therefore, if without Principle \ref{prp:longest}, to guarantee that the deadline is satisfied, the allocated number of cores $m$ can be 2.
In this example, by lifting the constraint of Principle \ref{prp:longest}, the allocated number of cores is reduced without compromising the hard real-time requirements.

% Figure environment removed


\textbf{The Proposed Technique.} %\gn{The XXX Technique}
Therefore, to reduce the allocated number of cores, the technique of adding edges without Principle \ref{prp:longest} is proposed.
We introduce a variable called \emph{limit}, which is an upper bound of the length of the longest path when adding edges.
The condition of the \emph{if} statement in Line 3 of Algorithm \ref{alg:first} is replaced with
\begin{equation}\label{equ:increase}
l(u)+r(v) \le \emph{limit}
\end{equation}
Others in Algorithm \ref{alg:framework} and Algorithm \ref{alg:first} are unchanged.
It can be seen that the meaningful range of \emph{limit} is $[len(G), vol(G)]$. If $\emph{limit}=len(G)$, this technique is the method in Section \ref{sec:method}; if $\emph{limit}=vol(G)$, the DAG task will be transformed into a sequential task.
%Note that although the second approach can possibly reduce the response time bound on average, it does not guarantee to dominate the method in \cite{he2022bounding}.
%Different values of \emph{limit} are evaluated in Section \ref{sec:evaluation} to provide guidance on how to choose the value of \emph{limit}.

\textbf{The Proposed Technique with Given Deadline.} %\gn{The XXX Technique with Given Deadlines}
If the deadline $D$ of the DAG task is provided, since the only requirement of real-time scheduling is to ensure that the task can finish before its deadline, we let the condition of the \emph{if} statement in Line 3 of Algorithm \ref{alg:first} be
\begin{equation}\label{equ:deadline}
l(u)+r(v) \le D
\end{equation}
Others in Algorithm \ref{alg:framework} and Algorithm \ref{alg:first} are unchanged.
Recall that during each iteration of Algorithm \ref{alg:framework}, a generalized path $\chain_i$ is computed in Line 7.
So Algorithm \ref{alg:framework}, with Line 3 modified according to (\ref{equ:deadline}), will also output a generalized path list $(\chain_i)_0^k$.

\begin{lemma}\label{lem:increase}
Let $(\chain_i)_0^k$ denote the generalized path list computed by Algorithm \ref{alg:framework} with (\ref{equ:deadline}). If the allocated number of cores $m=k+1$, the DAG task will finish before its deadline.
\end{lemma}
\begin{proof}
Let $G$ denote the DAG task, and $G'$ denote the DAG after Algorithm \ref{alg:framework} with Line 3 modified according to (\ref{equ:deadline}).
Since adding edges does not change the volume, we have $vol(G)=vol(G')$.
By Line 2 of Algorithm \ref{alg:framework}, since the loop iterates until the volume of the residue graph reaches zero, we have $vol(G)=\sum_{i=0}^{k} len(\chain_i)$.
By (\ref{equ:he_bound}),
\begin{align*}
R(G') &= \min \limits_{j \in [0, k]} \left\{ len(G')+\frac{vol(G')-\sum_{i=0}^{j} len(\chain_i)}{m-j} \right\} \\
      &= len(G')+\frac{vol(G)-\sum_{i=0}^{k} len(\chain_i)}{m-k} = len(G')
\end{align*}
By (\ref{equ:deadline}) and the proof of Lemma \ref{lem:longest}, we have $len(G') \le D$.
Therefore, $R(G') \le D$.
\end{proof}


\subsection{The Scheduling Approach}
\label{sec:task_set}
This subsection discusses in the proposed scheduling approach, how to compute the number of cores allocated to a DAG task.
For a DAG task $G$, \cite{he2022bounding} presented a method to compute the allocated number of cores such that the deadline is guaranteed (Theorem 3 of \cite{he2022bounding}).
Let $Path(G)$ denote this method in \cite{he2022bounding}, which takes a DAG $G$ as input and outputs the number of cores $m$.
The technique in Section \ref{sec:method} transforms the DAG task $G$ into another DAG $G'$.
Using the method of \cite{he2022bounding}, we can compute a valid number of cores $Path(G')$.

The technique in Section \ref{sec:increase} also transforms the DAG task $G$ into another DAG $G''$ and computes the allocated number of cores such that the deadline is guaranteed (see Lemma \ref{lem:increase}).
Let $Edge(G)$ denote this method, which takes a DAG $G$ as input and outputs the number of cores $m$.

In the proposed scheduling approach, for a DAG task $G$, the allocated number of cores $m$ is computed as
\begin{equation}\label{equ:task_set}
m= \min \{Path(G'), Edge(G)\}
\end{equation}
Since for a DAG task, both allocated numbers of cores (i.e., $Path(G')$, $Edge(G)$) can guarantee that the deadline is satisfied, we can safely use the smaller one as the final number of cores allocated to the DAG task.

\begin{theorem}\label{thm:task_set}
For scheduling a task set, the approach in Section \ref{sec:extension} dominates the approach in \cite{he2022bounding} in the sense that if \cite{he2022bounding} can schedule a task set, our approach can schedule this task set.
\end{theorem}
\begin{proof}
For an arbitrary task $G$ in this task set, let $G'$ denote the DAG produced by the technique in Section \ref{sec:method}.
By Theorem \ref{thm:domination}, $R(G') \le R(G)$, which means that for a deadline $D$, the number of cores required by $G'$ is no larger than that of $G$.
Therefore, $Path(G') \le Path(G)$, which means that the computed number of cores $m$ in (\ref{equ:task_set}) is no larger than $Path(G)$.
The conclusion is reached.
\end{proof}

Note that both the proposed scheduling approach and the original federated scheduling \cite{li2014analysis} belong to the federated scheduling paradigm, where heavy tasks are allocated and executed exclusively on a set of cores.
The critical difference among various federated scheduling approaches lies in the method of computing resource allocation.
The only difference between our approach and the approach in \cite{li2014analysis} also lies in resource allocation, i.e., the number of cores allocated to heavy tasks.
Compared to federated scheduling approaches such as \cite{li2014analysis, he2022bounding}, benefiting from the proposed techniques that reduce the number of cores for heavy tasks, our scheduling approach significantly improves the system schedulability (see Section \ref{sec:evaluation_set}).
Compared to federated scheduling approaches such as \cite{jiang2017semi, ueter2018reservation, jiang2021virtually}, where heavy tasks can share computing resources to some extent, not only the performance of the proposed approach is better, but also the implementation of the proposed approach is much easier, since in our approach there are not sophisticated policies for heavy tasks to share computing resources.

