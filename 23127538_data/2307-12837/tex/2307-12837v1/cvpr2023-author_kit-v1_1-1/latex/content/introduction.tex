\section{Introduction}
Egocentric action recognition, aiming to understand human activities from a first-person view, has gained significant attention with the rising popularity of wearable devices. 
Those have provided access to a vast amount of data, creating opportunities for applications in augmented reality, robotics, and human-computer interaction.
%However, supervised learning from this data presents challenges due to the substantial time and resource requirements for data labeling. 
%Consequently, leveraging a labeled subset of the data and adapting its knowledge to other visual scenarios with the same task holds promise as a solution. 
% Consequently, we leverage a labeled subset of the data to train the model and adapt it to a new domain using unlabeled samples from the same distribution as the test data.
%a labeled subset of the data and adapting its knowledge to an extended set of data holds promise as a solution.

However, achieving high accuracy on new data %in egocentric action recognition
becomes challenging due to the so called \textit{domain shift}, which refers to the difference in terms of distribution between the training (source) and test set (target), caused by changes in visual appearance or contexts, leading to a significant performance gap. To address this challenge, the Unsupervised Domain Adaptation (UDA) setting has been proposed, where an unlabeled set of samples from the test distribution is available during training for adaptation. % that needs to be addressed.

% Figure environment removed

Human activities tend to follow patterns as actions are strongly influenced by the temporal context in which they are performed. For example, regardless of the person and the environment, \textit{putting something in the fridge} always involves the same steps, as shown in Figure~\ref{fig:teaser}.
Based on this simple observation, we propose to use sequential prediction and the inherent relationships between action sequences to mitigate the negative effects of domain shift in EAR.

% Figure environment removed


%To tackle the domain shift problem in egocentric action recognition,
%We propose an approach inspired by the importance of sequential prediction and the inherent relationships between action sequences. While existing methods typically treat each action as an atomic unit~\cite{chen2019temporal,planamente2022polito, planamente2022domain,kim2021learning}, 

%Recently, Kazakos \emph{et al.}~\cite{kazakos_temporal2021} proposed an attention mechanism to incorporate the context derived from the surrounding actions in action recognition. %we recognise that actions often occur in a sequential manner to accomplish a primary goal. By incorporating information about previous and subsequent actions, we aim to improve action prediction accuracy and reduce the domain gap.
%Inspired by the idea of incorporating information about previous and subsequent actions, 

Our approach consists in replacing random action clips in a source domain sequence with action clips from the target domain that represent the same action. By training the model to predict the sequence of actions in the modified sequences, we encourage the model to learn common sequence patterns that exist across different domains, aiming at mitigating the influence of domain shift. % and improve the model's performance.
%Our approach involves introducing a swapping method, which adapts sequence prediction in the target domain using a self-supervised technique. This method leverages pseudo-labeling of the target domain and swaps labels with high confidence from the source dataset. By training the model with swapped labels, we encourage it to learn the sequence patterns and reduce the impact of domain shift.
Additionally, by taking inspiration from~\cite{kazakos_temporal2021}, we integrate a language model into our framework to better incorporate the context derived from the surrounding actions. 
%The latter helps normalize the visual predictions based on the context of the task in the source domain, further enhancing the accuracy of action recognition. 
Finally, we compute a co-occurrence matrix on the action of the source domain to filter out improbable predictions of verb and noun pairs, thus further refining the prediction process, as done in~\cite{cheng2022team}.

%By combining these techniques, we aim to enhance the robustness of sequence prediction, improve the understanding of visual information, and ultimately achieve higher accuracy in egocentric action recognition in the presence of domain shifts.




We evaluate our approach on the EPIC-Kitchens Unsupervised Domain Adaptation challenge~\cite{Damen2022RESCALING}, showcasing the effectiveness of exploiting sequential information in addressing the domain gap. %The results demonstrate the advantages and potential of our approach in addressing the challenges of domain shift in egocentric action recognition.