\section{Theory} \label{sec:theory}
%
% Figure environment removed
%
%
\subsection{BERT-inspired Neural Data Representations}
\label{ssec:bendr}
BENDR \cite{BENDR} is inspired by language modeling techniques that have found success also outside text analysis, in self-supervised end-to-end speech recognition and image recognition. It aims to develop EEG models for better brain-computer interface (BCI) classification, diagnosis support, and other EEG-based analyses. Importantly, the approach being based on self-supervision can learn from any EEG data using only unlabeled data.
The main goal of BENDR is to create self-supervised representations with minimal robust to context boundaries  like datasets and  human subjects. The approach is expected to be transferable to future unseen EEG datasets recorded from unseen subjects, different hardware, and different tasks. It can be used as-is or fine-tuned for various downstream EEG classification tasks.

\quad The architecture is based on \verb|wav2vec 2.0| \cite{wave2vec} developed for speech processing and  consists of two stages. The first stage takes raw data, and down-samples it using a stack of short-receptive field 1D convolutions, resulting in a sequence of vectors called BENDR. The second stage uses a transformer encoder \cite{vaswani2017attention} to map BENDR to a new sequence related to the target task. Down-sampling is achieved through strides, and the transformer follows the standard implementation with some modifications. The entire sequence is then classified, with a fixed token implemented as the first input for downstream tasks \cite{BERT}.
BENDR differs from the speech-specific architecture  in two ways: (1) BENDR is not quantized for pre-training targets, and (2) it has many incoming channels, unlike \verb|wav2vec 2.0| which uses quantization and is based on a single channel of raw audio. The 1D convolutions are preserved in BENDR, to reduce complexity. We note that BENDR down-samples at a lower factor than \verb|wav2vec 2.0|, here resulting in an effective sampling rate of $\approx 2.67$ Hz equivalent to a feature window of $\approx 375$ ms.

%\subsubsection{Downstream architecture}
\subsection{Linear Head BENDR}
For downstream fine-tuning, we use a version where the pre-trained transformer modules are ignored, such that the pre-trained convolutional BENDR stage is used as representation, see \cite{BENDR}. A consistent-length representation is created by dividing the BENDRs into four contiguous sub-sequences, averaging each sub-sequence, and concatenating them. A new linear layer with softmax activation is added to classify the downstream targets based on this concatenated vector of averaged BENDR. We call this the Linear Head BENDR (LHB) model and the structure is illustrated in Figure \ref{fig:linear_head_bendr}. 

The final LHB architecture consists of the following components:
\begin{enumerate}
    \item \textbf{Feature encoder:} Fine-tunes the pre-trained parameters and uses six convolution blocks, each containing a temporal convolution, group normalization, and a GELU activation function to produce a BENDR of length 512.
    \item \textbf{Encoding augment:} Involves masking and contextualizing the BENDR, with 10\% of the BENDR masked and 10\% of the channels dropped, while relative positional embeddings from the pre-trained task are added to the BENDR and further preprocessed.
    \item \textbf{Summarizer:} Applies adaptive average pooling to create four contiguous sub-sequences, averaging each sub-sequence to ensure the model's independence from the input length of EEG recordings.
    \item \textbf{Extended classifier:} Flattens the four sub-sequences, passes them through a fully connected layer to reduce their dimension, applies a dropout layer, uses a ReLU activation function, and normalizes the output using batch normalization.
    \item \textbf{Classifier:} Consists of a linear layer with a softmax activation function, which performs the classification task.
\end{enumerate}

% \begin{enumerate}
%     \item \textbf{Feature encoder:} Fine-tunes the pre-trained parameters and uses six convolution blocks, each containing a 1D temporal convolution with 512 filters, group normalization, and GELU activation function to produce BENDR of length 512.
%     \item \textbf{Encoding augment:} Involves masking and contextualizing the BENDR, with 10\% of the BENDR masked and 10\% of the channels dropped, while relative positional embeddings from the pre-trained task are added to the BENDR and further preprocessed.
%     \item \textbf{Summarizer:} Applies 1D adaptive average pooling to create four contiguous sub-sequences, averaging each sub-sequence to ensure the model's independence from the input length of EEG recordings.
%     \item \textbf{Extended classifier:} Flattens the four sub-sequences, passes them through a fully connected layer to reduce their dimension, applies a dropout layer, uses a ReLU activation function, and normalizes the output using batch normalization.
%     \item \textbf{Classifier:} Consists of a linear layer with a softmax activation function, which performs the classification task.
% \end{enumerate}
%
% Figure environment removed
%
\subsection{Testing with Concept Activation Vectors (TCAV)}
\label{ssec:tcav}
%
Testing with Concept Activation Vectors (TCAV) is a technique used to quantify the degree to which layers of neural networks align with human-defined concepts \cite{kim2018interpretability}. The method is general in the sense that it is not confined to the particular structure of the network nor to the data type. In its essence, TCAV can be broken down into five steps

\quad First, the process involves defining human-aligned concepts and representing them in the data. Alongside these, data from the target class must also be present for evaluation purposes. Furthermore, to establish the directions of the concept activation vector in the latent space, it is necessary to have a collection of concept-negative or random examples.

\quad Second, the layer activations of the concept input and the random input, respectively, are collected and separated by training 
a binary linear classifier. Then, the concept activation vector, $v_c^l$ is defined as the normal vector to the hyperplane that separates the two classes (concept vs. random).

\quad Third, for a layer $l$ in the network, the directional derivatives for the target class $k$ along the
learned activation vector for concept $C$ is used to calculate how sensitive the prediction of the network is to changes in the input data in the direction of $C$. We can quantify the sensitivity by
\begin{equation}
    S_{C,k,l}(\bm{x}) = \nabla h_{l,k} (f_l(\bm{x}))\cdot \bm{v}_C^l,
\end{equation}
where $h_{l,k}$ is defined as the function that maps activations in layer $l$ through the remaining network and predicts class $k$.

\quad Fourth, computing the sensitivity for several target examples, $\bm{x} \in X_k$, the TCAV score is defined as the ratio of examples that have positive sensitivity, i.e.,
\begin{equation}
    \vspace{-3pt}
    \text{TCAV}_{C,k,l} = \frac{|\{\bm{x} \in X_k : S_{C,k,l}(\bm{x}) > 0 \}|}{|X_k|}.
\end{equation}
In this way, concept activation vectors that are positively aligned with target activations have a TCAV score close to 1 and concept activation vectors that are negatively aligned with target activations have a TCAV score close to 0.

\quad Fifth and final, collecting samples of TCAV scores over several training runs, a suitable statistical test is used to assess the statistical significance of concept activation vectors aligning with the activation of target examples. The null hypothesis of the test is that half of the examples have positive sensitivity and the other half have negative or zero sensitivity, i.e.,
%
\begin{equation}
    H_0: \text{TCAV}_{C,k,l} = 0.5.
\end{equation}
%
Concepts $C$ for which the null hypothesis is rejected thus relate to the target class prediction, and may bring positive or negative evidence for the given target $k$.
%
\subsection{Source localization}
\label{ssec:sourcelocalisation}
Source localization for EEG data involves mapping electrical signals recorded on the scalp surface to corresponding regions on the cortical surface of the brain. This process uses a head model and the EEG data collected from electrodes placed on the scalp. The reconstruction is a grid of dipolar sources. The solution to this ill-posed problem is called the lead field and there exist many different ways to obtain this solution. In this work, we use the exact low-resolution electromagnetic tomography (eLORETA) method implemented in the MNE library \cite{doi:10.1098/rsta.2011.0081}.

\quad The eLORETA approach presupposes that the EEG measurements of the electric field present on the scalp reflect dipolar sources located in the cerebral cortex. These are conceptually modeled as a three-dimensional distribution of dipoles. The spatial resolution of eLORETA is relatively coarse, which can make pinpointing exact cortical sources challenging. However, for our purpose of estimating aggregated source activity over broadly defined brain regions, such reduced resolution is not an issue.

%\quad eLORETA assumes that the EEG measurements of the quasi-static electric field on the scalp reflect dipolar sources in the cortex, modeled as a three-dimensional distribution of dipoles. It is worth noting that the spatial resolution of eLORETA is relatively low, making it difficult to precisely locate cortical sources. However, as we are simply interested in reconstructing aggregate sources  across extended cortical areas, the comparatively low resolution is not a problem.
