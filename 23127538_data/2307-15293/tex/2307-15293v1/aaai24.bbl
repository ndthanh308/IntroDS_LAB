\begin{thebibliography}{23}
\providecommand{\natexlab}[1]{#1}

\bibitem[{Auer et~al.(2007)Auer, Bizer, Kobilarov, Lehmann, Cyganiak, and
  Ives}]{dbpedia}
Auer, S.; Bizer, C.; Kobilarov, G.; Lehmann, J.; Cyganiak, R.; and Ives, Z.
  2007.
\newblock DBpedia: A Nucleus for a Web of Open Data.
\newblock In Aberer, K.; Choi, K.-S.; Noy, N.; Allemang, D.; Lee, K.-I.; Nixon,
  L.; Golbeck, J.; Mika, P.; Maynard, D.; Mizoguchi, R.; Schreiber, G.; and
  Cudr{\'e}-Mauroux, P., eds., \emph{The Semantic Web}, 722--735. Berlin,
  Heidelberg: Springer Berlin Heidelberg.

\bibitem[{Chang et~al.(2008)Chang, Ratinov, Roth, and Srikumar}]{chang2008}
Chang, M.-W.; Ratinov, L.; Roth, D.; and Srikumar, V. 2008.
\newblock Importance of Semantic Representation: Dataless Classification.
\newblock In \emph{Proceedings of the 23rd National Conference on Artificial
  Intelligence - Volume 2}, AAAI’08, 830–835. AAAI Press.
\newblock ISBN 9781577353683.

\bibitem[{Chen et~al.(2022)Chen, Zhang, Zheng, and Mao}]{plm3}
Chen, Q.; Zhang, R.; Zheng, Y.; and Mao, Y. 2022.
\newblock Dual Contrastive Learning: Text Classification via Label-Aware Data
  Augmentation.
\newblock \emph{CoRR}, abs/2201.08702.

\bibitem[{Chu, Stratos, and Gimpel(2020)}]{chu2020}
Chu, Z.; Stratos, K.; and Gimpel, K. 2020.
\newblock Natcat: Weakly Supervised Text Classification with Naturally
  Annotated Datasets.
\newblock \emph{CoRR}, abs/2009.14335.

\bibitem[{Devlin et~al.(2019)Devlin, Chang, Lee, and Toutanova}]{bert2019}
Devlin, J.; Chang, M.-W.; Lee, K.; and Toutanova, K. 2019.
\newblock {BERT}: Pre-training of Deep Bidirectional Transformers for Language
  Understanding.
\newblock In \emph{Proceedings of the 2019 Conference of the North {A}merican
  Chapter of the Association for Computational Linguistics: Human Language
  Technologies, Volume 1 (Long and Short Papers)}, 4171--4186. Minneapolis,
  Minnesota: Association for Computational Linguistics.

\bibitem[{Ding et~al.(2022)Ding, Yang, Deng, Zhang, and Roth}]{tewiki}
Ding, H.; Yang, J.; Deng, Y.; Zhang, H.; and Roth, D. 2022.
\newblock Towards Open-Domain Topic Classification.
\newblock In \emph{Proceedings of the 2022 Conference of the North American
  Chapter of the Association for Computational Linguistics: Human Language
  Technologies: System Demonstrations}, 90--98. Hybrid: Seattle, Washington +
  Online: Association for Computational Linguistics.

\bibitem[{Gera et~al.(2022)Gera, Halfon, Shnarch, Perlitz, Ein-Dor, and
  Slonim}]{selftrain}
Gera, A.; Halfon, A.; Shnarch, E.; Perlitz, Y.; Ein-Dor, L.; and Slonim, N.
  2022.
\newblock Zero-Shot Text Classification with Self-Training.
\newblock In \emph{Proceedings of the 2022 Conference on Empirical Methods in
  Natural Language Processing}, 1107--1119. Abu Dhabi, United Arab Emirates:
  Association for Computational Linguistics.

\bibitem[{Liu et~al.(2023)Liu, Zhang, Chen, Wu, Luu, Chang, and
  Bing}]{zeroshot1}
Liu, C.; Zhang, W.; Chen, G.; Wu, X.; Luu, A.~T.; Chang, C.~H.; and Bing, L.
  2023.
\newblock Zero-Shot Text Classification via Self-Supervised Tuning.
\newblock arXiv:2305.11442.

\bibitem[{Liu et~al.(2022)Liu, Ji, Fu, Tam, Du, Yang, and Tang}]{liu2022p}
Liu, X.; Ji, K.; Fu, Y.; Tam, W.; Du, Z.; Yang, Z.; and Tang, J. 2022.
\newblock P-tuning: Prompt tuning can be comparable to fine-tuning across
  scales and tasks.
\newblock In \emph{Proceedings of the 60th Annual Meeting of the Association
  for Computational Linguistics (Volume 2: Short Papers)}, 61--68.

\bibitem[{Liu et~al.(2019)Liu, Ott, Goyal, Du, Joshi, Chen, Levy, Lewis,
  Zettlemoyer, and Stoyanov}]{roberta}
Liu, Y.; Ott, M.; Goyal, N.; Du, J.; Joshi, M.; Chen, D.; Levy, O.; Lewis, M.;
  Zettlemoyer, L.; and Stoyanov, V. 2019.
\newblock RoBERTa: {A} Robustly Optimized {BERT} Pretraining Approach.
\newblock \emph{CoRR}, abs/1907.11692.

\bibitem[{Mikolov et~al.(2013)Mikolov, Chen, Corrado, and Dean}]{word2vec}
Mikolov, T.; Chen, K.; Corrado, G.; and Dean, J. 2013.
\newblock Efficient Estimation of Word Representations in Vector Space.
\newblock \emph{Proceedings of Workshop at ICLR}, 2013.

\bibitem[{Pennington, Socher, and Manning(2014)}]{glove}
Pennington, J.; Socher, R.; and Manning, C. 2014.
\newblock {G}lo{V}e: Global Vectors for Word Representation.
\newblock In \emph{Proceedings of the 2014 Conference on Empirical Methods in
  Natural Language Processing ({EMNLP})}, 1532--1543. Doha, Qatar: Association
  for Computational Linguistics.

\bibitem[{Reimers and Gurevych(2019)}]{reimers-2019-sentence-bert}
Reimers, N.; and Gurevych, I. 2019.
\newblock Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks.
\newblock In \emph{Proceedings of the 2019 Conference on Empirical Methods in
  Natural Language Processing}. Association for Computational Linguistics.

\bibitem[{Schick and Sch{\"u}tze(2020)}]{schick2020exploiting}
Schick, T.; and Sch{\"u}tze, H. 2020.
\newblock Exploiting cloze questions for few shot text classification and
  natural language inference.
\newblock \emph{arXiv preprint arXiv:2001.07676}.

\bibitem[{Sivarajkumar and Wang(2022)}]{t5-zero}
Sivarajkumar, S.; and Wang, Y. 2022.
\newblock HealthPrompt: A Zero-shot Learning Paradigm for Clinical Natural
  Language Processing.
\newblock arXiv:2203.05061.

\bibitem[{van~de Kar et~al.(2022)van~de Kar, Xia, Chen, and
  Artetxe}]{zeroshot3}
van~de Kar, M.; Xia, M.; Chen, D.; and Artetxe, M. 2022.
\newblock Don{'}t Prompt, Search! Mining-based Zero-Shot Learning with Language
  Models.
\newblock In \emph{Proceedings of the 2022 Conference on Empirical Methods in
  Natural Language Processing}, 7508--7520. Abu Dhabi, United Arab Emirates:
  Association for Computational Linguistics.

\bibitem[{Yang et~al.(2022)Yang, Wang, Gan, Zhu, Zhang, Wu, Gao, Zhang, and
  Sakai}]{zeroshot2}
Yang, P.; Wang, J.; Gan, R.; Zhu, X.; Zhang, L.; Wu, Z.; Gao, X.; Zhang, J.;
  and Sakai, T. 2022.
\newblock Zero-Shot Learners for Natural Language Understanding via a Unified
  Multiple Choice Perspective.
\newblock In \emph{Proceedings of the 2022 Conference on Empirical Methods in
  Natural Language Processing}, 7042--7055. Abu Dhabi, United Arab Emirates:
  Association for Computational Linguistics.

\bibitem[{Yang et~al.(2021)Yang, Song, King, and Xu}]{semi}
Yang, X.; Song, Z.; King, I.; and Xu, Z. 2021.
\newblock A Survey on Deep Semi-supervised Learning.
\newblock \emph{CoRR}, abs/2103.00550.

\bibitem[{Yang et~al.(2019)Yang, Dai, Yang, Carbonell, Salakhutdinov, and
  Le}]{plm1}
Yang, Z.; Dai, Z.; Yang, Y.; Carbonell, J.; Salakhutdinov, R.~R.; and Le, Q.~V.
  2019.
\newblock XLNet: Generalized Autoregressive Pretraining for Language
  Understanding.
\newblock In Wallach, H.; Larochelle, H.; Beygelzimer, A.; d\textquotesingle
  Alch\'{e}-Buc, F.; Fox, E.; and Garnett, R., eds., \emph{Advances in Neural
  Information Processing Systems}, volume~32. Curran Associates, Inc.

\bibitem[{Zaheer et~al.(2020)Zaheer, Guruganesh, Dubey, Ainslie, Alberti,
  Ontanon, Pham, Ravula, Wang, Yang, and Ahmed}]{plm2}
Zaheer, M.; Guruganesh, G.; Dubey, K.~A.; Ainslie, J.; Alberti, C.; Ontanon,
  S.; Pham, P.; Ravula, A.; Wang, Q.; Yang, L.; and Ahmed, A. 2020.
\newblock Big Bird: Transformers for Longer Sequences.
\newblock In Larochelle, H.; Ranzato, M.; Hadsell, R.; Balcan, M.; and Lin, H.,
  eds., \emph{Advances in Neural Information Processing Systems}, volume~33,
  17283--17297. Curran Associates, Inc.

\bibitem[{Zhang, Wang, and Yang(2023)}]{gpt-zero}
Zhang, R.; Wang, Y.-S.; and Yang, Y. 2023.
\newblock Generation-driven Contrastive Self-training for Zero-shot Text
  Classification with Instruction-tuned GPT.
\newblock arXiv:2304.11872.

\bibitem[{Zhang, Zhao, and LeCun(2015)}]{yahoo-agnews}
Zhang, X.; Zhao, J.; and LeCun, Y. 2015.
\newblock Character-level Convolutional Networks for Text Classification.
\newblock In Cortes, C.; Lawrence, N.; Lee, D.; Sugiyama, M.; and Garnett, R.,
  eds., \emph{Advances in Neural Information Processing Systems}, volume~28.
  Curran Associates, Inc.

\bibitem[{Zou et~al.(2018)Zou, Yu, Kumar, and Wang}]{unsuper}
Zou, Y.; Yu, Z.; Kumar, B.~V.; and Wang, J. 2018.
\newblock Unsupervised Domain Adaptation for Semantic Segmentation via
  Class-Balanced Self-Training.
\newblock In \emph{Proceedings of the European Conference on Computer Vision
  (ECCV)}.

\end{thebibliography}
