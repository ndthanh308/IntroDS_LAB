\section{Preliminaries}

\begin{lemma}[{\citet[Lemma 3]{kakade2008generalization}}]\label{lem:free2}
Suppose $X_1, \ldots, X_T$ is a martingale difference sequence with $\left|X_t\right| \leq b$. Let
$$
\operatorname{Var}_t X_t=\operatorname{Var}\left(X_t \mid X_1, \ldots, X_{t-1}\right)
$$
Let $V=\sum_{t=1}^T \operatorname{Var}_t X_t$ be the sum of conditional variances of $X_t$ 's. Further, let $\sigma=\sqrt{V}$. Then we have, for any $\delta<1 / e$ and $T \geq 3$,
$$
\Pr\left(\sum_{t=1}^T X_t>\max \{2 \sigma, 3 b \sqrt{\ln (1 / \delta)}\} \sqrt{\ln (1 / \delta)}\right) \leq 4 \ln (T) \delta.
$$	
\end{lemma}


\begin{lemma}[{\citet[Lemma 3]{foster2020beyond}}]\label{lem:igw-general}
	For any vector $\^y\in[0,1]^A$, if we define $p$ to be
	\begin{align*}
		p(a)
=		\begin{cases}
			\frac{1}{A+\gamma \big(\^y(\^a)-\^y(a)\big)} & \text{if } a\not=\^a,\\
			1-\sum_{a\not=\^a}p(a) & \text{if } a=\^a
		\end{cases}
	\end{align*}
	where $\^a=\argmax_a \^y(a)$, then for any $y^\star\in[0,1]^A$ and $\gamma>0$, we have
	$$
		\E_{a\sim p}\left[\Big(y^\star(a^\star)-y^\star(a)\Big)-\gamma\Big(\^y(a)-y^\star(a)\Big)^2\right]\leq \frac{A}{\gamma}.
	$$
\end{lemma}

\begin{lemma}[{\citet[Lemma 2]{zhu2022efficient}}]\label{lem:freedman}
Let $(Z_t)_{t \leq T}$ to be real-valued sequence of positive random variables adapted to a filtration $\mathfrak{F}_t$. If $\left|Z_t\right| \leq B$ almost surely, then with probability at least $1-\delta$,
$$
\sum_{t=1}^T Z_t \leq \frac{3}{2} \sum_{t=1}^T \mathbb{E}_t\left[Z_t\right]+4 B \log \left(2 \delta^{-1}\right),
$$
and
$$
\sum_{t=1}^T \mathbb{E}_t\left[Z_t\right] \leq 2 \sum_{t=1}^T Z_t+8 B \log \left(2 \delta^{-1}\right).
$$
\end{lemma}














\begin{lemma}[Performance difference lemma \citep{agarwal2019reinforcement}]\label{lem:pdl}
	For any two policies $\pi$ and $\pi'$ and any state $x_0\in\+X$, we have
	\begin{align*}
		V^\pi_0(x_0)-V^{\pi'}_0(x_0)
		=
		\sum_{h=0}^{H-1} \E_{x_h,a_h\sim d^\pi_{x_0,h}} \big[A^{\pi'}_h(x_h,a_h)\big]
	\end{align*}
	where $A^\pi_h(x,a)=Q^\pi_h(x,a)-V^\pi_h(x,a)$ and $d^\pi_{x_0,h}(x,a)$ is the probability of $\pi$ reaching the state-action pair $(x,a)$ at time step $h$ starting from initial state $x_0$.
\end{lemma}






\begin{lemma}\label{lem:kl-bern}
	For any two Bernoulli distributions $\@{Bern}(x)$ and $\@{Bern}(y)$ with $x,y\in[b,1-b]$ for some $0<b\leq 1/2$, the KL divergence is bounded as
	\begin{align*}
		\@{KL}\Big(\@{Bern}(x),\@{Bern}(y)\Big)\leq \frac{2(x-y)^2}{b}.
	\end{align*}
\end{lemma}
\begin{proof}[Proof of \Cref{lem:kl-bern}]
Denote $\Delta=x-y$. Then, by definition, we have
	\begin{align*}
		\@{KL}\Big(\@{Bern}(x),\@{Bern}(y)\Big)
		= & x\ln \frac{x}{y} + (1-x)\ln \frac{1-x}{1-y}\\
		= & x\ln \frac{x}{x-\Delta} + (1-x)\ln \frac{1-x}{1-x+\Delta}\\
		= & x\ln \left(1+\frac{\Delta}{x-\Delta}\right) + (1-x)\ln\left(1- \frac{\Delta}{1-x+\Delta}\right)
	\end{align*}
	Since $\ln(1+x)\leq x$ for all $x>-1$, we have
	\begin{align*}
		\@{KL}\Big(\@{Bern}(x),\@{Bern}(y)\Big)
		\leq & x\cdot \frac{\Delta}{x-\Delta} - (1-x)\cdot \frac{\Delta}{1-x+\Delta}\\
		= & \Delta\cdot\left( \frac{x}{x-\Delta} - \frac{1-x}{1-x+\Delta}\right)\\
		= & \Delta\cdot\left(\frac{\Delta}{x-\Delta} + \frac{\Delta}{1-x+\Delta}\right)\\
		\leq & \Delta^2\cdot\left(\frac{1}{y} + \frac{1}{1-y}\right)
		\leq \frac{2\Delta^2}{b}.
	\end{align*}
\end{proof}






















