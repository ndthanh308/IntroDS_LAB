\section{Results}\label{sec:results}
We first go over some sample results for tasks 1-3 followed by offline metrics (retrieval performance, generation quality) and human perceptual study results.

\subsection{Sample results for tasks 1, 2 and 3}

\paragraph*{Task 1 (vanilla staging):} sample results for task 1 (obtained via pix2pix) are shown in Figures~\ref{fig:cp_example_1} (b) and \ref{fig:cp_example_2} (b). Compared to the original image with the background, the generated image has a lot of artifacts, and does not look so realistic. As we discuss below, the copy-paste staging results look more realistic.

\paragraph*{Task 2 (copy-paste staging):} Figures~\ref{fig:cp_example_1} (e) and \ref{fig:cp_example_2} (e) show sample results for task 2 using the proposed copy-paste staging approach. Overall, the copy-paste staging results look much more realistic compared to pix2pix results.
% Figure environment removed

% Figure environment removed
\paragraph*{Task 3 (parallax animation)} A sample for the generated image-to-parallax animation: \url{https://www.dropbox.com/s/9at5gz24ukhf2gi/product_staging_image_to_parallax_demo.mp4?dl=0}.

\subsection{Offline metrics}
\paragraph*{Similar product image retrieval performance:} a retrieved image is considered similar, if it belongs to the same subcategory as the input product. For example, if the input is a queen bed of subcategory "Furniture $>$ Bedroom $>$ Headboards $>$ Queen", the retrieved product should fall into the same subcategory.
Table~\ref{table:retrieval_res} shows precision-recall results for similar products retrieval. For evaluation, we considered furniture subcategories (42 in total) with number of images $\geq 20$.
\begin{table}[t]
%\vspace{-15pt}
\setlength\tabcolsep{4.3pt}
\centering
\caption{Precision/Recall results for image retrieval}
\label{table:retrieval_res}
\begin{tabular}{ c|c|c|c } 
\toprule
 & @1 & @3 & @5 \\ \midrule \midrule
precision@k & 0.468 & 0.409 & 0.374 \\ 
recall@k & 0.468 & 0.664 & 0.734 \\
\bottomrule
\end{tabular}
\vspace{-8pt}
\end{table}

\paragraph*{Generation quality:} we measure the performance of our copy-paste staging results by evaluating Frechet inception distance (FID) \cite{heusel2017gans}. FID is a popular metric for evaluating the quality of images created by GANs. The Wasserstein-2 distance in FID is calculated by comparing the features distribution of in-painted images with the distribution of real images, where the features are generated by a pre-trained InceptionV3 model. The comparison results are shown in Table~\ref{table:FID}. Since the copy-paste method in-paints only small regions of image around an object, it achieves much better FID score than vanilla staging. WBL further improves FID score in both methods.

\begin{table}[t]
%\vspace{-15pt}
\setlength\tabcolsep{4.3pt}
\centering
\caption{FID scores for various staging and training options}
\label{table:FID}
\begin{tabular}{c|c|c}
\toprule
 & EdgeConnect         & EdgeConnect \\ 
&  (baseline)          &  + WBL \\ \midrule \midrule
vanilla staging & 127.77 & 122.22  \\ %\midrule
copy-paste staging & 38.44 & 37.44 \\
\bottomrule
\end{tabular}
\vspace{-8pt}
\end{table}

\subsection{Human evaluation}
For a human perceptual study, we performed pairwise comparison tests, where experts were given two images at once, and the task was to determine which image appears more realistic (natural). For each comparison, we used three independent expert judgements, and decided the winner by majority voting. We performed three such tests: 1) 100 comparisons of vanilla staging images vs. ground truth images; 2) 100 copy-paste staging (with WBL) vs. ground truth; 3) 100 copy-paste (with WBL) vs. vanilla staging. The study showed:
\begin{itemize}
    \item 0\% of pix2pix images were better than ground truth;
    \item 3\% of copy-paste images were better than ground truth;
    \item 76\% of copy-paste images were better than pix2pix.
\end{itemize}
The above results clearly demonstrate the superiority of copy-paste staging and are in line with offline FID scores.

%\subsubsection{Editorial review}
%\subsection{Online results}