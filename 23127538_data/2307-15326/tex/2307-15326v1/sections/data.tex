\section{Data} \label{sec:data}
For our experiments, we sampled data from Yahoo Gemini DPA (spanning November-December 2020). With an impression threshold of $10,000$, we collected a sample of $\sim 18,899$ ads (each corresponding to a product), from which $11,927$ had solid backgrounds, and the rest $6,972$ had staged backgrounds. Each product in the sample belongs to a certain hierarchical category, e.g. "Kids $>$ Kids Nightstands", "Furniture $>$ Bedroom $>$ Headboards $>$ Queen", "Shoe $>$ Heel $>$ Oxford Heel". For our experiments, we considered only furniture images with staged backgrounds, which left us with $2071$ images. Top-frequent subcategories with instance counts for the ``Furniture" category (as in our sample) are shown in Figure~\ref{fig:furn_subcat}. 

% Figure environment removed



\begin{comment}
\subsection{Public dataset: DUTS}
%\subsubsection{TBD. Amazon, and MIT?}
We also use the DUTS image dataset \cite{wang2017learning} in our experiments. DUTS provides 10,553 training images and 5,019 testing images, containing challenging saliency detection scenarios. Specifically, we look up the synset ID of WordNet and map the DUTS images to different categories, and mainly focus on images in furniture category.This dataset is used for training the GAN models used in our proposed approaches as described in Section \ref{sec:method}.
\end{comment}
