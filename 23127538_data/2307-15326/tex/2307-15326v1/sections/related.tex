\section{Related work} \label{sec:related}
\paragraph*{Online advertising:} In online advertising, the ad creative (text and image) plays an important role in influencing online users towards brand awareness, clicks and purchases \cite{gemx_kdd,visualtextrank,recsys_2023_shaunak}. Studying ad images and text using state-of-the-art deep learning models in computer vision and natural language processing (NLP) is an emerging area of research. In \cite{cvpr_kovashka}, ad image content was studied using computer vision models, and their dataset had manual annotations for: ad category, reasons to buy products advertised in the ad, and expected user response given the ad.
%However, \emph{understanding ad creatives from a brand's perspective} was missing in both \cite{kovashka_eccv2018, cvpr_kovashka}, and 
Using this dataset, \cite{self_recsys2019, www20_joey} used ranking models to recommend themes for ad creative design using a brand's Wikipedia page. In \cite{cikm2020_createbetterads}, object tag recommendations for improving an ad image was studied using data from A/B tests. Although related to ads, the above methods are not applicable in our setup since none of them are image generation methods.

\paragraph*{GANs for image generation}
Generative Adversarial Networks (GANs) are a popular approach for image generation. While vanilla GANs~\cite{goodfellow2014generative} generate images from random noise, Conditional GANs~\cite{mirza2014conditional} also allow to use extra information in a generative process. Recently developed \verb|pix2pix| method~\cite{isola2017image} and its successors~\cite{wang2018high} use Conditional GANs for image-to-image generation optimizing GAN objective together with distance to a target image. While we focus on GANs in this paper, our copy-paste staging approach can be generalized to more recent diffusion models \cite{dalle} (discussed in Section~\ref{sec:discussion}).

\paragraph*{Saliency detection}
Saliency detection in product images is needed to understand which parts of an image correspond to the main product being advertised (as opposed to the background). Salient object detection (SOD) aims to detect the most visually attractive objects with precise boundaries in images (\emph{i.e.}, it returns a boundary map which can be used to segment out objects from the image). With the introduction of convolutional neural networks (CNNs) in computer vision, SOD accuracy has witnessed remarkable improvements. Recently, U\textsuperscript{2}-Net \cite{qin2020u2} achieved state-of-the-art results for saliency detection by using a nested version of U-Net \cite{ronneberger2015u}-like architecture to capture richer local and global information. In our proposed approaches, we use saliency detection via U\textsuperscript{2}-Net as a building block.

