% Chapter 1

\chapter{Biomedical Natural Language Processing and Text Mining} % Main chapter title

\label{Chapter2} % For referencing the chapter elsewhere, use \ref{Chapter1}

\minitoc


This chapter presents an introduction to natural language processing (NLP) and text mining, particularly in the biomedical domain. It also describes a broader classification framework involving QA systems based on different criteria, and important factors that distinguish restricted-domain QA from open-domain.

%----------------------------------------------------------------------------------------

% Define some commands to keep the formatting separated from the content
%\newcommand{\keyword}[1]{\textbf{#1}}
%\newcommand{\tabhead}[1]{\textbf{#1}}
%\newcommand{\code}[1]{\texttt{#1}}
%\newcommand{\file}[1]{\texttt{\bfseries#1}}
%\newcommand{\option}[1]{\texttt{\itshape#1}}

%----------------------------------------------------------------------------------------
\section{Introduction}
\label{Chapter2_2.1}

The volume of published biomedical scientific articles, and therefore the underlying knowledge base, is expanding at an increasing rate. \citep{Cohen_2005}. For instance, the MEDLINE\footnote{MEDLINE: \url{https://www.nlm.nih.gov/pubs/factsheets/medline.html}} 2016 database contains over 24 million citations, and it is growing at the rate of 700,000 new scientific articles per year. With such explosive growth of biomedical literature, it is extremely challenging to absorb all relevant information even within one's own field of biomedical research. To handle such amount of information, the interest for the biomedical text mining from biomedical texts (e.g., scientific articles and electronic health records) has experienced a huge increment by the research community. Text mining and NLP refer to understanding and analyzing natural human language by using computer methods and tools. In particular, most text mining applications rely, to varying degrees, on NLP techniques and tools.


In this chapter we will review some concepts and techniques we use as constructing blocks for the new methodologies we present and which are referred throughout this thesis work. We start this chapter by describing in section~\ref{Chapter2_2.2} some related tasks to the natural language processing, such as sentence splitting, word tokenization, n-grams, part-of-speech tagging, stemming and lemmatization, and parsing. We also describe the most widely used NLP toolkits/platforms for the most common NLP tasks. We then proceed
with the presentation in section~\ref{Chapter2_2.3} of the biomedical text mining tasks, such as information retrieval, document classification, named entity recognition, relation or information extraction, document summarization, and question answering. We next describe in section~\ref{Chapter3_2} a broader classification framework involving QA systems based on different criteria. We finally present in section~\ref{Chapter3_3} important factors that distinguish restricted-domain QA from open-domain.


\section{Natural Language Processing}
\label{Chapter2_2.2}
Natural Language Processing (``NLP'' or ``BioNLP'' for the biomedical domain) is differentiated from text mining in that while NLP attempts to analyse and understand the meaning of text as a whole, text mining focus on solving a specific problem by discovering relevant information or explicit and implicit facts in text (possibly using some NLP methods in the process) \citep{Cohen_2005}. Indeed, NLP is generally a component of a text mining application that performs some pre-processing steps that essentially helps a machine ``read'' text \citep{Friedman_2013,Sun_2017,Kreimeyer_2017}.  In this section, we describe some of these pre-processing steps that are usually present on most of the text mining applications.

\subsection{Sentence tokenization}

The determination of the sentences that constitute the text using a special sentence splitter, also known as sentence boundary, is one of the first operations that are usually carried out for the text processing. This operation is necessary and important as most of the text mining systems require their input to be segmented into sentences for a number of reasons (e.g., the difficulties in dealing with anaphora). Although sentence segmentation seems to be an easy task when considering punctuation marks as separator such as the period, punctuation marks are often ambiguous. For example, a period may denote an abbreviation or decimal point not the end of a sentence. In this thesis work, Stanford CoreNLP, OpenNLP and Lingpipe sentence splitters have been used for separating the sentences in the abstracts of biomedical documents which where used for extracting the answers to biomedical questions.

\subsection{Word tokenization}

Tokenizing text into a sequence of tokens, which separates the sentence into an ordered list of words, is often the second operation in a NLP pipeline. This step is usually necessary of the text mining applications that require word-level granularity since the token is considered as the smallest unit in the text. Here again, word tokenization seems like a straightforward process, by considering white spaces as separator. However, it might not be so obvious since simple space delimitation does not deal with some of the subtleties of natural language text especially for the biomedical text where there are a lot of words (or at least phrasal lexical entries) that contain parentheses, hyphens, and so on. In this thesis work, Stanford CoreNLP and OpenNLP tokenizers a have been widely used for segmenting the tokens.

\subsection{N-grams}
N-grams, a sequence of tokens, are extensively used in many text mining tasks.  They are basically a set of co-occurring words, characters or subsets of characters within a given window. They also known as unigram, bigram or trigram in the case of sequences of size 1, 2 or 3, respectively. In this thesis work, bigrams have been used when referring to sequences of words in a sentence and they have been served as one of features of the machine learning algorithms developed for question classification. For instance, the question ``What is the molecular pathogenesis of Spinal Muscular Atrophy?'' might be represented by the bigrams \{What is, is the, the molecular, molecular pathogenesis, pathogenesis of, of Spinal, Spinal Muscular, Muscular Atrophy, Atrophy ?\}.



\subsection{Stemming and lemmatization}
For morphological reasons, a word might be expressed in different morphological forms which are in general the inflectional or derivational forms. The inflectional variations of the root word are its related forms with the same part-of-speech tag (i.e., word class) such as singular/plural variation, past/present tense variation and so on. For example, ``fish'' and ``fishes'' are inflected forms of the base or root ``fish''. On the other hand, derivational forms of a word are related to its variations with different POS tags. For example, ``fisher'' (noun) and ``fishing'' (verb) are derived forms for the root ``fish''. The importance to reduce inflectional and derivational forms of a word to the root form lies in that it would be useful for a search for the root word to retrieve and return textual documents that contain its different forms in the set. In a NLP pipeline, both stemming and lemmatization are aiming at transforming inflected and sometimes derived words to their common base form. Indeed, lemmatisation is closely related to stemming and both are special cases of normalization.  The main difference is that a stemmer reduces the word forms to the same stem even if the stem is not identical to the valid root of the word, whereas in lemmatization it will return the linguistically form of a word known also as the lemma, which must be a valid word. One of the most used stemmers is the Porter stemmer \citep{Porter_1980} which has been also used in many parts of this thesis work. Common stemming techniques and existing stemmers are described in \citep{jivani2011comparative}.

\subsection{Part-of-speech tagging}

Part-of-speech (POS) tagging, which is a process whereby tokens are sequentially associated with syntactic labels, also known as syntactic tags, word classes, or syntactic categories, is one of the most used syntactic analyzer tools. It indicates whether the word is a noun, a verb, an adjective or an adverb, for example. Knowing POS tags of words helps text mining applications to solve some problems lies in the syntactic disambiguation of each word in the text. Indeed, many English words can be used in more than one part-of-speech, which makes part-of-speech tagging an important block of syntactic parsing. For example, the word ``chat'' might refer to a noun (e.g., to have a chat) or a verb (to chat) depending on the context. The POS taggers provided by the Stanford toolkits have been widely used in many steps of this thesis work.

\subsection{Dependency parsing}
Dependency parsing or syntactic parsing, the task of analyzing the grammatical structure of a sentence by establishing syntactic dependency relations among the words, is a modern parsing technique. The main concept of dependency parsing is to construct a dependency parse tree of a sentence where the nodes represent linguistic unit (words) and the edges represent binary
asymmetric relations (called dependencies) between words. These structure trees are useful in various NLP applications such as question answering in which they play a vital role in the syntactic analysis of questions and answers. In this thesis work, the dependency parsing has been used in the question classification task as part of the question answering pipeline.

\subsection{Available NLP softwares}


Due to the importance and the necessity of the text processing for many text mining applications, various NLP toolkits/tools have been developed and made available for free to the text mining researchers. These tools support the most common NLP tasks. We list and describe here the most widely used toolkits:

\begin{itemize}
  \item The Standford CoreNLP\footnote{Standford CoreNLP: \url{https://stanfordnlp.github.io/CoreNLP/}.} \citep{Manning_2014}, a freely available natural language software, integrates many NLP tools including tokenizers, POS tagger, syntactic parsers, the named entity recognizer, the coreference resolution system, sentiment analysis, bootstrapped pattern learning, and the open information extraction tools. The Stanford CoreNLP is one of the most widely used tools for natural language processing. Accordingly, the Stanford CoreNLP has been widely used in this thesis work especially for tokenization, POS tagging and syntactic parsing tasks.
  \item LingPipe\footnote{LingPipe: \url{http://alias-i.com/lingpipe}.} is a freely available tool kit for the text processing using computational linguistics. It includes many NLP tasks such as sentence detection, POS tagging, named entity recognition, word sense disambiguation, language identification, sentiment analysis,  etc. LingPipe has been also used in this thesis work, especially for sentence detection.

  \item OpenNLP \footnote{OpenNLP: \url{https://opennlp.apache.org/}.} is also a freely available tool to support the most common NLP tasks such as, sentence tokenization, word tokenization, POS tagging, named entity extraction, chunking, parsing, language detection and coreference resolution. OpenNLP has been also used in this thesis work for sentence tokenization.

\end{itemize}







\section{Text Mining Tasks}
\label{Chapter2_2.3}
Text mining is the process of identifying and extracting high-quality information from natural language text \citep{Jackson_2007}. This information may be explicitly or implicitly stated in the text \citep{Zweigenbaum_2007}. On this definition, any system that extract and discover explicit or implicit knowledge hidden in text, or perform processing that are mandatory prerequisites for doing so, would be considered as a text mining application. This would include a range of application types such as named entity recognition, text classification, relation or information extraction, information retrieval, text classification, text summarization and question answering. In this section, we define these main tasks of text mining.

%% Figure environment removed

\subsection{Named entity recognition}
Named entity recognition (NER) is a task that recognizes sequences of words in a natural language text which are the names for a specific type of thing, such as person, locations and company names, or drug, gene and protein names. This task is an important area of research as it allows more complex text-mining tasks to be addressed \citep{de_Bruijn_2002,Cohen_2005}. For instance, identifying entities in text allows for further extraction of semantic relationships, retrieving documents related to a certain type of thing (e.g., gene), and answering many natural language questions. Due to a variety of reasons, NER is a challenging task, especially for biomedical text (also known as BioNER) where biological or medical terms should be identified \citep{Simpson_2012}. In the biomedical domain, not only a vast amount of biomedical entities exists but also new entities are rapidly being discovered \citep{Yeh_2005}. This ever-increasing list of semantically relevant terms is a real challenge for simple text matching algorithms that use only a dictionary based approach since these dictionaries can never be complete as long as new scientific discoveries, achievements, and inventions are made all the time. Another challenge of NER for biomedical text is that the same concept may be expressed using different biomedical entities (e.g., PTEN and MMAC1 refer the same gene). Because of the potential utility of biomedical entities in many biomedical text mining applications, various BioNER systems have been developed such as MetaMap \citep{aronson2001effective} that relies on a biomedical metathesaurus constructed for the unified medical language system (UMLS).

\subsection{Relation or information extraction}

Information extraction, or more recently relation extraction, is the task that aims at extracting the basic facts from the literature. These facts typically take the form of semantic relationships between a pair of entities of given types. In their simplest form, relationships among entities are binary, involving only the pair-wise associations between two entities. However, relations can involve more than two entities, and extraction of these complex relations are also known as event extraction \citep{Zweigenbaum_2007}. On this definition, biomedical relation extraction is a subfield of the information extraction field that handles only with entities related to the biomedical domain, such as genes, proteins or diseases. Indeed, biomedical relation extraction is a key and an important task of text mining since it takes part in many biomedical processes, and various investigations and efforts have been carried out to this matter. For instance, a typical biomedical relation or information extraction might extract affirmations about gene-gene interactions \citep{Cordell_2009,Jiang2013}, protein-protein interactions \citep{Krallinger_2008,jhon_2012} or drugs-drugs interactions \citep{Ferdousi_2017}, or might also extract assertions about relationships between diseases and drugs \citep{van_Mulligen_2012,Jang_2016}.

By far, in addition to binary relation extraction, event extraction is one of the most popular kind of information extraction.
In this context, many challenges (evaluation forums) have taken place in the last years for evaluating information extraction systems in the biomedical domain, such as the BioCreAtIve\footnote{BioCreAtIve: \url{http://www.biocreative.org/tasks/}} challenge \citep{Yeh_2005,Krallinger_2008,Krallinger_2011,Islamaj_Dogan_2017}, the i2b2\footnote{i2b2: \url{https://www.i2b2.org/index.html}} challenge \citep{Uzuner_2011}, BioNLP Shared Task\footnote{BioNLP Shared Task: \url{http://2016.bionlp-st.org/home}} \citep{kim2011overview,nedellec2013overview,Kim_2012,nedellec2013overview,nedellec2016proceedings}, BioASQ\footnote{BioASQ: \url{http://www.bioasq.org/}} task on funding information extraction from biomedical literature \citep{Nentidis_2017}, and Text Analysis Conference (TAC\footnote{TAC: \url{https://tac.nist.gov/2017/}} 2017) track on adverse drug reaction extraction from drug labels.





\subsection{Text classification}

Text classification also known as text categorization is the task of classifying a natural language text into one or more predefined categories (also known as classes or labels) according to their content \citep{Cohen_2005}. Narrowing this definition, we define biomedical text classification as the task of the assignment of one or more classes to a biomedical text. In a typical text classification workflow, the information of interest is not specified explicitly by the users and, instead, they give a stream of textual documents that have been found to contain the characteristics of interest (the positive training set), and another collection that does not (the negative training set). Text classification systems first use feature sets extracted from the training data, such as a set of words that may allow determine positives from negatives and then apply those features to new textual documents using some kind of decision-making algorithm. Automatic text classification has many practical applications, including indexing for biomedical document retrieval \citep{Dram__2016}, biomedical named entity recognition \citep{Gridach_2017}, relation extraction \citep{Zheng_2017}, word sense disambiguation \citep{Jimeno_Yepes_2017}, and question classification \citep{Sarrouti_MIM_2017} by detecting the topics a questions covers. The approaches for text classification may be classified in methods based on rules, machine or deep learning, and hybrid which combine both rules and machine or deep learning.

\subsection{Text clustering}

Unlike text categorization (or text classification) which is a kind of ``supervised'' learning where the classes or labels are known beforehand and predefined in advance for each training textual document, text clustering, the application of cluster analysis to textual documents, is ``unsupervised'' learning. In text clustering, there is no predefined label or ``category,'' but groups of textual documents that contain the same characteristics are sought. Indeed, document clustering algorithms (e.g., K-Means) use and require only some approaches of distances or similarity between pairs of documents such as Euclidean distance, Jaccard Coefficient and Cosine Similarity. Although text clustering have seen relatively little application in biomedical text mining applications, it is important and useful for a variety of information needs and applications such as organizing documents for better information retrieval, classification, summarization and analysis \citep{Boyack_2011}.


\subsection{Text summarization}

Text summarization is the task of identifying the salient aspects of individual documents or groups of documents and present these aspects succinctly and coherently. In the biomedical domain, due to the continuous growth of textual information in the form of scientific articles, clinicians notes, electronic health records and a variety of other input types, automatic text summarization has been widely applied for aiding researchers and health care professionals to determine the shorter text that conveys the most important information contained in an increasingly large volume of biomedical text \citep{Simpson_2012}. In this context, summarization has been widely applied to journal articles, clinical notes, and a variety of other input types. For instance, one text summarization system, MITRE'S MiTAP, does multi-document summarization of epidemiological reports, online news, newswire feeds, email, television news, and radio news to identify and detect disease outbreaks. Summarization has been also widely to answer biomedical questions which requires single paragraph-sized (the most relevant information from concepts, articles, snippets, and triples) text as answers.


\subsection{Information retrieval}

Information retrieval (IR) is defined as a domain concerned with ``the structure, analysis, organization, storage, searching, and retrieval of information'' \citep{salton1968automatic}. On this definition, biomedical IR can be defined as ``the structure, analysis, organization, storage, searching, and retrieval of biomedical information''. A typical IR pipeline consists of a user, a collection of documents and an IR system. Given a collection of textual documents (e.g., web pages, biomedical scientific articles and medical reports) and a user's information need expressed as some sort of query, IR also known as document retrieval is the task of searching and returning the most relevant documents.
The information contained in documents can also be images, audio, video, etc. However, IR research has concentrated on retrieval of text written in natural language, a reasonable emphasis given the importance and large volume of textual data \citep{salton1986introduction,greengrass2000information,chowdhury2010introduction}. Due to the immense and increasing volume of biomedical literature, not only biomedical IR systems have become important for end-users, such as physicians, biologists, biochemists, and biomedical researchers searching directly for relevant citations to their queries, but also plays an important role in many other text mining applications. The identification of relevant documents for a given subject of interest is a preceding step for other text mining tasks, such as text classification, text summarization, and question answering. Several factors make this a challenging task: (1) the information in the documents is generally expressed in an unstructured form; (2) documents are usually written in natural language; and (3) very often, the documents may cover a wide range of topics \citep{mitra2000information}. Under these circumstances, IR is a key issue in text mining, and many efforts have been dedicated to this matter. PubMed is an example of a biomedical IR system for scientific articles; Google is an IR system for web pages.

\subsection{Question answering}

Unlike traditional IR systems (also known as search engines), where a list of potentially relevant documents from large text collections to a given query, question answering (QA) refers to the task of searching and returning the short, specific answers to questions usually expressed in natural language.  Since QA needs the use of more complex natural language processing methodologies than employed by information retrieval systems for linguistically and semantically processing both the questions and data sources so as to generate precise answers, QA systems go beyond search engines and regarded as the next generation for high accuracy information retrieval \citep{Zweigenbaum_2007}. Like automatic text summarization, QA is a process directed towards helping researchers, biologists and physicians in quickly and reliably managing the enormous growth of textual information in the biomedical domain \citep{Simpson_2012}. Due to the importance of retrieving the precise answers to natural language questions in the biomedical domain, developing and improving QA systems are desirable. Accordingly, this thesis work investigates and presents sophisticated methods for performing question answering in the biomedical domain.

In the following section~\ref{Chapter3_2}, we present the main classification criteria of question answering systems. We also describe in section~\ref{Chapter3_3} important factors that distinguish restricted-domain QA from open-domain.

\section{Question Answering Systems Classification}
\label{Chapter3_2}

Several criteria for classifying available large number of QA systems have been proposed. For instance, the task of generating and extracting answers to natural language questions is related to the application domain \citep{molla2007question}. Questions asked by users may require general answers on open, general topic; others may need specific answers from a specific, restricted domain. The nature of a specific domain impacts the kinds of questions posed and answers that can be expected. Therefore, the application domain may be considered as a basis of classification of QA systems.

In addition to the application domain, QA is directly related to the types of addressed questions and answers. Based on the complexity of addressed questions and challenges relied in answer generation, \citet{moldovan2003performance} have classified QA systems into five classes:

\begin{itemize}
  \item Systems able to answer factoid questions.
  \item Systems employing simple reasoning techniques.
  \item Systems that extract and generate the answers from different resources.
  \item Systems able to answer questions based on previous interactions with the user.
  \item Systems capable to perform an analogical reasoning.
\end{itemize}

The first class of QA systems covers a large number of systems that deal with WH-questions (what, when, which, who, how, etc.). It groups approaches that extract answers as pieces of text from one or more documents. The second class of systems is a subclass of the first category where the extraction of answers requires logical inferences. In the third category of systems, the answer is scattered in several documents and therefore answer fusion is required. The fourth category of systems exploits previous interactions with the user in order to extract answers. Finally, the last type of systems that are considered more complex, has the ability to answer prediction questions. The answers of such questions are not explicitly stated in the documents. In such systems, the answers are generated using analogical reasoning techniques.

Although the type of input and output seems to be an important criterion for classifying QA systems, this approach does not take this criterion into consideration since it uses the same type of input (natural language questions) and the same type of output (text segments). In addition, not only the techniques and strategies used for question analysis and classification, documents, and answer extraction are not taken as criteria for classification, but also this classification does not explain the sources from which the answers are generated or extracted. In this context, some authors have proposed approaches that take advantage of the input types, output types and resources as criteria for classifying semantic QA systems that uses knowledge bases and ontologies to generate the answers. For example, \citet{lopez2011question} have surveyed a state of the art on semantic QA systems and classified them into categories based on four dimensions: (1) the input or type of questions they deal with, (2) the resources from which the answers are extracted (structured versus unstructured data), (3) the scope (restricted-domain versus open-domain), and (4) how they copes with the search environment problems. These categories include:

\begin{itemize}%\itemsep-4pt
  \item Natural language interfaces to structured data on databases.
  \item QA over semi-structured data (e.g., health records).
  \item QA over textual documents (unstructured data).
  \item QA over ontologies (structured semantic data).
\end{itemize}


\cite{athenikos2010biomedical} have proposed a classification approach for classifying semantic knowledge-based QA systems into three categories:

\begin{itemize}
  \item Semantics-based QA systems.
  \item Inference-based QA systems.
  \item Logic-based QA systems.
\end{itemize}

Semantics-based approaches take advantage of semantic metadata encoded in structured semantic resources such as ontologies and knowledge bases in order to produce answers to questions; inference-based approaches derive answers by employing extracted semantic relationships, and logic-based approaches exploit explicit logical forms and theorem proving techniques to generate and extract answers.
This classification remains ambiguous, however, as the three categories seem to be connected and may have many intersections with each other, which does not allow to effectively categorize and group the different QA systems. Based on this classification, the author further have reviewed and classified medical QA approaches and biological QA approaches.

\citet{mishra2016survey} have identified eight criteria in support of classifying QA approaches based on the literature surveyed. These criteria include:
\begin{itemize}
  \item Application domains for which QA systems are developed (open domain QA or restricted-domain QA).
  \item Types of questions asked by the users, e.g., factoid, list, confirmation questions, etc.
  \item Types of analyses performed on users' questions and source documents, e.g., morphological analysis, syntactical
analysis, semantic analysis, etc.
  \item Types of data consulted in data sources: structured data, semi-structured data, and structured data.
  \item Characteristics of data sources such as source size and language.
  \item Types of representations used for questions and their matching functions (e.g., algebraic model, probability models, etc.).
  \item Types of techniques used for retrieving answers, e.g., NLP techniques, information retrieval techniques, etc.
  \item Types of answers returned by QA systems (extracted text, snippets or other multimedia information, and generated answer).
\end{itemize}


In the following section we discuss the main factors that distinguish between open-domain and restricted-domain QA.


\section{Open-Domain vs. Restricted-Domain Question Answering}
\label{Chapter3_3}
Question answering may be open-domain and restricted-domain, also known as general-domain and closed-domain QA, respectively. Open-domain QA deals with questions from diverse arias, whereas restricted-domain QA answers questions under a specific field. QA has been initially presented in the open-domain, and more recently in restricted domains \citep{HIRSCHMAN_2001}. Open-domain QA research area has received much attention from the IR community, initiated by the QA Track in TREC evaluations, which takes place regularly every year since 1999 \citep{voorhees1999trec}. Since then, various systems have been developed and participated in TREC and other evaluation companies such as NTCIR \citep{kando2002overview} and CLEF \citep{Magnini_2005}.

As \citet{molla2007question} point out in their review on restricted-domains QA, there are several factors that distinguish QA in the restricted-domains from general, open-domain QA systems. These factors include: (1) the size of the data, (2) domain context, and (3) resources. The size of the text corpus available for open-domain QA tends to be quite large, which explains and justifies the use redundancy-based answer generation and extraction methods. In contrast to open-domain QA, in restricted-domain QA, the size of the data is relatively small
and varies from domain to domain, as well as redundancy-based techniques are likely to have a weaker effect and would not be useful for a specific domain with a small corpus size. Although terminological variations and synonyms create many challenges for text mining and natural language processing applications in restricted domain, QA is advantaged by the limited scope of questions that a domain-specific terminology and types of
questions provides. Indeed, the kinds of questions posed in a restricted domain especially by users who are experts in the domain are in general more complex and difficult than these asked by users in open domain. Experts of a specific domain usually use specific terminologies and pose domain-specific types of questions that require specific processing of questions and answers. Finally, another important distinction between open-domain and restricted-domain QA relies in the existence of specific resources such as tools, methods and domain specific information for restricted domains that can be exploited in the QA process.



\section{Summary of the Chapter}
\label{Chapter2_2.5}
In this chapter, we have defined a serie of tasks that are actively used and studied in both biomedical natural language processing and text mining. Even if these tasks seem to be unconnected, they are usually correctly combined together to establish and develop an analysis workflow to solve the issues that occur in the area of text mining.

We started this chapter by presenting an introduction to biomedical natural language processing and text mining. We next described in details NLP tasks which are usually used for shallow linguistics processing tasks, such as sentence tokenization, word tokenization, n-grams, part-of-speech tagging, stemming and lemmatization, as well as dependency parsing. We have also presented and described the most widely used NLP toolkits/platforms for the most common NLP tasks.
We then presented and defined a range of text mining application types, such as named entity recognition, text classification, information extraction, information retrieval, text classification, text clustering, text summarization, as well as question answering which is the scope of this thesis work. We finally described a broader classification framework involving QA systems based on different criteria, and important factors that distinguish restricted-domain QA from open-domain.

In the following chapter, we will present in details the state-of-the-art on question answering systems with a particular focus on the biomedical domain.
