\babel@toc {french}{}
\babel@toc {english}{}
\babel@toc {french}{}
\babel@toc {english}{}
\addvspace {10\p@ }
\contentsline {xchapter}{Biomedical Natural Language Processing and Text Mining}{8}{chapter.19}
\addvspace {10\p@ }
\contentsline {xchapter}{State-of-the-Art in Biomedical Question Answering}{20}{chapter.49}
\contentsline {table}{\numberline {2.1}{\ignorespaces Question answering systems comparison matrix of features between the aforementioned systems and our proposed system SemBioNLQA}}{41}{table.caption.91}
\contentsline {table}{\numberline {2.2}{\ignorespaces Comparing biomedical QA datasets provided by the BioASQ challenge, TREC Genomics and QA4MRE Alzheimer Disease\relax }}{45}{table.caption.96}
\contentsline {table}{\numberline {2.3}{\ignorespaces The question types and the number of BioASQ training questions assigned to each category\relax }}{45}{table.caption.97}
\contentsline {table}{\numberline {2.4}{\ignorespaces Number of questions and their categories in test sets of biomedical questions provided in the 2015, 2016, and 2017 and BioASQ challenges\relax }}{46}{table.caption.98}
\contentsline {table}{\numberline {2.5}{\ignorespaces Question categories with some examples of biomedical questions collected from BioASQ training dataset\relax }}{46}{table.caption.99}
\contentsline {table}{\numberline {2.6}{\ignorespaces Examples of clinical questions and their topics maintained by the U.S. National Library of Medicine\relax }}{47}{table.caption.101}
\contentsline {table}{\numberline {2.7}{\ignorespaces Typology of 4654 clinical questions and their representatives. The first column represents generic question proportions}}{47}{table.caption.102}
\contentsline {table}{\numberline {2.8}{\ignorespaces The topics of 4654 clinical questions, the number of the clinical questions assigned and the percentage of the total questions}}{48}{table.caption.103}
\addvspace {10\p@ }
\contentsline {xchapter}{Question Classification in Biomedical Question Answering}{51}{chapter.117}
\contentsline {table}{\numberline {3.1}{\ignorespaces The different feature spaces of the biomedical question ``What is the definition of autophagy?''\relax }}{56}{table.caption.157}
\contentsline {table}{\numberline {3.2}{\ignorespaces The obtained results using SVM on five batches of testing datasets to automatically assign a category to biomedical questions}}{57}{table.caption.159}
\contentsline {table}{\numberline {3.3}{\ignorespaces The detailed results for each question category in two feature models (unigram and set of patterns) by applying SVM classifier}}{58}{table.caption.160}
\contentsline {table}{\numberline {3.4}{\ignorespaces Linguistic preprocessing of a sample clinical question}}{62}{table.caption.167}
\contentsline {table}{\numberline {3.5}{\ignorespaces Example of mapping the clinical question ``Mother is alcoholic and abuses tobacco. What are statistics regarding inheritance of tobacco abuse and relationship to social situation?'' to UMLS Metathesaurus concepts and semantic types. CUI and TUI indicate concept unique identifier and type unique identifier, respectively.\relax }}{63}{table.caption.168}
\contentsline {table}{\numberline {3.6}{\ignorespaces The obtained results in terms of F1-score using Na\IeC {\"\i }ve Bayes to automatically assign topics to ad hoc clinical questions}}{64}{table.caption.171}
\contentsline {table}{\numberline {3.7}{\ignorespaces The obtained results in terms of F1-score using SVM to automatically assign topics to ad hoc clinical questions}}{65}{table.caption.172}
\contentsline {table}{\numberline {3.8}{\ignorespaces Comparison between the proposed representation (the combination of various features: BOW+BOB+BOCST+BOSDR+BOS$_{porter}$) and state-of-the-art representations on 4654 natural language clinical questions using Naive Bayes as a classifier in terms of F-score.\relax }}{66}{table.caption.173}
\contentsline {table}{\numberline {3.9}{\ignorespaces Comparison between the proposed representation (the combination of various features: BOW+BOB+BOCST+BOSDR+BOS$_{porter}$) and state-of-the-art representations on 4654 natural language clinical questions using SVM as a classifier in terms of F-score.\relax }}{66}{table.caption.174}
\addvspace {10\p@ }
\contentsline {xchapter}{Document and Passage Retrieval in Biomedical Question Answering}{70}{chapter.179}
\contentsline {table}{\numberline {4.1}{\ignorespaces The experimental results of the proposed document retrieval system and state-of-the-art systems presented in \citep {balikas2014results}, which were ranked within the 10 top tier systems on batch 1 of BioASQ 2014.\relax }}{76}{table.caption.210}
\contentsline {table}{\numberline {4.2}{\ignorespaces Comparison of our document reranking method and GoPubMed document ranking for biomedical QA on batch 1 of BioASQ 2014.\relax }}{76}{table.caption.211}
\contentsline {table}{\numberline {4.3}{\ignorespaces The overall results of the proposed method on five batches of testing datasets provided by the BioASQ challenge.\relax }}{82}{table.caption.252}
\contentsline {table}{\numberline {4.4}{\ignorespaces Comparison in terms of MAP of the proposed biomedical passage retrieval method with the state-of-the-art methods on five batches of testing datasets provided by the BioASQ challenge}}{83}{table.caption.253}
\contentsline {table}{\numberline {4.5}{\ignorespaces The obtained results of the different implementation variations of the BM25 model, i.e., with or without stemming or UMLS concepts, and the two passage lengths: OpenNLP sentence length and Stanford CoreNLP sentence length\relax }}{84}{table.caption.258}
\contentsline {table}{\numberline {4.6}{\ignorespaces The detailed results using TFIDF metrics used in \citep {neves2015hpi} and Stanford CoreNLP passage length on five batches of testing datasets provided by the BioASQ challenge.\relax }}{84}{table.caption.259}
\addvspace {10\p@ }
\contentsline {xchapter}{Answer Extraction and End-to-End Biomedical Question Answering System SemBioNLQA}{87}{chapter.264}
\contentsline {table}{\numberline {5.1}{\ignorespaces The overall results of the proposed biomedical answer extraction methods and comparison with the current state-of-the-art methods on five batches of testing datasets provided by BioASQ 3b 2015.}}{95}{table.caption.284}
\contentsline {table}{\numberline {5.2}{\ignorespaces The overall results of the proposed biomedical answer extraction methods and comparison with the current state-of-the-art methods on five batches of testing datasets provided by BioASQ 4b 2016}}{96}{table.caption.285}
\contentsline {table}{\numberline {5.3}{\ignorespaces The obtained results of our participation in ``Exact Answers'', Phase B, Task 5b of the 2017 BioASQ challenge using the proposed answer extraction methods}}{96}{table.caption.286}
\contentsline {table}{\numberline {5.4}{\ignorespaces The obtained results of our participation in ``Ideal Answers'', Phase B, Task 5b of the 2017 BioASQ challenge using the proposed answer extraction methods}}{97}{table.caption.287}
\contentsline {table}{\numberline {5.5}{\ignorespaces The overall results of SemBioNLQA and comparison with Olelo on five batches of testing datasets provided by BioASQ 5b 2017}}{103}{table.caption.299}
\contentsline {table}{\numberline {5.6}{\ignorespaces The overall evaluation results of the SemBioNLQA system on five batches of biomedical questions provided by BioASQ 3b 2015 and BioASQ 4b 2016}}{104}{table.caption.303}
\contentsline {table}{\numberline {5.7}{\ignorespaces Comparison of the obtained results by SemBioNLQA, EAGLi, AskHERMES and Olelo in terms of number of recognized questions and correct answers\relax }}{107}{table.caption.309}
\addvspace {10\p@ }
\contentsline {xchapter}{List of BioASQ questions used for the manual evaluation}{116}{appendix.314}
\addvspace {10\p@ }
\contentsline {xchapter}{R\IeC {\'e}sum\IeC {\'e} d\IeC {\'e}taill\IeC {\'e} de la th\IeC {\`e}se en Fran\IeC {\c c}ais}{118}{appendix.345}
\babel@toc {french}{}
\babel@toc {english}{}
\babel@toc {french}{}
\contentsline {table}{\numberline {B.1}{\ignorespaces R\IeC {\'e}sultats obtenus en utilisant SVM sur cinq lots de questions de tests pour attribuer automatiquement une cat\IeC {\'e}gorie aux questions biom\IeC {\'e}dicales}}{124}{table.caption.356}
\babel@toc {english}{}
\babel@toc {french}{}
\contentsline {table}{\numberline {B.2}{\ignorespaces R\IeC {\'e}sultats obtenus en utilisant SVM pour attribuer automatiquement des sujets \IeC {\`a} des questions cliniques}}{127}{table.caption.359}
\babel@toc {english}{}
\babel@toc {french}{}
\contentsline {table}{\numberline {B.3}{\ignorespaces Comparaison des r\IeC {\'e}sultats exp\IeC {\'e}rimentaux du syst\IeC {\`e}me de recherche de documents propos\IeC {\'e} et des syst\IeC {\`e}mes de l'\IeC {\'e}tat de l'art pr\IeC {\'e}sent\IeC {\'e}s dans \citep {balikas2014results}.\relax }}{129}{table.caption.362}
\babel@toc {english}{}
\babel@toc {french}{}
\contentsline {table}{\numberline {B.4}{\ignorespaces Comparaison en termes de MAP de la m\IeC {\'e}thode de recherche des passages propos\IeC {\'e}e avec celles de l'\IeC {\'e}tat de l'art sur cinq lots de jeux de donn\IeC {\'e}es de test fournis par le challenge BioASQ}}{131}{table.caption.365}
\babel@toc {english}{}
\babel@toc {french}{}
\contentsline {table}{\numberline {B.5}{\ignorespaces R\IeC {\'e}sultats obtenus lors de notre participation dans la phase B \IeC {\guillemotleft }r\IeC {\'e}ponses exactes\IeC {\guillemotright } de la t\IeC {\^a}che 5b du challenge BioASQ 2017 en utilisant les m\IeC {\'e}thodes propos\IeC {\'e}es l'extraction des r\IeC {\'e}ponses}}{134}{table.caption.369}
\babel@toc {english}{}
\babel@toc {french}{}
\contentsline {table}{\numberline {B.6}{\ignorespaces R\IeC {\'e}sultats obtenus lors de notre participation dans la phase B \IeC {\guillemotleft }R\IeC {\'e}ponses id\IeC {\'e}ales\IeC {\guillemotright } de la t\IeC {\^a}che 5b du challenge BioASQ 2017 en utilisant les m\IeC {\'e}thodes propos\IeC {\'e}es pour l'extraction des r\IeC {\'e}ponses}}{135}{table.caption.370}
\babel@toc {english}{}
\babel@toc {french}{}
\contentsline {table}{\numberline {B.7}{\ignorespaces Comparaison des r\IeC {\'e}sultats obtenus par notre syst\IeC {\`e}me SemBioNLQA, EAGLi, AskHERMES et Olelo en terme du nombre de questions reconnues et de r\IeC {\'e}ponses correctes.\relax }}{136}{table.caption.374}
\babel@toc {english}{}
