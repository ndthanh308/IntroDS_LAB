\begin{thebibliography}{174}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Naumann et~al.(2023)Naumann, Hertlein, Doerr, Thoma, and
  Furmans]{naumannLiteratureReviewComputer2023}
Naumann, A., Hertlein, F., Doerr, L., Thoma, S. and Furmans, K.
\newblock \emph{Literature {Review}: {Computer} {Vision} {Applications} in
  {Transportation} {Logistics} and {Warehousing}}.
\newblock April 2023.

\bibitem[Rai et~al.(2021)Rai, Tiwari, Ivanov, and
  Dolgui]{raiMachineLearningManufacturing2021}
Rai, R., Tiwari, M., Ivanov, D. and Dolgui, A.
\newblock Machine learning in manufacturing and industry 4.0 applications.
\newblock \emph{International Journal of Production Research}, 59:\penalty0
  4773--4778, August 2021.
\newblock \doi{10.1080/00207543.2021.1956675}.

\bibitem[Zhou et~al.(2023{\natexlab{a}})Zhou, Zhang, and
  Konz]{zhouComputerVisionTechniques2023}
Zhou, L., Zhang, L. and Konz, N.
\newblock Computer {Vision} {Techniques} in {Manufacturing}.
\newblock \emph{IEEE Transactions on Systems, Man, and Cybernetics: Systems},
  53\penalty0 (1):\penalty0 105--117, January 2023{\natexlab{a}}.
\newblock ISSN 2168-2232.
\newblock \doi{10.1109/TSMC.2022.3166397}.

\bibitem[Grosser(2012)]{grosserIntegratedSolutions3d2012}
Grosser, H.
\newblock Integrated solutions for 3d scanning and generation of digital
  product models in mro processes.
\newblock January 2012.

\bibitem[Sarker(2021)]{sarkerDeepLearningComprehensive2021}
Sarker, I.H.
\newblock Deep {Learning}: {A} {Comprehensive} {Overview} on {Techniques},
  {Taxonomy}, {Applications} and {Research} {Directions}.
\newblock \emph{SN Computer Science}, 2\penalty0 (6):\penalty0 420, August
  2021.
\newblock ISSN 2661-8907.
\newblock \doi{10.1007/s42979-021-00815-1}.

\bibitem[Moenck et~al.(2023)Moenck, Rath, Koch, Wendt, Schoepflin, Kalscheuer,
  and Schüppstuhl]{moenckDigitalTwinsAircraft2023}
Moenck, K., Rath, J.E., Koch, J., Wendt, A., Schoepflin, D., Kalscheuer, F. and
  Schüppstuhl, T.
\newblock \emph{Digital {Twins} in {Aircraft} {Production}: {Challenges} and
  {Opportunities}}.
\newblock June 2023.
\newblock \doi{10.13140/RG.2.2.15698.53441}.

\bibitem[Yasuda et~al.(2022)Yasuda, Cappabianco, Martins, and
  Gripp]{yasudaAircraftVisualInspection2022}
Yasuda, Y., Cappabianco, F., Martins, L. and Gripp, J.
\newblock Aircraft visual inspection: {A} systematic literature review.
\newblock \emph{Computers in Industry}, 141:\penalty0 103695, October 2022.
\newblock \doi{10.1016/j.compind.2022.103695}.

\bibitem[Gierecker et~al.(2022)Gierecker, Schoepflin, Schmedemann, and
  Schüppstuhl]{giereckerConfigurationEnablementVision2022}
Gierecker, J., Schoepflin, D., Schmedemann, O. and Schüppstuhl, T.
\newblock Configuration and {Enablement} of {Vision} {Sensor} {Solutions}
  {Through} a {Combined} {Simulation} {Based} {Process} {Chain}.
\newblock pages 313--324. January 2022.
\newblock ISBN 978-3-030-74031-3.
\newblock \doi{10.1007/978-3-030-74032-0_26}.

\bibitem[Kähler et~al.(2023{\natexlab{a}})Kähler, Shetty, and
  Schüppstuhl]{kahlerAIbasedEndpointDetection2023}
Kähler, F., Shetty, A. and Schüppstuhl, T.
\newblock \emph{{AI}-based {Endpoint} {Detection} for {Surface} {Defect}
  {Removal} on {Aircraft} {Components}}.
\newblock January 2023{\natexlab{a}}.
\newblock \doi{10.1109/SII55687.2023.10039239}.

\bibitem[Büsch et~al.(2023)Büsch, Koch, Schoepflin, Schulze, and
  Schüppstuhl]{busch_towards_2023}
Büsch, L., Koch, J., Schoepflin, D., Schulze, M. and Schüppstuhl, T.
\newblock Towards {Recognition} of {Human} {Actions} in {Collaborative} {Tasks}
  with {Robots}: {Extending} {Action} {Recognition} with {Tool} {Recognition}
  {Methods}.
\newblock \emph{Sensors}, 23\penalty0 (12):\penalty0 5718, January 2023.
\newblock ISSN 1424-8220.
\newblock \doi{10.3390/s23125718}.

\bibitem[Kheddar et~al.(2019)Kheddar, Caron, Gergondet, Comport, Tanguy, Ott,
  Henze, Mesesan, Englsberger, Roa, Wieber, Chaumette, Spindler, Oriolo,
  Lanari, Escande, Chappellet, Kanehiro, and
  Rabaté]{kheddarHumanoidRobotsAircraft2019}
Kheddar, A. et~al.
\newblock Humanoid {Robots} in {Aircraft} {Manufacturing}: {The} {Airbus} {Use}
  {Cases}.
\newblock \emph{IEEE Robotics \& Automation Magazine}, 26\penalty0
  (4):\penalty0 30--45, December 2019.
\newblock ISSN 1558-223X.
\newblock \doi{10.1109/MRA.2019.2943395}.

\bibitem[Schoepflin et~al.(2021{\natexlab{a}})Schoepflin, Koch, Gomse, and
  Schüppstuhl]{schoepflinSmartMaterialDelivery2021}
Schoepflin, D., Koch, J., Gomse, M. and Schüppstuhl, T.
\newblock Smart {Material} {Delivery} {Unit} for the {Production} {Supplying}
  {Logistics} of {Aircraft}.
\newblock \emph{Procedia Manufacturing}, 55:\penalty0 455--462, January
  2021{\natexlab{a}}.
\newblock \doi{10.1016/j.promfg.2021.10.062}.

\bibitem[Hu et~al.(2019)Hu, Duan, Liu, Yan, Tao, Osman, Ibarra-Castanedo,
  Sfarra, Chen, and Zhang]{huLSTMRNNbasedDefectClassification2019}
Hu, C., Duan, Y., Liu, S., Yan, Y., Tao, N., Osman, A., Ibarra-Castanedo, C.,
  Sfarra, S., Chen, D. and Zhang, C.
\newblock {LSTM}-{RNN}-based defect classification in honeycomb structures
  using infrared thermography.
\newblock \emph{Infrared Physics \& Technology}, 102:\penalty0 103032, November
  2019.
\newblock ISSN 1350-4495.
\newblock \doi{10.1016/j.infrared.2019.103032}.

\bibitem[Ruiz et~al.(2020)Ruiz, Torres, Gómez, Díaz, González, and
  Cavas]{ruizDetectionClassificationAircraft2020}
Ruiz, L., Torres, M., Gómez, A., Díaz, S., González, J.M. and Cavas, F.
\newblock Detection and {Classification} of {Aircraft} {Fixation} {Elements}
  during {Manufacturing} {Processes} {Using} a {Convolutional} {Neural}
  {Network}.
\newblock \emph{Applied Sciences}, 10\penalty0 (19):\penalty0 6856, January
  2020.
\newblock ISSN 2076-3417.
\newblock \doi{10.3390/app10196856}.

\bibitem[Maji et~al.(2013)Maji, Rahtu, Kannala, Blaschko, and
  Vedaldi]{majiFineGrainedVisualClassification2013a}
Maji, S., Rahtu, E., Kannala, J., Blaschko, M. and Vedaldi, A.
\newblock Fine-{Grained} {Visual} {Classification} of {Aircraft}, June 2013.
\newblock \doi{10.48550/arXiv.1306.5151}.

\bibitem[Ding et~al.(2022)Ding, Wu, Xu, Kasule, and
  Zuo]{dingVisualInspectionAircraft2022}
Ding, M., Wu, B., Xu, J., Kasule, A.N. and Zuo, H.
\newblock Visual inspection of aircraft skin: {Automated} pixel-level defect
  detection by instance segmentation.
\newblock \emph{Chinese Journal of Aeronautics}, 35\penalty0 (10):\penalty0
  254--264, October 2022.
\newblock ISSN 1000-9361.
\newblock \doi{10.1016/j.cja.2022.05.002}.

\bibitem[Zhao et~al.(2021)Zhao, Hu, Xiao, and Zou]{zhaoMaskRCNNBased2021}
Zhao, G., Hu, J., Xiao, W. and Zou, J.
\newblock A mask {R}-{CNN} based method for inspecting cable brackets in
  aircraft.
\newblock \emph{Chinese Journal of Aeronautics}, 34\penalty0 (12):\penalty0
  214--226, December 2021.
\newblock ISSN 1000-9361.
\newblock \doi{10.1016/j.cja.2020.09.024}.

\bibitem[Moenck et~al.(2022)Moenck, Laukotka, Deneke, Schüppstuhl, Krause, and
  Nagel]{moenck_towards_2022}
Moenck, K., Laukotka, F., Deneke, C., Schüppstuhl, T., Krause, D. and Nagel,
  T.
\newblock \emph{Towards an {Intelligent} {Digital} {Cabin} {Twin} to {Support}
  an {Aircraft}'s {Retrofit} and {Base} {Maintenance} ({SAE} {Paper}
  2022-01-0046)}.
\newblock March 2022.
\newblock \doi{10.4271/2022-01-0046}.

\bibitem[Kähler et~al.(2022)Kähler, Schmedemann, and
  Schüppstuhl]{kahlerAnomalyDetectionIndustrial2022}
Kähler, F., Schmedemann, O. and Schüppstuhl, T.
\newblock Anomaly detection for industrial surface inspection: application in
  maintenance of aircraft components.
\newblock \emph{Procedia CIRP}, 107:\penalty0 246--251, January 2022.
\newblock \doi{10.1016/j.procir.2022.05.197}.

\bibitem[Schmedemann et~al.(2022)Schmedemann, Miotke, Kähler, and
  Schüppstuhl]{schmedemannDeepAnomalyDetection2022}
Schmedemann, O., Miotke, M., Kähler, F. and Schüppstuhl, T.
\newblock \emph{Deep {Anomaly} {Detection} for {Endoscopic} {Inspection} of
  {Cast} {Iron} {Parts}}.
\newblock October 2022.
\newblock ISBN 978-3-031-18325-6.
\newblock \doi{10.1007/978-3-031-18326-3_9}.

\bibitem[O’Mahony et~al.(2020)O’Mahony, Campbell, Carvalho, Harapanahalli,
  Hernandez, Krpalkova, Riordan, and Walsh]{omahonyDeepLearningVs2020}
O’Mahony, N., Campbell, S., Carvalho, A., Harapanahalli, S., Hernandez, G.V.,
  Krpalkova, L., Riordan, D. and Walsh, J.
\newblock Deep {Learning} vs. {Traditional} {Computer} {Vision}.
\newblock In Arai, K. and Kapoor, S., editors, \emph{Advances in {Computer}
  {Vision}}, Advances in {Intelligent} {Systems} and {Computing}, pages
  128--144, Cham, 2020. Springer International Publishing.
\newblock ISBN 978-3-030-17795-9.
\newblock \doi{10.1007/978-3-030-17795-9_10}.

\bibitem[Janiesch et~al.(2021)Janiesch, Zschech, and
  Heinrich]{janieschMachineLearningDeep2021}
Janiesch, C., Zschech, P. and Heinrich, K.
\newblock Machine learning and deep learning.
\newblock \emph{Electronic Markets}, 31, April 2021.
\newblock \doi{10.1007/s12525-021-00475-2}.

\bibitem[Wuest et~al.(2016)Wuest, Weimer, Irgens, and
  Thoben]{wuestMachineLearningManufacturing2016}
Wuest, T., Weimer, D., Irgens, C. and Thoben, K.D.
\newblock Machine learning in manufacturing: advantages, challenges, and
  applications.
\newblock \emph{Production \& Manufacturing Research}, 4\penalty0 (1):\penalty0
  23--45, January 2016.
\newblock ISSN null.
\newblock \doi{10.1080/21693277.2016.1192517}.

\bibitem[Bergmann et~al.(2019)Bergmann, Fauser, Sattlegger, and
  Steger]{bergmannMVTecADComprehensive2019}
Bergmann, P., Fauser, M., Sattlegger, D. and Steger, C.
\newblock \emph{{MVTec} {AD} - {A} {Comprehensive} {Real}-{World} {Dataset} for
  {Unsupervised} {Anomaly} {Detection}}.
\newblock June 2019.
\newblock \doi{10.1109/CVPR.2019.00982}.

\bibitem[Drost et~al.(2017)Drost, Ulrich, Bergmann, Härtinger, and
  Steger]{drostIntroducingMVTecITODD2017}
Drost, B., Ulrich, M., Bergmann, P., Härtinger, P. and Steger, C.
\newblock Introducing {MVTec} {ITODD} — {A} {Dataset} for {3D} {Object}
  {Recognition} in {Industry}.
\newblock In \emph{2017 {IEEE} {International} {Conference} on {Computer}
  {Vision} {Workshops} ({ICCVW})}, pages 2200--2208, October 2017.
\newblock \doi{10.1109/ICCVW.2017.257}.

\bibitem[Löffler et~al.(2018)Löffler, Riechel, Fischer, and
  Mutschler]{lofflerEvaluationCriteriaInsideOut2018}
Löffler, C., Riechel, S., Fischer, J. and Mutschler, C.
\newblock Evaluation {Criteria} for {Inside}-{Out} {Indoor} {Positioning}
  {Systems} {Based} on {Machine} {Learning}.
\newblock In \emph{2018 {International} {Conference} on {Indoor} {Positioning}
  and {Indoor} {Navigation} ({IPIN})}, pages 1--8, September 2018.
\newblock \doi{10.1109/IPIN.2018.8533862}.

\bibitem[Rutinowski et~al.(2023)Rutinowski, Youssef, Franke, Priyanta,
  Polachowski, Roidl, and Reining]{rutinowskiSemiAutomatedComputerVision2023}
Rutinowski, J., Youssef, H., Franke, S., Priyanta, I.F., Polachowski, F.,
  Roidl, M. and Reining, C.
\newblock Semi-{Automated} {Computer} {Vision} based {Tracking} of {Multiple}
  {Industrial} {Entities} -- {A} {Framework} and {Dataset} {Creation}
  {Approach}, April 2023.
\newblock \doi{10.48550/arXiv.2304.00950}.

\bibitem[Willis et~al.(2021)Willis, Pu, Luo, Chu, Du, Lambourne, Solar-Lezama,
  and Matusik]{willis_fusion_2021}
Willis, K.D.D., Pu, Y., Luo, J., Chu, H., Du, T., Lambourne, J.G.,
  Solar-Lezama, A. and Matusik, W.
\newblock Fusion 360 {Gallery}: {A} {Dataset} and {Environment} for
  {Programmatic} {CAD} {Construction} from {Human} {Design} {Sequences}, May
  2021.
\newblock \doi{10.48550/arXiv.2010.02392}.

\bibitem[Schoepflin et~al.(2021{\natexlab{b}})Schoepflin, Holst, Gomse, and
  Schüppstuhl]{schoepflinSyntheticTrainingData2021}
Schoepflin, D., Holst, D., Gomse, M. and Schüppstuhl, T.
\newblock Synthetic {Training} {Data} {Generation} for {Visual} {Object}
  {Identification} on {Load} {Carriers}.
\newblock \emph{Procedia CIRP}, 104:\penalty0 1257--1262, January
  2021{\natexlab{b}}.
\newblock \doi{10.1016/j.procir.2021.11.211}.

\bibitem[Dekhtiar et~al.(2018)Dekhtiar, Durupt, Bricogne, Eynard, Rowson, and
  Kiritsis]{dekhtiarDeepLearningBig2018}
Dekhtiar, J., Durupt, A., Bricogne, M., Eynard, B., Rowson, H. and Kiritsis, D.
\newblock Deep learning for big data applications in {CAD} and {PLM} –
  {Research} review, opportunities and case study.
\newblock \emph{Computers in Industry}, 100, September 2018.
\newblock \doi{10.1016/j.compind.2018.04.005}.

\bibitem[Alexopoulos et~al.(2020)Alexopoulos, Nikolakis, and
  Chryssolouris]{alexopoulosDigitalTwindrivenSupervised2020}
Alexopoulos, K., Nikolakis, N. and Chryssolouris, G.
\newblock Digital twin-driven supervised machine learning for the development
  of artificial intelligence applications in manufacturing.
\newblock \emph{International Journal of Computer Integrated Manufacturing},
  33\penalty0 (5):\penalty0 429--439, May 2020.
\newblock ISSN 0951-192X.
\newblock \doi{10.1080/0951192X.2020.1747642}.

\bibitem[Manettas et~al.(2021)Manettas, Nikolakis, and
  Alexopoulos]{manettasSyntheticDatasetsDeep2021}
Manettas, C., Nikolakis, N. and Alexopoulos, K.
\newblock Synthetic datasets for {Deep} {Learning} in computer-vision assisted
  tasks in manufacturing.
\newblock \emph{Procedia CIRP}, 103:\penalty0 237--242, January 2021.
\newblock ISSN 2212-8271.
\newblock \doi{10.1016/j.procir.2021.10.038}.

\bibitem[Bashkirova et~al.(2023)Bashkirova, Mishra, Lteif, Teterwak, Kim,
  Alladkani, Akl, Calli, Bargal, Saenko, Kim, Seo, Jeon, Choi, Ettedgui,
  Giryes, Abu-Hussein, Xie, and Li]{bashkirovaVisDA2022Challenge2023}
Bashkirova, D. et~al.
\newblock {VisDA} 2022 {Challenge}: {Domain} {Adaptation} for {Industrial}
  {Waste} {Sorting}, March 2023.
\newblock \doi{10.48550/arXiv.2303.14828}.

\bibitem[Li et~al.(2023{\natexlab{a}})Li, Yan, Qian, Shidong, Zhu, Liao, Tian,
  Li, Wang, and li]{liDomainAdaptationYOLOv52023}
Li, C., Yan, H., Qian, X., Shidong, Z., Zhu, P., Liao, C., Tian, H., Li, X.,
  Wang, X. and li, X.
\newblock A domain adaptation {YOLOv5} model for industrial defect inspection.
\newblock \emph{Measurement}, 213:\penalty0 112725, March 2023{\natexlab{a}}.
\newblock \doi{10.1016/j.measurement.2023.112725}.

\bibitem[Zhang et~al.(2021)Zhang, Zhang, Gu, Su, Li, and
  Pecht]{zhangVisualInspectionSteel2021}
Zhang, S., Zhang, Q., Gu, J., Su, L., Li, K. and Pecht, M.
\newblock Visual inspection of steel surface defects based on domain adaptation
  and adaptive convolutional neural network.
\newblock \emph{Mechanical Systems and Signal Processing}, 153:\penalty0
  107541, May 2021.
\newblock ISSN 0888-3270.
\newblock \doi{10.1016/j.ymssp.2020.107541}.

\bibitem[Bommasani et~al.(2022)Bommasani, Hudson, Adeli, Altman, Arora, von
  Arx, Bernstein, Bohg, Bosselut, Brunskill, Brynjolfsson, Buch, Card,
  Castellon, Chatterji, Chen, Creel, Davis, Demszky, Donahue, Doumbouya,
  Durmus, Ermon, Etchemendy, Ethayarajh, Fei-Fei, Finn, Gale, Gillespie, Goel,
  Goodman, Grossman, Guha, Hashimoto, Henderson, Hewitt, Ho, Hong, Hsu, Huang,
  Icard, Jain, Jurafsky, Kalluri, Karamcheti, Keeling, Khani, Khattab, Koh,
  Krass, Krishna, Kuditipudi, Kumar, Ladhak, Lee, Lee, Leskovec, Levent, Li,
  Li, Ma, Malik, Manning, Mirchandani, Mitchell, Munyikwa, Nair, Narayan,
  Narayanan, Newman, Nie, Niebles, Nilforoshan, Nyarko, Ogut, Orr,
  Papadimitriou, Park, Piech, Portelance, Potts, Raghunathan, Reich, Ren, Rong,
  Roohani, Ruiz, Ryan, Ré, Sadigh, Sagawa, Santhanam, Shih, Srinivasan,
  Tamkin, Taori, Thomas, Tramèr, Wang, Wang, Wu, Wu, Wu, Xie, Yasunaga, You,
  Zaharia, Zhang, Zhang, Zhang, Zhang, Zheng, Zhou, and
  Liang]{bommasaniOpportunitiesRisksFoundation2022}
Bommasani, R. et~al.
\newblock On the {Opportunities} and {Risks} of {Foundation} {Models}, July
  2022.
\newblock \doi{10.48550/arXiv.2108.07258}.

\bibitem[Devlin et~al.(2019)Devlin, Chang, Lee, and
  Toutanova]{devlinBERTPretrainingDeep2019}
Devlin, J., Chang, M.W., Lee, K. and Toutanova, K.
\newblock {BERT}: {Pre}-training of {Deep} {Bidirectional} {Transformers} for
  {Language} {Understanding}, May 2019.
\newblock \doi{10.48550/arXiv.1810.04805}.

\bibitem[Budzianowski and Vulić(2019)]{budzianowskiHelloItGPT22019}
Budzianowski, P. and Vulić, I.
\newblock Hello, {It}'s {GPT}-2 -- {How} {Can} {I} {Help} {You}? {Towards} the
  {Use} of {Pretrained} {Language} {Models} for {Task}-{Oriented} {Dialogue}
  {Systems}, August 2019.
\newblock \doi{10.48550/arXiv.1907.05774}.

\bibitem[Brown et~al.(2020)Brown, Mann, Ryder, Subbiah, Kaplan, Dhariwal,
  Neelakantan, Shyam, Sastry, Askell, Agarwal, Herbert-Voss, Krueger, Henighan,
  Child, Ramesh, Ziegler, Wu, Winter, Hesse, Chen, Sigler, Litwin, Gray, Chess,
  Clark, Berner, McCandlish, Radford, Sutskever, and
  Amodei]{brownLanguageModelsAre2020}
Brown, T.B. et~al.
\newblock Language {Models} are {Few}-{Shot} {Learners}, July 2020.
\newblock \doi{10.48550/arXiv.2005.14165}.

\bibitem[OpenAI(2023)]{openaiGPT4TechnicalReport2023}
OpenAI.
\newblock {GPT}-4 {Technical} {Report}, March 2023.
\newblock \doi{10.48550/arXiv.2303.08774}.

\bibitem[Touvron et~al.(2023)Touvron, Lavril, Izacard, Martinet, Lachaux,
  Lacroix, Rozière, Goyal, Hambro, Azhar, Rodriguez, Joulin, Grave, and
  Lample]{touvronLLaMAOpenEfficient2023}
Touvron, H. et~al.
\newblock {LLaMA}: {Open} and {Efficient} {Foundation} {Language} {Models},
  February 2023.
\newblock \doi{10.48550/arXiv.2302.13971}.

\bibitem[Radford et~al.(2021)Radford, Kim, Hallacy, Ramesh, Goh, Agarwal,
  Sastry, Askell, Mishkin, Clark, Krueger, and
  Sutskever]{radfordLearningTransferableVisual2021}
Radford, A. et~al.
\newblock Learning {Transferable} {Visual} {Models} {From} {Natural} {Language}
  {Supervision}, February 2021.
\newblock \doi{10.48550/arXiv.2103.00020}.

\bibitem[Jia et~al.(2021)Jia, Yang, Xia, Chen, Parekh, Pham, Le, Sung, Li, and
  Duerig]{jiaScalingVisualVisionLanguage2021}
Jia, C., Yang, Y., Xia, Y., Chen, Y.T., Parekh, Z., Pham, H., Le, Q.V., Sung,
  Y., Li, Z. and Duerig, T.
\newblock Scaling {Up} {Visual} and {Vision}-{Language} {Representation}
  {Learning} {With} {Noisy} {Text} {Supervision}, June 2021.
\newblock \doi{10.48550/arXiv.2102.05918}.

\bibitem[Peng et~al.(2023)Peng, Genova, Jiang, Tagliasacchi, Pollefeys, and
  Funkhouser]{pengOpenScene3DScene2023}
Peng, S., Genova, K., Jiang, C.M., Tagliasacchi, A., Pollefeys, M. and
  Funkhouser, T.
\newblock {OpenScene}: {3D} {Scene} {Understanding} with {Open} {Vocabularies},
  April 2023.
\newblock \doi{10.48550/arXiv.2211.15654}.

\bibitem[Yang et~al.(2023{\natexlab{a}})Yang, Ding, Wang, and
  Qi]{yangRegionPLCRegionalPointLanguage2023}
Yang, J., Ding, R., Wang, Z. and Qi, X.
\newblock {RegionPLC}: {Regional} {Point}-{Language} {Contrastive} {Learning}
  for {Open}-{World} {3D} {Scene} {Understanding}, April 2023{\natexlab{a}}.
\newblock \doi{10.48550/arXiv.2304.00962}.

\bibitem[Zhang et~al.(2023{\natexlab{a}})Zhang, Dong, and
  Ma]{zhangCLIPFO3DLearningFree2023}
Zhang, J., Dong, R. and Ma, K.
\newblock {CLIP}-{FO3D}: {Learning} {Free} {Open}-world {3D} {Scene}
  {Representations} from {2D} {Dense} {CLIP}, March 2023{\natexlab{a}}.
\newblock \doi{10.48550/arXiv.2303.04748}.

\bibitem[Vaswani et~al.(2017)Vaswani, Shazeer, Parmar, Uszkoreit, Jones, Gomez,
  Kaiser, and Polosukhin]{vaswaniAttentionAllYou2017}
Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A.N.,
  Kaiser, L. and Polosukhin, I.
\newblock Attention {Is} {All} {You} {Need}, December 2017.
\newblock \doi{10.48550/arXiv.1706.03762}.

\bibitem[Carion et~al.(2020)Carion, Massa, Synnaeve, Usunier, Kirillov, and
  Zagoruyko]{carionEndtoEndObjectDetection2020}
Carion, N., Massa, F., Synnaeve, G., Usunier, N., Kirillov, A. and Zagoruyko,
  S.
\newblock End-to-{End} {Object} {Detection} with {Transformers}, May 2020.
\newblock \doi{10.48550/arXiv.2005.12872}.

\bibitem[Dosovitskiy et~al.(2021)Dosovitskiy, Beyer, Kolesnikov, Weissenborn,
  Zhai, Unterthiner, Dehghani, Minderer, Heigold, Gelly, Uszkoreit, and
  Houlsby]{dosovitskiyImageWorth16x162021}
Dosovitskiy, A. et~al.
\newblock An {Image} is {Worth} 16x16 {Words}: {Transformers} for {Image}
  {Recognition} at {Scale}, June 2021.
\newblock \doi{10.48550/arXiv.2010.11929}.

\bibitem[Zhai et~al.(2022)Zhai, Kolesnikov, Houlsby, and
  Beyer]{zhaiScalingVisionTransformers2022}
Zhai, X., Kolesnikov, A., Houlsby, N. and Beyer, L.
\newblock Scaling {Vision} {Transformers}, June 2022.
\newblock \doi{10.48550/arXiv.2106.04560}.

\bibitem[Wang et~al.(2023{\natexlab{a}})Wang, Dai, Chen, Huang, Li, Zhu, Hu,
  Lu, Lu, Li, Wang, and Qiao]{wangInternImageExploringLargeScale2023}
Wang, W. et~al.
\newblock {InternImage}: {Exploring} {Large}-{Scale} {Vision} {Foundation}
  {Models} with {Deformable} {Convolutions}, April 2023{\natexlab{a}}.
\newblock \doi{10.48550/arXiv.2211.05778}.

\bibitem[Kirillov et~al.(2023)Kirillov, Mintun, Ravi, Mao, Rolland, Gustafson,
  Xiao, Whitehead, Berg, Lo, Dollár, and
  Girshick]{kirillovSegmentAnything2023}
Kirillov, A. et~al.
\newblock Segment {Anything}, April 2023.
\newblock \doi{10.48550/arXiv.2304.02643}.

\bibitem[{Jim Fan
  [@DrJimFan]}(2023)]{jimfan[@drjimfan]ReadingMetaAISegmentAnything2023}
{Jim Fan [@DrJimFan]}.
\newblock Reading @{MetaAI}'s {Segment}-{Anything}, and {I} believe today is
  one of the "{GPT}-3 moments" in computer vision. {It} has learned the
  *general* concept of what an "object" is, even for unknown objects,
  unfamiliar scenes (e.g. underwater \& cell microscopy), and ambiguous cases.
  {I} still…, April 2023.
\newblock URL \url{https://twitter.com/DrJimFan/status/1643647849824161792}.

\bibitem[Zhang et~al.(2023{\natexlab{b}})Zhang, Liu, Cui, Huang, Lin, Yang, and
  Hu]{zhangComprehensiveSurveySegment2023}
Zhang, C., Liu, L., Cui, Y., Huang, G., Lin, W., Yang, Y. and Hu, Y.
\newblock A {Comprehensive} {Survey} on {Segment} {Anything} {Model} for
  {Vision} and {Beyond}, May 2023{\natexlab{b}}.
\newblock \doi{10.48550/arXiv.2305.08196}.

\bibitem[Kellener et~al.(2023)Kellener, Nath, Ngo, Nguyen, Schuman, Adler, and
  Kartikeya]{kellener_utilizing_2023}
Kellener, E., Nath, I., Ngo, A., Nguyen, T., Schuman, J., Adler, C. and
  Kartikeya, A.
\newblock Utilizing {Segment} {Anything} {Model} {For} {Assessing}
  {Localization} of {GRAD}-{CAM} in {Medical} {Imaging}, June 2023.
\newblock \doi{10.48550/arXiv.2306.15692}.

\bibitem[Lei et~al.(2023)Lei, Wei, Zhang, Li, and Zhang]{lei_medlsam_2023}
Lei, W., Wei, X., Zhang, X., Li, K. and Zhang, S.
\newblock {MedLSAM}: {Localize} and {Segment} {Anything} {Model} for {3D}
  {Medical} {Images}, June 2023.
\newblock \doi{10.48550/arXiv.2306.14752}.

\bibitem[Zhang and Jiao(2023)]{zhangHowSegmentAnything2023}
Zhang, Y. and Jiao, R.
\newblock How {Segment} {Anything} {Model} ({SAM}) {Boost} {Medical} {Image}
  {Segmentation}?, May 2023.
\newblock \doi{10.48550/arXiv.2305.03678}.

\bibitem[Cheng et~al.(2023{\natexlab{a}})Cheng, Qin, Jiang, Zhang, Lao, and
  Li]{chengSAMMedicalImages2023}
Cheng, D., Qin, Z., Jiang, Z., Zhang, S., Lao, Q. and Li, K.
\newblock {SAM} on {Medical} {Images}: {A} {Comprehensive} {Study} on {Three}
  {Prompt} {Modes}, April 2023{\natexlab{a}}.
\newblock \doi{10.48550/arXiv.2305.00035}.

\bibitem[Deng et~al.(2023)Deng, Cui, Liu, Yao, Remedios, Bao, Landman, Wheless,
  Coburn, Wilson, Wang, Zhao, Fogo, Yang, Tang, and
  Huo]{dengSegmentAnythingModel2023}
Deng, R. et~al.
\newblock Segment {Anything} {Model} ({SAM}) for {Digital} {Pathology}:
  {Assess} {Zero}-shot {Segmentation} on {Whole} {Slide} {Imaging}, April 2023.
\newblock \doi{10.48550/arXiv.2304.04155}.

\bibitem[He et~al.(2023{\natexlab{a}})He, Bao, Li, Stout, Bjornerud, Grant, and
  Ou]{heComputerVisionBenchmarkSegmentAnything2023}
He, S., Bao, R., Li, J., Stout, J., Bjornerud, A., Grant, P.E. and Ou, Y.
\newblock Computer-{Vision} {Benchmark} {Segment}-{Anything} {Model} ({SAM}) in
  {Medical} {Images}: {Accuracy} in 12 {Datasets}, May 2023{\natexlab{a}}.
\newblock \doi{10.48550/arXiv.2304.09324}.

\bibitem[Huang et~al.(2023)Huang, Yang, Liu, Zhou, Chang, Zhou, Chen, Yu, Chen,
  Chen, Chi, Hu, Fan, Dong, and Ni]{huangSegmentAnythingModel2023}
Huang, Y. et~al.
\newblock Segment {Anything} {Model} for {Medical} {Images}?, May 2023.
\newblock \doi{10.48550/arXiv.2304.14660}.

\bibitem[Hu et~al.(2023{\natexlab{a}})Hu, Li, and
  Yang]{huBreastSAMStudySegment2023}
Hu, M., Li, Y. and Yang, X.
\newblock {BreastSAM}: {A} {Study} of {Segment} {Anything} {Model} for {Breast}
  {Tumor} {Detection} in {Ultrasound} {Images}, May 2023{\natexlab{a}}.
\newblock \doi{10.48550/arXiv.2305.12447}.

\bibitem[Hu et~al.(2023{\natexlab{b}})Hu, Li, and
  Yang]{huSkinSAMEmpoweringSkin2023}
Hu, M., Li, Y. and Yang, X.
\newblock {SkinSAM}: {Empowering} {Skin} {Cancer} {Segmentation} with {Segment}
  {Anything} {Model}, April 2023{\natexlab{b}}.
\newblock \doi{10.48550/arXiv.2304.13973}.

\bibitem[Hu et~al.(2023{\natexlab{c}})Hu, Xia, Ju, and Li]{huWhenSAMMeets2023}
Hu, C., Xia, T., Ju, S. and Li, X.
\newblock When {SAM} {Meets} {Medical} {Images}: {An} {Investigation} of
  {Segment} {Anything} {Model} ({SAM}) on {Multi}-phase {Liver} {Tumor}
  {Segmentation}, May 2023{\natexlab{c}}.
\newblock \doi{10.48550/arXiv.2304.08506}.

\bibitem[Iytha~Sridhar and
  Kamaleswaran(2023)]{iythasridharLungSegmentAnything2023}
Iytha~Sridhar, R. and Kamaleswaran, R.
\newblock Lung {Segment} {Anything} {Model} ({LuSAM}): {A} {Prompt}-integrated
  {Framework} for {Automated} {Lung} {Segmentation} on {ICU} {Chest} {X}-{Ray}
  {Images}, May 2023.
\newblock \doi{10.36227/techrxiv.22788959.v1}.

\bibitem[Li et~al.(2023{\natexlab{b}})Li, Hu, and
  Yang]{liPolypSAMTransferSAM2023}
Li, Y., Hu, M. and Yang, X.
\newblock Polyp-{SAM}: {Transfer} {SAM} for {Polyp} {Segmentation}, April
  2023{\natexlab{b}}.
\newblock \doi{10.48550/arXiv.2305.00293}.

\bibitem[Ma and Wang(2023)]{maSegmentAnythingMedical2023}
Ma, J. and Wang, B.
\newblock Segment {Anything} in {Medical} {Images}, April 2023.
\newblock \doi{10.48550/arXiv.2304.12306}.

\bibitem[Mattjie et~al.(2023)Mattjie, de~Moura, Ravazio, Kupssinskü, Parraga,
  Delucis, and Barros]{mattjieZeroshotPerformanceSegment2023}
Mattjie, C., de~Moura, L.V., Ravazio, R.C., Kupssinskü, L.S., Parraga, O.,
  Delucis, M.M. and Barros, R.C.
\newblock Zero-shot performance of the {Segment} {Anything} {Model} ({SAM}) in
  {2D} medical imaging: {A} comprehensive evaluation and practical guidelines,
  May 2023.
\newblock \doi{10.48550/arXiv.2305.00109}.

\bibitem[Mazurowski et~al.(2023)Mazurowski, Dong, Gu, Yang, Konz, and
  Zhang]{mazurowskiSegmentAnythingModel2023}
Mazurowski, M.A., Dong, H., Gu, H., Yang, J., Konz, N. and Zhang, Y.
\newblock Segment {Anything} {Model} for {Medical} {Image} {Analysis}: an
  {Experimental} {Study}, May 2023.
\newblock \doi{10.48550/arXiv.2304.10517}.

\bibitem[Mohapatra et~al.(2023)Mohapatra, Gosai, and
  Schlaug]{mohapatraSAMVsBET2023}
Mohapatra, S., Gosai, A. and Schlaug, G.
\newblock {SAM} vs {BET}: {A} {Comparative} {Study} for {Brain} {Extraction}
  and {Segmentation} of {Magnetic} {Resonance} {Images} using {Deep}
  {Learning}, April 2023.
\newblock \doi{10.48550/arXiv.2304.04738}.

\bibitem[Qiu et~al.(2023)Qiu, Hu, Li, and
  Liu]{qiuLearnableOphthalmologySAM2023}
Qiu, Z., Hu, Y., Li, H. and Liu, J.
\newblock Learnable {Ophthalmology} {SAM}, April 2023.
\newblock \doi{10.48550/arXiv.2304.13425}.

\bibitem[Roy et~al.(2023)Roy, Wald, Koehler, Rokuss, Disch, Holzschuh,
  Zimmerer, and Maier-Hein]{roySAMMDZeroshot2023}
Roy, S., Wald, T., Koehler, G., Rokuss, M.R., Disch, N., Holzschuh, J.,
  Zimmerer, D. and Maier-Hein, K.H.
\newblock {SAM}.{MD}: {Zero}-shot medical image segmentation capabilities of
  the {Segment} {Anything} {Model}, April 2023.
\newblock \doi{10.48550/arXiv.2304.05396}.

\bibitem[Shi et~al.(2023{\natexlab{a}})Shi, Qiu, Abaxi, Wei, Lo, and
  Yuan]{shiGeneralistVisionFoundation2023}
Shi, P., Qiu, J., Abaxi, S.M.D., Wei, H., Lo, F.P.W. and Yuan, W.
\newblock Generalist {Vision} {Foundation} {Models} for {Medical} {Imaging}:
  {A} {Case} {Study} of {Segment} {Anything} {Model} on {Zero}-{Shot} {Medical}
  {Segmentation}, April 2023{\natexlab{a}}.
\newblock \doi{10.48550/arXiv.2304.12637}.

\bibitem[Wu et~al.(2023)Wu, Zhang, Fu, Fang, Liu, Wang, Xu, and
  Jin]{wuMedicalSAMAdapter2023}
Wu, J., Zhang, Y., Fu, R., Fang, H., Liu, Y., Wang, Z., Xu, Y. and Jin, Y.
\newblock Medical {SAM} {Adapter}: {Adapting} {Segment} {Anything} {Model} for
  {Medical} {Image} {Segmentation}, May 2023.
\newblock \doi{10.48550/arXiv.2304.12620}.

\bibitem[Zhou et~al.(2023{\natexlab{b}})Zhou, Zhang, Zhou, Wu, and
  Gong]{zhouCanSAMSegment2023}
Zhou, T., Zhang, Y., Zhou, Y., Wu, Y. and Gong, C.
\newblock Can {SAM} {Segment} {Polyps}?, April 2023{\natexlab{b}}.
\newblock \doi{10.48550/arXiv.2304.07583}.

\bibitem[Semeraro et~al.(2023)Semeraro, Quintart, Izquierdo, and
  Ferguson]{semeraro_tomosam_2023}
Semeraro, F., Quintart, A., Izquierdo, S.F. and Ferguson, J.C.
\newblock {TomoSAM}: a {3D} {Slicer} extension using {SAM} for tomography
  segmentation, June 2023.
\newblock \doi{10.48550/arXiv.2306.08609}.

\bibitem[Chen et~al.(2023{\natexlab{a}})Chen, Liu, Chen, Zhang, Li, Zou, and
  Shi]{chen_rsprompter_2023}
Chen, K., Liu, C., Chen, H., Zhang, H., Li, W., Zou, Z. and Shi, Z.
\newblock {RSPrompter}: {Learning} to {Prompt} for {Remote} {Sensing}
  {Instance} {Segmentation} based on {Visual} {Foundation} {Model}, June
  2023{\natexlab{a}}.
\newblock \doi{10.48550/arXiv.2306.16269}.

\bibitem[Shankar et~al.(2023)Shankar, Stearns, and Veen]{shankar_segment_2023}
Shankar, S., Stearns, L.A. and Veen, C.J.V.D.
\newblock Segment {Anything} in {Glaciology}: {An} initial study implementing
  the {Segment} {Anything} {Model} ({SAM}), June 2023.
\newblock \doi{10.21203/rs.3.rs-3011246/v1}.

\bibitem[Ren et~al.(2023)Ren, Luzi, Lahrichi, Kassaw, Collins, Bradbury, and
  Malof]{renSegmentAnythingSpace2023}
Ren, S., Luzi, F., Lahrichi, S., Kassaw, K., Collins, L.M., Bradbury, K. and
  Malof, J.M.
\newblock Segment anything, from space?, May 2023.
\newblock \doi{10.48550/arXiv.2304.13000}.

\bibitem[Wang et~al.(2023{\natexlab{b}})Wang, Zhang, Du, Tao, and
  Zhang]{wangScalingupRemoteSensing2023}
Wang, D., Zhang, J., Du, B., Tao, D. and Zhang, L.
\newblock Scaling-up {Remote} {Sensing} {Segmentation} {Dataset} with {Segment}
  {Anything} {Model}, May 2023{\natexlab{b}}.
\newblock \doi{10.48550/arXiv.2305.02034}.

\bibitem[Osco et~al.(2023)Osco, Wu, de~Lemos, Gonçalves, Ramos, Li, and
  Junior]{osco_segment_2023}
Osco, L.P., Wu, Q., de~Lemos, E.L., Gonçalves, W.N., Ramos, A.P.M., Li, J. and
  Junior, J.M.
\newblock The {Segment} {Anything} {Model} ({SAM}) for {Remote} {Sensing}
  {Applications}: {From} {Zero} to {One} {Shot}, June 2023.
\newblock \doi{10.48550/arXiv.2306.16623}.

\bibitem[Giannakis et~al.(2023)Giannakis, Bhardwaj, Sam, and
  Leontidis]{giannakis_deep_2023}
Giannakis, I., Bhardwaj, A., Sam, L. and Leontidis, G.
\newblock Deep learning universal crater detection using {Segment} {Anything}
  {Model} ({SAM}), April 2023.
\newblock \doi{10.48550/arXiv.2304.07764}.

\bibitem[Julka and Granitzer(2023)]{julkaKnowledgeDistillationSegment2023}
Julka, S. and Granitzer, M.
\newblock Knowledge distillation with {Segment} {Anything} ({SAM}) model for
  {Planetary} {Geological} {Mapping}, May 2023.
\newblock \doi{10.48550/arXiv.2305.07586}.

\bibitem[Ahmadi et~al.(2023)Ahmadi, Lonbar, Sharifi, Beris, Nouri, and
  Javidi]{ahmadiApplicationSegmentAnything2023}
Ahmadi, M., Lonbar, A.G., Sharifi, A., Beris, A.T., Nouri, M. and Javidi, A.S.
\newblock Application of {Segment} {Anything} {Model} for {Civil}
  {Infrastructure} {Defect} {Assessment}, April 2023.
\newblock \doi{10.48550/arXiv.2304.12600}.

\bibitem[Glatt and Liu(2023)]{glatt_topological_2023}
Glatt, R. and Liu, S.
\newblock Topological {Data} {Analysis} {Guided} {Segment} {Anything} {Model}
  {Prompt} {Optimization} for {Zero}-{Shot} {Segmentation} in {Biological}
  {Imaging}, June 2023.
\newblock \doi{10.48550/arXiv.2306.17400}.

\bibitem[Wang et~al.(2023{\natexlab{c}})Wang, Ye, Zhu, Wu, Zhang, Xing, and
  Hu]{wang_when_2023}
Wang, L., Ye, X., Zhu, L., Wu, W., Zhang, J., Xing, H. and Hu, C.
\newblock When {SAM} {Meets} {Sonar} {Images}, June 2023{\natexlab{c}}.
\newblock \doi{10.48550/arXiv.2306.14109}.

\bibitem[Williams et~al.(2023)Williams, Macfarlane, and
  Britten]{williamsLeafOnlySAM2023}
Williams, D., Macfarlane, F. and Britten, A.
\newblock Leaf {Only} {SAM}: {A} {Segment} {Anything} {Pipeline} for
  {Zero}-{Shot} {Automated} {Leaf} {Segmentation}, May 2023.
\newblock \doi{10.48550/arXiv.2305.09418}.

\bibitem[Yang et~al.(2023{\natexlab{b}})Yang, Dai, Wu, Bist, Subedi, Sun, Lu,
  Li, Liu, and Chai]{yangSAMPoultryScience2023}
Yang, X., Dai, H., Wu, Z., Bist, R., Subedi, S., Sun, J., Lu, G., Li, C., Liu,
  T. and Chai, L.
\newblock {SAM} for {Poultry} {Science}, May 2023{\natexlab{b}}.
\newblock \doi{10.48550/arXiv.2305.10254}.

\bibitem[Ji et~al.(2023)Ji, Li, Bi, Liu, Li, and Cheng]{ji_segment_2023}
Ji, W., Li, J., Bi, Q., Liu, T., Li, W. and Cheng, L.
\newblock Segment {Anything} {Is} {Not} {Always} {Perfect}: {An}
  {Investigation} of {SAM} on {Different} {Real}-world {Applications}, May
  2023.
\newblock \doi{10.48550/arXiv.2304.05750}.

\bibitem[Zhang et~al.(2023{\natexlab{c}})Zhang, Zheng, Li, Qiao, Kang, Shan,
  Zhang, Qin, Rameau, Bae, and Hong]{zhangSurveySegmentAnything2023}
Zhang, C. et~al.
\newblock \emph{A {Survey} on {Segment} {Anything} {Model} ({SAM}): {Vision}
  {Foundation} {Model} {Meets} {Prompt} {Engineering}}.
\newblock May 2023{\natexlab{c}}.
\newblock \doi{10.13140/RG.2.2.14928.17923}.

\bibitem[noa(2023{\natexlab{a}})]{noauthor_grounded-segment-anything_2023}
Grounded-{Segment}-{Anything}, June 2023{\natexlab{a}}.
\newblock URL \url{https://github.com/IDEA-Research/Grounded-Segment-Anything}.

\bibitem[Ke et~al.(2023)Ke, Ye, Danelljan, Liu, Tai, Tang, and
  Yu]{ke_segment_2023}
Ke, L., Ye, M., Danelljan, M., Liu, Y., Tai, Y.W., Tang, C.K. and Yu, F.
\newblock Segment {Anything} in {High} {Quality}, June 2023.
\newblock URL \url{http://arxiv.org/abs/2306.01567}.

\bibitem[Zhang et~al.(2023{\natexlab{d}})Zhang, Han, Qiao, Kim, Bae, Lee, and
  Hong]{zhang_faster_2023}
Zhang, C., Han, D., Qiao, Y., Kim, J.U., Bae, S.H., Lee, S. and Hong, C.S.
\newblock Faster {Segment} {Anything}: {Towards} {Lightweight} {SAM} for
  {Mobile} {Applications}, July 2023{\natexlab{d}}.
\newblock \doi{10.48550/arXiv.2306.14289}.

\bibitem[He et~al.(2023{\natexlab{b}})He, Li, Zhang, Xu, Tang, Zhang, Guo, and
  Li]{heWeaklySupervisedConcealedObject2023}
He, C., Li, K., Zhang, Y., Xu, G., Tang, L., Zhang, Y., Guo, Z. and Li, X.
\newblock Weakly-{Supervised} {Concealed} {Object} {Segmentation} with
  {SAM}-based {Pseudo} {Labeling} and {Multi}-scale {Feature} {Grouping}, May
  2023{\natexlab{b}}.
\newblock \doi{10.48550/arXiv.2305.11003}.

\bibitem[Jiang and Yang(2023)]{jiangSegmentAnythingGood2023}
Jiang, P.T. and Yang, Y.
\newblock Segment {Anything} is {A} {Good} {Pseudo}-label {Generator} for
  {Weakly} {Supervised} {Semantic} {Segmentation}, May 2023.
\newblock \doi{10.48550/arXiv.2305.01275}.

\bibitem[Sun et~al.(2023)Sun, Liu, Zhang, Zhong, and
  Barnes]{sunAlternativeWSSSEmpirical2023}
Sun, W., Liu, Z., Zhang, Y., Zhong, Y. and Barnes, N.
\newblock An {Alternative} to {WSSS}? {An} {Empirical} {Study} of the {Segment}
  {Anything} {Model} ({SAM}) on {Weakly}-{Supervised} {Semantic} {Segmentation}
  {Problems}, May 2023.
\newblock \doi{10.48550/arXiv.2305.01586}.

\bibitem[Cui et~al.(2023)Cui, Deng, Liu, Yao, Bao, Remedios, Tang, and
  Huo]{cui_all--sam_2023}
Cui, C., Deng, R., Liu, Q., Yao, T., Bao, S., Remedios, L.W., Tang, Y. and Huo,
  Y.
\newblock All-in-{SAM}: from {Weak} {Annotation} to {Pixel}-wise {Nuclei}
  {Segmentation} with {Prompt}-based {Finetuning}, July 2023.
\newblock \doi{10.48550/arXiv.2307.00290}.

\bibitem[Chen et~al.(2023{\natexlab{b}})Chen, Mai, Li, and
  Chao]{chenSegmentAnythingModel2023}
Chen, T., Mai, Z., Li, R. and Chao, W.l.
\newblock Segment {Anything} {Model} ({SAM}) {Enhanced} {Pseudo} {Labels} for
  {Weakly} {Supervised} {Semantic} {Segmentation}, May 2023{\natexlab{b}}.
\newblock \doi{10.48550/arXiv.2305.05803}.

\bibitem[Li et~al.(2022{\natexlab{a}})Li, Li, Xiong, and Hoi]{li_blip_2022}
Li, J., Li, D., Xiong, C. and Hoi, S.
\newblock {BLIP}: {Bootstrapping} {Language}-{Image} {Pre}-training for
  {Unified} {Vision}-{Language} {Understanding} and {Generation}, February
  2022{\natexlab{a}}.
\newblock \doi{10.48550/arXiv.2201.12086}.

\bibitem[Nichol et~al.(2022)Nichol, Jun, Dhariwal, Mishkin, and
  Chen]{nichol_point-e_2022}
Nichol, A., Jun, H., Dhariwal, P., Mishkin, P. and Chen, M.
\newblock Point-{E}: {A} {System} for {Generating} {3D} {Point} {Clouds} from
  {Complex} {Prompts}, December 2022.
\newblock \doi{10.48550/arXiv.2212.08751}.

\bibitem[Shen et~al.(2023)Shen, Yang, and
  Wang]{shenAnything3DSingleviewAnything2023}
Shen, Q., Yang, X. and Wang, X.
\newblock Anything-{3D}: {Towards} {Single}-view {Anything} {Reconstruction} in
  the {Wild}, April 2023.
\newblock \doi{10.48550/arXiv.2304.10261}.

\bibitem[Wang et~al.(2023{\natexlab{d}})Wang, Zhang, Fei, Zheng, Tang, Li, Gao,
  and Zhao]{wangCaptionAnythingInteractive2023}
Wang, T., Zhang, J., Fei, J., Zheng, H., Tang, Y., Li, Z., Gao, M. and Zhao, S.
\newblock Caption {Anything}: {Interactive} {Image} {Description} with
  {Diverse} {Multimodal} {Controls}, May 2023{\natexlab{d}}.
\newblock \doi{10.48550/arXiv.2305.02677}.

\bibitem[Chen et~al.(2023{\natexlab{c}})Chen, Yang, and
  Zhang]{chen2023semantic}
Chen, J., Yang, Z. and Zhang, L.
\newblock Semantic segment anything, 2023{\natexlab{c}}.
\newblock URL \url{https://github.com/fudan-zvg/Semantic-Segment-Anything}.

\bibitem[Liu et~al.(2023{\natexlab{a}})Liu, Zeng, Ren, Li, Zhang, Yang, Li,
  Yang, Su, Zhu, and Zhang]{liu_grounding_2023}
Liu, S. et~al.
\newblock Grounding {DINO}: {Marrying} {DINO} with {Grounded} {Pre}-{Training}
  for {Open}-{Set} {Object} {Detection}, March 2023{\natexlab{a}}.
\newblock \doi{10.48550/arXiv.2303.05499}.

\bibitem[Cao et~al.(2023)Cao, Xu, Sun, Cheng, Du, Gao, and
  Shen]{cao_segment_2023}
Cao, Y., Xu, X., Sun, C., Cheng, Y., Du, Z., Gao, L. and Shen, W.
\newblock Segment {Any} {Anomaly} without {Training} via {Hybrid} {Prompt}
  {Regularization}, May 2023.
\newblock \doi{10.48550/arXiv.2305.10724}.

\bibitem[Yan(2023)]{yan2023count}
Yan, L.
\newblock Count anything, 2023.
\newblock URL \url{https://github.com/ylqi/Count-Anything}.

\bibitem[Jie and Zhang(2023)]{jieWhenSAMMeets2023}
Jie, L. and Zhang, H.
\newblock When {SAM} {Meets} {Shadow} {Detection}, May 2023.
\newblock \doi{10.48550/arXiv.2305.11513}.

\bibitem[Wang et~al.(2023{\natexlab{e}})Wang, Zhou, Mao, and
  Li]{wangDetectAnyShadow2023}
Wang, Y., Zhou, W., Mao, Y. and Li, H.
\newblock Detect {Any} {Shadow}: {Segment} {Anything} for {Video} {Shadow}
  {Detection}, May 2023{\natexlab{e}}.
\newblock \doi{10.48550/arXiv.2305.16698}.

\bibitem[Zhang et~al.(2023{\natexlab{e}})Zhang, Gu, and
  Zhu]{zhang_sam-helps-shadowwhen_2023}
Zhang, X., Gu, C. and Zhu, S.
\newblock {SAM}-helps-{Shadow}:{When} {Segment} {Anything} {Model} meet shadow
  removal, June 2023{\natexlab{e}}.
\newblock \doi{10.48550/arXiv.2306.06113}.

\bibitem[Li et~al.(2023{\natexlab{c}})Li, Jain, and Shi]{li_matting_2023}
Li, J., Jain, J. and Shi, H.
\newblock Matting {Anything}, June 2023{\natexlab{c}}.
\newblock \doi{10.48550/arXiv.2306.05399}.

\bibitem[Yao et~al.(2023)Yao, Wang, Ye, and Liu]{yao_matte_2023}
Yao, J., Wang, X., Ye, L. and Liu, W.
\newblock Matte {Anything}: {Interactive} {Natural} {Image} {Matting} with
  {Segment} {Anything} {Models}, June 2023.
\newblock \doi{10.48550/arXiv.2306.04121}.

\bibitem[Wang et~al.(2023{\natexlab{f}})Wang, Zhang, Abboud, and
  Süsstrunk]{wangInpaintNeRF360TextGuided3D2023}
Wang, D., Zhang, T., Abboud, A. and Süsstrunk, S.
\newblock {InpaintNeRF360}: {Text}-{Guided} {3D} {Inpainting} on {Unbounded}
  {Neural} {Radiance} {Fields}, May 2023{\natexlab{f}}.
\newblock \doi{10.48550/arXiv.2305.15094}.

\bibitem[Yu et~al.(2023)Yu, Feng, Feng, Liu, Jin, Zeng, and
  Chen]{yuInpaintAnythingSegment2023}
Yu, T., Feng, R., Feng, R., Liu, J., Jin, X., Zeng, W. and Chen, Z.
\newblock Inpaint {Anything}: {Segment} {Anything} {Meets} {Image}
  {Inpainting}, April 2023.
\newblock \doi{10.48550/arXiv.2304.06790}.

\bibitem[Jiang and Holz(2023)]{jiangRestoreAnythingPipeline2023}
Jiang, J. and Holz, C.
\newblock Restore {Anything} {Pipeline}: {Segment} {Anything} {Meets} {Image}
  {Restoration}, May 2023.
\newblock \doi{10.48550/arXiv.2305.13093}.

\bibitem[Luo et~al.(2023)Luo, Yan, and Li]{luo_calib-anything_2023}
Luo, Z., Yan, G. and Li, Y.
\newblock Calib-{Anything}: {Zero}-training {LiDAR}-{Camera} {Extrinsic}
  {Calibration} {Method} {Using} {Segment} {Anything}, June 2023.
\newblock \doi{10.48550/arXiv.2306.02656}.

\bibitem[Lu et~al.(2023)Lu, Xiao, Bai, Xiong, and Wang]{luCanSAMBoost2023}
Lu, Z., Xiao, Z., Bai, J., Xiong, Z. and Wang, X.
\newblock Can {SAM} {Boost} {Video} {Super}-{Resolution}?, May 2023.
\newblock \doi{10.48550/arXiv.2305.06524}.

\bibitem[Cheng et~al.(2023{\natexlab{b}})Cheng, Li, Xu, Li, Yang, Wang, and
  Yang]{chengSegmentTrackAnything2023}
Cheng, Y., Li, L., Xu, Y., Li, X., Yang, Z., Wang, W. and Yang, Y.
\newblock Segment and {Track} {Anything}, May 2023{\natexlab{b}}.
\newblock \doi{10.48550/arXiv.2305.06558}.

\bibitem[Yang et~al.(2023{\natexlab{c}})Yang, Gao, Li, Gao, Wang, and
  Zheng]{yangTrackAnythingSegment2023}
Yang, J., Gao, M., Li, Z., Gao, S., Wang, F. and Zheng, F.
\newblock Track {Anything}: {Segment} {Anything} {Meets} {Videos}, April
  2023{\natexlab{c}}.
\newblock \doi{10.48550/arXiv.2304.11968}.

\bibitem[Zhang et~al.(2023{\natexlab{f}})Zhang, Wei, Zhang, Dai, and
  Zhu]{zhangUVOSAMMaskfreeParadigm2023}
Zhang, Z., Wei, Z., Zhang, S., Dai, Z. and Zhu, S.
\newblock {UVOSAM}: {A} {Mask}-free {Paradigm} for {Unsupervised} {Video}
  {Object} {Segmentation} via {Segment} {Anything} {Model}, May
  2023{\natexlab{f}}.
\newblock \doi{10.48550/arXiv.2305.12659}.

\bibitem[Zhou et~al.(2023{\natexlab{c}})Zhou, Wu, Boutteau, Yang, and
  Ginhac]{zhouDSECMOSSegmentAny2023}
Zhou, Z., Wu, Z., Boutteau, R., Yang, F. and Ginhac, D.
\newblock {DSEC}-{MOS}: {Segment} {Any} {Moving} {Object} with {Moving} {Ego}
  {Vehicle}, April 2023{\natexlab{c}}.
\newblock \doi{10.48550/arXiv.2305.00126}.

\bibitem[Rajič et~al.(2023)Rajič, Ke, Tai, Tang, Danelljan, and
  Yu]{rajic_segment_2023}
Rajič, F., Ke, L., Tai, Y.W., Tang, C.K., Danelljan, M. and Yu, F.
\newblock Segment {Anything} {Meets} {Point} {Tracking}, July 2023.
\newblock \doi{10.48550/arXiv.2307.01197}.

\bibitem[Li et~al.(2023{\natexlab{d}})Li, Zhang, Teng, and Lan]{li_refsam_2023}
Li, Y., Zhang, J., Teng, X. and Lan, L.
\newblock {RefSAM}: {Efficiently} {Adapting} {Segmenting} {Anything} {Model}
  for {Referring} {Video} {Object} {Segmentation}, July 2023{\natexlab{d}}.
\newblock \doi{10.48550/arXiv.2307.00997}.

\bibitem[Ma et~al.(2023)Ma, Hong, and Shangguan]{maCanSAMCount2023a}
Ma, Z., Hong, X. and Shangguan, Q.
\newblock Can {SAM} {Count} {Anything}? {An} {Empirical} {Study} on {SAM}
  {Counting}, April 2023.
\newblock \doi{10.48550/arXiv.2304.10817}.

\bibitem[Shi et~al.(2023{\natexlab{b}})Shi, Sun, and
  Zhang]{shi_training-free_2023}
Shi, Z., Sun, Y. and Zhang, M.
\newblock Training-free {Object} {Counting} with {Prompts}, June
  2023{\natexlab{b}}.
\newblock \doi{10.48550/arXiv.2307.00038}.

\bibitem[Wang et~al.(2023{\natexlab{g}})Wang, Aboah, Zhang, and
  Bagci]{wangGazeSAMWhatYou2023}
Wang, B., Aboah, A., Zhang, Z. and Bagci, U.
\newblock {GazeSAM}: {What} {You} {See} is {What} {You} {Segment}, April
  2023{\natexlab{g}}.
\newblock \doi{10.48550/arXiv.2304.13844}.

\bibitem[He et~al.(2023{\natexlab{c}})He, Chen, Tan, and Wang]{he_usd_2023}
He, Y., Chen, W., Tan, Y. and Wang, S.
\newblock {USD}: {Unknown} {Sensitive} {Detector} {Empowered} by {Decoupled}
  {Objectness} and {Segment} {Anything} {Model}, June 2023{\natexlab{c}}.
\newblock \doi{10.48550/arXiv.2306.02275}.

\bibitem[Hu et~al.(2021)Hu, Shen, Wallis, Allen-Zhu, Li, Wang, Wang, and
  Chen]{hu_lora_2021}
Hu, E.J., Shen, Y., Wallis, P., Allen-Zhu, Z., Li, Y., Wang, S., Wang, L. and
  Chen, W.
\newblock {LoRA}: {Low}-{Rank} {Adaptation} of {Large} {Language} {Models},
  October 2021.
\newblock \doi{10.48550/arXiv.2106.09685}.

\bibitem[Zhang and Liu(2023)]{zhangCustomizedSegmentAnything2023}
Zhang, K. and Liu, D.
\newblock Customized {Segment} {Anything} {Model} for {Medical} {Image}
  {Segmentation}, April 2023.
\newblock \doi{10.48550/arXiv.2304.13785}.

\bibitem[Zhang et~al.(2023{\natexlab{g}})Zhang, Jiang, Guo, Yan, Pan, Dong,
  Gao, and Li]{zhangPersonalizeSegmentAnything2023}
Zhang, R., Jiang, Z., Guo, Z., Yan, S., Pan, J., Dong, H., Gao, P. and Li, H.
\newblock Personalize {Segment} {Anything} {Model} with {One} {Shot}, May
  2023{\natexlab{g}}.
\newblock \doi{10.48550/arXiv.2305.03048}.

\bibitem[Shaharabany et~al.(2023)Shaharabany, Dahan, Giryes, and
  Wolf]{shaharabany_autosam_2023}
Shaharabany, T., Dahan, A., Giryes, R. and Wolf, L.
\newblock {AutoSAM}: {Adapting} {SAM} to {Medical} {Images} by {Overloading}
  the {Prompt} {Encoder}, June 2023.
\newblock \doi{10.48550/arXiv.2306.06370}.

\bibitem[Liu et~al.(2023{\natexlab{b}})Liu, Zhu, Li, Chen, Wang, and
  Shen]{liuMatcherSegmentAnything2023}
Liu, Y., Zhu, M., Li, H., Chen, H., Wang, X. and Shen, C.
\newblock Matcher: {Segment} {Anything} with {One} {Shot} {Using}
  {All}-{Purpose} {Feature} {Matching}, May 2023{\natexlab{b}}.
\newblock \doi{10.48550/arXiv.2305.13310}.

\bibitem[noa(2023{\natexlab{b}})]{noauthor_recovery_2023}
Recovery climb continues - {Commercial} {Aerospace} {Insight} {Report}.
\newblock Technical report, accenture, April 2023{\natexlab{b}}.
\newblock URL
  \url{https://www.accenture.com/content/dam/accenture/final/industry/aerospace-and-defense/document/Accenture-Recovery-Climb-Continues-April-2023.pdf}.

\bibitem[Hornberg(2017)]{hornberg_handbook_2017}
Hornberg, A., editor.
\newblock \emph{Handbook of machine and computer vision: the guide for
  developers and users}.
\newblock Wiley-VCH, Weinheim, Germany, second, revised and updated edition
  edition, 2017.
\newblock ISBN 978-3-527-41341-6 978-3-527-41339-3.
\newblock \doi{10.1002/9783527413409}.

\bibitem[Gierecker et~al.(2023)Gierecker, Kalscheuer, Schoepflin, and
  Schüppstuhl]{gierecker_automated_2023}
Gierecker, J., Kalscheuer, F., Schoepflin, D. and Schüppstuhl, T.
\newblock Automated {CAD}-based sensor planning and system implementation for
  assembly supervision.
\newblock \emph{Procedia CIRP}, 118:\penalty0 930--934, 2023.
\newblock ISSN 22128271.
\newblock \doi{10.1016/j.procir.2023.06.160}.

\bibitem[Neumaier et~al.(2022)Neumaier, Kranemann, Kazmeier, and
  Rudolph]{neumaier_fully_2022}
Neumaier, M., Kranemann, S., Kazmeier, B. and Rudolph, S.
\newblock Fully automated piping in an {Airbus} {A320} landing gear bay using
  graph-based design languages.
\newblock \emph{IOP Conference Series: Materials Science and Engineering},
  1226\penalty0 (1):\penalty0 012026, February 2022.
\newblock ISSN 1757-899X.
\newblock \doi{10.1088/1757-899X/1226/1/012026}.

\bibitem[Gierecker and Schüppstuhl(2021)]{gierecker_assembly_2021}
Gierecker, J. and Schüppstuhl, T.
\newblock Assembly specific viewpoint generation as part of a simulation based
  sensor planning pipeline.
\newblock \emph{Procedia CIRP}, 104:\penalty0 981--986, January 2021.
\newblock ISSN 2212-8271.
\newblock \doi{10.1016/j.procir.2021.11.165}.

\bibitem[Kalscheuer et~al.(2023)Kalscheuer, Koch, and
  Schüppstuhl]{kalscheuer_reducing_2023}
Kalscheuer, F., Koch, J. and Schüppstuhl, T.
\newblock Reducing commissioning efforts for hybrid assembly systems using a
  data-driven approach.
\newblock \emph{Procedia CIRP}, 118:\penalty0 935--939, January 2023.
\newblock ISSN 2212-8271.
\newblock \doi{10.1016/j.procir.2023.06.161}.

\bibitem[Rožanec et~al.(2022)Rožanec, Zajec, Trajkova, Šircelj, Brecelj,
  Novalija, Dam, Fortuna, and Mladenić]{rozanec_towards_2022}
Rožanec, J.M., Zajec, P., Trajkova, E., Šircelj, B., Brecelj, B., Novalija,
  I., Dam, P., Fortuna, B. and Mladenić, D.
\newblock Towards a {Comprehensive} {Visual} {Quality} {Inspection} for
  {Industry} 4.0*.
\newblock \emph{IFAC-PapersOnLine}, 55\penalty0 (10):\penalty0 690--695,
  January 2022.
\newblock ISSN 2405-8963.
\newblock \doi{10.1016/j.ifacol.2022.09.486}.

\bibitem[noa(2018)]{noauthor_diehl_2018}
Diehl delivers milestone monument to {LHT}, November 2018.
\newblock URL
  \url{https://www.aircraftinteriorsinternational.com/news/galleys-monuments/diehl-delivers-milestone-monument-to-lht.html}.

\bibitem[Arnold(2006)]{arnold_intralogistik_2006}
Arnold, D., editor.
\newblock \emph{Intralogistik: {Potentiale}, {Perspektiven}, {Prognosen}}.
\newblock {VDI}-{Buch}. Springer, Berlin Heidelberg, 2006.
\newblock ISBN 978-3-540-29657-7.

\bibitem[Lotter and Wiendahl(2006)]{lotter_montage_2006}
Lotter, B. and Wiendahl, H.P., editors.
\newblock \emph{Montage in der industriellen {Produktion}}.
\newblock Springer Berlin Heidelberg, Berlin, Heidelberg, 2006.
\newblock ISBN 9783540214137 9783540366690.
\newblock \doi{10.1007/3-540-36669-5}.

\bibitem[Wehking(2020)]{wehking_technisches_2020}
Wehking, K.H.
\newblock \emph{Technisches {Handbuch} {Logistik} 1: {Fördertechnik},
  {Materialfluss}, {Intralogistik}}.
\newblock Springer Berlin Heidelberg, Berlin, Heidelberg, 2020.
\newblock ISBN 9783662608661 9783662608678.
\newblock \doi{10.1007/978-3-662-60867-8}.

\bibitem[Yang et~al.(2020)Yang, Han, Tang, Li, and Luo]{yang_detecting_2020}
Yang, X., Han, M., Tang, H., Li, Q. and Luo, X.
\newblock Detecting {Defects} {With} {Support} {Vector} {Machine} in
  {Logistics} {Packaging} {Boxes} for {Edge} {Computing}.
\newblock \emph{IEEE Access}, 8:\penalty0 64002--64010, 2020.
\newblock ISSN 2169-3536.
\newblock \doi{10.1109/ACCESS.2020.2984539}.

\bibitem[Malyshev et~al.(2021)Malyshev, Braginsky, Faddeeva, and
  Gogolin]{malyshev_artificial_2021}
Malyshev, M.I., Braginsky, S.A., Faddeeva, E.Y. and Gogolin, S.S.
\newblock Artificial {Neural} {Network} {Detection} of {Damaged} {Goods} by
  {Packaging} {State}.
\newblock In \emph{2021 {Intelligent} {Technologies} and {Electronic} {Devices}
  in {Vehicle} and {Road} {Transport} {Complex} ({TIRVED})}, pages 1--7,
  Moscow, Russian Federation, November 2021. IEEE.
\newblock ISBN 978-1-66540-075-6.
\newblock \doi{10.1109/TIRVED53476.2021.9639113}.

\bibitem[Noceti et~al.(2018)Noceti, Zini, and Odone]{noceti_multi-camera_2018}
Noceti, N., Zini, L. and Odone, F.
\newblock A multi-camera system for damage and tampering detection in a postal
  security framework.
\newblock \emph{EURASIP Journal on Image and Video Processing}, 2018\penalty0
  (1):\penalty0 11, December 2018.
\newblock ISSN 1687-5281.
\newblock \doi{10.1186/s13640-017-0242-x}.

\bibitem[Mayershofer et~al.(2021)Mayershofer, Ge, and
  Fottner]{liu_towards_2021}
Mayershofer, C., Ge, T. and Fottner, J.
\newblock Towards {Fully}-{Synthetic} {Training} for {Industrial}
  {Applications}.
\newblock In Liu, S., Bohács, G., Shi, X., Shang, X. and Huang, A., editors,
  \emph{{LISS} 2020}, pages 765--782. Springer Singapore, Singapore, 2021.
\newblock ISBN 978-981-334-358-0 978-981-334-359-7.
\newblock \doi{10.1007/978-981-33-4359-7_53}.

\bibitem[Özgür et~al.(2016)Özgür, Alias, and Noche]{ozgur_comparing_2016}
Özgür, C., Alias, C. and Noche, B.
\newblock Comparing sensor-based and camera-based approaches to recognizing the
  occupancy status of the load handling device of forklift trucks.
\newblock \emph{Volume 2016}, page Issue 05, 2016.
\newblock \doi{10.2195/LJ_PROC_OEZGUER_EN_201605_01}.

\bibitem[Dörr et~al.(2020)Dörr, Brandt, Pouls, and
  Naumann]{dorr_fully-automated_2020}
Dörr, L., Brandt, F., Pouls, M. and Naumann, A.
\newblock Fully-{Automated} {Packaging} {Structure} {Recognition} in
  {Logistics} {Environments}.
\newblock 2020.
\newblock \doi{10.48550/ARXIV.2008.04620}.

\bibitem[Mohamed et~al.(2020)Mohamed, Capitanelli, Mastrogiovanni, Rovetta, and
  Zaccaria]{mohamed_detection_2020}
Mohamed, I.S., Capitanelli, A., Mastrogiovanni, F., Rovetta, S. and Zaccaria,
  R.
\newblock Detection, localisation and tracking of pallets using machine
  learning techniques and {2D} range data.
\newblock \emph{Neural Computing and Applications}, 32\penalty0 (13):\penalty0
  8811--8828, July 2020.
\newblock ISSN 0941-0643, 1433-3058.
\newblock \doi{10.1007/s00521-019-04352-0}.

\bibitem[Khalid et~al.(2019)Khalid, Hager, Kraus, Huber, and
  Toussaint]{khalid_deep_2019}
Khalid, M.U., Hager, J.M., Kraus, W., Huber, M.F. and Toussaint, M.
\newblock Deep {Workpiece} {Region} {Segmentation} for {Bin} {Picking}.
\newblock In \emph{2019 {IEEE} 15th {International} {Conference} on
  {Automation} {Science} and {Engineering} ({CASE})}, pages 1138--1144,
  Vancouver, BC, Canada, August 2019. IEEE.
\newblock ISBN 978-1-72810-356-3.
\newblock \doi{10.1109/COASE.2019.8843050}.

\bibitem[Zhuang et~al.(2021)Zhuang, Wang, Zhao, and Ding]{zhuang_semantic_2021}
Zhuang, C., Wang, Z., Zhao, H. and Ding, H.
\newblock Semantic part segmentation method based {3D} object pose estimation
  with {RGB}-{D} images for bin-picking.
\newblock \emph{Robotics and Computer-Integrated Manufacturing}, 68:\penalty0
  102086, April 2021.
\newblock ISSN 07365845.
\newblock \doi{10.1016/j.rcim.2020.102086}.

\bibitem[Dong et~al.(2019)Dong, Liu, Zhou, Cheng, Zeng, Yu, and
  Liu]{dong_ppr-netpoint-wise_2019}
Dong, Z., Liu, S., Zhou, T., Cheng, H., Zeng, L., Yu, X. and Liu, H.
\newblock {PPR}-{Net}:{Point}-wise {Pose} {Regression} {Network} for {Instance}
  {Segmentation} and {6D} {Pose} {Estimation} in {Bin}-picking {Scenarios}.
\newblock In \emph{2019 {IEEE}/{RSJ} {International} {Conference} on
  {Intelligent} {Robots} and {Systems} ({IROS})}, pages 1773--1780, Macau,
  China, November 2019. IEEE.
\newblock ISBN 978-1-72814-004-9.
\newblock \doi{10.1109/IROS40897.2019.8967895}.

\bibitem[Thamer et~al.(2014)Thamer, Weimer, Kost, and
  Scholz-Reiter]{clausen_3d-computer_2014}
Thamer, H., Weimer, D., Kost, H. and Scholz-Reiter, B.
\newblock {3D}-{Computer} {Vision} for {Automation} of {Logistic} {Processes}.
\newblock In Clausen, U., Ten~Hompel, M. and Meier, J.F., editors,
  \emph{Efficiency and {Innovation} in {Logistics}}, pages 67--75. Springer
  International Publishing, Cham, 2014.
\newblock ISBN 978-3-319-01377-0 978-3-319-01378-7.
\newblock \doi{10.1007/978-3-319-01378-7_5}.

\bibitem[Bouarfa et~al.(2020)Bouarfa, Doğru, Arizar, Aydoğan, and
  Serafico]{bouarfa_towards_2020}
Bouarfa, S., Doğru, A., Arizar, R., Aydoğan, R. and Serafico, J.
\newblock Towards {Automated} {Aircraft} {Maintenance} {Inspection}. {A} use
  case of detecting aircraft dents using {Mask} {R}-{CNN}.
\newblock In \emph{{AIAA} {Scitech} 2020 {Forum}}, Orlando, FL, January 2020.
  American Institute of Aeronautics and Astronautics.
\newblock ISBN 978-1-62410-595-1.
\newblock \doi{10.2514/6.2020-0389}.

\bibitem[Malekzadeh et~al.(2017)Malekzadeh, Abdollahzadeh, Nejati, and
  Cheung]{malekzadeh_aircraft_2017}
Malekzadeh, T., Abdollahzadeh, M., Nejati, H. and Cheung, N.M.
\newblock Aircraft {Fuselage} {Defect} {Detection} using {Deep} {Neural}
  {Networks}.
\newblock 2017.
\newblock \doi{10.48550/ARXIV.1712.09213}.

\bibitem[Ramalingam et~al.(2019)Ramalingam, Manuel, Elara, Vengadesh,
  Lakshmanan, Ilyas, and James]{ramalingam_visual_2019}
Ramalingam, B., Manuel, V.H., Elara, M.R., Vengadesh, A., Lakshmanan, A.K.,
  Ilyas, M. and James, T.J.Y.
\newblock Visual {Inspection} of the {Aircraft} {Surface} {Using} a
  {Teleoperated} {Reconfigurable} {Climbing} {Robot} and {Enhanced} {Deep}
  {Learning} {Technique}.
\newblock \emph{International Journal of Aerospace Engineering}, 2019:\penalty0
  1--14, September 2019.
\newblock ISSN 1687-5966, 1687-5974.
\newblock \doi{10.1155/2019/5137139}.

\bibitem[Li et~al.(2019)Li, Han, Xu, Liu, Li, and Zhang]{li_yolov3-lite_2019}
Li, Y., Han, Z., Xu, H., Liu, L., Li, X. and Zhang, K.
\newblock {YOLOv3}-{Lite}: {A} {Lightweight} {Crack} {Detection} {Network} for
  {Aircraft} {Structure} {Based} on {Depthwise} {Separable} {Convolutions}.
\newblock \emph{Applied Sciences}, 9\penalty0 (18):\penalty0 3781, September
  2019.
\newblock ISSN 2076-3417.
\newblock \doi{10.3390/app9183781}.

\bibitem[Fotouhi et~al.(2021)Fotouhi, Pashmforoush, Bodaghi, and
  Fotouhi]{fotouhi_autonomous_2021}
Fotouhi, S., Pashmforoush, F., Bodaghi, M. and Fotouhi, M.
\newblock Autonomous damage recognition in visual inspection of laminated
  composite structures using deep learning.
\newblock \emph{Composite Structures}, 268:\penalty0 113960, July 2021.
\newblock ISSN 02638223.
\newblock \doi{10.1016/j.compstruct.2021.113960}.

\bibitem[Upadhyay et~al.(2023)Upadhyay, Li, King, and
  Addepalli]{upadhyay_deep-learning-based_2023}
Upadhyay, A., Li, J., King, S. and Addepalli, S.
\newblock A {Deep}-{Learning}-{Based} {Approach} for {Aircraft} {Engine}
  {Defect} {Detection}.
\newblock \emph{Machines}, 11\penalty0 (2):\penalty0 192, February 2023.
\newblock ISSN 2075-1702.
\newblock \doi{10.3390/machines11020192}.

\bibitem[Shen et~al.(2019)Shen, Wan, Ye, Guan, and Liu]{shen_deep_2019}
Shen, Z., Wan, X., Ye, F., Guan, X. and Liu, S.
\newblock Deep {Learning} based {Framework} for {Automatic} {Damage}
  {Detection} in {Aircraft} {Engine} {Borescope} {Inspection}.
\newblock In \emph{2019 {International} {Conference} on {Computing},
  {Networking} and {Communications} ({ICNC})}, pages 1005--1010, Honolulu, HI,
  USA, February 2019. IEEE.
\newblock ISBN 978-1-5386-9223-3.
\newblock \doi{10.1109/ICCNC.2019.8685593}.

\bibitem[Li et~al.(2022{\natexlab{b}})Li, Wang, Sun, Hu, Zhu, and
  Zhang]{li_deep_2022}
Li, X., Wang, W., Sun, L., Hu, B., Zhu, L. and Zhang, J.
\newblock Deep learning-based defects detection of certain aero-engine blades
  and vanes with {DDSC}-{YOLOv5s}.
\newblock \emph{Scientific Reports}, 12\penalty0 (1):\penalty0 13067, July
  2022{\natexlab{b}}.
\newblock ISSN 2045-2322.
\newblock \doi{10.1038/s41598-022-17340-7}.

\bibitem[Nguyen(2023)]{nguyen_anylabeling_2023}
Nguyen, V.A.
\newblock {AnyLabeling}: {Effortless} data labeling with {AI} support, July
  2023.
\newblock URL \url{https://github.com/vietanhdev/anylabeling}.

\bibitem[noa()]{noauthor_roboflow_nodate}
Roboflow: {Give} your software the power to see objects in images and video.
\newblock URL \url{https://roboflow.com/}.

\bibitem[Kähler et~al.(2023{\natexlab{b}})Kähler, Masekowsky, and
  Schüppstuhl]{kahlerAutomatedGrindingSurface2023}
Kähler, F., Masekowsky, S. and Schüppstuhl, T.
\newblock Automated {Grinding} for {Surface} {Defect} {Removal} on {Aircraft}
  {Components}, May 2023{\natexlab{b}}.
\newblock \doi{10.13140/RG.2.2.14302.61766}.

\bibitem[Mönchinger et~al.(2021)Mönchinger, Joost, and
  Stark]{monchinger_automated_2021}
Mönchinger, S., Joost, R. and Stark, R.
\newblock Automated {3D} scan based {CAD}-repositioning for design and
  verification in one-off construction.
\newblock \emph{Procedia CIRP}, 100:\penalty0 530--535, January 2021.
\newblock \doi{10.1016/j.procir.2021.05.115}.

\bibitem[Laukotka et~al.(2019)Laukotka, Oltmann, and
  Krause]{laukotka_digitized_2019}
Laukotka, F., Oltmann, J. and Krause, D.
\newblock \emph{A digitized approach to reduce assembly conflicts during
  aircraft cabin conversions}.
\newblock September 2019.
\newblock \doi{10.35199/dfx2019.22}.

\bibitem[Deneke et~al.(2021)Deneke, Moenck, and
  Schüppstuhl]{deneke_augmented_2021}
Deneke, C., Moenck, K. and Schüppstuhl, T.
\newblock \emph{Augmented {Reality} {Based} {Data} {Improvement} for the
  {Planning} of {Aircraft} {Cabin} {Conversions}}.
\newblock January 2021.
\newblock \doi{10.1145/3463858.3463896}.

\bibitem[Hu et~al.(2023{\natexlab{d}})Hu, Zhao, Xiao, and Li]{hu_ar-based_2023}
Hu, J., Zhao, G., Xiao, W. and Li, R.
\newblock {AR}-based deep learning for real-time inspection of cable brackets
  in aircraft.
\newblock \emph{Robotics and Computer-Integrated Manufacturing}, 83,
  2023{\natexlab{d}}.
\newblock ISSN 0736-5845.
\newblock \doi{10.1016/j.rcim.2023.102574}.

\bibitem[Zheng et~al.(2020)Zheng, Liu, An, Li, and Zhang]{zheng_smart_2020}
Zheng, L., Liu, X., An, Z., Li, S. and Zhang, R.
\newblock A smart assistance system for cable assembly by combining wearable
  augmented reality with portable visual inspection.
\newblock \emph{Virtual Reality \& Intelligent Hardware}, 2:\penalty0 12--27,
  February 2020.
\newblock \doi{10.1016/j.vrih.2019.12.002}.

\bibitem[Cen et~al.(2023{\natexlab{a}})Cen, Wu, Wang, Li, Yang, Pei, Kong, Liu,
  and Chen]{cenSADSegmentAny2023}
Cen, J., Wu, Y., Wang, K., Li, X., Yang, J., Pei, Y., Kong, L., Liu, Z. and
  Chen, Q.
\newblock {SAD}: {Segment} {Any} {RGBD}, May 2023{\natexlab{a}}.
\newblock \doi{10.48550/arXiv.2305.14207}.

\bibitem[Chen et~al.(2023{\natexlab{d}})Chen, Tang, Wan, Wang, and
  Zeng]{chenInteractiveSegmentAnything2023}
Chen, X., Tang, J., Wan, D., Wang, J. and Zeng, G.
\newblock Interactive {Segment} {Anything} {NeRF} with {Feature} {Imitation},
  May 2023{\natexlab{d}}.
\newblock \doi{10.48550/arXiv.2305.16233}.

\bibitem[Cen et~al.(2023{\natexlab{b}})Cen, Zhou, Fang, Yang, Shen, Xie, Jiang,
  Zhang, and Tian]{cenSegmentAnything3D2023}
Cen, J., Zhou, Z., Fang, J., Yang, C., Shen, W., Xie, L., Jiang, D., Zhang, X.
  and Tian, Q.
\newblock Segment {Anything} in {3D} with {NeRFs}, June 2023{\natexlab{b}}.
\newblock \doi{10.48550/arXiv.2304.12308}.

\bibitem[Yang et~al.(2023{\natexlab{d}})Yang, Wu, He, Zhao, and
  Liu]{yang_sam3d_2023}
Yang, Y., Wu, X., He, T., Zhao, H. and Liu, X.
\newblock {SAM3D}: {Segment} {Anything} in {3D} {Scenes}, June
  2023{\natexlab{d}}.
\newblock \doi{10.48550/arXiv.2306.03908}.

\bibitem[Zhang et~al.(2023{\natexlab{h}})Zhang, Liang, Yang, Zou, Ye, Liu, and
  Bai]{zhang_sam3d_2023}
Zhang, D., Liang, D., Yang, H., Zou, Z., Ye, X., Liu, Z. and Bai, X.
\newblock {SAM3D}: {Zero}-{Shot} {3D} {Object} {Detection} via {Segment}
  {Anything} {Model}, June 2023{\natexlab{h}}.
\newblock \doi{10.48550/arXiv.2306.02245}.

\end{thebibliography}
