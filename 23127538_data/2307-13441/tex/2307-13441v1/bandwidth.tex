\vspace{-0.1in}
\section{Following the shifting fulcrum}
\label{sec:bandwidth}
\vspace{-0.05in}

Social media users share photos and screenshots while posting online. Redditors on \starlinksubreddit{} often share screenshots (or links to them) of network performance test reports to spark discussions. We gather all such test report screenshots across test providers like Ookla~\cite{ookla_speedtest}, Fast (powered by Netflix)~\cite{fast_speedtest}, Starlink itself, and others, and extract uplink speed, downlink speed, latency information, etc. using Azure's Optical Character Recognition (OCR)~\cite{azure_ocr}. After applying a set of heuristics, as discussed in \S\ref{sec:methods}, to rule out false positives, we could identify $\sim${}$1$,$750$ reports of Starlink speed-tests being shared publicly between Jan, $2021$ and Dec, $2022$. In this section, we focus on the evolution of `observed' downlink speed during this period and users' perceptions of the same.

%\vspace{-0.2in}
% Figure environment removed


\parab{Demand vs. supply}
Fig.~\ref{fig:downlink_evolve} shows the change in observed downlink speeds with time. For each month, we plot the median speeds across all shared screenshots of Starlink speed tests. We annotate the observed speeds with the number of Starlink launches~\cite{starlink_launches} and also the reported number of Starlink users (whenever public information is available)~\cite{beta_10K,beta_69K,beta_90K,beta_140K,beta_250K,beta_400K,beta_500K} during a month. We also plot the monthly median downlink speeds with $95\%$ and $90\%$ of the monthly speed data picked uniformly at random -- the plots closely follow each other showing that the observed medians are considerably stable.


We observe that, between Jan and Sep'$21$, the median downlink speeds increased in general. SpaceX launched ($\sim${}$60$ satellites per launch) $14$ times during this period and the number of users increased from $10K$ (in Feb) to $90K$ (in Aug).  Further, between Sep'$21$ and Dec'$22$, there has been an almost steady decrease in observed speeds although SpaceX launched batches of Starlink satellites $32$ times. Note, however, that the number of reported Starlink users increased from $90K$ to $1M$ (and beyond) during the same period, resulting in more than $1000\%$ rise in downlink demand, assuming a linear increase in demand with users. Note that between Nov'$21$ and Jan'$22$, there were $4$ Starlink launches while the number of users increased by only $5K$ (announcement by Starlink on delay in terminal delivery in Nov'$21$, as shown in Fig.~\ref{fig:sentiment_temporal}). This resulted in slight improvements in observed bandwidth in Jan'$22$.
In March, April, and June'$21$, observed downlink speeds improved as new satellites were deployed steadily. But it is not always a straightforward reflection of deployment as more Starlink users are also added continually, as is evident in some other cases. On the contrary, if there aren't any new launches, and new users are added, the observed speeds decrease. Between Jun and Aug'$21$, $21K$ new users started using Starlink with no new launches happening. This is reflected in the sharp decrease in median speeds during the period. Beyond Sep'$21$, reported bandwidths have decreased almost steadily given the large increase in demand as Starlink service expanded to various countries across the globe.

The broad observation here is that more Starlink launches do not always result in higher observed bandwidth, although the aggregate bandwidth of the Starlink system should be increasing with the addition of satellites. It is a complex calculus involving both supply and demand, and it is always a race to add more satellites and cater to the ever-increasing aggregate bandwidth demands.


We did not quantify any bias inherent in such social media-based estimates. Note that unbiased absolute values of download speeds are not critical for our analyses; we rather needed relative changes in download speeds and corresponding sentiments (discussed next) from one month to the next. As part of future work, any bias arising due to demographics in a social community will hopefully reduce as we span across more social platforms. We discuss this in further depth under \S\ref{sec:discussions}.


\parab{The wheel of time}
With time, the perception of users on network performance changes. In Fig.~\ref{fig:downlink_evolve} we also plot (green, dashed) the strong positive sentiment of users on downlink speeds. To do this, we analyze the sentiment of posts (text content) that share Starlink speed-test reports using Azure's Cognitive Services. We identify posts with strong positive ($\geq${}$0.7$) or negative ($\geq${}$0.7$) scores, and define the normalized strong positive sentiment score ($Pos$) as the number of strong positive posts over sum of the number of strong positive and negative posts in a month thus filtering out edge cases when identifying the sentiment is hard.


We observe that $Pos$ broadly follows the observed downlink speed trends, but there are interesting exceptions. For instance, while downlink speed is higher in Dec'$21$ than Apr'$21$, $Pos$ is drastically lower for Dec'$21$. We believe this is because user sentiment is, in general, a reflection of both short-term and long-term conditioning -- users get acclimatized to their current network conditions and give negative sentiment for any degradation in network conditions even if such conditions are better than the past. The exact inverse of this trend is also visible -- the downlink speeds decrease between Mar'$22$ and Dec'$22$ while the $Pos$ improves over time. This demonstrates users getting conditioned to lower speeds, but not necessarily attachment and loyalty to the ISP. While we observed users frequently discussing application performance over LEO networks on social platforms, we keep such an in-depth and finer-granularity study of observed bandwidth versus user sentiment for future work.
