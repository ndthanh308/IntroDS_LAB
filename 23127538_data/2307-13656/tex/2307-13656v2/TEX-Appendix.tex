    \section{Revenue Maximization Under MNL}
    \label{apx1}

In this appendix, we present for completeness two standard known results about assortment optimization under MNL. Lemma \ref{lem:nestedrevenue}, shows that the optimal assortment for \ref{Unconstrained} is revenue-ordered. This is a standard result in assortment optimization under MNL \cite[Proposition~6][25]{talluri2004revenue}.
Lemma \ref{Revenue variations} provides a necessary and sufficient conditions under which adding a given product to a given assortment increases the overall revenue.
Consider the classic unconstrained revenue maximization problem under MNL, defined as follows
\begin{equation}
\label{Unconstrained}
\begin{aligned}
\max_{S \subseteq \mathcal{N}} \quad  R(S).
\end{aligned}
\tag{\sf{AP}}
\end{equation}
%The next lemma shows that the optimal assortment for \ref{Unconstrained} is revenue-ordered. This is a standard result in assortment optimization under MNL \cite[Proposition~6][25]{talluri2004revenue}. 
\begin{lemma}\label{lem:nestedrevenue}
    \label{Unconstrained solution}
    Let $R^* = \max_{S \subseteq \mathcal{N}} R(S)$ be the optimal value of \ref{Unconstrained problem}. There exists a revenue ordered optimal solution to \ref{Unconstrained problem}, given by $S^* = \{i \in \mathcal{N}, p_i \geq R^* \}$.
\end{lemma}

Before proving Lemma \ref{lem:nestedrevenue}, we state and prove the following more general lemma, which shows that adding a product $i$ to any given assortment $S$ increases the objective if and only if the price of the added product $i$ is greater than or equal to the original revenue $R(S)$.


\begin{lemma}\label{Revenue variations}
    For any assortment $S\subseteq {\cal N}$ and any product $k \in {\cal N} \setminus S$, the three following propositions are equivalent:
$$(i) \; R(S \cup \{k\}) \geq R(S),  \qquad (ii)  \; p_k \geq R(S),  \qquad (iii) \; p_k \geq R(S\cup \{k\}). $$
\end{lemma}
    


%\begin{lemma}\label{Revenue variations}
%    For any assortment $S\subseteq {\cal N}$ and any product $k \in {\cal N} \setminus S$, the three following propositions are equivalent
 %   \begin{itemize}
  %      \item[(i)] $R(S \cup \{k\}) \geq R(S)$.
   %     \item[(ii)] $p_k \geq R(S)$.
    %    \item[(iii)] $p_k \geq R(S\cup \{k\})$.
  %  \end{itemize}
%\end{lemma}
    
\begin{proof}[Proof of Lemma \ref{Revenue variations}]
    We simply show that $R(S\cup \{k\})$ is a convex combination of $R(S)$ and $p_k$. In fact, simple algebra gives  \begin{align*}
        R\left(S\cup \{k\}\right) &= \sum_{i\in S} p_i\cdot\phi\left(i,S\cup \{k\}\right) + p_k\cdot\phi\left(k,S\cup \{k\}\right)
   % & = \sum_{i\in S} p_i\cdot\phi\left(i,S\right) \cdot \frac{1+V(S)}{1+V(S\cup \{k\})}+ p_k\cdot\phi\left(k,S\cup \{k\}\right)\\
     = R(S) \cdot \alpha + p_k \cdot (1-\alpha),
    \end{align*}
    where $\alpha = (1+V(S)) / (1+V(S\cup\{k\}))$. It is easy to see that $\alpha \in (0,1)$,  which proves that $R(S\cup \{k\})$ is a convex combination of $R(S)$ and $p_k$. Consequently, $R(S\cup \{k\})$ belongs to the closed interval whose extremities are $R(S)$ and $p_k$. In particular, we have $R(S\cup \{k\}) \geq R(S)$ if and only if $p_k \geq R(S)$, and if and only if $p_k \geq R(S\cup \{k\})$.
\end{proof}

%We can now deduce the proof of Lemma \ref{lem:nestedrevenue}.
\begin{proof}[Proof of Lemma \ref{lem:nestedrevenue}]
Let $\Tilde{S}$ be the optimal assortment of \ref{Unconstrained} with maximal cardinality. In the case of ties, let $\Tilde{S}$ be any arbitrary such assortment. In the following, we show that $S^* = \Tilde S$ (which in particular implies that there can be no ties).
 Let $i\in S^*$, and assume by contradiction that $i\notin \Tilde S$. One one hand, we know by optimality of $\Tilde S$ that $R(\Tilde S) = R^*$. On the other hand, we know that $p_i\geq R^*$ by definition of $S^*$. Therefore, $p_i\geq R(\Tilde S)$ and we can apply lemma \ref{Revenue variations}, which implies that $R(\Tilde{S}\cup \{i\})\geq R(\Tilde S)$, and hence that $\Tilde{S}\cup \{i\}$ is also an optimal assortment. Since $\Tilde{S} \subsetneq \Tilde{S}\cup \{i\}$. This contradicts the definition of $\Tilde{S}$ as the optimal assortment with maximal cardinality, and therefore shows that $i\in \Tilde S$.
 Now, let $i \in \Tilde S$. Assume by contradiction that $i\notin S^*$, i.e., $p_i < R^* = R(\Tilde S)$. In particular, this implies using Lemma \ref{Revenue variations} that $R(\Tilde S\setminus \{i\}) > R(\Tilde S)$, which contradicts the optimality of $\Tilde S$, and therefore shows that $i \in S^*$. This proves the second inclusion, and thereby completes the proof of the lemma.
\end{proof}


\section{Additional Proofs from Section \ref{sec:APVC}}\label{apx:APVC}
\subsection{Proof of Theorem \ref{NP-hardness}}
\label{apxhard}
In order to show the result, we reduce the $3$-partition problem to \ref{APVC}. In the $3$-\texttt{PARTITION} problem, the input consists on an integer $T$, and a set of $3T$ integers ${\cal A} = \{a_1,\ldots, a_{3T}\}$ such that $\sum_{i=1}^{3T}a_i=BT$ for some $B\geq 0$, and seeks to determine whether $\cal A$ can be partitioned into $T$ triplets $A_1,\ldots, A_T$, and such that the sum of elements of each triplet is $B$. This problem is known to be strongly NP-hard (see \cite{garey1975complexity} for example, $3$-\texttt{PARTITION} is referred to there as $P[3,1]$).

Given an arbitrary instance of $3$-\texttt{PARTITION}, we construct the following instance of \ref{APVC}. We consider $3T$ products, simply denoted by the universe $\Nc = \{1,\ldots,3T\}$, and such that for all $i\in \Nc$, $v_i = a_i$, $p_i = 1$ and $\ell_i = 1$. In particular, note that $V(\Nc) = BT$. Finally, let $k=3$ in our instance, the upper bound on the cardinality of any offered assortment.
A first important observation is that any feasible solution for this instance of \ref{APVC} shows each product to exactly one customer. In other words, if $S_1,\ldots ,S_T$ is a feasible solution for this instance of \ref{APVC}, then for any product $i\in \Nc$, there exists a unique $t\in [T]$ such that $i\in S_t$. Indeed, one one hand, the visibility constraints impose that each product be shown at least once, and on the other hand, since each assortment can contain at most $k=3$ products and there are $3T$ products in our universe, this implies that each product must be shown at most once, which shows the observation. A natural consequence of this observation is that for any feasible solution $S_1,\ldots, S_T$ of our instance of \ref{APVC}, we have $\sum_{t=1}^TV(S_t) = V(\Nc) = BT.$
We denote by $S^* = (S^*_1,\ldots,S^*_T)$ an optimal sequence of assortments for this instance of \ref{APVC}. In order to show the strong NP-hardness, we introduce the following claim.
\begin{claim}\label{cl:NPhard}
    The answer to the $3$-\texttt{PARTITION} is {\em yes} if and only if $\sum_{t=1}^TR(S_t^*) = T\cdot B/(1+B).$
\end{claim}
Before proving the claim, note that it directly implies the strong NP-hardness of \ref{APVC}, even in the special case of equal prices and integer preference-weights, as it shows that $3$-\texttt{PARTITION} reduces to this special case of \ref{APVC} (see {\cite[Observation 5][504]{garey1978strong}}). Let us now prove the claim.
\begin{proof}[Proof of Claim \ref{cl:NPhard}]\phantom \\

\noindent \underline{Direct implication}. Suppose that a valid $3$-\texttt{PARTITION} exists, which we denote by $A_1,\ldots, A_T$, and let $S_t = \{i \,\colon\, a_i\in A_t\}$ for $t\in [T]$. On one hand, we have$$
    \sum_{t=1}^TR(S_t^*)\geq \sum_{t=1}^TR(S_t) = T\cdot\frac{B}{1+B},
$$
and on the other hand, we have using Jensen's inequality and the concavity of the map $x\mapsto x/(1+x)$,$$
    \sum_{t=1}^TR(S_t^*) = T \sum_{t=1}^T\frac{1}{T}\cdot\frac{V(S_t^*)}{1+V(S_t^*)} \leq T\cdot \frac{\sum_{t=1}^T\frac{V(S_t^*)}{T}}{1+\sum_{t=1}^T\frac{V(S_t^*)}{T}} = T\cdot\frac{B}{1+B}.
$$
This implies that $\sum_{t=1}^TR(S_t^*) = T\cdot B/(1+B)$ and proves the direct implication.

\noindent \underline{Indirect implication}. Assume that $$\sum_{t=1}^TR(S_t^*) = T\cdot \frac{B}{1+B}.$$
On one hand, we have according to Cauchy-Schwarz inequality,$$
    \sum_{t=1}^T(1+V(S_t^*)) \cdot \sum_{t=1}^T\frac{1}{1+V(S_t^*)} \geq T^2,
$$
with equality if and only if there exists some $\lambda$ such that for all $t\in [T]$, $1+V(S_t^*) = \lambda / (1+V(S^*_t))$, which in turn is equivalent to $V(S^*_1) = V(S^*_2)=\cdots = V(S^*_T) = \sqrt{\lambda}-1$.

On the other hand, it is easy to see that $$
    \sum_{t=1}^TR(S_t^*) = T - \sum_{t=1}^T\frac{1}{1+V(S^*_t)}.
$$
Therefore, \begin{align*}
    \sum_{t=1}^T(1+V(S_t^*)) \cdot \sum_{t=1}^T\frac{1}{1+V(S_t^*)} & = \left(T+V\left(\Nc\right)\right)\cdot \left(T - \sum_{t=1}^TR(S_t^*)\right)\\
    & =  \left(T+TB\right)\cdot \left(T - T\cdot\frac{B}{1+B}\right)\\
    & = T^2,
\end{align*}
This proves the equality case in Cauchy-Schwarz inequality, and consequently that $V(S^*_1) = V(S^*_2) = \cdots = V(S^*_T)$. Finally, taking $A_t = \{a_i\,:\, i\in S_t^*\}$ for $t\in [T]$, it is easy to see that $A_1,\ldots, A_T$ is a valid $3$-\texttt{PARTITION}, which concludes the proof of the claim.
\end{proof}

In the remainder of this proof, we show that the problem does not admit an FPTAS, relying on the following claim.
\begin{claim}\label{cl:noFPTAS}
    If the answer to the $3$-\texttt{PARTITION} is {\em no}, then $$
        \sum_{t=1}^TR(S_t^*) \leq (1-\delta)\cdot T\cdot \frac{B}{1+B},
    $$
    where $\delta = \frac{2}{TB^2(B+2)}$.
\end{claim}
Finally, the non-existence of an FPTAS for this problem follows naturally. Indeed, assume for the sake of contradiction that an FPTAS exists for \ref{APV}. Then by taking $\eps < \delta$, say $\eps = \delta/2$ for example, the FPTAS would return a solution $(S_1^*,\ldots, S_T^*)$ with an objective greater than or equal to $(1-\epsilon)\cdot TB/(1+B)$ if an only if a valid partition exists. This yields an algorithm that solves the $3$-\texttt{PARTITION} problem in pseudo-polynomial time, thereby contradicting its strong NP-hardness.
\\{\em Conclusion. }\ref{APV} is strongly NP-hard, and admits no FPTAS.






\begin{proof}[Proof of Claim \ref{cl:noFPTAS}]
Suppose the answer to the $3$-\texttt{PARTITION} problem is {\em no}.
Consider the following integer program:
    \begin{equation}\label{eq:clprog}
        \begin{aligned}
         \max_{\mathbf{b} \in \N^T}  & \; \;      \sum_{t=1}^T  \frac{b_t}{1+b_t}   \\  
          s.t. \;\;   & \;\;  \sum_{t=1}^Tb_t = BT\\
          &\,\, \mathbf{b} \neq (B,B,\ldots,B).
        \end{aligned}
    \end{equation}
Intuitively, this program's objective is to partition a budget of $BT$ into $T$ bins, under the constraint that not all the bins receive the same fraction of budget, and such that each bin $t\in [T]$ yields a return of $b_t/(1+b_t)$. Let $\mathbf{b}^*$ be the optimal solution of this problem. The idea of the proof is to show that:
\begin{equation}\label{eq:doubleineq}
    \sum_{t=1}^TR(S_t^*) \leq \sum_{t=1}^T\frac{b^*_t}{1+b^*_t} = (1-\delta)\cdot \frac{TB}{1+B}.
\end{equation}
\paragraph{The inequality. }
Let $\mathbf{b} = (V(S_1^*),\ldots, V(S_T^*))$. We have $\sum_{t=1}^TV(S_t^*) = BT$, and since a valid partition does not exist, then $\mathbf{b}\neq (B,B,\ldots,B)$  (see Claim \ref{cl:NPhard}). Therefore $\mathbf{b}$ is feasible for \eqref{eq:clprog}, and we have:
$$
    \sum_{t=1}^TR(S_t^*) = \sum_{t=1}^T\frac{b_t}{1+b_t} \leq \sum_{t=1}^T\frac{b^*_t}{1+b^*_t},
$$
by the optimality of $\mathbf{b}^*$.
\paragraph{The equality. }We show that $(B+1, B-1, B,\ldots,B)$ is an optimal solution for \eqref{eq:clprog}. Towards this purpose, we start by showing that the number of indices $u$ for which $b^*_u \neq B$ is at least two, before showing by contradiction that it is exactly $2$, then we show that the entries of these two indices in $\mathbf{b}^*$ are exactly $B+1$ and $B-1$. Since the indices are all interchangeable, this shows that $(B+1, B-1, B,\ldots,B)$ is an optimal solution for \eqref{eq:clprog}.

Let ${\cal U}\subseteq [T]$ be the set of indices $u$ such that $b^*_u\neq B$, i.e., ${\cal U} = \{u\in [T]\,:\, b_u^* \neq B\}$. First, ${\cal U} \neq \emptyset$, by the second constraint of \eqref{eq:clprog}. Also, if we suppose by contradiction that $|{\cal U}| = 1$, say ${\cal U} = \{1\}$ without loss of generality, then $\sum_{t=1}^T{b^*_t} = b_1^* + (T-1)B \neq BT$, which contradicts the first constraint of \eqref{eq:clprog}. Therefore, $|{\cal U}| \geq 2$.

Suppose by contradiction that $|{\cal U}| > 2$. Since the elements of $\cal U$ cannot all be smaller, or all be greater than $B$ (otherwise the second constraint in \eqref{eq:clprog} does not hold), there exists $u_1, u_2\in [T]$ such that $b_{u_1}^* \geq B+1$ and $b_{u_2}^* \leq B-1$. Also, since $|{\cal U}| >2$, there exists some $u_3\neq u_1,u_2$, such that $b_{u_3}^* \neq B$. For simplicity, we assume without loss of generality that $u_1 = 1$, $u_2 = 2$ and $u_3 = 3$. Let $ {\mathbf{\Tilde b}} = (b_1^*-1,b_2^*+1, b_3^*,\ldots, b_T^*)$, in other words, we transfer a unit of the budget from $b_1^*$ to $b_2^*$. First, $\sum_{t=1}^T{\Tilde b}_t = \sum_{t=1}^Tb_t^* =BT$. Moreover, since $3\in {\cal U}$, $\Tilde b_3 = b_3^* \neq B$, which implies that $\mathbf{\Tilde b}$ is feasible for \eqref{eq:clprog}. Finally, we have
\begin{align*}
    \sum_{t=1}^T \frac{\Tilde b_t}{1+\Tilde b_t} &=  \frac{b^*_1-1}{1+b^*_1-1} +\frac{b^*_2+1}{1+b^*_2+1} + \sum_{t=3}^T\frac{b^*_t}{1+b^*_t}\\
    & > \frac{b^*_1}{1+b^*_1} +\frac{b^*_2}{1+b^*_2} + \sum_{t=3}^T\frac{b^*_t}{1+b^*_t}\\
    & = \sum_{t=1}^T\frac{b^*_t}{1+b_t^*},
\end{align*}
where the inequality in the second line is due to the fact that the map
$$
    f:x\mapsto \frac{b_1^*-x}{1+b_1^*-x}+\frac{b_2^*+x}{1+b_2^*+x}
$$
is monotonically (strictly) increasing on $[0,1]$ (which we show at the end of the proof for completeness). This contradicts the optimality of $\mathbf{b}^*$, and thereby shows that $|{\cal U}| =2$.

Assume without loss of generality that ${\cal U} = \{1,2\}$, and that $b^*_1 = B+\alpha$, and $b^*_2 = B-\alpha$ for some $\alpha \in \N\setminus \{0\}$. Assume by contradiction that $\alpha \geq 2$, then using the same argument as the contradiction above, the map 
$$
    x\mapsto \frac{b_1^*-x}{1+b_1^*-x}+\frac{b_2^*+x}{1+b_2^*+x}
$$
is increasing, and we can therefore transfer a unit of the budget from $1$ to $2$, and strictly increase the objective of the obtained solution. Moreover, since $\alpha\geq 2$, $b_1^*-1 \neq B$, and the second constraint in \eqref{eq:clprog} is valid, which proves the feasibility of the obtained solution, and contradicts the optimality of $\mathbf{b}^*$. Therefore, $\alpha=1$ and $(B+1, B-1, B,\ldots,B)$ is an optimal solution for \eqref{eq:clprog}.

Going back to the seeked equality \eqref{eq:doubleineq}, we have\begin{align*}
    \sum_{t=1}^T\frac{b^*_t}{1+b_t^*} &= \frac{B-1}{1+B-1} + \frac{B+1}{1+B+1} + (T-2)\cdot \frac{B}{1+B} \\
    % & = \frac{TB}{1+B} - \left(\frac{2B}{1+B} - \frac{B-1}{B} - \frac{B+1}{B+2}\right)\\
    % & = \frac{TB}{1+B}\cdot \left(1 - \frac{2}{T} + \frac{(B-1)(B+1)}{TB^2} - \frac{(B+1)^2}{TB(B+2)}\right)\\
    % & = \frac{TB}{1+B} \cdot \left(1 - \frac{2}{TB^2(B+2)}\right)\\
    & = \frac{TB}{1+B} \cdot \left(1 - \delta\right).
\end{align*}
The second equality follows from basic algebra operations. This proves Equation \eqref{eq:doubleineq}, which in turn proves the claim.
\paragraph{Leftover: Proof of the strict monotonicity of $f$. }
For all $x\in [0,1]$, recall that $$
    f(x) = \frac{b_1^*-x}{1+b_1^*-x}+\frac{b_2^*+x}{1+b_2^*+x}.
$$
We differentiate $f$, and we have for all $x\in [0,1]$
$$
    f'(x) = \frac{1}{\left(1+b_2^*+x\right)^2}-\frac{1}{\left(1+b_1^*+x\right)^2}
$$
Therefore, it is easy to see that $f'(x) > 0$ for all $x<(b^*_1-b^*_2)/2$. Since $b_1^*\geq B+1$ and $b_2^*\leq B-1$, then $(b^*_1-b^*_2)/2 \leq 1$, which proves that $f$ is monotonically strictly increasing on $[0,1]$.
\end{proof}



\subsection{Proof of Lemma \ref{lem:LPopt}}\label{apx:LPopt}
    In this proof, we show separate inequalities for light, medium, and heavy customers. Combining these inequalities then gives the desired result.
    
    \noindent {\bf Heavy customers:} If $t\in [T]$ is heavy then by the fifth constraint of \ref{eq:ILP}, we have \begin{equation*}
            \sum_{i\in \Nc} v_ix^*_{it} \geq \frac{1}{\eps}.
        \end{equation*}
        Therefore, \begin{equation}\label{eq:heavy}
            \frac{\sum_{i\in \Nc} v_ix^*_{it}}{1+\sum_{i\in \Nc} v_ix^*_{it}} \geq \frac{1}{1+\eps} \geq (1-\eps) \cdot \frac{v(S_t^*)}{1+v(S_t^*)}.
        \end{equation}
    
    \noindent {\bf Medium customers:} If $t\in G_\ell$ for some $\ell \in \{1,\ldots,L\}$, then we have
        \begin{equation*}
            \sum_{i\in \Nc} v_i x_{it} \geq \eps\cdot (1+\eps)^{\ell-1} \geq \frac{1}{1+\eps} v(S_t^*),
        \end{equation*}
        where the first inequality follows from the fifth constraint of \ref{eq:ILP}, and the second follows from the fact that $v(S_t^*) \leq \eps \cdot (1+\eps)^{\ell}$ by definition of customers of type $\ell$.
        Therefore,\begin{equation}\label{eq:medium}
            \frac{\sum_{i\in \Nc} v_ix^*_{it}}{1+\sum_{i\in \Nc} v_ix^*_{it}} \geq \frac{1}{1+\eps} \cdot \frac{v(S_t^*)}{1+v(S_t^*)} =  (1-\eps)\cdot \frac{v(S_t^*)}{1+v(S_t^*)}.
        \end{equation}
    
    \noindent {\bf Light customers:} Let $\mathbf{X^*}$ be the solution defined as follows, for every $t\in [T]$, and every $i\in \Nc$, $X^*_{it} = \mathbbm 1\{i \in S_t^*\}$. It is easy to see that by construction of \ref{eq:ILP}, the solution $\mathbf{X^*}$ is feasible for \ref{eq:ILP}, and therefore, it is also feasible for its linear relaxation. Therefore, since $\mathbf{x^*}$ is optimal for \ref{eq:ILP}, we have\begin{equation*}
            \sum_{t\in G_{light}} \sum_{i\in \Nc} v_ix^*_{it} \geq \sum_{t\in G_{light}} \sum_{i\in \Nc} v_iX^*_{it} =  \sum_{t\in G_{light}} v(S_t^*).
        \end{equation*}
        We also have for all $t\in G_{light}$, $\sum_{i\in \Nc} v_i x^*_{it}\leq \eps$ by  the sixth constraint of \ref{eq:ILP}. Therefore, \begin{align}
            \sum_{t\in G_{light}}\frac{\sum_{i\in \Nc} v_ix^*_{it}}{1+\sum_{i\in \Nc} v_ix^*_{it}}&\geq \frac{1}{1+\eps}\cdot \sum_{t\in G_{light}}\sum_{i\in \Nc} v_ix^*_{it}\notag\\
            &\geq \sum_{t\in G_{light}} v(S_t^*)\notag\\
            & \geq \sum_{t\in G_{light}}\frac{v(S_t^*)}{1+v(S_t^*)}.\label{eq:light}
        \end{align}
    We conclude the proof by combining Equations \eqref{eq:heavy}, \eqref{eq:medium} and \eqref{eq:light}, as we have\begin{equation*}
        \sum_{t=1}^T\frac{\sum_{i\in \Nc} v_ix^*_{it}}{1+\sum_{i\in \Nc} v_ix^*_{it}}\geq (1-\eps)\cdot\sum_{t=1}^T\frac{v(S_t^*)}{1+v(S_t^*)}. 
    \end{equation*}

















\subsection{Proof of Claim \ref{cl:nonlightcust}}\label{apx:nonlightcust}
We have\begin{align*}
    W_t^\lar& = \sum_{q = 1}^Q\sum_{i\in D_q}v_iX_{it}\\
    & = \sum_{q = 1}^Q \eps^5\cdot(1+\eps)^{q-1}\sum_{i\in D_q}X_{it}\\
    & = \sum_{q = 1}^Q \eps^5\cdot(1+\eps)^{q-1}\sum_{i\in D_q}x^*_{it}\\
    & = \sum_{q = 1}^Q\sum_{i\in D_q}v_ix^*_{it}\\
    & = w_t^\lar,
\end{align*}
where the second equality follows from the definition of $D_q$, and the third inequality follows from the degree preservation property \ref{it:P2}.





















% \subsection{Proof of Claim \ref{cl:lightcusts}}\label{apx:lightcust}
% First, note that the proof of Claim \ref{cl:nonlightcust} holds even for the case where $t$ is a light customer. Therefore, we can decompose $v(S_t)$ into a sum of a random variable $W_t^\sma$ representing the contribution of products in $D_0$, and a deterministic random variable $W_t^{\lar} \overset{a.s}{=}w_t^\lar$ (which will be treated as a constant from this point on), i.e.,
% \begin{equation*}
%     v(S_t) = W_t^\sma + w_t^\lar.    
% \end{equation*}
% For simplicity of notation, and only in this proof, we use the notation $W\coloneqq W_t^\sma$ and $w \coloneqq w_t^\lar$.
% This proof consists on two steps. In the first step, we lower bound the expectation of $v(S_t)/(1+v(S_t))$ with $\sum_{i\in \Nc}v_ix^*_{it}$, up to a constant $\alpha<1$, mainly using a convexity argument. In other words, we provide a constant $\alpha$ such that $$
%     v(S_t)/(1+v(S_t)) \geq \alpha\cdot \sum_{i\in \Nc}v_ix^*_{it}.
% $$
% Then, in the second step, we show that $\alpha = (1-O(\eps))$.
% \paragraph{Step 1:}
% Let $\cal Y$ be the support of the random variable $W$, i.e.,$$
%     {\cal Y} = \left\{y\in\R\,\colon\, \P\left[W= y\right]>0\right\}.
% $$
% We have
% \begin{align*}
%     \E\left[\frac{v(S_t)}{1+v(S_t)}\right] & = \E\left[\frac{W+w}{1+W+w}\right]\\
%     & = \sum_{y \in {\cal Y}} \frac{y+w}{1+y+w}\P\left[W=y\right]\\
%     & = \left(\sum_{y\in {\cal Y}} \frac{1}{1+y+w}\cdot \frac{(y+w)\cdot \P\left[W=y\right]}{w+\E\left[W\right]}\right)\cdot \left(w+ \E\left[W\right]\right).
% \end{align*}
% For each $y\in {\cal Y}$, let $f(y) = \frac{1}{1+y+w}$ and let $t_y = \frac{(y+w)\cdot \P\left[W=y\right]}{w+\E\left[W\right]}$. It is easy to see that $\sum_{y\in {\cal Y}} t_y=1$, and that $f$ is a convex function on $(0, +\infty)$. Therefore, using Jensen's inequality, and recalling that $\E[W]+w = \E[v(S_t)]$ we have\begin{align*}
%     \E\left[\frac{v(S_t)}{1+v(S_t)}\right] &\geq f\left(\sum_{y\in {\cal Y}} t_y \cdot y\right)\cdot \E\left[v(S_t)\right]\\
%     & = \alpha\cdot \E\left[v(S_t)\right],
% \end{align*}
% where $\alpha = f\left(\sum_{y\in {\cal Y}} t_y \cdot y\right)$.
% \paragraph{Step 2.} Let us now show that $\alpha = 1-O(\eps)$. We have
% \begin{align}
%         \alpha& = \frac{1}{1+w + \frac{\sum_{y\in {\cal Y}}(y+w)\cdot \P[W=y]\cdot y}{w+\E[W]}} \notag\\
%     & = \frac{1}{1+w+\frac{w\E[W] + \E[W^2]}{w+\E[W]}}\notag\\
%     & = \frac{1}{1+w+\E[W] + \frac{Var[W]}{w+\E[W]}}.\label{eq:last}
% \end{align}
% In order to show the desired property, we need to bound the denomination in Equation \eqref{eq:last}. To this purpose we have\begin{align*}
%     Var[W] & = Var\left[\sum_{i\in D_0} v_iX_{it}\right]\\
%         & \leq \sum_{i\in D_0} v_i^2\cdot Var[X_{it}]\\
%         &\leq \eps^5\cdot \sum_{i\in D_0} v_i\cdot \E[X_{it}]\\
%         &= \eps^5\cdot \E[W].
% \end{align*}
% Therefore, by replacing in Equation \eqref{eq:last}, we have\begin{align*}
%     \alpha \geq \frac{1}{1+\eps+\eps^5} \geq \frac{1}{1+2\eps}\geq 1-2\eps.
% \end{align*}

% Finally, combining steps 1 and 2, we have \begin{align*}
%     \frac{v(S_t)}{1+v(S_t)} &\geq \alpha\cdot \E[v(S_t)]\\
%                     & \geq (1-2\eps)\cdot \sum_{i\in \Nc} v_ix^*_{it}\\
%                     &\geq (1-2\eps)\cdot \frac{\sum_{i\in \Nc} v_ix^*_{it}}{1+\sum_{i\in \Nc} v_ix^*_{it}}.     
%         \end{align*}

























\subsection{Proof of Claim \ref{cl:lightcusts}}\label{apx:lightcust}
First, note that the proof of Claim \ref{cl:nonlightcust} holds even for the case where $t$ is a light customer. Therefore, we can decompose $v(S_t)$ into a sum of a random variable $W_t^\sma$ representing the contribution of products in $D_0$, and a deterministic random variable $W_t^{\lar} \overset{a.s}{=}w_t^\lar$ (which will be treated as a constant from this point on), i.e.,
\begin{equation*}
    v(S_t) = W_t^\sma + w_t^\lar.    
\end{equation*}
For simplicity of notation, and only in this proof, we use the notation $A\coloneqq W_t^\sma$ and $b \coloneqq w_t^\lar$.
This proof consists on two steps. In the first step, we lower bound the expectation of $v(S_t)/(1+v(S_t))$ with $\sum_{i\in \Nc}v_ix^*_{it}$, up to a constant $\alpha<1$, mainly using a convexity argument. In other words, we provide a constant $\alpha$ such that $$
    v(S_t)/(1+v(S_t)) \geq \alpha\cdot \sum_{i\in \Nc}v_ix^*_{it}.
$$
Then, in the second step, we show that $\alpha = (1-O(\eps))$.
\paragraph{Step 1:}
Let $\cal A$ be the support of the random variable $A$, i.e.,$$
    {\cal A} = \left\{a\in\R\,\colon\, \P\left[A= a\right]>0\right\}.
$$
We have
\begin{align*}
    \E\left[\frac{v(S_t)}{1+v(S_t)}\right] & = \E\left[\frac{A+b}{1+A+b}\right]\\
    & = \sum_{a \in {\cal A}} \frac{a+b}{1+a+b}\P\left[A=a\right]\\
    & = \left(\sum_{a\in {\cal A}} \frac{1}{1+a+b}\cdot \frac{(a+b)\cdot \P\left[A=a\right]}{b+\E\left[A\right]}\right)\cdot \left(b+ \E\left[A\right]\right).
\end{align*}
For each $a\in {\cal A}$, let $f(a) = \frac{1}{1+a+b}$ and let $z_a = \frac{(a+b)\cdot \P\left[A=a\right]}{b+\E\left[A\right]}$. It is easy to see that $\sum_{a\in {\cal A}} z_a=1$, and that $f$ is a convex function on $(0, +\infty)$. Therefore, using Jensen's inequality, and recalling that $\E[A]+b = \E[v(S_t)]$ we have\begin{align*}
    \E\left[\frac{v(S_t)}{1+v(S_t)}\right] &\geq f\left(\sum_{a\in {\cal A}} z_a \cdot y\right)\cdot \E\left[v(S_t)\right] = \alpha\cdot \E\left[v(S_t)\right],
\end{align*}
where $\alpha = f\left(\sum_{a\in {\cal A}} z_a \cdot a\right)$.
\paragraph{Step 2.} Let us now show that $\alpha = 1-O(\eps)$. We have
\begin{align}
        \alpha& = \frac{1}{1+b + \frac{\sum_{a\in {\cal A}}(a+b)\cdot \P[A=a]\cdot a}{b+\E[A]}} \notag\\
    & = \frac{1}{1+b+\frac{b\E[A] + \E[A^2]}{b+\E[A]}}\notag\\
    & = \frac{1}{1+b+\E[A] + \frac{Var[A]}{b+\E[A]}}.\label{eq:last}
\end{align}
In order to show the desired property, we need to bound the denominator in Equation \eqref{eq:last}. To this purpose we have\begin{align*}
    Var[A] & = Var\left[\sum_{i\in D_0} v_iX_{it}\right]\\
        & \leq \sum_{i\in D_0} v_i^2\cdot Var[X_{it}]\\
        &\leq \eps^5\cdot \sum_{i\in D_0} v_i\cdot \E[X_{it}]\\
        &= \eps^5\cdot \E[A].
\end{align*}
Therefore, by replacing in Equation \eqref{eq:last}, we have\begin{align*}
    \alpha \geq \frac{1}{1+\eps+\eps^5} \geq \frac{1}{1+2\eps}\geq 1-2\eps.
\end{align*}
Finally, combining steps 1 and 2, we have \begin{align*}
    \frac{v(S_t)}{1+v(S_t)} &\geq \alpha\cdot \E[v(S_t)]  \geq (1-2\eps)\cdot \sum_{i\in \Nc} v_ix^*_{it} 
                    \geq (1-2\eps)\cdot \frac{\sum_{i\in \Nc} v_ix^*_{it}}{1+\sum_{i\in \Nc} v_ix^*_{it}}.     
        \end{align*}

























