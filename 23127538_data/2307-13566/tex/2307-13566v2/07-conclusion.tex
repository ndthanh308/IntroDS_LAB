\section{Conclusion}
\label{conclusion_section}

This article sets out a research model to investigate the effect of imperfect XAI on human-AI decision-making. Thus far, human-computer interaction and CSCW literature lack to thoroughly scrutinize how explanations' correctness affects humans' decision-making and their reliance behavior on AI. Hence, through a human study with 136 participants, we empirically analyze humans' decision-making and specifically assess whether their level of expertise and explanations' assertiveness moderate the effect of imperfect XAI on appropriate reliance. Furthermore, we explore to what extent incorrect explanations deceive decision-makers' reliance on AI. With our findings, we make several contributions: First, we propose a research model to investigate the moderation of assertiveness and humans' level of expertise on imperfect XAI in decision-making tasks. We thereby extend the existing conceptualization of appropriate reliance by a new dimension of XAI advice. Second, through an empirical study, we reveal that imperfect explanations and participants' level of expertise affect human-AI decision-making for two different explanation modalities. In addition, we show the effect on complementary team performance and provide guidance for future studies on how to investigate imperfect XAI in the context of human-AI decision-making. Third, we propose a novel metric called Deception of Reliance (DoR), which allows us to measure the impact of incorrect explanations on decision-makers' reliance. Our results inform designers of human-AI collaboration systems and provide guidelines for their development. Fourth, we reveal which role the language tone in explanations plays and outline important dimensions that should be considered when designing for XAI advice.

Overall, with this work, we reveal the impact of imperfect XAI on human-AI decision-making by taking into account humans' level of expertise and explanations' assertiveness. Extensive and rigorous research is needed to fully understand and exploit imperfect XAI in decision-making. We invite researchers to take part in this debate and hope to inspire scientists to actively participate in this endeavor.