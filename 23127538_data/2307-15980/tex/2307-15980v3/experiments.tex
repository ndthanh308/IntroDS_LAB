\section{EXPERIMENTS} \label{sec: experiments}
% Figure environment removed

We evaluate our approach on two custom simulated environments: \cp and \re. Each of these environments contains a nuisance feature which is likely to induce causal confusion. Our masking approach can successfully eliminate these spuriously correlated features. Precise experimental details are deferred to Appendix~\ref{app: experiments}.

\subsection{Environments} \label{sec: env}

Both considered environments are modified to include a nuisance feature corresponding to the previous action taken by the expert (analogous to the brake light example). For each environment, the expert is a standard constrained finite-time optimal control policy which minimizes cumulative trajectory loss. This expert reward function is not provided to the imitation learning agent.

\textbf{\cp}. This environment consists of a standard planar cart-pole system with a continuous scalar horizontal force applied to the cart. A quadratic cost is imposed for deviations from the vertical target state. The spuriously correlated feature is a colored square in the upper-left corner of each image, which interpolates between green and red depending on the most recently executed action.

\textbf{\re}. We consider a top-down version of a two-dimensional two-joint \re environment \cite{OpenAIGym}. The environment penalizes squared distance of the end effector to a black target dot. The target location is included in the state vector, thus satisfying Assumption~\ref{ass: expert_attend}. Two torques, one per joint, are specified as the control inputs; the nuisance feature is a red dot in the upper-left corner whose horizontal position and vertical position encode the two control inputs from the previous time step. This ``joystick'' introduces a different kind of nuisance feature than in the \cp environment.


\subsection{Discussion}

We compare the performance of our masked policy against vanilla behavior cloning. The baseline behavior cloning policy is denoted by \bc, and our masked policy is denoted by \masked. For reference, we also measure the performance of the behavior cloning policy with the confounding signals manually removed by superimposing a white square on the upper-left corner, denoted \bcd. We emphasize that \bcd requires human judgement to manually eliminate spurious confounders; we show that we can approach this performance in a principled and automated way.

Figure~\ref{fig: results} displays our experimental results. For \cp, the policies were not able to consistently stabilize the pendulum at the beginning of training, leading to high loss variance. Across both environments, the \masked policy substantially outperforms the vanilla behavior cloning policy $\bc$. It is worth noting that \masked approaches the manually deconfounded baseline's performance without requiring expert queries, access to the expert reward function, or pre-specified information on the causal graph in the deconfounding procedure. However, there is a gap between the performance of our method and manual masking for the \re environment. This is likely attributable to imperfect disentanglement in the $\beta$-VAE, and we expect that our approach could benefit substantially from future research in disentangled representation learning.

Figure~\ref{fig: dependencies} provides a visualization of our masking procedure and the resulting mask for the \cp environment. Note that our algorithm masks the third observation $\Ob[][3]$, corresponding precisely to the manually masked confounding square. While we use a latent space size of three (the precise number of independent factors of variation) for visualization purposes, our masking procedure is fully functional for larger choices of the latent size. For \re, although there are $6$ factors of variation in each image, a larger latent space of size $12$ yielded superior disentanglement and reconstruction performance.

% Figure environment removed



The most significant limitation of our work, besides the explicitly stated assumptions, is the requirement that confounding factors are observable and can be neatly disentangled. While this holds for the environments considered in this work, more complex environments may introduce entanglement between causally confusing features and important features to which the expert policy actually attends. We introduce the Hoeffding threshold hyperparameter $\gamma$ to mitigate this concern; however, investigating more principled methods for handling incomplete disentanglement would be an exciting area of future work.
