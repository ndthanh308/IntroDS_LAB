\section{PROBLEM STATEMENT AND METHOD} \label{sec: method}
We address the \emph{causal confusion} problem in imitation learning and aim to mask spuriously correlated observations. To this end, we investigate the following problem statement:

\begin{center}
\emph{How can we identify and eliminate spuriously correlated observations without relying on online expert queries or knowledge of the expert reward function?}
\end{center}

Our approach addresses this problem in a theoretically-grounded way. Specifically, we make the following contributions:
\begin{enumerate}
    \item We present an algorithm for identifying and masking causally confusing observations \emph{without relying on reward function knowledge, expert queries, or causal graph knowledge}.
    \item We prove that, under certain conditions, our procedure is \emph{conservative}: if an observation causally affects the expert actions, it will not be masked.
    \item We demonstrate the importance of \emph{initial state interventions} by showing theoretically that the interventions reduce excess conservatism in the masking algorithm.
\end{enumerate}

Section~\ref{sec: assumptions} presents and analyzes the assumptions underlying our method. Section~\ref{sec: derivation} motivates and derives our method, which is then presented formally in Section~\ref{sec: workflow}.


\subsection{Assumptions} \label{sec: assumptions}

Our proposed method relies on the following assumptions to ensure the theoretical guarantees in Section~\ref{sec: theory}.

\begin{assumption} \label{ass: time_invariance}
The system causal graph $\Gs$ is time invariant. Namely, consider two arbitrary time steps ${t, t' \in \N}$ with $t' \geq t$ and two arbitrary time-indexed variables $X_t$ and $Y_{t'}$ in $\Gs$. Then if $X_t \cau Y_{t'}$ is an edge in $\Gs$, then so is $X_{t + \Delta} \cau Y_{t' + \Delta}$ for any $\Delta \in \Z$ such that ${\min(t+\Delta,t'+\Delta) \geq 1}$.
\end{assumption}

Time-invariance of the expert policy allows for causal inference via interventions on the initial state $\St[1]$. Otherwise we would require the ability to intervene at arbitrary time steps, which is unrealistic for most real-world systems.

\begin{assumption} \label{ass: expert_attend}
The expert policy attends only to observational information derived from the underlying state. Namely, if $\Ob[t][\oi] \cau \Ac[t'][\ai]$ in $\Gs$ for $t,t' \in \N$ with $t' \geq t$, then there must exist an index $\si$ such that ${\St[t][\si] \cau \Ob[t][\oi]}$.
\end{assumption}

Assumption~\ref{ass: expert_attend} reflects the intuition that the expert policy itself must not be fooled by spurious information in the observation space. This is a natural assumption in the considered case where the dynamics of the underlying system depend only on $\St$, not $\Ob$. 

\begin{assumption} \label{ass: reaction_horizon}
    The expert policy reacts to observations within a \emph{reaction horizon} $H \in \N$. Specifically, if $\Ob[t][\oi] \cau \Ac[t_1][\ai]$ in $\Gs$ for some $t_1 > t$ and particular $t \in \N$, $\oi \in [\obdim]$, and $\ai \in [\acdim]$, then there exists a $t_2 \in [t \sdots t+H-1]$ such that $\Ob[t][\oi] \cau \Ac[t_2][\ai]$.
\end{assumption}

Assumption~\ref{ass: reaction_horizon} imposes a horizon within which the expert is assumed to react to a hypothetical intervention on a state or observation. For finite-length trajectories, $H$ can be chosen to be the entire trajectory length, with the algorithm and theory still valid. As such, $H$ introduces a hyperparameter that allows for more tractable computation under some assumptions on the expert. Our experiments show that $H$ can be much smaller than the trajectory length for certain practical dynamic systems and experts.

Finally, we formalize a class of SCMs that behave nicely under interventions.

\begin{assumption} \label{ass: abs_cont}
The system SCM $\Ms=\SCM$ is \emph{interventionally absolutely continuous}, meaning that for any disjoint sets of nodes $\bX$, $\bY$, and $\bZ$, the interventional distribution $\Pd{\bz \mid \doc(\bX = \bx), \by}$ is absolutely continuous with respect to the Lebesgue measure, has a bounded Radon-Nikodym derivative, and is continuous as a measure-valued function with respect to $\bx$ and $\by$.
\end{assumption}

Assumption~\ref{ass: abs_cont} stipulates that the probability distribution induced by our SCM on any set of non-intervened nodes is absolutely continuous with bounded density. This is a technical condition that fascilitates analysis and allows us to assert that Hoeffding's test is consistent. We note that subsequent D-statistic variations allow for non-absolutely continuous joint distributions \cite{blum1961distribution} --- we leave the theoretical and practical implications of more sophisticated testing to future work.
% \yb{How restrictive is this assumption?}


\subsection{Derivation} \label{sec: derivation}

Our aim is to mask a particular observation $\Ob[][\oi]$ across all time steps if it has no causal effect on any expert action within the reaction horizon. As intervening on observations is impractical, this causality is challenging to deduce. We do, however, assume the ability to intervene on the system in one specific instance: setting the state variables $\St[1]$ at initialization. We manipulate $\St[1]$ to infer the possible existence of a true causal relationship.

We first motivate our approach from an arbitrary time step $t \geq 2$ before specializing on the initialization. Consider arbitrary observation and action indices ${\oi \in [\obdim], \ai \in [\acdim]}$ and time steps $t, t' \in \N$ with $t' \in [t \sdots t + H - 1]$. Assumption~\ref{ass: expert_attend} states that a causal effect $\Ob[t][\oi] \cau \Ac[t'][\ai]$ must arise from a larger causal path
\begin{align} \label{eqn: causal_path}
    \St[t][\si] \cau \Ob[t][\oi] \cau \Ac[t'][\ai]
\end{align}
in $\Gs$, for some state variable index $\si \in [\stdim]$. We now observe that by faithfulness of $\sys$ it must be that $\St[t][\si] \nPI \Ob[t][\oi]$ and $\St[t][\si] \nPI \Ac[t'][\ai]$; i.e. the causal relationships in $\Gs$ imply probabilistic dependencies in the induced distribution from $\Ms$. Note that these are \emph{statistical} statements which can be ascertained from the observational data. We define the boolean variable $\Dfull$ to check these independencies:
    \begin{align} \label{eqn: causal_check}
        \Dfull \coloneqq (\St[t][\si] \nPI \Ob[t][\oi]) \land (\St[t][\si] \nPI \Ac[t'][\ai]),
    \end{align}
    and introduce the ``potential cause'' notation 
    \begin{align} \label{eqn: potential_cause}
        \Ob[t][\oi] \pcau \Ac[t'][\ai] \coloneqq \bigvee_{\si=1}^{\stdim} \left( \Dfull \right).
    \end{align}

The boolean-valued statement $\Ob[t][\oi] \pcau \Ac[t'][\ai]$ intuitively captures that, based on observational data, there may (but need not) exist a true causal edge $\Ob[t][\oi] \cau \Ac[t'][\ai]$ generated by some $\St[t][\si]$ as in \eqref{eqn: causal_path}. We denote by $\Ob[t][\oi] \npcau \Ac[t'][\ai]$ the logical negation of $\Ob[t][\oi] \pcau \Ac[t'][\ai]$. As we will elaborate in more detail shortly, if $\Ob[t][\oi] \npcau \Ac[t'][\ai]$ for all actions $\ai \in [\acdim]$ and $t'$ in the reaction horizon, we want to ``mask'' the $\oi \tth$ observation as it has no causal effect on the expert action but could be spuriously correlated in a way that undermines the imitation learning policy performance. 

It is immediate from the above faithfulness argument that for $t \geq 2$, we have the implication
\begin{align} \label{eqn: conservative_general}
    \Ob[t][\oi] \cau \Ac[t'][\ai] \implies \Ob[t][\oi] \pcau \Ac[t'][\ai].
\end{align}
Note that (\ref{eqn: conservative_general}) provides a \emph{conservativeness} guarantee: if an observation causally influences an action, we will not mistakenly conclude from observational data that it does not, and hence incorrectly mask an observation that is actually used by the expert policy. However, this conservativeness is not apparent for $t=1$ in the modified causal model $\sysi$, where we intervene to specify the initial state distribution, overriding the natural randomness resulting from $\Hi[1]$ and potentially breaking faithfulness. As a simple counterexample, initializing $\St[1]$ to a constant vector would make $\St[1][\si]$ independent of every other random variable in the causal graph, and therefore no potential causes could be discovered as \eqref{eqn: causal_check} would always be false. Nonetheless, when a sufficiently sensible initialization distribution is used, we prove that the conservativeness result still holds under intervention on $\St[1]$ in Section~\ref{sec: theory}.

The reverse implication to \eqref{eqn: conservative_general} does not hold. It is possible that spurious statistical relationships exist while a causal edge $\Ob[t][\oi] \to \Ac[t'][\ai]$ does not. Indeed, for $t \geq 2$, the abundance of chronologically antecedent variables virtually guarantees that all variables have share a common cause and hence a statistical dependence. The sole exception is the initial state $\St[1]$. By intervening on $\St[1]$, we eliminate the incoming edge from the only possible common ancestor $\Hi[1]$ in the causal graph (Figure~\ref{fig: structure}). Therefore, we expect that this interventional ability should help eliminate potential causes $\Ob[1][\oi] \pcau \Ac[t'][\ai]$ which do not exist in the true causal graph and reduce excessive conservativeness in the algorithm. We analyze this idea formally in Section~\ref{sec: theory}.

The culmination of our efforts is described in Algorithm~\ref{alg: mask}, which checks for potential causes at $t = 1$ using expert data $\trajs$ collected from the interventional system $\sysi$. Note that Algorithm~\ref{alg: mask} invokes the $\textsc{Hoeffding}$ routine to compute Hoeffding's D statistic for independence between two variables. This test is computed over our dataset of trajectories $\trajs$, extracting exactly one pair of variables from each trajectory ($\Nhoeff = N$). For concreteness, consider the call $\textsc{Hoeffding}(\St[1][2] \nPI \Ac[3][4]\ \mathrm{in}\ \trajs)$. This extracts, from each trajectory, the second element of the $t=1$ state and the fourth element of the $t=3$ action. These $N$ pairs are then supplied to Hoeffding's test, which returns a real number in the range $[-0.5, 1]$, with a value greater than zero indicating dependence. Since perfect observational disentanglement is unrealistic, we introduce a small positive threshold hyperparameter $\gamma$.

Algorithm~\ref{alg: mask} is presented for readability and can be implemented more efficiently. The Hoeffding tests between $\St[t][\si]$ and $\Ob[t][\oi], \Ac[t'][\ai]$ can be precomputed, yielding the runtime
\[
    O\left(\stdim (\obdim + H \acdim) N \log N\right),
\]
where $N \log N$ is the cost of evaluating Hoeffding's test for a specific pair of variables over $N$ trajectories. In practice, Hoeffding's test executions are very fast---on the order of milliseconds for $N=10^3$---and incur a negligible overhead compared with the training time of imitation learning.

 \begin{remark}
     The reader may have noticed that our approach bears a resemblance to \emph{instrumental variable regression}, a statistical technique for estimating causal relationships that has also received some attention in the causal imitation learning literature \cite{swamy2022causal}. We emphasize that $\St[t][\si]$ does not constitute a valid instrumental variable in the causal path \eqref{eqn: causal_path} as there may be many other paths between $\St[t][\si]$ and $\Ac[t'][\ai]$ which are not mediated by $\Ob[t][\oi]$. Thus while the spirit of our approach is related to instrumental variable regression, we cannot use $\St[t][\si]$ to precisely determine a causal relationship between $\Ob[t][\oi]$ and $\Ac[t'][\ai]$ and only use $\St[t][\si]$ to provide evidence of a potential cause.
\end{remark}


\subsection{Imitation Learning Workflow} \label{sec: workflow}

Drawing on the masking approach developed in Section~\ref{sec: derivation}, we summarize our overall deconfounded imitation learning workflow as the following four steps.

\begin{enumerate}
    \item Collect random-policy trajectories to learn a observation representation using a $\beta$-VAE, denoted by ${\dec\, \circ\, \enc: \imspace \to \imspace}$, with an encoder $\enc: \imspace \to \obspace$ and decoder $\dec: \obspace \to \imspace$. For a well-trained $\beta$-VAE, $\dec\, \circ\, \enc$ approximates the identity. We rely on $\beta$-VAEs' latent space regularization to produce disentangled observations.
    \item Collect a sequence of $N$ trajectories $\trajs$ from the expert policy, with the starting state distribution $\Pdint{\st[1]}$ over $\stspace$ having any density that is everywhere nonzero (e.g. uniform).
    \item Execute Algorithm~\ref{alg: mask} on $\trajs$ to obtain the observation mask $\maski \in \{0,1\}^{\obdim}$, where $\maski_{\oi} = 1$ if the $\oi \tth$ observation is to be masked.
    \item Train the final policy $\compnet: \imspace^L \to \acspace$ on $\trajs$ using standard supervised learning; $\compnet$ masks the disentangled observation space using $\maski$ before executing a learnable policy network $\net$:
        \[
            \compnet(\im[t], \dots, \im[t-L+1]) = \net(\vaemask(\im[t]), \dots, \vaemask(\im[t-L+1])),
        \]
        where the masked $\beta$-VAE $\vaemask: \imspace \to \imspace$ has its weights fixed and is defined as
        \[
            \vaemask(\im[][]) = \dec(\neg\maski \odot \enc(\im[][])).
        \]
\end{enumerate}

Note that this overall structure generally follows the seminal work of \cite{de2019causal}. Our key contribution is Algorithm~\ref{alg: mask}, which provides a mask for the disentangled observations without relying on expert queries, the expert reward function, or specification of the causal graph. A visualization of Algorithm~\ref{alg: mask} is provided in Figure~\ref{fig: dependencies} for the \cp system considered in the experiments. We show in Section~\ref{sec: theory} that Algorithm~\ref{alg: mask} enjoys notable theoretical guarantees.

\begin{algorithm}
	\caption{Masking algorithm} \label{alg: mask} 
    \hspace{2mm} Hyperparameter $\gamma > 0$.

\begin{algorithmic}
\Procedure{Mask}{$\trajs$}
	\State Initialize $\maski \in \{0, 1\}^{\obdim}$ to be an all-zero vector.
	\For{$\oi = 1, \ldots, \obdim$}
    	\State Mask the $\oi^{\text{th}}$ observation according to
    	\vspace{-1.5mm}
    	\begin{small}
    	\begin{align} \label{eqn: mask}
            \quad \maski_{\oi} \gets \left( \Ob[1][\oi] \npcau \Ac[t'][\ai] \;\; \forall \ai \in [\acdim], \;\; \forall t' \in [H] \right), \\[-6.5mm] \nonumber
    	\end{align}
    	\end{small}
        \hspace{8mm} computing $\Ob[1][\oi] \npcau \Ac[t'][\ai]$ using \textsc{Check}. 
	\EndFor
	\State \textbf{return} $\maski$
\EndProcedure
\end{algorithmic}
\vspace{0.2cm}
\begin{algorithmic}
\Procedure{Check$\{\Ob[t][\oi] \pcau \Ac[t'][\ai]\}$}{$\trajs$} 
	\For{$\si = 1, \dots, \stdim$}
		\State $a \gets \textsc{Hoeffding}(\St[t][\si] \nPI \Ob[t][\oi]\ \mathrm{in}\ \trajs) > \gamma$
		\State $b \gets \textsc{Hoeffding}(\St[t][\si] \nPI \Ac[t'][\ai]\ \mathrm{in}\ \trajs) > \gamma$
		\If{$a \land b$}
			\State {\bf return} True
		\EndIf
	\EndFor
	\State {\bf return} False
\EndProcedure
\end{algorithmic}
\end{algorithm}
