\section{NOTATION AND BACKGROUND}

We denote the set of real numbers by $\R$ and the set of natural numbers by $\N$. The set $\{1, \dots, a\} \subset \N$ is denoted by $[a]$ for $a \in \N$, and similarly ${a, \dots, b} \subset \N$ is denoted by $[a \sdots b]$. For a pair of boolean variables $x$ and $y$, the notation $\wedge$ denotes the ``and'' operator while $\vee$ denotes ``or.'' For a set of boolean variables $\{ x_1, x_2, \ldots, x_n \}$, the notations $\bigwedge_{i=1}^n x_i$ and $\bigvee_{i=1}^n x_i$ denote $x_1 \wedge x_2 \wedge \ldots \wedge x_n$ and $x_1 \vee x_2 \vee \ldots \vee x_n$, respectively. The logical negation of a boolean variable or vector $x$ is denoted by $\neg x$. We denote the identically zero function on a domain by $\zf$, and we write $f(\cdot) \not \equiv \zf$ to mean that $f(\cdot)$ is not equivalent to the zero function over its argument---i.e., there exists an input where $f$ is nonzero.


\subsection{Measure theory and probability}

For a random variable $X$, we introduce the notation ${\Pdi{x} \in M(X)}$ to represent a probability measure over the values $x$ in the domain of $X$, contained in the space of measures $M(X)$. The uniform measure over an interval $[a,b] \subset \R$ is denoted by $\cU(a,b)$. For two measures $\mu$ and $\nu$, we say that $\nu$ is absolutely continuous with respect to $\mu$ if for every $\mu$-measurable set $A$, $\mu(A) = 0$ implies $\nu(A) = 0$. If $\nu$ is absolutely continuous with respect to $\mu$, we let $d\nu / d\mu$ denote the Radon-Nikodym derivative of $\nu$ with respect to $\mu$. The standard Lebesgue measure on $\R$ is denoted $\lambda$. For a measure $\mu$ which is absolutely continuous with respect to $\lambda$, we define its $L_1$ norm in the typical manner
\begin{align*}
    \Pnormi{\mu} \defeq \int \biggl \lvert \frac{d \mu}{d \lambda} \biggr \rvert d \lambda,
\end{align*}
which we take to be the default norm in the Banach space of measures on $\R$. We denote independence between two random variables using $\PI$ and its negation by $\nPI$. 


\subsection{Causal graphs and structural causal models}

We denote a directed acyclic graph by $\G$, with the presence of a direct edge between nodes $X$ and $Y$ denoted $X \cau Y$. For a given node $X$ in $\G$, we let $\G_{\underline{X}}$ denote the graph obtained by deleting outgoing edges from $X$. We denote sets of nodes in a graph using bold font (e.g., $\bZ$). The set of parents of a node $X$ in a graph is denoted by $\pa{X}$. A path between two nodes $X$ and $Y$ can consist of arbitrarily directed edges and is said to be blocked by a set of nodes $\bZ$ if the path contains any of the following \cite{Pearl09}:
\begin{itemize}
    \item A chain $I \cau M \cau J$ with $M \in \bZ$.
    \item A fork $I \leftarrow M \cau J$ with $M \in \bZ$.
    \item A collider $I \cau M \leftarrow J$ such that $M \not \in \bZ$ and no descendent of $M$ is in $\bZ$.
\end{itemize}
     Two nodes $X$ and $Y$ are said to be d-separated by $\bZ$ if $\bZ$ blocks every path between $X$ and $Y$. We call a path with all edges oriented the same direction a directed path.

We leverage Pearl's structural causal model (SCM) formalism \cite{Pearl09}. An SCM $\M = \SCM$ consists of endogenous variables $\bV$, exogenous variables $\bU$, and structural equations $\cF$. Each $V \in \bV$ is represented by a node in the causal graph $\G$ and associated with an independently distributed exogenous variable $U_V \in \bU$. The structural equations $f_V \in \cF$ assign values of a particular node $V \in \bV$ as a function $V \defeq f_V(\pa{V}, U_V)$ of its parents and associated exogenous variable. The SCM $\M$ induces a joint distribution $\Pd{\bv}$ over the endogenous variables $\bV$. We say that an SCM $\M$ is faithful to its causal graph $\G$ if the distribution $\Pd{\bv}$ induced by $\M$ contains only the pairwise conditional independencies implied by $\G$; i.e. $X \PI Y \mid \bZ$ in the joint distribution from $\M$ iff $X$ and $Y$ are d-separated by $\bZ$ in $\G$ \cite{Spirtes2000}. As a notable special case, if $\bZ$ is empty and there exists a path from $X$ to $Y$ with no colliders then $X \nPI Y$. 

We define an intervention on a particular node $V$ to be a reassignment of the associated structural equation $f_V$. This intervention can take the form of a constant intervention $V \defeq v$, which we denote by $\doc(V = v)$ for a constant $v$ and may abbreviate to $\doc(v)$. We also define a distributional intervention, denoted by $\doc(V \sim \Pdint{v})$, where we assign $V$ to be drawn from a specified distribution $\Pdint{v}$. We denote the post-intervention SCM by $\Mi$, with an associated causal graph $\Gi$ identical to $\G$ but with incoming edges to $V$ removed. Note that reassigning the associated structural equation for any particular node $V$ induces a new distribution generated by $\Mi$ over the set of all endogenous variables $\bV$, which we denote by $\Pdi{\bv \mid \doc(V = v)}$ or $\Pdi{\bv \mid \doc(V \sim \Pdint{v})}$.


\subsection{Behavior cloning} \label{sec: imitation_learning}
Behavior cloning uses expert trajectories to train an imitating policy. For the system of interest, we use $\stdim$, $\imdim$, $\obdim$, and $\acdim$ to denote the dimensionality of the bounded state space $\stspace \subseteq \R^{\stdim}$, raw image observation space $\imspace \subseteq \R^{\imdim}$, disentangled observation space $\obspace \subseteq \R^{\obdim}$, and action space $\acspace \subseteq \R^{\acdim}$. Let $\St$, $\Im$, $\Ob$, and $\Ac$ be vector random variables taking on values in $\stspace$, $\imspace$, $\obspace$, and $\acspace$, respectively, for a discrete time step $t \in \N$. States variables $\St$ represent the intrinsic low-dimensional dynamics of the system (e.g. simulator variables) while observations $\Ob$ are distilled using a VAE-style framework from high-dimensional image measurements $\Im$, with $\imdim \gg \obdim$. The system dynamics assume that $\St[t+1]$ is strictly a function of $\St$ and $\Ac$. Lower-case script letters $\si \in [\stdim]$, $\oi \in [\obdim]$, and $\ai \in [\acdim]$ denote specific indices in the state, observation, and action vectors. For example, $\St[1][\si]$ refers to the real-valued random variable corresponding to the $\si \tth$ state variable at the first time step. We model $\Hi[1] \sim \cU(a,b)$ to be an unobserved variable capturing uncontrolled and unknown initialization stochasticity (i.e. a random ``seed'').

The collection of states, observations, and actions, along with $\Hi[1]$, comprise endogenous variables in an SCM defining our system. We denote the system SCM by $\Ms$ and denote the corresponding faithful causal graph by $\Gs$. Note that the SCM depends on the choice of policy. Since we aim to infer causalities regarding the expert policy, we generally let any causal relationships refer to the $\Ms$ and $\Gs$ induced by the expert policy unless otherwise stated. We pair the system SCM and causal graph with the tuple $\sys$. Although nodes in $\Gs$ are individual elements in our vector-valued random variables (i.e., $\St[t][\si]$ is a node, not $\St[t]$), with some abuse of notation, we let the edge symbol $\St[t] \cau X$ signify that $\St[t][\si] \cau X$ for some $\si \in [\stdim]$. Similarly, $X \cau \St[t]$ denotes that $X \cau \St[t][\si]$ for some $\si$.

% Figure environment removed

This work evaluates the importance of interventionally assigning the initial state to a particular distribution ${\St[1] \sim \Pdint{\st[1]}}$. This intervention yields a modified SCM $\Msi$ with a corresponding (not necessarily faithful) causal graph $\Gsi$, which removes the edge $\Hi[1] \to \St[1]$ in $\Gs$ (Figure~\ref{fig: structure}). We collect $N$ arbitrary-length expert trajectories from $\Msi$. The collection of all such trajectories is denoted $\trajs$. Among these $N$ trajectories, the $i^{\textrm{th}}$ trajectory consists of the tuple
\[
	\traj = \langle \st[1], \dots, \st[T];\ \im[1], \dots, \im[T];\ \ob[1], \dots, \ob[T];\ \ac[1], \dots, \ac[T] \rangle,
\]
where lowercase letters represent a concrete random variable value (to avoid confusion with indices, we use $\im$ to denote a value of $\Im$). Implicit in this definition is the existence of an \emph{encoder} $\enc: \imspace \to \obspace$ mapping each image $\im$ to a disentangled observation $\ob$. We characterize trajectories as containing observations for simplicity; our environment only provides the images $\im$, and the extraction of disentangled observations $\ob$ is method-dependent.

When training agents on $\trajs$, we parameterize policies as a neural network $\net: \imspace^L \to \acspace$. The neural policy maps some history of observations to an action $a_t$ via
\begin{align} \label{eqn: policy}
    \ac[t] = \net(\im[t], \im[t-1], \dots, \im[t-L+1]).
\end{align}
We then train $\net$ via standard behavior cloning by randomly sampling batches of images and expert actions from $\trajs$ and performing supervised regression.


\subsection{Statistical independence tests} \label{sec: hoeffding}
\newcommand{\Nhoeff}{N_{\textrm{Hoeff}}}

Our method relies on identifying whether two random variables are statistically dependent. While this is a challenging problem with a rich literature \cite{sheskin2020handbook}, in this paper, we only briefly introduce a well-known independence test for continuous distributions based on Hoeffding's D statistic \cite{hoeffding1994non, even2020independence}. Consider two real-valued random variables $X$ and $Y$ with a joint cumulative distribution function ${F(x, y) = \Pd{X \leq x, Y \leq y}}$. Hoeffding's D statistic operates on $\Nhoeff$ independent pairs of observations $\{(X_1, Y_1), \dots (X_{\Nhoeff}, Y_{\Nhoeff})\}$ and outputs a real number $D$ in the range $[-0.5, 1]$, with $D > 0$ indicating dependence. The computational complexity of calculating this statistic is $\mathcal{O} (\Nhoeff \log \Nhoeff)$. For absolutely continuous joint distributions, the D statistic is unbiased and consistent as $\Nhoeff \to \infty$, meaning that the dependence is correctly represented with probability arbitrarily close to $1$. Subsequent variations of the D statistic maintain consistency even for non-absolutely continuous joint distributions \cite{blum1961distribution}, although these complications are outside the scope of our work. We refer to the independence test based on the Hoeffding's D statistic as Hoeffding's independence test.
