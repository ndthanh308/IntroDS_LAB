\appendix

\section{Proof of Eq.~\ref{eqn:svd_diff_final_form}}
\label{app:full_derivation}

For the sake of simplicity, we avoid feature map index $i$ and task identifier $t$ in the following proof.
Let, feature map $\mat{F}$ be a ${d \times p}$ matrix and $d \ge p$. Then, $\mat{F}$ can be decomposed with $\mat{F}=\mat{P}\mat{\Sigma}\mat{Q}^{\top}$, where $\mat{P} \in \mathbb{R}^{d \times m}$, $\mat{\Sigma} \in \mathbb{R}^{m \times p}$, and $\mat{Q} \in \mathbb{R}^{p \times p}$ such that $ \mat{P}\mat{P}^{\top} = \mat{Q}\mat{Q}^{\top} = \mat{I} $. The differential of $\mat{P}$ can be expressed as
\begin{align}
    \label{eqn:a_dx}
    \dd \mat{F} = \dd \mat{P}\mat{\Sigma}\mat{Q}^{\top} + \mat{P}\dd\mat{\Sigma}\mat{Q}^{\top} + \mat{P}\mat{\Sigma}\dd\mat{Q}^{\top}
\end{align}

The differential $\dd \mat{\Sigma}$ is diagonal like $\mat{\Sigma}$ while $\dd \mat{P}$ and $\dd \mat{Q}$ maintain orthogonality constraints: $\dd \mat{P}^{\top} \mat{P} + \mat{P}^{\top} \dd \mat{P} = 0$ and $\dd \mat{Q}^{\top} \mat{Q} + \mat{Q}^{\top} \dd \mat{Q} = 0$ respectively. By applying the orthogonality of $\mat{P}$ and $\mat{Q}$, Eq.~\ref{eqn:a_dx} can be written as
\begin{align}
    \mat{P}^{\top}\dd \mat{F}\mat{Q} = \mat{P}^{\top}\dd \mat{P}\mat{\Sigma} + \dd\mat{\Sigma} + \mat{\Sigma} \dd\mat{Q}^{\top} \mat{Q}
\end{align}
Since both $\mat{P}^{\top}\dd \mat{P}$ and $\dd\mat{Q}^{\top} \mat{Q}$ are anti-symmetric as well as zero diagonal whereas $\dd \mat{\Sigma}$ is diagonal, $\dd \mat{\Sigma}$ can be written as
\begin{align}
    \label{eqn:a_ds}
    \dd\mat{\Sigma} = \Big(\mat{P}^{\top}\dd\mat{F}\mat{Q}\Big)_{\text{diag}}
\end{align}
with $\mat{A}=\mat{P}^{\top}\dd \mat{P}$, $\mat{B}=\dd\mat{Q}^{\top} \mat{Q}$ and $\mat{R} = \mat{P}^{\top}\dd \mat{F}\mat{Q}$ The off-diagonal part satisfies the following 
\begin{align}
    \label{eqn:a_bij}
    \mat{A} \mat{\Sigma} + \mat{\Sigma} \mat{B} = \mat{R} - \mat{R}_{\text{diag}} \nonumber \\
    \Rightarrow \mat{\Sigma}^{\top}\mat{A}\mat{\Sigma} + \mat{\Sigma}^{\top} \mat{\Sigma} \mat{B} = \mat{\Sigma}^{\top} \Big(\mat{R} - \mat{R}_{\text{diag}}\Big) = \mat{\Sigma}^{\top} \bar{\mat{R}} \nonumber\\
    \Rightarrow 
    \begin{cases}
    \sigma_{i}a_{ij}\sigma_{j} + \sigma_{i}^{2}b_{ij} = \sigma_{i}\bar{\mat{R}}_{ij} \nonumber\\
    -\sigma_{j}a_{ij}\sigma_{i} - \sigma_{j}^{2}b_{ij} = \bar{\mat{R}}_{ji}\sigma_{j}
    \end{cases} \nonumber\\
    \Rightarrow
    b_{ij} = \begin{cases}
    \Big(\sigma_{i}^{2} - \sigma_{j}^{2}\Big)^{-1}~\Big(\sigma_{i}\bar{\mat{R}}_{ij} + \bar{\mat{R}}_{ji}\sigma_{j}\Big) ~,~~~~i \ne j \\
    0~,~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~i = j
    \end{cases}
\end{align}
here $\bar{\mat{R}} = \mat{R} - \mat{R}_{\text{diag}}$ and $\sigma_{i} = \mat{\Sigma_{ii}}$. Using Eq.~\ref{eqn:a_bij}, we can write $\mat{B}$ as follows
\begin{align}
    \mat{B} = \mat{K} \circ \Big( \mat{\Sigma}^{\top} \bar{\mat{R}} + \bar{\mat{R}}^{\top} \mat{\Sigma} \Big) = \mat{K} \circ \Big( \mat{\Sigma}^{\top} \mat{R} + \mat{R}^{\top} \mat{\Sigma} \Big)
\end{align}
where
\begin{align}
    \label{eqn:a_kij}
    \mat{K}_{ij} =
    \begin{cases}
    \dfrac{1}{\sigma_i^2 - \sigma_j^2}, i \neq j \\
    0, i=j
    \end{cases}
\end{align}
Consequently,
\begin{align}
    \label{eqn:a_dq}
    \dd\mat{Q} = 2\mat{Q}~\Bigg(\mat{K}^{\top} \circ \Big(\mat{\Sigma}^{\top}\mat{P}^{\top}\dd\mat{F}\mat{Q}\Big)_{\text{sym}}~\Bigg)
\end{align}

Using Eq.~\ref{eqn:a_ds} and ~\ref{eqn:a_dq} we can obtain $\dd \mat{P}$ from Eq.~\ref{eqn:a_dx}
\begin{align}
\label{eqn:a_dps}
    \dd \mat{P} \mat{\Sigma} = \dd \mat{F} \mat{Q} - \mat{P} \dd \mat{\Sigma} - \mat{P}\mat{\Sigma}\dd \mat{Q}^{\top}\mat{Q} =: \mat{C}
\end{align}
For any block form $\dd \mat{P} = (\dd \mat{P_1}, \dd \mat{P_2})$, the Eq.~\ref{eqn:a_dps} would be satisfied, where $\dd \mat{P_1} \coloneqq \mat{C}\mat{\Sigma}_d^{-1} \in \mathbb{R}^{m \times d}$ and $\dd \mat{P_2} \coloneqq -\mat{P_1}\dd \mat{P_1}^{\top}\mat{P_2} \in \mathbb{R}^{m \times m-d}$ with $\mat{\Sigma}_d$ being the top $d$ rows of $\mat{\Sigma}$. Therefore,
\begin{align}
\label{eqn:a_dp}
    \dd \mat{P} = \Big( \mat{C}\mat{\Sigma}_d^{-1} ~|~ -\mat{P_1}\mat{\Sigma}_d^{-1}\mat{C}^{\top}\mat{P_2}\Big) ,~\mat{C} = \dd \mat{F} \mat{Q} - \mat{P} \dd \mat{\Sigma} - \mat{P}\mat{\Sigma}\dd \mat{Q}^{\top}\mat{Q}
\end{align}
and we have
\begin{align}
    \nabla_{\mat{F}}:\dd\mat{F} = \nabla_{\mat{P}}:\dd\mat{P} + \nabla_{\mat{\Sigma}}:\dd\mat{\Sigma} + \nabla_{\mat{Q}}:\dd\mat{Q}
\end{align}
As we only consider the basis of subspace $\mat{P}$ in the computation of subspace distillation loss, therefore
\begin{align}
\label{eqn:a_dldx1}
    \nabla_{\mat{F}}:\dd\mat{F} = \nabla_{\mat{P}}:\dd\mat{P}
\end{align}

we simplify $\nabla_{\mat{P}}:\dd\mat{P}$ as follows
\begin{align}
    \label{eqn:svd_diff_d_}
    \nabla_{\mat{P}}:\dd\mat{P} = \Big(\nabla_{\mat{P}}\Big)_{1}:\mat{C}\mat{\Sigma}_d^{-1} + \Big(\nabla_{\mat{P}}\Big)_{2}:-\mat{P_1}\mat{\Sigma}_d^{-1}\mat{C}^{\top}\mat{P_2}
\end{align}
As we consider top $d$ subspace in the computation of subspace distillation loss, therefore $\Big(\nabla_{\mat{P}}\Big)_{2}$ is zero. Consequently
\begin{align}
    \label{eqn:a_svd_diff_d}
    \begin{split}
    \nabla_{\mat{P}}:\dd\mat{P} & = \Big(\nabla_{\mat{P}}\Big)_{1}\mat{\Sigma}_d^{-1}:\mat{C} \\
    & = \underbrace{\Big(\nabla_{\mat{P}}\Big)_{1}\mat{\Sigma}_d^{-1}}_{\mat{D}} : \Big( \dd \mat{F} \mat{Q} - \mat{P} \dd \mat{\Sigma} - \mat{P}\mat{\Sigma}\dd \mat{Q}^{\top}\mat{Q} \Big)  \\
    & = \mat{D}:\dd \mat{F} \mat{Q} ~-~ \mat{D}:\mat{P} \dd \mat{\Sigma} ~-~ \mat{D}:\mat{P}\mat{\Sigma}\dd \mat{Q}^{\top}\mat{Q} ,~ \mat{D}=\Big(\nabla_{\mat{P}}\Big)_{1}\mat{\Sigma}_d^{-1}\\
    & = \mat{D}\mat{Q}^{\top}: \dd \mat{F} ~-~ \mat{P}^{\top}\mat{D}: \dd \mat{\Sigma}~-~ \mat{\Sigma}\mat{P}^{\top}\mat{D}\mat{Q}^{\top}:\dd \mat{Q}^{\top} \\
    & = \mat{D}\mat{Q}^{\top}:\dd \mat{F} ~-~ \mat{P}^{\top}\mat{D}: \dd \mat{\Sigma} ~-~ \mat{Q}\mat{D}^{\top}\mat{P}\mat{\Sigma}:\dd \mat{Q} \\
    & = \mat{D}\mat{Q}^{\top}:\dd \mat{F} ~-~ \mat{P}^{\top}\mat{D}: \Big(\mat{P}^{\top}\dd\mat{P}\mat{Q}\Big)_{\text{diag}} ~-~ \mat{Q}\mat{D}^{\top}\mat{P}\mat{\Sigma}:2\mat{Q}~\Biggl(\mat{K}^{\top} \circ \Big(\mat{\Sigma}^{\top}\mat{P}^{\top}\dd\mat{P}\mat{Q}\Big)_{\text{sym}}~\Biggl) \\
    & = \mat{D}\mat{Q}^{\top}:\dd \mat{F} ~-~ \Big(\mat{P}^{\top}\mat{D}\Big)_{\text{diag}}: \mat{P}^{\top}\dd\mat{P}\mat{Q} ~-~ 2\mat{Q}^{\top}\mat{Q}\mat{D}^{\top}\mat{P}\mat{\Sigma}:~\Biggl(\mat{K}^{\top} \circ \Big(\mat{\Sigma}^{\top}\mat{P}^{\top}\dd\mat{P}\mat{Q}\Big)_{\text{sym}}~\Biggl) \\
    & = \mat{D}\mat{Q}^{\top}:\dd \mat{F} ~-~ \mat{P}\Big(\mat{P}^{\top}\mat{D}\Big)_{\text{diag}}\mat{Q}^{\top}: \dd\mat{P} ~-~ 2\Big(\mat{K}^{\top} \circ \mat{D}^{\top}\mat{P}\mat{\Sigma}\Big)_{\text{sym}}:~ \Big(\mat{\Sigma}^{\top}\mat{P}^{\top}\dd\mat{P}\mat{Q}\Big)\\
    & = \mat{D}\mat{Q}^{\top}:\dd \mat{F} ~-~ \mat{P}\Big(\mat{P}^{\top}\mat{D}\Big)_{\text{diag}}\mat{Q}^{\top}: \dd\mat{P} ~-~ 2\mat{P}\mat{\Sigma}\Big(\mat{K}^{\top} \circ \mat{D}^{\top}\mat{P}\mat{\Sigma}\Big)_{\text{sym}}\mat{Q}^{\top}: \dd\mat{P}
    \end{split}
\end{align}
Finally by using Eq.~\ref{eqn:a_svd_diff_d} in Eq.~\ref{eqn:a_dldx1}, we have
\begin{align}
\label{eqn:a_dldx2}
    \nabla_{\mat{F}} = \mat{D}\mat{Q}^{\top} ~-~ \mat{P}\Big(\mat{P}^{\top}\mat{D}\Big)_{\text{diag}}\mat{Q}^{\top} ~-~ 2\mat{P}\mat{\Sigma}\Big(\mat{K}^{\top} \circ \mat{D}^{\top}\mat{P}\mat{\Sigma}\Big)_{\text{sym}}\mat{Q}^{\top}
\end{align}

\section{Notation and Properties}
The following notations have been used in the derivation
\begin{itemize}
    \item Symmetric part of a square matrix $\mat{A}$, $\mat{A}_{\text{sym}} = \dfrac{1}{2}\Big(\mat{A}^{\top} + \mat{A}\Big)$
    \item $\mat{A}_{\text{diag}}$ be $\mat{A}$ with all off-diagonal elements set to $0$.
    \item Element-wise product $\mat{A} \circ \mat{B}$
    \item Colon product $\mat{A}:\mat{B}=Tr(\mat{A}^{\top}\mat{B})$
    \item The following properties of inner product also have been used
    \begin{align}
        \mat{A}:\mat{B}\mat{C} = \mat{A}\mat{C}^{\top}:\mat{B} = \mat{B}^{\top}\mat{A}:\mat{C}\\
        \mat{A}:\mat{B}\circ\mat{C} = \mat{B}\circ\mat{A}:\mat{C} \\
        \mat{A}:\mat{B}_{\text{sym}} = \mat{A}_{\text{sym}}:\mat{B} \\
        \mat{A}:\mat{B}_{\text{diag}} = \mat{A}_{\text{diag}}:\mat{B}
    \end{align}

\end{itemize}

\vspace{7ex}
\section{Hyperparameter}

\subsection{Class-Incremental Learning}

\begin{table*}[htbp]
\centering
\resizebox{.9\textwidth}{!}{\begin{tabular}{ccccccc}
\hline
\multirow{2}{*}{Method} & \multicolumn{2}{c}{S-MNIST} & \multicolumn{2}{c}{S-CIFAR-10} & \multicolumn{2}{c}{S-Tiny Imagenet} \\ \cline{2-7} 
      & Task-IL           & Class-IL          & Task-IL       & Class-IL      & Task-IL          & Class-IL          \\ \hline
    & \multicolumn{5}{c}{Online Data Stream Setting with Tiny Memory (Buffer Size: 100)} & \\ \cline{2-6}
SD           & lr: .01, $\alpha: 8$~, $\beta: .4$     &  lr: .01, $\alpha: 10$~, $\beta: .5$  & lr:.03 , $\alpha:.5 $~, $\beta:.75 $ & lr:.03 , $\alpha:.5 $~, $\beta:.5 $  &  lr: .03, $\alpha: 1$~, $\beta: .25$                 &   lr: .03, $\alpha: 1$~, $\beta: .25$                \\

                        \hline
    &  \multicolumn{5}{c}{Small Memory  (Buffer Size: 200)} & \\ \cline{2-6}
SD           & lr: .03, $\alpha: 4$~, $\beta: .4$     &  lr: .03, $\alpha: 4$~, $\beta: .4$    & lr:.03 , $\alpha:.4 $~, $\beta:.4 $ & lr:.03 , $\alpha:.4 $~, $\beta:.4 $ &  lr: .03, $\alpha: .1$~, $\beta: .1$                 &   lr: .03, $\alpha: .1$~, $\beta: .1$                 \\
                        \hline
    &  \multicolumn{5}{c}{Medium Memory  (Buffer Size: 500)} & \\ \cline{2-6}

SD           & lr: .1, $\alpha: 1$~, $\beta: .1$    &  lr: .1, $\alpha: 1$~, $\beta: .1$    & lr:.03 , $\alpha:1 $~, $\beta:1 $ & lr:.03 , $\alpha:1 $~, $\beta:1 $ &  lr: .03, $\alpha: .1$~, $\beta: .1$        &   lr: .03, $\alpha: .1$~, $\beta: .1$                \\

                        \hline
    &  \multicolumn{5}{c}{Large Memory  (Buffer Size: 5120)} & \\ \cline{2-6}
SD           & lr: .1, $\alpha: 1$~, $\beta: 2$      &  lr: .1, $\alpha: 1$~, $\beta: 2$     & lr:.03 , $\alpha:1 $~, $\beta:2 $  & lr:.03 , $\alpha:1 $~, $\beta:2 $  &  lr:.03, $\alpha:1$, ~$\beta:2.5 $   &  lr:.03, $\alpha:1$, ~$\beta:2.5 $                  \\
\hline
\end{tabular}}
\caption{\label{tab:hyperparam}Hyperparameter selected for SD method for class-incremental classification.
}
\end{table*}

\vspace{-.2cm}
\subsection{Continual Semantic Segmentation}

\begin{table*}[htbp]
\centering
\begin{tabular}{c|cc|cc|cc}
\hline
Method & \multicolumn{2}{c|}{19-1 (2-Tasks)} & \multicolumn{2}{c|}{15-5 (2-Tasks)} & \multicolumn{2}{c}{15-1 (5-Tasks)} \\ \hline
SD           & \multicolumn{2}{c|}{lr: .001, $\alpha: 10$~, $\beta: .01$ }    &  \multicolumn{2}{c|}{lr: .001, $\alpha: 10$~, $\beta: .01$ } & \multicolumn{2}{c}{lr:.001 , $\alpha:10 $~, $\beta:.01 $ }              \\
                        \hline
\end{tabular}
\caption{\label{tab:hyperparam}Hyperparameter selected for SD method for Continual Semantic Segmentation.
}
\end{table*}
