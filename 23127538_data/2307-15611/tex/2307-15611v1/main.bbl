% Generated by IEEEtran.bst, version: 1.14 (2015/08/26)
\begin{thebibliography}{10}
\providecommand{\url}[1]{#1}
\csname url@samestyle\endcsname
\providecommand{\newblock}{\relax}
\providecommand{\bibinfo}[2]{#2}
\providecommand{\BIBentrySTDinterwordspacing}{\spaceskip=0pt\relax}
\providecommand{\BIBentryALTinterwordstretchfactor}{4}
\providecommand{\BIBentryALTinterwordspacing}{\spaceskip=\fontdimen2\font plus
\BIBentryALTinterwordstretchfactor\fontdimen3\font minus
  \fontdimen4\font\relax}
\providecommand{\BIBforeignlanguage}[2]{{%
\expandafter\ifx\csname l@#1\endcsname\relax
\typeout{** WARNING: IEEEtran.bst: No hyphenation pattern has been}%
\typeout{** loaded for the language `#1'. Using the pattern for}%
\typeout{** the default language instead.}%
\else
\language=\csname l@#1\endcsname
\fi
#2}}
\providecommand{\BIBdecl}{\relax}
\BIBdecl

\bibitem{mohamed2020concealnet}
M.~M. Mohamed and B.~W. Schuller, ``Concealnet: An end-to-end neural network
  for packet loss concealment in deep speech emotion recognition,'' \emph{arXiv
  preprint arXiv:2005.07777}, 2020.

\bibitem{adler2011audio}
A.~Adler, V.~Emiya, M.~G. Jafari, M.~Elad, R.~Gribonval, and M.~D. Plumbley,
  ``Audio inpainting,'' \emph{IEEE Transactions on Audio, Speech, and Language
  Processing}, vol.~20, no.~3, pp. 922--932, 2011.

\bibitem{mokry2020audio}
O.~Mokr{\`y} and P.~Rajmic, ``Audio inpainting: Revisited and reweighted,''
  \emph{IEEE/ACM Transactions on Audio, Speech, and Language Processing},
  vol.~28, pp. 2906--2918, 2020.

\bibitem{lagrange2005long}
M.~Lagrange, S.~Marchand, and J.-B. Rault, ``Long interpolation of audio
  signals using linear prediction in sinusoidal modeling,'' \emph{Journal of
  the Audio Engineering Society}, vol.~53, no.~10, pp. 891--905, 2005.

\bibitem{maher1994method}
R.~C. Maher, ``A method for extrapolation of missing digital audio data,''
  \emph{Journal of the Audio Engineering Society}, vol.~42, no.~5, pp.
  350--357, 1994.

\bibitem{chua2006qos}
T.-K. Chua and D.~C. Pheanis, ``Qos evaluation of sender-based loss-recovery
  techniques for voip,'' \emph{IEEE Network}, vol.~20, no.~6, pp. 14--22, 2006.

\bibitem{marafioti2019context}
A.~Marafioti, N.~Perraudin, N.~Holighaus, and P.~Majdak, ``A context encoder
  for audio inpainting,'' \emph{IEEE/ACM Transactions on Audio, Speech, and
  Language Processing}, vol.~27, no.~12, pp. 2362--2372, 2019.

\bibitem{lee2015packet}
B.-K. Lee and J.-H. Chang, ``Packet loss concealment based on deep neural
  networks for digital speech transmission,'' \emph{IEEE/ACM Transactions on
  Audio, Speech, and Language Processing}, vol.~24, no.~2, pp. 378--387, 2015.

\bibitem{lotfidereshgi2018speech}
R.~Lotfidereshgi and P.~Gournay, ``Speech prediction using an adaptive
  recurrent neural network with application to packet loss concealment,'' in
  \emph{2018 IEEE International Conference on Acoustics, Speech and Signal
  Processing (ICASSP)}.\hskip 1em plus 0.5em minus 0.4em\relax IEEE, 2018, pp.
  5394--5398.

\bibitem{chang2019deep}
Y.-L. Chang, K.-Y. Lee, P.-Y. Wu, H.-y. Lee, and W.~Hsu, ``Deep long audio
  inpainting,'' \emph{arXiv preprint arXiv:1911.06476}, 2019.

\bibitem{kegler2019deep}
M.~Kegler, P.~Beckmann, and M.~Cernak, ``{Deep Speech Inpainting of
  Time-Frequency Masks},'' in \emph{Proc. Interspeech 2020}, 2020, pp.
  3276--3280.

\bibitem{wang2021temporal}
J.~Wang, Y.~Guan, C.~Zheng, R.~Peng, and X.~Li, ``A temporal-spectral
  generative adversarial network based end-to-end packet loss concealment for
  wideband speech transmission,'' \emph{The Journal of the Acoustical Society
  of America}, vol. 150, no.~4, pp. 2577--2588, 2021.

\bibitem{ebner2020audio}
P.~P. Ebner and A.~Eltelt, ``Audio inpainting with generative adversarial
  network,'' \emph{arXiv preprint arXiv:2003.07704}, 2020.

\bibitem{isola2017image}
P.~Isola, J.-Y. Zhu, T.~Zhou, and A.~A. Efros, ``Image-to-image translation
  with conditional adversarial networks,'' in \emph{Proceedings of the IEEE
  conference on computer vision and pattern recognition}, 2017, pp. 1125--1134.

\bibitem{goodfellow2020generative}
I.~Goodfellow, J.~Pouget-Abadie, M.~Mirza, B.~Xu, D.~Warde-Farley, S.~Ozair,
  A.~Courville, and Y.~Bengio, ``Generative adversarial networks,''
  \emph{Communications of the ACM}, vol.~63, no.~11, pp. 139--144, 2020.

\bibitem{donahue2019wavegan}
C.~Donahue, J.~McAuley, and M.~Puckette, ``Adversarial audio synthesis,'' in
  \emph{7th International Conference on Learning Representations, {ICLR} 2019,
  New Orleans, LA, USA, May 6-9, 2019}, 2019.

\bibitem{lee2018conditional}
C.~Y. Lee, A.~Toffy, G.~J. Jung, and W.-J. Han, ``Conditional wavegan,''
  \emph{arXiv preprint arXiv:1809.10636}, 2018.

\bibitem{yamamoto2020parallel}
R.~Yamamoto, E.~Song, and J.-M. Kim, ``Parallel wavegan: A fast waveform
  generation model based on generative adversarial networks with
  multi-resolution spectrogram,'' in \emph{2020 IEEE International Conference
  on Acoustics, Speech and Signal Processing (ICASSP)}, 2020, pp. 6199--6203.

\bibitem{kumar2019melgan}
K.~Kumar, R.~Kumar, T.~De~Boissiere, L.~Gestin, W.~Z. Teoh, J.~Sotelo,
  A.~de~Br{\'e}bisson, Y.~Bengio, and A.~C. Courville, ``Melgan: Generative
  adversarial networks for conditional waveform synthesis,'' \emph{Advances in
  neural information processing systems}, vol.~32, 2019.

\bibitem{yang2020vocgan}
J.~Yang, J.~Lee, Y.~Kim, H.-Y. Cho, and I.~Kim, ``{VocGAN: A High-Fidelity
  Real-Time Vocoder with a Hierarchically-Nested Adversarial Network},'' in
  \emph{Proc. Interspeech 2020}, 2020, pp. 200--204.

\bibitem{palkama2020conditional}
K.~Palkama, L.~Juvela, and A.~Ilin, ``{Conditional Spoken Digit Generation with
  StyleGAN},'' in \emph{Proc. Interspeech 2020}, 2020, pp. 3166--3170.

\bibitem{mirza2014conditional}
M.~Mirza and S.~Osindero, ``Conditional generative adversarial nets,''
  \emph{arXiv preprint arXiv:1411.1784}, 2014.

\bibitem{miyato2018cgans}
T.~Miyato and M.~Koyama, ``c{GAN}s with projection discriminator,'' in
  \emph{International Conference on Learning Representations}, 2018.

\bibitem{ronneberger2015u}
O.~Ronneberger, P.~Fischer, and T.~Brox, ``U-net: Convolutional networks for
  biomedical image segmentation,'' in \emph{Medical Image Computing and
  Computer-Assisted Intervention--MICCAI 2015: 18th International Conference,
  Munich, Germany, October 5-9, 2015, Proceedings, Part III 18}.\hskip 1em plus
  0.5em minus 0.4em\relax Springer, 2015, pp. 234--241.

\bibitem{griffin1984signal}
D.~Griffin and J.~Lim, ``Signal estimation from modified short-time fourier
  transform,'' \emph{IEEE Transactions on acoustics, speech, and signal
  processing}, vol.~32, no.~2, pp. 236--243, 1984.

\bibitem{arik2018fast}
S.~{\"O}. Ar{\i}k, H.~Jun, and G.~Diamos, ``Fast spectrogram inversion using
  multi-head convolutional neural networks,'' \emph{IEEE Signal Processing
  Letters}, vol.~26, no.~1, pp. 94--98, 2018.

\bibitem{goodfellow2016nips}
I.~Goodfellow, ``Nips 2016 tutorial: Generative adversarial networks,''
  \emph{arXiv preprint arXiv:1701.00160}, 2016.

\bibitem{kingma2014adam}
D.~P. Kingma and J.~Ba, ``Adam: A method for stochastic optimization,'' in
  \emph{3rd International Conference on Learning Representations, {ICLR} 2015,
  San Diego, CA, USA, May 7-9, 2015, Conference Track Proceedings}, 2015.

\bibitem{yamagishi2019vctk}
J.~Yamagishi, C.~Veaux, and K.~MacDonald, ``{CSTR VCTK Corpus}: English
  multi-speaker corpus for {CSTR} voice cloning toolkit (version 0.92),'' 2019.

\bibitem{valin2016high}
J.-M. Valin, G.~Maxwell, T.~B. Terriberry, and K.~Vos, ``High-quality,
  low-delay music coding in the opus codec,'' in \emph{135th AES Convention,
  October 17–20 2013, New York, USA}, 2013.

\bibitem{blum2021webrtc}
N.~Blum, S.~Lachapelle, and H.~Alvestrand, ``Webrtc: Real-time communication
  for the open web platform,'' \emph{Commun. ACM}, p. 50–54, jul 2021.

\bibitem{lecomte2015evs}
J.~Lecomte, T.~Vaillancourt, S.~Bruhn, H.~Sung, K.~Peng, K.~Kikuiri, B.~Wang,
  S.~Subasingha, and J.~Faure, ``Packet-loss concealment technology advances in
  evs,'' in \emph{2015 IEEE International Conference on Acoustics, Speech and
  Signal Processing (ICASSP)}, 2015, pp. 5708--5712.

\bibitem{liu2022plcnet}
B.~Liu, Q.~Song, M.~Yang, W.~Yuan, and T.~Wang, ``Plcnet: Real-time packet loss
  concealment with semi-supervised generative adversarial network,''
  \emph{Proc. Interspeech 2022}, pp. 575--579, 2022.

\bibitem{pascual2021adversarial}
S.~Pascual, J.~Serr{\`a}, and J.~Pons, ``Adversarial auto-encoding for packet
  loss concealment,'' in \emph{2021 IEEE Workshop on Applications of Signal
  Processing to Audio and Acoustics (WASPAA)}.\hskip 1em plus 0.5em minus
  0.4em\relax IEEE, 2021, pp. 71--75.

\bibitem{recommendation2001perceptual}
I.-T. Recommendation, ``Perceptual evaluation of speech quality (pesq): An
  objective method for end-to-end speech quality assessment of narrow-band
  telephone networks and speech codecs,'' \emph{Rec. ITU-T P. 862}, 2001.

\bibitem{taal2010short}
C.~H. Taal, R.~C. Hendriks, R.~Heusdens, and J.~Jensen, ``A short-time
  objective intelligibility measure for time-frequency weighted noisy speech,''
  in \emph{2010 IEEE international conference on acoustics, speech and signal
  processing}.\hskip 1em plus 0.5em minus 0.4em\relax IEEE, 2010, pp.
  4214--4217.

\bibitem{miao_wang_2022_6549559}
\BIBentryALTinterwordspacing
M.~Wang, C.~Boeddeker, R.~G.~Dantas, and A.~Seelan, ``Pesq (perceptual
  evaluation of speech quality) wrapper for python users,'' May 2022. [Online].
  Available: \url{https://doi.org/10.5281/zenodo.6549559}
\BIBentrySTDinterwordspacing

\bibitem{mpariente2018pystoi}
\BIBentryALTinterwordspacing
M.~Pariente, ``Pystoi, python implementation of stoi,'' 2018. [Online].
  Available: \url{https://github.com/mpariente/pystoi}
\BIBentrySTDinterwordspacing

\end{thebibliography}
