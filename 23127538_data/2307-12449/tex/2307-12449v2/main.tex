\documentclass{sig-alternate}

\usepackage{mathptmx} % This is Times font
\usepackage{amsmath,amsfonts}
\usepackage{algorithmic}
\usepackage{algorithm}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage{booktabs} 
\usepackage{soul}
\graphicspath{{figs/}}
\usepackage{braket}
\usepackage{etoolbox}
\usepackage{subcaption}
\usepackage{fancyhdr}
\usepackage[normalem]{ulem}
\usepackage[hyphens]{url}
\usepackage[sort,nocompress]{cite}
\usepackage[final]{microtype}
\usepackage[keeplastbox]{flushend}
% Always include hyperref last
\usepackage[bookmarks=true,breaklinks=true,letterpaper=true,colorlinks,citecolor=blue,linkcolor=blue,urlcolor=blue]{hyperref}

% Ensure letter paper
\pdfpagewidth=8.5in
\pdfpageheight=11in

%%%%%%%%%%%---SETME-----%%%%%%%%%%%%%
\newcommand{\microsubmissionnumber}{1962}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% \fancypagestyle{firstpage}{
%   \fancyhf{}
%   \renewcommand{\headrulewidth}{0pt}
%   \fancyhead[C]{\vspace{10pt}\normalsize{MICRO 2023 Submission
%       \textbf{\#\microsubmissionnumber} -- Confidential Draft -- Do NOT Distribute!!}\\\vspace{-25pt}} 
%   \fancyfoot[C]{\thepage}
% }

\pagenumbering{arabic}

%%%%%%%%%%%---SETME-----%%%%%%%%%%%%%
\title{WEPRO: Weight Prediction for Efficient Optimization of Hybrid Quantum-Classical Algorithms \vspace{-10mm}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}

\author{%
Satwik Kundu\\
  \affaddr{Pennsylvania State University}\\
  \affaddr{University Park, PA, USA}\\
  \email{satwik@psu.edu}
\and
Debarshi Kundu\\
  \affaddr{Pennsylvania State University}\\
  \affaddr{University Park, PA, USA}\\
  \email{dqk5620@psu.edu}
\and
Swaroop Ghosh\\
  \affaddr{Pennsylvania State University}\\
  \affaddr{University Park, PA, USA}\\
  \email{szg212@psu.edu}
}



\maketitle

\maketitle
%\thispagestyle{firstpage}
\pagestyle{plain}



%%%%%% -- PAPER CONTENT STARTS-- %%%%%%%%
\begin{abstract}
\vspace{-4mm}
%\hl{New!}\hl{
The exponential run time of quantum simulators on classical machines and long queue depths and high costs of real quantum devices present significant challenges in the effective training of Variational Quantum Algorithms (VQAs) like Quantum Neural Networks (QNNs), Variational Quantum Eigensolver (VQE) and Quantum Approximate Optimization Algorithm (QAOA). To address these limitations, we propose a new approach, WEPRO (Weight Prediction), which accelerates the convergence of VQAs by exploiting regular trends in the parameter weights. We introduce two techniques for optimal prediction performance namely, Naive Prediction (NaP) and Adaptive Prediction (AdaP). Through extensive experimentation and training of multiple QNN models on various datasets, we demonstrate that WEPRO offers a speedup of approximately $2.25\times$ compared to standard training methods, while also providing improved accuracy (up to $2.3\%$ higher) and loss (up to $6.1\%$ lower) with low storage and computational overheads. We also evaluate WEPRO's effectiveness in VQE for molecular ground-state energy estimation and in QAOA for graph MaxCut. Our results show that WEPRO leads to speed improvements of up to $3.1\times$ for VQE and $2.91\times$ for QAOA, compared to traditional optimization techniques, while using up to $3.3\times$ less number of shots (i.e., repeated circuit executions) per training iteration. 
%However, this speed improvement comes at the cost of increased space and time complexity. Nevertheless, our work provides a promising solution for accelerating the parameter optimization process of VQA circuits, enabling more efficient use of quantum computing resources and the ability to tackle larger and more complex problems.


\end{abstract}

\section{Introduction}\label{introduction}

Hybrid quantum-classical algorithms, also known as VQAs, are widely regarded as the most promising application to attain quantum advantage in Noisy Intermediate-Scale Quantum (NISQ) era. One of the key drivers for this belief is that theoretically, VQAs have been found to have the ability to model complex systems that classical algorithms have difficulty simulating \cite{schuld2020circuit}. However, this has been hard to realize in modern-day NISQ-era computers due to many challenges such as, limited number of qubits and significant amounts of quantum noise (e.g., gate error, decoherence error, readout error, and crosstalk error). On top of that, real quantum devices are expensive, and slow (especially due to long queue depths), and access to them is quite limited obstructing the training of VQA circuits.

VQAs are a class of quantum algorithms that employ a hybrid quantum-classical approach to address a wide range of problems such as optimization, determination of the ground state energy of molecules, and machine learning tasks such as classification. Thus, VQAs are often considered the quantum counterparts of highly effective machine learning techniques, like neural networks, which have achieved great success in the classical domain \cite{cerezo2021variational}.
To provide an approximate solution to a problem, most current VQAs employ a variational ansatz, also known as a Parameterized Quantum Circuit (PQC) which is made up of trainable parameters that are generally tuned over time using a classical optimizer to achieve the desired output. Quantum Neural Networks (QNN) can also be thought of as VQAs since they use a variational ansatz to solve optimization/classification problems. QNNs use PQC as the primary tunable block, the parameters of which are updated to perform the prediction task. PQC is typically made up of several 1-qubit and 2-qubit gates that are used to entangle the qubits and explore the search space.

\subsection{Motivation}
\textbf{Cost of solving the problem:} Executing VQAs with larger circuits involving more qubits and parameters on real quantum devices can be rather expensive. This is because large-scale quantum circuits require costly quantum computing resources and longer convergence times. As a result, more circuit executions, or shots, are needed to achieve the optimal solution. Shots refer to the number of repetitions of a quantum circuit measurement to obtain a probability distribution of outcomes. The expense of employing high-quality quantum machines is directly proportional to the number of shots taken. For example, cloud services like Amazon's Braket \cite{AmazonBraketPricing} provide users easy access to real quantum machines, but they charge for both the number of circuit executions and shots used. Consequently, the cost of larger quantum circuits that require more shots to reach the optimal solution, increases. Acceleration of the optimization process of VQAs can decrease the number of total circuit runs needed, ultimately reducing the overall cost of utilizing high-quality quantum devices for solving a problem \cite{gu2021adaptive, phalak2023shot}.

\textbf{Time required to solve the problem:} In \cite{wang2022qoc}, the authors provided the first practical demonstration of training a PQC on real quantum hardware devices using the parameter shift rule. However, it took 2-5 days to train a relatively simple 4-qubit circuit on the quantum machine. Therefore, many researchers prefer quantum simulators to test new ideas and quantum algorithms (with a small number of qubits) as the simulators can easily run on classical computers. Nevertheless, even if a QNN is trained on a simulator, the training time would still be significantly higher compared to a Deep Neural Network (DNN) with 100 times more parameters than the QNN. This is primarily due to the fact that quantum simulators require the simulation of the quantum state, which grows exponentially with the number of qubits. 
%Therefore, quantum simulators are computationally expensive worsening the training time of QML models. %, even for classical computers. 
As a result, there is a need to speed up the training of large QML models (on real quantum devices or quantum simulators) for
%since shorter training times can lead to a lesser accumulation of errors and ultimately a more accurate model when trained on real/noisy devices and would also 
%enable faster evaluation of very large models required 
practically relevant applications like drug discovery \cite{li2021drug}. 

Furthermore, parameter optimization for corresponding variational ansatz or PQCs is challenging in VQAs due to the large number of measurements required for the accurate estimation of observable mean values. This high sampling rate can cause a bottleneck in the algorithm runtime. Therefore, it is necessary to minimize the number of measurements or function evaluations needed to improve the efficiency of parameter optimization for PQCs. In most of the VQAs, quantum circuits are used in combination with classical computation to solve problems and possibly demonstrate quantum advantage. Since these algorithms generally involve performing multiple iterations of quantum circuit parameter optimization, it can hinder the overall performance of the algorithm \cite{bharti2022noisy}. As a result, accelerating the parameter optimization process is crucial for achieving better performance in these hybrid algorithms.

% Figure environment removed

\subsection{Proposed Approach}
\textbf{Basic idea:} In this work, we present weight prediction to accelerate the convergence of VQAs. WEPRO involves fitting a non-linear model with a set of previously calculated parameter weights and using it to predict the weight of the parameters for future epochs, which are then updated at regular intervals. This approach enables WEPRO to reach the optimal parameters much faster than traditional methodologies, with minimal overhead. A visual representation of WEPRO is provided in Fig. \ref{idea}. 

\textbf{Relevance to quantum computing:} WEPRO is particularly well-suited for VQAs compared to classical models such as DNNs. This is because practically useful DNNs often have billions, if not trillions \cite{openai2023gpt} of parameters, and storing and predicting parameters at regular intervals might greatly increase both the space and time complexity, potentially eliminating the possibility of actual speedup. In contrast, QNNs are known to have superior entanglement capability and effective dimensions \cite{schuld2021effect, abbas2021power, schuld2020circuit} compared to DNNs, requiring only a fraction of parameters e.g., 400 instead of 20k \cite{li2021quantum} to solve any required problem. Entanglement enables quantum models to manipulate data in more complex ways, and a higher effective dimension allows quantum models to represent more complex data. Thus, QNNs, even large ones that are expected for practically relevant applications employing future large-scale quantum hardware, can effectively learn and generalize from smaller amounts of data with significantly fewer trainable parameters than DNNs \cite{schuld2021effect, caro2022generalization}.

Furthermore, for quantum circuits, gradient computations like the parameter shift rule are costly, necessitating $2 \cdot n$ circuit executions per step for all parameter's gradient, where $n$ is the total parameter count. WEPRO circumvents gradient needs, updating parameters using prior weights. This leads to a substantial decrease in total circuit executions, enhancing WEPRO's cost-effectiveness and quantum resource efficiency.

\textit{To our knowledge, this is the first work that introduces parameter prediction to accelerate the convergence of VQAs.}

The paper is organized into the following sections: Section \ref{background} provides an introduction to quantum computing, QNN, VQE, and QAOA; Section \ref{methodology} delves into the proposed WEPRO methodology and its underlying principles; Section \ref{evaluation} outlines the evaluation strategies used and discusses the obtained results; Section \ref{discussion} explores potential use cases and addresses the limitations of WEPRO; and finally, Section \ref{conclusion} presents our closing remarks and summarizes the key findings.

% Figure environment removed

\section{Background} \label{background}

\subsection{Basics of Quantum Computing} 
A quantum bit or qubit is a fundamental building block of quantum computers.
%and is usually driven by microwave or laser pulses for superconducting and trapped-ion qubits, respectively. 
Unlike a classical bit, a qubit can be in a superposition state, which is a combination of states $\ket{0}$ and $\ket{1}$ at the same time. Mathematically, a qubit state is represented by a two-dimensional column vector $[\alpha \; \beta]$ where $|\alpha|^2$ and $|\beta|^2$ represent probabilities that the qubit is in state `0' and `1', respectively. 
Quantum gates are operations that change the state of qubits, allowing them to perform computations. Mathematically, they can be represented using unitary matrices 
%(e.g. Pauli-Z gate is represented as $\begin{bmatrix} 1 & 0 \\ 0 & -1 \end{bmatrix}$). 
There are mainly two types of quantum gates: 1-qubit (like H, X gates) and 2-qubit (like CNOT, CRY gates). Complex 3-qubit gates like Toffoli gates are eventually broken down into 1-qubit and 2-qubit gates during the compilation process.
Qubits are measured on a desired basis to determine the final state of a quantum program. Measurements in physical quantum computers are typically restricted to a computational basis, such as the Z-basis in IBM quantum computers. 
Due to the high error rate of quantum computers, obtaining an accurate output after measuring just once is unlikely. Consequently, quantum circuits are measured multiple times ($n$), and the most probable outcomes from these measurements are then considered as the final output(s). This measurement frequency $n$ is known as \textit{shots}.

\subsection{Quantum Neural Network (QNN)} 
%QNN entails optimizing the parameters of a Parametric Quantum Circuit (PQC) to achieve the desired input-output relationship. 
QNN consists of three building blocks: (i) a classical to quantum data encoding (or embedding) circuit, (ii) a parameterized quantum circuit (PQC) whose parameters can be tuned (mostly by an optimizer) to perform the desired task, and (iii) measurement operations. There are a number of different encoding techniques available (basis encoding, amplitude encoding, etc.) but for continuous variables, the most widely used encoding scheme is angle encoding where a variable input classical feature is encoded as a rotation of a qubit along the desired axis \cite{abbas2021power}. As the states produced by a qubit rotation along any axis will repeat in 2$\pi$ intervals, features are generally scaled within 0 to 2$\pi$ (or -$\pi$ to $\pi$) in a data pre-processing step. In this study, we used $RZ$ gates to encode classical features into their quantum states.

A PQC consists of a sequence of quantum gates whose parameters can be varied to solve a given problem. In QNN, the PQC is the primary and only trainable block to recognize patterns in data. The PQC is composed of entangling operations and parameterized single-qubit rotations. The entanglement operations are a set of multi-qubit operations (may or may not be parameterized) performed between all of the qubits to generate correlated states and the parametric single-qubit operations are used to search the solution space. 
Finally, the measurement operation causes the qubit state to collapse to either `0' or `1'. We used the expectation value of Pauli-Z to determine the average state of the qubits. The measured values are then fed into a classical neuron layer (the number of neurons is equal to the number of classes in the dataset) in our hybrid QNN architecture as shown in Fig. \ref{qaoa_hqnn_combined} (a), which performs the final classification task.

\subsection{Variational Quantum Eigensolver (VQE)}
Variational Quantum Eigensolver (VQE) \cite{peruzzo2014variational} is a prominent hybrid algorithm primarily employed for estimating the ground state energy of a quantum system, represented by a Hamiltonian. 
%A Hamiltonian is an observable (depicted by a matrix) associated with the total energy of a system. Its eigenvalues correspond to the different possible energies of the system, with the lowest eigenvalue representing the system's ground state energy. Accurately determining a system's ground state energy is of utmost importance, as it is intrinsically linked to other significant molecular properties such as bond lengths and bond angles. The equilibrium state, characterized by optimal interatomic distances, corresponds to the lowest energy state. Additionally, chemical reaction rates are directly influenced by the ground state energy of molecules. Consequently, VQE holds the potential to drive advancements in fields like drug discovery and material science by offering precise and efficient methods to simulate quantum systems on quantum computers.
Finding the ground state energy of a molecule using a VQE involves the following steps; (1) Find the molecular Hamiltonian using the molecules symbol and the atomic coordinates, (2) Choose a PQC (also known as ansatz) with tunable parameters that approximate the true ground state of the molecule. This PQC is used to produce the trial state, with which the molecular Hamiltonian can be measured, (3) Use a classical optimizer to update the parameters of PQC in order to minimize the expectation value of the Hamiltonian until convergence. Once the optimization converges, the final expectation value of the molecular Hamiltonian represents the approximate ground state energy of the molecule. The objective of the VQE is therefore to find a state $\ket{\psi}$, such that the expectation value of the Hamiltonian is minimized \cite{tilly2022variational}. 

% Figure environment removed

Several PQC (ansatz) architectures are proposed for the VQE process such as Hardware Efficient Ansatz (HEA) \cite{kandala2017hardware}, Hamiltonian Variational Ansatz \cite{wecker2015progress} and Efficient Symmetry Preserving (EPS) ansatz \cite{gard2020efficient}. In this work, we used the Unitary Coupled-Cluster Single and Double (UCCSD) excitation variational ansatz \cite{peruzzo2014variational, romero2018strategies} which is described as a superposition of all possible single and double excitations from a reference state (Hartree-Fock \cite{echenique2007mathematical} state), where a single excitation means that one electron is excited from one spin-orbital to another, and a double excitation means that two electrons are excited simultaneously. Intuitively, these excitation gates take lower energy electrons to be in superposition with higher energy electrons and vice versa. The single and double excitation gates are 2-qubit and 4-qubit gates respectively. 

\subsection{Quantum Approximate Optimization Algorithm (QAOA)}
Quantum Approximate Optimization Algorithm (QAOA) is a promising hybrid algorithm for finding approximate solutions to combinatorial optimization problems \cite{farhi2014quantum, zhou2020quantum}. In general, any combinatorial optimization problem can be formulated as a cost function $C$($z$) defined using $n$ bit strings $z = (z_1, ..., z_n) \in \{\pm 1\}^{n} $ where the goal is to find $z^{*}$ which results in maximum $C(z^{*})$. The main advantage of QAOA is that it is scalable to larger problem sizes and can potentially solve large-scale optimization problems as it scales linearly with the number of qubits used in the circuit, unlike classical optimization algorithms that suffer from exponential scaling. 
%The most common way of solving an optimization problem on a quantum computer is by converting it into a problem of characterizing a Hamiltonian. QAOA uses a quantum circuit to prepare a Hamiltonian state that corresponds to a good approximate solution to the optimization problem. 

A QAOA circuit, shown in Fig. \ref{qaoa_hqnn_combined} (b), is made up of two layers/unitaries called the cost and mixer layers. The cost layer, parameterized by $\gamma$, is a unitary operator ($U_C(\gamma_i) = e^{-i\,\gamma_{i}\,H_{C}}$ where $H_C$ refers to the cost Hamiltonian) that encodes the optimization problem into a quantum circuit. Typically, the cost layer, representing the problem Hamiltonian, is a sum of Pauli-Z operators acting on qubit pairs. This layer promotes the lowest-cost solutions in the optimization problem. The mixer layer, parameterized by $\beta$, is a unitary operator ($U_M(\beta_i) = e^{-i\,\beta_{i}\,H_{M}}$ where $H_M$ refers to the mixer Hamiltonian) that is designed to mix quantum states such that various solutions can be explored. Typically, the mixer layer is a sum of Pauli-X operators acting on each qubit. This mixer layer has been chosen because it preserves the computational basis states, allowing the circuit's output to be easily measured in the computational basis. Thus, if the depth of the circuit is $p$ then the total number of tunable parameters is $2p$ i.e. $\{\gamma_1, ..., \gamma_p\}$ and $\{\beta_1, ..., \beta_p \}$. Even though increasing circuit depth leads to better performance, it also increases the number of gates in the circuit and which makes it more susceptible to noise. Thus, finding the optimal number of layers is a tradeoff between circuit depth and circuit complexity. QAOA can solve several optimization problems like finding the maximum clique, minimum vertex cover, etc. In this work, we used QAOA to solve the graph MaxCut problem. % to compare the efficacy of our methodology to that of the generic optimization technique.

\section{Proposed Methodology} \label{methodology}
\subsection{Overview}

Fig. \ref{pipeline} provides a high-level idea of WEPRO. The general idea behind most of the current variational quantum algorithms is to maximize/minimize some cost function value to get the desired output. The practical implementation entails the following steps: design a quantum circuit that encodes the problem the algorithm is trying to solve with a set of tunable parameters and use a classical optimizer \cite{kingma2014adam, ruder2016overview} to update the circuit's weights/parameters to minimize the cost. Thus, the optimizer gradually modifies (i.e., decreases or increases) each of the parameters based on the initialization and cost function at an instance to achieve the required output. Fig. \ref{weights} shows the evolution of parameter weights as a QNN model is trained. It can be noted that each parameter exhibits a consistent trend at each instance. We exploit this regular trend in parameters to predict the future parameter weights to speed up quantum algorithms convergence.

In order to make any meaningful prediction, we would first need to learn the weight patterns. To do that, in QNN, after training the model for a few epochs, let's say $p$ epochs, we consider weights $\{w_1, w_2,...w_p\}$ ($w_i$ is the parameter weight at epoch $i$) for each of the parameters and use a subset of these weights to fit a curve $f(x)$ (i.e. regression). We use this fitted function to predict a future weight, $w_d = f(d)$ of the parameters ($d$ is the prediction distance, more in Section \ref{pred_distance}). We repeat this prediction process for all the parameters at regular intervals (epochs/iterations) during the training process to accelerate the QNN's training. We define $p$ as the prediction interval i.e., the number of epochs after which we make predictions.

\subsection{Prediction Function}

For predictions, higher-order polynomials are generally effective at approximating complex relationships over a given range of data. Some functions like the exponential functions require a larger sample size to make accurate predictions. Linear functions, on the other hand, are unsuitable since they are incapable of mimicking a curve such as in Fig. \ref{weights}. Since we are predicting at frequent intervals i.e., after every $p = 4/5$ epochs/iterations, using a high-order polynomial would lead to overfitting making the predictions highly inaccurate. Also, theoretically, given a suitable learning rate, it is unlikely that the curve formed by these small datapoints will have a zero slope at more than one point, making a quadratic polynomial an ideal choice. Still, we  adopted an empirical approach and conducted experiments using a linear, cubic, logarithmic, and exponential function as well. They consistently performed worse or slightly better than vanilla method (1.05$\times$ speedup in VQE) while the quadratic polynomial significantly outperformed the vanilla (1.69$\times$ speedup in VQE). Thus, we note that a quadratic function works best, allowing us to make fairly accurate predictions even with a small sample size $p$. As a result, we fit a function of the form:
\[ f(x) = ax^2 + bx + c \]
using weights $[w_2, w_3,.. w_p]$ to get the approximate function coefficients ($a, b, c$) and predict a future weight ($w_d$) using our fitted quadratic function, i.e., $w_d = f(d) = ad^2 + bd + c$, for each parameter. Note that we do not consider the weight $w_1$ and use the remaining $p-1$ weights to fit the curve (discussed in Section \ref{pred_distance}). We define $d$ as the prediction distance. We chose simpler models for weight prediction to minimize space and time complexity, aiming for an optimal balanced between the complexity and accuracy of our method. 

\subsection{Prediction Distance} \label{pred_distance}
The optimal choice of prediction distance ($d$) so that the predicted weight ($w_d$) is close to the actual future weight is quite difficult to find. Inaccurate predictions can lead to large errors. Also, patterns and trends in weight used for prediction might not hold outside our sample range/size ($p$). Therefore, the value of $d$ should be decided carefully. 

The value of $d$ is dependent on several factors; (i) the sample size or the number of data points used to fit the function plays a role in determining the optimal value for $d$. A larger sample size typically allows the function to learn better and make more accurate predictions, which may require a higher value of $d$, although this may not always hold true in practice, (ii) the slope of the fitted curve ($f^{'}(x)$) also affects the choice of $d$. A steeper slope would indicate that the weights are changing rapidly, allowing for larger predictions, while a flatter slope would suggest that the weight is either converging or exhibiting a curvature, and smaller predictions would be more appropriate, (iii) the derivative of the slope, $f^{''}(x)$, is another factor that impacts the value of $d$. A low value of $f^{''}(x)$ would indicate that the slope is changing slowly, allowing for larger predictions, while a high value of $f^{''}(x)$ would suggest that the slope is varying rapidly, and smaller predictions would be more appropriate, (iv) the learning rate also plays a role in determining the optimal value for $d$. A higher learning rate implies taking larger steps towards the optimal value for each weight. In this scenario, it is necessary to use a smaller prediction distance $d$. If the value of $d$ is too large, the model might overshoot the optimal weight, leading to a high loss value, and (v) the point of time for making the prediction. Early on, we can afford to make larger predictions however later on in the training when the weights of the parameters are closer to the minima, we would prefer to make predictions with lower values of $d$ to avoid surpassing the minima.

Thus, it is clear that there are several factors that need to be considered to determine the prediction distance for each parameter at each prediction instance. Here, we formulate two prediction methodologies for WEPRO; (a) Naive Prediction (NaP) which is a mathematically simpler methodology inspired by the concept of learning rate decay where we decay the value of $d$ at each prediction interval, and (b) Adaptive Prediction (AdaP) which is a more robust prediction methodology where we intelligently determine the prediction distance $d$ for each parameter prediction, depending on the slope ($f^{'}(x)$), the derivative of the slope ($f^{''}(x)$) and the initial learning rate ($\alpha$).

% Figure environment removed

\subsection{Naive Prediction (NaP)} \label{nap}
Here, we formulate $d$ such that it has a reasonably large value initially but decreases as the optimizer gradually updates the parameters and moves toward the convergence/minima. A similar idea is followed for learning rates where one of the ways to increase the probability of convergence is by implementing learning rate decay where the learning rate is slowly decayed based on some predefined functions (step, exponential, hyperbolic, etc) or adaptively, depending on the gradient. In NaP, we proposed to dynamically reduce the prediction distance $d$ after every $p$ iteration/epoch as:
\begin{align} \label{eq:1}
    d = r^{(i / p)} \cdot d_0 + (p - 1)
\end{align}
where $r$ is known as the decay rate and set to $r = 0.95$,  $i$ is the current epoch/iteration, $p$ is the prediction interval, and $d_0$ is the initial prediction distance.
In the above formula for $d$, we predict after every $p$ epochs (and not $p-1$) even though we use $p-1$ samples to make the predictions. This is because, if the weights obtained just after prediction are slightly off the optimal weight, it may skew the curve fitting process resulting in an incorrect prediction. Thus, we train the model for an extra epoch to rectify any inaccuracies caused due to prediction, if any, and use the next $p-1$ epoch weights to make the future prediction. Furthermore, 
%we added $(p - 1)$ to the above equation because otherwise 
if we keep on decreasing the prediction distance with epochs, there might be a time when $d$ becomes less than $p - 1$, in which case we would end up predicting some data within our sample set of weights $p - 1$. To avoid this, we added $p-1$ which is a safe lower bound of the prediction distance $d$. A simplified pseudo-code representation of our proposed WEPRO algorithm can be found in Algorithm \ref{algo}.

When working with classical neural network models, we typically need to test models with different hyper-parameters (like learning rate, epochs, etc.) to find the optimal values that will provide the best possible performance. In the above formulation, we define $p$ and $d_0$ as the hyperparameters. The optimal $p$ and $d_0$ would vary depending on the circuit and problem size. However, we provide a safe range of $p$ and $d_0$ as $[(c + 2), 2(c + 2)]$ and $(0, 2p]$, respectively where $c$ is the degree of the polynomial used as the prediction function. The value of $p$ should not be lesser than $c+1$ because, in order to fit a $c$ degree polynomial, we at least need $c + 1$ data points. Here, since we are using $p - 1$ data points for regression, $p - 1 = c + 1$ or, $p = c + 2$. A higher $p$ value may not help in making more accurate predictions, especially when using quadratic polynomials, but it may be useful when using higher-order polynomials. However, a high $d_0$ value will almost certainly result in an erroneous prediction, especially in NaP because we will be using the same prediction distance $d$ for each parameter. Additionally, NaP exhibits sensitivity to the learning rate, meaning that as the learning rate $\alpha$ increases, the value of $d_0$ should decrease. To overcome these issues and make a more intelligent prediction we propose AdaP next.

\begin{algorithm}[!t]
\caption{WEPRO Algorithm}
\label{algo}
\begin{algorithmic}[1] % The number indicates the line numbering frequency.
\STATE \textbf{Function} $P_x(W, p)$
\STATE $f(x, a, b, c) \leftarrow ax^2 + bx + c$, $x_n \leftarrow [1, 2, ..., p]$ \COMMENT{Input and function}
\STATE $W_t \leftarrow W.T$, $N \leftarrow len(W_t)$ \COMMENT{Transpose and length}
\STATE Initialize $W_p[N]$ \COMMENT{Array for weights}
\FOR {$i = 1$ to $N$}
    \STATE $a, b, c$ = fit$(f, x_n, W_t[i])$
    \STATE Find prediction distance $d$ using NaP or AdaP
    \STATE Compute and store the predicted weight:
    \STATE $W_p[i] = f(d, a, b, c)$    
\ENDFOR
\RETURN $W_p$
\end{algorithmic}

\begin{algorithmic}[1]
\REQUIRE Number of epochs $E$ and prediction interval $p$.
\ENSURE Optimized PQC weights $W$
\STATE Initialize weights $W$, for storing epoch weights $W_e$
\FOR{$i = 1$ to $E$}
    \STATE Store model weights: $W_e[i] = W$
    \IF{$i$ \% $p == 0$}
        \STATE Get weights based on the last $p-1$ epoch weights:
        \STATE Compute $P_x(W_e[i - (p - 1):i], p - 1)$ 
        \STATE $W =  P_x(W_e[i - (p - 1):i], p - 1)$ \COMMENT{Update weights}
    \ELSE
        \STATE Update parameter weights $W$ using an optimizer
    \ENDIF
\ENDFOR
\RETURN $W$
\end{algorithmic}
\end{algorithm}


\subsection{Adaptive Prediction (AdaP)} \label{adap}
Unlike NaP where we use the same $d$ when making a prediction for each parameter, in AdaP we adaptively determine the value of $d$ for each parameter. This allows us to make more accurate predictions due to a reduction in the number of incorrect predictions by dynamically determining the optimal prediction distance for each parameter. In Section \ref{pred_distance} we discussed the relationship of $d$ with the slope, the derivative of the slope, and the learning rate. Intuitively, we can understand that the prediction distance $d$ should be directly proportional to the slope $f^{'}(x)$ since a higher value of $f^{'}(x)$ indicates that the weights are rapidly increasing/decreasing, and thus we can afford to make larger predictions i.e. make predictions with a high $d$,  whereas if $f^{'}(x)$ is low then we would want to make safer predictions (i.e., low $d$) since it would mean we are either near a curvature or reaching the convergence value. $f^{''}(x)$ should be inversely proportional to $d$ since a low $f^{''}(x)$ indicates that the slope is not varying much which would allow us to make predictions with high $d$ and vice versa. Similarly, learning rate $\alpha$ should also be inversely proportional to $d$ (Section \ref{pred_distance}). It should be noted that by slope or derivative of the slope, we refer to the slope of the $f(x)$ fitted by $p-1$ previously calculated weights of the parameter and not the slope/gradient with respect to the loss function. 

AdaP uses these three factors ($f^{'}, f^{''}, \alpha$) to adaptively determine the prediction distance for each parameter. We mathematically formulate the above relationship as:
\begin{align*}
    &&d_0 \propto &\frac{|f^{'}(x)|}{|f^{''}(x)| \cdot \alpha}&& \\
or, &&d_0 = k \cdot &\frac{|f^{'}(x)|}{|f^{''}(x)| \cdot \alpha + \epsilon}&&
\end{align*}
where $k$ is the proportionality constant or hyperparameter in our case and $\epsilon$ is a constant, which is set to $1e^{-6}$ and is defined to prevent numerical instability that may arise from calculations involving very small numbers i.e., when $f^{''}(x) \approx 0$. In the above formulation of $d_0$, we take absolute values of $f{'}(x)$ and $f{''}(x)$ since the direction would not have any separate impact on $d_0$ as we aim to determine how far we can accurately predict irrespective of direction. 

% Figure environment removed

However, we cannot use the above formulation of $d_0$ to directly make predictions since the range of $d_0$ would be $[0, 10000)$, making our predictions extremely erroneous for high values of $d_0$. Ideally, we would like to limit the value of prediction distance $d$ to a small range $[0, n)$, so that when $d$ is high (low) it is limited by $n$ (0). There are several ways to map a variable to a finite range. Here, we used an exponential function to map the value of $d_0$ to the range $[0, n)$. Also, as discussed earlier in NaP, we need to set a lower bound value of $d$ to avoid predicting some data within our sample set. Thus, using $d_0$, $n$ and $p$ we formulate our prediction distance $d$ using an exponential function as:
\begin{align*}
    d = (1 - e^{-d_0}) \cdot n + (p - 1)
\end{align*}
where $d_0$ is defined previously, $n$ is the maximum value of prediction distance $d$ and $p$ is the prediction interval.
Now, the only variables which we need to define are the values of $f^{'}(x)$ and $f^{''}(x)$ before we can implement AdaP. We have the quadratic function $f(x) = ax^2 + bx + c$, and for each parameter, after fitting the function using the required weights, we can obtain the values of the coefficients of $f(x)$, namely the values of $a$, $b$, and $c$. Therefore, we can easily calculate the slope and derivative of the slope as follows:
\begin{align*} 
    f^{'}(x) &= \dfrac{d}{dx} (ax^2 + bx + c) = 2ax + b\\
    f^{''}(x) &= \dfrac {d^{2}}{dx^{2}} = 2a
\end{align*}
The value of $f^{''}(x)$ is a constant but the value of the slope i.e. $f^{'}(x)$ is dependent on $x$. Since we predict weight at some future $x$, it makes sense to use the slope at the last datapoint with which we fit the curve. Thus, we take the slope for $f^{'}(p - 1)$ since we fit $f(x)$ with $x = [1, 2, ... p - 1]$ and $y = [w_2, w_3, .. w_p]$. Therefore, the final equations used for AdaP methodology are:
\begin{align} \label{eq:2}
    &&d &= (1 - e^{-d_0}) \cdot n + (p - 1)&& \\
    where, &&d_0 &= k \cdot \frac{|f^{'}(x)|}{|f^{''}(x)| \cdot \alpha + \epsilon}&& \notag \\
    &&f^{'}(x) &= 2a(p-1) + b && \notag \\
    &&f^{''}(x) &= 2a&& \notag
\end{align}
In the above equation, we define $k$, $p$, and $n$ as the hyperparameters. We found $n = 12$ to work best in most cases. The optimal values of $k$ and $p$ vary depending on the circuit and problem size. However, we provide a safe range for $k$ and $p$ as $(0, 1]$ and $[c + 1, 2(c + 1)]$, respectively where $c$ refers to the degree of the polynomial we use as our prediction function. A higher $k$ would result in larger predictions (high $d$) more frequently, which can sometimes lead to incorrect predictions. It should be noted that $p$ can take higher values but it would not really help in making a better prediction at least when using quadratic polynomials as our prediction function. Higher $p$ would be more suitable when using higher-order polynomials since otherwise, they might overfit which would lead to incorrect predictions.

\section{Evaluation} \label{evaluation}

\subsection{Setup}
All simulations are performed using Pennylane's \cite{bergholm2018pennylane} `lightning.qubit" device with the adjoint differentiation method for all gradient calculations if not mentioned otherwise. For all our prediction/regression tasks, we use the SciPy \cite{virtanen2020scipy} libraries $\mathrm{curve\_fit()}$ function which implements Non-Linear Least Squares (NLLS) optimization using the Levenberg-Marquardt algorithm. All numerical experiments are run on an Intel Core-i7-12700H CPU with 40GB of RAM.

\textbf{Setup for QNN:} For evaluation, we used the most complex circuit (w.r.t total number of parameters) i.e., PQC-6 from the set of various parameterized circuits where PQC-x represents circuit-x in \cite{sim2019expressibility}. For embedding classical feature values to their corresponding quantum state we use the angle encoding technique with $RZ$ gate and for measurement, we calculate the Pauli Z basis expectation value over all the qubits.

We conduct all experiments using a reduced feature set of MNIST \cite{yan1998mnist}, Fashion \cite{xiao2017fashion}, Kuzushiji \cite{clanuwat2018deep}, and Letters \cite{cohen2017emnist} datasets with latent dimension $d = 8$ (from the original 28$\times$28 sized image) using a convolutional autoencoder \cite{alam2021quantum}. Thus, for each dataset, we create a smaller 4-class dataset from these reduced feature sets i.e., MNIST-4 (class 0, 1, 2, 3), Fashion-4 (class 6, 7, 8, 9), Kuzushiji-4 (class 3, 5, 6, 9) and Letters-4 (class 1, 2, 3, 4) with each having 1000 samples (700 for training and 300 for testing). Since we use 4-qubit QNN models for training and each of these datasets is of dimension $d = 8$, we encode 2 features per qubit. For training, we use the following hyperparameters (unless specified otherwise); epoch = 200, batch\_size = 32, optimizer = Adam, Loss\_fn = SparseCategoricalCrossentropy and learning\_rate ($\alpha$) = 0.002. We use accuracy and loss as metrics to evaluate/analyze the efficacy of our methodology. The hyperparameters for NaP and AdaP methodologies are as follows: $p = 5$, $d_0 = 3$, $k = 0.0001$, and $n = 12$ (Eq. \ref{eq:1}, \ref{eq:2}).

\begin{table*}[t]
    \centering
    \caption{Comparison of final test accuracy and loss values after training a hybrid QNN on different datasets for 200 epochs with and without the WEPRO (with $p = 5$, $d_0 = 3$ and $k = 0.0001$). AdaP achieves the highest test accuracy and lowest test loss for all the datasets.}
    \label{acc_loss}
    \vspace{-5mm}
    \begin{tabular}{ccccccc}
    \cmidrule(lr){2-7}
    \multicolumn{1}{c}{} & \multicolumn{2}{c}{Vanilla} & \multicolumn{2}{c}{NaP} & \multicolumn{2}{c}{AdaP} \\
    \cmidrule(lr){1-7}
    Datasets    & Test Accuracy & Test Loss & Test Accuracy & Test Loss & Test Accuracy & Test Loss \\
    \cmidrule(lr){1-7}
    MNIST-4     & 0.920      & 0.242      & 0.923     & 0.241     & \textbf{0.943}      & \textbf{0.184}      \\
    Fashion-4     & 0.923      & 0.298      & 0.923      & 0.295     & \textbf{0.946}      & \textbf{0.237}        \\ 
    Kuzushiji-4   & 0.823      & 0.615      & 0.823     & 0.612     & \textbf{0.826}      & \textbf{0.605}       \\ 
    Letters-4   & 0.870      & 0.441      & 0.860     & 0.432     & \textbf{0.876}      & \textbf{0.391}        \\ 
    \bottomrule
    \end{tabular}
\end{table*}

% Figure environment removed

\textbf{Setup for VQE:} In order to find the ground state energy of molecules, we use the UCCSD ansatz. 
%UCCSD is basically described as a superposition of all possible single and double excitations from a reference state, where a single excitation means that one electron is excited from one spin-orbital to another, and a double excitation means that two electrons are excited simultaneously \cite{barkoutsos2018quantum}. The reference state in our experiments is the Hartree-Fock state of the molecule. It can be thought of intuitively as an approximate starting state that is encoded as the basis state of the UCCSD ansatz, the parameters of which are optimized using an optimizer that reduces the expectation value of the molecular Hamiltonian to obtain the molecule's approximate ground state energy.
We conducted experiments to calculate the ground state energy of various molecules namely, H$_2$, H$_3^{+}$, H$_2$O, BeH$_2$, LiH, NH$_3$, BH$_3$, and CH$_4$ to compare the efficacy of WEPRO against vanilla optimization technique. To obtain the molecular Hamiltonian \cite{kim2016pubchem}, we use a subset of electrons and orbitals, enabling quantum simulations with fewer qubits \cite{bao2018automatic}. For experiments, we used the Gradient Descent optimizer with a learning rate ($\alpha$) = 0.1 and convergence tolerance of $10^{-6}$. We initialized all parameters of the circuit to $0$. For the proposed NaP and AdaP methodologies, we set the hyperparameters as follows; $p = 4$, $d_0 = 5$, $k = 0.01$ and $n = 12$ (Eq.\ref{eq:1} and \ref{eq:2}).

\textbf{Setup for QAOA:} For QAOA, we find the approximate MaxCut of different-sized Erdos-Reyni graphs (probability of an edge between each node: 0.6) and compare the performance of WEPRO with general techniques. We use the approximation ratio (defined below) as a metric to evaluate the performance of QAOA in solving the MaxCut problem which is defined as: 
%the ratio of ApproxCut and MaxCut where 
\[ \text{Approximation Ratio (Ar)} = \frac{\text{ApproxCut}}{\text{MaxCut}}\]
where the `ApproxCut' is the approximate MaxCut value predicted by the QAOA circuit and `MaxCut' refers to the actual maximum cut.
Here, we used the Adagrad optimizer with a learning rate of 0.05 and ran each experiment for 100 steps. We initialized the parameter values to be uniformly distributed within the range $(0, \pi/2$). The hyperparameters for the proposed NaP and AdaP techniques are set as follows: $p = 4$, $d_0 = 3$, $k = 0.01$, and $n = 12$ (Eq.\ref{eq:1} and \ref{eq:2}).

It should be noted that the goal was not to find the best-performing QNN model (in terms of loss or accuracy), or the most accurate ground state energy approximation for a specific molecule, but rather to demonstrate how WEPRO can be easily applied to different hybrid algorithms and how well it performs when compared to traditional techniques used in optimizing a quantum circuit. A better choice of hyperparameter or a better prediction distance formulation could in fact provide better performance than shown here.

\begin{table}[!b]
    \vspace{-4mm}
    \centering
    \caption{Speedup provided by WEPRO over the vanilla technique for testing accuracy and loss on various datasets.}
    \label{qnn_speedup}
    \vspace{-2mm}
    \begin{tabular}{ccccc}
    \cmidrule(lr){2-5}
    \multicolumn{1}{c}{} & \multicolumn{2}{c}{AdaP} & \multicolumn{2}{c}{NaP} \\
    \cmidrule(lr){1-5}
    Datasets    & Test Acc & Test Loss & Test Acc & Test Loss \\
    \cmidrule(lr){1-5}
    MNIST-4     & \textbf{1.51}      & \textbf{1.48}       & 1.1      & 1.04 \\
    Fashion-4     & \textbf{1.58}       & \textbf{1.55}       & 1.06      & 1.02 \\
    Kuzushiji-4   &\textbf{ 2.25}       & \textbf{1.18}       & 1.30      & 1.04 \\ 
    Letters-4   & \textbf{1.36}       & \textbf{1.74}      & 0.95      & 1.10 \\
    \bottomrule
    \end{tabular}
\end{table}

% Figure environment removed


\subsection{Results} \label{results}

\subsubsection{Hyperparameter Analysis}
% To implement our proposed NaP and AdaP, we will mainly need to use Eq.(\ref{eq:1}) and (\ref{eq:2}) respectively. The only hyperparameters that we need to determine and keep constant throughout all the predictions are $d_0$ for NaP and $k$ for AdaP.
We intuitively determine the prediction interval $p$.
%, we consider the minimum number of weights (sample size) that allow our function to accurately predict future parameters' weight. 
The minimum number of samples needed to fit a quadratic function with 3 variables is 3 i.e., $p = 4$ (since we use the last $p-1$ weights to make the predictions). Therefore, we use $p = 4$ for the VQE and QAOA circuit optimization whereas for QNN training, we note that $p = 5$ can make better predictions.

For NaP, we trained the QNN models with PQC-6 \cite{sim2019expressibility} on a reduced MNIST 3-class dataset (class 0,1,3) with various $d_0 = \{2, 3, 4, 5\}$ for 50 epochs to find the optimal value for $d_0$. To avoid any inconsistencies, we initialized all the models with the same set of weights. Fig. \ref{d0_variation} shows the training and testing loss and accuracy for various values of $d_0$. From the plot, we can note that WEPRO consistently outperforms the original/vanilla training. However, not all $d_0$ values are suitable. Low values of $d_0$, e.g., $d_0 = 2$ will result in stable (safe) predictions but will not provide the optimal speed-up. High $d_0$, e.g., $d_0 = 5$ results in several inaccurate predictions (overshooting optimal weight) even though it can regain the accuracy with intermediate training. Thus, an initial prediction distance $d_0$ in the range [3, 4) provides the best results. We use $d_0 = 3$ for the entire QNN training.

For VQE and QAOA, a similar analysis is performed to determine the optimal $d_0$ for NaP. We also conducted experiments with the same QNN model for AdaP to determine the optimal value of hyperparameter $k$ that provides close to optimal performance. As previously discussed in Section \ref{adap}, high values of $k$ result in higher prediction values whereas lower values of $k$ did not provide the optimal performance. As a result, we found that $k = 0.0001$ works best for QNN and $k = 0.01$ gives the best performance in VQE and QAOA. We have also evaluated the effect of different learning rates ($\alpha$) on AdaP's performance for training a QNN (discussed in Section \ref{choices} and shown in Fig. \ref{lr_analysis}).

\subsubsection{Speedup}
We use the following \textit{Speedup} metric to show how quickly WEPRO achieves the peak performance compared to the vanilla technique;
\begin{equation} \label{eq:3}
    \textit{Speedup} = \dfrac{e_v}{e_p}
\end{equation}
where $e_v$ denotes the epoch/iteration at which the circuit achieves its maximum performance, in terms of loss (or accuracy or energy or approximation ratio), using vanilla training, and $e_p$ denotes the epoch at which WEPRO surpasses the peak performance achieved through vanilla training.

\begin{table}[!b]
    \vspace{-2mm}
    \centering
    \caption{Speedup and the convergence rate provided by NaP and AdaP over the vanilla technique for various molecules.}
    \label{vqe_rate_speedup}
    \vspace{-2mm}
    \begin{tabular}{cccccc}
    %\toprule
    \cmidrule(lr){1-6}
    \multicolumn{1}{c}{\textbf{VQE}} & \multicolumn{2}{c}{Speedup} & \multicolumn{3}{c}{Convergence Rate ($\times 10^{-4}$)}  \\
    \cmidrule(lr){1-6}
    Molecules   & AdaP & NaP & Vanilla & AdaP & NaP\\
    \cmidrule(lr){1-6}
    H$_2$       & \textbf{2.25} & 1.60 & 2.38       & \textbf{6.79}     & 4.20  \\
    H$_3^{+}$   & \textbf{2.16} & 1.62 & 2.93       & \textbf{7.64}     & 5.16  \\
    H$_2$O      & \textbf{2.50} & 1.66 & 2.15       & \textbf{7.52}     & 4.04  \\
    BeH$_2$     & \textbf{2.96}  & 1.58 & 0.49      & \textbf{1.78}     & 0.77 \\
    LiH         & \textbf{2.83}  &  1.69 & 0.14      & \textbf{0.45}    & 0.24 \\ 
    NH$_3$      & \textbf{2.12} &  1.69 & 2.03       & \textbf{5.36}     & 3.94  \\
    BH$_3$      &  \textbf{3.10} & 1.72  & 0.39      & \textbf{1.96}     & 0.81  \\
    CH$_4$      & \textbf{2.00}  & 1.71  & 2.78       & \textbf{6.67}     & 5.47  \\
    \bottomrule
    \end{tabular}
\end{table}

\textbf{QNN:} For evaluation, we trained QNN with PQC-6 for 200 epochs on multiple datasets. Table \ref{acc_loss} shows the comparison in final testing loss and accuracy between vanilla training, NaP, and AdaP. We chose to represent testing results rather than training loss and accuracy since it represents WEPRO's generalization capability better on new data. Even though the final loss/accuracy is not the primary criterion for demonstrating the superiority of our method, it is evident that WEPRO consistently outperforms the traditional (vanilla) technique for all datasets. We obtain up to 2.3\% higher final test accuracy and 6.1\% lower final test loss as compared to traditional training methodology. Fig. \ref{fashion_plot} gives a clear representation of the superiority of WEPRO over baseline training.

Table \ref{qnn_speedup} shows a speedup of up to 2.25$\times$ and 1.6$\times$ on average by WEPRO over vanilla training on various datasets. This means that WEPRO can attain the final loss/accuracy obtained through vanilla training in less than half the number of epochs. This significantly reduces the circuit training time and conserves computational and usage costs, especially when training on a real high-cost quantum device as we reduce the total number of circuit executions.

% Figure environment removed

\textbf{VQE:} Fig. \ref{vqe_results} shows the number of iterations required to reach the approximate ground state energy for the benchmark molecules using various methodologies. We note that AdaP takes the least number of iterations to converge to the optimal ground state energy. Table \ref{vqe_rate_speedup} provides the speedup provided by NaP and AdaP for multiple molecules. We note that for BH$_3$, AdaP provides $3.1\times$ speedup whereas NaP provides $1.72\times$ speedup over vanilla technique. 
%This means that the generic optimization technique requires almost $3\times$ the iteration required by AdaP for convergence. 
On average, AdaP provides a speedup of $\approx 2.5\times$, and NaP provides a speedup of $\approx 1.65\times$ demonstrating the superiority of WEPRO over traditional techniques currently used in the hybrid algorithms.

\textbf{QAOA:} Fig. \ref{qaoa_results} shows the change in approximation ratio with time when solving the MaxCut problem for an Erdos-Reyni 8-node graph with different circuit depths. For the lower-depth QAOA circuits (depths 1 and 2) both of the proposed WEPRO methodologies equally outperform the vanilla optimization technique. For circuit depth = 3, AdaP performs significantly better than NaP and the traditional technique. Table \ref{qaoa_rate_speedup} shows the speedup provided by AdaP and NaP for different-sized graphs and different circuit depths. AdaP performs the best except for the 8-node depth-2 graph.

\subsubsection{Convergence Rate}
We also use \textit{Convergence Rate} as a metric to measure how quickly WEPRO converges to optimal solutions and compare them to the vanilla technique. The convergence rate, calculated as the absolute value of the loss function's slope over epochs or iterations, is estimated through a linear regression model applied to the loss values. Selecting the appropriate number of epochs is crucial to obtain an accurate convergence rate, as too few epochs may be affected by initial random weights or learning rate adjustments, while too many epochs risk saturation influence. A high convergence rate signifies the algorithm's ability to rapidly and effectively reach an optimal or satisfactory solution, conserving time and resources. Though similar, convergence rate and speedup have distinct meanings: convergence rate gauges training efficiency in epochs, while speedup quantifies the actual time reduction for quantum circuit optimization. 

\textbf{QNN:} Fig. \ref{qnn_convrate} compares the convergence rates for various methodologies when evaluating QNNs on various datasets. WEPRO surpasses the vanilla approach, suggesting that WEPRO enables the QNN model to learn underlying patterns within the test data more rapidly and effectively.

\begin{table}[!b]
    \vspace{-3mm}
    \centering
    \caption{Speedup and the convergence rate provided by NaP and AdaP over the vanilla technique for different Erdo-Reyni graphs with different QAOA circuit depths.}
    \label{qaoa_rate_speedup}
    \vspace{-3mm}
    \begin{tabular}{cccccc}
    %\toprule
    \cmidrule(lr){1-6}
    \multicolumn{1}{c}{\textbf{QAOA}} & \multicolumn{2}{c}{Speedup} & \multicolumn{3}{c}{Convergence Rate ($\times 10^{-3}$)}  \\
    \cmidrule(lr){1-6}
    Nodes-Depth   & AdaP & NaP & Vanilla & AdaP & NaP\\
    \cmidrule(lr){1-6}
    4-1       & \textbf{2.60} & 2.02 & 4.34       & \textbf{5.85}     & 5.67  \\
    4-2   & \textbf{2.25} & 1.98 & 2.93       & \textbf{7.64}     & 5.16  \\
    4-3      & \textbf{1.94} & 1.65 & 2.15       & \textbf{7.52}     & 4.04  \\
    8-1     & \textbf{2.91}  & 2.06 & 3.53      & \textbf{5.44}     & 5.08 \\
    8-2         & 1.34  &  \textbf{1.52} & 3.77      & 4.94    & \textbf{5.58} \\ 
    8-3      & \textbf{2.47} &  1.52 & 2.69       & \textbf{6.60}     & 5.18  \\
    \bottomrule
    \end{tabular}
\end{table}

\begin{table}[!t]
    \vspace{-4mm}
    \centering
    \caption{Table comparing the total number of shots required by various variational quantum algorithms. WEPRO requires significantly less number of shots compared to the vanilla optimization technique (cost per shot = $\$0.01$ \cite{AmazonBraketPricing}).}
    \label{shots}
    \vspace{-2mm}
    \begin{tabular}{cccc}
    \cmidrule(lr){2-3}
    \multicolumn{1}{c}{} & \multicolumn{2}{c}{Shots} & \multicolumn{1}{c}{} \\
    \cmidrule(lr){1-4}
    Algorithms    & Vanilla & WEPRO & Cost Savings \\
    \cmidrule(lr){1-4}
    QNN     & $2 \times 10^8$       & $\mathbf{1.04 \times 10^8}$     &  $\$ 960$K\\ %1.92
    VQE     & $5 \times 10^4$       & $\mathbf{1.5 \times 10^4}$     &   $\$ 0.35$K\\ %3.33$
    QAOA    & $1 \times 10^5$       & $\mathbf{0.33 \times 10^5}$     &   $\$ 0.6$K\\ %3.03
    \bottomrule
    \end{tabular}
    \vspace{-4mm}
\end{table}

% Figure environment removed


\textbf{VQE:} Table \ref{vqe_rate_speedup} compares the convergence rate of the energy curve of various molecules for different methodologies. Here, we consider energy over all iterations (i.e., the number of iterations required by each method to converge) to calculate the convergence rate. AdaP has up to 400\% higher convergence rate (in the case of BH$_3$) than vanilla methodology. On average, the two WEPRO methods outperform the baseline technique significantly i.e., $\approx 223\%$ higher convergence rate (AdaP), and $\approx 83\%$ higher convergence rate (NaP).

\textbf{QAOA:} Table \ref{qaoa_rate_speedup} compares convergence rates across methodologies for different graph sizes and QAOA circuit layers. In order to calculate the convergence rate we consider the approximation ratio corresponding to the first 25 circuit iterations. This is done to avoid the influence of learning rate or saturation on the convergence rate calculation. Again, WEPRO significantly outperforms vanilla methodology for all cases. AdaP performs the best in all cases except for the 8-node graph with a QAOA circuit depth of 2, where NaP outperforms both AdaP and vanilla methods. AdaP provides up to $\approx 250\%$ higher convergence rate and NaP provides up to $\approx 88\%$ higher convergence compared to the vanilla method.

\subsubsection{Shot Savings}
By using previously calculated weights to update the circuit parameters, we also reduce the total number of circuit executions required to reach the optimal solution. Reduced circuit execution means fewer shots, which leads to significant cost savings. Here, we attempt to provide a lower bound on the number of shots saved per optimization process. In order to approximate the total number of shots, for VQE and QAOA we calculate the total shots (s) as a product of the total number of iterations ($N$) required by each on average multiplied by the number of shots for each measurement which is by default set to 1000 in Pennylane. For QNN, since we are training with 1000 samples and each forward pass or circuit execution takes in 1 sample, the total number of shots required to train a model is:
\[ \text{shots}_{QNN} = N \cdot \text{samples} \cdot 1000\]

Table \ref{shots} shows that WEPRO leads to shot savings of up to $3.33\times$ compared to the vanilla method making WEPRO highly (quantum) resource efficient while providing superior performance. Across various VQA tested in this work, WEPRO provides an average shot savings of $2.76\times$. This is primarily due to the fact that WEPRO updates parameters based on previously calculated weights rather than the circuit output. As a result, WEPRO requires fewer circuit executions overall while providing better performance. The cost of executing circuits on higher quality and/or larger (in terms of qubits) real quantum hardware is directly proportional to the number of shots that a program must execute. As a result, WEPRO saves a significant amount of monetary resources, making it extremely cost-effective.

\section{Discussion} \label{discussion}
\vspace{-2mm}
\subsection{Usage Model of WEPRO}
%\hl{Talk about how anyone will use WEPRO for their algo/dataset.} 

WEPRO is a versatile plug-and-play tool which can be seamlessly integrated into any VQA to accelerate convergence as long as the VQA uses a PQC whose parameters are being optimized by a classical optimizer and it has access to parameter weights of previous $p-1$ iterations (see Algorithm \ref{algo}). Thus, in order to incorporate WEPRO into any VQA which involves the optimization of a circuit, we use the following approach. At each iteration $i$, we first check the condition $(i \% p == 0)$. If it holds true, we update the weights using WEPRO, else we resort to updating the weights using a generic optimizer. The safe ranges of hyperparameters for NaP and AdaP have already been demonstrated for few algorithms and problem sizes. For instance, a smaller value of $k = 0.0001$ is found to be optimal for QNN, whereas a higher value of $k = 0.01$ is more suitable for QAOA and VQE. More generalized ranges are mentioned in Sec. \ref{nap} and \ref{adap}. One could further fine-tune the values of these hyperparameters for general cases using techniques like grid search or random search.

\subsection{Scalability}
%\hl{Large qnn, qaoa with 100s of qubits and deep layers}  \hl{New!}
%Table \ref{scalability} showcases the consistently superior performance of WEPRO over the vanilla method on varying QNN sizes with a larger MNIST-10 dataset, requiring fewer shots. 
WEPRO's flexibility allows extension to larger QNN models, QAOA implementations with hundreds of qubits, and VQE execution for determining large protein molecules' ground state energy, having numerous qubits and parameters. For larger PQCs with potentially non-convex/complex loss landscapes, AdaP, similar to Adam, would make smaller predictions due to each parameter's rapidly changing curvature. However, the core concept of WEPRO, fitting a curve for each parameter's prediction, should yield superior performance with proper hyperparameter tuning. It should match or surpass baseline's (only optimizer) performance for the same number of shots. 
%To illustrate this, we examined the worst-case scenario for WEPRO, fixing the value of prediction $d$ in the range (0, 1] for both NaP and AdaP from the first iteration and conducting experiments on QNN and VQE. Table \ref{scalability_complex} reveals that even in this scenario, WEPRO matches Adam's performance using fewer shots, highlighting WEPRO's advantages.
%Optimizing larger circuits generally takes more time to converge; however, since WEPRO relies solely on previously calculated weights rather than circuit size, it can still make accurate predictions, thus accelerating the optimization process. However, this would come at a cost of higher space and, possibly, time complexity due to the need for storage of previous $p - 1$ epoch weights and performing multiple regressions (discussed later in this Section).

\subsection{Impact of Choices} \label{choices}
%\hl{PQC type, number of layers, optimizer type} \hl{New!}
WEPRO is flexible and independent of the specific variational ansatz or the number of layers used in a PQC since it only requires knowledge about prior epochs/iterations weights to update parameters and not the type of gate/parameter. With appropriate hyperparameter tuning, WEPRO can perform well for various types of circuits. However, its effectiveness relies on the patterns in previously calculated weights. If an optimizer updates parameters irregularly \cite{spsa}, making it difficult to discern a pattern in the weights, WEPRO might struggle to generate accurate predictions. This might also happen when running a quantum circuit on real quantum device or a noisy simulator. To mitigate this issue, hyperparameters can be adjusted. For example, one can limit WEPRO's prediction distance ($d$) to only a few steps ahead, such as just 2 or 3 iterations from the current iteration and/or increase the prediction interval ($p$) so that it has more datapoints to correctly learn noisy parameter patterns. This approach will enable WEPRO to perform adequately, but may hinder the speedup.

% Figure environment removed

%Fig. \ref{noisy_vqe} compares the performance and parameter trend of vanilla and AdaP on noisy simulator. AdaP surpasses vanilla in performance, even under noise and with default hyperparameters, as it reaches optimal loss value and ground state energy faster. Parameter plots reveal that AdaP predicts future parameters earlier. Essentially, the AdaP parameter plot is a left-shifted version of the vanilla plot, illustrating AdaP's ability to anticipate future vanilla parameters ahead of time, even in noisy conditions.

Hardware noise variation can affect any VQAs performance, but WEPRO should outperform traditional methods when using mitigation techniques like training with averaged errors \cite{alam2019addressing} or remapping circuits to lowest error subgraphs \cite{nation2023suppressing}. However, WEPRO's aim is not to tackle noise variation, but to accelerate convergence and reduce quantum circuit executions, even under noise conditions. The use of a higher learning rate ($\alpha$) may also potentially impact the speedup of the WEPRO algorithm as can be seen in Fig. \ref{lr_analysis}. However, WEPRO still performs comparably to traditional methods in such cases, with its advantage residing in cost and quantum resource efficiency, as it demands fewer total shots for convergence than conventional algorithms.

\subsection{Limitations} \label{limitations}
The above experiments show that WEPRO %significantly outperforms the generic optimization process. Therefore, WEPRO 
can accelerate any variational quantum algorithm that uses an optimizer to update the parameters of the required PQC to achieve the desired output. However, WEPRO comes at the cost of an increase in space complexity and possibly an increase in time complexity as well depending on the implementation.

\subsubsection{Space Complexity} Normally, only parameter weights from the immediate previous epoch are available during training/optimization of the parameters of a quantum circuit. However, WEPRO requires $p-1$ previous weights which would need storage of $N*p$ weights, where N is the total number of parameters in the circuit/model. This would necessitate a higher space complexity of $O(Np)$. However, in most cases a low value of $p$ in the range $[4, 6]$ results in relatively high performance. Therefore, the space complexity would simplify to $O(N)$. 

The significant space complexity could particularly impact models with billions of parameters (like in GPT-3 \cite{brown2020language}). Hence, WEPRO is more suitable for VQAs where the parameter count is in the thousands. Furthermore, it has been demonstrated \cite{chen2020variational, li2021drug} that QML models can generalize effectively while using a fraction of the parameters required by deep learning models ($\approx 1\%$). Thus, for smaller $N$, the overhead of our methodology is minimal, making our algorithm practically viable, particularly in the current NISQ era. One can reduce space complexity using selectively storing and updating parameters however, we focus on updating quantum parameters with past computed weights, rather than designing the most efficient implementation of WEPRO.

\subsubsection{Time Complexity} Since each prediction instance requires multiple non-linear regression/curve fitting, one might assume that the total time complexity might be really high. However, since each of our regressions involves very few data points i.e., $p-1$ to fit a quadratic function, it does not have a drastic impact on the total run time. Furthermore, since each prediction is independent i.e., the prediction of the future value of the parameter does not require any information about the other parameters, we can easily parallelize them across different cores/threads. There are multiple AI parallel libraries like Ray \cite{moritz2018ray}, Horovod \cite{sergeev2018horovod}, Dask \cite{rocklin2015dask}, etc. which can be used to distribute regression tasks across multiple cores, GPUs, or nodes in a cluster, speeding up the training process.


\section{Conclusion} \label{conclusion}
Variational Quantum Algorithms (VQAs) can potentially solve certain problems faster than classical algorithms due to the inherent capabilities of quantum computing but this advantage has not been realized yet. The training time 
of VQA circuits 
%for Quantum Neural Networks (QNNs) and the execution time for Parameterized Quantum Circuits (PQCs) 
is currently limited by the computational intensity of quantum simulators and limited resources. In this study, we propose a Weight Prediction technique, WEPRO, which leverages regular trends in parameter weights to predict and update the parameter weights of VQAs at regular intervals. The results show that WEPRO can significantly speed up the convergence of these hybrid algorithms by up to $3.2\times$ while requiring $2.76\times$ lesser number of shots on average, with only a small additional cost in classical storage and computational resources. WEPRO offers a promising solution for improving the efficiency of VQAs in the NISQ era.


% \section*{ACKNOWLEDGMENTS}
% The work is supported in parts by NSF (CNS-1722557, CNS-2129675, CCF-2210963, CCF-1718474, OIA-2040667, DGE-1723687, DGE-1821766, and DGE-2113839), Intel's gift and seed grants from Penn State ICDS and Huck Institute of the Life Sciences.


%%%%%%% -- PAPER CONTENT ENDS -- %%%%%%%%


%%%%%%%%% -- BIB STYLE AND FILE -- %%%%%%%%
\bibliographystyle{IEEEtranS}
\bibliography{refs}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\end{document}
