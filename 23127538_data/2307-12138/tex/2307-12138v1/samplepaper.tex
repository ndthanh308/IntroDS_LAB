% This is samplepaper.tex, a sample chapter demonstrating the
% LLNCS macro package for Springer Computer Science proceedings;
% Version 2.20 of 2017/10/04
%
\documentclass[runningheads]{llncs}
%
\usepackage{graphicx}
\usepackage{tabularray}
\usepackage{tikz}
\usepackage{amsmath}
\usepackage{breqn}
\newcommand{\LArrow}[1]{%
\parbox{#1}{\tikz{\draw[->](0,0)--(#1,0);}}
}
\newcommand{\RArrow}[1]{%
\parbox{#1}{\tikz{\draw[<-](0,0)--(#1,0);}}
}
% \newcommand{\RArrow}[1]{%
% \parbox{#1}{\tikz{\draw[<-](0,0)--(#1,0);}}
% }
% Used for displaying a sample figure. If possible, figure files should
% be included in EPS format.
%
% If you use the hyperref package, please uncomment the following line
% to display URLs in blue roman font according to Springer's eBook style:
% \renewcommand\UrlFont{\color{blue}\rmfamily}

\begin{document}
%
\title{SCPAT-GAN: Structural Constrained and Pathology Aware Convolutional Transformer-GAN for Virtual Histology Staining of Human Coronary OCT images}
%
%\titlerunning{Abbreviated paper title}
% If the paper title is too long for the running head, you can set
% an abbreviated paper title here
%
\author{Xueshen Li$^{1}$, Hongshan Liu$^{1}$, Xiaoyu Song$^{3}$, Brigitta C. Brott$^{2}$, Silvio H. Litovsky$^{2}$, and Yu Gan$^{1}$}
%
\authorrunning{X.Li et al.}
% First names are abbreviated in the running head.
% If there are more than two authors, 'et al.' is used.
%
\institute{$^{1}$Department of Biomedical Engineering, Stevens Institute of Technology\\
$^{2}$School of Medicine, The University of Alabama at Birmingham\\
$^{3}$The Icahn School of Medicine at Mount Sinai\\
\email{\{ygan5\}@stevens.edu}}
%
\maketitle              % typeset the header of the contribution
%
\begin{abstract}
There is a significant need for the generation of virtual histological information from coronary optical coherence tomography (OCT) images to better guide the treatment of coronary artery disease. However, existing methods either require a large pixel-wisely paired training dataset or have limited capability to map pathological regions. To address these issues, we proposed a structural constrained, pathology aware, transformer generative adversarial network, namely SCPAT-GAN, to generate virtual stained H\&E histology from OCT images. 
The proposed SCPAT-GAN advances existing methods via a novel design to impose pathological guidance on structural layers using transformer-based network. 
Our experiments on human coronary data have demonstrated the superiority of SCPAT-GAN in comparison with existing methods. 
%Our generated virtual H\&E images also achieve a high indistinguishable rate per analysis from pathological analysis.
Also, qualitative comparison and a blind test from a pathologist indicate that our virtual histology images are indistinguishable from real histology. 

\keywords{Virtual histology, Coronary artery disease, Optical coherence tomography, Deep learning, Transformers}
\end{abstract}

\section{Introduction}
%Coronary artery disease (CAD) is a prevalent global health challenge, with 17.8 million deaths reported annually, placing it as the third leading cause of mortality worldwide \cite{hajar2017risk}. The manifestation of CAD extends beyond mortality, and is associated with symptoms such as angina, shortness of breath, heart attack, heart failure, and depression \cite{Lesperance.2000}. Given the high morbidity rates and significant impact of CAD, accurate diagnosis and effective management strategies are of paramount importance. 
Coronary artery disease (CAD) is narrowing of coronary arteries caused by build-up of atherosclerotic plaques. As the most common type of heart disease, CAD leads to 1 in 7 deaths in the United States \cite{hajar2017risk}.
%A common therapeutic approach for CAD is percutaneous coronary intervention (PCI), which involves the placement of a stent in narrowed coronary arteries. The improvement of coronary imaging techniques is crucial for the success of PCI.
Optical Coherence Tomography (OCT) has been recognized as a valuable tool for imaging coronary tissue structures due to its high resolution capabilities \cite{Tearney.2012}. 
%In the context of PCI, OCT is commonly employed for the evaluation of plaques prior to stenting, to confirm successful stent deployment, and to assess the response of blood vessels to interventions \cite{jones2018angiography,wijns2015optical}.
However, real-time interpretation of OCT images requires a significant amount of expertise and prior training. Additionally, the power of OCT interpretation, especially of the pathological region, is hindered by the lack of histopathological correlation. %may not be sufficient to achieve the level of analysis that can be obtained through histopathological evaluation.
%At present, direct histopathological analysis requires offline evaluation that involves post-mortem tissue examination. 
%This process is both invasive and time-consuming, involving tissue fixation, preparation of stained sections, and microscopic imaging. 
At present, direct histopathological analysis requires invasive and time-consuming evaluation that involves post-mortem tissue examination. 
The use of multiple reagents in histopathology can also lead to detrimental effects on tissue imaging. 
%The entire process usually takes several hours to several days.
%Histopathological analysis is not suitable for clinical use in patients, who require real-time tissue characterization of coronary arteries during PCI.
Histopathological analysis is not suitable for clinical use in patients, who require real-time tissue characterization of coronary arteries.

% Figure environment removed

Incorporating histopathological visualization into real-time OCT imaging holds great potential to complement OCT with histopathological visualization. A typical example of generating virtual histology images from OCT images of human coronary artery is shown in Figure \ref{fig:VirtualHistology}. To date, there are limited frameworks developed to generate virtual histology from OCT images \cite{Winetraub.2021,https://doi.org/10.48550/arxiv.2211.06737}. Winetraub et al. used Pix2Pix Generative Adversarial Networks (GANs) to generate virtual stained Hematoxylin and Eosin (H\&E) histology for human skin tissues \cite{Winetraub.2021}. However, Pix2Pix GAN for virtual staining requires a pixel-wisely paired OCT and H\&E image dataset. The creation of a pixel-wisely paired dataset demands a significant investment of resources and labor, including the embedding of samples in fluorescent gel, photo-bleaching, and manual fine alignment \cite{Winetraub.2021}. Such a method also lacks generalizability to blood vessel which is a deformable soft tissue. Our previous method \cite{https://doi.org/10.48550/arxiv.2211.06737} demonstrates the capability to segment the three-layer structure (i.e., intima, media, and adventitia) in both OCT and H\&E images, thereby generating virtual H\&E images optimized for different layers in human coronary. However, current performance has not been optimal if there are pathological patterns, such as calcium and lipid accumulation, that alter the typical three-layer structure of human coronary arteries. 

To generate pathological-related regions from an unpaired dataset, we propose a \textbf{S}tructural \textbf{C}onstrained, \textbf{P}athology \textbf{A}ware, convolutional \textbf{T}ransformer GAN (SCPAT-GAN) to generate virtually stained H\&E histology images from OCT images. The proposed SCPAT-GAN incorporates two key components to enhance image quality for both normal and pathological coronary samples: a structural constraining module and a pathology awareness module. In summary, our main contributions include: 

(1) We propose a convolutional transformer-GAN structure for virtual H\&E staining of human coronary arteries based on OCT. This generative method does not require pixel-wisely mapping in the training dataset.

(2) We incorporate a structural constraining and pathology awareness modules for virtually staining coronary arteries with both normal three-layer structures and pathological patterns. 

(3) %Exclusive experiment. 
%We invite an experienced pathologist to perform blind test on virtual H\&E images.  \textcolor{red}{YG: It can be a contribution if we design and conduct extensive experiments. Inviting someone to test itself may not be a contribution....}
%We design a protocol to involve experienced pathologist to evaluate the quality and clinical meaningness of the virtual H\&E images, and we carry out extensive experiments accordingly.
We conduct extensive experiments, including a blind test, to demonstrate that the generated images are indistinguishable from real histology images.
\section{Methodology}
\subsection{Design of SCPAT-GAN}


\subsubsection{Network architecture: }
The design of SCPAT-GAN is shown in Figure \ref{fig:SctrualSCPAT}. The SCPAT-GAN consists of two convolutional transformer generators ($G_{O\LArrow{.15cm}H}$ and G$_{H\LArrow{.15cm}O}$) and two discriminators ($D_H$ and $D_O$). \textcolor{black}{The transformer structure possesses self-focus mechanisms which provide the global context of a given data sample even at the lowest layer.} $G_{O\LArrow{.15cm}H}$ transfers images from OCT domain to histology domain; $G_{H\LArrow{.15cm}O}$ transfers images from the histology domain to OCT domain. The two generators share a similar structure. D$_H$ is the discriminator for histology images and D$_O$ is the discriminator for OCT images. Symbols $O$ and $H$ stand for OCT and histology images respectively.

The convolutional transformer generators ($G_{O\LArrow{.15cm}H}$ and G$_{H\LArrow{.15cm}O}$) take advantage of U-Net \cite{RFB15a} like structure to extract multi-scale features. The multi-scale features are sent to Swin Transformer Block (STB) and Structural Constraint and Pathology Aware (SCPA) Module.
The STB is a deep neural network architecture that employs multiple residual Swin Transformer sub-blocks (RSTBs) to extract features from input data. The RSTBs contain various Swin Transformer Layers (STLs) \cite{9607618} that facilitate local attention and cross-window interaction learning. 
%Residual learning is employed within each RSTB to stabilize feature extraction, while 3 × 3 convolutional layers are incorporated between RSTBs and STLs to enhance feature representation. 
The feature extraction process of RSTBs is expressed as: $T^{RSTB} = Conv(F^{STL} + T^{IN})$, where $F^{STL}$ denotes the features generated from STLs, Conv represents 2D convolutional layer with a kernel size of 3 × 3, and $T^{IN}$ represents the input feature of RSTBs. 
%Each STL comprises components including layer normalization, multi-head self-attention (MLA) modules, residual connections, and a two-level multilayer perceptron (MLP) with GELU non-linearity. The self-attention of each head can be calculated as: $Attention(Q, K, V) = SoftMax(\frac{QK^{T}}{\sqrt{d}} + B)V$, where Q, K, V $\in \mathbb{R}^{N^{2 \times d}}$ are the query, key and value matrices; $d$ denotes the query dimension; $N^2$ stands for the number of patches in a window; and $B$ is parameterized from $\hat{B} \in \mathbb{R}^{(2N-1)\times(2N+1)}$. 
Each STL comprises components including layer normalization, multi-head self-attention (MLA) modules, residual connections, and a two-level multilayer perceptron (MLP) with GELU non-linearity. The self-attention of each head can be calculated as: $Attention(Q, K, V) = SoftMax(\frac{QK^{T}}{\sqrt{d}} + B)V$, where Q, K, V $\in {R}^{N^{2 \times d}}$ are the query, key and value matrices; $d$ denotes the query dimension; $N$ stands for the number of patches in a window; and $B \in {R}^{(2N-1)\times(2N+1)}$. 
% Figure environment removed



\subsubsection{Structural constraining and pathology awareness: }
The SCPA module is based on a transformer encoder-decoder architecture, which guides the virtual staining procedure. The SCPA module performs structural constraining and pathology awareness functions by segmenting the human coronary layers and classifying the types of coronary samples (normal or pathological). 
%The SCPA module guide the virtual staining procedure. 
The multi-scale features are split into a sequence of patches x=$[x_1, ..., x_N]\in R^{N\times P^2\times C}$, where $(P,P)$ stands for the patch size, and C is the number of channels of the multi-scale features. The patches are flattened and then linearly projected to an embedding sequence x$_0=[E_{x_1}, ..., E_{x_N}] \in R^{N\times d}$, where $d$ is the embedding dimension. Learnable position embeddings pos=$[pos_1, ..., pos_N] \in R^{N\times d}$ are added to the sequence of patch embeddings to generate the tokens z$_0$=x$_0$+pos for Encoder. The Encoder maps the input sequence z$_0$ to z$_L=[z_{L_1},..., z_{L_N}]$, which is an encoding sequence containing contextualized information of multi-scale features. 

The SCPA module is designed to be aware of pathology patterns as well as maintain and constrain the normal structure of coronary samples. In the case of normal coronary samples, the z$_L$ is decoded to a segmentation map \textbf{s} $\in R^{H \times W \times K}$, where $K=3$ and represents the three-layer structure of human coronary arteries. The segmentation map is acquired by the SCPA module, taking the scalar production between patch embeddings z$_M$ and class embeddings $c$: $Segmentaion = z_M c^T$, where z$_M$ is acquired by decoding z$_L$, and $c$ is acquired by decoding a set of three randomly initialized learnable class embeddings [cls$_{Intima}$, cls$_{Media}$, cls$_{Adventitia}$] corresponding to the three coronary layers. In the case of diseased coronary samples, the patch embeddings z$_M$ are sent to a two-level MLP for classification between normal and pathological coronary images: $Classification = MLP(z_M)$.
Also, the patch embeddings z$_M$ is concatenated to the extracted features from STB and then merged and up-sampled for OCT$\LArrow{.2cm}$Histology and Histology$\LArrow{.2cm}$OCT conversion. 

\subsubsection{Loss function: }
The loss function $L$ of SCPAT-GAN consists of five terms, which are adversarial loss $L_{adv}$, cycle-consistency loss $L_{cycle}$, embedding loss $L_{embedding}$, structural constraint loss $L_{SC}$, pathology awareness loss $L_{PA}$. 
\begin{equation} \label{eq1}
\begin{split}
&L(G_{O\LArrow{.15cm}H}, G_{H\LArrow{.15cm}O}, D_H, D_O, G^{SC}_{O\LArrow{.15cm}H},  G^{SC}_{H\LArrow{.15cm}O}, G^{PA}_{O\LArrow{.15cm}H}, G^{PA}_{H\LArrow{.15cm}O}) 
\\
& = L_{adv}(G_{O\LArrow{.15cm}H}, D_H) +  L_{adv}(G_{H\LArrow{.15cm}O}, D_O)
\\
&+ \alpha L_{cycle}(G_{O\LArrow{.15cm}H}, G_{H\LArrow{.15cm}O}) + \beta L_{embedding}(G_{O\LArrow{.15cm}H}, G_{H\LArrow{.15cm}O}) \\
&+ \gamma L_{SC}(G^{SC}_{O\LArrow{.15cm}H}, G^{SC}_{H\LArrow{.15cm}O}) + \iota L_{PA}(G^{PA}_{O\LArrow{.15cm}H}, G^{PA}_{H\LArrow{.15cm}O})
\end{split}
\end{equation}
We follow the definition of $L_{adv}$ and $L_{cycle}$ in \cite{8237506} and definition of $L_{embedding}$ in \cite{Liu.2021}. $\alpha$, $\beta$, $\gamma$, and $\iota$ are hyper-parameters. G$_{O\LArrow{.15cm}H}$ and G$_{H\LArrow{.15cm}O}$ are two generators that generate virtual histology images from OCT images and virtual OCT images from histology images respectively. G$^{SC}_{O\LArrow{.15cm}H}$,  G$^{SC}_{H\LArrow{.15cm}O}$, G$^{PA}_{O\LArrow{.15cm}H}$,  and G$^{PA}_{H\LArrow{.15cm}O}$ are the SCPA modules for performing structural constraining and pathology awareness functions in the generators. 
%The structural constraint loss $L_{SC}$ enforces SCPAT-GAN virtually stain coronary layers using different strategies. 
The $L_{SC}$ is implemented by segmentation loss:
\begin{equation} \label{eq2}
\begin{split}
L_{SC} = E_H[-S_H^{-1}\sum^{s_H}_{n=1}\sum^{C}_{c=1}y^{n,c}_H\log(G^{ SC}_{O\LArrow{.15cm}H}(O))] 
 +E_O[-S_O^{-1}\sum^{s_O}_{n=1}\sum^{C}_{c=1}y^{n,c}_O\log(G^{SC}_{H\LArrow{.15cm}O}(H))]
\end{split}
\end{equation}
$S_H$ and $S_O$ stand for the number of pixels in segmentation maps. $y^{n,c}_H$ and $y^{n,c}_O$ are the ground-truth pixel labels of different coronary layers for H\&E and OCT images respectively. $C$ stands for the number of categories of the coronary layers (c=3). The $L_{PA}$ is implemented by classification loss:
%The pathology awareness loss $L_{PA}$ enforces the SCPAT-GAN to virtually stain normal and pathological coronary arteries using different strategies. The $L_{PA}$ is implemented by classification loss:
\begin{equation} \label{eq2}
\begin{split}
L_{PA} = & E_H[-y^p_H\log(G^{PA}_{O\LArrow{.15cm}H}(O)) + (1 -y^p_H)\log(1 - G^{PA}_{O\LArrow{.15cm}H}(O))] \\
& + E_O[-y^p_O\log(G^{PA}_{H\LArrow{.15cm}O}(H)) + (1 -y^p_O)\log(1 - G^{PA}_{H\LArrow{.15cm}O}(H))]
\end{split}
\end{equation}
$y^p_H$ and $y^p_O$ are the ground-truth labels for pathology samples. We aim to solve the following minmax optimization problem:
\begin{equation} \label{eq2}
\begin{split}
&G^{*}_{O\LArrow{.15cm}H}, G^{*}_{H\LArrow{.15cm}O}=
\\
& \arg \min\max L(G_{O\LArrow{.15cm}H}, G_{H\LArrow{.15cm}O}, D_H, D_O, G^{SC}_{O\LArrow{.15cm}H},  G^{SC}_{H\LArrow{.15cm}O}, G^{PA}_{O\LArrow{.15cm}H}, G^{PA}_{H\LArrow{.15cm}O})
\end{split}
\end{equation}

%Now 186
\section{Experiments}
\subsection{Experimental settings}
\subsubsection{Experimental dataset: }
Human coronary samples were collected from The University of Alabama at Birmingham. Specimens were imaged via a commercial OCT system (Thorlabs). A total of 194 OCT images were collected from 23 patients with an imaging depth of 2.56 mm. The pixel size was 2 µm × 2 µm within a B-scan. The width of the images ranged from 2 mm to 4 mm depending on the size of sample. After OCT imaging, samples were processed for H\&E histology at The University of Alabama at Birmingham. %Each OCT image is paired with a H\&E image. 
Among the dataset, 112 OCT images are from normal samples with the three-layer structure (i.e., intima, media, and adventitia); 82 OCT and H\&E images contain pathological patterns. 
%We pixel-wisely label the three-layer structure in a subset of 52 normal OCT and H\&E images. 
%Also, we image-wisely label the pathological OCT and H\&E images.
The OCT and H\&E images are divided into non-overlap patches with a size of 368$\times$368. We randomly flip the patches from left to right for data augmentation. The training set contains 4297 OCT image patches and 4297 H\&E image patches.
\subsubsection{Implementation details: }
We adopt three convolution and transpose convolution layers with a stride of two for building a U-Net like structure for generating multi-scale feature maps. For the STB, we follow the design in \cite{9607618}. Our design of SCPA module is inspired by \cite{R.Strudel.2021}. But different from \cite{R.Strudel.2021}, we design the SCPA module to be capable of performing both segmentation and classification tasks, which suits our need for structural constraining and pathology awareness functions during virtual staining. The SCPAT-GAN is implemented by Pytorch. For training, the hyperparameters $\alpha$, $\beta$, $\gamma$, and $\iota$ are set to 1, 0.2, 5, and 5 empirically. The pixel values of OCT and H\&E images are scaled to [0, 1]. The batch size is 9. The learning rate is initialized as $10^{-4}$, followed by a linearly decaying decay for every 2 epochs. In total, the SCPAT-GAN is trained 10,000 epochs to ensure convergence. The experiments are carried out on an RTX A6000 GPU. 
%For the encoders, we adopt 3 convolution layers with a stride of 2; for decoders, we adopt 3 transpose convolution layers also with a stride of 2. The feature extractor consists of 5 residual blocks as described in \cite{He2016DeepRL}. We use a convolution layer with a stride of 1 to perform coronary structure mapping. The G$_{O\LArrow{.15cm}H}$ takes 1 color channel for input and outputs 3 color channels; the G$_{H\LArrow{.15cm}O}$ takes 3 color channels and outputs 1 color channel. We follow the discriminator design in \cite{8237506}.

\subsubsection{Metrics: }
We measure the similarity \textcolor{black}{of pairs of virtual histology and real histology images} using reference-free metrics including Fréchet inception distance (FID) \cite{Heusel.2017} and Perceptual hash value (PHV) \cite{Liu.2021}. We use the three variations of PHV scores ($i=1$, PHV1), ($i=2$, PHV2), and ($i=3$, PHV3) which are extracted from different levels $i$ of feature maps.
%Also, we invite a pathologist to assess the quality of virtual histology images.
Also, we design a protocol to involve a pathologist to evaluate the quality of the virtual H\&E images. Real and virtual H\&E images are given to the pathologist, who is blinded to the true labels, to make predictions. %We calculate the accuracy and confusion matrix of the prediction results made by the pathologist.
We compare the prediction results from the pathologist with the true labels.



\subsection{Results and Discussion}

\subsubsection{Quantitative analysis: }
\begin{table}[t]
\centering
\caption{The FID and PHV scores of SCPAT-GAN, our previous method, and Cycle-GAN. The PHV scores calculated from different levels of the feature maps PHV$1$, PHV$2$, and PHV$3$. All the results are calculated using three-fold cross-validation.}
\label{table1}
\resizebox{0.7\textwidth}{!}{
\begin{tblr}{
  row{even} = {c},
  row{3} = {c},
  cell{1}{1} = {c},
  cell{1}{2} = {c=4}{c},
  cell{1}{6} = {c},
  cell{2}{2} = {c=4}{c},
  cell{2}{6} = {c},
  cell{2}{7} = {c},
  cell{2}{8} = {c},
  cell{3}{2} = {c=4}{},
  cell{4}{2} = {c=4}{},
  cell{5}{1} = {c},
  hline{1-2,5} = {-}{},
}
Metrics             & FID$\downarrow$ &  &  &  & PHV1$\uparrow$ & PHV2$\uparrow$ & PHV3$\uparrow$ \\
SCPAT-GAN           & \textbf{175.70}          &  &  &  & \textbf{57.41}          & \textbf{62.42}          & \textbf{52.93}          \\
GAN method in \cite{https://doi.org/10.48550/arxiv.2211.06737} & 238.74          &  &  &  & 48.18          & 55.17          & 49.29          \\
Cycle-GAN           & 284.53          &  &  &  & 45.48          & 54.31          & 48.67          \\
                    &                 &  &  &  &                &                &                
\end{tblr}}
\end{table}




The quantitative results of SCPAT-GAN for virtual H\&E are shown in Table \ref{table1}. Compared to our previous method and Cycle-GAN, the SCPAT-GAN generates virtual H\&E images of better quality, with lower FID scores and higher PHV scores. Those scores indicate that the virtual histology and real histology are perceptually similar. Moreover, we have a pathologist with more than 30 years of experience to evaluate the quality of virtual H\&E images. The pathologist, who is blind to the true labels, manually identifies if an image is real or virtual. 

% Figure environment removed




The results are shown in Figure \ref{fig:Conf}. 
\textcolor{black}{Among the total 60 images (half virtual and half real), over half of them (42 images) are deemed as 'real' by the pathologist. For the images that are deemed as 'virtual', half of them (9 images) are truly virtual while another half of images are real. This accuracy of the pathologist is close to the level of random guessing, which indicates that the generated virtual histology images are indistinguishable from real histology images.}

\begin{table}[t]
\centering
\caption{The ablation study. We disable pathological awareness module (SCT-GAN), structural constraining module (PAT-GAN), and both modules (T-GAN). }
\label{table2}
\resizebox{0.7\textwidth}{!}{
\begin{tblr}{
  row{even} = {c},
  row{3} = {c},
  row{5} = {c},
  cell{1}{1} = {c},
  cell{1}{2} = {c},
  cell{1}{3} = {c},
  cell{2}{2} = {c},
  cell{2}{3} = {c},
  cell{2}{4} = {c},
  cell{2}{5} = {c},
  hline{1-2,6} = {-}{},
}
Metrics   & FID$\downarrow$ & PHV1$\uparrow$ & PHV2$\uparrow$ & PHV3$\uparrow$ \\
SCPAT-GAN & \textbf{175.70}          & \textbf{57.41}          & \textbf{62.42}          & \textbf{52.93}          \\
SCT-GAN   & 177.60          & 53.59          & 59.28          & 51.33          \\
PAT-GAN   & 176.96          & 53.57          & 59.94          & 50.45          \\
T-GAN     & 203.24          & 47.00          & 54.32          & 47.48          
\end{tblr}}
\end{table}
%Overall, the pathologist has an accuracy of $50\%$ (14 normal and 16 pathological images over 60 images) for distinguishing between real and virtual H\&E images, which is close to 'random guessing'. Thus, the virtual H\&E images generated by SCPAT-GAN have a good quality that is indistinguishable from real H\&E images even by experienced pathologists. 
%The resulting confusion matrices are shown in Figure \ref{fig:Conf}. For normal coronary samples, the pathologist has an accuracy of $46.6\%$ to distinguish between virtual and real H\&E images; for pathological coronary samples, the pathologist has an accuracy of $53.3\%$ to distinguish between virtual and real H\&E images. Overall, the pathologist only reaches an accuracy of $50\%$ to distinguish between virtual and real histology H\&E images, which is close to the level of 'random guessing'. Thus the virtual H\&E images generated by SCPAT-GAN are hard to be distinguished from real ones even by experienced pathologists, which means the virtual H\&E images have good quality and are clinically meaningful.
%For the pathological coronary samples, the SCPAT-GAN outperforms our previous method and Cycle-GAN by a huge margin (). 
\subsubsection{Ablation study: }
We perform an ablation study by disabling the structural constraining (PAT-GAN) or pathology awareness functions (SCT-GAN) or both (T-GAN) to justify the design of SCPAT-GAN as shown in Table \ref{table2}. When both structural constraining and pathological awareness functions are activated, SCPAT-GAN reaches the best performance.

\subsubsection{Qualitative analysis: }
We visually inspect the virtual H\&E images generated by SCPAT-GAN in Figure \ref{fig:VisualInspection}. For normal coronary samples, the SCPAT-GAN is capable of generating the three-layer structure; for pathological coronary samples, the SCPAT-GAN is capable of resolving lipid-rich (red arrow) and calcified patterns (yellow star). Compared to real H\&E images, virtual H\&E images generated by SCPAT-GAN show similar patterns for lipid-rich and calcified regions. In the contrast, the GAN in \cite{https://doi.org/10.48550/arxiv.2211.06737} and Cycle-GAN fail to generate pathological patterns.

 % Figure environment removed
\section{Discussion and Conclusion}
In this paper, we design a novel convolutional transformer-GAN, namely SCPAT-GAN, for generating virtual H\&E histology from OCT images. Our SCPAT-GAN algorithm is capable of virtually staining OCT images for both normal and pathological human coronary samples. The SCPAT-GAN is weekly-supervised and does not require pixel-wisely matched OCT and H\&E datasets. By incorporating structural constraining and pathology awareness functions in the SCPAT-GAN, our methods outperform existing methods, which is confirmed by both objective metrics and the pathologist's evaluation. 
 
Compared to other label-free \cite{Cao.2023} or stain-to-stain \cite{Liu.2021} virtual histology works \cite{Bai.2023} which focused on top-view images, our SCPAT-GAN is designed for cross-sectional, depth-resolved OCT images and human coronary samples. Our SCPAT-GAN is the first to generate virtual H\&E images with pathological patterns for coronary samples based on OCT. In the future, we will further reducing the computational overhead of SCPAT-GAN via lightweight neural network \cite{belousov2021mobilestylegan}.


\subsubsection{Acknowledgements}
We would like to thank National Science Foundation
(CRII-1948540) and New Jersey Health Foundation.
 %\textcolor{red}{(YG: add discussion why virthual histology in other image modality can not be directly used in our coronary OCT cases)}
\bibliographystyle{unsrt}
\bibliography{reference}
\end{document}
