
@article{wijns2015optical,
  title={Optical coherence tomography imaging during percutaneous coronary intervention impacts physician decision-making: ILUMIEN I study},
  author={Wijns, William and Shite, Junya and Jones, Michael R and others},
  journal={European heart journal},
  volume={36},
  number={47},
  pages={3346--3355},
  year={2015},
  publisher={Oxford University Press}
}

@article{jones2018angiography,
  title={Angiography alone versus angiography plus optical coherence tomography to guide percutaneous coronary intervention: outcomes from the Pan-London PCI Cohort},
  author={Jones, Daniel A and Rathod, Krishnaraj S and Koganti, Sudheer and others},
  journal={JACC: Cardiovascular Interventions},
  volume={11},
  number={14},
  pages={1313--1321},
  year={2018},
  publisher={American College of Cardiology Foundation Washington, DC}
}

@article{hajar2017risk,
  title={Risk factors for coronary artery disease: historical perspectives},
  author={Hajar, Rachel},
  journal={Heart views: the official journal of the Gulf Heart Association},
  volume={18},
  number={3},
  pages={109},
  year={2017},
  publisher={Wolters Kluwer--Medknow Publications}
}

@ARTICLE{9779525,  author={Li, Xueshen and others},  journal={IEEE Transactions on Biomedical Engineering},   title={Multi-scale reconstruction of undersampled spectral-spatial OCT data for coronary imaging using deep learning},   year={2022},  volume={},  number={},  pages={1-1},  doi={10.1109/TBME.2022.3175670}}

@article{He2016DeepRL,
  title={Deep Residual Learning for Image Recognition},
  author={Kaiming He and others},
  journal={2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2016},
  pages={770-778}
}

@INPROCEEDINGS{8237506,
  author={Zhu, Jun-Yan and others},
  booktitle={2017 IEEE International Conference on Computer Vision (ICCV)}, 
  title={Unpaired Image-to-Image Translation Using Cycle-Consistent Adversarial Networks}, 
  year={2017},
  volume={},
  number={},
  pages={2242-2251},
  doi={10.1109/ICCV.2017.244}}


@article{EmeliaJ.Benjamin.2019,
 author = {Emelia J. Benjamin and others},
 year = {2019},
 title = {Heart Disease and Stroke Statistics---2019 Update: A Report From the American Heart Association},
 pages = {e56-e528},
 volume = {139},
 number = {10},
 journal = {Circulation},
 doi = {10.1161/CIR.0000000000000659}
}

% This file was created with Citavi 6.10.0.0

@article{Okrainec.2004,
 author = {Okrainec, Karen and others},
 year = {2004},
 title = {Coronary artery disease in the developing world},
 keywords = {Coronary Artery Disease/epidemiology/genetics/mortality;Developed Countries/statistics {\&} numerical data;Developing Countries;Diabetes Mellitus/epidemiology;Humans;Hypercholesterolemia/epidemiology;Hypertension/epidemiology;Prevalence;Risk Factors;Smoking/epidemiology;Social Class},
 pages = {7--15},
 volume = {148},
 number = {1},
 issn = {0002-8703},
 journal = {American heart journal},
 doi = {10.1016/j.ahj.2003.11.027}
}

@article{Goss2009TheoryAP,
  title={Theory and Practice of Histological Techniques},
  author={Gwendolyn R. Goss},
  journal={The American Journal of Surgical Pathology},
  year={2009},
  volume={33},
  pages={323}
}

% This file was created with Citavi 6.10.0.0

@article{Lesperance.2000,
 author = {Lesp{\'e}rance, F. and Frasure-Smith, N.},
 year = {2000},
 title = {Depression in patients with cardiac disease: a practical review},
 keywords = {Coronary Disease/complications/psychology;Depressive Disorder/diagnosis/etiology/therapy;Diagnosis, Differential;Humans;Prognosis;Quality of Life;Recurrence},
 pages = {379--391},
 volume = {48},
 number = {4-5},
 issn = {0022-3999},
 journal = {Journal of psychosomatic research},
 doi = {10.1016/s0022-3999(99)00102-6}
}

% This file was created with Citavi 6.10.0.0

@article{Tearney.2012,
 
 author = {Guillermo J. Tearney and Evelyn Regar and Takashi Akasaka and others},
 year = {2012},
 title = {Consensus Standards for Acquisition, Measurement, and Reporting of Intravascular Optical Coherence Tomography Studies: A Report From the International Working Group for Intravascular Optical Coherence Tomography Standardization and Validation},
 keywords = {atherosclerosis;consensus document;coronary artery;intravascular ultrasound;optical coherence tomography},
 pages = {1058--1072},
 volume = {59},
 number = {12},
 issn = {0735-1097},
 journal = {Journal of the American College of Cardiology},
 doi = {10.1016/j.jacc.2011.09.079}
}

@article{Winetraub.2021,
 author = {Winetraub, Yonatan and Edwin Yuan and Itamar Terem and others},
 year = {2021},
 title = {{OCT2Hist}: Non-Invasive Virtual Biopsy Using Optical Coherence Tomography},
 journal = {medRxiv},
 doi = {10.1101/2021.03.31.21254733}
}

@book{Isola.2017,
 author = {Isola, Phillip and Zhu, Jun-Yan and Zhou, Tinghui and Efros, Alexei},
 year = {2017},
 title = {Image-to-Image Translation with Conditional Adversarial Networks},
 doi = {10.1109/CVPR.2017.632}
}

@article{belousov2021mobilestylegan,
  title={Mobilestyle{GAN}: A lightweight convolutional neural network for high-fidelity image synthesis},
  author={Belousov, Sergei},
  journal={arXiv preprint arXiv:2104.04767},
  year={2021}
}
% This file was created with Citavi 6.10.0.0

@article{Liu.2021,
 author = {Liu, Shuting and Zhang, Baochang and Liu, Yiqing and Han, Anjia and Shi, Huijuan and Guan, Tian and He, Yonghong},
 year = {2021},
 title = {Unpaired Stain Transfer Using Pathology-Consistent Constrained Generative Adversarial Networks},
 keywords = {0 (Coloring Agents);Coloring Agents;Eosine Yellowish-(YS);Hematoxylin;Humans;Image Processing, Computer-Assisted;Staining and Labeling;TDQ283MPCW (Eosine Yellowish-(YS));YKM8PY2Z55 (Hematoxylin)},
 pages = {1977--1989},
 volume = {40},
 number = {8},
 issn = {0278-0062},
 journal = {IEEE transactions on medical imaging},
 doi = {10.1109/TMI.2021.3069874}
}

@misc{https://doi.org/10.48550/arxiv.2211.06737,
      title={Structural constrained virtual histology staining for human coronary imaging using deep learning}, 
      author={Xueshen Li and Hongshan Liu and Xiaoyu Song and Brigitta C. Brott and Silvio H. Litovsky and Yu Gan},
      year={2022},
      eprint={2211.06737},
      archivePrefix={arXiv},
      primaryClass={eess.IV}
}

% This file was created with Citavi 6.10.0.0

@inproceedings{Salimans.2016,
 author = {Salimans, Tim and Goodfellow, Ian and Zaremba, Wojciech and Cheung, Vicki and Radford, Alec and Chen, Xi},
 title = {Improved Techniques for Training GANs},
 url = {https://proceedings.neurips.cc/paper/2016/file/8a3363abe792db2d8761d6403605aeb7-Paper.pdf},
 volume = {29},
 publisher = {{Curran Associates, Inc}},
 editor = {{D. Lee} and {M. Sugiyama} and {U. Luxburg} and {I. Guyon} and {R. Garnett}},
 booktitle = {Advances in Neural Information Processing Systems},
 year = {2016}
}

% This file was created with Citavi 6.10.0.0

@inproceedings{Heusel.2017,
 abstract = {Generative Adversarial Networks (GANs) excel at creating realistic images with complex models for which maximum likelihood is infeasible. However, the convergence of GAN training has still not been proved. We propose a two time-scale update rule (TTUR) for training GANs with stochastic gradient descent on arbitrary GAN loss functions. TTUR has an individual learning rate for both the discriminator and the generator. Using the theory of stochastic approximation, we prove that the TTUR converges under mild assumptions to a stationary local Nash equilibrium. The convergence carries over to the popular Adam optimization, for which we prove that it follows the dynamics of a heavy ball with friction and thus prefers flat minima in the objective landscape. For the evaluation of the performance of GANs at image generation, we introduce the 'Fr{\'e}chet Inception Distance{\textquotedbl} (FID) which captures the similarity of generated images to real ones better than the Inception Score. In experiments, TTUR improves learning for DCGANs and Improved Wasserstein GANs (WGAN-GP) outperforming conventional GAN training on CelebA, CIFAR-10, SVHN, LSUN Bedrooms, and the One Billion Word Benchmark.},
 author = {Heusel, Martin and Ramsauer, Hubert and Unterthiner, Thomas and Nessler, Bernhard and Hochreiter, Sepp},
 title = {{GANs} Trained by a Two Time-Scale Update Rule Converge to a Local Nash Equilibrium},
 pages = {6629--6640},
 publisher = {{Curran Associates Inc}},
 isbn = {9781510860964},
 series = {NIPS'17},
 booktitle = {Proceedings of the 31st International Conference on Neural Information Processing Systems},
 year = {2017},
 address = {Red Hook, NY, USA}
}

% This file was created with Citavi 6.10.0.0

@inproceedings{J.Liang.2021,
 abstract = {Image restoration is a long-standing low-level vision problem that aims to restore high-quality images from low-quality images (e.g., downscaled, noisy and compressed images). While state-of-the-art image restoration methods are based on convolutional neural networks, few attempts have been made with Transformers which show impressive performance on high-level vision tasks. In this paper, we propose a strong baseline model SwinIR for image restoration based on the Swin Transformer. SwinIR consists of three parts: shallow feature extraction, deep feature extraction and high-quality image reconstruction. In particular, the deep feature extraction module is composed of several residual Swin Transformer blocks (RSTB), each of which has several Swin Transformer layers together with a residual connection. We conduct experiments on three representative tasks: image super-resolution (including classical, lightweight and real-world image super-resolution), image denoising (including grayscale and color image denoising) and JPEG compression artifact reduction. Experimental results demonstrate that SwinIR outperforms state-of-the-art methods on different tasks by up to 0.14$\sim$0.45dB, while the total number of parameters can be reduced by up to 67{\%}.},
 author = {{J. Liang} and {J. Cao} and {G. Sun} and {K. Zhang} and {L. Van Gool} and {R. Timofte}},
 title = {SwinIR: Image Restoration Using Swin Transformer},
 url = {https://doi.ieeecomputersociety.org/10.1109/ICCVW54120.2021.00210},
 keywords = {color;feature extraction;gray-scale;image coding;noise reduction;transform coding;transformers},
 pages = {1833--1844},
 publisher = {{IEEE Computer Society}},
 booktitle = {2021 IEEE/CVF International Conference on Computer Vision Workshops (ICCVW)},
 year = {2021},
 address = {Los Alamitos, CA, USA},
 doi = {10.1109/ICCVW54120.2021.00210}
}

% This file was created with Citavi 6.10.0.0

@inproceedings{R.Strudel.2021,
 abstract = {Image segmentation is often ambiguous at the level of individual image patches and requires contextual information to reach label consensus. In this paper we introduce Segmenter, a transformer model for semantic segmentation. In contrast to convolution-based methods, our approach allows to model global context already at the first layer and throughout the network. We build on the recent Vision Transformer (ViT) and extend it to semantic segmentation. To do so, we rely on the output embeddings corresponding to image patches and obtain class labels from these embed-dings with a point-wise linear decoder or a mask trans-former decoder. We leverage models pre-trained for image classification and show that we can fine-tune them on moderate sized datasets available for semantic segmentation. The linear decoder allows to obtain excellent results already, but the performance can be further improved by a mask transformer generating class masks. We conduct an extensive ablation study to show the impact of the different parameters, in particular the performance is better for large models and small patch sizes. Segmenter attains excellent results for semantic segmentation. It outperforms the state of the art on both ADE20K and Pascal Context datasets and is competitive on Cityscapes.},
 author = {{R. Strudel} and {R. Garcia} and {I. Laptev} and {C. Schmid}},
 title = {Segmenter: Transformer for Semantic Segmentation},
 url = {https://doi.ieeecomputersociety.org/10.1109/ICCV48922.2021.00717},
 keywords = {computer vision;decoding;encoding;image coding;image segmentation;semantics;transformers},
 pages = {7242--7252},
 publisher = {{IEEE Computer Society}},
 booktitle = {2021 IEEE/CVF International Conference on Computer Vision (ICCV)},
 year = {2021},
 address = {Los Alamitos, CA, USA},
 doi = {10.1109/ICCV48922.2021.00717}
}

@InProceedings{RFB15a,
  author       = "O. Ronneberger and P.Fischer and T. Brox",
  title        = "{U-Net}: Convolutional Networks for Biomedical Image Segmentation",
  booktitle    = "Medical Image Computing and Computer-Assisted Intervention (MICCAI)",
  series       = "LNCS",
  volume       = "9351",
  pages        = "234--241",
  year         = "2015",
  publisher    = "Springer",
  note         = "(available on arXiv:1505.04597 [cs.CV])",
  url          = "http://lmb.informatik.uni-freiburg.de/Publications/2015/RFB15a"
}

@INPROCEEDINGS{9607618,
  author={Liang, Jingyun and Cao, Jiezhang and Sun, Guolei and Zhang, Kai and Van Gool, Luc and Timofte, Radu},
  booktitle={2021 IEEE/CVF International Conference on Computer Vision Workshops (ICCVW)}, 
  title={{SwinIR}: Image Restoration Using Swin Transformer}, 
  year={2021},
  volume={},
  number={},
  pages={1833-1844},
  doi={10.1109/ICCVW54120.2021.00210}}

% This file was created with Citavi 6.10.0.0

@article{Bai.2023,
 author = {Bai, Bijie and Yang, Xilin and Li, Yuzhu and Zhang, Yijie and Pillar, Nir and Ozcan, Aydogan},
 year = {2023},
 title = {Deep learning-enabled virtual histological staining of biological samples},
 pages = {57},
 volume = {12},
 number = {1},
 issn = {2047-7538},
 journal = {Light: Science {\&} Applications},
 doi = {10.1038/s41377-023-01104-7}
}

% This file was created with Citavi 6.10.0.0

@article{Cao.2023,
 author = {Cao, Rui and Nelson, Scott D. and Davis, Samuel and Liang, Yu and Luo, Yilin and Zhang, Yide and Crawford, Brooke and Wang, Lihong V.},
 year = {2023},
 title = {Label-free intraoperative histology of bone tissue via deep-learning-assisted ultraviolet photoacoustic microscopy},
 pages = {124--134},
 volume = {7},
 number = {2},
 issn = {2157-846X},
 journal = {Nature Biomedical Engineering},
 doi = {10.1038/s41551-022-00940-z}
}







