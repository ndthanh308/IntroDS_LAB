\begin{thebibliography}{40}
\providecommand{\natexlab}[1]{#1}

\bibitem[{Andrianov(2012)}]{MFCONV}
Andrianov, S. 2012.
\newblock The convergence and accuracy of the matrix formalism approximation.
\newblock \emph{Proc. of ICAP2012}.

\bibitem[{Arik and Pfister(2021)}]{TabNet}
Arik, S.~O.; and Pfister, T. 2021.
\newblock Tabnet: Attentive interpretable tabular learning.
\newblock \emph{Proc. of the AAAI Conf. on Artificial Intelligence}, 35(8):
  6679--6687.

\bibitem[{Berz(1997)}]{ref_tm1}
Berz, M. 1997.
\newblock From Taylor Series to Taylor Models.

\bibitem[{Blondel et~al.(2016)Blondel, Ishihata, Fujino, and Ueda}]{FM}
Blondel, M.; Ishihata, M.; Fujino, A.; and Ueda, N. 2016.
\newblock Polynomial Networks and FM: New Insights and Efficient Training
  Algorithms.
\newblock \emph{In: Proc. of ICML 2016}.

\bibitem[{Borchani et~al.(2015)Borchani, Varando, Bielza, and
  Larra{\~n}aga}]{Borchani2015ASO}
Borchani, H.; Varando, G.; Bielza, C.; and Larra{\~n}aga, P. 2015.
\newblock A survey on multi‐output regression.
\newblock \emph{Wiley Interdisc. Rev.: Data Mining and Knowledge Discovery}, 5.

\bibitem[{Chen et~al.(2018)Chen, Rubanova, Bettencourt, and Duvenaud}]{ref9}
Chen, T.~Q.; Rubanova, Y.; Bettencourt, J.; and Duvenaud, D.~K. 2018.
\newblock Neural ordinary differential equations.
\newblock In \emph{Advances in Neural Information Proc. Systems}, 6571--6583.

\bibitem[{Chrysos et~al.(2021)Chrysos, Georgopoulos, Deng, and
  Panagakis}]{DBLP:journals/corr/abs-2104-07916}
Chrysos, G.~G.; Georgopoulos, M.; Deng, J.; and Panagakis, Y. 2021.
\newblock Polynomial Networks in Deep Classifiers.
\newblock \emph{CoRR}, abs/2104.07916.

\bibitem[{Chrysos et~al.(2020)Chrysos, Moschoglou, Bouritsas, Panagakis, Deng,
  and Zafeiriou}]{pinet}
Chrysos, G.~G.; Moschoglou, S.; Bouritsas, G.; Panagakis, Y.; Deng, J.; and
  Zafeiriou, S. 2020.
\newblock $\Pi$-nets: Deep Polynomial Neural Networks.
\newblock \emph{Conference on Computer Vision and Pattern Recognition (CVPR)}.

\bibitem[{Davierwalla(1977)}]{Stepwise}
Davierwalla, D. 1977.
\newblock REGSTEP - stepwise multivariate polynomial regression with singular
  extensions.

\bibitem[{Dette(1995)}]{dette1995}
Dette, H. 1995.
\newblock Optimal Designs for Identifying the Degree of a Polynomial.
\newblock \emph{Ann. Statist.}, 23(4): 1248--1266.

\bibitem[{Dolgov(2019)}]{ref_tm2}
Dolgov, S. 2019.
\newblock A tensor decomposition algorithm for large ODEs with conservation
  laws.
\newblock \emph{Computational Methods in Applied Mathematics}, 19(1): 23--38.

\bibitem[{Dorogush, Ershov, and Gulin(2018)}]{CatBoost}
Dorogush, A.; Ershov, V.; and Gulin, A. 2018.
\newblock CatBoost: gradient boosting with categorical features support.

\bibitem[{Dragt, Gjaja, and Rangarajan(1991)}]{DragtKick}
Dragt, A.; Gjaja, I.; and Rangarajan, G. 1991.
\newblock Kick Factorization of Symplectic Maps.

\bibitem[{Fan et~al.(1997)Fan, Gasser, Gijbels, Brockmann, and Engel}]{Fan}
Fan, J.; Gasser, T.; Gijbels, I.; Brockmann, M.; and Engel, J. 1997.
\newblock Local Polynomial Regression: Optimal Kernels and Asymptotic Minimax
  Efficiency.
\newblock \emph{Annals of the Institute of Statistical Mathematics}, 49:
  79--99.

\bibitem[{Folland(2007)}]{lpdense}
Folland, G. 2007.
\newblock \emph{Real Analysis: Modern Techniques and Their Applications}.
\newblock Wiley, 2nd edition.

\bibitem[{Freudenthaler, Schmidt-Thieme, and Rendle(2011)}]{Freudenthaler}
Freudenthaler, C.; Schmidt-Thieme, L.; and Rendle, S. 2011.
\newblock Factorization Machines Factorized Polynomial Regression Models.

\bibitem[{Friedman(1991)}]{Friedman}
Friedman, J.~H. 1991.
\newblock Multivariate adaptive regression splines.
\newblock \emph{The Annals of Statistics}, 19(1): 1--67.

\bibitem[{Fronk and Petzold(2023)}]{Fronk_2023}
Fronk, C.; and Petzold, L. 2023.
\newblock Interpretable polynomial neural ordinary differential equations.
\newblock \emph{Chaos: An Interdisciplinary Journal of Nonlinear Science},
  33(4): 043101.

\bibitem[{Gerritsma et~al.(2013)Gerritsma, Onnink, , and Versluis}]{yacht}
Gerritsma, J.; Onnink, R.; ; and Versluis, A. 2013.
\newblock {Yacht Hydrodynamics}.
\newblock UCI Machine Learning Repository.
\newblock {DOI}: https://doi.org/10.24432/C5XG7R.

\bibitem[{Green and Rindler(2019)}]{odepkr}
Green, D.; and Rindler, F. 2019.
\newblock Model inference for ODEs by parametric polynomial kernel regression.

\bibitem[{Hofwing, Strömberg, and Tapankov(2011)}]{Hofwing}
Hofwing, M.; Strömberg, N.; and Tapankov, M. 2011.
\newblock Optimal Polynomial Regression Models by using a Genetic Algorithm.
\newblock volume~97.
\newblock ISBN 978-1-905088-50-8.

\bibitem[{Iben and Wagner(2021)}]{UIben}
Iben, U.; and Wagner, C. 2021.
\newblock Taylor mapping method for solving and learning of dynamic processes.
\newblock \emph{Inverse Problems in Science and Engineering}, 29:13:
  3190--3213.

\bibitem[{Ivanov and Agapov(2020)}]{TMA}
Ivanov, A.; and Agapov, I. 2020.
\newblock Physics-based deep neural networks for beam dynamics in charged
  particle accelerators.
\newblock \emph{Phys. Rev. Accel. Beams}, 23: 074601.

\bibitem[{Ivanov, Golovkina, and Iben(2020)}]{TMPNN}
Ivanov, A.; Golovkina, A.; and Iben, U. 2020.
\newblock Polynomial Neural Networks and Taylor Maps for Dynamical Systems
  Simulation and Learning.
\newblock \emph{24th Europ. Conf. on AI 2020, Spain}.

\bibitem[{Kingma and Ba(2015)}]{DBLP:journals/corr/KingmaB14}
Kingma, D.~P.; and Ba, J. 2015.
\newblock Adam: {A} Method for Stochastic Optimization.
\newblock In Bengio, Y.; and LeCun, Y., eds., \emph{3rd International
  Conference on Learning Representations, {ICLR} 2015, San Diego, CA, USA, May
  7-9, 2015, Conference Track Proceedings}.

\bibitem[{Lewis(2007)}]{Hierarchical}
Lewis, M. 2007.
\newblock Stepwise versus Hierarchical Regression: Pros and Cons.
\newblock \emph{https://files.eric.ed.gov/fulltext/ED534385.pdf}.

\bibitem[{L\'{o}pez, Huerta, and Dorronsoro(1993)}]{neco}
L\'{o}pez, V.; Huerta, R.; and Dorronsoro, J.~R. 1993.
\newblock Recurrent and Feedforward Polynomial Modeling of Coupled Time Series.
\newblock \emph{Neural Comput.}, 5(5): 795–811.

\bibitem[{Nader, Sixt, and Landgraf(2022)}]{DNNR}
Nader, Y.; Sixt, L.; and Landgraf, T. 2022.
\newblock DNNR: Differential Nearest Neighbors Regression.
\newblock \emph{Proc. of the 39 th Intern. Conf. on Machine Learning}.

\bibitem[{Novikov, Trofimov, and Oseledets(2017)}]{ref201}
Novikov, A.; Trofimov, M.; and Oseledets, I. 2017.
\newblock Exponential Machines.

\bibitem[{Oh, Pedrycz, and Park(2003)}]{Oh}
Oh, S.-K.; Pedrycz, W.; and Park, B.-J. 2003.
\newblock Polynomial neural networks architecture: Analysis and design.
\newblock \emph{Computers \& Electrical Engineering}, 29: 703--725.

\bibitem[{Pakdemirli(2016)}]{Pakdemirli}
Pakdemirli, M. 2016.
\newblock A New Perturbation Approach to Optimal Polynomial Regression.
\newblock \emph{Mathematical and Computational Applications}, 21: 1.

\bibitem[{Stone(1948)}]{Stone}
Stone, M. 1948.
\newblock The generalized weierstrass approximation theorem.
\newblock \emph{Mathematics Magazine}, 21(5): 237--254.

\bibitem[{Udrescu and Tegmark(2020)}]{Feynman}
Udrescu, S.-M.; and Tegmark, M. 2020.
\newblock Ai feynman: A physics-inspired method for symbolic regression.
\newblock \emph{Science Advances}, 6(16).

\bibitem[{Weierstrass(1885)}]{Weierstrass}
Weierstrass, K. 1885.
\newblock On the analytical representability of so-called arbitrary functions
  of a real variable.
\newblock \emph{Meeting reports of the Royal Prussian Academy of Sciences in
  Berlin}, 2: 633–639.

\bibitem[{Wilson and Adams(2013)}]{wilson13}
Wilson, A.; and Adams, R. 2013.
\newblock Gaussian Process Kernels for Pattern Discovery and Extrapolation.
\newblock In Dasgupta, S.; and McAllester, D., eds., \emph{Proceedings of the
  30th International Conference on Machine Learning}, volume 28-3 of
  \emph{Proceedings of Machine Learning Research}, 1067--1075. Atlanta,
  Georgia, USA: PMLR.

\bibitem[{Wu et~al.(2022)Wu, Zhu, Liu, Chrysos, and
  Cevher}]{wu2022extrapolation}
Wu, Y.; Zhu, Z.; Liu, F.; Chrysos, G.~G.; and Cevher, V. 2022.
\newblock Extrapolation and Spectral Bias of Neural Nets with Hadamard Product:
  a Polynomial Net Study.
\newblock arXiv:2209.07736.

\bibitem[{Xioufis et~al.(2012)Xioufis, Groves, Tsoumakas, and
  Vlahavas}]{DBLP:journals/corr/abs-1211-6581}
Xioufis, E.~S.; Groves, W.; Tsoumakas, G.; and Vlahavas, I.~P. 2012.
\newblock Multi-Label Classification Methods for Multi-Target Regression.
\newblock \emph{CoRR}, abs/1211.6581.

\bibitem[{Yang, Hou, and Luo(2018)}]{ref11}
Yang, Y.; Hou, M.; and Luo, J. 2018.
\newblock A novel improved extreme learning machine algorithm in solving
  ordinary differential equations by Legendre neural network methods.
\newblock \emph{Advances in Difference Equations}, 4(1): 469.

\bibitem[{Zhang, Nettleton, and Zhu(2019)}]{RERF}
Zhang, H.; Nettleton, D.; and Zhu, Z. 2019.
\newblock Regression-Enhanced Random Forests.

\bibitem[{Zjavka(2011)}]{ref10}
Zjavka, L. 2011.
\newblock Differential polynomial neural network.
\newblock \emph{Journal of Artificial Intelligence}, 4 (1): 89–99.

\end{thebibliography}
