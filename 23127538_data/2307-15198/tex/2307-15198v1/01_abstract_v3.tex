\begin{abstract}
Brain extraction, registration and segmentation are indispensable preprocessing steps in neuroimaging studies. The aim is to extract the brain from raw imaging scans ({\ie} extraction step), align it with a target brain image ({\ie} registration step) and label the anatomical brain regions ({\ie} segmentation step).
Conventional studies typically focus on developing separate methods for the extraction, registration and segmentation tasks in a supervised setting.
The performance of these methods is largely contingent on the quantity of training samples and the extent of visual inspections carried out by experts for error correction.
Nevertheless, collecting voxel-level labels and performing manual quality control on high-dimensional neuroimages (\eg 3D MRI) are expensive and time-consuming in many medical studies.
In this paper, we study the problem of one-shot joint extraction, registration and segmentation in neuroimaging data, which exploits only one labeled template image (\emph{a.k.a.} atlas) and a few unlabeled raw images for training.
We propose a unified end-to-end framework, called JERS, to jointly optimize the extraction, registration and segmentation tasks, allowing feedback among them.
Specifically, we use a group of extraction, registration and segmentation modules to learn the extraction mask, transformation and segmentation mask, where modules are interconnected and mutually reinforced by self-supervision.
Empirical results on real-world datasets demonstrate that our proposed method performs exceptionally in the extraction, registration and segmentation tasks.
\input{fig_problem}
\end{abstract}

\keywords{brain extraction, skull stripping, registration, alignment, segmentation, joint learning, one-shot}
