\section{Related Work}
\label{sec:related}
\noindent \textbf{Neuroimage extraction.} 
In the past decade, numerous methods have emerged, highlighting the significance of the brain extraction problem. 
Smith et al.~\cite{smith2002fast} introduced a deformable model that fits the brain surface using a locally adaptive set model. 3dSkullStrip~\cite{cox1996afni} is a modified version of~\cite{smith2002fast} that employs points outside the brain surface to guide mesh evolution. Shattuck et al.~\cite{shattuck2002brainsuite} utilized anisotropic diffusion filtering and a 2D Marr Hildreth edge detector for brain boundary identification.
However, these methods heavily rely on parameter tuning and manual quality control, which are time-consuming and labor-intensive. Recently, brain extraction has benefited from the introduction of deep learning approaches, which exhibit exceptional performance and speed. 
Kleesiek et al.~\cite{kleesiek2016deep} proposed a voxel-wise 3D CNN for skull stripping, while Hwang et al.~\cite{hwang20193d} demonstrated the effectiveness of 3D-UNet in achieving competitive results. However, these learning-based approaches often necessitate a substantial amount of properly labeled data for effective training, which is a challenge considering that neuroimage datasets are typically small and costly to annotate.



\noindent \textbf{Neuroimage registration.}
Conventional techniques for image registration~\cite{avants2009advanced, avants2008symmetric, jenkinson2001global} typically aim to maximize image similarity by iteratively optimizing transformation parameters. Commonly used intensity-based similarity measures include normalized cross-correlation (NCC) and mutual information (MI), among others. However, this iterative optimization approach often suffers from high computational costs and being stuck in local optima, resulting in inefficient and unreliable registration outcomes. Recently, numerous deep learning-based methods have been proposed, offering improved computational efficiency and registration performance. For instance, Sokooti et al.~\cite{sokooti2017nonrigid} introduced a multi-scale 3D CNN called RegNet, which learns the displacement vector field (DVF) for 3D chest CT registration. Although these methods demonstrate competitive results, they require supervision. To overcome this limitation, unsupervised registration methods~\cite{balakrishnan2018unsupervised,zhao2019recursive} have garnered significant attention and shown promising outcomes.


\input{tab_ablation}
\input{tab_time_res}
\noindent \textbf{Neuroimage segmentation.}
CNN-based approaches have demonstrated superior performance in terms of speed and accuracy for supervised neuroimage segmentation. Based on the dimensionality of network operation, current work mainly falls into two categories:  2D CNN-based network and 3D CNN-based network. 2D CNN-based network processes the volumetric neuroimage data slice by slice, and assembles the final segmentation mask by putting segmentation results on all the slices together. The most representative networks include UNet \cite{ronneberger2015u} and Attention-UNet \cite{oktay2018attention}. Since the 2D CNN-based network treats each slice separately, the spatial information encoded between slices is not utilized, negatively affecting the segmentation performance. This limitation prompts the use of the 3D CNN-based network for 3D segmentation. The most representative network among all is the 3D UNet \cite{cciccek20163d}.
%a 3D version of the original UNet architecture.
Despite the success CNN-based approaches had in neuroimage segmentation, those approaches still possess a data-hungry nature and require a large number of labeled neuroimages for training, which is expensive to acquire.  

\input{fig_stage_dice}
\noindent \textbf{Joint neuroimage registration and segmentation}
The neuroimage registration and segmentation tasks are deeply co-related and mutually facilitating, thus should not be treated separately. Specifically, the anatomy structure produced by neuroimage segmentation can provide auxiliary information for neuroimage segmentation. This idea is practiced in \cite{hu2018weakly} and demonstrated to be effective. Complementary, the registration task can also aid the segmentation task, typically studied in the scope of atlas-based segmentation and data augmentation. In atlas-based segmentation, the atlas label is transferred to the unlabeled image space using the geometric transformation estimated by a registration module \cite{wang2020lt, dinsdale2019spatial}. Taking the idea a step further, for data augmentation, new image-label pairs are generated by means of sampling the geometric and style transformation \cite{ding2021modeling, zhao2019data}. The above methods still focus on a single task. To address this limitation, exploring work has been conducted to combine registration and segmentation together, by optimizing them either jointly \cite{qiu2021u} or alternatively \cite{xu2019deepatlas,he2020deep}, and is able to obtain better results.   


