\begin{thebibliography}{100}\itemsep=-1pt

\bibitem{an20221st}
Dong An, Zun Wang, Yangguang Li, Yi Wang, Yicong Hong, Yan Huang, Liang Wang,
  and Jing Shao.
\newblock 1st place solutions for rxr-habitat vision-and-language navigation
  competition (cvpr 2022).
\newblock {\em arXiv preprint arXiv:2206.11610}, 2022.

\bibitem{anderson2018evaluation}
Peter Anderson, Angel Chang, Devendra~Singh Chaplot, Alexey Dosovitskiy,
  Saurabh Gupta, Vladlen Koltun, Jana Kosecka, Jitendra Malik, Roozbeh
  Mottaghi, Manolis Savva, et~al.
\newblock On evaluation of embodied navigation agents.
\newblock {\em arXiv preprint arXiv:1807.06757}, 2018.

\bibitem{anderson2018vln}
Peter Anderson, Qi Wu, Damien Teney, Jake Bruce, Mark Johnson, Niko
  S{\"u}nderhauf, Ian Reid, Stephen Gould, and Anton van~den Hengel.
\newblock Vision-and-language navigation: Interpreting visually-grounded
  navigation instructions in real environments.
\newblock In {\em Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, pages 3674--3683, 2018.

\bibitem{batra2020objectnav}
Dhruv Batra, Aaron Gokaslan, Aniruddha Kembhavi, Oleksandr Maksymets, Roozbeh
  Mottaghi, Manolis Savva, Alexander Toshev, and Erik Wijmans.
\newblock Objectnav revisited: On evaluation of embodied agents navigating to
  objects.
\newblock {\em arXiv preprint arXiv:2006.13171}, 2020.

\bibitem{bucker2022latte}
Arthur Bucker, Luis Figueredo, Sami Haddadin, Ashish Kapoor, Shuang Ma, and
  Rogerio Bonatti.
\newblock Latte: Language trajectory transformer.
\newblock {\em arXiv preprint arXiv:2208.02918}, 2022.

\bibitem{caron2021dino}
Mathilde Caron, Hugo Touvron, Ishan Misra, Herv{\'e} J{\'e}gou, Julien Mairal,
  Piotr Bojanowski, and Armand Joulin.
\newblock Emerging properties in self-supervised vision transformers.
\newblock In {\em Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pages 9650--9660, 2021.

\bibitem{cartillier2021semmap}
Vincent Cartillier, Zhile Ren, Neha Jain, Stefan Lee, Irfan Essa, and Dhruv
  Batra.
\newblock Semantic mapnet: Building allocentric semantic maps and
  representations from egocentric views.
\newblock In {\em Proceedings of the AAAI Conference on Artificial
  Intelligence}, volume~35, pages 964--972, 2021.

\bibitem{chang2017matterport3d}
Angel Chang, Angela Dai, Thomas Funkhouser, Maciej Halber, Matthias Niebner,
  Manolis Savva, Shuran Song, Andy Zeng, and Yinda Zhang.
\newblock Matterport3d: Learning from rgb-d data in indoor environments.
\newblock In {\em 2017 International Conference on 3D Vision (3DV)}, pages
  667--676. IEEE, 2017.

\bibitem{chaplot2019activeslam}
Devendra~Singh Chaplot, Dhiraj Gandhi, Saurabh Gupta, Abhinav Gupta, and Ruslan
  Salakhutdinov.
\newblock Learning to explore using active neural slam.
\newblock In {\em International Conference on Learning Representations}, 2019.

\bibitem{chaplot2020object}
Devendra~Singh Chaplot, Dhiraj~Prakashchand Gandhi, Abhinav Gupta, and Russ~R
  Salakhutdinov.
\newblock Object goal navigation using goal-oriented semantic exploration.
\newblock {\em Advances in Neural Information Processing Systems},
  33:4247--4258, 2020.

\bibitem{chaplot2020neural}
Devendra~Singh Chaplot, Ruslan Salakhutdinov, Abhinav Gupta, and Saurabh Gupta.
\newblock Neural topological slam for visual navigation.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 12875--12884, 2020.

\bibitem{chattopadhyay2021robustnav}
Prithvijit Chattopadhyay, Judy Hoffman, Roozbeh Mottaghi, and Aniruddha
  Kembhavi.
\newblock Robustnav: Towards benchmarking robustness in embodied navigation.
\newblock In {\em Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pages 15691--15700, 2021.

\bibitem{chen2020soundspaces}
Changan Chen, Unnat Jain, Carl Schissler, Sebastia Vicenc~Amengual Gari, Ziad
  Al-Halah, Vamsi~Krishna Ithapu, Philip Robinson, and Kristen Grauman.
\newblock Soundspaces: Audio-visual navigation in 3d environments.
\newblock In {\em European Conference on Computer Vision}, pages 17--36.
  Springer, 2020.

\bibitem{chen2022weakly}
Peihao Chen, Dongyu Ji, Kunyang Lin, Runhao Zeng, Thomas Li, Mingkui Tan, and
  Chuang Gan.
\newblock Weakly-supervised multi-granularity map learning for
  vision-and-language navigation.
\newblock In {\em Annual Conference on Neural Information Processing Systems},
  2022.

\bibitem{chen2021hamt}
Shizhe Chen, Pierre-Louis Guhur, Cordelia Schmid, and Ivan Laptev.
\newblock History aware multimodal transformer for vision-and-language
  navigation.
\newblock {\em Advances in Neural Information Processing Systems},
  34:5834--5847, 2021.

\bibitem{chen2022learning}
Shizhe Chen, Pierre-Louis Guhur, Makarand Tapaswi, Cordelia Schmid, and Ivan
  Laptev.
\newblock Learning from unlabeled 3d environments for vision-and-language
  navigation.
\newblock {\em arXiv preprint arXiv:2208.11781}, 2022.

\bibitem{chen2022duet}
Shizhe Chen, Pierre-Louis Guhur, Makarand Tapaswi, Cordelia Schmid, and Ivan
  Laptev.
\newblock Think global, act local: Dual-scale graph transformer for
  vision-and-language navigation.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 16537--16547, 2022.

\bibitem{chen2020simclr}
Ting Chen, Simon Kornblith, Mohammad Norouzi, and Geoffrey Hinton.
\newblock A simple framework for contrastive learning of visual
  representations.
\newblock In {\em International conference on machine learning}, pages
  1597--1607. PMLR, 2020.

\bibitem{cho2014gru}
Kyunghyun Cho, Bart van Merrienboer, {\c{C}}aglar G{\"u}l{\c{c}}ehre, Dzmitry
  Bahdanau, Fethi Bougares, Holger Schwenk, and Yoshua Bengio.
\newblock Learning phrase representations using rnn encoder-decoder for
  statistical machine translation.
\newblock In {\em EMNLP}, 2014.

\bibitem{cui2022can}
Yuchen Cui, Scott Niekum, Abhinav Gupta, Vikash Kumar, and Aravind Rajeswaran.
\newblock Can foundation models perform zero-shot task specification for robot
  manipulation?
\newblock In {\em Learning for Dynamics and Control Conference}, pages
  893--905. PMLR, 2022.

\bibitem{deitke2020robothor}
Matt Deitke, Winson Han, Alvaro Herrasti, Aniruddha Kembhavi, Eric Kolve,
  Roozbeh Mottaghi, Jordi Salvador, Dustin Schwenk, Eli VanderBilt, Matthew
  Wallingford, et~al.
\newblock Robothor: An open simulation-to-real embodied ai platform.
\newblock In {\em Proceedings of the IEEE/CVF conference on computer vision and
  pattern recognition}, pages 3164--3174, 2020.

\bibitem{deitke2022procthor}
Matt Deitke, Eli VanderBilt, Alvaro Herrasti, Luca Weihs, Jordi Salvador, Kiana
  Ehsani, Winson Han, Eric Kolve, Ali Farhadi, Aniruddha Kembhavi, et~al.
\newblock Procthor: Large-scale embodied ai using procedural generation.
\newblock {\em arXiv preprint arXiv:2206.06994}, 2022.

\bibitem{deng2009imagenet}
Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei.
\newblock Imagenet: A large-scale hierarchical image database.
\newblock In {\em 2009 IEEE conference on computer vision and pattern
  recognition}, pages 248--255. Ieee, 2009.

\bibitem{desai2021auxiliary}
Saurabh~Satish Desai and Stefan Lee.
\newblock Auxiliary tasks for efficient learning of point-goal navigation.
\newblock In {\em Proceedings of the IEEE/CVF Winter Conference on Applications
  of Computer Vision}, pages 717--725, 2021.

\bibitem{dosovitskiy2020vit}
Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn,
  Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg
  Heigold, Sylvain Gelly, et~al.
\newblock An image is worth 16x16 words: Transformers for image recognition at
  scale.
\newblock In {\em International Conference on Learning Representations}, 2020.

\bibitem{downs2022gso}
Laura Downs, Anthony Francis, Nate Koenig, Brandon Kinman, Ryan Hickman, Krista
  Reymann, Thomas~B McHugh, and Vincent Vanhoucke.
\newblock Google scanned objects: A high-quality dataset of 3d scanned
  household items.
\newblock {\em arXiv preprint arXiv:2204.11918}, 2022.

\bibitem{du2021crl}
Yilun Du, Chuang Gan, and Phillip Isola.
\newblock Curious representation learning for embodied intelligence.
\newblock In {\em Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pages 10408--10417, 2021.

\bibitem{eftekhar2021omnidata}
Ainaz Eftekhar, Alexander Sax, Jitendra Malik, and Amir Zamir.
\newblock Omnidata: A scalable pipeline for making multi-task mid-level vision
  datasets from 3d scans.
\newblock In {\em Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pages 10786--10796, 2021.

\bibitem{epstein2017cognitive}
Russell~A Epstein, Eva~Zita Patai, Joshua~B Julian, and Hugo~J Spiers.
\newblock The cognitive map in humans: spatial navigation and beyond.
\newblock {\em Nature neuroscience}, 20(11):1504--1513, 2017.

\bibitem{fried2018speaker}
Daniel Fried, Ronghang Hu, Volkan Cirik, Anna Rohrbach, Jacob Andreas,
  Louis-Philippe Morency, Taylor Berg-Kirkpatrick, Kate Saenko, Dan Klein, and
  Trevor Darrell.
\newblock Speaker-follower models for vision-and-language navigation.
\newblock {\em Advances in Neural Information Processing Systems}, 31, 2018.

\bibitem{gadre2022onwheels}
Samir~Yitzhak Gadre, Mitchell Wortsman, Gabriel Ilharco, Ludwig Schmidt, and
  Shuran Song.
\newblock Clip on wheels: Zero-shot object navigation as object localization
  and exploration.
\newblock {\em arXiv preprint arXiv:2203.10421}, 2022.

\bibitem{georgakis2021learning}
Georgios Georgakis, Bernadette Bucher, Karl Schmeckpeper, Siddharth Singh, and
  Kostas Daniilidis.
\newblock Learning to map for active semantic goal navigation.
\newblock In {\em International Conference on Learning Representations}, 2021.

\bibitem{georgakis2022cross}
Georgios Georgakis, Karl Schmeckpeper, Karan Wanchoo, Soham Dan, Eleni
  Miltsakaki, Dan Roth, and Kostas Daniilidis.
\newblock Cross-modal map learning for vision and language navigation.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 15460--15470, 2022.

\bibitem{gordon2019splitnet}
Daniel Gordon, Abhishek Kadian, Devi Parikh, Judy Hoffman, and Dhruv Batra.
\newblock Splitnet: Sim2sim and task2task transfer for embodied visual
  navigation.
\newblock In {\em Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pages 1022--1031, 2019.

\bibitem{guhur2021airbert}
Pierre-Louis Guhur, Makarand Tapaswi, Shizhe Chen, Ivan Laptev, and Cordelia
  Schmid.
\newblock Airbert: In-domain pretraining for vision-and-language navigation.
\newblock In {\em Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pages 1634--1643, 2021.

\bibitem{hahn2021norlnosim}
Meera Hahn, Devendra~Singh Chaplot, Shubham Tulsiani, Mustafa Mukadam, James~M
  Rehg, and Abhinav Gupta.
\newblock No rl, no simulation: Learning to navigate without navigating.
\newblock {\em Advances in Neural Information Processing Systems},
  34:26661--26673, 2021.

\bibitem{hansen2020self}
Nicklas Hansen, Rishabh Jangir, Yu Sun, Guillem Aleny{\`a}, Pieter Abbeel,
  Alexei~A Efros, Lerrel Pinto, and Xiaolong Wang.
\newblock Self-supervised policy adaptation during deployment.
\newblock In {\em International Conference on Learning Representations}, 2020.

\bibitem{he2017maskrcnn}
Kaiming He, Georgia Gkioxari, Piotr Doll{\'a}r, and Ross Girshick.
\newblock Mask r-cnn.
\newblock In {\em Proceedings of the IEEE international conference on computer
  vision}, pages 2961--2969, 2017.

\bibitem{he2016resnet}
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
\newblock Deep residual learning for image recognition.
\newblock In {\em Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 770--778, 2016.

\bibitem{hong2020language}
Yicong Hong, Cristian Rodriguez, Yuankai Qi, Qi Wu, and Stephen Gould.
\newblock Language and visual entity relationship graph for agent navigation.
\newblock {\em Advances in Neural Information Processing Systems},
  33:7685--7696, 2020.

\bibitem{hong2022bridging}
Yicong Hong, Zun Wang, Qi Wu, and Stephen Gould.
\newblock Bridging the gap between learning in discrete and continuous
  environments for vision-and-language navigation.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 15439--15449, 2022.

\bibitem{hong2020recbert}
Yicong Hong, Qi Wu, Yuankai Qi, Cristian Rodriguez-Opazo, and Stephen Gould.
\newblock A recurrent vision-and-language bert for navigation.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition (CVPR)}, pages 1643--1653, June 2021.

\bibitem{ilharco2019general}
Gabriel Ilharco, Vihan Jain, Alexander Ku, Eugene Ie, and Jason Baldridge.
\newblock General evaluation for instruction conditioned navigation using
  dynamic time warping.
\newblock {\em arXiv preprint arXiv:1907.05446}, 2019.

\bibitem{irshad2021sasra}
Muhammad~Zubair Irshad, Niluthpol~Chowdhury Mithun, Zachary Seymour, Han-Pang
  Chiu, Supun Samarasekera, and Rakesh Kumar.
\newblock Sasra: Semantically-aware spatio-temporal reasoning agent for
  vision-and-language navigation in continuous environments.
\newblock {\em arXiv preprint arXiv:2108.11945}, 2021.

\bibitem{jiang2018rednet}
Jindong Jiang, Lunan Zheng, Fei Luo, and Zhijun Zhang.
\newblock Rednet: Residual encoder-decoder network for indoor rgb-d semantic
  segmentation.
\newblock {\em arXiv preprint arXiv:1806.01054}, 2018.

\bibitem{khandelwal2022embclip}
Apoorv Khandelwal, Luca Weihs, Roozbeh Mottaghi, and Aniruddha Kembhavi.
\newblock Simple but effective: Clip embeddings for embodied ai.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 14829--14838, 2022.

\bibitem{koh2022simple}
Jing~Yu Koh, Harsh Agrawal, Dhruv Batra, Richard Tucker, Austin Waters, Honglak
  Lee, Yinfei Yang, Jason Baldridge, and Peter Anderson.
\newblock Simple and effective synthesis of indoor 3d scenes.
\newblock {\em arXiv preprint arXiv:2204.02960}, 2022.

\bibitem{koh2021pathdreamer}
Jing~Yu Koh, Honglak Lee, Yinfei Yang, Jason Baldridge, and Peter Anderson.
\newblock Pathdreamer: A world model for indoor navigation.
\newblock In {\em Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pages 14738--14748, 2021.

\bibitem{krantz2021waypoint}
Jacob Krantz, Aaron Gokaslan, Dhruv Batra, Stefan Lee, and Oleksandr Maksymets.
\newblock Waypoint models for instruction-guided navigation in continuous
  environments.
\newblock In {\em Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pages 15162--15171, 2021.

\bibitem{krantz2022sim}
Jacob Krantz and Stefan Lee.
\newblock Sim-2-sim transfer for vision-and-language navigation in continuous
  environments.
\newblock In {\em European Conference on Computer Vision}, pages 588--603.
  Springer, 2022.

\bibitem{krantz2020vlnce}
Jacob Krantz, Erik Wijmans, Arjun Majumdar, Dhruv Batra, and Stefan Lee.
\newblock Beyond the nav-graph: Vision-and-language navigation in continuous
  environments.
\newblock In {\em European Conference on Computer Vision}, 2020.

\bibitem{krishna2017genome}
Ranjay Krishna, Yuke Zhu, Oliver Groth, Justin Johnson, Kenji Hata, Joshua
  Kravitz, Stephanie Chen, Yannis Kalantidis, Li-Jia Li, David~A Shamma, et~al.
\newblock Visual genome: Connecting language and vision using crowdsourced
  dense image annotations.
\newblock {\em International Journal of Computer Vision}, 123(1):32--73, 2017.

\bibitem{anderson2020rxr}
Alexander Ku, Peter Anderson, Roma Patel, Eugene Ie, and Jason Baldridge.
\newblock Room-across-room: Multilingual vision-and-language navigation with
  dense spatiotemporal grounding.
\newblock In {\em Proceedings of the 2020 Conference on Empirical Methods in
  Natural Language Processing (EMNLP)}, pages 4392--4412, 2020.

\bibitem{li2022igibson}
Chengshu Li, Fei Xia, Roberto Mart{\'\i}n-Mart{\'\i}n, Michael Lingelbach,
  Sanjana Srivastava, Bokui Shen, Kent~Elliott Vainio, Cem Gokmen, Gokul
  Dharan, Tanish Jain, et~al.
\newblock igibson 2.0: Object-centric simulation for robot learning of everyday
  household tasks.
\newblock In {\em Conference on Robot Learning}, pages 455--465. PMLR, 2022.

\bibitem{li2023panogen}
Jialu Li and Mohit Bansal.
\newblock Panogen: Text-conditioned panoramic environment generation for
  vision-and-language navigation.
\newblock {\em arXiv preprint arXiv:2305.19195}, 2023.

\bibitem{li2022envedit}
Jialu Li, Hao Tan, and Mohit Bansal.
\newblock Envedit: Environment editing for vision-and-language navigation.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 15407--15417, 2022.

\bibitem{lin2014mscoco}
Tsung-Yi Lin, Michael Maire, Serge Belongie, James Hays, Pietro Perona, Deva
  Ramanan, Piotr Doll{\'a}r, and C~Lawrence Zitnick.
\newblock Microsoft coco: Common objects in context.
\newblock In {\em European conference on computer vision}, pages 740--755.
  Springer, 2014.

\bibitem{liu2021envmixup}
Chong Liu, Fengda Zhu, Xiaojun Chang, Xiaodan Liang, Zongyuan Ge, and Yi-Dong
  Shen.
\newblock Vision-language navigation with random environmental mixup.
\newblock In {\em Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pages 1644--1654, 2021.

\bibitem{loshchilov2018adamw}
Ilya Loshchilov and Frank Hutter.
\newblock Decoupled weight decay regularization.
\newblock In {\em International Conference on Learning Representations}, 2018.

\bibitem{luo2022stubborn}
Haokuan Luo, Albert Yue, Zhang-Wei Hong, and Pulkit Agrawal.
\newblock Stubborn: A strong baseline for indoor object navigation.
\newblock {\em arXiv preprint arXiv:2203.07359}, 2022.

\bibitem{majumdar2020improving}
Arjun Majumdar, Ayush Shrivastava, Stefan Lee, Peter Anderson, Devi Parikh, and
  Dhruv Batra.
\newblock Improving vision-and-language navigation with image-text pairs from
  the web.
\newblock In {\em European Conference on Computer Vision}, pages 259--274.
  Springer, 2020.

\bibitem{maksymets2021thda}
Oleksandr Maksymets, Vincent Cartillier, Aaron Gokaslan, Erik Wijmans, Wojciech
  Galuba, Stefan Lee, and Dhruv Batra.
\newblock Thda: Treasure hunt data augmentation for semantic navigation.
\newblock In {\em Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pages 15374--15383, 2021.

\bibitem{mezghani2021imagenav}
Lina Mezghani, Sainbayar Sukhbaatar, Thibaut Lavril, Oleksandr Maksymets, Dhruv
  Batra, Piotr Bojanowski, and Karteek Alahari.
\newblock Memory-augmented reinforcement learning for image-goal navigation.
\newblock {\em arXiv preprint arXiv:2101.05181}, 2021.

\bibitem{mirowski2016complex}
Piotr Mirowski, Razvan Pascanu, Fabio Viola, Hubert Soyer, Andrew~J Ballard,
  Andrea Banino, Misha Denil, Ross Goroshin, Laurent Sifre, Koray Kavukcuoglu,
  et~al.
\newblock Learning to navigate in complex environments.
\newblock {\em arXiv preprint arXiv:1611.03673}, 2016.

\bibitem{oord2018infonce}
Aaron van~den Oord, Yazhe Li, and Oriol Vinyals.
\newblock Representation learning with contrastive predictive coding.
\newblock {\em arXiv preprint arXiv:1807.03748}, 2018.

\bibitem{padmakumar2022teach}
Aishwarya Padmakumar, Jesse Thomason, Ayush Shrivastava, Patrick Lange, Anjali
  Narayan-Chen, Spandana Gella, Robinson Piramuthu, Gokhan Tur, and Dilek
  Hakkani-Tur.
\newblock Teach: Task-driven embodied agents that chat.
\newblock In {\em Proceedings of the AAAI Conference on Artificial
  Intelligence}, volume~36, pages 2017--2025, 2022.

\bibitem{parisi2022unsurprising}
Simone Parisi, Aravind Rajeswaran, Senthil Purushwalkam, and Abhinav Gupta.
\newblock The unsurprising effectiveness of pre-trained vision models for
  control.
\newblock {\em arXiv preprint arXiv:2203.03580}, 2022.

\bibitem{pashevich2021episodic}
Alexander Pashevich, Cordelia Schmid, and Chen Sun.
\newblock Episodic transformer for vision-and-language navigation.
\newblock In {\em Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pages 15942--15952, 2021.

\bibitem{qi2021road}
Yuankai Qi, Zizheng Pan, Yicong Hong, Ming-Hsuan Yang, Anton van~den Hengel,
  and Qi Wu.
\newblock The road to know-where: An object-and-room informed sequential bert
  for indoor vision-language navigation.
\newblock In {\em Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pages 1655--1664, 2021.

\bibitem{qi2020reverie}
Yuankai Qi, Qi Wu, Peter Anderson, Xin Wang, William~Yang Wang, Chunhua Shen,
  and Anton van~den Hengel.
\newblock Reverie: Remote embodied visual referring expression in real indoor
  environments.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 9982--9991, 2020.

\bibitem{qiao2022hop}
Yanyuan Qiao, Yuankai Qi, Yicong Hong, Zheng Yu, Peng Wang, and Qi Wu.
\newblock Hop: History-and-order aware pre-training for vision-and-language
  navigation.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 15418--15427, 2022.

\bibitem{radford2021clip}
Alec Radford, Jong~Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh,
  Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark,
  et~al.
\newblock Learning transferable visual models from natural language
  supervision.
\newblock In {\em International Conference on Machine Learning}, pages
  8748--8763. PMLR, 2021.

\bibitem{ramakrishnan2022poni}
Santhosh~Kumar Ramakrishnan, Devendra~Singh Chaplot, Ziad Al-Halah, Jitendra
  Malik, and Kristen Grauman.
\newblock Poni: Potential functions for objectgoal navigation with
  interaction-free learning.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 18890--18900, 2022.

\bibitem{ramakrishnan2021hm3d}
Santhosh~Kumar Ramakrishnan, Aaron Gokaslan, Erik Wijmans, Oleksandr Maksymets,
  Alexander Clegg, John~M Turner, Eric Undersander, Wojciech Galuba, Andrew
  Westbury, Angel~X Chang, et~al.
\newblock Habitat-matterport 3d dataset (hm3d): 1000 large-scale 3d
  environments for embodied ai.
\newblock In {\em Thirty-fifth Conference on Neural Information Processing
  Systems Datasets and Benchmarks Track (Round 2)}, 2021.

\bibitem{ramakrishnan2021epc}
Santhosh~K Ramakrishnan, Tushar Nagarajan, Ziad Al-Halah, and Kristen Grauman.
\newblock Environment predictive coding for embodied agents.
\newblock {\em arXiv preprint arXiv:2102.02337}, 2021.

\bibitem{ramrakhya2022habweb}
Ram Ramrakhya, Eric Undersander, Dhruv Batra, and Abhishek Das.
\newblock Habitat-web: Learning embodied object-search strategies from human
  demonstrations at scale.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 5173--5183, 2022.

\bibitem{raychaudhuri2021law}
Sonia Raychaudhuri, Saim Wani, Shivansh Patel, Unnat Jain, and Angel Chang.
\newblock Language-aligned waypoint (law) supervision for vision-and-language
  navigation in continuous environments.
\newblock In {\em Proceedings of the 2021 Conference on Empirical Methods in
  Natural Language Processing}, pages 4018--4028, 2021.

\bibitem{ren2015faster}
Shaoqing Ren, Kaiming He, Ross Girshick, and Jian Sun.
\newblock Faster r-cnn: Towards real-time object detection with region proposal
  networks.
\newblock In {\em Advances in neural information processing systems}, pages
  91--99, 2015.

\bibitem{roberts2021hypersim}
Mike Roberts, Jason Ramapuram, Anurag Ranjan, Atulit Kumar, Miguel~Angel
  Bautista, Nathan Paczan, Russ Webb, and Joshua~M Susskind.
\newblock Hypersim: A photorealistic synthetic dataset for holistic indoor
  scene understanding.
\newblock In {\em Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pages 10912--10922, 2021.

\bibitem{russakovsky2015imagenet}
Olga Russakovsky, Jia Deng, Hao Su, Jonathan Krause, Sanjeev Satheesh, Sean Ma,
  Zhiheng Huang, Andrej Karpathy, Aditya Khosla, Michael Bernstein, et~al.
\newblock Imagenet large scale visual recognition challenge.
\newblock {\em International journal of computer vision}, 115(3):211--252,
  2015.

\bibitem{savinov2018semi}
Nikolay Savinov, Alexey Dosovitskiy, and Vladlen Koltun.
\newblock Semi-parametric topological memory for navigation.
\newblock In {\em International Conference on Learning Representations}, 2018.

\bibitem{savva2019habitat}
Manolis Savva, Abhishek Kadian, Oleksandr Maksymets, Yili Zhao, Erik Wijmans,
  Bhavana Jain, Julian Straub, Jia Liu, Vladlen Koltun, Jitendra Malik, et~al.
\newblock Habitat: A platform for embodied ai research.
\newblock In {\em Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pages 9339--9347, 2019.

\bibitem{shah2022lmnav}
Dhruv Shah, Blazej Osinski, Brian Ichter, and Sergey Levine.
\newblock Lm-nav: Robotic navigation with large pre-trained models of language,
  vision, and action.
\newblock {\em arXiv preprint arXiv:2207.04429}, 2022.

\bibitem{shen2021benefit}
Sheng Shen, Liunian~Harold Li, Hao Tan, Mohit Bansal, Anna Rohrbach, Kai-Wei
  Chang, Zhewei Yao, and Kurt Keutzer.
\newblock How much can clip benefit vision-and-language tasks?
\newblock In {\em International Conference on Learning Representations}, 2021.

\bibitem{shridhar2022cliport}
Mohit Shridhar, Lucas Manuelli, and Dieter Fox.
\newblock Cliport: What and where pathways for robotic manipulation.
\newblock In {\em Conference on Robot Learning}, pages 894--906. PMLR, 2022.

\bibitem{shridhar2020alfred}
Mohit Shridhar, Jesse Thomason, Daniel Gordon, Yonatan Bisk, Winson Han,
  Roozbeh Mottaghi, Luke Zettlemoyer, and Dieter Fox.
\newblock Alfred: A benchmark for interpreting grounded instructions for
  everyday tasks.
\newblock In {\em Proceedings of the IEEE/CVF conference on computer vision and
  pattern recognition}, pages 10740--10749, 2020.

\bibitem{song2015sunrgbd}
Shuran Song, Samuel~P Lichtenberg, and Jianxiong Xiao.
\newblock Sun rgb-d: A rgb-d scene understanding benchmark suite.
\newblock In {\em Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 567--576, 2015.

\bibitem{straub2019replica}
Julian Straub, Thomas Whelan, Lingni Ma, Yufan Chen, Erik Wijmans, Simon Green,
  Jakob~J Engel, Raul Mur-Artal, Carl Ren, Shobhit Verma, et~al.
\newblock The replica dataset: A digital replica of indoor spaces.
\newblock {\em arXiv preprint arXiv:1906.05797}, 2019.

\bibitem{szot2021habitat2}
Andrew Szot, Alexander Clegg, Eric Undersander, Erik Wijmans, Yili Zhao, John
  Turner, Noah Maestre, Mustafa Mukadam, Devendra~Singh Chaplot, Oleksandr
  Maksymets, et~al.
\newblock Habitat 2.0: Training home assistants to rearrange their habitat.
\newblock {\em Advances in Neural Information Processing Systems}, 34:251--266,
  2021.

\bibitem{tan2019envdrop}
Hao Tan, Licheng Yu, and Mohit Bansal.
\newblock Learning to navigate unseen environments: Back translation with
  environmental dropout.
\newblock In {\em Proceedings of NAACL-HLT}, pages 2610--2621, 2019.

\bibitem{tolman1948cognitive}
Edward~C Tolman.
\newblock Cognitive maps in rats and men.
\newblock {\em Psychological review}, 55(4):189, 1948.

\bibitem{wang2002human}
Ranxiao~Frances Wang and Elizabeth~S Spelke.
\newblock Human spatial representation: Insights from animals.
\newblock {\em Trends in cognitive sciences}, 6(9):376--382, 2002.

\bibitem{wang2023scalevln}
Zun Wang, Jialu Li, Yicong Hong, Yi Wang, Qi Wu, Mohit Bansal, Stephen Gould,
  Hao Tan, and Yu Qiao.
\newblock Scaling data generation in vision-and-language navigation.
\newblock 2023.

\bibitem{wijmans2019ddppo}
Erik Wijmans, Abhishek Kadian, Ari Morcos, Stefan Lee, Irfan Essa, Devi Parikh,
  Manolis Savva, and Dhruv Batra.
\newblock Dd-ppo: Learning near-perfect pointgoal navigators from 2.5 billion
  frames.
\newblock {\em arXiv preprint arXiv:1911.00357}, 2019.

\bibitem{xia2018gibson}
Fei Xia, Amir~R Zamir, Zhiyang He, Alexander Sax, Jitendra Malik, and Silvio
  Savarese.
\newblock Gibson env: Real-world perception for embodied agents.
\newblock In {\em Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, pages 9068--9079, 2018.

\bibitem{yadav2022ovrl}
Karmesh Yadav, Ram Ramrakhya, Arjun Majumdar, Vincent-Pierre Berges, Sachit
  Kuhar, Dhruv Batra, Alexei Baevski, and Oleksandr Maksymets.
\newblock Offline visual representation learning for embodied navigation.
\newblock {\em arXiv preprint arXiv:2204.13226}, 2022.

\bibitem{yao2020blendedmvs}
Yao Yao, Zixin Luo, Shiwei Li, Jingyang Zhang, Yufan Ren, Lei Zhou, Tian Fang,
  and Long Quan.
\newblock Blendedmvs: A large-scale dataset for generalized multi-view stereo
  networks.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 1790--1799, 2020.

\bibitem{ye2021auxiliary}
Joel Ye, Dhruv Batra, Abhishek Das, and Erik Wijmans.
\newblock Auxiliary tasks and exploration enable objectnav.
\newblock {\em arXiv preprint arXiv:2104.04112}, 2021.

\bibitem{ye2021auxpoint}
Joel Ye, Dhruv Batra, Erik Wijmans, and Abhishek Das.
\newblock Auxiliary tasks speed up learning point goal navigation.
\newblock In {\em Conference on Robot Learning}, pages 498--516. PMLR, 2021.

\bibitem{zamir2018taskonomy}
Amir~R Zamir, Alexander Sax, William Shen, Leonidas~J Guibas, Jitendra Malik,
  and Silvio Savarese.
\newblock Taskonomy: Disentangling task transfer learning.
\newblock In {\em Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 3712--3722, 2018.

\bibitem{zhang2020contrastive}
Yuhao Zhang, Hang Jiang, Yasuhide Miura, Christopher~D Manning, and Curtis~P
  Langlotz.
\newblock Contrastive learning of medical visual representations from paired
  images and text.
\newblock {\em arXiv preprint arXiv:2010.00747}, 2020.

\bibitem{zhou2017places365}
Bolei Zhou, Agata Lapedriza, Aditya Khosla, Aude Oliva, and Antonio Torralba.
\newblock Places: A 10 million image database for scene recognition.
\newblock {\em IEEE transactions on pattern analysis and machine intelligence},
  40(6):1452--1464, 2017.

\bibitem{zhou2023navgpt}
Gengze Zhou, Yicong Hong, and Qi Wu.
\newblock Navgpt: Explicit reasoning in vision-and-language navigation with
  large language models.
\newblock {\em arXiv preprint arXiv:2305.16986}, 2023.

\bibitem{zhu2020auxiliary}
Fengda Zhu, Yi Zhu, Xiaojun Chang, and Xiaodan Liang.
\newblock Vision-language navigation with self-supervised auxiliary reasoning
  tasks.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 10012--10022, 2020.

\bibitem{zhu2022navigating}
Minzhao Zhu, Binglei Zhao, and Tao Kong.
\newblock Navigating to objects in unseen environments by distance prediction.
\newblock {\em arXiv preprint arXiv:2202.03735}, 2022.

\end{thebibliography}
