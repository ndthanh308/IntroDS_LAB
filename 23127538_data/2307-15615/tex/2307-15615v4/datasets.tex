\begin{sidewaystable*}
        \rowcolors{2}{white}{cyan!10}
        \caption{{A summary of the publicly available benchmark dataset for medical image registration.}}
        \label{table:dataset_list}
        \fontsize{7.45}{8.95}\selectfont
        %\begin{tabular}{lc lc lc l}
        \begin{tabularx}{0.99\textwidth}{lc lc lc lc X}
        \toprule
        \rowcolor{white}
        \textbf{Dataset} && \textbf{Anatomy} && \textbf{Cohort Type} && \textbf{Modality} && \textbf{Highlights}\\
        %
        \cmidrule(lr){1-1}
        \cmidrule(lr){3-9}
        IXI\textsuperscript{a}  && Brain && Healthy Controls && T1w, T2w, PDw MRI && Nearly 600 MRI images with cortical and subcortical label maps from prior studies~\citep{liu2024vector,chen2022transmorph,hoopes2022synthstrip}. \\
        LUMIR~\citep{L2R24}  && Brain && Healthy Controls && T1w MRI && Part of Learn2Reg 2024~\citep{L2R24}, using the OpenBHB dataset~\citep{dufumier2022openbhb}; 4,014 MRIs from ten public datasets with label maps and landmarks. \\
        LPBA40~\citep{shattuck2008construction}  && Brain && Healthy Controls && T1w MRI && 40 MRI scans affine-transformed to a common atlas with 50 manually delineated brain structures. \\
        Mindboggle~\citep{klein2012101} && Brain && Healthy Controls && T1w MRI && 101 MRIs affine-aligned to an atlas with 106 manually delineated brain structures.\\
        OASIS~\citep{marcus2007open, hoopes2022learning} && Brain && Alzheimerâ€™s disease && T1w MRI && 416 MRIs from OASIS-1~\citep{marcus2007open} with label maps generated using FreeSurfer and SAMSEG, used in Learn2Reg 2021~\citep{hering2022learn2reg}.\\
        BraTS-Reg~\citep{baheti2021brain} && Brain && Glioma && T1w, T1ce, T2w, FLAIR MRI && 140 training, 20 validation, and 50 testing cases with manual landmarks across baseline and follow-up scans.\\
        CuRIOUS~\citep{hering2022learn2reg} && Brain && Glioma && T1w, T2-FLAIR MRI, 3D US && Part of Learn2Reg 2020, 22 subjects with pre-op MRI, and intra-op 3D US with annotated landmarks from EASY-RESECT~\citep{xiao2017re}.\\
        ReMIND2Reg~\citep{juvekar2024remind}  && Brain && Tumor resection && T1w, T2w MRI, 3D US && Part of Learn2Reg 2024~\citep{L2R24}, 104 intra-operative US, 98 T1ce, and 67 T2 MRIs from 104 patients, with manual landmarks.\\
        Hippocampus-MR~\citep{hering2022learn2reg} && Brain && Non-affective psychosis && T1w MRI && Part of Learn2Reg 2020, 394 MR scans of the hippocampus region with manually tracings for evaluation.\\
        DIR-Lab~\citep{castillo2013reference,castillo2009four}  && Lung && COPD, cancer && Breath-hold and 4DCT && 20 CTs (COPDgene and 4DCT subsets) with 7,000+ manually paired landmarks for evaluating deformable registration.  \\
        NLST~\citep{national2011reduced}  && Lung && Smokers && Spiral CT && 100 paired inhale-exhale CTs with lung masks and keypoints; 10 test images with manual landmarks for Learn2Reg 2022~\citep{l2r2022}.  \\
        Lung-CT~\citep{hering2022learn2reg}  && Lung && Healthy Controls && Inspiratory, expiratory CT && 30 paired lung CTs with lung masks and keypoints; evaluation with manual landmarks from vessels and airways for Learn2Reg 2021~\citep{hering2022learn2reg}.  \\
        EMPIRE10~\citep{murphy2011evaluation}  && Lung && Healthy Controls && Inspiratory, expiratory CT && 30 lung CT pairs with 100 manual landmarks for each, covering different scan types to evaluate registration methods.  \\
        Thorax-CBCT~\citep{hugo2016data}  && Lung && Cancer Patients && CT, CBCT && 18 paired CTs from TCIA-4D-Lung with manual organ and target delineations for interventional registration in Learn2Reg 2023~\citep{L2R2023}.  \\
        Lung250M-4B~\citep{falta2024lung250m}  && Lung && Mixed && CT && 248 paired CTs from seven datasets with 4 billion voxels and 250M keypoints, providing ground truth displacements and nnUNet segmentations.\\
        ACDC~\citep{bernard2018deep} && Heart && Cardiac diseases && 4D cine-MRI && 150 subjects with manual LV, RV, and Myo segmentations at ED and ES phases for intra-patient registration.  \\
        M\&Ms~\citep{campello2021multi}  && Heart && Cardiac diseases && 4D cine-MRI && 375 subjects from multiple centers with LV, RV, and Myo segmentations at ED and ES phases for intra-patient registration.  \\
        MM-WHS~\citep{zhuang2019evaluation} && Heart && Cardiac diseases && CT, MRI && 120 cardiac scans (CT and MRI) from 60 subjects with 7 key heart structures manually annotated for mono- and multi-modal registration.\\
        Abdomen-CT-CT~\citep{hering2022learn2reg} && Abdomen && Cancer Patients && CT && Part of Learn2Reg 2020~\citep{hering2022learn2reg}, featuring 50 CT images with 13 manually labeled structures from~\citep{xu2016evaluation}.\\
        Abdomen-MR-CT~\citep{hering2022learn2reg} && Abdomen && Cancer Patients && CT, MR && Part of Learn2Reg 2021~\citep{hering2022learn2reg}, containing 16 CT/MR pairs with 4 labeled structures.\\
        ACROBAT~\citep{weitz2024acrobat} && Breast && Breast Cancer && Pathological images && 4,212 whole-slide-images from 1,152 breast cancer patients.\\
        ANHIR~\citep{borovec2020tmi} && Body-wide && Cancer tissue samples && Pathological images && 355 images with 18 different stains, resulting in 481 valid image registration pairs.\\
        COMULISglobe SHG-BF~\citep{L2R24} && Breast / Pancreas && Cancer tissue samples && Pathological images && Part of Learn2Reg 2024~\citep{L2R24}, featuring paired second-harmonic generation and bright field pathology images.\\
        COMULISglobe 3D-CLEM~\citep{L2R24}  && Cell && Mitochondria, nuclei && Microscopy && Part of Learn2Reg 2024~\citep{L2R24}, featuring 3 pre-processed microscopy datasets with manually annotated landmarks.\\
        %FLoRI21~\citep{FLoRI21} && Retina && Diabetic retinopathy && Fluorescein Angiography && The main challenges of this data arise from geometric distortions due to the large field-of-view.\\
\bottomrule
    \end{tabularx}
    \vspace{1ex}
    
    \footnotesize \textsuperscript{a} https://brain-development.org/ixi-dataset/
\end{sidewaystable*}

{Due to the inherent black-box nature of DL, developing DL models often relies on empirical studies and author-reported evaluations. The reproducibility and replicability of these experiments have been central focuses since the rise of DL, and DL-based registration is no exception. A key method to promote reproducibility is evaluating models on publicly available datasets. To support this effort, we provide a list of benchmark datasets in Table~\ref{table:dataset_list} to serve as a reference for the medical image registration community. While segmentation label maps are frequently used as a surrogate measure for registration accuracy, theoretically, any dataset containing segmentation label maps for the same anatomical structures across patients or within the same patient could be used to evaluate registration performance. However, our focus here is specifically on datasets designed for, or have been widely used in, registration tasks. These datasets span anatomies such as the brain, lung, heart, abdomen, and pathological images, each presenting unique challenges.}

{For brain imaging, the challenge arises from the need for precise alignment of small structures such as the hippocampus, ventricles, and cortical sulci. Additionally, conditions like Alzheimer's disease lead to cortical thinning and atrophy, while tumors cause local and global distortions, making registration complex and requiring both fine and large-scale alignment across and within subjects.}
    
{In lung registration, one of the primary challenges is managing the large deformations caused by respiratory motion while also accounting for finer structural changes, such as those in vessels and airways. Evaluation is typically landmark-based, as anatomical label maps of lung structures are often too coarse to precisely measure registration accuracy. However, obtaining high-quality landmarks is both time-consuming and labor-intensive.}

{Cardiac image registration similarly faces the challenge of complex deformations due to both respiratory and cardiac motion. However, a unique difficulty is the limited availability of anatomical landmarks~\citep{makela2002review}, as the heart presents fewer distinct features compared to the lungs, complicating both alignment and evaluation.}
    
{Abdominal registration faces significant challenges due to substantial inter-subject variability in organ size, shape, and appearance, driven by factors such as age, gender, and disease. Soft tissue deformation adds another layer of complexity, constantly altering inter-organ relationships within the same subject~\citep{xu2016evaluation}. Compounding these issues, factors like body pose, respiratory cycle, and digestive status cause dynamic shifts in organ positioning. The multimodal nature of abdominal imaging, where anatomical (e.g., CT or MRI) and functional (e.g., PET or SPECT) data are often combined, further intensifies the complexity. Despite the advancements in modern hybrid scanners that perform co-registration, persistent errors remain~\citep{livieratos2015technical, roy2015quantitative}, underscoring the need for continued research in this area.}

{Pathological image registration also presents distinct challenges. Thin tissue sections, only a few micrometers thick, can deform easily during sample preparation, and parts of the tissue in whole-slide images (WSIs) of the same sample may be absent in other WSIs, particularly if sections are non-consecutive~\citep{weitz2024acrobat}. Additionally, tissue appearance can vary significantly depending on the staining method. The complexity of pathological features, combined with the gigapixel resolution of WSIs, demands robust registration methods that provide multi-resolution alignment while accommodating potential topological changes for accurate registration.}

{While Table \ref{table:dataset_list} lists datasets commonly used for benchmarking registration methods, the advent of automated segmentation tools (e.g., FreeSurfer~\citep{fischl2012freesurfer}, SynthSeg~\citep{billot2023synthseg}, SLANT~\citep{huo20193d}, TotalSegmentator~\citep{wasserthal2023totalsegmentator}) enables researchers to convert raw medical images from open-source platforms such as OpenNeuro~\citep{markiewicz2021openneuro} and the Cancer Imaging Archive~\citep{clark2013cancer}, as well as from large-scale publicly available datasets such as ADNI~\citep{jack2008alzheimer}, ABIDE~\citep{heinsfeld2018identification}, and autoPET~\citep{gatidis2023autopet} into benchmark datasets for image registration methods.}