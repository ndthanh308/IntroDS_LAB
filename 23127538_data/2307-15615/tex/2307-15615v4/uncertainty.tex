
DNNs are capable of learning complex representations. However, their predictions are typically deterministic and assumed to be accurate, which is usually not the case.
Estimating the uncertainty is important for evaluating what the models learn from the data and helps reduce risk in decision-making based on the model prediction.
In medical image analysis, uncertainty estimation has been widely used in tasks such as image segmentation, image classification, and image registration.
For example, registration uncertainty empowers surgeons to evaluate the surgical risk tied to the registration model's prediction, thereby avoiding undesirable consequences.
Prior to the deep learning-based registration, traditional registration uncertainty is based on the framework of probabilistic registration, where the probabilistic distribution of the transformation parameters is estimated. 

{In this section, we focus on reviewing the \textbf{recent advancements} in estimating registration uncertainty through deep learning methods, though many concepts have been drawn from traditional registration uncertainty estimation methods.}
We start with the general framework for estimating uncertainty using deep learning methods.
Next, we formally define the different types of registration uncertainty and elaborate on how the uncertainty estimation methods are used in learning-based registration.
Finally, we provide a summary of the methods used for evaluating the quality of uncertainty estimation.

\subsection{Bayesian Deep Learning}%Uncertainty Estimation Method}
%
% Figure environment removed
%
As shown in Fig.~\ref{fig:reg_uncert}, in general, uncertainty can be categorized into two types: aleatoric and epistemic uncertainty~\citep{kendall2017uncertainties}.
Aleatoric uncertainty, also known as data uncertainty or inherent uncertainty, refers to the inherent randomness or variability present in observed data.
It can be thought of as the variability of the data given the underlying true data generation model due to factors such as measurement errors, sensor noise, or the intrinsic stochastic nature of the data generation process.
Epistemic uncertainty, also known as model uncertainty or knowledge uncertainty, refers to variability present in the model structure, model parameters, and model assumptions.
It arises due to our limited knowledge or understanding of the underlying model.
Aleatoric uncertainty may be reduced by improving the data quality, while epistemic uncertainty may be mitigated by improving model selection, refining parameter estimation, or acquiring additional relevant information.

To predict aleatoric and epistemic uncertainty using deep learning, we train a model $W$ using data set $D$ that takes an input $x$ to generate an output $y(x, W)$ and a variance prediction $\sigma^2(x,W)$. 
Aleatoric uncertainty describes the uncertainty that is inherent in the training data $D$.
It is expressed as follows:
\begin{equation}
\label{eq:ua}
    u_a = E_{p(W|D)}\left[ \sigma^2(x,W) \right],
\end{equation}
where $E$ represents taking the average of $\sigma^2(x,W)$ over the distribution $p(W|D)$.
Epistemic uncertainty describes the uncertainty of the model $W$.
It is represented as follows:
\begin{equation}
\label{eq:ue}
    u_e = V_{p(W|D)} \left[ y(x,W) \right],
\end{equation}
where $V$ represents taking the variance of $y(x,W)$ over the distribution $p(W|D)$.
Directly computing aleatoric uncertainty using Eqn.~\ref{eq:ua} and epistemic uncertainty using Eqn.~\ref{eq:ue} is usually impractical, as it requires the integration of high dimensional numerical functions.
Instead, these uncertainties are approximated from a set of outputs by using the model weights $W$ sampled from the posterior distribution $p(W|D)$.  

In theory, the posterior distribution $p(W|D)$ can be obtained through Bayes' rule,
\begin{equation}
    p(W|D)=\frac{p(D|W)p(W)}{p(D)},
\end{equation}
where $p(W)$ is an assumed prior. 
However, it is not feasible to obtain $p(D)$ in the denominator due to the intractable integral.
As an alternative, variational inference is used to approximate $p(W|D)$ as a distribution $q_{\theta}(W)$ with parameter $\theta$ by minimizing the Kullback-Leibler~(KL) divergence between them.
This process can be simplified as follows:
\begin{equation}
\label{eq:theta_weight}
    \hat{\theta} = \argmin_{\theta}D_{KL}\Big[q_{\theta}(W)\Vert p(W)\Big] - E_{q_{\theta}} \Big[ \log{p(D|W)} \Big],
\end{equation}
%\begin{eqnarray}
%    \bm{\theta}^* & = & \argmin_{\bm{\theta}}KL\bigg[q_{\bm{\theta}}(\bm{W})\Vert p(\bm{W})\bigg] \nonumber\\
%    %
%    && \qquad - \int q_{\bm{\theta}}(\bm{W})\log{p(\bm{D}|\bm{W})} \mathrm{d}\bm{W}.
%\end{eqnarray}    
where $D_{KL}$ represents KL divergence and $E_{q_{\theta}}$ represents taking the average over the distribution $q_{\theta}(W)$.
With this, the aleatoric uncertainty in Eqn.~\ref{eq:ua} and the epistemic uncertainty in Eqn.~\ref{eq:ue} can be approximated by sampling $W$ from $q_{\hat{\theta}}(W)$.

Many sampling methods can be used for uncertainty estimation, including Monte Carlo dropout, bootstrap, and snapshot techniques. 
The Monte Carlo dropout sampling method operates under the assumption that $q_{\theta}(W)$ follows a Bernoulli distribution~\citep{gal2016dropout}.
It leverages dropout layers during the testing phase to perform multiple forward inferences.
This method is widely used in learning-based registration models, likely due to its straightforward implementation~\citep{yang2016fast, yang2017quicksilver, madsen2020closest, chen2022transmorph, xu2022double}.
Bootstrap sampling, a traditional method, involves training the registration model multiple times on independent training sets to produce multiple inferences~\citep{kybic2009bootstrap}.
Snapshot sampling uses the cyclic learning rate in one training process for perturbing the model to converge to multiple different local minimums~\citep{huang2017snapshot}.
It has shown that snapshot sampling performs better uncertainty estimation than other methods for the medical image registration use case~\citep{gong2022uncertainty}.

\subsection{Registration Uncertainty Estimation for DNN}
Both aleatoric and epistemic uncertainty are present in image registration. 
Aleatoric uncertainty in image registration may arise from factors such as image noise, image artifacts, lack of image features or image contrast, and natural anatomical variation between images.
There may be two types of aleatoric uncertainty in image registration.
One is that given the underlying true deformation field, two aligned images may not be exactly the same due to different image noise, image artifacts or natural anatomical variation between images.
Another type is that multiple deformation fields may align two images with similar performance due to lack of image features or image contrast.
On the other hand, epistemic uncertainty represents the limitations inherent in the modeling process. In image registration, this relates to the limited ability of the model to precisely capture the complex deformation field. This form of uncertainty can be attributed to factors like inadequate training data, choices in model architecture, or the inherent complexity posed by the inverse problem of estimating the deformation fields.
The following subsections provide details on each type of uncertainty.

\subsubsection{Aleatoric Uncertainty}
In medical image registration, the output of the network is usually a deformation field $\phi(I_f, I_m, W)$ as a function of the fixed image $I_f$, the moving image $I_m$ and the model $W$.
To help the model estimate the aleatoric uncertainty inherent from data, the model needs to predict a variance $\sigma(I_f, I_m, W)$ of the output.
Assuming the deformation field $\phi$ follows a voxel-wise Gaussian distribution, the model $W$ can be trained by minimizing the loss function,
\begin{equation}
\label{eq:loss}
    \mathcal{L} = \sum_{p} \frac{(\phi(p) - \phi^*(p))^2}{\sigma^2(p)} + \log{\sigma^2(p)},
\end{equation}
where $\phi^*$ is the ground truth for the deformation field. 
%However, the ground truth $\phi^*$ is usually not available in deep unsupervised registration, thus the loss function can be modified as,
%\begin{equation}
%    L = \sum_{p} \frac{(I_m \circ \phi(p) - I_f(p))^2}{\sigma^2(p)} + \log{\sigma^2(p)},
%\end{equation}
%where the new $\sigma^2$ is an approximated representation of the one in Eqn.~\ref{eq:loss}.
However, in unsupervised learning-based image registration, the ground truth deformation $\phi^*$ is unavailable, and the loss may be calculated in the image domain (\emph{i.e.}, in the form of image similarity measure) rather than directly comparing the deformation fields as in Eqn.~\ref{eq:loss}.
To overcome this issue, the aleatoric uncertainty for image registration is frequently estimated using a variational inference strategy, which optimizes a global neural network to produce {posterior} of deformation fields~\citep{dalca2019unsupervised, grzech2020image, grzech2022variational, wei2021recurrent, smolders2022deformable, croquet2021unsupervised, krebs2019learning}.
This approach circumvents the direct computation of the intractable posterior $p(\phi|I_f; I_m)$ by introducing an approximate posterior $q_{\theta}(\phi)$, where the parameter $\theta$ can be predicted by a network based on the inputs $I_f$ and $I_m$.
The KL divergence between the two posteriors is then minimized, which maximizes the evidence lower bound~(ELBO):
\begin{equation}
    \hat{\theta} = \argmin_{\theta} D_{KL} \Big[ q_{\theta}(\phi)\Vert p(\phi) \Big] - E_{q_{\theta}} \Big[ \log p(I_f|\phi;I_m) \Big],
\end{equation}
%\begin{equation}
%\begin{split}
%    \argmin_{\bm{\theta}}&KL\bigg[q_{\bm{\theta}}(\phi|I_f, I_m)\Vert p(\phi|I_f, I_m)\bigg]\\
%    =&\argmin_{\bm{\theta}}KL\bigg[q_{\bm{\theta}}(\phi|I_f, I_m)\Vert p(\phi)\bigg]-\bm{E}_q\bigg[\log p(I_f|\phi; I_m)\bigg].
%\end{split}
%\end{equation}
where $D_{KL}$ represents KL divergence and $E_{q_{\theta}}$ represents taking the average over the distribution $q_{\theta}(\phi)$, {and $p(\phi)$ represents the prior of the deformation field}.
Here, {the prior $p(\phi)$ is usually modeled using
a graph Laplacian matrix for smoothness
regularization~\citep{dalca2019unsupervised, grzech2020image,
grzech2022variational}}, and the approximate posterior $q_{\theta}(\phi)$ is frequently modeled as a multivariate normal distribution  (\textit{i.e.}, 
%$q_{\theta}(\phi)=\mathcal{N}(\phi; \mu_{\phi|I_f, I_m}, \sigma_{\phi|I_f, I_m})$. 
$\phi\sim\mathcal{N}(\mu_{\phi},\sigma_{\phi}^2)$). 
{A more complex prior can be designed to close the gap between the real posterior and the variational posterior~\citep{xu2023importance}.}
{To reduce the dimensionality of the covariance matrix $\sigma_{\phi}^2$ and simplify its optimization, a diagonal matirx~\citep{dalca2019unsupervised} or a sum of a diagonal and a low rank matrices~\citep{grzech2020image, grzech2022variational} are used.}
Moreover, the conditional probability $p(I_f|\phi; I_m)$ typically takes the Gaussian form (\textit{i.e.}, $I_f\sim\mathcal{N}(I_m \circ \phi, \sigma_I^2)$)~{\citep{dalca2019unsupervised}, or
can be implemented as a neural network for learning a more complex
form~\citep{grzech2022variational}}.
In practical applications, the mean $\mu_{\phi}$ and the standard deviation $\sigma_{\phi}$ of the deformation field can be {optimized directly as parameters using
backpropagation~\citep{grzech2020image, grzech2022variational}, or can be} predicted by the registration network, in a similar manner to a variational autoencoder~{\citep{dalca2019unsupervised}.
The obtained} variance $\sigma^2_{\phi}$ represents the aleatoric uncertainty associated with the deformation field, given the input images $I_f$ and $I_m$.

\subsubsection{Epistemic Uncertainty}
As illustrated in Fig. \ref{fig:reg_uncert}, the epistemic uncertainty in registration can be divided into two different measures \citep{luo2019applicability, xu2022double, chen2022transmorph}: transformation uncertainty and appearance uncertainty.
These measures refer to the uncertainty in generating the transformation and the plausibility of the transformation, respectively~\citep{bierbrier2022estimating}.
The former quantifies the uncertainty in the deformation space and tends to be large when the model is uncertain about establishing specific correspondences, such as when registering regions with piecewise constant intensity.
In contrast, the latter is often based on the assumption that high image similarity indicates correct alignment.
Consequently, this uncertainty would be large when the appearance differences between the warped and fixed images are significant. 

Transformation uncertainty can be described as the variance of the sampled deformation fields, which derives from Eqn.~\ref{eq:ue} by stochastic sampling:
\begin{equation}
\label{eq:ue_trans}
    u_{e,trans} = \frac{1}{N} \sum_{i=1}^{N} ( \phi_i - \frac{1}{N} \sum_{j=1}^{N} \phi_j ) ^2,
\end{equation}
where $\phi_i$ is generated by using the model weight $W_i$ sampled from the estimated variational distribution $q_{\hat{\theta}}(W)$ with the parameter $\hat{\theta}$ optimized by Eqn.~\ref{eq:theta_weight}, and $N$ is the total sampling number.
Appearance uncertainty is expressed as the variance of the warped images, which are created using the sampled deformation fields~\citep{luo2019applicability, xu2022double}:
\begin{equation}
\label{eq:uappea}
    u_{e,appea} = \frac{1}{N} \sum_{i=1}^{N} ( I_m \circ \phi_i - \frac{1}{N} \sum_{j=1}^{N} I_m \circ \phi_j ) ^2,
\end{equation}
where $\phi_i$ is generated by using the sampled $W_i$ as the
model, $N$ is the total sampling number and $I_m$ is the moving image. 
However, it should be noted that the uncertainty estimated using this equation for appearance uncertainty can be biased due to overfitting, as shown in~\citet{chen2022transmorph}. 
To correct this, the authors suggest using the following formulation instead:
\begin{equation}
    u_{e,appea} = \frac{1}{N} \sum_{i=1}^{N} ( I_m \circ \phi_i - I_f ) ^2,
\end{equation}
where the predictive mean is replaced by the fixed image $I_f$.

{It is important to note that while the presence of aleatoric and epistemic uncertainties in the image registration process, they may not provide useful insights for label propagation, where image registration is applied to warp between label maps. In such scenarios, segmentation uncertainty estimates could be more relevant. In \citep{chen2024registration}, the authors demonstrated that registration uncertainty estimates, which are primarily based on image intensity information rather than the underlying labels, do not correlate well with errors in label propagation. They proposed a plug-in-and-play DNN method that estimates both aleatoric and epistemic uncertainties in segmentation, in addition to registration uncertainties, to more effectively identify potential errors in using image registration for segmentation.}

\subsection{Uncertainty Evaluation in Registration}
One significant challenge in uncertainty estimation lies in its evaluation due to the absence of ground truth, especially in unsupervised learning-based registration.
To access the quality of uncertainty, sparsification plots are usually used for voxel-wise uncertainty evaluation~\citep{mac2012learning, wannenwetsch2017probflow, ilg2018uncertainty}.

Sparsification plots demonstrate how the registration error changes by gradually removing voxels ranked by the uncertainty measure. 
It is anticipated that removing a voxel with higher uncertainty will result in a greater reduction in registration error, and the opposite holds true for voxels with lower uncertainty.
If all voxels are arranged in descending order of uncertainty, and the uncertainty ranking matches the actual registration error ranking, the accumulated registration error under the sparsification plot will be small.
Therefore, the area under sparsification plots is also used as an evaluation metric to gauge the quality of the uncertainty estimation.

%
% Need a closing paragraph. -AJC
%

% Uncertainty quantification in non-rigid image registration via stochastic gradient Markov chain Monte Carlo ? (Unsure)
% Uncertainty Learning towards Unsupervised Deformable Medical Image Registration
% Unsupervised Learning of Probabilistic Diffeomorphic Registration for Images and Surfaces
% NPBDREG: Uncertainty assessment in diffeomorphic brain MRI registration using a non-parametric Bayesian deep-learning based approach
% Double-Uncertainty Guided Spatial and Temporal Consistency Regularization Weighting for Learning-based Abdominal Registration
% DragNet: Learning-based deformable registration for realistic cardiac MR sequence generation from a single frame

% to-do
% check notations in section 5.2.1
% 
