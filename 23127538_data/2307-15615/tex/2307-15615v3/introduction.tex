Medical image registration involves estimating the optimal spatial transformation to align the structures of interest in a pair of fixed and moving images.
The choice of spatial transformation depends on the specific application and can be categorized as either rigid/affine or non-rigid/deformable.
In rigid/affine registration, all spatial coordinates are transformed using the same rigid/affine matrix.
On the other hand, non-rigid/deformable registration employs independent transformations for individual local regions of spatial coordinates.
Both types of registration are of great importance to many medical imaging tasks.
Rigid registration is commonly used when the rigid body assumption holds.
For example, it is used to align a structural scan---\emph{e.g.}, magnetic resonance image~(MRI) or computed tomography~(CT)---with a functional scan---\emph{e.g.}, functional magnetic resonance image~(fMRI) or positron emission tomography~(PET)---of the same patient for attenuation correction~\citep{hofmann2008mri} or interpretation of functional activities~\citep{studholme2000accurate}.
On the other hand, deformable image registration~(DIR) is often used in cases where more complex, spatially varying deformations are needed.
Examples of such applications include constructing deformable templates for a patient
cohort~\hbox{\citep{christensen1996deformable, ganser2004deformable}}
or registering atlases to a patient image for multi-atlas
segmentation~\citep{reed2009automatic, cabezas2011review,
aljabar2009multi}.

% Figure environment removed

Traditionally, image registration has been accomplished by iteratively solving an optimization problem (\emph{e.g.}, demons~\citep{vercauteren2009diffeomorphic}, LDDMM~\citep{beg2005computing}, SyN~\citep{avants2008symmetric}, DARTEL~\citep{ashburner2007fast}, and Elastix~\citep{klein2009elastix}.
{These methods are well-established and supported by strong mathematical theory but come with notable limitations. Firstly, they are computationally intensive and tend to be slow, as  they involve solving a distinct optimization problem for every pair of moving and fixed images, leading to redundancy across optimizations. Secondly, the objective function related to transformation parameters (such as displacement fields or control points) typically exhibits non-linearity, creating a non-convex optimization dilemma. To address this, attempts have been made to simplify the problem, for instance, by linearizing the objective function~\citep{sun2013efficient}, convexifying the optimization~\citep{esser2010primal, heinrich2014non, rajchl2016fast}, or adopting discretized registration techniques~\citep{glocker2008dense, glocker2011deformable,
heinrich2012globally, heinrich2014non}. However, these approaches often increase computational costs and might lead to a less realistic problem, given the inherently non-convex nature of image registration~\citep{sotiras2013deformable}.} Several review papers have covered traditional medical image registration methods extensively~\citep{maintz1998survey, hill2001medical, shams2010survey, fluck2011survey, sotiras2013deformable, oliveira2014medical, viergever2016survey}.
Interested readers can refer to these references for more information on these methods. 

In the last decade, deep learning-based methods have shown promise in improving the accuracy and efficiency of image registration.
Unlike traditional methods, deep learning-based methods train a general network by optimizing a global objective function on a
training dataset. Then in the testing phase, the trained network is directly applied to each image pair with fixed network weights without further optimization. 
{Deep learning-based methods offer a threefold advantage:
First, the diversity within the training dataset acts as an implicit regularization, effectively smoothing the loss landscape by averaging out noisy or misleading gradients that may lead to suboptimal local minima.
Secondly, the optimization of non-convex problems is highly dependent on the initial starting point. The use of pretrained weights (i.e., transfer learning), combined with advanced optimization algorithms, enhances deep learning methods' capacity to locate global minima.
Lastly, the capability to process image pairs through a single forward pass during inference, avoiding iterative optimization, results in a significant speed advantage over traditional optimization-based methods.}
{Initially, image registration network architectures were mostly encoder-based, serving either as feature extractors to replace hand-crafted features in optimization-based registration methods~\citep{wu2013unsupervised} or as regressors for estimating transformation parameters from local image patches~\citep{miao2016cnn}.
However, following the success of U-Net~\citep{ronneberger2015u} in medical imaging, learning-based deformable registration methods began to incorporate an encoder-decoder architecture within a supervised learning framework~\citep{yang2017quicksilver, rohe2017svf, sokooti2017nonrigid, uzunova2017training}, often requiring ground truth deformation fields for direct supervision.
Concurrently, the advent of spatial transformer networks~\citep{jaderberg2015spatial} heralded a shift towards unsupervised and end-to-end learning for deformable registration employing the encoder-decoder framework, which has now become the dominant approach~\citep{vos2017end, li2018non,
balakrishnan2019voxelmorph, kim2021cyclemorph, chen2022deformer}.
On the other hand, learning-based rigid/affine registration methods continue to adopt encoder-only networks~\citep{miao2016cnn, hu2018weakly, de2019deep, chen2021learning, chen2022deformer, mok2022affine}, with the output being the rigid or affine parameters.
In the context of supervised learning for these deep learning-based methods, the ground truth is typically a transformation matrix for rigid/affine registration tasks, while a dense displacement field is used for deformable registration tasks.} %{It is also important to mention the rapidly evolving field of optical flow estimation, which shares significant conceptual and methodological overlap with medical image registration. This overlap has notably influenced the development of learning-based registration methods. Although a comprehensive exploration of optical flow algorithms is beyond the scope of this paper, their relevance to our discussion is undeniable. For readers interested in this intersection, we recommend~\cite{zhai2021optical} for further reading. This backdrop of evolving learning-based registration methods sets the stage for our review.} 
While there are papers that provide general reviews of learning-based registration methods~\citep{fu2020deep, chen2021deep, xiao2021review, zou2022review}, it is important to note that these reviews may not be fully up-to-date due to the rapid advancement of the field of deep learning. Recent advancements, including learning-based similarity metrics and regularizers, novel network architectures, and innovative evaluation metrics and uncertainty estimation methods, have demonstrated promising potential for medical image registration. This paper provides a timely review of learning-based methods in medical image registration, highlighting the latest technologies that have been proposed and discussing their respective characteristics and applications. In addition, we investigate and formally define registration uncertainty for deep learning-based image registration and address the appropriate evaluation metrics for these methods that have been overlooked in previous review papers. For simplicity, we refer to deep learning-based methods as learning-based methods throughout the paper.

In this paper, we surveyed over 250 articles on learning-based
medical image registration. As depicted in Fig.~\ref{fig:paper_count},
the focus is primarily on recent advancements proposed in the last
five years. Our search covers well-established medical imaging
journals, such as Medical Image Analysis, IEEE~Transactions on Medical
Imaging, Medical Physics, and NeuroImage, as well as conference
proceedings related to medical imaging and image registration, such as
MICCAI, IPMI, WBIR, CVPR, ECCV, ICCV, and NeurIPS.
{A comprehensive list of open-sourced code from the papers reviewed in this study has been organized and is available at \url{https://bit.ly/3QgFJ9z}}.
The remainder of
the paper is organized as follows:
Section~\ref{sec:Fund_Img_Reg}~offers a brief overview of the
fundamentals of learning-based image registration.
Section~\ref{sec:loss}~explores widely-used loss functions for
learning-based registration methods which resemble objective
functions in traditional methods, and discusses other novel loss functions
enabled by deep learning. Section~\ref{sec:net_arch}~investigates
network architectures developed for medical image registration,
with a focus on recent developments.  Section~\ref{sec:uncertainty}~delves
into methods for estimating registration uncertainty in learning-based
registration.  Section~\ref{sec:Eval_Metric}~considers appropriate
evaluation metrics for learning-based methods and examines methods for
quantifying the regularity of generated deformation fields.
Section~\ref{sec:Application}~summarizes recent applications of
learning-based registration in medical imaging. Finally,
Section~\ref{sec:future_persp}~discusses current challenges and
provides future perspectives for deep learning in medical image
registration.
