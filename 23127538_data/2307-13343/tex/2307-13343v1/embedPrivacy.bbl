% Generated by IEEEtran.bst, version: 1.13 (2008/09/30)
\begin{thebibliography}{10}
\providecommand{\url}[1]{#1}
\csname url@samestyle\endcsname
\providecommand{\newblock}{\relax}
\providecommand{\bibinfo}[2]{#2}
\providecommand{\BIBentrySTDinterwordspacing}{\spaceskip=0pt\relax}
\providecommand{\BIBentryALTinterwordstretchfactor}{4}
\providecommand{\BIBentryALTinterwordspacing}{\spaceskip=\fontdimen2\font plus
\BIBentryALTinterwordstretchfactor\fontdimen3\font minus
  \fontdimen4\font\relax}
\providecommand{\BIBforeignlanguage}[2]{{%
\expandafter\ifx\csname l@#1\endcsname\relax
\typeout{** WARNING: IEEEtran.bst: No hyphenation pattern has been}%
\typeout{** loaded for the language `#1'. Using the pattern for}%
\typeout{** the default language instead.}%
\else
\language=\csname l@#1\endcsname
\fi
#2}}
\providecommand{\BIBdecl}{\relax}
\BIBdecl

\bibitem{GUPTA20181}
O.~Gupta and R.~Raskar, ``Distributed learning of deep neural network over
  multiple agents,'' \emph{Journal of Network and Computer Applications}, vol.
  116, pp. 1--8, 2018.

\bibitem{9102875}
Y.~Han, S.~Li, Y.~Cao, Q.~Ma, and M.~Yoshikawa, ``Voice-indistinguishability:
  Protecting voiceprint in privacy-preserving speech data release,'' in
  \emph{2020 IEEE International Conference on Multimedia and Expo (ICME)},
  2020, pp. 1--6.

\bibitem{Qian2018HidebehindEV}
J.~Qian, H.~Du, J.~Hou, L.~Chen, T.~Jung, and X.~Li, ``Hidebehind: Enjoy voice
  input with voiceprint unclonability and anonymity,'' \emph{Proceedings of the
  16th ACM Conference on Embedded Networked Sensor Systems}, 2018.

\bibitem{9053868}
B.~M. Lal~Srivastava, N.~Vauquier, M.~Sahidullah, A.~Bellet, M.~Tommasi, and
  E.~Vincent, ``Evaluating voice conversion-based privacy protection against
  informed attackers,'' in \emph{2020 IEEE international conference on
  acoustics, speech and signal processing (ICASSP)}, 2020, pp. 2802--2806.

\bibitem{Maouche2022EnhancingSP}
M.~Maouche, B.~M.~L. Srivastava, N.~Vauquier, A.~Bellet, M.~Tommasi, and
  E.~Vincent, ``Enhancing speech privacy with slicing,'' in \emph{Interspeech},
  09 2022, pp. 5025--5029.

\bibitem{Shamsabadi2022DifferentiallyPS}
A.~S. Shamsabadi, B.~M.~L. Srivastava, A.~Bellet, N.~Vauquier, E.~Vincent,
  M.~Maouche, M.~Tommasi, and N.~Papernot, ``Differentially private speaker
  anonymization,'' \emph{ArXiv}, vol. abs/2202.11823, 2022.

\bibitem{meyer2022speaker}
S.~Meyer, F.~Lux, P.~Denisov, J.~Koch, P.~Tilli, and N.~T. Vu, ``Speaker
  anonymization with phonetic intermediate representations,'' \emph{arXiv
  preprint arXiv:2207.04834}, 2022.

\bibitem{meyer2023anonymizing}
S.~Meyer, P.~Tilli, P.~Denisov, F.~Lux, J.~Koch, and N.~T. Vu, ``Anonymizing
  speech with generative adversarial networks to preserve speaker privacy,'' in
  \emph{2022 IEEE Spoken Language Technology Workshop (SLT)}.\hskip 1em plus
  0.5em minus 0.4em\relax IEEE, 2023, pp. 912--919.

\bibitem{ganin2016domain}
Y.~Ganin, E.~Ustinova, H.~Ajakan, P.~Germain, H.~Larochelle, F.~Laviolette,
  M.~Marchand, and V.~Lempitsky, ``Domain-adversarial training of neural
  networks,'' \emph{The journal of machine learning research}, vol.~17, no.~1,
  pp. 2096--2030, 2016.

\bibitem{Srivastava2019PrivacyPreservingAR}
B.~M.~L. Srivastava, A.~Bellet, M.~Tommasi, and E.~Vincent,
  ``Privacy-preserving adversarial representation learning in asr: Reality or
  illusion?'' \emph{ArXiv}, vol. abs/1911.04913, 2019.

\bibitem{Jaiswal2019PrivacyEM}
M.~Jaiswal and E.~M. Provost, ``Privacy enhanced multimodal neural
  representations for emotion recognition,'' in \emph{AAAI Conference on
  Artificial Intelligence}, 2019.

\bibitem{zhou2022enhancing}
W.~Zhou, H.~Wu, J.~Xu, M.~Zeineldeen, C.~L{\"u}scher, R.~Schl{\"u}ter, and
  H.~Ney, ``Enhancing and adversarial: Improve asr with speaker labels,''
  \emph{arXiv preprint arXiv:2211.06369}, 2022.

\bibitem{10031189}
Y.~K. Singla, J.~Shah, C.~Chen, and R.~R. Shah, ``What do audio transformers
  hear? probing their representations for language delivery \& structure,'' in
  \emph{2022 IEEE International Conference on Data Mining Workshops (ICDMW)},
  2022, pp. 910--925.

\bibitem{ollerenshaw21_interspeech}
A.~Ollerenshaw, M.~A. Jalal, and T.~Hain, ``{Insights on Neural Representations
  for End-to-End Speech Recognition},'' in \emph{Interspeech 2021}.\hskip 1em
  plus 0.5em minus 0.4em\relax ISCA-International Speech Communication
  Association, 2021, pp. 4079--4083.

\bibitem{ollerenshaw2022}
\BIBentryALTinterwordspacing
A.~{Ollerenshaw}, M.~A. Jalal, and T.~Hain, ``Probing statistical
  representations for end-to-end asr,'' 2022. [Online]. Available:
  \url{https://arxiv.org/abs/2211.01993}
\BIBentrySTDinterwordspacing

\bibitem{Comanducci2021ReconstructingSF}
L.~Comanducci, P.~Bestagini, M.~Tagliasacchi, A.~Sarti, and S.~Tubaro,
  ``Reconstructing speech from cnn embeddings,'' \emph{IEEE Signal Processing
  Letters}, vol.~28, pp. 952--956, 2021.

\bibitem{Gulati2020ConformerCT}
A.~Gulati, J.~Qin, C.-C. Chiu, N.~Parmar, Y.~Zhang, J.~Yu, W.~Han, S.~Wang,
  Z.~Zhang, Y.~Wu, and R.~Pang, ``Conformer: Convolution-augmented transformer
  for speech recognition,'' \emph{ArXiv}, vol. abs/2005.08100, 2020.

\bibitem{8461375}
D.~Snyder, D.~Garcia-Romero, G.~Sell, D.~Povey, and S.~Khudanpur, ``X-vectors:
  Robust dnn embeddings for speaker recognition,'' in \emph{2018 IEEE
  International Conference on Acoustics, Speech and Signal Processing
  (ICASSP)}, 2018, pp. 5329--5333.

\bibitem{10.1145/1143844.1143891}
\BIBentryALTinterwordspacing
A.~Graves, S.~Fern\'{a}ndez, F.~Gomez, and J.~Schmidhuber, ``Connectionist
  temporal classification: Labelling unsegmented sequence data with recurrent
  neural networks,'' ser. ICML '06.\hskip 1em plus 0.5em minus 0.4em\relax New
  York, NY, USA: Association for Computing Machinery, 2006, p. 369–376.
  [Online]. Available: \url{https://doi.org/10.1145/1143844.1143891}
\BIBentrySTDinterwordspacing

\bibitem{10.1109/ICASSP.2018.8462105}
C.-C. Chiu, T.~N. Sainath, Y.~Wu, R.~Prabhavalkar, P.~Nguyen, Z.~Chen,
  A.~Kannan, R.~J. Weiss, K.~Rao, E.~Gonina, N.~Jaitly, B.~Li, J.~Chorowski,
  and M.~Bacchiani, ``State-of-the-art speech recognition with
  sequence-to-sequence models,'' in \emph{2018 IEEE International Conference on
  Acoustics, Speech and Signal Processing (ICASSP)}, 2018, p. 4774–4778.

\bibitem{speechbrain}
M.~Ravanelli, T.~Parcollet, P.~Plantinga, A.~Rouhe, S.~Cornell, L.~Lugosch,
  C.~Subakan, N.~Dawalatabad, A.~Heba, J.~Zhong, J.-C. Chou, S.-L. Yeh, S.-W.
  Fu, C.-F. Liao, E.~Rastorgueva, F.~Grondin, W.~Aris, H.~Na, Y.~Gao, R.~D.
  Mori, and Y.~Bengio, ``{SpeechBrain}: A general-purpose speech toolkit,''
  2021, arXiv:2106.04624.

\bibitem{snyder2018x}
D.~Snyder, D.~Garcia-Romero, G.~Sell, D.~Povey, and S.~Khudanpur, ``X-vectors:
  Robust dnn embeddings for speaker recognition,'' in \emph{2018 IEEE
  international conference on acoustics, speech and signal processing
  (ICASSP)}, 2018, pp. 5329--5333.

\bibitem{szegedy2013intriguing}
C.~Szegedy, W.~Zaremba, I.~Sutskever, J.~Bruna, D.~Erhan, I.~Goodfellow, and
  R.~Fergus, ``Intriguing properties of neural networks,'' \emph{arXiv preprint
  arXiv:1312.6199}, 2013.

\bibitem{goodfellow2014explaining}
I.~J. Goodfellow, J.~Shlens, and C.~Szegedy, ``Explaining and harnessing
  adversarial examples,'' \emph{stat}, vol. 1050, p.~20, 2015.

\bibitem{melgan2019}
K.~Kumar, R.~Kumar, T.~de~Boissiere, L.~Gestin, W.~Z. Teoh, J.~Sotelo,
  A.~de~Br\'{e}bisson, Y.~Bengio, and A.~C. Courville, ``Melgan: Generative
  adversarial networks for conditional waveform synthesis,'' in \emph{Advances
  in Neural Information Processing Systems}, H.~Wallach, H.~Larochelle,
  A.~Beygelzimer, F.~d\textquotesingle Alch\'{e}-Buc, E.~Fox, and R.~Garnett,
  Eds., vol.~32.\hskip 1em plus 0.5em minus 0.4em\relax Curran Associates,
  Inc., 2019.

\bibitem{hifigan2020}
J.~Kong, J.~Kim, and J.~Bae, ``Hifi-gan: Generative adversarial networks for
  efficient and high fidelity speech synthesis,'' in \emph{Advances in Neural
  Information Processing Systems}, H.~Larochelle, M.~Ranzato, R.~Hadsell,
  M.~Balcan, and H.~Lin, Eds., vol.~33.\hskip 1em plus 0.5em minus 0.4em\relax
  Curran Associates, Inc., 2020, pp. 17\,022--17\,033.

\bibitem{nagrani2017voxceleb}
A.~Nagrani, J.~S. Chung, and A.~Zisserman, ``Voxceleb: a large-scale speaker
  identification dataset,'' \emph{arXiv preprint arXiv:1706.08612}, 2017.

\bibitem{chung2018voxceleb2}
J.~S. Chung, A.~Nagrani, and A.~Zisserman, ``Voxceleb2: Deep speaker
  recognition,'' \emph{arXiv preprint arXiv:1806.05622}, 2018.

\bibitem{7178964}
V.~Panayotov, G.~Chen, D.~Povey, and S.~Khudanpur, ``Librispeech: An asr corpus
  based on public domain audio books,'' in \emph{2015 IEEE International
  Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 2015, pp.
  5206--5210.

\end{thebibliography}
