@inproceedings{ma2021smil,
  title={Smil: Multimodal learning with severely missing modality},
  author={Ma, Mengmeng and Ren, Jian and Zhao, Long and Tulyakov, Sergey and Wu, Cathy and Peng, Xi},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={35},
  number={3},
  pages={2302--2310},
  year={2021}
}

@inproceedings{li2020hero,
  title={HERO: Hierarchical Encoder for Video+ Language Omni-representation Pre-training},
  author={Li, Linjie and Chen, Yen-Chun and Cheng, Yu and Gan, Zhe and Yu, Licheng and Liu, Jingjing},
  booktitle={EMNLP},
  year={2020}
}

@InProceedings{Bain21frozen,
  author       = "Max Bain and Arsha Nagrani and G{\"u}l Varol and Andrew Zisserman",
  title        = "Frozen in Time: A Joint Video and Image Encoder for End-to-End Retrieval",
  booktitle    = "ICCV",
  year         = "2021",
}

@inproceedings{lei2021clipbert,
  title={Less is More: ClipBERT for Video-and-Language Learning via Sparse Sampling},
  author={Lei, Jie and Li, Linjie and Zhou, Luowei and Gan, Zhe and Berg, Tamara L. and Bansal, Mohit and Liu, Jingjing},
  booktitle={CVPR},
  year={2021}
}

@inproceedings{gorti2022xpool,
  title={X-Pool: Cross-Modal Language-Video Attention for Text-Video Retrieval},
  author={Gorti, Satya Krishna and Vouitsis, Noel and Ma, Junwei and Golestan, Keyvan and Volkovs, Maksims and Garg, Animesh and Yu, Guangwei},
  booktitle={CVPR},
  year={2022}
}

@inproceedings{liu2022ts2net,
      title={TS2-Net: Token Shift and Selection Transformer for Text-Video Retrieval}, 
      author={Yuqi Liu and Pengfei Xiong and Luhui Xu and Shengming Cao and Qin Jin},
      year={2022},
      booktitle={ECCV},
}

@InProceedings{bridgeformer,
    author    = {Ge, Yuying and Ge, Yixiao and Liu, Xihui and Li, Dian and Shan, Ying and Qie, Xiaohu and Luo, Ping},
    title     = {Bridging Video-Text Retrieval With Multiple Choice Questions},
    booktitle = {CVPR},
    year      = {2022}
}


@inproceedings{alpro,
  title={Align and Prompt: Video-and-Language Pre-training with Entity Prompts},
  author={Li, Dongxu and Li, Junnan and Li, Hongdong and Niebles, Juan Carlos and Hoi, Steven CH},
  booktitle={CVPR},
  pages={4953--4963},
  year={2022}
}

@inproceedings{xclip,
author = {Ma, Yiwei and Xu, Guohai and Sun, Xiaoshuai and Yan, Ming and Zhang, Ji and Ji, Rongrong},
title = {X-CLIP: End-to-End Multi-Grained Contrastive Learning for Video-Text Retrieval},
year = {2022},
booktitle = {ACM MM}
}

@article{Luo2022CLIP4ClipAE,
  title={CLIP4Clip: An Empirical Study of CLIP for End to End Video Clip Retrieval},
  author={Huaishao Luo and Lei Ji and Ming Zhong and Yang Chen and Wen Lei and Nan Duan and Tianrui Li},
  journal={Neurocomputing},
  year={2022},
  volume={508},
  pages={293-304}
}

@inproceedings{everythingatonce,
  author    = {Nina Shvetsova and
               Brian Chen and
               Andrew Rouditchenko and
               Samuel Thomas and
               Brian Kingsbury and
               Rog{\'{e}}rio Feris and
               David Harwath and
               James R. Glass and
               Hilde Kuehne},
  title     = {Everything at Once - Multi-modal Fusion Transformer for Video Retrieval},
  booktitle = {CVPR},
  year      = {2022}
}

@InProceedings{ECLIPSE_ECCV22,
author = {Yan-Bo Lin and Jie Lei and Mohit Bansal and Gedas Bertasius},
title = {ECLIPSE: Efficient Long-range Video Retrieval using Sight and Sound},
booktitle = {ECCV},
year = {2022}
}

# multimodal transformers

@inproceedings{vatt,
  author    = {Hassan Akbari and
               Liangzhe Yuan and
               Rui Qian and
               Wei{-}Hong Chuang and
               Shih{-}Fu Chang and
               Yin Cui and
               Boqing Gong},
  title     = {{VATT:} Transformers for Multimodal Self-Supervised Learning from
               Raw Video, Audio and Text},
  booktitle = {NeurIPS},
  year      = {2021}
}

@inproceedings{merlot_reserve,
  author    = {Rowan Zellers and
               Jiasen Lu and
               Ximing Lu and
               Youngjae Yu and
               Yanpeng Zhao and
               Mohammadreza Salehi and
               Aditya Kusupati and
               Jack Hessel and
               Ali Farhadi and
               Yejin Choi},
  title     = {{MERLOT} {RESERVE:} Neural Script Knowledge through Vision and Language
               and Sound},
  booktitle = {CVPR},
  year      = {2022}
}

@inproceedings{msrvtt,
  author    = {Jun Xu and
               Tao Mei and
               Ting Yao and
               Yong Rui},
  title     = {{MSR-VTT:} {A} Large Video Description Dataset for Bridging Video
               and Language},
  booktitle = {CVPR},
  year      = {2016}
}


@inproceedings{lsmdc,
  author    = {Anna Rohrbach and
               Marcus Rohrbach and
               Niket Tandon and
               Bernt Schiele},
  title     = {A dataset for Movie Description},
  booktitle = {CVPR},
  year      = {2015}
}


@inproceedings{gong21b_interspeech,
  author={Yuan Gong and Yu-An Chung and James Glass},
  title={AST: Audio Spectrogram Transformer},
  year={2021},
  booktitle={Interspeech},
}

@InProceedings{clip,
  title = {Learning Transferable Visual Models From Natural Language Supervision},
  author ={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and Krueger, Gretchen and Sutskever, Ilya},
  booktitle = {ICML},
  year = {2021}
}


@inproceedings{qbnorm,
  title={Cross Modal Retrieval with Querybank Normalisation},
  author={Bogolin, Simion-Vlad and Croitoru, Ioana and Jin, Hailin and Liu, Yang and Albanie, Samuel},
  booktitle={CVPR},
  year={2022}
}

@article{dsl,
  title={Improving Video-Text Retrieval by Multi-Stream Corpus Alignment and Dual Softmax Loss},
  author={Xingyi Cheng and Hezheng Lin and Xiangyu Wu and F. Yang and Dong Shen},
journal={arXiv preprint arXiv:2109.04290},
  year={2021}
}


@inproceedings{deit,
  author    = {Hugo Touvron and
               Matthieu Cord and
               Matthijs Douze and
               Francisco Massa and
               Alexandre Sablayrolles and
               Herv{\'{e}} J{\'{e}}gou},
  title     = {Training data-efficient image transformers {\&} distillation through
               attention},
  booktitle = {ICML},
  year      = {2021}
}

@inproceedings{audioset,
  author    = {Jort F. Gemmeke and
               Daniel P. W. Ellis and
               Dylan Freedman and
               Aren Jansen and
               Wade Lawrence and
               R. Channing Moore and
               Manoj Plakal and
               Marvin Ritter},
  title     = {Audio Set: An ontology and human-labeled dataset for audio events},
  booktitle = {ICASSP},
  year      = {2017}
}

@article{cpc,
  author    = {A{\"{a}}ron van den Oord and
               Yazhe Li and
               Oriol Vinyals},
  title     = {Representation Learning with Contrastive Predictive Coding},
  journal={arXiv preprint arXiv:1807.03748},
  year      = {2018},

}


@inproceedings{radford2021learning,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle={ICML},
  year={2021},
}

@inproceedings{wang2022omnivl,
  title={OmniVL: One Foundation Model for Image-Language and Video-Language Tasks},
  author={Wang, Junke and Chen, Dongdong and Wu, Zuxuan and Luo, Chong and Zhou, Luowei and Zhao, Yucheng and Xie, Yujia and Liu, Ce and Jiang, Yu-Gang and Yuan, Lu},
  booktitle={NeurIPS},
  year={2022}
}



@article{xu2022multimodal,
  title={Multimodal learning with transformers: a survey},
  author={Xu, Peng and Zhu, Xiatian and Clifton, David A},
  journal={arXiv preprint arXiv:2206.06488},
  year={2022}
}


@inproceedings{hu2022lightweight,
  title={Lightweight Attentional Feature Fusion: A New Baseline for Text-to-Video Retrieval},
  author={Hu, Fan and Chen, Aozhu and Wang, Ziyue and Zhou, Fangming and Dong, Jianfeng and Li, Xirong},
  booktitle={ECCV},
  year={2022}
}

@inproceedings{liu2022animating,
  title={Animating Images to Transfer CLIP for Video-Text Retrieval},
  author={Liu, Yu and Chen, Huai and Huang, Lianghua and Chen, Di and Wang, Bin and Pan, Pan and Wang, Lisheng},
  booktitle={SIGIR},
  year={2022}
}

@article{dong2021dual,
  title={Dual encoding for video retrieval by text},
  author={Dong, Jianfeng and Li, Xirong and Xu, Chaoxi and Yang, Xun and Yang, Gang and Wang, Xun and Wang, Meng},
  journal={TPAMI},
  volume    = {44},
  number    = {8},
  year={2021}
}

@inproceedings{wang2021t2vlad,
  title={T2vlad: global-local sequence alignment for text-video retrieval},
  author={Wang, Xiaohan and Zhu, Linchao and Yang, Yi},
  booktitle={CVPR},
  year={2021}
}

@inproceedings{croitoru2021teachtext,
  title={Teachtext: Crossmodal generalized distillation for text-video retrieval},
  author={Croitoru, Ioana and Bogolin, Simion-Vlad and Leordeanu, Marius and Jin, Hailin and Zisserman, Andrew and Albanie, Samuel and Liu, Yang},
  booktitle={ICCV},
  year={2021}
}

@article{ging2020coot,
  title={Coot: Cooperative hierarchical transformer for video-text representation learning},
  author={Ging, Simon and Zolfaghari, Mohammadreza and Pirsiavash, Hamed and Brox, Thomas},
  journal={NeurIPS},
  year={2020}
}

@inproceedings{zhu2020actbert,
  title={Actbert: Learning global-local video-text representations},
  author={Zhu, Linchao and Yang, Yi},
  booktitle={CVPR},
  year={2020}
}

@inproceedings{zhang2018cross,
  title={Cross-modal and hierarchical modeling of video and text},
  author={Zhang, Bowen and Hu, Hexiang and Sha, Fei},
  booktitle={ECCV},
  year={2018}
}

@inproceedings{hao2018integrating,
  title={Integrating both visual and audio cues for enhanced video caption},
  author={Hao, Wangli and Zhang, Zhaoxiang and Guan, He},
  booktitle={AAAI},
  year={2018}
}

@article{baltruvsaitis2018multimodal,
  title={Multimodal machine learning: A survey and taxonomy},
  author={Baltru{\v{s}}aitis, Tadas and Ahuja, Chaitanya and Morency, Louis-Philippe},
  journal={TPAMI},
  volume={41},
  number={2},
  year={2018}
}
@article{bayoudh2022survey,
  title={A survey on deep multimodal learning for computer vision: advances, trends, applications, and datasets},
  author={Bayoudh, Khaled and Knani, Raja and Hamdaoui, Fay{\c{c}}al and Mtibaa, Abdellatif},
  journal={The Visual Computer},
  volume={38},
  number={8},
  year={2022},
}

@article{radford2018improving,
  title={Improving language understanding by generative pre-training},
  author={Radford, Alec and Narasimhan, Karthik and Salimans, Tim and Sutskever, Ilya and others},
  year={2018},
  publisher={OpenAI}
}

@article{radford2019language,
  title={Language models are unsupervised multitask learners},
  author={Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya and others},
  journal={OpenAI blog},
  volume={1},
  number={8},
  pages={9},
  year={2019}
}

@article{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={NeurIPS},
  year={2020}
}

@inproceedings{wang2020alignnet,
  title={Alignnet: A unifying approach to audio-visual alignment},
  author={Wang, Jianren and Fang, Zhaoyuan and Zhao, Hang},
  booktitle={WACV},
  year={2020}
}

@InProceedings{vatex,
author = {Wang, Xin and Wu, Jiawei and Chen, Junkun and Li, Lei and Wang, Yuan-Fang and Wang, William Yang},
title = {VaTeX: A Large-Scale, High-Quality Multilingual Dataset for Video-and-Language Research},
booktitle = {ICCV},
year = {2019}
}

@inproceedings{charades,
  author    = {Gunnar A. Sigurdsson and
               G{\"{u}}l Varol and
               Xiaolong Wang and
               Ali Farhadi and
               Ivan Laptev and
               Abhinav Gupta},
  editor    = {Bastian Leibe and
               Jiri Matas and
               Nicu Sebe and
               Max Welling},
  title     = {Hollywood in Homes: Crowdsourcing Data Collection for Activity Understanding},
  booktitle = {ECCV},
  year      = {2016}
}

@article{hgr,
  title={Fine-grained Video-Text Retrieval with Hierarchical Graph Reasoning},
  author={Chen, Shizhe and Zhao, Yida and Jin, Qin and Wu, Qi},
  journal={CVPR},
  year={2020}
}

@inproceedings{MMVN,
  author       = {Jean{-}Baptiste Alayrac and
                  Adri{\`{a}} Recasens and
                  Rosalia Schneider and
                  Relja Arandjelovic and
                  Jason Ramapuram and
                  Jeffrey De Fauw and
                  Lucas Smaira and
                  Sander Dieleman and
                  Andrew Zisserman},
  title        = {Self-Supervised MultiModal Versatile Networks},
  booktitle    = {NeurIPS},
  year         = {2020}
}

@InProceedings{miech18learning,
    author      = "Miech, Antoine and  Laptev, Ivan and Sivic, Josef",
    title       = "{L}earning a {T}ext-{V}ideo {E}mbedding from {I}mcomplete and {H}eterogeneous {D}ata",
    journal     ={arXiv preprint arXiv:1804.02516},
    year        = "2018"
}

@inproceedings{collab_experts,
  author       = {Yang Liu and
                  Samuel Albanie and
                  Arsha Nagrani and
                  Andrew Zisserman},
  title        = {Use What You Have: Video retrieval using representations from collaborative
                  experts},
  booktitle    = {BMVC},
  year         = {2019}
}

@inproceedings{centerclip,
  author       = {Shuai Zhao and
                  Linchao Zhu and
                  Xiaohan Wang and
                  Yi Yang},
  title        = {CenterCLIP: Token Clustering for Efficient Text-Video Retrieval},
  booktitle    = {SIGIR},
  year         = {2022}
}
