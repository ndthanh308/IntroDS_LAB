\begin{thebibliography}{10}\itemsep=-1pt

\bibitem{vatt}
Hassan Akbari, Liangzhe Yuan, Rui Qian, Wei{-}Hong Chuang, Shih{-}Fu Chang, Yin
  Cui, and Boqing Gong.
\newblock {VATT:} transformers for multimodal self-supervised learning from raw
  video, audio and text.
\newblock In {\em NeurIPS}, 2021.

\bibitem{MMVN}
Jean{-}Baptiste Alayrac, Adri{\`{a}} Recasens, Rosalia Schneider, Relja
  Arandjelovic, Jason Ramapuram, Jeffrey~De Fauw, Lucas Smaira, Sander
  Dieleman, and Andrew Zisserman.
\newblock Self-supervised multimodal versatile networks.
\newblock In {\em NeurIPS}, 2020.

\bibitem{Bain21frozen}
Max Bain, Arsha Nagrani, G{\"u}l Varol, and Andrew Zisserman.
\newblock Frozen in time: A joint video and image encoder for end-to-end
  retrieval.
\newblock In {\em ICCV}, 2021.

\bibitem{baltruvsaitis2018multimodal}
Tadas Baltru{\v{s}}aitis, Chaitanya Ahuja, and Louis-Philippe Morency.
\newblock Multimodal machine learning: A survey and taxonomy.
\newblock {\em TPAMI}, 41(2), 2018.

\bibitem{bayoudh2022survey}
Khaled Bayoudh, Raja Knani, Fay{\c{c}}al Hamdaoui, and Abdellatif Mtibaa.
\newblock A survey on deep multimodal learning for computer vision: advances,
  trends, applications, and datasets.
\newblock {\em The Visual Computer}, 38(8), 2022.

\bibitem{qbnorm}
Simion-Vlad Bogolin, Ioana Croitoru, Hailin Jin, Yang Liu, and Samuel Albanie.
\newblock Cross modal retrieval with querybank normalisation.
\newblock In {\em CVPR}, 2022.

\bibitem{brown2020language}
Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared~D Kaplan, Prafulla
  Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell,
  et~al.
\newblock Language models are few-shot learners.
\newblock {\em NeurIPS}, 2020.

\bibitem{hgr}
Shizhe Chen, Yida Zhao, Qin Jin, and Qi Wu.
\newblock Fine-grained video-text retrieval with hierarchical graph reasoning.
\newblock {\em CVPR}, 2020.

\bibitem{dsl}
Xingyi Cheng, Hezheng Lin, Xiangyu Wu, F. Yang, and Dong Shen.
\newblock Improving video-text retrieval by multi-stream corpus alignment and
  dual softmax loss.
\newblock {\em arXiv preprint arXiv:2109.04290}, 2021.

\bibitem{croitoru2021teachtext}
Ioana Croitoru, Simion-Vlad Bogolin, Marius Leordeanu, Hailin Jin, Andrew
  Zisserman, Samuel Albanie, and Yang Liu.
\newblock Teachtext: Crossmodal generalized distillation for text-video
  retrieval.
\newblock In {\em ICCV}, 2021.

\bibitem{dong2021dual}
Jianfeng Dong, Xirong Li, Chaoxi Xu, Xun Yang, Gang Yang, Xun Wang, and Meng
  Wang.
\newblock Dual encoding for video retrieval by text.
\newblock {\em TPAMI}, 44(8), 2021.

\bibitem{bridgeformer}
Yuying Ge, Yixiao Ge, Xihui Liu, Dian Li, Ying Shan, Xiaohu Qie, and Ping Luo.
\newblock Bridging video-text retrieval with multiple choice questions.
\newblock In {\em CVPR}, 2022.

\bibitem{audioset}
Jort~F. Gemmeke, Daniel P.~W. Ellis, Dylan Freedman, Aren Jansen, Wade
  Lawrence, R.~Channing Moore, Manoj Plakal, and Marvin Ritter.
\newblock Audio set: An ontology and human-labeled dataset for audio events.
\newblock In {\em ICASSP}, 2017.

\bibitem{ging2020coot}
Simon Ging, Mohammadreza Zolfaghari, Hamed Pirsiavash, and Thomas Brox.
\newblock Coot: Cooperative hierarchical transformer for video-text
  representation learning.
\newblock {\em NeurIPS}, 2020.

\bibitem{gong21b_interspeech}
Yuan Gong, Yu-An Chung, and James Glass.
\newblock Ast: Audio spectrogram transformer.
\newblock In {\em Interspeech}, 2021.

\bibitem{gorti2022xpool}
Satya~Krishna Gorti, Noel Vouitsis, Junwei Ma, Keyvan Golestan, Maksims
  Volkovs, Animesh Garg, and Guangwei Yu.
\newblock X-pool: Cross-modal language-video attention for text-video
  retrieval.
\newblock In {\em CVPR}, 2022.

\bibitem{hao2018integrating}
Wangli Hao, Zhaoxiang Zhang, and He Guan.
\newblock Integrating both visual and audio cues for enhanced video caption.
\newblock In {\em AAAI}, 2018.

\bibitem{hu2022lightweight}
Fan Hu, Aozhu Chen, Ziyue Wang, Fangming Zhou, Jianfeng Dong, and Xirong Li.
\newblock Lightweight attentional feature fusion: A new baseline for
  text-to-video retrieval.
\newblock In {\em ECCV}, 2022.

\bibitem{lei2021clipbert}
Jie Lei, Linjie Li, Luowei Zhou, Zhe Gan, Tamara~L. Berg, Mohit Bansal, and
  Jingjing Liu.
\newblock Less is more: Clipbert for video-and-language learning via sparse
  sampling.
\newblock In {\em CVPR}, 2021.

\bibitem{alpro}
Dongxu Li, Junnan Li, Hongdong Li, Juan~Carlos Niebles, and Steven~CH Hoi.
\newblock Align and prompt: Video-and-language pre-training with entity
  prompts.
\newblock In {\em CVPR}, pages 4953--4963, 2022.

\bibitem{li2020hero}
Linjie Li, Yen-Chun Chen, Yu Cheng, Zhe Gan, Licheng Yu, and Jingjing Liu.
\newblock Hero: Hierarchical encoder for video+ language omni-representation
  pre-training.
\newblock In {\em EMNLP}, 2020.

\bibitem{ECLIPSE_ECCV22}
Yan-Bo Lin, Jie Lei, Mohit Bansal, and Gedas Bertasius.
\newblock Eclipse: Efficient long-range video retrieval using sight and sound.
\newblock In {\em ECCV}, 2022.

\bibitem{collab_experts}
Yang Liu, Samuel Albanie, Arsha Nagrani, and Andrew Zisserman.
\newblock Use what you have: Video retrieval using representations from
  collaborative experts.
\newblock In {\em BMVC}, 2019.

\bibitem{liu2022animating}
Yu Liu, Huai Chen, Lianghua Huang, Di Chen, Bin Wang, Pan Pan, and Lisheng
  Wang.
\newblock Animating images to transfer clip for video-text retrieval.
\newblock In {\em SIGIR}, 2022.

\bibitem{liu2022ts2net}
Yuqi Liu, Pengfei Xiong, Luhui Xu, Shengming Cao, and Qin Jin.
\newblock Ts2-net: Token shift and selection transformer for text-video
  retrieval.
\newblock In {\em ECCV}, 2022.

\bibitem{Luo2022CLIP4ClipAE}
Huaishao Luo, Lei Ji, Ming Zhong, Yang Chen, Wen Lei, Nan Duan, and Tianrui Li.
\newblock Clip4clip: An empirical study of clip for end to end video clip
  retrieval.
\newblock {\em Neurocomputing}, 508:293--304, 2022.

\bibitem{ma2021smil}
Mengmeng Ma, Jian Ren, Long Zhao, Sergey Tulyakov, Cathy Wu, and Xi Peng.
\newblock Smil: Multimodal learning with severely missing modality.
\newblock In {\em Proceedings of the AAAI Conference on Artificial
  Intelligence}, volume~35, pages 2302--2310, 2021.

\bibitem{xclip}
Yiwei Ma, Guohai Xu, Xiaoshuai Sun, Ming Yan, Ji Zhang, and Rongrong Ji.
\newblock X-clip: End-to-end multi-grained contrastive learning for video-text
  retrieval.
\newblock In {\em ACM MM}, 2022.

\bibitem{miech18learning}
Antoine Miech, Ivan Laptev, and Josef Sivic.
\newblock {L}earning a {T}ext-{V}ideo {E}mbedding from {I}mcomplete and
  {H}eterogeneous {D}ata.
\newblock 2018.

\bibitem{clip}
Alec Radford, Jong~Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh,
  Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark,
  Gretchen Krueger, and Ilya Sutskever.
\newblock Learning transferable visual models from natural language
  supervision.
\newblock In {\em ICML}, 2021.

\bibitem{radford2018improving}
Alec Radford, Karthik Narasimhan, Tim Salimans, Ilya Sutskever, et~al.
\newblock Improving language understanding by generative pre-training.
\newblock 2018.

\bibitem{radford2019language}
Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya
  Sutskever, et~al.
\newblock Language models are unsupervised multitask learners.
\newblock {\em OpenAI blog}, 1(8):9, 2019.

\bibitem{lsmdc}
Anna Rohrbach, Marcus Rohrbach, Niket Tandon, and Bernt Schiele.
\newblock A dataset for movie description.
\newblock In {\em CVPR}, 2015.

\bibitem{everythingatonce}
Nina Shvetsova, Brian Chen, Andrew Rouditchenko, Samuel Thomas, Brian
  Kingsbury, Rog{\'{e}}rio Feris, David Harwath, James~R. Glass, and Hilde
  Kuehne.
\newblock Everything at once - multi-modal fusion transformer for video
  retrieval.
\newblock In {\em CVPR}, 2022.

\bibitem{charades}
Gunnar~A. Sigurdsson, G{\"{u}}l Varol, Xiaolong Wang, Ali Farhadi, Ivan Laptev,
  and Abhinav Gupta.
\newblock Hollywood in homes: Crowdsourcing data collection for activity
  understanding.
\newblock In Bastian Leibe, Jiri Matas, Nicu Sebe, and Max Welling, editors,
  {\em ECCV}, 2016.

\bibitem{deit}
Hugo Touvron, Matthieu Cord, Matthijs Douze, Francisco Massa, Alexandre
  Sablayrolles, and Herv{\'{e}} J{\'{e}}gou.
\newblock Training data-efficient image transformers {\&} distillation through
  attention.
\newblock In {\em ICML}, 2021.

\bibitem{cpc}
A{\"{a}}ron van~den Oord, Yazhe Li, and Oriol Vinyals.
\newblock Representation learning with contrastive predictive coding.
\newblock {\em arXiv preprint arXiv:1807.03748}, 2018.

\bibitem{wang2022omnivl}
Junke Wang, Dongdong Chen, Zuxuan Wu, Chong Luo, Luowei Zhou, Yucheng Zhao,
  Yujia Xie, Ce Liu, Yu-Gang Jiang, and Lu Yuan.
\newblock Omnivl: One foundation model for image-language and video-language
  tasks.
\newblock In {\em NeurIPS}, 2022.

\bibitem{wang2020alignnet}
Jianren Wang, Zhaoyuan Fang, and Hang Zhao.
\newblock Alignnet: A unifying approach to audio-visual alignment.
\newblock In {\em WACV}, 2020.

\bibitem{vatex}
Xin Wang, Jiawei Wu, Junkun Chen, Lei Li, Yuan-Fang Wang, and William~Yang
  Wang.
\newblock Vatex: A large-scale, high-quality multilingual dataset for
  video-and-language research.
\newblock In {\em ICCV}, 2019.

\bibitem{wang2021t2vlad}
Xiaohan Wang, Linchao Zhu, and Yi Yang.
\newblock T2vlad: global-local sequence alignment for text-video retrieval.
\newblock In {\em CVPR}, 2021.

\bibitem{msrvtt}
Jun Xu, Tao Mei, Ting Yao, and Yong Rui.
\newblock {MSR-VTT:} {A} large video description dataset for bridging video and
  language.
\newblock In {\em CVPR}, 2016.

\bibitem{xu2022multimodal}
Peng Xu, Xiatian Zhu, and David~A Clifton.
\newblock Multimodal learning with transformers: a survey.
\newblock {\em arXiv preprint arXiv:2206.06488}, 2022.

\bibitem{merlot_reserve}
Rowan Zellers, Jiasen Lu, Ximing Lu, Youngjae Yu, Yanpeng Zhao, Mohammadreza
  Salehi, Aditya Kusupati, Jack Hessel, Ali Farhadi, and Yejin Choi.
\newblock {MERLOT} {RESERVE:} neural script knowledge through vision and
  language and sound.
\newblock In {\em CVPR}, 2022.

\bibitem{zhang2018cross}
Bowen Zhang, Hexiang Hu, and Fei Sha.
\newblock Cross-modal and hierarchical modeling of video and text.
\newblock In {\em ECCV}, 2018.

\bibitem{centerclip}
Shuai Zhao, Linchao Zhu, Xiaohan Wang, and Yi Yang.
\newblock Centerclip: Token clustering for efficient text-video retrieval.
\newblock In {\em SIGIR}, 2022.

\bibitem{zhu2020actbert}
Linchao Zhu and Yi Yang.
\newblock Actbert: Learning global-local video-text representations.
\newblock In {\em CVPR}, 2020.

\end{thebibliography}
