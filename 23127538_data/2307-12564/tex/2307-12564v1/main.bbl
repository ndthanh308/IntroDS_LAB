\begin{thebibliography}{10}

\bibitem{blei2003modeling}
D.~M. Blei and M.~I. Jordan, ``Modeling annotated data,'' in {\em Proceedings
  of the 26th annual international ACM SIGIR conference on Research and
  development in informaion retrieval}, pp.~127--134, 2003.

\bibitem{boyd2007topic}
J.~Boyd-Graber, D.~Blei, and X.~Zhu, ``A topic model for word sense
  disambiguation,'' in {\em Proceedings of the 2007 joint conference on
  empirical methods in natural language processing and computational natural
  language learning (EMNLP-CoNLL)}, pp.~1024--1033, 2007.

\bibitem{blei2003latent}
D.~M. Blei, A.~Y. Ng, and M.~I. Jordan, ``Latent dirichlet allocation,'' {\em
  Journal of machine Learning research}, vol.~3, no.~Jan, pp.~993--1022, 2003.

\bibitem{cheng2014btm}
X.~Cheng, X.~Yan, Y.~Lan, and J.~Guo, ``Btm: Topic modeling over short texts,''
  {\em IEEE Transactions on Knowledge and Data Engineering}, vol.~26, no.~12,
  pp.~2928--2941, 2014.

\bibitem{hai2017analyzing}
Z.~Hai, G.~Cong, K.~Chang, P.~Cheng, and C.~Miao, ``Analyzing sentiments in one
  go: A supervised joint topic modeling approach,'' {\em IEEE Transactions on
  Knowledge and Data Engineering}, vol.~29, no.~6, pp.~1172--1185, 2017.

\bibitem{guo2013two}
Z.~Guo, Z.~M. Zhang, S.~Zhu, Y.~Chi, and Y.~Gong, ``A two-level topic model
  towards knowledge discovery from citation networks,'' {\em IEEE Transactions
  on Knowledge and Data Engineering}, vol.~26, no.~4, pp.~780--794, 2013.

\bibitem{soleimani2014parsimonious}
H.~Soleimani and D.~J. Miller, ``Parsimonious topic models with salient word
  discovery,'' {\em IEEE Transactions on Knowledge and Data Engineering},
  vol.~27, no.~3, pp.~824--837, 2014.

\bibitem{zhao2014incorporating}
W.~X. Zhao, J.~Wang, Y.~He, J.-Y. Nie, J.-R. Wen, and X.~Li, ``Incorporating
  social role theory into topic models for social media content analysis,''
  {\em IEEE Transactions on Knowledge and Data Engineering}, vol.~27, no.~4,
  pp.~1032--1044, 2014.

\bibitem{duan2014limtopic}
D.~Duan, Y.~Li, R.~Li, R.~Zhang, X.~Gu, and K.~Wen, ``Limtopic: a framework of
  incorporating link based importance into topic modeling,'' {\em IEEE
  Transactions on Knowledge and Data Engineering}, vol.~26, no.~10,
  pp.~2493--2506, 2014.

\bibitem{zuo2021topic}
Y.~Zuo, C.~Li, H.~Lin, and J.~Wu, ``Topic modeling of short texts: A
  pseudo-document view with word embedding enhancement,'' {\em IEEE
  Transactions on Knowledge and Data Engineering}, 2021.

\bibitem{zhang2019combine}
P.~Zhang, S.~Wang, D.~Li, X.~Li, and Z.~Xu, ``Combine topic modeling with
  semantic embedding: Embedding enhanced topic model,'' {\em IEEE Transactions
  on Knowledge and Data Engineering}, vol.~32, no.~12, pp.~2322--2335, 2019.

\bibitem{yao2018topic}
L.~Yao, Y.~Zhang, B.~Wei, W.~Zhang, and Z.~Jin, ``A topic modeling approach for
  traditional chinese medicine prescriptions,'' {\em IEEE Transactions on
  Knowledge and Data Engineering}, vol.~30, no.~6, pp.~1007--1021, 2018.

\bibitem{wang2016using}
Y.~Wang, J.~Liu, Y.~Huang, and X.~Feng, ``Using hashtag graph-based topic model
  to connect semantically-related words without co-occurrence in microblogs,''
  {\em IEEE Transactions on Knowledge and Data Engineering}, vol.~28, no.~7,
  pp.~1919--1933, 2016.

\bibitem{shorten2019survey}
C.~Shorten and T.~M. Khoshgoftaar, ``A survey on image data augmentation for
  deep learning,'' {\em Journal of big data}, vol.~6, no.~1, pp.~1--48, 2019.

\bibitem{chen2020big}
T.~Chen, S.~Kornblith, K.~Swersky, M.~Norouzi, and G.~E. Hinton, ``Big
  self-supervised models are strong semi-supervised learners,'' {\em Advances
  in neural information processing systems}, vol.~33, pp.~22243--22255, 2020.

\bibitem{he2020momentum}
K.~He, H.~Fan, Y.~Wu, S.~Xie, and R.~Girshick, ``Momentum contrast for
  unsupervised visual representation learning,'' in {\em Proceedings of the
  IEEE/CVF conference on computer vision and pattern recognition},
  pp.~9729--9738, 2020.

\bibitem{jaiswal2020survey}
A.~Jaiswal, A.~R. Babu, M.~Z. Zadeh, D.~Banerjee, and F.~Makedon, ``A survey on
  contrastive self-supervised learning,'' {\em Technologies}, vol.~9, no.~1,
  p.~2, 2020.

\bibitem{bayer2022survey}
M.~Bayer, M.-A. Kaufhold, and C.~Reuter, ``A survey on data augmentation for
  text classification,'' {\em ACM Computing Surveys}, vol.~55, no.~7,
  pp.~1--39, 2022.

\bibitem{shorten2021text}
C.~Shorten, T.~M. Khoshgoftaar, and B.~Furht, ``Text data augmentation for deep
  learning,'' {\em Journal of big Data}, vol.~8, pp.~1--34, 2021.

\bibitem{yurochkin2019hierarchical}
M.~Yurochkin, S.~Claici, E.~Chien, F.~Mirzazadeh, and J.~M. Solomon,
  ``Hierarchical optimal transport for document representation,'' {\em Advances
  in Neural Information Processing Systems}, vol.~32, 2019.

\bibitem{zhao2021topic}
H.~Zhao, D.~Phung, V.~Huynh, Y.~Jin, L.~Du, and W.~Buntine, ``Topic modelling
  meets deep neural networks: A survey,'' {\em arXiv preprint
  arXiv:2103.00498}, 2021.

\bibitem{kingma2013auto}
D.~P. Kingma and M.~Welling, ``Auto-encoding variational bayes,'' {\em arXiv
  preprint arXiv:1312.6114}, 2013.

\bibitem{rezende2014stochastic}
D.~J. Rezende, S.~Mohamed, and D.~Wierstra, ``Stochastic backpropagation and
  approximate inference in deep generative models,'' in {\em International
  conference on machine learning}, pp.~1278--1286, PMLR, 2014.

\bibitem{peyre2019computational}
G.~Peyr{\'e}, M.~Cuturi, {\em et~al.}, ``Computational optimal transport: With
  applications to data science,'' {\em Foundations and Trends{\textregistered}
  in Machine Learning}, vol.~11, no.~5-6, pp.~355--607, 2019.

\bibitem{benamou2015iterative}
J.-D. Benamou, G.~Carlier, M.~Cuturi, L.~Nenna, and G.~Peyr{\'e}, ``Iterative
  bregman projections for regularized transportation problems,'' {\em SIAM
  Journal on Scientific Computing}, vol.~37, no.~2, pp.~A1111--A1138, 2015.

\bibitem{blondel2018smooth}
M.~Blondel, V.~Seguy, and A.~Rolet, ``Smooth and sparse optimal transport,'' in
  {\em International conference on artificial intelligence and statistics},
  pp.~880--889, PMLR, 2018.

\bibitem{bonneel2011displacement}
N.~Bonneel, M.~Van De~Panne, S.~Paris, and W.~Heidrich, ``Displacement
  interpolation using lagrangian mass transport,'' in {\em Proceedings of the
  2011 SIGGRAPH Asia conference}, pp.~1--12, 2011.

\bibitem{gozlan2017kantorovich}
N.~Gozlan, C.~Roberto, P.-M. Samson, and P.~Tetali, ``Kantorovich duality for
  general transport costs and applications,'' {\em Journal of Functional
  Analysis}, vol.~273, no.~11, pp.~3327--3405, 2017.

\bibitem{rakotomamonjy2015generalized}
A.~Rakotomamonjy, R.~Flamary, and N.~Courty, ``Generalized conditional
  gradient: analysis of convergence and applications,'' {\em arXiv preprint
  arXiv:1510.06567}, 2015.

\bibitem{cuturi2013sinkhorn}
M.~Cuturi, ``Sinkhorn distances: Lightspeed computation of optimal transport,''
  {\em Advances in neural information processing systems}, vol.~26, 2013.

\bibitem{miao2017discovering}
Y.~Miao, E.~Grefenstette, and P.~Blunsom, ``Discovering discrete latent topics
  with neural variational inference,'' in {\em International Conference on
  Machine Learning}, pp.~2410--2419, PMLR, 2017.

\bibitem{srivastava2017autoencoding}
A.~Srivastava and C.~Sutton, ``Autoencoding variational inference for topic
  models,'' {\em arXiv preprint arXiv:1703.01488}, 2017.

\bibitem{zhang2018whai}
H.~Zhang, B.~Chen, D.~Guo, and M.~Zhou, ``Whai: Weibull hybrid autoencoding
  inference for deep topic modeling,'' {\em arXiv preprint arXiv:1803.01328},
  2018.

\bibitem{burkhardt2019decoupling}
S.~Burkhardt and S.~Kramer, ``Decoupling sparsity and smoothness in the
  dirichlet variational autoencoder topic model.,'' {\em J. Mach. Learn. Res.},
  vol.~20, no.~131, pp.~1--27, 2019.

\bibitem{tian2020learning}
R.~Tian, Y.~Mao, and R.~Zhang, ``Learning vae-lda models with rounded
  reparameterization trick,'' in {\em Proceedings of the 2020 Conference on
  Empirical Methods in Natural Language Processing (EMNLP)}, pp.~1315--1325,
  2020.

\bibitem{card2017neural}
D.~Card, C.~Tan, and N.~A. Smith, ``Neural models for documents with
  metadata,'' {\em arXiv preprint arXiv:1705.09296}, 2017.

\bibitem{dieng2020topic}
A.~B. Dieng, F.~J. Ruiz, and D.~M. Blei, ``Topic modeling in embedding
  spaces,'' {\em Transactions of the Association for Computational
  Linguistics}, vol.~8, pp.~439--453, 2020.

\bibitem{bianchi2020pre}
F.~Bianchi, S.~Terragni, and D.~Hovy, ``Pre-training is a hot topic:
  Contextualized document embeddings improve topic coherence,'' {\em arXiv
  preprint arXiv:2004.03974}, 2020.

\bibitem{bianchi2020cross}
F.~Bianchi, S.~Terragni, D.~Hovy, D.~Nozza, and E.~Fersini, ``Cross-lingual
  contextualized topic models with zero-shot learning,'' {\em arXiv preprint
  arXiv:2004.07737}, 2020.

\bibitem{xu2022hyperminer}
Y.~Xu, D.~Wang, B.~Chen, R.~Lu, Z.~Duan, M.~Zhou, {\em et~al.}, ``Hyperminer:
  Topic taxonomy mining with hyperbolic embedding,'' {\em Advances in Neural
  Information Processing Systems}, vol.~35, pp.~31557--31570, 2022.

\bibitem{huynh2020otlda}
V.~Huynh, H.~Zhao, and D.~Phung, ``Otlda: A geometry-aware optimal transport
  approach for topic modeling,'' {\em Advances in Neural Information Processing
  Systems}, vol.~33, pp.~18573--18582, 2020.

\bibitem{nan2019topic}
F.~Nan, R.~Ding, R.~Nallapati, and B.~Xiang, ``Topic modeling with wasserstein
  autoencoders,'' {\em arXiv preprint arXiv:1907.12374}, 2019.

\bibitem{zhao2020neural}
H.~Zhao, D.~Phung, V.~Huynh, T.~Le, and W.~Buntine, ``Neural topic model via
  optimal transport,'' {\em arXiv preprint arXiv:2008.13537}, 2020.

\bibitem{blum2016generalized}
A.~Blum and N.~Haghtalab, ``Generalized topic modeling,'' {\em arXiv preprint
  arXiv:1611.01259}, 2016.

\bibitem{chen2015lifelong}
Z.~Chen, ``Lifelong machine learning for topic modeling and beyond,'' in {\em
  Proceedings of the 2015 Conference of the North American Chapter of the
  Association for Computational Linguistics: Student Research Workshop},
  pp.~133--139, 2015.

\bibitem{chen2014topic}
Z.~Chen and B.~Liu, ``Topic modeling using topics from many domains, lifelong
  learning and big data,'' in {\em International conference on machine
  learning}, pp.~703--711, PMLR, 2014.

\bibitem{gupta2020neural}
P.~Gupta, Y.~Chaudhary, T.~Runkler, and H.~Schuetze, ``Neural topic modeling
  with continual lifelong learning,'' in {\em International Conference on
  Machine Learning}, pp.~3907--3917, PMLR, 2020.

\bibitem{qin2021lifelong}
X.~Qin, Y.~Lu, Y.~Chen, and Y.~Rao, ``Lifelong learning of topics and
  domain-specific word embeddings,'' in {\em Findings of the Association for
  Computational Linguistics: ACL-IJCNLP 2021}, pp.~2294--2309, 2021.

\bibitem{zhang2022lifelong}
X.~Zhang, Y.~Rao, and Q.~Li, ``Lifelong topic modeling with knowledge-enhanced
  adversarial network,'' {\em World Wide Web}, vol.~25, no.~1, pp.~219--238,
  2022.

\bibitem{chen2019affinity}
Y.~Chen, J.~Wu, J.~Lin, R.~Liu, H.~Zhang, and Z.~Ye, ``Affinity regularized
  non-negative matrix factorization for lifelong topic modeling,'' {\em IEEE
  Transactions on Knowledge and Data Engineering}, vol.~32, no.~7,
  pp.~1249--1262, 2019.

\bibitem{lei2023nmtf}
Z.~Lei, H.~Liu, J.~Yan, Y.~Rao, and Q.~Li, ``Nmtf-ltm: Towards an alignment of
  semantics for lifelong topic modeling,'' {\em IEEE Transactions on Knowledge
  and Data Engineering}, 2023.

\bibitem{duan2022bayesian}
Z.~Duan, Y.~Xu, J.~Sun, B.~Chen, W.~Chen, C.~Wang, and M.~Zhou, ``Bayesian deep
  embedding topic meta-learner,'' in {\em International Conference on Machine
  Learning}, pp.~5659--5670, PMLR, 2022.

\bibitem{nguyen2021contrastive}
T.~Nguyen and A.~T. Luu, ``Contrastive learning for neural topic model,'' {\em
  Advances in Neural Information Processing Systems}, vol.~34,
  pp.~11974--11986, 2021.

\bibitem{mikolov2013efficient}
T.~Mikolov, K.~Chen, G.~Corrado, and J.~Dean, ``Efficient estimation of word
  representations in vector space,'' {\em arXiv preprint arXiv:1301.3781},
  2013.

\bibitem{pennington2014glove}
J.~Pennington, R.~Socher, and C.~D. Manning, ``Glove: Global vectors for word
  representation,'' in {\em Proceedings of the 2014 conference on empirical
  methods in natural language processing (EMNLP)}, pp.~1532--1543, 2014.

\bibitem{devlin2018bert}
J.~Devlin, M.-W. Chang, K.~Lee, and K.~Toutanova, ``Bert: Pre-training of deep
  bidirectional transformers for language understanding,'' {\em arXiv preprint
  arXiv:1810.04805}, 2018.

\bibitem{kusner2015word}
M.~Kusner, Y.~Sun, N.~Kolkin, and K.~Weinberger, ``From word embeddings to
  document distances,'' in {\em International conference on machine learning},
  pp.~957--966, PMLR, 2015.

\bibitem{lau2014machine}
J.~H. Lau, D.~Newman, and T.~Baldwin, ``Machine reading tea leaves:
  Automatically evaluating topic coherence and topic model quality,'' in {\em
  Proceedings of the 14th Conference of the European Chapter of the Association
  for Computational Linguistics}, pp.~530--539, 2014.

\bibitem{newman2010automatic}
D.~Newman, J.~H. Lau, K.~Grieser, and T.~Baldwin, ``Automatic evaluation of
  topic coherence,'' in {\em Human language technologies: The 2010 annual
  conference of the North American chapter of the association for computational
  linguistics}, pp.~100--108, 2010.

\bibitem{patrini2020sinkhorn}
G.~Patrini, R.~Van~den Berg, P.~Forre, M.~Carioni, S.~Bhargav, M.~Welling,
  T.~Genewein, and F.~Nielsen, ``Sinkhorn autoencoders,'' in {\em Uncertainty
  in Artificial Intelligence}, pp.~733--743, PMLR, 2020.

\bibitem{lang1995newsweeder}
K.~Lang, ``Newsweeder: Learning to filter netnews,'' in {\em Machine Learning
  Proceedings 1995}, pp.~331--339, Elsevier, 1995.

\bibitem{phan2008learning}
X.-H. Phan, L.-M. Nguyen, and S.~Horiguchi, ``Learning to classify short and
  sparse text \& web with hidden topics from large-scale data collections,'' in
  {\em Proceedings of the 17th international conference on World Wide Web},
  pp.~91--100, 2008.

\bibitem{vitale2012classification}
D.~Vitale, P.~Ferragina, and U.~Scaiella, ``Classification of short texts by
  deploying topical annotations,'' in {\em European Conference on Information
  Retrieval}, pp.~376--387, Springer, 2012.

\bibitem{zhang2015character}
X.~Zhang, J.~Zhao, and Y.~LeCun, ``Character-level convolutional networks for
  text classification,'' {\em Advances in neural information processing
  systems}, vol.~28, 2015.

\bibitem{nguyen2015improving}
D.~Q. Nguyen, R.~Billingsley, L.~Du, and M.~Johnson, ``Improving topic models
  with latent feature word representations,'' {\em Transactions of the
  Association for Computational Linguistics}, vol.~3, pp.~299--313, 2015.

\bibitem{schutze2008introduction}
H.~Schutze, C.~D. Manning, and P.~Raghavan, {\em Introduction to information
  retrieval}.
\newblock Cambridge University Press, 2008.

\bibitem{aletras2013evaluating}
N.~Aletras and M.~Stevenson, ``Evaluating topic coherence using distributional
  semantics,'' in {\em Proceedings of the 10th international conference on
  computational semantics (IWCS 2013)--Long Papers}, pp.~13--22, 2013.

\bibitem{yang2015efficient}
Y.~Yang, D.~Downey, and J.~Boyd-Graber, ``Efficient methods for incorporating
  knowledge into topic models,'' in {\em Proceedings of the 2015 conference on
  empirical methods in natural language processing}, pp.~308--317, 2015.

\bibitem{zhao2018dirichlet}
H.~Zhao, L.~Du, W.~Buntine, and M.~Zhou, ``Dirichlet belief networks for topic
  structure learning,'' {\em Advances in neural information processing
  systems}, vol.~31, 2018.

\bibitem{roder2015exploring}
M.~R{\"o}der, A.~Both, and A.~Hinneburg, ``Exploring the space of topic
  coherence measures,'' in {\em Proceedings of the eighth ACM international
  conference on Web search and data mining}, pp.~399--408, 2015.

\bibitem{qiang2020short}
J.~Qiang, Z.~Qian, Y.~Li, Y.~Yuan, and X.~Wu, ``Short text topic modeling
  techniques, applications, and performance: a survey,'' {\em IEEE Transactions
  on Knowledge and Data Engineering}, vol.~34, no.~3, pp.~1427--1445, 2020.

\bibitem{xuan2016bayesian}
J.~Xuan, J.~Lu, G.~Zhang, R.~Y. Da~Xu, and X.~Luo, ``Bayesian nonparametric
  relational topic model through dependent gamma processes,'' {\em IEEE
  Transactions on Knowledge and Data Engineering}, vol.~29, no.~7,
  pp.~1357--1369, 2016.

\end{thebibliography}
