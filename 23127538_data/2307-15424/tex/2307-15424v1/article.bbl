\begin{thebibliography}{137}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Abadi et~al.(2016)Abadi, Chu, Goodfellow, McMahan, Mironov, Talwar,
  and Zhang]{abadi2016deep}
Martin Abadi, Andy Chu, Ian Goodfellow, H.~Brendan McMahan, Ilya Mironov, Kunal
  Talwar, and Li~Zhang.
\newblock Deep {L}earning with {D}ifferential {P}rivacy.
\newblock \emph{Proceedings of the 2016 ACM SIGSAC Conference on Computer and
  Communications Security}, 2016.

\bibitem[Abowd and Vilhuber(2008)]{abowd2008protective}
John~M Abowd and Lars Vilhuber.
\newblock How protective are synthetic data?
\newblock In \emph{International Conference on Privacy in Statistical
  Databases}. Springer, 2008.

\bibitem[Aitsam(2022)]{aitsam2022differential}
Muhammad Aitsam.
\newblock Differential {P}rivacy made easy.
\newblock In \emph{International Conference on Emerging Trends in Electrical,
  Control, and Telecommunication Engineering}. IEEE, 2022.

\bibitem[Alaa et~al.(2022)Alaa, Van~Breugel, Saveliev, and van~der
  Schaar]{alaa2022faithful}
Ahmed Alaa, Boris Van~Breugel, Evgeny~S Saveliev, and Mihaela van~der Schaar.
\newblock How {F}aithful is your {S}ynthetic {D}ata? {S}ample-level {M}etrics
  for {E}valuating and {A}uditing {G}enerative {M}odels.
\newblock In \emph{International Conference on Machine Learning}. PMLR, 2022.

\bibitem[Amiri et~al.(2022)Amiri, Nalisnick, Belloum, Klous, and
  Gommans]{amiri2022generating}
Saba Amiri, Eric Nalisnick, Adam Belloum, Sander Klous, and Leon Gommans.
\newblock {Generating Heavy-Tailed Synthetic Data with Normalizing Flows}.
\newblock In \emph{The 5th Workshop on Tractable Probabilistic Modeling}, 2022.

\bibitem[Arjovsky et~al.(2017)Arjovsky, Chintala, and
  Bottou]{arjovsky2017wasserstein}
Martin Arjovsky, Soumith Chintala, and L{\'e}on Bottou.
\newblock {W}asserstein generative adversarial networks.
\newblock In Doina Precup and Yee~Whye Teh, editors, \emph{Proceedings of the
  34th International Conference on Machine Learning}, volume~70 of
  \emph{Proceedings of Machine Learning Research}, pages 214--223. PMLR, 06--11
  Aug 2017.

\bibitem[Babuschkin et~al.(2020)Babuschkin, Baumli, Bell, Bhupatiraju, Bruce,
  Buchlovsky, Budden, Cai, Clark, Danihelka, Fantacci, Godwin, Jones, Hemsley,
  Hennigan, Hessel, Hou, Kapturowski, Keck, Kemaev, King, Kunesch, Martens,
  Merzic, Mikulik, Norman, Quan, Papamakarios, Ring, Ruiz, Sanchez, Schneider,
  Sezener, Spencer, Srinivasan, Wang, Stokowiec, and Viola]{deepmind2020jax}
Igor Babuschkin, Kate Baumli, Alison Bell, Surya Bhupatiraju, Jake Bruce, Peter
  Buchlovsky, David Budden, Trevor Cai, Aidan Clark, Ivo Danihelka, Claudio
  Fantacci, Jonathan Godwin, Chris Jones, Ross Hemsley, Tom Hennigan, Matteo
  Hessel, Shaobo Hou, Steven Kapturowski, Thomas Keck, Iurii Kemaev, Michael
  King, Markus Kunesch, Lena Martens, Hamza Merzic, Vladimir Mikulik, Tamara
  Norman, John Quan, George Papamakarios, Roman Ring, Francisco Ruiz, Alvaro
  Sanchez, Rosalia Schneider, Eren Sezener, Stephen Spencer, Srivatsan
  Srinivasan, Luyu Wang, Wojciech Stokowiec, and Fabio Viola.
\newblock The {D}eep{M}ind {JAX} {E}cosystem, 2020.
\newblock URL \url{http://github.com/deepmind}.

\bibitem[Bachman and Precup(2015)]{bachman2015variational}
Philip Bachman and Doina Precup.
\newblock Variational generative stochastic networks with collaborative
  shaping.
\newblock In Francis Bach and David Blei, editors, \emph{Proceedings of the
  32nd International Conference on Machine Learning}, volume~37 of
  \emph{Proceedings of Machine Learning Research}, pages 1964--1972, Lille,
  France, 07--09 Jul 2015. PMLR.

\bibitem[Ballard(1987)]{ballard1987modular}
Dana~H Ballard.
\newblock Modular learning in neural networks.
\newblock In \emph{AAAI}, volume 647, pages 279--284, 1987.

\bibitem[Balle et~al.(2018)Balle, Barthe, and Gaboardi]{balle2018privacy}
Borja Balle, Gilles Barthe, and Marco Gaboardi.
\newblock {Privacy amplification by subsampling: Tight analyses via couplings
  and divergences}.
\newblock \emph{Advances in neural information processing systems}, 31, 2018.

\bibitem[Bartholomew et~al.(2011)Bartholomew, Knott, and
  Moustaki]{bartholomew2011latent}
D.J. Bartholomew, M.~Knott, and I.~Moustaki.
\newblock \emph{Latent Variable Models and Factor Analysis: A Unified
  Approach}.
\newblock Wiley Series in Probability and Statistics. Wiley, 2011.
\newblock ISBN 9781119973706.

\bibitem[Bassily et~al.(2014)Bassily, Smith, and Thakurta]{bassily2014private}
Raef Bassily, Adam Smith, and Abhradeep Thakurta.
\newblock Private {Empirical} {Risk} {Minimization}: {Efficient} {Algorithms}
  and {Tight} {Error} {Bounds}.
\newblock In \emph{2014 {IEEE} 55th {Annual} {Symposium} on {Foundations} of
  {Computer} {Science}}, pages 464--473, Philadelphia, PA, USA, October 2014.
  IEEE.
\newblock ISBN 978-1-4799-6517-5.
\newblock \doi{10.1109/FOCS.2014.56}.

\bibitem[Bassily et~al.(2018)Bassily, Thakkar, and
  Guha~Thakurta]{bassily2018agnostic}
Raef Bassily, Om~Thakkar, and Abhradeep Guha~Thakurta.
\newblock Model-{Agnostic} {Private} {Learning}.
\newblock In \emph{Advances in {Neural} {Information} {Processing} {Systems}}.
  Curran Associates, Inc., 2018.

\bibitem[Baydin et~al.(2018)Baydin, Pearlmutter, Radul, and
  Siskind]{baydin2018automatic}
Atilim~Gunes Baydin, Barak~A. Pearlmutter, Alexey~Andreyevich Radul, and
  Jeffrey~Mark Siskind.
\newblock {Automatic Differentiation in Machine Learning: a Survey}.
\newblock \emph{Journal of Machine Learning Research}, 18\penalty0
  (153):\penalty0 1--43, 2018.

\bibitem[Beaulieu-Jones et~al.(2019)Beaulieu-Jones, Wu, Williams, Lee,
  Bhavnani, Byrd, and Greene]{beaulieu2019privacy}
Brett~K Beaulieu-Jones, Zhiwei~Steven Wu, Chris Williams, Ran Lee, Sanjeev~P
  Bhavnani, James~Brian Byrd, and Casey~S Greene.
\newblock Privacy-preserving generative deep neural networks support clinical
  data sharing.
\newblock \emph{Circulation: Cardiovascular Quality and Outcomes}, 12\penalty0
  (7):\penalty0 e005122, 2019.

\bibitem[Bengio(2012)]{bengio2012deep}
Yoshua Bengio.
\newblock Deep learning of representations for unsupervised and transfer
  learning.
\newblock In \emph{Proceedings of ICML workshop on unsupervised and transfer
  learning}, pages 17--36. JMLR Workshop and Conference Proceedings, 2012.

\bibitem[Bengio et~al.(2013)Bengio, Courville, and
  Vincent]{bengio2013representation}
Yoshua Bengio, Aaron Courville, and Pascal Vincent.
\newblock Representation learning: A review and new perspectives.
\newblock \emph{IEEE transactions on pattern analysis and machine
  intelligence}, 35\penalty0 (8):\penalty0 1798--1828, 2013.

\bibitem[Bishop(1994)]{bishop1994mixture}
Christopher~M Bishop.
\newblock Mixture density networks.
\newblock \emph{Technical Report}, 1994.

\bibitem[Blei et~al.(2017)Blei, Kucukelbir, and McAuliffe]{blei2017variational}
David~M. Blei, Alp Kucukelbir, and Jon~D. McAuliffe.
\newblock Variational inference: A review for statisticians.
\newblock \emph{Journal of the American Statistical Association}, 112\penalty0
  (518):\penalty0 859--877, Apr 2017.
\newblock ISSN 1537-274X.
\newblock \doi{10.1080/01621459.2017.1285773}.

\bibitem[Bond-Taylor et~al.(2021)Bond-Taylor, Leach, Long, and
  Willcocks]{bondtaylor2021deep}
Sam Bond-Taylor, Adam Leach, Yang Long, and Chris~G. Willcocks.
\newblock {Deep Generative Modelling: A Comparative Review of VAEs, GANs,
  Normalizing Flows, Energy-Based and Autoregressive Models}, 2021.

\bibitem[Bradbury et~al.(2018)Bradbury, Frostig, Hawkins, Johnson, Leary,
  Maclaurin, Necula, Paszke, Vander{P}las, Wanderman-{M}ilne, and
  Zhang]{bradbury2018jax}
James Bradbury, Roy Frostig, Peter Hawkins, Matthew~James Johnson, Chris Leary,
  Dougal Maclaurin, George Necula, Adam Paszke, Jake Vander{P}las, Skye
  Wanderman-{M}ilne, and Qiao Zhang.
\newblock {JAX}: composable transformations of {P}ython+{N}um{P}y programs,
  2018.
\newblock URL \url{http://github.com/google/jax}.

\bibitem[Brenninkmeijer et~al.(2019)Brenninkmeijer, de~Vries, Marchiori, and
  Hille]{brenninkmeijer2019generation}
Bauke Brenninkmeijer, A~de~Vries, E~Marchiori, and Youri Hille.
\newblock \emph{On the Generation and Evaluation of Tabular Data Using {gans}}.
\newblock PhD thesis, Master's Thesis, Radboud University, Nijmegen, The
  Netherlands, 2019.[Google~{\ldots}, 2019.

\bibitem[Buczak et~al.(2010)Buczak, Babin, and Moniz]{buczak2010data}
Anna~L Buczak, Steven Babin, and Linda Moniz.
\newblock Data-driven approach for creating synthetic electronic medical
  records.
\newblock \emph{BMC medical informatics and decision making}, 10\penalty0
  (1):\penalty0 1--28, 2010.

\bibitem[Burda et~al.(2015)Burda, Grosse, and
  Salakhutdinov]{burda2015importance}
Yuri Burda, Roger Grosse, and Ruslan Salakhutdinov.
\newblock Importance weighted autoencoders.
\newblock \emph{arXiv preprint arXiv:1509.00519}, 2015.

\bibitem[Burgard et~al.(2017)Burgard, Kolb, Merkle, and
  M{\"u}nnich]{burgard2017synthetic}
Jan~Pablo Burgard, Jan-Philipp Kolb, Hariolf Merkle, and Ralf M{\"u}nnich.
\newblock Synthetic data for open and reproducible methodological research in
  social sciences and official statistics.
\newblock \emph{AStA Wirtschafts-und Sozialstatistisches Archiv}, 11\penalty0
  (3):\penalty0 233--244, 2017.

\bibitem[Chen et~al.(2020)Chen, Orekondy, and Fritz]{chen2020gswgan}
Dingfan Chen, Tribhuvanesh Orekondy, and Mario Fritz.
\newblock {GS-WGAN:} {A} gradient-sanitized approach for learning
  differentially private generators.
\newblock \emph{CoRR}, abs/2006.08265, 2020.

\bibitem[Chen et~al.(2018{\natexlab{a}})Chen, Xiang, Xue, Li, Borisov, Kaarfar,
  and Zhu]{chen2018differentially}
Qingrong Chen, Chong Xiang, Minhui Xue, Bo~Li, Nikita Borisov, Dali Kaarfar,
  and Haojin Zhu.
\newblock Differentially private data generative models.
\newblock \emph{arXiv preprint arXiv:1812.02274}, 2018{\natexlab{a}}.

\bibitem[Chen et~al.(2018{\natexlab{b}})Chen, Rubanova, Bettencourt, and
  Duvenaud]{chen2018neural}
Ricky T.~Q. Chen, Yulia Rubanova, Jesse Bettencourt, and David~K Duvenaud.
\newblock Neural {Ordinary} {Differential} {Equations}.
\newblock In \emph{Advances in {Neural} {Information} {Processing} {Systems}},
  volume~31. Curran Associates, Inc., 2018{\natexlab{b}}.

\bibitem[Chen et~al.(2019)Chen, Behrmann, Duvenaud, and
  Jacobsen]{chen2019residual}
Ricky~TQ Chen, Jens Behrmann, David~K Duvenaud, and J{\"o}rn-Henrik Jacobsen.
\newblock Residual flows for invertible generative modeling.
\newblock \emph{Advances in Neural Information Processing Systems}, 32, 2019.

\bibitem[Chin-Cheong et~al.(2019)Chin-Cheong, Sutter, and
  Vogt]{chincheong2019generation}
Kieran Chin-Cheong, Thomas~M. Sutter, and Julia~E. Vogt.
\newblock Generation of heterogeneous synthetic electronic health records using
  {gans}.
\newblock In \emph{NeurIPS 2019}, 2019.

\bibitem[Choi et~al.(2018)Choi, Biswal, Malin, Duke, Stewart, and
  Sun]{choi2018generating}
Edward Choi, Siddharth Biswal, Bradley Malin, Jon Duke, Walter~F. Stewart, and
  Jimeng Sun.
\newblock Generating multi-label discrete patient records using generative
  adversarial networks, 2018.

\bibitem[Chopra et~al.(2005)Chopra, Hadsell, and LeCun]{chopra2005learning}
Sumit Chopra, Raia Hadsell, and Yann LeCun.
\newblock Learning a similarity metric discriminatively, with application to
  face verification.
\newblock In \emph{2005 IEEE Computer Society Conference on Computer Vision and
  Pattern Recognition (CVPR'05)}, volume~1, pages 539--546. IEEE, 2005.

\bibitem[Cox(1958)]{cox1958regression}
David~R Cox.
\newblock The regression analysis of binary sequences.
\newblock \emph{Journal of the Royal Statistical Society: Series B
  (Methodological)}, 20\penalty0 (2):\penalty0 215--232, 1958.

\bibitem[Croitoru et~al.(2023)Croitoru, Hondru, Ionescu, and
  Shah]{croitoru2023diffusion}
Florinel-Alin Croitoru, Vlad Hondru, Radu~Tudor Ionescu, and Mubarak Shah.
\newblock Diffusion models in vision: A survey.
\newblock \emph{IEEE Transactions on Pattern Analysis and Machine
  Intelligence}, 2023.

\bibitem[Dankar and El~Emam(2013)]{dankar2013practicing}
Fida~Kamal Dankar and Khaled El~Emam.
\newblock Practicing differential privacy in health care: A review.
\newblock \emph{Trans. Data Priv.}, 6\penalty0 (1):\penalty0 35--67, 2013.

\bibitem[Darmois(1935)]{darmois1935surles}
g~Darmois.
\newblock Sur les lois de probabilites a estimation exhaustive.
\newblock In \emph{C. R. Acad. Sci. Paris}, pages 1265--1266, 1935.

\bibitem[Dinh et~al.(2016)Dinh, Sohl-Dickstein, and Bengio]{dinh2016density}
Laurent Dinh, Jascha Sohl-Dickstein, and Samy Bengio.
\newblock Density estimation using real {NVP}.
\newblock \emph{arXiv preprint arXiv:1605.08803}, 2016.

\bibitem[Dolatabadi et~al.(2020)Dolatabadi, Erfani, and
  Leckie]{dolatabadi2020invertible}
Hadi~M. Dolatabadi, Sarah Erfani, and Christopher Leckie.
\newblock Invertible generative modeling using linear rational splines, 2020.

\bibitem[Doucet et~al.(2023)Doucet, Moulines, and
  Thin]{doucet2023differentiable}
Arnaud Doucet, Eric Moulines, and Achille Thin.
\newblock {Differentiable samplers for deep latent variable models}.
\newblock \emph{Philosophical Transactions of the Royal Society A},
  381\penalty0 (2247):\penalty0 20220147, 2023.

\bibitem[Duda et~al.(1973)Duda, Hart, et~al.]{duda1973pattern}
Richard~O Duda, Peter~E Hart, et~al.
\newblock \emph{Pattern classification and scene analysis}, volume~3.
\newblock Wiley New York, 1973.

\bibitem[Durkan et~al.(2019{\natexlab{a}})Durkan, Bekasov, Murray, and
  Papamakarios]{durkan2019cubic}
Conor Durkan, Artur Bekasov, Iain Murray, and George Papamakarios.
\newblock Cubic-spline flows, 2019{\natexlab{a}}.

\bibitem[Durkan et~al.(2019{\natexlab{b}})Durkan, Bekasov, Murray, and
  Papamakarios]{durkan2019neural}
Conor Durkan, Artur Bekasov, Iain Murray, and George Papamakarios.
\newblock Neural spline flows, 2019{\natexlab{b}}.

\bibitem[Dwork(2019)]{dwork2019differential}
Cynthia Dwork.
\newblock Differential privacy and the {US} census.
\newblock In \emph{Proceedings of the 38th ACM SIGMOD-SIGACT-SIGAI Symposium on
  Principles of Database Systems}, pages 1--1, 2019.

\bibitem[Dwork and Feldman(2018)]{dwork2018prediction}
Cynthia Dwork and Vitaly Feldman.
\newblock Privacy-preserving prediction.
\newblock In \emph{Conference On Learning Theory}, pages 1693--1702. PMLR,
  2018.

\bibitem[Dwork and Lei(2009)]{dwork2009differential}
Cynthia Dwork and Jing Lei.
\newblock Differential privacy and robust statistics.
\newblock In \emph{Proceedings of the forty-first annual ACM symposium on
  Theory of computing}, pages 371--380, 2009.

\bibitem[Dwork et~al.(2010)Dwork, Rothblum, and Vadhan]{dwork2010boosting}
Cynthia Dwork, Guy~N. Rothblum, and Salil Vadhan.
\newblock Boosting and differential privacy.
\newblock In \emph{2010 IEEE 51st Annual Symposium on Foundations of Computer
  Science}, pages 51--60, 2010.
\newblock \doi{10.1109/FOCS.2010.12}.

\bibitem[Dwork et~al.(2014)Dwork, Roth, et~al.]{dwork2014algorithmic}
Cynthia Dwork, Aaron Roth, et~al.
\newblock The algorithmic foundations of differential privacy.
\newblock \emph{Foundations and Trends{\textregistered} in Theoretical Computer
  Science}, 9\penalty0 (3--4):\penalty0 211--407, 2014.

\bibitem[Fan(2020)]{fan2020survey}
Liyue Fan.
\newblock A survey of differentially private generative adversarial networks.
\newblock In \emph{The AAAI Workshop on Privacy-Preserving Artificial
  Intelligence}, 2020.

\bibitem[Germain et~al.(2015)Germain, Gregor, Murray, and
  Larochelle]{germain2015made}
Mathieu Germain, Karol Gregor, Iain Murray, and Hugo Larochelle.
\newblock {MADE: Masked autoencoder for distribution estimation}.
\newblock In \emph{International conference on machine learning}, pages
  881--889. PMLR, 2015.

\bibitem[Ghahramani et~al.(1996)Ghahramani, Hinton,
  et~al.]{ghahramani1996algorithm}
Zoubin Ghahramani, Geoffrey~E Hinton, et~al.
\newblock {The EM algorithm for mixtures of factor analyzers}.
\newblock Technical report, Technical Report CRG-TR-96-1, University of
  Toronto, 1996.

\bibitem[Goodfellow et~al.(2014)Goodfellow, Pouget-Abadie, Mirza, Xu,
  Warde-Farley, Ozair, Courville, and Bengio]{goodfellow2014generative}
Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley,
  Sherjil Ozair, Aaron Courville, and Yoshua Bengio.
\newblock Generative adversarial nets.
\newblock \emph{Advances in neural information processing systems}, 27, 2014.

\bibitem[Goodfellow et~al.(2016)Goodfellow, Bengio, and
  Courville]{goodfellow2016deep}
Ian Goodfellow, Yoshua Bengio, and Aaron Courville.
\newblock \emph{Deep learning}.
\newblock MIT press, 2016.

\bibitem[Grathwohl et~al.(2018)Grathwohl, Chen, Bettencourt, Sutskever, and
  Duvenaud]{grathwohl2018ffjord}
Will Grathwohl, Ricky~TQ Chen, Jesse Bettencourt, Ilya Sutskever, and David
  Duvenaud.
\newblock Ffjord: Free-form continuous dynamics for scalable reversible
  generative models.
\newblock \emph{arXiv preprint arXiv:1810.01367}, 2018.

\bibitem[Grover et~al.(2018)Grover, Dhar, and Ermon]{grover2018flow}
Aditya Grover, Manik Dhar, and Stefano Ermon.
\newblock {Flow-GAN: Combining maximum likelihood and adversarial learning in
  generative models}.
\newblock In \emph{Proceedings of the AAAI conference on artificial
  intelligence}, volume~32, 2018.

\bibitem[Gui et~al.(2021)Gui, Sun, Wen, Tao, and Ye]{gui2021review}
Jie Gui, Zhenan Sun, Yonggang Wen, Dacheng Tao, and Jieping Ye.
\newblock {A review on generative adversarial networks: Algorithms, theory, and
  applications}.
\newblock \emph{IEEE transactions on knowledge and data engineering},
  35\penalty0 (4):\penalty0 3313--3332, 2021.

\bibitem[Haykin and Network(2004)]{haykin2004comprehensive}
Simon Haykin and N~Network.
\newblock A comprehensive foundation.
\newblock \emph{Neural networks}, 2\penalty0 (2004):\penalty0 41, 2004.

\bibitem[He et~al.(2016)He, Zhang, Ren, and Sun]{he2016deep}
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
\newblock Deep residual learning for image recognition.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 770--778, 2016.

\bibitem[Hopfield and Tank(1986)]{hopfield1986computing}
John~J Hopfield and David~W Tank.
\newblock Computing with neural circuits: A model.
\newblock \emph{Science}, 233\penalty0 (4764):\penalty0 625--633, 1986.

\bibitem[Jordon et~al.(2018)Jordon, Yoon, and Van Der~Schaar]{jordon2018pate}
James Jordon, Jinsung Yoon, and Mihaela Van Der~Schaar.
\newblock {PATE-GAN: Generating synthetic data with differential privacy
  guarantees}.
\newblock In \emph{International conference on learning representations}, 2018.

\bibitem[Kairouz et~al.(2017)Kairouz, Oh, and
  Viswanath]{kairouz2017composition}
Peter Kairouz, Sewoong Oh, and Pramod Viswanath.
\newblock The {Composition} {Theorem} for {Differential} {Privacy}.
\newblock \emph{IEEE Transactions on Information Theory}, 63\penalty0
  (6):\penalty0 4037--4049, June 2017.
\newblock Conference Name: IEEE Transactions on Information Theory.

\bibitem[Kasiviswanathan et~al.(2011)Kasiviswanathan, Lee, Nissim,
  Raskhodnikova, and Smith]{kasiviswanathan2011what}
Shiva~Prasad Kasiviswanathan, Homin~K. Lee, Kobbi Nissim, Sofya Raskhodnikova,
  and Adam Smith.
\newblock What {Can} {We} {Learn} {Privacy}, 2011.

\bibitem[Keskar and Socher(2017)]{keskar2017improving}
Nitish~Shirish Keskar and Richard Socher.
\newblock Improving generalization performance by switching from {ADAM} to
  {SGD}.
\newblock \emph{arXiv preprint arXiv:1712.07628}, 2017.

\bibitem[Kingma and Welling(2014)]{kingma2014autoencoding}
Diederik~P Kingma and Max Welling.
\newblock Auto-encoding variational bayes, 2014.

\bibitem[Kingma et~al.(2016)Kingma, Salimans, Jozefowicz, Chen, Sutskever, and
  Welling]{kingma2016improved}
Durk~P Kingma, Tim Salimans, Rafal Jozefowicz, Xi~Chen, Ilya Sutskever, and Max
  Welling.
\newblock Improved variational inference with inverse autoregressive flow.
\newblock \emph{Advances in neural information processing systems},
  29:\penalty0 4743--4751, 2016.

\bibitem[Koopman(1936)]{koopman1936distributions}
Bernard~Osgood Koopman.
\newblock On distributions admitting a sufficient statistic.
\newblock \emph{Transactions of the American Mathematical society}, 39\penalty0
  (3):\penalty0 399--409, 1936.

\bibitem[Kunar et~al.(2021)Kunar, Birke, Chen, and Zhao]{kunar2021dtgan}
Aditya Kunar, Robert Birke, Lydia Chen, and Zilong Zhao.
\newblock {DTGAN: Differential Private Training for Tabular {gans}}.
\newblock \emph{arXiv preprint arXiv:2107.02521}, 2021.

\bibitem[Kynk{\"a}{\"a}nniemi et~al.(2019)Kynk{\"a}{\"a}nniemi, Karras, Laine,
  Lehtinen, and Aila]{kynkaanniemi2019improved}
Tuomas Kynk{\"a}{\"a}nniemi, Tero Karras, Samuli Laine, Jaakko Lehtinen, and
  Timo Aila.
\newblock Improved precision and recall metric for assessing generative models.
\newblock \emph{Advances in Neural Information Processing Systems}, 32, 2019.

\bibitem[Langley and Sage(1994)]{langley1994oblivious}
Pat Langley and Stephanie Sage.
\newblock Oblivious decision trees and abstract cases.
\newblock In \emph{Working notes of the AAAI-94 workshop on case-based
  reasoning}, pages 113--117. Seattle, WA, 1994.

\bibitem[LeCun and Huang(2005)]{lecun2005loss}
Yann LeCun and Fu~Jie Huang.
\newblock Loss functions for discriminative training of energy-based models.
\newblock In \emph{International workshop on artificial intelligence and
  statistics}, pages 206--213. PMLR, 2005.

\bibitem[LeCun et~al.(1989)LeCun, Boser, Denker, Henderson, Howard, Hubbard,
  and Jackel]{lecun1989backpropagation}
Yann LeCun, Bernhard Boser, John~S Denker, Donnie Henderson, Richard~E Howard,
  Wayne Hubbard, and Lawrence~D Jackel.
\newblock Backpropagation applied to handwritten zip code recognition.
\newblock \emph{Neural computation}, 1\penalty0 (4):\penalty0 541--551, 1989.

\bibitem[L'Ecuyer(1990)]{lecuyer1990unified}
Pierre L'Ecuyer.
\newblock A unified view of the {IPA, SF, and LR} gradient estimation
  techniques.
\newblock \emph{Management Science}, 36\penalty0 (11):\penalty0 1364--1383,
  1990.

\bibitem[Lee et~al.(2022)Lee, Kim, Jeong, and Ro]{lee2022differentially}
Jaewoo Lee, Minjung Kim, Yonghyun Jeong, and Youngmin Ro.
\newblock Differentially private normalizing flows for synthetic tabular data
  generation.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial
  Intelligence}, volume~36, pages 7345--7353, 2022.

\bibitem[Li et~al.(2021)Li, Luo, Qin, and Pan]{li2021inverse}
Ban Li, Senlin Luo, Xiaonan Qin, and Limin Pan.
\newblock Improving {GAN} with inverse cumulative distribution function for
  tabular data synthesis.
\newblock \emph{Neurocomputing}, 456:\penalty0 373--383, October 2021.
\newblock ISSN 0925-2312.
\newblock \doi{10.1016/j.neucom.2021.05.098}.

\bibitem[Liu et~al.(2023)Liu, Qian, Berrevoets, and van~der
  Schaar]{liu2022goggle}
Tennison Liu, Zhaozhi Qian, Jeroen Berrevoets, and Mihaela van~der Schaar.
\newblock {GOGGLE: Generative modelling for tabular data by learning relational
  structure}.
\newblock In \emph{The Eleventh International Conference on Learning
  Representations}, 2023.

\bibitem[Long et~al.(2021)Long, Wang, Yang, Kailkhura, Zhang, Gunter, and
  Li]{long2021gpate}
Yunhui Long, Boxin Wang, Zhuolin Yang, Bhavya Kailkhura, Aston Zhang, Carl~A.
  Gunter, and Bo~Li.
\newblock {G-PATE: Scalable Differentially Private Data Generator via Private
  Aggregation of Teacher Discriminators}, 2021.

\bibitem[McLachlan and Basford(1988)]{mclachlan1988mixture}
Geoffrey~J McLachlan and Kaye~E Basford.
\newblock \emph{Mixture models: Inference and applications to clustering},
  volume~38.
\newblock M. Dekker New York, 1988.

\bibitem[McLachlan and Krishnan(2007)]{mclachlan2007algorithm}
Geoffrey~J McLachlan and Thriyambakam Krishnan.
\newblock \emph{The {EM} algorithm and extensions}, volume 382.
\newblock John Wiley \& Sons, 2007.

\bibitem[Mengersen et~al.(2011)Mengersen, Robert, and
  Titterington]{mengersen2011mixtures}
Kerrie~L Mengersen, Christian Robert, and Mike Titterington.
\newblock \emph{Mixtures: estimation and applications}, volume 896.
\newblock John Wiley \& Sons, 2011.

\bibitem[Mironov(2017)]{mironov2017renyi}
Ilya Mironov.
\newblock R{\'e}nyi {Differential} {Privacy}.
\newblock In \emph{2017 {IEEE} 30th {Computer} {Security} {Foundations}
  {Symposium} ({CSF})}, pages 263--275, Santa Barbara, CA, August 2017. IEEE.
\newblock ISBN 978-1-5386-3217-8.
\newblock \doi{10.1109/CSF.2017.11}.

\bibitem[Mirza and Osindero(2014)]{mirza2014conditional}
Mehdi Mirza and Simon Osindero.
\newblock Conditional generative adversarial nets.
\newblock \emph{arXiv preprint arXiv:1411.1784}, 2014.

\bibitem[Mohamed et~al.(2020)Mohamed, Rosca, Figurnov, and
  Mnih]{mohamed2020monte}
Shakir Mohamed, Mihaela Rosca, Michael Figurnov, and Andriy Mnih.
\newblock Monte carlo gradient estimation in machine learning.
\newblock \emph{J. Mach. Learn. Res.}, 21\penalty0 (132):\penalty0 1--62, 2020.

\bibitem[M{\"{u}}ller et~al.(2018)M{\"{u}}ller, McWilliams, Rousselle, Gross,
  and Nov{\'{a}}k]{muller2019neural}
Thomas M{\"{u}}ller, Brian McWilliams, Fabrice Rousselle, Markus Gross, and Jan
  Nov{\'{a}}k.
\newblock Neural importance sampling.
\newblock \emph{CoRR}, abs/1808.03856, 2018.

\bibitem[Naeem et~al.(2020)Naeem, Oh, Uh, Choi, and Yoo]{naeem2020reliable}
Muhammad~Ferjad Naeem, Seong~Joon Oh, Youngjung Uh, Yunjey Choi, and Jaejun
  Yoo.
\newblock Reliable fidelity and diversity metrics for generative models.
\newblock In Hal~Daum{\'e} III and Aarti Singh, editors, \emph{Proceedings of
  the 37th International Conference on Machine Learning}, volume 119 of
  \emph{Proceedings of Machine Learning Research}, pages 7176--7185. PMLR,
  13--18 Jul 2020.

\bibitem[Nair and Hinton(2010)]{nair2010rectified}
Vinod Nair and Geoffrey~E. Hinton.
\newblock Rectified linear units improve restricted boltzmann machines.
\newblock In \emph{Proceedings of the 27th International Conference on
  International Conference on Machine Learning}, ICML'10, pages 807--814,
  Madison, WI, USA, 2010. Omnipress.
\newblock ISBN 9781605589077.

\bibitem[Neal(1990)]{neal1990learning}
Radford~M Neal.
\newblock Learning stochastic feedforward networks.
\newblock \emph{Department of Computer Science, University of Toronto},
  64\penalty0 (1283):\penalty0 1577, 1990.

\bibitem[Neal(2001)]{neal2001annealed}
Radford~M Neal.
\newblock Annealed importance sampling.
\newblock \emph{Statistics and computing}, 11:\penalty0 125--139, 2001.

\bibitem[Nelder and Wedderburn(1972)]{nelder1972glm}
J.~A. Nelder and R.~W.~M. Wedderburn.
\newblock Generalized linear models.
\newblock \emph{Journal of the Royal Statistical Society. Series A (General)},
  135\penalty0 (3):\penalty0 370--384, 1972.
\newblock ISSN 00359238.

\bibitem[Nott et~al.(2012)Nott, Tan, Villani, and Kohn]{nott2012regression}
David~J Nott, Siew~Li Tan, Mattias Villani, and Robert Kohn.
\newblock {Regression density estimation with variational methods and
  stochastic approximation}.
\newblock \emph{Journal of Computational and Graphical Statistics}, 21\penalty0
  (3):\penalty0 797--820, 2012.

\bibitem[Nowok et~al.(2016)Nowok, Raab, and Dibben]{nowok2016synthpop}
Beata Nowok, Gillian~M Raab, and Chris Dibben.
\newblock {synthpop: Bespoke creation of synthetic data in R}.
\newblock \emph{Journal of statistical software}, 74\penalty0 (1):\penalty0
  1--26, 2016.

\bibitem[Nwankpa et~al.(2018)Nwankpa, Ijomah, Gachagan, and
  Marshall]{nwankpa2018activation}
Chigozie Nwankpa, Winifred Ijomah, Anthony Gachagan, and Stephen Marshall.
\newblock Activation functions: Comparison of trends in practice and research
  for deep learning.
\newblock \emph{CoRR}, abs/1811.03378, 2018.

\bibitem[Papamakarios et~al.(2017)Papamakarios, Pavlakou, and
  Murray]{papamakarios2017masked}
George Papamakarios, Theo Pavlakou, and Iain Murray.
\newblock Masked autoregressive flow for density estimation.
\newblock In I.~Guyon, U.~V. Luxburg, S.~Bengio, H.~Wallach, R.~Fergus,
  S.~Vishwanathan, and R.~Garnett, editors, \emph{Advances in Neural
  Information Processing Systems}, volume~30. Curran Associates, Inc., 2017.

\bibitem[Papamakarios et~al.(2021)Papamakarios, Nalisnick, Rezende, Mohamed,
  and Lakshminarayanan]{papamakarios2021normalizing}
George Papamakarios, Eric Nalisnick, Danilo~Jimenez Rezende, Shakir Mohamed,
  and Balaji Lakshminarayanan.
\newblock Normalizing flows for probabilistic modeling and inference.
\newblock \emph{Journal of Machine Learning Research}, 22\penalty0
  (57):\penalty0 1--64, 2021.

\bibitem[Papernot et~al.(2017)Papernot, Abadi, Erlingsson, Goodfellow, and
  Talwar]{papernot2017semisupervised}
Nicolas Papernot, Mart{\'\i}n Abadi, {\'U}lfar Erlingsson, Ian Goodfellow, and
  Kunal Talwar.
\newblock Semi-supervised knowledge transfer for deep learning from private
  training data, 2017.

\bibitem[Papernot et~al.(2018)Papernot, Song, Mironov, Raghunathan, Talwar, and
  Erlingsson]{papernot2018scalable}
Nicolas Papernot, Shuang Song, Ilya Mironov, Ananth Raghunathan, Kunal Talwar,
  and {\'U}lfar Erlingsson.
\newblock {SCALABLE} {PRIVATE} {LEARNING} {WITH} {PATE}.
\newblock \emph{International {C}onference on {L}earning {R}epresentations},
  page~34, 2018.

\bibitem[Park et~al.(2018)Park, Mohammadi, Gorde, Jajodia, Park, and
  Kim]{park2018data}
Noseong Park, Mahmoud Mohammadi, Kshitij Gorde, Sushil Jajodia, Hongkyu Park,
  and Youngmin Kim.
\newblock Data synthesis based on generative adversarial networks.
\newblock \emph{Proceedings of the VLDB Endowment}, 11\penalty0 (10):\penalty0
  1071--1083, Jun 2018.
\newblock ISSN 2150-8097.
\newblock \doi{10.14778/3231751.3231757}.

\bibitem[Parzen(1962)]{parzen1962estimation}
Emanuel Parzen.
\newblock On estimation of a probability density function and mode.
\newblock \emph{The annals of mathematical statistics}, 33\penalty0
  (3):\penalty0 1065--1076, 1962.

\bibitem[Paszke et~al.(2019)Paszke, Gross, Massa, Lerer, Bradbury, Chanan,
  Killeen, Lin, Gimelshein, Antiga, et~al.]{paszke2019pytorch}
Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory
  Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, et~al.
\newblock {Pytorch: An imperative style, high-performance deep learning
  library}.
\newblock \emph{Advances in neural information processing systems}, 32, 2019.

\bibitem[Pitman(1936)]{pitman1936sufficient}
Edwin James~George Pitman.
\newblock Sufficient statistics and intrinsic accuracy.
\newblock In \emph{Mathematical Proceedings of the cambridge Philosophical
  society}, volume~32, pages 567--579. Cambridge University Press, 1936.

\bibitem[Popov et~al.(2019)Popov, Morozov, and Babenko]{popov2019neural}
Sergei Popov, Stanislav Morozov, and Artem Babenko.
\newblock Neural {Oblivious} {Decision} {Ensembles} for {Deep} {Learning} on
  {Tabular} {Data}.
\newblock \emph{arXiv:1909.06312 [cs, stat]}, September 2019.
\newblock arXiv: 1909.06312.

\bibitem[Qian et~al.(2023)Qian, Cebere, and van~der Schaar]{qian2023synthcity}
Zhaozhi Qian, Bogdan-Constantin Cebere, and Mihaela van~der Schaar.
\newblock Synthcity: facilitating innovative use cases of synthetic data in
  different data modalities, 2023.

\bibitem[Quinlan(1986)]{quinlan1986induction}
J.~Ross Quinlan.
\newblock Induction of decision trees.
\newblock \emph{Machine learning}, 1\penalty0 (1):\penalty0 81--106, 1986.

\bibitem[Ranganath et~al.(2014)Ranganath, Gerrish, and
  Blei]{blackboxVI_ranganath14}
Rajesh Ranganath, Sean Gerrish, and David Blei.
\newblock {Black Box Variational Inference}.
\newblock In Samuel Kaski and Jukka Corander, editors, \emph{Proceedings of the
  Seventeenth International Conference on Artificial Intelligence and
  Statistics (AISTATS)}, volume~33 of \emph{Proceedings of Machine Learning
  Research}, pages 814--822, Reykjavik, Iceland, 22--25 Apr 2014. PMLR.

\bibitem[Ranganath et~al.(2015)Ranganath, Tang, Charlin, and
  Blei]{ranganath2015deep}
Rajesh Ranganath, Linpeng Tang, Laurent Charlin, and David Blei.
\newblock Deep exponential families.
\newblock In \emph{Artificial Intelligence and Statistics}, pages 762--771.
  PMLR, 2015.

\bibitem[R{\'e}nyi et~al.(1961)]{renyi1961measures}
Alfr{\'e}d R{\'e}nyi et~al.
\newblock On measures of entropy and information.
\newblock In \emph{Proceedings of the fourth Berkeley symposium on mathematical
  statistics and probability}, volume~1, pages 547--561. Berkeley, California,
  USA, 1961.

\bibitem[Rezende and Mohamed(2015)]{rezende2015variational}
Danilo Rezende and Shakir Mohamed.
\newblock {Variational inference with normalizing flows}.
\newblock In \emph{International conference on machine learning}, pages
  1530--1538. PMLR, 2015.

\bibitem[Rezende et~al.(2014)Rezende, Mohamed, and
  Wierstra]{rezende2014stochastic}
Danilo~Jimenez Rezende, Shakir Mohamed, and Daan Wierstra.
\newblock Stochastic backpropagation and approximate inference in deep
  generative models, 2014.

\bibitem[Rippel and Adams(2013)]{rippel2013high}
Oren Rippel and Ryan~Prescott Adams.
\newblock High-dimensional probability estimation with deep density models.
\newblock \emph{arXiv preprint arXiv:1302.5125}, 2013.

\bibitem[Robbins and Monro(1951)]{robbins1951stochastic}
Herbert Robbins and Sutton Monro.
\newblock {A Stochastic Approximation Method}.
\newblock \emph{The Annals of Mathematical Statistics}, 22\penalty0
  (3):\penalty0 400 -- 407, 1951.
\newblock \doi{10.1214/aoms/1177729586}.

\bibitem[Ruder(2016)]{ruder_2016_gradient_descent}
Sebastian Ruder.
\newblock An overview of gradient descent optimization algorithms, September
  2016.

\bibitem[Rumelhart et~al.(1986)Rumelhart, Hinton, and
  Williams]{rumelhart1986learning}
David~E Rumelhart, Geoffrey~E Hinton, and Ronald~J Williams.
\newblock Learning representations by back-propagating errors.
\newblock \emph{nature}, 323\penalty0 (6088):\penalty0 533--536, 1986.

\bibitem[Sajjadi et~al.(2018)Sajjadi, Bachem, Lucic, Bousquet, and
  Gelly]{sajjadi2018assessing}
Mehdi~SM Sajjadi, Olivier Bachem, Mario Lucic, Olivier Bousquet, and Sylvain
  Gelly.
\newblock {Assessing generative models via precision and recall}.
\newblock \emph{Advances in neural information processing systems}, 31, 2018.

\bibitem[Salimans et~al.(2016)Salimans, Goodfellow, Zaremba, Cheung, Radford,
  and Chen]{salimans2016improved}
Tim Salimans, Ian Goodfellow, Wojciech Zaremba, Vicki Cheung, Alec Radford, and
  Xi~Chen.
\newblock Improved techniques for training {GANs}.
\newblock \emph{Advances in neural information processing systems}, 29, 2016.

\bibitem[Song et~al.(2013)Song, Chaudhuri, and Sarwate]{song2013stochastic}
Shuang Song, Kamalika Chaudhuri, and Anand~D. Sarwate.
\newblock Stochastic gradient descent with differentially private updates.
\newblock In \emph{2013 {IEEE} {Global} {Conference} on {Signal} and
  {Information} {Processing}}, pages 245--248, December 2013.
\newblock \doi{10.1109/GlobalSIP.2013.6736861}.

\bibitem[Stimper et~al.(2023)Stimper, Liu, Campbell, Berenz, Ryll,
  Sch{\"o}lkopf, and Hern{\'a}ndez-Lobato]{stimper2023normflows}
Vincent Stimper, David Liu, Andrew Campbell, Vincent Berenz, Lukas Ryll,
  Bernhard Sch{\"o}lkopf, and Jos{\'e}~Miguel Hern{\'a}ndez-Lobato.
\newblock normflows: A pytorch package for normalizing flows.
\newblock \emph{arXiv preprint arXiv:2302.12014}, 2023.

\bibitem[Tabak and Turner(2013)]{tabak2013family}
Esteban~G Tabak and Cristina~V Turner.
\newblock A family of nonparametric density estimation algorithms.
\newblock \emph{Communications on Pure and Applied Mathematics}, 66\penalty0
  (2):\penalty0 145--164, 2013.

\bibitem[Tabak and Vanden-Eijnden(2010)]{tabak2010density}
Esteban~G Tabak and Eric Vanden-Eijnden.
\newblock Density estimation by dual ascent of the log-likelihood.
\newblock \emph{Communications in Mathematical Sciences}, 8\penalty0
  (1):\penalty0 217--233, 2010.

\bibitem[Tantipongpipat et~al.(2021)Tantipongpipat, Waites, Boob, Siva, and
  Cummings]{Tanti2021}
U.~Tantipongpipat, C.~Waites, D.~Boob, A.~Siva, and R.~Cummings.
\newblock {Differentially Private Synthetic Mixed-Type Data Generation For
  Unsupervised Learning}.
\newblock In \emph{2021 12th International Conference on Information,
  Intelligence, Systems \& Applications (IISA)}, pages 1--9, Los Alamitos, CA,
  USA, jul 2021. IEEE Computer Society.
\newblock \doi{10.1109/IISA52424.2021.9555521}.

\bibitem[Theis et~al.(2015)Theis, Oord, and Bethge]{theis2015note}
Lucas Theis, A{\"a}ron van~den Oord, and Matthias Bethge.
\newblock A note on the evaluation of generative models.
\newblock \emph{arXiv preprint arXiv:1511.01844}, 2015.

\bibitem[Tipping and Bishop(1999)]{tipping1999probabilistic}
Michael~E Tipping and Christopher~M Bishop.
\newblock Probabilistic principal component analysis.
\newblock \emph{Journal of the Royal Statistical Society: Series B (Statistical
  Methodology)}, 61\penalty0 (3):\penalty0 611--622, 1999.

\bibitem[Tomczak(2022)]{tomczak2022deep}
Jakub Tomczak.
\newblock \emph{Deep Generative Modeling}.
\newblock Springer, 2022.

\bibitem[Torfi et~al.(2021)Torfi, Beyki, and Fox]{torfi2021evaluation}
Amirsina Torfi, Mohammadreza Beyki, and Edward~A Fox.
\newblock On the evaluation of generative adversarial networks by
  discriminative models.
\newblock In \emph{2020 25th International Conference on Pattern Recognition
  (ICPR)}, pages 991--998. IEEE, 2021.

\bibitem[Torfi et~al.(2022)Torfi, Fox, and Reddy]{torfi2022differentially}
Amirsina Torfi, Edward~A Fox, and Chandan~K Reddy.
\newblock {Differentially private synthetic medical data generation using
  convolutional GANs}.
\newblock \emph{Information Sciences}, 586:\penalty0 485--500, 2022.

\bibitem[Vardhan and Kok(2020)]{vardhan2020synthetic}
L~Vivek~Harsha Vardhan and Stanley Kok.
\newblock Generating privacy-preserving synthetic tabular data using oblivious
  variational autoencoders.
\newblock In \emph{Proceedings of the Workshop on Economics of Privacy and Data
  Labor at the 37 th International Conference on Machine Learning}, 2020.

\bibitem[Vaswani et~al.(2017)Vaswani, Shazeer, Parmar, Uszkoreit, Jones, Gomez,
  Kaiser, and Polosukhin]{vaswani2017attention}
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,
  Aidan~N Gomez, {\L}ukasz Kaiser, and Illia Polosukhin.
\newblock Attention is all you need.
\newblock \emph{Advances in neural information processing systems}, 30, 2017.

\bibitem[Waites and Cummings(2021)]{waites2021differentially}
Chris Waites and Rachel Cummings.
\newblock {Differentially private normalizing flows for privacy-preserving
  density estimation}.
\newblock In \emph{Proceedings of the 2021 AAAI/ACM Conference on AI, Ethics,
  and Society}, pages 1000--1009, 2021.

\bibitem[Walonoski et~al.(2018)Walonoski, Kramer, Nichols, Quina, Moesel, Hall,
  Duffett, Dube, Gallagher, and McLachlan]{walonoski2018synthea}
Jason Walonoski, Mark Kramer, Joseph Nichols, Andre Quina, Chris Moesel, Dylan
  Hall, Carlton Duffett, Kudakwashe Dube, Thomas Gallagher, and Scott
  McLachlan.
\newblock Synthea: An approach, method, and software mechanism for generating
  synthetic patients and the synthetic electronic health care record.
\newblock \emph{Journal of the American Medical Informatics Association},
  25\penalty0 (3):\penalty0 230--238, 2018.

\bibitem[Wang and Liu(2020)]{wang2020understanding}
Feng Wang and Huaping Liu.
\newblock Understanding the behaviour of contrastive loss.
\newblock \emph{arXiv preprint arXiv:2012.09740}, 2020.

\bibitem[Wang et~al.(2023)Wang, Wang, Zhao, and Wang]{wang2023differential}
Yanling Wang, Qian Wang, Lingchen Zhao, and Cong Wang.
\newblock {Differential privacy in deep learning: Privacy and beyond}.
\newblock \emph{Future Generation Computer Systems}, 2023.

\bibitem[Wang et~al.(2019)Wang, Balle, and Kasiviswanathan]{wang2019subsampled}
Yu-Xiang Wang, Borja Balle, and Shiva~Prasad Kasiviswanathan.
\newblock Subsampled {Renyi} {Differential} {Privacy} and {Analytical}
  {Moments} {Accountant}.
\newblock In \emph{Proceedings of the {Twenty}-{Second} {International}
  {Conference} on {Artificial} {Intelligence} and {Statistics}}, pages
  1226--1235. PMLR, April 2019.
\newblock ISSN: 2640-3498.

\bibitem[Williams(1992)]{williams1992simple}
Ronald~J Williams.
\newblock Simple statistical gradient-following algorithms for connectionist
  reinforcement learning.
\newblock \emph{Machine learning}, 8\penalty0 (3):\penalty0 229--256, 1992.

\bibitem[Winkler et~al.(2019)Winkler, Worrall, Hoogeboom, and
  Welling]{winkler2019learning}
Christina Winkler, Daniel Worrall, Emiel Hoogeboom, and Max Welling.
\newblock Learning likelihoods with conditional normalizing flows.
\newblock \emph{arXiv preprint arXiv:1912.00042}, 2019.

\bibitem[Xu et~al.(2019)Xu, Skoularidou, Cuesta-Infante, and
  Veeramachaneni]{xu2019modeling}
Lei Xu, Maria Skoularidou, Alfredo Cuesta-Infante, and Kalyan Veeramachaneni.
\newblock {Modeling tabular data using conditional GAN}.
\newblock \emph{Advances in neural information processing systems}, 32, 2019.

\bibitem[Yang et~al.(2022)Yang, Zhang, Song, Hong, Xu, Zhao, Shao, Zhang, Cui,
  and Yang]{yang2022diffusion}
Ling Yang, Zhilong Zhang, Yang Song, Shenda Hong, Runsheng Xu, Yue Zhao,
  Yingxia Shao, Wentao Zhang, Bin Cui, and Ming-Hsuan Yang.
\newblock Diffusion models: A comprehensive survey of methods and applications.
\newblock \emph{arXiv preprint arXiv:2209.00796}, 2022.

\bibitem[Yousefpour et~al.(2021)Yousefpour, Shilov, Sablayrolles, Testuggine,
  Prasad, Malek, Nguyen, Ghosh, Bharadwaj, Zhao, et~al.]{yousefpour2021opacus}
Ashkan Yousefpour, Igor Shilov, Alexandre Sablayrolles, Davide Testuggine,
  Karthik Prasad, Mani Malek, John Nguyen, Sayan Ghosh, Akash Bharadwaj,
  Jessica Zhao, et~al.
\newblock {Opacus: User-friendly differential privacy library in PyTorch}.
\newblock \emph{arXiv preprint arXiv:2109.12298}, 2021.

\bibitem[Zhang et~al.(2018{\natexlab{a}})Zhang, B{\"u}tepage, Kjellstr{\"o}m,
  and Mandt]{zhang2018advances}
Cheng Zhang, Judith B{\"u}tepage, Hedvig Kjellstr{\"o}m, and Stephan Mandt.
\newblock Advances in variational inference.
\newblock \emph{IEEE transactions on pattern analysis and machine
  intelligence}, 41\penalty0 (8):\penalty0 2008--2026, 2018{\natexlab{a}}.

\bibitem[Zhang et~al.(2018{\natexlab{b}})Zhang, Ji, and
  Wang]{zhang2018differentially}
Xinyang Zhang, Shouling Ji, and Ting Wang.
\newblock Differentially private releasing via deep generative model.
\newblock \emph{CoRR}, abs/1801.01594, 2018{\natexlab{b}}.

\bibitem[Zhou et~al.(2020)Zhou, Cui, Hu, Zhang, Yang, Liu, Wang, Li, and
  Sun]{zhou2020graph}
Jie Zhou, Ganqu Cui, Shengding Hu, Zhengyan Zhang, Cheng Yang, Zhiyuan Liu,
  Lifeng Wang, Changcheng Li, and Maosong Sun.
\newblock {Graph neural networks: A review of methods and applications}.
\newblock \emph{AI open}, 1:\penalty0 57--81, 2020.

\end{thebibliography}
