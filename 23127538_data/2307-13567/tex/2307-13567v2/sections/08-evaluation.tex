\section{Evaluation}

\subsection{Evaluation of Deconstruction Algorithm}\label{quantatitive}
% In this section, we report the performance of Mystique on our collected SVG dataset~(\cref{sec:dataset}).

\textbf{Chart Corpus.}
A chart corpus is essential for developing and evaluating reuse algorithms and tools. 
Based on our scope described in \cref{sec:intro}, we first considered the rectangle-based charts in Beagle~\cite{battle2018beagle}. However, we found that its distribution over chart types is unbalanced: a majority of the charts are simple bar charts and histograms. 
Furthermore, the corpus contains charts created by only five tools, which is insufficient to capture the differences in SVG representations across different tools to achieve tool-agnostic reuse.
Therefore, we decided to collect our own corpus. Instead of prioritizing the quantity of charts, we sought to promote distribution balance and chart diversity in terms of layout, SVG representation (which is associated with the tool that produced the example), and visual style (e.g., colors theme and decoration). 

We started with the chart designs in Beagle (which were mostly created using D3), then referred to online catalogs such as the Chartmaker Directory \cite{chartmaker_dir}, which maintain comprehensive chart taxonomies and tools for each chart type. For each rectangle-based chart type in the catalogs, we sampled examples with design variations~(e.g., different orientations, alignments, and axis positions) produced by different tools. We used two methods to obtain the SVG representations of these examples. We downloaded the SVG elements, if available, and re-created examples using Charticulator~\cite{ren_charticulator_2018} and Data Illustrator~\cite{liu_data_2018} when examples are available only in demo videos or in raster images (e.g., Figma charts \& infographics \cite{figma_charts}). Finally, we browsed D3 galleries including bl.ocks.org~\cite{blockOrg} and Observable~\cite{observableplot} to identify and download bespoke designs that do not fall into predefined chart categories. 
The final collection, shown in~\cref{fig:corpus}, consists of 150 SVG charts produced by 25 tools, encompassing 17 chart types, 7 small multiple designs, \markup{3 superimposed views}, and 9 bespoke designs. 
The supplementary materials contain the 150 charts and figures showing details on the distributions of chart design in Beagle and our corpus.

% Figure environment removed

\noindent \textbf{Axis \& Legend Detection Accuracy.}
On the 150 SVG charts, Mystique achieves $86.67\%$, $85.33\%$, and $90.67\%$ accuracy on the x-axis, y-axis, and legend inference, respectively. The supplementary materials contain detailed illustrations about the errors. \revise{All the detection errors can be corrected using the interactions described in \cref{sec:axisLegend}.} 

\bpstart{GREC-based Chart Deconstruction Accuracy} Before developing the deconstruction algorithm (\cref{sec:chartDecomp}), we split our dataset into $105$ training and $45$ test charts~(a standard 7:3 ratio~\cite{goodfellow2016deep}) to avoid over-fitting and promote generalizability. We ensured that this 7:3 split is approximately maintained for both chart types and visualization tools.
We designed and fine-tuned our algorithm based only on the training set. %, and evaluate the algorithm on the test set.
The deconstruction algorithm achieves $96.19\%$~(= $101$/$105$) accuracy on the training set and $95.56\%$~(= $43$/$45$) accuracy on the test set.
Specifically, the algorithm fails in three cases where multiple charts~(e.g., the superimposed bar charts in \cref{fig:errors}a) or marks~(e.g., the treemap in \cref{fig:errors}b) are overlaid on top of one another.
Among the remaining three error cases, two represent rectangles using $<$line$>$ elements with large stroke-width values which is rarely seen; it also interferes with the cases where large-stroke-width $<$line$>$ elements represent axis lines, hindering our pre-processing method from accurately handling such cases. The remaining error case is due to relatively large gaps~($6$ pixels) between neighboring rectangles in a treemap---our threshold hyper-parameter for the gap parameter in a packing relationship is 5. These error cases are included in the supplementary materials.

% Figure environment removed

\noindent \textbf{Algorithm Efficiency.} For each chart in the test set, we also recorded the time of main chart content decomposition. 
% The performance test is run using the Google Chrome browser on a 14-inch MacBook Pro with 8-Core Apple M1 Pro CPU, 16GB Unified Memory, and Mac OS Monterey v12.5.1. 
% As the number of marks increases, the computational time increases. 
All the examples can be deconstructed within one second, except a heatmap created with Vega, which consists of more than 8K marks. The supplementary materials include detailed performance data.


%=============================
\subsection{Chart Reproduction User Study}
To evaluate whether users can understand and follow the guidance from Mystique to reuse existing charts and produce new ones, we conducted a chart reproduction study~\cite{ren2018reflecting}.

\bpstart{Participants and Procedure}
We recruited $12$ participants~($5$ male, $7$ female) from the Washington metropolitan area. The statistics on how often they create data visualizations are as follows:
\markup{
Never~(1, $8.3\%$), A few times per year~(4, $33.3\%$), A few times per month~(5, $41.7\%$), and A few times per week~(2, $16.7\%$). The tools they have used are Excel~(6, $50.0\%$), Tableau~(6, $50.0\%$), D3.js~(5, $41.67\%$), ggplot2~(3, $25.0\%$), Vega/Vega-Lite~(2, $16.7\%$), Figma~(1, $8.3\%$), and Others~(4, $33.3\%$).
}

All the study sessions were conducted remotely on Zoom and each lasted about 1 hour. After a brief explanation of the study goal, we walked the participants through two sets of tutorials. The first set was on the UI for fixing axis and legend detection errors. The participants learned what kinds of errors could happen, and how to fix them through interactions. The second set of tutorials taught the participants about the workflows to reuse a simple bar chart and a grouped bar chart. The tutorials lasted about $25$ to $30$ minutes. The participants then were asked to complete four visualization creation tasks, reusing one chart for each task, with Mystique. At the end of the session, each participant completed a questionnaire, and we conducted a debriefing regarding their experiences using Mystique. Each participant was given a \$15 gift card as a token of appreciation.

\bpstart{Tasks}
We used a bullet chart (\cref{fig:teaser}c) for Task 1, a grouped stacked bar chart (\cref{fig:teaser}e) for Task 2, a diverging stacked bar chart (\cref{fig:teaser}d) for Task 3, and a range chart (\cref{fig:teaser}b) for Task 4. 
We chose these four charts to cover the major types of axis/legend detection errors: Task 2 requires adding a missing higher-level x-axis; Task 4 requires adding a missing y-axis; and Tasks 2 and 3 require changing incorrectly inferred field types. The four tasks also cover different semantic components with varying complexity in terms of nesting structures: Task 1 involves glyphs composed of multiple rectangles, whose positions are constrained; Task 2 has three levels of nesting; Task 3 involves the alignment constraint across collections; and in Task 4, the top and bottom segments of each rectangle encode data. 
For each task, we explained the input example chart, provided the participants with a new dataset, and described the schema and meaning of the new dataset. The participants were not shown any charts they need to create, only text descriptions of the target charts. 
Not to prime the participants or make the tasks too easy, we deliberately avoided mentioning visual channels in the instructions. For instance, the requirement for Task 4 is phrased as: ``\textit{Please create a visualization of the dataset. Each bar represents a dayâ€™s temperature range, from minimum to maximum temperature. The color represents the average temperature in the day}.''

% % Figure environment removed

\bpstart{Results}
All participants produced a visualization for all the tasks, but 5 out of 48 visualizations were not what the requirements asked for. The participants completed each task within five minutes on average, with Tasks 2 and 4 taking longer~(\cref{table:userStudy}): Task 2 involves three nesting levels, and Task 4 involves multiple combinations of the visual channel and data field.  
The participants rated their experience of using Mystique on a 5-point Likert scale (1: ``Strongly Disagree'' to 5:``Strongly Agree'') in the post-study questionnaire. The results are as follows: efficiency, $\mu=3.92$ $\sigma=1.04$; convenience regarding accommodating changes, $\mu=4.58$, $\sigma=0.49$; and \markup{comfort/confidence}, $\mu=4.25$, $\sigma=1.01$.

\begingroup
\renewcommand{\arraystretch}{1.1}
\begin{table}[ht]
\caption{The number of participants completing each task successfully, and the average completion time with standard deviation.}
\scriptsize
\begin{tabular*}{\linewidth}{cccc}
\toprule
Task       &      \# Successes  &     Average Time (minutes)   &      Standard Deviation         \\ \toprule
1            &     11            &  2.87     &  1.62                  \\ \midrule
2      &            11          &  4.35      &  2.47                \\ \midrule
3         &       11            &  2.86     &  2.40                  \\ \midrule
4      &           10          &  4.96      &  2.20                \\ \bottomrule
\end{tabular*}
\label{table:userStudy}
\end{table}
\endgroup

\vspace{-2mm}
We identified three main reasons why the participants failed to produce the correct visualization. First, some participants misunderstood the instructions. For instance, P3 produced a chart with three nested levels for Task 2, but the order of nesting was incorrect. He had trouble interpreting the instruction: ``\textit{The visualization should show the sales distribution for each region grouped by product category and subcategory}.'' Second, some participants did not understand the meanings of certain visual channels, particularly for Task 4. For instance, P4 stated that ``\textit{some sentences and words are not really clear for me. For example, there was a sentence where I can choose left-side, right-side [which were unclear].}'' Finally, one participant forgot that the visual channels were configurable too. After we reminded her, she could quickly create the desired chart during the debriefing.

Participants' experience in creating data visualizations affected their performance in completing tasks. Among the four participants who did not complete all tasks, three create visualizations ``a few times a year,'' and one ``never'' specifically created visualizations. It was harder for them to follow the instructions from Mystique. 

We also recorded the number of times participants clicked on the Back button to review previous steps. The average values for the tasks are 1.08, 1.42, 1.08, and 4.08, respectively. For the first three tasks, most participants were able to operate very close to the optimal strategies, i.e., without going back. For the last task~(a range chart), most participants more frequently used the Back button, trying to find the correct mappings between visual channels and data fields.

% \revise{To better understand participants' interaction and pain points in using the wizard interface, we analyze the number of times moving back and forth on the reuse steps~(\textit{\#Clicks on Back Button} in \cref{fig:evalMeasures}). 
% For the first three tasks (bullet chart, grouped stacked bar chart, and diverging stacked bar chart), most participants were able to operate very closely to the optimal strategies, i.e., without going back to previous steps. 
% For the last task of re-creating a range chart, most participants more frequently used the Back button compared to the first three tasks, trying to find the correct mapping between visual channels and data fields.
% Individual participants also encountered difficulties during specific tasks, and used the Back button extensively in such cases, 
% e.g., P9 on Task 1, P6 on Tasks 2 \& 3.
% Based on our observation, the interactions and real-time visualization rendering in the wizard interface help the participants to explore data bindings, validate user-specified reuse steps, and build confidence in users' results.}

Overall, participants were satisfied with the usability of Mystique. P8 stated that ``\textit{it makes new visualizations with my dataset very easily by taking an example visualization found somewhere and adjusting the visualization. Also, it is very intuitive.}'' P8 also commented on the non-programming authoring process: ``\textit{It is a very interesting tool and useful for people who have no interest in programming. It might be useful for quick prototyping for visualization ideas.}'' P1 liked Mystique's wizard interface: ``\textit{Mystique gives a response after each step so I know whether I am on the right track, while in Python I cannot imagine what chart I am getting when writing codes there}.''

Participants also suggested several aspects for improvement. First, the guidance information in the Instruction Panel can be conveyed more clearly,
e.g., P8 mentioned ``\textit{it was hard to understand what x position exactly means in Task 4}'' and P6 commented ``\textit{the terms were too difficult to understand. It was hard to find what they meant exactly~(top side, bottom side, height, etc.).}'' Second, since customization is done after exporting the chart and not included in the study,
the participants wanted the reuse UI to support fine-tuning:
``\textit{one improvement could be to allow more flexibility; for instance, currently there is no option for selecting the color used in the chart}'' (P7).
