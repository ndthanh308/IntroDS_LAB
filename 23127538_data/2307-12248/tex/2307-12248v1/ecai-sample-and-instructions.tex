\documentclass{ecai}
\usepackage{graphicx}
\usepackage{latexsym}
\usepackage{balance} % for balancing columns on the final page
\usepackage{hyperref}
% \usepackage{array,multirow}
\usepackage{enumerate}
\usepackage[inline]{enumitem}
% \usepackage{boldline}
\usepackage{hhline,multirow}%
\usepackage{amsmath,amssymb,amsfonts}%
% \usepackage{amsthm}%
% \usepackage{booktabs}%
% \usepackage{float}
% \restylefloat{table}
% \usepackage[utf8]{inputenc} % allow utf-8 input
% \usepackage[T1]{fontenc}    % use 8-bit T1 fonts
% \usepackage{hyperref}       % hyperlinks
% \usepackage{url}            % simple URL typesetting
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
% \usepackage{microtype}      % microtypography
% \usepackage{subcaption}
% \usepackage{times}
% \usepackage{soul}
% \usepackage{url}
% \usepackage{eucal}
% \usepackage{anyfontsize}
% \usepackage{t1enc}

\usepackage{booktabs} % for professional tables
\usepackage[caption = false]{subfig}
\usepackage{float}


% \usepackage{amsfonts,amssymb}
% \usepackage{amsmath}
% \usepackage{graphicx}
% \usepackage{mathrsfs}%
% \usepackage[title]{appendix}%
% % \usepackage{xcolor}%
% % \usepackage[table]{xcolor}
% \usepackage{textcomp}%
% \usepackage{manyfoot}%

% \usepackage{algorithm}%
% \usepackage{float}
% \usepackage{algcompatible}
% % \usepackage{algorithmic}%
% % \usepackage{algpseudocode}%
% % \usepackage{algcompatible}
% \usepackage{listings}%

\makeatletter
\DeclareRobustCommand{\qed}{%
  \ifmmode % if math mode, assume display: omit penalty etc.
  \else \leavevmode\unskip\penalty9999 \hbox{}\nobreak\hfill
  \fi
  \quad\hbox{\qedsymbol}}
\newcommand{\openbox}{\leavevmode
  \hbox to.77778em{%
  \hfil\vrule
  \vbox to.675em{\hrule width.6em\vfil\hrule}%
  \vrule\hfil}}
\newcommand{\qedsymbol}{\openbox}
\newenvironment{proof}[1][\proofname]{\par
  \normalfont
  \topsep6\p@\@plus6\p@ \trivlist
  \item[\hskip\labelsep\itshape
    #1.]\ignorespaces
}{%
  \qed\endtrivlist
}
\newcommand{\proofname}{Proof}
\makeatother

% \newenvironment{proof}[2] {\paragraph{Proof of {#1} {#2} :}}{\hfill$\square$}
% \newtheorem{thm}{Theorem}
\newtheorem{definition}{Definition}
\newtheorem{problem}{Problem}
\newtheorem{lemma}{Lemma}
% \newtheorem{proof}{Proof}
\newtheorem{example}{Example}
% \newtheorem{theorem}{Theorem}
\newtheorem{proposition}{Proposition}
\newtheorem{corollary}{Corollary}
\newtheorem{remark}{Remark}





\def \erre{\mathbb{R}}
\def \k{\mathbf{k}}
\def \FF{\mathcal{F}}
\def \WWl{\mathcal{W}_{\lambda,C}}
\def \BB{\mathcal{B}}
\def \DD{\mathcal{D}}
\def \DDr{\mathcal{D}_{rel}}
\def \DDp{\mathcal{D}_p}
\def \PP{\mathcal{P}}
\def \MM{\mathcal{M}}
\def \QQ{\mathcal{Q}}
\def \EE{\mathcal{E}}

\def \AA{\mathcal{A}}

\def\B{{\mathbb B}}
\def\N{{\mathbb N}}

\def \X{\Bar{X}}
\def \i{\Bar{i}}

\def\argmin{{\rm argmin}}
\def\argmax{{\rm argmax}}
% \ecaisubmission   % inserts page numbers. Use only for submission of paper.
                  % Do NOT use for camera-ready version of paper.

\begin{document}

\begin{frontmatter}

\title{A Bilevel Formalism for the Peer-Reviewing Problem}


\author[A]{\fnms{Gennaro}~\snm{Auricchio}\thanks{Corresponding Author. Email: ga647@bath.ac.uk}}
\author[B]{\fnms{Ruixiao}~\snm{Zhang}}
\author[A]{\fnms{Jie}~\snm{Zhang}}
\author[B]{\fnms{Xiaohao}~\snm{Cai}} % use of \orcid{} is optional


\address[A]{Department of Computer Science, University of Bath}
\address[B]{School of Electronic and Computer Science, University of Southampton}

\begin{abstract}
Due to the large number of submissions that more and more conferences experience, finding an automatized way to well distribute the submitted papers among reviewers has become necessary. We model the peer-reviewing matching problem as a {\it bilevel programming (BP)} formulation. Our model consists of a lower-level problem describing the reviewers' perspective and an upper-level problem describing the editors'. Every reviewer is interested in minimizing their overall effort, while the editors are interested in finding an allocation that maximizes the quality of the reviews and follows the reviewers' preferences the most. To the best of our knowledge, the proposed model is the first one that formulates the peer-reviewing matching problem by considering two objective functions, one to describe the reviewers' viewpoint and the other to describe the editors' viewpoint. We demonstrate that both the upper-level and lower-level problems are feasible and that our BP model admits a solution under mild assumptions. After studying the properties of the solutions, we propose a heuristic to solve our model and compare its performance with the relevant state-of-the-art methods. Extensive numerical results show that our approach can find fairer solutions with competitive quality and less effort from the reviewers.\footnotemark
% Due to the large number of submissions that more and more conferences experience, finding an automatized way to well distribute the submitted papers among reviewers has become necessary. 
% % 
% In this paper, we model the peer-reviewing matching problem as a {\it bilevel programming (BP)} formulation.
% % 
% Our model consists of a lower-level problem describing the reviewers' perspective and an upper-level problem describing the editors'.
% % 
% Every reviewer is interested in minimizing their overall effort, while the editors are interested in finding an allocation that maximizes the quality of the reviews and follows the reviewers' preferences the most.
% % 
% To the best of our knowledge, the proposed model is the first one that formulates the peer-reviewing matching problem by considering two objective function, one to describe the reviewers' viewpoint and to describe the editors' viewpoint.
% % 
% We demonstrate that both the upper-level and lower-level problems are feasible problems and that our BP model admits a solution under mild assumptions. 
% % 
% After studying the properties of the solutions, we propose a heuristic to solve our model and compare its performance with the relevant state-of-the-art methods.
% % 
% Extensive numerical results show that our approach can find fairer solutions with competitive quality and less effort from the reviewers.
\end{abstract}

\end{frontmatter}


\stepcounter{footnote}
\footnotetext{Our code website: \url{https://github.com/Galaxy-ZRX/Bilevel-Review}.}

\section{Introduction}
%\xc{Lots of paragraphs are too long I suppose. It would be better to break them into a few more short ones.}
%\genna{Agreed. What about this partition for the introduction? If it is ok, I will try to separate the other section following the same principles.} %\xc{Looks great. Yep, please also check other sections.}

% 
The peer-review process is the procedure followed by scientific journals to establish the novelty and correctness of research papers submitted for publication \cite{shah2022challenges,jana2019history}. 
% 
The principle behind this process is simple.
% 
Once the editors of a journal receive a submission, they invite a sufficient number of reviewers to review it and, depending on the reviewers' reports, the editors decide whether the paper meets the criteria for publication or not.
% 
To make this process meaningful, there must be a concordance between the topic of the paper and the expertise of the reviewers, ensuring both the authors of the paper and the editors that the reviewers are competent on the topics discussed in the paper.
% 
% 
% 
Although the peer-review procedure has been proven to be reliable for scientific journals, it shows some flaws when applied to large conferences. 
% 
In this case, all authors need to submit their papers by a specified deadline, after which all the submitted papers will be allocated to some reviewers by the editors.
% 
Since most conferences have only one submission deadline per year, all the papers are submitted in a few days; consequently, the editors need to handle a large number of papers at the same time.
% 
In particular, the editors have to determine the allocation hastily since this allocation process needs to respect the tight schedule of the conference.
% 

% 
Due to the large number of papers the editors usually receive and the lack of time, the allocation process becomes unaffordable through classic means.
% 
To meet this need for time efficiency, several automatized ways to determine a peer-reviewer allocation have been proposed.
% 
As we will detail in the related work below, the vast majority of the approaches assume that the best peer-reviewing matching is the minimum/maximum of a suitable objective function.
% 
This allows rephrasing the whole problem as an optimization problem whose objective encodes an appealing property that the peer-reviewing allocation should have.
% 
Albeit every model finds an allocation following its own criterion, all the models tacitly assume that the editors are the agents that actively decide the allocation.
% 
This is limiting for two reasons.
% 
One is that the efficiency of these methods is bound to how accurate the computation of the objective function is;
the other is that reviewers are often allowed to interfere in the assignment procedure by refusing to review some papers or by bidding for them. 
% 

% 
To represent the interplays between different agents (\textit{i.e.}, editors and reviewers), we propose and study a model that phrases the peer-reviewing allocation problem through a {\it bilevel programming (BP)} formulation.
% 
Bilevel optimization has been proven to be a valuable expedient to describe several allocation problems in a multi-agent framework, such as the ones concerning resource allocation \cite{xu2013bilevel}, traffic engineering  \cite{9170527}, genomic problems \cite{burgard2003optknock}, and Knapsack Problems \cite{denegre2011interdiction}.
%  
The appeal of BP problems lies in the fact that relating the solutions of different optimization problems well captures how the choice of one agent affects the others.
% 
For a complete discussion on the BP problems, we refer the reader to \cite{dempe2002foundations}.
% 



{\bf Related Work.} 
% 
At its core, finding a peer-reviewing matching is a matching problem for indivisible goods.
% 
Matching problems were first introduced in the first half of the twenty century by Hitchcock \cite{Hitchcock1941} and Kantorovich \cite{Kantorovitch1958}.
% 
Ever since they were introduced, this class of problems found several different applications, such as stable marriage \cite{irving1994stable,mcvitie1971stable}, workers and job matching \cite{Easterfield1946,Thorndike1950}, resource allocation \cite{feng2013device,7295474}, and biomedical data analysis \cite{auricchio2018computing}. 


It was observed that the first attempt at modeling the peer-reviewing process as a matching problem dates back to $2007$; and then an integer linear programming (ILP) model was proposed, whose solution is an allocation minimizing the possible complaints of the reviewers.
% 
This was done with or without considering the reviewers' expertise \cite{goldsmith2007ai}. 
% 
In \cite{garg2010assigning,lesca2010lp}, the authors improved this model by searching for a fair allocation, \emph{i.e.}, an allocation that equalizes every reviewers' payoff as much as possible. 
% 
In \cite{garg2010assigning}, this is accomplished by maximizing the minimum of the reviewers' payoffs, while in \cite{lesca2010lp}, the authors try to implement classic social inequality functions, such as the Gini's social evaluation function.
% 
Another similar approach is taken in \cite{DBLP:conf/aaai/DickersonSSX19}, where the authors proposed a new category of matching problems, called \emph{diverse matching problems}.
% 
% Given two sets, namely $A$ and $B$, and a partition over the set $B$, namely $\mathcal{B}$, the problem consists of finding a matching between two sets that matches the highest possible number of elements in $B$ from different sets of the fixed partition $\mathcal{B}$.
% % 
% They called these matchings \textit{diverse allocations} and, among the many possible applications, they proposed to use them to improve peer-reviewing matching. 
% 
Despite the differences of those models, they all share the idea that the optimal peer-reviewing allocation is characterizable as the minimum/maximum of an objective function over a suitable restricted set of matching.
% 
Moreover, all these routines are able to detect a solution without gathering data from the reviewers.
% 
Indeed, all the objective functions used by these procedures are assumed to be known \textit{a priori} or to be computable through machine learning means using data from open-access sites, such as Google Scholar.
% 
These concepts are also at the base of the Toronto Paper Matching System (TPMS) \cite{toronto} -- one of the most credited and used peer-reviewing matching procedures.
% 
% To the best of our knowledge, there are only a few works that proposed a mathematical formulation able to include the reviewers in the assignment process. 
% % 
% In \cite{lian2018conference}, the authors defined an algorithm that finds a peer-review allocation using voting mechanisms and order-weighted averages.
% % 
% Another approach using tools from game theory is presented in \cite{meir2021market}, where the authors studied the peer-reviewing problem under the assumption that the reviewers can lie about their preferences while bidding. 
% 

% 
% Finally, we highlight two papers that tackle the problem from a different perspective.
% %
% In \cite{DBLP:journals/corr/abs-2109-00923}, the process is modeled as a two-step mechanism, one for the submission and one for the reviewing. 
% % 
% In this model, the reviewers are assumed to be paid with the same currency that is used during the auctions to receive a review.
% % 
% In \cite{xiao2018incentive}, the authors studied an iterative allocation mechanism that rewards reviewers for their efforts by assigning them rankings. 
% % 
% The rankings of every individual determine the output of the matching mechanism during the following iterations.
% % 


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


{\bf Paper Outline.}
% 
In Section \ref{sec:basic_notions}, we briefly review the classic ILP model for the peer-reviewing matching problem.
% 
In Section \ref{sect:bilevel}, we introduce our BP model for the peer-reviewing matching problem.
% 
We describe and study the upper-level problem (ULp) and lower-level problem (LLp) of our formulation and give a set of conditions that ensure the existence of a solution.
% 
% Moreover, we show that the BP problem is equivalent to a single-level formulation and prove that our model generalizes the classic ILP model.
% 
In Section \ref{sec:num_exp}, a heuristic solution is introduced to our BP model and its performance compared with the ones obtained by the relevant state-of-the-art.
% is also conducted.
% 
The results show that our model can find quasi-optimal solutions that are much fairer than the classic ones. 
%
Finally, we conclude in Section \ref{sec:conclusion} and outline some future research directions.
% 
Due to space limit, we report the proofs of the proposed statements, the discussion on the Secondary Variational Problem, and additional numerical results in the Appendix.
% 

\section{Maximum Edge-weighted Matching formulation}
\label{sec:basic_notions}


% 
In this section, we recall the ILP model on which the TPMS is based \cite{toronto}.
% 
Throughout the paper, we denote with $\mathbb{B}_{nm}$ the set of $n\times m$ binary matrices.
% 
Given $A,B\in\mathbb{B}_{nm}$, we say that $A\le B$ if $a_{i,j}\le b_{i,j}$, $\forall i\in [n], \; j \in [m]$, where $[\ell]$ denotes the set containing the first $\ell$ natural numbers, \emph{i.e.}, $[\ell]:=\{1,2,3,\dots,\ell\}$. 


In mathematical terms, peer-reviewing matching can be described as the solution of a maximum edge-weighted matching problem over a bipartite graph $G$.
% 
The two sides of the bipartite graph $G$ are composed of the set of papers $\mathfrak{P}=[n]$ and  the set of reviewers $\mathfrak{R}=[m]$.
% 
The bipartite graph is therefore given by $G=([n]\cup [m], [n]\times [m])$ and any matrix $X\in\mathbb{B}_{nm}$ describes a possible papers allocation.
% 
Following the classic conventions, the edge $(i,j)$ is active, \emph{i.e.}, $X_{i,j}=1$, if and only if paper $i$ is allocated to reviewer $j$.


Since the editors have to ensure a certain amount of reviews for every paper and no reviewer can be overburdened with papers to review, every feasible matching has to comply with some restriction that bounds the number of active edges connected to every vertex of the bipartite graph.
% 
The linear objective function of the problem is determined by the edge weight matrix $W=\{w_{i,j}\}_{(i,j)\in G}$.
% 
The weight $w_{i,j}$ of the edge $(i,j)$ represents the expected quality of the review that paper $i$ receives from reviewer $j$, hence we refer to the matrix $W$ as the \emph{quality} matrix.
% 
In this framework, the optimal peer-reviewing matching is characterized as the solution of the maximum edge-weighted matching problem induced by the quality matrix $W$ over the bipartite graph $G$, since it describes the matching maximizing the overall quality of the reviews.
% 
We below detail the constraints the editors must comply with and how the matrix $W$ is determined.
% 


\paragraph{Problem Constraints.}


% 
We have two sets of constraints, one for each side of the bipartite graph.
% 
Their role is to regulate the number of reviews that every paper receives and to limit the number of reviews that every reviewer can be asked to perform.
% 
In detail, the constraints are as follows.
% 
\begin{enumerate*}[label=(\roman*)]
\item The set of constraints that is imposed over the set of reviewers is $\sum_{i\in [n]} X_{i,j}\le U_j$, $\forall j \in [m]$. 
    % 
    To do so, we restrict the number of papers the editors can assign to each reviewer.
    %
    The value $U_j$ is therefore the maximum number of papers that can be allocated to reviewer $j$.
\item The set of constraints that is imposed over the set of papers is $l_i \le \sum_{j\in [m]}X_{i,j}\le u_i$, $\forall i \in [n]$.
    % 
    To do so, we bound the editors to assign every paper $i$ to at least $l_i$ and at most $u_i$ reviewers.
    \item We assume every paper is indivisible, imposed by the restriction $X\in\mathbb{B}_{nm}$.
\end{enumerate*}
% 
Finally, the optimal peer-reviewing assignment is retrieved by solving the following ILP problem.
% \ref{eq:prob_LP_classic}.
% 

% 
\begin{problem}
\label{pr:classic}
Given $n,m\in\mathbb{N}$, and a quality matrix $W$, the classic ILP model for the peer-reviewing assignment is 
\begin{align*}
% \label{eq:prob_LP_classic}
   \max_{X\in\mathbb{B}_{nm}}\langle W,X \rangle,\quad\text{s.t.} \quad l_i \le \sum_{j\in [m]}X_{i,j} \le u_i, \quad \,\sum_{i\in [n]} X_{i,j}\le U_j,
\end{align*}
where the constraints hold for every $i\in [n]$ and $j\in [m]$ and $\langle \cdot , \cdot \rangle$ is the scalar product in the Euclidean space.
\end{problem}
% 

It is easy to see that, as long as $l_i\le u_i$, $\forall i\in [n]$ and $\sum_{i \in [n]}l_i\le \sum_{j\in [m]}U_j$, Problem \ref{pr:classic} is well-defined and admits a solution \cite{edmonds1965maximum}.
% 
% \begin{remark}
% \label{rmk:1}
% Depending on values $\{l_i\}_{i \in [n]}$, $\{u_i\}_{i \in [n]}$, and $\{U_j\}_{j\in [m]}$, the set of feasible matching might be empty.
% % 
% A classic condition ensures that if $l_i\le u_i$, $\forall i\in [n]$ and $\sum_{i \in [n]}l_i\le \sum_{j\in [m]}U_j$, then the set of feasible matching is not empty; Problem \ref{pr:classic} is well-defined and, therefore, admits at least a solution.
% % 
% For a complete discussion on the well-posedness of ILP problems and other related problems, we refer the reader to \cite{edmonds1965maximum}.
% \end{remark}
% 



\paragraph{Quality Matrix $W$ and Its Role.}
\label{sec:workload_matrix}
% 
Determining a meaningful quality matrix $W$ is of key importance for every allocation method based on the ILP model described in Problem \ref{pr:classic}.
% \eqref{eq:prob_LP_classic}.
% 
% Indeed, $W$ plays two different and important roles.
% % 
% First, it helps the editors get meaningful reviews for the papers they have to take care of.
% % 
% Second, it guarantees the authors that their work will be reviewed by people that are knowledgeable about the topics of the paper.
% 
For this reason, retrieving a quality matrix $W$ that reliably represents the expertise of the reviewers is still a topic of study and discussion.


One way to retrieve the matrix $W$ is to associate every paper and reviewer to a set of labels that summarizes the contents and the fields of expertise, respectively.
% 
Since both the contents of the paper and the fields of expertise are drawn from the same set of topics,  it is possible to represent these labels as vectors over an $r$ dimensional space, where $r$ is the total number of possible topics.
% 
If we denote with $v_{p_i}$ the vector describing the topics of the paper $i$ and with $v_{r_j}$ the expertise vector of reviewer $j$, we can then compute the quality of the review performed by reviewer $j$ on paper $i$ as the scalar product between $v_{p_i}$ and $v_{r_j}$, \cite{sugiyama2010scholarly}.
% 
This metric does make sense since the more the vectors are aligned, the higher will be their scalar product.
% 
Moreover, if all the vectors have only positive entries, all the scalar products will return a positive value.
% 
Since there is no canonical way to represent papers and reviewers in an $r$ dimensional space, this method highly depends on what embedding we use to translate papers and reviewers into vectors.
% 
Usually, the embedding is determined through neural network structures that use data reported from the reviewer or available from sites on the internet (such as Google Scholar \cite{toronto}).
% 
% 
% 
Despite the remarkable results obtained by those procedures, it is a common belief that evaluating the quality of a review only from the publication records of the reviewer is limiting \cite{toronto}.
% 
Indeed, these models do not consider other factors that are instead related to the effort the reviewer would put in reviewing the paper, such as personal interest, personal conflict, or even time at the disposal.
%
% that the reviewer can dedicate to the reviewing process.
% 
% Although these factors affect the quality of the review, the editors have no access to this information without enquiring the reviewers.
% % 
% The key idea of this paper is to formulate a problem in which the reviewers can actively alter the constraints and the objective function of the classic ILP formulation.
% %  

 % asdas


\section{Bilevel Formulation of the Assignment Problem}
\label{sect:bilevel}





% 
In this section, we first introduce our BP formulation for the peer-reviewing matching problem, followed by studying the LLp and ULp and showing that our model admits a solution under mild conditions.
% 
% We then exploit the LLp's theoretical properties to rewrite the BP model as a single-level formulation.
% 
We then highlight the relationship between our model and the classic literature.
% 
Throughout the paper, we assume that the editor in charge is just one person.
% 



\subsection{Bilevel Programming Model}


% 
Given a set of papers $\mathfrak{P}=[n]$ and a set of reviewers $\mathfrak{R}=[m]$, we define our BP peer-reviewing matching problem as follows. 

% 




\begin{problem}
\label{problem:bilevel}
Given $l_i$, $u_i$ and $U_j$ as in Section \ref{sec:basic_notions}, we consider the following problem:
\begin{eqnarray}
\label{eq:bivel_prob}
\arraycolsep=2pt\def\arraystretch{1.25}
\begin{array}{ll} 
\underset{Z,X\in \mathbb{B}_{nm}}\max &\;\;\; \langle W_E,X\rangle + \langle Y^*,X \rangle\\
\quad \quad {\rm s.t.} &
 \quad l_i \le\sum_{j\in [m]}X_{i,j}\le u_i, \quad \sum_{i\in [n]}X_{i,j}\le U_j,\\
& \quad\sum_{i\in [n]}Z_{i,j}=U_j+\phi_j,\quad X \le E-Z+Y^*, \\
    & \quad Y_j^* \in\underset{ Y_j\in \mathbb{B}_{n}}\argmin \; \langle (W_R)_j,Y_j\rangle, \\
    &\quad \sum_{i\in [n]}Y_{i,j}=U_j, \quad \text{and}\quad 0\le Y_j\le Z_j,
\end{array} 
\end{eqnarray}
where $E$ is a $n \times m$ matrix whose entries are all equal to $1$.
% 
We denote with $W_E$ the $n\times m$ matrix  describing the qualities of all the possible reviews from the editor's point of view, with $W_R$ the $n\times m$ matrix describing the reviewers' efforts, and with $\phi_j\in \mathbb{N}$ the number of papers that the reviewers can refuse to review.
% ,  degrees of freedom that the editor gives to the reviewers.
% 
Finally, since we assume that every reviewer bids independently, the LLp is a component-wise minimization, \textit{i.e.}, $Y^*$ is the matrix whose columns minimize the function $Y_{:,j}\to\langle (W_R)_{:,j},Y_{:,j} \rangle$.
% 
% We denote with $W_E$ the $n\times m$ matrix  describing the qualities of all the possible reviews from the editor's point of view, with $W_R$ the $n\times m$ matrix describing the reviewers' efforts, and with $\phi_j\in \mathbb{N}$ the degrees of freedom that the editor gives to the reviewers.
% 
% Finally, since we assume that every reviewer bids independently, the LLp is a component-wise minimization, i.e., $Y^*$ is the matrix whose columns minimize the quantity $\langle (W_R)_{:,j},Y_{:,j} \rangle$.
% 
\end{problem}

% All variables used in our model are reported 
In Table \ref{tab:variables_and_parameter_2}, we report the variables of our model and their meaning.


\begin{remark}
It is well-known that every BP problem describes a Stackelberg game \cite{von1952theory,luo1996mathematical}, and this is no exception.
% 
In our case, the leader is the editor who proposes $Z$ to the followers, which are the reviewers.
% 
Afterwards, the reviewers report a vector $Y$ according to their preferences.
% 
Every couple $(Z,Y)$ uniquely defines a maximum edge-weighted matching problem, whose objective value corresponds to the payoff of the editor\footnote{If the couple $(Z,Y)$ leads to an unfeasible problem, the payoff is $-\infty$.
% 
The reviewers' payoff is the total effort of the papers they bid for.}.
% 
% 
% 
Notice that the BP formulation we introduced is also equivalent to the following three-phase procedure.
% 
First, the editor proposes a set of papers, described by the vector $Z_j$, to every reviewer $j$.
% 
Second, the reviewers select a set $Y_j$ out of the set $Z_j$. 
% 
The vector $Y_j$ represents the papers that reviewer $j$ would review if asked.
% 
Finally, the editor gathers the replies of all the reviewers and searches for a papers-reviewers allocation that maximizes the quality and matches the reports given by the reviewers as much as possible.
% 
For this reason, given any feasible triplet to problem \eqref{eq:bivel_prob}, namely $(X,Y,Z)$, we refer to $Z$ as the editor's proposal, to $Y$ as the reviewers' bidding, and to $X$ as the final assignment.
% 
A graphical description of this procedure is also given in Figure \ref{fig:figures_bis}.
% 
\end{remark}





% Figure environment removed



% % Figure environment removed





% 
As in the previous model, we assume that the editor aims to maximize the quality of the peer-reviewing matching.
% 
In our case, however, both the objective function and the constraints of the problem depend on the reviewers' biddings, \textit{i.e.}, the solution of the LLp.
% 
The influence that the LLp has on both the objective function and the set of feasible matching of the ULp is the way in which we model the interaction between the reviewers and the editor.
% 
\begin{table}[t]
    
    \begin{center}
    \caption{List of variables and parameters used in our BP model.}
    \label{tab:variables_and_parameter_2}
        \begin{tabular}{ p{0.35cm}|p{7.45cm}}
     \midrule
     $l_i$ & minimal number of reviews needed by paper $i$\\
     $u_i$ & maximal number of reviews needed by paper $i$\\
     $U_j$ & number of papers that reviewer $j$ bids for and maximum number of papers that $j$ may review\\
     $Z_j$ & vector describing the set of papers proposed to reviewer $j$\\
     $Y_j$ & vector describing the set of papers that reviewer $j$ bids for\\
     $Y^*_j$ & vector that minimizes reviewer $j$'s effort\\
     $X$ & final allocation decided by the editor\\
     $\phi_j$ & degree of freedom of reviewer $j$ \\
     $W_E$ & quality matrix from the editor's point of view\\
     $W_R$ & reviewers' effort matrix\\
     
     \midrule
    \end{tabular}
    % \caption{List of variables and parameters used in our BP model.}
    % \label{tab:variables_and_parameter_2}
    \end{center}
     
\end{table}

\begin{remark}[The effort matrix $W_R$ and its role]

To describe the reviewers' point of view, we introduce a matrix $W_R$ that assigns an effort value to every reviewer-paper couple.
% 
% Notice that, for every reviewer, these effort values induce a preference order over the set of papers.
% \footnote{In our setting, the preference order sorts the papers from the one that takes less effort to review to the one that takes the most effort to review.}.
% 
% Since $W_R$ is a key component of the BP formulation, it has to be accessible to the editor.
% 
% {\color{blue}
When the number of papers is small, it is possible to retrieve $W_R$ by directly asking the reviewers.
% 
As an alternative, we can build a proxy version of $W_R$ using machine learning.
% }
% 
Indeed, there are machine learning methods able to find a complete preference order over a set of papers by only having a partial declaration of preferences \cite{toronto}.
% 
In previous models these values were used to enhance the quality matrix $W_E$ by refining the values that are less accurate due to a lack of information about the reviewer.
% 
Instead, in our model, we use the preference order to describe the criterion used by the reviewer during the bidding phase.

\end{remark}





%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%





\subsection{Lower-Level Problem}
\label{subsec:llp}



We now consider the LLp, which captures the reviewers' point of view.
% 
We first describe the objective function and the constraints, and then we show that the LLp has a solution and study its properties.
% 
%{\color{red} The main result is in Theorem \ref{lower-level-problem-primal}, which detects a set of conditions for which the solution of the LLp is unique and the ILP problem is equivalent to the linear programming (LP) problem obtained by relaxing the contraint $Y\in\mathbb{B}_{nm}$.} \xc{It's better to move this part next to Theorem \ref{lower-level-problem-primal}.}
% 


% % Figure environment removed


\subsubsection{Reviewer's Objective Function}

% 
Once the reviewers receive the editor's proposal $Z$, they have to bid for part of the papers proposed and report their bidding to the editor.
% 
In the following, we denote with $Y_{j}$ the $j$-th column of the matrix $Y$, so that $Y_j=Y_{:,j}$.
% 
Similarly, $(W_R)_j$ and $Z_j$ denote the $j$-th column of the matrices $W_R$ and $Z$, respectively.
% 
We model the interests of the reviewers through a linear objective function that evaluates the effort required by every reviewer $j$ to review a set of papers $Y_j$.
% 
In this framework, the bidding criterion adopted by reviewer $j$ is captured by the minimization of the objective function $Y_j\to \langle  (W_R)_j, Y_j\rangle$.
% 
Every entry of the reviewers' effort vector $((W_R)_j)_i$ describes how much effort reviewer $j$ would spend to review paper $i$. 
% 
To make the model meaningful, we assume that each entry of the vector $(W_R)_j$ is positive, which means that reviewing is never effortless.
% 




\subsubsection{Reviewer's Constraints}

% 
Every reviewer $j$ has to comply with two sets of constraints.
% 
Since reviewers are anonymous to each other, we assume that the constraints imposed on one reviewer do not depend on the constraints imposed on other reviewers. 
% 
Thus, we describe the constraints only for a fixed reviewer, namely $j$. 
% 
To impose the indivisibility of the reviews, every $Y_j$ is assumed to have binary entries.
% 
Finally, the set of constraints with which the reviewers have to comply is as follows.
\begin{enumerate*}[label=(\roman*)]
\item The \emph{consistency constraint}, that is $Y_j\le Z_j$, where $Z_j$ is the proposal advanced by the editor; this constraint imposes that every reviewer cannot bid for a paper that does not belong to the pool that the editor proposed.
% 
\item The \emph{quantity constraint}, that is $\sum_{i\in [n]}Y_{i,j}= U_j$; this constraint forces every reviewer to bid for $U_j$ papers.
% 
Since the review effort is always non-negative, imposing the quantity constraint is equivalent to imposing the following constraint $\sum_{i\in [n]}Y_{i,j} \ge U_j$.
\end{enumerate*}



\paragraph{Uniqueness of the Solution and the Equivalence Result.}
% 
To conclude, we study the solution of the LLp.
% 
As we will see, the set of conditions needed to ensure the uniqueness of the solution and the equivalence with the relaxed problem is natural to assume.
% 
 

\begin{lemma}
\label{property} 
Given two integers $0<a<b$, and let $\{w_{k}\}_{k=1,\dots,b}$ be a set of positive and increasingly ordered real values, \textit{i.e.}, $0\leq w_1\leq  \cdots \leq w_a\leq w_{a+1}\leq\cdots\leq w_{b}$. 
% 
If $x_i\in [0,1]$, $\forall i\in[b]$ and $\sum_{i=1}^b x_i=a$, then it holds $\sum_{i=1}^a w_i \leq \sum_{i=1}^b w_i x_i$.
\end{lemma}

% 
We now prove that the ILP problem in the LLp is equivalent to the LP problem obtained by relaxing the constraint $Y_j\in\{0,1\}$.
% over $Y$, \textit{i.e.} the entries of vector $Y_j$ belong to $[0,1]$ rather than being binary.
% 
% We are now ready to prove that every problem in the LLp is equivalent to its relaxed version, hence we can allow the entries of vector $Y_j$ to belong to $[0,1]$ rather than being binary.
% 

\begin{theorem}
\label{lemma-equivelance}
For any given $Z\in\B_{mn}$, the LP problem 
\begin{eqnarray}
\label{lower-level-problem-primal_0}
Y^* \in\underset{0\le Y\le Z}\argmin ~\langle W,Y \rangle,\quad {\rm s.t.} \ \ \sum_{i\in [n]}Y_{i,j}=U_j, 
\end{eqnarray}
and the ILP problem
\begin{equation} 
\label{lower-level-problem-primal}
\widehat Y \in\underset{Y \in \B_{mn}, Y\le Z }{\rm argmin}~\langle  W, Y\rangle,\quad {\rm s.t.} \ \ \sum_{i\in [n]}Y_{i,j}=U_j,
\end{equation}
attain the same optimal value, \textit{i.e.}, $\langle  W, Y^*\rangle=\langle  W, \widehat Y\rangle$. 
% 
Moreover, if $\forall j\in[m]$, the set $\{ W_{i,j}: (i,j) ~\text{s.t.}~ Z_{ij}=1\}$ does not contain two equal values, then the solution is unique and satisfies  $\widehat{Y} \in \B_{mn}$, \textit{i.e.}, Problems \eqref{lower-level-problem-primal_0} and \eqref{lower-level-problem-primal} are equivalent.
\end{theorem}

% 


% 
Notice that the hypothesis of Theorem \ref{lower-level-problem-primal} is satisfied whenever every reviewer has a strict preference order over the set of papers.
% 
Finally, we show that minimizing the component-wise reviewers' effort is the same as minimizing the global reviewers' effort.
% 

\begin{theorem}
    \label{prop:prob_simp}
For every given $Z$, $Y$ is a solution of the LLp if and only if $Y$ minimizes the function $Y\to \sum_{i\in [n]}\sum_{j\in [m]} (W_R)_{i,j}Y_{i,j}$ under the constraints $\sum_{i\in [n]}Y_{i,j}-U_j\ge 0$ and $Z_{i,j}-Y_{i,j}\ge 0$.
% 
\end{theorem}

% \end{thm}
% 



\subsection{Upper-Level Problem}

%
We now consider the ULp, which is the problem that captures the editor's point of view.
% 
We first describe the role of both the objective function and the constraints, and
then we show that the solution to the ULp problem always exists under mild assumptions.
%  



\subsubsection{The Editor's Objective Function}

% 
In our model, the editor needs to find an allocation that maximizes a linear objective function, described by the matrix $W_E$ and the scalar product of the variables $X$ and $Y$.
% 
While $\langle W_E,X \rangle$ represents the quality of matching $X$, the scalar product between $X$ and $Y$ describes how much the final assignment $X$ meets the reviewers' bidding $Y$.
% 
% In particular, the scalar product $\langle X, Y \rangle$ allows the reviewers to sway the editor's objective function by augmenting the weights of the edges the reviewers are interested in.
% 
We, therefore, define the following quantity.
% 

\begin{definition}
\label{def:perfect}
Given a solution $(X,Y,Z)$ to the BP Problem \ref{problem:bilevel}, we define its Accordance Percentage as $AC(X,Y,Z):=\frac{\langle X , Y \rangle}{\langle X , X \rangle}$.
\end{definition}

% 
By definition, we have $AC(X,Y,Z)\in [0,1]$ and $AC(X,Y,Z)=1$ if and only if $X\le Y$, \textit{i.e.} if and only if every reviewer receives only papers they bid for.
% expressed interest in during the bidding phase.
% 
If $AC(X,Y,Z)=1$ holds, we say that the solution $(X,Y,Z)$ is \emph{perfect}.
% 





\subsubsection{The editor's constraints}

% 
In our model, the editor controls two variables, $Z$ and $X$. 
% 
% Both $Z$ and $X$ are $n\times m$ binary matrices subject to two sets of constraints.
% 
Both $Z$ and $X$ are $n\times m$ binary matrices that are subject to two different sets of constraints below.
% 

% 
\paragraph{Constraints over $Z$.} We require the proposal $Z$ to comply with only one set of constraints, which we call \emph{freedom constraint}.
% 
The role of these constraints is to determine the number of papers the editor has to propose to every reviewer.
% 
In mathematical terms, this means that $\sum_{i\in [n]}Z_{i,j}=U_j+\phi_j$, $\forall j\in [m]$, where the constants $\phi_j\ge 0$ are the degrees of freedom.
% 
In fact, since the reviewer $j$ has to bid for $U_j$ papers, the parameter $\phi_j$ corresponds to the number of papers that the reviewer can refuse to review.
% 




\paragraph{Constraints over $X$.} 
The final assignment $X$ has to comply with the  constraints as follows.
% 
\begin{enumerate*}[label=(\roman*)]
\item The \emph{feasibility constraints}, that is, $l_i\le\sum_{j\in [m]}X_{i,j}\le u_i$, $\forall i \in [n]$ and $\sum_{i\in [n]} X_{i,j}\le U_j$, $\forall j \in [m]$.
    % 
    These constraints bound the editor to assign every paper $i$ to a number of reviewers between $l_i$ and $u_i$ and to assign at most $U_j$ reviews to every reviewer $j$.
    % 
    \item The \emph{consistency constraint}, that is $X\le E-Z+ Y^*$, where $Y^*$ is the solution to the LLp and $Z$ is the editor's proposal. 
    % ^^^ optimal solution
    This constraint bounds the editor to assign a paper to a reviewer only if the reviewer has not refused it before.
\end{enumerate*}



\paragraph{The Solutions of the ULp}

% 
In the previous section, we proved that the LLp admits a solution, regardless of what the editor proposes.
% 
As the next example shows, the same does not hold for the ULp.
% 

\begin{example}
\label{ex:fairness}
Let us consider the case in which we have three papers, namely $p_1$, $p_2$, and $p_3$, and two reviewers, namely $r_1$ and $r_2$.
% 
We assume every paper needs exactly one review (\textit{i.e.}, $l_i=u_i=1$) and that every reviewer can be asked to review at most $2$ papers (\textit{i.e.}, $U_j=2$).
% 
Finally, we assume that $W_R$ is defined as $W_R=\begin{pmatrix} 11 & 10 & 1\\3 & 2 & 1\end{pmatrix}$.
% 
Both reviewers have the same preference order over the set of papers, \textit{i.e.}, $p_1>p_2>p_3$.
% 
It is then easy to see that, if $\phi_1,\phi_2>0$, no reviewer will give its consensus to review paper $p_3$, making the ULP, and hence the whole BP problem, unfeasible.
% 
\end{example}

%  
Example \ref{ex:fairness} points out that allowing the reviewers to review or refuse too many papers leads to an unsolvable problem in some pathological cases.
% 
In fact, if we ask the second reviewer to review only one paper, that is $U_2=1$, the BP problem described in Example \ref{ex:fairness} becomes feasible.
% 
In general, the editor can ensure the existence of a solution to Problem \ref{problem:bilevel} by tuning the parameters of the problem.
% 


\begin{theorem}
\label{prop:feasibility}
If, in addition to the assumptions that make Problem \ref{problem:bilevel} feasible, it holds $\max_{j\in [m]}\;\phi_j + 2\max_{j\in [m]} \; U_j\le n$, then there exists a feasible triplet to Problem \ref{eq:bivel_prob}.
% 
In particular, under these assumptions, Problem \ref{eq:bivel_prob} has a solution.
\end{theorem}

% \begin{remark}
% The conditions of Theorem \ref{prop:feasibility} are sufficient but not necessary.
% % 
% Going back to Example \ref{ex:fairness}, if we ask the second reviewer to review only one paper, the problem becomes feasible, but it does not satisfy the hypothesis of Theorem \ref{prop:feasibility}.
% \end{remark}

% 
Notice that whenever the number of papers $n$ is large enough, the hypothesis of Theorem \ref{prop:feasibility} is likely to be satisfied, since both $U_j$ and $\phi_j$ are parameters bounded to the human capacity.
% 
For example, if $n=30$, the conditions will hold even if we require every reviewer to review at most $8$ papers while allowing everyone to reject up to $10$ papers.
% 
Finally, even when the number of papers is small, the editor can decrease $\phi_j$ and $U_j$ in order to make them suitable.
% 



% \subsection{Single-Level Formulation}
% \label{sec:slf}
% % 
% To conclude, we show that it is possible to rephrase the BP problem as a single-level formulation using the Karush-Khun-Trucker (KKT) conditions.
% % 
% Indeed, due to Theorems \ref{lemma-equivelance} and \ref{prop:prob_simp}, the LLp is equivalent to the following LP problem
% \begin{align*}
%     \min_{Y\in[0,1]^{nm}} &\langle W_R, Y \rangle,\quad {\rm s.t.} \ \ \sum_{i\in [n]}Y_{i,j}-U_j\ge 0 \quad \text{and} \quad Z_{i,j}-Y_{i,j}\ge 0.
% \end{align*}
% % 
% Then, from the dual theory, we know that $Y$ is optimal if and only if there exists a vector $\Lambda=(\alpha,\beta,\gamma)$ such that
% \begin{align*}
%     % \label{eq:KKT_cond_LLp}
%     &(W_R)_{i,j}-(\alpha_j+\beta_{i,j}-\gamma_{i,j})=0,\quad\quad \alpha_j,\beta_{i,j},\gamma_{i,j}\ge 0,\\
%      % \label{eq:KKT_cond_primal}
%      &\sum_{i\in [n]}Y_{i,j}-U_j=0, \quad  \quad Z_{i,j}-Y_{i,j}\ge 0,\\
%     % \label{eq:KKT_cond_dual}
%     &\alpha_{j}\Big(\sum_{i\in [n]}Y_{i,j}-U_j\Big)=0, \quad \beta_{i,j}Y_{i,j}=0, \quad \text{and} \quad \gamma_{i,j}(Z_{i,j}-Y_{i,j})= 0.
% \end{align*}
% Hence the first $m$ components of vector $\Lambda$ are the dual variables $\alpha_j$ associated with the constraint $\sum_{i\in [m]}Y_{i,j}=U_j$, while $\beta_{i,j}$ and $\gamma_{i,j}$ are the variables associated with the constraints $Y_{i,j}\ge 0$ and $Z_{i,j}-Y_{i,j}\ge 0$, respectively.
% % 
% Hence, by adding $m(2n+1)$ variables, we can rewrite Problem \ref{problem:bilevel} as follows.
% % 
% \begin{thm}
% \label{prop:single_level}
% The BP problem \eqref{eq:bivel_prob} is equivalent to the following Single-Level problem, i.e.,
% \begin{align}
% \label{eq:single_level}
%      \max &\;\;\langle W_E,X \rangle\; +\; \langle X,Y \rangle   \\
%     \quad  \nonumber {\rm s.t. }& \quad l_i \le\sum_{j\in [m]}X_{i,j}\le u_i, \quad \sum_{i\in [n]}X_{i,j}\le U_j, \quad \sum_{i\in [n]}Z_{i,j}=U_j+\phi_j,\\
%     \nonumber& \quad X+Z-Y \le E, \quad 0\le Y\le Z, \quad \sum_{i\in [n]}Y_{i,j}=U_j,\quad X,Z\in \mathbb{B}_{nm}\\
%     \nonumber& \quad (W_R)_{i,j}-(\alpha_j+\beta_{i,j}-\gamma_{i,j})=0,\quad\quad \alpha_j,\beta_{i,j},\gamma_{i,j}\ge 0,\\
%     \nonumber & \quad  \alpha_{j}\Big(\sum_{i\in [n]}Y_{i,j}-U_j\Big)=0, \quad \beta_{i,j}Y_{i,j}=0, \quad \gamma_{i,j}(Z_{i,j}-Y_{i,j})= 0.
% \end{align}
% \end{thm}







% \subsection{A Special Case of the BP Formulation: the Classic ILP Model}

% 
% We now show that our model extends the classic ILP formulation described in Problem \ref{pr:classic}.
% % 
% In particular, whenever we set $\phi_j=0$, $\forall j\in [m]$, the solution of the LLp is actually determined by the editor.
% % 
% This allows us to find a bijection between the solutions of the classic ILP model and the solutions of our BP model.
% % 


% \begin{proposition}
% \label{prop:dict}
% Set $\phi_j=0$, $\forall j\in [m]$.
% % 
% Then, given a solution $(X,Y,Z)$ of the BP problem, we have that $X$ solves Problem \ref{pr:classic}.
% % 
% Vice-versa, if $X$ is a solution to Problem \ref{pr:classic}, then all the triplets $(X,Y,Z)$ such that $X\subset Y=Z$ are perfect solutions to the BP problem. 
% \end{proposition}

% 
% Up to now, we have assumed that the objective of the ULp was linear in $X$.
% %
% However, it is worthy of notice that all the results are trivially extendable when the objective function is concave or convex.
% % 
% Indeed, in several alternative versions of Problem \ref{pr:classic}, the objective function is assumed to be a combination of the linear quality operator and a convex penalizer, namely $C$.
% % 
% In this framework, the quantity the editor has to maximize is $\langle W,X  \rangle -\lambda C(X)$.
% % 
% If we use this objective function in our ULp rather than the classic linear one, the BP formulation retains all the properties that we proved so far.
% % 
% Moreover, if we set $\phi_j=0$, $\forall j\in [m]$, the BP formulation enhanced with the convex function $C$ is equivalent to its correspondent ILP model. 
% % 
% In Appendix B, we delve into this class of problems and the related secondary variational problem (SVp).
% % 
% Moreover, we study the diversity function proposed in \cite{DBLP:conf/ijcai/AhmedDF17} and correct their original definition and relate it to an SVp induced by the entropy function.
% 



\subsection{Fairness and the relation with the ILP model}

% 
In Example \ref{ex:fairness}, we showed that when the reviewers share the same preference order over the set of papers, finding a solution to the BP formulation might be impossible. 
% 
In the following, we show that this phenomenon is also due to an intrinsic fairness property that perfect solutions to the BP problem possess.
% 



\begin{definition}
Let $X$ be a matching over the bipartite graph $G$ and let $W_R$ be the reviewers' effort matrix.
% 
Given a vector $\Phi:=(\phi_1,\dots,\phi_m)\in\mathbb{N}^{m}$, we say that $X$ is $\Phi$-weakly fair if, $\forall j\in [m]$, the set $BC_j(X):=\big\{i\in [n], \ \text{s.t.} \ X_{i,j}=0 \ \& \ (W_R)_{i,j} \ge \min_{ X_{i,j}=1}(W_R)_{i,j})\big\}$, contains at least $\phi_j$ elements.
\end{definition}

% 
Notice that the set $BC_j(X)$ contains all the papers in $[n]$ that require more effort than the highest effort-requiring paper assigned to $j$ according to $X$. 
% 
Therefore, a solution is $\Phi$-weakly fair if every reviewer $j$ is not allocated with its $\phi_j$ worst picks.
% 
Using the notion of a perfect solution, we are able to relate $\Phi$-weakly fair solutions of the classic ILP model to the perfect solutions of the BP model.
% 

\begin{proposition}
\label{prop:dots}
There exists a perfect solution $(X,Y,Z)$ that maximizes the quality if and only if the ILP problem admits a $\Phi$-weakly fair solution.
\end{proposition}
% 

To conclude, we show that our model extends the classic ILP formulation described in Problem \ref{pr:classic}.
% 
In particular, whenever we set $\phi_j=0$, $\forall j\in [m]$, the solution of the LLp is actually determined by the editor.
% 
This allows us to find a bijection between the solutions of the classic ILP model and the solutions of our BP model.
% 


\begin{proposition}
\label{prop:dict}
Set $\phi_j=0$, $\forall j\in [m]$.
% 
Then, given a solution $(X,Y,Z)$ of the BP problem, we have that $X$ solves Problem \ref{pr:classic}.
% 
Vice-versa, if $X$ is a solution to Problem \ref{pr:classic}, then all the triplets $(X,Y,Z)$ such that $X\subset Y=Z$ are perfect solutions to the BP problem. 
\end{proposition}

% {\color{blue}
In Appendix B, we delve further into the relationships between our BP model and previous models. 
% 
In particular, we focus on the class of diverse matching proposed in \cite{DBLP:conf/aaai/DickersonSSX19}, show how this specific model is related to a Secondary Variational Problem induced by Problem \ref{pr:classic}, and adapt it to our BP model.
% }
% 


\section{Numerical Experiments}
\label{sec:num_exp}


% 
In this section, we report the results of our numerical experiments.
% 
We first introduce the heuristic we use to solve the model.
% 
We then describe the experimental setting, the implementation details, and introduce the metrics used to compare the outcomes of our experiments.
%
Finally, we comment on the results we find.
% 
% All the codes are available at \url{https://github.com/Galaxy-ZRX/Bilevel-Review}.


\subsection{Greedy Heuristic}

% Due to the complexity of the BP problem described in \eqref{eq:bivel_prob}, approaching the problem through Bilevel solvers is impossible.
% 
Due to the complexity of the BP model described in Problem \ref{problem:bilevel}, approaching the problem through Bilevel solvers is prohibitive.
% 
% Moreover, using the single-level formulation proposed in Section \ref{sec:slf} is not practical due to a large number of variables and constraints the model needs.
% 
For this reason, we propose a greedy heuristic that finds a solution by fixing the editor's proposal $Z$.
% 
Indeed, once we fix $Z$, retrieving the reviewers' best response is simple since it is the minimum of $m$ independent LP problems.
% 
Once we retrieve the best reply $Y_Z$, we obtain the final allocation by solving the maximum edge-weighted matching problem induced by $Z$ and $Y$.
% 
For every $Z$ and $Y$, we denote the related final allocation with $X_{Z,Y}$.
% 
Given a quality matrix $W_E$, we define the greedy proposal $Z_g$ as the solution to the following ILP problem
\begin{align*}
    Z_g = & \ \underset{Z\in \mathbf{B}_{nm}}{\argmax}\;\langle W_E,Z  \rangle,\quad\sum_{i\in [n]}Z_{i,j}=U_j+\phi_j,\quad\forall j \in [m].
\end{align*}
% 
In particular, the greedy proposal $Z_g$ is the editor's proposal that maximizes the total quality of the papers proposed.
% 
Following the previous notation, we define the greedy heuristic solution to Problem \ref{problem:bilevel} as $(X_g,Y_g,Z_g):=(X_{Z_g,Y_{Z_g}},Y_{Z_g},Z_g)$.
% 
We notice that to build our heuristic solution, we need to solve at most three ILP problems. 
% 
Therefore, complexity-wise, our approach is as costly as any method based on the resolution of an ILP problem. Moreover,
% 
when the set of reviewers is large and heterogeneous enough, the greedy heuristic always finds a feasible peer review matching.
% 

\begin{theorem}
    \label{thm:feas_cond}
    The greedy heuristic always finds a feasible peer review matching if, for every paper $i \in [n]$, there are at least $L=\sum_{i\in [n]}l_i$ reviewers that do not place $i$ among its top $K:=(\max_{j\in [m]}\phi_j+\max_{j\in [m]}U_j)$ picks.
    % If there are at least $(\max_{j\in [m]} \phi_j)! + (\max_{j\in [m]}\phi_j)(\max_{i\in [n]} l_i)$ reviewers with different preference orders over the set of papers, then the greedy heuristic always find a feasible peer review matching.
\end{theorem}



Finally, we show that if the accordance percentage of the heuristic solution is equal to $1$, then the quality of the matching $X_g$ lower bounds the quality of the optimal solution to the BP problem.
% 


\begin{theorem}
\label{them:heur_estimate}
Let $(X_g,Y_g,Z_g)$ be the triplet found by the greedy heuristic.
% 
If $AC(X_g,Y_g,Z_g)=1$, then, for every optimal solution $(X^*,Y^*,Z^*)$ to the BP problem, we have  $\langle W_E, X_g\rangle\le \langle W_E, X^*\rangle$.
\end{theorem}




\subsection{Experimental Framework}
\label{subsect:exp}
% \input{AAMAS_section/result_table}

% 
We now detail the dataset, the parameters, and the solver we used during the implementation of our experiments.
% 

{\bf Dataset.} We use the multi-aspect review assignment evaluation dataset \cite{karimzadehgan2008multi,karimzadehgan2009constrained}, which is a classic benchmark dataset from UIUC.
% 
The dataset contains the information of $73$ papers accepted by SIGIR $2007$, as well as $189$ prospective reviewers who had published in the main information retrieval conferences. 
% 
Moreover, the dataset provides $25$ major topics and, for each paper in the set, it provides a $25$-dimensional label on that paper based on a set of defined topics. 
% 
Similarly, for each of the $189$ reviewers, a $25$-dimensional expertise representation is provided.
% 
% {\color{blue}{We focus on this dataset because it is relatively small and, according to Theorem \ref{prop:feasibility}, our model struggles the most when the number of papers is small.}}
% 
To the best of our knowledge, there is no available dataset from where we could retrieve the effort matrices needed for our tests.
% 
For this reason, we rely on two synthetically generated datasets as follows. 
%
\begin{enumerate*}[label=(\roman*)]
% 
\item The \textit{Aligned dataset}, in which there is a linear dependence between $W_R$ and $W_E$. We assume that $(W_R)_{i,j}=K-\big((W_E)_{i,j}+\chi)$, where $K$ is a constant ensuring $(W_R)_{i,j}>0$ and $\chi\sim \mathcal{N}(0,\sigma)$. 
% 
In this case, maximizing the quality of the assignment and minimizing the total reviewers' effort have the same objective function up to a Gaussian noise $\chi$, which describes the personal preferences the reviewers may have over papers from the same area.
% 
\item The \textit{Random dataset}, in which every entry of $W_R$ is defined as $(W_R)_{i,j}=\chi$, where $\chi$ is a random variable. 
% 
In our test, we consider two possible laws for $\chi$: the Uniform distribution $\mathcal{U}[0,1]$ and the Exponential distribution $Exp(0.5)$.
% 
% Notice that in both cases, $\chi$ is always greater than $0$ and that the average is equal to $0.5$.
% 
In this scenario, the effort needed by any reviewer does not depend on the paper, but rather on external factors not related to the expected quality of the review, such as time at disposal and conflict of interest.
% 
% \item The \textit{Mixed Random dataset}, in which we assume that part of the reviewers' effort vectors depends on the quality vector as for the Aligned dataset, while the other reviewers have their effort vectors determined by a random variable, as for the Random dataset.
% % 
% To partition the set of reviewers, we introduce a parameter $q\in [0,1]$ describing the probability that a reviewer belongs to the random part of the reviewers.
% % 
% When $q=0$, we retrieve the Aligned dataset, while when $q=1$, we retrieve the Random dataset.
% % 
% For the sake of simplicity, the efforts of the random reviewers are sampled only from the uniform distribution $\mathcal{U}[0,1]$.
% 
\end{enumerate*}
% 


\begin{table*}[ht!]
\begin{center}
% \vspace{0em}
% \small
% \resizebox{\textwidth}{!}{
%\begin{tabular}{V{4}  @{}c@{} V{4} @{}c@{}|@{}c@{}|@{}c@{}|@{}c@{}|@{}c@{}|@{}c@{}|@{}c@{} | @{}c@{}|@{}c@{} V{4} @{}c@{}|@{}c@{}|@{}c@{}|@{}c@{}|@{}c@{}|@{}c@{}  V{4} @{}c@{}|@{}c@{}|@{}c@{} | @{}c@{} |@{}c@{} |@{}c@{} V{4}}

% \resizebox{\textwidth}{!}{
\caption[Experiments]{Comparison between $X_{BP}$ and $X_{ILP}$. Quantitative results for different values of $\phi$ and differently generated effort matrices. 
% 
Every column represents a different framework and is characterized by the effort matrix, the random variable used to generate the matrices, and the degree of freedom.
% 
For each framework, we report the averages over $250$ instances of the Quality Percentage, the Reviewers' Average Effort Ratio, the Fairness Ratio, and the Accordance Percentage of the heuristic solution.
% , and the ratio between the number of active reviewers in the ILP solution and the number of active reviewers in the BP solution $p_{act}$.
% 
}

\begin{tabular}{  c | @{}c@{}|@{}c@{} | @{}c@{}|@{}c@{} | @{}c@{}|@{}c@{}|@{}c@{}|@{}c@{}|@{}c@{}|@{}c@{} |@{}c@{} | @{}c@{} }
  \hline
  & \multicolumn{6}{c |}{Aligned } & \multicolumn{6}{ c }{Random } \\
  \cline{2-13}
  U=8 & 
  % \multicolumn{2}{c|}{$\sigma=0.1$} & 
  \multicolumn{3}{c|}{$\sigma=0.1$} & \multicolumn{3}{c |}{$\sigma=0.3$} & \multicolumn{3}{c|}{$X\sim \mathcal{U}[0,1]$}  & \multicolumn{3}{c }{$X\sim Exp(0.5)$} \\
  %\Cline{1pt}{2-22}
  \cline{2-13}
  % & $\;\;\phi=4\;\;$ & 
  % $\;\;\phi=6\;\;$ & 
  % $\;\;\phi=8\;\;$ & 
  & $\;\;\phi=4\;\;$ & 
  % $\;\;\phi=6\;\;$ & 
  $\;\;\phi=6\;\;$ & $\;\;\phi=8\;\;$ & 
  % $\;\;\phi=6\;\;$ &  
  $\;\;\phi=4\;\;$ & $\;\;\phi=6\;\;$ & 
  % $\;\;\phi=6\;\;$ &
  $\;\;\phi=8\;\;$ & $\;\;\phi=4\;\;$ & 
  % $\;\;\phi=6\;\;$ &
  $\;\;\phi=6\;\;$ & $\;\;\phi=8\;\;$ & 
  % $\;\;\phi=6\;\;$ & 
  $\;\;\phi=4\;\;$ & $\;\;\phi=6\;\;$ & 
  % $\;\;\phi=6\;\;$ & 
  $\;\;\phi=8\;\;$ \\
  \hline
  $QP(X_{BP})$ & 0.99 & 0.99 & 0.99 & 0.98 & 0.98 & 0.97 & 0.96 & 0.95 & 0.93 & 0.97 & 0.96 & 0.94\\
  %\hline
  $RAER(X_{BP},X_{ILP})$ & 0.89 & 0.89 & 0.86 & 0.87 & 0.87 & 0.80 & 0.63 & 0.53 & 0.47 &  0.45 & 0.35 & 0.30   \\
  %\hline
  $FR(X_{BP},X_{ILP})$ & 0.65 & 0.75 & 0.57 & 0.61 & 0.61 & 0.48 & 0.35 & 0.24 & 0.19  & 0.16 & 0.09 & 0.07   \\
  %\hline
  $AC$ & 0.99 & 0.99 & 0.99 & 0.99 & 0.99 & 0.99 & 0.99 & 0.99 & 0.99 & 0.99 & 0.99 & 0.99 \\
  %\hline
  % $p_{act}$ & 0.93 & 0.93 & 0.91 & 0.92 & 0.91 & 0.89 & 0.91 & 0.90 & 0.88 & 0.91 & 0.90 & 0.88  \\
  \hline
 
\end{tabular}
% }
% \caption[Experiments]{Comparison between $X_{BP}$ and $X_{ILP}$. Quantitative results for different values of $\phi$ and differently generated effort matrices. 
% % 
% Every column represents a different framework and is characterized by the effort matrix, the random variable used to generate the matrices, and the degree of freedom.
% % 
% For each framework, we report the averages over $250$ instances of the $QP$ (Quality Percentage), $RAER$ (Reviewers' Average Effort Ratio), $FR$ (Fairness Ratio), and the $AC$ (Accordance Percentage) of the heuristic solution.
% % , and the ratio between the number of active reviewers in the ILP solution and the number of active reviewers in the BP solution $p_{act}$.
% % 
% }
\label{tab:downsample_tr}
\end{center}
\end{table*}


\begin{table*}[ht!]
\begin{center}
\caption[Experiments]{Comparison between $X_{BP}$ and $X^{(t)}_{ILP}$. Quantitative results for different values of $\phi$ and differently generated effort matrices. 
% 
Every column represents a different framework and is characterized by the effort matrix, the random variable used to generate the matrices, and the degree of freedom.
% 
% 
For each framework, we report the averages over $250$ instances of the Quality Percentage, the Reviewers' Average Effort Ratio, and the Fairness Ratio.
% 
% We recall that the quality percentage is computed with respect to the maximum achievable quality, i.e. the one achieved by $X_{ILP}$.
% % 
% The $RAER$ and the $FR$ are instead computed by comparing $X_{BP}$ and $X^{(t)}_{ILP}$.
% % 
}
% \vspace{0em}
% \small
% \resizebox{\textwidth}{!}{
%\begin{tabular}{V{4}  @{}c@{} V{4} @{}c@{}|@{}c@{}|@{}c@{}|@{}c@{}|@{}c@{}|@{}c@{}|@{}c@{} | @{}c@{}|@{}c@{} V{4} @{}c@{}|@{}c@{}|@{}c@{}|@{}c@{}|@{}c@{}|@{}c@{}  V{4} @{}c@{}|@{}c@{}|@{}c@{} | @{}c@{} |@{}c@{} |@{}c@{} V{4}}

% \resizebox{\textwidth}{!}{

\begin{tabular}{  @{}c | c | @{}c@{}|@{}c@{} | @{}c@{}|@{}c@{} | @{}c@{}|@{}c@{}|@{}c@{}|@{}c@{}|@{}c@{}|@{}c@{} |@{}c@{} | @{}c@{} }
  \hline
   \multicolumn{2}{c |}{ } &  \multicolumn{6}{c |}{Aligned } & \multicolumn{6}{ c }{Random } \\
  \cline{3-14}
  \multicolumn{2}{c |}{ U=8 } & 
  % \multicolumn{2}{c|}{$\sigma=0.1$} & 
  \multicolumn{3}{c|}{$\sigma=0.1$} & \multicolumn{3}{c |}{$\sigma=0.3$} & \multicolumn{3}{c|}{$X\sim \mathcal{U}[0,1]$}  & \multicolumn{3}{c }{$X\sim Exp(0.5)$} \\
  %\Cline{1pt}{2-22}
  \cline{3-14}
  % & $\;\;\phi=4\;\;$ & 
  % $\;\;\phi=6\;\;$ & 
  % $\;\;\phi=8\;\;$ & 
  \multicolumn{2}{c |}{} & $\;\;\phi=4\;\;$ & 
  % $\;\;\phi=6\;\;$ & 
  $\;\;\phi=6\;\;$ & $\;\;\phi=8\;\;$ & 
  % $\;\;\phi=6\;\;$ &  
  $\;\;\phi=4\;\;$ & $\;\;\phi=6\;\;$ & 
  % $\;\;\phi=6\;\;$ &
  $\;\;\phi=8\;\;$ & $\;\;\phi=4\;\;$ & 
  % $\;\;\phi=6\;\;$ &
  $\;\;\phi=6\;\;$ & $\;\;\phi=8\;\;$ & 
  % $\;\;\phi=6\;\;$ & 
  $\;\;\phi=4\;\;$ & $\;\;\phi=6\;\;$ & 
  % $\;\;\phi=6\;\;$ & 
  $\;\;\phi=8\;\;$ \\
  \hline
  \parbox[t]{2mm}{\multirow{3}{*}{\rotatebox[origin=c]{90}{$t=0.05$}}}& $QP(X_{ILP}^{(t)})$ & 0.99 & 0.99 & 0.99 & 0.99 & 0.99 & 0.99 & 0.99 & 0.99 & 0.99 & 0.99 & 0.99 & 0.99\\
  %\hline
  & $RAER(X_{BP},X_{ILP}^{(t)})$ & 0.96 & 0.95 & 0.95 & 0.93 & 0.91 & 0.89 &  0.72 & 0.60 & 0.53 & 0.59 & 0.47 & 0.39 \\
  %\hline
  & $FR(X_{BP},X_{ILP}^{(t)})$ & 0.77 & 0.77 & 0.76 & 0.70 & 0.65 & 0.62  & 0.43 & 0.29  & 0.23  & 0.26 & 0.16 & 0.11 \\
  %\hline
  % & $AC$ & 0.99 & 0.99 & 0.99 & 0.99 & 0.99 & 0.99 & 0.99 & 0.99 & 0.99 & 0.99 & 0.99 & 0.99 \\
  % %\hline
  % & $p_{act}$ & 0.93 & 0.91 & 0.92 & 0.89 & 0.91 & 0.88 & 0.91 & 0.88 & 0.93 & 0.91 & 0.92 & 0.91 \\
  \hline
  \parbox[t]{2mm}{\multirow{3}{*}{\rotatebox[origin=c]{90}{$t=0.1$}}}& $QP(X_{ILP}^{(t)})$ & 0.99 & 0.99 & 0.99 & 0.99 & 0.99 & 0.99 & 0.99 & 0.99 & 0.99 & 0.99 & 0.98 & 0.98\\
  %\hline
  & $RAER(X_{BP},X_{ILP}^{(t)})$ & 0.95 & 0.95 & 0.95 & 0.95 & 0.93 & 0.91 &  0.78 & 0.66  & 0.58 & 0.71 & 0.57 & 0.47 \\
  %\hline
  & $FR(X_{BP},X_{ILP}^{(t)})$ & 0.78 & 0.77 & 0.77 & 0.72 & 0.66 & 0.63  & 0.47 & 0.33  & 0.25  & 0.37 & 0.22 & 0.15 \\
  \hline
  \parbox[t]{2mm}{\multirow{3}{*}{\rotatebox[origin=c]{90}{$t=0.15$}}}& $QP(X_{ILP}^{(t)})$ & 0.99 & 0.99 & 0.99 & 0.99 & 0.99 & 0.99 & 0.98 & 0.98 & 0.98 & 0.98 & 0.97 & 0.97\\
  %\hline
  & $RAER(X_{BP},X_{ILP}^{(t)})$ & 0.96 & 0.95 & 0.95 & 0.96 & 0.95 & 0.92 &  0.88 & 0.75  & 0.66 & 0.86 & 0.68 & 0.57 \\
  %\hline
  & $FR(X_{BP},X_{ILP}^{(t)})$ & 0.79 & 0.77 & 0.77 & 0.74 & 0.69 & 0.65  & 0.55 & 0.38  & 0.30  & 0.53 & 0.32 & 0.22 \\
  \hline
\end{tabular}
% }
% \caption[Experiments]{Comparison between $X_{BP}$ and $X^{(t)}_{ILP}$. Quantitative results for different values of $\phi$ and differently generated effort matrices. 
% % 
% Every column represents a different framework and is characterized by the effort matrix, the random variable used to generate the matrices, and the degree of freedom.
% % 
% % 
% For each framework, we report the averages over $250$ instances of the $QP$ (Quality Percentage), the $RAER$ (Reviewers' Average Effort Ratio),  and the $FR$ (Fairness Ratio).
% % 
% % We recall that the quality percentage is computed with respect to the maximum achievable quality, i.e. the one achieved by $X_{ILP}$.
% % % 
% % The $RAER$ and the $FR$ are instead computed by comparing $X_{BP}$ and $X^{(t)}_{ILP}$.
% % % 
% }
\label{tab:downsample}
\end{center}
\end{table*}


{\bf Experiment Setting.} 
% 
% {\color{blue}
For every instance in our synthetic dataset, we use different methods to retrieve feasible peer-reviewer matchings.
% 
In particular, we consider:
% 
\begin{enumerate*}[label=(\roman*)]
% 
\item The matching obtained by solving the ILP problem described in Problem \ref{pr:classic}.
% 
We call this solution \textit{Pure-Quality solution} and denote it with $X_{ILP}$.
% 
\item The matching obtained by the greedy heuristic we presented above. We denote this matching with $X_{BP}$.
% 
\item The matching obtained by considering an ILP problem whose objective function tries to maximize the Quality and minimize the Reviewers' Effort at the same time. 
% 
Given $t$, we say that $X$ is a \textit{$t$-tuned solution} if it maximizes $\langle (1-t)W_E+t(-W_R),X \rangle$ under the constraints $l_i \le \sum_{j\in [m]}X_{i,j} \le u_i$ and $\sum_{i\in [n]} X_{i,j}\le U_j$.\footnote{We take $-W_R$ instead of $W_R$ because the LLp is a minimization problem.}
% 
We use $X_{ILP}^{(t)}$ to denote the $t$-tuned solution.
% 
% In our experiments, we consider $t=0.05,0.1,0.15$.
% 
% where we took $-W_R$ because we want to minimize $\langle W_R,X \rangle$. 
% 
% We denote with $X^{(t)}_{ILP}$ the solution to \eqref{eq:tuned_ILP}.
\end{enumerate*}
% }



% 
Finally, we fix the parameters we use in our simulations.
% 
% For all our tests and both the implementation of the ILP model and the BP model,
We set the values $u_i$ and $l_i$ respectively to be $3$ and $5$, $\forall i\in [n]$.
% 
We assume $U_j$ does not depend on $j\in [m]$ and let $U_j$ range in $\{6, 8\}$.
% 
Similarly, we assume $\phi_j$ does not depend on $j\in [m]$ and let its value vary in a set that depends on the value of $U_j$.
% 
We assume the degree of freedom to be proportional to the value $U_j$.
% 
In particular, we consider $\phi_j$ equals to the $50\%$, the $75\%$, and the $100\%$ of $U_j$, and thus, for $U_j=8$, we have $\phi\in\{4, 6, 8\}$.
% 
In the Aligned case, we let the variance of the Gaussian noise, namely $\sigma$, vary in the set $\{0.1,0.3\}$, since we want $X$ to be only a small influence.
% 
Due to the fact that the main goal of the editor is to retrieve high quality solutions and since there does not exist a unique best parameter $t$ to retrieve the $t$-tuned solutions, we let $t$ range in $\{0.05,0.1,0.15\}$.
% 
In that regard, it is worth noticing that the best parameter $t$ might change depending on the dimensions of the problem or on the reviewers' characteristics.
% 
% 
% 
Finally, since all the effort matrices are randomly generated, we run the experiment $250$ times for every set of parameters and report the average of our results.
% 
Due to space limits, we report only the results for the case of $U_j=8$.
% 
All the missing results are deferred in Appendix C.
% 

{\bf Implementation Details.} Our experiments are conducted in the Red Hat Linux Server with Intel Xeon Gold 6138 CPUs.
% 
We use Julia \cite{Julia-2017} as the main coding language and solve the ILP problems by using the JuMP package and HiGHS as an optimization solver \cite{DunningHuchetteLubin2017}.
% 


\subsection{Comparison Metrics}
% 
The metrics we use to evaluate our results are the \textit{Quality Percentage ($QP$)}, the \textit{Reviewers'Average Effort Ratio ($RAER$)}, and the \textit{Fairness Ratio ($FR$)}, which we detail in the following.
% 

% 
{\bf Quality Percentage.}
% 
Given a peer-reviewing allocation $X$ and a quality matrix $W_E$, we define the quality of $X$ as $\QQ(X):=\langle W_E,X \rangle$.
% 
Given a solution $X_{ILP}$ of the ILP problem and a matching $X$ found, we define the $QP$ as $QP(X):=\frac{\QQ(X)}{\QQ(X_{ILP})}$.
% 
Since $X_{ILP}$ does maximize the quality over the set of feasible matchings, we have that $QP(X)\in [0,1]$ for every feasible matching.
% 
% Notice that, for any given pair of editor's proposal $Z$ and reviewers' bidding $Y$, the set of feasible $X$ of the ULp is included in the feasible set of Problem \ref{pr:classic}, hence $\QQ(X_{BP})\le\QQ(X_{ILP})$.
% 
% As a straightforward consequence, we infer that $QP(X_{BP})\in [0,1]$.
%

% 
{\bf Reviewers' Average Effort Ratio.}
Given a peer-reviewing allocation $X$ and an effort matrix $W_R$, we define the effort required to reviewer $j$ from $X$ as $\rho_j(X):=\langle (W_R)_{:,j}, X_{:,j} \rangle$ and say that $j$ is \textit{active} if $\rho_j(X)>0$.
% 
We define the total reviewers' effort required by $X$ as $\EE(X):=\langle W_R,X \rangle=\sum_{j\in [m]}\rho_j(X)$.
% 
Finally, we define the average effort required by the active reviewers as $\EE_{avg}(X):=\frac{\EE(X)}{n_{act}(X)}$, where $n_{act}(X)$ is the number of active reviewers according to $X$.
% 
Given two peer-reviewers allocations $X$ and $X'$, we define the Reviewers' Average Effort Ratio as $RAER(X,X')=\frac{\EE_{avg}(X)}{\EE_{avg}(X')}$.
% % 
% Through the value $RAER$ we are able to compare the average effort required by the active reviewers from two different allocations.
% 
% Given a solution $X_{ILP}$ of the ILP problem and a final matching $X_{BP}$ found by the BP problem, we define $RAER(X_{BP},X_{ILP})=\frac{\EE_{avg}(X_{BP})}{\EE_{avg}(X_{ILP})}$.
% % 
% Through the value $RAER$ we are able to compare the average effort required by the active reviewers from the allocations $X_{ILP}$ and $X_{BP}$.
% 

% 
{\bf Fairness Ratio.} Given an allocation matrix $X$, let $\rho$ be the $n_{act}(X)$-dimensional vector containing the efforts of all the active reviewers.
% 
To measure how fairly spread the effort induced by $X$ is, we use the variance of vector $\rho$, denoted as $\theta(X)$ \cite{jain1984quantitative}.
% 
Given two peer-reviewers allocations $X$ and $Y$, we define the Fair Ratio between $X$ and $X'$ as $FR(X,X')=\frac{\theta(X)}{\theta(X')}$.
% $X_{ILP}$ and $X_{BP}$, respectively, we 
% define the $FR$ as 
% set $FR(X,X_{ILP})=\frac{\theta(X)}{\theta(X_{ILP})}$.
% 









\subsection{Results}

% 
In this section, we compare the performance of the three matchings described in Section \ref{subsect:exp}.
% 
First, we comment how $X_{BP}$ compares with $X_{ILP}$ and then compare $X_{BP}$ with $X^{(t)}_{ILP}$.
% 



% 
{\bf The Pure-Quality Solutions Against the Greedy Heuristic.}
% 
We first comment on the {Aligned case}.
% 
Notice that, in the Aligned case, maximizing the quality and minimizing the effort are similar tasks, thus this represents the best scenario for the ILP model.
% 
% This represents the best scenario for the ILP model since the reviewers are more inclined to review papers that the editor wants to allocate them.
% 
Nonetheless, we observe that our model is able to find solutions whose $QP$ is consistently larger than $95\%$, such that
\begin{enumerate*}[label=(\roman*)]
\item the $RAER$ is $10\%$ to $20\%$ lower and
\item the total effort is more evenly spread. 
\end{enumerate*}
Indeed, we observe that the $FR$ ranges from $76\%$ to $48\%$, so that the variance obtained by the ILP model is $1.3$ times the variance obtained by our model in the best case and more than double in the worst case.
% 
We, therefore, conclude that the personal effort required from every reviewer according to the solution of the BP model is lower on average, spread amongst more reviewers, and, overall, more fairly distributed.
% and less volatile.
% 
% It is also worthy of notice that the average number of reviewers involved in our model is higher than the one involved in the classic ILP model, which makes the variance results more solid.
% 


We now comment on the {Random case}, \textit{i.e.} the case in which there is no guaranteed relationship between the quality of a matching and the effort of the agents.
% 
% We run the experiment for two different probability distributions: the uniform distribution $\mathcal{U}[0,1]$ and the exponential distribution $Exp(0.5)$.
% 
For both the uniform and exponential distribution, we observe that the $QP$ slightly drops between from $94\%$ to $90\%$.
% 
However, the quality drop comes with a larger drop in the $RAER$ and an even larger drop in the $FR$.
% 
Indeed, the allocation found by our heuristic halves the effort required by every reviewer in most cases, and in some instances, it achieves almost a third of the effort required by the ILP solution.
% 
Similarly, the $FR$ drops between $0.35$ and $0.07$ hence the variance of the heuristic solution is up to $15$ times lower than the one found by the classic ILP model.
% 
All the results of our experiments are reported in Table \ref{tab:downsample_tr}. 

% In the {Mixed Random case}, we observe that the $QP$, $RAER$ and $FR$ are in between the ones obtained in the other two cases.
% % 
% Moreover, we notice that the $QP$ decreases as the number of reviewers whose effort vector is determined at random increases. 
% % 
% This effect is confirmed by the additional results  in Appendix C.
% 

{\bf The $t$-tuned Solutions Against the Greedy Heuristic.}
% 
Finally, we compare our heuristic to the $t$-tuned solutions for $t = 0.05,0.1,0.15$.
% 
As we observe from the results, taking a convex combination of the effort matrix and the quality matrix leads to solutions that better balance the quality and the effort. % required to the reviewers.
% 
This is clear when we look at the performance on the aligned dataset: in this case, the $QP$ of both $X_{BP}$ and $X^{(t)}_{ILP}$ are comparable for every $t$.
% 
Similarly, the $RAER$ between $X_{BP}$ and $X_{ILP}^{(t)}$, ranges between $90\%$ and $95\%$, hence the $X_{BP}$ still requires less effort to the reviewers, but only marginally.
% 
The real difference between the two solutions can be appreciated when look at their $FR$.
% 
Indeed, our heuristic is capable of finding a matching that spreads the effort in a more fair way amongst the reviewers.
% 
It is again worth stressing, that the aligned case represents the best set of conditions for any ILP model, since maximizing the quality and minimizing the effort do coincide in this specific framework.
% 
This consideration is confirmed by the results we get for the Random dataset.
% 
In this case, the performances of $X^{(t)}_{ILP}$ is more in line with the performance of $X_{ILP}$: the loss in $RAER$ is no longer negligible and the loss in $FR$ increases.
% 
Finally, we observe that using our model has a further advantage over the $t$-tuned solutions: our method does not require to find a tuning parameter $t$ to describe the interplay between the editor's and the reviewers' objective function.
% 
The experiment results are listed in the Table \ref{tab:downsample}. 
% 
% Indeed, to the best of our knowledge, there is no formula to determine how the $t$ that leads to the best $t$-tuned solutions.
% 

% 


% 
{\bf Final Remarks.}
% 
In every setting considered, we observe that the variance of our solution is noticeably lower than the one found by any ILP based model.
%
This is especially interesting since we are able to retrieve those fairer solutions without altering the objective function nor by determining a tuning parameter to mix the quality and the effort matrix.
% 
Finally, we notice that our accuracy results are acceptable since the percentages we found are well above the $83\%$ obtained by other heuristic approaches, as the one proposed in \cite{DBLP:conf/ijcai/AhmedDF17}. 
% 


\section{Conclusion and Future Works}
\label{sec:conclusion}

% 
In this paper, we introduced an integer BP model for the peer review problem.
% 
To the best of our knowledge, this is the first model that finds a peer-reviewing matching using this formalism.
% 
We showed that the LLp and the ULp are well-defined problems and that solution has a neat burden-free property under mild assumptions.
% 
Finally, we defined a heuristic solution and validated it through numerical tests.
% 
From the results, we observe that the heuristic finds fairer solutions that require a lower average effort from the reviewers and achieves a competitive quality without requiring any parameter tuning.
% 

% 
For the future avenue, a first improvement to the model would be to relax the binary constraints of the allocation and search for a probabilistic allocation rather than a deterministic one.
% 
% We believe that defining a probability distribution over a set of equally optimal allocations is better than searching for a specific optimal one.
% 
Another interesting aspect of the peer review problem is determining the expertise of the reviewers by comparing records from conferences.
% 

\ack{This project is partially supported by a Leverhulme Trust Research Project Grant (2021--2024). Jie Zhang is also supported by the EPSRC grant (EP/W014912/1).}

% 
\bibliography{ecai}

\clearpage

\section*{Appendix}

In this appendix, we report the missing proofs, the additional theoretical results, and the additional experimental results of our paper.

\input{AppendixA}
\input{AppendixB}
\input{AppendixC}
\end{document}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
