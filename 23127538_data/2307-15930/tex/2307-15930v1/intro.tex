%% -*- mode: LaTeX; fill-column: 78; -*-

\section{Introduction}
\label{sec:intro}
Event-driven multi-threaded programming is an important idiom for structuring concurrent computations
in distributed message-passing applications, file systems~\cite{Mazieres01},
high-performance servers~\cite{Dabek:event-driven-02}, systems programming~\cite{P:pldi13},
smartphone applications~\cite{mednieks2012programming}, and many other domains.
In this idiom, multiple threads execute concurrently and can communicate through shared objects.
In addition, some threads, called \emph{handler threads}, have an associated event pool
to which all threads can post events.
Each handler thread executes an event processing loop in which events
from its pool are processed sequentially, one after the other, interleaved with the execution of other threads.
An event is processed by invoking an appropriate handler, which can be, e.g., a callback function.

%% according to some policy (in arbitrary order, in the order of their arrival, or some other).
%% A handler thread processes an event 
%% The event processing loop processes an event only after the execution of the previous event has finished, but 

Testing and verification of event-driven multi-threaded programming faces
all the usual challenges of testing and verification for multi-threaded programs, and furthermore suffers from
%% since it requires reasoning about all the ways in which operations executed by different threads can interfere.
additional complexity, since the order of event execution is determined dynamically and non-deterministically.
%% the different possible orderings of events processed on the same handler thread, combined with the 
%% which can cause a blow-up in the number of interleavings, even when the events do not interfere.
A successful and fully automatic technique for finding concurrency bugs in multithreaded programs (i.e., defects that
arise only under some thread schedulings) and for verifying their absence is \emph{stateless model checking} (SMC)~\cite{Godefroid:popl97}.
Given a terminating program and fixed input data,
SMC systematically explores the set of
all thread schedulings that are possible during program runs.
%
A special runtime scheduler drives the SMC exploration by making decisions
on scheduling whenever such choices may affect the interaction between threads.
%% Given enough time, the exploration covers all possible executions and
%% detects any unexpected program results, program crashes, or assertion violations.
%% The technique is entirely automatic, has no false positives,
%% does not consume excessive memory, and
%% can reproduce the concurrency bugs it detects.
SMC has been implemented in many tools
(e.g., VeriSoft~\cite{Godefroid:verisoft-journal},
\textsc{Chess}~\cite{MQBBNN:chess}, Concuerror~\cite{Concuerror:ICST13},
\Nidhugg~\cite{tacas15:tso}, rInspect~\cite{DBLP:conf/pldi/ZhangKW15},
\CDSChecker~\cite{NoDe:toplas16}, \RCMC~\cite{KLSV:popl18}, and
\GenMC~\cite{GenMC@CAV-21}), and successfully applied to realistic
% concurrent
programs (e.g.,~\cite{GoHaJa:heartbeat} and~\cite{KoSa:spin17}).
%% A successful technique for finding concurrency bugs (i.e., defects that
%% arise only under some thread schedulings) and for verifying their absence is
%% \emph{stateless model checking} (SMC)~\cite{Godefroid:popl97}.
%% Given a terminating program, which may be annotated with assertions,
%% %
%% SMC systematically explores the set of
%% all thread schedulings that are possible during runs of this program.
%% %
%% A special runtime scheduler drives the SMC exploration by making decisions
%% on scheduling whenever such choices may affect the interaction between threads.
%% Given enough time, the exploration covers all possible executions and
%% detects any unexpected program results, program crashes, or assertion violations.
%% The technique is entirely automatic, has no false positives,
%% does not consume excessive memory, and
%% can reproduce the concurrency bugs it detects.
%% Throughout the years,
%% SMC has been implemented in many tools
%% (e.g., VeriSoft~\cite{Godefroid:verisoft-journal},
%% \textsc{Chess}~\cite{MQBBNN:chess}, Concuerror~\cite{Concuerror:ICST13},
%% \Nidhugg~\cite{tacas15:tso}, rInspect~\cite{DBLP:conf/pldi/ZhangKW15},
%% \CDSChecker~\cite{NoDe:toplas16}, \RCMC~\cite{KLSV:popl18}, and
%% \GenMC~\cite{GenMC@CAV-21}), and successfully applied to realistic concurrent
%% programs (e.g., \cite{GoHaJa:heartbeat,KoSa:spin17}).
To reduce the number of explored executions,
SMC tools typically employ \emph{dynamic partial order reduction}
(DPOR)~\cite{FG:dpor,abdulla2014optimal}.
DPOR defines an equivalence relation on executions, which
preserves relevant correctness properties, such as reachability of local
states and assertion violations, and explores at least one execution in each equivalence class.
\hasbeenremoved{We call a DPOR algorithm \emph{optimal} if it guarantees the exploration of exactly one execution per
equivalence class.}

%% SMC faces the problem that
%% the number of possible thread schedulings grows exponentially with
%% the length of program execution, and
%% must therefore be equipped with techniques to reduce the number of
%% explored executions.
%% %
%% The most prominent such technique is
%% \emph{partial order reduction} (POR)~\cite{Valmari:reduced:state-space,Peled:representatives,Godefroid:thesis,CGMP:partialorder},
%% adapted for SMC as \emph{dynamic partial order reduction} (DPOR)~\cite{FG:dpor,abdulla2014optimal}.
%% DPOR is based on the observation that 
%% two executions can be regarded as equivalent if they induce the same ordering
%% between conflicting statement executions,
%% and that it is therefore sufficient to
%% explore at least one execution in each equivalence class.

%% \bjcom{Here is on the challenges of DPOR for event-based}
Existing DPOR techniques for multi-threaded programs lack effectiveness in handling the complications brought by event-driven programming,
as has been observed by e.g., Jensen et al.~\cite{Event-DrivenSMC@OOPSLA-15}
and Maiya et al.~\cite{Maiya:tacas16}.
%% \fix{and others}.
A na\"ive way to handle such a program is to consider all pairs of events as conflicting,
%% A na\"ive way to handle such programs is to consider event pools as shared objects and operations that post events as writes,
%% (i.e., two postings of events to the same pool are always considered to be conflicting),
implying that different orderings of event executions by a handler thread will be considered inequivalent.
%% This leads Such techniques will explore  The induced equivalence on executions will then always consider
A major drawback is then that a DPOR algorithm cannot exploit the fact that different orderings of event executions by a single handler thread
can be considered equivalent in the case that events are non-conflicting.
In this way, a program in which $n$ non-conflicting events
are posted to a handler thread by $n$ concurrent threads can give rise to $n!$ explorations by a standard
DPOR algorithm, whereas all of them are in fact equivalent.
On the other hand, some events may be conflicting, so a DPOR algorithm for event-driven programs
should explore only the necessary inequivalent orderings between conflicting events.
This can be achieved by defining an equivalence on executions, which respects
only the ordering of conflicting accesses to shared variables,
%% performed when executing events or threads,
irrespective of the order in which events are executed.
For plain multi-threaded programs, this equivalence is the basis for several effective DPOR
algorithms~\cite{FG:dpor,abdulla2014optimal}.
%% This is the standard \emph{Mazurkiewicz~trace}-equivalence ~\cite{Mazurkiewicz:traces}.
% Its equivalence classes are the natural extension of Mazurkiewicz traces to event-driven programs.
The challenge is to develop an effective DPOR algorithm also for event-driven programs.
%% which is based on an equivalence that is based only on the ordering of
%% accesses to conflicting statement executions inside handlers or threads,
%% and does not worry about ordering of \texttt{post} events.

In this paper, we present \EventDPOR, a DPOR algorithm for event-driven multi-threaded programs
where handlers can execute events from their event pool in arbitrary order (i.e., the event pool is viewed as a multiset).
The multiset semantics is used in many works~\cite{popl07:JhalaM,Raychev:oopsla13,Event-DrivenSMC@OOPSLA-15}, often with the significant restriction that there is only one handler thread; we consider the more general situation with an arbitrary number of handler threads.
%% \revise{Existing event-driven frameworks employ different policies for selecting events from the event pool.
%% The multiset semantics is used in many works~\cite{popl07:JhalaM,Raychev:oopsla13,Event-DrivenSMC@OOPSLA-15}, often with the significant restriction that there is only one handler thread.
%% For other policies, the multiset semantics can serve as an overapproximation.}
%% which is correct with respect to the post-agnostic equivalence on executions.
%% which is based on only  the ordering of
%% accesses to conflicting statement executions inside handlers or threads, and does not worry about ordering of \texttt{post} events.
%% This equivalence is coarser than the equivalence obtained by considering \texttt{post} events as conflicting, since
%% it does not order non-conflicting event handlers.
%% Thus, our equivalence relation is in fact a natural extension of the Mazurkiewicz traces to the event-driven setting. 
%% Starting from a general model of event-driven multi-threaded programs, we define an
%% equivalence relation, which considers different orderings of non-conflicting handlers on the same threads
%% as equivalent.
%% We then proceed to define a DPOR algorithm which is optimal for this equivalence.
\EventDPOR is based on \OptimalDPOR~\cite{abdulla2014optimal,optimal-dpor-jacm},
a DPOR algorithm for multi-threaded programs.
%% in which threads interact only via shared variables.
%% \OptimalDPOR is both
%% \emph{correct} (explores at least one trace in each equivalence class) and
%% \emph{optimal} (explores exactly one trace in each equivalence class).
The basic working mode of \OptimalDPOR is similar to several other DPOR algorithms:
Given a terminating program, one of its executions is explored and then analyzed to construct initial fragments of
new executions; each fragment that is not redundant (i.e., which can be extended to an execution that is not equivalent to a previously explored execution),
is subsequently extended to a maximal execution, which is analyzed to construct
initial fragments of new executions, and so on.
\EventDPOR employs the same basic mode of operation as \OptimalDPOR,
but must be extended to cope with the event-driven execution model.
One complication is that the constructed initial fragments must satisfy the constraints imposed
by the fact that event executions on a handler are serialized; this may necessitate
reordering of several events when constructing new executions from an already explored one.
Another complication is that the check whether a new fragment is redundant
is NP-hard in the event-driven setting, as we prove in this paper.
We alleviate this by defining a sequence of inexpensive but incomplete rendundancy checks, using
a complete decision procedure only as a last resort.

%% \begin{enumerate}
%% \item
%% when constructing fragments of new executions,  %%by reversing races in existing executions,
%% it may be necessary to also change the order in which events are processed by some handlers.
\hasbeenremoved{A simple case is when two statements in different events
on the same handler are conflicting: such a race can often be reversed by reversing the order in which the events are executed by their handler.
However, in some cases a race can be reversed only by reordering a larger number of events, even on handlers where the racing statements do not execute. (We will illustrate this phenomenon in \cref{sec:concepts}.)
\EventDPOR extends \OptimalDPOR by mechanisms to perform such reorderings when necessary.}
%% \item
\hasbeenremoved{
Furthermore, and  in contrast  to the situation for plain multi-threaded programs,
    When analyzing plain multi-threaded programs, \OptimalDPOR can test whether a newly constructed execution fragment is equivalent to an already explored execution
  using sleep sets~\cite{Godefroid:thesis}, which need only 
  remember the first executed statement from each subtree of previously explored executions.
%% the first executed statement in each subtree of executions that have been explored in the past, 
  For event-driven programs, recording the first executed statement is not sufficient. The reason is that conflicts may appear at the granularity of events,
  and therefore it is necessary to record the execution of an entire event whenever the start of that event leads to a subtree of previously explored executions.
%% since one must record the excecution of an entire event in order to determine whether it conflicts with another event executed by the same handler thread.
Even with this information, 
the problem of determining whether a new execution is equivalent with an explored execution is NP-hard, as we prove in this paper.
We address this problem by To avoid repeated expensive equivalence checks, before employing a  precise one, which have shown to be sufficient
for all our benchmarks.
}
%% \EventDPOR therefore employs a sequence of fast but incomplete tests for equivalence checking, and performs precise checks only as a last resort. 
%% Its equivalence check is precise only for the sclass of \emph{non-branching} programs, in which the sequence of shared variables
%% that are accessed by an event during its execution does not depend on how its execution is interleaved with other threads. 
%% We address this problem by employing a sequence of fast but incomplete tests for equivalence, 
%% To avoid repeated expensive equivalence checks,
%% \EventDPOR therefore employs a sequence of fast but incomplete tests for equivalence checking, and performs precise checks only as a last resort. 
%% Its equivalence check is precise only for the sclass of \emph{non-branching} programs, in which the sequence of shared variables
%% that are accessed by an event during its execution does not depend on how its execution is interleaved with other threads. 
%% \end{enumerate}

We prove that the \EventDPOR algorithm is \emph{correct} (explores at least one execution in each equivalence class) for event-driven programs.
%% \emph{optimal} .
We also prove that it is \emph{optimal} (explores exactly one execution in each equivalence class) for the class of so-called \emph{non-branching} programs, in which the possible sequences of shared variable accesses that can be performed 
during execution of an event, whose handler also executes other events, does  not depend on how its execution is interleaved with other threads.
\hasbeenremoved{We conjecture that \EventDPOR can be made optimal for all programs by adding additional features that
may impose a significant overhead.}
%% Moreover, in all our benchmarks, also those that are not non-branching,
%% \EventDPOR explores only the optimal number of executions.



%% The overall idea of \OptimalDPOR is to detect races in explored executions, and reverse them to obtain new executions that will subsequently be explored, finding new races that will be reversed, etc. For plain shared-memory programs, reversing a race can be achieved simply by minimally changing the way threads are interleaved at the point in the execution where the race occurs, to make the racing statements execute in the opposite order.
%% Also for event-driven programs, many races can be reversed in this manner. However,

%% \EventDPOR includes mechanisms for changing the order in which events are processed, if necessary, when forming new executions by reversing races in
%% already old ones. This mechanism is
%% based on a framework for representing constraints on event processing imposed by the happens-before relation.
%% This mechanism \revise{may have to face a fundamental obstacle}
%% (\KS{vague and weak statement})
%% which makes it difficult to construct an efficient SMC algorithm for event-driven multi-threaded programs.
%% More precisely,
%% the problem of whether for a given event-driven execution, there is an equivalent execution where the order in which events are processed by event handlers
%% are changed to respect certain constraints, is NP-complete.

%% Problem (2) is central to achieving optimality for a DPOR algorithm, since they typically explore the space of executions in a depth-first manner.
%% After finishing the exploration of a subtree of executions, its memory is reclaimed, keeping only some information about the initial statements of its
%% executions. This information can then be used to check whether candidate future executions are redundant by checking whether then can start in the same way
%% (this is the essence of the sleep set technique~\cite{Godefroid:thesis}).

%% There is a fundamental obstacle which makes it difficult to construct an efficient SMC algorithm for event-driven multi-threaded programs.
%% To explain it, we note that the natural way for an SMC algorithm to find new executions is by swapping the order between conflicting (or ``racing'')
%% statements in a previously explored executions. Such a swap will in some cases be possible only if the order in which some handler threads process
%% their events is changed, compared to the previously explored execution.
%% \bjcom{Should we illustrate this phenomenon already here?}
%% This makes it challenging, both
%% \begin{inparaenum}[(i)]
%% \item
%% to determine whether and how a new execution can be formed by swapping conflicting statements in an existing execution, and
%% \item
%% determine whether the new execution is equivalent to a previously explored one.
%% \end{inparaenum}


%% \OptimalDPOR first explores a maximal execution $\exseq$, and then inspects $\exseq$ to find races. The analysis of each race shows that $\exseq$ can be continued in a different way by branching off from $\exseq$ at the point where the race occurred, in a way that results in a maximal execution that is ineq
%% \item
%% \bjcom{Skip this?}
%% The first contribution is a representation of executions of event-driven programs that is suitable for DPOR.
%% Event handlers are represented as ``mini-threads'', whose executions can be reordered relative to each other.
%% \KS{I think this was also done by~\citet{Maiya:tacas16}.  Can we claim it as ``contribution''?}
%% The representation includes ordering constraints that enforce sequential execution of event handlers on each handler thread.
%%, in the same order as events were posted. \EventDPOR is designed to manipulate such constraints in the appropriate way.
%% \item
%% A mechanism for changing the order in which events are processed, if necessary, when forming new executions from old ones. This mechanim is
%% based on a framework for representing constraints on event processing imposed by the happens-before relation.
%% \item
%% A mechanism for determining whether a new execution can be reordered to make a particular event execute first on its handler.
%% \end{itemize}


%% The \EventDPOR algorithm is correct. It is also optimal under the restriction that events access the same sequence of shared variables regardless of
%% which values they see when reading values of shared variable.
%% In addition, this paper includes
%% a proof of NP-completeness for the problem of determining whether a given multi-threaded execution can be transformed into an equivalent event-driven one,
%% and that of determining whether a particular event can execute first on its handler.

%% There is a fundamental obstacle which makes it difficult to construct an efficient SMC algorithm for event-driven multi-threaded programs.
%% To explain it, we note that the natural way for an SMC algorithm to find new executions is by swapping the order between conflicting (or ``racing'')
%% statements in a previously explored executions. Such a swap will in some cases be possible only if the order in which some handler threads process
%% their events is changed, compared to the previously explored execution.
%% \bjcom{Should we illustrate this phenomenon already here?}
%% This makes it challenging, both
%% \begin{inparaenum}[(i)]
%% \item
%% to determine whether and how a new execution can be formed by swapping conflicting statements in an existing execution, and
%% \item
%% determine whether the new execution is equivalent to a previously explored one.
%% \end{inparaenum}
%% In this paper, we show that formalizations of these two problems are in fact NP-complete. More precisely, the following ones:
%% \begin{inparaenum}[(1)]
%% \item
%% The problem of whether a given multithreaded execution can be transformed into an event-driven execution by serializing the execution of
%% of some events on some handlers, and
%% \item
%% The problem of whether a given event-driven execution can be reorganized in such a way that a particular handler executes a particular event as its
%% first one.
%% \end{inparaenum}
%% Problem (2) is central to achieving optimality for a DPOR algorithm, since they typically explore the space of executions in a depth-first manner.
%% After finishing the exploration of a subtree of executions, its memory is reclaimed, keeping only some information about the initial statements of its
%% executions. This information can then be used to check whether candidate future executions are redundant by checking whether then can start in the same way
%% (this is the essence of the sleep set technique~\cite{Godefroid:thesis}).




%% \KS{To an outside reader, this 2nd contribution might appear as a ``technical detail'' that needs to be addressed (in some cases only?).  We should make it stronger --- but this depends on the claim we will make about optimality!}
%% The second contribution addresses the challenge that event handlers may consist of arbitrary sequences of statements, possibly branching on values read from shared variables.
%% Since handlers must execute sequentially, we cannot reverse races between individual statements in two different handlers in the same way as in standard DPOR,
%% since we cannot swap just individual statements without swapping the order of two messages entirely.
%% The situation is analogous to having concurrent threads
%% that compete for a shared mutually exclusive resource (the handler thread).
%% We present a novel technique for swapping two such events handlers, which builds on the 
%% on the same handler thread. It builds on the 
%% Such swapping can produce many other changes to the execution, making it challenging to explore each equivalence class exactly once.
%% Most existing DPOR algorithms explore all serializations of such accesses.
%% The challenge for \EventDPOR is to avoid serialization-by-default,
%% in the case where messages can contain arbitrary (terminating) code.
%% A difficult complication is that conflicts between messages
%% may be conditional on the interleaving of other threads
%% that influence the outcome of tests in messages.
%% \EventDPOR  overcomes this challenge by the
%% key insight that races between statements in different handlers on the same handler thread should be
%% treated as races between a message and a statement. This allows to preserve the precision in race reversal that is necessary for an optimal DPOR algorithm.
%% The first is to take into account that event handlers must be executed in the same order as their corresponding post events.
%% This complicates the generation of new executions that reverse races in already explored ones.
%% If messages in their turn post new messages through several levels, a careful reorganization is required to construct new executions that
%% respect the FIFO policy of event queues, at the same time as avoiding redundant exploration.
%% \EventDPOR overcomes this challenges by equipping executions with additional ordering relations that
%% model the constraints imposed by the event-driven computation model, and adapting the DPOR algorithm accordingly.
%% \item
%% The second arises because event handlers
%% may consist of arbitrary sequences of statements, possibly branching on values read from shared variables.
%% Since handlers must execute sequentially, we cannot reverse races between individual statements in two different handlers in the same way as in standard DPOR,
%% since we cannot swap just individual statements without swapping the order of two messages entirely.
%% Such swapping can produce many other changes to the execution, making it challenging to explore each equivalence class exactly once.
%% The situation is analogous to having concurrent threads
%% that compete for a shared mutually exclusive resource (the message handler).
%% Most existing DPOR algorithms explore all serializations of such accesses.
%% The challenge for \EventDPOR is to avoid serialization-by-default,
%% in the case where messages can contain arbitrary (terminating) code.
%% A difficult complication is that conflicts between messages
%% may be conditional on the interleaving of other threads
%% that influence the outcome of tests in messages.
%% \EventDPOR  overcomes this challenge by the key insight that races between statements in different handlers on the same handler thread should be
%% treated as races between a message and an event. Only in this way can we preserve the precision in race reversal that is necessary for
%% an optimal DPOR algorithm.
%% \end{itemize}
%% \OptimalDPOR can can handle event-driven programs out-of-the-box
%% by considering event queues as shared objects and \texttt{post} events as
%% writes (i.e., racing).
%% However, this approach is not effective when handlers are non-conflicting.
%% This limitation can be overcome by a DPOR algorithm which is optimal with respect to an equivalence that completely ignores event queues,
%% considering only the ordering of accesses to shared variables by handlers and threads. The design of such a DPOR algorithm has to address two main
%% challenges.
%% \end{itemize}

%% These contributions allow \EventDPOR to be both correct and optimal with respect to the
%% equivalence induced only by the ordering of conflicting statement executions in threads and
%% handlers, without considering accesses to event queues as conflicting. This optimality depends
%% on being able to check whether an event handler can execute in such a way that it does not
%% conflict with a previous handler on the same thread. This check is straight-forward for
%% handlers with non-branching control, but may be more costly for handlers that branch
%% on values read from shared variables. In such cases, one can always fall back on a simple check
%% which considers only one branch; this preserves correctness but can sacrifice optimality.


We have implemented \EventDPOR in an extension of the \Nidhugg
tool~\cite{tacas15:tso}.
%
Our experimental evaluation shows that, when compared with other SMC tools in
which event handlers are simulated using locks, \EventDPOR incurs only a
moderate constant overhead, but can be exponentially faster than other
state-of-the-art DPOR algorithms. The same evaluation also shows that, unlike
other algorithms that can achieve analogous reduction, \EventDPOR manages to
completely avoid unnecessary exploration of executions that cannot be serialized.
Moreover, in all the programs we tried, 
also those that are not non-branching, \EventDPOR explored the optimal number of traces, suggesting that
\EventDPOR is optimal not only for non-branching programs but also for a good number of branching ones.
Also, our sequence of inexpensive checks for redundancy was sufficient in all tried programs, i.e.,
we never had to invoke the decision procedure for this NP-hard problem.



%% Moreover, in all the programs we tried, also those that are not non-branching,
%% \EventDPOR is optimal, i.e., explores only one execution in each equivalence class.
%% Also, in all checks for redundancy that occurred in the benchmarks,
%% our incomplete but efficient tests for redundancy were sufficient.
%% to avoid calling a potentially expensive decision procedure.

\hasbeenremoved{
  In summary, the contributions of this paper are:
\begin{enumerate}
\item[(\cref{sec:eventdpor}+\cref{sec:correctness})] A \textit{novel SMC
  algorithm}, \EventDPOR, for event-driven programs where handlers process
  events from their event queue in arbitrary order, which is proven correct,
  and is optimal for programs for which the variable accesses of events do not
  depend on how their execution is interleaved with other threads.
\item[(\cref{sec:np-complete})] A theorem with proof that the problem of
  deciding whether a given happens-before ordering can be realized in an
  event-driven execution is NP-hard.
\item[(\cref{sec:impl})] An \textit{implementation} of \EventDPOR,
  which is available in binary form in an
  \href{https://drive.google.com/file/d/17BbkGYfqSy-6OsbTWWzhEY5AYr2Bs9wL/view?usp=sharing}{anonymized VM image} and
  will become available in source form as part of the paper's artifact.
\item[(\cref{sec:eval})] An \textit{evaluation} of \EventDPOR,
  using a variety of programs for asynchronous event-driven programming,
  against three other state-of-the-art implementations of SMC algorithms.
\end{enumerate}
}

\bjforget{
\paragraph{Outline}
After a brief review of related work in the next section, in \cref{sec:concepts} we illustrate the main ideas of the \EventDPOR algorithm by a sequence of small examples.
\cref{sec:model} defines the event-driven execution model, and basic terminology, thereafter \cref{sec:eventdpor} presents the \EventDPOR algorithm.
The next two sections contain proof of correctness and optimality of the algorithm (\cref{sec:correctness}) and statements and proofs that equivalence checking is NP-hard (\cref{sec:np-complete}).
\Cref{sec:impl} describes our implementation, its performance is evaluated in \cref{sec:eval},
and the paper ends with some concluding remarks.
}

%% \footnote{
%%   Note that in the remainder of the paper, we will use the term \emph{message} to refer to what was called \emph{event} in this introduction, for the reason that the literature on DPOR has reserved the term \emph{event} to denote an execution of a program statement. We will also use \emph{mailbox} instead of event pool.}

