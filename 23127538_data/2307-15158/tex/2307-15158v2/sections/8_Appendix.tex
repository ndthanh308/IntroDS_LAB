\appendix
\clearpage

\section{Additional Materials For the User Study}
\label{app:demographics-survey}
\begin{itemize}
    \item How old are you?
    \item What is your gender? [Male, Female, Non-binary, Prefer not to say, Open-ended option]
    \item How many years of experience do you have in AI systems?
    \item What's your educational background?
    \item In which country do you currently reside?
    \item What is domain or sector of your work? (e.g., health, energy, education, finance, technology, food)
    \item What is your current role?
    \item What kinds of AI systems do you work on? (e.g., machine learning, computer vision, NLP, game theory, robotics)
\end{itemize}

\begin{table}[h]
\centering

\caption{Constructed themes for the user study based on how our participants saw the application of guidelines, what worked well and what could have been improved.}
\label{tab:codebook-interviews}
% \resizebox{\textwidth}{!}{%
\begin{tabular}{ll}
\toprule
\textbf{Theme} & \textbf{Participants} \\ \midrule
\quad Raising awareness, facilitating self-learning & 12 \\
\quad Aligning with roles & 10 \\
\quad Aligning with regulations & 10 \\
\quad Providing helpful examples & 7 \\
\quad Engaging team members and external experts & 5 \\
\quad Maintaining the visual simplicity of the guidelines & 3 \\
\quad Documenting guidelines in a concise summary PDF & 3 \\
\quad Providing a systematic flow of information and guidelines & 2 \\
\end{tabular}%
% }
\end{table}

\clearpage

\section{Mapping Guidelines with EU AI Act Articles}
\label{app:mapping_guidelines}

\noindent\textbf{Article 6 (\emph{Classification rules for high-risk AI systems}):} It states that an AI system shall be considered high-risk when \emph{``it [the AI system] is intended to be used as a safety component of a product, or is itself a product''.} This article aligns with \textbf{guideline \#1} as it mandates the identification of an AI system's intended use to determine whether its use poses a low or high risk.
\smallskip

\noindent\textbf{Article 9 (\emph{Risk management system}):} 
It states that \emph{``a risk management system shall be established, implemented, documented and maintained throughout the entire lifecycle of a high-risk AI system''.} This article aligns with \textbf{guidelines \#1, \#3-5, and \#13} as it is about the identification of harms and risks of the AI system's intended use.
\smallskip

\noindent\textbf{Article 10 (\emph{Data and data governance}):} 
It states that \emph{``training, validation and testing data sets shall be subject to appropriate data governance and management practices''.} This article aligns with \textbf{guidelines \#8 and \#15-18} as it discusses the management and quality of data for training, validation, and testing, including aspects of diversity and minimizing biases.
\smallskip

\noindent\textbf{Article 11 (\emph{Technical documentation}):}  
It states that the technical documentation of a high-risk AI system shall \emph{``be drawn up before that system is placed on the market or put into service and shall be kept up-to date''}, and \emph{``provide national competent authorities and notified bodies with all the necessary information to assess the compliance of the AI system''.} This article aligns with \textbf{guidelines \#2, \#6, \#14} as it about documentation of the system and its contractual requirements, which may also be needed for obtaining ethical approvals.
\smallskip

\noindent\textbf{Article 12 (\emph{Record-keeping}):} 
It states that high-risk AI systems shall include \emph{``logging capabilities to enable the monitoring of the operation of the high-risk AI system with respect to the occurrence of situations that may result in the AI system presenting a risk''.} This article aligns with \textbf{guidelines \#6, \#9, \#10, and \#14} as it is about providing mechanisms for interpretable outputs and auditing, and improving the security of the system. 
\smallskip

\noindent\textbf{Article 13 (\emph{Transparency and provision of information to users}):} 
It states that \emph{``high-risk AI systems shall be designed and developed in such a way to ensure that their operation is sufficiently transparent to enable users to interpret the system's output and use it appropriately''.} This article aligns with \textbf{guidelines \#8-10, \#16-18, and \#20} as it is about quality, representativeness, and fit of training and testing datasets with the intended use.
\smallskip

\noindent\textbf{Article 14 (\emph{Human oversight}):} 
It states that \emph{``high-risk AI systems shall be designed and developed in such a way, including with appropriate human-machine interface tools, that they can be effectively overseen by natural persons during the period in which the AI system is in use''.} This article aligns with \textbf{guidelines \#9 and \#20} as it about ensuring human control over the system.
\smallskip

\noindent\textbf{Article 15 (\emph{Accuracy, robustness and cybersecurity}):} 
It states that \emph{``high-risk AI systems shall be designed and developed in such a way that they achieve, in the light of their intended purpose, an appropriate level of accuracy, robustness and cybersecurity, and perform consistently in those respects throughout their lifecycle''.} This article aligns with \textbf{guideline \#10} as it is about documenting the security of all system components.
\smallskip

\noindent\textbf{Article 16 (\emph{Obligations of providers of high-risk AI systems}):} 
It states that \emph{``providers of high-risk AI systems shall draw-up the technical documentation of the high-risk AI system''.} This article aligns with \textbf{guideline \#6} as it is about system documentation.
\smallskip

\noindent\textbf{Article 17 (\emph{Quality management system}):} 
It states that ``an AI system shall be documented in a systematic and orderly manner in the form of written policies, procedures and instructions''. This article aligns with \textbf{guidelines \#6, \#7, \#10, and \#14-18} because it is about documentation of all system components, including AI models and testing and validation procedures.
\smallskip

\noindent\textbf{Article 18 (\emph{Obligation to draw up technical documentation}):}    
It states that \emph{``providers of high-risk AI systems shall draw up the technical documentation ''.} This article aligns with \textbf{guideline \#6} as it is about system documentation.
\smallskip

\noindent\textbf{Article 20 (\emph{Automatically generated logs}):} 
It states that \emph{``providers of high-risk AI systems shall keep the logs automatically generated by their high-risk AI systems, to the extent such logs are under their control by virtue of a contractual arrangement with the user or otherwise by law''.} This article aligns with \textbf{guideline \#19} as it is about monitoring of the system.
\smallskip

\noindent\textbf{Article 29 (\emph{Obligations of users of high-risk AI systems}):} 
It states that users shall \emph{``monitor the operation of the high-risk AI system on the basis of the instructions of use.''}, and \emph{``inform the provider or distributor when they have identified any serious incident or any malfunctioning and interrupt the use of the AI system''.}  This article aligns with \textbf{guideline \#19} as it about monitoring of the system and utilizing guardrails or rollbacks.
\smallskip

\noindent\textbf{Article 50 (\emph{Document retention}):} 
It states that \emph{``the provider shall, for a period ending 10 years after the AI system has been placed on the market or put into service, keep at the disposal of the national competent authorities the technical documentation''.} This article aligns with \textbf{guideline \#6} as it about system documentation.
\smallskip

\noindent\textbf{Article 60 (\emph{EU database for stand-alone high-risk AI systems}):} 
It states that information contained in the EU database shall \emph{``be accessible to the public''} and \emph{``include the names and contact details of natural persons who are responsible for registering the system and have the legal authority to represent the provider''.} This article aligns with \textbf{guideline \#4} as it is about providing mechanisms for reporting system harms.
\smallskip

\noindent\textbf{Article 61 (\emph{Post-market monitoring by providers and post-market monitoring plan for high-risk AI systems}):} 
It states that \emph{``the post-market monitoring system shall actively and systematically collect, document and analyse relevant data provided by users or collected through other sources on the performance of high-risk AI systems throughout their lifetime''.} This article aligns with \textbf{guidelines \#12, \#14, \#15, \#19} as it is about data handling and model updates when the AI system is in use.
\smallskip

\noindent\textbf{Article 62 (\emph{Reporting of serious incidents and of malfunctioning}):} 
It states that \emph{``providers of high-risk AI systems placed on the Union market shall report any serious incident or any malfunctioning of those systems which constitutes a breach of obligations under Union law intended to protect fundamental rights to the market surveillance authorities of the Member States where that incident or breach occurred''.} This article aligns with \textbf{guideline \#4} as it is about incentivizing the reporting of system harms.
\smallskip

\noindent\textbf{Article 63 (\emph{Market surveillance and control of AI systems in the Union market}):} 
It states that \emph{``the national supervisory authority shall report to the Commission on a regular basis the outcomes of relevant market surveillance activities. ''.} This article aligns with \textbf{guideline \#4} as it about incentivizing the reporting of system harms.
\smallskip

\noindent\textbf{Article 64 (\emph{Access to data and documentation}):} 
It states that \emph{``access to data and documentation in the context of their activities, the market surveillance authorities shall be granted full access to the training, validation and testing datasets used by the provider, including through application programming interfaces (`API') or other appropriate technical means and tools enabling remote access''.} This article aligns with \textbf{guidelines \#16 and \#17} as it is about data documentation.
\smallskip

\noindent\textbf{Article 65 (\emph{Procedure for dealing with AI systems presenting a risk at national level}):} 
It states that \emph{``AI systems presenting a risk shall be understood as a product presenting a risk defined in Article 3, point 19 of Regulation (EU) 2019/1020 insofar as risks to the health or safety or to the protection of fundamental rights of persons are concerned''.} This article aligns with \textbf{guideline \#3} as it is about harms and risks identification.
\smallskip

\noindent\textbf{Article 67 (\emph{Compliant AI systems which present a risk}):} 
It states that if the AI system is compliant with the EU AI Act but still presents a risk to the health or safety of persons, the market surveillance authority \emph{``shall require the relevant operator to take all appropriate measures to ensure that the AI system concerned, when placed on the market or put into service, no longer presents that risk, to withdraw the AI system from the market or to recall it within a reasonable period, commensurate with the nature of the risk, as it may prescribe''.} This article aligns with \textbf{guideline \#5} as it is about mitigation strategies about the identified harms and risks.
\smallskip

\noindent\textbf{Article 69 (\emph{Codes of conduct}):} 
It states that \emph{``the Commission and the Board shall encourage and facilitate the drawing up of codes of conduct intended to foster the voluntary application to AI systems of requirements related for example to environmental sustainability, accessibility for persons with a disability, stakeholders participation in the design and development of the AI systems and diversity of development teams on the basis of clear objectives and key performance indicators to measure the achievement of those objectives''.} This article aligns with \textbf{guidelines \#2, \#11, \#21, \#22} as it is about the environmental assessment of the system, the ethical approvals obtained from ethics committees and boards, and the characteristics of the development team.