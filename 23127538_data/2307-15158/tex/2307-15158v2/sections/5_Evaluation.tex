\section{Evaluation of the 22 Responsible AI Guidelines}
\label{sec:userstudy}

We first conducted a formative study with 10 AI practitioners from a large technology company to elicit design requirements for an evaluation tool, implemented the tool (Panel B in Figure~\ref{fig:card-elements} and \S\ref{subsec:populate_tool}), and relied on it to conduct a user study with 14 other AI researchers, engineers, designers, and product managers from the same company (Panel C in Figure~\ref{fig:card-elements} and \S \ref{subsec:evaluate_guidelines}).

\subsection{Incorporating  the guidelines into a tool} 
\label{subsec:populate_tool}

\mbox{ } \\
\noindent\textbf{Eliciting design requirements for a tool through a formative study.} We conducted a formative study that included semi-structured interviews with 10 participants. These participants, comprising 6 males and 4 females, were AI practitioners in their 30s and 40s employed at a large technology company. The participants had a range of work experience, spanning from 1 to 8 years, and were skilled in areas such as data science, data visualization, UX design, natural language processing, and machine learning. The interview study took place online and consisted of three parts. In the first part, we encouraged participants to share information about their ongoing AI projects. In the second part, we presented them with the table containing the 22 guidelines and asked them to think about how each guideline could apply to their projects. Finally, in the third part, we conducted semi-structured interviews to discuss how these guidelines could be incorporated into an interactive responsible AI tool.
 
Each study lasted about half an hour. Two authors took notes during the interviews, and afterward, they analyzed the interview transcripts using inductive thematic analysis~\cite{saldana2015coding, miles1994qualitative, mcdonald2019reliability, braun2006thematic}. This analysis then resulted in the following four design requirements (participant quotes are marked with FP):
\smallskip

\noindent
\emph{R1: Simplify the guidelines by breaking them into smaller visual components.} Participants found it challenging to reflect on guidelines and examples because of their quantity. According to FP5, \emph{``the sheer number of the guidelines is the main difficulty [...] they should be separated in bite-sized questions''}. Additionally, participants requested to visually separate the guidelines from the examples.
\smallskip

\noindent
\emph{R2: Implement clear navigation features to systematically guide users through the guidelines.} 
Participants were unsure about the best way to navigate through the guidelines. FP9 suggested that \emph{``the system should provide clear navigation [...] for example, using a progress bar''}. FP5 further emphasized that the design of the progress bar could facilitate \emph{``gaining insights while engaging with the 22 guidelines''}.
\smallskip

\noindent
\emph{R3: Track how guidelines are applied and share progress among team members.} 
Participants faced difficulty in tracking their responses on how to apply the guidelines to their projects and share progress among team members. To address this challenge, FP5 suggested implementing a feature that would save user responses as they progress through the guidelines: \emph{``there should be some functionality there that captures the answers I gave, so it'd allow me to track progress and share it among team members''}. These responses would then be transformed into comprehensive documentation and made accessible to users for download.
\smallskip

\noindent
\emph{R4: Develop a mechanism for post-hoc reflections on how the project aligns with responsible AI guidelines.} 
Participants found it challenging to envision how well their AI systems aligned with the guidelines. Therefore, FP8 suggested developing \emph{``visual feedback or a score that shows how responsible [their] AI system is.''} However, FP2 cautioned that this mechanism \emph{``should not make me anxious and feel like I have not done enough''}. Instead, it should create a positive learning experience and encourage users to generate ideas for improving their AI systems.
\smallskip

% Figure environment removed

\mbox{ } \\
\noindent\textbf{Designing the tool and incorporating the guidelines.} To meet these requirements, we designed an interactive web-based tool\footnote{\url{https://social-dynamics.net/rai-guidelines}} (Figure~\ref{fig:ui-sections}) and populated it with the 22 guidelines in Table~\ref{tbl:techniques}.

To meet  design requirement R1 (\emph{Simplify the guidelines}), each guideline is presented as a digital card \cite{RAIPatterns} with interactive boxes on both the front and back sides. The front side includes a symbolic graphic collage representing the guideline, followed by its name and full text. The back side includes an input box for users to write their thoughts on implementing each guideline in their project \cite{sanderson2023ai}. We also used this box to showcase an example for each guideline (refer to Figure~\ref{fig:card-elements}). Initially, the example in the box is visible, but it disappears once the user inputs their specific implementation details. Users can view the guideline from both sides by using the flip buttons at the bottom-left corner of each side.

Each guideline is paired with two guiding questions~\cite{yildirim2023investigating} that help users think about the relevance of the guideline to their specific AI system and context (Figure~\ref{fig:game-sorting}). The first question asks the user whether the guideline has been successfully implemented in their AI system. For example, for an engineer addressing fairness, the question asks if they have reported evaluation metrics for various groups based on factors like age, gender, and ethnicity (technique \#8 in Table~\ref{tbl:techniques}). If the engineer answers ``yes'', they are then prompted to provide specific details on how fairness was implemented in the input box on the card's back. After sharing this information, the tool moves the guideline to the ``successfully implemented'' stack. In contrast, if the engineer answers ``no'', the tool asks a second follow-up question regarding whether the guideline should be implemented in a future iteration. If the engineer answers ``yes'', they are prompted to provide specific details on how to implement it. The tool then moves the guideline to the ``should be considered'' stack. However, if the engineer answers ``no'' to both questions, indicating that the guideline is not applicable to their AI system, the tool moves the guideline to the ``inapplicable'' stack.

% Figure environment removed
\smallskip

To meet design requirement R2 (\emph{Implement clear navigation}), we explored different layout options and considered previous research that involved swiping ~\cite{cardInteractions_2020}, scrolling, or organizing guidelines into different groups ~\cite{dittus2017community}. Due to the limited screen size and the repetition of guidelines for each phase and role, we chose to organize the guidelines into nine groups. These groups were derived from three phases of the AI system: development (designing and coding),  deployment (transitioning into production), and use (actual usage of the system), as well as from three user roles:  designer,  engineer or researcher, and  manager or executive. The number of guidelines in each group varied and accommodated the specific requirements of each phase and role. For example, engineers or researchers needed to go through 20 guidelines for development, 18 for deployment, and 20 for use (\S\ref{sec:method}, Step 4).

%To facilitate the browsing of guidelines and addressing them in the user's preferred order, we introduced two arrow buttons on both the left and right side of the card group. We then introduced a graphical progress bar next to the group that not only displayed the number of remaining guidelines but also color-coded them to indicate their assignment to the three stacks. Blue leaves in the bar represented successfully implemented guidelines, magenta leaves represented guidelines for future consideration, and empty leaves represented inapplicable guidelines. Finally, we added an ``Exit'' button that becomes available as soon as the user goes through minimum two guidelines. In that way user can quit the experience at a preferable moment.

To meet design requirement R3 (\emph{Track how guidelines are applied and share progress among team members}), we added a feature to store user responses locally in the browser session. Users can download their responses as a structured PDF report at any time.

To fulfill the last requirement, R4 (\emph{Develop a mechanism for post-hoc reflections}), after completing the sorting process, we display a summary page to the user. The summary is divided into three sections, one for each stack of cards (i.e., successfully implemented, should be considered, and inapplicable), with in-text counters indicating the number of guidelines in each stack. To read the responses for each guideline, hover-over functionality is provided.

Figure~\ref{fig:ui-sections} shows the tool with its three parts that meet the four design requirements. The first part enables users to enter the name of the developed AI system (Figure \ref{fig:ui-sections}A), select the phase it belongs to and specify the user's role (Figure \ref{fig:ui-sections}B). Once the phase and role are selected, the second part displays the guidelines one by one (Figure \ref{fig:ui-sections}C). The third part presents the user with the summary for post-hoc reflections (Figure \ref{fig:ui-sections}D). If desired, the user can repeat the experience and generate documentation for other phases (Figure \ref{fig:ui-sections}E).

\subsection{Evaluating the Guidelines Through a User Study}
\label{subsec:evaluate_guidelines}
To evaluate whether our guidelines are usable by different roles and whether they match the EU AI Act articles and ISO standards, we conducted a user study with 14 AI researchers, engineers, designers, and managers (Panel C in Figure~\ref{fig:card-elements}).
\smallskip

\noindent\textbf{Participants.}
 The recruitment process took place in October and November 2022.\footnote{Participants who took part in the formative study were not eligible to participate in this evaluation study.} We aimed for a balanced sample of participants, including a variety of roles such as researchers (5), designers (3), engineers (3), and managers (3). All participants had significant expertise in AI, including areas such as machine learning, deep learning, and computer vision. Additionally, each participant was actively involved in at least one ongoing AI project during the time of the interviews. Table~\ref{tab:demographics} summarizes participants' demographics.
\smallskip

\begin{table*}[t!]
    \centering
    \caption{User study participants' demographics, including their job `Role' (designer ($R_{D}$),  engineer or researcher ($R_E$), and manager or executive ($R_M$)).}
    \label{tab:demographics}
    \resizebox{\textwidth}{!}{%
    \begin{tabular}{lllllll}
    \toprule
    \textbf{ID} & \textbf{Gender} & \textbf{Yrs of expr. in AI} & \textbf{Education} & \textbf{Current continent} & \textbf{Expertise} & \textbf{Role}\\ \midrule
    1 & Male & 6 & Ph.D. & EU & Deep learning, computer vision & $R_M$ \\
    2 & Male & 10+ & Ph.D. & North America & Machine learning, computer vision & $R_E$ \\
    3 & Male & 8 & Ph.D. & EU & Machine learning & $R_E$ \\
    4 & Male & 4 & Ph.D. & North America & Deep learning, IoT, computer vision & $R_E$ \\
    5 & Female & 5 & Ph.D. & EU & Machine learning & $R_{D}$ \\
    6 & Female & 8 & Ph.D. & EU & Computer vision & $R_{D}$ \\
    7 & Male & 2 & Ph.D. & North America & Computer vision & $R_E$ \\
    8 & Male & 10 & Ph.D. & EU & Machine learning & $R_M$ \\
    9 & Male & 4 & Ph.D. & North America & Computer vision & $R_E$ \\
    10 & Male & 10+ & M.Sc. & EU & Machine learning, natural language processing & $R_E$ \\
    11 & Male & 10+ & Ph.D. & EU & Machine learning & $R_M$  \\
    12 & Male & 6 & Ph.D. & EU & Machine learning & $R_E$ \\
    13 & Male & 4 & Ph.D. & EU & Reinforcement learning, decision making & $R_E$ \\
    14 & Male & 8 & Ph.D. & EU & Computer vision, robotics & $R_{D}$  \\ \bottomrule
    \end{tabular}%
    }
\end{table*}

\noindent\textbf{Procedure.}
Ahead of the interviews, we sent an email to all participants, providing a concise explanation of the study along with a brief demographics survey. The survey consisted of questions regarding participants' age, domain of expertise, role, and years of experience in AI system development. The survey is available in Appendix~\ref{app:demographics-survey}. It is important to note that our organization, Nokia Bell Labs, approved the study, and we adhered to established guidelines for user studies, ensuring that no personal identifiers were collected, personal information was removed, and the data remained accessible solely to the research team.

During the interview session, we presented either of these two systems to the participants: (1) our tool with the 22 guidelines; or (2) a web page with the checklist items from Microsoft's Fairness Checklist. We used the Microsoft's AI Fairness Checklist as a baseline alternative because it is a published work in a human-computer interaction conference (CHI 2020), is freely available, and has a rigorous, transparent creation process.\footnote{We decided not to compare our tool with existing card-based systems for responsible AI as they serve different purposes. Card-based systems such as the IDEO AI Ethics and the Feminist Tech card aim at providing thought-provoking activities~\cite{IDEODeck_2019} and stimulating ethical conversations~\cite{FeministDeck_2022}. However, they cannot be used as tools ensuring compliance with internal ethical procedures (like Microsoft's AI Fairness Checklist) or ISO standards.} We asked participants to interact with each system for 20 minutes (or less, if finished sooner), alternating between them to avoid any learning effect. To make the scenario as realistic as possible, we encouraged participants to reflect on their ongoing AI projects and consider how the guidelines could be applied in their roles. We also presented them with excerpts from the EU AI Act articles~\cite{eu_ai_act_2022} and summaries of each ISO standard (\S\ref{sec:step_adding_iso}), and asked them whether the guidelines link to these articles and summaries.  We further engaged participants by asking about their preferences, dislikes, and the relevance of the guidelines to their work. Subsequently, we administered the System Usability Scale (SUS)~\cite{brooke1996sus} to assess the usability of the guidelines and the checklist items.

We piloted our study with two researchers (1 female, 1 male), which helped us make minor changes to the study guide (e.g., clarifying question-wording and changing the order of questions for a better interview flow). These pilot interviews were not included in the analysis.
\smallskip

\noindent\textbf{Analysis.} First, we compared the two usability scores after using each system (i.e., the guidelines and the checklist items). Second, two authors conducted an inductive thematic analysis (bottom-up) of the interview transcripts, following established coding methodologies~\cite{saldana2015coding, miles1994qualitative, mcdonald2019reliability}.  The transcripts included  how the guidelines could be applied in the ongoing AI projects, how they link to the EU AI Act articles and ISO standards, and any other preferences or dislikes. The authors used sticky notes on the Miro platform~\cite{miro2022} to capture the participants' answers, and collaboratively created affinity diagrams based on these notes. They held seven meetings, totaling 14 hours, to discuss and resolve any disagreements that arose during the analysis process. Feedback from the last author was sought during these meetings. In some cases, a single note was relevant to multiple themes, leading to overlap between themes. All themes included quotes from at least two participants, indicating that data saturation had been achieved~\cite{guest2006many}. As a result, participant recruitment was concluded after the $14^{\text{th}}$ interview. 
\smallskip

\noindent\textbf{Results.}
\label{sec:users-results} Participants, on average, rated the guidelines' usability with a score of 66 out of 100 in SUS, with a standard deviation of 16.01 (Figure~\ref{fig:sus_boxplots}). This indicates a generally positive user experience~\cite{sauro2011practical}. The moderately high usability score was attributed to factors such as familiarity and efficiency in interacting with the guidelines, which were considered usable by different roles. In contrast, participants, on average, rated the checklist items' usability with a score of 44 out of 100 is SUS, with a standard deviation of 21.16. Despite the comparative lower SUS score, checklist items were seen as relevant for audit, formal processes, and certification purposes---acting as a `safeguard'. As for the thematic analysis, the resulting themes are provided in Table~\ref{tab:codebook-interviews} in the Appendix. These themes pertain to how our participants saw the application of guidelines, what worked well, and what could be improved.

% Figure environment removed
\smallskip

Guidelines were generally well-received by the participants. The majority of them (12 out of 14 participants) considered the guidelines valuable for raising awareness and facilitating self-learning about responsible AI, though to different extents.
Participants found the set of guidelines to be comprehensive and aligned with their roles (10 out of 14 participants), as evidenced by P8's observation that \emph{``There are some aspects of responsible AI in the project that I knew about, but I never faced them in such an organized manner''}. Similarly, P4 \emph{``felt that the guidelines were concrete and well-scoped, instead of the lengthy documents of current regulations}.'' Participants also stated that the guidelines align with current regulations (10 out of 14 participants). P7 mentioned that \emph{``he could understand the guidelines relevancy to the ISO standards and their applicability to his work.''} Similarly, P11 found the excerpts from the EU AI Act \emph{``relevant and the guidelines helped him to reflect how the current regulations will affect his project''.} Additionally, seven participants acknowledged the usefulness of the provided examples, which helped them think about potential scenarios and make the guidelines more actionable. One participant expressed that \emph{``the guidelines made me reflect on my previous choices and how I would describe my decisions when I had to develop the system (P3).''} Finally, after becoming familiar with the guidelines, P2 felt more empowered to introduce the topic of responsible system development during group discussions with his team, stating that \emph{``I can at least raise a few questions during team discussions---these are some additional aspects we may need to consider.''}

Participants also offered suggestions for further refinement of the guidelines. Although they found the guidelines aligned with their roles, they expressed the desire for solving team coordination challenges. For example, P6 stated that \emph{``It would be helpful if the guidelines were tailored to the specific challenges I encounter in my project such as seeking feedback from other people''}. P3 specifically mentioned four guidelines about data (listed 15-18 in the Table 1 in the manuscript) and thought of the following improvements: \emph{``I would collect more annotated data from diverse populations and incentivize underrepresented groups to participate in data annotation''.} An action plan was also devised by P1, who recognized that, \emph{``I need an expert in different areas of assessments, because I am probably not in the right position to do that.''} Other participants expressed the need to see how other team members completed the guidelines. For example, P4 stated, \emph{``I want to see how others in a similar role to mine have answered the guidelines''.} In fact,  sharing team members answers in real-time could indeed help reduce the effort required to go through the guidelines. However, this suggestion comes with trade-offs. On one hand, sharing answers among team members not only helps reduce the required effort to go through the guidelines but also helps alleviate the ``blank page syndrome'', also known as ``writer's block''~\cite{bastug2017phenomenological}, which refers to the inability to begin or continue writing due to a lack of ideas, motivation, or confidence. On the other hand, providing team members' answers might hinder an individual's creativity and limit diverse perspectives in the way guidelines are implemented.




