% This file was created with Citavi 6.14.0.0

@proceedings{.2009,
 year = {2009},
 title = {Proceedings of the International AAAI Conference on Web and Social Media}
}


@article{Abbeel.2004,
 abstract = {We consider learning in a Markov decision process where we are not explicitly given a reward function, but where instead we can observe an expert demonstrating the task that we want to learn to perform. This setting is useful in applications (such as the task of driving) where it may be difficult to write down an explicit reward function specifying exactly how different desiderata should be traded off. We think of the expert as trying to maximize a reward function that is expressible as a linear combination of known features, and give an algorithm for learning the task demonstrated by the expert. Our algorithm is based on using {\textquotedbl}inverse reinforcement learning{\textquotedbl} to try to recover the unknown reward function. We show that our algorithm terminates in a small number of iterations, and that even though we may never recover the expert's reward function, the policy output by the algorithm will attain performance close to that of the expert, where here performance is measured with respect to the expert's unknown reward function.},
 author = {Abbeel, Pieter and Ng, Andrew Y.},
 year = {2004},
 title = {Apprenticeship learning via inverse reinforcement learning},
 journal = {ICML}
}


@article{Abrams.2019,
 abstract = {From hacking the Clinton campaign to spreading propaganda, here's what we know about how Russia meddled in the 2016 election.},
 author = {Abrams, Abigail},
 year = {18 April 2019},
 title = {Here's what we know so far about {R}ussia's 2016 meddling},
 url = {https://time.com/5565991/russia-influence-2016-election/},
 keywords = {T: Russian Misinformation},
 urldate = {26 July 2022},
 journal = {Time},
 file = {Abrams 18 04 2019 - Here's What We Know So:Attachments/Abrams 18 04 2019 - Here's What We Know So.pdf:application/pdf}
}


@misc{Akimenko.2021,
 author = {Akimenko, V. and Petraitis, D. and Dauk{\v{s}}as, V. and Liubinavi{\v{c}}ius, B.},
 date = {2021},
 title = {{ZAPAD} 2021 Communication Analysis: Messages, Narratives, (Dis)Information},
 keywords = {M: Qualitative Analysis;T: Russian Misinformation},
 address = {Riga},
 urldate = {08/03/2022},
 institution = {{NATO Strategic Communications Centre of Excellence}},
 file = {637951218199431051:Attachments/637951218199431051.pdf:application/pdf}
}


@article{Alieva.2022,
 author = {Alieva, Iuliia and Moffitt, J. D. and Carley, Kathleen M.},
 year = {2022},
 title = {How disinformation operations against {R}ussian opposition leader {A}lexei {N}avalny influence the international audience on {T}witter},
 keywords = {T: Russian Misinformation},
 pages = {80},
 volume = {12},
 number = {1},
 issn = {1869-5450},
 doi = {10.1007/s13278-022-00908-6},
 file = {Alieva{\_}2022{\_}Article{\_}HowDisinformationOperationsAga:Attachments/Alieva{\_}2022{\_}Article{\_}HowDisinformationOperationsAga.pdf:application/pdf},
 journal = {Soc. Netw. Anal. Min.}
}


@article{Allcott.2017,
 author = {Allcott, Hunt and Gentzkow, Matthew},
 year = {2017},
 title = {Social Media and Fake News in the 2016 Election},
 keywords = {T: Fake News},
 pages = {211--236},
 volume = {31},
 number = {2},
 issn = {0895-3309},
 doi = {10.1257/jep.31.2.211},
 file = {Allcott, Gentzkow 2017 - Social Media and Fake News:Attachments/Allcott, Gentzkow 2017 - Social Media and Fake News.pdf:application/pdf},
 journal = {Journal of Economic Perspectives}
}


@article{Allen.2020,
 abstract = {{\textquotedbl}Fake news,{\textquotedbl} broadly defined as false or misleading information masquerading as legitimate news, is frequently asserted to be pervasive online with serious consequences for democracy. Using a unique multimode dataset that comprises a nationally representative sample of mobile, desktop, and television consumption, we refute this conventional wisdom on three levels. First, news consumption of any sort is heavily outweighed by other forms of media consumption, comprising at most 14.2{\%} of Americans' daily media diets. Second, to the extent that Americans do consume news, it is overwhelmingly from television, which accounts for roughly five times as much as news consumption as online. Third, fake news comprises only 0.15{\%} of Americans' daily media diet. Our results suggest that the origins of public misinformedness and polarization are more likely to lie in the content of ordinary news or the avoidance of news altogether as they are in overt fakery.},
 author = {Allen, Jennifer and Howland, Baird and Mobius, Markus and Rothschild, David and Watts, Duncan J.},
 year = {2020},
 title = {Evaluating the fake news problem at the scale of the information ecosystem},
 pages = {eaay3539},
 volume = {6},
 number = {14},
 doi = {10.1126/sciadv.aay3539},
 journal = {Sci Adv}
}


@article{Alyukov.2022,
 author = {Alyukov, Maxim},
 year = {2022},
 title = {Propaganda, authoritarianism and {R}ussia's invasion of {U}kraine},
 keywords = {T: Russian Misinformation},
 pages = {763--765},
 volume = {6},
 number = {6},
 doi = {10.1038/s41562-022-01375-x},
 file = {Alyukov{\_}NHB{\_}2022{\_}propaganda, authoritarianism and russias invasion of ukraine:Attachments/Alyukov{\_}NHB{\_}2022{\_}propaganda, authoritarianism and russias invasion of ukraine.pdf:application/pdf},
 journal = {Nat Hum Behav}
}


@article{Aral.2019,
 author = {Aral, Sinan and Eckles, Dean},
 year = {2019},
 title = {Protecting elections from social media manipulation},
 pages = {858--861},
 volume = {365},
 number = {6456},
 journal = {Science}
}


@article{Arif.2018,
 author = {Arif, Ahmer and Stewart, Leo Graiden and Starbird, Kate},
 year = {2018},
 title = {Acting the Part: Examining Information Operations Within {\#}{B}lack{L}ives{M}atter Discourse},
 doi = {10.1145/3274289},
 file = {Arif, Stewart et al. 2018 - Acting the Part:Attachments/Arif, Stewart et al. 2018 - Acting the Part.pdf:application/pdf},
 journal = {Proc. ACM Hum.-Comput. Interact.}
}


@incollection{Arroyave.2023,
 author = {Arroyave, Jes{\'u}s and Romero-Moreno, Martha},
 title = {Peace, Public Opinion and Disinformation in Colombia: Social Media and Its Role in the 2016 Plebiscite},
 keywords = {T: Russian Misinformation},
 pages = {63--77},
 publisher = {{Springer International Publishing}},
 isbn = {978-3-031-11975-0},
 editor = {Fowler-Watt, Karen and McDougall, Julian},
 booktitle = {The Palgrave Handbook of Media Misinformation},
 year = {2023},
 address = {Cham},
 doi = {10.1007/978-3-031-11976-7{\textunderscore }5}
}


@article{Badawy.2018,
 author = {Badawy, Adam and Ferrara, Emilio and Lerman, Kristina},
 year = {2018},
 title = {Analyzing the digital traces of political manipulation: The 2016 {R}ussian interference {T}witter campaign},
 keywords = {T: Russian Misinformation},
 doi = {10.1109/ASONAM.2018.8508646},
 file = {Badawy, Ferrara et al. 2018 - Analyzing the Digital Traces:Attachments/Badawy, Ferrara et al. 2018 - Analyzing the Digital Traces.pdf:application/pdf},
 journal = {ASONAM}
}


@article{Badawy.2019,
 author = {Badawy, Adam and Lerman, Kristina and Ferrara, Emilio},
 year = {2019},
 title = {Who falls for online political manipulation?},
 keywords = {T: Russian Misinformation},
 doi = {10.1145/3308560.3316494},
 file = {Badawy, Lerman et al. 2019 - Who Falls for Online Political:Attachments/Badawy, Lerman et al. 2019 - Who Falls for Online Political.pdf:application/pdf},
 journal = {WWW}
}


@article{Bail.2020,
 abstract = {There is widespread concern that Russia and other countries have launched social-media campaigns designed to increase political divisions in the United States. Though a growing number of studies analyze the strategy of such campaigns, it is not yet known how these efforts shaped the political attitudes and behaviors of Americans. We study this question using longitudinal data that describe the attitudes and online behaviors of 1,239 Republican and Democratic Twitter users from late 2017 merged with nonpublic data about the Russian Internet Research Agency (IRA) from Twitter. Using Bayesian regression tree models, we find no evidence that interaction with IRA accounts substantially impacted 6 distinctive measures of political attitudes and behaviors over a 1-mo period. We also find that interaction with IRA accounts were most common among respondents with strong ideological homophily within their Twitter network, high interest in politics, and high frequency of Twitter usage. Together, these findings suggest that Russian trolls might have failed to sow discord because they mostly interacted with those who were already highly polarized. We conclude by discussing several important limitations of our study-especially our inability to determine whether IRA accounts influenced the 2016 presidential election-as well as its implications for future research on social media influence campaigns, political polarization, and computational social science.},
 author = {Bail, Christopher A. and Guay, Brian and Maloney, Emily and Combs, Aidan and Hillygus, D. Sunshine and Merhout, Friedolin and Freelon, Deen and Volfovsky, Alexander},
 year = {2020},
 title = {Assessing the {R}ussian {I}nternet {R}esearch {A}gency's impact on the political attitudes and behaviors of {A}merican {T}witter users in late 2017},
 pages = {243--250},
 volume = {117},
 number = {1},
 doi = {10.1073/pnas.1906420116},
 file = {Bail, Guay et al. 2020 - Assessing the Russian Internet Research:Attachments/Bail, Guay et al. 2020 - Assessing the Russian Internet Research.pdf:application/pdf},
 journal = {PNAS}
}


@article{BakColeman.2022,
 abstract = {Misinformation online poses a range of threats, from subverting democratic processes to undermining public health measures. Proposed solutions range from encouraging more selective sharing by individuals to removing false content and accounts that create or promote it. Here we provide a framework to evaluate interventions aimed at reducing viral misinformation online both in isolation and when used in combination. We begin by deriving a generative model of viral misinformation spread, inspired by research on infectious disease. By applying this model to a large corpus (10.5 million tweets) of misinformation events that occurred during the 2020 US election, we reveal that commonly proposed interventions are unlikely to be effective in isolation. However, our framework demonstrates that a combined approach can achieve a substantial reduction in the prevalence of misinformation. Our results highlight a practical path forward as misinformation online continues to threaten vaccination efforts, equity and democratic processes around the globe.},
 author = {Bak-Coleman, Joseph B. and Kennedy, Ian and Wack, Morgan and Beers, Andrew and Schafer, Joseph S. and Spiro, Emma S. and Starbird, Kate and West, Jevin D.},
 year = {2022},
 title = {Combining interventions to reduce the spread of viral misinformation},
 keywords = {Inspiration;T: Mitigating Misinformation},
 doi = {10.1038/s41562-022-01388-6},
 file = {Bak-Coleman, Kennedy et al. 2022 - Combining interventions to reduce:Attachments/Bak-Coleman, Kennedy et al. 2022 - Combining interventions to reduce.pdf:application/pdf},
 journal = {Nat Hum Behav}
}


@article{Bar.2023,
 abstract = {The social media platform {\textquotedbl}Parler{\textquotedbl} has emerged into a prominent fringe community where a significant part of the user base are self-reported supporters of QAnon, a far-right conspiracy theory alleging that a cabal of elites controls global politics. QAnon is considered to have had an influential role in the public discourse during the 2020 U.S. presidential election. However, little is known about QAnon supporters on Parler and what sets them aside from other users. Building up on social identity theory, we aim at profiling the characteristics of QAnon supporters on Parler. We analyze a large-scale dataset with more than 600,000 profiles of English-speaking users on Parler. Based on users' profiles, posts, and comments, we then extract a comprehensive set of user features, linguistic features, network features, and content features. This allows us to perform user profiling and understand to what extent these features discriminate between QAnon and non-QAnon supporters on Parler. Our analysis is three-fold: (1) We quantify the number of QAnon supporters on Parler, finding that 34,913 users (5.5{\%} of all users) openly report to support the conspiracy. (2) We examine differences between QAnon vs. non-QAnon supporters. We find that QAnon supporters differ statistically significantly from non-QAnon supporters across multiple dimensions. For example, they have, on average, a larger number of followers, followees, and posts, and thus have a large impact on the Parler network. (3) We use machine learning to identify which user characteristics discriminate QAnon from non-QAnon supporters. We find that user features, linguistic features, network features, and content features, can - to a large extent - discriminate QAnon vs. non-QAnon supporters on Parler. In particular, we find that user features are highly discriminatory, followed by content features and linguistic features.},
 author = {B{\"a}r, Dominik and Pr{\"o}llochs, Nicolas and Feuerriegel, Stefan},
 year = {2023},
 title = {Finding {Q}s: {P}rofiling {QA}non supporters on {P}arler},
 keywords = {M: Stance of Users;M: User profiling},
 file = {B{\"a}r, Pr{\"o}llochs et al. 18 05 2022 - Finding Qs:Attachments/B{\"a}r, Pr{\"o}llochs et al. 18 05 2022 - Finding Qs.pdf:application/pdf},
 journal = {ICWSM}
}


@article{Bar.2023b,
 author = {B{\"a}r, Dominik and Pr{\"o}llochs, Nicolas and Feuerriegel, Stefan},
 year = {2023},
 title = {New threats to society from free-speech social media platforms},
 issn = {0001-0782},
 journal = {Commun. ACM}
}


@article{BBC.2022,
 abstract = {Social media accounts using pictures copied from famous and unknown people are tweeting in favour of Russia.},
 author = {Gragnani, Juliana and Arora, Medhavi and Ali, Seraj},
 year = {2022},
 title = {{U}kraine war: The stolen faces used to promote {V}ladimir {P}utin},
 url = {https://www.bbc.com/news/blogs-trending-61351342},
 keywords = {T: Russian Misinformation},
 urldate = {6 September 2022},
 journal = {BBC News},
 file = {Ukraine war 05 10 2022:Attachments/Ukraine war 05 10 2022.pdf:application/pdf}
}


@article{BBC.Energy.2022,
 abstract = {At a summit in Prague, 27 countries are asked to agree measures to protect consumers from soaring bills.},
 author = {Kirby, P.},
 year = {6 October 2022},
 title = {{EU} leaders consider how to cap gas prices},
 url = {https://www.bbc.com/news/world-europe-63130645},
 urldate = {11 October 2022},
 file = {EU leaders consider how 10 06 2022:Attachments/EU leaders consider how 10 06 2022.pdf:application/pdf},
 journal = {BBC News}
}


@article{Bessi.2016,
 author = {Bessi, Alessandro and Ferrara, Emilio},
 year = {2016},
 title = {Social bots distort the 2016 {U.S.} Presidential election online discussion},
 keywords = {M: Network;M: Plots;M: Sentiment;M: Stance of Users;T: Bots Influence;T: Influence of Users},
 volume = {21},
 number = {11},
 doi = {10.5210/fm.v21i11.7090},
 file = {Bessi, Ferrara 2016 - Social bots distort the 2016:Attachments/Bessi, Ferrara 2016 - Social bots distort the 2016.pdf:application/pdf;Bessi - social bots distort the 2016 us presidential election online discussion 2016:Attachments/Bessi - social bots distort the 2016 us presidential election online discussion 2016.pdf:application/pdf},
 journal = {FM}
}


@misc{Botometer.Python,
 author = {OSoMe},
 title = {Botometer {P}ython {API}},
 url = {https://github.com/IUNetSci/botometer-python}
}


@misc{BotSentinel.2022,
 author = {{Bot Sentinel}},
 year = {2022},
 title = {Platform developed to detect and track political bots, trollbots, and untrustworthy accounts},
 url = {https://botsentinel.com},
 urldate = {5 December 2022}
}


@article{Bruhl.2022,
 abstract = {Unbekannte missbrauchen die Marke der {\glqq}S{\"u}ddeutschen Zeitung{\grqq} f{\"u}r prorussische Propaganda.},
 author = {Br{\"u}hl, Jannis and Hurtz, Simon and Heubl, Ben},
 year = {09 May 2022},
 title = {{D}esinformation: {P}ropaganda mit gef{\"a}lschten {SZ}-{V}ideos},
 url = {https://www.sueddeutsche.de/politik/desinformation-russische-propaganda-sz-fakes-1.5651531},
 urldate = {06 September 2022},
 journal = {S{\"u}ddeutsche Zeitung},
 file = {Br{\"u}hl, Hurtz et al. 09 05 2022 - Desinformation:Attachments/Br{\"u}hl, Hurtz et al. 09 05 2022 - Desinformation.pdf:application/pdf}
}


@article{Burger.2011,
 author = {Burger, J. D. and Henderson, J. and Kim, G. and Zarrella, G.},
 year = {2011},
 title = {Discriminating gender on {T}witter},
 keywords = {M: User profiling},
 journal = {EMNLP}
}


@article{Bushwick.2022,
 abstract = {Scientific American is the essential guide to the most awe-inspiring advances in science and technology, explaining how they change our understanding of the world and shape our lives.},
 author = {Bushwick, Sophie},
 year = {03/08/2022},
 title = {{R}ussia's Information War Is Being Waged on Social Media Platforms},
 url = {https://www.scientificamerican.com/article/russia-is-having-less-success-at-spreading-social-media-disinformation/},
 keywords = {T: Russian Misinformation},
 urldate = {03/08/2022},
 journal = {Scientific American},
 file = {Bushwick 03 08 2022 - Russia's Information War Is Being:Attachments/Bushwick 03 08 2022 - Russia's Information War Is Being.pdf:application/pdf}
}


@article{Caldarelli.2020,
 author = {Caldarelli, Guido and de Nicola, Rocco and {Del Vigna}, Fabio and Petrocchi, Marinella and Saracco, Fabio},
 year = {2020},
 title = {The role of bot squads in the political propaganda on {T}witter},
 pages = {81},
 volume = {3},
 number = {1},
 doi = {10.1038/s42005-020-0340-4},
 file = {Caldarelli, Nicola et al. 2020 - The role of bot squads:Attachments/Caldarelli, Nicola et al. 2020 - The role of bot squads.pdf:application/pdf},
 journal = {Commun Phys}
}


@article{Cha.2010,
 author = {Cha, Meeyoung and Haddadi, Hamed and Benevenuto, Fabricio and Gummadi, Krishna},
 year = {2010},
 title = {Measuring User Influence in {T}witter: The Million Follower Fallacy},
 journal = {ICWSM}
}


@article{Chatzakou.2017,
 author = {Chatzakou, D. and Kourtellis, N. and Blackburn, J. and de Cristofaro, E. and Stringhini, G. and Vakali, A.},
 year = {2017},
 title = {Mean birds: {D}etecting aggression and bullying on {T}witter},
 keywords = {M: User profiling},
 journal = {WebSci}
}


@article{Chatzakou.2017b,
 author = {Chatzakou, Despoina and Kourtellis, Nicolas and Blackburn, Jeremy and de Cristofaro, Emiliano and Stringhini, Gianluca and Vakali, Athena},
 year = {2017},
 title = {Measuring {\#}{G}amer{G}ate: {A} tale of hate, sexism, and bullying},
 doi = {10.1145/3041021.3053890},
 journal = {WWW Companion}
}


@article{Chawla.2002,
 author = {Chawla, N. V. and Bowyer, K. W. and Hall, L. O. and Kegelmeyer, W. P.},
 year = {2002},
 title = {SMOTE: synthetic minority over-sampling technique},
 pages = {321--357},
 volume = {16},
 journal = {JAIR}
}


@article{Chen.2016,
 author = {Chen, Tianqi and Guestrin, Carlos},
 year = {2016},
 title = {{XGB}oost: {A} scalable tree boosting system},
 doi = {10.1145/2939672.2939785},
 journal = {KDD}
}


@article{Chen.2021,
 abstract = {Social media platforms attempting to curb abuse and misinformation have been accused of political bias. We deploy neutral social bots who start following different news sources on Twitter, and track them to probe distinct biases emerging from platform mechanisms versus user interactions. We find no strong or consistent evidence of political bias in the news feed. Despite this, the news and information to which U.S. Twitter users are exposed depend strongly on the political leaning of their early connections. The interactions of conservative accounts are skewed toward the right, whereas liberal accounts are exposed to moderate content shifting their experience toward the political center. Partisan accounts, especially conservative ones, tend to receive more followers and follow more automated accounts. Conservative accounts also find themselves in denser communities and are exposed to more low-credibility content.},
 author = {Chen, Wen and Pacheco, Diogo and Yang, Kai-Cheng and Menczer, Filippo},
 year = {2021},
 title = {Neutral bots probe political bias on social media},
 pages = {5580},
 volume = {12},
 number = {1},
 doi = {10.1038/s41467-021-25738-6},
 file = {Chen, Pacheco et al. 2021 - Neutral bots probe political bias:Attachments/Chen, Pacheco et al. 2021 - Neutral bots probe political bias.pdf:application/pdf},
 journal = {Nat Commun}
}


@misc{Chen.2022,
 abstract = {On February 24, 2022, Russia invaded Ukraine. In the days that followed, reports kept flooding in from layman to news anchors of a conflict quickly escalating into war. Russia faced immediate backlash and condemnation from the world at large. While the war continues to contribute to an ongoing humanitarian and refugee crisis in Ukraine, a second battlefield has emerged in the online space, both in the use of social media to garner support for both sides of the conflict and also in the context of information warfare. In this paper, we present a collection of over 63 million tweets, from February 22, 2022 through March 8, 2022 that we are publishing for the wider research community to use. This dataset can be found at https://github.com/echen102/ukraine-russia and will be maintained and regularly updated as the war continues to unfold. Our preliminary analysis already shows evidence of public engagement with Russian state sponsored media and other domains that are known to push unreliable information; the former saw a spike in activity on the day of the Russian invasion. Our hope is that this public dataset can help the research community to further understand the ever evolving role that social media plays in information dissemination, influence campaigns, grassroots mobilization, and much more, during a time of conflict.},
 author = {Chen, Emily and Ferrara, Emilio},
 date = {2022},
 title = {Tweets in time of conflict: {A} public dataset tracking the {T}witter discourse on the war between {U}kraine and {R}ussia},
 keywords = {Dataset},
 doi = {russia},
 file = {Chen, Ferrara 14 03 2022 - Tweets in Time of Conflict:Attachments/Chen, Ferrara 14 03 2022 - Tweets in Time of Conflict.pdf:application/pdf}
}


@article{CNN.2022,
 abstract = {Russian President Vladimir Putin announced a military operation in Ukraine early Thursday, and Ukraine's Interior Ministry has said Russia's {\textquotedbl}invasion has begun{\textquotedbl} with missile strikes on Kyiv. Follow here for the latest updates.},
 author = {Lister, Tim and Kesa, Julia},
 year = {24 February 2022},
 title = {{U}kraine says it was attacked through {R}ussian, {B}elarus and {C}rimea borders},
 url = {https://edition.cnn.com/europe/live-news/ukraine-russia-news-02-23-22/h_82bf44af2f01ad57f81c0760c6cb697c},
 urldate = {08 September 2022},
 journal = {CNN},
 file = {By a href= profiles:Attachments/By a href= profiles.pdf:application/pdf}
}


@article{Das.2014,
 author = {Das, Sanmay and Lavoie, Allen},
 year = {2014},
 title = {The effects of feedback on human behavior in social media: {A}n inverse reinforcement learning model},
 journal = {AAMAS}
}


@article{DaSanMartino.2019,
 author = {{Da San Martino}, Giovanni and Yu, Seunghak and Barr{\'o}n-Cede{\~n}o, Alberto and Petrov, Rostislav and Nakov, Preslav},
 year = {2019},
 title = {Fine-grained analysis of propaganda in news articles},
 doi = {10.18653/v1/D19-1565},
 file = {Da San Martino, Yu et al. - Fine-Grained Analysis of Propaganda:Attachments/Da San Martino, Yu et al. - Fine-Grained Analysis of Propaganda.pdf:application/pdf},
 journal = {EMNLP}
}


@article{DelVicario.2016,
 abstract = {The wide availability of user-provided content in online social media facilitates the aggregation of people around common interests, worldviews, and narratives. However, the World Wide Web (WWW) also allows for the rapid dissemination of unsubstantiated rumors and conspiracy theories that often elicit rapid, large, but naive social responses such as the recent case of Jade Helm 15--where a simple military exercise turned out to be perceived as the beginning of a new civil war in the United States. In this work, we address the determinants governing misinformation spreading through a thorough quantitative analysis. In particular, we focus on how Facebook users consume information related to two distinct narratives: scientific and conspiracy news. We find that, although consumers of scientific and conspiracy stories present similar consumption patterns with respect to content, cascade dynamics differ. Selective exposure to content is the primary driver of content diffusion and generates the formation of homogeneous clusters, i.e., {\textquotedbl}echo chambers.{\textquotedbl} Indeed, homogeneity appears to be the primary driver for the diffusion of contents and each echo chamber has its own cascade dynamics. Finally, we introduce a data-driven percolation model mimicking rumor spreading and we show that homogeneity and polarization are the main determinants for predicting cascades' size.},
 author = {{Del Vicario}, Michela and Bessi, Alessandro and Zollo, Fabiana and Petroni, Fabio and Scala, Antonio and Caldarelli, Guido and Stanley, H. Eugene and Quattrociocchi, Walter},
 year = {2016},
 title = {The spreading of misinformation online},
 keywords = {Inspiration;T: Spreading of Misinfo},
 pages = {554--559},
 volume = {113},
 number = {3},
 doi = {10.1073/pnas.1517441113},
 file = {Del Vicario, Bessi et al. 2016 - The spreading of misinformation online:Attachments/Del Vicario, Bessi et al. 2016 - The spreading of misinformation online.pdf:application/pdf},
 journal = {PNAS}
}


@article{Doroshenko.2021,
 author = {Doroshenko, Larissa and Lukito, Josephine},
 year = {2021},
 title = {Trollfare: {R}ussia's disinformation cmpaign during military conflict in {U}kraine},
 keywords = {T: Russian Misinformation},
 pages = {4662--4689},
 volume = {15},
 file = {LARISSA DOROSHENKO, JOSEPHINE LUKITO - Trollfare Russia's Disinformation Campaign:Attachments/LARISSA DOROSHENKO, JOSEPHINE LUKITO - Trollfare Russia's Disinformation Campaign.pdf:application/pdf},
 journal = {Int. J. Commun.}
}


@misc{Dubow.2021,
 author = {Dubow, B. and {Lucas, E: Morris, J}},
 date = {2 December 2021},
 title = {Jabbed in the back: mapping {R}ussian and {C}hinese information operations during {COVID}-19},
 url = {https://cepa.org/jabbed-in-the-back-mapping-russian-and-chinese-information-operations-during-covid-19/},
 keywords = {T: Russian Misinformation},
 urldate = {26 July 2022},
 institution = {CEPA},
 file = {Dubow 2021 - jabbed in the back- mapping russian and chinese information operations during covid19:Attachments/Dubow 2021 - jabbed in the back- mapping russian and chinese information operations during covid19.pdf:application/pdf;tmp8392:Attachments/tmp8392.pdf:application/pdf}
}


@article{Ducci.2020,
 author = {Ducci, Francesco and Kraus, Mathias and Feuerriegel, Stefan},
 year = {2020},
 title = {Cascade-{LSTM}: {A} tree-structured neural classifier for detecting misinformation cascades},
 doi = {10.1145/3394486.3403317},
 journal = {KDD}
}


@article{Dutta.2021,
 author = {Dutta, Upasana and Hanscom, Rhett and Zhang, Jason Shuo and Han, Richard and Lehman, Tamara and Lv, Qin and Mishra, Shivakant},
 year = {2021},
 title = {Analyzing {T}witter Users' Behavior Before and After Contact by the {R}ussia's {I}nternet {R}esearch {A}gency},
 pages = {1--24},
 volume = {5},
 number = {CSCW1},
 doi = {10.1145/3449164},
 file = {Dutta 2021 Analyzing Twitter user behvaior before and after contact by the IRA:Attachments/Dutta 2021 Analyzing Twitter user behvaior before and after contact by the IRA.pdf:application/pdf},
 journal = {Proc. ACM Hum.-Comput. Interact.}
}


@article{Dzubur.2022,
 abstract = {Millions of people around the world continue to express their view

on various topics on Twitter everyday. Such data is frequently used

to generate and analyze networks of users, tweets and hashtags

based on specific actions, such as tweets, retweets, mentions etc.

In our study we focus on tweets related to the Russo-Ukrainian

conflict. We combine sentiment and network analysis approaches

to produce various important insights into the discussion of the

conflict. We focused on the most influential actors in the debate

as well as uncovering communities of users or hashtags which

correspond to either side of the conflict. We discovered that the

vast majority of users express support for Ukraine, and that the

most important accounts belong to political leaders (e.g. Volodymyr

Zelenskyy), relevant organizations (NATO) or media outlets, who

actively report on the conflict (Kremlin News). Similarly, most of

the relevant hashtags are used predominantly in a pro-Ukraine

context, while many of them appear in tweets supporting Russia as

well (e.g. {\#}war, {\#}Russia). We have identified numerous communities

within the networks, which belong to discussions about the conflict

being held in various languages or about various aspects, that

the war indirectly affects (e.g. finance {\&} cryptocurencies). Apart

from a few very evidently pro-Russia communities, all the groups

express support for Ukraine to at least some degree. Future research

should focus on more thoughtful data collection and consequently

thorough analysis of various aspects of the networks.},
 author = {D{\v{z}}ubur, Benjamin and Trojer, {\v{Z}}iga and Zrim{\v{s}}ek, Ur{\v{s}}a},
 year = {2022},
 title = {Semantic Analysis of {R}usso-{U}krainian War {T}weet Networks},
 url = {https://www.scores.si/assets/papers/6258.pdf},
 keywords = {nicht zitieren},
 journal = {Proceedings of Student Computing Research Symposium}
}


@article{Eady.2023,
 author = {Eady, G. and Paskhalis, T. and Zilinsky, J. and Bonneau, Richard and Nagler, J. and Tucker, Joshua A.},
 year = {2023},
 title = {Exposure to the {R}ussian {I}nternet {R}esearch {A}gency foreign influence campaign on {T}witter in the 2016 {US} election and its relationship to attitudes and voting behavior},
 keywords = {T: Russian Misinformation},
 pages = {62},
 volume = {14},
 file = {s41467-022-35576-9:Attachments/s41467-022-35576-9.pdf:application/pdf},
 journal = {Nat Commun}
}


@article{ElSherief.2018,
 author = {ElSherief, Mai and Nilizadeh, Shirin and Nguyen, Dana and Vigna, Giovanni and Belding, Elizabeth},
 year = {2018},
 title = {Peer to peer hate: {H}ate speech instigators and their targets},
 keywords = {M: User profiling},
 journal = {ICWSM}
}


@article{Ferrara.2016,
 author = {Ferrara, Emilio and Varol, Onur and Davis, Clayton and Menczer, Filippo and Flammini, Alessandro},
 year = {2016},
 title = {The rise of social bots},
 pages = {96--104},
 volume = {59},
 number = {7},
 issn = {0001-0782},
 doi = {10.1145/2818717},
 file = {Ferrara, Varol et al. 2016 - The rise of social bots:Attachments/Ferrara, Varol et al. 2016 - The rise of social bots.pdf:application/pdf},
 journal = {Commun. ACM}
}


@article{Ferrara.2017,
 author = {Ferrara, Emilio},
 year = {2017},
 title = {Disinformation and social bot operations in the run up to the 2017 {F}rench presidential election},
 keywords = {M: Plots;T: Bots Influence;T: Fake News;T: Spreading of Misinfo},
 volume = {22},
 number = {8},
 doi = {10.5210/fm.v22i8.8005},
 file = {Ferrara 2017 - Disinformation and social bot operations:Attachments/Ferrara 2017 - Disinformation and social bot operations.pdf:application/pdf},
 journal = {FM}
}


@book{FowlerWatt.2023,
 year = {2023},
 title = {The Palgrave Handbook of Media Misinformation},
 address = {Cham},
 publisher = {{Springer International Publishing}},
 isbn = {978-3-031-11975-0},
 editor = {Fowler-Watt, Karen and McDougall, Julian},
 doi = {10.1007/978-3-031-11976-7}
}


@article{Freelon.2020,
 abstract = {Evidence from an analysis of Twitter data reveals that Russian social media trolls exploited racial and political identities to infiltrate distinct groups of authentic users, playing on their group identities. The groups affected spanned the ideological spectrum, suggesting the importance of coordinated counter-responses from diverse coalitions of users. Image by PhotoMIX-Company on Pixabay Research Questions},
 author = {Freelon, Deen and Lokot, Tetyana},
 year = {2020},
 title = {{R}ussian disinformation campaigns on {T}witter target political communities across the spectrum. Collaboration between opposed political groups might be the most effective way to counter it},
 url = {https://misinforeview.hks.harvard.edu/article/russian-disinformation-campaigns-on-twitter/},
 keywords = {T: Russian Misinformation},
 volume = {1},
 number = {1},
 doi = {10.37016/mr-2020-003},
 file = {Freelon, Lokot 2020 - Russian disinformation campaigns on Twitter:Attachments/Freelon, Lokot 2020 - Russian disinformation campaigns on Twitter.pdf:application/pdf},
 journal = {HKS Misinfo Review}
}


@article{Freitas.2015,
 author = {Freitas, Carlos and Benevenuto, Fabricio and Ghosh, Saptarshi and Veloso, Adriano},
 year = {2015},
 title = {Reverse engineering socialbot infiltration strategies in {T}witter},
 doi = {10.1145/2808797.2809292},
 file = {Freitas 2015 reverse engineering socialbot infiltration strategies in twitter:Attachments/Freitas 2015 reverse engineering socialbot infiltration strategies in twitter.pdf:application/pdf},
 journal = {ASONAM}
}


@article{Gallotti.2020,
 abstract = {During COVID-19, governments and the public are fighting not only a pandemic but also a co-evolving infodemic-the rapid and far-reaching spread of information of questionable quality. We analysed more than 100 million Twitter messages posted worldwide during the early stages of epidemic spread across countries (from 22 January to 10 March 2020) and classified the reliability of the news being circulated. We developed an Infodemic Risk Index to capture the magnitude of exposure to unreliable news across countries. We found that measurable waves of potentially unreliable information preceded the rise of COVID-19 infections, exposing entire countries to falsehoods that pose a serious threat to public health. As infections started to rise, reliable information quickly became more dominant, and Twitter content shifted towards more credible informational sources. Infodemic early-warning signals provide important cues for misinformation mitigation by means of adequate communication strategies.},
 author = {Gallotti, Riccardo and Valle, Francesco and Castaldo, Nicola and Sacco, Pierluigi and de Domenico, Manlio},
 year = {2020},
 title = {Assessing the risks of `infodemics' in response to {COVID}-19 epidemics},
 pages = {1285--1293},
 volume = {4},
 number = {12},
 doi = {10.1038/s41562-020-00994-6},
 journal = {Nat Hum Behav}
}


@article{Garrett.2013,
 author = {Garrett, R. Kelly and Weeks, Brian E.},
 year = {2013},
 title = {The promise and peril of real-time corrections to political misperceptions},
 doi = {10.1145/2441776.2441895},
 journal = {CSCW}
}


@article{Geissler.2022,
 abstract = {The Russian invasion of Ukraine in February 2022 was accompanied by a large-scale propaganda campaign. Here, we analyze the spread of Russian propaganda on social media. For this, we collected N = 349,455 messages from Twitter with pro-Russian content. Our findings suggest that pro-Russian messages were mainly disseminated through a systematic, coordinated propaganda campaign. Overall, pro-Russian content received {\~{}}251,000 retweets and thereby reached around 14.4 million users, primarily in countries such as India, South Africa, and the United States. We further provide evidence that bots played a disproportionate role in the dissemination of propaganda and amplified its proliferation. Overall, 20.28{\%} of the spreaders are classified as bots, most of which were created in the beginning of the invasion. Together, our results highlight the new threats to society that originate from coordinated propaganda campaigns on social media in modern warfare. Our results also suggest that curbing bots may be an effective strategy to mitigate such campaigns.},
 author = {Geissler, Dominique and B{\"a}r, Dominik and Pr{\"o}llochs, Nicolas and Feuerriegel, Stefan},
 year = {2022},
 title = {Russian propaganda on social media during the 2022 invasion of Ukraine},
 file = {Geissler, B{\"a}r et al. 08 11 2022 - Russian propaganda on social media:Attachments/Geissler, B{\"a}r et al. 08 11 2022 - Russian propaganda on social media.pdf:application/pdf},
 arxivID = {2211.04154}
}


@misc{Geocoder.2013,
 author = {Carriere, Denis},
 year = {2013},
 title = {Geocoder},
 url = {https://geocoder.readthedocs.io}
}


@misc{Geopandas.2022,
 abstract = {Python tools for geographic data},
 author = {Jordahl, Kelsey and {van den Bossche}, Joris and Fleischmann, Martin and McBride, James and Wasserman, Jacob and Richards, Matt and Badaracco, Adrian Garcia and Gerard, Jeffrey and Snow, Alan D. and Tratner, Jeff and Perry, Matthew and Farmer, Carson and Hjelle, Geir Arne and Ward, Brendan and Cochran, Micah and Taves, Mike and Gillies, Sean and Culbertson, Lucas and Bartos, Matt and Caria, Giacomo and Eubank, Nick and sangarshanan and Flavin, John and Rey, Sergio and maxalbert and Bilogur, Aleksey and Ren, Christopher and Arribas-Bel, Dani and Mesejo-Le{\'o}n, Daniel and Wasser, Leah},
 year = {2022},
 title = {Geopandas v0.11.1},
 url = {https://geopandas.org/en/stable/},
 urldate = {7 October 2022},
 publisher = {Zenodo},
 doi = {10.5281/ZENODO.2585848}
}


@inproceedings{Gephi.2009,
 author = {Bastian, M. and Heymann, S. and {{\&} Jacomy}, M.},
 title = {Gephi: An Open Source Software for Exploring and Manipulating Networks},
 url = {https://ojs.aaai.org/index.php/ICWSM/article/view/13937},
 urldate = {15.09.2022},
 pages = {361--362},
 volume = {3(1)},
 booktitle = {Proceedings of the International AAAI Conference on Web and Social Media},
 year = {2009}
}


@article{Goel.2016,
 author = {Goel, Sharad and Anderson, Ashton and Hofman, Jake and Watts, Duncan J.},
 year = {2016},
 title = {The Structural Virality of Online Diffusion},
 pages = {180--196},
 volume = {62},
 number = {1},
 issn = {0025-1909},
 doi = {10.1287/mnsc.2015.2158},
 journal = {Management Science}
}


@article{Golovchenko.2018,
 author = {Golovchenko, Yevgeniy and Hartmann, Mareike and Adler-Nissen, Rebecca},
 year = {2018},
 title = {State, media and civil society in the information warfare over {U}kraine: {C}itizen curators of digital disinformation},
 keywords = {T: Russian Misinformation},
 pages = {975--994},
 volume = {94},
 number = {5},
 issn = {0020-5850},
 doi = {10.1093/ia/iiy148},
 file = {Golovchenko, Hartmann et al. 2018 - State, media and civil society:Attachments/Golovchenko, Hartmann et al. 2018 - State, media and civil society.pdf:application/pdf},
 journal = {International Affairs}
}


@article{Golovchenko.2020,
 author = {Golovchenko, Yevgeniy},
 year = {2020},
 title = {Measuring the scope of pro-{K}remlin disinformation on {T}witter},
 pages = {176},
 volume = {7},
 number = {1},
 doi = {10.1057/s41599-020-00659-9},
 journal = {Humanit Soc Sci Commun}
}


@article{Golovchenko.2020b,
 abstract = {The International Journal of Press/Politics 2020.25:357-389},
 author = {Golovchenko, Yevgeniy and Buntain, Cody and Eady, G. and {Brown, M., A.} and Tucker, Joshua A.},
 year = {2020},
 title = {Cross-Platform State Propaganda: Russian Trolls on Twitter and YouTube during the 2016 U.S. Presidential Election},
 url = {https://journals.sagepub.com/doi/pdf/10.1177/1940161220912682},
 urldate = {23/06/2023},
 volume = {25},
 number = {3},
 file = {Russian Trolls on Twitter and YouTube during the 2016 U.S:Attachments/Russian Trolls on Twitter and YouTube during the 2016 U.S.pdf:application/pdf}
}


@article{GonzalezBailon.2021,
 abstract = {Information manipulation is widespread in today's media environment. Online networks have disrupted the gatekeeping role of traditional media by allowing various actors to influence the public agenda; they have also allowed automated accounts (or bots) to blend with human activity in the flow of information. Here, we assess the impact that bots had on the dissemination of content during two contentious political events that evolved in real time on social media. We focus on events of heightened political tension because they are particularly susceptible to information campaigns designed to mislead or exacerbate conflict. We compare the visibility of bots with human accounts, verified accounts, and mainstream news outlets. Our analyses combine millions of posts from a popular microblogging platform with web-tracking data collected from two different countries and timeframes. We employ tools from network science, natural language processing, and machine learning to analyze the diffusion structure, the content of the messages diffused, and the actors behind those messages as the political events unfolded. We show that verified accounts are significantly more visible than unverified bots in the coverage of the events but also that bots attract more attention than human accounts. Our findings highlight that social media and the web are very different news ecosystems in terms of prevalent news sources and that both humans and bots contribute to generate discrepancy in news visibility with their activity.},
 author = {Gonz{\'a}lez-Bail{\'o}n, Sandra and de Domenico, Manlio},
 year = {2021},
 title = {Bots are less central than verified accounts during contentious political events},
 pages = {e2013443118},
 volume = {118},
 number = {11},
 doi = {10.1073/pnas.2013443118},
 file = {Gonz{\'a}lez-Bail{\'o}n, Domenico 2021 - Bots are less central:Attachments/Gonz{\'a}lez-Bail{\'o}n, Domenico 2021 - Bots are less central.pdf:application/pdf},
 journal = {PNAS}
}


@article{Gorrell.2018,
 author = {Gorrell, Genevieve and Greenwood, Mark and Roberts, Ian and Maynard, Diana and Bontcheva, Kalina},
 year = {2018},
 title = {Twits, twats and twaddle: {T}rends in online abuse towards {UK} politicians},
 keywords = {M: User profiling},
 journal = {ICWSM}
}


@article{Grcar.2017,
 abstract = {Social media are an important source of information about the political issues, reflecting, as well as influencing, public mood. We present an analysis of Twitter data, collected over 6 weeks before the Brexit referendum, held in the UK in June 2016. We address two questions: what is the relation between the Twitter mood and the referendum outcome, and who were the most influential Twitter users in the pro- and contra-Brexit camps? First, we construct a stance classification model by machine learning methods, and are then able to predict the stance of about one million UK-based Twitter users. The demography of Twitter users is, however, very different from the demography of the voters. By applying a simple age-adjusted mapping to the overall Twitter stance, the results show the prevalence of the pro-Brexit voters, something unexpected by most of the opinion polls. Second, we apply the Hirsch index to estimate the influence, and rank the Twitter users from both camps. We find that the most productive Twitter users are not the most influential, that the pro-Brexit camp was four times more influential, and had considerably larger impact on the campaign than the opponents. Third, we find that the top pro-Brexit communities are considerably more polarized than the contra-Brexit camp. These results show that social media provide a rich resource of data to be exploited, but accumulated knowledge and lessons learned from the opinion polls have to be adapted to the new data sources.},
 author = {Gr{\v{c}}ar, Miha and Cherepnalkoski, Darko and Mozeti{\v{c}}, Igor and {Kralj Novak}, Petra},
 year = {2017},
 title = {Stance and influence of {T}witter users regarding the {B}rexit referendum},
 keywords = {M: Stance of Users;T: Influence of Users},
 pages = {6},
 volume = {4},
 doi = {10.1186/s40649-017-0042-6},
 file = {Gr{\v{c}}ar, Cherepnalkoski et al. 2017 - Stance and influence of Twitter:Attachments/Gr{\v{c}}ar, Cherepnalkoski et al. 2017 - Stance and influence of Twitter.pdf:application/pdf},
 journal = {Comput Soc Netw}
}


@article{Guess.2020,
 abstract = {Although commentators frequently warn about echo chambers, little is known about the volume or slant of political misinformation that people consume online, the effects of social media and fact checking on exposure, or the effects of political misinformation on behaviour. Here, we evaluate these questions for websites that publish factually dubious content, which is often described as fake news. Survey and web-traffic data from the 2016 US presidential campaign show that supporters of Donald Trump were most likely to visit these websites, which often spread through Facebook. However, these websites made up a small share of people's information diets on average and were largely consumed by a subset of Americans with strong preferences for pro-attitudinal information. These results suggest that the widespread speculation about the prevalence of exposure to untrustworthy websites has been overstated.},
 author = {Guess, Andrew M. and Nyhan, Brendan and Reifler, Jason},
 year = {2020},
 title = {Exposure to untrustworthy websites in the 2016 {US} election},
 keywords = {Inspiration;T: Spreading of Misinfo},
 pages = {472--480},
 volume = {4},
 number = {5},
 doi = {10.1038/s41562-020-0833-x},
 file = {Guess 2020 exposure to untrustworthy websites in the 2016 US election:Attachments/Guess 2020 exposure to untrustworthy websites in the 2016 US election.pdf:application/pdf},
 journal = {Nat Hum Behav}
}


@article{Hanley.06102022,
 abstract = {The coverage of the Russian invasion of Ukraine has varied widely between Western, Russian, and Chinese media ecosystems with propaganda, disinformation, and narrative spins present in all three. By utilizing the normalized pointwise mutual information metric, differential sentiment analysis, word2vec models, and partially labeled Dirichlet allocation, we present a quantitative analysis of the differences in coverage amongst these three news ecosystems. We find that while the Western press outlets have focused on the military and humanitarian aspects of the war, Russian media have focused on the purported justifications for the {\textquotedbl}special military operation{\textquotedbl} such as the presence in Ukraine of {\textquotedbl}bio-weapons{\textquotedbl} and {\textquotedbl}neo-nazis{\textquotedbl}, and Chinese news media have concentrated on the conflict's diplomatic and economic consequences. Detecting the presence of several Russian disinformation narratives in the articles of several Chinese outlets, we finally measure the degree to which Russian media has influenced Chinese coverage across Chinese outlets' news articles, Weibo accounts, and Twitter accounts. Our analysis indicates that since the Russian invasion of Ukraine, Chinese state media outlets have increasingly cited Russian outlets as news sources and spread Russian disinformation narratives.},
 author = {Hanley, Hans W. A. and Kumar, Deepak and Durumeric, Zakir},
 title = {{\textquotedbl}A Special Operation{\textquotedbl}: A Quantitative Approach to Dissecting and  Comparing Different Media Ecosystems' Coverage of the {R}usso-{U}krainian War},
 file = {Hanley, Kumar et al. 06 10 2022 - A Special Operation:Attachments/Hanley, Kumar et al. 06 10 2022 - A Special Operation.pdf:application/pdf},
 arxivID = {2210.03016v1}
}


@misc{Hanley.28052022,
 abstract = {In the buildup to and in the weeks following the Russian Federation's invasion of Ukraine, Russian disinformation outlets output torrents of misleading and outright false information. In this work, we study the coordinated information campaign to understand the most prominent disinformation narratives touted by the Russian government to English-speaking audiences. To do this, we first perform sentence-level topic analysis using the large-language model MPNet on articles published by nine different Russian disinformation websites and the new Russian {\textquotedbl}fact-checking{\textquotedbl} website waronfakes.com. We show that smaller websites like katehon.com were highly effective at producing topics that were later echoed by other disinformation sites. After analyzing the set of Russian information narratives, we analyze their correspondence with narratives and topics of discussion on the r/Russia and 10 other political subreddits. Using MPNet and a semantic search algorithm, we map these subreddits' comments to the set of topics extracted from our set of disinformation websites, finding that 39.6{\%} of r/Russia comments corresponded to narratives from Russian disinformation websites, compared to 8.86{\%} on r/politics.},
 author = {Hanley, Hans W. A. and Kumar, Deepak and Durumeric, Zakir},
 date = {28/05/2022},
 title = {Happenstance: Utilizing Semantic Search to Track {R}ussian State Media Narratives about the {R}usso-{U}krainian War On {R}eddit},
 url = {https://arxiv.org/pdf/2205.14484},
 keywords = {M: topic modelling;T: Russian Misinformation},
 file = {Hanley, Kumar et al. 28 05 2022 - Happenstance:Attachments/Hanley, Kumar et al. 28 05 2022 - Happenstance.pdf:application/pdf}
}


@misc{Haq.2022,
 abstract = {Online Social Networks (OSNs) play a significant role in information sharing during a crisis. The data collected during such a crisis can reflect the large scale public opinions and sentiment. In addition, OSN data can also be used to study different campaigns that are employed by various entities to engineer public opinions. Such information sharing campaigns can range from spreading factual information to propaganda and misinformation. We provide a Twitter dataset of the 2022 Russo-Ukrainian conflict. In the first release, we share over 1.6 million tweets shared during the 1st week of the crisis.},
 author = {Haq, Ehsan-Ul and Tyson, Gareth and Lee, Lik-Hang and Braud, Tristan and Hui, Pan},
 date = {06/03/2022},
 title = {{T}witter Dataset for 2022 {R}usso-{U}krainian Crisis},
 url = {https://arxiv.org/pdf/2203.02955},
 file = {Haq, Tyson et al. 06 03 2022 - Twitter Dataset for 2022 Russo-Ukrainian:Attachments/Haq, Tyson et al. 06 03 2022 - Twitter Dataset for 2022 Russo-Ukrainian.pdf:application/pdf}
}


@article{Hristakieva.2022,
 author = {Hristakieva, Kristina and Cresci, Stefano and {Da San Martino}, Giovanni and Conti, Mauro and Nakov, Preslav},
 year = {2022},
 title = {The spread of propaganda by coordinated communities on social media},
 doi = {10.1145/3501247.3531543},
 file = {Hristakieva 2022 spread of propganda by coordinated communities on social media:Attachments/Hristakieva 2022 spread of propganda by coordinated communities on social media.pdf:application/pdf;Hristakieva, Cresci et al. 2022 - The spread of propaganda:Attachments/Hristakieva, Cresci et al. 2022 - The spread of propaganda.pdf:application/pdf},
 journal = {WebSci}
}


@article{Hua.2020,
 author = {Hua, Y. and Naaman, M. and Ristenpart, T.},
 year = {2020},
 title = {Characterizing {T}witter users who engage in adversarial interactions against political candidates},
 keywords = {M: User profiling},
 journal = {CHI}
}


@article{Im.2020,
 author = {Im, Jane and Chandrasekharan, Eshwar and Sargent, Jackson and Lighthammer, Paige and Denby, Taylor and Bhargava, Ankit and Hemphill, Libby and Jurgens, David and Gilbert, Eric},
 year = {2020},
 title = {Still out there: {M}odeling and identifying {R}ussian troll accounts on {T}witter},
 keywords = {T: Troll Detection},
 file = {Im 2020 Still out there, modeling and identifyin russian troll accounts on Twitter:Attachments/Im 2020 Still out there, modeling and identifyin russian troll accounts on Twitter.pdf:application/pdf},
 journal = {WebSci}
}


@article{Jakubik.2023,
 abstract = {The storming of the U.S. Capitol on January 6, 2021 has led to the killing of 5 people and is widely regarded as an attack on democracy. The storming was largely coordinated through social media networks such as Parler. Yet little is known regarding how users interacted on Parler during the storming of the Capitol. In this work, we examine the emotion dynamics on Parler during the storming with regard to heterogeneity across time and users. For this, we segment the user base into different groups (e.g., Trump supporters and QAnon supporters). We use affective computing (Kratzwald et al. 2018) to infer the emotions in the contents, thereby allowing us to provide a comprehensive assessment of online emotions. Our evaluation is based on a large-scale dataset from Parler, comprising of 717,300 posts from 144,003 users. We find that the user base responded to the storming of the Capitol with an overall negative sentiment. Akin to this, Trump supporters also expressed a negative sentiment and high levels of unbelief. In contrast to that, QAnon supporters did not express a more negative sentiment during the storming. We further provide a cross-platform analysis and compare the emotion dynamics on Parler and Twitter. Our findings point at a comparatively less negative response to the incidents on Parler compared to Twitter accompanied by higher levels of disapproval and outrage. Our contribution to research is three-fold: (1) We identify online emotions that were characteristic of the storming; (2) we assess emotion dynamics across different user groups on Parler; (3) we compare the emotion dynamics on Parler and Twitter. Thereby, our work offers important implications for actively managing online emotions to prevent similar incidents in the future.},
 author = {Jakubik, Johannes and V{\"o}ssing, Michael and B{\"a}r, Dominik and Pr{\"o}llochs, Nicolas and Feuerriegel, Stefan},
 year = {2023},
 title = {Online Emotions During the Storming of the {U}.{S}. Capitol: {E}vidence from the Social Media Network {P}arler},
 file = {Jakubik, V{\"o}ssing et al. 08 04 2022 - Online Emotions During the Storming:Attachments/Jakubik, V{\"o}ssing et al. 08 04 2022 - Online Emotions During the Storming.pdf:application/pdf},
 arxivID = {2204.04245v3},
 journal = {ICWSM}
}


@article{Jin.2014,
 author = {Jin, Fang and Wang, Wei and Zhao, Liang and Dougherty, Edward and Cao, Yang and Lu, Chang-Tien and Ramakrishnan, Naren},
 year = {2014},
 title = {Misinformation Propagation in the Age of {T}witter},
 keywords = {T: Russian Misinformation},
 pages = {90--94},
 volume = {47},
 number = {12},
 issn = {0018-9162},
 doi = {10.1109/MC.2014.361},
 file = {Jin-2014-Misinformation propagation in the age of twitter:Attachments/Jin-2014-Misinformation propagation in the age of twitter.pdf:application/pdf},
 journal = {Computer}
}


@book{Jowett.2012,
 year = {2012},
 title = {Propaganda {\&} persuasion},
 url = {https://hiddenhistorycenter.org/wp-content/uploads/2016/10/PropagandaPersuasion2012.pdf},
 price = {{\pounds}39.99},
 address = {Los Angeles},
 urldate = {09/09/2022},
 edition = {5th},
 publisher = {SAGE},
 file = {Propaganda {\&} persuasion 2012:Attachments/Propaganda {\&} persuasion 2012.pdf:application/pdf;PropagandaPersuasion2012:Attachments/PropagandaPersuasion2012.pdf:application/pdf}
}


@incollection{Jowett.Chapter1.2012,
 author = {Jowett, Garth and O'Donnell, Victoria},
 title = {Chapter 1: {W}hat is propaganda, and how does it differ from persuasion?},
 publisher = {SAGE},
 booktitle = {Propaganda {\&} persuasion},
 year = {2012},
 address = {Los Angeles}
}


@incollection{Jowett.Chapter2.2012,
 author = {Jowett, Garth and O'Donnell, Victoria},
 title = {Chapter 2:  {P}ropaganda through the ages},
 publisher = {SAGE},
 booktitle = {Propaganda {\&} persuasion},
 year = {2012},
 address = {Los Angeles}
}


@article{Kaelbling.1996,
 author = {Kaelbling, Leslie Pack and Littman, Michael L. and Moore, Andrew W.},
 year = {1996},
 title = {Reinforcement learning: {A} survey},
 pages = {237--285},
 volume = {4},
 journal = {JAIR}
}


@article{Kawintiranon.2021,
 abstract = {naacl 2021},
 author = {Kawintiranon, Kornraphop and Singh, Lisa},
 year = {2021},
 title = {Knowledge Enhanced Masked Language Model for Stance Detection},
 keywords = {M: Stance of Users},
 file = {Knowledge Enhanced Masked Language Model for Stance Detection:Attachments/Knowledge Enhanced Masked Language Model for Stance Detection.pdf:application/pdf},
 journal = {NAACL}
}


@article{Khalid.2020,
 author = {Khalid, Osama and Srinivasan, Padmini},
 year = {2020},
 title = {Style matters! {I}nvestigating linguistic style in online communities},
 doi = {10.1609/icwsm.v14i1.7306},
 file = {Khalid 2020 style matters:Attachments/Khalid 2020 style matters.pdf:application/pdf},
 journal = {ICWSM}
}


@article{Kofman.2015,
 author = {Kofman, Michael and Rojansky, Matthew},
 year = {2015},
 title = {A closer look at {R}ussia's {\textquotedbl}Hybrid War{\textquotedbl}},
 url = {https://www.files.ethz.ch/isn/190090/5-KENNAN%20CABLE-ROJANSKY%20KOFMAN.pdf},
 keywords = {T: Russian Misinformation},
 urldate = {19/12/2022},
 file = {tmp2E2B:Attachments/tmp2E2B.pdf:application/pdf},
 journal = {Woodrow Wilson International Center for Scholars}
}


@article{KornraphopKawintiranon.,
 abstract = {naacl 2021},
 author = {{Kornraphop Kawintiranon} and {Lisa Singh}},
 title = {Knowledge Enhanced Masked Language Model for Stance Detection},
 url = {https://aclanthology.org/2021.naacl-main.376.pdf},
 keywords = {M: Stance of Users},
 urldate = {05/10/2023},
 file = {Knowledge Enhanced Masked Language Model for Stance Detection (2):Attachments/Knowledge Enhanced Masked Language Model for Stance Detection (2).pdf:application/pdf}
}


@book{Kozyreva.2022,
 author = {Kozyreva, Anastasia and Lorenz-Spreen, Philipp and Herzog, Stefan Michael and Ecker, Ullrich K. H. and Lewandowsky, Stephan and Hertwig, Ralph},
 year = {2022},
 title = {Toolbox of interventions against online misinformation and manipulation},
 publisher = {PsyArXiv},
 doi = {10.31234/osf.io/x8ejt},
 file = {Kozyreva, Lorenz-Spreen et al. 2022 - Toolbox of Interventions Against Online:Attachments/Kozyreva, Lorenz-Spreen et al. 2022 - Toolbox of Interventions Against Online.pdf:application/pdf}
}


@article{Kudugunta.2018,
 author = {Kudugunta, Sneha and Ferrara, Emilio},
 year = {2018},
 title = {Deep neural networks for bot detection},
 volume = {467},
 journal = {Information Sciences}
}


@article{Kunda.1990,
 author = {Kunda, Z.},
 year = {1990},
 title = {The case for motivated reasoning},
 pages = {480},
 volume = {108},
 number = {3},
 journal = {Psychological Bulletin}
}


@article{Lampos.2016,
 author = {Lampos, Vasileios and Aletras, Nikolaos and Geyti, Jens K. and Zou, Bin and Cox, Ingemar J.},
 year = {2016},
 title = {Inferring the socioeconomic status of social media users based on behaviour and language},
 keywords = {M: User profiling},
 journal = {ECIR}
}


@book{Levy.1997,
 author = {L{\'e}vy, Pierre},
 year = {1997},
 title = {Collective Intelligence: {M}ankind's emerging world in cyberspace},
 address = {New York, NY},
 publisher = {{Plenum/Harper Collins}}
}


@article{Lorenz.2011,
 author = {Lorenz, Jan and Rauhut, Heiko and Schweitzer, Frank and Helbing, Dirk},
 year = {2011},
 title = {How social influence can undermine the wisdom of crowd effect},
 pages = {9020--9025},
 volume = {108},
 number = {22},
 journal = {PNAS}
}


@article{Luceri.2019,
 author = {Luceri, Luca and Deb, Ashok and Badawy, Adam and Ferrara, Emilio},
 year = {2019},
 title = {Red bots do it better: {C}omparative analysis of social bot partisan behavior},
 keywords = {T: Bots Influence},
 doi = {10.1145/3308560.3316735},
 file = {Luceri 2019 red bots do it better:Attachments/Luceri 2019 red bots do it better.pdf:application/pdf},
 journal = {WWW}
}


@article{Luceri.2020,
 abstract = {Proceedings of the Fourteenth International AAAI Conference on Web and Social Media (ICWSM 2020)},
 author = {Luceri, Luca and Giordano, Silvia and Ferrara, Emilio},
 year = {2020},
 title = {Detecting troll behavior via inverse reinforcement learning: {A} case study of {R}ussian trolls in the 2016 {US} election},
 keywords = {M: IRL;T: Troll Detection},
 file = {Luca Luceri, Silvia Giordano et al. - Detecting Troll Behavior via Inverse:Attachments/Luca Luceri, Silvia Giordano et al. - Detecting Troll Behavior via Inverse.pdf:application/pdf},
 journal = {ICWSM}
}


@article{Maarouf.2022,
 abstract = {Online hate speech is responsible for violent attacks such as, e.g., the Pittsburgh synagogue shooting in 2018, thereby posing a significant threat to vulnerable groups and society in general. However, little is known about what makes hate speech on social media go viral. In this paper, we collected N = 25,219 Twitter cascades with 65,946 retweets and classify them as hateful vs. normal. Using a generalized linear regression, we then estimate differences in the spread of hateful vs. normal content based on author and content variables. We thereby identify important determinants that explain differences in the spreading of hateful vs. normal content. For example, hateful content authored by verified users is disproportionally more likely to go viral than hateful content from non-verified ones: hateful content from a verified user (as opposed to normal content) has a 3.5 times larger cascade size, a 3.2 times longer cascade lifetime, and a 1.2 times larger structural virality. Altogether, we offer novel insights into the virality of hate speech on social media.},
 author = {Maarouf, Abdurahman and Pr{\"o}llochs, Nicolas and Feuerriegel, Stefan},
 year = {2022},
 title = {The Virality of Hate Speech on Social Media},
 file = {Maarouf, Pr{\"o}llochs et al. 25 10 2022 - The Virality of Hate Speech:Attachments/Maarouf, Pr{\"o}llochs et al. 25 10 2022 - The Virality of Hate Speech.pdf:application/pdf},
 arxivID = {2210.13770}
}


@article{Maarouf.2023,
 abstract = {Online propaganda poses a severe threat to the integrity of societies. However, existing datasets for detecting online propaganda have a key limitation: they were annotated using weak labels that can be noisy and even incorrect. To address this limitation, our work makes the following contributions: (1) We present HQP: a novel dataset (N=30,000) for detecting online propaganda with high-quality labels. To the best of our knowledge, HQP is the first dataset for detecting online propaganda that was created through human annotation. (2) We show empirically that state-of-the-art language models fail in detecting online propaganda when trained with weak labels (AUC: 64.03). In contrast, state-of-the-art language models can accurately detect online propaganda when trained with our high-quality labels (AUC: 92.25), which is an improvement of {\~{}}44{\%}. (3) To address the cost of labeling, we extend our work to few-shot learning. Specifically, we show that prompt-based learning using a small sample of high-quality labels can still achieve a reasonable performance (AUC: 80.27). Finally, we discuss implications for the NLP community to balance the cost and quality of labeling. Crucially, our work highlights the importance of high-quality labels for sensitive NLP tasks such as propaganda detection.},
 author = {Maarouf, Abdurahman and B{\"a}r, Dominik and Geissler, Dominique and Feuerriegel, Stefan},
 year = {2023},
 title = {HQP: A Human-Annotated Dataset for Detecting Online Propaganda},
 file = {Maarouf, B{\"a}r et al. 28 04 2023 - HQP A Human-Annotated Dataset:Attachments/Maarouf, B{\"a}r et al. 28 04 2023 - HQP A Human-Annotated Dataset.pdf:application/pdf},
 arxivID = {2304.14931}
}


@article{Magelinski.2022,
 author = {Magelinski, Thomas and Ng, Lynnette and Carley, Kathleen},
 year = {2022},
 title = {Synchronized Action Framework for Detection of Coordination on Social Media},
 volume = {1},
 number = {2},
 doi = {10.54501/jots.v1i2.30},
 journal = {JOTS}
}


@article{Maity.2018,
 author = {Maity, Suman Kalyan and Chakraborty, Aishik and Goyal, Pawan and Mukherjee, Animesh},
 year = {2018},
 title = {Opinion Conflicts: {A}n Effective Route to Detect Incivility in {T}witter},
 keywords = {M: User profiling},
 pages = {1--27},
 volume = {2},
 number = {CSCW},
 doi = {10.1145/3274386},
 journal = {Proc. ACM Hum.-Comput. Interact.}
}


@misc{Marineau.17072022,
 abstract = {Russian interference deeply marked the 2016 American presidential election. Four years later, let's analyze the form and impact of disinformation coming from Russia.},
 author = {Marineau, Sophie},
 year = {17/07/2022},
 title = {Fact check {US}: What is the impact of {R}ussian interference in the {US} presidential election?},
 url = {https://theconversation.com/fact-check-us-what-is-the-impact-of-russian-interference-in-the-us-presidential-election-146711},
 keywords = {T: Russian Misinformation},
 urldate = {26/07/2022}
}


@article{Mason.2002,
 author = {Mason, S. J. and Graham, N. E.},
 year = {2002},
 title = {Areas beneath the Relative Operating Characteristics ({ROC}) and Levels ({ROL}) Curves: {S}tatistical Significance and Interpretation},
 pages = {2145--2166},
 volume = {128},
 journal = {Quarterly Journal of the Royal Meteorological Society}
}


@article{Massey.1951,
 author = {Massey, Frank J.},
 year = {1951},
 title = {The {K}olmogorov-{S}mirnov test for goodness of fit},
 pages = {68--78},
 volume = {46},
 number = {253},
 issn = {1537-274X},
 doi = {10.1080/01621459.1951.10500769},
 journal = {JASA}
}


@article{Mejias.2017,
 author = {Mejias, Ulises A. and Vokuev, Nikolai E.},
 year = {2017},
 title = {Disinformation and the media: the case of {R}ussia and {U}kraine},
 keywords = {T: Russian Misinformation},
 pages = {1027--1042},
 volume = {39},
 number = {7},
 issn = {0163-4437},
 doi = {10.1177/0163443716686672},
 file = {Mejias - Disinformation and the media the case of russia and ukraine 2017:Attachments/Mejias - Disinformation and the media the case of russia and ukraine 2017.pdf:application/pdf},
 journal = {Media, Culture {\&} Society}
}


@article{Meng.2018,
 abstract = {Relying on diffusion of innovation theory, this study examines the impacts of perceived message features and network characteristics on size (i.e., the number of retweets a message receives) and structural virality (i.e., quantified distinction between broadcast and viral diffusion) of information diffusion on Twitter. The study collected 425 unique tweets posted by CDC during a 17-week period and constructed a diffusion tree for each unique tweet. Findings indicated that, with respect to message features, perceived efficacy after reading a tweet positively predicted diffusion size of the tweet, whereas perceived susceptibility to a health condition after reading a tweet positively predicted structural virality of the tweet. Perceived negative emotion positively predicted both size and structural virality. With respect to network features, the level of involvement of brokers in diffusing a tweet increased the tweet's structural virality. Theoretical and practical implications were discussed on disseminating health information via broadcasting and viral diffusion on social media.},
 author = {Meng, Jingbo and Peng, Wei and Tan, Pang-Ning and Liu, Wuyu and Cheng, Ying and Bae, Arram},
 year = {2018},
 title = {Diffusion size and structural virality: The effects of message and network features on spreading health information on {T}witter},
 keywords = {M: Network;T: Spreading of Misinfo},
 pages = {111--120},
 volume = {89},
 issn = {0747-5632},
 doi = {10.1016/j.chb.2018.07.039},
 file = {Meng, Peng et al. 2018 - Diffusion size and structural virality:Attachments/Meng, Peng et al. 2018 - Diffusion size and structural virality.pdf:application/pdf},
 journal = {Comput Human Behav}
}


@article{Microsoft.,
 author = {Microsoft},
 title = {Defending {U}kraine: Early Lessons from the Cyber War},
 keywords = {T: Russian Misinformation},
 urldate = {07 July 2022},
 file = {Microsoft - Defending Ukraine:Attachments/Microsoft - Defending Ukraine.pdf:application/pdf}
}


@article{Miller.2019,
 author = {Miller, Daniel Taninecz},
 year = {2019},
 title = {Topics and emotions in Russian Twitter propaganda},
 volume = {24},
 number = {5},
 doi = {10.5210/fm.v24i5.9638},
 journal = {FM}
}


@misc{Miller.2022,
 author = {Miller, C. and Inskip, C. and Marsh, O. and Arcostanzo, F. and Weir, D.},
 date = {2022},
 title = {{\#}{IS}tand{W}ith{R}ussia {\#}{IS}tand{W}ith{P}utin Message-based community detection on {T}witter},
 url = {https://glavcom.ua/pub/pdf/49/4935/message-based-community-detection-on-twitter.pdf},
 keywords = {T: Russian Misinformation},
 urldate = {26/07/2022},
 institution = {{CASM Technology}},
 file = {CASM - message-based-community-detection-on-twitter:Attachments/CASM - message-based-community-detection-on-twitter.pdf:application/pdf}
}


@misc{Miller.2022b,
 abstract = {What can we learn about the next information operation from pro-Kremlin hashtags on Twitter about the Ukraine invasion?},
 author = {Miller, C. and Reffin, J.},
 year = {2022},
 title = {{\#}{I}standwith{R}ussia - Anatomy of a Pro-{K}remlin Influence Operation},
 url = {https://www.isdglobal.org/digital_dispatches/istandwithrussia-anatomy-of-a-pro-kremlin-influence-operation/},
 keywords = {T: Russian Misinformation},
 urldate = {03/08/2022},
 file = {Miller, Reffin 2022 - {\#}IstandwithRussia:Attachments/Miller, Reffin 2022 - {\#}IstandwithRussia.pdf:application/pdf}
}


@article{MisinformationReview.2022,
 author = {Linvill, D. L. and Warren, P. L.},
 year = {2022},
 title = {Engaging with others: How the {IRA} coordinated information operation made friends},
 journal = {HKS Misinfo Review}
}


@article{Mitchell.2021,
 abstract = {Fully 70{\%} of U.S. adult Twitter news consumers say they have used Twitter to follow live news events, up from 59{\%} who said this in 2015.},
 author = {Mitchell, Amy and Shearer, Elisa and Stocking, Galen},
 year = {2021},
 title = {News on {T}witter: {C}onsumed by most users and trusted by many},
 url = {https://www.pewresearch.org/journalism/2021/11/15/news-on-twitter-consumed-by-most-users-and-trusted-by-many/},
 urldate = {12 October 2022},
 file = {Mitchell, Shearer et al. 15 11 2021 - News on Twitter:Attachments/Mitchell, Shearer et al. 15 11 2021 - News on Twitter.pdf:application/pdf},
 journal = {Pew Research Center}
}


@article{Mohammad.2013,
 abstract = {Even though considerable attention has been given to the polarity of words (positive and negative) and the creation of large polarity lexicons, research in emotion analysis has had to rely on limited and small emotion lexicons. In this paper we show how the combined strength and wisdom of the crowds can be used to generate a large, high-quality, word-emotion and word-polarity association lexicon quickly and inexpensively. We enumerate the challenges in emotion annotation in a crowdsourcing scenario and propose solutions to address them. Most notably, in addition to questions about emotions associated with terms, we show how the inclusion of a word choice question can discourage malicious data entry, help identify instances where the annotator may not be familiar with the target term (allowing us to reject such annotations), and help obtain annotations at sense level (rather than at word level). We conducted experiments on how to formulate the emotion-annotation questions, and show that asking if a term is associated with an emotion leads to markedly higher inter-annotator agreement than that obtained by asking if a term evokes an emotion.},
 author = {Mohammad, S. M. and Turney, P. D.},
 year = {2013},
 title = {Crowdsourcing a Word-Emotion Association Lexicon},
 pages = {436--465},
 volume = {29},
 number = {3},
 file = {Mohammad, Turney - Crowdsourcing a Word-Emotion Association Lexicon:Attachments/Mohammad, Turney - Crowdsourcing a Word-Emotion Association Lexicon.pdf:application/pdf},
 arxivID = {1308.6297v1},
 journal = {Computational Intelligence}
}


@article{Networkx.2008,
 author = {Hagberg, Aric A. and Schult, Daniel A. and Swart, Pieter J.},
 year = {2008},
 title = {Exploring network structure, dynamics, and function using {N}etwork{X}},
 journal = {SciPy}
}


@article{Ng.2000,
 author = {Ng, Andrew Y. and Russel, Stuart},
 year = {2000},
 title = {Algorithms for inverse reinforcement learning},
 journal = {ICML}
}


@article{Ng.2022,
 author = {Ng, Lynnette Hui Xian and Carley, Kathleen M.},
 year = {2022},
 title = {Online Coordination: Methods and Comparative Case Studies of Coordinated Groups across Four Events in the United States},
 keywords = {M: Network},
 pages = {12--21},
 doi = {10.1145/3501247.3531542},
 journal = {WebSci}
}


@article{Nguyen.2020,
 author = {Nguyen, Dat Quoc and Vu, Thanh and Nguyen, Anh Tuan},
 year = {2020},
 title = {{BERT}weet: {A} pre-trained language model for {E}nglish tweets},
 journal = {EMNLP}
}


@book{Olson.1965,
 author = {Olson, Mancur},
 year = {1965},
 title = {The logic of collective action. Public goods and the theory of groups.},
 address = {Cambridge, Mass},
 publisher = {{Harvard University Press}}
}


@misc{OpenStreetMapWiki.2021,
 author = {{OpenStreetMap Wiki}},
 year = {2021},
 title = {{OSMP}ython{T}ools},
 url = {https://wiki.openstreetmap.org/w/index.php?title=OSMPythonTools&oldid=2150829},
 urldate = {5 September 2022}
}


@article{Oremus.14072022,
 abstract = {Ukrainian officials say platforms like YouTube, Twitter and LinkedIn are no longer applying the same vigilance to Russian propaganda and disinformation efforts.},
 author = {Oremus, Bill},
 year = {14/07/2022},
 title = {{U}kraine says Big Tech has dropped the ball on {R}ussian propaganda},
 url = {https://www.washingtonpost.com/technology/2022/07/14/ukraine-takedown-requests-russia-propaganda/},
 urldate = {18/07/2022},
 journal = {The Washington Post},
 file = {Ukraine says Big Tech has 14 07 2022:Attachments/Ukraine says Big Tech has 14 07 2022.pdf:application/pdf}
}


@proceedings{Palmer.2017,
 year = {2017},
 title = {Proceedings of the 2017 Conference on Empirical Methods in Natural  Language Processing},
 address = {Stroudsburg, PA, USA},
 publisher = {{Association for Computational Linguistics}},
 editor = {Palmer, Martha and Hwa, Rebecca and Riedel, Sebastian},
 doi = {10.18653/v1/D17-1}
}


@misc{Park.24052022,
 abstract = {In this report, we describe a new data set called VoynaSlov which contains 21M+ Russian-language social media activities (i.e. tweets, posts, comments) made by Russian media outlets and by the general public during the time of war between Ukraine and Russia. We scraped the data from two major platforms that are widely used in Russia: Twitter and VKontakte (VK), a Russian social media platform based in Saint Petersburg commonly referred to as {\textquotedbl}Russian Facebook{\textquotedbl}. We provide descriptions of our data collection process and data statistics that compare state-affiliated and independent Russian media, and also the two platforms, VK and Twitter. The main differences that distinguish our data from previously released data related to the ongoing war are its focus on Russian media and consideration of state-affiliation as well as the inclusion of data from VK, which is more suitable than Twitter for understanding Russian public sentiment considering its wide use within Russia. We hope our data set can facilitate future research on information warfare and ultimately enable the reduction and prevention of disinformation and opinion manipulation campaigns. The data set is available at https://github.com/chan0park/VoynaSlov and will be regularly updated as we continuously collect more data.},
 author = {Park, Chan Young and Mendelsohn, Julia and Field, Anjalie and Tsvetkov, Yulia},
 date = {24/05/2022},
 title = {VoynaSlov: A Data Set of {R}ussian Social Media Activity during the 2022 {U}kraine-{R}ussia War},
 url = {https://arxiv.org/pdf/2205.12382},
 keywords = {Dataset},
 file = {Park, Mendelsohn et al. 24 05 2022 - VoynaSlov A Data Set:Attachments/Park, Mendelsohn et al. 24 05 2022 - VoynaSlov A Data Set.pdf:application/pdf}
}


@article{Paul.2019,
 abstract = {Social network and publishing platforms, such as Twitter, support the concept of a secret proprietary verification process, for handles they deem worthy of platform-wide public interest. In line with significant prior work which suggests that possessing such a status symbolizes enhanced credibility in the eyes of the platform audience, a verified badge is clearly coveted among public figures and brands. What are less obvious are the inner workings of the verification process and what being verified represents. This lack of clarity, coupled with the flak that Twitter received by extending aforementioned status to political extremists in 2017, backed Twitter into publicly admitting that the process and what the status represented needed to be rethought. With this in mind, we seek to unravel the aspects of a user's profile which likely engender or preclude verification. The aim of the paper is two-fold: First, we test if discerning the verification status of a handle from profile metadata and content features is feasible. Second, we unravel the features which have the greatest bearing on a handle's verification status. We collected a dataset consisting of profile metadata of all 231,235 verified English-speaking users (as of July 2018), a control sample of 175,930 non-verified English-speaking users and all their 494 million tweets over a one year collection period. Our proposed models are able to reliably identify verification status (Area under curve AUC {\textgreater} 99{\%}). We show that number of public list memberships, presence of neutral sentiment in tweets and an authoritative language style are the most pertinent predictors of verification status. To the best of our knowledge, this work represents the first attempt at discerning and classifying verification worthy users on Twitter.},
 author = {Paul, Indraneil and Khattar, Abhinav and Chopra, Shaan and Kumaraguru, Ponnurangam and Gupta, Manish},
 year = {2019},
 title = {What sets verified users apart? {I}nsights, analysis and prediction of verified users on {T}witter},
 keywords = {M: User profiling},
 file = {Paul 2019 what sets verified users apart:Attachments/Paul 2019 what sets verified users apart.pdf:application/pdf},
 journal = {WebSci}
}


@article{Pennycook.2018,
 author = {Pennycook, Gordon and Cannon, Tyrone D. and Rand, David G.},
 year = {2018},
 title = {Prior exposure increases perceived accuracy of fake news},
 pages = {1865--1880},
 volume = {147},
 journal = {Journal of Experimental Psychology: General}
}


@article{Pennycook.2021,
 abstract = {In recent years, there has been a great deal of concern about the proliferation of false and misleading news on social media1,2,3,4. Academics and practitioners alike have asked why people share such misinformation, and sought solutions to reduce the sharing of misinformation5,6,7. Here, we attempt to address both of these questions. First, we find that the veracity of headlines has little effect on sharing intentions, despite having a large effect on judgments of accuracy. This dissociation suggests that sharing does not necessarily indicate belief. Nonetheless, most participants say it is important to share only accurate news. To shed light on this apparent contradiction, we carried out four survey experiments and a field experiment on Twitter; the results show that subtly shifting attention to accuracy increases the quality of news that people subsequently share. Together with additional computational analyses, these findings indicate that people often share misinformation because their attention is focused on factors other than accuracy---and therefore they fail to implement a strongly held preference for accurate sharing. Our results challenge the popular claim that people value partisanship over accuracy8,9, and provide evidence for scalable attention-based interventions that social media platforms could easily implement to counter misinformation online.},
 author = {Pennycook, Gordon and Epstein, Ziv and Mosleh, Mohsen and Arechar, Antonio A. and Eckles, Dean and Rand, David G.},
 year = {2021},
 title = {Shifting attention to accuracy can reduce misinformation online},
 pages = {590--595},
 volume = {592},
 journal = {Nature}
}


@article{Pierri.2022,
 abstract = {Online social media represent an oftentimes unique source of information, and having access to reliable and unbiased content is crucial, especially during crises and contentious events. We study the spread of propaganda and misinformation that circulated on Facebook and Twitter during the first few months of the Russia-Ukraine conflict. By leveraging two large datasets of millions of social media posts, we estimate the prevalence of Russian propaganda and low-credibility content on the two platforms, describing temporal patterns and highlighting the disproportionate role played by superspreaders in amplifying unreliable content. We infer the political leaning of Facebook pages and Twitter users sharing propaganda and misinformation, and observe they tend to be more right-leaning than the average. By estimating the amount of content moderated by the two platforms, we show that only about 8-15{\%} of the posts and tweets sharing links to Russian propaganda or untrustworthy sources were removed. Overall, our findings show that Facebook and Twitter are still vulnerable to abuse, especially during crises: we highlight the need to urgently address this issue to preserve the integrity of online conversations.

10 pages, 8 figures, 2 tables},
 author = {Pierri, Francesco and Luceri, Luca and Jindal, Nikhil and Ferrara, Emilio},
 year = {2022},
 title = {Propaganda and misinformation on {F}acebook and {T}witter during the {R}ussian invasion of {U}kraine},
 doi = {10.48550/arXiv.2212.00419},
 arxivID = {2212.00419}
}


@article{Pierri.2022b,
 abstract = {Social media moderation policies are often at the center of public debate, and their implementation and enactment are sometimes surrounded by a veil of mystery. Unsurprisingly, due to limited platform transparency and data access, relatively little research has been devoted to characterizing moderation dynamics, especially in the context of controversial events and the platform activity associated with them. Here, we study the dynamics of account creation and suspension on Twitter during two global political events: Russia's invasion of Ukraine and the 2022 French Presidential election. Leveraging a large-scale dataset of 270M tweets shared by 16M users in multiple languages over several months, we identify peaks of suspicious account creation and suspension, and we characterize behaviours that more frequently lead to account suspension. We show how large numbers of accounts get suspended within days from their creation. Suspended accounts tend to mostly interact with legitimate users, as opposed to other suspicious accounts, often making unwarranted and excessive use of reply and mention features, and predominantly sharing spam and harmful content. While we are only able to speculate about the specific causes leading to a given account suspension, our findings shed light on patterns of platform abuse and subsequent moderation during major events.},
 author = {Pierri, Francesco and Luceri, Luca and Ferrara, Emilio},
 year = {2022},
 title = {How does {T}witter account moderation work? {D}ynamics of account creation  and suspension during major geopolitical events},
 file = {Pierri, Luceri et al. 15 09 2022 - How Does Twitter Account Moderation:Attachments/Pierri, Luceri et al. 15 09 2022 - How Does Twitter Account Moderation.pdf:application/pdf;Pierri 2022 account creation and suspension:Attachments/Pierri 2022 account creation and suspension.pdf:application/pdf},
 arxivID = {2209.07614}
}


@article{Pohl.2022,
 author = {Pohl, Janina Susanne and Seiler, Moritz Vinzent and Assenmacher, Dennis and Grimme, Christian},
 year = {2022},
 title = {A {T}witter Streaming Dataset collected before and after the Onset of the War between {R}ussia and {U}kraine in 2022},
 keywords = {Dataset},
 doi = {10.2139/ssrn.4066543},
 file = {Pohl - a twitter streaming dataset collected before and after the onset of the war between russia and ukraine in 2022 - 2022:Attachments/Pohl - a twitter streaming dataset collected before and after the onset of the war between russia and ukraine in 2022 - 2022.pdf:application/pdf},
 journal = {SSRN Journal}
}


@article{PreotiucPietro.2015,
 author = {Preotiuc-Pietro, Daniel and Volkova, Svitlana and Lampos, Vasileios and Bachrach, Yoram and Aletras, Nikolaos},
 year = {2015},
 title = {Studying user income through language, behaviour and affect in social media},
 keywords = {M: User profiling},
 pages = {e0138717},
 volume = {10},
 number = {9},
 journal = {Plos One}
}


@article{Prollochs.2023,
 author = {Pr{\"o}llochs, Nicolas and Feuerriegel, Stefan},
 year = {2023},
 title = {Mechanisms of true and false rumor sharing in social media: {W}isdom-of-crowds or herd behavior?},
 journal = {CSCW}
}


@article{Ramachandran.2007,
 author = {Ramachandran, Deepak and Amir, Eyal},
 year = {2007},
 title = {Bayesian inverse reinforcement learning},
 journal = {IJCAI}
}


@article{Rao.2010,
 author = {Rao, D. and Yarowsky, D. and Shreevats, A. and Gupta, M.},
 year = {2010},
 title = {Classifying latent user attributes in {T}witter},
 keywords = {M: User profiling},
 pages = {37--44},
 journal = {SMUC}
}


@article{Rashkin.2017,
 author = {Rashkin, Hannah and Choi, Eunsol and Jang, Jin Yea and Volkova, Svitlana and Choi, Yejin},
 year = {2017},
 title = {Truth of varying shades: {A}nalyzing language in fake news and political fact-checking},
 doi = {10.18653/v1/D17-1317},
 journal = {EMNLP}
}


@article{Ratkiewicz.2018,
 abstract = {Proceedings of the Fifth International AAAI Conference on Weblogs and Social Media},
 author = {Ratkiewicz, Jacob and Conover, Michael D. and Meiss, Mark and Goncalves, Bruno and Flammini, Alessandro and Menczer, Filippo},
 year = {2011},
 title = {Detecting and tracking political abuse in social media},
 keywords = {Inspiration;T: Spreading of Misinfo},
 file = {J. Ratkiewicz, M. D. Conover, M. Meiss, B. Goncalves, A. Flammini, F. Menczer - Detecting and Tracking Political Abuse:Attachments/J. Ratkiewicz, M. D. Conover, M. Meiss, B. Goncalves, A. Flammini, F. Menczer - Detecting and Tracking Political Abuse.pdf:application/pdf},
 journal = {ICWSM}
}


@article{Ratliff.2006,
 abstract = {Imitation learning of sequential, goal-directed behavior by standard supervised techniques is often difficult. We frame learning such behaviors as a maximum margin structured prediction problem over a space of policies. In this approach, we learn mappings from features to cost so an optimal policy in an MDP with these cost mimics the expert's behavior. Further, we demonstrate a simple, provably efficient approach to structured maximum margin learning, based on the subgradient method, that leverages existing fast algorithms for inference. Although the technique is general, it is particularly relevant in problems where A* and dynamic programming approaches make learning policies tractable in problems beyond the limitations of a QP formulation. We demonstrate our approach applied to route planning for outdoor mobile robots, where the behavior a designer wishes a planner to execute is often clear, while specifying cost functions that engender this behavior is a much more difficult task.},
 author = {Ratliff, Nathan D. and Bagnell, J. Andrew and Zinkevich, Martin A.},
 year = {2006},
 title = {Maximum margin planning},
 doi = {10.1145/1143844.1143936},
 journal = {ICML}
}


@article{Ribeiro.2018,
 author = {Ribeiro, M. and Calais, P. and Santos, Y. and Almeida, V. and {Meira Jr.}, W.},
 year = {2018},
 title = {Characterizing and detecting hateful users on {T}witter},
 keywords = {M: User profiling},
 journal = {ICWSM}
}


@article{Rivers.2014,
 author = {Rivers, Caitlin M. and Lewis, Bryan L.},
 year = {2014},
 title = {Ethical research standards in a world of big data},
 pages = {38},
 volume = {3},
 doi = {10.12688/f1000research.3-38.v2},
 file = {Rivers, Lewis 2014 - Ethical research standards:Attachments/Rivers, Lewis 2014 - Ethical research standards.pdf:application/pdf},
 journal = {F1000Res}
}


@article{Roeder.08082018,
 abstract = {Last week, FiveThirtyEight published nearly 3 million tweets sent by handles affiliated with the Internet Research Agency, a Russian ``troll factory.'' That group$\ldots$},
 author = {Roeder, Oliver},
 year = {08/08/2018},
 title = {We Gave You 3 Million {R}ussian Troll Tweets. Here's What You've Found So Far},
 url = {https://fivethirtyeight.com/features/what-you-found-in-3-million-russian-troll-tweets/},
 keywords = {T: Russian Misinformation},
 urldate = {05/07/2022},
 journal = {FiveThirtyEight},
 file = {Roeder 08 08 2018 - We Gave You 3 Million:Attachments/Roeder 08 08 2018 - We Gave You 3 Million.pdf:application/pdf}
}


@misc{Rossetti.2022,
 abstract = {Automated social media accounts, known as bots, have been shown to spread disinformation and manipulate online discussions. We study the behavior of bots on Twitter during the first impeachment of U.S. President Donald Trump. We collect over 67.7 million impeachment related tweets from 3.6 million users, along with their 53.6 million edge follower network. We find although bots represent 1{\%} of all users, they generate over 31{\%} of all impeachment related tweets. We also find bots share more disinformation, but use less toxic language than other users. Among supporters of the Qanon conspiracy theory, a popular disinformation campaign, bots have a prevalence near 10{\%}. The follower network of Qanon supporters exhibits a hierarchical structure, with bots acting as central hubs surrounded by isolated humans. We quantify bot impact using the generalized harmonic influence centrality measure. We find there are a greater number of pro-Trump bots, but on a per bot basis, anti-Trump and pro-Trump bots have similar impact, while Qanon bots have less impact. This lower impact is due to the homophily of the Qanon follower network, suggesting this disinformation is spread mostly within online echo-chambers.},
 author = {Rossetti, Michael and Zaman, Tauhid},
 date = {19/04/2022},
 title = {Bots, Disinformation, and the First {T}rump Impeachment},
 url = {http://arxiv.org/pdf/2204.08915v2},
 keywords = {T: Bots Influence},
 file = {Rossetti - Bots. Disinformation, and the first trump impeachment 2022:Attachments/Rossetti - Bots. Disinformation, and the first trump impeachment 2022.pdf:application/pdf}
}


@article{Sanovich.2017,
 author = {Sanovich, Sergey},
 title = {Computational Propaganda in {R}ussia: The Origins of Digital Misinformation},
 keywords = {T: Russian Misinformation},
 file = {download{\_}file:Attachments/download{\_}file.pdf:application/pdf},
 journal = {Oxford Internet Institute}
}


@article{Sayyadiharikandeh.2020,
 author = {Sayyadiharikandeh, Mohsen and Varol, Onur and Yang, Kai-Cheng and Flammini, Alessandro and Menczer, Filippo},
 year = {2020},
 title = {Detection of Novel Social Bots by Ensembles of Specialized Classifiers},
 keywords = {M: Botometer;T: Bots Influence},
 doi = {10.1145/3340531.3412698},
 file = {Sayyadiharikandeh, Varol et al. 2020 - Detection of Novel Social Bots:Attachments/Sayyadiharikandeh, Varol et al. 2020 - Detection of Novel Social Bots.pdf:application/pdf},
 journal = {CIKM}
}


@proceedings{SciPy.2008,
 year = {2008},
 title = {Proceedings of the 7th Python in Science Conference (SciPy2008)},
 editor = {{G{\"a}el Varoquaux} and {Travis Vaught} and {Jarrod Millman}}
}


@article{Scott.2022,
 abstract = {Russian propaganda has shifted gears as the quick march to Kyiv has turned into entrenched warfare.},
 author = {Scott, Mark},
 year = {2022},
 title = {As war in {U}kraine evolves, so do disinformation tactics},
 url = {https://www.politico.eu/article/ukraine-russia-disinformation-propaganda/},
 keywords = {T: Russian Misinformation},
 urldate = {26 July 2022},
 journal = {Politico},
 file = {As war in Ukraine evolves 03 10 2022:Attachments/As war in Ukraine evolves 03 10 2022.pdf:application/pdf}
}


@article{Shahi.2021,
 abstract = {During the COVID-19 pandemic, social media has become a home ground for misinformation. To tackle this infodemic, scientific oversight, as well as a better understanding by practitioners in crisis management, is needed. We have conducted an exploratory study into the propagation, authors and content of misinformation on Twitter around the topic of COVID-19 in order to gain early insights. We have collected all tweets mentioned in the verdicts of fact-checked claims related to COVID-19 by over 92 professional fact-checking organisations between January and mid-July 2020 and share this corpus with the community. This resulted in 1500 tweets relating to 1274 false and 226 partially false claims, respectively. Exploratory analysis of author accounts revealed that the verified twitter handle(including Organisation/celebrity) are also involved in either creating(new tweets) or spreading(retweet) the misinformation. Additionally, we found that false claims propagate faster than partially false claims. Compare to a background corpus of COVID-19 tweets, tweets with misinformation are more often concerned with discrediting other information on social media. Authors use less tentative language and appear to be more driven by concerns of potential harm to others. Our results enable us to suggest gaps in the current scientific coverage of the topic as well as propose actions for authorities and social media users to counter misinformation.},
 author = {Shahi, Gautam Kishore and Dirkson, Anne and Majchrzak, Tim A.},
 year = {2021},
 title = {An exploratory study of {COVID}-19 misinformation on {T}witter},
 keywords = {T: Spreading of Misinfo},
 pages = {100104},
 volume = {22},
 doi = {10.1016/j.osnem.2020.100104},
 file = {Shahi, Dirkson et al. 2021 - An exploratory study of COVID-19:Attachments/Shahi, Dirkson et al. 2021 - An exploratory study of COVID-19.pdf:application/pdf},
 journal = {Online Soc Netw Media}
}


@article{Shane.07092017,
 author = {Shane, Scott},
 year = {07 September 2017},
 title = {The Fake {A}mericans {R}ussia Created To Influence The Election},
 url = {https://www.nytimes.com/2017/09/07/us/politics/russia-facebook-twitter-election.html},
 keywords = {T: Russian Misinformation},
 urldate = {07 July 2022},
 journal = {The New York Times},
 file = {2017{\_}09{\_}07{\_}NYT{\_}TheFakeAmericansRussiaCreatedToInfluenceTheElection:Attachments/2017{\_}09{\_}07{\_}NYT{\_}TheFakeAmericansRussiaCreatedToInfluenceTheElection.pdf:application/pdf}
}


@article{Shao.2018,
 abstract = {The massive spread of digital misinformation has been identified as a major threat to democracies. Communication, cognitive, social, and computer scientists are studying the complex causes for the viral diffusion of misinformation, while online platforms are beginning to deploy countermeasures. Little systematic, data-based evidence has been published to guide these efforts. Here we analyze 14 million messages spreading 400 thousand articles on Twitter during ten months in 2016 and 2017. We find evidence that social bots played a disproportionate role in spreading articles from low-credibility sources. Bots amplify such content in the early spreading moments, before an article goes viral. They also target users with many followers through replies and mentions. Humans are vulnerable to this manipulation, resharing content posted by bots. Successful low-credibility sources are heavily supported by social bots. These results suggest that curbing social bots may be an effective strategy for mitigating the spread of online misinformation.},
 author = {Shao, Chengcheng and Ciampaglia, Giovanni Luca and Varol, Onur and Yang, Kai-Cheng and Flammini, Alessandro and Menczer, Filippo},
 year = {2018},
 title = {The spread of low-credibility content by social bots},
 keywords = {T: Bots Influence},
 pages = {4787},
 volume = {9},
 number = {1},
 doi = {10.1038/s41467-018-06930-7},
 file = {Shao - the spread of low-credibility content by social bots 2018:Attachments/Shao - the spread of low-credibility content by social bots 2018.pdf:application/pdf},
 journal = {Nat Commun}
}


@article{Shen.2023,
 author = {Shen, Fei and Zhang, Erkun and Zhang, Hongzhong and Ren, Wujiong and Jia, Quanxin and He, Yuan},
 year = {2023},
 title = {Examining the differences between human and bot social media accounts: A case study of the Russia-Ukraine War},
 volume = {28},
 number = {2},
 file = {Shen, Zhang et al 2023 - Examining the differences between human:Attachments/Shen, Zhang et al 2023 - Examining the differences between human.pdf:application/pdf},
 journal = {FM}
}


@article{Singh.2022,
 author = {Singh, Iknoor and Bontcheva, Kalina and Song, Xingyi and Scarton, Carolina},
 year = {2022},
 title = {Comparative Analysis of Engagement, Themes, and Causality of {U}kraine-Related Debunks and Disinformation},
 keywords = {nicht zitieren},
 journal = {SocInfo}
}


@article{Sloane.2022,
 author = {Sloane, Wendy},
 year = {2022},
 title = {{P}utin cracks down on media},
 pages = {19--22},
 volume = {33},
 number = {3},
 issn = {0956-4748},
 doi = {10.1177/09564748221121468},
 journal = {British Journalism Review}
}


@article{Smart.2022,
 abstract = {The 2022 Russian invasion of Ukraine emphasises the role social media plays in modern-day warfare, with conflict occurring in both the physical and information environments. There is a large body of work on identifying malicious cyber-activity, but less focusing on the effect this activity has on the overall conversation, especially with regards to the Russia/Ukraine Conflict. Here, we employ a variety of techniques including information theoretic measures, sentiment and linguistic analysis, and time series techniques to understand how bot activity influences wider online discourse. By aggregating account groups we find significant information flows from bot-like accounts to non-bot accounts with behaviour differing between sides. Pro-Russian non-bot accounts are most influential overall, with information flows to a variety of other account groups. No significant outward flows exist from pro-Ukrainian non-bot accounts, with significant flows from pro-Ukrainian bot accounts into pro-Ukrainian non-bot accounts. We find that bot activity drives an increase in conversations surrounding angst (with p = 2.450 x 1e-4) as well as those surrounding work/governance (with p = 3.803 x 1e-18). Bot activity also shows a significant relationship with non-bot sentiment (with p = 3.76 x 1e-4), where we find the relationship holds in both directions. This work extends and combines existing techniques to quantify how bots are influencing people in the online conversation around the Russia/Ukraine invasion. It opens up avenues for researchers to understand quantitatively how these malicious campaigns operate, and what makes them impactful.},
 author = {Smart, Bridget and Watt, Joshua and Benedetti, Sara and Mitchell, Lewis and Roughan, Matthew},
 year = {2022},
 title = {{\#}{IS}tand{W}ith{P}utin versus {\#}{IS}tand{W}ith{U}kraine: {T}he interaction of bots and humans in discussion of the {R}ussia/{U}kraine war},
 keywords = {T: Russian Misinformation},
 file = {Smart 2022 istandwithputin vs istandiwthukraine the interaction of bots and humans in discussion of the russia ulraine war:Attachments/Smart 2022 istandwithputin vs istandiwthukraine the interaction of bots and humans in discussion of the russia ulraine war.pdf:application/pdf},
 arxivID = {2208.07038v2},
 journal = {SocInfo}
}


@article{Statista.Twitter.User.2022,
 abstract = {Social network Twitter is particularly popular in the United States, where as of January 2022, the microblogging service had audience reach of 76.9 million users.},
 author = {Dixon, S.},
 year = {2022},
 title = {Countries with most {T}witter users 2022},
 url = {https://www.statista.com/statistics/242606/number-of-active-twitter-users-in-selected-countries/},
 urldate = {12 October 2022},
 journal = {Statista}
}


@article{Steger.2022,
 abstract = {Bei gemeinsamen Milit{\"a}r{\"u}bungen von Russland und Belarus im September 2021 wurde nicht nur mit schwerem Ger{\"a}t, sondern auch f{\"u}r den Informationskrieg ge{\"u}bt. Das geht aus einer aktuellen Studie eines Nato-Exzellenzzentrums hervor. Unterdessen analysiert ein aktuelles Buch, wie russische Desinformation funktioniert.},
 author = {Steger, Johannes},
 year = {2022},
 title = {Wie {R}ussland den {K}rieg im {I}nformationsraum {\"u}bte},
 url = {https://background.tagesspiegel.de/digitalisierung/wie-russland-den-krieg-im-informationsraum-uebte},
 keywords = {T: Russian Misinformation},
 file = {Tagesspiegel Background - Wie Russland den Krieg im Informationsraum {\"u}bte 2022:Attachments/Tagesspiegel Background - Wie Russland den Krieg im Informationsraum {\"u}bte 2022.pdf:application/pdf},
 journal = {Tagesspiegel Background Digitalisierung {\&} KI}
}


@article{Stella.2018,
 abstract = {Societies are complex systems, which tend to polarize into subgroups of individuals with dramatically opposite perspectives. This phenomenon is reflected-and often amplified-in online social networks, where, however, humans are no longer the only players and coexist alongside with social bots-that is, software-controlled accounts. Analyzing large-scale social data collected during the Catalan referendum for independence on October 1, 2017, consisting of nearly 4 millions Twitter posts generated by almost 1 million users, we identify the two polarized groups of Independentists and Constitutionalists and quantify the structural and emotional roles played by social bots. We show that bots act from peripheral areas of the social system to target influential humans of both groups, bombarding Independentists with violent contents, increasing their exposure to negative and inflammatory narratives, and exacerbating social conflict online. Our findings stress the importance of developing countermeasures to unmask these forms of automated social manipulation.},
 author = {Stella, Massimo and Ferrara, Emilio and de Domenico, Manlio},
 year = {2018},
 title = {Bots increase exposure to negative and inflammatory content in online social systems},
 pages = {12435--12440},
 volume = {115},
 number = {49},
 doi = {10.1073/pnas.1803470115},
 file = {Stella, Ferrara et al. 2018 - Bots increase exposure to negative:Attachments/Stella, Ferrara et al. 2018 - Bots increase exposure to negative.pdf:application/pdf},
 journal = {PNAS}
}


@article{Stieglitz.2013,
 author = {Stieglitz, Stefan and Dang-Xuan, Linh},
 year = {2013},
 title = {Emotions and information diffusion in social media: {S}entiment of microblogs and sharing behavior},
 pages = {217--248},
 volume = {29},
 number = {4},
 issn = {0742-1222},
 doi = {10.2753/MIS0742-1222290408},
 journal = {Journal of Management Information Systems}
}


@article{Stukal.2017,
 abstract = {Automated and semiautomated Twitter accounts, bots, have recently gained significant public attention due to their potential interference in the political realm. In this study, we develop a methodology for detecting bots on Twitter using an ensemble of classifiers and apply it to study bot activity within political discussions in the Russian Twittersphere. We focus on the interval from February 2014 to December 2015, an especially consequential period in Russian politics. Among accounts actively Tweeting about Russian politics, we find that on the majority of days, the proportion of Tweets produced by bots exceeds 50{\%}. We reveal bot characteristics that distinguish them from humans in this corpus, and find that the software platform used for Tweeting is among the best predictors of bots. Finally, we find suggestive evidence that one prominent activity that bots were involved in on Russian political Twitter is the spread of news stories and promotion of media who produce them.},
 author = {Stukal, Denis and Sanovich, Sergey and Bonneau, Richard and Tucker, Joshua A.},
 year = {2017},
 title = {Detecting Bots on {R}ussian Political {T}witter},
 pages = {310--324},
 volume = {5},
 number = {4},
 doi = {10.1089/big.2017.0038},
 journal = {Big Data}
}


@article{SuarezSerrato.2016,
 abstract = {Social bots can affect online communication among humans. We study this phenomenon by focusing on {\#}YaMeCanse, the most active protest hashtag in the history of Twitter in Mexico. Accounts using the hashtag are classified using the BotOrNot bot detection tool. Our preliminary analysis suggests that bots played a critical role in disrupting online communication about the protest movement.},
 author = {Su{\'a}rez-Serrato, Pablo and Roberts, Margaret E. and Davis, Clayton and Menczer, Filippo},
 year = {2016},
 title = {On the Influence of Social Bots in Online Protests},
 keywords = {T: Bots Influence},
 doi = {10.1007/978-3-319-47874-6{\textunderscore }19},
 file = {Su{\'a}rez-Serrato, Roberts et al. - On the Influence of Social:Attachments/Su{\'a}rez-Serrato, Roberts et al. - On the Influence of Social.pdf:application/pdf},
 arxivID = {1609.08239},
 journal = {SocInfo}
}


@book{Sutton.2018,
 author = {Sutton, Richard S. and Barto, Andrew G.},
 year = {2018},
 title = {Reinforcement learning: {A}n introduction},
 address = {Cambridge, Massachusetts},
 publisher = {{MIT press}}
}


@article{Tajfel.1986,
 author = {Tajfel, H. and Turner, J. C.},
 year = {1986},
 title = {The social identity theory of intergroup behavior},
 keywords = {T: social identity theory},
 pages = {7--24},
 journal = {Psychology of Intergroup Relations}
}


@misc{TheConversation.2022,
 abstract = {Government Twitter accounts are dodging restrictions on state-backed media to churn out disinformation.},
 author = {Thompson, Jay Daniel and Graham, Timothy},
 year = {07 October 2022},
 title = {Russian government accounts are using a Twitter loophole to spread disinformation},
 url = {https://theconversation.com/russian-government-accounts-are-using-a-twitter-loophole-to-spread-disinformation-178001},
 urldate = {10 October 2022},
 file = {the conversation 2022 Russian government accounts are using a Twitter loophole to spread disinformation:Attachments/the conversation 2022 Russian government accounts are using a Twitter loophole to spread disinformation.pdf:application/pdf}
}


@article{TheEconomist.2022,
 abstract = {An army of suspicious accounts began churning out pro-Russian content in March | Graphic detail},
 author = {{The Economist}},
 year = {14 May 2022},
 title = {{R}ussia is swaying {T}witter users outside the {W}est to its side},
 url = {https://www.economist.com/graphic-detail/2022/05/14/russia-is-swaying-twitter-users-outside-the-west-to-its-side?utm_medium=social-media.content.np&utm_source=twitter&utm_campaign=editorial-social&utm_content=discovery.content},
 urldate = {06 September 2022}
}


@misc{TheEconomist.Food.2022,
 abstract = {War is tipping a fragile world towards mass hunger. Fixing that is everyone's business | Leaders},
 author = {{The Economist}},
 year = {19 May 2022},
 title = {The coming food catastrophe},
 url = {https://www.economist.com/leaders/2022/05/19/the-coming-food-catastrophe},
 urldate = {19 September 2022}
}


@article{Thornton.2015,
 author = {Thornton, Rod},
 year = {2015},
 title = {The changing nature of modern warfare},
 keywords = {T: Russian Misinformation},
 pages = {40--48},
 volume = {160},
 number = {4},
 issn = {0307-1847},
 doi = {10.1080/03071847.2015.1079047},
 file = {Thornton 2015 The changing nature of modern warfare:Attachments/Thornton 2015 The changing nature of modern warfare.pdf:application/pdf},
 journal = {The RUSI Journal}
}


@article{Touretzky.1997,
 author = {Touretzky, David S. and Saksida, Lisa M.},
 year = {1997},
 title = {Operant conditioning in skinnerbots},
 pages = {219--247},
 volume = {5},
 number = {3-4},
 journal = {Adaptive Behavior}
}


@book{Treyger.2022,
 abstract = {Although portrayals of Russia's disinformation machine as organized and well-resourced are exaggerated, social media disinformation can cause serious harm to U.S. interests. This report provides recommendations to better counter this threat.{\textless}/p{\textgreater}},
 author = {Treyger, Elina and Cheravitch, Joe and Cohen, Raphael S.},
 year = {2022},
 title = {{R}ussian disinformation efforts on social media},
 url = {https://www.rand.org/pubs/research_reports/RR4373z2.html},
 keywords = {T: Russian Misinformation},
 publisher = {{RAND Corporation}},
 file = {Treyger, Cheravitch et al. 2022 - Russian Disinformation Efforts on Social:Attachments/Treyger, Cheravitch et al. 2022 - Russian Disinformation Efforts on Social.pdf:application/pdf}
}


@article{Troianovski.03042022,
 abstract = {Contradicting the Kremlin on the war in Ukraine --- even calling it a war --- is now a crime, prompting independent media to close, and Russia cut off access to Facebook, the BBC and other news sources.},
 author = {Troianovski, Anton and Safronova, Valeriya},
 year = {4 March 2022},
 title = {{R}ussia Takes Censorship to New Extremes, Stifling War Coverage},
 url = {https://www.nytimes.com/2022/03/04/world/europe/russia-censorship-media-crackdown.html},
 urldate = {09/09/2022},
 journal = {The New York Times},
 file = {Troianovski, Safronova 03 04 2022 - Russia Takes Censorship to New:Attachments/Troianovski, Safronova 03 04 2022 - Russia Takes Censorship to New.pdf:application/pdf}
}


@misc{Twitter.API.2022,
 author = {Twitter},
 year = {2022},
 title = {{T}witter {API} v2},
 url = {https://developer.twitter.com/en/docs/twitter-api},
 urldate = {4 October 2022}
}


@misc{Twitter.IRA,
 author = {Twitter},
 year = {2018},
 title = {Update on {T}witter's review of the 2016 {US} election},
 url = {https://blog.twitter.com/official/en_us/topics/company/2018/2016-election-update.html},
 urldate = {10 January 2023}
}


@article{Twitter.privacy,
 author = {Twitter},
 year = {2023},
 title = {Privacy policy},
 url = {https://twitter.com/en/privacy},
 urldate = {09 January 2023}
}


@misc{Twitter.User,
 author = {Twitter},
 title = {{T}witter {API} v2 {U}sers {E}ndpoint},
 url = {https://developer.twitter.com/en/docs/twitter-api/users/follows/api-reference/get-users-id-followers},
 urldate = {4 October 2022}
}


@misc{UN.GA.2022,
 author = {{United Nations}},
 year = {2 March 2022},
 title = {{G}eneral {A}ssembly, 11th Emergency Special Session, 5th {\&} 6th Meetings (AM {\&} PM)},
 urldate = {08/09/2022},
 file = {United Nations 1 March 2022 - As Russian Federation's Invasion:Attachments/United Nations 1 March 2022 - As Russian Federation's Invasion.pdf:application/pdf}
}


@misc{UN.SC.2016,
 author = {{United Nations}},
 date = {28 April 2016},
 title = {{S}ecurity {C}ouncil, 7683rd meeting},
 urldate = {08/09/2022}
}


@misc{UN.SC.Veto.2022,
 author = {{United Nations}},
 title = {{S}ecurity {C}ouncil, 8979th meeting},
 urldate = {12/09/2022},
 file = {United Nations - Security Council:Attachments/United Nations - Security Council.pdf:application/pdf}
}


@misc{UN.SC.War.2022,
 author = {{United Nations}},
 date = {23 February 2022},
 title = {{S}ecurity {C}ouncil, 8974th meeting},
 urldate = {08/09/2022}
}


@misc{UNHCR.2022,
 author = {{United Nations High Commissioner for Refugees}},
 year = {19 September 2022},
 title = {Situation {U}kraine Refugee Situation},
 url = {https://data.unhcr.org/en/situations/ukraine},
 urldate = {19 September 2022}
}


@article{USSenate.2019,
 author = {{US Senate}},
 year = {2019},
 title = {Report of the select committee on intelligence {U}nited {S}tates {S}enate on {R}ussian active measures campaigns and interference in the 2016 {U.S}. election volume 2: Russia's use of social media with additional views}
}


@article{Varol.2017,
 abstract = {Proceedings of the Eleventh International AAAI Conference on Web and Social Media (ICWSM 2017)},
 author = {Varol, Onur and Ferrara, Emilio and Davis, Clayton A. and Menczer, Filippo and Flammini, Alessandro},
 year = {2017},
 title = {Online human-bot interactions: {D}etection, estimation, and characterization},
 keywords = {M: Botometer;T: Bots Influence},
 file = {Onur Varol, Emilio:Attachments/Onur Varol, Emilio.pdf:application/pdf},
 journal = {ICWSM}
}


@article{Vosoughi.2018,
 abstract = {We investigated the differential diffusion of all of the verified true and false news stories distributed on Twitter from 2006 to 2017. The data comprise {\~{}}126,000 stories tweeted by {\~{}}3 million people more than 4.5 million times. We classified news as true or false using information from six independent fact-checking organizations that exhibited 95 to 98{\%} agreement on the classifications. Falsehood diffused significantly farther, faster, deeper, and more broadly than the truth in all categories of information, and the effects were more pronounced for false political news than for false news about terrorism, natural disasters, science, urban legends, or financial information. We found that false news was more novel than true news, which suggests that people were more likely to share novel information. Whereas false stories inspired fear, disgust, and surprise in replies, true stories inspired anticipation, sadness, joy, and trust. Contrary to conventional wisdom, robots accelerated the spread of true and false news at the same rate, implying that false news spreads more than the truth because humans, not robots, are more likely to spread it.},
 author = {Vosoughi, Soroush and Roy, Deb and Aral, Sinan},
 year = {2018},
 title = {The spread of true and false news online},
 keywords = {T: Fake News},
 pages = {1146--1151},
 volume = {359},
 number = {6380},
 doi = {10.1126/science.aap9559},
 file = {Vosoughi - the spread of true and false news online 2018:Attachments/Vosoughi - the spread of true and false news online 2018.pdf:application/pdf},
 journal = {Science}
}


@article{Wang.2022,
 abstract = {The COVID-19 pandemic has created unprecedented burdens on people's physical health and subjective well-being. While countries worldwide have developed platforms to track the evolution of COVID-19 infections and deaths, frequent global measurements of affective states to gauge the emotional impacts of pandemic and related policy interventions remain scarce. Using 654 million geotagged social media posts in over 100 countries, covering 74{\%} of world population, coupled with state-of-the-art natural language processing techniques, we develop a global dataset of expressed sentiment indices to track national- and subnational-level affective states on a daily basis. We present two motivating applications using data from the first wave of COVID-19 (from 1 January to 31 May 2020). First, using regression discontinuity design, we provide consistent evidence that COVID-19 outbreaks caused steep declines in expressed sentiment globally, followed by asymmetric, slower recoveries. Second, applying synthetic control methods, we find moderate to no effects of lockdown policies on expressed sentiment, with large heterogeneity across countries. This study shows how social media data, when coupled with machine learning techniques, can provide real-time measurements of affective states.},
 author = {Wang, Jianghao and Fan, Yichun and Palacios, Juan and Chai, Yuchen and Guetta-Jeanrenaud, Nicolas and Obradovich, Nick and Zhou, Chenghu and Zheng, Siqi},
 year = {2022},
 title = {Global evidence of expressed sentiment alterations during the {COVID}-19 pandemic},
 keywords = {Inspiration},
 pages = {349--358},
 volume = {6},
 number = {3},
 doi = {10.1038/s41562-022-01312-y},
 file = {Wang, Fan et al. 2022 - Global evidence of expressed sentiment:Attachments/Wang, Fan et al. 2022 - Global evidence of expressed sentiment.pdf:application/pdf;Wang Global evidence of expressed sentiment alterations during the covid 19 pandemic:Attachments/Wang Global evidence of expressed sentiment alterations during the covid 19 pandemic.pdf:application/pdf},
 journal = {Nat Hum Behav}
}


@phdthesis{Watkins.1989,
 author = {{Watkins, Christopher J. C. H.}},
 year = {1989},
 title = {Learning from delayed rewards},
 address = {Camebridge, UK},
 school = {{King's College}},
 type = {Ph.D. diss.}
}


@article{Wojcik.2018,
 author = {Wojcik, Stefan and Messing, Solomon and Smith, Aaron and Rainie, Lee and Hitlin, Paul},
 year = {2018},
 title = {Bots in the {T}wittersphere},
 url = {https://www.pewresearch.org/internet/2018/04/09/bots-in-the-twittersphere/},
 journal = {Pew Research Center}
}


@article{Yablokov.2022,
 author = {Yablokov, Ilya},
 year = {2022},
 title = {{R}ussian disinformation finds fertile ground in the {W}est},
 keywords = {T: Russian Misinformation},
 pages = {766--767},
 volume = {6},
 number = {6},
 doi = {10.1038/s41562-022-01399-3},
 file = {Yablokov 2022 - Russian disinformation finds fertile ground:Attachments/Yablokov 2022 - Russian disinformation finds fertile ground.pdf:application/pdf},
 journal = {Nat Hum Behav}
}


@article{Yang.2011,
 author = {Yang, Zhi and Wilson, Christo and Wang, Xiao and Gao, Tingting and Zhao, Ben Y. and Dai, Yafei},
 year = {2011},
 title = {Uncovering social network sybils in the wild},
 doi = {10.1145/2068816.2068841},
 journal = {IMC}
}


@article{Yang.2019,
 author = {Yang, Kai--Cheng and Varol, Onur and Davis, Clayton A. and Ferrara, Emilio and Flammini, Alessandro and Menczer, Filippo},
 year = {2019},
 title = {Arming the public with artificial intelligence to counter social bots},
 keywords = {T: Mitigating Bots},
 pages = {48--61},
 volume = {1},
 number = {1},
 issn = {2578-1863},
 doi = {10.1002/hbe2.115},
 file = {Yang, Varol et al. 2019 - Arming the public with artificial:Attachments/Yang, Varol et al. 2019 - Arming the public with artificial.pdf:application/pdf},
 journal = {Human Behav and Emerg Tech}
}


@article{Zhang.2018,
 author = {Zhang, Amy X. and Robbins, Martin and Bice, Ed and Hawke, Sandro and Karger, David and Mina, An Xiao and Ranganathan, Aditya and Metz, Sarah Emlen and Appling, Scott and Sehat, Connie Moon and Gilmore, Norman and Adams, Nick B. and Vincent, Emmanuel and Lee, Jennifer},
 year = {2018},
 title = {A structured response to misinformation: {D}efining and annotating credibility indicators in news articles},
 doi = {10.1145/3184558.3188731},
 journal = {WWW}
}


@article{Ziebart.2008,
 author = {Ziebart, Brian D. and Maas, Andrew and Bagnell, J. Andrew and Dey, Anind K.},
 year = {2008},
 title = {Maximum entropy inverse reinforcement learning},
 journal = {AAAI}
}


