\documentclass[a4paper,preprintnumbers,floatfix,pra,onecolumn,showpacs,notitlepage,longbibliography,nofootinbib]{revtex4-1}


\usepackage{amsmath, amssymb, amsthm, thm-restate, bm, physics, dsfont, nicefrac}
\usepackage{xcolor, graphicx, subfigure, float, appendix, booktabs, microtype, footnote}
\usepackage[colorlinks,citecolor=bluenet,linkcolor=rednet,urlcolor=bluenet]{hyperref}

\usepackage{palatino}

\usepackage{geometry}

\renewcommand{\baselinestretch}{1.15} 

\newtheorem{innercustomthm}{Proposition}
\newenvironment{customthm}[1]
  {\renewcommand\theinnercustomthm{#1}\innercustomthm}
  {\endinnercustomthm}

\newtheorem{lemma}{Lemma}
\newtheorem{Proposition}{Proposition}
\newtheorem{remark}{Remark}


\newcommand{\hilb}{\mathcal{H}}
\newcommand{\id}{\mathds{1}}
%\renewcommand{\tr}{\mathrm{Tr}}
\newcommand{\mean}[1]{\langle #1 \rangle}
\newcommand{\kb}[1]{ | #1 \rangle \langle #1  | }
\newcommand{\kt}[1]{ | #1 \rangle}
\newcommand{\br}[1]{\langle #1  | }
\newcommand{\eps}{\varepsilon}
\newcommand{\diag}{\mathrm{diag}}

\definecolor{bluenet}{RGB}{68, 119, 170}
\definecolor{rednet}{RGB}{204, 102, 119}
\definecolor{orangenet}{RGB}{221, 204, 119}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{document}
\title{Covariance matrix-based criteria for network entanglement}
\author{Kiara Hansenne}
\email{kiara.hansenne@uni-siegen.de}
\author{Otfried Gühne}
\affiliation{Naturwissenschaftlich-Technische Fakultät, Universität Siegen, Walter-Flex-Stra\ss e 3, 57068 Siegen, Germany.}

\begin{abstract}
    Quantum networks offer a realistic and practical scheme for generating multiparticle entanglement and implementing multiparticle quantum communication protocols. However, the correlations that can be generated in networks with quantum sources and local operations are not yet well understood. 
    Covariance matrices, which are powerful tools in entanglement theory, have been also applied to the
    network scenario. We present simple proofs for the decomposition of such matrices into the sum of positive semidefinite block matrices and, based on that, develop analytical and computable necessary criteria for preparing states in quantum networks. These criteria can be applied to networks in which any two nodes share at most one source, such as all bipartite networks.
\end{abstract}

\maketitle

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}
    %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    % Figure environment removed  
    %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
    Entanglement is a central element in quantum theory and subject of famous debates at the beginning of the 20th century \cite{einstein1935, schroedinger1935} and gained the status of a resource with the advent of quantum information theory some decades later (see Refs.\@ \cite{otfried2009, friis2019} for reviews). Entanglement between two parties has been widely studied and characterised, but much less is known regarding multiparticle entanglement. Indeed, when more than two parties are involved, the structure of entanglement becomes more complex, with non-equivalent classes of entanglement appearing \cite{otfried2009, friis2019}. Apart from the foundational interest in understanding the structure of multiparticle entanglement, the {significance} lies in the fact that it also is a resource for many quantum information applications, such as quantum conference key distribution \cite{murta2020}, quantum error correcting codes \cite{scott2004}, or high-precision metrology \cite{toth2012}. However, generating and manipulating genuine multipartite entangled states experimentally is a difficult task, particularly when the number of entangled parties is large (see Ref.\@ \cite{friis2019} and references therein). To circumvent this issue, {the arguably more experimental friendly} concept of quantum networks has been introduced \cite{kimble2008, simon2017}. In the network setup, the goal is to generate a global $N$-partite state using a set of sources (represented by edges in a (hyper)graph) that distribute (connect) subsystems of entangled states to the different parties of the network (the nodes of the (hyper)graph). Strictly, we require sources to distribute particles to at most $N-1$ nodes, and the parties might be allowed to apply a local operation to their system. Figure \ref{fig:triangle} details an example of a tripartite network with bipartite sources. 
    
    The power and limitations of such networks have already been studied in Refs.\@ \cite{navascues2020, aberg2020, kraft2021, luo2021, tristan2021, luo2021bis, contreras2022, hansenne2022, makuta2022, wang2022}, however, it is still unclear which useful quantum states can actually be prepared using them. In the most general definition, the parties and the sources can additionally share a global classical random variable, and we say that such networks {arise from} local operations and shared randomness (\textsc{losr}). 
    {However, it might be also realistic to consider models where there is no access to such a global variable. The main aim of this paper is to show that covariance matrices (\textsc{cm}s) can be used to derive strong criteria for
    entanglement in the various network scenarios.}
    
    {First introduced in for continuous variable systems \cite{werner2001, giedke2001},} covariance matrices possess useful properties and have previously been used to characterise bipartite and multiparticle entanglement \cite{guehne2007, gittsovich2008}. Recently, they have also been used to derive necessary criteria for network scenarios \cite{aberg2020, kraft2021, zp2022, beigi2022}. In Ref.\@ \cite{aberg2020}, the authors formulate a necessary condition for a probability distribution to arise from measurements performed on a quantum network state. The condition states that the covariance matrix of the probability distribution can be decomposed into the sum of positive semi-definite (\textsc{psd}) block matrices,\footnote{We call this decomposition into a sum of \textsc{psd} block matrices the block decomposition of a covariance matrix.} and can be formulated as a semidefinite program (\textsc{sdp}). This result was applied in Ref.\@ \cite{kraft2021} to derive practical analytical criteria for networks with dichotomic measurements and for networks with bipartite sources. More recently, similar \textsc{sdp}s were developed in Ref.\@ \cite{zp2022} for the case of \textsc{losr} networks, with extra assumptions on rank and purity. Finally, striking generality, the authors of Ref.\@ \cite{beigi2022} showed that in the case of no-common-double-source (\textsc{ncds}) networks,\footnote{In no-common-double-source networks, two nodes can hold subsystems from at most one common source.} the block decomposition criterion holds for all generalised probabilistic theories.

    In this paper, we propose an alternative proof to the block decomposition of the \textsc{cm} of triangle network state derived in Ref.\@ \cite{aberg2020}. From it, we obtain an analytical, computable {necessary} criterion for {a state to arise from a triangle network}. This criterion can also be used to upper bound the maximal fidelity a triangle network state can have to a given target state, for instance the GHZ state. We {discuss} the fact that these bounds are still valid for networks with \textsc{losr} and finally show how this result can be extended to \textsc{ncds} networks.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Network entanglement}  \label{sec:net_ent}
    The general triangle network situation involves Alice, Bob, and Charlie wanting to share a tripartite (entangled) state, but they only have access to bipartite sources, as shown in Figure \ref{fig:triangle}. This situation differs from the usual consideration of tripartite entanglement, where the parties have access to a tripartite state generated by a global source. In addition, the parties in the triangle network considered here do not have access to classical communication, which prevents them from executing teleportation or entanglement swapping protocols. Although classical communication is usually considered a cheap resource in quantum communication protocols, it does require time. The classical information must be communicated across the network, which can introduce undesirable latency, particularly in a context where quantum memories are still sub-optimal and expensive.
    
    In this manuscript, we will focus on different triangle network scenarios: the basic triangle network (\textsc{btn}) where bipartite sources are shared among the parties, the triangle network with local unitaries (\textsc{utn}) where Alice, Bob and Charlie are allowed to perform unitary operations on their local systems, and finally, the triangle network with local channels (\textsc{ctn}) where, as the name indicates, local channels are performed by the parties. 
    
    In the \textsc{btn}, three (entangled) bipartite source states ($\varrho_a$, $\varrho_b$ and $\varrho_c$) are prepared and each subsystem is sent to a node according to the distribution in Figure \ref{fig:triangle}. Alice, Bob and Charlie own the bipartite systems $A_1A_2 = A$, $B_1B_2 = B$ and $C_1C_2 = C$ respectively. The global state of the system $ABC$ reads
    %
    \begin{equation} \label{eq:btn}
        \varrho_{\textsc{btn}} = \varrho_b \otimes \varrho_c \otimes \varrho_a.
    \end{equation}
    %
    Notice that the order of the subsystems is not $ABC$ for the right-hand side, it is organised following the partition $C_2 A_1 A_2 B_1 B_2 C_1$. The reduced states of Alice, Bob and Charlie are separable bipartite states. This scenario has for instance been studied in the context of pair entangled network states \cite{contreras2022}.  In this work, we will assume that the sources all send $d \times d$-dimensional states, while keeping in mind that all the results can easily be extended to unequal dimensions. 
    
    In the following two scenarios, we allow the parties to perform operations on their local systems.
        
    First, we only give Alice, Bob and Charlie the possibility of performing a unitary operation on their system, namely $U_A$, $U_B$ and $U_C$ respectively. This leads to the following global state
    %
    \begin{equation} \label{eq:utn}
        \varrho_{\textsc{utn}} = (U_A \otimes U_B \otimes U_C) \varrho_{\textsc{btn}} (U_A^\dagger \otimes U_B^\dagger \otimes U_C^\dagger).
    \end{equation}
    %
    Alice, Bob and Charlie no longer necessarily hold separable bipartite states. We note that here again, there is no tripartite interaction between the parties.
        
    Second, we drop the unitary restriction on the local operations, meaning that Alice, Bob and Charlie may now apply channels on their local systems, represented by completely positive and trace preserving maps $\mathcal{E}_A$, $\mathcal{E}_B$ and $\mathcal{E}_C$ respectively. In that case, the global state reads
    %
    \begin{equation} \label{eq:ctn}
        \varrho_{\textsc{ctn}} = \mathcal{E}_A \otimes \mathcal{E}_B \otimes \mathcal{E}_C (\varrho_{\textsc{btn}}).
    \end{equation}
    %
    We note that if the dimensions match,  $\{\varrho_{\textsc{btn}}\} \subset \{\varrho_{\textsc{utn}}\} \subset \{\varrho_{\textsc{ctn}}\}$, but in general
    $\textsc{ctn}$ networks can be defined in broader scenarios, since the maps $\mathcal{E}_A$, $\mathcal{E}_B$ and $\mathcal{E}_C$
    may reduce the dimension.
    

    A special instance of networks are the previously-mentioned \textsc{ncds} networks: In this case, any two parties share subsystems from at most one source. For instance, all bipartite networks are \textsc{ncds}. 

    Finally, we could also allow the whole system to be coordinated by a global classical random variable $\lambda$. In the most general situation, this would result in states of the form $\varrho_\Delta = \sum_\lambda p_\lambda \varrho_{\textsc{ctn}}^{(\lambda)}$. These networks are called \textsc{losr} networks. {One direct consequence is that the set of states $\{\varrho_\Delta\}$ is convex, whereas Eqs.\@ (\ref{eq:btn} -- \ref{eq:ctn}) lead to non-convex state sets.} As already pointed out in Refs.\@ \cite{navascues2020, hansenne2022}, in the case of unbounded source dimensions, it suffices to consider that either the state or the parties have solely access to the global variable. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Covariance matrices}
    In this paper, the tools used to analyse network entanglement are covariance matrices, which characterise states through the covariance of some given observables. In practice, the \textsc{cm} $\Gamma$ is constructed for a state $\varrho$ and a set of observables $\{M_i\}$, and has the following matrix elements
    %
    \begin{equation}
        [\Gamma (\{M_i\},\varrho)]_{mn} = \mean{M_m M_n}_\varrho - \mean{M_m}_\varrho \mean{M_n}_\varrho
    \end{equation}
    %
    with $\mean{X}_\varrho = \tr(X \varrho)$ being the expectation value of the observable $X$ when the state of the system is given by $\varrho$.
    As in network scenarios the parties can only access their local systems, it is sensible to choose observables $A_i$, $B_j$ and $C_k$ that only act on Alice's, Bob's and Charlie's side respectively. Explicitly, we have $A_i \otimes \id_B \otimes \id_C$, $\id_A \otimes B_j \otimes \id_C$ and $\id_A \otimes \id_B \otimes C_k$, and we will use the notation $\{A_i, B_j, C_k\} = \{A_i \otimes \id_B \otimes \id_C\}_i \cup \{\id_A \otimes B_j \otimes \id_C\}_j \cup \{\id_A \otimes \id_B \otimes C_k\}_{k}$. In that case, the \textsc{cm} of a tripartite state $\varrho$ has the following block structure
    %
    \begin{equation} \label{eq:cm_block_str}
    	\Gamma (\{A_i,B_j,C_k\},\varrho) = 
    	\begin{pmatrix}
        	\Gamma_A & \gamma_E & \gamma_F \\
        	\gamma_E ^T & \Gamma_ B & \gamma_G \\
        	\gamma_F^T & \gamma_G^T & \Gamma_C
    	\end{pmatrix}
    \end{equation}
    %
    where $\Gamma_A = \Gamma (\{A_i\},\varrho^{(A)})$ is the \textsc{cm} of the reduced state $\varrho^{(A)}$.\footnote{For a state $\varrho$ of a system $XY$, we denote by $\tr_Y(\varrho) = \varrho^{(X)}$ the reduced state of the subsystem $X$.} The matrices $\Gamma_B$ and $\Gamma_C$ have analogous expressions. The elements of the off-diagonal block $\gamma_E$ are given by the real numbers
    %
    \begin{equation} \label{eq:gammaE}
    	[\gamma_E]_{mn} = \mean{A_m \otimes B_n}_{\varrho} - \mean{A_m }_{\varrho} \mean{ B_n}_{\varrho},
    \end{equation}
    %
    with identity operators padded where needed (note that Eq.\@ \eqref{eq:gammaE} can be defined equivalently by taking the expectation values on $\varrho^{(AB)}$). Again, the matrices $\gamma_F$ and $\gamma_G$ can be expressed in a similar way.
    
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Basic triangle network}
    In this section, we derive the explicit structure of \textsc{cm}s of \textsc{btn} states. Let us first define what we will call the reduced observable $A_i^{(2)}$ of $A_i$, which describes
    an effective observable on the system $A_2.$ It is given by
    %
    \begin{equation} \label{eq:redobs}
        \begin{split}
            A_i^{(2)}   &= \tr_{A_1} \left(A_i [\varrho_{\textsc{btn}}^{(A_1)} \otimes \id_{A_2}] \right) .
        \end{split}
    \end{equation}
    %
    Note that $A_i$ acts on  both $A_1$ and $A_2$, so $A_i^{(2)}$ is an operator acting 
    on states of $A_2$, where the effect of $\varrho_b = \varrho_\textsc{btn}^{(A_1C_2)}$ has been taken into account. We define $B_j^{(1)}$ similarly and will use the notation $\{A_i^{(2)}, B_j^{(1)}\} = \{A_i^{(2)} \otimes \id_{B_1}\}_i \cup \{\id_{A_2} \otimes B_j^{(1)}\}_j $. The off-diagonal blocks of Eq.\@ \eqref{eq:cm_block_str} can be expressed using the reduced observables, that is,
    %
    \begin{equation}\label{eq:gammaEwithredobs}
    	[\gamma_E]_{mn} = \mean{A_m^{(2)} \otimes B_n^{(1)}} - \mean{A_m^{(2)} } \mean{B_n^{(1)}}.
    \end{equation} 
    %
    To see this, we notice that the reduces state $\varrho_{\textsc{btn}}^{(AB)}$ is a product state with respect to the partition $A_1 \mid A_2B_1 \mid B_2$ and use a local basis decomposition of the observables $A_m$ and $B_n$ (see Appendix \ref{app:redobs}). All expectation values of Eq.\@ \eqref{eq:gammaEwithredobs} are taken with respect to the state $\varrho_{\textsc{btn}}^{(A_2B_1)}$, which is nothing but $\varrho_c$.

    This representation means  that $\gamma_E$ can be computed using only the reduced observables on the state $\varrho_{\textsc{btn}}^{(A_2B_1)}$. This is a direct consequence of the fact that the marginal states of Alice, Bob and Charlie are a product states, which will no longer be the case in the next scenarios. Let us now introduce our first proposition.
    %%%%%%%%%%%%%
    \begin{Proposition}[Block decomposition for \textsc{cm}s of \textsc{btn} states] \label{prop:cmofbtn}
    	The \textsc{cm} of a \textsc{btn} state with local observables $\{A_i, B_j,C_k\}$ can be decomposed as
    	\begin{equation} \label{eq-gammadec}
    	    \begin{split}
        		\Gamma_{\textsc{btn}}   =& \Gamma (\{A_i,B_j,C_k\},\varrho_{\textsc{btn}}) \\
        	                            =&\underbrace{\begin{pmatrix}
        						\Gamma_{A_2} & \gamma_E & 0 \\
        						\gamma_E^T & \Gamma_{B_1} & 0 \\
        						0 & 0 & 0
        					\end{pmatrix}}_{T_c}
        				+	\underbrace{\begin{pmatrix}
        						\Gamma_{A_1} & 0 & \gamma_F \\
        						0 & 0 & 0 \\
        						\gamma_F^T & 0 & \Gamma_{C_2}
        					\end{pmatrix}}_{T_b}
        				+	\underbrace{\begin{pmatrix}
        						0 & 0 & 0 \\
        						0 & \Gamma_{B_2} & \gamma_G \\
        						0 & \gamma_G^T & \Gamma_{C_1}
        					\end{pmatrix}}_{T_a}
        				+ 	\underbrace{\begin{pmatrix}
        						R_A & 0 & 0 \\
        						0 & R_B & 0 \\
        						0 & 0 & R_C
        				\end{pmatrix}}_{R}
    	    \end{split}
    	\end{equation}
    	where the matrices $T_a$, $T_b$ and $T_c$ are \textsc{cm}s for the state-dependent reduced observables, i.e.\@, 
    	\begin{equation}
    		T_c = \Gamma(\{A_i^{(2)} , B_j^{(1)}\}, \varrho_{\textsc{btn}}^{(A_2B_1)}).
    	\end{equation}
    	and analogously for $T_b$ and $T_a$. The matrix $R$ is positive semi-definite. 
    \end{Proposition}
    %%%%%%%%%%%%%
    {Using Eq.\@ \eqref{eq:gammaEwithredobs}, it is only left to show that $R_A = \Gamma_A - \Gamma_{A_1} - \Gamma_{A_2}$ is \textsc{psd}, as well as $R_B$ and $R_C$. To do this, we show that $\bra{x}R_A\ket{x}$ can always be written as the trace of a product of \textsc{psd} matrices.}
    The proof is given in Appendix \ref{app:prop1}. 

    We want to emphasize that the results presented in this manuscript are valid only in the context of finite-dimensional Hilbert spaces. A potential future research direction is to investigate how these results can be extended to the infinite-dimensional case. As mentioned in the introduction, \textsc{cm}s are also well suited for continuous variable systems.

    Armed with this, we can now derive the structure of the covariance matrix of a \textsc{btn} state when the observables are full sets of local orthogonal observables, namely $\{A_i\} = \{G^{(A_1)}_\alpha \otimes G^{(A_2)}_\beta\}$, where $\{G^{(A_k)}_\alpha\}$  is a set of $d^2$
    orthogonal observables acting on states of $A_k$ such that $\tr (G_\alpha^{(A_k)} G_{\alpha'}^{(A_k)} ) = d \delta_{\alpha \alpha'}$ ($k=1,2$). This is done in a similar way  for the systems $B$ and $C$. When the situation is explicit enough, we will drop the superscripts. 
    {In the case of qubits, the Pauli operators $\sigma_x$, $\sigma_y$ and $\sigma_z$ together with the $2 \times 2$ identity operator $\id$ are an obvious choice.}
    With such sets of observables, a direct computation (see Appendix \ref{app:Rexplicit}) shows that 
    %
    \begin{equation}\label{eq:Rexplicitelements}
        \begin{split}
            R_X = & {\Gamma_X - \Gamma_{X_1} - \Gamma_{X_2}} \\
                = & \Gamma\left(\{G_\alpha\},\varrho_{\textsc{btn}}^{(X_1)}\right) \otimes \Gamma\left(\{G_\beta\},\varrho_{\textsc{btn}}^{(X_2)}\right), \quad X=A,B,C
        \end{split}
    \end{equation}
    %
    and therefore $R$ is trivially \textsc{psd} in the case of full sets of orthogonal observables.

    The structure of the matrices $T_a$, $T_b$ and $T_c$ can also be further explored. First, let us compute the reduced observables
    %
    \begin{equation}
    	A^{(2)}_i = \tr(G_\alpha \varrho_{\textsc{btn}}^{(A_1)}) G_\beta = a^{(1)}_\alpha G_\beta .
    \end{equation}
    where the coefficients $a^{(1)}_\alpha =  \tr(G_\alpha \varrho_{\textsc{btn}}^{(A_1)}) $ 
    are nothing but the {(real)} Bloch coefficients of the reduced states. In Appendix \ref{app:gammaA2}, we show that
    %
    \begin{equation} \label{eq:gammaA2}
    	\Gamma_{A_2} = \kb{\vec{a}^{(1)}} \otimes \Gamma(\{G_\beta\},\varrho_{\textsc{btn}}^{(A_2)})
    \end{equation}
    %
    and that
    %
    \begin{equation} \label{eqEijdec}
        \gamma_E = \kt{\vec{a}^{(1)}}\br{\vec{b}^{(2)}} \otimes \gamma(\{G_\beta,G_\alpha\},\varrho_{\textsc{btn}}^{(A_2B_1)})
    \end{equation}
    %
    with $\kt{\vec{a}^{(1)}} = (a_0^{(1)},\dots,a_{d^2-1}^{(1)})^T{\in \mathbb{R}^{d^2}}$ and similarly for $\kt{\vec{b}^{(2)}}$. The matrix $\gamma(\{G_\beta,G_\alpha\},\varrho_{\textsc{btn}}^{(A_2B_1)})$ is the off-diagonal block of the \textsc{cm} with the same observables and state.
    Finally, we can write 
    %
    \begin{equation}
    	T_c =\kt{\vec{a}^{(1)}\oplus \vec{b}^{(2)}}\br{\vec{a}^{(1)} \oplus \vec{b}^{(2)}} \star \Gamma\left(\varrho_{\textsc{btn}}^{(A_2B_1)}\right),
    \end{equation}
    %
    where $ \star $ is the {"block-wise" Kronecker product, called Khatri-Rao product \cite{khatri1968, liu1999}. Formally, if $A$ and $B$ are block matrices, the $i,j$-th block of their Khatri-Rao product, $(A \star B)_{i,j}$, is the Kronecker product of the $i,j$-th block of $A$ and $B$, $A_{i,j} \otimes B_{i,j}$. For instance, if $A$ and $B$ are $2 \times 2 $ block matrices, 
    %
    \begin{equation}
        A = \begin{pmatrix}
            A_{0,0} & A_{0,1} \\
            A_{1,0} & A_{1,1}
        \end{pmatrix}, \quad 
        B = \begin{pmatrix}
            B_{0,0} & B_{0,1} \\
            B_{1,0} & B_{1,1}
        \end{pmatrix},
    \end{equation}
    %
    we obtain
    %
    \begin{equation}
        A \star B = \begin{pmatrix}
            A_{0,0} \otimes B_{0,0} & A_{0,1} \otimes B_{0,1} \\
            A_{1,0} \otimes B_{1,0} & A_{1,1} \otimes B_{1,1}
        \end{pmatrix}
    \end{equation}
    %
     (see Ref.\@ \cite{liu1999} for more details). }

    Finally, one has 
    %%%%%%%%%%%%%
    \begin{Proposition} \label{prop:decofgamma}
    	The \textsc{cm} of a \textsc{btn} state, using complete sets of orthogonal observables acting locally can be decomposed as
            \begin{equation} \label{eq:gammadecorthonormalobs}
    		\begin{split}
    			\Gamma_{\textsc{btn}} = & \kt{\vec{a}^{(1)}\oplus \vec{b}^{(2)}}\br{\vec{a}^{(1)} \oplus \vec{b}^{(2)}} \star \Gamma\left(\varrho_{\textsc{btn}}^{(A_2B_1)}\right) 
    			+ \kt{\vec{b}^{(1)}\oplus \vec{c}^{(2)}}\br{\vec{b}^{(1)} \oplus \vec{c}^{(2)}} \star \Gamma\left(\varrho_{\textsc{btn}}^{(B_2C_1)}\right) \\ &
    			+ \kt{\vec{b}^{(1)}\oplus \vec{c}^{(2)}}\br{\vec{b}^{(1)} \oplus \vec{c}^{(2)}} \star \Gamma\left(\varrho_{\textsc{btn}}^{(B_2C_1)}\right)
    			+ \mathrm{diag}\left\{\Gamma\left(\varrho_{\textsc{btn}}^{(X_1)}\right) \otimes \Gamma\left(\varrho_{\textsc{btn}}^{(X_2)}\right), X=A,B,C\right\}.
    		\end{split}
    	\end{equation}
    \end{Proposition}  
    %%%%%%%%%%%%%
    Therefore, in order to test compatibility with the \textsc{btn} scenario for a given state, one can check if its \textsc{cm} can be written like the right-hand side of the above equation. While this might be cumbersome to test, we notice that the matrix $\Gamma_{\textsc{btn}} -R$ is also \textsc{psd}, which can also be used to check compatibility in the following way: 
    %%%%%%%%%%%%%
    \begin{Proposition}[Positivity condition]\label{positivitycdt}
    	The matrix
        \begin{equation}\label{eq:Xi}
            \begin{split}
                \Xi (\varrho_{\textsc{btn}}) =& \  \Gamma\left(\{G_\alpha^{A_1} \otimes G_\beta^{A_2} ,G_\gamma^{B_1} \otimes G_\delta^{B_2} ,G_\epsilon^{C_1} \otimes G_\zeta^{C_2} \},\varrho_{\textsc{btn}}\right) \\
                & - \diag\left\{\Gamma\left(\{G_\alpha^{X_1}\},\varrho_{\textsc{btn}}^{(X_1)}\right) \otimes \Gamma\left(\{G_\beta^{X_2}\},\varrho_{\textsc{btn}}^{(X_2)}\right), X=A,B,C\right\}
            \end{split}
        \end{equation}
    	is positive semi-definite.
    \end{Proposition}
    %%%%%%%%%%%%%
    We note that neither term of the right-hand side of Eq.\@ \eqref{eq:Xi} contains the reduced observables, which makes $\Xi$ easy to compute. 

    An advised reader might point out that in order to verify if a given state is compatible with the \textsc{btn} scenario, it suffices to test whether $\varrho_{\textsc{btn}} = \varrho_{\textsc{btn}}^{(A_2B_1)} \otimes\varrho_{\textsc{btn}}^{(B_2C_1)} \otimes\varrho_{\textsc{btn}}^{(C_2A_1)}$, up to reordering of the subsystems. We stress that although this simple equation does answer the question, it requires the knowledge of the full density operator, whereas \textsc{cm}-based criteria only need expectation values of some chosen observables in order to be evaluated.

    To close this section on \textsc{btn}, we present a few examples.
    First, we note that the lowest dimensional achievable states are sixty-four-dimensional states (six qubits, or three ququarts\footnote{{A ququart (sometimes ququad) is a four-dimensional quantum system.}}), and that the local dimensions cannot be prime numbers. Therefore we start with the three-ququart \textsc{ghz} state,
    %
    \begin{equation}
        \kt{GHZ_4} = \frac{1}{\sqrt{2}} (\kt{000} + \kt{333}),
    \end{equation}
    %
    which we mix with white noise
    %
    \begin{equation}
        \varrho_{GHZ_4}(v) = v \kb{GHZ_4} + (1-v) \frac{\id_{64}}{64},
    \end{equation}
    %
    {where $v$ is the visibility.}
    The corresponding $\Xi$ matrix is \textsc{psd} only for $p=0$, meaning that the \textsc{ghz} state cannot be prepared in a \textsc{btn} network even with a very high amount of white noise. The same result is obtained when applied to the four-level \textsc{ghz} state, $\nicefrac{1}{2}(\kt{000}+ \kt{111} + \kt{222} + \kt{333})$.
    
    Proposition \ref{positivitycdt} may also be applied to three-ququart Dicke states, which are defined by
    %
    \begin{equation}
        \kt{D_{3,4,k}} = \mathcal{N} \sum_{i_1+i_2+i_3=k}\kt{i_1i_2i_3}, \quad k=1,\dots,9,
    \end{equation}
    %
    with $\mathcal{N}$ being a normalisation factor. When mixed with white noise, they cannot be prepared in the \textsc{btn} scenario when $p \neq 0$ and $p \neq 1$ for $k=1$, and when $p\neq0$ for $k=2,\dots,7$.
    
    More generally, by directly applying the result of Proposition \ref{prop:decofgamma}, we can check whether the \textsc{cm} of a \textsc{btn} state can be written like the right-hand side of Eq.\@ \eqref{eq:gammadecorthonormalobs}. By doing that for $\kt{D^3_1}$, we conclude that this state cannot be generated in the \textsc{btn} scenario. On the other hand, the \textsc{cm} of the maximally mixed state $\nicefrac{\id}{64}$ has such a decomposition.

    The nature of interesting states that can be prepared in the \textsc{btn} scenario remains an open question. An obvious approach would be to distribute three Bell pairs across the network, resulting in a three-ququart genuine multipartite entangled triangle state. Getting ahead of the next sections where it will be permitted to apply local transformations on systems $A$, $B$ and $C$, it is less straightforward to see what operations could be applied after distributing for instance Bell pairs.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Triangle network with local operations} \label{sec:trianglenetandlo}
    Let us now consider the situation where Alice, Bob and Charlie can perform unitaries on their respective systems. As described in Section \ref{sec:net_ent}, the global state now reads
    %
    \begin{equation}
        \begin{split}
            \varrho_{\textsc{utn}}
            = & (U_A \otimes U_B \otimes U_C) \varrho_{\textsc{btn}} (U_A^\dagger \otimes U_B^\dagger \otimes U_C^\dagger).
        \end{split}
    \end{equation}
    %
    First, we note that in general, for any set of observables $\{M_i\}$, any unitary $U$ and any state $\varrho$ there exists a orthogonal matrix $O$ such that \cite{gittsovich2008}
    %
    \begin{equation}
        \Gamma(\{M_i\},U\varrho U^\dagger) = \Gamma(\{U^\dagger M_i U\}, \varrho) = O^T \Gamma(\{M_i\}, \varrho)O.
    \end{equation}
    %
    {Note that not all orthogonal transformations of \textsc{cm}s correspond to a unitary transformation on the system.}  
    From that we obtain to the following proposition: 
    %%%%%%%%%%%%%
    \begin{Proposition} \label{prop:GammaDecUTN} 
        Consider the \textsc{cm} of a \textsc{utn} state with observables $A_i$, $B_j$, $C_k$ that only act on the systems $A$, $B$, $C$ respectively. There exist an orthogonal matrix $O=O_A\oplus O_B \oplus O_C$ and a \textsc{btn} state $\varrho_{\textsc{btn}}$ such that the \textsc{cm} of $\varrho_{\textsc{utn}}$ can be written as
        %
        \begin{equation}
            \Gamma_{\textsc{utn}} \equiv \Gamma(\{A_i,B_j,C_k\}, \varrho_{\textsc{utn}}) = O^T \Gamma_{\textsc{btn}}O
        \end{equation}
        %
        with $\Gamma_{\textsc{btn}}$ as in Eq.\@ \eqref{eq-gammadec}.
    \end{Proposition}
    %%%%%%%%%%%%%
    Thus, the \textsc{cm} of $\varrho_{\textsc{utn}}$ can always be decomposed as a sum of positive semi-definite matrices with the following block decomposition
    \begin{equation} \label{eq:blocdecUTN}
        \Gamma_{\textsc{utn}} =
        \underbrace{
            \begin{pmatrix}
            \textcolor{rednet}{\blacksquare} & \textcolor{rednet}{\blacksquare} & 0  \\
            \textcolor{rednet}{\blacksquare} & \textcolor{rednet}{\blacksquare} & 0 \\
            0 & 0 & 0 \\
            \end{pmatrix}}_{O^T T_c O} + 
        \underbrace{
            \begin{pmatrix}
            \textcolor{bluenet}{\blacksquare} &  0  & \textcolor{bluenet}{\blacksquare} \\
            0&  0  & 0  \\
            \textcolor{bluenet}{\blacksquare} & 0  & \textcolor{bluenet}{\blacksquare} \\
            \end{pmatrix}}_{O^T T_b O}  + 
        \underbrace{
            \begin{pmatrix}
            0& 0  &  0 \\
            0& \textcolor{orangenet}{\blacksquare} & \textcolor{orangenet}{\blacksquare} \\
            0& \textcolor{orangenet}{\blacksquare} & \textcolor{orangenet}{\blacksquare} \\
            \end{pmatrix}}_{O^T T_a O}  +
        \underbrace{
            \begin{pmatrix}
            \blacksquare & 0  &  0 \\
            0& \blacksquare &0   \\
            0&  0 & \blacksquare \\
            \end{pmatrix}}_{O^T R O} . 
    \end{equation}
    %
    We may also look at this situation by noticing that the \textsc{cm}s of \textsc{utn} states can be written as 
    %
    \begin{equation}
        \begin{split}
            \Gamma_{\textsc{utn}} &= \Gamma(\{U_A^\dagger A_i U_A,U_B^\dagger B_jU_B,U_C^\dagger C_kU_C\}, \varrho_{\textsc{btn}})\\
            &= T_c^{U} + T_b^{U} + T_a^{U} + R^{U},
        \end{split}
    \end{equation}
    %
    with $T_c^U$ being the \textsc{cm}s of $\varrho_{\textsc{btn}}^{(A_2B_1)}$ with the following reduced observables 
    %
    \begin{equation}
        \begin{split}
            A_{U,i}^{(2)}\equiv&(U_A^\dagger A_i U_A)^{(2)}  \\
            =& \sum_{\alpha,\beta} \tr(U_A^\dagger A_i U_A \  G_\alpha\otimes G_\beta) \tr(G_\alpha \varrho_{A_1})G_\beta
        \end{split}
    \end{equation}
    %
    and $B_{U,j}^{(1)}$ build in the same way. The matrices $T_b^U$ and $T_a^U$ are defined similarly. The matrix $R_A^U$ is equal to $A^U-E_A^U-F_A^U$. One issue with this formulation is that, if one wants to test whether a given state is compatible with the \textsc{utn} scenario, the unitaries $U_A$, $U_B$ and $U_C$ and the state $\varrho_{\textsc{btn}}$ corresponding to the decomposition of $\varrho_{\textsc{utn}}$ are in general not known, thus there is no way to explicitly know the reduced observables.

    We are now interested in triangle networks in which the local operations can be any quantum channel, i.e., not longer restricted to unitary operations. By making use of the Stinespring dilation theorem \cite{heinosaari2012}, we can show that \textsc{ctn} states also lead to \textsc{cm}s that posses a block decomposition. As a matter of fact, any channel can be implemented by performing a unitary transformation on the system together with an ancilla, and then tracing out the ancilla. The covariance matrix of any state $\varrho$ after a channel $\mathcal{E}$ (i.e., $\mathcal{E}(\varrho)$) with observables $\{M_i\}$ therefore has the same expression as taking the \textsc{cm} of the state together with an ancilla and applying the corresponding unitary $U$, that is, $U(\varrho \otimes \varrho_\text{ancilla})U ^\dagger$, with observables $\{M_i \otimes \id_{\text{ancilla}}\}$. {We can also see this by noticing that the \textsc{cm} of a reduced state is just a principal submatrix of the \textsc{cm} of the global state.} Applying this to each node of the triangle network, we obtain the following proposition:
    %%%%%%%%%%%%%
    \begin{Proposition}[Block decomposition for \textsc{cm}s of \textsc{ctn} states] \label{prop:ctnstates}
        Let $\Gamma_{\textsc{ctn}}$ be the covariance matrix of $\varrho_{\textsc{ctn}} = \mathcal{E}_A \otimes \mathcal{E}_B \otimes \mathcal{E}_C (\varrho_{\textsc{btn}})$ with local observables $A_i$, $B_j$ and $C_k$ as in Eq.\@ \eqref{eq:cm_block_str}. There exist matrices $\Upsilon^X_i$ ($X=A,B,C$ and $i=1,2$) such that 
        %
        \begin{equation} \label{eq:GammaUncorrTN}
            \Gamma_\textsc{ctn} 
        			= \underbrace{\begin{pmatrix}
        						{\Upsilon^A_2} & \gamma_E & 0 \\
        						\gamma_E^T & {\Upsilon^B_1} & 0 \\
        						0 & 0 & 0
        					\end{pmatrix}}_{\textsc{psd}}
        				+	\underbrace{\begin{pmatrix}
        						{\Upsilon^A_1} & 0 & \gamma_F \\
        						0 & 0 & 0 \\
        						\gamma_F^T & 0 & {\Upsilon^C_2}
        					\end{pmatrix}}_{\textsc{psd}}
        				+	\underbrace{\begin{pmatrix}
        						0 & 0 & 0 \\
        						0 & {\Upsilon^B_2} & \gamma_G \\
        						0 & \gamma_G^T & {\Upsilon^C_1}
        					\end{pmatrix}}_{\textsc{psd}}.
        \end{equation}
        %
    \end{Proposition}
    %%%%%%%%%%%%%
    Comparing to Eq.\@ \eqref{eq:blocdecUTN}, we consider that we distributed the black blocks to the first three matrices. Although the proof techniques differ notably, the block decomposition has already been presented in the first work on \textsc{cm}s of network states \cite{aberg2020}. As demonstrated in that same work, Proposition \ref{prop:ctnstates} can be evaluated as an \textsc{sdp}. However, we are seeking practical analytical methods and criteria to determine if a state cannot be prepared in a network setting: In the next section, we present such a criterion that follows from Proposition \ref{prop:ctnstates}.

    Let us here briefly comment on how this proposition behaves for \textsc{losr} triangle network states, $\varrho_{\Delta} = \sum_\lambda p_\lambda \varrho_{\textsc{ctn}}^{\lambda}$. {We recall that in this set up, the sources and the local operations may be coordinated by a classical random variable $\lambda$.} From the concavity property in Ref.\@ \cite{gittsovich2008}, we know that the difference between the covariance matrix $\Gamma(\varrho_\Delta)$ and the weighted sum of \textsc{cm}s $\sum_\lambda p_\lambda \Gamma(\varrho_\textsc{ctn}^\lambda)$ is a \textsc{psd} matrix. Using Proposition \ref{prop:ctnstates}, we directly get that there exist block matrices such that
    %
    \begin{equation}
        \Gamma(\varrho_\Delta) \geq
        \underbrace{
            \begin{pmatrix}
            \textcolor{rednet}{\blacksquare} & \textcolor{rednet}{\blacksquare} & 0  \\
            \textcolor{rednet}{\blacksquare} & \textcolor{rednet}{\blacksquare} &  0 \\
            0& 0  &  0 \\
            \end{pmatrix}}_{\textsc{psd}} + 
        \underbrace{
            \begin{pmatrix}
            \textcolor{bluenet}{\blacksquare} & 0  & \textcolor{bluenet}{\blacksquare} \\
            0&  0 & 0  \\
            \textcolor{bluenet}{\blacksquare} & 0  & \textcolor{bluenet}{\blacksquare} \\
            \end{pmatrix}}_{\textsc{psd}}  + 
        \underbrace{
            \begin{pmatrix}
            0& 0  &0   \\
            0& \textcolor{orangenet}{\blacksquare} & \textcolor{orangenet}{\blacksquare} \\
            0& \textcolor{orangenet}{\blacksquare} & \textcolor{orangenet}{\blacksquare} \\
            \end{pmatrix}}_{\textsc{psd}}.
    \end{equation}
    %
    While a similar trick can lead to powerful necessary criteria for separability in the case of entanglement \cite{gittsovich2008}, it is not the case here. This is because the extreme points in the case of \textsc{losr} triangle network states are not well characterised, as already discussed in Supplementary Note 1 of Ref.\@ \cite{hansenne2022}. Indeed, while it is known that the extreme points are of the form $\mathcal{E}_A \otimes \mathcal{E}_B \otimes \mathcal{E}_C (\ketbra{c} \otimes \ketbra{b} \otimes \ketbra{a})$, it is not clear whether they are necessarily pure: On the one hand, the author of Ref.\@ \cite{luo2021} showed that no three-qubit genuine multipartite entangled (\textsc{gme}) pure state can be generated in a triangle network, and on the other hand, the authors of Ref.\@ \cite{navascues2020} managed to find a state in the \textsc{losr} triangle network with that has a fidelity to the \textsc{ghz} state of 0.5170. From Ref.\@ \cite{otfried2010}, we know that states with such fidelity must be \textsc{gme}: Thus, there exist extremal points of the set of three-qubit \textsc{losr} network states that are \textsc{gme} mixed states. Finally, we notice that pure \textsc{gme} states can exist in higher-dimensional triangle networks: For instance, the three-ququart state $\ket{\phi^+}_{A_2B_1} \otimes \ket{\phi^+}_{B_2C_1} \otimes \ket{\phi^+}_{C_2A_1}$ is \textsc{gme} for the partition $A_1A_2 \mid B_1B_2 \mid C_1C_2$ \cite{contreras2022}.

    When additional properties of the states are known, such as the purity or the rank, \textsc{sdp}-based criteria for \textsc{losr} networks can be obtained, as shown in Ref.\@ \cite{zp2022}.  
    
        
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Covariance matrix criterion for triangle network states} \label{sec:critfortiranle}
    As seen in the previous section, \textsc{cm}s of \textsc{ctn} states with local observables $\{A_i, B_j, C_k\}$ possess a block decomposition. From Proposition \ref{prop:ctnstates}, {} we obtain inequalities for any unitarily invariant norm $\norm{\cdot}$,
    \begin{equation}
        2 \norm{\gamma_E} \leq \norm{A_2} + \norm{B_1},
    \end{equation}
    %
    for which we can take the trace norm and obtain
    %
    \begin{equation}
        2 \norm{\gamma_E}_{\tr} + 2 \norm{\gamma_F}_{\tr} + 2 \norm{\gamma_G}_{\tr} \leq \tr(A_1 + A_2 + B_1 + B_2 + C_1 + C_2).
    \end{equation}
    %
    This gives us a direct necessary criterion for triangle network states.
    %%%%%%%%%%%%%
    \begin{Proposition}[\textsc{Cm} and trace norm criterion for triangle network states.] \label{prop:tracenormcrit}
        Let $\Gamma$ be the \textsc{cm} of a triangle network state $\varrho_\textsc{ctn} = \mathcal{E}_A  \otimes \mathcal{E}_B \otimes \mathcal{E}_C (\varrho_\textsc{btn})$ with local observables $\{A_i, B_j, C_k\}$. Then
        \begin{equation}
            \tr(\Gamma) \geq 2 \norm{\gamma_E}_{\tr} + 2 \norm{\gamma_F}_{\tr} + 2 \norm{\gamma_G}_{\tr} 
        \end{equation}
        has to hold, with $\gamma_E$, $\gamma_F$ and $\gamma_G$ as in Eq.\@ \eqref{eq:cm_block_str}.
    \end{Proposition}
    %%%%%%%%%%%%%

    Now, we apply the trace norm criterion to exclude states from the triangle network scenario. 

    First, we notice that contrarily to \textsc{btn} states, three-qubit states can be generated in the \textsc{ctn} scenario. Therefore, we first consider the three-qubit \textsc{ghz} state that we mix with white noise, i.e., 
    %
    \begin{equation}
        \varrho_{GHZ}(v) = v \kb{GHZ} + (1-v) \frac{\id_8}{8}.   
    \end{equation}
    %
    By taking the three-qubit observable set $\mathcal{S}_{GHZ}=\{\sigma_z \id \id, \id  \sigma_z  \id, \id  \id  \sigma_z\}$ for the \textsc{cm}, the \textsc{cm} and trance norm criterion excludes $\varrho_{GHZ}(v)$ for $v>\nicefrac{1}{2}$. The \textsc{cm} of the \textsc{w} state $\nicefrac{1}{\sqrt{3}}(\kt{100} + \kt{010} + \kt{001})$ with observables $\mathcal{S}_W=\{\sigma_x  \id  \id, \sigma_y  \id  \id, \id  \sigma_x  \id, \id  \sigma_y  \id, \id  \id  \sigma_x, \id  \id  \sigma_y\}$ excludes it for $v> \nicefrac{3}{4}$ by the same method. Note that we omitted the tensor product signs for readability.

    Further than that, we can put a bound on the fidelity of a triangle state to the \textsc{ghz} state. Consider an arbitrary state $\varrho = F \kb{GHZ} + (1-F) \tilde\varrho$, where $\br{GHZ}\tilde\varrho\kt{GHZ}=0$. 
    From Proposition \ref{prop:tracenormcrit} with $\mathcal{S}_{GHZ}$, we show that $F$ cannot be larger than $3-\sqrt{5}\simeq 0.76$. We note that this result was already obtained in Ref.\@ \cite{hansenne2022} using similar methods, and that by exploiting symmetries, this upper bound on the fidelity can be improved to $\nicefrac{1}{\sqrt{2}}\simeq 0.71$ {which is, to our knowledge, the best analytical bound so far.} 

   It is worth realising that upper bounds on the fidelity of triangle states to a given target state $\kt{\Psi}$ also hold in the case of \textsc{losr} networks. Indeed, \textsc{losr} network states $\varrho_\Delta$ are states that can be written as a convex combination of \textsc{ctn} states, and thus $\max_{\varrho_\Delta} \br{\Psi}\varrho_\Delta\kt{\Psi} = \max_{\varrho_{\textsc{ctn}}} \br{\Psi}\varrho_{\textsc{ctn}}\kt{\Psi}$. From this, we can conclude that from Proposition \ref{prop:tracenormcrit} it follows that any state with a fidelity to the \textsc{ghz} state higher than $3-\sqrt{5} \simeq 0.71$ is excluded also from the \textsc{losr} triangle network scenario.

   {Before closing this section, a brief comment is in order. At first glance, it may seem that by only using the $\sigma_z$ correlations of a three-qubit state, we could exclude it from the set of \textsc{losr} network states and thus learn about its entanglement. However, this would be problematic because all separable three-qubit states are in the set of \textsc{losr} triangle network states, and all $\sigma_z$ correlations can be simulated by separable states. But this is not the logic
   of the argument above: Proposition \ref{prop:tracenormcrit} puts a bound on the extremal points
   of  \textsc{losr} triangle network states, which then by convexity holds for all 
   \textsc{losr} states. In order to draw a conclusion for a given state, knowledge of the fidelity 
   to some target state is required, which requires additional measurements than the $\sigma_z$ correlations alone. 
   }

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{\textsc{Ncds} networks} \label{sec:ncdsnet}

    In this section, we show that the block decomposition of covariance matrices of network states can also hold for larger networks. Indeed, if we consider networks where two nodes share parties from at most one common source (\textsc{ncds} networks), the triangle network results can be extended. Examples of such networks are networks with bipartite sources. 
    
    More explicitly, consider a $N$-node \textsc{ncds} network with a set of sources $\mathds{S}$. The number of sources is given by $\abs{\mathds{S}}$, and each source $s\in \mathds{S}$ is the set of nodes the source connects.
    Let $\Gamma_\textsc{ncds}$ be the \textsc{cm} of a global state of such a network with observables $\{A_{x \mid i} : x = 1 , \dots, N\}$, where $A_{x \mid i}$ is the $i$th observables that only acts on the node $x$. Then $\Gamma_\textsc{ncds}$ has a block form analogous to Eq.\@ \eqref{eq:cm_block_str}, where the diagonal blocks are labelled $\Gamma_x$ and the off-diagonal block are $\gamma_{xy}=\gamma_{yx}^T$ ($x \neq y$, $x,y \in \{1, \dots,N\}$).
    Formally, we state that
    %%%%%%%%%%%%%
    \begin{Proposition}[Block decomposition for \textsc{cm}s of \textsc{ncds} network states] \label{prop:BlockDecNCDS}
        There exist matrices $\Upsilon_x^s$ ($s \in \mathds{S}$, $x \in s$) such that $\Gamma_\textsc{ncds}$ can be decomposed as a sum of $\abs{\mathds{S}}$ positive semi-definite block matrices $T_s$ ($s \in \mathds{S}$) where the off-diagonal blocks of each $T_s$ are $\gamma_{xy}$ for $\{x,y\} \subset s$ and $0$ for $\{x,y\} \not\subset s$, and where the diagonal blocks are $\Upsilon_x^s$.
    \end{Proposition}
    %%%%%%%%%%%%%
    For a technical proof, see Appendix \ref{app:prop7}. In there, we prove that in the case of basic (i.e., without local operations) networks with no common double source (\textsc{bncds} networks), the proposition holds. Following a similar line of reasoning to the proofs for triangle networks, the proposition naturally extends to \textsc{ncds} networks with local operations.

    Let us consider an easy example for the sake of clarity. Figure \ref{fig:ncds} shows a five-partite network consisting of two tripartite sources $\varrho_a$ and $\varrho_b$, and one bipartite $\varrho_c$. The set of sources is given by $\mathds{S}=\{a,b,c\}=\{\{1,2,3\},\{3,4,5\},\{1,5\}\}$.
    %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    % Figure environment removed
    %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    Following the notation of Proposition \ref{prop:BlockDecNCDS}, there must exist eight matrices $\Upsilon_1^a$, $\Upsilon_2^a$, $\Upsilon_3^a$, $\Upsilon_3^b$, $\Upsilon_4^b$, $\Upsilon_5^b$, $\Upsilon_1^c$ and $\Upsilon_5^c$ such that the \textsc{cm} of the global network state 
    %
    \begin{equation}
        \varrho_{\textsc{ncds}} = \mathcal{E}_1 \otimes \mathcal{E}_2 \otimes \mathcal{E}_3 \otimes \mathcal{E}_4 \otimes \mathcal{E}_5  (\varrho_a \otimes \varrho_b \otimes \varrho_c)
    \end{equation}
    %
    may be decomposed as 
    %
    \begin{equation}
        \Gamma_{\textsc{ncds}} =     
        \underbrace{
            \begin{pmatrix}
            \textcolor{orangenet}{\Upsilon_1^a} & \textcolor{orangenet}{\blacksquare} & \textcolor{orangenet}{\blacksquare} & 0 & 0  \\
            \textcolor{orangenet}{\blacksquare} & \textcolor{orangenet}{\Upsilon_2^a} & \textcolor{orangenet}{\blacksquare} & 0 & 0  \\
            \textcolor{orangenet}{\blacksquare} & \textcolor{orangenet}{\blacksquare} & \textcolor{orangenet}{\Upsilon_3^a} & 0 & 0  \\
            0 & 0  &  0 & 0 & 0 \\
            0 & 0  &  0 & 0 & 0 
            \end{pmatrix}}_{T_a} + 
        \underbrace{
            \begin{pmatrix}
            0 & 0  &  0 & 0 & 0 \\
            0 & 0  &  0 & 0 & 0 \\
            0 & 0 & \textcolor{bluenet}{\Upsilon_3^b} & \textcolor{bluenet}{\blacksquare} & \textcolor{bluenet}{\blacksquare}  \\
            0 & 0 & \textcolor{bluenet}{\blacksquare} & \textcolor{bluenet}{\Upsilon_4^b} & \textcolor{bluenet}{\blacksquare} \\
            0 & 0 & \textcolor{bluenet}{\blacksquare} & \textcolor{bluenet}{\blacksquare} & \textcolor{bluenet}{\Upsilon_5^b}  
            \end{pmatrix}}_{T_b}  + 
        \underbrace{
            \begin{pmatrix}
            \textcolor{rednet}{\Upsilon_1^c} & 0 & 0 & 0 &  \textcolor{rednet}{\blacksquare} \\
            0 & 0 & 0 & 0 & 0 \\
            0 & 0 & 0 & 0 & 0 \\
            0 & 0 & 0 & 0 & 0 \\
            \textcolor{rednet}{\blacksquare} & 0 & 0 & 0 &  \textcolor{rednet}{\Upsilon_5^c}
            \end{pmatrix}}_{T_c},
    \end{equation}
    %
    where the off-diagonal blocks are simply the ones from $\Gamma_{\textsc{ncds}}$.

    We see directly that we can extend Proposition \ref{prop:tracenormcrit} as
    %%%%%%%%%%%%%
    \begin{Proposition}[\textsc{Cm} and trace norm criterion for \textsc{ncds} network states.] \label{prop:TraceForNCDS}
        Let $\Gamma_\textsc{ncds} $ be as above. Then
        \begin{equation}
            \tr(\Gamma_\textsc{ncds}) \geq 2 \sum_{x>y=1}^N \norm{\gamma_{xy}}_{\tr}
        \end{equation}
        has to hold.
    \end{Proposition}
    %%%%%%%%%%%%%
    We note that this criterion does not take network topology into account: It treats a network with a single $N-1$-partite source the same way it treats a line network with $N-1$ bipartite sources. While this is interesting as it can exclude states from all networks, we also expect it to be weaker than criteria designed for specific network topologies. On top of that, Proposition \ref{prop:TraceForNCDS} only takes into account that the principal submatrices of each $T_s$ are positive semi-definite, not that the matrices themselves are \textsc{psd}.
    
    As an example, let us consider a $N$-qubit \textsc{ghz} state, $\ket{GHZ_N} = \nicefrac{1}{\sqrt{2}}(\ket{0}^{\otimes N} + \ket{1}^{\otimes N})$, of visibility $v$ mixed with white noise. As observables, we take $\sigma_z^{(x)}$ for each qubit $x$. The resulting \textsc{cm} will have diagonal elements equal to one, whereas the off-diagonal elements will be $v$. Applying the previous proposition, we exclude $N$-partite \textsc{ghz} states mixed with white noise from any \textsc{ncds} network scenario for 
    %
    \begin{equation}
        v > \frac{1}{N-1}.
    \end{equation}
    %
    With $N=3$, we recover the result of the example for the triangle network. 

    Nevertheless, we are forced to observe that the criterion only considers two-body correlation, therefore cannot fully capture the entanglement in the target states. To see this, let us look at the four-qubit cluster state $\ket{Cl}=\ket{+0+0} + \ket{+0-1} + \ket{-1-0} + \ket{-1+1}$ (up to normalisation). Its generators are $\sigma_x \sigma_z \id \id$, $\sigma_z \sigma_x \sigma_z \id$, $\id \sigma_z \sigma_x \sigma_z$ and $\id \id \sigma_z \sigma_x$, where the only two-body correlations are given by $\sigma_x \sigma_z \id \id$ and $\id \id \sigma_z \sigma_x$. A possible set of observables is $\mathcal{S} = \{\sigma_x^{(1)},\sigma_z^{(2)},\sigma_z^{(3)},\sigma_x^{(4)}\}$ and we obtain
    %
    \begin{equation}
        \Gamma(\mathcal{S}, \ket{Cl}) =
            \begin{pmatrix}
                1 & 1 & 0 & 0 \\
                1 & 1 & 0 & 0 \\
                0 & 0 & 1 & 1 \\
                0 & 0 & 1 & 1 
            \end{pmatrix}.
    \end{equation}
    %
    The trace criterion is satisfied and thus we cannot exclude $\ket{Cl}$ from \textsc{ncds} network scenarios by means of Proposition \ref{prop:TraceForNCDS}. Moreover, we directly see that the matrix has a block decomposition, namely $\begin{pmatrix}
        1 & 1 \\
        1 & 1
    \end{pmatrix} \oplus \begin{pmatrix}
        1 & 1 \\
        1 & 1
    \end{pmatrix}$, which \textit{a priori} could arise from a network with two bipartite sources. However, we know from Ref.\@ \cite{hansenne2022} that the four-qubit cluster state cannot be generated in bipartite networks.
    

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Conclusion}
    In this work, we presented alternative proofs to the block decomposition of covariance matrices for network states. From that, we derived analytical criteria to certify that some states cannot be generated through quantum networks as we define them in Eq.\@ \eqref{eq:ctn}. This means that those excluded states either require global sources that connect all nodes, classical communication, non-local operations, or shared randomness to be generated. Concerning the latter resource, we also showed that Propositions \ref{prop:tracenormcrit} can be used to upper bound the fidelity to some target states that \textsc{losr} network states can have. Furthermore, we stress that our criteria are analytical and computable. 

    Regarding extensions of our work, it would be worthwhile to investigate whether the proof of Proposition \ref{prop:BlockDecNCDS} can be extended to networks beyond \textsc{ncds} networks. As shown in Ref.\@ \cite{aberg2020}, the latter is indeed possible, which implies that Propositions \ref{prop:BlockDecNCDS} and \ref{prop:TraceForNCDS} hold for general networks as well.

    Finally, as the field of network entanglement and its potential applications in quantum information theory continues to grow, it may be valuable to investigate additional avenues for identifying compatible network states. Specifically, an area of interest could be finding sufficient criteria for network states, as current results only provide necessary criteria. By developing such criteria, we may be able to learn more about states that \textit{can} be generated in networks without communication and about their potential usefulness, for instance for quantum conference key agreement. In this context, it is interesting to also consider noisy networks: This would translate to imposing additional conditions on the sources states, e.g.\@ by making them travel through depolarisation channels or by constraining their purity.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section*{Acknowledgements}
This work was financially supported by the
Deutsche Forschungsgemeinschaft (DFG, German Research
Foundation, Projects No.\@ 447948357 and No.\@ 440958198),
the Sino-German Center for Research Promotion (Project No.\@
M-0294), the German Ministry of Education and Research
(Project QuKuK, BMBF Grant No.\@ 16KIS1618K) and the House of Young Talents of the University of
Siegen.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\appendix

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section[\appendixname~\thesection]{} \label{app:redobs}
    Here we prove that the off-diagonal blocks of the \textsc{cm} of a triangle network state can be expressed using the reduced observables, that is,
    %
    \begin{equation}
        [\gamma_E]_{mn} = \mean{A_m^{(2)} \otimes B_n^{(1)}} - \mean{A_m^{(2)} } \mean{B_n^{(1)}},
    \end{equation} 
    %
    with
    %
    \begin{equation} 
        \begin{split}
            A_m^{(2)}   &= \tr_{A_1} \left(A_m \varrho_{\textsc{btn}}^{(A_1)} \otimes \id_{A_2} \right) 
        \end{split}
    \end{equation}
    %
    and similarly for $B_n^{(1)}$.
    \begin{proof}[Proof of Eq.\@ \eqref{eq:gammaEwithredobs}]
    	Let us decompose $A_m$ and $B_n$ respectively in orthogonal bases $\{G_\alpha\otimes G_\beta\}$ and $\{G_\gamma \otimes G_\delta\}$ satisfying $\tr(G_\alpha G_{\alpha'})=d \delta_{\alpha \alpha'}$ as
    	\begin{equation}
    		A_m = \frac{1}{d^2} \sum_{\alpha,\beta} \tr(G_\alpha \otimes G_\beta A_m) G_\alpha \otimes G_\beta 
    	\end{equation}
    	and
    	\begin{equation}
    		B_n = \frac{1}{d^2} \sum_{\gamma,\delta} \tr(G_\gamma \otimes G_\delta B_n) G_\gamma \otimes G_\delta,
    	\end{equation}
    	and notice that the reduced states of $\varrho_{\textsc{btn}}$ are product states:
    	\begin{align}
    		&\varrho_{\textsc{btn}}^{(AB)} = \varrho_{\textsc{btn}}^{(A_1)} \otimes \varrho_{\textsc{btn}}^{(A_2B_1)} \otimes \varrho_{\textsc{btn}}^{(B_2)}, \label{eq:btnredAB} \\
    		&\varrho_{\textsc{btn}}^{(A)} = \varrho_{\textsc{btn}}^{(A_1)} \otimes \varrho_{\textsc{btn}}^{(A_2)}, \\ 
    		&\varrho_{\textsc{btn}}^{(B)} = \varrho_{\textsc{btn}}^{(B_1)} \otimes \varrho_{\textsc{btn}}^{(B_2)}. \label{eq:btnredB}
    	\end{align}
        Combining this, $[\gamma_E]_{mn}$ straightforwardly decomposes as 
        %
        \begin{equation}
            \mean{A_m^{(2)} \otimes B_n^{(1)}}_{\varrho_{\textsc{btn}}^{(A_2B_1)}} - \mean{A_m^{(2)}}_{\varrho_{\textsc{btn}}^{(A_2)}} \mean{B_n^{(1)}}_{\varrho_{\textsc{btn}}^{(B_1)}},
        \end{equation}
        %
        and the proof is complete.
    \end{proof}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section[\appendixname~\thesection]{} \label{app:prop1}
    We prove here one of our central results, namely that the \textsc{cm} of a \textsc{btn} state can be decomposed into the sum of \textsc{cm}s with reduced observables, i.e.,
    %%%%%%%%%%%%%
    \begin{customthm}{1}[Block decomposition for \textsc{cm}s of \textsc{btn} states]
    	The \textsc{cm} of a \textsc{btn} state with local observables $\{A_i, B_j,C_k\}$ can be decomposed as
    	\begin{equation}  \label{eq-gammadecAPP}
    	    \begin{split}
        		\Gamma_{\textsc{btn}}   =& \Gamma (\{A_i,B_j,C_k\},\varrho_{\textsc{btn}}) \\
        	                            =&\underbrace{\begin{pmatrix}
        						\Gamma_{A_2} & \gamma_E & 0 \\
        						\gamma_E^T & \Gamma_{B_1} & 0 \\
        						0 & 0 & 0
        					\end{pmatrix}}_{T_c}
        				+	\underbrace{\begin{pmatrix}
        						\Gamma_{A_1} & 0 & \gamma_F \\
        						0 & 0 & 0 \\
        						\gamma_F^T & 0 & \Gamma_{C_2}
        					\end{pmatrix}}_{T_b}
        				+	\underbrace{\begin{pmatrix}
        						0 & 0 & 0 \\
        						0 & \Gamma_{B_2} & \gamma_G \\
        						0 & \gamma_G^T & \Gamma_{C_1}
        					\end{pmatrix}}_{T_a}
        				+ 	\underbrace{\begin{pmatrix}
        						R_A & 0 & 0 \\
        						0 & R_B & 0 \\
        						0 & 0 & R_C
        				\end{pmatrix}}_{R}
    	    \end{split}
    	\end{equation}
    	where the matrices $T_a$, $T_b$ and $T_c$ are \textsc{cm}s for the state-dependent reduced observables, i.e.\@, 
    	\begin{equation}
    		T_c = \Gamma(\{A_i^{(2)} , B_j^{(1)}\}, \varrho_{\textsc{btn}}^{(A_2B_1)}).
    	\end{equation}
    	and analogously for $T_b$ and $T_a$. The matrix $R$ is positive semi-definite. 
    \end{customthm}
    %%%%%%%%%%%%%
    \begin{proof}[Proof of Proposition \ref{prop:cmofbtn}]
    	Following Eq.\@ \eqref{eq-gammadecAPP}, the matrix $R_A$ is given by
    	\begin{equation}\label{eqRa}
    		R_A= \Gamma_A - \Gamma_{A_1} - \Gamma_{A_2},
    	\end{equation}
        where the entries of $\Gamma_{A_2}$ are
    	\begin{equation}
    	[\Gamma_{A_2}]_{mn} = \mean{A_m^{(2)}A_n^{(2)}} - \mean{A_m^{(2)} }\mean{A_n^{(2)}},
    	\end{equation}
    	which is a \textsc{cm} for the reduced observables, evaluated on the state $\varrho_{\textsc{btn}}^{(A_2)}$ only. 
    	Let us now show that such a matrix $R_A$ is positive 
    	semi-definite by showing that $\br{x} R_A \kt{x} \geq 0$ for an 
    	arbitrary complex vector $\kt{x}$. Using the definition 
    	\begin{equation}
    		M = \sum_i x_i A_i
    	\end{equation}
    	and the fact that
    	\begin{equation}
    		M^{(1)} = \sum_i x_i A_i^{(1)} \quad \text{and} \quad M^{(2)} = \sum_i x_i A_i^{(2)},
    	\end{equation}
    	we have that 
            \begin{equation}
            	\begin{split}
            		\br{x} R_A \kt{x} =& 
            		\big(\mean{M^\dagger M} -  \mean{M^\dagger}\mean{M}\big)
            		- \big(\mean{(M^{(1)})^\dagger M^{(1)}}-\mean{M^\dagger}\mean{M} \big) \\
            		&- \big(\mean{(M^{(2)})^\dagger M^{(2)}}- \mean{M^\dagger}\mean{M} \big)
            		\\
            		=& \mean{M^\dagger M} + \mean{M^\dagger}\mean{M} - \mean{(M^{(1)})^\dagger M^{(1)}}
            		-\mean{(M^{(2)})^\dagger M^{(2)}}.
            	\end{split}
            \end{equation}
    	Since $M$ acts on $A_1A_2$, we can use a Schmidt-like decomposition for the bipartition 
    	$A_1 \mid A_2$,
    	\begin{equation}
    		M = \sum_i P_i \otimes Q_i
    	\end{equation}
    	and use the fact that $\varrho_{\textsc{btn}}^{(A_1A_2)}$ is a product state. We then arrive at
            \begin{equation}
            	\begin{split}
            		\br{x} R_A \kt{x} & = 
            		\sum_{ij} 
            		\Big(
            		\mean{P_i^\dagger P_j} \mean{Q_i^\dagger Q_j}
            		+
            		\mean{P_i^\dagger}\mean{P_j} \mean{Q_i^\dagger}\mean{Q_j}
            		- 
            		\mean{P_i^\dagger P_j}\mean{Q_i^\dagger}\mean{Q_j}
            		-
            		\mean{P_i^\dagger}\mean{P_j} \mean{Q_i^\dagger Q_j}
            		\Big)
            		\\
            		& = \tr\left(\big(\Gamma(P)\big)^T \Gamma(Q)\right),
                \end{split}
            \end{equation}
    	where
    	\begin{equation}
    		[\Gamma(P)]_{ij}= \mean{P_i^\dagger P_j}-\mean{P_i^\dagger}\mean{P_j}
    	\end{equation}
    	and similarly $\Gamma(Q)$ are \textsc{cm}s of the observables $\{P_i\}$ in the state $\varrho_{\textsc{btn}}^{A_1}$ and $\varrho_{\textsc{btn}}^{A_2}$, respectively. These matrices are positive semi-definite, 
    	so we have $\tr\left(\big(\Gamma(P)\big)^T \Gamma(Q)\right) \geq 0$, which finishes the proof.
    \end{proof}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section[\appendixname~\thesection]{} \label{app:Rexplicit}
    In the main text, we write (see Eq.\@ \eqref{eq:Rexplicitelements})
    %
    \begin{equation}
        \begin{split}
            R_X = & {\Gamma_X - \Gamma_{X_1} - \Gamma_{X_2}} \\
                = & \Gamma\left(\{G_\alpha\},\varrho_{\textsc{btn}}^{(X_1)}\right) \otimes \Gamma\left(\{G_\beta\},\varrho_{\textsc{btn}}^{(X_2)}\right), \quad X=A,B,C.
        \end{split}
    \end{equation}
    %
    A proof is given by direct calculation.
    \begin{proof}[Proof of Eq.\@ \eqref{eq:Rexplicitelements}]
        We show the statement for $X=A$. The matrices $\Gamma_A$, $\Gamma_{A_1}$ and $\Gamma_{A_2}$ have respectively the following matrix elements  
        \begin{equation}
            [\Gamma_A]_{\alpha\beta \mid \alpha'\beta'} = \mean{(G_\alpha\otimes G_\beta)(G_{\alpha'}\otimes G_{\beta'})} - \mean{G_\alpha \otimes G_\beta} \mean{G_{\alpha'} \otimes G_{\beta'}},
        \end{equation}
        \begin{equation}
            [\Gamma_{A_1}]_{\alpha\beta \mid \alpha'\beta'} = \mean{G_\alpha G_{\alpha'}}\mean{G_\beta}\mean{G_{\beta'}}-\mean{G_\alpha}\mean{G_{\alpha'}}\mean{G_\beta}\mean{G_{\beta'}},
        \end{equation}
        \begin{equation}
            [\Gamma_{A_2}]_{\alpha\beta \mid \alpha'\beta'} = \mean{G_\alpha}\mean{G_{\alpha'}}\mean{G_\beta G_{\beta'}}-\mean{G_\alpha}\mean{G_{\alpha'}}\mean{G_\beta}\mean{G_{\beta'}},
        \end{equation}
        where the expectation values are taken on the state $\varrho_{\textsc{btn}}^{(A)}$, with identity operators padded where needed. So, the matrix elements of $R_A$ are
        \begin{equation}
            \begin{split}
                [R_A]_{\alpha\beta \mid \alpha'\beta'}=&\mean{(G_\alpha\otimes G_\beta)(G_{\alpha'}\otimes G_{\beta'})} - \mean{G_\alpha G_{\alpha'}}\mean{G_\beta}\mean{G_{\beta'}} -\mean{G_\alpha}\mean{G_{\alpha'}}\mean{G_\beta G_{\beta'}} \\
                &+ \mean{G_\alpha}\mean{G_{\alpha'}}\mean{G_\beta}\mean{G_{\beta'}} \\
                =&(\mean{G_\alpha G_{\alpha'}}-\mean{G_\alpha}\mean{G_{\alpha'}})(\mean{G_\beta G_{\beta'}}-\mean{G_\beta}\mean{G_{\beta'}})\\
                =& [\Gamma(\{G_\alpha\},\varrho_{\textsc{btn}}^{(A_1)}]_{ \alpha \alpha'}[\Gamma(\{G_\beta\},\varrho_{\textsc{btn}}^{(A_2)}]_{\beta\beta'}\\
                =&[\Gamma(\{G_\alpha\},\varrho_{\textsc{btn}}^{(A_1)})\otimes \Gamma(\{G_\beta\},\varrho_{\textsc{btn}}^{(A_2)})]_{\alpha\beta \mid \alpha'\beta'}\\
            \end{split}
        \end{equation}
        since $[A \otimes B]_{ij \mid i'j'} = A_{ii'} B_{jj'}$, and therefore
        \begin{equation}
            R_A = \Gamma(\{G_\alpha\},\varrho_{\textsc{btn}}^{(A_1)})\otimes \Gamma(\{G_\beta\},\varrho_{\textsc{btn}}^{(A_2)}).
        \end{equation}
    \end{proof}
    \begin{remark} \label{rem:cmforprodstaes}
    	We note that in general, for a product state $\varrho=\varrho_1\otimes\varrho_2$ and product observables $\{A_k \otimes B_l\}$, it holds that
        %
        \begin{equation}
            \Gamma(\{A_k\otimes B_l\},\varrho)= \kb{\vec{a}}\otimes\Gamma(\{B_l\},\varrho_2) + \Gamma(\{A_k\},\varrho_1) \otimes \kb{\vec{b}} + \Gamma(\{A_k\},\varrho_1) \otimes\Gamma(\{B_l\},\varrho_2),
        \end{equation}
        %
        where $\ket{\vec{a}}$ and $\kt{\vec{b}}$ are the vector with entries $\mean{A_k}_{\varrho_1}$ and $\mean{B_l}_{\varrho_2}$ respectively. In the case of complete sets of orthogonal observables,  $\ket{\vec{a}}$ and $\kt{\vec{b}}$ are the Bloch vectors of $\varrho_1$ and $\varrho_2$ respectively.
    \end{remark}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section[\appendixname~\thesection]{} \label{app:gammaA2}
    In this appendix, we want to show that Eqs.\@ (\ref{eq:gammaA2}--\ref{eqEijdec}) hold, which we recall to be 
    %
    \begin{equation} 
    	\Gamma_{A_2} = \kb{\vec{a}^{(1)}} \otimes \Gamma(\{G_\beta\},\varrho_{\textsc{btn}}^{(A_2)})
    \end{equation}
    %
    and 
    %
    \begin{equation}
        \gamma_E = \kt{\vec{a}^{(1)}}\br{\vec{b}^{(2)}} \otimes \gamma(\{G_\beta,G_\alpha\},\varrho_{\textsc{btn}}^{(A_2B_1)})
    \end{equation}
    %
    respectively, with $\vec{a}^{(1)} \equiv (a_0^{(1)},\dots,a_{d^2-1}^{(1)})^T{\in \mathbb{R}^{d^2}}$ and similarly for $\vec{b}^{(2)}$.
    \begin{proof}[Proof of Eqs.\@ (\ref{eq:gammaA2}--\ref{eqEijdec})]
        A direct calculation shows that
        \begin{equation}
        	\begin{split}
        		[\Gamma_{A_2}]_{mn} 
                \equiv &  [\Gamma_{A_2}]_{\alpha\beta \mid \alpha'\beta'} 
                =  \mean{a_\alpha^{(1)}a_{\alpha'}^{(1)}G_\beta G_{\beta'}} - \mean{a_\alpha^{(1)}G_\beta}\mean{a_{\alpha'}^{(1)} G_{\beta'}} \\
        		= & a_\alpha^{(1)}a_{\alpha'}^{(1)} \left(\mean{G_\beta G_{\beta'}} - \mean{G_\beta}\mean{ G_{\beta'}} \right) \\
        		= & a_\alpha^{(1)}a_{\alpha'}^{(1)} [\Gamma(\{G_\beta\},\varrho_{\textsc{btn}}^{(A_2)})]_{\beta\beta'} \\
        		= & [\kb{\vec{a}^{(1)}} \otimes \Gamma(\{G_\beta\},\varrho_{\textsc{btn}}^{(A_2)})]_{\alpha\beta \mid \alpha'\beta'}
        	\end{split}
        \end{equation}
        and that
        \begin{equation}
        	\begin{split}
        		[\gamma_E]_{mn} \equiv [\gamma_E]_{\alpha\beta \mid \alpha'\beta'} = & a_\alpha^{(1)} b_\beta^{(2)} \left(\mean{G_\beta \otimes G_\alpha} - \mean{G_\beta } \mean{G_\alpha}\right) \\
        		= & [\kt{\vec{a}^{(1)}}\br{\vec{b}^{(2)}}]_{\alpha\beta} [\gamma(\{G_\beta,G_\alpha\},\varrho_{\textsc{btn}}^{(A_2B_1)})]_{\alpha'\beta'} \\
        		= & [\kt{\vec{a}^{(1)}}\br{\vec{b}^{(2)}} \otimes \gamma(\{G_\beta,G_\alpha\},\varrho_{\textsc{btn}}^{(A_2B_1)})]_{\alpha\beta \mid \alpha'\beta'}.
        	\end{split}
        \end{equation}    
    \end{proof}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section[\appendixname~\thesection]{} \label{app:prop7}
    Let us first recall notations from the main text. We have a $N$-node \textsc{ncds} network with a set of sources $\mathds{S}$. The number of sources is given by $\abs{\mathds{S}}$, and each source $s\in \mathds{S}$ is the set of nodes the source connects where the nodes themselves are labelled by $x \in \{1,\dots,N\}$. The sources states are denotes $\varrho_s$, $s \in \mathds{S}$. Each party $x$ obtains $n_x$ qudits from $n_x$ different sources and any two distinct parties share at most one source.
    
    Let $\Gamma_\textsc{ncds}$ be the \textsc{cm} of a global state of such a network with observables $\{A_{x \mid i} : x = 1 , \dots, N\}$, where $A_{x \mid i}$ is the $i$th observables that only acts on the node $x$. We show in this appendix that
    %%%%%%%%%%%%%
    \begin{customthm}{7}[Block decomposition for \textsc{cm}s of \textsc{ncds} network states]
        There exist matrices $\Upsilon_x^s$ ($s \in \mathds{S}$, $x \in s$) such that $\Gamma_\textsc{ncds}$ can be decomposed as a sum of $\abs{\mathds{S}}$ positive semi-definite block matrices $T_s$ ($s \in \mathds{S}$) where the off-diagonal blocks of each $T_s$ are $\gamma_{xy}$ for $\{x,y\} \subset s$ and $0$ for $\{x,y\} \not\subset s$, and where the diagonal blocks are $\Upsilon_x^s$.
    \end{customthm}
    %%%%%%%%%%%%%
    As mentioned in the main text, we first prove the proposition for basic networks with no common double source (\textsc{bncds} networks). The extension to \textsc{ncds} networks without local operations follows using similar tricks to the triangle network scenario. 

    To do so, we extend Remark \ref{rem:cmforprodstaes} to $N$ parties
    %%%%%%%
    \begin{lemma} \label{lemma}
        Let $\varrho = \varrho_1 \otimes \dots \otimes \varrho_N$ be a product state and $\{A_{i_1}^{(1)} \otimes \dots \otimes A_{i_N}^{(N)}\}$ be a set of product observables. The covariance matrix reads
        %
        \begin{equation}
            \Gamma\left( \{A_{i_1}^{(1)} \otimes \dots \otimes A_{i_N}^{(N)}\}, \varrho \right) = \bigotimes_{\alpha = 1}^N \left( \kb{\vec{a}_\alpha} + \Gamma(\{A_{i_\alpha}^{(\alpha)}, \varrho_\alpha) \right) - \bigotimes_{\alpha = 1}^N \kb{\vec{a}_\alpha},
        \end{equation}
        %
        where $\kt{\vec{a}_\alpha}$ is the vector with entries $\mean{A_{i_\alpha}^{(\alpha)}}_{\varrho_\alpha}$.
    \end{lemma}
    %%%%%%%
    \begin{proof}
        The \textsc{cm} has matrix elements 
        %
        \begin{equation} \label{eq:a34}
            \begin{split}
                &[  \Gamma( \{A_{i_1}^{(1)} \otimes \dots \otimes A_{i_N}^{(N)}\}, \varrho) ] _{i_1\dots i_n \mid j_1\dots j_n} \\
                &= \mean{(A_{i_1}^{(1)} \otimes \dots \otimes A_{i_N}^{(N)})(A_{j_1}^{(1)} \otimes \dots \otimes A_{j_N}^{(N)})}_\varrho - \mean{A_{i_1}^{(1)} \otimes \dots \otimes A_{i_N}^{(N)}}_\varrho  \mean{A_{j_1}^{(1)} \otimes \dots \otimes A_{j_N}^{(N)}}_\varrho \\
                &= \prod_{\alpha=1}^N \mean{A_{i_\alpha}A_{j_\alpha}}_{\varrho_\alpha} - \prod_{\alpha=1}^N \mean{A_{i_\alpha}}_{\varrho_\alpha} \mean{A_{j_\alpha}}_{\varrho_\alpha} 
            \end{split}
        \end{equation}
        %
        and 
        %
        \begin{equation}
            \Omega =  \Gamma\left( \{A_{i_1}^{(1)} \otimes \dots \otimes A_{i_N}^{(N)}\}, \varrho \right) = \bigotimes_{\alpha = 1}^N \left( \kb{\vec{a}_\alpha} + \Gamma(\{A_{i_\alpha}^{(\alpha)}, \varrho_\alpha) \right) - \bigotimes_{\alpha = 1}^N \kb{\vec{a}_\alpha}
        \end{equation}
        %
        has matrix elements 
        %
        \begin{equation}
            \begin{split}
                \Omega_{i_1\dots i_n \mid j_1\dots j_n} = \prod_{\alpha = 1}^N \mean{A_{i_\alpha}}_{\varrho_\alpha} \mean{A_{j_\alpha}}_{\varrho_\alpha} +\mean{A_{i_\alpha}A_{j_\alpha}}_{\varrho_\alpha}  - \mean{A_{i_\alpha}}_{\varrho_\alpha} \mean{A_{j_\alpha}}_{\varrho_\alpha} - \prod_{\alpha=1}^N \mean{A_{i_\alpha}}_{\varrho_\alpha} \mean{A_{j_\alpha}}_{\varrho_\alpha},
            \end{split}
        \end{equation}
        %
        which is exactly Eq.\@ \eqref{eq:a34}.
    \end{proof}
    
    We are now ready to prove the block decomposition of a \textsc{cm} of a \textsc{bncds} state with product observables, that is, we furthermore require that the observables are of the form $A_{x  \mid i} = A_{x^1 \mid i} \otimes \dots \otimes A_{x^{n_x} \mid i}$, with $A_{x^1 \mid i}$ acting on the first qudit of the party $x$, labelled $x^1$, and similarly for the others.
    \begin{lemma} \label{lemma:a2}
        Let $\varrho$ be a \textsc{bncds} network state. Let $A_{x  \mid i} = A_{x^1 \mid i} \otimes \dots \otimes A_{x^{n_x} \mid i}$, with $A_{x^1 \mid i}$ acting on the first qudit of the party $x$, labelled $x^1$, and similarly for the others. Then
        %
        \begin{equation}
            \Gamma\left(\{A_{x \mid i}:x=1,\dots,N\}, \varrho \right) = \sum_{s \in \mathds{S}} \Gamma\left( \{A_{x^\alpha \mid i}^\textsc{red}: x^\alpha \in s\}, \varrho_s \right) + \bigoplus_{x=1}^N R_x,
        \end{equation}
        %
        where $R_x$ are \textsc{psd} matrices and 
        %
        \begin{equation}
        \begin{split}
            A^\textsc{red}_{x^\alpha \mid i_\alpha} = \left( \prod_{\beta \neq \alpha, \beta = 1}^{n_x} \mean{A_{x^\beta \mid i_\beta}}_{\varrho^{(x^\beta)}} \right) A_{x^\alpha \mid i_\alpha}.
        \end{split}
        \end{equation}
        %
        We note that the matrices $\Gamma\left( \{A_{x^\alpha \mid i}^\textsc{red}: x^\alpha \in s\}, \varrho_s \right)$ are padded with blocks of zeros where needed, such that they are partitioned in $N \times N$ blocks with the $i$th diagonal block corresponding to the $i$th party.
    \end{lemma}
    \begin{proof}
        From the fact that each subset of observables $\{A_{x \mid i}\}$ only acts on one party of the network, it directly follows that $\Gamma_\textsc{ncds}$ has a block structure, 
        %
        \begin{equation}
            \Gamma_\textsc{ncds} = \begin{pmatrix}
                \Gamma_1 & \gamma_{12} & \dots & \gamma_{1N} \\
                \gamma_{12}^T & \Gamma_{2} & \dots & \gamma_{2N} \\
                \vdots & \vdots & \ddots & \vdots \\
                \gamma_{1N}^T & \gamma_{2N}^T & \dots & \Gamma_{N} \\
            \end{pmatrix}.
        \end{equation}
        %
        
        Let us investigate the structure of $\Gamma_x$ ($x\in\{1,\dots,N\}$) for a \textsc{bncds} network state $\varrho_\textsc{bncds}$. We recall that 
        %
        \begin{equation}
            \Gamma_x = \Gamma \left( \{A_{x^1 \mid i} \otimes \dots \otimes A_{x^{n_x} \mid i}\}_i, \varrho^{(x)}_\textsc{bncds}  \right)
        \end{equation}
        %
        where $\varrho_\textsc{bncds}^{(x)} = \tr_{\hat{x}} ( \varrho_\textsc{bncds})$, $\hat{x} =\{1,\dots,N\} \setminus \{x\}$. For the sake of readability, we will drop the subscript \textsc{bncds} until the end of the proof. As $\varrho^{(x)}$ is a product state, $\Gamma_x$ can be decomposed following Lemma \ref{lemma}, i.e.,
        %
        \begin{equation}
            \Gamma_x = \bigotimes_{\alpha = 1}^N \left( \kb{\vec{x}_\alpha} + \Gamma(\{A_{x^\alpha \mid i_\alpha}\}, \varrho^{(x^\alpha)}) \right) - \bigotimes_{\alpha = 1}^N \kb{\vec{x}_\alpha},
        \end{equation}
        %
        with $\mean{A_{x^\alpha \mid i_\alpha}}_{\varrho^{(x^\alpha)}}$ being the vector elements of $\kt{\vec{x}_\alpha}$. Therein, the summands
        %
        \begin{equation}
            \Gamma(\{A_{x^\alpha \mid i_\alpha}\}, \varrho^{(x^\alpha)}) \bigotimes_{\beta \neq \alpha, \beta = 1}^{n_x} \kb{\vec{x}_\beta}
        \end{equation}
        %
        can be written as
        %
        \begin{equation}
            \Gamma\left( \{A_{x^\alpha\mid i_\alpha}^\textsc{red}\}, \varrho^{(x^\alpha)} \right),
        \end{equation}
        %
        with 
        %
        \begin{equation} \label{eq:redobsncds}
            A^\textsc{red}_{x^\alpha \mid i_\alpha} = \left( \prod_{\beta \neq \alpha, \beta = 1}^{n_x} \mean{A_{x^\beta \mid i_\beta}}_{\varrho^{(x^\beta)}} \right) A_{x^\alpha \mid i_\alpha}.
        \end{equation}
        %

        Now, we analyse the off-diagonal blocks have matrix elements 
        %
        \begin{equation} \label{eq:gammaoffdiag}
            \left[ \gamma_{xy} \right]_{ij} = \mean{A_{x\mid i} \otimes A_{y \mid j}}_{\varrho^{xy}} - \mean{A_{x\mid i}}_{\varrho^{x}} \mean{A_{y\mid j}}_{\varrho^{y}}.
        \end{equation}
        %
        They are trivially equal to zero when the nodes $x$ and $y$ are not connected as in that case, $\varrho^{(xy)} = \varrho^{(x)} \otimes \varrho^{(y)} $. On the other hand, if they do are connected, it is by one source exactly. Without loss of generality, we assume that $x^1$ and $y^1$ are connected by the same source, and the state can be written as
        %
        \begin{equation}
            \varrho^{(xy)} = \varrho^{(x^1 y^1)} \bigotimes_{\alpha=2}^{{n_x}} \varrho^{(x^\alpha)}  \bigotimes_{\beta=2}^{{n_y}} \varrho^{(y^\beta)}.
        \end{equation}
        %
        Therefore, Eq.\@ \eqref{eq:gammaoffdiag} reads
        %
        \begin{equation} \label{eq:offdiagredobs}
            \left[ \gamma_{xy} \right]_{ij} = \left( \mean{A_{x^1 \mid i_1} \otimes A_{y^1 \mid j_1}}_{\varrho^{(x^1 y^1)}} -  \mean{A_{x^1 \mid i_1}}_{\varrho^{(x^1)}}  \mean{A_{y^1 \mid i_1}}_{\varrho^{(y^1)}} \right)  \prod_{\alpha=2}^{n_x} \mean{A_{x^\alpha \mid i_\alpha}}_{\varrho^{(x^\alpha)}} \prod_{\beta=2}^{n_y} \mean{A_{y^\beta \mid i_\beta}}_{\varrho^{(y^\beta)}} ,
        \end{equation}
        %
        which, with the reduced observables of Eq.\@ \eqref{eq:redobsncds} can be written as
        %
        \begin{equation}
            \left[ \gamma_{xy} \right]_{ij} = \mean{A^\textsc{red}_{x^1 \mid i_1} \otimes A^\textsc{red}_{y^1 \mid j_1}}_{\varrho^{(x^1 y^1)}} -  \mean{A^\textsc{red}_{x^1 \mid i_1}}_{\varrho^{(x^1)}}  \mean{A^\textsc{red}_{y^1 \mid i_1}}_{\varrho^{(y^1)}}  .
        \end{equation}
        %

        Finally, putting everything together, we obtain 
        %
        \begin{equation}
            \Gamma\left(\{A_{x \mid i}:x=1,\dots,N\}, \varrho \right) = \sum_{s \in \mathds{S}} \Gamma\left( \{A_{x^\alpha \mid i}^\textsc{red}: x^\alpha \in s\}, \varrho_s \right) + \bigoplus_{x=1}^N R_x,
        \end{equation}
        %
        where 
        %
        \begin{equation}
        \begin{split}
            R_x =& \bigotimes_{\alpha = 1}^{n_x} \left( \kb{\vec{x}_\alpha} + \Gamma(\{A_{x^\alpha \mid i_\alpha}\}, \varrho_\alpha) \right) - \bigotimes_{\alpha = 1}^{n_x} \kb{\vec{x}_\alpha} - \sum_{\alpha = 1}^{n_x} \left( \Gamma(\{A_{x^\alpha \mid i_\alpha}\}, \varrho_\alpha) \bigotimes_{\beta \neq \alpha, \beta = 1}^{n_x} \kb{\vec{x}_\beta}\right) 
        \end{split}
        \end{equation}
        %
        is positive semi-definite.
    \end{proof}

    Now that we have the explicit structure of \textsc{cm}s for product observables on \textsc{bncds} network states, it directly follows that in this case, the \textsc{cm}s have a block decomposition as described in Proposition \ref{prop:BlockDecNCDS}. We use the following lemma to argue that the block decomposition holds for any set of local observables:
    \begin{lemma} \label{lemma:a3}
        Let $\Gamma \left( \{N_i\}_{i=1}^n\}, \varrho \right)$ be a \textsc{cm}. Let $C$ be a real matrix such that $M_j = \sum_{i=1}^n C_{ij} N_i$, $j=1,\dots , m$. Then 
        %
        \begin{equation}
            \Gamma \left( \{M_j\}_{j=1}^m, \varrho\right) = C^T \Gamma \left( \{N_i\}_{i=1}^n, \varrho\right) C.
        \end{equation}
        %
    \end{lemma}
    \begin{proof}
        A direct calculation gives 
        %
        \begin{equation}
            \begin{split}
                \left[\Gamma \left( \{M_j\}_{j=1}^m, \varrho\right) \right]_{kl} =& \sum_{i,j=1}^n \mean{C_{ik}A_i C_{jl}A_j}_\varrho - \mean{C_{ik}A_i}_\varrho \mean{C_{jl}A_j}_\varrho \\
                =& \sum_{i,j} C_{ki}^T \left[\Gamma \left( \{N_i\}_{i=1}^n, \varrho\right)\right]_{ij} C_{jl},
            \end{split}
        \end{equation}
        %
    which proves the claim.
    \end{proof}

    Combining all those results, we are now ready to prove Proposition \ref{prop:BlockDecNCDS}.
    \begin{proof}[Proof of Proposition \ref{prop:BlockDecNCDS}.]
        From Lemma \ref{lemma:a2}, we know that the block decomposition holds for \textsc{bncds} network states with product observables. When those product observables are chosen to be a complete set of observables, Lemma \ref{lemma:a3} shows that the block decomposition holds for any observable set acting on \textsc{bncds} network states. Finally, an analogous reasoning to the cases of \textsc{utn} and \textsc{ctn} leads to the conclusion that the block decomposition holds for states of \textsc{ncds} networks with local operations. 
    \end{proof} 
    
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Please provide either the correct journal abbreviation (e.g. according to the “List of Title Word Abbreviations” http://www.issn.org/services/online-services/access-to-the-ltwa/) or the full name of the journal.
% Citations and References in Supplementary files are permitted provided that they also appear in the reference list here. 

%=====================================
% References, variant A: external bibliography
%=====================================
%\bibliography{your_external_BibTeX_file}

%=====================================
% References, variant B: internal bibliography
%=====================================
\begin{thebibliography}{50} 

% Ref 1
\bibitem[Einstein(1935)]{einstein1935}
Einstein, A.; Podolsky, B.; Rosen, N. {\em Phys. Rev.}, {\bf 1935} {\em 47}, 777.

% Ref 2
\bibitem[Schrödinger(1935)]{schroedinger1935}
Schrödinger, E. {\em Naturwiss.} {\bf 1935} {\em 23}, 844-849.

% Ref 3
\bibitem[Gühne(2009)]{otfried2009}
Gühne, O.; Tóth, G. {\em Phys. Rep.} {\bf 2009}, {\em 474}, 1-75.

% Ref 4
\bibitem[Friis(2019)]{friis2019}
Friis, N.; Vitagliano, G.; Malik, M.; Huber, M. {\em Nat. Rev. Phys.} {\bf 2019}, {\em 1.1}, 72-87.

% Ref 5
\bibitem[Murta(2020)]{murta2020}
Murta, G.; Grasselli, F.; Kampermann, H.; Bruß, D. {\em Adv. Quantum Technol.} {\bf 2020}, {\em 3}, 2000025.

% Ref 6
\bibitem[Scott(2004)]{scott2004}
Scott, A. J. {\em Phys. Rev. A} {\bf 2004}, {\em 69}, 052330.

% Ref 7
\bibitem[Toth(2012)]{toth2012}
Tóth, G. {\em Phys. Rev. A} {\bf 2012}, {\em 85}, 022322.

% Ref 8
\bibitem[Kimble(2008)]{kimble2008}
Kimble, H. J. {\em Nature} {\bf 2008}, {\em 453}, 1023.

%Ref 9
\bibitem[Simon(2017)]{simon2017}
Simon, C. {\em Nat. Phot.} {\bf 2017} {\em 11}, 678.

% Ref 10
\bibitem[Navascues(2020)]{navascues2020}
Navascués, M.; Wolfe, E.; Rosset, D; Pozas-Kerstjens, A. {\em Phys. Rev. Lett.} {\bf 2020}, {\em 125}, 240505.

% Ref 11
\bibitem[Åberg(2020)]{aberg2020}
Åberg, J.; Nery, R.; Duarte, C.; Chaves, R. {\em Phys. Rev. Lett.} {\bf 2020}, {\em 125}, 110505.

% Ref 12
\bibitem[Kraft(2021)]{tristan2021}
Kraft, T.; Designolle, S.; Ritz, C.; Brunner, N.; Gühne, O.; Huber, M. {\em Phys. Rev. A} {\bf 2021}, {\em 103}, L060401.

% Ref 13
\bibitem[Luo(2021)]{luo2021}
Luo, M.-X. {\em Adv. Quantum Technol.} {\bf 2021} {\em 4} 2000123.

% Ref 14
\bibitem[Kraft(2021)]{kraft2021}
Kraft, T.; Spee, C.; Yu, X.-D.; Gühne, O. {\em Phys. Rev. A} {\bf 2021}, {\em 103}, 052405.

% Ref 15
\bibitem[Luo(2021)]{luo2021bis}
Luo, M.-X. {\em arXiv preprint} {\bf 2021}, {\em arXiv:2107.05846}.

% Ref 16
\bibitem[Contreras(2022)]{contreras2022}
Contreras-Tejada, P.; Palazuelos, C.; de Vicente, J. {\em Phys. Rev. Lett.} {\bf 2022}, {\em 128}, 220501.

% Ref 17
\bibitem[Hansenne(2022)]{hansenne2022}
Hansenne, K.; Xu, Z.-P.; Kraft, T.; Gühne, O. {\em Nat. Commun.} {\bf 2022}, {\em 13}, 496.

% Ref 18
\bibitem[Makuta(2022)]{makuta2022}
Makuta, O.; Ligthart, L; Augusiak, R. {\em arXiv preprint}, {\bf 2022}, {\em arXiv:2208.12099}.

%Ref 19
\bibitem[Wang(2022)]{wang2022}
Wang, Y.-X.; Xu, Z.-P.; Gühne, O. {\em arXiv preprint}, {\bf 2022}, {\em arXiv:2208.12100}.

% Ref 20
\bibitem[Werner(2001)]{werner2001}
Werner, R.; Wolf, M. {\em Phys. Rev. Lett.} {\bf 2001}, {\em 86}, 3658.

% Ref 21
\bibitem[Giedke(2001)]{giedke2001}
Giedke, G.; Kraus, B.; Lewenstein, M.; Cirac, J. I. {\em Phys.Rev. Lett.} {\bf 2001}, {\em 87}, 167904.

% Ref 22
\bibitem[Guehne(2007)]{guehne2007}
Gühne, O.; Hyllus, P.; Gittsovich, O.; Eisert, J. {\em Phys. Rev. Lett.} {\bf 2007}, {\em 99}, 130504.

% Ref 23
\bibitem[Gittsovich(2008)]{gittsovich2008}
Gittsovich, O.; Gühne, O.; Hyllus, P.; Eisert, J. {\em Phys. Rev. A} {\bf 2008}, {\em 78}, 052319.

% Ref 24
\bibitem[Beigi(2022)]{beigi2022}
Beigi, S.; Renou, M.-O. {\em IEEE Trans. Inf. Theory} {\bf 2021}, {\em 68}, 384--394.

% Ref 25
\bibitem[Xu(2022)]{zp2022}
Xu, Z.-P. {\em arXiv preprint} {\bf 2022}, arXiv:2210.13751.

% Ref 26
\bibitem[Khatri(1968)]{khatri1968}
Khatri, C. G.; Rao, C. R. {\em Sankhya} {\bf 1968}, {\em 30}, 167.

% Ref 27
\bibitem[Liu(1999)]{liu1999}
Liu, S. {\em Linear algebra and its applications} {\bf 1999}, {\em 289}, 267.

% Ref 28
\bibitem[Heinosaari(2012)]{heinosaari2012}
Heinosaari, T.; Ziman, M. {\em The mathematical language of the quantum theory}; Cambridge University Press: Cambridge, England 2012.

% Ref 29
\bibitem[Gühne(2010)]{otfried2010}
Gühne, O.; Seevinck, M. {\em New J. Phys.} {\bf 2010}, {\em 12}, 053002.

\end{thebibliography}

% If authors have biography, please use the format below
%\section* {Short Biography of Authors}
%\bio
%{\raisebox{-0.35cm}{% Figure removed}}
%{\textbf{Firstname Lastname} Biography of first author}
%
%\bio
%{\raisebox{-0.35cm}{% Figure removed}}
%{\textbf{Firstname Lastname} Biography of second author}

% For the MDPI journals use author-date citation, please follow the formatting guidelines on http://www.mdpi.com/authors/references
% To cite two works by the same author: \citeauthor{ref-journal-1a} (\citeyear{ref-journal-1a}, \citeyear{ref-journal-1b}). This produces: Whittaker (1967, 1975)
% To cite two works by the same author with specific pages: \citeauthor{ref-journal-3a} (\citeyear{ref-journal-3a}, p. 328; \citeyear{ref-journal-3b}, p.475). This produces: Wong (1999, p. 328; 2000, p. 475)

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% for journal Sci
%\reviewreports{\\
%Reviewer 1 comments and authors’ response\\
%Reviewer 2 comments and authors’ response\\
%Reviewer 3 comments and authors’ response
%}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\end{document}

