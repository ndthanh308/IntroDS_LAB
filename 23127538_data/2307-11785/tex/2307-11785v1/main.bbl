\begin{thebibliography}{}

\bibitem[An et~al., 2021]{DBLP:journals/corr/abs-2104-03057}
An, C., Zhong, M., Chen, Y., Wang, D., Qiu, X., and Huang, X. (2021).
\newblock Enhancing scientific papers summarization with citation graph.
\newblock {\em CoRR}, abs/2104.03057.

\bibitem[Bahdanau et~al., 2016]{bahdanau2016neural}
Bahdanau, D., Cho, K., and Bengio, Y. (2016).
\newblock Neural machine translation by jointly learning to align and
  translate.

\bibitem[Brown et~al., 2020]{GPT}
Brown, T.~B., Mann, B., Ryder, N., Subbiah, M., Kaplan, J., Dhariwal, P.,
  Neelakantan, A., Shyam, P., Sastry, G., Askell, A., Agarwal, S.,
  Herbert-Voss, A., Krueger, G., Henighan, T., Child, R., Ramesh, A., Ziegler,
  D.~M., Wu, J., Winter, C., Hesse, C., Chen, M., Sigler, E., Litwin, M., Gray,
  S., Chess, B., Clark, J., Berner, C., McCandlish, S., Radford, A., Sutskever,
  I., and Amodei, D. (2020).
\newblock Language models are few-shot learners.

\bibitem[Buesing et~al., 2018]{DBLP:journals/corr/abs-1811-06272}
Buesing, L., Weber, T., Zwols, Y., Racani{\`{e}}re, S., Guez, A., Lespiau, J.,
  and Heess, N. (2018).
\newblock Woulda, coulda, shoulda: Counterfactually-guided policy search.
\newblock {\em CoRR}, abs/1811.06272.

\bibitem[Chen et~al., 2016]{NIPS2016_7c9d0b1f}
Chen, X., Duan, Y., Houthooft, R., Schulman, J., Sutskever, I., and Abbeel, P.
  (2016).
\newblock Infogan: Interpretable representation learning by information
  maximizing generative adversarial nets.
\newblock In Lee, D., Sugiyama, M., Luxburg, U., Guyon, I., and Garnett, R.,
  editors, {\em Advances in Neural Information Processing Systems}, volume~29.
  Curran Associates, Inc.

\bibitem[Chung et~al., 2014]{GRUPaper}
Chung, J., Gulcehre, C., Cho, K., and Bengio, Y. (2014).
\newblock Empirical evaluation of gated recurrent neural networks on sequence
  modeling.

\bibitem[Feng et~al., 2021]{feng2021survey}
Feng, S.~Y., Gangal, V., Wei, J., Chandar, S., Vosoughi, S., Mitamura, T., and
  Hovy, E. (2021).
\newblock A survey of data augmentation approaches for nlp.

\bibitem[Glover, 2016]{glover2016modeling}
Glover, J. (2016).
\newblock Modeling documents with generative adversarial networks.

\bibitem[Goodfellow et~al., 2014]{goodfellow2014generative}
Goodfellow, I.~J., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D.,
  Ozair, S., Courville, A., and Bengio, Y. (2014).
\newblock Generative adversarial networks.

\bibitem[Haidar and Rezagholizadeh, 2019]{haidar2019textkdgan}
Haidar, M.~A. and Rezagholizadeh, M. (2019).
\newblock Textkd-gan: Text generation using knowledgedistillation and
  generative adversarial networks.

\bibitem[Hochreiter and Schmidhuber, 1997]{LSTMPaper}
Hochreiter, S. and Schmidhuber, J. (1997).
\newblock {Long Short-Term Memory}.
\newblock {\em Neural Computation}, 9(8):1735--1780.

\bibitem[Johansson et~al., 2018]{johansson2018learning}
Johansson, F.~D., Shalit, U., and Sontag, D. (2018).
\newblock Learning representations for counterfactual inference.

\bibitem[Kaushik et~al., 2020]{kaushik2020learning}
Kaushik, D., Hovy, E., and Lipton, Z.~C. (2020).
\newblock Learning the difference that makes a difference with
  counterfactually-augmented data.

\bibitem[Labeau and Cohen, 2019]{labeau-cohen-2019-experimenting}
Labeau, M. and Cohen, S.~B. (2019).
\newblock Experimenting with power divergences for language modeling.
\newblock In {\em Proceedings of the 2019 Conference on Empirical Methods in
  Natural Language Processing and the 9th International Joint Conference on
  Natural Language Processing (EMNLP-IJCNLP)}, pages 4104--4114, Hong Kong,
  China. Association for Computational Linguistics.

\bibitem[Lamb et~al., 2016]{lamb2016professor}
Lamb, A., Goyal, A., Zhang, Y., Zhang, S., Courville, A., and Bengio, Y.
  (2016).
\newblock Professor forcing: A new algorithm for training recurrent networks.

\bibitem[Li et~al., 2015]{li2015hierarchical}
Li, J., Luong, M.-T., and Jurafsky, D. (2015).
\newblock A hierarchical neural autoencoder for paragraphs and documents.

\bibitem[Li et~al., 2017a]{Li2017AdversarialLF}
Li, J., Monroe, W., Shi, T., Jean, S., Ritter, A., and Jurafsky, D. (2017a).
\newblock Adversarial learning for neural dialogue generation.
\newblock {\em ArXiv}, abs/1701.06547.

\bibitem[Li et~al., 2017b]{DBLP:journals/corr/LiMSRJ17}
Li, J., Monroe, W., Shi, T., Ritter, A., and Jurafsky, D. (2017b).
\newblock Adversarial learning for neural dialogue generation.
\newblock {\em CoRR}, abs/1701.06547.

\bibitem[Li et~al., 2020]{LI2020103853}
Li, X., Grandvalet, Y., Davoine, F., Cheng, J., Cui, Y., Zhang, H., Belongie,
  S., Tsai, Y.-H., and Yang, M.-H. (2020).
\newblock Transfer learning in computer vision tasks: Remember where you come
  from.
\newblock {\em Image and Vision Computing}, 93:103853.

\bibitem[Li et~al., 2017c]{li2017dailydialog}
Li, Y., Su, H., Shen, X., Li, W., Cao, Z., and Niu, S. (2017c).
\newblock Dailydialog: A manually labelled multi-turn dialogue dataset.

\bibitem[Luan et~al., 2016]{luan2016lstm}
Luan, Y., Ji, Y., and Ostendorf, M. (2016).
\newblock Lstm based conversation models.

\bibitem[Luketina et~al., 2019]{luketina2019survey}
Luketina, J., Nardelli, N., Farquhar, G., Foerster, J., Andreas, J.,
  Grefenstette, E., Whiteson, S., and Rockt√§schel, T. (2019).
\newblock A survey of reinforcement learning informed by natural language.

\bibitem[Miao and Blunsom, 2016]{miao-blunsom-2016-language}
Miao, Y. and Blunsom, P. (2016).
\newblock Language as a latent variable: Discrete generative models for
  sentence compression.
\newblock In {\em Proceedings of the 2016 Conference on Empirical Methods in
  Natural Language Processing}, pages 319--328, Austin, Texas. Association for
  Computational Linguistics.

\bibitem[Radford et~al., 2016]{radford2016unsupervised}
Radford, A., Metz, L., and Chintala, S. (2016).
\newblock Unsupervised representation learning with deep convolutional
  generative adversarial networks.

\bibitem[Raffel et~al., 2020]{raffel2020exploring}
Raffel, C., Shazeer, N., Roberts, A., Lee, K., Narang, S., Matena, M., Zhou,
  Y., Li, W., and Liu, P.~J. (2020).
\newblock Exploring the limits of transfer learning with a unified text-to-text
  transformer.

\bibitem[Rajeswar et~al., 2017]{rajeswar2017adversarial}
Rajeswar, S., Subramanian, S., Dutil, F., Pal, C., and Courville, A. (2017).
\newblock Adversarial generation of natural language.

\bibitem[Ramamurthy et~al., 2020]{ramamurthy2020nlpgym}
Ramamurthy, R., Sifa, R., and Bauckhage, C. (2020).
\newblock Nlpgym -- a toolkit for evaluating rl agents on natural language
  processing tasks.

\bibitem[Ranzato et~al., 2016]{ranzato2016sequence}
Ranzato, M., Chopra, S., Auli, M., and Zaremba, W. (2016).
\newblock Sequence level training with recurrent neural networks.

\bibitem[Ritter et~al., 2011]{ritter-etal-2011-data}
Ritter, A., Cherry, C., and Dolan, W.~B. (2011).
\newblock Data-driven response generation in social media.
\newblock In {\em Proceedings of the 2011 Conference on Empirical Methods in
  Natural Language Processing}, pages 583--593, Edinburgh, Scotland, UK.
  Association for Computational Linguistics.

\bibitem[Ruder et~al., 2019]{ruder-etal-2019-transfer}
Ruder, S., Peters, M.~E., Swayamdipta, S., and Wolf, T. (2019).
\newblock Transfer learning in natural language processing.
\newblock In {\em Proceedings of the 2019 Conference of the North {A}merican
  Chapter of the Association for Computational Linguistics: Tutorials}, pages
  15--18, Minneapolis, Minnesota. Association for Computational Linguistics.

\bibitem[Rumelhart and McClelland, 1987]{RNNReport}
Rumelhart, D.~E. and McClelland, J.~L. (1987).
\newblock {\em Learning Internal Representations by Error Propagation}, pages
  318--362.

\bibitem[Schmidt, 2019]{Schmidt19}
Schmidt, F. (2019).
\newblock Generalization in generation: A closer look at exposure bias.
\newblock In {\em NGT@EMNLP-IJCNLP}, pages 157--167.

\bibitem[Schuster and Paliwal, 1997]{BiDir}
Schuster, M. and Paliwal, K. (1997).
\newblock Bidirectional recurrent neural networks.
\newblock {\em IEEE Transactions on Signal Processing}, 45(11):2673--2681.

\bibitem[Serban et~al., 2016]{serban2016generative}
Serban, I.~V., Lowe, R., Charlin, L., and Pineau, J. (2016).
\newblock Generative deep neural networks for dialogue: A short review.

\bibitem[Shen et~al., 2018]{shen2018improving}
Shen, X., Su, H., Niu, S., and Demberg, V. (2018).
\newblock Improving variational encoder-decoders in dialogue generation.

\bibitem[Sutskever et~al., 2014]{sutskever2014sequence}
Sutskever, I., Vinyals, O., and Le, Q.~V. (2014).
\newblock Sequence to sequence learning with neural networks.

\bibitem[Vaswani et~al., 2017]{vaswani2017attention}
Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A.~N.,
  Kaiser, L., and Polosukhin, I. (2017).
\newblock Attention is all you need.

\bibitem[Vinyals and Le, 2015]{vinyals2015neural}
Vinyals, O. and Le, Q. (2015).
\newblock A neural conversational model.

\bibitem[Wen et~al., 2017]{pmlr-v70-wen17a}
Wen, T.-H., Miao, Y., Blunsom, P., and Young, S. (2017).
\newblock Latent intention dialogue models.
\newblock In Precup, D. and Teh, Y.~W., editors, {\em Proceedings of the 34th
  International Conference on Machine Learning}, volume~70 of {\em Proceedings
  of Machine Learning Research}, pages 3732--3741. PMLR.

\bibitem[Williams, 1992]{Williams92simplestatistical}
Williams, R.~J. (1992).
\newblock Simple statistical gradient-following algorithms for connectionist
  reinforcement learning.
\newblock In {\em Machine Learning}, pages 229--256.

\bibitem[Xu et~al., 2018]{xu-etal-2018-diversity}
Xu, J., Ren, X., Lin, J., and Sun, X. (2018).
\newblock Diversity-promoting {GAN}: A cross-entropy based generative
  adversarial network for diversified text generation.
\newblock In {\em Proceedings of the 2018 Conference on Empirical Methods in
  Natural Language Processing}, pages 3940--3949, Brussels, Belgium.
  Association for Computational Linguistics.

\bibitem[Yu et~al., 2017]{yu2017seqgan}
Yu, L., Zhang, W., Wang, J., and Yu, Y. (2017).
\newblock Seqgan: Sequence generative adversarial nets with policy gradient.

\bibitem[Zhu et~al., 2020]{DBLP:journals/corr/abs-2004-14507}
Zhu, Q., Zhang, W., Liu, T., and Wang, W.~Y. (2020).
\newblock Counterfactual off-policy training for neural response generation.
\newblock {\em CoRR}, abs/2004.14507.

\bibitem[Zmigrod et~al., 2019]{zmigrod-etal-2019-counterfactual}
Zmigrod, R., Mielke, S.~J., Wallach, H., and Cotterell, R. (2019).
\newblock Counterfactual data augmentation for mitigating gender stereotypes in
  languages with rich morphology.
\newblock In {\em Proceedings of the 57th Annual Meeting of the Association for
  Computational Linguistics}, pages 1651--1661, Florence, Italy. Association
  for Computational Linguistics.

\end{thebibliography}
