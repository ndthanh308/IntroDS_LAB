\begin{thebibliography}{10}\itemsep=-1pt

\bibitem{Dong2022bevbert}
Dong An, Yuankai Qi, Yangguang Li, Yan Huang, Liang Wang, Tieniu Tan, and Jing
  Shao.
\newblock Bevbert: Topo-metric map pre-training for language-guided navigation.
\newblock {\em arXiv preprint arXiv:2212.04385}, 2022.

\bibitem{anderson2018bottom}
Peter Anderson, Xiaodong He, Chris Buehler, Damien Teney, Mark Johnson, Stephen
  Gould, and Lei Zhang.
\newblock Bottom-up and top-down attention for image captioning and visual
  question answering.
\newblock In {\em CVPR}, pages 6077--6086, 2018.

\bibitem{vln-pano2real}
Peter Anderson, Ayush Shrivastava, Joanne Truong, Arjun Majumdar, Devi Parikh,
  Dhruv Batra, and Stefan Lee.
\newblock Sim-to-real transfer for vision-and-language navigation.
\newblock In {\em Conference on Robot Learning (CoRL)}, 2020.

\bibitem{VLN-2018vision}
Peter Anderson, Qi Wu, Damien Teney, Jake Bruce, Mark Johnson, Niko
  S{\"u}nderhauf, Ian Reid, Stephen Gould, and Anton Van Den~Hengel.
\newblock Vision-and-language navigation: Interpreting visually-grounded
  navigation instructions in real environments.
\newblock In {\em CVPR}, pages 3674--3683, 2018.

\bibitem{beeching2020egomap}
Edward Beeching, Jilles Dibangoye, Olivier Simonin, and Christian Wolf.
\newblock Egomap: Projective mapping and structured egocentric memory for deep
  rl.
\newblock In {\em Joint European Conference on Machine Learning and Knowledge
  Discovery in Databases}, pages 525--540. Springer, 2020.

\bibitem{mapnet_aaai}
Vincent Cartillier, Zhile Ren, Neha Jain, Stefan Lee, Irfan Essa, and Dhruv
  Batra.
\newblock Semantic mapnet: Building allocentric semantic maps and
  representations from egocentric views.
\newblock In {\em Proceedings of the AAAI Conference on Artificial
  Intelligence}, volume~35, pages 964--972, 2021.

\bibitem{matterport3d}
Angel Chang, Angela Dai, Thomas Funkhouser, Maciej Halber, Matthias Niessner,
  Manolis Savva, Shuran Song, Andy Zeng, and Yinda Zhang.
\newblock Matterport3d: Learning from rgb-d data in indoor environments.
\newblock In {\em 3DV}, pages 667--676, 2017.

\bibitem{chaplot2020object}
Devendra~Singh Chaplot, Dhiraj~Prakashchand Gandhi, Abhinav Gupta, and Russ~R
  Salakhutdinov.
\newblock Object goal navigation using goal-oriented semantic exploration.
\newblock {\em Advances in Neural Information Processing Systems},
  33:4247--4258, 2020.

\bibitem{Chen_2022_Reinforced}
Jinyu Chen, Chen Gao, Erli Meng, Qiong Zhang, and Si Liu.
\newblock Reinforced structured state-evolution for vision-language navigation.
\newblock In {\em CVPR}, pages 15450--15459, June 2022.

\bibitem{chen2021topo}
Kevin Chen, Junshen~K. Chen, Jo Chuang, Marynel Vázquez, and Silvio Savarese.
\newblock Topological planning with transformers for vision-and-language
  navigation.
\newblock In {\em CVPR}, 2021.

\bibitem{chen2022weakly}
Peihao Chen, Dongyu Ji, Kunyang Lin, Runhao Zeng, Thomas~H Li, Mingkui Tan, and
  Chuang Gan.
\newblock Weakly-supervised multi-granularity map learning for
  vision-and-language navigation.
\newblock In {\em NeurIPS}, 2022.

\bibitem{chen2021history}
Shizhe Chen, Pierre-Louis Guhur, Cordelia Schmid, and Ivan Laptev.
\newblock History aware multimodal transformer for vision-and-language
  navigation.
\newblock In {\em NeurIPS}, volume~34, pages 5834--5847, 2021.

\bibitem{Chen_2022_HM3D_AutoVLN}
Shizhe Chen, Pierre-Louis Guhur, Makarand Tapaswi, Cordelia Schmid, and Ivan
  Laptev.
\newblock Learning from unlabeled 3d environments for vision-and-language
  navigation.
\newblock In {\em ECCV}, pages 638--655, 2022.

\bibitem{chen2022think-GL}
Shizhe Chen, Pierre-Louis Guhur, Makarand Tapaswi, Cordelia Schmid, and Ivan
  Laptev.
\newblock Think global, act local: Dual-scale graph transformer for
  vision-and-language navigation.
\newblock In {\em CVPR}, pages 16537--16547, 2022.

\bibitem{Datta_2022_CVPR}
Samyak Datta, Sameer Dharur, Vincent Cartillier, Ruta Desai, Mukul Khanna,
  Dhruv Batra, and Devi Parikh.
\newblock Episodic memory question answering.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 19119--19128, 2022.

\bibitem{efficient_llm}
Narayanan Deepak, Shoeybi Mohammad, Casper Jared, LeGresley Patrick, Patwary
  Mostofa, Korthikanti Vijay, Vainbrand Dmitri, Kashinkunti Prethvi, Bernauer
  Julie, Catanzaro Bryan, Phanishayee Amar, and Zaharia Matei.
\newblock Efficient large-scale language model training on gpu clusters using
  megatron-lm.
\newblock In {\em Proceedings of the International Conference for High
  Performance Computing, Networking, Storage and Analysis}, 2021.

\bibitem{2020image-vit}
Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn,
  Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg
  Heigold, Sylvain Gelly, et~al.
\newblock An image is worth 16x16 words: Transformers for image recognition at
  scale.
\newblock In {\em ICLR}, 2020.

\bibitem{dou2022foam}
Zi-Yi Dou and Nanyun Peng.
\newblock Foam: A follower-aware speaker model for vision-and-language
  navigation.
\newblock In {\em NAACL}, 2022.

\bibitem{2018-speaker}
Daniel Fried, Ronghang Hu, Volkan Cirik, Anna Rohrbach, Jacob Andreas,
  Louis-Philippe Morency, Taylor Berg-Kirkpatrick, Kate Saenko, Dan Klein, and
  Trevor Darrell.
\newblock Speaker-follower models for vision-and-language navigation.
\newblock In {\em NeurIPS}, volume~31, 2018.

\bibitem{georgakis2022cm2}
Georgios Georgakis, Karl Schmeckpeper, Karan Wanchoo, Soham Dan, Eleni
  Miltsakaki, Dan Roth, and Kostas Daniilidis.
\newblock Cross-modal map learning for vision and language navigation.
\newblock In {\em CVPR}, 2022.

\bibitem{2021airbert}
Pierre-Louis Guhur, Makarand Tapaswi, Shizhe Chen, Ivan Laptev, and Cordelia
  Schmid.
\newblock Airbert: In-domain pretraining for vision-and-language navigation.
\newblock In {\em CVPR}, pages 1634--1643, 2021.

\bibitem{gupta2017cognitive}
Saurabh Gupta, James Davidson, Sergey Levine, Rahul Sukthankar, and Jitendra
  Malik.
\newblock Cognitive mapping and planning for visual navigation.
\newblock In {\em Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 2616--2625, 2017.

\bibitem{hao2020towards}
Weituo Hao, Chunyuan Li, Xiujun Li, Lawrence Carin, and Jianfeng Gao.
\newblock Towards learning a generic agent for vision-and-language navigation
  via pre-training.
\newblock In {\em CVPR}, pages 13137--13146, 2020.

\bibitem{henriques2018mapnet}
Joao~F Henriques and Andrea Vedaldi.
\newblock Mapnet: An allocentric spatial memory for mapping environments.
\newblock In {\em proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, pages 8476--8484, 2018.

\bibitem{hong2020l-e-graph}
Yicong Hong, Cristian Rodriguez, Yuankai Qi, Qi Wu, and Stephen Gould.
\newblock Language and visual entity relationship graph for agent navigation.
\newblock In {\em NeurIPS}, volume~33, pages 7685--7696, 2020.

\bibitem{Hong2022bridging}
Yicong Hong, Zun Wang, Qi Wu, and Stephen Gould.
\newblock Bridging the gap between learning in discrete and continuous
  environments for vision-and-language navigation.
\newblock In {\em CVPR}, June 2022.

\bibitem{hong2021vln-bert}
Yicong Hong, Qi Wu, Yuankai Qi, Cristian Rodriguez-Opazo, and Stephen Gould.
\newblock Vln bert: A recurrent vision-and-language bert for navigation.
\newblock In {\em CVPR}, pages 1643--1653, 2021.

\bibitem{huang23vlmaps}
Chenguang Huang, Oier Mees, Andy Zeng, and Wolfram Burgard.
\newblock Visual language maps for robot navigation.
\newblock In {\em ICRA}, London, UK, 2023.

\bibitem{SASRA}
Muhammad~Zubair Irshad, Niluthpol~Chowdhury Mithun, Zachary Seymour, Han-Pang
  Chiu, Supun Samarasekera, and Rakesh Kumar.
\newblock Sasra: Semantically-aware spatio-temporal reasoning agent for
  vision-and-language navigation in continuous environments.
\newblock {\em arXiv preprint arXiv:2108.11945}, 2021.

\bibitem{li2022envedit}
Mohit~Bansal Jialu~Li, Hao~Tan.
\newblock Envedit: Environment editing for vision-and-language navigation.
\newblock In {\em CVPR}, 2022.

\bibitem{Scaling_rxr}
Aishwarya Kamath, Peter Anderson, Su Wang, Jing~Yu Koh, Alexander Ku, Austin
  Waters, Yinfei Yang, Jason Baldridge, and Zarana Parekh.
\newblock A new path: Scaling vision-and-language navigation with synthetic
  instructions and imitation learning.
\newblock {\em arXiv preprint arXiv:2210.03112}, 2022.

\bibitem{Krantz2021waypointmodel}
Jacob Krantz, Aaron Gokaslan, Dhruv Batra, Stefan Lee, and Oleksandr Maksymets.
\newblock Waypoint models for instruction guided navigation in continuous
  environment.
\newblock In {\em ICCV}, 2021.

\bibitem{krantz2022sim2sim}
Jacob Krantz and Stefan Lee.
\newblock Sim-2-sim transfer for vision-and-language navigation in continuous
  environments.
\newblock In {\em ECCV}, 2022.

\bibitem{Krantz2020r2r-ce}
Jacob Krantz, Erik Wijmans, Arjun Majumdar, Dhruv Batra, and Stefan Lee.
\newblock Beyond the nav-graph: Vision-and-language navigation in continuous
  environments.
\newblock In {\em ECCV}, 2020.

\bibitem{2020-RXR}
Alexander Ku, Peter Anderson, Roma Patel, Eugene Ie, and Jason Baldridge.
\newblock Room-across-room: Multilingual vision-and-language navigation with
  dense spatiotemporal grounding.
\newblock In {\em EMNLP}, pages 4392--4412, 2020.

\bibitem{VLN_LAD_2023}
Mingxiao Li, Zehao Wang, Tinne Tuytelaars, and Marie-Francine Moens.
\newblock Layout-aware dreamer for embodied referring expression grounding.
\newblock In {\em AAAI}, 2023.

\bibitem{isia_mm}
Weijie Li, Xinhang Song, Yubing Bai, Sixian Zhang, and Shuqiang Jiang.
\newblock {ION:} instance-level object navigation.
\newblock In {\em ACM MM}, pages 4343--4352, 2021.

\bibitem{Li2023KERM}
Xiangyang Li, Zihan Wang, Jiahao Yang, Yaowei Wang, and Shuqiang Jiang.
\newblock {KERM: K}nowledge enhanced reasoning for vision-and-language
  navigation.
\newblock In {\em CVPR}, pages 2583--2592, 2023.

\bibitem{liang2022visual}
Xiwen Liang, Fengda Zhu, Lingling Li, Hang Xu, and Xiaodan Liang.
\newblock Visual-language navigation pretraining via prompt-based environmental
  self-exploration.
\newblock In {\em ACL}, pages 4837--4851, 2022.

\bibitem{lin2022adapt}
Bingqian Lin, Yi Zhu, Zicong Chen, Xiwen Liang, Jianzhuang Liu, and Xiaodan
  Liang.
\newblock Adapt: Vision-language navigation with modality-aligned action
  prompts.
\newblock In {\em CVPR}, pages 15396--15406, 2022.

\bibitem{pashevich2021episodic}
Alexander Pashevich, Cordelia Schmid, and Chen Sun.
\newblock Episodic transformer for vision-and-language navigation.
\newblock In {\em ICCV}, 2021.

\bibitem{2020reverie}
Yuankai Qi, Qi Wu, Peter Anderson, Xin Wang, William~Yang Wang, Chunhua Shen,
  and Anton van~den Hengel.
\newblock Reverie: Remote embodied visual referring expression in real indoor
  environments.
\newblock In {\em CVPR}, pages 9982--9991, 2020.

\bibitem{qiao2022HOP}
Yanyuan Qiao, Yuankai Qi, Yicong Hong, Zheng Yu, Peng Wang, and Qi Wu.
\newblock {HOP}: History-and-order aware pre-training for vision-and-language
  navigation.
\newblock In {\em CVPR}, pages 15418--15427, 2022.

\bibitem{qiao2023hop+}
Yanyuan Qiao, Yuankai Qi, Yicong Hong, Zheng Yu, Peng Wang, and Qi Wu.
\newblock Hop+: History-enhanced and order-aware pre-training for
  vision-and-language navigation.
\newblock {\em IEEE Transactions on Pattern Analysis and Machine Intelligence},
  2023.

\bibitem{radford2021learning}
Alec Radford, Jong~Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh,
  Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark,
  et~al.
\newblock Learning transferable visual models from natural language
  supervision.
\newblock In {\em ICML}, pages 8748--8763, 2021.

\bibitem{ramakrishnan2021habitat}
Santhosh~K Ramakrishnan, Aaron Gokaslan, Erik Wijmans, Oleksandr Maksymets,
  Alex Clegg, John Turner, Eric Undersander, Wojciech Galuba, Andrew Westbury,
  Angel~X Chang, et~al.
\newblock Habitat-matterport 3d dataset (hm3d): 1000 large-scale 3d
  environments for embodied ai.
\newblock {\em arXiv preprint arXiv:2109.08238}, 2021.

\bibitem{Raychaudhuri2021law}
Sonia Raychaudhuri, Saim Wani, Shivansh Patel, Unnat Jain, and Angel Chang.
\newblock Language-aligned waypoint (law) supervision for vision-and-language
  navigation in continuous environments.
\newblock In {\em EMNLP}, 2021.

\bibitem{unet}
Olaf Ronneberger, Philipp Fischer, and Thomas Brox.
\newblock U-net: Convolutional networks for biomedical image segmentation.
\newblock In {\em MICCAI}, page 234–241, 2015.

\bibitem{ross2011reduction}
St{\'e}phane Ross, Geoffrey Gordon, and Drew Bagnell.
\newblock A reduction of imitation learning and structured prediction to
  no-regret online learning.
\newblock In {\em AISTATS}, pages 627--635. JMLR Workshop and Conference
  Proceedings, 2011.

\bibitem{2019habitat}
Manolis Savva, Abhishek Kadian, Oleksandr Maksymets, Yili Zhao, Erik Wijmans,
  Bhavana Jain, Julian Straub, Jia Liu, Vladlen Koltun, Jitendra Malik, et~al.
\newblock Habitat: A platform for embodied ai research.
\newblock In {\em ICCV}, pages 9339--9347, 2019.

\bibitem{2019-lxmert}
Hao Tan and Mohit Bansal.
\newblock Lxmert: Learning cross-modality encoder representations from
  transformers.
\newblock In {\em EMNLP}, pages 5103--5114, 2019.

\bibitem{tan2019learning}
Hao Tan, Licheng Yu, and Mohit Bansal.
\newblock Learning to navigate unseen environments: Back translation with
  environmental dropout.
\newblock In {\em NAACL}, pages 2610--2621, 2019.

\bibitem{tang2022monocular}
Tianqi Tang, Heming Du, Xin Yu, and Yi Yang.
\newblock Monocular camera-based point-goal navigation by learning depth
  channel and cross-modality pyramid fusion.
\newblock In {\em Proceedings of the AAAI Conference on Artificial
  Intelligence}, volume~36, pages 5422--5430, 2022.

\bibitem{tang2021auto}
Tianqi Tang, Xin Yu, Xuanyi Dong, and Yi Yang.
\newblock Auto-navigator: Decoupled neural architecture search for visual
  navigation.
\newblock In {\em Proceedings of the IEEE/CVF winter conference on applications
  of computer vision}, pages 3743--3752, 2021.

\bibitem{thomason2020cvdn}
Jesse Thomason, Michael Murray, Maya Cakmak, and Luke Zettlemoyer.
\newblock Vision-and-dialog navigation.
\newblock In {\em PMLR}, 2020.

\bibitem{2021structured-scene}
Hanqing Wang, Wenguan Wang, Wei Liang, Caiming Xiong, and Jianbing Shen.
\newblock Structured scene memory for vision-language navigation.
\newblock In {\em CVPR}, pages 8455--8464, 2021.

\bibitem{Ting2023graph-vlnce}
Ting Wang, Zongkai Wu, Feiyu Yao, and Donglin Wang.
\newblock Graph based environment representation for vision-and-language
  navigation in continuous environments.
\newblock {\em arXiv preprint arXiv:2301.04352}, 2023.

\bibitem{2019reinforced}
Xin Wang, Qiuyuan Huang, Asli Celikyilmaz, Jianfeng Gao, Dinghan Shen,
  Yuan-Fang Wang, William~Yang Wang, and Lei Zhang.
\newblock Reinforced cross-modal matching and self-supervised imitation
  learning for vision-language navigation.
\newblock In {\em CVPR}, pages 6629--6638, 2019.

\bibitem{wani2020multion}
Saim Wani, Shivansh Patel, Unnat Jain, Angel Chang, and Manolis Savva.
\newblock Multion: Benchmarking semantic map memory using multi-object
  navigation.
\newblock {\em Advances in Neural Information Processing Systems},
  33:9700--9712, 2020.

\bibitem{zhang2021vinvl}
Pengchuan Zhang, Xiujun Li, Xiaowei Hu, Jianwei Yang, Lei Zhang, Lijuan Wang,
  Yejin Choi, and Jianfeng Gao.
\newblock Vinvl: Revisiting visual representations in vision-language models.
\newblock In {\em CVPR}, pages 5579--5588, 2021.

\bibitem{zsx_eccv}
Sixian Zhang, Weijie Li, Xinhang Song, Yubing Bai, and Shuqiang Jiang.
\newblock Generative meta-adversarial network for unseen object navigation.
\newblock In {\em ECCV}, volume 13699, pages 301--320.

\bibitem{zsx_iccv}
Sixian Zhang, Xinhang Song, Yubing Bai, Weijie Li, Yakui Chu, and Shuqiang
  Jiang.
\newblock Hierarchical object-to-zone graph for object navigation.
\newblock In {\em ICCV}, pages 15110--15120, 2021.

\bibitem{Zhang_cvpr}
Sixian Zhang, Xinhang Song, Weijie Li, Yubing Bai, Xinyao Yu, and Shuqiang
  Jiang.
\newblock Layout-based causal inference for object navigation.
\newblock In {\em CVPR}, pages 10792--10802, 2023.

\bibitem{zhao2022target}
Yusheng Zhao, Jinyu Chen, Chen Gao, Wenguan Wang, Lirong Yang, Haibing Ren,
  Huaxia Xia, and Si Liu.
\newblock Target-driven structured transformer planner for vision-language
  navigation.
\newblock In {\em ACM MM}, pages 4194--4203, 2022.

\bibitem{zhu2021soon}
Fengda Zhu, Xiwen Liang, Yi Zhu, Qizhi Yu, Xiaojun Chang, and Xiaodan Liang.
\newblock Soon: Scenario oriented object navigation with graph-based
  exploration.
\newblock In {\em CVPR}, pages 12689--12699, 2021.

\bibitem{zhu2019sim}
Fengda Zhu, Linchao Zhu, and Yi Yang.
\newblock Sim-real joint reinforcement transfer for 3d indoor navigation.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 11388--11397, 2019.

\end{thebibliography}
