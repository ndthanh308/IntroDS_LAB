% Encoding: UTF-8
@String(AAAI = {AAAI})
@String(ACCV  = {ACCV})
@String(ACMMM= {ACM Int. Conf. Multimedia})
@String(BMVC= {Brit. Mach. Vis. Conf.})
@String(CGF  = {Comput. Graph. Forum})
@String(CSVT = {IEEE Trans. Circuit Syst. Video Technol.})
@String(CVM = {Computational Visual Media})
@String(CVPR= {IEEE Conf. Comput. Vis. Pattern Recog.})
@String(CVPRW= {IEEE Conf. Comput. Vis. Pattern Recog. Worksh.})
@String(ECCV= {Eur. Conf. Comput. Vis.})
@String(ICASSP=	{ICASSP})
@String(ICCV= {Int. Conf. Comput. Vis.})
@String(ICIP = {IEEE Int. Conf. Image Process.})
@String(ICLR = {Int. Conf. Learn. Represent.})
@String(ICME = {Int. Conf. Multimedia and Expo})
@String(ICPR = {Int. Conf. Pattern Recog.})
@String(IJCAI = {IJCAI})
@String(IJCV = {Int. J. Comput. Vis.})
@String(JCST  = {J. Comput. Sci. Tech.})
@String(JOV	 = {J. Vis.})
@String(NIPS= {Adv. Neural Inform. Process. Syst.})
@String(PAMI = {IEEE Trans. Pattern Anal. Mach. Intell.})
@String(PR   = {Pattern Recognition})

@String(SPL	= {IEEE Sign. Process. Letters})
@String(TCSVT = {IEEE TCSVT})
@String(TIP  = {IEEE Trans. Image Process.})
@String(TMM  = {IEEE Trans. Multimedia})
@String(TOG= {ACM Trans. Graph.})
@String(TVC  = {The Vis. Comput.})
@String(TVCG  = {IEEE Trans. Vis. Comput. Graph.})
@String(VR   = {Vis. Res.})

@InProceedings{chen2022think-GL,
  author    = {Chen, Shizhe and Guhur, Pierre-Louis and Tapaswi, Makarand and Schmid, Cordelia and Laptev, Ivan},
  booktitle = {CVPR},
  title     = {Think Global, Act Local: Dual-scale Graph Transformer for Vision-and-Language Navigation},
  year      = {2022},
  pages     = {16537--16547},
}

@InProceedings{qiao2022HOP,
  author    = {Qiao, Yanyuan and Qi, Yuankai and Hong, Yicong and Yu, Zheng and Wang, Peng and Wu, Qi},
  booktitle = {CVPR},
  title     = {{HOP}: History-and-Order Aware Pre-training for Vision-and-Language Navigation},
  year      = {2022},
  pages     = {15418--15427},
}

@InProceedings{chen2021history,
  author    = {Chen, Shizhe and Guhur, Pierre-Louis and Schmid, Cordelia and Laptev, Ivan},
  booktitle = {NeurIPS},
  title     = {History aware multimodal transformer for vision-and-language navigation},
  year      = {2021},
  pages     = {5834--5847},
  volume    = {34},
}

@InProceedings{hong2020l-e-graph,
  author    = {Hong, Yicong and Rodriguez, Cristian and Qi, Yuankai and Wu, Qi and Gould, Stephen},
  booktitle = {NeurIPS},
  title     = {Language and visual entity relationship graph for agent navigation},
  year      = {2020},
  pages     = {7685--7696},
  volume    = {33}
}

@InProceedings{Chen_2022_HM3D_AutoVLN,
  author    = {Chen, Shizhe and Guhur, Pierre-Louis and Tapaswi, Makarand and Schmid, Cordelia and Laptev, Ivan},
  booktitle = {ECCV},
  title     = {Learning from Unlabeled 3D Environments for Vision-and-Language Navigation},
  year      = {2022},
  pages     = {638--655},
}

@InProceedings{lin2021multimodal,
  author    = {Lin, Chuang and Jiang, Yi and Cai, Jianfei and Qu, Lizhen and Haffari, Gholamreza and Yuan, Zehuan},
  booktitle = {ECCV},
  title     = {Multimodal Transformer with Variable-length Memory for Vision-and-Language Navigation},
  year      = {2022},
  pages     = {380--397}
}

@InProceedings{moudgil2021soat,
  author    = {Moudgil, Abhinav and Majumdar, Arjun and Agrawal, Harsh and Lee, Stefan and Batra, Dhruv},
  booktitle = {NeurIPS},
  title     = {{SOAT}: A scene-and object-aware transformer for vision-and-language navigation},
  year      = {2021},
  pages     = {7357--7367},
  volume    = {34}
}

@InProceedings{2021airbert,
  author    = {Guhur, Pierre-Louis and Tapaswi, Makarand and Chen, Shizhe and Laptev, Ivan and Schmid, Cordelia},
  booktitle = {CVPR},
  title     = {Airbert: In-domain pretraining for vision-and-language navigation},
  year      = {2021},
  pages     = {1634--1643},
}

@InProceedings{VLN-2018vision,
  author    = {Anderson, Peter and Wu, Qi and Teney, Damien and Bruce, Jake and Johnson, Mark and S{\"u}nderhauf, Niko and Reid, Ian and Gould, Stephen and Van Den Hengel, Anton},
  booktitle = {CVPR},
  title     = {Vision-and-language navigation: Interpreting visually-grounded navigation instructions in real environments},
  year      = {2018},
  pages     = {3674--3683},
}

@InProceedings{hong2021vln-bert,
  author    = {Hong, Yicong and Wu, Qi and Qi, Yuankai and Rodriguez-Opazo, Cristian and Gould, Stephen},
  booktitle = {CVPR},
  title     = {Vln bert: A recurrent vision-and-language bert for navigation},
  year      = {2021},
  pages     = {1643--1653},
}

@InProceedings{zhu2021soon,
  author    = {Zhu, Fengda and Liang, Xiwen and Zhu, Yi and Yu, Qizhi and Chang, Xiaojun and Liang, Xiaodan},
  booktitle = {CVPR},
  title     = {Soon: Scenario oriented object navigation with graph-based exploration},
  year      = {2021},
  pages     = {12689--12699},
}

@InProceedings{2020reverie,
  author    = {Qi, Yuankai and Wu, Qi and Anderson, Peter and Wang, Xin and Wang, William Yang and Shen, Chunhua and Hengel, Anton van den},
  booktitle = {CVPR},
  title     = {Reverie: Remote embodied visual referring expression in real indoor environments},
  year      = {2020},
  pages     = {9982--9991},
}

@InProceedings{anderson2018bottom,
  author    = {Anderson, Peter and He, Xiaodong and Buehler, Chris and Teney, Damien and Johnson, Mark and Gould, Stephen and Zhang, Lei},
  booktitle = {CVPR},
  title     = {Bottom-up and top-down attention for image captioning and visual question answering},
  year      = {2018},
  pages     = {6077--6086},
}

@InProceedings{hao2020towards,
  author    = {Hao, Weituo and Li, Chunyuan and Li, Xiujun and Carin, Lawrence and Gao, Jianfeng},
  booktitle = {CVPR},
  title     = {Towards learning a generic agent for vision-and-language navigation via pre-training},
  year      = {2020},
  pages     = {13137--13146},
}

@InProceedings{matterport3d,
  author    = {Chang, Angel and Dai, Angela and Funkhouser, Thomas and Halber, Maciej and Niessner, Matthias and Savva, Manolis and Song, Shuran and Zeng, Andy and Zhang, Yinda},
  booktitle = {3DV},
  title     = {Matterport3d: Learning from rgb-d data in indoor environments},
  year      = {2017},
  pages     = {667-676}
}

@Article{ramakrishnan2021habitat,
  author  = {Ramakrishnan, Santhosh K and Gokaslan, Aaron and Wijmans, Erik and Maksymets, Oleksandr and Clegg, Alex and Turner, John and Undersander, Eric and Galuba, Wojciech and Westbury, Andrew and Chang, Angel X and others},
  journal = {arXiv preprint arXiv:2109.08238},
  title   = {Habitat-matterport 3D dataset (HM3D): 1000 large-scale 3D environments for embodied AI},
  year    = {2021},
}

@InProceedings{2019habitat,
  author    = {Savva, Manolis and Kadian, Abhishek and Maksymets, Oleksandr and Zhao, Yili and Wijmans, Erik and Jain, Bhavana and Straub, Julian and Liu, Jia and Koltun, Vladlen and Malik, Jitendra and others},
  booktitle = {ICCV},
  title     = {Habitat: A platform for embodied ai research},
  year      = {2019},
  pages     = {9339--9347},
}

@InProceedings{2018-gibson,
  author    = {Xia, Fei and Zamir, Amir R and He, Zhiyang and Sax, Alexander and Malik, Jitendra and Savarese, Silvio},
  booktitle = {CVPR},
  title     = {Gibson env: Real-world perception for embodied agents},
  year      = {2018},
  pages     = {9068--9079},
}

@InProceedings{dialog-navigation-2019,
  author        = {Thomason, Jesse and Murray, Michael and Cakmak, Maya and Zettlemoyer, Luke},
  booktitle     = {CoRL},
  title         = {Vision-and-dialog navigation},
  year          = {2019},
  pages         = {394--406},
  organization_ = {PMLR},
}

@InProceedings{2018embodied-ques,
  author    = {Das, Abhishek and Datta, Samyak and Gkioxari, Georgia and Lee, Stefan and Parikh, Devi and Batra, Dhruv},
  booktitle = {CVPR},
  title     = {Embodied question answering},
  year      = {2018},
  pages     = {1--10},
}

@InProceedings{2020alfred,
  author    = {Shridhar, Mohit and Thomason, Jesse and Gordon, Daniel and Bisk, Yonatan and Han, Winson and Mottaghi, Roozbeh and Zettlemoyer, Luke and Fox, Dieter},
  booktitle = {CVPR},
  title     = {Alfred: A benchmark for interpreting grounded instructions for everyday tasks},
  year      = {2020},
  pages     = {10740--10749},
}

@InProceedings{deitke2020robothor,
  author    = {Deitke, Matt and Han, Winson and Herrasti, Alvaro and Kembhavi, Aniruddha and Kolve, Eric and Mottaghi, Roozbeh and Salvador, Jordi and Schwenk, Dustin and VanderBilt, Eli and Wallingford, Matthew and others},
  booktitle = {CVPR},
  title     = {Robothor: An open simulation-to-real embodied ai platform},
  year      = {2020},
  pages     = {3164--3174},
}

@InProceedings{yu2019multi-EQA,
  author    = {Yu, Licheng and Chen, Xinlei and Gkioxari, Georgia and Bansal, Mohit and Berg, Tamara L and Batra, Dhruv},
  booktitle = {CVPR},
  title     = {Multi-target embodied question answering},
  year      = {2019},
  pages     = {6309--6318},
}

@InProceedings{2018-speaker,
  author  = {Fried, Daniel and Hu, Ronghang and Cirik, Volkan and Rohrbach, Anna and Andreas, Jacob and Morency, Louis-Philippe and Berg-Kirkpatrick, Taylor and Saenko, Kate and Klein, Dan and Darrell, Trevor},
  title   = {Speaker-follower models for vision-and-language navigation},
  year    = {2018},
  volume  = {31},
  booktitle = {NeurIPS},
}

@InProceedings{tan2019learning,
  author    = {Tan, Hao and Yu, Licheng and Bansal, Mohit},
  booktitle = {NAACL},
  title     = {Learning to navigate unseen environments: Back translation with environmental dropout},
  year      = {2019},
  pages     = {2610--2621}
}

@InProceedings{2019reinforced,
  author    = {Wang, Xin and Huang, Qiuyuan and Celikyilmaz, Asli and Gao, Jianfeng and Shen, Dinghan and Wang, Yuan-Fang and Wang, William Yang and Zhang, Lei},
  booktitle = {CVPR},
  title     = {Reinforced cross-modal matching and self-supervised imitation learning for vision-language navigation},
  year      = {2019},
  pages     = {6629--6638},
}

@InProceedings{qi2021-road-to-know,
  author    = {Qi, Yuankai and Pan, Zizheng and Hong, Yicong and Yang, Ming-Hsuan and van den Hengel, Anton and Wu, Qi},
  booktitle = {ICCV},
  title     = {The road to know-where: An object-and-room informed sequential bert for indoor vision-language navigation},
  year      = {2021},
  pages     = {1655--1664},
}

@InProceedings{2021structured-scene,
  author    = {Wang, Hanqing and Wang, Wenguan and Liang, Wei and Xiong, Caiming and Shen, Jianbing},
  booktitle = {CVPR},
  title     = {Structured scene memory for vision-language navigation},
  year      = {2021},
  pages     = {8455--8464},
}

@InProceedings{2020-RXR,
  author    = {Ku, Alexander and Anderson, Peter and Patel, Roma and Ie, Eugene and Baldridge, Jason},
  booktitle = {EMNLP},
  title     = {Room-across-room: Multilingual vision-and-language navigation with dense spatiotemporal grounding},
  year      = {2020},
  pages     = {4392-4412}
}

@InProceedings{zhu2020vision,
  author    = {Zhu, Fengda and Zhu, Yi and Chang, Xiaojun and Liang, Xiaodan},
  booktitle = {CVPR},
  title     = {Vision-language navigation with self-supervised auxiliary reasoning tasks},
  year      = {2020},
  pages     = {10012--10022},
}

@InProceedings{gao-2021room,
  author    = {Gao, Chen and Chen, Jinyu and Liu, Si and Wang, Luting and Zhang, Qiong and Wu, Qi},
  booktitle = {PCVPR},
  title     = {Room-and-object aware knowledge reasoning for remote embodied referring expression},
  year      = {2021},
  pages     = {3064--3073},
}

@InProceedings{2019-lxmert,
  author    = {Tan, Hao and Bansal, Mohit},
  booktitle = {EMNLP},
  title     = {Lxmert: Learning cross-modality encoder representations from transformers},
  year      = {2019},
  pages     = {5103--5114}
}

@InProceedings{radford2021learning,
  author        = {Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle     = {ICML},
  title         = {Learning transferable visual models from natural language supervision},
  year          = {2021},
  pages         = {8748--8763},
  organization_ = {PMLR},
}

@InProceedings{lin2022adapt,
  author    = {Lin, Bingqian and Zhu, Yi and Chen, Zicong and Liang, Xiwen and Liu, Jianzhuang and Liang, Xiaodan},
  booktitle = {CVPR},
  title     = {ADAPT: Vision-Language Navigation with Modality-Aligned Action Prompts},
  year      = {2022},
  pages     = {15396--15406},
}

@InProceedings{kuo2022beyond,
  author    = {Kuo, Chia-Wen and Kira, Zsolt},
  booktitle = {CVPR},
  title     = {Beyond a Pre-Trained Object Detector: Cross-Modal Textual and Visual Context for Image Captioning},
  year      = {2022},
  pages     = {17969--17979},
}

@Article{shen2021much,
  author  = {Shen, Sheng and Li, Liunian Harold and Tan, Hao and Bansal, Mohit and Rohrbach, Anna and Chang, Kai-Wei and Yao, Zhewei and Keutzer, Kurt},
  journal = {arXiv preprint arXiv:2107.06383},
  title   = {How Much Can CLIP Benefit Vision-and-Language Tasks?},
  year    = {2021},
}




@Article{wang2017fvqa,
  author    = {Wang, Peng and Wu, Qi and Shen, Chunhua and Dick, Anthony and Van Den Hengel, Anton},
  journal   = {TPAMI},
  title     = {Fvqa: Fact-based visual question answering},
  year      = {2017},
  number    = {10},
  pages     = {2413--2427},
  volume    = {40},
  publisher = {IEEE},
}




@Article{2017visual-genome,
  author    = {Krishna, Ranjay and Zhu, Yuke and Groth, Oliver and Johnson, Justin and Hata, Kenji and Kravitz, Joshua and Chen, Stephanie and Kalantidis, Yannis and Li, Li-Jia and Shamma, David A and others},
  journal   = {IJCV},
  title     = {Visual genome: Connecting language and vision using crowdsourced dense image annotations},
  year      = {2017},
  number    = {1},
  pages     = {32--73},
  volume    = {123},
  publisher = {Springer},
}

@InProceedings{2020image-vit,
  author    = {Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and others},
  booktitle = {ICLR},
  title     = {An image is worth 16x16 words: Transformers for image recognition at scale},
  year      = {2020}
}

@InProceedings{ross2011reduction,
  author       = {Ross, St{\'e}phane and Gordon, Geoffrey and Bagnell, Drew},
  booktitle    = {AISTATS},
  title        = {A reduction of imitation learning and structured prediction to no-regret online learning},
  year         = {2011},
  organization = {JMLR Workshop and Conference Proceedings},
  pages        = {627--635},
}

@InProceedings{zhang2021vinvl,
  author    = {Zhang, Pengchuan and Li, Xiujun and Hu, Xiaowei and Yang, Jianwei and Zhang, Lei and Wang, Lijuan and Choi, Yejin and Gao, Jianfeng},
  booktitle = {CVPR},
  title     = {Vinvl: Revisiting visual representations in vision-language models},
  year      = {2021},
  pages     = {5579--5588},
}



@article{Dong2022bevbert,
  title={BEVBert: Topo-Metric Map Pre-training for Language-guided Navigation},
  author={An, Dong and Qi, Yuankai and Li, Yangguang and Huang, Yan and Wang, Liang and Tan, Tieniu and Shao, Jing},
  journal={arXiv preprint arXiv:2212.04385},
  year={2022}
}



@inproceedings{huang23vlmaps,
          title={Visual Language Maps for Robot Navigation},
          author={Chenguang Huang and Oier Mees and Andy Zeng and Wolfram Burgard},
          booktitle = {ICRA},
          year={2023},
          address = {London, UK}
          } 

@InProceedings{Hong2022bridging,
    author    = {Hong, Yicong and Wang, Zun and Wu, Qi and Gould, Stephen},
    title     = {Bridging the Gap Between Learning in Discrete and Continuous Environments for Vision-and-Language Navigation},
    booktitle = {CVPR},
    month     = {June},
    year      = {2022}
}


@InProceedings{VLN_LAD_2023,
    author    = {Li, Mingxiao and Wang, Zehao and Tuytelaars, Tinne and Moens, Marie-Francine},
    title     = {Layout-aware Dreamer for Embodied Referring Expression Grounding},
    booktitle = {AAAI},
    year      = {2023}
}

@inproceedings{georgakis2022cm2,
  title = {Cross-modal Map Learning for Vision and Language Navigation},
  author = {Georgakis, Georgios and Schmeckpeper, Karl and Wanchoo, Karan and Dan, Soham and Miltsakaki, Eleni and Roth, Dan and Daniilidis, Kostas},
  booktitle = {CVPR},
  year = {2022},
}

@inproceedings{Krantz2020r2r-ce,
  
  author = {Krantz, Jacob and Wijmans, Erik and Majumdar, Arjun and Batra, Dhruv and Lee, Stefan},
  
  title = {Beyond the Nav-Graph: Vision-and-Language Navigation in Continuous Environments},
  
  booktitle = {ECCV},
  
  year = {2020},
}

@InProceedings{Chen_2022_Reinforced,
    author    = {Chen, Jinyu and Gao, Chen and Meng, Erli and Zhang, Qiong and Liu, Si},
    title     = {Reinforced Structured State-Evolution for Vision-Language Navigation},
    booktitle = {CVPR},
    month     = {June},
    year      = {2022},
    pages     = {15450-15459}
}

@inproceedings{pashevich2021episodic,
  title     = {Episodic Transformer for Vision-and-Language Navigation},
  author    = {Alexander Pashevich and Cordelia Schmid and Chen Sun},
  booktitle = {ICCV},
  year      = {2021},
}

@inproceedings{thomason2020cvdn,
  title={Vision-and-Dialog Navigation},
  author={Jesse Thomason and Michael Murray and Maya Cakmak and Luke Zettlemoyer},
  booktitle={PMLR},
  year={2020}
}

@inproceedings{li2022envedit,
  title     = {EnvEdit: Environment Editing for Vision-and-Language Navigation},
  author    = {Jialu Li, Hao Tan, Mohit Bansal},
  booktitle = {CVPR},
  year      = {2022}
}

@inproceedings{liang2022visual,
  title={Visual-Language Navigation Pretraining via Prompt-based Environmental Self-exploration},
  author={Liang, Xiwen and Zhu, Fengda and Li, Lingling and Xu, Hang and Liang, Xiaodan},
  booktitle={ACL},
  pages = {4837-4851},
  year={2022},
}

@inproceedings{dou2022foam,
  title={FOAM: A Follower-aware Speaker Model for Vision-and-Language Navigation},
  author={Dou, Zi-Yi and Peng, Nanyun},
  booktitle={NAACL},
  year={2022},
}

@inproceedings{chen2022weakly,
  title={Weakly-supervised multi-granularity map learning for vision-and-language navigation},
  author={Chen, Peihao and Ji, Dongyu and Lin, Kunyang and Zeng, Runhao and Li, Thomas H and Tan, Mingkui and Gan, Chuang},
  booktitle={NeurIPS},
  year={2022}
}

@inproceedings{chen2021topo,
  
  author = {Chen, Kevin and Chen, Junshen K. and Chuang, Jo and Vázquez, Marynel and Savarese, Silvio},

  title = {Topological Planning with Transformers for Vision-and-Language Navigation},
  
  booktitle = {CVPR},
  
  year = {2021},
 
}

@inproceedings{krantz2022sim2sim,
  author={Krantz, Jacob and Lee, Stefan},
  title={Sim-2-Sim Transfer for Vision-and-Language Navigation in Continuous Environments},
  booktitle={ECCV},
  year={2022}
}

@inproceedings{zhao2022target,
  title={Target-Driven Structured Transformer Planner for Vision-Language Navigation},
  author={Zhao, Yusheng and Chen, Jinyu and Gao, Chen and Wang, Wenguan and Yang, Lirong and Ren, Haibing and Xia, Huaxia and Liu, Si},
  booktitle={ACM MM},
  pages={4194--4203},
  year={2022}
}

@article{krantz2022iterative,
    title = {Iterative Vision-and-Language Navigation},
    author = {Krantz, Jacob and Banerjee, Shurjo and Zhu, Wang and Corso, Jason and Anderson, Peter and Lee, Stefan and Thomason, Jesse},
    year = {2022},
    journal = {arXiv preprint arXiv:2210.03087}
}

@article{Ting2023graph-vlnce,
  author = {Wang, Ting and Wu, Zongkai and Yao, Feiyu and Wang, Donglin},
  title = {Graph based Environment Representation for Vision-and-Language Navigation in Continuous Environments}, 
  year = {2023},
  journal = {arXiv preprint arXiv:2301.04352}
}

@article{ba2016layernorm,
  author = {Ba, Jimmy Lei and Kiros, Jamie Ryan and Hinton, Geoffrey E.},
  title = {Layer Normalization},
  journal = {arXiv preprint arXiv:1607.06450},
  year = {2016},
}

@inproceedings{Raychaudhuri2021law,
  author={Sonia Raychaudhuri and Saim Wani and Shivansh Patel and Unnat Jain and Angel Chang},
  title={Language-aligned waypoint (law) supervision for vision-and-language navigation in continuous environments},
  booktitle={EMNLP},
  year={2021}
}

@inproceedings{Krantz2021waypointmodel,
  author={Jacob Krantz and Aaron Gokaslan and Dhruv Batra and Stefan Lee and Oleksandr Maksymets},
  title={Waypoint models for instruction guided navigation in continuous environment},
  booktitle={ICCV},
  year={2021}
}

@inproceedings{vln-pano2real,
  title={Sim-to-Real Transfer for Vision-and-Language Navigation},
  author={Peter Anderson and Ayush Shrivastava and Joanne Truong and Arjun Majumdar and Devi Parikh and Dhruv Batra and Stefan Lee},
  booktitle={Conference on Robot Learning (CoRL)},
  year={2020}
}

@inproceedings{unet,
  
  author = {Ronneberger, Olaf and Fischer, Philipp and Brox, Thomas},
  
  title = {U-Net: Convolutional Networks for Biomedical Image Segmentation},
  
  booktitle = {MICCAI},
  pages={234–241},
  year = {2015},

}

@article{SASRA,
  author = {Irshad, Muhammad Zubair and Mithun, Niluthpol Chowdhury and Seymour, Zachary and Chiu, Han-Pang and Samarasekera, Supun and Kumar, Rakesh},
  
  title = {SASRA: Semantically-aware Spatio-temporal Reasoning Agent for Vision-and-Language Navigation in Continuous Environments},
  
  journal = {arXiv preprint arXiv:2108.11945},
  year = {2021},
}

@article{Scaling_rxr,
  
  author = {Kamath, Aishwarya and Anderson, Peter and Wang, Su and Koh, Jing Yu and Ku, Alexander and Waters, Austin and Yang, Yinfei and Baldridge, Jason and Parekh, Zarana},
  
  title = {A New Path: Scaling Vision-and-Language Navigation with Synthetic Instructions and Imitation Learning}, 
  
  journal = {arXiv preprint arXiv:2210.03112},
  year = {2022},
}

@inproceedings{efficient_llm,
  author = {Deepak, Narayanan and Mohammad, Shoeybi and Jared, Casper and Patrick, LeGresley and Mostofa, Patwary and Vijay, Korthikanti and Dmitri, Vainbrand and Prethvi, Kashinkunti and Julie, Bernauer and Bryan, Catanzaro and Amar, Phanishayee and Matei, Zaharia},
  title = {Efficient Large-Scale Language Model Training on GPU Clusters Using Megatron-LM},
  booktitle = {Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis},
  year = {2021},
}
@inproceedings{scaling_vit,
  
  author = {Xiaohua Zhai et al},
  
  title = {Scaling Vision Transformers},
  
  booktitle = {CVPR},
  year = {2022},

}

@inproceedings{zsx_eccv,
  author       = {Sixian Zhang and
                  Weijie Li and
                  Xinhang Song and
                  Yubing Bai and
                  Shuqiang Jiang},
  title        = {Generative Meta-Adversarial Network for Unseen Object Navigation},
  booktitle    = {ECCV},
  volume       = {13699},
  pages        = {301--320},
}

@inproceedings{zsx_iccv,
  author       = {Sixian Zhang and
                  Xinhang Song and
                  Yubing Bai and
                  Weijie Li and
                  Yakui Chu and
                  Shuqiang Jiang},
  title        = {Hierarchical Object-to-Zone Graph for Object Navigation},
  booktitle    = {ICCV},
  pages        = {15110--15120},
  year         = {2021},
}

@inproceedings{isia_mm,
  author       = {Weijie Li and
                  Xinhang Song and
                  Yubing Bai and
                  Sixian Zhang and
                  Shuqiang Jiang},
  title        = {{ION:} Instance-level Object Navigation},
  booktitle    = {ACM MM},
  pages        = {4343--4352},
  year         = {2021},
}

@InProceedings{Zhang_cvpr,
    author    = {Zhang, Sixian and Song, Xinhang and Li, Weijie and Bai, Yubing and Yu, Xinyao and Jiang, Shuqiang},
    title     = {Layout-Based Causal Inference for Object Navigation},
    booktitle = {CVPR},
    year      = {2023},
    pages     = {10792-10802}
}


@inproceedings{Datta_2022_CVPR,
  title={Episodic memory question answering},
  author={Datta, Samyak and Dharur, Sameer and Cartillier, Vincent and Desai, Ruta and Khanna, Mukul and Batra, Dhruv and Parikh, Devi},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={19119--19128},
  year={2022}
}


@inproceedings{mapnet_aaai,
  title={Semantic mapnet: Building allocentric semantic maps and representations from egocentric views},
  author={Cartillier, Vincent and Ren, Zhile and Jain, Neha and Lee, Stefan and Essa, Irfan and Batra, Dhruv},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={35},
  number={2},
  pages={964--972},
  year={2021}
}

@InProceedings{Li2023KERM,
  author  = {Xiangyang Li and Zihan Wang and Jiahao Yang and Yaowei Wang and Shuqiang Jiang},
  title   = {{KERM: K}nowledge Enhanced Reasoning for Vision-and-Language Navigation},
  booktitle = {CVPR},
  pages     = {2583-2592},
  year    = {2023},
}



@inproceedings{gupta2017cognitive,
  title={Cognitive mapping and planning for visual navigation},
  author={Gupta, Saurabh and Davidson, James and Levine, Sergey and Sukthankar, Rahul and Malik, Jitendra},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={2616--2625},
  year={2017}
}

@inproceedings{henriques2018mapnet,
  title={Mapnet: An allocentric spatial memory for mapping environments},
  author={Henriques, Joao F and Vedaldi, Andrea},
  booktitle={proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={8476--8484},
  year={2018}
}

@inproceedings{beeching2020egomap,
  title={EgoMap: Projective mapping and structured egocentric memory for Deep RL},
  author={Beeching, Edward and Dibangoye, Jilles and Simonin, Olivier and Wolf, Christian},
  booktitle={Joint European Conference on Machine Learning and Knowledge Discovery in Databases},
  pages={525--540},
  year={2020},
  organization={Springer}
}

@article{chaplot2020object,
  title={Object goal navigation using goal-oriented semantic exploration},
  author={Chaplot, Devendra Singh and Gandhi, Dhiraj Prakashchand and Gupta, Abhinav and Salakhutdinov, Russ R},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={4247--4258},
  year={2020}
}

@article{wani2020multion,
  title={Multion: Benchmarking semantic map memory using multi-object navigation},
  author={Wani, Saim and Patel, Shivansh and Jain, Unnat and Chang, Angel and Savva, Manolis},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={9700--9712},
  year={2020}
}
