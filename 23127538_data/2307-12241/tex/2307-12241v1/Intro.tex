%
%
%
%
%
Clinical depression, a prevalent mental health condition, is considered as one of the leading contributors to the global health-related burden \cite{greenberg2015economic, lepine2011increasing}, affecting millions of people worldwide \cite{vos_et_al_GBD2016,institute2021global}. As a mood disorder, it is characterised by a prolonged (> two weeks) feeling of sadness, worthlessness and hopelessness, a reduced interest and a loss of pleasure in normal daily life activities, sleep disturbances, tiredness and lack of energy. Depression can lead to suicide in extreme cases \cite{goldney2000suicidal} and is often linked to comorbidities such as anxiety disorders, substance abuse disorders, hypertensive diseases, metabolic diseases, and diabetes \cite{steffen_et_al_2020_BMCPsychiatry,campayo2011diabetes}. Although effective treatment options are available, diagnosing depression through self-report and clinical observations presents significant challenges due to the inherent subjectivity and biases involved.

Over the last decade, researchers from affective computing and psychology have focused on investigating objective measures that can aid clinicians in the initial diagnosis and monitoring of treatment progress of clinical depression \cite{cohn2018multimodal, pampouchidou_et_al_TAC_DepressionReview}. A key catalyst to this progress is the availability of relevant datasets, such as AVEC2013 and subsequent challenges~\cite{valstar2013avec}. In recent years, research on depression detection employing affective computing approaches has increasingly focused on leveraging non-verbal behavioural cues such as facial expressions \cite{bourke2010processing, de2019combining}, body gestures \cite{joshi2013relative}, eye gaze \cite{alghowinem2016multimodal}, head movements \cite{alghowinem2013head} and verbal features \cite{cummins2011investigation, huang2019investigation} extracted from multimedia data to develop distinctive features to classify individuals as depressed or healthy controls, or to estimate the severity of depression on a continuous scale. 

In this study, we examine the utility of inherently interpretable head motion units, referred to as \emph{kinemes} \cite{madan_gahalawat_guha_subramanian_ICMI2021_Kinemes}, for assessing depression. Initially, we utilise data from both healthy controls and depressed patients to discover a basis set of kinemes via the (\emph{pitch}, \emph{yaw}, and \emph{roll}) head pose angular data obtained from short overlapping time-segments (termed two-class kineme discovery or 2CKD). Further, we employ these kinemes to generate features based on the frequency of occurrence of distinctive, class-characteristic kinemes. Subsequently, we discover kineme patterns solely from head pose data corresponding to healthy controls (Healthy control kineme discovery or HCKD), and use them to represent both healthy and depressed class segments. A set of statistical features are then computed from the reconstruction errors between the raw and learned head-motion segments corresponding to both the depressed and control classes (see Figure ~\ref{fig:Depression_proposed_framework}). Using machine learning methodologies, we evaluate the performance of the features derived from the two approaches. Our results show that head motion patterns are effective behavioural cues for detecting depression. Additionally, explanatory class-specific kinemes patterns can be observed, in alignment with prior research.  

% Figure environment removed

This paper makes the following research contributions:
%
\begin{itemize}
    \item A study of head movements as a biomarker for clinical depression, which so far has been understudied.
    \item Proposing the \textit{kineme} representation of motion patterns as an effective and explanatory means for depression analysis.
    \item \begin{sloppypar} A detailed investigation of various classifiers for 2-class and 4-class categorisation on the AVEC2013 and BlackDog datasets. We obtain peak F1-scores of 0.79 and 0.82, respectively, on \textit{thin-slice} chunks for binary classification on the BlackDog and AVEC2013 datasets, which compare favorably to prior approaches. Also, a video-level F1-score of 0.72 is achieved for 4-class categorisation on AVEC2013.  \end{sloppypar}
\end{itemize}
%
The remainder of this paper is organised as follows. Section \ref{Sec:RW} provides an overview of related work. Section \ref{Sec:KF} describes the kineme formulation, followed by Section \ref{Sec:EKF} that details the explainable kineme features used as a representation of motion patterns. The methodology is presented in Section \ref{Sec:Meth}, while Section \ref{Sec:ER} provides details of the datasets, experimental settings, and classifiers used in this study. The experimental results are shown and discussed in Section \ref{sec:ResultsDiscussion}. Finally, the conclusions are drawn in Section \ref{Sec:DC}.


% Add the basics of kinemes, the approach used
% Add overview of the framework implemented
% Contribution




