%
This section describes our approach to discovering a set of elementary head motion units termed \emph{kinemes} from 3D head pose angles. These head pose angles are expressed as a time-series of short overlapping segments, which enables shift invariance. The segments are then projected onto a lower-dimensional space and clustered using a Gaussian Mixture Model \cite{samanta2017role}. 

We extracted 3D head pose angles using the OpenFace tool~\cite{Baltrusaitis16} in terms of 3D Euler rotation angles, \emph{pitch} ($\theta_p$), \emph{yaw} ($\theta_y$) and \emph{roll} ($\theta_r$). The head movement over a duration $T$ is denoted as a time-series: $\boldsymbol{\theta} = \{\theta_p^{1:T}, \theta_y^{1:T}, \theta_r^{1:T}\}$. We ensure that the rotation angles remain non-negative by defining the range in [0$^{\circ}$, 360$^{\circ}$]. 

For each video, the multivariate time-series $\boldsymbol{\theta}$ is divided into short overlapping segments of length $\ell$ with overlap $\ell/2$, where the $i^{th}$ segment is represented as a vector $\mathbf{h}^{(i)} = [\theta_p^{i:i+\ell}\, \theta_y^{i:i+\ell}\, \theta_r^{i:i+\ell}]$. Considering the total number of segments in any given video as $s$, the characterisation matrix  $\mathbf{H}_{\boldsymbol\theta}$ for this video is defined as
$ \mathbf{H}_{\boldsymbol\theta} = [\mathbf{h}^{(1)}, \mathbf{h}^{(2)},\cdots, \mathbf{h}^{(s)}]$. Thus, for a training set of $N$ samples, the head motion matrix is created as $\mathbf{H} = [\mathbf{H}_{\boldsymbol\theta_1}|\mathbf{H}_{\boldsymbol\theta_2}|\cdots|\mathbf{H}_{\boldsymbol\theta_N}]$ with each column of $\mathbf{H}$ representing a single head motion time-series for a given video sample. We decompose $\mathbf{H}\in\mathbb{R}_+^{m\times n}$ into a basis matrix $\mathbf{B}\in\mathbb{R}_+^{m\times q}$ and a coefficient matrix $\mathbf{C}\in\mathbb{R}_+^{q\times n}$ using Non-negative Matrix Factorization (NMF) such that $m = 3\ell$, $n = Ns$
%The head motion matrix $\mathbf{H}$ is decomposed into two non-negative matrices  $\mathbf{B}$ and $\mathbf{C}$ as follows: 
\vspace{-1mm}
%
\begin{equation}
    \underset{\mathbf{B} \geq 0, \mathbf{C} \geq 0}{\text{ min}} \lVert{\mathbf{H} - \mathbf{B}\mathbf{C}}\rVert_F^2
\end{equation}
%
where $q \leq min(m, n)$ and $\lVert \textbf{ . }  \rVert_F$ denotes the Frobenius norm. Rather than clustering the raw head motion segments, we employ a more interpretable and stable approach by clustering the coefficient vectors in the transformed space. To this end, we learn a Gaussian Mixture Model (GMM) using the columns of the coefficient matrix $\mathbf{C}$ to produce a ${\mathbf{C}^*}\in\mathbb{R}_+^{q\times k}$ where $k << Ns$. These vectors in the learned subspace are transformed back to the original head motion subspace defined by the Euler angles using $\mathbf{H}^*=\mathbf{B}\mathbf{C}^*$. The columns of matrix $\mathbf{H}^*$ represent the set of $K$ kinemes as $\{\mathcal{K}_i\}_{i=1}^K$. 

Now, we can represent any head motion time-series $\theta$ as a sequence of kinemes discovered from the input video set by associating each segment of length $\ell$ from $\theta$ with one of the kinemes. For each $i^{th}$ segment in the time-series, we compute the characterisation vector $\mathbf{h}^{(i)}$ and project it onto the transformed subspace defined by $\mathbf{B}$ to yield $\mathbf{c}^{(i)}$ such that:\vspace{-1mm}
%
\begin{equation}
    \hat{\mathbf{c}} = \underset{\mathbf{c}^{(i)} \geq 0}{\text{arg min}} \lVert{\mathbf{h}^{(i)} - \mathbf{B}\mathbf{c}^{(i)}}\rVert_F^2
\end{equation}
%
We then maximise the posterior probability $P({K}|\hat{\mathbf{c}})$ over all kinemes to map the $i^{th}$ segment with its corresponding kineme $K^{(i)}$. In the same way, we compute the corresponding kineme label for each segment of length $\ell$ to obtain a sequence of kinemes: $\{K^{(1)} \cdots K^{(s)}\}$, where $K^{(j)}\in \mathcal{K}$ for all segments of time-series $\theta$. 