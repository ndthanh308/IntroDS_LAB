
\section{Conclusion and Discussion}

We introduce the concept of the ripple effects of knowledge editing, suggesting that editing a particular fact implies that many other facts need to be updated. We additionally propose \ripple{}, a diagnostic benchmark designed to evaluate the ripple effects in realistic edits. We further evaluate various KE methods with various models, and show that models often fail to capture the ripple effects of a given knowledge edit. We thus suggest that future development of KE methods should consider those effects more carefully. Finally, we show that a simple in-context editing method achieves the best results on our benchmark, highlighting the potential of such editing approaches.

Our benchmark covers a small fraction of all possible ripple-edits. For example, one could consider ripples that involve more than two hops, and explore
the graph structure of different edits. Finally, it would be interesting to consider cases where models succeed in capturing ripple-edits, and analyze how these are implemented mechanistically in the transformer architecture \cite{geva2023dissecting}.
