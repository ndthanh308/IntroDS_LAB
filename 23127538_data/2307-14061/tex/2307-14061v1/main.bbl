\begin{thebibliography}{10}\itemsep=-1pt

\bibitem{Anderson2016SPICE}
Peter Anderson, Basura Fernando, Mark Johnson, and Stephen Gould.
\newblock Spice: Semantic propositional image caption evaluation.
\newblock In {\em ECCV}, 2016.

\bibitem{Banerjee2005METEORAA}
Satanjeev Banerjee and Alon Lavie.
\newblock Meteor: An automatic metric for mt evaluation with improved
  correlation with human judgments.
\newblock In {\em IEEvaluation@ACL}, 2005.

\bibitem{Carlini2017CW}
Nicholas Carlini and David~A. Wagner.
\newblock Towards evaluating the robustness of neural networks.
\newblock {\em 2017 IEEE Symposium on Security and Privacy (SP)}, pages 39--57,
  2017.

\bibitem{Chen2020IMRAM}
Hui Chen, Guiguang Ding, Xudong Liu, Zijia Lin, Ji Liu, and Jungong Han.
\newblock Imram: Iterative matching with recurrent attention memory for
  cross-modal image-text retrieval.
\newblock {\em 2020 IEEE/CVF Conference on Computer Vision and Pattern
  Recognition (CVPR)}, pages 12652--12660, 2020.

\bibitem{Chen2020UNITER}
Yen-Chun Chen, Linjie Li, Licheng Yu, Ahmed~El Kholy, Faisal Ahmed, Zhe Gan, Yu
  Cheng, and Jingjing Liu.
\newblock Uniter: Universal image-text representation learning.
\newblock In {\em ECCV}, 2020.

\bibitem{Cheng2022ViSTAVA}
Mengjun Cheng, Yipeng Sun, Long Wang, Xiongwei Zhu, Kun Yao, Jie Chen, Guoli
  Song, Junyu Han, Jingtuo Liu, Errui Ding, and Jingdong Wang.
\newblock Vista: Vision and scene text aggregation for cross-modal retrieval.
\newblock {\em 2022 IEEE/CVF Conference on Computer Vision and Pattern
  Recognition (CVPR)}, pages 5174--5183, 2022.

\bibitem{Dong2018BoostingAA}
Yinpeng Dong, Fangzhou Liao, Tianyu Pang, Hang Su, Jun Zhu, Xiaolin Hu, and
  Jianguo Li.
\newblock Boosting adversarial attacks with momentum.
\newblock {\em 2018 IEEE/CVF Conference on Computer Vision and Pattern
  Recognition}, pages 9185--9193, 2018.

\bibitem{Dosovitskiy2021ViT}
Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn,
  Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg
  Heigold, Sylvain Gelly, Jakob Uszkoreit, and Neil Houlsby.
\newblock An image is worth 16x16 words: Transformers for image recognition at
  scale.
\newblock {\em ArXiv}, abs/2010.11929, 2021.

\bibitem{Dou2021METER}
Zi-Yi Dou, Yichong Xu, Zhe Gan, Jianfeng Wang, Shuohang Wang, Lijuan Wang,
  Chenguang Zhu, Nanyun Peng, Zicheng Liu, and Michael Zeng.
\newblock An empirical study of training end-to-end vision-and-language
  transformers.
\newblock {\em ArXiv}, abs/2111.02387, 2021.

\bibitem{wei2022PNA_PO}
Wei et al.
\newblock Towards transferable adversarial attacks on vision transformers.
\newblock In {\em AAAI}, 2022.

\bibitem{Gao2018BlackBoxGO}
Ji Gao, Jack Lanchantin, Mary~Lou Soffa, and Yanjun Qi.
\newblock Black-box generation of adversarial text sequences to evade deep
  learning classifiers.
\newblock {\em 2018 IEEE Security and Privacy Workshops (SPW)}, pages 50--56,
  2018.

\bibitem{Goodfellow2015FGSM}
Ian~J. Goodfellow, Jonathon Shlens, and Christian Szegedy.
\newblock Explaining and harnessing adversarial examples.
\newblock {\em CoRR}, abs/1412.6572, 2015.

\bibitem{He2016ResNet}
Kaiming He, X. Zhang, Shaoqing Ren, and Jian Sun.
\newblock Deep residual learning for image recognition.
\newblock {\em 2016 IEEE Conference on Computer Vision and Pattern Recognition
  (CVPR)}, pages 770--778, 2016.

\bibitem{Jin2020IsBR}
Di Jin, Zhijing Jin, Joey~Tianyi Zhou, and Peter Szolovits.
\newblock Is bert really robust? a strong baseline for natural language attack
  on text classification and entailment.
\newblock In {\em AAAI}, 2020.

\bibitem{Karpathy2017KarpathySplit}
Andrej Karpathy and Li Fei-Fei.
\newblock Deep visual-semantic alignments for generating image descriptions.
\newblock {\em IEEE Transactions on Pattern Analysis and Machine Intelligence},
  39:664--676, 2017.

\bibitem{Khan2021ExploitingBF}
Zaid Khan and Yun~Raymond Fu.
\newblock Exploiting bert for multimodal target sentiment classification
  through input space translation.
\newblock {\em Proceedings of the 29th ACM International Conference on
  Multimedia}, 2021.

\bibitem{Lei2021UnderstandingCV}
Chenyi Lei, Shixian Luo, Yong Liu, Wanggui He, Jiamang Wang, Guoxin Wang,
  Haihong Tang, Chunyan Miao, and Houqiang Li.
\newblock Understanding chinese video and language via contrastive multimodal
  pre-training.
\newblock {\em Proceedings of the 29th ACM International Conference on
  Multimedia}, 2021.

\bibitem{Li2022BLIP}
Junnan Li, Dongxu Li, Caiming Xiong, and Steven C.~H. Hoi.
\newblock Blip: Bootstrapping language-image pre-training for unified
  vision-language understanding and generation.
\newblock {\em ArXiv}, abs/2201.12086, 2022.

\bibitem{Li2021ALBEF}
Junnan Li, Ramprasaath~R. Selvaraju, Akhilesh~Deepak Gotmare, Shafiq~R. Joty,
  Caiming Xiong, and Steven C.~H. Hoi.
\newblock Align before fuse: Vision and language representation learning with
  momentum distillation.
\newblock In {\em NeurIPS}, 2021.

\bibitem{Li2020BERTATTACK}
Linyang Li, Ruotian Ma, Qipeng Guo, X. Xue, and Xipeng Qiu.
\newblock Bert-attack: Adversarial attack against bert using bert.
\newblock {\em ArXiv}, abs/2004.09984, 2020.

\bibitem{Li2020Oscar}
Xiujun Li, Xi Yin, Chunyuan Li, Xiaowei Hu, Pengchuan Zhang, Lei Zhang, Lijuan
  Wang, Houdong Hu, Li Dong, Furu Wei, Yejin Choi, and Jianfeng Gao.
\newblock Oscar: Object-semantics aligned pre-training for vision-language
  tasks.
\newblock In {\em ECCV}, 2020.

\bibitem{Lin2004ROUGEAP}
Chin-Yew Lin.
\newblock Rouge: A package for automatic evaluation of summaries.
\newblock In {\em Annual Meeting of the Association for Computational
  Linguistics}, 2004.

\bibitem{Lin2019NesterovScaleInva}
Jiadong Lin, Chuanbiao Song, Kun He, Liwei Wang, and John~E. Hopcroft.
\newblock Nesterov accelerated gradient and scale invariance for adversarial
  attacks.
\newblock {\em arXiv: Learning}, 2019.

\bibitem{Lin2014COCO}
Tsung-Yi Lin, Michael Maire, Serge~J. Belongie, James Hays, Pietro Perona, Deva
  Ramanan, Piotr Doll{\'a}r, and C.~Lawrence Zitnick.
\newblock Microsoft coco: Common objects in context.
\newblock In {\em ECCV}, 2014.

\bibitem{Madry2018PGD}
Aleksander Madry, Aleksandar Makelov, Ludwig Schmidt, Dimitris Tsipras, and
  Adrian Vladu.
\newblock Towards deep learning models resistant to adversarial attacks.
\newblock {\em ArXiv}, abs/1706.06083, 2018.

\bibitem{Naseer2021IntriguingViT}
Muzammal Naseer, Kanchana Ranasinghe, Salman~Hameed Khan, Munawar Hayat,
  Fahad~Shahbaz Khan, and Ming-Hsuan Yang.
\newblock Intriguing properties of vision transformers.
\newblock In {\em Neural Information Processing Systems}, 2021.

\bibitem{Papineni2002BLEU}
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu.
\newblock Bleu: a method for automatic evaluation of machine translation.
\newblock In {\em ACL}, 2002.

\bibitem{Plummer2015Flickr30k}
Bryan~A. Plummer, Liwei Wang, Christopher~M. Cervantes, Juan~C. Caicedo, J.
  Hockenmaier, and Svetlana Lazebnik.
\newblock Flickr30k entities: Collecting region-to-phrase correspondences for
  richer image-to-sentence models.
\newblock {\em International Journal of Computer Vision}, 123:74--93, 2015.

\bibitem{Radford2021CLIP}
Alec Radford, Jong~Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh,
  Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark,
  Gretchen Krueger, and Ilya Sutskever.
\newblock Learning transferable visual models from natural language
  supervision.
\newblock In {\em ICML}, 2021.

\bibitem{Ren2019NLP_Adv_Saliency}
Shuhuai Ren, Yihe Deng, Kun He, and Wanxiang Che.
\newblock Generating natural language adversarial examples through probability
  weighted word saliency.
\newblock In {\em ACL}, 2019.

\bibitem{Shi2021DenseCV}
Lei Shi, Kai Shuang, Shijie Geng, Peng Gao, Zuohui Fu, Gerard de Melo, Yunpeng
  Chen, and Sen Su.
\newblock Dense contrastive visual-linguistic pretraining.
\newblock {\em Proceedings of the 29th ACM International Conference on
  Multimedia}, 2021.

\bibitem{Touvron2021TrainingDI_forBLIP_arhc}
Hugo Touvron, Matthieu Cord, Matthijs Douze, Francisco Massa, Alexandre
  Sablayrolles, and Herv'e J'egou.
\newblock Training data-efficient image transformers \& distillation through
  attention.
\newblock In {\em ICML}, 2021.

\bibitem{Vedantam2015CIDEr}
Ramakrishna Vedantam, C.~Lawrence Zitnick, and Devi Parikh.
\newblock Cider: Consensus-based image description evaluation.
\newblock {\em 2015 IEEE Conference on Computer Vision and Pattern Recognition
  (CVPR)}, pages 4566--4575, 2015.

\bibitem{wang2023accelerating}
Teng Wang, Yixiao Ge, Feng Zheng, Ran Cheng, Ying Shan, Xiaohu Qie, and Ping
  Luo.
\newblock Accelerating vision-language pretraining with free language modeling.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 23161--23170, 2023.

\bibitem{wang2022vlmixer}
Teng Wang, Wenhao Jiang, Zhichao Lu, Feng Zheng, Ran Cheng, Chengguo Yin, and
  Ping Luo.
\newblock Vlmixer: Unpaired vision-language pre-training via cross-modal
  cutmix.
\newblock In {\em International Conference on Machine Learning}, pages
  22680--22690. PMLR, 2022.

\bibitem{Wang2019CAMP}
Zihao Wang, Xihui Liu, Hongsheng Li, Lu Sheng, Junjie Yan, Xiaogang Wang, and
  Jing Shao.
\newblock Camp: Cross-modal adaptive message passing for text-image retrieval.
\newblock {\em 2019 IEEE/CVF International Conference on Computer Vision
  (ICCV)}, pages 5763--5772, 2019.

\bibitem{Xie2018ImprovingTransDiverse}
Cihang Xie, Zhishuai Zhang, Jianyu Wang, Yuyin Zhou, Zhou Ren, and Alan~Loddon
  Yuille.
\newblock Improving transferability of adversarial examples with input
  diversity.
\newblock {\em 2019 IEEE/CVF Conference on Computer Vision and Pattern
  Recognition (CVPR)}, pages 2725--2734, 2018.

\bibitem{Yang2022TCL}
Jinyu Yang, Jiali Duan, S. Tran, Yi Xu, Sampath Chanda, Liqun Chen, Belinda
  Zeng, Trishul~M. Chilimbi, and Junzhou Huang.
\newblock Vision-language pre-training with triple contrastive learning.
\newblock {\em ArXiv}, abs/2202.10401, 2022.

\bibitem{Yu2016RefCOCO}
Licheng Yu, Patrick Poirson, Shan Yang, Alexander~C. Berg, and Tamara~L. Berg.
\newblock Modeling context in referring expressions.
\newblock {\em ArXiv}, abs/1608.00272, 2016.

\bibitem{Yuan2021TokenstoTokenVT}
Li Yuan, Yunpeng Chen, Tao Wang, Weihao Yu, Yujun Shi, Francis E.~H. Tay,
  Jiashi Feng, and Shuicheng Yan.
\newblock Tokens-to-token vit: Training vision transformers from scratch on
  imagenet.
\newblock {\em 2021 IEEE/CVF International Conference on Computer Vision
  (ICCV)}, pages 538--547, 2021.

\bibitem{Zhang2022Co-attack}
Jiaming Zhang, Qiaomin Yi, and Jitao Sang.
\newblock Towards adversarial attack on vision-language pre-training models.
\newblock {\em Proceedings of the 30th ACM International Conference on
  Multimedia}, 2022.

\bibitem{Zhang2021VinVL}
Pengchuan Zhang, Xiujun Li, Xiaowei Hu, Jianwei Yang, Lei Zhang, Lijuan Wang,
  Yejin Choi, and Jianfeng Gao.
\newblock Vinvl: Revisiting visual representations in vision-language models.
\newblock {\em 2021 IEEE/CVF Conference on Computer Vision and Pattern
  Recognition (CVPR)}, pages 5575--5584, 2021.

\bibitem{Zhang2020ContextAwareAN}
Qi Zhang, Zhen Lei, Zhaoxiang Zhang, and S. Li.
\newblock Context-aware attention network for image-text retrieval.
\newblock {\em 2020 IEEE/CVF Conference on Computer Vision and Pattern
  Recognition (CVPR)}, pages 3533--3542, 2020.

\end{thebibliography}
