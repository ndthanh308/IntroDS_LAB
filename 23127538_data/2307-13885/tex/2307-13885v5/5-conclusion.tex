\section{Conclusion}

In this work, we find that adversarial robustness does not provide a comprehensive picture of model behavior, and to this end, we propose the usage of average-case robustness. While adversarial robustness is more suited for applications in model security, average-case robustness is suited for model understanding and debugging. 
To our knowledge, this work is the first to investigate analytical estimators for average-case robustness in a multi-class setting. The analytical aspect of these estimators helps understand average-case robustness via model decision boundaries, and also connect to ideas such as Randomized Smoothing (via the MMSE estimator) and softmax probabilities.

Future research directions include exploring additional applications of average-case robustness, such as training average-case robust models that minimize the probability of misclassification and debugging-oriented applications such as detecting model memorization, and dataset outliers.

\vspace{0.2cm}
\textbf{Code availability.}
Code is available at \url{https://github.com/AI4LIFE-GROUP/average-case-robustness}.
