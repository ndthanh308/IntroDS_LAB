\section{Experimental Evaluation}

We first evaluate the accuracy and efficiency of the analytical estimators. Then, we analyze the relationship between local robustness and softmax probability. Lastly, we demonstrate the usefulness of the estimators in real-world applications. 


\textbf{Datasets and Models.}
We use four datasets: MNIST \citep{deng2012mnist}, FashionMNIST \citep{xiao2017fashion}, CIFAR10 \citep{krizhevsky2009learning}, and CIFAR100 \citep{krizhevsky2009learning}. For MNIST and FashionMNIST, we train linear models and CNNs. For CIFAR10 and CIFAR100, we train ResNet18 \citep{he2016deep} models with varying levels of gradient norm regularization ($\lambda$) for varying levels of robustness. For experiments, we use 1,000 randomly-selected points from each dataset's test set. Details about datasets and models are in Appendix~\ref{app:datasets} and \ref{app:models}.


\subsection{Evaluation of the accuracy of analytical estimators}
\label{sec:exp_correctness}

\textbf{The analytical estimators accurately compute local robustness.}
We calculate \probust{} for each model using all six estimators for different $\sigma$'s. Then, we measure the absolute and relative difference between \pmc{} and the other estimators (Figure~\ref{fig1a:method-works-over-sigma}). The results indicate that \pmmsemvs{} and \pmmse{} are the best estimators of \probust{}, followed closely by \ptaylormvs{} and \ptaylor{}, and trailed by \psoftmax{}. The smaller the $\sigma$, the more accurate the estimators. In addition, for robust models, the analytical estimators are more accurate over a larger $\sigma$ (Appendix~\ref{app:experiments-main}). The \emph{mv-sigmoid} function also approximates the \emph{mvn-cdf} well in practice (Appendix~\ref{app:experiments-main}). Consistent with the theory in Section~\ref{sec:methods}, these results indicate that the analytical estimators accurately compute \probust{}.
% \footnote{For \pmc{}, \pmmse{}, and \pmmsemvs{}, we use a sample size at which these estimators have converged ($n=10000, 1000, \text{and } 1000$; Appendix~\ref{app:experiments}).} 
% (henceforth, these estimators use these sample sizes)
% The smaller these differences, the more accurately the estimator computes \probust{}.

% Consistent with the theory in Section~\ref{sec:methods}, the MMSE estimators outperform the Taylor ones because the former obtains better estimates of $\grad g_i(\X)$, and \psoftmax{} performs poorly in general settings because of its multiple levels of approximation.

%smaller noise neighborhood, better approximation
% The results also show that the smaller the noise neighborhood $\sigma$, the more accurately the estimators compute \probust{}. For the MMSE and Taylor estimators, this is because their linear approximation of the model around the input is more accurate for smaller $\sigma$'s. As expected, when the model is linear, \ptaylor{} and \pmmse{} accurately compute \probust{} for all $\sigma$'s (Appendix~\ref{app:experiments}). For \psoftmax{}, values are constant across $\sigma$ and this particular model has high \psoftmax{} values for most points. Thus, for small $\sigma$'s where \probust{} is near one, \psoftmax{} happens to approximate \probust{} for this particular model.




% fig1 -- method properly approximates p_empirical
% fig1a: method works
% 02e_pemp_vs_pothers_over_noise/rel/cnn_fmnist.png
% Figure environment removed





% %fig1 -- method properly approximates p_empirical
% %fig1a: method works
% %02e_pemp_vs_pothers_over_noise/rel/cnn_fmnist.png
% %fig1b: method works better for robust models
% %02l_pemp_vs_pmmse_over_noise_robust_models/rel/resnet18_cifar10.png
% % Figure environment removed




%table: naive method is inefficient, analytical method is efficient
\begin{table}[ht!]
\small
\centering
\begin{tabular}{l|l|l|l|l|l}
      & \multicolumn{2}{|c|}{CPU: Intel x86\_64}   & \multicolumn{2}{|c|}{GPU: Tesla V100} \\
    \midrule
    Estimator     & Serial   & Batched   & Serial   & Batched \\
    \midrule
    \pmc{}($n=10000$)                
             & \begin{tabular}[c]{@{}l@{}}  1:41:11\end{tabular}                                               
             & \begin{tabular}[c]{@{}l@{}}  1:14:38\end{tabular}                                                
             & \begin{tabular}[c]{@{}l@{}}  0:19:56\end{tabular}                                                
             & \begin{tabular}[c]{@{}l@{}}  0:00:35\end{tabular} \\
    \ptaylor{}  
                 & 0:00:08                                                                                                                      
                 & 0:00:07                                                                                                                      
                 & 0:00:02                                                                                                                      
                 & $<$ 0:00:01 \\
    \pmmse{}($n=5$)  
               & \begin{tabular}[c]{@{}l@{}} 0:00:41\end{tabular} 
               & \begin{tabular}[c]{@{}l@{}} 0:00:31\end{tabular} 
               & \begin{tabular}[c]{@{}l@{}} 0:00:06\end{tabular} 
               & \begin{tabular}[c]{@{}l@{}} 0:00:02\end{tabular} \\  
\end{tabular}
\caption{Runtimes of \probust{} estimators (H:M:S). Each estimator computes \probustwsigma{0.1} for the CIFAR10 ResNet18 model for 50 points using the minimum number of samples $n$ necessary for convergence. The analytical estimators (\ptaylor{} and \pmmse{}) are more efficient than the naïve estimator (\pmc{}).}
\vspace{-0.2cm}
\label{table:runtimes}
\end{table}


% %fig5: local robustness bias
% %02f_p_all_over_classes/p_all_over_classes/resnet18_cifar10_sigma0.08.png
% Figure environment removed


% %fig5: local robustness bias
% %02f_p_all_over_classes/p_all_over_classes/resnet18_cifar10_sigma0.08.png
% \begin{SCfigure}
%   \vspace{1cm}
%   \centering
%   % Figure removed
%   \vspace{-2.5cm}
%   \caption{Local robustness bias among classes for the ResNet18 CIFAR10 model. \probust{} reveals that the model is less locally robust for some classes than for others. The analytical estimator \pmmse{} properly captures this model bias.}
%   \label{fig5:robustness-bias}
% \end{SCfigure}




% Figure environment removed




% %fig4 -- 2x4 images
% %top-k and bottom-k images
% % 02g_topk_bottomk_p/resnet18_cifar10/p_mmse/
% % - resnet18_cifar10_p_mmse_sigma0.1_class9_topk.png
% % - resnet18_cifar10_p_mmse_sigma0.1_class9_bottomk.png
% % - ...class0... x 2
% % 02g_topk_bottomk_p/resnet18_cifar10/p_sm/
% % - resnet18_cifar10_p_sm_sigma0.1_class9_topk.png
% % - resnet18_cifar10_p_sm_sigma0.1_class9_bottomk.png
% % Figure environment removed



\subsection{Evaluation of the efficiency of analytical estimators}

\textbf{The naïve estimator is statistically inefficient.} We calculate \pmc{} for each model using different sample sizes ($n$) over different $\sigma$'s, and measure the absolute and relative difference between \pmc{} at a given $n$ and \pmc{} at $n=50,000$ (Appendix~\ref{app:experiments-main}). The results indicate that \pmc{} requires around 10,000 samples per point to converge, which is impractical.


\textbf{The analytical estimators are more efficient than the naïve estimator.}
We measure the runtimes of the estimators when calculating \probustwsigma{0.1} for the CIFAR10 ResNet18 model for 50 points (Table~\ref{table:runtimes}). Results indicate that \ptaylor{} and \pmmse{} perform at least 35x and 17x faster than \pmc{}, respectively.

\subsection{Comparison of local robustness and softmax probability}

\textbf{Local robustness and softmax probability are two distinct measures.} Consistent with the theory in Section~\ref{sec:methods}, we find that \probust{} and \psoftmax{} are not strongly correlated, indicating that in general settings, \psoftmax{} is not a good estimator for \probust{}. Details are in Appendix~\ref{app:experiments-main}. 

\subsection{Applications of local robustness}

\textbf{\boldmath \probust{} detects local robustness bias.} We calculate \probust{} using \pmmse{} and examine its distribution across classes (Figure~\ref{fig5:robustness-bias}). Results show that the models are more locally robust for some classes than for others. Thus, \probust{} can be applied to detect local robustness bias, which is critical when models are deployed in high-stakes, real-world settings.

\textbf{\boldmath \probust{} identifies images that are robust to and images that are vulnerable to random noise.} We visualize images with the highest and lowest \probust{} and \psoftmax{} in each class (Figure~\ref{fig6:topk-vs-bottomk}). Images with low \probust{} tend to have neutral colors and low object-background contrast while images with high \probust{} tend to be brightly-colored with high object-background contrast. These differences make the prediction more and less likely to change, respectively, when the image is perturbed. These differences are not as evident for \psoftmax{}. 
% Thus, \probust{} can also be applied to identify images that are robust to and images that are vulnerable to random noise.

For all experiments described above, additional results are in Appendix~\ref{app:experiments}.

