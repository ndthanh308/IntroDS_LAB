\section{Our Framework: The Local Robustness Estimator Family}
\label{sec:methods}

\newcommand{\E}{\mathop{\mathbb{E}}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\X}{\mathbf{x}}
\newcommand{\grad}{\nabla_{\X}}
\newcommand{\cdf}{\text{CDF}_{\mathcal{N}(0, UU^\top)}}

\newtheorem{defn}{Definition}
\newtheorem{thm}{Proposition}
% \newtheorem{lemma}{Lemma}


\newenvironment{hproof}{%
  \renewcommand{\proofname}{Proof Idea}\proof}{\endproof}

In this section, we describe the mathematical problem of local robustness estimation. Then, we present the naïve estimator and derive more efficient analytical estimators. Lastly, we explore the connections between local robustness and softmax probability.

\subsection{Notation and Preliminaries}

Assume there is a neural network $f: \R^d \rightarrow \R^C$ with $C$ classes, and the model predicts class $t \in [1,...C]$ for a given input $\X \in \R^d$, i.e., $t~=~\arg \max_{i=1}^{C} f_i(\X)$, where $f_i$ denotes the logits for the $i^{th}$ class. Given this model, the local robustness estimation problem is to compute the probability of consistent classification (to class $t$) under noise perturbation of the inputs. 

\begin{defn} We define the average \underline{local robustness} of a model $f$ at a point $\X$ as the probability of being classified to class $t$ under Normal noise $\mathcal{N}(0, \sigma^2)$ added to the inputs:
\begin{align*}
    p^\text{robust}_{\sigma}(\X, t) = P_{\epsilon \sim \mathcal{N}(0,\sigma^2)} \left[ \arg\max_i f_i(x+ \epsilon) = t \right]
\end{align*}
\end{defn}

\vspace{-0.3cm}
The higher \probust{} is, the more robust the model is in the local region around $\X$. In this paper, given that local robustness is always with respect to the predicted class~$t$, we henceforth suppress the dependence on $t$ in the notation. Note that \emph{\probust{} generalizes adversarial robustness}. Adversarial robustness detects the presence of a perturbation that leads to inconsistent classification (i.e., $\mathbf{1}($\probust{}$ < 1)$), while local robustness computes the probability of consistent classification (i.e., \probust{}). In the rest of this section, we derive estimators for \probust{}.


\subsubsection{Estimator 0: The Monte-Carlo Estimator}

A naïve estimator of \probust{} is a Monte-Carlo estimator, i.e., 
\vspace{-0.3cm}
\begin{align*}
    p_{\sigma}^\text{robust}(\X) 
    &= \E_{\epsilon \sim \mathcal{N}(0,\sigma^2)} \left[ \mathbf{1}_{\arg\max_i f_i(x+ \epsilon) = t} \right] \\ 
    &\approx \frac{1}{M} \sum_{j=1}^{M} \left[ \mathbf{1}_{\arg\max_i f_i(x+ \epsilon_j) = t} \right]
    = p_{\sigma}^\text{mc}(\X)
\end{align*}

\vspace{-0.3cm}
In practice, \pmc{} requires a large number of random samples to converge. For example, for CIFAR10 CNNs, it takes around $M = 10,000$ samples per point for \pmc{} to converge, which is computationally infeasible. Thus, we seek to address this problem by developing more efficient estimators.


\subsection{Analytical Estimators of Local Robustness}

\subsubsection{Estimator 1: The Taylor Estimator}

To derive efficient estimators of local robustness, we locally linearize non-linear models and compute the local robustness of the resulting linear models. However, even computing the local robustness of linear models is challenging due to the complex geometry of decision boundaries given $C$ classes. We derive the estimator for the linear model in Appendix~\ref{app:proofs}. Using this, we derive the Taylor estimator.

\vspace{0.2cm}
\begin{thm}
    The Taylor estimator for a model $f$ and point $\X$ is given by linearizing $f$ around $\X$ using $\mathbf{w} = \grad f(\X)$ and $b = f(\X)$, with decision boundaries $g_i(\X) = f_t(\X) - f_i(\X)$, $\forall i \neq t$, leading to
    \begin{align*}
        p^\text{taylor}_{\sigma}(\X) = \text{CDF}_{\mathcal{N}(0, UU^{\top})} (\left[  \frac{g_1(\X)}{\sigma \|\grad g_1(\X)\|_2},  ..., \frac{g_C(\X)}{\sigma \|\grad g_C(\X) \|_2} \right]) \\
        \text{where}~~U = \left[ \frac{\grad g_1(\X)'}{\| \grad g_1(\X)' \|_2}, ..., \frac{\grad g_C(\X)'}{\| \grad g_C(\X)' \|_2} \right] \in \R^{(C-1) \times d}
    \end{align*}
\label{eqn:taylor-estimator}
\end{thm}

The proof is in Appendix~\ref{app:proofs}. The smaller the $\sigma$, the more faithful the local linearization of the model, thus the more accurate the Taylor estimator.


\subsubsection{Estimator 2: The MMSE Estimator}

While the Taylor estimator is more efficient than the naïve one, it has a drawback: its linear approximation is less valid farther away from $\X$. To fix this, we use a linearization that is faithful to the model on the entire noise distribution, not just near $\X$, using SmoothGrad \cite{smilkov2017smoothgrad} (which has been described as the MMSE optimal linearization of the model \cite{han2022explanation, agarwal2021towards}). We propose the MMSE estimator as follows.



\begin{thm}
    The MMSE estimator for a model $f$ and point $\X$ is given by linearizing $f$ around $\X$ using $\mathbf{w}~=~\frac{1}{N}\sum_{j=1}^{N} \grad f(\X + \epsilon)$ and $b = \frac{1}{N}\sum_{j=1}^{N} f(\X + \epsilon)$, with decision boundaries $g_i(\X) = f_t(\X) - f_i(\X)$, $\forall i \neq t$, leading to
    \begin{align*}
        p^\text{mmse}_{\sigma}(\X) = \text{CDF}_{\mathcal{N}(0, UU^{\top})} (\left[\frac{ \frac{1}{N} \sum_{j=1}^{N} g_1(\X + \epsilon)}{\sigma \| \frac{1}{N} \sum_{j=1}^{N} \grad g_1(\X + \epsilon)\|_2},  \right. \\ 
        \left. ..., \frac{\frac{1}{N} \sum_{j=1}^{N} g_C(\X + \epsilon)}{\sigma \| \frac{1}{N} \sum_{j=1}^{N} \grad g_C(\X + \epsilon)\|_2} \right])
    \end{align*}
    with $U \in \R^{(C-1) \times d}$ defined as in the Taylor estimator and $N$ as the number of perturbations. 
\end{thm}

The proof is in Appendix~\ref{app:proofs}. \pmmse{} creates a randomized smooth model \cite{cohen2019certified} from the base model and then computes the decision boundaries of this smooth model. We show, for the first time, that performing such randomization helps compute robustness information for the original base model.

Like \pmc{}, \pmmse{} also requires sampling over the input space. However, due to \pmmse{}'s use of model gradients, it requires far fewer samples to converge (we observed $N=5-10$ to suffice in practice), thus making it computationally efficient. 

\subsubsection{Estimators 3 \& 4 : Approximate Taylor and MMSE Estimators}

One drawback of the Taylor and MMSE estimators is their use of the \emph{mvn-cdf} which does not have a closed form solution. As a result, these estimators can be slow when used for a large number of classes $C$ and are non-differentiable (which is inconvenient for applications which require differentiating \probust{}). Thus, we wish to approximate the \emph{mvn-cdf} with a closed-form expression. To this end, the \emph{univariate} Normal CDF is well-approximated by the sigmoid function, and has been used to propose the GeLU activation function \cite{hendrycks2016gaussian}. Inspired by this, we propose to approximate the \emph{mvn-cdf} with the multivariate-sigmoid function:
% As CDFs are monotonically increasing functions, the approximation should also be monotonically increasing.

\begin{defn}
    The multivariate sigmoid is defined as $\text{mv-sigmoid}(\X) = \frac{1}{1 + \sum_{i} \exp(-\X_i)}$ 
\end{defn}

We find experimentally that \emph{mv-sigmoid} well-approximates the \emph{mvn-cdf} for practical values of the covariance matrix $UU^\top$. Substituting \emph{mv-sigmoid} for the \emph{mvn-cdf} in \ptaylor{} and \pmmse{}, we get estimators \ptaylormvs{} and \pmmsemvs{}.

\subsection{Exploring the Connections Between Local Robustness and Softmax Probability}
\subsubsection{Estimator 5: Softmax Estimator}

Lastly, for linear models with a specific $\sigma$, the common softmax function taken with respect to the output logits can be viewed as an estimator of \probust{}, albeit in a very restricted setting. Full discussion is in Appendix~\ref{app:proofs}. 