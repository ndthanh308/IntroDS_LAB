\section{Appendix}


\subsection{Proofs}
\label{app:proofs}

\subsubsection{Local robustness for linear models}

Our goal is to derive analytical estimators which reduce the complexity of estimating local robustness. To this end, we first locally linearize non-linear models and then compute the local robustness of the resulting linear models. However, even the problem of computing the local robustness of linear models is more challenging than it appears due to the complex geometry of linear decision boundaries given $C$ classes. In particular, the relative orientation and similarities of these class-wise decision boundaries needs to be taken into account to compute local robustness.

Given a linear model for a three-class classification problem with weights $w_1, w_2, w_3$ and biases $b_1, b_2, b_3$, such that $y = \arg \max_i \{w_i^\top\X + b_i \mid i \in [1,2,3] \}$, the decision boundary between classes $1$ and $2$ is given by $y_{12} = (w_1 - w_2)^\top \X + (b_1 - b_2)$. This is easy to verify as for any $\X$ such that $y_{12}=0$, we have $w_1^\top\X + b_1 = w_2^\top\X + b_2$, making it the decision boundary. Thus, the relevant quantities are the pairwise difference terms among the weights and biases which characterize the decision boundaries. We take this into account and provide the expression for the linear case below. 

\begin{lemma} \label{proof:lemma}
The local robustness of a multi-class linear model $f(\X) = \mathbf{w}^\top \X + b$, with $\mathbf{w} \in \R^{d \times C}$ and $b \in \R^C$, with respect to a target class $t$ is given by the following. Define the decision boundary weights $w'_i = w_t - w_i \in \R^d, \forall i \neq t$, where $w_t, w_i$ are rows of $\mathbf{w}$ and biases $b'_i = {(w'_t - w'_i)}^\top\X + (b_t - b_i) \in \R$, then 
\begin{align*}
    p^\text{robust}_\sigma(\X) = \cdf \left( \frac{b'_1}{\sigma \| w'_1 \|_2}, ...\frac{b'_i}{\sigma \| w'_i \|_2}, ... \frac{b'_C}{\sigma \| w'_C \|_2} \right)\\
    \text{where}~~~~U = \left[ \frac{w'_1}{\| w'_1 \|_2}; ...\frac{w'_i}{\| w'_i \|_2};...\frac{w'_C}{\| w'_C \|_2} \right] \in \R^{(C-1) \times d}
\end{align*}
and $\cdf$ refers to the ($C-1$)-dimensional Normal CDF with covariance $UU^\top$.
\end{lemma}


%\begin{hproof}
%    We first note that $w'_i = w_t - w_i$ represents the decision boundary between classes $i,t$. Thus for $C$ classes we have $C-1$ decision boundaries. \suraj{complete this}
%\end{hproof}

The proof is below. The matrix $U$ exactly captures the geometry of the linear decision boundaries and the covariance matrix $UU^\top$ encodes the relative similarity between pairs of decision boundaries. If the decision boundaries are all orthogonal to each other, then the covariance matrix is the identity matrix. However, we find that, in practice, the covariance matrix is strongly non-diagonal, indicating that the decision boundaries are not orthogonal to each other.

For diagonal covariance matrices, the multivariate Normal CDF (\emph{mvn-cdf}) can be written as the product of univariate Normal CDFs, which would be easy to compute. However, the strong non-diagonal nature of covariance matrices in practice leads to the resulting \emph{mvn-cdf} not having a simple closed form solution, with the only alternative being approximation of the integral via sampling \cite{botev2017normal, SciPy}. However, this sampling is performed in the $(C-1)$-dimensional space as opposed to the $d$-dimensional space that \pmc{} performs. In practice, for classification problems, we often have $C << d$, making sampling in $(C-1)$-dimensions more efficient. 

\begin{proof}
First, we rewrite \probust{} in the following manner, by defining $g_i(\X) = f_t(\X) - f_i(\X) > 0$, which is the ``decision boundary function".

\begin{align*}
    p_\sigma^\text{robust} = P_{\epsilon \sim \mathcal{N}(0,\sigma^2)} \left[ \max_{i} f_i(\X + \epsilon) < f_t(\X + \epsilon) \right] = P_{\epsilon \sim \mathcal{N}(0,\sigma^2)} \left[ \bigcup_{i=1; i \neq t}^C g_i(\X + \epsilon) > 0 \right]
\end{align*}

Now, assuming that $f,g$ are linear such that $g_i(\X) = {w'_i}^\top \X + g(0)$, we have $g_i(\X + \epsilon) = g_i(\X) + {w'_i}^\top \epsilon$, and obtain

\begin{align*}
p_\sigma^\text{robust} &= P_{\epsilon \sim \mathcal{N}(0,\sigma^2)}\left[ \bigcup_{i=1; i \neq t}^C {w'_i}^{\top}\epsilon > -g_i(\X) \right] \\
&= P_{z \sim \mathcal{N}(0,I_d)} \left[ \bigcup_{i=1; i \neq t}^C \frac{w'_i}{\| w'_i \|_2}^{\top}z > - \frac{g_i(\X)}{\sigma \| w'_i \|_2} \right] ~~~~~~~~ (\text{Rescaling and standardization})\\
\end{align*}

We now make the following observations:
\begin{itemize}
    \item For any matrix $U \in \R^{C \times d}$ and a d-dimensional Gaussian random variable $z \sim \mathcal{N}(0, I_d) \in \R^d$, we have $U^\top z \sim \mathcal{N}(0, U U^\top)$, i.e., an C-dimensional Gaussian random variable. 
    \item CDF of a multivariate Gaussian RV is defined as $P_z [\bigcup_i z_i < t_i]$ for some input values $t_i$
\end{itemize}

Using these observations, if we construct $U = [\frac{w'_1}{\| w'_1 \|_2} ; \frac{w'_2}{\| w'_2 \|_2} ; ... \frac{w'_C}{\| w'_C \|_2}] \in \R^{(C-1) \times d}$, and obtain

\begin{align*}
p_\text{robust} &= P_{u \sim \mathcal{N}(0, UU^\top)} \left[ \bigcup_{i=1; i \neq t}^C u_i < \frac{g_i(\X)}{\sigma \| w'_i \|_2} \right] \\
&= \text{CDF}_{\mathcal{N}(0, UU^{\top})} (\left[  \frac{g_1(\X)}{\sigma \| w'_1 \|_2},  \frac{g_2(\X)}{\sigma \|w'_2\|_2}, ... \frac{g_C(\X)}{\sigma \| w'_C \|_2} \right] )
\end{align*}

where $g_i(\X) = {w'_i}^\top \X + g_i(0) = {(w'_t - w'_i)}^\top\X + (b_t - b_i)$

\end{proof}



\subsubsection{Taylor Estimator}
\begin{thm}
    The Taylor estimator for a model $f$ and point $\X$ is given by linearizing $f$ around $\X$ using $\mathbf{w} = \grad f(\X)$ and $b = f(\X)$, with decision boundaries $g_i(\X) = f_t(\X) - f_i(\X)$, leading to
    \begin{align*}
        p^\text{taylor}_{\sigma}(\X) = \text{CDF}_{\mathcal{N}(0, UU^{\top})} (\left[  \frac{g_1(\X)}{\sigma \|\grad g_1(\X)\|_2},  ...\frac{g_i(\X)}{\sigma \|\grad g_i(\X)\|_2}, ... \frac{g_C(\X)}{\sigma \|\grad g_C(\X) \|_2} \right]) 
    \end{align*}
    with $U \in \R^{(C-1) \times d}$ defined as in the linear case.
% \label{eqn:taylor-estimator}
\end{thm}

\begin{proof}
    Using the notations from the previous Lemma \ref{proof:lemma}, we can use $g(\X + \epsilon) \approx g(\X) + \grad g(\X)^\top \epsilon$ using a first order Taylor series expansion.
    Thus we use $w'_i = \grad g_i(\X)$ and $b' = g(\X)$, and plug it into the result of Lemma \ref{proof:lemma}.
\end{proof}



\subsubsection{MMSE Estimator}

\begin{thm}
    The MMSE estimator for a model $f$ and point $\X$ is given by linearizing $f$ around $\X$ using $\mathbf{w} = \sum_{j=1}^{N} \grad f(\X + \epsilon)$ and $b = \sum_{j=1}^{N} f(\X)$, with decision boundaries $g_i(\X) = f_t(\X) - f_i(\X)$, leading to
    \begin{align*}
        p^\text{mmse}_{\sigma}(\X) = \text{CDF}_{\mathcal{N}(0, UU^{\top})} (\left[  \frac{\sum_{j=1}^{N} g_1(\X + \epsilon)}{\sigma \| \sum_{j=1}^{N} \grad g_1(\X + \epsilon)\|_2},  ... \frac{\sum_{j=1}^{N} g_C(\X + \epsilon)}{\sigma \| \sum_{j=1}^{N} \grad g_C(\X + \epsilon)\|_2} \right] )
    \end{align*}
    with $U \in \R^{(C-1) \times d}$ defined as in the linear case, where $N$ is the number of perturbations. 
\end{thm}

\begin{proof}
We would like to improve upon the Taylor approximation to $g(\X + \epsilon)$ by using an MMSE local function approximation. Essentially, we'd like the find $w \in \R^d$ and $b \in \R$ such that 

\begin{align*}
    (w^*(\X), b^*(\X)) = \arg\min_{w,b} \E_{\epsilon \sim \mathcal{N}(0, \sigma^2)} (g(x+\epsilon) - w^{\top} \epsilon - b)^2
\end{align*}

A straightforward solution by finding critical points and equating it to zero gives us the following:

\begin{align*}
    w^*(\X) &= \E_\epsilon \left[ g(x + \epsilon) \epsilon^{\top} \right] / \sigma^2 = \E_\epsilon \left[ \grad g(\X + \epsilon) \right] ~~~~~ (\text{Stein's Lemma}) \\
    b^*(\X) &= \E_\epsilon g(x + \epsilon)
\end{align*}

Plugging in these values of $w^*, b^*$ into Lemma \ref{proof:lemma}, we have the result.

\end{proof}



\subsubsection{Softmax Estimator}

Lastly, we observe that for linear models with a specific noise perturbation $\sigma$, the common softmax function taken with respect to the output logits can be viewed as an estimator of \probust{}, albeit in a very restricted setting. Specifically,

\begin{lemma}
    For linear models $f(\X) = \mathbf{w}^\top \X + b$, such that the decision boundary weight norms $\| w'_i \|_2 = \| w'_j \|_2 = \| w \|_2, \forall i,j$, we have
    \begin{align*}
        p^\text{softmax}_{T} = p^\text{taylor\_mvs}_{\sigma}~~~~\text{where}~~~~T = \sigma \| w \|_2
    \end{align*}
\end{lemma}

\begin{proof} Let us consider softmax with respect to the $t^{th}$ output class and define $g_i(\X) = f_t(\X) - f_i(\X)$, with $f$ being the linear model logits. Using this, we first show that softmax is identical to \emph{mv-sigmoid}:

\begin{align*}
        p^\text{softmax}_T(\X) &= \text{softmax}_t(f_1(\X)/T, ... f_C(\X)/T) \\
        &= \frac{\exp(f_t(\X)/T)}{\sum_i \exp(f_i(\X)/T)} \\ 
        &= \frac{1}{1 + \sum_{i; i\neq t} \exp((f_i(\X) - f_t(\X))/T)} \\ 
        &= ~\text{mv-sigmoid} \left[ g_1(\X)/T, g_2(\X)/T, ... g_C(\X)/T \right]
\end{align*}

Next, by denoting $w'_i = w_t - w_i$, each row has equal norm $\| w'_i \|_2 = \| w'_j \|_2, \forall i,j,t \in [1,...C]$ which implies: 

\begin{align*}
        p^\text{taylor\_mvs}_\sigma(\X) &= \text{mv-sigmoid} \left[ \frac{g_1(\X)}{\sigma \| w'_1 \|_2}, ... \frac{g_C(\X)}{\sigma \| w'_C \|_2} \right]\\ 
        &= \text{mv-sigmoid} \left[ g_1(\X)/T, g_2(\X)/T, ... g_C(\X)/T \right]~~~~ \because \text{$T = \sigma \| w'_i \|_2 $}\\ 
        & = p^\text{softmax}_T(\X)
\end{align*}
\end{proof}

This indicates that the temperature parameter $T$ of softmax roughly corresponds to the $\sigma$ of the added Normal noise with respect to which local robustness is measured. Overall, this shows that under the restricted setting where the local linear model consists of decision boundaries with equal weight norms, the softmax outputs can be viewed as an estimator of the \ptaylormvs{} estimator, which itself is an estimator of \probust{}. However, due to the multiple levels of approximation, we can expect the quality of \psoftmax{}'s approximation of \probust{} to be poor in general settings (outside of the very restricted setting), so much so that in general settings, \probust{} and \psoftmax{} would be unrelated.



\subsection{Experiments referenced in main paper}
\label{app:experiments-main}

\textbf{For robust models, the analytical estimators compute local robustness more accurately over a larger noise neighborhood.} 
The performance of \pmmse{} for CIFAR10 ResNet18 models of varying levels of robustness is shown in Figure~\ref{fig1b:method-works-robust}. The results indicate that for more robust models (larger $\lambda$), the estimator is more accurate over a larger $\sigma$. This is because gradient norm regularization leads to models that are more locally linear, making the estimator's linear approximation of the model around the input more accurate over a larger $\sigma$.


\textbf{The mv-sigmoid function approximates the multivariate Normal CDF well in practice.} To examine \emph{mv-sigmoid}'s approximation of \emph{mvn-cdf}, we compute both functions using the same inputs ($z~=~\left[  \frac{g_1(\X)}{\sigma \|\grad g_1(\X)\|_2}, ..., \frac{g_C(\X)}{\sigma \|\grad g_C(\X) \|_2} \right]$, as described in Proposition~\ref{eqn:taylor-estimator}) for the CIFAR10 ResNet18 model and its test set for different $\sigma$'s. The plot of \emph{mv-sigmoid(z)} against \emph{mvn-cdf(z)} for $\sigma=0.1$ is shown in Figure~\ref{fig2:mvsig-mvncdf}. The results indicate that the two functions are strongly positively correlated, suggesting that \emph{mv-sigmoid} approximates the \emph{mvn-cdf} well in practice.


\textbf{Local robustness and softmax probability are two distinct measures.} To examine the relationship between \probust{} and \psoftmax{}, we calculate \pmmse{} and \psoftmax{} for CIFAR10 and CIFAR100 models of varying levels of robustness, and measure the correlation of their values and ranks using Pearson and Spearman correlations. Results are in Appendix~\ref{app:experiments-main}. For a non-robust model, \probust{} and \psoftmax{} are not strongly correlated (Figure~\ref{fig4a:ps-nonrob-model}). As model robustness increases, the two quantities become more correlated (Figures~\ref{fig4b:ps-rob-models-lineplot} and~\ref{fig4c:ps-rob-model}). However, even for robust models, the relationship between the two quantities is mild (Figure~\ref{fig4c:ps-rob-model}). That \probust{} and \psoftmax{} are not strongly correlated is consistent with the theory in Section~\ref{sec:methods}: in general settings, \psoftmax{} is not a good estimator for \probust{}.


%fig1b: method works better for robust models
%02l_pemp_vs_pmmse_over_noise_robust_models/rel/resnet18_cifar10.png
% Figure environment removed


%fig2: mvsigmoid is a good approximator for mvncdf
%correlation for sigma=0.1 
%03_mvncdf_vs_mvsigmoid/resnet18_cifar10_sigma0.1.png
%fig3: p_mc takes many samples to converge
%02a2_delta_p_emp_convergence_n50000_baseline/rel/resnet18_cifar10_sigma0.1.png
% Figure environment removed



%fig4 -- p_robust and p_softmax
%fig4a: scatterplot, non-robust model
%02m_pemp_vs_pmmse_corr_robust_models/resnet18_cifar10_sigma0.1_gnormreg0.png
%fig4b: scatterplot, robust model
%02m_pemp_vs_pmmse_corr_robust_models/resnet18_cifar10_sigma0.1_gnormreg0.01.png
%fig4c: the more robust the model, the more the two are related
%02n_pemp_vs_pmmse_corr_robust_models_line_plots/cifar_family/sigma0.1.png
% Figure environment removed





% %fig4 -- p_robust and p_softmax
% %fig4a: scatterplot, non-robust model
% %02m_pemp_vs_pmmse_corr_robust_models/resnet18_cifar10_sigma0.1_gnormreg0.png
% %fig4b: scatterplot, robust model
% %02m_pemp_vs_pmmse_corr_robust_models/resnet18_cifar10_sigma0.1_gnormreg0.01.png
% %fig4c: the more robust the model, the more the two are related
% %02n_pemp_vs_pmmse_corr_robust_models_line_plots/cifar_family/sigma0.1.png
% % Figure environment removed




\clearpage
\subsection{Datasets}
\label{app:datasets}

The MNIST dataset consists of images of gray-scale handwritten digits. The images span 10 classes: digits 0 through 9. Each image is of size 28 pixels x 28 pixels. The training set consists of 60,000 images and the test set consists of 10,000 images.

The FashionMNIST dataset consists of gray-scale images of articles of clothing. The images span 10 classes: t-shirt, trousers, pullover, dress, coat, sandal, shirt, sneaker, bag, and ankle boot. Each image is of size 28 pixels x 28 pixels. The training set consists of 60,000 images and the test set consists of 10,000 images.

The CIFAR10 dataset consists of color images of common objects and animals. The images span 10 classes: airplane, car, bird, cat, deer, dog, frog, horse, ship, and truck. Each image is of size 3 pixels x 32 pixels x 32 pixels. The training set consists of 50,000 images and the test set consists of 10,000 images.

The CIFAR100 dataset consists of color images of common objects and animals. The images span 100 classes: apple, bowl, chair, dolphin, lamp, mouse, plain, rose, squirrel, train, etc. Each image is of size 3 pixels x 32 pixels x 32 pixels. The training set consists of 50,000 images and the test set consists of 10,000 images.

For experiments, we use 1,000 randomly-selected test set images for each dataset.


\subsection{Models}
\label{app:models}

For the MNIST and FashionMNIST (FMNIST) datasets, we train a linear model and a convolutional neural network (CNN) to perform 10-class classification. The linear model consists of one hidden layer with 10 neurons. The CNN consists of four hidden layers: one convolutional layer with 5x5 filters and 10 output channels, one convolutional layer 5x5 filters and 20 output channels, and one linear layer with 50 neurons, and one linear layer 10 neurons. 

For CIFAR10 and CIFAR100 datasets, we train a ResNet18 model to perform 10-class and 100-class classification, respectively. The model architecture is described in \citep{he2016deep}. We train the ResNet18 models using varying levels of gradient norm regularization to obtain models with varying levels of robustness. The larger the weight of gradient norm regularization ($\lambda$), the more robust the model.

All models were trained using stochastic gradient descent. Hyperparameters were selected to achieve decent model performance. The emphasis is on analyzing the estimators’ estimates of local robustness of each model, not on high model performance. Thus, we do not focus on tuning model hyperparameters. All models were trained for 200 epochs. The test set accuracy (on each dataset's full 10,000-point test set) for each model is shown in Table~\ref{table:app-model-acc}.

\begin{table}[ht!]
    \centering
    \begin{tabular}{c|c|c|c}
    Dataset      & Model  & $\lambda$  & Test set accuracy \\
    \midrule
    MNIST        & Linear  & 0 & 92\%                         \\
    MNIST        & CNN     & 0 & 99\%                         \\
    \midrule
    FashionMNIST & Linear  & 0 & 84\%                         \\
    FashionMNIST & CNN     & 0 & 91\%                         \\
    \midrule
    CIFAR10      & ResNet18 & 0 & 94\%                         \\
    CIFAR10      & ResNet18 & 0.0001 & 93\%                         \\
    CIFAR10      & ResNet18 & 0.001 & 90\%                         \\
    CIFAR10      & ResNet18 & 0.01 & 85\%                         \\
    \midrule
    CIFAR100     & ResNet18 & 0 & 76\%                        \\
    CIFAR100     & ResNet18 & 0.0001 & 74\%                         \\
    CIFAR100     & ResNet18 & 0.001 & 69\%                         \\
    CIFAR100     & ResNet18 & 0.01 & 60\%                         
    \end{tabular}
    \vspace*{3mm}
    \caption{Accuracy of models on test set.}
    \label{table:app-model-acc}
\end{table}


\clearpage
\subsection{Experiments}
\label{app:experiments}

\subsubsection{Convergence of \pmc{}}

%appendix/a_convergence_pmc = 02a2_delta_p_emp_convergence_n50000_baseline

% Figure environment removed





\subsubsection{Convergence of \pmmse{}}

%appendix/b_convergence_pmmse = 02c2_delta_p_mmse_convergence_n1000_baseline
% Figure environment removed



\clearpage
\subsubsection{Distribution of \probust{} over noise}

%appendix/c_probust_over_noise = 02b_p_over_noise/p_all_over_noise
% Figure environment removed



\subsubsection{Accuracy of \probust{} estimators}

%appendix/d_accuracy_of_estimators = 02e_pemp_vs_pothers_over_noise/rel
% Figure environment removed


\clearpage
\subsubsection{Accuracy of \probust{} estimators for robust models}

%appendix/e_accuracy_of_estimators_robust_models = 02l_pemp_vs_pmmse_over_noise_robust_models/rel
% Figure environment removed





\subsubsection{mv-sigmoid function's approximation of mvn-cdf function}

%appendix/f_mvsigmoid_vs_mvncdf = 03_mvncdf_vs_mvsigmoid
% Figure environment removed

\subsubsection{Local robustness bias among classes}

%appendix/g_robustness_bias = 02f_p_all_over_classes/p_all_over_classes
% Figure environment removed


\clearpage


\subsubsection{Runtimes of \probust{} estimators}

\begin{table}[ht!]
\begin{tabular}{l|l|l|l|l|l}
    \multicolumn{2}{c}{}   & \multicolumn{2}{|c|}{CPU: Intel x86\_64}   & \multicolumn{2}{|c}{GPU: Tesla V100-PCIE-32GB} \\
    \midrule
    Estimator   & \# samples ($n$)   & Serial   & Batched   & Serial   & Batched \\
    \midrule
    \pmc{}   & \begin{tabular}[c]{@{}l@{}}$n=100$\\ $n=1000$\\ $n=10000$\end{tabular}               
             & \begin{tabular}[c]{@{}l@{}}0:00:59\\ 0:09:50\\ \textit{1:41:11}\end{tabular}                                               
             & \begin{tabular}[c]{@{}l@{}}0:00:42\\ 0:07:22\\ \textit{1:14:38}\end{tabular}                                                
             & \begin{tabular}[c]{@{}l@{}}0:00:12\\ 0:02:00\\ \textit{0:19:56}\end{tabular}                                                
             & \begin{tabular}[c]{@{}l@{}}0:00:01\\ 0:00:04\\ \textit{0:00:35}\end{tabular} \\
    \midrule
    \ptaylor{}   & N/A
                 & 0:00:08                                                                                                                      
                 & 0:00:07                                                                                                                      
                 & 0:00:02                                                                                                                      
                 & $<$ 0:00:01 \\
    \midrule
    \ptaylormvs{}   & N/A
                    & 0:00:08                                                                                                                   
                    & 0:00:07                                                                                                                  
                    & 0:00:01                                                                                                                   
                    & $<$ 0:00:01 \\
    \midrule
    \pmmse{}   & \begin{tabular}[c]{@{}l@{}}$n=1$\\ $n=5$\\ $n=10$\\ $n=25$\\ $n=50$\\ $n=100$\end{tabular} 
               & \begin{tabular}[c]{@{}l@{}}0:00:08\\ \textit{0:00:41}\\ 0:01:21\\ 0:03:21\\ 0:06:47\\ 0:13:57\end{tabular} 
               & \begin{tabular}[c]{@{}l@{}}0:00:10\\ \textit{0:00:31}\\ 0:01:02\\ 0:02:44\\ 0:05:38\\ 0:11:31\end{tabular} 
               & \begin{tabular}[c]{@{}l@{}}0:00:02\\ \textit{0:00:06}\\ 0:00:11\\ 0:00:26\\ 0:00:51\\ 0:01:42\end{tabular} 
               & \begin{tabular}[c]{@{}l@{}}0:00:02\\ \textit{0:00:02}\\ 0:00:02\\ 0:00:03\\ 0:00:04\\ 0:00:06\end{tabular} \\
    \midrule
    \pmmsemvs{}   & \begin{tabular}[c]{@{}l@{}}$n=1$\\ $n=5$\\ $n=10$\\ $n=25$\\ $n=50$\\ $n=100$\end{tabular} 
                  & \begin{tabular}[c]{@{}l@{}}0:00:08\\ \textit{0:00:41}\\ 0:01:21\\ 0:03:24\\ 0:06:47\\ 0:13:28\end{tabular} 
                  & \begin{tabular}[c]{@{}l@{}}0:00:08\\ \textit{0:00:32}\\ 0:01:00\\ 0:02:37\\ 0:05:35\\ 0:11:32\end{tabular} 
                  & \begin{tabular}[c]{@{}l@{}}0:00:01\\ \textit{0:00:05}\\ 0:00:10\\ 0:00:25\\ 0:00:51\\ 0:01:42\end{tabular} 
                  & \begin{tabular}[c]{@{}l@{}}0:00:01\\ \textit{0:00:01}\\ 0:00:02\\ 0:00:02\\ 0:00:03\\ 0:00:06\end{tabular} \\
    \midrule
    \psoftmax{}   & N/A                                                                             
                  & 0:00:01                                                                                                                              
                  & $<$ 0:00:01                                                                                                                              
                  & $<$ 0:00:01                                                                                                                              
                  & $<$ 0:00:01                                                                                                                             
\end{tabular}
\caption{Runtimes of each \probust{} estimator. Each estimator computes \probustwsigma{0.1} for the CIFAR10 ResNet18 model for 50 data points. For estimators that use sampling, the row with the minimum number of samples necessary for convergence is italicized. The analytical estimators (\ptaylor{}, \ptaylormvs{}, \pmmse{}, and \pmmsemvs{}) are more efficient than the naïve estimator (\pmc{}). Runtimes are in the format of hour:minute:second.}
\end{table}



\subsection{Broader Impact}
This work is concerned with improving estimation of local robustness of machine learning models, and as such does not have any immediate foreseeable negative societal impact. However, inexact estimation can affect downstream decisions, and as such, estimator quality must always be taken into account to mitigate such cases.