\begin{thebibliography}{22}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Nanda et~al.(2021)Nanda, Dooley, Singla, Feizi, and Dickerson]{nanda2021fairness}
Vedant Nanda, Samuel Dooley, Sahil Singla, Soheil Feizi, and John~P Dickerson.
\newblock Fairness through robustness: {I}nvestigating robustness disparity in deep learning.
\newblock \emph{ACM Conference on Fairness, Accountability, and Transparency}, 2021.

\bibitem[Ribeiro et~al.(2016)Ribeiro, Singh, and Guestrin]{ribeiro2016lime}
Marco~Tulio Ribeiro, Sameer Singh, and Carlos Guestrin.
\newblock {W}hy should {I} trust you? {E}xplaining the predictions of any classifier.
\newblock \emph{International Conference on Knowledge Discovery and Data Mining}, 2016.

\bibitem[Han et~al.(2022)Han, Srinivas, and Lakkaraju]{han2022explanation}
Tessa Han, Suraj Srinivas, and Himabindu Lakkaraju.
\newblock Which explanation should {I} choose? {A} function approximation perspective to characterizing post hoc explanations.
\newblock \emph{Neural Information Processing Systems}, 2022.

\bibitem[Pawelczyk et~al.(2023)Pawelczyk, Datta, van-den Heuvel, Kasneci, and Lakkaraju]{pawelczyk2022probabilistically}
Martin Pawelczyk, Teresa Datta, Johannes van-den Heuvel, Gjergji Kasneci, and Himabindu Lakkaraju.
\newblock Probabilistically robust recourse: {N}avigating the trade-offs between costs and robustness in algorithmic recourse.
\newblock \emph{International Conference on Learning Representations}, 2023.

\bibitem[Carlini and Wagner(2017)]{carlini2017towards}
Nicholas Carlini and David Wagner.
\newblock Towards evaluating the robustness of neural networks.
\newblock \emph{IEEE Symposium on Security and Privacy}, 2017.

\bibitem[Goodfellow et~al.(2015)Goodfellow, Shlens, and Szegedy]{goodfellow2014explaining}
Ian~J Goodfellow, Jonathon Shlens, and Christian Szegedy.
\newblock Explaining and harnessing adversarial examples.
\newblock \emph{International Conference on Learning Representations}, 2015.

\bibitem[Moosavi-Dezfooli et~al.(2016)Moosavi-Dezfooli, Fawzi, and Frossard]{moosavi2016deepfool}
Seyed-Mohsen Moosavi-Dezfooli, Alhussein Fawzi, and Pascal Frossard.
\newblock Deep{F}ool: {A} simple and accurate method to fool deep neural networks.
\newblock \emph{IEEE Conference on Computer Vision and Pattern Recognition}, 2016.

\bibitem[Cohen et~al.(2019)Cohen, Rosenfeld, and Kolter]{cohen2019certified}
Jeremy Cohen, Elan Rosenfeld, and Zico Kolter.
\newblock Certified adversarial robustness via randomized smoothing.
\newblock \emph{International Conference on Machine Learning}, 2019.

\bibitem[Carlini et~al.(2022)Carlini, Tramer, Dvijotham, Rice, Sun, and Kolter]{carlini2022certified}
Nicholas Carlini, Florian Tramer, Krishnamurthy Dvijotham, Leslie Rice, Mingjie Sun, and Zico Kolter.
\newblock ({C}ertified!!) adversarial robustness for free!
\newblock \emph{International Conference on Learning Representations}, 2022.

\bibitem[Guo et~al.(2017)Guo, Pleiss, Sun, and Weinberger]{guo2017calibration}
Chuan Guo, Geoff Pleiss, Yu~Sun, and Kilian~Q Weinberger.
\newblock On calibration of modern neural networks.
\newblock \emph{International Conference on Machine Learning}, 2017.

\bibitem[Kendall and Gal(2017)]{kendall2017uncertainties}
Alex Kendall and Yarin Gal.
\newblock What uncertainties do we need in {B}ayesian deep learning for computer vision?
\newblock \emph{Neural Information Processing Systems}, 2017.

\bibitem[Shafer and Vovk(2008)]{shafer2008tutorial}
Glenn Shafer and Vladimir Vovk.
\newblock A tutorial on conformal prediction.
\newblock \emph{Journal of Machine Learning Research}, 2008.

\bibitem[Vershynin(2018)]{vershynin2018high}
Roman Vershynin.
\newblock \emph{High-dimensional probability: An introduction with applications in data science}.
\newblock Cambridge University Press, 2018.

\bibitem[Botev(2017)]{botev2017normal}
Zdravko~I Botev.
\newblock The normal law under linear restrictions: {S}imulation and estimation via minimax tilting.
\newblock \emph{Journal of the Royal Statistical Society. Series B (Statistical Methodology)}, 2017.

\bibitem[Sci()]{SciPy}
Sci{P}y multivariate normal {CDF}.
\newblock \url{https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.multivariate_normal.html}.

\bibitem[Smilkov et~al.(2017)Smilkov, Thorat, Kim, Vi{\'e}gas, and Wattenberg]{smilkov2017smoothgrad}
Daniel Smilkov, Nikhil Thorat, Been Kim, Fernanda Vi{\'e}gas, and Martin Wattenberg.
\newblock Smooth{G}rad: removing noise by adding noise.
\newblock \emph{arXiv preprint arXiv:1706.03825}, 2017.

\bibitem[Agarwal et~al.(2021)Agarwal, Jabbari, Agarwal, Upadhyay, Wu, and Lakkaraju]{agarwal2021towards}
Sushant Agarwal, Shahin Jabbari, Chirag Agarwal, Sohini Upadhyay, Steven Wu, and Himabindu Lakkaraju.
\newblock Towards the unification and robustness of perturbation and gradient based explanations.
\newblock \emph{International Conference on Machine Learning}, 2021.

\bibitem[Hendrycks and Gimpel(2016)]{hendrycks2016gaussian}
Dan Hendrycks and Kevin Gimpel.
\newblock Gaussian error linear units ({GELU}s).
\newblock \emph{arXiv preprint arXiv:1606.08415}, 2016.

\bibitem[Deng(2012)]{deng2012mnist}
Li~Deng.
\newblock The {MNIST} database of handwritten digit images for machine learning research.
\newblock \emph{IEEE Signal Processing Magazine}, 2012.

\bibitem[Xiao et~al.(2017)Xiao, Rasul, and Vollgraf]{xiao2017fashion}
Han Xiao, Kashif Rasul, and Roland Vollgraf.
\newblock Fashion-{MNIST}: {A} novel image dataset for benchmarking machine learning algorithms.
\newblock \emph{arXiv preprint arXiv:1708.07747}, 2017.

\bibitem[Krizhevsky et~al.(2009)Krizhevsky, Hinton, et~al.]{krizhevsky2009learning}
Alex Krizhevsky, Geoffrey Hinton, et~al.
\newblock Learning multiple layers of features from tiny images.
\newblock \emph{University of Toronto}, 2009.

\bibitem[He et~al.(2016)He, Zhang, Ren, and Sun]{he2016deep}
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
\newblock Deep residual learning for image recognition.
\newblock \emph{IEEE Conference on Computer Vision and Pattern Recognition}, 2016.

\end{thebibliography}
