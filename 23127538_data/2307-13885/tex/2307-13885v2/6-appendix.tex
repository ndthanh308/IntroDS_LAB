\section{Appendix}

\subsection{Proofs}
\label{app:proofs}

\begin{lemma} \label{proof:lemma}
The local robustness of a multi-class linear model $f(\X) = \mathbf{w}^\top \X + b$, with $\mathbf{w} \in \R^{d \times C}$ and $b \in \R^C$, with respect to a target class $t$ is given by the following. Define the decision boundary weights $w'_i = w_t - w_i \in \R^d, \forall i \neq t$, where $w_t, w_i$ are rows of $\mathbf{w}$ and biases $b'_i = {(w'_t - w'_i)}^\top\X + (b_t - b_i) \in \R$, then 
\begin{align*}
    p^\text{robust}_\sigma(\X) = \cdf \left( \frac{b'_1}{\sigma \| w'_1 \|_2}, ...\frac{b'_i}{\sigma \| w'_i \|_2}, ... \frac{b'_C}{\sigma \| w'_C \|_2} \right)\\
    \text{where}~~~~U = \left[ \frac{w'_1}{\| w'_1 \|_2}; ...\frac{w'_i}{\| w'_i \|_2};...\frac{w'_C}{\| w'_C \|_2} \right] \in \R^{(C-1) \times d}
\end{align*}
and $\cdf$ refers to the ($C-1$)-dimensional Normal CDF with covariance $UU^\top$.
\end{lemma}

\begin{proof}
First, we rewrite \probust{} in the following manner, by defining $g_i(\X) = f_t(\X) - f_i(\X) > 0$, which is the ``decision boundary function".

\begin{align*}
    p_\sigma^\text{robust} = P_{\epsilon \sim \mathcal{N}(0,\sigma^2)} \left[ \max_{i} f_i(\X + \epsilon) < f_t(\X + \epsilon) \right] = P_{\epsilon \sim \mathcal{N}(0,\sigma^2)} \left[ \bigcup_{i=1; i \neq t}^C g_i(\X + \epsilon) > 0 \right]
\end{align*}

Now, assuming that $f,g$ are linear such that $g_i(\X) = {w'_i}^\top \X + g(0)$, we have $g_i(\X + \epsilon) = g_i(\X) + {w'_i}^\top \epsilon$, and obtain

\begin{align*}
p_\sigma^\text{robust} &= P_{\epsilon \sim \mathcal{N}(0,\sigma^2)}\left[ \bigcup_{i=1; i \neq t}^C {w'_i}^{\top}\epsilon > -g_i(\X) \right] \\
&= P_{z \sim \mathcal{N}(0,I_d)} \left[ \bigcup_{i=1; i \neq t}^C \frac{w'_i}{\| w'_i \|_2}^{\top}z > - \frac{g_i(\X)}{\sigma \| w'_i \|_2} \right] ~~~~~~~~ (\text{Rescaling and standardization})\\
\end{align*}

We now make the following observations:
\begin{itemize}
    \item For any matrix $U \in \R^{C \times d}$ and a d-dimensional Gaussian random variable $z \sim \mathcal{N}(0, I_d) \in \R^d$, we have $U^\top z \sim \mathcal{N}(0, U U^\top)$, i.e., an C-dimensional Gaussian random variable. 
    \item CDF of a multivariate Gaussian RV is defined as $P_z [\bigcup_i z_i < t_i]$ for some input values $t_i$
\end{itemize}

Using these observations, if we construct $U = [\frac{w'_1}{\| w'_1 \|_2} ; \frac{w'_2}{\| w'_2 \|_2} ; ... \frac{w'_C}{\| w'_C \|_2}] \in \R^{(C-1) \times d}$, and obtain

\begin{align*}
p_\text{robust} &= P_{u \sim \mathcal{N}(0, UU^\top)} \left[ \bigcup_{i=1; i \neq t}^C u_i < \frac{g_i(\X)}{\sigma \| w'_i \|_2} \right] \\
&= \text{CDF}_{\mathcal{N}(0, UU^{\top})} (\left[  \frac{g_1(\X)}{\sigma \| w'_1 \|_2},  \frac{g_2(\X)}{\sigma \|w'_2\|_2}, ... \frac{g_C(\X)}{\sigma \| w'_C \|_2} \right])
\end{align*}

where $g_i(\X) = {w'_i}^\top \X + g_i(0) = {(w'_t - w'_i)}^\top\X + (b_t - b_i)$

\end{proof}

\begin{thm}
    The Taylor estimator for a model $f$ and point $\X$ is given by linearizing $f$ around $\X$ using $\mathbf{w} = \grad f(\X)$ and $b = f(\X)$, with decision boundaries $g_i(\X) = f_t(\X) - f_i(\X)$, leading to
    \begin{align*}
        p^\text{taylor}_{\sigma}(\X) = \text{CDF}_{\mathcal{N}(0, UU^{\top})} (\left[  \frac{g_1(\X)}{\sigma \|\grad g_1(\X)\|_2},  ...\frac{g_i(\X)}{\sigma \|\grad g_i(\X)\|_2}, ... \frac{g_C(\X)}{\sigma \|\grad g_C(\X) \|_2} \right]) 
    \end{align*}
    with $U \in \R^{(C-1) \times d}$ defined as in the linear case.
% \label{eqn:taylor-estimator}
\end{thm}

\begin{proof}
    Using the notations from the previous Lemma \ref{proof:lemma}, we can use $g(\X + \epsilon) \approx g(\X) + \grad g(\X)^\top \epsilon$ using a first order Taylor series expansion.
    Thus we use $w'_i = \grad g_i(\X)$ and $b' = g(\X)$, and plug it into the result of Lemma \ref{proof:lemma}.
\end{proof}

\begin{thm}
    The MMSE estimator for a model $f$ and point $\X$ is given by linearizing $f$ around $\X$ using $\mathbf{w} = \sum_{j=1}^{N} \grad f(\X + \epsilon)$ and $b = \sum_{j=1}^{N} f(\X)$, with decision boundaries $g_i(\X) = f_t(\X) - f_i(\X)$, leading to
    \begin{align*}
        p^\text{mmse}_{\sigma}(\X) = \text{CDF}_{\mathcal{N}(0, UU^{\top})} (\left[  \frac{\sum_{j=1}^{N} g_1(\X + \epsilon)}{\sigma \| \sum_{j=1}^{N} \grad g_1(\X + \epsilon)\|_2},  ... \frac{\sum_{j=1}^{N} g_C(\X + \epsilon)}{\sigma \| \sum_{j=1}^{N} \grad g_C(\X + \epsilon)\|_2} \right] )
    \end{align*}
    with $U \in \R^{(C-1) \times d}$ defined as in the linear case, where $N$ is the number of perturbations. 
\end{thm}

\begin{proof}
We would like to improve upon the Taylor approximation to $g(\X + \epsilon)$ by using an MMSE local function approximation. Essentially, we'd like the find $w \in \R^d$ and $b \in \R$ such that 

\begin{align*}
    (w^*(\X), b^*(\X)) = \arg\min_{w,b} \E_{\epsilon \sim \mathcal{N}(0, \sigma^2)} (g(x+\epsilon) - w^{\top} \epsilon - b)^2
\end{align*}

A straightforward solution by finding critical points and equating it to zero gives us the following:

\begin{align*}
    w^*(\X) &= \E_\epsilon \left[ g(x + \epsilon) \epsilon^{\top} \right] / \sigma^2 = \E_\epsilon \left[ \grad g(\X + \epsilon) \right] ~~~~~ (\text{Stein's Lemma}) \\
    b^*(\X) &= \E_\epsilon g(x + \epsilon)
\end{align*}

Plugging in these values of $w^*, b^*$ into Lemma \ref{proof:lemma}, we have the result.

\end{proof}



\begin{lemma}
    For multi-class linear models $f(\X) = \mathbf{w}^\top \X + b$, such that the decision boundary weight norms $\| w'_i \|_2 = \| w'_j \|_2 = \| w \|_2, \forall i,j$,
    \begin{align*}
        p^\text{softmax}_{T} = p^\text{taylor\_mvs}_{\sigma}~~~~\text{where}~~~~T = \sigma \| w \|_2
    \end{align*}
\end{lemma}

\begin{proof} Consider softmax with respect to the $t^{th}$ output class and define $g_i(\X) = f_t(\X) - f_i(\X)$, with $f$ being the linear model logits. Using this, we first show that softmax is identical to \emph{mv-sigmoid}:

\begin{align*}
        p^\text{softmax}_T(\X) &= \text{softmax}_t(f_1(\X)/T, ..., f_C(\X)/T) \\
        &= \frac{\exp(f_t(\X)/T)}{\sum_i \exp(f_i(\X)/T)} \\ 
        &= \frac{1}{1 + \sum_{i; i\neq t} \exp((f_i(\X) - f_t(\X))/T)} \\ 
        &= ~\text{mv-sigmoid} \left[ g_1(\X)/T, g_2(\X)/T, ... g_{C-1}(\X)/T \right]
\end{align*}

Next, by denoting $w'_i = w_t - w_i$, each row has equal norm $\| w'_i \|_2 = \| w'_j \|_2, \forall i,j,t \in [1,...C]$ which implies: 

\begin{align*}
        p^\text{taylor\_mvs}_\sigma(\X) &= \text{mv-sigmoid} \left[ \frac{g_1(\X)}{\sigma \| w'_1 \|_2}, ..., \frac{g_{C-1}(\X)}{\sigma \| w'_{C-1} \|_2} \right]\\ 
        &= \text{mv-sigmoid} \left[ g_1(\X)/T, ..., g_{C-1}(\X)/T \right]~~~~ \because \text{$T = \sigma \| w'_i \|_2 $}\\ 
        & = p^\text{softmax}_T(\X)
\end{align*}
\end{proof}

\subsection{Datasets}
\label{app:datasets}

The MNIST dataset consists of images of gray-scale handwritten digits spanning 10 classes: digits 0 through 9. The FashionMNIST (FMNIST) dataset consists of gray-scale images of articles of clothing spanning 10 classes: t-shirt, trousers, pullover, dress, coat, sandal, shirt, sneaker, bag, and ankle boot. For MNIST and FMNIST, each image is 28 pixels x 28 pixels. For MNIST and FMNIST, the training set consists of 60,000 images and the test set consists of 10,000 images.

The CIFAR10 dataset consists of color images of common objects and animals spanning 10 classes: airplane, car, bird, cat, deer, dog, frog, horse, ship, and truck. The CIFAR100 dataset consists of color images of common objects and animals spanning 100 classes: apple, bowl, chair, dolphin, lamp, mouse, plain, rose, squirrel, train, etc. For CIFAR10 and CIFAR100, each image is 3 pixels x 32 pixels x 32 pixels. For CIFAR10 and CIFAR100, the training set consists of 50,000 images and the test set consists of 10,000 images.


\subsection{Models}
\label{app:models}

For the MNIST and FMNIST, we train a linear model and a convolutional neural network (CNN) to perform 10-class classification. The linear model consists of one hidden layer with 10 neurons. The CNN consists of four hidden layers: one convolutional layer with 5x5 filters and 10 output channels, one convolutional layer 5x5 filters and 20 output channels, and one linear layer with 50 neurons, and one linear layer 10 neurons. 

For CIFAR10 and CIFAR100, we train a ResNet18 model to perform 10-class and 100-class classification, respectively. The model architecture is described in \citep{he2016deep}. We train the ResNet18 models using varying levels of gradient norm regularization to obtain models with varying levels of robustness. The larger the weight of gradient norm regularization ($\lambda$), the more robust the model.

All models were trained using stochastic gradient descent. Hyperparameters were selected to achieve decent model performance. The emphasis is on analyzing the estimators’ estimates of local robustness of each model, not on high model performance. Thus, we do not focus on tuning model hyperparameters. All models were trained for 200 epochs. The test set accuracy for each model is shown in Table~\ref{table:app-model-acc}.

\begin{table}[ht!]
    \centering
    \begin{tabular}{c|c|c|c}
    Dataset      & Model  & $\lambda$  & Test set accuracy \\
    \midrule
    MNIST        & Linear  & 0 & 92\%                         \\
    MNIST        & CNN     & 0 & 99\%                         \\
    \midrule
    FashionMNIST & Linear  & 0 & 84\%                         \\
    FashionMNIST & CNN     & 0 & 91\%                         \\
    \midrule
    CIFAR10      & ResNet18 & 0 & 94\%                         \\
    CIFAR10      & ResNet18 & 0.0001 & 93\%                         \\
    CIFAR10      & ResNet18 & 0.001 & 90\%                         \\
    CIFAR10      & ResNet18 & 0.01 & 85\%                         \\
    \midrule
    CIFAR100     & ResNet18 & 0 & 76\%                        \\
    CIFAR100     & ResNet18 & 0.0001 & 74\%                         \\
    CIFAR100     & ResNet18 & 0.001 & 69\%                         \\
    CIFAR100     & ResNet18 & 0.01 & 60\%                         
    \end{tabular}
    \vspace*{3mm}
    \caption{Test set accuracy of models.}
    \label{table:app-model-acc}
\end{table}


\clearpage
\subsection{Experiments}
\label{app:experiments}

\subsubsection{Convergence of \boldmath \pmc{}}

%appendix/a_convergence_pmc = 02a_p_emp_convergence_n50000_baseline
% Figure environment removed



\subsubsection{Convergence of \boldmath \pmmse{}}

%appendix/b_convergence_pmmse = 02b_p_mmse_convergence_n500_baseline
% Figure environment removed


\clearpage
\subsubsection{Distribution of \boldmath \probust{} over noise}

%appendix/c_probust_over_noise = 02b_p_over_noise/p_all_over_noise

%appendix/c_probust_over_noise = 02c_p_vs_sigma/p_all_vs_sigma

% Figure environment removed



\subsubsection{Accuracy of \boldmath \probust{} estimators}

%appendix/d_accuracy_of_estimators = 02d_pemp_vs_pothers_over_sigma/rel
% Figure environment removed



\clearpage
\subsubsection{Accuracy of \boldmath \probust{} estimators for robust models}

%appendix/e_accuracy_of_estimators_robust_models = 02e_pemp_vs_pmmse_over_sigma_robust_models/rel
% Figure environment removed


\subsubsection{mv-sigmoid function's approximation of mvn-cdf function}

%appendix/f_mvsigmoid_vs_mvncdf = 03_mvncdf_vs_mvsigmoid/cifar10_resnet18
% Figure environment removed

\subsubsection{Local robustness bias among classes}

%appendix/g_robustness_bias = 02f_p_distr_vs_classes/p_all_over_classes
% Figure environment removed

\clearpage
\subsubsection{Runtimes of \probust{} estimators}

\begin{table}[ht!]
\begin{tabular}{l|l|l|l|l|l}
    \multicolumn{2}{c}{}   & \multicolumn{2}{|c|}{CPU: Intel x86\_64}   & \multicolumn{2}{|c}{GPU: Tesla V100-PCIE-32GB} \\
    \midrule
    Estimator   & \# samples ($n$)   & Serial   & Batched   & Serial   & Batched \\
    \midrule
    \pmc{}   & \begin{tabular}[c]{@{}l@{}}$n=100$\\ $n=1000$\\ $n=10000$\end{tabular}               
             & \begin{tabular}[c]{@{}l@{}}0:00:59\\ 0:09:50\\ \textit{1:41:11}\end{tabular}                                               
             & \begin{tabular}[c]{@{}l@{}}0:00:42\\ 0:07:22\\ \textit{1:14:38}\end{tabular}                                                
             & \begin{tabular}[c]{@{}l@{}}0:00:12\\ 0:02:00\\ \textit{0:19:56}\end{tabular}                                                
             & \begin{tabular}[c]{@{}l@{}}0:00:01\\ 0:00:04\\ \textit{0:00:35}\end{tabular} \\
    \midrule
    \ptaylor{}   & N/A
                 & 0:00:08                                                                                                                      
                 & 0:00:07                                                                                                                      
                 & 0:00:02                                                                                                                      
                 & $<$ 0:00:01 \\
    \midrule
    \ptaylormvs{}   & N/A
                    & 0:00:08                                                                                                                   
                    & 0:00:07                                                                                                                  
                    & 0:00:01                                                                                                                   
                    & $<$ 0:00:01 \\
    \midrule
    \pmmse{}   & \begin{tabular}[c]{@{}l@{}}$n=1$\\ $n=5$\\ $n=10$\\ $n=25$\\ $n=50$\\ $n=100$\end{tabular} 
               & \begin{tabular}[c]{@{}l@{}}0:00:08\\ \textit{0:00:41}\\ 0:01:21\\ 0:03:21\\ 0:06:47\\ 0:13:57\end{tabular} 
               & \begin{tabular}[c]{@{}l@{}}0:00:10\\ \textit{0:00:31}\\ 0:01:02\\ 0:02:44\\ 0:05:38\\ 0:11:31\end{tabular} 
               & \begin{tabular}[c]{@{}l@{}}0:00:02\\ \textit{0:00:06}\\ 0:00:11\\ 0:00:26\\ 0:00:51\\ 0:01:42\end{tabular} 
               & \begin{tabular}[c]{@{}l@{}}0:00:02\\ \textit{0:00:02}\\ 0:00:02\\ 0:00:03\\ 0:00:04\\ 0:00:06\end{tabular} \\
    \midrule
    \pmmsemvs{}   & \begin{tabular}[c]{@{}l@{}}$n=1$\\ $n=5$\\ $n=10$\\ $n=25$\\ $n=50$\\ $n=100$\end{tabular} 
                  & \begin{tabular}[c]{@{}l@{}}0:00:08\\ \textit{0:00:41}\\ 0:01:21\\ 0:03:24\\ 0:06:47\\ 0:13:28\end{tabular} 
                  & \begin{tabular}[c]{@{}l@{}}0:00:08\\ \textit{0:00:32}\\ 0:01:00\\ 0:02:37\\ 0:05:35\\ 0:11:32\end{tabular} 
                  & \begin{tabular}[c]{@{}l@{}}0:00:01\\ \textit{0:00:05}\\ 0:00:10\\ 0:00:25\\ 0:00:51\\ 0:01:42\end{tabular} 
                  & \begin{tabular}[c]{@{}l@{}}0:00:01\\ \textit{0:00:01}\\ 0:00:02\\ 0:00:02\\ 0:00:03\\ 0:00:06\end{tabular} \\
    \midrule
    \psoftmax{}   & N/A                                                                             
                  & 0:00:01                                                                                                                              
                  & $<$ 0:00:01                                                                                                                              
                  & $<$ 0:00:01                                                                                                                              
                  & $<$ 0:00:01                                                                                                                             
\end{tabular}
\vspace{0.3cm}
\caption{Runtimes of each \probust{} estimator. Each estimator computes \probustwsigma{0.1} for the CIFAR10 ResNet18 model for 50 data points. For estimators that use sampling, the row with the minimum number of samples necessary for convergence is italicized. Runtimes are in the format of hour:minute:second. The analytical estimators (\ptaylor{}, \ptaylormvs{}, \pmmse{}, and \pmmsemvs{}) are more efficient than the naïve estimator (\pmc{}).}
\end{table}

\subsubsection{\probust{} identifies images that are robust to and images
that are vulnerable to random noise}

For each dataset, we train a simple CNN to distinguish between images with high and low \pmmse{}. We train the same CNN to also distinguish between images with high and low \psoftmax{}. The CNN consists of two convolutional layers and two fully-connected feedforward layers with a total of 21,878 parameters. For a given dataset, for each class, we take the images with the top-25 and bottom-25 \pmmse{} values. This yields 500 images for CIFAR10 (10 classes x 50 images per class) and 5,000 images for CIFAR100 (100 classes x 50 images per class). We also perform the same steps using \psoftmax{}, yielding another 500 images for CIFAR10 and another 5,000 images for CIFAR100. For each dataset, the train/test split is 90\%/10\% of points. 

Then, we compare the performance of the two models. For CIFAR10, the test set accuracy for the \pmmse{} CNN is 0.92 while that for the \psoftmax{} CNN is 0.58. For CIFAR100, the test set accuracy for the \pmmse{} CNN is 0.74 while that for the \psoftmax{} CNN is 0.55. The higher the test set accuracy of a CNN, the better the CNN distinguishes between images. Thus, the results indicate that \probust{} better identifies images that are robust to and vulnerable to random noise than \psoftmax{}.

Below, we also provide additional visualizations of images with the highest and lowest \probust{} and images with the highest and lowest \psoftmax{}.

\clearpage
%fig4 -- 2x4 images
%top-k and bottom-k images
% 02g_topk_bottomk_images/cifar10_resnet18/p_mmse/
% - cifar10_resnet18_p_mmse_sigma0.1_class8_bottomk.png
% - cifar10_resnet18_p_mmse_sigma0.1_class8_topk.png
% - ... class1 x 2
% 02g_topk_bottomk_images/cifar10_resnet18/p_sm
% - cifar10_resnet18_p_sm_sigma0.1_class8_bottomk.png
% - cifar10_resnet18_p_sm_sigma0.1_class8_topk.png
% - ... class1 x 2
% Figure environment removed


%fig4 -- 2x4 images
%top-k and bottom-k images
% 02g_topk_bottomk_images/cifar10_resnet18/p_mmse/
% - cifar100_resnet18_p_mmse_sigma0.1_class8_bottomk.png
% - cifar100_resnet18_p_mmse_sigma0.1_class8_topk.png
% - ... class23 x 2
% 02g_topk_bottomk_images/cifar10_resnet18/p_sm
% - cifar100_resnet18_p_sm_sigma0.1_class8_bottomk.png
% - cifar100_resnet18_p_sm_sigma0.1_class8_topk.png
% - ... class23 x 2
% Figure environment removed

\clearpage
\subsubsection{Examples of noisy images}

%3x1 noisy images
%top-k and bottom-k images
% 00_noisy_images/mnist/
% - mnist_imgidx10_class0_noisy_sigmas0.0_0.2_0.4_0.6_0.8_1.0.png
% - mnist_imgidx2_class1_noisy_sigmas0.0_0.2_0.4_0.6_0.8_1.0.png
% - mnist_imgidx1_class2_noisy_sigmas0.0_0.2_0.4_0.6_0.8_1.0.png
% Figure environment removed


%3x1 noisy images
%top-k and bottom-k images
% 00_noisy_images/fmnist/
% - fmnist_imgidx7_classshirt_noisy_sigmas0.0_0.2_0.4_0.6_0.8_1.0.png
% - fmnist_imgidx2_classtrousers_noisy_sigmas0.0_0.2_0.4_0.6_0.8_1.0.png
% - fmnist_imgidx0_classankle_boot_noisy_sigmas0.0_0.2_0.4_0.6_0.8_1.0.png
% Figure environment removed


\clearpage
%3x1 noisy images
%top-k and bottom-k images
% 00_noisy_images/cifar10/
% - cifar10_imgidx22_classdeer_noisy_sigmas0.0_0.02_0.04_0.06_0.08_0.1.png
% - cifar10_imgidx2_classship_noisy_sigmas0.0_0.02_0.04_0.06_0.08_0.1.png
% - cifar10_imgidx10_classairplane_noisy_sigmas0.0_0.02_0.04_0.06_0.08_0.1.png
% Figure environment removed


%3x1 noisy images
%top-k and bottom-k images
% 00_noisy_images/cifar10/
% - cifar100_imgidx4_classsea_noisy_sigmas0.0_0.02_0.04_0.06_0.08_0.1.png
% - cifar100_imgidx8_classcloud_noisy_sigmas0.0_0.02_0.04_0.06_0.08_0.1.png
% - cifar100_imgidx15_classlion_noisy_sigmas0.0_0.02_0.04_0.06_0.08_0.1.png
% Figure environment removed


\subsection{Broader Impact}
This work focuses on improving estimation of local robustness of machine learning models, and does not have any immediate foreseeable negative societal impact. Inexact estimation can affect downstream decisions and estimator quality should be taken into account to mitigate such cases.




% *********** OLD STUFF BELOW ***********

% \subsubsection{Convergence of \boldmath \pmc{} and \boldmath \pmmse{}}
% \label{app:exp-convergence-pmc-pmmse}

% \textbf{Convergence of \boldmath \pmc{}.} As the number of noisy samples increases, \pmc{} converges. The results indicate that \pmc{} converges at around 10,000 noisy samples.


% \textbf{Convergence of \boldmath \pmmse{}.} As the number of noisy samples increases, \pmmse{} converges. The results indicate that \pmmse{} converges at around 5-10 noisy samples.


% \subsubsection{Performance of method}
% \label{app:exp-method-performance}

% Experiment 1

% The proposed method properly estimates \probust{}.

% As expected, when the model is linear, estimators \ptaylor{} and \pmmse{} (which use a linear approximation of the model) perfectly approximate \probust{}.

% Metric 1: absolute differences

% Metric 2: relative differences

% robust models


% \textcolor{red}{below: need to update}

% \subsubsection{Local robustness vs. noise}
% \label{app:exp-pmc-vs-noise}

% Experiment 1

% As the noise neighborhood increases, local robustness deteriorates.




% \subsubsection{Correlation of \boldmath \probust{} and \boldmath \psoftmax{}}
% \label{app:exp-correlation-pmmse-psm}

% Experiment 3

% \probust{} and \psoftmax{} are not very correlated



% \subsubsection{Local robustness bias among classes}
% \label{app:exp-robustness-bias}

% Experiment 4

% fixed sigma

% fixed confidence level


% \subsubsection{Top vs. bottom images}
% \label{app:exp-topk-vs-bottomk}

% Experiment 5

% graphs

% topk vs. bottomk based on \probust{} (estimated by \pmmse{})

% topk vs. bottomk based on \psoftmax{}
