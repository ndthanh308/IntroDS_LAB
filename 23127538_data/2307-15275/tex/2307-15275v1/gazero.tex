
\textcolor{red}{
\subsection{Invariant Subspaces}
Consider the system
\begin{align}\label{lin_system}
    \dot x =Ax,
\end{align}
where $A \in \mathbb{R}^n$
\begin{definition}[Invariant Set]
    A set $\Gamma \subseteq \mathbb{R}^n$ is called \textbf{an invariant set} of \eqref{lin_system} if for any initial condition $x_0 \in \Gamma$ we have
    \begin{align}
        x=e^{At}x_0 \in \Gamma,~\forall t\geq 0.
    \end{align}
\end{definition}
\textbf{A special case of an invariant set is an invariant subspace}. Consider a subspace $\mathcal{J}$. From the Taylor series expansion we have
\begin{align}
    x = x_0 + tAx_0 + \dfrac{t^2}{2}A^2x_0 + \cdots.
\end{align}
It can be seen that if $A^kx_0 \in J, ~\forall k\geq 0$. Then, $x \in J, ~\forall t\geq0$. This is true only if $\mathcal{J}$ is a linear subspace. Then, a sufficient condition is
\begin{align}
    Az \in \mathcal{J}, ~\forall z \in \mathcal{J}.
\end{align}
This condition implies that the image of $J \in \mathbb{R}^n$ is contained in $\mathcal{J}$, or similarly,
\begin{align}
    A\mathcal{J} \subseteq \mathcal{J}
\end{align}
\begin{definition}
    \textbf{A necessary and sufficient condition} for a \textbf{linear subspace} $\mathcal{J}$ to be \textbf{A-invariant} under \eqref{lin_system} is that the following condition holds
    \begin{align}
        A\mathcal{J} \subseteq \mathcal{J}
    \end{align}
\end{definition}
\begin{proposition} \label{mult_subs}
    A subspace $\mathcal{J}$ with \textbf{basis matrix} $V$ is an $A-invariant$ if and only if $\exists$ a matrix $X$ such that
    \begin{align}
        AV = VX
    \end{align}
\end{proposition}
\begin{proof}
    Let $v_i ~\forall i=1,2,\cdots,r$ be the columns of the basis matrix $V$. Then, $\mathcal{J}$ is an \textbf{A-invariant} if and only if each transformed column $v_i$ (by $A$) is a linear combinations of all columns of $V$, or in other words, $\exists$ vectors $x_i$ such that
    \begin{align}
        Av_i = Vx_i,
    \end{align}
    or in general
    \begin{align}
        AV = VX.
    \end{align}
\end{proof}
\begin{theorem}
    Let $A$ be a \textbf{linear map} $\mathcal{F}^n \rightarrow \mathcal{F}^n$, and $\mathcal{J} \subseteq \mathcal{F}^n$ be an \textbf{A-invariant} subspace. Then, $\exists$ a similarity transformation $T$ such that
    \begin{align}
        A' \isdef T^{-1}AT = \matl
                                A_{11}' & A_{12}'\\
                                0 & A_{22}'
                             \matr,
    \end{align}
    where $A_{11}' \in \mathbb{R}^{D_{\mathcal{J}}}$, with $D_{\mathcal{J}} = \text{dim}(\mathcal{J})$
\end{theorem}
\begin{proof}
    Defining
    \begin{align}
        T = \matl
                T_1 & T_2,
            \matr
    \end{align}
    with $\text{Range}(T_1) = \mathcal{J}$. Then,
    \begin{align}
        W = T^{-1}T_1 = \matl
                            I_h\\
                            0
                        \matr.
    \end{align}
    Using, \ref{mult_subs}, we have
    \begin{align}
        A'W =& WX \nn\\
        \matl
                A_{11}' & A_{12}'\\
                0 & A_{22}'
        \matr
        \matl
                I_h\\
                0
        \matr    =&  \matl
                I_h\\
                0
        \matr X  \nn \\
        \matl
                A_{11}'\\
                0
        \matr    =&  \matl
                I_h\\
                0
        \matr X  
    \end{align}
    Then, that matrix $X$ is $A'_{11}$
\end{proof}
\subsection{Controlled invariant subspace}
Consider the system
\begin{align}\label{control_sys}
    \dot{x} =Ax + Bu.
\end{align}
\begin{definition}
    $\mathcal{V}$ is known as a controlled invariant subspace of \eqref{control_sys} if $\exists$ a feedback control $u=Fx$ such that $\mathcal{V}$ is an invariant subspace of
    \begin{align}
        \dot x= (A +BF)x = \Bar{A}x.
    \end{align}
\end{definition}
Then,
\begin{definition}
    $\mathcal{V}$ is an $\Bar{A}$ or $A,\text{Range}(B)$-invariant (controlled invariant) subspace if $\exists$ a matrix $F$, known as a \textbf{friend of $\mathcal{V}$}, such that
    \begin{align}
        (A+BF)\mathcal{V} \subseteq \mathcal{V}.
    \end{align}
\end{definition}
\begin{proposition}
    $\mathcal{V}$ is an $\Bar{A}$ or $(A,B)-$invariant if and only if 
    \begin{align}
        A\mathcal{V} \subseteq \mathcal{V} + \text{Range}(B).
    \end{align}
\end{proposition}
\begin{proof}[Necessity direction]
    Suppose $F$ is a friend of $\mathcal{V}.$ Then,
    \begin{align}
        (A + BF)\mathcal{V} \subseteq \mathcal{V},
    \end{align}
    which implies that
    \begin{align}
        A\mathcal{V}\subseteq \mathcal{V} - BF\mathcal{V}.
    \end{align}
    Since for any constant $a$, $a.\text{Range}(B) = \text{Range}(B)$, and
    \begin{align}
        BF\mathcal{V} \subseteq& \text{Range}(B)\nn \\
        -BF\mathcal{V} \subseteq& \text{Range}(B)\nn\\
        \mathcal{V} -BF\mathcal{V} \subseteq & \mathcal{V} + \text{Range}(B).
    \end{align}
    Then,
    \begin{align}
        A\mathcal{V}\subseteq& \mathcal{V} - BF\mathcal{V}\subseteq  \mathcal{V} + \text{Range}(B).\nn \\
        A\mathcal{V}\subseteq& \mathcal{V} + \text{Range}(B).
    \end{align}
    \textit{Sufficient direction and algorithm to find $F$}\\
    \hfill \\
    Let $\{v_1,v_2,\cdots,v_r\}$ be a basis of $\mathcal{V}$. Since $A\mathcal{V} \subseteq \mathcal{V}  + \text{Range}(B)$, $\exists$ for each $i=1,2,\cdots,r$ vectors $w_i$ and $u_i$ such that
    \begin{align}
        Av_i = w_i + Bu_i.
    \end{align}
    Let $F \in \mathbb{R}^{m \times n}$ such that
    \begin{align}
        Fv_i = -u_i ~ \forall i=1,2,\cdots,r.
    \end{align}
    Then,
    \begin{align}
        Av_i = w_i - BFv_i.\nn\\
        (A + BF)v_i = w_i \in \mathcal{V}.
    \end{align}
    Thus,
    \begin{align}
        (A+BF)\mathcal{V}\subseteq \mathcal{V}.
    \end{align}
    \textbf{Remark} if $r < n$, $F$ is not unique.
\end{proof}
\subsection{Conditioned Invariant Subspace}
Consider a pair $(A,\text{Null}(C))$. A subspace $\mathcal{S}$ is called an $(A,C)-$conditioned invariant if 
\begin{align}
    A(\mathcal{S}\cap\text{Null}(C)) \subseteq \mathcal{S}.
\end{align}
\textbf{Note:} Any $A-$invariant subspace is also a $(A,\text{Range}(B))-$ controlled invariant subspace or $(A,\text{Null}(C))-$conditioned invariant subspace
\begin{property}
    The sum of any two $(A,\text{Range}(B))-$controlled invariants is an $(A,\text{Range}(B))-$controlled invariant
\end{property}
\begin{property}
    The intersection of any two $(A,\text{Null}(C))-$conditioned invariants is an $(A,\text{Null}(C))-$conditioned invariant
\end{property}
\begin{property}
    For a pair $(A,B)$, a subspace $\mathcal{V} \subseteq \mathcal{F}^n$ is a \textbf{locus of controlled trajectories} of $(A,B)$ if and only if it is an \textbf{$(A,\text{Range}(B))-$controlled invariant subspace.}
\end{property}
\begin{proposition}[Minimal A-Invariant containing Range(B)]\label{min_A_inv} The minimal A-invariant containing Range$(B)$ is denoted by $\min \mathcal{J}(A,\text{Range}(B))$ and given by the last element of the sequence
    \begin{align}
        Z_k = Z_{k-1} + AZ_{k-1} ~\forall k=0,1,\cdots,r,
    \end{align}
where $r\leq n-1.$, a value which is determined by the condition $Z_{k+1}=Z_{k}$ , and $Z_0=\text{Range}(B)$,
\end{proposition}
\begin{proof}
    Note that
    \begin{align}
        Z_{k-1} \subseteq Z_k.
    \end{align}
    Therefore,
    \begin{align}
        AZ_{k-1} \subseteq AZ_k.
    \end{align}
    The condition for $Z_k$ to be an A-invariant subspace is given by
    \begin{align}
        AZ_k \subseteq Z_k.
    \end{align}
    Let's analyze the case when $k=n$. Then,
    \begin{align}
        Z_n = Z_{n-1}  + AZ_{n-1},
    \end{align}
    By induction, we have
    \begin{align}\label{seq}
        Z_1 =& \text{Range}(B) + A\text{Range}(B)\nn\\
        Z_2 =& \text{Range}(B) + A\text{Range}(B) + A^2\text{Range}(B)\nn\\
        \vdots &\nn\\
        Z_{n-1} =& \text{Range}(B) + A\text{Range}(B) + \cdots +A^{n-1}\text{Range}(B).\nn \\
        Z_n =& \text{Range}(B) + A\text{Range}(B) + \cdots +A^n\text{Range}(B).
    \end{align}
    By the Cayley-Hamilton theorem, 
    \begin{align}
        A^n =& c_0 I + c_1 A + \cdots + c_{n-1}A^{n-1}\nn \\
        A^n\text{Range}(B) =& c_0 \text{Range}(B) + c_1 A\text{Range}(B) + \cdots + c_{n-1}A^{n-1}\text{Range}(B).
    \end{align}
    Here it is important to note that for any constant $a$, $a.\text{Range}(B) = \text{Range}(B)$. Therefore,
    \begin{align}\label{Cayley-An}
        A^n\text{Range}(B) =& \text{Range}(B) + A\text{Range}(B) + \cdots + A^{n-1}\text{Range}(B).
    \end{align}
    Using \eqref{Cayley-An} in \label{seq},
    \begin{align}
        Z_{n} =& 2\text{Range}(B) + 2A\text{Range}(B) + \cdots +2A^{n-1}\text{Range}(B).
    \end{align}
    Using again the fact that $a.\text{Range}(B) = \text{Range}(B)$,
    \begin{align}
        Z_{n} =& \text{Range}(B) + A\text{Range}(B) + \cdots +A^{n-1}\text{Range}(B).\nn \\
        Z_{n} =& Z_{n-1}.
    \end{align}
    We also know that
    \begin{align}
        Z_{n} = \text{Range}(B) + AZ_{n-1}.
    \end{align}
    Since $Z_n=Z_{n-1}$, and we are looking for the smallest subspace,
    \begin{align}
        Z_{n-1} = \text{Range}(B) + AZ_{n-1},
    \end{align}
    which shows that
    \begin{align}
        \text{Range}(B) \subseteq Z_{n-1},
    \end{align}
    and
    \begin{align}
        AZ_{n-1} \subseteq Z_{n-1}.
    \end{align}
    Thus,
    \begin{align}
        Z_{n-1} = \text{Range}(B) + A\text{Range}(B) + \cdots +A^{n-1}\text{Range}(B).  
    \end{align}
    is the smallest $A-$invariant subspace that contains $\text{Range}(B)$ for a fully controllable system, or similarly,
    \begin{align}
        Z_{n-1} = \text{span}\matl B & AB & \cdots & A^{n-1}B\matr,
    \end{align}
    and in general, $\min \mathcal{J}(A,\text{Range}(B))$, is given by the last element of the sequence of subspaces,
    \begin{align}
        Z_{k} = Z_{k-1} + AZ_{k-1} ~\forall k=1,2,\cdots,r=\text{span}\matl B & AB & \cdots & A^{r}B\matr,
    \end{align}
    for $r\leq n-1$, a value which is determined by the condition $Z_{k+1}=Z_{k}$
    \end{proof}  
    \begin{proposition}[Maximal A-Invariant contained in Null(C)]\label{max_A_inv}
        \textit{The maximal A-invariant contained in Null(C) is denoted by} $\max \mathcal{J}(A,\text{Null}(C)$ and is given by the last element of the sequence of subspaces
        \begin{align}
            Z_0 =& \text{Null}(C)\nn\\
            Z_k =& \text{Null}(C)~\cap~A^{-1}Z_{k-1}~\forall~k=1,2,\cdots,r,
        \end{align}
        where $r\leq n-1$, a value which is determined by the condition $Z_{k+1}=Z_{k}$.
    \end{proposition}
    \begin{proof}
        Proposition \ref{max_A_inv} is equivalent to
        \begin{align}
            Z_0^{\perp} =& (\text{Null}(C))^{\perp}\nn\\
            Z_k^{\perp} =& (\text{Null}(C)~\cap~A^{-1}Z_{k-1})^{\perp} = (\text{Null}(C))^{\perp} + A^{\rm T}Z_{k-1}^{\perp}~\forall~k=1,2,\cdots,r, 
        \end{align}
        which, following the proof from  proposition \ref{min_A_inv} and from the duality
        \begin{align}
            A\mathcal{J}\subseteq&\mathcal{J} ~\Leftrightarrow ~ A^{\rm T}\mathcal{J}^{\rm T} \subseteq \mathcal{J}^{\rm T}\\
            \text{Null}(C) \supseteq& \mathcal{J} ~\Leftrightarrow ~ (\text{Null}(C))^{\perp} \subseteq (\mathcal{J})^{\perp},
        \end{align}
        to be the orthogonal complement of the minimum \textit{A-invariant} subspace containing Null$(C)$, or
        \begin{align}
            (\min\mathcal{J}(A^{\rm T},\text{Null}(C)^{\perp}))^{\perp}=\max\mathcal{J}(A,\text{Null}(C))
        \end{align}
    \end{proof}
    \begin{definition}[$\min \mathcal{S}(A,\text{Null}(C),\text{Range}(B))$]
        The infimum (or the intersection) of all $(A,\text{Null}(C))$-conditioned invariant subspaces containing a given subspace $\text{Range}(B)$ is known as the $\min \mathcal{S}(A,\text{Null}(C),\text{Range}(B))$.
    \end{definition}
    \begin{definition}
        The supremum of all $(A,\text{Rane}(B))$-controlled invariant subspaces contained a given subspace $\text{Null}(C)$ is known as the $\max \mathcal{S}(A,\text{Range}(B),\text{Null}(C))$.
    \end{definition}
    \begin{proposition}[Minimal $(A,\text{Null}(C))-$conditioned invariant containing $\text{Range}(B)$]
        It is denoted by the \textit{Subspace} $\min \mathcal{S}(A,\text{Null}(C),\text{Range}(B))$ coincides with the last term of the sequence of subspaces
        \begin{align}
            Z_0 =& \text{Range}(B)\nn\\
            Z_k =& \text{Range}(B) + A(Z_{k-1}\cap \text{Null}(C)) ~\forall k=1,2,\cdots,r
        \end{align},
        where the value of $r\leq n-1$ is determined by the condition $Z_{k+1}=Z_k.$
    \end{proposition}
    \begin{proof}
        Note that
        \begin{align}
            Z_{k-1} \subseteq Z_k.
        \end{align}
        Therefore,
        \begin{align}
            A(Z_{k-1}\cap\text{Null}(C))\subseteq A(Z_k\cap \text{Null}(C)).
        \end{align}
        We need to have
        \begin{align}
            Z_k =& \text{Range}(B) + A(Z_{k}\cap \text{Null}(C)),
        \end{align}
        for the following conditions to hold
        \begin{align}
            \text{Range}(B) \subseteq& Z_k\nn\\
            A(Z_k \cap \text{Null}(C)) \subseteq& Z_k,
        \end{align}
        which is the condition for a $(A,\text{Null}(C))-$conditioned invariant subspace containing $\text{Range}(B)$. 
    \end{proof}
    \begin{proposition}[maximal $(A,\text{Range}(B))-$controlled invariant subspace contained in $\text{Null}(C).$]
        or $\max\mathcal{V}(A,\text{Range}(B),\text{Null}(C))$ coincides with the last term of the sequence
        \begin{align}
            Z_0 =& \text{Null}(C)\nn\\
            Z_k =& \text{Null}(C)\cap A^{-1}(Z_{k-1} + \text{Range}(B))~\forall~i=1,2,\cdots,r,
        \end{align}
        where the value of $k\leq n-1$ is determined by the condition $Z_{r+1}=Z_r$
    \end{proposition}
    \begin{proof}
        This problem is equivalent to
        \begin{align}
            Z_0^{\perp} =& \text{Null}(C)^{\perp}\nn\\
            Z_k^{\perp} =& (\text{Null}(C)\cap A^{-1}(Z_{k-1} + \text{Range}(B)))^{\perp} = \text{Null}(C)^{\perp} + A^{\rm T}(Z_{k-1}^{\perp} \cap \text{Range}(B)^{\perp}).
        \end{align}
        This converges to the orthogonal complement,
        \begin{align}
            (\min\mathcal{S}(A^{\rm T},\text{Range}(B)^{\perp},\text{Null}(C)^{\perp}))^{\perp}.
        \end{align}
        We also know that
        \begin{align}
            (\min\mathcal{S}(A^{\rm T},\text{Range}(B))^{\perp},\text{Null}(C)^{\perp})^{\perp} = \max\mathcal{V}(A,\text{Range}(B),\text{Null}(C)).
        \end{align}
    \end{proof}
    \begin{definition}[\textbf{Stability and Complementability}]
        Since an $A-$invariant $\mathcal{J}\subseteq\mathcal{F}^n$ is a locus of trajectories, stability can be studied with respect to $\mathcal{J}$. We know that an $A-$invariant subspace has a linear transformation $T:$ $x=Tz$ such that
        \begin{align}
            \matl
                \dot{z}_1(t)\\
                \dot{z}_2(t)
            \matr = \matl
                        A'_{11} & A'_{12}\\
                        0 & A'_{22}
                    \matr
                    \matl
                        z_1(t)\\
                        z_2(t)
                    \matr,
        \end{align}
        and consider an initial state $x_0 \in \mathcal{J}$. Then,
        \begin{align}
            z_0 = T^{-1} x_0
        \end{align}
        descomposes $x'_0$ into $(z_{01},0)$, since the motion on $\mathcal{J}$ is described by
        \begin{align}
            \dot{z}_1(t)=A'_{11}z_1(t),\quad z_1(0)=z_{01},
        \end{align}
        and
        \begin{align}
            \dot z_2 = 0,\quad z_2(0)=0,
        \end{align}
        which implies that $z_2$ remains identically zero. This implies that the motion of $\mathcal{J}$ is stable if and only if the submatrix $A'_{11}$ is stable. On the other hand, consider an initial state $x'_0 \not \in \mathcal{J},$, which implies that $z'_{02}\neq 0$, and $z_2(0)=(0,z'_{02})$. Then,
        \begin{align}
            \dot z_2(t)=A'_{22}z_2(t),\quad z_2(0)=z'_{02},
        \end{align}
        In this case the canonical projection of the state on the quotient space $\mathcal{F}/\mathcal{J}$ tends to the origin as $t\to\infty$ if $A'_{22}$ is a stable matrix. Therefore, \textbf{The invariant subspace $\mathcal{J}$ is said to be \textit{internally stable} if the submatrix $A'_{11}$ is stable and \textit{externally stable} if $A'_{22}$ is stable}
        % Figure environment removed
    \end{definition}
    \begin{definition}[Internally or externally stable invariant subspaces]
        Consider a linear map $A: \mathcal{F} \to \mathcal{F}$. Then, an $A-$invariant $\mathcal{J}\subseteq\mathcal{F}$ is said to be internally stable if $A|_{\mathcal{J}}$ is stable and externally stable if $A|_{\mathcal{F}/\mathcal{J}}$ is stable. From the Laplace expansion of determinants we have
        \begin{align}
            \det(A) = \det(A'_{11}).\det(A'_{22}).
        \end{align}
        Thus, a partition of the eigenvalues of $A$ is associated to every $A-$invariant $\mathcal{J}$ is given by the \textbf{\textit{internal eigenvalues with respect to $\mathcal{J}$, given by the eigenvalues of $A'_{11}$ or $A|_{\mathcal{J}}$}}, and \textbf{\textit{the external eigenvalues with respect to $\mathcal{J}$, given by the eigenvalues of $A'_{22}$ or $A|_{\mathcal{F}/\mathcal{J}}$}}.
    \end{definition}
    \begin{definition}[\textbf{Relative Stability}]
        Internal and/or external stability of invariants can be referred to other invariants. Let $\mathcal{J}$ and $\mathcal{J}_c$ be $A-$invariants and define
        \begin{align}
            \mathcal{J}_1=&\mathcal{J}\cap\mathcal{J}_c\nn\\
            \mathcal{J}_2=&\mathcal{J}+\mathcal{J}_c.
        \end{align}
        $\mathcal{J}_1$, and $\mathcal{J}_2$ are $A-$invariants too. Then, the changes of basis defined by
        \begin{align}
            T=\matl
                T_1 & T_2 & T_3 & T_4
              \matr,
        \end{align}
        with $\text{Range}(T_1)=\mathcal{J}_1$, $\text{Range}(\matl T_1 & T_2\matr)=\mathcal{J}$, $\text{Range}(\matl T_1 & T_3\matr)=\mathcal{J}_c$. Then, from the transformation $T$ of $A-$invariants we have
        \begin{align}
            A'=T^{-1}AT=\matl
                            A'_{11} & A'_{12} & A'_{13} & A'_{14}\\
                            0 & A'_{22} & 0 & A'_{24}\\
                            0 & 0 & A'_{33} & A'_{34}\\
                            0 & 0 & 0 & A'_{44}
                        \matr.
        \end{align}
        $\mathcal{J}$ is \textbf{internally stable} or $A|_{\mathcal{J}}$ is stable if and only if \textbf{ matrices $A'_{11}$ and $A'_{22}$ are stable}, and it is \textbf{externally stable} or $A|_{\mathcal{F}/\mathcal{J}}$ is stable if and only if \textbf{matrices $A'_{33}$ and $A'_{44}$ are stable}. Similarly, $\mathcal{J}_c$ is internally stable if and only if matrices $A'_{11}$ and $A'_{33}$ are stable, and it is externally stable if and only if matrices $A'_{22}$ and $A'_{44}$ are stable. Then, it follows that
        \begin{enumerate}
            \item The sum of 2 internally stable invariants is an internally stable invariant
            \item The intersection of 2 externally stable invariants is an externally stable invariant
            \item The intersection of an internally stable invariant and any other invariant is internally stable
            \item The sum of an externally stable invariant and any other invariant is externally stable
        \end{enumerate}
        Similarly, external stability for $\mathcal{J}_1$, and $\mathcal{J}_2$ can be listed as
        \begin{enumerate}
            \item $\mathcal{J}_1$ is \textbf{externally stable} with repect to $\mathcal{J}$ ($A|_{\mathcal{J}/\mathcal{J}_1}$) if \textbf{matrix $A'_{22}$ is stable.}
            \item $\mathcal{J}_1$ is \textbf{externally stable} with repect to $\mathcal{J}_c$ ($A|_{\mathcal{J}_c/\mathcal{J}_1}$) if \textbf{matrix $A'_{33}$ is stable.}
        \end{enumerate}
    \end{definition}
    \subsection{Self-Bounded Controlled Invariants and their Duals}
    \textbf{Self-bounded} controlled invariants admit both a supremum and an infimum. Given $\text{Null}(C) \subseteq \mathcal{F}$, define
    \begin{align}
        \mathcal{V}^{*}:=\max \mathcal{V}(A,\text{Range}(B),\text{Null}(C)),
    \end{align}
    as the maximal $(A,\text{Range}(B))-$controlled invariant contained in $\text{Null}(C)$. It is known that a trajectory of a pair $(A,B)$ can be controlled on $\text{Null}(C)$ if and only if its initial state belongs to a controlled invariant contained in $\text{Null}(C)$. \textbf{In general, for any initial state belonging to a controlled invariant $\mathcal{V}$, it is possible not only to continuously maintain the state on $\mathcal{V}$ by a suitable controller but also to leave $\mathcal{V}$ with a trajectory in $\text{Null}(C)$ (Hence on $\mathcal{V}^*$) and go to other controlled invariants contained in $\text{Null}(C)$}. \textbf{\textit{On the other hand, $\exists$ controlled invariants that are closed with respect to the control action (cannot be exited by any trajectory on $\text{Null}(C)$), this are called self-bounded with respect to $\text{Null}(C)$}}
    \begin{definition}[\textbf{Self-bounded Controlled invariant}]
        Let $\mathcal{V}$ be an $(A,\text{Range}(B))-$controlled invariant contained in a subspace $\text{Null}(C) \subseteq\mathcal{F}$. $\mathcal{V}$ is \textbf{self-bounded} with respect to $\text{Null}(C)$ if
        \begin{align}
            \mathcal{V}^*\cap\text{Range}(B)\subseteq\mathcal{V},
        \end{align}
        where
        \begin{align}
            \mathcal{V}^{*}:=\max \mathcal{V}(A,\text{Range}(B),\text{Null}(C)).
        \end{align}
        Let $F$ be a \textbf{friend} matrix such that
        \begin{align}
            (A +BF)\mathcal{V}\subseteq\mathcal{V}.
        \end{align}
        Hence,
        \begin{align}
            \mathcal{T}(x)=(A+BF)x + \mathcal{V}^*\cap\text{Range}(B).
        \end{align}
        Therefore, all the trajectories must belong to $\text{Null}(C)$ and not leave from it, or similarly,
        \begin{align}
            \mathcal{T}(x) \subseteq \mathcal{V}~\forall~x \in \mathcal{V}.
        \end{align}
        Thus,
        \begin{align}
            \mathcal{V}^*\cap\text{Range}(B)\subseteq \mathcal{V}.
        \end{align}
    \end{definition}
    \begin{definition}[$\Phi_{(\text{Range}(B),\text{Null}(C))}$]
        The set of all $(A,\text{Rangle}(B))-$controlled invariants self-bounded with respect to $\text{Null}(C)$ is closed with respect to the intersection and the sum
        \begin{align}
            \Phi_{(\text{Range}(B),\text{Null}(C))} = \{\mathcal{V}: A\mathcal{V}\subseteq \mathcal{V} + \text{Range}(B), \mathcal{V}\subseteq\text{Null}(C),\mathcal{V}\supseteq\mathcal{V}^{*}\cap \text{Range}(B)\},
        \end{align}
        where \textbf{the maximal} $(A,\text{Range}(B))-$controlled invariant contained in the $\text{Range}(C),$ (which is also the supremum of $\Phi_{(\text{Range}(B),\text{Null}(C))}$), is \textbf{self-bounded} (which means that it contains $\mathcal{V}^{*}\cap \text{Range}(B)$)
    \end{definition}
    \begin{definition}[\textbf{Infimum of} $\Phi_{(\text{Range}(B),\text{Null}(C))}$]
        The infimum of $\Phi_{(\text{Range}(B),\text{Null}(C))}$ is
        \begin{align}
            \mathcal{V}^* \cap \mathcal{S}^*,
        \end{align}
        with
        \begin{align}
            \mathcal{S}^*=& \min\mathcal{S}(A,\text{Null}(C),\text{Range}(B)).\nn\\
            \mathcal{V}^*=& \max\mathcal{V}(A,\text{Range}(B),\text{Null}(C))
        \end{align}
    \end{definition}
    \subsection{Invariant Zeros}
    Let $\mathcal{Z}$ be an $(A,\text{Range}(B))-$controlled invariant subspace. The set of invariant zeros is the set of $\lambda$ for which
    \begin{align}
        \matl
            \lambda I -A & B\\
            C & 0
        \matr
        \matl
            x\\
            u
        \matr=
        \matl
            0\\
            0
        \matr,
    \end{align}
    has a solution for some scalar $u_0$ and nonzero $x_0 \in \mathcal{F}\cap\mathcal{Z}$. Suppose that $\lambda$ is an eigenvalue of $(A,\text{Range}(B))|_{\mathcal{Z}}$, and an invariant zero of the system. Then,
    \begin{align}
        \matl
            \lambda I -A & B\\
            C & 0
        \matr
        \matl
            x_0\\
            u_0
        \matr=
        \matl
            0\\
            0
        \matr.
    \end{align}
    This shows that
    \begin{align}
        Cx_0=0,
    \end{align}
    which implies that $x_0 \in \text{Null}(C)$, and also
    \begin{align}
        \lambda x_0 + Bu_0 = Ax_0,
    \end{align}
    so $x_0$ is contained in a $(A,\text{Range}(B))-$controlled invariant subspace contained in $\text{Null}(C)$. Moreover, we want the supremum of the $(A,\text{Range}(C))$ contained in $\text{Null}(C)$. Then,
    \begin{align}
        x_0 \in \max \mathcal{V}(A,\text{Range}(B),\text{Null}(C)).
    \end{align}
    Furthermore, $\mathcal{V}^*$ has an infimum as well, which is
    \begin{align}
        R_{V^*}=V^*\cap S^*,
    \end{align}
    which represents the assignable subspace of $V^*,$ (or in other words the subspace of $V^*$ for which $\text{Range}\in \mathcal{V}^*$). From the complementability property of $\mathcal{V}^*$ we have
    \begin{align}
        R_{\mathcal{V}^*} + \mathcal{V} = \mathcal{V}^*.
    \end{align}
    where $\mathcal{V}$ is also an $(A,\text{Range}(B))-$controlled invariant subspace that represents the unassignable subspace of $\mathcal{V}$ such that,
    \begin{align}
        (A + BF)\mathcal{V}\subseteq\mathcal{V}.
    \end{align}
}
