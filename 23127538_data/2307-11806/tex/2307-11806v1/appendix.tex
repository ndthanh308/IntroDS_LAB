\section{Survey}
\label{app:b}
\subsection{Variables}%Independent, Confounding, Control, and Dependent Variables}
The independent variables are the possible scenarios (TP, TN, FP, FN, and rejection).
%
%The true positive (TP) and true negative (TN) scenarios mean that SocialNet successfully detects whether a post is hateful or not, respectively.
%
%The false positive (FP) scenario means that SocialNet incorrectly predicts a non-hateful post as hateful, and conversely for the false negative (FN) scenario.
%
We inform participants in the survey that when hate speech is detected, SocialNet ranks the hateful post lower so that it takes much more effort for the users to find the post.
%
%The rejection scenario means that SocialNet is uncertain whether the post was hateful or non-hateful and thus the post requires human decision-making.
%
For the rejection scenario, we inform the participants in the survey that a moderator needs to check the post within 24 hours, and meanwhile, the post remains visible.% with its original rank on the page.
%
The design decision of using 24 hours is based on the German NetzDG law, which allows the government to fine social media platforms if they do not remove illegal hate speech within 24 hours~\cite{Tworek2019AnAO}.
%
%\subsection{Confounding Variables}
%Confounding variables are demographics, such as gender, education, location, and age.
%
%Participants from different backgrounds may define hate speech differently and have various perspectives about handling hate speech.
%
%Some previous work focuses on studying confounding variables such as demographics. For example, \citet{gold2018women} showed that there is no significant difference when perceiving hate between genders.
%
%Our research does not study the effect of confounding variables though we may report them to inform the readers about the study context.
%
%We leave the investigation of the effects of demographics on the outcomes to future research.
%\subsection{Control variables}
Our study has two control variables: the measurement scales and the content of posts.
%
%Regarding the content of the post, due to limited resources, we manually select 40 posts from existing datasets containing hateful, neutral, and non-hateful tweets.
%
%The selection procedure is explained in a later subsection.
%
Regarding scales, as described before, we choose ME as our primary scale and use the 100-level scale for validation.
%
%We leave the study of other scales to future work.
%\subsection{Dependent variables}
Our dependent variables are reliability, validity, and value ratios.
%
We use Krippendorff's alpha to compute reliability, where a value equal to or larger than 0.8 and 0.6 indicates reliable and tentative conclusions, respectively~\cite{krippendorff2004reliability, maddalena2017crowdsourcing}.
%
Regarding validity, we use convergent validity~\cite{fitzner2007reliability} between the two scales to assess if they measure the same phenomenon.
%
The value ratio variable describes the perceived value of the scenarios, which is measured by calculating the median of the normalized magnitude estimates of each decision scenario.






\subsection{Demographics}
We perform a demographic analysis regarding the sex, student status, continent of residence, nationality, language, and ethnicity of our participants to study whether there are statistical differences in how they perceive hate speech. We have multiple groups for nationality, ethnicity, and language and two groups for the features of student status, sex, and continent of residence (since only two continents were present in the demographic data of all participants).



\begin{table*}[]
    \small
    \centering
    \begin{tabular}{lccc|ccc}
        \toprule
                     & \multicolumn{3}{c}{\textbf{Two groups}} & \multicolumn{3}{c}{\textbf{More than two groups}}                                                                                                                                                                       \\
        \midrule
                     & \multicolumn{1}{c}{\textbf{Sex}}        & \multicolumn{1}{c}{\textbf{Student}}              & \multicolumn{1}{c}{\textbf{Continent}} & \multicolumn{1}{c}{\textbf{Nationality}} & \multicolumn{1}{c}{\textbf{Language}}  & \multicolumn{1}{c}{\textbf{Ethnicity}} \\
        \midrule
        \textbf{TP}  & 0.302                                   & \textbf{0.032}            & 0.286                                  & 0.218                                    & 0.109                                  & 0.242                                  \\
        \textbf{TN}  & 0.726                                   & 0.379                                             & 0.204                                  & 0.190                                    & 0.216                                  & 0.281                                  \\
        \textbf{FP}  & 0.699                                   & 0.933                                             & 0.073                                  & \textbf{0.020}   & \textbf{0.040} & \textbf{0.037} \\
        \textbf{FN}  & 0.961                                   & 0.150                                             & 0.847                                  & 0.478                                    & 0.438                                  & 0.584                                  \\
        \textbf{REJ} & 0.835                                   & 0.625                                             & 0.496                                  & 0.271                                    & 0.103                                  & 0.068                                  \\
        \bottomrule
    \end{tabular}
    \caption{\textbf{Statistical differences between different groups of participants for various demographic characteristics for each aggregated scenario type in the ME survey. Each cell contains the $p$ value of either the Mann-Whitney U test for two groups or the Kruskal-Wallis test for more than two groups. Bold text indicates significant statistical differences.}}
    \label{tab:results-differences-grp}
\end{table*}


Table \ref{tab:results-differences-grp} shows the group differences for the aggregated scenario types (TP, TN, FP, FN, and REJ) and highlights the $p$ values that differ substantially. We found the most significant differences across all scenarios for different nationalities and languages of participants.


\subsection{Pilot Study}

We conducted a pilot study with 24 participants to test the survey and estimate the required completion time.
%
The pilot study showed low inter-rater reliability, which may be due to unmatched expectations and unclear scenario descriptions.
%
Initially, our scenarios mentioned that machine-detected hateful posts would be removed, which could be controversial.
%
Thus, we changed scenarios to rank the hateful posts lower on the feed. % so that it takes more effort for users to scroll the page to access the posts.
%
Moreover, we added more lengthy descriptions to explain the potential consequences of all scenarios in a neutral tone, which prepares the participants to focus on evaluating harm (instead of giving rewards).
%
%After the changes, the official survey study shows higher inter-rater reliability.




\subsection{Example Tasks}
\textbf{WARNING: GRAPHIC LANGUAGE.}
\subsubsection{FN scenario with ME scale}
\begin{flushleft}
    Suppose we have the following post:\\
    \textit{``I want this stupid bitch out of my head I've never even liked her lmao I just basically want to rape her''} (from \citet{basile2019semeval})\\
\end{flushleft}
\begin{flushleft}
    \textbf{Question 1}:\\
    Please indicate whether you feel that this post is hateful or not hateful.\\
    **Select input with options: 'hateful' or 'not hateful'**\\
\end{flushleft}
\begin{flushleft}
    \textbf{Question 2}:\\
    You are a user of the SocialNet platform and just saw this post on your main feed because SocialNet's automated detection system is confident that it is not hateful.
\end{flushleft}
\begin{itemize}
    \item This post remains visible on other people's main feeds as well.
    \item If the post is hateful after all, then the detection system was incorrect. This hateful post is now visible on people's main feeds with the consequence that they can get harmed.
    \item If the post is indeed not hateful, then the detection system was correct.
    \item You should be aware that it is expected for SocialNet to correctly classify hate speech. Wrong classifications are undesirable as they may cause harm to people.
\end{itemize}
\begin{flushleft}
    Please indicate whether you agree, disagree, or are neutral about SocialNet's decision.\\
    **Select input with options: 'agree', 'neutral', or 'disagree'.**\\
\end{flushleft}
\begin{flushleft}
    \textbf{Question 3 (only visible when 'agree' or 'disagree' are selected):}\\
    Please indicate how much you agree/disagree with SocialNet's decision using any positive number.\\
    **Show ME input field that allows all positive values greater than 0.**
\end{flushleft}
\subsubsection{FP scenario with 100-level scale}
\begin{flushleft}
    Suppose we have the following post:
    \textit{``Ontario concerns were not listened at immigration meeting in Ottawa For illegal crossing''} (from \citet{basile2019semeval})\\
\end{flushleft}
\begin{flushleft}
    \textbf{Question 1}:\\
    Please indicate whether you feel that this post is hateful or not hateful.\\
    **Select input with options: 'hateful' or 'not hateful'**\\
\end{flushleft}
\begin{flushleft}
    \textbf{Question 2}:\\
    You are a user of the SocialNet platform and have not seen this post on your main feed because SocialNet's automated detection system is confident that it is hateful.
\end{flushleft}
\begin{itemize}
    \item You can still find this post when you scroll down your feed since SocialNet ranks hateful posts lower.
    \item If the post is not hateful after all, then the detection system was incorrect. This neutral post is now ranked lower on people's feeds with the consequence that the post cannot easily reach the author's followers.
    \item If the post is indeed hateful, then the detection system was correct.
    \item You should be aware that it is expected for SocialNet to correctly classify hate speech. Wrong classifications are undesirable as they may cause harm to people.
\end{itemize}
\begin{flushleft}
    Please indicate whether you agree, disagree, or are neutral about SocialNet's decision.
    **Select input with options: 'agree', 'neutral', or 'disagree'.**\\
\end{flushleft}
\begin{flushleft}
    \textbf{Question 3 (only visible when 'agree' or 'disagree' are selected):}\\
    Please indicate how much you agree/disagree with SocialNet's decision using any positive number from 1 to 100. If you feel neutral about SocialNet's decision, select neutral in the field above.
    **Show a numerical slider with values between 1 and 100.**\\
\end{flushleft}
\subsubsection{Rejection scenario with 100-level scale}
\begin{flushleft}
    Suppose we have the following post:
    \textit{``Ever been so hungover that your stomach feels like it's eating itself''} (from \citet{basile2019semeval})\\
\end{flushleft}
\begin{flushleft}
    \textbf{Question 1}:\\
    Please indicate whether you feel that this post is hateful or not hateful.\\
    **Select input with options: 'hateful' or 'not hateful'**\\
\end{flushleft}
\begin{flushleft}
    \textbf{Question 2}:\\
    You are a user of the SocialNet platform and just saw this post on your main feed because SocialNet's automated detection system was not confident enough in whether it was hateful or not.
\end{flushleft}
\begin{itemize}
    \item An internal human moderator at SocialNet needs to look at it within at most 24 hours.
    \item Meanwhile, the post remains visible on people's main feeds.
\end{itemize}
\begin{flushleft}
    Please indicate whether you agree, disagree, or are neutral about SocialNet's decision.\\
    **Select input with options: 'agree', 'neutral', or 'disagree'.**\\
\end{flushleft}
\begin{flushleft}
    \textbf{Question 3 (only visible when 'agree' or 'disagree' are selected):}\\
    Please indicate how much you agree/disagree with SocialNet's decision using any positive number.\\
    **Show a numerical slider with values between 1 and 100.**\\
\end{flushleft}

