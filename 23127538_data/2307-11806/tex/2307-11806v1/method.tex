

\section{Background on Value-Sensitive Rejection of Machine Decisions}
\label{s:3}
This section introduces the background of value-sensitive rejection of machine decisions in a hybrid human-AI workflow, based on previous work \cite{Sayin2022,Sayin2021reject}, and subsequently identifies factors that influence value perception in hate speech detection.
% our assumptions for hate speech detection. We then show how value guides the decision of rejecting machine decisions, through the determination of the optimal rejection threshold.
\iffalse
\subsection{Preliminary Value Formulation}

We first introduce the notations used in the paper and then formalize the optimal threshold in terms of value. We use boldface lowercase letters to denote vectors and boldface uppercase letters to denote matrices. For an arbitrary vector $\mathbf{v}$ and matrix $\mathbf{M}$, we use $\mathbf{v}_i$ to denote the $i$-th entry and $\mathbf{M}_{i,j}$ to denote the entry at the $i$-th row and $j$-th column, respectively. To denote sets, we use capital letters (e.g., $\mathcal{P}$) in calligraphic math font.

\subsubsection{Machine Decision with Rejection} 
\color{blue} Following the recent discussions on value-sensitive machine learning~\cite{Sayin2021reject,casati2021value}, \color{black} we consider the general setup of human-AI collaboration as follows: the machine decision can either be accepted or rejected; if rejected, the decision will be taken over by a human decision maker. 
%
\color{red}Formally, consider a $k$-class classification problem for which we have a machine learning classifier $g$, whose output on a data item $x\in\mathcal{D}$ is a vector of probability distribution $\mathbf{c}\in [0,1]^k$ consisting of the confidence per class (e.g., the output from the softmax layer of a neural network). $x$ is assigned class $y = \argmax_k(\mathbf{c}_k)$. \color{black} The rejection is determined based on a threshold denoted by $\tau \in [0,1]$, which then modifies the output of the machine as follows
\begin{equation}
    \hat{y} = 
    \begin{cases}
       \text{$y$,\ } \quad\text{$\mathbf{c}_y \geq \tau$,}\\
       \text{$y_r$,} \quad\text{otherwise.} \\ 
     \end{cases}
\end{equation}
where $y_r$ denotes the special decision of rejection which results in a human making the final decision. Note that we can have different thresholds for different classes, e.g., one for positive predictions and another for negative predictions in a binary classification task. 

\subsubsection{Value of Machine Decisions}
\color{red} Given such a setting, we now formalize the value (or cost) of correct and incorrect decisions by the machine and that of rejections. We denote the value of classifying a data item correctly, incorrectly, and that of rejecting a classification as $\mathbf{V}_{c} \in \mathbb{R}^{k\times k}$, $\mathbf{V}_{w}  \in \mathbb{R}^{k\times k}$, and $V_r \in \mathbb{R}$, respectively. Note,$\mathbf{V}_{c}$ is a diagonal matrix where $\left[\mathbf{V}_{c}\right]_{ii}$ represents the positive value of the \emph{correct} decision for $i$-th class; $\mathbf{V}_{w}$ is a matrix having the same size as a confusion matrix where $\left[\mathbf{V}_{w}\right]_{ij}$ represents the cost of corresponding \emph{incorrect} decisions, which is negative, that classifies an item of class $i$ to $j$; and $V_r$ is a negative scalar that can be viewed as a constant cost for rejecting any decisions. % In the context of hate speech detection, we consider the value from user-only perspective. 
% representing the cost of a rejection, which is equivalent to the cost of a manual moderation that can be assumed to be a constant. 

With these notations, the equation for the average value of a decision made by $g$ operating on data $x \in \mathcal{D}$ with a reject option can be stated as
\begin{equation}
    \label{eq:value}
    V \left(g, \mathcal{D} \right) = \rho V_r + \left( 1 - \rho \right)\sum_{ij} \mathbf{\Omega}_{ij} \odot \left( \left[\mathbf{V}_{c}\right]_{ij} + \left[\mathbf{V}_{w} \right]_{ij} \right),
\end{equation}
where $\rho$ is the proportion of elements found in $\mathcal{D}$ which are rejected by $g$. Further, $\mathbf{\Omega}$ is a matrix containing the proportion of predictions in each cell of the confusion matrix, provided that they are above the threshold. Finally, $\odot$ indicates the Hadamard product between two matrices, of which we use the summation across all elements of row $i$ and column $j$.

\color{black}\fi


\subsection{Rejection for Binary Classification} 
We consider the general case of human-AI collaboration as follows: the machine decision can either be accepted or rejected; if rejected, the decision will be taken over by a human decision maker. 
%
Formally, consider a binary classification problem for which we have a machine learning classifier, whose output on a data item $x$ is confidence, $\mathbf{c}$, (e.g., the output from the softmax layer of a neural network). The rejection is dependent on a threshold denoted by $\tau \in [0,1]$, which then modifies the final output of the machine as
\begin{equation}
    \hat{y} = 
    \begin{cases}
       \text{$y$,\ } \quad\text{$\mathbf{c}_y \geq \tau$,}\\
       \text{$y_r$,} \quad\text{otherwise.} \\ 
     \end{cases}
\end{equation}
where $y$ denotes an accepted decision and $y_r$ denotes the special decision of rejection, resulting in a human making the final decision. 

We now discuss how the optimal confidence threshold for rejecting machine decisions is affected by the value formulation. 
%
%Without loss of generality, 
We consider the binary classification case: when the machine decision is either positive (i.e., the content is deemed hateful) or negative (i.e., non-hateful). There is a value, $V$, attached to each of these, depending on whether this positive or negative decision is correct or not. This results in true positive (TP), true negative (TN), false positive (FP), false negative (FN), and rejected predictions as possible outcomes. $V_{TP}$ and $V_{TN}$ are positive, while $V_{FP}$, $V_{FP}$, and rejected predictions, $V_r$, are negative (i.e., costs).
%We further consider the case when the classifier is well-calibrated, as well as when the classifier is not calibrated. 
% \subsubsection{Optimal Threshold for Calibrated Machines}
\iffalse
Consider that for the positive classifications, the accuracy of the classifier is $\alpha^p$, meaning that the $\alpha^p$ proportion of the positive classifications are true positives, and $(1-\alpha^p)$ are false positives. \color{red}Given this, the optimal threshold $\tau^p$ should be the one where the total value is greater than 0 when the confidence of machine decision is above $\tau^p$ and less than 0 otherwise. Equivalently, it means the value of acceptance of the machine decision when the confidence is $\tau^p$ should be 0. When the model is calibrated, we have $\alpha^p = \tau^p$; that is, the model confidence equals the accuracy, resulting in\color{black}
\begin{equation}
\tau^p V_{TP} + (1-\tau^p) V_{FP} = 0
\end{equation}
where $V_{TP}$ and $V_{FP}$ are the value of true positive and false positive outcomes\cmj{let's add a footnote here that the value of false positive $V_{FP}$ should be a negative number, indicating essentially a cost}, respectively. 
\fi
The optimal threshold for positive classifications is:
\begin{equation}
    \tau^p_O = \frac{V_{FP}}{V_{FP} - V_{TP}} = \frac{\gamma^p}{\gamma^p+1}
    \label{eq:optimal_threshold}
\end{equation}
if we assume $V_{FP} = -\gamma^p \cdot V_{TP}$, that is, the cost of a false positive is $\gamma^p$ times worse than the value of a true positive. Similarly, in the case of negative classifications, the optimal threshold would be $\tau_O^n = \frac{\gamma^n}{\gamma^n+1}$ where $V_{FN} = -\gamma^n \cdot V_{TN}$, i.e., the cost of false negative is $\gamma^n$ times worse than the value of a true negative.

When the cost of incorrect decisions is very high, i.e., $\gamma \gg 1$, the optimal confidence threshold would tend close to 1, meaning almost all machine decisions are rejected. When the cost of an incorrect decision is very low, i.e., $\gamma \approx 0$, the optimal threshold would be close to 0, and virtually all machine decisions are accepted. These results, therefore, follow our intuition. 
%
An important conclusion we can draw from~\cref{eq:optimal_threshold} is that the optimal threshold is dependent \emph{only on the ratio} of the value (or cost) between an incorrect decision and that of a correct one (per class). % instead of the absolute quantities. 

% \subsubsection{Optimal Threshold for Non-Calibrated Machines} 
 
%As different thresholds lead to different total values, the optimal threshold that corresponds to the highest overall value can be selected.
%
Threshold optimization is the process of finding the threshold that maximizes value empirically. If a system is calibrated before use, simulations can be used to find the optimal theoretical threshold, which is the optimal $\tau$ that maximizes value. In this paper, $\tau$ is determined by means of calibration, done by means of temperature scaling~\cite{Mozafari2018scaling}, followed by a calculation of the theoretical threshold based on the crowdsourced survey data, as it allows us to quantify and compare the opinions of participants on the value of true and false predictions and thus compute the ratios for our use case.
%
%When the machine confidence is not well-calibrated, the optimal threshold can be found by fitting empirical observations.

%This is done by plotting a threshold-total value curve where each point in the curve represents the overall value of machine decisions on a given dataset.

%The classifier will reject a prediction if its confidence $c$ in the prediction falls below the required threshold $\tau \in [0,1]$. The cost ratio for a TP, TN, FP, FN, and rejected prediction can be determined through calibration or threshold optimization. This ratio is determined by considering the relative value of false predictions to true predictions. Calibration of a $m$ before use can lead to a subsequent maximization of value through filtering for the theoretical threshold, which is the optimal $\tau$ that maximizes value. Threshold optimization is the process of finding the threshold that maximizes value empirically. In this paper, $\tau$ is determined by means of calibration, done by means of temperature scaling, followed by a calculation of the theoretical threshold based on the crowdsourced survey data, as it allows us to quantify and compare the opinions of participants on the value of true and false predictions and thus compute the ratios for our use case.


% For each prediction that is made $\tau$ is dependent on the $k$ classes, namely TP, TN, FP, and FN. This results in a distinct $\tau$ for each class that has to be exceeded by $c$ for a prediction to be made. The value for the case of the classifier rejecting to make a prediction, $V_{R}$, is a constant, as the reduction of value through the use of additional human effort does not change as a result of $x$. Thus the value for an individual data instance $x$ where $g$ chooses to reject is always $V_{x} = V_{R}$. When a prediction is made, then the binary classification can either be correct or wrong, resulting in the following confusion matrix
% %
% \begin{equation}
%     \label{eqn:conf}
%   V_{c} = \begin{bmatrix}
% V_{TP} & V_{FP}\\
% V_{FN} & V_{TN}
% \end{bmatrix}. 
% \end{equation}
% %
% In terms of value, we expect $V_R$ to be the least significant in magnitude, slightly below zero, as it's only purpose is to account for the human cost incurred when a decision is deferred by the classifier. Further, $V_{w}$ should be far below zero, thus reducing overall value when a false prediction is made, as such a decision, whether FP or FN should be avoided. Finally, we expect $V_{c}$  to be positive, as a true prediction, whether TP or TN, increases overall value. For the system to be effective, it is key to disincentivize $g$ from just always making the prediction, regardless of confidence, which would happen if $V_{c} >> 0 \approx V_R > V_{w}$, where the value of a rejection is negligible and the value gained through a correct prediction greatly outweights the value lost through a false prediction.

% An important conclusion to be drawn from this approach is the fact that different models will perform better than others when accuracy is used as evaluation metric instead of value and vice versa. Thus, current state of the art models might be outperformed on the same data by other, less accurate models when value is chosen as the evaluation metric. Beyond this, when considering value, certain models can also outperform others at, for example, low thresholds but fail to do so at high ones.

\subsection{Value Factors in Hate Speech Detection}
%\subsubsection{Value Characteristics in Hate Speech Detection}
We denote the value of classifying a data item correctly, or incorrectly, and that of rejecting a classification as ${V}_{c}$, ${V}_{w}$, and $V_r$, respectively. We make the following observations when considering value for hate speech detection: 1) Value is dependent not only on the machine learning model but also on the specific context to which the model is applied. For example, an incorrect prediction in the medical domain potentially has a bigger impact than one in e-commerce. In a high-stakes domain, generally, we would assume ${V}_{c} > V_r > {V}_{w}$ and thus a correct machine decision saves the cost of human moderation and accelerates the decision-making process, while a rejection requires additional human intervention. 2) Value interpretations from different stakeholders can vary. In hate speech detection, for example, a rejection of a machine decision induces the cost of human moderation from the business perspective, while from the user perspective what is more important is the exposure to hateful content. In our study, we choose to take the user's standpoint, and, as such, view $V_r$ to come with an inherent cost since human moderation will be pending and the potentially hateful content will remain visible. 3) Value is affected by both stakeholder expectations and regulation.
%
For example, in the hate speech detection case, when hateful content is posted, from the user's perspective, the value derived from a correct machine decision depends on the user's general expectation of how hateful content should be handled. Similarly, the legality of hate speech in certain jurisdictions may influence stakeholder perception.
%
%If the expectation is that generally, the platform takes no action, then a correct machine decision would be highly appreciated, hence it comes with a high value; otherwise 
%If users generally expect that hateful content can be detected and removed by the platform, then a correct machine decision has less value -- though the value should still be higher than zero since automation accelerates decision making.%, compared to the baseline of human moderation that takes time. 
%

%Regarding regulation, when legal requirements are in place, the value of correct machine decisions will be less appreciated while incorrect ones may be penalized. 


%\subsubsection{Calculation of Total Value}
Given the above observations, we now introduce the function to determine the total value, $V(\tau)$, of a given model with a reject option at the rejection threshold $\tau$ on a given dataset. Assuming that when accepted, correct decisions increase the overall value and when rejected, they decrease the overall value and vice versa, then, $V(\tau)$ may be formalized as: %We extended the work of~\citet{de2000reject} by introducing a $V(\tau)$ that measures the total value of the model and is based on the crowdsourced values of TP, TN, FP, FN, and rejected predictions.
%
\begin{align}
    \label{for:final-V}
    V(\tau) = \sum_{p} (V_p - V_r)N_p + \sum_{q} (V_r - V_q)N_{q},
\end{align}
where $p \in [TP, TN, FP, FN]$, $q \in [TP, TN, FP, FN]$, and $N_p$ and $N_q$ are the number of accepted and rejected data items for the difference scenarios, respectively. Note, that we assume that rejected decisions have a cost that decreases the overall value, i.e., $V_r$ is negative, as users have to wait on a moderation decision. Thus,~\cref{for:final-V} allows us to summarize the value gained and the cost subtracted into a single value for the model by considering the value or cost of each scenario and how often it occurs, while also taking the cost of rejection into account.

%, while accepted predictions save the cost of rejections and therefore increase value. %Here, we take a middle ground standpoint without assuming a baseline expectation of user perception to machine decisions or rejections, considering the relativity of value. 

% The above formulation has several nice properties. If we formalise our considerations so far in terms of the roles of correct, incorrect decisions, and rejections on the overall value a model delivers, we have the following:
% \begin{subequations}
% \label{for:conditions}
% \begin{align}
%     \frac{\partial V}{\partial N_{tp}^p} + \frac{\partial V}{\partial N_{tn}^p} &> 0 , &\quad
%     \frac{\partial V}{\partial N_{tp}^q} + \frac{\partial V}{\partial N_{tn}^q} &< 0 \label{for:conditions-tp-tn},\\
%     \frac{\partial V}{\partial N_{fp}^q} + \frac{\partial V}{\partial N_{fn}^q} &> 0, &\quad
%     \frac{\partial V}{\partial N_{fp}^p} + \frac{\partial V}{\partial N_{fn}^p} &< 0 \label{for:conditions-fp-fn},
% \end{align}
% \end{subequations}
% We can derive that all the above conditions are satisfied given Equation~\ref{for:final-V}, under an extra condition that $(V_{fp} + V_{fn})/2 < V_r$. This final condition says that the average value of false positive and false negative decisions should always be lower than the value of a rejection, which is not a strict condition since otherwise adopting the reject option serves no purpose. 

% %
% where $N$ is the number of accepted predictions and $N_r,o$ is the number of predictions that were rejected (but would have been $o \in [$TP, TN, FP, or FN$]$).
% %
% We create a linear $V(\tau)$ function and assume that the values are constants. Subsequently, we can formulate $V(\tau)$ as:
% % \begin{multline}
% %     \label{for:final-V}
% %     V = (V_{tp} + V_r)N_{tp} + (V_{tn} + V_r)N_{tn}\\
% %     + (V_r - V_{fp})N_{fp} +  (V_r - V_{fn})N_{fn}\\
% %     - (V_r + V_{tp})N_{r, tp} - (V_r + V_{tn})N_{r, tn}\\
% %     + (V_{fp} - V_r)N_{r, fp} + (V_{fn} - V_r)N_{r, fn}\\
% % \end{multline}
% \begin{align}
%     \label{for:final-V}
%     V = \sum_{i} (V_i - V_r)N_i + \sum_{j} (V_r - V_j)N_{r, j},
% \end{align}
% where $i, j \in [$TP, TN, FP, FN$]$.
% %
% We assume that $V_{fp}$, $V_{fn}$, and $V_r$ are negative (costs) and $V_{tp}$ and $V_{tn}$ are positive (gains). 
% %
% Therefore,~\cref{for:conditions-tp-tn} is satisfied and~\cref{for:conditions-fp-fn} is satisfied due to~\cref{for:value-condition}.
% %
% We can now use~\cref{for:final-V} to calculate the total value $V$ for for all possible threshold ($\tau$) values. The optimal rejection threshold is equal to the $\tau$ value for which we achieve the maximum value of $V(\tau)$.

% =========================
% We use a confidence metric to calculate the theoretical rejection threshold for which the total value, when incorporating the reject option, is maximized. \citet{de2000reject} developed a confidence metric that calculates this threshold for any classification model based on the values of correct, incorrect, and rejected predictions on a set of predictions for some test dataset. In this work, we extended their metric by calculating the optimal threshold based on the values of TP, TN, FP, FN, and rejected predictions. Our metric measures the total value of the model including the reject option, while the metric from \citet{de2000reject} measures the effectiveness of the reject option only.

% The goal of the reject option using a confidence metric is to calculate the optimal threshold where we accept predictions for which $c$ is above $\tau$ and reject predictions for which this is not true. Here, we derive a value function $V$, that measures how effective the model is with the reject option. Therefore, we can express $V$ as:
% % 
% \begin{multline}
%     V = V(V_{TP}, R_{TP}, V_{TN}, R_{TN}, V_{FP}, R_{FP}, V_{FN}, R_{FN},\\
%     V_R, R_R),
% \end{multline}
% % 
% where $V_t$ defines the value of a prediction of type $t$, which denotes all possible classes if a prediction is made $t \in [TP, TN, FP, FN]$. $R_t$ defines the percentage of accepted predictions of type $t$ and $R_R$ is the percentage of all rejected predictions. %All values of $V_t$ should be positive, but we interpret $V_{TP}$ and $V_{TN}$ as gains and $V_{FP}$, $V_{FN}$, and $V_R$ as costs. 
% There is one condition that needs to hold: the reduction of total value by means of a rejection should always be smaller in magnitude than the value reduction of an incorrect prediction, otherwise adopting the reject option serves no purpose. This can be formulated as:
% % 
% \begin{align}
%     \label{for:value-condition}
%     V_R < \frac{V_{FP} + V_{FN}}{2},
% \end{align}
% %
% For each $\tau$ value between 0 (accepting all predictions) and 1 (rejecting all predictions), we would like to know whether the model with the reject option is more effective (increased $V$) or less effective (decreased $V$ value). Therefore, the metric needs to take the following conditions into account:
% % 
% \begin{enumerate}
%     \item Correct accepted predictions should increase the value of $V$, while incorrect accepted should decrease the value of $V$.
%     \item Correct rejected predictions should decrease the value of $V$, while incorrect rejected predictions should increase the value of $V$.
%     \item Rejected predictions have a cost as well and should therefore decrease $V$, while accepted predictions saved us the cost of rejections and, therefore, should increase the value of $V$, provided that they are correct.
% \end{enumerate}
% % 
% We can convert these into the following equations:
% \begin{subequations}
% \label{for:conditions}
% \begin{align}
%     \frac{\partial V}{\partial R_{TP}} + \frac{\partial V}{\partial R_{TN}} > 0 \label{for:condition1},\\
%     \frac{\partial V}{\partial R_R^{TP}} + \frac{\partial V}{\partial R_R^{TN}} < 0 \label{for:condition2},\\
%     \frac{\partial V}{\partial R_R^{FP}} + \frac{\partial V}{\partial R_R^{FN}} > 0 \label{for:condition3},\\
%     \frac{\partial V}{\partial R_{FP}} + \frac{\partial V}{\partial R_{FN}} < 0 \label{for:condition4},
% \end{align}
% \end{subequations}
% \iffalse
% We can verify that $V$ satisfies the conditions in \cref{for:conditions}:
% \begin{align*}
%     \frac{\partial V}{\partial R_{TP}} + \frac{\partial V}{\partial R_{TP}} &> 0 \\
%     V_{TP} + V_{TN} + 2V_R &> 0\\
%     \\
%     \frac{\partial V}{\partial R_R^{TP}} + \frac{\partial V}{\partial R_R^{TN}} &< 0 \\
%     -V_{TP} - V_{TN} - 2V_R &< 0\\
%     \\
%     \frac{\partial V}{\partial R_R^{FP}} + \frac{\partial V}{\partial R_R^{FN}} &> 0 \\
%     V_{FP} + V_{FN} - 2V_R &> 0\\
%     \\
%     \frac{\partial V}{\partial R_{FP}} + \frac{\partial V}{\partial R_{FN}} &< 0 \\
%     2V_R -V_{FP} - V_{FN} &< 0
% \end{align*}
% \fi %
% where $R_R = R_R^{TP} + R_R^{TN} + R_R^{FP} + R_R^{FN}$ and $R_R^t$ is the percentage of rejected predictions of type $t$. \Cref{for:condition1} and \cref{for:condition2} are satisfied by default and \cref{for:condition3} and \cref{for:condition4} are satisfied since we know that $2V_R < V_{FP} + V_{FN}$.
% \iffalse
% We create a linear $V$ function and assume that the values $V_t$ are constants. Subsequently, we can formulate $V$ as:
% \begin{align}
%     \begin{split}
%         V ={}& V_{TP}R_{TP} + V_{TN}R_{TN} - V_{FP}R_{FP} - V_{FN}R_{FN}\\
%         & - V_{TP}R_R^{TP} - V_{TN}R_R^{TN} + V_{FP}R_R^{FP} + V_{FN}R_R^{FN}\\
%         & - V_R(R_R^{TP} + R_R^{TN} + R_R^{FP} + R_R^{FN})\\
%         & + V_R(R_{TP} + R_{TN} + R_{FP} + R_{FN})
%     \end{split}
% \end{align}
% \fi % 
% We can rewrite the value equation as:
% \begin{multline}
%     \label{for:initial-V}
%     V = (V_{TP} + V_R)R_{TP} + (V_{TN} + V_R)R_{TN}\\
%     + (V_R - V_{FP})R_{FP} +  (V_R - V_{FN})R_{FN}\\
%     - (V_R + V_{TP})R_R^{TP} - (V_R + V_{TN})R_R^{TN}\\
%     + (V_{FP} - V_R)R_R^{FP} + (V_{FN} - V_R)R_R^{FN}\\
% \end{multline}
% % 
% We can define the $R_t$ and the $R_R^t$ values by computing the integrals over the probability density functions (PDF) of the confidence values of the predictions with type $t \in [TP, TN, FP, FN]$ \cite{de2000reject}. We can define $R^t_R$ by taking the integral over the interval $[0, \tau]$, where $\tau$ is the rejection threshold, and $R_t$ by taking the integral over the interval $[\tau, 1]$:
% %
% \begin{align}
%     \label{for:R}
%     \begin{aligned}
%         R_R^{TP}(\tau) &= \int_0^\tau D_{TP}(x)dx & R_R^{TN}(\tau) &= \int_0^\tau D_{TN}(x)dx\\
%         R_R^{FP}(\tau) &= \int_0^\tau D_{FP}(x)dx & R_R^{FN}(\tau) &= \int_0^\tau D_{FN}(x)dx\\
%         R_{TP}(\tau) &= \int_\tau^1 D_{TP}(x)dx & R_{TN}(\tau) &= \int_\tau^1 D_{TN}(x)dx\\
%         R_{FP}(\tau) &= \int_\tau^1 D_{FP}(x)dx & R_{FN}(\tau) &= \int_\tau^1 D_{FN}(x)dx
%     \end{aligned}
% \end{align}
% %
% Therefore, we should define $V$ as a function of the threshold value $\tau$. By inserting the integrals from \cref{for:R} into \cref{for:initial-V}, we get the final value function:
% %
% \begin{align}
%     \label{for:final-V}
%     \begin{split}
%         V(\tau) &= (V_{TP} + V_{REJ})\int_\tau^1 D_{TP}(x)dx\\
%         & + (V_{TN} + V_{REJ})\int_\tau^1 D_{TN}(x)dx\\
%         & + (V_{REJ} - V_{FP})\int_\tau^1 D_{FP}(x)dx\\
%         & + (V_{REJ} - V_{FN})\int_\tau^1 D_{FN}(x)dx\\
%         & - (V_{REJ} + V_{TP})\int_0^\tau D_{TP}(x)dx\\
%         & - (V_{REJ} + V_{TN})\int_0^\tau D_{TN}(x)dx\\
%         & + (V_{FP} - V_{REJ})\int_0^\tau D_{FP}(x)dx\\
%         & + (V_{FN} - V_{REJ})\int_0^\tau D_{FN}(x)dx\\
%     \end{split}
% \end{align}
% %
% We can now use \cref{for:final-V} to calculate the total value $m$ with the reject option for all possible threshold ($\tau$) values. The theoretical optimal rejection threshold is equal to the $\tau$ value for which we achieve the maximum value of $V(\tau)$.













