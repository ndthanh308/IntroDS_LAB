\section{Conclusions}
\label{sec:conclusion}

This paper studies the operationalization and integration of value into human-AI collaboration for hate speech detection. We introduce a value-sensitive rejection mechanism for machine decisions that takes into account the implications of decisions from a user-centered standpoint. We propose 
ME to measure users' value perception regarding different hate speech detection scenarios. To validate ME, we design a survey study, showing that it can provide a reliable, human-centered assessment of the value a machine learning model delivers. Our survey study uncovers a series of interesting findings on user perception. In particular, participants appreciate correct decisions made by the platform, while they show a strong consensus over the harm of incorrect decisions. 
%To demonstrate the utility of value assessment in human-AI collaboration, we experimented with state-of-the-art hate speech detection models on real-world datasets. 
Our results show that value assessment performed by means of ME can guide us to select the best confidence threshold for rejecting machine decisions, thereby maximizing model value and potentially leading to a different best model than when using accuracy.
% The results indicate a discrepancy between the general practice in machine learning assessment and the actual value a model can provide in a specific context. 

% how a value-sensitive smart rejector allows us to take the implications of machine decisions into account when evaluating them.
% %
% We find that Magnitude Estimation can be used for collecting participants' opinions regarding different hate speech detection scenarios while providing reliable results.
% %
% We propose a method for evaluating the value of machine learning models using the values of true positive, true negative, false positive, false negative, and rejected predictions.
% %
% Beyond this, we show that the total value of a machine learning model with a rejector can be formulated by considering users' perspectives towards instances of hate speech. 
%
%\color{red}
% Specifically, when running the model on the test set of a similar source, the rejector shows promising results and the total value for each model used can be maximized through the use of it. 
% %\color{black}
% %\ych{Please check if this red-marked sentence is correct.}
% %
% %Under no circumstances does the rejector reduce total value.
% %
% Our value-sensitive approach, therefore, has the potential to improve user experiences and reduce harm in the context of social media platforms.