{
  "2207-10050": {
    "title": "Discriminator-Weighted Offline Imitation Learning from Suboptimal Demonstrations",
    "authors": [
      "Haoran Xu",
      "Xianyuan Zhan"
    ],
    "submission_date": "2022-07-20",
    "semantic_scholar_id": "5c9a3e399ab79877eeacb4f33bda006690bbe398"
  },
  "2206-07568": {
    "title": "Contrastive Learning as Goal-Conditioned Reinforcement Learning",
    "authors": [
      "Benjamin Eysenbach",
      "Tianjun Zhang",
      "R. Salakhutdinov",
      "S. Levine"
    ],
    "submission_date": "2022-06-15",
    "semantic_scholar_id": "53dcf467fbded741dd08902d4203a9b57e889c87"
  },
  "2203-12601": {
    "title": "R3M: A Universal Visual Representation for Robot Manipulation",
    "authors": [
      "Suraj Nair",
      "A. Rajeswaran",
      "Vikash Kumar",
      "Chelsea Finn",
      "Abhi Gupta"
    ],
    "submission_date": "2022-03-23",
    "semantic_scholar_id": "c9bdc9ad2c3cf3230ba9aac7b5783ab411f0d204"
  },
  "2202-01741": {
    "title": "How to Leverage Unlabeled Data in Offline Reinforcement Learning",
    "authors": [
      "Tianhe Yu",
      "Aviral Kumar",
      "Yevgen Chebotar",
      "Karol Hausman",
      "Chelsea Finn",
      "S. Levine"
    ],
    "submission_date": "2022-02-03",
    "semantic_scholar_id": "5b37ecab1039b50102fac9e11dd02b0158ef742c"
  },
  "2107-07184": {
    "title": "MURAL: Meta-Learning Uncertainty-Aware Rewards for Outcome-Driven Reinforcement Learning",
    "authors": [
      "Kevin Li",
      "Abhishek Gupta",
      "Ashwin Reddy",
      "Vitchyr H. Pong",
      "Aurick Zhou",
      "Justin Yu",
      "S. Levine"
    ],
    "submission_date": "2021-07-15",
    "semantic_scholar_id": "6382bec2c2fd18d388483653409b1a18048521da"
  },
  "2106-08909": {
    "title": "Offline RL Without Off-Policy Evaluation",
    "authors": [
      "David Brandfonbrener",
      "William F. Whitney",
      "R. Ranganath",
      "Joan Bruna"
    ],
    "submission_date": "2021-06-16",
    "semantic_scholar_id": "a3b82f4fc10caf6243afbd77c9c990ce03ae36d1"
  },
  "2106-06860": {
    "title": "A Minimalist Approach to Offline Reinforcement Learning",
    "authors": [
      "Scott Fujimoto",
      "S. Gu"
    ],
    "submission_date": "2021-06-12",
    "semantic_scholar_id": "c879b25308026d6538e52b27bcf4fd3cb60855f3"
  },
  "2106-05068": {
    "title": "Offline Inverse Reinforcement Learning",
    "authors": [
      "Firas Jarboui",
      "Vianney Perchet"
    ],
    "submission_date": "2021-06-09",
    "semantic_scholar_id": "97b5623306afe19757946c7bc449277981c9e335"
  },
  "2104-08212": {
    "title": "MT-Opt: Continuous Multi-Task Robotic Reinforcement Learning at Scale",
    "authors": [
      "Dmitry Kalashnikov",
      "Jacob Varley",
      "Yevgen Chebotar",
      "Benjamin Swanson",
      "Rico Jonschkowski",
      "Chelsea Finn",
      "S. Levine",
      "Karol Hausman"
    ],
    "submission_date": "2021-04-16",
    "semantic_scholar_id": "3e85d208b1b927fdb69ecf8336c70995818aaebd"
  },
  "2103-16817": {
    "title": "Learning Generalizable Robotic Reward Functions from \"In-The-Wild\" Human Videos",
    "authors": [
      "Annie S. Chen",
      "Suraj Nair",
      "Chelsea Finn"
    ],
    "submission_date": "2021-03-31",
    "semantic_scholar_id": "b3efeb1a8e44b4ba4476d3e7bf83cf0cb9682291"
  },
  "2103-12656": {
    "title": "Replacing Rewards with Examples: Example-Based Policy Search via Recursive Classification",
    "authors": [
      "Benjamin Eysenbach",
      "S. Levine",
      "R. Salakhutdinov"
    ],
    "submission_date": "2021-03-23",
    "semantic_scholar_id": "07283c33464eb4f56a13caeb52cb2f9b988557b3"
  },
  "2103-08050": {
    "title": "Offline Reinforcement Learning with Fisher Divergence Critic Regularization",
    "authors": [
      "Ilya Kostrikov",
      "Jonathan Tompson",
      "R. Fergus",
      "Ofir Nachum"
    ],
    "submission_date": "2021-03-14",
    "semantic_scholar_id": "362cc80481b288874af0428107ab31e955dcf09f"
  },
  "2103-06326": {
    "title": "S4RL: Surprisingly Simple Self-Supervision for Offline Reinforcement Learning",
    "authors": [
      "Samarth Sinha",
      "Animesh Garg"
    ],
    "submission_date": "2021-03-10",
    "semantic_scholar_id": "30256fd41d471e8c6731c732e41ba865321ced7d"
  },
  "2102-08363": {
    "title": "COMBO: Conservative Offline Model-Based Policy Optimization",
    "authors": [
      "Tianhe Yu",
      "Aviral Kumar",
      "Rafael Rafailov",
      "A. Rajeswaran",
      "S. Levine",
      "Chelsea Finn"
    ],
    "submission_date": "2021-02-16",
    "semantic_scholar_id": "245682e8b3fa76f4a3e2991b5497577af95cbb3f"
  },
  "2102-02872": {
    "title": "Feedback in Imitation Learning: The Three Regimes of Covariate Shift",
    "authors": [
      "Jonathan Spencer",
      "Sanjiban Choudhury",
      "Arun Venkatraman",
      "Brian D. Ziebart",
      "J. Bagnell"
    ],
    "submission_date": "2021-02-04",
    "semantic_scholar_id": "1eae98b0c9c6ccd9044db332e63eadf01cb1fa23"
  },
  "2012-11547": {
    "title": "Offline Reinforcement Learning from Images with Latent Space Models",
    "authors": [
      "Rafael Rafailov",
      "Tianhe Yu",
      "A. Rajeswaran",
      "Chelsea Finn"
    ],
    "submission_date": "2020-12-21",
    "semantic_scholar_id": "c32a6fc742b927e72ed496743a8dcf9ca1cc415c"
  },
  "2012-06899": {
    "title": "Semi-supervised reward learning for offline reinforcement learning",
    "authors": [
      "Ksenia Konyushkova",
      "Konrad Zolna",
      "Y. Aytar",
      "Alexander Novikov",
      "Scott E. Reed",
      "Serkan Cabi",
      "Nando de Freitas"
    ],
    "submission_date": "2020-12-12",
    "semantic_scholar_id": "1eecf98de4024893bb51ed2e26b9d186e305c519"
  },
  "2011-13885": {
    "title": "Offline Learning from Demonstrations and Unlabeled Experience",
    "authors": [
      "Konrad Zolna",
      "Alexander Novikov",
      "Ksenia Konyushkova",
      "Caglar Gulcehre",
      "Ziyun Wang",
      "Y. Aytar",
      "Misha Denil",
      "Nando de Freitas",
      "Scott E. Reed"
    ],
    "submission_date": "2020-11-27",
    "semantic_scholar_id": "23472dde7735dbe88b300662a0421aca52692075"
  },
  "2011-07213": {
    "title": "PLAS: Latent Action Space for Offline Reinforcement Learning",
    "authors": [
      "Wenxuan Zhou",
      "Sujay Bajracharya",
      "David Held"
    ],
    "submission_date": "2020-11-14",
    "semantic_scholar_id": "cff6566e92e71c8fcc5cfa5d16eef34e95b1a1f3"
  },
  "2010-14500": {
    "title": "COG: Connecting New Skills to Past Experience with Offline Reinforcement Learning",
    "authors": [
      "Avi Singh",
      "Albert Yu",
      "Jonathan Yang",
      "Jesse Zhang",
      "Aviral Kumar",
      "S. Levine"
    ],
    "submission_date": "2020-10-27",
    "semantic_scholar_id": "f204041dd567025217adc8070ca292e89cc80488"
  },
  "2008-05533": {
    "title": "Overcoming Model Bias for Robust Offline Deep Reinforcement Learning",
    "authors": [
      "Phillip Swazinna",
      "S. Udluft",
      "T. Runkler"
    ],
    "submission_date": "2020-08-12",
    "semantic_scholar_id": "124b683a6f0f8ac8e13e204dfcd30a5497ab581d"
  },
  "2008-05556": {
    "title": "Model-Based Offline Planning",
    "authors": [
      "Arthur Argenson",
      "Gabriel Dulac-Arnold"
    ],
    "submission_date": "2020-08-12",
    "semantic_scholar_id": "3cb8e96faba73efa027fa858e2a78cd1fc3c6e4d"
  },
  "2007-11091": {
    "title": "EMaQ: Expected-Max Q-Learning Operator for Simple Yet Effective Offline and Online RL",
    "authors": [
      "Seyed Kamyar Seyed Ghasemipour",
      "D. Schuurmans",
      "S. Gu"
    ],
    "submission_date": "2020-07-21",
    "semantic_scholar_id": "fa7f88f77de02ae9389e514a1cd13083a624ec78"
  },
  "2007-08202": {
    "title": "Provably Good Batch Reinforcement Learning Without Great Exploration",
    "authors": [
      "Yao Liu",
      "Adith Swaminathan",
      "Alekh Agarwal",
      "E. Brunskill"
    ],
    "submission_date": "2020-07-16",
    "semantic_scholar_id": "49b9f1f108729aaba4d69d0c145390b76603188f"
  },
  "2006-07217": {
    "title": "Deep Reinforcement and InfoMax Learning",
    "authors": [
      "Bogdan Mazoure",
      "Rémi Tachet des Combes",
      "T. Doan",
      "Philip Bachman",
      "R. Devon Hjelm"
    ],
    "submission_date": "2020-06-12",
    "semantic_scholar_id": "27a7df880e9c4ccd87cb88cccb131e2b4687567f"
  },
  "2006-04779": {
    "title": "Conservative Q-Learning for Offline Reinforcement Learning",
    "authors": [
      "Aviral Kumar",
      "Aurick Zhou",
      "G. Tucker",
      "S. Levine"
    ],
    "submission_date": "2020-06-08",
    "semantic_scholar_id": "28db20a81eec74a50204686c3cf796c42a020d2e"
  },
  "2006-03647": {
    "title": "Deployment-Efficient Reinforcement Learning via Model-Based Offline Optimization",
    "authors": [
      "T. Matsushima",
      "Hiroki Furuta",
      "Y. Matsuo",
      "Ofir Nachum",
      "S. Gu"
    ],
    "submission_date": "2020-06-05",
    "semantic_scholar_id": "79ebde314ab90d066cee3b82193ef05666323394"
  },
  "2006-00979": {
    "title": "Acme: A Research Framework for Distributed Reinforcement Learning",
    "authors": [
      "Matthew W. Hoffman",
      "Bobak Shahriari",
      "John Aslanides",
      "Gabriel Barth-Maron",
      "Feryal M. P. Behbahani",
      "Tamara Norman",
      "A. Abdolmaleki",
      "Albin Cassirer",
      "Fan Yang",
      "Kate Baumli",
      "Sarah Henderson",
      "Alexander Novikov",
      "Sergio Gomez Colmenarejo",
      "Serkan Cabi",
      "Caglar Gulcehre",
      "T. Paine",
      "A. Cowie",
      "Ziyun Wang",
      "Bilal Piot",
      "Nando de Freitas"
    ],
    "submission_date": "2020-06-01",
    "semantic_scholar_id": "2e1ac521d53e09e90fd9b4bf949f667d756853de"
  },
  "2005-13239": {
    "title": "MOPO: Model-based Offline Policy Optimization",
    "authors": [
      "Tianhe Yu",
      "G. Thomas",
      "Lantao Yu",
      "Stefano Ermon",
      "James Y. Zou",
      "S. Levine",
      "Chelsea Finn",
      "Tengyu Ma"
    ],
    "submission_date": "2020-05-27",
    "semantic_scholar_id": "dea0f1c5949f8d898b9b6ff68226a781558e413c"
  },
  "2005-05951": {
    "title": "MOReL : Model-Based Offline Reinforcement Learning",
    "authors": [
      "Rahul Kidambi",
      "A. Rajeswaran",
      "Praneeth Netrapalli",
      "T. Joachims"
    ],
    "submission_date": "2020-05-12",
    "semantic_scholar_id": "309c2c5ee60e725244da09180f913cd8d4b8d4e9"
  },
  "2005-01643": {
    "title": "Offline Reinforcement Learning: Tutorial, Review, and Perspectives on Open Problems",
    "authors": [
      "S. Levine",
      "Aviral Kumar",
      "G. Tucker",
      "Justin Fu"
    ],
    "submission_date": "2020-05-04",
    "semantic_scholar_id": "5e7bc93622416f14e6948a500278bfbe58cd3890"
  },
  "2004-12570": {
    "title": "The Ingredients of Real-World Robotic Reinforcement Learning",
    "authors": [
      "Henry Zhu",
      "Justin Yu",
      "Abhishek Gupta",
      "Dhruv Shah",
      "Kristian Hartikainen",
      "Avi Singh",
      "Vikash Kumar",
      "S. Levine"
    ],
    "submission_date": "2020-04-27",
    "semantic_scholar_id": "2d85f63a193cd88741c8398ceb98c55e1e89387d"
  },
  "2004-10190": {
    "title": "Efficient Adaptation for End-to-End Vision-Based Robotic Manipulation",
    "authors": [
      "Ryan C. Julian",
      "Benjamin Swanson",
      "G. Sukhatme",
      "S. Levine",
      "Chelsea Finn",
      "Karol Hausman"
    ],
    "submission_date": "2020-04-21",
    "semantic_scholar_id": "9d9fcaaaafa97b3239a78ea086e04ac8545e9f03"
  },
  "2002-08396": {
    "title": "Keep Doing What Worked: Behavioral Modelling Priors for Offline Reinforcement Learning",
    "authors": [
      "Noah Siegel",
      "Jost Tobias Springenberg",
      "Felix Berkenkamp",
      "A. Abdolmaleki",
      "M. Neunert",
      "Thomas Lampe",
      "Roland Hafner",
      "Martin A. Riedmiller"
    ],
    "submission_date": "2020-02-19",
    "semantic_scholar_id": "0881655dcdf891f529ebe7ac18301e138a5e265b"
  },
  "1911-05321": {
    "title": "IRIS: Implicit Reinforcement without Interaction at Scale for Learning Control from Offline Robot Manipulation Data",
    "authors": [
      "Ajay Mandlekar",
      "Fabio Ramos",
      "Byron Boots",
      "Li Fei-Fei",
      "Animesh Garg",
      "D. Fox"
    ],
    "submission_date": "2019-11-13",
    "semantic_scholar_id": "5e9764f45e7ea6206594deb94753a5cad4e31a1a"
  },
  "1911-00459": {
    "title": "Positive-Unlabeled Reward Learning",
    "authors": [
      "Danfei Xu",
      "Misha Denil"
    ],
    "submission_date": "2019-11-01",
    "semantic_scholar_id": "fcb4d00462eefa53a496b45acb87fa0d258d3500"
  },
  "1910-10897": {
    "title": "Meta-World: A Benchmark and Evaluation for Multi-Task and Meta Reinforcement Learning",
    "authors": [
      "Tianhe Yu",
      "Deirdre Quillen",
      "Zhanpeng He",
      "Ryan C. Julian",
      "Karol Hausman",
      "Chelsea Finn",
      "S. Levine"
    ],
    "submission_date": "2019-10-24",
    "semantic_scholar_id": "0bc855f84668b35cb65618d996d09f6e434d28c9"
  },
  "1910-00177": {
    "title": "Advantage-Weighted Regression: Simple and Scalable Off-Policy Reinforcement Learning",
    "authors": [
      "Xue Bin Peng",
      "Aviral Kumar",
      "Grace Zhang",
      "S. Levine"
    ],
    "submission_date": "2019-10-01",
    "semantic_scholar_id": "ad14227e4f51276892ffc37aa43fd8750bb5eba8"
  },
  "1909-12200": {
    "title": "A Framework for Data-Driven Robotics",
    "authors": [
      "Serkan Cabi",
      "Sergio Gomez Colmenarejo",
      "Alexander Novikov",
      "Ksenia Konyushkova",
      "Scott E. Reed",
      "Rae Jeong",
      "Konrad Zolna",
      "Y. Aytar",
      "D. Budden",
      "Mel Vecerík",
      "Oleg O. Sushkov",
      "David Barker",
      "Jonathan Scholz",
      "Misha Denil",
      "Nando de Freitas",
      "Ziyun Wang"
    ],
    "submission_date": "2019-09-26",
    "semantic_scholar_id": "cac78ad6696d6b6370942679f7d0e4425ef4b3e7"
  },
  "1910-01077": {
    "title": "Task-Relevant Adversarial Imitation Learning",
    "authors": [
      "Konrad Zolna",
      "Scott E. Reed",
      "Alexander Novikov",
      "Sergio Gomez Colmenarejo",
      "D. Budden",
      "Serkan Cabi",
      "Misha Denil",
      "Nando de Freitas",
      "Ziyun Wang"
    ],
    "submission_date": "2019-09-25",
    "semantic_scholar_id": "2542f383c4002f7e523e1bf44caaea6d68beaee6"
  },
  "1911-11361": {
    "title": "Behavior Regularized Offline Reinforcement Learning",
    "authors": [
      "Yifan Wu",
      "G. Tucker",
      "Ofir Nachum"
    ],
    "submission_date": "2019-09-25",
    "semantic_scholar_id": "9be492858863c8c7c24be1ecb75724de5086bd8e"
  },
  "1907-00456": {
    "title": "Way Off-Policy Batch Deep Reinforcement Learning of Implicit Human Preferences in Dialog",
    "authors": [
      "Natasha Jaques",
      "Asma Ghandeharioun",
      "Judy Hanwen Shen",
      "Craig Ferguson",
      "Àgata Lapedriza",
      "Noah J. Jones",
      "S. Gu",
      "Rosalind W. Picard"
    ],
    "submission_date": "2019-06-30",
    "semantic_scholar_id": "57daffd65a5d73a439903f3e50950c21c9eba687"
  },
  "1906-00949": {
    "title": "Stabilizing Off-Policy Q-Learning via Bootstrapping Error Reduction",
    "authors": [
      "Aviral Kumar",
      "Justin Fu",
      "G. Tucker",
      "S. Levine"
    ],
    "submission_date": "2019-06-03",
    "semantic_scholar_id": "82b4b03a4659d6e04bd7cbf51d6e08fde1348dbd"
  },
  "1904-07854": {
    "title": "End-to-End Robotic Reinforcement Learning without Reward Engineering",
    "authors": [
      "Avi Singh",
      "Larry Yang",
      "Kristian Hartikainen",
      "Chelsea Finn",
      "S. Levine"
    ],
    "submission_date": "2019-04-16",
    "semantic_scholar_id": "00a5cdb5768fdfabfa9decad28271afde9880579"
  },
  "1812-02900": {
    "title": "Off-Policy Deep Reinforcement Learning without Exploration",
    "authors": [
      "Scott Fujimoto",
      "D. Meger",
      "Doina Precup"
    ],
    "submission_date": "2018-12-07",
    "semantic_scholar_id": "5285cb8faada5de8a92a47622950f6cfd476ac1d"
  },
  "1810-00482": {
    "title": "Few-Shot Goal Inference for Visuomotor Learning and Planning",
    "authors": [
      "Annie Xie",
      "Avi Singh",
      "S. Levine",
      "Chelsea Finn"
    ],
    "submission_date": "2018-09-30",
    "semantic_scholar_id": "f0070a6e7345c3a703db308a55211b4bddae9c85"
  },
  "1809-01812": {
    "title": "Noise Contrastive Estimation and Negative Sampling for Conditional Models: Consistency and Statistical Efficiency",
    "authors": [
      "Zhuang Ma",
      "Michael Collins"
    ],
    "submission_date": "2018-09-01",
    "semantic_scholar_id": "ac61568c081c03730c58bd34c023a6952803da13"
  },
  "1806-10293": {
    "title": "QT-Opt: Scalable Deep Reinforcement Learning for Vision-Based Robotic Manipulation",
    "authors": [
      "Dmitry Kalashnikov",
      "A. Irpan",
      "P. Pastor",
      "Julian Ibarz",
      "Alexander Herzog",
      "Eric Jang",
      "Deirdre Quillen",
      "E. Holly",
      "Mrinal Kalakrishnan",
      "Vincent Vanhoucke",
      "S. Levine"
    ],
    "submission_date": "2018-06-27",
    "semantic_scholar_id": "eb37e7b76d26b75463df22b2a3aa32b6a765c672"
  },
  "1805-11686": {
    "title": "Variational Inverse Control with Events: A General Framework for Data-Driven Reward Definition",
    "authors": [
      "Justin Fu",
      "Avi Singh",
      "Dibya Ghosh",
      "Larry Yang",
      "S. Levine"
    ],
    "submission_date": "2018-05-01",
    "semantic_scholar_id": "36f7f407bbad234929c69c0dd3bdcfcd80298c7c"
  },
  "1802-09464": {
    "title": "Multi-Goal Reinforcement Learning: Challenging Robotics Environments and Request for Research",
    "authors": [
      "Matthias Plappert",
      "Marcin Andrychowicz",
      "Alex Ray",
      "Bob McGrew",
      "Bowen Baker",
      "Glenn Powell",
      "Jonas Schneider",
      "Joshua Tobin",
      "Maciek Chociej",
      "Peter Welinder",
      "Vikash Kumar",
      "Wojciech Zaremba"
    ],
    "submission_date": "2018-02-26",
    "semantic_scholar_id": "ce1c28ca2f52a42c6e60d792cd71ba894abc47d5"
  },
  "1710-11248": {
    "title": "Learning Robust Rewards with Adversarial Inverse Reinforcement Learning",
    "authors": [
      "Justin Fu",
      "Katie Luo",
      "S. Levine"
    ],
    "submission_date": "2017-10-30",
    "semantic_scholar_id": "5e2c4e7b3302549b3718601c44d9af6c7554efef"
  },
  "1707-01495": {
    "title": "Hindsight Experience Replay",
    "authors": [
      "Marcin Andrychowicz",
      "Dwight Crow",
      "Alex Ray",
      "Jonas Schneider",
      "Rachel Fong",
      "Peter Welinder",
      "Bob McGrew",
      "Joshua Tobin",
      "P. Abbeel",
      "Wojciech Zaremba"
    ],
    "submission_date": "2017-07-05",
    "semantic_scholar_id": "429ed4c9845d0abd1f8204e1d7705919559bc2a2"
  },
  "1606-03476": {
    "title": "Generative Adversarial Imitation Learning",
    "authors": [
      "Jonathan Ho",
      "Stefano Ermon"
    ],
    "submission_date": "2016-06-10",
    "semantic_scholar_id": "4ab53de69372ec2cd2d90c126b6a100165dc8ed1"
  },
  "1603-00448": {
    "title": "Guided Cost Learning: Deep Inverse Optimal Control via Policy Optimization",
    "authors": [
      "Chelsea Finn",
      "S. Levine",
      "P. Abbeel"
    ],
    "submission_date": "2016-03-01",
    "semantic_scholar_id": "04162cb8cfaa0f7e37586823ff4ad0bff09ed21d"
  },
  "1011-0686": {
    "title": "A Reduction of Imitation Learning and Structured Prediction to No-Regret Online Learning",
    "authors": [
      "Stéphane Ross",
      "Geoffrey J. Gordon",
      "J. Bagnell"
    ],
    "submission_date": "2010-11-02",
    "semantic_scholar_id": "79ab3c49903ec8cb339437ccf5cf998607fc313e"
  }
}