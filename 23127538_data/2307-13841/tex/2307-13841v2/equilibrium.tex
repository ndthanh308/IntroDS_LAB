\section{Analysis and Main Results} \label{sect_signaling_game}



In this section, we present the main results of our analysis. First, we define our solution concept, $\Delta$-\textit{rationalizability}, and proceed to derive the sets of rationalizable type-strategy profiles for the leader and the followers. Then, we identify a necessary 
and sufficient condition under which the model exhibits unique rationalizable behavior. Finally, we discuss our results and the analysis's implications for efficiency.

\medskip


\subsection{Rationalizable Behavior}
Our solution concept is $\Delta$-rationalizability of \cite{battigalli_siniscalchi_2003}, which extends \citeapos{pearce_1984} notion of extensive-form rationalizability to games with incomplete information.
The ``$\Delta$'' in $\Delta$-rationalizability indicates a specific set of restrictions on beliefs that are required to be satisfied at each round of the iterative procedure. In our case, it is the signal structure commonly known to all players. We will show that in general, the set of action-type pairs that are $\Delta$-rationalizable constitute an interval both for the leader and the followers unless the followers' information is sufficiently noisy. This result hinges on the possibility of ``knowledge traps'': more precise information on the followers' part induces multiplicity of  $\Delta$-rationalizable type-strategy profiles which can lead to serious inefficiencies.


% \subsubsection*{Actions, Strategies and Beliefs}

Before providing a formal definition of the procedure, we introduce the following notation. Recall that $\Action_L=\{\invest,\notinvest\}$ is the action set of the leader. To simplify notation, we also consider it to be the set of possible (non-terminal) histories of the game. We, therefore, let $a_L \in \Action_L$ denote the action chosen by the leader and $h \in \Action_L$ the corresponding history.
A strategy for follower $j \in F$ is a mapping, $s_j: \Action_L \to \Action_j$, that maps history $h$ into action $s_j(h)$.
Let $S_j$ be the set of strategies for follower $j$. The sets of all possible types of the leader and follower $j$ are $\Theta$ and $X_j$, respectively. We call $(\theta_L , a_L )\in \Theta \times \Action_L$ a type-strategy pair for the leader. Likewise, $(x_j , s_j)\in X_j \times S_j$ is a type-strategy pair for follower $j$.
Players' interim beliefs are conditional probabilities, derived from the Bayes' rule, about the type-strategy pairs of their opponents. Specifically, an interim belief of leader $\theta$ is $\mu_L (\cdot \vl \theta) \in \Delta \left(X \times S \right)$, 
where $X \times S = \prod_{j\in F} X_j \times S_j$
with a generic element $(x, s) = (x_j, s_j)_{j \in F}$, 
and the interim belief for follower $j$ given type $x_j$ and history $h$ is $\mu_j (\cdot \vl x_j,h) \in \Delta \left(\Theta \times \prod_{k \neq j} (X_{k}\times S_{k})\right)$.

 
For leader $\theta$, exerting effort, $a_L = \invest$, is the best response with respect to a belief $\mu_L(x, s \vl \theta)$
if
\[
\int_{(x, s)} u(\theta, A_{-L}(s))\dd \mu_L(x, s \vl \theta) > 0,
\]
where $A_{-L}(s(\invest)) = \sum_{j \in F} \one\left(s_j(\invest) = \invest \right)$.\footnote{~We assume, without loss of generality, that players break the tie by choosing not to exert effort.}
Similarly, for type $x_j$ of follower $j$ under history $h$, action $s_j(h) = \invest$ is the best response to a belief $\mu_j(\theta, x_{-j}, s_{-j} \vl x_j, h)$ if
\[
\int_{(\theta, x_{-j}, s_{-j})} u(\theta, A_{-j}(h, s_{-j}))\dd \mu_j(\theta, x_{-j}, s_{-j} \vl x_j, h) > 0,
\]
where $A_{-j}(h, s_{-j}(h)) = \chi_\invest  + \sum_{k \neq j,~k \in F} \one\left(s_k(h) = \invest \right)$ and $\chi_\invest = \one\left(h = \invest \right)$.\footnote{~Likewise, $\chi_\notinvest = \one(h = \notinvest)$.} The notion of $\Delta$-rationalizability is defined as follows.


\begin{definition}[$\Delta$-rationalizability]
Consider the following procedure.\\
(Round 0) Let $R_L^0 = \Theta \times \Action_L$ and $R_{F, \,j}^0 = X_j \times S_j$ for each $j \in F$. \\
(Round $k \geq 1$) Let $R_F^m = \prod_{j \in F} R_{F, \,j}^m$ and $R_{F, -j}^m = \prod_{\ell \neq j} R_{F, \ell}^m, m \in \{0\} \cup \NN$. Then
\begin{enumerate}
    \item[(i)] $(\theta, a_L) \in R_L^k$ if and only if $(\theta, a_L) \in R_L^{k-1}$ and there exists a belief $\mu_L(\cdot \vl \theta) \in \Delta(R_F^0)$ such that $\mu_L(R_F^{k-1} \vl \theta) = 1$ and $a_L$ is a best response with respect to $\mu_L(\cdot \vl \theta)$.
    
    \item[(ii)] For every follower $j \in F$, $(x_j, s_j) \in R_j^{k-1}$ if and only if $(x_j, s_j) \in R_j^{k-1}$ and for each history $h$ there exists a belief $\mu_j(\cdot \vl x_j, h) \in \Delta(R_L^0 \times R_{F, \,-j}^0)$ such that $\mu_j(R_L^k \times R_{F, \,-j}^{k-1} \vl x_j, h) = 1$ and $s_j(h)$ is a best response with respect to $\mu_j(\cdot \vl x_j, h)$.
\end{enumerate}
Finally, let $R_L^\infty = \bigcap_{k=0}^\infty R_L^k$ and $R_{F, \,j}^\infty = \bigcap_{k=0}^\infty R_{F, \,j}^k$. Then an action $a_L$ is $\Delta$-rationalizable for type $\theta$ of the leader if $(\theta, a_L) \in R_L^\infty$. Analogously, a strategy $s_j$ is $\Delta$-rationalizable for type $x_j$ of follower $j$ if $(x_j, s_j) \in R_{F, \,j}^\infty$.
\end{definition}


\subsubsection*{Follower Problem}
Consider type $x$ of follower $j \in F$. 
Suppose that he believes that the leader uses a monotone strategy with threshold $z \in \RR$; that is, $a_L = \invest$ for all $\theta > z$.
Therefore, type $x$'s interim belief about $\theta$ has a truncated Gaussian distribution with density
\begin{equation} \label{interim_belief}
    \psi^h(\theta; x, z) = \begin{cases}
    \frac{\frac{1}{\sigma_F}\phi\left(\frac{\theta - x}{\sigma_F}\right)}{1 - \Phi\left(\frac{z - x}{\sigma_F}\right)}\one(\theta > z) & \text{if $h = \invest$} \\
    ~ & ~ \\
    \frac{\frac{1}{\sigma_F}\phi\left(\frac{\theta - x}{\sigma_F}\right)}{\Phi\left(\frac{z - x}{\sigma_F}\right)}\one(\theta \leq z) & \text{if $h = \notinvest$}
    \end{cases},
\end{equation}
where $\phi(\cdot)$ and $\Phi(\cdot)$ denote the standard Gaussian density function (PDF) and cumulative distribution function (CDF), respectively.
Let $\Psi^h(\cdot; \,x, z)$ be the corresponding CDF under history $h$. 
We denote by $\lambda(x) = \phi(x)/\Phi(x)$ the \textit{reversed hazard rate}. Then 
type $x$'s expectation of $\theta$ can be written as
\begin{equation} \label{eq_expectation_of_theta}
    \EE_{\theta \sim \Psi^h(\cdot; \,x, z)}[\theta] = \begin{cases}
   x + \sigma_F \lambda \left(\frac{x - z}{\sigma_F}\right)  & \text{if $h = \invest$} \\
   ~ & ~ \\
   x - \sigma_F \lambda \left( \frac{z - x}{\sigma_F} \right) & \text{if $h = \notinvest$}
   \end{cases},
\end{equation}
which has the following properties.

\begin{lemma} \label{lemma_truncated_expectation}
The interim expectations $\EE_{\theta \sim \Psi^h(\cdot; \,x, z)}[\theta]$ are strictly increasing in $x$ and $z$. Moreover,
\begin{equation*}
    \lim_{x \to -\infty} \EE_{\theta \sim \Psi^h(\cdot; \,x, z)}[\theta] = \begin{cases}
    z & \text{if $h = \invest$} \\
    - \infty & \text{if $h = \notinvest$}
    \end{cases},
\end{equation*}
and
\begin{equation*}
    \lim_{x \to \infty} \EE_{\theta \sim \Psi^h(\cdot ; \,x, z)}[\theta] = \begin{cases}
    \infty & \text{if $h = \invest$} \\
    z & \text{if $h = \notinvest$}
    \end{cases}.
\end{equation*}
\end{lemma}

Now suppose further that follower $j$ believes that other followers are using monotone strategies with threshold $x_h$ under history $h$; that is, for any 
follower $\ell \neq j$ with type $x$, 
$s_\ell(h) = \invest$ if and only if $x > x_h$. This implies that, at a given state $\theta$, the probability that follower $j$ assigns to
$k$ other followers investing equals
$\left[1 - \Phi\left((x_h - \theta)/\sigma_F\right)\right]^k$, $k \in \{0, 1, \dots, n-1\}$. Therefore
follower $j$'s expected proportion of other players investing at state $\theta$ is
\begin{align*}
    A_{-j}(\theta) & = \sum_{k=0}^{n-1}  \binom{n-1}{k} \frac{k }{n} \left[1 - \Phi\left(\frac{x_h - \theta}{\sigma_F}\right)\right]^k \Phi\left(\frac{x_h - \theta}{\sigma_F}\right)^{n-1-k} +\frac{\chi_{\invest}}{n}\\
    & = \frac{n-1}{n}\left[\left(1 - \Phi\left(\frac{x_h - \theta}{\sigma_F}\right)\right) \right] + \frac{\chi_\invest}{n}.
\end{align*}
The second equality follows from
the binomial identity $\sum_{k=0}^{n-1} \binom{n-1}{k} k (1-q)^k q^{n-1-k} = (n-1)(1-q)$. Since the leader's action is observable, follower $j$ has certainty about receiving the network benefit $\chi_\invest/n$.
Thus, we may write the payoff to choosing $a_j =\invest$ for type $x$, under history $h$, as
\begin{equation} \label{follower_payoff}
   \pi_F^h(x; z, x_h) = \EE_{\theta \sim \Psi^h(\cdot; \,x, z)} \left[ \theta - \frac{n-1}{n} \Phi\left(\frac{x_h -\theta}{\sigma_F}\right)   \right] - \frac{\chi_\notinvest}{n}.
\end{equation}
We then have the next lemma.

\begin{lemma} \label{lemma_x_payoff}
The follower payoffs $\pi_F^h(x; z, x_h)$ are strictly increasing in $x$ and $z$, and are strictly decreasing in $x_h$. Moreover,
\begin{equation*}
    \lim_{x \to -\infty} \pi_F^h(x; z, x_h) = \begin{cases}
z - \frac{n-1}{n}\Phi\left( \frac{x_\invest - z}{\sigma_F} \right) & \text{if $h = \invest$} \\
-\infty & \text{if $h = \notinvest$}
\end{cases}
\end{equation*}
and
\begin{equation*}
    \lim_{x \to \infty} \pi_F^h(x; z, x_h) = \begin{cases}
\infty & \text{if $h = \invest$} \\
z - \frac{1}{n} + \frac{n-1}{n}\Phi\left( \frac{x_\notinvest - z}{\sigma_F} \right) & \text{if $h = \notinvest$}
\end{cases}.
\end{equation*}
\end{lemma}

\medskip
\subsubsection*{Leader Problem}
Suppose that, under history $h = \invest$, followers use monotone strategies with threshold $x_\invest \in \RR$; that is, $s_j(\invest) = \invest$ for $x_j > x_\invest$.\footnote{~Since followers are \emph{ex ante} identical, assuming a common threshold is without loss.} If the leader chooses $a_L=\invest$, then the expected aggregate action is given by
\begin{equation*}
    A_{-L}(\theta) = 1 - \Phi\left(\frac{x_\invest - \theta}{\sigma_F}\right).
\end{equation*}
Note that the behavior of followers matters to the leader only when $a_L = \invest$; otherwise, she obtains a payoff of zero by taking the safe action $a_L = \notinvest$. The payoff to choosing $a_L=\invest$ for type $\theta$ is therefore
\begin{equation} \label{leader_payoff}
    \pi_L (\theta; x_\invest)= \theta - \Phi\left(\frac{x_\invest - \theta}{\sigma_F}\right).
\end{equation}
It is immediate to see that $\pi_L(\theta; x_\invest)$ is strictly increasing in $\theta$ and crosses zero only once from below. Thus, the leader's best response to $x_\invest$ is the unique solution to $\pi_L(\theta; x_\invest) = 0$.



\subsection{Main Results} \label{main_results}


We first provide an intuitive explanation of how $\Delta$-rationalizability proceeds. Before the procedure starts, all players deem all type-strategy pairs possible. Let $\thetalow^0 = \xhlow^ 0 = -\infty$ and $\thetaup^0 = \xhup^0 = \infty$ for each history $h$. We call the former \textit{lower dominance bounds} and the latter \textit{upper dominance bounds}.
Note that the payoff to the leader, given $\xilow^0$ and $\xiup^0$, satisfies the standard two-sided ``limit dominance'' property of global games \citep{morris_shin_2003}, with the \textit{dominance regions} being $(-\infty, 0)$ and $(1, \infty)$. That is, exerting no effort ($a_L = \notinvest$) is dominant for all types $\theta < 0$, and exerting effort ($a_L = \invest$) is dominant for all types $\theta > 1$.
This implies that
the leader will eliminate, in Round 1, all type-action pairs $(\theta, \invest)$ with $\theta < \thetalow^1 = 0$ and $(\theta, \notinvest)$ with $\theta > \thetaup^1 = 1$. 

By knowing the leader's dominance bounds $\thetalow^1$ and $\thetaup^1$, each follower can infer from $h = \invest$ that this decision cannot be made by a type $\theta < \thetalow^1$. 
This, in turn, 
determines each follower's dominance regions. For type $x$ of a follower, Lemma \ref{lemma_x_payoff} implies that
the worst-case payoff equals 
\begin{equation*}
   \pi_F^\invest(x; \thetalow^1, \xiup^0) =   \EE_{\theta \sim \Psi^\invest(\cdot; \,x, \thetalow^1)} [\theta] - \frac{n-1}{n}.
\end{equation*}
Let $\xiup^1$ be the unique solution to $\EE_{\theta \sim \Psi^\invest(\cdot; \,\xiup^1, 0)} [\theta] = \frac{n-1}{n}$. Exerting no effort is never a best response for $x > \xiup^1$ because the worst-case payoff is strictly increasing in $x$. But since the best-case payoff is positive for all $x$:
\begin{equation*}
   \pi_F^\invest(x; \thetaup^1, \xilow ^0) = \EE_{\theta \sim \Psi^\invest(\cdot; \,x, \thetaup^1)}[\theta] > 0,
\end{equation*}
the subgame under $h = \invest$ violates 
the two-sided limit dominance property because
exerting effort is not strictly dominated for any type $x$.\footnote{~See \cite{baliga_sjostrom_2004} and \cite{bueno_de_mesquita_2010} for applications with one-sided limit dominance but different signal structures.} 
This implies that the lower dominance bound yields $\xilow^1 = -\infty$. 

Now, under history $h = \notinvest$, followers know that it must be leader $\theta \leq \thetaup^1$ that has chosen not to exert effort. The subgame exhibits no upper dominance region because the worst-case payoff to any follower type $x$
\begin{equation*}
    \pi_F^\notinvest(x; \thetalow^1, \xiup ^0) = \EE_{\theta \sim \Psi^\notinvest(\cdot; \,x, \thetalow^1)}[\theta] - 1 < 0
\end{equation*}
is negative. Thus, $\xnup^1 = \infty$. The lower dominance bound is given by the unique solution $\xnlow^1$ to 
\begin{equation*}
    \pi_F^\notinvest(\xnlow^1; \thetaup^1, \xnlow^0) = \EE_{\theta \sim \Psi^\notinvest(\cdot; \,\xnlow^1, \thetaup^1)}[\theta] - \frac{1}{n} = 0. 
\end{equation*}
In sum, each follower $j$ will delete type-strategy pairs $(x, s_j)$ such that (i) $x > \xiup^1$ and $s_j(\invest) = \notinvest$, and (ii) $x < \xnlow^1$ and $s_j(\notinvest) = \invest$.

In Round 2, $\thetalow^2$, $\xilow^2$, and $\xnup^2$ are given analogously.  The leader's upper dominance bound, $\thetaup^2$, is the unique solution to 
\begin{equation*}
    \pi_L(\thetaup^2; \xiup^1) = \thetaup^2 - \Phi\bigg( \frac{ \xiup^1 - \thetaup^2 }{\sigma_F} \bigg) = 0.
\end{equation*}
Moreover, Lemma \ref{lemma_x_payoff} implies that followers' upper dominance bound under history $h = \invest$ is the unique value of $\xiup^2$ that solves 
\begin{equation*}
    \pi_F^\invest(\xiup^2; \thetalow^2, \xiup^1) = \EE_{\theta \sim \Psi^\invest(\cdot; \, \xiup^2, \thetalow^2)} \left[\theta - \frac{n-1}{n}\Phi\left(\frac{\xiup^1 - \xiup^2}{\sigma_F}\right)\right ] = 0,
\end{equation*}
and the lower dominance bound under history $h = \notinvest$ is given by the unique solution $\xnlow^2$ to
\begin{equation*}
        \pi_F^\notinvest(\xnlow^2; \thetaup^2, \xnlow^1) = \EE_{\theta \sim \Psi^\invest(\cdot; \, \xnlow^2, \thetaup^2)} \left[\theta - \frac{n-1}{n}\Phi\left(\frac{\xnlow^1 - \xnlow^2}{\sigma_F}\right)\right ] - \frac{1}{n} = 0.
\end{equation*}

A similar argument goes for all Rounds $k > 2$.
The iteration procedure ultimately yields six sequences. We summarize their properties in the following lemma.


\begin{lemma} \label{lemma_rat_seq}
The sequences are such that:\\
(a) $(\thetalow^k)_{k=0}^\infty$ is such that $\thetalow^k = \thetalow = 0$ for all $k \geq 1$; \\
(b) $(\thetaup^k)_{k=0}^\infty$ is strictly decreasing and bounded below; \\
(c) $(\xilow^k)_{k=0}^\infty$ is such that $\xilow^k = \xilow = -\infty$ for all $k \geq 0$; \\
(d) $(\xiup^k)_{k=0}^\infty$ is strictly decreasing; \\
(e) $(\xnlow^k)_{k=0}^\infty$ is strictly increasing; \\
(f) $(\xnup^k)_{k=0}^\infty$ is such that $\xnup^k = \xnup = \infty$ for all $k \geq 0$.
\end{lemma}

By the monotone convergence theorem, $\thetaup^k$ converges to $\thetaup$ as $k \to \infty$. Moreover, $\thetaup$ is the unique solution to
\begin{equation} \label{leader_upper}
    \pi_L(\thetaup; \xiup) = 0,
\end{equation}
where $\xiup = \lim_{k \to \infty} \xiup^k$, and hence $\thetaup < 1$.
If $\xiup > - \infty$, it solves 
\begin{equation} \label{follower_invest_upper}
    \pi_F^\invest(\xiup; \thetalow, \xiup) = 0;
\end{equation}
otherwise $\xiup = -\infty$. Similarly, let $\xnlow = \lim_{k \to \infty}\xnlow^k$, and $\xnlow$ solves
\begin{equation} \label{follower_notinvest_lower}
        \pi_F^\notinvest(\xnlow; \thetaup, \xnlow) = 0
\end{equation}
if a solution exists. Otherwise $\xnlow^k$ diverges to $\xnlow = \infty$.
We now state the main result of the paper.

\begin{proposition} \label{prop_unique_rat}
The $\Delta$-rationalizable sets are $R_L^\infty = R_L^0 \setminus \overline{R}_L^\infty$ and $R_{F, \,j}^\infty = R_{F, \,j}^0 \setminus \overline{R}_{F, \,j}^\infty$, where
\begin{equation*}
     \overline{R}_L^{\infty} = \left\{(\theta, a_L) \vl~ a_L = \invest ~\text{if}~ \theta \leq 0 ~\text{and}~ a_L = \notinvest ~\text{if}~ \theta > \thetaup \right\}
\end{equation*}
and
\begin{equation*}
    \overline{R}_{F, \,j}^\infty = \left\{(x_j, s_j) \vl ~ s_j(\invest) = \notinvest ~\text{if}~x_j > \xiup ~\text{and}~s_j(\notinvest) = \invest ~\text{if}~ x < \xnlow \right\}.
\end{equation*}
Moreover, there exists a unique $\widehat{\sigma}_F$ such that there is a unique $\Delta$-rationalizable strategy profile with 
$(\thetaup, \xiup, \xnlow) = (0, -\infty, \infty)$ if and only if $\sigma_F > \widehat{\sigma}_F$.

\end{proposition}







In words, Proposition \ref{prop_unique_rat} conveys the message that if the leader has a sufficient informational advantage (i.e.,
$\sigma_F > \widehat{\sigma}_F$), then  
the unique $\Delta$-rationalizable strategy profile features leader type $\theta$ choosing $a_L = \invest$ when $\theta > 0$ and $a_L = \notinvest$ otherwise, and all follower types imitating the leader's action. This leads to a fully efficient outcome. However, 
when followers have relatively precise information (i.e.,
$\sigma_F \leq \widehat{\sigma}_F$), both actions become rationalizable for leader types $\theta \in (0,\thetaup]$ and for follower types in $(-\infty,\xiup]$ if the leader chooses to exert effort and in $(\xnlow, \infty)$ if the leader chooses to exert no effort. Thus, the leader does not necessarily choose the efficient action ($a_L = \invest$) when $\theta \in (0, \thetaup]$ for fear that followers might coordinate against her and choose the inefficient action.




Moreover, whenever we obtain unique rationalizable behavior under history $h=\invest$, we also do so under history $h=\notinvest$. This is because followers understand that the state is negative which implies that $\pi_F^{\notinvest} (\xnlow;\thetaup ,\xnlow)=0$ has no solution. If, however, we get multiplicity of rationalizable profiles under history $h=\invest$, we may or may not get multiplicity under history $h=\notinvest$. This will depend on whether $\pi_F^{\notinvest} (\xnlow;\thetaup ,\xnlow)=0$ has solutions or not for the particular value of $\sigma_F < \widehat{\sigma}_F$ considered. It should also be noted that when the necessary and sufficient condition is not satisfied, then the values of $(\thetaup, \xiup, \xnlow)$ depend on the value of $\sigma_F$ and, thus, the game features noise-dependent selection. We plot the values of $\thetaup$ in Figure 2. Figure \ref{fig_n_vs_sigma_f_hat} illustrates how the value of $\widehat{\sigma}_F$ changes with the number of followers. 



% Figure environment removed


The next result shows what happens in the limit as $\sigma_F$ tends to zero.  
\begin{proposition} \label{prop_limit}
    In the limit as $\sigma_F \to 0$, the dominance bounds $\thetaup \to (n-1)/(2n)$, $\xiup \to (n-1)/(2n)$, and $\xnlow \to \infty$.
\end{proposition}

It is worth noting that the leader's and followers' upper threshold is given by $(n-1)/2n$ which corresponds to the ``risk dominant'' strategy profile of the subgame given the spillover benefit of the leader's action. This is because, in this extreme, the followers are allowed to have beliefs that completely shut down the informational role of the leader. In particular, this would be the unique rationalizable behavior of an alternative game, with the same payoffs as in this subgame, where there is no leader and the beliefs about the state are given by the Bayesian updating of the prior after followers receive their signals. This will be better illustrated in the next section where we interpret our results in terms of "conditional rank beliefs". 


% Figure environment removed

\subsection{The Signaling Role of Leader and Information Traps}

It is now evident that when the condition $\sigma_F > \widehat{\sigma}_F$ is met, we obtain \emph{efficient leadership}: the leader chooses action $a_L = \invest$ whenever it socially desirable to do so (i.e., $\theta > 0$) and chooses $a_L = \notinvest$ otherwise. In this case, the outcome of the game corresponds to the fully efficient subgame perfect equilibrium of the complete information game, which may not come as a surprise.
Indeed, \cite{komai_et_al_2007} reach a similar conclusion in a different framework, which focuses on the signaling role of leaders primarily in organizational economics settings. However, our global games perspective speaks to leadership in a variety of scenarios, such as regime change, bank runs, and currency attacks. Additionally, our result reinforces theirs by deriving it using a weaker solution concept.
% the same conclusion, albeit in a different framework. While their framework captures the signaling role of leaders mostly in the organizational economics settings, our global games perspective speaks about leadership in other types of scenarios as well, such as regime change, bank runs, or currency attacks. Moreover, our result strengthens theirs in that we derive it using a weaker solution concept.

However, the significance of our contribution lies in the converse direction, demonstrating that if followers possess sufficiently precise private information, the leader may choose a socially undesirable action. The leader may fear that her well-informed followers might make the ``wrong'' decision, which could, in turn, compel her to act inefficiently by selecting $a_L = \notinvest$ even when $\theta > 0$.
% However, we believe that the importance of our contribution comes from the converse direction: if the followers have sufficiently precise private information, then the leader herself might choose the socially undesirable action. This is because the leader might be afraid that her followers will choose the ``wrong'' action when they are well informed. 
% This, in turn, might lead the leader herself to act inefficiently; that is, she might choose $a_L=\notinvest$ even if she knows that $\theta > 0$. 
Furthermore, even if $\theta < 0 $ and the leader chooses $\notinvest$, well-informed followers might be tempted to choose $\invest$, which is socially undesirable in this scenario because they do not know what type of leader chose action $\notinvest$. Therefore, we may encounter an \textit{information trap}: better-informed followers might make the leader choose incorrectly, or even if the leader does choose the efficient action, they, themselves, might not do so. On the other hand, if these followers were ``kept in the dark,'' efficient coordination would be achieved as the unique rationalizable outcome of the game. This is surprising in the sense that, we do not obtain ``limit uniqueness'' but rather ``limit multiplicity'' of rationalizable profiles, contrary to the standard results in the global games literature (see, for example, \cite{frankel_et_al_2003}). 


Therefore, it is clear that the role of the leader is undermined by the more precise information the followers hold. Our model uncovers two opposite forces that compete with each other: we term them the signaling effect and the miscoordination effect. The necessary and sufficient condition derived in Proposition \ref{prop_unique_rat} makes certain that the signaling effect dominates the miscoordination effect and, as a result, ensures that the efficient outcome is realized. We now proceed to shed more light on these two forces and make the tension uncovered clearer. 


\subsubsection{Signaling Effect versus Miscoordination Effect: Why Multiplicity Happens?}

To see why multiplicity presents itself, we will analyze the subgame after history $h$ and consider the rationalizable profiles of followers' type-strategy pairs. Notice that given the action of the leader, the subgame appears to be a global game except we have one-sided dominance regions. To make the intuition clearer it is useful to consider \textit{monotone strategies}. In that regard, consider type $x$ of follower $j$.  This type of follower $j$ does not know which threshold the leader used to make the choice that led to history $h$ being realized, so let $z$ denote this threshold.  Now, define follower $j$'s \textit{conditional rank belief} as the probability he assigns to the event that the other follower's type $x_k$ is at most his own ($x_j = x$) conditional on history $h$. We have that:

\begin{equation} \label{rank_belief}
    R^h(x; z)= \prob(x_k \leq x_j \vl x_j = x, h) = \frac{1}{2}\left[\Phi\left(\frac{x - z}{\sigma_F}\right) + \chi_\notinvest \right] 
\end{equation}
This definition is a direct extension of the rank belief function introduced in \cite{morris_et_al_2016} and \cite{morris_yildiz_2019}. 

Assume that follower $j$ conjectures that his opponents in the subgame will use a threshold $x_h$. Then, the expected payoff to choosing $\invest$ under history $h$ is given by:
\begin{equation} \label{follower_payoff_rank_belief}
    \pi_F^h(x; z, x_h) = \EE_{\theta \sim \Psi^h(\cdot; \,x, z)} \left[ \theta - \frac{n-1}{n} \Phi\left(\frac{x_h-\theta}{\sigma_F}\right)   \right] - \frac{\chi_\notinvest}{n}.
\end{equation}
Now, consider the type of follower $j$ whose signal is equal to the conjectured threshold of followers $-j$. Then, we can write this type's expected payoff to choosing $\invest$ as 
\begin{equation*}
    \pi_F^h(x_h; z, x_h) = \EE_{\theta \sim \Psi^h(x_h; \,z, x_h)} \left[ \theta \right] + \frac{n-1}{n}\left[1 - R^h(x_h; z)\right] + \frac{\chi_\invest}{n} - 1.
\end{equation*}

In order for type $x_h$ of follower $j$ to be indifferent between choosing $\invest$ and $\notinvest$ it must be the case that $x_h$ must solve for all $h$
\begin{equation} \label{eq_eqm_follower}
   \EE_{\underbrace{\theta \sim \Psi^h(\cdot; \,z, x_h)}_{\text{signaling effect}}} \left[ \theta \right] -  \underbrace{\frac{\chi_\notinvest}{n}}_{\text{spillover from leader's action}}= \underbrace{\frac{n-1}{n}R^h(x_h; z)}_{\text{miscoordination effect}} 
\end{equation}
The left-hand side of this equation captures the twofold effect of the leader's choice. First, the signaling effect simply says that by observing history $\invest$, it must be the case that $\theta>z$. The rationality of the leader implies that $z\geq 0$ and this is common knowledge among followers. Second, if the leader chose $\notinvest$ there is a negative spillover benefit to followers. The right-hand side captures the miscoordination effect: given the leader's threshold, if a follower $-j$ invests only if his type is greater than $x_h$, then type $x_h$ of follower $j$ faces an expected loss equal to (1/n) times the probability of this event, which is given exactly by the conditional rank belief function. 
Notice that if type $x_h$ of follower $j$ is indifferent between $\invest$ and $\notinvest$, then any type lower than $x_h$ will choose $\notinvest$ given the conjectured strategies. 



Focus on history $h=\invest$. An analogous argument holds for history $h=\notinvest$. Notice that we can write Equation (\ref{eq_eqm_follower}) under $h = \invest$ as 
\begin{equation} \label{eq_eqm_follower_rewrite}
    x_\invest + \sigma_F \lambda\left(\frac{x_\invest - z}{\sigma_F}\right) = \frac{n-1}{n}\left[\frac{1}{2}\Phi\left(\frac{x_\invest - z}{\sigma_F}\right)\right]
\end{equation}
 Since the leader choosing action $\invest$ whenever $\theta>0$ and followers imitating the leader's action is always rationalizable behavior, to get uniqueness,
Equation (\ref{eq_eqm_follower_rewrite}) must either have no solution or have exactly one solution for $z=\thetalow=0$. In the former case we obtain the efficient outcome, while in the latter, we obtain uniqueness but full efficiency is not achieved.
Observe that
the noise, $\sigma_F$, affects both the signaling and the miscoordination effect. Moreover, the former is increasing in $\sigma_F$. In contrast, the latter does not change monotonically with $\sigma_F$ but features rapid slope change around $x_h=z$.\footnote{~It changes monotonically for $x_h<z$ and $x_h>z$ but not for all $x$.} For large values of $\sigma_F$  (i.e., $\sigma_F \geq \widehat{\sigma}_F$), the signaling effect dominates the miss-coordination effect, implying that Equation (\ref{eq_eqm_follower_rewrite}) has no solution, that is, the expected loss is always smaller than the expected return to choosing $\invest$. This means that $\xiup^k \to \xilow$ as $k \to \infty$ and hence $\invest$ is the unique rationalizable action in the subgame following $h = \invest$. See Figure \ref{fig_invest_unique} for an illustration.
As a consequence, $\thetalow = \thetaup$, $\xnlow = \xnup$ and we obtain a unique $\Delta$-rationalizable strategy profile.

% Figure environment removed

On the contrary, for small values of $\sigma_F$ (i.e., $\sigma_F \leq \widehat{\sigma}_F$), the signaling effect stops playing a dominant role, meaning that the expected loss may be higher than the expected return. Hence Equation (\ref{eq_eqm_follower_rewrite}) may have multiple solutions (see Figure \ref{fig_invest_multiple}). Indeed, this is the case. In particular, the largest solution corresponds to the limit $\xiup$ to which the sequence $(\xiup^k)$ will converge. This yields the fact that both actions are rationalizable for follower types $(\xilow,\xiup]$ with $\xilow=-\infty$.


At this point, the fact that $\theta>0$ has become common knowledge plays a minimal role. In fact, as $\sigma_F$ approaches zero, the signaling effect is completely obliterated and followers behave as if $\theta$ can take any value on the real line\footnote{~In fact, the monotone strategy profiles with thresholds $\xilow$ and $\xiup$ are the least and greatest Bayesian Nash equilibria that bound all rationalizable strategies in the sub-game that follows action $\invest$ of the leader \citep{van_zandt_vives_2007}.}. An interesting aspect of the model is that 
$R^\invest(\xiup, \thetalow) \to 1/2$ as $\sigma_F \to 0^+$. This guarantees that the monotone strategy profile with threshold $\xiup$ which bounds the set of rationalizable profiles in the subgame, corresponds to the ``risk dominant'' equilibrium \citep{harsanyi_selten_1988} of the subgame game given history $\invest$. That is, a follower will only choose $\invest$ if $\invest$ is a best response to a uniform belief over other followers choosing each action. However, this point cannot be supported as an equilibrium in monotone strategies of the whole game. When followers play according to the threshold $\xiup$, the leader will best respond by using a monotone strategy with threshold $\thetaup > \thetalow$, which is the limit of $\thetaup^k$ as $k \to \infty$. Thus, any leader type $\theta \in (\thetalow, \thetaup)$ will find both actions rationalizable. 

% Figure environment removed





\subsection{Discussion}

\subsubsection{Equilibrium Behavior}

If the necessary and sufficient condition derived in Proposition \ref{prop_unique_rat} is satisfied, the game features unique rationalizable behavior. This immediately implies that the game features unique equilibrium behavior. In particular, the unique rationalizable strategy profile corresponds to the unique Perfect Bayesian Equilibrium of the game, which is in monotone strategies, with thresholds for the leader and followers given by $\theta_L^*=\thetaup=0 $, $\xilow=\xiup=-\infty$ and $\xnlow=\xnup=\infty$. 

As we prove in Appendix B, it is the case that when one considers monotone strategies only, the game always has a unique monotone equilibrium. However, restricting attention to these types of strategies only may be with loss, since one cannot rule out the existence of other equilibria in more complicated, non-monotone strategies. This is one of the reasons that we chose rationalizability as our solution concept.










\subsubsection{Peer-confirming Equilibrium}

Although our model features incomplete information about a fundamental state, the result is consistent with the prediction delivered by the peer-confirming equilibrium of \cite{lipnowski_sadler_2019}. In a leader-centered star network where all followers observe the leader's strategy, \cite{lipnowski_sadler_2019} argue that ``imitation'' may arise as the unique extensive-form peer-confirming equilibrium since followers do not observe any information that could contradict the leader's rationality. 
The leader, thus, has the advantage of inducing others to imitate her behavior.
In this regard, Proposition 1 deals with the interplay between strategic uncertainty and fundamental uncertainty by
identifying a necessary and sufficient condition under which the unique $\Delta$-rationalizable strategy profile that arises also corresponds to the unique peer-confirming equilibrium that highlights imitation.









\medskip







