{
  "title": "Rating-based Reinforcement Learning",
  "authors": [
    "Devin White",
    "Mingkang Wu",
    "Ellen Novoseller",
    "Vernon J. Lawhern",
    "Nicholas Waytowich",
    "Yongcan Cao"
  ],
  "submission_date": "2023-07-30T23:54:22+00:00",
  "revised_dates": [
    "2024-01-29T15:00:50+00:00"
  ],
  "abstract": "This paper develops a novel rating-based reinforcement learning approach that uses human ratings to obtain human guidance in reinforcement learning. Different from the existing preference-based and ranking-based reinforcement learning paradigms, based on human relative preferences over sample pairs, the proposed rating-based reinforcement learning approach is based on human evaluation of individual trajectories without relative comparisons between sample pairs. The rating-based reinforcement learning approach builds on a new prediction model for human ratings and a novel multi-class loss function. We conduct several experimental studies based on synthetic ratings and real human ratings to evaluate the effectiveness and benefits of the new rating-based reinforcement learning approach.",
  "categories": [
    "cs.LG",
    "cs.AI",
    "cs.RO"
  ],
  "primary_category": "cs.LG",
  "doi": null,
  "journal_ref": null,
  "arxiv_id": "2307.16348",
  "pdf_url": "https://arxiv.org/pdf/2307.16348v2",
  "comment": "This is an extended version of the paper \"Rating-based Reinforcement Learning\" accepted to the 38th Annual AAAI Conference on Artificial Intelligence",
  "num_versions": null,
  "size_before_bytes": 4292591,
  "size_after_bytes": 936362
}