{
  "title": "Exploring Annotation-free Image Captioning with Retrieval-augmented Pseudo Sentence Generation",
  "authors": [
    "Zhiyuan Li",
    "Dongnan Liu",
    "Heng Wang",
    "Chaoyi Zhang",
    "Weidong Cai"
  ],
  "submission_date": "2023-07-27T10:16:13+00:00",
  "revised_dates": [
    "2023-07-28T05:53:33+00:00",
    "2024-10-14T09:31:18+00:00"
  ],
  "abstract": "Recently, training an image captioner without annotated image-sentence pairs has gained traction. Previous methods have faced limitations due to either using mismatched corpora for inaccurate pseudo annotations or relying on resource-intensive pre-training. To alleviate these challenges, we propose a new strategy where the prior knowledge from large pre-trained models (LPMs) is distilled and leveraged as supervision, and a retrieval process is integrated to further reinforce its effectiveness. Specifically, we introduce Retrieval-augmented Pseudo Sentence Generation (RaPSG), which can efficiently retrieve highly relevant short region descriptions from the mismatching corpora and use them to generate a variety of high-quality pseudo sentences via LPMs. Additionally, we introduce a fluency filter and a CLIP guidance objective to enhance contrastive information learning. Experimental results indicate that our method outperforms SOTA captioning models across various settings including zero-shot, unsupervised, semi-supervised, and cross-domain scenarios. Code is available at: https://github.com/Zhiyuan-Li-John/RaPSG.",
  "categories": [
    "cs.CV",
    "cs.AI"
  ],
  "primary_category": "cs.CV",
  "doi": null,
  "journal_ref": null,
  "arxiv_id": "2307.14750",
  "pdf_url": "https://arxiv.org/pdf/2307.14750v3",
  "comment": "Accepted by ACM Multimedia Asia 2024",
  "num_versions": null,
  "size_before_bytes": 53572949,
  "size_after_bytes": 451996
}