\documentclass[journal]{IEEEtran}
%\documentclass[10pt,draft]{IEEEtran}

\usepackage[cmex10]{amsmath}
\usepackage{amssymb}
\usepackage[mathscr]{eucal}
%\pdfmapfile{+rsfso.map}
%\DeclareSymbolFont{rsfso}{U}{rsfso}{m}{n}
%\DeclareSymbolFontAlphabet{\mathscr}{rsfso}
%\usepackage[scr]{rsfso}
%\usepackage[mathscr]{mathpi}
\usepackage{cite}
\usepackage{amsbsy}
\usepackage{esint}
\usepackage{tikz}
%\usepackage{graphicx,slashbox}
\input definition.tex

\ifCLASSINFOpdf

\else

\fi

\usepackage{algorithmic}

\usepackage{array}

\usepackage{fixltx2e}



\usepackage{stfloats}




\usepackage{url}


% \hyphenation{op-tical net-works semi-conduc-tor}



\begin{document}

\title{Neural Representation-Based Method for Metal-induced Artifact Reduction in Dental CBCT Imaging}



% author names and affiliations
% transmag papers use the long conference author name format.

\author{\IEEEauthorblockN{Hyoung Suk Park, Kiwan Jeon, and Jin Keun Seo, Member, IEEE}\\

\thanks{Hyoung Suk Park and Kiwan Jeon are with the National Institute for Mathematical Sciences, Daejeon, 34047, Republic of Korea (e-mail: hspark@nims.re.kr; jeonkiwan@nims.re.kr)}
\thanks{Jin Keun Seo is with the School of Mathematics and Computing (Computational Science and Engineering), Yonsei University, Seoul, 03722, Republic of Korea (e-mail: seoj@yonsei.ac.kr)}
\thanks{Manuscript received XXX; revised  XXX. Corresponding author: J. K. Seo (email: seoj@yonsei.ac.kr).}}



% The paper headers
\markboth{IEEE}%
{Park \MakeLowercase{\textit{et al.}}: }


\IEEEtitleabstractindextext{%
\begin{abstract}
This study introduces a novel reconstruction method for dental cone-beam computed tomography (CBCT), focusing on effectively reducing metal-induced artifacts commonly encountered in the presence of prevalent metallic implants. Despite significant progress in metal artifact reduction techniques, challenges persist owing to the intricate physical interactions between polychromatic X-ray beams and metal objects, which are further compounded by the additional effects associated with metal-tooth interactions and factors specific to the dental CBCT data environment. To overcome these limitations, we propose an implicit neural network that generates two distinct and informative tomographic images. One image represents the monochromatic attenuation distribution at a specific energy level, whereas the other captures the nonlinear beam-hardening factor resulting from the polychromatic nature of X-ray beams. In contrast to existing CT reconstruction techniques, the proposed method relies exclusively on the Beer--Lambert law, effectively preventing the generation of metal-induced artifacts during the backprojection process commonly implemented in conventional methods. Extensive experimental evaluations demonstrate that the proposed method effectively reduces metal artifacts while providing high-quality image reconstructions, thus emphasizing the significance of the second image in capturing the nonlinear beam-hardening factor.
\end{abstract}

% Note that keywords are not normally used for peerreview papers.
\begin{IEEEkeywords}
Computerized tomography, Metal artifact reduction, Beam hardening effect, Neural Radiation Fields.
\end{IEEEkeywords}}



% make the title area
\maketitle



% papers do.
\IEEEdisplaynontitleabstractindextext
% \IEEEdisplaynontitleabstractindextext has no effect when using
% compsoc or transmag under a non-conference mode.



\IEEEpeerreviewmaketitle



\section{Introduction}
Metal artifact reduction (MAR) in dental cone-beam computed tomography (CBCT) is challenging owing to the prevalence of metallic implants in patients. Multiple metallic objects, such as dental implants, in the scanned region can result in severe computed tomography (CT) image artifacts owing to the complex physical interactions between the polychromatic X-ray beams and metal objects. However, despite significant progress in MAR methods over the past four decades, existing approaches have shown limited performance in effectively reducing metal artifacts in dental CBCT environments, where multiple metal inserts occupy a significant area.

Dental CBCT has gained popularity as a cost-effective and low-radiation alternative to multidetector CT (MDCT) in dental clinics. However, a significant drawback of it is that its inverse problem is more challenging compared with MDCT. Specifically, it poses a highly complex and nonlinear challenge, primarily attributed to multiple factors, including intricate metal-bone and metal-tooth interactions, photon starvation, field-of-view truncation, offset detector, and scattering.
Metal-induced artifacts stem from the mismatch between the forward models employed in conventional reconstruction algorithms (such as filtered backprojection (FBP) \cite{Bracewell1967} and Feldkamp-Davis-Kress (FDK) \cite{Feldkamp1984}), and the polychromatic nature of X-ray beams. X-ray beams in dental CBCT comprise photons with energies ranging from minimum (e.g., 0 keV) to peak energy (e.g., between 60 and 120 keV)\cite{Pauwels2014}. However, these conventional algorithms overlook the polychromatic nature of X-ray beams, thus leading to a discrepancy between the sinogram data and the range space of the forward operator, such as the Radon transform. This discrepancy can result in widespread artifacts in the reconstructed image; the reconstruction process aims to minimize the discrepancy between the forward projection of the image and measured sinogram.


Over the past four decades, numerous methods for MAR have been developed, including projection-based methods \cite{Abdoli2010,Kalender1987,Lewitt1978,Meyer2010,Park2013,Roeske2003,Zhao2000}, iterative reconstruction methods \cite{DeMan2001,Elbakri2002,Menvielle2005,OSullivan2007,Wang1996}, dual-energy CT methods \cite{Alvarez1976,Lehmann1981,Yu2012}, and photon counting methods \cite{Layer2023,Patzer2023}.
Projection-based methods may encounter difficulties in correcting distorted data, particularly when metal objects are large or complex.
Iterative methods can achieve superior results compared with projection-based methods; however, they have limitations in accurately modeling complex interactions between X-rays and metal objects.
Dual-energy methods improve the accuracy of material identification and artifact reduction; however, they require specialized hardware or software, and an increased radiation dose.
Photon counting is a promising technology that has recently gained attention for its potential application in MAR \cite{Layer2023,Patzer2023}. However, it may not be suitable for dental CBCT because of the high cost of photon-counting detectors. Recently, deep learning algorithms have been widely utilized for MAR in X-ray CT and can be roughly classified into three categories: image-domain learning \cite{Gjesteby2017,Nakao2020,Zhang2018-1}, projection-domain learning \cite{Park2018}, and dual-domain learning \cite{Lin2019,Zhang2020}. The abovementioned methods require numerous paired metal-affected and metal-free CT scans for network training. However, obtaining paired datasets in clinical practice remains challenging. Furthermore, the performance of deep learning methods can considerably degrade when applied to CT scans acquired under acquisition conditions or CT scanners that differ from those used for training.

To address the intricate challenge of MAR in dental CBCT, we thoroughly investigated the limitations of conventional methods, such as FBP and FDK algorithms. Recognizing the need for an innovative approach that circumvents the backprojection process commonly used in these methods and its tendency to generate metal-induced artifacts, we proposed a novel MAR algorithm. Recently, neural radiance fields (NeRFs) \cite{Mildenhall2021} in computer vision have demonstrated considerable potential for representing 3D scenes from 2D camera data using deep neural networks. Inspired by this, we proposed a CT reconstruction method that utilizes the inherent capabilities of neural representations to generate two distinct, informative tomographic images. One image represents the monochromatic attenuation distribution at a specific energy level, whereas the other captures the nonlinear beam-hardening factor stemming from the polychromatic nature of X-ray beams. In contrast to the existing CT reconstruction techniques, the proposed method exclusively relies on the Beer--Lambert law, effectively preventing the generation of metal-induced artifacts during the backprojection process commonly employed in conventional methods. Figure \ref{fig-main} shows the schematic diagram of the proposed method.

The efficacy of the proposed method was assessed through evaluations of realistic simulated and phantom experiment datasets. The results demonstrated increased efficiency in reducing metal artifacts while preserving the morphological structures around metallic objects. Furthermore, the proposed method offers promising performance even with photon starvation.

% Figure environment removed

\section{Mathematical framework}
In dental CBCT, a cone-shaped X-ray beam is directed through a patient's head while they are positioned between an X-ray source and a flat-panel detector housed in a gantry. The gantry is rotated to allow the X-ray beam to pass through the patient's head from various angles. During this process, a planar detector acquires the CBCT projection data denoted as $\text{P}(\varphi, u, v)$, where $\varphi\in [0,2\pi)$ represents the projection angle and $(u,v)$ represents the position of the planar detector. The position is scaled using the ratio of the distance between the X-ray source and detector plane to the distance between the source and rotation axes.

The sinogram $\text{P}$ acquired from low-dose dental CBCT can be described by the expression:
\begin{equation} \label{pfull}
	\text{P} =  \mathcal S_{\mbox{\scriptsize truncation}}( \text{P}_{\mbox{\scriptsize full}}),
\end{equation}
where  $\text{P}_{\mbox{\scriptsize full}}$ denotes the corresponding sinogram acquired using a wide-detector CBCT without any offset, thus providing the entire information for a sinogram; and $\mathcal S_{\mbox{\scriptsize truncation}}$ represents the truncation operator determined by the size and offset configuration of the detector.

The main objective here is using the truncated data $\text{P}$ to reconstruct a scalar value $\mu(\x)$ that represents the attenuation coefficient at a fixed energy level $E_0$ and for a specific position $\x=(x,y,z)$ in world coordinates. Under the idealized monochromatic assumption, a linear X-ray transform exists, denoted by $\mathcal T_{\text{\tiny fw}}$, such as the Radon or cone-beam transforms, which maps the CT image to the projection data as follows.
\begin{equation}\label{Forward1}
\text{P} = \mathcal T_{\text{\tiny fw}}~ \mu.
\end{equation}
However, this monochromatic model is inaccurate because the X-ray beams used in these scans consist of photons with a range of energies. Thus, the X-ray attenuation coefficient distribution, denoted by $\mu_E (\x)$, varies with the position $\x$ and photon energy level $E$.
Consider the path of the X-ray beam from the source position ${\bf o}_{\varphi}$ to the detector position $\x_{\varphi, u,v}$ in the world coordinates. Owing to the polychromatic nature of X-ray beams, the projection data $\text{P}(\varphi, u, v)$ follow the Lambert-Beer law \cite{Beer1852,Lambert1892}.
\begin{align}\label{Lambert-Beer-law}
\text{P}(\varphi, u, v)
=-\ln\left(\int_{E_{\text{min}}}^{E_{\text{max}}}\eta(E)\exp \left(-\int_{\ell_{\varphi, u,v}} \mu_E ds\right)dE\right),
\end{align}
where $\int_{\ell_{\varphi, u,v}} \mu_E ds$ is the line integral of $\mu_E$ over the ray $\ell_{\varphi, u,v}$ joining the source position ${\bf o}_\varphi$ and detector position $\x_{\varphi, u,v}$; and $\eta(E)$ represents the fractional energy at photon energy $E$ in the spectrum of the X-ray source \cite{Herman1983}, with its support being the interval $[E_{\text{min}},E_{\text{max}}]$, and $\int_{\Bbb R} \eta(E) dE=1$.



\subsection{Inherent drawbacks of methods using FBP or FDK}
To solve the ill-posed problem, a regularized least squares method of the following form can be used:
\begin{equation}\label{leastSquare1}
	\mu_*=\underset{\mu}{\mbox{argmin}}   \|\text{P} - \mathcal T_{\text{\tiny fw}}~ \mu\|_{\ell_2}^2 +\gamma \text{Reg}(\mu),
\end{equation}
where $\text{Reg}(\mu)$ is a regularization term constraining prior knowledge of artifact-free and noise-free CBCT images; $\|\cdot\|_{\ell_2}$ denotes the standard Euclidean norm; and $\gamma$ is the regularization parameter controlling the trade-off between the fidelity term and regularity.

The linear operator can be expressed as follows:
\begin{equation}\label{linear-pojection}
 \mathcal T_{\text{\tiny fw}}: \mu \in \R^{V}	\mapsto\text{P}\in \R^{S\times D}
\end{equation}
where $V$ denotes the numebr of voxels in the CBCT images, $S$ denotes the number of views, and $D$ denotes the number of detector cells. According to the Hiblert projection theorem, the Hilbert space $\mathcal H=\R^{S\times D} $ can be decomposed as:
\begin{equation}\label{Hilbert-pojection}
	\mathcal H= \mathcal H^{sino} \oplus \mathcal H^{\perp}
\end{equation}
where $\mathcal H{sino}=\{\mathcal T_{\text{\tiny fw}}\mu : \mu \in \R^{V}\}$ is the range space,  $\mathcal H^{\perp}$ is its orthogonal complement, and $\bigoplus$ denotes the orthogonal direct sum.
Hence,  $\text{P}$ can be decomposed into
\begin{equation}\label{Hilbert-pojection2}
	\text{P}=\text{P}^{sino} + \text{P}^{\perp}
\end{equation}
where $\text{P}^{sino}\in \mathcal H^{sino}$ and $\text{P}^{\perp}\in \mathcal H^{\perp}$.
Thus, the problem is equivalent to:
\begin{equation}\label{leastSquare2}
	\mu_*=\underset{\mu}{\mbox{argmin}}   \|\text{P}-\text{P}^{\perp}  - \mathcal T_{\text{\tiny fw}}~ \mu\|_{\ell_2}^2 +\gamma \text{Reg}(\mu).
\end{equation}
Note that $\mathcal T_{\text{\tiny fw}}$ maps an arbitrary single voxel image to the corresponding sinusoidal curve in the sinogram space $\mathcal H$. Hence, any single-pixel mismatch in $\text{P}$ leads to a sinusoidal global change $\text{P}^{\perp}$ when inputting data into the range space $\mathcal H^{sino}$. Thus, attempting a local mismatch in $\text{P}$ is highly desirable; however, this is not possible within the above least-squares framework. Global matching of $\text{P}$ by subtracting $\text{P}^{\perp}$ produces streaking or shadowing artifacts (see Fig. \ref{fig-mar-ct}).

To provide a rigorous explanation of cupping and streaking artifacts for metallic objects in CT imaging, we focus on the fan-beam CT model, where we restrict $\text{P}(\varphi, u,0)$ to detector position $v=0$. We can then represent $\mathcal{T}_{\text{\tiny fw}}$ as a composition of the Radon transform and the data-filtering operator that converts the fan-beam projection data into a parallel beam sinogram. To explain how $\text{P}^\perp$ destroys the global structure of $\text{P}$, we examined a simplified model comprising two disk-shaped metallic objects, as shown in Fig. \ref{fig-mar-ct}. Specifically, the desired ideal CT image can be represented as $\mu=c\chi_{D_1\cup D_2}$ (where $c$ is a constant, $D_1$ and $D_2$ are disks of equal radius, and $\chi_D$ denotes the characteristic function of region $D$), by assigning it a value of one inside $D$ and zero otherwise.
To analyze the projection data $\text{P}$, we introduce $\text{P}_{D_1}$ to denote the projection data solely related to $D_1$, and $\text{P}_{D_2}$ for $D_2$. Interestingly, $\text{P}_{D_1}$ and $\text{P}_{D_2}$ lie within the range space but yield cupping artifacts \cite{Park2015,Park2017}. Therefore, $\text{P}_{D_1}$ and $\text{P}_{D_2}$ are consistent and $\text{P}_{D_1}^\perp=0=\text{P}_{D_2}^\perp$. By contrast, $\text{P}$ exhibits inconsistency, thus leading to $\text{P}^\perp\neq 0$, as shown in Fig. \ref{fig-mar-ct}. Here, $\text{P}^\perp$ was computed as $\text{P}^\perp=\text{P}-\mR\mR^{-1}\text{P}$, where $\mR$ and $\mR^{-1}$ denote the Radon transform and FBP operators, respectively. Consider a scenario in which an X-ray beam passes through both disks within a projection angle range of $4\pi/9$ to $5\pi/9$. Thus, $\text{P}(\phi,u)\neq \text{P}_{D_1}(\phi,u)+ \text{P}_{D_2}(\phi,u)$ for $\phi$ within the range $[4\pi/9, 5\pi/9]$, whereas $\text{P}(\phi,u)= \text{P}_{D_1}(\phi,u)+ \text{P}_{D_2}(\phi,u)$ holds true for $\phi$ outside this interval.
Based on the sinogram consistency condition for $\text{P}^{sino}$, it follows that for all $\phi \in [4\pi/9, 5\pi/9]$ and $\phi' \notin [4\pi/9, 5\pi/9]$,
\begin{equation}\label{ortho}\int (\text{P}(\phi, u)-\text{P}^\perp(\phi,u))du=\int (\text{P}(\phi', u)-\text{P}^\perp(\phi', u))du.\end{equation}
This indicates that $\text{P}^\perp$ corrects specific regions and affects the global structure of $\text{P}$ in a broader sense. As shown in Fig. \ref{fig-mar-ct}, $\text{P}^\perp$, used for rectifying the mismatch, has a broad impact on the entire sinogram, thus leading to the deterioration of its global structure and introduction of streaking and shadowing artifacts. Existing methods that use the backprojection process cannot offer localized correction solely to $\text{P}$ within the projection angle range of $[4\pi/9, 5\pi/9]$ without influencing other segments of the sinogram $\text{P}$. Consequently, novel methods that address this issue and provide localized corrections specifically to the relevant regions of the sinogram while avoiding adverse impact on other portions must be urgently developed.

% Figure environment removed

\subsection{Fundamental structure of global artifacts caused by sinogram inconsistency}
This section investigates the structure of artifacts caused by a sinogram inconsistency. Assume that $\text{P}$ has a local mismatch $\text{P}^{\mbox{\tiny mismatch}}$ whose support occupies a small area in the sinogram space. The corrected sinogram $\text{P}-\text{P}^{\mbox{\tiny mismatch}}$ is in the range space such that $\mu_*$ exists, where $\mathcal T_{\text{\tiny fw}}~ \mu_*=\text{P}-\text{P}^{\mbox{\tiny mismatch}}$.

To simplify notation, we will denote a position $(\varphi, u, v)$ in sinogram space as $\xi = (\varphi, u, v)$.
Let us consider the scenario where a sinogram mismatch occurs at a single point $\xi_0=(\varphi_0, u_0, v_0)$. If this mismatch is a Dirac function $\delta_{\xi_0}$, then the corresponding artifact can be represented as:
\begin{equation}\label{f-artifact1}
	\Gamma _{\xi_0}=\underset{\mu}{\mbox{argmin}}   \|\delta_{\xi_0} - \mathcal T_{\text{\tiny fw}}~ \mu\|_{\ell_2}^2
\end{equation}
Then, the artifacts caused by the sinogram inconsistency $\text{P}^\perp$ can be expressed as:
\begin{equation}\label{f-artifact2}
	\Upsilon(\x)=\int_{\Omega} \Gamma_{\xi}(\x) \text{P}^{\mbox{\tiny mismatch}}(\xi) d\xi
\end{equation}
where $\Omega$ is the support of $\text{P}^{\mbox{\tiny mismatch}}$.

\begin{remark} To understand metal-induced artifacts more intuitively, let us consider a simplified scenario of a bichromatic model with energies of 64 and 80 KeV and the fractional energy is described as $
\eta(E)=\frac{1}{2} \delta(E-64)+\frac{1}{2} \delta(E-80)$. We want to reconstruct an image that is a $3\times 3$ pixel matrix, which is represented as:
   $$
   \left(
   \begin{array}{ccc}
      \mu_{1,1} &   \mu_{1,2} & \mu_{1,3} \\
      \mu_{2,1} &   \mu_{2,2} & \mu_{2,3} \\
      \mu_{3,1} &   \mu_{3,2} & \mu_{3,3}\\
   \end{array}
   \right),
   $$
   where $\mu_{2,1}=\mu_{2,3}$ are metals and the rest are air. We hope that the reconstructed image should be of the form
\begin{equation}\label{sol}
   \left(
\begin{array}{ccc}
   0 &   0 & 0\\
   c &   0 &  c \\
   0 &   0 & 0\\
\end{array}
\right),
\end{equation}
for some constant $c$ associated with the attenuation coefficient of the metal. The attenuation coefficients of the metal are 64 at $E=64$ keV and 5 at $E=80$ keV. Assume that we have the projection data of three angles $\varphi=0,\frac{\pi}{4}, \frac{\pi}{2}$.
Then, the conventional CT reconstruction problem solves the following system.
\begin{equation}\label{RT}
\left\{\begin{array}{llll}
      \mu_{1,1} +   \mu_{2,1} + \mu_{3,1} &=   &\text{P}(0, 1)&=5.7  \\
   \mu_{1,2} +   \mu_{2,2} + \mu_{3,2} &=   &\text{P}(0, 2)&=0  \\
   \mu_{1,3} +   \mu_{2,3} + \mu_{3,3} &=   &\text{P}(0, 3)&=5.7 \\
  \mu_{2,1} +   \mu_{3,2}  &=   &\text{P}(\pi/4, 1)&=5.7\\
   \mu_{1,1} +    \mu_{2,2} +  \mu_{3,3} &=   &\text{P}(\pi/4, 2)&=0\\
   \mu_{1,2} +   \mu_{2,3} &=   &\text{P}(\pi/4, 3)&=5.7 \\
   \mu_{3,1} +   \mu_{3,2} + \mu_{3,3} &=   &\text{P}(\pi/2, 1)&=0\\
   \mu_{2,1} +   \mu_{2,2} + \mu_{2,3} &=   &\text{P}(\pi/2, 2)&=10.7\\
   \mu_{1,1} +   \mu_{1,2} + \mu_{1,3} &=   &\text{P}(\pi/2, 3)&=0 \\
   \end{array}
   \right.
\end{equation}
where 10.7 comes from
$
10.7 \approx  - \log (0.5\exp(-64\times2) + 0.5\exp(-5\times2))
$
 and 5.7 comes from $5.7\approx  - \log (0.5\exp(-64\times1) + 0.5\exp(-5\times1)) $.
The standard CT reconstruction algorithm is to find $\boldsymbol \mu_{\CT}$ such that
$$
\boldsymbol \mu_\CT = \underset{\boldsymbol \mu}{\mbox{argmin}}
\| A \boldsymbol \mu - \text{P} \|_{\ell_2}^2, $$
where $\A$ is the $9\times 9$ matrix corresponding to the Radon transform in \eqref{RT} and  $\mu$  can be understood as a vectorized version.  The reconstructed image using the formula $\mu_\CT =(\A^T\A)^{-1}\A^T \text{P}$ is given by $$
\left(
\begin{array}{ccc}
   -1.0 &   2.2 & 0.4\\
   6.8 &   2.5 &  6.3 \\
   0.2 &  -0.5 & 0.7\\
\end{array}
\right).
$$ Note that the reconstructed image $\boldsymbol{\mu}_{\text{CT}}$ significantly deviates from the true solution in \eqref{sol} owing to the backprojection process $\A^T\text{P}$.
This discrepancy can be attributed to the single mismatch observed in the 8th equation of \eqref{RT}, where $\text{P}(\pi/2, 2)=10.7\neq 2\times 5.7$.
\end{remark}



% Figure environment removed

\subsection{Implicit neural representation-based MAR}
Conventional CBCT reconstructions use a pixel or voxel-based approach to represent images; however, using this approach in low-dose dental CBCT is challenging owing to the large dimension of the solution space and inconsistent data in the presence of metal implants. To address these issues, it is crucial to incorporate an image prior that constrains the relationships between pixels based on underlying head anatomy. Although regularization techniques are commonly used for this purpose, their performance is limited because they lack global control between pixels.

By contrast, neural representations using multilayer perceptrons (MLPs) utilize implicit representations that can capture complex relationships between image pixels more efficiently. These representations enable a significant reduction in the dimensions of the solution space, thus offering a more efficient and accurate reconstruction with highly undersampled data.


Our approach to solving the inverse problem of dental CBCT is inspired by the recent success of NeRF in accurately representing 3D scenes derived from 2D camera data using a deep learning network. The proposed approach uses MLP to encode CT representations. The MLP takes a 3D point $\x=(x,y,z)$ as the input and outputs the attenuation coefficient $\mu(\x)=\mu(\x,E_0)$ and its energy-dependent beam-hardening factor $\sigma(\x):=\frac{\partial}{\partial E}\mu (\x, E_0)$.
\begin{equation}\label{MARNeRF}
   f_\Theta: \x \mapsto (\mu(\x), \sigma(\x)) .
\end{equation}
Instead of directly computing the attenuation coefficient $\mu(\x)$, we use $f_\Theta$ rather than the standard expression for $\mu$ because it provides a more concise representation of the CT image while producing the same $\mu(\x)$ as the standard expression. This compact implicit expression allows us to solve the inverse problem with highly undersampled data $\text{P}$.

To learn function $f_\Theta$, we minimize the difference between the measured data $\text{P}$ (ground truth) and the predicted data $\hat{\text{P}}$, generated using the output of $f_\Theta$. The loss function is defined as
\begin{equation}\label{linear-approximation3-0}
   \mathcal L = \f{1}{|\mS|}\sum_{ (\varphi,u,v) \in \mathcal S} |\hat{\text{P}}(\varphi,u,v) -\text{P}(\varphi,u,v)|,
\end{equation}
where $\mathcal S$ represents the set of X-rays that pass through the detector positions.

Next, we explain computing $\hat{\text{P}}(\varphi,u,v)$ from $f_\Theta$. Consider the X-ray path $\br(t)={\bf o}_{\varphi}+ t\bd_{\varphi,u,v}$, $t\in [0,L]$, where ${\bf o}_{\varphi}$ is the X-ray source position and $\bd_{\varphi,u,v}=(\sin\varphi,-\cos\varphi, \beta v)$ is a direction vector of the X-ray corresponding to the position $(\varphi, u, v)$ in the projection data $\text{P}$. This path is defined for $t\in [0,L]$, where $L$ is the path length.

We use $f_\Theta$ to compute $\mu (\br(t))$ and $\sigma (\br(t))$.
A careful analysis reveals that $\hat{\text{P}}(\varphi,u,v)$ can be approximately computed as follows.
\begin{equation}\label{linear-approximation3}
 \hat{\text{P}}(\varphi,u,v)= \int_0^L \mu(\br(t)) dt -\ln \left(\frac{ \mbox{sinh}(\lambda \int_0^L \sigma(\br(t))dt) }{\lambda \int_0^L \sigma(\br(t))dt} \right),
\end{equation}
where $\lambda>0$ is a constant depending on CBCT scanning system.


Now, we provide the proof of \eqref{linear-approximation3}.
From the Beer-Lambert law \eqref{Lambert-Beer-law}, we have
\begin{align}\label{linear-approximation4}
   \text{P}(\varphi,u,v) &= -\ln \int_{E_{\text{min}}}^{E_{\text{max}}} \eta(E)\exp\left[-\int_0^L \mu (\br(t), E_0) \right. \nonumber\\
   &\left. + (E-E_0)\frac{\partial}{\partial E}\mu (\br(t), E_0)dt\right ] dE,
\end{align}
where $E_0$ is a reference energy level and the partial derivative of the attenuation coefficient $\mu$ with respect to photon energy $E$ is evaluated at $E_0$. This expression leads to the following approximation.

\begin{align}\label{linear-approximation2}
  \text{P}(\varphi,u,v) & \approx \int_0^L \mu (\br(t)) dt \nonumber\\ &- \ln \int_{-1}^{1} \frac{1}{2}\exp\left[- \lambda s\int_0^L \sigma (\br(t))dt\right ] ds.
\end{align}
Direct computation of \eqref{linear-approximation2} yields \eqref{linear-approximation3}, which completes the proof.


In practice, accurately estimating the parameter $\lambda$ in $\hat{\text{P}}$ is challenging. Alternatively, for any constant $\hat{\lambda}$, $\hat{\text{P}}$ can be reformulated as follows.
\begin{align}\label{linear-approximation5}
 \hat{\text{P}}(\varphi,u,v)&= \int_0^L \mu(\br(t)) dt \nonumber\\ & -\ln \left(\frac{ \mbox{sinh}\left(\hat{\lambda} \left(\int_0^L \tilde{\sigma}(\br(t))dt +\eps\right)\right)}{\tilde{\lambda} \left(\int_0^L \tilde{\sigma}(\br(t))dt +\eps\right)}  \right),
\end{align}
where $\tilde{\sigma}$ is a scaled version of $\sigma$, expressed as  $\tilde{\sigma}= (\lambda\slash\tilde{\lambda})|\sigma|$. Based on this formulation, we train $f_{\Theta}$ to provide $(\mu, \tilde{\sigma})$ with a suitably selected $\tilde{\lambda}$. In eq. \eref{linear-approximation5}, to ensure training stability and avoid division by zero, we incorporate a small positive value $\epsilon > 0$ in the numerator and denominator of $\hat{\text{P}}$. In this study, we consistently set $\tilde{\lambda}$ to three, which demonstrates stable performance across our experiments. 

\subsection{Implicit Neural Representations with Sinusoidal Activations}
To enhance the ability of the network $f_\Theta$ to accurately model data with high frequency variations, the  $f_\Theta$ is designed with a sinusoidal activation function \cite{Sitzmann2020}:
\begin{align}
f_\Theta(\x) = \W_n\left(\psi_{n-1}\circ \psi_{n-2}\circ\cdots\circ\psi_0\right)(\x) + \bb_n,
\end{align}
where $\W_i$ and $\bb_i$ are the weight and bias at the $i^{th}$ layer of the network, respectively. Further, $\psi_i$ is the $i^{th}$ layer of the network and is expressed as:
\begin{align}
\psi_i (\x_i) = \sin(\W_i\x_i + \bb_i).
\end{align}
The sinusoidal activation function can better represent the function, its derivative, and Laplacian information compared with the positional encoding method \cite{Mildenhall2021,Tancik2020}, which applies a serious of sine and cosine transforms to the input coordinates $\x$.

In our experiments, $f_\Theta$ consisted of five fully connected layers in between input and output layers. Each fully connected layer comprises 128 nodes, whereas the input and output layers each consist of two nodes. The network weights were updated using the Adam optimizer \cite{Kingma2015} at a learning rate of $5\times10^{-4}$. The training process was terminated when the loss function value in \eref{linear-approximation3-0} fell below $5\times10^{-3}$ for the numerical simulation and $9\times10^{-3}$ for the phantom experiment. The training procedure is implemented using PyTorch \cite{Paszke2019} on a system equipped with two CPUs (Intel(R) Xeon Gold 6226R, 2.9 GHz) and a GPU (NVIDIA RTX 3090, 24GB). Training the network per 2D CT image took approximately 3--5 min.

% Figure environment removed

% Figure environment removed


\begin{remark} In the field of medical tomographic image reconstruction, the conventional approach typically relies on a pixel-based (or voxel-based) representation, where each pixel corresponds to a dimension in the solution space. This process is particularly challenging when faced with a highly ill-posed reconstruction problem. The objective is to explore a vast solution space to and identify a single point that accurately represents the desired image. However, due to the inherent high-resolution nature of medical imaging, the solution space is primarily dominated by noise-like images, while practical solutions that resemble actual medical images occupy an incredibly small fraction, practically negligible in terms of probability. To mitigate these difficulties, researchers have developed various regularization techniques over the past several decades. These techniques aim to impose strong constraints on the solution to improve the reconstruction outcomes. However, these regularization methods often exhibit limited performance and loss of intricate details in the images. Implicit neural representation through MLPs shows promise for overcoming these limitations by optimizing its parameters to effectively search for the most appropriate solution within its architecture, thus offering a potential breakthrough in the field.
\end{remark}

\section{Results}
\subsection{Numerical Simulation}
To assess the effectiveness of the proposed method, we conducted a performance evaluation using a 2D numerical phantom. The phantom consisted of teeth, bones, and multiple crowns, as shown in Fig. \ref{fig-num-result}. Individual teeth were segmented as in \cite{Jang2021}, and a virtual crown was generated using dilation and erosion functions as in \cite{Hyun2022,Park2022}. The geometries of the teeth and bones were obtained by manually segmenting a real CBCT image.

The generated teeth, bone, and crowns were projected based on the X-ray polychromatic model in \eref{Lambert-Beer-law}. Here, we utilized the attenuation coefficients provided by the National Institute of Standards and Technology \cite{Hubbell1995} along with the energy spectrum $\eta(E)$ generated using the Spektr software \cite{Punnoose2016} at a tube voltage of 100 kVp. The crowns were composed of titanium. Additionally, we added Poisson and electric noise to the projection data, and disregarding other factors, such as photon starvation, scattering, and nonlinear partial volume effects. All $413\times 413$ was reconstructed with a pixel size of $0.4~\text{mm} \times 0.4~\text{mm}$.

We compared the performance of the proposed method with that of FBP and metal beam hardening correction (MBHC) methods. The FBP images were reconstructed using a standard Ram-Lak filter. In the MBHC method, the beam-hardening artifacts caused by metals were addressed using the following correction formula:
\begin{align}\label{bhc_formula}
  \phi_{D,\kappa}(\x) = -\mR^{-1}\left[\ln\left(\f{\sinh(\kappa\mR\chi_D)}{\kappa\mR\chi_D}\right)\right](\x).
\end{align}
In this method, we segmented the metal region $D$ using a simple thresholding approach. The optimal parameter $\kappa$ was chosen as $\kappa = 3$ based on Equation (17) in \cite{Park2015}. Based on \eref{linear-approximation2}, the two parameters $\kappa$ in \eref{bhc_formula} and $\lambda$ in \eref{linear-approximation3} are related as follows.
$$\kappa = -\alpha\lambda,$$
where the parameter $\alpha$ is defined as $\alpha=\f{\p}{\p E}\mu(\x,\E_0), \x\in D$.

Fig. \ref{fig-num-result} compares the reconstruction results for the numerical phantom. The second and third columns show CT images reconstructed using FBP and MBHC, respectively, whereas the fourth and fifth columns show that of the proposed method. The second and fourth rows show the backgrounds of the reconstructed CT images, which correspond to the air region (i.e., $\mu(\x)=0, \sigma(\x)=0$) without teeth, bones, and crowns. The mean absolute error (MAE) was computed and is listed in the upper-left corner of each background image.

Evidently, the FBP image suffered from severe streaking and shadow artifacts, primarily owing to the beam hardening effect caused by the crowns and teeth. The MBHC method reduced the metal beam-hardening artifacts between crowns in the FBP image. However, the artifacts from the interaction between the crowns and teeth remained (red arrows in the third column) because the metal beam-hardening corrector $\phi_{D,\kappa}$ only addresses the interactions between crowns.

The proposed method successfully reconstructed the attenuation ($\mu$) and its scaled energy dependent beam hardening factor ($\tilde{\sigma}$) images. The proposed method, as opposed to FBP and MBHC methods, successfully reduced the streaking and shadowing artifacts in the reconstructed images. Notably, the proposed method mitigated the discretization error introduced during the standard backprojection process (yellow arrows in the third column). Quantitative analysis revealed that the proposed method achieved the lowest MAE compared with the FBP and MBHC methods.

We further investigated the performance of the proposed method for the photon starvation effect. The relationship described in \eref{linear-approximation3} is valid when sufficient X-ray photons reach the detector. Assuming that the metal trace of the numerical phantom was significantly affected by photon starvation, we trained the neural network $f_{\Theta}$ in (\ref{MARNeRF}) using a subset of X-rays, denoted by $\mS_t\subseteq \mS$, passing through the teeth and bone only.

Fig. \ref{fig-num-result_ps} compares the reconstruction results of the proposed method trained using the sets $\mS$ (labeled as `w/o photon starvation') and $\mS_t$ (labeled as `w/ photon starvation'). For photon starvation, crown masks were added to the reconstructed image. As indicated by the red arrows, the proposed method trained using $\mS_t$ faced challenges in fully restoring the teeth surrounded by crowns owing to limited information available for recovery. However, the proposed method successfully recovered the morphological structures of the teeth near the crowns.


\subsection{Phantom Experiment}

The phantom experiment was conducted using an industrial CBCT scanner equipped with a flat-panel detector (DUKIN, Korea). The resolution phantom containing the three metallic bolts was scanned using a tube voltage of 160 kVp and tube current of 3.0 mAs. A comparison was performed on the sinogram corresponding to the midplane of the CBCT scan. All CBCT images of size $512\times 512$ were reconstructed with a pixel size of $0.2~\text{mm} \times 0.2~\text{mm}$. The MBHC method corrects metal artifacts using \eref{bhc_formula} with the parameter $\kappa=1$. In the proposed method, the estimate $\hat{\text{P}}$ in \eref{linear-approximation5} is computed using a fan-beam projection operator \cite{Feldkamp1984}. % kappa = 0.025/0.02/0.1

Fig. \ref{fig-phan_exp} compares the reconstruction results for the experiment phantom. The first row shows CT images reconstructed using FBP, MBHC, and the proposed method. The insets represent enlarged metal regions, thus highlighting the presence of cupping artifacts. The second row shows background images of the resolution phantom. A background mask was generated manually from the FBP image. The MBHC and proposed method reduced the cupping artifacts in the reconstructed image. Compared with the MBHC method, the proposed method more effectively reduced the streaking and shadowing artifacts caused by the three metallic bolts in the reconstructed images while preserving the structures of the resolution phantom (red arrows in the first row). However, as indicated by the yellow arrow, additional artifacts were introduced in the reconstructed image obtained by the proposed method, possibly owing to other causes of metal artifacts, such as scattering. For a quantitative evaluation, MSEs were computed in the background region. The proposed method demonstrated the lowest MSE value.


%%%%%%%%%%%%%%%%%%
\section{Discussion and Conclusion}
This study presented an innovative approach for MAR in dental CBCT by harnessing the regularization power of implicit neural representation techniques. The MLP supplementary output, which captures the nonlinear beam-hardening factor stemming from the polychromatic nature of the X-ray beams, is critical in generating high-quality cross-sectional images. By integrating the MLP with a modified Beer-Lambert law and incorporating X-ray casting of point samples, the proposed method effectively mitigates beam-hardening artifacts, substantially enhancing the overall image quality and increasing the clinical relevance of dental CBCT imaging.


Recently, Kim et al. \cite{Kim2022} introduced an implicit neural representation-based approach for CT reconstruction. Their work focused primarily on sparse-view CT reconstruction and did not specifically address the challenging tasks of MAR. Furthermore, their method relied on existing CT reconstruction techniques. By contrast, our study fills this gap by presenting a novel approach for specifically addressing the MAR in dental CBCT, thereby paving the way for improved image quality. Because our approach is in its initial stages, it can be further improved, thus holding the potential to revolutionize the field of low-dose CT reconstruction.

Implicit neural representations offer substantial advantages over traditional grid-based representations, such as pixels and voxels, particularly in solving ill-posed image reconstruction problems. A key advantage is their resolution-independent capability, wherein the representation capacity is determined by the MPLs capacity rather than the grid resolution. MLPs can capture the underlying structure of an image while minimizing redundancy in the representation without sacrificing accuracy or information content.

Our ongoing research aims to enhance the proposed method based on implicit neural representation, focusing on two critical aspects: improving computational time and achieving accurate 3D reconstruction in dental CBCT. To enhance computational efficiency, the implementation of pre-trained parameters can be investigated using transfer learning, specifically leveraging image priors in dental CBCT. Although our experiments have shown promising capabilities for removing metal-induced artifacts, residual artifacts, particularly thread-like structures, were observed around metal objects. This observation indicates a minor discrepancy between the rendered model used in our method and real-world clinical CBCT data. Therefore, our ongoing research focuses on refining our mathematical model to better align it with the intricacies and nuances of clinical CBCT data.


%\section*{Acknowledgements}
%H.S.P. and K. J were supported by  the National Institute for Mathematical Sciences (NIMS) grant funded by the Korean government (No. NIMS-B23910000). J.K.S was partially supported by Samsung Science $\&$ Technology Foundation (No. SRFC-IT1902-09).

% Generated by IEEEtran.bst, version: 1.14 (2015/08/26)
\begin{thebibliography}{10}
\providecommand{\url}[1]{#1}
\csname url@samestyle\endcsname
\providecommand{\newblock}{\relax}
\providecommand{\bibinfo}[2]{#2}
\providecommand{\BIBentrySTDinterwordspacing}{\spaceskip=0pt\relax}
\providecommand{\BIBentryALTinterwordstretchfactor}{4}
\providecommand{\BIBentryALTinterwordspacing}{\spaceskip=\fontdimen2\font plus
\BIBentryALTinterwordstretchfactor\fontdimen3\font minus
  \fontdimen4\font\relax}
\providecommand{\BIBforeignlanguage}[2]{{%
\expandafter\ifx\csname l@#1\endcsname\relax
\typeout{** WARNING: IEEEtran.bst: No hyphenation pattern has been}%
\typeout{** loaded for the language `#1'. Using the pattern for}%
\typeout{** the default language instead.}%
\else
\language=\csname l@#1\endcsname
\fi
#2}}
\providecommand{\BIBdecl}{\relax}
\BIBdecl

\bibitem{Bracewell1967}
R.~N. Bracewell and A.~Riddle, ``Inversion of fan-beam scans in radio
  astronomy,'' \emph{Astrophysical Journal, vol. 150, p. 427}, vol. 150, p.
  427, 1967.

\bibitem{Feldkamp1984}
L.~A. Feldkamp, L.~C. Davis, and J.~W. Kress, ``Practical cone-beam
  algorithm,'' \emph{Josa a}, vol.~1, no.~6, pp. 612--619, 1984.

\bibitem{Pauwels2014}
R.~Pauwels, O.~Silkosessak, R.~Jacobs, R.~Bogaerts, H.~Bosmans, and
  S.~Panmekiate, ``A pragmatic approach to determine the optimal kvp in cone
  beam ct: balancing contrast-to-noise ratio and radiation dose,''
  \emph{Dentomaxillofacial Radiology}, vol.~43, no.~5, p. 20140059, 2014.

\bibitem{Abdoli2010}
M.~Abdoli, M.~R. Ay, A.~Ahmadian, R.~A. J.~O. Dierckx, and H.~Zaidi,
  ``{Reduction of dental filling metallic artifacts in CT-based attenuation
  correction of PET data using weighted virtual sinograms optimized by a
  genetic algorithm},'' \emph{Medical Physics}, vol.~37, no.~12, pp.
  6166--6177, 2010.

\bibitem{Kalender1987}
W.~A. Kalender, R.~Hebel, and J.~Ebersberger, ``{Reduction of CT artifacts
  caused by metallic implants},'' \emph{Radiology}, vol. 164, no.~2, pp.
  576--577, 1987.

\bibitem{Lewitt1978}
R.~M. Lewitt and R.~H.~T. Bates, ``{Image reconstruction from projections: IV.
  Projection completion methods (computational examples)},'' \emph{Optik},
  vol.~50, pp. 269--278, 1978.

\bibitem{Meyer2010}
E.~Meyer, R.~Raupach, M.~Lell, B.~Schmidt, and M.~Kachelrie{\ss}, ``{Normalized
  metal artifact reduction (NMAR) in computed tomography},'' \emph{Medical
  Physics}, vol.~37, no.~10, pp. 5482--5493, 2010.

\bibitem{Park2013}
H.~S. Park, J.~K. Choi, K.-R. Park, K.~S. Kim, S.-H. Lee, J.~C. Ye, and J.~K.
  Seo, ``{Metal artifact reduction in CT by identifying missing data hidden in
  metals},'' \emph{Journal of X-ray Science and Technology}, vol.~21, no.~3,
  pp. 357--372, 2013.

\bibitem{Roeske2003}
J.~C. Roeske, C.~Lund, C.~A. Pelizzari, X.~Pan, and A.~J. Mundt, ``{Reduction
  of computed tomography metal artifacts due to the Fletcher-Suit applicator in
  gynecology patients receiving intracavitary brachytherapy},''
  \emph{Brachytherapy}, vol.~2, no.~4, pp. 207--214, 2003.

\bibitem{Zhao2000}
S.~Zhao, D.~Robeltson, G.~Wang, B.~Whiting, and K.~Bae, ``{X-ray CT metal
  artifact reduction using wavelets: an application for imaging total hip
  prostheses},'' \emph{IEEE Transactions on Medical Imaging}, vol.~19, no.~12,
  pp. 1238--1247, 2000.

\bibitem{DeMan2001}
B.~D. Man, J.~Nuyts, P.~Dupont, G.~Marchal, and P.~Suetens, ``{An iterative
  maximum-likelihood polychromatic algorithm for CT},'' \emph{IEEE Transactions
  on Medical Imaging}, vol.~20, no.~10, pp. 999--1008, 2001.

\bibitem{Elbakri2002}
I.~A. Elbakri and J.~A. Fessler, ``{Statistical Image Reconstruction for
  Polyenergetic X-Ray Computed Tomography},'' \emph{IEEE Transactions on
  Medical Imaging}, vol.~21, no.~2, pp. 89--99, 2002.

\bibitem{Menvielle2005}
N.~Menvielle, Y.~Goussard, D.~Orban, and G.~Soulez, ``{Reduction of
  Beam-Hardening Artifacts in X-Ray CT},'' in \emph{IEEE Engineering in
  Medicine and Biology 27th Annual Conference}, 2005, pp. 1865--1868.

\bibitem{OSullivan2007}
J.~A. O'Sullivan and J.~Benac, ``{Alternating minimization algorithms for
  transmission tomography},'' \emph{IEEE Transactions on Medical Imaging},
  vol.~26, no.~3, pp. 283--297, 2007.

\bibitem{Wang1996}
G.~Wang, D.~Snyder, J.~O'Sullivan, and M.~Vannier, ``{Iterative deblurring for
  CT metal artifact reduction},'' \emph{IEEE Transactions on Medical Imaging},
  vol.~15, no.~5, pp. 657--664, 1996.

\bibitem{Alvarez1976}
R.~E. Alvarez and A.~Macovski, ``{Energy-selective reconstructions in x-ray
  computerised tomography},'' \emph{Physics in Medicine \& Biology}, vol.~21,
  no.~5, pp. 733--744, 1976.

\bibitem{Lehmann1981}
L.~A. Lehmann, R.~E. Alvarez, A.~Macovski, W.~R. Brody, N.~J. Pelc, S.~J.
  Riederer, and A.~L. Hall, ``{Generalized image combinations in dual KVP
  digital radiography},'' \emph{Medical Physics}, vol.~8, no.~5, pp. 659--667,
  1981.

\bibitem{Yu2012}
L.~Yu, S.~Leng, and C.~H. McCollough, ``{Dual-energy CT-based monochromatic
  imaging},'' \emph{American Journal of Roentgenology}, vol. 199, pp. S9--S15,
  2012.

\bibitem{Layer2023}
Y.~C. Layer, N.~Mesropyan, P.~A. Kupczyk, J.~A. Luetkens, A.~Isaak, T.~Dell,
  U.~I. Attenberger, and D.~Kuetting, ``Combining iterative metal artifact
  reduction and virtual monoenergetic images severely reduces hip
  prosthesis-associated artifacts in photon-counting detector ct,''
  \emph{Scientific Reports}, vol.~13, no.~1, p. 8955, 2023.

\bibitem{Patzer2023}
T.~S. Patzer, A.~S. Kunz, H.~Huflage, P.~Gruschwitz, P.~Pannenbecker, S.~Afat,
  J.~Herrmann, B.~Petritsch, T.~A. Bley, and J.-P. Grunz, ``Combining virtual
  monoenergetic imaging and iterative metal artifact reduction in
  first-generation photon-counting computed tomography of patients with dental
  implants,'' \emph{European Radiology}, pp. 1--12, 2023.

\bibitem{Gjesteby2017}
L.~Gjesteby, Q.~Yang, Y.~Xi, H.~Shan, B.~Claus, Y.~Jin, B.~D. Man, and G.~Wang,
  ``{Deep learning methods for CT image-domain metal artifact reduction},'' in
  \emph{Proceedings Volume 10391, Developments in X-Ray Tomography XI}, 2017.

\bibitem{Nakao2020}
M.~Nakao, K.~Imanishi, N.~Ueda, Y.~Imai, T.~Kirita, and T.~Matsuda,
  ``{Regularized Three-Dimensional Generative Adversarial Nets for Unsupervised
  Metal Artifact Reduction in Head and Neck CT Images},'' \emph{IEEE Access},
  vol.~8, pp. 109\,453--109\,465, 2020.

\bibitem{Zhang2018-1}
Y.~Zhang and H.~Yu, ``{Convolutional Neural Network Based Metal Artifact
  Reduction in X-Ray Computed Tomography},'' \emph{IEEE Transactions on Medical
  Imaging}, vol.~37, no.~6, pp. 1370--1381, 2018.

\bibitem{Park2018}
H.~S. Park, S.~M. Lee, H.~P. Kim, J.~K. Seo, and Y.~E. Chung, ``{CT
  sinogram-consistency learning for metal-induced beam hardening correction},''
  \emph{Medical Physics}, vol.~45, no.~12, pp. 5376--5384, 2018.

\bibitem{Lin2019}
W.-A. Lin, H.~Liao, C.~Peng, X.~Sun, J.~Zhang, J.~Luo, R.~Chellappa, and S.~K.
  Zhou, ``{DuDoNet: Dual Domain Network for CT Metal Artifact Reduction},'' in
  \emph{IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  2019, pp. 10\,512--10\,521.

\bibitem{Zhang2020}
L.~Yu, Z.~Zhang, X.~Li, and L.~Xing, ``{Deep Sinogram Completion With Image
  Prior for Metal Artifact Reduction in CT Images},'' \emph{IEEE Transactions
  on Medical Imaging}, vol.~40, no.~1, pp. 228--238, 2021.

\bibitem{Mildenhall2021}
B.~Mildenhall, P.~P. Srinivasan, M.~Tancik, J.~T. Barron, R.~Ramamoorthi, and
  R.~Ng, ``Nerf: Representing scenes as neural radiance fields for view
  synthesis,'' \emph{Communications of the ACM}, vol.~65, no.~1, pp. 99--106,
  2021.

\bibitem{Beer1852}
A.~Beer, ``Bestimmung der absorption des rothen lichts in farbigen
  flussigkeiten,'' \emph{Ann. Physik}, vol. 162, pp. 78--88, 1852.

\bibitem{Lambert1892}
J.~H. Lambert, \emph{Lambert's Photometrie:(Photometria, sive De mensura et
  gradibus luminis, colorum et umbrae)(1760)}.\hskip 1em plus 0.5em minus
  0.4em\relax W. Engelmann, 1892, no. 31-33.

\bibitem{Herman1983}
G.~T. Herman and S.~S. Trivedi, ``A comparative study of two postreconstruction
  beam hardening correction methods,'' \emph{IEEE transactions on medical
  imaging}, vol.~2, no.~3, pp. 128--135, 1983.

\bibitem{Park2015}
H.~S. Park, D.~Hwang, and J.~K. Seo, ``Metal artifact reduction for
  polychromatic x-ray ct based on a beam-hardening corrector,'' \emph{IEEE
  transactions on medical imaging}, vol.~35, no.~2, pp. 480--487, 2015.

\bibitem{Park2017}
H.~S. Park, J.~K. Choi, and J.~K. Seo, ``Characterization of metal artifacts in
  x-ray computed tomography,'' \emph{Communications on Pure and Applied
  Mathematics}, vol.~70, no.~11, pp. 2191--2217, 2017.

\bibitem{Sitzmann2020}
V.~Sitzmann, J.~Martel, A.~Bergman, D.~Lindell, and G.~Wetzstein, ``Implicit
  neural representations with periodic activation functions,'' \emph{Advances
  in Neural Information Processing Systems}, vol.~33, pp. 7462--7473, 2020.

\bibitem{Tancik2020}
M.~Tancik, P.~Srinivasan, B.~Mildenhall, S.~Fridovich-Keil, N.~Raghavan,
  U.~Singhal, R.~Ramamoorthi, J.~Barron, and R.~Ng, ``Fourier features let
  networks learn high frequency functions in low dimensional domains,''
  \emph{Advances in Neural Information Processing Systems}, vol.~33, pp.
  7537--7547, 2020.

\bibitem{Kingma2015}
D.~Kingma and J.~Ba, ``Adam: A method for stochastic optimization in:
  Proceedings of the 3rd international conference for learning representations
  (iclrâ€™15),'' \emph{San Diego}, vol. 500, 2015.

\bibitem{Paszke2019}
A.~Paszke, S.~Gross, F.~Massa, A.~Lerer, J.~Bradbury, G.~Chanan, T.~Killeen,
  Z.~Lin, N.~Gimelshein, L.~Antiga \emph{et~al.}, ``Pytorch: An imperative
  style, high-performance deep learning library,'' \emph{Advances in neural
  information processing systems}, vol.~32, 2019.

\bibitem{Jang2021}
T.~J. Jang, K.~C. Kim, H.~C. Cho, and J.~K. Seo, ``A fully automated method for
  3d individual tooth identification and segmentation in dental cbct,''
  \emph{IEEE transactions on pattern analysis and machine intelligence},
  vol.~44, no.~10, pp. 6562--6568, 2021.

\bibitem{Hyun2022}
C.~M. Hyun, T.~Bayaraa, H.~S. Yun, T.-J. Jang, H.~S. Park, and J.~K. Seo,
  ``Deep learning method for reducing metal artifacts in dental cone-beam ct
  using supplementary information from intra-oral scan,'' \emph{Physics in
  Medicine \& Biology}, vol.~67, no.~17, p. 175007, 2022.

\bibitem{Park2022}
H.~S. Park, J.~K. Seo, C.~M. Hyun, S.~M. Lee, and K.~Jeon, ``A
  fidelity-embedded learning for metal artifact reduction in dental cbct,''
  \emph{Medical Physics}, vol.~49, no.~8, pp. 5195--5205, 2022.

\bibitem{Hubbell1995}
J.~H. Hubbell and S.~M. Seltzer, ``Tables of x-ray mass attenuation
  coefficients and mass energy-absorption coefficients 1 kev to 20 mev for
  elements z= 1 to 92 and 48 additional substances of dosimetric interest,''
  National Inst. of Standards and Technology-PL, Gaithersburg, MD (United~â€¦,
  Tech. Rep., 1995.

\bibitem{Punnoose2016}
J.~Punnoose, J.~Xu, A.~Sisniega, W.~Zbijewski, and J.~Siewerdsen, ``spektr
  3.0â€”a computational tool for x-ray spectrum modeling and analysis,''
  \emph{Medical physics}, vol.~43, no. 8Part1, pp. 4711--4717, 2016.

\bibitem{Kim2022}
B.~Kim, H.~Shim, and J.~Baek, ``A streak artifact reduction algorithm in
  sparse-view ct using a self-supervised neural representation,'' \emph{Medical
  physics}, vol.~49, no.~12, pp. 7497--7515, 2022.

\end{thebibliography}


% \bibliographystyle{IEEEtran}
% \bibliography{reference}

\stop

