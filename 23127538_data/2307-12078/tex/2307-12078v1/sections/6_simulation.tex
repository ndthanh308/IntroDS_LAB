\section{Numerical Example}
\label{sec:numerical}

In this section, we consider a numerical example of a sensor network consisting of $13$ uncrewed aerial vehicles (UAVs) positioned in a $3$-dimensional configuration. It is assumed that the UAVs are able to measure their distances from the others in their vicinity by using ultra wideband (UWB) ranging \cite{cao2021relative}. The SCP algorithm (given in Algorithm \ref{alg:scp}) is used to process the distance measurements, identify the UAVs having localization errors, as well as recover their true positions.

The details of the numerical example are as follows; the network of UAVs is represented by a graph $\mathcal G=(\mathcal V, \mathcal E)$ having $13$ vertices and $36$ edges, where the vertices represent the UAVs and the edges correspond to the availability of distance measurements between them. The sensor network's configuration is determined by the positions of its vertices in $\mathbb R^3$ (shown in Fig. \ref{fig:single_run}), which are collectively represented by the block vector $\bold p$. Each UAV uses a suite of onboard sensors such as inertial navigation systems (INS), visual odometry, and GNSS receivers to estimate its own position, such that the position estimates of the UAVs are collectively represented by the block vector, $\hat{\bold p}$. 
Due to GNSS multipath errors and/or spoofing of GNSS signals, a subset of the UAVs, $\mathcal D\subseteq \mathcal V$, have localization errors.

Letting $\bold R_D$ denote the distance rigidity matrix of the sensor network, we have that the $7^{th}$-smallest eigenvalue of $\bold R_D^\top \bold R_D$ is equal to $0.334$, whereas $6$ of its eigenvalues are smaller than $10^{-14}$ (i.e., are close to zero). Using Lemma \ref{lemma:distance_rigidity_properties}, we know that the rank of $\bold R_D$ is maximal, and thus, the sensor network is infinitesimally rigid.
Using Theorem \ref{theorem:3d_lq_recovery}, we compute that $l_2/l_1$ minimization can be used to uniquely recover the localization error vector, $\bold x=\bold p - \hat{\bold p}$, as long as the number of localization errors is no greater than $6$. In the presence of linearization error (which was not considered in Theorem \ref{theorem:3d_lq_recovery}), the number of localization errors which can be recovered with certainty turns out to be about $4$, as demonstrated in Section \ref{subsection:n_faulty}.

\subsection{Noise-Free Case}
\label{subsection:sim_noisefree}
We first consider the noise-free case, where the measurement noise vector $\bold e$ is set to $\bold 0$, and the agents without localization errors are assumed to have perfect estimates, i.e., $\hat {\bold p}_{\mathcal D^\complement} = \bold p_{\mathcal D^\complement}$. The set of localization errors, $\mathcal D$, is constructed by randomly selecting $4$ agents from $\mathcal V$. For each agent in $\mathcal D$, its localization error is chosen by generating independent samples from a random vector having the uniform distribution over the $3$-dimensional unit cube. 

Figure \ref{fig:single_run} shows the non-zero blocks of the vector $\bold x^*$ recovered by the SCP algorithm (Algorithm \ref{alg:scp}) after $4$ iterations, along with the blocks of $\bold p$ and $\hat{\bold p}$ (which represent the true and estimated positions of each of the agents, respectively), demonstrating that the proposed $l_2/l_1$ minimization approach is able to uniquely recover the localization error vector as expected. For the SCP algorithm, its parameters $\epsilon_0$ and $\rho$ were chosen as $4.0$ and $3.0$, respectively, based on an iterative parameter tuning process.
% , combined with the knowledge that the localization errors are on the order of $1m$ for each of the agents in $\mathcal D$. 
Figure \ref{fig:error_vs_scp_iterations} shows the relative approximation error, defined as $\|\bold x - \bold x^*\|_2 / \| \bold x \|_2$, as a function of the number of SCP iterations, showing that a larger number of SCP iterations can be used to improve the accuracy of the error recovery.

% Figure environment removed

% Figure environment removed

\subsection{Uncorrelated vs. Fully Correlated Errors}
\label{subsection:n_faulty}

So far, the localization errors (i.e., the non-zero blocks of $\bold x$) were sampled in an independent and identically distributed (i.i.d.) manner, such that the localization errors are \textit{uncorrelated}, i.e., $\mathbb E\left[\bold x[i] \bold x[j]^\top\right]=\bold 0$ whenever $i\neq j$. The other extreme case is that of \textit{fully correlated} localization errors, i.e., $\bold x[i]=\bold x[j],\ \forall i,j \in \mathcal D$. For either type of localization errors, we repeat the simulation scenario considered in Section \ref{subsection:sim_noisefree} for $250$ Monte Carlo trials. In each simulation, the identities of the agents in $\mathcal D$ were selected at random.

Given the block vector $\bold x^*$ obtained using the SCP algorithm, let $\hat {\mathcal D}$ denote the locations of its non-zero blocks, such that $\|\bold x[i]\|_2 > 0 \Leftrightarrow i \in \hat {\mathcal D}$.
Figure \ref{fig:error_vs_n_faulty} shows the percentage of Monte Carlo trials in which the SCP algorithm was able to identify the localization error vector correctly (i.e., $\hat {\mathcal D} = \mathcal D$) within $4$ iterations. It can be seen that the SCP algorithm is able to recover a smaller number of localization errors when the errors are fully correlated. In either case, up to $4$ localization errors were identified with a high degree of certainty.

% Figure environment removed

\subsection{Robustness}
Finally, we assess the robustness of the $l_2/l_1$ minimization approach subject to measurement noise and imperfect position estimates. We consider the simulation scenario described in Section \ref{subsection:sim_noisefree}, wherein $4$ of the UAVs (selected at random) are subject to independent random localization errors. As discussed in Section \ref{sec:robustness}, the magnitude of measurement noise is dictated by the quantity $\epsilon$. We consider the following values of $\epsilon$: $0, 1, 2, 3, 4,$ and $5$, for which the corresponding slackness reduction parameter $\rho$ of the SCP algorithm is set to $3.0, 2.0, 1.5, 1.5, 1.3,$ and $1.2$, respectively. The motivation for choosing the foregoing values of $\rho$ is that when the magnitude of measurement noise is high, a greater amount of slack is required in the constraint of problem P3 in order to make it feasible. Similarly, the initial constraint slackness $\epsilon_0$ of the SCP algorithm is set to $4 + \epsilon$, wherein the first term accommodates the $4$ localization errors, whereas the second term accommodates the measurement noise. For each simulation, we vary the value of $\kappa$ (which dictates the amount of imperfection in the position estimates of the agents in $\mathcal D^\complement$) between $0.0$ to $0.9$.

The measurement noise vector is sampled from the uniform random distribution over the surface of a sphere centred at the origin, having the radius $\epsilon$. Similarly, the position estimates are generated such that for each $i \in \mathcal D^\complement$, $\hat {\bold p}[i]$ is sampled from the uniform random distribution over the surface of a sphere centred at $\bold p[i]$, having the radius $\kappa$. Thus, both the measurement noise and the imperfection in the position estimates are random, whereas their corresponding magnitudes are chosen deterministically as $\epsilon$ and $\kappa$.
% , where $\epsilon$ and $\kappa$ are as described in Section \ref{sec:robustness}. 
This allows us to visualize the dependency of the approximation error on $\epsilon$ and $\kappa$, which is shown in Fig. \ref{fig:error_vs_measurement_error}. 
Observe that the plots in Fig. \ref{fig:error_vs_measurement_error} are bounded from above by $1.0$, indicating that while the performance of $l_2/l_1$ minimization degrades as $\epsilon$ and/or $\kappa$ increase, the $l_2/l_1$ minimization approach can partially recover the localization error vector $\bold x$ up to some approximation error. 

% Figure environment removed

\section{Conclusions}
In this paper, we developed a novel approach for recovering (i.e., identifying and reconstructing) the localization errors in a sensor network by processing inter-agent measurements such as distances and/or bearings. The proposed method brings together analytical tools from compressive sensing and rigidity theory, allowing us to establish necessary and sufficient conditions on the sensor network's configuration and connectivity which guarantee that a given number of localization errors can be recovered uniquely. The proposed $l_2/l_1$ minimization method for recovering the localization errors is an efficient convex optimization problem that circumvents the combinatorial complexity of the approaches found in the literature. Moreover, the proposed method does not require a subset of the agents of the sensor network to be labeled as the \textit{anchors}, which differentiates our method from each of the existing approaches for sensor network localization using inter-agent measurements. Using a numerical example, we demonstrated our findings and benchmarked the performance and robustness properties of the proposed $l_2/l_1$ minimization approach for detecting localization errors.

Future work on this topic will focus on developing a distributed algorithm for solving the $l_2/l_1$ minimization problem, which can be used to recover the localization errors in large-scale sensor networks consisting of autonomous agents.