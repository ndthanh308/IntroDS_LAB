\section{INTRODUCTION}
% \subsection{Background and Motivation}
% A mobile sensor network refers to a system of interconnected autonomous agents in which each agent is equipped with a suite of sensors.
Groups of autonomous systems such as rovers and uncrewed aerial vehicles (UAVs) can accomplish complex tasks in a collaborative manner.
In order to facilitate this collaboration, they are typically interconnected in terms of their sensing and/or communication capabilities, forming a sensor network. For instance, an agent of a sensor network may be able to measure its \textit{distances} from the other agents in its vicinity using received signal strength (RSS) or time of arrival (ToA) based ranging \cite{cao2021relative, sadowski2018rssi}. Similarly, cameras pointed from one vehicle to another as well as the angle of arrival (AoA) of inter-agent communications are examples of \textit{bearing} measurements which may be available between agents \cite{deghat2014localization, zhang2020bearing_aoa}. The design of efficient algorithms which utilize distance and bearing measurements to enhance the localization (i.e., position estimation) capabilities of sensor networks has been well-studied in the literature, using the theories of distance and bearing rigidity \cite{decent_dist_rigidity_2015,zhao2016localizability,zhao2019bearing}. Similarly, the theory of weak rigidity was developed recently in \cite{jing2018weak}, which can model sensor networks in which the agents are able to measure the subtended angles of their neighbors, e.g., using the time difference of arrival (TDoA) of communications or scanning radars \cite{subtended_angle_scan_TDOA}. 
% In each of the above works, the authors assume that some of the agents, called as the *anchors*, are known to be correctly localized. In particular, the identities of these anchors must be known, so that only the remaining agents (which are not anchors) need to be localized.

The academic and practical importance of inter-agent measurements stems from the observation that the onboard localization 
mechanisms of autonomous systems can incur significant errors. This is because the sensors which contribute to the position estimation, including satellite-based geopositioning systems, are susceptible to faults (such as bias, loss of signal, etc.) and cyberattacks (such as sensor spoofing and replay attacks) \cite{multipath_2013, ranyal2021unmanned}. Motivated by these concerns, several researchers have proposed the use of inter-agent measurements for detecting and identifying the localization errors \cite{xia2013distributed, lim2019detecting}. Inter-agent measurements are especially useful for identifying localization errors in low-cost and resource-constrained sensor network applications, in which it may not be possible to install expensive and/or heavy onboard components such as LiDAR sensors. 
% For instance, since the RSS or ToA of communication packets can be used to infer the inter-agent distances in wireless sensor networks, it serves as a pre-existing source of information redundancy.
Despite the practical importance and relevance of this problem, a formal theoretical treatment of it is lacking in the literature. Most theoretical works have focused on directly using the inter-agent measurements for onboard localization \cite{Eren_rigidity_randomness_2004, decent_dist_rigidity_2015,zhao2016localizability,zhao2019bearing, zhang2020bearing_aoa}, rather than addressing the question of how these measurements can be used to identify faults or cyberattacks. 
In particular, they assume that a subset of the agents, called as \textit{anchors} or \textit{beacons} in the literature, are known to be correctly localized, precluding the possibility that the anchors themselves may have localization errors; in this study, we drop the assumption that the set of correctly localized agents is known \textit{a priori}.
 
Generally, the problem of fault and/or cyberattack identification in multi-sensor systems is solved using combinatorial approaches such as fault tree analysis, or by using a bank of observers
\cite{faultdetection_2012}\cite{yang2018multi}, which are intractable for large-scale sensor networks as their computational complexity
% require centralized decision-making mechanisms, as well as 
scales exponentially with respect to the size of the network. The authors in \cite{nstacked_2015} showed that the computational complexity of fault or cyberattack detection can be reduced by
reformulating it as an $l_0$ minimization\footnote{In the literature, this is sometimes called $l_0$ ``norm" minimization; we avoid this usage as the $l_0$ operation does not satisfy the axioms of a norm
\cite{nstacked_2015}.} problem, where the $l_0$ operation, as defined, counts the number of non-zero elements of a vector.
% Similarly, \cite{jung2018residual} used cardinality minimization to solve the related problem of residual selection. 
In addition to having a lower computational complexity, the $l_0$ minimization approach is able to uniquely recover the solution of an underdetermined system of equations.
This has motivated researchers to make the additional assumption on the sparsity of the error vector (i.e., they assume that the number of faults/cyberattacks is small) enabling the use of $l_0$  minimization (or when the solution is known to be a block vector, $l_2/l_0$  minimization \cite{latushkin_null_2015}) for the detection and identification of sparse sensor faults and cyberattacks \cite{ozay_sparse_2013,nstacked_2015,attack_sparse_Lu_Yang_2022}. 
% The use of $l_0$ minimization corresponds with the assumption that the the number of agents with localization errors is some fraction (less than $1$) of the total number of agents.

Nevertheless, the $l_0$ minimization problem is still computationally expensive due to its combinatorial nature, which motivates the search for an efficient algorithm that scales well (e.g., linearly) with respect to the number of agents in the sensor network. Inspired by the abundant literature on compressive sensing, the authors of \cite{nstacked_2015} relaxed the $l_0$ minimization problem to an $l_1$ minimization problem, which is a convex optimization problem that admits efficient algorithms for finding its solution. However, $l_1$ (or in the case of block vectors, $l_2/l_1$) minimization can only recover a given number of errors uniquely and exactly when one of certain conditions is met, such as the (block) restricted isometry property or the (block) null space property (NSP) \cite{latushkin_null_2015, robust_NSP_2017, Block_COSAMP_2019}. These conditions are often ignored or assumed to hold true in the literature, as they depend on the measurement matrix and are difficult to establish \textit{a priori}, especially when the measurement matrix is a part of the problem specification (i.e., cannot be chosen arbitrarily) \cite{ozay_sparse_2013, yuan2020gps}.
% In our problem, the measurement matrix is a function of the sensor network connectivity and configuration, so we can ask (and answer) the question of which sensor networks are able to uniquely identify a given number of localization errors.

%-------- RELATED WORKS
% While there is some literature on compressive sensing 
% over graphs \cite{compressiveGraphs_2011}, as well as compressive sensing 
% for sparse attack identification \cite{Sou_Sandberg_Johansson_2013, attack_resilient_2015, nstacked_2015}, these works have not considered the structured measurement matrices that arise when inter-agent measurements such as distances or bearings are considered, which can be studied using distance or bearing rigidity theory, respectively. At the same time, the literature on rigidity theory only offers a solution for reconstructing the localization errors when the identities of the anchors are known a priori, precluding the possibility that the anchors themselves may have localization errors.
% At the same time, the literature which has explored the use of inter-agent measurements for identifying localization errors either does not incorporate ideas from compressive sensing \cite{xia2013distributed}, or does so without theoretical justification \cite{yuan2020gps}. 
% A similar approach to ours was proposed in \cite{Sou_Sandberg_Johansson_2013} for a power network problem, in which the authors exploit the special structure of the measurement matrices.
In this paper, we propose a novel method for processing the inter-agent distance or bearing measurements to recover (i.e., identify and reconstruct) the localization errors in $2$ and $3$-dimensional sensor network configurations, while addressing the aforementioned shortcomings of the existing works.
The proposed method is developed by reformulating the error recovery problem as an $l_2/l_q$ minimization problem, where $0\leq q \leq 1$. While the existing solutions for localization error identification assume that some of the agents are classified as anchors \textit{a priori}, the proposed $l_2/l_q$ minimization approach does not require this assumption; to our knowledge, the possibility of dropping the foregoing assumption has not been recognized or explored in the literature previously.
Furthermore, we establish the conditions on the sensor network's connectivity and configuration under which a given number of localization errors can be uniquely identified and corrected using the proposed $l_2/l_q$ minimization method. 
% We consider all four combinations of distance and bearing-based localization error identification in $2$ and $3$ dimensions.
% The proposed $l_2/l_q$ minimization method does not require any agents to be classified as anchors a priori, which makes it more general than 
% While existing solutions for localization error identification make the assumption that
%
Our analysis is based on the conditions for the recovery of block sparse signals borrowed from the literature on compressive sensing, which manifest as purely geometric properties of the sensor network's configuration. On the other hand, results from distance and bearing rigidity theory are used to establish the sufficient conditions on the sensor network's connectivity.
% , as well as dictate the sensitivity of the $l_2/l_q$ minimization approach to measurement noise.
% The resulting convex optimization problem can be solved using distributed algorithms similar to \cite{mota2011basis}, which makes the proposed approach scalable and well-suited for large scale sensor network applications as well. 
To demonstrate the applicability of our results, a sequential convex programming (SCP) algorithm is proposed for solving the $l_2/l_1$ minimization problem efficiently, while accommodating the nonlinearity in the measurement model.
The proposed SCP algorithm is validated using a numerical example of identifying the localization errors in a sensor network using inter-agent distance measurements.