%%
%% This is file `sample-sigplan.tex',
%% generated with the docstrip utility.
%%
%% The original source files were:
%%
%% samples.dtx  (with options: `sigplan')
%% 
%% IMPORTANT NOTICE:
%% 
%% For the copyright see the source file.
%% 
%% Any modified versions of this file must be renamed
%% with new filenames distinct from sample-sigplan.tex.
%% 
%% For distribution of the original source see the terms
%% for copying and modification in the file samples.dtx.
%% 
%% This generated file may be distributed as long as the
%% original source files, as listed above, are part of the
%% same distribution. (The sources need not necessarily be
%% in the same archive or directory.)
%%
%% Commands for TeXCount
%TC:macro \cite [option:text,text]
%TC:macro \citep [option:text,text]
%TC:macro \citet [option:text,text]
%TC:envir table 0 1
%TC:envir table* 0 1
%TC:envir tabular [ignore] word
%TC:envir displaymath 0 word
%TC:envir math 0 word
%TC:envir comment 0 0
%%
%%
%% The first command in your LaTeX source must be the \documentclass command.
\documentclass[sigconf]{acmart}%review,anonymous]
\usepackage{multirow}
\usepackage{booktabs}
\usepackage{colortbl}
\usepackage{enumitem}
\usepackage{soul} 
\usepackage{color} 
\usepackage{xcolor}
\definecolor{bestresult}{RGB}{221,238,211}
\definecolor{Green}{RGB}{112,173,71}
\definecolor{Red}{RGB}{237,125,49}
\definecolor{Purple}{RGB}{112,48,160}
\definecolor{Blue}{RGB}{101,165,223}
\definecolor{DarkBlue}{RGB}{68,114,196}
\definecolor{Yellow}{RGB}{255,192,0}
\usepackage{listings}
\lstset{ %
language=python,                % choose the language of the code
basicstyle=\footnotesize,       % the size of the fonts that are used for the code
numbers=left,                   % where to put the line-numbers
numberstyle=\footnotesize,      % the size of the fonts that are used for the line-numbers
stepnumber=1,                   % the step between two line-numbers. If it is 1 each line will be numbered
numbersep=5pt,                  % how far the line-numbers are from the code
backgroundcolor=\color{white},  % choose the background color. You must add \usepackage{color}
showspaces=false,               % show spaces adding particular underscores
showstringspaces=false,         % underline spaces within strings
showtabs=false,                 % show tabs within strings adding particular underscores
frame=single,           % adds a frame around the code
tabsize=2,          % sets default tabsize to 2 spaces
captionpos=b,           % sets the caption-position to bottom
breaklines=true,        % sets automatic line breaking
breakatwhitespace=false,    % sets if automatic breaks should only happen at whitespace
escapeinside={\%*}{*)}          % if you want to add a comment within your code
}

%% NOTE that a single column version is required for 
%% submission and peer review. This can be done by changing
%% the \doucmentclass[...]{acmart} in this template to 
%% \documentclass[manuscript,screen,review]{acmart}
%% 
%% To ensure 100% compatibility, please check the white list of
%% approved LaTeX packages to be used with the Master Article Template at
%% https://www.acm.org/publications/taps/whitelist-of-latex-packages 
%% before creating your document. The white list page provides 
%% information on how to submit additional LaTeX packages for 
%% review and adoption.
%% Fonts used in the template cannot be substituted; margin 
%% adjustments are not allowed.
%%
%% \BibTeX command to typeset BibTeX logo in the docs
%%\AtBeginDocument{%
%%  \providecommand\BibTeX{{%
%%   \normalfont B\kern-0.5em{\scshape i\kern-0.25em b}\kern-0.8em\TeX}}}

%% Rights management information.  This information is sent to you
%% when you complete the rights form.  These commands have SAMPLE
%% values in them; it is your responsibility as an author to replace
%% the commands and values with those provided to you when you
%% complete the rights form.
 %\setcopyright{acmcopyright}
%% \copyrightyear{2018}
%% \acmYear{2018}
%% \acmDOI{XXXXXXX.XXXXXXX}

%% These commands are for a PROCEEDINGS abstract or paper.
%% \acmConference[Conference acronym 'XX]{Make sure to enter the correct
%%   conference title from your rights confirmation emai}{June 03--05,
 %%  2018}{Woodstock, NY}
%
%  Uncomment \acmBooktitle if th title of the proceedings is different
%  from ``Proceedings of ...''!
%
%\acmBooktitle{Woodstock '18: ACM Symposium on Neural Gaze Detection,
%  June 03--05, 2018, Woodstock, NY} 
%\acmPrice{15.00}
%\acmISBN{978-1-4503-XXXX-X/18/06}


%%
%% Submission ID.
%% Use this when submitting an article to a sponsored event. You'll
%% receive a unique submission ID from the organizers
%% of the event, and this ID should be used as the parameter to this command.
\acmSubmissionID{2459}

%%
%% For managing citations, it is recommended to use bibliography
%% files in BibTeX format.
%%
%% You can then either use BibTeX with the ACM-Reference-Format style,
%% or BibLaTeX with the acmnumeric or acmauthoryear sytles, that include
%% support for advanced citation of software artefact from the
%% biblatex-software package, also separately available on CTAN.
%%
%% Look at the sample-*-biblatex.tex files for templates showcasing
%% the biblatex styles.
%%

%%
%% The majority of ACM publications use numbered citations and
%% references.  The command \citestyle{authoryear} switches to the
%% "author year" style.
%%
%% If you are preparing content for an event
%% sponsored by ACM SIGGRAPH, you must use the "author year" style of
%% citations and references.
%% Uncommenting
%% the next command will enable that style.
%%\citestyle{acmauthoryear}

%%
%% end of the preamble, start of the body of the document source.
\setcopyright{none}
\settopmatter{printacmref=false} % Removes citation information below abstract
\renewcommand\footnotetextcopyrightpermission[1]{} % removes footnote with conference information in first column
\pagestyle{plain}

\newcommand{\qin}[1]{{\color{red}{\bf Qin}: {#1}}}

\begin{document}

%%
%% The "title" command has an optional parameter,
%% allowing the author to define a "short title" to be used in page headers.
%\title{Visual Captioning at Will: Describing Visual Contents with the Text Style Extracted from a Few Examples}
\title{Visual Captioning at Will: Describing Images and Videos \\Guided by a Few Stylized Sentences}
%%Arbitrary Stylized Visual Captioning: Few-Shot Text Style Extraction and Cross-Modal Alignment}

%%
%% The "author" command and its associated commands are used to define
%% the authors and their affiliations.
%% Of note is the shared affiliation of the first two authors, and the
%% "authornote" and "authornotemark" commands
%% used to denote shared contribution to the research.

\author{Dingyi Yang}
\authornote{This work was completed during the author's internship at Alibaba Group.}
\email{yangdingyi@ruc.edu.cn}
\affiliation{%
  \institution{School of Information,\\ Renmin University of China}
  \state{Beijing}
  \country{China}
  \postcode{43017-6221}
}

\author{Hongyu Chen}
\email{yinchen.chy@alibaba-inc.com}
\affiliation{%
  \institution{Alibaba Group}
  \state{Beijing}
  \country{China}
}

\author{Xinglin Hou}
\email{ xingli.hxl@alibaba-inc.com}
\affiliation{%
  \institution{Alibaba Group}
  \state{Beijing}
  \country{China}
}
\author{Tiezheng Ge}
\email{ tiezheng.gtz@alibaba-inc.com}
\affiliation{%
  \institution{Alibaba Group}
  \state{Beijing}
  \country{China}
}
\author{Yuning Jiang}
\email{ mengzhu.jyn@alibaba-inc.com}
\affiliation{%
  \institution{Alibaba Group}
  \state{Beijing}
  \country{China}
}


\author{Qin Jin}
\authornote{Corresponding Author.}
\email{qjin@ruc.edu.cn}
\affiliation{%
  \institution{School of Information, \\Renmin University of China}
  \state{Beijing}
  \country{China}
  \postcode{43017-6221}
}



%%
%% By default, the full list of authors will be used in the page
%% headers. Often, this list is too long, and will overlap
%% other information printed in the page headers. This command allows
%% the author to define a more concise list
%% of authors' names for this purpose.
%\renewcommand{\shortauthors}{Trovato and Tobin, et al.}

%%
%% The abstract is a short summary of the work to be presented in the
%% article.
\begin{abstract}
  Stylized visual captioning aims to generate image or video descriptions with specific styles, making them more attractive and emotionally appropriate. One major challenge with this task is the lack of paired stylized captions for visual content, so most existing works focus on unsupervised methods that do not rely on parallel datasets. However, these approaches still require training with sufficient examples that have style labels, and the generated captions are limited to predefined styles. To address these limitations, we explore the problem of Few-Shot Stylized Visual Captioning, which aims to generate captions in any desired style, using only a few examples as guidance during inference, without requiring further training. We propose a framework called FS-StyleCap for this task, which utilizes a conditional encoder-decoder language model and a visual projection module. Our two-step training scheme proceeds as follows: first, we train a style extractor to generate style representations on an unlabeled text-only corpus. Then, we freeze the extractor and enable our decoder to generate stylized descriptions based on the extracted style vector and projected visual content vectors. During inference, our model can generate desired stylized captions by deriving the style representation from user-supplied examples. Our automatic evaluation results for few-shot sentimental visual captioning outperform state-of-the-art approaches and are comparable to models that are fully trained on labeled style corpora. Human evaluations further confirm our modelâ€™s ability to handle multiple styles.
  
  %Stylized visual captioning aims to generate image or video descriptions with specific styles, making them more attractive and emotionally appropriate. One major challenge with this task is the lack of paired stylized captions for visual content. As a result, most existing works focus on unsupervised methods that do not rely on parallel datasets. However, these approaches still require training with numerous examples that have style labels, and the generated captions are limited to predefined styles. To overcome these limitations, we investigate the problem of \textbf{F}ew-\textbf{S}hot \textbf{Styl}iz\textbf{e}d Visual \textbf{Cap}tioning. This task aims to generate captions with any desired styles, using only a few examples as guidance, without requiring further training.
  %aims to generate captions with arbitrary style guided by a few examples, and not requiring further training.
  %Compared to previous methods, our approach is not limited to predefined styles, does not require a large amount of labeled style corpus, and does not need additional training processes to handle new styles. 
  %To tackle this problem, we propose a framework called \textbf{FS-StyleCap}, which utilizes a conditional encoder-decoder language model and a visual projection module. Our two-step training scheme proceeds as follows: first, we train a style extractor using an unlabeled text-only corpus to enable text style extraction. Then, we freeze the extractor and enable our decoder to generate stylized descriptions based on the extracted style vector and projected visual content vectors. During inference, our model generates any desired stylized captions by simply extracting text style from user-supplied examples. %As verified by human evaluations, our model is able to handle multiple styles. 
  %Compared to previous methods, our approach is not limited to predefined styles, and does not need additional training processes . 
  %With training on unlabeled corpus, our model is able to generate captions with multiple styles, guided by only 1-100 stylized examples. 
\end{abstract}

%%
%% The code below is generated by the tool at http://dl.acm.org/ccs.cfm.
%% Please copy and paste the code instead of the example below.
%%

\begin{CCSXML}
<ccs2012>
 <concept>
  <concept_id>10010520.10010553.10010562</concept_id>
  <concept_desc>Computer systems organization~Embedded systems</concept_desc>
  <concept_significance>500</concept_significance>
 </concept>
 <concept>
  <concept_id>10010520.10010575.10010755</concept_id>
  <concept_desc>Computer systems organization~Redundancy</concept_desc>
  <concept_significance>300</concept_significance>
 </concept>
 <concept>
  <concept_id>10010520.10010553.10010554</concept_id>
  <concept_desc>Computer systems organization~Robotics</concept_desc>
  <concept_significance>100</concept_significance>
 </concept>
 <concept>
  <concept_id>10003033.10003083.10003095</concept_id>
  <concept_desc>Networks~Network reliability</concept_desc>
  <concept_significance>100</concept_significance>
 </concept>
</ccs2012>
\end{CCSXML}

%% \ccsdesc[500]{Computer systems organization~Embedded systems}
%% \ccsdesc[300]{Computer systems organization~Redundancy}


\ccsdesc[500]{Computing methodologies~Natural language generation}
%% \ccsdesc[100]{Networks~Network reliability}

%%
%% Keywords. The author(s) should pick words that accurately describe
%% the work being presented. Separate the keywords with commas.
\keywords{Stylized visual captioning, Few-shot learning}

%% A "teaser" image appears between the author and affiliation
%% information and the body of the document, and typically spans the
%% page.
\iffalse
\begin{teaserfigure}
  % Figure removed
  \caption{Seattle Mariners at Spring Training, 2010.}
  \Description{Enjoying the baseball game from the third-base
  seats. Ichiro Suzuki preparing to bat.}
  \label{fig:teaser}
\end{teaserfigure}
\fi

%%
%% This command processes the author and affiliation and title
%% information and builds the first part of the formatted document.
\settopmatter{printfolios=true}
\maketitle





\input{Sections/Introduction}
\input{Sections/Related_works}
\input{Sections/Methods}
\input{Sections/Experiments}
\input{Sections/Results}
\input{Sections/Conclusion}



\iffalse
% Figure environment removed
\fi
\bibliographystyle{ACM-Reference-Format}
\bibliography{refs}
%\appendix
%\input{Sections/appendix.tex}
\end{document}
\endinput
%%
%% End of file `sample-sigplan.tex'.
