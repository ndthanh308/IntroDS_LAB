\section{Theoretical Preliminaries}
\label{sec:backgnd}

\subsection{Fourier Equation}
The temperature distribution in a body is governed by the Fourier heat equation~\cite{fourier}, described mathematically as:
\begin{equation}
\label{eqn:fourier}
 \nabla.\left(\kappa\nabla T\right) + \dot{q} = \rho C_v \frac{\partial T}{\partial t},
\end{equation}
where $\rho$ is the material density, $T$ is the temperature, $C_v$ is the volumetric specific heat, $\kappa$ is the thermal 
conductivity, and $\dot{q}$
is the rate of heat energy generation inside the volume.
 However, this equation is too complex to be solved analytically in the general case. Hence most chip-level thermal simulators use numerical methods such as the finite difference and the finite element methods to arrive at an approximate solution quickly.

\subsection{Green's Functions}
An alternative approach to obtain the temperature profile is based on the impulse response of the chip (or the 
Green's function~\cite{greenintro}). This impulse response is obtained by applying a unit power source to the center of the chip and getting the  corresponding temperature rise. {The Green's function is essentially the heat spread function, $f_{sp}$, of a point power source.}
 This Green's function is then convolved with the power profile to obtain the full-chip temperature profile. This approach is analytical, and 
much faster than finite difference or finite element-based approaches since the entire heat transfer path is not modeled, rather 
only the power dissipating layers and the boundary conditions are considered~\cite{lightsim,3dsim, sapatnekar}.
This is because the accuracy of the finite element method is dependent on the grid size, and reducing the grid size comes at the expense of lost accuracy. However, because of the analytical nature of the Green's function, the grid size here merely determines the output resolution and the accuracy of the method is independent of the grid size.

Using the impulse response (Green's function), the complete full-chip temperature profile can be calculated as~\cite{powerblur2014}:
\begin{equation}
\label{eqn:Green}
T = f_{sp} \star P
\end{equation}
where $P$ is the power dissipation profile, $f_{sp}$ is the Green's function, and $\star$ is the convolution operator.

{The Green's function is radially symmetric and can be further decomposed into a rapidly decaying part $f_{silic}$, and a constant representing heat redistributed through the heat spreader~\cite{lightsim}.}

Interested readers may read more about the Green's function in~\cite{lightsim, 3dsim, sapatnekar}.


\subsection{Process and Temperature Variation}
The manufacturing of an IC involves a large number of steps or processes that are imperfect in nature. As a result, the properties of a manufactured chip often differ from its nominal values. The device dimensions have reached the scale of tens of atoms in modern-day chips. As a result, the impact of variation has become much more prominent. 

The parameters affected by variation include the
oxide thickness, threshold voltage, gate width, and channel length.
The variation in these parameters is classified as: \textit{wafer-to-wafer}, \textit{die-to-die} and \textit{within-die} variations. 
The first two effects (collectively known as \textit{inter-die} variation) uniformly affect all regions of a given die. They used to have a larger significance in older 
technology generations; they can be mitigated easily by relatively simple methods such as \textit{frequency binning}. These typically cause a constant shift in the mean value of a parameter across all the devices on a die. 

For newer 
technology generations, within-die variation dominates and requires more complex management 
strategies~\cite{mittal}. This type of variation leads to deviations in the electrical and thermal properties of the chip on the same die. Within-die variation is further classified as:

\begin{enumerate}[wide, labelwidth=!, labelindent=0pt]
\item \textbf{Systematic variations:} These are introduced because of lithographic aberrations and diffraction or chemical-mechanical polishing/planarization (CMP) effects. Systematic variation results in proximate regions on the die having similar values of parameters. It is modeled by a multivariate Gaussian 
distribution~\cite{varius} having a spherical correlation~\ref{fig:pleakcorr}.   

% Figure environment removed


\item \textbf{Random variations:} These are caused by random dopant fluctuations 
(RDF) and line edge roughness; they are together modeled as a 
zero-mean Gaussian random variable. These variations do not exhibit any spatial correlation.
\end{enumerate}


There are two variables in the heat equation that are strongly affected by parameter 
variation: leakage power and thermal
conductivity. We discuss these next.

\subsection{Leakage power}
The variability in leakage power arises because of both systematic and random variations. However, it is well-known~\cite{skadronvar} 
that the effects of random variation tend to get averaged out at the architectural level when considering temperature. 
We have also observed the same in our experiments.

\label{sec:leakagedef}
The subthreshold leakage current, $I_{leak}$ is given by Equation~\ref{eqn:bsim}.
\begin{equation}
\label{eqn:bsim}
 I_{leak} \propto v_{T}^{2} * e^{\frac{V_{GS}-V_{th}-V_{off}}
{\eta * v_{T}}} (1-e^{\frac{-V_{DS}}{v_{T}}})
\end{equation}

where, $v_T$ is the thermal voltage ($kT/q$), $V_{th}$ is the threshold voltage, $V_{off}$ is the offset voltage in the
sub-threshold region and $\eta$ is a constant. Because of variability, the oxide thickness and gate length 
change, which result in a change in the threshold voltage. 
The temperature 
dependence of $I_{leak}$ can be 
modeled with a reasonable accuracy using a linear equation~\cite{lightsim,3dsim, liu}. Equation~\ref{eqn:bsim} then becomes:

\begin{equation}
\label{eqn:Ileakmod}
 I_{leak} \propto (1+\beta \Delta T)e^{\beta_{ L}\Delta L + \beta_{ t_{ox}}\Delta t_{ox}}
\end{equation}

where $\beta$ represents the change in leakage power with temperature, $\beta_{ t_{ox}}$ is a constant 
representing the variability in the oxide thickness $t_{ox}$ and $\beta_{L}$ 
represents the variability in the gate 
length, $L$.
The corresponding leakage power is given by:
\begin{equation}
\label{eqn:Pleak}
 P_{leak} = (1+\beta \Delta T) P_{leak_0},
\end{equation}
where $\Pleak$ is the leakage power at ambient temperature after considering the impact of variability.
For improved accuracy, we can use a piece-wise linear leakage model, which provides an accuracy of over 
99\%~\cite{tempsurvey}.

\subsection{Conductivity of Silicon}
In addition to considering the impact of variation on leakage power, we also consider the impact of variability on the conductivity of silicon. This is because in accordance with the Fourier's law, the temperature profile is impacted by both the power consumed by the chip as well as the conductivity of the chip. 
Random dopant fluctuations (RDF) cause a variation in the doping profile, resulting in variations in the conductivity of the material as well. 
To model this variation in conductivity, we consider a Gaussian random variable, $K$. The range of variation in the doping profiles because of RDF is obtained from the literature~\cite{leungvar}. The range of conductivity values of silicon for these dopant densities is obtained from the literature~\cite{burzo}. Using these, the variance in the conductivity of silicon is then obtained.


In addition to the random variation in conductivity, the conductivity of silicon also depends on temperature. The conductivity of silicon varies with temperature according to the following equation:
\begin{equation}
\label{eqn:condsi}
\kappa = k_{0} \left({T \over 300}\right)^{-\eta}, 
\end{equation}
where $k_{0}$ is the conductivity of silicon at 300K, $T$ is the temperature in Kelvin, and $\eta$ is a material-dependent constant. 
As the chip gets heated, the conductivity of silicon decreases which further affects the temperature profile.


\subsection{Transforms used in this Paper}
Thermal problems are often easier to solve in the transform domain. We use two types of transforms in this work -- the \textit{Fourier transform}  and the \textit{Hankel transform}.

\subsubsection{Fourier Transform} 
The Fourier transform decomposes a signal from the spatial domain and brings it into the frequency domain. 
The result is a complex function, the magnitude of which represents the amount of each frequency present in the signal.
In the present work, we make use of the 2-dimensional Fourier transform, which is given by:
\begin{equation}
\begin{split}
\label{eqn:fourierdef}
F(u,v) = \fourier(f(x,y)) = \int^{\infty}_{-\infty} \int^{\infty}_{-\infty} f(x,y) e^{-j 2 \pi(ux+vy)}dx dy\\
\end{split}
\end{equation}
where $u,v$ are the Fourier frequency domain variables, $x,y$ are the spatial domain variables, and $f(x,y)$ is the spatial domain signal being transformed into the frequency domain.


\subsubsection{Hankel Transform}
The Hankel transform is equivalent to the 
2-D Fourier transform of a radially symmetric function. It uses the Bessel function as its basis. The Hankel transform is
defined as: 
\begin{equation}
\label{eqn:hankeldef}
\hankel(f(r)) = H(s) = \int_0^\infty f(r) \bessel_0(sr)r dr,
\end{equation}
where $\bessel_0$ is the Bessel function of the first kind of order 0, and $\hankel$ denotes the Hankel transform operator.





