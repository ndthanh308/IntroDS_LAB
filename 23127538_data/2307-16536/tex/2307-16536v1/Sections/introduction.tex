\section{Introduction}\label{sec:introduction}
% The very first letter is a 2 line initial drop letter followed
% by the rest of the first word in caps.
% 
% form to use if the first word consists of a single letter:
% \IEEEPARstart{A}{demo} file is ....
% 
% form to use if you need the single drop letter followed by
% normal text (unknown if ever used by the IEEE):
% \IEEEPARstart{A}{}demo file is ....
% 
% Some journals put the first two words in caps:
% \IEEEPARstart{T}{his demo} file is ....
% 
% Here we have the typical use of a "T" for an initial drop letter
% and "HIS" in caps to complete the first word.
%\IEEEPARstart{T}{his} demo file is intended to serve as a ``starter file''
%for IEEE Communications Society journal papers produced under \LaTeX\ using
%IEEEtran.cls version 1.8b and later.
%% You must have at least 2 lines in the paragraph with the drop letter
%% (should never be an issue)
%I wish you the best of success.
%
%\hfill mds
%
%\hfill August 26, 2015

%\subsection{Subsection Heading Here}
%Subsection text here.

% needed in second column of first page if using \IEEEpubid
%\IEEEpubidadjcol

%\subsubsection{Subsubsection Heading Here}
%Subsubsection text here.


% An example of a floating figure using the graphicx package.
% Note that \label must occur AFTER (or within) \caption.
% For figures, \caption should occur after the \includegraphics.
% Note that IEEEtran v1.7 and later has special internal code that
% is designed to preserve the operation of \label within \caption
% even when the captionsoff option is in effect. However, because
% of issues like this, it may be the safest practice to put all your
% \label just after \caption rather than within \caption{}.
%
% Reminder: the "draftcls" or "draftclsnofoot", not "draft", class
% option should be used if it is desired that the figures are to be
% displayed while in draft mode.
%
%% Figure environment removed

% Note that the IEEE typically puts floats only at the top, even when this
% results in a large percentage of a column being occupied by floats.


% An example of a double column floating figure using two subfigures.
% (The subfig.sty package must be loaded for this to work.)
% The subfigure \label commands are set within each subfloat command,
% and the \label for the overall figure must come after \caption.
% \hfil is used as a separator to get equal spacing.
% Watch out that the combined width of all the subfigures on a 
% line do not exceed the text width or a line break will occur.
%
%% Figure environment removed
%
% Note that often IEEE papers with subfigures do not employ subfigure
% captions (using the optional argument to \subfloat[]), but instead will
% reference/describe all of them (a), (b), etc., within the main caption.
% Be aware that for subfig.sty to generate the (a), (b), etc., subfigure
% labels, the optional argument to \subfloat must be present. If a
% subcaption is not desired, just leave its contents blank,
% e.g., \subfloat[].


% An example of a floating table. Note that, for IEEE style tables, the
% \caption command should come BEFORE the table and, given that table
% captions serve much like titles, are usually capitalized except for words
% such as a, an, and, as, at, but, by, for, in, nor, of, on, or, the, to
% and up, which are usually not capitalized unless they are the first or
% last word of the caption. Table text will default to \footnotesize as
% the IEEE normally uses this smaller font for tables.
% The \label must come after \caption as always.
%
%\begin{table}[!t]
%% increase table row spacing, adjust to taste
%\renewcommand{\arraystretch}{1.3}
% if using array.sty, it might be a good idea to tweak the value of
% \extrarowheight as needed to properly center the text within the cells
%\caption{An Example of a Table}
%\label{table_example}
%\centering
%% Some packages, such as MDW tools, offer better commands for making tables
%% than the plain LaTeX2e tabular which is used here.
%\begin{tabular}{|c||c|}
%\hline
%One & Two\\
%\hline
%Three & Four\\
%\hline
%\end{tabular}
%\end{table}


% Note that the IEEE does not put floats in the very first column
% - or typically anywhere on the first page for that matter. Also,
% in-text middle ("here") positioning is typically not used, but it
% is allowed and encouraged for Computer Society conferences (but
% not Computer Society journals). Most IEEE journals/conferences use
% top floats exclusively. 
% Note that, LaTeX2e, unlike IEEE journals/conferences, places
% footnotes above bottom floats. This can be corrected via the
% \fnbelowfloat command of the stfloats package.

%%%%%%%%%%%%%%%%%START HERE%%%%%%%%%%%%%
%-----UNCONSTRAINED MDPs and POMDPs
% \IEEEPARstart{W}{ith}
Single-Agent Markov Decision Processes (SA-MDPs) \cite{bellman57} and Single-Agent Partially Observable Markov Decision Processes (SA-POMDPs) \cite{astrom65} have long served as the basic building-blocks in the study of sequential decision-making. %under uncertainty. 
An SA-MDP is an abstraction in which an agent (sequentially) interacts with a fully-observable Markovian environment to solve a multi-period optimization problem; in contrast, in SA-POMDP, the agent only gets to observe a noisy or incomplete version of the environment. %Approaches to solve these two problems have also come a long way. 
In 1957, Bellman proposed dynamic-programming as an approach to solve SA-MDPs \cite{bellman57,howard:dp}. This combined with the characterization of SA-POMDP into an equivalent SA-MDP \cite{smallwood1973optimal,sondik1978optimal,kaelbing199899} (in which the agent maintains a belief about the environment's true state) made it possible to extend dynamic-programming results to SA-POMDPs. \emph{Reinforcement learning}~\cite{sutton98} based algorithmic frameworks (\cite{watkins1992,rummery1994,schulman2015,schulman2017,subramanian19,subramanian22} to name a few) use data-driven dynamic-programming approaches to solve such single-agent sequential decision problems when the environment is unknown.

%------NOW MA-C-POMDPs 
In many engineering systems, there are multiple decision-makers that collectively solve a sequential decision-making problem but with safety constraints: e.g., a team of robots performing a joint task, a fleet of automated cars navigating a city, multiple traffic-light controllers in a city, etc. Bandwidth constrained communications and communication delays in such systems lead to a decentralized team problem with information asymmetry. In this work, we study a fairly general abstraction of such systems and develop an algorithmic framework that (approximately) solves the underlying constrained decision problem. The abstraction that we consider is that of a cooperative multi-agent constrained POMDP, %\footnote{also known as decentralized constrained POMDP.} 
hereon referred to as MA-C-POMDP. The special cases of MA-C-POMDP when there are no constraints, when there is only one agent, or when the environment is fully observable to each agent are referred to as MA-POMDP\footnote{For a good introduction to MA-POMDPs, see \cite{oliehoek16}.}, SA-C-POMDP, and MA-C-MDP respectively. The relationships among these models are shown in Figure \ref{fig:model_relationships}.

\subsection{Related Work}
% Constrained MDPs and Constrained POMDPs
Prior work on planning and learning under constraints has primarily focused on single-agent constrained MDP (SA-C-MDP) where unlike in SA-MDPs, the agent solves a constrained optimization problem. For this setup, a number of fundamental results from the planning perspective have been derived -- for instance \cite{altman94,altman96,feinberg94,feinberg95,feinberg96,feinberg2000,feinberg2020}; see \cite{altman-constrainedMDP} for a details of the convex-analytic approach. 
% A well-expounded presentation on SA-C-MDPs can be found in the excellent book by Altman \cite{altman-constrainedMDP}. These aforementioned results have led to the development of a number of nice algorithms in the learning setting (such as \cite{borkar2005AnAA,bhatnagar2010AnAA,bhatnagar2012AnOA,Wei2022APM,wei22a-pmlr-v151,bura2021,vaswani2022}). 
These results have led to the development of many algorithms in the learning setting: see \cite{borkar2005AnAA,bhatnagar2010AnAA,bhatnagar2012AnOA,Wei2022APM,wei22a-pmlr-v151,bura2021,vaswani2022}. Unlike SA-C-MDPs, rigorous results for SA-C-POMDPs are limited; few  reference works include \cite{dongho2011,jongmin18,undurti2010,jamgochian2022}.


%----MA-POMDPs and MA-C-POMDPs
There has been little work done on MA-POMDPs and MA-C-POMDPs due to challenges arising from the combination of \emph{partial observability} of the environment and \emph{information-asymmetry}\footnote{Here, information-asymmetry refers to the mismatch in the information each agent has when choosing their action; information asymmetry in decision problems typically results in non-classical information structures~\cite{mahajan2012information}.}; solving a finite-horizon MA-POMDP with more than two agents is known to be NEXP-complete \cite{bernstein00}. Nevertheless, conceptual approaches exist to establish solution methodologies and structural properties in (finite-horizon) MA-POMDPs namely: i) the person-by-person approach~\cite{witsenhausen1979structure}; ii) the designer's approach~\cite{witsenhausen1973standard}; and iii) the \emph{common-information (CI) approach}~\cite{nayyar13,nayyar14}, which we will use in the second part of this work. In the CI approach, the common information of all agents is used to instantiate a fictitious/virtual entity, known as the \emph{coordinator}, that takes an action based only on this common information, while its action is an enforcing prescription to each agent on how to act given a specific realization of their private history. Akin to a SA-POMDP, this transformation leads to the formulation of a dynamic program that in principle can be used 
to solve the (finite-horizon) MA-POMDP. The CI approach has also led to the development of a multi-agent reinforcement learning (MARL) framework \cite{hsu22} where agents learn good compressions of common and private information that can suffice for approximate optimality. On the empirical front, a few worth-mentioning works include \cite{gupta17,nolan2020,rashid2020,rashid2020-2}.

% MA-C-POMDPs (not much to mention, little or no prior work)
The technical challenges increase even more so for MA-C-POMDPs where restriction of the policy-profile space to %only 
deterministic policy-profiles is no longer an option\footnote{Restricting to deterministic policies can be sub-optimal in SA-C-MDPs and SA-C-POMDPs: see \cite{altman-constrainedMDP} and \cite{dongho2011} for details.}. Thus, 
%with no restriction to the policy-profile search space, 
the coordinator in the equivalent SA-C-POMDP has an uncountable prescription space, which leads to an uncountable state-space in its equivalent SA-C-MDP. This is an issue because most fundamental results in the theory of SA-C-MDPs (largely based on occupation-measures) rely heavily on the state-space being countable; see \cite{altman-constrainedMDP}. Due to these reasons, the study of MA-C-POMDPs calls for a new methodology, one which avoids this transformation and directly studies the problem. Our work takes the first steps in this direction.

\subsection{Contributions}
We present the first rigorous approach for MA-C-POMDPs that is based on a principled theory of strong duality and using measure theoretic results. In particular,
\begin{itemize}
\item%[a)] 
In Theorem \ref{thm:strongduality}, we establish strong duality and existence of a saddle-point for a fairly general formulation of a MA-C-POMDP.
\item%[b)] 
In Section \ref{sec:history_embedding}, we propose a universal compression methodology similar to \cite{hsu22} that holds for any valid vector of Lagrange-multipliers.
\item%[c)] 
In Section \ref{sec:marl}, we combine strong duality with the proposed compression methodology to lay out the design of a primal-dual MARL framework based on centralized training and decentralized execution (CTDE) -- for developing close-to-optimal algorithms (using neural-networks to approximate any  functions).%as function-approximators/work-horse).
\end{itemize}


\subsection{Organization}
The rest of the paper is organized as follows. A mathematical formulation of cooperative MA-C-POMDPs is introduced in Section \ref{sec:problem}. Strong duality results are derived in Section \ref{sec:strongduality} with details deferred to Appendices \ref{sec:appendix:intermediary_results} and \ref{sec:appendix:helpful_facts}. Computationally feasible algorithms based on compression of agents' histories to approximate information states are developed in Sections \ref{sec:history_embedding} and \ref{sec:marl}. Finally, concluding remarks are given in Section \ref{sec:conclusion}.

\subsection{Notation}
Before we present the model, we highlight the key notation in this paper.
\begin{itemize}
\item The sets of integers and positive integers are respectively denoted by $\mbb{Z}$ and $\mbb{N}$. For integers $a$ and $b$, $[a,b]_{\mbb{Z}}$ represents the set $\{a, a+1, \dots, b\}$ if $a\le b$ and $\emptyset$ otherwise. The notations [a] and $[a,\infty]_{\mbb{Z}}$ are used as shorthands for $[1, a]_{\mbb{Z}}$ and $\{a, a+1, \dots \}$, respectively.
\item For integers $a \le b$ and $c \le d$, and a quantity of interest $q$, $\un{q}{a:b}$ is a shorthand for the vector $\l( \un{q}{a}, \un{q}{a+1}, \dots, \un{q}{b} \r)$ while $\ut{q}{c:d}$ is a shorthand for the vector $\l( \ut{q}{c}, \ut{q}{c+1}, \dots, \ut{q}{d} \r)$. The combined notation $\utn{q}{a:b}{c:d}$ is a shorthand for the vector $(\utn{q}{i}{j}: i \in [a,b]_{\mbb{Z}}, j \in [c, d]_{\mbb{Z}})$. The infinite tuples $\l( \un{q}{a}, \un{q}{a+1}, \dots, \r)$ and $\l( \ut{q}{c}, \ut{q}{c+1}, \dots, \r)$ are respectively denoted by $ \un{q}{a:\infty}$ and $\ut{q}{c:\infty}$.
\item For two real-valued vectors $v_1$ and $v_2$, the inequalities $v_1 \le v_2$ and $v_1 < v_2$ are meant to be element-wise inequalities.
\item Probability and expectation operators are denoted by $\pr$ and $\mbb{E}$, respectively. Random variables are denoted by upper-case letters and their realizations by the corresponding lower-case letters.  At times, we also use the shorthand  $\mbb{E}\l[ \cdot | x \r] \defeq \mbb{E}\l[ \cdot | X = x \r]$ and $\pr\l( y | x \r) \defeq \pr\l( Y = y | X = x \r)$ for conditional quantities.
\item Whenever a conditional probability or conditional expectation is written, it is implicitly assumed that the conditioning event has non-zero probability.
\item Topological spaces are denoted by upper-case calligraphic letters. For a topological-space $\mcl{W}$, $\borel{\mcl{W}}$ denotes the Borel $\sigma$-algebra, measurability is determined with respect to $\borel{\mcl{W}}$, and $\m{\mcl{W}}$ denotes the set of all probability measures on $\borel{\mcl{W}}$ endowed with the topology of weak convergence. Also, unless stated otherwise, ``measure'' means a non-negative measure.
\item Unless otherwise stated, if a set $\mcl{W}$ is countable, as a topological space it will be assumed to have the discrete topology. Therefore, the corresponding Borel $\sigma$-algebra $\borel{\mcl{W}}$ will be the power-set $2^{\mcl{W}}$.
\item Unless stated otherwise, the product of a collection of topological spaces will be assumed to have the product topology.
% \item To aid the reading experience, important notations and definitions are listed in Appendix \ref{sec:appendix:notation}.
\item The notation in Appendices \ref{sec:appendix:helpful_facts} and \ref{sec:appendix:minimax} is exclusive and should be read independent of the rest of the manuscript.
\item To aid the reading experience, we strongly encourage the reader to refer to important notation and definitions listed in Appendix \ref{sec:appendix:notation}.
\end{itemize}
% Figure environment removed