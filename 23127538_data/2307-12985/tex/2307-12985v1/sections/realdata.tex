\section{Application to fetal cell atlas data}
\label{section_realData_nb}

In this section, we apply negative binomial count splitting to solve the problems associated with Example~\ref{ex:stable} from Section~\ref{section_intro_nb}. \cite{cao2020human} sequenced more than 4 million cells from 121 human fetal samples to create a fetal cell atlas, with a goal of organizing the cells from each of 15 different organs into cell types and cell subtypes. In one analysis, after preprocessing, they clustered the expression data from 
the kidney cells into nine main cell types. They then subsetted the data to include only the cluster thought to correspond to metanephric kidney cells, and clustered that subset into 10 cell subtypes. As there is no ground truth available for the main cell types or the cell subtypes, it is difficult to validate their results. \cite{cao2020human} use a procedure that they call \emph{intradataset cross-validation}; see their Figure 2. We describe a simplified version of this procedure in Algorithm~\ref{alg_cao_intra}. 

\begin{algorithm}[Intradataset cross-validation, \cite{cao2020human}]
\label{alg_cao_intra} 
Input: a cell-by-gene expression matrix $X \in \mathbb{Z}_{\geq 0}^{n \times p}$. 
\begin{enumerate}
\item After preprocessing, cluster the dataset $X$ to obtain estimated cell types $\hat{L}(X)^\mathrm{cluster}$. 
\item Divide the $n$ cells into $5$ folds and, for $m = 1,\ldots, 5$: 
\begin{enumerate}
\item Let all cells in the $m$th fold be the test set; the remaining cells are the training set. 
\item Train a classifier to predict $\hat{L}(X)^\mathrm{cluster}_i$ using $X_i$, where $i$ indexes the cells in the training set. 
\item Use this trained classifier
to predict $\hat{L}^{\mathrm{cluster}}_{i'}$ using $X_{i'}$, where $i'$ indexes the cells in the test set. Let $\hat{L}_{i'}^\mathrm{classifier}$ denote the prediction for the $i'$th cell. 
\end{enumerate} 
\item For $i=1,\ldots,n$, the $i$th cell now has a value $\hat{L}(X)^\mathrm{cluster}_i$, obtained from clustering, and $\hat{L}^{\mathrm{classifier}}_i$, obtained via prediction when it belonged to the test set. Make a confusion matrix comparing  $\hat{L}(X)^\mathrm{cluster}$ and $\hat{L}^{\mathrm{classifier}}$. A diagonal confusion matrix is treated as evidence that the clusters are reproducible, since the cluster assignment for a given cell can be recovered by a classifier that was trained without knowledge of that cell's cluster assignment. The adjusted Rand index (ARI) numerically summarizes the degree of agreement between $\hat{L}(X)^\mathrm{cluster}$ and $\hat{L}^{\mathrm{classifier}}$.
\end{enumerate}	
\end{algorithm}

In Section~\ref{section_intro_nb} (Figure~\ref{fig_intro}(e)), we showed using a toy dataset that this procedure is problematic. Because the entire dataset $X$ is used in Step 1 to estimate the clusters $\hat{L}(X)^\mathrm{cluster}$, the test set in Step 2(c) has not truly been held out of the training process.  Thus, despite the fact that the clusters estimated on the toy dataset are driven by random noise, the confusion matrix output by Algorithm~\ref{alg_cao_intra} is close to diagonal and the ARI is close to $1$ (Figure~\ref{fig_intro}(e)). Negative binomial count splitting provides a simple alternative (Figure~\ref{fig_intro}(f)), which we outline below. 

\begin{algorithm}[Intradataset cross-validation via count splitting]
\label{alg_cs_intra} \hspace{1mm} \\
Input: a cell-by-gene expression matrix $X \in \mathbb{Z}_{\geq 0}^{n \times p}$. 
\begin{enumerate}
\item Obtain an estimate $\hat{b}_j$ of the gene-specific overdispersion parameter $b_j$ for $j=1,\ldots,p$. 
\item Apply Algorithm~\ref{alg_gcs} (negative binomial count splitting) with $M=2$, $\epsilon_1 = \epsilon_2 = 0.5$, and $(b_1',\ldots, b_p') = (\hat{b}_1,\ldots,\hat{b}_p)$ to create two folds of data, $\xo$ and $\xt$.
\item After preprocessing, apply a clustering algorithm to $\xo$ to obtain an estimated cluster $\hat{L}(X^{(1)})_i$ for the $i$th cell for $i=1,\ldots,n$. 
\item After preprocessing, apply the same clustering algorithm to $\xt$ to obtain an estimated cluster $\hat{L}(X^{(2)})_i$ for the $i$th cell for $i=1,\ldots,n$. 
\item Make a confusion matrix comparing $\hat{L}(X^{(1)})$ and $\hat{L}(X^{(2)})$. A diagonal confusion matrix (up to a permutation of the columns) is treated as evidence of cluster reproducibility, since the cells are reliably assigned to the same cluster on independent realizations of the data. The ARI numerically summarizes the degree of agreement between $\hat{L}(X^{(1)})$ and $\hat{L}(X^{(2)})$. 
\end{enumerate}	
\end{algorithm}

We now compare Algorithm~\ref{alg_cao_intra} and Algorithm~\ref{alg_cs_intra} on data from the human fetal cell atlas. We consider two versions of Algorithm~\ref{alg_cs_intra}. We apply a version where, in Step 1, we let each $\hat{b}_j = \infty$, which corresponds to assuming that the data are Poisson. We also apply a version where, in Step 1, we estimate each $\hat{b}_j$ using the full dataset using \texttt{sctransform}; details are given in Appendix~\ref{appendix_sct}. In both cases, we use $\epsilon_1=\epsilon_2=0.5$ such that $\xo$ and $\xt$ are identically distributed. Our goal is not to discover the optimal clusters in this dataset, but rather to compare Algorithm~\ref{alg_cao_intra} and Algorithm~\ref{alg_cs_intra} as strategies for validating clusters. As such, we do not attempt to reproduce the exact analysis from \cite{cao2020human}; we use a simplified implementation, which is described in Appendix~\ref{appendix_cao}.

To start, we apply Algorithm~\ref{alg_cao_intra} and both versions of Algorithm~\ref{alg_cs_intra} to all $178,603$ kidney cells from the human fetal cell atlas. The results are shown in panels (a), (b), and (c) of Figure~\ref{fig_realData_confusion}. Regardless of the algorithm used, we see diagonal confusion matrices and high ARIs, suggesting reproducibility of the clusters. For panels (b) and (c), we permute the columns of the matrices to make them appear as diagonal as possible, but we note that the ARI is invariant to these permutations. 

We next apply Algorithm~\ref{alg_cao_intra} and both versions of Algorithm~\ref{alg_cs_intra} to the $90,876$ kidney cells that \cite{cao2020human} annotated as metanephric cells. The results are shown in  panels (d), (e), and (f) of Figure~\ref{fig_realData_confusion}. Overall, panels (e) and (f) show lower ARIs than panels (b) and (c), suggesting that these supposed cell subtypes are somewhat less reproducible than the main cell types. We note that the difference between the main cell type analysis and the cell subtype analysis is least stark for Algorithm~\ref{alg_cao_intra}, where the double use of data causes the cell subtypes to appear more reproducible than they are in both analyses. Similarly, the difference 
between the main cell type analysis and the cell subtype analysis is less stark for the Poisson version of Algorithm~\ref{alg_cs_intra} than the \texttt{sctransform} version, suggesting that the dependence between the training set and the test set induced by setting $\hat{b}_1 = \ldots = \hat{b}_p = \infty$ is also enough to make the cell subtypes appear slightly more reproducible than they are.

We repeat each version of Algorithm~\ref{alg_cs_intra} ten times, using ten different random splits of the data. The resulting ARIs are shown in Figures~\ref{fig_realData_confusion}(d) and \ref{fig_realData_confusion}(h). The ARIs from the cell subtype analysis are consistently lower than those from the main cell type analysis. 



% Figure environment removed

In summary, due to the double use of data, Algorithm~\ref{alg_cao_intra} overestimates the reproducibility of the metanephric cell subtypes. On the other hand, Algorithm~\ref{alg_cs_intra} allows us to see that the metanephric cell subtypes are less reproducible than the main kidney cell types. 
