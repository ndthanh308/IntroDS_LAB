
@article{bichuch_endogenous_2022,
	title = {Endogenous {Inverse} {Demand} {Functions}},
	volume = {70},
	issn = {0030-364X},
	url = {https://pubsonline.informs.org/doi/full/10.1287/opre.2022.2325},
	doi = {10.1287/opre.2022.2325},
	abstract = {In this work we present an equilibrium formulation for price impacts. This is motivated by the Bühlmann equilibrium in which assets are sold into a system of market participants, for example, a fire sale in systemic risk, and can be viewed as a generalization of the Esscher premium. Existence and uniqueness of clearing prices for the liquidation of a portfolio are studied. We also investigate other desired portfolio properties including monotonicity and concavity. Price per portfolio unit sold is also calculated. In special cases, we study price impacts generated by market participants who follow the exponential utility and power utility.},
	number = {5},
	urldate = {2023-06-20},
	journal = {Operations Research},
	author = {Bichuch, Maxim and Feinstein, Zachary},
	month = sep,
	year = {2022},
	note = {Publisher: INFORMS},
	keywords = {equilibrium liquidation, Financial Engineering, fire sale, inverse demand function, price impacts, risk sharing},
	pages = {2702--2714},
	file = {Full Text PDF:/Users/zihanchen/Zotero/storage/XPFB7XWP/Bichuch and Feinstein - 2022 - Endogenous Inverse Demand Functions.pdf:application/pdf},
}

@article{amini_uniqueness_2016,
	title = {Uniqueness of equilibrium in a payment system with liquidation costs},
	volume = {44},
	issn = {0167-6377},
	url = {https://www.sciencedirect.com/science/article/pii/S0167637715001364},
	doi = {10.1016/j.orl.2015.10.005},
	abstract = {We study a financial network where forced liquidations of an illiquid asset have a negative impact on its price, thus reinforcing network contagion. We give conditions for uniqueness of the clearing asset price and liability payments. Our main result holds under mild and natural assumptions on the price impact function: monotonicity of the price impact function and strict monotonicity of the proceeds of liquidation in the liquidated quantity.},
	language = {en},
	number = {1},
	urldate = {2023-06-20},
	journal = {Operations Research Letters},
	author = {Amini, Hamed and Filipović, Damir and Minca, Andreea},
	month = jan,
	year = {2016},
	keywords = {Asset price contagion, Eisenberg–Noe model, Financial network, Systemic risk},
	pages = {1--5},
	file = {ScienceDirect Full Text PDF:/Users/zihanchen/Zotero/storage/8R2ABTEB/Amini et al. - 2016 - Uniqueness of equilibrium in a payment system with.pdf:application/pdf},
}

@article{amini_optimal_2023,
	title = {Optimal network compression},
	volume = {306},
	issn = {0377-2217},
	url = {https://www.sciencedirect.com/science/article/pii/S0377221722005793},
	doi = {10.1016/j.ejor.2022.07.026},
	abstract = {This paper introduces a formulation of the optimal network compression problem for financial systems. This general formulation is presented for different levels of network compression or rerouting allowed from the initial interbank network. We prove that this problem is, generically, NP-hard. We focus on objective functions generated by systemic risk measures under shocks to the financial network. We use this framework to study the (sub)optimality of the maximally compressed network. We conclude by studying the optimal compression problem for specific networks; this permits us to study, e.g., the so-called robust fragility of certain network topologies more generally as well as the potential benefits and costs of network compression. In particular, under systematic shocks and heterogeneous financial networks the robust fragility results of Acemoglu, Ozdaglar, and Tahbaz-Salehi (2015) no longer hold generally.},
	language = {en},
	number = {3},
	urldate = {2023-06-20},
	journal = {European Journal of Operational Research},
	author = {Amini, Hamed and Feinstein, Zachary},
	month = may,
	year = {2023},
	keywords = {Finance, Systemic risk, Financial networks, Portfolio compression, Systematic shocks},
	pages = {1439--1455},
	file = {ScienceDirect Full Text PDF:/Users/zihanchen/Zotero/storage/86J3IGNJ/Amini and Feinstein - 2023 - Optimal network compression.pdf:application/pdf},
}

@article{braouezec_strategic_2019,
	title = {Strategic fire-sales and price-mediated contagion in the banking system},
	volume = {274},
	issn = {0377-2217},
	url = {https://www.sciencedirect.com/science/article/pii/S0377221718309378},
	doi = {10.1016/j.ejor.2018.11.012},
	abstract = {We consider a price-mediated contagion framework in which each bank, after an exogenous shock, may have to sell assets in order to comply with regulatory constraints. Interaction between banks takes place only through price impact. We characterize the equilibrium of the strategic deleveraging problem and we calibrate our model to publicly-available data, the US banks that were part of the 2015 regulatory stress-tests. We then consider a more sophisticated model in which each bank is exposed to two risky assets (marketable and not marketable) and is only able to sell the marketable asset. We calibrate our model using the six banks with significant trading operations and we show that, depending on the price impact, the contagion of failures may be significant. Our results may be used to refine current stress testing frameworks by incorporating potential contagion mechanisms between banks.},
	language = {en},
	number = {3},
	urldate = {2023-06-20},
	journal = {European Journal of Operational Research},
	author = {Braouezec, Yann and Wagalath, Lakshithe},
	month = may,
	year = {2019},
	keywords = {Finance, CCAR 2015, Macro-prudential stress-tests, Nash equilibrium with strategic Complementarities, Price-mediated contagion},
	pages = {1180--1197},
	file = {ScienceDirect Full Text PDF:/Users/zihanchen/Zotero/storage/V8XIKYRX/Braouezec and Wagalath - 2019 - Strategic fire-sales and price-mediated contagion .pdf:application/pdf},
}

@article{cifuentes_liquidity_2005,
	title = {Liquidity {Risk} and {Contagion}},
	volume = {3},
	issn = {1542-4766},
	url = {https://doi.org/10.1162/jeea.2005.3.2-3.556},
	doi = {10.1162/jeea.2005.3.2-3.556},
	abstract = {This paper explores liquidity risk in a system of interconnected financial institutions when these institutions are subject to regulatory solvency constraints and mark their assets to market. When the market's demand for illiquid assets is less than perfectly elastic, sales by distressed institutions depress the market prices of such assets. Marking to market of the asset book can induce a further round of endogenously generated sales of assets, depressing prices further and inducing further sales. Contagious failures can result from small shocks. We investigate the theoretical basis for contagious failures and quantify them through simulation exercises. Liquidity requirements on institutions can be as effective as capital requirements in forestalling contagious failures.},
	number = {2-3},
	urldate = {2023-06-20},
	journal = {Journal of the European Economic Association},
	author = {Cifuentes, Rodrigo and Ferrucci, Gianluigi and Shin, Hyun Song},
	month = may,
	year = {2005},
	pages = {556--566},
	file = {Snapshot:/Users/zihanchen/Zotero/storage/J5KA8GV9/2281473.html:text/html},
}

@article{greenwood_vulnerable_2015,
	title = {Vulnerable banks},
	volume = {115},
	issn = {0304-405X},
	url = {https://www.sciencedirect.com/science/article/pii/S0304405X14002529},
	doi = {10.1016/j.jfineco.2014.11.006},
	abstract = {We present a model in which fire sales propagate shocks across bank balance sheets. When a bank experiences a negative shock to its equity, a natural way to return to target leverage is to sell assets. If potential buyers are limited, then asset sales depress prices, in which case one bank׳s sales impact other banks with common exposures. We show how this contagion effect adds up across the banking sector, and how it can be estimated empirically using balance sheet data. We compute bank exposures to system-wide deleveraging, as well as the spillovers induced by individual banks. Applying the model to European banks, we evaluate a variety of interventions to reduce their vulnerability to fire sales during the sovereign debt crisis.},
	language = {en},
	number = {3},
	urldate = {2023-06-20},
	journal = {Journal of Financial Economics},
	author = {Greenwood, Robin and Landier, Augustin and Thesmar, David},
	month = mar,
	year = {2015},
	keywords = {Systemic risk, Banks, Contagion, Fire sales, Price pressure},
	pages = {471--485},
	file = {ScienceDirect Full Text PDF:/Users/zihanchen/Zotero/storage/6UCFAURS/Greenwood et al. - 2015 - Vulnerable banks.pdf:application/pdf;ScienceDirect Snapshot:/Users/zihanchen/Zotero/storage/K4ITG9I8/S0304405X14002529.html:text/html},
}

@article{glasserman_how_2015,
	title = {How likely is contagion in financial networks?},
	volume = {50},
	issn = {0378-4266},
	url = {https://www.sciencedirect.com/science/article/pii/S0378426614000600},
	doi = {10.1016/j.jbankfin.2014.02.006},
	abstract = {Interconnections among financial institutions create potential channels for contagion and amplification of shocks to the financial system. We estimate the extent to which interconnections increase expected losses and defaults under a wide range of shock distributions. In contrast to most work on financial networks, we assume only minimal information about network structure and rely instead on information about the individual institutions that are the nodes of the network. The key node-level quantities are asset size, leverage, and a financial connectivity measure given by the fraction of a financial institution’s liabilities held by other financial institutions. We combine these measures to derive explicit bounds on the potential magnitude of network effects on contagion and loss amplification. Spillover effects are most significant when node sizes are heterogeneous and the originating node is highly leveraged and has high financial connectivity. Our results also highlight the importance of mechanisms that go beyond simple spillover effects to magnify shocks; these include bankruptcy costs, and mark-to-market losses resulting from credit quality deterioration or a loss of confidence. We illustrate the results with data on the European banking system.},
	language = {en},
	urldate = {2023-06-20},
	journal = {Journal of Banking \& Finance},
	author = {Glasserman, Paul and Young, H. Peyton},
	month = jan,
	year = {2015},
	keywords = {Financial network, Systemic risk, Contagion},
	pages = {383--399},
	file = {ScienceDirect Full Text PDF:/Users/zihanchen/Zotero/storage/NKPU3HIJ/Glasserman and Young - 2015 - How likely is contagion in financial networks.pdf:application/pdf},
}

@article{brunnermeier_deciphering_2009,
	title = {Deciphering the {Liquidity} and {Credit} {Crunch} 2007-2008},
	volume = {23},
	issn = {0895-3309},
	url = {https://www.aeaweb.org/articles?id=10.1257/jep.23.1.77},
	doi = {10.1257/jep.23.1.77},
	abstract = {The financial market turmoil in 2007 and 2008 has led to the most severe financial crisis since the Great Depression and threatens to have large repercussions on the real economy. The bursting of the housing bubble forced banks to write down several hundred billion dollars in bad loans caused by mortgage delinquencies. At the same time, the stock market capitalization of the major banks declined by more than twice as much. While the overall mortgage losses are large on an absolute scale, they are still relatively modest compared to the \$8 trillion of U.S. stock market wealth lost between October 2007, when the stock market reached an all-time high, and October 2008. This paper attempts to explain the economic mechanisms that caused losses in the mortgage market to amplify into such large dislocations and turmoil in the financial markets, and describes common economic threads that explain the plethora of market declines, liquidity dry-ups, defaults, and bailouts that occurred after the crisis broke in summer 2007.},
	language = {en},
	number = {1},
	urldate = {2023-06-20},
	journal = {Journal of Economic Perspectives},
	author = {Brunnermeier, Markus K.},
	month = mar,
	year = {2009},
	keywords = {Business Fluctuations, Cycles, Financial Markets and the Macroeconomy, Banks, Event Studies, Micro Finance Institutions, Mortgages, Financial Institutions and Services: Government Policy and Regulation, Information and Market Efficiency, Other Depository Institutions},
	pages = {77--100},
	file = {Full Text PDF:/Users/zihanchen/Zotero/storage/ZGYPKEVJ/Brunnermeier - 2009 - Deciphering the Liquidity and Credit Crunch 2007-2.pdf:application/pdf},
}

@article{elsinger_risk_2006,
	title = {Risk {Assessment} for {Banking} {Systems}},
	volume = {52},
	issn = {0025-1909},
	url = {https://pubsonline.informs.org/doi/abs/10.1287/mnsc.1060.0531},
	doi = {10.1287/mnsc.1060.0531},
	abstract = {We propose a new approach to assess systemic financial stability of a banking system using standard tools from modern risk management in combination with a network model of interbank loans. We apply our model to a unique data set of all Austrian banks. We find that correlation in banks' asset portfolios dominates contagion as the main source of systemic risk. Contagion is rare but can nonetheless wipe out a major part of the banking system. Low bankruptcy costs and an efficient crisis resolution policy are crucial to limit the systemwide impact of contagious default events. We compute the “value at risk” for a lender of last resort and find that the funds necessary to prevent contagion are surprisingly small.},
	number = {9},
	urldate = {2023-06-20},
	journal = {Management Science},
	author = {Elsinger, Helmut and Lehar, Alfred and Summer, Martin},
	month = sep,
	year = {2006},
	note = {Publisher: INFORMS},
	keywords = {financial stability, interbank market, risk management, systemic risk},
	pages = {1301--1314},
	file = {Full Text PDF:/Users/zihanchen/Zotero/storage/P2TA46Y7/Elsinger et al. - 2006 - Risk Assessment for Banking Systems.pdf:application/pdf},
}

@article{shleifer_fire_2011,
	title = {Fire {Sales} in {Finance} and {Macroeconomics}},
	volume = {25},
	issn = {0895-3309},
	url = {https://www.aeaweb.org/articles?id=10.1257/jep.25.1.29},
	doi = {10.1257/jep.25.1.29},
	abstract = {Analysts of the recent financial crisis often refer to the role of asset "fire sales" in depleting the balance sheets of financial institutions and aggravating the fragility of the financial system. The term "fire sale" has been around since the nineteenth century to describe firms selling smoke-damaged merchandise at cut-rate prices in the aftermath of a fire. But what are fire sales in broad financial markets with hundreds of participants? As we suggested in a 1992 paper, a fire sale is essentially a forced sale of an asset at a dislocated price. The asset sale is forced in the sense that the seller cannot pay creditors without selling assets. The price is dislocated because the highest potential bidders are typically involved in a similar activity as the seller, and are therefore themselves indebted and cannot borrow more to buy the asset. Indeed, rather than bidding for the asset, they might be selling similar assets themselves. Assets are then bought by nonspecialists who, knowing that they have less expertise with the assets in question, are only willing to buy at valuations that are much lower. In this paper, we selectively review some of the research on fire sales, emphasizing both concepts and supporting evidence. We begin by describing our 1992 model of fire sales and the related findings in empirical corporate finance. We then show that models of fire sales can account for several related phenomena during the recent financial crisis, including the contraction of the banking system and the failures of arbitrage in financial markets exemplified by historically unprecedented differences in prices of very similar securities. We then link fire sales to macroeconomics by discussing how such dislocations of security prices and the reduction in balance sheets of banks can reduce investment and output. Finally, we consider how the concept of fire sales can help us think about government interventions in financial markets, including the evidently successful Federal Reserve interventions in 2009. Fire sales are surely not the whole story of the financial crisis, but they are a phenomenon that binds together many elements of the crisis.},
	language = {en},
	number = {1},
	urldate = {2023-06-20},
	journal = {Journal of Economic Perspectives},
	author = {Shleifer, Andrei and Vishny, Robert},
	month = mar,
	year = {2011},
	keywords = {Micro Finance Institutions, Other Depository Institutions, Financial Crises, Banks, Mortgages, Financial Institutions and Services: Government Policy and Regulation},
	pages = {29--48},
	file = {Full Text PDF:/Users/zihanchen/Zotero/storage/W8L7VDLE/Shleifer and Vishny - 2011 - Fire Sales in Finance and Macroeconomics.pdf:application/pdf},
}

@article{hornik_multilayer_1989,
	title = {Multilayer feedforward networks are universal approximators},
	volume = {2},
	issn = {0893-6080},
	url = {https://www.sciencedirect.com/science/article/pii/0893608089900208},
	doi = {10.1016/0893-6080(89)90020-8},
	abstract = {This paper rigorously establishes that standard multilayer feedforward networks with as few as one hidden layer using arbitrary squashing functions are capable of approximating any Borel measurable function from one finite dimensional space to another to any desired degree of accuracy, provided sufficiently many hidden units are available. In this sense, multilayer feedforward networks are a class of universal approximators.},
	language = {en},
	number = {5},
	urldate = {2023-06-20},
	journal = {Neural Networks},
	author = {Hornik, Kurt and Stinchcombe, Maxwell and White, Halbert},
	month = jan,
	year = {1989},
	keywords = {Back-propagation networks, Feedforward networks, Mapping networks, Network representation capability, Sigma-Pi networks, Squashing functions, Stone-Weierstrass Theorem, Universal approximation},
	pages = {359--366},
	file = {ScienceDirect Snapshot:/Users/zihanchen/Zotero/storage/5BP2KL73/0893608089900208.html:text/html},
}

@article{feinstein_effects_2017,
	title = {The effects of leverage requirements and fire sales on financial contagion via asset liquidation strategies in financial networks},
	volume = {34},
	issn = {2196-7040},
	url = {https://www.degruyter.com/document/doi/10.1515/strm-2015-0030/html},
	doi = {10.1515/strm-2015-0030},
	abstract = {This paper provides a framework for modeling the financial system with multiple illiquid assets when liquidation of illiquid assets is caused by failure to meet a leverage requirement. This extends the network model of [6] which incorporates a single asset with fire sales and capital adequacy ratio. This also extends the network model of [14] which incorporates multiple illiquid assets with fire sales and no leverage ratios. We prove existence of equilibrium clearing payments and liquidation prices for a known liquidation strategy when leverage requirements are required. We also prove sufficient conditions for the existence of an equilibrium liquidation strategy with corresponding clearing payments and liquidation prices. Finally, we calibrate network models to asset and liability data for 50 banks in the United States from 2007–2014 in order to draw conclusions on systemic risk as a function of leverage requirements.},
	language = {en},
	number = {3-4},
	urldate = {2023-06-20},
	journal = {Statistics \& Risk Modeling},
	author = {Feinstein, Zachary and El-Masri, Fatena},
	month = sep,
	year = {2017},
	note = {Publisher: De Gruyter (A)},
	keywords = {Systemic risk, financial contagion, financial network, fire sales, leverage requirements},
	pages = {113--139},
	file = {Submitted Version:/Users/zihanchen/Zotero/storage/BL4IU64N/Feinstein and El-Masri - 2017 - The effects of leverage requirements and fire sale.pdf:application/pdf},
}

@article{zhang_explainable_2022,
	title = {An explainable artificial intelligence approach for financial distress prediction},
	volume = {59},
	issn = {0306-4573},
	url = {https://www.sciencedirect.com/science/article/pii/S0306457322001030},
	doi = {10.1016/j.ipm.2022.102988},
	abstract = {External stakeholders require accurate and explainable financial distress prediction (FDP) models. Complex machine learning algorithms offer high accuracy, but most of them lack explanatory power, resulting in external stakeholders being cautious in adopting them. Therefore, an explainable artificial intelligence approach including a whole process ensemble method and an explainable frame for FDP is here proposed. The ensemble algorithm from feature selection to predictor construction can achieve high accuracy according to the actual case, and the interpretation framework can meet the needs of external users by generating local explanations and global explanations. First, a two-stage scheme integrated with a filter and wrapper technique is designed for feature selection. Second, multiple ensemble models are explored and they are evaluated according to the actual case. Finally, Shapley additive explanations, counterfactual explanations and partial dependence plots are employed to enhance model interpretability. Taking financial data of Chinese listed companies from 2007 to 2020 as a dataset, the highest AUC is ensured by LightGBM with a value of 0.92. Local explanations help individual enterprises identify the key features which lead to their financial distress, and counterfactual explanations are produced to provide improvement strategies. By analyzing the features importance and the impact of feature interaction on the results, global explanations can improve the transparency and credibility of ‘black box’ models.},
	language = {en},
	number = {4},
	urldate = {2023-07-06},
	journal = {Information Processing \& Management},
	author = {Zhang, Zijiao and Wu, Chong and Qu, Shiyou and Chen, Xiaofang},
	month = jul,
	year = {2022},
	keywords = {Ensemble method, Explainable artificial intelligence, Feature selection, Financial distress prediction, SHapley Additive exPlanations},
	pages = {102988},
}

@inproceedings{dosilovic_explainable_2018,
	title = {Explainable artificial intelligence: {A} survey},
	shorttitle = {Explainable artificial intelligence},
	doi = {10.23919/MIPRO.2018.8400040},
	abstract = {In the last decade, with availability of large datasets and more computing power, machine learning systems have achieved (super)human performance in a wide variety of tasks. Examples of this rapid development can be seen in image recognition, speech analysis, strategic game planning and many more. The problem with many state-of-the-art models is a lack of transparency and interpretability. The lack of thereof is a major drawback in many applications, e.g. healthcare and finance, where rationale for model's decision is a requirement for trust. In the light of these issues, explainable artificial intelligence (XAI) has become an area of interest in research community. This paper summarizes recent developments in XAI in supervised learning, starts a discussion on its connection with artificial general intelligence, and gives proposals for further research directions.},
	booktitle = {2018 41st {International} {Convention} on {Information} and {Communication} {Technology}, {Electronics} and {Microelectronics} ({MIPRO})},
	author = {Došilović, Filip Karlo and Brčić, Mario and Hlupić, Nikica},
	month = may,
	year = {2018},
	keywords = {comprehensibility, Decision trees, explainability, explainable artificial intelligence, interpretability, Machine learning, Optimization, Predictive models, Supervised learning, Support vector machines},
	pages = {0210--0215},
}

@misc{misheva_explainable_2021,
	title = {Explainable {AI} in {Credit} {Risk} {Management}},
	url = {http://arxiv.org/abs/2103.00949},
	doi = {10.48550/arXiv.2103.00949},
	abstract = {Artificial Intelligence (AI) has created the single biggest technology revolution the world has ever seen. For the finance sector, it provides great opportunities to enhance customer experience, democratize financial services, ensure consumer protection and significantly improve risk management. While it is easier than ever to run state-of-the-art machine learning models, designing and implementing systems that support real-world finance applications have been challenging. In large part because they lack transparency and explainability which are important factors in establishing reliable technology and the research on this topic with a specific focus on applications in credit risk management. In this paper, we implement two advanced post-hoc model agnostic explainability techniques called Local Interpretable Model Agnostic Explanations (LIME) and SHapley Additive exPlanations (SHAP) to machine learning (ML)-based credit scoring models applied to the open-access data set offered by the US-based P2P Lending Platform, Lending Club. Specifically, we use LIME to explain instances locally and SHAP to get both local and global explanations. We discuss the results in detail and present multiple comparison scenarios by using various kernels available for explaining graphs generated using SHAP values. We also discuss the practical challenges associated with the implementation of these state-of-art eXplainabale AI (XAI) methods and document them for future reference. We have made an effort to document every technical aspect of this research, while at the same time providing a general summary of the conclusions.},
	urldate = {2023-07-06},
	publisher = {arXiv},
	author = {Misheva, Branka Hadji and Osterrieder, Joerg and Hirsa, Ali and Kulkarni, Onkar and Lin, Stephen Fung},
	month = mar,
	year = {2021},
	note = {arXiv:2103.00949 [cs, q-fin]},
	keywords = {Computer Science - Machine Learning, Quantitative Finance - Risk Management},
	file = {arXiv Fulltext PDF:/Users/zihanchen/Zotero/storage/4QXKAT5P/Misheva et al. - 2021 - Explainable AI in Credit Risk Management.pdf:application/pdf;arXiv.org Snapshot:/Users/zihanchen/Zotero/storage/N2GTXRXH/2103.html:text/html},
}

@article{bussmann_explainable_2020,
	title = {Explainable {AI} in {Fintech} {Risk} {Management}},
	volume = {3},
	issn = {2624-8212},
	url = {https://www.frontiersin.org/articles/10.3389/frai.2020.00026},
	abstract = {The paper proposes an explainable AI model that can be used in fintech risk management and, in particular, in measuring the risks that arise when credit is borrowed employing peer to peer lending platforms. The model employs Shapley values, so that AI predictions are interpreted according to the underlying explanatory variables. The empirical analysis of 15,000 small and medium companies asking for peer to peer lending credit reveals that both risky and not risky borrowers can be grouped according to a set of similar financial characteristics, which can be employed to explain and understand their credit score and, therefore, to predict their future behavior.},
	urldate = {2023-07-06},
	journal = {Frontiers in Artificial Intelligence},
	author = {Bussmann, Niklas and Giudici, Paolo and Marinelli, Dimitri and Papenbrock, Jochen},
	year = {2020},
	file = {Full Text PDF:/Users/zihanchen/Zotero/storage/SRH9GTW4/Bussmann et al. - 2020 - Explainable AI in Fintech Risk Management.pdf:application/pdf},
}

@misc{hanif_towards_2021,
	title = {Towards {Explainable} {Artificial} {Intelligence} in {Banking} and {Financial} {Services}},
	url = {http://arxiv.org/abs/2112.08441},
	doi = {10.48550/arXiv.2112.08441},
	abstract = {Artificial intelligence (AI) enables machines to learn from human experience, adjust to new inputs, and perform human-like tasks. AI is progressing rapidly and is transforming the way businesses operate, from process automation to cognitive augmentation of tasks and intelligent process/data analytics. However, the main challenge for human users would be to understand and appropriately trust the result of AI algorithms and methods. In this paper, to address this challenge, we study and analyze the recent work done in Explainable Artificial Intelligence (XAI) methods and tools. We introduce a novel XAI process, which facilitates producing explainable models while maintaining a high level of learning performance. We present an interactive evidence-based approach to assist human users in comprehending and trusting the results and output created by AI-enabled algorithms. We adopt a typical scenario in the Banking domain for analyzing customer transactions. We develop a digital dashboard to facilitate interacting with the algorithm results and discuss how the proposed XAI method can significantly improve the confidence of data scientists in understanding the result of AI-enabled algorithms.},
	urldate = {2023-07-06},
	publisher = {arXiv},
	author = {Hanif, Ambreen},
	month = dec,
	year = {2021},
	note = {arXiv:2112.08441 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
	file = {arXiv Fulltext PDF:/Users/zihanchen/Zotero/storage/A37TKGTH/Hanif - 2021 - Towards Explainable Artificial Intelligence in Ban.pdf:application/pdf;arXiv.org Snapshot:/Users/zihanchen/Zotero/storage/PPH4YGPG/2112.html:text/html},
}

@article{benhamou_explainable_2021,
	title = {Explainable {AI} ({XAI}) models applied to planning in financial markets},
	url = {https://openreview.net/forum?id=mJrKRgYm2f1},
	abstract = {Regime changes planning in financial markets is well known to be hard to explain and interpret. Can an asset manager explain clearly the intuition of his regime changes prediction on equity market ? To answer this question, we consider a gradient boosting decision trees (GBDT) approach to plan regime changes on S{\textbackslash}\&P 500 from a set of 150 technical, fundamental and macroeconomic features. We report an improved accuracy of GBDT over other machine learning (ML) methods on the S{\textbackslash}\&P 500 futures prices. We show that retaining fewer and carefully selected features provides improvements across all ML approaches. Shapley values have recently been introduced from game theory to the field of ML. This approach allows a robust identification of the most important variables planning stock market crises, and of a local explanation of the crisis probability at each date, through a consistent features attribution. We apply this methodology to analyse in detail the March 2020 financial meltdown, for which the model offered a timely out of sample prediction. This analysis unveils in particular the contrarian predictive role of the tech equity sector before and after the crash.},
	language = {en},
	urldate = {2023-07-06},
	author = {Benhamou, Eric and Ohana, Jean-Jacques and Saltiel, David and Guez, Beatrice},
	month = jun,
	year = {2021},
	file = {Full Text PDF:/Users/zihanchen/Zotero/storage/JJXN9ZCY/Benhamou et al. - 2021 - Explainable AI (XAI) models applied to planning in.pdf:application/pdf},
}

@article{gunning_xaiexplainable_2019,
	title = {{XAI}—{Explainable} artificial intelligence},
	volume = {4},
	url = {https://www.science.org/doi/abs/10.1126/scirobotics.aay7120},
	doi = {10.1126/scirobotics.aay7120},
	abstract = {Explainability is essential for users to effectively understand, trust, and manage powerful artificial intelligence applications.},
	number = {37},
	urldate = {2023-07-06},
	journal = {Science Robotics},
	author = {Gunning, David and Stefik, Mark and Choi, Jaesik and Miller, Timothy and Stumpf, Simone and Yang, Guang-Zhong},
	month = dec,
	year = {2019},
	note = {Publisher: American Association for the Advancement of Science},
	pages = {eaay7120},
	file = {Accepted Version:/Users/zihanchen/Zotero/storage/L5HD4AWP/Gunning et al. - 2019 - XAI—Explainable artificial intelligence.pdf:application/pdf},
}

@misc{quinn_explaining_2023,
	title = {Explaining {AI} in {Finance}: {Past}, {Present}, {Prospects}},
	shorttitle = {Explaining {AI} in {Finance}},
	url = {http://arxiv.org/abs/2306.02773},
	doi = {10.48550/arXiv.2306.02773},
	abstract = {This paper explores the journey of AI in finance, with a particular focus on the crucial role and potential of Explainable AI (XAI). We trace AI's evolution from early statistical methods to sophisticated machine learning, highlighting XAI's role in popular financial applications. The paper underscores the superior interpretability of methods like Shapley values compared to traditional linear regression in complex financial scenarios. It emphasizes the necessity of further XAI research, given forthcoming EU regulations. The paper demonstrates, through simulations, that XAI enhances trust in AI systems, fostering more responsible decision-making within finance.},
	urldate = {2023-07-06},
	publisher = {arXiv},
	author = {Quinn, Barry},
	month = jun,
	year = {2023},
	note = {arXiv:2306.02773 [q-fin]},
	keywords = {Quantitative Finance - General Finance, Quantitative Finance - Statistical Finance},
	file = {arXiv Fulltext PDF:/Users/zihanchen/Zotero/storage/T6F2IE2C/Quinn - 2023 - Explaining AI in Finance Past, Present, Prospects.pdf:application/pdf;arXiv.org Snapshot:/Users/zihanchen/Zotero/storage/55WDDEAM/2306.html:text/html},
}

@article{weber_applications_2023,
	title = {Applications of {Explainable} {Artificial} {Intelligence} in {Finance}—a systematic review of {Finance}, {Information} {Systems}, and {Computer} {Science} literature},
	issn = {2198-1639},
	url = {https://doi.org/10.1007/s11301-023-00320-0},
	doi = {10.1007/s11301-023-00320-0},
	abstract = {Digitalization and technologization affect numerous domains, promising advantages but also entailing risks. Hence, when decision-makers in highly-regulated domains like Finance implement these technological advances—especially Artificial Intelligence—regulators prescribe high levels of transparency, assuring the traceability of decisions for third parties. Explainable Artificial Intelligence (XAI) is of tremendous importance in this context. We provide an overview of current research on XAI in Finance with a systematic literature review screening 2,022 articles from leading Finance, Information Systems, and Computer Science outlets. We identify a set of 60 relevant articles, classify them according to the used XAI methods and goals that they aim to achieve, and provide an overview of XAI methods used in different Finance areas. Areas like risk management, portfolio optimization, and applications around the stock market are well-researched, while anti-money laundering is understudied. Researchers implement both transparent models and post-hoc explainability, while they recently favored the latter.},
	language = {en},
	urldate = {2023-07-06},
	journal = {Management Review Quarterly},
	author = {Weber, Patrick and Carl, K. Valerie and Hinz, Oliver},
	month = feb,
	year = {2023},
	keywords = {Explainable artificial intelligence, Finance, G00, L50, Machine learning, Review, Systematic literature review},
	file = {Full Text PDF:/Users/zihanchen/Zotero/storage/SZECIGUL/Weber et al. - 2023 - Applications of Explainable Artificial Intelligenc.pdf:application/pdf},
}

@article{du_techniques_2019,
	title = {Techniques for interpretable machine learning},
	volume = {63},
	issn = {0001-0782, 1557-7317},
	url = {https://dl.acm.org/doi/10.1145/3359786},
	doi = {10.1145/3359786},
	abstract = {Uncovering the mysterious ways machine learning models make decisions.},
	language = {en},
	number = {1},
	urldate = {2023-07-06},
	journal = {Communications of the ACM},
	author = {Du, Mengnan and Liu, Ninghao and Hu, Xia},
	month = dec,
	year = {2019},
	pages = {68--77},
	file = {Submitted Version:/Users/zihanchen/Zotero/storage/NKUXG36J/Du et al. - 2019 - Techniques for interpretable machine learning.pdf:application/pdf},
}

@article{nauta_anecdotal_2023,
	title = {From {Anecdotal} {Evidence} to {Quantitative} {Evaluation} {Methods}: {A} {Systematic} {Review} on {Evaluating} {Explainable} {AI}},
	issn = {0360-0300},
	shorttitle = {From {Anecdotal} {Evidence} to {Quantitative} {Evaluation} {Methods}},
	url = {https://dl.acm.org/doi/10.1145/3583558},
	doi = {10.1145/3583558},
	abstract = {The rising popularity of explainable artificial intelligence (XAI) to understand high-performing black boxes raised the question of how to evaluate explanations of machine learning (ML) models. While interpretability and explainability are often presented as a subjectively validated binary property, we consider it a multi-faceted concept. We identify 12 conceptual properties, such as Compactness and Correctness, that should be evaluated for comprehensively assessing the quality of an explanation. Our so-called Co-12 properties serve as categorization scheme for systematically reviewing the evaluation practices of more than 300 papers published in the last 7 years at major AI and ML conferences that introduce an XAI method. We find that 1 in 3 papers evaluate exclusively with anecdotal evidence, and 1 in 5 papers evaluate with users. This survey also contributes to the call for objective, quantifiable evaluation methods by presenting an extensive overview of quantitative XAI evaluation methods. Our systematic collection of evaluation methods provides researchers and practitioners with concrete tools to thoroughly validate, benchmark and compare new and existing XAI methods. The Co-12 categorization scheme and our identified evaluation methods open up opportunities to include quantitative metrics as optimization criteria during model training in order to optimize for accuracy and interpretability simultaneously.},
	urldate = {2023-07-06},
	journal = {ACM Computing Surveys},
	author = {Nauta, Meike and Trienes, Jan and Pathak, Shreyasi and Nguyen, Elisa and Peters, Michelle and Schmitt, Yasmin and Schlötterer, Jörg and van Keulen, Maurice and Seifert, Christin},
	month = feb,
	year = {2023},
	note = {Just Accepted},
	keywords = {evaluation, explainability, explainable AI, explainable artificial intelligence, interpretability, interpretable machine learning, quantitative evaluation methods, XAI},
	file = {Full Text PDF:/Users/zihanchen/Zotero/storage/XFW8QMKS/Nauta et al. - 2023 - From Anecdotal Evidence to Quantitative Evaluation.pdf:application/pdf},
}

@article{huang_deep_2020,
	title = {Deep learning in finance and banking: {A} literature review and classification},
	volume = {14},
	issn = {1673-7431},
	shorttitle = {Deep learning in finance and banking},
	url = {https://doi.org/10.1186/s11782-020-00082-6},
	doi = {10.1186/s11782-020-00082-6},
	abstract = {Deep learning has been widely applied in computer vision, natural language processing, and audio-visual recognition. The overwhelming success of deep learning as a data processing technique has sparked the interest of the research community. Given the proliferation of Fintech in recent years, the use of deep learning in finance and banking services has become prevalent. However, a detailed survey of the applications of deep learning in finance and banking is lacking in the existing literature. This study surveys and analyzes the literature on the application of deep learning models in the key finance and banking domains to provide a systematic evaluation of the model preprocessing, input data, and model evaluation. Finally, we discuss three aspects that could affect the outcomes of financial deep learning models. This study provides academics and practitioners with insight and direction on the state-of-the-art of the application of deep learning models in finance and banking.},
	number = {1},
	urldate = {2023-07-06},
	journal = {Frontiers of Business Research in China},
	author = {Huang, Jian and Chai, Junyi and Cho, Stella},
	month = jun,
	year = {2020},
	keywords = {Banking, Deep learning, Finance, Fintech, Literature review},
	pages = {13},
	file = {Full Text PDF:/Users/zihanchen/Zotero/storage/ZDSXPLJA/Huang et al. - 2020 - Deep learning in finance and banking A literature.pdf:application/pdf},
}

@article{nicholls_financial_2021,
	title = {Financial {Cybercrime}: {A} {Comprehensive} {Survey} of {Deep} {Learning} {Approaches} to {Tackle} the {Evolving} {Financial} {Crime} {Landscape}},
	volume = {9},
	issn = {2169-3536},
	shorttitle = {Financial {Cybercrime}},
	doi = {10.1109/ACCESS.2021.3134076},
	abstract = {Machine Learning and Deep Learning methods are widely adopted across financial domains to support trading activities, mobile banking, payments, and making customer credit decisions. These methods also play a vital role in combating financial crime, fraud, and cyberattacks. Financial crime is increasingly being committed over cyberspace, and cybercriminals are using a combination of hacking and social engineering techniques which are bypassing current financial and corporate institution security. With this comes a new umbrella term to capture the evolving landscape which is financial cybercrime. It is a combination of financial crime, hacking, and social engineering committed over cyberspace for the sole purpose of illegal economic gain. Identifying financial cybercrime-related activities is a hard problem, for example, a highly restrictive algorithm may block all suspicious activity obstructing genuine customer business. Navigating and identifying legitimate illicit transactions is not the only issue faced by financial institutions, there is a growing demand of transparency, fairness, and privacy from customers and regulators, which imposes unique constraints on the application of artificial intelligence methods to detect fraud-related activities. Traditionally, rule based systems and shallow anomaly detection methods have been applied to detect financial crime and fraud, but recent developments have seen graph based techniques and neural network models being used to tackle financial cybercrime. There is still a lack of a holistic understanding of the financial cybercrime ecosystem, relevant methods, and their drawbacks and new emerging open problems in this domain in spite of their popularity. In this survey, we aim to bridge the gap by studying the financial cybercrime ecosystem based on four axes: (a) different fraud methods adopted by criminals; (b) relevant systems, algorithms, drawbacks, constraints, and metrics used to combat each fraud type; (c) the relevant personas and stakeholders involved; (d) open and emerging problems in the financial cybercrime domain.},
	journal = {IEEE Access},
	author = {Nicholls, Jack and Kuppa, Aditya and Le-Khac, Nhien-An},
	year = {2021},
	note = {Conference Name: IEEE Access},
	keywords = {Anomaly detection, artificial intelligence, Computer crime, cryptocurrency analysis, cybersecurity, deep learning, Deep learning, Economics, Finance, financial crime, Graph neural networks, hacking, Machine learning, SIM-swap analysis, social engineering},
	pages = {163965--163986},
	file = {IEEE Xplore Full Text PDF:/Users/zihanchen/Zotero/storage/UXQLI5P9/Nicholls et al. - 2021 - Financial Cybercrime A Comprehensive Survey of De.pdf:application/pdf},
}

@article{elhoseny_deep_2022,
	title = {Deep {Learning}-{Based} {Model} for {Financial} {Distress} {Prediction}},
	issn = {1572-9338},
	url = {https://doi.org/10.1007/s10479-022-04766-5},
	doi = {10.1007/s10479-022-04766-5},
	abstract = {Predicting bankruptcies and assessing credit risk are two of the most pressing issues in finance. Therefore, financial distress prediction and credit scoring remain hot research topics in the finance sector. Earlier studies have focused on the design of statistical approaches and machine learning models to predict a company's financial distress. In this study, an adaptive whale optimization algorithm with deep learning (AWOA-DL) technique is used to create a new financial distress prediction model. The goal of the AWOA-DL approach is to determine whether a company is experiencing financial distress or not. A deep neural network (DNN) model called multilayer perceptron based predictive and AWOA-based hyperparameter tuning processes are used in the AWOA-DL method. Primarily, the DNN model receives the financial data as input and predicts financial distress. In addition, the AWOA is applied to tune the DNN model's hyperparameters, thereby raising the predictive outcome. The proposed model is applied in three stages: preprocessing, hyperparameter tuning using AWOA, and the prediction phase. A comprehensive simulation took place on four datasets, and the results pointed out the supremacy of the AWOA-DL method over other compared techniques by achieving an average accuracy of 95.8\%, where the average accuracy equals 93.8\%, 89.6\%, 84.5\%, and 78.2\% for compared models.},
	language = {en},
	urldate = {2023-07-06},
	journal = {Annals of Operations Research},
	author = {Elhoseny, Mohamed and Metawa, Noura and Sztano, Gabor and El-hasnony, Ibrahim M.},
	month = may,
	year = {2022},
	keywords = {Deep learning, Deep Neural network, Financial distress, Machine learning, Parameter tuning, Prediction model},
	file = {Full Text PDF:/Users/zihanchen/Zotero/storage/2H8MKEEQ/Elhoseny et al. - 2022 - Deep Learning-Based Model for Financial Distress P.pdf:application/pdf},
}

@article{marques-silva_delivering_2022,
	title = {Delivering {Trustworthy} {AI} through {Formal} {XAI}},
	volume = {36},
	copyright = {Copyright (c) 2022 Association for the Advancement of Artificial Intelligence},
	issn = {2374-3468},
	url = {https://ojs.aaai.org/index.php/AAAI/article/view/21499},
	doi = {10.1609/aaai.v36i11.21499},
	abstract = {The deployment of systems of artificial intelligence (AI) in high-risk settings warrants the need for trustworthy AI. This crucial requirement is highlighted by recent EU guidelines and regulations, but also by recommendations from OECD and UNESCO, among several other examples. One critical premise of trustworthy AI involves the necessity of finding explanations that offer reliable guarantees of soundness. This paper argues that the best known eXplainable AI (XAI) approaches fail to provide sound explanations, or that alternatively find explanations which can exhibit significant redundancy. The solution to these drawbacks are explanation approaches that offer formal guarantees of rigor. These formal explanations are not only sound but guarantee irredundancy. This paper summarizes the recent developments in the emerging discipline of formal XAI. The paper also outlines existing challenges for formal XAI.},
	language = {en},
	number = {11},
	urldate = {2023-07-06},
	journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
	author = {Marques-Silva, Joao and Ignatiev, Alexey},
	month = jun,
	year = {2022},
	note = {Number: 11},
	keywords = {Reliable And Irredundant Explanations},
	pages = {12342--12350},
	file = {Full Text PDF:/Users/zihanchen/Zotero/storage/BJXZXPJI/Marques-Silva and Ignatiev - 2022 - Delivering Trustworthy AI through Formal XAI.pdf:application/pdf},
}

@misc{yang_generating_2020,
	title = {Generating {Plausible} {Counterfactual} {Explanations} for {Deep} {Transformers} in {Financial} {Text} {Classification}},
	url = {http://arxiv.org/abs/2010.12512},
	doi = {10.48550/arXiv.2010.12512},
	abstract = {Corporate mergers and acquisitions (M\&A) account for billions of dollars of investment globally every year, and offer an interesting and challenging domain for artificial intelligence. However, in these highly sensitive domains, it is crucial to not only have a highly robust and accurate model, but be able to generate useful explanations to garner a user's trust in the automated system. Regrettably, the recent research regarding eXplainable AI (XAI) in financial text classification has received little to no attention, and many current methods for generating textual-based explanations result in highly implausible explanations, which damage a user's trust in the system. To address these issues, this paper proposes a novel methodology for producing plausible counterfactual explanations, whilst exploring the regularization benefits of adversarial training on language models in the domain of FinTech. Exhaustive quantitative experiments demonstrate that not only does this approach improve the model accuracy when compared to the current state-of-the-art and human performance, but it also generates counterfactual explanations which are significantly more plausible based on human trials.},
	urldate = {2023-07-06},
	publisher = {arXiv},
	author = {Yang, Linyi and Kenny, Eoin M. and Ng, Tin Lok James and Yang, Yi and Smyth, Barry and Dong, Ruihai},
	month = oct,
	year = {2020},
	note = {arXiv:2010.12512 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
	file = {arXiv Fulltext PDF:/Users/zihanchen/Zotero/storage/5J3UDD48/Yang et al. - 2020 - Generating Plausible Counterfactual Explanations f.pdf:application/pdf;arXiv.org Snapshot:/Users/zihanchen/Zotero/storage/KGHVA5NC/2010.html:text/html},
}

@inproceedings{demajo_explainable_2020,
	title = {Explainable {AI} for {Interpretable} {Credit} {Scoring}},
	url = {http://arxiv.org/abs/2012.03749},
	doi = {10.5121/csit.2020.101516},
	abstract = {With the ever-growing achievements in Artificial Intelligence (AI) and the recent boosted enthusiasm in Financial Technology (FinTech), applications such as credit scoring have gained substantial academic interest. Credit scoring helps financial experts make better decisions regarding whether or not to accept a loan application, such that loans with a high probability of default are not accepted. Apart from the noisy and highly imbalanced data challenges faced by such credit scoring models, recent regulations such as the `right to explanation' introduced by the General Data Protection Regulation (GDPR) and the Equal Credit Opportunity Act (ECOA) have added the need for model interpretability to ensure that algorithmic decisions are understandable and coherent. An interesting concept that has been recently introduced is eXplainable AI (XAI), which focuses on making black-box models more interpretable. In this work, we present a credit scoring model that is both accurate and interpretable. For classification, state-of-the-art performance on the Home Equity Line of Credit (HELOC) and Lending Club (LC) Datasets is achieved using the Extreme Gradient Boosting (XGBoost) model. The model is then further enhanced with a 360-degree explanation framework, which provides different explanations (i.e. global, local feature-based and local instance-based) that are required by different people in different situations. Evaluation through the use of functionallygrounded, application-grounded and human-grounded analysis show that the explanations provided are simple, consistent as well as satisfy the six predetermined hypotheses testing for correctness, effectiveness, easy understanding, detail sufficiency and trustworthiness.},
	urldate = {2023-07-06},
	booktitle = {Computer {Science} \& {Information} {Technology} ({CS} \& {IT})},
	author = {Demajo, Lara Marie and Vella, Vince and Dingli, Alexiei},
	month = nov,
	year = {2020},
	note = {arXiv:2012.03749 [cs, q-fin]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Quantitative Finance - Risk Management},
	pages = {185--203},
	file = {arXiv Fulltext PDF:/Users/zihanchen/Zotero/storage/KE5N5VC7/Demajo et al. - 2020 - Explainable AI for Interpretable Credit Scoring.pdf:application/pdf;arXiv.org Snapshot:/Users/zihanchen/Zotero/storage/G3WF3PSD/2012.html:text/html},
}

@article{lin_machine_2012,
	title = {Machine {Learning} in {Financial} {Crisis} {Prediction}: {A} {Survey}},
	volume = {42},
	issn = {1558-2442},
	shorttitle = {Machine {Learning} in {Financial} {Crisis} {Prediction}},
	doi = {10.1109/TSMCC.2011.2170420},
	abstract = {For financial institutions, the ability to predict or forecast business failures is crucial, as incorrect decisions can have direct financial consequences. Bankruptcy prediction and credit scoring are the two major research problems in the accounting and finance domain. In the literature, a number of models have been developed to predict whether borrowers are in danger of bankruptcy and whether they should be considered a good or bad credit risk. Since the 1990s, machine-learning techniques, such as neural networks and decision trees, have been studied extensively as tools for bankruptcy prediction and credit score modeling. This paper reviews 130 related journal papers from the period between 1995 and 2010, focusing on the development of state-of-the-art machine-learning techniques, including hybrid and ensemble classifiers. Related studies are compared in terms of classifier design, datasets, baselines, and other experimental factors. This paper presents the current achievements and limitations associated with the development of bankruptcy-prediction and credit-scoring models employing machine learning. We also provide suggestions for future research.},
	number = {4},
	journal = {IEEE Transactions on Systems, Man, and Cybernetics, Part C (Applications and Reviews)},
	author = {Lin, Wei-Yang and Hu, Ya-Han and Tsai, Chih-Fong},
	month = jul,
	year = {2012},
	note = {Conference Name: IEEE Transactions on Systems, Man, and Cybernetics, Part C (Applications and Reviews)},
	keywords = {Accuracy, Bankruptcy prediction, Boosting, credit scoring, ensemble classifiers, Genetic algorithms, hybrid classifiers, machine learning, Neural networks, Predictive models, Training},
	pages = {421--436},
}

@misc{allen_survey_2020,
	address = {Rochester, NY},
	type = {{SSRN} {Scholarly} {Paper}},
	title = {A {Survey} of {Fintech} {Research} and {Policy} {Discussion}},
	url = {https://papers.ssrn.com/abstract=3622468},
	doi = {10.21799/frbp.wp.2020.21},
	abstract = {The intersection of finance and technology, known as fintech, has resulted in the dramatic growth of innovations and has changed the entire financial landscape. While fintech has a critical role to play in democratizing credit access to the unbanked and thin-file consumers around the globe, those consumers who are currently well served also turn to fintech for faster services and greater transparency. Fintech, particularly the blockchain, has the potential to be disruptive to financial systems and intermediation. Our aim in this paper is to provide a comprehensive fintech literature survey with relevant research studies and policy discussion around the various aspects of fintech. The topics include marketplace and peer-to-peer lending, credit scoring, alternative data, distributed ledger technologies, blockchain, smart contracts, cryptocurrencies and initial coin offerings, central bank digital currency, robo-advising, quantitative investment and trading strategies, cybersecurity, identity theft, cloud computing, use of big data and artificial intelligence and machine learning, identity and fraud detection, anti-money laundering, Know Your Customers, natural language processing, regtech, insuretech, sandboxes, and fintech regulations.},
	language = {en},
	urldate = {2023-07-06},
	author = {Allen, Franklin and Gu, Xian and Jagtiani, Julapa},
	month = may,
	year = {2020},
	keywords = {A Survey of Fintech Research and Policy Discussion, Franklin Allen, Julapa Jagtiani, SSRN, Xian Gu},
	file = {Full Text PDF:/Users/zihanchen/Zotero/storage/V88X95DC/Allen et al. - 2020 - A Survey of Fintech Research and Policy Discussion.pdf:application/pdf},
}

@article{lai_statistical_2020,
	title = {Statistical models and stochastic optimization in financial technology and investment science},
	volume = {5},
	issn = {2380-2898},
	url = {https://www.intlpress.com/site/pub/pages/journals/items/amsa/content/vols/0005/0002/a005/abstract.php},
	doi = {10.4310/AMSA.2020.v5.n2.a5},
	abstract = {International Press of Boston - publishers of scholarly mathematical and scientific journals and books},
	language = {EN},
	number = {2},
	urldate = {2023-07-06},
	journal = {Annals of Mathematical Sciences and Applications},
	author = {Lai, Tze L. and Liao, Shih-Wei and Wong, Samuel P. S. and Xu, Huanzhong},
	month = sep,
	year = {2020},
	note = {Publisher: International Press of Boston},
	pages = {317--345},
}

@article{suryono_challenges_2020,
	title = {Challenges and {Trends} of {Financial} {Technology} ({Fintech}): {A} {Systematic} {Literature} {Review}},
	volume = {11},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2078-2489},
	shorttitle = {Challenges and {Trends} of {Financial} {Technology} ({Fintech})},
	url = {https://www.mdpi.com/2078-2489/11/12/590},
	doi = {10.3390/info11120590},
	abstract = {Digital transformation creates challenges in all industries and business sectors. The development of digital transformation has also clearly triggered the emergence of fintech (financial technology) initiatives, which are recognized as some of the most important innovations in the financial industry. These initiatives are developing rapidly, driven in part by the sharing economy, regulations, and information technology. However, research in the field of fintech remains in its infancy. Fintech offers several services, such as funding, payment (including electronic wallets), e-aggregators, e-trading, and e-insurance, and cryptocurrencies such as Bitcoin. This provides an opportunity to more closely examine fintech’s research challenges and trends. This study aims to (1) determine the state of the art of financial technology research; (2) identify gaps in the financial technology research field; and (3) identify challenges and trends for future research potential. The novel proposal in this study includes theoretical contributions regarding financial technology. Using the systematic literature review approach of Kitchenham, in addition to thematic analysis, meta-analysis and observation to validate the quality of literature and analysis, the results of this study provide a theoretical basis fintech research from an information systems perspective, including the formulation of fintech technology concepts and their development.},
	language = {en},
	number = {12},
	urldate = {2023-07-06},
	journal = {Information},
	author = {Suryono, Ryan Randy and Budi, Indra and Purwandari, Betty},
	month = dec,
	year = {2020},
	note = {Number: 12
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {financial technology, fintech, meta-analysis, systematic literature review, thematic analysis},
	pages = {590},
	file = {Full Text PDF:/Users/zihanchen/Zotero/storage/ADLCVXZX/Suryono et al. - 2020 - Challenges and Trends of Financial Technology (Fin.pdf:application/pdf},
}

@article{gai_survey_2018,
	title = {A survey on {FinTech}},
	volume = {103},
	issn = {1084-8045},
	url = {https://www.sciencedirect.com/science/article/pii/S1084804517303247},
	doi = {10.1016/j.jnca.2017.10.011},
	abstract = {As a new term in the financial industry, FinTech has become a popular term that describes novel technologies adopted by the financial service institutions. This term covers a large scope of techniques, from data security to financial service deliveries. An accurate and up-to-date awareness of FinTech has an urgent demand for both academics and professionals. This work aims to produce a survey of FinTech by collecting and reviewing contemporary achievements, by which a theoretical data-driven FinTech framework is proposed. Five technical aspects are summarized and involved, which include security and privacy, data techniques, hardware and infrastructure, applications and management, and service models. The main findings of this work are fundamentals of forming active FinTech solutions.},
	language = {en},
	urldate = {2023-07-06},
	journal = {Journal of Network and Computer Applications},
	author = {Gai, Keke and Qiu, Meikang and Sun, Xiaotong},
	month = feb,
	year = {2018},
	keywords = {Big data, Cloud computing, Cyber security, Data-driven framework, Financial computing, FinTech},
	pages = {262--273},
}

@article{sun_explain_2022,
	title = {Explain and improve: {LRP}-inference fine-tuning for image captioning models},
	volume = {77},
	issn = {1566-2535},
	shorttitle = {Explain and improve},
	url = {https://www.sciencedirect.com/science/article/pii/S1566253521001494},
	doi = {10.1016/j.inffus.2021.07.008},
	abstract = {This paper analyzes the predictions of image captioning models with attention mechanisms beyond visualizing the attention itself. We develop variants of Layer-wise Relevance Propagation (LRP) and gradient-based explanation methods, tailored to image captioning models with attention mechanisms. We compare the interpretability of attention heatmaps systematically against the explanations provided by explanation methods such as LRP, Grad-CAM, and Guided Grad-CAM. We show that explanation methods provide simultaneously pixel-wise image explanations (supporting and opposing pixels of the input image) and linguistic explanations (supporting and opposing words of the preceding sequence) for each word in the predicted captions. We demonstrate with extensive experiments that explanation methods (1) can reveal additional evidence used by the model to make decisions compared to attention; (2) correlate to object locations with high precision; (3) are helpful to “debug” the model, e.g. by analyzing the reasons for hallucinated object words. With the observed properties of explanations, we further design an LRP-inference fine-tuning strategy that reduces the issue of object hallucination in image captioning models, and meanwhile, maintains the sentence fluency. We conduct experiments with two widely used attention mechanisms: the adaptive attention mechanism calculated with the additive attention and the multi-head attention mechanism calculated with the scaled dot product.},
	language = {en},
	urldate = {2023-07-06},
	journal = {Information Fusion},
	author = {Sun, Jiamei and Lapuschkin, Sebastian and Samek, Wojciech and Binder, Alexander},
	month = jan,
	year = {2022},
	keywords = {Attention, Explainable AI, Image captioning, Neural networks},
	pages = {233--246},
	file = {ScienceDirect Full Text PDF:/Users/zihanchen/Zotero/storage/G8VLFHAB/Sun et al. - 2022 - Explain and improve LRP-inference fine-tuning for.pdf:application/pdf},
}

@inproceedings{bhatt_explainable_2020,
	address = {New York, NY, USA},
	series = {{FAT}* '20},
	title = {Explainable machine learning in deployment},
	isbn = {978-1-4503-6936-7},
	url = {https://dl.acm.org/doi/10.1145/3351095.3375624},
	doi = {10.1145/3351095.3375624},
	abstract = {Explainable machine learning offers the potential to provide stakeholders with insights into model behavior by using various methods such as feature importance scores, counterfactual explanations, or influential training data. Yet there is little understanding of how organizations use these methods in practice. This study explores how organizations view and use explainability for stakeholder consumption. We find that, currently, the majority of deployments are not for end users affected by the model but rather for machine learning engineers, who use explainability to debug the model itself. There is thus a gap between explainability in practice and the goal of transparency, since explanations primarily serve internal stakeholders rather than external ones. Our study synthesizes the limitations of current explainability techniques that hamper their use for end users. To facilitate end user interaction, we develop a framework for establishing clear goals for explainability. We end by discussing concerns raised regarding explainability.},
	urldate = {2023-07-06},
	booktitle = {Proceedings of the 2020 {Conference} on {Fairness}, {Accountability}, and {Transparency}},
	publisher = {Association for Computing Machinery},
	author = {Bhatt, Umang and Xiang, Alice and Sharma, Shubham and Weller, Adrian and Taly, Ankur and Jia, Yunhan and Ghosh, Joydeep and Puri, Ruchir and Moura, José M. F. and Eckersley, Peter},
	month = jan,
	year = {2020},
	keywords = {deployed systems, explainability, machine learning, qualitative study, transparency},
	pages = {648--657},
	file = {Full Text PDF:/Users/zihanchen/Zotero/storage/KNHRP9RS/Bhatt et al. - 2020 - Explainable machine learning in deployment.pdf:application/pdf},
}

@article{miller_explanation_2019,
	title = {Explanation in artificial intelligence: {Insights} from the social sciences},
	volume = {267},
	issn = {0004-3702},
	shorttitle = {Explanation in artificial intelligence},
	url = {https://www.sciencedirect.com/science/article/pii/S0004370218305988},
	doi = {10.1016/j.artint.2018.07.007},
	abstract = {There has been a recent resurgence in the area of explainable artificial intelligence as researchers and practitioners seek to provide more transparency to their algorithms. Much of this research is focused on explicitly explaining decisions or actions to a human observer, and it should not be controversial to say that looking at how humans explain to each other can serve as a useful starting point for explanation in artificial intelligence. However, it is fair to say that most work in explainable artificial intelligence uses only the researchers' intuition of what constitutes a ‘good’ explanation. There exist vast and valuable bodies of research in philosophy, psychology, and cognitive science of how people define, generate, select, evaluate, and present explanations, which argues that people employ certain cognitive biases and social expectations to the explanation process. This paper argues that the field of explainable artificial intelligence can build on this existing research, and reviews relevant papers from philosophy, cognitive psychology/science, and social psychology, which study these topics. It draws out some important findings, and discusses ways that these can be infused with work on explainable artificial intelligence.},
	language = {en},
	urldate = {2023-07-06},
	journal = {Artificial Intelligence},
	author = {Miller, Tim},
	month = feb,
	year = {2019},
	keywords = {Explainability, Explainable AI, Explanation, Interpretability, Transparency},
	pages = {1--38},
	file = {ScienceDirect Full Text PDF:/Users/zihanchen/Zotero/storage/KUPXIX8P/Miller - 2019 - Explanation in artificial intelligence Insights f.pdf:application/pdf},
}

@article{rudin2019we,
  title={Why are we using black box models in AI when we don’t need to? A lesson from an explainable AI competition},
  author={Rudin, Cynthia and Radin, Joanna},
  journal={Harvard Data Science Review},
  volume={1},
  number={2},
  pages={1--9},
  year={2019},
  publisher={PubPub}
}

@article{park_explainability_2021,
	title = {Explainability of {Machine} {Learning} {Models} for {Bankruptcy} {Prediction}},
	volume = {9},
	issn = {2169-3536},
	doi = {10.1109/ACCESS.2021.3110270},
	abstract = {As the amount of data increases, it is more likely that the assumptions in the existing economic analysis model are unsatisfied or make it difficult to establish a new analysis model. Therefore, there has been increased demand for applying the machine learning methodology to bankruptcy prediction due to its high performance. By contrast, machine learning models usually operate as black-boxes but credit rating regulatory systems require the provisioning of appropriate information regarding credit rating standards. If machine learning models have sufficient interpretablility, they would have the potential to be used as effective analytical models in bankruptcy prediction. From this aspect, we study the explainability of machine learning models for bankruptcy prediction by applying the Local Interpretable Model-Agnostic Explanations (LIME) algorithm, which measures the feature importance for each data point. To compare how the feature importance measured through LIME differs from that of models themselves, we first applied this algorithm to typical tree-based models that have ability to measure the feature importance of the models themselves. We showed that the feature importance measured through LIME could be a consistent generalization of the feature importance measured by tree-based models themselves. Moreover, we study the consistency of the feature importance through the model's predicted bankruptcy probability, which suggests the possibility that observations of important features can be used as a basis for the fair treatment of loan eligibility requirements.},
	journal = {IEEE Access},
	author = {Park, Min Sue and Son, Hwijae and Hyun, Chongseok and Hwang, Hyung Ju},
	year = {2021},
	note = {Conference Name: IEEE Access},
	keywords = {Analytical models, Bankruptcy, Bankruptcy prediction, Companies, Data models, explainable AI, Feature extraction, feature importance, machine learning, Machine learning, Predictive models},
	pages = {124887--124899},
	file = {IEEE Xplore Full Text PDF:/Users/zihanchen/Zotero/storage/PPBXZDKJ/Park et al. - 2021 - Explainability of Machine Learning Models for Bank.pdf:application/pdf},
}

@article{goodman_european_2017,
	title = {European {Union} {Regulations} on {Algorithmic} {Decision}-{Making} and a “{Right} to {Explanation}”},
	volume = {38},
	copyright = {Copyright (c) 2017 AI Magazine},
	issn = {2371-9621},
	url = {https://ojs.aaai.org/aimagazine/index.php/aimagazine/article/view/2741},
	doi = {10.1609/aimag.v38i3.2741},
	abstract = {We summarize the potential impact that the European Union’s new General Data Protection Regulation will have on the routine use of machine learning algorithms. Slated to take effect as law across the EU in 2018, it will restrict automated individual decision-making (that is, algorithms that make decisions based on user-level predictors) which “significantly affect” users. The law will also effectively create a “right to explanation,” whereby a user can ask for an explanation of an algorithmic decision that was made about them. We argue that while this law will pose large challenges for industry, it highlights opportunities for computer scientists to take the lead in designing algorithms and evaluation frameworks which avoid discrimination and enable explanation.},
	language = {en},
	number = {3},
	urldate = {2023-07-06},
	journal = {AI Magazine},
	author = {Goodman, Bryce and Flaxman, Seth},
	month = oct,
	year = {2017},
	note = {Number: 3},
	pages = {50--57},
	file = {Full Text PDF:/Users/zihanchen/Zotero/storage/A6WXBEI8/Goodman and Flaxman - 2017 - European Union Regulations on Algorithmic Decision.pdf:application/pdf},
}

@misc{marcus_deep_2018,
	title = {Deep {Learning}: {A} {Critical} {Appraisal}},
	shorttitle = {Deep {Learning}},
	url = {http://arxiv.org/abs/1801.00631},
	doi = {10.48550/arXiv.1801.00631},
	abstract = {Although deep learning has historical roots going back decades, neither the term "deep learning" nor the approach was popular just over five years ago, when the field was reignited by papers such as Krizhevsky, Sutskever and Hinton's now classic (2012) deep network model of Imagenet. What has the field discovered in the five subsequent years? Against a background of considerable progress in areas such as speech recognition, image recognition, and game playing, and considerable enthusiasm in the popular press, I present ten concerns for deep learning, and suggest that deep learning must be supplemented by other techniques if we are to reach artificial general intelligence.},
	urldate = {2023-07-06},
	publisher = {arXiv},
	author = {Marcus, Gary},
	month = jan,
	year = {2018},
	note = {arXiv:1801.00631 [cs, stat]},
	keywords = {97R40, Computer Science - Artificial Intelligence, Computer Science - Machine Learning, I.2.0, I.2.6, Statistics - Machine Learning},
	file = {arXiv Fulltext PDF:/Users/zihanchen/Zotero/storage/IIQ46KQK/Marcus - 2018 - Deep Learning A Critical Appraisal.pdf:application/pdf;arXiv.org Snapshot:/Users/zihanchen/Zotero/storage/9QRRZ8I2/1801.html:text/html},
}

@article{edwards_slave_2017,
	title = {Slave to the {Algorithm}? {Why} a '{Right} to an {Explanation}' {Is} {Probably} {Not} the {Remedy} {You} {Are} {Looking} for},
	volume = {16},
	shorttitle = {Slave to the {Algorithm}?},
	url = {https://heinonline.org/HOL/Page?handle=hein.journals/dltr16&id=18&div=&collection=},
	journal = {Duke Law \& Technology Review},
	author = {Edwards, Lilian and Veale, Michael},
	year = {2017},
	pages = {18},
}

@article{jin_pareto-based_2008,
	title = {Pareto-{Based} {Multiobjective} {Machine} {Learning}: {An} {Overview} and {Case} {Studies}},
	volume = {38},
	issn = {1558-2442},
	shorttitle = {Pareto-{Based} {Multiobjective} {Machine} {Learning}},
	doi = {10.1109/TSMCC.2008.919172},
	abstract = {Machine learning is inherently a multiobjective task. Traditionally, however, either only one of the objectives is adopted as the cost function or multiple objectives are aggregated to a scalar cost function. This can be mainly attributed to the fact that most conventional learning algorithms can only deal with a scalar cost function. Over the last decade, efforts on solving machine learning problems using the Pareto-based multiobjective optimization methodology have gained increasing impetus, particularly due to the great success of multiobjective optimization using evolutionary algorithms and other population-based stochastic search methods. It has been shown that Pareto-based multiobjective learning approaches are more powerful compared to learning algorithms with a scalar cost function in addressing various topics of machine learning, such as clustering, feature selection, improvement of generalization ability, knowledge extraction, and ensemble generation. One common benefit of the different multiobjective learning approaches is that a deeper insight into the learning problem can be gained by analyzing the Pareto front composed of multiple Pareto-optimal solutions. This paper provides an overview of the existing research on multiobjective machine learning, focusing on supervised learning. In addition, a number of case studies are provided to illustrate the major benefits of the Pareto-based approach to machine learning, e.g., how to identify interpretable models and models that can generalize on unseen data from the obtained Pareto-optimal solutions. Three approaches to Pareto-based multiobjective ensemble generation are compared and discussed in detail. Finally, potentially interesting topics in multiobjective machine learning are suggested.},
	number = {3},
	journal = {IEEE Transactions on Systems, Man, and Cybernetics, Part C (Applications and Reviews)},
	author = {Jin, Yaochu and Sendhoff, Bernhard},
	month = may,
	year = {2008},
	note = {Conference Name: IEEE Transactions on Systems, Man, and Cybernetics, Part C (Applications and Reviews)},
	keywords = {Clustering algorithms, Cost function, Ensemble, Evolutionary computation, evolutionary multiobjective optimization, generalization, machine learning, Machine learning, Machine learning algorithms, multiobjective learning, multiobjective optimization, neural networks, Pareto analysis, Pareto optimization, Power generation, Search methods, Stochastic processes, Supervised learning},
	pages = {397--415},
}

@article{lecun_deep_2015,
	title = {Deep learning},
	volume = {521},
	copyright = {2015 Springer Nature Limited},
	issn = {1476-4687},
	url = {https://www.nature.com/articles/nature14539},
	doi = {10.1038/nature14539},
	abstract = {Deep learning allows computational models that are composed of multiple processing layers to learn representations of data with multiple levels of abstraction. These methods have dramatically improved the state-of-the-art in speech recognition, visual object recognition, object detection and many other domains such as drug discovery and genomics. Deep learning discovers intricate structure in large data sets by using the backpropagation algorithm to indicate how a machine should change its internal parameters that are used to compute the representation in each layer from the representation in the previous layer. Deep convolutional nets have brought about breakthroughs in processing images, video, speech and audio, whereas recurrent nets have shone light on sequential data such as text and speech.},
	language = {en},
	number = {7553},
	urldate = {2023-07-06},
	journal = {Nature},
	author = {LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
	month = may,
	year = {2015},
	note = {Number: 7553
Publisher: Nature Publishing Group},
	keywords = {Computer science, Mathematics and computing},
	pages = {436--444},
	file = {Full Text PDF:/Users/zihanchen/Zotero/storage/5SJF5B8H/LeCun et al. - 2015 - Deep learning.pdf:application/pdf},
}


@article{ariza-garzon_explainability_2020,
	title = {Explainability of a {Machine} {Learning} {Granting} {Scoring} {Model} in {Peer}-to-{Peer} {Lending}},
	volume = {8},
	issn = {2169-3536},
	doi = {10.1109/ACCESS.2020.2984412},
	abstract = {Peer-to-peer (P2P) lending demands effective and explainable credit risk models. Typical machine learning algorithms offer high prediction performance, but most of them lack explanatory power. However, this deficiency can be solved with the help of the explainability tools proposed in the last few years, such as the SHAP values. In this work, we assess the well-known logistic regression model and several machine learning algorithms for granting scoring in P2P lending. The comparison reveals that the machine learning alternative is superior in terms of not only classification performance but also explainability. More precisely, the SHAP values reveal that machine learning algorithms can reflect dispersion, nonlinearity and structural breaks in the relationships between each feature and the target variable. Our results demonstrate that is possible to have machine learning credit scoring models be both accurate and transparent. Such models provide the trust that the industry, regulators and end-users demand in P2P lending and may lead to a wider adoption of machine learning in this and other risk assessment applications where explainability is required.},
	journal = {IEEE Access},
	author = {Ariza-Garzón, Miller Janny and Arroyo, Javier and Caparrini, Antonio and Segovia-Vargas, Maria-Jesus},
	year = {2020},
	note = {Conference Name: IEEE Access},
	keywords = {Analytical models, boosting, Credit risk, Decision trees, explainability, logistic regression, Logistics, Machine learning, Machine learning algorithms, Neural networks, P2P lending, Peer-to-peer computing, Shapley values},
	pages = {64873--64890},
	file = {IEEE Xplore Full Text PDF:/Users/zihanchen/Zotero/storage/3NVDNX46/Ariza-Garzón et al. - 2020 - Explainability of a Machine Learning Granting Scor.pdf:application/pdf},
}

@misc{bracke_machine_2019,
	address = {Rochester, NY},
	type = {{SSRN} {Scholarly} {Paper}},
	title = {Machine {Learning} {Explainability} in {Finance}: {An} {Application} to {Default} {Risk} {Analysis}},
	shorttitle = {Machine {Learning} {Explainability} in {Finance}},
	url = {https://papers.ssrn.com/abstract=3435104},
	doi = {10.2139/ssrn.3435104},
	abstract = {We propose a framework for addressing the ‘black box’ problem present in some Machine Learning (ML) applications. We implement our approach by using the Quantitative Input Influence (QII) method of Datta et al (2016) in a real‑world example: a ML model to predict mortgage defaults. This method investigates the inputs and outputs of the model, but not its inner workings. It measures feature influences by intervening on inputs and estimating their Shapley values, representing the features’ average marginal contributions over all possible feature combinations. This method estimates key drivers of mortgage defaults such as the loan‑to‑value ratio and current interest rate, which are in line with the findings of the economics and finance literature. However, given the non‑linearity of ML model, explanations vary significantly for different groups of loans. We use clustering methods to arrive at groups of explanations for different areas of the input space. Finally, we conduct simulations on data that the model has not been trained or tested on. Our main contribution is to develop a systematic analytical framework that could be used for approaching explainability questions in real world financial applications. We conclude though that notable model uncertainties do remain which stakeholders ought to be aware of.},
	language = {en},
	urldate = {2023-07-06},
	author = {Bracke, Philippe and Datta, Anupam and Jung, Carsten and Sen, Shayak},
	month = aug,
	year = {2019},
	keywords = {explainability, machine learning, mortgage defaults},
	file = {Full Text PDF:/Users/zihanchen/Zotero/storage/6ZV6YCFG/Bracke et al. - 2019 - Machine Learning Explainability in Finance An App.pdf:application/pdf},
}

@article{gomber_fintech_2018,
	title = {On the {Fintech} {Revolution}: {Interpreting} the {Forces} of {Innovation}, {Disruption}, and {Transformation} in {Financial} {Services}},
	volume = {35},
	issn = {0742-1222},
	shorttitle = {On the {Fintech} {Revolution}},
	url = {https://doi.org/10.1080/07421222.2018.1440766},
	doi = {10.1080/07421222.2018.1440766},
	abstract = {The financial services industry has been experiencing the recent emergence of new technology innovations and process disruptions. The industry overall, and many fintech start-ups are looking for new pathways to successful business models, the creation of enhanced customer experience, and approaches that result in services transformation. Industry and academic observers believe this to be more of a revolution than a set of less influential changes, with financial services as a whole due for major improvements in efficiency, customer centricity, and informedness. The long-standing dominance of leading firms that are not able to figure out how to effectively hook up with the “Fintech Revolution” is at stake. We present a new fintech innovation mapping approach that enables the assessment of the extent to which there are changes and transformations in four areas of financial services. We discuss: operations management in financial services and the changes occurring; technology innovations that have begun to leverage the execution and stakeholder value associated with payments, cryptocurrencies, blockchain, and cross-border payments; multiple innovations that have affected lending and deposit services, peer-to-peer (P2P) lending, and social media use; issues with respect to investments, financial markets, trading, risk management, robo-advisory and services influenced by blockchain and fintech innovations.},
	number = {1},
	urldate = {2023-07-06},
	journal = {Journal of Management Information Systems},
	author = {Gomber, Peter and Kauffman, Robert J. and Parker, Chris and Weber, Bruce W.},
	month = jan,
	year = {2018},
	note = {Publisher: Routledge
\_eprint: https://doi.org/10.1080/07421222.2018.1440766},
	keywords = {business models, digital banking, financial services, Fintech Revolution, lending, market operations, markets, payments, process transformation, technology disruption, technology innovation},
	pages = {220--265},
}

@article{barredo_arrieta_explainable_2020,
	title = {Explainable {Artificial} {Intelligence} ({XAI}): {Concepts}, taxonomies, opportunities and challenges toward responsible {AI}},
	volume = {58},
	issn = {1566-2535},
	shorttitle = {Explainable {Artificial} {Intelligence} ({XAI})},
	url = {https://www.sciencedirect.com/science/article/pii/S1566253519308103},
	doi = {10.1016/j.inffus.2019.12.012},
	abstract = {In the last few years, Artificial Intelligence (AI) has achieved a notable momentum that, if harnessed appropriately, may deliver the best of expectations over many application sectors across the field. For this to occur shortly in Machine Learning, the entire community stands in front of the barrier of explainability, an inherent problem of the latest techniques brought by sub-symbolism (e.g. ensembles or Deep Neural Networks) that were not present in the last hype of AI (namely, expert systems and rule based models). Paradigms underlying this problem fall within the so-called eXplainable AI (XAI) field, which is widely acknowledged as a crucial feature for the practical deployment of AI models. The overview presented in this article examines the existing literature and contributions already done in the field of XAI, including a prospect toward what is yet to be reached. For this purpose we summarize previous efforts made to define explainability in Machine Learning, establishing a novel definition of explainable Machine Learning that covers such prior conceptual propositions with a major focus on the audience for which the explainability is sought. Departing from this definition, we propose and discuss about a taxonomy of recent contributions related to the explainability of different Machine Learning models, including those aimed at explaining Deep Learning methods for which a second dedicated taxonomy is built and examined in detail. This critical literature analysis serves as the motivating background for a series of challenges faced by XAI, such as the interesting crossroads of data fusion and explainability. Our prospects lead toward the concept of Responsible Artificial Intelligence, namely, a methodology for the large-scale implementation of AI methods in real organizations with fairness, model explainability and accountability at its core. Our ultimate goal is to provide newcomers to the field of XAI with a thorough taxonomy that can serve as reference material in order to stimulate future research advances, but also to encourage experts and professionals from other disciplines to embrace the benefits of AI in their activity sectors, without any prior bias for its lack of interpretability.},
	language = {en},
	urldate = {2023-07-06},
	journal = {Information Fusion},
	author = {Barredo Arrieta, Alejandro and Díaz-Rodríguez, Natalia and Del Ser, Javier and Bennetot, Adrien and Tabik, Siham and Barbado, Alberto and Garcia, Salvador and Gil-Lopez, Sergio and Molina, Daniel and Benjamins, Richard and Chatila, Raja and Herrera, Francisco},
	month = jun,
	year = {2020},
	keywords = {Accountability, Comprehensibility, Data Fusion, Deep Learning, Explainable Artificial Intelligence, Fairness, Interpretability, Machine Learning, Privacy, Responsible Artificial Intelligence, Transparency},
	pages = {82--115},
	file = {Accepted Version:/Users/zihanchen/Zotero/storage/5Q2SVNN7/Barredo Arrieta et al. - 2020 - Explainable Artificial Intelligence (XAI) Concept.pdf:application/pdf},
}

@article{collins_artificial_2021,
	title = {Artificial intelligence in information systems research: {A} systematic literature review and research agenda},
	volume = {60},
	issn = {0268-4012},
	shorttitle = {Artificial intelligence in information systems research},
	url = {https://www.sciencedirect.com/science/article/pii/S0268401221000761},
	doi = {10.1016/j.ijinfomgt.2021.102383},
	abstract = {AI has received increased attention from the information systems (IS) research community in recent years. There is, however, a growing concern that research on AI could experience a lack of cumulative building of knowledge, which has overshadowed IS research previously. This study addresses this concern, by conducting a systematic literature review of AI research in IS between 2005 and 2020. The search strategy resulted in 1877 studies, of which 98 were identified as primary studies and a synthesise of key themes that are pertinent to this study is presented. In doing so, this study makes important contributions, namely (i) an identification of the current reported business value and contributions of AI, (ii) research and practical implications on the use of AI and (iii) opportunities for future AI research in the form of a research agenda.},
	language = {en},
	urldate = {2023-07-06},
	journal = {International Journal of Information Management},
	author = {Collins, Christopher and Dennehy, Denis and Conboy, Kieran and Mikalef, Patrick},
	month = oct,
	year = {2021},
	keywords = {AI, Artificial intelligence, Machine learning, Research agenda, Systematic literature review},
	pages = {102383},
	file = {ScienceDirect Full Text PDF:/Users/zihanchen/Zotero/storage/8KS49FQB/Collins et al. - 2021 - Artificial intelligence in information systems res.pdf:application/pdf},
}

@article{cao_ai_2022,
	title = {{AI} in {Finance}: {Challenges}, {Techniques}, and {Opportunities}},
	volume = {55},
	issn = {0360-0300},
	shorttitle = {{AI} in {Finance}},
	url = {https://dl.acm.org/doi/10.1145/3502289},
	doi = {10.1145/3502289},
	abstract = {AI in finance refers to the applications of AI techniques in financial businesses. This area has attracted attention for decades, with both classic and modern AI techniques applied to increasingly broader areas of finance, economy, and society. In contrast to reviews on discussing the problems, aspects, and opportunities of finance benefited from specific or some new-generation AI and data science (AIDS) techniques or the progress of applying specific techniques to resolving certain financial problems, this review offers a comprehensive and dense landscape of the overwhelming challenges, techniques, and opportunities of AIDS research in finance over the past decades. The challenges of financial businesses and data are first outlined, followed by a comprehensive categorization and a dense overview of the decades of AIDS research in finance. We then structure and illustrate the data-driven analytics and learning of financial businesses and data. A comparison, criticism, and discussion of classic versus modern AIDS techniques for finance follows. Finally, the open issues and opportunities to address future AIDS-empowered finance and finance-motivated AIDS research are discussed.},
	number = {3},
	urldate = {2023-07-06},
	journal = {ACM Computing Surveys},
	author = {Cao, Longbing},
	month = feb,
	year = {2022},
	keywords = {advanced analytics, AI, AI in finance, AI in FinTech, data analytics, data science, economics, finance, FinTech, machine learning, mathematics, modeling, smart FinTech, statistics},
	pages = {64:1--64:38},
	file = {Full Text PDF:/Users/zihanchen/Zotero/storage/KS2Q6N3D/Cao - 2022 - AI in Finance Challenges, Techniques, and Opportu.pdf:application/pdf},
}

@inproceedings{ribeiro_why_2016,
	address = {New York, NY, USA},
	series = {{KDD} '16},
	title = {"{Why} {Should} {I} {Trust} {You}?": {Explaining} the {Predictions} of {Any} {Classifier}},
	isbn = {978-1-4503-4232-2},
	shorttitle = {"{Why} {Should} {I} {Trust} {You}?},
	url = {https://dl.acm.org/doi/10.1145/2939672.2939778},
	doi = {10.1145/2939672.2939778},
	abstract = {Despite widespread adoption, machine learning models remain mostly black boxes. Understanding the reasons behind predictions is, however, quite important in assessing trust, which is fundamental if one plans to take action based on a prediction, or when choosing whether to deploy a new model. Such understanding also provides insights into the model, which can be used to transform an untrustworthy model or prediction into a trustworthy one. In this work, we propose LIME, a novel explanation technique that explains the predictions of any classifier in an interpretable and faithful manner, by learning an interpretable model locally varound the prediction. We also propose a method to explain models by presenting representative individual predictions and their explanations in a non-redundant way, framing the task as a submodular optimization problem. We demonstrate the flexibility of these methods by explaining different models for text (e.g. random forests) and image classification (e.g. neural networks). We show the utility of explanations via novel experiments, both simulated and with human subjects, on various scenarios that require trust: deciding if one should trust a prediction, choosing between models, improving an untrustworthy classifier, and identifying why a classifier should not be trusted.},
	urldate = {2023-07-06},
	booktitle = {Proceedings of the 22nd {ACM} {SIGKDD} {International} {Conference} on {Knowledge} {Discovery} and {Data} {Mining}},
	publisher = {Association for Computing Machinery},
	author = {Ribeiro, Marco Tulio and Singh, Sameer and Guestrin, Carlos},
	month = aug,
	year = {2016},
	keywords = {black box classifier, explaining machine learning, interpretability, interpretable machine learning},
	pages = {1135--1144},
	file = {Full Text PDF:/Users/zihanchen/Zotero/storage/43RXIM24/Ribeiro et al. - 2016 - Why Should I Trust You Explaining the Predicti.pdf:application/pdf},
}

@inproceedings{lundberg_unified_2017,
	title = {A {Unified} {Approach} to {Interpreting} {Model} {Predictions}},
	volume = {30},
	url = {https://proceedings.neurips.cc/paper/2017/hash/8a20a8621978632d76c43dfd28b67767-Abstract.html},
	abstract = {Understanding why a model makes a certain prediction can be as crucial as the prediction's accuracy in many applications. However, the highest accuracy for large modern datasets is often achieved by complex models that even experts struggle to interpret, such as ensemble or deep learning models, creating a tension between accuracy and interpretability. In response, various methods have recently been proposed to help users interpret the predictions of complex models, but it is often unclear how these methods are related and when one method is preferable over another. To address this problem, we present a unified framework for interpreting predictions, SHAP (SHapley Additive exPlanations). SHAP assigns each feature an importance value for a particular prediction. Its novel components include: (1) the identification of a new class of additive feature importance measures, and (2) theoretical results showing there is a unique solution in this class with a set of desirable properties. The new class unifies six existing methods, notable because several recent methods in the class lack the proposed desirable properties. Based on insights from this unification, we present new methods that show improved computational performance and/or better consistency with human intuition than previous approaches.},
	urldate = {2023-07-06},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates, Inc.},
	author = {Lundberg, Scott M and Lee, Su-In},
	year = {2017},
	file = {Full Text PDF:/Users/zihanchen/Zotero/storage/3LEB3BLR/Lundberg and Lee - 2017 - A Unified Approach to Interpreting Model Predictio.pdf:application/pdf},
}

@article{zheng_finbrain_2019,
	title = {{FinBrain}: when finance meets {AI} 2.0},
	volume = {20},
	issn = {2095-9230},
	shorttitle = {{FinBrain}},
	url = {https://doi.org/10.1631/FITEE.1700822},
	doi = {10.1631/FITEE.1700822},
	abstract = {Artificial intelligence (AI) is the core technology of technological revolution and industrial transformation. As one of the new intelligent needs in the AI 2.0 era, financial intelligence has elicited much attention from the academia and industry. In our current dynamic capital market, financial intelligence demonstrates a fast and accurate machine learning capability to handle complex data and has gradually acquired the potential to become a “financial brain.” In this paper, we survey existing studies on financial intelligence. First, we describe the concept of financial intelligence and elaborate on its position in the financial technology field. Second, we introduce the development of financial intelligence and review state-of-the-art techniques in wealth management, risk management, financial security, financial consulting, and blockchain. Finally, we propose a research framework called FinBrain and summarize four open issues, namely, explainable financial agents and causality, perception and prediction under uncertainty, risk-sensitive and robust decision-making, and multi-agent game and mechanism design. We believe that these research directions can lay the foundation for the development of AI 2.0 in the finance field.},
	language = {en},
	number = {7},
	urldate = {2023-07-06},
	journal = {Frontiers of Information Technology \& Electronic Engineering},
	author = {Zheng, Xiao-lin and Zhu, Meng-ying and Li, Qi-bing and Chen, Chao-chao and Tan, Yan-chao},
	month = jul,
	year = {2019},
	keywords = {Artificial intelligence, Financial intelligence, TP391},
	pages = {914--924},
	file = {Full Text PDF:/Users/zihanchen/Zotero/storage/EGJC87EC/Zheng et al. - 2019 - FinBrain when finance meets AI 2.0.pdf:application/pdf},
}

@article{sigrist_grabit_2019,
	title = {Grabit: {Gradient} tree-boosted {Tobit} models for default prediction},
	volume = {102},
	issn = {0378-4266},
	shorttitle = {Grabit},
	url = {https://www.sciencedirect.com/science/article/pii/S0378426619300573},
	doi = {10.1016/j.jbankfin.2019.03.004},
	abstract = {A frequent problem in binary classification is class imbalance between a minority and a majority class such as defaults and non-defaults in default prediction. In this article, we introduce a novel binary classification model, the Grabit model, which is obtained by applying gradient tree boosting to the Tobit model. We show how this model can leverage auxiliary data to obtain increased predictive accuracy for imbalanced data. We apply the Grabit model to predicting defaults on loans made to Swiss small and medium-sized enterprises (SME) and obtain a large and significant improvement in predictive performance compared to other state-of-the-art approaches.},
	language = {en},
	urldate = {2023-07-06},
	journal = {Journal of Banking \& Finance},
	author = {Sigrist, Fabio and Hirnschall, Christoph},
	month = may,
	year = {2019},
	keywords = {Bankruptcy prediction, Censored regression, Class imbalance, Classification, Credit scoring},
	pages = {177--192},
	file = {Submitted Version:/Users/zihanchen/Zotero/storage/N6CA5J84/Sigrist and Hirnschall - 2019 - Grabit Gradient tree-boosted Tobit models for def.pdf:application/pdf},
}

@article{calimani2022simulating,
  title={Simulating fire sales in a system of banks and asset managers},
  author={Calimani, Susanna and Ha{\l}aj, Grzegorz and {\.Z}ochowski, Dawid},
  journal={Journal of Banking \& Finance},
  volume={138},
  pages={105707},
  year={2022},
  publisher={Elsevier}
}

@article{cont2019monitoring,
  title={Monitoring indirect contagion},
  author={Cont, Rama and Schaanning, Eric},
  journal={Journal of Banking \& Finance},
  volume={104},
  pages={85--102},
  year={2019},
  publisher={Elsevier}
}

@article{banerjee2020price,
  title={Price mediated contagion through capital ratio requirements},
  author={Banerjee, Tathagata and Feinstein, Zachary},
  journal={European Journal of Operational Research},
  volume={295},
  pages={1147-1160},
  year={2021},
  publisher={North-Holland}
}

@article{amicaosu2021fire,
	author = {Amini, Hamed and Cao, Zhongyuan and Sulem, Agnes},
	journal = {Available at SSRN 3935450},
	title = {Fire Sales, Default Cascades and Complex Financial Networks},
	year = {2021}}