\section{EMA approximation theorems with SDEs}
\label{app:ema-approximation-theorem}
\subsection{SGD with model EMA}

We will now derive the EMA scaling rule when tracking model parameters and the model is trained using SGD. We employ a strategy similar to \citet{DBLP:conf/nips/MalladiLPA22}, where we associate to each iterative process a Stochastic Differential Equation (SDE). In order to control the distance between the SDE and the discrete process, we use the tools from \citet{li2019stochastic}.
\begin{definition}[Polynomial growth, Definition 1 in \citep{li2019stochastic}]
\label{def:polynomial-growth}
The set $G$ is the set of continuous functions $\sR^d\to\sR$ with at most polynomial growth, i.e., for $g\in G$ there exists two scalars $\kappa_1, \kappa_2>0$ such that for all $\vx\in\sR^d$, we have $|g(\vx)|\leq \kappa_1(1+\|\vx\|^{\kappa_2})$.

For an integer $\alpha >0$, $G^\alpha$ is the set of functions $\sR^d\to \sR$ that are $\alpha$-times continuously differentiable and such that all their derivatives up to order $\alpha$ are in $G$.
\end{definition}



Similarly to \citet{DBLP:conf/nips/MalladiLPA22}, we use Noisy Gradient Oracle with Scale Parameter (NGOS) to define the update rules on the parameters.
\begin{definition}[Noisy Gradient Oracle with Scale Parameter (NGOS), adaptation of \citep{DBLP:conf/nips/MalladiLPA22}]
\label{def:ngos}
A NGOS is a tuple $\mathcal{G}_\sigma = (f, \mSigma, \mathcal{Z}_\sigma)$. Given a noise scale parameter $\sigma >0$, the NGOS $\mathcal{G}_\sigma$ takes as input the parameters $\vtheta$ and outputs a random vector $\rvg= \nabla f(\vtheta, \vzeta) + \sigma \rvepsilon$ where $\nabla f(\vtheta, \vzeta)$ is the gradient of $f$ with respect to $\vtheta$ at $\inParentheses{\vtheta, \vzeta}$, and $\rvepsilon$ is a random vector drawn from the distribution $\mathcal{Z}_\sigma(\vtheta, \vzeta)$ with zero mean and covariance $\mSigma(\vtheta, \vzeta)$.
\end{definition}

Note that in the above definition, the probability distribution $\mathcal{Z}_\sigma(\vtheta, \vzeta)$ is allowed to change with the scale $\sigma$, but its first two moments --- its mean and its covariance --- are fixed with $\sigma$. We have the following theorem for model EMA under optimization with SGD:
\begin{theorem}[SDE for SGD + EMA]
    \label{thm:app:sde}
Consider the couple $\rvx_k = (\rvtheta_k, \rvzeta_k)$ where $\rvtheta_k$ are the iterates of SGD with a NGOS (\Cref{def:ngos}) and $\rvzeta_k$ is an EMA of $\rvtheta_k$, defined, starting from $\rvx_0 = \vx_0$, by
\begin{align}
    \rvtheta_{k+1} &= \rvtheta_{k} - \eta \rvg_k, \enspace \text{with } \rvg_k=\nabla f(\rvtheta_k, \rvzeta_k) + \sigma \rvepsilon_k , \text{ and }\rvepsilon_k \sim \mathcal{Z}_\sigma(\rvtheta_k, \rvzeta_k),\\
    \rvzeta_{k+1} &= \rho \rvzeta_k + (1-\rho) \rvtheta_k\enspace.
\end{align}
Define $\beta_0 = (1-\rho) / \eta$, $\sigma_0 = \sigma\sqrt{\eta}$, and define the SDE for $X_t = (\Theta_t, Z_t)$, starting from $X_0 = \vx_0$, by
\begin{align}
\label{eq:app:sde-sgd}
    d\Theta_t &= - \nabla f(\Theta_t, Z_t)dt + \sigma_0\mSigma(\Theta_t, Z_t)^{\frac12}dW_t,\enspace\text{with}\enspace W_t \text{ a Wiener process}\\
    \label{eq:app:sde-ema}
    dZ_t &= \beta_0(\Theta_t - Z_t)dt\enspace.
\end{align}
Assume that $f$ is continuously differentiable, with $f\in G^3$ and $\mSigma^{\frac12}\in G^2$ (\Cref{def:polynomial-growth}). Then, for any time horizon $T >0$ and test function $g\in G^2$ , there exists a constant $c>0$ such that 
\begin{equation}
    \max_{k=0,\dots, \lfloor T /\eta \rfloor} |\mathbb{E}[g(X_{\eta k})] - \mathbb{E}[g(\rvx_k)]| \leq c\times  \eta \enspace.
\end{equation}
\end{theorem}
\begin{proof}
The proof uses the same tools as in \citet{li2019stochastic}. Define $\Delta(\vtheta, \vzeta) = \eta (-\nabla f(\vtheta, \vzeta) + \sigma \rvepsilon, \beta_0(\vtheta- \vzeta))$ with $\rvepsilon\sim \mathcal{Z}_{\sigma}(\vtheta, \vzeta)$ the one-step update for the SGD + EMA update, such that $\rvx_{k+1} = \rvx_k +\Delta(\rvx_k)$. We have the first two moments:
\begin{align}
    \mathbb{E}[\Delta(\vtheta, \vzeta)] &= \eta (-\nabla f(\vtheta, \vzeta), \beta_0(\vtheta- \vzeta))\\
    \mathbb{V}[\Delta(\vtheta, \vzeta)] &= \eta \sigma_0^2\begin{bmatrix}\mSigma(\vtheta, \vzeta) & 0 \\ 0 & 0 \end{bmatrix}
\end{align}
and the higher-order moments are $O(\eta^2)$.
Similarly, let $\tilde{\Delta}(\vtheta, \vzeta)$ be the solution at time $\eta$ of the SDE defined by \Cref{eq:sde-sgd} starting from $X_0=(\vtheta, \vzeta)$. From Ito's formula, we also obtain
\begin{align}
    \mathbb{E}[\tilde{\Delta}(\vtheta, \vzeta)] &= \eta (-\nabla f(\vtheta), \beta_0(\vtheta- \vzeta))\\
    \mathbb{V}[\tilde{\Delta}(\vtheta, \vzeta)] &= \eta \sigma_0^2\begin{bmatrix}\mSigma(\vtheta, \vzeta) & 0 \\ 0 & 0 \end{bmatrix}
\end{align}
and the higher-order moments are $O(\eta^2)$.
Hence, the moments of the discrete iteration and of the SDE match up to second order. 
Following the same proof technique as in~\citet{li2019stochastic} then leads to the advertized theorem.
\end{proof}
This theorem is a simple adaptation of the results of~\cite{li2019stochastic}. Intuitively, it is expected that $X_t$ and $\rvx_k$ are close since $\rvx_k$ is the Euler-Maruyama discretization of $X_t$ with learning rate $\eta$. 
We then have the corollary.
\begin{corollary}[Validity of the \gls{ema} Scaling Rule]
    Assume that $f$ is continuously differentiable, with $f\in G^3$ and $\mSigma^{\frac12}\in G^2$. 
    Let $\rvtheta_k^{B}, \rvzeta_k^{B}$ the iterates of the \Cref{eq:iterations} with batch size $B$ and hyperparameters $\eta, \rho$. 
    Let $\rvtheta_k^{\kappa B}, \rvzeta_k^{\kappa B}$ be iterates with batch size $\kappa B$, learning rate $\eta$ determined by the \gls{sgd} Scaling Rule (\Cref{def:lsr}) and momentum determined by the \gls{ema} Scaling Rule, linear version (\Cref{def:ema-sr}). 
    Then, for any time horizon $T >0$ and function $g\in G^2$, there exists a constant $d>0$ such that 
   \begin{equation}
       \max_{k=0,\dots, \lfloor T /\eta \rfloor} |\mathbb{E}[g(\rvtheta_{\lfloor k / \kappa \rfloor}^{\kappa B}, \rvzeta_{\lfloor k / \kappa \rfloor}^{\kappa B})] - \mathbb{E}[g(\rvtheta_k, \rvzeta_k)]| \leq d\times  \eta \enspace.
   \end{equation}
\end{corollary}
\begin{proof}
    The proof is similar to~\citet{DBLP:conf/nips/MalladiLPA22}. Under the scaling rule, both $\rvx_k = (\rvtheta_k, \rvzeta_k)$ and $\hat{\rvx}_{\lfloor k / \kappa \rfloor}= (\rvtheta_{\lfloor k / \kappa \rfloor}^{\kappa B}, \rvzeta_{\lfloor k / \kappa \rfloor}^{\kappa B})$ have the same limiting SDE. Hence we have from the previous theorem that for all test function $g$, we can find $c, c'$ such that  
    \begin{equation}
        \max_{k=0,\dots, \lfloor T /\eta \rfloor} |\mathbb{E}[g(X_{\eta k})] - \mathbb{E}[g(\rvx_k)]| \leq c\times  \eta \text{ and }\max_{k=0,\dots, \lfloor T /\eta \rfloor} |\mathbb{E}[g(X_{\eta k})] - \mathbb{E}[g(\hat{\rvx}_{\lfloor k / \kappa \rfloor})]| \leq c'\times  \eta.
    \end{equation}
    The triangle inequality then gives
    \begin{equation}
        \max_{k=0,\dots, \lfloor T /\eta \rfloor} |\mathbb{E}[g(\hat{\rvx}_{\lfloor k / \kappa \rfloor})]- \mathbb{E}[g(\rvx_k)]|\leq (c + c') \times \eta.
    \end{equation}
    Hence, taking $d = c+ c'$ gives the expected result.
\end{proof}


\subsection{Adaptive gradient methods with model EMA}

We now turn to the case where one uses an adaptive gradient method rather than SGD to train the model.
We follow derivations similar to those of \citet{DBLP:conf/nips/MalladiLPA22}, with an added EMA. 
Like above, we consider that the loss function $f$ also depends on the EMA tracking parameter $\rvzeta_k$.
We begin with RMSProp with EMA, which iterates:
\begin{align}
    \rvv_{k+1} &= \gamma \rvv_k + (1 - \gamma) \rvg_k^2, \enspace \text{with } \rvg_k=\nabla f(\rvtheta_k, \rvzeta_k) + \sigma \rvepsilon_k , \text{ and }\rvepsilon_k \sim \mathcal{Z}_\sigma(\rvtheta_k, \rvzeta_k),\label{app:eq:rmsprop_v}\\
    \rvtheta_{k+1} &= \rvtheta_k - \eta (\sqrt{\rvv_k} + \varepsilon)^{-1} \times \rvg_k\\
    \rvzeta_{k+1} &= \rho \rvzeta_k + (1- \rho) \rvtheta_k.
\end{align}

Like in \citet{DBLP:conf/nips/MalladiLPA22}, we place ourselves in the high noise regime, in which the term $\rvg_k^2$ in \Cref{app:eq:rmsprop_v} is approximated by $\rvg_k^2\simeq \sigma^2\mathrm{diag}(\Sigma(\rvtheta_k, \rvzeta_k))$. We use the same scaling rules, with an additional one for $\rho$:
\begin{equation}
    \label{app:eq:scaling_rmsprop}
    \gamma_0 = (1 - \gamma) / \eta^2,\enspace \sigma_0 = \sigma\eta, \enspace \varepsilon_0 = \varepsilon \eta, \text{ and } \beta_0 = (1-\rho) / \eta^2,
\end{equation}
and we let $\rvu_k = \rvv_k / \sigma^2$. The equations for RMSProp with EMA then become, using only these new variables and $\eta$:
\begin{align}
    \rvu_{k+1} - \rvu_k &= \eta^2 \gamma_0 (\mathrm{diag}(\Sigma(\rvtheta_k, \rvzeta_k)) - \ru_k), \\
    \rvtheta_{k+1} - \rvtheta_k &= - (\sqrt{\rvu_k} + \varepsilon_0)^{-1}\left(\eta^2  \nabla f(\rvtheta_k, \rvzeta_k) + \eta \rvepsilon_k \right)\\
    \rvzeta_{k+1} -\rvzeta_k &= \eta^2\beta_0 (\rvtheta_k - \rvzeta_k).
\end{align}
This formulation makes it clear that these iterations can be seen as the discretization of the SDE
\begin{align}
    dU_t &=  \gamma_0 (\mathrm{diag}(\Sigma(\Theta_t, Z_t)) - U_t)dt, \\
    d\Theta_t &= - (\sigma_0\sqrt{U_t} + \varepsilon_0)^{-1} (\nabla f(\Theta_t, Z_t) dt + \sigma_0 \Sigma(\Theta_t, Z_t)^{1/2}dWt) \\
    dZ_t &= \beta_0 (\Theta_t - Z_t)dt,
\end{align}
with step size $\eta^2$.
Of course, we recover the SDE of \citet{DBLP:conf/nips/MalladiLPA22} in the case where $\beta_0 = 0$.
A formal proof of closeness between the iterates and the SDE trajectory is out of the scope of the present paper since it would imply redoing much of the theoretical work developed in \citet{DBLP:conf/nips/MalladiLPA22}.
Still, the previous informal analysis hints that for RMSProp, the scaling rule in \Cref{app:eq:scaling_rmsprop} should be used.
In other words, given a certain set of hyperparameters $\gamma, \eta$ and $\rho$, if the batch size goes from $B$ to $\hat{B} = \kappa \times B$, the noise level becomes $\hat{\sigma} = \sigma / \sqrt{\kappa}$, and keeping the quantities in \Cref{app:eq:scaling_rmsprop} constant means that we should use as new hyperparameters
$$
\hat{\gamma} = 1 - (1-\gamma) \times \kappa,\enspace \hat{\eta} = \eta \times \sqrt{\kappa}, \text{ and } \hat{\rho} = 1 - (1 - \rho)\times \kappa\enspace.
$$
The linear rule $ \hat{\rho} = 1 - (1 - \rho)\times \kappa$ is at the first order equivalent to the exponential scaling rule $\hat{\rho} = \rho^{\kappa}$.
Hence, even though the limiting SDE differs greatly from that of SGD, and even though the scaling rule regarding the learning rate differs, we recover for the momentum term $\rho$ the exact same scaling rule as for SGD.

We finish the discussion with the case of Adam, which leads once again to the same rule as for SGD.
Adam with EMA tracking of the network parameters iterates
\begin{align}
    \rvm_{k+1} &=\beta_1\rvm_k + (1 - \beta_1) \rvg_k, \enspace \text{with } \rvg_k=\nabla f(\rvtheta_k, \rvzeta_k) + \sigma \rvepsilon_k , \text{ and }\rvepsilon_k \sim \mathcal{Z}_\sigma(\rvtheta_k, \rvzeta_k),\\
    \rvv_{k+1} &= \beta_2 \rvv_k + (1 - \beta_2) \rvg_k^2 \\
    \tilde{\rvm}_{k+1} &= \rvm_{k+1} / (1 - \beta_1^{k+1})\\ 
    \tilde{\rvv}_{k+1} &= \rvv_{k+1} / (1 - \beta_2^{k+1})\\ 
    \rvtheta_{k+1} &= \rvtheta_k - \eta (\sqrt{\tilde{\rvv}_{k}} + \varepsilon)^{-1} \times \tilde{\rvm}_{k+1}\\
    \rvzeta_{k+1} &= \rho \rvzeta_k + (1- \rho) \rvtheta_k\enspace.
\end{align}
 Here, we use the same minor modification of the iterations as in \citet{DBLP:conf/nips/MalladiLPA22}, where we use $\rvv_k$ instead of $\rvv_{k+1}$ in the denominator of the $\rvtheta_k$ update.

We consider the following scaling for the hyperparameters
\begin{equation}
    \label{app:eq:scaling_adam}
    c_1 = (1 - \beta_1)/ \eta^2,\enspace c_2 = (1- \beta_2) / \eta^2,\enspace \sigma_0 = \sigma\eta, \enspace \varepsilon_0 = \varepsilon \eta, \text{ and } \beta_0 = (1 - \rho) / \eta^2,
\end{equation}
and $\gamma_1(t) = 1 - \exp(-c_1t)$, $\gamma_2(t) = 1 - \exp(-c_2t)$, and $\rvu_k = \rvv_k / \sigma^2 $. The SDE for Adam + EMA is given by
\begin{align}
    dM_t &=c_1\left((\nabla f(\Theta_t, Z_t) - M_t)dt + \sigma_0\Sigma(\Theta_t, Z_t)^{1/2}dW_t\right)\\
    dU_t &=c_2(\mathrm{diag}(\Sigma(\Theta_t, Z_t)) - U_t)dt\\
    d\Theta_t &= -  \frac{\sqrt{\gamma_2(t)}}{\gamma_1(t)}(\sigma_0\sqrt{U_t} + \varepsilon_0\sqrt{\gamma_2(t)})^{-1} \times M_t dt\\
    dZ_t &= \beta_0(\Theta_t - Z_t)dt.
\end{align}

This is once again the same SDE as in \citet{DBLP:conf/nips/MalladiLPA22} with the added EMA term. Like previously, this SDE hints at the fact that the scaling rule in \cref{app:eq:scaling_adam} should be used. In other words, given a set of hyperparameters $\beta_1,\beta_2, \eta$, and $\rho$, if the batch size goes from $B$ to $\kappa \times B$, then the noise level becomes $\hat{\sigma} = \sigma/ \sqrt{\kappa}$ and keeping quantities in \cref{app:eq:scaling_adam} constant means that we should use as new hyperparameters
$$
\hat{\beta}_1 = 1 - (1 - \beta_1)\times \kappa,\enspace 
\hat{\beta}_2 = 1 - (1 - \beta_2)\times \kappa,\enspace 
\hat{\eta} = \eta \times \sqrt{\kappa},\text{ and } \hat{\rho} = 1 - (1-\rho)\times \kappa.
$$
We once again recover a linear rule for $1 - \rho$ which is equivalent to the exponential scaling rule $\hat{\rho} = \rho^\kappa$ in the limit $\rho\to 0$.

