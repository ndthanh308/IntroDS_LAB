\begin{thebibliography}{33}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Aghajanyan et~al.()Aghajanyan, Huang, Ross, Karpukhin, Xu, Goyal,
  Okhonko, Joshi, Ghosh, Lewis, and Zettlemoyer]{aghajanyan_cm3_2022}
Armen Aghajanyan, Bernie Huang, Candace Ross, Vladimir Karpukhin, Hu~Xu, Naman
  Goyal, Dmytro Okhonko, Mandar Joshi, Gargi Ghosh, Mike Lewis, and Luke
  Zettlemoyer.
\newblock {CM}3: A causal masked multimodal model of the internet.

\bibitem[Alayrac et~al.()Alayrac, Donahue, Luc, Miech, Barr, Hasson, Lenc,
  Mensch, Millican, Reynolds, Ring, Rutherford, Cabi, Han, Gong, Samangooei,
  Monteiro, Menick, Borgeaud, Brock, Nematzadeh, Sharifzadeh, Binkowski,
  Barreira, Vinyals, Zisserman, and Simonyan]{alayrac_flamingo_2022}
Jean-Baptiste Alayrac, Jeff Donahue, Pauline Luc, Antoine Miech, Iain Barr,
  Yana Hasson, Karel Lenc, Arthur Mensch, Katherine Millican, Malcolm Reynolds,
  Roman Ring, Eliza Rutherford, Serkan Cabi, Tengda Han, Zhitao Gong, Sina
  Samangooei, Marianne Monteiro, Jacob Menick, Sebastian Borgeaud, Andrew
  Brock, Aida Nematzadeh, Sahand Sharifzadeh, Mikolaj Binkowski, Ricardo
  Barreira, Oriol Vinyals, Andrew Zisserman, and Karen Simonyan.
\newblock Flamingo: a visual language model for few-shot learning.
\newblock In \emph{Advances in Neural Information Processing Systems}.

\bibitem[Alayrac et~al.(2022)Alayrac, Donahue, Luc, Miech, Barr, Hasson, Lenc,
  Mensch, Millican, Reynolds, et~al.]{alayrac2022flamingo}
Jean-Baptiste Alayrac, Jeff Donahue, Pauline Luc, Antoine Miech, Iain Barr,
  Yana Hasson, Karel Lenc, Arthur Mensch, Katherine Millican, Malcolm Reynolds,
  et~al.
\newblock Flamingo: a visual language model for few-shot learning.
\newblock \emph{Advances in Neural Information Processing Systems},
  35:\penalty0 23716--23736, 2022.

\bibitem[Awadalla et~al.(2023)Awadalla, Gao, Gardner, Hessel, Hanafy, Zhu,
  Marathe, Bitton, Gadre, Jitsev, Kornblith, Koh, Ilharco, Wortsman, and
  Schmidt]{awadalla2023}
Anas Awadalla, Irena Gao, Joshua Gardner, Jack Hessel, Yusuf Hanafy, Wanrong
  Zhu, Kalyani Marathe, Yonatan Bitton, Samir Gadre, Jenia Jitsev, Simon
  Kornblith, Pang~Wei Koh, Gabriel Ilharco, Mitchell Wortsman, and Ludwig
  Schmidt.
\newblock Openflamingo, March 2023.

\bibitem[Bolton et~al.()Bolton, Hall, Yasunaga, Lee, Manning, and
  Liang]{biomedlm}
Elliot Bolton, David Hall, Michihiro Yasunaga, Tony Lee, Chris Manning, and
  Percy Liang.
\newblock {BioMedLM}: a domain-specific large language model for biomedical
  text.

\bibitem[Bommasani et~al.(2021)Bommasani, Hudson, Adeli, Altman, Arora, von
  Arx, Bernstein, Bohg, Bosselut, Brunskill,
  et~al.]{bommasani2021opportunities}
Rishi Bommasani, Drew~A Hudson, Ehsan Adeli, Russ Altman, Simran Arora, Sydney
  von Arx, Michael~S Bernstein, Jeannette Bohg, Antoine Bosselut, Emma
  Brunskill, et~al.
\newblock On the opportunities and risks of foundation models.
\newblock \emph{arXiv preprint arXiv:2108.07258}, 2021.

\bibitem[Brown et~al.()Brown, Mann, Ryder, Subbiah, Kaplan, Dhariwal,
  Neelakantan, Shyam, Sastry, Askell, Agarwal, Herbert-Voss, Krueger, Henighan,
  Child, Ramesh, Ziegler, Wu, Winter, Hesse, Chen, Sigler, Litwin, Gray, Chess,
  Clark, Berner, {McCandlish}, Radford, Sutskever, and
  Amodei]{brown_language_2020}
Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared~D Kaplan, Prafulla
  Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell,
  Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon
  Child, Aditya Ramesh, Daniel Ziegler, Jeffrey Wu, Clemens Winter, Chris
  Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess,
  Jack Clark, Christopher Berner, Sam {McCandlish}, Alec Radford, Ilya
  Sutskever, and Dario Amodei.
\newblock Language models are few-shot learners.
\newblock In \emph{Advances in Neural Information Processing Systems},
  volume~33, pp.\  1877--1901.

\bibitem[Brown et~al.(2020)Brown, Mann, Ryder, Subbiah, Kaplan, Dhariwal,
  Neelakantan, Shyam, Sastry, Askell, Agarwal, Herbert{-}Voss, Krueger,
  Henighan, Child, Ramesh, Ziegler, Wu, Winter, Hesse, Chen, Sigler, Litwin,
  Gray, Chess, Clark, Berner, McCandlish, Radford, Sutskever, and
  Amodei]{brown2020}
Tom~B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan,
  Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda
  Askell, Sandhini Agarwal, Ariel Herbert{-}Voss, Gretchen Krueger, Tom
  Henighan, Rewon Child, Aditya Ramesh, Daniel~M. Ziegler, Jeffrey Wu, Clemens
  Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott
  Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec
  Radford, Ilya Sutskever, and Dario Amodei.
\newblock Language models are few-shot learners.
\newblock In Hugo Larochelle, Marc'Aurelio Ranzato, Raia Hadsell,
  Maria{-}Florina Balcan, and Hsuan{-}Tien Lin (eds.), \emph{Advances in Neural
  Information Processing Systems 33: Annual Conference on Neural Information
  Processing Systems 2020, NeurIPS 2020, December 6-12, 2020, virtual}, 2020.

\bibitem[Dosovitskiy et~al.(2021)Dosovitskiy, Beyer, Kolesnikov, Weissenborn,
  Zhai, Unterthiner, Dehghani, Minderer, Heigold, Gelly, Uszkoreit, and
  Houlsby]{dosovitskiy2020vit}
Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn,
  Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg
  Heigold, Sylvain Gelly, Jakob Uszkoreit, and Neil Houlsby.
\newblock An image is worth 16x16 words: Transformers for image recognition at
  scale.
\newblock \emph{ICLR}, 2021.

\bibitem[Gu et~al.(2021)Gu, Tinn, Cheng, Lucas, Usuyama, Liu, Naumann, Gao, and
  Poon]{gu2021domain}
Yu~Gu, Robert Tinn, Hao Cheng, Michael Lucas, Naoto Usuyama, Xiaodong Liu,
  Tristan Naumann, Jianfeng Gao, and Hoifung Poon.
\newblock Domain-specific language model pretraining for biomedical natural
  language processing.
\newblock \emph{ACM Transactions on Computing for Healthcare (HEALTH)},
  3\penalty0 (1):\penalty0 1--23, 2021.

\bibitem[Huang et~al.(2019)Huang, Altosaar, and
  Ranganath]{huang2019clinicalbert}
Kexin Huang, Jaan Altosaar, and Rajesh Ranganath.
\newblock Clinicalbert: Modeling clinical notes and predicting hospital
  readmission.
\newblock \emph{arXiv preprint arXiv:1904.05342}, 2019.

\bibitem[Johnson et~al.(2019)Johnson, Douze, and J{\'e}gou]{johnson2019billion}
Jeff Johnson, Matthijs Douze, and Herv{\'e} J{\'e}gou.
\newblock Billion-scale similarity search with {GPUs}.
\newblock \emph{IEEE Transactions on Big Data}, 7\penalty0 (3):\penalty0
  535--547, 2019.

\bibitem[Kiyasseh et~al.(2023)Kiyasseh, Ma, Haque, Miles, Wagner, Donoho,
  Anandkumar, and Hung]{kiyasseh2023vision}
Dani Kiyasseh, Runzhuo Ma, Taseen~F Haque, Brian~J Miles, Christian Wagner,
  Daniel~A Donoho, Animashree Anandkumar, and Andrew~J Hung.
\newblock A vision transformer for decoding surgeon activity from surgical
  videos.
\newblock \emph{Nature Biomedical Engineering}, pp.\  1--17, 2023.

\bibitem[Lee et~al.(2020)Lee, Yoon, Kim, Kim, Kim, So, and
  Kang]{lee2020biobert}
Jinhyuk Lee, Wonjin Yoon, Sungdong Kim, Donghyeon Kim, Sunkyu Kim, Chan~Ho So,
  and Jaewoo Kang.
\newblock Biobert: a pre-trained biomedical language representation model for
  biomedical text mining.
\newblock \emph{Bioinformatics}, 36\penalty0 (4):\penalty0 1234--1240, 2020.

\bibitem[Li et~al.(2023)Li, Wong, Zhang, Usuyama, Liu, Yang, Naumann, Poon, and
  Gao]{li2023llava}
Chunyuan Li, Cliff Wong, Sheng Zhang, Naoto Usuyama, Haotian Liu, Jianwei Yang,
  Tristan Naumann, Hoifung Poon, and Jianfeng Gao.
\newblock Llava-med: Training a large language-and-vision assistant for
  biomedicine in one day.
\newblock \emph{arXiv preprint arXiv:2306.00890}, 2023.

\bibitem[Liang et~al.(2022)Liang, Bommasani, Lee, Tsipras, Soylu, Yasunaga,
  Zhang, Narayanan, Wu, Kumar, et~al.]{liang2022holistic}
Percy Liang, Rishi Bommasani, Tony Lee, Dimitris Tsipras, Dilara Soylu,
  Michihiro Yasunaga, Yian Zhang, Deepak Narayanan, Yuhuai Wu, Ananya Kumar,
  et~al.
\newblock Holistic evaluation of language models.
\newblock \emph{arXiv preprint arXiv:2211.09110}, 2022.

\bibitem[Lin et~al.(2023)Lin, Zhao, Zhang, Wu, Zhang, Wang, and Xie]{pmcclip}
Weixiong Lin, Ziheng Zhao, Xiaoman Zhang, Chaoyi Wu, Ya~Zhang, Yanfeng Wang,
  and Weidi Xie.
\newblock Pmc-clip: Contrastive language-image pre-training using biomedical
  documents.
\newblock \emph{arXiv preprint arXiv:2303.07240}, 2023.

\bibitem[Luo et~al.(2022)Luo, Sun, Xia, Qin, Zhang, Poon, and
  Liu]{luo2022biogpt}
Renqian Luo, Liai Sun, Yingce Xia, Tao Qin, Sheng Zhang, Hoifung Poon, and
  Tie-Yan Liu.
\newblock Biogpt: generative pre-trained transformer for biomedical text
  generation and mining.
\newblock \emph{Briefings in Bioinformatics}, 23\penalty0 (6):\penalty0
  bbac409, 2022.

\bibitem[Moor et~al.(2023)Moor, Banerjee, Abad, Krumholz, Leskovec, Topol, and
  Rajpurkar]{moor2023foundation}
Michael Moor, Oishi Banerjee, Zahra Shakeri~Hossein Abad, Harlan~M Krumholz,
  Jure Leskovec, Eric~J Topol, and Pranav Rajpurkar.
\newblock Foundation models for generalist medical artificial intelligence.
\newblock \emph{Nature}, 616\penalty0 (7956):\penalty0 259--265, 2023.

\bibitem[Qin et~al.(2023)Qin, Zhang, Zhang, Chen, Yasunaga, and
  Yang]{qin2023chatgpt}
Chengwei Qin, Aston Zhang, Zhuosheng Zhang, Jiaao Chen, Michihiro Yasunaga, and
  Diyi Yang.
\newblock Is chatgpt a general-purpose natural language processing task solver?
\newblock \emph{arXiv preprint arXiv:2302.06476}, 2023.

\bibitem[Radford et~al.()Radford, Kim, Hallacy, Ramesh, Goh, Agarwal, Sastry,
  Askell, Mishkin, Clark, Krueger, and Sutskever]{radford_learning_2021}
Alec Radford, Jong~Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh,
  Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark,
  Gretchen Krueger, and Ilya Sutskever.
\newblock Learning transferable visual models from natural language
  supervision.
\newblock In \emph{Proceedings of the 38th International Conference on Machine
  Learning}, pp.\  8748--8763.
\newblock {ISSN}: 2640-3498.

\bibitem[Ramesh et~al.()Ramesh, Pavlov, Goh, Gray, Voss, Radford, Chen, and
  Sutskever]{ramesh_zero-shot_2021}
Aditya Ramesh, Mikhail Pavlov, Gabriel Goh, Scott Gray, Chelsea Voss, Alec
  Radford, Mark Chen, and Ilya Sutskever.
\newblock Zero-shot text-to-image generation.
\newblock In \emph{Proceedings of the 38th International Conference on Machine
  Learning}, pp.\  8821--8831.
\newblock {ISSN}: 2640-3498.

\bibitem[Singhal et~al.()Singhal, Azizi, Tu, Mahdavi, Wei, Chung, Scales,
  Tanwani, Cole-Lewis, Pfohl, Payne, Seneviratne, Gamble, Kelly, Scharli,
  Chowdhery, Mansfield, Arcas, Webster, Corrado, Matias, Chou, Gottweis,
  Tomasev, Liu, Rajkomar, Barral, Semturs, Karthikesalingam, and
  Natarajan]{singhal_large_2022}
Karan Singhal, Shekoofeh Azizi, Tao Tu, S.~Sara Mahdavi, Jason Wei, Hyung~Won
  Chung, Nathan Scales, Ajay Tanwani, Heather Cole-Lewis, Stephen Pfohl, Perry
  Payne, Martin Seneviratne, Paul Gamble, Chris Kelly, Nathaneal Scharli,
  Aakanksha Chowdhery, Philip Mansfield, Blaise Aguera~y Arcas, Dale Webster,
  Greg~S. Corrado, Yossi Matias, Katherine Chou, Juraj Gottweis, Nenad Tomasev,
  Yun Liu, Alvin Rajkomar, Joelle Barral, Christopher Semturs, Alan
  Karthikesalingam, and Vivek Natarajan.
\newblock Large language models encode clinical knowledge.

\bibitem[Steinberg et~al.(2021)Steinberg, Jung, Fries, Corbin, Pfohl, and
  Shah]{steinberg2021language}
Ethan Steinberg, Ken Jung, Jason~A Fries, Conor~K Corbin, Stephen~R Pfohl, and
  Nigam~H Shah.
\newblock Language models are an effective representation learning technique
  for electronic health record data.
\newblock \emph{Journal of biomedical informatics}, 113:\penalty0 103637, 2021.

\bibitem[Su et~al.(2019)Su, Zhu, Cao, Li, Lu, Wei, and Dai]{su2019vl}
Weijie Su, Xizhou Zhu, Yue Cao, Bin Li, Lewei Lu, Furu Wei, and Jifeng Dai.
\newblock Vl-bert: Pre-training of generic visual-linguistic representations.
\newblock \emph{arXiv preprint arXiv:1908.08530}, 2019.

\bibitem[Tiu et~al.(2022)Tiu, Talius, Patel, Langlotz, Ng, and
  Rajpurkar]{tiu_expert-level_2022}
Ekin Tiu, Ellie Talius, Pujan Patel, Curtis~P Langlotz, Andrew~Y Ng, and Pranav
  Rajpurkar.
\newblock Expert-level detection of pathologies from unannotated chest x-ray
  images via self-supervised learning.
\newblock \emph{Nature Biomedical Engineering}, 6\penalty0 (12):\penalty0
  1399--1406, 2022.

\bibitem[Touvron et~al.(2023)Touvron, Lavril, Izacard, Martinet, Lachaux,
  Lacroix, Rozi{\`e}re, Goyal, Hambro, Azhar, et~al.]{touvron2023llama}
Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne
  Lachaux, Timoth{\'e}e Lacroix, Baptiste Rozi{\`e}re, Naman Goyal, Eric
  Hambro, Faisal Azhar, et~al.
\newblock Llama: Open and efficient foundation language models.
\newblock \emph{arXiv preprint arXiv:2302.13971}, 2023.

\bibitem[Yasunaga et~al.({\natexlab{a}})Yasunaga, Bosselut, Ren, Zhang,
  Manning, Liang, and Leskovec]{yasunaga_deep_2022}
Michihiro Yasunaga, Antoine Bosselut, Hongyu Ren, Xikun Zhang, Christopher~D.
  Manning, Percy Liang, and Jure Leskovec.
\newblock Deep bidirectional language-knowledge graph pretraining.
\newblock In \emph{Advances in Neural Information Processing Systems},
  {\natexlab{a}}.

\bibitem[Yasunaga et~al.({\natexlab{b}})Yasunaga, Leskovec, and
  Liang]{yasunaga_linkbert_2022}
Michihiro Yasunaga, Jure Leskovec, and Percy Liang.
\newblock {LinkBERT}: Pretraining language models with document links.
\newblock In \emph{Proceedings of the 60th Annual Meeting of the Association
  for Computational Linguistics (Volume 1: Long Papers)}, pp.\  8003--8016.
  Association for Computational Linguistics, {\natexlab{b}}.
\newblock \doi{10.18653/v1/2022.acl-long.551}.

\bibitem[Yasunaga et~al.(2023)Yasunaga, Aghajanyan, Shi, James, Leskovec,
  Liang, Lewis, Zettlemoyer, and Yih]{yasunaga2022retrieval}
Michihiro Yasunaga, Armen Aghajanyan, Weijia Shi, Rich James, Jure Leskovec,
  Percy Liang, Mike Lewis, Luke Zettlemoyer, and Wen-tau Yih.
\newblock Retrieval-augmented multimodal language modeling.
\newblock 2023.

\bibitem[Zhang et~al.(2023{\natexlab{a}})Zhang, Xu, Usuyama, Bagga, Tinn,
  Preston, Rao, Wei, Valluri, Wong, et~al.]{zhang2023large}
Sheng Zhang, Yanbo Xu, Naoto Usuyama, Jaspreet Bagga, Robert Tinn, Sam Preston,
  Rajesh Rao, Mu~Wei, Naveen Valluri, Cliff Wong, et~al.
\newblock Large-scale domain-specific pretraining for biomedical
  vision-language processing.
\newblock \emph{arXiv preprint arXiv:2303.00915}, 2023{\natexlab{a}}.

\bibitem[Zhang et~al.(2020)Zhang, Kishore*, Wu, Weinberger, and
  Artzi]{bert-score}
Tianyi Zhang, Varsha Kishore*, Felix Wu, Kilian~Q. Weinberger, and Yoav Artzi.
\newblock Bertscore: Evaluating text generation with bert.
\newblock In \emph{International Conference on Learning Representations}, 2020.

\bibitem[Zhang et~al.(2023{\natexlab{b}})Zhang, Wu, Zhao, Lin, Zhang, Wang, and
  Xie]{zhang2023pmc}
Xiaoman Zhang, Chaoyi Wu, Ziheng Zhao, Weixiong Lin, Ya~Zhang, Yanfeng Wang,
  and Weidi Xie.
\newblock Pmc-vqa: Visual instruction tuning for medical visual question
  answering.
\newblock \emph{arXiv preprint arXiv:2305.10415}, 2023{\natexlab{b}}.

\end{thebibliography}
