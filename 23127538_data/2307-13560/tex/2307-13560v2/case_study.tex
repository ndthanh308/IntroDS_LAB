\section{Case Study}
\label{sec:case_study}
In this section, we carry out a qualitative analysis to highlight the merits of our model by demonstrating the generated samples using the WMT14 dataset. Several representative samples are presented in Table 3.





Through comparison, we observe that the conventional RDM model struggles to grasp the mapping relationship between different language domains and is inclined to generate text with a blend of domains. Conversely, under the guidance of language embedding, our XDLM model proficiently masters the mapping relations between different languages. The sample also illustrates the enhanced speed of convergence exhibited by XDLM under the pretraining provided by TDLM.

%\begin{table}[]
%\centering
%\begin{tabular}{|c|l|l|}
%\hline
%\multicolumn{3}{|c|}{Source: Yesterday, Gutacht's Mayor gave a clear answer to this question.} \\
%\multicolumn{3}{|c|}{Target: Diese Frage hat Gutachs BÃ¼rgermeister gestern klar beantwortet.}  \\
%\hline
%Name & Iteration & Decodes \\
%\hline
%\multirow{RDM-Multinomial} & 0 & Content 1 \\
% & 1 & Content 2 \\
% & 2 & Content 3 \\
% & 3 & Content 4 \\
% & 4 & Content 5 \\
%\hline
%\multirow{XDLM} & 0 & Content 6 \\
% & 1 & Content 7 \\
% & 2 & Content 8 \\
% & 3 & Content 9 \\
% & 4 & Content 10 \\
%\hline
%\end{tabular}
%\caption{Qualitative samples of test paraphrases generated from different diffusion models. Words are in lower case}
%\label{table:your_label}
%\end{table}

