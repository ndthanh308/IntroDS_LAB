\section{Introduction}
\label{sec:introduction}

%The shift to digital news made personalized news recommendation ubiquitous in everyday information consumption. 
Neural content-based recommenders \cite{li2019survey, wu2023personalized}, trained to infer users' preferences from their click history, represent the current state of the art in news recommendation. While previously consumed content clearly points to users' preferences, \textit{aspects} other than content alone, e.g., topical category (e.g., \textit{sports}) or sentiment, contribute to their news consumption decisions. Accordingly, some neural news recommendation (NNR) models leverage information on these aspects in addition to text content, be it (i) directly as input to the model \cite{wang2018dkn, wu2019naml, liu2020kred, xun2021we} or (ii) indirectly, as auxiliary training tasks \cite{wu2019tanr, wu2020sentirec, qi2021pp}. 

Increased personalization, however, is often at odds with \textit{diversity} \cite{pariser2011filter,wu2020sentirec}. NNRs, optimized to maximize congruity to the users' preferences, particularly tend to produce recommendations highly similar in content to previously consumed news \cite{liu2021interaction, wu2020sentirec}. Another strand of work thus focuses on increasing diversity of recommendations w.r.t. aspects other than content (e.g., sentiment). To this effect, prior work either (i) re-ranks the content-based recommendations to decrease the aspectual similarity between them \cite{rao2013taxonomy, gharahighehi2023diversification}, or (ii) trains the NNR model by combining a content-based personalization objective with an aspect-based diversification objective \cite{wu2020sentirec, wu2022end, shi2022dcan, choi2022not}. 

Different users, however, assign different importance to different aspects of news (e.g., following developing events requires maximization of content-based overlap with the user's recent history; in another use-case, a user may prefer content-wise diversification of recommendations, but within the same topic of interest). Moreover, with personalization and diversification as mutually conflicting goals, users should be able to seamlessly define their own optimal trade-offs between the two. % needs to choose between the two for each aspect.
The existing body of work is ill-equipped for such multi-aspect customization, because each set of preferences -- i.e., to personalize or diversify for each aspect -- requires a different NNR model to be trained from scratch. Put differently, baking global assumptions on personalization and diversification preferences (i.e., same for all users) into the NNR model design and training prevents customization at inference time. We address this critical limitation of existing NNR work.     

\rparagraph{Contributions.} We propose a \textit{modular} framework for \textit{Multi-Aspect} (Neural) News Recommendation (\manner{}) in which we leverage metric-based contrastive learning to induce a dedicated news encoder for each aspect, starting from a pretrained language model (PLM). This way, we can obtain aspect-specific similarity scores for pairs of news, allowing us to define ad-hoc at inference a custom ranking function for each user, reflecting her preferences 
%(i.e., personalization or diversification) 
across all aspects.
%%
The modular design of \manner{} allows it to be customized for any recommendation objective (i.e., task) specified over (i) standard (i.e., content-based) personalization, (ii) aspect-based diversification, and (iii) aspect-based personalization. The modular design makes \manner{} easily extendable: to support personalization and diversification over a new aspect (e.g., news outlet), one only needs to train the aspect-specific encoder for the new aspect.         

We evaluate \manner{} on two prominent NNR benchmarks: MIND \cite{wu2020mind} (English) and Adressa \cite{gulla2017adressa} (Norwegian), with \textit{topical categories} and \textit{sentiment} as the additional aspects next to content itself.  
%%
\manner{} outperforms state-of-the-art NNRs on standard content-based recommendation across a range of metrics. Thanks to \manner{}'s modular design, we show -- without having to train a multitude of models with different training objectives -- that one can, depending on the recommendation goals, either (i) vastly increase aspect diversity (i.e., diversity over topics and sentiment) of recommendations or (ii) improve aspect-based personalization, while retaining much of the content-based personalization performance. 
%%
Additionally, we carry out a nuanced analysis that shows how weighting of aspect relevance scores affects the trade-off between the content-based recommendation performance and aspect-based diversity or personalization.
%% 
Finally, we demonstrate that \manner{} based on a multilingual PLM is robust to (cross-lingual) transfer of both content- and aspect-based encoders.

%through extensive cross-lingual experiments that \manner{} can integrate aspect-specific news encoders trained on a combination of source- and target-language datasets without loss in either content-based recommendation performance or aspect-based customization compared to the model fully trained on the target-language dataset. Specifically, we quantify these findings for a source-language dataset which is smaller (i.e., 1-week Adressa) and lower-resource (i.e., Norwegian) than the target-language dataset (i.e., English large-scale dataset MIND).   
