\section{Results and Discussion}
\label{sec:results_discussion}
%
\input{tables/recommendation_results}
%

We first discuss \manner{}'s content personalization performance. We then analyze its capability for single- and multi-aspect (i) diversification and (ii) personalization. In the aspect customization setups, we treat \manner{}'s \texttt{CR-Module} as a baseline. Lastly, we evaluate its ability to re-use pretrained aspect-specific modules in cross-lingual transfer. 

\subsection{Content Personalization}
\label{sec:content_personalization}

Table \ref{tab:results_recommendation} summarizes the results on content personalization. Since the task does not require any aspect-based customization, we evaluate the \manner{} variant that uses only its CR-Module at inference time (i.e., $\lambda \hspace{-0.2em} = \hspace{-0.2em} 0$).
%%
\manner{} consistently outperforms all state-of-the-art NNRs in terms of both classification and ranking metrics on both datasets. Given that \manner{}'s \texttt{CR-Module} derives the user embedding by merely averaging clicked news embeddings, these results question the need for complex parameterized UEs, present in all the baselines, in line with the findings of \citet{iana2023simplifying}. 

% \vspace{1.4mm}
% \noindent\textbf{Ablations.}
% 
We ablate \texttt{CR-Module}'s content personalization performance for (i) different inputs to the NE and (ii) alternative architecture designs and training objectives.
%
We find that all groups of features (e.g., abstract, named entities) contribute to the overall performance (cf. Fig. \ref{fig:ablation_features}). 
% 
Moreover, we confirm the findings of \citet{iana2023simplifying} that (i) late fusion outperforms a parameterized UE (i.e., early fusion), and that (ii) SCL better separates classes than cross-entropy loss, in line with other similarity-oriented NLP tasks  \cite{reimers2019sentence}.

\subsection{Single-Aspect Customization}
%%
\input{tables/diversification_results}
%
% Figure environment removed



\vspace{1.4mm}
\noindent\textbf{Diversification.}
Table~\ref{tab:results_diversification} summarizes the results on aspect diversification tasks.
%%%
Most baselines (including \manner{}'s \texttt{CR-Module} without aspect diversification) obtain similar diversification scores (D\textsubscript{ctg} and D\textsubscript{snt}). 
%
The sentiment-aware SentiRec-PLM, with an explicit auxiliary sentiment diversification objective, yields the highest sentiment diversity on Adressa; this comes at the expense of content personalization quality (lowest nDCG).
%
On MIND, the sentiment-specific SentiDebias-PLM achieves the highest sentiment diversity, but also exhibits lower content personalization performance. Overall, these results point to a trade-off between content personalization and aspectual diversity: models with higher D\textsubscript{A\textsubscript{p}} tend to have a lower nDCG. 

Unlike all other models, \manner{} can trade content personalization for diversity (and vice-versa) with different values of the aspect coefficients $\lambda_{A_p}$. Fig. \ref{fig:single_aspect_div_mind} illustrates its performance in single-aspect diversification tasks for different values of $\lambda$\textsubscript{ctg} and $\lambda$\textsubscript{snt} on MIND.
%%%
The steady drop in nDCG together with the steady increase in D\textsubscript{A\textsubscript{p}} indeed indicate the existence of a trade-off between content personalization and aspect diversification. For topical categories we observe a steeper decline in content personalization quality with improved diversification than for sentiment. Sentiment diversity reaches peak performance for $\lambda_{snt} \hspace{-0.2em} = \hspace{-0.2em} -0.4$, whereas category diversity continues to increase all the way to $\lambda_{ctg} \hspace{-0.2em} = \hspace{-0.2em} -0.9$. Intuitively, content-based recommendation is more aligned with the topical than with the sentiment consistency of recommendations. The best trade-off (i.e., maximal performance w.r.t. T\textsubscript{A\textsubscript{p}}@10) is achieved for $\lambda_{ctg}\hspace{-0.2em} = \hspace{-0.2em} -0.2$ for topics, and $\lambda_{snt} \hspace{-0.2em} = \hspace{-0.2em} -0.3$ for sentiment. We report analogous results on Adressa in Appendix \ref{sec:appendix_single_apsect_customization}.
%
We attribute these effects to the representation spaces of the \texttt{A-Modules}. Fig. \ref{fig:tsne_categ_mind} shows the 2-dimensional t-SNE visualizations \cite{van2008visualizing} of the news embeddings produced with category-specialized encoders trained on MIND (see Fig. \ref{fig:tsne_sent_mind} for sentiment). The results confirm that the latent representation space of the encoder was reshaped to group same-class instances. The separation of classes, however, is less prominent for representation spaces of the encoders trained on Adressa (cf. Fig. \ref{fig:tsne_embeddings_adressa}) than for those learned on MIND (e.g., the effect is stronger on the category-shaped embedding space).\footnote{We believe that this is because Adressa has 10 times fewer news than MIND (and contrastive learning, naturally, benefits from more news pairs), with over half of the topical categories in Adressa being represented with fewer than 100 examples.} 
%
\input{tables/personalization_results}

\vspace{1.4mm}
\noindent\textbf{Personalization.}
Table \ref{tab:results_personalization} displays the results on aspect personalization tasks. TANR, trained with an auxiliary topic classification task, underperforms NAML, which uses topical categories as NE input features, in category personalization on both datasets . 
%
\manner{}'s \texttt{CR-Module} alone (i.e., without any aspect customization) yields competitive category personalization performance. We believe that this is because (i) the \texttt{CR-Module} is best in content personalization and (ii) category personalization is well-aligned with content personalization (i.e., news with similar content tend to belong to the same category). 
%
Fig. \ref{fig:single_aspect_pers_mind} explores the trade-off between content and aspect personalization, for different positive values of $\lambda_{A_p}$ on MIND (see Fig. \ref{fig:single_aspect_pers_adressa} for Adressa). The best topical category personalization (PS\textsubscript{ctg}), obtained for $\lambda_{ctg} \hspace{-0.2em} > \hspace{-0.2em} 0.7$, comes at the small expense of content personalization: too much weight on the category similarity of news dilutes the impact of content relevance. Increased sentiment personalization, however, is much more detrimental to content personalization. Intuitively, users do not choose articles based on sentiment. Tailoring recommendations according to the sentiment of previously clicked news thus leads to more content-irrelevant suggestions. 


\subsection{Multi-Aspect Customization} 
% \vspace{1.4mm}
% \noindent\textbf{Diversification.}
We further explore the trade-off between content personalization and multi-aspect diversification, i.e. diversifying simultaneously over both topical categories and sentiments, for different values of the aspect coefficients $\lambda_{ctg}$ and $\lambda_{snt}$. We achieve the highest T\textsubscript{all} for $\lambda_{ctg} \hspace{-0.2em} = \hspace{-0.2em} -0.2$ and $\lambda_{snt} \hspace{-0.2em} = \hspace{-0.2em} -0.25$ on MIND (cf. Fig. \ref{fig:multi_aspect_div_mind}). In line with results on single-aspect diversification, we observe that improving diversity in terms of topical categories rather than sentiments has a more negative effect on content personalization quality, i.e. steeper decline in T\textsubscript{all}. Overall, these results confirm that \manner{} can generalize to diversify for multiple aspects at once by weighting individual aspect relevance scores less than in the single-aspect task. This can be explained by the fact that weighting several aspects higher at the same time acts as a double discounting for content personalization, diluting content relevance disproportionately.
%
% \vspace{1.4mm}
% \noindent\textbf{Personalization.}
Similarly, for multi-aspect personalization, we achieve the best multi-aspect trade-off on MIND (cf. Fig. \ref{fig:multi_aspect_pers_mind}) for $\lambda_{ctg} \hspace{-0.2em} = \hspace{-0.2em} 0.45$ and $\lambda_{snt} \hspace{-0.2em} = \hspace{-0.2em} 0.25$. Stronger enforcing of alignment of candidate news with user's history is needed for topical categories than for sentiment (i.e., $\lambda_{ctg} \hspace{-0.2em} > \hspace{-0.2em} \lambda_{snt}$). This is because sentiment exhibits low variance within topical categories (e.g., \textit{politics} news are mostly negative) and enforcing categorical personalization thus partly also achieves sentiment personalization. 
%
% Figure environment removed
%                                        

\subsection{Cross-Lingual Transfer}
\label{sec:xlt}

Lastly, we analyze the transferability of \manner{} across datasets and languages in single-aspect customization experiments.\footnote{We evaluate only the title-based version of \manner{}, as the full version cannot be trained on Adressa.} 
%
Concretely, we train the \texttt{CR-Module} and \texttt{A-Modules} on both MIND (i.e., in English) and Adressa (i.e., in Norwegian), respectively. 
At inference, we evaluate all combinations of pretrained \texttt{CR-Module} and \texttt{A-Modules} on the test set of MIND. 
We replace the monolingual PLMs used in \manner{}'s NE with a multilingual DistilBERT Base \cite{sanh2019distilbert} to enable cross-lingual transfer (\texttt{XLT}).
%
Fig. \ref{fig:cross_lingual_transfer_results} summarizes the \texttt{XLT} results for single-aspect diversification. We refer to Appendix \ref{sec:appendix_xlt} for similar results on single-aspect personalization and on Adressa as target-language dataset.
%
As expected, \manner{} trained fully on Adressa suffers a large drop in content personalization performance, compared to the counterpart trained on MIND. 
%
In contrast, transferring only the \texttt{A-Module}, i.e., training the \texttt{CR-Module} on MIND and the \texttt{A-Module} (for topics and sentiment) on Adressa, yields performance comparable to that of complete in-language training (i.e., both \texttt{CR-Module} and \texttt{A-Module} trained on MIND). 
% 
This is particularly the case for the sentiment \texttt{A-Module}, since the sentiment labels between the datasets are more aligned than those for topical categories. 
%
These results indicate that the plug-and-play of \texttt{A-Modules} enables zero-shot \texttt{XLT}, as modules trained on the much smaller Norwegian Adressa transfer well to the large English MIND. 
%
This suggests that, coupled with multilingual PLMs, \manner{} can be used for effective news recommendation in lower-resource languages, where training data and aspectual labels are scarce. Furthermore, the results demonstrate that the \texttt{A-Modules} could be trained on general-purpose classification datasets  (e.g. topic or sentiment classification datasets), 
alleviating the need for aspect-specific annotation of news stories. 
% Figure environment removed