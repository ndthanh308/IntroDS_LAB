\section{Results and Discussion}
\label{sec:results_discussion}
%
\input{tables/recommendation_results}
%%
\input{tables/diversification_results}
%

We first discuss \manner{}'s content personalization performance. We then analyze its capability for single- and multi-aspect (i) diversification and (ii) personalization. In the aspect customization setups, we treat \manner{}'s \texttt{CR-Module} as a baseline. Lastly, we evaluate its ability to re-use pretrained aspect-specific modules in cross-lingual transfer. 

\subsection{Content Personalization}
\label{sec:content_personalization}

Table \ref{tab:results_recommendation} summarizes the results on content personalization. Since the task does not require any aspect-based customization, we evaluate the \manner{} variant that uses only its CR-Module at inference time (i.e., $\lambda \hspace{-0.2em} = \hspace{-0.2em} 0$).
%%
\manner{} consistently outperforms all state-of-the-art NNRs in terms of both classification and ranking metrics on both datasets. Given that \manner{}'s \texttt{CR-Module} derives the user embedding by merely averaging clicked news embeddings, these results question the need for complex parameterized UEs, present in all the baselines, in line with the findings of \citet{iana2023simplifying}. 

% 
We ablate the \texttt{CR-Module}'s content personalization performance for (i) different inputs to the NE and (ii) alternative architecture designs and training objectives.
%
We find that all groups of features (e.g., abstract, named entities) contribute to the overall performance (cf. Fig. \ref{fig:ablation_features}). 
% 
Moreover, we confirm the findings of \citet{iana2023simplifying} that (i) late fusion outperforms a parameterized UE (i.e., early fusion), and that (ii) SCL better separates classes than cross-entropy loss, in line with other similarity-oriented NLP tasks  \cite{reimers2019sentence}.

\subsection{Single-Aspect Customization}

% Figure environment removed
%
% Figure environment removed

\vspace{1.4mm}
\noindent\textbf{Diversification.}
Table~\ref{tab:results_diversification} summarizes the results on aspect diversification tasks.
%%%
Most baselines (including \manner{}'s \texttt{CR-Module} without aspect diversification) obtain similar diversification scores (D\textsubscript{ctg} and D\textsubscript{snt}). 
%
The sentiment-aware SentiRec-PLM, with an explicit auxiliary sentiment diversification objective, yields the highest sentiment diversity on Adressa; this comes at the expense of content personalization quality (lowest nDCG).
%
On MIND, the sentiment-specific SentiDebias-PLM achieves the highest sentiment diversity, but also exhibits lower content personalization performance. Overall, these results point to a trade-off between content personalization and aspectual diversity: models with higher D\textsubscript{A\textsubscript{p}} tend to have a lower nDCG. 

Unlike all other models, \manner{} can trade content personalization for diversity (and vice-versa) with different values of the aspect coefficients $\lambda_{A_p}$. Figs. \ref{fig:single_aspect_div_sent_mind}-\ref{fig:single_aspect_div_categ_mind} illustrate its performance in single-aspect sentiment and category diversification tasks for different values of $\lambda$\textsubscript{snt}, and $\lambda$\textsubscript{ctg}, respectively, on MIND.
%%%
The steady drop in nDCG together with the steady increase in D\textsubscript{A\textsubscript{p}} indeed indicate the existence of a trade-off between content personalization and aspect diversification. For topical categories we observe a steeper decline in content personalization quality with improved diversification than for sentiment. Sentiment diversity reaches peak performance for $\lambda_{snt} \hspace{-0.2em} = \hspace{-0.2em} -0.4$, whereas category diversity continues to increase up to $\lambda_{ctg} \hspace{-0.2em} = \hspace{-0.2em} -0.9$. Intuitively, content-based recommendation is more aligned with the topical than with the sentiment consistency of recommendations. The best trade-off (i.e., maximal performance w.r.t. T\textsubscript{A\textsubscript{p}}@10) is achieved for $\lambda_{snt} \hspace{-0.2em} = \hspace{-0.2em} -0.3$ for sentiment, and $\lambda_{ctg}\hspace{-0.2em} = \hspace{-0.2em} -0.2$ for topics.\footnote{We report analogous results on Adressa in Figs.  \ref{fig:single_aspect_div_sent_adressa}-\ref{fig:single_aspect_div_categ_adressa}.}
%
We attribute these effects to the representation spaces of the \texttt{A-Modules}. Fig. \ref{fig:tsne_embeddings_mind} shows the 2-dimensional t-SNE visualizations \cite{van2008visualizing} of the news embeddings produced with category-specialized, and respectively, sentiment-specialized NEs trained on MIND. The results confirm that the  encoder's latent representation space was reshaped to group same-class instances. The separation of classes, however, is less prominent for representation spaces of the encoders trained on Adressa (cf. Fig. \ref{fig:tsne_embeddings_adressa},  e.g., the effect is stronger on the category-shaped embedding space).\footnote{We believe that this is because Adressa has 10 times fewer news than MIND, with over half of the topical categories in Adressa being represented with fewer than 100 examples.} 
%
\input{tables/personalization_results}

\vspace{1.4mm}
\noindent\textbf{Personalization.}
Table \ref{tab:results_personalization} displays the results on aspect personalization tasks. TANR, trained with an auxiliary topic classification task, underperforms NAML, which uses topical categories as NE input features, in category personalization on both datasets. 
%
\manner{}'s \texttt{CR-Module} alone (i.e., without any aspect customization) yields competitive category personalization performance. We believe that this is because (i) the \texttt{CR-Module} is best in content personalization and (ii) category personalization is well-aligned with content personalization (i.e., news with similar content tend to belong to the same category). 
%
Fig. \ref{fig:single_aspect_pers_categ_mind} explores the trade-off between content and category personalization, for positive values of $\lambda_{ctg}$ on MIND.
% \footnote{We refer to Figs. \ref{fig:single_aspect_pers_sent_adressa}-\ref{fig:single_aspect_pers_categ_adressa} for results on Adressa.}
%
The best topical category personalization (PS\textsubscript{ctg}), obtained for $\lambda_{ctg} \hspace{-0.2em} > \hspace{-0.2em} 0.7$, comes at the small expense of content personalization: too much weight on the category similarity of news dilutes the impact of content relevance. Increased sentiment personalization (cf. Fig. \ref{fig:single_aspect_pers_sent_mind}), however, is much more detrimental to content personalization. Intuitively, users do not choose articles based on sentiment. Tailoring recommendations according to the sentiment of previously clicked news thus leads to more content-irrelevant suggestions. 


\subsection{Multi-Aspect Customization} 
We further explore the trade-off between content personalization and multi-aspect diversification, i.e. diversifying over both topical categories and sentiments.
% , for different values of the aspect coefficients $\lambda_{ctg}$ and $\lambda_{snt}$. 
We achieve the highest T\textsubscript{all} for $\lambda_{ctg} \hspace{-0.2em} = \hspace{-0.2em} -0.2$ and $\lambda_{snt} \hspace{-0.2em} = \hspace{-0.2em} -0.25$ on MIND (cf. Fig. \ref{fig:multi_aspect_div_mind}). In line with single-aspect diversification results, we observe that improving diversity in terms of topical categories rather than sentiments has a more negative effect on content personalization quality, i.e. steeper decline in T\textsubscript{all}. These results confirm that \manner{} can generalize to diversify for multiple aspects at once by weighting individual aspect relevance scores less than in the single-aspect task. Weighting several aspects higher simultaneously acts as a double discounting for content personalization, diluting content relevance disproportionately.
%
Similarly, for multi-aspect personalization, we achieve the best multi-aspect trade-off on MIND (cf. Fig. \ref{fig:multi_aspect_pers_mind}) for $\lambda_{ctg} \hspace{-0.2em} = \hspace{-0.2em} 0.45$ and $\lambda_{snt} \hspace{-0.2em} = \hspace{-0.2em} 0.25$. Stronger enforcing of alignment of candidate news with the user's history is needed for topical categories than for sentiment (i.e., $\lambda_{ctg} \hspace{-0.2em} > \hspace{-0.2em} \lambda_{snt}$). This is because sentiment exhibits low variance within categories (e.g., \textit{politics} news are mostly negative) and enforcing categorical personalization partly also achieves sentiment personalization.\footnote{We refer to Fig. \ref{fig:multi_aspect_results_addressa} for analogous results on Adressa.}

% Figure environment removed
%

% Figure environment removed


\subsection{Cross-Lingual Transfer}
\label{sec:xlt}

We next analyze the transferability of \manner{} across datasets and languages in single-aspect customization experiments.\footnote{We evaluate only the title-based version of \manner{}, as the full version cannot be trained on Adressa.} 
%
Concretely, we train the \texttt{CR-Module} and \texttt{A-Modules} on both MIND (i.e., in English) and Adressa (i.e., in Norwegian), respectively. 
At inference, we evaluate all combinations of pretrained \texttt{CR-Module} and \texttt{A-Modules} on the test set of MIND. 
We now use a multilingual DistilBERT Base \cite{sanh2019distilbert} as \manner{}'s NE to enable cross-lingual transfer (\texttt{XLT}).
%
Fig. \ref{fig:xlt_adressa_mind_div} summarizes the \texttt{XLT} results for single-aspect diversification.\footnote{Figs. \ref{fig:xlt_adressa_mind_div} and \ref{fig:xlt_mind_adressa} provide similar results for single-aspect personalization and single-aspect customization on MIND, and respectively, Adressa, as target-language datasets.}
%
As expected, \manner{} trained fully on Adressa suffers a large drop in content personalization performance, compared to the counterpart trained on MIND. 
%
In contrast, transferring only the \texttt{A-Module}, i.e., training the \texttt{CR-Module} on MIND and the \texttt{A-Module} on Adressa, yields performance comparable to that of complete in-language training (i.e., both \texttt{CR-Module} and \texttt{A-Module} trained on MIND). 
% 
This is particularly the case for the sentiment \texttt{A-Module}, since the sentiment labels between the datasets are more aligned than those for topical categories. 
%
These results indicate that the plug-and-play of \texttt{A-Modules} enables zero-shot \texttt{XLT}, as modules trained on the much smaller Norwegian Adressa transfer well to the large English MIND. 
%
This suggests that, coupled with multilingual PLMs, \manner{} can be used for effective news recommendation in lower-resource languages, where training data and aspectual labels are scarce. Furthermore, the results demonstrate that the \texttt{A-Modules} could be trained on general-purpose classification datasets  (e.g. topic or sentiment classification datasets), 
alleviating the need for aspect-specific annotation of news stories. 

\subsection{Computational Complexity}
\label{sec:computational_complexity}
While A-Modules add extra parameters, their average training time is two orders of magnitude faster than that of the CR-Module.\footnote{On MIND (Adressa), the A-Module for topical category trains 277 (51) times faster and that for sentiment 204 (53) times faster on average per epoch than the CR-Module.}
%
This is a \textit{one-time} increase in training time: the resulting modules can then be arbitrarily combined for any recommendation goal without additional training. In contrast, all other NNRs require re-training or fine-tuning if the recommendation objective changes as the model weights have to be adjusted each time. This translates into much higher computational costs in practice. We emphasize that \manner{} also has a much lower inference latency due to the (i) CR-Module's lean architecture without a parameterized UE, and (ii) ability to parallelize loading and deploying different modules, for which only the final score has to be combined.\footnote{We provide the average inference times in Appendix \ref{sec:appendix_time}.} 
%
Overall, considering both training and inference, \manner{} is more efficient and flexible in a realistic setup with differing recommendation goals that may vary by user or for the same user over time. 