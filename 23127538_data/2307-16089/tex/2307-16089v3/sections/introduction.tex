\section{Introduction}
\label{sec:introduction}

Neural content-based recommenders, trained to infer users' preferences from their click history, represent the state of the art in news recommendation \cite{li2019survey,wu2023personalized}. 
%
While previously consumed content clearly indicates users' preferences, \textit{aspects} other than content alone, namely categorical features of the news such as topical category, sentiment, news outlet, or stance, contribute to their news consumption decisions. 
Accordingly, some neural news recommenders (NNRs) leverage information on these aspects in addition to text content, be it (i) directly as model input \cite{wu2019naml, liu2020kred} or (ii) indirectly, as auxiliary training tasks \cite{wu2019tanr, wu2020sentirec}. 

Increased personalization is often at odds with \textit{diversity} \cite{pariser2011filter}. NNRs optimized to maximize congruity to users' preferences tend to produce suggestions highly similar in content to previously consumed news \cite{liu2021interaction, wu2020sentirec, sertkan2023effect}. Another strand of work thus focuses on increasing diversity of recommendations w.r.t. aspects other than content (e.g., sentiment). To this effect, prior work either (i) re-ranks content-based recommendations to decrease the aspectual similarity between them \cite{rao2013taxonomy, gharahighehi2023diversification}, or (ii) trains the NNR model by combining a content-based personalization objective with an aspect-based diversification objective \cite{wu2020sentirec, wu2022end, shi2022dcan, choi2022not}. 

Different users assign different importance to various news aspects (e.g., following developing events requires maximization of content-based overlap with the user's recent history; in another use-case, a user may prefer content-wise diversification of recommendations, but within the same topic of interest). Moreover, with personalization and diversification as mutually conflicting goals, users should be able to seamlessly define their own optimal trade-offs between the two. 
%
The existing body of work is ill-equipped for such multi-aspect customization, because each set of preferences -- i.e., to personalize or diversify for each aspect -- requires a different NNR model to be trained from scratch. Put differently, forcing global assumptions on personalization and diversification preferences (i.e., same for all users) into the model design and training prevents customization at inference time. 

\vspace{1.4mm}
\noindent\textbf{Contributions.} We propose a \textit{modular} framework for \textit{Multi-Aspect} Neural News Recommendation (\manner{}) to address this limitation. It leverages metric-based contrastive learning to induce a dedicated news encoder for each aspect, starting from a pretrained language model (PLM). This way, we obtain linearly-combinable aspect-specific similarity scores for pairs of news, allowing us to define ad-hoc at inference a custom ranking function for each user, reflecting their preferences across all aspects.
%%
\manner{}'s modular design allows customization for any recommendation objective specified over (i) standard (i.e., content-based) personalization, (ii) aspect-based diversification, and (iii) aspect-based personalization. It also makes \manner{} easily extendable: to support personalization and diversification over a new aspect (e.g., news outlet), one only needs to train the aspect-specific news encoder for that aspect.    
%
Through extensive experiments
% on two established benchmarks,
with \textit{topical categories} and \textit{sentiment} as additional aspects next to content itself, we find that \manner{} outperforms state-of-the-art NNRs on standard content-based recommendation.
%
Thanks to its module-specific outputs being \textit{linearly composable} between objectives, we show -- without training numerous models with different objectives -- that depending on the recommendation goals, one can either (i) vastly increase aspect diversity (e.g., over topics and sentiment) of recommendations or (ii) improve aspect-based personalization, while retaining much of the content-based personalization performance. Finally, we demonstrate that \manner{} with a multilingual PLM is robust to the (cross-lingual) transfer of aspect-based encoders.