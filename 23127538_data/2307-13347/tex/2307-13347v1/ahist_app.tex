\section{Proof of \cref{thm:ahist_r}} \label{sec:ahist_app}

\new{We start with the case when $\tau \le \sqrt{R}$. In this case, \cref{alg:ahist_r} implements \cref{alg:subsample_IBLT} with $\tau = 1$ and returns the obtained histogram in Line 11. Notice that when $\tau = 1$, the subsampling step is trivial and each user encodes their entire histogram. Hence as long as long the decoding of IBLT succeeds (as promised in the performance analysis of \cref{alg:subsample_IBLT}), we recover the histogram perfectly, \ie $\hat{h}^{[R]} = h^{[R]}.$ And the communication cost will be $\tilde{\Theta}(mn)$.
}

Next we focus on the case when $\tau \ge \sqrt{R}.$ We will condition on the event that the list $H$ obtained in Line 8 of \cref{alg:ahist_r} is a $\thr$ approximate heavy hitter set and hence setting $\hat{x} = 0$ for $x \notin H$ won't introduce error larger than $\thr$.

The rest of the proof follows similarly as the standard proof for Count-sketch. Since $\rep = \ceil{\log\Paren{\frac{4\nspu\ns R}{\tau \beta}}}$, it would be enough to prove that $\forall x \in \cX$, with probability at least 2/3, we have
\[
    |\sum_{r \in [R]} T_r(j, \hash_{j}(x)) \cdot s_{j, r}(x)  - h^{[R]}(x)|  = O(\thr).
\]
Let
\begin{align*}
       \hat{h}_j(x) \eqdef & \sum_{r \in [R]} T^{(r)}(j, \hash_{j}(x))  \cdot s_{j, r}(x) \\ =  & \sum_{r \in [R]}  \sum_{x'}\indic{ \hash_{j}(x') = \hash_{j}(x)} s_{j, r}(x') s_{j, r}(x) \cdot h^{(r)}(x') \\
        = & \sum_{x'}\indic{ \hash_{j}(x') = \hash_{j}(x)} \sum_{r \in [R]} s_{j, r}(x') s_{j, r}(x) \cdot h^{(r)}(x') \\
        = & h^{[R]}(x) +  \sum_{x'\neq x}\indic{ \hash_{j}(x') = \hash_{j}(x)} \sum_{r \in [R]} s_{j, r}(x') s_{j, r}(x) \cdot h^{(r)}(x') 
\end{align*}

Then we have $\expectation{ \hat{h}_j(x) = h^{[R]}(x)}$. Next we provide a bound on the variance.  
Let $H_{10\tau/\sqrt{R}}$ be the set of elements with frequency at least $10\tau/\sqrt{R}$, then we have $|H_{10\tau/\sqrt{R}}| \le \frac{mn\sqrt{R}}{10\tau}$. Since $w = \ceil{\frac{10mn\sqrt{R}}{\tau}}$, we have with probability at least 5/6, 
\[
    \sum_{x' \in H_{10\tau/\sqrt{R}}, x' \neq x}\indic{ \hash_{j}(x') = \hash_{j}(x)}  = 0.
\]
Conditioned on this event, we have
\begin{align*}
    \expectation{\Paren{\hat{h}_j(x)  - h^{[R]}(x)}^2}  & = \expectation{\Paren{\sum_{x' \notin H_{10\tau/\sqrt{R}}, x' \neq x}\indic{ \hash_{j}(x') = \hash_{j}(x)} \sum_{r \in [R]} s_{j, r}(x') s_{j, r}(x) \cdot h^{(r)}(x')}^2}
    \\
    & \le \frac{\max_{x' \notin H_{10\tau/\sqrt{R}}} h^{[R]}(x) \sum_{x' \notin H_{10\tau/\sqrt{R}}} h^{[R]}(x) }{w} \\
    & \le \thr^2.
\end{align*}

Hence with probability at least $5/6$, we have
\[
     \expectation{\absv{\hat{h}_j(x)  - h^{[R]}(x)}} \le \sqrt{6}\tau.
\]
We conclude the proof by a union bound over the two events.