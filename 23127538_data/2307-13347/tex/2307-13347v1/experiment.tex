\section{Experiments} \label{sec:exp}
In this section, we empirically evaluate our proposed algorithms (\cref{alg:subsample_IBLT,alg:adaptive_iblt}) for the task of heavy hitter recovery and compare it with baseline methods including (1) Count-sketch based method; (2) IBLT-based method without subsampling (\cref{alg:subsample_IBLT} with $\tau = 1$). We measure communication cost 
in units of words (denoted as $\size$) and each word unit is an {\rm int16} object (can be communicated with 2 bytes) in python and $C$++ for implementation purposes. 
We will mainly focus on string data with characters from $\rm ROOT$ consisting of lower-case letters, digits and special symbols in $\{'~@~\#~-~;~*~:~.~/~\_\}$. %
Below are the details of our implementation. 

\paragraph{Count-median sketch.} We use $\length$ hash functions, each with domain size $\width$ and the total communication cost is $\size = \length\cdot\width$ words\footnote{In our experiments, $\nspu\ns$ will be between $\sim1000$ and $\sim10, 000$, and hence one word is enough  to store an entry in the sketch.}. In the $R$-round setting, for each round $r$, we loop over all $x \in \cX$ and compute an estimate $\hat{h}_r(x)$ and the recovered heavy hitters are those with $\sum_{r}\hat{h}_r(x) \ge \tau$. Note that in the open-domain setting, $d = |\cX|$ can be large and this decoding procedure can be computationally infeasible. There are more computationally feasible variants including tree-based decoding but these come at the cost of higher communication cost or lower utility. We stick to the described version in this work and show that our proposed algorithms outperform this computationally expensive version. The advantage will be be at least as large when comparing to the more computationally feasible versions. %


\paragraph{IBLT-based method.} 
In our experiment, each IBLT data structure is of size $8L_0$, where $L_0$ is the targeted capacity for IBLT.
We state more details about how the size is computed in \cref{sec:iblt_app}.

We consider fixed subsampling and adaptive subsampling. 
For fixed subsampling, when the max number of items in each round is upper bounded by $\mmax$, we set the subsampling parameter in \cref{alg:threshold_sampling}, to be $ t = \max\{1, \min\{ \frac{\mmax}{L_0}, \frac{\thr}{2}\} \}$.  In practice, $\mmax$ can be obtained by system parameters such as the number of users in a round and the maximum contribution by a single user.
Setting $t\le \thr/2$ guarantees that the heavy hitters will be kept with high probability ( \cref{lem:threshold}). And setting $t = \frac{\mmax}{L_0}$ guarantees that with high probability, the decoding of IBLT in each round will succeed and we can obtain more information. We set $b = 1$ in our experiments, the estimated and the heavy hitters are defined as those with estimated frequency at least $\thr$.
In the adaptive algorithm (\cref{alg:adaptive_iblt}), for the update rule, we use
\[
    t_{r + 1} =
    0.5 t_r + 0.5 t_r \times \frac{\hat{s}_r}{C}\]
We leave designing better update rules as future work.  

\paragraph{Client data simulation.} We take the ground-truth distribution of strings in the Stackoverflow dataset in Tensorflow Federated and truncate them to the first $3$ characters in set $\rm ROOT$. This is to make sure that the computation is feasible for Count-median Sketch. And the data universe is of size $d = 97336$. In each round, we take $M_r \sim \cN(M, M/10)$ \iid~samples from the this distribution and encode them using the algorithms mentioned above. In the experiment, we assume all samples come from different users ($\nspu = 1$). For Count-sketch, this won't affect the performance. For IBLT with threshold sampling, this will be equivalent to IBLT with binomial sampling. And by \cite{Duffield2005threshold}, this will only increase the variance of the noise introduced in the sampling process. %
The metric we use is the F1 score of real heavy hitters (heavy hitters with true cumulative frequency at least $\thr$) and the estimated heavy hitters.

We take $R \in \{10, 30, 50, 100\}$, $\thr \in  \{20, 50,$ $100, 200\}$, $M \in \{1000, 2000, 5000, 10000 \}$ and $C \in \{100, 200, 500, 1000, 2000, 5000, 8000, 10000, 20000,$ $30000, 40000\}$. For Count-median method, we take the max F1 score over all $H \in \{5, 7, 9, 11\}$ for each communication cost. We run each experiment for 5 times and compute the mean and standard deviation of the obtained F1 score. Our proposed algorithms consistently outperforms the sketching based method. Below we list and analyze a few representative plots. 

In \cref{fig:communication_m10000}, we plot the F1 score comparison under different communication costs when $R = 30, \thr = 50, M = 10000$. It can be seen that our proposed algorithms significantly outperforms the Count-sketch method. Among the IBLT-based methods, Subsampled IBLT with adaptive tuning is performing the best. For non-interactive algorithms, subsampled IBLT with fixed subsampling probability is better compared to the unsampled counter part for a wide range of capacity. 

% Figure environment removed

In \cref{fig:round_m10000}, we plot the F1 score comparison under different round numbers when $C = 10000, \thr = 200, M = 10000$. As we can see, the performance of Count-sketch decreases significantly when the number of rounds increase while the performance of IBLT-based methods remains relatively flat, which is consistent with the theoretical results\footnote{The communication complexity of SubsampledIBLT is $\tilde{\Theta}(mN/\tau R) =\tilde{\Theta}(mn/\tau)$, which depends on $R$ at most logarithmically when $\ns$ is fixed}. The slight increase in the F1 score when $R$ increases might be due to the \iid~generating process of the data in each round. As $R$ increases, we get more information about the underlying distribution and this effect outweighs additional noise introduced by multiple rounds. Better understanding of this effect is an interesting further direction.

% Figure environment removed

In \cref{fig:adaptive_m10000}, we further demonstrate our adaptive tuning method by showing that it is comparable with the best possible subsampling parameter in a candidate set. More specifically, we run subsampled IBLT with $t \in \{  1,   1.25,   2  ,   5  ,  10  ,  20  ,  50  , 100   \}$ for all communication costs. And the F1 score for SubsampledIBLT (best fixed) is defined as the best F1 score among these candidates. Our result shows that the performance of tha adaptive algorithm is in-par with the best fixed subsampling parameter. It outperforms the best fixed subsampling parameter in certain cases because the set of subsampling parameters we choose from has limited granularity and hence the adaptive algorithm might find better parameters for the underlying instance.

% Figure environment removed