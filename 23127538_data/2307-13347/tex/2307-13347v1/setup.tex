\section{Problem setup and preliminaries}
\label{sec:prelim}
We consider heavy hitter discovery in the distributed setting with multi-round communication between the users and a central server. 
Suppose users come in $R$ rounds. In round $r \in [R]$, there are $\ns$ users, denoted by the set $B_r$. %
We assume the sets are pairwise disjoint, \ie $\forall r \neq r', B_r \cap B_r' = \emptyset$. Each user $i \in B_r$ contributes $m_i$ samples with a contribution bound $m_i \le m$ from a finite domain $\cX$ of size $d$. Let $h_i$ denote the user's local histogram where $\forall x \in \cX$, $h_i(x)$ is the number of times element $x$ appeared in user $i$'s local samples. By assumption, we have $\norm{h_i}_1 = m_i \le m$. Let $h^{(r)}$ be the aggregated histogram in round $r$, \ie
\[
\forall x \in \cX: \quad \quad h^{(r)}(x) = \sum_{i \in B_r} h_i(x).
\]
The aggregated histogram across all $R$ rounds is denoted by $h^{[R]}$ where
\[
    \forall x \in \cX: \quad \quad h^{[R]}(x) = \sum_{r \in [R]} h^{(r)}(x).
\]

The total number of users is denoted by $N \eqdef n R$. 
We will focus on cases where $d \gg Nm$, \ie the case where the support is large and the data is sparse.

The goal of the server is to learn useful information about the aggregated histogram $h^{[R]}$. More precisely, we consider the two tasks described below.

\ignore{
\paragraph{$(\thr, \dist)$-heavy hitter (\ahh).}  For a given threshold $\thr$, the goal of $\dist$-approximate heavy hitter recovery on the entire data stream is to return a set $\heavy$ such that with probability $1 - \beta$,
 \begin{enumerate}
     \item If $h^{[R]}(x) \ge \thr$, $x \in \heavy$.
     \item If $h^{[R]}(x) \le \thr - \dist$, $x \notin \heavy$.
 \end{enumerate}
 To simplify the notation, for most parts of the paper, we will consider heavy hitter recovery for $\dist = 9\thr/10$. And we will denote this problem as $\thr$-approximate heavy hitter. The results naturally extend to cases where $\dist = C \thr$ for some constant $C$ without changing the communication complexity up to a constant factor.
}

\paragraph{$\dist$-heavy hitter (\ahh).}  For a given threshold $\dist$, the goal of $\dist$-heavy hitter recovery on the entire data stream is to return a set $\heavy$ such that with probability $1 - \beta$,
 \begin{enumerate}
     \item If $h^{[R]}(x) \ge \dist$, $x \in \heavy$.
     \item If $h^{[R]}(x) \le \dist/10$, $x \notin \heavy$.
 \end{enumerate}
\paragraph{$\dist$-approximate histogram (\ahist).} The goal is to return an approximate histogram $\widehat{h}^{[R]}$ such that with probability $1 - \beta$,
\[
    \forall x \in \cX, \quad \quad \absv{\widehat{h}^{[R]}(x) - {h}^{[R]}(x)} \le \dist.
\]

It can be seen that $\dist/3$-approximate histogram is a harder problem than $\dist$-heavy hitter (HH) since an $\dist/3$-approximate histogram would imply a set of approximate heavy hitters by returning $H$ to be the list of elements with approximate frequency more than $\thr - \dist/2$. \new{Previous work often solves \ahh~by reducing it to \ahist~(\eg, in \citet{chen2022secagg}). However, as we show in this paper, our work establishes a seperation between the two tasks in terms of the communication complexity in the multi-round setting.} 

\paragraph{Efficient decoding.} Since $d \gg Nm$, we require
efficient encoding (run by users) and decoding (run by the server). More precisely, the encoding/decoding time should be polynomial in $N, m, R, \log d, \log(1/\beta)$ and other parameters.


\paragraph{Per-user communication complexity.} We focus on distributed settings where each user has limited uplink communication capacity. In particular, each user must compress their local histogram $h_i$ to a message of bit length $\ell$, denoted by $Y_i$. And the server must solve the above tasks based on the received messages. The \emph{communication complexity} of each task is the \emph{smallest} bit length such that there exists a communication protocol to solve the task. 

\begin{table*}[ht]
\centering
\renewcommand{\arraystretch}{2}
\begin{tabular}{|c|c|c|c|}
\hline
 Task/Setting & 1-round  \linagg & $R$-round \linagg & Without \linagg~($R = N$)\\ \hline
  $\thr$-\ahh & $\tilde{\Theta} \Paren{\frac{mN}{\thr}}$& $\tilde{\Theta}\Paren{\frac{mN}{\thr R}}$ & $\tilde{\Theta}\Paren{\frac{m}{\thr}}$\\ \hline
  $\thr$-\ahist &  $\tilde{\Theta} \Paren{\frac{mN}{\thr}}$& $\tilde{\Theta} \Paren{ \min\{\frac{mN}{\thr\sqrt{R}}, \frac{mN}{R} \}}$ & $\tilde{\Theta}\Paren{\min\{ \frac{m \sqrt{N}}{\thr}, m\}}$ \\ \hline
\end{tabular}
\caption{Per-user communication complexity. All described bounds can be acheived by a \emph{non-interactive} protocol with server runtime $\text{poly}(m,n,R,\log(d), \log(1/\beta))$. Recall $N = nR$ denotes the total number of users. All bounds cannot be improved up to logarithmic factors
even under \textit{interactive} protocols. $\tilde{\Theta}$ omits factor that are logarithmic in $\tau, R, m$ and $N$.
}
\label{tab:results}
\end{table*}

\paragraph{Distributed estimation with linear sketching (\linagg).} A even more stringent communication model is the linear summation model. In each round $r$, each user $i \in B_r$ can only send a message $Y_i$ from a finite ring $G_r$ %
based on their local histogram and shared randomness $U$. 
For all $i \in B_r$, let
\[
    Y_i = f_i(h_i, U).
\]
Under the linear aggregation model, the server only observes 
\[
    Y^{(r)} = \sum_{i \in B_r} Y_i,
\]
where the addition is the additive operation in the ring $G_r$ and by definition, $Y^{(r)} \in G_r$.
The reason why we restrict ourselves
to a finite ring is for compatibility with cryptographic protocols for secure vector summation~\citep{bonawitz2017secure, BellBGL020}, which operates over a finite space.
These protocols ensure that any additional
information observed by the server beyond $Y^{(r)}$ can in fact be simulated given $Y^{(r)}$, under standard cryptographic assumptions. As mentioned above, we abstract away the specifics of the underlying protocol and assume that the server observes exactly $Y^{(r)}$.
For vector summation, it is convenient to think of $G_r$ as $\mathbb{Z}_{q_r}^\ell$, i.e. length-$\ell$ vectors with integer entries mod $q_r$ (we might chose $q_r$ to be prime when we require division, e.g. in the IBLT construction).


If the protocol is \emph{interactive}, for $i \in B_r$, $Y_i$ is allowed to depend on $Y^{(1)}, \ldots, Y^{(r-1)}$. In this case,
 each $f_i$ is a function of $Y^{(1)}, \ldots, Y^{(r-1)}$. If the protocol is \emph{non-interactive}, $f_i$'s must be fixed independently from previous messages.
 
The server then must recover heavy hitters (and their frequencies) based on the transcript of the protocol, denoted by
 \[
    \Pi = (Y^{(1)}, \ldots, Y^{(R)}, U).
 \]


\new{
\subsection{Connection to other constrained settings.}

Below we discuss the connection between our stated setting to other popular constrained settings including the streaming setting, and the general communication constrained setting. 

\textbf{Connection to the streaming setting.} When $R = 1$, the setting is similar to the streaming setting (\eg in \citet{CORMODE200558}) since they both require that all information about the dataset must be ``compressed'' into a small state. One important difference is that in the distributed setting, the local data is processed independently at each user and only linear operation on the state is permitted due to the linear aggregation operation.
For the $R$-round case, our setting is different since the server observes $R$ states, each with bit length at most $\ell$. These states couldn't be viewed as a mega-state with bit length $R\cdot \ell$ since there is a further restriction that each sub-state (corresponding to the aggregated message observed in a round) can only contain information about data in the corresponding round instead of the entire data stream. Another naive way to reduce the problem to the streaming setting is to sum over all $R$ states and obtain a single state with $\ell$ bits. However, our result implies that this reduction is strictly sub-optimal
(see \cref{tab:results}). To the best of our knowledge, similar settings have not been studied in either the federated analytics literature or the streaming literature. 

\textbf{Connection to distributed estimation without linear sketching.} The general communication constrained setting where linear sketching is not enforced could be viewed as a special case of the proposed framework with $n = 1$ and $R = N$ since in this case, the linear aggregation is performed only over one user's message and hence trivial.

We list comparisons to these settings for the considered tasks in \cref{tab:results}. %
}