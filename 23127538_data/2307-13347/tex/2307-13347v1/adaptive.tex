\section{Practical adaptive tuning for instance-specific bounds} \label{sec:adaptive}
In practical scenarios, the per-user communication cost $\ell$ is often determined by system constraints (\eg delay tolerance, bandwidth constraint) and the goal is to recovery heavy hitters with the small enough $\thr$ under a fixed communication cost $\lmax$. While we have shown in \cref{thm:ahh_lower}, in the worst case, we can only reliably recover heavy hitters with frequency at least $\Omega(\frac{\nspu\ns}{\lmax})$. However, since the successful decoding of IBLTs only requires the number of \emph{unique} elements in a round to be small, when users' data is more favorable, it is possible to obtain better instance-specific bounds when the data is more concentrated on ``heavy'' elements.

When interactivity across rounds is allowed, we give an adaptive tuning algorithm for the subsampling parameter, which can be implemented when interactivity is allowed. The details of the algorithm are described in \cref{alg:adaptive_iblt}. At a high level, our algorithm is based on an estimate for $\norm{\sum_{i \in B_r} h_i'}_0$ where $h_i'$s are the subsampled histograms. When the decoding is successful, we can compute $\norm{\sum_{i \in B_r} h_i'}_0$ exactly from the recovered histogram. When the decoding is not successful, we rely on an analysis based on the ``core size'' of a random hypergraph~\citep{molloy2005cores} introduced by the hashing process to get an estimate of $\norm{\sum_{i \in B_r} h_i'}_0$. We discuss this in details in \cref{sec:iblt_app}.
Under the assumption that for a fixed subsampling parameter $t$, $\norm{\sum_{i \in B_r} h_i'}_0$  will be relatively stable across rounds, we can then increase/decrease $t$ based on past estimates of the data process.

We will empirically demonstrate the effectiveness of our tuning procedure. We leave proving rigorous guarantees on the adaptive tuning algorithm as an interesting future direction.


\begin{algorithm}[h]
\caption{Adaptive subsampled IBLT}\label{alg:adaptive_iblt}
\begin{algorithmic}[1]
\REQUIRE{Communication budget $C$, number of users $\ns$, user contribution bound $\nspu$. \\
\textbf{Update}: A tuning function that updates the subsampling parameter based on past observations.}
\STATE Set $
    t_0 = \Theta\Paren{\frac{\ns m}{C}}.
$
\FOR{$r = 0 , 1, 2, \ldots, R$}
        \STATE Each user $i \in B_r$ applies \cref{alg:threshold_sampling} with threshold $t$ in to their local histogram with fresh randomness to get $h'_{i}$. \label{line:iblt_encoding}
\STATE Each user sends message
$
    Y_{i} = f_{i}(h'_{i})
$
where $f_{i}$'s are mappings from \cref{lem:iblt} with parameter $L_0, \gamma$ and fresh randomness.
\STATE Server observes $\sum_{i \in B_r} Y_{i}$ and computes $$\hat{h}_{r} = \deciblt \paren{\sum_{i \in B_r} Y_{i}}$$
If the decoding is not successful, we let $\hat{h}_{r, j}$ be the all-zero vector.\label{line:iblt_decoding} 
\IF{The decoding is successful,}
    \STATE Set $\hat{s}_r = \norm{\hat{h}_{r}}_0$.
    \ELSE
        \STATE Get an estimate $\hat{s}_r$ for $\norm{\sum_{i \in B_r} h_i'}_0$ based on $\sum_{i \in B_r} Y_{i}$ using \eqref{eq:cardinality-from-core} and \eqref{eq:cardinality-from-core-2} (\cref{sec:iblt_app}). 
\ENDIF
        \STATE Set
        \[
        t_{r + 1} = \textbf{Update}(t_r, C, \hat{s}_r).
        \]
\ENDFOR
\end{algorithmic}
\end{algorithm}
