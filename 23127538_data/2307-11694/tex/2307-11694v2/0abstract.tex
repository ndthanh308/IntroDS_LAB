\begin{abstract}
Predicting synergistic drug combinations can help accelerate discovery of cancer treatments, particularly therapies personalized to a patient's specific tumor via biopsied cells. 
In this paper, we propose a novel setting and models for \emph{in-context drug synergy learning}. We are given a small ``personalized dataset'' of 10-20 drug synergy relationships in the context of specific cancer cell targets. Our goal is to predict additional drug synergy relationships in that context. Inspired by recent work that pre-trains a GPT language model (LM) to ``in-context learn'' common function classes, we devise novel pre-training schemes that enable a GPT model to in-context learn ``drug synergy functions''. Our model---which does not use any textual corpora, molecular fingerprints, protein interaction or any other domain-specific knowledge--- is able to achieve competitive results. We further integrate our in-context approach with a genetic algorithm to optimize model prompts and select synergy candidates to test after conducting a patient biopsy. Finally, we explore a novel task of inverse drug design which can potentially enable the design of drugs that synergize specifically to target a given patient's ``personalized dataset''. Our findings can potentially have an important impact on precision cancer medicine, and also raise intriguing questions on non-textual pre-training for LMs.\footnote{Code will be made available upon publication.}
 

\end{abstract}

