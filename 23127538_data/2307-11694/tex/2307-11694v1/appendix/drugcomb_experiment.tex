
\section{DrugComb Language Model Experiments}

In this section we consider whether our experiments on BERT hold on the DrugComb dataset \cite{zagidullin2019drugcomb, zheng2021drugcomb}. Here, we use the version used in \cite{rozemberczki2022chemicalx} which contains 4,146 drugs, 288 cell lines, and 659,333 synergy tuples. 


\begin{table}[h!]%
\centering
\begin{tabular}{ c|c|c|c|c}%

 Model & \thead{KB Info} & \thead{Name Info} & ROC-AUC & PR-AUC \\%& Precision & Recall & F$_1$ \\
\thickhline
 DeepSynergy & $\times$ &  & 79.7 & 83.2 \\%& 72.0 & 60.0 & 65.4 \\
 \hline
 MR-GNN & $\times$ &  & 68.2 & 74.7 \\%& 67.7 & 41.8 & 51.7 \\
 \hline
 SSI-DDI & $\times$ &  & 55.8 & 62.7 \\%& 59.0 & 6.1 & 11.0 \\
 \hline
 DeepDDS & $\times$ & & 81.7 & 85.8 \\%& 74.9 & 63.1 & 68.5 \\
 \hline
 SciBERT (random) & & & 82.0 & 86.1 \\%& 67.5 & 66.4 & 66.9 \\
 \hline
 BioLinkBERT (random) & & & 82.5 & 86.6 \\

\end{tabular}
\caption{Classification results for four selected ChemicalX \cite{rozemberczki2022chemicalx} baselines and two BERT-base models on DrugComb \cite{zagidullin2019drugcomb, zheng2021drugcomb}. BERT models use random token inputs. Values are average of five runs.}
\label{tab:drugcomb_full_transductive_results}
\end{table} 
