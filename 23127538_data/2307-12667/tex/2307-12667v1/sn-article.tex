%Version 2.1 April 2023
% See section 11 of the User Manual for version history
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                                                 %%
%% Please do not use \input{...} to include other tex files.       %%
%% Submit your LaTeX manuscript as one .tex document.              %%
%%                                                                 %%
%% All additional figures and files should be attached             %%
%% separately and not embedded in the \TeX\ document itself.       %%
%%                                                                 %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%\documentclass[referee,sn-basic]{sn-jnl}% referee option is meant for double line spacing

%%=======================================================%%
%% to print line numbers in the margin use lineno option %%
%%=======================================================%%

%%\documentclass[lineno,sn-basic]{sn-jnl}% Basic Springer Nature Reference Style/Chemistry Reference Style

%%======================================================%%
%% to compile with pdflatex/xelatex use pdflatex option %%
%%======================================================%%

%%\documentclass[pdflatex,sn-basic]{sn-jnl}% Basic Springer Nature Reference Style/Chemistry Reference Style


%%Note: the following reference styles support Namedate and Numbered referencing. By default the style follows the most common style. To switch between the options you can add or remove Numbered in the optional parenthesis. 
%%The option is available for: sn-basic.bst, sn-vancouver.bst, sn-chicago.bst, sn-mathphys.bst. %  
 
\documentclass[sn-nature, iicol]{sn-jnl}% Style for submissions to Nature Portfolio journals
%%\documentclass[sn-basic, iicol]{sn-jnl}% Basic Springer Nature Reference Style/Chemistry Reference Style
%%\documentclass[sn-mathphys,Numbered]{sn-jnl}% Math and Physical Sciences Reference Style
%%\documentclass[sn-aps]{sn-jnl}% American Physical Society (APS) Reference Style
%%\documentclass[sn-vancouver,Numbered]{sn-jnl}% Vancouver Reference Style
%%\documentclass[sn-apa]{sn-jnl}% APA Reference Style 
%%\documentclass[sn-chicago]{sn-jnl}% Chicago-based Humanities Reference Style
%%\documentclass[default]{sn-jnl}% Default
%%\documentclass[default,iicol]{sn-jnl}% Default with double column layout

%%%% Standard Packages
%%<additional latex packages if required can be included here>

\usepackage{graphicx}%
\usepackage{multirow}%
\usepackage{amsmath,amssymb,amsfonts}%
\usepackage{amsthm}%
\usepackage{mathrsfs}%
\usepackage[title]{appendix}%
\usepackage{xcolor}%
\usepackage{textcomp}%
\usepackage{manyfoot}%
\usepackage{booktabs}%
\usepackage{algorithm}%
\usepackage{algorithmicx}%
\usepackage{algpseudocode}%
\usepackage{listings}%
%%%%

%%%%%=============================================================================%%%%
%%%%  Remarks: This template is provided to aid authors with the preparation
%%%%  of original research articles intended for submission to journals published 
%%%%  by Springer Nature. The guidance has been prepared in partnership with 
%%%%  production teams to conform to Springer Nature technical requirements. 
%%%%  Editorial and presentation requirements differ among journal portfolios and 
%%%%  research disciplines. You may find sections in this template are irrelevant 
%%%%  to your work and are empowered to omit any such section if allowed by the 
%%%%  journal you intend to submit to. The submission guidelines and policies 
%%%%  of the journal take precedence. A detailed User Manual is available in the 
%%%%  template package for technical guidance.
%%%%%=============================================================================%%%%

%\jyear{2021}%

%% as per the requirement new theorem styles can be included as shown below
\theoremstyle{thmstyleone}%
\newtheorem{theorem}{Theorem}%  meant for continuous numbers
%%\newtheorem{theorem}{Theorem}[section]% meant for sectionwise numbers
%% optional argument [theorem] produces theorem numbering sequence instead of independent numbers for Proposition
\newtheorem{proposition}[theorem]{Proposition}% 
%%\newtheorem{proposition}{Proposition}% to get separate numbers for theorem and proposition etc.

\theoremstyle{thmstyletwo}%
\newtheorem{example}{Example}%
\newtheorem{remark}{Remark}%

\theoremstyle{thmstylethree}%
\newtheorem{definition}{Definition}%

\raggedbottom
%%\unnumbered% uncomment this for unnumbered level heads

\begin{document}

\title[TransFusion]{TransFusion: Generating Long, High Fidelity Time Series using Diffusion Models with Transformers}

%%=============================================================%%
%% Prefix	-> \pfx{Dr}
%% GivenName	-> \fnm{Joergen W.}
%% Particle	-> \spfx{van der} -> surname prefix
%% FamilyName	-> \sur{Ploeg}
%% Suffix	-> \sfx{IV}
%% NatureName	-> \tanm{Poet Laureate} -> Title after name
%% Degrees	-> \dgr{MSc, PhD}
%% \author*[1,2]{\pfx{Dr} \fnm{Joergen W.} \spfx{van der} \sur{Ploeg} \sfx{IV} \tanm{Poet Laureate} 
%%                 \dgr{MSc, PhD}}\email{iauthor@gmail.com}
%%=============================================================%%

\author*[1]{\fnm{Md Fahim} \sur{Sikder}}\email{md.fahim.sikder@liu.se}
\author[1,2]{\fnm{Resmi} \sur{Ramachandranpillai}}\email{r.ramachandranpillai@northeastern.edu}
\equalcont{Work done while at Link\"oping University}
\author[1]{\fnm{Fredrik} \sur{Heintz}}\email{fredrik.heintz@liu.se}

% \author[2,3]{\fnm{Second} \sur{Author}}\email{iiauthor@gmail.com}
% \equalcont{These authors contributed equally to this work.}

% \author[1,2]{\fnm{Third} \sur{Author}}\email{iiiauthor@gmail.com}
% \equalcont{These authors contributed equally to this work.}

\affil[1]{\orgdiv{Department of Computer and Information Science (IDA)}, \orgname{Link\"oping University}, \orgaddress{\city{Link\"oping}, \country{Sweden}}}
\affil[2]{\orgdiv{Institute for Experiential AI}, \orgname{Northeastern University}, \orgaddress{\city{Boston}, \country{USA}}}

% \affil[2]{\orgdiv{Department}, \orgname{Organization}, \orgaddress{\street{Street}, \city{City}, \postcode{10587}, \state{State}, \country{Country}}}

% \affil[3]{\orgdiv{Department}, \orgname{Organization}, \orgaddress{\street{Street}, \city{City}, \postcode{610101}, \state{State}, \country{Country}}}

%%==================================%%
%% sample for unstructured abstract %%
%%==================================%%

\abstract{The generation of high-quality, long-sequenced time-series data is essential due to its wide range of applications. In the past, standalone Recurrent and Convolutional Neural Network-based Generative Adversarial Networks (GAN) were used to synthesize time-series data. However, they are inadequate for generating long sequences of time-series data due to limitations in the architecture. Furthermore, GANs are well known for their training instability and mode collapse problem. To address this, we propose TransFusion, a diffusion, and transformers-based generative model to generate high-quality long-sequence time-series data. We have stretched the sequence length to 384, and generated high-quality synthetic data. To the best of our knowledge, this is the first study that has been done with this long-sequence length. Also, we introduce two evaluation metrics to evaluate the quality of the synthetic data as well as its predictive characteristics. We evaluate TransFusion with a wide variety of visual and empirical metrics, and TransFusion outperforms the previous state-of-the-art by a significant margin.}

%%================================%%
%% Sample for structured abstract %%
%%================================%%

% \abstract{\textbf{Purpose:} The abstract serves both as a general introduction to the topic and as a brief, non-technical summary of the main results and their implications. The abstract must not include subheadings (unless expressly permitted in the journal's Instructions to Authors), equations or citations. As a guide the abstract should not exceed 200 words. Most journals do not set a hard limit however authors are advised to check the author instructions for the journal they are submitting to.
% 
% \textbf{Methods:} The abstract serves both as a general introduction to the topic and as a brief, non-technical summary of the main results and their implications. The abstract must not include subheadings (unless expressly permitted in the journal's Instructions to Authors), equations or citations. As a guide the abstract should not exceed 200 words. Most journals do not set a hard limit however authors are advised to check the author instructions for the journal they are submitting to.
% 
% \textbf{Results:} The abstract serves both as a general introduction to the topic and as a brief, non-technical summary of the main results and their implications. The abstract must not include subheadings (unless expressly permitted in the journal's Instructions to Authors), equations or citations. As a guide the abstract should not exceed 200 words. Most journals do not set a hard limit however authors are advised to check the author instructions for the journal they are submitting to.
% 
% \textbf{Conclusion:} The abstract serves both as a general introduction to the topic and as a brief, non-technical summary of the main results and their implications. The abstract must not include subheadings (unless expressly permitted in the journal's Instructions to Authors), equations or citations. As a guide the abstract should not exceed 200 words. Most journals do not set a hard limit however authors are advised to check the author instructions for the journal they are submitting to.}

\keywords{Time Series Generation, Generative Models, Diffusion Models, Synthetic Data, Long-Sequenced Data}

%%\pacs[JEL Classification]{D8, H51}

%%\pacs[MSC Classification]{35A01, 65L10, 65L12, 65L20, 65L70}

\maketitle

\section{Introduction}
\label{sec:introduction}


Synthetic time-series generation has been a popular research field in recent years due to its wide variety of applications. Electronic health record (EHR) generation, trajectory generation, and vehicle routing need tremendous amounts of data to learn the pattern in the samples. Unfortunately, it is challenging to get a hold of real data due to the lack of public access to the dataset \cite{walonoski2018synthea}. Synthetic data can be a solution to mitigate this problem \cite{jordon2019pate, torfi2020corgan}. However, generating synthetic time-series data is challenging due to its random nature. In recent years, researchers used different generative techniques like Variational Auto Encoders (VAE) and Generative Adversarial Networks (GAN) to generate synthetic time series data \cite{yoon2019time, mogren2016c, niu2020lstm, xu2020cot, jeon2022gt}. But these studies were done using shorter sequence lengths (less than 100). Also, training GAN is extremely unstable, and it is prone to the mode-collapse problem \cite{goodfellow2020generative}, where the model provide limited sample variety. Generating long-sequenced time-series data is necessary to understand the data context better. The longer the sequence length is, the more information it can capture about the data over time. For example, monitoring a diabetic patient's blood sugar level for a long time will reveal patterns and trends better than monitoring for a short period of time.

Capturing temporal dependencies in long-sequential data is challenging for standalone Convolutional Neural Networks (CNN) and Recurrent Neural Networks (RNN) because of their architectural limitations \cite{ismail2019deep, siami2019performance}. Most of the evaluation metrics for synthetic time series are also CNN and RNN based. So, new metrics are needed for evaluating synthetic time series with long sequences.

Diffusion-based models have garnered extensive interest for their potential in the Computer Vision (CV) and Natural Language Processing (NLP) domains \cite{ho2020denoising, nichol2021improved, rombach2022high}. These models gradually add noise to the input data and make it a noisy data distribution. Adding noise to the data is called the forward diffusion process. And then, a neural network architecture tries to remove the noise and learn the data distribution of the real data. This process is called the backward diffusion process. After training, the diffusion-based generative model can generate high-quality synthetic data. On top of this, these models overcome the mode-collapse problem by learning the semantic nature of the data. Though much interesting work has been done in the CV and NLP domain using diffusion models, time-series generation is still unexplored. 

In this study, we present TransFusion, a diffusion-based model to generate high-quality time series data. We use a transformers encoder \cite{vaswani2017attention} in the backward diffusion process to approximate the real data distribution. As the transformer encoder consists of the attention mechanism, it can capture the long-term temporal dependencies. We conduct extensive experiments with the data consisting of sequences of length 100. We further investigate the generated data quality by TransFusion on the sequence length 384. We perform various evaluations using visual (PCA \& t-SNE) and empirical metrics. Since existing evaluation metrics for synthetic data are based on RNN and CNN architectures, they are unable to capture long-term dependencies. Therefore, we propose two transformers-based evaluation metrics to distinguish between synthetic and original data (post-hoc classifier) and to see if the synthetic data preserves the predictive characteristics of the original data by using a sequence prediction task, respectively. We find that, TransFusion outperforms other state-of-the-art methods in these evaluations in generating long-sequence time-series data.

Our contribution to this work is as follows:

\begin{itemize}
	\item We introduce TransFusion, a diffusion-based generative model, capable of generating long-sequence, high-fidelity time series data that outperforms previous state-of-the-art time series generative models, such as GT-GAN \cite{jeon2022gt}, TimeGAN \cite{yoon2019time}, CotGAN \cite{xu2020cot}, etc.
	\item We propose two evaluation metrics for synthetic time series data which can distinguish original and synthetic data and provide an overview of the synthetic data's performance over sequence prediction tasks. 
	\item We show the quality of the generated data using a wide variety of evaluation metrics (both visual and empirical).
	\item By conducting an ablation study, we show the combination of diffusion model and transformers is needed for generating high-quality, long-sequenced time series data.
\end{itemize}



\section{Related Works}
\label{sec:relatedworks}

Time-series generation has seen an increased amount of interest in recent years for its applications. In most research, Generative Adversarial Networks (GAN) have been used to generate synthetic time series data. GAN has been widely used in computer vision (CV) and Natural Language Processing (NLP) domains with a high success rate \cite{bao2017cvae, zhang2017adversarial}. For the time series generation, most of the studies used Recurrent Neural Network (RNN) and Convolutional Neural Network (CNN) based architecture. For example, C-RNN-GAN \cite{mogren2016c} used Recurrent Neural Network based GAN to generate music. TimeGAN \cite{yoon2019time}, used a combination of supervised and unsupervised learning to generate time series data, and in the architecture, they also used Recurrent Neural Networks. A Convolutional Neural Network based architecture was used in Energy Based GAN \cite{zhao2016energy}, where the author used this CNN architecture in the discriminator, which was later used as an Autoencoder. Causal optimal transport was used to generate the time sequence in CotGAN \cite{xu2020cot}. WaveGAN \cite{donahueadversarial} uses combination of Transposed Convolutional Neural Networks in its generator for generating audio data and QuantGAN \cite{wiese2020quant} uses Temporal Convolutional Networks (TCN) \cite{lea2017temporal} to generate financial time-series data. GT-GAN \cite{jeon2022gt} used a combination of GANs, Autoencoders, Neural Ordinary Differential Equations \cite{chen2018neural}, Neural Controlled Differential Equations \cite{kidger2020neural}, and Continuous time-flow processes \cite{deng2020modeling} for time series generation. Although standalone RNN and CNN architectures have been used widely, these architectures are not well suited for generating longer sequences, because they cannot capture the long-term time dependencies. So, all of the studies mentioned above cannot generate meaningful time series data when the sequence length is longer such as a sequence length of more than 100 (we show in Table \ref{tab:evaluation-table1}). Besides these issues, training GAN is extremely difficult and it is prone to the mode collapse problem.


In contrast, the diffusion-based model has recently caught the attention of researchers and it is yielding promising results in both the CV and NLP domains. Diffusion-based generative models with the correct architecture are capable of generating high quality samples. Also these models are not limited to the mode collapse problem which provides an advantage over the GAN-based models. Generation of time-series using a diffusion-based architecture is fairly new. It has been tested on conditional and unconditional video generation \cite{ho2022video} tasks, and audio generation tasks \cite{kong2020diffwave}. In Diffwave \cite{kong2020diffwave}, the author used a Convolutional Neural Network-based diffusion model that can synthesize audio and outperforms previous GAN-based audio synthesis work. In another audio generation task, the author tried to combine diffusion-based models and GAN-based models for Mandarin-based voice synthesis \cite{cho2022mandarin}. It is important to note that most audio data is low dimensional in nature. This is in contrast to general time-series data, which can often be high-dimensional.

In this study, we leverage the use of transformers architecture to capture the long-term dependencies of time and combine it with the diffusion model. Also, to distinguish original data from synthetic data for long-sequences, we propose a transformer-based post-hoc classifier. Additionally, to see the predictive characteristics in the synthetic data, we also propose a metric called long-sequence predictive score (LPS).

\section{Preliminaries}
\label{sec:preliminaries}

In this section, we formulate the problem definition and give some background information to accompany the paper.

\subsection{Problem Statement}
\label{subsec:problemstatement}


Given a time series data $x \sim q(x)\in \mathbb{R}^D$, where $x = \{x^1, x^2, x^3, ..., x^N\}$, $N$ is the sequence length of time series data, and $D$ is the data dimension, we need to train a generative model that will learn $p_\theta(x)$ which approximate $q(x)$ best. 

In this study, we use diffusion-based models as generative models to synthesize time-series data.

% Figure environment removed


\subsection{Denoising Diffusion Probabilistic Model (DDPM)}

The denoising diffusion probabilistic model \cite{ho2020denoising} works in two steps. First, it takes data $x_0 \sim q(x_0)$ and over the time it adds Gaussian noise and after $T$ steps, the data should become pure Gaussian noise $x_T$ (if $T$ is higher \cite{nichol2021improved}). How much noise is added to each step is calculated by the variance schedule $\beta_{t}$. So the forward diffusion process can be defined as follows:

\begin{equation}
q(x_{1:T}|x_0) = \prod_{t = 1}^T q(x_t|x_{t-1})
\end{equation}

\begin{equation}
q(x_t|x_{t-1}) = \mathcal{N}(x_t;\sqrt{1-\beta_t}x_{t-1}, \beta_t\textbf{I})
\end{equation}

After further calculation, it is possible to sample $x_t$ at any given time given $x_0$ as they are Gaussian. 

\begin{equation}
q(x_t|x_0) = \mathcal{N}(x_t; \sqrt{\Bar{\alpha_t}}x_0, (1-\Bar{\alpha_t})\textbf{I})
\end{equation}

Here, $\alpha_t = 1 - \beta_t$ and $\Bar{\alpha_t} = \prod_{s=0}^t \alpha_s$. In the backward diffusion process, a model is trained to learn $p_\theta$ that approximate $q(x_{t-1}|x_t)$ because it is not possible to learn $q(x_{t-1}|x_t)$ directly as it needs the knowledge of the whole data distribution.

\begin{equation}
\label{eq:diff-back}
p_\theta(x_{t-1}|x_t) = \mathcal{N}(x_{t-1}, \mu_\theta(x_t, t), \Sigma_\theta(x_t, t))
\end{equation}

In practice, a neural network is used to learn the distribution $p_\theta(x_{t-1}|x_t)$, and it tries to predict the parameters $\mu_\theta(x_t, t)$ and $\Sigma_\theta(x_t, t)$. DDPM \cite{ho2020denoising} achieved the best result with a fixed variance $\sigma^2\textbf{I}$. And the mean $\mu_\theta(x_t, t)$ is calculated as follows:

\begin{equation}
\mu_\theta(x_t, t) = \frac{1}{\sqrt{\alpha_t}}\big(x_t-\frac{\beta_t}{\sqrt{1-\Bar{\alpha_t}}}\epsilon_{\theta}(x_t, t)\big)
\end{equation}

So we can re-write equation \ref{eq:diff-back} as:

\begin{equation}
\label{eq:approx}
\begin{split}
p_\theta(x_{t-1}|x_t) = \mathcal{N}(x_{t-1},\frac{1}{\sqrt{\alpha_t}}\big(x_t-\frac{\beta_t}{\sqrt{1-\Bar{\alpha_t}}} & \epsilon_{\theta}(x_t, t)\big), \\
& \sigma^2\textbf{I})
\end{split}
\end{equation}

Also the training objective defined by DDPM is,

\begin{equation}
L_{simple} = \mathbb{E}_{t,x_0,\epsilon}\big[||\epsilon - \epsilon_\theta(x_t, t)||^2\big]
\label{eq:obje}
\end{equation}

where, $\epsilon \sim \mathcal{N}(0, \textbf{I})$


\section{TransFusion: Transformers Diffusion Model}
\label{sec:model}

In this study, we introduce a diffusion model-based time-series generative model called TransFusion. We use the transformer encoder as the neural network architecture to approximate the target data distribution for the backward diffusion process. Figure \ref{fig:transfusion} shows the overall architecture of the TransFusion. 

For the forward diffusion process, we use the cosine variance scheduler \cite{ho2020denoising} to calculate the amount of noise added in each time-step. In the neural network architecture, the time-series data goes through a linear layer, positional encoding, then to the transformer encoder. Positional encoding is used to keep track of the data in each time-step. Then the data is passed through another linear layer to make it the same shape as the original data.

Over time the network tries to denoise the data and learn to approximate the original data distribution using the objective equation \ref{eq:obje}. Algorithm \ref{alg:train} \cite{ho2020denoising} and \ref{alg:sample} show how TransFusion is trained and how samples are generated from it.

\begin{algorithm}
	\caption{Training}
	\label{alg:train}
	\begin{algorithmic}
		\State {\bfseries Input:} Pre-calculated variance schedule $\beta$
		\Repeat
		\State sample $x_0 \sim q(x_0)$, $\epsilon \sim \mathcal{N}(0, \textbf{I})$, $t \sim \mathcal{U}(\{1,..,T\})$
		\State Take Gradient step on
		\State $\nabla_\theta||\epsilon - \epsilon_\theta(x_t, t)||^2$
		\Until{converged}
	\end{algorithmic}
\end{algorithm}

\begin{algorithm}
	\caption{Sampling}
	\label{alg:sample}
	\begin{algorithmic}
		% \STATE {\bfseries Input:} Pre-calculated variance schedule $\beta$
		\State sample $x_T \sim \mathcal{N}(0, \textbf{I})$
		\For{$t=T, ..., 1$}
		\State sample $x_{t-1} \sim p_\theta(x_{t-1|x_t})$ using equation \ref{eq:approx}
		\EndFor
		\State {\bfseries return:} $x_0$
	\end{algorithmic}
\end{algorithm}


\section{Experimental Results}
\label{sec:experiment}

We perform extensive experiments with four time-series datasets and compare the results with seven time-series generative models, TimeGAN \cite{yoon2019time}, C-RNN-GAN \cite{mogren2016c}, EBGAN \cite{zhao2016energy}, CotGAN \cite{xu2020cot}, WaveGAN \cite{donahueadversarial}, QuantGAN \cite{wiese2020quant}, and GT-GAN \cite{jeon2022gt}. We use sequence lengths $100$ and $384$ for the experiments. The result shows that even at this high sequence length (384), TransFusion is capable of generating high-quality synthetic data. We evaluate our study with various evaluation metrics, including qualitative and quantitative analysis. We also propose two evaluation metrics to assess the predictive nature of the synthetic data and to evaluate if the original data and the synthetic data are distinguishable. We also present an ablation analysis to show that the combination of diffusion and transformers is necessary to generate long-sequenced time-series data. Datasets preprocessing procedure, hyperparameters of the TransFusion and benchmarking models can be found in the appendices \ref{ap:dataset}, \ref{ap:hyper}.


\subsection{Datasets}

We use four time-series datasets for this experiment (one simulated and three real-world datasets).

\subsubsection{Sine Data}

We create a sinusoidal function $f(x)$ that generates sine wave data with a dimension of five with various frequencies and phases. The function generates $x_i(t) = sin(2\pi ft + \phi)$, here $f$ represents the frequency and it is sampled from a uniform distribution, $f\sim \mathcal{U}[0, 1]$, the phase $\phi$ is as well sampled from the uniform distributions, $\phi \sim \mathcal{U}[-\pi, \pi]$. The phase is different in each dimension $i \in {1,2, ..., 5}$.

\subsubsection{Stock}

We use Google stock data for the time between 2004 to 2017. This dataset contains six stock features (opening, closing, highest, lowest, and adjacent closing values) per day.

\subsubsection{Energy Consumption}

We also test our model using high-dimensional, noisy energy consumption data from the UCI repository \cite{candanedo2017data}. This dataset contains the electricity consumption of households at 10 minutes intervals for 4.5 months. It has 28 features, including electricity consumption in kilowatts per hour, temperature, humidity reading in various rooms, wind speed, pressure, etc.

\subsubsection{Air Quality}

Finally, we consider using another high-dimensional dataset on air quality \cite{de2008field} from the UCI repository. This dataset was collected from an Italian city hourly and recorded for one year. The data contains 13 features, including the level of carbon mono-oxide (CO), benzin level, etc. in the air.

\subsection{Evaluation Metrics}

We evaluate the quality of the synthetic data in terms of fidelity (does the generated data comes from the same distributions as the original one), diversity (is the generated data diverse enough to fit the whole data) and check if the generative model is demonstrating the mode-collapse problem or not. We also implement a transformers-based post-hoc classifier metric, Long-Sequence Discriminative Score (LDS) that evaluates the fidelity of the synthetic data. Additionally, we implement a transformers-based sequence prediction metric, Long-Sequence Predictive Score (LPS) to observe the predictive characteristics in the synthetic data. In order to evaluate the predictive characteristics of the synthetic data beyond LPS, we conduct another sequence prediction task. The goal of the task is to predict the next five steps of feature vectors given an input sequence.


% Figure environment removed

\subsubsection{PCA \& t-SNE plots}

To evaluate the quality of the synthetic data, we use both Principal Component Analysis \cite{bryant1995principal}, and t-distributed Stochastic Neighbor Embedding \cite{van2008visualizing} techniques. They show how closely the distribution of synthetic data resembles real data in 2-dimensional space and also show if the generated data covers the area of the original data. This gives us the fidelity and diversity evaluation of the synthetic data.

\subsubsection{Long-Sequence Discriminative Score}

We create an evaluation metric to determine if the synthetic data is indistinguishable from the original data. In order to use this metric, first we train a transformers-based \cite{vaswani2017attention} (only using a transformers encoder) post-hoc classifiers with the original \& synthetic data labeled as original and fake, respectively. Then we use the held-out dataset to measure the classification error. This metric is inspired by the discriminative score from the TimeGAN \cite{yoon2019time}. But the discriminative score from TimeGAN uses a RNN-based classifier, which may not work when the sequence length is long. Consequently, we use a transformer-based classifier to capture long-term time dependencies. This metric provides an evaluation of the fidelity of the assessment.



\subsubsection{Long-Sequence Predictive Score}

To check if the synthetic data captured the predictive characteristics of the original data or not, we create a transformers-based sequence prediction task called long-sequence predictive score (LPS). Here we train a transformers-based sequence prediction model to predict the next step feature vector given an input sequence. The metric was also inspired by TimeGAN's predictive score \cite{yoon2019time}, but since TimeGAN's predictive score uses a RNN-based model, it may not be suitable for long-sequenced tasks. We train the model using synthetic data and then evaluate it using the original dataset. The mean absolute error (MAE) is used to measure the performance of the LPS. In addition, we extend the LPS to predict the next five steps (\textbf{+5 Steps Ahead}) feature vectors given the input sequence to see how features evolve over time.

\subsubsection{Jensen-Shannon Divergence}

This quantitative evaluation metric measures if the original and the synthetic data come from the same distributions or not. A lower JSD \cite{menendez1997jensen} score means the distributions are similar between the original and synthetic datasets.



\subsubsection{$\alpha$-precision, $\beta$-recall \& Coverage}

$\alpha$-precision and $\beta$-recall \cite{alaa2022faithful} also provide the assessment of fidelity and diversity, respectively, of the synthetic data. And coverage \cite{naeem2020reliable} checks the mode-dropping issue in the generative models by using nearest neighbor manifolds \cite{ma2010local} and measuring the fraction of the original samples whose neighborhoods contain at least one synthetic sample.

\subsection{Visualization Results}
For the qualitative comparison, we use the PCA and t-SNE plots of our generative models and compare them with other model plots. Figure \ref{fig:pca-tsne-100}, shows the plots of the energy dataset, sequence length 100 (high-dimensional data in our experiment). Each dot in the plot represents a sequence of data. We can observe, for TransFusion, the generated data's dot is closer to the original data. This indicates that our generative model learns the distribution of the original data and is capable of generating high-quality data. %Figure \ref{fig:384-figure} shows that TransFusion is capable of generating great results even with a higher sequence length (384), whereas the CoTGAN is unable to keep up.

\begin{sidewaystable*}[]
	\caption{Resutls on Different Time-Series Datasets, Sequence Length: 100, we report the mean and standard deviation (bold indicates best result, $\uparrow$ indicates higher as better, $\downarrow$ indicates lower as better)}
	\centering
	{\small
		\begin{tabular}{lcccccccc}\toprule
			& \multicolumn{7}{c}{\textbf{Evaluation Metrics}} 
			\\\cmidrule(lr){3-9}
			\textbf{Dataset} & \textbf{Model Name} & LDS & LPS & JSD & $\alpha$- & $\beta$- & Coverage & + 5 Steps\\ 
			& &  & & & precision & recall & & Ahead\\ 
			& & ($\downarrow$) & ($\downarrow$) & ($\downarrow$) & ($\uparrow$)& ($\uparrow$)& ($\uparrow$) & ($\downarrow$)\\ \midrule
			& TimeGAN & 0.499  $\pm$ .001 & 0.253 $\pm$ .001 & 0.11 $\pm$ .00 &  0.863 $\pm$ .00 & 0.089 $\pm$ .00 & 0.355 $\pm$ .00 & 0.257 $\pm$ .005\\ 
			& CotGAN &  0.467 $\pm$ .003  & 0.249 $\pm$ .001 & 0.10 $\pm$ .00 &  0.795 $\pm$ .00 & \textbf{0.984} $\pm$ .00 & 0.852 $\pm$ .00 & 0.253 $\pm$ .001\\ 
			& C-RNN-GAN  &  0.5 $\pm$ .00  & 0.649  $\pm$ .001 & 0.53 $\pm$ .00 & 0.00 $\pm$ .00 & 0.00 $\pm$ .00 & 0.00 $\pm$ .00 & 0.651 $\pm$ .001 \\
			Sine & EBGAN & 0.499 $\pm$ .001  &0.260 $\pm$ .001 & 0.32 $\pm$ .00 & 0.901 $\pm$ .00 & 0.00 $\pm$ .00 & 0.322 $\pm$ .00 & 0.261 $\pm$ .001\\ 
			& WaveGAN  & 0.500 $\pm$ .000 & 0.353 $\pm$ .001& 0.414 $\pm$ .00 & 0.00 $\pm$ .00 & 0.00 $\pm$ .00 & 0.000 $\pm$ .00 & 0.351 $\pm$ .001\\
			& QuantGAN  & 0.469 $\pm$ .013 & 0.249 $\pm$ .001 & 0.253 $\pm$ .00 &\textbf{ 0.992} $\pm$ .00 & 0.384 $\pm$ .00 & 0.823 $\pm$ .00 & 0.253 $\pm$ .001\\
			& GT-GAN  & 0.465  $\pm$ .001 & 0.246 $\pm$ .001 & 0.048 $\pm$ .00 & 0.684 $\pm$ .00 &  0.954 $\pm$ .00 & 0.737 $\pm$ .00 & 0.253 $\pm$ .001 \\
			& TransFusion (ours)  & \textbf{0.097} $\pm$ .042 & \textbf{0.243} $\pm$ .001 & \textbf{0.02} $\pm$ .00 & \textbf{0.992} $\pm$ .00 &  0.974 $\pm$ .00 & \textbf{0.963} $\pm$ .00 & \textbf{0.245} $\pm$ .001\\ \midrule
			& TimeGAN  &  0.494 $\pm$ .001 & 0.062 $\pm$ .001 & 0.11 $\pm$ .00 & 0.994 $\pm$ .00 & 0.649 $\pm$ .00 & 0.073 $\pm$ .00 & 0.063 $\pm$ .001\\ 
			& CotGAN &   0.494 $\pm$ .001 &0.066 $\pm$ .001  & \textbf{0.010} $\pm$ .00 &  0.827 $\pm$ .00 & 0.837 $\pm$ .00 & 0.295 $\pm$ .00 & 0.067 $\pm$ .001\\ 
			& C-RNN-GAN & \textbf{0.19}  $\pm$ .03 & 0.068 $\pm$ .001 & 0.05 $\pm$ .00 & 0.899 $\pm$ .00 & 0.963 $\pm$ .00 & 0.605 $\pm$ .00 & 0.069 $\pm$ .001 \\ 
			Stock & EBGAN & 0.5  $\pm$ .00  & 0.495 $\pm$ .001& 0.66 $\pm$ .00 & 0.487 $\pm$ .00 & 0.00 $\pm$ .00 & 0.011 $\pm$ .00 & 0.496 $\pm$ .001 \\
			& WaveGAN  & 0.496 $\pm$ .007 & 0.064 $\pm$ .000& 0.272 $\pm$ .00 & \textbf{1.000} $\pm$ .00 & 0.000 $\pm$ .00 & 0.010 $\pm$ .00 & 0.064 $\pm$ .001\\
			& QuantGAN  & 0.497 $\pm$ .003 & 0.062 $\pm$ .000& 0.824 $\pm$ .00 & 0.660 $\pm$ .00 & 0.826 $\pm$ .00 & 0.405 $\pm$ .00 & 0.063 $\pm$ .001 \\
			& GT-GAN  & 0.416  $\pm$ .026 & 0.071 $\pm$ .001 & 0.048 $\pm$ .00 & 0.684 $\pm$ .00 &  0.954 $\pm$ .00 & 0.737 $\pm$ .00 & 0.071$\pm$ .001 \\
			& TransFusion (ours)  & 0.498 $\pm$ .001 &\textbf{0.060}$\pm$ .001 & 0.018 $\pm$ .00 & 0.97 $\pm$ .00 &  \textbf{0.99} $\pm$ .00  &\textbf{ 0.93} $\pm$ .00 & \textbf{0.061} $\pm$ .001\\ \midrule
			~ & TimeGAN &  0.497 $\pm$ .001 & 0.002 $\pm$ .001 & 0.11 $\pm$ .00 &  0.916 $\pm$ .00 &  0.343 $\pm$ .00 & 0.278 $\pm$ .00 & 0.003 $\pm$ .001\\ 
			& CotGAN & 0.482 $\pm$  .017 & 0.006 $\pm$ .001 &  0.10 $\pm$ .00 &  0.850 $\pm$ .00 & 0.617 $\pm$ .00 & 0.687 $\pm$ .00 & 0.006 $\pm$ .001 \\ 
			& C-RNN-GAN &  0.5 $\pm$  0.00 & 0.061 $\pm$ .001 & 0.344 $\pm$ .00 & \textbf{1.00} $\pm$ .00 & 0.00 $\pm$ .00 & 0.001 $\pm$ .00 & 0.065 $\pm$ .001\\ 
			Air & EBGAN &  0.5 $\pm$ .00 & 0.872 $\pm$  .106 & 0.423 $\pm$ .00 & 0.00 $\pm$ .00 & 0.00 $\pm$ .001 & 0.00 $\pm$ .00 & 0.813 $\pm$ .001\\
			& WaveGAN  & 0.439 $\pm$ .034 & 0.009 $\pm$ .001& 0.595 $\pm$ .00 & 0.942 $\pm$ .00 & 0.586 $\pm$ .00 & 0.750 $\pm$ .00 & 0.010 $\pm$ .001 \\
			& QuantGAN  & 0.464 $\pm$ .030 & 0.002 $\pm$ .001& 0.555 $\pm$ .00 & 0.983 $\pm$ .00 & 0.506 $\pm$ .00 & 0.749 $\pm$ .00 & \textbf{0.002} $\pm$ .001\\
			& GT-GAN  &  0.491 $\pm$ .005 & 0.003 $\pm$ .001 & 0.065  $\pm$ .00 & 0.687 $\pm$ .00 &  0.938 $\pm$ .00 & 0.824 $\pm$ .00 & 0.003 $\pm$ .001\\
			& TransFusion (ours)  & \textbf{0.148} $\pm$ .029 & \textbf{0.001} $\pm$ .001& \textbf{0.027} $\pm$ .00 & 0.926 $\pm$ .00 & \textbf{0.956} $\pm$ .00 & \textbf{0.944} $\pm$ .00 & \textbf{0.002} $\pm$ .001\\ \midrule
			~ & TimeGAN  &  0.490 $\pm$ .001 & 0.015 $\pm$ .001 & 0.176 $\pm$ .00 &  0.816 $\pm$ .00 &  0.213 $\pm$ .00 & 0.076 $\pm$ .00 & 0.015 $\pm$ .001\\ 
			& CotGAN &  0.497 $\pm$ .002 & 0.066 $\pm$ .001 & 0.183 $\pm$ .00 &  0.968 $\pm$ .00 & 0.374 $\pm$ .00 & 0.28 $\pm$ .00 & 0.067 $\pm$ .001\\ 
			& C-RNN-GAN  & 0.5 $\pm$ .00 & 0.264 $\pm$ .001 & 0.170 $\pm$ .34 & 0.00 $\pm$ .00 &  0.00 $\pm$ .00 & 0.00 $\pm$ .00 & 0.215 $\pm$ .001 \\ 
			Energy & EBGAN  & 0.5 $\pm$ 0.00 &0.971 $\pm$ .001 & 0.49 $\pm$ .00 &  0.00 $\pm$ .00 &  0.00 $\pm$ .00 & 0.00 $\pm$ .00 & 0.971 $\pm$ .001 \\
			& WaveGAN  & 0.496 $\pm$ .010 & 0.012 $\pm$ .000& 0.211 $\pm$ .00 & \textbf{1.000} $\pm$ .00 & 0.00 $\pm$ .00 & 0.014 $\pm$ .00 & \textbf{0.012 }$\pm$ .001 \\
			& QuantGAN  & 0.498 $\pm$ .002 & 0.012 $\pm$ .000& 0.826 $\pm$ .00 & 0.793 $\pm$ .00 & 0.701 $\pm$ .00 & 0.373 $\pm$ .00 & \textbf{0.012} $\pm$ .001 \\
			& GT-GAN  & 0.423 $\pm$ .030 & 0.012 $\pm$ .001& 0.158 $\pm$ .00 & 0.820 $\pm$ .00 & 0.26 $\pm$ .00 & 0.391 $\pm$ .00 & \textbf{0.012} $\pm$ .001 \\
			& TransFusion (ours)  & \textbf{0.332} $\pm$ .019 & \textbf{0.011} $\pm$ .001 & \textbf{0.016} $\pm$ .00 & 0.983 $\pm$ .00 & \textbf{0.876} $\pm$ .00 & \textbf{0.847} $\pm$ .00 & \textbf{0.012}$\pm$ .001\\ \bottomrule
		\end{tabular}
	}
	\label{tab:evaluation-table1}
	
\end{sidewaystable*}

\begin{sidewaystable}[]
	\caption{Resutls on Different Time-Series Datasets, Sequence Length: 384, we report the mean and standard deviation (bold indicates best result, $\uparrow$ indicates higher as better, $\downarrow$ indicates lower as better)}
	\centering
	{\small
		\begin{tabular}{lcccccccc}\toprule
			& \multicolumn{7}{c}{\textbf{Evaluation Metrics}} 
			\\\cmidrule(lr){3-9}
			\textbf{Dataset} & \textbf{Model Name} & LDS & LPS & JSD & $\alpha$- & $\beta$- & Coverage & + 5 Steps\\ 
			& &  & & & precision & recall & & Ahead\\ 
			& & ($\downarrow$) & ($\downarrow$) & ($\downarrow$) & ($\uparrow$)& ($\uparrow$)& ($\uparrow$) & ($\downarrow$)\\ \midrule
			& GT-GAN  & 0.497 $\pm$ .003 & 0.313 $\pm$ .001& 0.189 $\pm$ .00 & 0.978 $\pm$ .00 & 0.016 $\pm$ .00 & 0.162 $\pm$ .00 & 0.316 $\pm$ .001\\
			Sine & CotGAN  & 0.370 $\pm$ .075 & 0.307 $\pm$ .000& 0.465 $\pm$ .00 & 0.904 $\pm$ .00 & 0.984 $\pm$ .00 & 0.926 $\pm$ .00 & 0.310 $\pm$ .001 \\
			& TransFusion (ours)  & \textbf{0.075} $\pm$ .032 & \textbf{0.306} $\pm$ .001 & \textbf{0.006} $\pm$ .00 & \textbf{0.99} $\pm$ .00 &  0.99 $\pm$ .00 & \textbf{0.96} $\pm$ .00 &\textbf{ 0.301} $\pm$ .001\\
			\midrule
			& GT-GAN  &\textbf{ 0.441} $\pm$ .022 & 0.112 $\pm$ .000& 0.091 $\pm$ .00 & 0.961 $\pm$ .00 & 0.913 $\pm$ .00 & 0.556 $\pm$ .00 & 0.112 $\pm$ .001\\
			Stock   & CotGAN  & 0.445 $\pm$ .148 & 0.087 $\pm$ .000& 0.804 $\pm$ .00 & 0.840 $\pm$ .00 & 0.972 $\pm$ .00 & 0.870 $\pm$ .00 & 0.087 $\pm$ .001\\
			& TransFusion (ours)  & 0.483 $\pm$ .001 &\textbf{0.060}$\pm$ .001 & \textbf{0.018} $\pm$ .00 & \textbf{0.984} $\pm$ .00 &  \textbf{0.991} $\pm$ .00  &\textbf{ 0.984} $\pm$ .00 &\textbf{ 0.061} $\pm$ .001\\
			\midrule
			
			& GT-GAN  & 0.495 $\pm$ .004 & 0.002 $\pm$ .000& 0.182 $\pm$ .00 & \textbf{1.000} $\pm$ .00 & 0.888 $\pm$ .00 & 0.190 $\pm$ .00 & 0.003 $\pm$ .001\\
			Air & CotGAN  & 0.481 $\pm$ .030 & 0.006 $\pm$ .000& 0.780 $\pm$ .00 & 0.980 $\pm$ .00 & 0.304 $\pm$ .00 & 0.920 $\pm$ .00 & 0.005 $\pm$ .001\\
			& TransFusion (ours)  &\textbf{ 0.162} $\pm$ .029 & \textbf{0.001} $\pm$ .001& \textbf{0.027} $\pm$ .00 & 0.951 $\pm$ .00 & \textbf{0.956} $\pm$ .00 & \textbf{0.944} $\pm$ .00 & \textbf{0.002} $\pm$ .001\\
			
			\midrule
			
			& GT-GAN  & 0.434 $\pm$ .041 & 0.012 $\pm$ .000& 0.074 $\pm$ .00 & 0.586 $\pm$ .00 & 0.334 $\pm$ .00 & 0.480 $\pm$ .00 & 0.012 $\pm$ .001\\
			Energy & CotGAN  & 0.472 $\pm$ .024 & 0.012 $\pm$ .000 & 0.529 $\pm$ .00 & \textbf{1.000} $\pm$ .00 & 0.000 $\pm$ .00 & 0.096 $\pm$ .00 & 0.012 $\pm$ .001\\
			& TransFusion (ours)  & \textbf{0.400} $\pm$ .019 & \textbf{0.011} $\pm$ .001 & \textbf{0.012} $\pm$ .00 & 0.998 $\pm$ .00 & \textbf{0.644} $\pm$ .00 & \textbf{0.850} $\pm$ .00 & \textbf{0.011}$\pm$ .001\\
			
			
			\bottomrule
		\end{tabular}
	}
	\label{tab:evaluation-table2}
\end{sidewaystable}


\begin{sidewaystable}[]
	\caption{Ablation Study: Sequence Length: 100, we report the mean and standard deviation (bold indicates best result, $\uparrow$ indicates higher as better, $\downarrow$ indicates lower as better)}
	\centering
	{\small
		\begin{tabular}{lcccccccc}\toprule
			& \multicolumn{7}{c}{\textbf{Evaluation Metrics}} 
			\\\cmidrule(lr){3-9}
			\textbf{Dataset} & \textbf{Model Name} & LDS & LPS & JSD & $\alpha$- & $\beta$- & Coverage & + 5 Steps\\ 
			& &  & & & precision & recall & & Ahead\\ 
			& & ($\downarrow$) & ($\downarrow$) & ($\downarrow$) & ($\uparrow$)& ($\uparrow$)& ($\uparrow$) & ($\downarrow$)\\ \midrule
			
			& TransGAN  & 0.500 $\pm$ .000 & 0.352 $\pm$ .000& 0.392 $\pm$ .00 & 0.000 $\pm$ .00 & 0.000 $\pm$ .00 & 0.000 $\pm$ .00 & 0.349 $\pm$ .001\\
			Sine & Diffusion-GRU & 0.498 $\pm$ .002 & 0.252 $\pm$ .000& 0.106 $\pm$ .00 & 0.946 $\pm$ .00 & 0.408 $\pm$ .00 & 0.703 $\pm$ .00 & 0.260 $\pm$ .001\\
			& TransFusion (ours)  & \textbf{0.097} $\pm$ .042 & \textbf{0.243} $\pm$ .001 & \textbf{0.02} $\pm$ .00 & \textbf{0.992} $\pm$ .00 &  \textbf{0.974} $\pm$ .00 & \textbf{0.963} $\pm$ .00 & \textbf{0.245} $\pm$ .001\\ \midrule
			
			& TransGAN  & 0.500 $\pm$ .000 & 0.905 $\pm$ .011& 0.630 $\pm$ .00 & 0.000 $\pm$ .00 & 0.000 $\pm$ .00 & 0.000 $\pm$ .00 & 0.862  $\pm$ .001\\
			Stock & Diffusion-GRU  & 0.500 $\pm$ .000 & 0.066 $\pm$ .000& 0.273 $\pm$ .00 & 0.315 $\pm$ .00 & 0.744 $\pm$ .00 & 0.166 $\pm$ .00 & 0.067 $\pm$ .001\\
			& TransFusion (ours)  & \textbf{0.498} $\pm$ .001 &\textbf{0.060}$\pm$ .001 & \textbf{0.018} $\pm$ .00 & \textbf{0.97} $\pm$ .00 &  \textbf{0.99} $\pm$ .00  &\textbf{ 0.93} $\pm$ .00 & \textbf{0.061} $\pm$ .001\\ \midrule
			
			& TransGAN  & 0.500 $\pm$ .000 & 0.065 $\pm$ .001& 0.532 $\pm$ .00 & 0.000 $\pm$ .00 & 0.000 $\pm$ .00 & 0.000 $\pm$ .00 & 0.080 $\pm$.001\\
			Air & Diffusion-GRU  & 0.500 $\pm$ .000 & 0.051 $\pm$ .005& 0.230 $\pm$ .00 & 0.001 $\pm$ .00 & 0.049 $\pm$ .00 & 0.001 $\pm$ .00 &  0.057 $\pm$ .001 \\
			& TransFusion (ours)  &\textbf{ 0.148} $\pm$ .029 &\textbf{ 0.001} $\pm$ .001& \textbf{0.027} $\pm$ .00 & \textbf{0.926 }$\pm$ .00 & \textbf{0.956} $\pm$ .00 & \textbf{0.944} $\pm$ .00 & \textbf{0.002} $\pm$ .001\\ \midrule
			
			& TransGAN  & 0.500 $\pm$ .000 & 0.971 $\pm$ .000& 0.692 $\pm$ .00 & 0.000 $\pm$ .00 & 0.000 $\pm$ .00 & 0.000 $\pm$ .00 & 0.970 $\pm$ .001\\
			Energy & Diffusion-GRU  & 0.500 $\pm$ .000 & 0.097 $\pm$ .007& 0.421 $\pm$ .00 & 0.000 $\pm$ .00 & 0.000 $\pm$ .00 & 0.000 $\pm$ .00 & 0.092 $\pm$ .001 \\
			& TransFusion (ours)  & \textbf{0.332} $\pm$ .019 & \textbf{0.011} $\pm$ .001 & \textbf{0.016} $\pm$ .00 & \textbf{0.983} $\pm$ .00 & \textbf{0.876} $\pm$ .00 & \textbf{0.847} $\pm$ .00 & \textbf{0.012}$\pm$ .001\\
			\bottomrule
		\end{tabular}
	}
	
	\label{tab:ablation-table1}
\end{sidewaystable}

\subsection{Empirical Evaluation}

An ideal generative model should generate samples that are statistically close to the original data (fidelity) and diverse enough to cover the whole area of the original data (diversity), and the model should not fall into mode dropping (coverage). We provide multiple assessments of fidelity (LDS, JSD, $\alpha$-precision, PCA plots, t-SNE plots) and diversity ($\beta$-recall, PCA plots, t-SNE plots) and also show if the generative models are suffering from the mode-collapse problem or not (coverage). We also show the predictive characteristicness of the synthetic data by using LPS and +5 Steps Ahead score. 

In our experiments, we use both high dimensional and long-sequenced data (Air Quality, Energy Consumption). Table \ref{tab:evaluation-table1} indicates the results of our experiment for sequence length 100. We run the evaluation metrics ten times and report the mean and standard deviation in the table. Overall, TransFusion performs better than all the state-of-the-art generative models. We achieve a significantly higher score in every metric. Although some of the other methods get a high score in some metrics, if we consider all the aspects of fidelity, diversity, and coverage, we observe that TransFusion outperforms them all. The combination of diffsuion model and Transformers make it possible to generate high-dimensional and long-sequenced data. Whereas, Generative Adversarial Networks based architecture provide limited sample variety due to the mode-collapse problem, also as they use CNN, RNN-based architecture, they fail to generate long-sequenced data. 

From Table \ref{tab:evaluation-table1}, we can observe our evaluation metrics, LDS and LPS reflect the results with other metrics. Transfusion achieve a 22\% higher score than the GT-GAN (most recent time-series generative model) on the Long-Sequence Discriminative Score for the energy dataset. Also, from the coverage metric, we see that, except TransFusion, all the models suffer mode-collapse when the data is high dimensional (energy dataset). So, these state-of-the-art methods can not keep up with the long-sequence high-dimensional data. On top of these, the synthetic data generated by TransFusion achieve the best score on both LPS and +5 steps ahead prediction tasks. Therefore, synthetic data generated by TransFusion can be used in the forecasting tasks.

Furthermore, we also stretch the sequence length of the datasets to 384 to observe the robustness of our model and compare the result with GT-GAN and CotGAN (two recent models). Table \ref{tab:evaluation-table2} shows the outcome. We see that both GT-GAN and CotGAN can not keep up with the long-sequence data, and suffer the mode-collapse problem.

Besides empirical evaluation, training time is another factor to consider. TransFusion is able to generate high-quality samples by only training for 5 hours whereas GT-GAN takes nearly 28 hours to produce their result. All the experiments were run on an NVIDIA A100 GPU with 40GB of memory.

\subsection{Ablation Study}

The combination of the diffusion model and transformers architecture allows us to generate long-sequenced, high-quality samples, as evidenced by the ablation study. For this, we train a transformers-based Generative Adversarial Network (TransGAN), where the transformer's encoder serves as both generator and discriminator. We also train a diffusion model without transformers. For the diffusion model's backward process, we use the Gated Recurrent Unit (GRU). Table \ref{tab:ablation-table1} shows the analysis of the experiment. We use sequence length 100 for the ablation study. We can see both TransGAN and Diffusion-GRU is unable to keep up with the TransFusion.


\section{Limitations and Future Work}

While diffusion-based generative models are fast in terms of training compared with other generative models such as GANs, sampling from learned distributions takes longer. But, on the other hand, it learns the data distribution well and is capable of generating high-quality data, and also overcomes the mode-collapse problem. Variational AutoEncoder (VAE) can sample faster and avoid mode-collapse problem but is incapable of generating high-quality samples. GANs can generate high-quality samples faster but are prone to mode-collapse.

In future work, beside generating high-quality, long-sequenced time-series, we will try to generate fair synthetic time-series data.


\section{Conclusion}
\label{sec:conclusion}


In this study, we present a diffusion and transformers-based framework, \textbf{TransFusion}, for generating high-quality, long-sequence time-series data. Generating long-sequence time-series data is important because of its numerous applications. Long sequence data can capture more context and pattern of the data better than shorter sequences. In the past, researchers used, Generative Adversarial Network-based generative models to generate time-series data, but GAN is well known for falling into mode-collapse problems, and usage of standalone Recurrent Neural Network- and Convolutional Neural Network-based architectures made it difficult to generate long-sequence data. Our framework, with the combination of a transformers architecture and diffusion model, solve both mode collapse problems and capture longer time dependencies. We also implement two new evaluation metrics for time-series synthetic data. We evaluate our framework with various evaluation metrics and show it outperforms state-of-the-art architectures. And to the best of our knowledge, our study is the first where time-series data was successfully generated with a sequence length of 384.  We believe this framework can generate even longer time-series data given adequate GPU memory. This framework can be used in different domains to generate synthetic time-series data to better understand the data context and find patterns in the data.

\begin{appendices}
	
	\section{Dataset Preprocessing}
	\label{ap:dataset}
	
	Before proceeding with the experiment, we normalize the datasets in a way that the range of the values is between [0,1]. We follow the same procedure of TimeGAN \cite{yoon2019time} for normalizing the datasets. %The stock, air quality, and energy datasets are available online.
	
%	\begin{itemize}
%		\item Google Stock Data: Link\footnote{\url{https://finance.yahoo.com/quote/GOOG?p=GOOG&.tsrc=fin-srch}}
%		\item Air Quality \cite{de2008field}: Link\footnote{\url{https://archive.ics.uci.edu/ml/datasets/Air+quality}}
%		\item Energy \cite{candanedo2017data}: Link\footnote{\url{https://archive.ics.uci.edu/ml/datasets/Appliances+energy+prediction}}
%	\end{itemize}
%	
	\section{Hyperparameters}
	\label{ap:hyper}
	
	We use pytorch \cite{paszke2019pytorch} to implement TransFusion. We take a hidden dimension of $256$, a batch size of $256$, attention head is $8$ and $6$  transformer encoder layers. We use the $Adam$ optimizer with a learning rate of $1e-4$. We train TransFusion for $5000$ epochs.
	
	We use publicly available source code to implement the benchmarks. We use the same training setups and hyperparameters as the respective original papers.
	
	\begin{itemize}
		\item C-RNN-GAN \cite{mogren2016c}: \url{https://github.com/olofmogren/c-rnn-gan}
		\item TimeGAN \cite{yoon2019time}: \url{https://github.com/jsyoon0823/TimeGAN}
		\item EBGAN \cite{zhao2016energy}: \url{https://github.com/buriburisuri/ebgan}
		\item CoTGAN \cite{xu2020cot}: \url{https://github.com/tianlinxu312/cot-gan}
		\item GT-GAN \cite{jeon2022gt}: \url{https://github.com/Jinsung-Jeon/GT-GAN}
		\item WaveGAN \cite{donahueadversarial}: \url{https://github.com/chrisdonahue/wavegan}
	\end{itemize}
	
\end{appendices}

\backmatter

\bmhead{Data Availability}

The air quality \cite{de2008field} data is available at \url{https://archive.ics.uci.edu/ml/datasets/Air+quality}, google stock data is available at \url{https://finance.yahoo.com/quote/GOOG?p=GOOG&.tsrc=fin-srch}, energy consumption \cite{candanedo2017data} data is available at \url{https://archive.ics.uci.edu/ml/datasets/Appliances+energy+prediction}.

\bmhead{Acknowledgments}

This work was funded by the Knut and Alice Wallenberg Foundation, the ELLIIT Excellence Center at Linköping-Lund for Information Technology, and TAILOR - an EU project with the aim to provide the scientific foundations for Trustworthy AI in Europe. The computations were enabled by the Berzelius resource provided by the Knut and Alice Wallenberg Foundation at the National Supercomputer Centre.


\section*{Declarations}

\bmhead{Conflict of Interest}

The authors have no conflicts of interest to declare that are relevant to the content of this article.


%%===========================================================================================%%
%% If you are submitting to one of the Nature Portfolio journals, using the eJP submission   %%
%% system, please include the references within the manuscript file itself. You may do this  %%
%% by copying the reference list from your .bbl file, paste it into the main manuscript .tex %%
%% file, and delete the associated \verb+\bibliography+ commands.                            %%
%%===========================================================================================%%



\bibliography{sn-bibliography}% common bib file
%% if required, the content of .bbl file can be included here once bbl is generated
%%\input sn-article.bbl


\end{document}
