% Generated by IEEEtran.bst, version: 1.14 (2015/08/26)
\begin{thebibliography}{10}
\providecommand{\url}[1]{#1}
\csname url@samestyle\endcsname
\providecommand{\newblock}{\relax}
\providecommand{\bibinfo}[2]{#2}
\providecommand{\BIBentrySTDinterwordspacing}{\spaceskip=0pt\relax}
\providecommand{\BIBentryALTinterwordstretchfactor}{4}
\providecommand{\BIBentryALTinterwordspacing}{\spaceskip=\fontdimen2\font plus
\BIBentryALTinterwordstretchfactor\fontdimen3\font minus
  \fontdimen4\font\relax}
\providecommand{\BIBforeignlanguage}[2]{{%
\expandafter\ifx\csname l@#1\endcsname\relax
\typeout{** WARNING: IEEEtran.bst: No hyphenation pattern has been}%
\typeout{** loaded for the language `#1'. Using the pattern for}%
\typeout{** the default language instead.}%
\else
\language=\csname l@#1\endcsname
\fi
#2}}
\providecommand{\BIBdecl}{\relax}
\BIBdecl

\bibitem{DBLP:journals/corr/abs-2205-01068}
\BIBentryALTinterwordspacing
S.~Zhang, S.~Roller, N.~Goyal, M.~Artetxe, M.~Chen, S.~Chen, C.~Dewan, M.~T.
  Diab, X.~Li, X.~V. Lin, T.~Mihaylov, M.~Ott, S.~Shleifer, K.~Shuster,
  D.~Simig, P.~S. Koura, A.~Sridhar, T.~Wang, and L.~Zettlemoyer, ``{OPT:} open
  pre-trained transformer language models,'' \emph{CoRR}, vol. abs/2205.01068,
  2022. [Online]. Available: \url{https://doi.org/10.48550/arXiv.2205.01068}
\BIBentrySTDinterwordspacing

\bibitem{DBLP:journals/corr/abs-2210-11416}
\BIBentryALTinterwordspacing
H.~W. Chung, L.~Hou, S.~Longpre, B.~Zoph, Y.~Tay, W.~Fedus, E.~Li, X.~Wang,
  M.~Dehghani, S.~Brahma, A.~Webson, S.~S. Gu, Z.~Dai, M.~Suzgun, X.~Chen,
  A.~Chowdhery, S.~Narang, G.~Mishra, A.~Yu, V.~Y. Zhao, Y.~Huang, A.~M. Dai,
  H.~Yu, S.~Petrov, E.~H. Chi, J.~Dean, J.~Devlin, A.~Roberts, D.~Zhou, Q.~V.
  Le, and J.~Wei, ``Scaling instruction-finetuned language models,''
  \emph{CoRR}, vol. abs/2210.11416, 2022. [Online]. Available:
  \url{https://doi.org/10.48550/arXiv.2210.11416}
\BIBentrySTDinterwordspacing

\bibitem{tan2021co}
C.~Tan, J.~Xia, L.~Wu, and S.~Z. Li, ``Co-learning: Learning from noisy labels
  with self-supervision,'' in \emph{Proceedings of the 29th ACM International
  Conference on Multimedia}, 2021, pp. 1405--1413.

\bibitem{DBLP:journals/corr/abs-2302-13971}
\BIBentryALTinterwordspacing
H.~Touvron, T.~Lavril, G.~Izacard, X.~Martinet, M.~Lachaux, T.~Lacroix,
  B.~Rozi{\`{e}}re, N.~Goyal, E.~Hambro, F.~Azhar, A.~Rodriguez, A.~Joulin,
  E.~Grave, and G.~Lample, ``Llama: Open and efficient foundation language
  models,'' \emph{CoRR}, vol. abs/2302.13971, 2023. [Online]. Available:
  \url{https://doi.org/10.48550/arXiv.2302.13971}
\BIBentrySTDinterwordspacing

\bibitem{DBLP:conf/nips/2022}
\BIBentryALTinterwordspacing
S.~Koyejo, S.~Mohamed, A.~Agarwal, D.~Belgrave, K.~Cho, and A.~Oh, Eds.,
  \emph{Advances in Neural Information Processing Systems 35: Annual Conference
  on Neural Information Processing Systems 2022, NeurIPS 2022, New Orleans, LA,
  USA, November 28 - December 9, 2022}, 2022. [Online]. Available:
  \url{https://papers.nips.cc/paper_files/paper/2022}
\BIBentrySTDinterwordspacing

\bibitem{tan2022hyperspherical}
C.~Tan, Z.~Gao, L.~Wu, S.~Li, and S.~Z. Li, ``Hyperspherical consistency
  regularization,'' in \emph{Proceedings of the IEEE/CVF Conference on Computer
  Vision and Pattern Recognition}, 2022, pp. 7244--7255.

\bibitem{DBLP:journals/corr/abs-2201-08239}
\BIBentryALTinterwordspacing
R.~Thoppilan, D.~D. Freitas, J.~Hall, N.~Shazeer, A.~Kulshreshtha, H.~Cheng,
  A.~Jin, T.~Bos, L.~Baker, Y.~Du, Y.~Li, H.~Lee, H.~S. Zheng, A.~Ghafouri,
  M.~Menegali, Y.~Huang, M.~Krikun, D.~Lepikhin, J.~Qin, D.~Chen, Y.~Xu,
  Z.~Chen, A.~Roberts, M.~Bosma, Y.~Zhou, C.~Chang, I.~Krivokon, W.~Rusch,
  M.~Pickett, K.~S. Meier{-}Hellstern, M.~R. Morris, T.~Doshi, R.~D. Santos,
  T.~Duke, J.~Soraker, B.~Zevenbergen, V.~Prabhakaran, M.~Diaz, B.~Hutchinson,
  K.~Olson, A.~Molina, E.~Hoffman{-}John, J.~Lee, L.~Aroyo, R.~Rajakumar,
  A.~Butryna, M.~Lamm, V.~Kuzmina, J.~Fenton, A.~Cohen, R.~Bernstein,
  R.~Kurzweil, B.~Aguera{-}Arcas, C.~Cui, M.~Croak, E.~H. Chi, and Q.~Le,
  ``Lamda: Language models for dialog applications,'' \emph{CoRR}, vol.
  abs/2201.08239, 2022. [Online]. Available:
  \url{https://arxiv.org/abs/2201.08239}
\BIBentrySTDinterwordspacing

\bibitem{DBLP:journals/corr/abs-2204-02311}
\BIBentryALTinterwordspacing
A.~Chowdhery, S.~Narang, J.~Devlin, M.~Bosma, G.~Mishra, A.~Roberts, P.~Barham,
  H.~W. Chung, C.~Sutton, S.~Gehrmann, P.~Schuh, K.~Shi, S.~Tsvyashchenko,
  J.~Maynez, A.~Rao, P.~Barnes, Y.~Tay, N.~Shazeer, V.~Prabhakaran, E.~Reif,
  N.~Du, B.~Hutchinson, R.~Pope, J.~Bradbury, J.~Austin, M.~Isard,
  G.~Gur{-}Ari, P.~Yin, T.~Duke, A.~Levskaya, S.~Ghemawat, S.~Dev,
  H.~Michalewski, X.~Garcia, V.~Misra, K.~Robinson, L.~Fedus, D.~Zhou,
  D.~Ippolito, D.~Luan, H.~Lim, B.~Zoph, A.~Spiridonov, R.~Sepassi, D.~Dohan,
  S.~Agrawal, M.~Omernick, A.~M. Dai, T.~S. Pillai, M.~Pellat, A.~Lewkowycz,
  E.~Moreira, R.~Child, O.~Polozov, K.~Lee, Z.~Zhou, X.~Wang, B.~Saeta,
  M.~Diaz, O.~Firat, M.~Catasta, J.~Wei, K.~Meier{-}Hellstern, D.~Eck, J.~Dean,
  S.~Petrov, and N.~Fiedel, ``Palm: Scaling language modeling with pathways,''
  \emph{CoRR}, vol. abs/2204.02311, 2022. [Online]. Available:
  \url{https://doi.org/10.48550/arXiv.2204.02311}
\BIBentrySTDinterwordspacing

\bibitem{tan2022target}
C.~Tan, Z.~Gao, and S.~Z. Li, ``Target-aware molecular graph generation,''
  \emph{arXiv preprint arXiv:2202.04829}, 2022.

\bibitem{DBLP:conf/nips/LuMX0CZTCK22}
\BIBentryALTinterwordspacing
P.~Lu, S.~Mishra, T.~Xia, L.~Qiu, K.~Chang, S.~Zhu, O.~Tafjord, P.~Clark, and
  A.~Kalyan, ``Learn to explain: Multimodal reasoning via thought chains for
  science question answering,'' in \emph{NeurIPS}, 2022. [Online]. Available:
  \url{http://papers.nips.cc/paper_files/paper/2022/hash/11332b6b6cf4485b84afadb1352d3a9a-Abstract-Conference.html}
\BIBentrySTDinterwordspacing

\bibitem{DBLP:journals/corr/abs-2302-00923}
\BIBentryALTinterwordspacing
Z.~Zhang, A.~Zhang, M.~Li, H.~Zhao, G.~Karypis, and A.~Smola, ``Multimodal
  chain-of-thought reasoning in language models,'' \emph{CoRR}, vol.
  abs/2302.00923, 2023. [Online]. Available:
  \url{https://doi.org/10.48550/arXiv.2302.00923}
\BIBentrySTDinterwordspacing

\bibitem{DBLP:journals/corr/abs-2301-13379}
\BIBentryALTinterwordspacing
Q.~Lyu, S.~Havaldar, A.~Stein, L.~Zhang, D.~Rao, E.~Wong, M.~Apidianaki, and
  C.~Callison{-}Burch, ``Faithful chain-of-thought reasoning,'' \emph{CoRR},
  vol. abs/2301.13379, 2023. [Online]. Available:
  \url{https://doi.org/10.48550/arXiv.2301.13379}
\BIBentrySTDinterwordspacing

\bibitem{lin2014microsoft}
T.-Y. Lin, M.~Maire, S.~Belongie, J.~Hays, P.~Perona, D.~Ramanan,
  P.~Doll{\'a}r, and C.~L. Zitnick, ``Microsoft coco: Common objects in
  context,'' in \emph{Computer Vision--ECCV 2014: 13th European Conference,
  Zurich, Switzerland, September 6-12, 2014, Proceedings, Part V 13}.\hskip 1em
  plus 0.5em minus 0.4em\relax Springer, 2014, pp. 740--755.

\bibitem{gao2022simvp}
Z.~Gao, C.~Tan, L.~Wu, and S.~Z. Li, ``Simvp: Simpler yet better video
  prediction,'' in \emph{Proceedings of the IEEE/CVF Conference on Computer
  Vision and Pattern Recognition}, 2022, pp. 3170--3180.

\bibitem{tan2022simvp}
C.~Tan, Z.~Gao, S.~Li, and S.~Z. Li, ``Simvp: Towards simple yet powerful
  spatiotemporal predictive learning,'' \emph{arXiv preprint arXiv:2211.12509},
  2022.

\bibitem{cao2022survey}
H.~Cao, C.~Tan, Z.~Gao, G.~Chen, P.-A. Heng, and S.~Z. Li, ``A survey on
  generative diffusion model,'' \emph{arXiv preprint arXiv:2209.02646}, 2022.

\bibitem{liu2022decoupled}
Z.~Liu, S.~Li, G.~Wang, C.~Tan, L.~Wu, and S.~Z. Li, ``Decoupled mixup for
  data-efficient learning,'' \emph{arXiv preprint arXiv:2203.10761}, 2022.

\bibitem{tan2022temporal}
C.~Tan, Z.~Gao, S.~Li, Y.~Xu, and S.~Z. Li, ``Temporal attention unit: Towards
  efficient spatiotemporal predictive learning,'' \emph{arXiv preprint
  arXiv:2206.12126}, 2022.

\bibitem{li2022efficient}
S.~Li, Z.~Wang, Z.~Liu, C.~Tan, H.~Lin, D.~Wu, Z.~Chen, J.~Zheng, and S.~Z. Li,
  ``Efficient multi-order gated aggregation network,'' \emph{arXiv preprint
  arXiv:2211.03295}, 2022.

\bibitem{zheng2023cvt}
J.~Zheng, Y.~Wang, C.~Tan, S.~Li, G.~Wang, J.~Xia, Y.~Chen, and S.~Z. Li,
  ``Cvt-slr: Contrastive visual-textual transformation for sign language
  recognition with variational alignment,'' in \emph{Proceedings of the
  IEEE/CVF Conference on Computer Vision and Pattern Recognition}, 2023, pp.
  23\,141--23\,150.

\bibitem{DBLP:conf/iccv/AntolALMBZP15}
\BIBentryALTinterwordspacing
S.~Antol, A.~Agrawal, J.~Lu, M.~Mitchell, D.~Batra, C.~L. Zitnick, and
  D.~Parikh, ``{VQA:} visual question answering,'' in \emph{2015 {IEEE}
  International Conference on Computer Vision, {ICCV} 2015, Santiago, Chile,
  December 7-13, 2015}.\hskip 1em plus 0.5em minus 0.4em\relax {IEEE} Computer
  Society, 2015, pp. 2425--2433. [Online]. Available:
  \url{https://doi.org/10.1109/ICCV.2015.279}
\BIBentrySTDinterwordspacing

\bibitem{WU201721}
\BIBentryALTinterwordspacing
Q.~Wu, D.~Teney, P.~Wang, C.~Shen, A.~Dick, and A.~{van den Hengel}, ``Visual
  question answering: A survey of methods and datasets,'' \emph{Computer Vision
  and Image Understanding}, vol. 163, pp. 21--40, 2017, language in Vision.
  [Online]. Available:
  \url{https://www.sciencedirect.com/science/article/pii/S1077314217300772}
\BIBentrySTDinterwordspacing

\bibitem{10.1007/978-981-16-1092-9_7}
Y.~Srivastava, V.~Murali, S.~R. Dubey, and S.~Mukherjee, ``Visual question
  answering using deep learning: A survey and performance analysis,'' in
  \emph{Computer Vision and Image Processing}, S.~K. Singh, P.~Roy, B.~Raman,
  and P.~Nagabhushan, Eds.\hskip 1em plus 0.5em minus 0.4em\relax Singapore:
  Springer Singapore, 2021, pp. 75--86.

\bibitem{9422035}
Y.~Zou and Q.~Xie, ``A survey on vqa: Datasets and approaches,'' in \emph{2020
  2nd International Conference on Information Technology and Computer
  Application (ITCA)}, 2020, pp. 289--297.

\bibitem{10.1007/978-981-99-1354-1_1}
H.~Wang and H.~Du, ``Knowledge-enhanced medical visual question answering: A
  survey (invited talk summary),'' in \emph{Web and Big Data. APWeb-WAIM 2022
  International Workshops}, S.~Yang and S.~Islam, Eds.\hskip 1em plus 0.5em
  minus 0.4em\relax Singapore: Springer Nature Singapore, 2023, pp. 3--9.

\bibitem{DBLP:conf/icip/ChowdhuryNFS17}
\BIBentryALTinterwordspacing
I.~Chowdhury, K.~Nguyen, C.~Fookes, and S.~Sridharan, ``A cascaded long
  short-term memory {(LSTM)} driven generic visual question answering
  {(VQA)},'' in \emph{2017 {IEEE} International Conference on Image Processing,
  {ICIP} 2017, Beijing, China, September 17-20, 2017}.\hskip 1em plus 0.5em
  minus 0.4em\relax {IEEE}, 2017, pp. 1842--1846. [Online]. Available:
  \url{https://doi.org/10.1109/ICIP.2017.8296600}
\BIBentrySTDinterwordspacing

\bibitem{DBLP:conf/icip/HuangKJLJT18}
\BIBentryALTinterwordspacing
L.~Huang, K.~Kulkarni, A.~Jha, S.~Lohit, S.~Jayasuriya, and P.~K. Turaga,
  ``{CS-VQA:} visual question answering with compressively sensed images,'' in
  \emph{2018 {IEEE} International Conference on Image Processing, {ICIP} 2018,
  Athens, Greece, October 7-10, 2018}.\hskip 1em plus 0.5em minus 0.4em\relax
  {IEEE}, 2018, pp. 1283--1287. [Online]. Available:
  \url{https://doi.org/10.1109/ICIP.2018.8451445}
\BIBentrySTDinterwordspacing

\bibitem{DBLP:journals/ijcv/GoyalKASBP19}
\BIBentryALTinterwordspacing
Y.~Goyal, T.~Khot, A.~Agrawal, D.~Summers{-}Stay, D.~Batra, and D.~Parikh,
  ``Making the {V} in {VQA} matter: Elevating the role of image understanding
  in visual question answering,'' \emph{Int. J. Comput. Vis.}, vol. 127, no.~4,
  pp. 398--414, 2019. [Online]. Available:
  \url{https://doi.org/10.1007/s11263-018-1116-0}
\BIBentrySTDinterwordspacing

\bibitem{DBLP:conf/clef/ChenGL20}
\BIBentryALTinterwordspacing
G.~Chen, H.~Gong, and G.~Li, ``{HCP-MIC} at vqa-med 2020: Effective visual
  representation for medical visual question answering,'' in \emph{Working
  Notes of {CLEF} 2020 - Conference and Labs of the Evaluation Forum,
  Thessaloniki, Greece, September 22-25, 2020}, ser. {CEUR} Workshop
  Proceedings, L.~Cappellato, C.~Eickhoff, N.~Ferro, and A.~N{\'{e}}v{\'{e}}ol,
  Eds., vol. 2696.\hskip 1em plus 0.5em minus 0.4em\relax CEUR-WS.org, 2020.
  [Online]. Available: \url{https://ceur-ws.org/Vol-2696/paper_74.pdf}
\BIBentrySTDinterwordspacing

\bibitem{DBLP:conf/conll/SoodKSDB21}
\BIBentryALTinterwordspacing
E.~Sood, F.~K{\"{o}}gel, F.~Strohm, P.~Dhar, and A.~Bulling, ``{VQA-MHUG:} {A}
  gaze dataset to study multimodal neural attention in visual question
  answering,'' in \emph{Proceedings of the 25th Conference on Computational
  Natural Language Learning, CoNLL 2021, Online, November 10-11, 2021},
  A.~Bisazza and O.~Abend, Eds.\hskip 1em plus 0.5em minus 0.4em\relax
  Association for Computational Linguistics, 2021, pp. 27--43. [Online].
  Available: \url{https://doi.org/10.18653/v1/2021.conll-1.3}
\BIBentrySTDinterwordspacing

\bibitem{DBLP:conf/miccai/SeenivasanIKR22}
\BIBentryALTinterwordspacing
L.~Seenivasan, M.~Islam, A.~K. Krishna, and H.~Ren, ``Surgical-vqa: Visual
  question answering in surgical scenes using transformer,'' in \emph{Medical
  Image Computing and Computer Assisted Intervention - {MICCAI} 2022 - 25th
  International Conference, Singapore, September 18-22, 2022, Proceedings, Part
  {VII}}, ser. Lecture Notes in Computer Science, L.~Wang, Q.~Dou, P.~T.
  Fletcher, S.~Speidel, and S.~Li, Eds., vol. 13437.\hskip 1em plus 0.5em minus
  0.4em\relax Springer, 2022, pp. 33--43. [Online]. Available:
  \url{https://doi.org/10.1007/978-3-031-16449-1_4}
\BIBentrySTDinterwordspacing

\bibitem{DBLP:journals/frai/WellsB21}
\BIBentryALTinterwordspacing
L.~Wells and T.~Bednarz, ``Explainable {AI} and reinforcement learning - {A}
  systematic review of current approaches and trends,'' \emph{Frontiers Artif.
  Intell.}, vol.~4, p. 550030, 2021. [Online]. Available:
  \url{https://doi.org/10.3389/frai.2021.550030}
\BIBentrySTDinterwordspacing

\bibitem{DBLP:journals/jair/RasXGD22}
\BIBentryALTinterwordspacing
G.~Ras, N.~Xie, M.~van Gerven, and D.~Doran, ``Explainable deep learning: {A}
  field guide for the uninitiated,'' \emph{J. Artif. Intell. Res.}, vol.~73,
  pp. 329--396, 2022. [Online]. Available:
  \url{https://doi.org/10.1613/jair.1.13200}
\BIBentrySTDinterwordspacing

\bibitem{gao2023llamaadapterv2}
P.~Gao, J.~Han, R.~Zhang, Z.~Lin, S.~Geng, A.~Zhou, W.~Zhang, P.~Lu, C.~He,
  X.~Yue, H.~Li, and Y.~Qiao, ``Llama-adapter v2: Parameter-efficient visual
  instruction model,'' \emph{arXiv preprint arXiv:2304.15010}, 2023.

\bibitem{touvron2023llama}
H.~Touvron, T.~Lavril, G.~Izacard, X.~Martinet, M.-A. Lachaux, T.~Lacroix,
  B.~Rozi{\`e}re, N.~Goyal, E.~Hambro, F.~Azhar \emph{et~al.}, ``Llama: Open
  and efficient foundation language models,'' \emph{arXiv preprint
  arXiv:2302.13971}, 2023.

\bibitem{chen2015microsoft}
X.~Chen, H.~Fang, T.-Y. Lin, R.~Vedantam, S.~Gupta, P.~Doll{\'a}r, and C.~L.
  Zitnick, ``Microsoft coco captions: Data collection and evaluation server,''
  \emph{arXiv preprint arXiv:1504.00325}, 2015.

\bibitem{goyal2017making}
Y.~Goyal, T.~Khot, D.~Summers-Stay, D.~Batra, and D.~Parikh, ``Making the v in
  vqa matter: Elevating the role of image understanding in visual question
  answering,'' in \emph{Proceedings of the IEEE conference on computer vision
  and pattern recognition}, 2017, pp. 6904--6913.

\bibitem{zhu2023minigpt}
D.~Zhu, J.~Chen, X.~Shen, X.~Li, and M.~Elhoseiny, ``Minigpt-4: Enhancing
  vision-language understanding with advanced large language models,''
  \emph{arXiv preprint arXiv:2304.10592}, 2023.

\bibitem{DBLP:conf/nips/VaswaniSPUJGKP17}
\BIBentryALTinterwordspacing
A.~Vaswani, N.~Shazeer, N.~Parmar, J.~Uszkoreit, L.~Jones, A.~N. Gomez,
  L.~Kaiser, and I.~Polosukhin, ``Attention is all you need,'' in
  \emph{Advances in Neural Information Processing Systems 30: Annual Conference
  on Neural Information Processing Systems 2017, December 4-9, 2017, Long
  Beach, CA, {USA}}, I.~Guyon, U.~von Luxburg, S.~Bengio, H.~M. Wallach,
  R.~Fergus, S.~V.~N. Vishwanathan, and R.~Garnett, Eds., 2017, pp. 5998--6008.
  [Online]. Available:
  \url{https://proceedings.neurips.cc/paper/2017/hash/3f5ee243547dee91fbd053c1c4a845aa-Abstract.html}
\BIBentrySTDinterwordspacing

\bibitem{DBLP:conf/cvpr/Yu0CT019}
\BIBentryALTinterwordspacing
Z.~Yu, J.~Yu, Y.~Cui, D.~Tao, and Q.~Tian, ``Deep modular co-attention networks
  for visual question answering,'' in \emph{{IEEE} Conference on Computer
  Vision and Pattern Recognition, {CVPR} 2019, Long Beach, CA, USA, June 16-20,
  2019}.\hskip 1em plus 0.5em minus 0.4em\relax Computer Vision Foundation /
  {IEEE}, 2019, pp. 6281--6290. [Online]. Available:
  \url{http://openaccess.thecvf.com/content_CVPR_2019/html/Yu_Deep_Modular_Co-Attention_Networks_for_Visual_Question_Answering_CVPR_2019_paper.html}
\BIBentrySTDinterwordspacing

\bibitem{DBLP:conf/cvpr/00010BT0GZ18}
\BIBentryALTinterwordspacing
P.~Anderson, X.~He, C.~Buehler, D.~Teney, M.~Johnson, S.~Gould, and L.~Zhang,
  ``Bottom-up and top-down attention for image captioning and visual question
  answering,'' in \emph{2018 {IEEE} Conference on Computer Vision and Pattern
  Recognition, {CVPR} 2018, Salt Lake City, UT, USA, June 18-22, 2018}.\hskip
  1em plus 0.5em minus 0.4em\relax Computer Vision Foundation / {IEEE} Computer
  Society, 2018, pp. 6077--6086. [Online]. Available:
  \url{http://openaccess.thecvf.com/content_cvpr_2018/html/Anderson_Bottom-Up_and_Top-Down_CVPR_2018_paper.html}
\BIBentrySTDinterwordspacing

\bibitem{DBLP:journals/titb/YuPFCS23}
\BIBentryALTinterwordspacing
R.~Yu, C.~Pan, X.~Fei, M.~Chen, and D.~Shen, ``Multi-graph attention networks
  with bilinear convolution for diagnosis of schizophrenia,'' \emph{{IEEE} J.
  Biomed. Health Informatics}, vol.~27, no.~3, pp. 1443--1454, 2023. [Online].
  Available: \url{https://doi.org/10.1109/JBHI.2022.3229465}
\BIBentrySTDinterwordspacing

\bibitem{DBLP:conf/cvpr/GaoJYLHWL19}
\BIBentryALTinterwordspacing
P.~Gao, Z.~Jiang, H.~You, P.~Lu, S.~C.~H. Hoi, X.~Wang, and H.~Li, ``Dynamic
  fusion with intra- and inter-modality attention flow for visual question
  answering,'' in \emph{{IEEE} Conference on Computer Vision and Pattern
  Recognition, {CVPR} 2019, Long Beach, CA, USA, June 16-20, 2019}.\hskip 1em
  plus 0.5em minus 0.4em\relax Computer Vision Foundation / {IEEE}, 2019, pp.
  6639--6648. [Online]. Available:
  \url{http://openaccess.thecvf.com/content_CVPR_2019/html/Gao_Dynamic_Fusion_With_Intra-_and_Inter-Modality_Attention_Flow_for_Visual_CVPR_2019_paper.html}
\BIBentrySTDinterwordspacing

\bibitem{DBLP:conf/icml/KimSK21}
\BIBentryALTinterwordspacing
W.~Kim, B.~Son, and I.~Kim, ``Vilt: Vision-and-language transformer without
  convolution or region supervision,'' in \emph{Proceedings of the 38th
  International Conference on Machine Learning, {ICML} 2021, 18-24 July 2021,
  Virtual Event}, ser. Proceedings of Machine Learning Research, M.~Meila and
  T.~Zhang, Eds., vol. 139.\hskip 1em plus 0.5em minus 0.4em\relax {PMLR},
  2021, pp. 5583--5594. [Online]. Available:
  \url{http://proceedings.mlr.press/v139/kim21k.html}
\BIBentrySTDinterwordspacing

\bibitem{lu2021iconqa}
P.~Lu, L.~Qiu, J.~Chen, T.~Xia, Y.~Zhao, W.~Zhang, Z.~Yu, X.~Liang, and S.-C.
  Zhu, ``Iconqa: A new benchmark for abstract diagram understanding and visual
  language reasoning,'' in \emph{The 35th Conference on Neural Information
  Processing Systems (NeurIPS 2021) Track on Datasets and Benchmarks}, 2021.

\bibitem{li2019visualbert}
L.~H. Li, M.~Yatskar, D.~Yin, C.-J. Hsieh, and K.-W. Chang, ``Visualbert: A
  simple and performant baseline for vision and language,'' \emph{arXiv
  preprint arXiv:1908.03557}, 2019.

\bibitem{khashabi-etal-2020-unifiedqa}
\BIBentryALTinterwordspacing
D.~Khashabi, S.~Min, T.~Khot, A.~Sabharwal, O.~Tafjord, P.~Clark, and
  H.~Hajishirzi, ``{UNIFIEDQA}: Crossing format boundaries with a single {QA}
  system,'' in \emph{Findings of the Association for Computational Linguistics:
  EMNLP 2020}.\hskip 1em plus 0.5em minus 0.4em\relax Online: Association for
  Computational Linguistics, Nov. 2020, pp. 1896--1907. [Online]. Available:
  \url{https://aclanthology.org/2020.findings-emnlp.171}
\BIBentrySTDinterwordspacing

\bibitem{DBLP:journals/corr/abs-2304-08485}
\BIBentryALTinterwordspacing
H.~Liu, C.~Li, Q.~Wu, and Y.~J. Lee, ``Visual instruction tuning,''
  \emph{CoRR}, vol. abs/2304.08485, 2023. [Online]. Available:
  \url{https://doi.org/10.48550/arXiv.2304.08485}
\BIBentrySTDinterwordspacing

\end{thebibliography}
