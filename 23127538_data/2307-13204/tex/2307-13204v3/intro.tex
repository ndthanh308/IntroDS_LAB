\section{INTRODUCTION}
Tool manipulation is a fundamental skill for household robots. To achieve successful tool manipulation and accomplish specific goals, the robot must, in the first place, grasp the tool in a task-oriented manner, i.e., perform task-oriented grasping\cite{kokic2020learning, fang2020learning}. For instance, accurately gripping the handle of a knife to slice an apple into pieces or securely holding the tip of the blade of the knife during a handover. Considering the vast number of object classes and tasks in open-world operating environments like offices and kitchens, it is challenging to model the complex relationships between object classes, tasks, and grasps due to the diverse and dynamic nature of open-world environments. Practically, one can expect the robot to be trained on a limited set of examples and generalize the learned TOG skills to novel object classes and tasks beyond the training examples.

 % Attempting to collect all combinations of class, task, and grasp through brute force is nonetheless impractical.

To achieve such a goal, recent works have proposed incorporating semantic knowledge into TOG pipelines to enable robots to adapt to various situations. Semantic knowledge provides high-level abstractions of open-world environments and captures the underlying relationships between concepts. For instance, Song et al.\cite{song2010learning} construct a semantic knowledge base (KB) with a pre-defined set of concepts and constraints with Bayesian Networks. Recently, Murali et al.\cite{murali2021same} contribute the largest and the most diverse TOG dataset, named TaskGrasp dataset, and build a knowledge graph (KG) based on the concepts collected in the dataset. Although these methods have demonstrated their generalization abilities to concepts pre-defined within the KB, they still operate under the closed-world assumption and cannot handle novel concepts out of the KB. This limitation is critical as a household robot must deal with open-end object classes and tasks.

% Ard{\'o}n et al.\cite{ardon2019learning} and Antanas et al.\cite{antanas2019semantic} propose probabilistic logic approaches to build knowledge graphs (KGs) relating pre-defined semantic attributes. 

% Figure environment removed


% brown2020language,


The recent advancements in large language models (LLMs) \cite{chowdhery2022palm, thoppilan2022lamda} have brought about significant progresses in various robot tasks\cite{ahn2022can, ren2023leveraging, huang2022language, liang2022code}. These LLMs are trained with internet-scale text corpora. Thus, robots can seamlessly extract and harness open-end semantic knowledge from LLMs to plan actions in unseen scenarios. In this letter, we follow the same spirit and introduce \textbf{GraspGPT}, an LLM-based TOG framework. GraspGPT distinguishes itself from previous TOG methods by not being constrained to a closed-world concept set. Instead, it leverages the open-end semantic knowledge about object classes and tasks from an LLM to achieve zero-shot generalization to novel concepts out of the training set. Specifically, we focus on two types of concepts: object class and task. As is shown in Figure \ref{fig:concept} (a), when presented with a novel concept in a language instruction, GraspGPT first prompts an LLM to acquire a set of natural language description paragraphs of the concept. These description paragraphs connect the novel concept to its related concepts described during training, as depicted in Figure \ref{fig:concept} (b). Subsequently, the robot can generalize the learned TOG skills from known concepts to novel concepts out of the training set. Evaluation on the contributed TOG dataset named Language Augmented TaskGrasp (LA-TaskGrasp) dataset demonstrates that GraspGPT outperforms existing TOG methods under different held-out settings. We further deploy GraspGPT on a Kinova Gen3 robotic arm to validate its effectiveness in real-world robotic applications.

% Different from previous methods, LLMs free robots from pre-defined concept sets, helping them better generalizing to novel concepts.

% GraspGPT fuses the descriptions with other sensory inputs to output a set of task-oriented grasp poses.


% To further validate the effectiveness of GraspGPT in real-world robotic applications, we deploy the framework on a Franka Emika Panda robotic arm for performing task-oriented grasping on household objects based on user language instructions.

 % such as object point clouds, and language instructions (e.g., ``\textit{Grasp the knife to cut}"),

In summary, our contributions are two-fold:
\begin{itemize}
    \item We propose GraspGPT, an LLM-based TOG framework that leverages the open-end semantic knowledge from an LLM to achieve zero-shot generalization to novel concepts out of the training set.
    \item We present a pipeline to automatically generate language descriptions of concepts with an LLM and contribute a language augmented TOG dataset named LA-TaskGrasp dataset.
    % \item A physical system is built to enable a robotic arm to perform task-oriented grasping and manipulation on household objects based on user language instructions.
\end{itemize}

% \textcolor{blue}{The rest of this paper is organized as follows.} 































