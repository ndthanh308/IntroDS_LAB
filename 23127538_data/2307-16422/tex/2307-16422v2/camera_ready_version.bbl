\begin{thebibliography}{69}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Arjovsky et~al.(2017)Arjovsky, Chintala, and Bottou]{pmlr-v70-arjovsky17a}
Martin Arjovsky, Soumith Chintala, and L{\'e}on Bottou.
\newblock {W}asserstein {G}enerative {A}dversarial {N}etworks.
\newblock In \emph{Proceedings of the 34th International Conference on Machine Learning}, volume~70 of \emph{Proceedings of Machine Learning Research}, pages 214--223. PMLR, 2017.

\bibitem[Arora et~al.(2017)Arora, Ge, Liang, Ma, and Zhang]{Arora0LMZ17}
Sanjeev Arora, Rong Ge, Yingyu Liang, Tengyu Ma, and Yi~Zhang.
\newblock {G}eneralization and {E}quilibrium in {G}enerative {A}dversarial {N}ets ({GANs}).
\newblock In \emph{{ICML}, Sydney, NSW, Australia, 6-11 August 2017}, volume~70 of \emph{Proceedings of Machine Learning Research}, pages 224--232. {PMLR}, 2017.

\bibitem[Arora et~al.(2018)Arora, Risteski, and Zhang]{AroraRZ18}
Sanjeev Arora, Andrej Risteski, and Yi~Zhang.
\newblock Do {GAN}s {L}earn the {D}istribution? {S}ome {T}heory and {E}mpirics.
\newblock In \emph{{ICLR}, Vancouver, BC, Canada, April 30 - May 3, 2018}, 2018.

\bibitem[Bai et~al.(2018)Bai, Ma, and Risteski]{bai_ma_risteski_2019}
Yu~Bai, Tengyu Ma, and Andrej Risteski.
\newblock Approximability of {D}iscriminators {I}mplies {D}iversity in {GAN}s.
\newblock \emph{ArXiv}, abs/1806.10586, 2018.

\bibitem[Belomestny et~al.(2023)Belomestny, Moulines, Naumov, Puchkin, and Samsonov]{belomestny2023rates}
Denis Belomestny, Eric Moulines, Alexey Naumov, Nikita Puchkin, and Sergey Samsonov.
\newblock {R}ates of {C}onvergence for {D}ensity {E}stimation with {G}enerative {A}dversarial {N}etworks, 2023.

\bibitem[Biau et~al.(2020)Biau, Cadre, Sangnier, and Tanielian]{Biau}
G{\'e}rard Biau, Beno{\^i}t Cadre, Maxime Sangnier, and Ugo Tanielian.
\newblock {Some {T}heoretical {P}roperties of {GAN}s}.
\newblock \emph{The Annals of Statistics}, 48\penalty0 (3):\penalty0 1539 -- 1566, 2020.
\newblock \doi{10.1214/19-AOS1858}.

\bibitem[Biau et~al.(2021)Biau, Sangnier, and Tanielian]{BiauST21}
G{\'{e}}rard Biau, Maxime Sangnier, and Ugo Tanielian.
\newblock Some {T}heoretical {I}nsights into {W}asserstein {GAN}s.
\newblock \emph{J. Mach. Learn. Res.}, 22:\penalty0 119:1--119:45, 2021.

\bibitem[Block et~al.(2020)Block, Mroueh, and Rakhlin]{Block}
Adam Block, Youssef Mroueh, and Alexander Rakhlin.
\newblock Generative {M}odeling with {D}enoising {A}uto-{E}ncoders and {L}angevin {S}ampling.
\newblock \emph{CoRR}, abs/2002.00107, 2020.

\bibitem[Boissard and Gouic(2014)]{Boissard}
Emmanuel Boissard and Thibaut~Le Gouic.
\newblock {O}n the {M}ean {S}peed of {C}onvergence of {E}mpirical and {O}ccupation {M}easures in {W}asserstein {D}istance.
\newblock \emph{Annales de l'Institut Henri Poincaré, Probabilités et Statistiques}, 50\penalty0 (2):\penalty0 539 -- 563, 2014.

\bibitem[Bortoli et~al.(2022)Bortoli, Mathieu, Hutchinson, Thornton, Teh, and Doucet]{debortoli2022riemannian}
Valentin~De Bortoli, Emile Mathieu, MJ~Hutchinson, James Thornton, Yee~Whye Teh, and Arnaud Doucet.
\newblock Riemannian {S}core-{B}ased {G}enerative {M}odelling.
\newblock \emph{Advances in Neural Information Processing Systems}, page~46, 2022.

\bibitem[Bourgain(1985)]{Bourgain}
Jean Bourgain.
\newblock On {L}ipschitz {E}mbedding of {F}inite {M}etric {S}paces in {H}ilbert space.
\newblock \emph{Israel J. Math.}, 52\penalty0 (1-2):\penalty0 46--52, 1985.

\bibitem[Carlini et~al.(2021)Carlini, Tram{\`{e}}r, Wallace, Jagielski, Herbert{-}Voss, Lee, Roberts, Brown, Song, Erlingsson, Oprea, and Raffel]{carlini2021extracting}
Nicholas Carlini, Florian Tram{\`{e}}r, Eric Wallace, Matthew Jagielski, Ariel Herbert{-}Voss, Katherine Lee, Adam Roberts, Tom~B. Brown, Dawn Song, {\'{U}}lfar Erlingsson, Alina Oprea, and Colin Raffel.
\newblock Extracting {T}raining {D}ata from {L}arge {L}anguage {M}odels.
\newblock In \emph{30th USENIX Security Symposium (USENIX Security 21)}, pages 2633--2650, 2021.

\bibitem[Carlini et~al.(2023)Carlini, Hayes, Nasr, Jagielski, Sehwag, Tramer, Balle, Ippolito, and Wallace]{carlini2023extracting}
Nicolas Carlini, Jamie Hayes, Milad Nasr, Matthew Jagielski, Vikash Sehwag, Florian Tramer, Borja Balle, Daphne Ippolito, and Eric Wallace.
\newblock Extracting {T}raining {D}ata from {D}iffusion {M}odels.
\newblock In \emph{32nd USENIX Security Symposium (USENIX Security 23)}, pages 5253--5270, 2023.

\bibitem[Chae et~al.(2023)Chae, Kim, Kim, and Lin]{chae2023likelihood}
Minwoo Chae, Dongha Kim, Yongdai Kim, and Lizhen Lin.
\newblock A {L}ikelihood {A}pproach to {N}onparametric {E}stimation of a {S}ingular {D}istribution {U}sing {D}eep {G}enerative {M}odels.
\newblock \emph{Journal of Machine Learning Research}, 24\penalty0 (77):\penalty0 1--42, 2023.

\bibitem[Chen et~al.(2022)Chen, Li, Li, and Meka]{chen2022minimax}
Sitan Chen, Jerry Li, Yuanzhi Li, and Raghu Meka.
\newblock Minimax {O}ptimality ({P}robably) {D}oesn't {I}mply {D}istribution {L}earning for {GAN}s.
\newblock \emph{arXiv preprint arXiv:2201.07206}, 2022.

\bibitem[Daras et~al.(2023)Daras, Shah, Dagan, Gollakota, Dimakis, and Klivans]{daras2023ambient}
Giannis Daras, Kulin Shah, Yuval Dagan, Aravind Gollakota, Alex Dimakis, and Adam Klivans.
\newblock Ambient {D}iffusion: {L}earning {C}lean {D}istributions from {C}orrupted {D}ata.
\newblock In \emph{Thirty-seventh Conference on Neural Information Processing Systems}, 2023.

\bibitem[De~Bortoli et~al.(2021)De~Bortoli, Thornton, Heng, and Doucet]{Bortoli1}
Valentin De~Bortoli, James Thornton, Jeremy Heng, and Arnaud Doucet.
\newblock Diffusion {S}chr\"{o}dinger {B}ridge with {A}pplications to {S}core-{B}ased {G}enerative {M}odeling.
\newblock In M.~Ranzato, A.~Beygelzimer, Y.~Dauphin, P.S. Liang, and J.~Wortman Vaughan, editors, \emph{Advances in Neural Information Processing Systems}, volume~34, pages 17695--17709. Curran Associates, Inc., 2021.

\bibitem[Dudley(1969)]{dudley_1969}
Richard~M. Dudley.
\newblock The {S}peed of {M}ean {G}livenko-{C}antelli {C}onvergence.
\newblock \emph{The Annals of Mathematical Statistics}, 40\penalty0 (1):\penalty0 40 -- 50, 1969.
\newblock \doi{10.1214/aoms/1177697802}.

\bibitem[Dumoulin et~al.(2017)Dumoulin, Belghazi, Poole, Lamb, Arjovsky, Mastropietro, and Courville]{DumoulinBPLAMC17}
Vincent Dumoulin, Ishmael Belghazi, Ben Poole, Alex Lamb, Mart{\'{\i}}n Arjovsky, Olivier Mastropietro, and Aaron~C. Courville.
\newblock Adversarially {L}earned {I}nference.
\newblock In \emph{{ICLR}, Toulon, France, April 24-26, 2017, Conference Track Proceedings}. OpenReview.net, 2017.

\bibitem[Fefferman et~al.(2016)Fefferman, Mitter, and Narayanan]{fefferman2016}
Charles Fefferman, Sanjoy Mitter, and Hariharan Narayanan.
\newblock {T}esting the {M}anifold {H}ypothesis.
\newblock \emph{Journal of the American Mathematical Society}, 29\penalty0 (4):\penalty0 983--1049, 2016.

\bibitem[Fekri et~al.(2019)Fekri, Ghosh, and Grolinger]{fekri2019generating}
Mohammad~Navid Fekri, Ananda~Mohon Ghosh, and Katarina Grolinger.
\newblock Generating {E}nergy {D}ata for {M}achine {L}earning with {R}ecurrent {G}enerative {A}dversarial {N}etworks.
\newblock \emph{Energies}, 13\penalty0 (1):\penalty0 130, 2019.

\bibitem[Gagne et~al.(2020)Gagne, Christensen, Subramanian, and Monahan]{gagne2020machine}
David~John Gagne, Hannah~M Christensen, Aneesh~C Subramanian, and Adam~H Monahan.
\newblock Machine {L}earning for {S}tochastic {P}arameterization: {G}enerative {A}dversarial {N}etworks in the {L}orenz'96 {M}odel.
\newblock \emph{Journal of Advances in Modeling Earth Systems}, 12\penalty0 (3):\penalty0 e2019MS001896, 2020.

\bibitem[Genevay et~al.(2018)Genevay, Peyr{\'{e}}, and Cuturi]{GenevayPC18}
Aude Genevay, Gabriel Peyr{\'{e}}, and Marco Cuturi.
\newblock Learning generative models with sinkhorn divergences.
\newblock In \emph{{AISTATS}}, volume~84 of \emph{Proceedings of Machine Learning Research}, pages 1608--1617. {PMLR}, 2018.

\bibitem[Goodfellow et~al.(2014)Goodfellow, Pouget-Abadie, Mirza, Xu, Warde-Farley, Ozair, Courville, and Bengio]{goodfellow2014generative}
Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio.
\newblock {G}enerative {A}dversarial {N}etworks.
\newblock \emph{Advances in Neural Information Processing Systems}, 27:\penalty0 2672--2680, 2014.

\bibitem[Gulrajani et~al.(2017)Gulrajani, Ahmed, Arjovsky, Dumoulin, and Courville]{GulrajaniAADC17}
Ishaan Gulrajani, Faruk Ahmed, Mart{\'{\i}}n Arjovsky, Vincent Dumoulin, and Aaron~C. Courville.
\newblock Improved {T}raining of {W}asserstein {GAN}s.
\newblock In \emph{{NIPS}}, pages 5767--5777, 2017.

\bibitem[Gulrajani et~al.(2019)Gulrajani, Raffel, and Metz]{GulrajaniRM19}
Ishaan Gulrajani, Colin Raffel, and Luke Metz.
\newblock Towards {GAN} {B}enchmarks {W}hich require {G}eneralization.
\newblock In \emph{{ICLR} (Poster)}. OpenReview.net, 2019.

\bibitem[Huang et~al.(2022)Huang, Jiao, Li, Liu, Wang, and Yang]{huang_etal_2022}
Jian Huang, Yuling Jiao, Zhen Li, Shiao Liu, Yang Wang, and Yunfei Yang.
\newblock An {E}rror {A}nalysis of {G}enerative {A}dversarial {N}etworks for {L}earning {D}istributions.
\newblock \emph{Journal of Machine Learning Research}, 23:\penalty0 1--43, 2022.

\bibitem[Jagielski et~al.(2023)Jagielski, Thakkar, Tramer, Ippolito, Lee, Carlini, Wallace, Song, Thakurta, Papernot, and Zhang]{jagielski2023measuring}
Matthew Jagielski, Om~Thakkar, Florian Tramer, Daphne Ippolito, Katherine Lee, Nicholas Carlini, Eric Wallace, Shuang Song, Abhradeep~Guha Thakurta, Nicolas Papernot, and Chiyuan Zhang.
\newblock Measuring {F}orgetting of {M}emorized {T}raining {E}xamples.
\newblock In \emph{The Eleventh International Conference on Learning Representations}, 2023.

\bibitem[Jordan and Dimakis(2021)]{JordanD21}
Matt Jordan and Alex Dimakis.
\newblock Provable {L}ipschitz {C}ertification for {G}enerative {M}odels.
\newblock In \emph{{ICML}}, volume 139 of \emph{Proceedings of Machine Learning Research}, pages 5118--5126. {PMLR}, 2021.

\bibitem[Jordan and Dimakis(2020)]{Jordan20}
Matt Jordan and Alexandros~G Dimakis.
\newblock Exactly {C}omputing the {L}ocal {L}ipschitz {C}onstant of {ReLU} {N}etworks.
\newblock In H.~Larochelle, M.~Ranzato, R.~Hadsell, M.F. Balcan, and H.~Lin, editors, \emph{Advances in Neural Information Processing Systems}, volume~33, pages 7344--7353. Curran Associates, Inc., 2020.

\bibitem[Kingma and Welling(2014)]{kingma_welling_2013}
Diederik~P. Kingma and Max Welling.
\newblock {A}uto-{E}ncoding {V}ariational {B}ayes.
\newblock \emph{2nd International Conference on Learning Representations, {ICLR}}, 2014.

\bibitem[Krizhevsky(2009)]{krizhevskyCifar}
Alex Krizhevsky.
\newblock {L}earning {M}ultiple {L}ayers of {F}eatures from {T}iny {I}mages.
\newblock 2009.

\bibitem[Kwon and Chae(2024)]{kwon2023minimax}
Hyeok~Kyu Kwon and Minwoo Chae.
\newblock Minimax {O}ptimal {D}ensity {E}stimation using a {S}hallow {G}enerative {M}odel with a {O}ne-{D}imensional {L}atent {V}ariable.
\newblock pages 469--477, 2024.

\bibitem[LeCun(1998)]{lecun1998mnist}
Yann LeCun.
\newblock The {MNIST} {D}atabase of {H}andwritten {D}igits.
\newblock 1998.
\newblock URL \url{http://yann.lecun.com/exdb/mnist/}.

\bibitem[Li and Farnia(2023)]{pmlr-v206-ting-li23a}
Cheuk~Ting Li and Farzan Farnia.
\newblock {M}ode-{S}eeking {D}ivergences: {T}heory and {A}pplications to {GAN}s.
\newblock In Francisco Ruiz, Jennifer Dy, and Jan-Willem van~de Meent, editors, \emph{Proceedings of The 26th International Conference on Artificial Intelligence and Statistics}, volume 206 of \emph{Proceedings of Machine Learning Research}, pages 8321--8350. PMLR, 25--27 Apr 2023.

\bibitem[Li et~al.(2024)Li, Chen, and Li]{li2024good}
Sixu Li, Shi Chen, and Qin Li.
\newblock A good score does not lead to a good generative model.
\newblock \emph{arXiv preprint arXiv:2401.04856}, 2024.

\bibitem[Liang(2021)]{Liang}
Tengyuan Liang.
\newblock How {W}ell {G}enerative {A}dversarial {N}etworks {L}earn {D}istributions.
\newblock \emph{J. Mach. Learn. Res.}, 22\penalty0 (1), jan 2021.

\bibitem[Lu and Lu(2020)]{lu2020universal}
Yulong Lu and Jianfeng Lu.
\newblock A {U}niversal {A}pproximation {T}heorem of {D}eep {N}eural {N}etworks for {E}xpressing {P}robability {D}istributions.
\newblock \emph{Advances in neural information processing systems}, 33:\penalty0 3094--3105, 2020.

\bibitem[Luise et~al.(2020)Luise, Pontil, and Ciliberto]{Luise2020}
Giulia Luise, Massimiliano Pontil, and Carlo Ciliberto.
\newblock Generalization properties of optimal transport gans with latent distribution learning.
\newblock \emph{CoRR}, abs/2007.14641, 2020.

\bibitem[Marsland(2009)]{swissroll}
Stephen Marsland.
\newblock \emph{Machine {L}earning - {A}n {A}lgorithmic {P}erspective.}
\newblock Chapman and Hall / CRC machine learning and pattern recognition series. CRC Press, 2009.

\bibitem[Maziarka et~al.(2020)Maziarka, Pocha, Kaczmarczyk, Rataj, Danel, and Warcho{\l}]{maziarka2020mol}
{\L}ukasz Maziarka, Agnieszka Pocha, Jan Kaczmarczyk, Krzysztof Rataj, Tomasz Danel, and Micha{\l} Warcho{\l}.
\newblock Mol-{C}ycle{GAN}: {A} {G}enerative {M}odel for {M}olecular {O}ptimization.
\newblock \emph{Journal of Cheminformatics}, 12\penalty0 (1):\penalty0 1--18, 2020.

\bibitem[Nagarajan et~al.(2018)Nagarajan, Raffel, and Goodfellow]{nagarajan2018theoretical}
Vaishnavh Nagarajan, Colin Raffel, and Ian~J Goodfellow.
\newblock Theoretical {I}nsights into {M}emorization in {GAN}s.
\newblock \emph{Neural Information Processing Systems (NeurIPS) 2017 - Integration of Deep Learning Theories Workshop}, 2018.

\bibitem[Nakada and Imaizumi(2020)]{nakada2020adaptive}
Ryumei Nakada and Masaaki Imaizumi.
\newblock Adaptive {A}pproximation and {G}eneralization of {D}eep {N}eural {N}etwork with {I}ntrinsic {D}imensionality.
\newblock \emph{The Journal of Machine Learning Research}, 21\penalty0 (1):\penalty0 7018--7055, 2020.

\bibitem[Narayanan and Mitter(2010)]{NarayananM10}
Hariharan Narayanan and Sanjoy~K. Mitter.
\newblock Sample {C}omplexity of {T}esting the {M}anifold {H}ypothesis.
\newblock In \emph{{NIPS}}, pages 1786--1794. Curran Associates, Inc., 2010.

\bibitem[Nie et~al.(2017)Nie, Trullo, Lian, Petitjean, Ruan, Wang, and Shen]{nie2017medical}
Dong Nie, Roger Trullo, Jun Lian, Caroline Petitjean, Su~Ruan, Qian Wang, and Dinggang Shen.
\newblock Medical {I}mage {S}ynthesis with {C}ontext-{A}ware {G}enerative {A}dversarial {N}etworks.
\newblock In \emph{Medical Image Computing and Computer Assisted Intervention, 2017, Proceedings, Part III 20}, pages 417--425. Springer, 2017.

\bibitem[Niles-Weed and Rigollet(2022)]{weed2022estimation}
Jonathan Niles-Weed and Philippe Rigollet.
\newblock Estimation of {W}asserstein {D}istances in the {S}piked {T}ransport {M}odel.
\newblock \emph{Bernoulli}, 28\penalty0 (4):\penalty0 2663 -- 2688, 2022.
\newblock \doi{10.3150/21-BEJ1433}.

\bibitem[Ollivier et~al.(2014)Ollivier, Pajot, and Villani]{Ollivier_Pajot_Villani_2014}
Yann Ollivier, Hervé Pajot, and Cedric Villani.
\newblock \emph{Optimal {T}ransport: {T}heory and {A}pplications}.
\newblock London Mathematical Society Lecture Note Series. Cambridge University Press, 2014.

\bibitem[Paganini et~al.(2018)Paganini, de~Oliveira, and Nachman]{paganini2018calogan}
Michela Paganini, Luke de~Oliveira, and Benjamin Nachman.
\newblock Calo{GAN}: {S}imulating {3D} {H}igh {E}nergy {P}article {S}howers in {M}ultilayer {E}lectromagnetic {C}alorimeters with {G}enerative {A}dversarial {N}etworks.
\newblock \emph{Physical Review D}, 97\penalty0 (1):\penalty0 014021, 2018.

\bibitem[Petersen and Voigtlaender(2018)]{petersen2018optimal}
Philipp Petersen and Felix Voigtlaender.
\newblock Optimal {A}pproximation of {P}iecewise {S}mooth {F}unctions using {D}eep {ReLU} {N}eural {N}etworks.
\newblock \emph{Neural Networks}, 108:\penalty0 296--330, 2018.

\bibitem[Petzka et~al.(2018)Petzka, Fischer, and Lukovnikov]{petzka2018on}
Henning Petzka, Asja Fischer, and Denis Lukovnikov.
\newblock On the {R}egularization of {W}asserstein {GAN}s.
\newblock In \emph{International Conference on Learning Representations}, 2018.

\bibitem[Peyr{\'{e}} and Cuturi(2019)]{PeyreCuturi}
Gabriel Peyr{\'{e}} and Marco Cuturi.
\newblock Computational {O}ptimal {T}ransport: {W}ith {A}pplications to {D}ata {S}cience.
\newblock \emph{Foundations and Trends® in Machine Learning}, 11\penalty0 (5-6):\penalty0 355--607, 2019.

\bibitem[Repecka et~al.(2021)Repecka, Jauniskis, Karpus, Rembeza, Rokaitis, Zrimec, Poviloniene, Laurynenas, Viknander, Abuajwa, Savolainen, Meškys, Engqvist, and Zelezniak]{repecka2021expanding}
Donatas Repecka, Vykintas Jauniskis, Laurynas Karpus, Elzbieta Rembeza, Irmantas Rokaitis, Jan Zrimec, Simona Poviloniene, Audrius Laurynenas, Sandra Viknander, Wissam Abuajwa, Otto Savolainen, Rolandas Meškys, Martin Engqvist, and Aleksej Zelezniak.
\newblock Expanding {F}unctional {P}rotein {S}equence {S}paces using {G}enerative {A}dversarial {N}etworks.
\newblock \emph{Nature Machine Intelligence}, 3\penalty0 (4):\penalty0 324--333, 2021.

\bibitem[Roth et~al.(2017)Roth, Lucchi, Nowozin, and Hofmann]{roth_gan_regulariz}
Kevin Roth, Aur{\'{e}}lien Lucchi, Sebastian Nowozin, and Thomas Hofmann.
\newblock Stabilizing {T}raining of {G}enerative {A}dversarial {N}etworks through {R}egularization.
\newblock In \emph{{NIPS}}, pages 2018--2028, 2017.

\bibitem[Schreuder et~al.(2021)Schreuder, Brunel, and Dalalyan]{schreuder_brunel_dalalyan_2021}
Nicolas Schreuder, Victor{-}Emmanuel Brunel, and Arnak~S. Dalalyan.
\newblock Statistical {G}uarantees for {G}enerative {M}odels without {D}omination.
\newblock In \emph{{ALT}}, volume 132 of \emph{Proceedings of Machine Learning Research}, pages 1051--1071. {PMLR}, 2021.

\bibitem[Somepalli et~al.(2023{\natexlab{a}})Somepalli, Singla, Goldblum, Geiping, and Goldstein]{somepalli2023diffusion}
Gowthami Somepalli, Vasu Singla, Micah Goldblum, Jonas Geiping, and Tom Goldstein.
\newblock Diffusion {A}rt or {D}igital {F}orgery? {I}nvestigating {D}ata {R}eplication in {D}iffusion {M}odels.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 6048--6058, 2023{\natexlab{a}}.

\bibitem[Somepalli et~al.(2023{\natexlab{b}})Somepalli, Singla, Goldblum, Geiping, and Goldstein]{somepalli2023understanding}
Gowthami Somepalli, Vasu Singla, Micah Goldblum, Jonas Geiping, and Tom Goldstein.
\newblock Understanding and {M}itigating {C}opying in {D}iffusion {M}odels.
\newblock In \emph{Thirty-seventh Conference on Neural Information Processing Systems}, 2023{\natexlab{b}}.

\bibitem[Srivastava et~al.(2017)Srivastava, Valkov, Russell, Gutmann, and Sutton]{VEEGAN}
Akash Srivastava, Lazar Valkov, Chris Russell, Michael~U. Gutmann, and Charles Sutton.
\newblock {VEEGAN}: {R}educing {M}ode {C}ollapse in {GAN}s using {I}mplicit {V}ariational {L}earning.
\newblock In \emph{Neural Information Processing Systems}, 2017.

\bibitem[Stéphanovitch et~al.(2023)Stéphanovitch, Aamari, and Levrard]{stéphanovitch2023wasserstein}
Arthur Stéphanovitch, Eddie Aamari, and Clément Levrard.
\newblock Wasserstein {GAN}s are {M}inimax {O}ptimal {D}istribution {E}stimators, 2023.

\bibitem[Tang and Yang(2023)]{tang2022minimax}
Rong Tang and Yun Yang.
\newblock Minimax {R}ate of {D}istribution {E}stimation on {U}nknown {S}ubmanifold under {A}dversarial {L}osses, 2023.

\bibitem[Uppal et~al.(2019)Uppal, Singh, and P{\'o}czos]{uppal2019nonparametric}
Ananya Uppal, Shashank Singh, and Barnab{\'a}s P{\'o}czos.
\newblock Nonparametric {D}ensity {E}stimation \& {C}onvergence {R}ates for {GANs} under {B}esov {IPM} {L}osses.
\newblock \emph{Advances in neural information processing systems}, 32, 2019.

\bibitem[Varuna~Jayasiri(2020)]{labml}
Nipun~Wijerathne Varuna~Jayasiri.
\newblock labml.ai annotated paper implementations, 2020.
\newblock URL \url{https://nn.labml.ai/}.

\bibitem[Wang and Manchester(2023)]{WangM23}
Ruigang Wang and Ian~R. Manchester.
\newblock Direct {P}arameterization of {L}ipschitz-{B}ounded {D}eep {N}etworks.
\newblock In \emph{{ICML}}, volume 202 of \emph{Proceedings of Machine Learning Research}, pages 36093--36110. {PMLR}, 2023.

\bibitem[Wiese et~al.(2020)Wiese, Knobloch, Korn, and Kretschmer]{wiese2020quant}
Magnus Wiese, Robert Knobloch, Ralf Korn, and Peter Kretschmer.
\newblock Quant {GAN}s: {D}eep {G}eneration of {F}inancial {T}ime {S}eries.
\newblock \emph{Quantitative Finance}, 20\penalty0 (9):\penalty0 1419--1440, 2020.

\bibitem[Xi and Bloem-Reddy(2023)]{xi_reddy_2023}
Quanhan Xi and Benjamin Bloem-Reddy.
\newblock Indeterminacy in {G}enerative {M}odels: {C}haracterization and {S}trong {I}dentifiability.
\newblock \emph{arXiv preprint arXiv:2206.00801}, 2023.

\bibitem[Xiao et~al.(2018)Xiao, Zhong, and Zheng]{xiao2018bourgan}
Chang Xiao, Peilin Zhong, and Changxi Zheng.
\newblock {BourGAN}: {G}enerative {N}etworks with {M}etric {E}mbeddings.
\newblock \emph{Advances in neural information processing systems}, 31, 2018.

\bibitem[Yan et~al.(2018)Yan, Wang, Lu, and Summers]{yan2018deeplesion}
Ke~Yan, Xiaosong Wang, Le~Lu, and Ronald~M Summers.
\newblock {D}eep{L}esion: {A}utomated {M}ining of {L}arge-{S}cale {L}esion {A}nnotations and {U}niversal {L}esion {D}etection with {D}eep {L}earning.
\newblock \emph{Journal of medical imaging}, 5\penalty0 (3):\penalty0 036501--036501, 2018.

\bibitem[Yang et~al.(2022)Yang, Li, and Wang]{yang2022capacity}
Yunfei Yang, Zhen Li, and Yang Wang.
\newblock On the {C}apacity of {D}eep {G}enerative {N}etworks for {A}pproximating {D}istributions.
\newblock \emph{Neural networks}, 145:\penalty0 144--154, 2022.

\bibitem[Yarotsky(2017)]{yarotsky2017error}
Dmitry Yarotsky.
\newblock Error {B}ounds for {A}pproximations with {D}eep {ReLU} {N}etworks.
\newblock \emph{Neural Networks}, 94:\penalty0 103--114, 2017.

\bibitem[Zhu et~al.(2017)Zhu, Park, Isola, and Efros]{zhu_park_isola_efros_2017}
Jun-Yan Zhu, Taesung Park, Phillip Isola, and Alexei~A. Efros.
\newblock Unpaired {I}mage-to-{I}mage {T}ranslation using {C}ycle-{C}onsistent {A}dversarial {N}etworks.
\newblock In \emph{Proceedings of the IEEE international conference on computer vision}, pages 2868--2876, 2017.

\end{thebibliography}
