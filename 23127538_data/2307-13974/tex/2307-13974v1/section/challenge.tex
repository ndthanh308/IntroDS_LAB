\section{Experiment}
\label{sec:challenge}


\begin{table}[t]
  % \vspace{-2mm}
    \renewcommand\arraystretch {1.25}
    \centering
    \small
    \setlength{\tabcolsep}{1pt} % 
    % \rowcolors{3}{}{lightgray}
    \begin{tabularx}{\linewidth}{>{\raggedright\arraybackslash}p{2.8cm} >{\centering\arraybackslash}X>{\centering\arraybackslash}X>{\centering\arraybackslash}X>{\centering\arraybackslash}X>{\centering\arraybackslash}X>{\centering\arraybackslash}X}
  \hline
  Method & AUC &A &R &NRE$\downarrow$ &DRE$\downarrow$ &ADQ   \\
  \hline
  MS\_AOT (Separate) &0.552&0.625&0.831&0.063&0.106&0.417  \\
  MS\_AOT (Joint) &\textbf{0.566}&0.645&0.782&0.097&0.121&0.561\\
  \hline
    \end{tabularx}
    \vspace{-2mm}
    \caption{Ablation study of separate tracking $v.s.$ joint tracking paradigm on VOTS2023 validation set. 
    The metrics marked with	$\downarrow$ indicate that smaller is better and vice versa. 
	NRE: Not-Reported Error. DRE: Drift-Rate Error. ADQ: Absence-Detection Quality. 
	We refer readers to ~\cite{vots2023_metric} for more details about evaluation metrics.
}
    \label{table:separate_joint}
  %   \vspace{-5mm}
\end{table}

\begin{table}[t]
	% \vspace{-2mm}
	\renewcommand\arraystretch {1.25}
	\centering
	\small
	\setlength{\tabcolsep}{1pt} % 
	% \rowcolors{3}{}{lightgray}
	\begin{tabularx}{\linewidth}{>{\centering\arraybackslash}p{4mm}|>{\raggedright\arraybackslash}p{2.35cm} >{\centering\arraybackslash}X>{\centering\arraybackslash}X>{\centering\arraybackslash}X>{\centering\arraybackslash}X>{\centering\arraybackslash}X>{\centering\arraybackslash}X}
		\hline
		\# &Method & AUC &A &R &NRE$\downarrow$ &DRE$\downarrow$ &ADQ   \\
		\hline
		1& Baseline & 0.576	&0.675	&0.77	&0.122	&0.108	&0.581  \\
		2& $w/$ InternImage-T &0.611	&0.656	&0.809	&0.137	&0.054	&0.788\\
		3& VMOS &\textbf{0.650}	&0.681	&0.886	&0.059	&0.055	&0.648\\
		\hline
	\end{tabularx}
	\vspace{-2mm}
	\caption{Ablation study of components of VMOS on VOTS2023 validation set. We train a DeAOT~\cite{deaot} as the baseline method.}
	\label{table:vmos_com}
	%   \vspace{-5mm}
\end{table}

\begin{table}[t]
	% \vspace{-2mm}
	\renewcommand\arraystretch {1.25}
	\centering
	\small
	\setlength{\tabcolsep}{1pt} % 
	% \rowcolors{3}{}{lightgray}
	\begin{tabularx}{\linewidth}{>{\centering\arraybackslash}p{1cm} >{\centering\arraybackslash}X>{\centering\arraybackslash}X>{\centering\arraybackslash}X>{\centering\arraybackslash}X>{\centering\arraybackslash}X>{\centering\arraybackslash}X}
		%\hline 
		\hline  
		\rowcolor{white!}
		\hline 
		$G=$ & AUC &A &R &NRE$\downarrow$ &DRE$\downarrow$ &ADQ   \\
		\hline
		10 &0.610	&0.668	&0.807	&0.110	&0.083	&0.694  \\\rowcolor{gray!25}
		20 &0.607	&0.65	&0.806	&0.12	&0.074	&0.697\\
		30 &0.626	&0.689	&0.813	&0.127	&0.060	&0.715\\\rowcolor{gray!25}
		40 &0.650	&0.681	&0.886	&0.059	&0.055	&0.648\\
		50 &\textbf{0.669}	&0.692	&0.885	&0.057	&0.058	&0.682\\\rowcolor{gray!25}
		60 &0.653	&0.669	&0.889	&0.059	&0.052	&0.685\\
		70 &0.656	&0.688	&0.865	&0.052	&0.082	&0.666\\\rowcolor{gray!25}
		\hline
	\end{tabularx}
	\vspace{-2mm}
	\caption{Ablation study of long-term memory gap ($G$) on VOTS2023 validation set.}
	\label{table:ltm_param}
	\vspace{-5mm}
\end{table}


\subsection{Ablation Study}

\noindent\textbf{Separate tracking $v.s.$ Joint tracking.}
We conduct ablation studies on different tracking paradigms. 
\textit{Separate tracking} means initializing a separate tracker for each target object, and running multiple times of inference for multiple object tracking.
\textit{Joint tracking} means joint tracking all target objects with a single tracker.
We choose MS\_AOT~\cite{vot22} (removing Mixformer~\cite{mixformer}) as the baseline.
The results on VOTS2023 validation set are shown in Tabled~\ref{table:separate_joint}.
We can see that joint tracking shows better performance than separate tracking.
It may be that when joint tracking, the tracker will have a better understanding of the relationship between the target objects which makes the tracker obtain better robustness to distractor interference.

\noindent\textbf{Component-Wise Analysis on VMOS.}
Table~\ref{table:vmos_com} shows the component-wise study results on VMOS.
\#1 is a trained baseline method DeAOT~\cite{deaot}.
In \#2, we replace the original ResNet50~\cite{resnet} backbone with InternImage-T~\cite{internimage}, and the AUC score increases to 0.611.
Then, as reported in \#3, we add the multi-scale propagation mechanism as described in Section~\ref{sec:vmos}, the performance boosts to 0.650 in terms of AUC score, with a remarkable improvement of 3.9\%, which demonstrates the effectiveness.

\noindent\textbf{Long-term Memory Gap.}
Since the VOTS video sequences tend to be long (the longest exceeds 10,000 frames), the original long-term memory gap parameter on test time for the VOS benchmark is less suitable. 
Therefore, we do an ablution study on long-term memory gap ($G$) parameter as shown in Table~\ref{table:ltm_param}. 
We find that a memory gap of 50 shows the best performance.

\noindent\textbf{Analysis on Mask Refiner (MR).}
%We employ a HQ-SAM~\cite{sam_hq} model to refine the segmentation mask from VMOS.
As we discuss in Section~\ref{sec:mr}, directly refining all the segmentation masks is not optimal. We provide a comparison between VMOS and VMOS + SAM in Figure~\ref{fig:sam_plot}. In VMOS + SAM case, a SAM-h~\cite{sam} is employed to refine all the object masks from VMOS. 
We can see that refining by SAM can bring significant improvement. However, for these masks with low quality (with low IoU score on ground truth), SAM harms the performance instead.
Therefore, we propose to select mask results from VMOS and SAM. We calculate the IoU score between the masks from VMOS and SAM. When the IoU score is higher than $\tau$, we choose the refined mask as the final output. 
We evaluate the influence of threshold $\tau$ in MR on the VOTS2023 validation set, the results are shown in Table~\ref{table:mr_iou}.
$\tau=0.1$ yields the most promising results and we choose this setting in HQTrack.

% Figure environment removed



\begin{table}[t]
	% \vspace{-2mm}
	\renewcommand\arraystretch {1.25}
	\centering
	\small
	\setlength{\tabcolsep}{1pt} % 
	% \rowcolors{3}{}{lightgray}
	\begin{tabularx}{\linewidth}{>{\centering\arraybackslash}p{1cm} >{\centering\arraybackslash}X>{\centering\arraybackslash}X>{\centering\arraybackslash}X>{\centering\arraybackslash}X>{\centering\arraybackslash}X>{\centering\arraybackslash}X}
		\hline  
		\rowcolor{white!}
		\hline 
		$\tau=$ & AUC &A &R &NRE$\downarrow$ &DRE$\downarrow$ &ADQ   \\
		\hline
		0 &0.702	&0.756	&0.866	&0.072	&0.062	&0.769  \\\rowcolor{gray!25}
		0.1 &\textbf{0.708}	&0.753	&0.878	&0.072	&0.050	&0.769\\
		0.2 &0.707	&0.753	&0.878	&0.072	&0.050	&0.768\\\rowcolor{gray!25}
		0.3 &0.704	&0.750	&0.878	&0.072	&0.050	&0.764\\
		0.4 &0.701	&0.745	&0.878	&0.072	&0.050	&0.763\\\rowcolor{gray!25}
		0.5 &0.695	&0.739	&0.878	&0.072	&0.050	&0.758\\
		\hline
	\end{tabularx}
	\vspace{-2mm}
	\caption{Tracking performance with different threshold $\tau$ on VOTS2023 validation set. Mask refiner (MR) is a SAM\_H model.}
	\label{table:mr_iou}
	%   \vspace{-5mm}
\end{table}



\begin{table}[t]
	% \vspace{-2mm}
	\renewcommand\arraystretch {1.25}
	\centering
	\small
	\setlength{\tabcolsep}{1pt} % 
	% \rowcolors{3}{}{lightgray}
	\begin{tabularx}{\linewidth}{>{\centering\arraybackslash}p{2.5cm} >{\centering\arraybackslash}X>{\centering\arraybackslash}X>{\centering\arraybackslash}X>{\centering\arraybackslash}X>{\centering\arraybackslash}X>{\centering\arraybackslash}X}
		\hline
		Method & AUC &A &R &NRE$\downarrow$ &DRE$\downarrow$ &ADQ   \\
		\hline
		VMOS (Res50) &0.564	&0.693	&0.759	&0.155	&0.086	&0.691  \\
		VMOS &0.596	&0.724	&0.765	&0.159	&0.075	&0.711  \\
		VMOS + SAM\_H &0.610 &0.751	&0.757  &0.159  &0.084 &0.706\\
		\textbf{HQTrack} &\textbf{0.615} &0.752 &0.766  &0.155 &0.079	&0.694
		\\
		\hline
	\end{tabularx}
	\vspace{-2mm}
	\caption{Performance on VOTS2023 test set.}
	\label{table:testset_results}
	\vspace{-5mm}
\end{table}

% Figure environment removed

\subsection{Challenge Results}
The results on VOTS2023 test set are shown in Table~\ref{table:testset_results}.
After replacing the VMOS encoder from ResNet50~\cite{resnet} to InternImage-T~\cite{internimage}, the AUC score increased  by 3.2\%.
When using SAM\_H to refine the masks of VMOS, the performance in terms of AUC increased by 1.4\%. 
After employing HQ-SAM\_H as our mask refine module, the AUC score boosts to 0.615, which outperforms VMOS by 0.9\%.
Figure~\ref{fig:hqsam_plot} provides the quality plot comparison between VMOS and HQtrack.
As we can see and compare with Figure~\ref{fig:sam_plot}, selectively taking the processed results of the MR can effectively avoid performance degradation from low IoU objects. 
Finally, HQTrack ranks 2nd place\footnote{\url{https://eu.aihub.ml/competitions/201\#results}, VOTS2023 benchmark is open for allowing post-challenge submissions.} in the Visual Object Tracking and Segmentation Challenge.

\subsection{Visualization}
Figure~\ref{fig:vis} provides some representative visual results on challenging video sequences. 
As shown, HQTrack demonstrates strong tracking capabilities.
It can stably handle long-term object tracking scenarios, tracking multiple objects at the same time, and capturing target objects accurately even if there are a lot of distractors. 
With the help of HQ-SAM, accurate masks can also be segmented when facing challenges such as object appearance changes, fast motion, and scale changes.






