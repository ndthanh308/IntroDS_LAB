%apsrev4-2.bst 2019-01-14 (MD) hand-edited version of apsrev4-1.bst
%Control: key (0)
%Control: author (8) initials jnrlst
%Control: editor formatted (1) identically to author
%Control: production of article title (0) allowed
%Control: page (0) single
%Control: year (1) truncated
%Control: production of eprint (0) enabled
\begin{thebibliography}{55}%
\makeatletter
\providecommand \@ifxundefined [1]{%
 \@ifx{#1\undefined}
}%
\providecommand \@ifnum [1]{%
 \ifnum #1\expandafter \@firstoftwo
 \else \expandafter \@secondoftwo
 \fi
}%
\providecommand \@ifx [1]{%
 \ifx #1\expandafter \@firstoftwo
 \else \expandafter \@secondoftwo
 \fi
}%
\providecommand \natexlab [1]{#1}%
\providecommand \enquote  [1]{``#1''}%
\providecommand \bibnamefont  [1]{#1}%
\providecommand \bibfnamefont [1]{#1}%
\providecommand \citenamefont [1]{#1}%
\providecommand \href@noop [0]{\@secondoftwo}%
\providecommand \href [0]{\begingroup \@sanitize@url \@href}%
\providecommand \@href[1]{\@@startlink{#1}\@@href}%
\providecommand \@@href[1]{\endgroup#1\@@endlink}%
\providecommand \@sanitize@url [0]{\catcode `\\12\catcode `\$12\catcode
  `\&12\catcode `\#12\catcode `\^12\catcode `\_12\catcode `\%12\relax}%
\providecommand \@@startlink[1]{}%
\providecommand \@@endlink[0]{}%
\providecommand \url  [0]{\begingroup\@sanitize@url \@url }%
\providecommand \@url [1]{\endgroup\@href {#1}{\urlprefix }}%
\providecommand \urlprefix  [0]{URL }%
\providecommand \Eprint [0]{\href }%
\providecommand \doibase [0]{https://doi.org/}%
\providecommand \selectlanguage [0]{\@gobble}%
\providecommand \bibinfo  [0]{\@secondoftwo}%
\providecommand \bibfield  [0]{\@secondoftwo}%
\providecommand \translation [1]{[#1]}%
\providecommand \BibitemOpen [0]{}%
\providecommand \bibitemStop [0]{}%
\providecommand \bibitemNoStop [0]{.\EOS\space}%
\providecommand \EOS [0]{\spacefactor3000\relax}%
\providecommand \BibitemShut  [1]{\csname bibitem#1\endcsname}%
\let\auto@bib@innerbib\@empty
%</preamble>
\bibitem [{\citenamefont {Goodfellow}\ \emph {et~al.}(2016)\citenamefont
  {Goodfellow}, \citenamefont {Bengio},\ and\ \citenamefont
  {Courville}}]{GoodfellowBook}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {I.}~\bibnamefont
  {Goodfellow}}, \bibinfo {author} {\bibfnamefont {Y.}~\bibnamefont {Bengio}},\
  and\ \bibinfo {author} {\bibfnamefont {A.}~\bibnamefont {Courville}},\ }\href
  {http://www.deeplearningbook.org} {\emph {\bibinfo {title} {Deep Learning}}}\
  (\bibinfo  {publisher} {MIT Press},\ \bibinfo {year} {2016})\BibitemShut
  {NoStop}%
\bibitem [{\citenamefont {Bengio}\ \emph {et~al.}(2013)\citenamefont {Bengio},
  \citenamefont {Courville},\ and\ \citenamefont {Vincent}}]{6472238}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {Y.}~\bibnamefont
  {Bengio}}, \bibinfo {author} {\bibfnamefont {A.}~\bibnamefont {Courville}},\
  and\ \bibinfo {author} {\bibfnamefont {P.}~\bibnamefont {Vincent}},\
  }\bibfield  {title} {\bibinfo {title} {Representation learning: A review and
  new perspectives},\ }\href {https://doi.org/10.1109/TPAMI.2013.50} {\bibfield
   {journal} {\bibinfo  {journal} {IEEE Transactions on Pattern Analysis and
  Machine Intelligence}\ }\textbf {\bibinfo {volume} {35}},\ \bibinfo {pages}
  {1798} (\bibinfo {year} {2013})}\BibitemShut {NoStop}%
\bibitem [{\citenamefont {Yu}\ \emph {et~al.}(2013)\citenamefont {Yu},
  \citenamefont {Seltzer}, \citenamefont {Li}, \citenamefont {Huang},\ and\
  \citenamefont {Seide}}]{yu2013feature}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {D.}~\bibnamefont
  {Yu}}, \bibinfo {author} {\bibfnamefont {M.~L.}\ \bibnamefont {Seltzer}},
  \bibinfo {author} {\bibfnamefont {J.}~\bibnamefont {Li}}, \bibinfo {author}
  {\bibfnamefont {J.-T.}\ \bibnamefont {Huang}},\ and\ \bibinfo {author}
  {\bibfnamefont {F.}~\bibnamefont {Seide}},\ }\bibfield  {title} {\bibinfo
  {title} {Feature learning in deep neural networks-studies on speech
  recognition tasks},\ }\href@noop {} {\bibfield  {journal} {\bibinfo
  {journal} {arXiv preprint arXiv:1301.3605}\ } (\bibinfo {year}
  {2013})}\BibitemShut {NoStop}%
\bibitem [{\citenamefont {Neal}(1996)}]{Neal}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {R.~M.}\ \bibnamefont
  {Neal}},\ }\bibinfo {title} {Priors for infinite networks},\ in\ \href
  {https://doi.org/10.1007/978-1-4612-0745-0_2} {\emph {\bibinfo {booktitle}
  {Bayesian Learning for Neural Networks}}}\ (\bibinfo  {publisher} {Springer
  New York},\ \bibinfo {address} {New York, NY},\ \bibinfo {year} {1996})\ pp.\
  \bibinfo {pages} {29--53}\BibitemShut {NoStop}%
\bibitem [{\citenamefont {Williams}(1996)}]{NIPS1996_ae5e3ce4}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {C.}~\bibnamefont
  {Williams}},\ }\bibfield  {title} {\bibinfo {title} {Computing with infinite
  networks},\ }in\ \href
  {https://proceedings.neurips.cc/paper/1996/file/ae5e3ce40e0404a45ecacaaf05e5f735-Paper.pdf}
  {\emph {\bibinfo {booktitle} {Advances in Neural Information Processing
  Systems}}},\ Vol.~\bibinfo {volume} {9},\ \bibinfo {editor} {edited by\
  \bibinfo {editor} {\bibfnamefont {M.}~\bibnamefont {Mozer}}, \bibinfo
  {editor} {\bibfnamefont {M.}~\bibnamefont {Jordan}},\ and\ \bibinfo {editor}
  {\bibfnamefont {T.}~\bibnamefont {Petsche}}}\ (\bibinfo  {publisher} {MIT
  Press},\ \bibinfo {year} {1996})\BibitemShut {NoStop}%
\bibitem [{\citenamefont {de~G.~Matthews}\ \emph {et~al.}(2018)\citenamefont
  {de~G.~Matthews}, \citenamefont {Hron}, \citenamefont {Rowland},
  \citenamefont {Turner},\ and\ \citenamefont {Ghahramani}}]{g.2018gaussian}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {A.~G.}\ \bibnamefont
  {de~G.~Matthews}}, \bibinfo {author} {\bibfnamefont {J.}~\bibnamefont
  {Hron}}, \bibinfo {author} {\bibfnamefont {M.}~\bibnamefont {Rowland}},
  \bibinfo {author} {\bibfnamefont {R.~E.}\ \bibnamefont {Turner}},\ and\
  \bibinfo {author} {\bibfnamefont {Z.}~\bibnamefont {Ghahramani}},\ }\bibfield
   {title} {\bibinfo {title} {Gaussian process behaviour in wide deep neural
  networks},\ }in\ \href {https://openreview.net/forum?id=H1-nGgWC-} {\emph
  {\bibinfo {booktitle} {International Conference on Learning
  Representations}}}\ (\bibinfo {year} {2018})\BibitemShut {NoStop}%
\bibitem [{\citenamefont {Lee}\ \emph {et~al.}(2018)\citenamefont {Lee},
  \citenamefont {Sohl-dickstein}, \citenamefont {Pennington}, \citenamefont
  {Novak}, \citenamefont {Schoenholz},\ and\ \citenamefont
  {Bahri}}]{LeeGaussian}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {J.}~\bibnamefont
  {Lee}}, \bibinfo {author} {\bibfnamefont {J.}~\bibnamefont {Sohl-dickstein}},
  \bibinfo {author} {\bibfnamefont {J.}~\bibnamefont {Pennington}}, \bibinfo
  {author} {\bibfnamefont {R.}~\bibnamefont {Novak}}, \bibinfo {author}
  {\bibfnamefont {S.}~\bibnamefont {Schoenholz}},\ and\ \bibinfo {author}
  {\bibfnamefont {Y.}~\bibnamefont {Bahri}},\ }\bibfield  {title} {\bibinfo
  {title} {Deep neural networks as gaussian processes},\ }in\ \href
  {https://openreview.net/forum?id=B1EA-M-0Z} {\emph {\bibinfo {booktitle}
  {International Conference on Learning Representations}}}\ (\bibinfo {year}
  {2018})\BibitemShut {NoStop}%
\bibitem [{\citenamefont {Garriga-Alonso}\ \emph {et~al.}(2019)\citenamefont
  {Garriga-Alonso}, \citenamefont {Rasmussen},\ and\ \citenamefont
  {Aitchison}}]{garriga-alonso2018deep}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {A.}~\bibnamefont
  {Garriga-Alonso}}, \bibinfo {author} {\bibfnamefont {C.~E.}\ \bibnamefont
  {Rasmussen}},\ and\ \bibinfo {author} {\bibfnamefont {L.}~\bibnamefont
  {Aitchison}},\ }\bibfield  {title} {\bibinfo {title} {Deep convolutional
  networks as shallow gaussian processes},\ }in\ \href
  {https://openreview.net/forum?id=Bklfsi0cKm} {\emph {\bibinfo {booktitle}
  {International Conference on Learning Representations}}}\ (\bibinfo {year}
  {2019})\BibitemShut {NoStop}%
\bibitem [{\citenamefont {Novak}\ \emph {et~al.}(2019)\citenamefont {Novak},
  \citenamefont {Xiao}, \citenamefont {Bahri}, \citenamefont {Lee},
  \citenamefont {Yang}, \citenamefont {Abolafia}, \citenamefont {Pennington},\
  and\ \citenamefont {Sohl-dickstein}}]{novak2019bayesian}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {R.}~\bibnamefont
  {Novak}}, \bibinfo {author} {\bibfnamefont {L.}~\bibnamefont {Xiao}},
  \bibinfo {author} {\bibfnamefont {Y.}~\bibnamefont {Bahri}}, \bibinfo
  {author} {\bibfnamefont {J.}~\bibnamefont {Lee}}, \bibinfo {author}
  {\bibfnamefont {G.}~\bibnamefont {Yang}}, \bibinfo {author} {\bibfnamefont
  {D.~A.}\ \bibnamefont {Abolafia}}, \bibinfo {author} {\bibfnamefont
  {J.}~\bibnamefont {Pennington}},\ and\ \bibinfo {author} {\bibfnamefont
  {J.}~\bibnamefont {Sohl-dickstein}},\ }\bibfield  {title} {\bibinfo {title}
  {Bayesian deep convolutional networks with many channels are gaussian
  processes},\ }in\ \href {https://openreview.net/forum?id=B1g30j0qF7} {\emph
  {\bibinfo {booktitle} {International Conference on Learning
  Representations}}}\ (\bibinfo {year} {2019})\BibitemShut {NoStop}%
\bibitem [{\citenamefont {Jacot}\ \emph {et~al.}(2018)\citenamefont {Jacot},
  \citenamefont {Gabriel},\ and\ \citenamefont {Hongler}}]{JacotNTK}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {A.}~\bibnamefont
  {Jacot}}, \bibinfo {author} {\bibfnamefont {F.}~\bibnamefont {Gabriel}},\
  and\ \bibinfo {author} {\bibfnamefont {C.}~\bibnamefont {Hongler}},\
  }\bibfield  {title} {\bibinfo {title} {Neural tangent kernel: Convergence and
  generalization in neural networks},\ }in\ \href
  {https://proceedings.neurips.cc/paper/2018/file/5a4be1fa34e62bb8a6ec6b91d2462f5a-Paper.pdf}
  {\emph {\bibinfo {booktitle} {Advances in Neural Information Processing
  Systems}}},\ Vol.~\bibinfo {volume} {31},\ \bibinfo {editor} {edited by\
  \bibinfo {editor} {\bibfnamefont {S.}~\bibnamefont {Bengio}}, \bibinfo
  {editor} {\bibfnamefont {H.}~\bibnamefont {Wallach}}, \bibinfo {editor}
  {\bibfnamefont {H.}~\bibnamefont {Larochelle}}, \bibinfo {editor}
  {\bibfnamefont {K.}~\bibnamefont {Grauman}}, \bibinfo {editor} {\bibfnamefont
  {N.}~\bibnamefont {Cesa-Bianchi}},\ and\ \bibinfo {editor} {\bibfnamefont
  {R.}~\bibnamefont {Garnett}}}\ (\bibinfo  {publisher} {Curran Associates,
  Inc.},\ \bibinfo {year} {2018})\BibitemShut {NoStop}%
\bibitem [{\citenamefont {Chizat}\ \emph {et~al.}(2019)\citenamefont {Chizat},
  \citenamefont {Oyallon},\ and\ \citenamefont {Bach}}]{ChizatLazy}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {L.}~\bibnamefont
  {Chizat}}, \bibinfo {author} {\bibfnamefont {E.}~\bibnamefont {Oyallon}},\
  and\ \bibinfo {author} {\bibfnamefont {F.}~\bibnamefont {Bach}},\ }\bibfield
  {title} {\bibinfo {title} {On lazy training in differentiable programming},\
  }in\ \href
  {https://proceedings.neurips.cc/paper/2019/file/ae614c557843b1df326cb29c57225459-Paper.pdf}
  {\emph {\bibinfo {booktitle} {Advances in Neural Information Processing
  Systems}}},\ Vol.~\bibinfo {volume} {32},\ \bibinfo {editor} {edited by\
  \bibinfo {editor} {\bibfnamefont {H.}~\bibnamefont {Wallach}}, \bibinfo
  {editor} {\bibfnamefont {H.}~\bibnamefont {Larochelle}}, \bibinfo {editor}
  {\bibfnamefont {A.}~\bibnamefont {Beygelzimer}}, \bibinfo {editor}
  {\bibfnamefont {F.}~\bibnamefont {d\textquotesingle Alch\'{e}-Buc}}, \bibinfo
  {editor} {\bibfnamefont {E.}~\bibnamefont {Fox}},\ and\ \bibinfo {editor}
  {\bibfnamefont {R.}~\bibnamefont {Garnett}}}\ (\bibinfo  {publisher} {Curran
  Associates, Inc.},\ \bibinfo {year} {2019})\BibitemShut {NoStop}%
\bibitem [{\citenamefont {Lee}\ \emph {et~al.}(2019)\citenamefont {Lee},
  \citenamefont {Xiao}, \citenamefont {Schoenholz}, \citenamefont {Bahri},
  \citenamefont {Novak}, \citenamefont {Sohl-Dickstein},\ and\ \citenamefont
  {Pennington}}]{lee2019wide}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {J.}~\bibnamefont
  {Lee}}, \bibinfo {author} {\bibfnamefont {L.}~\bibnamefont {Xiao}}, \bibinfo
  {author} {\bibfnamefont {S.}~\bibnamefont {Schoenholz}}, \bibinfo {author}
  {\bibfnamefont {Y.}~\bibnamefont {Bahri}}, \bibinfo {author} {\bibfnamefont
  {R.}~\bibnamefont {Novak}}, \bibinfo {author} {\bibfnamefont
  {J.}~\bibnamefont {Sohl-Dickstein}},\ and\ \bibinfo {author} {\bibfnamefont
  {J.}~\bibnamefont {Pennington}},\ }\bibfield  {title} {\bibinfo {title} {Wide
  neural networks of any depth evolve as linear models under gradient
  descent},\ }in\ \href
  {https://proceedings.neurips.cc/paper/2019/file/0d1a9651497a38d8b1c3871c84528bd4-Paper.pdf}
  {\emph {\bibinfo {booktitle} {Advances in Neural Information Processing
  Systems}}},\ Vol.~\bibinfo {volume} {32},\ \bibinfo {editor} {edited by\
  \bibinfo {editor} {\bibfnamefont {H.}~\bibnamefont {Wallach}}, \bibinfo
  {editor} {\bibfnamefont {H.}~\bibnamefont {Larochelle}}, \bibinfo {editor}
  {\bibfnamefont {A.}~\bibnamefont {Beygelzimer}}, \bibinfo {editor}
  {\bibfnamefont {F.}~\bibnamefont {d\textquotesingle Alch\'{e}-Buc}}, \bibinfo
  {editor} {\bibfnamefont {E.}~\bibnamefont {Fox}},\ and\ \bibinfo {editor}
  {\bibfnamefont {R.}~\bibnamefont {Garnett}}}\ (\bibinfo  {publisher} {Curran
  Associates, Inc.},\ \bibinfo {year} {2019})\BibitemShut {NoStop}%
\bibitem [{\citenamefont {Cortes}\ and\ \citenamefont
  {Vapnik}(1995)}]{cortes1995support}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {C.}~\bibnamefont
  {Cortes}}\ and\ \bibinfo {author} {\bibfnamefont {V.}~\bibnamefont
  {Vapnik}},\ }\bibfield  {title} {\bibinfo {title} {Support-vector networks},\
  }\href {https://doi.org/10.1007/BF00994018} {\bibfield  {journal} {\bibinfo
  {journal} {Machine Learning}\ }\textbf {\bibinfo {volume} {20}},\ \bibinfo
  {pages} {273} (\bibinfo {year} {1995})}\BibitemShut {NoStop}%
\bibitem [{\citenamefont {Dietrich}\ \emph {et~al.}(1999)\citenamefont
  {Dietrich}, \citenamefont {Opper},\ and\ \citenamefont
  {Sompolinsky}}]{PhysRevLett.82.2975}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {R.}~\bibnamefont
  {Dietrich}}, \bibinfo {author} {\bibfnamefont {M.}~\bibnamefont {Opper}},\
  and\ \bibinfo {author} {\bibfnamefont {H.}~\bibnamefont {Sompolinsky}},\
  }\bibfield  {title} {\bibinfo {title} {Statistical mechanics of support
  vector networks},\ }\href {https://doi.org/10.1103/PhysRevLett.82.2975}
  {\bibfield  {journal} {\bibinfo  {journal} {Phys. Rev. Lett.}\ }\textbf
  {\bibinfo {volume} {82}},\ \bibinfo {pages} {2975} (\bibinfo {year}
  {1999})}\BibitemShut {NoStop}%
\bibitem [{\citenamefont {Bordelon}\ \emph {et~al.}(2020)\citenamefont
  {Bordelon}, \citenamefont {Canatar},\ and\ \citenamefont
  {Pehlevan}}]{pmlr-v119-bordelon20a}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {B.}~\bibnamefont
  {Bordelon}}, \bibinfo {author} {\bibfnamefont {A.}~\bibnamefont {Canatar}},\
  and\ \bibinfo {author} {\bibfnamefont {C.}~\bibnamefont {Pehlevan}},\
  }\bibfield  {title} {\bibinfo {title} {Spectrum dependent learning curves in
  kernel regression and wide neural networks},\ }in\ \href
  {https://proceedings.mlr.press/v119/bordelon20a.html} {\emph {\bibinfo
  {booktitle} {Proceedings of the 37th International Conference on Machine
  Learning}}},\ \bibinfo {series} {Proceedings of Machine Learning Research},
  Vol.\ \bibinfo {volume} {119},\ \bibinfo {editor} {edited by\ \bibinfo
  {editor} {\bibfnamefont {H.~D.}\ \bibnamefont {III}}\ and\ \bibinfo {editor}
  {\bibfnamefont {A.}~\bibnamefont {Singh}}}\ (\bibinfo  {publisher} {PMLR},\
  \bibinfo {year} {2020})\ pp.\ \bibinfo {pages} {1024--1034}\BibitemShut
  {NoStop}%
\bibitem [{\citenamefont {Canatar}\ \emph {et~al.}(2021)\citenamefont
  {Canatar}, \citenamefont {Bordelon},\ and\ \citenamefont
  {Pehlevan}}]{canatar2021}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {A.}~\bibnamefont
  {Canatar}}, \bibinfo {author} {\bibfnamefont {B.}~\bibnamefont {Bordelon}},\
  and\ \bibinfo {author} {\bibfnamefont {C.}~\bibnamefont {Pehlevan}},\
  }\bibfield  {title} {\bibinfo {title} {Spectral bias and task-model alignment
  explain generalization in kernel regression and infinitely wide neural
  networks},\ }\href {https://doi.org/10.1038/s41467-021-23103-1} {\bibfield
  {journal} {\bibinfo  {journal} {Nature communications}\ }\textbf {\bibinfo
  {volume} {12}},\ \bibinfo {pages} {1} (\bibinfo {year} {2021})}\BibitemShut
  {NoStop}%
\bibitem [{\citenamefont {Vyas}\ \emph {et~al.}(2022)\citenamefont {Vyas},
  \citenamefont {Bansal},\ and\ \citenamefont {Preetum}}]{Vyas2022}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {N.}~\bibnamefont
  {Vyas}}, \bibinfo {author} {\bibfnamefont {Y.}~\bibnamefont {Bansal}},\ and\
  \bibinfo {author} {\bibfnamefont {N.}~\bibnamefont {Preetum}},\ }\bibfield
  {title} {\bibinfo {title} {Limitations of the ntk for understanding
  generalization in deep learning},\ }\href@noop {} {\bibfield  {journal}
  {\bibinfo  {journal} {arXiv preprint arXiv:2206.10012}\ } (\bibinfo {year}
  {2022})}\BibitemShut {NoStop}%
\bibitem [{\citenamefont {Lee}\ \emph {et~al.}(2020)\citenamefont {Lee},
  \citenamefont {Schoenholz}, \citenamefont {Pennington}, \citenamefont
  {Adlam}, \citenamefont {Xiao}, \citenamefont {Novak},\ and\ \citenamefont
  {Sohl-Dickstein}}]{NEURIPS2020_ad086f59}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {J.}~\bibnamefont
  {Lee}}, \bibinfo {author} {\bibfnamefont {S.}~\bibnamefont {Schoenholz}},
  \bibinfo {author} {\bibfnamefont {J.}~\bibnamefont {Pennington}}, \bibinfo
  {author} {\bibfnamefont {B.}~\bibnamefont {Adlam}}, \bibinfo {author}
  {\bibfnamefont {L.}~\bibnamefont {Xiao}}, \bibinfo {author} {\bibfnamefont
  {R.}~\bibnamefont {Novak}},\ and\ \bibinfo {author} {\bibfnamefont
  {J.}~\bibnamefont {Sohl-Dickstein}},\ }\bibfield  {title} {\bibinfo {title}
  {Finite versus infinite neural networks: an empirical study},\ }in\ \href
  {https://proceedings.neurips.cc/paper/2020/file/ad086f59924fffe0773f8d0ca22ea712-Paper.pdf}
  {\emph {\bibinfo {booktitle} {Advances in Neural Information Processing
  Systems}}},\ Vol.~\bibinfo {volume} {33},\ \bibinfo {editor} {edited by\
  \bibinfo {editor} {\bibfnamefont {H.}~\bibnamefont {Larochelle}}, \bibinfo
  {editor} {\bibfnamefont {M.}~\bibnamefont {Ranzato}}, \bibinfo {editor}
  {\bibfnamefont {R.}~\bibnamefont {Hadsell}}, \bibinfo {editor} {\bibfnamefont
  {M.}~\bibnamefont {Balcan}},\ and\ \bibinfo {editor} {\bibfnamefont
  {H.}~\bibnamefont {Lin}}}\ (\bibinfo  {publisher} {Curran Associates, Inc.},\
  \bibinfo {year} {2020})\ pp.\ \bibinfo {pages} {15156--15172}\BibitemShut
  {NoStop}%
\bibitem [{\citenamefont {Atanasov}\ \emph {et~al.}(2022)\citenamefont
  {Atanasov}, \citenamefont {Bordelon}, \citenamefont {Sainathan},\ and\
  \citenamefont {Pehlevan}}]{atanasov2022onset}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {A.}~\bibnamefont
  {Atanasov}}, \bibinfo {author} {\bibfnamefont {B.}~\bibnamefont {Bordelon}},
  \bibinfo {author} {\bibfnamefont {S.}~\bibnamefont {Sainathan}},\ and\
  \bibinfo {author} {\bibfnamefont {C.}~\bibnamefont {Pehlevan}},\ }\bibfield
  {title} {\bibinfo {title} {The onset of variance-limited behavior for
  networks in the lazy and rich regimes},\ }\href@noop {} {\bibfield  {journal}
  {\bibinfo  {journal} {arXiv preprint arXiv:2212.12147}\ } (\bibinfo {year}
  {2022})}\BibitemShut {NoStop}%
\bibitem [{\citenamefont {Mei}\ \emph {et~al.}(2018)\citenamefont {Mei},
  \citenamefont {Montanari},\ and\ \citenamefont
  {Nguyen}}]{doi:10.1073/pnas.1806579115}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {S.}~\bibnamefont
  {Mei}}, \bibinfo {author} {\bibfnamefont {A.}~\bibnamefont {Montanari}},\
  and\ \bibinfo {author} {\bibfnamefont {P.-M.}\ \bibnamefont {Nguyen}},\
  }\bibfield  {title} {\bibinfo {title} {A mean field view of the landscape of
  two-layer neural networks},\ }\href {https://doi.org/10.1073/pnas.1806579115}
  {\bibfield  {journal} {\bibinfo  {journal} {Proceedings of the National
  Academy of Sciences}\ }\textbf {\bibinfo {volume} {115}},\ \bibinfo {pages}
  {E7665} (\bibinfo {year} {2018})},\ \Eprint
  {https://arxiv.org/abs/https://www.pnas.org/doi/pdf/10.1073/pnas.1806579115}
  {https://www.pnas.org/doi/pdf/10.1073/pnas.1806579115} \BibitemShut {NoStop}%
\bibitem [{\citenamefont {Geiger}\ \emph {et~al.}(2021)\citenamefont {Geiger},
  \citenamefont {Petrini},\ and\ \citenamefont {Wyart}}]{GEIGER20211}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {M.}~\bibnamefont
  {Geiger}}, \bibinfo {author} {\bibfnamefont {L.}~\bibnamefont {Petrini}},\
  and\ \bibinfo {author} {\bibfnamefont {M.}~\bibnamefont {Wyart}},\ }\bibfield
   {title} {\bibinfo {title} {Landscape and training regimes in deep
  learning},\ }\href
  {https://doi.org/https://doi.org/10.1016/j.physrep.2021.04.001} {\bibfield
  {journal} {\bibinfo  {journal} {Physics Reports}\ }\textbf {\bibinfo {volume}
  {924}},\ \bibinfo {pages} {1} (\bibinfo {year} {2021})},\ \bibinfo {note}
  {landscape and training regimes in deep learning}\BibitemShut {NoStop}%
\bibitem [{\citenamefont {Geiger}\ \emph {et~al.}(2020)\citenamefont {Geiger},
  \citenamefont {Spigler}, \citenamefont {Jacot},\ and\ \citenamefont
  {Wyart}}]{Geiger_2020}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {M.}~\bibnamefont
  {Geiger}}, \bibinfo {author} {\bibfnamefont {S.}~\bibnamefont {Spigler}},
  \bibinfo {author} {\bibfnamefont {A.}~\bibnamefont {Jacot}},\ and\ \bibinfo
  {author} {\bibfnamefont {M.}~\bibnamefont {Wyart}},\ }\bibfield  {title}
  {\bibinfo {title} {Disentangling feature and lazy training in deep neural
  networks},\ }\href {https://doi.org/10.1088/1742-5468/abc4de} {\bibfield
  {journal} {\bibinfo  {journal} {Journal of Statistical Mechanics: Theory and
  Experiment}\ }\textbf {\bibinfo {volume} {2020}},\ \bibinfo {pages} {113301}
  (\bibinfo {year} {2020})}\BibitemShut {NoStop}%
\bibitem [{\citenamefont {Seroussi}\ \emph {et~al.}(2023)\citenamefont
  {Seroussi}, \citenamefont {Naveh},\ and\ \citenamefont
  {Ringel}}]{seroussi2023natcomm}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {I.}~\bibnamefont
  {Seroussi}}, \bibinfo {author} {\bibfnamefont {G.}~\bibnamefont {Naveh}},\
  and\ \bibinfo {author} {\bibfnamefont {Z.}~\bibnamefont {Ringel}},\
  }\bibfield  {title} {\bibinfo {title} {Separation of scales and a
  thermodynamic description of feature learning in some cnns},\ }\href
  {https://doi.org/10.1038/s41467-023-36361-y} {\bibfield  {journal} {\bibinfo
  {journal} {Nature Communications}\ }\textbf {\bibinfo {volume} {14}},\
  \bibinfo {pages} {908} (\bibinfo {year} {2023})}\BibitemShut {NoStop}%
\bibitem [{\citenamefont {Naveh}\ and\ \citenamefont
  {Ringel}(2021)}]{NEURIPS2021_b24d2101}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {G.}~\bibnamefont
  {Naveh}}\ and\ \bibinfo {author} {\bibfnamefont {Z.}~\bibnamefont {Ringel}},\
  }\bibfield  {title} {\bibinfo {title} {A self consistent theory of gaussian
  processes captures feature learning effects in finite cnns},\ }in\ \href
  {https://proceedings.neurips.cc/paper/2021/file/b24d21019de5e59da180f1661904f49a-Paper.pdf}
  {\emph {\bibinfo {booktitle} {Advances in Neural Information Processing
  Systems}}},\ Vol.~\bibinfo {volume} {34},\ \bibinfo {editor} {edited by\
  \bibinfo {editor} {\bibfnamefont {M.}~\bibnamefont {Ranzato}}, \bibinfo
  {editor} {\bibfnamefont {A.}~\bibnamefont {Beygelzimer}}, \bibinfo {editor}
  {\bibfnamefont {Y.}~\bibnamefont {Dauphin}}, \bibinfo {editor} {\bibfnamefont
  {P.}~\bibnamefont {Liang}},\ and\ \bibinfo {editor} {\bibfnamefont {J.~W.}\
  \bibnamefont {Vaughan}}}\ (\bibinfo  {publisher} {Curran Associates, Inc.},\
  \bibinfo {year} {2021})\ pp.\ \bibinfo {pages} {21352--21364}\BibitemShut
  {NoStop}%
\bibitem [{\citenamefont {Zavatone-Veth}\ \emph {et~al.}(2021)\citenamefont
  {Zavatone-Veth}, \citenamefont {Canatar}, \citenamefont {Ruben},\ and\
  \citenamefont {Pehlevan}}]{NEURIPS2021_cf9dc5e4}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {J.}~\bibnamefont
  {Zavatone-Veth}}, \bibinfo {author} {\bibfnamefont {A.}~\bibnamefont
  {Canatar}}, \bibinfo {author} {\bibfnamefont {B.}~\bibnamefont {Ruben}},\
  and\ \bibinfo {author} {\bibfnamefont {C.}~\bibnamefont {Pehlevan}},\
  }\bibfield  {title} {\bibinfo {title} {Asymptotics of representation learning
  in finite bayesian neural networks},\ }in\ \href
  {https://proceedings.neurips.cc/paper/2021/file/cf9dc5e4e194fc21f397b4cac9cc3ae9-Paper.pdf}
  {\emph {\bibinfo {booktitle} {Advances in Neural Information Processing
  Systems}}},\ Vol.~\bibinfo {volume} {34},\ \bibinfo {editor} {edited by\
  \bibinfo {editor} {\bibfnamefont {M.}~\bibnamefont {Ranzato}}, \bibinfo
  {editor} {\bibfnamefont {A.}~\bibnamefont {Beygelzimer}}, \bibinfo {editor}
  {\bibfnamefont {Y.}~\bibnamefont {Dauphin}}, \bibinfo {editor} {\bibfnamefont
  {P.}~\bibnamefont {Liang}},\ and\ \bibinfo {editor} {\bibfnamefont {J.~W.}\
  \bibnamefont {Vaughan}}}\ (\bibinfo  {publisher} {Curran Associates, Inc.},\
  \bibinfo {year} {2021})\ pp.\ \bibinfo {pages} {24765--24777}\BibitemShut
  {NoStop}%
\bibitem [{\citenamefont {Zavatone-Veth}\ \emph {et~al.}(2022)\citenamefont
  {Zavatone-Veth}, \citenamefont {Tong},\ and\ \citenamefont
  {Pehlevan}}]{PhysRevE.105.064118}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {J.~A.}\ \bibnamefont
  {Zavatone-Veth}}, \bibinfo {author} {\bibfnamefont {W.~L.}\ \bibnamefont
  {Tong}},\ and\ \bibinfo {author} {\bibfnamefont {C.}~\bibnamefont
  {Pehlevan}},\ }\bibfield  {title} {\bibinfo {title} {Contrasting random and
  learned features in deep bayesian linear regression},\ }\href
  {https://doi.org/10.1103/PhysRevE.105.064118} {\bibfield  {journal} {\bibinfo
   {journal} {Phys. Rev. E}\ }\textbf {\bibinfo {volume} {105}},\ \bibinfo
  {pages} {064118} (\bibinfo {year} {2022})}\BibitemShut {NoStop}%
\bibitem [{\citenamefont {Zavatone-Veth}\ and\ \citenamefont
  {Pehlevan}(2021)}]{zavatone-veth2021exact}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {J.~A.}\ \bibnamefont
  {Zavatone-Veth}}\ and\ \bibinfo {author} {\bibfnamefont {C.}~\bibnamefont
  {Pehlevan}},\ }\bibfield  {title} {\bibinfo {title} {Exact marginal prior
  distributions of finite bayesian neural networks},\ }in\ \href
  {https://openreview.net/forum?id=MxE7xFzv0N8} {\emph {\bibinfo {booktitle}
  {Advances in Neural Information Processing Systems}}},\ \bibinfo {editor}
  {edited by\ \bibinfo {editor} {\bibfnamefont {A.}~\bibnamefont
  {Beygelzimer}}, \bibinfo {editor} {\bibfnamefont {Y.}~\bibnamefont
  {Dauphin}}, \bibinfo {editor} {\bibfnamefont {P.}~\bibnamefont {Liang}},\
  and\ \bibinfo {editor} {\bibfnamefont {J.~W.}\ \bibnamefont {Vaughan}}}\
  (\bibinfo {year} {2021})\BibitemShut {NoStop}%
\bibitem [{\citenamefont {Roberts}\ \emph {et~al.}(2022)\citenamefont
  {Roberts}, \citenamefont {Yaida},\ and\ \citenamefont {Hanin}}]{PDLT-2022}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {D.~A.}\ \bibnamefont
  {Roberts}}, \bibinfo {author} {\bibfnamefont {S.}~\bibnamefont {Yaida}},\
  and\ \bibinfo {author} {\bibfnamefont {B.}~\bibnamefont {Hanin}},\
  }\href@noop {} {\emph {\bibinfo {title} {The Principles of Deep Learning
  Theory}}}\ (\bibinfo  {publisher} {Cambridge University Press},\ \bibinfo
  {year} {2022})\ \bibinfo {note} {\url{https://deeplearningtheory.com}},\
  \Eprint {https://arxiv.org/abs/2106.10165} {arXiv:2106.10165 [cs.LG]}
  \BibitemShut {NoStop}%
\bibitem [{\citenamefont {Hanin}(2023)}]{hanin2023random}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {B.}~\bibnamefont
  {Hanin}},\ }\href@noop {} {\bibinfo {title} {Random fully connected neural
  networks as perturbatively solvable hierarchies}} (\bibinfo {year} {2023}),\
  \Eprint {https://arxiv.org/abs/2204.01058} {arXiv:2204.01058 [math.PR]}
  \BibitemShut {NoStop}%
\bibitem [{\citenamefont {Antognini}(2019)}]{antognini2019finite}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {J.~M.}\ \bibnamefont
  {Antognini}},\ }\href@noop {} {\bibinfo {title} {Finite size corrections for
  neural network gaussian processes}} (\bibinfo {year} {2019}),\ \Eprint
  {https://arxiv.org/abs/1908.10030} {arXiv:1908.10030 [cs.LG]} \BibitemShut
  {NoStop}%
\bibitem [{\citenamefont {Yaida}(2020)}]{yaida2020nonGauss}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {S.}~\bibnamefont
  {Yaida}},\ }\bibfield  {title} {\bibinfo {title} {Non-{G}aussian processes
  and neural networks at finite widths},\ }in\ \href
  {https://proceedings.mlr.press/v107/yaida20a.html} {\emph {\bibinfo
  {booktitle} {Proceedings of The First Mathematical and Scientific Machine
  Learning Conference}}},\ \bibinfo {series} {Proceedings of Machine Learning
  Research}, Vol.\ \bibinfo {volume} {107},\ \bibinfo {editor} {edited by\
  \bibinfo {editor} {\bibfnamefont {J.}~\bibnamefont {Lu}}\ and\ \bibinfo
  {editor} {\bibfnamefont {R.}~\bibnamefont {Ward}}}\ (\bibinfo  {publisher}
  {PMLR},\ \bibinfo {year} {2020})\ pp.\ \bibinfo {pages}
  {165--192}\BibitemShut {NoStop}%
\bibitem [{\citenamefont {Aitchison}(2020)}]{aitchison2020bigger}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {L.}~\bibnamefont
  {Aitchison}},\ }\bibfield  {title} {\bibinfo {title} {Why bigger is not
  always better: on finite and infinite neural networks},\ }in\ \href
  {https://proceedings.mlr.press/v119/aitchison20a.html} {\emph {\bibinfo
  {booktitle} {Proceedings of the 37th International Conference on Machine
  Learning}}},\ \bibinfo {series} {Proceedings of Machine Learning Research},
  Vol.\ \bibinfo {volume} {119},\ \bibinfo {editor} {edited by\ \bibinfo
  {editor} {\bibfnamefont {H.~D.}\ \bibnamefont {III}}\ and\ \bibinfo {editor}
  {\bibfnamefont {A.}~\bibnamefont {Singh}}}\ (\bibinfo  {publisher} {PMLR},\
  \bibinfo {year} {2020})\ pp.\ \bibinfo {pages} {156--164}\BibitemShut
  {NoStop}%
\bibitem [{\citenamefont {Yang}\ \emph {et~al.}(2023)\citenamefont {Yang},
  \citenamefont {Robeyns}, \citenamefont {Milsom}, \citenamefont {Schoots},\
  and\ \citenamefont {Aitchison}}]{yang2023theory}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {A.~X.}\ \bibnamefont
  {Yang}}, \bibinfo {author} {\bibfnamefont {M.}~\bibnamefont {Robeyns}},
  \bibinfo {author} {\bibfnamefont {E.}~\bibnamefont {Milsom}}, \bibinfo
  {author} {\bibfnamefont {N.}~\bibnamefont {Schoots}},\ and\ \bibinfo {author}
  {\bibfnamefont {L.}~\bibnamefont {Aitchison}},\ }\href@noop {} {\bibinfo
  {title} {A theory of representation learning in deep neural networks gives a
  deep generalisation of kernel methods}} (\bibinfo {year} {2023}),\ \Eprint
  {https://arxiv.org/abs/2108.13097} {arXiv:2108.13097 [stat.ML]} \BibitemShut
  {NoStop}%
\bibitem [{\citenamefont {Favaro}\ \emph {et~al.}(2023)\citenamefont {Favaro},
  \citenamefont {Hanin}, \citenamefont {Marinucci}, \citenamefont {Nourdin},\
  and\ \citenamefont {Peccati}}]{favaro2023quantitative}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {S.}~\bibnamefont
  {Favaro}}, \bibinfo {author} {\bibfnamefont {B.}~\bibnamefont {Hanin}},
  \bibinfo {author} {\bibfnamefont {D.}~\bibnamefont {Marinucci}}, \bibinfo
  {author} {\bibfnamefont {I.}~\bibnamefont {Nourdin}},\ and\ \bibinfo {author}
  {\bibfnamefont {G.}~\bibnamefont {Peccati}},\ }\bibfield  {title} {\bibinfo
  {title} {Quantitative clts in deep neural networks},\ }\href@noop {}
  {\bibfield  {journal} {\bibinfo  {journal} {arXiv preprint arXiv:2307.06092}\
  } (\bibinfo {year} {2023})}\BibitemShut {NoStop}%
\bibitem [{\citenamefont {Cagnetta}\ \emph {et~al.}(2023)\citenamefont
  {Cagnetta}, \citenamefont {Favero},\ and\ \citenamefont
  {Wyart}}]{cagnetta2023what}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {F.}~\bibnamefont
  {Cagnetta}}, \bibinfo {author} {\bibfnamefont {A.}~\bibnamefont {Favero}},\
  and\ \bibinfo {author} {\bibfnamefont {M.}~\bibnamefont {Wyart}},\ }\href
  {https://openreview.net/forum?id=m3QhpKNXU6-} {\bibinfo {title} {What can be
  learnt with wide convolutional neural networks?}} (\bibinfo {year}
  {2023})\BibitemShut {NoStop}%
\bibitem [{\citenamefont {Favero}\ \emph {et~al.}(2021)\citenamefont {Favero},
  \citenamefont {Cagnetta},\ and\ \citenamefont {Wyart}}]{favero2021locality}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {A.}~\bibnamefont
  {Favero}}, \bibinfo {author} {\bibfnamefont {F.}~\bibnamefont {Cagnetta}},\
  and\ \bibinfo {author} {\bibfnamefont {M.}~\bibnamefont {Wyart}},\ }\bibfield
   {title} {\bibinfo {title} {Locality defeats the curse of dimensionality in
  convolutional teacher-student scenarios},\ }in\ \href
  {https://openreview.net/forum?id=sBBnfOFtPc} {\emph {\bibinfo {booktitle}
  {Advances in Neural Information Processing Systems}}},\ \bibinfo {editor}
  {edited by\ \bibinfo {editor} {\bibfnamefont {A.}~\bibnamefont
  {Beygelzimer}}, \bibinfo {editor} {\bibfnamefont {Y.}~\bibnamefont
  {Dauphin}}, \bibinfo {editor} {\bibfnamefont {P.}~\bibnamefont {Liang}},\
  and\ \bibinfo {editor} {\bibfnamefont {J.~W.}\ \bibnamefont {Vaughan}}}\
  (\bibinfo {year} {2021})\BibitemShut {NoStop}%
\bibitem [{\citenamefont {Petrini}\ \emph {et~al.}(2022)\citenamefont
  {Petrini}, \citenamefont {Cagnetta}, \citenamefont {Vanden-Eijnden},\ and\
  \citenamefont {Wyart}}]{petrini2022learning}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {L.}~\bibnamefont
  {Petrini}}, \bibinfo {author} {\bibfnamefont {F.}~\bibnamefont {Cagnetta}},
  \bibinfo {author} {\bibfnamefont {E.}~\bibnamefont {Vanden-Eijnden}},\ and\
  \bibinfo {author} {\bibfnamefont {M.}~\bibnamefont {Wyart}},\ }\bibfield
  {title} {\bibinfo {title} {Learning sparse features can lead to overfitting
  in neural networks},\ }in\ \href
  {https://openreview.net/forum?id=dZEZu7zxJBF} {\emph {\bibinfo {booktitle}
  {Advances in Neural Information Processing Systems}}},\ \bibinfo {editor}
  {edited by\ \bibinfo {editor} {\bibfnamefont {A.~H.}\ \bibnamefont {Oh}},
  \bibinfo {editor} {\bibfnamefont {A.}~\bibnamefont {Agarwal}}, \bibinfo
  {editor} {\bibfnamefont {D.}~\bibnamefont {Belgrave}},\ and\ \bibinfo
  {editor} {\bibfnamefont {K.}~\bibnamefont {Cho}}}\ (\bibinfo {year}
  {2022})\BibitemShut {NoStop}%
\bibitem [{\citenamefont {Ariosto}\ \emph {et~al.}(2022)\citenamefont
  {Ariosto}, \citenamefont {Pacelli}, \citenamefont {Pastore}, \citenamefont
  {Ginelli}, \citenamefont {Gherardi},\ and\ \citenamefont
  {Rotondo}}]{ariosto2022statistical}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {S.}~\bibnamefont
  {Ariosto}}, \bibinfo {author} {\bibfnamefont {R.}~\bibnamefont {Pacelli}},
  \bibinfo {author} {\bibfnamefont {M.}~\bibnamefont {Pastore}}, \bibinfo
  {author} {\bibfnamefont {F.}~\bibnamefont {Ginelli}}, \bibinfo {author}
  {\bibfnamefont {M.}~\bibnamefont {Gherardi}},\ and\ \bibinfo {author}
  {\bibfnamefont {P.}~\bibnamefont {Rotondo}},\ }\bibfield  {title} {\bibinfo
  {title} {Statistical mechanics of deep learning beyond the infinite-width
  limit},\ }\href@noop {} {\bibfield  {journal} {\bibinfo  {journal} {arXiv
  preprint arXiv:2209.04882}\ } (\bibinfo {year} {2022})}\BibitemShut {NoStop}%
\bibitem [{\citenamefont {Li}\ and\ \citenamefont
  {Sompolinsky}(2021)}]{SompolinskyLinear}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {Q.}~\bibnamefont
  {Li}}\ and\ \bibinfo {author} {\bibfnamefont {H.}~\bibnamefont
  {Sompolinsky}},\ }\bibfield  {title} {\bibinfo {title} {Statistical mechanics
  of deep linear neural networks: The backpropagating kernel renormalization},\
  }\href {https://doi.org/10.1103/PhysRevX.11.031059} {\bibfield  {journal}
  {\bibinfo  {journal} {Phys. Rev. X}\ }\textbf {\bibinfo {volume} {11}},\
  \bibinfo {pages} {031059} (\bibinfo {year} {2021})}\BibitemShut {NoStop}%
\bibitem [{\citenamefont {Hanin}\ and\ \citenamefont
  {Zlokapa}(2023)}]{doi:10.1073/pnas.2301345120}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {B.}~\bibnamefont
  {Hanin}}\ and\ \bibinfo {author} {\bibfnamefont {A.}~\bibnamefont
  {Zlokapa}},\ }\bibfield  {title} {\bibinfo {title} {Bayesian interpolation
  with deep linear networks},\ }\href {https://doi.org/10.1073/pnas.2301345120}
  {\bibfield  {journal} {\bibinfo  {journal} {Proceedings of the National
  Academy of Sciences}\ }\textbf {\bibinfo {volume} {120}},\ \bibinfo {pages}
  {e2301345120} (\bibinfo {year} {2023})},\ \Eprint
  {https://arxiv.org/abs/https://www.pnas.org/doi/pdf/10.1073/pnas.2301345120}
  {https://www.pnas.org/doi/pdf/10.1073/pnas.2301345120} \BibitemShut {NoStop}%
\bibitem [{\citenamefont {Li}\ and\ \citenamefont
  {Sompolinsky}(2022)}]{li2022globally}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {Q.}~\bibnamefont
  {Li}}\ and\ \bibinfo {author} {\bibfnamefont {H.}~\bibnamefont
  {Sompolinsky}},\ }\bibfield  {title} {\bibinfo {title} {Globally gated deep
  linear networks},\ }\href@noop {} {\bibfield  {journal} {\bibinfo  {journal}
  {arXiv preprint arXiv:2210.17449}\ } (\bibinfo {year} {2022})}\BibitemShut
  {NoStop}%
\bibitem [{\citenamefont {Mei}\ and\ \citenamefont
  {Montanari}(2019)}]{mei2019}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {S.}~\bibnamefont
  {Mei}}\ and\ \bibinfo {author} {\bibfnamefont {A.}~\bibnamefont
  {Montanari}},\ }\bibfield  {title} {\bibinfo {title} {The generalization
  error of random features regression: Precise asymptotics and the double
  descent curve},\ }\href {https://doi.org/10.1002/cpa.22008} {\bibfield
  {journal} {\bibinfo  {journal} {Communications on Pure and Applied
  Mathematics}\ } (\bibinfo {year} {2019})}\BibitemShut {NoStop}%
\bibitem [{\citenamefont {Goldt}\ \emph {et~al.}(2020)\citenamefont {Goldt},
  \citenamefont {Loureiro}, \citenamefont {Reeves}, \citenamefont {Krzakala},
  \citenamefont {M{\'e}zard},\ and\ \citenamefont
  {Zdeborov{\'a}}}]{goldt2020gaussian}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {S.}~\bibnamefont
  {Goldt}}, \bibinfo {author} {\bibfnamefont {B.}~\bibnamefont {Loureiro}},
  \bibinfo {author} {\bibfnamefont {G.}~\bibnamefont {Reeves}}, \bibinfo
  {author} {\bibfnamefont {F.}~\bibnamefont {Krzakala}}, \bibinfo {author}
  {\bibfnamefont {M.}~\bibnamefont {M{\'e}zard}},\ and\ \bibinfo {author}
  {\bibfnamefont {L.}~\bibnamefont {Zdeborov{\'a}}},\ }\bibfield  {title}
  {\bibinfo {title} {The gaussian equivalence of generative models for learning
  with shallow neural networks},\ }\href@noop {} {\bibfield  {journal}
  {\bibinfo  {journal} {arXiv preprint arXiv:2006.14709}\ } (\bibinfo {year}
  {2020})}\BibitemShut {NoStop}%
\bibitem [{\citenamefont {Gerace}\ \emph {et~al.}(2021)\citenamefont {Gerace},
  \citenamefont {Loureiro}, \citenamefont {Krzakala}, \citenamefont {Mézard},\
  and\ \citenamefont {Zdeborová}}]{Gerace_2021}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {F.}~\bibnamefont
  {Gerace}}, \bibinfo {author} {\bibfnamefont {B.}~\bibnamefont {Loureiro}},
  \bibinfo {author} {\bibfnamefont {F.}~\bibnamefont {Krzakala}}, \bibinfo
  {author} {\bibfnamefont {M.}~\bibnamefont {Mézard}},\ and\ \bibinfo {author}
  {\bibfnamefont {L.}~\bibnamefont {Zdeborová}},\ }\bibfield  {title}
  {\bibinfo {title} {Generalisation error in learning with random features and
  the hidden manifold model},\ }\href
  {https://doi.org/10.1088/1742-5468/ac3ae6} {\bibfield  {journal} {\bibinfo
  {journal} {Journal of Statistical Mechanics: Theory and Experiment}\ }\textbf
  {\bibinfo {volume} {2021}},\ \bibinfo {pages} {124013} (\bibinfo {year}
  {2021})}\BibitemShut {NoStop}%
\bibitem [{\citenamefont {Loureiro}\ \emph {et~al.}(2021)\citenamefont
  {Loureiro}, \citenamefont {Gerbelot}, \citenamefont {Cui}, \citenamefont
  {Goldt}, \citenamefont {Krzakala}, \citenamefont {Mezard},\ and\
  \citenamefont {Zdeborov{\'a}}}]{loureiro2021learning}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {B.}~\bibnamefont
  {Loureiro}}, \bibinfo {author} {\bibfnamefont {C.}~\bibnamefont {Gerbelot}},
  \bibinfo {author} {\bibfnamefont {H.}~\bibnamefont {Cui}}, \bibinfo {author}
  {\bibfnamefont {S.}~\bibnamefont {Goldt}}, \bibinfo {author} {\bibfnamefont
  {F.}~\bibnamefont {Krzakala}}, \bibinfo {author} {\bibfnamefont
  {M.}~\bibnamefont {Mezard}},\ and\ \bibinfo {author} {\bibfnamefont
  {L.}~\bibnamefont {Zdeborov{\'a}}},\ }\bibfield  {title} {\bibinfo {title}
  {Learning curves of generic features maps for realistic datasets with a
  teacher-student model},\ }\href@noop {} {\bibfield  {journal} {\bibinfo
  {journal} {Advances in Neural Information Processing Systems}\ }\textbf
  {\bibinfo {volume} {34}} (\bibinfo {year} {2021})}\BibitemShut {NoStop}%
\bibitem [{\citenamefont {Breuer}\ and\ \citenamefont {Major}(1983)}]{BM}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {P.}~\bibnamefont
  {Breuer}}\ and\ \bibinfo {author} {\bibfnamefont {P.}~\bibnamefont {Major}},\
  }\bibfield  {title} {\bibinfo {title} {Central limit theorems for non-linear
  functionals of gaussian fields},\ }\href
  {https://doi.org/10.1016/0047-259X(83)90019-2} {\bibfield  {journal}
  {\bibinfo  {journal} {Journal of Multivariate Analysis}\ }\textbf {\bibinfo
  {volume} {13}},\ \bibinfo {pages} {425} (\bibinfo {year} {1983})}\BibitemShut
  {NoStop}%
\bibitem [{\citenamefont {Shah}\ \emph {et~al.}(2014)\citenamefont {Shah},
  \citenamefont {Wilson},\ and\ \citenamefont {Ghahramani}}]{Shah2014}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {A.}~\bibnamefont
  {Shah}}, \bibinfo {author} {\bibfnamefont {A.}~\bibnamefont {Wilson}},\ and\
  \bibinfo {author} {\bibfnamefont {Z.}~\bibnamefont {Ghahramani}},\ }\bibfield
   {title} {\bibinfo {title} {{Student-t Processes as Alternatives to Gaussian
  Processes}},\ }in\ \href {https://proceedings.mlr.press/v33/shah14.html}
  {\emph {\bibinfo {booktitle} {Proceedings of the Seventeenth International
  Conference on Artificial Intelligence and Statistics}}},\ \bibinfo {series}
  {Proceedings of Machine Learning Research}, Vol.~\bibinfo {volume} {33},\
  \bibinfo {editor} {edited by\ \bibinfo {editor} {\bibfnamefont
  {S.}~\bibnamefont {Kaski}}\ and\ \bibinfo {editor} {\bibfnamefont
  {J.}~\bibnamefont {Corander}}}\ (\bibinfo  {publisher} {PMLR},\ \bibinfo
  {address} {Reykjavik, Iceland},\ \bibinfo {year} {2014})\ pp.\ \bibinfo
  {pages} {877--885}\BibitemShut {NoStop}%
\bibitem [{\citenamefont {Cui}\ \emph {et~al.}(2023)\citenamefont {Cui},
  \citenamefont {Krzakala},\ and\ \citenamefont
  {Zdeborov{\'a}}}]{cui2023optimal}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {H.}~\bibnamefont
  {Cui}}, \bibinfo {author} {\bibfnamefont {F.}~\bibnamefont {Krzakala}},\ and\
  \bibinfo {author} {\bibfnamefont {L.}~\bibnamefont {Zdeborov{\'a}}},\
  }\bibfield  {title} {\bibinfo {title} {Optimal learning of deep random
  networks of extensive-width},\ }\href@noop {} {\bibfield  {journal} {\bibinfo
   {journal} {arXiv preprint arXiv:2302.00375}\ } (\bibinfo {year}
  {2023})}\BibitemShut {NoStop}%
\bibitem [{\citenamefont {Schr{\"o}der}\ \emph {et~al.}(2023)\citenamefont
  {Schr{\"o}der}, \citenamefont {Cui}, \citenamefont {Dmitriev},\ and\
  \citenamefont {Loureiro}}]{schroder2023deterministic}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {D.}~\bibnamefont
  {Schr{\"o}der}}, \bibinfo {author} {\bibfnamefont {H.}~\bibnamefont {Cui}},
  \bibinfo {author} {\bibfnamefont {D.}~\bibnamefont {Dmitriev}},\ and\
  \bibinfo {author} {\bibfnamefont {B.}~\bibnamefont {Loureiro}},\ }\bibfield
  {title} {\bibinfo {title} {Deterministic equivalent and error universality of
  deep random features learning},\ }\href@noop {} {\bibfield  {journal}
  {\bibinfo  {journal} {arXiv preprint arXiv:2302.00401}\ } (\bibinfo {year}
  {2023})}\BibitemShut {NoStop}%
\bibitem [{\citenamefont {Camilli}\ \emph {et~al.}(2023)\citenamefont
  {Camilli}, \citenamefont {Tieplova},\ and\ \citenamefont
  {Barbier}}]{camilli2023fundamental}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {F.}~\bibnamefont
  {Camilli}}, \bibinfo {author} {\bibfnamefont {D.}~\bibnamefont {Tieplova}},\
  and\ \bibinfo {author} {\bibfnamefont {J.}~\bibnamefont {Barbier}},\
  }\bibfield  {title} {\bibinfo {title} {Fundamental limits of overparametrized
  shallow neural networks for supervised learning},\ }\href@noop {} {\bibfield
  {journal} {\bibinfo  {journal} {arXiv preprint arXiv:2307.05635}\ } (\bibinfo
  {year} {2023})}\BibitemShut {NoStop}%
\bibitem [{\citenamefont {Guerra}\ and\ \citenamefont
  {Toninelli}(2002)}]{guerra2002thermodynamic}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {F.}~\bibnamefont
  {Guerra}}\ and\ \bibinfo {author} {\bibfnamefont {F.~L.}\ \bibnamefont
  {Toninelli}},\ }\bibfield  {title} {\bibinfo {title} {The thermodynamic limit
  in mean field spin glass models},\ }\href
  {https://doi.org/10.1007/s00220-002-0699-y} {\bibfield  {journal} {\bibinfo
  {journal} {Communications in Mathematical Physics}\ }\textbf {\bibinfo
  {volume} {230}},\ \bibinfo {pages} {71} (\bibinfo {year} {2002})}\BibitemShut
  {NoStop}%
\bibitem [{\citenamefont {Agliari}\ \emph {et~al.}(2020)\citenamefont
  {Agliari}, \citenamefont {Alemanno}, \citenamefont {Barra},\ and\
  \citenamefont {Fachechi}}]{AGLIARI2020254}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {E.}~\bibnamefont
  {Agliari}}, \bibinfo {author} {\bibfnamefont {F.}~\bibnamefont {Alemanno}},
  \bibinfo {author} {\bibfnamefont {A.}~\bibnamefont {Barra}},\ and\ \bibinfo
  {author} {\bibfnamefont {A.}~\bibnamefont {Fachechi}},\ }\bibfield  {title}
  {\bibinfo {title} {Generalized guerra’s interpolation schemes for dense
  associative neural networks},\ }\href
  {https://doi.org/https://doi.org/10.1016/j.neunet.2020.05.009} {\bibfield
  {journal} {\bibinfo  {journal} {Neural Networks}\ }\textbf {\bibinfo {volume}
  {128}},\ \bibinfo {pages} {254} (\bibinfo {year} {2020})}\BibitemShut
  {NoStop}%
\bibitem [{\citenamefont {Ingrosso}\ and\ \citenamefont
  {Goldt}(2022)}]{doi:10.1073/pnas.2201854119}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {A.}~\bibnamefont
  {Ingrosso}}\ and\ \bibinfo {author} {\bibfnamefont {S.}~\bibnamefont
  {Goldt}},\ }\bibfield  {title} {\bibinfo {title} {Data-driven emergence of
  convolutional structure in neural networks},\ }\href
  {https://doi.org/10.1073/pnas.2201854119} {\bibfield  {journal} {\bibinfo
  {journal} {Proceedings of the National Academy of Sciences}\ }\textbf
  {\bibinfo {volume} {119}},\ \bibinfo {pages} {e2201854119} (\bibinfo {year}
  {2022})},\ \Eprint
  {https://arxiv.org/abs/https://www.pnas.org/doi/pdf/10.1073/pnas.2201854119}
  {https://www.pnas.org/doi/pdf/10.1073/pnas.2201854119} \BibitemShut {NoStop}%
\bibitem [{\citenamefont {Kingma}\ and\ \citenamefont {Ba}(2014)}]{adam}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {D.~P.}\ \bibnamefont
  {Kingma}}\ and\ \bibinfo {author} {\bibfnamefont {J.}~\bibnamefont {Ba}},\
  }\bibfield  {title} {\bibinfo {title} {Adam: A method for stochastic
  optimization},\ }\href@noop {} {\bibfield  {journal} {\bibinfo  {journal}
  {arXiv preprint arXiv:1412.6980}\ } (\bibinfo {year} {2014})}\BibitemShut
  {NoStop}%
\bibitem [{\citenamefont {Abadi}\ \emph {et~al.}(2015)\citenamefont {Abadi},
  \citenamefont {Agarwal}, \citenamefont {Barham}, \citenamefont {Brevdo},
  \citenamefont {Chen}, \citenamefont {Citro}, \citenamefont {Corrado},
  \citenamefont {Davis}, \citenamefont {Dean}, \citenamefont {Devin},
  \citenamefont {Ghemawat}, \citenamefont {Goodfellow}, \citenamefont {Harp},
  \citenamefont {Irving}, \citenamefont {Isard}, \citenamefont {Jia},
  \citenamefont {Jozefowicz}, \citenamefont {Kaiser}, \citenamefont {Kudlur},
  \citenamefont {Levenberg}, \citenamefont {Man\'{e}}, \citenamefont {Monga},
  \citenamefont {Moore}, \citenamefont {Murray}, \citenamefont {Olah},
  \citenamefont {Schuster}, \citenamefont {Shlens}, \citenamefont {Steiner},
  \citenamefont {Sutskever}, \citenamefont {Talwar}, \citenamefont {Tucker},
  \citenamefont {Vanhoucke}, \citenamefont {Vasudevan}, \citenamefont
  {Vi\'{e}gas}, \citenamefont {Vinyals}, \citenamefont {Warden}, \citenamefont
  {Wattenberg}, \citenamefont {Wicke}, \citenamefont {Yu},\ and\ \citenamefont
  {Zheng}}]{tensorflow2015-whitepaper}%
  \BibitemOpen
  \bibfield  {author} {\bibinfo {author} {\bibfnamefont {M.}~\bibnamefont
  {Abadi}}, \bibinfo {author} {\bibfnamefont {A.}~\bibnamefont {Agarwal}},
  \bibinfo {author} {\bibfnamefont {P.}~\bibnamefont {Barham}}, \bibinfo
  {author} {\bibfnamefont {E.}~\bibnamefont {Brevdo}}, \bibinfo {author}
  {\bibfnamefont {Z.}~\bibnamefont {Chen}}, \bibinfo {author} {\bibfnamefont
  {C.}~\bibnamefont {Citro}}, \bibinfo {author} {\bibfnamefont {G.~S.}\
  \bibnamefont {Corrado}}, \bibinfo {author} {\bibfnamefont {A.}~\bibnamefont
  {Davis}}, \bibinfo {author} {\bibfnamefont {J.}~\bibnamefont {Dean}},
  \bibinfo {author} {\bibfnamefont {M.}~\bibnamefont {Devin}}, \bibinfo
  {author} {\bibfnamefont {S.}~\bibnamefont {Ghemawat}}, \bibinfo {author}
  {\bibfnamefont {I.}~\bibnamefont {Goodfellow}}, \bibinfo {author}
  {\bibfnamefont {A.}~\bibnamefont {Harp}}, \bibinfo {author} {\bibfnamefont
  {G.}~\bibnamefont {Irving}}, \bibinfo {author} {\bibfnamefont
  {M.}~\bibnamefont {Isard}}, \bibinfo {author} {\bibfnamefont
  {Y.}~\bibnamefont {Jia}}, \bibinfo {author} {\bibfnamefont {R.}~\bibnamefont
  {Jozefowicz}}, \bibinfo {author} {\bibfnamefont {L.}~\bibnamefont {Kaiser}},
  \bibinfo {author} {\bibfnamefont {M.}~\bibnamefont {Kudlur}}, \bibinfo
  {author} {\bibfnamefont {J.}~\bibnamefont {Levenberg}}, \bibinfo {author}
  {\bibfnamefont {D.}~\bibnamefont {Man\'{e}}}, \bibinfo {author}
  {\bibfnamefont {R.}~\bibnamefont {Monga}}, \bibinfo {author} {\bibfnamefont
  {S.}~\bibnamefont {Moore}}, \bibinfo {author} {\bibfnamefont
  {D.}~\bibnamefont {Murray}}, \bibinfo {author} {\bibfnamefont
  {C.}~\bibnamefont {Olah}}, \bibinfo {author} {\bibfnamefont {M.}~\bibnamefont
  {Schuster}}, \bibinfo {author} {\bibfnamefont {J.}~\bibnamefont {Shlens}},
  \bibinfo {author} {\bibfnamefont {B.}~\bibnamefont {Steiner}}, \bibinfo
  {author} {\bibfnamefont {I.}~\bibnamefont {Sutskever}}, \bibinfo {author}
  {\bibfnamefont {K.}~\bibnamefont {Talwar}}, \bibinfo {author} {\bibfnamefont
  {P.}~\bibnamefont {Tucker}}, \bibinfo {author} {\bibfnamefont
  {V.}~\bibnamefont {Vanhoucke}}, \bibinfo {author} {\bibfnamefont
  {V.}~\bibnamefont {Vasudevan}}, \bibinfo {author} {\bibfnamefont
  {F.}~\bibnamefont {Vi\'{e}gas}}, \bibinfo {author} {\bibfnamefont
  {O.}~\bibnamefont {Vinyals}}, \bibinfo {author} {\bibfnamefont
  {P.}~\bibnamefont {Warden}}, \bibinfo {author} {\bibfnamefont
  {M.}~\bibnamefont {Wattenberg}}, \bibinfo {author} {\bibfnamefont
  {M.}~\bibnamefont {Wicke}}, \bibinfo {author} {\bibfnamefont
  {Y.}~\bibnamefont {Yu}},\ and\ \bibinfo {author} {\bibfnamefont
  {X.}~\bibnamefont {Zheng}},\ }\href {https://www.tensorflow.org/} {\bibinfo
  {title} {{TensorFlow}: Large-scale machine learning on heterogeneous
  systems}} (\bibinfo {year} {2015}),\ \bibinfo {note} {software available from
  tensorflow.org}\BibitemShut {NoStop}%
\end{thebibliography}%
