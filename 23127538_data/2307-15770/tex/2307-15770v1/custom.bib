% Use this file for citations not found in the ACL Anthology (contained in "anthology.bib").

@book{Aho:72,
    author  = {Alfred V. Aho and Jeffrey D. Ullman},
    title   = {The Theory of Parsing, Translation and Compiling},
    year    = "1972",
    volume  = "1",
    publisher = {Prentice-Hall},
    address = {Englewood Cliffs, NJ}
}

@book{APA:83,
    author  = {{American Psychological Association}},
    title   = {Publications Manual},
    year    = "1983",
    publisher = {American Psychological Association},
    address = {Washington, DC}
}

@article{Chandra:81,
	author = {Ashok K. Chandra and Dexter C. Kozen and Larry J. Stockmeyer},
	year = "1981",
	title = {Alternation},
	journal = {Journal of the Association for Computing Machinery},
	volume = "28",
	number = "1",
	pages = "114--133",
	doi = "10.1145/322234.322243",
}

@inproceedings{andrew2007scalable,
  title={Scalable training of {$L_1$}-regularized log-linear models},
  author={Andrew, Galen and Gao, Jianfeng},
  booktitle={Proceedings of the 24th International Conference on Machine Learning},
  pages={33--40},
  year={2007},
  url={https://dl.acm.org/doi/abs/10.1145/1273496.1273501}
}

@book{Gusfield:97,
    author  = {Dan Gusfield},
    title   = {Algorithms on Strings, Trees and Sequences},
    year    = "1997",
    publisher = {Cambridge University Press},
    address = {Cambridge, UK},
    url={https://www.cambridge.org/core/books/algorithms-on-strings-trees-and-sequences/F0B095049C7E6EF5356F0A26686C20D3}
}

@article{rasooli-tetrault-2015,
    author    = {Mohammad Sadegh Rasooli and Joel R. Tetreault},
    title     = {Yara Parser: {A} Fast and Accurate Dependency Parser},
    journal   = {Computing Research Repository},
    volume    = {arXiv:1503.06733},
    year      = {2015},
    url       = {http://arxiv.org/abs/1503.06733},
    note    = {version 2}
}

@article{Ando2005,
	Acmid = {1194905},
	Author = {Ando, Rie Kubota and Zhang, Tong},
	Issn = {1532-4435},
	Issue_Date = {12/1/2005},
	Journal = {Journal of Machine Learning Research},
	Month = dec,
	Numpages = {37},
	Pages = {1817--1853},
	Publisher = {JMLR.org},
	Title = {A Framework for Learning Predictive Structures from Multiple Tasks and Unlabeled Data},
	Volume = {6},
	Year = {2005},
	url={https://www.jmlr.org/papers/volume6/ando05a/ando05a.pdf}
}

@article{ct1965,
  title={An algorithm for the machine calculation of complex {F}ourier series},
  author={Cooley, James W. and Tukey, John W.},
  journal={Mathematics of Computation},
  volume={19},
  number={90},
  pages={297--301},
  year={1965},
  url={https://www.ams.org/journals/mcom/1965-19-090/S0025-5718-1965-0178586-1/S0025-5718-1965-0178586-1.pdf}
}

@misc{johnson2017faiss,
      title={Billion-scale similarity search with GPUs}, 
      author={Jeff Johnson and Matthijs Douze and Hervé Jégou},
      year={2017},
      eprint={1702.08734},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{anil2023palm,
      title={PaLM 2 Technical Report}, 
      author={Rohan Anil and Andrew M. Dai and Orhan Firat and Melvin Johnson and Dmitry Lepikhin and Alexandre Passos and Siamak Shakeri and Emanuel Taropa and Paige Bailey and Zhifeng Chen and Eric Chu and Jonathan H. Clark and Laurent El Shafey and Yanping Huang and Kathy Meier-Hellstern and Gaurav Mishra and Erica Moreira and Mark Omernick and Kevin Robinson and Sebastian Ruder and Yi Tay and Kefan Xiao and Yuanzhong Xu and Yujing Zhang and Gustavo Hernandez Abrego and Junwhan Ahn and Jacob Austin and Paul Barham and Jan Botha and James Bradbury and Siddhartha Brahma and Kevin Brooks and Michele Catasta and Yong Cheng and Colin Cherry and Christopher A. Choquette-Choo and Aakanksha Chowdhery and Clément Crepy and Shachi Dave and Mostafa Dehghani and Sunipa Dev and Jacob Devlin and Mark Díaz and Nan Du and Ethan Dyer and Vlad Feinberg and Fangxiaoyu Feng and Vlad Fienber and Markus Freitag and Xavier Garcia and Sebastian Gehrmann and Lucas Gonzalez and Guy Gur-Ari and Steven Hand and Hadi Hashemi and Le Hou and Joshua Howland and Andrea Hu and Jeffrey Hui and Jeremy Hurwitz and Michael Isard and Abe Ittycheriah and Matthew Jagielski and Wenhao Jia and Kathleen Kenealy and Maxim Krikun and Sneha Kudugunta and Chang Lan and Katherine Lee and Benjamin Lee and Eric Li and Music Li and Wei Li and YaGuang Li and Jian Li and Hyeontaek Lim and Hanzhao Lin and Zhongtao Liu and Frederick Liu and Marcello Maggioni and Aroma Mahendru and Joshua Maynez and Vedant Misra and Maysam Moussalem and Zachary Nado and John Nham and Eric Ni and Andrew Nystrom and Alicia Parrish and Marie Pellat and Martin Polacek and Alex Polozov and Reiner Pope and Siyuan Qiao and Emily Reif and Bryan Richter and Parker Riley and Alex Castro Ros and Aurko Roy and Brennan Saeta and Rajkumar Samuel and Renee Shelby and Ambrose Slone and Daniel Smilkov and David R. So and Daniel Sohn and Simon Tokumine and Dasha Valter and Vijay Vasudevan and Kiran Vodrahalli and Xuezhi Wang and Pidong Wang and Zirui Wang and Tao Wang and John Wieting and Yuhuai Wu and Kelvin Xu and Yunhan Xu and Linting Xue and Pengcheng Yin and Jiahui Yu and Qiao Zhang and Steven Zheng and Ce Zheng and Weikang Zhou and Denny Zhou and Slav Petrov and Yonghui Wu},
      year={2023},
      eprint={2305.10403},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{Stammbach2023fact,
author = {Stammbach, Dominik and Zhang, Boya and Ash, Elliott},
title = {The Choice of Textual Knowledge Base in Automated Claim Checking},
year = {2023},
issue_date = {March 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {15},
number = {1},
issn = {1936-1955},
url = {https://doi.org/10.1145/3561389},
doi = {10.1145/3561389},
journal = {J. Data and Information Quality},
month = {mar},
articleno = {3},
numpages = {22}
}

@article{vaghefi2023chatclimate,
  title={Chatclimate: Grounding conversational AI in climate science},
  author={Vaghefi, Saeid Ashraf and Wang, Qian and Muccione, Veruska and Ni, Jingwei and Kraus, Mathias and Bingler, Julia and Schimanski, Tobias and Colesanti-Senni, Chiara and Stammbach, Dominik and Webersinke, Nicolas and others},
  year={2023}
}

@article{berg2022aggregate,
  title={Aggregate confusion: The divergence of ESG ratings},
  author={Berg, Florian and Koelbel, Julian F and Rigobon, Roberto},
  journal={Review of Finance},
  volume={26},
  number={6},
  pages={1315--1344},
  year={2022},
  publisher={Oxford University Press}
}

@inproceedings{jang2022towards,
  title={Towards Continual Knowledge Learning of Language Models},
  author={Jang, Joel and Ye, Seonghyeon and Yang, Sohee and Shin, Joongbo and Han, Janghoon and Kim, Gyeonghun and Choi, Stanley Jungkyu and Seo, Minjoon},
  booktitle={ICLR},
  year={2022}
}

@inproceedings{stochachstic_parrots,
author = {Bender, Emily M. and Gebru, Timnit and McMillan-Major, Angelina and Shmitchell, Shmargaret},
title = {On the Dangers of Stochastic Parrots: Can Language Models Be Too Big?},
year = {2021},
isbn = {9781450383097},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3442188.3445922},
doi = {10.1145/3442188.3445922},
abstract = {The past 3 years of work in NLP have been characterized by the development and deployment of ever larger language models, especially for English. BERT, its variants, GPT-2/3, and others, most recently Switch-C, have pushed the boundaries of the possible both through architectural innovations and through sheer size. Using these pretrained models and the methodology of fine-tuning them for specific tasks, researchers have extended the state of the art on a wide array of tasks as measured by leaderboards on specific benchmarks for English. In this paper, we take a step back and ask: How big is too big? What are the possible risks associated with this technology and what paths are available for mitigating those risks? We provide recommendations including weighing the environmental and financial costs first, investing resources into curating and carefully documenting datasets rather than ingesting everything on the web, carrying out pre-development exercises evaluating how the planned approach fits into research and development goals and supports stakeholder values, and encouraging research directions beyond ever larger language models.},
booktitle = {Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency},
pages = {610–623},
numpages = {14},
location = {Virtual Event, Canada},
series = {FAccT '21}
}

@misc{schick2021its,
      title={It's Not Just Size That Matters: Small Language Models Are Also Few-Shot Learners}, 
      author={Timo Schick and Hinrich Schütze},
      year={2021},
      eprint={2009.07118},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{kojima2023large,
      title={Large Language Models are Zero-Shot Reasoners}, 
      author={Takeshi Kojima and Shixiang Shane Gu and Machel Reid and Yutaka Matsuo and Yusuke Iwasawa},
      year={2023},
      eprint={2205.11916},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@inproceedings{prompt_programming,
author = {Reynolds, Laria and McDonell, Kyle},
title = {Prompt Programming for Large Language Models: Beyond the Few-Shot Paradigm},
year = {2021},
isbn = {9781450380959},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411763.3451760},
doi = {10.1145/3411763.3451760},
abstract = {Prevailing methods for mapping large generative language models to supervised tasks may fail to sufficiently probe models’ novel capabilities. Using GPT-3 as a case study, we show that 0-shot prompts can significantly outperform few-shot prompts. We suggest that the function of few-shot examples in these cases is better described as locating an already learned task rather than meta-learning. This analysis motivates rethinking the role of prompts in controlling and evaluating powerful language models. We discuss methods of prompt programming, emphasizing the usefulness of considering prompts through the lens of natural language. We explore techniques for exploiting the capacity of narratives and cultural anchors to encode nuanced intentions and techniques for encouraging deconstruction of a problem into components before producing a verdict. Informed by this more encompassing theory of prompt programming, we also introduce the idea of a metaprompt that seeds the model to generate its own natural language prompts for a range of tasks. Finally, we discuss how these more general methods of interacting with language models can be incorporated into existing and future benchmarks and practical applications.},
booktitle = {Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {314},
numpages = {7},
keywords = {serial reasoning, GPT-3, transformers, prompt programming, few-shot learning, language models, semiotics, metaprompts},
location = {Yokohama, Japan},
series = {CHI EA '21}
}

@article{guo-etal-2022-survey,
    title = "A Survey on Automated Fact-Checking",
    author = "Guo, Zhijiang  and
      Schlichtkrull, Michael  and
      Vlachos, Andreas",
    journal = "Transactions of the Association for Computational Linguistics",
    volume = "10",
    year = "2022",
    address = "Cambridge, MA",
    publisher = "MIT Press",
    url = "https://aclanthology.org/2022.tacl-1.11",
    doi = "10.1162/tacl_a_00454",
    pages = "178--206",
    abstract = "Fact-checking has become increasingly important due to the speed with which both information and misinformation can spread in the modern media ecosystem. Therefore, researchers have been exploring how fact-checking can be automated, using techniques based on natural language processing, machine learning, knowledge representation, and databases to automatically predict the veracity of claims. In this paper, we survey automated fact-checking stemming from natural language processing, and discuss its connections to related tasks and disciplines. In this process, we present an overview of existing datasets and models, aiming to unify the various definitions given and identify common concepts. Finally, we highlight challenges for future research.",
}

@article{acm_stammbach,
author = {Stammbach, Dominik and Zhang, Boya and Ash, Elliott},
title = {The Choice of Textual Knowledge Base in Automated Claim Checking},
year = {2023},
issue_date = {March 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {15},
number = {1},
issn = {1936-1955},
url = {https://doi.org/10.1145/3561389},
doi = {10.1145/3561389},
abstract = {Automated claim checking is the task of determining the veracity of a claim given evidence retrieved from a textual knowledge base of trustworthy facts. While previous work has taken the knowledge base as given and optimized the claim-checking pipeline, we take the opposite approach—taking the pipeline as given, we explore the choice of the knowledge base. Our first insight is that a claim-checking pipeline can be transferred to a new domain of claims with access to a knowledge base from the new domain. Second, we do not find a “universally best” knowledge base—higher domain overlap of a task dataset and a knowledge base tends to produce better label accuracy. Third, combining multiple knowledge bases does not tend to improve performance beyond using the closest-domain knowledge base. Finally, we show that the claim-checking pipeline’s confidence score for selecting evidence can be used to assess whether a knowledge base will perform well for a new set of claims, even in the absence of ground-truth labels.},
journal = {J. Data and Information Quality},
month = {mar},
articleno = {3},
numpages = {22},
keywords = {content management, evidence selection, Automated claim verification, information retrieval, textual knowledge bases}
}

@inproceedings{vlachos-riedel-2014-fact,
    title = "Fact Checking: Task definition and dataset construction",
    author = "Vlachos, Andreas  and
      Riedel, Sebastian",
    booktitle = "Proceedings of the {ACL} 2014 Workshop on Language Technologies and Computational Social Science",
    month = jun,
    year = "2014",
    address = "Baltimore, MD, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/W14-2508",
    doi = "10.3115/v1/W14-2508",
    pages = "18--22",
}



@inproceedings{vasvani_2017,
 author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, \L ukasz and Polosukhin, Illia},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {I. Guyon and U. Von Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Attention is All you Need},
 url = {https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf},
 volume = {30},
 year = {2017}
}

@misc{weidinger2021ethical,
      title={Ethical and social risks of harm from Language Models}, 
      author={Laura Weidinger and John Mellor and Maribeth Rauh and Conor Griffin and Jonathan Uesato and Po-Sen Huang and Myra Cheng and Mia Glaese and Borja Balle and Atoosa Kasirzadeh and Zac Kenton and Sasha Brown and Will Hawkins and Tom Stepleton and Courtney Biles and Abeba Birhane and Julia Haas and Laura Rimell and Lisa Anne Hendricks and William Isaac and Sean Legassick and Geoffrey Irving and Iason Gabriel},
      year={2021},
      eprint={2112.04359},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}


@misc{retro,
      title={Improving language models by retrieving from trillions of tokens}, 
      author={Sebastian Borgeaud and Arthur Mensch and Jordan Hoffmann and Trevor Cai and Eliza Rutherford and Katie Millican and George van den Driessche and Jean-Baptiste Lespiau and Bogdan Damoc and Aidan Clark and Diego de Las Casas and Aurelia Guy and Jacob Menick and Roman Ring and Tom Hennigan and Saffron Huang and Loren Maggiore and Chris Jones and Albin Cassirer and Andy Brock and Michela Paganini and Geoffrey Irving and Oriol Vinyals and Simon Osindero and Karen Simonyan and Jack W. Rae and Erich Elsen and Laurent Sifre},
      year={2022},
      eprint={2112.04426},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
@inproceedings{luger2016towards,
  title={Towards a framework for evaluation and design of conversational agents},
  author={Luger, Ewa and Sellen, Abigail},
  booktitle={Proceedings of the 2016 CHI Conference Extended Abstracts on Human Factors in Computing Systems},
  pages={2885--2891},
  year={2016},
  organization={ACM}
}

@article{abdar2020impact,
  title={The impact of chatbot characteristics on user satisfaction and conversational performance},
  author={Abdar, Moloud and Tait, Jonathan and Aleven, Vincent},
  journal={Journal of Educational Psychology},
  volume={112},
  number={4},
  pages={667--683},
  year={2020},
  publisher={American Psychological Association}
}

@article{diggelmann2020climate,
  title={Climate-fever: A dataset for verification of real-world climate claims},
  author={Diggelmann, Thomas and Boyd-Graber, Jordan and Bulian, Jannis and Ciaramita, Massimiliano and Leippold, Markus},
  journal={arXiv preprint arXiv:2012.00614},
  year={2020}
}

@inproceedings{ramachandran2020framework,
  title={A Framework for Understanding and Evaluating Automated Systems},
  author={Ramachandran, Darshini and Eslami, Mohammadreza and Sandvig, Christian},
  booktitle={Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency},
  pages={154--164},
  year={2020}
}

@article{PRZEGALINSKA2019785,
title = {In bot we trust: A new methodology of chatbot performance measures},
journal = {Business Horizons},
volume = {62},
number = {6},
pages = {785-797},
year = {2019},
note = {Digital Transformation and Disruption},
issn = {0007-6813},
doi = {https://doi.org/10.1016/j.bushor.2019.08.005},
url = {https://www.sciencedirect.com/science/article/pii/S000768131930117X},
author = {Aleksandra Przegalinska and Leon Ciechanowski and Anna Stroz and Peter Gloor and Grzegorz Mazurek}
}
@misc{openai2022chatgpt,
  title={ChatGPT: A Large-scale Generative Language Model for Conversational AI},
  author={OpenAI},
  year={2022}
}
@inproceedings{Shin_2021,
	doi = {10.1145/3448139.3448188},
	year = 2021,
	month = {apr},
	publisher = {ACM},
	author = {Dongmin Shin and Yugeun Shim and Hangyeol Yu and Seewoo Lee and Byungsoo Kim and Youngduck Choi},
	title = {{SAINT}$\mathplus$: Integrating Temporal Features for {EdNet} Correctness Prediction},
	booktitle = {11th International Learning Analytics and Knowledge Conference}
}
@misc{lin2023healthy,
      title={Towards Healthy AI: Large Language Models Need Therapists Too}, 
      author={Baihan Lin and Djallel Bouneffouf and Guillermo Cecchi and Kush R. Varshney},
      year={2023},
      eprint={2304.00416},
      archivePrefix={arXiv},
      primaryClass={cs.AI}
}

@misc{fan2023bibliometric,
      title={A Bibliometric Review of Large Language Models Research from 2017 to 2023}, 
      author={Lizhou Fan and Lingyao Li and Zihui Ma and Sanggyu Lee and Huizi Yu and Libby Hemphill},
      year={2023},
      eprint={2304.02020},
      archivePrefix={arXiv},
      primaryClass={cs.DL}
}

@misc{adiwardana2020humanlike,
      title={Towards a Human-like Open-Domain Chatbot}, 
      author={Daniel Adiwardana and Minh-Thang Luong and David R. So and Jamie Hall and Noah Fiedel and Romal Thoppilan and Zi Yang and Apoorv Kulshreshtha and Gaurav Nemade and Yifeng Lu and Quoc V. Le},
      year={2020},
      eprint={2001.09977},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{webersinke2022climatebert,
      title={ClimateBert: A Pretrained Language Model for Climate-Related Text}, 
      author={Nicolas Webersinke and Mathias Kraus and Julia Anna Bingler and Markus Leippold},
      year={2022},
      eprint={2110.12010},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{article,
author = {Callaghan, Max and Schleussner, Carl-Friedrich and Nath, Shruti and Lejeune, Quentin and Knutson, Thomas and Reichstein, Markus and Hansen, Gerrit and Theokritoff, Emily and Andrijevic, Marina and Brecha, R.J. and Hegarty, Michael and Jones, Chelsea and Lee, Kaylin and Lucas, Agathe and Maanen, Nicole and Menke, Inga and Pfleiderer, Peter and Yesil, Burcu and Minx, Jan},
year = {2021},
month = {11},
pages = {1-7},
title = {Machine-learning-based evidence and attribution mapping of 100,000 climate impact studies},
volume = {11},
journal = {Nature Climate Change},
doi = {10.1038/s41558-021-01168-6}
}

@misc{luccioni2020analyzing,
      title={Analyzing Sustainability Reports Using Natural Language Processing}, 
      author={Alexandra Luccioni and Emily Baylor and Nicolas Duchene},
      year={2020},
      eprint={2011.08073},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{gerhardyoung2022lowresource,
      title={Low-Resource Adaptation of Open-Domain Generative Chatbots}, 
      author={Greyson Gerhard-Young and Raviteja Anantha and Srinivas Chappidi and Björn Hoffmeister},
      year={2022},
      eprint={2108.06329},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{nair2023dera,
      title={DERA: Enhancing Large Language Model Completions with Dialog-Enabled Resolving Agents}, 
      author={Varun Nair and Elliot Schumacher and Geoffrey Tso and Anitha Kannan},
      year={2023},
      eprint={2303.17071},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{shen2023hugginggpt,
      title={HuggingGPT: Solving AI Tasks with ChatGPT and its Friends in HuggingFace}, 
      author={Yongliang Shen and Kaitao Song and Xu Tan and Dongsheng Li and Weiming Lu and Yueting Zhuang},
      year={2023},
      eprint={2303.17580},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{wu2023bloomberggpt,
      title={BloombergGPT: A Large Language Model for Finance}, 
      author={Shijie Wu and Ozan Irsoy and Steven Lu and Vadim Dabravolski and Mark Dredze and Sebastian Gehrmann and Prabhanjan Kambadur and David Rosenberg and Gideon Mann},
      year={2023},
      eprint={2303.17564},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{kraus2023enhancing,
      title={Enhancing Large Language Models with Climate Resources}, 
      author={Mathias Kraus and Julia Anna Bingler and Markus Leippold and Tobias Schimanski and Chiara Colesanti Senni and Dominik Stammbach and Saeid Ashraf Vaghefi and Nicolas Webersinke},
      year={2023},
      eprint={2304.00116},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{sethi2020importance,
  title={The importance of accurate and up-to-date information in the context of climate change},
  author={Sethi, Nitin and Singh, Shweta and Kumar, Ashish},
  journal={Journal of Cleaner Production},
  volume={277},
  pages={123304},
  year={2020},
  publisher={Elsevier}
}

@article{kumar2021climate,
  title={Climate change and cities: challenges ahead},
  author={Kumar, Ashish and Singh, Shweta and Sethi, Nitin},
  journal={Frontiers in Sustainable Cities},
  volume={3},
  pages={645613},
  year={2021},
  publisher={Frontiers}
}
@article{ipcc2022climateWG3,
  title={Climate Change 2022: Mitigation of Climate Change},
  author={IPCC},
  journal={Contribution of Working Group III to the Sixth Assessment Report of the Intergovernmental Panel on Climate Change},
  year={2022}
}
@article{ipcc2022climateWG2,
  title={Climate Change 2022: Impacts, Adaptation, and Vulnerability},
  author={IPCC},
  journal={Contribution of Working Group II to the Sixth Assessment Report of the Intergovernmental Panel on Climate Change},
  year={2022}
}
@article{ipcc2021climateWG1,
  title={Climate Change 2021: The Physical Science Basis},
  author={IPCC},
  journal={Contribution of Working Group I to the Sixth Assessment Report of the Intergovernmental Panel on Climate Change},
  year={2021}
}


@article{Ji_2023,
    title = {Survey of Hallucination in Natural Language Generation},
	url = {https://doi.org/10.1145%2F3571730},
	year = 2023,
	month = {mar},
    publisher = {Association for Computing Machine},
	volume = {55},
	number = {12},
	pages = {1--38},
	author = {Ziwei Ji and Nayeon Lee and Rita Frieske and Tiezheng Yu and Dan Su and Yan Xu and Etsuko Ishii and Ye Jin Bang and Andrea Madotto and Pascale Fung},
	journal = {ACMComputing Surveys},
    doi = {10.1145/3571730}
}

@misc{devlin2019bert,
      title={BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding}, 
      author={Jacob Devlin and Ming-Wei Chang and Kenton Lee and Kristina Toutanova},
      year={2019},
      eprint={1810.04805},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{shao2023prompting,
      title={Prompting Large Language Models with Answer Heuristics for Knowledge-based Visual Question Answering}, 
      author={Zhenwei Shao and Zhou Yu and Meng Wang and Jun Yu},
      year={2023},
      eprint={2303.01903},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{robinson2023leveraging,
      title={Leveraging Large Language Models for Multiple Choice Question Answering}, 
      author={Joshua Robinson and Christopher Michael Rytting and David Wingate},
      year={2023},
      eprint={2210.12353},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{li2022selfprompting,
      title={Self-Prompting Large Language Models for Open-Domain QA}, 
      author={Junlong Li and Zhuosheng Zhang and Hai Zhao},
      year={2022},
      eprint={2212.08635},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{lee2022plugandplay,
      title={Plug-and-Play Adaptation for Continuously-updated QA}, 
      author={Kyungjae Lee and Wookje Han and Seung-won Hwang and Hwaran Lee and Joonsuk Park and Sang-Woo Lee},
      year={2022},
      eprint={2204.12785},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

























 
@article{schick2020exploiting,
  title={Exploiting cloze questions for few shot text classification and natural language inference},
  author={Schick, Timo and Sch{\"u}tze, Hinrich},
  journal={arXiv preprint arXiv:2001.07676},
  year={2020}
}

@article{wu2023visual,
  title={Visual {chatGPT}: Talking, drawing and editing with visual foundation models},
  author={Wu, Chenfei and Yin, Shengming and Qi, Weizhen and Wang, Xiaodong and Tang, Zecheng and Duan, Nan},
  journal={arXiv preprint arXiv:2303.04671},
  year={2023}
}

@article{hendy2023good,
  title={How good are {GPT} models at machine translation? {A} comprehensive evaluation},
  author={Hendy, Amr and Abdelrehim, Mohamed and Sharaf, Amr and Raunak, Vikas and Gabr, Mohamed and Matsushita, Hitokazu and Kim, Young Jin and Afify, Mohamed and Awadalla, Hany Hassan},
  journal={arXiv preprint arXiv:2302.09210},
  year={2023}
}

@article{zheng2023progressive,
  title={Progressive-hint prompting improves reasoning in large language models},
  author={Zheng, Chuanyang and Liu, Zhengying and Xie, Enze and Li, Zhenguo and Li, Yu},
  journal={arXiv preprint arXiv:2304.09797},
  year={2023}
}

@article{wei2022chain,
  title={Chain of thought prompting elicits reasoning in large language models},
  author={Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Chi, Ed and Le, Quoc and Zhou, Denny},
  journal={arXiv preprint arXiv:2201.11903},
  year={2022}
}


@article{gao2020making,
  title={Making pre-trained language models better few-shot learners},
  author={Gao, Tianyu and Fisch, Adam and Chen, Danqi},
  journal={arXiv preprint arXiv:2012.15723},
  year={2020}
}
 

@article{schick2023toolformer,
  title={Toolformer: Language models can teach themselves to use tools},
  author={Schick, Timo and Dwivedi-Yu, Jane and Dess{\`\i}, Roberto and Raileanu, Roberta and Lomeli, Maria and Zettlemoyer, Luke and Cancedda, Nicola and Scialom, Thomas},
  journal={arXiv preprint arXiv:2302.04761},
  year={2023}
}

@article{ghazvininejad2023dictionary,
  title={Dictionary-based phrase-level prompting of large language models for machine translation},
  author={Ghazvininejad, Marjan and Gonen, Hila and Zettlemoyer, Luke},
  journal={arXiv preprint arXiv:2302.07856},
  year={2023}
}
@article{zhou2022large,
  title={Large language models are human-level prompt engineers},
  author={Zhou, Yongchao and Muresanu, Andrei Ioan and Han, Ziwen and Paster, Keiran and Pitis, Silviu and Chan, Harris and Ba, Jimmy},
  journal={arXiv preprint arXiv:2211.01910},
  year={2022}
}

@article{sanh2021multitask,
  title={Multitask prompted training enables zero-shot task generalization},
  author={Sanh, Victor and Webson, Albert and Raffel, Colin and Bach, Stephen H and Sutawika, Lintang and Alyafeai, Zaid and Chaffin, Antoine and Stiegler, Arnaud and Scao, Teven Le and Raja, Arun and others},
  journal={arXiv preprint arXiv:2110.08207},
  year={2021}
}

@article{bingler2022initiatives,
  title={Cheap talk in corporate climate commitments: The role of active institutional ownership, signaling, materiality, and sentiment},
  author={Bingler, Julia Anna and Kraus, Mathias and Leippold, Markus and Webersinke, Nicolas},
  journal={Swiss Finance Institute Research Paper},
  year={2022}
}

@inproceedings{wkbl2021,
    title={ClimateBERT: A Pretrained Language Model for Climate-Related Text},
    author={Webersinke, Nicolas and Kraus, Mathias and Bingler, Julia and Leippold, Markus},
    booktitle={Proceedings of AAAI 2022 Fall Symposium: The Role of AI in Responding to Climate Challenges},
    year={2022}
}

@article{stammbach2022dataset,
  title={Environmental Claim Detection},
  author={Stammbach, Dominik and Webersinke, Nicolas and Bingler, Julia Anna and Kraus, Mathias and Leippold, Markus},
  journal={Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics. Toronto, Canada},
  year={2023}
}

@article{bingler2022cheap,
  title={Cheap talk and cherry-picking: What {ClimateBert} has to say on corporate climate risk disclosures},
  author={Bingler, Julia Anna and Kraus, Mathias and Leippold, Markus and Webersinke, Nicolas},
  journal={Finance Research Letters},
  pages={102776},
  year={2022},
  publisher={Elsevier}
}

@article{hershcovich2022towards,
  title={Towards Climate Awareness in NLP Research},
  author={Hershcovich, Daniel and Webersinke, Nicolas and Kraus, Mathias and Bingler, Julia Anna and Leippold, Markus},
  journal={arXiv preprint arXiv:2205.05071},
  year={2022}
}

@article{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={1877--1901},
  year={2020}
}

@article{radford2019language,
title={Language Models are Unsupervised Multitask Learners},
author={Radford, Alec and Wu, Jeff and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya},
journal={OpenAI Blog},
year={2019}
}

@article{noauthor_sustainable_2019,
author = {Editorial},
	title = {Sustainable development through climate action},
	volume = {9},
	issn = {1758-6798},
	url = {https://doi.org/10.1038/s41558-019-0528-3},
	doi = {10.1038/s41558-019-0528-3},
	abstract = {Parties to the Paris Agreement must increase their ambition, but stringent climate policy has the potential to put sustainable development at risk. A collaborative effort is underway to identify potential trade-offs and to strengthen synergies between climate action and sustainable development.},
	number = {7},
	journal = {Nature Climate Change},
	month = jul,
	year = {2019},
	pages = {491--491},
}

@article{lenton2023quantifying,
  title={Quantifying the human cost of global warming},
  author={Lenton, Timothy M and Xu, Chi and Abrams, Jesse F and Ghadiali, Ashish and Loriani, Sina and Sakschewski, Boris and Zimm, Caroline and Ebi, Kristie L and Dunn, Robert R and Svenning, Jens-Christian and others},
  journal={Nature Sustainability},
  pages={1--11},
  year={2023},
  publisher={Nature Publishing Group UK London}
}

@article{sarfraz2023toward,
  title={Toward a new understanding of environmental and financial performance through corporate social responsibility, green innovation, and sustainable development},
  author={Sarfraz, Muddassar and Ozturk, Ilhan and Yoo, Sunghoon and Raza, Muhammad Ali and Han, Heesup},
  journal={Humanities and Social Sciences Communications},
  volume={10},
  number={1},
  pages={1--17},
  year={2023},
  publisher={Palgrave}
}

@article{soergel_sustainable_2021,
	title = {A sustainable development pathway for climate action within the {UN} 2030 {Agenda}},
	volume = {11},
	issn = {1758-6798},
	url = {https://doi.org/10.1038/s41558-021-01098-3},
	doi = {10.1038/s41558-021-01098-3},
	abstract = {Ambitious climate policies, as well as economic development, education, technological progress and less resource-intensive lifestyles, are crucial elements for progress towards the UN Sustainable Development Goals (SDGs). However, using an integrated modelling framework covering 56 indicators or proxies across all 17 SDGs, we show that they are insufficient to reach the targets. An additional sustainable development package, including international climate finance, progressive redistribution of carbon pricing revenues, sufficient and healthy nutrition and improved access to modern energy, enables a more comprehensive sustainable development pathway. We quantify climate and SDG outcomes, showing that these interventions substantially boost progress towards many aspects of the UN Agenda 2030 and simultaneously facilitate reaching ambitious climate targets. Nonetheless, several important gaps remain; for example, with respect to the eradication of extreme poverty (180 million people remaining in 2030). These gaps can be closed by 2050 for many SDGs while also respecting the 1.5 °C target and several other planetary boundaries.},
	number = {8},
	journal = {Nature Climate Change},
	author = {Soergel, Bjoern and Kriegler, Elmar and Weindl, Isabelle and Rauner, Sebastian and Dirnaichner, Alois and Ruhe, Constantin and Hofmann, Matthias and Bauer, Nico and Bertram, Christoph and Bodirsky, Benjamin Leon and Leimbach, Marian and Leininger, Julia and Levesque, Antoine and Luderer, Gunnar and Pehl, Michaja and Wingens, Christopher and Baumstark, Lavinia and Beier, Felicitas and Dietrich, Jan Philipp and Humpenöder, Florian and von Jeetze, Patrick and Klein, David and Koch, Johannes and Pietzcker, Robert and Strefler, Jessica and Lotze-Campen, Hermann and Popp, Alexander},
	month = aug,
	year = {2021},
	pages = {656--664},
}


@article{ouyang2022training,
  title={Training language models to follow instructions with human feedback},
  author={Ouyang, Long and Wu, Jeffrey and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and others},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={27730--27744},
  year={2022}
}
 

@article{jo2023promise,
  title={The Promise and Peril of Generative {AI}},
  author={Jo, Awe{\L}},
  journal={Nature},
  volume={614},
  year={2023}
}

@inproceedings{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  booktitle={Advances in Neural Information Processing Systems},
  pages={5998--6008},
  year={2017}
}

@article{touvron2023llama,
  title={Llama: Open and efficient foundation language models},
  author={Touvron, Hugo and Lavril, Thibaut and Izacard, Gautier and Martinet, Xavier and Lachaux, Marie-Anne and Lacroix, Timoth{\'e}e and Rozi{\`e}re, Baptiste and Goyal, Naman and Hambro, Eric and Azhar, Faisal and others},
  journal={arXiv preprint arXiv:2302.13971},
  year={2023}
}

@article{diaz2017quantifying,
  title={Quantifying the economic risks of climate change},
  author={Diaz, Delavane and Moore, Frances},
  journal={Nature Climate Change},
  volume={7},
  number={11},
  pages={774--782},
  year={2017},
  publisher={Nature Publishing Group UK London}
}

@techreport{gpt4techreport,
    title={GPT-4 Technical Report},
    author={OpenAI},
    year={2023},
    institution={OpenAI},
    url={https://cdn.openai.com/papers/gpt-4.pdf}
}

@article{board2017task,
  title={Recommendations of the Task Force on Climate-Related Financial Disclosures},
  author={{TCFD}},
  journal={Task force on climate-related financial disclosures},
  year={2017}
}

@article{tcfd2021,
  title={Implementing the Recommendations of the TCFD},
  author={{TCFD}},
  journal={Task force on climate-related financial disclosures},
  year={2021}
}

@article{brunetti2021climate,
  title={Climate Change and Financial Stability},
  author={Brunetti, Celso and Dennis, Benjamin and Gates, Dylan and Hancock, Diana and Ignell, David and Kiser, Elizabeth K and Kotta, Gurubala and Kovner, Anna and Rosen, Richard J and Tabor, Nicholas Kean},
  journal={Federal Reserve Notes},
  year={2021}
}

@article{mac2017role,
  title={The role of CO2 capture and utilization in mitigating climate change},
  author={Mac Dowell, Niall and Fennell, Paul S and Shah, Nilay and Maitland, Geoffrey C},
  journal={Nature climate change},
  volume={7},
  number={4},
  pages={243--249},
  year={2017},
  publisher={Nature Publishing Group UK London}
}

@article{tcfd_overview,
  title={Task force on climate-related financial disclosures: Overview},
  author={{Financial Stability Board}},
  journal={Task force on climate-related financial disclosures},
  year={2017}
}

@article{callaghan2021machine,
  title={Machine-learning-based evidence and attribution mapping of 100,000 climate impact studies},
  author={Callaghan, Max and Schleussner, Carl-Friedrich and Nath, Shruti and Lejeune, Quentin and Knutson, Thomas R and Reichstein, Markus and Hansen, Gerrit and Theokritoff, Emily and Andrijevic, Marina and Brecha, Robert J and others},
  journal={Nature climate change},
  volume={11},
  number={11},
  pages={966--972},
  year={2021},
  publisher={Nature Publishing Group}
}

@misc{instructgpt,
title={InstructGPT: AI for Generating Instructions},
author={OpenAI},
howpublished={https://openai.com/research/instructgpt/},
year={2023}
}

@article{liu2019roberta,
title={RoBERTa: A Robustly Optimized BERT Pretraining Approach},
author={Liu, Yinhan and Ott, Myle and Goyal, Naman and Du, Jingfei and Joshi, Mandar and Chen, Danqi and Levy, Omer and Lewis, Mike and Zettlemoyer, Luke and Stoyanov, Veselin},
journal={arXiv preprint arXiv:1907.11692},
year={2019}
}

@article{bender2021dangers,
title={Dangers of AI: LLMs, Inaccuracy, and the Need for Responsibility},
author={Bender, Emily M and Gebru, Timnit and McMillan-Major, Angelina and Shmitchell, Shomir},
journal={arXiv preprint arXiv:2108.10010},
year={2021}
}

@article{ipcc2018,
title={Global Warming of 1.5°C. An IPCC Special Report on the impacts of global warming of 1.5°C above pre-industrial levels and related global greenhouse gas emission pathways, in the context of strengthening the global response to the threat of climate change},
author={Masson-Delmotte, Valérie and Zhai, Panmao and Pörtner, Hans-Otto and Roberts, Debra and Skea, Jim and Shukla, Priyadarshi R and Pirani, Anna and Moufouma-Okia, Wilfran and Péan, Clotilde and Pidcock, Roz and others},
journal={Intergovernmental Panel on Climate Change},
year={2018}
}

@book{houghton2015global,
title={Global Warming: The Complete Briefing},
author={Houghton, John},
publisher={Cambridge University Press},
year={2015}
}

@book{stern2007economics,
title={The Economics of Climate Change: The Stern Review},
author={Stern, Nicholas},
publisher={Cambridge University Press},
year={2007}
}

@article{brohan2006uncertainty,
title={Uncertainty estimates in regional and global observed temperature changes: A new data set from 1850},
author={Brohan, Philip and Kennedy, John J and Harris, Ian and Tett, Simon FB and Jones, Phil D},
journal={Journal of Geophysical Research: Atmospheres},
volume={111},
number={D12},
year={2006}
}

@article{hao2019training,
  title={Training a single AI model can emit as much carbon as five cars in their lifetimes},
  author={Hao, Karen},
  journal={MIT technology Review},
  volume={75},
  pages={103},
  year={2019}
}

@article{hu2021lora,
  title={Lora: Low-rank adaptation of large language models},
  author={Hu, Edward J and Shen, Yelong and Wallis, Phillip and Allen-Zhu, Zeyuan and Li, Yuanzhi and Wang, Shean and Wang, Lu and Chen, Weizhu},
  journal={arXiv preprint arXiv:2106.09685},
  year={2021}
}

@article{dettmers2022llmint8,
  title={LLM.int8(): 8-bit Matrix Multiplication for Transformers at Scale},
  author={Dettmers, Tim and Lewis, Mike and Belkada, Younes and Zettlemoyer, Luke},
  journal={arXiv preprint arXiv:2208.07339},
  year={2022}
}

@article{dettmers2022optimizers,
  title={8-bit Optimizers via Block-wise Quantization},
  author={Dettmers, Tim and Lewis, Mike and Shleifer, Sam and Zettlemoyer, Luke},
  journal={9th International Conference on Learning Representations, ICLR},
  year={2022}
}

@misc{FLI2023,
  author = {{Future of Life Institute}},
  title = {Pause Giant AI Experiments: An Open Letter},
  year = {2023},
  howpublished = {https://futureoflife.org/pause-giant-ai-experiments/}
}

@article{edmans2016realcosts,
    author = {Edmans, Alex and Heinle, Mirko S. and Huang, Chong},
    title = "{The real costs of financial efficiency when some information is soft}",
    journal = {Review of Finance},
    volume = {20},
    number = {6},
    pages = {2151-2182},
    year = {2016},
    month = {06}
}

@article{chowdhery2022palm,
  title={Palm: Scaling language modeling with pathways},
  author={Chowdhery, Aakanksha and Narang, Sharan and Devlin, Jacob and Bosma, Maarten and Mishra, Gaurav and Roberts, Adam and Barham, Paul and Chung, Hyung Won and Sutton, Charles and Gehrmann, Sebastian and others},
  journal={arXiv preprint arXiv:2204.02311},
  year={2022}
}

 

@article{liang2023taskmatrixai,
      title={TaskMatrix.AI: Completing Tasks by Connecting Foundation Models with Millions of APIs}, 
      author={Yaobo Liang and Chenfei Wu and Ting Song and Wenshan Wu and Yan Xia and Yu Liu and Yang Ou and Shuai Lu and Lei Ji and Shaoguang Mao and Yun Wang and Linjun Shou and Ming Gong and Nan Duan},
      year={2023},
      journal={arXiv preprint arXiv:2303.16434},
}

@article{kolbel2020ask,
  title={Ask {BERT}: How regulatory disclosure of transition and physical climate risks affects the CDS term structure},
  author={K{\"o}lbel, Julian F and Leippold, Markus and Rillaerts, Jordy and Wang, Qian},
  journal={Available at SSRN 3616324},
  year={2020}
}

@article{chiang2023vicuna,
  title={Vicuna: An open-source chatbot impressing {GPT}-4 with 90\%* chatgpt quality},
  author={Chiang, Wei-Lin and Li, Zhuohan and Lin, Zi and Sheng, Ying and Wu, Zhanghao and Zhang, Hao and Zheng, Lianmin and Zhuang, Siyuan and Zhuang, Yonghao and Gonzalez, Joseph E and others},
  journal={See https://vicuna. lmsys. org (accessed 5 June 2023)},
  year={2023}
}

@article{peng2023instruction,
  title={Instruction tuning with {GPT}-4},
  author={Peng, Baolin and Li, Chunyuan and He, Pengcheng and Galley, Michel and Gao, Jianfeng},
  journal={arXiv preprint arXiv:2304.03277},
  year={2023}
}

@article{wang2023large,
  title={Large Language Models are not Fair Evaluators},
  author={Wang, Peiyi and Li, Lei and Chen, Liang and Zhu, Dawei and Lin, Binghuai and Cao, Yunbo and Liu, Qi and Liu, Tianyu and Sui, Zhifang},
  journal={arXiv preprint arXiv:2305.17926},
  year={2023}
}

@article{zhou2023lima,
  title={Lima: Less is more for alignment},
  author={Zhou, Chunting and Liu, Pengfei and Xu, Puxin and Iyer, Srini and Sun, Jiao and Mao, Yuning and Ma, Xuezhe and Efrat, Avia and Yu, Ping and Yu, Lili and others},
  journal={arXiv preprint arXiv:2305.11206},
  year={2023}
}

@misc{yue2023automatic,
      title={Automatic Evaluation of Attribution by Large Language Models}, 
      author={Xiang Yue and Boshi Wang and Kai Zhang and Ziru Chen and Yu Su and Huan Sun},
      year={2023},
      eprint={2305.06311},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{liu2023evaluating,
      title={Evaluating Verifiability in Generative Search Engines}, 
      author={Nelson F. Liu and Tianyi Zhang and Percy Liang},
      year={2023},
      eprint={2304.09848},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{peng2023check,
      title={Check Your Facts and Try Again: Improving Large Language Models with External Knowledge and Automated Feedback}, 
      author={Baolin Peng and Michel Galley and Pengcheng He and Hao Cheng and Yujia Xie and Yu Hu and Qiuyuan Huang and Lars Liden and Zhou Yu and Weizhu Chen and Jianfeng Gao},
      year={2023},
      eprint={2302.12813},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}


@misc{liSelfCheckerPlugandPlayModules2023,
	title = {Self-{Checker}: {Plug}-and-{Play} {Modules} for {Fact}-{Checking} with {Large} {Language} {Models}},
	shorttitle = {Self-{Checker}},
	url = {http://arxiv.org/abs/2305.14623},
	doi = {10.48550/arXiv.2305.14623},
	abstract = {Fact-checking is an essential task in NLP that is commonly utilized for validating the factual accuracy of claims. Prior work has mainly focused on fine-tuning pre-trained languages models on specific datasets, which can be computationally intensive and time-consuming. With the rapid development of large language models (LLMs), such as ChatGPT and GPT-3, researchers are now exploring their in-context learning capabilities for a wide range of tasks. In this paper, we aim to assess the capacity of LLMs for fact-checking by introducing Self-Checker, a framework comprising a set of plug-and-play modules that facilitate fact-checking by purely prompting LLMs in an almost zero-shot setting. This framework provides a fast and efficient way to construct fact-checking systems in low-resource environments. Empirical results demonstrate the potential of Self-Checker in utilizing LLMs for fact-checking. However, there is still significant room for improvement compared to SOTA fine-tuned models, which suggests that LLM adoption could be a promising approach for future fact-checking research.},
	urldate = {2023-06-14},
	publisher = {arXiv},
	author = {Li, Miaoran and Peng, Baolin and Zhang, Zhu},
	month = may,
	year = {2023},
	note = {arXiv:2305.14623 [cs]},
	keywords = {Computer Science - Computation and Language, misinfo},
	file = {arXiv Fulltext PDF:C\:\\Users\\jingni\\Zotero\\storage\\NUADW2MB\\Li et al. - 2023 - Self-Checker Plug-and-Play Modules for Fact-Check.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\jingni\\Zotero\\storage\\2IRD3ZF9\\2305.html:text/html},
}

@misc{zhengJudgingLLMasajudgeMTBench2023,
	title = {Judging {LLM}-as-a-judge with {MT}-{Bench} and {Chatbot} {Arena}},
	url = {http://arxiv.org/abs/2306.05685},
	abstract = {Evaluating large language model (LLM) based chat assistants is challenging due to their broad capabilities and the inadequacy of existing benchmarks in measuring human preferences. To address this, we explore using strong LLMs as judges to evaluate these models on more open-ended questions. We examine the usage and limitations of LLM-as-a-judge, such as position and verbosity biases and limited reasoning ability, and propose solutions to migrate some of them. We then verify the agreement between LLM judges and human preferences by introducing two benchmarks: MT-bench, a multi-turn question set; and Chatbot Arena, a crowdsourced battle platform. Our results reveal that strong LLM judges like GPT-4 can match both controlled and crowdsourced human preferences well, achieving over 80{\textbackslash}\% agreement, the same level of agreement between humans. Hence, LLM-as-a-judge is a scalable and explainable way to approximate human preferences, which are otherwise very expensive to obtain. Additionally, we show our benchmark and traditional benchmarks complement each other by evaluating several variants of LLaMA/Vicuna. We will publicly release 80 MT-bench questions, 3K expert votes, and 30K conversations with human preferences from Chatbot Arena.},
	urldate = {2023-07-04},
	publisher = {arXiv},
	author = {Zheng, Lianmin and Chiang, Wei-Lin and Sheng, Ying and Zhuang, Siyuan and Wu, Zhanghao and Zhuang, Yonghao and Lin, Zi and Li, Zhuohan and Li, Dacheng and Xing, Eric P. and Zhang, Hao and Gonzalez, Joseph E. and Stoica, Ion},
	month = jun,
	year = {2023},
	note = {arXiv:2306.05685 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
	file = {arXiv.org Snapshot:C\:\\Users\\jingni\\Zotero\\storage\\FDHFQZWA\\2306.html:text/html;Full Text PDF:C\:\\Users\\jingni\\Zotero\\storage\\ITG766VV\\Zheng et al. - 2023 - Judging LLM-as-a-judge with MT-Bench and Chatbot A.pdf:application/pdf},
}

@inproceedings{Raghavan2006ActiveLW,
  title={Active Learning with Feedback on Both Features and Instances},
  author={Hema Raghavan},
  year={2006}
}

@misc{wu2021active,
      title={Active Learning for Graph Neural Networks via Node Feature Propagation}, 
      author={Yuexin Wu and Yichong Xu and Aarti Singh and Yiming Yang and Artur Dubrawski},
      year={2021},
      eprint={1910.07567},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{tandon2021interscript,
      title={Interscript: A dataset for interactive learning of scripts through error feedback}, 
      author={Niket Tandon and Aman Madaan and Peter Clark and Keisuke Sakaguchi and Yiming Yang},
      year={2021},
      eprint={2112.07867},
      archivePrefix={arXiv},
      primaryClass={cs.AI}
}



@inproceedings{tandonLearningRepairRepairing2022,
	address = {Seattle, United States},
	title = {Learning to repair: {Repairing} model output errors after deployment using a dynamic memory of feedback},
	shorttitle = {Learning to repair},
	url = {https://aclanthology.org/2022.findings-naacl.26},
	doi = {10.18653/v1/2022.findings-naacl.26},
	abstract = {Large language models (LMs), while powerful, are not immune to mistakes, but can be difficult to retrain. Our goal is for an LM to continue to improve after deployment, without retraining, using feedback from the user. Our approach pairs an LM with (i) a growing memory of cases where the user identified an output error and provided general feedback on how to correct it (ii) a corrector model, trained to translate this general feedback into specific edits to repair the model output. Given a new, unseen input, our model can then use feedback from similar, past cases to repair output errors that may occur. We instantiate our approach using an existing, fixed model for script generation, that takes a goal (e.g., “bake a cake”) and generates a partially ordered sequence of actions to achieve that goal, sometimes containing errors. Our memory-enhanced system, , learns to apply user feedback to repair such errors (up to 30 points improvement), while making a start at avoiding similar past mistakes on new, unseen examples (up to 7 points improvement in a controlled setting). This is a first step towards strengthening deployed models, potentially broadening their utility. Our code and data is available at https://github.com/allenai/interscript},
	urldate = {2023-06-14},
	booktitle = {Findings of the {Association} for {Computational} {Linguistics}: {NAACL} 2022},
	publisher = {Association for Computational Linguistics},
	author = {Tandon, Niket and Madaan, Aman and Clark, Peter and Yang, Yiming},
	month = jul,
	year = {2022},
	keywords = {use\_feedback},
	pages = {339--352},
	file = {Full Text PDF:C\:\\Users\\jingni\\Zotero\\storage\\RUZAN33W\\Tandon et al. - 2022 - Learning to repair Repairing model output errors .pdf:application/pdf},
}


@misc{kocmiLargeLanguageModels2023,
	title = {Large {Language} {Models} {Are} {State}-of-the-{Art} {Evaluators} of {Translation} {Quality}},
	url = {http://arxiv.org/abs/2302.14520},
	abstract = {We describe GEMBA, a GPT-based metric for assessment of translation quality, which works both with a reference translation and without. In our evaluation, we focus on zero-shot prompting, comparing four prompt variants in two modes, based on the availability of the reference. We investigate nine versions of GPT models, including ChatGPT and GPT-4. We show that our method for translation quality assessment only works with GPT{\textasciitilde}3.5 and larger models. Comparing to results from WMT22's Metrics shared task, our method achieves state-of-the-art accuracy in both modes when compared to MQM-based human labels. Our results are valid on the system level for all three WMT22 Metrics shared task language pairs, namely English into German, English into Russian, and Chinese into English. This provides a first glimpse into the usefulness of pre-trained, generative large language models for quality assessment of translations. We publicly release all our code and prompt templates used for the experiments described in this work, as well as all corresponding scoring results, to allow for external validation and reproducibility.},
	urldate = {2023-06-18},
	publisher = {arXiv},
	author = {Kocmi, Tom and Federmann, Christian},
	month = may,
	year = {2023},
	note = {arXiv:2302.14520 [cs]},
	keywords = {Computer Science - Computation and Language, llm\_as\_evaluator},
	annote = {Comment: Accepted in EAMT, 10 pages, 8 tables, one figure},
	file = {arXiv.org Snapshot:C\:\\Users\\jingni\\Zotero\\storage\\35W3R9QE\\2302.html:text/html;Full Text PDF:C\:\\Users\\jingni\\Zotero\\storage\\MR29LZ7C\\Kocmi and Federmann - 2023 - Large Language Models Are State-of-the-Art Evaluat.pdf:application/pdf},
}


@misc{chen2023chatgpts,
      title={How is ChatGPT's behavior changing over time?}, 
      author={Lingjiao Chen and Matei Zaharia and James Zou},
      year={2023},
      eprint={2307.09009},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{touvron2023llama2,
      title={Llama 2: Open Foundation and Fine-Tuned Chat Models}, 
      author={Hugo Touvron and Louis Martin and Kevin Stone and Peter Albert and Amjad Almahairi and Yasmine Babaei and Nikolay Bashlykov and Soumya Batra and Prajjwal Bhargava and Shruti Bhosale and Dan Bikel and Lukas Blecher and Cristian Canton Ferrer and Moya Chen and Guillem Cucurull and David Esiobu and Jude Fernandes and Jeremy Fu and Wenyin Fu and Brian Fuller and Cynthia Gao and Vedanuj Goswami and Naman Goyal and Anthony Hartshorn and Saghar Hosseini and Rui Hou and Hakan Inan and Marcin Kardas and Viktor Kerkez and Madian Khabsa and Isabel Kloumann and Artem Korenev and Punit Singh Koura and Marie-Anne Lachaux and Thibaut Lavril and Jenya Lee and Diana Liskovich and Yinghai Lu and Yuning Mao and Xavier Martinet and Todor Mihaylov and Pushkar Mishra and Igor Molybog and Yixin Nie and Andrew Poulton and Jeremy Reizenstein and Rashi Rungta and Kalyan Saladi and Alan Schelten and Ruan Silva and Eric Michael Smith and Ranjan Subramanian and Xiaoqing Ellen Tan and Binh Tang and Ross Taylor and Adina Williams and Jian Xiang Kuan and Puxin Xu and Zheng Yan and Iliyan Zarov and Yuchen Zhang and Angela Fan and Melanie Kambadur and Sharan Narang and Aurelien Rodriguez and Robert Stojnic and Sergey Edunov and Thomas Scialom},
      year={2023},
      eprint={2307.09288},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}


