% Generated by IEEEtran.bst, version: 1.14 (2015/08/26)
\begin{thebibliography}{10}
\providecommand{\url}[1]{#1}
\csname url@samestyle\endcsname
\providecommand{\newblock}{\relax}
\providecommand{\bibinfo}[2]{#2}
\providecommand{\BIBentrySTDinterwordspacing}{\spaceskip=0pt\relax}
\providecommand{\BIBentryALTinterwordstretchfactor}{4}
\providecommand{\BIBentryALTinterwordspacing}{\spaceskip=\fontdimen2\font plus
\BIBentryALTinterwordstretchfactor\fontdimen3\font minus
  \fontdimen4\font\relax}
\providecommand{\BIBforeignlanguage}[2]{{%
\expandafter\ifx\csname l@#1\endcsname\relax
\typeout{** WARNING: IEEEtran.bst: No hyphenation pattern has been}%
\typeout{** loaded for the language `#1'. Using the pattern for}%
\typeout{** the default language instead.}%
\else
\language=\csname l@#1\endcsname
\fi
#2}}
\providecommand{\BIBdecl}{\relax}
\BIBdecl

\bibitem{Dual-Generator}
G.~Hsu, C.~Tsai, and H.~Wu, ``Dual-generator face reenactment,'' in
  \emph{Conference on Computer Vision and Pattern Recognition}.\hskip 1em plus
  0.5em minus 0.4em\relax {IEEE}, 2022, pp. 632--640.

\bibitem{df3}
Y.~Nirkin, Y.~Keller, and T.~Hassner, ``{FSGAN:} subject agnostic face swapping
  and reenactment,'' in \emph{International Conference on Computer
  Vision}.\hskip 1em plus 0.5em minus 0.4em\relax {IEEE}, 2019, pp. 7183--7192.

\bibitem{faceshifter}
L.~Li, J.~Bao, H.~Yang, D.~Chen, and F.~Wen, ``Advancing high fidelity identity
  swapping for forgery detection,'' in \emph{Conference on Computer Vision and
  Pattern Recognition}.\hskip 1em plus 0.5em minus 0.4em\relax CVF/IEEE, 2020,
  pp. 5073--5082.

\bibitem{SRM}
Y.~Luo, Y.~Zhang, J.~Yan, and W.~Liu, ``Generalizing face forgery detection
  with high-frequency features,'' in \emph{Conference on Computer Vision and
  Pattern Recognition}.\hskip 1em plus 0.5em minus 0.4em\relax {IEEE}, 2021,
  pp. 16\,317--16\,326.

\bibitem{F3Net}
Y.~Qian, G.~Yin, L.~Sheng, Z.~Chen, and J.~Shao, ``Thinking in frequency: Face
  forgery detection by mining frequency-aware clues,'' in \emph{European
  Conference on Computer Vision}.\hskip 1em plus 0.5em minus 0.4em\relax
  Springer, 2020, pp. 86--103.

\bibitem{Learning_Second_Order}
J.~Fei, Y.~Dai, P.~Yu, T.~Shen, Z.~Xia, and J.~Weng, ``Learning second order
  local anomaly for general face forgery detection,'' in \emph{Conference on
  Computer Vision and Pattern Recognition}.\hskip 1em plus 0.5em minus
  0.4em\relax IEEE, 2022, pp. 20\,238--20\,248.

\bibitem{Leveraging_Real_Talking}
A.~Haliassos, R.~Mira, S.~Petridis, and M.~Pantic, ``Leveraging real talking
  faces via self-supervision for robust forgery detection,'' in
  \emph{Conference on Computer Vision and Pattern Recognition}.\hskip 1em plus
  0.5em minus 0.4em\relax IEEE, 2022, pp. 14\,930--14\,942.

\bibitem{lipsdontlie}
A.~Haliassos, K.~Vougioukas, S.~Petridis, and M.~Pantic, ``Lips don't lie: {A}
  generalisable and robust approach to face forgery detection,'' in
  \emph{Conference on Computer Vision and Pattern Recognition}.\hskip 1em plus
  0.5em minus 0.4em\relax IEEE, 2021, pp. 5039--5049.

\bibitem{emotion}
T.~Mittal, U.~Bhattacharya, R.~Chandra, A.~Bera, and D.~Manocha, ``Emotions
  don't lie: An audio-visual deepfake detection method using affective cues,''
  in \emph{ACM International Conference on Multimedia}.\hskip 1em plus 0.5em
  minus 0.4em\relax ACM, 2020, pp. 2823--2832.

\bibitem{x-ray}
L.~Li, J.~Bao, T.~Zhang, H.~Yang, D.~Chen, F.~Wen, and B.~Guo, ``Face x-ray for
  more general face forgery detection,'' in \emph{Conference on Computer Vision
  and Pattern Recognition}.\hskip 1em plus 0.5em minus 0.4em\relax CVF/IEEE,
  2020, pp. 5000--5009.

\bibitem{What_Makes_Fake}
L.~Chai, D.~Bau, S.~Lim, and P.~Isola, ``What makes fake images detectable?
  understanding properties that generalize,'' in \emph{{European Conference on
  Computer Vision}}.\hskip 1em plus 0.5em minus 0.4em\relax Springer, 2020, pp.
  103--120.

\bibitem{RFM}
C.~Wang and W.~Deng, ``Representative forgery mining for fake face detection,''
  in \emph{Conference on Computer Vision and Pattern Recognition}.\hskip 1em
  plus 0.5em minus 0.4em\relax {IEEE}, 2021, pp. 14\,923--14\,932.

\bibitem{Xception}
A.~R{\"{o}}ssler, D.~Cozzolino, L.~Verdoliva, C.~Riess, J.~Thies, and
  M.~Nie{\ss}ner, ``Faceforensics++: Learning to detect manipulated facial
  images,'' in \emph{International Conference on Computer Vision}.\hskip 1em
  plus 0.5em minus 0.4em\relax {IEEE}, 2019, pp. 1--11.

\bibitem{FakeLocator}
Y.~Huang, F.~Juefei{-}Xu, Q.~Guo, Y.~Liu, and G.~Pu, ``Fakelocator: Robust
  localization of gan-based face manipulations,'' \emph{IEEE Transactions on
  Information Forensics and Security}, vol.~17, pp. 2657--2672, 2022.

\bibitem{facial_manipulated}
G.~Mazaheri and A.~K. Roy{-}Chowdhury, ``Detection and localization of facial
  expression manipulations,'' in \emph{Winter Conference on Applications of
  Computer Vision}.\hskip 1em plus 0.5em minus 0.4em\relax {IEEE}, 2022, pp.
  2773--2783.

\bibitem{On_the_Detection_2020}
H.~Dang, F.~Liu, J.~Stehouwer, X.~Liu, and A.~K. Jain, ``On the detection of
  digital face manipulation,'' in \emph{Conference on Computer Vision and
  Pattern Recognition}.\hskip 1em plus 0.5em minus 0.4em\relax CVF/IEEE, 2020,
  pp. 5780--5789.

\bibitem{Face_Reconstruction}
J.~Cao, C.~Ma, T.~Yao, S.~Chen, S.~Ding, and X.~Yang, ``End-to-end
  reconstruction-classification learning for face forgery detection,'' in
  \emph{Conference on Computer Vision and Pattern Recognition}.\hskip 1em plus
  0.5em minus 0.4em\relax IEEE, 2022, pp. 4103--4112.

\bibitem{chen2022ost}
L.~Chen, Y.~Zhang, Y.~Song, J.~Wang, and L.~Liu, ``{OST}: Improving
  generalization of deepfake detection via one-shot test-time training,'' in
  \emph{{Advances in Neural Information Processing Systems}}.\hskip 1em plus
  0.5em minus 0.4em\relax MIT Press, 2022, pp. 1--14.

\bibitem{MagDR}
Z.~Chen, L.~Xie, S.~Pang, Y.~He, and B.~Zhang, ``Magdr: Mask-guided detection
  and reconstruction for defending deepfakes,'' in \emph{{Conference on
  Computer Vision and Pattern Recognition}}.\hskip 1em plus 0.5em minus
  0.4em\relax IEEE, 2021, pp. 9014--9023.

\bibitem{Self_ADV}
L.~Chen, Y.~Zhang, Y.~Song, L.~Liu, and J.~Wang, ``Self-supervised learning of
  adversarial example: Towards good generalizations for deepfake detection,''
  in \emph{Conference on Computer Vision and Pattern Recognition}.\hskip 1em
  plus 0.5em minus 0.4em\relax IEEE, 2022, pp. 18\,689--18\,698.

\bibitem{Ensemble_1}
Z.~Chen, J.~Duan, L.~Kang, and G.~Qiu, ``Supervised anomaly detection via
  conditional generative adversarial network and ensemble active learning,''
  \emph{IEEE Transactions on Pattern Analysis and Machine Intelligence},
  vol.~45, no.~6, pp. 7781--7798, 2023.

\bibitem{Ensemble_2}
C.~Zhao, D.~Wu, J.~Huang, Y.~Yuan, H.~Zhang, R.~Peng, and Z.~Shi, ``Boosttree
  and boostforest for ensemble learning,'' \emph{IEEE Transactions on Pattern
  Analysis and Machine Intelligence}, vol.~45, no.~7, pp. 8110--8126, 2023.

\bibitem{dfdc}
B.~Dolhansky, J.~Bitton, B.~Pflaum, J.~Lu, R.~Howes, M.~Wang, and
  C.~Canton{-}Ferrer, ``The deepfake detection challenge dataset,''
  \emph{CoRR}, pp. 1--13, 2020.

\bibitem{DF1.0}
L.~Jiang, R.~Li, W.~Wu, C.~Qian, and C.~C. Loy, ``Deeperforensics-1.0: {A}
  large-scale dataset for real-world face forgery detection,'' in
  \emph{{Conference on Computer Vision and Pattern Recognition}}.\hskip 1em
  plus 0.5em minus 0.4em\relax CVF/IEEE, 2020, pp. 2886--2895.

\bibitem{Celeb-DF}
Y.~Li, X.~Yang, P.~Sun, H.~Qi, and S.~Lyu, ``Celeb-df: {A} large-scale
  challenging dataset for deepfake forensics,'' in \emph{Conference on Computer
  Vision and Pattern Recognition}.\hskip 1em plus 0.5em minus 0.4em\relax
  CVF/IEEE, 2020, pp. 3204--3213.

\bibitem{DF_PAMI4}
X.~Xu, Y.~Chen, X.~Tao, and J.~Jia, ``Text-guided human image manipulation via
  image-text shared space,'' \emph{IEEE Transactions on Pattern Analysis and
  Machine Intelligence}, vol.~44, no.~10, pp. 6486--6500, 2022.

\bibitem{autoencoder}
D.~P. Kingma and M.~Welling, ``Auto-encoding variational bayes,'' in
  \emph{International Conference on Learning Representations}.\hskip 1em plus
  0.5em minus 0.4em\relax OpenReview.net, 2014, pp. 1--14.

\bibitem{Face2Face}
J.~Thies, M.~Zollh{\"{o}}fer, M.~Stamminger, C.~Theobalt, and M.~Nie{\ss}ner,
  ``Face2face: Real-time face capture and reenactment of {RGB} videos,'' in
  \emph{{Conference on Computer Vision and Pattern Recognition}}.\hskip 1em
  plus 0.5em minus 0.4em\relax IEEE, 2016, pp. 2387--2395.

\bibitem{S_Ob}
S.~Suwajanakorn, S.~M. Seitz, and I.~Kemelmacher{-}Shlizerman, ``Synthesizing
  obama: learning lip sync from audio,'' \emph{ACM Transactions on Graphics},
  vol.~36, no.~4, pp. 95:1--95:13, 2017.

\bibitem{GAN}
I.~J. Goodfellow, J.~Pouget{-}Abadie, M.~Mirza, B.~Xu, D.~Warde{-}Farley,
  S.~Ozair, A.~C. Courville, and Y.~Bengio, ``Generative adversarial nets,'' in
  \emph{Conference on Neural Information Processing Systems}.\hskip 1em plus
  0.5em minus 0.4em\relax MIT Press, 2014, pp. 2672--2680.

\bibitem{StyleGAN}
T.~Karras, S.~Laine, and T.~Aila, ``A style-based generator architecture for
  generative adversarial networks,'' in \emph{{Conference on Computer Vision
  and Pattern Recognition}}.\hskip 1em plus 0.5em minus 0.4em\relax IEEE, 2019,
  pp. 4401--4410.

\bibitem{IPGAN}
J.~Bao, D.~Chen, F.~Wen, H.~Li, and G.~Hua, ``Towards open-set identity
  preserving face synthesis,'' in \emph{{Conference on Computer Vision and
  Pattern Recognition}}.\hskip 1em plus 0.5em minus 0.4em\relax {IEEE}, 2018,
  pp. 6713--6722.

\bibitem{DBLP:journals/tog/KimCTXTNPRZT18}
H.~Kim, P.~Garrido, A.~Tewari, W.~Xu, J.~Thies, M.~Nie{\ss}ner, P.~P{\'{e}}rez,
  C.~Richardt, M.~Zollh{\"{o}}fer, and C.~Theobalt, ``Deep video portraits,''
  \emph{{ACM} Transactions on Graphics}, vol.~37, no.~4, pp. 163:1--163:14,
  2018.

\bibitem{3DMM2}
V.~Blanz, K.~Scherbaum, T.~Vetter, and H.~Seidel, ``Exchanging faces in
  images,'' \emph{Computer Graphics Forum}, vol.~23, no.~3, pp. 669--676, 2004.

\bibitem{Region_aware_swapping}
C.~Xu, J.~Zhang, M.~Hua, Q.~He, Z.~Yi, and Y.~Liu, ``Region-aware face
  swapping,'' in \emph{Conference on Computer Vision and Pattern
  Recognition}.\hskip 1em plus 0.5em minus 0.4em\relax IEEE, 2022, pp.
  7622--7631.

\bibitem{DF_PAMI2}
G.~Chen and C.~Hsu, ``Jointly defending deepfake manipulation and adversarial
  attack using decoy mechanism,'' \emph{IEEE Transactions on Pattern Analysis
  and Machine Intelligence}, vol.~45, no.~8, pp. 9922--9931, 2023.

\bibitem{DF_PAMI3}
X.~Zhu, H.~Fei, B.~Zhang, T.~Zhang, X.~Zhang, S.~Z. Li, and Z.~Lei, ``Face
  forgery detection by 3d decomposition and composition search,'' \emph{IEEE
  Transactions on Pattern Analysis and Machine Intelligence}, vol.~45, no.~7,
  pp. 8342--8357, 2023.

\bibitem{Exploring_Frequency_Adversarial}
S.~Jia, C.~Ma, T.~Yao, B.~Yin, S.~Ding, and X.~Yang, ``Exploring frequency
  adversarial attacks for face forgery detection,'' in \emph{Conference on
  Computer Vision and Pattern Recognition}.\hskip 1em plus 0.5em minus
  0.4em\relax IEEE, 2022, pp. 4093--4102.

\bibitem{Two-Branch}
I.~Masi, A.~Killekar, R.~M. Mascarenhas, S.~P. Gurudatt, and W.~AbdAlmageed,
  ``Two-branch recurrent network for isolating deepfakes in videos,'' in
  \emph{European Conference on Computer Vision}.\hskip 1em plus 0.5em minus
  0.4em\relax Springer, 2020, pp. 667--684.

\bibitem{SSTNET}
X.~Wu, Z.~Xie, Y.~Gao, and Y.~Xiao, ``Sstnet: Detecting manipulated faces
  through spatial, steganalysis and temporal features,'' in \emph{International
  Conference on Acoustics, Speech, and Signal Processing}.\hskip 1em plus 0.5em
  minus 0.4em\relax {IEEE}, 2020, pp. 2952--2956.

\bibitem{DF_PAMI1}
Y.~Nirkin, L.~Wolf, Y.~Keller, and T.~Hassner, ``Deepfake detection based on
  discrepancies between faces and their context,'' \emph{IEEE Transactions on
  Pattern Analysis and Machine Intelligence}, vol.~44, no.~10, pp. 6111--6121,
  2022.

\bibitem{jointAV}
Y.~Zhou and S.-N. Lim, ``Joint audio-visual deepfake detection,'' in
  \emph{International Conference on Computer Vision}.\hskip 1em plus 0.5em
  minus 0.4em\relax {IEEE}, 2021, pp. 14\,800--14\,809.

\bibitem{DFTIMIT}
P.~Korshunov and S.~Marcel, ``Deepfakes: a new threat to face recognition?
  assessment and detection,'' \emph{CoRR}, pp. 1--5, 2018.

\bibitem{KODF}
P.~Kwon, J.~You, G.~Nam, S.~Park, and G.~Chae, ``Kodf: {A} large-scale korean
  deepfake detection dataset,'' in \emph{International Conference on Computer
  Vision}.\hskip 1em plus 0.5em minus 0.4em\relax {IEEE}, 2021, pp.
  10\,724--10\,733.

\bibitem{Openfor}
T.~Le, H.~H. Nguyen, J.~Yamagishi, and I.~Echizen, ``Openforensics: Large-scale
  challenging dataset for multi-face forgery detection and segmentation
  in-the-wild,'' in \emph{International Conference on Computer Vision}.\hskip
  1em plus 0.5em minus 0.4em\relax {IEEE}, 2021, pp. 10\,097--10\,107.

\bibitem{FakeAVCeleb}
H.~Khalid, S.~Tariq, M.~Kim, and S.~S. Woo, ``Fakeavceleb: {A} novel
  audio-video multimodal deepfake dataset,'' in \emph{Conference on Neural
  Information Processing Systems}.\hskip 1em plus 0.5em minus 0.4em\relax MIT
  Press, 2021, pp. 1--15.

\bibitem{dgm4}
R.~Shao, T.~Wu, and Z.~Liu, ``Detecting and grounding multi-modal media
  manipulation,'' in \emph{Conference on Computer Vision and Pattern
  Recognition}.\hskip 1em plus 0.5em minus 0.4em\relax IEEE, 2023, pp.
  6904--6913.

\bibitem{df-platte}
K.~Narayan, H.~Agarwal, K.~Thakral, S.~Mittal, M.~Vatsa, and R.~Singh,
  ``Df-platter: Multi-face heterogeneous deepfake dataset,'' in
  \emph{Conference on Computer Vision and Pattern Recognition}.\hskip 1em plus
  0.5em minus 0.4em\relax IEEE, 2023, pp. 9739--9748.

\bibitem{regu_PAMI}
K.~Fatras, B.~B. Damodaran, S.~Lobry, R.~Flamary, D.~Tuia, and N.~Courty,
  ``Wasserstein adversarial regularization for learning with label noise,''
  \emph{IEEE Transactions on Pattern Analysis and Machine Intelligence},
  vol.~44, no.~10, pp. 7296--7306, 2022.

\bibitem{mixupfirst}
H.~Zhang, M.~Ciss{\'{e}}, Y.~N. Dauphin, and D.~Lopez{-}Paz, ``mixup: Beyond
  empirical risk minimization,'' in \emph{International Conference on Learning
  Representations}.\hskip 1em plus 0.5em minus 0.4em\relax OpenReview.net,
  2018, pp. 1--13.

\bibitem{risk}
O.~Chapelle, J.~Weston, L.~Bottou, and V.~Vapnik, ``Vicinal risk
  minimization,'' in \emph{Advances in Neural Information Processing
  Systems}.\hskip 1em plus 0.5em minus 0.4em\relax {MIT} Press, 2000, pp.
  416--422.

\bibitem{CutOut}
T.~Devries and G.~W. Taylor, ``Improved regularization of convolutional neural
  networks with cutout,'' \emph{CoRR}, pp. 1--7, 2017.

\bibitem{CutMix}
S.~Yun, D.~Han, S.~Chun, S.~J. Oh, Y.~Yoo, and J.~Choe, ``Cutmix:
  Regularization strategy to train strong classifiers with localizable
  features,'' in \emph{International Conference on Computer Vision}.\hskip 1em
  plus 0.5em minus 0.4em\relax {IEEE}, 2019, pp. 6022--6031.

\bibitem{DropBlock}
G.~Ghiasi, T.~Lin, and Q.~V. Le, ``Dropblock: {A} regularization method for
  convolutional networks,'' in \emph{Advances in Neural Information Processing
  Systems}.\hskip 1em plus 0.5em minus 0.4em\relax {MIT} Press, 2018, pp.
  10\,750--10\,760.

\bibitem{AAAI_regu}
M.~Faramarzi, M.~Amini, A.~Badrinaaraayanan, V.~Verma, and S.~Chandar,
  ``Patchup: {A} feature-space block-level regularization technique for
  convolutional neural networks,'' in \emph{{AAAI} Conference on Artificial
  Intelligence}.\hskip 1em plus 0.5em minus 0.4em\relax {AAAI} Press, 2022, pp.
  589--597.

\bibitem{Kim_regu}
J.~Kim, Y.~Choi, and Y.~Uh, ``Feature statistics mixing regularization for
  generative adversarial networks,'' in \emph{Conference on Computer Vision and
  Pattern Recognition}.\hskip 1em plus 0.5em minus 0.4em\relax IEEE, 2022, pp.
  11\,294--11\,303.

\bibitem{label_smooth}
R.~M{\"{u}}ller, S.~Kornblith, and G.~E. Hinton, ``When does label smoothing
  help?'' in \emph{Conference on Neural Information Processing Systems}.\hskip
  1em plus 0.5em minus 0.4em\relax OpenReview.net, 2019, pp. 4696--4705.

\bibitem{Grad-Cam}
R.~R. Selvaraju, M.~Cogswell, A.~Das, R.~Vedantam, D.~Parikh, and D.~Batra,
  ``Grad-cam: Visual explanations from deep networks via gradient-based
  localization,'' in \emph{International Conference on Computer Vision}.\hskip
  1em plus 0.5em minus 0.4em\relax {IEEE}, 2017, pp. 618--626.

\bibitem{gradcam_explain}
G.~Novakovsky, N.~Dexter, M.~W. Libbrecht, W.~W. Wasserman, and S.~Mostafavi,
  ``Obtaining genetics insights from deep learning via explainable artificial
  intelligence,'' \emph{Nature Reviews Genetics}, pp. 1--13, 2022.

\bibitem{gradcam_explain_2}
Q.~Zhang, Y.~Xu, J.~Zhang, and D.~Tao, ``Vitaev2: Vision transformer advanced
  by exploring inductive bias for image recognition and beyond,''
  \emph{International Journal of Computer Vision}, pp. 1--22, 2023.

\bibitem{MAT}
H.~Zhao, W.~Zhou, D.~Chen, T.~Wei, W.~Zhang, and N.~Yu, ``Multi-attentional
  deepfake detection,'' in \emph{Conference on Computer Vision and Pattern
  Recognition}.\hskip 1em plus 0.5em minus 0.4em\relax IEEE, 2021, pp.
  2185--2194.

\bibitem{VFD}
H.~Cheng, Y.~Guo, T.~Wang, Q.~Li, X.~Chang, and L.~Nie, ``Voice-face
  homogeneity tells deepfake,'' \emph{CORR}, pp. 1--13, 2022.

\bibitem{Efficient}
M.~Tan and Q.~V. Le, ``Efficientnet: Rethinking model scaling for convolutional
  neural networks,'' in \emph{International Conference on Machine Learning},
  vol.~97.\hskip 1em plus 0.5em minus 0.4em\relax {PMLR}, 2019, pp. 6105--6114.

\bibitem{VGG}
K.~Simonyan and A.~Zisserman, ``Very deep convolutional networks for
  large-scale image recognition,'' in \emph{International Conference on
  Learning Representations}.\hskip 1em plus 0.5em minus 0.4em\relax
  OpenReview.net, 2015, pp. 1--14.

\bibitem{Grad_CAM++}
A.~Chattopadhyay, A.~Sarkar, P.~Howlader, and V.~N. Balasubramanian,
  ``Grad-cam++: Generalized gradient-based visual explanations for deep
  convolutional networks,'' in \emph{Winter Conference on Applications of
  Computer Vision}.\hskip 1em plus 0.5em minus 0.4em\relax {IEEE}, 2018, pp.
  839--847.

\bibitem{chen2020counterfactual}
L.~Chen, X.~Yan, J.~Xiao, H.~Zhang, S.~Pu, and Y.~Zhuang, ``Counterfactual
  samples synthesizing for robust visual question answering,'' in
  \emph{Conference on Computer Vision and Pattern Recognition}.\hskip 1em plus
  0.5em minus 0.4em\relax CVF/IEEE, 2020, pp. 10\,797--10\,806.

\bibitem{fine-tune_mask}
S.~Tilgner, D.~Wagner, K.~Kalischewski, J.~Schmitz, and A.~Kummert, ``Study on
  the influence of multiple image inputs of a multi-view fusion neural network
  based on grad-cam and masked image inputs,'' in \emph{European Conference on
  Computer Vision}.\hskip 1em plus 0.5em minus 0.4em\relax Springer, 2020, pp.
  1427--1431.

\bibitem{Mixup}
L.~Zhang, Z.~Deng, K.~Kawaguchi, and J.~Zou, ``When and how mixup improves
  calibration,'' in \emph{{ICML}}, vol. 162.\hskip 1em plus 0.5em minus
  0.4em\relax {PMLR}, 2022, pp. 26\,135--26\,160.

\bibitem{Mixupthe}
L.~Zhang, Z.~Deng, K.~Kawaguchi, A.~Ghorbani, and J.~Zou, ``How does mixup help
  with robustness and generalization?'' in \emph{International Conference on
  Learning Representations}.\hskip 1em plus 0.5em minus 0.4em\relax
  OpenReview.net, 2021.

\bibitem{Mixup19}
S.~Yun, D.~Han, S.~Chun, S.~J. Oh, Y.~Yoo, and J.~Choe, ``Cutmix:
  Regularization strategy to train strong classifiers with localizable
  features,'' in \emph{{International Conference on Computer Vision}}.\hskip
  1em plus 0.5em minus 0.4em\relax {IEEE}, 2019, pp. 6022--6031.

\bibitem{mesonet}
D.~Afchar, V.~Nozick, J.~Yamagishi, and I.~Echizen, ``Mesonet: a compact facial
  video forgery detection network,'' in \emph{International Workshops on
  Information Forensics and Security}.\hskip 1em plus 0.5em minus 0.4em\relax
  {IEEE}, 2018, pp. 1--7.

\bibitem{capsule}
H.~H. Nguyen, J.~Yamagishi, and I.~Echizen, ``Capsule-forensics: Using capsule
  networks to detect forged images and videos,'' in \emph{International
  Conference on Acoustics, Speech, and Signal Processing}.\hskip 1em plus 0.5em
  minus 0.4em\relax {IEEE}, 2019, pp. 2307--2311.

\bibitem{CViT}
D.~Wodajo and S.~Atnafu, ``Deepfake video detection using convolutional vision
  transformer,'' \emph{CoRR}, pp. 1--9, 2021.

\bibitem{ResNet}
K.~He, X.~Zhang, S.~Ren, and J.~Sun, ``Deep residual learning for image
  recognition,'' in \emph{{Conference on Computer Vision and Pattern
  Recognition}}.\hskip 1em plus 0.5em minus 0.4em\relax {IEEE}, 2016, pp.
  770--778.

\bibitem{imagenet}
O.~Russakovsky, J.~Deng, H.~Su, J.~Krause, S.~Satheesh, S.~Ma, Z.~Huang,
  A.~Karpathy, A.~Khosla, M.~Bernstein \emph{et~al.}, ``Imagenet large scale
  visual recognition challenge,'' \emph{International Journal of Computer
  Vision}, vol. 115, pp. 211--252, 2015.

\end{thebibliography}
