\begin{thebibliography}{40}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Brown et~al.(2020)Brown, Mann, Ryder, Subbiah, Kaplan, Dhariwal,
  Neelakantan, Shyam, Sastry, Askell, Agarwal, Herbert-Voss, Krueger, Henighan,
  Child, Ramesh, Ziegler, Wu, Winter, Hesse, Chen, Sigler, Litwin, Gray, Chess,
  Clark, Berner, McCandlish, Radford, Sutskever, and Amodei]{GPT3}
Brown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J.~D., Dhariwal, P.,
  Neelakantan, A., Shyam, P., Sastry, G., Askell, A., Agarwal, S.,
  Herbert-Voss, A., Krueger, G., Henighan, T., Child, R., Ramesh, A., Ziegler,
  D., Wu, J., Winter, C., Hesse, C., Chen, M., Sigler, E., Litwin, M., Gray,
  S., Chess, B., Clark, J., Berner, C., McCandlish, S., Radford, A., Sutskever,
  I., and Amodei, D.
\newblock Language models are few-shot learners.
\newblock In Larochelle, H., Ranzato, M., Hadsell, R., Balcan, M., and Lin, H.
  (eds.), \emph{Advances in Neural Information Processing Systems}, volume~33,
  pp.\  1877--1901. Curran Associates, Inc., 2020.
\newblock URL
  \url{https://proceedings.neurips.cc/paper_files/paper/2020/file/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf}.

\bibitem[Buciluundefined et~al.(2006)Buciluundefined, Caruana, and
  Niculescu-Mizil]{10.1145/1150402.1150464}
Buciluundefined, C., Caruana, R., and Niculescu-Mizil, A.
\newblock Model compression.
\newblock In \emph{Proceedings of the 12th ACM SIGKDD International Conference
  on Knowledge Discovery and Data Mining}, KDD '06, pp.\  535–541, New York,
  NY, USA, 2006. Association for Computing Machinery.
\newblock ISBN 1595933395.
\newblock \doi{10.1145/1150402.1150464}.
\newblock URL \url{https://doi.org/10.1145/1150402.1150464}.

\bibitem[Cavigelli et~al.(2017)Cavigelli, Degen, and
  Benini]{10.1145/3131885.3131906}
Cavigelli, L., Degen, P., and Benini, L.
\newblock Cbinfer: Change-based inference for convolutional neural networks on
  video data.
\newblock In \emph{Proceedings of the 11th International Conference on
  Distributed Smart Cameras}, ICDSC 2017, pp.\  1–8, New York, NY, USA, 2017.
  Association for Computing Machinery.
\newblock ISBN 9781450354875.
\newblock \doi{10.1145/3131885.3131906}.
\newblock URL \url{https://doi.org/10.1145/3131885.3131906}.

\bibitem[Chen et~al.(2023)Chen, Liu, Tang, Yi, Zhao, and
  Han]{chen2023sparsevit}
Chen, X., Liu, Z., Tang, H., Yi, L., Zhao, H., and Han, S.
\newblock Sparsevit: Revisiting activation sparsity for efficient
  high-resolution vision transformer.
\newblock In \emph{IEEE/CVF Conference on Computer Vision and Pattern
  Recognition (CVPR)}, 2023.

\bibitem[Cohen et~al.(2018)Cohen, Sharir, Levine, Tamari, Yakira, and
  Shashua]{cohen2018analysis}
Cohen, N., Sharir, O., Levine, Y., Tamari, R., Yakira, D., and Shashua, A.
\newblock Analysis and design of convolutional networks via hierarchical tensor
  decompositions, 2018.

\bibitem[Devlin et~al.(2019)Devlin, Chang, Lee, and Toutanova]{BERT}
Devlin, J., Chang, M.-W., Lee, K., and Toutanova, K.
\newblock {BERT}: Pre-training of deep bidirectional transformers for language
  understanding.
\newblock In \emph{Proceedings of the 2019 Conference of the North {A}merican
  Chapter of the Association for Computational Linguistics: Human Language
  Technologies, Volume 1 (Long and Short Papers)}, pp.\  4171--4186,
  Minneapolis, Minnesota, June 2019. Association for Computational Linguistics.
\newblock \doi{10.18653/v1/N19-1423}.
\newblock URL \url{https://aclanthology.org/N19-1423}.

\bibitem[Ding et~al.(2021)Ding, Shang, Wang, Sun, Tian, Wu, and
  Wang]{ding-etal-2021-ernie}
Ding, S., Shang, J., Wang, S., Sun, Y., Tian, H., Wu, H., and Wang, H.
\newblock {ERNIE}-{D}oc: A retrospective long-document modeling transformer.
\newblock In \emph{Proceedings of the 59th Annual Meeting of the Association
  for Computational Linguistics and the 11th International Joint Conference on
  Natural Language Processing (Volume 1: Long Papers)}, pp.\  2914--2927,
  Online, August 2021. Association for Computational Linguistics.
\newblock \doi{10.18653/v1/2021.acl-long.227}.
\newblock URL \url{https://aclanthology.org/2021.acl-long.227}.

\bibitem[Gao et~al.(2020)Gao, Biderman, Black, Golding, Hoppe, Foster, Phang,
  He, Thite, Nabeshima, Presser, and Leahy]{pile}
Gao, L., Biderman, S., Black, S., Golding, L., Hoppe, T., Foster, C., Phang,
  J., He, H., Thite, A., Nabeshima, N., Presser, S., and Leahy, C.
\newblock The {P}ile: An 800gb dataset of diverse text for language modeling.
\newblock \emph{arXiv preprint arXiv:2101.00027}, 2020.

\bibitem[Gholami et~al.(2021)Gholami, Kim, Dong, Yao, Mahoney, and
  Keutzer]{gholami2021survey}
Gholami, A., Kim, S., Dong, Z., Yao, Z., Mahoney, M.~W., and Keutzer, K.
\newblock A survey of quantization methods for efficient neural network
  inference, 2021.

\bibitem[Gray(1984)]{ClasssicVQ}
Gray, R.
\newblock Vector quantization.
\newblock \emph{IEEE ASSP Magazine}, 1\penalty0 (2):\penalty0 4--29, 1984.
\newblock \doi{10.1109/MASSP.1984.1162229}.

\bibitem[Gu et~al.(2022)Gu, Chen, Bao, Wen, Zhang, Chen, Yuan, and
  Guo]{Gu_2022_CVPR}
Gu, S., Chen, D., Bao, J., Wen, F., Zhang, B., Chen, D., Yuan, L., and Guo, B.
\newblock Vector quantized diffusion model for text-to-image synthesis.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition (CVPR)}, pp.\  10696--10706, June 2022.

\bibitem[Han et~al.(2015)Han, Pool, Tran, and Dally]{han2015learning}
Han, S., Pool, J., Tran, J., and Dally, W.
\newblock Learning both weights and connections for efficient neural network.
\newblock In \emph{Advances in Neural Information Processing Systems (NIPS)},
  pp.\  1135--1143, 2015.

\bibitem[Han et~al.(2016)Han, Mao, and Dally]{han2015deep_compression}
Han, S., Mao, H., and Dally, W.~J.
\newblock Deep compression: Compressing deep neural networks with pruning,
  trained quantization and huffman coding.
\newblock \emph{International Conference on Learning Representations (ICLR)},
  2016.

\bibitem[Hendrycks \& Gimpel(2020)Hendrycks and Gimpel]{GELU}
Hendrycks, D. and Gimpel, K.
\newblock Gaussian error linear units (gelus), 2020.

\bibitem[Hinton et~al.(2015)Hinton, Vinyals, and Dean]{hinton2015distilling}
Hinton, G., Vinyals, O., and Dean, J.
\newblock Distilling the knowledge in a neural network, 2015.

\bibitem[Hsu et~al.(2022)Hsu, Hua, Chang, Lou, Shen, and Jin]{hsu2022language}
Hsu, Y.-C., Hua, T., Chang, S., Lou, Q., Shen, Y., and Jin, H.
\newblock Language model compression with weighted low-rank factorization.
\newblock In \emph{International Conference on Learning Representations}, 2022.
\newblock URL \url{https://openreview.net/forum?id=uPv9Y3gmAI5}.

\bibitem[Hua et~al.(2022)Hua, Dai, Liu, and Le]{pmlr-v162-hua22a}
Hua, W., Dai, Z., Liu, H., and Le, Q.
\newblock Transformer quality in linear time.
\newblock In Chaudhuri, K., Jegelka, S., Song, L., Szepesvari, C., Niu, G., and
  Sabato, S. (eds.), \emph{Proceedings of the 39th International Conference on
  Machine Learning}, volume 162 of \emph{Proceedings of Machine Learning
  Research}, pp.\  9099--9117. PMLR, 17--23 Jul 2022.
\newblock URL \url{https://proceedings.mlr.press/v162/hua22a.html}.

\bibitem[Ippolito et~al.(2022)Ippolito, Yuan, Coenen, and
  Burnam]{ippolito2022creative}
Ippolito, D., Yuan, A., Coenen, A., and Burnam, S.
\newblock Creative writing with an ai-powered writing assistant: Perspectives
  from professional writers, 2022.

\bibitem[Jang et~al.(2017)Jang, Gu, and Poole]{jang2017categorical}
Jang, E., Gu, S., and Poole, B.
\newblock Categorical reparameterization with gumbel-softmax.
\newblock In \emph{International Conference on Learning Representations}, 2017.
\newblock URL \url{https://openreview.net/forum?id=rkE3y85ee}.

\bibitem[Levine et~al.(2017)Levine, Sharir, and Shashua]{2017benefits}
Levine, Y., Sharir, O., and Shashua, A.
\newblock Benefits of depth for long-term memory of recurrent networks.
\newblock \emph{arXiv preprint arXiv:1710.09431}, 2017.

\bibitem[Li et~al.(2022)Li, Lin, Meng, Ermon, song han, and
  Zhu]{li2022efficient}
Li, M., Lin, J., Meng, C., Ermon, S., song han, and Zhu, J.-Y.
\newblock Efficient spatially sparse inference for conditional {GAN}s and
  diffusion models.
\newblock In Oh, A.~H., Agarwal, A., Belgrave, D., and Cho, K. (eds.),
  \emph{Advances in Neural Information Processing Systems}, 2022.
\newblock URL \url{https://openreview.net/forum?id=AUz5Oig77OS}.

\bibitem[Liu et~al.(2021)Liu, Lamb, Kawaguchi, ALIAS PARTH~GOYAL, Sun, Mozer,
  and Bengio]{NEURIPS2021_10907813}
Liu, D., Lamb, A.~M., Kawaguchi, K., ALIAS PARTH~GOYAL, A.~G., Sun, C., Mozer,
  M.~C., and Bengio, Y.
\newblock Discrete-valued neural communication.
\newblock In Ranzato, M., Beygelzimer, A., Dauphin, Y., Liang, P., and Vaughan,
  J.~W. (eds.), \emph{Advances in Neural Information Processing Systems},
  volume~34, pp.\  2109--2121. Curran Associates, Inc., 2021.
\newblock URL
  \url{https://proceedings.neurips.cc/paper_files/paper/2021/file/10907813b97e249163587e6246612e21-Paper.pdf}.

\bibitem[Liu et~al.(2022)Liu, Lamb, Ji, Notsawo, Mozer, Bengio, and
  Kawaguchi]{liu2022adaptive}
Liu, D., Lamb, A., Ji, X., Notsawo, P., Mozer, M., Bengio, Y., and Kawaguchi,
  K.
\newblock Adaptive discrete communication bottlenecks with dynamic vector
  quantization, 2022.

\bibitem[Liu et~al.(2019)Liu, Ott, Goyal, Du, Joshi, Chen, Levy, Lewis,
  Zettlemoyer, and Stoyanov]{liu2019roberta}
Liu, Y., Ott, M., Goyal, N., Du, J., Joshi, M., Chen, D., Levy, O., Lewis, M.,
  Zettlemoyer, L., and Stoyanov, V.
\newblock Roberta: A robustly optimized bert pretraining approach.
\newblock \emph{arXiv preprint arXiv:1907.11692}, 2019.

\bibitem[Ma et~al.(2022)Ma, Zhou, Kong, He, Gui, Neubig, May, and
  Luke]{ma2022mega}
Ma, X., Zhou, C., Kong, X., He, J., Gui, L., Neubig, G., May, J., and Luke, Z.
\newblock Mega: Moving average equipped gated attention.
\newblock \emph{arXiv preprint arXiv:2209.10655}, 2022.

\bibitem[Maas et~al.(2011)Maas, Daly, Pham, Huang, Ng, and Potts]{maas2011IMDB}
Maas, A.~L., Daly, R.~E., Pham, P.~T., Huang, D., Ng, A.~Y., and Potts, C.
\newblock Learning word vectors for sentiment analysis.
\newblock In \emph{Proceedings of the 49th Annual Meeting of the Association
  for Computational Linguistics: Human Language Technologies}, pp.\  142--150,
  Portland, Oregon, USA, June 2011. Association for Computational Linguistics.
\newblock URL \url{https://aclanthology.org/P11-1015}.

\bibitem[Pan et~al.(2018)Pan, Lin, Fang, Huang, Zhou, and Lu]{Pan_2018_CVPR}
Pan, B., Lin, W., Fang, X., Huang, C., Zhou, B., and Lu, C.
\newblock Recurrent residual module for fast inference in videos.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition (CVPR)}, June 2018.

\bibitem[Parger et~al.(2022)Parger, Tang, Twigg, Keskin, Wang, and
  Steinberger]{parger2022deltacnn}
Parger, M., Tang, C., Twigg, C.~D., Keskin, C., Wang, R., and Steinberger, M.
\newblock Deltacnn: End-to-end cnn inference of sparse frame differences in
  videos.
\newblock \emph{CVPR 2022}, June 2022.

\bibitem[Radford et~al.(2019)Radford, Wu, Child, Luan, Amodei, and
  Sutskever]{GPT2}
Radford, A., Wu, J., Child, R., Luan, D., Amodei, D., and Sutskever, I.
\newblock Language models are unsupervised multitask learners.
\newblock 2019.

\bibitem[Ren et~al.(2018)Ren, Pokrovsky, Yang, and Urtasun]{ren2018sbnet}
Ren, M., Pokrovsky, A., Yang, B., and Urtasun, R.
\newblock Sbnet: Sparse blocks network for fast inference.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, pp.\  8711--8720, 2018.

\bibitem[Sanh et~al.(2020)Sanh, Debut, Chaumond, and Wolf]{sanh2020distilbert}
Sanh, V., Debut, L., Chaumond, J., and Wolf, T.
\newblock Distilbert, a distilled version of bert: smaller, faster, cheaper and
  lighter, 2020.

\bibitem[Sharir \& Shashua(2018)Sharir and Shashua]{sharir2018expressive}
Sharir, O. and Shashua, A.
\newblock On the expressive power of overlapping architectures of deep
  learning.
\newblock In \emph{6th International Conference on Learning Representations
  (ICLR)}, 2018.

\bibitem[Shi et~al.(2022)Shi, Zhao, Tang, Wang, Li, Bi, Jiang, Huang, Cui,
  Huang, Zhou, Dai, and Ma]{shi2022effidit}
Shi, S., Zhao, E., Tang, D., Wang, Y., Li, P., Bi, W., Jiang, H., Huang, G.,
  Cui, L., Huang, X., Zhou, C., Dai, Y., and Ma, D.
\newblock Effidit: Your ai writing assistant, 2022.

\bibitem[van~den Oord et~al.(2017)van~den Oord, Vinyals, and
  kavukcuoglu]{VQ2017_7a98af17}
van~den Oord, A., Vinyals, O., and kavukcuoglu, k.
\newblock Neural discrete representation learning.
\newblock In Guyon, I., Luxburg, U.~V., Bengio, S., Wallach, H., Fergus, R.,
  Vishwanathan, S., and Garnett, R. (eds.), \emph{Advances in Neural
  Information Processing Systems}, volume~30. Curran Associates, Inc., 2017.
\newblock URL
  \url{https://proceedings.neurips.cc/paper_files/paper/2017/file/7a98af17e63a0ac09ce2e96d03992fbc-Paper.pdf}.

\bibitem[Vaswani et~al.(2017)Vaswani, Shazeer, Parmar, Uszkoreit, Jones, Gomez,
  Kaiser, and Polosukhin]{transformers}
Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A.~N.,
  Kaiser, L.~u., and Polosukhin, I.
\newblock Attention is all you need.
\newblock In Guyon, I., Luxburg, U.~V., Bengio, S., Wallach, H., Fergus, R.,
  Vishwanathan, S., and Garnett, R. (eds.), \emph{Advances in Neural
  Information Processing Systems}, volume~30. Curran Associates, Inc., 2017.
\newblock URL
  \url{https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf}.

\bibitem[Xiao et~al.(2022)Xiao, Lin, Seznec, Wu, Demouth, and
  Han]{xiao2022smoothquant}
Xiao, G., Lin, J., Seznec, M., Wu, H., Demouth, J., and Han, S.
\newblock Smoothquant: Accurate and efficient post-training quantization for
  large language models.
\newblock \emph{arXiv}, 2022.

\bibitem[Yu et~al.(2022)Yu, Li, Koh, Zhang, Pang, Qin, Ku, Xu, Baldridge, and
  Wu]{yu2022vectorquantized}
Yu, J., Li, X., Koh, J.~Y., Zhang, H., Pang, R., Qin, J., Ku, A., Xu, Y.,
  Baldridge, J., and Wu, Y.
\newblock Vector-quantized image modeling with improved {VQGAN}.
\newblock In \emph{International Conference on Learning Representations}, 2022.
\newblock URL \url{https://openreview.net/forum?id=pfNyExj7z2}.

\bibitem[Yu et~al.(2017)Yu, Liu, Wang, and Tao]{Yu_2017_CVPR}
Yu, X., Liu, T., Wang, X., and Tao, D.
\newblock On compressing deep models by low rank and sparse decomposition.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition (CVPR)}, July 2017.

\bibitem[Zeghidour et~al.(2021)Zeghidour, Luebs, Omran, Skoglund, and
  Tagliasacchi]{zeghidour2021soundstream}
Zeghidour, N., Luebs, A., Omran, A., Skoglund, J., and Tagliasacchi, M.
\newblock Soundstream: An end-to-end neural audio codec, 2021.

\bibitem[Zhang et~al.(2022)Zhang, Roller, Goyal, Artetxe, Chen, Chen, Dewan,
  Diab, Li, Lin, Mihaylov, Ott, Shleifer, Shuster, Simig, Koura, Sridhar, Wang,
  and Zettlemoyer]{zhang2022opt}
Zhang, S., Roller, S., Goyal, N., Artetxe, M., Chen, M., Chen, S., Dewan, C.,
  Diab, M., Li, X., Lin, X.~V., Mihaylov, T., Ott, M., Shleifer, S., Shuster,
  K., Simig, D., Koura, P.~S., Sridhar, A., Wang, T., and Zettlemoyer, L.
\newblock Opt: Open pre-trained transformer language models, 2022.

\end{thebibliography}
