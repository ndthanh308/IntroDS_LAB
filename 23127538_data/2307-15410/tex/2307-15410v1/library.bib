Automatically generated by Mendeley Desktop 1.19.8
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop

@article{Matsumura2019,
abstract = {In this research, we tackle the problem of picking an object from randomly stacked pile. Since complex physical phenomena of contact among objects and fingers makes it difficult to perform the bin-picking with high success rate, we consider introducing a learning based approach. For the purpose of collecting enough number of training data within a reasonable period of time, we introduce a physics simulator where approximation is used for collision checking. In this paper, we first formulate the learning based robotic bin-picking by using CNN (Convolutional Neural Network). We also obtain the optimum grasping posture of parallel jaw gripper by using CNN. Finally, we show that the effect of approximation introduced in collision checking is relaxed if we use exact 3D model to generate the depth image of the pile as an input to CNN.},
archivePrefix = {arXiv},
arxivId = {1805.08936},
author = {Matsumura, Ryo and Harada, Kensuke and Domae, Yukiyasu and Wan, Weiwei},
doi = {10.1007/978-3-030-01370-7_61},
eprint = {1805.08936},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Matsumura et al. - 2019 - Learning based industrial bin-picking trained with approximate physics simulator.pdf:pdf},
isbn = {9783030013691},
issn = {21945357},
journal = {Advances in Intelligent Systems and Computing},
pages = {786--798},
title = {{Learning based industrial bin-picking trained with approximate physics simulator}},
volume = {867},
year = {2019}
}
@article{Madotto2018,
abstract = {End-to-end task-oriented dialog systems usually suffer from the challenge of incorporating knowledge bases. In this paper, we propose a novel yet simple end-to-end differentiable model called memory-to-sequence (Mem2Seq) to address this issue. Mem2Seq is the first neural generative model that combines the multi-hop attention over memories with the idea of pointer network. We empirically show how Mem2Seq controls each generation step, and how its multi-hop attention mechanism helps in learning correlations between memories. In addition, our model is quite general without complicated task-specific designs. As a result, we show that Mem2Seq can be trained faster and attain the state-of-the-art performance on three different task-oriented dialog datasets.},
archivePrefix = {arXiv},
arxivId = {1804.08217},
author = {Madotto, Andrea and Wu, Chien Sheng and Fung, Pascale},
doi = {10.18653/v1/p18-1136},
eprint = {1804.08217},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Madotto, Wu, Fung - 2018 - MEM2Seq Effectively incorporating knowledge bases into end-to-end task-oriented dialog systems.pdf:pdf},
isbn = {9781948087322},
journal = {ACL 2018 - 56th Annual Meeting of the Association for Computational Linguistics, Proceedings of the Conference (Long Papers)},
pages = {1468--1478},
title = {{MEM2Seq: Effectively incorporating knowledge bases into end-to-end task-oriented dialog systems}},
volume = {1},
year = {2018}
}
@inproceedings{Schubert2015,
abstract = {In recent years, there has been renewed interest in the NLP community in genuine language understanding and dialogue. Thus the long-standing issue of how the semantic content of language should be represented is reentering the communal discussion. This paper provides a brief "opinionated survey" of broad-coverage semantic representation (SR). It suggests multiple desiderata for such representations, and then outlines more than a dozen approaches to SR-some long-standing, and some more recent, providing quick characterizations , pros, cons, and some comments on implementations .},
author = {Schubert, Lenhart},
booktitle = {Proc. of the AAAI Conference},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Schubert - 2015 - Semantic Representation.pdf:pdf},
keywords = {intelligent tutoring systems,language agnostic,semantic analysis,vocabulary},
pages = {1--12},
title = {{Semantic Representation}},
url = {www.aaai.org},
year = {2015}
}
@article{Peng2020,
abstract = {As a crucial component in task-oriented dialog systems, the Natural Language Generation (NLG) module converts a dialog act represented in a semantic form into a response in natural language. The success of traditional template-based or statistical models typically relies on heavily annotated data, which is infeasible for new domains. Therefore, it is pivotal for an NLG system to generalize well with limited labelled data in real applications. To this end, we present FewShotWoz, the first NLG benchmark to simulate the few-shot learning setting in task-oriented dialog systems. Further, we develop the SC-GPT model. It is pre-trained on a large set of annotated NLG corpus to acquire the controllable generation ability, and fine-tuned with only a few domain-specific labels to adapt to new domains. Experiments on FewShotWoz and the large Multi-Domain-WOZ datasets show that the proposed SC-GPT significantly outperforms existing methods, measured by various automatic metrics and human evaluations.},
archivePrefix = {arXiv},
arxivId = {2002.12328},
author = {Peng, Baolin and Zhu, Chenguang and Li, Chunyuan and Li, Xiujun and Li, Jinchao and Zeng, Michael and Gao, Jianfeng},
eprint = {2002.12328},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Peng et al. - 2020 - Few-shot Natural Language Generation for Task-Oriented Dialog.pdf:pdf},
title = {{Few-shot Natural Language Generation for Task-Oriented Dialog}},
url = {https://arxiv.org/abs/2002.12328},
year = {2020}
}
@article{Wolf2019,
abstract = {We introduce a new approach to generative data-driven dialogue systems (e.g. chatbots) called TransferTransfo which is a combination of a Transfer learning based training scheme and a high-capacity Transformer model. Fine-tuning is performed by using a multi-task objective which combines several unsupervised prediction tasks. The resulting fine-tuned model shows strong improvements over the current state-of-the-art end-to-end conversational models like memory augmented seq2seq and information-retrieval models. On the privately held PERSONA-CHAT dataset of the Conversational Intelligence Challenge 2, this approach obtains a new state-of-the-art, with respective perplexity, Hits@1 and F1 metrics of 16.28 (45 {\%} absolute improvement), 80.7 (46 {\%} absolute improvement) and 19.5 (20 {\%} absolute improvement).},
author = {Wolf, Thomas and Sanh, Victor and Chaumond, Julien and Delangue, Clement},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wolf et al. - 2019 - TransferTransfo A Transfer Learning Approach for Neural Network Based Conversational Agents.pdf:pdf},
title = {{TransferTransfo: A Transfer Learning Approach for Neural Network Based Conversational Agents}},
url = {http://arxiv.org/abs/1901.08149},
year = {2019}
}
@article{Deriu2019,
abstract = {In this paper we survey the methods and concepts developed for the evaluation of dialogue systems. Evaluation is a crucial part during the development process. Often, dialogue systems are evaluated by means of human evaluations and questionnaires. However, this tends to be very cost and time intensive. Thus, much work has been put into finding methods, which allow to reduce the involvement of human labour. In this survey, we present the main concepts and methods. For this, we differentiate between the various classes of dialogue systems (task-oriented dialogue systems, conversational dialogue systems, and question-answering dialogue systems). We cover each class by introducing the main technologies developed for the dialogue systems and then by presenting the evaluation methods regarding this class.},
author = {Deriu, Jan and Rodrigo, Alvaro and Otegi, Arantxa and Echegoyen, Guillermo and Rosset, Sophie and Agirre, Eneko and Cieliebak, Mark},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Deriu et al. - 2020 - Survey on Evaluation Methods for Dialogue Systems.pdf:pdf},
journal = {Artificial Intelligence Review},
title = {{Survey on Evaluation Methods for Dialogue Systems}},
year = {2020}
}
@article{Rosenblatt1958,
abstract = {To answer the questions of how information about the physical world is sensed, in what form is information remembered, and how does information retained in memory influence recognition and behavior, a theory is developed for a hypothetical nervous system called a perceptron. The theory serves as a bridge between biophysics and psychology. It is possible to predict learning curves from neurological variables and vice versa. The quantitative statistical approach is fruitful in the understanding of the organization of cognitive systems. 18 references. (PsycINFO Database Record (c) 2006 APA, all rights reserved). {\textcopyright} 1958 American Psychological Association.},
author = {Rosenblatt, F.},
doi = {10.1037/h0042519},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rosenblatt - 1958 - The perceptron A probabilistic model for information storage and organization in the brain.pdf:pdf},
issn = {0033295X},
journal = {Psychological Review},
keywords = {PERCEPTION, AS INFORMATION STORAGE MODEL INFORMATI},
number = {6},
pages = {386--408},
pmid = {13602029},
title = {{The perceptron: A probabilistic model for information storage and organization in the brain}},
volume = {65},
year = {1958}
}
@article{Hochreiter2001,
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Hochreiter, Sepp and Frasconi, Paolo},
doi = {10.1109/9780470544037.ch14},
eprint = {arXiv:1011.1669v3},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hochreiter, Frasconi - 2001 - Gradient Flow in Recurrent Neural Nets The Difficulty of Learning Long-Term Dependencies. A Field Guide t.pdf:pdf},
isbn = {978-0-7803-5369-5},
issn = {1098-6596},
journal = {A Field Guide to Dynamical Recurrent Neural Network},
pages = {401--403},
pmid = {25246403},
title = {{Gradient Flow in Recurrent Neural Nets : The Difficulty of Learning Long-Term Dependencies. A Field Guide to Dynamical Recurrent Neural Network}},
year = {2001}
}
@inproceedings{Peters2018,
abstract = {We introduce a new type of deep contextualized word representation that models both (1) complex characteristics of word use (e.g., syntax and semantics), and (2) how these uses vary across linguistic contexts (i.e., to model polysemy). Our word vectors are learned functions of the internal states of a deep bidirectional language model (biLM), which is pretrained on a large text corpus. We show that these representations can be easily added to existing models and significantly improve the state of the art across six challenging NLP problems, including question answering, textual entailment and sentiment analysis. We also present an analysis showing that exposing the deep internals of the pre-Trained network is crucial, allowing downstream models to mix different types of semi-supervision signals.},
archivePrefix = {arXiv},
arxivId = {1802.05365},
author = {Peters, Matthew E. and Neumann, Mark and Iyyer, Mohit and Gardner, Matt and Clark, Christopher and Lee, Kenton and Zettlemoyer, Luke},
booktitle = {Proc. of the Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies},
eprint = {1802.05365},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Peters et al. - 2018 - Deep Contextualized Word Representations.pdf:pdf},
title = {{Deep Contextualized Word Representations}},
year = {2018}
}
@article{Thompson1977,
author = {Thompson, H and Winograd, Terry and Bobrow, D and Norman, D and Kay, Martin and Kaplan, R},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Thompson et al. - 1977 - GUS, a Frame-Driven Dialog System.pdf:pdf},
journal = {Artificial Intelligence},
number = {2},
pages = {155--173},
title = {{GUS, a Frame-Driven Dialog System}},
url = {http://explorer.csse.uwa.edu.au/reference/browse{\_}paper.php?pid=233281430},
volume = {8},
year = {1977}
}
@inproceedings{Finch2020,
author = {Finch, Sarah E. and Choi, Jinho D.},
booktitle = {Proc. of the Annual Meeting of the Special Interest Group on Discourse and Dialogue},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Finch, Choi - 2020 - Towards Unified Dialogue System Evaluation A Comprehensive Analysis of Current Evaluation Protocols.pdf:pdf},
title = {{Towards Unified Dialogue System Evaluation: A Comprehensive Analysis of Current Evaluation Protocols}},
year = {2020}
}
@article{Zaib2020,
abstract = {Building a dialogue system that can communicate naturally with humans is a challenging yet interesting problem of agent-based computing. The rapid growth in this area is usually hindered by the long-standing problem of data scarcity as these systems are expected to learn syntax, grammar, decision making, and reasoning from insufficient amounts of task-specific dataset. The recently introduced pre-trained language models have the potential to address the issue of data scarcity and bring considerable advantages by generating contextualized word embeddings. These models are considered counterpart of ImageNet in NLP and have demonstrated to capture different facets of language such as hierarchical relations, long-term dependency, and sentiment. In this short survey paper, we discuss the recent progress made in the field of pre-trained language models. We also deliberate that how the strengths of these language models can be leveraged in designing more engaging and more eloquent conversational agents. This paper, therefore, intends to establish whether these pre-trained models can overcome the challenges pertinent to dialogue systems, and how their architecture could be exploited in order to overcome these challenges. Open challenges in the field of dialogue systems have also been deliberated.},
author = {Zaib, Munazza and Sheng, Quan Z. and {Emma Zhang}, Wei},
doi = {10.1145/3373017.3373028},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zaib, Sheng, Emma Zhang - 2020 - A Short Survey of Pre-trained Language Models for Conversational AI-A New Age in NLP.pdf:pdf},
isbn = {9781450376976},
journal = {ACM International Conference Proceeding Series},
keywords = {Agent-based computing,dialogue systems,intelligent agents,natural language processing,pre-trained language models},
number = {March 2021},
title = {{A Short Survey of Pre-trained Language Models for Conversational AI-A New Age in NLP}},
year = {2020}
}
@article{Casanueva2020,
abstract = {Building conversational systems in new domains and with added functionality requires resource-efficient models that work under low-data regimes (i.e., in few-shot setups). Motivated by these requirements, we introduce intent detection methods backed by pretrained dual sentence encoders such as USE and ConveRT. We demonstrate the usefulness and wide applicability of the proposed intent detectors, showing that: 1) they outperform intent detectors based on fine-tuning the full BERT-Large model or using BERT as a fixed black-box encoder on three diverse intent detection data sets; 2) the gains are especially pronounced in few-shot setups (i.e., with only 10 or 30 annotated examples per intent); 3) our intent detectors can be trained in a matter of minutes on a single CPU; and 4) they are stable across different hyperparameter settings. In hope of facilitating and democratizing research focused on intention detection, we release our code, as well as a new challenging single-domain intent detection dataset comprising 13,083 annotated examples over 77 intents.},
archivePrefix = {arXiv},
arxivId = {2003.04807},
author = {Casanueva, I{\~{n}}igo and Tem{\v{c}}inas, Tadas and Gerz, Daniela and Henderson, Matthew and Vuli{\'{c}}, Ivan},
doi = {10.18653/v1/2020.nlp4convai-1.5},
eprint = {2003.04807},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Casanueva et al. - 2020 - Efficient intent detection with dual sentence encoders.pdf:pdf},
issn = {23318422},
journal = {arXiv},
title = {{Efficient intent detection with dual sentence encoders}},
year = {2020}
}
@inproceedings{Zhu2015,
abstract = {Books are a rich source of both fine-grained information, how a character, an object or a scene looks like, as well as high-level semantics, what someone is thinking, feeling and how these states evolve through a story. This paper aims to align books to their movie releases in order to provide rich descriptive explanations for visual content that go semantically far beyond the captions available in the current datasets. To align movies and books we propose a neural sentence embedding that is trained in an unsupervised way from a large corpus of books, as well as a video-text neural embedding for computing similarities between movie clips and sentences in the book. We propose a context-aware CNN to combine information from multiple sources. We demonstrate good quantitative performance for movie/book alignment and show several qualitative examples that showcase the diversity of tasks our model can be used for.},
author = {Zhu, Yukun and Kiros, Ryan and Zemel, Rich and Salakhutdinov, Ruslan and Urtasun, Raquel and Torralba, Antonio and Fidler, Sanja},
booktitle = {Proc. of the IEEE International Conference on Computer Vision},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhu et al. - 2015 - Aligning Books and Movies Towards Story-like Visual Explanations by Watching Movies and Reading Books.pdf:pdf},
title = {{Aligning Books and Movies: Towards Story-like Visual Explanations by Watching Movies and Reading Books}},
year = {2015}
}
@article{Pereira2016,
abstract = {In the last years, chatbots have gained new attention, due to the interest showed by widely known personalities and companies. The concept is broad, and, in this paper we target the work developed by the (old) community that is typically associated with chatbot's competitions. In our opinion, they contribute with very interesting know-how, but specially with large-scale corpora, gathered by interactions with real people, an invaluable resource considering the renewed interest in Deep Nets.},
archivePrefix = {arXiv},
arxivId = {1609.06479},
author = {Pereira, Maria Jo{\~{a}}o and Coheur, Lu{\'{i}}sa and Fialho, Pedro and Ribeiro, Ricardo},
eprint = {1609.06479},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Pereira et al. - 2016 - Chatbots' Greetings to Human-Computer Communication.pdf:pdf},
issn = {16130073},
keywords = {Agent-based interaction,Intelligent agents,Interaction design,Natural language interfaces},
title = {{Chatbots' Greetings to Human-Computer Communication}},
year = {2016}
}
@inproceedings{Zhao2017,
abstract = {While recent neural encoder-decoder models have shown great promise in modeling open-domain conversations, they often generate dull and generic responses. Unlike past work that has focused on diversifying the output of the decoder at word-level to alleviate this problem, we present a novel framework based on conditional variational autoencoders that captures the discourse-level diversity in the encoder. Our model uses latent variables to learn a distribution over potential conversational intents and generates diverse responses using only greedy decoders. We have further developed a novel variant that is integrated with linguistic prior knowledge for better performance. Finally, the training procedure is improved by introducing a bag-of-word loss. Our proposed models have been validated to generate significantly more diverse responses than baseline approaches and exhibit competence in discourse-level decision-making.1},
author = {Zhao, Tiancheng and Zhao, Ran and Eskenazi, Maxine},
booktitle = {Proc. of the Annual Meeting of the Association for Computational Linguistics},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhao, Zhao, Eskenazi - 2017 - Learning Discourse-level Diversity for Neural Dialog Models using Conditional Variational Autoencoders.pdf:pdf},
title = {{Learning Discourse-level Diversity for Neural Dialog Models using Conditional Variational Autoencoders}},
year = {2017}
}
@inproceedings{Ma2019,
abstract = {This paper presents the results of the WMT19 Metrics Shared Task. Participants were asked to score the out},
author = {Ma, Qingsong and Wei, Johnny and Bojar, Ondřej and Graham, Yvette},
booktitle = {Proc. of the Conference on Machine Translation},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ma et al. - 2019 - Results of the WMT19 Metrics Shared Task Segment-Level and Strong MT Systems Pose Big Challenges.pdf:pdf},
title = {{Results of the WMT19 Metrics Shared Task: Segment-Level and Strong MT Systems Pose Big Challenges}},
year = {2019}
}
@inproceedings{Pascanu2013,
abstract = {There are two widely known issues with properly training recurrent neural networks, the vanishing and the exploding gradient problems detailed in Bengio et al. (1994). In this paper we attempt to improve the understanding of the underlying issues by exploring these problems from an analytical, a geometric and a dynamical systems perspective. Our analysis is used to justify a simple yet effective solution. We propose a gradient norm clipping strategy to deal with exploding gradients and a soft constraint for the vanishing gradients problem. We validate empirically our hypothesis and proposed solutions in the experimental section. Copyright 2013 by the author(s).},
author = {Pascanu, Razvan and Mikolov, Tomas and Bengio, Yoshua},
booktitle = {Proc. of the International Conference on Machine Learning},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Pascanu, Mikolov, Bengio - 2013 - On the Difficulty of Training Recurrent Neural Networks.pdf:pdf},
title = {{On the Difficulty of Training Recurrent Neural Networks}},
year = {2013}
}
@inproceedings{Wu2019,
abstract = {Though great progress has been made for human-machine conversation, current dialogue system is still in its infancy: it usually converses passively and utters words more as a matter of response, rather than on its own initiatives. In this paper, we take a radical step towards building a human-like conversational agent: endowing it with the ability of proactively leading the conversation (introducing a new topic or maintaining the current topic). To facilitate the development of such conversation systems, we create a new dataset named DuConv where one acts as a conversation leader and the other acts as the follower. The leader is provided with a knowledge graph and asked to sequentially change the discussion topics, following the given conversation goal, and meanwhile keep the dialogue as natural and engaging as possible. DuConv enables a very challenging task as the model needs to both understand dialogue and plan over the given knowledge graph. We establish baseline results on this dataset (about 270K utterances and 30k dialogues) using several state-of-the-art models. Experimental results show that dialogue models that plan over the knowledge graph can make full use of related knowledge to generate more diverse multi-turn conversations. The baseline systems along with the dataset are publicly available.},
author = {Wu, Wenquan and Guo, Zhen and Zhou, Xiangyang and Wu, Hua and Zhang, Xiyuan and Lian, Rongzhong and Wang, Haifeng},
booktitle = {Proc. of the Annual Meeting of the Association for Computational Linguistics},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wu et al. - 2019 - Proactive Human-Machine Conversation with Explicit Conversation Goals.pdf:pdf},
title = {{Proactive Human-Machine Conversation with Explicit Conversation Goals}},
year = {2019}
}
@article{Pal2020,
abstract = {Spoken dialogue systems typically use a list of top-N ASR hypotheses for inferring the semantic meaning and tracking the state of the dialogue. However ASR graphs, such as confusion networks (confnets), provide a compact representation of a richer hypothesis space than a top-N ASR list. In this paper, we study the benefits of using confusion networks with a state-of-the-art neural dialogue state tracker (DST). We encode the 2-dimensional confnet into a 1-dimensional sequence of embeddings using an attentional confusion network encoder which can be used with any DST system. Our confnet encoder is plugged into the state-of-the-art'Global-locally Self-Attentive Dialogue State Tacker' (GLAD) model for DST and obtains significant improvements in both accuracy and inference time compared to using top-N ASR hypotheses.},
archivePrefix = {arXiv},
arxivId = {2002.00768},
author = {Pal, Vaishali and Guillot, Fabien and Renders, Jean Michel and Besacier, Laurent},
eprint = {2002.00768},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Pal et al. - 2020 - Modeling ASR ambiguity for neural dialogue state tracking using word confusion networks.pdf:pdf},
issn = {23318422},
journal = {arXiv},
keywords = {Automatic Speech Recognition,Confusion Network,Neural Dialogue State Tracking,Spoken Dialogue Systems},
pages = {2--6},
title = {{Modeling ASR ambiguity for neural dialogue state tracking using word confusion networks}},
year = {2020}
}
@inproceedings{Holtzman2019,
abstract = {Despite considerable advances in neural language modeling, it remains an open question what the best strategy is for generating text from a language model. Counter-intuitively, maximization-based decoding methods such as beam search lead to degeneration — output text that is bland, incoherent, or repetitive. We propose Nucleus Sampling, a simple but effective method to draw high quality text out of neural language models by truncating the unreliable tail of the probability distribution, sampling words from the nucleus of tokens containing most probability mass. We compare generations from maximization-based and stochastic decoding methods to the distribution of human text along several axes including likelihood, diversity, and repetition. Our results show that (1) maximization is an inappropriate decoding objective for open-ended text generation, (2) the probability distributions of the best current language models have an unreliable tail which needs to be truncated during generation and (3) Nucleus Sampling is the best available decoding strategy for generating long-form text that is both high-quality — as measured by human evaluation — and as diverse as human-written text.},
author = {Holtzman, Ari and Buys, Jan and Du, Leo and Forbes, Maxwell and Choi, Yejin},
booktitle = {Proc. of the International Conference on Learning Representations},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Holtzman et al. - 2020 - The Curious Case of Neural Text Degeneration.pdf:pdf},
title = {{The Curious Case of Neural Text Degeneration}},
year = {2020}
}
@inproceedings{Liu2016a,
abstract = {We investigate evaluation metrics for dialogue response generation systems where supervised labels, such as task completion, are not available. Recent works in response generation have adopted metrics from machine translation to compare a model's generated response to a single target response. We show that these metrics correlate very weakly with human judgements in the non-technical Twitter domain, and not at all in the technical Ubuntu domain. We provide quantitative and qualitative results highlighting specific weaknesses in existing metrics, and provide recommendations for future development of better automatic evaluation metrics for dialogue systems.},
author = {Liu, Chia Wei and Lowe, Ryan and Serban, Iulian V. and Noseworthy, Michael and Charlin, Laurent and Pineau, Joelle},
booktitle = {Proc. of the Conference on Empirical Methods in Natural Language Processing},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Liu et al. - 2016 - How NOT To Evaluate Your Dialogue System An Empirical Study of Unsupervised Evaluation Metrics for Dialogue Response.pdf:pdf},
title = {{How NOT To Evaluate Your Dialogue System: An Empirical Study of Unsupervised Evaluation Metrics for Dialogue Response Generation}},
year = {2016}
}
@inproceedings{Williams2013,
abstract = {In a spoken dialog system, dialog state tracking deduces information about the user's goal as the dialog progresses, synthesizing evidence such as dialog acts over multiple turns with external data sources. Recent approaches have been shown to overcome ASR and SLU errors in some applications. However, there are currently no common testbeds or evaluation measures for this task, hampering progress. The dialog state tracking challenge seeks to address this by providing a heterogeneous corpus of 15K human-computer dialogs in a standard format, along with a suite of 11 evaluation metrics. The challenge received a total of 27 entries from 9 research groups. The results show that the suite of performance metrics cluster into 4 natural groups. Moreover, the dialog systems that benefit most from dialog state tracking are those with less discriminative speech recognition confidence scores. Finally, generalization is a key problem: in 2 of the 4 test sets, fewer than half of the entries out-performed simple baselines.},
author = {Williams, Jason and Raux, Antoine and Ramachandran, Deepak and Black, Alan},
booktitle = {Proc. of the Annual Meeting of the Special Interest Group on Discourse and Dialogue, Proceedings of the Conference},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Williams et al. - 2016 - The Dialog State Tracking Challenge Series A Review.pdf:pdf},
keywords = {conversational sys-,dialog modeling,dialog state tracking,spoken dialog systems,spoken language understanding,tems},
title = {{The Dialog State Tracking Challenge Series: A Review}},
year = {2016}
}
@inproceedings{Young2013,
abstract = {Statistical dialogue systems are motivated by the need for a data-driven framework that reduces the cost of laboriously hand-crafting complex dialogue managers and that provides robustness against the errors created by speech recognisers operating in noisy environments. By including an explicit Bayesian model of uncertainty and by optimising the policy via a reward-driven process, partially observable Markov decision processes (POMDPs) provide such a framework. However, exact model representation and optimisation is computationally intractable. Hence, the practical application of POMDP-based systems requires efficient algorithms and carefully constructed approximations. This review article provides an overview of the current state of the art in the development of POMDP-based spoken dialogue systems.},
author = {Young, Steve and Gasiˇ c, Milica and Thomson, Blaise and Williams, Jason D},
booktitle = {Proc. of the IEEE},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Young et al. - 2013 - POMDP-based Statistical Spoken Dialogue Systems a Review.pdf:pdf},
title = {{POMDP-based Statistical Spoken Dialogue Systems: a Review}},
year = {2013}
}
@article{Laban2021,
abstract = {Recent progress in Natural Language Understanding (NLU) has seen the latest models outperform human performance on many standard tasks. These impressive results have led the community to introspect on dataset limitations, and iterate on more nuanced challenges. In this paper, we introduce the task of HeadLine Grouping (HLG) and a corresponding dataset (HLGD) consisting of 20,056 pairs of news headlines, each labeled with a binary judgement as to whether the pair belongs within the same group. On HLGD, human annotators achieve high performance of around 0.9 F-1, while current state-of-the art Transformer models only reach 0.75 F-1, opening the path for further improvements. We further propose a novel unsupervised Headline Generator Swap model for the task of HeadLine Grouping that achieves within 3 F-1 of the best supervised model. Finally, we analyze high-performing models with consistency tests, and find that models are not consistent in their predictions, revealing modeling limits of current architectures.},
archivePrefix = {arXiv},
arxivId = {2105.05391},
author = {Laban, Philippe and Bandarkar, Lucas and Hearst, Marti A.},
eprint = {2105.05391},
file = {:home/theritacosta/Desktop/botbuilder{\_}project/reading/NAACL2021{\_}HLG.pdf:pdf},
title = {{News Headline Grouping as a Challenging NLU Task}},
url = {http://arxiv.org/abs/2105.05391},
year = {2021}
}
@article{Vakulenko2020a,
abstract = {The dependency between an adequate question formulation and correct answer selection is a very intriguing but still underexplored area. In this paper, we show that question rewriting (QR) of the conversational context allows to shed more light on this phenomenon and also use it to evaluate robustness of different answer selection approaches. We introduce a simple framework that enables an automated analysis of the conversational question answering (QA) performance using question rewrites, and present the results of this analysis on the TREC CAsT and QuAC (CANARD) datasets. Our experiments uncover sensitivity to question formulation of the popular state-of-the-art models for reading comprehension and passage ranking. Our results demonstrate that the reading comprehension model is insensitive to question formulation, while the passage ranking changes dramatically with a little variation in the input question. The benefit of QR is that it allows us to pinpoint and group such cases automatically. We show how to use this methodology to verify whether QA models are really learning the task or just finding shortcuts in the dataset, and better understand the frequent types of error they make.},
archivePrefix = {arXiv},
arxivId = {2010.06835},
author = {Vakulenko, Svitlana and Longpre, Shayne and Tu, Zhucheng and Anantha, Raviteja},
doi = {10.18653/v1/2020.scai-1.2},
eprint = {2010.06835},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Vakulenko et al. - 2020 - A Wrong Answer or a Wrong Question An Intricate Relationship between Question Reformulation and Answer Selecti.pdf:pdf},
pages = {7--16},
title = {{A Wrong Answer or a Wrong Question? An Intricate Relationship between Question Reformulation and Answer Selection in Conversational Question Answering}},
year = {2020}
}
@article{Qu2018,
abstract = {Understanding and characterizing how people interact in information-seeking conversations is crucial in developing conversational search systems. In this paper, we introduce a new dataset designed for this purpose and use it to analyze information-seeking conversations by user intent distribution, co-occurrence, and flow patterns. The MSDialog dataset is a labeled dialog dataset of question answering (QA) interactions between information seekers and providers from an online forum on Microsoft products. The dataset contains more than 2,000 multi-turn QA dialogs with 10,000 utterances that are annotated with user intent on the utterance level. Annotations were done using crowdsourcing. With MSDialog, we find some highly recurring patterns in user intent during an information-seeking process. They could be useful for designing conversational search systems. We will make our dataset freely available to encourage exploration of information-seeking conversation models.},
archivePrefix = {arXiv},
arxivId = {1804.08759},
author = {Qu, Chen and Yang, Liu and Croft, W. Bruce and Trippas, Johanne R. and Zhang, Yongfeng and Qiu, Minghui},
doi = {10.1145/3209978.3210124},
eprint = {1804.08759},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Qu et al. - 2018 - Analyzing and Characterizing User Intent in Information-seeking Conversations.pdf:pdf},
isbn = {9781450356572},
journal = {41st International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR 2018},
keywords = {Conversational search,Information-seeking,User intent},
pages = {989--992},
title = {{Analyzing and Characterizing User Intent in Information-seeking Conversations}},
year = {2018}
}
@inproceedings{Vinyals2015,
abstract = {Conversational modeling is an important task in natural language understanding and machine intelligence. Although previous approaches exist, they are often restricted to specific domains (e.g., booking an airline ticket) and require hand-crafted rules. In this paper, we present a simple approach for this task which uses the recently proposed sequence to sequence framework. Our model converses by predicting the next sentence given the previous sentence or sentences in a conversation. The strength of our model is that it can be trained end-to-end and thus requires much fewer hand-crafted rules. We find that this straightforward model can generate simple conversations given a large conversational training dataset. Our preliminary results suggest that, despite optimizing the wrong objective function, the model is able to converse well. It is able extract knowledge from both a domain specific dataset, and from a large, noisy, and general domain dataset of movie subtitles. On a domain-specific IT helpdesk dataset, the model can find a solution to a technical problem via conversations. On a noisy open-domain movie transcript dataset, the model can perform simple forms of common sense reasoning. As expected, we also find that the lack of consistency is a common failure mode of our model.},
author = {Vinyals, Oriol and Le, Quoc},
booktitle = {Proc. of the International Conference on Machine Learning},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Vinyals, Le - 2015 - A Neural Conversational Model.pdf:pdf},
keywords = {chatbots,dialog systems,neural networks},
title = {{A Neural Conversational Model}},
year = {2015}
}
@article{Al-Rfou2019,
abstract = {LSTMs and other RNN variants have shown strong performance on character-level language modeling. These models are typically trained using truncated backpropagation through time, and it is common to assume that their success stems from their ability to remember long-term contexts. In this paper, we show that a deep (64-layer) transformer model (Vaswani et al. 2017) with fixed context outperforms RNN variants by a large margin, achieving state of the art on two popular benchmarks: 1.13 bits per character on text8 and 1.06 on enwik8. To get good results at this depth, we show that it is important to add auxiliary losses, both at intermediate network layers and intermediate sequence positions.},
archivePrefix = {arXiv},
arxivId = {1808.04444},
author = {Al-Rfou, Rami and Choe, Dokook and Constant, Noah and Guo, Mandy and Jones, Llion},
doi = {10.1609/aaai.v33i01.33013159},
eprint = {1808.04444},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Al-Rfou et al. - 2019 - Character-Level Language Modeling with Deeper Self-Attention.pdf:pdf},
issn = {2159-5399},
journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
pages = {3159--3166},
title = {{Character-Level Language Modeling with Deeper Self-Attention}},
volume = {33},
year = {2019}
}
@article{Liu2018,
abstract = {We show that generating English Wikipedia articles can be approached as a multi-document summarization of source documents. We use extractive summarization to coarsely identify salient information and a neural abstractive model to generate the article. For the abstractive model, we introduce a decoder-only architecture that can scalably attend to very long sequences, much longer than typical encoder-decoder architectures used in sequence transduction. We show that this model can generate fluent, coherent multi-sentence paragraphs and even whole Wikipedia articles. When given reference documents, we show it can extract relevant factual information as reflected in perplexity, ROUGE scores and human evaluations.},
archivePrefix = {arXiv},
arxivId = {1801.10198},
author = {Liu, Peter J. and Saleh, Mohammad and Pot, Etienne and Goodrich, Ben and Sepassi, Ryan and Kaiser, {\L}ukasz and Shazeer, Noam},
eprint = {1801.10198},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Liu et al. - 2018 - Generating wikipedia by summarizing long sequences.pdf:pdf},
journal = {6th International Conference on Learning Representations, ICLR 2018 - Conference Track Proceedings},
pages = {1--18},
title = {{Generating wikipedia by summarizing long sequences}},
year = {2018}
}
@article{Gravano2010,
abstract = {We propose an architecture for expressing various linguistically-motivated features that help identify multi-word expressions in nat- ural language texts. The architecture com- bines various linguistically-motivated clas- sification features in a Bayesian Network. We introduce novel ways for computing many of these features, and manually de- fine linguistically-motivated interrelationships among them, which the Bayesian network models. Our methodology is almost en- tirely unsupervised and completely language- independent; it relies on few language re- sources and is thus suitable for a large num- ber of languages. Furthermore, unlike much recent work, our approach can identify ex- pressions of various types and syntactic con- structions. We demonstrate a significant im- provement in identification accuracy, com- pared with less sophisticated baselines.},
author = {Gravano, Agustin},
doi = {10.1162/COLI},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gravano - 2010 - Turn-taking and affirmative cue words in task-oriented dialogue.pdf:pdf},
isbn = {9781608459858},
issn = {04194217},
journal = {Dissertation Abstracts International, B: Sciences and Engineering},
number = {8},
pages = {4943},
title = {{Turn-taking and affirmative cue words in task-oriented dialogue}},
volume = {70},
year = {2010}
}
@article{Fagundes-lima2012,
author = {Fagundes-lima, Denise and Weber, Gerald},
file = {:home/theritacosta/Desktop/botbuilder{\_}project/reading/06268266.pdf:pdf},
number = {3},
pages = {940--941},
title = {{Comments Papers {\_}{\_}{\_}{\_}{\_}{\_}{\_}{\_}{\_}{\_}{\_}{\_}{\_}{\_}{\_}{\_}{\_}{\_}{\_}{\_}{\_}{\_}{\_}{\_}{\_}{\_}{\_}{\_}{\_}{\_}{\_}{\_}{\_}{\_}{\_}{\_}{\_}{\_}{\_}{\_}{\_}{\_}{\_}{\_}{\_}{\_}{\_}{\_}{\_}{\_}{\_}{\_}{\_}{\_}{\_}{\_}{\_}{\_}{\_}{\_}{\_}{\_}{\_}{\_}{\_}{\_}{\_}{\_}{\_}{\_}{\_}{\_}{\_}{\_}{\_}{\_}{\_}{\_}{\_}{\_}{\_}{\_}}},
volume = {9},
year = {2012}
}
@article{Liu2016,
abstract = {我们调查对话监督生成系统的评估指标，其中没有监督标签，例如任务完成。 响应生成的最新工作采用了机器翻译中的指标，以将模型的生成响应与单个目标响应进行比较。 我们表明，这些指标与非技术性Twitter领域中的人类判断非常不相关，而在技术性Ubuntu领域中则根本没有。 我们提供定量和定性结果，突出显示现有指标中的特定弱点，并为将来开发更好的对话系统自动评估指标提供建议。},
archivePrefix = {arXiv},
arxivId = {1603.08023},
author = {Liu, Chia-Wei and Lowe, Ryan and Serban, Iulian V and Noseworthy, Michael and Charlin, Laurent and Pineau, Joelle},
eprint = {1603.08023},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Liu et al. - 2016 - Unsupervised Evaluation Metrics for Dialogue Response Generation.pdf:pdf},
isbn = {978-1-945626-25-8},
pages = {2122--2132},
title = {{Unsupervised Evaluation Metrics for Dialogue Response Generation}},
url = {https://aclweb.org/anthology/D16-1230},
year = {2016}
}
@article{Madotto2020,
abstract = {Task-oriented dialogue systems use four connected modules, namely, Natural Language Understanding (NLU), a Dialogue State Tracking (DST), Dialogue Policy (DP) and Natural Language Generation (NLG). A research challenge is to learn each module with the least amount of samples (i.e., few-shots) given the high cost related to the data collection. The most common and effective technique to solve this problem is transfer learning, where large language models, either pre-trained on text or task-specific data, are fine-tuned on the few samples. These methods require fine-tuning steps and a set of parameters for each task. Differently, language models, such as GPT-2 (Radford et al., 2019) and GPT-3 (Brown et al., 2020), allow few-shot learning by priming the model with few examples. In this paper, we evaluate the priming few-shot ability of language models in the NLU, DST, DP and NLG tasks. Importantly, we highlight the current limitations of this approach, and we discuss the possible implication to future work.},
archivePrefix = {arXiv},
arxivId = {2008.06239},
author = {Madotto, Andrea and Liu, Zihan and Lin, Zhaojiang and Fung, Pascale},
eprint = {2008.06239},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Madotto et al. - 2020 - Language models as few-shot learner for task-oriented dialogue systems.pdf:pdf},
journal = {arXiv},
title = {{Language models as few-shot learner for task-oriented dialogue systems}},
year = {2020}
}
@inproceedings{Konstas2017,
abstract = {Sequence-to-sequence models have shown strong performance across a broad range of applications. However, their application to parsing and generating text using Abstract Meaning Representation (AMR) has been limited, due to the relatively limited amount of labeled data and the non-sequential nature of the AMR graphs. We present a novel training procedure that can lift this limitation using millions of unlabeled sentences and careful preprocessing of the AMR graphs. For AMR parsing, our model achieves competitive results of 62.1 SMATCH, the current best score reported without significant use of external semantic resources. For AMR generation, our model establishes a new state-of-the-art performance of BLEU 33.8. We present extensive ablative and qualitative analysis including strong evidence that sequence-based AMR models are robust against ordering variations of graph-to-sequence conversions.},
archivePrefix = {arXiv},
arxivId = {1704.08381},
author = {Konstas, Ioannis and Iyer, Srinivasan and Yatskar, Mark and Choi, Yejin and Zettlemoyer, Luke},
booktitle = {Proc. of the Annual Meeting of the Association for Computational Linguistics},
doi = {10.18653/v1/P17-1014},
eprint = {1704.08381},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Konstas et al. - 2017 - Neural AMR Sequence-to-Sequence Models for Parsing and Generation.pdf:pdf},
isbn = {9781945626753},
pages = {146--157},
title = {{Neural AMR: Sequence-to-Sequence Models for Parsing and Generation}},
volume = {1},
year = {2017}
}
@article{Yang2019,
abstract = {Intelligent personal assistant systems that are able to have multi-turn conversations with human users are becoming increasingly popular. Most previous research has been focused on using either retrieval-based or generation-based methods to develop such systems. Retrieval-based methods have the advantage of returning fluent and informative responses with great diversity. However, the performance of the methods is limited by the size of the response repository. On the other hand, generation-based methods can produce highly coherent responses on any topics. But the generated responses are often generic and not informative due to the lack of grounding knowledge. In this paper, we propose a hybrid neural conversation model that combines the merits of both response retrieval and generation methods. Experimental results on Twitter and Foursquare data show that the proposed model outperforms both retrieval-based methods and generation-based methods (including a recently proposed knowledge-grounded neural conversation model [8]) under both automatic evaluation metrics and human evaluation. We hope that the findings in this study provide new insights on how to integrate text retrieval and text generation models for building conversation systems.},
archivePrefix = {arXiv},
arxivId = {1904.09068},
author = {Yang, Liu and Hu, Junjie and Qiu, Minghui and Qu, Chen and Gao, Jianfeng and {Bruce Croft}, W. and Liu, Xiaodong and Shen, Yelong and Liu, Jingjing},
doi = {10.1145/3357384.3357881},
eprint = {1904.09068},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yang et al. - 2019 - A hybrid retrieval-generation neural conversation model.pdf:pdf},
isbn = {9781450369763},
journal = {International Conference on Information and Knowledge Management, Proceedings},
pages = {1341--1350},
title = {{A hybrid retrieval-generation neural conversation model}},
year = {2019}
}
@article{Gu2020,
abstract = {Automatic evaluation for open-ended natural language generation tasks remains a challenge. Existing metrics such as BLEU show a low correlation with human judgment. We propose a novel and powerful learning-based evaluation metric: Perception Score. The method measures the overall quality of the generation and scores holistically instead of only focusing on one evaluation criteria, such as word overlapping. Moreover, it also shows the amount of uncertainty about its evaluation result. By connecting the uncertainty, Perception Score gives a more accurate evaluation for the generation system. Perception Score provides state-of-the-art results on two conditional generation tasks and two unconditional generation tasks.},
archivePrefix = {arXiv},
arxivId = {2008.03082},
author = {Gu, Jing and Wu, Qingyang and Yu, Zhou},
eprint = {2008.03082},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gu, Wu, Yu - 2020 - Perception Score, A Learned Metric for Open-ended Text Generation Evaluation.pdf:pdf},
title = {{Perception Score, A Learned Metric for Open-ended Text Generation Evaluation}},
url = {http://arxiv.org/abs/2008.03082},
year = {2020}
}
@article{Mehri2020a,
abstract = {The lack of meaningful automatic evaluation metrics for dialog has impeded open-domain dialog research. Standard language generation metrics have been shown to be ineffective for evaluating dialog models. To this end, this paper presents USR, an UnSupervised and Reference-free evaluation metric for dialog. USR is a reference-free metric that trains unsupervised models to measure several desirable qualities of dialog. USR is shown to strongly correlate with human judgment on both Topical-Chat (turn-level: 0.42, system-level: 1.0) and PersonaChat (turn-level: 0.48 and system-level: 1.0). USR additionally produces interpretable measures for several desirable properties of dialog.},
archivePrefix = {arXiv},
arxivId = {2005.00456},
author = {Mehri, Shikib and Eskenazi, Maxine},
doi = {10.18653/v1/2020.acl-main.64},
eprint = {2005.00456},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mehri, Eskenazi - 2020 - USR An Unsupervised and Reference Free Evaluation Metric for Dialog Generation.pdf:pdf},
pages = {681--707},
title = {{USR: An Unsupervised and Reference Free Evaluation Metric for Dialog Generation}},
year = {2020}
}
@article{Radford2019,
abstract = {Natural language processing tasks, such as question answering, machine translation, reading comprehension , and summarization, are typically approached with supervised learning on task-specific datasets. We demonstrate that language models begin to learn these tasks without any explicit supervision when trained on a new dataset of millions of webpages called WebText. When conditioned on a document plus questions, the answers generated by the language model reach 55 F1 on the CoQA dataset-matching or exceeding the performance of 3 out of 4 baseline systems without using the 127,000+ training examples. The capacity of the language model is essential to the success of zero-shot task transfer and increasing it improves performance in a log-linear fashion across tasks. Our largest model, GPT-2, is a 1.5B parameter Transformer that achieves state of the art results on 7 out of 8 tested language modeling datasets in a zero-shot setting but still underfits WebText. Samples from the model reflect these improvements and contain coherent paragraphs of text. These findings suggest a promising path towards building language processing systems which learn to perform tasks from their naturally occurring demonstrations.},
author = {Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Radford et al. - 2019 - Language Models are Unsupervised Multitask Learners.pdf:pdf},
journal = {OpenAI Blog},
title = {{Language Models are Unsupervised Multitask Learners}},
url = {https://openai.com/blog/better-language-models/},
year = {2019}
}
@article{Mehri2019,
abstract = {Neural dialog models have exhibited strong performance, however their end-to-end nature lacks a representation of the explicit structure of dialog. This results in a loss of generalizability, controllability and a data-hungry nature. Conversely, more traditional dialog systems do have strong models of explicit structure. This paper introduces several approaches for explicitly incorporating structure into neural models of dialog. Structured Fusion Networks first learn neural dialog modules corresponding to the structured components of traditional dialog systems and then incorporate these modules in a higher-level generative model. Structured Fusion Networks obtain strong results on the MultiWOZ dataset, both with and without reinforcement learning. Structured Fusion Networks are shown to have several valuable properties, including better domain generalizability, improved performance in reduced data scenarios and robustness to divergence during reinforcement learning.},
archivePrefix = {arXiv},
arxivId = {1907.10016},
author = {Mehri, Shikib and Srinivasan, Tejas and Eskenazi, Maxine},
doi = {10.18653/v1/w19-5921},
eprint = {1907.10016},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mehri, Srinivasan, Eskenazi - 2019 - Structured Fusion Networks for Dialog.pdf:pdf},
pages = {165--177},
title = {{Structured Fusion Networks for Dialog}},
year = {2019}
}
@inproceedings{Abend2017,
abstract = {Semantic representation is receiving growing attention in NLP in the past few years, and many proposals for semantic schemes (e.g., AMR, UCCA, GMB, UDS) have been put forth. Yet, little has been done to assess the achievements and the shortcomings of these new contenders, compare them with syntactic schemes, and clarify the general goals of research on semantic representation. We address these gaps by critically surveying the state of the art in the field.},
author = {Abend, Omri and Rappoport, Ari},
booktitle = {Proc. of the Annual Meeting of the Association for Computational Linguistics},
doi = {10.18653/v1/P17-1008},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Abend, Rappoport - 2017 - The State of the Art in Semantic Representation.pdf:pdf},
isbn = {9781945626753},
pages = {77--89},
title = {{The State of the Art in Semantic Representation}},
volume = {1},
year = {2017}
}
@article{Amigo2009,
abstract = {There is a wide set of evaluation metrics available to compare the quality of text clustering algorithms. In this article, we define a few intuitive formal constraints on such metrics which shed light on which aspects of the quality of a clustering are captured by different metric families. These formal constraints are validated in an experiment involving human assessments, and compared with other constraints proposed in the literature. Our analysis of a wide range of metrics shows that only BCubed satisfies all formal constraints. We also extend the analysis to the problem of overlapping clustering, where items can simultaneously belong to more than one cluster. As Bcubed cannot be directly applied to this task, we propose a modified version of Bcubed that avoids the problems found with other metrics. {\textcopyright} 2008 Springer Science+Business Media, LLC.},
author = {Amig{\'{o}}, Enrique and Gonzalo, Julio and Artiles, Javier and Verdejo, Felisa},
doi = {10.1007/s10791-008-9066-8},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Amig{\'{o}} et al. - 2009 - A comparison of extrinsic clustering evaluation metrics based on formal constraints.pdf:pdf},
issn = {15737659},
journal = {Information Retrieval},
keywords = {Clustering,Evaluation metrics,Formal constraints},
number = {4},
pages = {461--486},
title = {{A comparison of extrinsic clustering evaluation metrics based on formal constraints}},
volume = {12},
year = {2009}
}
@article{Eric2019,
abstract = {MultiWOZ 2.0 (Budzianowski et al., 2018) is a recently released multi-domain dialogue dataset spanning 7 distinct domains and containing over 10,000 dialogues. Though immensely useful and one of the largest resources of its kind to-date, MultiWOZ 2.0 has a few shortcomings. Firstly, there is substantial noise in the dialogue state annotations and dialogue utterances which negatively impact the performance of state-tracking models. Secondly, follow-up work (Lee et al., 2019) has augmented the original dataset with user dialogue acts. This leads to multiple co-existent versions of the same dataset with minor modifications. In this work we tackle the aforementioned issues by introducing MultiWOZ 2.1. To fix the noisy state annotations, we use crowdsourced workers to re-annotate state and utterances based on the original utterances in the dataset. This correction process results in changes to over 32{\%} of state annotations across 40{\%} of the dialogue turns. In addition, we fix 146 dialogue utterances by canonicalizing slot values in the utterances to the values in the dataset ontology. To address the second problem, we combined the contributions of the follow-up works into MultiWOZ 2.1. Hence, our dataset also includes user dialogue acts as well as multiple slot descriptions per dialogue state slot. We then benchmark a number of state-of-the-art dialogue state tracking models on the MultiWOZ 2.1 dataset and show the joint state tracking performance on the corrected state annotations. We are publicly releasing MultiWOZ 2.1 to the community, hoping that this dataset resource will allow for more effective models across various dialogue subproblems to be built in the future.},
author = {Eric, Mihail and Goel, Rahul and Paul, Shachi and Kumar, Adarsh and Sethi, Abhishek and Ku, Peter and Goyal, Anuj Kumar and Agarwal, Sanchit and Gao, Shuyang and Hakkani-Tur, Dilek},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Eric et al. - 2019 - MultiWOZ 2.1 A Consolidated Multi-Domain Dialogue Dataset with State Corrections and State Tracking Baselines.pdf:pdf},
journal = {ArXiv},
title = {{MultiWOZ 2.1: A Consolidated Multi-Domain Dialogue Dataset with State Corrections and State Tracking Baselines}},
url = {http://arxiv.org/abs/1907.01669},
year = {2019}
}
@article{Griol2021,
abstract = {Conversational systems have become an element of everyday life for billions of users who use speech-based interfaces to services, engage with personal digital assistants on smartphones, social media chatbots, or smart speakers. One of the most complex tasks in the development of these systems is to design the dialogue model, the logic that provided a user input selects the next answer. The dialogue model must also consider mechanisms to adapt the response of the system and the interaction style according to different groups and user profiles. Rule-based systems are difficult to adapt to phenomena that were not taken into consideration at design-time. However, many of the systems that are commercially available are based on rules, and so are the most widespread tools for the development of chatbots and speech interfaces. In this article, we present a proposal to: (a) automatically generate the dialogue rules from a dialogue corpus through the use of evolving algorithms, (b) adapt the rules according to the detected user intention. We have evaluated our proposal with several conversational systems of different application domains, from which our approach provided an efficient way for adapting a set of dialogue rules considering user utterance clusters.},
author = {Griol, David and Callejas, Zoraida and Molina, Jose Manuel and Sanchis, Araceli},
doi = {10.1111/exsy.12630},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Griol et al. - 2021 - Adaptive dialogue management using intent clustering and fuzzy rules.pdf:pdf},
issn = {14680394},
journal = {Expert Systems},
keywords = {clustering,conversational systems,dialogue management,dialogue rules,evolving classifiers,user modelling},
number = {1},
pages = {1--15},
title = {{Adaptive dialogue management using intent clustering and fuzzy rules}},
volume = {38},
year = {2021}
}
@article{Weilhammer2006,
abstract = {We report results on rapidly building language models for dialogue systems. Our base line is a recogniser using a grammar network. We show that we can almost halve the word error rate (WER) by combining language models generated from a simple task grammar with a standard speech corpus and data collected from the web using a sentence selection algorithm based on relative perplexity. This model compares very well to a language model using "in-domain" data from a Wizard Of Oz (WOZ) collection. We strongly advocate the use of statistical language models (SLMs) in speech recognisers for dialogue systems and show that costly WOZ data collections are not necessary to build SLMs.},
author = {Weilhammer, Karl and Stuttle, Matthew N. and Young, Steve},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Weilhammer, Stuttle, Young - 2006 - Bootstrapping language models for dialogue systems.pdf:pdf},
isbn = {9781604234497},
issn = {19909772},
journal = {Proceedings of the Annual Conference of the International Speech Communication Association, INTERSPEECH},
keywords = {Dialogue systems,Grammar,Language models,Speech recognition},
title = {{Bootstrapping language models for dialogue systems}},
volume = {1},
year = {2006}
}
@inproceedings{Koller2019,
abstract = {This tutorial is on representing and processing sentence meaning in the form of labeled directed graphs. The tutorial will (a) briefly review relevant background in formal and linguistic semantics; (b) semi-formally define a unified abstract view on different flavors of semantic graphs and associated terminology; (c) survey common frameworks for graph-based meaning representation and available graph banks; and (d) offer a technical overview of a representative selection of different parsing approaches.},
author = {Koller, Alexander and Oepen, Stephan and Sun, Weiwei},
booktitle = {Tutorial at ACL},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Koller, Oepen, Sun - 2019 - Graph-Based Meaning Representations Design and Processing.pdf:pdf},
pages = {6--11},
title = {{Graph-Based Meaning Representations: Design and Processing}},
url = {https://github.com/cfmrp/tutorial},
year = {2019}
}
@article{Chatterjee2021,
abstract = {Conversational systems are of primary interest in the AI community. Chatbots are increasingly being deployed to provide round-the-clock support and to increase customer engagement. Many of the commercial bot building frameworks follow a standard approach that requires one to build and train an intent model to recognize a user input. Intent models are trained in a supervised setting with a collection of textual utterance and intent label pairs. Gathering a substantial and wide coverage of training data for different intent is a bottleneck in the bot building process. Moreover, the cost of labeling a hundred to thousands of conversations with intent is a time consuming and laborious job. In this paper, we present an intent discovery framework that involves 4 primary steps: Extraction of textual utterances from a conversation using a pre-trained domain agnostic Dialog Act Classifier (Data Extraction), automatic clustering of similar user utterances (Clustering), manual annotation of clusters with an intent label (Labeling) and propagation of intent labels to the utterances from the previous step, which are not mapped to any cluster (Label Propagation); to generate intent training data from raw conversations. We have introduced a novel density-based clustering algorithm ITER-DBSCAN for unbalanced data clustering. Subject Matter Expert (Annotators with domain expertise) manually looks into the clustered user utterances and provides an intent label for discovery. We conducted user studies to validate the effectiveness of the trained intent model generated in terms of coverage of intents, accuracy and time saving concerning manual annotation. Although the system is developed for building an intent model for the conversational system, this framework can also be used for a short text clustering or as a labeling framework.},
archivePrefix = {arXiv},
arxivId = {2005.11014},
author = {Chatterjee, Ajay and Sengupta, Shubhashis},
doi = {10.18653/v1/2020.coling-main.366},
eprint = {2005.11014},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chatterjee, Sengupta - 2020 - Intent Mining from past conversations for conversational agent.pdf:pdf},
issn = {23318422},
journal = {arXiv},
title = {{Intent Mining from past conversations for conversational agent}},
year = {2021}
}
@inproceedings{Sutskever2014,
abstract = {Deep Neural Networks (DNNs) are powerful models that have achieved excellent performance on difficult learning tasks. Although DNNs work well whenever large labeled training sets are available, they cannot be used to map sequences to sequences. In this paper, we present a general end-to-end approach to sequence learning that makes minimal assumptions on the sequence structure. Our method uses a multilayered Long Short-Term Memory (LSTM) to map the input sequence to a vector of a fixed dimensionality, and then another deep LSTM to decode the target sequence from the vector. Our main result is that on an English to French translation task from the WMT'14 dataset, the translations produced by the LSTM achieve a BLEU score of 34.8 on the entire test set, where the LSTM's BLEU score was penalized on out-of-vocabulary words. Additionally, the LSTM did not have difficulty on long sentences. For comparison, a phrase-based SMT system achieves a BLEU score of 33.3 on the same dataset. When we used the LSTM to rerank the 1000 hypotheses produced by the aforementioned SMT system, its BLEU score increases to 36.5, which is close to the previous best result on this task. The LSTM also learned sensible phrase and sentence representations that are sensitive to word order and are relatively invariant to the active and the passive voice. Finally, we found that reversing the order of the words in all source sentences (but not target sentences) improved the LSTM's performance markedly, because doing so introduced many short term dependencies between the source and the target sentence which made the optimization problem easier.},
author = {Sutskever, Ilya and Vinyals, Oriol and Le, Quoc V.},
booktitle = {Proc. of the International Conference on Neural Information Processing Systems},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sutskever, Vinyals, Le - 2014 - Sequence to Sequence Learning with Neural Networks.pdf:pdf},
title = {{Sequence to Sequence Learning with Neural Networks}},
year = {2014}
}
@article{Zang2020,
abstract = {MultiWOZ is a well-known task-oriented dialogue dataset containing over 10,000 annotated dialogues spanning 8 domains. It is extensively used as a benchmark for dialogue state tracking. However, recent works have reported presence of substantial noise in the dialogue state annotations. MultiWOZ 2.1 identified and fixed many of these erroneous annotations and user utterances, resulting in an improved version of this dataset. This work introduces MultiWOZ 2.2, which is a yet another improved version of this dataset. Firstly, we identify and fix dialogue state annotation errors across 17.3{\%} of the utterances on top of MultiWOZ 2.1. Secondly, we redefine the ontology by disallowing vocabularies of slots with a large number of possible values (e.g., restaurant name, time of booking). In addition, we introduce slot span annotations for these slots to standardize them across recent models, which previously used custom string matching heuristics to generate them. We also benchmark a few state of the art dialogue state tracking models on the corrected dataset to facilitate comparison for future work. In the end, we discuss best practices for dialogue data collection that can help avoid annotation errors.},
author = {Zang, Xiaoxue and Rastogi, Abhinav and Chen, Jindong},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zang, Rastogi, Chen - 2020 - MultiWOZ 2.2 A Dialogue Dataset with Additional Annotation Corrections and State Tracking Baselines.pdf:pdf},
title = {{MultiWOZ 2.2: A Dialogue Dataset with Additional Annotation Corrections and State Tracking Baselines}},
url = {https://arxiv.org/abs/2007.12720},
year = {2020}
}
@inproceedings{Cho2014,
abstract = {In this paper, we propose a novel neural network model called RNN Encoder- Decoder that consists of two recurrent neural networks (RNN). One RNN encodes a sequence of symbols into a fixedlength vector representation, and the other decodes the representation into another sequence of symbols. The encoder and decoder of the proposed model are jointly trained to maximize the conditional probability of a target sequence given a source sequence. The performance of a statistical machine translation system is empirically found to improve by using the conditional probabilities of phrase pairs computed by the RNN Encoder-Decoder as an additional feature in the existing log-linear model. Qualitatively, we show that the proposed model learns a semantically and syntactically meaningful representation of linguistic phrases.},
author = {Cho, Kyunghyun and {Van Merri{\"{e}}nboer}, Bart and Gulcehre, Caglar and Bahdanau, Dzmitry and Bougares, Fethi and Schwenk, Holger and Bengio, Yoshua},
booktitle = {2014 Conference on Empirical Methods in Natural Language Processing},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cho et al. - 2014 - Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation.pdf:pdf},
title = {{Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation}},
year = {2014}
}
@phdthesis{Ruder2019,
abstract = {The current generation of neural network-based natural language processing models excels at learning from large amounts of labelled data. Given these capabilities, natural language processing is increasingly applied to new tasks, new domains, and new languages. Current models, however, are sensitive to noise and adversarial examples and prone to overfitting. This brittleness, together with the cost of attention, challenges the supervised learning paradigm. Transfer learning allows us to leverage knowledge acquired from related data in order to improve performance on a target task. Implicit transfer learning in the form of pretrained word representations has been a common component in natural language processing. In this dissertation, we argue that more explicit transfer learning is key to deal with the dearth of training data and to improve downstream performance of natural language processing models. We show experimental results transferring knowledge from related domains, tasks, and languages that support this hypothesis. We make several contributions to transfer learning for natural language processing: Firstly, we propose new methods to automatically select relevant data for supervised and unsupervised domain adaptation. Secondly, we propose two novel architectures that improve sharing in multi-task learning and outperform single-task learning as well as the state-of-the-art. Thirdly, we analyze the limitations of current models for unsupervised cross-lingual transfer and propose a method to mitigate them as well as a novel latent- variable cross-lingual word embedding model. Finally, we propose a framework based on fine-tuning language models for sequential transfer learning and analyze the adaptation phase.},
author = {Ruder, Sebastian},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ruder - 2019 - Neural Transfer Learning for Natural Language Processing.pdf:pdf},
pages = {42--46},
title = {{Neural Transfer Learning for Natural Language Processing}},
year = {2019}
}
@article{Liu2019,
abstract = {Language model pretraining has led to significant performance gains but careful comparison between different approaches is challenging. Training is computationally expensive, often done on private datasets of different sizes, and, as we will show, hyperparameter choices have significant impact on the final results. We present a replication study of BERT pretraining (Devlin et al., 2019) that carefully measures the impact of many key hyperparameters and training data size. We find that BERT was significantly undertrained, and can match or exceed the performance of every model published after it. Our best model achieves state-of-the-art results on GLUE, RACE and SQuAD. These results highlight the importance of previously overlooked design choices, and raise questions about the source of recently reported improvements. We release our models and code.},
archivePrefix = {arXiv},
arxivId = {1907.11692},
author = {Liu, Yinhan and Ott, Myle and Goyal, Naman and Du, Jingfei and Joshi, Mandar and Chen, Danqi and Levy, Omer and Lewis, Mike and Zettlemoyer, Luke and Stoyanov, Veselin},
eprint = {1907.11692},
file = {:home/theritacosta/Desktop/botbuilder{\_}project/reading/1907.11692.pdf:pdf},
number = {1},
title = {{RoBERTa: A Robustly Optimized BERT Pretraining Approach}},
url = {http://arxiv.org/abs/1907.11692},
year = {2019}
}
@article{Hakkani-Tur2016,
abstract = {Sequence-to-sequence deep learning has recently emerged as a new paradigm in supervised learning for spoken language understanding. However, most of the previous studies explored this framework for building single domain models for each task, such as slot filling or domain classification, comparing deep learning based approaches with conventional ones like conditional random fields. This paper proposes a holistic multi-domain, multi-task (i.e. slot filling, domain and intent detection) modeling approach to estimate complete semantic frames for all user utterances addressed to a conversational system, demonstrating the distinctive power of deep learning methods, namely bi-directional recurrent neural network (RNN) with long-short term memory (LSTM) cells (RNN-LSTM) to handle such complexity. The contributions of the presented work are three-fold: (i) we propose an RNN-LSTM architecture for joint modeling of slot filling, intent determination, and domain classification; (ii) we build a joint multi-domain model enabling multi-task deep learning where the data from each domain reinforces each other; (iii) we investigate alternative architectures for modeling lexical context in spoken language understanding. In addition to the simplicity of the single model framework, experimental results show the power of such an approach on Microsoft Cortana real user data over alternative methods based on single domain/task deep learning.},
author = {Hakkani-T{\"{u}}r, Dilek and Tur, Gokhan and Celikyilmaz, Asli and Chen, Yun Nung and Gao, Jianfeng and Deng, Li and Wang, Ye Yi},
doi = {10.21437/Interspeech.2016-402},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hakkani-T{\"{u}}r et al. - 2016 - Multi-Domain Joint Semantic Frame Parsing using Bi-directional RNN-LSTM.pdf:pdf},
issn = {19909772},
journal = {Proceedings of the Annual Conference of the International Speech Communication Association, INTERSPEECH},
keywords = {Joint modeling,Long short term memory,Multi-domain language understanding,Recurrent neural networks},
pages = {715--719},
title = {{Multi-Domain Joint Semantic Frame Parsing using Bi-directional RNN-LSTM}},
volume = {08-12-Sept},
year = {2016}
}
@article{Ramadan2018,
abstract = {Robust dialogue belief tracking is a key component in maintaining good quality dialogue systems. The tasks that dialogue systems are trying to solve are becoming increasingly complex, requiring scalability to multi-domain, semantically rich dialogues. However, most current approaches have difficulty scaling up with domains because of the dependency of the model parameters on the dialogue ontology. In this paper, a novel approach is introduced that fully utilizes semantic similarity between dialogue utterances and the ontology terms, allowing the information to be shared across domains. The evaluation is performed on a recently collected multi-domain dialogues dataset, one order of magnitude larger than currently available corpora. Our model demonstrates great capability in handling multi-domain dialogues, simultaneously outperforming existing state-of-the-art models in single-domain dialogue tracking tasks.},
archivePrefix = {arXiv},
arxivId = {1807.06517},
author = {Ramadan, Osman and Budzianowski, Pawe{\l} and Ga{\v{s}}i{\'{c}}, Milica},
doi = {10.18653/v1/p18-2069},
eprint = {1807.06517},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ramadan, Budzianowski, Ga{\v{s}}i{\'{c}} - 2018 - Large-scale multi-domain belief tracking with knowledge sharing.pdf:pdf},
isbn = {9781948087346},
journal = {ACL 2018 - 56th Annual Meeting of the Association for Computational Linguistics, Proceedings of the Conference (Long Papers)},
pages = {432--437},
title = {{Large-scale multi-domain belief tracking with knowledge sharing}},
volume = {2},
year = {2018}
}
@article{Song2018,
abstract = {Human-computer conversation systems have attracted much attention in Natural Language Processing. Conversation systems can be roughly divided into two categories: retrieval-based and generation-based systems. Retrieval systems search a user-issued utterance (namely a query) in a large conversational repository and return a reply that best matches the query. Generative approaches synthesize new replies. Both ways have certain advantages but suffer from their own disadvantages. We propose a novel ensemble of retrieval-based and generation-based conversation system. The retrieved candidates, in addition to the original query, are fed to a reply generator via a neural network, so that the model is aware of more information. The generated reply together with the retrieved ones then participates in a re-ranking process to find the final reply to output. Experimental results show that such an ensemble system outperforms each single module by a large margin.},
author = {Song, Yiping and Li, Cheng Te and Nie, Jian Yun and Zhang, Ming and Zhao, Dongyan and Yan, Rui},
doi = {10.24963/ijcai.2018/609},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Song et al. - 2018 - An ensemble of retrieval-based and generation-based human-computer conversation systems.pdf:pdf},
isbn = {9780999241127},
issn = {10450823},
journal = {IJCAI International Joint Conference on Artificial Intelligence},
keywords = {Humans and AI: Human-Computer Interaction,Natural Language Processing: Dialogue},
pages = {4382--4388},
title = {{An ensemble of retrieval-based and generation-based human-computer conversation systems}},
volume = {2018-July},
year = {2018}
}
@article{Lee2018,
abstract = {Many machine learning tasks such as multiple instance learning, 3D shape recognition, and few-shot image classification are defined on sets of instances. Since solutions to such problems do not depend on the order of elements of the set, models used to address them should be permutation invariant. We present an attention-based neural network module, the Set Transformer, specifically designed to model interactions among elements in the input set. The model consists of an encoder and a decoder, both of which rely on attention mechanisms. In an effort to reduce computational complexity, we introduce an attention scheme inspired by inducing point methods from sparse Gaussian process literature. It reduces the computation time of self-attention from quadratic to linear in the number of elements in the set. We show that our model is theoretically attractive and we evaluate it on a range of tasks, demonstrating the state-of-the-art performance compared to recent methods for set-structured data.},
archivePrefix = {arXiv},
arxivId = {1810.00825},
author = {Lee, Juho and Lee, Yoonho and Kim, Jungtaek and Kosiorek, Adam R. and Choi, Seungjin and Teh, Yee Whye},
eprint = {1810.00825},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lee et al. - 2018 - Set Transformer A Framework for Attention-based Permutation-Invariant Neural Networks.pdf:pdf},
title = {{Set Transformer: A Framework for Attention-based Permutation-Invariant Neural Networks}},
url = {http://arxiv.org/abs/1810.00825},
year = {2018}
}
@article{Xia2018,
abstract = {User intent detection plays a critical role in question-answering and dialog systems. Most previous works treat intent detection as a classification problem where utterances are labeled with predefined intents. However, it is labor-intensive and time-consuming to label users' utterances as intents are diversely expressed and novel intents will continually be involved. Instead, we study the zero-shot intent detection problem, which aims to detect emerging user intents where no labeled utterances are currently available. We propose two capsule-based architectures: IntentCapsNet that extracts semantic features from utterances and aggregates them to discriminate existing intents, and IntentCapsNet-ZSL which gives IntentCapsNet the zero-shot learning ability to discriminate emerging intents via knowledge transfer from existing intents. Experiments on two real-world datasets show that our model not only can better discriminate diversely expressed existing intents, but is also able to discriminate emerging intents when no labeled utterances are available.},
author = {Xia, Congying and Zhang, Chenwei and Yan, Xiaohui and Chang, Yi and Yu, Philip S.},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Xia et al. - 2018 - Zero-shot user intent detection via capsule neural networks.pdf:pdf},
issn = {23318422},
journal = {arXiv},
pages = {3090--3099},
title = {{Zero-shot user intent detection via capsule neural networks}},
year = {2018}
}
@inproceedings{Byrne2019,
abstract = {A significant barrier to progress in data-driven approaches to building dialog systems is the lack of high quality, goal-oriented conversational data. To help satisfy this elementary requirement, we introduce the initial release of the Taskmaster-1 dataset which includes 13,215 task-based dialogs comprising six domains. Two procedures were used to create this collection, each with unique advantages. The first involves a two-person, spoken “Wizard of Oz” (WOz) approach in which trained agents and crowdsourced workers interact to complete the task while the second is “self-dialog” in which crowdsourced workers write the entire dialog themselves. We do not restrict the workers to detailed scripts or to a small knowledge base and hence we observe that our dataset contains more realistic and diverse conversations in comparison to existing datasets. We offer several baseline models including state of the art neural seq2seq architectures with benchmark performance as well as qualitative human evaluations. Dialogs are labeled with API calls and arguments, a simple and cost effective approach which avoids the requirement of complex annotation schema. The layer of abstraction between the dialog model and the service provider API allows for a given model to interact with multiple services that provide similar functionally. Finally, the dataset will evoke interest in written vs. spoken language, discourse patterns, error handling and other linguistic phenomena related to dialog system research, development and design.1.},
author = {Byrne, Bill and Krishnamoorthi, Karthik and Sankar, Chinnadhurai and Neelakantan, Arvind and Duckworth, Daniel and Yavuz, Semih and Goodrich, Ben and Dubey, Amit and Cedilnik, Andy and Kim, Kyu Young},
booktitle = {Proc. of the Conference on Empirical Methods in Natural Language Processing},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Byrne et al. - 2019 - Taskmaster-1 Toward a Realistic and Diverse Dialog Dataset.pdf:pdf},
title = {{Taskmaster-1: Toward a Realistic and Diverse Dialog Dataset}},
year = {2019}
}
@article{Wu2020,
abstract = {The use of pre-trained language models has emerged as a promising direction for improving dialogue systems. However, the underlying difference of linguistic patterns between conversational data and general text makes the existing pre-trained language models not as effective as they have been shown to be. Recently, there are some pre-training approaches based on open-domain dialogues, leveraging large-scale social media data such as Twitter or Reddit. Pre-training for task-oriented dialogues, on the other hand, is rarely discussed because of the long-standing and crucial data scarcity problem. In this work, we combine nine English-based, human-human, multi-turn and publicly available task-oriented dialogue datasets to conduct language model pre-training. The experimental results show that our pre-trained task-oriented dialogue BERT (ToD-BERT) surpasses BERT and other strong baselines in four downstream task-oriented dialogue applications, including intention detection, dialogue state tracking, dialogue act prediction, and response selection. Moreover, in the simulated limited data experiments, we show that ToD-BERT has stronger few-shot capacity that can mitigate the data scarcity problem in task-oriented dialogues.},
archivePrefix = {arXiv},
arxivId = {2004.06871},
author = {Wu, Chien-Sheng and Hoi, Steven and Socher, Richard and Xiong, Caiming},
eprint = {2004.06871},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wu et al. - 2020 - ToD-BERT Pre-trained Natural Language Understanding for Task-Oriented Dialogues.pdf:pdf},
title = {{ToD-BERT: Pre-trained Natural Language Understanding for Task-Oriented Dialogues}},
url = {http://arxiv.org/abs/2004.06871},
year = {2020}
}
@article{Hosseini-Asl2020a,
abstract = {Task-oriented dialogue is often decomposed into three tasks: understanding user input, deciding actions, and generating a response. While such decomposition might suggest a dedicated model for each sub-task, we find a simple, unified approach leads to state-of-the-art performance on the MultiWOZ dataset. SimpleTOD is a simple approach to task-oriented dialogue that uses a single causal language model trained on all sub-tasks recast as a single sequence prediction problem. This allows SimpleTOD to fully leverage transfer learning from pre-trained, open domain, causal language models such as GPT-2. SimpleTOD improves over the prior state-of-the-art by 0.49 points in joint goal accuracy for dialogue state tracking. More impressively, SimpleTOD also improves the main metrics used to evaluate action decisions and response generation in an end-to-end setting for task-oriented dialog systems: inform rate by 8.1 points, success rate by 9.7 points, and combined score by 7.2 points.},
archivePrefix = {arXiv},
arxivId = {2005.00796},
author = {Hosseini-Asl, Ehsan and McCann, Bryan and Wu, Chien-Sheng and Yavuz, Semih and Socher, Richard},
eprint = {2005.00796},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hosseini-Asl et al. - 2020 - A Simple Language Model for Task-Oriented Dialogue.pdf:pdf},
title = {{A Simple Language Model for Task-Oriented Dialogue}},
url = {http://arxiv.org/abs/2005.00796},
year = {2020}
}
@article{Haponchyk2020a,
abstract = {Modern automated dialog systems require complex dialog managers able to deal with user intent triggered by high-level semantic questions. In this paper, we propose a model for automatically clustering questions into user intents to help the design tasks. Since questions are short texts, uncovering their semantics to group them together can be very challenging. We approach the problem by using powerful semantic classifiers from question duplicate/matching research along with a novel idea of supervised clustering methods based on structured output. We test our approach on two intent clustering corpora, showing an impressive improvement over previous methods for two languages/domains.},
author = {Haponchyk, Iryna and Uva, Antonio and Yu, Seunghak and Uryupina, Olga and Moschitti, Alessandro},
doi = {10.18653/v1/d18-1254},
file = {:home/theritacosta/Desktop/botbuilder{\_}project/reading/emnlp2018-IC.pdf:pdf},
isbn = {9781948087841},
journal = {Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, EMNLP 2018},
pages = {2310--2321},
title = {{Supervised clustering of questions into intents for dialog system applications}},
year = {2020}
}
@article{Viera2005,
author = {Viera, Anthony J and Garrett, Joanne M},
journal = {Family medicine},
pages = {360--363},
title = {{Understanding Interobserver Agreement: the Kappa Statistic}},
volume = {37},
year = {2005}
}
@inproceedings{Swanson2019,
abstract = {Response suggestion is an important task for building human-computer conversation systems. Recent approaches to conversation modeling have introduced new model architectures with impressive results, but relatively little attention has been paid to whether these models would be practical in a production setting. In this paper, we describe the unique challenges of building a production retrieval-based conversation system, which selects outputs from a whitelist of candidate responses. To address these challenges, we propose a dual encoder architecture which performs rapid inference and scales well with the size of the whitelist. We also introduce and compare two methods for generating whitelists, and we carry out a comprehensive analysis of the model and whitelists. Experimental results on a large, proprietary help desk chat dataset, including both offline metrics and a human evaluation, indicate production-quality performance and illustrate key lessons about conversation modeling in practice.},
archivePrefix = {arXiv},
arxivId = {1906.03209},
author = {Swanson, Kyle and Yu, Lili and Fox, Christopher and Wohlwend, Jeremy and Lei, Tao},
booktitle = {Proc. of the First Workshop on NLP for Conversational AI},
doi = {10.18653/v1/w19-4104},
eprint = {1906.03209},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Swanson et al. - 2019 - Building a Production Model for Retrieval-Based Chatbots.pdf:pdf},
issn = {23318422},
pages = {32--41},
title = {{Building a Production Model for Retrieval-Based Chatbots}},
year = {2019}
}
@inproceedings{Pennington2014,
author = {Pennington, Jeffrey and Socher, Richard and Manning, Christopher},
booktitle = {Proc. of the Conference on Empirical Methods in Natural Language Processing},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Pennington, Socher, Manning - 2014 - GloVe Global Vectors for Word Representation.pdf:pdf},
title = {{GloVe: Global Vectors for Word Representation}},
year = {2014}
}
@article{Fleiss1971,
author = {Fleiss, Joseph L.},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Fleiss - 1971 - Measuring Nominal Scale Agreement Among Many Raters.pdf:pdf},
journal = {Psychological Bulletin},
pages = {378--382},
title = {{Measuring Nominal Scale Agreement Among Many Raters}},
volume = {76},
year = {1971}
}
@article{Henaff2017,
archivePrefix = {arXiv},
arxivId = {arXiv:1612.03969v1},
author = {Henaff, Mikael and Weston, Jason and Szlam, Arthur and Bordes, Antoine and Lecun, Yann},
eprint = {arXiv:1612.03969v1},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Henaff et al. - 2017 - T Racking the W Orld S Tate With.pdf:pdf},
pages = {1--14},
title = {{T Racking the W Orld S Tate With}},
year = {2017}
}
@inproceedings{Budzianowski2019a,
abstract = {Data scarcity is a long-standing and crucial challenge that hinders quick development of task-oriented dialogue systems across multiple domains: task-oriented dialogue models are expected to learn grammar, syntax, dialogue reasoning, decision making, and language generation from absurdly small amounts of task-specific data. In this paper, we demonstrate that recent progress in language modeling pre-training and transfer learning shows promise to overcome this problem. We propose a task-oriented dialogue model that operates solely on text input: it effectively bypasses explicit policy and language generation modules. Building on top of the TransferTransfo framework (Wolf et al., 2019) and generative model pre-training (Radford et al., 2019), we validate the approach on complex multi-domain task-oriented dialogues from the MultiWOZ dataset. Our automatic and human evaluations show that the proposed model is on par with a strong task-specific neural baseline. In the long run, our approach holds promise to mitigate the data scarcity problem, and to support the construction of more engaging and more eloquent task-oriented conversational agents.},
author = {Budzianowski, Pawe{\l} and Vuli{\'{c}}, Ivan},
booktitle = {Proc. of the Workshop on Neural Generation and Translation},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Budzianowski, Vuli{\'{c}} - 2019 - Hello, It's GPT-2 - How Can I Help You Towards the Use of Pretrained Language Models for Task-Oriented Dia.pdf:pdf},
title = {{Hello, It's GPT-2 - How Can I Help You? Towards the Use of Pretrained Language Models for Task-Oriented Dialogue Systems}},
year = {2019}
}
@article{Chen2020a,
abstract = {Inspired by progress in unsupervised representation learning for natural language, we examine whether similar models can learn useful representations for images. We train a sequence Transformer to auto-regressively predict pixels, without incorporating knowledge of the 2D input structure. Despite training on low-resolution ImageNet without labels, we find that a GPT-2 scale model learns strong image representations as measured by linear probing, fine-tuning, and low-data classification. On CIFAR-10, we achieve 96.3{\%} accuracy with a linear probe, outperforming a supervised Wide ResNet, and 99.0{\%} accuracy with full finetuning, matching the top supervised pre-trained models. An even larger model trained on a mixture of ImageNet and web images is competitive with self-supervised benchmarks on ImageNet, achieving 72.0{\%} top-1 accuracy on a linear probe of our features.},
author = {Chen, Mark and Radford, Alec and Child, Rewon and Wu, Jeff and Jun, Heewoo and Dhariwal, Prafulla and Luan, David},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chen et al. - 2020 - Image GPT.pdf:pdf},
journal = {OpenAI Blog},
title = {{Image GPT}},
url = {https://openai.com/blog/image-gpt/},
year = {2020}
}
@article{Rastogi2019,
abstract = {Virtual assistants such as Google Assistant, Alexa and Siri provide a conversational interface to a large number of services and APIs spanning multiple domains. Such systems need to support an ever-increasing number of services with possibly overlapping functionality. Furthermore, some of these services have little to no training data available. Existing public datasets for task-oriented dialogue do not sufficiently capture these challenges since they cover few domains and assume a single static ontology per domain. In this work, we introduce the the Schema-Guided Dialogue (SGD) dataset, containing over 16k multi-domain conversations spanning 16 domains. Our dataset exceeds the existing task-oriented dialogue corpora in scale, while also highlighting the challenges associated with building large-scale virtual assistants. It provides a challenging testbed for a number of tasks including language understanding, slot filling, dialogue state tracking and response generation. Along the same lines, we present a schema-guided paradigm for task-oriented dialogue, in which predictions are made over a dynamic set of intents and slots, provided as input, using their natural language descriptions. This allows a single dialogue system to easily support a large number of services and facilitates simple integration of new services without requiring additional training data. Building upon the proposed paradigm, we release a model for dialogue state tracking capable of zero-shot generalization to new APIs, while remaining competitive in the regular setting.},
archivePrefix = {arXiv},
arxivId = {1909.05855},
author = {Rastogi, Abhinav and Zang, Xiaoxue and Sunkara, Srinivas and Gupta, Raghav and Khaitan, Pranav},
eprint = {1909.05855},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rastogi et al. - 2019 - Towards Scalable Multi-domain Conversational Agents The Schema-Guided Dialogue Dataset.pdf:pdf},
title = {{Towards Scalable Multi-domain Conversational Agents: The Schema-Guided Dialogue Dataset}},
url = {http://arxiv.org/abs/1909.05855},
year = {2019}
}
@inproceedings{Graves2013,
abstract = {Recurrent neural networks (RNNs) are a powerful model for sequential data. End-to-end training methods such as Connectionist Temporal Classification make it possible to train RNNs for sequence labelling problems where the input-output alignment is unknown. The combination of these methods with the Long Short-term Memory RNN architecture has proved particularly fruitful, delivering state-of-the-art results in cursive handwriting recognition. However RNN performance in speech recognition has so far been disappointing, with better results returned by deep feedforward networks. This paper investigates deep recurrent neural networks, which combine the multiple levels of representation that have proved so effective in deep networks with the flexible use of long range context that empowers RNNs. When trained end-to-end with suitable regularisation, we find that deep Long Short-term Memory RNNs achieve a test set error of 17.7{\%} on the TIMIT phoneme recognition benchmark, which to our knowledge is the best recorded score. {\textcopyright} 2013 IEEE.},
author = {Graves, Alex and Mohamed, Abdel Rahman and Hinton, Geoffrey},
booktitle = {IEEE International Conference on Acoustics, Speech and Signal Processing},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Graves, Mohamed, Hinton - 2013 - Speech Recognition with Deep Recurrent Neural Networks.pdf:pdf},
title = {{Speech Recognition with Deep Recurrent Neural Networks}},
year = {2013}
}
@article{Ji2014,
abstract = {Human computer conversation is regarded as one of the most difficult problems in artificial intelligence. In this paper, we address one of its key sub-problems, referred to as short text conversation, in which given a message from human, the computer returns a reasonable response to the message. We leverage the vast amount of short conversation data available on social media to study the issue. We propose formalizing short text conversation as a search problem at the first step, and employing state-of-the-art information retrieval (IR) techniques to carry out the task. We investigate the significance as well as the limitation of the IR approach. Our experiments demonstrate that the retrieval-based model can make the system behave rather "intelligently", when combined with a huge repository of conversation data from social media.},
archivePrefix = {arXiv},
arxivId = {1408.6988},
author = {Ji, Zongcheng and Lu, Zhengdong and Li, Hang},
eprint = {1408.6988},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ji, Lu, Li - 2014 - An Information Retrieval Approach to Short Text Conversation.pdf:pdf},
keywords = {information retrieval,learning to match,learning to rank,short text conversation},
number = {Hang Li},
pages = {1--21},
title = {{An Information Retrieval Approach to Short Text Conversation}},
url = {http://arxiv.org/abs/1408.6988},
year = {2014}
}
@article{Nogueira2019a,
abstract = {One technique to improve the retrieval effectiveness of a search engine is to expand documents with terms that are related or representative of the documents' content. From the perspective of a question answering system, this might comprise questions the document can potentially answer. Following this observation, we propose a simple method that predicts which queries will be issued for a given document and then expands it with those predictions with a vanilla sequence-to-sequence model, trained using datasets consisting of pairs of query and relevant documents. By combining our method with a highly-effective re-ranking component, we achieve the state of the art in two retrieval tasks. In a latencycritical regime, retrieval results alone (without re-ranking) approach the effectiveness of more computationally expensive neural re-rankers but are much faster.},
archivePrefix = {arXiv},
arxivId = {1904.08375},
author = {Nogueira, Rodrigo and Yang, Wei and Lin, Jimmy and Cho, Kyunghyun},
eprint = {1904.08375},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Nogueira et al. - 2019 - Document expansion by query prediction.pdf:pdf},
issn = {23318422},
journal = {arXiv},
pages = {1--7},
title = {{Document expansion by query prediction}},
year = {2019}
}
@inproceedings{Shen2018,
abstract = {This paper proposes a layered semantic graph representation for dialogue information. The representation factors information into several interdependent layers, facilitating efficient information access and processing by the components in a dialogue system. We describe the layers in the semantic graph and the function they serve in an implemented task-oriented dialogue system.},
author = {Shen, Jiaying and Harkema, Hendrik and Crouch, Richard and Yu, Peng and O'reilly, Ciaran},
booktitle = {Proc. of the Workshop on the Semantics and Pragmatics of Dialogue (SemDial)},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Shen et al. - 2018 - Layered Semantic Graphs for Dialogue Management.pdf:pdf},
title = {{Layered Semantic Graphs for Dialogue Management}},
year = {2018}
}
@article{Raffel2019,
abstract = {Transfer learning, where a model is first pre-trained on a data-rich task before being fine-tuned on a downstream task, has emerged as a powerful technique in natural language processing (NLP). The effectiveness of transfer learning has given rise to a diversity of approaches, methodology, and practice. In this paper, we explore the landscape of transfer learning techniques for NLP by introducing a unified framework that converts every language problem into a text-to-text format. Our systematic study compares pre-training objectives, architectures, unlabeled datasets, transfer approaches, and other factors on dozens of language understanding tasks. By combining the insights from our exploration with scale and our new "Colossal Clean Crawled Corpus", we achieve state-of-the-art results on many benchmarks covering summarization, question answering, text classification, and more. To facilitate future work on transfer learning for NLP, we release our dataset, pre-trained models, and code.1.},
archivePrefix = {arXiv},
arxivId = {1910.10683},
author = {Raffel, Colin and Shazeer, Noam and Roberts, Adam and Lee, Katherine and Narang, Sharan and Matena, Michael and Zhou, Yanqi and Peter, Wei Li and Liu, J.},
eprint = {1910.10683},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Raffel et al. - 2020 - Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer.pdf:pdf},
issn = {23318422},
journal = {Journal of Machine Learning Research},
keywords = {attention-,multi-task learning,natural language processing,transfer learning},
pages = {1--67},
title = {{Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer}},
volume = {21},
year = {2020}
}
@article{Anantha2020,
abstract = {We introduce a new dataset for Question Rewriting in Conversational Context (QReCC), which contains 14K conversations with 81K question-answer pairs. The task in QReCC is to find answers to conversational questions within a collection of 10M web pages (split into 54M passages). Answers to questions in the same conversation may be distributed across several web pages. QReCC provides annotations that allow us to train and evaluate individual subtasks of question rewriting, passage retrieval and reading comprehension required for the end-to-end conversational question answering (QA) task. We report the effectiveness of a strong baseline approach that combines the state-of-the-art model for question rewriting, and competitive models for open-domain QA. Our results set the first baseline for the QReCC dataset with F1 of 19.07, compared to the human upper bound of 74.47, indicating the difficulty of the setup and a large room for improvement.},
archivePrefix = {arXiv},
arxivId = {2010.04898},
author = {Anantha, Raviteja and Vakulenko, Svitlana and Tu, Zhucheng and Longpre, Shayne and Pulman, Stephen and Chappidi, Srinivas},
eprint = {2010.04898},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Anantha et al. - 2020 - Open-domain question answering goes conversational via question rewriting.pdf:pdf},
issn = {23318422},
journal = {arXiv},
title = {{Open-Domain Question Answering Goes Conversational via Question Rewriting}},
year = {2020}
}
@inproceedings{Mehri2020,
abstract = {It is important to define meaningful and interpretable automatic evaluation metrics for open-domain dialog research. Standard language generation metrics have been shown to be ineffective for dialog. This paper introduces the FED metric (fine-grained evaluation of dialog), an automatic evaluation metric which uses DialoGPT, without any fine-tuning or supervision. It also introduces the FED dataset which is constructed by annotating a set of human-system and human-human conversations with eighteen fine-grained dialog qualities. The FED metric (1) does not rely on a ground-truth response, (2) does not require training data and (3) measures fine-grained dialog qualities at both the turn and whole dialog levels. FED attains moderate to strong correlation with human judgement at both levels.},
author = {Mehri, Shikib and Eskenazi, Maxine},
booktitle = {Proc. of the Annual Meeting of the Special Interest Group on Discourse and Dialogue},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mehri, Eskenazi - 2020 - Unsupervised Evaluation of Interactive Dialog with DialoGPT.pdf:pdf},
title = {{Unsupervised Evaluation of Interactive Dialog with DialoGPT}},
year = {2020}
}
@article{Dai2019a,
abstract = {Term frequency is a common method for identifying the importance of a term in a query or document. But it is a weak signal, especially when the frequency distribution is flat, such as in long queries or short documents where the text is of sentence/passage-length. This paper proposes a Deep Contextualized Term Weighting framework that learns to map BERT's contextualized text representations to context-aware term weights for sentences and passages. When applied to passages, DeepCT-Index produces term weights that can be stored in an ordinary inverted index for passage retrieval. When applied to query text, DeepCT-Query generates a weighted bag-of-words query. Both types of term weight can be used directly by typical first-stage retrieval algorithms. This is novel because most deep neural network based ranking models have higher computational costs, and thus are restricted to later-stage rankers. Experiments on four datasets demonstrate that DeepCT's deep contextualized text understanding greatly improves the accuracy of first-stage retrieval algorithms.},
archivePrefix = {arXiv},
arxivId = {1910.10687},
author = {Dai, Zhuyun and Callan, Jamie},
eprint = {1910.10687},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Dai, Callan - 2019 - Context-Aware SentencePassage Term Importance Estimation For First Stage Retrieval.pdf:pdf},
issn = {23318422},
journal = {arXiv},
keywords = {Neural-IR,Term Weighting,Text Understanding},
title = {{Context-Aware Sentence/Passage Term Importance Estimation For First Stage Retrieval}},
year = {2019}
}
@article{Huang2020,
author = {Huang, Minlie and Zhu, Xiaoyan and Gao, Jianfeng},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Huang, Zhu, Gao - 2020 - Challenges in Building Intelligent Open-Domain Dialog Systems.pdf:pdf},
journal = {ACM Transactions on Information Systems},
title = {{Challenges in Building Intelligent Open-Domain Dialog Systems}},
volume = {38},
year = {2020}
}
@article{Schatzmann2009,
abstract = {A key advantage of taking a statistical approach to spoken dialogue systems is the ability to formalise dialogue policy design as a stochastic optimization problem. However, since dialogue policies are learnt by interactively exploring alternative dialogue paths, conventional static dialogue corpora cannot be used directly for training and instead, a user simulator is commonly used. This paper describes a novel statistical user model based on a compact stack-like state representation called a user agenda which allows state transitions to be modeled as sequences of push- and pop-operations and elegantly encodes the dialogue history from a user's point of view. An expectation-maximisation based algorithm is presented which models the observable user output in terms of a sequence of hidden states and thereby allows the model to be trained on a corpus of minimally annotated data. Experimental results with a real-world dialogue system demonstrate that the trained user model can be successfully used to optimise a dialogue policy which outperforms a hand-crafted baseline in terms of task completion rates and user satisfaction scores. {\textcopyright} 2006 IEEE.},
author = {Schatzmann, Jost and Young, Steve},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Schatzmann, Young - 2009 - The Hidden Agenda User Simulation Model.pdf:pdf},
journal = {IEEE Transactions on Audio, Speech and Language Processing},
keywords = {Dialogue management,Markov decision process,Planning under uncertainty,Spoken dialogue system (SDS),User simulation},
title = {{The Hidden Agenda User Simulation Model}},
volume = {17},
year = {2009}
}
@article{Elman1990,
abstract = {Time underlies many interesting human behaviors. Thus, the question of how to represent time in connectionist models is very important. One approach is to represent time implicitly by its effects on processing rather than explicitly (as in a spatial representation). The current report develops a proposal along these lines first described by Jordan (1986) which involves the use of recurrent links in order to provide networks with a dynamic memory. In this approach, hidden unit patterns are fed back to themselves; the internal representations which develop thus reflect task demands in the context of prior internal states. A set of simulations is reported which range from relatively simple problems (temporal version of XOR) to discovering syntactic/semantic features for words. The networks are able to learn interesting internal representations which incorporate task demands with memory demands; indeed, in this approach the notion of memory is inextricably bound up with task processing. These representations reveal a rich structure, which allows them to be highly context-dependent, while also expressing generalizations across classes of items. These representations suggest a method for representing lexical categories and the type/token distinction. {\textcopyright} 1990.},
author = {Elman, Jeffrey L.},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Elman - 1990 - Finding Structure in Time.pdf:pdf},
journal = {Cognitive Science},
pages = {179--211},
title = {{Finding Structure in Time}},
volume = {14},
year = {1990}
}
@inproceedings{Qiu2019,
abstract = {Due to its potential applications, open-domain dialogue generation has become popular and achieved remarkable progress in recent years, but sometimes suffers from generic responses. Previous models are generally trained based on 1-to-1 mapping from an input query to its response, which actually ignores the nature of 1-to-n mapping in dialogue that there may exist multiple valid responses corresponding to the same query. In this paper, we propose to utilize the multiple references by considering the correlation of different valid responses and modeling the 1-to-n mapping with a novel two-step generation architecture. The first generation phase extracts the common features of different responses which, combined with distinctive features obtained in the second phase, can generate multiple diverse and appropriate responses. Experimental results show that our proposed model can effectively improve the quality of response and outperform existing neural dialogue models on both automatic and human evaluations.},
author = {Qiu, Lisong and Li, Juntao and Bi, Wei and Zhao, Dongyan and Yan, Rui},
booktitle = {Proc. of the Annual Meeting of the Association for Computational Linguistics},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Qiu et al. - 2019 - Are Training Samples Correlated Learning to Generate Dialogue Responses with Multiple References.pdf:pdf},
title = {{Are Training Samples Correlated? Learning to Generate Dialogue Responses with Multiple References}},
year = {2019}
}
@article{Copestake2005,
abstract = {Minimal recursion semantics (MRS) is a framework for computational semantics that is suitable for parsing and generation and that can be implemented in typed feature structure formalisms. We discuss why, in general, a semantic representation with minimal structure is desirable and illustrate how a descriptively adequate representation with a nonrecursive structure may be achieved. MRS enables a simple formulation of the grammatical constraints on lexical and phrasal semantics, including the principles of semantic composition. We have integrated MRS with a broad- coverage HPSG grammar.},
author = {Copestake, Ann and Flickinger, Dan and Sag, Ivan A. and Pollard, Carl},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Copestake et al. - 2005 - Minimal Recursion Semantics.pdf:pdf},
journal = {Research on Language and Computation},
pages = {281--332},
title = {{Minimal Recursion Semantics}},
volume = {3},
year = {2005}
}
@inproceedings{Post2019,
abstract = {The field of machine translation faces an under-recognized problem because of inconsistency in the reporting of scores from its dominant metric. Although people refer to "the" BLEU score, BLEU is in fact a parameterized metric whose values can vary wildly with changes to these parameters. These parameters are often not reported or are hard to find, and consequently, BLEU scores between papers cannot be directly compared. I quantify this variation, finding differences as high as 1.8 between commonly used configurations. The main culprit is different tokenization and normalization schemes applied to the reference. Pointing to the success of the parsing community, I suggest machine translation researchers settle upon the BLEU scheme used by the annual Conference on Machine Translation (WMT), which does not allow for user-supplied reference processing, and provide a new tool, SacreBLEU, to facilitate this.},
archivePrefix = {arXiv},
arxivId = {1804.08771},
author = {Post, Matt},
booktitle = {Proc. of the Conference on Machine Translation},
eprint = {1804.08771},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Post - 2018 - A Call for Clarity in Reporting BLEU Scores.pdf:pdf},
title = {{A Call for Clarity in Reporting BLEU Scores}},
year = {2018}
}
@article{Eisenstein2018,
author = {Eisenstein, Jacob},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Eisenstein - 2018 - Natural Language Processing.pdf:pdf},
title = {{Natural Language Processing}},
year = {2018}
}
@article{Holtzman2018,
abstract = {Despite their local fluency, long-form text generated from RNNs is often generic, repetitive, and even self-contradictory. We propose a unified learning framework that collectively addresses all the above issues by composing a committee of discriminators that can guide a base RNN generator towards more globally coherent generations. More concretely, discriminators each specialize in a different principle of communication, such as Grice's maxims, and are collectively combined with the base RNN generator through a composite decoding objective. Human evaluation demonstrates that text generated by our model is preferred over that of baselines by a large margin, significantly enhancing the overall coherence, style, and information of the generations.},
archivePrefix = {arXiv},
arxivId = {1805.06087},
author = {Holtzman, Ari and Buys, Jan and Forbes, Maxwell and Bosselut, Antoine and Golub, David and Choi, Yejin},
doi = {10.18653/v1/p18-1152},
eprint = {1805.06087},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Holtzman et al. - 2018 - Learning to write with cooperative discriminators.pdf:pdf},
isbn = {9781948087322},
journal = {ACL 2018 - 56th Annual Meeting of the Association for Computational Linguistics, Proceedings of the Conference (Long Papers)},
pages = {1638--1649},
title = {{Learning to write with cooperative discriminators}},
volume = {1},
year = {2018}
}
@inproceedings{Wen2015,
abstract = {Natural language generation (NLG) is a critical component of spoken dialogue and it has a significant impact both on usability and perceived quality. Most NLG systems in common use employ rules and heuristics and tend to generate rigid and stylised responses without the natural variation of human language. They are also not easily scaled to systems covering multiple domains and languages. This paper presents a statistical language generator based on a semantically controlled Long Short-term Memory (LSTM) structure. The LSTM generator can learn from unaligned data by jointly optimising sentence planning and surface realisation using a simple cross entropy training criterion, and language variation can be easily achieved by sampling from output candidates. With fewer heuristics, an objective evaluation in two differing test domains showed the proposed method improved performance compared to previous methods. Human judges scored the LSTM system higher on informativeness and naturalness and overall preferred it to the other systems..},
author = {Wen, Tsung Hsien and Ga{\v{s}}i{\'{c}}, Milica and Mrk{\v{s}}i{\'{c}}, Nikola and Su, Pei Hao and Vandyke, David and Young, Steve},
booktitle = {Proc. of the Conference on Empirical Methods in Natural Language Processing},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wen et al. - 2015 - Semantically Conditioned LSTM-based Natural Language Generation for Spoken Dialogue Systems.pdf:pdf;:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wen et al. - 2015 - Semantically conditioned lstm-based Natural language generation for spoken dialogue systems.pdf:pdf},
title = {{Semantically Conditioned LSTM-based Natural Language Generation for Spoken Dialogue Systems}},
year = {2015}
}
@article{Zhang2019a,
abstract = {Recent work pre-training Transformers with self-supervised objectives on large text corpora has shown great success when fine-tuned on downstream NLP tasks including text summarization. However, pre-training objectives tailored for abstractive text summarization have not been explored. Furthermore there is a lack of systematic evaluation across diverse domains. In this work, we propose pre-training large Transformer-based encoder-decoder models on massive text corpora with a new self-supervised objective. In PEGASUS, important sentences are removed/masked from an input document and are generated together as one output sequence from the remaining sentences, similar to an extractive summary. We evaluated our best PEGASUS model on 12 downstream summarization tasks spanning news, science, stories, instructions, emails, patents, and legislative bills. Experiments demonstrate it achieves state-of-the-art performance on all 12 downstream datasets measured by ROUGE scores. Our model also shows surprising performance on low-resource summarization, surpassing previous state-of-the-art results on 6 datasets with only 1000 examples.},
archivePrefix = {arXiv},
arxivId = {1912.08777},
author = {Zhang, Jingqing and Zhao, Yao and Saleh, Mohammad and Liu, Peter J.},
eprint = {1912.08777},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhang et al. - 2019 - PEGASUS Pre-training with Extracted Gap-sentences for Abstractive Summarization.pdf:pdf},
issn = {23318422},
journal = {arXiv},
title = {{PEGASUS: Pre-training with Extracted Gap-sentences for Abstractive Summarization}},
year = {2019}
}
@article{Cheung2012,
abstract = {One popular form of semantic search observed in several modern search engines is to recognize query patterns that trigger instant answers or domain-specific search, producing semantically enriched search results. This often requires understanding the query intent in addition to the meaning of the query terms in order to access structured data sources. A major challenge in intent understanding is to construct a domain-dependent schema and to annotate search queries based on such a schema, a process that to date has required much manual annotation effort. We present an unsupervised method for clustering queries with similar intent and for producing a pattern consisting of a sequence of semantic concepts and/or lexical items for each intent. Furthermore, we leverage the discovered intent patterns to automatically annotate a large number of queries beyond those used in clustering. We evaluated our method on 10 selected domains, discovering over 1400 intent patterns and automatically annotating 125K (and potentially many more) queries. We found that over 90{\%} of patterns and 80{\%} of instance annotations tested are judged to be correct by a majority of annotators. Copyright 2012 ACM.},
author = {Cheung, Jackie Chi Kit and Li, Xiao},
doi = {10.1145/2124295.2124342},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cheung, Li - 2012 - Sequence clustering and labeling for unsupervised query intent discovery.pdf:pdf},
isbn = {9781450307475},
journal = {WSDM 2012 - Proceedings of the 5th ACM International Conference on Web Search and Data Mining},
keywords = {Clustering,Query intent discovery,Semantic search},
pages = {383--392},
title = {{Sequence clustering and labeling for unsupervised query intent discovery}},
year = {2012}
}
@inproceedings{Zhu2018,
abstract = {Dialogue systems are usually built on either generation-based or retrieval-based approaches, yet they do not benefit from the advantages of different models. In this paper, we propose a Retrieval-Enhanced Adversarial Training (REAT) method for neural response generation. Distinct from existing approaches, the REAT method leverages an encoder-decoder framework in terms of an adversarial training paradigm, while taking advantage of N-best response candidates from a retrieval-based system to construct the discriminator. An empirical study on a large scale public available benchmark dataset shows that the REAT method significantly outperforms the vanilla Seq2Seq model as well as the conventional adversarial training approach.},
author = {Zhu, Qingfu and Cui, Lei and Zhang, Weinan and Wei, Furu and Liu, Ting},
booktitle = {Proc. of the Annual Meeting ofthe Association for Computational Linguistics},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhu et al. - 2019 - Retrieval-Enhanced Adversarial Training for Neural Response Generation.pdf:pdf},
title = {{Retrieval-Enhanced Adversarial Training for Neural Response Generation}},
year = {2019}
}
@article{Li2020a,
abstract = {Dialogue state trackers have made significant progress on benchmark datasets, but their generalization capability to novel and realistic scenarios beyond the held-out conversations is less understood. We propose controllable counterfactuals (CoCo) to bridge this gap and evaluate dialogue state tracking (DST) models on novel scenarios, i.e., would the system successfully tackle the request if the user responded differently but still consistently with the dialogue flow? CoCo leverages turn-level belief states as counterfactual conditionals to produce novel conversation scenarios in two steps: (i) counterfactual goal generation at turn-level by dropping and adding slots followed by replacing slot values, (ii) counterfactual conversation generation that is conditioned on (i) and consistent with the dialogue flow. Evaluating state-of-the-art DST models on MultiWOZ dataset with CoCo-generated counterfactuals results in a significant performance drop of up to 30.8{\%} (from 49.4{\%} to 18.6{\%}) in absolute joint goal accuracy. In comparison, widely used techniques like paraphrasing only affect the accuracy by at most 2{\%}. Human evaluations show that COCO-generated conversations perfectly reflect the underlying user goal with more than 95{\%} accuracy and are as human-like as the original conversations, further strengthening its reliability and promise to be adopted as part of the robustness evaluation of DST models. Code is available at https://github.com/salesforce/coco-dst.},
archivePrefix = {arXiv},
arxivId = {2010.12850},
author = {Li, Shiyang and Yavuz, Semih and Hashimoto, Kazuma and Li, Jia and Niu, Tong and Rajani, Nazneen and Yan, Xifeng and Zhou, Yingbo and Xiong, Caiming},
eprint = {2010.12850},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Li et al. - 2020 - CoCo Controllable Counterfactuals for Evaluating Dialogue State Trackers.pdf:pdf},
pages = {1--25},
title = {{CoCo: Controllable Counterfactuals for Evaluating Dialogue State Trackers}},
url = {http://arxiv.org/abs/2010.12850},
year = {2020}
}
@inproceedings{Rei2020,
abstract = {We present COMET, a neural framework for training multilingual machine translation evaluation models which obtains new state-of-the-art levels of correlation with human judgements. Our framework leverages recent breakthroughs in cross-lingual pretrained language modeling resulting in highly multilingual and adaptable MT evaluation models that exploit information from both the source input and a target-language reference translation in order to more accurately predict MT quality. To showcase our framework, we train three models with different types of human judgements: Direct Assessments, Human-mediated Translation Edit Rate and Multidimensional Quality Metrics. Our models achieve new state-of-the-art performance on the WMT 2019 Metrics shared task and demonstrate robustness to high-performing systems.},
archivePrefix = {arXiv},
arxivId = {2009.09025},
author = {Rei, Ricardo and Stewart, Craig and Farinha, Ana C and Lavie, Alon},
booktitle = {Proc. of the Conference on Empirical Methods in Natural Language Processing},
eprint = {2009.09025},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rei et al. - 2020 - COMET A Neural Framework for MT Evaluation.pdf:pdf},
title = {{COMET: A Neural Framework for MT Evaluation}},
year = {2020}
}
@article{Wen2016,
abstract = {Moving from limited-domain natural language generation (NLG) to open domain is difficult because the number of semantic input combinations grows exponentially with the number of domains. Therefore, it is important to leverage existing resources and exploit similarities between domains to facilitate domain adaptation. In this paper, we propose a procedure to train multi-domain, Recurrent Neural Network-based (RNN) language generators via multiple adaptation steps. In this procedure, a model is first trained on counterfeited data synthesised from an out-of-domain dataset, and then fine tuned on a small set of in-domain utterances with a discriminative objective function. Corpus-based evaluation results show that the proposed procedure can achieve competitive performance in terms of BLEU score and slot error rate while significantly reducing the data needed to train generators in new, unseen domains. In subjective testing, human judges confirm that the procedure greatly improves generator performance when only a small amount of data is available in the domain.},
archivePrefix = {arXiv},
arxivId = {1603.01232},
author = {Wen, Tsung Hsien and Ga{\v{s}}i{\'{c}}, Milica and Mrk{\v{s}}i{\'{c}}, Nikola and Rojas-Barahona, Lina M. and Su, Pei Hao and Vandyke, David and Young, Steve},
doi = {10.18653/v1/n16-1015},
eprint = {1603.01232},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wen et al. - 2016 - Multi-domain neural network language generation for spoken dialogue systems.pdf:pdf},
isbn = {9781941643914},
journal = {2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL HLT 2016 - Proceedings of the Conference},
pages = {120--129},
title = {{Multi-domain neural network language generation for spoken dialogue systems}},
year = {2016}
}
@article{He2017,
abstract = {We study a symmetric collaborative dialogue setting in which two agents, each with private knowledge, must strategically communicate to achieve a common goal. The open-ended dialogue state in this setting poses new challenges for existing dialogue systems. We collected a dataset of 11K human-human dialogues, which exhibits interesting lexical, semantic, and strategic elements. To model both structured knowledge and unstructured language, we propose a neural model with dynamic knowledge graph embeddings that evolve as the dialogue progresses. Automatic and human evaluations show that our model is both more effective at achieving the goal and more human-like than baseline neural and rule-based models.},
archivePrefix = {arXiv},
arxivId = {1704.07130},
author = {He, He and Balakrishnan, Anusha and Eric, Mihail and Liang, Percy},
doi = {10.18653/v1/P17-1162},
eprint = {1704.07130},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/He et al. - 2017 - Learning symmetric collaborative dialogue agents with dynamic knowledge graph embeddings.pdf:pdf},
isbn = {9781945626753},
journal = {ACL 2017 - 55th Annual Meeting of the Association for Computational Linguistics, Proceedings of the Conference (Long Papers)},
pages = {1766--1776},
title = {{Learning symmetric collaborative dialogue agents with dynamic knowledge graph embeddings}},
volume = {1},
year = {2017}
}
@inproceedings{Kollar2018,
abstract = {This paper introduces a meaning representation for spoken language understanding. The Alexa meaning representation language (AMRL), unlike previous approaches, which factor spoken utterances into domains, provides a common representation for how people communicate in spoken language. AMRL is a rooted graph, links to a large-scale ontology, supports cross-domain queries, finegrained types, complex utterances and composition. A spoken language dataset has been collected for Alexa, which contains ∼ 20k examples across eight domains. A version of this meaning representation was released to developers at a trade show in 2016.},
author = {Kollar, Thomas and Berry, Danielle and Stuart, Lauren and Owczarzak, Karolina and Chung, Tagyoung and Mathias, Lambert and Kayser, Michael and Snow, Bradford and Matsoukas, Spyros},
booktitle = {Proc. of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies},
doi = {10.18653/v1/n18-3022},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kollar et al. - 2018 - The Alexa Meaning Representation Language.pdf:pdf},
isbn = {9781948087308},
pages = {177--184},
title = {{The Alexa Meaning Representation Language}},
volume = {3},
year = {2018}
}
@article{Zhang2021,
abstract = {Training machines to understand natural language and interact with humans is an elusive and essential task in the field of artificial intelligence. In recent years, a diversity of dialogue systems has been designed with the rapid development of deep learning researches, especially the recent pre-trained language models. Among these studies, the fundamental yet challenging part is dialogue comprehension whose role is to teach the machines to read and comprehend the dialogue context before responding. In this paper, we review the previous methods from the perspective of dialogue modeling. We summarize the characteristics and challenges of dialogue comprehension in contrast to plain-text reading comprehension. Then, we discuss three typical patterns of dialogue modeling that are widely-used in dialogue comprehension tasks such as response selection and conversation question-answering, as well as dialogue-related language modeling techniques to enhance PrLMs in dialogue scenarios. Finally, we highlight the technical advances in recent years and point out the lessons we can learn from the empirical analysis and the prospects towards a new frontier of researches.},
archivePrefix = {arXiv},
arxivId = {2103.03125},
author = {Zhang, Zhuosheng and Zhao, Hai},
eprint = {2103.03125},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhang, Zhao - 2021 - Advances in Multi-turn Dialogue Comprehension A Survey.pdf:pdf},
title = {{Advances in Multi-turn Dialogue Comprehension: A Survey}},
url = {http://arxiv.org/abs/2103.03125},
year = {2021}
}
@book{Renkema2012,
author = {Renkema, Jan},
edition = {5 edition},
title = {{Schrijfwijzer}},
year = {2012}
}
@article{Rei2017,
abstract = {We propose a sequence labeling framework with a secondary training objective, learning to predict surrounding words for every word in the dataset. This language modeling objective incentivises the system to learn general-purpose patterns of semantic and syntactic composition, which are also useful for improving accuracy on different sequence labeling tasks. The architecture was evaluated on a range of datasets, covering the tasks of error detection in learner texts, named entity recognition, chunking and POS-tagging. The novel language modeling objective provided consistent performance improvements on every benchmark, without requiring any additional annotated or unannotated data.},
archivePrefix = {arXiv},
arxivId = {1704.07156},
author = {Rei, Marek},
doi = {10.18653/v1/P17-1194},
eprint = {1704.07156},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rei - 2017 - Semi-supervised multitask learning for sequence labeling.pdf:pdf},
isbn = {9781945626753},
journal = {ACL 2017 - 55th Annual Meeting of the Association for Computational Linguistics, Proceedings of the Conference (Long Papers)},
pages = {2121--2130},
title = {{Semi-supervised multitask learning for sequence labeling}},
volume = {1},
year = {2017}
}
@inproceedings{Wen2017,
abstract = {Teaching machines to accomplish tasks by conversing naturally with humans is challenging. Currently, developing taskoriented dialogue systems requires creating multiple components and typically this involves either a large amount of handcrafting, or acquiring costly labelled datasets to solve a statistical learning problem for each component. In this work we introduce a neural network-based text-in, textout end-to-end trainable goal-oriented dialogue system along with a new way of collecting dialogue data based on a novel pipe-lined Wizard-of-Oz framework. This approach allows us to develop dialogue systems easily and without making too many assumptions about the task at hand. The results show that the model can converse with human subjects naturally whilst helping them to accomplish tasks in a restaurant search domain.},
author = {Wen, Tsung Hsien and Vandyke, David and Mrk{\v{s}}{\'{i}}c, Nikola and Ga{\v{s}}{\'{i}}c, Milica and Rojas-Barahona, Lina M. and Su, Pei Hao and Ultes, Stefan and Young, Steve},
booktitle = {Proc. of the Conference of the European Chapter of the Association for Computational Linguistics},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wen et al. - 2017 - A Network-based End-to-End Trainable Task-oriented Dialogue System.pdf:pdf},
title = {{A Network-based End-to-End Trainable Task-oriented Dialogue System}},
year = {2017}
}
@article{Zhang2020,
abstract = {Due to the significance and value in human-computer interaction and natural language processing, task-oriented dialog systems are attracting more and more attention in both academic and industrial communities. In this paper, we survey recent advances and challenges in task-oriented dialog systems. We also discuss three critical topics for task-oriented dialog systems: (1) improving data efficiency to facilitate dialog modeling in low-resource settings, (2) modeling multi-turn dynamics for dialog policy learning to achieve better task-completion performance, and (3) integrating domain ontology knowledge into the dialog model. Besides, we review the recent progresses in dialog evaluation and some widely-used corpora. We believe that this survey, though incomplete, can shed a light on future research in task-oriented dialog systems.},
author = {Zhang, Zheng and Takanobu, Ryuichi and Zhu, Qi and Huang, Minlie and Zhu, Xiaoyan},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhang et al. - 2020 - Recent Advances and Challenges in Task-oriented Dialog System.pdf:pdf},
journal = {Science China Technological Sciences},
title = {{Recent Advances and Challenges in Task-oriented Dialog System}},
volume = {63},
year = {2020}
}
@article{Vijayakumar2016,
abstract = {Neural sequence models are widely used to model time-series data. Equally ubiquitous is the usage of beam search (BS) as an approximate inference algorithm to decode output sequences from these models. BS explores the search space in a greedy left-right fashion retaining only the top-B candidates - resulting in sequences that differ only slightly from each other. Producing lists of nearly identical sequences is not only computationally wasteful but also typically fails to capture the inherent ambiguity of complex AI tasks. To overcome this problem, we propose Diverse Beam Search (DBS), an alternative to BS that decodes a list of diverse outputs by optimizing for a diversity-augmented objective. We observe that our method finds better top-1 solutions by controlling for the exploration and exploitation of the search space - implying that DBS is a better search algorithm. Moreover, these gains are achieved with minimal computational or memory over- head as compared to beam search. To demonstrate the broad applicability of our method, we present results on image captioning, machine translation and visual question generation using both standard quantitative metrics and qualitative human studies. Further, we study the role of diversity for image-grounded language generation tasks as the complexity of the image changes. We observe that our method consistently outperforms BS and previously proposed techniques for diverse decoding from neural sequence models.},
author = {Vijayakumar, Ashwin K and Cogswell, Michael and Selvaraju, Ramprasath R. and Sun, Qing and Lee, Stefan and Crandall, David and Batra, Dhruv},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Vijayakumar et al. - 2016 - Diverse Beam Search Decoding Diverse Solutions from Neural Sequence Models.pdf:pdf},
title = {{Diverse Beam Search: Decoding Diverse Solutions from Neural Sequence Models}},
url = {http://arxiv.org/abs/1610.02424},
year = {2016}
}
@article{Chen2017,
abstract = {Dialogue systems have attracted more and more attention. Recent advances on dialogue systems are overwhelmingly contributed by deep learning techniques, which have been employed to enhance a wide range of big data applications such as computer vision, natural language processing, and recommender systems. For dialogue systems, deep learning can leverage a massive amount of data to learn meaningful feature representations and response generation strategies, while requiring a minimum amount of hand-crafting. In this article, we give an overview to these recent advances on dialogue systems from various perspectives and discuss some possible research directions. In particular, we generally divide existing dialogue systems into task-oriented and non-task-oriented models, then detail how deep learning techniques help them with representative algorithms and finally discuss some appealing research directions that can bring the dialogue system research into a new frontier.},
author = {Chen, Hongshen and Liu, Xiaorui and Yin, Dawei and Tang, Jiliang},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chen et al. - 2017 - A Survey on Dialogue Systems Recent Advances and New Frontiers.pdf:pdf},
journal = {ACM SIGKDD Explorations Newsletter},
pages = {25--35},
title = {{A Survey on Dialogue Systems: Recent Advances and New Frontiers}},
volume = {19},
year = {2017}
}
@article{Budzianowski2018,
author = {{Budzianowski Pawe{\l}and Casanueva}, I{\~{n}}igo and Tseng, Bo-hsiang and Ga{\v{s}}i{\'{c}}, Milica},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Budzianowski et al. - 2018 - Towards end-to-end multi-domain dialogue modelling.pdf:pdf},
number = {September},
pages = {1--9},
title = {{Towards end-to-end multi-domain dialogue modelling}},
year = {2018}
}
@article{Lan2020,
archivePrefix = {arXiv},
arxivId = {arXiv:2004.02399v1},
author = {Lan, Tian and Mao, Xian-ling and Wei, Wei and Gao, Xiaoyan and Huang, Heyan},
eprint = {arXiv:2004.02399v1},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lan et al. - 2020 - PONE A Novel Automatic Evaluation Metric for Open-Domain Generative Dialogue Systems.pdf:pdf},
journal = {CoRR},
title = {{PONE: A Novel Automatic Evaluation Metric for Open-Domain Generative Dialogue Systems}},
url = {https://arxiv.org/abs/2004.02399},
volume = {abs/2004.0},
year = {2020}
}
@inproceedings{Peters2019,
abstract = {Sequence-to-sequence models are a powerful workhorse of NLP. Most variants employ a softmax transformation in both their attention mechanism and output layer, leading to dense alignments and strictly positive output probabilities. This density is wasteful, making models less interpretable and assigning probability mass to many implausible outputs. In this paper, we propose sparse sequence-to-sequence models, rooted in a new family of {\$}\backslashalpha{\$}-entmax transformations, which includes softmax and sparsemax as particular cases, and is sparse for any {\$}\backslashalpha {\textgreater} 1{\$}. We provide fast algorithms to evaluate these transformations and their gradients, which scale well for large vocabulary sizes. Our models are able to produce sparse alignments and to assign nonzero probability to a short list of plausible outputs, sometimes rendering beam search exact. Experiments on morphological inflection and machine translation reveal consistent gains over dense models.},
author = {Peters, Ben and Niculae, Vlad and Martins, Andr{\'{e}} F. T.},
booktitle = {Proc. of the Annual Meeting of the Association for Computational Linguistics},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Peters, Niculae, Martins - 2019 - Sparse Sequence-to-Sequence Models.pdf:pdf},
title = {{Sparse Sequence-to-Sequence Models}},
year = {2019}
}
@inproceedings{Banarescu2013,
abstract = {We describe Abstract Meaning Representation (AMR), a semantic representation language in which we are writing down the meanings of thousands of English sentences. We hope that a sembank of simple, whole-sentence semantic structures will spur new work in statistical natural language understanding and generation, like the Penn Treebank encouraged work on statistical parsing. This paper gives an overview of AMR and tools associated with it.},
author = {Banarescu, Laura and Bonial, Claire and Cai, Shu and Georgescu, Madalina and Griffitt, Kira and Hermjakob, Ulf and Knight, Kevin and Koehn, Philipp and Palmer, Martha and Schneider, Nathan},
booktitle = {Proc. of the Linguistic Annotation Workshop and Interoperability with Discourse},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Banarescu et al. - 2013 - Abstract Meaning Representation for Sembanking.pdf:pdf},
isbn = {9781937284589},
pages = {178--186},
title = {{Abstract Meaning Representation for Sembanking}},
year = {2013}
}
@inproceedings{Fan2018,
abstract = {We explore story generation: creative systems that can build coherent and fluent passages of text about a topic. We collect a large dataset of 300K human-written stories paired with writing prompts from an online forum. Our dataset enables hierarchical story generation, where the model first generates a premise, and then transforms it into a passage of text. We gain further improvements with a novel form of model fusion that improves the relevance of the story to the prompt, and adding a new gated multi-scale self-attention mechanism to model long-range context. Experiments show large improvements over strong baselines on both automated and human evaluations. Human judges prefer stories generated by our approach to those from a strong non-hierarchical model by a factor of two to one.},
author = {Fan, Angela and Lewis, Mike and Dauphin, Yann},
booktitle = {Proc. of the Annual Meeting of the Association for Computational Linguistics},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Fan, Lewis, Dauphin - 2018 - Hierarchical Neural Story Generation.pdf:pdf},
title = {{Hierarchical Neural Story Generation}},
year = {2018}
}
@article{Vaswani2017,
abstract = {The dominant sequence transduction models are based on complex recurrent or convolutional neural networks that include an encoder and a decoder. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles, by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.0 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature.},
author = {Vaswani, Ashish and Brain, Google and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Vaswani et al. - 2017 - Attention Is All You Need.pdf:pdf},
journal = {Proc. of the Conference on Neural Information Processing Systems},
title = {{Attention Is All You Need}},
year = {2017}
}
@article{Budzianowski2018,
author = {Budzianowski, Pawe{\l} and Casanueva, I{\~{n}}igo and Tseng, Bo-hsiang and Ga{\v{s}}i{\'{c}}, Milica},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Budzianowski et al. - 2018 - Towards end-to-end multi-domain dialogue modelling.pdf:pdf},
number = {September},
pages = {1--9},
title = {{Towards end-to-end multi-domain dialogue modelling}},
year = {2018}
}
@article{Vakulenko2020,
abstract = {Conversational question answering (QA) requires answers conditioned on the previous turns of the conversation. We address the conversational QA task by decomposing it into question rewriting and question answering subtasks, and conduct a systematic evaluation of this approach on two publicly available datasets. Question rewriting is designed to reformulate ambiguous questions, dependent on the conversation context, into unambiguous questions that are fully interpretable outside of the conversation context. Thereby, standard QA components can consume such explicit questions directly. The main benefit of this approach is that the same questions can be used for querying different information sources, e.g., multiple 3rd-party QA services simultaneously, as well as provide a human-readable interpretation of the question in context. To the best of our knowledge, we are the first to evaluate question rewriting on the conversational question answering task and show its improvement over the end-to-end baselines. Moreover, our conversational QA architecture based on question rewriting sets the new state of the art on the TREC CAsT 2019 dataset with a 28{\%} improvement in MAP and 21{\%} in NDCG@3. Our detailed analysis of the evaluation results provide insights into the sensitivity of QA models to question reformulation, and demonstrates the strengths and weaknesses of the retrieval and extractive QA architectures, that should be reflected in their integration.},
archivePrefix = {arXiv},
arxivId = {2004.14652},
author = {Vakulenko, Svitlana and Longpre, Shayne and Tu, Zhucheng and Anantha, Raviteja},
eprint = {2004.14652},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Vakulenko et al. - 2020 - Question Rewriting for Conversational Question Answering.pdf:pdf},
issn = {23318422},
journal = {arXiv},
keywords = {Conversational question answering,Question answering,Question rewriting},
pages = {0--8},
title = {{Question Rewriting for Conversational Question Answering}},
year = {2020}
}
@article{Celikyilmaz2020,
author = {Celikyilmaz, Asli and Clark, Elizabeth and Gao, Jianfeng},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Celikyilmaz, Clark, Gao - 2020 - Evaluation of Text Generation A Survey.pdf:pdf},
title = {{Evaluation of Text Generation: A Survey}},
url = {https://arxiv.org/abs/2006.14799},
year = {2020}
}
@article{Sarikaya2014,
abstract = {We describe several algorithms for developing natural language understanding (NLU) natural languageunderstanding (NLU) applications. The algorithms include a rule-based system and several statistical systems. We consider two major types of NLU applications: dialog systems dialogsystem and speech mining. speechmining For dialog systems, the NLU function aims to understand the full meaning of a userʼs request in the context of a human-machine interaction in a narrow domain such as travel reservation. For speech mining applications, the NLU function aims at detecting the presence of a limited set of concepts and some of their relations in unrestricted human-human conversations such as in a call center or an oral history digital library. We describe in more detail a statistical parsing algorithm using decision trees for dialog systems and two word-tagging algorithms for speech mining.},
author = {Sarikaya, Ruhi and Hinton, Geoffrey E. and Deoras, Anoop},
doi = {10.1007/978-3-540-49127-9_31},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sarikaya, Hinton, Deoras - 2014 - Application of Deep Belief Networks for Natural Language Understanding.pdf:pdf},
issn = {25228706},
journal = {IEEE/ACM TRANSACTIONS ON AUDIO, SPEECH, AND LANGUAGE PROCESSING},
keywords = {Call Center,Defense Advance Research Project Agency,Mutual Fund,Parse Tree,Structure Query Language},
number = {4},
pages = {617--626},
publisher = {IEEE},
title = {{Application of Deep Belief Networks for Natural Language Understanding}},
volume = {22},
year = {2014}
}
@article{Vakulenko2021,
abstract = {Conversational passage retrieval relies on question rewriting to modify the original question so that it no longer depends on the conversation history. Several methods for question rewriting have recently been proposed, but they were compared under different retrieval pipelines. We bridge this gap by thoroughly evaluating those question rewriting methods on the TREC CAsT 2019 and 2020 datasets under the same retrieval pipeline. We analyze the effect of different types of question rewriting methods on retrieval performance and show that by combining question rewriting methods of different types we can achieve state-of-the-art performance on both datasets.},
archivePrefix = {arXiv},
arxivId = {2101.07382},
author = {Vakulenko, Svitlana and Voskarides, Nikos and Tu, Zhucheng and Longpre, Shayne},
doi = {10.1007/978-3-030-72240-1_43},
eprint = {2101.07382},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Vakulenko et al. - 2021 - A Comparison of Question Rewriting Methods for Conversational Passage Retrieval.pdf:pdf},
pages = {418--424},
title = {{A Comparison of Question Rewriting Methods for Conversational Passage Retrieval}},
year = {2021}
}
@article{Bechet2019,
abstract = {Empirical evaluation is nowadays the main evaluation paradigm in Natural Language Processing for assessing the relevance of a new machine-learning based model. If large corpora are available for tasks such as Automatic Speech Recognition, this is not the case for other tasks such as Spoken Language Understanding (SLU), consisting in translating spoken transcriptions into a formal representation often based on semantic frames. Corpora such as ATIS or SNIPS are widely used to compare systems, however differences in performance among systems are often very small, not statistically significant, and can be produced by biases in the data collection or the annotation scheme, as we presented on the ATIS corpus (“Is ATIS too shallow?, IS2018”). We propose in this study a new methodology for assessing the relevance of an SLU corpus. We claim that only taking into account systems performance does not provide enough insight about what is covered by current state-of-the-art models and what is left to be done. We apply our methodology on a set of 4 SLU systems and 5 benchmark corpora (ATIS, SNIPS, M2M, MEDIA) and automatically produce several indicators assessing the relevance (or not) of each corpus for benchmarking SLU models.},
author = {B{\'{e}}chet, Fr{\'{e}}d{\'{e}}ric and Raymond, Christian},
doi = {10.21437/Interspeech.2019-3033},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/B{\'{e}}chet, Raymond - 2019 - Benchmarking benchmarks Introducing new automatic indicators for benchmarking Spoken Language Understanding co.pdf:pdf},
issn = {19909772},
journal = {Proceedings of the Annual Conference of the International Speech Communication Association, INTERSPEECH},
keywords = {ATIS,Benchmark,M2M,MEDIA,SNIPS,Spoken Language Understanding (SLU)},
pages = {4145--4149},
title = {{Benchmarking benchmarks: Introducing new automatic indicators for benchmarking Spoken Language Understanding corpora}},
volume = {2019-Septe},
year = {2019}
}
@article{Peng2020a,
abstract = {We present a new method SOLOIST that uses transfer learning and machine teaching to build task bots at scale. We parameterize classical modular task-oriented dialog systems using a Transformer-based auto-regressive language model, which subsumes different dialog modules into a single neural model. We pre-train, on heterogeneous dialog corpora, a task-grounded response generation model, which can generate dialog responses grounded in user goals and real-world knowledge for task completion. The pre-trained model can be efficiently adapted to accomplish new tasks with a handful of task-specific dialogs via machine teaching, where training samples are generated by human teachers interacting with the system. Experiments show that (i) SOLOIST creates new state-of-the-art on well-studied task-oriented dialog benchmarks, including CamRest676 and MultiWOZ; (ii) in the few-shot fine-tuning settings, SOLOIST significantly outperforms existing methods, and (iii) the use of machine teaching substantially reduces the labeling cost of fine-tuning. The pre-trained models and codes are available at https://aka.ms/soloist.},
archivePrefix = {arXiv},
arxivId = {2005.05298},
author = {Peng, Baolin and Li, Chunyuan and Li, Jinchao and Shayandeh, Shahin and Liden, Lars and Gao, Jianfeng},
eprint = {2005.05298},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Peng et al. - 2020 - SOLOIST Building Task Bots at Scale with Transfer Learning and Machine Teaching.pdf:pdf},
title = {{SOLOIST: Building Task Bots at Scale with Transfer Learning and Machine Teaching}},
url = {http://arxiv.org/abs/2005.05298},
year = {2020}
}
@article{Lei2018,
abstract = {Existing solutions to task-oriented dialogue systems follow pipeline designs which introduce architectural complexity and fragility. We propose a novel, holistic, extendable framework based on a single sequence-to-sequence (seq2seq) model which can be optimized with supervised or reinforcement learning. A key contribution is that we design text spans named belief spans to track dialogue believes, allowing task-oriented dialogue systems to be modeled in a seq2seq way. Based on this, we propose a simplistic Two Stage CopyNet instantiation which demonstrates good scalability: significantly reducing model complexity in terms of number of parameters and training time by an order of magnitude. It significantly outperforms state-of-the-art pipeline-based methods on two datasets and retains a satisfactory entity match rate on out-of-vocabulary (OOV) cases where pipeline-designed competitors totally fail.},
author = {Lei, Wenqiang and Jin, Xisen and Ren, Zhaochun and He, Xiangnan and Kan, Min Yen and Yin, Dawei},
doi = {10.18653/v1/p18-1133},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lei et al. - 2018 - Sequicity Simplifying task-oriented dialogue systems with single sequence-to-sequence architectures.pdf:pdf},
isbn = {9781948087322},
journal = {ACL 2018 - 56th Annual Meeting of the Association for Computational Linguistics, Proceedings of the Conference (Long Papers)},
pages = {1437--1447},
title = {{Sequicity: Simplifying task-oriented dialogue systems with single sequence-to-sequence architectures}},
volume = {1},
year = {2018}
}
@inproceedings{Serban2016,
abstract = {We investigate the task of building open domain, conversational dialogue systems based on large dialogue corpora using generative models. Generative models produce system responses that are autonomously generated word-by-word, opening up the possibility for realistic, flexible interactions. In support of this goal, we extend the recently proposed hierarchical recurrent encoder-decoder neural network to the dialogue domain, and demonstrate that this model is competitive with state-of-The-Art neural language models and backoff n-gram models. We investigate the limitations of this and similar approaches, and show how its performance can be improved by bootstrapping the learning from a larger questionanswer pair corpus and from pretrained word embeddings.},
author = {Serban, Iulian V. and Sordoni, Alessandro and Bengio, Yoshua and Courville, Aaron and Pineau, Joelle},
booktitle = {Proc. of the AAAI Conference on Artificial Intelligence},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Serban et al. - 2016 - Building End-To-End Dialogue Systems Using Generative Hierarchical Neural Network Models.pdf:pdf},
title = {{Building End-To-End Dialogue Systems Using Generative Hierarchical Neural Network Models}},
year = {2016}
}
@article{Ueyama2021,
abstract = {Dialogue systems using deep learning have achieved generation of fluent response sentences to user utterances. Nevertheless, they tend to produce responses that are not diverse and which are less context-dependent. To address these shortcomings, we propose a new loss function, an Inverse N-gram loss (INF), which incorporates contextual fluency and diversity at the same time by a simple formula. Our INF loss can adjust its loss dynamically by a weight using the inverse frequency of the tokens{\{}'{\}} n-gram applied to Softmax Cross-Entropy loss, so that rare tokens appear more likely while retaining the fluency of the generated sentences. We trained Transformer using English and Japanese Twitter replies as single-turn dialogues using different loss functions. Our INF loss model outperformed the baselines of SCE loss and ITF loss models in automatic evaluations such as DIST-N and ROUGE, and also achieved higher scores on our human evaluations of coherence and richness.},
author = {Ueyama, Ayaka and Kano, Yoshinobu},
doi = {10.18653/v1/2020.coling-main.364},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ueyama, Kano - 2021 - Diverse dialogue generation with context dependent dynamic loss function.pdf:pdf},
number = {Mmi},
pages = {4123--4127},
title = {{Diverse dialogue generation with context dependent dynamic loss function}},
year = {2021}
}
@article{Rocktaschel2016,
abstract = {While most approaches to automatically recognizing entailment relations have used classifiers employing hand engineered features derived from complex natural language processing pipelines, in practice their performance has been only slightly better than bag-of-word pair classifiers using only lexical similarity. The only attempt so far to build an end-to-end differentiable neural network for entailment failed to outperform such a simple similarity classifier. In this paper, we propose a neural model that reads two sentences to determine entailment using long short-term memory units. We extend this model with a word-by-word neural attention mechanism that encourages reasoning over entailments of pairs of words and phrases. Furthermore, we present a qualitative analysis of attention weights produced by this model, demonstrating such reasoning capabilities. On a large entailment dataset this model outperforms the previous best neural model and a classifier with engineered features by a substantial margin. It is the first generic end-to-end differentiable system that achieves state-of-the-art accuracy on a textual entailment dataset.},
archivePrefix = {arXiv},
arxivId = {1509.06664},
author = {Rockt{\"{a}}schel, Tim and Grefenstette, Edward and Hermann, Karl Moritz and Ko{\v{c}}isk{\'{y}}, Tom{\'{a}}{\v{s}} and Blunsom, Phil},
eprint = {1509.06664},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rockt{\"{a}}schel et al. - 2016 - Reasoning about entailment with neural attention.pdf:pdf},
journal = {4th International Conference on Learning Representations, ICLR 2016 - Conference Track Proceedings},
number = {2015},
pages = {1--9},
title = {{Reasoning about entailment with neural attention}},
year = {2016}
}
@article{Chen2020b,
abstract = {Query reformulation aims to alter potentially noisy or ambiguous text sequences into coherent ones closer to natural language questions. In this process, it is also crucial to maintain and even enhance performance in a downstream environments like question answering when rephrased queries are given as input. We explore methods to generate these query reformulations by training reformulators using text-to-text transformers and apply policy-based reinforcement learning algorithms to further encourage reward learning. Query fluency is numerically evaluated by the same class of model fine-tuned on a human-evaluated well-formedness dataset. The reformulator leverages linguistic knowledge obtained from transfer learning and generates more well-formed reformulations than a translation-based model in qualitative and quantitative analysis. During reinforcement learning, it better retains fluency while optimizing the RL objective to acquire question answering rewards and can generalize to out-of-sample textual data in qualitative evaluations. Our RL framework is demonstrated to be flexible, allowing reward signals to be sourced from different downstream environments such as intent classification.},
archivePrefix = {arXiv},
arxivId = {2012.10033},
author = {Chen, Jerry Zikun and Yu, Shi and Wang, Haoran},
eprint = {2012.10033},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chen, Yu, Wang - 2020 - Exploring fluent query reformulations with text-to-text transformers and reinforcement learning.pdf:pdf},
issn = {23318422},
journal = {arXiv},
title = {{Exploring fluent query reformulations with text-to-text transformers and reinforcement learning}},
volume = {2021},
year = {2020}
}
@article{Ahuja2020,
abstract = {Task-oriented dialog models typically leverage complex neural architectures and large-scale, pre-trained Transformers to achieve state-of-the-art performance on popular natural language understanding benchmarks. However, these models frequently have in excess of tens of millions of parameters, making them impossible to deploy on-device where resource-efficiency is a major concern. In this work, we show that a simple convolutional model compressed with structured pruning achieves largely comparable results to BERT on ATIS and Snips, with under 100K parameters. Moreover, we perform acceleration experiments on CPUs, where we observe our multi-task model predicts intents and slots nearly 63x faster than even DistilBERT.},
archivePrefix = {arXiv},
arxivId = {2006.03701},
author = {Ahuja, Ojas and Desai, Shrey},
doi = {10.18653/v1/2020.nlp4convai-1.6},
eprint = {2006.03701},
file = {:home/theritacosta/Desktop/botbuilder{\_}project/reading/2020.nlp4convai-1.6.pdf:pdf},
pages = {46--53},
title = {{Accelerating Natural Language Understanding in Task-Oriented Dialog}},
year = {2020}
}
@article{Kim2019,
abstract = {Recent works in dialogue state tracking (DST) focus on an open vocabulary-based setting to resolve scalability and generalization issues of the predefined ontology-based approaches. However, they are inefficient in that they predict the dialogue state at every turn from scratch. Here, we consider dialogue state as an explicit fixed-sized memory and propose a selectively overwriting mechanism for more efficient DST. This mechanism consists of two steps: (1) predicting state operation on each of the memory slots, and (2) overwriting the memory with new values, of which only a few are generated according to the predicted state operations. Our method decomposes DST into two sub-tasks and guides the decoder to focus only on one of the tasks, thus reducing the burden of the decoder. This enhances the effectiveness of training and DST performance. Our SOM-DST (Selectively Overwriting Memory for Dialogue State Tracking) model achieves state-of-the-art joint goal accuracy with 51.72{\%} in MultiWOZ 2.0 and 53.01{\%} in MultiWOZ 2.1 in an open vocabulary-based DST setting. In addition, we analyze the accuracy gaps between the current and the ground truth-given situations and suggest that it is a promising direction to improve state operation prediction to boost the DST performance.},
archivePrefix = {arXiv},
arxivId = {1911.03906},
author = {Kim, Sungdong and Yang, Sohee and Kim, Gyuwan and Lee, Sang-Woo},
eprint = {1911.03906},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kim et al. - 2019 - Efficient Dialogue State Tracking by Selectively Overwriting Memory.pdf:pdf},
pages = {567--582},
title = {{Efficient Dialogue State Tracking by Selectively Overwriting Memory}},
url = {http://arxiv.org/abs/1911.03906},
year = {2019}
}
@article{Zhang2020a,
abstract = {We present a large, tunable neural conversational response generation model, DialoGPT (dialogue generative pre-trained transformer). Trained on 147M conversation-like exchanges extracted from Reddit comment chains over a period spanning from 2005 through 2017, DialoGPT extends the Hugging Face PyTorch transformer to attain a performance close to human both in terms of automatic and human evaluation in single-turn dialogue settings. We show that conversational systems that leverage DialoGPT generate more relevant, contentful and context-consistent responses than strong baseline systems. The pre-trained model and training pipeline are publicly released to facilitate research into neural response generation and the development of more intelligent open-domain dialogue systems.},
archivePrefix = {arXiv},
arxivId = {1911.00536},
author = {Zhang, Yizhe and Sun, Siqi and Galley, Michel and Chen, Yen-Chun and Brockett, Chris and Gao, Xiang and Gao, Jianfeng and Liu, Jingjing and Dolan, Bill},
doi = {10.18653/v1/2020.acl-demos.30},
eprint = {1911.00536},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhang et al. - 2020 - DIALOGPT Large-Scale Generative Pre-training for Conversational Response Generation.pdf:pdf},
pages = {270--278},
title = {{DIALOGPT : Large-Scale Generative Pre-training for Conversational Response Generation}},
year = {2020}
}
@article{Adiwardana2020,
abstract = {We present Meena, a multi-turn open-domain chatbot trained end-to-end on data mined and filtered from public domain social media conversations. This 2.6B parameter neural network is simply trained to minimize perplexity of the next token. We also propose a human evaluation metric called Sensibleness and Specificity Average (SSA), which captures key elements of a human-like multi-turn conversation. Our experiments show strong correlation between perplexity and SSA. The fact that the best perplexity end-to-end trained Meena scores high on SSA (72{\%} on multi-turn evaluation) suggests that a human-level SSA of 86{\%} is potentially within reach if we can better optimize perplexity. Additionally, the full version of Meena (with a filtering mechanism and tuned decoding) scores 79{\%} SSA, 23{\%} higher in absolute SSA than the existing chatbots we evaluated.},
archivePrefix = {arXiv},
arxivId = {2001.09977},
author = {Adiwardana, Daniel and Luong, Minh-Thang and So, David R. and Hall, Jamie and Fiedel, Noah and Thoppilan, Romal and Yang, Zi and Kulshreshtha, Apoorv and Nemade, Gaurav and Lu, Yifeng and Le, Quoc V.},
eprint = {2001.09977},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Adiwardana et al. - 2020 - Towards a Human-like Open-Domain Chatbot.pdf:pdf},
title = {{Towards a Human-like Open-Domain Chatbot}},
url = {http://arxiv.org/abs/2001.09977},
year = {2020}
}
@article{Rajbhandari2019,
abstract = {Training large DL models with billions and potentially trillions of parameters is challenging. Existing solutions exhibit fundamental limitations to obtain both memory and scaling (computation/communication) efficiency together. Data parallelism does not help reduce memory footprint per device: a model with 1.5 billion parameters or more runs out of memory. Model parallelism hardly scales efficiently beyond multiple devices of a single node due to fine-grained computation and expensive communication. We develop a novel solution, Zero Redundancy Optimizer (ZeRO), to optimize memory, achieving both memory efficiency and scaling efficiency. Unlike basic data parallelism where memory states are replicated across data-parallel processes, ZeRO partitions model states instead, to scale the model size linearly with the number of devices. Furthermore, it retains scaling efficiency via computation and communication rescheduling and by reducing the model parallelism degree required to run large models. Our analysis on memory requirements and communication volume demonstrates: ZeRO has the potential to scale beyond 1 Trillion parameters using today's hardware (e.g., 1024 GPUs, 64 DGX-2 nodes). To meet near-term scaling goals and serve as a demonstration of ZeRO's capability, we implemented stage-1 optimizations of ZeRO (out of 3 stages in total described in the paper) and tested this ZeRO-OS version. ZeRO-OS reduces memory and boosts model size by 4x compared with the state-of-art, scaling up to 100B parameters. Moving forward, we will work on unlocking stage-2 optimizations, with up to 8x memory savings per device, and ultimately stage-3 optimizations, reducing memory linearly with respect to the number of devices and potentially scaling to models of arbitrary size. We are excited to transform very large models from impossible to train to feasible and efficient to train!},
archivePrefix = {arXiv},
arxivId = {1910.02054},
author = {Rajbhandari, Samyam and Rasley, Jeff and Ruwase, Olatunji and He, Yuxiong},
eprint = {1910.02054},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rajbhandari et al. - 2019 - ZeRO Memory optimization towards training a trillion parameter models.pdf:pdf},
issn = {23318422},
journal = {arXiv},
pages = {1--24},
title = {{ZeRO: Memory optimization towards training a trillion parameter models}},
year = {2019}
}
@article{Curtin2013,
abstract = {Dual-tree algorithms are a widely used class of branch-and-bound algorithms. Unfortunately, developing dual-tree algorithms for use with different trees and problems is often complex and burdensome. We introduce a four-part logical split: the tree, the traversal, the point-to-point base case, and the pruning rule. We provide a meta-algorithm which allows development of dual-tree algorithms in a tree-independent manner and easy extension to entirely new types of trees. Representations are provided for five common algorithms; for k-nearcst neighbor search, this leads to a novel, tighter pruning bound. The meta-algorithm also allows straightforward extensions to massively parallel settings. Copyright 2013 by the author(s).},
archivePrefix = {arXiv},
arxivId = {1304.4327},
author = {Curtin, Ryan R. and March, William B. and Ram, Parikshit and Anderson, David V. and Gray, Alexander G. and Isbell, Charles L.},
eprint = {1304.4327},
file = {:home/theritacosta/Desktop/botbuilder{\_}project/reading/1304.4327.pdf:pdf},
journal = {30th International Conference on Machine Learning, ICML 2013},
keywords = {some keywords},
number = {PART 3},
pages = {2485--2493},
title = {{Tree-independent dual-tree algorithms}},
volume = {28},
year = {2013}
}
@article{Brunton2020,
abstract = {Data science, and machine learning in particular, is rapidly transforming the scientific and industrial landscapes. The aerospace industry is poised to capitalize on big data and machine learning, which excels at solving the types of multi-objective, constrained optimization problems that arise in aircraft design and manufacturing. Indeed, emerging methods in machine learning may be thought of as data-driven optimization techniques that are ideal for high-dimensional, non-convex, and constrained, multi-objective optimization problems, and that improve with increasing volumes of data. In this review, we will explore the opportunities and challenges of integrating data-driven science and engineering into the aerospace industry. Importantly, we will focus on the critical need for interpretable, generalizeable, explainable, and certifiable machine learning techniques for safety-critical applications. This review will include a retrospective, an assessment of the current state-of-the-art, and a roadmap looking forward. Recent algorithmic and technological trends will be explored in the context of critical challenges in aerospace design, manufacturing, verification, validation, and services. In addition, we will explore this landscape through several case studies in the aerospace industry. This document is the result of close collaboration between UW and Boeing to summarize past efforts and outline future opportunities.},
author = {Brunton, Steven L. and {Nathan Kutz}, J. and Manohar, Krithika and Aravkin, Aleksandr Y. and Morgansen, Kristi and Klemisch, Jennifer and Goebel, Nicholas and Buttrick, James and Poskin, Jeffrey and Blom-Schieber, Agnes and Hogan, Thomas and McDonald, Darren},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Brunton et al. - 2020 - Data-Driven Aerospace Engineering Reframing the Industry with Machine Learning.pdf:pdf},
keywords = {Aerospace engineering,Data science,Design,Machine learning,Manufacturing,Optimization},
title = {{Data-Driven Aerospace Engineering: Reframing the Industry with Machine Learning}},
url = {https://arxiv.org/abs/2008.10740},
year = {2020}
}
@inproceedings{Shao2017,
abstract = {Sequence-to-sequence models have been applied to the conversation response generation problem where the source sequence is the conversation history and the target sequence is the response. Unlike translation, conversation responding is inherently creative. The generation of long, informative, coherent, and diverse responses remains a hard task. In this work, we focus on the single turn setting. We add self-attention to the decoder to maintain coherence in longer responses, and we propose a practical approach, called the glimpse-model, for scaling to large datasets. We introduce a stochastic beam-search algorithm with segment-by-segment reranking which lets us inject diversity earlier in the generation process. We trained on a combined data set of over 2.3B conversation messages mined from the web. In human evaluation studies, our method produces longer responses overall, with a higher proportion rated as acceptable and excellent as length increases, compared to baseline sequence-to-sequence models with explicit length-promotion. A back-off strategy produces better responses overall, in the full spectrum of lengths.},
author = {Shao, Louis and Gouws, Stephan and Britz, Denny and Goldie, Anna and Strope, Brian and Kurzweil, Ray},
booktitle = {Proc. of the Conference on Empirical Methods in Natural Language Processing},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Shao et al. - 2017 - Generating High-Quality and Informative Conversation Responses with Sequence-to-Sequence models.pdf:pdf},
title = {{Generating High-Quality and Informative Conversation Responses with Sequence-to-Sequence models}},
year = {2017}
}
@article{Zhao2019a,
abstract = {Defining action spaces for conversational agents and optimizing their decision-making process with reinforcement learning is an enduring challenge. Common practice has been to use handcrafted dialog acts, or the output vocabulary, e.g. in neural encoder decoders, as the action spaces. Both have their own limitations. This paper proposes a novel latent action framework that treats the action spaces of an end-to-end dialog agent as latent variables and develops unsupervised methods in order to induce its own action space from the data. Comprehensive experiments are conducted examining both continuous and discrete action types and two different optimization methods based on stochastic variational inference. Results show that the proposed latent actions achieve superior empirical performance improvement over previous word-level policy gradient methods on both DealOrNoDeal and MultiWoz dialogs. Our detailed analysis also provides insights about various latent variable approaches for policy learning and can serve as a foundation for developing better latent actions in future research.},
archivePrefix = {arXiv},
arxivId = {1902.08858},
author = {Zhao, Tiancheng and Xie, Kaige and Eskenazi, Maxine},
doi = {10.18653/v1/n19-1123},
eprint = {1902.08858},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhao, Xie, Eskenazi - 2019 - Rethinking Action Spaces for Reinforcement Learning in End-to-end Dialog Agents with Latent Variable Models.pdf:pdf},
pages = {1208--1218},
title = {{Rethinking Action Spaces for Reinforcement Learning in End-to-end Dialog Agents with Latent Variable Models}},
year = {2019}
}
@article{Haponchyk2020,
abstract = {Modern automated dialog systems require complex dialog managers able to deal with user intent triggered by high-level semantic questions. In this paper, we propose a model for automatically clustering questions into user intents to help the design tasks. Since questions are short texts, uncovering their semantics to group them together can be very challenging. We approach the problem by using powerful semantic classifiers from question duplicate/matching research along with a novel idea of supervised clustering methods based on structured output. We test our approach on two intent clustering corpora, showing an impressive improvement over previous methods for two languages/domains.},
author = {Haponchyk, Iryna and Uva, Antonio and Yu, Seunghak and Uryupina, Olga and Moschitti, Alessandro},
doi = {10.18653/v1/d18-1254},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Haponchyk et al. - 2020 - Supervised Clustering of Questions into Intents for Dialog System Applications.pdf:pdf},
isbn = {9781948087841},
journal = {Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, EMNLP 2018},
pages = {2310--2321},
title = {{Supervised Clustering of Questions into Intents for Dialog System Applications}},
year = {2020}
}
@article{Moulavi2014,
abstract = {One of the most challenging aspects of clustering is validation, which is the objective and quantitative assessment of clustering results. A number of different relative validity criteria have been proposed for the validation of globular, clusters. Not all data, however, are composed of globular clusters. Density-based clustering algorithms seek partitions with high density areas of points (clusters, not necessarily globular) separated by low density areas, possibly containing noise objects. In these cases relative validity indices proposed for globular cluster validation may fail. In this paper we propose a relative validation index for density-based, arbitrarily shaped clusters. The index assesses clustering quality based on the relative density connection between pairs of objects. Our index is formulated on the basis of a new kernel density function, which is used to compute the density of objects and to evaluate the within- and between-cluster density connectedness of clustering results. Experiments on synthetic and real world data show the effectiveness of our approach for the evaluation and selection of clustering algorithms and their respective appropriate parameters.},
author = {Moulavi, Davoud and Jaskowiak, Pablo A. and Campello, Ricardo J.G.B. and Zimek, Arthur and Sander, Jorg},
doi = {10.1137/1.9781611973440.96},
file = {:home/theritacosta/Desktop/botbuilder{\_}project/reading/DBCV.pdf:pdf;:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Moulavi et al. - 2014 - Density-Based Clustering Validation.pdf:pdf},
isbn = {9781510811515},
journal = {SIAM International Conference on Data Mining 2014, SDM 2014},
number = {i},
pages = {839--847},
title = {{Density-Based Clustering Validation}},
volume = {2},
year = {2014}
}
@article{Kim2021,
abstract = {One of the main challenges in conversational question answering (CQA) is to resolve the conversational dependency, such as anaphora and ellipsis. However, existing approaches do not explicitly train QA models on how to resolve the dependency, and thus these models are limited in understanding human dialogues. In this paper, we propose a novel framework, ExCorD (Explicit guidance on how to resolve Conversational Dependency) to enhance the abilities of QA models in comprehending conversational context. ExCorD first generates self-contained questions that can be understood without the conversation history, then trains a QA model with the pairs of original and self-contained questions using a consistency-based regularizer. In our experiments, we demonstrate that ExCorD significantly improves the QA models' performance by up to 1.2 F1 on QuAC, and 5.2 F1 on CANARD, while addressing the limitations of the existing approaches.},
archivePrefix = {arXiv},
arxivId = {2106.11575},
author = {Kim, Gangwoo and Kim, Hyunjae and Park, Jungsoo and Kang, Jaewoo},
eprint = {2106.11575},
file = {:home/theritacosta/Desktop/botbuilder{\_}project/reading/2106.11575.pdf:pdf},
title = {{Learn to Resolve Conversational Dependency: A Consistency Training Framework for Conversational Question Answering}},
url = {http://arxiv.org/abs/2106.11575},
year = {2021}
}
@article{Regan2019,
abstract = {We present Contextual Query Rewrite (CQR) a dataset for multi-domain task-oriented spoken dialogue systems that is an extension of the Stanford dialog corpus (Eric et al., 2017a). While previous approaches have addressed the issue of diverse schemas by learning candidate transformations (Naik et al., 2018), we instead model the reference resolution task as a user query reformulation task, where the dialog state is serialized into a natural language query that can be executed by the downstream spoken language understanding system. In this paper, we describe our methodology for creating the query reformulation extension to the dialog corpus, and present an initial set of experiments to establish a baseline for the CQR task. We have released the corpus to the public1 to support further research in this area.},
archivePrefix = {arXiv},
arxivId = {1903.11783},
author = {Regan, Michael and Rastogi, Pushpendre and Gupta, Arpit and Mathias, Lambert},
eprint = {1903.11783},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Regan et al. - 2019 - A dataset for resolving referring expressions in spoken dialogue via contextual query rewrites (CQR).pdf:pdf},
issn = {23318422},
journal = {arXiv},
title = {{A dataset for resolving referring expressions in spoken dialogue via contextual query rewrites (CQR)}},
year = {2019}
}
@article{March2010,
abstract = {The Euclidean Minimum Spanning Tree problem has applications in a wide range of fields, and many efficient algorithms have been developed to solve it. We present a new, fast, general EMST algorithm, motivated by the clustering and analysis of astronomical data. Large-scale astronomical surveys, including the Sloan Digital Sky Survey, and large simulations of the early universe, such as the Millennium Simulation, can contain millions of points and fill terabytes of storage. Traditional EMST methods scale quadratically, and more advanced methods lack rigorous runtime guarantees. We present a new dual-tree algorithm for efficiently computing the EMST, use adaptive algorithm analysis to prove the tightest (and possibly optimal) runtime bound for the EMST problem to-date, and demonstrate the scalability of our method on astronomical data sets. {\textcopyright} 2010 ACM.},
author = {March, William B. and Ram, Parikshit and Gray, Alexander G.},
doi = {10.1145/1835804.1835882},
file = {:home/theritacosta/Desktop/botbuilder{\_}project/reading/emst.pdf:pdf},
isbn = {9781450300551},
journal = {Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
keywords = {Adaptive algorithm analysis,Euclidean Minimum Spanning Trees},
pages = {603--611},
title = {{Fast Euclidean Minimum Spanning Tree: Algorithm, analysis, and applications}},
year = {2010}
}
@article{Yang2019a,
author = {Yang, Wei and Lu, Kuang and Yang, Peilin and Lin, Jimmy},
doi = {10.1145/3331184.3331340},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yang et al. - 2019 - Critically Examining the Neural Hype.pdf:pdf},
isbn = {9781450361729},
number = {January},
pages = {1129--1132},
title = {{Critically Examining the "Neural Hype"}},
year = {2019}
}
@article{Gonzalez2019,
abstract = {Most research on dialogue has focused either on dialogue generation for openended chit chat or on state tracking for goal-directed dialogue. In this work, we explore a hybrid approach to goal-oriented dialogue generation that combines retrieval from past history with a hierarchical, neural encoder-decoder architecture. We evaluate this approach in the customer support domain using the Multiwoz dataset (Budzianowski et al., 2018). We show that adding this retrieval step to a hierarchical, neural encoder-decoder architecture leads to significant improvements, including responses that are rated more appropriate and fluent by human evaluators. Finally, we compare our retrieval-based model to various semantically conditioned models explicitly using past dialog act information, and find that our proposed model is competitive with the current state of the art (Chen et al., 2019), while not requiring explicit labels about past machine acts.},
archivePrefix = {arXiv},
arxivId = {1909.13717},
author = {Gonzalez, Ana Valeria and Augenstein, Isabelle and S{\o}gaard, Anders},
eprint = {1909.13717},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gonzalez, Augenstein, S{\o}gaard - 2019 - Retrieval-based Goal-Oriented Dialogue Generation.pdf:pdf},
title = {{Retrieval-based Goal-Oriented Dialogue Generation}},
url = {http://arxiv.org/abs/1909.13717},
year = {2019}
}
@article{Cambazoglu,
author = {Cambazoglu, B Barla and Sanderson, Mark and Croft, Bruce},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cambazoglu, Sanderson, Croft - 2020 - A Review of Public Datasets in Question Answering Research.pdf:pdf},
journal = {ACM SIGIR Forum},
number = {2},
pages = {1--23},
title = {{A Review of Public Datasets in Question Answering Research}},
volume = {54},
year = {2020}
}
@article{Ward1994,
abstract = {We have been developing a spoken language system to recognize and understand spontaneous speech. It is difficult for such systems to achieve good coverage of the lexicon and grammar that subjects might use because spontaneous speech often contains disfluencies and ungrammatical constructions. Our goal is to respond appropriately to input, even though coverage is not complete. The natural language component of our system is oriented toward the extraction of information relevant to a task, and seeks to directly optimize the correctness of the extracted information (and therefore the system response). We use a flexible frame-based parser, which parses as much of the input as possible. This approach leads both to high accuracy and robustness. We have implemented a version of this system for the Air Travel Information Service (ATIS) task, which is being used by several ARPA-funded sites to develop and evaluate speech understanding systems. Users are asked to perform a task that requires getting information from an Air Travel database. In this paper, we describe recent improvements in our system resulting from our efforts to improve the coverage given a limited amount of training data. These improvements address a number of problems including generating an adequate lexicon and grammar for the recognizer, generating and generalizing an appropriate grammar for the parser, and dealing with ambiguous parses.},
author = {Ward, Wayne and Issar, Sunil},
doi = {10.3115/1075812.1075857},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ward, Issar - 1994 - Recent improvements in the CMU spoken language understanding system.pdf:pdf},
pages = {213},
title = {{Recent improvements in the CMU spoken language understanding system}},
year = {1994}
}
@article{Smith2020,
abstract = {Being engaging, knowledgeable, and empathetic are all desirable general qualities in a conversational agent. Previous work has introduced tasks and datasets that aim to help agents to learn those qualities in isolation and gauge how well they can express them. But rather than being specialized in one single quality, a good open-domain conversational agent should be able to seamlessly blend them all into one cohesive conversational flow. In this work, we investigate several ways to combine models trained towards isolated capabilities, ranging from simple model aggregation schemes that require minimal additional training, to various forms of multi-task training that encompass several skills at all training stages. We further propose a new dataset, BlendedSkillTalk, to analyze how these capabilities would mesh together in a natural conversation, and compare the performance of different architectures and training schemes. Our experiments show that multi-tasking over several tasks that focus on particular capabilities results in better blended conversation performance compared to models trained on a single skill, and that both unified or two-stage approaches perform well if they are constructed to avoid unwanted bias in skill selection or are fine-tuned on our new task.},
archivePrefix = {arXiv},
arxivId = {2004.08449},
author = {Smith, Eric Michael and Williamson, Mary and Shuster, Kurt and Weston, Jason and Boureau, Y-Lan},
eprint = {2004.08449},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Smith et al. - 2020 - Can You Put it All Together Evaluating Conversational Agents' Ability to Blend Skills.pdf:pdf},
title = {{Can You Put it All Together: Evaluating Conversational Agents' Ability to Blend Skills}},
url = {http://arxiv.org/abs/2004.08449},
year = {2020}
}
@article{Tomashenko2019,
abstract = {This work investigates spoken language understanding (SLU) systems in the scenario when the semantic information is extracted directly from the speech signal by means of a single end-to-end neural network model. Two SLU tasks are considered: named entity recognition (NER) and semantic slot filling (SF). For these tasks, in order to improve the model performance, we explore various techniques including speaker adaptation, a modification of the connectionist temporal classification (CTC) training criterion, and sequential pretraining.},
archivePrefix = {arXiv},
arxivId = {1909.13332},
author = {Tomashenko, Natalia and Caubri{\`{e}}re, Antoine and Est{\`{e}}ve, Yannick and Laurent, Antoine and Morin, Emmanuel},
doi = {10.1007/978-3-030-31372-2_4},
eprint = {1909.13332},
file = {:home/theritacosta/Desktop/botbuilder{\_}project/reading/1909.13332.pdf:pdf},
isbn = {9783030313715},
issn = {16113349},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
keywords = {Acoustic adaptation,End-to-end SLU,Named entity recognition,Slot filling,Spoken language understanding (SLU)},
pages = {44--55},
title = {{Recent Advances in End-to-End Spoken Language Understanding}},
volume = {11816 LNAI},
year = {2019}
}
@inproceedings{Bhowmick2008,
abstract = {An affective text may be judged to belong to multiple affect categories as it may evoke different affects with varying degree of intensity. For affect classification of text, it is often required to annotate text corpus with affect categories. This task is often performed by a number of human judges. This paper presents a new agreement measure inspired by Kappa coefficient to compute inter-annotator reliability when the annotators have freedom to categorize a text into more than one class. The extended reliability coefficient has been applied to measure the quality of an affective text corpus. An analysis of the factors that influence corpus quality has been provided.},
author = {Bhowmick, Plaban Kr. and Mitra, Pabitra and Basu, Anupam},
booktitle = {Proc. of the Workshop on Human Judgements in Computational Linguistics},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bhowmick, Mitra, Basu - 2008 - An Agreement Measure for Determining Inter-Annotator Reliability of Human Judgements on Affective Text.pdf:pdf},
title = {{An Agreement Measure for Determining Inter-Annotator Reliability of Human Judgements on Affective Text}},
year = {2008}
}
@article{McInnes2018,
abstract = {UMAP (Uniform Manifold Approximation and Projection) is a novel manifold learning technique for dimension reduction. UMAP is constructed from a theoretical framework based in Riemannian geometry and algebraic topology. The result is a practical scalable algorithm that applies to real world data. The UMAP algorithm is competitive with t-SNE for visualization quality, and arguably preserves more of the global structure with superior run time performance. Furthermore, UMAP has no computational restrictions on embedding dimension, making it viable as a general purpose dimension reduction technique for machine learning.},
archivePrefix = {arXiv},
arxivId = {1802.03426},
author = {McInnes, Leland and Healy, John and Melville, James},
eprint = {1802.03426},
file = {:home/theritacosta/Desktop/botbuilder{\_}project/reading/1802.03426.pdf:pdf},
title = {{UMAP: Uniform Manifold Approximation and Projection for Dimension Reduction}},
url = {http://arxiv.org/abs/1802.03426},
year = {2018}
}
@inproceedings{Kannan2016,
abstract = {In this paper we propose and investigate a novel end-to-end method for automatically generating short email responses, called Smart Reply. It generates semantically diverse sug- gestions that can be used as complete email responses with just one tap on mobile. The system is currently used in Inbox by Gmail and is responsible for assisting with 10{\%} of all mobile responses. It is designed to work at very high throughput and process hundreds of millions of messages daily. The system exploits state-of-the-art, large-scale deep learning. We describe the architecture of the system as well as the challenges that we faced while building it, like response diversity and scalability. We also introduce a new method for semantic clustering of user-generated content that requires only a modest amount of explicitly labeled data.},
author = {Kannan, Anjuli and Kurach, Karol and Ravi, Sujith and Kaufmann, Tobias and Tomkins, Andrew and Miklos, Balint and Corrado, Greg and Luk{\'{a}}cs, L{\'{a}}szl{\'{o}} and Ganea, Marina and Young, Peter and Ramavajjala, Vivek},
booktitle = {Proc. of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kannan et al. - 2016 - Smart Reply Automated Response Suggestion for Email.pdf:pdf},
keywords = {Clustering,Deep learning,Email,LSTM,Semantics},
title = {{Smart Reply: Automated Response Suggestion for Email}},
year = {2016}
}
@article{Lowe2017,
abstract = {In this paper, we analyze neural network-based dialogue systems trained in an end-to-end manner using an updated version of the recent Ubuntu Dialogue Corpus, a dataset containing almost 1 million multi-turn dialogues, with a total of over 7 million utterances and 100 million words1. This dataset is interesting because of its size, long context lengths, and technical nature; thus, it can be used to train large models directly from data with minimal feature engineering. We provide baselines in two different environments: one where models are trained to select the correct next response from a list of candidate responses, and one where models are trained to maximize the loglikelihood of a generated utterance conditioned on the context of the conversation. These are both evaluated on a recall task that we call next utterance classification (NUC), and using vector-based metrics that capture the topicality of the responses. We observe that current end-to-end models are unable to completely solve these tasks; thus, we provide a qualitative error analysis to determine the primary causes of error for end-to-end models evaluated on NUC, and examine sample utterances from the generative models. As a result of this analysis, we suggest some promising directions for future research on the Ubuntu Dialogue Corpus, which can also be applied to end-to-end dialogue systems in general.},
author = {Lowe, Ryan and Pow, Nissan and Serban, Iulian Vlad and Charlin, Laurent and Liu, Chia Wei and Pineau, Joelle},
doi = {10.5087/dad.2017.102},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lowe et al. - 2017 - Training End-to-End Dialogue Systems with the Ubuntu Dialogue Corpus.pdf:pdf},
issn = {21529620},
journal = {Dialogue and Discourse},
number = {1},
pages = {31--65},
title = {{Training End-to-End Dialogue Systems with the Ubuntu Dialogue Corpus}},
volume = {8},
year = {2017}
}
@inproceedings{Ham2019,
abstract = {The goal-oriented dialogue system needs to be optimized for tracking the dialogue flow and carrying out an effective conversation under various situations to meet the user goal. The traditional approach to building such a dialogue system is to take a pipelined modular architecture, where its modules are optimized individually. However, such an optimization scheme does not necessarily yield an overall performance improvement of the whole system. On the other hand, end-to-end dialogue systems with monolithic neural architecture are often trained only with input-output utterances, without taking into account the entire annotations available in the corpus. This scheme makes it difficult for goal-oriented dialogues where the system needs to be integrated with external systems or to provide in-terpretable information about why the system generated a particular response. In this paper, we present an end-to-end neural architecture for dialogue systems that addresses both challenges above. Our dialogue system achieved the success rate of 68.32{\%}, the language understanding score of 4.149, and the response appropriateness score of 4.287 in human evaluations , which ranked the system at the top position in the end-to-end multi-domain dialogue system task in the 8th dialogue systems technology challenge (DSTC8).},
author = {Ham, Donghoon and Lee, Jeong-gwan and Jang, Youngsoo and Kim, Kee-eung},
booktitle = {Proc. of the Annual Meeting of the Association for Computational Linguistics},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ham et al. - 2020 - End-to-End Neural Pipeline for Goal-Oriented Dialogue System using GPT-2.pdf:pdf},
title = {{End-to-End Neural Pipeline for Goal-Oriented Dialogue System using GPT-2}},
year = {2020}
}
@article{Kalchbrenner2014,
abstract = {The ability to accurately represent sentences is central to language understanding. We describe a convolutional architecture dubbed the Dynamic Convolutional Neural Network (DCNN) that we adopt for the semantic modelling of sentences. The network uses Dynamic k-Max Pooling, a global pooling operation over linear sequences. The network handles input sentences of varying length and induces a feature graph over the sentence that is capable of explicitly capturing short and long-range relations. The network does not rely on a parse tree and is easily applicable to any language. We test the DCNN in four experiments: small scale binary and multi-class sentiment prediction, six-way question classification and Twitter sentiment prediction by distant supervision. The network achieves excellent performance in the first three tasks and a greater than 25{\%} error reduction in the last task with respect to the strongest baseline. {\textcopyright} 2014 Association for Computational Linguistics.},
archivePrefix = {arXiv},
arxivId = {1404.2188},
author = {Kalchbrenner, Nal and Grefenstette, Edward and Blunsom, Phil},
doi = {10.3115/v1/p14-1062},
eprint = {1404.2188},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kalchbrenner, Grefenstette, Blunsom - 2014 - A convolutional neural network for modelling sentences.pdf:pdf},
isbn = {9781937284725},
journal = {52nd Annual Meeting of the Association for Computational Linguistics, ACL 2014 - Proceedings of the Conference},
pages = {655--665},
title = {{A convolutional neural network for modelling sentences}},
volume = {1},
year = {2014}
}
@article{Artstein2008,
author = {Artstein, Ron and Poesio, Massimo},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Artstein, Poesio - 2008 - Survey Article Inter-Coder Agreement for Computational Linguistics.pdf:pdf},
journal = {Computational Linguistics},
pages = {555--596},
title = {{Survey Article: Inter-Coder Agreement for Computational Linguistics}},
volume = {34},
year = {2008}
}
@article{Zhang2011,
abstract = {Gradient coils are essential components of magnetic resonance imaging (MRI) systems. In this paper, we present an optimized target-field method for designing a transverse biplanar gradient coil with high linearity, low inductance and small resistance, which can well satisfy the requirements of permanent-magnet MRI systems. In this new method, the current density is expressed by trigonometric basis functions with unknown coefficients in polar coordinates. Following the standard procedures, we construct an objective function with respect to the total square errors of the magnetic field at all target-field points with the penalty items associated with the stored magnetic energy and the dissipated power. By adjusting the two penalty factors and minimizing the objective function, the appropriate coefficients of the current density are determined. Applying the stream function method to the current density, the specific winding patterns on the planes can be obtained. A novel biplanar gradient coil has been designed using this method to operate in a permanent-magnet MRI system. In order to verify the validity of the proposed approach, the gradient magnetic field generated by the resulted current density has been calculated via the Biot-Savart law. The results have demonstrated the effectiveness and advantage of this proposed method. {\textcopyright} 2011 IOP Publishing Ltd.},
author = {Zhang, Rui and Xu, Jing and Fu, Youyi and Li, Yangjing and Huang, Kefu and Zhang, Jue and Fang, Jing},
doi = {10.1088/0957-0233/22/12/125505},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhang et al. - 2011 - An optimized target-field method for MRI transverse biplanar gradient coil design.pdf:pdf},
issn = {13616501},
journal = {Measurement Science and Technology},
keywords = {MRI,biplanar gradient coil,current density,optimized target-field method,polar coordinates,trigonometric basis function},
number = {12},
pages = {12--18},
title = {{An optimized target-field method for MRI transverse biplanar gradient coil design}},
volume = {22},
year = {2011}
}
@article{Lin2020b,
abstract = {This paper presents an empirical study of conversational question reformulation (CQR) with sequence-to-sequence architectures and pretrained language models (PLMs). We leverage PLMs to address the strong token-to-token independence assumption made in the common objective, maximum likelihood estimation, for the CQR task. In CQR benchmarks of task-oriented dialogue systems, we evaluate fine-tuned PLMs on the recently-introduced CANARD dataset as an in-domain task and validate the models using data from the TREC 2019 CAsT Track as an out-domain task. Examining a variety of architectures with different numbers of parameters, we demonstrate that the recent text-to-text transfer transformer (T5) achieves the best results both on CANARD and CAsT with fewer parameters, compared to similar transformer architectures.},
archivePrefix = {arXiv},
arxivId = {2004.01909},
author = {Lin, Sheng Chieh and Yang, Jheng Hong and Nogueira, Rodrigo and Tsai, Ming Feng and Wang, Chuan Ju and Lin, Jimmy},
eprint = {2004.01909},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lin et al. - 2020 - Conversational question reformulation via sequence-to-sequence architectures and pretrained language models.pdf:pdf},
issn = {23318422},
journal = {arXiv},
pages = {2--6},
title = {{Conversational question reformulation via sequence-to-sequence architectures and pretrained language models}},
year = {2020}
}
@article{Maaten2008,
abstract = {Local Indicators of Spatial Aggregation (LISA) can be used as objectives in a multicriteria framework when highly autocorrelated areas (hot-spots) must be identified and geographically located in complex areas. To do so, a Multi-Objective Evolutionary Algorithm (MOEA) based on SPEA2 (Strength Pareto Evolutionary Algorithm v.2) has been designed to evaluate three different fitness functions (fine-grained strength, the weighted sum of objectives and fuzzy evaluation of weighted objectives) and three LISA methods. MOEA makes it possible to achieve a compromise between spatial econometric methods as it highlights areas where a specific phenomenon shows significantly high autocorrelation. The spatial distribution of financially compromised olive-tree farms in Andalusia (Spain) was selected for analysis and two fuzzy hot-spots were statistically identified and spatially located. Hot-spots can be considered to be spatial fuzzy sets where the spatial units have a membership degree that can also be calculated. {\textcopyright} 2011 Springer Science+Business Media, LLC.},
author = {van der Maaten, Laurens and Hinton, Geoffrey},
file = {:home/theritacosta/Desktop/botbuilder{\_}project/reading/vandermaaten08a.pdf:pdf},
issn = {15729338},
journal = {Journal of Machine Learning Research 9},
keywords = {Financially compromised areas,Fuzzy hot-spots,Local indicators of spatial aggregation,Multiobjective evolutionary algorithms,Spatial analysis},
title = {{Visualizing Data using t-SNE}},
year = {2008}
}
@article{Bagga1998,
abstract = {Cross-document coreference occurs when the same person, place, event, or concept is discussed in more than one text source. Computer recognition of this phenomenon is important because it helps break "the document boundary" by allowing a user to examine information about a particular entity from multiple text sources at the same time. In this paper we descrive a cross-document coreference resolution algorithm which uses the Vector Space Model to resolve ambiguities between people having the same name. In addition, we also describe a scoring algorithm for evaluating the cross-document coreference chains produced by our system and we compare our algorithm to the scoring algorithm used in the MUC-6 (within document) coreference task.},
author = {Bagga, Amit and Baldwin, Breck},
doi = {10.3115/980845.980859},
file = {:home/theritacosta/Desktop/botbuilder{\_}project/reading/P98-1012.pdf:pdf},
pages = {79},
title = {{Entity-Based Cross-Document Coreferencing Using the Vector Space Model}},
year = {1998}
}
@article{Nogueira2019,
abstract = {Recently, neural models pretrained on a language modeling task, such as ELMo (Peters et al., 2017), OpenAI GPT (Radford et al., 2018), and BERT (Devlin et al., 2018), have achieved impressive results on various natural language processing tasks such as question-answering and natural language inference. In this paper, we describe a simple re-implementation of BERT for query-based passage re-ranking. Our system is the state of the art on the TREC-CAR dataset and the top entry in the leaderboard of the MS MARCO passage retrieval task, outperforming the previous state of the art by 27{\%} (relative) in MRR@10. The code to reproduce our results is available at https://github.com/nyu-dl/ dl4marco-bert.},
archivePrefix = {arXiv},
arxivId = {1901.04085},
author = {Nogueira, Rodrigo and Cho, Kyunghyun},
eprint = {1901.04085},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Nogueira, Cho - 2019 - Passage Re-ranking with BERT.pdf:pdf},
issn = {23318422},
journal = {arXiv},
pages = {1--5},
title = {{Passage Re-ranking with BERT}},
year = {2019}
}
@inproceedings{Mathur2020,
abstract = {This paper presents the results of the WMT18 Metrics Shared Task. We asked participants of this task to score the outputs of the MT systems involved in the WMT18 News Translation Task with automatic metrics. We collected scores of 10 metrics and 8 research groups. In addition to that, we computed scores of 8 standard met-rics (BLEU, SentBLEU, chrF, NIST, WER, PER, TER and CDER) as base-lines. The collected scores were evaluated in terms of system-level correlation (how well each metric's scores correlate with WMT18 official manual ranking of systems) and in terms of segment-level correlation (how often a metric agrees with humans in judging the quality of a particular sentence relative to alternate outputs). This year, we employ a single kind of manual evaluation: direct assessment (DA).},
author = {Mathur, Nitika and Wei, Johnny Tian-Zheng and Freitag, Markus and Ma, Qingsong and Bojar, Ondrej},
booktitle = {Proc. of the Conference on Machine Translation},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mathur et al. - 2020 - Results of the WMT20 Metrics Shared Task.pdf:pdf},
title = {{Results of the WMT20 Metrics Shared Task}},
year = {2020}
}
@inproceedings{Angeli2010,
abstract = {We present a simple, robust generation system which performs content selection and surface realization in a unified, domain-independent framework. In our approach, we break up the end-to-end generation process into a sequence of local decisions, arranged hierarchically and each trained discriminatively. We deployed our system in three different domains - Robocup sportscasting, technical weather forecasts, and common weather forecasts, obtaining results comparable to state-of-the-art domain-specific systems both in terms of BLEU scores and human evaluation. {\textcopyright} 2010 Association for Computational Linguistics.},
author = {Angeli, Gabor and Liang, Percy and Klein, Dan},
booktitle = {Proc. of the Conference on Empirical Methods in Natural Language Processing},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Angeli, Liang, Klein - 2010 - A Simple Domain-Independent Probabilistic Approach to Generation.pdf:pdf},
title = {{A Simple Domain-Independent Probabilistic Approach to Generation}},
year = {2010}
}
@article{Zhao2020,
abstract = {A robust evaluation metric has a profound impact on the development of text generation systems. A desirable metric compares system output against references based on their semantics rather than surface forms. In this paper we investigate strategies to encode system and reference texts to devise a metric that shows a high correlation with human judgment of text quality. We validate our new metric, namely MoverScore, on a number of text generation tasks including summarization, machine translation, image captioning, and data-to-text generation, where the outputs are produced by a variety of neural and non-neural systems. Our findings suggest that metrics combining contextualized representations with a distance measure perform the best. Such metrics also demonstrate strong generalization capability across tasks. For ease-of-use we make our metrics available as web service.1.},
archivePrefix = {arXiv},
arxivId = {1909.02622},
author = {Zhao, Wei and Peyrard, Maxime and Liu, Fei and Gao, Yang and Meyer, Christian M. and Eger, Steffen},
doi = {10.18653/v1/d19-1053},
eprint = {1909.02622},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhao et al. - 2020 - Moverscore Text generation evaluating with contextualized embeddings and earth mover distance.pdf:pdf},
isbn = {9781950737901},
journal = {EMNLP-IJCNLP 2019 - 2019 Conference on Empirical Methods in Natural Language Processing and 9th International Joint Conference on Natural Language Processing, Proceedings of the Conference},
pages = {563--578},
title = {{Moverscore: Text generation evaluating with contextualized embeddings and earth mover distance}},
year = {2020}
}
@article{Reimers2020,
abstract = {BERT (Devlin et al., 2018) and RoBERTa (Liu et al., 2019) has set a new state-of-the-art performance on sentence-pair regression tasks like semantic textual similarity (STS). However, it requires that both sentences are fed into the network, which causes a massive computational overhead: Finding the most similar pair in a collection of 10,000 sentences requires about 50 million inference computations ({\~{}}65 hours) with BERT. The construction of BERT makes it unsuitable for semantic similarity search as well as for unsupervised tasks like clustering. In this publication, we present Sentence-BERT (SBERT), a modification of the pretrained BERT network that use siamese and triplet network structures to derive semantically meaningful sentence embeddings that can be compared using cosine-similarity. This reduces the effort for finding the most similar pair from 65 hours with BERT / RoBERTa to about 5 seconds with SBERT, while maintaining the accuracy from BERT. We evaluate SBERT and SRoBERTa on common STS tasks and transfer learning tasks, where it outperforms other state-of-the-art sentence embeddings methods.},
archivePrefix = {arXiv},
arxivId = {1908.10084},
author = {Reimers, Nils and Gurevych, Iryna},
doi = {10.18653/v1/d19-1410},
eprint = {1908.10084},
file = {:home/theritacosta/Desktop/botbuilder{\_}project/reading/1908.10084.pdf:pdf},
isbn = {9781950737901},
journal = {EMNLP-IJCNLP 2019 - 2019 Conference on Empirical Methods in Natural Language Processing and 9th International Joint Conference on Natural Language Processing, Proceedings of the Conference},
pages = {3982--3992},
title = {{Sentence-BERT: Sentence embeddings using siamese BERT-networks}},
year = {2020}
}
@inproceedings{Zhang2018,
abstract = {Chit-chat models are known to have several problems: they lack specificity, do not display a consistent personality and are often not very captivating. In this work we present the task of making chit-chat more engaging by conditioning on profile information. We collect data and train models to (i) condition on their given profile information; and (ii) information about the person they are talking to, resulting in improved dialogues, as measured by next utterance prediction. Since (ii) is initially unknown, our model is trained to engage its partner with personal topics, and we show the resulting dialogue can be used to predict profile information about the interlocutors.},
author = {Zhang, Saizheng and Dinan, Emily and Urbanek, Jack and Szlam, Arthur and Kiela, Douwe and Weston, Jason},
booktitle = {Proc. of the Annual Meeting of the Association for Computational Linguistics},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhang et al. - 2018 - Personalizing Dialogue Agents I have a dog, do you have pets too.pdf:pdf},
title = {{Personalizing Dialogue Agents: I have a dog, do you have pets too?}},
year = {2018}
}
@inproceedings{Papineni2002,
author = {Papineni, Kishore and Roukos, Salim and Ward, Todd and Zu, Wei-Jing},
booktitle = {Proc. of the Annual Meeting on Association for Computational Linguistics},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Papineni et al. - 2002 - BLEU A Method for Automatic Evaluation of Machine Translation.pdf:pdf},
title = {{BLEU: A Method for Automatic Evaluation of Machine Translation}},
year = {2002}
}
@article{Lemon2002,
abstract = {We explain dialogue management techniques for collaborative activities with humans , involving multiple concurrent tasks. Conversational context for multiple concurrent activities is represented using a "Dialogue Move Tree" and an "Activity Tree" which support multiple interleaved threads of dialogue about different activities and their execution status. We also describe the incremental message selection, aggregation, and generation method employed in the system.},
author = {Lemon, Oliver and Gruenstein, Alexander and Battle, Alexis and Peters, Stanley},
doi = {10.3115/1118121.1118137},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lemon et al. - 2002 - Multi-tasking and collaborative activities in dialogue systems.pdf:pdf},
number = {July},
pages = {113--124},
title = {{Multi-tasking and collaborative activities in dialogue systems}},
year = {2002}
}
@article{Dalton2019,
archivePrefix = {arXiv},
arxivId = {arXiv:2003.13624v1},
author = {Dalton, Jeffrey and Xiong, Chenyan and Callan, Jamie},
eprint = {arXiv:2003.13624v1},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Dalton, Xiong, Callan - 2020 - CAsT 2019 The Conversational Assistance Track Overview.pdf:pdf},
title = {{CAsT 2019: The Conversational Assistance Track Overview}},
year = {2020}
}
@inproceedings{Budzianowski2019,
abstract = {Even though machine learning has become the major scene in dialogue research community, the real breakthrough has been blocked by the scale of data available. To address this fundamental obstacle, we introduce the Multi-Domain Wizard-of-Oz dataset (MultiWOZ), a fully-labeled collection of human-human written conversations spanning over multiple domains and topics. At a size of {\$}10{\$}k dialogues, it is at least one order of magnitude larger than all previous annotated task-oriented corpora. The contribution of this work apart from the open-sourced dataset labelled with dialogue belief states and dialogue actions is two-fold: firstly, a detailed description of the data collection procedure along with a summary of data structure and analysis is provided. The proposed data-collection pipeline is entirely based on crowd-sourcing without the need of hiring professional annotators; secondly, a set of benchmark results of belief tracking, dialogue act and response generation is reported, which shows the usability of the data and sets a baseline for future studies.},
author = {Budzianowski, Pawe{\l} and Wen, Tsung-hsien Hsien and Tseng, Bo-Hsiang and Casanueva, I{\~{n}}igo and Ultes, Stefan and Ramadan, Osman and Ga{\v{s}}i{\'{c}}, Milica},
booktitle = {Proc. of the Conference on Empirical Methods in Natural Language Processing},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Budzianowski et al. - 2019 - MultiWOZ - A Large-Scale Multi-Domain Wizard-of-Oz Dataset for Task-Oriented Dialogue Modelling.pdf:pdf},
title = {{MultiWOZ - A Large-Scale Multi-Domain Wizard-of-Oz Dataset for Task-Oriented Dialogue Modelling}},
year = {2018}
}
@article{Lin2020,
abstract = {The goal of text ranking is to generate an ordered list of texts retrieved from a corpus in response to a query for a particular task. Although the most common formulation of text ranking is search, instances of the task can also be found in many natural language processing applications. This survey provides an overview of text ranking with neural network architectures known as transformers, of which BERT is the best-known example. The combination of transformers and self-supervised pretraining has, without exaggeration, revolutionized the fields of natural language processing (NLP), information retrieval (IR), and beyond. In the context of text ranking, these models produce high quality results across many domains, tasks, and settings. In this survey, we provide a synthesis of existing work as a single point of entry for practitioners who wish to gain a better understanding of how to apply transformers to text ranking problems and researchers who wish to pursue work in this area. We cover a wide range of modern techniques, grouped into two high-level categories: transformer models that perform reranking in multi-stage ranking architectures and learned dense representations that attempt to perform ranking directly. There are numerous examples that fall into the first category, including approaches based on relevance classification, evidence aggregation from multiple segments of text, corpus analysis, and sequence-to-sequence models. While the second category of approaches is less well studied, representation learning with transformers is an emerging and exciting direction that is bound to attract more attention moving forward. There are two themes that pervade our survey: techniques for handling long documents, beyond the typical sentence-by-sentence processing approaches used in NLP, and techniques for addressing the tradeoff between effectiveness (result quality) and efficiency (query latency). Although transformer architectures and pretraining techniques are recent innovations, many aspects of how they are applied to text ranking are relatively well understood and represent mature techniques. However, there remain many open research questions, and thus in addition to laying out the foundations of pretrained transformers for text ranking, this survey also attempts to prognosticate where the field is heading.},
archivePrefix = {arXiv},
arxivId = {2010.06467},
author = {Lin, Jimmy and Nogueira, Rodrigo and Yates, Andrew},
eprint = {2010.06467},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lin, Nogueira, Yates - 2020 - Pretrained Transformers for Text Ranking BERT and Beyond.pdf:pdf},
issn = {23318422},
journal = {arXiv},
title = {{Pretrained Transformers for Text Ranking: BERT and Beyond}},
year = {2020}
}
@book{Kokoska2000,
author = {Kokoska, Stephen and Zwillinger, Daniel},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kokoska, Zwillinger - 2000 - CRC Standard Probability and Statistics Tables and Formulae.pdf:pdf},
isbn = {9781482273847},
title = {{CRC Standard Probability and Statistics Tables and Formulae}},
year = {2000}
}
@article{Weizenbaum1966,
abstract = {The inclusion of computer-based assemblies into man-machine complexes has enhanced the relevance of characteristics of the human link in the system. In particular, the virtues and limitations for transmission of information among the physical subsystems through a human channel is an important consideration in systems design. The current status of the supporting research for this area is briefly summarized. The related but more recondite area covering communication between man and computer is also important to the effectiveness of man-machine complexes. However, supporting research for this area is meager and most of it is contained in engineering psychology studies pertinent to the needs of specific systems. Research facilities more appropriate for the exploratory needs of both areas are becoming available and these presage the broad intensive programs needed to provide research guidance to the systems design of man-machine complexes. Copyright {\textcopyright} 1962 by The Institute of Radio Engineers, Inc.},
author = {Weizenbaum, Joseph},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Weizenbaum - 1966 - ELIZA - A Computer Program For the Study of Natural Language Communication Between Man And Machine.pdf:pdf},
journal = {Communications of the ACM},
keywords = {2,3,4,5,a discussion of some,and,capability for eliza,context,editing,generation of responses in,of appropriate transformations,psychologi-,scripts,the absence of key,the choice,the discovery of minimal,the provision of an,words},
title = {{ELIZA - A Computer Program For the Study of Natural Language Communication Between Man And Machine}},
volume = {9},
year = {1966}
}
@article{Wolf2019a,
abstract = {Recent progress in natural language processing has been driven by advances in both model architecture and model pretraining. Transformer architectures have facilitated building higher-capacity models and pretraining has made it possible to effectively utilize this capacity for a wide variety of tasks. $\backslash$textit{\{}Transformers{\}} is an open-source library with the goal of opening up these advances to the wider machine learning community. The library consists of carefully engineered state-of-the art Transformer architectures under a unified API. Backing this library is a curated collection of pretrained models made by and available for the community. $\backslash$textit{\{}Transformers{\}} is designed to be extensible by researchers, simple for practitioners, and fast and robust in industrial deployments. The library is available at $\backslash$url{\{}https://github.com/huggingface/transformers{\}}.},
archivePrefix = {arXiv},
arxivId = {1910.03771},
author = {Wolf, Thomas and Debut, Lysandre and Sanh, Victor and Chaumond, Julien and Delangue, Clement and Moi, Anthony and Cistac, Pierric and Rault, Tim and Louf, R{\'{e}}mi and Funtowicz, Morgan and Davison, Joe and Shleifer, Sam and von Platen, Patrick and Ma, Clara and Jernite, Yacine and Plu, Julien and Xu, Canwen and Scao, Teven Le and Gugger, Sylvain and Drame, Mariama and Lhoest, Quentin and Rush, Alexander M.},
eprint = {1910.03771},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wolf et al. - 2019 - HuggingFace's Transformers State-of-the-art Natural Language Processing.pdf:pdf},
title = {{HuggingFace's Transformers: State-of-the-art Natural Language Processing}},
url = {http://arxiv.org/abs/1910.03771},
year = {2019}
}
@article{Keneshloo2020,
abstract = {In recent times, sequence-to-sequence (seq2seq) models have gained a lot of popularity and provide state-of-the-art performance in a wide variety of tasks, such as machine translation, headline generation, text summarization, speech-to-text conversion, and image caption generation. The underlying framework for all these models is usually a deep neural network comprising an encoder and a decoder. Although simple encoder-decoder models produce competitive results, many researchers have proposed additional improvements over these seq2seq models, e.g., using an attention-based model over the input, pointer-generation models, and self-attention models. However, such seq2seq models suffer from two common problems: 1) exposure bias and 2) inconsistency between train/test measurement. Recently, a completely novel point of view has emerged in addressing these two problems in seq2seq models, leveraging methods from reinforcement learning (RL). In this survey, we consider seq2seq problems from the RL point of view and provide a formulation combining the power of RL methods in decision-making with seq2seq models that enable remembering long-term memories. We present some of the most recent frameworks that combine the concepts from RL and deep neural networks. Our work aims to provide insights into some of the problems that inherently arise with current approaches and how we can address them with better RL models. We also provide the source code for implementing most of the RL models discussed in this paper to support the complex task of abstractive text summarization and provide some targeted experiments for these RL models, both in terms of performance and training time.},
archivePrefix = {arXiv},
arxivId = {1805.09461},
author = {Keneshloo, Yaser and Shi, Tian and Ramakrishnan, Naren and Reddy, Chandan K.},
doi = {10.1109/TNNLS.2019.2929141},
eprint = {1805.09461},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Keneshloo et al. - 2020 - Deep Reinforcement Learning for Sequence-to-Sequence Models(2).pdf:pdf},
issn = {21622388},
journal = {IEEE Transactions on Neural Networks and Learning Systems},
keywords = {Actor critic (AC) methods,Q-learning,deep learning,policy gradients (PGs),reinforcement learning (RL),sequence-to-sequence (seq2seq) learning},
number = {7},
pages = {2469--2489},
pmid = {31425057},
title = {{Deep Reinforcement Learning for Sequence-to-Sequence Models}},
volume = {31},
year = {2020}
}
@article{Lin2020a,
abstract = {Passage retrieval in a conversational context is essential for many downstream applications; it is however extremely challenging due to limited data resources. To address this problem, we present an effective multi-stage pipeline for passage ranking in conversational search that integrates a widely-used IR system with a conversational query reformulation module. Along these lines, we propose two simple yet effective query reformulation approaches: historical query expansion (HQE) and neural transfer reformulation (NTR). Whereas HQE applies query expansion, a traditional IR query reformulation technique, NTR transfers human knowledge of conversational query understanding to a neural query reformulation model. The proposed HQE method was the top-performing submission of automatic systems in CAsT Track at TREC 2019. Building on this, our NTR approach improves an additional 18{\%} over that best entry in terms of NDCG@3. We further analyze the distinct behaviors of the two approaches, and show that fusing their output reduces the performance gap (measured in NDCG@3) between the manually-rewritten and automatically-generated queries to 4 from 22 points when compared with the best CAsT submission.},
archivePrefix = {arXiv},
arxivId = {2005.02230},
author = {Lin, Sheng-Chieh and Yang, Jheng-Hong and Nogueira, Rodrigo and Tsai, Ming-Feng and Wang, Chuan-Ju and Lin, Jimmy},
eprint = {2005.02230},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lin et al. - 2020 - Query Reformulation using Query History for Passage Retrieval in Conversational Search.pdf:pdf},
issn = {23318422},
journal = {arXiv},
title = {{Query Reformulation using Query History for Passage Retrieval in Conversational Search}},
year = {2020}
}
@book{Renkema2012,
author = {Renkema, Jan},
edition = {5 edition},
title = {{Schrijfwijzer}},
year = {2012}
}
@article{Bengio2003,
author = {Bengio, Yoshua and Ducharme, R{\'{e}}jean and Vincent, Pascal and Jauvin, Christian},
editor = {Leen, T and Dietterich, T and Tresp, V},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bengio et al. - 2003 - A Neural Probabilistic Language Model.pdf:pdf},
journal = {Journal of Machine Learning Research},
pages = {1137--1155},
publisher = {MIT Press},
title = {{A Neural Probabilistic Language Model}},
volume = {3},
year = {2003}
}
@inproceedings{Takanobu2020,
abstract = {There is a growing interest in developing goal-oriented dialog systems which serve users in accomplishing complex tasks through multi-turn conversations. Although many methods are devised to evaluate and improve the performance of individual dialog components, there is a lack of comprehensive empirical study on how different components contribute to the overall performance of a dialog system. In this paper, we perform a system-wise evaluation and present an empirical analysis on different types of dialog systems which are composed of different modules in different settings. Our results show that (1) a pipeline dialog system trained using fine-grained supervision signals at different component levels often obtains better performance than the systems that use joint or end-to-end models trained on coarse-grained labels, (2) component-wise, single-turn evaluation results are not always consistent with the overall performance of a dialog system, and (3) despite the discrepancy between simulators and human users, simulated evaluation is still a valid alternative to the costly human evaluation especially in the early stage of development.},
author = {Takanobu, Ryuichi and Zhu, Qi and Li, Jinchao and Peng, Baolin and Gao, Jianfeng and Huang, Minlie},
booktitle = {Proc. of the Annual Meeting of the Special Interest Group on Discourse and Dialogue},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Takanobu et al. - 2020 - Is Your Goal-Oriented Dialog Model Performing Really Well Empirical Analysis of System-wise Evaluation.pdf:pdf},
title = {{Is Your Goal-Oriented Dialog Model Performing Really Well? Empirical Analysis of System-wise Evaluation}},
year = {2020}
}
@article{Perkins2019,
abstract = {We introduce the dialog intent induction task and present a novel deep multi-view clustering approach to tackle the problem. Dialog intent induction aims at discovering user intents from user query utterances in human-human conversations such as dialogs between customer support agents and customers.1 Motivated by the intuition that a dialog intent is not only expressed in the user query utterance but also captured in the rest of the dialog, we split a conversation into two independent views and exploit multi-view clustering techniques for inducing the dialog intent. In particular, we propose alternating-view k-means (AV-KMEANS) for joint multi-view representation learning and clustering analysis. The key innovation is that the instance-view representations are updated iteratively by predicting the cluster assignment obtained from the alternative view, so that the multi-view representations of the instances lead to similar cluster assignments. Experiments on two public datasets show that AV-KMEANS can induce better dialog intent clusters than state-of-the-art unsupervised representation learning methods and standard multi-view clustering approaches.2},
author = {Perkins, Hugh and Yang, Yi},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Perkins, Yang - 2019 - Dialog Intent Induction with Deep Multi-View Clustering.pdf:pdf},
issn = {23318422},
journal = {arXiv},
pages = {4016--4025},
title = {{Dialog Intent Induction with Deep Multi-View Clustering}},
year = {2019}
}
@inproceedings{Golovanov2019,
abstract = {Large-scale pretrained language models define state of the art in natural language processing, achieving outstanding performance on a variety of tasks. We study how these architectures can be applied and adapted for natural language generation, comparing a number of architectural and training schemes. We focus in particular on open-domain dialog as a typical high entropy generation task, presenting and comparing different architectures for adapting pretrained models with state of the art results.},
author = {Golovanov, Sergey and Kurbanov, Rauf and Nikolenko, Sergey and Truskovskyi, Kyryl and Tselousov, Alexander and Wolf, Thomas},
booktitle = {Proc. of the Annual Meeting of the Association for Computational Linguistics},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Golovanov et al. - 2019 - Large-Scale Transfer Learning for Natural Language Generation.pdf:pdf},
title = {{Large-Scale Transfer Learning for Natural Language Generation}},
year = {2019}
}
@article{Sennrich2016,
abstract = {Neural machine translation (NMT) models typically operate with a fixed vocabulary, but translation is an open-vocabulary problem. Previous work addresses the translation of out-of-vocabulary words by backing off to a dictionary. In this paper, we introduce a simpler and more effective approach, making the NMT model capable of open-vocabulary translation by encoding rare and unknown words as sequences of subword units. This is based on the intuition that various word classes are translatable via smaller units than words, for instance names (via character copying or transliteration), compounds (via compositional translation), and cognates and loanwords (via phonological and morphological transformations). We discuss the suitability of different word segmentation techniques, including simple character ngram models and a segmentation based on the byte pair encoding compression algorithm, and empirically show that subword models improve over a back-off dictionary baseline for the WMT 15 translation tasks English→German and English→Russian by up to 1.1 and 1.3 Bleu, respectively.},
author = {Sennrich, Rico and Haddow, Barry and Birch, Alexandra},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sennrich, Haddow, Birch - 2016 - Neural Machine Translation of Rare Words with Subword Units.pdf:pdf},
journal = {Proc. of the Annual Meeting of the Association for Computational Linguistics},
title = {{Neural Machine Translation of Rare Words with Subword Units}},
year = {2016}
}
@article{Luong2015,
abstract = {An attentional mechanism has lately been used to improve neural machine translation (NMT) by selectively focusing on parts of the source sentence during translation. However, there has been little work exploring useful architectures for attention-based NMT. This paper examines two simple and effective classes of attentional mechanism: a global approach which always attends to all source words and a local one that only looks at a subset of source words at a time. We demonstrate the effectiveness of both approaches on the WMT translation tasks between English and German in both directions. With local attention, we achieve a significant gain of 5.0 BLEU points over non-attentional systems that already incorporate known techniques such as dropout. Our ensemble model using different attention architectures yields a new state-of-the-art result in the WMT'15 English to German translation task with 25.9 BLEU points, an improvement of 1.0 BLEU points over the existing best system backed by NMT and an n-gram reranker.},
archivePrefix = {arXiv},
arxivId = {1508.04025},
author = {Luong, Minh Thang and Pham, Hieu and Manning, Christopher D.},
doi = {10.18653/v1/d15-1166},
eprint = {1508.04025},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Luong, Pham, Manning - 2015 - Effective approaches to attention-based neural machine translation.pdf:pdf},
isbn = {9781941643327},
journal = {Conference Proceedings - EMNLP 2015: Conference on Empirical Methods in Natural Language Processing},
pages = {1412--1421},
title = {{Effective approaches to attention-based neural machine translation}},
year = {2015}
}
@article{Roller2020,
abstract = {Building open-domain chatbots is a challenging area for machine learning research. While prior work has shown that scaling neural models in the number of parameters and the size of the data they are trained on gives improved results, we show that other ingredients are important for a high-performing chatbot. Good conversation requires a number of skills that an expert conversationalist blends in a seamless way: providing engaging talking points and listening to their partners, and displaying knowledge, empathy and personality appropriately, while maintaining a consistent persona. We show that large scale models can learn these skills when given appropriate training data and choice of generation strategy. We build variants of these recipes with 90M, 2.7B and 9.4B parameter models, and make our models and code publicly available under the collective name Blender. Human evaluations show our best models are superior to existing approaches in multi-turn dialogue in terms of engagingness and humanness measurements. We then discuss the limitations of this work by analyzing failure cases of our models.},
archivePrefix = {arXiv},
arxivId = {2004.13637},
author = {Roller, Stephen and Dinan, Emily and Goyal, Naman and Ju, Da and Williamson, Mary and Liu, Yinhan and Xu, Jing and Ott, Myle and Shuster, Kurt and Smith, Eric M. and Boureau, Y-Lan and Weston, Jason},
eprint = {2004.13637},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Roller et al. - 2020 - Recipes for building an open-domain chatbot.pdf:pdf},
title = {{Recipes for building an open-domain chatbot}},
url = {http://arxiv.org/abs/2004.13637},
year = {2020}
}
@article{Li2016,
abstract = {Sequence-to-sequence neural network models for generation of conversational responses tend to generate safe, commonplace responses (e.g., I don't know) regardless of the input. We suggest that the traditional objective function, i.e., the likelihood of output (response) given input (message) is unsuited to response generation tasks. Instead we propose using Maximum Mutual Information (MMI) as the objective function in neural models. Experimental results demonstrate that the proposed MMI models produce more diverse, interesting, and appropriate responses, yielding substantive gains in BLEU scores on two conversational datasets and in human evaluations.},
archivePrefix = {arXiv},
arxivId = {1510.03055},
author = {Li, Jiwei and Galley, Michel and Brockett, Chris and Gao, Jianfeng and Dolan, Bill},
doi = {10.18653/v1/n16-1014},
eprint = {1510.03055},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Li et al. - 2016 - A diversity-promoting objective function for neural conversation models.pdf:pdf},
isbn = {9781941643914},
journal = {2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL HLT 2016 - Proceedings of the Conference},
pages = {110--119},
title = {{A diversity-promoting objective function for neural conversation models}},
year = {2016}
}
@techreport{Gaizauskas,
author = {Gaizauskas, Rob and Law, James and Barker, Emma},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gaizauskas, Law, Barker - 2018 - Investigating Spoken Dialogue to Support Manufacturing Processes.pdf:pdf},
institution = {University of Sheffield},
title = {{Investigating Spoken Dialogue to Support Manufacturing Processes}},
year = {2018}
}
@article{Pei2001,
abstract = {Sequential pattern mining is an important data mining problem with broad applications. It is challenging since one may need to examine a combinatorially explosive number of possible subsequence patterns. Most of the previously developed sequential pattern mining methods follow the methodology of Apriori which may substantially reduce the number of combinations to be examined. However Apriori still encounters problems when a sequence database is large and/or when sequential patterns to be mined are numerous and/or long. In this paper, we propose a novel sequential pattern mining method, called PrefixSpan (i.e., Prefix-projected Sequential pattern mining), which explores prefix-projection in sequential pattern mining. PrefixSpan mines the complete set of patterns but greatly reduces the efforts of candidate subsequence generation. Moreover, prefix-projection substantially reduces the size of projected databases and leads to efficient processing. Our performance study shows that PrefixSpan outperforms both the Apriori-based GSP algorithm and another recently proposed method, FreeSpan, in mining large sequence databases.},
author = {Pei, J. and Han, J. and Mortazavi-Asl, B. and Pinto, H. and Chen, Q. and Dayal, U. and Hsu, M. C.},
doi = {10.1109/icde.2001.914830},
file = {:home/theritacosta/Desktop/botbuilder{\_}project/reading/span01.pdf:pdf},
journal = {Proceedings - International Conference on Data Engineering},
pages = {215--224},
title = {{PrefixSpan: Mining sequential patterns efficiently by prefix-projected pattern growth}},
year = {2001}
}
@article{Hochreiter1997,
author = {Hochreiter, Sepp and Schmidhuber, J{\"{u}}rgen},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hochreiter, Schmidhuber - 1997 - Long Short-Term Memory.pdf:pdf},
journal = {Neural Computation},
pages = {1735--1780},
title = {{Long Short-Term Memory}},
volume = {9},
year = {1997}
}
@inproceedings{Gao2018,
abstract = {This tutorial surveys neural approaches to conversational AI that were developed in the last few years. We group conversational systems into three categories: (1) question answering agents, (2) task-oriented dialogue agents, and (3) social bots. For each category, we present a review of state-of-the-art neural approaches, draw the connection between neural approaches and traditional symbolic approaches, and discuss the progress we have made and challenges we are facing, using specific systems and models as case studies.},
author = {Gao, Jianfeng and Galley, Michel and Li, Lihong},
booktitle = {Proc. of the Annual Meeting of the Association for Computational Linguistics},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gao, Galley, Li - 2018 - Neural Approaches to Conversational AI.pdf:pdf},
title = {{Neural Approaches to Conversational AI}},
year = {2018}
}
@article{Ghaemi2019,
abstract = {Extracting the latent knowledge from Twitter by applying spatial clustering on geotagged tweets provides the ability to discover events and their locations. DBSCAN (density-based spatial clustering of applications with noise), which has been widely used to retrieve events from geotagged tweets, cannot efficiently detect clusters when there is significant spatial heterogeneity in the dataset, as it is the case for Twitter data where the distribution of users, as well as the intensity of publishing tweets, varies over the study areas. This study proposes VDCT (Varied Density-based spatial Clustering for Twitter data) algorithm that extracts clusters from geotagged tweets by considering spatial heterogeneity. The algorithm employs exponential spline interpolation to determine different search radiuses for cluster detection. Moreover, in addition to spatial proximity, textual similarities among tweets are also taken into account by the algorithm. In order to examine the efficiency of the algorithm, geotagged tweets collected during a hurricane in the United States were used for event detection. The output clusters of VDCT have been compared to those of DBSCAN. Visual and quantitative comparison of the results proved the feasibility of the proposed method.},
author = {Ghaemi, Zeinab and Farnaghi, Mahdi},
doi = {10.3390/ijgi8020082},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ghaemi, Farnaghi - 2019 - A Varied Density-based Clustering Approach for Event Detection from Heterogeneous Twitter Data.pdf:pdf},
issn = {22209964},
journal = {ISPRS International Journal of Geo-Information},
keywords = {Density-based clustering,Spatial clustering,Spatial heterogeneity,Text Similarity,Twitter},
number = {2},
pages = {1--18},
title = {{A Varied Density-based Clustering Approach for Event Detection from Heterogeneous Twitter Data}},
volume = {8},
year = {2019}
}
@inproceedings{Hashimoto2019,
author = {Hashimoto, Tatsunori B and Zhang, Hugh and Liang, Percy},
booktitle = {Proc. of the Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hashimoto, Zhang, Liang - 2019 - Unifying Human and Statistical Evaluation for Natural Language Generation.pdf:pdf},
title = {{Unifying Human and Statistical Evaluation for Natural Language Generation}},
year = {2019}
}
@article{Yasunaga2021,
abstract = {The problem of answering questions using knowledge from pre-trained language models (LMs) and knowledge graphs (KGs) presents two challenges: given a QA context (question and answer choice), methods need to (i) identify relevant knowledge from large KGs, and (ii) perform joint reasoning over the QA context and KG. Here we propose a new model, QA-GNN, which addresses the above challenges through two key innovations: (i) relevance scoring, where we use LMs to estimate the importance of KG nodes relative to the given QA context, and (ii) joint reasoning, where we connect the QA context and KG to form a joint graph, and mutually update their representations through graph-based message passing. We evaluate QA-GNN on the CommonsenseQA and OpenBookQA datasets, and show its improvement over existing LM and LM+KG models, as well as its capability to perform interpretable and structured reasoning, e.g., correctly handling negation in questions.},
archivePrefix = {arXiv},
arxivId = {2104.06378},
author = {Yasunaga, Michihiro and Ren, Hongyu and Bosselut, Antoine and Liang, Percy and Leskovec, Jure},
eprint = {2104.06378},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yasunaga et al. - 2021 - QA-GNN Reasoning with Language Models and Knowledge Graphs for Question Answering.pdf:pdf},
title = {{QA-GNN: Reasoning with Language Models and Knowledge Graphs for Question Answering}},
url = {http://arxiv.org/abs/2104.06378},
year = {2021}
}
@inproceedings{Bahdanau2015,
abstract = {Neural machine translation is a recently proposed approach to machine translation. Unlike the traditional statistical machine translation, the neural machine translation aims at building a single neural network that can be jointly tuned to maximize the translation performance. The models proposed recently for neural machine translation often belong to a family of encoder–decoders and encode a source sentence into a fixed-length vector from which a decoder generates a translation. In this paper, we conjecture that the use of a fixed-length vector is a bottleneck in improving the performance of this basic encoder–decoder architecture, and propose to extend this by allowing a model to automatically (soft-)search for parts of a source sentence that are relevant to predicting a target word, without having to form these parts as a hard segment explicitly. With this new approach, we achieve a translation performance comparable to the existing state-of-the-art phrase-based system on the task of English-to-French translation. Furthermore, qualitative analysis reveals that the (soft-)alignments found by the model agree well with our intuition.},
author = {Bahdanau, Dzmitry and Cho, Kyung Hyun and Bengio, Yoshua},
booktitle = {Proc. of the International Conference on Learning Representations},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bahdanau, Cho, Bengio - 2015 - Neural Machine Translation by Jointly Learning to Align and Translate.pdf:pdf},
title = {{Neural Machine Translation by Jointly Learning to Align and Translate}},
year = {2015}
}
@article{Hornik1989,
abstract = {This paper rigorously establishes that standard multilayer feedforward networks with as few as one hidden layer using arbitrary squashing functions are capable of approximating any Borel measurable function from one finite dimensional space to another to any desired degree of accuracy, provided sufficiently many hidden units are available. In this sense, multilayer feedforward networks are a class of universal approximators. {\textcopyright} 1989.},
author = {Hornik, Kurt and Stinchcombe, Maxwell and White, Halbert},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hornik, Stinchcombe, White - 1989 - Multilayer Feedforward Networks are Universal Approximators.pdf:pdf},
journal = {Neural Networks},
keywords = {Back-propagation networks,Feedforward networks,Mapping networks,Network representation capability,Sigma-Pi networks,Squashing functions,Stone-Weierstrass Theorem,Universal approximation},
pages = {359--366},
title = {{Multilayer Feedforward Networks are Universal Approximators}},
volume = {2},
year = {1989}
}
@article{Hao2020,
abstract = {The task of dialogue rewriting aims to reconstruct the latest dialogue utterance by copying the missing content from the dialogue context. Until now, the existing models for this task suffer from the robustness issue, i.e., performances drop dramatically when testing on a different domain. We address this robustness issue by proposing a novel sequence-tagging-based model so that the search space is significantly reduced, yet the core of this task is still well covered. As a common issue of most tagging models for text generation, the model's outputs may lack fluency. To alleviate this issue, we inject the loss signal from BLEU or GPT-2 under a REINFORCE framework. Experiments show huge improvements of our model over the current state-of-the-art systems on domain transfer.},
archivePrefix = {arXiv},
arxivId = {2012.14535},
author = {Hao, Jie and Song, Linfeng and Wang, Liwei and Xu, Kun and Tu, Zhaopeng and Yu, Dong},
eprint = {2012.14535},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hao et al. - 2020 - Robust Dialogue Utterance Rewriting as Sequence Tagging.pdf:pdf},
title = {{Robust Dialogue Utterance Rewriting as Sequence Tagging}},
url = {http://arxiv.org/abs/2012.14535},
volume = {4},
year = {2020}
}
@book{Goldberg2017,
abstract = {Neural networks are a family of powerful machine learning models. This book focuses on the application of neural network models to natural language data. The first half of the book (Parts I and II) covers the basics of supervised machine learning and feed-forward neural networks, the basics of working with machine learning over language data, and the use of vector-based rather than symbolic representations for words. It also covers the computation-graph abstraction, which allows to easily define and train arbitrary neural networks, and is the basis behind the design of contemporary neural network software libraries. The second part of the book (Parts III and IV) introduces more specialized neural network architectures, including 1D convolutional neural networks, recurrent neural networks, conditioned-generation models, and attention-based models. These architectures and techniques are the driving force behind state-of-the-art algorithms for machine translation, syntactic parsing, and many other applications. Finally, we also discuss tree-shaped networks, structured prediction, and the prospects of multi-task learning.},
author = {Goldberg, Yoav},
booktitle = {Synthesis Lectures on Human Language Technologies},
doi = {10.2200/S00762ED1V01Y201703HLT037},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Goldberg - 2017 - Neural Network Methods for Natural Language Processing.pdf:pdf},
isbn = {9781627052986},
issn = {19474040},
keywords = {deep learning,machine learning,natural language processing,neural networks,recurrent neural networks,sequence to sequence models,supervised learning,word embeddings},
number = {1},
pages = {1--311},
title = {{Neural Network Methods for Natural Language Processing}},
volume = {10},
year = {2017}
}
@article{Srivastava2014a,
author = {Srivastava, Nitish and Hinton, Geoffrey and Krizhevsky, Alex and Sutskever, Ilya and Salakhutdinov, Ruslan},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Srivastava et al. - 2014 - Dropout A Simple Way to Prevent Neural Networks from Overfitting.pdf:pdf},
issn = {03702693},
journal = {Journal of Machine Learning Research},
number = {56},
pages = {1929--1958},
title = {{Dropout: A Simple Way to Prevent Neural Networks from Overfitting}},
url = {http://jmlr.org/papers/v15/srivastava14a.html},
volume = {15},
year = {2014}
}
@inproceedings{Martins2020,
author = {Martins, Pedro Henrique and Marinho, Zita and Martins, Andr{\'{e}} F. T.},
booktitle = {Proc. of the Conference on Empirical Methods in Natural Language Processing},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Martins, Marinho, Martins - 2020 - Sparse Text Generation.pdf:pdf},
title = {{Sparse Text Generation}},
year = {2020}
}
@article{McInnes2017,
abstract = {We present an accelerated algorithm for hierarchical density based clustering. Our new algorithm improves upon HDBSCAN∗, which itself provided a significant qualitative improvement over the popular DBSCAN algorithm. The accelerated HDBSCAN∗ algorithm provides comparable performance to DBSCAN, while supporting variable density clusters, and eliminating the need for the difficult to tune distance scale parameter epsilon. This makes accelerated HDBSCAN∗ the default choice for density based clustering.},
author = {McInnes, Leland and Healy, John},
doi = {10.1109/ICDMW.2017.12},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/McInnes, Healy - 2017 - Accelerated Hierarchical Density Based Clustering.pdf:pdf},
isbn = {9781538614808},
issn = {23759259},
journal = {IEEE International Conference on Data Mining Workshops, ICDMW},
keywords = {Clustering,Density based clustering,Hierarchical clustering},
pages = {33--42},
title = {{Accelerated Hierarchical Density Based Clustering}},
volume = {2017-Novem},
year = {2017}
}
@inproceedings{Henderson2019,
abstract = {Despite their popularity in the chatbot literature, retrieval-based models have had modest impact on task-oriented dialogue systems, with the main obstacle to their application being the low-data regime of most task-oriented dialogue tasks. Inspired by the recent success of pretraining in language modelling, we propose an effective method for deploying response selection in task-oriented dialogue. To train response selection models for task-oriented dialogue tasks, we propose a novel method which: 1) pretrains the response selection model on large general-domain conversational corpora; and then 2) fine-tunes the pretrained model for the target dialogue domain, relying only on the small in-domain dataset to capture the nuances of the given dialogue domain. Our evaluation on six diverse application domains, ranging from e-commerce to banking, demonstrates the effectiveness of the proposed training method.},
author = {Henderson, Matthew and Vuli{\'{c}}, Ivan and Gerz, Daniela and Casanueva, I{\~{n}}igo and Budzianowski, Pawe{\l} and Coope, Sam and Spithourakis, Georgios and Wen, Tsung-Hsien and Mrk{\v{s}}i{\'{c}}, Nikola and Su, Pei-Hao},
booktitle = {Proc. of the Annual Meeting of the Association for Computational Linguistics},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Henderson et al. - 2019 - Training Neural Response Selection for Task-Oriented Dialogue Systems.pdf:pdf},
title = {{Training Neural Response Selection for Task-Oriented Dialogue Systems}},
year = {2019}
}
@article{Gupta2020,
abstract = {Task oriented dialog systems typically first parse user utterances to semantic frames comprised of intents and slots. Previous work on task oriented intent and slot-filling work has been restricted to one intent per query and one slot label per token, and thus cannot model complex compositional requests. Alternative semantic parsing systems have represented queries as logical forms, but these are challenging to annotate and parse. We propose a hierarchical annotation scheme for semantic parsing that allows the representation of compositional queries, and can be efficiently and accurately parsed by standard constituency parsing models. We release a dataset of 44k annotated queries 1, and show that parsing models outperform sequence-to-sequence approaches on this dataset.},
archivePrefix = {arXiv},
arxivId = {1810.07942},
author = {Gupta, Sonal and Shah, Rushin and Mohit, Mrinal and Kumar, Anuj and Lewis, Michael},
doi = {10.18653/v1/d18-1300},
eprint = {1810.07942},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gupta et al. - 2020 - Semantic Parsing for Task Oriented Dialog using Hierarchical Representations.pdf:pdf},
isbn = {9781948087841},
journal = {Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, EMNLP 2018},
pages = {2787--2792},
title = {{Semantic Parsing for Task Oriented Dialog using Hierarchical Representations}},
year = {2020}
}
@article{Lewis2017,
abstract = {Future robotic agents may be required to reason about a given situation and decide whether it is appropriate to lie to or deceive humans. One type of deception, known formally as strategic deception, is the act of influencing others toward a specific goal through non-truths. To demonstrate and test for the kind of reasoning required in strategic deception, we use a modified form of the social strategy game "Mafia" as a testing ground. In the game, the townsfolk, who can be seen as an uninformed majority, must determine who amongst themselves are members of the informed minority (the Mafia) via social cues before the Mafia eliminate all the townsfolk. First, we talk about how strategic deception applies to Mafia. We then present simplified rules for the game which can be formalized into a logic-based language. Once formalized, the rules can be provided to an automated theorem prover, which can carry out the necessary reasoning. By using this automated theorem prover we discuss how one can demonstrate automated strategic deception.},
author = {Lewis, Brad and Smith, Isaac and Fowler, Max and Licato, John},
doi = {10.1145/1235},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lewis et al. - 2017 - Query Intent Detection using Convolutional Neural Networks.pdf:pdf},
isbn = {9781450321389},
journal = {28th Modern Artificial Intelligence and Cognitive Science Conference, MAICS 2017},
keywords = {Robots,Social Games,Strategic Deception},
pages = {189--190},
title = {{Query Intent Detection using Convolutional Neural Networks}},
year = {2017}
}
@article{Keen2018,
abstract = {We propose sparsemax, a new activation function similar to the traditional softmax, but able to output sparse probabilities. After deriving its properties, we show how its Jacobian can be efficiently computed, enabling its use in a network trained with backpropagation. Then, we propose a new smooth and convex loss function which is the sparsemax analogue of the logistic loss. We reveal an unexpected connection between this new loss and the Huber classification loss. We obtain promising empirical results in multi-label classification problems and in attention-based neural networks for natural language inference. For the latter, we achieve a similar performance as the traditional softmax, but with a selective, more compact, attention focus.},
author = {Keen, Antony. G.},
doi = {10.1163/9789004351523},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Keen - 2018 - Dynastic Lycia.pdf:pdf},
journal = {Dynastic Lycia},
title = {{Dynastic Lycia}},
volume = {48},
year = {2018}
}
@article{Cohen1960,
abstract = {A coefficient of interjudge agreement for nominal scales, formula-omitted, is presented. It is directly interpretable as the pro-portion of joint judgments in which there is agreement, after chance agreement is excluded. Its upper limit is +1.00, and its lower limit falls between zero and -1.00, depending on the distribution of judgments by the two judges. The maximum value which x can take for any given problem is given, and the implications of this value to the question of agreement discussed. An interesting characteristic of x is its identity with 0 in the dichotomous case when the judges give the same marginal distributions. Finally, its standard error and techniques for estimation and hypothesis testing are presented. {\textcopyright} 1960, Sage Publications. All rights reserved.},
author = {Cohen, Jacob},
doi = {10.1177/001316446002000104},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cohen - 1960 - A Coefficient of Agreement for Nominal Scales.pdf:pdf},
issn = {15523888},
journal = {Educational and Psychological Measurement},
number = {1},
pages = {37--46},
title = {{A Coefficient of Agreement for Nominal Scales}},
volume = {20},
year = {1960}
}
@article{Zhao2019,
abstract = {Defining action spaces for conversational agents and optimizing their decision-making process with reinforcement learning is an enduring challenge. Common practice has been to use handcrafted dialog acts, or the output vocabulary, e.g. in neural encoder decoders, as the action spaces. Both have their own limitations. This paper proposes a novel latent action framework that treats the action spaces of an end-to-end dialog agent as latent variables and develops unsupervised methods in order to induce its own action space from the data. Comprehensive experiments are conducted examining both continuous and discrete action types and two different optimization methods based on stochastic variational inference. Results show that the proposed latent actions achieve superior empirical performance improvement over previous word-level policy gradient methods on both DealOrNoDeal and MultiWoz dialogs. Our detailed analysis also provides insights about various latent variable approaches for policy learning and can serve as a foundation for developing better latent actions in future research.},
archivePrefix = {arXiv},
arxivId = {1902.08858},
author = {Zhao, Tiancheng and Xie, Kaige and Eskenazi, Maxine},
doi = {10.18653/v1/n19-1123},
eprint = {1902.08858},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhao, Xie, Eskenazi - 2019 - Rethinking Action Spaces for Reinforcement Learning in End-to-end Dialog Agents with Latent Variable Mod(2).pdf:pdf},
pages = {1208--1218},
title = {{Rethinking Action Spaces for Reinforcement Learning in End-to-end Dialog Agents with Latent Variable Models}},
year = {2019}
}
@article{Liu2019a,
abstract = {Spoken language understanding is an important part of the human-machine dialogue system, intent detection is a sub-task of spoken language understanding, and it is very important. The accuracy of intent detection is directly related to the performance of semantic slot filling, and it is helpful to the following research of the dialogue system. Considering the difficulty of intent detection in human-machine dialogue system, the traditional machine learning method cannot understand the deep semantic information of user's discourse. This paper mainly analyzes, compares and summarizes the deep learning methods applied in the research of intent detection in recent years, and further considers how to apply deep learning model to multi-intent detection task, so as to promote the research of multi-intent detection methods based on deep neural network.},
author = {Liu, Jiao and Li, Yanling and Lin, Min},
doi = {10.1088/1742-6596/1267/1/012059},
file = {:home/theritacosta/Desktop/botbuilder{\_}project/reading/Liu{\_}2019{\_}J.{\_}Phys.{\_}{\_}Conf.{\_}Ser.{\_}1267{\_}012059.pdf:pdf},
issn = {17426596},
journal = {Journal of Physics: Conference Series},
number = {1},
title = {{Review of Intent Detection Methods in the Human-Machine Dialogue System}},
volume = {1267},
year = {2019}
}
@inproceedings{Bonial2019,
abstract = {In this research, we begin to tackle the challenge of natural language understanding (NLU) in the context of the development of a robot dialogue system. We explore the adequacy of Abstract Meaning Representation (AMR) as a conduit for NLU. First, we consider the feasibility of using existing AMR parsers for automatically creating meaning representations for robot-directed transcribed speech data. We evaluate the quality of output of two parsers on this data against a manually annotated gold-standard data set. Second, we evaluate the semantic coverage and distinctions made in AMR overall: how well does it capture the meaning and distinctions needed in our collaborative human-robot dialogue do-main? We find that AMR has gaps that align with linguistic information critical for effective human-robot collaboration in search and navigation tasks, and we present task-specific modifications to AMR to address the deficiencies .},
author = {Bonial, Claire and Donatelli, Lucia and Ervin, Jessica and Voss, Clare R.},
booktitle = {Proc. of the Society for Computation in Linguistics},
doi = {10.18653/v1/w19-3322},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bonial et al. - 2019 - Abstract Meaning Representation for Human-Robot Dialogue.pdf:pdf},
title = {{Abstract Meaning Representation for Human-Robot Dialogue}},
year = {2019}
}
@article{Gao2020,
abstract = {Recent progress in deep learning has brought tremendous improvements in conversational AI, leading to a plethora of commercial conversational services that allow naturally spoken interactions, increasing the need for more human-centric interactions in IR. As a result, we have witnessed a resurgent interest in developing modern CIR systems in research communities and industry. This tutorial presents recent advances in CIR, focusing mainly on neural approaches and new applications developed in the past five years. Our goal is to provide a thorough and in-depth overview of the general definition of CIR, the components of CIR systems, new applications raised for its conversational aspects, and the (neural) techniques recently developed for it.},
author = {Gao, Jianfeng and Xiong, Chenyan and Bennett, Paul},
doi = {10.1145/3397271.3401418},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gao, Xiong, Bennett - 2020 - Recent Advances in Conversational Information Retrieval.pdf:pdf},
isbn = {9781450380164},
journal = {SIGIR 2020 - Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval},
keywords = {conversational information retrieval,conversational search},
pages = {2421--2424},
title = {{Recent Advances in Conversational Information Retrieval}},
year = {2020}
}
@article{Pappagari2019,
abstract = {BERT, which stands for Bidirectional Encoder Representations from Transformers, is a recently introduced language representation model based upon the transfer learning paradigm. We extend its fine-Tuning procedure to address one of its major limitations-applicability to inputs longer than a few hundred words, such as transcripts of human call conversations. Our method is conceptually simple. We segment the input into smaller chunks and feed each of them into the base model. Then, we propagate each output through a single recurrent layer, or another transformer, followed by a softmax activation. We obtain the final classification decision after the last segment has been consumed. We show that both BERT extensions are quick to fine-Tune and converge after as little as 1 epoch of training on a small, domain-specific data set. We successfully apply them in three different tasks involving customer call satisfaction prediction and topic classification, and obtain a significant improvement over the baseline models in two of them.},
archivePrefix = {arXiv},
arxivId = {1910.10781},
author = {Pappagari, Raghavendra and Zelasko, Piotr and Villalba, Jesus and Carmiel, Yishay and Dehak, Najim},
doi = {10.1109/ASRU46091.2019.9003958},
eprint = {1910.10781},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Pappagari et al. - 2019 - Hierarchical Transformers for Long Document Classification(2).pdf:pdf},
isbn = {9781728103068},
journal = {2019 IEEE Automatic Speech Recognition and Understanding Workshop, ASRU 2019 - Proceedings},
keywords = {BERT,Customer Satisfaction Prediction,Recurrent Neural Networks,Topic Identification,Transformer},
pages = {838--844},
title = {{Hierarchical Transformers for Long Document Classification}},
year = {2019}
}
@article{Chen2017a,
abstract = {Until recently, the goal of developing open-domain dialogue systems that not only emulate hu-man conversation but fulfill complex tasks, such as travel planning, seemed elusive. However, we start to observe promising results in the last few years as the large amount of conversation data is available for training and the breakthroughs in deep learning and reinforcement learning are ap-plied to dialogue. In this tutorial, we start with a brief introduction to the history of dialogue re-search. Then, we describe in detail the deep learn-ing and reinforcement learning technologies that have been developed for two types of dialogue systems. First is a task-oriented dialogue system that can help users accomplish tasks, ranging from meeting scheduling to vacation planning. Second is a social bot that can converse seamlessly and appropriately with humans. In the final part of the tutorial, we review attempts to developing open-domain neural dialogue systems by combining the strengths of task-oriented dialogue systems and social bots. The tutorial material is available at},
author = {Chen, Yun-Nung and Gao, Jianfeng},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chen, Gao - 2017 - Open-Domain Neural Dialogue Systems.pdf:pdf},
journal = {Afnlp},
pages = {6--10},
title = {{Open-Domain Neural Dialogue Systems}},
year = {2017}
}
@inproceedings{Kondadadi2013,
abstract = {We present a hybrid natural language generation (NLG) system that consolidates macro and micro planning and surface realization tasks into one statistical learning process. Our novel approach is based on deriving a template bank automatically from a corpus of texts from a target domain. First, we identify domain specific entity tags and Discourse Representation Structures on a per sentence basis. Each sentence is then organized into semantically similar groups (representing a domain specific concept) by k-means clustering. After this semi-automatic processing (human review of cluster assignments), a number of corpus-level statistics are compiled and used as features by a ranking SVM to develop model weights from a training corpus. At generation time, a set of input data, the collection of semantically organized templates, and the model weights are used to select optimal templates. Our system is evaluated with automatic, non-expert crowdsourced and expert evaluation metrics. We also introduce a novel automatic metric - syntactic variability - that represents linguistic variation as a measure of unique template sequences across a collection of automatically generated documents. The metrics for generated weather and biography texts fall within acceptable ranges. In sum, we argue that our statistical approach to NLG reduces the need for complicated knowledge-based architectures and readily adapts to different domains with reduced development time. {\textcopyright} 2013 Association for Computational Linguistics.},
author = {Kondadadi, Ravi and Howald, Blake and Schilder, Frank},
booktitle = {Proc. of the Annual Meeting of the Association for Computational Linguistics},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kondadadi, Howald, Schilder - 2013 - A Statistical NLG Framework for Aggregated Planning and Realization.pdf:pdf},
title = {{A Statistical NLG Framework for Aggregated Planning and Realization}},
year = {2013}
}
@inproceedings{Wu2019,
abstract = {Over-dependence on domain ontology and lack of knowledge sharing across domains are two practical and yet less studied problems of dialogue state tracking. Existing approaches generally fall short in tracking unknown slot values during inference and often have difficulties in adapting to new domains. In this paper, we propose a Transferable Dialogue State Generator (TRADE) that generates dialogue states from utterances using a copy mechanism, facilitating knowledge transfer when predicting (domain, slot, value) triplets not encountered during training. Our model is composed of an utterance encoder, a slot gate, and a state generator, which are shared across domains. Empirical results demonstrate that TRADE achieves state-of-the-art joint goal accuracy of 48.62{\%} for the five domains of MultiWOZ, a human-human dialogue dataset. In addition, we show its transferring ability by simulating zero-shot and few-shot dialogue state tracking for unseen domains. TRADE achieves 60.58{\%} joint goal accuracy in one of the zero-shot domains, and is able to adapt to few-shot cases without forgetting already trained domains.},
author = {Wu, Chien-Sheng and Madotto, Andrea and Hosseini-Asl, Ehsan and Xiong, Caiming and Socher, Richard and Fung, Pascale},
booktitle = {Proc. of the Annual Meeting of the Association for Computational Linguistics},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wu et al. - 2019 - Transferable Multi-Domain State Generator for Task-Oriented Dialogue Systems.pdf:pdf},
title = {{Transferable Multi-Domain State Generator for Task-Oriented Dialogue Systems}},
year = {2019}
}
@article{Li2017a,
abstract = {Language understanding is a key component in a spoken dialogue system. In this paper, we investigate how the language understanding module influences the dialogue system performance by conducting a series of systematic experiments on a task-oriented neural dialogue system in a reinforcement learning based setting. The empirical study shows that among different types of language understanding errors, slot-level errors can have more impact on the overall performance of a dialogue system compared to intent-level errors. In addition, our experiments demonstrate that the reinforcement learning based dialogue system is able to learn when and what to confirm in order to achieve better performance and greater robustness.},
archivePrefix = {arXiv},
arxivId = {1703.07055},
author = {Li, Xiujun and Chen, Yun Nung and Li, Lihong and Gao, Jianfeng and Celikyilmaz, Asli},
eprint = {1703.07055},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Li et al. - 2017 - Investigation of language understanding impact for reinforcement learning based dialogue systems.pdf:pdf},
issn = {23318422},
journal = {arXiv},
keywords = {Policy learning,Reinforcement learning,Spoken language understanding,Task-completion dialogue},
title = {{Investigation of language understanding impact for reinforcement learning based dialogue systems}},
year = {2017}
}
@article{Dosovitskiy2020,
abstract = {While the Transformer architecture has become the de-facto standard for natural language processing tasks, its applications to computer vision remain limited. In vision, attention is either applied in conjunction with convolutional networks, or used to replace certain components of convolutional networks while keeping their overall structure in place. We show that this reliance on CNNs is not necessary and a pure transformer applied directly to sequences of image patches can perform very well on image classification tasks. When pre-trained on large amounts of data and transferred to multiple mid-sized or small image recognition benchmarks (ImageNet, CIFAR-100, VTAB, etc.), Vision Transformer (ViT) attains excellent results compared to state-of-the-art convolutional networks while requiring substantially fewer computational resources to train.},
archivePrefix = {arXiv},
arxivId = {2010.11929},
author = {Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and Uszkoreit, Jakob and Houlsby, Neil},
eprint = {2010.11929},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Dosovitskiy et al. - 2020 - An Image is Worth 16x16 Words Transformers for Image Recognition at Scale.pdf:pdf},
title = {{An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale}},
url = {http://arxiv.org/abs/2010.11929},
year = {2020}
}
@article{PanYang2010,
abstract = {A major assumption in many machine learning and data mining algorithms is that the training and future data must be in the same feature space and have the same distribution. However, in many real-world applications, this assumption may not hold. For example, we sometimes have a classification task in one domain of interest, but we only have sufficient training data in another domain of interest, where the latter data may be in a different feature space or follow a different data distribution. In such cases, knowledge transfer, if done successfully, would greatly improve the performance of learning by avoiding much expensive data labeling efforts. In recent years, transfer learning has emerged as a new learning framework to address this problem. This survey focuses on categorizing and reviewing the current progress on transfer learning for classification, regression and clustering problems. In this survey, we discuss the relationship between transfer learning and other related machine learning techniques such as domain adaptation, multi- task learning and sample selection bias, as well as co-variate shift. We also explore some potential future issues in transfer learning research.},
author = {Pan, Sinno Jialin and Yang, Qiang},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Pan, Yang - 2010 - A Survey on Transfer Learning.pdf:pdf},
journal = {IEEE Transactions on Knowledge and Data Engineering},
keywords = {Data Mining,Machine Learning,Survey,Transfer Learning},
pages = {1345--1359},
title = {{A Survey on Transfer Learning}},
volume = {22},
year = {2010}
}
@book{Jurafsky2008,
author = {Jurafsky, Daniel and Martin, James},
edition = {3rd},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Jurafsky, Martin - 2019 - Speech and Language Processing An Introduction to Natural Language Processing, Computational Linguistics and S.pdf:pdf},
title = {{Speech and Language Processing: An Introduction to Natural Language Processing, Computational Linguistics and Speech Recognition}},
year = {2019}
}
@article{Hori2019,
abstract = {This paper describes the experimental setups and the evaluation results of the sixth Dialog System Technology Challenges (DSTC6) aiming to develop end-to-end dialogue systems. Neural network models have become a recent focus of investigation in dialogue technologies. Previous models required training data to be manually annotated with word meanings and dialogue states, but end-to-end neural network dialogue systems learn to directly output natural-language system responses without needing training data to be manually annotated. Thus, this approach allows us to scale up the size of training data and cover more dialog domains. In addition, dialogue systems require a meta-function to avoid deploying inappropriate responses generated by themselves. To challenge such issues, the DSTC6 consists of three tracks, (1). End-to-End Goal Oriented dialogue Learning to select system responses, (2). End-to-End Conversation Modeling to generate system responses using Natural Language Generation (NLG) and (3). Dialogue Breakdown Detection. Since each domain has different issues to be addressed to develop dialogue systems, we targeted restaurant retrieval dialogues to fill slot-value in Track 1, customer services on Twitter by combining goal-oriented dialogues and ChitChat in Track 2 and human-machine dialogue data for ChitChat in Track 3. DSTC6 had 141 people declaring their interests and 23 teams submitted their final results. 18 scientific papers were presented in the wrap-up workshop. We find the blending end-to-end trainable models associated to meaningful prior knowledge performs the best for the restaurant retrieval for Track 1. Indeed, Hybrid Code Network and Memory Network have been the best models for this task. In Track 2, 78.5{\%} of the system responses automatically generated by the best system were rated better than acceptable by humans and this achieves 89{\%} of the number of the human responses rated in the same class. In Track3, the dialogue breakdown detection technologies performed as well as human agreements, in both data-sets of English and Japanese.},
archivePrefix = {arXiv},
arxivId = {2011.06486},
author = {Hori, Chiori and Perez, Julien and Higashinaka, Ryuichiro and Hori, Takaaki and Boureau, Y. Lan and Inaba, Michimasa and Tsunomori, Yuiko and Takahashi, Tetsuro and Yoshino, Koichiro and Kim, Seokhwan},
doi = {10.1016/j.csl.2018.09.004},
eprint = {2011.06486},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hori et al. - 2019 - Overview of the Ninth Dialog System Technology Challenge DSTC9.pdf:pdf},
issn = {10958363},
journal = {Computer Speech and Language},
keywords = {Conversation model,DSTC,Dialogue breakdown,End-to-end dialogue system,Natural Language Generation,Sequence-to-sequence model},
pages = {1--25},
title = {{Overview of the Ninth Dialog System Technology Challenge: DSTC9}},
volume = {55},
year = {2019}
}
@article{Zhang2017,
abstract = {Multi-Task Learning (MTL) is a learning paradigm in machine learning and its aim is to leverage useful information contained in multiple related tasks to help improve the generalization performance of all the tasks. In this paper, we give a survey for MTL. First, we classify different MTL algorithms into several categories, including feature learning approach, low-rank approach, task clustering approach, task relation learning approach, and decomposition approach, and then discuss the characteristics of each approach. In order to improve the performance of learning tasks further, MTL can be combined with other learning paradigms including semi-supervised learning, active learning, unsupervised learning, reinforcement learning, multi-view learning and graphical models. When the number of tasks is large or the data dimensionality is high, batch MTL models are difficult to handle this situation and online, parallel and distributed MTL models as well as dimensionality reduction and feature hashing are reviewed to reveal their computational and storage advantages. Many real-world applications use MTL to boost their performance and we review representative works. Finally, we present theoretical analyses and discuss several future directions for MTL.},
archivePrefix = {arXiv},
arxivId = {1707.08114},
author = {Zhang, Yu and Yang, Qiang},
eprint = {1707.08114},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhang, Yang - 2017 - A Survey on Multi-Task Learning.pdf:pdf},
pages = {1--20},
title = {{A Survey on Multi-Task Learning}},
url = {http://arxiv.org/abs/1707.08114},
year = {2017}
}
@article{Humeau2019,
abstract = {The use of deep pre-trained bidirectional transformers has led to remarkable progress in a number of applications (Devlin et al., 2018). For tasks that make pairwise comparisons between sequences, matching a given input with a corresponding label, two approaches are common: Cross-encoders performing full self-attention over the pair and Bi-encoders encoding the pair separately. The former often performs better, but is too slow for practical use. In this work, we develop a new transformer architecture, the Poly-encoder, that learns global rather than token level self-attention features. We perform a detailed comparison of all three approaches, including what pre-training and fine-tuning strategies work best. We show our models achieve state-of-the-art results on three existing tasks; that Poly-encoders are faster than Cross-encoders and more accurate than Bi-encoders; and that the best results are obtained by pre-training on large datasets similar to the downstream tasks.},
archivePrefix = {arXiv},
arxivId = {1905.01969},
author = {Humeau, Samuel and Shuster, Kurt and Lachaux, Marie-Anne and Weston, Jason},
eprint = {1905.01969},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Humeau et al. - 2019 - Poly-encoders Transformer Architectures and Pre-training Strategies for Fast and Accurate Multi-sentence Scoring.pdf:pdf},
pages = {1--13},
title = {{Poly-encoders: Transformer Architectures and Pre-training Strategies for Fast and Accurate Multi-sentence Scoring}},
url = {http://arxiv.org/abs/1905.01969},
year = {2019}
}
@inproceedings{Serban2017,
abstract = {Sequential data often possesses hierarchical structures with complex dependencies between sub-sequences, such as found between the utterances in a dialogue. To model these dependencies in a generative framework, we propose a neural network-based generative architecture, with stochastic latent variables that span a variable number of time steps. We apply the proposed model to the task of dialogue response generation and compare it with other recent neural-network architectures. We evaluate the model performance through a human evaluation study. The experiments demonstrate that our model improves upon recently proposed models and that the latent variables facilitate both the generation of meaningful, long and diverse responses and maintaining dialogue state.},
archivePrefix = {arXiv},
arxivId = {arXiv:1605.06069v3},
author = {Serban, Iulian Vlad and Sordoni, Alessandro and Lowe, Ryan and Charlin, Laurent and Pineau, Joelle and Courville, Aaron and Bengio, Yoshua},
booktitle = {Proc. of the AAAI Conference on Artificial Intelligence},
eprint = {arXiv:1605.06069v3},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Serban et al. - 2016 - A Hierarchical Latent Variable Encoder-Decoder Model for Generating Dialogues.pdf:pdf},
pages = {3295--3301},
title = {{A Hierarchical Latent Variable Encoder-Decoder Model for Generating Dialogues}},
year = {2016}
}
@article{Mitra2019,
abstract = {Classical information retrieval (IR) methods, such as query likelihood and BM25, score documents independently w.r.t. each query term, and then accumulate the scores. Assuming query term independence allows precomputing term-document scores using these models - which can be combined with specialized data structures, such as inverted index, for efficient retrieval. Deep neural IR models, in contrast, compare the whole query to the document and are, therefore, typically employed only for late stage re-ranking. We incorporate query term independence assumption into three state-of-the-art neural IR models: BERT, Duet, and CKNRM - and evaluate their performance on a passage ranking task. Surprisingly, we observe no significant loss in result quality for Duet and CKNRM - and a small degradation in the case of BERT. However, by operating on each query term independently, these otherwise computationally intensive models become amenable to offline precomputation - dramatically reducing the cost of query evaluations employing state-ofthe-art neural ranking models. This strategy makes it practical to use deep models for retrieval from large collections - and not restrict their usage to late stage re-ranking.},
archivePrefix = {arXiv},
arxivId = {1907.03693},
author = {Mitra, Bhaskar and Rosset, Corby and Hawking, David and Craswell, Nick and Diaz, Fernando and Yilmaz, Emine},
eprint = {1907.03693},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mitra et al. - 2019 - Incorporating query term independence assumption for efficient retrieval and ranking using deep neural networks.pdf:pdf},
issn = {23318422},
journal = {arXiv},
keywords = {Deep learning,Indexing,Information retrieval,Query evaluation},
title = {{Incorporating query term independence assumption for efficient retrieval and ranking using deep neural networks}},
year = {2019}
}
@article{Xu2000,
abstract = {Language modeling for speech recognizer in dialog systems can take two forms. Human input can be constrained through a directed dialog, allowing the decoder to use a state-specific language model to improve recognition accuracy. Mixedinitiative systems allow for human input that while domainspecific might not be state-specific. Nevertheless, for the most part human input to a mixed-initiative system is predictable, particularly when given information about the immediately preceding system prompt. The work reported in this paper addresses the problem of balancing state-specific and general language modeling in a mixed-initiative dialog system. By incorporating dialog state adaptation of the language model, we have reduced the recognition error rate by 11.5{\%}.},
author = {Xu, Wei and Rudnicky, Alex},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Xu, Rudnicky - 2000 - Language modeling for dialog system.pdf:pdf},
isbn = {7801501144},
journal = {6th International Conference on Spoken Language Processing, ICSLP 2000},
pages = {118--121},
title = {{Language modeling for dialog system}},
year = {2000}
}
@inproceedings{Devlin2018,
abstract = {We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models, BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5{\%} (7.7{\%} point absolute improvement), MultiNLI accuracy to 86.7{\%} (4.6{\%} absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement).},
author = {Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
booktitle = {Proc. of the Conference of the North American Chapter of the Association for Computational Linguistics},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Devlin et al. - 2019 - BERT Pre-training of Deep Bidirectional Transformers for Language Understanding.pdf:pdf},
title = {{BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding}},
year = {2019}
}
@article{Solaiman2019,
abstract = {Large language models have a range of beneficial uses: they can assist in prose, poetry, and programming; analyze dataset biases; and more. However, their flexibility and generative capabilities also raise misuse concerns. This report discusses OpenAI's work related to the release of its GPT-2 language model. It discusses staged release, which allows time between model releases to conduct risk and benefit analyses as model sizes increased. It also discusses ongoing partnership-based research and provides recommendations for better coordination and responsible publication in AI.},
archivePrefix = {arXiv},
arxivId = {1908.09203},
author = {Solaiman, Irene and Brundage, Miles and Clark, Jack and Askell, Amanda and Herbert-Voss, Ariel and Wu, Jeff and Radford, Alec and Wang, Jasmine},
eprint = {1908.09203},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Solaiman et al. - 2019 - Release Strategies and the Social Impacts of Language Models.pdf:pdf},
title = {{Release Strategies and the Social Impacts of Language Models}},
url = {http://arxiv.org/abs/1908.09203},
year = {2019}
}
@article{Pandey2018,
abstract = {In this paper we present the Exemplar Encoder-Decoder network (EED), a novel conversation model that learns to utilize similar examples from training data to generate responses. Similar conversation examples (context-response pairs) from training data are retrieved using a traditional TF-IDF based retrieval model. The retrieved responses are used to create exemplar vectors that are used by the decoder to generate the response. The contribution of each retrieved response is weighed by the similarity of corresponding context with the input context. We present detailed experiments on two large data sets and find that our method outperforms state of the art sequence to sequence generative models on several recently proposed evaluation metrics. We also observe that the responses generated by the proposed EED model are more informative and diverse compared to existing state-of-the-art method.},
author = {Pandey, Gaurav and Contractor, Danish and Kumar, Vineet and Joshi, Sachindra},
doi = {10.18653/v1/p18-1123},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Pandey et al. - 2018 - Exemplar encoder-decoder for neural conversation generation.pdf:pdf},
isbn = {9781948087322},
journal = {ACL 2018 - 56th Annual Meeting of the Association for Computational Linguistics, Proceedings of the Conference (Long Papers)},
pages = {1329--1338},
title = {{Exemplar encoder-decoder for neural conversation generation}},
volume = {1},
year = {2018}
}
@article{Gao2020a,
author = {Gao, Jianfeng and Xiong, Chenyan and Bennett, Paul},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gao, Xiong, Bennett - 2020 - Recent Advances in Conversational Information Retrieval ( CIR ) - A review of neural approaches.pdf:pdf},
title = {{Recent Advances in Conversational Information Retrieval ( CIR ) - A review of neural approaches}},
volume = {2020},
year = {2020}
}
@article{Yao2013,
abstract = {Recurrent Neural Network Language Models (RNN-LMs) have recently shown exceptional performance across a variety of applications. In this paper, we modify the architecture to perform Language Understanding, and advance the state-of-the-art for the widely used ATIS dataset. The core of our approach is to take words as input as in a standard RNN-LM, and then to predict slot labels rather than words on the output side. We present several variations that differ in the amount of word context that is used on the input side, and in the use of non-lexical features. Remarkably, our simplest model produces state-of-the-art results, and we advance state-of-the-art through the use of bagof- words, word embedding, named-entity, syntactic, and wordclass features. Analysis indicates that the superior performance is attributable to the task-specific word representations learned by the RNN. Copyright {\textcopyright} 2013 ISCA.},
author = {Yao, Kaisheng and Zweig, Geoffrey and Hwang, Mei Yuh and Shi, Yangyang and Yu, Dong},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yao et al. - 2013 - Recurrent Neural Networks for Language Understanding.pdf:pdf},
issn = {19909772},
journal = {Proceedings of the Annual Conference of the International Speech Communication Association, INTERSPEECH},
keywords = {Recurrent neural networks,Spoken language understanding},
number = {1},
pages = {2524--2528},
title = {{Recurrent Neural Networks for Language Understanding}},
year = {2013}
}
@article{Amidei2019,
abstract = {Rating and Likert scales are widely used in evaluation experiments to measure the quality of Natural Language Generation (NLG) systems. We review the use of rating and Likert scales for NLG evaluation tasks published in NLG specialized conferences over the last ten years (135 papers in total). Our analysis brings to light a number of deviations from good practice in their use. We conclude with some recommendations about the use of such scales. Our aim is to encourage the appropriate use of evaluation methodologies in the NLG community.},
author = {Amidei, Jacopo and Piwek, Paul and Willis, Alistair and Keynes, Milton},
doi = {10.18653/v1/W19-8648},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Amidei et al. - 2019 - The use of rating and Likert scales in Natural Language Generation human evaluation tasks A review and some reco.pdf:pdf},
journal = {Proceedings of the 12th International Conference on Natural Language Generation},
pages = {397--402},
title = {{The use of rating and Likert scales in Natural Language Generation human evaluation tasks : A review and some recommendations}},
url = {https://www.aclweb.org/anthology/W19-8648},
year = {2019}
}
@article{Sharma2017,
abstract = {Automated metrics such as BLEU are widely used in the machine translation literature. They have also been used recently in the dialogue community for evaluating dialogue response generation. However, previous work in dialogue response generation has shown that these metrics do not correlate strongly with human judgment in the non task-oriented dialogue setting. Task-oriented dialogue responses are expressed on narrower domains and exhibit lower diversity. It is thus reasonable to think that these automated metrics would correlate well with human judgment in the task-oriented setting where the generation task consists of translating dialogue acts into a sentence. We conduct an empirical study to confirm whether this is the case. Our findings indicate that these automated metrics have stronger correlation with human judgments in the task-oriented setting compared to what has been observed in the non task-oriented setting. We also observe that these metrics correlate even better for datasets which provide multiple ground truth reference sentences. In addition, we show that some of the currently available corpora for task-oriented language generation can be solved with simple models and advocate for more challenging datasets.},
author = {Sharma, Shikhar and Asri, Layla El and Schulz, Hannes and Zumer, Jeremie},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sharma et al. - 2017 - Relevance of Unsupervised Metrics in Task-Oriented Dialogue for Evaluating Natural Language Generation.pdf:pdf},
title = {{Relevance of Unsupervised Metrics in Task-Oriented Dialogue for Evaluating Natural Language Generation}},
url = {http://arxiv.org/abs/1706.09799},
year = {2017}
}
@inproceedings{Paulus2018,
abstract = {Attentional, RNN-based encoder-decoder models for abstractive summarization have achieved good performance on short input and output sequences. For longer documents and summaries however these models often include repetitive and incoherent phrases. We introduce a neural network model with a novel intra-attention that attends over the input and continuously generated output separately, and a new training method that combines standard supervised word prediction and reinforcement learning (RL). Models trained only with supervised learning often exhibit “exposure bias” – they assume ground truth is provided at each step during training. However, when standard word prediction is combined with the global sequence prediction training of RL the resulting summaries become more readable. We evaluate this model on the CNN/Daily Mail and New York Times datasets. Our model obtains a 41.16 ROUGE-1 score on the CNN/Daily Mail dataset, an improvement over previous state-of-the-art models. Human evaluation also shows that our model produces higher quality summaries.},
archivePrefix = {arXiv},
arxivId = {1705.04304},
author = {Paulus, Romain and Xiong, Caiming and Socher, Richard},
booktitle = {6th International Conference on Learning Representations, ICLR 2018},
eprint = {1705.04304},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Paulus, Xiong, Socher - 2018 - A Deep Reinforced Model for Abstractive Summarization(2).pdf:pdf},
number = {i},
pages = {1--12},
title = {{A Deep Reinforced Model for Abstractive Summarization}},
year = {2018}
}
@article{Radford2018,
abstract = {We introduce a new type of deep contextualized word representation that models both (1) complex characteristics of word use (e.g., syntax and semantics), and (2) how these uses vary across linguistic contexts (i.e., to model polysemy). Our word vectors are learned functions of the internal states of a deep bidirectional language model (biLM), which is pre-trained on a large text corpus. We show that these representations can be easily added to existing models and significantly improve the state of the art across six challenging NLP problems, including question answering, textual entailment and sentiment analysis. We also present an analysis showing that exposing the deep internals of the pre-trained network is crucial, allowing downstream models to mix different types of semi-supervision signals.},
author = {Radford, Alec and Salimans, Tim},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Radford, Salimans - 2018 - Improving Language Understanding by Generative Pre-Training.pdf:pdf},
journal = {OpenAI Blog},
title = {{Improving Language Understanding by Generative Pre-Training}},
url = {https://openai.com/blog/language-unsupervised/},
year = {2018}
}
@inproceedings{Yu2020,
abstract = {Conversational query rewriting aims to reformulate a concise conversational query to a fully specified, context-independent query that can be effectively handled by existing information retrieval systems. This paper presents a few-shot generative approach to conversational query rewriting. We develop two methods, based on rules and self-supervised learning, to generate weak supervision data using large amounts of ad hoc search sessions, and to fine-tune GPT-2 to rewrite conversational queries. On the TREC Conversational Assistance Track, our weakly supervised GPT-2 rewriter improves the state-of-the-art ranking accuracy by 12{\%}, only using very limited amounts of manual query rewrites. In the zero-shot learning setting, the rewriter still gives a comparable result to previous state-of-the-art systems. Our analyses reveal that GPT-2 effectively picks up the task syntax and learns to capture context dependencies, even for hard cases that involve group references and long-turn dependencies.},
archivePrefix = {arXiv},
arxivId = {2006.05009},
author = {Yu, Shi and Liu, Jiahua and Yang, Jingqin and Xiong, Chenyan and Bennett, Paul and Gao, Jianfeng and Liu, Zhiyuan},
booktitle = {43rd International ACM SIGIR Conference on Research and Development in Information Retrieval},
doi = {10.1145/3397271.3401323},
eprint = {2006.05009},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yu et al. - 2020 - Few-Shot Generative Conversational Query Rewriting.pdf:pdf},
isbn = {9781450380164},
keywords = {conversational search,few-shot learning,query rewriting},
pages = {1933--1936},
title = {{Few-Shot Generative Conversational Query Rewriting}},
year = {2020}
}
@inproceedings{Zhang2019,
abstract = {We propose BERTScore, an automatic evaluation metric for text generation. Analogously to common metrics, BERTScore computes a similarity score for each token in the candidate sentence with each token in the reference sentence. However, instead of exact matches, we compute token similarity using contextual embeddings. We evaluate using the outputs of 363 machine translation and image captioning systems. BERTScore correlates better with human judgments and provides stronger model selection performance than existing metrics. Finally, we use an adversarial paraphrase detection task to show that BERTScore is more robust to challenging examples when compared to existing metrics.},
author = {Zhang, Tianyi and Kishore, Varsha and Wu, Felix and Weinberger, Kilian Q. and Artzi, Yoav},
booktitle = {Proc. of the International Conference on Learning Representations},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhang et al. - 2020 - BERTScore Evaluating Text Generation with BERT.pdf:pdf},
title = {{BERTScore: Evaluating Text Generation with BERT}},
year = {2020}
}
@article{Pang2020,
abstract = {Open-domain dialogue generation has gained increasing attention in Natural Language Processing. Its evaluation requires a holistic means. Human ratings are deemed as the gold standard. As human evaluation is inefficient and costly, an automated substitute is highly desirable. In this paper, we propose holis-tic evaluation metrics that capture different aspects of open-domain dialogues. Our metrics consist of (1) GPT-2 based context coherence between sentences in a dialogue, (2) GPT-2 based fluency in phrasing, (3) n-gram based diversity in responses to augmented queries, and (4) textual-entailment-inference based logical self-consistency. The empirical validity of our metrics is demonstrated by strong correlations with human judgments. We open source the code and relevant materials. 1},
author = {Pang, Bo and Nijkamp, Erik and Han, Wenjuan and Zhou, Linqi and Liu, Yixian and Tu, Kewei},
doi = {10.18653/v1/2020.acl-main.333},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Pang et al. - 2020 - Towards Holistic and Automatic Evaluation of Open-Domain Dialogue Generation.pdf:pdf},
pages = {3619--3629},
title = {{Towards Holistic and Automatic Evaluation of Open-Domain Dialogue Generation}},
year = {2020}
}
@inproceedings{Mikolov2013,
abstract = {Methods based on representation learning currently hold the state-of-the-art in many natural language processing and knowledge base inference tasks. Yet, a major challenge is how to efficiently incorporate commonsense knowledge into such models. A recent approach regularizes relation and entity representations by propositionalization of first-order logic rules. However, propositionalization does not scale beyond domains with only few entities and rules. In this paper we present a highly efficient method for incorporating implication rules into distributed representations for automated knowledge base construction. We map entity-tuple embeddings into an approximately Boolean space and encourage a partial ordering over relation embeddings based on implication rules mined from WordNet. Surprisingly, we find that the strong restriction of the entity-tuple embedding space does not hurt the expressiveness of the model and even acts as a regularizer that improves generalization. By incorporating few commonsense rules, we achieve an increase of 2 percentage points mean average precision over a matrix factorization baseline, while observing a negligible increase in runtime.},
author = {Mikolov, Tomas and Sutskever, Ilya and Chen, Kai and Corrado, Greg S and Dean, Jeff},
booktitle = {Proc. of the International Conference on Neural Information Processing Systems},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mikolov et al. - 2013 - Distributed Representations of Words and Phrases and their Compositionality.pdf:pdf},
title = {{Distributed Representations of Words and Phrases and their Compositionality}},
year = {2013}
}
@inproceedings{VanDerLee2019,
author = {{Van Der Lee}, Chris and Gatt, Albert and van Miltenburg, Emiel and Wubben, Sander and Krahmer, Emiel},
booktitle = {Proc. of the International Conference on Natural Language Generation},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Van Der Lee et al. - 2019 - Best Practices for the Human Evaluation of Automatically Generated Text.pdf:pdf},
title = {{Best Practices for the Human Evaluation of Automatically Generated Text}},
year = {2019}
}
@article{Campello2015,
abstract = {An integrated framework for density-based cluster analysis, outlier detection, and data visualization is introduced in this article. The main module consists of an algorithm to compute hierarchical estimates of the level sets of a density, following Hartigan's classic model of density-contour clusters and trees. Such an algorithm generalizes and improves existing density-based clustering techniques with respect to different aspects. It provides as a result a complete clustering hierarchy composed of all possible density-based clusters following the nonparametric model adopted, for an infinite range of density thresholds. The resulting hierarchy can be easily processed so as to provide multiple ways for data visualization and exploration. It can also be further postprocessed so that: (i) a normalized score of "outlierness" can be assigned to each data object, which unifies both the global and local perspectives of outliers into a single definition; and (ii) a "flat"(i.e., nonhierarchical) clustering solution composed of clusters extracted from local cuts through the cluster tree (possibly corresponding to different density thresholds) can be obtained, either in an unsupervised or in a semisupervised way. In the unsupervised scenario, the algorithm corresponding to this postprocessing module provides a global, optimal solution to the formal problem of maximizing the overall stability of the extracted clusters. If partially labeled objects or instance-level constraints are provided by the user, the algorithm can solve the problem by considering both constraints violations/satisfactions and cluster stability criteria. An asymptotic complexity analysis, both in terms of running time and memory space, is described. Experiments are reported that involve a variety of synthetic and real datasets, including comparisons with state-of-the-art, density-based clustering and (global and local) outlier detection methods.},
author = {Campello, Ricardo J.G.B. and Moulavi, Davoud and Zimek, Arthur and Sander, J{\"{o}}rg},
doi = {10.1145/2733381},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Campello et al. - 2015 - Hierarchical Density Estimates for Data Clustering, Visualization, and Outlier Detection.pdf:pdf},
issn = {1556472X},
journal = {ACM Transactions on Knowledge Discovery from Data},
keywords = {Algorithms,Clustering,Data mining,Data visualization,Density-based clustering,Global/local outliers,H.2.8 [database mamagement]: Database applications,H.3.3 [information storage and retrieval]: Informa,Hierarchical and nonhierarchical clustering,I.5.3 [pattern recognition]: Clustering - Algorith,Outlier detection,Unsupervised and semisupervised clustering},
number = {1},
pages = {1--51},
title = {{Hierarchical Density Estimates for Data Clustering, Visualization, and Outlier Detection}},
volume = {10},
year = {2015}
}
@article{Mehri2020b,
abstract = {A long-standing goal of task-oriented dialogue research is the ability to flexibly adapt dialogue models to new domains. To progress research in this direction, we introduce DialoGLUE (Dialogue Language Understanding Evaluation), a public benchmark consisting of 7 task-oriented dialogue datasets covering 4 distinct natural language understanding tasks, designed to encourage dialogue research in representation-based transfer, domain adaptation, and sample-efficient task learning. We release several strong baseline models, demonstrating performance improvements over a vanilla BERT architecture and state-of-the-art results on 5 out of 7 tasks, by pre-training on a large open-domain dialogue corpus and task-adaptive self-supervised training. Through the DialoGLUE benchmark, the baseline methods, and our evaluation scripts, we hope to facilitate progress towards the goal of developing more general task-oriented dialogue models.1},
archivePrefix = {arXiv},
arxivId = {2009.13570},
author = {Mehri, Shikib and Eric, Mihail and Hakkani-Tur, Dilek},
eprint = {2009.13570},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mehri, Eric, Hakkani-Tur - 2020 - DialoGLUE A Natural Language Understanding Benchmark for Task-Oriented Dialogue.pdf:pdf},
issn = {23318422},
journal = {arXiv},
title = {{DialoGLUE: A Natural Language Understanding Benchmark for Task-Oriented Dialogue}},
year = {2020}
}
@article{Lloyd1982,
abstract = {It has long been realized that in pulse-code modulation (PCM), with a given ensemble of signals to handle, the quantum values should be spaced more closely in the voltage regions where the signal amplitude is more likely to fall. It has been shown by Panter and Dite that, in the limit as the number of quanta becomes infinite, the asymptotic fractional density of quanta per unit voltage should vary as the one-third power of the probability density per unit voltage of signal amplitudes. In this paper the corresponding result for any finite number of quanta is derived; that is, necessary conditions are found that the quanta and associated quantization intervals of an optimum finite quantization scheme must satisfy. The optimization criterion used is that the average quantization noise power be a minimum. It is shown that the result obtained here goes over into the Panter and Dite result as the number of quanta become large. The optimum quantization schemes for 2b quanta, b = 1,2, {\textperiodcentered}{\textperiodcentered}{\textperiodcentered}, 7, are given numerically for Gaussian and for Laplacian distribution of signal amplitudes. {\textcopyright}1982 IEEE},
author = {Lloyd, Stuart P.},
doi = {10.1109/TIT.1982.1056489},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lloyd - 1982 - Least Squares Quantization in PCM.pdf:pdf},
issn = {15579654},
journal = {IEEE Transactions on Information Theory},
number = {2},
pages = {129--137},
title = {{Least Squares Quantization in PCM}},
volume = {28},
year = {1982}
}
@article{Bordes2017,
abstract = {Traditional dialog systems used in goal-oriented applications require a lot of domain-specific handcrafting, which hinders scaling up to new domains. End-to-end dialog systems, in which all components are trained from the dialogs themselves, escape this limitation. But the encouraging success recently obtained in chit-chat dialog may not carry over to goal-oriented settings. This paper proposes a testbed to break down the strengths and shortcomings of end-to-end dialog systems in goal-oriented applications. Set in the context of restaurant reservation, our tasks require manipulating sentences and symbols in order to properly conduct conversations, issue API calls and use the outputs of such calls. We show that an end-to-end dialog system based on Memory Networks can reach promising, yet imperfect, performance and learn to perform non-trivial operations. We confirm those results by comparing our system to a hand-crafted slot-filling baseline on data from the second Dialog State Tracking Challenge (Henderson et al., 2014a). We show similar result patterns on data extracted from an online concierge service.},
archivePrefix = {arXiv},
arxivId = {arXiv:1605.07683v4},
author = {Bordes, Antoine and {Lan Boureau}, Y. and Weston, Jason},
eprint = {arXiv:1605.07683v4},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bordes, Lan Boureau, Weston - 2017 - Learning End-to-End Goal-Oriented Dialog.pdf:pdf},
journal = {Proc. of the International Conference on Learning Representations},
title = {{Learning End-to-End Goal-Oriented Dialog}},
url = {http://arxiv.org/abs/2005.00796-},
year = {2017}
}
@article{Jordan2015,
author = {Jordan, M. I. and Mitchell, T. M.},
doi = {10.1126/science.aaa8415},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Jordan, Mitchell - 2015 - Machine Learning Trends, Perspectives and Prospects.pdf:pdf},
journal = {Science},
number = {6245},
pages = {255--260},
title = {{Machine Learning: Trends, Perspectives and Prospects}},
volume = {349},
year = {2015}
}
@inproceedings{Martins2016,
abstract = {We propose sparsemax, a new activation function similar to the traditional softmax, but able to output sparse probabilities. After deriving its properties, we show how its Jacobian can be efficiently computed, enabling its use in a network trained with backpropagation. Then, we propose a new smooth and convex loss function which is the sparsemax analogue of the logistic loss. We reveal an unexpected connection between this new loss and the Huber classification loss. We obtain promising empirical results in multi-label classification problems and in attention-based neural networks for natural language inference. For the latter, we achieve a similar performance as the traditional softmax, but with a selective, more compact, attention focus.},
author = {Martins, Andre F.T. and Astudillo, Ramon F.},
booktitle = {Proc. of the International Conference on Machine Learning},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Martins, Astudillo - 2016 - From Softmax to Sparsemax A Sparse Model of Attention and Multi-Label Classification.pdf:pdf},
title = {{From Softmax to Sparsemax: A Sparse Model of Attention and Multi-Label Classification}},
year = {2016}
}
@article{Young2018,
abstract = {Building dialogue systems that can converse naturally with humans is a challenging yet intriguing problem of artificial intelligence. In open-domain human-computer conversation, where the conversational agent is expected to respond to human utterances in an interesting and engaging way, commonsense knowledge has to be integrated into the model effectively. In this paper, we investigate the impact of providing commonsense knowledge about the concepts covered in the dialogue. Our model represents the first attempt to integrating a large commonsense knowledge base into end-to-end conversational models. In the retrieval-based scenario, we propose a model to jointly take into account message content and related commonsense for selecting an appropriate response. Our experiments suggest that the knowledge-augmented models are superior to their knowledge-free counterparts.},
archivePrefix = {arXiv},
arxivId = {1709.05453},
author = {Young, Tom and Cambria, Erik and Chaturvedi, Iti and Zhou, Hao and Biswas, Subham and Huang, Minlie},
eprint = {1709.05453},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Young et al. - 2018 - Augmenting end-to-end dialogue systems with commonsense knowledge.pdf:pdf},
isbn = {9781577358008},
journal = {32nd AAAI Conference on Artificial Intelligence, AAAI 2018},
pages = {4970--4977},
title = {{Augmenting end-to-end dialogue systems with commonsense knowledge}},
year = {2018}
}
@article{Daza2018,
abstract = {We explore a novel approach for Semantic Role Labeling (SRL) by casting it as a sequence-to-sequence process. We employ an attention-based model enriched with a copying mechanism to ensure faithful regeneration of the input sequence, while enabling interleaved generation of argument role labels. Here, we apply this model in a monolingual setting, performing PropBank SRL on English language data. The constrained sequence generation set-up enforced with the copying mechanism allows us to analyze the performance and special properties of the model on manually labeled data and benchmarking against state-of-the-art sequence labeling models. We show that our model is able to solve the SRL argument labeling task on English data, yet further structural decoding constraints will need to be added to make the model truly competitive. Our work represents a first step towards more advanced, generative SRL labeling setups.},
archivePrefix = {arXiv},
arxivId = {1807.03006},
author = {Daza, Angel and Frank, Anette},
doi = {10.18653/v1/w18-3027},
eprint = {1807.03006},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Daza, Frank - 2018 - A Sequence-to-Sequence Model for Semantic Role Labeling.pdf:pdf},
issn = {23318422},
journal = {arXiv},
title = {{A Sequence-to-Sequence Model for Semantic Role Labeling}},
year = {2018}
}
@article{Li2020,
abstract = {We present an empirical investigation of pre-trained Transformer-based auto-regressive language models for the task of open-domain dialogue generation. Training paradigm of pre-training and fine-tuning is employed to conduct the parameter learning. Corpora of News and Wikipedia in Chinese and English are collected for the pre-training stage respectively. Dialogue context and response are concatenated into a single sequence utilized as the input of the models during the fine-tuning stage. A weighted joint prediction paradigm for both context and response is designed to evaluate the performance of models with or without the loss term for context prediction. Various of decoding strategies such as greedy search, beam search, top-k sampling, etc. are employed to conduct the response text generation. Extensive experiments are conducted on the typical single-turn and multi-turn dialogue corpora such as Weibo, Douban, Reddit, DailyDialog, and Persona-Chat. Detailed numbers of automatic evaluation metrics on relevance and diversity of the generated results for the languages models as well as the baseline approaches are reported.},
archivePrefix = {arXiv},
arxivId = {2003.04195},
author = {Li, Piji},
eprint = {2003.04195},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Li - 2020 - An Empirical Investigation of Pre-Trained Transformer Language Models for Open-Domain Dialogue Generation.pdf:pdf},
title = {{An Empirical Investigation of Pre-Trained Transformer Language Models for Open-Domain Dialogue Generation}},
url = {http://arxiv.org/abs/2003.04195},
year = {2020}
}
@inproceedings{Wang2013,
abstract = {This paper presents a generic dialogue state tracker that maintains beliefs over user goals based on a few simple domainindependent rules, using basic probability operations. The rules apply to observed system actions and partially observable user acts, without using any knowledge obtained from external resources (i.e. without requiring training data). The core insight is to maximise the amount of information directly gainable from an errorprone dialogue itself, so as to better lowerbound one's expectations on the performance of more advanced statistical techniques for the task. The proposed method is evaluated in the Dialog State Tracking Challenge, where it achieves comparable performance in hypothesis accuracy to machine learning based systems. Consequently, with respect to different scenarios for the belief tracking problem, the potential superiority and weakness of machine learning approaches in general are investigated.},
author = {Wang, Zhuoran and Lemon, Oliver},
booktitle = {Proc. of the Annual Meeting of the Special Interest Group on Discourse and Dialogue},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wang, Lemon - 2013 - A Simple and Generic Belief Tracking Mechanism for the Dialog State Tracking Challenge On the believability of obse.pdf:pdf},
title = {{A Simple and Generic Belief Tracking Mechanism for the Dialog State Tracking Challenge: On the believability of observed information}},
year = {2013}
}
@article{Cai2019,
abstract = {End-to-end sequence generation is a popular technique for developing open domain dialogue systems, though they suffer from the safe response problem. Researchers have attempted to tackle this problem by incorporating generative models with the returns of retrieval systems. Recently, a skeleton-then-response framework has been shown promising results for this task. Nevertheless, how to precisely extract a skeleton and how to effectively train a retrieval-guided response generator are still challenging. This paper presents a novel framework in which the skeleton extraction is made by an interpretable matching model and the following skeleton-guided response generation is accomplished by a separately trained generator. Extensive experiments demonstrate the effectiveness of our model designs.},
author = {Cai, Deng and Wang, Yan and Bi, Wei and Tu, Zhaopeng and Liu, Xiaojiang and Shi, Shuming},
doi = {10.18653/v1/d19-1195},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cai et al. - 2019 - Retrieval-guided Dialogue Response Generation via a Matching-to-Generation Framework.pdf:pdf},
pages = {1866--1875},
title = {{Retrieval-guided Dialogue Response Generation via a Matching-to-Generation Framework}},
year = {2019}
}
@article{Tax2016,
abstract = {In this paper we describe a method to discover frequent behavioral patterns in event logs. We express these patterns as $\backslash$emph{\{}local process models{\}}. Local process model mining can be positioned in-between process discovery and episode / sequential pattern mining. The technique presented in this paper is able to learn behavioral patterns involving sequential composition, concurrency, choice and loop, like in process mining. However, we do not look at start-to-end models, which distinguishes our approach from process discovery and creates a link to episode / sequential pattern mining. We propose an incremental procedure for building local process models capturing frequent patterns based on so-called process trees. We propose five quality dimensions and corresponding metrics for local process models, given an event log. We show monotonicity properties for some quality dimensions, enabling a speedup of local process model discovery through pruning. We demonstrate through a real life case study that mining local patterns allows us to get insights in processes where regular start-to-end process discovery techniques are only able to learn unstructured, flower-like, models.},
archivePrefix = {arXiv},
arxivId = {1606.06066},
author = {Tax, Niek and Sidorova, Natalia and Haakma, Reinder and van der Aalst, Wil M.P.},
doi = {10.1016/j.jides.2016.11.001},
eprint = {1606.06066},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Tax et al. - 2016 - Mining Local Process Models.pdf:pdf},
issn = {23526645},
journal = {Journal of Innovation in Digital Ecosystems},
number = {2},
pages = {183--196},
title = {{Mining Local Process Models}},
volume = {3},
year = {2016}
}
@article{Turing1950,
author = {Turing, A. M.},
doi = {10.1093/mind/LIX.236.433},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Turing - 1950 - I.—COMPUTING MACHINERY AND INTELLIGENCE.pdf:pdf},
journal = {Mind},
number = {236},
pages = {433--460},
title = {{I.—COMPUTING MACHINERY AND INTELLIGENCE}},
url = {https://doi.org/10.1093/mind/LIX.236.433},
volume = {LIX},
year = {1950}
}
@inproceedings{Lemon2006,
abstract = {We demonstrate a multimodal dialogue system using reinforcement learning for in-car scenarios, developed at Edinburgh University and Cambridge University for the TALK project1. This prototype is the first "Information State Update" (ISU) dialogue system to exhibit reinforcement learning of dialogue strategies, and also has a fragmentary clarification feature. This paper describes the main components and functionality of the system, as well as the purposes and future use of the system, and surveys the research issues involved in its construction. Evaluation of this system (i.e. comparing the baseline system with handcoded vs. learnt dialogue policies) is ongoing, and the demonstration will show both.},
author = {Lemon, Oliver and Georgila, Kallirroi and Henderson, James and Stuttle, Matthew},
booktitle = {Proc. of the Conference of the European Chapter of the Association for Computational Linguistics},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lemon et al. - 2006 - An ISU Dialogue System Exhibiting Reinforcement Learning of Dialogue Policies Generic Slot-Filling in the TALK In-.pdf:pdf},
title = {{An ISU Dialogue System Exhibiting Reinforcement Learning of Dialogue Policies: Generic Slot-Filling in the TALK In-car System}},
year = {2006}
}
@article{Navigli2018,
abstract = {In this paper I look at Natural Language Understanding, an area of Natural Language Processing aimed at making sense of text, through the lens of a visionary future: what do we expect a machine should be able to understand? and what are the key dimensions that require the attention of researchers to make this dream come true?},
author = {Navigli, Roberto},
doi = {10.24963/ijcai.2018/812},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Navigli - 2018 - Natural Language Understanding Instructions for (Present and Future) Use.pdf:pdf},
isbn = {9780999241127},
issn = {10450823},
journal = {IJCAI International Joint Conference on Artificial Intelligence},
keywords = {Natural Language Processing: Natural Language Sema,Natural Language Processing: Resources and Evaluat},
pages = {5697--5702},
title = {{Natural Language Understanding: Instructions for (Present and Future) Use}},
volume = {2018-July},
year = {2018}
}
@inproceedings{Zhao2016,
abstract = {This paper presents an end-to-end framework for task-oriented dialog systems using a variant of Deep Recurrent Q-Networks (DRQN). The model is able to interface with a relational database and jointly learn policies for both language understanding and dialog strategy. Moreover, we propose a hybrid algorithm that combines the strength of reinforcement learning and supervised learning to achieve faster learning speed. We evaluated the proposed model on a 20 Question Game conversational game simulator. Results show that the proposed method outperforms the modular-based baseline and learns a distributed representation of the latent dialog state.},
author = {Zhao, Tiancheng and Eskenazi, Maxine},
booktitle = {Proc. of the Annual Meeting of the Special Interest Group on Discourse and Dialogue},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhao, Eskenazi - 2016 - Towards End-to-End Learning for Dialog State Tracking and Management using Deep Reinforcement Learning.pdf:pdf},
title = {{Towards End-to-End Learning for Dialog State Tracking and Management using Deep Reinforcement Learning}},
year = {2016}
}
@inproceedings{Padmakumar2017,
abstract = {Natural language understanding and dialog management are two integral components of interactive dialog systems. Previous research has used machine learning techniques to individually optimize these components, with different forms of direct and indirect supervision. We present an approach to integrate the learning of both a dialog strategy using reinforcement learning, and a semantic parser for robust natural language understanding, using only natural dialog interaction for supervision. Experimental results on a simulated task of robot instruction demonstrate that joint learning of both components improves dialog performance over learning either of these components alone.},
author = {Padmakumar, Aishwarya and Thomason, Jesse and Mooney, Raymond J.},
booktitle = {Proc. of the EACL},
doi = {10.18653/v1/e17-1052},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Padmakumar, Thomason, Mooney - 2017 - Integrated Learning of Dialog Strategies and Semantic Parsing.pdf:pdf},
isbn = {9781510838604},
title = {{Integrated Learning of Dialog Strategies and Semantic Parsing}},
year = {2017}
}
@article{Chatterjee2020,
abstract = {Conversational systems are of primary interest in the AI community. Chatbots are increasingly being deployed to provide round-the-clock support and to increase customer engagement. Many of the commercial bot building frameworks follow a standard approach that requires one to build and train an intent model to recognize a user input. Intent models are trained in a supervised setting with a collection of textual utterance and intent label pairs. Gathering a substantial and wide coverage of training data for different intent is a bottleneck in the bot building process. Moreover, the cost of labeling a hundred to thousands of conversations with intent is a time consuming and laborious job. In this paper, we present an intent discovery framework that involves 4 primary steps: Extraction of textual utterances from a conversation using a pre-trained domain agnostic Dialog Act Classifier (Data Extraction), automatic clustering of similar user utterances (Clustering), manual annotation of clusters with an intent label (Labeling) and propagation of intent labels to the utterances from the previous step, which are not mapped to any cluster (Label Propagation); to generate intent training data from raw conversations. We have introduced a novel density-based clustering algorithm ITER-DBSCAN for unbalanced data clustering. Subject Matter Expert (Annotators with domain expertise) manually looks into the clustered user utterances and provides an intent label for discovery. We conducted user studies to validate the effectiveness of the trained intent model generated in terms of coverage of intents, accuracy and time saving concerning manual annotation. Although the system is developed for building an intent model for the conversational system, this framework can also be used for a short text clustering or as a labeling framework.},
archivePrefix = {arXiv},
arxivId = {2005.11014},
author = {Chatterjee, Ajay and Sengupta, Shubhashis},
doi = {10.18653/v1/2020.coling-main.366},
eprint = {2005.11014},
file = {:home/theritacosta/Desktop/botbuilder{\_}project/reading/2005.11014v1.pdf:pdf},
pages = {4140--4152},
title = {{Intent Mining from past conversations for Conversational Agent}},
year = {2020}
}
@article{Chen2020,
abstract = {Semantically controlled neural response generation on limited-domain has achieved great performance. However, moving towards multi-domain large-scale scenarios are shown to be difficult because the possible combinations of semantic inputs grow exponentially with the number of domains. To alleviate such scalability issue, we exploit the structure of dialog acts to build a multi-layer hierarchical graph, where each act is represented as a root-to-leaf route on the graph. Then, we incorporate such graph structure prior as an inductive bias to build a hierarchical disentangled self-attention network, where we disentangle attention heads to model designated nodes on the dialog act graph. By activating different (disentangled) heads at each layer, combinatorially many dialog act semantics can be modeled to control the neural response generation. On the large-scale Multi-Domain-WOZ dataset, our model can yield a significant improvement over the baselines on various automatic and human evaluation metrics.},
archivePrefix = {arXiv},
arxivId = {1905.12866},
author = {Chen, Wenhu and Chen, Jianshu and Qin, Pengda and Yan, Xifeng and Wang, William Yang},
doi = {10.18653/v1/p19-1360},
eprint = {1905.12866},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chen et al. - 2020 - Semantically conditioned dialog response generation via hierarchical disentangled self-attention.pdf:pdf},
isbn = {9781950737482},
journal = {ACL 2019 - 57th Annual Meeting of the Association for Computational Linguistics, Proceedings of the Conference},
pages = {3696--3709},
title = {{Semantically conditioned dialog response generation via hierarchical disentangled self-attention}},
year = {2020}
}
@inproceedings{Elgohary2020,
abstract = {Question answering is an AI-complete problem, but existing datasets lack key elements of language understanding such as coreference and ellipsis resolution. We consider sequential question answering: multiple questions are asked one-by-one in a conversation between a questioner and an answerer. Answering these questions is only possible through understanding the conversation history. We introduce the task of question-in-context rewriting: given the context of a conversation's history, rewrite a context-dependent into a self-contained question with the same answer. We construct, CANARD, a dataset of 40,527 questions based on QUAC (Choi et al., 2018) and train Seq2Seq models for incorporating context into standalone questions.},
author = {Elgohary, Ahmed and Peskov, Denis and Boyd-Graber, Jordan},
booktitle = {Proc. of EMNLP-IJCNLP},
doi = {10.18653/v1/d19-1605},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Elgohary, Peskov, Boyd-Graber - 2019 - Can You Unpack That Learning to Rewrite Questions-in-Context.pdf:pdf},
isbn = {9781950737901},
pages = {5918--5924},
title = {{Can You Unpack That? Learning to Rewrite Questions-in-Context}},
year = {2019}
}
@article{Daszykowski2009,
abstract = {Clustering techniques are often used for data exploration. In the literature, there are many examples of applications of different clustering methods. The density-based approaches form a separate group within the clustering techniques since they take into account the density of the data. Using the density of data as a similarity measure is practical in many real situations, because clusters of arbitrary shapes can be handled, what is not possible with convectional clustering methods.{\textcopyright} 2009 Elsevier B.V. All rights reserved.},
author = {Daszykowski, M. and Walczak, B.},
doi = {10.1016/B978-044452701-1.00067-3},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Daszykowski, Walczak - 2009 - Density-Based Clustering Methods.pdf:pdf},
isbn = {9780444527011},
journal = {Comprehensive Chemometrics},
keywords = {Color maps,Core plot,Density-based techniques,Inliers,Natural clusters,Outliers,Reachability plot},
pages = {635--654},
title = {{Density-Based Clustering Methods}},
volume = {2},
year = {2009}
}
@inproceedings{Banerjee2005,
abstract = {METEOR, an automatic metric for machine translation evaluation that is based on a generalized concept of unigram matching between the machine-produced translation and human-produced reference translations. Unigrams can be matched based on their surface forms, stemmed forms, and meanings; furthermore, METEOR can be easily extended to include more advanced matching strategies. Once all generalized unigram matches between the two strings have been found, METEOR computes a score for this matching using a combination of unigram-precision, unigram-recall, and a measure of fragmentation that is designed to directly capture how well-ordered the matched words in the machine translation are in relation to the reference. METEOR gets an R correlation value of 0.347 with human evaluation on the Arabic data and 0.331 on the Chinese data. This is shown to be an improvement on using simply unigram-precision, unigram-recall and their harmonic F1 combination.},
author = {Banerjee, Satanjeev and Lavie, Alon},
booktitle = {Proc. of the ACL Workshop on Intrinsic and Extrinsic Evaluation Measures for Machine Translation and/or Summarization},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Banerjee, Lavie - 2005 - METEOR An Automatic Metric for MT Evaluation with Improved Correlation with Human Judgments.pdf:pdf},
title = {{METEOR: An Automatic Metric for MT Evaluation with Improved Correlation with Human Judgments}},
year = {2005}
}
@article{Wang2010,
abstract = {Objective To investigate the appropriate criteria for the screening of retinopathy of prematurity ( ROP) in Xi'an region and to determine the risk factors for ROP. Methods Screening criteria were established basing on the ROP screening guidelines, implemented by Ministry of Public Health with minor modification. It included newborn infants with birth weight of 2000 g or less, or gestational age of 34 w or less. The results obtained by the present screening criteria were compared with those obtained from the national screening criteria Gestation age and birth weight between groups of ROP and normal fundus were compared by Student t - test, the ratios of persistent oxygen inhalation were examined by Chi-square test, and the risk factors for ROP were analyzed by Fisher exact test A P {\textless} 0.05 was considered significant Results In all the infants examined, 18 cases (36 eyes, 13.43{\%}) developed ROP, including 4 cases (8 eyes) suffering from stage 1, 5 cases (10 eyes) from stage 2 (one was affected in zone II with plus disease) , 5 cases (10 eyes) from stage 3 with plus disease, 1 case (2 eyes) from stage 4 A, 1 case (2 eyes) from stage 5, and 2 cases (4 eyes) from regressed stage. In ROP cases, gestation age ranged from 28 to 34 w, (30.58 ± 1.97) w; birth weight ranged from 880 to 1950 g, ( 1388.89 ±268.39) g. Statistical analysis showed that, the gestation age and birth weight in normal fundus group were (32.56 ±2.00) w and (1773.91 ±349.73) g respectively, which were higher than group of ROP (gestation age t =3. 90, P {\textless} 0.01 ; birth weight t =4.45, P {\textless}0.01 ). The ratios of persistent oxygen inhalation in group of normal fundus and ROP were 59.48{\%} and 61.11{\%} ( Χ2 = 0.017, P {\textgreater} 0.05 ) . It was also observed that the ratios of hypoxic - ischemic encephalopathy and placenta abruption in those two groups were 12. 07{\%} , 33. 33{\%} (P = 0.030) and 0.86{\%} , 11.11{\%} (P=0.047). Clinical analysis indicated that prematurity, low birth weight, hypoxic-ischemic encephalopathy and placenta abruption were closely related to the occurrence of ROP. On the other hand, if using national screening criteria, only 108 infants in all 134 cases required screening, and all of the ROP cases could be detected with a detection rate at 16.67{\%}. Conclusions The detection rate of ROP is 13.43{\%} (18/134) in the present study, which is consistent with the results obtained in previous studies in China The national criteria are appropriate for the ROP screening in Xi'an region. Prematurity, low birth weight and the relative hypoxia are high risk factors for the occurrence of ROP.},
author = {Wang, Yu Sheng and Zhang, Zi Feng and Li, Man Hong and Zhang, Peng and Liu, Xiao Yan},
doi = {10.3760/cma.j.issn.04124081.2010.02.006},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wang et al. - 2010 - Preliminary results of screening of retinopathy of prematurity in Xi' an.pdf:pdf},
issn = {04124081},
journal = {Chinese Journal of Ophthalmology},
keywords = {Epidemiology,Mass screening,Retinopathy of prematurity},
number = {2},
pages = {119--124},
pmid = {20388344},
title = {{Preliminary results of screening of retinopathy of prematurity in Xi' an}},
volume = {46},
year = {2010}
}
@article{Ren2014,
abstract = {The problem of learning user search intents has attracted intensive attention from both industry and academia. However, state-of-the-art intent learning algorithms suffer from different drawbacks when only using a single type of data source. For example, query text has difficulty in distinguishing ambiguous queries; search log is bias to the order of search results and users' noisy click behaviors. In this work, we for the first time leverage three types of objects, namely queries, web pages and Wikipedia concepts collaboratively for learning generic search intents and construct a heterogeneous graph to represent multiple types of relationships between them. A novel unsupervised method called heterogeneous graph-based soft-clustering is developed to derive an intent indicator for each object based on the constructed heterogeneous graph. With the proposed co-clustering method, one can enhance the quality of intent understanding by taking advantage of different types of data, which complement each other, and make the implicit intents easier to interpret with explicit knowledge from Wikipedia concepts. Experiments on two real-world datasets demonstrate the power of the proposed method where it achieves a 9.25{\%} improvement in terms of NDCG on search ranking task and a 4.67{\%} enhancement in terms of Rand index on object co-clustering task compared to the best state-of-the-art method. {\textcopyright} 2014 ACM.},
author = {Ren, Xiang and Wang, Yujing and Yu, Xiao and Yan, Jun and Chen, Zheng and Han, Jiawei},
doi = {10.1145/2556195.2556222},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ren et al. - 2014 - Heterogeneous graph-based intent learning with queries, web pages and Wikipedia concepts.pdf:pdf},
isbn = {9781450323512},
journal = {WSDM 2014 - Proceedings of the 7th ACM International Conference on Web Search and Data Mining},
keywords = {heterogeneous graph clustering,search intent,wikipedia},
pages = {23--32},
title = {{Heterogeneous graph-based intent learning with queries, web pages and Wikipedia concepts}},
year = {2014}
}
@inproceedings{Dai2019,
author = {Dai, Zihang and Yang, Zhilin and Yang, Yiming and Carbonell, Jaime and Le, Quoc V. and Salakhutdinov, Ruslan},
booktitle = {Proc. of the Annual Meeting of the Association for Computational Linguistics},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Dai et al. - 2019 - Transformer-XL Attentive Language Models Beyond a Fixed-Length Context.pdf:pdf},
title = {{Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context}},
year = {2019}
}
@article{Goodfellow2016,
author = {Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron},
journal = {MIT Note},
title = {{Deep Learning}},
url = {https://www.deeplearningbook.org/},
year = {2016}
}
@article{Liu2020,
abstract = {Contextual embeddings, such as ELMo and BERT, move beyond global word representations like Word2Vec and achieve ground-breaking performance on a wide range of natural language processing tasks. Contextual embeddings assign each word a representation based on its context, thereby capturing uses of words across varied contexts and encoding knowledge that transfers across languages. In this survey, we review existing contextual embedding models, cross-lingual polyglot pre-training, the application of contextual embeddings in downstream tasks, model compression, and model analyses.},
archivePrefix = {arXiv},
arxivId = {2003.07278},
author = {Liu, Qi and Kusner, Matt J. and Blunsom, Phil},
eprint = {2003.07278},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Liu, Kusner, Blunsom - 2020 - A Survey on Contextual Embeddings.pdf:pdf},
title = {{A Survey on Contextual Embeddings}},
url = {http://arxiv.org/abs/2003.07278},
year = {2020}
}
@article{Li2017,
abstract = {In this paper, drawing intuition from the Turing test, we propose using adversarial training for open-domain dialogue generation: the system is trained to produce sequences that are indistinguishable from human-generated dialogue utterances. We cast the task as a reinforcement learning (RL) problem where we jointly train two systems, a generative model to produce response sequences, and a discriminator—analagous to the human evaluator in the Turing test— to distinguish between the human-generated dialogues and the machine-generated ones. The outputs from the discriminator are then used as rewards for the generative model, pushing the system to generate dialogues that mostly resemble human dialogues. In addition to adversarial training we describe a model for adversarial evaluation that uses success in fooling an adversary as a dialogue evaluation metric, while avoiding a number of potential pitfalls. Experimental results on several metrics, including adversarial evaluation, demonstrate that the adversarially-trained system generates higher-quality responses than previous baselines.},
archivePrefix = {arXiv},
arxivId = {1701.06547},
author = {Li, Jiwei and Monroe, Will and Shi, Tianlin and Jean, S{\'{e}}bastien and Ritter, Alan and Jurafsky, Dan},
doi = {10.18653/v1/d17-1230},
eprint = {1701.06547},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Li et al. - 2017 - Adversarial learning for neural dialogue generation.pdf:pdf},
isbn = {9781945626838},
journal = {EMNLP 2017 - Conference on Empirical Methods in Natural Language Processing, Proceedings},
pages = {2157--2169},
title = {{Adversarial learning for neural dialogue generation}},
year = {2017}
}
@article{Qi2021,
abstract = {Now, the pre-training technique is ubiquitous in natural language processing field. ProphetNet is a pre-training based natural language generation method which shows powerful performance on English text summarization and question generation tasks. In this paper, we extend ProphetNet into other domains and languages, and present the ProphetNet family pre-training models, named ProphetNet-X, where X can be English, Chinese, Multi-lingual, and so on. We pre-train a cross-lingual generation model ProphetNet-Multi, a Chinese generation model ProphetNet-Zh, two open-domain dialog generation models ProphetNet-Dialog-En and ProphetNet-Dialog-Zh. And also, we provide a PLG (Programming Language Generation) model ProphetNet-Code to show the generation performance besides NLG (Natural Language Generation) tasks. In our experiments, ProphetNet-X models achieve new state-of-the-art performance on 10 benchmarks. All the models of ProphetNet-X share the same model structure, which allows users to easily switch between different models. We make the code and models publicly available, and we will keep updating more pre-training models and finetuning scripts.},
archivePrefix = {arXiv},
arxivId = {2104.08006},
author = {Qi, Weizhen and Gong, Yeyun and Yan, Yu and Xu, Can and Yao, Bolun and Zhou, Bartuer and Cheng, Biao and Jiang, Daxin and Chen, Jiusheng and Zhang, Ruofei and Li, Houqiang and Duan, Nan},
eprint = {2104.08006},
file = {:home/theritacosta/Desktop/botbuilder{\_}project/reading/2104.08006.pdf:pdf},
title = {{ProphetNet-X: Large-Scale Pre-training Models for English, Chinese, Multi-lingual, Dialog, and Code Generation}},
url = {http://arxiv.org/abs/2104.08006},
year = {2021}
}
@article{Lee2019,
abstract = {In natural language processing, it has been observed recently that generalization could be greatly improved by finetuning a large-scale language model pretrained on a large unlabeled corpus. Despite its recent success and wide adoption, finetuning a large pretrained language model on a downstream task is prone to degenerate performance when there are only a small number of training instances available. In this paper, we introduce a new regularization technique, to which we refer as "mixout", motivated by dropout. Mixout stochastically mixes the parameters of two models. We show that our mixout technique regularizes learning to minimize the deviation from one of the two models and that the strength of regularization adapts along the optimization trajectory. We empirically evaluate the proposed mixout and its variants on finetuning a pretrained language model on downstream tasks. More specifically, we demonstrate that the stability of finetuning and the average accuracy greatly increase when we use the proposed approach to regularize finetuning of BERT on downstream tasks in GLUE.},
archivePrefix = {arXiv},
arxivId = {1909.11299},
author = {Lee, Cheolhyoung and Cho, Kyunghyun and Kang, Wanmo},
eprint = {1909.11299},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lee, Cho, Kang - 2019 - Mixout Effective Regularization to Finetune Large-scale Pretrained Language Models.pdf:pdf},
pages = {1--17},
title = {{Mixout: Effective Regularization to Finetune Large-scale Pretrained Language Models}},
url = {http://arxiv.org/abs/1909.11299},
year = {2019}
}
@article{Weston2019,
abstract = {Sequence generation models for dialogue are known to have several problems: they tend to produce short, generic sentences that are uninformative and unengaging. Retrieval models on the other hand can surface interesting responses, but are restricted to the given retrieval set leading to erroneous replies that cannot be tuned to the specific context. In this work we develop a model that combines the two approaches to avoid both their deficiencies: first retrieve a response and then refine it -- the final sequence generator treating the retrieval as additional context. We show on the recent CONVAI2 challenge task our approach produces responses superior to both standard retrieval and generation models in human evaluations.},
archivePrefix = {arXiv},
arxivId = {1808.04776},
author = {Weston, Jason and Dinan, Emily and Miller, Alexander},
doi = {10.18653/v1/w18-5713},
eprint = {1808.04776},
file = {:home/theritacosta/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Weston, Dinan, Miller - 2019 - Retrieve and Refine Improved Sequence Generation Models For Dialogue.pdf:pdf},
isbn = {9781948087759},
pages = {87--92},
title = {{Retrieve and Refine: Improved Sequence Generation Models For Dialogue}},
year = {2019}
}
@article{Li2020a,
   abstract = {Dialogue state trackers have made significant progress on benchmark datasets, but their generalization capability to novel and realistic scenarios beyond the held-out conversations is less understood. We propose controllable counterfactuals (CoCo) to bridge this gap and evaluate dialogue state tracking (DST) models on novel scenarios, i.e., would the system successfully tackle the request if the user responded differently but still consistently with the dialogue flow? CoCo leverages turn-level belief states as counterfactual conditionals to produce novel conversation scenarios in two steps: (i) counterfactual goal generation at turn-level by dropping and adding slots followed by replacing slot values, (ii) counterfactual conversation generation that is conditioned on (i) and consistent with the dialogue flow. Evaluating state-of-the-art DST models on MultiWOZ dataset with CoCo-generated counterfactuals results in a significant performance drop of up to 30.8% (from 49.4% to 18.6%) in absolute joint goal accuracy. In comparison, widely used techniques like paraphrasing only affect the accuracy by at most 2%. Human evaluations show that COCO-generated conversations perfectly reflect the underlying user goal with more than 95% accuracy and are as human-like as the original conversations, further strengthening its reliability and promise to be adopted as part of the robustness evaluation of DST models. Code is available at https://github.com/salesforce/coco-dst.},
   author = {Shiyang Li and Semih Yavuz and Kazuma Hashimoto and Jia Li and Tong Niu and Nazneen Rajani and Xifeng Yan and Yingbo Zhou and Caiming Xiong},
   pages = {1-25},
   title = {CoCo: Controllable Counterfactuals for Evaluating Dialogue State Trackers},
   url = {http://arxiv.org/abs/2010.12850},
   year = {2020},
}
@article{Gupta2020,
   abstract = {Task oriented dialog systems typically first parse user utterances to semantic frames comprised of intents and slots. Previous work on task oriented intent and slot-filling work has been restricted to one intent per query and one slot label per token, and thus cannot model complex compositional requests. Alternative semantic parsing systems have represented queries as logical forms, but these are challenging to annotate and parse. We propose a hierarchical annotation scheme for semantic parsing that allows the representation of compositional queries, and can be efficiently and accurately parsed by standard constituency parsing models. We release a dataset of 44k annotated queries 1, and show that parsing models outperform sequence-to-sequence approaches on this dataset.},
   author = {Sonal Gupta and Rushin Shah and Mrinal Mohit and Anuj Kumar and Michael Lewis},
   doi = {10.18653/v1/d18-1300},
   isbn = {9781948087841},
   journal = {Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, EMNLP 2018},
   pages = {2787-2792},
   title = {Semantic Parsing for Task Oriented Dialog using Hierarchical Representations},
   year = {2020},
}
@article{Mehri2020b,
   abstract = {A long-standing goal of task-oriented dialogue research is the ability to flexibly adapt dialogue models to new domains. To progress research in this direction, we introduce DialoGLUE (Dialogue Language Understanding Evaluation), a public benchmark consisting of 7 task-oriented dialogue datasets covering 4 distinct natural language understanding tasks, designed to encourage dialogue research in representation-based transfer, domain adaptation, and sample-efficient task learning. We release several strong baseline models, demonstrating performance improvements over a vanilla BERT architecture and state-of-the-art results on 5 out of 7 tasks, by pre-training on a large open-domain dialogue corpus and task-adaptive self-supervised training. Through the DialoGLUE benchmark, the baseline methods, and our evaluation scripts, we hope to facilitate progress towards the goal of developing more general task-oriented dialogue models.1},
   author = {Shikib Mehri and Mihail Eric and Dilek Hakkani-Tur},
   issn = {23318422},
   journal = {arXiv},
   title = {DialoGLUE: A Natural Language Understanding Benchmark for Task-Oriented Dialogue},
   year = {2020},
}
@article{Hori2019,
   abstract = {This paper describes the experimental setups and the evaluation results of the sixth Dialog System Technology Challenges (DSTC6) aiming to develop end-to-end dialogue systems. Neural network models have become a recent focus of investigation in dialogue technologies. Previous models required training data to be manually annotated with word meanings and dialogue states, but end-to-end neural network dialogue systems learn to directly output natural-language system responses without needing training data to be manually annotated. Thus, this approach allows us to scale up the size of training data and cover more dialog domains. In addition, dialogue systems require a meta-function to avoid deploying inappropriate responses generated by themselves. To challenge such issues, the DSTC6 consists of three tracks, (1). End-to-End Goal Oriented dialogue Learning to select system responses, (2). End-to-End Conversation Modeling to generate system responses using Natural Language Generation (NLG) and (3). Dialogue Breakdown Detection. Since each domain has different issues to be addressed to develop dialogue systems, we targeted restaurant retrieval dialogues to fill slot-value in Track 1, customer services on Twitter by combining goal-oriented dialogues and ChitChat in Track 2 and human-machine dialogue data for ChitChat in Track 3. DSTC6 had 141 people declaring their interests and 23 teams submitted their final results. 18 scientific papers were presented in the wrap-up workshop. We find the blending end-to-end trainable models associated to meaningful prior knowledge performs the best for the restaurant retrieval for Track 1. Indeed, Hybrid Code Network and Memory Network have been the best models for this task. In Track 2, 78.5% of the system responses automatically generated by the best system were rated better than acceptable by humans and this achieves 89% of the number of the human responses rated in the same class. In Track3, the dialogue breakdown detection technologies performed as well as human agreements, in both data-sets of English and Japanese.},
   author = {Chiori Hori and Julien Perez and Ryuichiro Higashinaka and Takaaki Hori and Y. Lan Boureau and Michimasa Inaba and Yuiko Tsunomori and Tetsuro Takahashi and Koichiro Yoshino and Seokhwan Kim},
   doi = {10.1016/j.csl.2018.09.004},
   issn = {10958363},
   journal = {Computer Speech and Language},
   keywords = {Conversation model,DSTC,Dialogue breakdown,End-to-end dialogue system,Natural Language Generation,Sequence-to-sequence model},
   pages = {1-25},
   title = {Overview of the Ninth Dialog System Technology Challenge: DSTC9},
   volume = {55},
   year = {2019},
}
@article{Pal2020,
   abstract = {Spoken dialogue systems typically use a list of top-N ASR hypotheses for inferring the semantic meaning and tracking the state of the dialogue. However ASR graphs, such as confusion networks (confnets), provide a compact representation of a richer hypothesis space than a top-N ASR list. In this paper, we study the benefits of using confusion networks with a state-of-the-art neural dialogue state tracker (DST). We encode the 2-dimensional confnet into a 1-dimensional sequence of embeddings using an attentional confusion network encoder which can be used with any DST system. Our confnet encoder is plugged into the state-of-the-art'Global-locally Self-Attentive Dialogue State Tacker' (GLAD) model for DST and obtains significant improvements in both accuracy and inference time compared to using top-N ASR hypotheses.},
   author = {Vaishali Pal and Fabien Guillot and Jean Michel Renders and Laurent Besacier},
   issn = {23318422},
   journal = {arXiv},
   keywords = {Automatic Speech Recognition,Confusion Network,Neural Dialogue State Tracking,Spoken Dialogue Systems},
   pages = {2-6},
   title = {Modeling ASR ambiguity for neural dialogue state tracking using word confusion networks},
   year = {2020},
}
@article{Lewis2017,
   abstract = {Future robotic agents may be required to reason about a given situation and decide whether it is appropriate to lie to or deceive humans. One type of deception, known formally as strategic deception, is the act of influencing others toward a specific goal through non-truths. To demonstrate and test for the kind of reasoning required in strategic deception, we use a modified form of the social strategy game "Mafia" as a testing ground. In the game, the townsfolk, who can be seen as an uninformed majority, must determine who amongst themselves are members of the informed minority (the Mafia) via social cues before the Mafia eliminate all the townsfolk. First, we talk about how strategic deception applies to Mafia. We then present simplified rules for the game which can be formalized into a logic-based language. Once formalized, the rules can be provided to an automated theorem prover, which can carry out the necessary reasoning. By using this automated theorem prover we discuss how one can demonstrate automated strategic deception.},
   author = {Brad Lewis and Isaac Smith and Max Fowler and John Licato},
   doi = {10.1145/1235},
   isbn = {9781450321389},
   journal = {28th Modern Artificial Intelligence and Cognitive Science Conference, MAICS 2017},
   keywords = {Robots,Social Games,Strategic Deception},
   pages = {189-190},
   title = {Query Intent Detection using Convolutional Neural Networks},
   year = {2017},
}
@article{Mitra2019,
   abstract = {Classical information retrieval (IR) methods, such as query likelihood and BM25, score documents independently w.r.t. each query term, and then accumulate the scores. Assuming query term independence allows precomputing term-document scores using these models - which can be combined with specialized data structures, such as inverted index, for efficient retrieval. Deep neural IR models, in contrast, compare the whole query to the document and are, therefore, typically employed only for late stage re-ranking. We incorporate query term independence assumption into three state-of-the-art neural IR models: BERT, Duet, and CKNRM - and evaluate their performance on a passage ranking task. Surprisingly, we observe no significant loss in result quality for Duet and CKNRM - and a small degradation in the case of BERT. However, by operating on each query term independently, these otherwise computationally intensive models become amenable to offline precomputation - dramatically reducing the cost of query evaluations employing state-ofthe-art neural ranking models. This strategy makes it practical to use deep models for retrieval from large collections - and not restrict their usage to late stage re-ranking.},
   author = {Bhaskar Mitra and Corby Rosset and David Hawking and Nick Craswell and Fernando Diaz and Emine Yilmaz},
   issn = {23318422},
   journal = {arXiv},
   keywords = {Deep learning,Indexing,Information retrieval,Query evaluation},
   title = {Incorporating query term independence assumption for efficient retrieval and ranking using deep neural networks},
   year = {2019},
}
@article{Keneshloo2020,
   abstract = {In recent times, sequence-to-sequence (seq2seq) models have gained a lot of popularity and provide state-of-the-art performance in a wide variety of tasks, such as machine translation, headline generation, text summarization, speech-to-text conversion, and image caption generation. The underlying framework for all these models is usually a deep neural network comprising an encoder and a decoder. Although simple encoder-decoder models produce competitive results, many researchers have proposed additional improvements over these seq2seq models, e.g., using an attention-based model over the input, pointer-generation models, and self-attention models. However, such seq2seq models suffer from two common problems: 1) exposure bias and 2) inconsistency between train/test measurement. Recently, a completely novel point of view has emerged in addressing these two problems in seq2seq models, leveraging methods from reinforcement learning (RL). In this survey, we consider seq2seq problems from the RL point of view and provide a formulation combining the power of RL methods in decision-making with seq2seq models that enable remembering long-term memories. We present some of the most recent frameworks that combine the concepts from RL and deep neural networks. Our work aims to provide insights into some of the problems that inherently arise with current approaches and how we can address them with better RL models. We also provide the source code for implementing most of the RL models discussed in this paper to support the complex task of abstractive text summarization and provide some targeted experiments for these RL models, both in terms of performance and training time.},
   author = {Yaser Keneshloo and Tian Shi and Naren Ramakrishnan and Chandan K. Reddy},
   doi = {10.1109/TNNLS.2019.2929141},
   issn = {21622388},
   issue = {7},
   journal = {IEEE Transactions on Neural Networks and Learning Systems},
   keywords = {Actor critic (AC) methods,Q-learning,deep learning,policy gradients (PGs),reinforcement learning (RL),sequence-to-sequence (seq2seq) learning},
   pages = {2469-2489},
   pmid = {31425057},
   title = {Deep Reinforcement Learning for Sequence-to-Sequence Models},
   volume = {31},
   year = {2020},
}
@article{Zhang2021,
   abstract = {Training machines to understand natural language and interact with humans is an elusive and essential task in the field of artificial intelligence. In recent years, a diversity of dialogue systems has been designed with the rapid development of deep learning researches, especially the recent pre-trained language models. Among these studies, the fundamental yet challenging part is dialogue comprehension whose role is to teach the machines to read and comprehend the dialogue context before responding. In this paper, we review the previous methods from the perspective of dialogue modeling. We summarize the characteristics and challenges of dialogue comprehension in contrast to plain-text reading comprehension. Then, we discuss three typical patterns of dialogue modeling that are widely-used in dialogue comprehension tasks such as response selection and conversation question-answering, as well as dialogue-related language modeling techniques to enhance PrLMs in dialogue scenarios. Finally, we highlight the technical advances in recent years and point out the lessons we can learn from the empirical analysis and the prospects towards a new frontier of researches.},
   author = {Zhuosheng Zhang and Hai Zhao},
   title = {Advances in Multi-turn Dialogue Comprehension: A Survey},
   url = {http://arxiv.org/abs/2103.03125},
   year = {2021},
}
@inproceedings{Paulus2018,
   abstract = {Attentional, RNN-based encoder-decoder models for abstractive summarization have achieved good performance on short input and output sequences. For longer documents and summaries however these models often include repetitive and incoherent phrases. We introduce a neural network model with a novel intra-attention that attends over the input and continuously generated output separately, and a new training method that combines standard supervised word prediction and reinforcement learning (RL). Models trained only with supervised learning often exhibit “exposure bias” – they assume ground truth is provided at each step during training. However, when standard word prediction is combined with the global sequence prediction training of RL the resulting summaries become more readable. We evaluate this model on the CNN/Daily Mail and New York Times datasets. Our model obtains a 41.16 ROUGE-1 score on the CNN/Daily Mail dataset, an improvement over previous state-of-the-art models. Human evaluation also shows that our model produces higher quality summaries.},
   author = {Romain Paulus and Caiming Xiong and Richard Socher},
   issue = {i},
   journal = {6th International Conference on Learning Representations, ICLR 2018},
   pages = {1-12},
   title = {A Deep Reinforced Model for Abstractive Summarization},
   year = {2018},
}
@article{Ueyama2021,
   abstract = {Dialogue systems using deep learning have achieved generation of fluent response sentences to user utterances. Nevertheless, they tend to produce responses that are not diverse and which are less context-dependent. To address these shortcomings, we propose a new loss function, an Inverse N-gram loss (INF), which incorporates contextual fluency and diversity at the same time by a simple formula. Our INF loss can adjust its loss dynamically by a weight using the inverse frequency of the tokens\{'\} n-gram applied to Softmax Cross-Entropy loss, so that rare tokens appear more likely while retaining the fluency of the generated sentences. We trained Transformer using English and Japanese Twitter replies as single-turn dialogues using different loss functions. Our INF loss model outperformed the baselines of SCE loss and ITF loss models in automatic evaluations such as DIST-N and ROUGE, and also achieved higher scores on our human evaluations of coherence and richness.},
   author = {Ayaka Ueyama and Yoshinobu Kano},
   doi = {10.18653/v1/2020.coling-main.364},
   issue = {Mmi},
   pages = {4123-4127},
   title = {Diverse dialogue generation with context dependent dynamic loss function},
   year = {2021},
}
@article{Vakulenko2020a,
   abstract = {The dependency between an adequate question formulation and correct answer selection is a very intriguing but still underexplored area. In this paper, we show that question rewriting (QR) of the conversational context allows to shed more light on this phenomenon and also use it to evaluate robustness of different answer selection approaches. We introduce a simple framework that enables an automated analysis of the conversational question answering (QA) performance using question rewrites, and present the results of this analysis on the TREC CAsT and QuAC (CANARD) datasets. Our experiments uncover sensitivity to question formulation of the popular state-of-the-art models for reading comprehension and passage ranking. Our results demonstrate that the reading comprehension model is insensitive to question formulation, while the passage ranking changes dramatically with a little variation in the input question. The benefit of QR is that it allows us to pinpoint and group such cases automatically. We show how to use this methodology to verify whether QA models are really learning the task or just finding shortcuts in the dataset, and better understand the frequent types of error they make.},
   author = {Svitlana Vakulenko and Shayne Longpre and Zhucheng Tu and Raviteja Anantha},
   doi = {10.18653/v1/2020.scai-1.2},
   pages = {7-16},
   title = {A Wrong Answer or a Wrong Question? An Intricate Relationship between Question Reformulation and Answer Selection in Conversational Question Answering},
   year = {2020},
}
@article{Regan2019,
   abstract = {We present Contextual Query Rewrite (CQR) a dataset for multi-domain task-oriented spoken dialogue systems that is an extension of the Stanford dialog corpus (Eric et al., 2017a). While previous approaches have addressed the issue of diverse schemas by learning candidate transformations (Naik et al., 2018), we instead model the reference resolution task as a user query reformulation task, where the dialog state is serialized into a natural language query that can be executed by the downstream spoken language understanding system. In this paper, we describe our methodology for creating the query reformulation extension to the dialog corpus, and present an initial set of experiments to establish a baseline for the CQR task. We have released the corpus to the public1 to support further research in this area.},
   author = {Michael Regan and Pushpendre Rastogi and Arpit Gupta and Lambert Mathias},
   issn = {23318422},
   journal = {arXiv},
   title = {A dataset for resolving referring expressions in spoken dialogue via contextual query rewrites (CQR)},
   year = {2019},
}
@article{Rajbhandari2019,
   abstract = {Training large DL models with billions and potentially trillions of parameters is challenging. Existing solutions exhibit fundamental limitations to obtain both memory and scaling (computation/communication) efficiency together. Data parallelism does not help reduce memory footprint per device: a model with 1.5 billion parameters or more runs out of memory. Model parallelism hardly scales efficiently beyond multiple devices of a single node due to fine-grained computation and expensive communication. We develop a novel solution, Zero Redundancy Optimizer (ZeRO), to optimize memory, achieving both memory efficiency and scaling efficiency. Unlike basic data parallelism where memory states are replicated across data-parallel processes, ZeRO partitions model states instead, to scale the model size linearly with the number of devices. Furthermore, it retains scaling efficiency via computation and communication rescheduling and by reducing the model parallelism degree required to run large models. Our analysis on memory requirements and communication volume demonstrates: ZeRO has the potential to scale beyond 1 Trillion parameters using today’s hardware (e.g., 1024 GPUs, 64 DGX-2 nodes). To meet near-term scaling goals and serve as a demonstration of ZeRO’s capability, we implemented stage-1 optimizations of ZeRO (out of 3 stages in total described in the paper) and tested this ZeRO-OS version. ZeRO-OS reduces memory and boosts model size by 4x compared with the state-of-art, scaling up to 100B parameters. Moving forward, we will work on unlocking stage-2 optimizations, with up to 8x memory savings per device, and ultimately stage-3 optimizations, reducing memory linearly with respect to the number of devices and potentially scaling to models of arbitrary size. We are excited to transform very large models from impossible to train to feasible and efficient to train!},
   author = {Samyam Rajbhandari and Jeff Rasley and Olatunji Ruwase and Yuxiong He},
   issn = {23318422},
   journal = {arXiv},
   pages = {1-24},
   title = {ZeRO: Memory optimization towards training a trillion parameter models},
   year = {2019},
}
@article{Vakulenko2020,
   abstract = {Conversational question answering (QA) requires answers conditioned on the previous turns of the conversation. We address the conversational QA task by decomposing it into question rewriting and question answering subtasks, and conduct a systematic evaluation of this approach on two publicly available datasets. Question rewriting is designed to reformulate ambiguous questions, dependent on the conversation context, into unambiguous questions that are fully interpretable outside of the conversation context. Thereby, standard QA components can consume such explicit questions directly. The main benefit of this approach is that the same questions can be used for querying different information sources, e.g., multiple 3rd-party QA services simultaneously, as well as provide a human-readable interpretation of the question in context. To the best of our knowledge, we are the first to evaluate question rewriting on the conversational question answering task and show its improvement over the end-to-end baselines. Moreover, our conversational QA architecture based on question rewriting sets the new state of the art on the TREC CAsT 2019 dataset with a 28% improvement in MAP and 21% in NDCG@3. Our detailed analysis of the evaluation results provide insights into the sensitivity of QA models to question reformulation, and demonstrates the strengths and weaknesses of the retrieval and extractive QA architectures, that should be reflected in their integration.},
   author = {Svitlana Vakulenko and Shayne Longpre and Zhucheng Tu and Raviteja Anantha},
   issn = {23318422},
   journal = {arXiv},
   keywords = {Conversational question answering,Question answering,Question rewriting},
   pages = {0-8},
   title = {Question Rewriting for Conversational Question Answering},
   year = {2020},
}
@article{Lin2020a,
   abstract = {Passage retrieval in a conversational context is essential for many downstream applications; it is however extremely challenging due to limited data resources. To address this problem, we present an effective multi-stage pipeline for passage ranking in conversational search that integrates a widely-used IR system with a conversational query reformulation module. Along these lines, we propose two simple yet effective query reformulation approaches: historical query expansion (HQE) and neural transfer reformulation (NTR). Whereas HQE applies query expansion, a traditional IR query reformulation technique, NTR transfers human knowledge of conversational query understanding to a neural query reformulation model. The proposed HQE method was the top-performing submission of automatic systems in CAsT Track at TREC 2019. Building on this, our NTR approach improves an additional 18% over that best entry in terms of NDCG@3. We further analyze the distinct behaviors of the two approaches, and show that fusing their output reduces the performance gap (measured in NDCG@3) between the manually-rewritten and automatically-generated queries to 4 from 22 points when compared with the best CAsT submission.},
   author = {Sheng-Chieh Lin and Jheng-Hong Yang and Rodrigo Nogueira and Ming-Feng Tsai and Chuan-Ju Wang and Jimmy Lin},
   issn = {23318422},
   journal = {arXiv},
   title = {Query Reformulation using Query History for Passage Retrieval in Conversational Search},
   year = {2020},
}
@article{Nogueira2019,
   abstract = {Recently, neural models pretrained on a language modeling task, such as ELMo (Peters et al., 2017), OpenAI GPT (Radford et al., 2018), and BERT (Devlin et al., 2018), have achieved impressive results on various natural language processing tasks such as question-answering and natural language inference. In this paper, we describe a simple re-implementation of BERT for query-based passage re-ranking. Our system is the state of the art on the TREC-CAR dataset and the top entry in the leaderboard of the MS MARCO passage retrieval task, outperforming the previous state of the art by 27% (relative) in MRR@10. The code to reproduce our results is available at https://github.com/nyu-dl/ dl4marco-bert.},
   author = {Rodrigo Nogueira and Kyunghyun Cho},
   issn = {23318422},
   journal = {arXiv},
   pages = {1-5},
   title = {Passage Re-ranking with BERT},
   year = {2019},
}
@article{Gao2020a,
   author = {Jianfeng Gao and Chenyan Xiong and Paul Bennett},
   title = {Recent Advances in Conversational Information Retrieval ( CIR ) - A review of neural approaches},
   volume = {2020},
   year = {2020},
}
@article{Gao2020,
   abstract = {Recent progress in deep learning has brought tremendous improvements in conversational AI, leading to a plethora of commercial conversational services that allow naturally spoken interactions, increasing the need for more human-centric interactions in IR. As a result, we have witnessed a resurgent interest in developing modern CIR systems in research communities and industry. This tutorial presents recent advances in CIR, focusing mainly on neural approaches and new applications developed in the past five years. Our goal is to provide a thorough and in-depth overview of the general definition of CIR, the components of CIR systems, new applications raised for its conversational aspects, and the (neural) techniques recently developed for it.},
   author = {Jianfeng Gao and Chenyan Xiong and Paul Bennett},
   doi = {10.1145/3397271.3401418},
   isbn = {9781450380164},
   journal = {SIGIR 2020 - Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval},
   keywords = {conversational information retrieval,conversational search},
   pages = {2421-2424},
   title = {Recent Advances in Conversational Information Retrieval},
   year = {2020},
}
@article{Lin2020,
   abstract = {The goal of text ranking is to generate an ordered list of texts retrieved from a corpus in response to a query for a particular task. Although the most common formulation of text ranking is search, instances of the task can also be found in many natural language processing applications. This survey provides an overview of text ranking with neural network architectures known as transformers, of which BERT is the best-known example. The combination of transformers and self-supervised pretraining has, without exaggeration, revolutionized the fields of natural language processing (NLP), information retrieval (IR), and beyond. In the context of text ranking, these models produce high quality results across many domains, tasks, and settings. In this survey, we provide a synthesis of existing work as a single point of entry for practitioners who wish to gain a better understanding of how to apply transformers to text ranking problems and researchers who wish to pursue work in this area. We cover a wide range of modern techniques, grouped into two high-level categories: transformer models that perform reranking in multi-stage ranking architectures and learned dense representations that attempt to perform ranking directly. There are numerous examples that fall into the first category, including approaches based on relevance classification, evidence aggregation from multiple segments of text, corpus analysis, and sequence-to-sequence models. While the second category of approaches is less well studied, representation learning with transformers is an emerging and exciting direction that is bound to attract more attention moving forward. There are two themes that pervade our survey: techniques for handling long documents, beyond the typical sentence-by-sentence processing approaches used in NLP, and techniques for addressing the tradeoff between effectiveness (result quality) and efficiency (query latency). Although transformer architectures and pretraining techniques are recent innovations, many aspects of how they are applied to text ranking are relatively well understood and represent mature techniques. However, there remain many open research questions, and thus in addition to laying out the foundations of pretrained transformers for text ranking, this survey also attempts to prognosticate where the field is heading.},
   author = {Jimmy Lin and Rodrigo Nogueira and Andrew Yates},
   issn = {23318422},
   journal = {arXiv},
   title = {Pretrained Transformers for Text Ranking: BERT and Beyond},
   year = {2020},
}
@inproceedings{Shen2018,
   abstract = {This paper proposes a layered semantic graph representation for dialogue information. The representation factors information into several interdependent layers, facilitating efficient information access and processing by the components in a dialogue system. We describe the layers in the semantic graph and the function they serve in an implemented task-oriented dialogue system.},
   author = {Jiaying Shen and Hendrik Harkema and Richard Crouch and Peng Yu and Ciaran O'reilly},
   journal = {Proc. of the Workshop on the Semantics and Pragmatics of Dialogue (SemDial)},
   title = {Layered Semantic Graphs for Dialogue Management},
   year = {2018},
}
@article{Dalton2019,
   author = {Jeffrey Dalton and Chenyan Xiong and Jamie Callan},
   title = {CAsT 2019: The Conversational Assistance Track Overview},
   year = {2020},
}
@inproceedings{Abend2017,
   abstract = {Semantic representation is receiving growing attention in NLP in the past few years, and many proposals for semantic schemes (e.g., AMR, UCCA, GMB, UDS) have been put forth. Yet, little has been done to assess the achievements and the shortcomings of these new contenders, compare them with syntactic schemes, and clarify the general goals of research on semantic representation. We address these gaps by critically surveying the state of the art in the field.},
   author = {Omri Abend and Ari Rappoport},
   doi = {10.18653/v1/P17-1008},
   isbn = {9781945626753},
   journal = {Proc. of the Annual Meeting of the Association for Computational Linguistics},
   pages = {77-89},
   title = {The State of the Art in Semantic Representation},
   volume = {1},
   year = {2017},
}
@inproceedings{Banarescu2013,
   abstract = {We describe Abstract Meaning Representation (AMR), a semantic representation language in which we are writing down the meanings of thousands of English sentences. We hope that a sembank of simple, whole-sentence semantic structures will spur new work in statistical natural language understanding and generation, like the Penn Treebank encouraged work on statistical parsing. This paper gives an overview of AMR and tools associated with it.},
   author = {Laura Banarescu and Claire Bonial and Shu Cai and Madalina Georgescu and Kira Griffitt and Ulf Hermjakob and Kevin Knight and Philipp Koehn and Martha Palmer and Nathan Schneider},
   isbn = {9781937284589},
   journal = {Proc. of the Linguistic Annotation Workshop and Interoperability with Discourse},
   pages = {178-186},
   title = {Abstract Meaning Representation for Sembanking},
   year = {2013},
}
@inproceedings{Schubert2015,
   abstract = {In recent years, there has been renewed interest in the NLP community in genuine language understanding and dialogue. Thus the long-standing issue of how the semantic content of language should be represented is reentering the communal discussion. This paper provides a brief "opinionated survey" of broad-coverage semantic representation (SR). It suggests multiple desiderata for such representations, and then outlines more than a dozen approaches to SR-some long-standing, and some more recent, providing quick characterizations , pros, cons, and some comments on implementations .},
   author = {Lenhart Schubert},
   journal = {Proc. of the AAAI Conference},
   keywords = {intelligent tutoring systems,language agnostic,semantic analysis,vocabulary},
   pages = {1-12},
   title = {Semantic Representation},
   url = {www.aaai.org},
   year = {2015},
}
@inproceedings{Kollar2018,
   abstract = {This paper introduces a meaning representation for spoken language understanding. The Alexa meaning representation language (AMRL), unlike previous approaches, which factor spoken utterances into domains, provides a common representation for how people communicate in spoken language. AMRL is a rooted graph, links to a large-scale ontology, supports cross-domain queries, finegrained types, complex utterances and composition. A spoken language dataset has been collected for Alexa, which contains ∼ 20k examples across eight domains. A version of this meaning representation was released to developers at a trade show in 2016.},
   author = {Thomas Kollar and Danielle Berry and Lauren Stuart and Karolina Owczarzak and Tagyoung Chung and Lambert Mathias and Michael Kayser and Bradford Snow and Spyros Matsoukas},
   doi = {10.18653/v1/n18-3022},
   isbn = {9781948087308},
   journal = {Proc. of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies},
   pages = {177-184},
   title = {The Alexa Meaning Representation Language},
   volume = {3},
   year = {2018},
}
@inproceedings{Padmakumar2017,
   abstract = {Natural language understanding and dialog management are two integral components of interactive dialog systems. Previous research has used machine learning techniques to individually optimize these components, with different forms of direct and indirect supervision. We present an approach to integrate the learning of both a dialog strategy using reinforcement learning, and a semantic parser for robust natural language understanding, using only natural dialog interaction for supervision. Experimental results on a simulated task of robot instruction demonstrate that joint learning of both components improves dialog performance over learning either of these components alone.},
   author = {Aishwarya Padmakumar and Jesse Thomason and Raymond J. Mooney},
   doi = {10.18653/v1/e17-1052},
   isbn = {9781510838604},
   journal = {Proc. of the EACL},
   title = {Integrated Learning of Dialog Strategies and Semantic Parsing},
   year = {2017},
}
@inproceedings{Bonial2019,
   abstract = {In this research, we begin to tackle the challenge of natural language understanding (NLU) in the context of the development of a robot dialogue system. We explore the adequacy of Abstract Meaning Representation (AMR) as a conduit for NLU. First, we consider the feasibility of using existing AMR parsers for automatically creating meaning representations for robot-directed transcribed speech data. We evaluate the quality of output of two parsers on this data against a manually annotated gold-standard data set. Second, we evaluate the semantic coverage and distinctions made in AMR overall: how well does it capture the meaning and distinctions needed in our collaborative human-robot dialogue do-main? We find that AMR has gaps that align with linguistic information critical for effective human-robot collaboration in search and navigation tasks, and we present task-specific modifications to AMR to address the deficiencies .},
   author = {Claire Bonial and Lucia Donatelli and Jessica Ervin and Clare R. Voss},
   doi = {10.18653/v1/w19-3322},
   journal = {Proc. of the Society for Computation in Linguistics},
   title = {Abstract Meaning Representation for Human-Robot Dialogue},
   year = {2019},
}
@article{Daza2018,
   abstract = {We explore a novel approach for Semantic Role Labeling (SRL) by casting it as a sequence-to-sequence process. We employ an attention-based model enriched with a copying mechanism to ensure faithful regeneration of the input sequence, while enabling interleaved generation of argument role labels. Here, we apply this model in a monolingual setting, performing PropBank SRL on English language data. The constrained sequence generation set-up enforced with the copying mechanism allows us to analyze the performance and special properties of the model on manually labeled data and benchmarking against state-of-the-art sequence labeling models. We show that our model is able to solve the SRL argument labeling task on English data, yet further structural decoding constraints will need to be added to make the model truly competitive. Our work represents a first step towards more advanced, generative SRL labeling setups.},
   author = {Angel Daza and Anette Frank},
   doi = {10.18653/v1/w18-3027},
   issn = {23318422},
   journal = {arXiv},
   title = {A Sequence-to-Sequence Model for Semantic Role Labeling},
   year = {2018},
}
@book{Jurafsky2008,
   author = {Daniel Jurafsky and James Martin},
   edition = {3rd},
   title = {Speech and Language Processing: An Introduction to Natural Language Processing, Computational Linguistics and Speech Recognition},
   year = {2019},
}
@article{Rastogi2019,
   abstract = {Virtual assistants such as Google Assistant, Alexa and Siri provide a conversational interface to a large number of services and APIs spanning multiple domains. Such systems need to support an ever-increasing number of services with possibly overlapping functionality. Furthermore, some of these services have little to no training data available. Existing public datasets for task-oriented dialogue do not sufficiently capture these challenges since they cover few domains and assume a single static ontology per domain. In this work, we introduce the the Schema-Guided Dialogue (SGD) dataset, containing over 16k multi-domain conversations spanning 16 domains. Our dataset exceeds the existing task-oriented dialogue corpora in scale, while also highlighting the challenges associated with building large-scale virtual assistants. It provides a challenging testbed for a number of tasks including language understanding, slot filling, dialogue state tracking and response generation. Along the same lines, we present a schema-guided paradigm for task-oriented dialogue, in which predictions are made over a dynamic set of intents and slots, provided as input, using their natural language descriptions. This allows a single dialogue system to easily support a large number of services and facilitates simple integration of new services without requiring additional training data. Building upon the proposed paradigm, we release a model for dialogue state tracking capable of zero-shot generalization to new APIs, while remaining competitive in the regular setting.},
   author = {Abhinav Rastogi and Xiaoxue Zang and Srinivas Sunkara and Raghav Gupta and Pranav Khaitan},
   title = {Towards Scalable Multi-domain Conversational Agents: The Schema-Guided Dialogue Dataset},
   url = {http://arxiv.org/abs/1909.05855},
   year = {2019},
}
@conference{Wang2004,
title = "BIDE: Efficient mining of frequent closed sequences",
abstract = "Previous studies have presented convincing arguments that a frequent pattern mining algorithm should not mine all frequent patterns but only the closed ones because the latter leads to not only more compact yet complete result set but also better efficiency. However, most of the previously developed closed pattern mining algorithms work under the candidate maintenance-and-test paradigm which is inherently costly in both runtime and space usage when the support threshold is low or the patterns become long. In this paper, we present, BIDE, an efficient algorithm for mining frequent closed sequences without candidate maintenance. It adopts a novel sequence closure checking scheme called BI-Directional Extension, and prunes the search space more deeply compared to the previous algorithms by using the BackScan pruning method and the Scan-Skip optimization technique. A thorough performance study with both sparse and dense real-life data sets has demonstrated that BIDE significantly outperforms the previous algorithms: it consumes order(s) of magnitude less memory and can be more than an order of magnitude faster. It is also linearly scalable in terms of database size.",
author = "Jianyong Wang and Jiawei Han",
year = "2004",
month = jun,
day = "1",
language = "English (US)",
pages = "79--90",
note = "Proceedings - 20th International Conference on Data Engineering - ICDE 2004 ; Conference date: 30-03-2004 Through 02-04-2004",
}
@inproceedings{Gao2008,
author = {Gao, Chuancong and Wang, Jianyong and He, Yukai and Zhou, Lizhu},
title = {Efficient Mining of Frequent Sequence Generators},
year = {2008},
isbn = {9781605580852},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1367497.1367651},
doi = {10.1145/1367497.1367651},
abstract = {Sequential pattern mining has raised great interest in data mining research field in recent years. However, to our best knowledge, no existing work studies the problem of frequent sequence generator mining. In this paper we present a novel algorithm, FEAT (abbr. Frequent sEquence generATor miner), to perform this task. Experimental results show that FEAT is more efficient than traditional sequential pattern mining algorithms but generates more concise result set, and is very effective for classifying Web product reviews.},
booktitle = {Proceedings of the 17th International Conference on World Wide Web},
pages = {1051–1052},
numpages = {2},
keywords = {sequence generators, sequence, web mining},
location = {Beijing, China},
series = {WWW '08}
}
