{
  "title": "Fair Machine Unlearning: Data Removal while Mitigating Disparities",
  "authors": [
    "Alex Oesterling",
    "Jiaqi Ma",
    "Flavio P. Calmon",
    "Hima Lakkaraju"
  ],
  "submission_date": "2023-07-27T10:26:46+00:00",
  "revised_dates": [
    "2024-02-16T01:42:48+00:00"
  ],
  "abstract": "The Right to be Forgotten is a core principle outlined by regulatory frameworks such as the EU's General Data Protection Regulation (GDPR). This principle allows individuals to request that their personal data be deleted from deployed machine learning models. While \"forgetting\" can be naively achieved by retraining on the remaining dataset, it is computationally expensive to do to so with each new request. As such, several machine unlearning methods have been proposed as efficient alternatives to retraining. These methods aim to approximate the predictive performance of retraining, but fail to consider how unlearning impacts other properties critical to real-world applications such as fairness. In this work, we demonstrate that most efficient unlearning methods cannot accommodate popular fairness interventions, and we propose the first fair machine unlearning method that can efficiently unlearn data instances from a fair objective. We derive theoretical results which demonstrate that our method can provably unlearn data and provably maintain fairness performance. Extensive experimentation with real-world datasets highlight the efficacy of our method at unlearning data instances while preserving fairness.",
  "categories": [
    "cs.LG",
    "cs.AI"
  ],
  "primary_category": "cs.LG",
  "doi": null,
  "journal_ref": null,
  "arxiv_id": "2307.14754",
  "pdf_url": "https://arxiv.org/pdf/2307.14754v2",
  "comment": "25 pages, 3 figures, accepted to AISTATS 2024. Code is provided at https://github.com/AI4LIFE-GROUP/fair-unlearning",
  "num_versions": null,
  "size_before_bytes": 23473740,
  "size_after_bytes": 793406
}