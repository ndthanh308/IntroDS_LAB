In this section, we introduce the proposed fair unlearning method. Our method builds upon a convex fair learning loss, and provides an algorithm that can efficiently unlearn requested data points from a model trained with fair loss. We also provide theoretical guarantees on both the effectiveness of unlearning and the fairness of the model unlearned by our method. We develop the algorithm and theory in the context of logistic regression, however, our method can also be easily extended to unlearn the final linear layer of a neural network model. \citet{guoCertifiedDataRemoval2020} show that combining an unlearnable linear layer with a DP-SGD trained neural network preserves unlearning guarantees.
% We begin by introducing a fair regularizer and explore how to achieve the nontrivial task of unlearning with this modified objective. We then show our update provably achieves unlearning defined by Definition~\ref{unlearning_definition} while maintaining performance similar to retraining in terms of accuracy as well as equalized odds according to Definition~\ref{equalizedodds}.

\subsection{A Convex Fair Learning Loss}
To simultaneously achieve fairness and provable unlearning, we leverage a convex fair learning loss introduced by \citet{berk2017convex}. This fair loss can effectively optimize for several popular notions of group fairness, including Equalized Odds. In addition, the inherent convexity of this loss offers mathematical convenience in the development of our provable unlearning algorithm. 

Formally, the fair loss consists of two parts. The first part is a binary cross-entropy (BCE) loss for binary classification:
\begin{align}
    \mathcal{L}_\textrm{BCE}(\theta, D) = \frac{1}{n}\sum_{i = 1}^{n} \ell(\theta,x_i, y_i) + \frac{\lambda}{2}||\theta||_2^2, \label{bceloss}
\end{align}
where $\ell(\theta,x_i, y_i) = -y_i\log(\langle x_i,\theta\rangle) - (1-y_i) \log(1 - \langle x_i,\theta\rangle)$ is the logistic loss.

% To achieve fairness, we include an additional fairness loss term in our objective function. Unlearning guarantees require a convex objective function to achieve $(\epsilon, \delta)$-statistical indistinguishability, so we choose a convex loss function introduced by \citet{berk2017convex}.
% \alex{should I make this a definition or something more formal?}

The second part is a fairness regularizer. Let $G_a := \{i : s_i = a\}$, $G_b := \{i : s_i = b\}$ be sets of indices indicating subgroup membership for each sample in dataset $D$ with $n_a = |G_a|$ and $n_b = |G_b|$. The fairness regularizer is defined as the following:
\begin{align}
    &\mathcal{L}_\textrm{fair}(\theta, D) := \nonumber \\
    &\qquad\left(\frac{1}{n_an_b} \sum_{i \in G_a}\sum_{j \in G_b} \mathbbm{1}[y_i = y_j](\langle x_i,\theta\rangle - \langle x_j, \theta\rangle) \right)^2. \label{eqn:pairwisefair}
\end{align}
In simple terms, $\mathcal{L}_\textrm{fair}$ penalizes the pairwise difference in logits for samples with the same label between subgroups. Because $\mathcal{L}_\textrm{fair}$ considers samples that share a label regardless of label value, this term directly optimizes for Equalized Odds from Definition~\ref{equalizedodds}. The full fair loss becomes
\begin{align}
    \mathcal{L}(\theta, D) = \mathcal{L}_\textrm{BCE}(\theta, D) + \gamma\mathcal{L}_\textrm{fair}(\theta, D), \label{fairloss}
\end{align}
where $\gamma$ is the fairness regularization parameter.

Most existing unlearning methods~\citep{guoCertifiedDataRemoval2020,izzoApproximateDataDeletion,neelDescenttoDeleteGradientBasedMethods2020a} are specifically designed to unlearn over objective functions like Eq.~(\ref{bceloss}), where the objective constitutes a sum of independent functions on each data point. However, the introduction of the fairness regularizer $\mathcal{L}_\textrm{fair}(\theta, D)$ (and most other fairness regularizers alike~\citep{beutel2019fairness}) entangles the influence of data points, rendering existing unlearning methods inapplicable.

\subsection{The Fair Unlearning Algorithm}
Recall the goal of an unlearning algorithm $M$ is to efficiently update the model $A(D)$, such that $M(A(D), D, R)$ is close to $A(D\setminus R)$. With the concrete definition of the fair loss, we can represent the fully trained model $A(D)$ by its parameters $\theta_D^* := \arg\min_{\theta} \mathcal{L}(\theta, D)$. Similarly, the retrained model $A(D\setminus R)$ corresponds to parameters $\theta_{D'}^* := \arg\min_{\theta} \mathcal{L}(\theta, D')$, where we define $D' := D\setminus R$ for simplicity.

Similar to several existing unlearning methods~\citep{guoCertifiedDataRemoval2020,neelDescenttoDeleteGradientBasedMethods2020a}, our fair unlearning method consists of two major parts. The first part conducts an efficient update on $\theta_D^*$ to obtain updated model parameters $\theta_{D'}^-$. The goal of this part is to make the updated model parameters $\theta_{D'}^-$ close to the retrained model parameters $\theta_{D'}^*$. Then the second part adds noise to the loss function such that both $A(D)$ and $A(D')$ are randomized, from which we can establish a statistical indistinguishability result between $M(\theta_D^*, D, R)$ and $A(D')$.

\paragraph{Efficient Model Update.}
We first introduce the efficient model update. To simplify notations, we can unroll the squared double sum in Eq.~(\ref{eqn:pairwisefair}) into a single sum using a Cartesian product. Define $N := G_a \times G_b \times G_a \times G_b$. Then we can write $\mathcal{L}_\textrm{fair}$ as
\begin{align}
    \mathcal{L}_\textrm{fair}(\theta, D) = \frac{1}{|N|} \sum_{(i, j, k, l) \in N} \ell_\textrm{fair}(\theta, \{(x_m, y_m)\}_{m \in \{i,j,k,l\}}), \nonumber\\[-15pt]
\end{align}
% \vspace{-10pt}
where
\begin{align}
    &\ell_\textrm{fair}(\theta, \{(x_m, y_m)\}_{m \in \{i,j,k,l\}}) := \nonumber\\
    &\mathbbm{1}[y_i = y_j](\langle x_i, \theta\rangle - \langle x_j, \theta\rangle)\mathbbm{1}[y_k = y_l](\langle x_k, \theta\rangle - \langle x_l, \theta\rangle). 
\end{align}

Without loss of generality, assume that we want to remove one single data point, the final sample $(x_n, y_n, s_n)$, and that this sample comes from subgroup $a$, i.e., $n \in G_a$. We propose an algorithm that updates $\theta_D^*$ to approximately minimize $\mathcal{L}(\theta, D')$ over the remaining dataset $D'= D\setminus R$ where $R = \{(x_n, y_n, s_n)\}$. Similar to \citet{guoCertifiedDataRemoval2020}, our algorithm takes a second-order Newton update from $\theta_D^*$, which results in $\theta_{D'}^-$. Let $C := \{n\} \times G_b \times \{n\} \times G_b$. We define a quantity $\Delta$ related to the residual difference between gradients over $D$ and $D'$ as follows:
\begin{align}
    &\Delta := \ell'(\theta^*, x_n, y_n) + \lambda \theta^* \nonumber \\
    &+\gamma\left(\frac{n}{|N|} - \frac{n-1}{|N\setminus C|}\right)\sum_{\mathclap{\substack{(i,j,k,l)\\  \in N \setminus C}}}\ell_\textrm{fair}'(\theta, \{(x_m, y_m)\}_{m \in \{i,j,k,l\}})\nonumber\\
    &+\gamma\frac{n}{|N|} \sum_{(i,j,k,l) \in C}\ell_\textrm{fair}'(\theta, \{(x_m, y_m)\}_{m \in \{i,j,k,l\}}).
\end{align}
Next, define the Hessian of the fair loss at $\theta_D^*$ over the remaining dataset $D'$ as $H_{\theta_D^*} = \nabla^2 \mathcal{L}(\theta_D^*, D')$. The update on the model parameters is obtained by:
\begin{align}
    \theta_{D'}^- = \theta_D^* + H_{\theta_D^*}^{-1}\Delta. \label{fairnewton}
\end{align}
% which is a Newton step over $\Delta$. \alex{I think I will remove this, any thoughts?} Note that $\Delta$ is not simply the gradient over our unlearned samples, $\nabla \mathcal{L}_{full}(\theta^*, R)$. The third term of $\Delta$ is a slightly modified factored form of $\mathcal{L}_\textrm{fair}(\theta^*, D)$ which permits us to guarantee unlearning.

% \begin{theorem}
% Assume the individual ERM loss terms $\ell$ are $\psi$-Lipschitz in their second derivative ($\ell''$ is $\psi$-Lipschitz) and bounded in their first derivative $||\ell'(\theta, x, y)|| \leq C$. Assume the data is bounded $||x_i||_2 \leq 1$ for all  $i \in n$. Then,
% \begin{align}
%     ||\nabla \mathcal{L}(\theta^-; \mathcal{D}')||_2 \leq \frac{\psi}{\lambda^2(n-1)}(2C + R)^2,
% \end{align}
% where $R$ is $O(1/n)$.
% \end{theorem} 

\paragraph{Noisy Loss Perturbation.}

% \subsection{Achieving Unlearning}

To achieve $(\epsilon, \delta)$-statistical indistinguishability, we add Gaussian noise to both the original model training and the retraining process. Specifically, we modify the loss function by an additional term $\textbf{b}^T\theta$, where $\textbf{b} \sim N(0, \sigma I)^d$, resulting in the perturbed loss function $\mathcal{L}^\textbf{b}(\theta, D) = \mathcal{L}(\theta, D) + \textbf{b}^T\theta$. 

\subsection{Theoretical Guarantees}

\paragraph{Theoretical Guarantee on Statistical Indistinguishability.}
When both the original training and retraining are randomized, the following Theorem~\ref{thm:eps_delta} provides a theoretical guarantee that our update step in Eq.~(\ref{fairnewton}) is $(\epsilon, \delta)$-indistinguishable from retraining for some $\epsilon, \delta > 0$.

% Past work by Guo et al. has shown that if an unlearning algorithm that outputs unlearned parameter $\theta^-$ has a bounded gradient over the remaining dataset $\mathcal{D}'$ (which we show for our method in Theorem \ref{thm1}), then the standard deviation of objective perturbation determines the values of $\epsilon$ and $\delta$. \alex{How do I cite another work's theorem?}. 

\begin{theorem}[$(\epsilon, \delta)$-unlearning.] \label{thm:eps_delta}
    Let $\theta^*$ be the output of algorithm $A$ trained on $\mathcal{L}^\textbf{b}$. Assume the logistic loss $\ell$ is $\psi$-Lipschitz in its second derivative ($\ell''$ is $\psi$-Lipschitz), and bounded in its first derivative by a constant $||\ell'(\theta, x, y)||_2 \leq g$. Assume the data is bounded such that for all $i \in n$, $||x_i||_2 \leq 1$. Then, 
    \begin{align}
        &||\nabla \mathcal{L}(\thetaunlearn; D')||_2 \leq  \nonumber \\
        &\qquad \frac{\psi}{\lambda^2(n-1)}\left(2g + ||\thetafull||_2\left|\left|\frac{8(n-1)}{n_a^2} \right|\right|_2\right)^2 ,
    \end{align}
    and if $\textbf{b} \sim N(0, k\epsilon'/\epsilon)^d$ with k $>$ 0 and $||\nabla \mathcal{L}(\thetaunlearn; D')||_2 \leq \epsilon'$, then the unlearning algorithm defined by Eq.~\ref{fairnewton} is $(\epsilon, \delta)$-unlearnable with $\delta = 1.5\exp(-k^2/2)$.
\end{theorem}
For logistic loss, we know $||\ell'(\theta, x, y)||_2 \leq 1$ and that $\ell''$ is $1/4$-Lipschitz.

Intuitively, our goal is to achieve Definition~\ref{unlearning_definition} by making the likelihood of a model being output by training approximately equal to the likelihood of that same model being output by unlearning. We do this by 1) ensuring the gradient of our unlearned model is bounded, which for strongly convex loss directly means our unlearned parameter $\thetaunlearn$ is close to the optimal retrained parameter $\thetaretrain$, and 2) adding a sufficient amount of noise to the training objective such that any parameter close to $\thetaretrain$ could have been generated by $A$.

\paragraph{Theoretical Guarantee on Fairness.}

Finally, we show that the model output by our method, $\theta_{D'}^-$, also has bounded increase on Absolute Equalized Odds Difference as defined in Eq.~(\ref{eq:aeod}) in comparison to the original model $\thetafull$. To ease notation, let us define 
\begin{align}
    &\text{AEOD}(\theta) := \frac{1}{2}\sum_{y\in \{0, 1\}}\big|P(h_{\theta}(X) = 1 \mid S = a, Y=y) \nonumber \\
    &\qquad-P(h_{\theta}(X) = 1 \mid S = b, Y=y)\big|,
\end{align}
where $h_{\theta}$ is the logistic regression model parameterized by $\theta$. Then we can formalize that $\text{AEOD}(\theta_{D'}^-)$ is bounded in the following Theorem~\ref{thm:fairnesG_bound}.

% To start, the following Theorem~\ref{thm:closeness} guarantees that \emph{the unlearned and fully-trained model parameters are close.}

% \begin{theorem}[$||\thetafull - \thetaunlearn||_2$ is bounded.]
%     \label{thm:closeness}
%     Assume both $\ell_\textrm{BCE}(\theta, x, y) := \ell(\theta, x, y) + \frac{2\lambda}{n}||\theta||_2^2$ and $\ell_\textrm{fair}$ are $L$-Lipschitz. Again assume $||x_i||_2 \leq 1$. Then,
%     \begin{align}
%         &\leq \frac{L(\frac{1}{n} + \gamma \frac{|C|}{|N|})+\sqrt{L(\frac{1}{n} + \gamma \frac{|C|}{|N|})^2+2m\frac{2}{n_a}(1+\frac{\lambda}{2})||\thetaretrain||_2}}{m} \nonumber \\
%         &+\frac{\psi}{\lambda^2(n-1)}\left(2c + ||\theta^*||_2\left|\left|\frac{8(n-1)}{n_a^2} \right|\right|_2\right)^2
%     \end{align}
% \end{theorem}

% Finally, this allows us to state Theorem~\ref{thm:fairnesG_bound}

\begin{theorem}[AEOD is bounded.] \label{thm:fairnesG_bound}
    Assume both $\ell_\textrm{BCE}(\theta, x, y) = \ell(\theta, x, y) + \frac{2\lambda}{n}||\theta||_2^2$ and $\ell_\textrm{fair}$ are $L$-Lipschitz. Suppose $\forall x \in \mathcal{X} \subseteq \mathbb{R}^d, ||x||_2 \leq 1$, and for all $\mathcal{Z} \subseteq \mathcal{X}$, the conditional probability $P(\mathcal{Z} | S, Y) \leq c\frac{|\mathcal{Z}|}{|\mathcal{X}|}$ for some $c\ge 1$, which controls the concentration of the probability distribution. Then, we can show that $||\thetafull-\thetaunlearn||_2 \leq \kappa$ for some $\kappa$ being $O(1/n)$. Furthermore, 
    % if the absolute equalized odds difference for $\thetafull$ is bounded such that
    % \begin{align}
    %     \text{AEOD}(\thetafull) \leq \alpha,
    % \end{align}
    % then 
    we have that the absolute equalized odds difference for $\thetaunlearn$ is bounded by
    \begin{align}
        &\text{AEOD}(\thetaunlearn) \leq \text{AEOD}(\thetafull) \nonumber \\
        & \qquad + c\left(1- \frac{2\int_{\mu}^{1}\frac{\pi^{\frac{d-1}{2}}}{\Gamma(\frac{d+1}{2})}(1-y^2)^{\frac{d-1}{2}} dy}{V}\right), \label{eq:aeodbound}
    \end{align}
    where $V$ is the volume of the unit $d$-sphere, and $\mu = O(\sqrt{\kappa})$.
\end{theorem}

As $n$ goes to infinity, $\kappa$ approaches 0, the integral $\int_{\mu}^{1}\frac{\pi^{\frac{d-1}{2}}}{\Gamma(\frac{d+1}{2})}(1-y^2)^{\frac{d-1}{2}} dy$ in Eq.~(\ref{eq:aeodbound}) evaluates to $V/2$. So the whole second term vanishes and the AEOD of the unlearned model approaches the AEOD of the original model. 
% Further, $\kappa$ is $O(1/n)$, providing a tight data-dependent bound on the difference in disparity.

% fairness:

% introduce regularizer

% unlearning:

% introduce our algorithm
% acknowledge guo et al

% theorem on unlearnability

% theorem on fairness loss

% introduce metrics:
% statistical parity
% equalized odds