Let $D = \{(x_1, y_1, s_1), \dots, (x_n, y_n, s_n)\} \in \mathcal{D}$ be a training dataset with size $n$, where $\mathcal{D}$ is the set of all possible datasets. For $i=1,2,\ldots, n$, $x_i \in \mathcal{X} \subseteq \mathbb{R}^d$ is a feature vector; $y_i \in \mathcal{Y} = \{0, 1\}$ is a binary label; and $s_i \in \mathcal{S} = \{a, b\}$ is a binary sensitive attribute. A learning algorithm is represented as a mapping $A: \mathcal{D} \rightarrow \mathcal{H}_\Theta$ that maps a dataset $D\in \mathcal{D}$ to a model $A(D)$ in a hypothesis space $\mathcal{H}$ parametrized by some $\theta \in \Theta$. 

\paragraph{Unlearning.} Given set of samples to be deleted $R \subseteq D$, the goal of unlearning is to efficiently find a model that resembles the model retrained on $D\setminus R$ from scratch. We define  an unlearning mechanism as a mapping $M: \mathcal{H}_\Theta \times \mathcal{D} \times \mathcal{D} \rightarrow \mathcal{H}_\Theta$ that maps a learned model $A(D)$, the original dataset $D$, and a subset $R\subseteq D$ of data points to be deleted, to a new unlearned model $M(A(D), D, R)$. Ideally, the unlearned model $M(A(D), D, R)$ is \emph{statistically indistinguishable} from $A(D\setminus R)$~\citep{guoCertifiedDataRemoval2020,neelDescenttoDeleteGradientBasedMethods2020a}. When both the learning algorithm $A$ and the unlearning mechanism $M$ are randomized, i.e., their outputs produce a probability distribution over the hypothesis $\mathcal{H}_\Theta$, the notion of statistical indistinguishability can be formalized as follows.

\begin{definition}[$(\epsilon, \delta)$-Statistical Indistinguishability~\citep{guoCertifiedDataRemoval2020, neelDescenttoDeleteGradientBasedMethods2020a}.]\label{unlearning_definition}

For given $\epsilon, \delta > 0$, an unlearning mechanism $M$ achieves \emph{$(\epsilon, \delta)$-Statistical Indistinguishability} with respect to $A$, if for all $ \mathcal{M} \subseteq \mathcal{H}_\Theta, D\in \mathcal{D}, R \subseteq D$ and $|R| = 1$, we have
\begin{align*}
    \Pr(M(A(D), D, R) \in \mathcal{M}) \leq e^\epsilon \Pr(A(D \setminus R) \in \mathcal{M}) + \delta, \\
    \Pr(A(D \setminus R) \in \mathcal{M}) \leq e^\epsilon \Pr(M(A(D), D, R) \in \mathcal{M}) + \delta.
\end{align*}
\end{definition}
Note that this definition is based on deletion of one data point ($|R| = 1$). We include results for unlearning over multiple requests ($|R| = m$) in the Appendix.% and our theoretical analysis focuses on this simple case. However, it is possible to directly extend our theory to a batch of deletions with $|R| \le m$ for some $m < n$ in a manner similar to \citet{guoCertifiedDataRemoval2020}.

\paragraph{Fairness.} We focus on a popular notion of group fairness, \emph{Equalized Odds}~\citep{hardt2016equality}, and present results for other popular metrics such as \emph{Demographic Parity}, \emph{Equality of Opportunity}, and \emph{Subgroup Accuracy} in the Appendix. Consider a data point $(X, Y, S)$ randomly drawn from the data distribution, where $X\in \mathcal{X}, Y\in \mathcal{Y}$, and $S \in \mathcal{S}$. Note that $X$, $Y$, and $S$ are random variables. Equalized Odds is then defined as follows.
\begin{definition}[Equalized Odds~\citep{hardt2016equality}.] \label{equalizedodds}
A model $h_\theta: \mathcal{X} \rightarrow \mathcal{Y}$ satisfies \emph{Equalized Odds} with respect to the sensitive attribute $S$ and the outcome $Y$ if the model prediction $h_\theta(X)$ and $S$ are independent conditional on $Y$. More formally, for all $y \in \{0, 1\},$
    \begin{align*}
        \Pr(h_\theta(X) = 1 \mid S = a, Y = y) = \\
        \Pr(h_\theta(X) = 1 \mid S = b, Y = y).
    \end{align*}
\end{definition} 

In practice, when exact Equalized Odds is not achieved, we can use \emph{Absolute Equalized Odds Difference}, the absolute difference for both false positive rates and true positive rates between the two subgroups, as a quantitative measure for unfairness. The Absolute Equalized Odds Difference (AEOD) is defined as:
\begin{align}
    \text{AEOD}(\theta) := \frac{1}{2}&\sum_{y\in \{0, 1\}}\big|\Pr(h_\theta(X) = 1 \mid S = a, Y=y) - \nonumber \\
    &\Pr(h_\theta(X) = 1 \mid S = b, Y=y)\big|. \label{eq:aeod}
\end{align} 

We build on prior approaches by incorporating fairness goals into the classic unlearning problem. In the next section, we propose the first method to satisfy fairness and unlearning simultaneously.