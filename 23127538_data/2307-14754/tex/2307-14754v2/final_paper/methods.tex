We provide an algorithm that can efficiently unlearn requested data points from a model trained with fair loss. We also prove theoretical guarantees on the unlearnability of our method, and show novel fairness bounds that can be applied to our method as well as prior work.

\subsection{A Convex Fair Loss Function}
To simultaneously achieve fairness and provable unlearning, we leverage a convex fair learning loss introduced by \citet{berk2017convex}. This fair loss can effectively optimize for several popular notions of group fairness, including Equalized Odds. In addition, the convexity of this loss offers mathematical convenience in the development of our provable unlearning algorithm. 

We begin with a binary cross-entropy (BCE) loss for binary classification:
\begin{align}
    \mathcal{L}_\textrm{BCE}(\theta, D) = \frac{1}{n}\sum_{i = 1}^{n} \ell(\theta,x_i, y_i) + \frac{\lambda}{2}||\theta||_2^2, \label{bceloss}
\end{align}
where $\ell(\theta,x_i, y_i) = -y_i\log(\langle x_i,\theta\rangle) - (1-y_i) \log(1 - \langle x_i,\theta\rangle)$ is the logistic loss.

We then add a fairness regularizer. Let $G_a := \{i : s_i = a\}$, $G_b := \{i : s_i = b\}$ be sets of indices indicating subgroup membership for each sample in dataset $D$ with $n_a = |G_a|$ and $n_b = |G_b|$. The fairness regularizer is defined as the following:
\begin{align}
    &\mathcal{L}_\textrm{fair}(\theta, D) := \nonumber \\
    &\qquad\left(\frac{1}{n_an_b} \sum_{i \in G_a}\sum_{j \in G_b} \mathbbm{1}[y_i = y_j](\langle x_i,\theta\rangle - \langle x_j, \theta\rangle) \right)^2. \label{eqn:pairwisefair}
\end{align}
In simple terms, $\mathcal{L}_\textrm{fair}$ penalizes the pairwise difference in logits for samples with the same label between subgroups. Because $\mathcal{L}_\textrm{fair}$ considers samples that share a label regardless of label value, this term directly optimizes for Equalized Odds (Def.~\ref{equalizedodds}). The full fair loss becomes
\begin{align}
    \mathcal{L}(\theta, D) = \mathcal{L}_\textrm{BCE}(\theta, D) + \gamma\mathcal{L}_\textrm{fair}(\theta, D), \label{fairloss}
\end{align}
where $\gamma$ is the fairness regularization parameter.

Most existing unlearning methods~\citep{guoCertifiedDataRemoval2020,izzoApproximateDataDeletion,neelDescenttoDeleteGradientBasedMethods2020a} are specifically designed to unlearn over objective functions like Eq.~(\ref{bceloss}), where the objective constitutes a sum of independent functions on each data point. However, the introduction of the fairness regularizer $\mathcal{L}_\textrm{fair}(\theta, D)$ (and most other fairness regularizers~\citep{beutel2019fairness}) entangles the influence of data points, rendering existing unlearning methods inapplicable. In the following section, we propose a method to address these issues and the first fair unlearning algorithm.

\subsection{The Fair Unlearning Algorithm}
Recall the goal of an unlearning algorithm $M$ is to efficiently update the model $A(D)$, such that $M(A(D), D, R)$ is close to $A(D\setminus R)$. With a concrete definition of our fair loss, we can represent the fully trained model $A(D)$ by its parameters $\theta_D^* := \arg\min_{\theta} \mathcal{L}(\theta, D)$. Similarly, the retrained model $A(D\setminus R)$ corresponds to parameters $\theta_{D'}^* := \arg\min_{\theta} \mathcal{L}(\theta, D')$, where we define $D' := D\setminus R$ for simplicity.

Similar to several existing unlearning methods~\citep{guoCertifiedDataRemoval2020,neelDescenttoDeleteGradientBasedMethods2020a}, our fair unlearning method consists of two steps. First we conduct an efficient update on $\theta_D^*$ to obtain updated model parameters $\theta_{D'}^-$. The goal of this part is to make the updated model parameters $\theta_{D'}^-$ close to the retrained model parameters $\theta_{D'}^*$. Then we add noise to the loss function such that both $A(D)$ and $A(D')$ are randomized, from which we can establish a statistical indistinguishability result between $M(\theta_D^*, D, R)$ and $A(D')$.

\paragraph{Efficient Model Update.}
We first introduce the efficient model update. To simplify notations, we can unroll the squared double sum in Eq.~(\ref{eqn:pairwisefair}) into a single sum using a Cartesian product. Define $N := G_a \times G_b \times G_a \times G_b$. Then we can write $\mathcal{L}_\textrm{fair}$ as
\begin{align}
    \mathcal{L}_\textrm{fair}(\theta, D) = \frac{1}{|N|} \sum_{(i, j, k, l) \in N} \ell_\textrm{fair}(\theta, \{(x_f, y_f)\}_{f \in \{i,j,k,l\}}), \nonumber\\[-15pt]
\end{align}
where
\begin{align}
    &\ell_\textrm{fair}(\theta, \{(x_f, y_f)\}_{f \in \{i,j,k,l\}}) := \nonumber\\
    &\mathbbm{1}[y_i = y_j](\langle x_i, \theta\rangle - \langle x_j, \theta\rangle)\mathbbm{1}[y_k = y_l](\langle x_k, \theta\rangle - \langle x_l, \theta\rangle). 
\end{align}

Without loss of generality, assume that we want to remove one single data point, the final sample $(x_n, y_n, s_n)$, and that this sample comes from subgroup $a$, i.e., $n \in G_a$. We propose an algorithm that updates $\theta_D^*$ to approximately minimize $\mathcal{L}(\theta, D')$ over the remaining dataset $D'= D\setminus R$ where $R = \{(x_n, y_n, s_n)\}$. Our algorithm takes a second-order Newton update from $\theta_D^*$, which results in $\theta_{D'}^-$. Let $d'_a := \{i \in G_a : x_i \in D'\}$, $C_{D'} := d_a' \times G_b \times d_a' \times G_b$. We define a quantity $\Delta$ related to the residual difference between gradients over $D$ and $D'$ as follows:
\begin{align}
    % &\Delta := \ell'(\thetafull, x_n, y_n) + \lambda \theta^* \nonumber \\
    % &+\gamma\left(\frac{n}{|N|} - \frac{n-1}{|N\setminus C|}\right)\sum_{\mathclap{\substack{(i,j,k,l)\\  \in N \setminus C}}}\ell_\textrm{fair}'(\theta, \{(x_f, y_f)\}_{f \in \{i,j,k,l\}})\nonumber\\
    % &+\gamma\frac{n}{|N|} \sum_{(i,j,k,l) \in C}\ell_\textrm{fair}'(\theta, \{(x_f, y_f)\}_{f \in \{i,j,k,l\}}). \label{eq:delta}\\
    &\Delta := \ell'(\thetafull, x_n, y_n) + \lambda \thetafull \nonumber \\
    &\quad +\gamma\frac{n}{|N|} \sum_{(i,j,k,l) \in N}\ell_\textrm{fair}'(\thetafull, \{(x_f, y_f)\}_{f \in \{i,j,k,l\}})  \nonumber\\
    &\quad -\gamma\frac{n-1}{|C_{D'}|}\sum_{(i,j,k,l)\in C_{D'}}\ell_\textrm{fair}'(\thetafull, \{(x_f, y_f)\}_{f \in \{i,j,k,l\}}). \label{eq:delta}
\end{align}
Intuitively, the first and second term correspond to taking a gradient step in the direction of the BCE loss and $\ell_2$ penalty respectively, while the third term counteracts the entangled influence the sample has on the remaining data and the fourth term takes a gradient step over the fairness penalty. By constructing $\Delta$ in this way, our unlearning algorithm becomes the following: 
\begin{align}
    \theta_{D'}^- = \theta_D^* + H_{\theta_D^*}^{-1}\Delta, \label{fairnewton}
\end{align}
where $H_{\theta_D^*}=\nabla^2 \mathcal{L}(\theta_D^*, D')$ is the Hessian of the full loss. In Theorem \ref{thm:eps_delta}, we achieve a bound on the gradient $||\nabla \mathcal{L}(\thetaunlearn; D')||_2$ and then apply this bound to perform $(\epsilon, \delta)$-unlearning.

\paragraph{Noisy Loss Perturbation.}

To achieve $(\epsilon, \delta)$-statistical indistinguishability, we add Gaussian noise to both the original training and the retraining process. Specifically, we modify the loss function by an additional term $\textbf{b}^T\theta$, where $\textbf{b} \sim N(0, \sigma I)^d$, resulting in the perturbed loss function $\mathcal{L}^\textbf{b}(\theta, D) = \mathcal{L}(\theta, D) + \textbf{b}^T\theta$. 

\paragraph{Runtime Complexity.}

Hessian inversion takes $O(d^2n)$ time, but this can be precomputed and cached as in~\citep{izzoApproximateDataDeletion, guoCertifiedDataRemoval2020}. We can also rearrange terms in Eq.~\eqref{eq:delta} to precompute the double sum over all elements in $N$ which is $O(n^2)$ and then subtract terms accordingly from $N\setminus C$ which is $O(kn+k^2)$, where $k$ is the size of our unlearning request and $k << n$. Thus, at unlearning time, our runtime is of order $O(kn+k^2)$. 

\paragraph{Trade-off between fairness and unlearning.} Although not directly related to each other, both fairness (in the form of increased regularization, $\gamma$) and unlearning (in the form of increased noise, $\sigma$), form a Pareto frontier with accuracy. Thus, for a given accuracy budget, fairness and unlearning come at a cost to one another.

\subsection{Theoretical Guarantees}

\paragraph{Theoretical Guarantee on Statistical Indistinguishability.}
When both the original training and retraining are randomized, the following Theorem~\ref{thm:eps_delta} provides a guarantee that our unlearning method in Eq.~(\ref{fairnewton}) is $(\epsilon, \delta)$-indistinguishable from retraining for some $\epsilon, \delta > 0$.

\begin{theorem}[$(\epsilon, \delta)$-unlearning.\footnote{For proof and generalization to unlearning $m$ samples, see Appendix \ref{sec:thm1_proof}}] \label{thm:eps_delta}
    Let $\thetafull$ be the output of algorithm $A$ trained on $\mathcal{L}^\textbf{b}$. Assume the loss $\ell$ is $\psi$-Lipschitz in its second derivative ($\ell''$ is $\psi$-Lipschitz), and bounded in its first derivative by a constant $||\ell'(\theta, x, y)||_2 \leq g$. Assume the data is bounded such that for all $i \in n$, $||x_i||_2 \leq 1$. Then, 
    \begin{align}
        &||\nabla \mathcal{L}(\thetaunlearn; D')||_2 \leq  \nonumber \\
        &\qquad \frac{\psi}{\lambda^2(n-1)}\left(2g + ||\thetafull||_2\left|\left|\frac{8(n-1)}{n_a^2} \right|\right|_2\right)^2 ,
    \end{align}
    and if $\textbf{b} \sim N(0, k\epsilon'/\epsilon)^d$ with k $>$ 0 and $||\nabla \mathcal{L}(\thetaunlearn; D')||_2 \leq \epsilon'$, then the unlearning algorithm defined by Eq.~\ref{fairnewton} is $(\epsilon, \delta)$-unlearnable with $\delta = 1.5\exp(-k^2/2)$.
\end{theorem}
For logistic loss, we know $||\ell'(\theta, x, y)||_2 \leq 1$ and that $\ell''$ is $1/4$-Lipschitz.

Intuitively, our goal is to achieve Definition~\ref{unlearning_definition} by making the likelihood of a model being output by training approximately equal to the likelihood of that same model being output by unlearning. We do this by 1) ensuring the gradient of our unlearned model is bounded, which for strongly convex loss directly means our unlearned parameter $\thetaunlearn$ is close to the optimal retrained parameter $\thetaretrain$, and 2) adding a sufficient amount of noise to the training objective such that any parameter close to $\thetaretrain$ could have been generated by $A$.

\paragraph{Theoretical Guarantee on Fairness.}

Finally, we show that the model output by our method, $\thetaunlearn$, has a bounded change in Absolute Equalized Odds Difference (Eq.~\eqref{eq:aeod}) in comparison to the model output by retraining, $\thetaretrain$. We formalize that $\text{AEOD}(\thetaunlearn)$ is bounded in the following theorem.

\begin{theorem}[AEOD is bounded.] \label{thm:fairnesG_bound}
    Assume both $\ell_\textrm{BCE}(\theta, x, y) = \ell(\theta, x, y) + \frac{2\lambda}{n}||\theta||_2^2$ and $\ell_\textrm{fair}$ are $L$-Lipschitz. Suppose $\forall x \in \mathcal{X} \subseteq \mathbb{R}^d, ||x||_2 \leq 1$, and for all $\mathcal{Z} \subseteq \mathcal{X}$, the conditional probability $P(\mathcal{Z} | S, Y) \leq c\frac{|\mathcal{Z}|}{|\mathcal{X}|}$ for some $c\ge 1$, which controls the concentration of the probability distribution. Then, with the results from Thm.~\ref{thm:eps_delta} we can show that $||\thetaretrain-\thetaunlearn||_2 \leq \kappa$ for some $\kappa$ being $O(1/n^2)$. Furthermore, we have that the absolute equalized odds difference for $\thetaunlearn$ is bounded by
    \begin{align}
        &\text{AEOD}(\thetaunlearn) \leq \text{AEOD}(\thetaretrain) \nonumber \\
        & \qquad + c\left(1- \frac{2\int_{\mu}^{1}\frac{\pi^{\frac{d-1}{2}}}{\Gamma(\frac{d+1}{2})}(1-y^2)^{\frac{d-1}{2}} dy}{V}\right), \label{eq:aeodbound}
    \end{align}
    where $V$ is the volume of the unit $d$-sphere, and $\mu = O(\sqrt{\kappa})$.
\end{theorem}

As $n$ goes to infinity, $\kappa$ approaches 0, the integral in Eq.~(\ref{eq:aeodbound}) evaluates to $V/2$, so the second term vanishes.

Theorem~\ref{thm:fairnesG_bound} states that the unlearned and retrained models will be similar to each other in terms of fairness performance. By developing an unlearnable method that optimizes for fairness during training and retraining, our theory guarantees that unlearning will also be as fair. Furthermore, Thm.~\ref{thm:fairnesG_bound} only requires $||\thetaretrain-\thetaunlearn||_2 \leq \kappa$ in addition to standard assumptions in unlearning literature for linear models such as Lipschitzness and bounded data. For any other method that achieves the above bound on parameter distance, Thm.~\ref{thm:fairnesG_bound} bounds the change in fairness of the unlearned and retrained model. Proofs for both theorems can be found in the Appendix.