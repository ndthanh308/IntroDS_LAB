














####################################################### Verions 2 
\begin{comment}
Prompt engineering as a new discipline, is an approach to designing optimal prompts to instruct the model to perform a task. Since LLMs such as GPT-3 are tuned to follow instructions so they are capable of performing tasks in a zero-shot \cite{wei2022finetuned} few-shot \cite{kaplan2020scaling,min2022rethinking} manners. Where, due to the complex nature of tasks, few-shot prompting provides a technique to enable in-context learning by using subsequent examples to condition the models to generate the most likely responses. However, more complex tasks that require more knowledge than conditioning such as reasoning tasks require more advanced prompt engineering. Reasoning tasks in NLP involve models to perform logical inference and draw conclusions from textual data. More recently, Chain-of-Thought (CoT) \cite{NEURIPS20229d560961} prompting has been introduced to address more complex mathematic, commonsense, and symbolic reasoning tasks. The CoT unlocks complex reasoning capabilities through intermediate reasoning steps in combination with few-shot or zero-shot \cite{kojima2023large} prompting. Moreover, Tree-of-Thoughts (ToT) \cite{yao2023tree} prompting has been introduced for tasks that require exploration or strategic lookahead. ToT generalizes over CoT prompting by exploring thoughts that serve as intermediate steps for general problem-solving with LLMs. Another approach for solving more complex tasks is using decomposed prompting \cite{khot2023decomposed}, where we can further decompose tasks that are hard for LLMs into simpler solvable sub-tasks and delegate these to sub-task-specific LLMs.

The self-design prompts engineering in this work was motivated by the desire to understand how LLMs function in different scenarios of ontology learning. By exploring both zero-shot and few-shot prompting, we aim to measure the model's existing effectiveness and its ability to learn from a limited amount of data. Zero-shot prompting involves instructing the model to perform tasks without prior knowledge. This method allows us to observe how much the model already knows about the tasks. It is a way to assess the innate abilities of the model without providing it with additional task-specific information due to the costly expenses of training/finetuning of LLMs. On the other hand, few-shot prompting provides a technique to enable in-context learning that later unlocks the integration of more knowledge into LLMs without the need to be concerned about specific user queries. By employing both prompting techniques, we can gain valuable insights into the LLM's initial knowledge and its ability to learn and generalize from a small amount of additional data in ontology learning. 
\end{comment}


%The Chain-of-Thought (CoT) prompting \cite{NEURIPS20229d560961} has been introduced to address more complex arithmetic, commonsense, and symbolic reasoning tasks.  This is achieved through a combination of intermediate reasoning steps along with standard prompting \cite{kojima2023large}. The CoT reasoning steps include breaking down complex tasks into a chain of incremental steps toward the solution helping the LLM to explicitly reason step-by-step, consequently arriving at a more accurate and logical conclusion. However, CoT fails to explore more strategic approaches for accurate conclusions in more complex tasks. Moreover, the Tree-of-Thoughts (ToT) prompting \cite{yao2023tree} has been introduced to build upon CoT prompting and generalize its capabilities by exploring a broader range of thoughts that can serve as intermediate steps for general problem-solving with LLMs. ToT first generates intermediate thoughts (thoughts decomposition) as a tree states, which leads to multiple possible approaches for the problem. Next, it uses generated intermediate thoughts to generate more thoughts (thought generator), where each state will be evaluated by the state evaluator as a metric for calculating progress toward solving the problem. Finally, using search algorithms explore answer space to achieve optimal answers. Another approach for solving more complex tasks is using decomposed prompting \cite{khot2023decomposed}, where it decomposes complete tasks into simpler solvable sub-tasks and delegates them to sub-task-specific LLMs.  Each sub-task is operational as a separate prompt and contains examples that are independent of the original complex task. Sub-tasks are answered and the entire decomposition history of sub-tasks are passed to the merge prompt to get the final answer.


\begin{comment}
Prompt engineering as a new discipline, is an approach to designing optimal prompts to instruct the model to perform a task. The self-design prompt engineering in this work was motivated by the desire to understand how LLMs function in different scenarios of ontology learning. By exploring both zero-shot  \cite{wei2022finetuned} and few-shot \cite{kaplan2020scaling,min2022rethinking} prompting, the aim was to measure the model's existing effectiveness and its ability to learn from a limited amount of data. Zero-shot prompting involves instructing the model to perform tasks without any specific fine-tuning on the given tasks. This method allows us to observe how much the model already knows about the tasks based on its pre-training. It is a way to assess the innate abilities of the model without providing it with additional task-specific information due to the costly expenses of training/finetuning of LLMs. On the other hand, few-shot prompting provides a technique to enable in-context learning by using subsequent examples to condition the models to generate the most likely responses. It enables the integration of knowledge into LLMs without the need to be concerned about specific user queries. By employing both prompting techniques, researchers can gain valuable insights into the LLM's initial knowledge and its ability to learn and generalize from a small amount of additional data. 

However, when ontology learning tasks become more complex, it will require advanced prompt engineering techniques such as Chain-of-Thought (CoT) \cite{NEURIPS20229d560961} prompting with the aim of breaking down complex tasks into a chain of smaller, manageable steps, where each step builds upon the previous ones. This helps the LLM to reason step-by-step and arrive at a more accurate and logical conclusion. On the other hand Tree-of-Thoughts (ToT) \cite{yao2023tree} has been introduced for tasks that require exploration or strategic lookahead. ToT generalizes over CoT prompting by exploring thoughts that serve as intermediate steps for general problem-solving with LLMs. Both CoT and ToT unlock complex reasoning capabilities through intermediate reasoning steps in combination with few-shot or zero-shot \cite{kojima2023large} prompting. 

At the moment, complex prompting is not a primary concern, as our current focus is on the initial exploration of the task to identify the areas where we need further improvement. We want to understand how much we have accomplished so far before delving into more complex techniques like CoT prompting. Once we have a clearer picture of the model's capabilities and limitations, we can then consider advanced approaches to enhance its performance and address more intricate reasoning tasks.

    
\end{comment}