\begin{thebibliography}{10}
\providecommand{\url}[1]{\texttt{#1}}
\providecommand{\urlprefix}{URL }
\providecommand{\doi}[1]{https://doi.org/#1}

\bibitem{geonames}
Geonames geographical database (2023), \url{http://www.geonames.org/}

\bibitem{agirre2000enriching}
Agirre, E., Ansa, O., Hovy, E., Mart{\'\i}nez, D.: Enriching very large
  ontologies using the www. In: Proceedings of the First International
  Conference on Ontology Learning-Volume 31. pp. 25--30 (2000)

\bibitem{akkalyoncu-yilmaz-etal-2019-applying}
Akkalyoncu~Yilmaz, Z., Wang, S., Yang, W., Zhang, H., Lin, J.: Applying {BERT}
  to document retrieval with birch. In: Proceedings of the 2019 Conference on
  Empirical Methods in Natural Language Processing and the 9th International
  Joint Conference on Natural Language Processing (EMNLP-IJCNLP): System
  Demonstrations. pp. 19--24. Association for Computational Linguistics, Hong
  Kong, China (Nov 2019). \doi{10.18653/v1/D19-3004},
  \url{https://aclanthology.org/D19-3004}

\bibitem{alfonseca2002unsupervised}
Alfonseca, E., Manandhar, S.: An unsupervised method for general named entity
  recognition and automated concept discovery. In: Proceedings of the 1st
  international conference on general WordNet, Mysore, India. pp. 34--43 (2002)

\bibitem{amatriain2023transformer}
Amatriain, X.: Transformer models: an introduction and catalog. arXiv preprint
  arXiv:2302.07730  (2023)

\bibitem{r3-soa1}
Asim, M.N., Wasim, M., Khan, M.U.G., Mahmood, W., Abbasi, H.M.: A survey of
  ontology learning techniques and applications. Database  \textbf{2018},
  bay101 (2018)

\bibitem{umls}
Bodenreider, O.: {The Unified Medical Language System (UMLS): integrating
  biomedical terminology}. Nucleic Acids Research  \textbf{32}(suppl\_1),
  D267--D270 (01 2004). \doi{10.1093/nar/gkh061},
  \url{https://doi.org/10.1093/nar/gkh061}

\bibitem{bodenreider2004unified}
Bodenreider, O.: The unified medical language system (umls): integrating
  biomedical terminology. Nucleic acids research  \textbf{32}(suppl\_1),
  D267--D270 (2004)

\bibitem{gpt3}
Brown, T.B., Mann, B., Ryder, N., Subbiah, M., Kaplan, J., Dhariwal, P.,
  Neelakantan, A., Shyam, P., Sastry, G., Askell, A., Agarwal, S.,
  Herbert-Voss, A., Krueger, G., Henighan, T., Child, R., Ramesh, A., Ziegler,
  D.M., Wu, J., Winter, C., Hesse, C., Chen, M., Sigler, E., Litwin, M., Gray,
  S., Chess, B., Clark, J., Berner, C., McCandlish, S., Radford, A., Sutskever,
  I., Amodei, D.: Language models are few-shot learners (2020)

\bibitem{flant5}
Chung, H.W., Hou, L., Longpre, S., Zoph, B., Tay, Y., Fedus, W., Li, Y., Wang,
  X., Dehghani, M., Brahma, S., Webson, A., Gu, S.S., Dai, Z., Suzgun, M.,
  Chen, X., Chowdhery, A., Castro-Ros, A., Pellat, M., Robinson, K., Valter,
  D., Narang, S., Mishra, G., Yu, A., Zhao, V., Huang, Y., Dai, A., Yu, H.,
  Petrov, S., Chi, E.H., Dean, J., Devlin, J., Roberts, A., Zhou, D., Le, Q.V.,
  Wei, J.: Scaling instruction-finetuned language models (2022)

\bibitem{cui2021template}
Cui, L., Wu, Y., Liu, J., Yang, S., Zhang, Y.: Template-based named entity
  recognition using bart. arXiv preprint arXiv:2106.01760  (2021)

\bibitem{dai2019transformerxl}
Dai, Z., Yang, Z., Yang, Y., Carbonell, J., Le, Q.V., Salakhutdinov, R.:
  Transformer-xl: Attentive language models beyond a fixed-length context
  (2019)

\bibitem{dalvi2022discovering}
Dalvi, F., Khan, A.R., Alam, F., Durrani, N., Xu, J., Sajjad, H.: Discovering
  latent concepts learned in {BERT}. In: International Conference on Learning
  Representations (2022), \url{https://openreview.net/forum?id=POTMtpYI1xH}

\bibitem{wn18rr}
Dettmers, T., Pasquale, M., Pontus, S., Riedel, S.: Convolutional 2d knowledge
  graph embeddings. In: Proceedings of the 32th AAAI Conference on Artificial
  Intelligence. pp. 1811--1818 (February 2018),
  \url{https://arxiv.org/abs/1707.01476}

\bibitem{bert}
Devlin, J., Chang, M.W., Lee, K., Toutanova, K.: Bert: Pre-training of deep
  bidirectional transformers for language understanding (2019)

\bibitem{dopazo1997phylogenetic}
Dopazo, J., Carazo, J.M.: Phylogenetic reconstruction using an unsupervised
  growing neural network that adopts the topology of a phylogenetic tree.
  Journal of molecular evolution  \textbf{44}(2),  226--233 (1997)

\bibitem{gruber1995toward}
Gruber, T.R.: Toward principles for the design of ontologies used for knowledge
  sharing? International journal of human-computer studies  \textbf{43}(5-6),
  907--928 (1995)

\bibitem{pubmedbert}
Gu, Y., Tinn, R., Cheng, H., Lucas, M., Usuyama, N., Liu, X., Naumann, T., Gao,
  J., Poon, H.: Domain-specific language model pretraining for biomedical
  natural language processing. ACM Transactions on Computing for Healthcare
  (HEALTH)  \textbf{3}(1),  1--23 (2021)

\bibitem{guha2016schema}
Guha, R.V., Brickley, D., Macbeth, S.: Schema. org: evolution of structured
  data on the web. Communications of the ACM  \textbf{59}(2),  44--51 (2016)

\bibitem{hahn2001joint}
Hahn, U., Mark{\'o}, K.G.: Joint knowledge capture for grammars and ontologies.
  In: Proceedings of the 1st international conference on Knowledge capture. pp.
  68--75 (2001)

\bibitem{hamp1997germanet}
Hamp, B., Feldweg, H.: Germanet-a lexical-semantic net for german. In:
  Automatic information extraction and building of lexical semantic resources
  for NLP applications (1997)

\bibitem{hearst1998automated}
Hearst, M.A.: Automated discovery of wordnet relations. WordNet: an electronic
  lexical database  \textbf{2} (1998)

\bibitem{hwang1999incompletely}
Hwang, C.H.: Incompletely and imprecisely speaking: using dynamic ontologies
  for representing and retrieving information. In: KRDB. vol.~21, pp. 14--20.
  Citeseer (1999)

\bibitem{jiang-etal-2020-know}
Jiang, Z., Xu, F.F., Araki, J., Neubig, G.: How can we know what language
  models know? Transactions of the Association for Computational Linguistics
  \textbf{8},  423--438 (2020). \doi{10.1162/tacl\_a\_00324},
  \url{https://aclanthology.org/2020.tacl-1.28}

\bibitem{khan2002ontology}
Khan, L., Luo, F.: Ontology construction for information selection. In: 14th
  IEEE International Conference on Tools with Artificial Intelligence,
  2002.(ICTAI 2002). Proceedings. pp. 122--127. IEEE (2002)

\bibitem{khot2023decomposed}
Khot, T., Trivedi, H., Finlayson, M., Fu, Y., Richardson, K., Clark, P.,
  Sabharwal, A.: Decomposed prompting: A modular approach for solving complex
  tasks (2023)

\bibitem{kietz2000method}
Kietz, J.U., Maedche, A., Volz, R.: A method for semi-automatic ontology
  acquisition from a corporate intranet. In: EKAW-2000 Workshop “Ontologies
  and Text”, Juan-Les-Pins, France, October 2000 (2000)

\bibitem{kojima2023large}
Kojima, T., Gu, S.S., Reid, M., Matsuo, Y., Iwasawa, Y.: Large language models
  are zero-shot reasoners (2023)

\bibitem{konys2019knowledge}
Konys, A.: Knowledge repository of ontology learning tools from text. Procedia
  Computer Science  \textbf{159},  1614--1628 (2019)

\bibitem{lester2021power}
Lester, B., Al-Rfou, R., Constant, N.: The power of scale for
  parameter-efficient prompt tuning. arXiv preprint arXiv:2104.08691  (2021)

\bibitem{levy-etal-2017-zero}
Levy, O., Seo, M., Choi, E., Zettlemoyer, L.: Zero-shot relation extraction via
  reading comprehension. In: Proceedings of the 21st Conference on
  Computational Natural Language Learning ({C}o{NLL} 2017). pp. 333--342.
  Association for Computational Linguistics, Vancouver, Canada (Aug 2017).
  \doi{10.18653/v1/K17-1034}, \url{https://aclanthology.org/K17-1034}

\bibitem{bart}
Lewis, M., Liu, Y., Goyal, N., Ghazvininejad, M., Mohamed, A., Levy, O.,
  Stoyanov, V., Zettlemoyer, L.: Bart: Denoising sequence-to-sequence
  pre-training for natural language generation, translation, and comprehension
  (2019)

\bibitem{li2021prefix}
Li, X.L., Liang, P.: Prefix-tuning: Optimizing continuous prompts for
  generation. arXiv preprint arXiv:2101.00190  (2021)

\bibitem{prompting}
Liu, P., Yuan, W., Fu, J., Jiang, Z., Hayashi, H., Neubig, G.: Pre-train,
  prompt, and predict: A systematic survey of prompting methods in natural
  language processing. ACM Comput. Surv.  \textbf{55}(9) (jan 2023).
  \doi{10.1145/3560815}, \url{https://doi.org/10.1145/3560815}

\bibitem{longpre2023flan}
Longpre, S., Hou, L., Vu, T., Webson, A., Chung, H.W., Tay, Y., Zhou, D., Le,
  Q.V., Zoph, B., Wei, J., et~al.: The flan collection: Designing data and
  methods for effective instruction tuning. arXiv preprint arXiv:2301.13688
  (2023)

\bibitem{lonsdale2002peppering}
Lonsdale, D., Ding, Y., Embley, D.W., Melby, A.: Peppering knowledge sources
  with salt: Boosting conceptual content for ontology generation. In:
  Proceedings of the AAAI Workshop on Semantic Web Meets Language Resources,
  Edmonton, Alberta, Canada (2002)

\bibitem{r3-soa2}
Lourdusamy, R., Abraham, S.: A survey on methods of ontology learning from
  text. In: Intelligent Computing Paradigm and Cutting-edge Technologies:
  Proceedings of the First International Conference on Innovative Computing and
  Cutting-edge Technologies (ICICCT 2019), Istanbul, Turkey, October 30-31,
  2019 1. pp. 113--123. Springer (2020)

\bibitem{maedche2001ontology}
Maedche, A., Staab, S.: Ontology learning for the semantic web. IEEE
  Intelligent systems  \textbf{16}(2),  72--79 (2001)

\bibitem{MEDCIN}
{Medicomp Systems}: {MEDCIN} (January 2023), \url{https://medicomp.com}

\bibitem{miller1995wordnet}
Miller, G.A.: Wordnet: a lexical database for english. Communications of the
  ACM  \textbf{38}(11),  39--41 (1995)

\bibitem{missikoff2002usable}
Missikoff, M., Navigli, R., Velardi, P.: The usable ontology: An environment
  for building and assessing a domain ontology. In: The Semantic Web—ISWC
  2002: First International Semantic Web Conference Sardinia, Italy, June
  9--12, 2002 Proceedings. pp. 39--53. Springer (2002)

\bibitem{moldovan2001interactive}
Moldovan, D.I., GiRJU, R.C.: An interactive tool for the rapid development of
  knowledge bases. International Journal on Artificial Intelligence Tools
  \textbf{10}(01n02),  65--86 (2001)

\bibitem{NCI}
{National Cancer Institute, National Institutes of Health}: {NCI Thesaurus}
  (September 2022), \url{http://ncit.nci.nih.gov}

\bibitem{noy2001ontology}
Noy, N.F., McGuinness, D.L., et~al.: Ontology development 101: A guide to
  creating your first ontology (2001)

\bibitem{chatgpt}
OpenAI: Chatgpt. \url{https://openai.com/chat-gpt/} (2023), accessed May 5,
  2023

\bibitem{gpt4}
OpenAI: Gpt-4 technical report (2023)

\bibitem{schemaorg}
Patel-Schneider, P.F.: Analyzing schema.org. In: Mika, P., Tudorache, T.,
  Bernstein, A., Welty, C., Knoblock, C., Vrande{\v{c}}i{\'{c}}, D., Groth, P.,
  Noy, N., Janowicz, K., Goble, C. (eds.) The Semantic Web -- ISWC 2014. pp.
  261--276. Springer International Publishing, Cham (2014)

\bibitem{peters-etal-2018-deep}
Peters, M.E., Neumann, M., Iyyer, M., Gardner, M., Clark, C., Lee, K.,
  Zettlemoyer, L.: Deep contextualized word representations. In: Proceedings of
  the 2018 Conference of the North {A}merican Chapter of the Association for
  Computational Linguistics: Human Language Technologies, Volume 1 (Long
  Papers). pp. 2227--2237. Association for Computational Linguistics, New
  Orleans, Louisiana (Jun 2018). \doi{10.18653/v1/N18-1202},
  \url{https://aclanthology.org/N18-1202}

\bibitem{petroni2020how}
Petroni, F., Lewis, P., Piktus, A., Rockt{\"a}schel, T., Wu, Y., Miller, A.H.,
  Riedel, S.: How context affects language models' factual predictions. In:
  Automated Knowledge Base Construction (2020),
  \url{https://openreview.net/forum?id=025X0zPfn}

\bibitem{petroni2019language}
Petroni, F., Rockt{\"a}schel, T., Lewis, P., Bakhtin, A., Wu, Y., Miller, A.H.,
  Riedel, S.: Language models as knowledge bases? arXiv preprint
  arXiv:1909.01066  (2019)

\bibitem{lms-as-kb}
Petroni, F., Rockt{\"a}schel, T., Riedel, S., Lewis, P., Bakhtin, A., Wu, Y.,
  Miller, A.: Language models as knowledge bases? In: Proceedings of the 2019
  Conference on Empirical Methods in Natural Language Processing and the 9th
  International Joint Conference on Natural Language Processing (EMNLP-IJCNLP).
  Association for Computational Linguistics (2019)

\bibitem{rebele2016yago}
Rebele, T., Suchanek, F., Hoffart, J., Biega, J., Kuzey, E., Weikum, G.: Yago:
  A multilingual knowledge base from wikipedia, wordnet, and geonames. In: The
  Semantic Web--ISWC 2016: 15th International Semantic Web Conference, Kobe,
  Japan, October 17--21, 2016, Proceedings, Part II 15. pp. 177--185. Springer
  (2016)

\bibitem{roux2000ontology}
Roux, C., Proux, D., Rechenmann, F., Julliard, L.: An ontology enrichment
  method for a pragmatic information extraction system gathering data on
  genetic interactions. In: ECAI Workshop on Ontology Learning (2000)

\bibitem{sajjad2022analyzing}
Sajjad, H., Durrani, N., Dalvi, F., Alam, F., Khan, A.R., Xu, J.: Analyzing
  encoded concepts in transformer language models (2022)

\bibitem{bloom}
Scao, T.L., Fan, A., Akiki, C., Pavlick, E., Ili{\'c}, S., Hesslow, D.,
  Castagn{\'e}, R., Luccioni, A.S., Yvon, F., Gall{\'e}, M., et~al.: Bloom: A
  176b-parameter open-access multilingual language model. arXiv preprint
  arXiv:2211.05100  (2022)

\bibitem{SNOMEDCT-US}
{SNOMED International}: {US Edition of SNOMED CT} (March 2023),
  \url{https://www.nlm.nih.gov/healthit/snomedct/us_edition.html}

\bibitem{srivastava2022beyond}
Srivastava, A., Rastogi, A., Rao, A., Shoeb, A.A.M., Abid, A., Fisch, A.,
  Brown, A.R., Santoro, A., Gupta, A., Garriga-Alonso, A., et~al.: Beyond the
  imitation game: Quantifying and extrapolating the capabilities of language
  models. arXiv preprint arXiv:2206.04615  (2022)

\bibitem{llama}
Touvron, H., Lavril, T., Izacard, G., Martinet, X., Lachaux, M.A., Lacroix, T.,
  Rozi{\`e}re, B., Goyal, N., Hambro, E., Azhar, F., et~al.: Llama: Open and
  efficient foundation language models. arXiv preprint arXiv:2302.13971  (2023)

\bibitem{wagner2000enriching}
Wagner, A.: Enriching a lexical semantic net with selectional preferences by
  means of statistical corpus analysis. In: ECAI Workshop on Ontology Learning.
  vol.~61. Citeseer (2000)

\bibitem{wkatrobski2020ontology}
W{\c{a}}tr{\'o}bski, J.: Ontology learning methods from text-an extensive
  knowledge-based approach. Procedia Computer Science  \textbf{176},
  3356--3368 (2020)

\bibitem{wei2022finetuned}
Wei, J., Bosma, M., Zhao, V., Guu, K., Yu, A.W., Lester, B., Du, N., Dai, A.M.,
  Le, Q.V.: Finetuned language models are zero-shot learners. In: International
  Conference on Learning Representations (2022),
  \url{https://openreview.net/forum?id=gEZrGCozdqR}

\bibitem{wei2022emergent}
Wei, J., Tay, Y., Bommasani, R., Raffel, C., Zoph, B., Borgeaud, S., Yogatama,
  D., Bosma, M., Zhou, D., Metzler, D., et~al.: Emergent abilities of large
  language models. arXiv preprint arXiv:2206.07682  (2022)

\bibitem{NEURIPS20229d560961}
Wei, J., Wang, X., Schuurmans, D., Bosma, M., ichter, b., Xia, F., Chi, E., Le,
  Q.V., Zhou, D.: Chain-of-thought prompting elicits reasoning in large
  language models. In: Koyejo, S., Mohamed, S., Agarwal, A., Belgrave, D., Cho,
  K., Oh, A. (eds.) Advances in Neural Information Processing Systems. vol.~35,
  pp. 24824--24837. Curran Associates, Inc. (2022),
  \url{https://proceedings.neurips.cc/paper_files/paper/2022/file/9d5609613524ecf4f15af0f7b31abca4-Paper-Conference.pdf}

\bibitem{weibel2000dublin}
Weibel, S.L., Koch, T.: The dublin core metadata initiative. D-lib magazine
  \textbf{6}(12),  1082--9873 (2000)

\bibitem{xu2002domain}
Xu, F., Kurz, D., Piskorski, J., Schmeier, S.: A domain adaptive approach to
  automatic acquisition of domain relevant terms and their relations with
  bootstrapping. In: LREC (2002)

\bibitem{yang2019simple}
Yang, W., Zhang, H., Lin, J.: Simple applications of bert for ad hoc document
  retrieval (2019)

\bibitem{yao2023tree}
Yao, S., Yu, D., Zhao, J., Shafran, I., Griffiths, T.L., Cao, Y., Narasimhan,
  K.: Tree of thoughts: Deliberate problem solving with large language models
  (2023)

\end{thebibliography}
