%An early work in ontology learning~\cite{hearst1998automated} addressed the discovery of new lexicosemantic concepts and relations from large collections of unstructured text to enrich or extend WordNet~\cite{miller1995wordnet}. WordNet is a lexical database defined by an ontology of lexical concepts, e.g., nouns, verbs, etc., and lexico-semantic relations, e.g., synonymy, hyponymy, etc. Toward its extraction objective of new lexicosemantic concepts and relations, it defined a lexicosyntactic pattern-based acquisition algorithm that searched for and mined new lexicosemantic relations as defined by the patterns. Such methods tend to have a near perfect coverage but at the expense of precision of the extraction objective and thus necessitate situating a human-in-the-loop for the selection and pruning of the mined information.

%\cite{hwang1999incompletely} discusses an approach that constructs dynamic ontologies that are automatically constructed from textual data. The method is based on detecting the relationship between linguistic features and simple ontology algebra based on inheritance hierarchy and set operations. The algorithm operates in several iterations to dynamically construct an ontology for an application domain given unstructured text that is pos-tagged and a small number of seedwords that represent high-level concepts. In a given run of the algorithm, concept terms are generated and additional concept seedwords are discovered which are bootstrapped for the next iteration of the algorithm. This method designed to work on any domain cannot handle the polysemy problem as well as is encumbered by high recall and low precision.


%\cite{agirre2000enriching} offered a unique take on ontology learning by enriching the WordNet lexical ontology by extracting additionally topically related words via queries made to the documents in the WWW. This work shows how to build lists of words that are topically related to a concept as an enrichment.


%The On-To-Knowledge system~\cite{kietz2000method} offered a generic architecture and an acquisition methodology for acquiring concepts and relations from intranet resources for the corporate domain. Based on a generic core ontology, e.g. lexicalsemantic ontologies such as GermaNet~\cite{hamp1997germanet} or WordNet, as a top level structure for the domain-specific goal ontology, the On-To-Knowledge system focused on domain-specific concept and relation acquisition applying statistical term frequency count heuristics and association rules on texts in a corporate intranet that were classified into the concept taxonomy defined by a semi-structured dictionary with important corporate terms. Following which, non-domain-specific concepts were pruned from the acquired ontology based on a heuristic where domain-specific concepts appeared more frequently in domain-specific than in a general corpus of texts.

%\cite{roux2000ontology} focused on a domain-specific application in genetics where they proposed a method to build an ontology by reusing existing genetics domain ontologies and to enrich its concepts by applying a system of verb patterns that specify relations between concepts extracted from unstructured text. Their system operated based on outputs from traditional linguistic tools such as part-of-speech taggers and syntactic parsers.

%\cite{wagner2000enriching} used statistical analysis of corpora based on verbs to enrich lexical WordNet in other languages than English. They introduced a novel direction in OL to discover new relations, to enrich concepts, and to enrich the ontology with new concepts via the automatic acquisition of selectional preferences of verbs relating terms by means of statistical corpus analysis. The selectional preferences in a sense helped induce thematic relations, whereby verbal terms were linked to nominal terms that were statistically, selectionally preferred as their complements.

%\cite{hahn2001joint} propose a method to learn new concepts from generating concept hypothesis based on linguistic and conceptual quality labels. Their work incorporates several linguistic dimensions simultaneously (parts of speech, semantic and conceptual encodings) within an integrated approach.

%~\cite{moldovan2001interactive} introduced the Knowledge Acquisition from Text (KAT) system which aimed to discover finance domain-specific concepts and relations based on a seed set of terms to enrich WordNet. It operates in four stages: (1) discovery of new concepts based on a seed set of terms from POS-tagged and parsed sentences, expansion of the concept list based on dictionaries; (2) discovery of new lexical patterns based on the new concepts; (3) discovery of new relations reflected by the lexical patterns; and (4) knowledge classification algorithm to integrate the extracted information in WordNet.

%Each of these related work try to address the knowledge acquisition bottleneck associated with the OL tasks that depend on high levels of domain expertise to be performed well.

%\cite{alfonseca2002unsupervised} proposed a method for enriching ontologies with domain-dependent information in a fully unsupervized way, by putting together methods from different NLP fields such as NER and procedures used in word sense disambiguation (WSD). For the former, their method was grounded on the concept of a general NER system that assigned a more general type to a given concept and thus implicitly enabled the discovery of a taxonomic hierarchy. WSD was used a method to enrich existing synsets with new terms where they queried the internet with existing WordNet synset terms and the new discovered terms were disambiguated to a synset leveraging metrics of semantic distance based on context words cooccurrence frequency.

%General Named Entity Recognition is a task that covers, and is harder than both Named Entity Recognition and Word Sense Disambiguation

%\cite{khan2002ontology} use clustering techniques to discover new terms that were typed using WordNet. And inspired from the field of molecular evolution, they used the self-organizing tree algorithm~\cite{dopazo1997phylogenetic} to discover a hierarchy for an ontology.

%\cite{missikoff2002usable} propose ``the Usable Ontology'' by laying out a desiderata of features that makes an ontology usable such as Coverage, Consensus, and Accessibility. They design an ontology engineering architecture aimed at facilitating the task of populating tourism domain ontologies and building a shared consensus about their actual content. Their OL task comprises a linguistic processor to extract terms based on syntactically plausible terminological patterns from tourism domain documents, builds lexicalized trees of terms generated based on head words as generic references, and fuses the extracted information with WordNet as the upper domain ontology or core domain ontology to assign types to terms

%The cited works provide different approaches to ontology learning (OL) by extracting knowledge from unstructured text to enrich or construct ontologies. In the past, NLP was defined by modular pipelines by which machines were equipped stepwise with annotations at the linguistic, syntactic, and semantic levels to process text. As evident in the relatedThe task of OL was not far removed from the traditional NLP paradigm comprising modules such as tokenizers, lexical processors, POS taggers, NER, and chunkers arranged in a pipeline. Predominantly, the approaches for OL that stand out are based on lexico-syntactic patterns for concept/term and relation extraction, leveraging clustering for types discovery--the latter task being much rare in existing work. Otherwise, seed-term-based bootstrapping methods. LLMs have ushered in a new era of possibilities for AI systems which we tap in to for the first time for the OL task in this work.


%The seminal work by Maedche and Staab~\cite{maedche2001ontology} offered a framework for ontology learning for the semantic web which was formulated as a methodology involving four main tasks, i.e. 1) import and reuse, 2) extraction, 3) pruning, and 4) refinement.


old text
\begin{comment}
In a traditional supervised learning system for NLP, we take an input $x$, usually text, and output $y$ based on a model $P(y|x;\theta)$, where $\theta$ is model learnable parameters and $y$ could be a label from a fixed label set (in a case of \textit{text classification} problem) or text (in a case of \textit{conditional text generation} problem). The major issue with the supervised learning system is that for training model $P(y|x;\theta)$, it is necessary to have supervised data, which for many tasks including ontology learning or integration on new domains we may not be able to find an appropriate number of data for new classes. For example, imagine we want to add another set of concepts from the new disease domain to the knowledge graphs and drive new ontology out of textual information. The first step would be to categorize concepts into different groups and design a hierarchy of conceptual types. In the case of using the traditional supervised learning method, we may want to annotate a huge amount of data for the task, however, this may be repeated anytime that we want to extract ontologies from new domains.

Prompt-based learning in NLP attempts to solve this issue by converting original input $x$ using a \textit{template} into a textual string prompt input $x_{input}^{\prime}$ that has some unfilled slots, and then the LMs is used to probabilistically fill the unfilled information to obtain a final string $x_{output}^{\prime}$, from which the final output $y$ can be derived \cite{prompting}. This technique reduces the need for large supervised datasets, where we can use a small number of samples in the form of zero-shot or few-shot setting for querying LMs for various tasks including ontology learning.  The prompting input is defined as $x_{input}^{\prime}=f_{prompt}(x)$, where $f_{prompt}(.)$ is a prompting function that is applied to modify the input text into $x_{input}^{\prime}$. The $f_{prompt}(.)$ is consist of a two-step process: (1) apply a \textit{template}, and (2) Fill slot $[X]$ with the input $x$. Next $x^{\prime}$ is fed into LM and outputs the answer, where answer engineering comes into the light, intending to search for an answer space $Z$ and a map to the original output $Y$ that results in an effective predictive model \cite{prompting}.
\end{comment}

