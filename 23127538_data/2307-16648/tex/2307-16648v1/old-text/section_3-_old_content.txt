%Ontology learning from text is the process of identifying terms, concepts, relations, and optionally, axioms from textual information and using them to construct an ontology[4].

%Ontology learning involves a sequence of steps (described in figure \ref{llms4ol}) that begin with the creation of a corpus of raw text data, followed by pre-processing to extract and prepare the text for analysis. The next step involves the extraction of terms and the conceptualization of the ontology, which involves grouping and defining similar terms to create a structured representation of concepts and their relationships. This is followed by properties, constraints, and instances definitions. According to our main objective in this research, we endeavor to examine the potential of LLMs in the conceptualization phase of OL. In this section, we first give task definitions of ontology learning.
% In the following sections, we will present our primary formulations and task definitions for investigating LLMs in the context of OL and describe their respective methodologies in addressing our research questions. 

%The first step of the conceptualization phase concerns identifying and categorizing different types of terms/entities within text data. So LLM's ability for entity typing step is crucial for better OL. We will examine whether LLMs can correctly recognize different types of entities and assign them to appropriate categories (e.g. person, location, organization, etc.), which will be the focus of Task A for answering RQ1. Since we do not want to provide any prior knowledge for LLMs about terms and their types, this task is considered a text generation task. Next,  can we leverage LLMs to automate term typing in a predefined semantic space with the capability of automated discovery of candidate classes and subclasses (helping the following tasks as well)? 

% The leveraged LLMs should be able to perform tasks A, B, and C. 
% \hamed{the examples are not from our datasets, I will consider changing it}
% \hamed{Adding example here for templates on tasks}
%\vspace{-0.4cm}

%The Is-A relations are a famous class of relations among entity types since they construct hierarchies/taxonomy of types in a form of a tree structure that organizes concepts and factual entities. According to this, this task aims to investigate whether LLMs can recognize entity type hierarchies within text data. Specifically, we will examine whether LLMs can correctly identify different entity types hierarchies in Is-A relations (e.g. parent-child, is-a), which will provide evidence for RQ2. Due to the limited number of entity types (entity classes) in hierarchies, we considered this task as a zero-shot text classification task.

%Besides RQ2 there is always a possibility to find Non-Is-A relations (e.g. overlapping hierarchies) in text data where mostly represented as graph structures. This task drives to evaluate the ability of LLMs to identify non-is-a relationships within type hierarchical structures which will answer RQ3. Similar to Task B this is a zero-shot text classification task.

% \vspace{-0.4cm}
% \subsubsection{Task D}: Can we leverage LLMs to automate term typing in a predefined semantic space with the capability of automated discovery of candidate classes and subclasses? The leveraged LLMs should be able to perform tasks A, B, and C. 
% Can LLMs be leveraged to automate term typing and in turn support the automated discovery of candidate classes that should constitute an ontology in a predefined semantic space?