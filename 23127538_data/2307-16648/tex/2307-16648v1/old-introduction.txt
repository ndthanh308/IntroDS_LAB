Ontology Learning (OL) is an important field of research in artificial intelligence (AI) and knowledge engineering, as it addresses the challenge of knowledge acquisition and representation in a variety of domains. OL involves automatically identifying terms, types, relations, and potentially axioms from textual information to construct an ontology~\cite{konys2019knowledge}.
%OL is the incremental process of automatically identifying terms, types, relations, and optionally, axioms from textual information and using them to construct an ontology~\cite{konys2019knowledge}. 
Numerous examples of human-expert created ontologies exist, ranging from general-purpose ontologies to domain-specific ones, e.g., Unified Medical Language System (UMLS)~\cite{bodenreider2004unified}, WordNet~\cite{miller1995wordnet}, GeoNames~\cite{rebele2016yago}, Dublin Core Metadata Initiative (DCMI)~\cite{weibel2000dublin}, schema.org~\cite{guha2016schema}, etc. Traditional ontology creation relies on manual specification by domain experts, which can be time-consuming, costly, error-prone, and impractical when knowledge constantly evolves or domain experts are unavailable.
%Traditional approaches to ontology creation and maintenance require domain experts to manually specify the types, relationships, and properties that define a particular domain of knowledge. However, this process can be time-consuming, expensive, and error-prone, particularly in domains where the knowledge is constantly evolving. Furthermore, it may not be feasible to involve domain experts in all cases, as they may not be available or may have limited knowledge in a particular domain. 
Consequently, OL techniques have emerged to automatically acquire knowledge from unstructured or semi-structured sources, such as text documents and the web, and transform it into a structured ontology. A quick review of the field shows that traditional approaches to OL are based on lexico-syntactic pattern mining and clustering~\cite{xu2002domain,missikoff2002usable,lonsdale2002peppering,khan2002ontology,alfonseca2002unsupervised,hahn2001joint,wagner2000enriching,roux2000ontology,kietz2000method,agirre2000enriching,hwang1999incompletely,hearst1998automated}. In contrast, recent advances in natural language processing (NLP) through Large Language Models (LLMs)~\cite{chatgpt} offer a promising alternative to traditional OL methods.
%In contrast, the recent great strides in natural language processing (NLP) brought by Large Language Models (LLMs)~\cite{chatgpt} open a promising avenue in addition to traditional OL methods. 
The ultimate goal of OL is to provide a cost-effective and scalable solution for knowledge acquisition and representation, enabling more efficient and effective decision-making in a range of domains. To this end, we introduce the LLMs4OL paradigm and empirically ground it as a foundational first step.
%In this context, we introduce the LLMs4OL paradigm as a foundational step, supported by empirical evidence.

%These emergent abilities of LLMs are driving breakthroughs in a wide range of fields, and as researchers continue to push the boundaries of what LLMs can do, we can expect to see even more impressive capabilities emerge in the future. At the outset, two main considerations were made. Does the theory of LLMs justify our LLMs4OL hypothesis? Which LLMs should be tested?
%To our knowledge, there is at the time of writing this article no research on training LLMs explicitly for OL. 
As far as we know, there is currently no research on explicitly training LLMs for OL.
Thus to test LLMs for OL for the first time, we made some experimental considerations. The first being: \textit{Do the characteristics of LLMs justify ontology learning?} %First, LLMs are trained on massive scales of text from various domains ranging from billions to trillions of tokens. This makes them akin to knowledge bases with domain-pertinent overviews~\cite{petroni2019language}. That the domain expert who builds an ontology is well-equipped with vast domain knowledge and has a strong overview of the domain is an essential requirement for ontology development. LLMs seemed to pass this check. 
First, LLMs are trained on vast amounts of text from diverse domains, comparable to knowledge bases with domain-specific overviews~\cite{petroni2019language}. This aligns with the requirement for ontology developers to possess extensive domain knowledge.
Second, LLMs are built on the core technology of transformers that has enabled their higher language modeling complexity by facilitating the rapid scaling of their parameters. These parameters represent connections between words, enabling LLMs to comprehend the meaning of unstructured text like sentences or paragraphs.
%These parameters are nothing but connections between words. It is these vast stores of connections between words that essentially allows LLMs to analyze and understand the meaning of unstructured text, such as natural language sentences or paragraphs. 
Further, by extrapolating complex linguistic patterns from word connections, LLMs exhibit human-like response capabilities across various tasks, as observed in the field of ``emergent'' AI. This behavior entails performing tasks beyond their explicit training, such as generating executable code, diverse genre text, and accurate text summaries~\cite{srivastava2022beyond,wei2022emergent}.
%Further, by extrapolating complex linguistic patterns from word connections, they display human-like response abilities across task contexts. Consider the field of ``emergent'' AI focused on recording all the new tasks that LLMs can perform, showing human-like response behavior as comprehension of diverse tasks for which the LLMs were not known to be explicitly trained and therefore can be seen as extrapolated behavior~\cite{srivastava2022beyond,wei2022emergent}. Examples include generating executable computer code, generating stylistic text in diverse genres, and even summarizing lengthy texts with a high degree of accuracy. 
The ability to extrapolate patterns from basic word connections encoding the semantics of language is critical for OL, as ontologies are often built based on analyzing and extrapolating structured information connections such as term-type taxonomies and relations from unstructured text. Consequently, LLMs excel at crystallizing knowledge and patterns from extensive text sources. As OL aims to extract a shared conceptualization by understanding types and relationships from diverse sources~\cite{gruber1995toward}, LLMs fulfill this requirement.
%Thus LLMs have shown to be good at crystallizing knowledge and patterns from vast text sources. Since OL depends on extracting a common understanding of types and relationships from a variety of sources, i.e. extract a shared conceptualization~\cite{gruber1995toward}, LLMs satisfied this second requirement as well. 
Thus the LLMs4OL hypothesis of the fruitful application of LLMs for OL seemed conceptually justified.

%Many of these emergent behaviors illustrate “zero-shot” or “few-shot” learning, which describes an LLM’s ability to solve problems it has never — or rarely — seen before.

LLMs are being developed at a fast pace. At the time of writing of this work, at least 60 different LLMs are reported~\cite{amatriain2023transformer}. This led to our second main experimental consideration. \textit{Which LLMs to test for the LLMs4OL task hypothesis?} 
Validating various LLMs empirically is crucial for advancing NLP and for choosing the most suitable models for specific research tasks. Although LLMs have shown impressive performance in diverse NLP tasks, their effectiveness varies.
%We observe that for any given task, the empirical validation of different LLMs is critical for advancing the field of NLP and ensuring that researchers are using the most effective models for their specific research questions and tasks. While LLMs have achieved impressive results on a wide range of NLP tasks, they are not universally effective. 
Thus, as the empirical foundational groundwork for the LLMs4OL task paradigm, we selected models based on their architectural diversity. There are three main LLM architectures: encoder, decoder, and encoder-decoder. Representatively, we selected the following five state-of-the-art LLMs to empirically validate the LLMs4OL task paradigm: BERT~\cite{bert} as an encoder-only model, BLOOM~\cite{bloom} and GPT-3~\cite{gpt3} are decoder-only models, and finally BART~\cite{bart} and Flan-T5~\cite{flant5} as encoder-decoder models. 
%They are all state-of-the-art LLMs that have been developed for NLP tasks. 
According to recent studies, BERT performs well on tasks such as text classification and named entity recognition~\cite{bert}, BART is effective at text generation and summarization~\cite{bart}, Flan-T5 has achieved high accuracy on a wide range of NLP tasks, including language translation and question answering~\cite{flant5}, BLOOM's multi-task approach has led to robust performance on tasks such as text classification and sequence tagging~\cite{bloom}, and GPT-3 has gained attention for its ability to generate human-like text~\cite{gpt3}. In this work, we aimed to unify these LLMs for their effectiveness under the LLMs4OL paradigm for the first time.

%what are we trying to achieve or show the community with this work?
With the two experimental considerations in place, we now introduce the LLMs4OL paradigm and highlight our contributions. LLMs4OL is centered around the development of ontologies that comprise the following primitives~\cite{maedche2001ontology}: \textbf{1.} a set of strings that describe terminological lexical entries $L$ for conceptual types; \textbf{2.} a set of conceptual types $T$; \textbf{3.} a taxonomy of types in a hierarchy $H_{T}$; \textbf{4.} a set of non-taxonomic relations $R$ described by their domain and range restrictions arranged in a heterarchy of relations $H_{R}$; and \textbf{5.} a set of axioms $A$ that describe additional constraints on the ontology and make implicit facts explicit.

\begin{comment}
\begin{enumerate}
  \item a set of strings that describe terminological lexical entries $L$ for conceptual types;
  \item a set of conceptual types $T$;
  \item a taxonomy of types in a hierarchy $H_{T}$;
  \item a set of non-taxonomic relations $R$ described by their domain and range restrictions arranged in a heterarchy of relations $H_{R}$;
  \item a set of axioms $A$ that describe additional constraints on the ontology and make implicit facts explicit. 
\end{enumerate}
\end{comment}

In this context, the LLMs4OL paradigm laid out for the first time in this work selectively tackles three core aspects of OL as tasks. They are presented as the following research questions (RQs).
\begin{itemize}
    \item \textbf{RQ1}: \textit{Term Typing Task} -- How effective are LLMs for automated type discovery to construct an ontology?
    \item \textbf{RQ2}: \textit{Type Taxonomy Discovery Task} -- How effective are LLMs to recognize a type taxonomy i.e. the ``is-a'' hierarchy between types?
    \item \textbf{RQ3}: \textit{Type Non-Taxonomic Relation Extraction Task} -- How effective are LLMs to discover non-taxonomic relations between types?
\end{itemize}

The diversity of the empirical tests of this work are not just w.r.t. LLMs considered, but also the ontological knowledge domains tested for. Since LLMs are constructed over diverse domains or genres of text, an assumption made in the LLMs4OL paradigm is that they are just as simultaneously capable of OL over diverse knowledge domains. Thus, specifically, we test them for lexico-semantic knowledge in WordNet~\cite{miller1995wordnet}, geographical knowledge in GeoNames~\cite{geonames}, biomedical knowledge in UMLS~\cite{umls}, and web content type representations in Schema.Org~\cite{schemaorg}. Summarily, our main contributions are:

\begin{itemize}
    \item The LLMs4OL task paradigm as a conceptual framework for leveraging LLMs for OL.
    \item An implementation of the LLMs4OL concept leveraging tailored prompt templates for zero-shot OL in the context of three specific tasks, viz. term typing, type taxonomic relation discovery, and type non-taxonomic relation discovery. These tasks are evaluated across unique ontological sources well-known in the community. Our code source with templates and datasets per task are released here \url{https://anonymous.4open.science/r/LLMs4OL}.
    \item A thorough empirical evaluation of seven state-of-the-art LLMs w.r.t. to their suitability for the various OL tasks considered in this work.
\end{itemize}