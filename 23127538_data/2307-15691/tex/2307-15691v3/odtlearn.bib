@article{bertsimas2019optimal,
  title={Optimal prescriptive trees},
  author={Bertsimas, Dimitris and Dunn, Jack and Mundru, Nishanth},
  journal={INFORMS Journal on Optimization},
  volume={1},
  number={2},
  pages={164--183},
  year={2019},
  publisher={INFORMS}
}


@inproceedings{kallus2017recursive,
  title={Recursive partitioning for personalization using observational data},
  author={Kallus, Nathan},
  booktitle={International conference on machine learning},
  pages={1789--1798},
  year={2017},
  organization={PMLR}
}


@book{bertsimas2019machine,
  title={Machine learning under a modern optimization lens},
  author={Bertsimas, Dimitris and Dunn, Jack},
  year={2019},
  publisher={Dynamic Ideas LLC Charlestown, MA}
}


@misc{BoTangOCT,
  author = {Bo Tang},
  title = {Optimal Classification Tree},
  year = {2021},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/LucasBoTang/Optimal_Classification_Trees}},
  commit = {9a5714d}
}

@inproceedings{verwer2019learning,
  title={Learning optimal classification trees using a binary linear program formulation},
  author={Verwer, Sicco and Zhang, Yingqian},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={33},
  number={01},
  pages={1625--1632},
  year={2019}
}


@techreport{therneau1997introduction,
  title={An introduction to recursive partitioning using the RPART routines},
  author={Therneau, Terry M and Atkinson, Elizabeth J and others},
  year={1997},
  institution={Technical report Mayo Foundation}
}
@article{kuhn2008caret,
  title={Caret package},
  author={Kuhn, Max and others},
  journal={Journal of statistical software},
  volume={28},
  number={5},
  pages={1--26},
  year={2008}
}


@inproceedings{mctavish2022fast,
  title={Fast sparse decision tree optimization via reference ensembles},
  author={McTavish, Hayden and Zhong, Chudi and Achermann, Reto and Karimalis, Ilias and Chen, Jacques and Rudin, Cynthia and Seltzer, Margo},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={36},
  number={9},
  pages={9604--9613},
  year={2022}
}


@ARTICLE{Sverdrup2020-jk,
  title     = "policytree: Policy learning via doubly robust empirical welfare
               maximization over trees",
  author    = "Sverdrup, Erik and Kanodia, Ayush and Zhou, Zhengyuan and Athey,
               Susan and Wager, Stefan",
  journal   = "J. Open Source Softw.",
  publisher = "The Open Journal",
  volume    =  5,
  number    =  50,
  pages     =  2232,
  abstract  = "Sverdrup et al., (2020). policytree: Policy learning via doubly
               robust empirical welfare maximization over trees. Journal of Open
               Source Software, 5(50), 2232, https://doi.org/10.21105/joss.02232",
  month     =  jun,
  year      =  2020
}


@ARTICLE{Lin2020-hv,
  title         = "Generalized and scalable optimal sparse decision trees",
  author        = "Lin, Jimmy and Zhong, Chudi and Hu, Diane and Rudin, Cynthia
                   and Seltzer, Margo",
  journal       = "arXiv [cs.LG]",
  abstract      = "Decision tree optimization is notoriously difficult from a
                   computational perspective but essential for the field of
                   interpretable machine learning. Despite efforts over the past
                   40 years, only recently have optimization breakthroughs been
                   made that have allowed practical algorithms to find optimal
                   decision trees. These new techniques have the potential to
                   trigger a paradigm shift where it is possible to construct
                   sparse decision trees to efficiently optimize a variety of
                   objective functions without relying on greedy splitting and
                   pruning heuristics that often lead to suboptimal solutions.
                   The contribution in this work is to provide a general
                   framework for decision tree optimization that addresses the
                   two significant open problems in the area: treatment of
                   imbalanced data and fully optimizing over continuous
                   variables. We present techniques that produce optimal
                   decision trees over a variety of objectives including
                   F-score, AUC, and partial area under the ROC convex hull. We
                   also introduce a scalable algorithm that produces provably
                   optimal results in the presence of continuous variables and
                   speeds up decision tree construction by several orders of
                   magnitude relative to the state-of-the art.",
  month         =  jun,
  year          =  2020,
  archivePrefix = "arXiv",
  primaryClass  = "cs.LG"
}


@ARTICLE{Grubinger2014-zl,
  title     = "Evtree: Evolutionary learning of globally optimal classification
               and regression trees {inR}",
  author    = "Grubinger, Thomas and Zeileis, Achim and Pfeiffer, Karl-Peter",
  journal   = "J. Stat. Softw.",
  publisher = "Foundation for Open Access Statistic",
  volume    =  61,
  number    =  1,
  pages     = "1--29",
  abstract  = "Commonly used classification and regression tree methods like the
               CART algorithm are recursive partitioning methods that build the
               model in a forward stepwise search. Although this approach is
               known to be an efficient heuristic, the results of recursive tree
               methods are only locally optimal, as splits are chosen to
               maximize homogeneity at the next step only. An alternative way to
               search over the parameter space of trees is to use global
               optimization methods like evolutionary algorithms. This paper
               describes the evtree package, which implements an evolutionary
               algorithm for learning globally optimal classification and
               regression trees in R. Computationally intensive tasks are fully
               computed in C++ while the partykit package is leveraged for
               representing the resulting trees in R, providing unified
               infrastructure for summaries, visualizations, and predictions.
               evtree is compared to the open-source CART implementation rpart,
               conditional inference trees (ctree), and the open-source C4.5
               implementation J48. A benchmark study of predictive accuracy and
               complexity is carried out in which evtree achieved at least
               similar and most of the time better results compared to rpart,
               ctree, and J48. Furthermore, the usefulness of evtree in practice
               is illustrated in a textbook customer classification task.",
  month     =  oct,
  year      =  2014,
  language  = "en"
}


@article{amram2022optimal,
  title={Optimal policy trees},
  author={Amram, Maxime and Dunn, Jack and Zhuo, Ying Daisy},
  journal={Machine Learning},
  volume={111},
  number={7},
  pages={2741--2768},
  year={2022},
  publisher={Springer}
}



@inproceedings{aglin2021pydl8,
  title={Pydl8. 5: a library for learning optimal decision trees},
  author={Aglin, Ga{\"e}l and Nijssen, Siegfried and Schaus, Pierre},
  booktitle={Proceedings of the Twenty-Ninth International Conference on International Joint Conferences on Artificial Intelligence},
  pages={5222--5224},
  year={2021}
}



@inproceedings{aglin2020learning,
  title={Learning optimal decision trees using caching branch-and-bound search},
  author={Aglin, Ga{\"e}l and Nijssen, Siegfried and Schaus, Pierre},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={34},
  number={04},
  pages={3146--3153},
  year={2020}
}



@inproceedings{Chen:2016:XST:2939672.2939785,
 author = {Chen, Tianqi and Guestrin, Carlos},
 title = {{XGBoost}: A Scalable Tree Boosting System},
 booktitle = {Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
 series = {KDD '16},
 year = {2016},
 isbn = {978-1-4503-4232-2},
 location = {San Francisco, California, USA},
 pages = {785--794},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/2939672.2939785},
 doi = {10.1145/2939672.2939785},
 acmid = {2939785},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {large-scale machine learning},
}

@article{hart2011pyomo,
  title={Pyomo: modeling and solving mathematical programs in {P}ython},
  author={Hart, William E and Watson, Jean-Paul and Woodruff, David L},
  journal={Mathematical Programming Computation},
  volume={3},
  pages={219--260},
  year={2011},
  publisher={Springer}
}



@article{santos2020mixed,
  title={Mixed integer linear programming with {P}ython},
  author={Santos, Haroldo G and Toffolo, T},
  journal={Accessed: Apr},
  year={2020}
}

@article{mitchell2011pulp,
  title={PuLP: a linear programming toolkit for {P}ython},
  author={Mitchell, Stuart and OSullivan, Michael and Dunning, Iain},
  journal={The University of Auckland, Auckland, New Zealand},
  volume={65},
  year={2011}
}



@misc{gurobi,
  author = {{Gurobi Optimization, LLC}},
  title = {{Gurobi Optimizer Reference Manual}},
  year = 2023,
  url = "https://www.gurobi.com"
}

@misc{cbc,
  author       = {John Forrest and
                  Ted Ralphs and
                  Haroldo Gambini Santos and
                  Stefan Vigerske and
                  John Forrest and
                  Lou Hafer and
                  Bjarni Kristjansson and
                  jpfasano and
                  EdwinStraver and
                  Miles Lubin and
                  Jan-Willem and
                  rlougee and
                  jpgoncal1 and
                  Samuel Brito and
                  h-i-Gassmann and
                  Cristina and
                  Matthew Saltzman and
                  tosttost and
                  Bruno Pitrus and
                  Fumiaki MATSUSHIMA and
                  to-st},
  title        = {coin-or/Cbc: Release releases/2.10.10},
  month        = apr,
  year         = 2023,
  publisher    = {Zenodo},
  version      = {releases/2.10.10},
  doi          = {10.5281/zenodo.7843975},
  url          = {https://doi.org/10.5281/zenodo.7843975}
}

@article{Julia-2017,
    title={Julia: A fresh approach to numerical computing},
    author={Bezanson, Jeff and Edelman, Alan and Karpinski, Stefan and Shah, Viral B},
    journal={SIAM {R}eview},
    volume={59},
    number={1},
    pages={65--98},
    year={2017},
    publisher={SIAM},
    doi={10.1137/141000671},
    url={https://epubs.siam.org/doi/10.1137/141000671}
}

@inproceedings{kearns2018preventing,
  title={Preventing fairness gerrymandering: Auditing and learning for subgroup fairness},
  author={Kearns, Michael and Neel, Seth and Roth, Aaron and Wu, Zhiwei Steven},
  booktitle={International conference on machine learning},
  pages={2564--2572},
  year={2018},
  organization={PMLR}
}



@inproceedings{celis2019classification,
  title={Classification with fairness constraints: A meta-algorithm with provable guarantees},
  author={Celis, L Elisa and Huang, Lingxiao and Keswani, Vijay and Vishnoi, Nisheeth K},
  booktitle={Proceedings of the conference on fairness, accountability, and transparency},
  pages={319--328},
  year={2019}
}



@inproceedings{agarwal2018reductions,
  title={A reductions approach to fair classification},
  author={Agarwal, Alekh and Beygelzimer, Alina and Dud{\'\i}k, Miroslav and Langford, John and Wallach, Hanna},
  booktitle={International Conference on Machine Learning},
  pages={60--69},
  year={2018},
  organization={PMLR}
}

@book{martin2003agile,
  title={Agile software development: principles, patterns, and practices},
  author={Martin, Robert Cecil},
  year={2003},
  publisher={Prentice Hall PTR}
}


@article{zhou2022offline,
  title={Offline multi-action policy learning: Generalization and optimization},
  author={Zhou, Zhengyuan and Athey, Susan and Wager, Stefan},
  journal={Operations Research},
  year={2022},
  publisher={INFORMS}
}



@article{Sverdrup2020, doi = {10.21105/joss.02232}, url = {https://doi.org/10.21105/joss.02232}, year = {2020}, publisher = {The Open Journal}, volume = {5}, number = {50}, pages = {2232}, author = {Erik Sverdrup and Ayush Kanodia and Zhengyuan Zhou and Susan Athey and Stefan Wager}, title = {policytree: Policy learning via doubly robust empirical welfare maximization over trees}, journal = {Journal of Open Source Software} } 

@misc{InterpretableAI,
  author = "Interpretable AI, LLC",
  title = "Interpretable {AI} Documentation",
  year = 2022,
  url = "https://www.interpretable.ai"
}


@misc{aif360-oct-2018,
    title = "{AI Fairness} 360:  An Extensible Toolkit for Detecting, Understanding, and Mitigating Unwanted Algorithmic Bias",
    author = {Rachel K. E. Bellamy and Kuntal Dey and Michael Hind and
	Samuel C. Hoffman and Stephanie Houde and Kalapriya Kannan and
	Pranay Lohia and Jacquelyn Martino and Sameep Mehta and
	Aleksandra Mojsilovic and Seema Nagar and Karthikeyan Natesan Ramamurthy and
	John Richards and Diptikalyan Saha and Prasanna Sattigeri and
	Moninder Singh and Kush R. Varshney and Yunfeng Zhang},
    month = oct,
    year = {2018},
    url = {https://arxiv.org/abs/1810.01943}
}

@misc{causalinference360,
  author = {Shimoni, Yishai and Karavani, Ehud and Ravid, Sivan and Bak, Peter and Ng, Tan Hung and Alford, Sharon Hensley and Meade, Denise and Goldschmidt, Yaara},
  title = {An Evaluation Toolkit to Guide Model Selection and Cohort Definition in Causal Inference},
  publisher = {arXiv},
  year = {2019},
  copyright = {Creative Commons Attribution Share Alike 4.0 International}
}

@techreport{bird2020fairlearn,
    author = {Bird, Sarah and Dud{\'i}k, Miro and Edgar, Richard and Horn, Brandon and Lutz, Roman and Milan, Vanessa and Sameki, Mehrnoosh and Wallach, Hanna and Walker, Kathleen},
    title = {Fairlearn: A toolkit for assessing and improving fairness in {AI}},
    institution = {Microsoft},
    year = {2020},
    month = {May},
    url = "https://www.microsoft.com/en-us/research/publication/fairlearn-a-toolkit-for-assessing-and-improving-fairness-in-ai/",
    number = {MSR-TR-2020-32},
}

@misc{econml,
  author={Battocchi, Keith and Dillon, Eleanor and Hei, Maggie and Lewis, Greg and Oka, Paul and Oprescu, Miruna and Syrgkanis, Vasilis},
  title={{EconML}: {A {P}ython Package for ML-Based Heterogeneous Treatment Effects Estimation}},
  howpublished={https://github.com/microsoft/EconML},
  note={Version 0.13.1},
  year={2019}
}

@article{tibshirani2022package,
  title={Package ‘grf’},
  author={Tibshirani, Julie and Athey, Susan and Friedberg, Rina and Hadad, Vitor and Hirshberg, David and Miner, Luke and Sverdrup, Erik and Wager, Stefan and Wright, Marvin and Tibshirani, Maintainer Julie},
  year={2022}
}

@Article{Hunter2007,
  Author    = {Hunter, J. D.},
  Title     = {Matplotlib: A 2D graphics environment},
  Journal   = {Computing in Science \& Engineering},
  Volume    = {9},
  Number    = {3},
  Pages     = {90--95},
  abstract  = {Matplotlib is a 2D graphics package used for {P}ython for
  application development, interactive scripting, and publication-quality
  image generation across user interfaces and operating systems.},
  publisher = {IEEE COMPUTER SOC},
  doi       = {10.1109/MCSE.2007.55},
  year      = 2007
}

@inproceedings{aghaei2019learning,
  title={Learning optimal and fair decision trees for non-discriminative decision-making},
  author={Aghaei, Sina and Azizi, Mohammad Javad and Vayanos, Phebe},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={33},

  pages={1418--1426},
  year={2019}
}


@book{breiman1984classification,
  title={Classification and regression trees},
  author={Breiman, Leo and Friedman, Jerome H and Olshen, Richard A and Stone, Charles J},
  year={1984},
  publisher={Routledge}
}



@article{bertsimas2017optimal,
  title={Optimal classification trees},
  author={Bertsimas, Dimitris and Dunn, Jack},
  journal={Machine Learning},
  volume={106},
  number={7},
  pages={1039--1082},
  year={2017},
  publisher={Springer}
}



@inproceedings{mckinney2010data,
  title={Data structures for statistical computing in {P}ython},
  author={McKinney, Wes and others},
  booktitle={Proceedings of the 9th {P}ython in Science Conference},
  volume={445},
  pages={51--56},
  year={2010},
  organization={Austin, TX}
}

@article{harris2020array,
  title={Array programming with {N}umPy},
  author={Harris, Charles R and Millman, K Jarrod and Van Der Walt, St{\'e}fan J and Gommers, Ralf and Virtanen, Pauli and Cournapeau, David and Wieser, Eric and Taylor, Julian and Berg, Sebastian and Smith, Nathaniel J and others},
  journal={Nature},
  volume={585},
  number={7825},
  pages={357--362},
  year={2020},
  publisher={Nature Publishing Group}
}

@article{pedregosa2011scikit,
  title={Scikit-learn: Machine learning in {P}ython},
  author={Pedregosa, Fabian and Varoquaux, Ga{\"e}l and Gramfort, Alexandre and Michel, Vincent and Thirion, Bertrand and Grisel, Olivier and Blondel, Mathieu and Prettenhofer, Peter and Weiss, Ron and Dubourg, Vincent and others},
  journal={Journal of Machine Learning Research},
  volume={12},
  pages={2825--2830},
  year={2011},
  publisher={JMLR. org}
}


@article{aghaei2021strong,
  title={Strong optimal classification trees},
  author={Aghaei, Sina and G{\'o}mez, Andr{\'e}s and Vayanos, Phebe},
  journal={arXiv preprint arXiv:2103.15965},
  year={2021}
}

@inproceedings{justin2021optimal,
  title={Optimal robust classification trees},
  author={Justin, Nathan and Aghaei, Sina and Gomez, Andres and Vayanos, Phebe},
  booktitle={The AAAI-22 Workshop on Adversarial Machine Learning and Beyond},
  year={2021}
}

@article{jo2022learning,
  title={Learning Optimal Fair Classification Trees},
  author={Jo, Nathanael and Aghaei, Sina and Benson, Jack and G{\'o}mez, Andr{\'e}s and Vayanos, Phebe},
  journal={arXiv preprint arXiv:2201.09932},
  year={2022}
}

@article{jo2021learning,
  title={Learning optimal prescriptive trees from observational data},
  author={Jo, Nathanael and Aghaei, Sina and G{\'o}mez, Andr{\'e}s and Vayanos, Phebe},
  journal={arXiv preprint arXiv:2108.13628},
  year={2021}
}

@misc{buitinck_api_2013,
	title = {{API} design for machine learning software: experiences from the scikit-learn project},
	shorttitle = {{API} design for machine learning software},
	url = {http://arxiv.org/abs/1309.0238},
	doi = {10.48550/arXiv.1309.0238},
	abstract = {Scikit-learn is an increasingly popular machine learning li- brary. Written in {P}ython, it is designed to be simple and efficient, accessible to non-experts, and reusable in various contexts. In this paper, we present and discuss our design choices for the application programming interface (API) of the project. In particular, we describe the simple and elegant interface shared by all learning and processing units in the library and then discuss its advantages in terms of composition and reusability. The paper also comments on implementation details specific to the {P}ython ecosystem and analyzes obstacles faced by users and developers of the library.},
	urldate = {2022-07-11},
	publisher = {arXiv},
	author = {Buitinck, Lars and Louppe, Gilles and Blondel, Mathieu and Pedregosa, Fabian and Mueller, Andreas and Grisel, Olivier and Niculae, Vlad and Prettenhofer, Peter and Gramfort, Alexandre and Grobler, Jaques and Layton, Robert and Vanderplas, Jake and Joly, Arnaud and Holt, Brian and Varoquaux, Gaël},
	month = sep,
	year = {2013},
	note = {arXiv:1309.0238 [cs]},
	keywords = {Computer Science - Machine Learning, Computer Science - Mathematical Software},
	file = {arXiv.org Snapshot:/Users/patrick/Zotero/storage/JBNQXC8V/1309.html:text/html;Buitinck et al_2013_API design for machine learning software.pdf:/Users/patrick/Dropbox/Apps/GoodNotes 5/GoodNotes/2013/Buitinck et al_2013_API design for machine learning software.pdf:application/pdf},
}

