\begin{thebibliography}{32}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Abdelnabi \& Fritz(2021)Abdelnabi and Fritz]{adversarial_watermarking}
Sahar Abdelnabi and Mario Fritz.
\newblock {Adversarial Watermarking Transformer: Towards Tracing Text
  Provenance with Data Hiding}.
\newblock In \emph{2021 IEEE Symposium on Security and Privacy (SP)}, pp.\
  121--140. IEEE, 2021.

\bibitem[Bakhtin et~al.(2019)Bakhtin, Gross, Ott, Deng, Ranzato, and
  Szlam]{real_or_fake}
Anton Bakhtin, Sam Gross, Myle Ott, Yuntian Deng, Marc'Aurelio Ranzato, and
  Arthur Szlam.
\newblock {Real or Fake? Learning to Discriminate Machine from Human-Generated
  Text}.
\newblock \emph{arXiv preprint arXiv:1906.03351}, 2019.

\bibitem[Devlin et~al.(2019)Devlin, Chang, Lee, and Toutanova]{bert}
Jacob Devlin, Ming{-}Wei Chang, Kenton Lee, and Kristina Toutanova.
\newblock {BERT: Pre-training of Deep Bidirectional Transformers for Language
  Understanding}.
\newblock In \emph{Proceedings of the 2019 Conference of the North American
  Chapter of the Association for Computational Linguistics: Human Language
  Technologies, {NAACL-HLT} 2019, Minneapolis, MN, USA, June 2-7, 2019, Volume
  1 (Long and Short Papers)}, pp.\  4171--4186, 2019.

\bibitem[Jalil \& Mirza(2009)Jalil and Mirza]{review_of_digital_watermarking}
Zunera Jalil and Anwar~M Mirza.
\newblock {A Review of Digital Watermarking Techniques for Text Documents}.
\newblock In \emph{2009 International Conference on Information and Multimedia
  Technology}, pp.\  230--234. IEEE, 2009.

\bibitem[Jawahar et~al.(2020)Jawahar, Abdul-Mageed, and
  Lakshmanan]{automatic_detection}
Ganesh Jawahar, Muhammad Abdul-Mageed, and Laks~VS Lakshmanan.
\newblock {Automatic Detection of Machine-Generated Text: A Critical Survey}.
\newblock \emph{arXiv preprint arXiv:2011.01314}, 2020.

\bibitem[Kirchenbauer et~al.(2023{\natexlab{a}})Kirchenbauer, Geiping, Wen,
  Katz, Miers, and Goldstein]{watermark_llm}
John Kirchenbauer, Jonas Geiping, Yuxin Wen, Jonathan Katz, Ian Miers, and Tom
  Goldstein.
\newblock {A Watermark for Large Language Models}.
\newblock \emph{arXiv preprint arXiv:2301.10226}, 2023{\natexlab{a}}.

\bibitem[Kirchenbauer et~al.(2023{\natexlab{b}})Kirchenbauer, Geiping, Wen,
  Shu, Saifullah, Kong, Fernando, Saha, Goldblum, and
  Goldstein]{reliability_of_watermark}
John Kirchenbauer, Jonas Geiping, Yuxin Wen, Manli Shu, Khalid Saifullah, Kezhi
  Kong, Kasun Fernando, Aniruddha Saha, Micah Goldblum, and Tom Goldstein.
\newblock {On the Reliability of Watermarks for Large Language Models}.
\newblock \emph{arXiv preprint arXiv:2306.04634}, 2023{\natexlab{b}}.

\bibitem[Koike et~al.(2023)Koike, Kaneko, and Okazaki]{new-detection-1}
Ryuto Koike, Masahiro Kaneko, and Naoaki Okazaki.
\newblock {OUTFOX: LLM-generated Essay Detection through In-context Learning
  with Adversarially Generated Examples}.
\newblock \emph{CoRR}, abs/2307.11729, 2023.

\bibitem[Krishna et~al.(2023)Krishna, Song, Karpinska, Wieting, and
  Iyyer]{paraphrasing_attack}
Kalpesh Krishna, Yixiao Song, Marzena Karpinska, John Wieting, and Mohit Iyyer.
\newblock {Paraphrasing Evades Detectors of AI-Generated Text, but Retrieval is
  an Effective Defense}.
\newblock \emph{arXiv preprint arXiv:2303.13408}, 2023.

\bibitem[Lee et~al.(2023)Lee, Hong, Ahn, Hong, Lee, Yun, Shin, and Kim]{sweet}
Taehyun Lee, Seokhee Hong, Jaewoo Ahn, Ilgee Hong, Hwaran Lee, Sangdoo Yun,
  Jamin Shin, and Gunhee Kim.
\newblock {Who Wrote this Code? Watermarking for Code Generation}.
\newblock \emph{arXiv preprint arXiv:2305.15060}, 2023.

\bibitem[Liu et~al.(2019)Liu, Ott, Goyal, Du, Joshi, Chen, Levy, Lewis,
  Zettlemoyer, and Stoyanov]{roberta}
Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer
  Levy, Mike Lewis, Luke Zettlemoyer, and Veselin Stoyanov.
\newblock {Roberta: A Robustly Optimized Bert Pretraining Approach}.
\newblock \emph{arXiv preprint arXiv:1907.11692}, 2019.

\bibitem[Mitchell et~al.(2023)Mitchell, Lee, Khazatsky, Manning, and
  Finn]{detectgpt}
Eric Mitchell, Yoonho Lee, Alexander Khazatsky, Christopher~D Manning, and
  Chelsea Finn.
\newblock {Detectgpt: Zero-Shot Machine-Generated Text Detection using
  Probability Curvature}.
\newblock \emph{arXiv preprint arXiv:2301.11305}, 2023.

\bibitem[Mitrovi{\'c} et~al.(2023)Mitrovi{\'c}, Andreoletti, and
  Ayoub]{chatgpt_or_human}
Sandra Mitrovi{\'c}, Davide Andreoletti, and Omran Ayoub.
\newblock {Chatgpt or Human? Detect and Explain. Explaining Decisions of
  Machine Learning Model for Detecting Short Chatgpt-Generated Text}.
\newblock \emph{arXiv preprint arXiv:2301.13852}, 2023.

\bibitem[OpenAI(2019)]{gpt-2-release}
OpenAI.
\newblock {GPT-2: 1.5B Release}.
\newblock November 2019.
\newblock URL \url{https://openai.com/research/gpt-2-1-5b-release}.

\bibitem[OpenAI(2022)]{chatgpt}
OpenAI.
\newblock {ChatGPT: Optimizing Language Models for Dialogue}.
\newblock November 2022.
\newblock URL \url{https://openai.com/blog/chatgpt/}.

\bibitem[OpenAI(2023)]{openai_classifier}
OpenAI.
\newblock {New AI Classifier for Indicating AI-Written Text}, 2023.
\newblock URL
  \url{https://openai.com/blog/new-ai-classifier-for-indicating-ai-written-text}.

\bibitem[Radford et~al.(2019)Radford, Wu, Child, Luan, Amodei, and
  Sutskever]{gpt2}
Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, and Ilya
  Sutskever.
\newblock {Language Models are Unsupervised Multitask Learners}.
\newblock \emph{OpenAI blog}, 1\penalty0 (8):\penalty0 9, 2019.

\bibitem[Raffel et~al.(2019)Raffel, Shazeer, Roberts, Lee, Narang, Matena,
  Zhou, Li, and Liu]{2019t5}
Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael
  Matena, Yanqi Zhou, Wei Li, and Peter~J. Liu.
\newblock {Exploring the Limits of Transfer Learning with a Unified
  Text-to-Text Transformer}.
\newblock \emph{arXiv e-prints}, 2019.

\bibitem[Sadasivan et~al.(2023)Sadasivan, Kumar, Balasubramanian, Wang, and
  Feizi]{reliably_detect}
Vinu~Sankar Sadasivan, Aounon Kumar, Sriram Balasubramanian, Wenxiao Wang, and
  Soheil Feizi.
\newblock {Can AI-Generated Text be Reliably Detected?}
\newblock \emph{arXiv preprint arXiv:2303.11156}, 2023.

\bibitem[Sanh et~al.(2019)Sanh, Debut, Chaumond, and Wolf]{distilbert}
Victor Sanh, Lysandre Debut, Julien Chaumond, and Thomas Wolf.
\newblock {DistilBERT, a Distilled Version of BERT: Smaller, Faster, Cheaper
  and Lighter}.
\newblock \emph{arXiv preprint arXiv:1910.01108}, 2019.

\bibitem[Solaiman et~al.(2019)Solaiman, Brundage, Clark, Askell, Herbert-Voss,
  Wu, Radford, Krueger, Kim, Kreps, et~al.]{release_strategies}
Irene Solaiman, Miles Brundage, Jack Clark, Amanda Askell, Ariel Herbert-Voss,
  Jeff Wu, Alec Radford, Gretchen Krueger, Jong~Wook Kim, Sarah Kreps, et~al.
\newblock {Release Strategies and the Social Impacts of Language Models}.
\newblock \emph{arXiv preprint arXiv:1908.09203}, 2019.

\bibitem[Tian(2023)]{gptzero}
Edward Tian.
\newblock {GPTZero}.
\newblock 2023.
\newblock URL \url{https://gptzero.me/}.

\bibitem[Touvron et~al.(2023)Touvron, Lavril, Izacard, Martinet, Lachaux,
  Lacroix, Rozi{\`e}re, Goyal, Hambro, Azhar, et~al.]{llama}
Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne
  Lachaux, Timoth{\'e}e Lacroix, Baptiste Rozi{\`e}re, Naman Goyal, Eric
  Hambro, Faisal Azhar, et~al.
\newblock {Llama: Open and efficient foundation language models}.
\newblock \emph{arXiv preprint arXiv:2302.13971}, 2023.

\bibitem[Venugopal et~al.(2011)Venugopal, Uszkoreit, Talbot, Och, and
  Ganitkevitch]{watermarking_statistical_mt}
Ashish Venugopal, Jakob Uszkoreit, David Talbot, Franz~Josef Och, and Juri
  Ganitkevitch.
\newblock {Watermarking the Outputs of Structured Prediction with an
  Application in Statistical Machine Translation.}
\newblock In \emph{Proceedings of the 2011 Conference on Empirical Methods in
  Natural Language Processing}, pp.\  1363--1372, 2011.

\bibitem[Wolf et~al.(2019)Wolf, Debut, Sanh, Chaumond, Delangue, Moi, Cistac,
  Rault, Louf, Funtowicz, and Brew]{Wolf2019HuggingFacesTS}
Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue,
  Anthony Moi, Pierric Cistac, Tim Rault, R{\'e}mi Louf, Morgan Funtowicz, and
  Jamie Brew.
\newblock {HuggingFace's Transformers: State-of-the-art Natural Language
  Processing}.
\newblock \emph{ArXiv}, abs/1910.03771, 2019.

\bibitem[Wu et~al.(2023)Wu, Pang, Shen, Cheng, and Chua]{llmdet}
Kangxi Wu, Liang Pang, Huawei Shen, Xueqi Cheng, and Tat-Seng Chua.
\newblock {LLMDet: A Large Language Models Detection Tool}.
\newblock \emph{arXiv preprint arXiv:2305.15004}, 2023.

\bibitem[Yang et~al.(2023{\natexlab{a}})Yang, Jiang, and Li]{new-detection-2}
Lingyi Yang, Feng Jiang, and Haizhou Li.
\newblock {Is ChatGPT Involved in Texts? Measure the Polish Ratio to Detect
  ChatGPT-Generated Text}.
\newblock \emph{CoRR}, abs/2307.11380, 2023{\natexlab{a}}.

\bibitem[Yang et~al.(2022)Yang, Zhang, Chen, Zhang, Ma, Wang, and
  Yu]{tracing_text_provenance}
Xi~Yang, Jie Zhang, Kejiang Chen, Weiming Zhang, Zehua Ma, Feng Wang, and
  Nenghai Yu.
\newblock {Tracing Text Provenance via Context-Aware Lexical Substitution}.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial
  Intelligence}, volume~36, pp.\  11613--11621, 2022.

\bibitem[Yang et~al.(2023{\natexlab{b}})Yang, Chen, Zhang, Liu, Qi, Zhang,
  Fang, and Yu]{black_box_watermark}
Xi~Yang, Kejiang Chen, Weiming Zhang, Chang Liu, Yuang Qi, Jie Zhang, Han Fang,
  and Nenghai Yu.
\newblock {Watermarking Text Generated by Black-Box Language Models}.
\newblock \emph{arXiv preprint arXiv:2305.08883}, 2023{\natexlab{b}}.

\bibitem[Yoo et~al.(2023)Yoo, Ahn, Jang, and Kwak]{acl_muilit_bit}
KiYoon Yoo, Wonhyuk Ahn, Jiho Jang, and Nojun Kwak.
\newblock {Robust Multi-bit Natural Language Watermarking through Invariant
  Features}.
\newblock In \emph{Proceedings of the 61st Annual Meeting of the Association
  for Computational Linguistics (Volume 1: Long Papers)}, pp.\  2092--2115,
  2023.

\bibitem[Zhang et~al.(2022)Zhang, Roller, Goyal, Artetxe, Chen, Chen, Dewan,
  Diab, Li, Lin, Mihaylov, Ott, Shleifer, Shuster, Simig, Koura, Sridhar, Wang,
  and Zettlemoyer]{Zhang2022OPTOP}
Susan Zhang, Stephen Roller, Naman Goyal, Mikel Artetxe, Moya Chen, Shuohui
  Chen, Christopher Dewan, Mona Diab, Xian Li, Xi~Victoria Lin, Todor Mihaylov,
  Myle Ott, Sam Shleifer, Kurt Shuster, Daniel Simig, Punit~Singh Koura, Anjali
  Sridhar, Tianlu Wang, and Luke Zettlemoyer.
\newblock {OPT: Open Pre-trained Transformer Language Models}.
\newblock \emph{ArXiv}, abs/2205.01068, 2022.

\bibitem[Zhao et~al.(2023)Zhao, Ananth, Li, and
  Wang]{provable_robust_watermark}
Xuandong Zhao, Prabhanjan~Vijendra Ananth, Lei Li, and Yu-Xiang Wang.
\newblock {Provable Robust Watermarking for AI-Generated Text}.
\newblock 2023.

\end{thebibliography}
