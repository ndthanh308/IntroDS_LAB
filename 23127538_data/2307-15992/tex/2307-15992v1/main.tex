
\documentclass{article} % For LaTeX2e
\usepackage{iclr2023_conference,times}

% Optional math commands from https://github.com/goodfeli/dlbook_notation.
\input{math_commands.tex}

\usepackage{hyperref}
\usepackage{url}
% \usepackage{subfig}
\usepackage{graphicx}
\usepackage{subcaption}
\usepackage{etoolbox}
\usepackage{mdframed}
\usepackage{makecell}
\usepackage[ruled]{algorithm2e}
% \usepackage{algorithm}
% \usepackage{algorithmic}


\usepackage{etoolbox}
\usepackage{xcolor}
\usepackage{multirow}
\usepackage{booktabs}


\newbool{showcomments}
\booltrue{showcomments} % Set to true to display comments, false to hide them
\newcommand{\wang}[1]{\ifbool{showcomments}{\textcolor{brown}{[#1 - wang]}}{}}
\newcommand{\deli}[1]{\ifbool{showcomments}{\textcolor{red}{[#1 - deli]}}{}}
\newcommand{\tux}[1]{\ifbool{showcomments}{\textcolor{violet}{[#1 - tux]}}{}}


\title{Towards Codable Text Watermarking for Large Language Models}

% Authors must not appear in the submitted version. They should be hidden
% as long as the \iclrfinalcopy macro remains commented out below.
% Non-anonymous submissions will be rejected without review.


\author{%
  Lean Wang\thanks{\quad Equal contribution. The work was done while Lean Wang and Wenkai Yang were in Tencent internship.}\hspace{0.5em}$^{1,2}$,
  Wenkai Yang$^{\ast}$\thanks{\quad Part of the work was done while Wenkai Yang was at Peking University.}\hspace{0.5em}$^{1,3}$,
  Deli Chen$^{\ast}$$^{1}$,
\\ \textbf{Hao Zhou}$^{1}$\textbf{,} 
  \textbf{Yankai Lin}$^{3}$\textbf{,} 
  \textbf{Fandong Meng}$^{1}$\textbf{,} 
  \textbf{Jie Zhou}$^{1}$\textbf{,} 
  \textbf{Xu Sun}$^{2}$ \\
  \textsuperscript{1}{Pattern Recognition Center, WeChat AI, Tencent Inc., China}\\
  \textsuperscript{2}{National Key Laboratory for Multimedia Information Processing,} \\
  {\, School of Computer Science, Peking University} \\
  \textsuperscript{3}{Gaoling School of Artificial Intelligence, Renmin University of China} \\
  \texttt{\{lean, xusun\}@pku.edu.cn}, \\ 
  \texttt{kevenyang98@gmail.com}, \quad\texttt{yankailin@ruc.edu.cn} \\
  \texttt{\{delichen, tuxzhou, fandongmeng, withtomzhou\}@tencent.com}
}

% The \author macro works with any number of authors. There are two commands
% used to separate the names and addresses of multiple authors: \And and \AND.
%
% Using \And between authors leaves it to \LaTeX{} to determine where to break
% the lines. Using \AND forces a linebreak at that point. So, if \LaTeX{}
% puts 3 of 4 authors names on the first line, and the last on the second
% line, try using \AND instead of \And before the third author name.

\newcommand{\fix}{\marginpar{FIX}}
\newcommand{\new}{\marginpar{NEW}}

%\iclrfinalcopy % Uncomment for camera-ready version, but NOT for submission.
% \fancyhead{}
\begin{document}


\maketitle

\begin{abstract}
As large language models (LLMs) generate texts with increasing fluency and realism, there is a growing need to identify the source of texts to prevent the abuse of LLMs.
Text watermarking techniques have proven reliable in distinguishing whether a text is generated by LLMs by injecting hidden patterns into the generated texts.
However, we argue that existing watermarking methods for LLMs are encoding-inefficient (only contain one bit of information - whether it is generated from an LLM or not) and cannot flexibly meet the diverse information encoding needs (such as encoding model version, generation time, user id, etc.) in different LLMs application scenarios. 
In this work, we conduct the first systematic study on the topic of~\textbf{Codable Text Watermarking for LLMs} (CTWL) that allows text watermarks to carry more customizable information.
% For example, in copyright protection, we may need to encode the model owner and generation time; in model debugging, we may need to encode the model version and parameter settings, etc. 
First of all, we study the taxonomy of LLM watermarking technology and give a mathematical formulation for CTWL. 
Additionally, we provide a comprehensive evaluation system for CTWL: (1)~watermarking success rate, (2)~robustness against various corruptions, (3)~coding rate of payload information, (4)~encoding and decoding efficiency, (5)~impacts on the quality of the generated text. 
To meet the requirements of these non-Pareto-improving metrics, we devise a CTWL method named~\textbf{Balance-Marking}, based on the motivation of %ensuring that the probability of available and unavailable parts in the vocabulary is as close to 50-50 as possible.
% ensuring that the available parts in the vocabulary contain high-probability tokens for a high-quality generation.
ensuring that available and unavailable vocabularies for encoding information have approximately equivalent probabilities. 
Compared to the random vocabulary partitioning extended from the existing work, a probability-balanced vocabulary partition can significantly improve the quality of the generated text.
% Extensive experimental results have shown that our method outperforms a direct baseline in the evaluation of the above five indicators.
Extensive experimental results have shown that our method outperforms a direct baseline under comprehensive evaluation.
% We also conducted further research to analyze how to adjust our method to adapt to different LLMs application scenarios.
% We also conduct analytical experiments to show how CTWL should make trade-offs in design to meet different requirements in different application scenarios. 
We hope this work can raise the communityâ€™s awareness of the importance of CTWL and inspire further research on designing more efficient, practical, and robust watermarking methods for LLMs.
\end{abstract}


\section{Introduction}

%\footnote{*Equal contribution. Work done while Lean Wang and Wenkai Yang were in Tencent internship.}
Recently, with the explosive development of Large Language Models~(\textbf{LLMs})~\citep{chatgpt,llama}, there has been growing concern in the community about the potential negative effects of the AI-generated content (\textbf{AIGC}). For instance, large models could be exploited to produce fake news, encyclopedia entries, or academic papers for cheating. 
Hence, there is an urgent need to reliably distinguish between human-written and AI-generated texts. 

Text watermarking~\citep{review_of_digital_watermarking,watermarking_statistical_mt} aims to inject hidden patterns into the generated text, so as to detect the specific patterns to determine the source of text.
Table~\ref{tab:watermark_classification} presents a taxonomy of LLM watermarking methods. Based on the timing of watermark injection, watermarking methods can be divided into two categories: 
(1) Integrating into the model generation process~\citep{watermark_llm}, or 
(2) Post-processing after text generation~\citep{acl_muilit_bit}. We argue that post-processing methods are not as effective as integrating methods in maintaining a high quality of the generated texts, since they do not take advantage of the generative power of LLMs. 
In this work, we follow the most representative and advanced line of integrating methods~\footnote{In this work, the LLM watermarking refers to the integrating method unless otherwise specified.}~\citep{watermark_llm, sweet,provable_robust_watermark}, which injects the watermark by controlling the available part of the vocabulary during LLM's decoding process and can detect whether a text contains a watermark with high accuracy and low false positive rate.

\begin{table}[t]
\centering
\caption{Taxonomy of LLM watermarking technologies, with a representative work of each direction attached. It can be found that existing LLM watermarking methods either do not make full use of the generation ability of LLMs, or lack customized watermarking information. Our work simultaneously addresses both of these issues, filling the gap in this line of academic research.}
\resizebox{.99\columnwidth}{!}
{
\begin{tabular}{c|ll}
\toprule

\multirow{2}{*}{\begin{tabular}[c]{@{}c@{}} 
\textbf{Watermark}\\ \textbf{Information}\end{tabular}} 
& \multicolumn{2}{c} {\textbf{Watermark Injection Timing}}         
\\  \cmidrule{2-3}    
& \multicolumn{1}{c}{Post-process after LLM Generation}
& \multicolumn{1}{c}{Integrate with LLM Generation}      
 \\ \midrule 
 One-Bit             
& Black-Box Watermarking~\citep{black_box_watermark}
& LLM Watermarking~\citep{watermark_llm}      
\vspace{0.06in} \\ 
Multi-Bits  
& Natual Language Watermarking~\citep{acl_muilit_bit} 
& Codable Text Watermarking for LLMs~(This Work)
\\ \bottomrule

\end{tabular}}   
\label{tab:watermark_classification}
\end{table}

However, we argue that existing integrating LLM watermarking methods~\citep{watermark_llm, sweet, reliability_of_watermark} encode too limited information (only 1 bit of information - whether the text is generated by one specific model or not), and can not satisfy the increasing demand for customizing information in the application of LLMs. For example, embedding model and version information in the watermark can effectively trace the source of a text among multiple LLMs; and embedding user id in the watermark can help prevent unauthorized use of the model for malicious purposes. The demand for customized watermarks will become more and more diverse and important with the rapid development of LLM technologies and applications.
% With the rapid development of LLMs, the demand for customized information will become more and more important.

\textbf{Present Work.} We conducted the first systematic study on the topic of Codable Text Watermarking for LLMs (\textbf{CTWL}), which allows the watermark injected into LLM-generated text to carry more customizable information. 
% making it more adaptable to prevent the abuse of LLMs as well as protect the intellectual property of the model owners. 
First and foremost, given the fact that the boundary and definition of CTWL remain unclear, we start with the 
watermarking taxonomy analysis~(Section~\ref{sec: related_work}) and then give a 
mathematical formalization of the CTWL problem~(Section~\ref{sec: format}). 
Then, we propose a comprehensive evaluation system for CTWL~(Section~\ref{sec: evaluation}), which consists of the following 5 criteria: (1)~\textbf{Success Rate}: the LLM watermarking method should have high success rates of both detecting model-generated texts and recovering message from watermarked texts. (2)~\textbf{Robustness}: the watermarking method should avoid a significant drop in success rate when facing different challenging attacks (such as copy-paste attack, substitution attack, paraphrasing attack, etc.). (3)~\textbf{Coding Rate}: the ratio of text token number to information bit number should be as high as possible. (4)~\textbf{Computational Complexity}: the computation cost of watermark writing and decoding should meet the practical hardware and latency requirements. (5)~\textbf{Text Quality}: the impact of adding complex watermark patterns on the quality of generated texts should be minimal. 
% Thus, we argue that a practically usable CTWL method needs to satisfy these five dimensions simultaneously.

Therefore, devising a practically applicable CTWL method is a challenging task, since it is difficult to make Pareto improvements in these conflicting metrics. For example, when the coding rate increases, the robustness and text quality will inevitably decrease; and when the encoding and decoding methods are sufficiently complex to ensure the success rate and robustness, the computation cost will become prohibitive. 
In this work, we first adopt the random vocabulary splitting idea from~\citet{watermark_llm}, and propose a vanilla codable watermarking (\textbf{Vanilla-Marking}) method to encode information with the help of tokens lied in the available part of the vocabulary. However, this naive baseline may perform poorly in maintaining a high quality of the generated text. Thus, inspired by the idea that a probability-balanced vocabulary partition can more effectively ensure the quality of watermarked text, we devise a CTWL method named~\textbf{Balance-Marking}, which can simultaneously satisfy the various evaluation dimensions mentioned above. 
Balance-Marking has the following innovation: we leverage a proxy language model (proxy-LM) for dividing the available/unavailable token lists; the proxy-LM can either be the LLM itself when the model company only wants itself to decode the watermark information, or be a smaller and public language model (e.g, GPT-2~\citep{gpt2}) with comparable performance to original LLM but has a higher inference efficiency.\footnote{Also, a public proxy-LM allows for anyone to perform information decoding without access to the original LLM. Please refer to Section~\ref{sec: scenes}.} In this way, the probabilities of available and unavailable vocabularies are as close as possible. This avoids the excessive impact on text quality caused by random vocabulary splitting used in \citet{watermark_llm}, while not introducing too much additional computation cost. Also, this may implicitly help the watermark algorithm to skip low-entropy segments of text, as detailed in Section~\ref{sec: intuitive analysis}, which further ensures the robustness and text quality of our method.%(2) Second, for extreme low-entropy segments of the text, Balance-Marking tends adopt a global soft entropy-adaptive watermarking mechanism to make the watermark bypass low-entropy text segments automatically, which further ensures the robustness and text quality of our method.

Extensive experimental results demonstrate that the proposed Balance-Marking method surpasses the baseline without proxy-LM and effectively balances the five aforementioned evaluation dimensions. 
Additional experiments are performed to assess the influence of crucial modules within our approach. Furthermore, we examine the application scenarios of CTWL, the limitations of our method, and potential avenues for future research.
We hope that this work will draw great attention from the community to the topic of codable text watermarking, and inspire more innovative works on the development of datasets, evaluation, and implementation for CTWL.
% % Figure environment removed


% \begin{table}[t]
%     \centering
%     \begin{tabular}{|c|cc|}
% \hline
% \multirow{2}{*}{\begin{tabular}[c]{@{}c@{}}Watermark\\ Information\end{tabular}} & \multicolumn{2}{c|}{Watermark Injection Timing}         \\ \cline{2-3} 
%                                                                                  & During LLM Generation    & After LLM Generation         \\ \hline
% One-Bit                                                                          & LLM Watermarking         & Black-Box Watermarking       \\
% Multi-Bits                                                                       & Codable LLM Watermarking & Natual Language Watermarking \\ \hline
% \end{tabular}
    
%     \caption{Taxonomy of LLM watermarking technologies.}
%     \label{tab:watermark_classification}
% \end{table}




% Figure environment removed

% In summary, the core contributions of our work are as follows:
% \begin{itemize}
%     \item We give a rigorous mathematical formalization of the codable watermarking problem for the first time.
%     \item We design a comprehensive evaluation system for codable watermarking, which evaluates the practical usability of methods from five different dimensions. 
%     \item We propose a codable watermarking method based on homomorphic pre-decoding, which is verified by extensive experiments to satisfy the various criteria of the evaluation system.
% \end{itemize}




\section{Related Work}
\label{sec: related_work}
The current studies on identifying LLM-generated texts can be mainly divided into two categories:

\paragraph{Detecting-based Methods.} This kind of methods aims to detect whether a text is generated by a language model by formulating the task as a binary classification problem~\citep{real_or_fake,automatic_detection,gpt-2-release}. (1) One way to achieve this goal is to first collect outputs from a specific LLM along with human-written texts, and then use them to train a binary classifier. For example,~\citet{gpt-2-release} fine-tune a RoBERTa classification model to detect whether a text is generated by GPT-2 model or not. Later,~\cite{chatgpt_or_human} collect data produced by ChatGPT~\cite{chatgpt} and fine-tune a DistilBERT model~\citep{distilbert} to distinguish texts written by humans and that generated by ChatGPT.~\citet{openai_classifier} further create a more advanced classifier that can detect texts generated by a variety of diverse LLMs. (2) Besides explicitly training deep classifiers, some other methods achieve detection by exploring the statistical differences between LLM-generated texts and human-written texts~\citep{release_strategies,llmdet}. GPTZero~\citep{gptzero} is a popular tool to identify machine-generated texts by calculating the perplexity and burstiness\footnote{Burstiness score measures whether the sentences in the text consistently have low perplexity scores.} scores of texts and comparing them with specific thresholds, based on the analysis that LLMs always generated tokens with high predicted probabilities. DetectGPT~\citep{detectgpt} claims that when a machine-generated text is perturbed, its log probability will always show a decreasing pattern, which is not the same for human-written texts. Based on this finding, it defines a log probability-based metric to help detect texts generated by LLMs. 
Recently, there have been some works~\citep{new-detection-1, new-detection-2} exploring the detection of machine-generated text in specific domains.
However, all these detection methods face the risk of becoming increasingly ineffective in the future, as the LLMs will be consistently improved to behave more and more like humans, which finally makes detection impractical~\citep{reliably_detect}.
% Watermarking can be applied to any model without additional parameter training and has proven more effective than the classification-based ~\citep{gpt-2-release,distilbert,openai_classifier} or statistical-based~\citep{gptzero,detectgpt} detection methods~\citep{reliably_detect}.


\paragraph{Watermarking-based Methods.}
Text watermarking technology marks text by injecting human-invisible hidden patterns into the text, and uses specific detection methods to determine whether the text contains a watermark~\citep{review_of_digital_watermarking,watermarking_statistical_mt,adversarial_watermarking,tracing_text_provenance}. 
We analyze the taxonomy of LLM watermarking methods in Table~\ref{tab:watermark_classification}. Watermarking techniques can be categorized into two types according to the point of watermark insertion: : (1) Integrated into the model generation process~\citep{watermark_llm}, and (2) Post-processing after text generation~\citep{acl_muilit_bit, black_box_watermark}. 
Post-processing methods are independent of LLMs and they usually utilize masked language models (MLMs) (e.g. BERT~\citep{bert}, RoBERTa~\citep{roberta}) to replace tokens with synonyms. 
~\cite{black_box_watermark} proposes injecting a watermark containing 1-bit information into the text generated by LLMs by performing synonym replacement.
~\cite{acl_muilit_bit} proposes a token substitution-based text watermarking method that achieves to encode multi-bits information into text from any source.
We argue that post-processing methods are not as effective as integrating methods, since they do not take advantage of the generative power of LLMs. Additionally, replacement-based methods can only operate individual tokens and cannot adaptively change the subsequent generation sequence like integrating methods, which severely limits the freedom and consistency of the watermarked texts.

The most representative integrating watermarking technique for LLMs is proposed by~\citet{watermark_llm}, which watermarks the LLM-generated text by manipulating the available token part of the vocabulary when sampling each token. Specifically, when LLM generates the current token, it first creates a random seed based on the hash value of the previous token and splits the whole vocabulary into two parts (i.e., green list and red list) conditioned on that random seed. Then, the logits of tokens in the green list will be added with a small positive value, which leads to the result that the tokens in the green list will be more likely to be sampled. In the watermark detecting stage, the same hash function is utilized to determine the number of tokens in the red list and green list in a text, thereby determining whether the text contains watermark information. Following~\citet{watermark_llm}, several studies explore effective text watermarking in various scenarios.
~\citet{reliability_of_watermark} later improve this method by exploring diverse choices of random seed generators for splitting the vocabulary. 
~\citet{sweet} takes a step further to actively select high entropy tokens to watermark instead of all tokens, which is shown to be more effective in the code detection task, as it will not affect the generation of those deterministic code segments.
~\citet{provable_robust_watermark} simplify the watermark method of~\citet{watermark_llm} by making the vocabulary splitting independent of the previously generated tokens and only dependent on a global key. 
However, all these methods generate watermarks that only contain 1 bit of information, which cannot meet the need for injecting watermarks with diverse customized information. In this work, we first analyze the research objectives of codable text watermarking, and then propose a practical method that achieves a good balance among multiple indicators designed for evaluating the effectiveness of CTWL.
% In this work, we make novel explorations towards the codable text watermarking techniques based on the setting in~\citet{watermark_llm}.

%Recently, a contemporaneous work~\citep{acl_muilit_bit} proposed to utilize a corruption-resistant infill model to inject watermarks with multi-bits information into texts from any sources. We argue that such a black-box watermarking manner is independent of LLMs and will decline the generation ability of LLMs, while our work focuses on the integration of text generation technology and codable watermarking technology, so as to preserve the generation ability of LLMs to the greatest extent.
% Recently, a contemporaneous work~\citep{acl_muilit_bit} proposes a token substitution-based text watermarking method that achieves to encode multi-bits information into text from any sources. However, it mainly focus on improving the robustness of the watermark against adversarial corruptions on the text, while our work takes the first step to provide a systematic formulation and comprehensive evaluation of codable text watermarking. Furthermore, we propose a different codable text watermarking method that achieves satisfactory performance in multiple aspects including the robustness against text modifications. 
% This work lacks a systematic study on the concept of codable watermarking, which can be regarded as another independent implementation method of codable watermarking method.

% \subsubsection*{Author Contributions}

% \subsubsection*{Acknowledgments}



\section{Mathematical Formulation of Codable LLM Watermarking}
\label{sec: format}
\subsection{Notations and Preliminaries}

Here, we first introduce the necessary notations used in this paper. Assume there is a large language model (denoted as $LLM$) that takes a prompt sequence as the input and sequentially outputs the corresponding tokens to form natural sentences as the response. Specifically, we denote $\mathbf{x}^{prompt}$ as the prefix prompt. At $l$-th step ($l=1,2,\cdots,L$), the entire input for $LLM$ is the combination of the original prompt $\mathbf{x}^{prompt}$ and the sequence of tokens $\mathbf{t}_{:(l-1)}=\{ t_{0},\cdots,t_{l-1}\}$ that are already predicted by $LLM$ in previous steps.\footnote{In the first step, there is no previously generated token, thus define $t_{0}$ is none.} Then, $LLM$ produces a probability distribution over the entire vocabulary $\mathcal{V}$ as $\mathbf{P}_{LLM}(\mathbf{x}^{prompt},\mathbf{t}_{:(l-1)})=(\cdots,P_{LLM}(v | \mathbf{x}^{prompt},\mathbf{t}_{:(l-1)}),\cdots )$, in which $P_{LLM}(v | \mathbf{x}^{prompt},\mathbf{t}_{:(l-1)})$ is the predicted probability of a specific token $v$ by $LLM$. The next token $t_{l}$ is sampled based on $\mathbf{P}_{LLM}(\mathbf{x}^{prompt},\mathbf{t}_{:(l-1)})$ according to specific sampling rules, such as multinomial sampling or greedy sampling.


As we mentioned before, we aim to introduce a codable text watermarking scheme that allows the watermark to carry meaningful information/messages. Thus, we define $m$ as the message that we want the watermark to carry in the $LLM$'s response. 
%Besides the original $LLM$ for generating the responses, in our proposed method, we will utilize a public language model (e.g., GPT-2~\citep{gpt2}) to help encoding $m$ during $LLM$'s generation and decoding $m$ when the text receiver attempts to recover the watermark message. We denote this public LM as $LM_{proxy}$.
Also, in our proposed method, we further define a proxy language model (proxy-LM) to help encode $m$ during $LLM$'s generation and decode $m$ when the text receiver attempts to recover the watermark message. This proxy-LM can either be the $LLM$ itself or be a smaller public language model (e.g., GPT-2~\citep{gpt2}), depending on different realistic situations.\footnote{Refer to the discussions in Section~\ref{sec: scenes}.} We denote this proxy-LM as $LM_{proxy}$.


\subsection{Formulation of Codable Text Watermarking}

\label{sec:formulation_of_codable_text_watermarking}

Current text watermarking schemes include a \textit{watermark embedding} procedure and a \textit{watermark detecting} procedure:
\begin{equation}
\label{eq: vanilla watermark}
\begin{aligned}
 \textit{Embedding: } \qquad &  \mathcal{P}  \rightarrow \mathcal{T}, \quad Emb(\mathbf{x}^{prompt}) = \mathbf{t}, \\
 \textit{Detecting: } \qquad & \mathcal{T} \rightarrow \{ 0,1\}, \quad Det(\mathbf{t}) = 0 \text{ or }  1.
\end{aligned}
\end{equation}
$\mathcal{P}$ and $\mathcal{T}$ represent the prompt space and text space respectively. In the watermark embedding phase, 
%the goal is to make language model $LLM$ output a response $\mathbf{t}$ given a prompt input $\mathbf{x}^{prompt}$ following a specific rule $w$. 
the goal is to produce a response $\mathbf{t}$ given a prompt input $\mathbf{x}^{prompt}$ under a specific embedding function $Emb(\cdot)$, which may includes a language model $LLM$ and a designed watermarking rule $w$. 
Then, when the text receiver obtains a text and wants to detect whether this text is watermarked, it needs to utilize the detecting function $Det(\cdot)$ to extract the potential watermark from $\mathbf{t}$, then output $1$ if the text contains the watermark signal and $0$ otherwise.

However, these methods have a limitation that they can only encode one bit of information in the watermark, which is encoding-inefficient. That is, \textbf{their injected watermark can only be used to justify whether a text is generated by one specific LLM or not.} However, as more and more types and versions of LLMs emerges rapidly, a more practical watermarking method should allow the encoding of rich information in the watermarks in order to satisfy the multiple demands on the realistic application of LLMs. For example, a machine-generated text with watermarks that carry the information of the name of the source LLM can be easily traced from the source once it is used for harmful purposes, such as spreading fake news or cheating on academic writings.

Therefore, we propose the concept of \textbf{codable text watermarking for LLMs} (\textbf{CTWL}) that can encode rich and necessary information into the text watermarks. Formally, CTWL can be formulated as a \textit{message encoding} stage with a \textit{message decoding/extracting} stage:
\begin{equation}
\label{eq: codable watermark}
\begin{aligned}
 \textit{Encoding: } \qquad &  \mathcal{P}  \times \mathcal{M}  \rightarrow \mathcal{T}, \quad Enc(\mathbf{x}^{prompt},m) = \mathbf{t}, \\
 \textit{Decoding: } \qquad & \mathcal{T} \rightarrow \mathcal{M}, \quad Dec(\mathbf{t}) = m,
\end{aligned}
\end{equation}
where $\mathcal{M}$ represents the message/information space, $m \in \mathcal{M}$ is the message that needs to be encoded. As we can see, previous watermarking methods in Eq.~(\ref{eq: vanilla watermark}) can be considered as a simplified case of CTWL, where the message space only contains one bit of information (i.e., \{0, 1\}).

Following the definition in Eq.~(\ref{eq: codable watermark}), the target on precisely extracting messages from $\mathbf{t}$ can be written as 
\begin{equation}
\label{eq: target on extracting messages}
\begin{aligned}
 m = \mathop{\arg\max}_{m' \in \mathcal{M}}  P_{w}(m'|\mathbf{t})  ,
\end{aligned}
\end{equation}
where we need to design a specific probability function $P_{w}$ referred to as \textbf{message function}\footnote{We will discuss how to effectively design message function $P_{w}$ in Section~\ref{sec: design of P}.} in the decoding phase to measure how likely is that the watermarked message is $m'$ given $\mathbf{t}$.

Therefore, according to Bayes Formula, in the message encoding phase, it is equivalent to achieve
\begin{equation}
\label{eq: target on encoding messages}
\begin{aligned}
 & \mathop{\max}\limits_{\mathbf{t}}  \{ P_{w}(\mathbf{t}|m) / 
 \mathop{\max}_{m' \neq m} P_{w}(\mathbf{t}|m')  \} \\ &\iff
 \mathop{\max}\limits_{\mathbf{t}} \{ \mathop{\Pi}\limits_{l=1}^{L} P_{w}(t_{l}|,m,\mathbf{t}_{:(l-1)}) / \mathop{\max}_{m' \neq m} \mathop{\Pi}\limits_{l=1}^{L} P_{w}(t_{l}|m',\mathbf{t}_{:(l-1)})  \} 
 \\ &\iff
 \mathop{\max}\limits_{\mathbf{t}} \{ \mathop{\sum}\limits_{l=1}^{L} \mathop{\log}P_{w}(t_{l}|m,\mathbf{t}_{:(l-1)}) - \mathop{\max}_{m' \neq m} \mathop{\sum}\limits_{l=1}^{L} \mathop{\log}P_{w}(t_{l}|m',\mathbf{t}_{:(l-1)})  \} .
\end{aligned}
\end{equation}
%where $S_{enc}$ is the corresponding score function in the encoding phase to reflect the probability of the appearance of the text $\mathbf{t}$ given the message $m$.
That is, we aim to enlarge the gap between the probability that the text $\mathbf{t}$ is generated under message $m$ and the probability that it is generated under other $m'$.\footnote{The reason why we take the form of division in Eq.~(\ref{eq: target on encoding messages}) is for successfully deriving to the optimization target to Eq.~(\ref{eq: encoding optimization problem}).} 
% Moreover, taking the quality of generated text as consideration, the encoding phase can be formulated as
% \begin{equation}
% \label{eq: encoding message and text quality}
% \begin{aligned}
% & \mathop{\max} \{ \mathop{\sum}\limits_{l=1}^{L} \mathop{\log}P(t_{l}|m,t_{:(l-1)}) - \mathop{\max}_{m' \neq m} \mathop{\sum}\limits_{l=1}^{L} \mathop{\log}P(t_{l}|m',t_{:(l-1)})  \} , 
%  \\
% & \text{s.t. \quad } \text{PPL}(t|\mathbf{x}^{prompt},m) \leq \text{PPL}(t| \mathbf{x}^{prompt}) +\epsilon ,
% \end{aligned}
% \end{equation}
% where we use perplexity (PPL) metric to measure the quality of the generated text, and aim to make the watermarked text have comparable quality with that of the text generated without embedded watermarks.
%Moreover, considering that the quality of the generated text with watermarks should not degrade greatly, we take the text generated without embedded watermarks $\mathbf{t}^{original}$ as a baseline for comparison. In this circumstance, we can express the encoding phase as:
However, as we can see, the above equation only considers the target of effectively hiding message $m$ into $\mathbf{t}$, but does not take the quality of the generated text into consideration. Thus, we take the original text generated without embedded watermarks $\mathbf{t}^{ori}$ as a baseline for comparison, and reformulate the encoding phase as:
\begin{equation}
\label{eq: encoding message and text quality original}
\begin{aligned}
& \mathop{\max}\limits_{\mathbf{t}} \{ \mathop{\sum}\limits_{l=1}^{L} \mathop{\log}P_{w}(t_{l}|m,\mathbf{t}_{:(l-1)}) - \mathop{\max}_{m' \neq m} \mathop{\sum}\limits_{l=1}^{L} \mathop{\log}P_{w}(t_{l}|m',\mathbf{t}_{:(l-1)})  \} , 
 \\
& \text{s.t. \quad } \text{PPL}(\mathbf{t}|\mathbf{x}^{prompt}) \leq \text{PPL}(\mathbf{t}^{ori}| \mathbf{x}^{prompt}) +\epsilon .
\end{aligned}
\end{equation}
Here, we utilize the perplexity (PPL) metric to estimate the quality of the generated text, with the aim of ensuring the watermarked text maintains a similar quality to the text generated without embedded watermarks. Furthermore, using the computational formula of PPL that $\text{PPL}(\mathbf{t}|\mathbf{x}^{prompt})=[\mathop{\Pi}\nolimits_{l=1}^{L}P(t_{l}|\mathbf{x}^{prompt},\mathbf{t}_{:(l-1)})]^{-\frac{1}{L}} $, Eq.~(\ref{eq: encoding message and text quality original}) is equivalent to 
\begin{equation}
\label{eq: encoding message and text quality}
\begin{aligned}
& \mathop{\max}\limits_{\mathbf{t}} \{ \mathop{\sum}\limits_{l=1}^{L} \mathop{\log}P_{w}(t_{l}|m,\mathbf{t}_{:(l-1)}) - \mathop{\max}_{m' \neq m} \mathop{\sum}\limits_{l=1}^{L} \mathop{\log}P_{w}(t_{l}|m',\mathbf{t}_{:(l-1)})  \} , 
 \\
& \text{s.t. \quad } -\frac{1}{L}[\mathop{\sum}\limits_{l=1}^{L} \log P(t_{l}|\mathbf{x}^{prompt},\mathbf{t}_{:(l-1)})] \leq %-\frac{1}{L^{ori}}[\mathop{\Pi}\limits_{l=1}^{L^{ori}}P(t_{l}^{ori}|\mathbf{x}^{prompt},\mathbf{t}_{:(l-1)}^{ori})] +\epsilon .
\log (\text{PPL}(\mathbf{t}^{ori}| \mathbf{x}^{prompt})  +\epsilon )
\end{aligned}
\end{equation}




\section{Balance-Marking: A Simple yet Effective CTWL Method}
\label{sec: method}

% As stated in Section~\ref{sec:formulation_of_codable_text_watermarking}, a watermarking algorithm mainly consists of three parts, encoding algorithm~(the optimization of Eq.~\ref{eq: encoding message and text quality}), decoding algorithm~(the optimization of Eq.~\ref{eq: target on extracting messages}), and the design of $P_{w}$, i.e. the mapping between text and message. Once $P_{w}$ is determined, the decoding can be directly performed. In the following parts, we will first propose a approximation algorithm to solve Eq.~\ref{eq: encoding message and text quality} in Section~\ref{sec: encoding framwwork}, leaving the design of $P_{w}$ to be the only part that should be cared in the design of watermarking algorithm, and propose intuitive designs of $P_{w}$ in Section~\ref{sec: design of P}.

% As outlined in Section Section~\ref{sec:formulation_of_codable_text_watermarking}, a watermarking algorithm principally includes three components: the encoding algorithm (optimizing Eq.~\ref{eq: encoding message and text quality}), the decoding algorithm (optimizing Eq.~\ref{eq: target on extracting messages}), and the design of $P_{w}$, i.e. the relationship between text and message. With a settled $P_{w}$, decoding becomes directly executable. Subsequent sections will first introduce an approximation algorithm to resolve Eq.~\ref{eq: encoding message and text quality} in Section~\ref{sec: encoding framwwork}, i.e. proposing a general encoding algorithm for a settled $P_{w}$. This leaves $P_{w}$'s definition as the lone element requiring attention in the structuring of the watermarking algorithm. We discuss designs for $P_{w}$ in Section Section~\ref{sec: design of P}.

% polished
% As delineated in Section~\ref{sec:formulation_of_codable_text_watermarking}, a codable watermarking algorithm hinges upon three fundamental components: the message encoding algorithm (which solves Eq.~(\ref{eq: encoding message and text quality})), the message extracting algorithm (which solves Eq.~(\ref{eq: target on extracting messages})), and the construction of probability function $P_{w}$ (which defines the connection between texts and messages). Notably, once the particular $P_{w}$ is determined, decoding can be performed straightforwardly by solving Eq.~(\ref{eq: target on extracting messages}). 

In this section, we introduce a simple yet effective implementation of CTWL as our preliminary exploration. As delineated in Section~\ref{sec:formulation_of_codable_text_watermarking}, a CTWL consists of two fundamental parts: one is a message encoding algorithm to solve Eq.~(\ref{eq: encoding message and text quality}), the other is a message extracting algorithm to achieve Eq.~(\ref{eq: target on extracting messages}). Furthermore, in both two phases, we rely on a well-defined probability function $P_{w}$ as a unified guideline to encode and decode messages.

Therefore, in the subsequent sections, we first present an approximation algorithm derived to solve Eq.~(\ref{eq: encoding message and text quality}) in Section~\ref{sec: encoding framwwork}. This will serve as a general encoding algorithm for any predefined $P_{w}$. Following this, we introduce two designs of $P_{w}$ in Section~\ref{sec: design of P}. Finally, given the pre-defined encoding algorithm and $P_{w}$, we can successfully perform message extracting as presented in Section~\ref{subsec: message extracting phase}.

\subsection{A general framework for codable watermark encoding}
\label{sec: encoding framwwork}





% As stated in Section~\ref{sec:formulation_of_codable_text_watermarking}, the task of generating watermarked text without largely hurting the text quality can be formulated as Eq.~\ref{eq: encoding message and text quality}. Suppose PPL is calculated by the $LLM$ used to generate the text, then $x_{original}$, the text generated without embedded watermarks, can be expressed as $\mathop{\mathrm{argmin}}\limits_{x} \text{PPL}(x|\mathbf{x}^{prompt})$. So Eq.~\ref{eq: encoding message and text quality} can be rewritten as:

As mentioned in Section~\ref{sec:formulation_of_codable_text_watermarking}, the target on generating watermarked text while minimally impacting text quality can be presented in the format of Eq.~(\ref{eq: encoding message and text quality}). 
%For simplicity but without loss of generality, let's assume that the perplexity (PPL) scores in Eq.~(\ref{eq: encoding message and text quality}) are calculated based on the same $LLM$ used to generate $t$.\footnote{This assumption is practical because the LLM is powerful enough to accurately measure the real perplexity of a text.} 
% Furthermore, $\mathbf{t}^{original}$, which represents text generated without embedded watermarks, can then be regarded as $\mathbf{t}^{original}=\mathop{\arg\min}\limits_{\mathbf{t}^{'}} \text{PPL}(\mathbf{t}^{'}|\mathbf{x}^{prompt})$. 
%Let's assume that the perplexity (PPL) is calculated by the same $LLM$ used to generate the text. Subsequently, $t_{original}$, which represents text generated without embedded watermarks, can be delineated as $\mathop{\mathrm{argmin}}\limits_{x} \text{PPL}(x|\mathbf{x}^{prompt})$. 
% Therefore, Eq.~(\ref{eq: encoding message and text quality}) can be refactored as:
% \begin{equation}
% \label{eq: encoding message and text quality method}
% \begin{aligned}
% & \mathop{\max}_{\mathbf{t}} \ \{\mathop{\sum}\limits_{l=1}^{L} \mathop{\log}P(t_{l}|m,\mathbf{t}_{:(l-1)}) - \mathop{\max}_{m' \neq m} \mathop{\sum}\limits_{l=1}^{L} \mathop{\log}P(t_{l}|m',\mathbf{t}_{:(l-1)})\}, 
%  \\
% & \text{s.t. \quad } \text{PPL}(\mathbf{t}|\mathbf{x}^{prompt}) \leq \min\limits_{\mathbf{t}^{'}}\text{PPL}(\mathbf{t}^{'}| \mathbf{x}^{prompt}) +\epsilon .
% \end{aligned}
% \end{equation}
%The optimization problem can be further redefined by employing a Lagrange multiplier, $\lambda$, and interpreting it as a hyper-parameter:
In order to solve the constrained optimization problem above, we are motivated to apply the method of Lagrange Multipliers by introducing a dual variable $\lambda$ and re-defining the target as:
\begin{equation}
\label{eq: encoding message and text quality method 2}
\begin{aligned}
\mathop{\max}_{\mathbf{t}} \{& \mathop{\sum}\limits_{l=1}^{L} \mathop{\log}P_{w}(t_{l}|m,\mathbf{t}_{:(l-1)}) -\mathop{\max}_{m' \neq m} \mathop{\sum}\limits_{l=1}^{L} \mathop{\log}P_{w}(t_{l}|m',\mathbf{t}_{:(l-1)})\\ & -\lambda[
% \text{PPL}(\mathbf{t}|\mathbf{x}^{prompt}) - \min\limits_{\mathbf{t}^{'}} \text{PPL}(\mathbf{t}^{'}| \mathbf{x}^{prompt}) -\epsilon
-\frac{1}{L}[\mathop{\sum}\limits_{l=1}^{L} \log P(t_{l}|\mathbf{x}^{prompt},\mathbf{t}_{:(l-1)})] -
\log (\text{PPL}(\mathbf{t}^{ori}| \mathbf{x}^{prompt})  +\epsilon )
] \}.
% & \text{s.t. \quad } \text{PPL}(t|\mathbf{x}^{prompt},m) \leq \min\limits_x\text{PPL}(x| \mathbf{x}^{prompt}) +\epsilon ,
\end{aligned}
\end{equation}

% Note that $\min\limits_x \text{PPL}(x| \mathbf{x}^{prompt}) + \epsilon $ is a constant given $\mathbf{x}^{prompt}$, and combining the calculation formula of PPL, we get
For simplicity but without loss of generality, let's assume that the perplexity (PPL) scores in Eq.~(\ref{eq: encoding message and text quality}) are calculated based on the same $LLM$ used to generate $t$.\footnote{This assumption is practical because the LLM is powerful enough to accurately measure the real perplexity of a text.} In this case, given the prompt $\mathbf{x}^{prompt}$ and $LLM$, the term $ \text{PPL}_{LLM}(\mathbf{t}^{ori}| \mathbf{x}^{prompt})$ can be regarded as a constant. Therefore, Eq.~(\ref{eq: encoding message and text quality method 2}) can be rephrased as:
%Given the prompt $\mathbf{x}^{prompt}$, the term $\min\limits_{\mathbf{t}^{'}} \text{PPL}(\mathbf{t}^{'}| \mathbf{x}^{prompt}) + \epsilon$ is a constant. Therefore, by utilizing the computational formula of PPL, Eq.~(\ref{eq: encoding message and text quality method 2}) can be rephrased as:
\begin{equation}
\begin{aligned}
\mathop{\max}_{\mathbf{t}} \{& \mathop{\sum}\limits_{l=1}^{L} \mathop{\log}P_{w}(t_{l}|m,\mathbf{t}_{:(l-1)}) -\mathop{\max}_{m' \neq m} \mathop{\sum}\limits_{l=1}^{L} \mathop{\log}P_{w}(t_{l}|m',\mathbf{t}_{:(l-1)})\\
&+\frac{\lambda}{L} \mathop{\sum}\limits_{l=1}^{L} \mathop{\log}P_{LLM}(t_{l}|\mathbf{x}^{prompt},\mathbf{t}_{:(l-1)}) \}.
% & \text{s.t. \quad } \text{PPL}(t|\mathbf{x}^{prompt},m) \leq \min\limits_x\text{PPL}(x| \mathbf{x}^{prompt}) +\epsilon ,
\end{aligned}
\end{equation}
% Let $\delta$ be $\frac{L}{\lambda}$ and $\hat m$ be $\mathop{\mathrm{argmax}}_{m' \neq m} \mathop{\sum}\limits_{l=1}^{L} \mathop{\log}P(t_{l}|m',t_{:(l-1)})$, we can reorganize the objective function as 
Let $\delta$ represent $\frac{L}{\lambda}$ and $\hat m=\mathop{\mathrm{argmax}}\limits_{m' \neq m} \mathop{\sum}\limits_{l=1}^{L} \mathop{\log}P(t_{l}|m',\mathbf{t}_{:(l-1)})$, the objective function can be restructured as:
\begin{equation}
\label{eq: encoding optimization problem}
\begin{aligned}
\mathop{\max}_{\mathbf{t}} & \mathop{\sum}\limits_{l=1}^{L}\{ \ \mathop{\log}P_{LLM}(t_{l}|\mathbf{x}^{prompt},\mathbf{t}_{:(l-1)})\\ 
&+\delta(\mathop{\log}P_{w}(t_{l}|m,\mathbf{t}_{:(l-1)}) - \mathop{\log}P_{w}(t_{l}|\hat{m},\mathbf{t}_{:(l-1)})\}.
% & \text{s.t. \quad } \text{PPL}(t|\mathbf{x}^{prompt},m) \leq \min\limits_x\text{PPL}(x| \mathbf{x}^{prompt}) +\epsilon ,
\end{aligned}
\end{equation}

% Inspired by the fact that the text decoding algorithms like beam search can use $\mathop{\log} P_{LLM}(x_{l}|\mathbf{x}^{prompt},x_{:(l-1)})$ to get a approximation solution of 
Note that if without the watermarking requirement, existing text generation algorithms such as greedy search exactly aim to approximate the solution of $\mathop{\max}_{\mathbf{t}}\mathop{\sum}\nolimits_{l=1}^{L}\mathop{\log}P_{LLM}(t_{l}|\mathbf{x}^{prompt},\mathbf{t}_{:(l-1)}) $ by sampling the token based on the model logits $P_{LLM}(t_{l}|\mathbf{x}^{prompt},\mathbf{t}_{:(l-1)})$ during each step.
%if we substitute the term $\mathop{\log}P_{LLM}(x_{l}|\mathbf{x}^{prompt},x_{:(l-1)}) \}$ with $\mathop{\log}P_{LLM}(t_{l}|\mathbf{x}^{prompt},t_{:(l-1)}) + \delta(\mathop{\log}P(t_{l}|m,t_{:(l-1)}) - \mathop{\log}P(t_{l}|\hat{m},t_{:(l-1)})$, we can leverage the original text generation algorithm to tackle Eq.~\ref{eq: encoding message and text quality method}, thus accomplishing the encoding process. Furthermore, as solving $\hat m$ is challenging, for approximation, we loosen $\mathop{\log}P(t_{l}|\hat{m},t_{:(l-1)})$ to an approximation using $\frac{1}{|\mathcal{M}|}\mathop{\sum}\limits_{m'\in \mathcal{M}}\mathop{\log}P(t_{l}|m',t_{:(l-1)})$.
Therefore, Eq.~(\ref{eq: encoding optimization problem}) motivates us that in order to encode $m$ into $\mathbf{t}$, we can manipulate the output logits during each token's generation by adding a term $\delta(\mathop{\log}P_{w}(t_{l}|m,\mathbf{t}_{:(l-1)}) - \mathop{\log}P_{w}(t_{l}|\hat{m},\mathbf{t}_{:(l-1)})$ to the original log logits. \textbf{However, in practice, solving $\hat m$ is infeasible because the true $\hat{m}$ can only be solved after the whole output $t$ is determined, while we need to calculate $\delta(\mathop{\log}P_{w}(t_{l}|m,\mathbf{t}_{:(l-1)}) - \mathop{\log}P_{w}(t_{l}|\hat{m},\mathbf{t}_{:(l-1)})$ in each generation step according to Eq.~(\ref{eq: encoding optimization problem}).} Therefore, we replace $\mathop{\log}P_{w}(t_{l}|\hat{m},\mathbf{t}_{:(l-1)})$ with calculable $\frac{1}{|\mathcal{M}|}\mathop{\sum}\nolimits_{m'\in \mathcal{M}}\mathop{\log}P_{w}(t_{l}|m',\mathbf{t}_{:(l-1)})$ as an alternative, and finally get the message encoding object function in each generation step as:
\begin{equation}
\begin{aligned}
    L(m,\mathbf x^{prompt}&, 
    \mathbf{t}_{:(l-1)})= \mathop{\max}\limits_{v}\{\underbrace{\mathop{\log}P_{LLM}(v|\mathbf{x}^{prompt},\mathbf{t}_{:(l-1)})}_{\text{model logit}}\\ &+ \delta(\underbrace{\mathop{\log}P_{w}(v|m,\mathbf{t}_{:(l-1)}) - \frac{1}{|\mathcal{M}|}\mathop{\sum}\limits_{m'\in \mathcal{M}}\mathop{\log}P_{w}(v|m',\mathbf{t}_{:(l-1)}}_{\text{message logit}})\},
    \label{eq: encoding objective function}
\end{aligned}
\end{equation}
where we denote the first term in the right as the \textbf{model logit}, which is determined by the $LLM$ only; we denote the second additional term as the \textbf{message logit}, which is the key component for encoding message $m$ into $t$.

As we can see, as long as the function $P_{w}$ is well-defined, the encoding process can be completed by adding the message logits to the model logits and sampling the token based on the new logits. We put the formal message encoding procedure in Algorithm~\ref{algo: encoding algorithm for general P},\footnote{Though we employ a greedy search as the text generation algorithm in Algorithm~\ref{algo: encoding algorithm for general P} for example, our framework is also compatible with other generation rules such as beam search.} and will discuss how to properly design $P_{w}$ in detail in the following section.

% In summary, the algorithm for encoding can be realized by adjusting the model logits used in text generation procedures such as beam search, i.e. adding to logits an additional term $\delta(\mathop{\log}P(t_{l}|m,t_{:(l-1)}) - \frac{1}{|\mathcal{M}|}\mathop{\sum}\limits_{m'\in \mathcal{M}}\mathop{\log}P(t_{l}|\mathbf{x}^{prompt},m',t_{:(l-1)})$. 
% Algorithm~\ref{algo: encoding algorithm for general P} describes the detailed steps of the encoding algorithm for a settled $P_{w}$. For simplicity, we employ a greedy search as the text generation algorithm in our demonstration.
% In summary, we can implement the encoding algorithm by manipulating the model logits used in text generation algorithms, such as beam search. This manipulation involves the addition of a term, $\delta(\mathop{\log}P(t_{l}|m,t_{:(l-1)}) - \frac{1}{|\mathcal{M}|}\mathop{\sum}\limits_{m'\in \mathcal{M}}\mathop{\log}P(t_{l}|m',t_{:(l-1)})$, to the original logits.
% Algorithm~\ref{algo: encoding algorithm for general P} describes the detailed steps of the encoding algorithm for a settled $P_{w}$. For simplicity, we employ a greedy search as the text generation algorithm in Algorithm~\ref{algo: encoding algorithm for general P}.




\begin{algorithm}[t]
\SetAlgoLined
% \KwResult{Result of the algorithm}
\KwIn{Language model $LLM$, prompt $\mathbf x^{prompt}$, message $m$, watermarking weight $\delta$}
% \KwOut{Here, provide the expected output/results of your algorithm}
%$\mathbf{x}^{:-1}:=\mathbf{x}^{prompt}$ \;
\For{$l=1,\cdots, L$}{

1. Calculate $\mathop{\log}P_{LLM}(v|\mathbf{x}^{prompt},\mathbf{t}_{:(l-1)}) \}$ for each $v$ in the vocabulary using $LLM$\;
2. Calculate $\mathop{\log}P_{w}(v|m,\mathbf{t}_{:(l-1)})$ based on the settled $P_{w}$\; 
3. Select $t_{l} = \mathop{\arg\max}\limits_{v}\ \{\mathop{\log}P_{LLM}(v|\mathbf{x}^{prompt},\mathbf{t}_{:(l-1)}) + \delta(\mathop{\log}P_{w}(v|m,\mathbf{t}_{:(l-1)}) - \frac{1}{|\mathcal{M}|}\mathop{\sum}\limits_{m'\in \mathcal{M}}\mathop{\log}P_{w}(v|m',\mathbf{t}_{:(l-1)})\}$
}
\KwOut{watermarked text $\mathbf{t} = \{t_1,t_2,\cdots,t_{L}\}$}
\caption{A General Message Encoding Framework for A Settled $P_{w}$}
\label{algo: encoding algorithm for general P}
\end{algorithm}


\subsection{The Design of message function $P_{w}$}
\label{sec: design of P}

% In Section~\ref{sec: encoding framwwork}, we propose a general encoding algorithm for $P_{w}$. Also, the decoding can be directly performed given $P_{w}$. So, the only thing that needs discussion is the design of $P_{w}$. Considering Algorithm~\ref{algo: encoding algorithm for general P}, a good design of P is supposed to make the following term $L(m,\mathbf x^{prompt}, \mathbf{t}_{:(l-1)})$ as large as possible for any message $m$:
In the above section, we present a general encoding algorithm for an arbitrary $P_{w}$. Consequently, the focus of our discussion shifts to the design of $P_{w}$. In the following, we will introduce two designs of $P_{w}$ as our preliminary attempts toward CTWL. 
% By considering Algorithm~\ref{algo: encoding algorithm for general P} and Eq.~(\ref{eq: encoding optimization problem}), a well-designed $P_{w}$ should maximize the following term, $L(m,\mathbf x^{prompt}, \mathbf{t}_{:(l-1)})$, for any message $m$:

% \begin{equation}
% \begin{aligned}
%     L(m,\mathbf x^{prompt}&, x_{:(l-1)})= \mathop{\max}\limits_{v}\{\underbrace{\mathop{\log}P_{LLM}(v|\mathbf{x}^{prompt},\mathbf{t}_{:(l-1)})}_{\text{model logit}}\\ &+ \delta(\underbrace{\mathop{\log}P(v|m,x_{:(l-1)}) - \frac{1}{|\mathcal{M}|}\mathop{\sum}\limits_{m'\in \mathcal{M}}\mathop{\log}P(v|m',x_{:(l-1)}}_{\text{message logit}})\}
%     \label{eq: encoding objective function}
% \end{aligned}
% \end{equation}

% Intuitively, a good $P_{w}$ should ensure that $\mathop{\log}P(v|m,x_{:(l-1)})$ largely differs for different $m$, so that there can be a large gap between $\mathop{\log}P(v|m,x_{:(l-1)})$ and $\frac{1}{|\mathcal{M}|}\mathop{\sum}\limits_{m'\in \mathcal{M}}\mathop{\log}P(v|\mathbf{x}^{prompt},m',x_{:(l-1)})$. Also, the token $v$ where $\mathop{\log}P(v|m,x_{:(l-1)})$ has a large gap against $\frac{1}{|\mathcal{M}|}\mathop{\sum}\limits_{m'\in \mathcal{M}}\mathop{\log}P(v|\mathbf{x}^{prompt},m',x_{:(l-1)})$ should also have high $\mathop{\log}P_{\mathca   l{LLM}}(v|\mathbf{x}^{prompt},m,x_{:(l-1)})$, to ensure that $L$ is large.

% Intuitively, an effective $P_{w}$ should aim to achieve a noticeable disparity between the values $\mathop{\log}P(v|m,x_{:(l-1)})$ for different message $m$. For certain $v$, this can create a significant gap between $\mathop{\log}P(v|m,x_{:(l-1)})$ and and the average $\frac{1}{|\mathcal{M}|}\mathop{\sum}\limits_{m'\in \mathcal{M}}\mathop{\log}P(v|m',x_{:(l-1)})$. Moreover, the token $v$ for which $\mathop{\log}P(v|m,x_{:(l-1)})$ exhibits a significant gap against $\frac{1}{|\mathcal{M}|}\mathop{\sum}\limits_{m'\in \mathcal{M}}\mathop{\log}P(v|m',x_{:(l-1)})$ should also have a high $\mathop{\log}P_{LLM}(v|\mathbf{x}^{prompt},\mathbf{t}_{:(l-1)})$. This ensures that the overall $L(m,\mathbf x^{prompt}, \mathbf{t}_{:(l-1)})$ value is large.


% new draft
% The $L(m,\mathbf x^{prompt}, \mathbf{t}_{:(l-1)})$ in Eq.~(\ref{eq: encoding objective function}), which measures the performance of a watermark algorithm base on $P_w$, comprises two components: model logit and message logit. The model logit is determined by the LLM used in generation, and is unchangeable. Conversely, the message logit is determined by $P_{w}$, providing the opportunity to enhance the watermark quality $L(m,\mathbf x^{prompt}, \mathbf{t}_{:(l-1)})$ by optimizing the design of $P_{w}$.
%The objective function $L(m,\mathbf x^{prompt}, \mathbf{t}_{:(l-1)})$ specified in Eq.~(\ref{eq: encoding objective function}) serves as a metric for evaluating the performance of a watermarking algorithm based on $P_w$. It comprises two core elements: the model logit and the message logit. The model logit is determined by the $LLM$ used in the text generation and is thus unchangeable. On the other hand, the message logit is determined by $P_{w}$, providing us the opportunity to enhance the watermark quality $L(m,\mathbf x^{prompt}, \mathbf{t}_{:(l-1)})$ by optimizing the design of $P_{w}$.

% Consider the message logits alone, i.e. consider Eq.~


\subsubsection{Vanilla $P_{w}$ for Random Vocabulary Partition}
\label{sec: vanilla P}
According to Eq.~(\ref{eq: encoding objective function}), a high value of $L(m,\mathbf x^{prompt}, \mathbf{t}_{:(l-1)})$ relies on the existence of a $v$ with a high message logit. In other words, there should be a $v$ for which $\log P_{w}(v|m,\mathbf{t}_{:(l-1)})$ greatly surpasses the mean. To achieve this, one natural idea is to ensure that the distribution $\mathbf P_{w}(m,\mathbf{t}_{:(l-1)}) = (P_{w}(v_1|m,\mathbf{t}_{:(l-1)}),P_{w}(v_2|m,\mathbf{t}_{:(l-1)}),\cdots,P_{w}(v_{|\mathcal{V}|}|m,\mathbf{t}))$ varies greatly across distinct messages. In this way, for a message $m$, there would at least exist a $v$ whose $\log P_w(v|m,\mathbf{t}_{:(l-1)})$ deviates far from the mean $\frac{1}{|\mathcal{M}|}\mathop{\sum}\nolimits_{m'\in \mathcal{M}}\mathop{\log}P_{w}(v|m',\mathbf{t}_{:(l-1)})$, thereby resulting in a high message logit. To ensure such differences in $\mathbf P_{w}(m,\mathbf{t}_{:(l-1)})$ with different $m$, we can assign random values for $\mathbf P_{w}(m,\mathbf{t}_{:(l-1)})$ based on the random seeds directly decided by their own $m$:
% One straightforward method to design $P_{w}$ is to assign random values for $\mathop{\log}P(v|m,x_{:(l-1)})$. This random assignment allows for the existence of a certain $v$ that results in a large $\mathop{\log}P(v|m,x_{:(l-1)}) - \frac{1}{|\mathcal{M}|}\mathop{\sum}\limits_{m'\in \mathcal{M}}\mathop{\log}P(v|m',x_{:(l-1)})$ for any given message. This vanilla approach can be seen as an expansion of the soft watermarking method proposed by~\citet{watermark_llm}, which we refer to as \textbf{Vanilla Codable Text Watermarking for LLMs~(Vanilla CTWL)}\wang{how to name it?}.
\begin{equation}
    \label{eq: vanilla_CTWL raw}
  \log \hat{P}_w(v|m,\mathbf{t}_{:(l-1)}) = \begin{cases}
        1 , & h(v,m,\mathbf{t}_{:(l-1)}) = 1, \\
        0 ,& h(v,m,\mathbf{t}_{:(l-1)}) = 0.
    \end{cases}
\end{equation}
\begin{equation}
    \label{eq: vanilla_CTWL}
  \log P_w(v|m,\mathbf{t}_{:(l-1)}) = \log\frac{\hat{P}_w(v|m,\mathbf{t}_{:(l-1)})}{\sum\limits_{v} \hat{P}_w(v|m,\mathbf{t}_{:(l-1)})}.
\end{equation}
In the above, $h$ denotes a hash function that maps the input $(v,m,\mathbf{t}_{:(l-1)})$ to either 0 or 1. 
%, and $Z$ is a normalization term to ensure that $\mathop{\sum}\limits_{v} P_w(v|m,x_{:(l-1)}) = 1$. 
This can be considered as a vanilla extension from the soft watermarking method in~\citet{watermark_llm} by further taking $m$ into consideration, thus we denote it as \textbf{Vanilla-Marking}.

%Additionally, because the assignment of values in $P_w$ is random, $\frac{1}{|\mathcal{M}|}\mathop{\sum}\nolimits_{m'\in \mathcal{M}}\mathop{\log}P_w(v|m',\mathbf{t}_{:(l-1)})$ is nearly constant, so we can omit it in the encoding procedure.

\subsubsection{$LM_{proxy}$-aided $P_{w}$ for Balance Vocabulary Partition}

% The vanilla $P_{w}$ in Section~\ref{sec: vanilla P} does not incorporate $\mathop{\log}P_{LLM}(v|\mathbf{x}^{prompt},\mathbf{t}_{:(l-1)})$, potentially resulting in a suboptimal balance between watermark and text quality. For any given message $m$, to ensure that the whole $L(m,\mathbf x^{prompt}, \mathbf{t}_{:(l-1)})$ value is large, there needs to be a particular $v$ satisfying both high $\mathop{\log}P_{LLM}(v|\mathbf{x}^{prompt},\mathbf{t}_{:(l-1)})$ and high $\mathop{\log}P(v|m,x_{:(l-1)}) - \frac{1}{|\mathcal{M}|}\mathop{\sum}\limits_{m'\in \mathcal{M}}\mathop{\log}P(v|m',x_{:(l-1)})$. Encouraged by this insight, for each message $m$, we randomly choose a set $V_{m,\mathbf{t}_{:(l-1)}}$ from the vocabulary that satisfies the below condition:

The message function $P_w$ proposed in Section~\ref{sec: vanilla P} indeed ensures the existence of a $v$ with a high message logit. However, 
%the same $v$ may have a low model logit, which will lead to a low $L(m,\mathbf x^{prompt}, \mathbf{t}_{:(l-1)})$. 
it does not guarantee that the same $v$ can also have a high model logit at the same time. This could potentially result in a small sum of the model logit and the message logit. Therefore, we argue that \textbf{a more advanced $P_{w}$ should produce a $v$ with both a high model logit and a message logit}. 

To accomplish this, we are motivated to utilize the model logit distribution $\mathbf{P}_{LLM}(\mathbf{x}^{prompt},\mathbf{t}_{:(l-1)})$ as prior knowledge, and select a subset of tokens that is likely to contain some token $v$ with a high model logit in advance. Then, we assign high message logits to those tokens in the above subset, ensuring the existence of a token $v$ with both a high model logit and message logit. Specifically, we propose to use Algorithm~\ref{algo: choose V_{m,x_{:(l-1)}}_old} to randomly choose the subset $V_{m,\mathbf{t}_{:(l-1)}}$ from the vocabulary that satisfies the following condition:
% \begin{equation}
% \label{eq: V_m condition}
%     \mathop{\sum}\limits_{v\in V_{m,\mathbf{t}_{:(l-1)}}} P_{LM_{proxy}}(v| x_{(l-1- L_{prefix}):(l-1)}) \geq 0.5 
% \end{equation}
\begin{equation}
\label{eq: V_m condition}
    \mathop{\sum}\limits_{v\in V_{m, \mathbf{t}_{:(l-1)}}}P_{LLM}(\mathbf{x}^{prompt},\mathbf{t}_{:(l-1)}) \geq \sigma, 
\end{equation}
where $\sigma$ is a controllable threshold. In the following sections, we set $\sigma=0.5$ unless otherwise stated. That is because we believe that balancing the probability accumulations of tokens within and out of $V_{m, \mathbf{t}_{:(l-1)}}$ can achieve the maximal diversity of $V_{m, \mathbf{t}_{:(l-1)}}$ w.r.t.\ different $m$. After getting $V_{m, \mathbf{t}_{:(l-1)}}$, we assign the message logits as
\begin{equation}
    \label{eq: LM_pub-aided P raw}
     \log \hat{P}_w(v|m,\mathbf{t}_{:(l-1)}) = \begin{cases}
        1 , & v \in V_{m,\mathbf{t}_{:(l-1)}}, \\
        0 ,& v \not\in V_{m,\mathbf{t}_{:(l-1)}}.
    \end{cases}
\end{equation}
\begin{equation}
    \label{eq: LM_pub-aided P}
  \log P_w(v|m,\mathbf{t}_{:(l-1)}) = \log\frac{\hat{P}_w(v|m,\mathbf{t}_{:(l-1)})}{\sum\limits_{v} \hat{P}_w(v|m,\mathbf{t}_{:(l-1)})}.
\end{equation}

The reason why we design Algorithm~\ref{algo: choose V_{m,x_{:(l-1)}}_old} in such a way is that the case when all $\{P_{LLM}(v|\mathbf x^{prompt}, \mathbf{t}_{:(l-1)})|v \in V_{m,\mathbf{t}_{:(l-1)}}\}$ values tend to be small, yet still sum to $\sigma$, is very unlikely to occur. That is, there should always be some $P_{LLM}(v|\mathbf x^{prompt}, \mathbf{t}_{:(l-1)})$ that is relatively large to make the summation exceed the threshold. Additionally, introducing randomness in the selection process of $V_{m,\mathbf{t}_{:(l-1)}}$ can enlarge the difference in $V_{m,\mathbf{t}_{:(l-1)}}$ among different messages $m$, which plays the same role as that in Vanilla-Marking.
%The way of choosing $V_{m,\mathbf{t}_{:(l-1)}}$ in Algorithm~\ref{algo: choose V_{m,x_{:(l-1)}}_old} ensures the existence of a $v$ with high model logit in $V_{m,\mathbf{t}_{:(l-1)}}$. Otherwise, all $P_{LLM}(v_1|m,\mathbf x^{prompt}, \mathbf{t}_{:(l-1)}), ..., P_{LLM}(v_k|m,\mathbf x^{prompt}, \mathbf{t}_{:(l-1)})$ would have to be low, but still sum to $0.5$, a scenario that is highly improbable. Additionally, introducing randomness in the selection process of $V_{m,\mathbf{t}_{:(l-1)}}$ can enlarge the difference in $V_{m,\mathbf{t}_{:(l-1)}}$ for different messages $m$, which aids in distinguishing between different messages during decoding.


% Then, we allocate high message logits to the tokens within this set, ensuring the existence of a $v$ with both a high model logit and message logit:

% \begin{equation}
%     \label{eq: LM_pub-aided P}
%     \mathop{\log} P_w(v|m,x_{:(l-1)}) = \begin{cases}
%         1 - Z_{m,\mathbf{t}_{:(l-1)}} & v \in V_{m,\mathbf{t}_{:(l-1)}} \\
%         0 - Z_{m,\mathbf{t}_{:(l-1)}} & v \not\in V_{m,\mathbf{t}_{:(l-1)}}
%     \end{cases}
% \end{equation}
% Here, as in Eq.~(\ref{eq: vanilla_CTWL}), $Z$ is a normalization term ensuring that $\mathop{\sum}\limits_{v} P_w(v|m,\mathbf{t}_{:(l-1)}) = 1$.

\begin{algorithm}[t]
\SetAlgoLined
% \KwResult{Result of the algorithm}
\KwIn{Message $m$, text prefix $\mathbf{t}_{:(l-1)}$, language model $LLM$}
% \KwOut{Here, provide the expected output/results of your algorithm}
1. Calculate a seed $s = h(m,\mathbf{t}_{:(l-1)})$ with a hash function $h$\;
2. Shuffle the vocab list $(v_1, \cdots, v_{|\mathcal{V}|})$ to $(v'_1, \cdots, v'_{|\mathcal{V}|})$ with the seed $s$\;
3. Select the first $k$ tokens in the shuffled list so that $k$ is the minimal value to make $\{v'_1,\cdots,v'_k\}$ satisfy Eq.~(\ref{eq: V_m condition}).

\KwOut{$V_{m,\mathbf{t}_{:(l-1)}} = \{v'_1,\cdots,v'_k\}$}
\caption{Ideal Version of Choosing Subset $V_{m,\mathbf{t}_{:(l-1)}}$}
\label{algo: choose V_{m,x_{:(l-1)}}_old}
\end{algorithm}

% However, such a method faces two challenges. (1) Since $P_{w}$ is a function of the input $(m, x_{:(l-1)})$, it cannot involve $\mathbf{x}^{prompt}$ (2) During the decoding process, we may only receive a segment of the watermarked text, leading to disparities between the $x_{:(l-1)}$ used in encoding and decoding. Given this, we use $P_{LLM}(v| \mathbf{t}_{(l-1- L_{prefix}):(l-1)})$ to estimate $P_{LLM}(v|\mathbf{x}^{prompt},\mathbf{t}_{:(l-1)})$, where we omit $\mathbf{x}^{prompt}$, and truncate $x_{:(l-1)}$ to a fixed-length $x_{(l-1- L_{prefix}):(l-1)}$, so that it can remain consistent during encoding and decoding.
Nevertheless, the above approach still encounters several obstacles in realistic applications. Thus, we make the following improvements to make it more practical: 

\paragraph{(1) Omit $\mathbf{x}^{prompt}$ and truncate $\mathbf{t}_{:(l-1)}$ into a fixed length.} Considering that the $\mathbf{x}^{prompt}$ is usually unavailable and we might only obtain a segment of the watermarked text during the message decoding phase, it will cause inconsistency between the encoding and decoding phases on calculating the token probabilities for creating $V_{m,\mathbf{t}_{:(l-1)}}$. To address this problem, we employ $P_{LLM}(v| \mathbf{t}_{(l-1- L_{prefix}):(l-1)})$ to approximate $P_{LLM}(v|\mathbf{x}^{prompt},\mathbf{t}_{:(l-1)})$. That is, we omit $\mathbf{x}^{prompt}$ and truncate $\mathbf{t}_{:(l-1)}$ to a fixed-length $\mathbf{t}_{(l-1- L_{prefix}):(l-1)}$ for consistency during both encoding and decoding.

\paragraph{(2) Use a proxy language model (proxy-LM) $LM_{proxy}$ in Eq.~(\ref{eq: V_m condition}).} Moreover, considering several usage scenarios discussed in Section~\ref{sec: scenes}, we broaden the $LLM$ in $P_{LLM}(v| \mathbf{t}_{(l-1- L_{prefix}):(l-1)})$ into a proxy model $LM_{proxy}$. This model can either be $LLM$ itself when the model company wants that the watermarked text can only be decoded by itself, or be another smaller and public  language model (e.g., GPT-2~\citep{gpt2}) $P_{LLM}$ that allows for quicker computation of $P_{w}$ and enables anyone to decode the embedded message without knowing the specific $LLM$ used in text generation. 
Following this, we modify the condition in Eq.~(\ref{eq: V_m condition}) to:
\begin{equation}
\label{eq: V_m condition proxy}
    \mathop{\sum}\limits_{v\in V_{m, \mathbf{t}_{:(l-1)}}} P_{LM_{proxy}}(v| \mathbf{t}_{(l-1- L_{prefix}):(l-1)}) \geq \sigma.
\end{equation}

\paragraph{(3) Pre-map message space into a smaller space for efficient computing.} 
%Changing the condition Eq.~(\ref{eq: V_m condition}) in Algorithm~\ref{algo: choose V_{m,x_{:(l-1)}}_old} to the condition Eq.~(\ref{eq: V_m condition proxy}) results in Algorithm~\ref{algo: choose V_{m,x_{:(l-1)}}}. 
Since computing $V_{m,\mathbf{t}_{:(l-1)}}$ for each $m$ during encoding can be much time-consuming when the message space is pretty large, we opt to first map the entire message space into a smaller space as $m \rightarrow \hat{h}(m) \in \mathcal{M}_{A}=\{1,\cdots, A \}$ by using another hash function $\hat{h}$, and then compute the seed $s$ as $s = h(\hat h(m), x_{:(l-1)})$. By this way, we only need to run Algorithm~\ref{algo: choose V_{m,x_{:(l-1)}}_old} a mere $A$ times for each $\mathbf{t}_{:(l-1)}$.\footnote{For a detailed discussion about the choice of $A$, refer to Section~\ref{sec: The effect of $A$}.}
% and use this condition in Algorithm~\ref{algo: choose V_{m,x_{:(l-1)}}_old} and Eq.~(\ref{eq: LM_pub-aided P}). 


\begin{algorithm}[t]
\SetAlgoLined
% \KwResult{Result of the algorithm}
\KwIn{Message $m$, text prefix $\mathbf{t}_{:(l-1)}$, proxy-LM $LM_{proxy}$, $\mathcal{M_A}=\{1,\cdots,A\}$.}
% \KwOut{Here, provide the expected output/results of your algorithm}
1. Calculate a seed $s = h(\hat h(m),\mathbf{t}_{:(l-1)})$ with a hash function $h$ and another hash function $\hat h$ that maps $m$ to $\hat{h}(m) \in \mathcal{M}_{A}$\;
2. Shuffle the vocab list $(v_1, \cdots, v_{|\mathcal{V}|})$ to $(v'_1, \cdots, v'_{|\mathcal{V}|})$ with the seed $s$\;
3. Select the first $k$ tokens in the shuffled list so that $k$ is the minimal value to make $\{v'_1,\cdots,v'_k\}$ satisfy Eq.~(\ref{eq: V_m condition proxy}).\

\KwOut{$V_{m,\mathbf{t}_{:(l-1)}} = \{v'_1,...,v'_k\}$}
\caption{Practical Version of Choosing Subset $V_{m,\mathbf{t}_{:(l-1)}}$}
\label{algo: choose V_{m,x_{:(l-1)}}}
\end{algorithm}

%The watermarking algorithm, which uses $P_{w}$ as defined in Eq.~(\ref{eq: LM_pub-aided P}) and Algorithm~\ref{algo: choose V_{m,x_{:(l-1)}}}, is referred to as \textbf{Balance-Marking}. 
All in all, we summarize the final practical version of the above $LM_{proxy}$-aided watermarking method in Algorithm~\ref{algo: choose V_{m,x_{:(l-1)}}}. Given that this method employs a probability-balanced vocabulary partition, we refer to it as \textbf{Balance-Marking}. 
%Still, we omit $\frac{1}{|\mathcal{M}|}\mathop{\sum}\limits_{m'\in \mathcal{M}}\mathop{\log}P_w(v|m',\mathbf{t}_{:(l-1)})$ during encoding as discussed in Section~\ref{sec: vanilla P}.
 % Additionally, thanks to the randomness in selecting, $\frac{1}{|\mathcal{M}|}\mathop{\sum}\limits_{m'\in \mathcal{M}}\mathop{\log}P_w(v|m',x_{:(l-1)})$ is still nearly a constant,  so we omit it in encoding as in Section~\ref{sec: vanilla P}.


\subsubsection{An intuitive analysis of Vanilla-Marking and Balance-Marking}
\label{sec: intuitive analysis}
In the watermark algorithm proposed by \cite{watermark_llm}, the candidates for the preceding tokens are randomly split into two parts: the available token part (i.e., ``green token list'') and the unavailable token part (i.e., ``red token list''). The model is then encouraged to generate tokens lying in the green list so as to watermark the text. In our work, Eq.~(\ref{eq: vanilla_CTWL raw}) and Eq.~(\ref{eq: vanilla_CTWL}) of Vanilla-Marking, and Eq.~(\ref{eq: LM_pub-aided P raw}) and Eq.~(\ref{eq: LM_pub-aided P}) of Balance-Marking fulfill similar roles, assigning some tokens with higher message logits.

However, Balance-Marking is more effective in maintaining text quality when choosing the available tokens for a specific message compared to Vanilla-Marking. That is because Balance-Marking strives to find the available token list whose accumulated model logits surpass a certain percentage of the total probability sum. This strategy ensures that it can include some tokens with relatively high model logits in the available token list, and make the next word generation more reliable. On the other hand, Vanilla-Marking, which randomly selects the available tokens with no extra conditions, might end up with an unreasonable next token and reduce text quality. 
%This forces the model to generate either texts with high perplexity (PPL) or texts devoid of any watermark.

Interestingly, Balance-Marking also has the ability to automatically bypass low-entropy sections of the text, which is a property that \citet{sweet} explicitly aims to achieve. For example, consider a special situation in which there is only one reasonable token candidate, whose predicted probability by proxy-LM is almost 1.0. Then, 
%Take for example a situation where there is only one reasonable preceding token,  which possesses a probability nearing 1. 
for all messages, this token would be selected into the available part, according to Eq.~(\ref{eq: V_m condition proxy}). In other words, this position in the sequence is implicitly ``skipped'' during watermark encoding and decoding, and the decoding process is actually carried out by comparing the values of $P_w$ under different $m$ on those high-entropy sections of the text.



\subsection{Message Decoding}
\label{subsec: message extracting phase}
For a settled $P_w$, the decoding process is conducted by finding a solution to Eq.~(\ref{eq: target on extracting messages}). As per Bayes' Theorem, this can be rewritten as:
\begin{equation}
\label{eq: decoding messages}
\begin{aligned}
 m &= \mathop{\arg\max}_{m' \in \mathcal{M}}  P_{w}(\mathbf{t}|m'), \\
 &= \mathop{\arg\max}_{m' \in \mathcal{M}} \{ \mathop{\sum}\limits_{l=1}^{L} \mathop{\log}P_{w}(t_{l}|m,\mathbf{t}_{:(l-1)})\}.
\end{aligned}
\end{equation}
Eq.~(\ref{eq: decoding messages}) can be computed directly using either Eq.~(\ref{eq: vanilla_CTWL}) for Vanilla-Marking, or Eq.~(\ref{eq: LM_pub-aided P}) for Balance-Marking. 
%Similar to Section~\ref{sec: vanilla P}, we omit $Z_{m,\mathbf{t}_{:(l-1)}}$ in  Eq.~(\ref{eq: vanilla_CTWL}) and Eq.~(\ref{eq: LM_pub-aided P}) to simplify the computation, since $Z_{m,\mathbf{t}_{:(l-1)}}$ values are similar across different messages $m$, due to the randomness in the assignment of values to $P_w$.

Furthermore, when we need to encode multiple messages into text, we can sequentially encode each message into one segment of the text (e.g., every 100 tokens of the text). Then, message decoding can be conducted independently within each segment.





% ToDo: V2é‡Œå°†æ›´å¤šçš„æ•°æ®é›†å¼•å…¥è¿›æ¥ï¼Œå°†å•çº¯çš„Evaluation Systemå‡çº§æˆåŒ…å«Evalå’ŒDatasetsçš„Benchmark
% \section{Benchmark of Codable Text Watermarking for LLMs}
\section{The Evaluation System of CTWL}
\label{sec: evaluation}
The prosperity of LLM technology has brought more diverse and differentiated application scenarios than traditional NLP models. 
Therefore, the evaluation of the practicability of LLM-generated text watermarking technology is expected to keep pace with this trend.
However, existing studies lack a unified convincing evaluation system for LLM-generated text watermarking technology.
In this section, we start with analyzing the uniqueness of LLM applications and establish a comprehensive evaluation system for LLM-generated text watermarking from 5 different aspects.
\subsection{Watermarking Success Rate}
We define two indicators to measure how successful the watermark is injected into LLM-generated texts as expected: (1) Success rate of recognizing the model-generated texts from human written texts, referred to as Success$_\text{h}$, and (2) Success rate of recovering the injected watermark message, referred to as Success$_\text{m}$. 
Both of these two metrics need to be considered for CTWL; while for normal LLM watermarking~\citep{watermark_llm}, only the first metric need to be evaluated. 

\subsection{Robustness Against Attacks}
Texts generated by LLMs are usually modified before they are actually used for the purpose of polishing or detection escaping. Thus, the watermarking algorithms need to ensure robustness in the face of various corruptions and attacks.
We summarize the three most representative attacks threatening the success of LLM watermarking: (1)~\textbf{Copy-Paste Attack}~\citep{reliability_of_watermark}, where LLM-generated text fragments are mixed with human-written text fragments; (2)~\textbf{Substitution Attack}, where individual or sequential tokens are synonymously replaced based on human knowledge or masked language models like BERT~\citep{bert} or RoBERTa~\citep{roberta}; (3)~\textbf{Paraphrase Attack}~\citep{paraphrasing_attack}, where the entire LLM-generated text is paraphrased by human or model, resulting in a complete reconstruction of the original text. Paraphrase attack poses an extremely difficult challenge for the watermarking algorithms~\citep{paraphrasing_attack}. 

\subsection{Payload Information Coding Rate}
For non-codable watermarking methods, the encoded information is always one-bit. While for CTWL, we divide the number of bits carried by the watermark by the length of the covered tokens as the indicator for measuring the coding rate of the watermarking algorithm.
Obviously, a good watermarking technique should encode as many bits of information as possible without sacrificing the performance on other metrics.

\subsection{Encoding and Decoding Efficiency}
Injecting watermarks during LLMs generation will inevitably increase the computational cost. Moreover, restoring multiple bits of information from the text also takes higher computational complexity than decoding 1-bit information. We argue that it is necessary to consider the additional computational complexity brought by the encoding and decoding of the large model watermarking algorithm. 
Besides, the parallelism of the watermarking algorithm is also vital for the actual time consumption.

\subsection{Impact on the Quality of Generated Text}
Codable watermarks contain more complex information and have a larger impact on the quality of text generated by LLMs than non-codable watermarks. Therefore, it is necessary to ensure that the impact of the watermark on the quality of LLM-generated text is within an acceptable range for the deployment of watermarking algorithms. In the current work, we adopt the text perplexity (PPL) as an automated metric to measure the quality of LLM-generated texts. In future work, we will include more metrics such as semantic similarity or human evaluation for comprehensive evaluation of text quality.
%As an alternative supplementary, manually reviewing the LLM-generated text with watermarks can further confirm the impact of watermark on the quality of texts.
% V2 ToDo
% \subsection{Datasets}




\section{Experiment}
\label{sec: experiment}
\subsection{Experimental Settings}

In line with the experimental settings used in~\citet{watermark_llm}, we utilize the OPT-1.3B model~\citep{Zhang2022OPTOP} for the generation of texts. Our prompt inputs are derived from the news-like subset of the C4 dataset~\citep{2019t5}. In each experiment, we extract 500 prompt inputs in total. These inputs are then truncated to maintain a uniform length of 300 tokens. Subsequently, the model is requested to generate 200 tokens predicated on the given input. This is achieved through a 4-way beam-search process. Moreover, to mitigate repetition in the generated text, we implement a repetition penalty of 1.5, which is applied akin to the ``alpha\_presence'' parameter in the OpenAI API.\footnote{\url{https://platform.openai.com/docs/api-reference/parameter-details}}

To assess the quality of the generated text, we adopt the perplexity~(PPL) measurement, calculated using the superior-performing OPT-2.7B model~\citep{Zhang2022OPTOP}. This choice aligns with the methodology used by \citet{watermark_llm}. All our experiments are conducted based on the Huggingface library~\citep{Wolf2019HuggingFacesTS}.


\subsection{Implemention details}
\label{sec: implementation}
% add some details of the method, like A, L_prefix's values, LM_proxy, and so on, and tokenizer in encoding and decoding.
% \paragraph{Vanilla-Marking} 
\paragraph{Hash Scheme.} Following the hash implementation in \cite{watermark_llm}, in the case of both Vanilla-Marking and Balance-Marking methods, we make use of the last token in $\mathbf{t}_{:(l-1)}$ to calculate $h(v,m,\mathbf{t}_{:(l-1)})$ in Eq.~(\ref{eq: vanilla_CTWL raw}) and $h(m,\mathbf{t}_{:(l-1)})$ in Algorithm~\ref{algo: choose V_{m,x_{:(l-1)}}}, i.e. $h(v,m,\mathbf{t}_{:(l-1)})=h(v,m,t_{l-1})$ and $h(m,\mathbf{t}_{:(l-1)})=h(m,t_{l-1})$. 

\paragraph{The Choice of $\boldsymbol{\sigma}$.} In %both Eq.~(\ref{eq: V_m condition}) and 
Eq.~(\ref{eq: V_m condition proxy}), we set $\sigma=0.5$. The reason to set $\sigma=0.5$ is to achieve the maximal diversity of $V_{m, \mathbf{t}_{:(l-1)}}$ w.r.t. different $m$. However, it is possible that the value $\sigma$ can be further optimized, and we leave it to the next version of work.

\paragraph{Hyper-parameters of Balance-Marking.} As for the $LM_{proxy}$ in Balance-Marking, we opt to use GPT2~\citep{gpt2}, a well-known, publicly available, and comparatively smaller language model, which comprises 124M parameters. Additional hyper-parameters used in Balance-Marking are set to the following: $A=100$, $L_{prefix}=10$, and $\mathcal{M}=\{0,1,...,2^{20}-1\}$. Here, a message $m\in \mathcal{M}$ corresponds to 20-bit information. We analyze the impact of these hyper-parameters in Section~\ref{sec: analyze}. 

% may change the name; not polished
\paragraph{Computation Simplification.} (1) When implementing Algorithm~\ref{algo: encoding algorithm for general P}, there is a need to compute $\frac{1}{|\mathcal{M}|}\mathop{\sum}\nolimits_{m'\in \mathcal{M}}\mathop{\log}P_{w}(v|m',\mathbf{t}_{:(l-1)})$, which can be a time-consuming task. However, due to the inherent randomness of $P_w$, we hypothesize that this mean value almost remains constant under the Law of Large Numbers. This hypothesis is corroborated by our empirical studies which indicate that this value remains close to -11 with a relatively insignificant standard deviation (less than 0.05) across $v$. Hence, we can \textbf{exclude this calculation from Algorithm~\ref{algo: encoding algorithm for general P} during encoding for efficiency}. (2) Similarly, we \textbf{substitute $ \log P_w(v|m,\mathbf{t}_{:(l-1)})$ with $\log \hat{P}_w(v|m,\mathbf{t}_{:(l-1)})$ in Eq.~(\ref{eq: decoding messages})}. The difference between the two expressions equals $\mathop{\log}\mathop{\sum}\limits_v \hat{P}_w(v|m,\mathbf{t}_{:(l-1)})$, which we assume to be almost constant. Our empirical findings support this claim. In the Vanilla-Marking approach, the standard deviation is as low as 0.002, with an average value of 11.4. Despite Balance-Marking having a slightly higher deviation (0.23) and a mean of 11.4, it still allows for the exclusion of this calculation to help speed up the computation process. The detailed discussion and empirical evidence for (1) and (2) are put in Appendix~\ref{appendix: reasons for omitting}.
%(3) Finally, when resolving $t_l$ in Algorithm~\ref{algo: encoding algorithm for general P}, we \textbf{focus only on the top-1000 tokens (as predicted by $LLM$) so as to expedite the computation}. We make this choice since tokens $v$ with a low $P_{LLM}(v|\mathbf{x}^{prompt} ,\mathbf{t}_{:(l-1)})$ cannot be potential solutions for $t_l$.


In order to accelerate the decoding process of Vanilla-Marking and Balance-Marking, we have taken special care to perform vectorization during $P_w$ calculations. All detailed implementation and related code can be viewed via our provided GitHub repository.\footnote{\url{https://github.com/lancopku/codable-watermarking-for-llm}}




\subsection{The Results of Watermark Quality}
\label{sec: main_results}

% Figure environment removed


For both Vanilla-Marking and Balance-Marking, we can adjust $\delta$ in Algorithm~\ref{algo: encoding algorithm for general P} to balance text quality and watermark success rate. A high $\delta$ encourages a strong watermark but hurts text quality. To explore the performance of a specific watermark algorithm, we run experiments with multiple $\delta$s (i.e., $\{0.5, 0.8, 0.9, 1.0, 1.1, 1.2, 1.3, 1.4, 1.5, 1.8, 2.0, 2.5, 3.0, 4.0\}$) and record the corresponding text quality and watermark success rate.

Figure~\ref{subfig:ppl-WSR-10} and~\ref{subfig:ppl-WSR-5} illustrate the trade-off relationship between text quality (measured via perplexity) and the watermarking success rate of restoring the injected watermark message, Success$_\text{m}$, under different payload information coding rates. We filtered out the points with too poor text quality (PPL $> 4$) and rescaled the y-axis for clearer demonstration. As expected, an increase in Success$_\text{m}$ compromises text quality. 

Watermarks with high coding rates, which encapsulate more information, are particularly challenging to embed into text without causing noticeable effects. Such watermarks tend to increase perplexity, degrading text quality. 


Upon analysis, it is evident that Balance-Marking surpasses the Vanilla-Marking approach, achieving a more favorable balance between text quality and the success rate of watermarking.

% not totally finished
\subsection{The Results of Robustness to Real-world Attacks}

In practical use cases, the watermark embedded within a text may face attenuation due to various attacks. It may become challenging to detect when concealed within human-generated texts, a scenario termed as Copy-Paste Attacks~\citep{reliability_of_watermark}. Additionally, the watermark might be exposed to erosion stemming from activities like word substitution, which we refer to as Substitution Attacks.\footnote{Both Vanilla-Marking and Balance-Marking are unable to decode the original message after Paraphrasing Attacks~\citep{reliability_of_watermark} performed by GPT-3.5-turbo. We discuss this as a limitation in Section~\ref{sec: limitation}.}. Here, we only apply these attacks to the watermark under the coding rate of 10 tokens per bit. This is based on our observation that a payload of 5 tokens per bit results in a watermark excessively susceptible to attacks.

% V2 ToDO: å¯ä»¥è€ƒè™‘åœ¨è¿™é‡Œç”»ä¸€å¼ ç›´è§‚çš„å›¾ï¼Œå±•ç¤ºæˆ‘ä»¬çš„æ–¹æ³•å¯¹äºŽäººç±»/æœºå™¨æ–‡æœ¬è¾¹ç•Œçš„åˆ¤æ–­æƒ…å†µ
% ç›´è§‚çš„æŠŠçª—å£åœ¨æ··åˆæ–‡æœ¬ä¸Šæ»‘åŠ¨æ—¶çš„ç»“æžœç½®ä¿¡åº¦ç”»å‡ºæ¥
\subsubsection{Robustness to Copy-paste Attacks}
\label{sec: copy-paste attack}

In cases where individuals utilize texts produced by language models, these pieces might later be appended to other human-written texts. We denote this phenomenon as a "Copy-Paste Attack". This technique complicates the detection of watermarks since the place of the watermarked text is no longer predictable.

In our attempt to reproduce real-world scenarios, we introduce a 200-token watermarked text into a 1000-token human-written text, sourced from the c4 dataset. To detect the text, we employ a sliding window with a width of 190 tokens and calculate $P_w(m|\mathbf{x})$,\footnote{According to Bayes' Formula, $P_w(m|\mathbf{x}) \propto P_w(\mathbf{x}|m)$ and the latter can be directly computed as discussed in Section~\ref{subsec: message extracting phase}. So, by normalizing  $P_w(\mathbf{x}|m)$ we get $P_w(m|\mathbf{x})$.} where $\mathbf{x}$ is the text enclosed within the window. To minimize computational overhead, we set the stride to 10. As the watermarked text consists of 200 tokens, a 190-token-width window falling within the watermarked text must exist when the stride is 10.

% To exclude human-written text, we establish a threshold of  $1-10^{-5}$. In the case where the value of $\max_m P(m|x)$ falls below this threshold, the text $x$ is identified as human-written. Our experiments showed that this threshold could affirm that no human-written text is incorrectly labeled as watermarked. However, it's worth noting that there's a chance for some watermarked texts to be misidentified as human-written. % add a commment that there is also no message falsely decoded out, the error all due to misclassfied as human-written

To exclude human-written text, we establish a threshold of  $1-10^{-5}$. In the case where the value of $\max_m P(m|\mathbf{x})$ falls below this threshold, the text $x$ is identified as human-written. Our experiments showed that this threshold could affirm that no human-written text is incorrectly labeled as watermarked. The error occurs only in one particular scenario: the message cannot be extracted from the watermarked text and the text is misidentified as human-written.

Figure~\ref{fig:cp} illustrates the impact of Copy-Paste Attacks. Both Balance-Marking and Vanilla-Marking are affected by such attacks, while Balance-Marking still outperforms Vanilla-Marking.

% add analysis of figure~\ref{fig:cp} 

% Figure environment removed

\subsubsection{Robustness to Substitution Attacks}
In the practical application of model-generated texts, tokens may be replaced for editing purposes or to prevent watermark detection. To replicate this, we employ the Roberta-Large model to carry out word substitution. For a chosen text to be tested on, we arbitrarily pick an unaltered token each time. This token is then masked and the model is asked to predict it. In the event that a token's predicted logit surpasses the predicted logit of the original token minus 1.0, we replace the original token with the new one. With a designated substitution ratio $\alpha$ and a sentence consisting of $L$ tokens, we continue this process until the substituted tokens reach the value of $\alpha L$ or after $3\alpha L$ attempts are made. From empirical analysis, we establish that such replacements result in a marginal increase in PPL by around 0.1.

% Figure environment removed

Figure~\ref{fig:substitution-attacks} illustrates the impact of Substitution Attacks on Vanilla-Marking and Balance-Marking. A higher substitution results in a lower success rate Success$_\text{m}$. The performance of Balance-Marking and Vanilla-Marking become closer from Figure~\ref{fig:sub-0.05} to Figure~\ref{fig:sub-0.1}, indicating that Substitution Attacks may do more hurt to Balance-Marking than Vanilla-Marking. This can be attributed to the fact that $P_w$ of Balance-Marking relies on $\mathbf{t}_{(l-1-L_{prefix}):(l-1)}$~(see Eq.~(\ref{eq: V_m condition proxy})), while $P_w$ of Vanilla-Marking only depends on $t_{(l-1)}$, since we only use the last token of $\mathbf{t}_{:(l-1)}$ to calculate $h(m,\mathbf{t}_{:(l-1)})$ (see Section~\ref{sec: implementation}). So, Balance-Marking will be affected more when more tokens are substituted.



\subsection{The results of Distinguishing between human-written and message-embedded texts}

% In the sections above, we measure the watermark quality by Success$_\text{m}$, success rate of restoring the injected watermark message. In practical scenarios, we may also need to avoid misclassifying human-written texts as watermarked texts and extracting messages from them. To achieve this, we can use a threshold to filter the human-written messages, as Section~\ref{sec: copy-paste attack} has done. Still, we use threshold  $1-10^{-5}$ as Section~\ref{sec: copy-paste attack}, which has been proven effective to filter all human-written texts. Figure~\ref{fig:ppl-10-WSR-1-1e-5} shows the Success$_\text{h}$ and text quality under different $\delta$s and coding rate 10 tokens per bit. Here, since all human-written text are classified correctly under threshold  $1-10^{-5}$, Success$_\text{h}$ actually measures the proportion of watermarked texts that misclassified as human-written. 


We previously evaluated watermark quality using the Success$_\text{m}$ metric, which gauges the success rate of restoring the injected watermark message. In real-world applications, however, it's just as crucial to prevent the misidentification of human-written texts as watermarked ones and avoid extracting false messages from them. To mitigate this issue, a threshold can be utilized to filter out human-written messages, similar to the approach outlined in Section~\ref{sec: copy-paste attack}.

By continuing to use a threshold of  $1-10^{-5}$, as discussed in Section~\ref{sec: copy-paste attack}, we can effectively filter out all human-written texts, but some watermarked texts may be incorrectly identified as human-written. Figure~\ref{fig:ppl-10-WSR-1-1e-5} illustrates both the Success$\text{h}$, i.e. the success rate of recognizing the model-generated texts from human-written texts, and the corresponding text quality, under the coding rate of 10 tokens per bit.

% Figure environment removed

It's worth noting that Figure~\ref{fig:ppl-10-WSR-1-1e-5} bears similarities to Figure~\ref{fig:cp} from the Copy-Paste Attack section~(Section~\ref{sec: copy-paste attack}), given that they both involve a threshold of  $1-10^{-5}$.



\section{Deep Analysis}
\label{sec: analyze}
In this section, we will discuss the efficiency of Balance-Marking and explore the influence of specific hyper-parameters Balance-Marking on both performance and efficiency.

\subsection{Efficiency of Balance-Marking}

% As stated in Section~\ref{sec: experiment}, Balance-Marking can generally outperform Vanilla CTWL, due to its utilization of $LM_{proxy}$. $LM_{proxy}$ can provide information of the probability of the preceding token, helping maximize $L(m,\mathbf x^{prompt}, \mathbf{t}_{:(l-1)})$ during the design of $P_{w}$\wang{may need to change the symbol P}. However, introducing $LM_{proxy}$ and the additional calculation of $V_{m,\mathbf{t}_{:(l-1)}}$ add up to the computational cost in the encoding and decoding procedure, as shown in Table~\ref{tab:main_efficieny}.
Referring back to Section~\ref{sec: experiment}, it is established that Balance-Marking generally outperforms Vanilla-Marking. This superior performance is attributable to the application of $LM_{proxy}$, which provides information about the probability of a token's predecessor, thereby aiding the maximization of $L(m,\mathbf x^{prompt}, \mathbf{t}_{:(l-1)})$ during the design of $P_{w}$. However, the integration of $LM_{proxy}$ and the additional computation of $V_{m,\mathbf{t}_{:(l-1)}}$ increase the computational costs of the encoding and decoding process, as reflected in Table~\ref{tab:main_efficieny}.

\begin{table}[t]
    \centering
    \caption{Encoding and decoding time for processing a 200-token sentence on a single NVIDIA TITAN RTX GPU. Balance-Marking takes longer for its enhanced performance}
    \begin{tabular}{c|c|c|c}
        \toprule
        \textbf{Method} &\textbf{No watermarking} & \textbf{Vanilla-Marking} & \textbf{Balance-Marking} \\
        \midrule
        Encoding Time (s) & 4.83 & 4.84 & 9.50 \\
        \midrule
        Decoding Time (s) & N/A & 0.94 & 2.97 \\
        \bottomrule
    \end{tabular}
    \label{tab:main_efficieny}
\end{table}


% only draft!
% We use $x_{l-L_{prefix}-1:(l-1)}$ to calculate $P_{w}$\wang{there should be revised according to the change in section5-Method}, so for each $l$, we can not cache the hidden states for the $x_i$ as in generation, so, although we use a smaller LM, the cost is roughly equal to that of the LLM when encoding, and the time cost in decoding is also much. Still, notice the LLM use here is a OPT-1.3B model, which is small compared to the giant LLMs used in real-world. For a LLM like gpt-3.5, the extra cost introduced by Balance-Marking is likely to be ignorable.
% The calculation of $P_{w}$ employs $P_{LM_{proxy}}(v|x_{l-L_{prefix}-1:(l-1)})$. For each 200-token sentence, about 200 $P_{LM_{proxy}}(v|x_{l-L_{prefix}-1:(l-1)})$ need to be calculated. In text generation, there are also about 200 $P_{LLM}(v|x_{:(l-1)})$ to be calculated, but by caching the hidden states of $x_{:(l-1)}$, the generation can be sped up. However, each $P_{LM_{proxy}}(v|x_{l-L_{prefix}-1:(l-1)})$ have different prefixs, so that we cannot cache hidden states for reuse. Therefore, even though a smaller LM GPT2~(124M) is used, the cost aligns closely with that of the LLM OPT-1.3B during encoding. Nevertheless, it's worth noting that the OPT-1.3B model used here is still very small compared to the large-scale LLMs used in practice like gpt-3.5. For those large-scale models, the additional cost implicated by Balance-Marking is expected to be negligible.

The computation of $P_{w}$ involves $P_{LM_{proxy}}(v|\mathbf{t}_{(l-1-L_{prefix}):(l-1)})$. In handling each 200-token sentence, approximately 200 instances of $P_{LM_{proxy}}(v|\mathbf{t}_{(l-1-L_{prefix}):(l-1)})$ need to be calculated.\footnote{During normal text generation, there are also about 200 instances of $P_{LLM}(v|\mathbf{x}^{prompt},\mathbf{t}_{:(l-1)})$ requiring calculation, but caching the hidden states of $\mathbf{t}_{:(l-1)}$ can expedite the generation process.} As such, despite utilizing a comparatively smaller $LM_{proxy}$, GPT2~(124M), the extra cost of watermarking aligns closely with the text generation cost of the $LLM$ OPT-1.3B. However, it is noteworthy that the OPT-1.3B model used here is minor in scale compared to larger LLMs used in practical cases such as ChatGPT~\citep{chatgpt}. Hence, the additional cost introduced by Balance-Marking is anticipated to be negligible for these large-scale models.


\subsection{The impact of the proxy language model $LM_{proxy}$}
\label{sec: ablation_lm}
% In Balance-Marking, we use $P_{LM_{proxy}}(v|x_{l-L_{prefix}-1:(l-1)})$ to estimate $P_LLM(v|x_{:(l-1)})$. It seems plausible that using a better $LM_{proxy}$ can provide more precise estimation of $P_LLM(v|x_{:(l-1)})$, thus resulting in better performance. Experiments detailed in Figure~\ref{fig: ablation_figs} verify the hypothesis. Interestingly, GPT2-Large has better performance than GPT2-XL, indicating that such promotion may have an upper limit.
In our Balance-Marking method, we employ $LM_{proxy}$ to generate an estimation for $P_{LLM}(v|\mathbf{t}_{:(l-1)})$. It can be reasonably hypothesized that an enhanced $LM_{proxy}$ could offer a more accurate estimation of $P_{LLM}(v|\mathbf{t}_{:(l-1)})$, thereby leading to superior performance. Experiments detailed in Figure~\ref{fig: ablation_figs} support this hypothesis.\footnote{Here, we run experiments with $\delta\in\{1.0, 1.2, 1.5, 2.0, 3.0\}$. Section~\ref{sec: The effect of $A$},~\ref{sec: The impact of L_prefix}, and~\ref{sec: The impact of |M|} also use the same $\delta$s.} However, GPT2-Large illustrates better performance in comparison to GPT2-XL, suggesting that the improvement might have a certain ceiling.

% Figure environment removed

% Regrettably, the computational cost also rises with a larger $LM_{proxy}$, as shown in Table~\ref{tab:lm_pub_efficieny}. In practical usage, one may need to balance between time cost and watermark quality.
Unfortunately, as the size of $LM_{proxy}$ increases, there follows a consequential surge in computational cost, clearly demonstrated in Table~\ref{tab:lm_pub_efficieny}. For practical applications, it becomes necessary to establish a balance between time expenditure and the quality of the watermark.

% \begin{table}[t]
%     \centering
%     \begin{tabular}{c|c|c|c|c}
%         \toprule
%         $\boldsymbol{LM_{proxy}}$ & \textbf{GPT2~(124M)} & \textbf{GPT2-Medium~(355M)} & \textbf{GPT2-Larg~(774M)} & \textbf{GPT2-XL~(1.5B)} \\
%         \midrule
%         Encoding Time & 9.50 & 11.69 & 14.08 & 16.38 \\
%         \midrule
%         Decoding Time & 2.21 & 2.37 & 2.57 & 2.83 \\
%         \bottomrule
%     \end{tabular}
%     \caption{The increase in $LM_{proxy}$ size escalates the computational cost during both encoding and decoding.}
%     \label{tab:lm_pub_efficieny}
% \end{table}
\begin{table}[t]
    \centering
    \caption{Growing $LM_{proxy}$ size amplifies the computational cost during both encoding and decoding processes.}
    \begin{tabular}{c|c|c|c|c}
        \toprule
         $\boldsymbol{LM_{proxy}}$ & \makecell{\textbf{GPT2}\\(124M)} & \makecell{\textbf{GPT2-Medium}\\(355M)} & \makecell{\textbf{GPT2-Large}\\(774M)} & \makecell{\textbf{GPT2-XL}\\(1.5B)} \\
        \midrule
        Encoding Time~(s) & 9.50 & 11.69 & 14.08 & 16.38 \\
        \midrule
        Decoding Time~(s) & 2.97 & 3.09 & 3.43 & 3.53 \\
        \bottomrule
    \end{tabular}
    \label{tab:lm_pub_efficieny}
\end{table}




\subsection{The impact of the pre-mapping space size $A$}
\label{sec: The effect of $A$}
% The hyper-parameter $A$ introduced in $LM_{proxy}$ aims to reduce the number of $V_{m,\mathbf{t}_{:(l-1)}}$s that need to be computed. A smaller $A$ means lower computation costs during decoding, as shown in Figure~\ref{tab:A_efficieny} (encoding time is roughly the same, since we only needs to calculate one $V_{m,\mathbf{t}_{:(l-1)}}$ when encoding the message $m$ into text).
The purpose of introducing hyper-parameter $A$ in Balance-Marking is to reduce the number of $V_{m,\mathbf{t}_{:(l-1)}}$ to be computed. A lower value of $A$ results in lower computational expenses during decoding, as shown in Table~\ref{tab:A_efficieny}. On the other hand, the cost of encoding remains relatively constant because only a single message $m$ requires the computation of $V_{m,\mathbf{t}_{:(l-1)}}$ during encoding.

\begin{table}[t]
    \centering
    \caption{Investigation into the impact of $A$ on watermark efficiency. A larger $A$ value generally results in a longer decoding time.}
    \begin{tabular}{c|c|c|c|c|c}
        \toprule
        $\boldsymbol{A}$ & \textbf{25} & \textbf{50} & \textbf{100} & \textbf{150} & \textbf{250} \\
        \midrule
        Encoding Time~(s) & 9.39 & 9.48 & 9.50 & 9.22 & 9.37 \\
        \midrule
        Decoding Time~(s) & 1.89 & 2.27 & 2.97 & 4.49 & 6.24 \\
        \bottomrule
    \end{tabular}
    \label{tab:A_efficieny}
\end{table}

To explore the impact of $A$ on watermarking quality, we conducted additional experiments as demonstrated in Figure~\ref{fig: ablation_A}. Although a larger $A$ generally leads to enhanced performance, there exist notable exceptions, such as when $A=150$, where the performance is lower than when $A=100$.

To strike a balance between performance and computational efficiency, we elected to use $A=100$ for our main experiments in Section~\ref{sec: main_results}.

% Figure environment removed



% Figure environment removed

\begin{table}[t]
    \centering
    \caption{Investigation into the impact of $L_{prefix}$ on watermark efficiency. $L_{prefix}$ has a modest impact on watermark efficiency.}
    \begin{tabular}{c|c|c|c|c|c}
        \toprule
        $\boldsymbol{L_{prefix}}$ & \textbf{5} & \textbf{7} & \textbf{10} & \textbf{15} & \textbf{20} \\
        \midrule
        Encoding Time~(s) & 9.52 & 9.03 & 9.50 & 9.29 & 9.10 \\
        \midrule
        Decoding Time~(s) & 3.01 & 3.05 & 2.97 & 2.91 & 2.86 \\
        \bottomrule
    \end{tabular}
    \label{tab: prefix_efficieny}
\end{table}

\begin{table}[t]
    \centering
    \caption{Investigation into the impact of $|\mathcal{M}|$ on watermark efficiency. The size of $\mathcal{M}$ has a modest impact on watermark efficiency.}
    \begin{tabular}{c|c|c|c|c}
        \toprule
        $\boldsymbol{|\mathcal{M}|}$ & $\boldsymbol{2^5}$ & $\boldsymbol{2^7}$ & $\boldsymbol{2^{10}}$ & $\boldsymbol{2^{20}}$ \\
        \midrule
        Encoding Time~(s) & 9.89 & 10.02 & 9.83 & 10.05 \\
        \midrule
        Decoding Time~(s) & 2.37 & 2.34 & 2.36 & 3.13 \\
        \bottomrule
    \end{tabular}
    \label{tab:M_efficieny}
\end{table}

% Figure environment removed

\subsection{The impact of the truncation length $L_{prefix}$}
\label{sec: The impact of L_prefix}
The parameter $L_{prefix}$, which is part of Eq.~(\ref{eq: V_m condition proxy}), impacts the quality of the watermark in two significant ways. (1) A longer $\mathbf{t}_{(l-1- L_{prefix}):(l-1)}$ in $P_{LM_{proxy}}(v| \mathbf{t}_{(l-1- L_{prefix}):(l-1)})$ can potentially provide a superior approximation of $P_{LLM}(v|\mathbf x^{prompt},\mathbf{t}_{:(l-1)})$. However, (2) an increased $\mathbf{t}_{(l-1- L_{prefix}):(l-1)}$ length will reduce the number of effective tokens in $\mathbf t$ available for encoding and decoding. This reduction occurs because  $\mathbf t_{:L_{prefix}}$ lacks sufficient preceding words to form a $\mathbf{t}_{(l-1- L_{prefix}):(l-1)}$, which consequently results in their exclusion from encoding and decoding. Figure~\ref{fig: prefix} illustrates the influence of $L_{prefix}$. Generally speaking, a relatively low $L_{prefix}$ value can degrade the watermark quality, while a moderate $L_{prefix}$ like 10 achieves similar performance to larger values such as 15 or 20.


The time cost for encoding and decoding remains relatively consistent across varying $L_{prefix}$ values, as demonstrated in Table~\ref{tab: prefix_efficieny}. Interestingly, a larger $L_{prefix}$ might lead to a decrease in time cost, aligning with the aforementioned explanation that a more extended $L_{prefix}$ results in a shorter effective $\mathbf t$ utilized in the encoding and decoding stages.

\subsection{The impact of the message space size $|\mathcal{M}|$}
\label{sec: The impact of |M|}
% With a fixed payload information coding rate, a larger size of $|\mathcal{M}|$ means more tokens for a single message. Consider the situation that parts of the text are low-entropy areas where watermark is difficult to apply, with more tokens, it is unlikely that all text for a message is of low-entropy, thus providing high-entropy parts for the message to be embedded. Also, suppose $|\mathcal{M}|$ is small, then a piece of 20-bit information may be split to 4 pieces of 5-bit information to be encoded respectively. If any of 4 pieces of 5-bit information fails to be encoded, the whole 20-bit information fails to be encoded. In other words, the error may be accumulated to a high degree. Figure~\ref{fig: ablation_message_code_len} verifies that a larger $\mathcal{M}$ corresponds to better watermark quality. Here, we ask the model to generate 210 tokens, since for $|\mathcal{M}| = 2^7$ and a coding rate of 7 token per bit, one message corresponds to 70 tokens.
Increasing the size of $|\mathcal{M}|$ under a fixed payload information coding rate results in a larger number of tokens available for embedding a single message. In text watermarking scenarios, certain parts of the text often exhibit low entropy, thereby challenging the watermark encoding process~\citep{watermark_llm}. However, an increase in the number of tokens mitigates this problem, as it improves the likelihood of having high-entropy sections where the message can be effectively embedded. Moreover, let's consider an example where $|\mathcal{M}|$ is relatively small. In such a case, a piece of information of 20 bits might need to be divided into four separate chunks of 5 bits each to be encoded. If encoding fails for any of these 5-bit information segments, the encoding of the entire 20-bit information fails. This phenomenon potentially results in a significant accumulation of errors. 

Figure~\ref{fig: ablation_message_code_len} validates the analysis above by demonstrating a strong correlation between larger $|\mathcal{M}|$ and better watermark quality. Here, the experiment utilizes the $LLM$ to generate 210 tokens for encoding and decoding, since when $|\mathcal{M}| = 2^7$ and the coding rate is 10 tokens per bit, one message corresponds to 70 tokens.





% Interstingly, the encoding and decoding time are similar when $|M|$ increases. This indicates the calculation of $P_{LM_{proxy}}(v|x_{(l-1-L_{prefix}):(l-1)}$ and $V_{m,\mathbf{t}_{:(l-1)}}$ takes up most of the time (note here the number of $V_{m,\mathbf{t}_{:(l-1)}}$ needing computation depends on $A$ instead of $m$). However, $|\mathcal{M}|$ can not be enlarged limitlessly. Suppose $|\mathcal{M}|$ is $2^{40}$, it is nearly impossible to calculate $P_w(\mathbf t| m')$ in Eq.~(\ref{eq: decoding messages}) for all messages $m'\in\mathcal{M}$ during decoding. 
Table~\ref{tab:M_efficieny} shows the time costs of the encoding and decoding processes when $|\mathcal{M}|$ increases. The time expenditure for encoding remains relatively stable, since there is only one message for which the calculation of $P_w$ is necessary. Contrastingly, the decoding process experiences a noticeable increase in time cost when $|\mathcal{M}|$ rises up to $2^{20}$. Thus, while an increase in $|\mathcal{M}|$ steadily improves watermark quality, the size of $\mathcal{M}$ can not be increased unlimitedly.\footnote{For instance, if $|\mathcal{M}|$ equals $2^{40}$, it becomes exceedingly difficult to calculate $P_w(\mathbf t| m')$ in Eq.~(\ref{eq: decoding messages}) for all messages $m'\in\mathcal{M}$ during the decoding process.}



\section{Potential Application Scenes of Codable LLM Watermarking}
\label{sec: scenes}
In this section, we analyze some potential application scenarios of codable LLM watermarking, and examine how our method adjusts the proxy-LM to adapt to the varying demands for watermarking techniques in different application scenarios.

\subsection{Corporate Intellectual Property Protection}
For service providers based on LLMs, generating texts with watermarks containing information related to the model, service, request, or user can effectively ensure that the generated texts can be traced and identified, thereby preventing the model from being used unreasonably or without authorization. Service providers can flexibly choose and combine the information to be included in the watermark to better protect their intellectual property. 
In this scenario, as the owner of LLMs, the service provider can choose to use the large model itself as a proxy-LM to minimize the impact of adding watermarks on the quality of the text, or prepare a small model similar to the large one to accelerate inference through methods like distillation, quantization, or pruning.



\subsection{User-level Copyright Protection}
The discussion on the copyright of text generated by LLMs is also an interesting topic, as users may believe that their intellectual input when writing prompts gives them (at least part of) the copyright of the generated text. In such a situation, users can choose to reach an agreement with the LLMs service provider on a customized watermark algorithm for the user self (through customizing the proxy-LM or hash function). In the encoding stage, the service provider will generate text containing a specific watermark according to the user's exclusive watermark encoding algorithm. When the user wants to prove that a piece of text comes from him- or herself, the user can request the service provider to use his or her exclusive decoding algorithm to confirm whether it contains a personal watermark. To make this more credible, an independent third-party organization similar to the patent office can take the responsibility to manage and certify these customized watermark algorithms.

\subsection{Open Watermarking Protocol}
For the public, it is desirable to have a very convenient way to identify whether a text comes from a model and which model it comes from. 
We propose an idea based on an open watermark protocol to reduce the identification problems caused by scattered and differentiated watermarking methods adopted by different service providers. 
First, the protocol selects an open-source language model (such as GPT-2) as a proxy-LM, and then determines a unified and scalable message coding system to establish a publicly available watermark encoding and decoding algorithm. 
Any service provider that joins this protocol can use the watermark encoding algorithm to inject watermarks into the texts generated by their private models by extending the message coding system. 
In this way, the public can efficiently identify all models that join the protocol using a single decoding algorithm. 
The technical support for this idea to work is that our Balance-Marking leverages both the LLMs and the proxy-LM during the encoding stage, while in the decoding stage, only the proxy-LM is needed to restore the watermark information. This makes it possible to have multiple closed-source LLMs encodings and a single public model decoding.
If as many service providers as possible join this protocol, identifying the source of the text will become an increasingly easy task, which can effectively alleviate the impact of LLM-generated texts on human community order and security.


\subsection{Relay Watermarking among Models}
Model-generated text that is actually applied is usually not generated in one step, but may go through multiple users or multiple models for processing, such as expansion, polishing, translation, paraphrasing, and so on. If we want to track the complete production process of a text, not just obtain the information of the last model processing, it is feasible to ensure that the watermark is incrementally written in a relay form among different models. As discussed in the previous subsection, this requires an open watermark protocol and a scalable information encoding system. This also requires adding a processing step to our method: first extract the watermark message from the text input to the model, mix it with the message of the new model itself, and then add the new message to the watermark of the newly generated text. In this way, we can track the complete life cycle of machine-generated text. Of course, as discussed in the previous subsection, this also requires as many LLMs service providers as possible to join the open watermark protocol.



\section{Limitations and Future Work}
\label{sec: limitation}
This is an ongoing iterative work, and we summarize the limitations of our current version and discuss future work in this section. 
(1) Firstly, the sizes of our experimental base models do not cover all model scales, so the conclusions obtained may be affected by the scaling law; we will supplement more experimental results on models of different sizes and structures in future versions. 
(2) Secondly, the datasets we evaluated were limited to the natural text domain. We will explore and construct more diverse watermarking evaluation benchmarks, including code segments, logic problems, and more fine-grained natural texts in future versions. 
(3) Furthermore, our method performs poorly when facing paraphrase attacks, which is actually a significant threat to all watermarking methods. We look forward to developing watermarking algorithms that can resist paraphrase attacks. 
(4) In addition, we will continue to focus on and improve the vital trade-offs of watermarking algorithms, such as effectiveness and efficiency, and coding rate and robustness.

\section{Conclusion}
\label{sec: conclusion}
In this work, we provide the first systematic study on the topic of Codable Text Watermarking for Large Language Models (\textbf{CTWL}), filling the research gap of integrating multi-bit information watermarks into the generation process of LLMs. 
Our contributions mainly lie in three aspects.
(1) From a research perspective, we conduct a taxonomic analysis of CTWL and provide rigorous mathematical formalization for this problem. 
(2) From an application perspective, we analyze the demand for watermark technology in diverse application scenarios of LLMs and summarize a comprehensive evaluation system for the availability of CTWL from 5 evaluation dimensions. 
(3) From an empirical perspective, we design a CTWL method Balance-Marking, which effectively ensures the balance of the probabilities of available and unavailable vocabularies by introducing a proxy language model, thereby ensuring the quality and diversity of generated text without significantly increasing computational complexity. 
Extensive experiments have shown that our method significantly outperforms the direct baseline method in the comprehensive evaluation of five dimensions, reaching a practical level of usability. 
Further analysis has revealed the underlying mechanisms of the various modules in our method.
We hope that our work can help the community better understand the CTWL issue and inspire more outstanding research in the future.



\bibliography{iclr2023_conference}
\bibliographystyle{iclr2023_conference}

\section*{Acknowledgements}
This work was supported in part by a Tencent Research Grant and National Natural Science Foundation of China (No. 62176002). Xu Sun is the corresponding author of this paper.





% no appendix for now
\newpage
\appendix

\section{Reasons for Excluding Term $\frac{1}{|\mathcal{M}|}\mathop{\sum}\nolimits_{m'\in \mathcal{M}}\mathop{\log}P_{w}(v|m',\mathbf{t}_{:(l-1)})$ from encoding and substituting $ \log P_w(v|m,\mathbf{t}_{:(l-1)})$ with $\log \hat{P}_w(v|m,\mathbf{t}_{:(l-1)})$ during decoding}
\label{appendix: reasons for omitting}


\subsection{Excluding Term $\frac{1}{|\mathcal{M}|}\mathop{\sum}\nolimits_{m'\in \mathcal{M}}\mathop{\log}P_{w}(v|m',\mathbf{t}_{:(l-1)})$ from encoding}
\label{appendix:omit1}
The randomness present within the design of the message function $P_w$ allows us to interpret expressions of $\log P_{w}(v|m',\mathbf{t}_{:(l-1)})$s in $\frac{1}{|\mathcal{M}|}\mathop{\sum}\nolimits_{m'\in \mathcal{M}}\mathop{\log}P_{w}(v|m',\mathbf{t}_{:(l-1)})$ as independent and identically distributed (i.i.d.) random variables. Consequently, via the law of large numbers, the term $\frac{1}{|\mathcal{M}|}\mathop{\sum}\nolimits_{m'\in \mathcal{M}}\mathop{\log}P_{w}(v|m',\mathbf{t}_{:(l-1)})$ remains approximately constant.

As a practical test of our hypothesis, we randomly selected 100 sequences of $\mathbf{t}_{:(l-1)}$ from human-written texts (specifically, the news-like subset of the C4 dataset~\citep{2019t5}) as well as watermarked texts. Afterward, for each $\mathbf{t}_{:(l-1)}$, we randomly picked 100 tokens $v$ from the vocabulary to calculate the standard deviation of $\frac{1}{|\mathcal{M}|}\mathop{\sum}\limits_{m'\in \mathcal{M}}\log P_{w}(v|m',\mathbf{t}_{:(l-1)})$ across $v$.\footnote{Since the solution $t_l$ depends on the model logit and message logit of $v$ under a given $\mathbf{t}_{:(l-1)}$, it's enough to concentrate on the variations across $v$.}
%\footnote{$\mathop{\log}\mathop{\sum}\limits_v \hat{P}_w(v|m,\mathbf{t}_{:(l-1)})$ in $\frac{1}{|\mathcal{M}|}\mathop{\sum}\nolimits_{m'\in \mathcal{M}}\mathop{\log}P_{w}(t_{l}|m',\mathbf{t}_{:(l-1)})$ for Vanilla-Marking is difficult to compute, since we have to compute $\mathop{\log}\mathop{\sum}\limits_v \hat{P}_w(v|m,\mathbf{t}_{:(l-1)})$ for $|\mathcal{M}|$ times. Since Appendix~\ref{appendix:omit2} shows that $\mathop{\log}\mathop{\sum}\limits_v \hat{P}_w(v|m,\mathbf{t}_{:(l-1)})$ is nearly a constant, when  we use the mean of $\mathop{\log}\mathop{\sum}\limits_v \hat{P}_w(v|m,\mathbf{t}_{:(l-1)})$ in Eq.~(\ref{eq:18}), instead of calculating $\mathop{\log}\mathop{\sum}\limits_v \hat{P}_w(v|m,\mathbf{t}_{:(l-1)})$ for each $m$. For the standard deviation, we use the sum of the deviation of $\frac{1}{|\mathcal{M}|}\mathop{\sum}\nolimits_{m'\in \mathcal{M}}\mathop{\log}\hat P_{w}(t_{l}|m',\mathbf{t}_{:(l-1)})$ and the deviation of $\mathop{\log}\mathop{\sum}\limits_v \hat{P}_w(v|m,\mathbf{t}_{:(l-1)})$ as an estimation.} 
We report the standard deviation and mean across $v$ (averaged over 100 instances of $\mathbf{t}_{:(l-1)}$s) in Table~\ref{tab:omit1}.  Given the small standard deviation across the vocabulary, it's appropriate to exclude it in Algorithm~\ref{algo: encoding algorithm for general P}.

\begin{table}[t]
    \centering
    \caption{$\frac{1}
{|\mathcal{M}|}\mathop{\sum}\limits_{m'\in \mathcal{M}}\mathop{\log}P_{w}(v|m',\mathbf{t}_{:(l-1)})$ on human-written texts and watermarked texts. The numbers are the mean $\pm$ the standard deviation across $v$.}
    \begin{tabular}{c|c|c}
        \toprule
        &\textbf{Human-Written Texts} & \textbf{Watermarked Texts} \\
        \midrule
        Vanilla-Marking & -10.95 $\pm$ 0.0005 &  -10.95 $\pm$ 0.0005 \\
        \midrule
        Balance-Marking & -10.93 $\pm$ 0.0461 & -10.93 $\pm$ 0.0457 \\
        \bottomrule
    \end{tabular}
    \label{tab:omit1}
\end{table}

\subsection{substituting $ \log P_w(v|m,\mathbf{t}_{:(l-1)})$ with $\log \hat{P}_w(v|m,\mathbf{t}_{:(l-1)})$ during decoding}
\label{appendix:omit2}
Consider that 
\begin{equation}
\label{eq:18}
    \log P_w(v|m,\mathbf{t}_{:(l-1)}) = \log \hat P_w(v|m,\mathbf{t}_{:(l-1)}) - \mathop{\log}\mathop{\sum}\limits_v \hat{P}_w(v|m,\mathbf{t}_{:(l-1)}),
\end{equation}
in a manner akin to Appendix~\ref{appendix:omit1}, we hypothesize that $\mathop{\log}\mathop{\sum}\limits_v \hat{P}_w(v|m,\mathbf{t}_{:(l-1)})$ may remain nearly constant. If so, the magnitude of $P_w(v|m,\mathbf{t}_{:(l-1)})$ can be represented by the term $\hat{P}_w(v|m,\mathbf{t}_{:(l-1)})$. 

As Appendix~\ref{appendix:omit1}, the term $\log \hat P_w(v|m,\mathbf{t}_{:(l-1)})$ can be interpreted as i.i.d. random variables, hence by invoking the law of large numbers, for any $\epsilon$, we establish:
\begin{equation}
   \label{eq:19}
    \lim _{|\mathcal{V}| \rightarrow \infty} P\left(\left|\frac{\mathop{\sum}\limits_v \hat{P}_w(v|m,\mathbf{t}_{:(l-1)})}{|\mathcal{V}|}-\mu\right|>\varepsilon\right)=0,
\end{equation}
with $\mathcal{V}$ representing the vocabulary and $\mu$ is the mean.

According to the mean value theorem, a $c$ exists between $\mathop{\sum}\limits_v \hat{P}_w(v|m,\mathbf{t}_{:(l-1)})$ and $\mu|\mathcal{V}|$ such that
\begin{equation}
    \frac{\mathop{\log}\mathop{\sum}\limits_v \hat{P}_w(v|m,\mathbf{t}_{:(l-1)})  - \log (\mu|\mathcal{V}|)}{\mathop{\sum}\limits_v \hat{P}_w(v|m,\mathbf{t}_{:(l-1)}) - \mu |\mathcal{V}|} = \frac{1}{c} .
\end{equation}

Through empirical experimentation,\footnote{We use the same experimental settings as the experiments shown in Table~\ref{tab:omit2}.} it is observed that $\log\mathop{\sum}\limits_v \hat{P}_w(v|m,\mathbf{t}_{:(l-1)})$ exceeds 10.5. Given that the size of vocabulary $|\mathcal{V}|$ is 50257, it implies $c>e^{10.5}>  \frac{1}{2}|\mathcal{V}|$, leading to
\begin{equation}
\label{eq:21}
    |\mathop{\log}\mathop{\sum}\limits_v \hat{P}_w(v|m,\mathbf{t}_{:(l-1)})  - \log \mu|\mathcal{V}||< 2|\mathop{\sum}\limits_v \frac{\hat{P}_w(v|m,\mathbf{t}_{:(l-1)}}{|\mathcal{V}|}) - \mu|.
\end{equation}

Merging Eq.~(\ref{eq:19}) and Eq.~(\ref{eq:21}) confirms that, with high certainty, , $\mathop{\log}\mathop{\sum}\limits_v \hat{P}_w(v|m,\mathbf{t}_{:(l-1)})$ approximates a constant.

To validate our hypothesis, we  randomly select 100 $\mathbf{t}_{:(l-1)}$ as above, and randomly pick 100 $m$ from $\mathcal{M}$. The standard deviation and mean of $\mathop{\log}\mathop{\sum}\limits_v \hat{P}_w(v|m,\mathbf{t}_{:(l-1)})$  are presented in Table~\ref{tab:omit2}.
The deviation of $\mathop{\log}\mathop{\sum}\limits_v \hat{P}_w(v|m,\mathbf{t}_{:(l-1)})$ is higher in Balance-Marking than in Vanilla-Marking, due to the likelihood that  $\log \hat P_w(v|m,\mathbf{t}_{:(l-1)})$ may not be precisely i.i.d for Balance-Marking. Nevertheless, this modest variation still allows us to exclude $\mathop{\log}\mathop{\sum}\limits_v \hat{P}_w(v|m,\mathbf{t}_{:(l-1)})$ for the sake of swifter computation.

\begin{table}[t]
    \centering
    \caption{$\mathop{\log}\mathop{\sum}\limits_v \hat{P}_w(v|m,\mathbf{t}_{:(l-1)})$ on human-written texts and watermarked texts. The numbers are the average $\pm$ the standard deviation across $(\mathbf{t}_{:(l-1)}, m)$ .}
    \begin{tabular}{c|c|c|c}
        \toprule
        &\textbf{Human-Written Texts} & \textbf{Watermarked Texts} \\
        \midrule
        Vanilla-Marking & 11.45 $\pm$ 0.0019 & 11.45 $\pm$ 0.0022  \\
        \midrule
        Balance-Marking & 11.42 $\pm$ 0.1797 &  11.41 $\pm$ 0.2266 \\
        \bottomrule
    \end{tabular}
    \label{tab:omit2}
\end{table}




\end{document}
