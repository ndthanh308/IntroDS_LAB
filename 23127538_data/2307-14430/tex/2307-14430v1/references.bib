@misc{wei2022emergent,
	title        = {Emergent Abilities of Large Language Models},
	author       = {Jason Wei and Yi Tay and Rishi Bommasani and Colin Raffel and Barret Zoph and Sebastian Borgeaud and Dani Yogatama and Maarten Bosma and Denny Zhou and Donald Metzler and Ed H. Chi and Tatsunori Hashimoto and Oriol Vinyals and Percy Liang and Jeff Dean and William Fedus},
	year         = 2022,
	eprint       = {2206.07682},
	archiveprefix = {arXiv},
	primaryclass = {cs.CL}
}

@misc{alpaca,
	title        = {Stanford Alpaca: An Instruction-following LLaMA model},
	author       = {Rohan Taori and Ishaan Gulrajani and Tianyi Zhang and Yann Dubois and Xuechen Li and Carlos Guestrin and Percy Liang and Tatsunori B. Hashimoto},
	year         = 2023,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/tatsu-lab/stanford_alpaca}}
}


@misc{ouyang2022training,
	title        = {Training language models to follow instructions with human feedback},
	author       = {Long Ouyang and Jeff Wu and Xu Jiang and Diogo Almeida and Carroll L. Wainwright and Pamela Mishkin and Chong Zhang and Sandhini Agarwal and Katarina Slama and Alex Ray and John Schulman and Jacob Hilton and Fraser Kelton and Luke Miller and Maddie Simens and Amanda Askell and Peter Welinder and Paul Christiano and Jan Leike and Ryan Lowe},
	year         = 2022,
	eprint       = {2203.02155},
	archiveprefix = {arXiv},
	primaryclass = {cs.CL}
}
@misc{wang2022selfinstruct,
	title        = {Self-Instruct: Aligning Language Model with Self Generated Instructions},
	author       = {Yizhong Wang and Yeganeh Kordi and Swaroop Mishra and Alisa Liu and Noah A. Smith and Daniel Khashabi and Hannaneh Hajishirzi},
	year         = 2022,
	eprint       = {2212.10560},
	archiveprefix = {arXiv},
	primaryclass = {cs.CL}
}
@misc{wang2022supernaturalinstructions,
	title        = {Super-NaturalInstructions: Generalization via Declarative Instructions on 1600+ NLP Tasks},
	author       = {Yizhong Wang and Swaroop Mishra and others},
	year         = 2022,
	eprint       = {2204.07705},
	archiveprefix = {arXiv},
	primaryclass = {cs.CL}
}


@misc{zha2023datacentric,
	title        = {Data-centric Artificial Intelligence: A Survey},
	author       = {Daochen Zha and Zaid Pervaiz Bhat and Kwei-Herng Lai and Fan Yang and Zhimeng Jiang and Shaochen Zhong and Xia Hu},
	year         = 2023,
	eprint       = {2303.10158},
	archiveprefix = {arXiv},
	primaryclass = {cs.LG}
}


@book{mitchell1997machine,
	title        = {Machine Learning},
	author       = {Mitchell, T.M.},
	year         = 1997,
	publisher    = {McGraw-Hill},
	series       = {McGraw-Hill International Editions},
	isbn         = 9780071154673,
	url          = {https://books.google.com/books?id=EoYBngEACAAJ},
	lccn         = 97007692
}


@article{gagne1962acquisition,
	title        = {The acquisition of knowledge.},
	author       = {Gagne, Robert M},
	year         = 1962,
	journal      = {Psychological review},
	publisher    = {American Psychological Association},
	volume       = 69,
	number       = 4,
	pages        = 355
}


@article{white1973research,
	title        = {Research into learning hierarchies},
	author       = {White, Richard T},
	year         = 1973,
	journal      = {Review of Educational Research},
	publisher    = {Sage Publications Sage CA: Thousand Oaks, CA},
	volume       = 43,
	number       = 3,
	pages        = {361--375}
}

@misc{zhang2022unveiling,
	title        = {Unveiling Transformers with LEGO: a synthetic reasoning task},
	author       = {Yi Zhang and Arturs Backurs and Sébastien Bubeck and Ronen Eldan and Suriya Gunasekar and Tal Wagner},
	year         = 2022,
	eprint       = {2206.04301},
	archiveprefix = {arXiv},
	primaryclass = {cs.LG}
}


@inproceedings{kitaev-etal-2019-multilingual,
	title        = {Multilingual Constituency Parsing with Self-Attention and Pre-Training},
	author       = {Kitaev, Nikita  and Cao, Steven  and Klein, Dan},
	year         = 2019,
	month        = jul,
	booktitle    = {Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics},
	publisher    = {Association for Computational Linguistics},
	address      = {Florence, Italy},
	pages        = {3499--3505},
	doi          = {10.18653/v1/P19-1340},
	url          = {https://www.aclweb.org/anthology/P19-1340}
}
@inproceedings{kitaev-klein-2018-constituency,
	title        = {Constituency Parsing with a Self-Attentive Encoder},
	author       = {Kitaev, Nikita  and Klein, Dan},
	year         = 2018,
	month        = jul,
	booktitle    = {Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
	publisher    = {Association for Computational Linguistics},
	address      = {Melbourne, Australia},
	pages        = {2676--2686},
	doi          = {10.18653/v1/P18-1249},
	url          = {https://www.aclweb.org/anthology/P18-1249}
}


@software{gpt-neo,
	title        = {{GPT-Neo: Large Scale Autoregressive Language Modeling with Mesh-Tensorflow}},
	author       = {Black, Sid and Leo, Gao and Wang, Phil and Leahy, Connor and Biderman, Stella},
	year         = 2021,
	month        = mar,
	publisher    = {Zenodo},
	doi          = {10.5281/zenodo.5297715},
	url          = {https://doi.org/10.5281/zenodo.5297715},
	note         = {{If you use this software, please cite it using these metadata.}},
	version      = {1.0}
}
@article{gao2020pile,
	title        = {The Pile: An 800GB Dataset of Diverse Text for Language Modeling},
	author       = {Gao, Leo and Biderman, Stella and Black, Sid and Golding, Laurence and Hoppe, Travis and Foster, Charles and Phang, Jason and He, Horace and Thite, Anish and Nabeshima, Noa and others},
	year         = 2020,
	journal      = {arXiv preprint arXiv:2101.00027}
}


@misc{hendersonkrass2022pileoflaw,
	title        = {Pile of Law: Learning Responsible Data Filtering from the Law and a 256GB Open-Source Legal Dataset},
	author       = {Henderson*, Peter and Krass*, Mark S. and Zheng, Lucia and Guha, Neel and Manning, Christopher D. and Jurafsky, Dan and Ho, Daniel E.},
	year         = 2022,
	publisher    = {arXiv},
	url          = {https://arxiv.org/abs/2207.00220}
}


@misc{redpajama,
  title = {RedPajama-Data: An Open Source Recipe to Reproduce LLaMA training dataset},
    year = 2023,
    url = {https://github.com/togethercomputer/RedPajama-Data},
    author = {Together}
}


@misc{mpt,
  title = {Introducing MPT-7B: A New Standard for Open-Source, Commercially Usable LLMs},
    year = 2023,
    url = {https://www.mosaicml.com/blog/mpt-7b},
    author = {MosaicML}
}


@techreport{palm2techreport,
	title        = {Palm2 Technical Report},
	author       = {{Google}},
	year         = 2023,
	url          = {https://ai.google/static/documents/palm2techreport.pdf}
}


@article{lee2022deduplicating,
	title        = {Deduplicating Training Data Makes Language Models Better},
	author       = {Lee, Katherine and Ippolito, Daphne and Nystrom, Andrew and Zhang, Chiyuan and Eck, Douglas and Callison-Burch, Chris and Carlini, Nicholas},
	year         = 2022,
	journal      = {Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
	publisher    = {Association for Computational Linguistics},
	doi          = {10.18653/v1/2022.acl-long.577},
	url          = {http://dx.doi.org/10.18653/v1/2022.acl-long.577}
}


@misc{touvron2023llama,
	title        = {LLaMA: Open and Efficient Foundation Language Models},
	author       = {Hugo Touvron and Thibaut Lavril and Gautier Izacard and Xavier Martinet and Marie-Anne Lachaux and Timothée Lacroix and Baptiste Rozière and Naman Goyal and Eric Hambro and Faisal Azhar and Aurelien Rodriguez and Armand Joulin and Edouard Grave and Guillaume Lample},
	year         = 2023,
	eprint       = {2302.13971},
	archiveprefix = {arXiv},
	primaryclass = {cs.CL}
}


@article{nemirovskij1983problem,
	title        = {Problem complexity and method efficiency in optimization},
	author       = {Nemirovskij, Arkadij Semenovi{\v{c}} and Yudin, David Borisovich},
	year         = 1983,
	publisher    = {Wiley-Interscience}
}


@article{soviany2022curriculum,
	title        = {Curriculum Learning: A Survey},
	author       = {Soviany, Petru and Ionescu, Radu Tudor and Rota, Paolo and Sebe, Nicu},
	year         = 2022,
	month        = {Apr},
	journal      = {International Journal of Computer Vision},
	publisher    = {Springer Science and Business Media LLC},
	volume       = 130,
	number       = 6,
	pages        = {1526–1565},
	doi          = {10.1007/s11263-022-01611-x},
	issn         = {1573-1405},
	url          = {http://dx.doi.org/10.1007/s11263-022-01611-x}
}

@misc{wu2020curricula,
	title        = {When Do Curricula Work?},
	author       = {Xiaoxia Wu and Ethan Dyer and Behnam Neyshabur},
	year         = 2020,
	eprint       = {2012.03107},
	archiveprefix = {arXiv},
	primaryclass = {cs.LG}
}


@inproceedings{bengio2009curriculum,
	title        = {Curriculum learning},
	author       = {Bengio, Yoshua and Louradour, J{\'e}r{\^o}me and Collobert, Ronan and Weston, Jason},
	year         = 2009,
	booktitle    = {Proceedings of the 26th annual international conference on machine learning},
	pages        = {41--48}
}


@misc{stevenson2022putting,
	title        = {Putting GPT-3's Creativity to the (Alternative Uses) Test},
	author       = {Claire Stevenson and Iris Smal and Matthijs Baas and Raoul Grasman and Han van der Maas},
	year         = 2022,
	eprint       = {2206.08932},
	archiveprefix = {arXiv},
	primaryclass = {cs.AI}
}


@misc{chen2021evaluating,
	title        = {Evaluating Large Language Models Trained on Code},
	author       = {Mark Chen and Jerry Tworek and others},
	year         = 2021,
	eprint       = {2107.03374},
	archiveprefix = {arXiv},
	primaryclass = {cs.LG}
}

@article{brown2020language,
	title        = {Language Models are Few-Shot Learners},
	author       = {Brown, Tom B. and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
	year         = 2020,
	journal      = {arXiv preprint arXiv:2005.14165}
}


@misc{paul2021deep,
	title        = {Deep Learning on a Data Diet: Finding Important Examples Early in Training},
	author       = {Mansheej Paul and Surya Ganguli and Gintare Karolina Dziugaite},
	year         = 2021,
	eprint       = {2107.07075},
	archiveprefix = {arXiv},
	primaryclass = {cs.LG}
}


@misc{toneva2018empirical,
	title        = {An Empirical Study of Example Forgetting during Deep Neural Network Learning},
	author       = {Mariya Toneva and Alessandro Sordoni and Remi Tachet des Combes and Adam Trischler and Yoshua Bengio and Geoffrey J. Gordon},
	year         = 2018,
	eprint       = {1812.05159},
	archiveprefix = {arXiv},
	primaryclass = {cs.LG}
}


@misc{mirzasoleiman2019coresets,
	title        = {Coresets for Data-efficient Training of Machine Learning Models},
	author       = {Baharan Mirzasoleiman and Jeff Bilmes and Jure Leskovec},
	year         = 2019,
	eprint       = {1906.01827},
	archiveprefix = {arXiv},
	primaryclass = {cs.LG}
}


@misc{phillips2016coresets,
	title        = {Coresets and Sketches},
	author       = {Jeff M. Phillips},
	year         = 2016,
	eprint       = {1601.00617},
	archiveprefix = {arXiv},
	primaryclass = {cs.CG}
}

@misc{abbas2023semdedup,
	title        = {SemDeDup: Data-efficient learning at web-scale through semantic deduplication},
	author       = {Amro Abbas and Kushal Tirumala and Dániel Simig and Surya Ganguli and Ari S. Morcos},
	year         = 2023,
	eprint       = {2303.09540},
	archiveprefix = {arXiv},
	primaryclass = {cs.LG}
}


@misc{varshney2022let,
	title        = {Let the Model Decide its Curriculum for Multitask Learning},
	author       = {Neeraj Varshney and Swaroop Mishra and Chitta Baral},
	year         = 2022,
	eprint       = {2205.09898},
	archiveprefix = {arXiv},
	primaryclass = {cs.LG}
}

@misc{xie2023data,
	title        = {Data Selection for Language Models via Importance Resampling},
	author       = {Sang Michael Xie and Shibani Santurkar and Tengyu Ma and Percy Liang},
	year         = 2023,
	eprint       = {2302.03169},
	archiveprefix = {arXiv},
	primaryclass = {cs.CL}
}


@misc{michaud2023quantization,
	title        = {The Quantization Model of Neural Scaling},
	author       = {Eric J. Michaud and Ziming Liu and Uzay Girit and Max Tegmark},
	year         = 2023,
	eprint       = {2303.13506},
	archiveprefix = {arXiv},
	primaryclass = {cs.LG}
}


@misc{prystawski2023think,
	title        = {Why think step-by-step? Reasoning emerges from the locality of experience},
	author       = {Ben Prystawski and Noah D. Goodman},
	year         = 2023,
	eprint       = {2304.03843},
	archiveprefix = {arXiv},
	primaryclass = {cs.AI}
}

@misc{reddy2016latent,
	title        = {Latent Skill Embedding for Personalized Lesson Sequence Recommendation},
	author       = {Siddharth Reddy and Igor Labutov and Thorsten Joachims},
	year         = 2016,
	eprint       = {1602.07029},
	archiveprefix = {arXiv},
	primaryclass = {cs.LG}
}


@article{white1974past,
	title        = {Past and future research on learning hierarchies},
	author       = {Richard T.   White  and  Robert M.   Gagné},
	year         = 1974,
	journal      = {Educational Psychologist},
	publisher    = {Routledge},
	volume       = 11,
	number       = 1,
	pages        = {19--28},
	doi          = {10.1080/00461527409529119},
	url          = {https://doi.org/10.1080/00461527409529119},
	eprint       = {https://doi.org/10.1080/00461527409529119}
}

@inproceedings{
nanda2023progress,
title={Progress measures for grokking via mechanistic interpretability},
author={Neel Nanda and Lawrence Chan and Tom Lieberum and Jess Smith and Jacob Steinhardt},
booktitle={The Eleventh International Conference on Learning Representations },
year={2023},
url={https://openreview.net/forum?id=9XFSbDPmdW}
}


@software{eval-harness,
  author       = {Gao, Leo and
                  Tow, Jonathan and
                  Biderman, Stella and
                  Black, Sid and
                  DiPofi, Anthony and
                  Foster, Charles and
                  Golding, Laurence and
                  Hsu, Jeffrey and
                  McDonell, Kyle and
                  Muennighoff, Niklas and
                  Phang, Jason and
                  Reynolds, Laria and
                  Tang, Eric and
                  Thite, Anish and
                  Wang, Ben and
                  Wang, Kevin and
                  Zou, Andy},
  title        = {A framework for few-shot language model evaluation},
  month        = sep,
  year         = 2021,
  publisher    = {Zenodo},
  version      = {v0.0.1},
  doi          = {10.5281/zenodo.5371628},
  url          = {https://doi.org/10.5281/zenodo.5371628}
}


@inproceedings{naturalinstructions,
  title={Cross-task generalization via natural language crowdsourcing instructions},
  author={Mishra, Swaroop and Khashabi, Daniel and Baral, Chitta and Hajishirzi, Hannaneh},
  booktitle={ACL},
  year={2022}
}


@misc{wei2021finetuned,
    title={Finetuned Language Models Are Zero-Shot Learners},
    author={Jason Wei and Maarten Bosma and Vincent Y. Zhao and Kelvin Guu and Adams Wei Yu and Brian Lester and Nan Du and Andrew M. Dai and Quoc V. Le},
    year={2021},
    eprint={2109.01652},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}


@article{gururangan2020dont,
   title={Don’t Stop Pretraining: Adapt Language Models to Domains and Tasks},
   url={http://dx.doi.org/10.18653/v1/2020.acl-main.740},
   DOI={10.18653/v1/2020.acl-main.740},
   journal={Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics},
   publisher={Association for Computational Linguistics},
   author={Gururangan, Suchin and Marasović, Ana and Swayamdipta, Swabha and Lo, Kyle and Beltagy, Iz and Downey, Doug and Smith, Noah A.},
   year={2020} }


@inproceedings{kirk2021bias,
	title        = {Bias Out-of-the-Box: An Empirical Analysis of Intersectional Occupational Biases in Popular Generative Language Models},
	author       = {Kirk, Hannah Rose and Jun, Yennie and Volpin, Filippo and Iqbal, Haider and Benussi, Elias and Dreyer, Frederic and Shtedritski, Aleksandar and Asano, Yuki},
	year         = 2021,
	booktitle    = {Advances in Neural Information Processing Systems},
	publisher    = {Curran Associates, Inc.},
	volume       = 34,
	pages        = {2611--2624},
	url          = {https://proceedings.neurips.cc/paper_files/paper/2021/file/1531beb762df4029513ebf9295e0d34f-Paper.pdf},
	editor       = {M. Ranzato and A. Beygelzimer and Y. Dauphin and P.S. Liang and J. Wortman Vaughan}
}



@article{nadeem2021stereoset,
	title        = {StereoSet: Measuring stereotypical bias in pretrained language models},
	author       = {Nadeem, Moin and Bethke, Anna and Reddy, Siva},
	year         = 2021,
	journal      = {Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)},
	publisher    = {Association for Computational Linguistics},
	doi          = {10.18653/v1/2021.acl-long.416},
	url          = {http://dx.doi.org/10.18653/v1/2021.acl-long.416}
}


@inproceedings{liang2021towards,
	title        = {Towards Understanding and Mitigating Social Biases in Language Models},
	author       = {Liang, Paul Pu and Wu, Chiyu and Morency, Louis-Philippe and Salakhutdinov, Ruslan},
	year         = 2021,
	month        = {18--24 Jul},
	booktitle    = {Proceedings of the 38th International Conference on Machine Learning},
	publisher    = {PMLR},
	series       = {Proceedings of Machine Learning Research},
	volume       = 139,
	pages        = {6565--6576},
	url          = {https://proceedings.mlr.press/v139/liang21a.html},
	editor       = {Meila, Marina and Zhang, Tong},
	pdf          = {http://proceedings.mlr.press/v139/liang21a/liang21a.pdf},
}


@misc{bommasani2021opportunities,
	title        = {On the Opportunities and Risks of Foundation Models},
	author       = {Rishi Bommasani and Percy Liang and others},
	year         = 2021,
	eprint       = {2108.07258},
	archiveprefix = {arXiv},
	primaryclass = {cs.LG}
}


@misc{bai2022training,
	title        = {Training a Helpful and Harmless Assistant with Reinforcement Learning from Human Feedback},
	author       = {Yuntao Bai and Andy Jones and others},
	year         = 2022,
	eprint       = {2204.05862},
	archiveprefix = {arXiv},
	primaryclass = {cs.CL}
}


@misc{vicuna2023,
	title        = {Vicuna: An Open-Source Chatbot Impressing GPT-4 with 90\%* ChatGPT Quality},
	author       = {Chiang, Wei-Lin and Li, Zhuohan and Lin, Zi and Sheng, Ying and Wu, Zhanghao and Zhang, Hao and Zheng, Lianmin and Zhuang, Siyuan and Zhuang, Yonghao and Gonzalez, Joseph E. and Stoica, Ion and Xing, Eric P.},
	year         = 2023,
	month        = {March},
	url          = {https://lmsys.org/blog/2023-03-30-vicuna/}
}


@misc{koala_blogpost_2023,
	title        = {Koala: A Dialogue Model for Academic Research},
	author       = {Xinyang Geng and Arnav Gudibande and Hao Liu and Eric Wallace and Pieter Abbeel and Sergey Levine and Dawn Song},
	year         = 2023,
	month        = {April},
	url          = {https://bair.berkeley.edu/blog/2023/04/03/koala/},
	urldate      = {2023-04-03},
	howpublished = {Blog post}
}



@misc{gupta2020,
  author        = {Anupam Gupta},
  title         = {Advanced Algorithms: Notes for CMU 15-850 (Fall 2020)},
  year          = {2020},
  publisher={Carnegie Mellon University}
}


@misc{biderman2023pythia,
    title={Pythia: A Suite for Analyzing Large Language Models Across Training and Scaling},
    author={Stella Biderman and Hailey Schoelkopf and Quentin Anthony and Herbie Bradley and Kyle O'Brien and Eric Hallahan and Mohammad Aflah Khan and Shivanshu Purohit and USVSN Sai Prashanth and Edward Raff and Aviya Skowron and Lintang Sutawika and Oskar van der Wal},
    year={2023},
    eprint={2304.01373},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}

@misc{zhang2022opt,
    title={OPT: Open Pre-trained Transformer Language Models},
    author={Susan Zhang and Stephen Roller and Naman Goyal and Mikel Artetxe and Moya Chen and Shuohui Chen and Christopher Dewan and Mona Diab and Xian Li and Xi Victoria Lin and Todor Mihaylov and Myle Ott and Sam Shleifer and Kurt Shuster and Daniel Simig and Punit Singh Koura and Anjali Sridhar and Tianlu Wang and Luke Zettlemoyer},
    year={2022},
    eprint={2205.01068},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}

@misc{laurenon2023bigscience,
    title={The BigScience ROOTS Corpus: A 1.6TB Composite Multilingual Dataset},
    author={Hugo Laurençon and Lucile Saulnier and others},
    year={2023},
    eprint={2303.03915},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}

@misc{hern2022scaling,
    title={Scaling Laws and Interpretability of Learning from Repeated Data},
    author={Danny Hernandez and Tom Brown and Tom Conerly and Nova DasSarma and Dawn Drain and Sheer El-Showk and Nelson Elhage and Zac Hatfield-Dodds and Tom Henighan and Tristan Hume and Scott Johnston and Ben Mann and Chris Olah and Catherine Olsson and Dario Amodei and Nicholas Joseph and Jared Kaplan and Sam McCandlish},
    year={2022},
    eprint={2205.10487},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}







@inbook{langberg2010universal,
author = {Michael Langberg and Leonard J. Schulman},
title = {Universal approximators for integrals},
booktitle = {Proceedings of the 2010 Annual ACM-SIAM Symposium on Discrete Algorithms  (SODA)},
chapter = {},
pages = {598-607},
doi = {10.1137/1.9781611973075.50},
URL = {https://epubs.siam.org/doi/abs/10.1137/1.9781611973075.50},
eprint = {https://epubs.siam.org/doi/pdf/10.1137/1.9781611973075.50},
}

@misc{sorscher2022neural,
    title={Beyond neural scaling laws: beating power law scaling via data pruning},
    author={Ben Sorscher and Robert Geirhos and Shashank Shekhar and Surya Ganguli and Ari S. Morcos},
    year={2022},
    eprint={2206.14486},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

@inproceedings{lewis1995sequential,
  title={A sequential algorithm for training text classifiers: Corrigendum and additional data},
  author={Lewis, David D},
  booktitle={Acm Sigir Forum},
  volume={29},
  number={2},
  pages={13--19},
  year={1995},
  organization={ACM New York, NY, USA}
}

@misc{coleman2019selection,
    title={Selection via Proxy: Efficient Data Selection for Deep Learning},
    author={Cody Coleman and Christopher Yeh and Stephen Mussmann and Baharan Mirzasoleiman and Peter Bailis and Percy Liang and Jure Leskovec and Matei Zaharia},
    year={2019},
    eprint={1906.11829},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

@article{ruder2017learning,
   title={Learning to select data for transfer learning with Bayesian Optimization},
   url={http://dx.doi.org/10.18653/v1/D17-1038},
   DOI={10.18653/v1/d17-1038},
   journal={Proceedings of the 2017 Conference on Empirical Methods in Natural
          Language Processing},
   publisher={Association for Computational Linguistics},
   author={Ruder, Sebastian and Plank, Barbara},
   year={2017} }


@misc{ruder2017data,
    title={Data Selection Strategies for Multi-Domain Sentiment Analysis},
    author={Sebastian Ruder and Parsa Ghaffari and John G. Breslin},
    year={2017},
    eprint={1702.02426},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}

@inproceedings{moore2010intelligent,
    title = "Intelligent Selection of Language Model Training Data",
    author = "Moore, Robert C.  and
      Lewis, William",
    booktitle = "Proceedings of the {ACL} 2010 Conference Short Papers",
    month = jul,
    year = "2010",
    address = "Uppsala, Sweden",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P10-2041",
    pages = "220--224",
}

@inproceedings{kung-etal-2021-efficient,
    title = "Efficient Multi-Task Auxiliary Learning: Selecting Auxiliary Data by Feature Similarity",
    author = "Kung, Po-Nien  and
      Yin, Sheng-Siang  and
      Chen, Yi-Cheng  and
      Yang, Tse-Hsuan  and
      Chen, Yun-Nung",
    booktitle = "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing",
    month = nov,
    year = "2021",
    address = "Online and Punta Cana, Dominican Republic",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.emnlp-main.34",
    doi = "10.18653/v1/2021.emnlp-main.34",
    pages = "416--428",
}


@misc{koh2017understanding,
    title={Understanding Black-box Predictions via Influence Functions},
    author={Pang Wei Koh and Percy Liang},
    year={2017},
    eprint={1703.04730},
    archivePrefix={arXiv},
    primaryClass={stat.ML}
}

@inproceedings{ghorbani2019data,
  title={Data shapley: Equitable valuation of data for machine learning},
  author={Ghorbani, Amirata and Zou, James},
  booktitle={International Conference on Machine Learning},
  pages={2242--2251},
  year={2019},
  organization={PMLR}
}

@misc{ilyas2022datamodels,
    title={Datamodels: Predicting Predictions from Training Data},
    author={Andrew Ilyas and Sung Min Park and Logan Engstrom and Guillaume Leclerc and Aleksander Madry},
    year={2022},
    eprint={2202.00622},
    archivePrefix={arXiv},
    primaryClass={stat.ML}
}

@misc{guu2023simfluence,
    title={Simfluence: Modeling the Influence of Individual Training Examples by Simulating Training Runs},
    author={Kelvin Guu and Albert Webson and Ellie Pavlick and Lucas Dixon and Ian Tenney and Tolga Bolukbasi},
    year={2023},
    eprint={2303.08114},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

@inproceedings{saxena2019data,
 author = {Saxena, Shreyas and Tuzel, Oncel and DeCoste, Dennis},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Data Parameters: A New Family of Parameters for Learning a Differentiable Curriculum},
 url = {https://proceedings.neurips.cc/paper_files/paper/2019/file/926ffc0ca56636b9e73c565cf994ea5a-Paper.pdf},
 volume = {32},
 year = {2019}
}


@misc{mindermann2021prioritized,
    title={Prioritized training on points that are learnable, worth learning, and not yet learned (workshop version)},
    author={Sören Mindermann and Muhammed Razzak and Winnie Xu and Andreas Kirsch and Mrinank Sharma and Adrien Morisot and Aidan N. Gomez and Sebastian Farquhar and Jan Brauner and Yarin Gal},
    year={2021},
    eprint={2107.02565},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

@misc{li2023transformers,
    title={How Do Transformers Learn Topic Structure: Towards a Mechanistic Understanding},
    author={Yuchen Li and Yuanzhi Li and Andrej Risteski},
    year={2023},
    eprint={2303.04245},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

@misc{madaan2022language,
    title={Language Models of Code are Few-Shot Commonsense Learners},
    author={Aman Madaan and Shuyan Zhou and Uri Alon and Yiming Yang and Graham Neubig},
    year={2022},
    eprint={2210.07128},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}


@article{zamir2018taskonomy,
   title={Taskonomy: Disentangling Task Transfer Learning},
   url={http://dx.doi.org/10.1109/CVPR.2018.00391},
   DOI={10.1109/cvpr.2018.00391},
   journal={2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition},
   publisher={IEEE},
   author={Zamir, Amir R. and Sax, Alexander and Shen, William and Guibas, Leonidas and Malik, Jitendra and Savarese, Silvio},
   year={2018},
   month={Jun} }


@misc{xie2023doremi,
    title={DoReMi: Optimizing Data Mixtures Speeds Up Language Model Pretraining},
    author={Sang Michael Xie and Hieu Pham and Xuanyi Dong and Nan Du and Hanxiao Liu and Yifeng Lu and Percy Liang and Quoc V. Le and Tengyu Ma and Adams Wei Yu},
    year={2023},
    eprint={2305.10429},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}

@article{gagne1961abilities,
  title={Abilities and learning sets in knowledge acquisition.},
  author={Gagne, Robert M and Paradise, Noel E},
  journal={Psychological Monographs: General and Applied},
  volume={75},
  number={14},
  pages={1},
  year={1961},
  publisher={American Psychological Association}
}

@misc{kim2023taskweb,
    title={TaskWeb: Selecting Better Source Tasks for Multi-task NLP},
    author={Joongwon Kim and Akari Asai and Gabriel Ilharco and Hannaneh Hajishirzi},
    year={2023},
    eprint={2305.13256},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}

@misc{wang2023farewell,
    title={Farewell to Aimless Large-scale Pretraining: Influential Subset Selection for Language Model},
    author={Xiao Wang and Weikang Zhou and Qi Zhang and Jie Zhou and Songyang Gao and Junzhe Wang and Menghan Zhang and Xiang Gao and Yunwen Chen and Tao Gui},
    year={2023},
    eprint={2305.12816},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}