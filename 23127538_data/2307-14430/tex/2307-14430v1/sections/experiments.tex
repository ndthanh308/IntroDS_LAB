\section{Experimental results}\label{sec:exp}

Given an ordered skill set, we aim to validate \name's ability to select data for efficiently learning skills in the continual pre-training, fine-tuning, and out-of-domain settings. 
We provide full tables of results in Appendix~\ref{supp:full} and results where we learn the skills graph on the 125M model and use it for the 1.3B parameter model in Appendix~\ref{supp:larger_model}. Skills graphs are in Appendix~\ref{supp:skill_graphs}, weight trajectories for \name are in Appendix~\ref{supp:weights}, and ablations on the graph and online components of \name are in Appendix~\ref{supp:ablations}.


\subsection{Continual pre-training}

\noindent \textbf{Setup} \; We evaluate the ability of \name to select data for efficiently learning over all skills. We measure average validation loss per skill after a fixed number of training steps. We construct the LEGO synthetic and addition synthetic with $k = 5$ and $3$, respectively, and an imbalanced dataset over the skills. On the Natural Instructions dataset, we use $23$ of the task categories as skills.

\noindent \textbf{Baselines}\; We compare \name against three baselines that do not account for skills: random sampling, curriculum learning, and anticurriculum learning. Random sampling is a standard procedure for selecting samples given no additional information. Curriculum learning~\cite{bengio2009curriculum} and anticurriculum learning~\cite{wu2020curricula} score the samples from easiest to hardest and vice versa, respectively, and sample over an expanding set of the lowest scored samples at every epoch; we use the pre-trained model's loss to rank points. We evaluate skill-stratified sampling, which uses knowledge of the skills but is not online, and include an additional skills curriculum baseline in Appendix~\ref{supp:full}

\noindent \textbf{Analysis} \; Our results are shown in Figure~\ref{fig:lego_mw}. Across our experiments we find that \name outperforms baselines that do not use skills as well as skill-stratified sampling. 
On the LEGO dataset, all three baselines that do not utilize a notion of skills exhibit plateauing loss on four of the skills. Both skill-stratified sampling and \name are able to significantly reduce loss on all skills, but the former is slower. Halfway through training, \name exhibits an accuracy improvement between $9.9$ and $25.9$ points over other approaches, reaching a final accuracy of $99.4$ (Figure~\ref{fig:lego_accs}).
\name outperforms skill-stratified sampling by initially allocating more weight to prerequisite skills and eventually allocating more weight to skills that are learned more slowly (Figure~\ref{fig:lego_weights}).
On the addition synthetic with $k = 3$, \name converges to near-zero validation loss faster than the baselines on skills 1 and 2. 
While the random baseline may seem competitive at first glance, it fails to learn skill 1 (adding together the ones digits), which hurts its average loss per skill. 
On NI, the validation loss from \name is $3.2\%$ lower than from random sampling (Table~\ref{tab:ni_pretraining}). Our results suggest that exploiting the construction and ordering of skills is critical to learning skills quickly.


% Figure environment removed

\subsection{Fine-tuning}


% Figure environment removed

\noindent \textbf{Setup} \; We evaluate the ability of \name to select data from an ordered training skill set for learning a target skill. Mirroring Figure~\ref{fig:ni_lego_examples}, we evaluate on LEGO target skill 3 (third in reasoning chain), on the addition synthetic's skill 1 (ones place digit addition), and on NI's Spanish QG and Stance Detection.

\noindent \textbf{Baselines} \; We compare \name against training on the target skill only and skill-stratified sampling over prerequisite skills and the target skill. The skill-stratified sampling approach uses the ordered skill set to identify prerequisite skills, but does not exploit them dynamically. 

\noindent \textbf{Analysis} \; Our results are shown in Figure~\ref{fig:ni_targeted}. 
On LEGO, \name results in the same validation loss of $0.01$ as training only on the target skill in $38.1\%$ fewer steps.
We observe a similar trend on addition, with \name converging to a validation loss of $0.01$ in $59\%$ fewer steps required to do so when training only on the target skill.
Finally, on NI, \name improves validation loss on Spanish question generation by $5.3\%$ and Stance Detection by $13.6\%$ over just training on the respective target skill only.  
In this setting, a significant portion of the improvement over training only on the target skill comes from identification of prerequisite skills through the learned graph in the skill-stratified sampling method. \name is further able to improve performance with finer-grained dynamic weighting on prerequisite skills.

\subsection{Out-of-domain setting}

% Figure environment removed


\noindent \textbf{Natural Instructions} \;
We evaluate the ability of \name to select data from a set of training skills for learning a disjoint set of evaluation skills that we cannot train on. We use all $59$ task categories in the NI train tasks split as the training skills and the $12$ task categories in the test tasks split as our evaluation skills.
We compare \name against random and skill-stratified sampling, both of which do not exploit the relationships between training skills and evaluation skills.
\name achieves the lowest loss on 11 out of 12 task categories over random and skill-stratified sampling (Figure~\ref{fig:ni_test}, tables in Appendix). 

\noindent \textbf{RedPajama} \;
We use \name to produce a data mixture on the RedPajama dataset. The training skills are the data sources comprising the dataset, and the evaluation skills are several tasks from the Language Model Evaluation Harness~\cite{eval-harness}. \name with $T = 1$ (i.e. a static, graph-based mixture) yields the mixture in Figure~\ref{fig:redpajama} (right). We continually pre-train a 3B parameter model trained on one trillion tokens for three billion additional tokens using this mixture, and see that it outperforms uniform sampling over the data sources (Figure~\ref{fig:redpajama} left). In particular, \name achieves higher accuracy with 1B additional tokens than uniform with 3B additional tokens. 


% Figure environment removed


