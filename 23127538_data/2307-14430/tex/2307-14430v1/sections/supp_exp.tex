\section{Additional Experimental Results}

\subsection{Additional examples of LEGO ordered skill sets} \label{supp:lego_exp}


For the LEGO synthetic, it may appear obvious that the skills graph is equivalent to the reasoning chain over the variables. However, in Figure~\ref{fig:more_lego} we see that this is not the case. Training on skills $2$ and $4$ together results in lower loss on skill $4$ than when trained on skill $4$ alone. However, training on skills $3$ and $4$ together results in roughly the same loss on skill $4$ as when training on skill $4$ alone, even though skill $3$ and skill $4$ share an edge in the LEGO synthetic's underlying reasoning chain. This suggests that our intuition for how skills influence each other does not always match how the model learns skills.

% Figure environment removed

Next, we consider a slightly more complex reasoning pattern on the LEGO synthetic. Instead of a chain, we construct a tree, where two variables in the LEGO synthetic are both defined in terms of the same parent variable. For example,
\begin{quote}
    Input:  c = val 1, y = not w, v = val c,  w = not c. Output: y = 1.
\end{quote}

In this example, $k = 4$ and both $v$ and $w$ are written in terms of $c$, and the reasoning graph has edges $1 \rightarrow 2$, $1 \rightarrow 3$, $2 \rightarrow 4$. In this case, we see that training on skill $2$ or skill $3$ both improve losses on skills $2$ and $3$ (Figure~\ref{fig:lego_tree_23}). However, unlike the previous figures, training on skills $2$ and $4$ or skills $3$ and $4$ do not significantly help reduce loss on skill $4$ (Figure~\ref{fig:lego_tree_4}). Again, these measurements demonstrate that the reasoning graph does not necessarily equal the skills graph.

% Figure environment removed

% Figure environment removed



\subsection{Unsupervised skill recovery} \label{supp:skill_clustering}

We explore several clustering techniques for recovering the skills in the LEGO synthetic on the validation dataset. Our results are shown in Table~\ref{tab:skill_recovery}.

We first cluster based on the pre-trained model embeddings of the last token and the average token. We also report accuracies of clustering based on the trained model embedding's last token, where we train the model using random sampling for $6000$ steps, and clustering based on Sentence-BERT embeddings. Among these four methods, using the trained model embeddings has the highest accuracy of $38.4$ points. 

Next, we cluster points based on losses. In particular, we do $10$ runs, each for $6000$ steps and with a randomly sampled mixture of skills. For each run, we evaluate the model on the validation dataset at $120$ checkpoints. Then, each sample in the validation dataset has $1200$ losses associated with it, comprising a feature vector for that sample. We perform k-means clustering on these features, which has an accuracy of $61.0$ points, significantly higher than the second best accuracy of $38.4$. 

\begin{table}
    \small
    \centering
\caption{Clustering-based skill recovery methods on the LEGO dataset. The validation dataset we cluster consists of $500$ points with $k=5$, and results are reported over 10 runs of k-means.}
\begin{tabular}{|c|c|}
    \hline
    Cluster method & Accuracy \\
    \hline
    Pretrained embedding of last token & $24.8 \pm 0.5$ \\
    \hline 
    Pretrained embedding of average token & $25.2 \pm 1.1$ \\
    \hline 
    Trained model embedding of last token & $38.4 \pm 0.8$ \\ 
    \hline 
    Sentence-BERT embedding & $23.9 \pm 0.7$ \\
    \hline
    Losses over multiple runs & $\mathbf{61.0 \pm 1.6}$ \\
    \hline
\end{tabular}
\label{tab:skill_recovery}
\end{table}

\subsection{Full results for Section~\ref{sec:exp}}

\subsubsection{Per-skill performance}\label{supp:full}

In this section, we provide tables containing the per skill break-down of our results from Section~\ref{sec:exp}.

\paragraph{Continual Pre-training}

In the continual pre-training setting, we report two additional baselines that combine curriculum learning with skills. Curriculum learning has been proposed for multitask learning~\cite{varshney2022let}, in which groups of data are ranked by their average score and then trained in order of this ranking (with mixing of previously seen groups to avoid forgetting). We construct two baselines, Skill-curriculum and Skill-anticurriculum, using Algorithm 1 from~\cite{varshney2022let}. In contrast to the random baseline which has imbalanced skills, this approach has knowledge of skills and thus uses a skill-stratified training dataset to sample from. We set the fraction of the previous group to be $\text{frac}=0.4$, as we found that setting $\text{frac}=0.0$ resulted in forgetting.

We report loss per skill for the LEGO synthetic in Table~\ref{tab:lego_pt_loss}, which corresponds to the results in Figure~\ref{fig:lego_mw}. We report accuracy per skill in Table~\ref{tab:lego_pt_acc} and Figure~\ref{fig:lego_accs}.
We report the loss per skill for the Addition synthetic in Table~\ref{tab:addition_pt_loss}, which also correspond to to the results in Figure~\ref{fig:lego_mw}. 
Finally, we report validation loss per task category for the Natural Instructions continual pre-training experiment in Table~\ref{tab:ni_pretraining}, where we find that \name outperforms random sampling by $3.2\%$ on average across skills.

\begin{table}[h]
\footnotesize
\caption{Results on validation loss per skill for LEGO pre-training experiment, averaged over $5$ random seeds.}
\begin{adjustbox}{center}
\begin{tabular}{c|cccccc}
\toprule
& Skill 1 & Skill 2 & Skill 3 & Skill 4 & Skill 5 & Average \\
\midrule
Random & $0_{\pm 0.000}$ & $0.675_{\pm 0.041}$ & $0.688_{\pm 0.008}$ & $0.673_{\pm 0.049}$ & $0.667_{\pm 0.056}$ & $0.541_{\pm 0.031}$ \\
Curriculum & $0_{\pm 0.000}$ & $0.645_{\pm 0.052}$ & $0.686_{\pm 0.018}$ & $0.674_{\pm 0.042}$ & $0.671_{\pm 0.0459}$ & $0.535_{\pm 0.029}$ \\
Anticurriculum & $0_{\pm 0.000}$ & $0.690_{\pm 0.003}$ & $0.695_{\pm 0.004}$ & $0.693_{\pm 0.003}$ & $0.689_{\pm 0.004}$ & $0.554_{\pm 0.001}$ \\
Skill-stratified & $0_{\pm 0.000}$ & $0.045_{\pm 0.036}$ & $0.056_{\pm 0.029}$ & $0.079_{\pm 0.044}$ & $0.050_{\pm 0.025}$ & $0.046_{\pm 0.022}$ \\
Skill-curriculum & $0_{\pm 0.000}$ & $0.484_{\pm 0.200}$ & $0.698_{\pm 0.027}$ & $0.697_{\pm 0.010}$ & $0.689_{\pm 0.007}$ & $0.514_{\pm 0.040}$ \\
Skill-anticurriculum & $0.001_{\pm 0.001}$ & $0.174_{\pm 0.118}$ & $0.245_{\pm 0.091}$ & $0.443_{\pm 0.125}$ & $0.566_{\pm 0.118}$ & $0.286_{\pm 0.060}$ \\
\name & $0_{\pm 0.000}$ & $0.002_{\pm 0.002}$ & $0.024_{\pm 0.031}$ & $0.013_{\pm 0.010}$ & $0.022_{\pm 0.021}$ & $0.012_{\pm 0.008}$ \\
\bottomrule
\end{tabular}
\end{adjustbox}
\label{tab:lego_pt_loss}
\end{table}



\begin{table}[h]
\footnotesize
\centering
\caption{Results on accuracy per skill (binary classification) for LEGO pre-training experiment, averaged over $5$ random seeds.}
\begin{adjustbox}{center}
\begin{tabular}{c|cccccc}
\toprule
& Skill 1 & Skill 2 & Skill 3 & Skill 4 & Skill 5 & Average \\
\midrule
Random & $100.0_{\pm 0.0}$ & $54.2_{\pm 5.9}$ & $58.0_{\pm 3.1}$ & $48.0_{\pm 6.3}$ & $54.4_{\pm 7.3}$ & $62.9_{\pm 3.5}$ \\
Curriculum & $100.0_{\pm 0.0}$ & $60.0_{\pm 10.6}$ & $55.2_{\pm 5.8}$ & $51.2_{\pm 6.3}$ & $51.8_{\pm 6.1}$ & $63.6_{\pm 3.6}$ \\
Anticurriculum & $100.0_{\pm 0.0}$ & $53.4_{\pm 2.3}$ & $49.0_{\pm 4.8}$ & $48.2_{\pm 6.4}$ & $56.0_{\pm 5.7}$ & $61.3_{\pm 2.2}$ \\
Skill-stratified & $100.0_{\pm 0.0}$ & $98.2_{\pm 1.8}$ & $98.2_{\pm 1.3}$ & $97.8_{\pm 1.6}$ & $98.2_{\pm 1.3}$ & $98.5_{\pm 0.9}$ \\
Skill-curriculum & $100.0_{\pm 0.0}$ & $75.2_{\pm 30.1}$ & $52.2_{\pm 3.7}$ & $51.0_{\pm 4.6}$ & $54.4_{\pm 3.1}$ & $66.6_{\pm 7.7}$ \\
Skill-anticurriculum & $100.0_{\pm 0.0}$ & $90.2_{\pm 8.1}$ & $88.2_{\pm 8.3}$ & $73.2_{\pm 12.2}$ & $62.4_{\pm 9.4}$ & $82.8_{\pm 4.9}$ \\
\name & $100.0_{\pm 0.0}$ & $99.2_{\pm 0.8}$ & $99.0_{\pm 1.0}$ & $99.4_{\pm 0.5}$ & $99.6_{\pm 0.5}$ & $99.4_{\pm 0.2}$ \\
\bottomrule
\end{tabular}
\end{adjustbox}
\label{tab:lego_pt_acc}
\end{table}

% Figure environment removed



\begin{table}[h] 
\footnotesize
\caption{Results on validation loss per skill for Addition pre-training experiment, averaged over $5$ random seeds.}
\begin{adjustbox}{center}
\begin{tabular}{c|cccc}
\toprule
& Skill 1 & Skill 2 & Skill 3 & Average \\
\midrule
Random & $0.008_{\pm 0.007}$ & $0.020_{\pm 0.019}$ & $0.005_{\pm 0.005}$ & $0.011_{\pm 0.014}$ \\
Curriculum & $0.009_{\pm 0.011}$ & $0.010_{\pm 0.008}$ & $0.008_{\pm 0.010}$ & $0.009_{\pm 0.010}$ \\
Anticurriculum & $0.007_{\pm 0.010}$ & $0.012_{\pm 0.013}$ & $0.008_{\pm 0.017}$ & $0.009_{\pm 0.014}$ \\
Skill-stratified & $0.012_{\pm 0.011}$ & $0.015_{\pm 0.015}$ & $0.010_{\pm 0.020}$ & $0.012_{\pm 0.016}$ \\
Skill-curriculum & $0.016_{\pm 0.013}$ & $0.019_{\pm 0.013}$ & $0.010_{\pm 0.003}$ & $0.015_{\pm 0.010}$ \\
Skill-anticurriculum & $0.005_{\pm 0.008}$ & $0.037_{\pm 0.028}$ & $1.141_{\pm 1.126}$ & $0.395_{\pm 0.371}$ \\
 % $\substack{\mathrm{Skill} \\\mathrm{-curriculum}}$ & \\
 % $\substack{\mathrm{Skill} \\\mathrm{-anticurriculum}}$ & \\
\name & $0.004_{\pm 0.003}$ & $0.009_{\pm 0.007}$ & $0.013_{\pm 0.017}$ & $0.009_{\pm 0.011}$ \\
\bottomrule
\end{tabular}
\end{adjustbox}
\label{tab:addition_pt_loss}
\end{table}




\begin{landscape}
\begin{table}
\footnotesize
\centering
\caption{Validation loss per skill for data selection in continual pre-training setting on a subset of the Natural Instructions Dataset.}
\centerline{\begin{tabular}{l|c|c|c|c|c|c|c}
\toprule
Skill & Random & Curriculum & Anticurriculum & Skill-stratified & Skill-curriculum & Skill-anticurriculum & \name \\
\midrule
Answer Verification & $2.297_{\pm 0.058}$ & $2.368_{\pm 0.055}$ & $2.391_{\pm 0.061}$ & $2.180_{\pm 0.059}$ & $2.249_{\pm 0.116}$ & $2.325_{\pm 0.085}$ & $2.158_{\pm 0.059}$ \\
Code to Text & $0.246_{\pm 0.021}$ & $0.203_{\pm 0.019}$ & $1.099_{\pm 0.115}$ & $0.178_{\pm 0.016}$ & $0.126_{\pm 0.009}$ & $1.232_{\pm 0.070}$ & $0.223_{\pm 0.017}$ \\
Discourse Connective Identification & $2.927_{\pm 0.069}$ & $3.084_{\pm 0.067}$ & $2.932_{\pm 0.058}$ & $2.805_{\pm 0.071}$ & $2.891_{\pm 0.001}$ & $2.925_{\pm 0.011}$ & $2.784_{\pm 0.068}$ \\
Entity Generation & $2.033_{\pm 0.421}$ & $2.012_{\pm 0.437}$ & $2.363_{\pm 0.234}$ & $1.803_{\pm 0.384}$ & $1.853_{\pm 0.483}$ & $2.068_{\pm 0.719}$ & $1.863_{\pm 0.418}$ \\
Entity Relation Classification & $1.020_{\pm 0.147}$ & $1.014_{\pm 0.140}$ & $1.533_{\pm 0.138}$ & $0.859_{\pm 0.131}$ & $0.825_{\pm 0.022}$ & $0.959_{\pm 0.009}$ & $0.908_{\pm 0.146}$ \\
Information Extraction & $2.154_{\pm 0.040}$ & $2.247_{\pm 0.037}$ & $2.352_{\pm 0.042}$ & $2.140_{\pm 0.037}$ & $2.286_{\pm 0.022}$ & $2.338_{\pm 0.025}$ & $2.073_{\pm 0.042}$ \\
Irony Detection & $3.024_{\pm 0.154}$ & $3.798_{\pm 0.095}$ & $2.942_{\pm 0.158}$ & $2.680_{\pm 0.146}$ & $3.889_{\pm 0.066}$ & $2.099_{\pm 0.152}$ & $2.797_{\pm 0.155}$ \\
Preposition Prediction & $0.979_{\pm 0.124}$ & $0.887_{\pm 0.147}$ & $1.488_{\pm 0.213}$ & $0.845_{\pm 0.152}$ & $0.941_{\pm 0.019}$ & $1.044_{\pm 0.029}$ & $0.876_{\pm 0.173}$ \\
Punctuation Error Detection & $2.950_{\pm 0.065}$ & $3.120_{\pm 0.052}$ & $2.961_{\pm 0.064}$ & $3.264_{\pm 0.061}$ & $3.019_{\pm 0.010}$ & $3.360_{\pm 0.013}$ & $3.216_{\pm 0.055}$ \\
Question Answering & $2.277_{\pm 0.005}$ & $2.367_{\pm 0.006}$ & $2.398_{\pm 0.006}$ & $2.542_{\pm 0.004}$ & $2.689_{\pm 0.001}$ & $2.707_{\pm 0.016}$ & $2.448_{\pm 0.008}$ \\
Question Generation & $2.617_{\pm 0.005}$ & $2.777_{\pm 0.015}$ & $2.695_{\pm 0.008}$ & $2.783_{\pm 0.021}$ & $3.062_{\pm 0.006}$ & $2.876_{\pm 0.032}$ & $2.666_{\pm 0.012}$ \\
Question Understanding & $1.965_{\pm 0.051}$ & $2.199_{\pm 0.059}$ & $2.060_{\pm 0.033}$ & $1.958_{\pm 0.051}$ & $2.385_{\pm 0.022}$ & $2.100_{\pm 0.054}$ & $1.895_{\pm 0.043}$ \\
Sentence Expansion & $2.501_{\pm 0.095}$ & $2.598_{\pm 0.097}$ & $2.583_{\pm 0.074}$ & $2.225_{\pm 0.095}$ & $2.311_{\pm 0.076}$ & $2.408_{\pm 0.074}$ & $2.236_{\pm 0.083}$ \\
Sentiment Analysis & $3.203_{\pm 0.012}$ & $3.415_{\pm 0.016}$ & $3.209_{\pm 0.010}$ & $3.278_{\pm 0.014}$ & $3.607_{\pm 0.012}$ & $3.308_{\pm 0.015}$ & $3.213_{\pm 0.012}$ \\
Stance Detection & $1.810_{\pm 0.100}$ & $1.775_{\pm 0.120}$ & $2.231_{\pm 0.128}$ & $1.385_{\pm 0.070}$ & $1.361_{\pm 0.114}$ & $1.823_{\pm 0.189}$ & $1.556_{\pm 0.125}$ \\
Summarization & $2.961_{\pm 0.015}$ & $3.149_{\pm 0.023}$ & $3.041_{\pm 0.014}$ & $2.960_{\pm 0.019}$ & $3.323_{\pm 0.028}$ & $3.021_{\pm 0.013}$ & $2.907_{\pm 0.012}$ \\
Text Categorization & $2.488_{\pm 0.023}$ & $2.692_{\pm 0.029}$ & $2.553_{\pm 0.006}$ & $2.570_{\pm 0.015}$ & $3.001_{\pm 0.007}$ & $2.635_{\pm 0.014}$ & $2.448_{\pm 0.017}$ \\
Text Matching & $2.177_{\pm 0.059}$ & $2.232_{\pm 0.055}$ & $2.316_{\pm 0.048}$ & $2.152_{\pm 0.061}$ & $2.324_{\pm 0.004}$ & $2.304_{\pm 0.035}$ & $2.093_{\pm 0.054}$ \\
Text Simplification & $2.155_{\pm 0.023}$ & $2.193_{\pm 0.039}$ & $2.325_{\pm 0.033}$ & $1.926_{\pm 0.026}$ & $2.037_{\pm 0.005}$ & $2.156_{\pm 0.011}$ & $1.952_{\pm 0.026}$ \\
Text to Code & $0.560_{\pm 0.037}$ & $0.495_{\pm 0.036}$ & $1.215_{\pm 0.052}$ & $0.490_{\pm 0.029}$ & $0.433_{\pm 0.014}$ & $1.455_{\pm 0.086}$ & $0.553_{\pm 0.042}$ \\
Toxic Language Detection & $3.106_{\pm 0.027}$ & $3.496_{\pm 0.017}$ & $3.058_{\pm 0.029}$ & $3.199_{\pm 0.024}$ & $3.758_{\pm 0.025}$ & $3.155_{\pm 0.050}$ & $3.129_{\pm 0.020}$ \\
Word Semantics & $2.092_{\pm 0.027}$ & $2.334_{\pm 0.034}$ & $2.156_{\pm 0.064}$ & $1.916_{\pm 0.043}$ & $1.784_{\pm 0.048}$ & $2.424_{\pm 0.038}$ & $1.952_{\pm 0.019}$ \\
Wrong Candidate Generation & $2.438_{\pm 0.021}$ & $2.606_{\pm 0.039}$ & $2.519_{\pm 0.027}$ & $2.506_{\pm 0.026}$ & $2.849_{\pm 0.029}$ & $2.574_{\pm 0.018}$ & $2.432_{\pm 0.025}$ \\
\midrule 
Average & $2.173_{\pm 0.028}$ & $2.307_{\pm 0.025}$ & $2.366_{\pm 0.026}$ & $2.115_{\pm 0.027}$ & $2.304_{\pm 0.031}$ & $2.317_{\pm 0.052}$ & $2.103_{\pm 0.032}$ \\
\bottomrule
\end{tabular}}
\label{tab:ni_pretraining}
\end{table}
\end{landscape}


\paragraph{Out-of-domain}

In Table~\ref{tab:ni_test}, we provide a breakdown of validation loss per evaluation skill under random sampling on the training data, skill-stratified sampling over prerequisite skills (e.g., the nonzero rows in Figure~\ref{fig:ni_test_heatmap}), and \name. 



\begin{table}[htbp]
  \centering
  \caption{Validation loss per skill for data selection in out-of-domain setting over Natural Instructions train task split and test task split.}
  \label{tab:skill-results}
  \begin{tabular}{l |c |c |c}
    \toprule
    Skill & Random & Skill-stratified & \name \\
    \midrule
    Answerability Classification & $3.048_{\pm 0.003}$ & $3.076_{\pm 0.002}$ & $3.043_{\pm 0.003}$ \\
    Cause Effect Classification & $2.068_{\pm 0.004}$ & $2.101_{\pm 0.005}$ & $2.067_{\pm 0.006}$ \\
    Coreference Resolution & $3.101_{\pm 0.003}$ & $3.142_{\pm 0.004}$ & $3.099_{\pm 0.004}$ \\
    Data to Text & $2.363_{\pm 0.004}$ & $2.388_{\pm 0.005}$ & $2.359_{\pm 0.005}$ \\
    Dialogue Act Recognition & $2.329_{\pm 0.009}$ & $2.364_{\pm 0.010}$ & $2.320_{\pm 0.009}$ \\
    Grammar Error Correction & $2.399_{\pm 0.008}$ & $2.418_{\pm 0.009}$ & $2.389_{\pm 0.007}$ \\
    Keyword Tagging & $2.744_{\pm 0.005}$ & $2.760_{\pm 0.007}$ & $2.733_{\pm 0.006}$ \\
    Overlap Extraction & $2.749_{\pm 0.011}$ & $2.763_{\pm 0.012}$ & $2.733_{\pm 0.010}$ \\
    Question Rewriting & $2.591_{\pm 0.009}$ & $2.628_{\pm 0.011}$ & $2.586_{\pm 0.010}$ \\
    Textual Entailment & $2.472_{\pm 0.002}$ & $2.503_{\pm 0.003}$ & $2.468_{\pm 0.002}$ \\
    Title Generation & $3.027_{\pm 0.002}$ & $3.037_{\pm 0.002}$ & $3.015_{\pm 0.002}$ \\
    Word Analogy & $1.665_{\pm 0.016}$ & $1.682_{\pm 0.015}$ & $1.668_{\pm 0.016}$ \\
    \midrule 
    Average & $2.546_{\pm 0.003}$ & $2.572_{\pm 0.003}$ & $2.540_{\pm 0.003}$ \\
    \bottomrule
  \end{tabular}
  \label{tab:ni_test}
\end{table}


 In Table~\ref{tab:redpajama} we provide a breakdown of the RedPajama experiment's accuracy per evaluation skill, corresponding to the results in Figure~\ref{fig:redpajama}.

\begin{table}[ht]
\centering
\caption{Performance of model trained on RedPajama with uniform sampling and \name on LM evaluation harness. Unless otherwise noted, accuracy is reported for each task.}
\begin{tabular}{l|cc|cc|cc}
\toprule
& \multicolumn{2}{c|}{1 Billion Tokens} & \multicolumn{2}{c|}{2 Billion Tokens} & \multicolumn{2}{c}{3 Billion Tokens} \\
\cmidrule{2-3} \cmidrule{4-5} \cmidrule{6-7}
& Uniform & \name & Uniform & \name & Uniform & \name  \\
\midrule
ARC Challenge (acc norm) & $35.4$ & $34.6$ & $35.3$ & $34.9$ & $34.6$ & $34.8$ \\
ARC Easy (acc norm) & $62.2$ & $61.2$ & $62.4$ & $61.7$ & $62.5$ & $62.0$ \\
BoolQ & $68.9$ & $68.2$ & $67.7$ & $68.6$ & $67.2$ & $68.7$ \\
COPA & $81.0$ & $82.0$ & $80.0$ & $81.0$ & $81.0$ & $81.0$ \\
HellaSwag (acc norm) & $63.9$ & $63.7$ & $63.8$ & $63.9$ & $64.0$ & $63.9$ \\
LAMBADA OpenAI & $64.4$ & $67.0$ & $65.9$ & $66.7$ & $66.8$ & $66.0$ \\
PIQA (acc norm) & $74.8$ & $75.0$ & $75.5$ & $75.2$ & $75.0$ & $75.7$ \\
Winogrande & $62.8$ & $63.9$ & $63.9$ & $63.2$ & $63.4$ & $63.1$ \\
\midrule 
Average accuracy & $64.2$ & $64.4$ & $64.3$ & $64.4$ & $64.3$ & $64.4$ \\
\bottomrule
\end{tabular}
\label{tab:redpajama}
\end{table}


\subsubsection{Weight trajectories} \label{supp:weights}

We provide \name's weight trajectories for each result. The weight per skill across training steps for the LEGO pre-training experiment corresponding to Figure~\ref{fig:lego_mw} (left) is shown in Figure~\ref{fig:lego_weights}. We see that \name initially allocates more weight to skill $2$ and less to $1, 3, 4, 5$. Since skill $1$ is learned quickly, the weight on skill $1$ immediately drops to below $0.1$ at $1000$ steps. The weight on skills $3, 4,$ and $5$ increase from around $0$ to $3000$ steps, during which their respective validation losses are higher than those of skills $1$ and $2$. Near the end of training, all losses are converging to $0$, and so the weight per skill is roughly uniform.

The weight per skill across training steps for the addition pre-training experiment corresponding to Figure~\ref{fig:lego_mw} (right) is shown in Figure~\ref{fig:addn_weights}. \name allocates more weight to skill $2$, which has an edge to skill $1$ as shown in Figure~\ref{fig:addition_heatmap}. It also allocates very little weight to skill $3$, which is learned faster than the other two skills. Eventually, it puts more weight on skill $1$, the hardest skill, and then converges to uniform sampling as all validation losses approach $0$.

The weight per skill across training steps for the LEGO fine-tuning experiment and the Spanish question generation and stance detection experiments corresponding to Figure~\ref{fig:ni_targeted} is shown in Figure~\ref{fig:ft_weights}. Since there is only one target skill in these experiments, the mixture of weights approaches uniform as the loss on the target skill approaches $0$. It is interesting to explore how to reduce edge weights and regularization so that the mixture approaches the target skill instead, although preliminary experiments where we decayed the edge weight and the strength of the Bregman divergence term did not appear better. We hypothesize that since training on a uniform mixture (as in Figure~\ref{fig:ni_lego_examples}) did strictly better than training on the target skill and their loss curves did not intersect during the training run, it is better to allocate non-negligible weight on all skills throughout the training run. 

The weight per skill across training steps for the Natural Instructions out-of-domain experiment corresponding to Figure~\ref{fig:ni_test} is shown in Figure~\ref{fig:ni_test_weights}, where the legend is provided for the top $10$ task categories with the largest weights. While the initial weights based on the skills graph roughly establishes the order of weight magnitude, the differences among the losses on the evaluation skills increases the range of weights as training continues. As validation losses saturate, the weights also converge to fixed values.

% Figure environment removed

% Figure environment removed




% Figure environment removed



% Figure environment removed

\subsection{Experiments on 1.3B parameter model}\label{supp:larger_model}

We demonstrate that the skills graph learned on the 125M parameter model can be used for data selection with the GPT-Neo-1.3B model. We present results in the continual pre-training setting on the LEGO synthetic and Natural Instructions.

All results are reported over $3$ random seeds. For the LEGO experiment, we train for $1500$ steps with $\eta =0.5, T = 30, w = 3$. For the NI experiment, we train for $5000$ steps with $\eta = 0.2$, and $T = 1$. The skill graphs were learned using the 125M parameter model as described in section~\ref{supp:skill_graphs}.

 
In Figure~\ref{fig:lego_large}, we train the $1.3$B model using \name for the LEGO synthetic and find that it still outperforms random and skill-stratified sampling on average. In particular, while performance across sampling methods is similar for early skills, the discrepancy is larger for skill $5$, for which \name allocates more weight to dynamically. In Figure~\ref{fig:lego_weights_large}, we provide the weight trajectories of \name. We observe that the weight trajectories are similar to that on the 125M parameter model, where initial weight is allocated towards skill $2$. Later on, more weight is allocated towards skills $4$ and $5$, whose losses are higher, and eventually the weight mixture converges to uniform as all losses converge to near $0$. 

In Table~\ref{tab:ni_pretraining_large}, we report performance of \name with the $1.3$B model on the Natural Instructions pre-training experiment and find that the trends from the smaller model hold---\name outperforms random and skill-stratified sampling on average.


% Figure environment removed

% Figure environment removed


\begin{table}[ht]
\footnotesize
\centering
\caption{Results when skills graph for Natural Instructions learned on 125M parameter model is used for data selection with a 1.3B model. We see that \name on average still outperforms random and skill-stratified sampling, even though the edges used by \name are not derived from the larger model.}
\begin{tabular}{l|c|c|c}
\toprule
Skill & Random & Skill-stratified & \name \\
\midrule
Answer Verification & $2.005_{\pm 0.059}$ & $1.903_{\pm 0.069}$ & $1.890_{\pm 0.072}$ \\
Code to Text & $0.302_{\pm 0.032}$ & $0.204_{\pm 0.022}$ & $0.269_{\pm 0.032}$ \\
Discourse Connective Identification & $2.529_{\pm 0.046}$ & $2.372_{\pm 0.054}$ & $2.393_{\pm 0.056}$ \\
Entity Generation & $2.108_{\pm 0.328}$ & $1.788_{\pm 0.429}$ & $1.885_{\pm 0.461}$ \\
Entity Relation Classification & $1.130_{\pm 0.048}$ & $0.836_{\pm 0.006}$ & $0.841_{\pm 0.010}$ \\
Information Extraction & $2.032_{\pm 0.013}$ & $1.992_{\pm 0.006}$ & $1.933_{\pm 0.013}$ \\
Irony Detection & $2.802_{\pm 0.125}$ & $2.528_{\pm 0.146}$ & $2.585_{\pm 0.149}$ \\
Preposition Prediction & $1.095_{\pm 0.040}$ & $0.686_{\pm 0.041}$ & $0.774_{\pm 0.029}$ \\
Punctuation Error Detection & $2.633_{\pm 0.027}$ & $3.188_{\pm 0.055}$ & $2.726_{\pm 0.025}$ \\
Question Answering & $1.947_{\pm 0.003}$ & $2.119_{\pm 0.003}$ & $2.073_{\pm 0.001}$ \\
Question Generation & $2.214_{\pm 0.007}$ & $2.345_{\pm 0.008}$ & $2.263_{\pm 0.010}$ \\
Question Understanding & $1.928_{\pm 0.020}$ & $1.837_{\pm 0.031}$ & $1.700_{\pm 0.042}$ \\
Sentence Expansion & $2.054_{\pm 0.018}$ & $1.828_{\pm 0.060}$ & $1.853_{\pm 0.058}$ \\
Sentiment Analysis & $2.771_{\pm 0.009}$ & $2.818_{\pm 0.006}$ & $2.774_{\pm 0.007}$ \\
Stance Detection & $1.814_{\pm 0.151}$ & $1.500_{\pm 0.117}$ & $1.628_{\pm 0.149}$ \\
Summarization & $2.531_{\pm 0.009}$ & $2.472_{\pm 0.012}$ & $2.440_{\pm 0.013}$ \\
Text Categorization & $2.289_{\pm 0.016}$ & $2.341_{\pm 0.021}$ & $2.231_{\pm 0.022}$ \\
Text Matching & $1.967_{\pm 0.008}$ & $1.913_{\pm 0.005}$ & $1.872_{\pm 0.005}$ \\
Text Simplification & $1.861_{\pm 0.003}$ & $1.692_{\pm 0.023}$ & $1.698_{\pm 0.022}$ \\
Text to Code & $0.614_{\pm 0.030}$ & $0.518_{\pm 0.030}$ & $0.585_{\pm 0.022}$ \\
Toxic Language Detection & $2.853_{\pm 0.020}$ & $2.911_{\pm 0.019}$ & $2.862_{\pm 0.018}$ \\
Word Semantics & $1.999_{\pm 0.023}$ & $1.870_{\pm 0.039}$ & $1.902_{\pm 0.024}$ \\
Wrong Candidate Generation & $2.187_{\pm 0.028}$ & $2.192_{\pm 0.023}$ & $2.140_{\pm 0.020}$ \\
\midrule 
Average & $1.985_{\pm 0.022}$ & $1.907_{\pm 0.027}$ & $1.883_{\pm 0.032}$ \\
\bottomrule
\end{tabular}
\label{tab:ni_pretraining_large}
\end{table}

\subsection{Ablations} \label{supp:ablations}

We report ablations on the skills graph and the online component of \name. Instead of using $A$ in Algorithm~\ref{alg:skillit}, we study the performance when the identity matrix is used instead; intuitively, this corresponds to a misspecified skills graph where no skill influences another skill. We refer this approach as ``No graph''. Note that the opposite case of a complete graph recovers skill-stratified sampling, which we already have as a baseline.

Second, instead of sampling over multiple rounds and weighting according to the loss of each skill, we study the effect of setting $T = 1$, which only uses a softmax on $A$ to yield static weights on the skills. We refer to this approach as ``Static''. We omit results on Natural Instructions continual pre-training, since \name uses $T = 1$ and using no graph with $T = 1$ recovers skill-stratified sampling. Intuitively, we expect the static version of \name to perform somewhat well unless there is significant discrepancy among the losses (e.g. in synthetics where the loss on one skill can be close to $0$ while the other is not, versus in Natural Instructions where all losses decrease consistently). For both ablations, we sweep over values of $\eta = [0.1, 0.2, 0.5, 0.8]$.

Figure~\ref{fig:lego_ablation_no_graph} shows the comparison between \name and no graph on the continual pre-training LEGO experiment, and Figure~\ref{fig:lego_ablation_static} shows the comparison between \name and a static approach. We see that both the graph and the online dynamics of \name are important for its performance. In particular, using no graph results in allocating significant weight to harder skills early on, even though many of them have easier prerequisite skills (such as skill 3 having edges to skills 1 and 2). Using a static graph results in consistent allocation of significant weight to prerequisite skills even after their validation losses converge to near $0$, and thus the harder skills that have higher loss are not learned quickly afterwards.

% Figure environment removed

% Figure environment removed


We perform the same ablation on the Addition dataset---the results for this are shown in Figures~\ref{fig:addn_ablation_no_graph} and~Figure~\ref{fig:addn_ablation_static}.
We find that these simple baselines, including using a static graph and no graph perform similarly to \name on average across all skills---while \name performs the best on skill 2 compared to vanilla multiplicative weights, and \name performs the best on skill 1 compared to a static graph. 
This suggests that Addition is somewhat easier than the other datasets that we consider, as \name still outperforms other baselines, as shown in Figure~\ref{fig:lego_mw}. 

% Figure environment removed

% Figure environment removed


Figure~\ref{fig:lego_one_skill_ablation} compares \name, no graph, and static data selection for the LEGO fine-tuning experiment. No graph can be interpreted as allocating equal weight to all training skills not equal to the target skill, and varying this weight versus the weight on the target skill. While \name and setting $T = 1$ behave similarly, we see that \name is slightly better than using no graph. For instance, \name obtains a validation loss of $0.05$ in $2000$ steps, compared to $2050$-$2200$ steps when using no graph.

% Figure environment removed


Figure~\ref{fig:spanish_qg_ablation} and~\ref{fig:stance_detection_ablation} compare \name, no graph, and static data selection for the Natural Instructions fine-tuning experiments. For both Spanish QG and stance detection, \name attains lower loss than using no graph or using $T = 1$ round.


% Figure environment removed

% Figure environment removed

Figure~\ref{fig:ni_test_ablation} compares \name and static data selection for the Natural Instructions out-of-domain experiment. \name attains the lowest validation loss on $7$ out of $12$ evaluation skills. It has an average loss of $2.540$ compared to a range of $2.541$-$2.551$ for static data selection.

% Figure environment removed