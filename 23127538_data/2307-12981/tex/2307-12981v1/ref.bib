% Encoding: UTF-8
@String{i3d          = {I3D}}
@String{aaai         = {AAAI}}
@String{aaais        = {AAAI Symposium}}
@String{aas          = {Ann. Appl. Stat.}}
@String{ab           = {Adapt. Behav.}}
@String{accv         = {ACCV}}
@String{acl          = {ACL}}
@String{acml         = {ACML}}
@String{acmmm        = {ACM MM}}
@String{acssc        = {ACSSC}}
@String{ai           = {Artif. Intell.}}
@String{aim          = {AI Mag.}}
@String{aistats      = {AISTATS}}
@String{am           = {Ann. Math.}}
@String{ampsy        = {Am. Psychol.}}
@String{ap           = {Atten. Perform.}}
@String{arp          = {Annu. Rev. Psychol.}}
@String{arxiv        = {arXiv:}}
@String{as           = {Ann. Stat.}}
@String{asplos       = {ASPLOS}}
@String{autorobot    = {Auton. Robots}}
@String{avbpa        = {AVBPA}}
@String{ba           = {Bayesian Anal.}}
@String{bbs          = {Behav. Brain Sci.}}
@String{bc           = {Biol. Cybern.}}
@String{biorxiv      = {bioRxiv}}
@String{bjps         = {BJPS}}
@String{bmvc         = {BMVC}}
@String{cacm         = {Commun. ACM}}
@String{case         = {CASE}}
@String{cb           = {Curr. Biol.}}
@String{cc           = {Cereb. Cortex}}
@String{ccn          = {CCN}}
@String{ccs          = {CCS}}
@String{cdc          = {CDC}}
@String{cdps         = {Curr. Dir. Psychol. Sci.}}
@String{cell         = {Cell}}
@String{cga          = {IEEE CGA}}
@String{cgf          = {CGF}}
@String{cgi          = {CGI}}
@String{cgip         = {CGIP}}
@String{chi          = {CHI}}
@String{childdev     = {Child Dev.}}
@String{cikm         = {CIKM}}
@String{civr         = {CIVR}}
@String{cmmr         = {CMMR}}
@String{cmvp         = {CMVP}}
@String{cog          = {Cognition}}
@String{cogdev       = {Cognit. Dev.}}
@String{cogneuropsy  = {Cogn. Neuropsychol.}}
@String{cogpsy       = {Cognit. Psychol.}}
@String{cogsci       = {CogSci}}
@String{cogscij      = {Cognit. Sci.}}
@String{coling       = {COLING}}
@String{colt         = {COLT}}
@String{compstat     = {COMPSTAT}}
@String{compsys      = {Complex Syst.}}
@String{coneur       = {Curr. Opin. Neurobiol.}}
@String{conll        = {CoNLL}}
@String{conn1993     = {Proc. 1993 Connect. Models Summer Sch.}}
@String{corl         = {CoRL}}
@String{csur         = {ACM CSUR}}
@String{cvgip        = {CVGIP}}
@String{cvgipiu      = {CVGIP:IU}}
@String{cviu         = {CVIU}}
@String{cvpr         = {CVPR}}
@String{cvprw        = {CVPR Workshop}}
@String{das          = {DAS}}   
@String{devpsy       = {Dev. Sci.}}
@String{devsci       = {Dev. Psychol.}}
@String{dim          = {3DIM}}
@String{dis          = {DIS}}
@String{dpvt         = {3DPVT}}
@String{dv           = {3DV}}
@String{ecai         = {ECAI}}
@String{ecal         = {ECAL}}
@String{eccv         = {ECCV}}
@String{eccvw        = {ECCV Workshop}}
@String{ecml         = {ECML}}
@String{eics         = {EICS}}
@String{elife        = {eLife}}
@String{emmcvpr      = {EMMCVPR}}
@String{emnlp        = {EMNLP}}
@String{emnlpw       = {EMNLP Workshop}}
@String{eurographics = {Eurographics}}
@String{fg           = {FG}}
@String{fmcad        = {FMCAD}}
@String{focs         = {FOCS}}
@String{fse          = {FSE}}
@String{ftcgv        = {Foundations and Trends{\textregistered} in Computer Graphics and Vision}}
@String{ftml         = {Foundations and Trends{\textregistered} in Machine Learning}}
@String{ftr          = {Foundations and Trends{\textregistered} in Robotics}}
@String{gcpr         = {GCPR}}
@String{graphite     = {GRAPHITE}}
@String{hpca         = {HPCA}}
@String{humanoids    = {Humanoids}}
@String{icad         = {ICAD}}
@String{icann        = {ICANN}}
@String{icassp       = {ICASSP}}
@String{iccp         = {ICCP}}
@String{iccv         = {ICCV}}
@String{iccvw        = {ICCV Workshop}}
@String{icdar        = {ICDAR}}
@String{icdl         = {ICDL}}
@String{icdm         = {ICDM}}
@String{icdmw        = {ICDM Workshop}}
@String{icfp         = {ICFP}}
@String{icilp        = {ICILP}}
@String{icip         = {ICIP}}
@String{iclr         = {ICLR}}
@String{iclrw        = {ICLR Workshop}}
@String{icml         = {ICML}}
@String{icmlw        = {ICML Workshop}}
@String{icpr         = {ICPR}}
@String{icra         = {ICRA}}
@String{icraw        = {ICRA Workshop}}
@String{icse         = {ICSE}}
@String{icvgip       = {ICVGIP}}
@String{ieeemm       = {IEEE MM}}
@String{ijcai        = {IJCAI}}
@String{ijcnn        = {IJCNN}}
@String{ijcv         = {IJCV}}
@String{ijdar        = {IJDAR}}
@String{ijprai       = {IJPRAI}}
@String{ijrr         = {IJRR}}
@String{interspeech  = {Interspeech}}
@String{iros         = {IROS}}
@String{isar         = {ISAR}}
@String{isca         = {ISCA}}
@String{iser         = {ISER}}
@String{ismar        = {ISMAR}}
@String{ismir        = {ISMIR}}
@String{isrr         = {ISRR}}
@String{ivc          = {IVC}}
@String{jacm         = {JACM}}
@String{jacsa        = {J. Acoust. Soc. Am.}}
@String{jair         = {JAIR}}
@String{jama         = {JAMA}}
@String{jamia        = {JAMIA}}
@String{jasa         = {J. Am. Stat. Assoc.}}
@String{jcn          = {J. Cognit. Neurosci.}}
@String{jepg         = {J. Exp. Psychol. Gen.}}
@String{jephpp       = {J. Exp. Psychol. Hum. Percept. Perform.}}
@String{jeplmc       = {J. Exp. Psychol. Learn. Mem. Cogn.}}
@String{jfr          = {J. Field Rob.}}
@String{jmlr         = {JMLR}}
@String{jmp          = {J. Math. Psychol.}}
@String{jneuro       = {J. Neurosci.}}
@String{jneurophy    = {J. Neurophysiol.}}
@String{josa         = {JOSA}}
@String{josaa        = {JOSA A}}
@String{joser        = {JOSER}}
@String{jov          = {JOV}}
@String{jphysio      = {J. Physiol.}}
@String{kdd          = {KDD}}
@String{mia          = {MIA}}
@String{miccai       = {MICCAI}}
@String{micro        = {MICRO}}
@String{mlj          = {MLJ}}
@String{mmsys        = {Multimed. Syst.}}
@String{mobicom      = {MobiCom}}
@String{mva          = {MVA}}
@String{naacl-hlt    = {NAACL-HLT}}
@String{natcomm      = {Nat. Commun.}}
@String{nathb        = {Nat. Hum. Behav.}}
@String{natmed       = {Nat. Med.}}
@String{natmi        = {Nat. Mach. Intell.}}
@String{natneuro     = {Nat. Neurosci.}}
@String{nature       = {Nat.}}
@String{nc           = {Neural Comput.}}
@String{nct          = {Neurocomputing}}
@String{ndss         = {NDSS}}
@String{neuron       = {Neuron}}
@String{nips         = {NeurIPS}}
@String{nipsw        = {NeurIPS Workshop}}
@String{nn           = {Neural Netw.}}
@String{npar         = {NPAR}}
@String{nsdi         = {NSDI}}
@String{nsr          = {NSR}}
@String{oopsla       = {OOPSLA}}
@String{osdi         = {OSDI}}
@String{pakdd        = {PAKDD}}
@String{pbr          = {Psychon. Bull. Rev.}}
@String{pdp          = {Parallel Distributed Processing}}
@String{percept      = {Percept.}}
@String{pg           = {PG}}
@String{pieee        = {Proc. IEEE}}
@String{pkdd         = {PKDD}}
@String{pldi         = {PLDI}}
@String{ploscb       = {PLOS Comput. Biol.}}
@String{plosone      = {PLOS One}}
@String{pnas         = {PNAS}}
@String{pods         = {PODS}}
@String{popl         = {POPL}}
@String{pp           = {Percept. Psychophys.}}
@String{ppopp        = {PPoPP}}
@String{pr           = {PR}}
@String{prl          = {PRL}}
@String{prsb         = {Proc. R. Soc. B}}
@String{prx          = {Phys. Rev. X}}
@String{psybull      = {Psychol. Bull.}}
@String{psymet       = {Psychometrika}}
@String{psyrev       = {Psychol. Rev.}}
@String{psysci       = {Psychol. Sci.}}
@String{ral          = {IEEE RA-L}}
@String{ram          = {IEEE RAM}}
@String{ras          = {RAS}}
@String{rss          = {RSS}}
@String{rssw         = {RSS Workshop}}
@String{sc           = {Stat. Comput.}}
@String{sca          = {SCA}}
@String{sciadv       = {Sci. Adv.}}
@String{sciamer      = {Sci. Amer.}}
@String{science      = {Sci.}}
@String{scirobot     = {Sci. Robotics}}
@String{sgp          = {SGP}}
@String{sigasia      = {SIGGRAPH Asia}}
@String{sigasiacrs   = {SIGGRAPH Asia Courses}}
@String{sigcomm      = {SIGCOMM}}
@String{siggraph     = {SIGGRAPH}}
@String{siggraphcrs  = {SIGGRAPH Courses}}
@String{sigir        = {SIGIR}}
@String{sigmod       = {SIGMOD}}
@String{smi          = {SMI}}
@String{snp          = {S\&P}}
@String{soda         = {SODA}}
@String{sp           = {Signal Process.}}
@String{spie         = {SPIE}}
@String{spl          = {IEEE SPL}}
@String{spm          = {IEEE SPM}}
@String{stoc         = {STOC}}
@String{synt         = {Workshop Synth.}}
@String{tacas        = {TACAS}}
@String{tacl         = {TACL}}
@String{tap          = {ACM TAP}}
@String{tark         = {TARK}}
@String{tase         = {IEEE T-ASE}}
@String{taslp        = {IEEE TASLP}}
@String{tassp        = {IEEE TASSP}}
@String{tcasi        = {IEEE TCAS I}}
@String{tcasii       = {IEEE TCAS II}}
@String{tci          = {IEEE TCI}}
@String{tcsvt        = {IEEE TCSVT}}
@String{tics         = {TiCS}}
@String{tip          = {IEEE TIP}}
@String{tit          = {IEEE TIT}}
@String{tmi          = {IEEE TMI}}
@String{tmm          = {IEEE TMM}}
@String{tnn          = {IEEE TNN}}
@String{tnnls        = {IEEE TNNLS}}
@String{tog          = {ACM TOG}}
@String{tois         = {ACM TOIS}}
@String{topics       = {topiCS}}
@String{tpami        = {IEEE TPAMI}}
@String{tra          = {IEEE T. Robotic. Autom.}}
@String{tro          = {IEEE TRO}}
@String{tsap         = {IEEE TSAP}}
@String{tsmc         = {IEEE TSMC}}
@String{tvcg         = {IEEE TVCG}}
@String{uai          = {UAI}}
@String{ubicomp      = {UbiComp}}
@String{uist         = {UIST}}
@String{usenix       = {USENIX Security}}
@String{vc           = {Vis. Comput.}}
@String{vcip         = {VCIP}}
@String{visapp       = {VISAPP}}
@String{visionres    = {Vis. Res.}}
@String{vldb         = {VLDB}}
@String{wacv         = {WACV}}
@String{wafr         = {WAFR}}
@String{wear         = {Wear}}
@String{whc          = {WHC}}
@String{wsdm         = {WSDM}}
@String{www          = {WWW}}

@article{Azuma2022ScanQA3Q,
  title={{ScanQA}: {3D} Question Answering for Spatial Scene Understanding},
  author={Daich Azuma and Taiki Miyanishi and Shuhei Kurita and Motoki Kawanabe},
  journal={2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2022},
  pages={19107-19117}
}

@inproceedings{Huang2021TextGuidedGN,
  title={Text-Guided Graph Neural Networks for Referring {3D} Instance Segmentation},
  author={Pin-Hao Huang and Han-Hung Lee and Hwann-Tzong Chen and Tyng-Luh Liu},
  booktitle={AAAI},
  year={2021}
}

@article{Feng2021FreeformDG,
  title={Free-form Description Guided 3D Visual Graph Network for Object Grounding in Point Cloud},
  author={Mingtao Feng and Zhen Li and Qi Li and Liang Zhang and Xiangdong Zhang and Guangming Zhu and Hui Zhang and Yaonan Wang and Ajmal S. Mian},
  journal={2021 IEEE/CVF International Conference on Computer Vision (ICCV)},
  year={2021},
  pages={3702-3711}
}

@inproceedings{Achlioptas2020ReferIt3DNL,
  title={{ReferIt3D}: Neural Listeners for Fine-Grained {3D} Object Identification in Real-World Scenes},
  author={Panos Achlioptas and Ahmed Abdelreheem and Fei Xia and Mohamed Elhoseiny and Leonidas J. Guibas},
  booktitle={ECCV},
  year={2020}
}

@inproceedings{yu2019multi,
  title={Multi-target embodied question answering},
  author={Yu, Licheng and Chen, Xinlei and Gkioxari, Georgia and Bansal, Mohit and Berg, Tamara L and Batra, Dhruv},
  booktitle= CVPR,
  pages={6309--6318},
  year={2019}
}

@article{Das2018EmbodiedQA,
  title={Embodied Question Answering},
  author={Abhishek Das and Samyak Datta and Georgia Gkioxari and Stefan Lee and Devi Parikh and Dhruv Batra},
  journal={2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)},
  year={2018},
  pages={2135-213509}
}

@inproceedings{chen2021scan2cap,
  title={Scan2cap: Context-aware dense captioning in rgb-d scans},
  author={Chen, Zhenyu and Gholami, Ali and Nie{\ss}ner, Matthias and Chang, Angel X},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={3193--3203},
  year={2021}
}

@inproceedings{yu2016modeling,
  title={Modeling context in referring expressions},
  author={Yu, Licheng and Poirson, Patrick and Yang, Shan and Berg, Alexander C and Berg, Tamara L},
  booktitle={Computer Vision--ECCV 2016: 14th European Conference, Amsterdam, The Netherlands, October 11-14, 2016, Proceedings, Part II 14},
  pages={69--85},
  year={2016},
  organization={Springer}
}

@article{chen2015microsoft,
  title={Microsoft coco captions: Data collection and evaluation server},
  author={Chen, Xinlei and Fang, Hao and Lin, Tsung-Yi and Vedantam, Ramakrishna and Gupta, Saurabh and Doll{\'a}r, Piotr and Zitnick, C Lawrence},
  journal={arXiv preprint arXiv:1504.00325},
  year={2015}
}

@InProceedings{balanced_binary_vqa,
author = {Peng Zhang and Yash Goyal and Douglas Summers{-}Stay and Dhruv Batra and Devi Parikh},
title = {{Y}in and {Y}ang: Balancing and Answering Binary Visual Questions},
booktitle = {Conference on Computer Vision and Pattern Recognition (CVPR)},
year = {2016},
}

@InProceedings{balanced_vqa_v2,
author = {Yash Goyal and Tejas Khot and Douglas Summers{-}Stay and Dhruv Batra and Devi Parikh},
title = {Making the {V} in {VQA} Matter: Elevating the Role of Image Understanding in {V}isual {Q}uestion {A}nswering},
booktitle = {Conference on Computer Vision and Pattern Recognition (CVPR)},
year = {2017},
}

@inproceedings{jia2021scaling,
  title={Scaling up visual and vision-language representation learning with noisy text supervision},
  author={Jia, Chao and Yang, Yinfei and Xia, Ye and Chen, Yi-Ting and Parekh, Zarana and Pham, Hieu and Le, Quoc and Sung, Yun-Hsuan and Li, Zhen and Duerig, Tom},
  booktitle={International Conference on Machine Learning},
  pages={4904--4916},
  year={2021},
  organization={PMLR}
}

@inproceedings{radford2021learning,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle={International conference on machine learning},
  pages={8748--8763},
  year={2021},
  organization={PMLR}
}

@article{gong2023multimodal,
  title={{MultiModal-GPT}: A Vision and Language Model for Dialogue with Humans},
  author={Gong, Tao and Lyu, Chengqi and Zhang, Shilong and Wang, Yudong and Zheng, Miao and Zhao, Qian and Liu, Kuikun and Zhang, Wenwei and Luo, Ping and Chen, Kai},
  journal={arXiv preprint arXiv:2305.04790},
  year={2023}
}

@article{liu2023visual,
  title={Visual instruction tuning},
  author={Liu, Haotian and Li, Chunyuan and Wu, Qingyang and Lee, Yong Jae},
  journal={arXiv preprint arXiv:2304.08485},
  year={2023}
}

@article{li2023blip,
  title={{BLIP-2}: Bootstrapping language-image pre-training with frozen image encoders and large language models},
  author={Li, Junnan and Li, Dongxu and Savarese, Silvio and Hoi, Steven},
  journal={arXiv preprint arXiv:2301.12597},
  year={2023}
}

@misc{dollyblog,   
    title = {Free Dolly: Introducing the World's First Truly Open Instruction-Tuned LLM},   
    url = {https://www.databricks.com/blog/2023/04/12/dolly-first-open-commercially-viable-instruction-tuned-llm},   
    author = {Databricks},
    year = {2023}
}

@article{sun2023principle,
  title={Principle-Driven Self-Alignment of Language Models from Scratch with Minimal Human Supervision},
  author={Sun, Zhiqing and Shen, Yikang and Zhou, Qinhong and Zhang, Hongxin and Chen, Zhenfang and Cox, David and Yang, Yiming and Gan, Chuang},
  journal={arXiv e-prints},
  pages={arXiv--2305},
  year={2023}
}

@article{chung2022scaling,
  title={Scaling instruction-finetuned language models},
  author={Chung, Hyung Won and Hou, Le and Longpre, Shayne and Zoph, Barret and Tay, Yi and Fedus, William and Li, Eric and Wang, Xuezhi and Dehghani, Mostafa and Brahma, Siddhartha and others},
  journal={arXiv preprint arXiv:2210.11416},
  year={2022}
}

@article{ouyang2022training,
  title={Training language models to follow instructions with human feedback},
  author={Ouyang, Long and Wu, Jeffrey and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and others},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={27730--27744},
  year={2022}
}

@article{raffel2020exploring,
  title={Exploring the limits of transfer learning with a unified text-to-text transformer},
  author={Raffel, Colin and Shazeer, Noam and Roberts, Adam and Lee, Katherine and Narang, Sharan and Matena, Michael and Zhou, Yanqi and Li, Wei and Liu, Peter J},
  journal={The Journal of Machine Learning Research},
  volume={21},
  number={1},
  pages={5485--5551},
  year={2020},
  publisher={JMLRORG}
}

@article{OpenAI2023GPT4TR,
  title={{GPT-4} Technical Report},
  author={OpenAI},
  journal={ArXiv},
  year={2023},
  volume={abs/2303.08774}
}

@article{chowdhery2022palm,
  title={Palm: Scaling language modeling with pathways},
  author={Chowdhery, Aakanksha and Narang, Sharan and Devlin, Jacob and Bosma, Maarten and Mishra, Gaurav and Roberts, Adam and Barham, Paul and Chung, Hyung Won and Sutton, Charles and Gehrmann, Sebastian and others},
  journal={arXiv preprint arXiv:2204.02311},
  year={2022}
}

@article{radford2019language,
  title={Language models are unsupervised multitask learners},
  author={Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya and others},
  journal={OpenAI blog},
  volume={1},
  number={8},
  pages={9},
  year={2019}
}

@article{devlin2018bert,
  title={Bert: Pre-training of deep bidirectional transformers for language understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  journal={arXiv preprint arXiv:1810.04805},
  year={2018}
}

@article{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={Advances in neural information processing systems},
  pages={1877--1901},
  year={2020}
}

@article{Ye20213DQA,
  title={{3D} Question Answering},
  author={Shuquan Ye and Dongdong Chen and Songfang Han and Jing Liao},
  journal={IEEE transactions on visualization and computer graphics},
  year={2021},
  volume={PP}
}

@article{chen2020scanrefer,
    title={{ScanRefer}: {3D} Object Localization in {RGB-D} Scans using Natural Language},
    author={Chen, Dave Zhenyu and Chang, Angel X and Nie{\ss}ner, Matthias},
    journal={16th European Conference on Computer Vision (ECCV)},
    year={2020}
}

@misc{zhu2023chatgpt,
      title={ChatGPT Asks, BLIP-2 Answers: Automatic Questioning Towards Enriched Visual Descriptions}, 
      author={Deyao Zhu and Jun Chen and Kilichbek Haydarov and Xiaoqian Shen and Wenxuan Zhang and Mohamed Elhoseiny},
      year={2023},
      eprint={2303.06594},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@article{Deitke2022ObjaverseAU,
  title={Objaverse: A Universe of Annotated {3D} Objects},
  author={Matt Deitke and Dustin Schwenk and Jordi Salvador and Luca Weihs and Oscar Michel and Eli VanderBilt and Ludwig Schmidt and Kiana Ehsani and Aniruddha Kembhavi and Ali Farhadi},
  journal={ArXiv},
  year={2022},
  volume={abs/2212.08051}
}

@article{Dai2017ScanNetR3,
  title={{ScanNet}: Richly-Annotated {3D} Reconstructions of Indoor Scenes},
  author={Angela Dai and Angel X. Chang and Manolis Savva and Maciej Halber and Thomas A. Funkhouser and Matthias Nie{\ss}ner},
  journal={2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2017},
  pages={2432-2443}
}

@article{Chen2019ScanRefer3O,
  title={{ScanRefer}: {3D} Object Localization in RGB-D Scans using Natural Language},
  author={Dave Zhenyu Chen and Angel X. Chang and Matthias Nie{\ss}ner},
  journal={ArXiv},
  year={2019},
  volume={abs/1912.08830}
}

@inproceedings{achlioptas2020referit_3d,
    title={{ReferIt3D}: Neural Listeners for Fine-Grained 3D Object Identification in Real-World Scenes},
    author={Achlioptas, Panos and Abdelreheem, Ahmed and Xia, Fei and Elhoseiny, Mohamed and Guibas, Leonidas J.},
    booktitle={16th European Conference on Computer Vision (ECCV)},
    year={2020}
}

@inproceedings{ramakrishnan2021hm3d,
  title={Habitat-Matterport {3D} Dataset ({HM3D}): 1000 Large-scale {3D} Environments for Embodied {AI}},
  author={Santhosh Kumar Ramakrishnan and Aaron Gokaslan and Erik Wijmans and Oleksandr Maksymets and Alexander Clegg and John M Turner and Eric Undersander and Wojciech Galuba and Andrew Westbury and Angel X Chang and Manolis Savva and Yili Zhao and Dhruv Batra},
  booktitle={Thirty-fifth Conference on Neural Information Processing Systems Datasets and Benchmarks Track},
  year={2021},
  url={https://arxiv.org/abs/2109.08238}
}

@article{yadav2022habitat, title={Habitat-Matterport {3D} Semantics Dataset}, author={Yadav, Karmesh and Ramrakhya, Ram and Ramakrishnan, Santhosh Kumar and Gervet, Theo and Turner, John and Gokaslan, Aaron and Maestre, Noah and Chang, Angel Xuan and Batra, Dhruv and Savva, Manolis and others}, journal={arXiv preprint arXiv:2210.05633}, year={2022}, url={https://arxiv.org/abs/2210.05633} }

@misc{jatavallabhula2023conceptfusion,
      title={ConceptFusion: Open-set Multimodal {3D} Mapping}, 
      author={Krishna Murthy Jatavallabhula and Alihusein Kuwajerwala and Qiao Gu and Mohd Omama and Tao Chen and Shuang Li and Ganesh Iyer and Soroush Saryazdi and Nikhil Keetha and Ayush Tewari and Joshua B. Tenenbaum and Celso Miguel de Melo and Madhava Krishna and Liam Paull and Florian Shkurti and Antonio Torralba},
      year={2023},
      eprint={2302.07241},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@article{gradslam,
    author  = { {Krishna Murthy}, Jatavallabhula and Saryazdi, Soroush and Iyer, Ganesh and Paull, Liam },
    title   = { gradSLAM: Dense SLAM meets Automatic Differentiation },
    journal = { arXiv },
    year    = { 2020 },
}

@misc{hong20233d,
      title={{3D} Concept Learning and Reasoning from Multi-View Images}, 
      author={Yining Hong and Chunru Lin and Yilun Du and Zhenfang Chen and Joshua B. Tenenbaum and Chuang Gan},
      year={2023},
      eprint={2303.11327},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@article{Chen2021Pix2seqAL,
  title={Pix2seq: A Language Modeling Framework for Object Detection},
  author={Ting Chen and Saurabh Saxena and Lala Li and David J. Fleet and Geoffrey E. Hinton},
  journal={ArXiv},
  year={2021},
  volume={abs/2109.10852}
}

@inproceedings{Wang2022UnifyingAT,
  title={Unifying Architectures, Tasks, and Modalities Through a Simple Sequence-to-Sequence Learning Framework},
  author={Peng Wang and An Yang and Rui Men and Junyang Lin and Shuai Bai and Zhikang Li and Jianxin Ma and Chang Zhou and Jingren Zhou and Hongxia Yang},
  booktitle={International Conference on Machine Learning},
  year={2022}
}

@inproceedings{Jaegle2021PerceiverGP,
  title={Perceiver: General Perception with Iterative Attention},
  author={Andrew Jaegle and Felix Gimeno and Andrew Brock and Andrew Zisserman and Oriol Vinyals and Jo{\~a}o Carreira},
  booktitle={International Conference on Machine Learning},
  year={2021}
}

@misc{li2023blip2,
      title={{BLIP-2}: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models}, 
      author={Junnan Li and Dongxu Li and Silvio Savarese and Steven Hoi},
      year={2023},
      eprint={2301.12597},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@article{DBLP:journals/corr/abs-2107-06278,
  author       = {Bowen Cheng and
                  Alexander G. Schwing and
                  Alexander Kirillov},
  title        = {Per-Pixel Classification is Not All You Need for Semantic Segmentation},
  journal      = {CoRR},
  volume       = {abs/2107.06278},
  year         = {2021},
  url          = {https://arxiv.org/abs/2107.06278},
  eprinttype    = {arXiv},
  eprint       = {2107.06278},
  timestamp    = {Wed, 21 Jul 2021 15:55:35 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2107-06278.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{Alayrac2022Flamingo,
    title   = {Flamingo: a Visual Language Model for Few-Shot Learning},
    author  = {Jean-Baptiste Alayrac et al},
    year    = {2022}
}

@article{Gadre2022CLIPOW,
  title={{CLIP} on Wheels: Zero-Shot Object Navigation as Object Localization and Exploration},
  author={Samir Yitzhak Gadre and Mitchell Wortsman and Gabriel Ilharco and Ludwig Schmidt and Shuran Song},
  journal={ArXiv},
  year={2022},
  volume={abs/2203.10421}
}

@misc{huang2023visual,
      title={Visual Language Maps for Robot Navigation}, 
      author={Chenguang Huang and Oier Mees and Andy Zeng and Wolfram Burgard},
      year={2023},
      eprint={2210.05714},
      archivePrefix={arXiv},
      primaryClass={cs.RO}
}

@InProceedings{Sun_2022_CVPR,
    author    = {Sun, Cheng and Sun, Min and Chen, Hwann-Tzong},
    title     = {Direct Voxel Grid Optimization: Super-Fast Convergence for Radiance Fields Reconstruction},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    month     = {June},
    year      = {2022},
    pages     = {5459-5469}
}

@misc{li2022lavis,
      title={{LAVIS}: A Library for Language-Vision Intelligence}, 
      author={Dongxu Li and Junnan Li and Hung Le and Guangsen Wang and Silvio Savarese and Steven C. H. Hoi},
      year={2022},
      eprint={2209.09019},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{anas_awadalla_2023_7733589,
  author = {Awadalla, Anas and Gao, Irena and Gardner, Joshua and Hessel, Jack and Hanafy, Yusuf and Zhu, Wanrong and Marathe, Kalyani and Bitton, Yonatan and Gadre, Samir and Jitsev, Jenia and Kornblith, Simon and Koh, Pang Wei and Ilharco, Gabriel and Wortsman, Mitchell and Schmidt, Ludwig},
  title = {OpenFlamingo},
  month        = mar,
  year         = 2023,
  publisher    = {Zenodo},
  version      = {v0.1.1},
  doi          = {10.5281/zenodo.7733589},
  url          = {https://doi.org/10.5281/zenodo.7733589}
}

@misc{openai2023gpt4,
      title={{GPT}-4 Technical Report}, 
      author={OpenAI},
      year={2023},
      eprint={2303.08774},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{wijmans2019dd,
  title={Dd-ppo: Learning near-perfect pointgoal navigators from 2.5 billion frames},
  author={Wijmans, Erik and Kadian, Abhishek and Morcos, Ari and Lee, Stefan and Essa, Irfan and Parikh, Devi and Savva, Manolis and Batra, Dhruv},
  journal={arXiv preprint arXiv:1911.00357},
  year={2019}
}

@article{Qi2019DeepHV,
  title={Deep Hough Voting for 3D Object Detection in Point Clouds},
  author={C. Qi and Or Litany and Kaiming He and Leonidas J. Guibas},
  journal={2019 IEEE/CVF International Conference on Computer Vision (ICCV)},
  year={2019},
  pages={9276-9285}
}

@misc{hu2016natural,
      title={Natural Language Object Retrieval}, 
      author={Ronghang Hu and Huazhe Xu and Marcus Rohrbach and Jiashi Feng and Kate Saenko and Trevor Darrell},
      year={2016},
      eprint={1511.04164},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{yang2019fast,
      title={A Fast and Accurate One-Stage Approach to Visual Grounding}, 
      author={Zhengyuan Yang and Boqing Gong and Liwei Wang and Wenbing Huang and Dong Yu and Jiebo Luo},
      year={2019},
      eprint={1908.06354},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@inproceedings{savva2019habitat,
  title={Habitat: A platform for embodied ai research},
  author={Savva, Manolis and Kadian, Abhishek and Maksymets, Oleksandr and Zhao, Yili and Wijmans, Erik and Jain, Bhavana and Straub, Julian and Liu, Jia and Koltun, Vladlen and Malik, Jitendra and others},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={9339--9347},
  year={2019}
}

@article{ramakrishnan2021habitat,
  title={Habitat-matterport 3d dataset (hm3d): 1000 large-scale 3d environments for embodied ai},
  author={Ramakrishnan, Santhosh K and Gokaslan, Aaron and Wijmans, Erik and Maksymets, Oleksandr and Clegg, Alex and Turner, John and Undersander, Eric and Galuba, Wojciech and Westbury, Andrew and Chang, Angel X and others},
  journal={arXiv preprint arXiv:2109.08238},
  year={2021}
}

@article{hong2023threedclr,
            title={3D Concept Learning and Reasoning from Multi-View Images},
            author={Hong, Yining and Lin, Chunru and Du, Yilun and Chen, Zhenfang and Tenenbaum, Joshua B and Gan, Chuang},
            journal={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
            year={2023}
}

@article{hong20223d,
  title={3d concept grounding on neural fields},
  author={Hong, Yining and Du, Yilun and Lin, Chunru and Tenenbaum, Josh and Gan, Chuang},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={7769--7782},
  year={2022}
}
